start	end	text
0	9280	It's such a pleasure to be here with you today to talk about the rise of artificial
9280	15920	intelligence that you heard about and what both the opportunities are and the challenges
15920	19160	that we need to overcome to get these opportunities.
19160	24440	So I want to encourage you to think big.
24440	31040	I love the historical intro we got with the toilet paper roll and the dinosaurs reminding
31040	34120	us of the big picture.
34120	39920	So if we zoom out even bigger, as we see here, here we are at 13.8 billion years after our
39920	44480	big bang and realizing that something remarkable has happened.
44480	50520	Finally, after all this time, our universe has woken up and become aware of itself through
50520	54760	us conscious beings on this little spinning blue ball in space.
54760	60480	And when we look out into this beautiful cosmos, we discover something very humbling.
60480	68040	We discover that a universe is vastly grander than we thought and that it looks mostly dead
68040	69040	at first glance.
69040	75720	But we've also discovered something truly inspiring, which is that by carefully studying
75720	82720	our universe and its laws and building technology, we actually have much more influence than
82720	84720	we thought.
84720	91400	For example, we can, through science and technology, harness the powers of our universe and start
91400	95960	exploring it and do all sorts of great things.
95960	107000	And when we think about rockets, for example, as an example of what we can do with tech,
107000	112120	it gives us a great metaphor that can guide us through this morning.
112120	118400	To do inspiring things with technology, it's not enough to make your technology powerful.
118400	127680	You also have to figure out, of course, how to steer it and where you want to go with it.
127680	133440	Now, there's another journey that's much more inspiring still than that with rockets, which
133440	136600	is that with artificial intelligence, which we're going to go on together this morning,
136600	140040	where the passengers aren't just a few astronauts, but all of humanity.
140040	146960	So let's talk about this collective journey we're taking into the future with AI, thinking
146960	151840	about both the power, the steering, and the destination.
151840	152840	Okay?
152840	153840	Ready to go?
153840	155840	And jam on.
155840	161720	Let's begin with the power.
161720	165240	What is intelligence?
165240	171280	I define it just as the ability to accomplish goals, and the more complex the goals are,
171280	172920	the more intelligent.
172920	180520	And I give this very inclusive definition, covering both biological and non-biological
180520	188640	intelligence, because the key idea, in my opinion, which I'll try to sell you on here,
188640	195040	is that intelligence is all about information processing.
195040	200040	Many people think intelligence is something mysterious that can only exist in biological
200040	201040	organisms.
201240	208400	I call that carbon chauvinism, this idea that you can only be smart if you're made of meat.
208400	214080	And I think it's exactly the opposite idea that's powered the great progress in AI.
214080	219000	The idea that it doesn't matter whether the information is processed by carbon atoms in
219000	222840	neurons and brains, or by silicon atoms in our technology.
222840	226160	It's the information processing itself that matters.
226160	236440	And this simple idea has really, really transformed artificial intelligence, and greatly grown
236440	238320	the power of this tech.
238320	239320	Just think about it.
239320	245520	Not long ago, this was the state of the art in robots trying to walk.
245520	251720	It is extra embarrassing for me, because one of these is the MIT robot.
251720	253960	And that was just six years ago.
253960	255600	It was fast forward to today.
255600	256960	Can you see any difference?
263480	270640	In other words, the momentum in the field of artificial intelligence is really quite palpable.
270640	275240	Not long ago, we didn't have self-driving cars.
275240	280640	Now we have self-flying rockets that can land themselves with artificial intelligence.
284080	287920	Not long ago, we couldn't do face recognition.
287920	293000	Now we can do that great.
293000	296680	We can even simulate your face saying all sorts of things you never said, and we have
296680	301840	all these great tools that we heard about from Luca using artificial intelligence.
301840	305920	Not long ago, AI could not save lives.
305920	311040	I believe that soon artificial intelligence will eliminate more than one million pointless
311040	315360	road deaths on the Earth's highways.
315360	320680	And even more lives will be saved by eliminating stupid mistakes in health care.
320680	326000	And still more lives will be saved by actually accelerating the pace of medical research.
326000	331680	We already have AI that is as good as the best doctors at diagnosing prostate cancer,
331680	335600	lung cancer, various eye diseases.
336560	342000	The most lives of all I think in medicine will be saved by just accelerating the pace
342000	344200	of scientific research itself.
344200	350080	For example, for over 50 years, biologists have tried and failed to solve the protein
350080	355760	folding problem, where you start with a genetic sequence of a protein and you try to figure
355760	361560	out if it's going to fold up into a donut shape like the hemoglobin molecules that take
361560	364840	oxygen to your brains right now or to some other shape.
364840	368040	And then AI solved it.
368040	376440	And it's really cool to just look at how Google DeepMind's AlphaFold AI takes the amino acid
376440	383080	genetic sequence as input and just figures out how the protein folds up in 3D and really
383080	389960	spectacular agreement also with expensive and slow measurements from X-ray crystallography.
389960	395280	This is an example of AI for good, which I think can greatly accelerate drug discovery
395280	398880	and drug development.
398880	404680	Not long ago, staying on the theme of the growing power of AI, AI could not beat us at the Asian
404680	406000	Board Game of Go.
406000	411720	Raise your hand if you've ever tried playing Go.
411720	420040	And then, of course, Google DeepMind's AlphaGo and then later AlphaZero, MuZero software,
420040	424720	it took 3,000 years of human Go games and Go wisdom and put it all in the garbage can,
424720	430160	became the best Go player in the world by playing against itself for 24 hours.
430160	435960	And the most interesting thing of all was that it didn't just crush gamers, but it crushed
435960	441520	AI developers like myself who had spent all this time hand-crafting code to do it, all
441520	442800	made obsolete.
442800	449840	And the same AI was able to learn not just this game, but also at the same time become
449840	459160	the world's best player at chess, crushing stockfish and also at now many other games.
459160	465800	This year, 2022, we've seen spectacular progress in large language models that we'll hear
465800	468600	a lot more about later today.
468600	472440	And other models that just take a lot of it, massive amounts of input, train on them and
472440	474080	do cool things.
474080	478640	The Dali 2 AI, if you tell it, to show you a picture of an armchair in the shape of
478640	481960	an avocado.
481960	485760	This is what it comes up with.
485760	490720	One of all the language models so far I'm most impressed with is actually Google Palm,
490720	496080	which just came out a couple of months ago.
496080	500560	If you put in this joke into it like this, saying, hey, I was going to go fly visit my
500560	508840	family on April 6, my mom said, oh, great, your stepdad's poet reading is that night.
508840	511920	So now I'm flying in on April 7.
511920	523080	When this was put into this AI, this is how the AI explains the joke.
523080	536760	I'll shut up for a moment so you can read this.
536760	541280	The one that freaked me out the most was this example.
541280	547560	Same AI, so the input we give to it is Trevor has wanted to see the mountain with all of
547560	552640	the heads on it for a long time, so he finally drove out to see it.
552640	559600	What is the capital of the state that is directly east of the state that Trevor is currently
559600	564480	in?
564480	566000	You guys are really smart.
566000	571560	Can any of you answer this?
571560	581320	Just shout out if you have any thoughts.
581320	586320	The mountain with all the heads on it, what's that?
586320	587520	Mount Rushmore.
587520	588840	All right.
588840	592840	Where is Mount Rushmore?
592840	602200	Any takers?
602200	603200	This is pretty tough.
603200	607800	I couldn't do it, even though I live in the US.
607800	614960	So this is what the AI said, the mountain with all the heads on it is Mount Rushmore.
614960	617360	Mount Rushmore is in South Dakota.
617360	621600	The state directly east of South Dakota is Minnesota.
621600	624640	The capital of Minnesota is St. Paul.
624640	629640	The answer is St. Paul.
629640	638160	As recently as January, February of this year, I remember hearing many AI researchers saying,
638160	641160	oh, these large language models are just kind of fake.
641160	645760	They train on massive amounts of data to predict the next word and so on, but they don't really
645760	646920	understand anything.
646920	652680	They can't really do profound logical reasoning.
652680	661880	When you look at this, that criticism doesn't feel quite as convincing anymore, does it?
661880	665960	So things are happening very, very fast.
665960	676880	And to put this a little bit in context, this, the Google Palm model here, it has 540 billion
677440	682120	parameters in the neural network that's been trained here.
682120	687760	That's about a thousand times more than a mouse.
687760	689760	Our symposium is called Synapse.
689760	695080	A mouse has about 500 million synapses, which you could truly think of a single parameter
695080	696080	each.
696080	700000	And we humans, we have about 200 times more than that.
700000	705520	To put this in context, if we think about the memory capacity of our computational devices
705560	714880	over time, we see this familiar Moore's Law, where there's been a spectacular increase
714880	721800	of a thousand million, million times growth since the 1950s.
721800	732080	And here we are today, where you can now buy a little memory card about the size of my
732120	736760	thumbnail, twice that, for 100 bucks.
736760	741200	So it costs about $1 per terabyte.
741200	747640	And if we compare this with the amount of memory or data in these models, we see that
747640	752880	actually, you know, we're already far beyond the mouse.
752880	757040	Google Palm sits about here, you know, this is about the amount of data in the Google
757040	758040	Palm model.
758160	764000	Humans are a little bit above there, but you can buy 100 of these little cards.
764000	767280	That's about as much information as you have stored in your entire brain.
767280	773640	The hardware has already more or less caught up with the human hardware in some ways, even
773640	776720	though it's much less energy efficient and so on.
776720	781600	It seems like we're mainly just limited by having much more stupid software in our machines
781600	785800	than we have in our brains.
785800	787840	This begs the question, though.
787840	789800	How far will this go?
789800	795880	We've talked here about how amazing the growth of power of artificial intelligence has been.
795880	799640	And I hope with these examples, especially with the Mount Rushmore one, I can convince
799640	804960	you that really, AI is happening, whether we like it or not.
804960	807400	How far is it going to go?
807400	814800	Well, I like to think about this question in terms of this abstract landscape of tasks,
814800	821800	where the elevation represents how difficult it is for AI to do each task, and the sea
821800	828560	level represents what computers can do today.
828560	833960	The sea level is obviously rising, so an obvious takeaway from this is for all of you thinking
833960	839360	about your careers, be careful with careers right at the waterfront, which are in the
839360	842760	process of getting disrupted.
842760	850520	But the bigger question is, of course, how high is the water eventually going to rise?
850520	856840	Is it eventually going to submerge all land?
856840	863920	This is the definition of artificial general intelligence, AGI.
863920	869560	So with this definition, people who say, ah, you know, there'll always be jobs that humans
869560	878880	can do better than machines, are simply saying that there will never be AGI.
878880	883880	If you think this sounds like crazy science fiction, AGI, I want you to be clear on the
883880	888000	fact that there is something else which sounds like even more crazy science fiction, the
888000	891440	idea of super intelligence.
891440	896320	An idea which is actually quite simple, the idea is that if we actually do get the AGI,
896320	901600	and then, since by definition, machines can do all jobs better than humans, that includes
901600	908400	the job of AI development and everything else that is done by bending spoons.
908400	914680	So it opens up the controversial possibility that future AI development after that can
914680	920400	be done much faster, replacing the typical human research and development timescale
920400	927040	of years by months or weeks or hours or whatever it takes for machines to make better versions
927040	930160	of their software, etc.
930160	936080	And so if that happens, it opens up the possibility of a recursively self-improving technology
936080	940120	which could quickly leave us humans far, far behind.
940120	943520	Here, we need a bit of a reality check.
943520	949920	Is this just crazy science fiction speculation by people who have no idea about technology
949920	950920	really?
950920	954480	I'll let you decide that for yourselves by playing a little clip from a conference that
954480	959720	I was involved in organizing some years ago.
959720	962840	It's a fair science controversy.
962840	966680	On one hand, you have people like my former MIT colleague Rodney Brooks who would be like,
966680	970760	ah, this is all just bullshit, you know, this won't happen for centuries.
970760	977200	On the other hand, you have people like Demi Sassabis, CEO of Google DeepMind, gave us
977200	982480	AlphaZero and so much else who think it is going to happen and who's betting their whole
982480	986920	company on trying to build these things.
986920	995160	So here is the little video clip I'll share with you.
995160	1006200	Let's see if we have any luck here.
1006200	1008800	This is actually a very good metaphor for the whole talk.
1008800	1012560	With technology, what can possibly go wrong?
1012560	1016480	So before I asked if superintelligence is possible at all according to the laws of physics, now
1016480	1019080	I'm asking, will it actually happen?
1019080	1022240	Yes, no, or it's complicated?
1022240	1024600	A little bit complicated, but yes.
1024600	1030040	Yes, and if it doesn't, something terrible has happened to prevent it?
1030040	1031040	Yes.
1031040	1032040	Probably.
1032040	1033040	Yes.
1033040	1034040	Yes.
1034040	1035040	Yes.
1035040	1036040	Yes.
1036040	1037040	Yes.
1037040	1038040	Yes.
1038040	1039040	Yes.
1039040	1040040	No.
1040040	1045640	So what do we make of that?
1045640	1053000	Well, aside from the fact that Elon has a sense of humor, it's quite obvious that these
1053000	1057400	people who are saying this are not all just the much of philosophers who don't know anything
1057400	1058400	about physics.
1058400	1061640	This, for example, is Demi Sassabis from Google DeepMind.
1061640	1063680	There were a bunch of AI professors there, et cetera.
1063680	1067160	So that doesn't prove that superintelligence will happen, but it means that we have to
1067160	1070800	take it very seriously as an actual possibility.
1070800	1075680	In terms of the much slower ambition of just replacing all human jobs with machines that
1075680	1080840	can do it cheaper and better, in other words, AGI, there are actually recent surveys have
1080840	1087160	shown that most AI researchers think this is going to happen within a matter of decades.
1087160	1092800	So when I look at you, you all look healthy, like you're taking your vitamins, going to
1092800	1097520	the gym, et cetera, who are going to be around in a few decades.
1097520	1103440	So you should definitely be very open to the possibility that it might happen in your lifetime
1103440	1109400	and think about, well, what does that imply for you and how can we make sure that this
1109400	1113440	becomes the best thing ever to happen to humanity rather than the worst thing ever to happen
1113440	1114440	to humanity?
1114440	1120360	That is the defining challenge of our generation.
1120360	1125320	I'm going to try this pointer and see if it works better, proving that Italian technology
1125320	1127640	is better than American technology.
1127640	1128640	Great works.
1128640	1129640	Will that happen?
1129640	1131640	Yes, no, or it's complicated.
1131640	1132640	I shouldn't have said that.
1132640	1133640	A little bit complicated, but yes.
1133640	1135640	Okay, well, try both pointers.
1135640	1136640	Yes.
1136640	1137640	There.
1137640	1139360	All right.
1139360	1145720	So if this happens and we get to artificial general intelligence and then it starts taking
1145720	1148040	off towards superintelligence, what does that really mean?
1148040	1151800	Well, one thing it's obviously going to mean is that we should start imagining technology
1151800	1156480	which is limited not by human intelligence the way it is today, but limited instead by
1156480	1161640	the laws of physics, and that's a huge, huge difference.
1161640	1168360	So just to get you thinking big again, we already looked at the exponential growth,
1168360	1170080	for example, of memory technology.
1170080	1174680	Well, these technologies, even though they're cool, are still pretty stupid.
1174680	1179880	It still takes 100 billion atoms to store each one bit.
1179880	1180880	That's pretty dumb.
1180880	1182760	I mean, you have 100 billion neurons in your brain.
1182760	1186600	Imagine if you're only using one of them to store information in it.
1186600	1191640	So that suggests you can do way better quite easily as you start using quantum tech to
1191640	1194480	get down closer to one bit per atom.
1194480	1200120	If you go and look at other things you might care about, like computation, how much can
1200120	1203240	you compute per dollar?
1203240	1207800	The trend has been even more spectacular in terms of the performance cost.
1207800	1211220	We've gone down 19 orders of magnitude in price.
1211220	1216640	If you cut the prices of everything in Italy and the world by 10 to the power of 19, you
1216640	1220760	know, a thousand billion, billion, billion times, you could buy all the economic production
1220760	1224960	of the world for less than one cent.
1224960	1231840	And here again, if we get limited by the laws of physics, we're nowhere near the limits.
1231840	1235960	Professor Seth Floyd at MIT actually calculated what the physical limits are before your computer
1235960	1240960	turns into a black hole or anything like that, or violating speed of light limits.
1240960	1247160	And this is to scale how far we are from the physical limits.
1247160	1252280	We talk a lot now in Italy and elsewhere about energy, crisis, and energy independence.
1252280	1258080	Look how terribly inefficient our technology is today, like burning coal and gasoline.
1258080	1262360	This is how many percent of the energy you actually get out of it.
1262360	1267720	With nuclear reactors, you do it a little bit better, but it's still quite pathetic compared
1267720	1270680	to the limits that Einstein say are put by nature.
1270680	1275640	And we already have technological ideas like spalarizers and things like this, which if
1275640	1281120	you have superintelligence you could build, just do dramatically better than this.
1281120	1283160	Raise your hand if you like to travel.
1283160	1287240	All right, so there's a cool universe out there, right?
1287240	1293800	So far, we haven't even been anywhere further, we humans, than going to the moon, but obviously
1293800	1298960	if you have suddenly enhanced our technology to be limited by the laws of physics rather
1298960	1305120	than by our intelligence, things look a lot more rosy instead of having to wait thousands
1305120	1309200	or millions of years like in science fiction novels to have this tech, you could have it
1309200	1311520	in your lifetime.
1311520	1319080	And it becomes suddenly quite straightforward to go visit other stars, even other galaxies.
1319080	1323280	You can ask me in the Q&A if you want a little bit about how to do it, but I just threw in
1323280	1329600	this little thing here to just show you how much more resources there are out there in
1329600	1333680	the cosmos compared to the resources that we keep fighting about on Earth when we have
1333680	1339200	our stupid little wars.
1339200	1344120	And even here, even with human intelligence, there have been all sorts of very clever solutions
1344120	1348840	that people have figured out, like how to go live in the solar system and a fun habitat,
1348840	1351560	which is solar powered, etc.
1351560	1358120	We could build these sort of things very quickly with robots that were controlled with AI if
1358120	1359920	we wanted to.
1360920	1365640	All right, so we've spent most of our time talking about the growing power of artificial
1365640	1371120	intelligence, and the key message that I want you to take away from this again is the fact
1371120	1381800	that artificial intelligence really is happening for better or for worse, and the pace of progress
1381800	1384960	in the field is just absolutely amazing.
1384960	1391480	And if it continues, and we get to artificial general intelligence and beyond, we will have
1391480	1395360	enormous opportunities, we'll become the masters of our own destiny.
1395360	1401840	Instead of being running around trying to not get stepped on or eaten by tigers, we will
1401840	1405440	be making the decisions about our future.
1405440	1406760	What should those decisions be?
1406760	1409200	How can we make sure that this becomes good?
1409200	1415800	As Luca said, if you think about, even without worrying about what machines might do to you,
1415800	1424280	if you just offer a moment to imagine your least favorite leader on the planet, don't
1424280	1427840	tell me who it is, but just imagine their face for a second, okay?
1427840	1433920	Imagine now that they are the ones who control AGI and use it to take over the world.
1433920	1435440	How does that make you feel?
1439440	1440440	Great.
1442680	1444160	Or less so.
1444160	1450720	So how can we steer in the progress of this technology towards an inspiring future?
1450720	1451720	Let's talk a little bit about this.
1451720	1457200	To help with this issue, I teamed up with some colleagues and we created the Future Life Institute,
1457200	1461960	whose goal is precisely for the future life to be awesome and not awful.
1462040	1470280	We've done a lot of things to help focus people's thinking about how to steer.
1470280	1477960	We, for example, had conferences where we developed principles for guiding the beneficial
1477960	1483920	use of artificial intelligence, which have been signed by thousands of leading AI researchers.
1483920	1489360	They've even been adopted into law by the state of California and inspired a lot of
1489360	1492720	the OECD principles here in Europe, et cetera.
1492720	1498600	And I'll just give a couple, a few quick, very quick examples of such principles.
1498600	1506720	Try this one, try this one, there.
1506720	1511320	If you see me struggling too much with a clicker, you can just press the right arrow on the
1511320	1512840	laptop back there.
1512840	1517520	One principle is that we should, like, you know, all technologies can be used to help
1517520	1520000	people or for new ways of harming people.
1520000	1525480	So biologists and chemists, for example, have been working very hard to make sure that they
1525480	1530840	ban bio weapons and ban chemical weapons so we can use their sciences for new machines
1530840	1532960	and materials instead.
1532960	1538120	And of course, AI researchers are an idealistic bunch, as those of you who work on it know,
1538120	1542280	who want to make sure we use artificial intelligence for new solutions also, not for just new ways
1542280	1546200	of killing people with slaughterbots or whatever.
1546200	1551800	Another principle that there's very broad agreement on is that we really need to make
1551800	1557080	sure that all the enormous growth in the economic pie benefits everybody.
1557080	1562080	And my opinion is that if we can produce this future abundance of goods and services with
1562080	1566840	artificial intelligence, and we still cannot figure out how to share this in such a way
1566840	1572640	that everybody on Earth gets better off, then shame on us.
1572640	1576040	And it's fun to talk about this in Europe because I feel Italy and Europe in general
1576040	1581160	has a much stronger tradition actually in this regard of asking the question, how can
1581160	1590120	we make our growing economy work for all of us, not just for some of us?
1590120	1596680	A third principle is, well, raise your hand if your computer has ever crashed.
1596680	1601440	That's a lot of hats.
1601440	1609160	So how did that make you feel?
1609160	1610160	Frustrated.
1610160	1619600	All right, now suppose this computer was actually in charge of the nearby nuclear power plant
1619600	1625760	or the U.S. nuclear arsenal or something else that really affects people's lives.
1625760	1627600	Frustrated probably would not be the first word you would use.
1627600	1629560	You'd probably use a stronger one, right?
1629560	1635800	So this means that as AI gets more powerful, it becomes ever more important to work on AI
1635800	1636800	safety research.
1636800	1642560	And this is actually an encouragement for all of those of you who work in AI.
1642560	1646000	Don't just think about how you can work to make it more powerful.
1646000	1650280	Also think about the technical work you might be able to contribute to, to make it safe
1650280	1660560	and robust and beneficial so it actually does what we want to do.
1660560	1671840	Finally, it's part of this has to also involve thinking about putting goals into our machines
1671840	1675080	that are aligned with human goals.
1675080	1679400	Because the greatest risk from very powerful artificial intelligence is not that it's going
1679400	1685360	to turn evil like in stupid Hollywood movies, it's that it's going to just turn very competent
1685360	1691480	and go out and accomplish goals that are not aligned with our goals.
1691480	1698080	If we think about this guy, for example, the West African black rhino, why did we humans
1698080	1699240	drive it extinct?
1699240	1702760	Is it because we are actually a bunch of evil rhinoceros haters?
1702760	1703760	No.
1703760	1707440	It's that we are more intelligent than they were, and our goals are not aligned with
1707440	1710200	their goals and tough luck for them.
1710200	1717920	Let's not put humanity in the place of those rhinos by giving a bunch of power to machines
1717920	1726280	who don't share our goals or to humans who control machines that don't have our goals.
1726280	1727720	We can talk a lot about this.
1727720	1731720	This is also partly a very technical problem, actually, how to make machines understand our
1731720	1734880	goals, learn our goals, retain their goals.
1734880	1739320	Also a problem, of course, of making sure that we give the right incentives to the corporations
1739320	1745640	and governments that, in turn, have power over the machines.
1745640	1755240	My research that my group at MIT focuses on is very much dedicated to technical artificial
1755240	1763560	intelligence research, and we don't have time for me to go into it in any great detail
1763680	1767080	at all, but I'll just give you a little bit of a flavor.
1767080	1774480	So today, the vast majority of the really high-powered AI systems, like the language
1774480	1779600	models that we looked at a little bit here, and you'll hear more about today, like Google
1779600	1783400	Palm and GPT-3 and so on, are gigantic black boxes.
1783400	1788600	They do very intelligent things, but we really don't understand how they work, which limits
1788600	1791720	the extent to which you can trust them.
1791760	1794680	We are very focused on how can we open up the black box?
1794680	1803400	How can we use the training of a giant black box AI model as the first step, rather than
1803400	1805560	the last step?
1805560	1811800	So our vision is, first, you create something like this that learns something very smart,
1811800	1817120	and then, instead of just selling it at that point, you do a second step and try to get
1817120	1819680	the knowledge out of it.
1819680	1823200	So you can put the knowledge into something which you can trust more.
1823200	1827800	We've had some success with very basic things, like if you have a big table of numbers, for
1827800	1832080	example, and you want to predict the last column from the previous ones, this is called
1832080	1835040	symbolic regression.
1835040	1840920	It's the nonlinear NP-hard version of what's known as linear regression, which is very
1840920	1841920	easy.
1841920	1846960	This normally takes longer than the age of the universe to discover simple formulas,
1846960	1848640	in general.
1848640	1851960	But we were able to get state-of-the-art performance on this.
1851960	1856760	We first train a black box neural network, and then we use all sorts of techniques by
1856760	1862680	looking at the gradients and so on to figure out how we can be broken apart into modules.
1862680	1867720	And then we do this in a recursive way that I can tell you about over coffee if you're
1867720	1869200	interested.
1869200	1873920	And eventually, the thing works so well that we were able to put in the 100 most famous
1873920	1878800	physics equations from the Feynman Lecturers and from other books.
1878800	1884280	And by just showing data, it was able to not just fit them accurately with a sort of black
1884280	1888840	box system that you don't understand, but actually discover what the formulas were so
1888840	1891120	you could extract out the knowledge.
1891120	1896840	This is very inspired, for me, I was very inspired to do this project by an Italian,
1896840	1899440	Galileo Galilei.
1899440	1905560	Because when he was four years old, if his mother threw him an apple, of course he could
1905560	1907360	catch it.
1907360	1910720	Because his neural network that he had trained during his childhood in his brain was very
1910720	1917000	good at predicting the shape in which apples moved under the influence of gravity.
1917000	1920080	And so you could do the same when you were four years old.
1920080	1924520	But when Galileo got older, he did something more.
1924520	1930000	He said, hmm, can I take this intuitive knowledge that I have that I don't know how it's represented
1930000	1934040	and somehow get it out of my brain?
1934040	1940040	And he said, well, this curve, it's a parabola, regardless of what kind of apple it is and
1940040	1941280	how fast it's thrown.
1941280	1943840	And there's an equation for it, y equals x squared.
1943840	1948840	And he was able to tell his friends about this and publish papers.
1948840	1958480	So this ability to transform poorly understood intuitive knowledge into symbolic representations
1958480	1961380	is really at the heart of human intelligence.
1961380	1964640	When you speak Italian with your friends, you're doing exactly the same thing.
1964640	1968840	You're taking some knowledge that you have in your brain and you're verbalizing it, putting
1968840	1973560	it in a symbolic representation where it can be communicated and explained.
1973560	1978680	So if we can do it, I believe that we can make machines that can also do it.
1978680	1983160	And they will be much more safe and trustworthy that way because the hard part is usually
1983160	1984680	discovering the knowledge.
1984680	1989520	Once you have the knowledge, you can implement it in something maybe which is not the standard
1989520	1992720	neural network, but something that you really, really understand.
1992720	1998800	So this was just one little hopeful example of how I think that we can do much better
1998800	2005320	in terms of trustworthiness of our AI systems going forward than we should.
2005680	2010160	And in my final two minutes, let's talk just a little bit about the destination also.
2010160	2014200	So we're making this ever more powerful tech.
2014200	2019440	I mentioned various ideas for how we can steer it better, control it better, trust it better.
2019440	2023640	But what do we ultimately want to do with it?
2023640	2028720	How can we ensure an inspiring future with artificial intelligence, both for businesses
2028720	2032720	like Bending Spoons and for our entire civilization?
2033560	2040400	I've already alluded to one important strategy, which is just to think about all the uses
2040400	2048280	of AI and then draw a very clear red line between what we consider acceptable uses and
2048280	2052000	unacceptable uses.
2052000	2056240	I would encourage you to keep this very ethical framework in the back of your mind in your
2056240	2061240	future career also whenever you build something, ask yourself also what the social impact
2061240	2063800	of it will be.
2063800	2071400	And the second strategy is we really need to articulate positive visions for what we want
2071400	2078520	to accomplish with this because shared positive visions are the fundamental driver of collaboration
2078520	2083920	in companies, in relationships, and in the world.
2083920	2090920	And it's easy to say, well, we'll never find any goals for the future that the US and China
2091120	2093960	and Italy are all going to agree on.
2093960	2095720	But that's obviously not true.
2095720	2101080	The United Nations Sustainable Development Goals, for example, are quite ambitious visions
2101080	2103600	and basically every country on the planet agrees with it.
2103600	2107760	We even wrote this paper here in Nature Commons recently about how AI can help us accomplish
2107760	2110720	the Sustainable Development Goals faster.
2110720	2116880	And if we get ever more advanced AI, we can go much more ambitious than that also and
2116880	2123880	say, well, let's not just try to reduce a few problems a little bit, but really actually
2124680	2128440	solve them and just do dramatically better.
2128440	2131760	The sky is the limit.
2131760	2138760	So in summary, I feel that artificial general intelligence is the ultimate game-changing
2138880	2145080	technology for our human species, and it is coming.
2145080	2149680	And what does that mean, exactly?
2149680	2156680	First of all, it means we're not just some tiny little life forms here on a tiny little
2156680	2162320	planet that's completely irrelevant because we're so small.
2162320	2168320	What's happening on this planet in your lifetime is probably the most significant thing ever
2168400	2174640	to happen anywhere in our universe so far, and could easily affect the entire future
2174640	2181640	of much of this gorgeous and beautiful universe that you're looking at in the background.
2181640	2188640	So my charge to you folks is be proactive and think about how can you steer this technology
2190160	2192440	to a good place?
2192440	2198680	Let's be the masters of our own destiny by envisioning it the way we want it to be and
2198680	2200840	by actually building it.
2200840	2201840	Thank you.
2201840	2202840	Thank you.
2202840	2203840	That was great.
2203840	2204840	Thank you very much.
2204840	2205840	Stay there for a minute.
2205840	2206840	Thank you very much, Max.
2206840	2217840	That was absolutely awesome.
2217840	2221800	I want to move things along, but we can't let Max go without asking him a few questions.
2221800	2223440	This is your opportunity.
2223440	2225920	Who would like to ask a question?
2225920	2226920	Who will be brave and ask that?
2226920	2228680	Do you want me to ask the first question?
2228680	2229680	Okay.
2229680	2230760	All right then.
2230760	2236040	You talked about, I've got about five questions I want to ask you.
2236040	2237920	We're not going to have time for all of these.
2237920	2243000	Are we better at seeing how AI works?
2243000	2250000	I'm reminded of the example of Microsoft's Tay when it was your friend in your pocket
2250000	2253760	that you would have a conversation with and it randomly started to be racist and insult
2253760	2258280	people and they turned it off because they didn't know why it was doing it.
2258280	2265040	Are we better now at looking, opening up the brain and looking inside it and seeing why
2265040	2270120	it is doing things as opposed to looking at the outcome?
2270120	2271120	Very good question.
2271120	2275520	We're a little bit better, but in the meantime the technology has gotten dramatically more
2275520	2276520	powerful.
2276520	2278880	So we really need to up our game in this area.
2278880	2283760	I really do believe that this is one of the most valuable things we can do for a good
2283760	2290300	future to win this wisdom race between the growing power of the tech and the growing
2290300	2292920	wisdom with which we understand it.
2292920	2296200	I hope there are some of the examples I mentioned that suggest that it's not as hopeless at
2296200	2298880	all as people think.
2298880	2305400	After all, we humans are able to extract our own insights in a fashion we can explain to
2305400	2311960	others and we really should be able to get the AIs to do the same for us.
2311960	2312960	Any questions?
2312960	2313960	Yes, sir.
2313960	2314960	There we go.
2314960	2315960	This works.
2315960	2316960	It does.
2316960	2317960	Bonjour, everybody.
2317960	2325680	So I was thinking about the super intelligence.
2325680	2330000	We could see it as our next big step in evolution.
2330000	2331640	We're already moving so far.
2331640	2338720	The older generations are having really troubles in understanding AI, the power, the steering
2338720	2340520	and the direction of it.
2340520	2348240	So I wanted to hear your take on do you have a feeling of when the overtaking, the super
2348240	2358320	intelligence might happen and how can we gracefully go in that direction, make it gracefully
2358320	2362040	modern within the society, let's say.
2362040	2363040	Great.
2363040	2371080	So as to the question of when, you know, the most reliable polls of AI researchers suggest
2371080	2378520	maybe a 30 years, but it could be a lot sooner, it could be later, but I think it's very likely
2378520	2383720	to be within your lifetime, which is really the number one thing to take away from that.
2383720	2389560	In terms of how to make it graceful and make it something good, I think we have both a
2389560	2393320	bunch of these technical challenges, again, how can we make AI systems that we actually
2393320	2400720	trust to do what we want them to do, and how can we make sure that we improve our democracy
2400720	2406320	so that the control over this ever greater power actually lies in the hands of all of
2406320	2407320	us.
2407320	2412760	I personally believe that the only way in which you can guarantee that things actually can
2412760	2416760	get better for everybody is if everybody has a say in how it's used.
2416760	2422000	I think right now, especially in America where I live, things are going pretty rapidly in
2422000	2428320	the opposite direction, where ever more power gets concentrated into ever fewer hands and
2428320	2435560	you even have large social media companies starting to get almost a monopoly of the truth,
2435560	2438280	which gives them even more power.
2438280	2444840	And as a scientist, I much prefer the democratic idea that everybody should be able to challenge
2444840	2448760	everything and to make it.
2448760	2454960	So Europe is, I think, actually totally key in this.
2454960	2459200	We have this tradition in Europe of trying to build a society that ultimately really
2459200	2460680	works for everybody.
2460680	2467920	That's why we have free healthcare and free universities in Italy, not in the United States.
2467920	2475760	And I would encourage you all to sort of envision how can we reinvent, reimagine sort of the
2475760	2483040	welfare state 3.0, which is even more awesome because it has all this technology and remains
2483040	2490600	very firmly aligned with what's actually good for people, all people, not just some
2490600	2491600	tech nerds.
2491600	2492600	Thanks.
2492600	2496600	Does anyone else have a question?
2496600	2498600	Yes, please.
2498600	2503640	Oh, okay.
2503640	2513840	So my question is, do you think, so let's say we are able to develop AGI, but we cannot
2513840	2521680	impose like, so if we have the ability to develop AGI, and if this means that we cannot
2521680	2527200	impose like, go alignment limits on it, should we do it?
2527200	2532880	To have something intelligent as humans, it should have also like the bad qualities of
2532880	2533880	humans.
2533880	2544360	So if we can't control it, should we still build it?
2544360	2546480	On one hand, of course not.
2546480	2552680	On the other hand, the way the economy works, I think it's not realistic to say, let's
2552680	2558760	just press pause on technology until we got our act together, because there's just so
2558760	2561720	much money in it and so much power in it.
2561720	2567800	I think what's the more realistic game plan is rather than trying to go, stop, stop, stop.
2567800	2572360	To think of this as a race between the growing power of the technology and the growing wisdom
2572360	2576240	with which we manage it, solve all of these problems.
2576240	2581640	If we can't slow down the growth of power, what we can do is accelerate the growth of
2581640	2583160	the wisdom.
2583160	2587080	That's why it's so wonderful that Luca and his colleagues are organizing conversations
2587080	2589520	about precisely this.
2589520	2591440	How can we grow the wisdom?
2591440	2594440	How can we invest more in AI safety research?
2594440	2601720	How can we have more conversations in society about how we want to use this, how it should
2601720	2605040	be regulated, who should be in charge, and so on?
2605040	2611440	That I think is our best shot that we have.
2611440	2617880	In Europe right now, the European Union is actually developing the EU AI Act, which is
2617880	2623160	the first time in the West that there will be actually a law trying to steer things in
2623160	2624160	the right direction.
2624160	2626000	I personally think this is very exciting.
2626000	2630160	In America, there's no meaningful attempts to regulate AI at all, because lobbyists are
2630160	2633840	too powerful there.
2633840	2639160	Sure enough, big social media companies from America have now sent more lobbyists to Brussels
2639160	2645560	to fight this than the oil companies ever sent to Brussels.
2645560	2648680	As Europeans, be mindful of this.
2648680	2652800	This might be the first battle you can actually win, where you start laying down the ground
2652800	2659240	rules in such a way that you score up a big victory for the wisdom.
2659240	2664000	Then right here, I have a question.
2664000	2665000	Good morning.
2665000	2667000	Thank you for your presentation.
2667000	2669840	My question is about your program.
2669840	2676120	You said that you are a physicist, so I want to know how was your transition to AI and
2676120	2678240	what was your challenges?
2678240	2679240	Thank you.
2679240	2680240	Thank you.
2680240	2682520	Yeah, that's right.
2682520	2687960	When I was a teenager, I used to lie in my hammock between two apple trees and think about and
2687960	2691120	realize that I was just really excited by big questions.
2691120	2695960	The two biggest was our universe out there, which is also what my first book was about,
2695960	2701640	and then the second one was our universe in here, intelligence and the mind.
2701640	2707320	Seven years ago, roughly, after spending my career on physics, I decided to dramatically
2707320	2711580	change careers and start doing AI research instead.
2711580	2719700	I could get away with it in terms of my job because they can't fire me, an MIT, whatever
2719700	2722900	I do, a tenure.
2722900	2724300	Your question is very good.
2724300	2725420	How hard was it?
2725420	2731340	I would say it certainly was quite hard to learn so many things in a new field, but it
2731340	2734380	was also really fun.
2734380	2735900	It's such a fascinating topic.
2735900	2736900	You know that.
2736900	2737900	That's why you're here.
2738220	2742860	And I was actually surprised also by how much I could make use of things I knew from my
2742860	2744380	past life.
2744380	2750620	So in physics, I had worked a lot on dealing with large data sets and information theory.
2750620	2755380	I love computers and apps, which is why as we heard in the intro, I wrote games when
2755380	2759780	I was a teenager and so on.
2759780	2763820	The message I have for all of you is if you're ever thinking about a career change in the
2763820	2769940	future and you're really, really excited about it and thought it through a little bit, you
2769940	2771780	go for it.
2771780	2777340	You get one shot to live on this planet, so make it count.
2777340	2780780	Yeah, another question.
2780780	2786940	This is a very broad question, but do you think AI has to be understandable in order to be
2786940	2788940	ethical or trustworthy?
2788940	2791020	Oh, that's good.
2791020	2798300	Do we need it to be understanding in order to be ethical or what was the last word?
2798300	2802580	For trustworthy, yes.
2802580	2809540	For trustworthy, for sure, I think we should trust things, machines, not because some sales
2809540	2811660	representative says, oh, trust this.
2811660	2815900	It's great that it has a little sticker on it saying AI, but rather because we can understand
2815900	2819740	how it works.
2820700	2825420	On the other hand, just because it does what it's supposed to does not in any way guarantee
2825420	2827060	it's ethical.
2827060	2834820	If some terrorist has built this slaughter bot, then it's very trustworthy and he programs
2834820	2841100	it to go kill all people with a certain skin color, for example, it's completely trustworthy.
2841100	2847020	It's going to obey its owner even if it's by maybe my standards completely unethical.
2847100	2849100	Those are two separate things.
2849100	2854380	What that means simply is that, yes, of course, we have to first of all make things trustworthy,
2854380	2859660	otherwise we don't even have the luxury of talking about ethics, but it's not enough.
2859660	2866660	We also have to have a very serious conversation in our society about how to make sure that
2866660	2872020	we align the goals of people and companies and governments who have this technology to
2872020	2876620	do what's good for society as a whole.
2876620	2882060	I think we're not doing so great there either today.
2882060	2888460	If you have a company that decides to chop down the rainforest or whatever, maybe their
2888460	2896380	technology they use to do it is very trustworthy for them, but companies are also a kind of
2896380	2902140	artificial intelligence, even though it's built out of people, not out of machines.
2902140	2907140	With the same alignment challenge we have of making sure that the machines we build
2907140	2914380	do what's good for humanity, we also have to apply that same approach to companies and
2914380	2917540	other entities that control machines.
2917540	2921260	Thank you very much.
2921260	2924540	One more question here, another one over there as well.
2924540	2926260	We are running out of time.
2926260	2930540	If you have questions actually for Max, we're going to be doing a panel later on, so come
2930540	2937860	and find me and we can ask those questions later on as well.
2937860	2939860	Over here.
2939860	2945460	One question about the James Webb Telescope, it's been like 10 days that it's operative,
2945460	2951540	so I wanted to ask you how is AI going to impact the research on these infrared images
2951540	2958500	that we now have about the deep universe, because we've never been able to look so deep.
2958500	2965140	How is going to be the AI impact on that, and do we have some future projects on it?
2965140	2972660	I'm very excited about the opportunity of using AI for science more broadly, and astronomy
2972660	2977060	and extragalactic astrophysics is a great example of this, because we're getting such
2977060	2981780	enormous amounts of data, that you just cannot do what you would do in the past, it's like
2981780	2986300	give it to a grad student to look at it all and come back and tell you what they found.
2986580	2990100	It'll go away for 100 years.
2990100	2996220	We have already been quite successful using AI to analyze enormous amounts of astronomical
2996220	3001620	data to figure out, to find all the stars in the galaxies in there, to figure out what's
3001620	3006780	there, what's different, what's surprising.
3006780	3015020	I think 10 years from now it'll be almost as difficult to find a physicist or astrophysicist
3015020	3020580	who does not use any kind of machine learning, as it is today to find someone in those fields
3020580	3022340	who says, I don't use mathematics.
