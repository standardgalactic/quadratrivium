1
00:00:00,000 --> 00:00:07,280
Hi and welcome to Global Governance Futures based out of the Global Governance Institute

2
00:00:07,280 --> 00:00:13,440
at University College London. This is a podcast about the challenges facing humanity

3
00:00:14,000 --> 00:00:20,000
and possible global responses. If you're new to the show and you want to get a list of our favorite

4
00:00:20,000 --> 00:00:30,880
books, other resources, listen to past shows and join our community, go to ucl.ac.uk forward slash

5
00:00:30,880 --> 00:00:41,600
global dash governance. We're really excited to have Dr Zach Stein join us today. Zach is a writer,

6
00:00:41,600 --> 00:00:49,440
a futurist, a transformative educator, working to bring a greater sense of justice and sanity

7
00:00:49,440 --> 00:00:57,520
to education. Alongside Daniel Schmackenberger who featured in episode 12, Zach is also a founding

8
00:00:57,520 --> 00:01:04,480
member of the Consilience Project, a non-profit media organization aiming to improve public

9
00:01:04,480 --> 00:01:12,560
sense-making and democratic dialogue. Zach received his PhD in education from Harvard

10
00:01:12,560 --> 00:01:18,800
University where he studied educational neuroscience, human development and the philosophy

11
00:01:18,800 --> 00:01:26,880
of education. He's published dozens of articles and two books, his most recent book and one which

12
00:01:26,880 --> 00:01:33,520
really caught my attention is called Education in a Time Between Worlds and Grapples with the

13
00:01:33,520 --> 00:01:42,880
Dangers posed by a profound learning and capacity deficit in the face of civilization-wide transformations.

14
00:01:43,440 --> 00:01:50,080
It really is an incredibly rich and thought-provoking work and at the risk of oversimplifying,

15
00:01:50,080 --> 00:01:57,600
Zach argues that the world as we have known it is rapidly disappearing and as a result,

16
00:01:57,600 --> 00:02:06,480
radical transformation of our legacy education systems is now an urgent, even existential imperative.

17
00:02:07,200 --> 00:02:15,120
As he puts it, we can no longer assume, if we ever could, the unproblematic intergenerational

18
00:02:15,120 --> 00:02:20,000
transmission of essential human capacities for reasoning and reflection.

19
00:02:22,480 --> 00:02:28,800
So, in the spirits of the philosopher John Dewey, we're going to discuss today why Zach believes

20
00:02:28,800 --> 00:02:34,800
that at roots all current global crises might be best understood as crises of education

21
00:02:35,040 --> 00:02:43,600
and why as educators, learners and concerned planetary inhabitants, we should all care about that.

22
00:02:44,240 --> 00:02:49,360
So, we're super excited to get into this with you, Zach. Thanks so much for taking the time to

23
00:02:49,360 --> 00:02:55,920
speak with us. It's a pleasure to be here. Thank you for inviting me. And before we get started,

24
00:02:55,920 --> 00:03:03,120
I'll just ask the poll crew to say hello. Hi, I'm Jessica. I work on the research and

25
00:03:03,120 --> 00:03:06,560
I'm very looking forward to hearing what Dr. Stein has to say today.

26
00:03:09,680 --> 00:03:15,280
Hi, my name is Sam. I do the audio and the video editing and hopefully some of the thinking.

27
00:03:17,360 --> 00:03:20,640
Hi, I'm Zoe. I help with the social media and running of the YouTube channel.

28
00:03:23,520 --> 00:03:31,680
Great. Okay. So, to open, Zach, perhaps you can help us set the scene. You describe in the book

29
00:03:31,680 --> 00:03:39,920
the years 2000 to 2050 as a critical turning point in the history of humanity and the planet.

30
00:03:40,640 --> 00:03:47,600
So, what is so special about this 50-year stretch and how does this this interregnum,

31
00:03:47,600 --> 00:03:51,440
how does this turning relate to the educational crisis?

32
00:03:53,520 --> 00:04:00,560
Yeah, so that specific time period. I took that on the cue of Immanuel Wallerstein,

33
00:04:00,560 --> 00:04:05,840
who was the creator of World Systems Analysis, which is this fascinating kind of approach to

34
00:04:05,840 --> 00:04:12,080
doing big history, specifically long-term stretches of the development of the capitalist

35
00:04:12,080 --> 00:04:17,840
world system. And he was actually following from complex dynamical system theory, like

36
00:04:17,840 --> 00:04:27,120
prigazine and things like that. And he saw this kind of like rhythm of changing in the basic

37
00:04:27,200 --> 00:04:34,000
organization of capitalism, this transformation of the hegemonic structure, as he called it.

38
00:04:34,640 --> 00:04:42,000
And so, you know, one occurred when we went from having capitalism being rooted in basically Venice

39
00:04:42,000 --> 00:04:48,320
to it being rooted with the Dutch and then from the Dutch to the British and then from the British

40
00:04:48,320 --> 00:04:54,560
to the United States. And each time that kind of hegemonic world system transformation, as Wallerstein

41
00:04:54,560 --> 00:05:00,960
would call it, occurred, whole swaths of culture, whole swaths of political life, whole swaths of

42
00:05:01,840 --> 00:05:10,800
the ecology and the humanity were changed. And he saw this in several other kind of like people

43
00:05:10,800 --> 00:05:16,000
doing actually quantitative analysis of large historical swaths of time, like Peter Turchin

44
00:05:16,000 --> 00:05:21,200
more recently have seen these actual, their rhythms, their cycles of historical transformation.

45
00:05:21,200 --> 00:05:27,680
And so Wallerstein says, Hey, we're about to be in one of these, we're about to be in a situation

46
00:05:27,680 --> 00:05:34,000
where, you know, the British kind of and then the Americans and now the Americans and now what

47
00:05:34,000 --> 00:05:41,360
basically is what Wallerstein saying is like the, the end of America as the dominant hegemonic force

48
00:05:41,360 --> 00:05:48,000
in the capitalist world system, he's predicting. And he's saying that for the first time the system

49
00:05:48,080 --> 00:05:53,520
is global. And that means that it's not clear that the hegemon can just move geographically,

50
00:05:53,520 --> 00:06:00,720
that we may be approaching something that looks more like a transformation of a deeper, more

51
00:06:00,720 --> 00:06:04,800
profound nature at the structure of the economic system itself. So this is where I got the idea.

52
00:06:05,680 --> 00:06:09,600
And then I started looking around at other thinkers who are also like even, you know,

53
00:06:09,600 --> 00:06:18,400
New Age thinkers and like futurists and, you know, anthropologists and other people pointing at the

54
00:06:18,400 --> 00:06:25,840
same kind of time period, basically. And so yeah, I brought that I pulled that in there and put it

55
00:06:25,840 --> 00:06:31,440
in the book just to make people aware that when I say we're in a time between worlds, like it's a,

56
00:06:31,440 --> 00:06:36,320
it's a technical phrase. Like if there's a, there's poetics in it, but it's actually a technical

57
00:06:36,320 --> 00:06:43,280
phrase. And it's referring to this basically almost inevitable historical unfolding of a very

58
00:06:43,280 --> 00:06:51,200
significant transformation in the techno economic and political base of our world. And the argument

59
00:06:51,200 --> 00:06:56,560
that I weave in there is that, hey, don't forget education. Like Wallerstein doesn't mention

60
00:06:56,560 --> 00:07:01,520
education. And my argument is basically that all those other things, economics, politics,

61
00:07:01,520 --> 00:07:06,880
warfare, technology, you don't get those without education. And it's interesting to me that people

62
00:07:06,880 --> 00:07:15,200
neglect that insight, it shows how taken for granted, much of the processes of intergenerational

63
00:07:15,200 --> 00:07:20,640
transmission have been. And so that's invisible when they become problematized in our society,

64
00:07:20,640 --> 00:07:25,200
because we take it for granted. Each time the capitalist world system changed, the nature of

65
00:07:25,200 --> 00:07:33,360
education itself changed. And so yeah, so that's, I'm pulling that bit out. And one thing that's

66
00:07:33,360 --> 00:07:43,440
interesting is that great historian, again, of capitalism, Jason Moore, his book, Capitalism

67
00:07:43,440 --> 00:07:50,000
and the Web of Life. It's an incredible book. He talks about not just like capitalist world systems,

68
00:07:50,000 --> 00:07:58,800
but world ecologies, which is to say the way that capital shapes the nature of the planetary

69
00:07:58,800 --> 00:08:07,840
biosphere, literally dams and canals and all of these things. And of course now, emissions and

70
00:08:07,840 --> 00:08:15,840
transformations in weather as a result of this. So we're having, and I know this in the book,

71
00:08:16,720 --> 00:08:23,200
we're having these crazy hockey stick patterns of major ecological transformation. At the same

72
00:08:23,200 --> 00:08:29,040
time, the underlying techno economic base is fundamentally transforming at the same time

73
00:08:29,600 --> 00:08:34,320
education is transforming. And I'm pointing at education as the thing that needs to be worked

74
00:08:34,320 --> 00:08:41,120
on basically first or as most primary, or at least not put on the back burner, like it's going to

75
00:08:41,120 --> 00:08:48,080
take care of itself. When in fact, most of the problems as you mentioned in the intro that we're

76
00:08:48,080 --> 00:08:54,800
looking at are our issues of skill deficit, capacity deficit, personality disorganization,

77
00:08:55,840 --> 00:09:04,560
low grade ubiquitous psychopathology. And so it's a complex psychological crisis, as much as it's

78
00:09:04,560 --> 00:09:10,720
an ecological or technological or political or economic crisis. So that's a little bit about

79
00:09:10,800 --> 00:09:16,960
that where that period came from. And I've been saying we were between worlds for,

80
00:09:17,600 --> 00:09:22,640
you know, five or six years. And then when the pandemic hit, people were like, oh,

81
00:09:22,640 --> 00:09:26,880
that's what you mean. I was like, yes. I was like, it's everything is fundamentally,

82
00:09:26,880 --> 00:09:31,360
we're in a liminal space, we can't go back or stabilize the prior system.

83
00:09:33,200 --> 00:09:38,400
We're going to be in a disequilibrated state. And this is Wallerstein's notion he's getting it

84
00:09:38,400 --> 00:09:43,360
from privileging complex open dynamical systems, right, they go through periods of turbulence

85
00:09:43,360 --> 00:09:49,120
before they restabilize. So we're in that period of turbulence and will remain in that period of

86
00:09:49,120 --> 00:09:56,720
turbulence, I'm saying for, for decades, until something new locks in. And the concern we have

87
00:09:56,720 --> 00:10:01,920
is that what's going to lock in is not going to be good. So there's a way to solve this problem that

88
00:10:02,000 --> 00:10:06,880
looks, for lack of a better word, like totalitarian or authoritarian.

89
00:10:09,040 --> 00:10:12,800
So, you know, the Consilience Project and my other work is trying to find a way to solve these

90
00:10:12,800 --> 00:10:20,320
problems that result in an open society on the other side of this kind of reorganization of the

91
00:10:20,320 --> 00:10:26,160
world system. So it's kind of like the broadest framing. Yeah, that's super helpful, Zach. Thank

92
00:10:26,160 --> 00:10:32,320
you. So maybe we'll sort of drill down a bit now into a concrete example. So thinking about climate

93
00:10:32,320 --> 00:10:38,880
change, I've been doing quite a bit of research recently on climate change. And there's a real

94
00:10:38,880 --> 00:10:46,400
sort of focus on, I'd even say fetish for CO2 metrics. We have this kind of war on carbon.

95
00:10:47,200 --> 00:10:54,080
And the solution ontology is really about sort of technology. So carbon capture storage, net

96
00:10:54,080 --> 00:11:00,640
zero, very current at the moment, very lively debate there. But also, you know, state multilateral

97
00:11:00,640 --> 00:11:04,880
agreement. This is a collective action problem. It's a political problem. If we can just,

98
00:11:05,520 --> 00:11:12,000
if we just see our way through that impasse, we can solve climate change. But we're 30 years down

99
00:11:12,000 --> 00:11:18,800
the road from Rio 1992, carbon emissions are yet to peak. And you argue in the book that the climate

100
00:11:18,800 --> 00:11:25,280
crisis is at root, not a problem of pollution or habitat destruction is actually a crisis of human

101
00:11:25,280 --> 00:11:34,960
decision making. So if you were speaking to some of our most highly educated elite decision makers,

102
00:11:34,960 --> 00:11:41,680
experts, and there I said, academics, what is it that we're not getting right?

103
00:11:41,680 --> 00:11:50,880
Yeah, there's at least kind of two ways to answer the question. One is that one of the things we're

104
00:11:50,880 --> 00:11:58,000
not getting right is the communication and education of those people who are not academics

105
00:11:58,000 --> 00:12:05,040
and who are not high level policy decision makers. So like, this is in part a decision making crisis

106
00:12:05,120 --> 00:12:11,520
and a capacities crisis among those epistemic elites, let's call them, and decision makers,

107
00:12:12,080 --> 00:12:19,120
who are laying out this solution ontology, right, inadequately. So there's something I'll get to

108
00:12:19,120 --> 00:12:24,240
that point, like what's wrong with the highest level models about the global situation and why

109
00:12:24,240 --> 00:12:32,400
those are inadequate. But prior to that, there's actually this issue that the degree of polarization

110
00:12:32,400 --> 00:12:40,000
around climate change, for example, in the United States, the degree of intensity, even though it's

111
00:12:40,000 --> 00:12:47,600
low grade, it will emerge again around escalating economic inequality. Like there's a series of

112
00:12:47,600 --> 00:12:55,280
things that require really complex educational initiatives, not involving the most elite decision

113
00:12:55,280 --> 00:13:00,960
makers, involving every citizen in an open society's understanding of the global situation.

114
00:13:02,560 --> 00:13:07,760
That we have not provided educational systems that brought people up and into a mature and

115
00:13:07,760 --> 00:13:16,560
complex view of the global situation. At least in the United States, you know, we're being entertained.

116
00:13:17,680 --> 00:13:22,240
We should be being informed and educated by the media, we're being entertained and brought into

117
00:13:22,880 --> 00:13:31,600
basically cultural war as a form of entertainment and catharsis. And so that's the first thing that

118
00:13:31,600 --> 00:13:41,280
these epistemic elites need to consider is that the people, so-called, can't just simply be told

119
00:13:41,280 --> 00:13:47,040
what to do when you figure out what the right policy is. This is the, remember, the scary

120
00:13:48,160 --> 00:13:54,080
lockdown of excuse the terminology on the other side of being between worlds is the option where

121
00:13:54,080 --> 00:14:00,480
we figure out the climate policy that works. We can't explain it to the people, quote unquote,

122
00:14:00,480 --> 00:14:07,680
the masses. So we have coercive legislation that basically mandates their behavior change

123
00:14:07,680 --> 00:14:13,120
without their understanding why the behavior change is necessary. And we saw this with the

124
00:14:13,120 --> 00:14:18,560
pandemic a little bit because of the information warfare around science, right? So you get a

125
00:14:18,560 --> 00:14:24,320
situation where people are being requested to do things that are reducing their quality of life,

126
00:14:24,400 --> 00:14:31,840
but they don't actually have the epistemic insight. They don't have the knowledge they need to have

127
00:14:31,840 --> 00:14:38,080
the law be understandable, justified. This goes way back in legal theory to like

128
00:14:38,640 --> 00:14:43,760
Kant, if you will, you know, and forgive Kant his transgressions. But he did say that if you're

129
00:14:43,760 --> 00:14:50,720
going to have a legal framework in something like a democracy, an open society, if you will,

130
00:14:51,280 --> 00:14:56,800
it needs to be both, you know, have the force of law, which is to say you get punished if you

131
00:14:56,800 --> 00:15:00,560
don't follow it, even if you don't understand it. But you also need to be able to be in a position

132
00:15:00,560 --> 00:15:04,480
to understand that you need to have all the information you need as a citizen to see why this

133
00:15:04,480 --> 00:15:13,920
law is valid, just appropriate. So if we don't solve that problem, which is to say, really educating

134
00:15:14,240 --> 00:15:20,880
folks, the everyday person, and that requires changing the nature of the media. I'm getting

135
00:15:20,880 --> 00:15:25,520
to the Consilience Project here, the nature of the media, the nature of how we understand

136
00:15:25,520 --> 00:15:29,680
public sense making, public dialogue around complex scientific topics, for example.

137
00:15:31,200 --> 00:15:35,840
Then we could be in a position where even if the epistemic elite get themselves in order

138
00:15:35,840 --> 00:15:41,120
and start using much more comprehensive, you know, global frames and, you know, multicast

139
00:15:41,440 --> 00:15:44,720
decision making procedures with second and third order effects and all these things we'd

140
00:15:44,720 --> 00:15:53,200
like to see, even if they do that, if the people, as it were, the masses, are still in a media

141
00:15:53,200 --> 00:15:59,200
environment that's completely saturated with disinformation and advertising and information

142
00:15:59,200 --> 00:16:05,360
extraction, predatory social media, then we're going to end up basically being in a situation

143
00:16:05,360 --> 00:16:10,320
where the epistemic elite feel that they have no choice but to coerce the vast majority of the

144
00:16:10,320 --> 00:16:15,200
global population into following the laws necessary for humanity to survive. And then

145
00:16:15,200 --> 00:16:21,840
we have a civilization which may not be worth actually living in, even though it's sustainable,

146
00:16:22,960 --> 00:16:28,320
even though it is within planetary boundaries. So that's the first place where decision making

147
00:16:28,320 --> 00:16:32,880
is key is that it's, yeah, we can be concerned about the epistemic elites, but until they become

148
00:16:32,880 --> 00:16:37,120
more concerned with actually educating people instead of propagandizing them and entertaining

149
00:16:37,120 --> 00:16:42,560
them and extracting profit from them, there'll be no way that we can actually navigate the

150
00:16:43,600 --> 00:16:49,360
crisis in the context of an open society. If we turn to the epistemic elites,

151
00:16:50,240 --> 00:16:53,840
then it becomes clear that we're still dominated by short-term thinking.

152
00:16:55,600 --> 00:17:05,360
We're still dominated by certain ideologies that privilege reductive epistemics over

153
00:17:06,240 --> 00:17:12,880
comprehensive and open epistemics, if I can put it that way. So reducing in all the carbon

154
00:17:12,880 --> 00:17:21,040
emissions, for example, seeking only those approaches that can be measured in quantitative

155
00:17:21,040 --> 00:17:28,480
terms, reducing the problem to a technical and scientific problem. This folds already into

156
00:17:28,480 --> 00:17:35,920
what I explained, that they're mostly being worked on as a technological solution, often

157
00:17:35,920 --> 00:17:42,000
somehow a technological solution that's actually going to come about as a result of competition

158
00:17:42,000 --> 00:17:49,200
between entrepreneurial forces and the interest of seeking profit. So this is, again, a high-level

159
00:17:49,200 --> 00:17:55,360
frame about the kinds of contexts in which basic research should be taking place to solve the problem

160
00:17:55,920 --> 00:18:02,640
and a lack of coordinated effort, like, for example, we had around, let's say, the Manhattan

161
00:18:02,640 --> 00:18:07,120
Project, where it wasn't like, oh, let's let private industry solve this problem. It was like,

162
00:18:07,120 --> 00:18:15,840
no, this is a problem that needs the concerted effort of everybody. Note that they didn't

163
00:18:15,840 --> 00:18:24,640
solve the basic problem that I mentioned earlier, which was a secret project. So I think

164
00:18:24,640 --> 00:18:30,960
there's those two issues. There's a lot more to say about the kind of absence of comprehensive

165
00:18:30,960 --> 00:18:38,000
epistemics among the elite decision makers and policymakers. And somehow that discourse often

166
00:18:38,000 --> 00:18:44,960
feels captured to me or insincere to me. And at some point, you know, I don't know how to quite

167
00:18:44,960 --> 00:18:49,600
get in there and look at that. But that's, I think, a deep issue. I remember Jonathan Ross and my

168
00:18:49,600 --> 00:18:58,880
colleague at Perspectiva talking about finance. Just finance as one of the major profit centers

169
00:18:58,880 --> 00:19:04,880
of our civilization is basically the manipulation of fictitious capital. And the way these things

170
00:19:04,880 --> 00:19:10,880
down propagate into how people make decisions about very concrete things involving the ecology

171
00:19:10,880 --> 00:19:18,080
of the planet, or even just local ecologies. So yeah, so there's some form of motivated reasoning

172
00:19:18,640 --> 00:19:30,320
or kind of a very astute and studied blindness to certain issues, the like conspicuous absence of

173
00:19:30,320 --> 00:19:39,120
comprehensive approaches. So anyway, we have to get more specific about certain models. And again,

174
00:19:39,120 --> 00:19:45,440
I'm not an educator. So I'm thinking about the errors and they're thinking at a deeper level,

175
00:19:45,440 --> 00:19:50,400
not about like, oh, they've got these statistics wrong about CO2, or they haven't thought through

176
00:19:50,400 --> 00:19:55,760
the, you know, how difficult it is to actually make solar panels or all those technical questions

177
00:19:55,760 --> 00:20:01,360
are important. I'm looking at the underlying structure of their arguments and epistemics,

178
00:20:01,360 --> 00:20:06,400
essentially, and saying these are kind of flawed to begin with. So I'll leave it there.

179
00:20:08,000 --> 00:20:15,280
Yeah, I think it's very helpful to actually dive down and expose those underlying structural

180
00:20:15,280 --> 00:20:20,000
assumptions. Because it's very easy. I mean, I find myself doing all the time just getting

181
00:20:20,000 --> 00:20:27,680
captured by an interest in, in a part of the problem to compartmentalizing, siloing. So to

182
00:20:27,680 --> 00:20:32,960
actually step back and to try and get a sense of what are these larger macro structural forces in

183
00:20:32,960 --> 00:20:38,560
play is crucial. And I'm not sure we're very good at doing that. But I just want to hand over to

184
00:20:38,560 --> 00:20:45,360
Sam. Sam, Sam's got a question. Hi, thanks, Tom. And thank you, Zach. I just wanted to ask if we

185
00:20:46,400 --> 00:20:53,520
say in a perfect word, we realize the two issues that you very articulately put. And so we have

186
00:20:53,520 --> 00:20:58,400
an open society, let's say, for example, the United States of America, we have an open, educated

187
00:20:58,400 --> 00:21:05,520
society, finance capitalism is the thing of the past. How do we move that out of the confines

188
00:21:05,520 --> 00:21:12,160
of a kind of national paradigm? And could you talk a bit about obviously climate change is a

189
00:21:12,160 --> 00:21:18,640
collective action problem, a global collective action problem? And is there a space for more

190
00:21:18,640 --> 00:21:27,280
cosmopolitan education and working in a kind of global capacity or a cosmopolitan capacity

191
00:21:27,280 --> 00:21:31,600
to solve some of these collective action problems so that we don't have one society that is,

192
00:21:31,680 --> 00:21:38,880
you know, really clued up, but then constantly hitting up against brick walls around it?

193
00:21:40,720 --> 00:21:45,840
Yeah, I mean, I would point to nationalism, at least certain forms of nationalism,

194
00:21:45,840 --> 00:21:51,360
as one of those flaws and the highest level epistemic models that are plaguing the epistemic

195
00:21:51,360 --> 00:21:55,280
elites. It's a lot of epistemics in there. But you see what I'm saying, like there's a

196
00:21:55,840 --> 00:22:01,440
there's a bias towards certain ways of thinking about what the world situation is that makes

197
00:22:01,440 --> 00:22:06,160
it seem like the Brenton Woods agreements are still completely relevant and stuff when they're

198
00:22:06,160 --> 00:22:11,360
absolutely not, right? Or as if the UN actually somehow imposed a global order when it completely

199
00:22:11,360 --> 00:22:18,960
didn't. So there's a misunderstanding of what the actual real politic is at the level of what's

200
00:22:18,960 --> 00:22:27,280
going to take to solve these problems. And so it this isn't like, you know, we can't be naive

201
00:22:27,280 --> 00:22:32,080
and think that there will be international cooperation. But we do need to think about

202
00:22:32,080 --> 00:22:40,720
the forms of judgment, like as I was articulating, the forms of judgment that allow

203
00:22:41,600 --> 00:22:48,000
certain people within certain nations to be truly cosmopolitan actors, to not say they're

204
00:22:48,000 --> 00:22:52,400
acting in the interest of everyone, but actually be interesting, acting national interests,

205
00:22:52,960 --> 00:22:58,320
but that certain countries will actually have to sacrifice their advantages, right? They'll

206
00:22:58,320 --> 00:23:04,320
actually have to sacrifice their advantages in order to secure any possible viable future for

207
00:23:04,320 --> 00:23:07,680
other countries who don't have an opportunity to actually save themselves because of the position

208
00:23:07,680 --> 00:23:13,200
they've been put in by those countries who need to make a sacrifice, right? So there can't be

209
00:23:13,200 --> 00:23:17,040
anything like good faith conversation between the global north and the global south,

210
00:23:17,040 --> 00:23:20,560
until the global north is like, hey, we're going to make some sacrifices for you guys.

211
00:23:22,240 --> 00:23:27,680
And so and that story can be said, you know, east west, like north south, like this is a

212
00:23:28,720 --> 00:23:34,800
very complex situation. And so it requires a form of, let's just say, moral judgment,

213
00:23:34,800 --> 00:23:42,320
post-conventional, post-formal operational, cosmo-centric, cosmopolitan moral judgment,

214
00:23:42,320 --> 00:23:48,000
which is a rare human trait. I point to it in my book when I say, I can literally, as a human

215
00:23:48,000 --> 00:23:53,040
development expert, I can point at those capacities that we're going to need, right? We're going to

216
00:23:53,040 --> 00:24:00,400
need very complex forms of ethical self understanding, which position you within a local bioregion,

217
00:24:00,400 --> 00:24:04,400
within some kind of national structure, within some kind of global structure,

218
00:24:04,400 --> 00:24:10,800
probably within some kind of larger structure of universal value, ultimately. And that is not

219
00:24:10,800 --> 00:24:14,960
something you get from the American public education system as it stands now, for example.

220
00:24:15,600 --> 00:24:24,000
Like, we're not preparing post-conventional, dialectically thinking global citizens. We're

221
00:24:24,000 --> 00:24:30,560
preparing basically simple minded consumers, sometimes consumers of cultural warfare, so

222
00:24:30,560 --> 00:24:36,400
that they can participate in the entertainment of the culture wars. And so that's obviously an

223
00:24:36,400 --> 00:24:41,040
adequate that's going to lead us to further into some kind of self terminating tribalization.

224
00:24:41,040 --> 00:24:47,600
So you're pointing to the cosmopolitan consciousness as key. And it's going to be, like I said,

225
00:24:47,600 --> 00:24:58,080
unequally distributed in terms of the cascade effects of risk, right? And Ulrich back pointed

226
00:24:58,080 --> 00:25:02,080
this out in his work on the risk society, like that the risks are inevitably distributed.

227
00:25:02,080 --> 00:25:08,240
Some people are kind of safe. Some people are relatively unsafe, right? And then the need for

228
00:25:09,040 --> 00:25:12,880
getting out of your position of advantage and putting your position in a position of

229
00:25:12,880 --> 00:25:17,120
basically sacrificing for the whole, that's going to be unequally distributed, right?

230
00:25:18,400 --> 00:25:27,840
So it's become a very delicate situation where we need to avoid the pitfalls of those prior attempts

231
00:25:28,720 --> 00:25:37,120
by the north and the west to try to like help out in the global south and elsewhere.

232
00:25:37,120 --> 00:25:45,840
Well, we're going to need a way to flip that kind of relationship. And so, yeah, some of what's

233
00:25:45,840 --> 00:25:52,560
taking place with social justice and kind of issues of race in the United States,

234
00:25:53,520 --> 00:25:59,280
you know, these conversations will need to be expanded. Again, this is part of what I mean by

235
00:25:59,280 --> 00:26:03,680
it's fundamentally an educational crisis. Even if we solve the technological problems,

236
00:26:03,680 --> 00:26:07,600
we still have to resolve this history of injustice that we're living with.

237
00:26:09,360 --> 00:26:15,440
Or else, who's going to want to join your future sustainable, super technologically awesome society?

238
00:26:16,480 --> 00:26:19,600
Like it just doesn't make sense. Like we have to, there's a certain

239
00:26:20,240 --> 00:26:27,360
healing at the level of culture and a willingness to somehow reengage in good faith again.

240
00:26:29,440 --> 00:26:33,120
And so I don't know the kind of crisis that will ensue that will allow that

241
00:26:33,760 --> 00:26:39,280
transformation of self understanding to unfold with a broad enough swath of people.

242
00:26:40,640 --> 00:26:49,120
But yeah, I know as a human development person that it is, it is crises. It is crises and tragedy

243
00:26:49,120 --> 00:26:55,600
often that can break the psyche open enough to actually transform.

244
00:26:56,960 --> 00:27:00,240
So that would be one way to think about that.

245
00:27:02,240 --> 00:27:08,880
I think it's incredibly helpful and important to bring history into this conversation.

246
00:27:10,160 --> 00:27:13,360
Global history, which is something which has been somewhat missing from

247
00:27:14,160 --> 00:27:20,320
the international relations scholarship in recent years. And there is a certain resurgence now

248
00:27:20,320 --> 00:27:24,800
of a historical sensibility in the current scholarship. And the importance, of course,

249
00:27:24,800 --> 00:27:31,040
of acknowledging militarism and economic imperialism. And I think what you just said, Zach,

250
00:27:31,040 --> 00:27:36,560
there's a bracing clarity in understanding the ethical core of the challenge. And it reminds

251
00:27:36,560 --> 00:27:42,640
me of Henry Shu, a prominent human rights scholar, writing in 1992 about the unavoidability of

252
00:27:42,640 --> 00:27:47,760
justice when it comes to climate change and the crucial distinction between luxury emissions

253
00:27:47,760 --> 00:27:55,200
and survival emissions. And that conversation has sort of crept in from time to time,

254
00:27:55,200 --> 00:28:00,000
but it's rarely been at the foreground of how we actually deal with climate change,

255
00:28:00,000 --> 00:28:05,920
the climate emergency. But I was curious to pick up on this idea of biases and the way

256
00:28:05,920 --> 00:28:11,760
that we see the world. We're now almost halfway through this 50 year critical turning point.

257
00:28:11,760 --> 00:28:19,120
So riffing on Wallerstein, but also say Gramski, is there more to what's going on right now

258
00:28:19,120 --> 00:28:26,400
in the midst of COVID as well, than a host of morbid symptoms? You write in the book,

259
00:28:27,120 --> 00:28:33,040
or you quote actually HG Wells, that the future is a race between catastrophe and education.

260
00:28:33,760 --> 00:28:39,760
And you hold out the prospect of good educational futures emerging out of the present.

261
00:28:40,720 --> 00:28:47,200
But it often seems to me or feels like there's not much space in the culture for exploring the

262
00:28:47,200 --> 00:28:56,320
upside of risks and uncertainties. There's a certain sort of catastrophesism, that's the word.

263
00:28:57,680 --> 00:29:05,280
And that in itself might be a kind of educational deficit. But I wonder then, how do we even get

264
00:29:05,360 --> 00:29:11,680
started if our collective aversion to risk closes off the possibility of

265
00:29:12,960 --> 00:29:17,600
accelerating in the direction of healthy radical transformation?

266
00:29:20,160 --> 00:29:25,840
Yeah, this is interesting because I think there's two ways that there's two reactions

267
00:29:25,840 --> 00:29:32,080
when you start to become aware of the existential risk landscape. I'll call them techno-optimist

268
00:29:32,080 --> 00:29:43,920
and techno-pessimist. The techno-optimist basically talks themselves out of the idea that

269
00:29:43,920 --> 00:29:50,720
there actually is a risk and puts a tremendous amount of faith in human problem-solving capacity.

270
00:29:50,720 --> 00:30:00,240
And this is not an error. We're still here. We should maybe not be probabilistically

271
00:30:00,240 --> 00:30:07,120
on many ledgers. It's actually a question, I think, for people who study existential risk.

272
00:30:07,120 --> 00:30:14,160
Why are we still here? But that's a separate question. So with that, I think is a way to

273
00:30:14,160 --> 00:30:24,080
avoid looking at the risk, really just having an overtly optimistic view of our ability to

274
00:30:24,080 --> 00:30:29,440
solve these problems, usually with technology. The other way is also a way of averting looking

275
00:30:29,440 --> 00:30:33,360
at the risk because you basically say there's nothing we can do about it and you go to the

276
00:30:33,360 --> 00:30:41,200
techno-optimist view, which basically says it's over. It's done. Get ready basically to die.

277
00:30:41,200 --> 00:30:49,600
Maybe we can reboot somehow after everything goes away, but technology has done us in.

278
00:30:53,600 --> 00:30:57,600
And the truth is that when you look at the probabilities and you look at the extra landscape,

279
00:30:57,600 --> 00:31:04,240
it's hard not to be pessimistic. So there's a huge moment of truth in the views. So there's

280
00:31:04,240 --> 00:31:12,000
something about both of those extremes, which is partially right and partially wrong. And the bit

281
00:31:12,000 --> 00:31:16,080
about education is a great example because this is what I'm doing my thinking. So right now,

282
00:31:16,080 --> 00:31:22,720
I believe we have the most sophisticated communication technologies ever for delivering

283
00:31:22,720 --> 00:31:30,640
propaganda directly into people's minds. Those very same tools could be used to make the most

284
00:31:30,640 --> 00:31:37,120
powerful educational infrastructure that has ever been created. And so this is this notion of we're

285
00:31:37,120 --> 00:31:42,720
getting exponential information technology in particular. It's disrupting the educational

286
00:31:43,360 --> 00:31:48,640
dynamics of intergenerational transmission. It's making us go insane right now. We're all going

287
00:31:48,720 --> 00:31:53,280
insane because we're being deeply propagandized by these things we're holding in the palm of

288
00:31:53,280 --> 00:31:58,880
our hand that are basically making us addicted to staring at them. All of that same infrastructure,

289
00:31:58,880 --> 00:32:05,840
were we to retool it, could be used to actually customize the delivery of truly educational

290
00:32:05,840 --> 00:32:12,400
material. This is basically the crux of my argument that we're misusing the potentialities of the

291
00:32:12,400 --> 00:32:19,040
digital. And we could potentially wield them in the interest of unprecedented education and

292
00:32:19,040 --> 00:32:25,040
unprecedented kind of capacities for having a complex open society. And so many of the technologies

293
00:32:25,040 --> 00:32:32,560
that we have have this double-sided nature to them. Artificial intelligence is another one.

294
00:32:33,600 --> 00:32:37,680
You can go techno-optimist or techno-pessimist on the artificial intelligence thing.

295
00:32:38,640 --> 00:32:43,680
And both of those are right and wrong. And the truth of the matter is that

296
00:32:46,240 --> 00:32:51,840
yeah, there's always going to be

297
00:32:55,600 --> 00:33:04,000
a lack of determinism around what the outcome of a technological innovation is. So this is my view,

298
00:33:04,080 --> 00:33:08,640
like following Mumford and Marshall McLuhan and others. There are certain things that are laid out

299
00:33:08,640 --> 00:33:13,760
that are that come with the technology. And then there's this space of freedom around the technology

300
00:33:13,760 --> 00:33:19,920
as to where and how and when the technology gets used. And so I think right now we're not even close

301
00:33:19,920 --> 00:33:24,000
to doing what the digital could do in the realm of education because we're using it for entertainment

302
00:33:24,000 --> 00:33:32,640
and propaganda because it's profitable. But at a certain point, we're a group to decide like a

303
00:33:33,120 --> 00:33:38,720
country-sized group or even like a city-state where a group decide to retool these things

304
00:33:38,720 --> 00:33:44,160
precisely for education. They would have a tremendous asymmetric advantage very rapidly,

305
00:33:44,960 --> 00:33:49,600
epistemically over the entire rest of the world who's misusing the tools.

306
00:33:52,080 --> 00:33:57,440
So that's like a glimmer. And there's many of these glimmers of hope right at the heart of the

307
00:33:57,440 --> 00:34:03,600
darkness like right in the place where all of the propaganda is coming from. It's like right in

308
00:34:03,600 --> 00:34:11,120
there that there's actually the potential for profound educational possibilities. And I end

309
00:34:11,120 --> 00:34:16,240
amending up sounding a lot like a Marxist here. I'm not a Marxist. But that idea that capitalism

310
00:34:16,240 --> 00:34:21,440
builds out this massive global structure of technology and then right as it's about to lock in,

311
00:34:22,080 --> 00:34:28,720
it flips and that same technology becomes the infrastructure of freedom. That's a very

312
00:34:28,720 --> 00:34:38,320
interesting idea. So yeah, that's one way I think. Again, just one way to think about that.

313
00:34:39,600 --> 00:34:46,720
Yeah, fantastic. Thanks Zach. Hope right in the darkness. That's a phrase to ponder I think.

314
00:34:47,440 --> 00:34:54,400
Okay, I'm going to hand over to Jess. Jess, please. Yes. Thanks so much Zach for everything

315
00:34:54,400 --> 00:35:01,920
you've shared so far. Coming off this idea of propaganda and the tech tools that deliver it to

316
00:35:01,920 --> 00:35:11,360
us as a foremost teacher-lead authority in our society right now. How and if it is retooled

317
00:35:11,920 --> 00:35:19,440
to become a source of mass delivery for education, how will it be established in a culture which is

318
00:35:19,440 --> 00:35:26,240
often suspicious of authority claims? I mean, as a child growing up when the internet was just

319
00:35:26,240 --> 00:35:30,720
becoming widespread, we were always told not to believe what you read on the internet. And I think

320
00:35:30,720 --> 00:35:35,440
some kids have maybe lost that as it's become more and more ubiquitous throughout our lives.

321
00:35:35,440 --> 00:35:40,080
But if it does in the future become something positive, quote unquote, or

322
00:35:41,360 --> 00:35:47,120
you know, dependable, how do you think the population would react to that and will it be a

323
00:35:47,120 --> 00:35:53,920
smooth transition? It's very interesting. And yeah, I have this term teacher-lead authority,

324
00:35:53,920 --> 00:36:00,480
which I use a lot in my book and it hinges on this. It hinges on what's the nature of legitimate

325
00:36:00,480 --> 00:36:05,440
teacher-lead authority and how do you know when you've got it in a context that's

326
00:36:06,320 --> 00:36:11,600
saturated with illegitimate teacher-lead authority. And so the classic example is a school, right?

327
00:36:11,600 --> 00:36:16,480
The school and their students and teachers, right? Students have to be there because they're forced

328
00:36:16,480 --> 00:36:22,160
to be there. The teachers are there because they get paid. The teachers have teacher-lead authority

329
00:36:22,160 --> 00:36:27,840
by virtue of their bureaucratic position in relation to the student, right? So most students

330
00:36:27,840 --> 00:36:33,760
experience teachers as teachers, not necessarily because they're super smart and like really good

331
00:36:33,760 --> 00:36:39,200
at being teachers, but because this is their job. And so we're in an environment where there's an

332
00:36:39,200 --> 00:36:45,920
inorganic, let's call it inorganic, bureaucratically mediated teacher-lead authority, right? Now,

333
00:36:45,920 --> 00:36:54,160
sometimes in those contexts, your high school teacher is a teacher. Like, he's brilliant and

334
00:36:54,160 --> 00:36:59,680
he's really good at teaching you. And you've kind of fallen in love with the idea that like this man

335
00:36:59,680 --> 00:37:02,800
can like change your whole mind. I'm speaking about one teacher, I'm remembering this teacher,

336
00:37:02,800 --> 00:37:08,320
I had an high school, right? And so all of a sudden in this bureaucratically mediated teacher-lead

337
00:37:08,320 --> 00:37:12,880
authority, where often you encounter a teacher who's lazy and you don't understand them and you

338
00:37:12,880 --> 00:37:17,360
don't know why they became a teacher and you think it's bullshit. There is actually a beacon of

339
00:37:17,360 --> 00:37:21,520
legitimate teacher-lead authority. And you can recognize legitimate teacher-lead authority

340
00:37:21,520 --> 00:37:28,080
because one of the main things it's doing is trying to make itself obsolete. It wants you

341
00:37:28,080 --> 00:37:34,160
to be able to do what it does. Like by definition, a good teacher is trying to get you up to their

342
00:37:34,160 --> 00:37:39,680
level and maybe actually get you to go beyond their level. So one of the ways you know when

343
00:37:39,680 --> 00:37:45,760
you're looking at like the media or you're looking at a pundit or someone who's speaking is,

344
00:37:46,480 --> 00:37:55,520
are they actually encouraging you and giving you what you need to detach yourself from being

345
00:37:55,520 --> 00:38:02,240
their student forever, right? Or are they addicting to you to them, excuse me, are they

346
00:38:02,240 --> 00:38:06,320
are you becoming addicted to them as the only source of information you can trust and use,

347
00:38:07,120 --> 00:38:11,840
right? So this becomes a very interesting dynamic when you look at the media landscape.

348
00:38:12,720 --> 00:38:19,920
And when you look specifically at the discussion of science in the media and the disconnect between

349
00:38:19,920 --> 00:38:25,280
the stories the media tell and the complexity of the science that's happening and their attempt to

350
00:38:25,280 --> 00:38:31,120
run interference on readers so that you don't go to the primary source material, that you're not

351
00:38:31,120 --> 00:38:36,720
actually equipped to be able to be smarter about the issue than this random journalist who actually

352
00:38:36,720 --> 00:38:42,080
isn't a virologist, right? It's journalist, not a virologist. It's never studied vaccines, right?

353
00:38:43,280 --> 00:38:45,920
Are they putting me in a position to actually understand the issue?

354
00:38:46,880 --> 00:38:53,360
Are the actual major institutions involved giving me the information I need to be truly

355
00:38:53,360 --> 00:38:58,320
informed about the issue or not? Or are they just basically telling me what to do pretending to be a

356
00:38:58,320 --> 00:39:06,880
teacherly authority? So you're right, we've become suspicious of teacherly authority because we have

357
00:39:06,880 --> 00:39:15,680
good reason to be. Most of what takes place in the fourth estate, which is supposed to be, you

358
00:39:15,680 --> 00:39:21,360
know, journalism and the press and supposed to be an educational institution, most of what's

359
00:39:21,360 --> 00:39:28,480
taking place there is not by any definition looking like legitimate teacherly authority.

360
00:39:30,640 --> 00:39:37,280
And so, but the saving grace, and this gets to your point, the saving grace is that when that

361
00:39:37,280 --> 00:39:43,520
high school teacher appears, he gets a posse, like students are like, that's the real deal.

362
00:39:44,880 --> 00:39:48,960
Like that's someone who actually cares and is actually trying to empower us, like actually

363
00:39:48,960 --> 00:39:53,520
trying to give us the capacities and the skills that we could become our own teachers, right?

364
00:39:54,880 --> 00:40:04,800
So I do think that if you build the system correctly, and you have the kind of stepwise access

365
00:40:04,800 --> 00:40:10,160
to deeper and deeper and deeper information and empowerment epistemically, where there's no

366
00:40:10,160 --> 00:40:16,560
invisible ceiling of a epistemic asymmetry, where the populace is like, all right, on the other side

367
00:40:16,640 --> 00:40:22,960
of this, those guys know what's going on, which is what it feels right now. Most people feel

368
00:40:22,960 --> 00:40:27,520
like no one really trusts the media. We do what the media tells us because we're socially pressured

369
00:40:27,520 --> 00:40:32,880
to use certain words and to have certain beliefs, especially in social media. But if you look at

370
00:40:32,880 --> 00:40:37,120
the statistics, most people just simply don't trust the media. They have allegiance to certain

371
00:40:37,120 --> 00:40:42,240
ones because they're useful in cultural warfare, but they don't actually really trust what's being

372
00:40:42,240 --> 00:40:48,400
said by the media. And so when you have this kind of duplicity and this deep sense that, well,

373
00:40:48,400 --> 00:40:54,400
somebody must know what's actually going on. And so there's this deep suspicion and this lays,

374
00:40:54,400 --> 00:40:58,640
of course, the groundwork for much of the cultural dysfunction we're seeing around, you know, so-called

375
00:40:58,640 --> 00:41:03,280
conspiracy theories and things of that nature, which emerge from the sense of somehow there's a

376
00:41:03,280 --> 00:41:12,160
ceiling of epistemic asymmetry, that the main kind of media, like news media, social media,

377
00:41:12,160 --> 00:41:18,960
the ways we're supposed to get up and into understanding the world, don't give or don't

378
00:41:18,960 --> 00:41:25,680
kind of work in context of legitimate teacherly authority. So it's a widespread and deep problem

379
00:41:25,680 --> 00:41:30,000
because now we're cynical about the idea that there could even be teacherly authority. So I

380
00:41:30,000 --> 00:41:33,120
think to your point where someone said, don't believe what you read online. I don't think

381
00:41:33,760 --> 00:41:38,240
kids forgot that. I think it's that they don't believe what they read online, which means they

382
00:41:38,240 --> 00:41:42,080
don't believe anything because all they do is read online. So it becomes, it moves from like,

383
00:41:42,080 --> 00:41:47,120
there's a true story and then there's this crazy online stuff to just like, there's just crazy

384
00:41:47,120 --> 00:41:53,200
online stuff. And the idea that there's a true story somewhere, that's not even really an idea

385
00:41:53,200 --> 00:41:59,760
anymore. I'm telling you, like, when you look at the epistemologies of people under 20, what you

386
00:41:59,760 --> 00:42:07,680
end up getting is a kind of widely diffuse epistemic nihilism, you know, where there's this fusion

387
00:42:07,680 --> 00:42:15,280
between entertainment and belief, and a fusion between a need to have in-group membership in a

388
00:42:15,280 --> 00:42:22,560
cultural war and motivated reasoning to believe certain things. So the sense of like having

389
00:42:23,520 --> 00:42:30,320
an integrist truth and an orientation towards ongoing learning and having access to stuff

390
00:42:30,320 --> 00:42:36,320
that would allow you to do that and that would encourage doing that. These are cultures like

391
00:42:36,320 --> 00:42:42,480
that are few and far between right now and hard to find, but they need to be created. And I think

392
00:42:42,480 --> 00:42:48,960
when they are, I do think people will be attracted to them because most people don't trust the media,

393
00:42:48,960 --> 00:42:53,120
but they want to know what's going on. Like people want to know, it's not that people don't want to

394
00:42:53,120 --> 00:42:59,840
know, it's that there's a certain cynicism or nihilism about the prospect of success of knowing

395
00:43:00,400 --> 00:43:05,600
that we've been disadvantaged in our ability to know. And there's a lot to say there, some of the

396
00:43:05,600 --> 00:43:11,040
research I'm doing now is on the nature and the history of propaganda and information warfare

397
00:43:11,040 --> 00:43:17,760
and communication sciences. And it's a long history, you know, decades and decades and decades,

398
00:43:17,760 --> 00:43:23,920
we've been working on how to kind of like manipulate large populations through communication

399
00:43:23,920 --> 00:43:32,080
science, often with a kind of technocratically benevolent notion that the masses need to be

400
00:43:32,080 --> 00:43:37,920
helped in making the right decision. And that brings us back to that prior point I made about

401
00:43:37,920 --> 00:43:41,360
the relation between the epistemic elites and the so-called people.

402
00:43:41,360 --> 00:43:51,680
Yes, that point really resonated with me, especially it gave me the idea that it seems

403
00:43:51,680 --> 00:43:58,320
that true education, where everyone can have access to a primary source, is mutually exclusive

404
00:43:58,320 --> 00:44:05,280
from control and power. I was wondering if you had any thoughts on that and whether the epistemic

405
00:44:05,280 --> 00:44:11,840
elite or high-level policymakers would ever be motivated to relinquish control and power that

406
00:44:11,840 --> 00:44:18,080
has been designed and fueled through this structure of propaganda and entertainment media?

407
00:44:19,440 --> 00:44:26,640
It's a very, very good question. The relationship between power and education and the relationship

408
00:44:26,640 --> 00:44:34,720
between power and teacherly authority in particular. It's funny because I say teacherly

409
00:44:34,720 --> 00:44:38,960
authority and everyone thinks like a school and I use that context, but actually it's the mother and

410
00:44:38,960 --> 00:44:46,160
the child or the parent, the parenting one and the child, where you get that most basic, actually

411
00:44:46,160 --> 00:44:56,960
most kind of like anthropologically primordial case of teacherly authority. And what you see in

412
00:44:56,960 --> 00:45:05,440
that relationship is in fact the power, like the power of the mother over the child. Let's

413
00:45:05,440 --> 00:45:13,040
talk about that. What kind of power is that? It's not the same power as what Roy Baskar and others

414
00:45:13,040 --> 00:45:19,120
would call power over, like the political power, having access to the legitimate use of force

415
00:45:19,120 --> 00:45:26,560
or the legitimate use of bureaucratic mechanism to punish basically. So the power of the mother

416
00:45:26,560 --> 00:45:34,080
over the infant is actually the power of care. And so it's a legitimate asymmetry. The mother's

417
00:45:34,080 --> 00:45:41,040
larger, stronger, literally provides sustenance to the child and then teaches the child all kinds of

418
00:45:41,040 --> 00:45:46,240
things without even intending to do so. The child instinctively puts itself in relationship to the

419
00:45:46,240 --> 00:45:55,600
mother as teacher. And so it's not about the absence of power that you get legitimate teacherly

420
00:45:55,600 --> 00:46:01,680
authority. It's about a particular kind of power, a power of care or a power of love that binds people

421
00:46:01,680 --> 00:46:07,280
in a relationship that's completely non-coercive. It's completely non-coercive. We associate power

422
00:46:07,280 --> 00:46:13,680
with coercion and that's what most political power is. But there's actually a power, Habermas would

423
00:46:13,680 --> 00:46:18,880
call it, like the unforced force of the better argument. That's an example of legitimate teacherly

424
00:46:18,880 --> 00:46:23,280
authority. Or it's like, why do I agree with you? I'm not agreeing with you because you're going to

425
00:46:23,280 --> 00:46:29,680
beat me up or because I get in trouble or I get shunned from my in-group. I'm agreeing with you

426
00:46:29,680 --> 00:46:35,280
because that is a better argument than the arguments I've heard, the force of logic, right?

427
00:46:35,280 --> 00:46:41,440
The force of reason compels me, not the force of physical. So the power of a strong argument

428
00:46:41,440 --> 00:46:46,560
is an example of the power that's in legitimate teacherly authority. Now, when you try to merge

429
00:46:46,560 --> 00:46:52,560
teacherly authority with bureaucratic power, that's when you get that situation where now you can't

430
00:46:52,560 --> 00:46:57,760
tell. Am I doing what this teacher tells me because I respect them the way I might respect

431
00:46:57,760 --> 00:47:02,240
my mother and am I vibing with them through love and teacherly authority? Or is it I have

432
00:47:02,240 --> 00:47:06,880
to do this because otherwise I get punished? They have the legitimate use of bureaucratic force over

433
00:47:06,880 --> 00:47:13,920
me as a student. And similarly with the media and social media, things of that nature. And of

434
00:47:13,920 --> 00:47:20,640
course, political speeches and the communication scientists that kind of roll out political

435
00:47:20,640 --> 00:47:29,200
platforms. There's always this question about the form of power that's in play. And

436
00:47:31,920 --> 00:47:37,520
the degree to which we can say that we are consenting with full knowledge of what our

437
00:47:37,520 --> 00:47:47,920
situation is or not. And so yeah, I think in an ideal world, you would have conditions of education

438
00:47:47,920 --> 00:47:53,920
where there wasn't the opportunity to confuse those two forms of power. Where you gravitated to

439
00:47:53,920 --> 00:48:01,760
particular teachers and you gravitated to particular courses of study because of the power of the

440
00:48:02,800 --> 00:48:08,560
teacherly, of the power of the true argument, the power of the curiosity, the power of the

441
00:48:08,560 --> 00:48:15,760
attraction between teacher and student, the epistemic humility and these kinds of qualities.

442
00:48:16,720 --> 00:48:20,960
Whereas now it's often the case and has been with the public schools that

443
00:48:22,160 --> 00:48:27,200
there is a certain, there's a certain coercion that takes place in just getting a kid to go to school.

444
00:48:28,480 --> 00:48:34,080
You know, like literally you have to kid, like even if you don't want to. So yeah, so I think

445
00:48:34,960 --> 00:48:43,760
those, the kind of like the power over the political power and then this other form of power

446
00:48:43,760 --> 00:48:48,880
which we, which we're not as familiar with, like power gets a bad name and what I'm trying to say

447
00:48:48,880 --> 00:48:54,400
is like there's actually this, there is this form of power. You know, like when you see Martin

448
00:48:54,400 --> 00:48:59,840
Luther King speak, for example, it's a different kind of power, like there's a power of persuasion

449
00:48:59,840 --> 00:49:06,080
that's not coercion or there's a power to educate that's not propaganda. And so these kinds of

450
00:49:06,080 --> 00:49:09,520
distinctions are some of the stuff I'm working on for the Consilience Project because it becomes

451
00:49:09,520 --> 00:49:13,600
essential as the information environment gets more complex for people who'd be able to tell

452
00:49:13,680 --> 00:49:18,800
what's the difference here. Is this person sincerely trying to educate me or are they just

453
00:49:18,800 --> 00:49:25,120
doing one of their shticks and trying to, you know, basically, so yeah, so this is a good question.

454
00:49:25,120 --> 00:49:29,440
And again, I'm just like touching on it. There's, there's a lot of, a lot of complexity there.

455
00:49:30,960 --> 00:49:37,440
Yeah, fantastic. Fascinating. Yeah, definitely. This idea of power as protein,

456
00:49:38,160 --> 00:49:43,520
it's really something which often is difficult to grasp. There's a certain

457
00:49:45,680 --> 00:49:53,120
allergic reaction to shifting the focus away from, say, the material, the tangible,

458
00:49:53,120 --> 00:49:58,640
but clearly it's absolutely vital. Perhaps just to rip a bit on Jesse's personal reflection,

459
00:49:59,600 --> 00:50:06,640
you know, as, as an academic, as a child of Fukuyama, I sometimes do wonder,

460
00:50:07,440 --> 00:50:13,280
who are we as educators to tell future generations what to think or what to do

461
00:50:14,080 --> 00:50:23,200
with this world that we're sort of leaving them? And as educators, what if our ideas about the

462
00:50:23,200 --> 00:50:33,280
future are no longer relevant, which is a pretty disconcerting thought? And I wonder, how can we

463
00:50:33,280 --> 00:50:43,440
distinguish between those legacy ideas and frames that must be salvaged and those that really we

464
00:50:43,440 --> 00:50:51,280
should consider relinquishing? And it's disconcerting not only because it, because it leaves you

465
00:50:51,280 --> 00:50:56,960
disorientated, but also perhaps because it feels disempowering to consider that it kind of undercuts

466
00:50:58,880 --> 00:51:02,880
the conviction that you can change things for the better.

467
00:51:06,000 --> 00:51:09,600
Yeah, this is, is a very foundational question in the philosophy of education,

468
00:51:10,960 --> 00:51:16,960
which is, you know, what is the knowledge and skill and capacity, even the disposition,

469
00:51:17,600 --> 00:51:20,880
dispositions and forms of personality? Like, what are those things that we should be

470
00:51:21,760 --> 00:51:30,320
handing on to the next generation? It's a book by Margaret Mead. I want to say 61. I don't remember

471
00:51:30,320 --> 00:51:34,400
exactly culture and commitment. It's the name of the book. And it's amazing. It's a fascinating book.

472
00:51:34,400 --> 00:51:37,920
She talks about these three forms of culture, which is really talking about three forms of

473
00:51:37,920 --> 00:51:42,960
intergenerational transmission. There's a post figurative culture. This is what human cultures

474
00:51:42,960 --> 00:51:48,000
were forever. That's when what your dad-dads did, your dad did. That's what you're going to do.

475
00:51:48,560 --> 00:51:56,080
Like, you can just know as an elder, like I will hand on to my kids what basically they need,

476
00:51:56,080 --> 00:52:00,480
and things just don't change. And the kids can be like, they really know how the world works.

477
00:52:01,760 --> 00:52:05,760
And it's a post figurative, right? And then there are what are called

478
00:52:06,160 --> 00:52:10,880
configurative cultures. And that's where you have some of the post figurative stuff

479
00:52:11,440 --> 00:52:16,000
and stuff going on within generations where you're changing what your parents gave you a little bit.

480
00:52:16,800 --> 00:52:23,040
So you're getting peer-to-peer changes in technology, which slightly augment intergenerational

481
00:52:23,040 --> 00:52:29,520
transmission. And so not just the sheer tradition of the post figurative, a certain amount of

482
00:52:29,520 --> 00:52:35,440
innovation. And that's what began when, especially and took off with, again, back to Wallerstein,

483
00:52:35,440 --> 00:52:40,720
the birth of the capitalist world system. Her argument is that there's a thing called a prefigurative

484
00:52:40,720 --> 00:52:48,640
culture. And that's where basically, like, those bets are off because things are changing so rapidly

485
00:52:49,280 --> 00:52:55,840
that the world that the children will inhabit is not understandable by the elders today.

486
00:52:56,320 --> 00:53:03,200
Right? So it's a very, very novel situation in the evolution of human culture now. It happened

487
00:53:03,200 --> 00:53:08,720
occasionally in the past when there was an invading army, or there was a massive storm,

488
00:53:08,720 --> 00:53:14,800
or there was desertification. And in a generation or two, the entire life, you know, of a culture

489
00:53:14,800 --> 00:53:19,920
changed when that was a rare cataclysmic event. Our technological development and economic development

490
00:53:19,920 --> 00:53:26,880
and political development is such that now we are generating those types of total world

491
00:53:26,880 --> 00:53:32,560
transformation within a single generation. And so what that means is that, to your point,

492
00:53:32,560 --> 00:53:35,920
we have no idea really what to tell the kids about what Tamara is going to be like.

493
00:53:37,200 --> 00:53:42,640
We actually need to find ways to have them listen to the future and then give them the

494
00:53:42,640 --> 00:53:49,520
help that they realize that they need. So, and this has been seen by educators since the 60s,

495
00:53:49,520 --> 00:53:55,280
when it became clear that you all are preparing these kids for jobs that will not be there in 20

496
00:53:55,280 --> 00:54:01,440
years when they graduate. And that problem has compounded to the sense of that we can no longer

497
00:54:01,440 --> 00:54:09,040
think simply about that form. But at an even deeper level, the intergenerational crisis is one of

498
00:54:09,040 --> 00:54:15,200
both the children not thinking that the elders know how the world works, right, and being skeptical

499
00:54:15,200 --> 00:54:20,080
that, well, aren't you the guys that messed up this world? Like, why should we learn from you?

500
00:54:20,080 --> 00:54:25,760
You created this mess. But it's also the elders realizing that is the elders saying,

501
00:54:26,480 --> 00:54:31,920
we're a failed, we're failed beings, like we're a failed species, like what have we done? How can

502
00:54:31,920 --> 00:54:37,600
we teach the kids what to do? And so, and that's part of that prefigurative culture, like those

503
00:54:37,600 --> 00:54:44,400
reflections are correct, but they're not quite fair to each side of the generational gap that

504
00:54:44,400 --> 00:54:53,600
there's a situation that's emerged that came unplanned, but has basically left the youth kind

505
00:54:53,600 --> 00:54:59,600
of stranded at the edge of history without any elders to tell them what tomorrow will look like

506
00:54:59,600 --> 00:55:04,720
or how to handle it. So the elders, what they need to do is step in and hold education in a

507
00:55:04,720 --> 00:55:09,040
completely different way. And this is kind of the argument of my book, that we need to

508
00:55:10,000 --> 00:55:16,160
reground education of the youth in the communities that they live and in the concrete problems of

509
00:55:16,160 --> 00:55:24,960
those communities, right, which is to say something a little bit more like guild systems and skill and

510
00:55:24,960 --> 00:55:31,760
time sharing networks and non-age segregated classrooms and a whole bunch of other stuff

511
00:55:31,760 --> 00:55:39,520
that allow the education system to be responsive to the novel insights of youth who

512
00:55:40,640 --> 00:55:46,080
know more about what might emerge in the future than the elders can pretend to know.

513
00:55:47,120 --> 00:55:53,120
And so I think that's, it's a lot to swallow, but it's completely necessary. And it doesn't mean

514
00:55:53,120 --> 00:55:57,600
that there isn't a role for intergenerational transmission. It means that of the skills that

515
00:55:57,600 --> 00:56:05,360
we have as elders, let the kids tell us which ones they believe are relevant. And so that's,

516
00:56:05,360 --> 00:56:13,120
that's, I think, I think that's key. And then some of it's also the shifting of focus away from,

517
00:56:14,240 --> 00:56:19,600
again, technical skills and into what might be called skills of wisdom or skills of ethics,

518
00:56:20,560 --> 00:56:29,120
that a lot of what is needed from the elders is that, like, don't tell us how to solve these

519
00:56:29,120 --> 00:56:36,080
problems or how to organize our future economic lives or anything like that, but please share

520
00:56:36,080 --> 00:56:47,280
stories of human suffering, of human love, of human overcoming difficulty. The continuity of the human

521
00:56:47,360 --> 00:56:55,760
is at risk. It's a strange way to say it, but this is has been reflected upon by technologists

522
00:56:55,760 --> 00:57:02,560
and others that if the generation gap becomes acute enough, it becomes almost like a speciation

523
00:57:02,560 --> 00:57:10,640
event where the youth become a new kind of being that almost can't be understood, that we can't.

524
00:57:10,640 --> 00:57:16,000
Like if we were to genetically engineer superhumans, this would be the situation we would have

525
00:57:16,640 --> 00:57:22,080
extincted ourselves by virtue of giving birth to a new species and that would be an intergenerational

526
00:57:22,080 --> 00:57:29,120
gap that's unbridgeable. So that, you know, with the rate of technological change and specifically

527
00:57:29,120 --> 00:57:35,120
the information technology and the neurological effects and the cascades of all those on human

528
00:57:35,120 --> 00:57:43,600
physiology, yeah, the generation gap approaches almost unbridgeable speciation event. So that

529
00:57:43,600 --> 00:57:50,240
means that, yeah, how do we educate those who will come after us who are not like us? It looks like

530
00:57:50,240 --> 00:57:58,000
I said creating very different contexts and allowing more epistemic humility on the part of

531
00:57:58,000 --> 00:58:05,760
the elders, but it's risky because the kids, they're just, they're still youth. It's not like,

532
00:58:05,760 --> 00:58:11,280
I'm also not making an argument of like, you know, the indigo kids are like that they're instantly,

533
00:58:11,360 --> 00:58:15,920
you know, adapting to the technology and that the millennials are like way smarter than any

534
00:58:15,920 --> 00:58:20,320
other generation. They're going to figure it out. I'm also not saying that. Like there needs to be

535
00:58:20,320 --> 00:58:25,600
intergenerational transmission. The prefigure of culture that I mentioned doesn't just throw its

536
00:58:25,600 --> 00:58:29,840
hands up and say, let the kids do whatever it wants. It says no, it's we're in a fundamentally

537
00:58:29,840 --> 00:58:35,200
different situation of intergenerational transmission. It's actually more attention is needed. We need

538
00:58:35,200 --> 00:58:42,000
to be more careful to pulling out the responsiveness and the kind of native intelligence of the youth

539
00:58:43,520 --> 00:58:48,080
than just giving them rote curriculum that we've been giving for a decade. So there's some asking

540
00:58:48,080 --> 00:58:52,960
for more attentiveness on the part of the elders and the youth, more intergenerational

541
00:58:52,960 --> 00:59:00,560
transmission, just of a different kind. And it's not the case that the youth are prepared

542
00:59:00,560 --> 00:59:09,600
or instantly adapted or evolved for it. They're not. So yeah, the nature of our responsibility

543
00:59:09,600 --> 00:59:16,480
as educators has changed. I think the the question of differences of generation is such an

544
00:59:16,480 --> 00:59:21,600
interesting one. And I was wondering if we think of a hypothetical new generation in a

545
00:59:21,600 --> 00:59:28,000
utopian society that is not a generation of knowers. So a generation that's been raised on

546
00:59:28,000 --> 00:59:33,680
knowing stuff, knowing things, but a generation of thinkers, I think we've skirted around and

547
00:59:33,680 --> 00:59:38,160
we've addressed as well some of the real benefits of that, you know, a generation of thinkers,

548
00:59:38,160 --> 00:59:42,560
but I just wanted to red team for a second and think of what are some of the challenges

549
00:59:43,200 --> 00:59:48,480
of having a generation of thinkers, because the instruments we have at our disposal

550
00:59:49,920 --> 00:59:54,240
aren't geared towards a generation of thinkers. And I was just really interested to

551
00:59:54,240 --> 00:59:59,360
get the kind of red team assessment of a generation of thinkers and how that might

552
01:00:00,480 --> 01:00:08,880
what a diagnosis of that. That's interesting. I mean, there's a long so I've read a lot of the

553
01:00:08,880 --> 01:00:14,480
history of education, you know, and, and some histories of education are triumphant, especially

554
01:00:14,480 --> 01:00:21,120
about the American education system that, you know, we were made into a society of thinkers

555
01:00:21,120 --> 01:00:27,680
and etc. Then you get other people like John Taylor Gatto, and like Jonathan Cozel and others,

556
01:00:28,400 --> 01:00:33,440
even Chomsky and some foods, who would look at the American public education system as basically

557
01:00:33,440 --> 01:00:39,840
doing the opposite. And so the argument there, you know, and even goes to the Dowdy Ching,

558
01:00:39,840 --> 01:00:45,440
right, keep the people's bellies full, but their minds empty. I think that's how you govern

559
01:00:45,760 --> 01:00:52,480
it by precisely not really educating. And I'm not saying that that view is true. I'm saying

560
01:00:52,480 --> 01:00:59,200
there's enough people writing that history to suggest that at least one of the kind of like

561
01:01:00,160 --> 01:01:06,480
functions of the educational system as we have known it is to simplify the range of diversity

562
01:01:06,480 --> 01:01:11,600
of thought in the populace, right? Like, you can think about preparing them for the workforce,

563
01:01:11,680 --> 01:01:16,000
you can think about preparing them to be consumers, but you need to basically be able to predict

564
01:01:17,280 --> 01:01:21,120
what people are going to think. And part of that is to weave the culture together.

565
01:01:21,840 --> 01:01:27,680
But part of that is to simplify the human side of the equation. And so it started

566
01:01:27,680 --> 01:01:32,480
to happen with the internet, and it continues to happen, although the marketers have figured out

567
01:01:32,480 --> 01:01:38,560
how to do a standardized differentiation. Instead of like the early modern one size fits all

568
01:01:38,560 --> 01:01:43,040
homogenization, now we have the late modern or postmodern standardized differentiation,

569
01:01:43,040 --> 01:01:46,400
where there's two dozen advertising groups that think you're unique, but you're not.

570
01:01:47,280 --> 01:01:55,040
So they figured that out. But it's still the case that if you promote a culture of learning,

571
01:01:55,040 --> 01:02:02,080
and you promote a culture not of ingesting and regurgitating, or in a culture of knowing and

572
01:02:02,080 --> 01:02:08,160
knowing and resisting change of thought, but a culture where people are truly interested

573
01:02:08,160 --> 01:02:14,160
in learning and thinking, then you better have a culture that's ready to have truly an open society

574
01:02:14,160 --> 01:02:19,360
for governance and decision making, and an economic system that has true transparency

575
01:02:19,360 --> 01:02:23,840
and visibility around commodity supply chains, and ethical responsibilities of corporations,

576
01:02:23,840 --> 01:02:29,280
and the society that got transparency around law enforcement, and the criminal justice system.

577
01:02:29,280 --> 01:02:35,120
There's a whole bunch of stuff that you can kind of keep a mess, like not in good order,

578
01:02:35,120 --> 01:02:39,680
if you've got a society of folks who really aren't equipped to be paying attention,

579
01:02:40,640 --> 01:02:44,960
but if you equip people to pay attention, then they're going to start paying attention.

580
01:02:45,840 --> 01:02:49,120
And so that's part of the arguments that have been unfolding for such a long time

581
01:02:50,400 --> 01:02:57,280
around this kind of negative view of education, that there's been a manufacturing of consent,

582
01:02:57,280 --> 01:03:05,920
and kind of an arrangement of selective inattention, which is like a psychological defense mechanism,

583
01:03:05,920 --> 01:03:10,720
right? So if I'm a neurotic person, and let's say I'm just not very nice to the people who

584
01:03:10,720 --> 01:03:16,080
look close to me, I will selectively not attend to those behaviors, which disconfirm my view of

585
01:03:16,080 --> 01:03:19,520
myself as being a good person. And so I'm so frustrating to be with someone who has these

586
01:03:19,520 --> 01:03:24,080
neuroses, because it's so clear that you're doing this, that you can't see, because you're

587
01:03:24,080 --> 01:03:28,320
defending yourself. It's a defense mechanism, selective inattention. And so similarly at the

588
01:03:28,320 --> 01:03:37,200
cultural level, we're taught not to think about certain things. We're taught to studiously ignore

589
01:03:37,840 --> 01:03:44,480
certain ways of framing problems. Selective inattention is part of the education system.

590
01:03:44,480 --> 01:03:48,560
So if we start to remove those defense mechanisms, that's what you're talking about,

591
01:03:48,560 --> 01:03:50,960
which is what you want to do in psychotherapy, but when that happens,

592
01:03:51,200 --> 01:03:57,760
you know, you get a divorce, you change your job, like you move, like start having crazy dreams,

593
01:03:57,760 --> 01:04:02,960
like your whole life changes, right? And so this is what we need. We need some kind

594
01:04:02,960 --> 01:04:07,840
of cultural renaissance, if we need the equivalent of a midlife crisis or a resolution of the

595
01:04:07,840 --> 01:04:13,920
adolescent identity crisis for the whole culture. But it will be, there'll be a reckoning,

596
01:04:14,480 --> 01:04:21,440
there'll be a reckoning. And so that kind of has to happen. So that would be the downside,

597
01:04:21,440 --> 01:04:27,360
it would be the reckoning, and that you can't predict what will happen,

598
01:04:28,240 --> 01:04:32,640
in the way you can predict what will happen when you're systematically nudging everybody into

599
01:04:32,640 --> 01:04:37,280
particular groups and then predicting what those groups will be, which is what's happening now.

600
01:04:38,160 --> 01:04:47,440
Yeah, that question, what am I studiously ignoring? Maybe that's one to open up a seminar with.

601
01:04:49,440 --> 01:04:55,680
So we're rolling, I think, to the close, that so much more we could discuss. I hope we might be

602
01:04:55,680 --> 01:05:00,880
able to continue this conversation at some time down the road. But I'd like to hand over to Zoe

603
01:05:01,600 --> 01:05:08,480
to lead us out. So I think my questions are still very much percolating in my mind.

604
01:05:08,480 --> 01:05:14,080
So if I'm not as coherent or eloquent as the rest of you, I apologize. So we've kind of talked

605
01:05:14,080 --> 01:05:21,200
about a society or like a generation of thinkers and knowers. But I'm also quite interested in

606
01:05:21,200 --> 01:05:27,520
pulling on what you mentioned about the power through love. And so thinking about generations

607
01:05:27,520 --> 01:05:33,600
of feelers, because I feel like, I mean, even in generations of people or like relatives, cousins,

608
01:05:33,600 --> 01:05:38,800
and whatnot younger than myself, you mentioned nihilism, and it's almost like there's a competition

609
01:05:38,800 --> 01:05:44,080
to see who can care the least. And caring and feeling is seen as sort of a weakness and something

610
01:05:44,080 --> 01:05:51,040
that's that should be weeded out. So I guess my question is sort of, how do we make those younger

611
01:05:51,040 --> 01:05:55,760
generations feel cared for and loved, in a way that they're not going to reject and be like,

612
01:05:55,760 --> 01:06:00,320
oh, this is this is cringy. And I you don't understand me. So it's also into

613
01:06:00,880 --> 01:06:06,640
tying into intergenerational gap. But I guess also across, you mentioned an epistemic elite.

614
01:06:06,640 --> 01:06:13,760
And that's, in my mind, also, we are hoarding in the epistemic elites, the potential for intergenerational

615
01:06:13,760 --> 01:06:19,040
transmission of these essential human capacities. And I do, for me, anyway, I do feel like a lot of

616
01:06:19,040 --> 01:06:24,000
that will come from better handling of your emotions, and maybe de-celebritizing, actually

617
01:06:24,000 --> 01:06:28,960
caring about things and being very vocal about caring without worrying that you would be seen as,

618
01:06:29,520 --> 01:06:35,040
I don't know, vulnerable or weak or irrelevant. Sorry, if that's a bit all over the place.

619
01:06:35,040 --> 01:06:39,280
Now, that's a very profound question. I mean, the one thing you said in passing was that the

620
01:06:39,280 --> 01:06:44,720
epistemic elite were hoarding a certain command. That's a that's like a key insight that and there

621
01:06:44,720 --> 01:06:54,320
has been for a long time, a false scarcity of cognitive supply, false scarcity of cognitive

622
01:06:54,320 --> 01:07:00,560
resources, a artificially generated scarcity. And so that's important to get. And some of what has

623
01:07:00,560 --> 01:07:05,920
been made scarce are the conditions for the possibility of love. I mean, this is one of the

624
01:07:05,920 --> 01:07:11,600
main reasons in my book, I talk about these social miracles. It's really about creating a society

625
01:07:12,480 --> 01:07:18,960
where people are don't have to be courageous to love one another, right? Because like,

626
01:07:20,320 --> 01:07:27,040
if you don't love anyone, then you can't get hurt. Full stop. Like, if I love you a lot and you die,

627
01:07:27,680 --> 01:07:32,960
I'm in a lot of pain. If I love you a lot and you do something that disappoints me, I'm in a lot

628
01:07:33,520 --> 01:07:38,880
of pain. So there's a kind of defense mechanism psychologically to in a world where you can't

629
01:07:38,960 --> 01:07:43,040
predict what's going to happen to the people that you love, right? Well, you can you don't even know

630
01:07:43,040 --> 01:07:46,960
if you can get up to where you want to go to be economically or whatever, or to get the skills

631
01:07:46,960 --> 01:07:55,920
you want to have the self understand, like, because of the sense of precarity that many people feel.

632
01:07:57,120 --> 01:08:01,600
There is a and most of that I believe is economic and politically generated.

633
01:08:01,840 --> 01:08:09,680
There is a there's a tendency, yes, to withdraw into the isolated atomized individual and take a

634
01:08:09,680 --> 01:08:15,120
cynical view towards anything that would deepen connection and love because of the risk that's

635
01:08:15,120 --> 01:08:21,680
there. So one of the things the elders can do is actually demonstrate the courage that it takes

636
01:08:21,680 --> 01:08:28,480
to love in a world that's well, in a world that in an unworlded world, if I can say that,

637
01:08:29,040 --> 01:08:34,160
in a time between worlds, right? And it's when you're in a world it's easier to love because you

638
01:08:34,160 --> 01:08:39,840
can say, oh, here's how the world works. It's safe to love you because I've got this many years

639
01:08:39,840 --> 01:08:44,960
before my life is disrupted or whatever, right? But right now, there's this danger. So we need

640
01:08:44,960 --> 01:08:52,720
to do the opposite. And and and so the I do not like the phrase emotional intelligence. So I talk

641
01:08:52,720 --> 01:08:59,360
about like emotional self regulation and emotional self awareness and the languages of emotional

642
01:08:59,360 --> 01:09:06,080
self description and emotional connection. And these are as essential, if not more essential,

643
01:09:06,080 --> 01:09:11,120
and especially to notions of ethical identity. So right, if you think about the situation we're

644
01:09:11,120 --> 01:09:17,920
going to end up in, as the wheels start to come off, I talk a lot about, you know, that parable

645
01:09:17,920 --> 01:09:25,520
of the Good Samaritan, like what do you do when you meet someone a stranger on the road between

646
01:09:25,520 --> 01:09:30,240
civilizations, which means you're not beholden to the law of either of those civilizations or on the

647
01:09:30,240 --> 01:09:35,040
road or in the wilderness, there's no cops going to show up, right? No one's going to come and tell

648
01:09:35,040 --> 01:09:41,120
you you disobey the laws of the city, you're just a stranger in need on the road, just you and him.

649
01:09:41,680 --> 01:09:48,080
And in the Bible, God, what do you do, right? We're going to be confronted with that kind of

650
01:09:48,080 --> 01:09:54,320
situation, where we're meeting strangers on the road, and sometimes with those strangers that we

651
01:09:54,320 --> 01:10:02,560
numerous. And it's not a it's not a cognitive question. It's not a calculation or a game

652
01:10:02,560 --> 01:10:08,240
theoretic relationship that needs to be taken up. It's a problem of feeling. That's a problem of

653
01:10:08,240 --> 01:10:16,560
the human heart and the ability of the human to see another human as a human. And so, yeah, those

654
01:10:16,560 --> 01:10:24,080
are the deeper, the deeper kind of strata of the personality, which are also in play right now. So

655
01:10:24,080 --> 01:10:30,320
I'm glad you raised that. And, you know, the approaches that I've seen in this area, social

656
01:10:30,320 --> 01:10:35,760
emotional skills, mindfulness, education and things like those nature are good and important.

657
01:10:36,560 --> 01:10:42,640
But again, to speak to them kind of psychotherapeutic context, we're going to need to learn how to

658
01:10:42,640 --> 01:10:51,280
process intense emotion to not just to be calm, but to figure out how to deal with grief, sorrow,

659
01:10:51,920 --> 01:10:58,640
tragedy, righteous anger, there's a whole bunch of stuff that we need to be able to work with,

660
01:10:59,360 --> 01:11:05,360
aside from just like staying calm and I meditate a lot. But the point is that you need to be able to

661
01:11:05,600 --> 01:11:11,120
to move emotion through you in a complex way. So, yeah, so that's a whole other,

662
01:11:11,920 --> 01:11:17,040
whole other, you open to giant can of emotional worms there, but it's an important one. And I

663
01:11:17,040 --> 01:11:22,560
can't see a way out of it without. And again, I've listed in my book, I can't remember which page,

664
01:11:22,560 --> 01:11:30,800
but it's post-conventional ethics, but also like, you know, these really, really,

665
01:11:31,440 --> 01:11:36,480
robust forms of emotional self-regulation and emotional self-understanding,

666
01:11:36,480 --> 01:11:42,800
which allow for actual real empathy. So, yeah, thank you for, for bringing that up.

667
01:11:44,240 --> 01:11:48,320
Well, thank you for such a comprehensive answer and just a really thought-provoking conversation.

668
01:11:48,320 --> 01:11:52,640
It just stirred a lot of things in my mind and I'm sure I'll, I'll go in,

669
01:11:53,200 --> 01:11:57,280
tell my mumble about it because I feel like she's very much, she's very much on the emotional

670
01:11:57,280 --> 01:12:00,960
spectrum of things with, with me as so, so yeah, thank you very much.

671
01:12:02,400 --> 01:12:06,160
Yeah, I'd like to echo that. Thanks so much for that. It's really a, kind of,

672
01:12:06,160 --> 01:12:12,480
a very grounded, profound heartfelt conversation. We really appreciate it. And, you know, end on

673
01:12:12,480 --> 01:12:18,880
that note that this is also a problem of feeling or of emotion. There is this tendency, I know,

674
01:12:18,880 --> 01:12:23,680
well, to slide into kind of a full sense of objective detachment from these questions.

675
01:12:24,080 --> 01:12:30,240
And, of course, as complexity science reminds us, there is actually no view from nowhere.

676
01:12:31,120 --> 01:12:38,880
So, also, perhaps just to, just to end as to where we might go next in future conversations.

677
01:12:38,880 --> 01:12:43,600
There clearly are insights and lessons to be drawn from other cultures here and what you

678
01:12:43,600 --> 01:12:50,080
just reflected remind me a bit of Martin Prechtel's work, the Guatemalan spiritual teacher and his

679
01:12:50,080 --> 01:12:57,120
impression of Western culture as drowning in kind of atomistic alienation. So, I think lots more

680
01:12:57,120 --> 01:13:04,720
to explore there. And, yeah, there's a beautiful way to end this conversation on, on education

681
01:13:04,720 --> 01:13:11,600
as, as the core challenge of our time. So, thank you. And look forward to picking this up again.

682
01:13:12,880 --> 01:13:14,320
Thank you guys. This was a blast.

683
01:13:14,960 --> 01:13:24,080
Thanks for tuning into Global Governance Futures. To get access to all of our content

684
01:13:24,080 --> 01:13:29,840
and to stay up to date with future Zoom calls, workshops and events and more,

685
01:13:29,840 --> 01:13:40,080
check us out at ucl.ac.uk forward slash global dash governance. And if you like this content,

686
01:13:40,080 --> 01:13:48,800
please do leave us a comment and subscribe. Until next time.

