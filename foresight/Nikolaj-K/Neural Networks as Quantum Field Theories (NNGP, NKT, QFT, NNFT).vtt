WEBVTT

00:00.000 --> 00:07.760
Hello boys and girls. In this video I want to talk about the line of research that I

00:07.760 --> 00:17.600
only came across last week, namely the very strong connection between quantum fields and

00:17.600 --> 00:27.800
neural network theory. And what emerges from that is tools from one field being applicable

00:27.800 --> 00:34.520
to the other. So you can then use let's say Feynman diagrams to find stuff out about

00:34.520 --> 00:40.960
neural networks. And in the other way around you can use neural networks to compute stuff

00:40.960 --> 00:49.280
for quantum fields. I think the most senior researcher, if I'm not mistaken from this

00:49.280 --> 00:58.200
list of this paper in particular is James Harvorsson. And if you look it up there have

00:58.200 --> 01:08.160
been a few papers in this direction in the last years. And nonetheless I chose this particular

01:08.160 --> 01:16.800
paper because it's clearly some of the more advanced results there. And to motivate how

01:16.800 --> 01:26.280
things work, I'm also in this video going to explain some results which were known for longer

01:26.280 --> 01:33.280
time. So there I suppose it's fair to say that this sort of stochastic result for large neural

01:33.280 --> 01:40.840
networks that we are going to discuss emerge in the mid 90s. And I'm going to explain this because

01:41.800 --> 01:52.680
I want these subjects which I find very exciting actually to be known also a little better. In

01:52.680 --> 01:58.600
this video however I will not go into any deep mathematical analysis. I have also not written

01:58.600 --> 02:09.080
down much. I will basically jump from tab to tab. And nonetheless give a sensible explanation of

02:09.080 --> 02:14.200
these things. So I think everything that I say should make sense in principle. And then you can

02:14.200 --> 02:20.520
delve into all the subjects on your own. If you're actually interested in doing something in this

02:20.520 --> 02:29.800
direction let me know in the comments. I will also point to some Google libraries regarding neural

02:30.040 --> 02:37.880
kernel theory that I will also sketch out in this video. And yeah so that's that.

02:39.320 --> 02:44.360
The requirements for the video are that you have like a basic understanding of deep neural networks

02:44.360 --> 02:52.520
like the fact that these neural networks encode the parameterization of certain functions. And then

02:52.520 --> 02:57.000
if you have a big enough network stuff like universal approximation theorem the fact that

02:57.000 --> 03:04.520
you basically can represent functions in the space let's say continuous functions densely.

03:05.080 --> 03:12.600
And it helps if you have a basic understanding about the ideas of quantum mechanics. So the

03:12.600 --> 03:20.120
fact that what you're interested in is transition probabilities and that they are expressed as some

03:20.120 --> 03:30.920
products in a Hilbert space. In this video I have a section where I motivate the jump from the

03:30.920 --> 03:37.720
expressions that we are going to be able to compute with neural networks as they are explained in

03:37.720 --> 03:46.200
this paper. Let me scroll down a second. How these expressions connect to scattering amplitudes in

03:46.200 --> 03:54.440
let's say some large hydrogen collider experiments. These sort of stuff so I have a small like wake

03:56.280 --> 04:03.800
mafia section that concerns physics. But my main goal is that if you go away from this video

04:03.800 --> 04:09.240
and have a vague understanding why these sort of expressions that you see on the screen right now

04:09.240 --> 04:16.120
are both relevant for neural network theory and for quantum field theory then my job is done.

04:16.840 --> 04:24.040
As I said this gives the possibility not just to compute stuff in physics but for example

04:24.040 --> 04:33.880
you might then be able to apply Feynman diagram calculus to compute various aspects of neural

04:33.880 --> 04:39.560
networks as well and so even if you edit from a purely computer science perspective

04:40.440 --> 04:46.040
and have some statistics background then this might be fairly helpful.

04:47.320 --> 04:55.800
Okay so I have here just a bunch of bullet points that I want to go through. I might come back to

04:56.600 --> 05:03.800
this from time to time otherwise I will just jump through like here 15 tabs or so and explain some

05:03.960 --> 05:13.080
results. I am actually currently working on or started working on a video that I maybe want to

05:13.800 --> 05:23.240
make as my some for summer video where I will do like a painful analysis of the universal

05:23.240 --> 05:28.440
approximation theorem. But that's like months and months out. In this video I'm basically just

05:28.440 --> 05:38.280
rambling. I hope you don't expect to neither deep or concise elaboration so I'm warning you already

05:38.280 --> 05:49.240
but nonetheless I would really recommend that you listen up. Okay so first off as you have just

05:49.240 --> 05:59.960
seen in the bullet points I will explain to you like sketch out this result from the 90s which

05:59.960 --> 06:06.680
concerns neural network Gaussian processes. So there are nice results that have been found there

06:06.680 --> 06:13.480
and have since been extended to a broad range of neural network architectures. So this is

06:13.560 --> 06:20.200
mathematical theory results for neural networks that hold in general. In this video for simplicity

06:20.200 --> 06:27.240
we can just look at fully connected in the sense that you see in the screen here feed

06:28.040 --> 06:35.320
forward neural networks and for this video it's not even super relevant how many inputs

06:35.320 --> 06:41.400
outputs you have. Basically you have let's say at least one input some float or if you want a real

06:41.400 --> 06:49.080
number x that goes in one real number y that goes out and in the middle you have a bunch of

06:49.080 --> 06:54.920
hidden layers in the image you just see one but you know for the sake of it you might think of two

06:54.920 --> 07:04.520
three four something like that and you see the nodes in this one hidden layer here and the

07:04.520 --> 07:10.520
theory that we are going to discuss kicks in once you have a really big network. So this

07:11.880 --> 07:19.320
you think of the number of nodes in each hidden layer here going to infinity or you know it will

07:19.320 --> 07:27.160
suffice if you think of a huge number a bunch of billions of billions and the thing that then

07:27.160 --> 07:35.000
emerges with large networks is not just the universal approximation theorem that says

07:35.560 --> 07:41.560
the the nice functions let's say continuous functions from r to r are represented densely

07:41.560 --> 07:51.800
by this sort of neural network by these weights but what also emerges in this large network limit

07:51.800 --> 08:05.400
is that the dependency of the output for fixed input and probabilistic weights

08:06.920 --> 08:12.520
takes on a very deterministic character okay so this is this neural network Gaussian process

08:12.520 --> 08:18.280
phenomenon and then I will explain in a second in more detail but basically what we want to

08:18.280 --> 08:24.520
hear first look at is we take one fixed architecture some big neural network with let's say three

08:24.520 --> 08:32.120
hidden layers and all the layers are very large and what we're here are first concerned with

08:32.120 --> 08:37.640
before we talk about tangent kernels before we talk about quantum field theory is we few

08:39.400 --> 08:45.000
we're concerned with the random initialization of these networks right so let's say you are on a

08:45.000 --> 08:56.520
computer you you have this network encoded on your GPU or whatever and or then the weights really

08:56.520 --> 09:04.760
I mean the you have the architecture laid out the way in which all the the the float data

09:05.720 --> 09:14.680
pass to each other naturally if you have this this float types in every realized configuration

09:14.760 --> 09:22.600
the weights have to have some some value and this gives the start configuration for the

09:22.600 --> 09:28.600
learning process right in the learning process you're going to probably assign some some

09:29.400 --> 09:34.840
loss function and you do gradient descent and then you tweak the network to behave in a certain

09:34.840 --> 09:42.120
nice way and fulfill some task but to start this process you need to initialize the network you

09:42.280 --> 09:49.320
want to maybe explicitly set some weights okay and now what you can do is you can play around with

09:49.320 --> 09:55.320
what is actually your starting condition right you can say hey shoot all the weights in the beginning

09:55.320 --> 10:03.480
be set to zero or be set to one or and this is the interesting thing here you do a random

10:03.480 --> 10:12.280
initialization of all the weights and biases also so think of you know you're in python you

10:12.840 --> 10:17.960
take a library and you sample from a normal distribution for all the

10:19.720 --> 10:26.440
trillion weights you sample trillion random numbers and you sample them each from a Gaussian

10:27.240 --> 10:36.040
from a bell curve and then set the corresponding weights like this okay so all these w i j are

10:36.040 --> 10:45.080
sampled from some from some Gaussian and when you like put in some input right we said there's one

10:45.080 --> 10:55.800
input let's say you you take the input seven and set x to seven and then feed do the feed forward

10:55.800 --> 11:03.240
process the evaluation of the neural network then if these things are random then the output will

11:03.240 --> 11:09.400
also be some essentially random number it will be determined for whatever random weight you have

11:09.400 --> 11:18.600
sampled here and in this way you can think of y for fixed x as a random variable composed of the

11:18.600 --> 11:28.760
random variables w right so we have here's the neural network Gaussian process page the math

11:28.760 --> 11:34.600
and the proof sketch of this result that we are going to get to is actually described there so the

11:34.600 --> 11:41.400
weights are sampled from some Gaussian we are going to take a Gaussian where the standard deviation

11:42.280 --> 11:47.080
gets tighter and tighter with the number of layers right but if you have a fixed network this is some

11:47.080 --> 11:58.360
fixed variance here and the output that is in a standard way computed from neural network is

11:59.080 --> 12:08.920
um computed as you see here you do fast forward and I think it's fairly easy to believe that just

12:08.920 --> 12:14.440
due to the central limit theorem right the statement that if you have a bunch of independent

12:16.280 --> 12:23.480
random variables if you sum them all up then this is another random variable that will behave

12:23.480 --> 12:30.040
like a Gaussian process right so basically if you sum up random numbers then you usually end up with

12:31.720 --> 12:35.240
if all the conditions are fulfilled all the mathematical conditions then you will end up

12:35.240 --> 12:39.480
with a Gaussian this is the statement of the central central limit theorem and this exact

12:39.480 --> 12:44.120
thing applies here also you know maybe there's some non-linearities involved and maybe there's

12:44.120 --> 12:51.240
different steps but in the end the final output of the network here in this picture in the on the

12:51.240 --> 12:58.840
last layer this set is still a function of all these small Gaussians and because there are so many

12:58.840 --> 13:07.240
sums this is again just a Gaussian process right so and so this says that in the limit and this

13:07.240 --> 13:15.160
is especially emerges if you have enough width if the width is big enough so that the central

13:15.160 --> 13:21.400
limit theorem really kicks in but this basically means that the as a random field as a random

13:21.400 --> 13:28.040
variable the output of the neural network has very nice stochastic process properties and it's

13:28.040 --> 13:34.440
it's a Gaussian process in particular one of the nicest you can have basically here on this

13:34.440 --> 13:45.160
web page on this Wikipedia page there's also like this this this example animation so here they have

13:45.720 --> 13:50.440
some network with three inputs right as I said it doesn't have to be three it suffices to think of

13:50.440 --> 13:56.520
one and they have a bunch of outputs again it suffices to think of one so one green input one

13:57.240 --> 14:07.160
yellow output and a bunch of nodes in in bunch of layers in this case two layers one layer would

14:07.160 --> 14:13.960
also work you see on the right side I mean you probably don't see just because of my face here

14:13.960 --> 14:20.680
but I mean doesn't really matter too much it's just a bunch of like random distribution the

14:20.680 --> 14:27.400
statement is that for fixed input the green value again let's say there's one green input and it's

14:27.400 --> 14:37.080
set to this the float number seven if you fix if you go up with the the number of nodes and

14:37.080 --> 14:43.400
random initialize this with weights and biases then just by the central limit theorem which is

14:44.120 --> 14:52.360
dependent on this this seven and this bunch of random numbers the output y1 here this yellow

14:52.360 --> 15:01.400
output will behave like a Gaussian just by the central limit theorem and in this case there's

15:01.400 --> 15:09.160
two outputs so you can draw a plot and the statement is then that both y1 and y2 behaving

15:09.160 --> 15:16.840
like Gaussians independently from another like it's not a statistic statement but each behave

15:16.840 --> 15:23.800
like a like a Gaussian they have some peak and so on the plot you get another nice Gaussian with

15:23.800 --> 15:34.280
some peak here and so if then the press play again if the network becomes even bigger then you get

15:34.280 --> 15:42.200
like this perfect Gaussian where it this just says that it has this maximum expected value here in

15:42.200 --> 15:50.520
the middle and this goes for all the outputs right so this is the result that that that

15:53.640 --> 16:01.560
the okay I closed the neural network Gaussian process page but doesn't matter this is the result

16:01.560 --> 16:09.160
that just because of statistics you the network if it's large enough at random initialization

16:09.160 --> 16:17.240
behaves like a Gaussian we will not need it for the this video but if you want to take a look

16:17.240 --> 16:22.120
this is the the formal definition of a Gaussian Gaussian process I mean to motivate this basically

16:22.120 --> 16:26.440
you think you know a Gaussian is something which if you do the Fourier transform it's again like

16:26.440 --> 16:33.560
a Gaussian and the Gaussian process is abstractly defined as this random variable or sequence of

16:33.560 --> 16:38.760
random variables where the characteristic function the expectation value of this phase

16:39.480 --> 16:46.760
is this Gaussian with a certain mean we are not going to need this the Fourier transform will

16:46.760 --> 16:54.840
pop up again when I talk about the quantum field theories but suffice to say the nice thing is

16:54.840 --> 17:01.160
that the neural network the big neural networks behave like Gaussian processes sorry if I repeat

17:01.160 --> 17:11.960
myself okay so do we do physics first or do we do neural tangent kernels first

17:12.440 --> 17:21.400
um let me actually um yeah let me actually say something about

17:23.080 --> 17:31.320
the neural tangent kernel so um could we know now that the the network at the start behaves

17:31.320 --> 17:37.480
like this Gaussian for all inputs and if you do the learning process then this is about

17:37.880 --> 17:48.440
um giving it a test data and then moving um in parameter space from wherever we random started

17:49.000 --> 17:56.440
to some other position in in weight space and I have made a bunch of videos on gradient descent

17:56.440 --> 18:02.760
I will not explain it here but suffice to say you have a space of weights and then the the weights

18:02.760 --> 18:09.000
follow some path and you do that in a way that optimizes some goal that you have right some

18:09.000 --> 18:23.640
task for the neural network and I think I sketched it out here so as is common we're dealing with

18:23.640 --> 18:28.600
not only here with a large neural network so that the the theory becomes simpler and nicer

18:28.600 --> 18:34.040
but also we are matching we have so much compute that we can do really small step sizes

18:34.040 --> 18:40.040
so that we can then in the limit talk of the behavior of the network as in a differentiable

18:40.040 --> 18:51.400
way where we say the the the motion of the in path space in a parameter space can be described

18:51.400 --> 18:59.480
you know with literally just calculus differentials and so the gradient descent algorithm what we are

18:59.480 --> 19:06.200
doing really is um you know as per instruction of the algorithm we say the change of the weights

19:06.200 --> 19:11.960
and here I abbreviate all the weights together with this uh theta the the change in the weights

19:11.960 --> 19:17.720
right from from one point to the next in the graphic that you just saw um is chosen in a way

19:17.720 --> 19:27.960
that it takes the negative direction of the gradient of some cost function and the cost

19:27.960 --> 19:35.400
function in here is the you know the the difference essentially between what the neural network

19:35.400 --> 19:42.520
currently says versus where we want to get at where set is all the learning data that we have

19:42.520 --> 19:49.000
available right so we say for all the learning data that we that we have um there is a discrepancy

19:49.000 --> 19:56.840
between what the network f currently um says um what's correct and what is actually correct

19:57.400 --> 20:04.200
why I said here is what's actually correct um and we send that up and so this is like the the this

20:05.240 --> 20:10.760
cost of all learning data together and at every step in time in the learning process

20:11.480 --> 20:18.680
we go follow this path right and this equation is really just the Newtonian equation um where

20:19.880 --> 20:24.360
you know in in physics um theta would be the momentum

20:28.520 --> 20:35.400
and where you um look at the situation where the force on the right hand side is governed by a

20:35.400 --> 20:46.360
potential and you'll say um the the direction of motion um captured by the momentum is given

20:46.360 --> 20:52.120
wherever the you know potential energy will be lowest and that's where the path followed by

20:52.120 --> 21:00.120
the particle in Newtonian physics right so this already looks very um like like this simple physics

21:01.080 --> 21:07.480
uh equation governing governing the motion in weight space and now given that you have

21:08.040 --> 21:14.120
the behavior of the um the the particle if you will uh going through weight space like

21:14.120 --> 21:22.360
and give you just saw um and the the potential depends on the outputs at the network on all

21:22.360 --> 21:28.360
these spaces you can also then um do the calculus and and look at hey how does the output of the

21:28.360 --> 21:34.680
network which depends on the position where you are at right where the weights determine what the

21:34.680 --> 21:40.440
network output will be on all the um learning data how does that the f change and so if you

21:40.440 --> 21:50.440
do them just do the math um and I think I have this is here so this is um newer tangent kernel

21:50.520 --> 21:53.400
theory um if you

21:59.960 --> 22:05.240
if you do this sort of calculation and if you uh you know if you ever started physics you have to

22:05.240 --> 22:10.440
this this sort of calculation a million times because basically if you have some observable

22:10.440 --> 22:16.120
in a physical system and you know all the the constituents of the particles behave in this

22:16.120 --> 22:20.200
isn't this way and then I have some observable which is made out of particles and you say how

22:20.200 --> 22:26.760
does this this observable quantity change then um you have to plug in a bunch of partial derivatives

22:26.760 --> 22:31.640
and then the Hamiltonian comes in and whatever and so on and so forth what comes out of this

22:31.640 --> 22:40.520
is that the development of the output of the neural network um is governed by some matrix

22:40.520 --> 22:52.040
this is the so-called newer tangent kernel and the changes of uh the the loss in uh with respect

22:52.040 --> 22:58.760
to the to the weights right so I mean I did not adopt this terminology theta is again all the weights

22:58.760 --> 23:10.120
together and um you can do this calculation on one sheet of paper yourself I'm not going to discuss

23:10.120 --> 23:17.240
all the the convention or a notation chosen here but the point is that the evolution of the output

23:17.240 --> 23:24.040
on a network from your starting point which might be a random starting point is understood at least

23:24.040 --> 23:28.840
here in theory it's another question of whether you can actually calculate that because this matrix

23:28.840 --> 23:35.080
which determines how this the output of the network evolves as you do the learning according

23:35.080 --> 23:40.840
to gradient descent is determined by this complicated object theta and the theta is basically

23:42.040 --> 23:50.840
this so-called kernel um this is you can view this as the inner product of the gradient of the

23:50.840 --> 23:55.640
output with research with respect to the weight change and so the interpretation is basically

23:56.360 --> 24:07.560
that um you look at uh different inputs and then you um you as a kernel a kernel roughly

24:07.560 --> 24:14.360
charges how similar input data are and this kernel basically looks at uh hey these two

24:14.360 --> 24:22.280
input data are similar if upon a change of the weights the um the response of the network changes

24:22.280 --> 24:27.880
in a similar fashion and you compute this it's in a product in any case this is like an interesting

24:27.880 --> 24:37.080
object that in the end determines how the network behaves um and similar to neural network Gaussian

24:37.080 --> 24:46.920
process theory where you say once I have enough um uh weights in my layer some nice theory emerges

24:46.920 --> 24:53.320
right in in the Gaussian network case it goes towards a Gaussian it's also the case that

24:54.040 --> 25:01.160
for a large network then these these matrix can simplify and then you can get the infinite

25:02.200 --> 25:07.720
size network also to an analytical theory and basically you random initialize you already

25:07.720 --> 25:14.520
know it's some Gaussian process and then you have some matrix which determines how the network moves

25:15.240 --> 25:22.920
um through through weight space and thereby you you have an idea of actually what happens

25:22.920 --> 25:28.360
during network to network training right so if you have never heard that and more or less followed

25:28.360 --> 25:35.640
my explanation then you can see this is kind of cool that at least in this limits you have

25:36.200 --> 25:42.920
sort of an analytical idea what happens during learning and then the question is to what extent

25:43.240 --> 25:50.920
is this sort of logic valid for networks as we can implement them at the moment at the moment

25:50.920 --> 25:56.200
because of course we have a lot of weights like billions of weights but it's not infinite so

25:56.840 --> 26:01.720
you might ask to what extent is the analytical theory where these limits are taken right so

26:02.600 --> 26:10.920
super small step size very large networks applicable to today's convolutional deep neural

26:10.920 --> 26:16.920
networks and so on and so forth and this is basically a subject of study so this is something

26:16.920 --> 26:26.440
where people still put a lot of time in and so for example you have here this google uh neural

26:26.440 --> 26:36.440
tangents project which i might be interested in looking at and there's a bunch of google researchers

26:36.440 --> 26:41.640
who are still using this and publishing papers in this and and so on and so forth there's also

26:42.520 --> 26:53.400
i think a recent um new rips uh poster from 2019 where you get some of the examples of

26:53.400 --> 26:58.360
analytical formulas that i talked about um just because i want to get to the quantum

26:58.360 --> 27:05.480
field theory part i will not discuss this in detail but i um i hope my tangent pun intended

27:06.920 --> 27:11.480
was interesting and as i said i would also actually like to to work a little bit in

27:11.480 --> 27:16.680
this direction myself so if you want to look into that um feel free to reach out and we can

27:16.680 --> 27:31.000
do some sort of project together okay so um now for the the the field theory part

27:36.440 --> 27:42.920
but still extremely important for us is this neural network Gaussian process inside okay

27:43.640 --> 27:47.160
and if i'm here in the paper on page four

27:50.280 --> 27:55.800
then um let's make first some definitions okay so here we have these correlation functions

27:56.520 --> 28:03.880
which we call g n uh for uh for a concreteness sake you can think of n uh let's say as two

28:03.880 --> 28:12.520
so um we are going to actually look at um two different um forward passes for the neural network

28:12.520 --> 28:19.320
right so you have two different imports that you want to try x and you plug them in and you

28:19.320 --> 28:28.200
get something out of your current network which might be randomly initialized um and if you

28:29.560 --> 28:36.680
as we had it with the neural network Gaussian process case if you your weights as a random

28:36.680 --> 28:43.240
variable right over all the weights over all your trillion weights you put a little Gaussian and let

28:43.240 --> 28:53.160
them wiggle a little bit um and you say what typically happens if i sample once and um

28:55.400 --> 29:05.000
put into uh inputs x uh how are the inputs on a on a typical or random network correlated with

29:05.000 --> 29:12.360
each other then you can you can try this a bunch of times and get an idea um what you can also do is

29:14.040 --> 29:17.080
analytically if you know the distribution of where your weights

29:17.800 --> 29:22.600
compute what what will come out right so you have here uh p over the weights this is the

29:22.600 --> 29:27.960
distribution that you yourself chose from which you can sample and uh for fixed neural network

29:27.960 --> 29:38.840
architecture um the weights and um the neural network um which um is here called phi this is the

29:40.680 --> 29:47.080
function that depends on the weights depending on your architecture right so this is the sigmoids

29:47.080 --> 29:54.520
and this sum and so on and so forth and so the correlation function gives you how this how

29:54.520 --> 30:02.120
let's say two inputs are um correlated with each other for this network right and by the neural

30:02.120 --> 30:13.240
network Gaussian process result if we said that uh this this billion uh probability distribution over

30:13.240 --> 30:20.360
the weights um make the input output relation of the whole network also into a random variable

30:20.360 --> 30:27.880
right so you can also view uh this the setup that you have here not as um as um

30:29.720 --> 30:36.840
not just a sampling um the weights and getting uh then a fixed input output but you can also

30:36.840 --> 30:42.440
view any sample process as sampling a whole neural network right even this is just what

30:42.440 --> 30:48.280
you do if you sample if you random initialize for fixed architecture um the um

30:50.760 --> 30:55.320
certain uh functions as your certain neural network then you've also sampled the neural

30:55.320 --> 31:01.480
network from who knows what distribution right so there's also this different the different

31:01.480 --> 31:10.520
view of this initialization process and then um by the result of the neural network Gaussian process

31:10.520 --> 31:16.920
what you have is that you can also view the same uh exact object this correlation function or any

31:17.000 --> 31:25.720
expectation value really um as in terms of distribution over the these functions themselves

31:25.720 --> 31:30.520
and by the result that we just had for a large network this will be a Gaussian process and this

31:30.520 --> 31:37.240
manifests in this way right so um here is the integral not over the weights but over the um the

31:38.200 --> 31:48.920
uh whole function that the network represents itself and um the the um probability distribution

31:48.920 --> 31:59.160
that you have in this case is um of of this sort where this s uh and now this relates back to the

31:59.160 --> 32:06.440
formal definition of the Gaussian process is some quadratic let's say let me fill some local terms

32:08.200 --> 32:14.760
cost associated with the whole um with the whole function so basically what what this does I mean

32:14.760 --> 32:18.200
do they give here some examples I think they do um

32:22.920 --> 32:29.320
okay so this is already sort of a physical example but what you have as s here in the the exponent

32:29.400 --> 32:37.240
is some sum over all uh the values of the network and what what they like what in effect happens is

32:37.240 --> 32:50.680
that um the um the the this this weight is such that um field configurations and when I say field

32:50.680 --> 32:54.760
now I always just mean the same as the input output relation not given by the neural network

32:55.400 --> 33:03.800
field configurations or neural networks where at one uh places you get a huge output these are just

33:03.800 --> 33:11.880
exponentially suppressed because um if you random sample from the with the weights then you are not

33:11.880 --> 33:20.840
likely to get um some basically you are going to get um neural networks in initializations

33:20.920 --> 33:27.800
which are around some some uh some certain um typical expectation value like they have there are

33:27.800 --> 33:34.840
some typical behaviors and everything that deviates uh a lot from it is like exponentially less

33:34.840 --> 33:42.360
likely right you um if you do um thousand random initialization of the neural network you will

33:42.360 --> 33:48.360
get some typical behavior and then you can cook up some other extreme behavior that is not likely

33:48.360 --> 33:56.680
to happen and um by the result of the neural network Gaussian process um theory um it tells you

33:56.680 --> 34:03.320
what the the the probability distribution looks for the neural network so there is this connection

34:03.320 --> 34:09.480
that you have here right and as I will motivate um later uh in quantum field theory this is exactly

34:09.480 --> 34:18.040
sort of the setup for the path integral and what this paper does is it um if you view um

34:18.360 --> 34:27.080
the um this this sort of um mathematical um overlap um as a physicist and you want to use

34:27.080 --> 34:34.760
neural networks as as as a physicist you you see this as a way to um then try to craft neural

34:34.760 --> 34:40.520
network architecture and sampling techniques right the the way in which you sample the weights

34:41.240 --> 34:48.440
in a way so that the this this whole process of random initialization corresponds to certain

34:48.440 --> 34:54.680
s s certain actions here right you do you have some physical scenario in mind there's physical

34:54.680 --> 35:02.040
theory that says oh you know uh certain scalar field theories have this and this action what is

35:02.040 --> 35:08.920
the way I and in which I must set up a network and the way in which I must sample the weights

35:09.480 --> 35:14.520
so that what I sample is exactly as if I would sample from a quantum field

35:14.520 --> 35:22.280
like like as if I would sample from uh would I would sample a field which is one instance of

35:23.720 --> 35:31.240
um a quantum field in the path integral formalism right and then I get out a bunch of correlation

35:31.240 --> 35:37.720
functions this endpoint functions um and these are exactly the things that are uh what what you

35:37.720 --> 35:42.600
do quantum field theory for right you you compute these g's and then I will explain it later then

35:42.600 --> 35:51.960
there's some mathematical connections to how you get from this this this g's to um the scattering

35:51.960 --> 35:57.480
amplitude or whatever your quantum field theory does um maybe particle physics solid state physics

35:57.480 --> 36:07.400
and so on and so forth okay uh let me see so as you might notice this is a very free flow

36:07.480 --> 36:19.080
sort of explanation right um so I have to check uh what I have touched upon and what I didn't

36:23.320 --> 36:27.080
okay

36:27.720 --> 36:38.200
yeah okay so um from the very complicated quantum field theory math you get some

36:38.840 --> 36:49.000
you know relations of um how the correlation function must relate to these actions and there's

36:49.000 --> 36:56.200
a bunch of stochastic differential equation mathematics involved and because in physics

36:56.200 --> 37:02.680
the evolution is always governed by some Hamiltonian operator function there's a bunch of energy

37:02.680 --> 37:09.880
terms that you have to kick around and that's why for example um these objects tend to look

37:09.880 --> 37:18.280
a little bit like this um like if you're never studied this physics um maybe one way in which

37:18.280 --> 37:23.800
you should look at this is that because the evolution of these fields like how they um

37:24.680 --> 37:33.400
have often time is governed by the Schrodinger equation which relates the time derivatives

37:34.440 --> 37:42.440
like the evolution of the fields themselves to some energy expression captured in the Hamiltonians

37:42.440 --> 37:51.880
and the the energy kinetic energy and in particular for fields is given by some spatial operators

37:51.880 --> 37:57.240
that's that's why these sort of objects pop up here and you know mass energy equivalents

37:57.240 --> 38:04.440
that's why we also have mass and so if you see these Laplacian operators or mass terms um you

38:04.440 --> 38:09.160
should not be too surprised uh there because in physics they just always pop up in relation to

38:09.160 --> 38:16.200
the time evolution of the the fields okay so okay now I've already touched upon the concept of time

38:16.200 --> 38:25.320
the thing is of course that um here this the fields as they pop up here will um be

38:28.280 --> 38:35.640
not uh like what you get there is the better controlled theory of euclidean fields right

38:35.640 --> 38:42.440
you're not you're not having to do a priori with spacetime metrics and all these things which make

38:42.440 --> 38:49.880
field theory quantum field field extra complicated but um just talking about Gaussian processes is

38:49.880 --> 38:55.000
just talking about stochastics and then there is this sort of bridge that you have to take

38:55.000 --> 39:03.240
and hope that you can get from the the euclidean field theories to um to some actual quantum field

39:03.240 --> 39:12.360
and I will just name drop um a bunch of concepts there the idea is that you uh if you approach

39:12.360 --> 39:20.920
quantum field theory with this neural network she bang then um you want to find a neural network

39:20.920 --> 39:34.120
which mimics the weak rotated version uh of um of physical quantum field and so there is um

39:35.160 --> 39:40.440
a bunch of uh so-called constructive quantum field theory coming in so there are various approaches

39:40.440 --> 39:47.240
for of people trying to um uh make certain aspects of quantum field theory more rigorous

39:47.240 --> 39:56.520
and um transfer like get rid of uh pseudo metrics in quantum field theory move everything um to the

39:56.520 --> 40:06.840
euclidean domain where you have nice metrics and um uh so in this paper for example they say that um

40:06.840 --> 40:12.600
you know what we really want to impose is um neural networks which when you view them as a field

40:12.600 --> 40:17.640
behave in a certain way and something that is important there for example are these uh

40:17.640 --> 40:25.000
Osterwald Schrader relations so for example here in this case the um correlation functions um

40:25.000 --> 40:29.960
these particular coordination functions of relevance here are called denoted s and then you see on

40:29.960 --> 40:35.320
the screen a bunch of properties that these shall have right so there you have the physical

40:35.320 --> 40:42.280
translation in variances of certain objects and certain symmetry or independence relations right

40:42.280 --> 40:48.120
i'm just mentioning this that there is uh it's not like um you just take any neural network

40:48.120 --> 40:53.720
and then you get some uh some quantum field theory in the path into word formalisms out of it

40:53.720 --> 41:01.320
there's a fairly restricted subset of uh fields that the physicists for quantum field theory might

41:01.320 --> 41:09.160
be interested in um okay but i should probably not go into too much detail on that uh here

41:09.240 --> 41:20.760
um yeah uh also the um these objects in this um exponential so sorry here um

41:22.680 --> 41:27.720
if you if you know some physics then you know this but um if you don't then just want to mention

41:27.720 --> 41:35.640
that these sort of s s um basically any s that you can write down uh gives you some field theory

41:35.640 --> 41:46.040
these s s are some sums or integrals over energy terms and if you go to um sorry for the click

41:46.680 --> 41:52.120
clickery um if you go to the Lagrangian field theory Wikipedia page then you can find

41:52.840 --> 42:00.200
a whole lot of different um s objects that make sense and you can see here see how they

42:00.200 --> 42:06.520
data mine how the data mine um the various physical theories that you have certainly heard of

42:06.520 --> 42:11.720
we are interested in particular about fields so we have here scalar field theories this is what we

42:11.720 --> 42:21.160
just saw you have some partial and then um some um some mass and there will be also be some time

42:21.160 --> 42:29.800
the derivatives there um but the thing is that the pure gaussians are um where this is just

42:29.800 --> 42:37.080
this quadratic object in in s are actually relatively um uninteresting from the physical

42:37.080 --> 42:42.680
perspective because if you have for example if you have different quantum fields that interact

42:42.680 --> 42:48.680
with each other and and then this information how they interact is also all encoded in this

42:48.680 --> 42:55.560
in this um in this Lagrangian cells or in the action s and then uh you will have some more

42:55.560 --> 43:03.320
complicated products in these objects and um if you have some power of the field that's higher than

43:03.320 --> 43:12.840
two then this is actually uh representing um sort of self interaction in in field theory so um what

43:12.840 --> 43:20.280
we really want to have is not just um the fields which fulfill these nice um properties in the

43:21.000 --> 43:26.920
Euclidean version but we also want to have very finely controlled um interaction terms

43:26.920 --> 43:36.360
there and so what we really want to have is um processes which are actually not gaussian right

43:37.320 --> 43:43.000
and so what they do in the paper is in in the end um look at

43:43.000 --> 43:54.200
uh um five to the fourth field theory so quadratic interaction let me see sorry

44:07.400 --> 44:11.320
so what they really want to implement and what they actually then do in the paper is

44:11.320 --> 44:16.760
they take this sort of action you you not only have this quadratic term there but you also have

44:17.400 --> 44:29.320
their um this five to the four uh term and to to get this in to get um uh away from the

44:29.320 --> 44:37.240
just quadratic gaussian process scenario there is two ways um to implement this self interaction

44:37.480 --> 44:45.720
uh and one way is to actually not look at the infinite and limit right not the infinite

44:47.080 --> 44:56.520
size network limit um because then uh the you basically break the neural network gaussian

44:56.520 --> 45:05.400
process scenario you you person person uh you purposely stop a little bit earlier and get some

45:05.480 --> 45:11.320
non gaussian effects and so what from the mathematical point of view is a bug that for

45:11.320 --> 45:17.240
a real network you actually don't get a perfect gaussian situation here becomes sort of feature

45:17.240 --> 45:23.640
it gives you the freedom to actually implement behavior and if you tweak the network uh nice

45:23.640 --> 45:29.160
enough the ideas that then you can sort of control how it is broken this bug certainly

45:29.240 --> 45:36.280
becomes a feature this is one way and the other way is if you um actually um

45:39.080 --> 45:45.880
in sampling you do not uh take a trillion independent distributions over the weights

45:45.880 --> 45:53.560
but what you and instead do is you introduce on purpose some dependencies of the individual

45:53.560 --> 45:59.480
weight uh distributions right do you break the independence such that um there is a little

45:59.480 --> 46:05.720
bit of a flaw in the central limit theorem and in this way by independence you also get some

46:05.720 --> 46:11.800
non gaussian process because it's clear that if you do only um break the independence of this

46:11.800 --> 46:17.640
weights a little bit you'll still by the central limit theorem get something which is just a slight

46:17.640 --> 46:23.320
deviation from discussion processes right so if you the idea is if you tweak the this

46:23.320 --> 46:28.920
the conditions for the god for the central limit theorem just in a wide way then you might produce

46:31.480 --> 46:39.000
errors to the the gaussianity in a in a in a very controlled way and this is exactly what

46:39.000 --> 46:46.680
they do here so here they describe a neural network with particular non-linearity as activations it

46:46.680 --> 46:53.800
looks like this and what they do is they sample in this um in this dependent way in exactly the

46:53.800 --> 47:05.640
correct way so that the um the action um that emerges by random sampling in this you know

47:06.440 --> 47:14.680
particular way represents uh this uh this sort of physical field theory so this field theory in

47:14.680 --> 47:20.360
particular is basically always the first interaction uh interacting field theory or one of the first

47:20.360 --> 47:25.000
interaction field theories that you would learn in the quantum field theory course um this is not

47:25.000 --> 47:35.320
one of the famous standard model um energy densities at least not in the exact same way here

47:36.280 --> 47:41.000
but nonetheless this is like classical physical theory and so this is what this paper is all

47:41.000 --> 47:48.200
about right breaking the neural network gaussian process uh theorems in the correct way to get um

47:49.480 --> 47:58.200
the the right uh g functions endpoint functions out there that are relevant for physics um and

47:58.200 --> 48:06.040
so you see that then you can you know in principle sample uh from this fixed neural network architectures

48:06.040 --> 48:12.920
fields and then once you have like a way of sampling fields you can in principle because

48:12.920 --> 48:17.640
the fields that demand all the properties of the quantum field theory uh compute expectation

48:17.640 --> 48:23.480
values and thereby get physical uh information so this is the idea it also goes in the other direction

48:23.480 --> 48:34.040
in um since there is uh these methods in particular um Feynman diagram computation methods that compute

48:34.040 --> 48:43.320
correlations um for quantum fields you also have a method of computing aspects of random

48:43.320 --> 48:49.320
initialized big neural networks right you have a big neural network you know that if you uh

48:52.440 --> 48:59.240
to sample from it it is as if you would sample from a quantum field um and because you have

48:59.240 --> 49:04.360
ways in physics to compute aspects like correlation functions and so on of the quantum fields

49:05.000 --> 49:10.280
these uh g functions that you can compute in physics with Feynman diagrams and so on

49:10.280 --> 49:19.320
also have a relevant meaning for computing typical aspects of random initialized neural networks

49:19.960 --> 49:24.600
okay i know this is a little bit much but i hope it sort of makes sense um

49:24.600 --> 49:36.520
um i um i don't know how clear everything was that i discussed so far i just want to give you

49:37.960 --> 49:43.240
this is then more on the quantum field theory side a little motivation that i have just here

49:43.240 --> 49:50.040
written up um that connects these g functions right these autocorrelations to physics i just

49:50.120 --> 49:56.840
want to motivate it maybe give me a three more minutes so i i'm going to assume that you have

49:56.840 --> 50:03.000
an idea of the fact that transition probabilities are the squares of inner products in a Hilbert's

50:03.000 --> 50:10.840
base in quantum mechanics um so there are these um kernel objects k which are given like that

50:10.840 --> 50:17.560
so in in in you know standard quantum mechanics what you have is some um you have some in um

50:18.280 --> 50:22.600
current state which i call here in and then you have some uh other state out that you are

50:22.600 --> 50:29.000
interested in you want to know what is the chance that this state um transitions over in that state

50:29.000 --> 50:36.360
what you do is you um take the Schrodinger equation uh evolution which is governed by the

50:36.360 --> 50:43.880
Hamiltonian h in in the nicest case um here the formal solution of this equation is just e to the i

50:44.840 --> 50:52.360
h so this is the operator which moves any state forward in time you apply it to in to the like

50:52.360 --> 50:59.320
let's say this is now this is in two days you say this state that i have currently how will it

50:59.320 --> 51:06.280
evolve into the in like how will it look in two days then you basically apply this operator to

51:06.280 --> 51:13.640
fast forward this thing um and then you get something uh the in state how it will look like

51:13.640 --> 51:20.280
in two days and then the product with this object in two days with the out state that you're interested

51:20.280 --> 51:27.960
in gives you the probability that the the current state after it has evolved is going to be observed

51:27.960 --> 51:34.520
in uh in the out state okay so this is basically quantum mechanics one one um the for whatever

51:34.520 --> 51:41.880
Hamiltonian you have here you um can often then compute some analytical case some kernels

51:44.280 --> 51:49.320
these are these things and i think here if you score down in this Wikipedia page you find some

51:49.320 --> 51:55.160
examples so these are just you know in this case uh three particle in one dimension this is like

51:55.320 --> 52:05.480
some Gaussian this is similar to some heat dissipation equation and then if you have some

52:05.480 --> 52:10.840
more relativistic scenario i think they also write down here some this is more complicated

52:12.440 --> 52:22.840
correlation functions and examples okay so that's the one thing now if we talk

52:23.560 --> 52:25.000
quantum field theory

52:31.080 --> 52:31.480
then

52:38.760 --> 52:45.880
yeah the uh this is basically just a definition um the the g's we all also had that in the paper

52:46.520 --> 52:53.480
are certain expectation values right so there since we're on the pure relativistic side

52:53.480 --> 52:59.000
and i'll take your clean side there's some time operator there but you can basically ignore it

52:59.000 --> 53:04.920
for for the moment the the point is that these g's are determined by some fairly simple looking

53:05.880 --> 53:10.600
expectation values and in the in the quantum mechanical formalisms these are also some

53:10.600 --> 53:15.400
inner products in some Hilbert space of course in a quantum field theory there is no super nice

53:15.400 --> 53:22.360
theory um about uh Hilbert spaces and and and these operators so there is it's more like a

53:23.160 --> 53:29.000
like a functional definition this is what you calculate and um you hope it's somewhere

53:29.000 --> 53:33.720
else comes up with the sort of rigorous setting to compute this but nonetheless you know how to

53:33.720 --> 53:43.320
compute these g's you know how to set up the an evolution equation of your choice and make

53:43.320 --> 53:47.640
sense of these correlation functions which is um what you want to get at in the first step

53:48.680 --> 53:57.560
so given um you have uh definition of these g's there is actually then a sort of generating

53:57.560 --> 54:03.560
function in the in the um you know analysis generating function sense there are these partition

54:03.560 --> 54:09.560
functions which look like so so you basically we can view it like starting from this we start

54:09.560 --> 54:16.920
with some some definition where all these g's are um captured uh in this sort of formal some

54:16.920 --> 54:24.360
formal sum of products and then these g's are once you would have this uh partition function

54:24.360 --> 54:30.360
with this j parameter you can in principle like formally speaking with functional derivatives

54:30.360 --> 54:34.680
compute this g from this thing and then there's this whole quantum field theory I mean this is

54:34.680 --> 54:41.240
what quantum field theory is all about that tells you how to compute this this set and this is

54:41.240 --> 54:48.520
then exactly this sort of object this is what we already had have had there right we already said

54:48.520 --> 54:58.440
that um if you um take the expectation value of e to the minus s in the euclidean case is here

54:59.720 --> 55:06.760
of a product of these phi's you get all these these g's and this is basically sort of the

55:06.760 --> 55:14.760
generating function trick to get to this to these sort of objects okay um okay so this is

55:14.760 --> 55:21.080
what you do in practice and just to motivate also that how um neural network sampling would

55:21.080 --> 55:25.720
be done another way of getting at this these g functions which you want to to have okay and

55:25.720 --> 55:32.760
and so to round it up to see to to explain how this this simple g's this field theory um

55:34.760 --> 55:43.560
correlation functions relate to actually um to actual observables right you want to have this

55:43.560 --> 55:48.760
sort of transition functions as I discussed them for the quantum mechanics case there is then

55:51.000 --> 55:56.840
complicated theory of how you take these states how they how you encode these states with some

55:56.840 --> 56:02.360
fixed momentum in the in the quantum field theory you know they also live in some supposed

56:03.480 --> 56:12.360
Hilbert space let's say you have to compute a lot in in momentum space which by Fourier

56:12.360 --> 56:18.280
transform is sort of the dual to the the position space that we talked about in the whole video

56:18.280 --> 56:25.240
so there are some Fourier transforms involved and you pass from the phi's to this a's so

56:26.200 --> 56:29.800
just to sketch this out here um

56:34.120 --> 56:39.560
yeah so you have when these are I'm just throwing these formulas at you right but

56:39.560 --> 56:47.480
there's this typical relations between um the momentum space here ap and the the

56:49.320 --> 56:56.280
spacetime fields and you can view this as a transition link by Fourier transform but

56:57.160 --> 57:03.160
Fourier transform is with respect to space and also like you know momentum on space and also time

57:03.320 --> 57:10.920
and energy and the energy encodes the sort of relation that is governed by the

57:12.920 --> 57:19.000
Schrodinger equation relation and so all these things are fairly like complex but in the end

57:19.000 --> 57:25.000
it's clear that once we have these g's we have to sort of Fourier transform them over to a momentum

57:25.000 --> 57:30.520
space and in momentum space we encode actually the input output state that we are actually interested

57:30.520 --> 57:42.840
in like this for some scattering transition probability stuff okay and then there is some more

57:42.840 --> 57:49.720
theory that gives you this momentum space in out transition amplitudes that you're actually

57:49.720 --> 57:56.840
interested in in terms of these these g's basically you see on this side here these are basically g's

57:56.840 --> 58:03.800
and then from Fourier transforming and taking into account how the the frequency is and space is

58:03.800 --> 58:09.080
sort of tied together through the evolution equations you get some nasty object here that you

58:09.080 --> 58:18.920
have to then compute and then with this this this formalism you get from the green's functions to

58:18.920 --> 58:24.920
the transition probability right so I in these last 10 minutes yeah I just explained to you

58:24.920 --> 58:28.840
why these g's are really the important thing that you want to get that once you have them

58:28.840 --> 58:37.800
then in principle you can compute this transition probabilities and the neural network aspect

58:37.800 --> 58:46.840
gives you a way to get at these g's okay so lastly I want also to mention that

58:47.160 --> 58:56.360
apart from the neural network kernel theory stuff there's also the you know classical

58:57.320 --> 59:05.800
information geometry approach where you you know you have the underlying parameters theta

59:05.800 --> 59:15.240
which are the weights and you can see them as encoding if you put a distribution over the

59:15.320 --> 59:19.560
inputs and you get the distribution over the outputs which are governed by the parameters

59:19.560 --> 59:25.000
then you get this information manifold so you heard that information geometry stuff this is

59:25.000 --> 59:32.040
like a related but different mathematical angle that I just wanted to mention because we are like

59:32.040 --> 59:36.760
formally so close having all the important all these stochastics already but this is a little

59:36.760 --> 59:42.360
bit different nonetheless but also interesting there you have this neural neural manifold

59:42.360 --> 59:49.480
thing so this is also one line of research I actually try to find things going into the

59:49.480 --> 59:55.400
this quantum field theory research direction in in deep learning books in preparation for this video

59:56.440 --> 01:00:02.040
and actually didn't find too much so there was more about this classical information geometry

01:00:02.040 --> 01:00:11.080
aspect of things and then also worth noting the applications to quantum field theory is not the

01:00:11.080 --> 01:00:18.760
only way in which people try to apply neural network theory and all these nice formulas to

01:00:18.760 --> 01:00:29.080
physics there's also this mathematical metric flow things going on I just mentioned it because if

01:00:29.080 --> 01:00:38.440
you look at for example the research groups that put out this paper then you will also find these

01:00:38.440 --> 01:00:46.680
sort of neural network applications using quantum field theories okay so I mean at one hour I know

01:00:46.680 --> 01:00:52.360
it has been a little bit fuzzy but nonetheless I think I at least maybe you understood the neural

01:00:52.360 --> 01:00:58.440
network Gaussian process stuff and and can see how this ties in with path integral formalisms

01:00:59.960 --> 01:01:05.560
and I motivated you I'm really I know very few people will make it through a one hour

01:01:05.640 --> 01:01:12.920
video of these sort of friends but it's probably nonetheless I think the best way to get an infusion

01:01:12.920 --> 01:01:19.320
of this sort of theory in a digestible way and in a way where somebody highlights these things so

01:01:19.320 --> 01:01:23.880
this is it's not a real excuse I think it's nonetheless helpful even if this was not very

01:01:23.880 --> 01:01:34.360
super prepared okay with that I leave it I leave it at that I wish you a good transition into the

01:01:34.360 --> 01:01:42.680
next year I have no real videos planned for the upcoming months really I mean I have a folder with

01:01:42.680 --> 01:01:50.280
20 started projects and videos I could talk about that I might come back to probably not

01:01:50.280 --> 01:01:57.720
within the next months but then as I said I might look more into classical classical

01:01:57.720 --> 01:02:02.520
functional analysis stuff for the sake of making a nice video about the universal approximation

01:02:02.520 --> 01:02:14.360
theorem and at the latest then I will have a polished video take care

