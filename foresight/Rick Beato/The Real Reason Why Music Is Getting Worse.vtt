WEBVTT

00:00.000 --> 00:03.920
Hey everybody, I'm Rick Biotto. We're going to try something new today. This video is on the

00:03.920 --> 00:11.840
history of the music business and technology in two acts. Act one. Music is too easy to make.

00:13.040 --> 00:20.320
What do I mean by music is too easy to make? Let's just go back to the 1940s and 50s. Frank Sinatra

00:20.320 --> 00:25.840
used to get up in front of an orchestra and sing a vocal take and they had one microphone

00:25.840 --> 00:30.080
and they would get it balanced just right. Frank would say, okay, I'm ready to do it and he'd sing.

00:34.080 --> 00:39.360
Then you get into the 1960s or so and then you have things where you have multi-track machines.

00:39.360 --> 00:44.000
You could go in if you had a mistake in a vocal part or any instrument and you do a punch in. Oh,

00:44.000 --> 00:47.200
I don't like that word. I sang it out of tune or I want to change this lyric. You go in and you

00:47.200 --> 00:53.440
just punch in, fix the line, punch out. Fast forward to 1998 with Cher the Believe Son. They

00:53.440 --> 00:57.120
invented this thing, autotune, that I've talked about this a million times on here, but autotune

00:57.120 --> 01:02.640
was a plugin that would go into these DAWs, digital audio workstations. So you'd have something like

01:02.640 --> 01:07.680
Pro Tools or Logic or Ableton. What you do is you take the vocal, let's say the song's in C major.

01:07.680 --> 01:13.280
Any note in the key of C major, it would tune the note too. Well, T-Pain and people like that

01:13.280 --> 01:17.920
realize if you put it on a really hard tuning, it would make it sound like a keyboard and that's

01:17.920 --> 01:22.160
what they did in the Believe song. Well, then the same thing starts happening with drum parts.

01:22.160 --> 01:25.840
Guys play it in drum part and you're like, you know what? This would be a great take of this

01:25.840 --> 01:29.600
first verse. If this one hi-hat wasn't a little dragged, well, let's move it back a little bit

01:29.600 --> 01:32.800
or let's move it forward, whatever. And then you move that and you're like, well, the snare after

01:32.800 --> 01:36.640
it kind of sounds weird because we move that forward. Now the snare sounds like it's dragged,

01:36.640 --> 01:39.760
so we do that. Then you're like, well, you know what? Let's just look at the grid lines,

01:39.760 --> 01:42.960
the bar lines, and we'll just move them to that. Then you start cutting out, moving them. Then

01:42.960 --> 01:47.760
they give you this tool called Beat Detective. Then you can actually quantize an entire part. So then

01:47.760 --> 01:53.360
it becomes like a drum machine, just not human-like. Here's an example of a quantized drum part,

01:53.360 --> 01:58.320
it's John Bonham's drum performance from Fool in the Rain that's a shuffle. Here's what it sounds

01:58.320 --> 02:11.760
like as a machine. Now, here's the actual human performance of John Bonham. Notice the swing in

02:11.760 --> 02:24.160
it. Once you've quantized the drum part, it's a drum machine. It's just like superior drums.

02:27.440 --> 02:32.960
So what started happening in the year 2000 or so is that everyone started quantizing their drums

02:32.960 --> 02:38.400
because the budgets, the higher session guys like Josh Freese and Kenny Aronoff went away

02:38.400 --> 02:42.480
and you'd have to use the crappy drummers. I mean, some bands would have good enough drummers to play,

02:42.480 --> 02:46.480
but you typically have these crappy drummers that you'd have to fix their parts. And once you fix

02:46.480 --> 02:50.640
their parts, you start moving the bass around, you start moving the guitars around, and then you

02:50.640 --> 02:56.800
pretty much have sterile, generic, quantized rock music that has no vibe at all. The other thing

02:56.800 --> 03:02.080
that people realize is that it's really difficult and time-consuming to record a drum set. You need

03:02.080 --> 03:07.200
a studio and a lot of gear. Look at all these mics. Now, you can put up three mics and get a drum

03:07.200 --> 03:11.440
sound. You can put up two mics and get a drum sound. But to get a professional drum sound,

03:11.440 --> 03:15.360
you tend to mic up the different instruments. I got two mics on the bass drum. I got a mic on

03:15.360 --> 03:20.080
this time, mic on that time, mic on the ride, two mics on the overheads, two mics on the snare here.

03:20.080 --> 03:24.080
I actually have three mics on the snare and a mic on the hi-hat. And I have a couple of room mics.

03:24.080 --> 03:29.280
It's hard to record it well. Not only is it hard to play the drums well, but it's hard to record

03:29.280 --> 03:33.680
the drums well and you have to have training. It's not easy to do. You have a great ear. You've

03:33.680 --> 03:37.360
got to know how to tune them. You've got to know what is a good snare sound from a bad sound.

03:37.360 --> 03:40.960
You've got to know if the toms are ringing too much. You've got to know if they're in the right

03:40.960 --> 03:45.360
pitches, all this kind of stuff. There's so many decisions to make. Now, some of you are out there

03:45.360 --> 03:49.120
thinking, what are you talking about, Rick? You don't need to have a good sounding room. You're

03:49.120 --> 03:52.640
going to have a crappy sounding room. You don't even need good mics because you're going to just

03:52.640 --> 03:58.000
replace everything with samples. Well, where do you think samples come from? They come from people

03:58.000 --> 04:04.160
that know how to record them. That one was for free. It's difficult to get a good guitar sound.

04:04.160 --> 04:07.840
You have to have a good sounding amp. You have to have good sounding speakers, good microphones that

04:07.840 --> 04:12.960
work well. Most people now just use amp modelers. They plug into their computer. They pull up their

04:12.960 --> 04:16.960
program. Everything is done for them. They've already been pre-miked, pre-selected. They're

04:16.960 --> 04:21.760
all using the same algorithms. They can create great sounds. They're so easy to use. It doesn't

04:21.760 --> 04:26.160
take any skill at all, but it doesn't take any creativity either. Then, of course, you have

04:26.160 --> 04:30.800
the MIDI packs that you can buy if you can't play keyboards. So, it'll just have pre-program

04:30.800 --> 04:35.920
chord progressions because for some reason, people can't just kind of space their fingers out and learn

04:35.920 --> 04:41.520
to play a few chords like that or maybe just experiment, huh, what is this? What is this?

04:42.160 --> 04:48.400
In the early 2000s, labels stopped signing rock bands, essentially, because it was way too resource

04:48.400 --> 04:53.600
intensive. It was far easier to sign artists that could make their own music using a laptop

04:53.600 --> 04:58.480
and a microphone. Why is this a bad thing? Well, let's start with the creative dependency on

04:58.480 --> 05:03.760
technology limits the ability of people to innovate, I believe. Could be wrong about that.

05:03.760 --> 05:09.280
Maybe it helps them innovate. I don't think so, though. The homogenization of music, the over-reliance

05:09.280 --> 05:15.200
on similar tools as I just brought up with the amp models, creates a lack of diversity. I think

05:15.200 --> 05:21.200
that leads to music becoming more formulaic and people just following trends of using certain

05:21.200 --> 05:26.640
types of sounds. This is why these trap beats have been in vogue for the last 20 years. People

05:26.640 --> 05:32.160
just, they know they work, so they just keep using them all the time. Quality versus quantity.

05:32.160 --> 05:38.320
This is a big, big thing, okay? So, the easier production makes the process go faster, which

05:38.320 --> 05:44.880
creates an oversaturation of music, making it harder to find really exceptional things.

05:44.880 --> 05:52.000
As Ted Joya talks about in this clip. This is Spotify's way of using AI. They have AI songs,

05:52.000 --> 05:56.560
they attribute them to people that don't exist, and this allows them to take royalties that would

05:56.560 --> 06:02.960
go to musicians and keep them for themselves. On the AI front related to music is too easy to make.

06:02.960 --> 06:07.920
I made a video last week called, I told you this was going to happen, and I played some songs off

06:07.920 --> 06:14.800
UDO, and I was saying how my kids could detect that they were AI songs, but other people could not.

06:14.800 --> 06:20.800
Well, it just came out. All three major labels are suing AI startups for copyright infringement.

06:20.800 --> 06:27.200
Universal Music Group, Sony Music, and Warner Music are suing Suno and UDO for copyright

06:27.200 --> 06:32.560
infringement, because guess what? They're using all their music to train these AI models. Well,

06:32.560 --> 06:37.520
of course they are. How else do they get to train it? No, companies like Universal are not doing it

06:37.520 --> 06:42.000
for the good of their music to protect their copyright owners. What's going on here is they

06:42.000 --> 06:47.280
just announced that they're partnering with a company called Soundlab to make AI models of

06:47.280 --> 06:54.240
their artists for themselves. They can use this Soundlab plug-in in Pro Tools or Logic, and you

06:54.240 --> 06:59.840
can sing your own voice and replace it with one of their artists like Drake or Taylor Swift

06:59.840 --> 07:04.880
or Billie Eilish or whoever agrees to this, and I guarantee you all these labels are going to do

07:04.880 --> 07:10.720
that because they want to own the AI versions of these songs. Whether you create it or whether they

07:10.720 --> 07:16.080
create it, they're going to own it. And just to show you how easy it is to model someone's voice

07:16.080 --> 07:20.960
with AI, I'm speaking to you through a voice modeling program called 11 Labs that was trained

07:20.960 --> 07:25.760
on my voice over a four-week period. So for those of you that keep writing to me every day, I get

07:25.760 --> 07:30.000
about 20 of these a day, and they always start, Rick, I wrote a song that I think can be a hit.

07:30.000 --> 07:35.360
I used AI to hear it because I know nothing about making music. That's literally from an email I got

07:35.360 --> 07:41.600
yesterday. This reminds me of the best AI critique I've seen. Creative AI tools can be seen as

07:41.600 --> 07:46.480
sophisticated plagiarism software as they do not produce genuinely original content,

07:46.480 --> 07:53.200
but rather emulate and modify existing works by artists subtly enough to circumvent copyright

07:53.200 --> 08:00.240
laws. Well, what's funny about that is that was actually written by chat GPT. Act two, music is too

08:00.240 --> 08:12.800
easy to consume. So this is the water faucet in my kitchen, but imagine this is streaming on Spotify

08:12.800 --> 08:21.520
or Apple Music. You can turn it on, you can turn it off, but what's going on in the stream of water

08:21.520 --> 08:27.840
is all of the music that's on these platforms. Now imagine this is one artist's

08:28.720 --> 08:36.400
entire output. Their entire catalog might be the police, could be Billy Eilish, could be Led Zeppelin,

08:36.400 --> 08:44.240
the Beatles, and then this dropper is each of their songs. One, two, three, four. Oh,

08:44.240 --> 08:50.560
I just did a whole record there, and eventually you exhaust their whole catalog. When I hit this,

08:50.560 --> 08:56.400
and I start the stream, the music has very little importance if you think about it this way.

08:57.280 --> 09:05.360
It goes from the faucet down the drain out to the sewer where it's recycled again. Except in this

09:05.360 --> 09:11.440
case, the music is not recycled like it is through the sewer. There were 100,000 new songs added

09:11.440 --> 09:19.040
every day in 2023 to streaming platforms. That's more than one song per second for the entire year.

09:19.040 --> 09:26.800
By comparison, when I was a kid, if I wanted to buy this Led Zeppelin II record, I had to get a job

09:26.800 --> 09:32.320
or borrow money from my parents to buy it, because I wanted to own it. I wanted it to be in my

09:32.320 --> 09:38.800
collection. This album here, Pat Matheny, New Chautauqua, I paid eight bucks for, brand new,

09:38.800 --> 09:44.960
with the money that I made by bagging groceries at Topps Grocery Store in Fairport, New York.

09:44.960 --> 09:52.000
You actually had to expend energy riding your bike or walking to your job, working your shift,

09:52.000 --> 09:56.240
getting your paycheck at the end of the week, depositing it in the bank, getting money out,

09:56.240 --> 10:00.480
going to the record store, buying the record, bringing it home, playing it, listening to it a

10:00.480 --> 10:05.920
bunch of times, going over to your friend's house, sharing it with them. When a kid opens Spotify

10:05.920 --> 10:11.120
and clicks on on a song, they can just skip to the next one if they don't like it. Think about this.

10:12.080 --> 10:16.560
All of the music that exists, or at least has been uploaded to Spotify or Apple Music,

10:16.560 --> 10:23.120
is available for $10.99 a month. I'm talking about all of Michael Jackson's music, all of ACDC,

10:23.120 --> 10:30.400
Pink Floyd, Whitney Houston, Tupac, Kendrick Lamar, Juice World, Eminem, Dr. Dre, all the works of

10:30.400 --> 10:36.640
Beethoven, of Bach, of Mozart, of Stravinsky, of Shostakovich, of Charlie Parker, of John Coltrane,

10:36.640 --> 10:44.320
of Miles Davis, Brad Meldow, of Pat Metheny, Keith Jarrett, all of that. $10.99 a month for the price

10:44.320 --> 10:49.680
of what we used to pay for one album. It's all available on these streaming platforms.

10:49.680 --> 10:57.040
Which is why music is not as valued by young people. There is no sweat equity put into obtaining it,

10:57.040 --> 11:02.240
having it be part of your collection, having it be part of your identity of who you are. These are

11:02.240 --> 11:07.200
the bands I believe in. These are the artists that I love. And I'm going to share it with my friends.

11:07.200 --> 11:11.360
I'm going to bring that record to school. I'm going to play it for my friends after school. We're all

11:11.360 --> 11:17.040
hanging out reading the back cover of it and seeing who played on it. These things meant something.

11:17.760 --> 11:25.280
What was on here meant something produced by John Burns and Genesis. It was important.

11:25.280 --> 11:28.800
What I'm saying is that music is basically become

11:29.360 --> 11:36.640
valueless. If you only have to pay $10.99 a month to have access to anything, what is one song worth?

11:36.640 --> 11:40.480
You know, people tell me that they want me to make certain kinds of videos.

11:40.480 --> 11:46.160
They have these aspirational ideas, as my friend Todd calls them. But then they ultimately vote

11:46.160 --> 11:50.880
with their attention. Rick, make more of what makes a song great videos. Make this kind of video.

11:50.880 --> 11:56.400
Or I wish that people would write songs in odd meters or use these more complex chord changes.

11:56.400 --> 12:03.440
But you know, ultimately people will do that and then they don't listen to them because you vote

12:03.440 --> 12:12.720
with your attention. So try this. Try to sit down just a couple times a week. Play just a few songs.

12:12.720 --> 12:17.600
Don't look at your phone or as I call it the thought deletion device because it empties

12:17.600 --> 12:23.200
your mind out. Don't look at TikTok. Don't look at YouTube or Twitter. Don't look at Instagram.

12:23.200 --> 12:28.560
Just listen to the music. Let it flow over you. Think about the lyrics. Think about the melody.

12:29.120 --> 12:35.360
And try to experience music like you used to. Or if you're young, try to experience music in the way

12:35.360 --> 12:41.440
that we used to. Love to know your thoughts. Hit the subscribe button. Leave a comment. Thanks for watching.

