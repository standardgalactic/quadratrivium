start	end	text
0	17120	Hello and welcome. It is July 17th, 2024. We're in active inference guest stream 83.1 with
17120	23360	Josh Bongard. Thank you for joining. This should be very exciting. We'll have a presentation
23360	28160	and then some discussion. So if you're in the live chat, please feel free to write any
28160	34000	questions. And thank you again, Josh, looking forward to this. Yeah, thank you, Daniel. And thanks
34000	39280	to those of you that are attending online. So my name is Josh Bongard. I'm a professor of computer
39280	45760	science here at the University of Vermont. And my bread and butter in my lab is the study of
45760	54240	robotics and AI. And obviously, we're in the middle of the current AI summer. So what I wanted to do
54240	58640	today is show a couple of highlights from my group, things that I've worked on in the past and
58640	64240	that we're working on at the moment, that I hope in the long term will help us realize sort of the
64240	69360	long term vision for a lot of those trying to create intelligent machines, which is to create
69360	75920	machines that are helpful, but but also safe. We're part of the way there. But as anyone who's
75920	82240	worked with chat GPT or stable diffusion knows or even has a robot vacuum cleaner at home,
82240	87280	there are some limitations to our current technology. It's hard to create machines that are
87280	93920	autonomous and useful and safe all simultaneously. So what are the things that we're missing?
94640	99840	That's what I wanted to sort of seed the pool with today and hopefully we can move on to an
99840	105360	interactive discussion about it. So I'm going to leave this slide up and just sort of talk over
105360	109520	this slide for a few minutes that will hopefully generate some food for thought and then questions.
109760	115840	This is a snapshot from some of the projects I've worked on over the years. First thing you'll
115840	120560	probably notice is there's a lot of different robots that have very different structural
120560	126720	properties. They not only act differently, but look very different. And that is a fundamental
126720	133040	foundation in everything we do in my research group, which is to try and understand how the
133280	141760	body facilitates cognition. Years ago with my PhD advisor, we wrote a popular science book called
141760	148640	How the Body Shapes the Way We Think. And we can mean that literally or figuratively. We wrote that
148640	153680	book a while ago. We made some arguments about how the body shapes the way we think. And since that
153680	160320	time, my group and others have formulated other arguments for why or how the body shapes the
160320	167200	way we think. And I'm hoping to survey some of those today. So as I mentioned, you can see
167200	172000	a lot of different robots here, very different structure. They've got very different form and
172000	178560	function. But across each of the pair of videos that you see here, you'll notice that there's also
178560	183840	a common pattern, which is on the left side, you tend to see something that's virtual. And on the
183840	189520	right side of the video pair, you tend to see something that's physical. And this illustrates
189520	195200	the basic approach that my group takes to understanding how the body shapes the way we think,
196000	204240	which is to create AI that creates robots, creates embodied AI. So what do I mean by that?
204960	211120	What I mean is that in all of the projects that you see here, we create an AI that searches the
211120	217840	space of all possible robots that could solve the tasks that we want the robots to solve.
218800	224240	Most people that are familiar with AI and robotics and autonomous cars and drones have
224240	231520	a rough understanding that AI is somehow optimizing or tuning the brain of the autonomous car or the
231520	237280	drone or the robot, what have you. There's an underlying assumption in all of that current,
237280	243440	in most current robotics, which is that the AI tunes the brain, but does not tune the body.
243440	251200	Tesla cars are dreamed up mostly by humans and an AI tunes their brain or their control policy.
251760	256160	But of course, nature doesn't work that way. Nature produced us and all the other intelligent
256160	263920	organisms on this planet by carefully tuning body and brain simultaneously. Certain bodies
263920	268640	facilitate certain kinds of behaviors and certain kinds of intelligent behavior,
268640	273760	and other bodies don't. They obstruct that particular behavior or that intelligent behavior.
274560	281360	So in all of our work, we ask the AI not just to tune the brain of a robot, but its body
281360	288960	simultaneously. And as you can see visually here, the AI often comes up with bodies that are well
288960	295200	suited to whatever we want them to do. So if you direct your attention to the very top left of
295200	301040	the screen for a moment, this is now a 22 year old experiment, but I think it still visualizes
301040	307200	the potential of this approach. In this case, we were interested in creating a robot that can
307200	313920	brachiate, that can swim, swing across beams or tree branches or electrical wires for various
313920	319840	inspection tasks. And you'll notice that in this case, the AI came up with a solution that in
319840	326560	retrospect seems intuitive. The robot has to carry a very heavy battery, which you can see in
326560	332960	the physical robot in the top left there, the black box that's at the bottom. And the AI has
332960	340160	figured out how to design the body of this robot so that it's actually able to exploit the forward
340160	347280	momentum of this heavy object, this battery, to facilitate its movement or brachiation across
347280	353680	this physical beam. So it's a simple example, a simple robot, a simple task, but it demonstrates
354560	363600	this interplay between AI, robotics, body and brain. If the AI was not free to place the body,
364080	369920	to place the battery at a particular place on the robot's body, it would be much harder,
369920	375280	it would require more energy, it would require a more complex brain for the robot to figure out how
375280	382880	to move its heavy weight across this beam. So that idea of tuning body and brain has
382880	389680	suffused everything that we work on. Some other examples you can see in the top center and the
389680	397920	top right. Here we have a robot that suffers damage, its body changes over time. So now the AI has to
397920	403440	grapple with not just designing a body, but grappling with a body that changes. One of the
403440	409920	things that we as intelligent organisms here in the world and all embodied AI, all autonomous cars,
409920	416080	all drones, all robots have to deal with is entropy. The world throws a lot of stuff at us,
416080	422400	we have to deal with wear and tear, injury. In our case, we grow from a single cell into about
422400	429840	10 to the 12 cells. We change massively in terms of our physical magnitude. How do you continue
429840	437040	to operate, keep yourself alive and do whatever it is you need to do across massive morphological
437040	443280	change? That is not an easy thing to do. And again, it requires an AI, if it's going to do this with
443280	450320	robots, it's got to figure out how to carefully tune body and brain to deal with the generation
450320	457120	of behavior inside a body that is changing, either unexpectedly due to injury and wear and tear,
458080	464800	or intentionally. You can see in the very center panel, this is again a pretty good
464800	472560	visualization of where designing body along with brain comes in handy. If we want to make
472560	478640	flying machines or swimming machines, we have to very, very carefully tune the geometry and
478640	485600	material properties of the body itself to realize flight. So what you're seeing in this middle panel
485600	491600	here, this is partway through the AI experimenting with the design of different kinds of wings
491600	500480	for an ornithopter, a drone that flies by flapping its wings. This flexible wing that you see here
500480	506000	in the center of the screen, this is a bit of a transition from traditional robots that are made
506000	513360	of rigid structures, like you can see in the top row, into a more modern era in robotics,
513360	519280	which is sometimes referred to as soft robotics. Material science has come a long way in the last
519280	526800	20 years. So we can now start to build robots embodied AI. We can start to build robots out of
526800	533840	materials other than rigid plastic and metals. And we can again, we can start to move into an era
533840	540320	in which robots like organisms can exploit the material properties of their bodies
541120	547280	to facilitate whatever behaviors they need to do to survive or be useful to humans and so on.
548400	554560	So in the middle right panel, this is a highlight of some work that my group has done in collaboration
554560	562080	with Rebecca Kramer, Bottiglio's lab at Yale. Rebecca's lab is famously advancing the state of
562080	568320	the art in soft robotics. What can you get robots to do when they're made out of soft materials?
568320	573760	You can see an example of some of those soft robots. Middle right and a very different soft
573760	581120	robot lower left, which is exploiting its body properties in order to move in interesting
581120	588080	ways. One of the interesting things about soft robotics in my perspective is that it starts to
588080	595840	usher in an era in which robots can actually grow and complexify their bodies. You can see these
596480	603680	hollow cubes in the middle right and these hollow sort of chambers in the bottom left
603680	611520	expanding and contracting as we push and pull air into and then out of the body of the robot.
612640	617440	Suddenly, now you have robots that can change their geometry. They can change their volume.
618480	624640	They become what's known as thermodynamically open. It's a fancy term for meaning that they can
624640	633040	draw new material and new energy into themselves. The thermodynamically open machines that you see
633040	639200	middle right and lower left, the only thing they're drawing into their body is more air,
639200	646960	but it's a start. I mentioned already that humans grow from a single cell into 10 to the 12 cells.
647600	654880	Every organism on this planet, with a few exceptions, starts small and gets bigger over its
654880	663360	lifetime. That fundamental morphological change starts small, starts simple and gradually grow
663360	673440	in size and complexity. That provides scaffolding. It provides a gradient on which to learn how to
673440	678800	gradually grapple with the world around you. Most organisms, again, there are exceptions,
678800	685280	are not thrust into this world with all of their machinery online from the beginning.
686320	692080	Just the way I'm phrasing this is obviously intentional to sort of dichotomize growing
692080	699440	organisms and robots with fixed bodies. Autonomous cars are still very dangerous.
699440	706640	Autonomous drones are still very dangerous to be around because 99.99% of the time,
706640	711280	they do the right thing, but every once in a while, they don't know what to do,
712000	720240	and no one knows what they're going to do in those uncertain circumstances. That is a very
720240	727840	concerning situation as we start to now deploy robots and autonomous vehicles into everyday
727840	734640	environments where they are in close proximity to humans. Why is it that even with state-of-the-art
734640	741360	AI and with all of Google's data centers and AI training algorithms, we still can't rub out that
741360	750080	0.001% where no one knows what's going to happen? Part of the reason, again, is these machines
750160	759600	are born with complex bodies. We drop a controller into a one-ton autonomous car made of metal and
759600	767120	plastics. It's very dangerous. We don't grow autonomous cars from a very small, simple,
767120	773280	lightweight machine that can't cause anyone any harm whatsoever, and then when that simple,
773360	780240	small machine demonstrates and verifies to us that it's safe, then we allow it to become larger
780240	786320	and more complex. It sounds like silly sci-fi. Why would we build a machine like that? But again,
786320	792400	every organism starts simple and grows in complexity. If it doesn't do the right thing,
792400	798720	if it performs dangerous actions that are harmful to itself or fatal to itself, by definition,
798720	805360	it doesn't get any further. That's, again, one of the ways of thinking about how the body shapes
805360	812240	the way we think. In my personal and professional opinion, any physical machines that we deploy
812240	818000	into the real world, they should start as very small, lightweight machines that can't harm anyone.
818880	823760	They have a very limited number of actions that they can perform, and they sort of cycle
823760	831040	through all those actions and verify everything, and only then can they take more mass, more energy
831040	837680	into themselves. Can they recruit more material? They can sort of be allowed to be thermodynamically
837680	844160	open and grow and complexify themselves. There's lots of ways in which we're starting to create
844160	850240	machines that grow and complexify themselves. I just talked about these soft robots that can pull
850240	857440	in air or pass possibly fluids. They could be hydrodynamic machines. They could mechanically
857440	863920	or magnetically connect to other robots. That sort of swarm robotics. That's another path
863920	871200	to growing machines. At the moment, most of these machines are still restricted to academic labs.
871200	876480	They also are not safe yet, but I think in the long run, they're going to be a safer alternative to
877360	883360	dropping AI into very large, complex, heavy, dangerous machines and crossing our fingers
883360	890000	and hoping for the best. I've talked a little bit about rigid robots and soft robots.
890720	894800	I want to try and talk as little as possible. There's some time for a good discussion,
894800	900480	but I want to talk about what I see as sort of a third era of robotics and embodied AI,
900480	907760	which is just starting to open up in the last few years, which is biobotics or creating biobots.
908400	917360	You can see two biobots on display at the bottom center of my slide here. A biobot is a robot
917360	925360	that's made up of only biological components, no technological components whatsoever. In the bottom
925360	932320	left here, Kriegman, Blackiston, Levin and myself in 2020 published a paper demonstrating the first
932320	940080	biobot. This became known after publication in the popular media as Xenobots, X-E-N-O,
940880	949520	Xeno, Xenobots, because these Xenobots are built from about 2,000 frog cells and the cells were
949520	956880	taken from a particular species of frog, which is Xenopus laevis. Michael Levin, our biology
956880	963760	colleague at Tufts University, is world-renowned for demonstrating that you can reconfigure
963760	971840	genetically unmodified materials like, for example, frog cells, and that rearrangement
971840	977520	of living tissues not only does not kill the organism, the organism is able to in some cases
978080	984320	continue on doing what it does, what it needs to do, ingest materials, survive,
984320	991440	reproduce in this reconfigured state. There's a lot of biological implications for that.
991440	998160	One of the biological implications is that frog DNA does not code for frog. What you're looking at
998160	1003360	in the bottom left, the Xenobot is about a millimeter in diameter, so it looks like a speck
1003360	1010640	of pepper to the unmagnified eye, and yet it's able to walk around the bottom of a petri dish.
1010640	1016000	It doesn't have all the features of a living organism, but it's got enough of them that it's
1016000	1025040	motile. It's able to get itself from point A to point B. One of the other implications for AI
1025040	1030880	of this biological discovery that you could rearrange genetically unmodified living tissues
1030880	1039120	is that maybe we can task an AI with discovering novel rearrangements of living tissue to produce
1039760	1045840	robots, to produce something that moves around and does something useful on a human's behalf.
1047120	1052800	That's what I mean by a biobot, a biobot that's made from, in this case, genetically unmodified
1053360	1061120	cells. The swarm of Xenobots that you see in the bottom right, as you can see,
1061120	1068400	they're sort of pushing around some material in their dish. This sort of visually hints at
1068400	1074480	applications for this type of robotic technology, which is they might be able to act like very,
1074480	1080480	very small Roomba robot vacuum cleaners in the future. They might be able to collect
1080480	1089360	microplastics out of waterways or cancer cells out of bloodstreams. The swarm that you see that's
1089360	1095200	cleaning up in this slide at the bottom right, the material that they're cleaning up is actually
1096000	1103440	other frog cells. It turns out that if the AI designs this swarm just right and the swarm
1103440	1110000	that you're looking at, this is an AI designed swarm, the AI came up with the shape for each
1110000	1116880	member of the swarm. This swarm is pushing these little white circles, which are individual frog
1116880	1123280	cells, pushing them into piles. Turns out these individual frog skin cells at a certain stage
1123280	1130080	of development are sticky, and they clump together into a pile. Some of these piles,
1130080	1135680	if they're big enough, if they contain enough frog cells, they will grow very small hairs
1135680	1141840	on the surface cells, the cells that are on the surface of the pile. Those little small hairs are
1141840	1151360	called cilia. They're usually used to pull dirt and pathogens off the body of frogs, adult frogs.
1151360	1159200	Here, when those cilia grow on small piles of frog cells, they're able to exert enough force
1159200	1167360	against the surrounding water that these piles start to move. What you have in essence is a child
1167360	1173840	xenobot. This swarm pushes cells together and in essence makes copies of themselves.
1174640	1180400	This is another implication of this work, is that in this case the AI has figured out how to design
1180400	1187600	robots that replicate. They make copies of themselves by finding raw material in their
1187600	1193440	environment and constructing copies of themselves. This has been a long-standing dream in robotics,
1195520	1201440	dating back a very long time to John von Neumann in the 1950s who had a thought experiment. It would
1201440	1206880	be great if we could create robots that would create copies of themselves, which would create
1206880	1214400	copies of themselves. If those robots do useful work for humans as a side effect, for von Neumann
1214400	1220560	that was creating moon bases and then Mars bases and then colonizing the galaxy, which sounds great.
1222160	1230160	But the seed of this idea is if we want robots to really be useful at scale, instead of manually
1230160	1236320	constructing billions of robots and then deploying them to do something useful, which is expensive,
1236320	1240320	it would be much cheaper to make one robot that does something useful for us.
1241200	1247040	By the way, it also makes two copies of itself, which does more useful work for us in four and eight
1247040	1253440	and sixteen and so on. We're not there yet with the Xenobots, but it's a demonstration that that
1253440	1259920	is possible. Again, all of that becomes possible because the AI is designing both the bodies
1259920	1267040	and the brains of these robots. This is very far now from the traditional view of AI and robotics,
1267040	1274000	where we build a robot body, we humans build a robot body, and then the AI tinkers with the brain
1274000	1280960	of that fixed machine. Part of the reason why I'm here today and part of the message of my group is
1280960	1288320	we need to think more broadly about how to combine AI and robotics and possibly synthetic biology.
1289200	1295920	When we do and we think more broadly, there are whole new paths that open up to ways in which
1295920	1303120	we might create in the future, not yet, but in the future, create intelligent, useful, and safe
1303120	1310720	machines. In the current era in AI, there is one particular approach, which is auto completion of
1310720	1317040	tokens, which has come to dominate the field and come to dominate the popular imagination. We all
1317040	1323760	kind of have an understanding more or less of what chat GPT is doing, and there are some very strong
1323760	1329520	lobbying organizations out there that are bent on convincing us that if we just do this with
1329520	1336320	more compute, more data, we will eventually get to safe machines. My contention is there just
1336320	1344160	isn't enough data out there to make non-embodied AI like chat GPT and stable diffusion and all the
1344160	1352160	rest to make them safe. We have to think differently about designing bodies and brains of machines
1352160	1360160	simultaneously to realize this long-term goal. Okay, I've been talking for a while. I'm going to
1360160	1365280	stop and I'm happy to take questions or engage in some discussion, and I'm happy to come back to
1365280	1371120	any of these experiments and provide more detail if that's helpful. Over to you, Daniel.
1371920	1380080	Thank you. Wow. Awesome. What a cornucopia of bodies and minds.
1383120	1389840	It was a great overview. I was really struck by some of the similarities and the convergence on
1390480	1397040	whole of lifecycle design and kind of holistic design coming from, on one hand, a systems engineering
1397040	1403680	and a materials perspective, and on the other hand, from the biology perspective with like eco-evo-devo
1404400	1411840	and this convergence upon needing to think about how the end-to-end function maybe even past the
1411840	1419280	point of functionality like into the planned graceful decay of a robot as well. So it brings in a lot
1419280	1425600	of topics that even from an outsider's perspective seem to be put as kind of secondary. So that's
1425680	1430960	very cool. Okay, great. I'm looking forward to what people in the live chat, right?
1432320	1442080	My first question is how over these 22 years, how have the materials, the theories, like the
1442080	1448960	contexts, advances in turing computation, all these kinds of things, how have they intersected
1449280	1453120	just what has the ride been like as you pursued these questions?
1454560	1462560	Yeah, I think the short answer again is focusing on the physical aspect of AI and robotics. So the
1462560	1470480	materials from which we can build machines has changed over 20 years. And from my perspective,
1471040	1474320	the experiment, the top left there, that was something I did as part of my PhD,
1475040	1480000	you know, the materials at the time, it was very hard to build a robot. You bought some
1480000	1485040	motors, you bought a battery, you bought some metal, you bought some wires, and you wired
1485040	1490400	everything up. There was the assumption that bodies were fixed. And not only that, but they were
1490400	1495600	difficult to make. So once you made one, you were very careful with it to make sure it didn't change,
1495600	1502560	that it didn't become damaged. And that seemed to comport with a lot of the theory in AI and
1502560	1509840	neuroscience, which had the same sort of idea that the brain, or in the case of robotics,
1509840	1516960	the control policy is the puppeteer. It's something that's pulling the strings of a fixed thing,
1516960	1525120	either the body of an organism or a robot. And if you look at a lot of theory in both fields,
1525200	1531040	AI and neuroscience, that assumption runs so deep. So for example, an active
1531920	1537360	inference, you know, the free energy principle, we want to reduce surprise all that there's a
1537360	1543360	fixed set of actions that we perform to try and reduce the surprise between what we're sensing
1543360	1549680	and what we predicted we would sense given the past action. Where do those actions come from?
1549680	1557440	Why are they fixed? Does the set of actions grow over time? Maybe the sensory data that's coming
1557440	1562720	is coming from a new sensor that's just coming online or a sensor that's recently duplicated.
1562720	1569120	Now there's two of them, but they're not quite reporting exactly the same thing. There's a whole
1569120	1576640	bunch of assumptions underlying a lot of the theory about active inference, predictive coding.
1577600	1582560	You name it, you pick your concept from neuroscience or cognitive science or AI.
1585360	1592080	Once you peel back those assumptions, imagine the robot's body changes. Imagine the robot splits
1592080	1600960	in two and becomes two copies of itself. A lot of the theory and the formal underpinnings of
1601040	1606240	that theory break down. You start to get into ill posed questions, which force you to now
1606240	1612800	think about how do you fundamentally change the theory? If you have a hierarchy of actions,
1612800	1618160	like in predictive coding or active inference, what if that hierarchy is growing and changing
1618160	1624400	over itself is growing and changing over time? How do we address that in a formal manner? So
1624400	1629040	to get back to your question, I think these advances in what we can do physically, we can
1629040	1634720	build robots now out of soft materials. We can build robots out of living materials,
1635520	1641120	which on their own will grow and divide and seek out energy and material on their own.
1642800	1648160	Those physical machines, these odd new kinds of creatures, are militating. They're pushing
1648160	1654080	against the theory. Specifically, they're pushing against these unspoken assumptions that lie
1654080	1661760	underneath a lot of this theory about what's required to act intelligently in a complex world.
1663120	1670400	That's awesome. Like the real world and the territory expanding into our unknown unknown.
1670400	1674640	Okay, there's a bunch of questions in the live chat. So I'm just going to go for them,
1674640	1677360	give any answer that you like. Okay.
1677360	1682400	Sure. David Williams wrote,
1683280	1689280	How do you think about the controllers in your robotics? Embedded AI at least today is rather
1689280	1695760	hard. Batteries and chips, PCBs, not soft and not easily synthesized locally. So how do you
1695760	1701120	think about the controllers in your robotics? Yeah, great question. So, right, exactly. The
1701120	1707840	controllers are dealing with hard rigid fixed components. We need to start thinking about
1707840	1714400	controllers that can, in which, for example, the input layer and the output layer can grow and shrink
1714400	1721360	over time. There may be new sensors or new input coordinates that are growing or being attached
1721360	1728480	to a machine. And the controller needs to be able to carefully deal with those new input channels
1728480	1735040	while the machine is operating. Same thing goes for the output channel. There may be new
1735040	1744480	actions or new dimensions of action along which the machine can act. And control policies,
1744480	1750560	reinforcement learning, all the rest of it does all those assumptions that make reinforcement
1750560	1756240	learning work, which is what drives most autonomous vehicles at the moment, assumes
1756240	1761200	that the dimensionality of input and the dimensionality of output, the things that the machine
1761200	1769120	can do and sense, are fixed during training or during behavior generation, during execution.
1769120	1775520	That is absolutely not true in any organism on the planet. And that's becoming increasingly untrue
1776640	1783040	for our coming machines. Now, how to do it well? I don't have any answers, but we have to figure
1783040	1789040	it out. You were asking a question about thinking about controllers. That's a concrete example
1789040	1795040	about how we have to rethink control policy optimization, even if we're not thinking directly
1795040	1800400	about the body, even if we just focus on the control policy and ask what happens as the input
1800400	1806480	and output channel, the dimensionality of the input and output channels change during behavior
1806480	1814400	execution. Yeah, just one short point on that. It's like training with a fixed set of perceptual
1814400	1820640	elements or of affordances or actuators. It's like training on one point in a larger space of the
1820640	1827200	adjacent possible of bodies or of architectures. So then, okay, we're bringing all this compute
1827200	1834800	to train a special case in the fixed setting. And that's not even how the smallest organism works.
1834800	1841680	So that just again, kind of shows that point. Okay. Sorry, before we move on from that point,
1841680	1847680	just to again, illustrate how the body shapes the way we think. In the case of a growing biological
1847680	1853600	body, there are new input channels that come online throughout our lifetime, but they don't
1853600	1859280	appear de novo. Whatever it is, whatever that new input channel is, as we're growing, we just have
1859360	1868560	more sense cells. The signals that they're sending into the peripheral and central nervous system
1868560	1874960	are not orthogonal to whatever else is already coming in as input, because new input channels
1874960	1881760	or new cells are slowly dividing. And at the moment of division, they're providing exactly the same
1881760	1889040	signal as some other sensory channel that already exists. So the body, or in this case, biological
1889040	1896400	growth provides an immediate scaffold, a gradient. In robotics, it can be very scary to think about
1896400	1902000	like attaching a sensor to an autonomous vehicle. What the hell does it do with this new information
1902000	1908880	that's coming in? Because we haven't thought carefully about how to add that new sense modality
1908880	1917280	to the machine. Again, we have to look to nature that every new sense modality is gradually coming
1917280	1924800	online and gradually drifts away or becomes increasingly orthogonal to the starting input
1924800	1932080	modality. So that's how we should, if we did that physically with machines, it would simplify
1933200	1936960	reinforcement learning or would make it easier for reinforcement learning or what have you,
1938240	1943280	sorry, let me reshare my screen here, it would simply make it easier for the,
1943280	1948480	sorry, something seems to have gone wrong here, give me a moment.
1956320	1963040	Yep. Okay, all right. Yeah, it makes things easier on the control policy optimization process
1963760	1970080	if new sense organs and new motor outputs are coming online, but they resemble things that already exist.
1973280	1979280	That's super interesting. Brings up a lot of questions about like self and non self recognition
1979280	1986560	and what is a self as new and different senses and actions come online. Sure. Okay. Prakash
1986560	1994800	Kavi asks, do these bio bots have any sense of agency? What is your sense? I'm quite intrigued
1994800	2000800	by the idea that beyond a critical point, they start growing hair. And do these bio bots act
2000800	2005520	independently of each other? And also what happens at a group level? So what's your sense
2005520	2011200	of agency in bio bots? And I guess the bio bot and the group level?
2012400	2017440	Yeah, it's a great question. So I'll start with the disclaimer. I'm not a biologist. I'm a computer
2017440	2024720	scientist by formal training. So I can only say so much about what the cells are doing and what
2024720	2034640	they want to do. I definitely follow in the footsteps of the late Daniel Dennett in that
2034640	2039360	when we talk about agency, we each of us individually has to decide whether or not we
2039360	2047200	take the intentional stance or not. It's in my opinion, it's a point of view. If it's easier to
2047200	2055280	explain what the Xenobots are doing by talking about what the cells want to do, like grow cilia
2055280	2062160	and coordinate their actions, fine. If it's easier to explain what the Xenobots are doing by not
2062160	2068560	taking the intentional stance and describing cells as mechanical components that are transforming
2068560	2075920	input into actions, that's fine too. This is something also that comes from my colleague,
2075920	2081520	Mike Levin. It depends. As scientists, if we want to try and explain and understand what these
2081520	2087600	machines are doing, if taking the intentional stance makes explanation easier, fine. If not,
2087600	2095840	then not. But attributing agency is sort of an objective property of the bots or the cells themselves.
2095840	2103520	Independent of us is observers. To me, that's philosophically and practically problematic.
2104480	2112320	As far as I know, there is no objective measure of agency in cells, let alone inorganic robots.
2115280	2120320	Super interesting. That's like the second order cybernetics or the observer theory
2120320	2126080	or the poly computing question, which is to say just looking at something and then
2126080	2132560	treating one's perspective as objectively. The case, it is objectively the subjective experience.
2133600	2138800	Absolutely. Now, that being said, again, there is an empirical side to this. We can make some
2138800	2148400	progress in understanding the Xenobots by comparing them against a control. So instead of cells,
2148400	2156720	if these were magnets or some complex mechanical system in which more of us are comfortable in
2156720	2165920	saying there is no agency, it's just a bucket of cogs doing something, and that control does not
2165920	2171440	exhibit kinematic self-replication, for example, or it's much harder for the AI to figure out how
2171440	2180640	to put together non-agential components to do what it is, then I feel a little bit more comfortable
2180640	2185200	by saying the cells are doing something more. Now, I don't know whether it's agential or they
2185200	2191760	want to do something, or if it's free will or consciousness, I don't know. But if we can point
2191760	2198640	at biobots or machines that are built from biological components and say it's easier to get them to do
2198640	2206560	things because they become complicit in the overall goal compared to mechanical parts,
2206560	2214720	which don't, okay. And again, as a roboticist, the top and the middle rows that you see on my
2214720	2219840	slide here, when we do build things out of metal and rubber and plastics and ceramics,
2220640	2225280	it's usually super hard. It's really hard to get them to do whatever we want them to do.
2226640	2231680	We've been working on robotics since the end of the Second World War, and we've got the Roomba,
2231680	2236880	and maybe we've got autonomous cars, we're getting there. It's taken a really long time
2236880	2243440	because robotics is really hard. It's really hard to convince physical materials to adapt and do
2243440	2248480	something useful and safe. On the flip side, we've been working on Xenobots at the bottom here.
2248480	2254560	We've been working on them for about five or six years, and we've got Roombas. We're making faster
2254560	2262560	progress in robotics when we build from cells than when we build from metal suggests the cells are
2262560	2267200	somehow helping. I don't know that they want to help. We've got to be careful there. That's the
2267200	2275840	intentional stance, but when you try and compose machines from smart machines and cells are smart
2275840	2283200	machines, I know I'm biased, but I think we're making faster progress than when we build machines
2283200	2291840	out of inert materials. Yeah, super interesting. Okay, I'll read some comments from David Clement.
2291840	2301280	David wrote, does your work incorporate a gentile hierarchies? For example, does Xenobots grow by
2301280	2308320	replicating the initial seed cell into a higher order system? And is it critical for lower order
2308320	2314720	systems to act as a component of a virtual machine, meaning that they have a target behavior that is
2314720	2319840	less than the higher order system? And that's kind of related to Prakash's question as well. Like,
2319840	2325920	how do you bridge that from the individual component into the swarm or the aggregate?
2327040	2333840	Yeah, it's a really good question. So, absolutely, I think that when we started working on the Xenobots
2333840	2339680	and Mike Levin started to talk about machines made of machines, made of machines, that definitely
2339680	2345440	has influenced the work in my group to focus on this issue of hierarchy. I don't know about a
2345440	2350560	gentile hierarchy. Again, we just talked about a gentile agency, that's maybe a
2351520	2357600	subjective stance. But definitely, you know, why would you want to build machines out of
2357600	2363760	machines out of machines? At the moment, our state of the art robots, like autonomous vehicles,
2363760	2372160	are not hierarchical. The control policy operates at the level of the machine as a whole.
2372960	2379520	For example, if there's an emergency blowout of the tire, an autonomous vehicle, the tire itself,
2379520	2385840	the rubber that makes up the tire, doesn't deform and try and fix or reduce surprise all locally.
2385840	2392960	It can't. It's rubber. It's inert material. We don't have machines built of machines built
2392960	2399280	of machines yet. But as biology in general and the Xenobots in particular demonstrate,
2399360	2404720	there's an adaptive advantage to being a hierarchy of physical things, of physical machines.
2405760	2409760	If there is a surprising event at the level of the machine as a whole,
2410800	2417760	but that surprise trickles down through the hierarchy, it's unlikely that everyone at every
2417760	2423040	level of the hierarchy is going to be surprised. Someone somewhere in the hierarchy is going to
2423040	2430160	say, from my local view at least on this bigger surprising issue, I know what to do. So let me
2430160	2436720	start to communicate to my peers and up the hierarchy to deal with surprise. That would be,
2437440	2444480	from an engineering point of view, that would be a good thing to have in big, heavy, fast-moving
2444480	2451440	robots that are near humans. There's always going to be some surprising event that the vehicle
2451440	2457040	as a whole has never seen before. There's great YouTube videos of horrifyingly
2458000	2463600	scary surprising edge cases for autonomous vehicles. Okay, we're never going to fix every
2463600	2471920	edge case. What we can fix is to make hierarchies and maybe agential hierarchies where local surprise
2471920	2478400	can be handled or global surprise can be broken down into local surprising events, which can be
2478480	2485920	handled locally. If I understood the second part of your question is how do we design that
2485920	2491840	hierarchy? Should the smaller parts be trying to pull in the same direction or be trying to solve
2491840	2497680	some part of the goal of the higher level? I think that's a super interesting question
2497680	2503920	and I don't think that the answer is obvious. It may be that smaller parts pursuing orthogonal
2503920	2516320	goals may end up being useful. Just to give you a quick example, if there's a surprising event
2516320	2522080	and you've got a whole bunch of semi-independent machines organized in a hierarchy, I would argue
2522080	2527040	that every single one of those members of the hierarchy should have a slightly different
2527040	2531280	body and brain. It should have a slightly different form and function. You don't want a
2531280	2536000	monoculture. You don't want all the parts being smaller versions of the bigger parts
2536560	2543440	and trying to achieve smaller versions of the same goals because then you've basically got
2543440	2549200	a committee in which everybody thinks and feels the same way. As we know from humans, that's a
2549200	2555360	dangerous thing. You get group think or group act. You actually want a hetero culture. You
2555360	2560080	want a whole bunch of things that are unique in terms of form and function and that maximizes
2560080	2564480	your chances that someone somewhere in the hierarchy says, just because of the way I'm
2564480	2570400	built and the way I think with my local control policy, I know what's going on and I have the
2570400	2575680	seed of a solution. Here's the seed. You all figure out what you need to do to make it a
2575680	2581600	reality at the larger level. That's another aspect of where the body comes into play.
2582320	2592240	Yeah. Thank you. Like everywhere is the last mile from somewhere. Things have to be addressed
2592240	2596800	locally. No matter how you think about a communications architecture distally,
2597680	2603440	everything and embodiment calls our attention back to that. It has to be somewhere locally.
2603440	2609360	So then why not take that as the starting point instead of this resource challenge
2609360	2618400	and then about the multiple subunits when there's a damage to the nest of an ant colony or
2618400	2624720	there's some things spilled on the surface. It's not that every single nest makes a perfect
2624720	2632960	pebble move. It's that 51% accuracy with a bunch of nonspecific flurrying of activity,
2632960	2638880	just like kind of stress or these more generic higher order signaling. That is what allows
2639440	2645680	nest mates with different brains and bodies to fulfill their own paths of least action.
2645680	2651440	And then colonies for which that doesn't clean up the mess or it cleans up too well and there's
2651440	2656800	externalities, those colonies are swept off a table. And then we see the persistence of
2656800	2662800	collective systems that could figure that out in their growth from a little colony to a big colony
2663760	2670800	Absolutely, great, great example. I had a question you mentioned, both safety as well as
2670800	2680240	like reliability. And how do you think about capacities and evaluations on diverse intelligences?
2680800	2688240	We're all familiar with RAM, CPU, hard drive storage, some of the von Neumann type architectural
2688320	2695440	descriptors. However, how do we even think about what does that rubric or report card
2695440	2700160	even start to look like when we know that there's complex interactions with the niche
2700160	2704240	and when the kinds of capacities that we're talking about may have even open-endedness?
2705520	2712320	Yeah, great point, great point. So we are the beneficiaries of two big revolutions,
2712320	2717360	one of them is the AI revolution, but then the older one is the digital electronics revolution.
2718480	2723760	Digital electronics works, we all have a super computer in our pocket, like there's no arguing
2723760	2729840	with it. It's an incredibly powerful way to make machines that internally communicate quickly and
2729840	2736560	richly and then can communicate with other machines. I mean, that's it, that's the information age
2736560	2743440	that we're in. It's been so successful that it's hard to think about alternatives or why we would
2743440	2750960	even bother thinking about alternatives. But again, living systems, a lot of what cells do,
2750960	2756480	they rely on electrical communication, but they also rely on mechanical communication,
2756480	2764800	chemical communication, thermal communication. Cells are using all physical modalities,
2764800	2770720	not all physical modalities, as many as they can get their hands on simultaneously all the time.
2770720	2775040	Why? Why don't they just abandon everything and do everything purely electrically,
2775040	2780640	like our modern civilization has done? Because it's dangerous, you don't have a diversified
2780640	2786800	portfolio. So one panel here that I haven't talked about is the one in the bottom right,
2787360	2794000	which is basically just what you're looking at is what's called a granular material. It's a material
2794000	2799120	that's made up of a bunch of grains. In this case, the blue circles that you see, these are little
2799120	2806240	just rubber pucks. And there is an oscillation being supplied at the left hand side. And you can
2806240	2814000	see that this leads to interesting non-linear vibrational behavior within this material.
2814560	2821280	What does that have to do with robotics or AI? If you view the vibrations as the carrier of
2821280	2828640	information, so if a puck is vibrating, that's a one. If the puck is not vibrating, that's a zero.
2829840	2835440	Now you can start to imagine creating materials that communicate Shannon information
2836240	2842880	throughout the physical structure, not with electricity, but with a different modality,
2842880	2850080	dynamics or vibration. And it turns out that you can actually compose these meta materials to
2850080	2857600	embody logic gates. If you vibrate one particle or another particle, but not both and not neither,
2857680	2864000	you can watch a third particle and it will either vibrate or not in accordance with an exclusive
2864000	2871360	OR gate. And you can build this up. Now again, why would you do that? We can make an XOR gate
2871360	2876800	that's vanishingly small and vanishingly fast in digital electronics. Why would you ever want to
2876800	2883680	do something different? Because it turns out there are advantages of communicating with vibration
2883680	2890000	rather than electricity under certain conditions. Having a machine that can communicate between
2890000	2895840	distant parts of its body through mechanical vibration as well as electricity has an advantage
2895840	2902640	over a machine that can only communicate long distances within its body electrically. I won't
2902640	2908320	go into the reasons, but you can intuitively start to understand that. So again, I think we need to,
2908880	2915280	if we're serious about creating safe and useful autonomous machines, we have to break out of the
2915280	2920400	digital electronics assumption that that's the only way to do things. We have to break out of
2920400	2926160	the assumption that non-embodied cognition is the way to go and it's easy to just drop it into a
2926160	2931920	physical body and we're good to go. We have to peel back some of these very deep assumptions about
2931920	2937200	the right way to do things that have built up in our society since the Second World War,
2937200	2942160	because a lot of those technologies have been very successful, nothing wrong with them. But when
2942160	2949120	we come to apply them to creating safe and useful machines, not always the right thing or the only
2949120	2957280	way to approach things. That's really interesting. It's like a sort of generalized compute concept
2957280	2963840	where we could talk about, well, these are the chemicals that it can detect with this fidelity
2963840	2969120	and here's its tactile interface, here's its electromagnetic capacity for sending and receiving.
2969120	2976240	That's what kind of motivates or complements the generic theory like free energy principle,
2976240	2982240	which doesn't tell us about how anything is in particular, but then sets us up with kind of
2982240	2989440	the framework to plug in these different modules. And then it's an empirical question. And then
2989440	2999120	right here is sort of the virtual body and a real body. And so that's also very interesting.
2999760	3007280	How does that work in a collaboration or with a graduate student? How do you balance
3007920	3017760	this digital adjacent possible off of the material and the more costly implementation with embodiment?
3018720	3024480	Yeah, well with grad students and postdocs or whoever I'm collaborating with that's kind of
3024480	3029520	starting out, this can be a very frightening prospect for someone who's trying to get into
3029520	3035920	AI and robotics because it looks like everything's been done, it's solved. We just have to wait for
3035920	3042160	Google and Microsoft to buy more compute and data and they're going to finish off the last 1% of
3042480	3049920	dangerous behavior. So if you're trying to contribute to society's goal of making useful
3049920	3056400	autonomous safe machines as starting out, what do you do? It looks like this massive brick wall,
3056400	3063120	there's no entry point. So my take on this is again is that we may be going about this all wrong,
3063120	3069920	right? The assumption that electricity should be the carrier of information inside an autonomous
3069920	3076160	machine, that's an assumption. Why electricity? Why not vibration? Why not something else? So
3077440	3081520	even if you start to think about the alternatives, the immediate reaction as well, it's not going to
3081520	3087520	be as good, maybe, maybe. But if you think about vibration, you were just mentioning like compute.
3087520	3094560	We can use vibration for compute, but vibration is movement. So the minute you start to think
3094560	3101120	about vibration as the carrier of Shannon information, you're now conflating action with
3101120	3109120	computation. They cannot be separated. Descartes convinced the West 400 years ago that they're
3109120	3118480	separate. They just are. And you look at AI and robotics, what a surprise. These two are attempts
3118560	3125680	to create, you know, AGI is bicameral. There's one team that says it's going to happen in computers
3125680	3131280	and the other side that says it's going to happen in physical machines. That's the Cartesian legacy,
3131280	3136160	that they're separate. But the minute you look at some very humble material like the one in the
3136160	3142560	bottom right, it's a bunch, it's 12 hockey pucks next to one another. There's no Cartesian division
3142560	3148720	anymore between body and brain. There is a body and there is a brain there, but it looks very
3148720	3156720	different from anything we would usually consider. And there's no value judgment here. It's not
3156720	3163600	better or worse, maybe it is depending on what your metric is. It's just very different. And so
3163600	3170400	with grad students and postdocs, I encourage them to pursue that. Could we do things completely
3170400	3177120	differently? And in the long run, might that be a better way to do things? Who knows? We'll see.
3178880	3185120	Awesome. I'll make one comment and then ask a last question. You brought up Descartes and that's
3185120	3194560	the rest extensa, rest cognitive dualism between the thinking and the non-thinking substance and
3195120	3202800	embodied cognition, embodied intelligence provides both an operational, instrumental,
3202800	3209200	and an ontological counter argument or complementary perspective, which is just, well,
3209200	3216640	in practice and in actuality, take it or leave it, they are inseparable. And so at the very least,
3216640	3222640	that that starts to ratchet and leapfrog the discussion about what is mind and body.
3223440	3229200	And you started with pointing out how important it was to co-evolve and the complementarity of
3229200	3233520	mind and body. And it's like, there are two separate things that need to be complementary
3233520	3241120	and tangoing. And also, maybe they're integrated and blurred in even deeper ways than the dance.
3241120	3248800	So it's an empirical entry point into what otherwise is a thought experiment, which can
3248880	3256240	have utility, but also can be just arbitrarily misleading. Absolutely. One of my former mentors,
3256240	3261600	Inman Harvey at the University of Sussex, used to talk about robotics as philosophy with a screwdriver.
3262960	3267040	It's not just armchair philosophy. It's when you start to build some of these machines,
3267600	3273280	maybe in retrospect, in the case of the Metamaterials project, for me in retrospect,
3273280	3278640	I said, oh my God, most action and cognition are not complementary, separate things that
3278640	3283440	are complementary. They're one and the same thing. It's not embodied cognition. It's not
3283440	3291600	an adjective of a noun. It's embodiment is cognition. There are not two things here.
3291600	3297760	There's just one thing. Very hard to think about. It's so alien to a Western mind, but
3298880	3304640	it just is. Sometimes I think about that in terms of adjectives getting added in front of a word
3304720	3311680	and then the term expanding, and then it just encompassing, oh, of course, cognition is ecological,
3311680	3316080	embodied, enacted, et cetera, et cetera, et cetera, et cetera. And then so it kind of like needs to be
3316080	3325200	distinguished. And then it subsumes again. And that's part of in closing, like, what are you excited
3325200	3331840	about? Where can people continue to learn more? What would you say to a person who's wanting to
3331840	3341520	like go in this area? Yeah. Okay. Great question. So Google my name and it'll take you into lectures
3341520	3347200	and papers and tutorials. And people want folks want to email me. That's perfectly fine. Again,
3347200	3350720	Google my name. You can find my email. Happy to put you in touch with the right people.
3352240	3357520	I think it's, you know, it's easier than ever to get started. You can go to chat GPT and say,
3357600	3364720	you know, create some tutorials for me to start coding up robots. You know, they're, ironically,
3364720	3370640	non embodied AI provides a good on ramp now, not just for reading about these ideas or listening to
3370640	3376480	people talk about these ideas. You can start coding them up in a way that was easier than ever.
3376480	3381040	That's easier than ever. The old days, you know, you had to learn C and then, you know,
3381040	3386960	go on from there. Very easy to get your hands dirty, maybe not with physical materials,
3386960	3392480	but you can create like you see in the left of each of these panels. You can create machines that
3392480	3397280	are virtual. They're not physical, but they're embodied. It's another point that's important
3397280	3404240	to make embodiment does not imply physicality. You need to be able to push against the world and
3404240	3409600	observe how the world pushes back, but the world and you may be virtual like you see on the left
3409600	3415520	or physical like you see on the right. So you can actually relatively quickly get your hands dirty
3415520	3421440	with playing around with embodied AI these days. And I encourage everyone to do so.
3422880	3424880	Cool. Any last comments?
3426320	3432800	I would just say I was at the computer vision and pattern recognition conference CVPR a few
3432800	3438720	weeks back. This is one of the flagship AI conferences, 15,000 attendees. And after my
3438720	3442880	talk, a lot of grad students came up and they said, listen, I, you know, you, you sort of
3442880	3448000	demonstrated there's another path here that I was feeling depressed or anxious about how to make
3448000	3453440	progress in AI when these goliaths are, you know, have these data centers at their beck and call.
3454160	3460160	I would just encourage everyone that when you think differently about all this stuff,
3460720	3465520	there are new paths that open up. They may not in the long run be the right path, but there are
3465520	3472080	alternatives to this monolithic predict the next token idea, which is currently, you know,
3472080	3478960	in vogue. It's, it may be the beginning of the end, but I think this is just the end of the
3478960	3484080	beginning. We've, we figured a few things out. There are some things that work, but they're
3484080	3490160	still producing not quite useful and definitely dangerous machines. There is room for improvement.
3490160	3495120	And there's nothing that says that only Google, Google with all its resources is going to be the
3495120	3500720	one that can figure out these improvements. Think differently, try some of these alternative
3500720	3508800	approaches and maybe you will be the one, you know, that comes up with the answer, whatever it is.
3509840	3516240	Cool. Good luck. Awesome. Thank you, Josh. Really appreciate it. Thanks for having me.
3516240	3522000	Yeah. And until next time. Thank you. Bye.
3530720	3532100	you
3560720	3562100	you
