WEBVTT

00:00.000 --> 00:30.000
ლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლლ�

00:30.000 --> 00:32.000
ლლ-ლლლლლლლ어얼leლ

00:32.000 --> 00:36.060
Opport.

00:36.060 --> 00:55.520
Hello, everyone. Welcome to ActonFlab livestream 25.0. Today is July first 2021. And we're going to be talking about this paper, the computational boundary of a self. Developmental bio-electricity drives multi-cellularity and scale-free cognition.

00:55.520 --> 00:58.700
I'm blue, and I'm here with Daniel. bill.

00:58.700 --> 00:59.960
Awesome.

00:59.960 --> 01:11.960
So, welcome to the Active Inference Lab, everyone. We are a participatory online lab that is communicating, learning and practicing applied active inference.

01:11.960 --> 01:21.960
You can find us at the links here on this page. This is a recorded and archived live stream, so please provide us with feedback so that we can improve our work.

01:21.960 --> 01:27.960
All backgrounds and perspectives are welcome here. We will be following good video etiquette for live streams.

01:28.960 --> 01:36.960
Here at the short link, you'll find all of the live streams and different series that we do in the communications unit of the Active Inference Lab.

01:36.960 --> 01:56.960
And today, we're doing the contextualizing paper, the .0 video for two upcoming discussions in the first half of July 2021 on the 6th and the 13th, when we have discussions 25.1 and 25.2 on this paper and hopefully the author joining.

01:57.960 --> 02:05.960
Today, in Active Lab live stream 25.0, we're going to be trying to set some context and give an introduction to the following paper.

02:05.960 --> 02:13.960
The computational boundary of a self, developmental bioelectricity drives multicellularity and scale-free cognition by Mike Levin.

02:13.960 --> 02:18.960
And this video is just an introduction to some of the ideas. It's not a review or a final word.

02:18.960 --> 02:28.960
It's kind of like a three-way intersection where we have people who might be within the Active Inference community looking to be exposed to some different areas like developmental biology or cognitive science.

02:28.960 --> 02:36.960
And then another group of people who are coming from the developmental biology or cognitive science background and curious about active inference.

02:36.960 --> 02:45.960
And then also we hope that this is exciting and interesting even for people who are not familiar with active inference or developmental biology or cognitive science.

02:46.960 --> 02:52.960
We will hopefully try to connect it with some broader questions.

02:52.960 --> 03:08.960
So we're going to walk through some of the aims and claims of the paper, the abstract and the roadmap and bring a few big questions and some key points of the paper so that whether you read the paper or not, you'll hopefully be in a good spot to ask questions and learn more.

03:08.960 --> 03:20.960
And of course in the .1 and .2 videos in the coming weeks we'll be discussing the same paper. So save and submit your questions and let us know if you'd like to participate or contribute in any way.

03:20.960 --> 03:32.960
So here we are on the paper itself. That's a screenshot of the cover and the aims and claims and I'll read them so that then Daniel you can give a first thought on what you thought was cool or what you thought was important about the paper.

03:32.960 --> 03:34.960
So the aims and claims of the paper.

03:35.960 --> 03:46.960
First, they define individuals and selves in a way that facilitates taxonomy, comparison and communication with evolved, created biological, artificial and exobiological agents.

03:46.960 --> 04:01.960
He says, I propose a fundamental definition of an individual based on the ability to pursue goals at an appropriate level of scale and organization and suggest a formalism for defining and comparing the cognitive capacities of highly diverse types of agents.

04:02.960 --> 04:14.960
Second, he proposes a plausible naturalistic framework for the evolutionary scale-up of cognition from the earliest origins of life, hypothesizing about the forces that drove it and the major transitions along the continuum.

04:14.960 --> 04:22.960
And the goal of this research program is to show how complex agency and goal-directedness evolves naturally from ancient mechanisms.

04:22.960 --> 04:24.960
So Daniel, what do you think about that?

04:26.960 --> 04:27.960
Nice work.

04:27.960 --> 04:39.960
Well, I thought the paper was pretty exciting because it touches on just so many big topics like goal-setting and agency, cognition and natural and artificial systems, multi-scale systems.

04:39.960 --> 04:52.960
And then it links it in a way that people might not expect, which is through developmental biology and bioelectricity, which are kind of like processes that these life forms or other forms engage in.

04:52.960 --> 05:09.960
So to be able to connect things that are awesome about systems that matter, like, again, their goal-seeking nature, their ability to do cognition, and then connect that to a process theory, it's kind of what we're all about in active inference, connecting the cool features of the world to process theories that are tractable.

05:09.960 --> 05:10.960
Cool.

05:10.960 --> 05:15.960
So moving on to the abstract, I'll read the first part and then you can read the next slide.

05:15.960 --> 05:21.960
So all epistemic agents physically consist of parts that must somehow comprise an integrated cognitive self.

05:21.960 --> 05:30.960
Biological individuals consist of subunits, organs, cells and molecular networks that are themselves complex and competent in their own native contexts.

05:31.960 --> 05:37.960
How do coherent biological individuals result from the activity of smaller subagents?

05:37.960 --> 05:52.960
To understand the evolution and function of metazone creatures, bodies and minds, it is essential to conceptually explore the origin of multicellularity and the scaling of basal cognition of individual cells into a coherent, larger organism.

05:52.960 --> 06:05.960
So I find this line of research truly fascinating and really a burning question for me is how information is consolidated or prioritized across scales, whether it's coarse-graining or salience or something else.

06:05.960 --> 06:07.960
So do you want to read the next part?

06:07.960 --> 06:11.960
Yep, just one thought on that and it's going to be a theme that's returned to.

06:11.960 --> 06:18.960
It's that cognition or agency doesn't just blink into existence at a larger level of analysis.

06:18.960 --> 06:30.960
It's actually composed of smaller cognitive units and so it's kind of like cognition all the way down that helps us integrate across scales but also recognize what's special about larger levels of organization like culture.

06:30.960 --> 06:33.960
So part two of the abstract.

06:33.960 --> 06:46.960
In this article, I synthesize ideas in cognitive science, evolutionary biology and developmental physiology towards a hypothesis about the origin of individuality, scale-free cognition.

06:46.960 --> 07:02.960
I propose a fundamental definition of an individual based upon the ability to pursue goals at an appropriate level of scale and organization and suggest a formalism for defining and comparing the cognitive capacities of highly diverse types of agents.

07:02.960 --> 07:11.960
Any self is demarcated by a computational surface, the spatial temporal boundary of events that it can measure, model and try to affect.

07:11.960 --> 07:19.960
The surface sets a functional boundary, a cognitive light cone, which defines the scale and limits of its cognition.

07:19.960 --> 07:36.960
I hypothesize that higher level goal directed activity and agency resulting in larger cognitive boundaries evolves from the primal homeostatic drive of living things to reduce stress, the difference between current conditions and life optimal conditions.

07:36.960 --> 07:52.960
So I like this goal directed like aspect of this and it really kind of implies to me that the it's like biological cognition has to be biological but I wonder about like, you know what is the goal of molecules in their like organization right is that

07:52.960 --> 08:04.960
like a goal directed activity like the protons and neutrons and electrons want to like reduce their uncertainty about where they are in space or how does it work at like a non biological level makes me wonder that.

08:04.960 --> 08:20.960
Or strain strain and stress, those are things we psychologically experienced but then you can have you know like a ring with four carbons it's under strain and the carbons they seek to do what well get into a less stressed position like a unstrained arrangement.

08:20.960 --> 08:45.960
For sure. The next part, the mechanisms of developmental bio electricity, the ability of all cells to form electrical networks the process information suggest a plausible set of gradual evolutionary steps that naturally lead from physiological homeostasis in single cells to memory prediction and ultimately complex cognitive agents via scale up of the basic drive of info taxes.

08:45.960 --> 09:00.960
Recent data on the molecular mechanisms of pre neuro bio electricity suggest a model of how increasingly sophisticated cognitive functions emerge smoothly from cell to cell communication used to guide embryogenesis and regeneration.

09:00.960 --> 09:19.960
This set of hypotheses provides a novel perspective on numerous phenomena, such as cancer and makes several unique testable predictions for interdisciplinary research that have implications not only for evolutionary developmental biology, but also for bio medicine and perhaps artificial intelligence and exo biology.

09:19.960 --> 09:23.960
Do you have any thoughts on that Daniel.

09:23.960 --> 09:33.960
I guess it's just cool to see development and cognition come on to equal grounding because there was ecology evolution and development eco evo divo.

09:33.960 --> 09:43.960
And then it's sort of that's natural things happening and then often cognition and especially computational perspectives on cognition are seen as unnatural or designed.

09:43.960 --> 09:54.960
And so again, all of these pieces are going to be woven together with a few pieces like bio electricity and light cones that maybe people aren't expecting.

09:54.960 --> 09:55.960
Cool.

09:55.960 --> 10:02.960
So the roadmap of the paper, we're going to go through the introduction, then the papers broken up into lots of different parts.

10:02.960 --> 10:03.960
What is a self?

10:03.960 --> 10:12.960
How do you define an individual body patterning cognition multi cellularity versus cancer defining individuation from a cognitive perspective.

10:12.960 --> 10:21.960
The agents evolutionary backstory conclusion future outlook discussion and then some predictions and research program.

10:21.960 --> 10:28.960
And then in the end, what does it feel like to be a pancreas, which I renamed that part, but maybe you changed it back.

10:28.960 --> 10:29.960
So we'll see.

10:29.960 --> 10:32.960
Do you want to read over the keywords.

10:32.960 --> 10:45.960
Here's the provided keywords were development bio electricity and the related gap junctions primitive cognition and our favorite active inference.

10:45.960 --> 10:52.960
So development, I like this quote from Seth Smith, Seth, Mary and Maynard Smith, which I can never say yours is last name.

10:52.960 --> 10:53.960
I feel bad.

10:53.960 --> 11:01.960
Sorry, yours developmental biology can be seen as the study of how information in the genome is translated into the adult structure.

11:01.960 --> 11:06.960
And evolutionary biology of how the information came to be there in the first place.

11:06.960 --> 11:09.960
So that's a kind of cool definition of development.

11:09.960 --> 11:12.960
Do you have any thoughts on that?

11:12.960 --> 11:20.960
It reminds me of earlier discussions we had about Tim Bergen's for wise, which are kind of related to Aristotle's for wise.

11:20.960 --> 11:22.960
It's like, why is there a foot?

11:22.960 --> 11:26.960
Well, the easy sort of material answers because there's matter in the shape of a foot.

11:26.960 --> 11:29.960
But maybe you want to know something that's historical.

11:29.960 --> 11:35.960
And over really long periods of time, it's a story about evolution, how the foot came to be selected on through time.

11:35.960 --> 11:43.960
But development is just right there in the middle where it's the story for that individual, how that foot came to be.

11:43.960 --> 11:46.960
Thanks said, blue, could you turn down my mic?

11:46.960 --> 11:49.960
It apparently is a little louder distorted.

11:49.960 --> 11:50.960
Thank you for the feedback.

11:50.960 --> 11:57.960
Yeah, if anybody has comments on like the audio, blue is doing an awesome job of first broadcaster role.

11:57.960 --> 11:58.960
Cool.

11:58.960 --> 11:59.960
All right.

11:59.960 --> 12:02.960
Hopefully that's a little bit better.

12:02.960 --> 12:05.960
All right.

12:05.960 --> 12:06.960
Bioelectricity.

12:06.960 --> 12:09.960
So this is a quote from the paper.

12:09.960 --> 12:17.960
Developmental bioelectricity is the ubiquitous exchange of slowly changing ion based voltage signals within and among cells.

12:17.960 --> 12:26.960
All cells are electrically active and modern neurons evolved from preneural precursors that were already reaping the benefits of ionic signaling for competition.

12:26.960 --> 12:28.960
Computation.

12:28.960 --> 12:30.960
Ionic signaling for computation.

12:30.960 --> 12:32.960
So there's some ion channels.

12:32.960 --> 12:36.960
I like that cool, like digital image of ion channels and cells.

12:36.960 --> 12:44.960
And of course, this painting by Alex Gray, like isn't officially bioelectricity, but whenever I think of the word bioelectricity, I always think of this picture.

12:44.960 --> 12:46.960
Do you have any thoughts?

12:46.960 --> 12:54.960
And to connect the developmental aspect to what is mentioned here about the cells being electrically active.

12:54.960 --> 12:58.960
The neural tissue arises during development from neuroectoderm.

12:58.960 --> 13:05.960
So before there was sort of an inner layer of these electrically specialized cells, the ones that we call neurons.

13:05.960 --> 13:13.960
There was an outer layer and we see that recapitulated in embryogenesis when the neural tube is closed.

13:13.960 --> 13:26.960
So that's combining sort of ontogeny recapitulates phylogeny, which is just to say that the development of the organism carries some resonance with the way that the organism evolved through time.

13:26.960 --> 13:32.960
And then just to remind that every cell has those pumps that maintain charge.

13:32.960 --> 13:44.960
All of them are involved in rapid fire signaling, but to maintain ionic gradients and therefore bioelectric gradients is essentially what cells do with their membranes.

13:44.960 --> 13:48.960
Cool, and awesome segue into talking about gap junctions.

13:48.960 --> 13:52.960
So this is like something that's near and dear to my heart with my neuroscience background.

13:52.960 --> 13:57.960
So gap junctions were originally attributed to neurons.

13:57.960 --> 14:03.960
Like gap junctions are there at the synapse and they facilitate the electrical signaling between neural cells.

14:03.960 --> 14:09.960
But really they're channels that permit cell to cell transfer of ions directly.

14:09.960 --> 14:17.960
And they were originally described in nerve and muscle, but they're really found in virtually all cells that are present in solid tissues.

14:17.960 --> 14:25.960
And then I just did a quick like brief look up of a recent review of gap junctions and it's cool like they're involved in all kinds of things, right?

14:25.960 --> 14:39.960
Like so cell proliferation, immune response, migration, optosis, carcinogenesis, hyper proliferative skin disorders, lymphatic vessel diseases, inflammatory lung diseases that's like asthma, liver injury and neoplastic disorders.

14:39.960 --> 14:41.960
That's also cancer.

14:41.960 --> 14:45.960
So I thought that that was kind of a neat thing.

14:45.960 --> 14:48.960
Any thoughts on this one, Daniel?

14:48.960 --> 14:54.960
Just that active inference helps us think about how agents communicate and interact.

14:54.960 --> 15:01.960
So if there's two cells and they have totally disjoint membranes, then they can both modify a niche in common.

15:01.960 --> 15:07.960
So they could pump ions in and out of the fluid like the extracellular matrix that's surrounding the cells.

15:07.960 --> 15:09.960
So there's a common niche that they're sharing.

15:09.960 --> 15:11.960
That's like the least connected they could be.

15:11.960 --> 15:17.960
And then there are also ways in which they can have a long term connection with a higher throughput.

15:17.960 --> 15:33.960
So we're seeing a lot of these ideas of communication where we can talk about these two agents now directly exchanging information with each other as their electrochemical niche rather than just jointly modifying the shared fluid that they're in.

15:33.960 --> 15:35.960
Cool.

15:35.960 --> 15:42.960
Okay, next.

15:42.960 --> 15:45.960
All right, primitive cognition.

15:45.960 --> 15:49.960
Let's see if I can play this video. Did you want me to play it?

15:49.960 --> 15:51.960
Sure, if it works on your side.

15:51.960 --> 15:54.960
Let's see it.

15:54.960 --> 15:58.960
Perfect.

15:58.960 --> 16:04.960
Role of actin and cell motility, stunning 3D animation.

16:04.960 --> 16:09.960
Maybe we don't need the sound.

16:09.960 --> 16:24.960
Well, what is written in the paper is the emerging field known as basal cognition tracks the evolutionary history of learning and decision making processes beginning from the dynamic problem solving capacities of cellular and subcellular forms.

16:24.960 --> 16:38.960
Many examples of memory, anticipation, context dependent decision making and learning are exhibited by organisms from yeast and bacteria to plants and somatic cells.

16:39.960 --> 16:44.960
So down at the bottom, what does cognition or intelligent behavior look like across scales?

16:44.960 --> 16:50.960
Where and how does cognition arise and how does it develop or evolve convergent and divergent features?

16:50.960 --> 16:55.960
And where does active inference come into play?

16:55.960 --> 17:13.960
I think that first question is fun because it's a little easy to off the cuff just say, well, I don't recognize the intelligence of a cell because it's not, you know, doing an undergrad course, or it's not doing skillful performance like we talked about in a previous discussion.

17:13.960 --> 17:20.960
So will we have a human centric conception of intelligence tied up with all of our cultural understandings?

17:20.960 --> 17:26.960
Or is there something about intelligent behavior that might help us recognize it across scales?

17:26.960 --> 17:32.960
And that's what turns us to these fundamentals like memory, anticipation, context dependent decision making.

17:33.960 --> 17:40.960
And then once we open up to that functional level of intelligent behavior and cognition, we start seeing it everywhere.

17:40.960 --> 17:51.960
And so instead of just seeing these cells and their behavior as taking part of an intelligent system that again only blinks into existence at the top level, they're in and of themselves intelligent actors.

17:53.960 --> 17:54.960
Awesome.

18:03.960 --> 18:05.960
The video got me locked in here, sorry.

18:08.960 --> 18:10.960
How about that? You want to take us through that slide, Daniel?

18:11.960 --> 18:14.960
Yep, so it's written in the paper.

18:14.960 --> 18:19.960
I propose, well, we'll come back to, I'll give you a second.

18:19.960 --> 18:29.960
At the top, it's written, developmental bio electricity is the ubiquitous exchange of slowly changing ion based voltage signals within and among cells.

18:29.960 --> 18:34.960
All cells are electric electrically active, and we talked about that just a few slides ago.

18:34.960 --> 18:36.960
How ancient are these mechanisms?

18:36.960 --> 18:40.960
How early was bioelectric coordination exploited by evolution?

18:40.960 --> 18:47.960
So this is raising the notion that early cognition was biomechanical, it was biophysical.

18:47.960 --> 18:58.960
It involved morphological computation like we saw on the previous slide with the movie of cells, but also electrical affordances existed from the beginning.

18:58.960 --> 19:16.960
And so if biophysical affordances existed from the beginning and allowed for cognition to arise, then it makes just as much sense to say that electrical affordances for cells to communicate and do these types of cognitive processes also were exploited very early in evolution.

19:17.960 --> 19:29.960
So primitive, meaning at a smaller level, but also earlier on, and suggesting that it's bioelectric was one of the earlier mechanisms of cognition is pretty cool.

19:31.960 --> 19:45.960
And I like this quote from the paper that says the ability to operate toward a region and state space may be the primitive origin of complex cognitive systems that can entertain counterfactuals, which is to remember or anticipate events that are not occurring right now.

19:45.960 --> 19:49.960
So we'll touch back on homeostasis, but how are the goals related to homeostasis?

19:49.960 --> 19:52.960
How does bioelectricity play a role in homeostasis?

19:52.960 --> 19:54.960
And I think we come back around to that.

19:59.960 --> 20:08.960
On 17, I wanted to give an example about where bioelectricity and development came together with cognition.

20:08.960 --> 20:15.960
And for some people, genetic reductionism makes it so that, you know, the story is not complete until we know what gene is involved.

20:15.960 --> 20:37.960
And I think that they'd find this recent 2021 paper from Drosophila fruit flies to be really interesting, because what they do with a series of experiments is actually demonstrate the importance of membrane depolarization, which is to say bioelectric capacity in gene regulatory networks.

20:37.960 --> 20:50.960
So like H H and PTC are proteins that are produced by loci and DNA, and they're part of feedback loops involving the depolarization of membranes.

20:50.960 --> 21:01.960
So they show that regulation of that membrane potential has an important role in signaling hedgehog and that there's a mutually reinforcing relationship between these two processes.

21:01.960 --> 21:11.960
And then what does that allow? Well, it allows morphological computation of this developing disk of the fly that later turns into the wing.

21:11.960 --> 21:23.960
And so there's advantages and disadvantages like with diffusible molecules, there's a tremendous amount of expressivity with what that molecule is like you have an infinite number of hormone possibilities.

21:23.960 --> 21:26.960
But on the other hand, it's very slowly diffusing.

21:26.960 --> 21:29.960
And maybe you can only signal a short range.

21:29.960 --> 21:32.960
On the other hand, there's only like one electricity.

21:32.960 --> 21:38.960
There's not like the blue membrane potential and the pink membrane potential as parallel membrane potential.

21:38.960 --> 21:40.960
There's only one membrane potential.

21:40.960 --> 21:42.960
So it's kind of a big knob to turn.

21:42.960 --> 21:48.960
However, as shown here, it really does play a functional role in stabilizing gene regulatory networks.

21:48.960 --> 21:54.960
If you were missing that part of the puzzle, it would be as incomplete as if you were missing a critical signaling molecule.

21:54.960 --> 22:06.960
So I suspect that as advances, the kind that are going to be referenced in this paper, advances in being able to visualize and track and manipulate bioelectric fields become more accessible,

22:06.960 --> 22:15.960
that more and more systems that were thought to be purely chemical or purely mechanical, I think that they'll be a more important role for bioelectricity.

22:15.960 --> 22:19.960
Right. It is like one big surface, one membrane potential.

22:19.960 --> 22:30.960
So you have one membrane and that's like the differentiator right between that's the boundary right is what is enclosed or encapsulated in the membrane versus what is not.

22:30.960 --> 22:32.960
Okay, so here we are active inference.

22:32.960 --> 22:45.960
This is the final keyword and I pulled this image out from the active inference lab, a previous live stream that we did with Ines and Thomas or Thomas.

22:45.960 --> 22:49.960
So this is the free energy principle computation and computationalism and realism and tragedy.

22:49.960 --> 22:53.960
And so this is just the basic action perception loop.

22:53.960 --> 22:58.960
So you have active states, external states, sensory states and internal states.

22:58.960 --> 23:04.960
And so the both of the active states and the sensory states are the blanket states, right.

23:04.960 --> 23:10.960
So you have the the internal connect on the external via these two blanket states.

23:10.960 --> 23:19.960
So this is all of the sensory perception of the organism and the degree on which they're able to act on the environment.

23:19.960 --> 23:23.960
Do you want to add any thoughts here, Daniel?

23:23.960 --> 23:30.960
Just that active inference is a unifying framework for thinking about perception, cognition and action.

23:30.960 --> 23:36.960
And it does that in a scale free way that's grounded in Bayesian statistics and physics.

23:36.960 --> 23:42.960
So it's going to be deployed as a way to help us look for different kinds of behavior across scales,

23:42.960 --> 23:48.960
because the internal state could be internal to a cell, it could be internal to a tissue, internal to the organism, etc.

23:48.960 --> 23:55.960
And it's that expressivity of the active inference framework that is going to come into play in the paper.

23:55.960 --> 24:01.960
Awesome, and it's a process, a scale free process.

24:01.960 --> 24:06.960
Okay, active inference as brought up in this paper.

24:06.960 --> 24:13.960
The author says agents scaled up by evolving from basic homeostatic loops driven by active inference,

24:13.960 --> 24:20.960
surprise minimization via addition of delays, which are memory, anticipation, which is inference and networks,

24:20.960 --> 24:27.960
spatially distributed processing that enables learning and progressive abstraction or generalization from the data.

24:27.960 --> 24:34.960
Gathering into larger collectives with optimal information structure also improves the computational i.e. predictive capabilities

24:34.960 --> 24:40.960
and gives rise to functional relationships such as memories, encoded goal states, test, operate, test, exit loops

24:40.960 --> 24:43.960
that exist over and above any individual member.

24:43.960 --> 24:51.960
These levels coexist, enabling numerous coherent selves of different scales to be implemented by any collection of living matter.

24:52.960 --> 24:56.960
That's intense.

24:56.960 --> 25:08.960
One of the other pieces about active inference that differentiates it from a framework like reinforcement learning is right there that there's the minimization of surprise.

25:08.960 --> 25:17.960
And in order to minimize surprise through time, you kind of have to be doing two things that at first pass don't seem like they're going to facilitate each other,

25:17.960 --> 25:21.960
which is the pursuit of what you already know is going to be useful.

25:21.960 --> 25:27.960
That's called pragmatic value, as well as the pursuit of sampling things that will be informative.

25:27.960 --> 25:29.960
That's epistemic value.

25:29.960 --> 25:35.960
And so in active inference, the way that agents through deep time minimize their surprise about perception,

25:35.960 --> 25:40.960
that's what's referenced in the top paragraph about perceptual control theory,

25:40.960 --> 25:56.960
the way that the agents minimize their surprise about their future expectations of perception is going to be by jointly working on pragmatic and epistemic aspects of their behavior

25:56.960 --> 26:06.960
and thinking about what behavior is going to be minimizing free energy in terms of kind of existing on the optimal trade off where you're performing, but also learning.

26:06.960 --> 26:09.960
So these are a few features of active inference that differentiate it.

26:09.960 --> 26:14.960
And then if we think about like a growth cone of a neuron, is it doing reinforcement learning?

26:14.960 --> 26:16.960
Is it doing reward maximization?

26:16.960 --> 26:18.960
It just barely makes sense.

26:18.960 --> 26:25.960
But once we start to think about surprise minimization, like it's a dad with an evolutionary prior, it expects to connect to a neuromuscular junction.

26:25.960 --> 26:29.960
Then maybe some of its searching behavior makes more sense.

26:30.960 --> 26:37.960
And in the top section also the author, you know, states that the sensory input layer is what enables active inference to operate.

26:37.960 --> 26:43.960
So because there's receptors and channels that that's the perception, the perception for a cell.

26:43.960 --> 26:45.960
Yeah, anyway, just thought I'd add that in.

26:45.960 --> 26:47.960
Okay.

26:47.960 --> 26:49.960
Greetings Sarah.

26:49.960 --> 26:51.960
Hi Sarah.

26:51.960 --> 26:56.960
Daniel, do you want to read these core assumptions and I'll fix the thing. Thank you.

26:56.960 --> 26:58.960
Classic.

26:58.960 --> 27:06.960
I'm only going to read the two highlighted parts here because these are paragraphs that people want more detail on.

27:06.960 --> 27:09.960
They can definitely read the paper to learn more about.

27:09.960 --> 27:13.960
There's three core assumptions that are laid out really clearly.

27:13.960 --> 27:21.960
So I appreciated that about this paper that it makes clear assumptions and shows how those assumptions come into play.

27:21.960 --> 27:25.960
And then basically there's two avenues for disagreeing.

27:25.960 --> 27:36.960
I guess one would be, I think those are invalid assumptions, but they're properly applied, or one can think that they're valid assumptions but improperly applied.

27:36.960 --> 27:41.960
And so that helps structure discussion with the contents of the paper.

27:41.960 --> 27:44.960
So the first core assumption is a commitment to evolution.

27:44.960 --> 27:49.960
Every capacity has a natural history and emerged from simpler variants.

27:50.960 --> 27:54.960
I guess also evolution can proceed through a reduction of complexity.

27:54.960 --> 28:00.960
So eventually it had to have emerged from simpler variants, but in the short time I guess it could have emerged from more complex variants.

28:00.960 --> 28:12.960
But the commitment to evolution means the commitment to the dispelling of magical thinking and not looking for some sort of a metaphysical answer to our physical questions.

28:12.960 --> 28:22.960
And the second assumption of the three is it is assumed that all metaphors are to be judged by their utility in driving scientific progress,

28:22.960 --> 28:29.960
and there is not a binary categorization of scientific pictures which should be taken literally or not, which can be decided a priori.

28:29.960 --> 28:34.960
So we're not going around with posted notes saying what's real or what's not.

28:34.960 --> 28:38.960
We're using utility as a guiding metric.

28:39.960 --> 28:46.960
We can actually just take a quick visualization and then Sarah, you can say hello and give any thoughts if you'd like.

28:46.960 --> 28:55.960
But we previously in livestream 15 and 20 talked a lot about this continuum from realism to instrumentalism.

28:55.960 --> 28:59.960
Like is active inference the territory itself? That's realism.

28:59.960 --> 29:03.960
We're really describing what's really there when we make an active inference model.

29:03.960 --> 29:08.960
Or instrumentalism on the right side here is like active inference as a map.

29:08.960 --> 29:17.960
We're just using it as something that could be used to capture some features of a system and then used instrumentally like a model.

29:17.960 --> 29:27.960
And then here we've introduced sort of this third vector of utility, which is like, okay, whether it's the map or the territory or diagonal to that is, is it useful?

29:28.960 --> 29:36.960
And so this is a space that's describing not just where we can think about active inference existing, but also ways to evaluate different models.

29:36.960 --> 29:41.960
Not that one is better than the other, but these are just different dimensions that models exist on.

29:42.960 --> 29:43.960
Yeah.

29:54.960 --> 29:55.960
All right.

29:55.960 --> 29:57.960
Okay, maybe go to the third course option.

29:57.960 --> 29:58.960
Onto the third one.

29:58.960 --> 30:04.960
So much of the discussion centers around goals related to teleology, a hotly debated topic.

30:04.960 --> 30:20.960
Here goal directedness is taken in the non magical cybernetic engineering and control theory sense of a feedback system that operates to maximize some specific state of affairs which could be modeled as a dynamical system with the tractors in its state space.

30:21.960 --> 30:27.960
So to reiterate these three assumptions, the first one is evolution.

30:27.960 --> 30:29.960
The second one is utility.

30:29.960 --> 30:34.960
And the third one is a non magical sense of goal directedness.

30:34.960 --> 30:38.960
So these three assumptions play nice with each other.

30:38.960 --> 30:44.960
And then they also lead directly to this final statement that except for a few brief remarks at the end.

30:45.960 --> 30:53.960
No claims about consciousness defined rapidly as first person experience or sense of self as qualia are made.

30:53.960 --> 31:00.960
All the examples concern functional third person objective capacities, computation and behaviors.

31:00.960 --> 31:05.960
So we're kind of like outside of systems looking at them as an investigator.

31:05.960 --> 31:07.960
This isn't about the first person perspective.

31:07.960 --> 31:12.960
And there's always so much fascination and interest in what consciousness is.

31:12.960 --> 31:24.960
But in a way, these three assumptions go a really long distance towards just saying, hey, let's look at the systems behavior as we observe it, rather than as we imagine it to be like.

31:24.960 --> 31:30.960
So that's at least a starting point for a great discussion.

31:30.960 --> 31:37.960
Before we jump into the figures, Sarah, do you want to give any thoughts or say hello?

31:37.960 --> 31:41.960
Sure. Yeah, I am.

31:41.960 --> 31:52.960
I'm kind of coming in pretty different, but I've tried to follow Michael's work quite a bit and I'm enjoying discussing it from whatever angle comes up.

31:52.960 --> 31:55.960
And, oh, I don't know background who cares.

31:55.960 --> 31:58.960
I'm in philosophy right now.

31:58.960 --> 32:01.960
Yeah, that's all.

32:01.960 --> 32:02.960
Nice.

32:02.960 --> 32:08.960
Well, any slide you want to chime in on is great.

32:08.960 --> 32:10.960
I have to find the slides.

32:10.960 --> 32:13.960
Yeah, anyway.

32:13.960 --> 32:19.960
Okay.

32:19.960 --> 32:21.960
Go for figure one blue if you want.

32:21.960 --> 32:22.960
Sure.

32:22.960 --> 32:25.960
So this is a continuum of cognitive powers.

32:25.960 --> 32:28.960
So this is just the first part of the figure.

32:28.960 --> 32:30.960
We'll show the next part in the next slide.

32:30.960 --> 32:57.960
So the author says that by continuously taking action to minimize the distance, the difference in error between the current state of affairs and a set point describing a different possible future state of affairs, it enables a system to pursue goals despite perturbations from the outside world and intrinsic noise.

32:58.960 --> 33:10.960
So this is, I thought, cool, like, you know, the first, like, possible counterfactual, like, yes, it's 75 degrees and I have plenty of sodium and potassium and, you know, calcium.

33:10.960 --> 33:13.960
But what if I don't always, what if it's not always this way, right?

33:13.960 --> 33:15.960
What if what if my state changes?

33:15.960 --> 33:20.960
So like that the first counterfactual maybe enabled this kind of homeostatic feedback loop.

33:20.960 --> 33:23.960
I thought that that was a neat idea put forward in the paper.

33:23.960 --> 33:28.960
So how is this related to active inference or systems engineering, Daniel?

33:28.960 --> 33:36.960
Well, the terminology reminded me a lot more of engineering than we often see, like sensors and actuators.

33:36.960 --> 33:39.960
It makes it sound like it's going to be a robot.

33:39.960 --> 33:44.960
And also this like test exit sounds like we're going to be doing sort of software evaluation.

33:44.960 --> 33:55.960
But we can pretty clearly see the skeleton of action perception loops, whether it's framed as it was a couple slides ago with internal external states and then blanket states.

33:55.960 --> 34:05.960
Or here, where you had basically have the difference between the desired and expected value, leading to policy selection, not shown here, leading to action.

34:05.960 --> 34:10.960
Actions cause events in the environment on the yonder side of the blanket.

34:10.960 --> 34:20.960
And then the state of the external environment influences the measurements on the inbound side, which are again contrasted with the idealized state.

34:20.960 --> 34:22.960
And that leads to another round of action selection.

34:22.960 --> 34:30.960
So this is an engineering way of laying out the tote test operate test exit loop.

34:30.960 --> 34:37.960
But who knows, we're able to jump from active inference pretty nicely into a more engineering frame.

34:37.960 --> 34:44.960
And so perhaps engineering could be integrated closely into active inference.

34:44.960 --> 34:52.960
Yeah, it seems like the blanket states like the sensors and actuators like our, you know, the action perception part are here in the middle.

34:52.960 --> 34:57.960
And so it kind of reminds me of the active inference loop like diagram that we showed earlier.

34:57.960 --> 35:01.960
So it's interesting.

35:01.960 --> 35:05.960
Next part. Do you want to go through this one Daniel?

35:05.960 --> 35:16.960
Yeah, so in figure one B, the caption reads that the scale is showing how different types of activity and systems can be ranked according to their degree of purposeness.

35:16.960 --> 35:21.960
So again, think about purpose in the third person, not the first person.

35:21.960 --> 35:28.960
Not the sense of purpose, but more what I believe Hofstetter called the anti-spectus niche.

35:28.960 --> 35:35.960
I'm not sort of pronounced it, but it was like, think about the most mindless behavior and then push away from that.

35:35.960 --> 35:42.960
And that's what you can call purposeful rather than imagining that there's like this pure crystallized purposeful behavior.

35:42.960 --> 35:48.960
And it sort of goes from bottom to top in terms of the degree of purpose ability.

35:48.960 --> 36:01.960
And on the bottom, we see basically just action that doesn't appear to have any kind of sense or purpose to it, like maybe gas molecules bumping around.

36:01.960 --> 36:06.960
And then we progress through higher higher levels of feedback loops.

36:06.960 --> 36:10.960
And then each one of these brackets, it's kind of like a distinction.

36:10.960 --> 36:17.960
So like starting the left behavior, you can take the right branch or bottom branch passive behavior like a ball that's being thrown or active behavior.

36:18.960 --> 36:23.960
Okay, active behavior. Is it going to be non random or random?

36:23.960 --> 36:31.960
Like many things are random, but you know, is it a wind up toy that's just doing something that is not appearing to be too purposeful?

36:31.960 --> 36:45.960
And you continue up and up the branch choosing the higher branch each time till you get to these first and second order predictions and higher order recursive logics, which are seen as higher and higher levels of purpose.

36:47.960 --> 36:51.960
Cool. Do you have any thoughts, Sarah?

36:51.960 --> 36:55.960
Okay.

36:55.960 --> 36:59.960
Daniel, do you want to take this one?

36:59.960 --> 37:07.960
What is an individual? Well, there's so many ways to go about this. And as an aunt researcher, that's always the debate.

37:07.960 --> 37:20.960
Like, okay, is the individual the six legged next mate, and then that makes the colony like a society or a super individual, or is the colony the individual and then the nest mate is like the tissue.

37:20.960 --> 37:29.960
So there's a lot of discussion around what constitutes an individual and how would you determine where the boundaries of individual individuality are.

37:30.960 --> 37:37.960
And that piece I just referenced about establishing the bounds can be done in a few different ways.

37:37.960 --> 37:44.960
One of them would be looking at where information theory is strongest or where information flows are occurring.

37:44.960 --> 37:47.960
That's the information theory of individuality.

37:47.960 --> 37:52.960
And here we're going to take a cognitive perspective on individuation.

37:52.960 --> 37:57.960
And McCulloch is quoted so early in the neural network days.

37:57.960 --> 38:13.960
The definition of the paper is I propose a definition of an individual based upon its information processing structure, the scales and types of goals that a system can pursue to finds slash determines the boundaries and contents of the putative agent.

38:13.960 --> 38:19.960
So it's an informational lens on what constitutes an individual.

38:19.960 --> 38:33.960
Like, we can say that individual people become maybe an individual mob, just one mob, not multiple mobs, when they start integrating information differently, or when they start pursuing different kinds of goals in a different way.

38:33.960 --> 38:45.960
And it touches on these big questions like, why does it matter how we define individual, as well as what other ways of thinking about individuality exists.

38:45.960 --> 38:47.960
Yeah, it's intense, right?

38:47.960 --> 38:56.960
So not only like in the information theory of individuality, is it like the most concentrated information, but it's also like that bi-directional information flow, right?

38:56.960 --> 39:01.960
Is how Krakauer and that group defined individuality in that paper.

39:01.960 --> 39:03.960
And so that's super interesting to me.

39:03.960 --> 39:07.960
Like at what point is there downward causation in an aggregate?

39:08.960 --> 39:16.960
So it's at that point, that is like the crux for how they talked about individuality, which is, I mean, it makes sense to me, right?

39:16.960 --> 39:23.960
Like, you know, my brain tells my foot to kick the ball, or I decide I want to kick the ball, and so my body then acts accordingly.

39:23.960 --> 39:31.960
But it's really interesting to think about when that emerges, that downward causation in a system.

39:31.960 --> 39:36.960
Anyway, something I think a lot about probably too much.

39:36.960 --> 39:38.960
What about you, Tara?

39:40.960 --> 39:46.960
Yeah, that is actually one of the few papers I actually have read, and I like went with a highlighter and everything.

39:46.960 --> 39:55.960
And I always wonder on, I was looking through the math on that, and I actually learned a lot about, like, math I didn't even think was possible yet.

39:55.960 --> 39:59.960
But it was binary in a sense, it was digital.

39:59.960 --> 40:05.960
And I'm never clear about when that matters and when it doesn't in these kinds of models.

40:05.960 --> 40:08.960
So that's one thing that came up for me.

40:11.960 --> 40:13.960
Sounds good.

40:13.960 --> 40:15.960
Next slide.

40:15.960 --> 40:21.960
No, it's not the Sims, it's a cone of individuation.

40:21.960 --> 40:33.960
And in 2A is this sort of like cone based representation of individuality that's going to be returning in a few different guises in the paper.

40:33.960 --> 40:48.960
And on the plane going out in different directions from a central point is like the zone of influence or the extent of the systems ability to perceive act plan.

40:48.960 --> 40:55.960
And then piercing that coming up and down in the C dimension is going from the past to the future.

40:56.960 --> 41:08.960
And so this is a cool way to look at how multi-scale systems or what are called compound intelligences, compound intelligences down there on the bottom right exist.

41:08.960 --> 41:17.960
So we can use this kind of a cone representation or to look at single cognitive agents and potentially contrast them.

41:17.960 --> 41:29.960
Like in part B, where we have a tick with what's hypothesized to be like a smaller scope, spatially in the now, as well as a shorter temporal scope in the past and future.

41:29.960 --> 41:38.960
Compare a tick with a human and then also ask maybe about what kinds of other cognitive forms exist.

41:38.960 --> 41:42.960
And then these cones can be composed really nicely.

41:43.960 --> 41:51.960
On the example on the bottom right with an ant colony, again, controversial to say that the ant is the organism when potentially the colony is the organism.

41:51.960 --> 41:53.960
That's why I usually call them an estimate.

41:53.960 --> 42:00.960
But we can see how the estimates are inside of the colony within this cone.

42:00.960 --> 42:06.960
And so the colony pushes out the boundaries of what these ants can do.

42:06.960 --> 42:10.960
So they're kind of like on different parts of the spatial plane in the current moments.

42:10.960 --> 42:23.960
And then the colony is something that is cognitively able to move beyond the time horizon of an individual nest mate by virtue of its collective organization and information processing.

42:23.960 --> 42:35.960
This is cool and something that we talked about a lot like offline in preparation for this and preparing the slides is like the inversion of the typical like light cone.

42:36.960 --> 42:43.960
So maybe Daniel, you want to walk us through this light cone and then we can maybe go back to the other one.

42:43.960 --> 42:48.960
Yeah, so this is a similar light cone notion.

42:48.960 --> 42:57.960
And it's just that instead of having the two cups, you know, meeting mouth to mouth and then coming pinch off in a small time.

42:57.960 --> 43:04.960
Another way that light cones have been represented is actually with the current moments like the eye of the needle.

43:04.960 --> 43:06.960
Our glass, the pinch point.

43:06.960 --> 43:17.960
And then in the past and in the future are the set of states that influence a given point and then the set of states it influences.

43:17.960 --> 43:22.960
So let's like think about that butterfly flopping its wings in the here and now.

43:22.960 --> 43:29.960
So if you go back one time step, the air molecules that might influence it are like one layer of air molecule away.

43:29.960 --> 43:36.960
And as you go back and back and back, more and more spatial extents matters for the state of the butterfly in the moment.

43:36.960 --> 43:45.960
And then similarly one time step in the future, the butterflies flapping is only able to influence a small zone proximal to the insect.

43:45.960 --> 43:54.960
Whereas further and further out into the future, more and more spatial extents might be modified because of the actions that happen in the here and now.

43:55.960 --> 44:00.960
And then this is a Lee Kors cabinet, you know, joke on a liquor cabinet.

44:00.960 --> 44:14.960
But it's a paper that actually uses this kind of an approach to do modeling of empirical data and to fit machine learning models, which we can talk about going forward.

44:15.960 --> 44:26.960
Why and how do you get a speed up of certain kinds of simulations or data fitting by approaching it like a light come.

44:26.960 --> 44:39.960
So it's just interesting the axes here like and this is kind of how I'm used to seeing these represented our time and space right so like in physical space I am physically in this space that I am at right now.

44:39.960 --> 44:48.960
And it's interesting as like, you know, as you go forward in time, like, you know, given enough like hours, I could theoretically like fly from New Mexico to Singapore.

44:48.960 --> 44:55.960
But like for right now, I mean, I'm kind of limited to like my house or my block or, you know, like I don't have like point to point transport.

44:56.960 --> 45:14.960
So I always like the way that Mike represents this light cone, like in this way, like in the inverse, it's like time and space and, and you know, it gets, it starts in a very broad space, and it proceeds to a very narrow space.

45:14.960 --> 45:24.960
And it's like, of course, in the past, like if I go to my distant past, like I came out of an egg that was in my mother's uterus, right, like so in my mother's womb, like I came, that's where I came from.

45:24.960 --> 45:32.960
I was in that one point, and I've gone all kinds of places, I guess until now, but I'm not, I don't feel like I'm many places now.

45:32.960 --> 45:43.960
And I also don't feel like I'm going to be many places in the future, so I'm interested to talk to Mike when he comes on to the live stream about the way that this is represented, because it's very different.

45:43.960 --> 45:47.960
Do you guys have any more thoughts on that?

45:47.960 --> 45:49.960
Yeah, I have one.

45:49.960 --> 46:01.960
I mean, it seems to me he's, he's almost trying to do, he's almost trying to take the case of the light cone and look at a particular ambition that you might have at this point in time.

46:01.960 --> 46:10.960
And then, and then can you carry out that ambition through time and as you get further and further, you realize there's all these impediments, you know, that come in your way.

46:10.960 --> 46:17.960
And so it's just like one axis is the ability to envision what it is you want to do.

46:17.960 --> 46:29.960
And the other axis is the ability to enact it, is the ability to, well, even control or whatever your environment, any number of things that are required to enact this vision that you have.

46:29.960 --> 46:36.960
And that's an interesting, interesting axis transformation.

46:36.960 --> 46:48.960
Agreed, the light cone where the, that looks more like an hourglass is kind of related to our limited degrees of freedom in the current moment.

46:48.960 --> 46:52.960
But it, you know, expanding out into the future of what we can influence.

46:52.960 --> 47:03.960
And then the diamond shape that we see in figure two is more like our zone of what can be cognized, which goes beyond what we can influence in the current moment.

47:03.960 --> 47:14.960
Because there's some future time when you won't be able to imagine, you know, as the curtains close on life and it narrows in and it's like smaller and smaller.

47:14.960 --> 47:20.960
And then there's some point where your capacity to influence is actually kind of toned out.

47:20.960 --> 47:25.960
And so there are two complementary ways to look at the same thing.

47:25.960 --> 47:40.960
Although it's interesting, I want to say, because I, you know, like you look at, like there could be some inner supervening or intervening thing where it actually helps you that you never considered in this cone of possibility.

47:40.960 --> 47:46.960
So you've become wider, like really it's just this mind road, right?

47:46.960 --> 47:50.960
For sure.

47:50.960 --> 47:51.960
All right, moving on.

47:51.960 --> 47:53.960
Let's go to 28.

47:53.960 --> 48:01.960
This is sort of taking the light cone is just one and a half more slides that take the light cone and a little bit of a different, more physical direction.

48:01.960 --> 48:05.960
But again, it's all part of a continued conversation.

48:05.960 --> 48:07.960
So we can look at the now.

48:07.960 --> 48:21.960
That's the middle of those three layers where there's two different like individuals, you know, Sally and, you know, friend and so it's like two of those are at different points now.

48:21.960 --> 48:23.960
And so then we look over on the time cone on the right.

48:23.960 --> 48:27.960
And so agent N is, you know, Nick, that's the one that we're focusing on.

48:27.960 --> 48:33.960
And now the same time they're at the same moment, but they're in different points in space.

48:33.960 --> 48:40.960
And so from the point of view of N, S is a space like point.

48:40.960 --> 48:55.960
But then in the same spot in the future or the past F or P in the same location, you know, the same address 20 minutes ago is time like and the same address 20 minutes in the future is also time like.

48:55.960 --> 49:08.960
But then on the edges of this cone is like light, which I don't know the physics behind, but I think it's kind of a cool idea that space and time have this boundary nature.

49:08.960 --> 49:20.960
And that there's things that are more space like, like things that are instantaneously at the same moment, but in different spaces, and more time like the pure case being the same location at a different time.

49:20.960 --> 49:24.960
But then it's like, I'll meet you in 20 minutes to blocks away.

49:24.960 --> 49:31.960
That's like moving through both space and time, and maybe light does that in a kind of unique way.

49:31.960 --> 49:42.960
So there's just one way that in relativity that they talk about light cones and indeed the light cone concept is a is a physicist's concept.

49:42.960 --> 49:50.960
That's really cool to think about like the light is the boundary between space and time.

49:50.960 --> 49:52.960
That's kind of a neat thought.

49:53.960 --> 50:03.960
And then on 29, I just wanted to pull one again, the details going beyond me and this discussion.

50:03.960 --> 50:11.960
But here in a recent paper that explored how you could do simulations using light cones.

50:11.960 --> 50:15.960
And so this is not just like sort of a metaphor or cognitive heuristic.

50:15.960 --> 50:19.960
This is something that you can use for large scale data analysis.

50:19.960 --> 50:30.960
And so the way which I alluded to earlier in which you can speak up a simulation potentially by using the light cone is by having a point that you're focusing on.

50:30.960 --> 50:41.960
And then you only need to consider one time point in the past at a radius of one spatially two time points in the past radius of two spatially three three out.

50:41.960 --> 50:54.960
And so it helps you reduce the space of what you need to calculate from all versus all to the idea of calculating more and more out in more and more past steps and more and more out as you go into the future.

50:54.960 --> 51:02.960
So that's because in the physical interpretation, there's a speed of propagation through a media.

51:02.960 --> 51:04.960
So things don't happen instantaneously.

51:04.960 --> 51:08.960
So that's like light moving through a media at speed of light.

51:08.960 --> 51:12.960
And then in the case of information propagation, it's similar.

51:12.960 --> 51:23.960
Like if you wanted to focus on a given person and their role on an informational network, you would maybe make like an informational cone instead of needing to calculate all by all at every single time steps.

51:23.960 --> 51:29.960
So just made us curious about how active inference related to light cones.

51:29.960 --> 51:33.960
So how can we apply this to some of the simulation models that we've already seen?

51:33.960 --> 51:38.960
And then just, you know, what does the past of the light cone represent?

51:38.960 --> 51:39.960
What is the current moment?

51:39.960 --> 51:40.960
What's the future?

51:40.960 --> 51:43.960
Just fun, eternal questions.

51:45.960 --> 51:46.960
Cool.

51:47.960 --> 51:49.960
Ah, so I made this slide.

51:49.960 --> 51:50.960
This is funny.

51:50.960 --> 51:56.960
This light cone I actually showed when I gave a seminar at Mike Levin's lab a couple of years ago.

51:56.960 --> 52:04.960
It's from Andrew Gallimore's paper, Restructuring Consciousness, The Psychedelic State in the Light of Integrated Information Theory.

52:04.960 --> 52:12.960
But I was thinking about this in terms of shrinking and expanding the boundary of the self, which the author discusses a lot in the paper here.

52:13.960 --> 52:17.960
And just like how that would change your effective light cone, right?

52:17.960 --> 52:25.960
Like, so if you have your, your self boundary, it's like a limited light cone, like the darker one that's shown in this figure on the right.

52:25.960 --> 52:28.960
And if you expand the boundary of yourself, it expands your light cone.

52:28.960 --> 52:35.960
So it made me think of that as we were talking, as he was talking, as Mike was talking about the shrinking and expanding the boundary of the self in the paper.

52:35.960 --> 52:36.960
And so I'm really curious.

52:36.960 --> 52:41.960
Here's a couple of quotes from the paper about boundary establishment and maintenance.

52:41.960 --> 52:48.960
So he says, the surrounding body becomes an informational shield or Markov blanket for the stem cell.

52:48.960 --> 52:52.960
And this is, he references Carl Friston's 2013 paper.

52:52.960 --> 52:57.960
And so I wonder about like the Markov blanket.

52:57.960 --> 53:04.960
And I think that, you know, Daniel, this is something you and I have talked about as well about the Markov blanket, like being the defining boundary for the self.

53:06.960 --> 53:11.960
And like how, I mean, things must pop in and out of a Markov blanket.

53:11.960 --> 53:12.960
Right?

53:12.960 --> 53:16.960
Like if I think about the cells that are in my skin layer, right?

53:16.960 --> 53:20.960
Like, I mean, I'm losing them all the time and new ones are constantly being added.

53:20.960 --> 53:24.960
So there's no distinct hard line to be drawn.

53:24.960 --> 53:28.960
So like under, like how do things pop in and out of a Markov blanket?

53:28.960 --> 53:34.960
Like, and what do you, can you like just have like peripheral boundary nodes on the edges there?

53:34.960 --> 53:38.960
Like I've talked before also about like the difference between like your fingernail and your cuticle.

53:38.960 --> 53:43.960
Like there's like a small tiny layer that doesn't know whether it's a fingernail or a cuticle.

53:43.960 --> 53:47.960
So it's like, how do you like have these like boundaries, right?

53:47.960 --> 53:49.960
Anyway, another quote from the paper.

53:49.960 --> 54:01.960
Crucially, by organizing into a partial electrochemical and informational pool or synctetium, somebody say that for me please.

54:02.960 --> 54:04.960
Syn, syncytium.

54:04.960 --> 54:05.960
Syncytium.

54:05.960 --> 54:06.960
There we go.

54:06.960 --> 54:15.960
All of the cells are able to measure and detect events occurring within the same boundary, creating a larger individual that emerges from the collective.

54:15.960 --> 54:30.960
And I think this quote was like in reference to the gap junctions and how they expand that electrochemical pool by like they open up like some, like they pull the plug on the electrochemical gradient and so it kind of enables this like cell linkage.

54:31.960 --> 54:39.960
So that's one, one way that, you know, boundaries are maybe established, but any thoughts on this guys?

54:43.960 --> 54:44.960
We'll come back to it.

54:44.960 --> 54:48.960
I think I have a few thoughts on where the mark off like it's coming to play through time.

54:48.960 --> 54:49.960
Cool.

54:49.960 --> 54:50.960
All right.

54:50.960 --> 54:53.960
So homeostasis, which we promised to come back to.

54:53.960 --> 54:58.960
So what evolutionary pressures led cognitive boundaries to the to expand.

54:58.960 --> 55:05.960
This is from the paper and the author proposes that the atom of this cognitive hierarchy is homeostasis.

55:05.960 --> 55:15.960
So reactive homeostasis evolves into predictive allostasis under the pressure to predict signals from the environment and other elements of the biosphere.

55:15.960 --> 55:25.960
And that's like what I was talking about earlier about the first like counterfactual about, you know, what if it's not always 76 degrees and full of nutrients in my environment?

55:25.960 --> 55:27.960
How can I regulate that?

55:27.960 --> 55:31.960
Reduce my uncertainty about future availability of the supplies that I need.

55:33.960 --> 55:37.960
And also there's this nice progression from homeostasis.

55:37.960 --> 55:42.960
So that's sort of like similar, you know, same homeostasis.

55:42.960 --> 55:45.960
It's the thermometer is trying to get within the bound.

55:45.960 --> 55:56.960
But the best way to stay within the bounds when the environment is changing is actually to not just be reactive, but to be proactive or predictive.

55:56.960 --> 55:59.960
And then what's the best way to be proactive?

55:59.960 --> 56:04.960
Well, it's to have increasingly rich generative models of the niche.

56:04.960 --> 56:11.960
If you know that nighttime is coming, you're going to be able to take really good predictive behavior right now for tonight.

56:11.960 --> 56:19.960
If you know that winter is coming at a larger time scale, it's another level of you being able to make adaptive decisions.

56:19.960 --> 56:28.960
So what looks like homeostasis sometimes can actually just be very skillful predictive allostasis.

56:33.960 --> 56:35.960
Do you have any thoughts Sarah on that?

56:38.960 --> 56:39.960
Cool.

56:42.960 --> 56:47.960
Okay, so this one is memory and scale free cognition and active inference.

56:48.960 --> 56:55.960
So, I don't know, I just had some thoughts here like memory in as a gene regulatory network.

56:55.960 --> 57:14.960
And this is kind of something that not really was stated in this paper, but really like, you know, it's our evolutionary memory of like where we've been before and how we've come to regulate and, you know, work within our environmental condition and like also memory as a process like, I don't know.

57:15.960 --> 57:20.960
I think about that, like where is it stored? Is it externalized into the niche?

57:20.960 --> 57:24.960
Like we do a lot of niche modification and so, I don't know.

57:24.960 --> 57:31.960
It's interesting to think about our RAM and our ROM in like a biological sense.

57:31.960 --> 57:40.960
So it's the author says a second step in the simplest homeostatic loop is the inclusion of a richer set of hidden layers in the neural network sense.

57:40.960 --> 57:46.960
These are additional biochemical nodes between sensors and effectors of a given system that enable a degree of memory.

57:46.960 --> 57:55.960
And importantly, memory can serve as the beginning of modularity because learning essentially groups diverse stimuli into compressed representations.

57:55.960 --> 58:00.960
Complex states of affairs become remembered as compact biophysical and grams.

58:00.960 --> 58:10.960
This is the essence of the kind of modularity when a simple biophysical event kicks off the formation of a complex morphogenetic cascade such as building a hand in embryogenesis.

58:12.960 --> 58:20.960
One nice point there is the difference between modularity and memory about how they enable each other.

58:20.960 --> 58:26.960
It's sort of like if everything is being mixed in one cup, there can't be a memory of different colors.

58:26.960 --> 58:31.960
Well, if you have two separated cups, you can remember two different colors and so on.

58:31.960 --> 58:42.960
So memory can serve as the beginning of modularity is saying that it's this relationship between things becoming distinct and being remembered through time.

58:42.960 --> 58:45.960
Distinctness carried through time is memory.

58:45.960 --> 58:53.960
You can remember a longer number when you have more modularity that's being propagated through time.

58:53.960 --> 59:09.960
And then the paper on the right is an older first in paper talking about memory, attention and salience and active inference where they described memory, working memory as a process of evidence accumulation in a temporarily structured hierarchy.

59:09.960 --> 59:17.960
So I guess like going back through deep time, like that's where the gene regulatory network kind of comes in as a process, right?

59:17.960 --> 59:22.960
Like the process of evolution and that's like the working memory there anyway.

59:22.960 --> 59:27.960
And just one note there on the multi-scale active inference models.

59:27.960 --> 59:36.960
Sometimes the way that memory is being modeled in active inference is as a state variable that changes at a slower rate.

59:36.960 --> 59:47.960
And so within the longer timescale model, we have a shorter timescale model and then that can be modeled from setting to setting as memory carrying over.

59:48.960 --> 59:58.960
And so it relates to this idea that the larger cognitive system is able to also act over longer timescales as well as reach back with the deeper memory.

59:58.960 --> 01:00:07.960
Because if you have the kind of short-term model that's just standalone, it's like a memory-less process.

01:00:07.960 --> 01:00:15.960
But if that has inherited from a hierarchical model, the state from a previous click of the model, it's memory.

01:00:15.960 --> 01:00:20.960
And then if it's able to imagine one more click out into the future, it's goal planning, it's anticipation.

01:00:20.960 --> 01:00:31.960
And so in active inference, one of the ways that we integrate memory and planning together is by thinking about hierarchically nested models.

01:00:31.960 --> 01:00:36.960
So also I wonder what role memory plays in policy selection.

01:00:36.960 --> 01:00:43.960
Like I remember every summer when I go to Scotland, it is cold, right?

01:00:43.960 --> 01:00:46.960
Like I mean, I live in New Mexico, it's like 120 degrees here, Fahrenheit.

01:00:46.960 --> 01:00:50.960
So every summer I remember that when I go to Scotland, it's cold.

01:00:50.960 --> 01:00:54.960
So now it's my policy to bring a jacket when I go, right?

01:00:54.960 --> 01:00:57.960
So even though it's the summertime and I wouldn't normally do that.

01:00:57.960 --> 01:01:02.960
So is that memory also ever modeled in the policy selection, Daniel?

01:01:05.960 --> 01:01:07.960
It's a good question.

01:01:07.960 --> 01:01:13.960
Like I wonder if you can plan to forget or, you know, I'll make a note, I'll plan to remember.

01:01:13.960 --> 01:01:20.960
I'd say active inference just gives us a way to think about all those different affordances that real cognitive systems have,

01:01:20.960 --> 01:01:28.960
like offloading memory to the niche through external computation or in terms of what you just described.

01:01:28.960 --> 01:01:31.960
But that's a good question we can ask.

01:01:31.960 --> 01:01:36.960
Right. I don't actually even need to remember that it's cold in Scotland because, you know, I can just ask Google.

01:01:36.960 --> 01:01:39.960
They will tell me the weather and it will be cold in Scotland.

01:01:39.960 --> 01:01:44.960
So if I just remember to, you know, check my cognitive offloading device,

01:01:44.960 --> 01:01:47.960
then I don't even need to remember to bring a jacket when I go.

01:01:47.960 --> 01:01:49.960
Yep.

01:01:49.960 --> 01:01:51.960
Okay, next.

01:01:51.960 --> 01:01:53.960
So figure three.

01:01:53.960 --> 01:01:55.960
I have one random thought.

01:01:55.960 --> 01:02:02.960
Maybe it comes up in another slide, but is this question that Michael Levin has about how does it know when to stop in terms of cell growth

01:02:02.960 --> 01:02:07.960
or for Genesis, if it's the case that it's connected to memory in the way that he's suggesting then,

01:02:07.960 --> 01:02:11.960
you know, like maybe it's to make the information flow.

01:02:11.960 --> 01:02:14.960
I guess that's maybe obvious given the focus of this.

01:02:14.960 --> 01:02:20.960
But it is interesting, you know, it's like the cell is just like, oh, we've got it.

01:02:20.960 --> 01:02:31.960
We've got to now become multi-bodied or, you know, or become social rather than individual in order to store memory like there's a funny like break point.

01:02:32.960 --> 01:02:38.960
Yeah, I didn't see the stop mechanism really brought up in this paper, but I have seen it.

01:02:38.960 --> 01:02:42.960
So I'm not really sure where it ties in here.

01:02:48.960 --> 01:02:49.960
Figure three.

01:02:49.960 --> 01:02:58.960
I mean, I mean, if you talk about a morphogenic cascade, you know, it's like, well, we're, we were born, we grow, we grow to a certain point and then we shrivel and die.

01:02:58.960 --> 01:03:01.960
So it's like, how does that connect to memory and information?

01:03:01.960 --> 01:03:03.960
Wow, it's kind of suggested.

01:03:05.960 --> 01:03:06.960
Yep.

01:03:07.960 --> 01:03:15.960
So figure three is looking at sort of cells I view of that time cone.

01:03:15.960 --> 01:03:19.960
And now we're going to step away from, you know, is it a time diamond or is the time cone?

01:03:19.960 --> 01:03:23.960
And we're going to just think about the trajectory of a given cell.

01:03:23.960 --> 01:03:25.960
Go back to the assumptions of the paper, though.

01:03:25.960 --> 01:03:28.960
This isn't about whether the cell is experiencing things.

01:03:28.960 --> 01:03:30.960
It's not what it's like to be a cell.

01:03:30.960 --> 01:03:39.960
It's about how the cell has a given spatial extent in a it has given spatial extent that can be thought of as having a memory.

01:03:39.960 --> 01:03:46.960
It inherits a history through time and then also has an anticipation zone in the future.

01:03:46.960 --> 01:03:54.960
Then it can do anticipation of memory as a soul agent, or it can interact socially.

01:03:54.960 --> 01:03:59.960
So what happens when it interacts socially with other agents like itself?

01:03:59.960 --> 01:04:04.960
Well, it expands the spatial dimension in the now.

01:04:04.960 --> 01:04:07.960
That's what's being called integrated spatial perception.

01:04:07.960 --> 01:04:11.960
And that allows it to have expanded memory in the past.

01:04:11.960 --> 01:04:18.960
Like if each of your five friends have a book, then there's more memory as a group because there's more books.

01:04:18.960 --> 01:04:23.960
And then also the ability to extend the anticipation into the future.

01:04:23.960 --> 01:04:29.960
And then this part I just highlighted in blue is joining into communication networks

01:04:29.960 --> 01:04:35.960
allows the cell to have temporarily delayed access to the information obtained by neighboring cells.

01:04:35.960 --> 01:04:38.960
This is where the time cone comes into play.

01:04:38.960 --> 01:04:43.960
It's not that when something is perceived by one of these cells off on the fringe,

01:04:43.960 --> 01:04:47.960
the focal cell doesn't instantly hear about it.

01:04:47.960 --> 01:04:50.960
They hear about it one time step later.

01:04:50.960 --> 01:04:54.960
So that's where the time the time cone comes into play.

01:04:54.960 --> 01:05:02.960
Because from the point of view of this focal cell, just assuming that information moves one cell per unit of time,

01:05:02.960 --> 01:05:07.960
then at zero time points, its radius is one.

01:05:07.960 --> 01:05:13.960
One time point away, its ability to integrate sense is one more radius away.

01:05:13.960 --> 01:05:19.960
And so you can keep on clicking back and that's reflecting a broader and broader zone of memory.

01:05:19.960 --> 01:05:26.960
Or you can carry it forward with a broader and broader zone of influences or states that it can affect.

01:05:26.960 --> 01:05:33.960
And so the resulting larger individual, and again individual is being used cognitively here,

01:05:33.960 --> 01:05:41.960
not like evolutionarily, is formed with a cognitive world that's unified by the cells sharing of information across time and space.

01:05:41.960 --> 01:05:50.960
So no teleportation and no time travel, the limitations of propagation of information in our physical universe

01:05:50.960 --> 01:05:58.960
means that from the point of any given cell or agents, it's existing in this time cone like structure.

01:05:58.960 --> 01:06:06.960
Yeah, that was like the expanding the boundary of the cell and like kind of like what happens like the time cone is expanded.

01:06:06.960 --> 01:06:17.960
And you know what this just makes me think of well first, I just want to remind everyone that this like cell cell communication is like what is what gap junctions facilitate because they're really connecting all cells and solid tissues.

01:06:17.960 --> 01:06:22.960
But but really I thought about you know the old adage that you are your company.

01:06:22.960 --> 01:06:34.960
And like if you think about you know your five like closest friends and that like communication like network that you have like you hear about you know world events or events that are relevant to their lives.

01:06:34.960 --> 01:06:44.960
It might be relevant to you like you hear about it one time step later and just how like, you know your cognitive like boundary is expanded by like your inner circle.

01:06:44.960 --> 01:06:47.960
I don't know, maybe think of that.

01:06:47.960 --> 01:06:48.960
Yep.

01:06:48.960 --> 01:06:54.960
Can you just, can you just re highlight or talk about the cell dimension that you're just mentioning.

01:06:54.960 --> 01:07:00.960
Oh yeah, so that was earlier in the talk it was one of the keywords so let me just go back to that slide.

01:07:00.960 --> 01:07:04.960
So here, these gap junctions.

01:07:04.960 --> 01:07:13.960
So they are, they were originally, you know, categorized in like neural tissue and in muscle, you know, to facilitate like rapid communication.

01:07:13.960 --> 01:07:26.960
But they're really present in every cell and solid tissue and they just perform not ion exchange but it's like passive diffusion of ions, so that it's like almost a shared intercellular space.

01:07:27.960 --> 01:07:35.960
So what did you say to call that a kind of a information bottleneck?

01:07:35.960 --> 01:07:36.960
I just wonder.

01:07:36.960 --> 01:07:44.960
So maybe not as much of a bottleneck as it is like it pokes a hole in informational boundary.

01:07:44.960 --> 01:07:48.960
Yeah, so that is the more rapidly.

01:07:48.960 --> 01:07:50.960
Let's just say that the gap junction.

01:07:50.960 --> 01:08:00.960
So the no gap junction, it moves like takes three time steps for the signal, you know, one time step to release the molecule one for it to diffuse one for it to be perceived.

01:08:00.960 --> 01:08:05.960
So every three units of time, you're getting a radius expanding out by one.

01:08:05.960 --> 01:08:10.960
Now let's just say that a gap junction allows one time step the direct diffusion.

01:08:10.960 --> 01:08:20.960
So then the time cone is expanding wider because the diffusion from the target cell is able to sweep out a larger time cone.

01:08:20.960 --> 01:08:26.960
Whereas if again if it took three units of time for every one of diffusion, it'd be like a narrower time cone.

01:08:26.960 --> 01:08:39.960
So rat communication, which is never instant allows that time cone to access more memory into the presence and then influence more broadly.

01:08:39.960 --> 01:08:45.960
And so bottleneck is sort of like thinking like a bottleneck is a constraint relative to the width of the bottle.

01:08:45.960 --> 01:08:52.960
But in the context of a gap junction, it's actually like a channel or an opening for information transmission.

01:08:52.960 --> 01:09:07.960
So if you think about it in terms of like your inner circle of friends, imagine like you can wait for your friend to call you up and tell you this exciting new event or like you can have a wire tap into their house.

01:09:07.960 --> 01:09:10.960
So like the gap junction is like having a wire tap into their house.

01:09:10.960 --> 01:09:15.960
So like you always know like what is going on.

01:09:15.960 --> 01:09:16.960
Okay.

01:09:16.960 --> 01:09:20.960
What I'm also searching for another analogy that's just stay into this stuff I've been looking at lately.

01:09:20.960 --> 01:09:26.960
Do you think it's fair that analysis is to, you know, compression function?

01:09:26.960 --> 01:09:32.960
Like, you know, if you picture the classic neural net, you know, a bunch of notes here, just a few in the center of the hidden layer and then expand it out.

01:09:32.960 --> 01:09:39.960
Would it better be a fair analogy or a gap junction?

01:09:39.960 --> 01:09:41.960
Yeah, I'm not seeing it.

01:09:41.960 --> 01:09:42.960
Sorry.

01:09:42.960 --> 01:09:43.960
Okay.

01:09:43.960 --> 01:09:45.960
Okay, I would just to recover it.

01:09:45.960 --> 01:09:54.960
I would just say the transmission is like a compressed form of it's like a little sampling of the chemical milieu from one cell being passed to the other.

01:09:54.960 --> 01:10:00.960
If there was no bottleneck, no compression of information, they would be just in one unit.

01:10:00.960 --> 01:10:02.960
They'd be in one Markov blanket.

01:10:02.960 --> 01:10:11.960
And so there's this trade off where if you totally isolate the rate of information propagation is low, the modularity is very high though.

01:10:11.960 --> 01:10:17.960
On the other hand, with total integration, you can't have memory because you don't have modularity.

01:10:17.960 --> 01:10:21.960
However, you do have instantaneous or close to that transmission.

01:10:21.960 --> 01:10:37.960
And then the gap junction exists at this kind of sweet spot that allows for modularity with narrow channels of communication, which is what Shannon was studying in the first place.

01:10:37.960 --> 01:10:38.960
Cool.

01:10:38.960 --> 01:10:39.960
So figure.

01:10:39.960 --> 01:10:40.960
Okay.

01:10:40.960 --> 01:10:42.960
So figure three, I think we just put popped on the cone.

01:10:42.960 --> 01:10:43.960
Is that true?

01:10:44.960 --> 01:10:45.960
Yep.

01:10:45.960 --> 01:10:52.960
That's just to draw the connection between the figure two with the time diamonds time cone and then just this figure.

01:10:52.960 --> 01:10:54.960
Cool.

01:10:54.960 --> 01:10:55.960
Okay.

01:10:55.960 --> 01:10:57.960
Figure four.

01:10:57.960 --> 01:11:00.960
So figure three.

01:11:00.960 --> 01:11:06.960
Yeah, well, the figure three, the slide that we just had was like, as things build out.

01:11:06.960 --> 01:11:08.960
So that was the point of view of the agent building out.

01:11:08.960 --> 01:11:10.960
And now it's like things fall apart.

01:11:10.960 --> 01:11:20.960
So figure four, we see a sort of rehearsal in B of what we saw previously, which is that that target cell, it's combining sensory information.

01:11:20.960 --> 01:11:25.960
That's able enabling it to detect patterns more rapidly getting a big picture.

01:11:25.960 --> 01:11:27.960
That's what it says in B.

01:11:27.960 --> 01:11:33.960
And therefore missing information can be anticipated by this pattern seeking drive.

01:11:33.960 --> 01:11:36.960
But what happens when things go wrong?

01:11:36.960 --> 01:11:42.960
That's in C where this bottom right cell, the green one has gone rogue.

01:11:42.960 --> 01:11:49.960
It has stopped communicating in a way that was participating in this broader sense making.

01:11:49.960 --> 01:11:53.960
And it has shrunk its sensory radius down.

01:11:53.960 --> 01:11:59.960
And so in doing so, it reduced the cognitive capacity of the other four cells.

01:11:59.960 --> 01:12:02.960
And it has reduced its own sphere of influence.

01:12:02.960 --> 01:12:12.960
And it's also introduced this adversarial dynamic potentially over evolutionary or developmental timescales.

01:12:12.960 --> 01:12:13.960
Cool.

01:12:13.960 --> 01:12:16.960
Any more thoughts on that one?

01:12:16.960 --> 01:12:21.960
Yeah, it reminds me of a friend I know, but no, otherwise.

01:12:22.960 --> 01:12:28.960
Cancer research is starting to think more about the niche and the signaling between cancer and non-cancer cells.

01:12:28.960 --> 01:12:31.960
Like cancer cells need to call down healthy blood vessels.

01:12:31.960 --> 01:12:36.960
They need to prevent healthy immune response from taking them out.

01:12:36.960 --> 01:12:43.960
And so it's like cancer as a dialectic or as a relationship between agents with different goals.

01:12:43.960 --> 01:12:47.960
Again, not the experience of the goal, but acting as if it has a goal.

01:12:47.960 --> 01:12:51.960
That third person cybernetic teleology.

01:12:51.960 --> 01:13:03.960
And so that helps us make sense of all these disparate features of cancer by thinking about internal and external states, information propagation, etc.

01:13:03.960 --> 01:13:10.960
What if you think it would be right or off to think about the one possible place where that could go wrong?

01:13:10.960 --> 01:13:12.960
Happening at the gap junction.

01:13:12.960 --> 01:13:22.960
Like the gap junction would no longer function as a good sampler compression thing, which I know you don't agree with the analogy, but something like that.

01:13:22.960 --> 01:13:28.960
I don't know what's happening in that research area, but does that make any sense?

01:13:28.960 --> 01:13:35.960
Yeah, we talked about gap junctions earlier and their involvement in neoplasticity and all kinds of other disorders.

01:13:35.960 --> 01:13:37.960
So definitely.

01:13:37.960 --> 01:13:45.960
I just found this really nice paper called gap junctions and cancer communicating for 50 years.

01:13:45.960 --> 01:13:59.960
The abstract starts with 50 years ago tumor cells were found to lack electrical coupling, leading to the hypothesis that loss of direct intracellular communication is commonly associated with cancer progression and onset.

01:13:59.960 --> 01:14:01.960
So that's pretty interesting.

01:14:01.960 --> 01:14:09.960
It's like when you shut down the lines of communication, like between two countries, are those two countries having an improving relationship?

01:14:09.960 --> 01:14:13.960
Or is that like the last time that they spoke before war?

01:14:13.960 --> 01:14:23.960
So closing down the embassy, shutting down the gap junction, it doesn't bode well for sort of amicable resolution to conflict or communication.

01:14:23.960 --> 01:14:31.960
That's why it's so important to maintain the avenues of communication, even when there is an adversarial relationship, because things can always get worse.

01:14:31.960 --> 01:14:41.960
You can always shut down the communication, which will make the generative models and the incentives and the goals diverged even more.

01:14:41.960 --> 01:14:43.960
Cool.

01:14:43.960 --> 01:14:47.960
I don't know. I'll just send you into politics and I'm like, yeah, but wait a minute.

01:14:47.960 --> 01:14:49.960
Anyway.

01:14:49.960 --> 01:14:55.960
No, but we should shut down. They're bad. We should shut down.

01:14:55.960 --> 01:15:01.960
If you keep the channel open, you also stand more chance of injury by way of keeping the channel open.

01:15:01.960 --> 01:15:05.960
Keep the channel open until you shouldn't.

01:15:05.960 --> 01:15:17.960
This is just a fun discussion for a little bit on the evolutionary anachronism, which means just something that's happening at a different time than it's expected, like a feature from the past that gets brought back.

01:15:17.960 --> 01:15:21.960
Like an evolutionary reversion.

01:15:21.960 --> 01:15:37.960
And so in the paper, it's described that this is a breakdown of multicellularity and highlights the fact that the scale of the structure which sells work to maintain can change rapidly for cooperation towards an entire organ system or body.

01:15:37.960 --> 01:15:41.960
That's a healthy organism to the level of a single cell.

01:15:41.960 --> 01:15:55.960
Instead of seeing cancer just mechanistically as a derangement of signaling or derangement of replication and DNA reproduction of a cell, we can think about it informationally and cognitively and cybernetically.

01:15:55.960 --> 01:16:03.960
Like the cell has changed its cybernetic horizon from the goals of the organism to its own local goals.

01:16:04.960 --> 01:16:16.960
And so this concept of an evolutionary anachronism and how even in the current day, we can study anachronism in examples with avocados, a tasty fruit.

01:16:16.960 --> 01:16:28.960
And as per the Wikipedia, it says avocados are exceptionally fatty fruits with seeds far too large to be successfully dispersed by any wild animal presently alive in the Americas.

01:16:28.960 --> 01:16:41.960
And so that is a paper of Janssen and Martin in the 80s, which was actually talking about the ecology of large animal plant interactions of animals that we've never directly seen.

01:16:41.960 --> 01:16:55.960
But it's like if you know that there is a really large seed and you know that there's seed dispersing mammals, then it can lead you to hypothesize that there was a seed disperser that was large enough to eat avocados whole.

01:16:56.960 --> 01:17:04.960
And so we can look at anachronism in the current moments and help us, you know, retrace the past.

01:17:04.960 --> 01:17:21.960
So just like the avocado is an anachronistic trait with such large seeds given to the current ecology, past ecology, we can see cancer as this anachronistic reversion to a previous mode of information integration and goal setting.

01:17:21.960 --> 01:17:30.960
That it's like it's inappropriate in the context of the goals of the body, but not necessarily within the goals of a single cell that just wakes up one day.

01:17:30.960 --> 01:17:36.960
It's like, wow, I'm bathed in glucose. I should replicate. So can't blame that cell.

01:17:36.960 --> 01:17:43.960
Also like the cancer, a lot of the markers in cancer cells are really like it's like a developmental reversion.

01:17:43.960 --> 01:17:49.960
So not sure if you guys are aware of that or not, but it's like they, they revert to like a more immature cellular phenotype.

01:17:50.960 --> 01:17:55.960
And so that the, I mean, it's literally like going back to the past. So it's interesting.

01:17:57.960 --> 01:17:58.960
Yep. Steminess.

01:17:59.960 --> 01:18:00.960
Yes. Steminess.

01:18:02.960 --> 01:18:08.960
Are there degrees of reversion? Like, is there something to be learned from the degree of reversion?

01:18:13.960 --> 01:18:14.960
I'm not sure.

01:18:15.960 --> 01:18:24.960
There's one thing that comes to mind there is there's some cancers where it goes back to like a stem cell of that tissue.

01:18:24.960 --> 01:18:30.960
So like it's like a white blood cell cancer that like replicates a lot of white blood cells.

01:18:30.960 --> 01:18:41.960
But when there is a cancer in a reproductive organ, sometimes it's like called a teratoma because it can have like hair and nails and stuff like that.

01:18:41.960 --> 01:18:47.960
Because it's actually pulled back so far that it can then differentiate on all the pathways.

01:18:49.960 --> 01:19:00.960
Rather than a reversion up from being like a healthy reproducing white blood cell precursor to just a higher white blood cell stem lineage.

01:19:00.960 --> 01:19:04.960
But it doesn't pull back all the way to including ectoderm.

01:19:04.960 --> 01:19:08.960
Whereas if it was in a reproductive cell, then it could do that.

01:19:12.960 --> 01:19:15.960
Cool. Biofilms.

01:19:15.960 --> 01:19:17.960
Do you want to take this one, Daniel?

01:19:17.960 --> 01:19:24.960
Yep. So I think the key point here is that bacteria have ion channels just like metazones do.

01:19:24.960 --> 01:19:29.960
You know, dopamine, GPCRs, the proteins that signal between neurons.

01:19:29.960 --> 01:19:31.960
Those are not innovations of mammals.

01:19:31.960 --> 01:19:33.960
They're not innovations of vertebrates.

01:19:33.960 --> 01:19:38.960
Those kinds of channels and diffusable molecules are cellular.

01:19:39.960 --> 01:19:47.960
And so what's being shown here is just like in previous figures, we saw one kind of eukaryotic cell, right?

01:19:47.960 --> 01:19:49.960
You knew because it had a nucleus.

01:19:49.960 --> 01:19:54.960
We have one eukaryote connecting with a few other eukaryotes.

01:19:54.960 --> 01:20:03.960
Well, here we have one prokaryote connecting with other prokaryotes to do the exact same thing, which is increase its sensory capacity.

01:20:04.960 --> 01:20:08.960
Again, not instantaneously, but think time-tone, light-tone.

01:20:08.960 --> 01:20:17.960
And so in the same way that the eukaryotic cells form a cognitive individual through their associations and affordances such as the gap junctions,

01:20:17.960 --> 01:20:25.960
bacteria, when they form a biofilm, can also form a larger cognitive integrated individual.

01:20:25.960 --> 01:20:31.960
And you can still say, well, but from an evolutionary point of view, the unit of selection is the single bacteria.

01:20:32.960 --> 01:20:35.960
But that's the evolutionary individuality definition.

01:20:35.960 --> 01:20:47.960
And when we use the cognitive individuality definition, we see a lot of similarities between a multicellular organism's tissue and then a multicellular biofilm tissue.

01:20:47.960 --> 01:20:54.960
Even not in a biofilm, I mean, bacteria have an incredible ability to like, I mean, it's like antibiotic resistance, right?

01:20:54.960 --> 01:20:59.960
Like they do plasma exchange, which isn't like their chromosomal DNA, but it's like small little snips of DNA.

01:21:00.960 --> 01:21:03.960
Like they just like have a handshake, like it's like a bacterial handshake.

01:21:03.960 --> 01:21:06.960
Like now I'm going to give you some antibiotic resistance too.

01:21:06.960 --> 01:21:09.960
Like we spread germs like COVID and bacteria to one another.

01:21:09.960 --> 01:21:14.960
They spread plasmids to one another, which confer different properties.

01:21:14.960 --> 01:21:20.960
And then we select for this like antibiotic resistance through the use of all of our like antibacterials.

01:21:20.960 --> 01:21:24.960
And so only bacteria that have these little plasmids survive.

01:21:24.960 --> 01:21:25.960
It's really interesting.

01:21:25.960 --> 01:21:34.960
So even outside of a biofilm, they do some some kind of, you know, communication and like cognitive expansion of their self in like the way that we do with our inner circle of friends.

01:21:38.960 --> 01:21:40.960
Cool. All right. Key ideas.

01:21:40.960 --> 01:21:45.960
I just highlighted a few of these like points, but there's a huge box in the paper.

01:21:45.960 --> 01:21:48.960
So we'll just read through the highlighted parts here.

01:21:48.960 --> 01:21:49.960
I'll take this one.

01:21:50.960 --> 01:22:01.960
First, a unified integrated cognitive self or individual can be defined with respect to the integrated ability to pursue specific goals via a homeostatic process that resists perturbations.

01:22:02.960 --> 01:22:14.960
Second, an agent's cognitive world can be quantified and characterized enabling comparison with others regardless of their material implementation by estimating the spatiotemporal boundaries of its area of concern.

01:22:15.960 --> 01:22:23.960
The volume and space and time over which the agent is able to take measurements, exert influence and functionally link disparate events, learning and association.

01:22:24.960 --> 01:22:35.960
Three, the borders of the temporal and spatial events of which a given system is capable of measuring and acting map out a cognitive light cone, a boundary in the informational space of a mind.

01:22:36.960 --> 01:22:41.960
So estimating the spatiotemporal boundaries of an agent is something I find particularly interesting.

01:22:41.960 --> 01:22:45.960
So I just put that in as a question at the bottom to read some of the next ones.

01:22:45.960 --> 01:22:46.960
Daniel.

01:22:47.960 --> 01:22:59.960
Yep. So these are some key ideas for five six four cancer is reversible shrinking of the computational boundary of a biosystem pretty tantalizing there with the reversible.

01:22:59.960 --> 01:23:03.960
I'm sure that's something that a lot of people would like to see.

01:23:03.960 --> 01:23:09.960
Maybe the idea is you remind the rogue agents about bigger goal.

01:23:09.960 --> 01:23:18.960
Like, hey, you know, I know you're hungry, but we wait in line at this restaurant so that everybody gets what takes care of them.

01:23:18.960 --> 01:23:22.960
And maybe that helps remove the cancerous restaurant tour.

01:23:22.960 --> 01:23:31.960
Five agents scaled up by evolving from basic homeostatic loops driven by active inference, which is surprise minimization.

01:23:32.960 --> 01:23:45.960
By the addition of delays, which are memory anticipation, which is inference inference has planning as inference and networks, which is spatially distributed processing, enabling learning and progressive abstraction

01:23:45.960 --> 01:23:47.960
generalization data.

01:23:47.960 --> 01:23:58.960
That's pretty cool to see active inference and elaborations of active inference at the heart of this future electrical Evo eco vivo.

01:23:58.960 --> 01:24:09.960
It's like saying you start with action and perception, and then you can carry that forward in time planning anticipation have extended trail of memory.

01:24:09.960 --> 01:24:13.960
That's, you know, the past, and then you can also expand spatially.

01:24:13.960 --> 01:24:15.960
But again, the spatial isn't instantaneous.

01:24:15.960 --> 01:24:18.960
There's a propagation speed in the media.

01:24:18.960 --> 01:24:23.960
And so even laterally similar agents interact through this light cone way.

01:24:23.960 --> 01:24:27.960
So nice to see where active inference plays into light cones there.

01:24:27.960 --> 01:24:35.960
And then six info taxes, the drive for better actionable intelligence about the regularities and patterns in the world.

01:24:35.960 --> 01:24:40.960
And in the agents own mechanism encourages cells to connect in groups via signaling.

01:24:40.960 --> 01:24:50.960
This is another area where active inference has a lot to say and is a value add relative to a reward only framework like reinforcement learning.

01:24:50.960 --> 01:24:56.960
Because again, what drives the bacteria to cover less into work together.

01:24:56.960 --> 01:25:05.960
So maybe it's reward, but then you have to appeal to this idea that they're maximizing reward with their behavior and the state or leave and all this kind of stuff.

01:25:05.960 --> 01:25:25.960
Infotaxis helps us understand that the way to get good actionable intelligence, which is kind of like active inference a I right there is to make your actions exist on the trade off frontier like the Pareto optimal trade off between getting it done right now and expanding

01:25:25.960 --> 01:25:27.960
your epistemic boundaries.

01:25:27.960 --> 01:25:34.960
Sometimes the right move is to contact somebody who knows better or to go to a website that might inform you better.

01:25:34.960 --> 01:25:41.960
And so it's actually a useful action in the moments to arrange to get better information later.

01:25:41.960 --> 01:25:48.960
And so active inference helps us think about how these different needs are traded off by organisms.

01:25:48.960 --> 01:25:50.960
Cool.

01:25:50.960 --> 01:25:55.960
All right, so seven collecting into. Oh, I can't do it.

01:25:55.960 --> 01:25:58.960
Syncium, syncytium, syncytium.

01:25:58.960 --> 01:26:00.960
Did I do it?

01:26:00.960 --> 01:26:10.960
Okay, collecting into a syncytium enables all of the cells to share the same data and access the same memories.

01:26:10.960 --> 01:26:12.960
That's pretty awesome.

01:26:12.960 --> 01:26:13.960
You must assimilate.

01:26:13.960 --> 01:26:16.960
It's like the Borg.

01:26:16.960 --> 01:26:18.960
Sorry, Star Wars nerd.

01:26:18.960 --> 01:26:32.960
Okay, also greed, eight greed at the single cell level for information info taxes drives cooperativity as each unit expands its measurement boundary communication with neighbors, and thus inevitable

01:26:32.960 --> 01:26:38.960
inevitably becomes part of a bigger self with bigger set points, serving as homeostatic attractors.

01:26:39.960 --> 01:26:45.960
So I think active inference also has a role to play here in this cooperativity.

01:26:45.960 --> 01:26:53.960
So like I can reduce my uncertainty about my environment by cooperating with people who have the same goal that I have, right?

01:26:53.960 --> 01:27:02.960
Like or cooperating becoming part of a group, you know, and therefore our efforts make a bigger effort or bigger.

01:27:02.960 --> 01:27:07.960
Anyway, less surprise when I'm in a bigger group because it expands that that light cone, right?

01:27:07.960 --> 01:27:08.960
And then nine.

01:27:08.960 --> 01:27:15.960
There's a fundamental symmetry between anatomical control mechanisms and cognitive mechanisms.

01:27:15.960 --> 01:27:21.960
And I think that this was discussed in terms of bio electricity in the paper.

01:27:21.960 --> 01:27:23.960
Do you guys have anything to add?

01:27:23.960 --> 01:27:27.960
One thought on that is cooperation arising at a higher level.

01:27:27.960 --> 01:27:35.960
So that just reminds me of like if you're looking through a microscope and you saw cell A eats cell B, you go, I mean adversarial relationship, right?

01:27:35.960 --> 01:27:37.960
Could there be anything more directly adversarial?

01:27:37.960 --> 01:27:43.960
And then you pull back and it's a white blood cell, you know, that's attacking a cancer cell.

01:27:43.960 --> 01:27:49.960
So it's cooperative at a higher level, but it can look adversarial at a low level.

01:27:49.960 --> 01:27:54.960
And so what does that map on to in different systems?

01:27:54.960 --> 01:28:03.960
Can we reimagine conflict and tension as actually playing a stabilizing or cooperative role at a larger scale?

01:28:03.960 --> 01:28:11.960
Can interpersonal differences in perspective or disagreements lead to a cooperative or regenerative collective?

01:28:11.960 --> 01:28:15.960
This is what we hopefully move towards.

01:28:15.960 --> 01:28:22.960
I saw some pigeons procreating yesterday while I was out walking around in my neighborhood and it definitely looked adversarial.

01:28:22.960 --> 01:28:28.960
It looked very, very adversarial, but they're cooperating at a higher level.

01:28:28.960 --> 01:28:31.960
Looks can be deceiving.

01:28:32.960 --> 01:28:33.960
Okay, definitely.

01:28:33.960 --> 01:28:41.960
I was thinking of a case where like if a tiger attacked me, I should just assume that it's like an information transfer that needs to happen.

01:28:41.960 --> 01:28:42.960
I don't know.

01:28:42.960 --> 01:28:44.960
Come get a piece with it.

01:28:44.960 --> 01:28:46.960
I was thinking on that, Sarah.

01:28:46.960 --> 01:28:50.960
Oh, it's like in the selfish gene by Dawkins.

01:28:50.960 --> 01:28:53.960
He says, yeah, why would you go beyond the gene?

01:28:53.960 --> 01:28:54.960
Doesn't make any sense.

01:28:54.960 --> 01:28:59.960
You know, would you have mammals like doing kind acts for each other?

01:28:59.960 --> 01:29:01.960
Just look at the lion eating the gazelle.

01:29:01.960 --> 01:29:04.960
How could that possibly be a collaborative relationship?

01:29:04.960 --> 01:29:17.960
And I thought, what if those two populations stabilize each other through a deep time and they can't coexist and then they actually persist better both because of that one act?

01:29:17.960 --> 01:29:21.960
So who's to say?

01:29:21.960 --> 01:29:28.960
But just one thing, like if that is all the case, you know, if this is all like whatever man, the universe becoming.

01:29:28.960 --> 01:29:31.960
Why would it be that we have such a hard time with it?

01:29:31.960 --> 01:29:32.960
Like shouldn't it?

01:29:32.960 --> 01:29:36.960
Shouldn't there be some mechanism that allows me to just be like, oh, okay, cool.

01:29:36.960 --> 01:29:39.960
You know, I don't get that.

01:29:39.960 --> 01:29:42.960
I think the mechanism is narrative.

01:29:42.960 --> 01:29:44.960
Cognitively.

01:29:44.960 --> 01:29:49.960
It might play out differently in different systems, but agree to disagree.

01:29:49.960 --> 01:29:51.960
It's a narrative that we can both agree on.

01:29:51.960 --> 01:29:53.960
We're cooperating at that narrative level.

01:29:53.960 --> 01:29:55.960
Doesn't mean that we don't disagree.

01:29:55.960 --> 01:30:03.960
In fact, we entrenched that we disagree, but we're agreeing at a higher level.

01:30:03.960 --> 01:30:04.960
Cool.

01:30:04.960 --> 01:30:08.960
Do you want to read the next ones?

01:30:08.960 --> 01:30:21.960
So yeah, just a few of the key points from 1011 1210 bioelectric integration helped evolve control strategies and cognitive content across the continuum from chemical networks to human minds.

01:30:22.960 --> 01:30:40.960
11 the key points here where that there's a scale in variance with how different systems make decisions and that we can across different systems study how the cybernetic processes of learning and parameter optimization are implemented by a large number of units pursuing

01:30:40.960 --> 01:30:53.960
Infotaxis and homeostatic goals a.k.a. pragmatic value and epicenter value and 12 a conceptual unification is proposed in this paper as scale free cognition.

01:30:53.960 --> 01:31:07.960
And then it's talked about how these boundaries between different subunits are a major control mob between the self and the world like the sound is doing the same stuff whether it's part of an organism or part of a cancer.

01:31:07.960 --> 01:31:16.960
But it's actually this control knob like what are the limits of the cognitive individual that sets the cell up to act a certain way or another.

01:31:16.960 --> 01:31:26.960
And then a reminder at the very end from a utilitarian perspective that the most appropriate level of analysis is to be determined empirically.

01:31:26.960 --> 01:31:29.960
Aha, but was empiricism determined empirically.

01:31:30.960 --> 01:31:38.960
And that is said to be the level that facilitates prediction control with the least effort by the experimenter or by the system itself.

01:31:38.960 --> 01:31:46.960
What if they disagree and gives rise to a unified understanding that drives the most novel, robust research programs at the bench.

01:31:46.960 --> 01:31:51.960
Nice, you know, if it doesn't advance your career as a scientist.

01:31:51.960 --> 01:31:53.960
And it's not the case.

01:31:54.960 --> 01:32:01.960
This was you Daniel active inference and multi scale communication.

01:32:01.960 --> 01:32:05.960
Just wanted to capture a little bit about multi scale systems and active.

01:32:05.960 --> 01:32:09.960
So here we have nested systems on top left, you know, that's an answering.

01:32:09.960 --> 01:32:13.960
That's a picture that Sasha took of an answering that came from a Pogo ants.

01:32:13.960 --> 01:32:20.960
And then there's the colony with a bunch of nest mates driving food around and then the colony is embedded within an ecosystem.

01:32:21.960 --> 01:32:28.960
So within one nested system, you know, within these time diamonds that are sort of nested inside of each other.

01:32:28.960 --> 01:32:39.960
We can think about how the internal state of one is linked to the external state being the next level up like the internal state is the brain and the external niche to the brain is the body.

01:32:39.960 --> 01:32:48.960
Okay, now the body and the brain are the internal state for what the colony and then the colony is like the internal state for the ecological niche.

01:32:48.960 --> 01:32:56.960
So that's something that we've seen before with how active inference helps us understand and model and simulate hierarchically nested systems.

01:32:56.960 --> 01:33:09.960
But also we can think about interactions at the same scale like collective behavior, collective intelligence as occurring when at the same type of agents, they're interacting like laterally.

01:33:09.960 --> 01:33:11.960
And so that's this teal arrow.

01:33:11.960 --> 01:33:16.960
That's where you have two agents there are there each other's external state.

01:33:16.960 --> 01:33:28.960
So active inference helps us zoom up and out and down and in, and then also helps us go laterally, and then not to repeat it too many times but the lateral transmission isn't instantaneous.

01:33:28.960 --> 01:33:37.960
It's dynamic it happens through time, which means that we don't need to look at all lateral interactions just the time cone.

01:33:40.960 --> 01:33:41.960
Cool.

01:33:42.960 --> 01:33:44.960
Predictions and research program.

01:33:44.960 --> 01:33:48.960
There was a big list here so I just pulled a few of them out.

01:33:48.960 --> 01:33:52.960
I'll read some of these off, which are a lot of them questions.

01:33:52.960 --> 01:33:58.960
So is there a quantifiable sense in which biological systems model themselves?

01:33:58.960 --> 01:34:14.960
Can an in silico evolutionary system be built containing both genetic and physiological components, which simulates the scheme described above homeostasis and infotaxis and illustrates the emergence of different scales of cognitive horizons over time?

01:34:14.960 --> 01:34:22.960
Can we directly observe the evolution of multicellular goals from networking of agents with single cell homeostatic goals?

01:34:22.960 --> 01:34:37.960
Might there be higher level effects on the physiological boundaries of the cognitive sub agents within the body from exposure to psychedelics, which have long been claimed to expand transpersonal boundaries or induce ego death?

01:34:37.960 --> 01:34:47.960
The analogies between geometric spaces and cognitive ones need to be explored further as is beginning to be done via geometric information theory.

01:34:47.960 --> 01:34:49.960
Time diamond anyone?

01:34:49.960 --> 01:34:50.960
Definitely.

01:34:50.960 --> 01:34:53.960
I think that there's a lot of room to go here.

01:34:53.960 --> 01:34:58.960
Will complex engineered systems set novel goals and if so how?

01:34:58.960 --> 01:35:08.960
It is a prediction of this view that adaptive useful robotics will require components that are themselves competent and goal seeking.

01:35:08.960 --> 01:35:16.960
That is super interesting also because really as an intelligent being capable of cognition so are all of my parts.

01:35:16.960 --> 01:35:24.960
So if we're going to really import you know give rise to intelligent life intelligent artificial life.

01:35:24.960 --> 01:35:26.960
We have to start with intelligent artificial components.

01:35:26.960 --> 01:35:28.960
I think that's super cool.

01:35:28.960 --> 01:35:30.960
And also goals.

01:35:30.960 --> 01:35:36.960
We can't we can't just say well let's just build you know a bigger car or a bigger computer.

01:35:36.960 --> 01:35:44.960
I mean what do we want this intelligence design system to be intelligence in the service of or in the way of.

01:35:44.960 --> 01:35:50.960
And it's a disaster waiting to build capacity without goal.

01:35:50.960 --> 01:35:52.960
For sure.

01:35:52.960 --> 01:35:54.960
Do you want to read some more of these?

01:35:54.960 --> 01:35:57.960
Yep so the second set of predictions.

01:35:57.960 --> 01:36:01.960
So this is where Mike is setting out a little bit of his agenda.

01:36:01.960 --> 01:36:04.960
The next work in this subfield.

01:36:04.960 --> 01:36:07.960
Just you know the subfield each of the fields they're modular.

01:36:07.960 --> 01:36:12.960
They have their own disciplinary histories their own disciplinary anticipation.

01:36:12.960 --> 01:36:18.960
But this subfield should focus on the discovery of bioelectric communication inducing technology.

01:36:18.960 --> 01:36:25.960
So just like once we had chemical biology people were really excited about finding drugs that bound to proteins.

01:36:25.960 --> 01:36:32.960
Well now that we're aware of bioelectricity let's think about manipulations and measurements of bioelectricity.

01:36:33.960 --> 01:36:43.960
Two it's a prediction that it's possible to induce the formation of metazoan like bodies in an otherwise unicellular organism by forcing the expression of appropriate

01:36:43.960 --> 01:36:45.960
electrogenic proteins and gap junctions.

01:36:45.960 --> 01:36:50.960
So he's trying to get towards some unique predictions and experiments.

01:36:50.960 --> 01:37:02.960
A prediction that transcriptomic which means gene expression analysis of regeneration events from bacterial biofilms plants and metazoan models of limb regeneration.

01:37:02.960 --> 01:37:11.960
Should so show consistent use of electrogenic proteins in the events that enable cooperation towards self limiting morphogenetic cascades.

01:37:11.960 --> 01:37:26.960
So it's kind of like the structure informational or cognitive structure of recovery and repair might have some similarities across systems that wouldn't immediately be seen as similar otherwise.

01:37:26.960 --> 01:37:31.960
Scale free cognition hypothesis suggests that multi human systems.

01:37:31.960 --> 01:37:35.960
Kafka remote teams could have their own degree of cognition.

01:37:36.960 --> 01:37:43.960
So as we always say no things that the brain knows that the neuron doesn't things that the colony knows that the ants nest mate doesn't.

01:37:43.960 --> 01:37:50.960
There's got to be things that remote teams or any other kind of team know that individual participants don't know.

01:37:50.960 --> 01:37:56.960
And then the exobiology question is given a novel life form or just a novel form.

01:37:56.960 --> 01:38:00.960
How does one know when successful communication has taken place.

01:38:00.960 --> 01:38:12.960
And that's an interesting question for a lot of you Zeno slash exobiologists said anyone.

01:38:12.960 --> 01:38:13.960
Cool.

01:38:13.960 --> 01:38:14.960
Next slide.

01:38:14.960 --> 01:38:18.960
So this is in the section what it feels like to be a pancreas.

01:38:18.960 --> 01:38:26.960
But I really pulled the point that kind of hit home for me the most out of the section and the final point that Mike makes in the paper.

01:38:26.960 --> 01:38:28.960
So I'll just read this off.

01:38:28.960 --> 01:38:45.960
It is striking that the process which Zen practice is meant to reverse attachment to past memories and high valence for future expectations or fears is precisely the process suggested to be responsible for the creation of complex cells with a capital S.

01:38:45.960 --> 01:38:53.960
It is unclear whether it is beneficial or even possible to truly live in the moment and let go of past memories and future expectations.

01:38:53.960 --> 01:39:00.960
But anyone who succeeded in doing this would achieve precisely what Zen promises the dissolution of the self.

01:39:00.960 --> 01:39:17.960
And the final sentence of the paper which I just love recreating the unification into and liberation from larger scale unifying unifying cells with a capital S would be a true pinnacle of synthetic biology and artificial intelligence engineering.

01:39:17.960 --> 01:39:18.960
Wow.

01:39:18.960 --> 01:39:21.960
This is a good paper.

01:39:21.960 --> 01:39:23.960
So just keep questions at the end.

01:39:23.960 --> 01:39:25.960
What might a good understanding of this work enable?

01:39:25.960 --> 01:39:28.960
What are the unique predictions and implications of this work?

01:39:28.960 --> 01:39:33.960
What are the next steps for FEP and active inference in relation to this work?

01:39:33.960 --> 01:39:37.960
What are the goals of this research and what are you still curious about?

01:39:37.960 --> 01:39:45.960
So we will be thinking of all of these things as we get ready to do 25.1 and 25.2 over the next couple weeks.

01:39:45.960 --> 01:39:47.960
So thank you for participating.

01:39:47.960 --> 01:39:56.960
There is a feedback forum for feedback and you can get in touch with Active Inference Lab at all of these links on this slide.

01:39:56.960 --> 01:39:57.960
Nice work, Blue.

01:39:57.960 --> 01:40:02.960
Great job with your first broadcasting and facilitating on this one.

01:40:02.960 --> 01:40:03.960
It was really fun.

01:40:03.960 --> 01:40:11.960
So yeah, anyone's welcome to participate or contribute to our lab activities asynchronously.

01:40:11.960 --> 01:40:14.960
We'll figure out the right performance for you.

01:40:14.960 --> 01:40:16.960
Thanks, Sarah, also for joining.

01:40:16.960 --> 01:40:17.960
Thanks again, Blue.

01:40:17.960 --> 01:40:18.960
Cool.

