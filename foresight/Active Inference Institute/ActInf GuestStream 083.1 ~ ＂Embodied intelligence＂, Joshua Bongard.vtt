WEBVTT

00:00.000 --> 00:17.120
Hello and welcome. It is July 17th, 2024. We're in active inference guest stream 83.1 with

00:17.120 --> 00:23.360
Josh Bongard. Thank you for joining. This should be very exciting. We'll have a presentation

00:23.360 --> 00:28.160
and then some discussion. So if you're in the live chat, please feel free to write any

00:28.160 --> 00:34.000
questions. And thank you again, Josh, looking forward to this. Yeah, thank you, Daniel. And thanks

00:34.000 --> 00:39.280
to those of you that are attending online. So my name is Josh Bongard. I'm a professor of computer

00:39.280 --> 00:45.760
science here at the University of Vermont. And my bread and butter in my lab is the study of

00:45.760 --> 00:54.240
robotics and AI. And obviously, we're in the middle of the current AI summer. So what I wanted to do

00:54.240 --> 00:58.640
today is show a couple of highlights from my group, things that I've worked on in the past and

00:58.640 --> 01:04.240
that we're working on at the moment, that I hope in the long term will help us realize sort of the

01:04.240 --> 01:09.360
long term vision for a lot of those trying to create intelligent machines, which is to create

01:09.360 --> 01:15.920
machines that are helpful, but but also safe. We're part of the way there. But as anyone who's

01:15.920 --> 01:22.240
worked with chat GPT or stable diffusion knows or even has a robot vacuum cleaner at home,

01:22.240 --> 01:27.280
there are some limitations to our current technology. It's hard to create machines that are

01:27.280 --> 01:33.920
autonomous and useful and safe all simultaneously. So what are the things that we're missing?

01:34.640 --> 01:39.840
That's what I wanted to sort of seed the pool with today and hopefully we can move on to an

01:39.840 --> 01:45.360
interactive discussion about it. So I'm going to leave this slide up and just sort of talk over

01:45.360 --> 01:49.520
this slide for a few minutes that will hopefully generate some food for thought and then questions.

01:49.760 --> 01:55.840
This is a snapshot from some of the projects I've worked on over the years. First thing you'll

01:55.840 --> 02:00.560
probably notice is there's a lot of different robots that have very different structural

02:00.560 --> 02:06.720
properties. They not only act differently, but look very different. And that is a fundamental

02:06.720 --> 02:13.040
foundation in everything we do in my research group, which is to try and understand how the

02:13.280 --> 02:21.760
body facilitates cognition. Years ago with my PhD advisor, we wrote a popular science book called

02:21.760 --> 02:28.640
How the Body Shapes the Way We Think. And we can mean that literally or figuratively. We wrote that

02:28.640 --> 02:33.680
book a while ago. We made some arguments about how the body shapes the way we think. And since that

02:33.680 --> 02:40.320
time, my group and others have formulated other arguments for why or how the body shapes the

02:40.320 --> 02:47.200
way we think. And I'm hoping to survey some of those today. So as I mentioned, you can see

02:47.200 --> 02:52.000
a lot of different robots here, very different structure. They've got very different form and

02:52.000 --> 02:58.560
function. But across each of the pair of videos that you see here, you'll notice that there's also

02:58.560 --> 03:03.840
a common pattern, which is on the left side, you tend to see something that's virtual. And on the

03:03.840 --> 03:09.520
right side of the video pair, you tend to see something that's physical. And this illustrates

03:09.520 --> 03:15.200
the basic approach that my group takes to understanding how the body shapes the way we think,

03:16.000 --> 03:24.240
which is to create AI that creates robots, creates embodied AI. So what do I mean by that?

03:24.960 --> 03:31.120
What I mean is that in all of the projects that you see here, we create an AI that searches the

03:31.120 --> 03:37.840
space of all possible robots that could solve the tasks that we want the robots to solve.

03:38.800 --> 03:44.240
Most people that are familiar with AI and robotics and autonomous cars and drones have

03:44.240 --> 03:51.520
a rough understanding that AI is somehow optimizing or tuning the brain of the autonomous car or the

03:51.520 --> 03:57.280
drone or the robot, what have you. There's an underlying assumption in all of that current,

03:57.280 --> 04:03.440
in most current robotics, which is that the AI tunes the brain, but does not tune the body.

04:03.440 --> 04:11.200
Tesla cars are dreamed up mostly by humans and an AI tunes their brain or their control policy.

04:11.760 --> 04:16.160
But of course, nature doesn't work that way. Nature produced us and all the other intelligent

04:16.160 --> 04:23.920
organisms on this planet by carefully tuning body and brain simultaneously. Certain bodies

04:23.920 --> 04:28.640
facilitate certain kinds of behaviors and certain kinds of intelligent behavior,

04:28.640 --> 04:33.760
and other bodies don't. They obstruct that particular behavior or that intelligent behavior.

04:34.560 --> 04:41.360
So in all of our work, we ask the AI not just to tune the brain of a robot, but its body

04:41.360 --> 04:48.960
simultaneously. And as you can see visually here, the AI often comes up with bodies that are well

04:48.960 --> 04:55.200
suited to whatever we want them to do. So if you direct your attention to the very top left of

04:55.200 --> 05:01.040
the screen for a moment, this is now a 22 year old experiment, but I think it still visualizes

05:01.040 --> 05:07.200
the potential of this approach. In this case, we were interested in creating a robot that can

05:07.200 --> 05:13.920
brachiate, that can swim, swing across beams or tree branches or electrical wires for various

05:13.920 --> 05:19.840
inspection tasks. And you'll notice that in this case, the AI came up with a solution that in

05:19.840 --> 05:26.560
retrospect seems intuitive. The robot has to carry a very heavy battery, which you can see in

05:26.560 --> 05:32.960
the physical robot in the top left there, the black box that's at the bottom. And the AI has

05:32.960 --> 05:40.160
figured out how to design the body of this robot so that it's actually able to exploit the forward

05:40.160 --> 05:47.280
momentum of this heavy object, this battery, to facilitate its movement or brachiation across

05:47.280 --> 05:53.680
this physical beam. So it's a simple example, a simple robot, a simple task, but it demonstrates

05:54.560 --> 06:03.600
this interplay between AI, robotics, body and brain. If the AI was not free to place the body,

06:04.080 --> 06:09.920
to place the battery at a particular place on the robot's body, it would be much harder,

06:09.920 --> 06:15.280
it would require more energy, it would require a more complex brain for the robot to figure out how

06:15.280 --> 06:22.880
to move its heavy weight across this beam. So that idea of tuning body and brain has

06:22.880 --> 06:29.680
suffused everything that we work on. Some other examples you can see in the top center and the

06:29.680 --> 06:37.920
top right. Here we have a robot that suffers damage, its body changes over time. So now the AI has to

06:37.920 --> 06:43.440
grapple with not just designing a body, but grappling with a body that changes. One of the

06:43.440 --> 06:49.920
things that we as intelligent organisms here in the world and all embodied AI, all autonomous cars,

06:49.920 --> 06:56.080
all drones, all robots have to deal with is entropy. The world throws a lot of stuff at us,

06:56.080 --> 07:02.400
we have to deal with wear and tear, injury. In our case, we grow from a single cell into about

07:02.400 --> 07:09.840
10 to the 12 cells. We change massively in terms of our physical magnitude. How do you continue

07:09.840 --> 07:17.040
to operate, keep yourself alive and do whatever it is you need to do across massive morphological

07:17.040 --> 07:23.280
change? That is not an easy thing to do. And again, it requires an AI, if it's going to do this with

07:23.280 --> 07:30.320
robots, it's got to figure out how to carefully tune body and brain to deal with the generation

07:30.320 --> 07:37.120
of behavior inside a body that is changing, either unexpectedly due to injury and wear and tear,

07:38.080 --> 07:44.800
or intentionally. You can see in the very center panel, this is again a pretty good

07:44.800 --> 07:52.560
visualization of where designing body along with brain comes in handy. If we want to make

07:52.560 --> 07:58.640
flying machines or swimming machines, we have to very, very carefully tune the geometry and

07:58.640 --> 08:05.600
material properties of the body itself to realize flight. So what you're seeing in this middle panel

08:05.600 --> 08:11.600
here, this is partway through the AI experimenting with the design of different kinds of wings

08:11.600 --> 08:20.480
for an ornithopter, a drone that flies by flapping its wings. This flexible wing that you see here

08:20.480 --> 08:26.000
in the center of the screen, this is a bit of a transition from traditional robots that are made

08:26.000 --> 08:33.360
of rigid structures, like you can see in the top row, into a more modern era in robotics,

08:33.360 --> 08:39.280
which is sometimes referred to as soft robotics. Material science has come a long way in the last

08:39.280 --> 08:46.800
20 years. So we can now start to build robots embodied AI. We can start to build robots out of

08:46.800 --> 08:53.840
materials other than rigid plastic and metals. And we can again, we can start to move into an era

08:53.840 --> 09:00.320
in which robots like organisms can exploit the material properties of their bodies

09:01.120 --> 09:07.280
to facilitate whatever behaviors they need to do to survive or be useful to humans and so on.

09:08.400 --> 09:14.560
So in the middle right panel, this is a highlight of some work that my group has done in collaboration

09:14.560 --> 09:22.080
with Rebecca Kramer, Bottiglio's lab at Yale. Rebecca's lab is famously advancing the state of

09:22.080 --> 09:28.320
the art in soft robotics. What can you get robots to do when they're made out of soft materials?

09:28.320 --> 09:33.760
You can see an example of some of those soft robots. Middle right and a very different soft

09:33.760 --> 09:41.120
robot lower left, which is exploiting its body properties in order to move in interesting

09:41.120 --> 09:48.080
ways. One of the interesting things about soft robotics in my perspective is that it starts to

09:48.080 --> 09:55.840
usher in an era in which robots can actually grow and complexify their bodies. You can see these

09:56.480 --> 10:03.680
hollow cubes in the middle right and these hollow sort of chambers in the bottom left

10:03.680 --> 10:11.520
expanding and contracting as we push and pull air into and then out of the body of the robot.

10:12.640 --> 10:17.440
Suddenly, now you have robots that can change their geometry. They can change their volume.

10:18.480 --> 10:24.640
They become what's known as thermodynamically open. It's a fancy term for meaning that they can

10:24.640 --> 10:33.040
draw new material and new energy into themselves. The thermodynamically open machines that you see

10:33.040 --> 10:39.200
middle right and lower left, the only thing they're drawing into their body is more air,

10:39.200 --> 10:46.960
but it's a start. I mentioned already that humans grow from a single cell into 10 to the 12 cells.

10:47.600 --> 10:54.880
Every organism on this planet, with a few exceptions, starts small and gets bigger over its

10:54.880 --> 11:03.360
lifetime. That fundamental morphological change starts small, starts simple and gradually grow

11:03.360 --> 11:13.440
in size and complexity. That provides scaffolding. It provides a gradient on which to learn how to

11:13.440 --> 11:18.800
gradually grapple with the world around you. Most organisms, again, there are exceptions,

11:18.800 --> 11:25.280
are not thrust into this world with all of their machinery online from the beginning.

11:26.320 --> 11:32.080
Just the way I'm phrasing this is obviously intentional to sort of dichotomize growing

11:32.080 --> 11:39.440
organisms and robots with fixed bodies. Autonomous cars are still very dangerous.

11:39.440 --> 11:46.640
Autonomous drones are still very dangerous to be around because 99.99% of the time,

11:46.640 --> 11:51.280
they do the right thing, but every once in a while, they don't know what to do,

11:52.000 --> 12:00.240
and no one knows what they're going to do in those uncertain circumstances. That is a very

12:00.240 --> 12:07.840
concerning situation as we start to now deploy robots and autonomous vehicles into everyday

12:07.840 --> 12:14.640
environments where they are in close proximity to humans. Why is it that even with state-of-the-art

12:14.640 --> 12:21.360
AI and with all of Google's data centers and AI training algorithms, we still can't rub out that

12:21.360 --> 12:30.080
0.001% where no one knows what's going to happen? Part of the reason, again, is these machines

12:30.160 --> 12:39.600
are born with complex bodies. We drop a controller into a one-ton autonomous car made of metal and

12:39.600 --> 12:47.120
plastics. It's very dangerous. We don't grow autonomous cars from a very small, simple,

12:47.120 --> 12:53.280
lightweight machine that can't cause anyone any harm whatsoever, and then when that simple,

12:53.360 --> 13:00.240
small machine demonstrates and verifies to us that it's safe, then we allow it to become larger

13:00.240 --> 13:06.320
and more complex. It sounds like silly sci-fi. Why would we build a machine like that? But again,

13:06.320 --> 13:12.400
every organism starts simple and grows in complexity. If it doesn't do the right thing,

13:12.400 --> 13:18.720
if it performs dangerous actions that are harmful to itself or fatal to itself, by definition,

13:18.720 --> 13:25.360
it doesn't get any further. That's, again, one of the ways of thinking about how the body shapes

13:25.360 --> 13:32.240
the way we think. In my personal and professional opinion, any physical machines that we deploy

13:32.240 --> 13:38.000
into the real world, they should start as very small, lightweight machines that can't harm anyone.

13:38.880 --> 13:43.760
They have a very limited number of actions that they can perform, and they sort of cycle

13:43.760 --> 13:51.040
through all those actions and verify everything, and only then can they take more mass, more energy

13:51.040 --> 13:57.680
into themselves. Can they recruit more material? They can sort of be allowed to be thermodynamically

13:57.680 --> 14:04.160
open and grow and complexify themselves. There's lots of ways in which we're starting to create

14:04.160 --> 14:10.240
machines that grow and complexify themselves. I just talked about these soft robots that can pull

14:10.240 --> 14:17.440
in air or pass possibly fluids. They could be hydrodynamic machines. They could mechanically

14:17.440 --> 14:23.920
or magnetically connect to other robots. That sort of swarm robotics. That's another path

14:23.920 --> 14:31.200
to growing machines. At the moment, most of these machines are still restricted to academic labs.

14:31.200 --> 14:36.480
They also are not safe yet, but I think in the long run, they're going to be a safer alternative to

14:37.360 --> 14:43.360
dropping AI into very large, complex, heavy, dangerous machines and crossing our fingers

14:43.360 --> 14:50.000
and hoping for the best. I've talked a little bit about rigid robots and soft robots.

14:50.720 --> 14:54.800
I want to try and talk as little as possible. There's some time for a good discussion,

14:54.800 --> 15:00.480
but I want to talk about what I see as sort of a third era of robotics and embodied AI,

15:00.480 --> 15:07.760
which is just starting to open up in the last few years, which is biobotics or creating biobots.

15:08.400 --> 15:17.360
You can see two biobots on display at the bottom center of my slide here. A biobot is a robot

15:17.360 --> 15:25.360
that's made up of only biological components, no technological components whatsoever. In the bottom

15:25.360 --> 15:32.320
left here, Kriegman, Blackiston, Levin and myself in 2020 published a paper demonstrating the first

15:32.320 --> 15:40.080
biobot. This became known after publication in the popular media as Xenobots, X-E-N-O,

15:40.880 --> 15:49.520
Xeno, Xenobots, because these Xenobots are built from about 2,000 frog cells and the cells were

15:49.520 --> 15:56.880
taken from a particular species of frog, which is Xenopus laevis. Michael Levin, our biology

15:56.880 --> 16:03.760
colleague at Tufts University, is world-renowned for demonstrating that you can reconfigure

16:03.760 --> 16:11.840
genetically unmodified materials like, for example, frog cells, and that rearrangement

16:11.840 --> 16:17.520
of living tissues not only does not kill the organism, the organism is able to in some cases

16:18.080 --> 16:24.320
continue on doing what it does, what it needs to do, ingest materials, survive,

16:24.320 --> 16:31.440
reproduce in this reconfigured state. There's a lot of biological implications for that.

16:31.440 --> 16:38.160
One of the biological implications is that frog DNA does not code for frog. What you're looking at

16:38.160 --> 16:43.360
in the bottom left, the Xenobot is about a millimeter in diameter, so it looks like a speck

16:43.360 --> 16:50.640
of pepper to the unmagnified eye, and yet it's able to walk around the bottom of a petri dish.

16:50.640 --> 16:56.000
It doesn't have all the features of a living organism, but it's got enough of them that it's

16:56.000 --> 17:05.040
motile. It's able to get itself from point A to point B. One of the other implications for AI

17:05.040 --> 17:10.880
of this biological discovery that you could rearrange genetically unmodified living tissues

17:10.880 --> 17:19.120
is that maybe we can task an AI with discovering novel rearrangements of living tissue to produce

17:19.760 --> 17:25.840
robots, to produce something that moves around and does something useful on a human's behalf.

17:27.120 --> 17:32.800
That's what I mean by a biobot, a biobot that's made from, in this case, genetically unmodified

17:33.360 --> 17:41.120
cells. The swarm of Xenobots that you see in the bottom right, as you can see,

17:41.120 --> 17:48.400
they're sort of pushing around some material in their dish. This sort of visually hints at

17:48.400 --> 17:54.480
applications for this type of robotic technology, which is they might be able to act like very,

17:54.480 --> 18:00.480
very small Roomba robot vacuum cleaners in the future. They might be able to collect

18:00.480 --> 18:09.360
microplastics out of waterways or cancer cells out of bloodstreams. The swarm that you see that's

18:09.360 --> 18:15.200
cleaning up in this slide at the bottom right, the material that they're cleaning up is actually

18:16.000 --> 18:23.440
other frog cells. It turns out that if the AI designs this swarm just right and the swarm

18:23.440 --> 18:30.000
that you're looking at, this is an AI designed swarm, the AI came up with the shape for each

18:30.000 --> 18:36.880
member of the swarm. This swarm is pushing these little white circles, which are individual frog

18:36.880 --> 18:43.280
cells, pushing them into piles. Turns out these individual frog skin cells at a certain stage

18:43.280 --> 18:50.080
of development are sticky, and they clump together into a pile. Some of these piles,

18:50.080 --> 18:55.680
if they're big enough, if they contain enough frog cells, they will grow very small hairs

18:55.680 --> 19:01.840
on the surface cells, the cells that are on the surface of the pile. Those little small hairs are

19:01.840 --> 19:11.360
called cilia. They're usually used to pull dirt and pathogens off the body of frogs, adult frogs.

19:11.360 --> 19:19.200
Here, when those cilia grow on small piles of frog cells, they're able to exert enough force

19:19.200 --> 19:27.360
against the surrounding water that these piles start to move. What you have in essence is a child

19:27.360 --> 19:33.840
xenobot. This swarm pushes cells together and in essence makes copies of themselves.

19:34.640 --> 19:40.400
This is another implication of this work, is that in this case the AI has figured out how to design

19:40.400 --> 19:47.600
robots that replicate. They make copies of themselves by finding raw material in their

19:47.600 --> 19:53.440
environment and constructing copies of themselves. This has been a long-standing dream in robotics,

19:55.520 --> 20:01.440
dating back a very long time to John von Neumann in the 1950s who had a thought experiment. It would

20:01.440 --> 20:06.880
be great if we could create robots that would create copies of themselves, which would create

20:06.880 --> 20:14.400
copies of themselves. If those robots do useful work for humans as a side effect, for von Neumann

20:14.400 --> 20:20.560
that was creating moon bases and then Mars bases and then colonizing the galaxy, which sounds great.

20:22.160 --> 20:30.160
But the seed of this idea is if we want robots to really be useful at scale, instead of manually

20:30.160 --> 20:36.320
constructing billions of robots and then deploying them to do something useful, which is expensive,

20:36.320 --> 20:40.320
it would be much cheaper to make one robot that does something useful for us.

20:41.200 --> 20:47.040
By the way, it also makes two copies of itself, which does more useful work for us in four and eight

20:47.040 --> 20:53.440
and sixteen and so on. We're not there yet with the Xenobots, but it's a demonstration that that

20:53.440 --> 20:59.920
is possible. Again, all of that becomes possible because the AI is designing both the bodies

20:59.920 --> 21:07.040
and the brains of these robots. This is very far now from the traditional view of AI and robotics,

21:07.040 --> 21:14.000
where we build a robot body, we humans build a robot body, and then the AI tinkers with the brain

21:14.000 --> 21:20.960
of that fixed machine. Part of the reason why I'm here today and part of the message of my group is

21:20.960 --> 21:28.320
we need to think more broadly about how to combine AI and robotics and possibly synthetic biology.

21:29.200 --> 21:35.920
When we do and we think more broadly, there are whole new paths that open up to ways in which

21:35.920 --> 21:43.120
we might create in the future, not yet, but in the future, create intelligent, useful, and safe

21:43.120 --> 21:50.720
machines. In the current era in AI, there is one particular approach, which is auto completion of

21:50.720 --> 21:57.040
tokens, which has come to dominate the field and come to dominate the popular imagination. We all

21:57.040 --> 22:03.760
kind of have an understanding more or less of what chat GPT is doing, and there are some very strong

22:03.760 --> 22:09.520
lobbying organizations out there that are bent on convincing us that if we just do this with

22:09.520 --> 22:16.320
more compute, more data, we will eventually get to safe machines. My contention is there just

22:16.320 --> 22:24.160
isn't enough data out there to make non-embodied AI like chat GPT and stable diffusion and all the

22:24.160 --> 22:32.160
rest to make them safe. We have to think differently about designing bodies and brains of machines

22:32.160 --> 22:40.160
simultaneously to realize this long-term goal. Okay, I've been talking for a while. I'm going to

22:40.160 --> 22:45.280
stop and I'm happy to take questions or engage in some discussion, and I'm happy to come back to

22:45.280 --> 22:51.120
any of these experiments and provide more detail if that's helpful. Over to you, Daniel.

22:51.920 --> 23:00.080
Thank you. Wow. Awesome. What a cornucopia of bodies and minds.

23:03.120 --> 23:09.840
It was a great overview. I was really struck by some of the similarities and the convergence on

23:10.480 --> 23:17.040
whole of lifecycle design and kind of holistic design coming from, on one hand, a systems engineering

23:17.040 --> 23:23.680
and a materials perspective, and on the other hand, from the biology perspective with like eco-evo-devo

23:24.400 --> 23:31.840
and this convergence upon needing to think about how the end-to-end function maybe even past the

23:31.840 --> 23:39.280
point of functionality like into the planned graceful decay of a robot as well. So it brings in a lot

23:39.280 --> 23:45.600
of topics that even from an outsider's perspective seem to be put as kind of secondary. So that's

23:45.680 --> 23:50.960
very cool. Okay, great. I'm looking forward to what people in the live chat, right?

23:52.320 --> 24:02.080
My first question is how over these 22 years, how have the materials, the theories, like the

24:02.080 --> 24:08.960
contexts, advances in turing computation, all these kinds of things, how have they intersected

24:09.280 --> 24:13.120
just what has the ride been like as you pursued these questions?

24:14.560 --> 24:22.560
Yeah, I think the short answer again is focusing on the physical aspect of AI and robotics. So the

24:22.560 --> 24:30.480
materials from which we can build machines has changed over 20 years. And from my perspective,

24:31.040 --> 24:34.320
the experiment, the top left there, that was something I did as part of my PhD,

24:35.040 --> 24:40.000
you know, the materials at the time, it was very hard to build a robot. You bought some

24:40.000 --> 24:45.040
motors, you bought a battery, you bought some metal, you bought some wires, and you wired

24:45.040 --> 24:50.400
everything up. There was the assumption that bodies were fixed. And not only that, but they were

24:50.400 --> 24:55.600
difficult to make. So once you made one, you were very careful with it to make sure it didn't change,

24:55.600 --> 25:02.560
that it didn't become damaged. And that seemed to comport with a lot of the theory in AI and

25:02.560 --> 25:09.840
neuroscience, which had the same sort of idea that the brain, or in the case of robotics,

25:09.840 --> 25:16.960
the control policy is the puppeteer. It's something that's pulling the strings of a fixed thing,

25:16.960 --> 25:25.120
either the body of an organism or a robot. And if you look at a lot of theory in both fields,

25:25.200 --> 25:31.040
AI and neuroscience, that assumption runs so deep. So for example, an active

25:31.920 --> 25:37.360
inference, you know, the free energy principle, we want to reduce surprise all that there's a

25:37.360 --> 25:43.360
fixed set of actions that we perform to try and reduce the surprise between what we're sensing

25:43.360 --> 25:49.680
and what we predicted we would sense given the past action. Where do those actions come from?

25:49.680 --> 25:57.440
Why are they fixed? Does the set of actions grow over time? Maybe the sensory data that's coming

25:57.440 --> 26:02.720
is coming from a new sensor that's just coming online or a sensor that's recently duplicated.

26:02.720 --> 26:09.120
Now there's two of them, but they're not quite reporting exactly the same thing. There's a whole

26:09.120 --> 26:16.640
bunch of assumptions underlying a lot of the theory about active inference, predictive coding.

26:17.600 --> 26:22.560
You name it, you pick your concept from neuroscience or cognitive science or AI.

26:25.360 --> 26:32.080
Once you peel back those assumptions, imagine the robot's body changes. Imagine the robot splits

26:32.080 --> 26:40.960
in two and becomes two copies of itself. A lot of the theory and the formal underpinnings of

26:41.040 --> 26:46.240
that theory break down. You start to get into ill posed questions, which force you to now

26:46.240 --> 26:52.800
think about how do you fundamentally change the theory? If you have a hierarchy of actions,

26:52.800 --> 26:58.160
like in predictive coding or active inference, what if that hierarchy is growing and changing

26:58.160 --> 27:04.400
over itself is growing and changing over time? How do we address that in a formal manner? So

27:04.400 --> 27:09.040
to get back to your question, I think these advances in what we can do physically, we can

27:09.040 --> 27:14.720
build robots now out of soft materials. We can build robots out of living materials,

27:15.520 --> 27:21.120
which on their own will grow and divide and seek out energy and material on their own.

27:22.800 --> 27:28.160
Those physical machines, these odd new kinds of creatures, are militating. They're pushing

27:28.160 --> 27:34.080
against the theory. Specifically, they're pushing against these unspoken assumptions that lie

27:34.080 --> 27:41.760
underneath a lot of this theory about what's required to act intelligently in a complex world.

27:43.120 --> 27:50.400
That's awesome. Like the real world and the territory expanding into our unknown unknown.

27:50.400 --> 27:54.640
Okay, there's a bunch of questions in the live chat. So I'm just going to go for them,

27:54.640 --> 27:57.360
give any answer that you like. Okay.

27:57.360 --> 28:02.400
Sure. David Williams wrote,

28:03.280 --> 28:09.280
How do you think about the controllers in your robotics? Embedded AI at least today is rather

28:09.280 --> 28:15.760
hard. Batteries and chips, PCBs, not soft and not easily synthesized locally. So how do you

28:15.760 --> 28:21.120
think about the controllers in your robotics? Yeah, great question. So, right, exactly. The

28:21.120 --> 28:27.840
controllers are dealing with hard rigid fixed components. We need to start thinking about

28:27.840 --> 28:34.400
controllers that can, in which, for example, the input layer and the output layer can grow and shrink

28:34.400 --> 28:41.360
over time. There may be new sensors or new input coordinates that are growing or being attached

28:41.360 --> 28:48.480
to a machine. And the controller needs to be able to carefully deal with those new input channels

28:48.480 --> 28:55.040
while the machine is operating. Same thing goes for the output channel. There may be new

28:55.040 --> 29:04.480
actions or new dimensions of action along which the machine can act. And control policies,

29:04.480 --> 29:10.560
reinforcement learning, all the rest of it does all those assumptions that make reinforcement

29:10.560 --> 29:16.240
learning work, which is what drives most autonomous vehicles at the moment, assumes

29:16.240 --> 29:21.200
that the dimensionality of input and the dimensionality of output, the things that the machine

29:21.200 --> 29:29.120
can do and sense, are fixed during training or during behavior generation, during execution.

29:29.120 --> 29:35.520
That is absolutely not true in any organism on the planet. And that's becoming increasingly untrue

29:36.640 --> 29:43.040
for our coming machines. Now, how to do it well? I don't have any answers, but we have to figure

29:43.040 --> 29:49.040
it out. You were asking a question about thinking about controllers. That's a concrete example

29:49.040 --> 29:55.040
about how we have to rethink control policy optimization, even if we're not thinking directly

29:55.040 --> 30:00.400
about the body, even if we just focus on the control policy and ask what happens as the input

30:00.400 --> 30:06.480
and output channel, the dimensionality of the input and output channels change during behavior

30:06.480 --> 30:14.400
execution. Yeah, just one short point on that. It's like training with a fixed set of perceptual

30:14.400 --> 30:20.640
elements or of affordances or actuators. It's like training on one point in a larger space of the

30:20.640 --> 30:27.200
adjacent possible of bodies or of architectures. So then, okay, we're bringing all this compute

30:27.200 --> 30:34.800
to train a special case in the fixed setting. And that's not even how the smallest organism works.

30:34.800 --> 30:41.680
So that just again, kind of shows that point. Okay. Sorry, before we move on from that point,

30:41.680 --> 30:47.680
just to again, illustrate how the body shapes the way we think. In the case of a growing biological

30:47.680 --> 30:53.600
body, there are new input channels that come online throughout our lifetime, but they don't

30:53.600 --> 30:59.280
appear de novo. Whatever it is, whatever that new input channel is, as we're growing, we just have

30:59.360 --> 31:08.560
more sense cells. The signals that they're sending into the peripheral and central nervous system

31:08.560 --> 31:14.960
are not orthogonal to whatever else is already coming in as input, because new input channels

31:14.960 --> 31:21.760
or new cells are slowly dividing. And at the moment of division, they're providing exactly the same

31:21.760 --> 31:29.040
signal as some other sensory channel that already exists. So the body, or in this case, biological

31:29.040 --> 31:36.400
growth provides an immediate scaffold, a gradient. In robotics, it can be very scary to think about

31:36.400 --> 31:42.000
like attaching a sensor to an autonomous vehicle. What the hell does it do with this new information

31:42.000 --> 31:48.880
that's coming in? Because we haven't thought carefully about how to add that new sense modality

31:48.880 --> 31:57.280
to the machine. Again, we have to look to nature that every new sense modality is gradually coming

31:57.280 --> 32:04.800
online and gradually drifts away or becomes increasingly orthogonal to the starting input

32:04.800 --> 32:12.080
modality. So that's how we should, if we did that physically with machines, it would simplify

32:13.200 --> 32:16.960
reinforcement learning or would make it easier for reinforcement learning or what have you,

32:18.240 --> 32:23.280
sorry, let me reshare my screen here, it would simply make it easier for the,

32:23.280 --> 32:28.480
sorry, something seems to have gone wrong here, give me a moment.

32:36.320 --> 32:43.040
Yep. Okay, all right. Yeah, it makes things easier on the control policy optimization process

32:43.760 --> 32:50.080
if new sense organs and new motor outputs are coming online, but they resemble things that already exist.

32:53.280 --> 32:59.280
That's super interesting. Brings up a lot of questions about like self and non self recognition

32:59.280 --> 33:06.560
and what is a self as new and different senses and actions come online. Sure. Okay. Prakash

33:06.560 --> 33:14.800
Kavi asks, do these bio bots have any sense of agency? What is your sense? I'm quite intrigued

33:14.800 --> 33:20.800
by the idea that beyond a critical point, they start growing hair. And do these bio bots act

33:20.800 --> 33:25.520
independently of each other? And also what happens at a group level? So what's your sense

33:25.520 --> 33:31.200
of agency in bio bots? And I guess the bio bot and the group level?

33:32.400 --> 33:37.440
Yeah, it's a great question. So I'll start with the disclaimer. I'm not a biologist. I'm a computer

33:37.440 --> 33:44.720
scientist by formal training. So I can only say so much about what the cells are doing and what

33:44.720 --> 33:54.640
they want to do. I definitely follow in the footsteps of the late Daniel Dennett in that

33:54.640 --> 33:59.360
when we talk about agency, we each of us individually has to decide whether or not we

33:59.360 --> 34:07.200
take the intentional stance or not. It's in my opinion, it's a point of view. If it's easier to

34:07.200 --> 34:15.280
explain what the Xenobots are doing by talking about what the cells want to do, like grow cilia

34:15.280 --> 34:22.160
and coordinate their actions, fine. If it's easier to explain what the Xenobots are doing by not

34:22.160 --> 34:28.560
taking the intentional stance and describing cells as mechanical components that are transforming

34:28.560 --> 34:35.920
input into actions, that's fine too. This is something also that comes from my colleague,

34:35.920 --> 34:41.520
Mike Levin. It depends. As scientists, if we want to try and explain and understand what these

34:41.520 --> 34:47.600
machines are doing, if taking the intentional stance makes explanation easier, fine. If not,

34:47.600 --> 34:55.840
then not. But attributing agency is sort of an objective property of the bots or the cells themselves.

34:55.840 --> 35:03.520
Independent of us is observers. To me, that's philosophically and practically problematic.

35:04.480 --> 35:12.320
As far as I know, there is no objective measure of agency in cells, let alone inorganic robots.

35:15.280 --> 35:20.320
Super interesting. That's like the second order cybernetics or the observer theory

35:20.320 --> 35:26.080
or the poly computing question, which is to say just looking at something and then

35:26.080 --> 35:32.560
treating one's perspective as objectively. The case, it is objectively the subjective experience.

35:33.600 --> 35:38.800
Absolutely. Now, that being said, again, there is an empirical side to this. We can make some

35:38.800 --> 35:48.400
progress in understanding the Xenobots by comparing them against a control. So instead of cells,

35:48.400 --> 35:56.720
if these were magnets or some complex mechanical system in which more of us are comfortable in

35:56.720 --> 36:05.920
saying there is no agency, it's just a bucket of cogs doing something, and that control does not

36:05.920 --> 36:11.440
exhibit kinematic self-replication, for example, or it's much harder for the AI to figure out how

36:11.440 --> 36:20.640
to put together non-agential components to do what it is, then I feel a little bit more comfortable

36:20.640 --> 36:25.200
by saying the cells are doing something more. Now, I don't know whether it's agential or they

36:25.200 --> 36:31.760
want to do something, or if it's free will or consciousness, I don't know. But if we can point

36:31.760 --> 36:38.640
at biobots or machines that are built from biological components and say it's easier to get them to do

36:38.640 --> 36:46.560
things because they become complicit in the overall goal compared to mechanical parts,

36:46.560 --> 36:54.720
which don't, okay. And again, as a roboticist, the top and the middle rows that you see on my

36:54.720 --> 36:59.840
slide here, when we do build things out of metal and rubber and plastics and ceramics,

37:00.640 --> 37:05.280
it's usually super hard. It's really hard to get them to do whatever we want them to do.

37:06.640 --> 37:11.680
We've been working on robotics since the end of the Second World War, and we've got the Roomba,

37:11.680 --> 37:16.880
and maybe we've got autonomous cars, we're getting there. It's taken a really long time

37:16.880 --> 37:23.440
because robotics is really hard. It's really hard to convince physical materials to adapt and do

37:23.440 --> 37:28.480
something useful and safe. On the flip side, we've been working on Xenobots at the bottom here.

37:28.480 --> 37:34.560
We've been working on them for about five or six years, and we've got Roombas. We're making faster

37:34.560 --> 37:42.560
progress in robotics when we build from cells than when we build from metal suggests the cells are

37:42.560 --> 37:47.200
somehow helping. I don't know that they want to help. We've got to be careful there. That's the

37:47.200 --> 37:55.840
intentional stance, but when you try and compose machines from smart machines and cells are smart

37:55.840 --> 38:03.200
machines, I know I'm biased, but I think we're making faster progress than when we build machines

38:03.200 --> 38:11.840
out of inert materials. Yeah, super interesting. Okay, I'll read some comments from David Clement.

38:11.840 --> 38:21.280
David wrote, does your work incorporate a gentile hierarchies? For example, does Xenobots grow by

38:21.280 --> 38:28.320
replicating the initial seed cell into a higher order system? And is it critical for lower order

38:28.320 --> 38:34.720
systems to act as a component of a virtual machine, meaning that they have a target behavior that is

38:34.720 --> 38:39.840
less than the higher order system? And that's kind of related to Prakash's question as well. Like,

38:39.840 --> 38:45.920
how do you bridge that from the individual component into the swarm or the aggregate?

38:47.040 --> 38:53.840
Yeah, it's a really good question. So, absolutely, I think that when we started working on the Xenobots

38:53.840 --> 38:59.680
and Mike Levin started to talk about machines made of machines, made of machines, that definitely

38:59.680 --> 39:05.440
has influenced the work in my group to focus on this issue of hierarchy. I don't know about a

39:05.440 --> 39:10.560
gentile hierarchy. Again, we just talked about a gentile agency, that's maybe a

39:11.520 --> 39:17.600
subjective stance. But definitely, you know, why would you want to build machines out of

39:17.600 --> 39:23.760
machines out of machines? At the moment, our state of the art robots, like autonomous vehicles,

39:23.760 --> 39:32.160
are not hierarchical. The control policy operates at the level of the machine as a whole.

39:32.960 --> 39:39.520
For example, if there's an emergency blowout of the tire, an autonomous vehicle, the tire itself,

39:39.520 --> 39:45.840
the rubber that makes up the tire, doesn't deform and try and fix or reduce surprise all locally.

39:45.840 --> 39:52.960
It can't. It's rubber. It's inert material. We don't have machines built of machines built

39:52.960 --> 39:59.280
of machines yet. But as biology in general and the Xenobots in particular demonstrate,

39:59.360 --> 40:04.720
there's an adaptive advantage to being a hierarchy of physical things, of physical machines.

40:05.760 --> 40:09.760
If there is a surprising event at the level of the machine as a whole,

40:10.800 --> 40:17.760
but that surprise trickles down through the hierarchy, it's unlikely that everyone at every

40:17.760 --> 40:23.040
level of the hierarchy is going to be surprised. Someone somewhere in the hierarchy is going to

40:23.040 --> 40:30.160
say, from my local view at least on this bigger surprising issue, I know what to do. So let me

40:30.160 --> 40:36.720
start to communicate to my peers and up the hierarchy to deal with surprise. That would be,

40:37.440 --> 40:44.480
from an engineering point of view, that would be a good thing to have in big, heavy, fast-moving

40:44.480 --> 40:51.440
robots that are near humans. There's always going to be some surprising event that the vehicle

40:51.440 --> 40:57.040
as a whole has never seen before. There's great YouTube videos of horrifyingly

40:58.000 --> 41:03.600
scary surprising edge cases for autonomous vehicles. Okay, we're never going to fix every

41:03.600 --> 41:11.920
edge case. What we can fix is to make hierarchies and maybe agential hierarchies where local surprise

41:11.920 --> 41:18.400
can be handled or global surprise can be broken down into local surprising events, which can be

41:18.480 --> 41:25.920
handled locally. If I understood the second part of your question is how do we design that

41:25.920 --> 41:31.840
hierarchy? Should the smaller parts be trying to pull in the same direction or be trying to solve

41:31.840 --> 41:37.680
some part of the goal of the higher level? I think that's a super interesting question

41:37.680 --> 41:43.920
and I don't think that the answer is obvious. It may be that smaller parts pursuing orthogonal

41:43.920 --> 41:56.320
goals may end up being useful. Just to give you a quick example, if there's a surprising event

41:56.320 --> 42:02.080
and you've got a whole bunch of semi-independent machines organized in a hierarchy, I would argue

42:02.080 --> 42:07.040
that every single one of those members of the hierarchy should have a slightly different

42:07.040 --> 42:11.280
body and brain. It should have a slightly different form and function. You don't want a

42:11.280 --> 42:16.000
monoculture. You don't want all the parts being smaller versions of the bigger parts

42:16.560 --> 42:23.440
and trying to achieve smaller versions of the same goals because then you've basically got

42:23.440 --> 42:29.200
a committee in which everybody thinks and feels the same way. As we know from humans, that's a

42:29.200 --> 42:35.360
dangerous thing. You get group think or group act. You actually want a hetero culture. You

42:35.360 --> 42:40.080
want a whole bunch of things that are unique in terms of form and function and that maximizes

42:40.080 --> 42:44.480
your chances that someone somewhere in the hierarchy says, just because of the way I'm

42:44.480 --> 42:50.400
built and the way I think with my local control policy, I know what's going on and I have the

42:50.400 --> 42:55.680
seed of a solution. Here's the seed. You all figure out what you need to do to make it a

42:55.680 --> 43:01.600
reality at the larger level. That's another aspect of where the body comes into play.

43:02.320 --> 43:12.240
Yeah. Thank you. Like everywhere is the last mile from somewhere. Things have to be addressed

43:12.240 --> 43:16.800
locally. No matter how you think about a communications architecture distally,

43:17.680 --> 43:23.440
everything and embodiment calls our attention back to that. It has to be somewhere locally.

43:23.440 --> 43:29.360
So then why not take that as the starting point instead of this resource challenge

43:29.360 --> 43:38.400
and then about the multiple subunits when there's a damage to the nest of an ant colony or

43:38.400 --> 43:44.720
there's some things spilled on the surface. It's not that every single nest makes a perfect

43:44.720 --> 43:52.960
pebble move. It's that 51% accuracy with a bunch of nonspecific flurrying of activity,

43:52.960 --> 43:58.880
just like kind of stress or these more generic higher order signaling. That is what allows

43:59.440 --> 44:05.680
nest mates with different brains and bodies to fulfill their own paths of least action.

44:05.680 --> 44:11.440
And then colonies for which that doesn't clean up the mess or it cleans up too well and there's

44:11.440 --> 44:16.800
externalities, those colonies are swept off a table. And then we see the persistence of

44:16.800 --> 44:22.800
collective systems that could figure that out in their growth from a little colony to a big colony

44:23.760 --> 44:30.800
Absolutely, great, great example. I had a question you mentioned, both safety as well as

44:30.800 --> 44:40.240
like reliability. And how do you think about capacities and evaluations on diverse intelligences?

44:40.800 --> 44:48.240
We're all familiar with RAM, CPU, hard drive storage, some of the von Neumann type architectural

44:48.320 --> 44:55.440
descriptors. However, how do we even think about what does that rubric or report card

44:55.440 --> 45:00.160
even start to look like when we know that there's complex interactions with the niche

45:00.160 --> 45:04.240
and when the kinds of capacities that we're talking about may have even open-endedness?

45:05.520 --> 45:12.320
Yeah, great point, great point. So we are the beneficiaries of two big revolutions,

45:12.320 --> 45:17.360
one of them is the AI revolution, but then the older one is the digital electronics revolution.

45:18.480 --> 45:23.760
Digital electronics works, we all have a super computer in our pocket, like there's no arguing

45:23.760 --> 45:29.840
with it. It's an incredibly powerful way to make machines that internally communicate quickly and

45:29.840 --> 45:36.560
richly and then can communicate with other machines. I mean, that's it, that's the information age

45:36.560 --> 45:43.440
that we're in. It's been so successful that it's hard to think about alternatives or why we would

45:43.440 --> 45:50.960
even bother thinking about alternatives. But again, living systems, a lot of what cells do,

45:50.960 --> 45:56.480
they rely on electrical communication, but they also rely on mechanical communication,

45:56.480 --> 46:04.800
chemical communication, thermal communication. Cells are using all physical modalities,

46:04.800 --> 46:10.720
not all physical modalities, as many as they can get their hands on simultaneously all the time.

46:10.720 --> 46:15.040
Why? Why don't they just abandon everything and do everything purely electrically,

46:15.040 --> 46:20.640
like our modern civilization has done? Because it's dangerous, you don't have a diversified

46:20.640 --> 46:26.800
portfolio. So one panel here that I haven't talked about is the one in the bottom right,

46:27.360 --> 46:34.000
which is basically just what you're looking at is what's called a granular material. It's a material

46:34.000 --> 46:39.120
that's made up of a bunch of grains. In this case, the blue circles that you see, these are little

46:39.120 --> 46:46.240
just rubber pucks. And there is an oscillation being supplied at the left hand side. And you can

46:46.240 --> 46:54.000
see that this leads to interesting non-linear vibrational behavior within this material.

46:54.560 --> 47:01.280
What does that have to do with robotics or AI? If you view the vibrations as the carrier of

47:01.280 --> 47:08.640
information, so if a puck is vibrating, that's a one. If the puck is not vibrating, that's a zero.

47:09.840 --> 47:15.440
Now you can start to imagine creating materials that communicate Shannon information

47:16.240 --> 47:22.880
throughout the physical structure, not with electricity, but with a different modality,

47:22.880 --> 47:30.080
dynamics or vibration. And it turns out that you can actually compose these meta materials to

47:30.080 --> 47:37.600
embody logic gates. If you vibrate one particle or another particle, but not both and not neither,

47:37.680 --> 47:44.000
you can watch a third particle and it will either vibrate or not in accordance with an exclusive

47:44.000 --> 47:51.360
OR gate. And you can build this up. Now again, why would you do that? We can make an XOR gate

47:51.360 --> 47:56.800
that's vanishingly small and vanishingly fast in digital electronics. Why would you ever want to

47:56.800 --> 48:03.680
do something different? Because it turns out there are advantages of communicating with vibration

48:03.680 --> 48:10.000
rather than electricity under certain conditions. Having a machine that can communicate between

48:10.000 --> 48:15.840
distant parts of its body through mechanical vibration as well as electricity has an advantage

48:15.840 --> 48:22.640
over a machine that can only communicate long distances within its body electrically. I won't

48:22.640 --> 48:28.320
go into the reasons, but you can intuitively start to understand that. So again, I think we need to,

48:28.880 --> 48:35.280
if we're serious about creating safe and useful autonomous machines, we have to break out of the

48:35.280 --> 48:40.400
digital electronics assumption that that's the only way to do things. We have to break out of

48:40.400 --> 48:46.160
the assumption that non-embodied cognition is the way to go and it's easy to just drop it into a

48:46.160 --> 48:51.920
physical body and we're good to go. We have to peel back some of these very deep assumptions about

48:51.920 --> 48:57.200
the right way to do things that have built up in our society since the Second World War,

48:57.200 --> 49:02.160
because a lot of those technologies have been very successful, nothing wrong with them. But when

49:02.160 --> 49:09.120
we come to apply them to creating safe and useful machines, not always the right thing or the only

49:09.120 --> 49:17.280
way to approach things. That's really interesting. It's like a sort of generalized compute concept

49:17.280 --> 49:23.840
where we could talk about, well, these are the chemicals that it can detect with this fidelity

49:23.840 --> 49:29.120
and here's its tactile interface, here's its electromagnetic capacity for sending and receiving.

49:29.120 --> 49:36.240
That's what kind of motivates or complements the generic theory like free energy principle,

49:36.240 --> 49:42.240
which doesn't tell us about how anything is in particular, but then sets us up with kind of

49:42.240 --> 49:49.440
the framework to plug in these different modules. And then it's an empirical question. And then

49:49.440 --> 49:59.120
right here is sort of the virtual body and a real body. And so that's also very interesting.

49:59.760 --> 50:07.280
How does that work in a collaboration or with a graduate student? How do you balance

50:07.920 --> 50:17.760
this digital adjacent possible off of the material and the more costly implementation with embodiment?

50:18.720 --> 50:24.480
Yeah, well with grad students and postdocs or whoever I'm collaborating with that's kind of

50:24.480 --> 50:29.520
starting out, this can be a very frightening prospect for someone who's trying to get into

50:29.520 --> 50:35.920
AI and robotics because it looks like everything's been done, it's solved. We just have to wait for

50:35.920 --> 50:42.160
Google and Microsoft to buy more compute and data and they're going to finish off the last 1% of

50:42.480 --> 50:49.920
dangerous behavior. So if you're trying to contribute to society's goal of making useful

50:49.920 --> 50:56.400
autonomous safe machines as starting out, what do you do? It looks like this massive brick wall,

50:56.400 --> 51:03.120
there's no entry point. So my take on this is again is that we may be going about this all wrong,

51:03.120 --> 51:09.920
right? The assumption that electricity should be the carrier of information inside an autonomous

51:09.920 --> 51:16.160
machine, that's an assumption. Why electricity? Why not vibration? Why not something else? So

51:17.440 --> 51:21.520
even if you start to think about the alternatives, the immediate reaction as well, it's not going to

51:21.520 --> 51:27.520
be as good, maybe, maybe. But if you think about vibration, you were just mentioning like compute.

51:27.520 --> 51:34.560
We can use vibration for compute, but vibration is movement. So the minute you start to think

51:34.560 --> 51:41.120
about vibration as the carrier of Shannon information, you're now conflating action with

51:41.120 --> 51:49.120
computation. They cannot be separated. Descartes convinced the West 400 years ago that they're

51:49.120 --> 51:58.480
separate. They just are. And you look at AI and robotics, what a surprise. These two are attempts

51:58.560 --> 52:05.680
to create, you know, AGI is bicameral. There's one team that says it's going to happen in computers

52:05.680 --> 52:11.280
and the other side that says it's going to happen in physical machines. That's the Cartesian legacy,

52:11.280 --> 52:16.160
that they're separate. But the minute you look at some very humble material like the one in the

52:16.160 --> 52:22.560
bottom right, it's a bunch, it's 12 hockey pucks next to one another. There's no Cartesian division

52:22.560 --> 52:28.720
anymore between body and brain. There is a body and there is a brain there, but it looks very

52:28.720 --> 52:36.720
different from anything we would usually consider. And there's no value judgment here. It's not

52:36.720 --> 52:43.600
better or worse, maybe it is depending on what your metric is. It's just very different. And so

52:43.600 --> 52:50.400
with grad students and postdocs, I encourage them to pursue that. Could we do things completely

52:50.400 --> 52:57.120
differently? And in the long run, might that be a better way to do things? Who knows? We'll see.

52:58.880 --> 53:05.120
Awesome. I'll make one comment and then ask a last question. You brought up Descartes and that's

53:05.120 --> 53:14.560
the rest extensa, rest cognitive dualism between the thinking and the non-thinking substance and

53:15.120 --> 53:22.800
embodied cognition, embodied intelligence provides both an operational, instrumental,

53:22.800 --> 53:29.200
and an ontological counter argument or complementary perspective, which is just, well,

53:29.200 --> 53:36.640
in practice and in actuality, take it or leave it, they are inseparable. And so at the very least,

53:36.640 --> 53:42.640
that that starts to ratchet and leapfrog the discussion about what is mind and body.

53:43.440 --> 53:49.200
And you started with pointing out how important it was to co-evolve and the complementarity of

53:49.200 --> 53:53.520
mind and body. And it's like, there are two separate things that need to be complementary

53:53.520 --> 54:01.120
and tangoing. And also, maybe they're integrated and blurred in even deeper ways than the dance.

54:01.120 --> 54:08.800
So it's an empirical entry point into what otherwise is a thought experiment, which can

54:08.880 --> 54:16.240
have utility, but also can be just arbitrarily misleading. Absolutely. One of my former mentors,

54:16.240 --> 54:21.600
Inman Harvey at the University of Sussex, used to talk about robotics as philosophy with a screwdriver.

54:22.960 --> 54:27.040
It's not just armchair philosophy. It's when you start to build some of these machines,

54:27.600 --> 54:33.280
maybe in retrospect, in the case of the Metamaterials project, for me in retrospect,

54:33.280 --> 54:38.640
I said, oh my God, most action and cognition are not complementary, separate things that

54:38.640 --> 54:43.440
are complementary. They're one and the same thing. It's not embodied cognition. It's not

54:43.440 --> 54:51.600
an adjective of a noun. It's embodiment is cognition. There are not two things here.

54:51.600 --> 54:57.760
There's just one thing. Very hard to think about. It's so alien to a Western mind, but

54:58.880 --> 55:04.640
it just is. Sometimes I think about that in terms of adjectives getting added in front of a word

55:04.720 --> 55:11.680
and then the term expanding, and then it just encompassing, oh, of course, cognition is ecological,

55:11.680 --> 55:16.080
embodied, enacted, et cetera, et cetera, et cetera, et cetera. And then so it kind of like needs to be

55:16.080 --> 55:25.200
distinguished. And then it subsumes again. And that's part of in closing, like, what are you excited

55:25.200 --> 55:31.840
about? Where can people continue to learn more? What would you say to a person who's wanting to

55:31.840 --> 55:41.520
like go in this area? Yeah. Okay. Great question. So Google my name and it'll take you into lectures

55:41.520 --> 55:47.200
and papers and tutorials. And people want folks want to email me. That's perfectly fine. Again,

55:47.200 --> 55:50.720
Google my name. You can find my email. Happy to put you in touch with the right people.

55:52.240 --> 55:57.520
I think it's, you know, it's easier than ever to get started. You can go to chat GPT and say,

55:57.600 --> 56:04.720
you know, create some tutorials for me to start coding up robots. You know, they're, ironically,

56:04.720 --> 56:10.640
non embodied AI provides a good on ramp now, not just for reading about these ideas or listening to

56:10.640 --> 56:16.480
people talk about these ideas. You can start coding them up in a way that was easier than ever.

56:16.480 --> 56:21.040
That's easier than ever. The old days, you know, you had to learn C and then, you know,

56:21.040 --> 56:26.960
go on from there. Very easy to get your hands dirty, maybe not with physical materials,

56:26.960 --> 56:32.480
but you can create like you see in the left of each of these panels. You can create machines that

56:32.480 --> 56:37.280
are virtual. They're not physical, but they're embodied. It's another point that's important

56:37.280 --> 56:44.240
to make embodiment does not imply physicality. You need to be able to push against the world and

56:44.240 --> 56:49.600
observe how the world pushes back, but the world and you may be virtual like you see on the left

56:49.600 --> 56:55.520
or physical like you see on the right. So you can actually relatively quickly get your hands dirty

56:55.520 --> 57:01.440
with playing around with embodied AI these days. And I encourage everyone to do so.

57:02.880 --> 57:04.880
Cool. Any last comments?

57:06.320 --> 57:12.800
I would just say I was at the computer vision and pattern recognition conference CVPR a few

57:12.800 --> 57:18.720
weeks back. This is one of the flagship AI conferences, 15,000 attendees. And after my

57:18.720 --> 57:22.880
talk, a lot of grad students came up and they said, listen, I, you know, you, you sort of

57:22.880 --> 57:28.000
demonstrated there's another path here that I was feeling depressed or anxious about how to make

57:28.000 --> 57:33.440
progress in AI when these goliaths are, you know, have these data centers at their beck and call.

57:34.160 --> 57:40.160
I would just encourage everyone that when you think differently about all this stuff,

57:40.720 --> 57:45.520
there are new paths that open up. They may not in the long run be the right path, but there are

57:45.520 --> 57:52.080
alternatives to this monolithic predict the next token idea, which is currently, you know,

57:52.080 --> 57:58.960
in vogue. It's, it may be the beginning of the end, but I think this is just the end of the

57:58.960 --> 58:04.080
beginning. We've, we figured a few things out. There are some things that work, but they're

58:04.080 --> 58:10.160
still producing not quite useful and definitely dangerous machines. There is room for improvement.

58:10.160 --> 58:15.120
And there's nothing that says that only Google, Google with all its resources is going to be the

58:15.120 --> 58:20.720
one that can figure out these improvements. Think differently, try some of these alternative

58:20.720 --> 58:28.800
approaches and maybe you will be the one, you know, that comes up with the answer, whatever it is.

58:29.840 --> 58:36.240
Cool. Good luck. Awesome. Thank you, Josh. Really appreciate it. Thanks for having me.

58:36.240 --> 58:42.000
Yeah. And until next time. Thank you. Bye.

58:50.720 --> 58:52.100
you

59:20.720 --> 59:22.100
you

