1
00:00:00,000 --> 00:00:14,520
Hello and welcome, everyone. It's January 26th, 2024. We're here in active inference,

2
00:00:14,520 --> 00:00:22,480
MathStream 8.1 with Richard Sarajevan. And we're going to have an interesting presentation

3
00:00:22,480 --> 00:00:28,080
and discussion today on introduction to Bayesian mechanics, free energy principle and the state

4
00:00:28,080 --> 00:00:34,880
based formalism. This is part one. So Richard, thank you for joining. Looking forward to this

5
00:00:34,880 --> 00:00:42,480
presentation and discussion. So to you. Hi, everybody. So yeah, my name is Richard Sarajevan.

6
00:00:42,480 --> 00:00:51,520
I'm French working in Switzerland. I'm a PhD student at EPFL in Lausanne. And just to bring a bit

7
00:00:51,520 --> 00:01:00,080
of context, I'm not working on Bayesian mechanics. We are, we do have a physics background, but we

8
00:01:00,080 --> 00:01:07,680
are interested in modeling bacterial evolution and ecology. And what happened is that something like,

9
00:01:08,560 --> 00:01:14,400
I mean, the free energy principle was always in the corner of my head. And one year and a half ago,

10
00:01:14,400 --> 00:01:21,040
I decided to really read about the free energy principle, especially if I wanted to transition

11
00:01:21,120 --> 00:01:27,200
to the field. And I do want to transition to the field after my PhD. And so I started to ask

12
00:01:27,200 --> 00:01:32,720
many questions to the people from the FEP community. And I'm so grateful. Thanks for them.

13
00:01:33,440 --> 00:01:40,240
And also on the discord of the of the active inference Institute. And at some point, I said that

14
00:01:40,240 --> 00:01:48,320
I was preparing a lab meeting about the free energy principle. And Daniel proposed to have this

15
00:01:48,880 --> 00:01:55,440
discussed on the live stream, because there isn't such material to specifically learn about

16
00:01:56,240 --> 00:02:00,320
Bayesian mechanics and the actual physics underlying the free energy principle.

17
00:02:01,520 --> 00:02:08,160
And so here I am. So once again, I'm not an expert on the matter. So always refer to the

18
00:02:08,160 --> 00:02:16,080
original papers. But hopefully I gonna, I gonna do a decent job. So without further ado, let's,

19
00:02:16,080 --> 00:02:23,120
let's start. I'm not going to tell you what we where we are heading, what questions we would like to

20
00:02:24,080 --> 00:02:28,960
to address or whatever. I'm rather rather going to start building the framework right away.

21
00:02:29,680 --> 00:02:34,000
And at some point, what we're doing, doing will become clear. So

22
00:02:35,440 --> 00:02:40,000
as you may know, there are two formulations or formalisms

23
00:02:40,960 --> 00:02:47,280
of the free energy principles, the so called state based formulation, and the so called

24
00:02:47,280 --> 00:02:55,280
path based formulation. So today, we will focus on the state based formalism. It's not like the old

25
00:02:55,280 --> 00:03:01,840
versus the new formulation. In fact, thinking in terms of path, or so called generalized

26
00:03:01,840 --> 00:03:08,400
coordinates of motion, I've been around forever, but in the literature, but it kind of came back

27
00:03:08,400 --> 00:03:14,320
to the front scene of the Bayesian mechanics literature, I think. Anyway, today, we will

28
00:03:14,320 --> 00:03:23,120
focus on the state based form, formalism. So the very starting point is to write down

29
00:03:23,120 --> 00:03:29,840
Langevin equation, a generic Langevin equation. So it's literally like saying, let's consider

30
00:03:29,840 --> 00:03:37,120
a random dynamical system. Very briefly for the people not acquainted with such an equation,

31
00:03:37,920 --> 00:03:44,480
x here is the state of your system. So it could be a simple scalar if you are

32
00:03:44,480 --> 00:03:51,600
considering a one dimensional process. But in general, x would be a vector. For instance,

33
00:03:51,600 --> 00:03:59,200
if I don't know, you want to, to model the 3d diffusion of a Brownian particle immersed in

34
00:03:59,200 --> 00:04:06,640
a liquid, x would be a 3d vector was components are the coordinates of your Brownian particle.

35
00:04:07,680 --> 00:04:14,080
And you can see on the left hand side that we have dx over dt, the time derivative of the state

36
00:04:14,080 --> 00:04:22,080
vector. So that's such an equation really describes or specifies the dynamics of the system.

37
00:04:23,120 --> 00:04:28,160
So many things can influence indeed the dynamics of the system. If I stick to my

38
00:04:28,160 --> 00:04:34,960
Brownian particle example, maybe it is subject to an external force. So whatever is relevant here,

39
00:04:34,960 --> 00:04:42,000
you put it in F, the so-called deterministic term or flow, we will refer to it as the flow

40
00:04:42,000 --> 00:04:49,040
for the presentation. However, in some cases, there is stuff you don't want to explicitly model.

41
00:04:49,760 --> 00:04:57,040
For instance, if I stick with my Brownian particle example, it is constantly hit by

42
00:04:58,240 --> 00:05:02,720
the molecules of the medium surrounding it. Hence it's a Brownian motion, right?

43
00:05:03,680 --> 00:05:08,720
And it would be so if you want to take into account this thermal fluctuations,

44
00:05:08,720 --> 00:05:15,440
it would be mission impossible to explicitly model every single molecule of the millions,

45
00:05:15,440 --> 00:05:21,840
if not billions of the molecules surrounding it. So a convenient way to still take into account

46
00:05:21,840 --> 00:05:28,000
these fluctuations, which are literally thermal fluctuations in my example, a convenient way

47
00:05:28,080 --> 00:05:36,960
to proceed is just to add a noisy term to the equation. So omega here is a random variable

48
00:05:37,520 --> 00:05:46,240
was value changes with time with the appropriate statistics. Okay, so two brief remarks before

49
00:05:46,240 --> 00:05:53,920
moving on. If you assume that the state of your system changes slowly compared to the time relaxation

50
00:05:54,880 --> 00:06:00,560
of your fluctuations, you can write the autocorrelation function of the

51
00:06:01,360 --> 00:06:08,480
noise like that, where gamma is the diffusion matrix and delta is the delta direct function.

52
00:06:08,480 --> 00:06:16,240
So what it means, it's just that in that case, your noise is super rough and it's not correlated

53
00:06:16,240 --> 00:06:24,160
in time basically. Also, second remark, you can, I mean, you can use the central limit theorem

54
00:06:24,160 --> 00:06:32,560
to argue that it makes sense to assume that omega is normally distributed. So that in the end,

55
00:06:33,760 --> 00:06:39,280
the noise is a Gaussian white noise, but not that in the next live stream where we will

56
00:06:40,000 --> 00:06:46,000
discuss the path based formulation of the FEP, we will relax the white noise assumption.

57
00:06:46,720 --> 00:06:55,920
Anyway, so we have this random dynamical system. And we can do something cool with the flow. So

58
00:06:55,920 --> 00:07:02,560
the flow F is a vector, it has the same dimension than the state vector, because each component

59
00:07:02,560 --> 00:07:09,200
of the state vector has its own longitudinal equation, if you will. And you can decompose it

60
00:07:09,200 --> 00:07:19,280
into a solenoidal and a gradient terms. So before telling you what this decomposition is all about,

61
00:07:20,000 --> 00:07:29,520
on a technical note, just notice that first Q here is the so-called solenoidal matrix. Gamma

62
00:07:29,520 --> 00:07:38,720
is the diffusion matrix just as before. And the I here with the nabla I, this I of X here,

63
00:07:38,720 --> 00:07:45,280
is a negative log of a density. So it's a self-information or surprise we will refer to

64
00:07:45,280 --> 00:07:54,080
it as the surprise throughout the presentation. And the density at play here in this negative

65
00:07:54,080 --> 00:08:02,880
log density is the steady state or nest for non-equilibrium steady state density of the system.

66
00:08:02,880 --> 00:08:11,280
So we assume that there is such nest density that exists, so that if you from a given initial

67
00:08:13,200 --> 00:08:20,080
initial state you let your system evolve, it will reach at some point a unique well-defined

68
00:08:21,040 --> 00:08:28,160
nest density. And second remark before telling you what this decomposition is all about,

69
00:08:28,160 --> 00:08:37,920
note that usually in the papers the divergent terms here and here are put together in a third term

70
00:08:39,600 --> 00:08:47,280
which is sometimes called housekeeping or correction term. But actually if Q and gamma

71
00:08:47,280 --> 00:08:57,040
are not state dependent, these divergent terms vanish anyway and we end up with these the two

72
00:08:57,040 --> 00:09:04,720
remaining terms which can be nicely factorized like that. Also a last thing I want to say is that

73
00:09:05,440 --> 00:09:12,880
if you you consider the solenoidal term, the first term, it is indeed a solenoidal term,

74
00:09:12,880 --> 00:09:19,520
you can indeed write it as the rotational of some potential. I'm saying that because sometimes

75
00:09:19,520 --> 00:09:29,840
people get confused when they see a gradient in both terms. Anyway, what this decomposition is all

76
00:09:29,840 --> 00:09:44,320
about is quite in fact simple. Let's consider this nice 2D single-moded nest density. Okay, so the flow

77
00:09:44,320 --> 00:09:52,880
and more specifically the gradient component of the flow which is here the vertical flow will drive

78
00:09:52,880 --> 00:10:00,880
the system towards its mode while fluctuations kind of push it away. But it's not the only flow,

79
00:10:00,880 --> 00:10:08,320
there is also the solenoidal flow which is here called the horizontal flow which

80
00:10:10,000 --> 00:10:21,440
will make the system kind of converge to its mode with ever-decreasing cycles. And so if you want to

81
00:10:21,440 --> 00:10:27,360
get some more intuitions on this solenoidal flow what we can do is to remove the fluctuations.

82
00:10:28,240 --> 00:10:35,360
So all the entries of gamma, the diffusion matrix go to zero and this means that we would not have

83
00:10:35,360 --> 00:10:41,280
any gradient flow anymore. We end up with only the solenoidal flow and if we do that

84
00:10:43,360 --> 00:10:49,760
the system will just follow an isocontour circulation on the nest density that's the

85
00:10:50,320 --> 00:11:00,000
bottom right panel here where the solenoidal flow kind of drives the system on this circulation here.

86
00:11:00,560 --> 00:11:10,560
So a small remark about this solenoidal flow because it kind of drives the system in this simple

87
00:11:10,560 --> 00:11:18,080
example in either clockwise or anti-clockwise direction in an irreversible fashion, irreversible

88
00:11:18,080 --> 00:11:26,560
in the statistical physics sense. So it breaks detail balance and so on. People sometimes view

89
00:11:26,560 --> 00:11:33,920
this solenoidal flow as underwriting the symmetry breaking ubiquitous in living systems. Anyway,

90
00:11:34,880 --> 00:11:43,120
okay so before using this decomposition of the flow to do some cool stuff I need to introduce

91
00:11:43,120 --> 00:11:50,800
some stuff. So I will have to go through a couple of things of notions one after the other

92
00:11:51,440 --> 00:11:58,160
and afterwards we will put everything together and actually derive the free energy principle.

93
00:11:59,040 --> 00:12:07,200
So the first thing I want to introduce is the notion of sparse coupling. So let's say that

94
00:12:07,280 --> 00:12:15,600
in my state vector x here I have a subset of variables this mu here we refer to as the

95
00:12:15,600 --> 00:12:25,600
internal states and they specify the state of some subsystem called mu. So I mean you get the idea

96
00:12:27,360 --> 00:12:34,400
that we have like an organism, an agent, the bacteria in my schematic and these variables here

97
00:12:34,400 --> 00:12:43,120
literally specifies the internal states of my bacteria and this bacteria is in a given

98
00:12:43,840 --> 00:12:52,400
environment, niche, whatever. So there is this other subsets of variable we refer to as the

99
00:12:52,400 --> 00:12:59,440
external states and which corresponds to the external world, the external states of the

100
00:12:59,680 --> 00:13:08,240
bacteria. And the idea here is that these two subsystems are not connected to each other. So

101
00:13:08,240 --> 00:13:13,840
when I'm saying that two variables are not connected to each other I just mean that

102
00:13:15,760 --> 00:13:22,800
their respective flows do not take the other one state as arguments so they do not influence

103
00:13:22,880 --> 00:13:30,400
each other basically. In fact they are indirectly connected to each other thanks

104
00:13:30,400 --> 00:13:39,280
or through a third subsystem we refer to as the marcov blanket so that these guys here

105
00:13:39,280 --> 00:13:44,880
are called the blanket states and we will see in a minute that it really corresponds to a

106
00:13:44,880 --> 00:13:53,200
marcov blanket in a statistical sense. Okay so we have this architecture, this

107
00:13:53,200 --> 00:13:59,280
path coping architecture here and in fact we can even go a bit further and assume that

108
00:13:59,920 --> 00:14:07,040
within the blanket there are two more systems, the so-called sensory states and the so-called

109
00:14:07,040 --> 00:14:16,800
active states A. So basically the idea here is that the external states eta they influence the

110
00:14:16,800 --> 00:14:24,480
sensory states S and these sensory states S influence the internal states mu but not the

111
00:14:24,480 --> 00:14:33,120
other way around and the internal states mu they influence the active states A which influence

112
00:14:33,120 --> 00:14:40,480
the external states eta but not the other way around. So it's really a path coping architecture

113
00:14:40,480 --> 00:14:47,760
inspired by the so-called action perception loop however you could ask questions like why do the

114
00:14:47,760 --> 00:14:55,360
sensory states influence the external states or why do the active states influence the internal

115
00:14:55,360 --> 00:15:02,320
states etc. So we don't have really time to discuss this I guess you can think of some

116
00:15:03,360 --> 00:15:11,120
qualitative example in biology but I just want to point out that even though this architecture is

117
00:15:11,120 --> 00:15:18,000
quite canonical it's not a definitive feature of the free-nury principle and in fact in the next

118
00:15:18,000 --> 00:15:24,720
time when we will discuss the other formalism we will do a bit of zoology and we will look at

119
00:15:24,720 --> 00:15:33,920
other path coping architecture. Okay so on a technical note just notice that such

120
00:15:34,720 --> 00:15:40,640
path couplings are encoded by zero entries in the Jacobian matrix of the flow.

121
00:15:41,520 --> 00:15:48,000
Anyway so thanks to this path coupling architecture we have this system of four

122
00:15:48,560 --> 00:15:54,880
coupled long-run equations which respectively describes or specifies

123
00:15:56,240 --> 00:16:03,760
the dynamics of the external states eta the sensory and active states s and a and

124
00:16:04,480 --> 00:16:16,880
of the internal states mu. Okay so I want to say here about the Markov-Blanket thing

125
00:16:16,880 --> 00:16:23,520
that under some conditions I'm not going to discuss here so for the people acquainted it

126
00:16:23,520 --> 00:16:30,400
involves having no solenoidal couplings between autonomous and not autonomous states but anyway

127
00:16:30,400 --> 00:16:38,560
I'm not going to go into this let's say under some conditions the external states eta and the

128
00:16:38,560 --> 00:16:45,280
internal states mu are conditional independent so they are independent when conditioned upon b

129
00:16:45,280 --> 00:16:53,280
which makes sense because all the informations kind of transit through b however not that when

130
00:16:53,280 --> 00:16:59,440
I'm talking about conditional independences here I'm talking about conditional independences

131
00:16:59,440 --> 00:17:07,120
in the stationary density so basically if you fix p and you have this joint

132
00:17:08,080 --> 00:17:16,640
uh conditional stationary density here for x i and x j if these two guys are conditional

133
00:17:16,640 --> 00:17:24,000
independent it just means that you can write this joint density like that and so that such

134
00:17:24,000 --> 00:17:31,440
conditional uh independences are encoded by zero entries in the ACN matrix of surprizo.

135
00:17:31,840 --> 00:17:42,240
Okay so now just a bit more of vocabulary before moving on um note that if we

136
00:17:43,440 --> 00:17:49,200
put together a and mu so we consider the couple active states and internal states

137
00:17:50,160 --> 00:17:57,120
we refer to to these guys are as the autonomous states alpha and the cool thing about the

138
00:17:57,120 --> 00:18:05,440
autonomous states a and mu or alpha is that they are conditionally independent of the external

139
00:18:05,440 --> 00:18:13,760
states so autonomous and external states are independent when conditioned upon uh sensory

140
00:18:13,760 --> 00:18:23,360
states and if you add the sensory state s to the autonomous states so you consider the whole thing

141
00:18:23,360 --> 00:18:30,160
the whole marco blanket and the act and the internal states we refer to to these guys as the

142
00:18:30,160 --> 00:18:37,600
particular states pi and pi constitutes a particle a particle in a generic sense of course

143
00:18:37,600 --> 00:18:46,320
so an organism an agent whatever a bacteria in my schematic okay so here I just want to make a

144
00:18:46,320 --> 00:18:51,760
point to make a bit more clear what we are doing what what this this approach is all about

145
00:18:52,000 --> 00:19:01,040
so basically here we kind of define what it means for something a bacteria any whatever to exist in

146
00:19:01,040 --> 00:19:09,760
the sense that it has its own internal dynamics statistically separated from the the external

147
00:19:09,760 --> 00:19:17,360
it does have a marco blanket it does have its own physical integrity so we have no clue of how it

148
00:19:18,000 --> 00:19:26,080
maintains indeed it's it's uh it's integrity in the sense that if you're considering uh real systems

149
00:19:26,080 --> 00:19:34,560
like like an like an actual bacteria or a human being or whatever it it does survive at a given

150
00:19:34,560 --> 00:19:41,440
in a given time scale um right for instance this playing I don't know like active processes

151
00:19:42,000 --> 00:19:48,320
contouring dissipation for instance here we don't say anything about how it does survive it just

152
00:19:48,320 --> 00:19:55,440
does we do have this path coupling architecture and from there from the starting point we are going

153
00:19:55,440 --> 00:20:05,120
to derive the the necessary uh the consequences of such sparse coupling so basically we kind of ask

154
00:20:05,120 --> 00:20:13,600
or answer to or try to answer the questions if things exist what must they do and so if you're

155
00:20:13,600 --> 00:20:19,760
a bit confused don't worry we're going to go back to this idea later but I just want first to show

156
00:20:19,760 --> 00:20:27,280
you this quote here which tells you many theories in the biological sciences are answers to the

157
00:20:27,280 --> 00:20:34,720
question what must things do in order to exist the FEP turned this question on its head and

158
00:20:34,720 --> 00:20:42,160
asks if things exist what must they do but once again we are going to go back to this idea later

159
00:20:42,160 --> 00:20:51,760
but that's kind of the idea of this approach in a nutshell so as I told you I still have a couple

160
00:20:51,760 --> 00:20:59,120
of things to present so I will have to go through each of them one after the other and finally we

161
00:20:59,120 --> 00:21:06,720
will put everything together and finally derive the free energy principle so the next thing I need

162
00:21:06,720 --> 00:21:18,320
to introduce is the notion of synchronization map so very uh very generally speaking I'm not

163
00:21:18,320 --> 00:21:25,280
specifically here talking about our random dynamical system if you have a linear map

164
00:21:26,000 --> 00:21:36,640
uh g mu here which gives you mu from b and g eta here which gives you eta from b then

165
00:21:37,920 --> 00:21:44,160
if g mu here is injected so that basically you can go back to the pre-image from the image

166
00:21:44,720 --> 00:21:53,360
you can use the pseudo inverse of g mu so that from mu you go back to b and from b you can go back

167
00:21:53,360 --> 00:22:08,640
to you can go to eta so the successive application of the pseudo inverse of g mu and then of g eta

168
00:22:09,680 --> 00:22:17,040
is called the synchronization map and it basically allows you to directly go to eta from mu

169
00:22:18,000 --> 00:22:29,920
okay so now let's try to uh to use this idea in the context of our system so b here corresponds to

170
00:22:29,920 --> 00:22:37,920
the blanket states so if I fix the blanket states I have a corresponding conditional

171
00:22:37,920 --> 00:22:46,160
densities for mu and eta I have p of mu given b and p of eta given b and I call and what I

172
00:22:46,240 --> 00:22:55,200
I am and their their modes are bold mu and bold eta so in virtue of this synchronization map

173
00:22:55,920 --> 00:23:03,520
I can go back to the external mode from the internal mode thanks to once again this

174
00:23:03,520 --> 00:23:11,040
synchronization map here and I'm going to give an example in a sec which is going to to make

175
00:23:11,040 --> 00:23:16,560
to clarify a bit more what we are doing here but first I just want to say that

176
00:23:17,440 --> 00:23:24,080
in this nice paper by Lenz Dacosta about this this this synchronization map

177
00:23:24,800 --> 00:23:34,000
basically everything was Gaussian but sometimes I mean if it is not the case a Laplace approximation

178
00:23:34,000 --> 00:23:41,200
which which is literally a Gaussian approximation might be necessary to derive a synchronization

179
00:23:41,200 --> 00:23:47,760
map of closed form but don't worry we'll go back to this idea of Laplace approximation later just

180
00:23:47,760 --> 00:23:55,440
remember that we have this synchronization map here which allows you to go to the external map

181
00:23:56,160 --> 00:24:05,360
external mode sorry from the internal mode so for instance if given b given the blanket states

182
00:24:06,480 --> 00:24:16,320
the corresponding p of eta given b follows this nice normal distribution where bold

183
00:24:16,640 --> 00:24:27,440
bold eta here corresponds to the mode then in virtue of the synchronization map I can view

184
00:24:27,440 --> 00:24:36,800
the internal mode mu as parameterizing a density I write it that way q mu which is equal to this

185
00:24:36,800 --> 00:24:44,720
nice normal distribution where the mode is just the synchronization map applied to the internal

186
00:24:44,720 --> 00:24:53,120
mode to itself and by construction of the synchronization map it is equal to the true

187
00:24:53,120 --> 00:25:02,240
external density so you can view the internal mode as parameterizing a distribution over

188
00:25:02,240 --> 00:25:07,760
external states basically thanks to the synchronization map that's why what the synchronization map

189
00:25:07,760 --> 00:25:14,960
is all about so just a small point because maybe some of you are a bit confused here because we're

190
00:25:14,960 --> 00:25:25,360
talking about modes as opposed to actual states so we will talk about that later but indeed I mean

191
00:25:25,360 --> 00:25:32,160
if I take the actual internal states at a given time t they are not necessarily equal to their modes

192
00:25:32,240 --> 00:25:38,720
just because of fluctuations or whatever so that if I apply the synchronization map on the actual

193
00:25:39,680 --> 00:25:47,520
internal states it might not give you the true external mode but anyway we will discuss this

194
00:25:49,040 --> 00:25:54,560
a bit more later so that was the notion of synchronization map in a nutshell basically

195
00:25:55,360 --> 00:26:03,200
so last thing I want to to introduce before finally putting everything together and actually

196
00:26:03,200 --> 00:26:11,520
derive the free energy principle is the notion of variational inference so very simply let's say

197
00:26:11,520 --> 00:26:20,000
that you have some latent variables or hidden variable or some latent generative process

198
00:26:20,960 --> 00:26:31,520
causing some data s so you have a prior p of eta over the state of these hidden causes of data

199
00:26:32,320 --> 00:26:39,600
and you are also equipped with a generative model which just designates this joint distribution

200
00:26:39,600 --> 00:26:48,320
here p of eta and s so you can view it as a model of how the latent variables cause the data

201
00:26:49,200 --> 00:26:57,600
so the idea here is the following you sample some data s and you want to compute the posterior

202
00:26:57,600 --> 00:27:04,560
distribution p of eta given s so in a way you want to refine your belief about the

203
00:27:06,000 --> 00:27:14,000
the hidden cause of data thanks to a new sample data so it's very simple you in principle because

204
00:27:14,000 --> 00:27:23,920
you just have to apply base theorem right however in practical settings the denominator here p of s

205
00:27:24,560 --> 00:27:35,040
so the marginal density over sensory data usually requires a monstrous marginalization so it's just

206
00:27:35,040 --> 00:27:46,480
not tractable so we can't just apply a base theorem so we need we need a method uh which

207
00:27:46,480 --> 00:27:56,080
given some variational sorry which given some some variational distribution q also called recognition

208
00:27:56,080 --> 00:28:05,920
density uh gives us uh i mean we want a method that makes it as close as possible if not equal

209
00:28:06,480 --> 00:28:13,760
to the true distribution we want ultimately to compute namely p of eta given s and these two

210
00:28:13,760 --> 00:28:22,480
density so q our variational distribution and the true distribution p of eta given s are equal or

211
00:28:22,880 --> 00:28:32,960
more or less equal if their divergence cal divergence here is zero because this quantity here the cal

212
00:28:32,960 --> 00:28:42,000
divergence basically measure the difference between two distributions so that's what i wrote here on

213
00:28:42,000 --> 00:28:49,840
the top of the slides finding an accurate distribution q in the sense of finding a q as close as possible

214
00:28:49,840 --> 00:28:59,200
if not equal to the true target density is equal to minimize to minimizing these divergence

215
00:28:59,840 --> 00:29:06,960
however these divergence i mean there is the target density appearing here we can't

216
00:29:07,520 --> 00:29:13,440
do anything directly with it we can't compute it or whatever we need a proxy for this target

217
00:29:13,440 --> 00:29:21,200
divergence and there in the proxy called variational free energy f in green in my in my uh slide here

218
00:29:21,760 --> 00:29:31,840
so f is is equal to this divergence here between q and the generative model and the idea here is

219
00:29:31,840 --> 00:29:39,120
that you can decompose these divergence into the true the target sorry into the target divergence

220
00:29:39,840 --> 00:29:46,000
in red here plus something so it is indeed a proxy for the target divergence

221
00:29:47,520 --> 00:29:56,240
and note that interestingly enough the second term here is the surprise over sensory data or

222
00:29:56,240 --> 00:30:04,480
negative log p of s so that f is it can be viewed as an upper bound or lower bound depending on how

223
00:30:04,480 --> 00:30:13,440
you define it uh unsurprise okay so what i just said here is that minimizing the target

224
00:30:14,160 --> 00:30:23,520
divergence just means minimizing f so that's basically what variational inference uh is all

225
00:30:23,520 --> 00:30:32,720
about and note that usually algorithms require q to be Gaussian or require a mean field approximation

226
00:30:32,720 --> 00:30:41,440
or whatever and if q is required to be Gaussian even though the target density is not Gaussian

227
00:30:41,440 --> 00:30:48,320
we would end up with the best Gaussian approximation of the target density basically

228
00:30:48,320 --> 00:30:55,840
and in practice it would mean working with a so-called Laplace encoded free energy

229
00:30:55,920 --> 00:31:06,000
okay so before moving on i just want to say that uh this quantity the variational free energy

230
00:31:06,800 --> 00:31:13,920
is in itself a quite rich and interesting quantity so you can decompose it in many ways

231
00:31:13,920 --> 00:31:21,200
and each decompose uh provide interesting uh interpretations for instance if you look at

232
00:31:21,200 --> 00:31:27,760
the second line here you can see that minimizing free free energy means

233
00:31:30,480 --> 00:31:36,880
maximizing this accuracy term here you basically want to explain the data i would say but at the

234
00:31:36,880 --> 00:31:44,960
same time you you want q to differ the least possible from a prior distribution so that's

235
00:31:44,960 --> 00:31:53,760
that's um an interesting quantity anyway now let's finally go back to our sparsely coupled

236
00:31:53,760 --> 00:32:01,760
random dynamica system and use everything we we talked about and finally let's uh derive the

237
00:32:01,760 --> 00:32:10,640
free energy principle so here is our system and we have this four langen equations and the first

238
00:32:10,640 --> 00:32:16,560
thing to do is just to apply the decomposition we talked about in the beginning so basically

239
00:32:17,920 --> 00:32:25,360
the flows of each of them can be written like that so i just directly applied the Helmholtz

240
00:32:25,360 --> 00:32:36,320
decomposition we talked about in the beginning okay so now um let's try to understand uh how

241
00:32:36,320 --> 00:32:45,040
it works let's talk about the dynamics of the system let's say that uh so there is a momentary

242
00:32:45,040 --> 00:32:52,720
instantiated uh uh sensory state and let's fix let's say that the sensory states are fixed

243
00:32:52,720 --> 00:33:00,080
and there is a corresponding autonomous density uh autonomous mode toward which the autonomous

244
00:33:00,080 --> 00:33:08,240
states are going to converge and stay in the vicinity of the of their mode in the closed

245
00:33:08,240 --> 00:33:18,080
vicinity if uh fluctuations are not too large okay but in fact sensory states with time changes

246
00:33:19,600 --> 00:33:28,960
so that the the mode of the autonomous state move as well and in fact it it moves on its

247
00:33:28,960 --> 00:33:33,920
corresponding autonomous manifold so i'm not going to go into the details but just

248
00:33:33,920 --> 00:33:40,960
have in mind that the autonomous mode moves on a so-called autonomous manifold which can

249
00:33:40,960 --> 00:33:46,160
be viewed as a statistical manifold and which can also be viewed as a so-called center or

250
00:33:46,160 --> 00:33:57,280
center manifold so if i kind of rephrase what i am saying here is that the flow of the of the

251
00:33:57,280 --> 00:34:07,440
autonomous states can be decomposed into uh off manifold flow and uh on manifold flow which

252
00:34:07,440 --> 00:34:14,960
corresponds to the path of the mode itself on the manifold okay so just to be a bit more clear

253
00:34:15,520 --> 00:34:24,480
let's say in my bottom right uh illustration diagram here the autonomous states are here

254
00:34:25,040 --> 00:34:36,160
and i'm i'm interested in the the off manifold flow so basically i have the this component here

255
00:34:36,160 --> 00:34:41,920
which corresponds to the gradient flow towards the manifold towards the mode basically here it's

256
00:34:41,920 --> 00:34:49,120
pretty much like what we discussed in the beginning and at the same time there is here this orthogonal

257
00:34:49,760 --> 00:34:58,880
component which corresponds to the solenoidal flow so that's basically the way the autonomous state

258
00:34:58,880 --> 00:35:07,440
are going to reach their mode here it can be viewed as this ever decreasing cycle towards

259
00:35:07,440 --> 00:35:16,560
the the manifold on which the autonomous mode move okay so that's a bit dense i guess so

260
00:35:17,200 --> 00:35:23,120
i recommend to check the paper the free energy principle made simpler but not too simple which

261
00:35:23,120 --> 00:35:34,800
kind of discuss all this this idea about center manifolds and stuff so here the interesting point

262
00:35:34,800 --> 00:35:44,560
is that if you assume a separation of timescale between the fast flow of the manifold as opposed

263
00:35:44,560 --> 00:35:53,040
to the slow flow on the manifold basically the autonomous state always are always in the vicinity

264
00:35:53,040 --> 00:35:58,480
of their modes and if you want to characterize the overall dynamics of the autonomous states

265
00:35:58,480 --> 00:36:07,040
you can focus on the autonomous mode on the path of the mode and in the next slides we will indeed

266
00:36:07,040 --> 00:36:17,200
focus on the autonomous mode and and by definition as we already discussed the autonomous mode

267
00:36:18,000 --> 00:36:23,520
the autonomous mode is or corresponds to the autonomous states which minimize

268
00:36:25,760 --> 00:36:33,520
surprise here in the last two launch variations because the autonomous mode corresponds to the

269
00:36:33,520 --> 00:36:40,320
least surprise of autonomous states before moving on i just want to say something

270
00:36:41,360 --> 00:36:46,000
we can maybe discuss afterwards because i'm not sure to fully understand but basically

271
00:36:47,280 --> 00:36:54,480
if i'm here in my bottom right schematic and so i have this gradient flow towards the manifold and

272
00:36:54,560 --> 00:37:04,720
this solenoidal flow parallel to the manifold and if i remove fluctuations so all the corresponding

273
00:37:04,720 --> 00:37:11,600
entries in the diffusion matrix go to zero as we saw in the beginning it means that there is no

274
00:37:13,120 --> 00:37:17,920
gradient component anymore and what the system will be doing is kind of

275
00:37:18,560 --> 00:37:28,240
um orbiting or oscillating around a point which is which moves on the manifold so that's

276
00:37:28,240 --> 00:37:36,400
interesting and i guess that if we do the exact same reasoning but starting already on the mode

277
00:37:36,400 --> 00:37:45,920
then the world flow reduces to the unmanifold flow and i guess that in that case the autonomous

278
00:37:45,920 --> 00:37:52,320
states follow and in fact coincide with their mode but anyway maybe we we can discuss about that

279
00:37:52,320 --> 00:38:02,240
afterwards so okay so let's use the various things we talked about and especially the notion of

280
00:38:02,240 --> 00:38:10,480
synchronization map we as we said the internal mode parametrize indeed um a distribution over

281
00:38:10,480 --> 00:38:18,880
the external state so mu here parametrize a distribution which by construction coincides

282
00:38:18,880 --> 00:38:26,240
with the true distribution p of eta given b and in fact thanks to the conditional independence

283
00:38:26,240 --> 00:38:34,800
between external states and autonomous states you can just drop the condition upon a and you

284
00:38:34,800 --> 00:38:45,600
just have q mu equal p of eta given f and equivalently you can you can write it p of eta given pi

285
00:38:46,400 --> 00:38:55,840
and the idea here is that you can view q mu as a variational distribution if you want you can

286
00:38:56,400 --> 00:39:05,680
write its associated variational free energy so you have this this formula here the free energy

287
00:39:05,680 --> 00:39:13,760
and because q mu is already already coincide with the true posterior distribution if you will

288
00:39:14,400 --> 00:39:24,080
the first term here goes to zero and so that f here reduces if you will to

289
00:39:25,440 --> 00:39:31,760
the surprise over particular states and surprise over particular states they appear here in the

290
00:39:31,760 --> 00:39:38,240
equations of the autonomous states so we can do this identification and we realize that the

291
00:39:38,240 --> 00:39:47,600
autonomous uh mode not only minimize um not only minimize surprise though but free energy in general

292
00:39:48,400 --> 00:39:56,640
and the way uh mu the internal states will be updated when the sensory states will change

293
00:39:56,640 --> 00:40:05,280
will always be so that this divergence here is zero so that mu is always always keeps track or

294
00:40:05,280 --> 00:40:11,840
synchronized with or in fact interfere the external states so that you can interpret that

295
00:40:12,640 --> 00:40:19,440
under a generative model which is here p the next entity the internal states can be viewed as

296
00:40:19,440 --> 00:40:29,520
performing inference over external states and so in fact it's not only this divergence which is

297
00:40:29,520 --> 00:40:38,640
minimized but it's also surprised and it's not only um only the internal states which uh minimize

298
00:40:38,640 --> 00:40:46,320
free energy but also the active states so let me give an example let's say that the actual

299
00:40:47,360 --> 00:40:54,400
instantiated sensory states are likely sensory states or unsurprising sensory states and by

300
00:40:54,400 --> 00:41:02,240
definition in general the instantiated sensory states will be likely sensory states so mu will

301
00:41:02,240 --> 00:41:07,680
will the corresponding mu will be so that this divergence will be zero as we just discussed

302
00:41:08,400 --> 00:41:16,320
and at the same times the corresponding active mode will be so you can see in composition with the

303
00:41:16,320 --> 00:41:25,920
third term here i of a given s and mu a this active mode will just be the one the most consistent

304
00:41:25,920 --> 00:41:32,480
with this in intensiated sensory states and in fact you can view it the other way around and say that

305
00:41:33,440 --> 00:41:42,320
the active mode is the mode which yield unsurprising sensory states so that the particle can be viewed

306
00:41:43,040 --> 00:41:52,240
viewed as uh actively sampling unsurprising or likely sensory states or equivalently you can

307
00:41:52,240 --> 00:41:59,360
say that the particle kind of um accumulate evidence for its own generative model and i'm going to

308
00:41:59,360 --> 00:42:06,320
say something about the generative model in a sec but i just want first to so yeah this sentence

309
00:42:06,320 --> 00:42:14,400
here just sum up what we said mu is updated so that q mu is always the the best distribution of

310
00:42:14,400 --> 00:42:22,000
our external states and we refer to this as perceptual inference and the idea to in addition

311
00:42:22,800 --> 00:42:29,200
trying to minimize surprise for action is called active inference so a brief note

312
00:42:29,840 --> 00:42:37,440
uh we said earlier that in order to have a synchronization map of closed form it could

313
00:42:37,440 --> 00:42:46,640
be necessary to work under a Laplace approximation so that in that case q mu is always is is just

314
00:42:46,640 --> 00:42:54,320
the best Gaussian for instance of the target density so that the divergence here would not

315
00:42:54,320 --> 00:43:03,520
be zero but it still would be minimized so that the identification here between the two gradients

316
00:43:04,240 --> 00:43:11,840
still hold and nothing change um nothing changes with respect to our discussion so here i just want

317
00:43:11,840 --> 00:43:21,200
to say something about this what we are doing here basically we assume that we have our agents

318
00:43:21,200 --> 00:43:27,680
or organisms that survives indeed exist or persist in a given environment let's say at a

319
00:43:27,680 --> 00:43:36,640
given time scale and we end up with the fact that our particle must be equipped with or must be

320
00:43:36,640 --> 00:43:45,440
must embody a generative model which may or may not exactly coincide with the true generative process

321
00:43:46,160 --> 00:43:53,840
and which encodes the causal structure of the world under which it tries to perform inference

322
00:43:53,840 --> 00:44:01,840
and to minimize surprise to perform perceptual and active inference but the interesting thing

323
00:44:01,840 --> 00:44:08,400
as well is that and i think that's something fundamental that people tend to misunderstood

324
00:44:08,400 --> 00:44:18,160
i guess maybe i'm not sure is that the generative model also encodes the preferences of the system

325
00:44:18,160 --> 00:44:26,080
and let me explain why if i tell you that an organism manages to survive to exist to persist

326
00:44:26,080 --> 00:44:35,840
etc and so it means that such an organism manages to stay in its homeostatic life compatible

327
00:44:36,800 --> 00:44:42,080
states you would be of course it almost sounds like a tautology survive equal

328
00:44:44,240 --> 00:44:50,080
staying in it in in its homeostatic states that obvious right and that's exactly what we are doing

329
00:44:50,080 --> 00:44:58,880
here we assume existence survival so that the likely state in which the particle will will persist

330
00:44:59,840 --> 00:45:08,080
are preferred states per se so that for instance if i'm considering the prior of my generative model

331
00:45:08,080 --> 00:45:19,520
over sensory inputs p of s sensory outcomes s associated with high p of s so likely or

332
00:45:19,520 --> 00:45:27,760
unsurprising sensory states are preferred sensory states states hence when i'm saying that the active

333
00:45:27,760 --> 00:45:35,520
states try to sample unsurprising sensory states it means trying to sample preferred sensory states

334
00:45:36,400 --> 00:45:46,240
and so basically the particle appears to kind of actively accumulate evidence

335
00:45:49,040 --> 00:45:56,240
for its own existence in a way it kind of sample life to sample it kind of sample life compatible

336
00:45:56,240 --> 00:46:02,800
data if you will and that's exactly the definition of self-evident thing so i think

337
00:46:02,800 --> 00:46:09,200
we touch here something fundamental about agency is that agents are self-evident thing

338
00:46:09,920 --> 00:46:20,080
creatures in that sense okay anyway so basically i think that's the most interesting things of

339
00:46:20,080 --> 00:46:26,480
the free energy principle we start from existence and we end up that such a particle which is

340
00:46:26,480 --> 00:46:34,640
coupled to the world in that way must embody a generative model which encodes the causal structure

341
00:46:34,640 --> 00:46:42,000
of the world and which encodes the its preferences in terms of what is life compatible if you will

342
00:46:42,240 --> 00:46:50,400
okay so just to sum up what we did here this idea that free energy is minimized

343
00:46:51,680 --> 00:46:59,360
you can write it that way and this is in a way a variational principle for self organization

344
00:46:59,360 --> 00:47:06,880
that's a free energy principle so here i just wrote what we just discussed the agent keeps

345
00:47:06,880 --> 00:47:11,680
tracks and acts on its external milieu through perceptual and active inference

346
00:47:14,080 --> 00:47:21,280
and note that interestingly enough you can write such a principle as a principle of

347
00:47:21,280 --> 00:47:28,240
least or stationary action where the Lagrangian which is constantly minimized along the path

348
00:47:28,800 --> 00:47:39,040
is variational free energy so here are some concluding remarks i'm not going to throw all

349
00:47:39,040 --> 00:47:45,120
of them but the first one is basically what we just discussed this idea that the generative model

350
00:47:46,720 --> 00:47:54,400
encodes preferences if an agent maintains existence its likely states are its preferred ones per se

351
00:47:55,360 --> 00:48:03,680
hence the notion of stealthily dancing and i just also want to point out that this new approach

352
00:48:05,520 --> 00:48:14,960
or chapter of physics let's say consisting in describing physical systems as encoding probabilistic

353
00:48:14,960 --> 00:48:24,160
beliefs is called Bayesian mechanics okay so having said that thank you very much and especially

354
00:48:24,400 --> 00:48:32,880
thanks to all these guys who who helped me so much especially Len and yeah thank you for

355
00:48:33,840 --> 00:48:35,360
for your your attention

356
00:48:45,360 --> 00:48:48,240
I'm back thank you Richard

357
00:48:48,880 --> 00:48:59,680
okay well while we're settling back in and anyone is asking questions in a live stream

358
00:49:00,880 --> 00:49:09,360
what is your phd research and if this is your side project what is your main project that this

359
00:49:09,360 --> 00:49:17,040
kind of relates to yes so well in fact um i kind of read about the free energy principle

360
00:49:17,760 --> 00:49:28,480
in my free time whenever i i had some time and what i'm doing in my phd is so we have

361
00:49:29,680 --> 00:49:36,880
a couple of projects the first project we did was really modeling bacterial evolution through

362
00:49:36,880 --> 00:49:43,440
so basically we model bacterial evolution as a bias random work on genotype space with

363
00:49:44,320 --> 00:49:50,960
successive mutations and and and successful fixations so that's what we are doing it's

364
00:49:50,960 --> 00:50:02,240
not related to the fp at all and the second thing we have been doing is modeling so basically we

365
00:50:02,240 --> 00:50:10,160
had a system where you have bacteria which can kill each other thanks to a system which is called

366
00:50:10,160 --> 00:50:17,600
the t6 secretion system they kind of have needles with which they can go through the membrane of

367
00:50:17,600 --> 00:50:24,480
other bacteria and and liberate toxins and they can also bind to each other so there is like a

368
00:50:24,480 --> 00:50:30,960
prepredator kind of dynamics and we did like a lattice gas modeling of such systems so basically

369
00:50:30,960 --> 00:50:38,240
that's what i'm doing in my phd which is not related to to Bayesian mechanics but i would like to

370
00:50:38,960 --> 00:50:43,440
to transition to to the field afterwards so yeah i will see how it it goes

371
00:50:45,360 --> 00:50:48,560
i remember when i thought my phd wasn't related to active inference

372
00:50:51,440 --> 00:51:01,600
okay cool well the work built to an amazing crescendo that in its simplicity

373
00:51:02,560 --> 00:51:10,880
even though you highlighted it's easy to fly by which is the coincidence of the preferences

374
00:51:10,880 --> 00:51:17,680
and the expectations so could you maybe give a little context how else has that nexus

375
00:51:18,480 --> 00:51:27,600
of preference and expectation been approached and is the fvp only and simply and always that

376
00:51:27,680 --> 00:51:33,440
coincidence is that coincidence upstream or downstream of some other commitment that we make

377
00:51:33,440 --> 00:51:41,600
like what are the commitments that we really make and is that um alignment the commitment or a

378
00:51:41,600 --> 00:51:52,320
resulting commitment yeah so um so first of all i think the notion of um self evidencing

379
00:51:52,400 --> 00:51:58,400
may be a bit refined with the next formulation but anyway it's i think that's a crucial point

380
00:51:59,120 --> 00:52:06,240
about the fvp and usually it's kind of confusing because when you're reading the papers and

381
00:52:06,800 --> 00:52:14,960
people are starting to write that the system um sample evidence for its own existence you're like

382
00:52:14,960 --> 00:52:21,600
what i mean i'm not sure to understand what's going on here um but in fact yeah it's i i think

383
00:52:22,880 --> 00:52:33,680
the way i i um introduced it this idea that by definition um a living thing is a thing which

384
00:52:34,960 --> 00:52:45,360
which managed to sample live compatible uh sensory data is really what allows this

385
00:52:45,680 --> 00:52:55,680
um align alignment story between the that the idea that between surprise and preferences

386
00:52:55,680 --> 00:53:04,640
basically and this idea that actively sampling um unsurprising data is in fact and it's not

387
00:53:04,640 --> 00:53:12,240
like a tricky wording it's in in a way that's really what's happening it is sampling uh live

388
00:53:12,240 --> 00:53:21,840
compatible or preferred in that sense data hence the notion of self evidencing um but um

389
00:53:22,800 --> 00:53:31,200
yeah i think the whole idea here is that we start from existence we start from the uh

390
00:53:31,920 --> 00:53:37,920
from this past coupling architecture where the particle uh managed to maintain its physical

391
00:53:37,920 --> 00:53:45,920
integrity managed to display a mark of blanket which uh allows the the agent to have its nice

392
00:53:45,920 --> 00:53:51,120
it's um its own internal dynamics separated from the external so somehow it managed to

393
00:53:51,120 --> 00:54:00,960
counter dissipation or whatever and so from there likely states are states consistent with the fact

394
00:54:00,960 --> 00:54:08,480
that it is existing existing indeed so i think that's basically the the the idea but yeah in the

395
00:54:08,480 --> 00:54:14,640
beginning this kind of um line of reasoning can be a bit uh confusing but in fact i think that's

396
00:54:15,680 --> 00:54:24,160
very much what the FEP is all about and actually last remark um in a machine learning street talk

397
00:54:24,160 --> 00:54:33,200
interview of Maxwell Ramstead he it was titled the FEP as um a physics of survival if i remember

398
00:54:33,200 --> 00:54:39,600
well and i think that's that's very very much what what it is all about in a way

399
00:54:42,160 --> 00:54:49,200
awesome how would you relate what you just described to reward or to reinforcement type

400
00:54:49,200 --> 00:54:58,480
learning schemes yeah so i i mean i'm not an expert at all i could not uh make the bridge here

401
00:54:59,200 --> 00:55:07,440
but i know that um Lance Dacosta made several uh works and interviews about the the subject

402
00:55:07,440 --> 00:55:14,160
and actually i think there is a very new paper called active inference as a model of agency

403
00:55:14,160 --> 00:55:21,120
you just shared actually today um so i yeah i recommend the viewers to to check them out

404
00:55:21,120 --> 00:55:27,680
and as far as i know but here i'm just i'm just uh seeing what i heard is that um any

405
00:55:27,680 --> 00:55:35,440
reinforcement learning algorithms can be um can be framed in terms of active inference

406
00:55:36,160 --> 00:55:46,160
so i think active inference is a very um uh fundamental scheme but yeah yeah it's all good

407
00:55:46,160 --> 00:55:52,800
like the reason i ask just with how you presented it is what kind of observations do we want to

408
00:55:52,800 --> 00:55:58,160
sample that could be the sensory embodied interface between the agent and the environment

409
00:55:58,160 --> 00:56:04,640
or you can take a more cognitivist approach and sample internal observations but those are just

410
00:56:04,720 --> 00:56:10,560
external some other internal so what do we want to really sample well if you're even in a position

411
00:56:10,560 --> 00:56:16,240
where you're talking about sampling from like a utility or a reward distribution you've already

412
00:56:16,240 --> 00:56:27,280
specified a distribution why not just specify the existence distribution the actual attractors

413
00:56:27,280 --> 00:56:40,320
and stationaries of the measurements and then um it's simpler because there's no proposal of a

414
00:56:40,320 --> 00:56:47,360
secondary intermediate between the temperature and how good different temperatures are by going

415
00:56:47,360 --> 00:56:52,560
and just saying it's not rewarding to be at 37 homeostatic temperature it's just expected and

416
00:56:52,560 --> 00:57:00,800
likely and the ball rims downhill it's actually a lot simpler and more general yeah and i i think that

417
00:57:01,920 --> 00:57:12,080
um it's way more simpler to i mean the idea here is that the agent has a kind of world model which

418
00:57:12,080 --> 00:57:19,920
as you said uh specified what are the the expectation uh with regards to just existing

419
00:57:20,000 --> 00:57:25,280
in a way and as opposed to designing explicitly

420
00:57:29,760 --> 00:57:30,880
objective functions

421
00:57:34,400 --> 00:57:41,200
with the which incorporates the notions of utility and so on so yeah i'm very much agree

422
00:57:41,520 --> 00:57:52,880
um earlier when we were looking at the flows and we had the breakdown of a flow um could you maybe just

423
00:57:55,360 --> 00:58:05,200
um what animal are you thinking about or what scenario can help us understand like what's the

424
00:58:05,200 --> 00:58:12,160
solid black line what's the small red line what's the spiral what's like a physiological setting

425
00:58:12,160 --> 00:58:16,800
that we could associate here to help us understand that kind of complex movement

426
00:58:18,640 --> 00:58:27,520
yeah so uh generally speaking the first thing i could say is that this notion of solenoidal flow

427
00:58:27,520 --> 00:58:34,320
so it's like in the schematic schematic in the first slide where you have you had this

428
00:58:34,320 --> 00:58:41,200
either contour circulation on the next entity or here the the the component of the flow which

429
00:58:41,200 --> 00:58:53,200
creates this sort of spiral here it can so that um it's this sort of um oscillations are i think

430
00:58:54,160 --> 00:59:01,600
the sort of oscillations or cycles that are ubiquitous in living systems um i mean i i'm not

431
00:59:02,240 --> 00:59:08,880
a biologist but you can uh or not really a biologist but you can think of the circadian

432
00:59:08,880 --> 00:59:16,960
cycle or or anything in any sort of systems there is this sort of of of um attractor where

433
00:59:17,120 --> 00:59:26,480
you're circulating along and so here specifically to this to this um a schematic here i think the

434
00:59:26,480 --> 00:59:37,440
idea is that um um you have so you have you basically let's say that uh for a given sensory

435
00:59:37,440 --> 00:59:45,120
states you have a corresponding autonomous mode and the when the sensory states change the

436
00:59:45,200 --> 00:59:53,120
autonomous mode mode changes as well and in fact move on its so-called manifold so basically i guess

437
00:59:53,120 --> 01:00:03,440
here you have the mode moving on its manifold and now if we take the perspective of this

438
01:00:04,160 --> 01:00:11,040
autonomous states here we converge to the the manifold to the mode

439
01:00:11,360 --> 01:00:21,280
um and because of the solenoidal uh component of this flow the way we will um reach it is

440
01:00:21,920 --> 01:00:32,240
with this kind of uh ever-decreasing cycles um so here's the idea and i and um i really recommend

441
01:00:32,240 --> 01:00:40,880
here the free energy principle simple paper you have the the flow on the manifold it's just the

442
01:00:40,880 --> 01:00:51,280
path of the mode itself let's say and you have the flow of the manifold was gradient component

443
01:00:51,280 --> 01:01:02,240
is the flow towards the manifold in fact um so basically so that's basically how autonomous states

444
01:01:02,240 --> 01:01:11,120
kind of um reacts to to to sensory data which change the autonomous mode and i think the whole

445
01:01:11,920 --> 01:01:20,240
an important idea here is to assume that the flow of the manifold is fast as opposed to the flow

446
01:01:20,960 --> 01:01:27,040
on the manifold so that's basically the sensory states are always uh in the vicinity of their

447
01:01:27,040 --> 01:01:38,240
mode and move with their mode and um sorry and um and um and yeah i think that's pretty much the the

448
01:01:38,240 --> 01:01:48,880
idea here okay so let's just say that the black line is um our homeostatic body existence life

449
01:01:48,960 --> 01:01:58,320
compatible ph oxygen blood sugar and yeah we are that light blue dot that's off that manifold

450
01:01:59,680 --> 01:02:06,880
of course if we were far enough off to be dead it would be a moot question but we're off but

451
01:02:06,880 --> 01:02:15,600
within a life um scaffolding a compatible zone and now as time pushes us down into the right

452
01:02:16,240 --> 01:02:26,800
um there are different slices that we can trace um we could take the shortest path the gradient

453
01:02:26,800 --> 01:02:33,040
flow directly towards the manifold so as that plays out through time it would look like a linear line

454
01:02:33,920 --> 01:02:41,840
converging to the thick black line or pure solenoidal flow would just stay equally far away

455
01:02:41,840 --> 01:02:47,040
from the thick black line and continue to spiral so that would look like a cork screw uh through

456
01:02:47,040 --> 01:02:55,040
time and then here when you have the combined character of the linearized convergence towards

457
01:02:55,040 --> 01:03:04,080
the manifold and the cork screw out through time we get this kind of winding spiral so

458
01:03:04,400 --> 01:03:17,200
it reflects on me that the gradient flow is pragmatic value in that it aligns future observations

459
01:03:17,200 --> 01:03:26,880
with preferences and the solenoidal flow has an almost epistemic character in that it circulates

460
01:03:26,880 --> 01:03:36,640
amongst a set of equally valid outcomes yet here we're not looking at the pragmatic plus

461
01:03:36,640 --> 01:03:45,840
epistemic decomposition of the expected free energy policy selection strategy like equation 2.6

462
01:03:45,840 --> 01:03:54,080
in the 2022 textbook so is that just a concordance or where do you see some of those topics connecting

463
01:03:57,600 --> 01:04:06,480
um I am not sure maybe uh but having said that on this on the the meaning of the solenoidal part

464
01:04:06,480 --> 01:04:14,720
here I know that on the on the uh I don't remember if it's in the free energy principle

465
01:04:14,720 --> 01:04:23,680
simpler paper or or someone else but there is an analogy I mean they discuss the the meaning

466
01:04:23,680 --> 01:04:33,920
and the role of the solenoidal flow where they say that it it it kind of help um it kind of helps

467
01:04:33,920 --> 01:04:40,800
mixing system the systems and you can view and they discuss the metaphor with where you want to

468
01:04:40,800 --> 01:04:50,080
dilute your um your um your coffee for instance and you're going to have this sort of uh motion

469
01:04:50,080 --> 01:04:59,040
in order to reach the the as fast as possible the the steady state where everything is diluted but I

470
01:05:00,080 --> 01:05:06,320
I am I'm not sure I didn't think enough myself to provide any sort of interesting insight

471
01:05:07,440 --> 01:05:15,200
oh good just to have composed it it's very insightful um well you made choices assembling

472
01:05:15,200 --> 01:05:24,080
things like what do you feel like would have been background maybe a course or a skill what

473
01:05:24,080 --> 01:05:28,960
background do you feel like you kind of conditioned upon that somebody might want to check out

474
01:05:29,520 --> 01:05:35,760
and then what do you feel like you would have wanted to include in the state-based formalism

475
01:05:36,720 --> 01:05:49,760
um because to to bring it into a under one hour timing is very concise so where do you feel like

476
01:05:50,400 --> 01:05:57,600
somebody could fill in some background to pick up with you at the beginning and then what else

477
01:05:57,600 --> 01:06:07,120
do you think would make a fuller presentation I think I mean there are a few aspects and details

478
01:06:07,120 --> 01:06:18,000
I didn't really uh like fully discuss um well first of all all these um things which

479
01:06:18,560 --> 01:06:23,520
here which involves like center theory a center manifold theory and stuff like that

480
01:06:24,240 --> 01:06:31,520
uh we we kind of played uh qualitatively with it we didn't really go into that

481
01:06:32,400 --> 01:06:44,080
and also if we want to be like full really full formally speaking um let's see maybe um

482
01:06:44,960 --> 01:06:54,800
um uh well there are a couple of things where we that we kind of accept without really checking

483
01:06:54,800 --> 01:07:00,240
all the assumptions and all the derivation derivation and I'm especially thinking of the

484
01:07:01,040 --> 01:07:07,200
of the Helmholtz Hau decomposition of F because of course you need a steady state

485
01:07:07,200 --> 01:07:15,520
net density to exist to in order to have such a decomposition so here I think it's it's there is

486
01:07:16,960 --> 01:07:25,280
a lot of stuff to to check and I mean there is a nice I think it's in the appendix B of the

487
01:07:25,280 --> 01:07:33,840
Bayesian mechanics of stationary process paper by Lenz where it derives the Helmholtz decomposition

488
01:07:34,080 --> 01:07:44,560
uh so yeah there are quite a few things we kind of state we vote um derive so it can

489
01:07:45,200 --> 01:07:51,840
if people are interested in in going further I think that's kind of interesting formal uh directions

490
01:07:52,320 --> 01:08:04,720
um and um um yeah cool I think it'll be a really fun collaborative project to

491
01:08:05,760 --> 01:08:14,560
axiomatize and formalize and modularize using the actin fontology and understand a lot of these um

492
01:08:15,360 --> 01:08:19,920
relationships and then the other piece that that made me think about is like

493
01:08:20,720 --> 01:08:27,520
what work is any of this math doing at all just kind of like the the ultimate existential question

494
01:08:27,520 --> 01:08:37,120
here um and when we condition upon existence we've kind of like off sourced a lot of cognition

495
01:08:37,680 --> 01:08:45,040
we don't need to make the jump or the walk or the miracle from axiom to embodied existence or to

496
01:08:45,040 --> 01:08:53,680
even measured hypothetical existence so that is left unaddressed the margin was not big enough

497
01:08:53,680 --> 01:09:00,880
but it wasn't even addressed and maybe there are even advantages to leaving the um

498
01:09:01,440 --> 01:09:05,040
um what happens before the conditioning

499
01:09:07,680 --> 01:09:11,680
you don't want to take it with you after you condition upon it that's the whole mark off

500
01:09:11,680 --> 01:09:17,040
like a concept like if you're like well I'm conditioning on five years ago in the present

501
01:09:17,040 --> 01:09:21,600
but also I'm carrying five years with me today well then it's like well then it wasn't conditioned

502
01:09:21,600 --> 01:09:33,040
upon so to really condition upon measurements is an extremely radically simplifying maneuver

503
01:09:34,160 --> 01:09:40,160
that may change the scope or the applicability of the framework

504
01:09:42,000 --> 01:09:47,440
relative to a conception in which what the free energy principle does is describe how things come

505
01:09:47,440 --> 01:09:58,000
to be however yeah this rather conditioning upon it opens up that discussion and more circumscribes

506
01:09:58,720 --> 01:10:06,960
this very analytically tractable setting of the agent and the environment across a conditional

507
01:10:06,960 --> 01:10:17,040
interface yeah by the way about about the conditional thing there is now the notion of

508
01:10:17,120 --> 01:10:24,240
you know weak mark of blankets that Dalton introduced which kind of lose the approach let's say

509
01:10:24,960 --> 01:10:36,400
and because indeed there is a question on I mean does it apart from the formal setting we have here

510
01:10:36,400 --> 01:10:45,520
can we really apply it to real systems and stuff like that and also I think it's the physics of

511
01:10:45,520 --> 01:10:55,760
survival in itself at a given survive at a given time scale there is at if I have at a given time

512
01:10:55,760 --> 01:11:01,840
scale we survive indeed in the sense that there is indeed this partition or conditional independence

513
01:11:01,840 --> 01:11:08,240
between the internal and external here is the physics you have to comply with but we didn't

514
01:11:08,240 --> 01:11:15,120
tell you tells you how was the mark of blanket rise or whatever it's it's it's it's just not what it

515
01:11:15,600 --> 01:11:27,520
is designed to to explain but I think generally speaking it's it's really informative because

516
01:11:27,520 --> 01:11:34,960
for instance if you are considering the I mean the sort of approach in general I mean for instance

517
01:11:34,960 --> 01:11:42,720
if you consider the pendulum effect where you put pendulum oscillating on the table and they are

518
01:11:42,720 --> 01:11:49,040
going to synchronize synchronize with each other and I think that Kuiha Isomura did a paper about

519
01:11:49,040 --> 01:11:58,160
that recently in order to understand what is going on and why the pendulum synchronized at some point

520
01:11:58,160 --> 01:12:05,600
you just have to recycle all this line of reasoning with the synchronization map that's very what is

521
01:12:05,600 --> 01:12:11,600
at play and what explains why the pendulum synchronized when they are both on the same table

522
01:12:12,160 --> 01:12:21,040
so I think it really it is really informative to in order to understand what is going on when we

523
01:12:21,040 --> 01:12:29,760
are talking about synchronization phenomena across sparsely coupled systems and also it gives you

524
01:12:29,840 --> 01:12:40,400
I guess the sort of recipe to understand what it what it what it takes to be an agent if you want

525
01:12:40,960 --> 01:12:52,960
to design your an intelligence system and but yeah the question of how much useful it is

526
01:12:53,920 --> 01:13:01,680
beyond the fact that it's just some nice formal framework it's it's an interesting

527
01:13:02,400 --> 01:13:11,200
interesting discussion yeah and I just two things first I would like to go back to your

528
01:13:11,200 --> 01:13:19,520
previous question about what sort of things could be could be discussed further I think

529
01:13:19,520 --> 01:13:28,160
an interesting point we didn't really discuss fully is the notion of synchronization map

530
01:13:28,720 --> 01:13:39,280
because we didn't necessarily discuss the the hypothesis and stuff about the synchronization

531
01:13:39,280 --> 01:13:48,080
map and I in fact I think there is much things that can be said for instance because we assume

532
01:13:48,080 --> 01:13:57,440
injectivity thanks to the rank nullity theorem it's kind of constrain the dimension of the

533
01:13:57,440 --> 01:14:05,200
internal manifold here with respect to the blanket manifold here and it kinds of constrain

534
01:14:05,200 --> 01:14:10,800
in order to have injectivity thanks to the rank nullity theorem and so it kind of constrain the

535
01:14:11,680 --> 01:14:17,840
the in order to say it in a qualitative fashion it kind of constrain the the complexity or

536
01:14:17,840 --> 01:14:26,640
richness of the internal states which speaks nicely to other frameworks like

537
01:14:30,240 --> 01:14:37,360
like HB's laws of requisite variability where you want the regulator system to be as

538
01:14:38,320 --> 01:14:45,360
as sophisticated or as rich to the regulated systems and here you need the internal states to

539
01:14:46,160 --> 01:14:54,080
be enough complex to or to constitute the sufficient statistics let's say to parametrize

540
01:14:54,080 --> 01:15:03,440
to be able to parametrize the density indeed and this and this richness let's say is constrained by

541
01:15:04,080 --> 01:15:11,760
the the cardinality of your sensory channels if you will because basically you need the internal

542
01:15:12,640 --> 01:15:20,480
manifold to be to have the same dimension than the blanket manifold or the sensory manifold to be

543
01:15:20,480 --> 01:15:29,200
to have the same dimensions than the autonomous manifold so I I mean I think there is many things

544
01:15:29,200 --> 01:15:38,560
to discuss about this this aspect here and the last thing I would like to say about your

545
01:15:39,840 --> 01:15:46,160
about your last question about the applicability of the framework and how much it's useful

546
01:15:46,160 --> 01:15:54,400
as opposed to be a simple elegant formal framework I think so you know there is this

547
01:15:54,960 --> 01:16:04,000
these papers about about like the Markov-Blanquet trick and stuff like that

548
01:16:05,520 --> 01:16:11,920
about how much difficulties like to identify what states corresponds to the Markov-Blanquet or whatever

549
01:16:12,880 --> 01:16:24,480
and I'm personally I'm not really convinced by this these critiques because to me it's like

550
01:16:24,480 --> 01:16:31,280
to me it's like saying to Newton yeah I mean it's I'm not sure that I can do anything with your

551
01:16:31,280 --> 01:16:40,160
framework it's it's complicated if not impossible to model systems with clearly identified and

552
01:16:40,160 --> 01:16:47,840
separated rows and masses let's say okay fine but we are talking about Newton mechanics here so

553
01:16:47,840 --> 01:16:53,280
I mean I think it's the same here it's if you have a sparsic coupled random domain because

554
01:16:53,280 --> 01:16:58,720
systems that's the sort of behavior it will display it tells you fundamental things about

555
01:16:58,720 --> 01:17:05,840
the nature of living systems and the idea that when it comes to a specific system it can be

556
01:17:05,840 --> 01:17:09,600
quite tricky to to model it that's another question

557
01:17:12,720 --> 01:17:18,720
and indeed when it comes to the art of modeling complex systems it's it's it's interesting and

558
01:17:18,720 --> 01:17:26,400
and we can discuss about how much complicated it can be to apply the framework yeah awesome I love

559
01:17:26,400 --> 01:17:34,960
that it's like the art of the science and the art of the modeling and the and the craft especially

560
01:17:34,960 --> 01:17:43,520
in the kind of early hand-built largely custom stage like one thing I even wondered looking

561
01:17:43,520 --> 01:17:51,680
through these slides what fraction of these representations and formalisms exist only

562
01:17:52,240 --> 01:17:58,800
analytically and do or is there a code representation of this exact scenario

563
01:17:58,800 --> 01:18:07,200
or you know are some of these areas equations that don't have

564
01:18:09,760 --> 01:18:13,840
code realizations they're just pure existing equations

565
01:18:16,000 --> 01:18:25,920
so I mean I think more or less everything here can be can be simulated even this synchronization

566
01:18:25,920 --> 01:18:35,280
thing here you can perform simulations where you can really literally see within the simulations

567
01:18:35,280 --> 01:18:45,760
the synchronization and I mean the the the whole thing here can be you can simulate such

568
01:18:45,760 --> 01:18:53,520
sparsic coupled random dynamic systems and and kind of interprets the dynamics indeed as

569
01:18:54,240 --> 01:18:56,880
the way we we frame we frame it

570
01:18:59,760 --> 01:19:08,480
but but yeah that's also an interesting aspect it could be cool like in the github repo

571
01:19:09,200 --> 01:19:15,520
in the journal for this transcript or something like that to to curate together

572
01:19:15,520 --> 01:19:22,160
the simulations that demonstrate or a minimal specification for it

573
01:19:24,240 --> 01:19:30,560
you know because it's it's actually there is a great yeah and actually there is a

574
01:19:31,760 --> 01:19:38,240
I mean I think it's in the in in length paper about synchronization map the Bayesian mechanics

575
01:19:38,240 --> 01:19:47,280
of stationary process processes paper there there are some simulations where he shows that

576
01:19:49,120 --> 01:19:53,840
I mean he shows the the synchronization map at play and it shows that

577
01:19:54,640 --> 01:20:02,240
basically you can't go back to I mean if the the the map between the blanket states to the

578
01:20:02,240 --> 01:20:10,720
internet states is not injective uh and you apply the synchronization map to the actual

579
01:20:10,720 --> 01:20:17,520
sensory uh to the actual internet states it gives you like some not relevant things and

580
01:20:17,520 --> 01:20:22,640
there are some nice plots from simulations so that's definitely a paper to to check out

581
01:20:22,640 --> 01:20:35,040
so where do we land and then how do we leap exercise relax to prepare for part two

582
01:20:36,640 --> 01:20:44,960
yeah so I think here's the the world point was I mean the this world formulation is in a way

583
01:20:44,960 --> 01:20:54,400
about the momentary the short day the short term and the momentary response to autonomous states to

584
01:20:54,400 --> 01:21:06,080
sensory stimuli let's say if there is this uh this um I mean the the kind of instantiated active

585
01:21:06,160 --> 01:21:15,200
states are so that it comes whatever but in the next uh video where we will look at the path

586
01:21:15,200 --> 01:21:22,720
based formulation of the framework the world idea would be to ask what about path and what about

587
01:21:23,360 --> 01:21:34,480
future path and what about the long term behavior uh and what about planning what about higher order

588
01:21:34,480 --> 01:21:44,960
cognitive abilities um and we we will kind of extend the scope of what we are doing in in in

589
01:21:44,960 --> 01:21:55,520
that sense um but um yeah I mean I think from a formal point of view uh here I kind of introduced

590
01:21:55,520 --> 01:22:01,200
many things variational variational inference synchronization map etc one after the other

591
01:22:01,200 --> 01:22:06,560
before actually deriving the free energy principle next time I think we will it will

592
01:22:06,560 --> 01:22:15,520
be more straightforward but the the main concepts to to which will be at the core of the of the

593
01:22:15,520 --> 01:22:21,840
framework and which can be confusing if it's the first time you you look at it is the notion of

594
01:22:23,280 --> 01:22:30,480
of generalized coordinates of motion when you relax the white noise assumption and that's

595
01:22:30,480 --> 01:22:34,960
something that can be confusing especially for the physicists because when you're starting

596
01:22:34,960 --> 01:22:40,960
saying yeah the generalized lagrangian he plays a role of an action or whatever they are like

597
01:22:40,960 --> 01:22:46,800
no but lagrangian is not an action what are you talking about etc but when you get acquainted with

598
01:22:47,520 --> 01:22:54,160
the the world construction is very elegant but that definitely something people can

599
01:22:54,160 --> 01:23:02,800
started look at before prior to the the live stream yeah awesome yeah well it was excellent

600
01:23:02,800 --> 01:23:11,120
you you brought a lot together and a lot of trails leading off this trail and the citations and

601
01:23:11,120 --> 01:23:18,800
previous um papers that that also brought things together lance's work and others

602
01:23:19,440 --> 01:23:26,000
and it's going to be awesome to see part two so thank you Richard yeah thank you very much

603
01:23:26,000 --> 01:23:32,000
Daniel thank you all right see ya bye bye

604
01:23:48,800 --> 01:23:50,080
you

