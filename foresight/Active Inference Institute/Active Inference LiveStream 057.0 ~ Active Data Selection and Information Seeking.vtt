WEBVTT

00:00.000 --> 00:15.760
Alright, hello and welcome. It's May 24th, 2024. We're in ACTIMF livestream number 57.0,

00:15.760 --> 00:20.840
doing background and context video for the active data selection and information seeking

00:20.840 --> 00:26.720
paper and series. So welcome to the ACTIMF Institute. We're a participatory online institute

00:26.720 --> 00:31.360
that is communicating, learning and practicing applied active inference. This is a recorded

00:31.360 --> 00:36.000
and archived livestream. Please provide feedback so we can improve our work. All backgrounds

00:36.000 --> 00:40.720
perspectives are welcome. And we'll follow video etiquette for live streams. Head over

00:40.720 --> 00:47.760
to active inference.org to learn more about any of the projects, including the live streams.

00:47.760 --> 00:56.880
Today, we're going to do together a background first pass on a very interesting paper from

00:56.880 --> 01:01.680
Thomas Parr, Carl Friston and Peter Seidman, active data selection and information seeking

01:01.680 --> 01:09.760
from 2024. In this video, we're going to introduce ourselves, talk about big questions, go through

01:09.760 --> 01:15.120
the keywords of the paper, then most of the sections, section by section. And as always,

01:15.120 --> 01:19.840
with the dot zero, it's just like a first pass. And we'll look forward to speaking with

01:19.840 --> 01:26.160
hopefully some of the authors in the coming weeks, and also looking what people ask about. So

01:28.000 --> 01:34.080
Christopher, let us introduce ourselves and go from there. Thanks a lot also for helping in

01:34.080 --> 01:41.120
the dot zero preparation. Happily. Yeah, so I'm Christopher Bennett. I'm a bioinformatics

01:41.120 --> 01:49.760
scientist. I do a lot of data mangling data analysis and that sort of thing. This paper was

01:49.760 --> 01:56.000
of great interest to me as we kind of go into this more data driven era in making sure that with

01:56.000 --> 02:01.120
such large data sets that we have, making sure that we can actually select relevant data for any of

02:01.120 --> 02:06.800
our applications going forward, be it machine learning or whatever we're trying to do.

02:11.440 --> 02:17.280
And I'm Daniel. I'm a researcher in California and also was drawn to this on one hand on the

02:17.280 --> 02:24.880
applied side, the idea of more efficient and effective data sampling. And then on the more

02:25.520 --> 02:29.440
theory side, the connection with epistemic value information gain.

02:30.800 --> 02:36.000
So here are some of the big questions. Why don't you add some detail to this?

02:36.960 --> 02:42.000
Absolutely. So there's five major big questions that I had after reading this.

02:43.520 --> 02:45.600
For the most part, it boils down to

02:48.160 --> 02:53.280
doing our sampling. You can do sampling over time and sampling of different data sets in different

02:53.280 --> 03:02.080
ways. Is there a way that we can intelligently select the data that we're going for the time

03:03.040 --> 03:09.120
the time that we're trying to select? Is there a way that we can understand how the

03:09.120 --> 03:17.760
time aspect helps sample through time instead of just doing a dynamic or more dynamic instead of

03:17.760 --> 03:24.960
doing a static like we're going to do time zero, time seven, time 14, time 21. Can we say, hey,

03:24.960 --> 03:30.240
the differences between time one and time two are very 10.1, time point two are very interesting.

03:30.240 --> 03:36.400
It's a lot of data in there alone. So we'll sample one and two and then maybe sample 10. Is

03:36.400 --> 03:41.280
there a way that we can intelligently select the time points that we are sampling from

03:42.080 --> 03:48.400
when we get into the time series aspect? The Piper mentioned a number of different

03:49.520 --> 03:55.200
time dimension models that you can add to the four model that they're utilizing,

03:55.840 --> 04:00.880
one of which was a hidden Markov model, another was they mentioned a differential equation in the

04:01.520 --> 04:10.560
actual model itself, in the equation itself. Is there one, are there situations that one

04:10.560 --> 04:16.720
performs better over than the other? Or is what they have selected to use in the paper the optimal

04:16.720 --> 04:24.960
solution in most cases, if not all cases? When it comes to clinical trials, that was a

04:25.120 --> 04:33.440
section in this that they discussed. There's a lot of FDA regulations of the clinical trials and

04:33.440 --> 04:41.680
it's very heavy red tape right now. Is there a way that there's minimum ends that you need in

04:41.680 --> 04:48.240
many clinical trials to actually be considered passing? Is there a way that you can bound this

04:49.200 --> 04:56.560
model that they've developed into something that you can guarantee a minimum number,

04:56.560 --> 05:00.480
a minimum sampling that the FDA requires or any regulatory body?

05:03.040 --> 05:08.960
Another point is the next step of how are we going to integrate this in with other machine

05:08.960 --> 05:15.600
learning models or any downstream applications that you're going with? Is there a selection method

05:15.600 --> 05:24.960
that we can, or how do you see these, this method kind of pre, kind of before machine learning?

05:24.960 --> 05:30.800
How are we going to attach these things together so that we feed the right data into machine learning?

05:32.480 --> 05:38.880
Being an LLM. And then scalability and computation demands. That's going to be a big one if this

05:38.880 --> 05:44.160
is going to be something that is used routinely in industry. We need to make sure that this is

05:44.160 --> 05:52.480
something that is as scalable as you can get. Go from small scale, which is a lot of what they

05:52.480 --> 05:56.240
show in this paper and then all the way up to the very large scale data sets that we

05:57.280 --> 06:03.120
use to train LLMs and other models. Those are kind of the five major points that I have.

06:05.120 --> 06:11.680
Thank you. Those are very insightful. Here were some of the big questions that I was excited about.

06:12.480 --> 06:18.400
So first, from a more general information gain, epistemic foraging perspective,

06:18.400 --> 06:23.520
how do we model the implicit and explicit constraints or trade-offs or dynamics of

06:23.520 --> 06:29.840
information seeking? Which is often addressing a question that is left unaddressed in data science

06:29.840 --> 06:34.080
of where the data comes from. It's just about doing analysis with the data that's there.

06:34.080 --> 06:38.800
But even there, as this paper will kind of get into, there's still sub-sampling and all these

06:38.800 --> 06:46.720
other factors to consider. The clinical trial example brings a very serious and very real plot

06:46.720 --> 06:55.440
twist into the paper, which moves through several levels of adding theoretical generalization and

06:55.440 --> 07:00.400
incorporating like the time dimension and other features. And then the plot twist is when the

07:00.400 --> 07:07.120
preferences for certain kinds of observations is specified, then there's all this interesting

07:07.120 --> 07:10.960
behavior and decisions that come into play. So I'm sure that'll be a great discussion.

07:11.920 --> 07:17.040
And then also in section four, they mentioned the streetlight effect, which is, quote,

07:17.040 --> 07:21.920
the tendency to search where data are generated in a minimally ambiguous way,

07:21.920 --> 07:27.040
i.e. under a street lamp compared to searching elsewhere on a darkened street. And so there it's

07:27.680 --> 07:32.560
an interesting scenario and there'll be some fun art coming up and also how they distinguish the

07:32.560 --> 07:38.800
sampling method with the full information seeking from the maximum entropy sampling

07:39.440 --> 07:44.800
is a very subtle but very important point that I look forward to hearing more from the authors about.

07:49.600 --> 07:59.120
Okay, so just to summarize, the paper is Active Data Selection and Information Seeking,

07:59.200 --> 08:05.200
2024, Thomas Parr, Carl Friston, Peter Seidman, and just a few of the aims and claims of the paper,

08:05.200 --> 08:10.480
and then Christopher will read the abstract. This paper aims to unpack the principles of

08:10.480 --> 08:14.960
active sampling of data by drawing from neurobiological research on animal exploration

08:15.520 --> 08:20.880
and from the theory of optimal experimental design. Our overall aim is to provide an intuitive

08:20.880 --> 08:26.080
overview of the principles that underwrite active data selection and to illustrate this with some

08:26.080 --> 08:32.880
simple examples. Our interest is in the selection of data, either through sampling subsets of data

08:32.880 --> 08:39.040
from a large data set or through optimizing experimental design based upon the models we have

08:39.040 --> 08:44.640
of how those data are generated. Optimizing data selection ensures we can achieve good

08:44.640 --> 08:51.440
inference with fewer data, saving on computational and experimental costs. So if you could read the

08:51.440 --> 08:59.920
abstracts. Absolutely, so the main points in the abstract are the Bayesian inference is typically

08:59.920 --> 09:05.680
focused on two major issues. The first one is that you have to estimate the parameters of the model

09:05.680 --> 09:10.880
of the data, and the second is that you need to quantify the evidence for alternative hypotheses

09:11.680 --> 09:18.320
and formulate an alternative model. But this paper is actually looking at a third issue,

09:18.320 --> 09:25.120
which is in how you're going to select the data for your models. And either through sampling

09:25.120 --> 09:30.160
subsets of large data is typically used or optimizing experiments of design.

09:32.320 --> 09:39.360
Based upon the models we have these of how these data are generated. Optimizing data selection,

09:39.360 --> 09:46.960
what's going into the models can achieve a very good inference with fewer data points. So you're

09:47.040 --> 09:51.920
saving on computational time costs, that sort of thing by actually reducing the amount of

09:51.920 --> 09:58.240
information that you're putting into a model. So what we're doing here is trying to unpack

09:58.240 --> 10:04.560
how you're going to actively select data, and I mean actively select data through a machine

10:05.680 --> 10:13.440
optimization protocol by drawing from some of these neurobiology concepts and trying to optimize

10:13.440 --> 10:22.880
the maximum information that the information can provide, maximum information gain. So they offer

10:22.880 --> 10:29.200
overview of some basic points from the field and illustrates the application in some of the toy

10:29.200 --> 10:35.520
examples that they have will go through, ranging from different approximations with basis sets

10:36.160 --> 10:42.000
to inference about how the process can evolve over time. And finally they'll go through and

10:42.000 --> 10:47.280
consider how the approach to the data selection could be applied to design of clinical trials in

10:47.280 --> 10:52.640
this case, and specifically Bayes adapted clinical trial, something that is more and more

10:53.680 --> 11:00.480
seeing headlines and it's more and more used today now that we have the technology to do it.

11:02.720 --> 11:09.200
Great. Okay. For the roadmap, the paper begins with introduction section,

11:10.080 --> 11:14.480
goes into Bayesian inference, generative models and expected information gain.

11:15.280 --> 11:22.240
They go through a simplest worked example, and then consider a few more ways to level up that model

11:22.240 --> 11:28.400
with function approximation, consideration of the time dimension with dynamic processes,

11:28.400 --> 11:32.720
and then bring in the preference for certain observations in the clinical trials.

11:32.720 --> 11:38.160
Then there's a discussion and conclusion, and they also have a paragraph explaining their

11:38.240 --> 11:44.800
kind of logic there. The keywords for the paper were experimental design, active sampling,

11:44.800 --> 11:51.040
information gain, and Bayesian inference. So the next slides are going to go into those

11:51.040 --> 11:57.680
four background topics. After the four background topics, we'll speed through the sections and

11:57.680 --> 12:02.880
just plant a few seeds for what we want to explore more. So first, experimental design.

12:03.600 --> 12:11.600
Here's two kind of classical views of experimental design in the active inference and free energy

12:11.600 --> 12:21.120
principle eras. So on the left is the statistical parametric mapping, textbook, toolbox, documentation,

12:21.120 --> 12:28.240
et cetera, has multiple chapters and kinds of analyses included in the package to specify

12:28.240 --> 12:33.360
and simulate and also to recognize data according to different experimental designs.

12:34.080 --> 12:41.520
And one very hallmark or common visualization of these kinds of patterns of experimental design

12:41.520 --> 12:49.040
are these design matrices. And it's just represented in this black to white gray scale,

12:49.920 --> 12:55.200
and it summarizes different kinds of measurements across different experimental settings. Like here

12:55.200 --> 13:01.360
might be six settings in the larger white blocks. And then there was variability within each of those

13:01.360 --> 13:05.760
trials. And those are the smaller row levels. So that's like where the data are collected.

13:05.760 --> 13:10.640
And a lot of this has to do with the linear operations that can occur on this kind of

13:10.640 --> 13:17.360
matrix in a general linear modeling framework. And then on the right is the experimental design

13:18.080 --> 13:24.880
experimenters perspective, where the experimental stimuli they output as actions are the

13:24.880 --> 13:31.040
observations going into the subjective model, like of the rat in the team is, and then the action

13:31.040 --> 13:36.960
output of the rat is the observations of the experiment of the experiment. So kind of two

13:36.960 --> 13:47.040
different perspectives, SPM with more of a matrix multiplication, f m r i optimal design, and then

13:47.040 --> 13:52.320
active inference with the more general graphical Bayesian modeling, starting to broaden the

13:52.320 --> 13:57.840
consideration of what optimal foraging and what information gain epistemic value mean.

13:57.840 --> 14:02.560
These are kind of the experimental design themes and how they connect a little bit with

14:03.360 --> 14:09.840
other experimental design factors. Want to add anything? Yeah, keep in mind that a lot of these

14:09.840 --> 14:16.320
experiments, experimental design is a very big and very important consideration when you're

14:16.320 --> 14:21.920
actually running any sort of science or analytics of any variety. And these experiments can actually

14:21.920 --> 14:29.120
get very large with huge, huge amounts of data. And all of that data is relevant for every

14:29.120 --> 14:34.000
application that you want. So you want to be able to design your experiment in a way that you can

14:34.000 --> 14:40.640
collect information in a intelligent way rather than trying to go through and just collect every

14:40.640 --> 14:45.600
data point that you can because humans in many cases are running some of these experiments and

14:45.600 --> 14:51.680
they are have limited time. I certainly do when I'm running these things. So I have to be very

14:51.680 --> 14:56.960
intelligent in how I set things up and how I actually collect data and what did I collect,

14:56.960 --> 15:00.640
because you only get in many of these cases, you only get one shot to collect the data,

15:00.640 --> 15:06.960
you miss it, it's over. You won't have that data point. So it's very critical that you actually

15:06.960 --> 15:09.920
take the experimental design seriously when you're setting these things up.

15:10.640 --> 15:18.880
Great. So connecting that kind of experimental design, experimenter on a budget perspective

15:18.880 --> 15:28.640
with a more statistical and biologically statistical based perspective, active sampling.

15:28.640 --> 15:33.200
So they wrote, when we look at the world around us, we are implicitly engaging in a form of active

15:33.200 --> 15:38.720
data sampling, also known as active sensing or active inference. So this is referencing the

15:38.800 --> 15:45.200
visual saccades. And just to kind of highlight how extreme the relative acuity difference is

15:45.840 --> 15:51.360
between the center of the eye where the gaze is focused on and the off center,

15:51.360 --> 15:56.640
among other visual changes. And vision is just being taken as one sensory example here.

15:57.040 --> 16:02.080
It could also be thought of as like looking for books within a library or any other kind of

16:02.080 --> 16:07.840
selection of what data are going to come in, even if it seems like all of it is going to

16:07.840 --> 16:14.640
all of it is coming in, that still is going to be perhaps addressed with different sensors that

16:14.640 --> 16:19.840
have different variability profiles, or like there's different RNA sequencing kits that you

16:19.840 --> 16:26.400
could buy. And so how do you balance the kind of more samples or which samples, especially as

16:26.400 --> 16:33.040
those spaces grow massive. And then just to contrast that, whereas digit recognition in a

16:33.040 --> 16:40.400
saccade based paradigm would focus on the motor patterns and the small centrally focused

16:40.400 --> 16:46.400
visual acuity and then the motor patterns that relate to circuiting around a digit. Whereas

16:46.400 --> 16:52.960
in the kind of machine learning taken all at once approach, a matrix corresponding to like the

16:52.960 --> 17:00.880
pixels in the MNIST dataset are simply taken in all at equivariance level. So that's just kind

17:00.960 --> 17:04.800
of taking in the data. There's still another higher order data selection question of like,

17:04.800 --> 17:10.400
which digits do you take? If there was a large number of digits in that library. So this is

17:11.120 --> 17:17.280
active data sampling on multiple scales, which records you pull at all, and then how the resolution

17:17.280 --> 17:22.160
and all the tradeoffs that are associated with using the data processing or making the experiment.

17:22.720 --> 17:30.000
Yeah, add more though. And, you know, keep in mind that when you're talking about something

17:30.000 --> 17:34.800
like the visual system, you know, our visual system has access to untold amounts of information,

17:34.800 --> 17:42.080
but our brain can't take advantage of all of that at once. So there's low energy usage of the brain

17:42.080 --> 17:46.960
that needs to optimize the relevant information. Think, you know, your nose is right at the end

17:46.960 --> 17:52.240
of your face. Your eyes are always seeing your nose, but your brain is filtering it out. And this

17:52.240 --> 17:57.040
is happening all the time at all points in time. There are literal blind spots in what you are

17:57.040 --> 18:05.120
actually capable of intaking and processing all at once. And then additionally, when you're

18:05.120 --> 18:10.560
moving away from something like your eye or biological systems and into the experiment

18:10.560 --> 18:15.920
design itself, you know, you oftentimes can't run a full factorial design. And there are other

18:15.920 --> 18:22.080
methods like a fractional factorial design. But those are random base. And this is trying to

18:22.080 --> 18:28.880
actually talk about actively selecting how you're going to set up that design. So it's kind of a,

18:28.880 --> 18:35.920
you can think of it multiple different ways. Awesome. The factor that's going to come into

18:35.920 --> 18:43.840
play as driving the active sampling is going to be the information gain. And there's some quotes

18:43.840 --> 18:50.320
here. And equation two is shown. They write, we have conditioned our model upon the variable

18:50.400 --> 18:55.600
pi, which represents a choice we can make in selecting our data. So data recognition,

18:55.600 --> 19:00.960
interpretation, analysis, and so on. It's often framed as kind of like an observation type or

19:00.960 --> 19:09.120
sense making type activity. Here, pi for policy, as with usual, is being framed as a control or

19:09.120 --> 19:17.360
an active data selection policy, we're applying to some data set. So it adds a action element

19:18.000 --> 19:23.200
into this sequential epistemic foraging, rather than just taking a large data set,

19:23.200 --> 19:29.120
and just munching it like all at once, it brings in this sequential question of where to sample,

19:29.120 --> 19:36.160
and potentially updating where is informative to sample through time. And that I of pi is the

19:36.800 --> 19:42.480
functional on that policy distribution or specific choice that can be decomposed,

19:42.480 --> 19:46.320
all these interesting ways that we can explore more in the coming discussions.

19:46.320 --> 19:48.400
What else would you add, though, about information gain?

19:49.440 --> 19:54.000
I think this is one of the biggest points in this whole paper is you're measuring how much

19:54.000 --> 19:59.440
information you are gaining in your model by adding these different variables in here and

19:59.440 --> 20:05.360
selecting different variables. You're effectively automatically taking out or trying to remove

20:05.360 --> 20:10.320
things that have high mutual information that don't add as much. So if you have parameter A

20:10.320 --> 20:15.680
and parameter B that are effectively just transformations of the same data, then you

20:15.680 --> 20:19.840
can easily remove one of those and still have all the information that you need.

20:20.800 --> 20:26.720
So it's a really, really powerful way of saying I'm trying to optimize and maximize the amount

20:26.720 --> 20:33.120
of information that I'm adding into the model by selecting data that actually has the information

20:33.120 --> 20:43.280
that is going to improve them. Awesome. One other interesting angle here is often in the control

20:43.280 --> 20:50.000
literature, utility, reinforcement learning, etc. The epistemic value component is added in,

20:51.120 --> 20:58.080
whereas in the structure of this paper, they start with the pure information gain perspective.

20:58.080 --> 21:03.520
And then in the clinical trial, they bring the preference in. So the pragmatic value

21:04.160 --> 21:09.520
comes in secondary to the information gain in how they build it up step by step.

21:12.000 --> 21:19.360
Bayesian inference is the last keyword. A lot of places to go. Here's what they showed

21:19.920 --> 21:25.280
for equation one. And they wrote Bayesian inference is the process of inverting

21:25.760 --> 21:32.640
a model of how data, why, are generated to obtain two things, the marginal likelihood

21:32.640 --> 21:37.520
and the posterior probability. So anything you want to say about Bayesian inference or

21:37.520 --> 21:42.320
do you want to say something about Bayesian networks and graphs? I think that you've kind of

21:42.320 --> 21:48.960
covered it here. It's, I think, barely textbook on this part. Yeah. How about graphs?

21:49.920 --> 21:57.680
On the Bayesian graphs side of it, there's multiple different ways that these Bayesian

21:57.680 --> 22:03.360
statistics is done nowadays. And the Bayesian networks and graphs is a really powerful method

22:03.360 --> 22:10.880
going forward. I know that right now in the Institute, we have an Rx and Fur group working

22:10.880 --> 22:17.040
right now, which is a Julia package for actually just building these network graphs, these Bayesian

22:17.040 --> 22:22.480
graphs and doing message passing between the different factors and the different nodes of

22:22.480 --> 22:31.440
the graph. So this is a very big up and coming area right now. It's very early in the time frame

22:31.440 --> 22:36.480
that this is going to become big. It's kind of on the upswing right now. And it's kind of,

22:37.440 --> 22:42.000
at least I would predict, going to be kind of the next big thing going forward in the next five

22:42.080 --> 22:50.880
years or so. Yeah. We've been having a great epistemic time and Livestream 55 explores some of

22:50.880 --> 22:59.360
this in more detail. Okay. That was the background now on to the paper. So first, just to get the

23:00.560 --> 23:06.960
last part of the paper out of the way, they have a GitHub, Thomas Parr's GitHub with the

23:06.960 --> 23:12.560
active data selection repo. And maybe in one of the upcoming discussions or somebody in the time

23:12.560 --> 23:20.960
between can explore and transform and play with the code. And also all these different

23:20.960 --> 23:25.760
ways that we have fun discussions around the language of the active inference model

23:26.320 --> 23:32.240
and how building it in different languages or using different styles like is there isn't plausible.

23:32.240 --> 23:38.400
These have been very fun discussions that help us get at what the core of the math really is

23:39.040 --> 23:43.680
and how that's independent of whether it's written in MATLAB or any other language.

23:44.640 --> 23:49.840
And then also as it is simulated, it's written here in MATLAB. And so that's kind of interesting.

23:50.560 --> 23:54.640
Any thoughts on that or just like coding in Rx and fur or or

23:55.600 --> 24:03.440
Yeah, I think that with Rx and fur being, I think, relatively new on the scene, you have some of

24:03.440 --> 24:10.960
these other traditional approaches with MATLAB and high MD and that sort of thing. It'll be very

24:10.960 --> 24:18.320
interesting to see how these techniques evolve over time with packages like Rx and fur really,

24:19.040 --> 24:25.280
I think, changing how we approach building these models and designing them. I think that it's going

24:25.280 --> 24:32.240
to be even more critical now in this current environment to select the data intelligently

24:32.240 --> 24:38.080
going in so that you're not muddying up your models or having to build two big of models that might

24:38.080 --> 24:46.560
have information that's not as useful to the application at hand. Yeah, great. All right,

24:46.640 --> 24:52.400
section one introduction. So we'll try to hit on some of the key points. I'll say something briefly

24:52.400 --> 24:59.840
and then feel free to add something if you want. Section one situates that inference and action

25:00.800 --> 25:09.520
cycle or loop or partition in terms of a statistician's job or process in modeling

25:09.520 --> 25:17.520
observations data as sampled and latent variables as models and the process by which there's

25:18.560 --> 25:26.560
kind of snapshot or bulk summarization or generativity or and how it's possible to have a

25:26.560 --> 25:33.360
continuous resampling of informative data or how you even evaluate how data are informative in which

25:33.360 --> 25:40.080
way. Want to add anything? I think you've captured that very well. I'm going to actually pull out my

25:40.080 --> 25:48.400
notes so that I can actually remember all the symbols. Why are going to be used for data and

25:48.400 --> 25:56.800
data for the latent variables? So distributions of data, distributions of latent variables

25:56.800 --> 26:04.080
conditioned upon data coming in. So that could be seen as just one data point sequentially or a big

26:04.080 --> 26:11.360
bulk vector coming in like all at once. Just continuing to move through this section, they wrote

26:12.640 --> 26:17.440
careful data selection is especially important when we consider the problems associated with

26:17.440 --> 26:22.240
very large data sets of the sort that are now ubiquitous in machine learning and artificial

26:22.240 --> 26:29.920
intelligence settings. So just to summarize a little bit or add a few notes that came up in

26:29.920 --> 26:36.080
the paper. So other than this topic being very fascinating and very integrative in terms of a

26:36.080 --> 26:41.520
unifying approach for information and behavior etc. Also this is definitely one of the active

26:41.520 --> 26:47.200
inference questions that has a lot of pragmatic relevance as dealing with with data sets of

26:47.200 --> 26:54.240
different kind is totally day to day. And especially the way that even the examples specify

26:54.240 --> 27:00.400
important settings is very clear, very direct. Though also the mathematics are very general

27:00.400 --> 27:08.400
about epistemics and this motivation that they lay out in the first section about how if this

27:08.400 --> 27:13.040
challenge could be addressed, then there will be all these kinds of benefits that could be realized

27:13.040 --> 27:20.000
with current systems and data sets. And then they provide the approach to at least getting

27:20.000 --> 27:25.280
there or towards it to optimize data selection. We first need to identify an appropriate optimality

27:25.280 --> 27:29.680
criterion. And so they're going to kind of go through several stages of with different

27:30.320 --> 27:37.920
generative models how that optimality criterion is defined. Anything else that

27:38.880 --> 27:44.000
And keep in mind that this is the expected information gain that they're talking about.

27:44.000 --> 27:49.760
It's effectively how much do we think we're going to gain by adding this information in there.

27:49.760 --> 27:56.160
And then you can of course train your model by looking at the actual information gain if necessary

27:56.160 --> 28:02.000
and go through kind of a learning cycle. But we're basing this all off of what do we expect

28:02.080 --> 28:08.640
to gain from this information. All right, section two, basing inference generative models and

28:08.640 --> 28:18.400
expected information gain. In this equation three, I won't read it all. It models the Markov blanket

28:18.400 --> 28:24.800
formalism in terms of upstream and downstream causal relationships in terms of messages that are

28:24.800 --> 28:31.200
passed along edges of a factor graph. They introduce in this paper the lambda operator

28:31.200 --> 28:37.920
to indicate either summation or integration. So this is across continuous variables or discrete

28:37.920 --> 28:44.960
variables. And we'll explore this more with the authors, hopefully anything you want to add on

28:44.960 --> 28:54.160
equation three. More that you know the information gain is a function of the data that you sample.

28:54.160 --> 28:58.480
So depending on how you sample that data, you're going to get different information gain out of

28:58.560 --> 29:05.360
it as you would expect. And then you start to get into the message passing, which is that base graph

29:05.360 --> 29:11.200
and factor graph, I guess, challenge going forward that that construct when you build

29:11.200 --> 29:16.720
it in a factor graph model, you have to be able to pass the messages between the nodes effectively.

29:17.680 --> 29:24.640
Yeah, and to kind of ground that in the data science situation, if you have a latent

29:24.640 --> 29:30.400
state estimate and you're generating data, generative AI, synthetic data, then the latent

29:30.400 --> 29:36.800
variable is upstream, causally, statistically from the data pseudo observation. But that might be

29:36.800 --> 29:43.040
the actual real observation if you're interested in the computer model. Whereas the data recognition

29:43.040 --> 29:49.440
case where the data are upstream of the estimate of a parameter, like a risk score or something like

29:49.440 --> 29:55.760
that, then the parents of the latent state estimate is the data. So that's the recognition

29:55.760 --> 30:01.680
direction. So this kind of covers the whole Bayesian update possibility spectrum in this

30:02.640 --> 30:09.120
essentially Markov blanket, but it could be in face space or time or a few other situations

30:09.120 --> 30:21.840
they explore. All right, three, a worked example. This section lays out the overall pipeline for

30:21.840 --> 30:29.040
how you get from the graphical notation of the Bayesian network, whether it's viewed visually

30:29.040 --> 30:36.160
graphically, like with a variable dependency structure, or whether it's just written out

30:36.160 --> 30:42.560
in terms of the plain text with the analytical, the Bayesian network is transformed into a factor

30:42.560 --> 30:49.440
graph, probably constrained factor graph, discussion for another day. On that graph,

30:49.440 --> 30:59.040
certain messages are passed at inference runtime. conditional and predictive entropies are calculated

30:59.040 --> 31:07.520
as part of the way that this system outputs or is described by different probability distributions

31:07.520 --> 31:14.000
understand in a kind of statistical mechanical way in terms of entropy. And then that is going

31:14.000 --> 31:20.640
to come together into calculation of the objective function, which is the expected information gain,

31:20.640 --> 31:26.800
which is basically conditioned upon the cognitive model of the sampler. So just because the sampling

31:26.800 --> 31:33.360
is active data sampling, doesn't mean that it's going to lead to like an adaptive behavior.

31:34.320 --> 31:40.240
It just means that where the learning rate is perceived to be highest informationally,

31:40.240 --> 31:48.080
iteratively, there is a ranking by which those can be, which this the space of experiments

31:48.080 --> 31:56.240
can be ranked by and it can connect to pragmatic value in terms of epistemic and pragmatic coming

31:56.240 --> 32:01.280
together for the full expected free energy like in the clinical trial. Anything else?

32:02.240 --> 32:09.120
And you'll notice in this story example, they are discussing here, the factors that they have in

32:09.120 --> 32:16.400
their graph in each of their nodes is actually a cosine. So that's why you get that kind of

32:16.400 --> 32:25.680
oscillation in that bottom plot there. So you'll have areas of maximal information and then areas

32:25.680 --> 32:30.960
of minimal information just based on the toy example they have. And this doesn't always have

32:30.960 --> 32:36.240
to be cosine, but in this example it is. And so it just kind of gives you a really good graphical

32:36.240 --> 32:46.160
understanding of how your information gain can be viewed over a sinusoidal sort of oscillation.

32:47.440 --> 32:52.480
Yeah, just to kind of double down on that, if you sample right here on the number line,

32:52.480 --> 32:59.200
or right here, the lines are indistinguishable. So the information gain is expected to be low

33:00.080 --> 33:05.520
under understanding the parameter family that is being generated and sampled from,

33:05.520 --> 33:12.080
which in this first example is the same, same type of equations. Whereas where the functions are

33:12.080 --> 33:18.880
maximally distinct, the information gain associated with reducing uncertainty about which one of those

33:18.960 --> 33:29.680
five the data point is coming from, those are the informative points at the zero on the number line

33:29.680 --> 33:36.880
and far out. That's where just perceiving one point uncolored would give you the most ability to

33:36.880 --> 33:41.360
even perfectly resolve which one of the five situations it was.

33:41.920 --> 33:51.280
So they're right. In effect, this model amplifies or attenuates the amplitude of the predicted

33:51.280 --> 33:57.840
data, depending upon a periodic function of our data sampling policy pi. So here the policy

33:57.840 --> 34:03.520
distribution is like that kind of around the clock direction, which is not a common setting,

34:03.520 --> 34:11.680
but the general idea of sampling amongst a finite set of alternatives, where a control

34:11.680 --> 34:18.800
variable is going to result in the most informative data point, is a theme that is going to be

34:18.800 --> 34:26.720
expanded upon, and also one interesting mathematical move. Once all terms that are constant with

34:26.720 --> 34:33.600
respect to pi are eliminated, we are left with equation six. So equation five comes down to

34:33.600 --> 34:42.960
equation six, or maybe not exactly only five to six, but six has removed all the variables

34:43.680 --> 34:49.680
that don't change as policy changes. So if the question of policy selection is taken alone,

34:49.680 --> 34:56.160
like gradients on policy updating, then everything that's constant with respect to it

34:56.240 --> 35:02.080
doesn't come into like the delta pi, delta something. So it just simplifies it down to

35:02.080 --> 35:07.120
only a function of policy, and that just kind of reflects how like the sense making and belief

35:07.120 --> 35:13.200
updating component is partitioned off from the policy selection component here.

35:15.520 --> 35:21.840
Yeah, you're looking for change in your belief based on the observations that you're gained.

35:21.840 --> 35:26.560
So if it's not changing, it's not as informative in your information model.

35:28.880 --> 35:35.840
Yeah, continuing on equation six there, which is modeling the policy dependent

35:35.840 --> 35:42.880
components of information gain as an objective function that ranks decisions about where to

35:42.880 --> 35:50.560
sample. Equation six is a special case of the third row of table one, which highlights analytical

35:50.560 --> 35:56.400
expressions for expected information gain for a few common model structures. As we might intuit,

35:56.400 --> 36:00.400
the most informative place is to sample data aligned with those in which differences in data

36:00.400 --> 36:05.360
lead to large differences in the predicted data, in which our choice of pi maximizes the sensitivity

36:05.360 --> 36:16.000
with which y depends on data. So here are the categorical, the Dirichlet, and other functions

36:16.000 --> 36:22.880
in terms of how they'd be written out in the probabilistic, like specifying a distribution

36:22.880 --> 36:31.840
way, and then how there's this relationship analytically to a related distribution, which is

36:32.640 --> 36:40.400
an objective function that ranks the information content of sampling the likelihood distribution

36:40.400 --> 36:47.280
in a certain way. And that's closed form in certain situations. And then also they explore

36:47.280 --> 36:53.280
where it's intractable formally. And so then that's where the variational approximation comes into

36:53.280 --> 37:03.600
play. Anything to add? No, I think that summarizes this slide. Okay, section four, function approximation.

37:04.560 --> 37:10.400
We next turn to a generic supervised learning problem, that of trying to approximate some

37:10.960 --> 37:14.880
function based upon known inputs and the observable outcomes they stochastically

37:14.880 --> 37:23.760
cause. Pretty general neural network or latent state observation setup.

37:24.000 --> 37:37.680
That information is composed and concatenated. So that there's a common variable with that's

37:37.680 --> 37:42.560
describing the statistical object that's going to be describing the inputs and the relationship

37:42.560 --> 37:53.920
with the observable outcomes. And then that function approximation from sequential data

37:53.920 --> 38:00.640
in figure three is simulated with random but potentially you could call all of them random.

38:00.640 --> 38:10.400
But this one is a flatter or a less informed and iterated model of data sampling,

38:11.120 --> 38:16.800
just going to show that samples of random data with even this minimal

38:17.760 --> 38:24.720
non information gain driven model has a certain baseline prediction that's associated with

38:24.720 --> 38:32.320
certain choices about sampling sequentially from this generative model. Want to add anything?

38:33.360 --> 38:39.680
Yeah, it's just I like that they highlighted in this that choice diagram there that you can

38:39.680 --> 38:45.440
actually get the inefficient sampling just by random that you start to you can randomly select

38:45.440 --> 38:52.800
two things very close together and you've effectively maybe not wasted a choice but

38:52.800 --> 38:57.600
you know not gotten the maximum gain from that choice that you could have.

38:59.440 --> 39:08.400
Yeah, they write a little bit more about figure three. Figure three illustrates a depiction of

39:08.400 --> 39:13.440
this model as a Bayesian network and a visual representation of the data generating process.

39:16.960 --> 39:22.960
Now they're going to bring in information gain. So they write this is where information gain

39:22.960 --> 39:29.760
becomes relevant into designing a more informed way to sample data than from a flat or a non

39:29.760 --> 39:34.800
updating prior data sampling distribution. It's like equivalent to having a policy prior that's

39:34.800 --> 39:42.080
fixed which might be a heuristic in certain space. They write substituting equation seven into

39:42.080 --> 39:53.760
equation three. So here's that Markov blanket parent child concept and here equation three is

39:53.760 --> 40:00.640
describing the policy dependence on the joint distribution of the observed and unobserved

40:00.640 --> 40:10.640
and this is combined into equation 10. To show what equation 10 does in terms of now that we're

40:10.640 --> 40:19.120
sampling from this distribution or like statistical distributions that this describes they'll

40:19.120 --> 40:23.760
differentiate figure three from figure four kind of like bring in this model change between those

40:23.760 --> 40:28.640
two figures. Now samples are drawn from a distribution whose log is proportional to the

40:28.640 --> 40:36.640
information gain in equation 10. So it takes the flat policy prior and in a fixed way has remapped it

40:36.640 --> 40:45.760
to be proportional to the information gain. So here's three on the right and then four on the right

40:46.880 --> 40:53.360
and the figure uses the same format as figure three but now each choice is sampled to maximize

40:53.360 --> 41:00.800
anticipated information gain and they point to some specific quantitative patterns but also

41:00.800 --> 41:07.120
like qualitative patterns. So want to add anything on figure four? Just that now if you focus on those

41:07.120 --> 41:13.120
choices because that I really did I think like that choice plot there you can see that the walks

41:13.120 --> 41:19.920
around kind of choices around your data space are a little bit more distributed evenly distributed

41:19.920 --> 41:25.680
a little bit less random but you start to get I think a more cohesive sampling of the data

41:25.680 --> 41:31.440
without entire randomness putting things too close together putting selections too close together.

41:34.480 --> 41:42.160
Yeah okay continuing on well they set up the question as this raises the question as to how

41:42.160 --> 41:48.960
many samples should we collect. So within a foraging bout where should one look and then at the kind

41:48.960 --> 41:54.480
of like pulling a layer back in the strategy when should you halt look it like if you have already

41:54.480 --> 42:00.720
sampled all three records from a data set then unless you had some other reason you could fully

42:00.720 --> 42:07.360
stop sampling there but you also might want to have a softer stopping criterion that would relate to

42:07.360 --> 42:12.800
how much information you're gaining from continuing to sample in that way before like halting and so

42:12.800 --> 42:21.280
they include that by having like an exit policy in the state space of foraging possibilities.

42:22.400 --> 42:27.520
So how do you resolve that and answer this question can be drawn from behavioral neuroscience in the

42:27.520 --> 42:36.560
so-called exploitation exploration dilemma and they introduced the notion of sampling costs

42:37.120 --> 42:44.960
to help decide that. So this method is still going to require parameterization and situation

42:44.960 --> 42:50.240
specific modeling of the relative costs versus the relative information gain however at least

42:50.240 --> 42:57.440
there's an accounting that includes costs into the sampling equation to give any possibility of

42:57.440 --> 43:02.880
exiting because if no costs are provided for sampling then the model might just converge

43:02.880 --> 43:08.240
and continue to eke out very small amounts of variance explained if it doesn't explicitly

43:08.240 --> 43:16.880
have that stop option so they take the policy vector the list of locations that can be sampled

43:16.880 --> 43:22.480
from and adds a zero element which reflects the information gained if we were to stop sampling

43:23.440 --> 43:30.160
and then there's a preference over those observations expressed in the c vector preferences

43:31.120 --> 43:36.320
and this brings in the information seeking and the cost averse of imperatives into the same

43:36.320 --> 43:42.960
objective function in 11. Anything to add on 11? Yeah eventually the idea is that it just gets to

43:42.960 --> 43:49.760
a point where you're no longer whatever you set you're kind of stopping like energy to be

43:51.120 --> 43:55.680
kind of breaking energy eventually it's just gonna get to a point where the model just says

43:55.680 --> 44:02.240
hey I've reached what I can you've set this you're not gaining any anything beyond this point

44:02.240 --> 44:07.520
we can just stop at this point which is nice since in the random selection case there's not

44:07.520 --> 44:13.680
necessarily a stopping parameter as Daniel mentioned you could continue to get eke out

44:13.680 --> 44:19.360
very very small marginal changes but you're not going to gain anything else and so you're just

44:19.360 --> 44:24.960
spinning your wheels for no reason so this is a very elegant way of saying hey I've reached kind

44:24.960 --> 44:34.720
of an inflection point of data gain I'm done. So figure five they're continuing in this genre of

44:34.720 --> 44:42.160
three four five and now they've added in to the policy decision which which has an upstream

44:42.160 --> 44:48.480
dependency on the data that's the active policy edge they add in this

44:48.880 --> 44:58.400
cost to sampling so we can explore more however it now includes not just the information gain

44:58.400 --> 45:06.880
driven choices within a trial but it includes a specific probabilistic but decisive stopping point

45:07.440 --> 45:13.440
for that trial as parameterized by how sensitive it is to information gain and preference

45:14.000 --> 45:20.080
so this is one of the most interesting parts and and discussions in the paper

45:21.040 --> 45:26.800
they they ask it out loud a reasonable question to ask at this stage is why bother

45:27.360 --> 45:33.040
with the full information seeking objective and basically how does this differ from maximum

45:33.040 --> 45:43.120
entropy sampling and um let's look forward to the authors or other guests but here's just a

45:43.120 --> 45:48.400
few notes on this because I think it'll be a great place to explore what it really means to do

45:48.400 --> 45:56.400
statistical and physical modeling on cognitive systems they directly contrast maximum entropy

45:56.400 --> 46:04.960
sampling and their whole information gain family against each other and then the rebuttal is in

46:05.520 --> 46:12.080
figure six so just to show figure six for a second the measurement noise increases in variance from

46:12.080 --> 46:19.440
the center of the function domain so the the variability profile of the function is non-uniform

46:20.080 --> 46:25.040
this means this means the amount of unresolvable uncertainty is heterogeneous through the domain

46:25.040 --> 46:33.280
of potential sampler so I in some kind of ways of thinking about what they're really getting at

46:33.280 --> 46:38.400
and just putting this out as a speculation or starting point for for this key technical point

46:39.120 --> 46:46.560
so if there were a case where the latent states were equivariants they had iid variability

46:46.560 --> 46:53.200
profiles then sampling the most variable sensory data is the most informative like if

46:53.200 --> 47:00.720
you're taking a picture of a solid black image then sampling from the noisy pixels is going to

47:00.720 --> 47:05.680
potentially provide more information gain you're reducing uncertainty more about something

47:05.680 --> 47:12.400
it might be overfitting but you can select as a heuristic wanting to sample from where variability

47:12.400 --> 47:20.160
is high at just kind of a first pass layer however as we start to think about richer or

47:20.160 --> 47:29.680
more specified statistical patterns generative models there become dependencies that are sparse

47:29.680 --> 47:36.960
but important amongst all different kinds of things so things that are variable from a sensory

47:36.960 --> 47:45.920
perspective provide high information gain potentially to one part of a generative model

47:46.800 --> 47:57.520
like a screen and static but then other events might be less variable from a sensory perspective

47:57.520 --> 48:03.600
but smaller differences even in that variable relate to some other component of uncertainty

48:04.320 --> 48:10.720
resolution from some other component of the the model like those are going to be the cases where

48:11.680 --> 48:18.640
cognitive modeling does differ from just dispersed decision-making however they're

48:18.640 --> 48:26.800
both going to result in dispersed decision-making profiles like looking at the choices in the

48:26.800 --> 48:35.520
figures but the choices to sample from the less ambiguous parts of the actual distribution

48:36.320 --> 48:45.600
that leads to a much narrower policy path in this cognitive control setting versus in a variability

48:45.600 --> 48:52.560
sampling where it would go for the areas that were just more variable but not necessarily

48:52.560 --> 48:55.760
providing more information question mark

48:59.280 --> 49:01.840
and you can add on this with the maximum entropy or anything

49:03.200 --> 49:10.320
and I would even highlight kind of on the next slide it effectively what it is doing is accepting

49:10.320 --> 49:16.640
that you're not going to gain a lot of resolution in these highly variable regions and so you don't

49:16.640 --> 49:22.720
really have to sample into those deeply because you've accepted that it is variable it is not

49:22.720 --> 49:27.840
something it is inherently variable in the data we're not going to gain a lot of information

49:27.840 --> 49:34.080
from these regions and it's highlighted in blue down there and I think that's one of the big highlight

49:34.080 --> 49:41.120
notes of this figure is this less information gain available in these highly available regions

49:41.120 --> 49:47.760
and that's something that makes this method more robust and powerful when you're dealing with some

49:47.760 --> 50:00.160
of these non-uniform variable data yeah awesome and then the the um streetlight effect is brought in

50:00.160 --> 50:05.360
there so the avoidance of sampling in ambiguous locations is sometime referred to as a streetlight

50:05.360 --> 50:10.480
effect the tendency to search where data are generated in a minimally ambiguous way i.e.

50:10.480 --> 50:18.000
under streetlamp compared to searching elsewhere on a darkened street so I made some GPT-40 images

50:18.800 --> 50:25.520
some fun streetlight and on one hand there's kind of this sense of like is it constraining to look

50:25.520 --> 50:30.640
under only the streetlight isn't that kind of absurd and then there's the joke about how what

50:30.640 --> 50:35.040
the person's looking for is elsewhere but they're still searching under the streetlight

50:35.040 --> 50:38.560
but they're looking for something they they know is elsewhere so that's the kind of

50:38.560 --> 50:44.480
tragic element of it then there's this limited element however there's also this realistic element

50:44.480 --> 50:51.120
which is like well are you supposed to search where you can't sense or outside of where you

50:51.120 --> 50:58.880
are at that moment so how could you you know say that that wasn't just and then this paper is more

50:58.880 --> 51:07.280
framing it as just a general condition of perception like you're in your tactile streetlight

51:07.360 --> 51:14.640
that is the part you can see at all you can have latent modeling of any and other things

51:14.640 --> 51:20.960
but if it's not grounded in some way to a measurement made in a streetlight under the

51:20.960 --> 51:26.080
metaphor where the light allows for observation then you're not connected to data unless you're

51:26.080 --> 51:31.200
connected to that streetlight so that's just a very interesting kind of topic and and reference

51:31.200 --> 51:36.160
that the authors use what do you think absolutely I mean it kind of boils down to you can't

51:36.160 --> 51:41.520
know what you don't know what you can't observe you know if you can only observe what's underneath

51:41.520 --> 51:46.240
the streetlight then you can't really know what else is outside of there and so your inference

51:46.240 --> 51:51.360
necessarily should be constrained to what you're able to actually observe you can't observe the

51:51.360 --> 51:57.440
unknown and so not necessarily in this case um because you don't even know if it even exists

51:57.440 --> 52:05.280
you have no data to confirm or to refute it all right section five dynamic processes so

52:06.080 --> 52:10.720
in that previous example there was a data selection challenge whether it was approached

52:10.720 --> 52:16.400
from the flat fixed prior or all these other kind of subsequent variants with the adaptivity

52:16.400 --> 52:22.320
and or with the cost now there's going to be a time element brought into the underlying

52:22.320 --> 52:26.960
generative model we'll just go quickly here because that's the big point they take the static

52:26.960 --> 52:33.120
distribution that was sampled from and now give the underlying process also variability

52:33.120 --> 52:40.800
through time so this is like a very SPM brain latent state causal modeling type set yeah anything

52:40.800 --> 52:46.880
you want to say on that before we go in oh no go ahead okay okay so they consider processes that

52:46.880 --> 52:52.720
evolve in time equation 12 can be interpreted similarly to equation eight in which the expectation

52:52.720 --> 52:57.680
of the data is treated as a function approximation which now includes a time argument so here was eight

52:58.320 --> 53:05.040
expectation of the data given latent state parameterization and policy equals so on

53:05.840 --> 53:12.880
and then here there is data also being a function of parameterization and policy

53:12.880 --> 53:20.480
and then also bringing in an element with a subscript tau for time uh then you mentioned in

53:20.480 --> 53:28.160
your big questions the different approaches that they raise here with the three ways to

53:28.960 --> 53:33.440
bring temporalities into a model so let's definitely talk about that but just to show

53:33.440 --> 53:41.920
their images seven and eight are the pair for this dynamical section so figure seven shows a

53:41.920 --> 53:46.560
graphical representation of the matrices involved in generating our data and the inferences obtained

53:46.560 --> 53:54.720
after sampling so here it is sampling from a time variance function and then figure eight goes into

53:54.720 --> 54:01.280
more detail and notes predictions based upon current data can be used to inform predictions

54:01.280 --> 54:06.400
about nearby spatial locations and to predict and post it the values of the function at different

54:06.400 --> 54:15.520
points in time so just like you could have a 2d plane grayscale and infer the location of the

54:15.520 --> 54:20.320
streetlight by pursuing like a gradient up the light and then there would be this optimal

54:20.320 --> 54:25.760
sampling like if you just got one observation you would want to sample on a line that was

54:25.760 --> 54:30.800
orthogonal to the one that you couldn't resolve lots of ways to think about this sequential

54:31.440 --> 54:35.120
prediction but now the underlying landscape also changes so there's some

54:36.000 --> 54:40.880
temporal dynamics and then that can be fit with all these different time series models and

54:41.600 --> 54:47.200
autocorrelation and so on however that's specified statistically in the generative model

54:47.200 --> 54:51.840
but this section just shows however you do make a statistical model for time

54:53.360 --> 54:59.760
it's basically going to be the same thing where information is going to be drawn from a distribution

54:59.760 --> 55:06.160
and now time is a variable in that distribution uh they write in this in the previous section we

55:06.160 --> 55:10.400
have demonstrated the way in which smarter optimal sampling may be used to select data

55:10.400 --> 55:15.440
in a manner that balances the cost of sampling or performing further experiments against the

55:15.440 --> 55:20.560
information gained from those samples or experiments each of these examples has relied

55:20.560 --> 55:25.680
upon relatively simple and analytically comfortable linear Gaussian systems next we address active

55:25.680 --> 55:32.640
sampling in a situation where analytical solutions are no longer possible so to highlight the key

55:33.600 --> 55:40.320
formalisms that they're working with in that kind of background section uh or setup section

55:41.680 --> 55:47.760
they kept one thing constant which was that the the generative model the generative process or

55:47.760 --> 55:54.720
however it's considered with the family of equations that the agent is inferring and tracking hidden

55:54.720 --> 56:00.080
states with and that being the same as the actual family of equations that's generating

56:00.720 --> 56:09.440
the function of observations and here that is relaxed so that opens it up to all empirical

56:09.440 --> 56:15.920
settings where you can just say right off the bat we do not have access to the generative model of

56:15.920 --> 56:20.800
those data so we're making a map statistical map with all the associated trade-offs and

56:20.800 --> 56:28.400
statuses of like that genetic data or that transcriptomic data all those different kinds

56:28.400 --> 56:34.960
of data sets starting from a position where it's going to have to be statistically approximated

56:35.760 --> 56:41.680
and it isn't going to be based unless explicitly otherwise on actual knowledge about the causal

56:41.680 --> 56:49.600
elements of the system any any thoughts on that well in something else that they noted in the paper

56:49.600 --> 56:56.240
by adding this time element when they're actually going through the time series the model itself will

56:57.040 --> 57:04.400
preferentially select different data beyond what it just recently selected so time point one it

57:04.400 --> 57:11.120
selects x and y data time point two it might select l and m data so it actually will go through and

57:11.120 --> 57:17.920
select different types of data and it'll take a little bit of time um what the time is variable

57:17.920 --> 57:23.920
but it'll take a little bit of time before it revisits some of that previous data um at a

57:24.000 --> 57:28.560
previous time so by this you kind of have a sliding window of data that you're selecting

57:28.560 --> 57:37.680
over different time periods yeah all right that's all going to come to play in this clinical trial

57:38.320 --> 57:45.200
which is the big final contribution section of the paper in our final example we demonstrate the

57:45.200 --> 57:51.600
potential utility of the ideas outlined above in the context of a more concrete example so

57:51.600 --> 57:59.840
they model the statistical setting here as an adaptive Bayesian clinical intervention methodology

57:59.840 --> 58:07.280
experiment for example the kind that was done during the 2014 West African Ebola outbreak

58:08.240 --> 58:13.120
the active sampling approach advocated in this paper offers two main opportunities to augment

58:13.120 --> 58:20.000
adaptive trial designs first it allows us to adapt the design to maximize the information we obtain

58:20.000 --> 58:26.240
about treatment efficacy so that's the pure sense making information gain learning sampling from

58:26.240 --> 58:32.320
where it's informative not from where like we habitually or prefer to look and then second

58:33.120 --> 58:41.440
to balance and bring together that information gain with costs and that was brought in with

58:41.440 --> 58:48.640
the cost of the sampling section which was done in this paper by adding the stop policy option

58:48.640 --> 58:54.960
which can be probabilistically selected and then as other sampling locations become less

58:54.960 --> 58:59.920
informative or if somebody was just sampled and you know that there's a slow decay through time

58:59.920 --> 59:09.440
then on that subject the stop policy cost would outweigh the information gain from an experiment

59:10.640 --> 59:17.440
and this is also I think will be a very interesting discussion this blows the line between clinical

59:17.440 --> 59:22.640
trial and public health intervention and can be seen as analogous to animal behavior that is never

59:22.640 --> 59:29.120
fully exploitive or explorative but is a balance between the two so how do we think about that

59:29.120 --> 59:35.760
in terms of biomedical and health security and all these different topics and any thoughts on this

59:35.760 --> 59:40.800
before we go into the formalism of the clinical trial just like about clinical trials or anything

59:40.800 --> 59:47.200
yeah and I think that that's going to be like that last point there is going to be a big one

59:47.200 --> 59:52.960
going forward of like how do you balance benefits to the patient benefits to your trial benefits to

59:54.400 --> 59:58.960
essentially the company like there's a lot of different benefits and costs that you have to

59:58.960 --> 01:00:05.760
weigh into this and so these models are going to get very complicated when you start to distill

01:00:05.840 --> 01:00:12.480
this into something especially with health related so it'll be very interesting to see how this evolves

01:00:15.200 --> 01:00:22.240
okay so here's how they do it our setup is as follows for each new cohort of participants

01:00:22.240 --> 01:00:30.640
we decide upon the randomization ratio to adopt that's the orange subscript r of policy so this

01:00:30.640 --> 01:00:38.480
is policy on a randomization ratio there's three options so this is a discrete but linearly ranked

01:00:38.480 --> 01:00:47.600
not fully categorical policy decision where one half would be the 50-50 sampling between the two

01:00:47.600 --> 01:00:57.920
groups whereas you know a priori that sampling in a skewed ratio is going to be less informative

01:00:57.920 --> 01:01:02.480
like if you sampled only from one you would obviously be maximally uninformed about the other

01:01:02.480 --> 01:01:10.320
however what's going to end up being reflected in the policy decision to shift to a one-third or

01:01:10.320 --> 01:01:16.880
a two-third which is focusing observations on one branch of the study more than the other

01:01:16.880 --> 01:01:22.720
is going to focus on the explicit quantitative preference for observations of survival

01:01:23.520 --> 01:01:29.440
so that's going to be very interesting to see how the time variable which relates to the

01:01:29.440 --> 01:01:38.480
experimental design but by way of modeling the death curves of the participants and how different

01:01:38.480 --> 01:01:45.440
preferences for complementary processes of reducing uncertainty about the treatment specific

01:01:45.440 --> 01:01:52.480
death curves and not preferring to see death observations because that would introduce the

01:01:52.480 --> 01:01:59.680
pragmatic imperative to measure low survival experiments so there's a lot of complexity

01:01:59.680 --> 01:02:07.120
in there from the public health side also in this very simple and interpretable way that like this

01:02:07.120 --> 01:02:14.240
is like a Bayesian light switch with 50-50 information seeking mode or tilt it one way or

01:02:14.240 --> 01:02:21.360
the other to bias observations whereas if no information had to be resolved then the policy

01:02:21.360 --> 01:02:28.480
selection would orient towards observing long survival whereas if that was somehow changed

01:02:28.480 --> 01:02:32.960
then it would have to be adaptively sampled on the fly and changing these ratios and all that

01:02:32.960 --> 01:02:37.360
what do you what do you think about this yeah and what we're going to kind of get into is

01:02:39.120 --> 01:02:44.400
especially with these sorts of health decisions you want people to survive like that's your

01:02:44.400 --> 01:02:49.200
that's your primary goal in a lot of these you want to see an effect you want to see a positive

01:02:49.200 --> 01:02:54.560
effect of your treatment one way or the other you know if it's the placebo that's the positive or

01:02:54.560 --> 01:02:59.600
it's the actual treatment that's the positive you want people to survive so this is kind of

01:02:59.600 --> 01:03:05.760
getting into that ethics of making sure that when you design these things that you're doing the

01:03:05.760 --> 01:03:13.600
maximum good to your participants who you know may not have you know much hope to stand on

01:03:14.560 --> 01:03:20.400
doing some of these crises or epidemics or whatever they are experiencing at the time

01:03:22.160 --> 01:03:27.840
so you want to design this in such a way that you know you keep them the patients in mind

01:03:27.840 --> 01:03:35.920
that is the whole point of this and so by having a Bayesian kind of preference and bias to keeping

01:03:35.920 --> 01:03:43.120
the patient alive and the best outcome you're maximizing how the patient's outcome in the

01:03:43.120 --> 01:03:50.000
patient's life thanks for adding that another point to make this is from figure nine that's

01:03:50.000 --> 01:03:56.960
gonna come up but it really highlights how sparse and few and interpretable the Bayesian

01:03:56.960 --> 01:04:02.240
graphical formalism is and message passing which a lot of the equations describe and

01:04:02.240 --> 01:04:08.960
the discussion about rx and fur touched upon message passing gives procedural ways to implement this

01:04:09.920 --> 01:04:15.200
in computational systems because it's sometimes hard to go from the simplicity of like this

01:04:15.200 --> 01:04:22.960
graphical model to fitting it iteratively on complex data sets but it's pretty clear to see

01:04:23.040 --> 01:04:29.520
how different variables are upstream or downstream of other variables and also how the time

01:04:31.440 --> 01:04:39.120
sampling can be shown to be which is the upstream of data sampled as these other factors are

01:04:40.080 --> 01:04:49.440
but it has a separable interpretable calculable epistemic value that doesn't have a certain kind

01:04:49.440 --> 01:04:55.440
of connection to randomization ratio for example so being able to have explicit statistical

01:04:55.440 --> 01:05:03.280
calculations and directnesses where the follow-up time doesn't influence the treatment group ratio

01:05:03.280 --> 01:05:10.320
or the randomization ratio or other processes gives a type of interpretability that the

01:05:10.320 --> 01:05:16.320
generative model gives us the equations for and then the pragmatic challenges are about actually

01:05:16.320 --> 01:05:21.440
implementing that and then even if the computational component were totally addressed and abstracted

01:05:21.440 --> 01:05:27.520
away that would basically center these broader questions which i think the health example is

01:05:27.520 --> 01:05:34.160
a great like jumping off point four yeah and uh you have probably recalled from all the other

01:05:34.160 --> 01:05:41.520
different uh figures despite how simple this figure is the other figures the the plots were very

01:05:42.000 --> 01:05:47.920
basic the models themselves like you just had the three nodes you know converging on the y so

01:05:47.920 --> 01:05:55.040
despite how simple this looks you are adding more complexity to these um to these systems and the more

01:05:56.080 --> 01:06:02.080
complexity that you add the harder it is the more computationally intensive it is and so this is

01:06:02.080 --> 01:06:08.560
that question of how big can you go you know how how many nodes can you add how many parameters

01:06:08.560 --> 01:06:13.360
can you add how much complexity can you add to the system before it starts to break down

01:06:13.360 --> 01:06:21.360
or not perform as well as you would hope yeah so other than bringing in that randomization ratio

01:06:21.360 --> 01:06:29.200
kind of expression of preference this model differs from the prior one in that it's defined

01:06:29.200 --> 01:06:34.240
that the kind of cognitive map is not the territory they're different families so that's

01:06:34.240 --> 01:06:40.880
what motivates this um approximation approach so this is a simple displacement where still it's a

01:06:40.880 --> 01:06:49.760
trackable problem as they'll unfold however the simulation family chosen for the for like the

01:06:49.760 --> 01:06:54.320
approximation basically the approximation could apply to any data set but it might be woefully

01:06:54.320 --> 01:07:00.880
inadequate like it might fit only one component of it so that's again part of the interesting

01:07:00.880 --> 01:07:08.880
question is like how similar does the statistical model have to be or what information does it really

01:07:08.880 --> 01:07:17.200
bring in and how to to model or work with an empirical side um but just on a more general

01:07:17.200 --> 01:07:25.040
statistical level equations 15 16 17 describe some of the technical details of the incremental

01:07:25.040 --> 01:07:31.440
optimization gradient scheme the newton optimization variational plus we'll talk to

01:07:31.440 --> 01:07:39.920
thomas et al figure nine is displaying the kind of before picture for the randomized control

01:07:39.920 --> 01:07:47.120
trial so here's where that graphical model is that was shown earlier and then here are these two

01:07:47.840 --> 01:07:54.640
groups and their survival through time and different sampling uh choices that are made

01:07:56.000 --> 01:08:04.000
then just to to jump to figure 10 has the same layout as figure nine but now using the expected

01:08:04.000 --> 01:08:09.520
information gain from equation 18 to guide sampling of data so this is just to show the

01:08:09.520 --> 01:08:15.200
impact of that active data sampling and it will drop back to the equation uh there are some notable

01:08:15.200 --> 01:08:24.720
differences between the choices made in figure 10 compared with nine nine choices 10 uh the most

01:08:24.800 --> 01:08:30.480
obvious of these is that the follow-up time selected have been moved later once optimal sampling is

01:08:30.480 --> 01:08:36.000
employed this makes intuitive sense as a later follow-up time is informative about the survival

01:08:36.000 --> 01:08:40.720
probabilities at all prior times whereas an earlier follow-up time is not informative about

01:08:40.720 --> 01:08:54.240
survival probabilities at later time um where it gets in the final uh simulation brings in the

01:08:54.240 --> 01:09:03.120
random sampling plus the preference element here's where the symmetry is broken to also want the

01:09:03.120 --> 01:09:08.160
measurement of survival as more likely than death which is how the preferences are specified

01:09:08.720 --> 01:09:18.320
in active inference um and then the policy switch is reflected in this like um part where

01:09:18.320 --> 01:09:24.960
the observations are shifted later because there's there's less than a threshold of information to

01:09:24.960 --> 01:09:31.840
gain by having them earlier and then they uh even if there is equal variance i'm not exactly sure we

01:09:31.840 --> 01:09:38.960
can ask between the two branches there is uh an over sampling for the group with the higher

01:09:38.960 --> 01:09:46.160
survival which in this case was the placebo group so anything to add on this preference element

01:09:46.160 --> 01:09:53.440
this is the the like the crux of the whole making sure that you optimize you know the patient's

01:09:53.440 --> 01:09:59.040
outcome on this because the treatments in this scenario were not um were not beneficial they're

01:09:59.040 --> 01:10:04.960
actually harmful and so throughout the course of the study this by utilizing this model you

01:10:04.960 --> 01:10:11.840
actually randomized more people into the placebo group which caused a greater survival of these

01:10:11.840 --> 01:10:18.640
uh individuals and so you're you can already see the effect that this sort of methodology has on

01:10:18.640 --> 01:10:24.720
clinical trials because you're optimizing the outcome and i think that is exactly what you want

01:10:24.720 --> 01:10:31.440
to do in these health decisions in these trials in these things that impact human health uh or

01:10:31.440 --> 01:10:38.480
humanity in general you want to optimize the outcome uh and you know in this way you're actually

01:10:38.480 --> 01:10:48.320
reducing the overall harm to patients yeah interesting um here's the specification for the

01:10:48.320 --> 01:11:00.400
information gain so uh bringing in the the form of the message is required for equation three now

01:11:00.400 --> 01:11:06.720
with all these extra components that have been added in with time variability demographic and the

01:11:06.720 --> 01:11:15.760
sampling they write out some of the technical details for the approximations in the variational

01:11:15.760 --> 01:11:23.680
Laplace and then some aspects about those models which we can ask about but figure 11 basically

01:11:23.680 --> 01:11:32.640
shows the big change which is that uh as you go from having a a flat sampling distribution

01:11:33.920 --> 01:11:40.640
across time and across treatment groups you can actually do better than that basically by choosing

01:11:40.640 --> 01:11:49.120
a sampling regime that makes sense given the costs of sampling so that's just very interesting

01:11:49.120 --> 01:11:54.560
because it it really does look like given the the possibility for these two lines to diverge

01:11:55.440 --> 01:12:01.760
their divergence would be largest later on whereas if you could only schedule like one

01:12:02.320 --> 01:12:07.440
check for every person if it was something that was expected to happen later in life

01:12:07.440 --> 01:12:16.160
then sampling all the young wouldn't even make sense so then one approach is like flat

01:12:16.160 --> 01:12:23.280
sampling but that is kind of sometimes erroneously called uh like unbiased or or uninformative but

01:12:23.280 --> 01:12:29.440
it is very informative and then this is pointing towards how there can be better sampling than

01:12:29.440 --> 01:12:37.840
just trying to go flat across the entire latent state estimate if there are priors relating to

01:12:37.840 --> 01:12:44.400
something they can be leveraged as part of the probabilistic sampling and adapted to the

01:12:44.400 --> 01:12:52.240
data set at the in the end however for picking prior families for the active data selection

01:12:52.480 --> 01:12:59.760
that's a big question about how much it will change how the algorithms work so I guess that kind of takes us to the

01:13:01.120 --> 01:13:07.280
discussion the paper's focus has been on illustrating how we might make use of

01:13:07.280 --> 01:13:12.960
information seeking objectives augmented with costs which gave kind of the exit criterion or

01:13:12.960 --> 01:13:19.440
preferences which gives the biased pragmatic part of data selection to choose the best data to

01:13:20.400 --> 01:13:28.800
optimize our inferences and they highlight that the maximum entropy would yield identical results

01:13:29.680 --> 01:13:34.400
in several of our examples so that'll be interesting like what were the examples where

01:13:34.400 --> 01:13:41.360
maximum entropy and the information gain are identical and then what are the real world

01:13:41.360 --> 01:13:47.520
or the statistical settings when the variance around predicted outcomes is in homogeneous

01:13:48.480 --> 01:13:59.040
how does the full cognitive epistemic model based objective do differently than the max and

01:14:00.640 --> 01:14:06.480
distribution dispersal kind of null hypothesis any thoughts on this

01:14:08.640 --> 01:14:15.440
no I think you've captured it very well okay then there are several technical points worth

01:14:15.440 --> 01:14:19.760
considering for how we might advance the concepts reviewed in this paper so let's talk about each

01:14:19.760 --> 01:14:26.800
of these one refinement of the active selection process two empirical evaluation of active versus

01:14:26.800 --> 01:14:33.520
alternative sampling methods and three identifying the appropriate cost functions so we'll talk about

01:14:33.520 --> 01:14:42.320
those coming up conclusion here's the entire conclusion the key ideas involved in appeal

01:14:42.320 --> 01:14:48.080
to foveal like sampling of small portions of the total available data to minimize computational cost

01:14:48.720 --> 01:14:56.080
that's a very cool way to put it and it highlights that kind of like sequential scanning but also

01:14:56.080 --> 01:15:03.200
opens up some very exciting directions about how efficient that could be for some but not

01:15:03.200 --> 01:15:08.560
other kinds of problems and how those problems could be identified or those patterns could be

01:15:08.560 --> 01:15:15.040
filtered for to where different kinds of succating models would be adaptive or not so like these are

01:15:15.040 --> 01:15:21.680
all fun discussions we'll have and then they kind of brought all the theoretical components together

01:15:21.680 --> 01:15:28.880
at the end with the Bayes adaptive clinical trial with the cost of sampling constraints on

01:15:28.880 --> 01:15:37.600
sampling and also the preference for survival so what are your overall thoughts or what are you

01:15:37.600 --> 01:15:43.840
excited about for the ones to come I'm excited to kind of see me I mean this is a fairly recent

01:15:43.840 --> 01:15:49.280
paper I'm excited to see kind of where they have gone since this paper was published you know they

01:15:49.280 --> 01:15:56.080
had a number of kind of next directions I would love to see what of those directions have they've

01:15:56.080 --> 01:16:04.880
taken what they've compared it to other other sampling techniques this show shows a lot of promise

01:16:04.880 --> 01:16:12.640
going forward for very complex and you know ethical situations or situations where ethics

01:16:12.640 --> 01:16:19.760
are going to be a huge component so kind of where that is what they're going into and kind of where

01:16:19.760 --> 01:16:26.160
they see you know further improvements I still kind of want to know what would happen or what

01:16:26.160 --> 01:16:33.440
of these other time metrics or what are the situations these time metrics would or alternative

01:16:33.440 --> 01:16:40.800
time models would be applicable to or if this really is like the de facto just the way it needs

01:16:40.800 --> 01:16:46.800
to be done totally totally fair I think that could very well be the case I would just love to hear

01:16:46.800 --> 01:16:52.480
exactly you know if you did a hidden Markov model how would that look you know is is there a benefit

01:16:52.480 --> 01:16:58.880
of that over the selection that they have is there does it provide more or less versatility in the

01:16:59.120 --> 01:17:04.080
models these are things that are going to be I think very interesting going forward and then

01:17:05.280 --> 01:17:11.680
you know how do we like the like you noted in the discussion how do you optimize those cost

01:17:11.680 --> 01:17:16.880
functions what's what's a cost you know you're dealing with clinical trials it's a human life

01:17:16.880 --> 01:17:22.960
that's a cost time it's a cost there's also just computer time how much you can actually get

01:17:23.520 --> 01:17:29.520
how much compute you can get and give them all the time some of these machine learning models

01:17:29.520 --> 01:17:35.440
that you might want to apply this to or you know select data going into sometimes takes a long

01:17:35.440 --> 01:17:42.800
time to train how are you going to sample data that's going into those models how are you going

01:17:42.800 --> 01:17:50.960
to continually feed those models appropriate data going forward so this is a huge broad category of

01:17:51.840 --> 01:17:59.200
um directions that you can go clinical trials was a very wonderful example of a complex situation

01:17:59.200 --> 01:18:06.240
that is you know right there applicable to human life um but then you also have just data science

01:18:06.240 --> 01:18:11.840
in general like how are you going to utilize this to you know going more broad how are you

01:18:11.840 --> 01:18:17.200
going to utilize this just going forward in any data sense data is growing it'll continue to grow

01:18:17.200 --> 01:18:22.560
it will never really stop growing so it's going to be more and more important going forward to

01:18:22.560 --> 01:18:31.920
have these methods more broadly used and random's nice random's really really good but this holds

01:18:31.920 --> 01:18:37.920
a lot of promise to being I would love to just hear their thoughts on where that's going where

01:18:37.920 --> 01:18:47.520
they see that yeah a lot of a lot of interesting directions a few things that made me think of

01:18:47.520 --> 01:18:53.040
one was about search and about relational search concepts page rank and everything

01:18:53.040 --> 01:19:00.480
syntactic semantic new kinds of search algorithms and personalization for search and learning and

01:19:00.480 --> 01:19:06.320
updating and to what extent like explicit cognitive modeling would change the way that

01:19:06.320 --> 01:19:13.200
different recommendation algorithms or different kinds of computer systems would work I'll read

01:19:13.200 --> 01:19:19.120
a question um and then any any other questions otherwise this is our our last slide so thank

01:19:19.120 --> 01:19:27.440
you Christopher um okay glia maximalist wrote interesting point about biased and unbiased

01:19:27.440 --> 01:19:32.400
sampling schemes perhaps this points out the fact that unbiased approaches are the wrong

01:19:32.400 --> 01:19:39.760
thing to strive for in research study design what do you think about that unbiased research

01:19:39.760 --> 01:19:45.920
in study design um I think there's a time and place for unbiased and I think there's a time

01:19:45.920 --> 01:19:52.400
and place for bias I think that but you when you accept a bias into your model or refute

01:19:52.400 --> 01:19:58.800
take bias out of your model you need to understand why you're doing certain bias you don't want to

01:19:58.800 --> 01:20:04.560
have you know researcher bias is something that's a huge bias that you want to not have for example

01:20:06.080 --> 01:20:11.200
but in certain cases um like in this paper where you actually do want to have a bias

01:20:11.920 --> 01:20:16.720
you want to make an intelligent decision know why you're making that decision call it out and then

01:20:16.720 --> 01:20:22.800
build it into your model that would be my problem yeah that's interesting like there are certain

01:20:22.800 --> 01:20:27.920
statistical distributions the bias or the constraints on which to find the research study

01:20:28.000 --> 01:20:34.880
whereas other ones that can have an explicitly strictly negative like data loss or something

01:20:34.880 --> 01:20:40.960
but then the trade-offs of how that distribution actually interacts with others can enter into

01:20:40.960 --> 01:20:47.200
this more complex experimental calculus that relates to like well all these different

01:20:47.200 --> 01:20:55.200
experimental factors and so the optimal experiment for for different labs or different

01:20:55.280 --> 01:21:00.080
moments for the lab could look extremely different and that's going to be the case

01:21:00.720 --> 01:21:03.840
there's going to be just first behavior out of the way but then the question is how is that actually

01:21:03.840 --> 01:21:12.880
driven in a way that is doing better than drawing from distributions however even that does interestingly

01:21:12.880 --> 01:21:22.400
well for the right variables and you can mind bias all over the place I bias in data design

01:21:22.400 --> 01:21:28.160
in experiments is can be very useful so it'll just be interesting I think it'll be case by case

01:21:28.160 --> 01:21:29.040
it's the way I see it

01:21:35.920 --> 01:21:45.120
okay well do you have any last comments I think that the main thing here is I'm just very excited

01:21:45.120 --> 01:21:51.040
to see this paper come out I would love to see how this is going to evolve over time

01:21:51.040 --> 01:21:57.920
see if this can be applied to different technologies different areas I'm really excited

01:21:57.920 --> 01:22:04.320
just to see where this is going because I think this is just right on the cusp of what's needed

01:22:06.160 --> 01:22:14.720
awesome thank you okay we will look forward to it thank you see you all right thanks guys

01:22:21.040 --> 01:22:22.320
you

