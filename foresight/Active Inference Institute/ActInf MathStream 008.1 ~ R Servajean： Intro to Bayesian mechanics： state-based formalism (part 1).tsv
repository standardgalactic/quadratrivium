start	end	text
0	14520	Hello and welcome, everyone. It's January 26th, 2024. We're here in active inference,
14520	22480	MathStream 8.1 with Richard Sarajevan. And we're going to have an interesting presentation
22480	28080	and discussion today on introduction to Bayesian mechanics, free energy principle and the state
28080	34880	based formalism. This is part one. So Richard, thank you for joining. Looking forward to this
34880	42480	presentation and discussion. So to you. Hi, everybody. So yeah, my name is Richard Sarajevan.
42480	51520	I'm French working in Switzerland. I'm a PhD student at EPFL in Lausanne. And just to bring a bit
51520	60080	of context, I'm not working on Bayesian mechanics. We are, we do have a physics background, but we
60080	67680	are interested in modeling bacterial evolution and ecology. And what happened is that something like,
68560	74400	I mean, the free energy principle was always in the corner of my head. And one year and a half ago,
74400	81040	I decided to really read about the free energy principle, especially if I wanted to transition
81120	87200	to the field. And I do want to transition to the field after my PhD. And so I started to ask
87200	92720	many questions to the people from the FEP community. And I'm so grateful. Thanks for them.
93440	100240	And also on the discord of the of the active inference Institute. And at some point, I said that
100240	108320	I was preparing a lab meeting about the free energy principle. And Daniel proposed to have this
108880	115440	discussed on the live stream, because there isn't such material to specifically learn about
116240	120320	Bayesian mechanics and the actual physics underlying the free energy principle.
121520	128160	And so here I am. So once again, I'm not an expert on the matter. So always refer to the
128160	136080	original papers. But hopefully I gonna, I gonna do a decent job. So without further ado, let's,
136080	143120	let's start. I'm not going to tell you what we where we are heading, what questions we would like to
144080	148960	to address or whatever. I'm rather rather going to start building the framework right away.
149680	154000	And at some point, what we're doing, doing will become clear. So
155440	160000	as you may know, there are two formulations or formalisms
160960	167280	of the free energy principles, the so called state based formulation, and the so called
167280	175280	path based formulation. So today, we will focus on the state based formalism. It's not like the old
175280	181840	versus the new formulation. In fact, thinking in terms of path, or so called generalized
181840	188400	coordinates of motion, I've been around forever, but in the literature, but it kind of came back
188400	194320	to the front scene of the Bayesian mechanics literature, I think. Anyway, today, we will
194320	203120	focus on the state based form, formalism. So the very starting point is to write down
203120	209840	Langevin equation, a generic Langevin equation. So it's literally like saying, let's consider
209840	217120	a random dynamical system. Very briefly for the people not acquainted with such an equation,
217920	224480	x here is the state of your system. So it could be a simple scalar if you are
224480	231600	considering a one dimensional process. But in general, x would be a vector. For instance,
231600	239200	if I don't know, you want to, to model the 3d diffusion of a Brownian particle immersed in
239200	246640	a liquid, x would be a 3d vector was components are the coordinates of your Brownian particle.
247680	254080	And you can see on the left hand side that we have dx over dt, the time derivative of the state
254080	262080	vector. So that's such an equation really describes or specifies the dynamics of the system.
263120	268160	So many things can influence indeed the dynamics of the system. If I stick to my
268160	274960	Brownian particle example, maybe it is subject to an external force. So whatever is relevant here,
274960	282000	you put it in F, the so-called deterministic term or flow, we will refer to it as the flow
282000	289040	for the presentation. However, in some cases, there is stuff you don't want to explicitly model.
289760	297040	For instance, if I stick with my Brownian particle example, it is constantly hit by
298240	302720	the molecules of the medium surrounding it. Hence it's a Brownian motion, right?
303680	308720	And it would be so if you want to take into account this thermal fluctuations,
308720	315440	it would be mission impossible to explicitly model every single molecule of the millions,
315440	321840	if not billions of the molecules surrounding it. So a convenient way to still take into account
321840	328000	these fluctuations, which are literally thermal fluctuations in my example, a convenient way
328080	336960	to proceed is just to add a noisy term to the equation. So omega here is a random variable
337520	346240	was value changes with time with the appropriate statistics. Okay, so two brief remarks before
346240	353920	moving on. If you assume that the state of your system changes slowly compared to the time relaxation
354880	360560	of your fluctuations, you can write the autocorrelation function of the
361360	368480	noise like that, where gamma is the diffusion matrix and delta is the delta direct function.
368480	376240	So what it means, it's just that in that case, your noise is super rough and it's not correlated
376240	384160	in time basically. Also, second remark, you can, I mean, you can use the central limit theorem
384160	392560	to argue that it makes sense to assume that omega is normally distributed. So that in the end,
393760	399280	the noise is a Gaussian white noise, but not that in the next live stream where we will
400000	406000	discuss the path based formulation of the FEP, we will relax the white noise assumption.
406720	415920	Anyway, so we have this random dynamical system. And we can do something cool with the flow. So
415920	422560	the flow F is a vector, it has the same dimension than the state vector, because each component
422560	429200	of the state vector has its own longitudinal equation, if you will. And you can decompose it
429200	439280	into a solenoidal and a gradient terms. So before telling you what this decomposition is all about,
440000	449520	on a technical note, just notice that first Q here is the so-called solenoidal matrix. Gamma
449520	458720	is the diffusion matrix just as before. And the I here with the nabla I, this I of X here,
458720	465280	is a negative log of a density. So it's a self-information or surprise we will refer to
465280	474080	it as the surprise throughout the presentation. And the density at play here in this negative
474080	482880	log density is the steady state or nest for non-equilibrium steady state density of the system.
482880	491280	So we assume that there is such nest density that exists, so that if you from a given initial
493200	500080	initial state you let your system evolve, it will reach at some point a unique well-defined
501040	508160	nest density. And second remark before telling you what this decomposition is all about,
508160	517920	note that usually in the papers the divergent terms here and here are put together in a third term
519600	527280	which is sometimes called housekeeping or correction term. But actually if Q and gamma
527280	537040	are not state dependent, these divergent terms vanish anyway and we end up with these the two
537040	544720	remaining terms which can be nicely factorized like that. Also a last thing I want to say is that
545440	552880	if you you consider the solenoidal term, the first term, it is indeed a solenoidal term,
552880	559520	you can indeed write it as the rotational of some potential. I'm saying that because sometimes
559520	569840	people get confused when they see a gradient in both terms. Anyway, what this decomposition is all
569840	584320	about is quite in fact simple. Let's consider this nice 2D single-moded nest density. Okay, so the flow
584320	592880	and more specifically the gradient component of the flow which is here the vertical flow will drive
592880	600880	the system towards its mode while fluctuations kind of push it away. But it's not the only flow,
600880	608320	there is also the solenoidal flow which is here called the horizontal flow which
610000	621440	will make the system kind of converge to its mode with ever-decreasing cycles. And so if you want to
621440	627360	get some more intuitions on this solenoidal flow what we can do is to remove the fluctuations.
628240	635360	So all the entries of gamma, the diffusion matrix go to zero and this means that we would not have
635360	641280	any gradient flow anymore. We end up with only the solenoidal flow and if we do that
643360	649760	the system will just follow an isocontour circulation on the nest density that's the
650320	660000	bottom right panel here where the solenoidal flow kind of drives the system on this circulation here.
660560	670560	So a small remark about this solenoidal flow because it kind of drives the system in this simple
670560	678080	example in either clockwise or anti-clockwise direction in an irreversible fashion, irreversible
678080	686560	in the statistical physics sense. So it breaks detail balance and so on. People sometimes view
686560	693920	this solenoidal flow as underwriting the symmetry breaking ubiquitous in living systems. Anyway,
694880	703120	okay so before using this decomposition of the flow to do some cool stuff I need to introduce
703120	710800	some stuff. So I will have to go through a couple of things of notions one after the other
711440	718160	and afterwards we will put everything together and actually derive the free energy principle.
719040	727200	So the first thing I want to introduce is the notion of sparse coupling. So let's say that
727280	735600	in my state vector x here I have a subset of variables this mu here we refer to as the
735600	745600	internal states and they specify the state of some subsystem called mu. So I mean you get the idea
747360	754400	that we have like an organism, an agent, the bacteria in my schematic and these variables here
754400	763120	literally specifies the internal states of my bacteria and this bacteria is in a given
763840	772400	environment, niche, whatever. So there is this other subsets of variable we refer to as the
772400	779440	external states and which corresponds to the external world, the external states of the
779680	788240	bacteria. And the idea here is that these two subsystems are not connected to each other. So
788240	793840	when I'm saying that two variables are not connected to each other I just mean that
795760	802800	their respective flows do not take the other one state as arguments so they do not influence
802880	810400	each other basically. In fact they are indirectly connected to each other thanks
810400	819280	or through a third subsystem we refer to as the marcov blanket so that these guys here
819280	824880	are called the blanket states and we will see in a minute that it really corresponds to a
824880	833200	marcov blanket in a statistical sense. Okay so we have this architecture, this
833200	839280	path coping architecture here and in fact we can even go a bit further and assume that
839920	847040	within the blanket there are two more systems, the so-called sensory states and the so-called
847040	856800	active states A. So basically the idea here is that the external states eta they influence the
856800	864480	sensory states S and these sensory states S influence the internal states mu but not the
864480	873120	other way around and the internal states mu they influence the active states A which influence
873120	880480	the external states eta but not the other way around. So it's really a path coping architecture
880480	887760	inspired by the so-called action perception loop however you could ask questions like why do the
887760	895360	sensory states influence the external states or why do the active states influence the internal
895360	902320	states etc. So we don't have really time to discuss this I guess you can think of some
903360	911120	qualitative example in biology but I just want to point out that even though this architecture is
911120	918000	quite canonical it's not a definitive feature of the free-nury principle and in fact in the next
918000	924720	time when we will discuss the other formalism we will do a bit of zoology and we will look at
924720	933920	other path coping architecture. Okay so on a technical note just notice that such
934720	940640	path couplings are encoded by zero entries in the Jacobian matrix of the flow.
941520	948000	Anyway so thanks to this path coupling architecture we have this system of four
948560	954880	coupled long-run equations which respectively describes or specifies
956240	963760	the dynamics of the external states eta the sensory and active states s and a and
964480	976880	of the internal states mu. Okay so I want to say here about the Markov-Blanket thing
976880	983520	that under some conditions I'm not going to discuss here so for the people acquainted it
983520	990400	involves having no solenoidal couplings between autonomous and not autonomous states but anyway
990400	998560	I'm not going to go into this let's say under some conditions the external states eta and the
998560	1005280	internal states mu are conditional independent so they are independent when conditioned upon b
1005280	1013280	which makes sense because all the informations kind of transit through b however not that when
1013280	1019440	I'm talking about conditional independences here I'm talking about conditional independences
1019440	1027120	in the stationary density so basically if you fix p and you have this joint
1028080	1036640	uh conditional stationary density here for x i and x j if these two guys are conditional
1036640	1044000	independent it just means that you can write this joint density like that and so that such
1044000	1051440	conditional uh independences are encoded by zero entries in the ACN matrix of surprizo.
1051840	1062240	Okay so now just a bit more of vocabulary before moving on um note that if we
1063440	1069200	put together a and mu so we consider the couple active states and internal states
1070160	1077120	we refer to to these guys are as the autonomous states alpha and the cool thing about the
1077120	1085440	autonomous states a and mu or alpha is that they are conditionally independent of the external
1085440	1093760	states so autonomous and external states are independent when conditioned upon uh sensory
1093760	1103360	states and if you add the sensory state s to the autonomous states so you consider the whole thing
1103360	1110160	the whole marco blanket and the act and the internal states we refer to to these guys as the
1110160	1117600	particular states pi and pi constitutes a particle a particle in a generic sense of course
1117600	1126320	so an organism an agent whatever a bacteria in my schematic okay so here I just want to make a
1126320	1131760	point to make a bit more clear what we are doing what what this this approach is all about
1132000	1141040	so basically here we kind of define what it means for something a bacteria any whatever to exist in
1141040	1149760	the sense that it has its own internal dynamics statistically separated from the the external
1149760	1157360	it does have a marco blanket it does have its own physical integrity so we have no clue of how it
1158000	1166080	maintains indeed it's it's uh it's integrity in the sense that if you're considering uh real systems
1166080	1174560	like like an like an actual bacteria or a human being or whatever it it does survive at a given
1174560	1181440	in a given time scale um right for instance this playing I don't know like active processes
1182000	1188320	contouring dissipation for instance here we don't say anything about how it does survive it just
1188320	1195440	does we do have this path coupling architecture and from there from the starting point we are going
1195440	1205120	to derive the the necessary uh the consequences of such sparse coupling so basically we kind of ask
1205120	1213600	or answer to or try to answer the questions if things exist what must they do and so if you're
1213600	1219760	a bit confused don't worry we're going to go back to this idea later but I just want first to show
1219760	1227280	you this quote here which tells you many theories in the biological sciences are answers to the
1227280	1234720	question what must things do in order to exist the FEP turned this question on its head and
1234720	1242160	asks if things exist what must they do but once again we are going to go back to this idea later
1242160	1251760	but that's kind of the idea of this approach in a nutshell so as I told you I still have a couple
1251760	1259120	of things to present so I will have to go through each of them one after the other and finally we
1259120	1266720	will put everything together and finally derive the free energy principle so the next thing I need
1266720	1278320	to introduce is the notion of synchronization map so very uh very generally speaking I'm not
1278320	1285280	specifically here talking about our random dynamical system if you have a linear map
1286000	1296640	uh g mu here which gives you mu from b and g eta here which gives you eta from b then
1297920	1304160	if g mu here is injected so that basically you can go back to the pre-image from the image
1304720	1313360	you can use the pseudo inverse of g mu so that from mu you go back to b and from b you can go back
1313360	1328640	to you can go to eta so the successive application of the pseudo inverse of g mu and then of g eta
1329680	1337040	is called the synchronization map and it basically allows you to directly go to eta from mu
1338000	1349920	okay so now let's try to uh to use this idea in the context of our system so b here corresponds to
1349920	1357920	the blanket states so if I fix the blanket states I have a corresponding conditional
1357920	1366160	densities for mu and eta I have p of mu given b and p of eta given b and I call and what I
1366240	1375200	I am and their their modes are bold mu and bold eta so in virtue of this synchronization map
1375920	1383520	I can go back to the external mode from the internal mode thanks to once again this
1383520	1391040	synchronization map here and I'm going to give an example in a sec which is going to to make
1391040	1396560	to clarify a bit more what we are doing here but first I just want to say that
1397440	1404080	in this nice paper by Lenz Dacosta about this this this synchronization map
1404800	1414000	basically everything was Gaussian but sometimes I mean if it is not the case a Laplace approximation
1414000	1421200	which which is literally a Gaussian approximation might be necessary to derive a synchronization
1421200	1427760	map of closed form but don't worry we'll go back to this idea of Laplace approximation later just
1427760	1435440	remember that we have this synchronization map here which allows you to go to the external map
1436160	1445360	external mode sorry from the internal mode so for instance if given b given the blanket states
1446480	1456320	the corresponding p of eta given b follows this nice normal distribution where bold
1456640	1467440	bold eta here corresponds to the mode then in virtue of the synchronization map I can view
1467440	1476800	the internal mode mu as parameterizing a density I write it that way q mu which is equal to this
1476800	1484720	nice normal distribution where the mode is just the synchronization map applied to the internal
1484720	1493120	mode to itself and by construction of the synchronization map it is equal to the true
1493120	1502240	external density so you can view the internal mode as parameterizing a distribution over
1502240	1507760	external states basically thanks to the synchronization map that's why what the synchronization map
1507760	1514960	is all about so just a small point because maybe some of you are a bit confused here because we're
1514960	1525360	talking about modes as opposed to actual states so we will talk about that later but indeed I mean
1525360	1532160	if I take the actual internal states at a given time t they are not necessarily equal to their modes
1532240	1538720	just because of fluctuations or whatever so that if I apply the synchronization map on the actual
1539680	1547520	internal states it might not give you the true external mode but anyway we will discuss this
1549040	1554560	a bit more later so that was the notion of synchronization map in a nutshell basically
1555360	1563200	so last thing I want to to introduce before finally putting everything together and actually
1563200	1571520	derive the free energy principle is the notion of variational inference so very simply let's say
1571520	1580000	that you have some latent variables or hidden variable or some latent generative process
1580960	1591520	causing some data s so you have a prior p of eta over the state of these hidden causes of data
1592320	1599600	and you are also equipped with a generative model which just designates this joint distribution
1599600	1608320	here p of eta and s so you can view it as a model of how the latent variables cause the data
1609200	1617600	so the idea here is the following you sample some data s and you want to compute the posterior
1617600	1624560	distribution p of eta given s so in a way you want to refine your belief about the
1626000	1634000	the hidden cause of data thanks to a new sample data so it's very simple you in principle because
1634000	1643920	you just have to apply base theorem right however in practical settings the denominator here p of s
1644560	1655040	so the marginal density over sensory data usually requires a monstrous marginalization so it's just
1655040	1666480	not tractable so we can't just apply a base theorem so we need we need a method uh which
1666480	1676080	given some variational sorry which given some some variational distribution q also called recognition
1676080	1685920	density uh gives us uh i mean we want a method that makes it as close as possible if not equal
1686480	1693760	to the true distribution we want ultimately to compute namely p of eta given s and these two
1693760	1702480	density so q our variational distribution and the true distribution p of eta given s are equal or
1702880	1712960	more or less equal if their divergence cal divergence here is zero because this quantity here the cal
1712960	1722000	divergence basically measure the difference between two distributions so that's what i wrote here on
1722000	1729840	the top of the slides finding an accurate distribution q in the sense of finding a q as close as possible
1729840	1739200	if not equal to the true target density is equal to minimize to minimizing these divergence
1739840	1746960	however these divergence i mean there is the target density appearing here we can't
1747520	1753440	do anything directly with it we can't compute it or whatever we need a proxy for this target
1753440	1761200	divergence and there in the proxy called variational free energy f in green in my in my uh slide here
1761760	1771840	so f is is equal to this divergence here between q and the generative model and the idea here is
1771840	1779120	that you can decompose these divergence into the true the target sorry into the target divergence
1779840	1786000	in red here plus something so it is indeed a proxy for the target divergence
1787520	1796240	and note that interestingly enough the second term here is the surprise over sensory data or
1796240	1804480	negative log p of s so that f is it can be viewed as an upper bound or lower bound depending on how
1804480	1813440	you define it uh unsurprise okay so what i just said here is that minimizing the target
1814160	1823520	divergence just means minimizing f so that's basically what variational inference uh is all
1823520	1832720	about and note that usually algorithms require q to be Gaussian or require a mean field approximation
1832720	1841440	or whatever and if q is required to be Gaussian even though the target density is not Gaussian
1841440	1848320	we would end up with the best Gaussian approximation of the target density basically
1848320	1855840	and in practice it would mean working with a so-called Laplace encoded free energy
1855920	1866000	okay so before moving on i just want to say that uh this quantity the variational free energy
1866800	1873920	is in itself a quite rich and interesting quantity so you can decompose it in many ways
1873920	1881200	and each decompose uh provide interesting uh interpretations for instance if you look at
1881200	1887760	the second line here you can see that minimizing free free energy means
1890480	1896880	maximizing this accuracy term here you basically want to explain the data i would say but at the
1896880	1904960	same time you you want q to differ the least possible from a prior distribution so that's
1904960	1913760	that's um an interesting quantity anyway now let's finally go back to our sparsely coupled
1913760	1921760	random dynamica system and use everything we we talked about and finally let's uh derive the
1921760	1930640	free energy principle so here is our system and we have this four langen equations and the first
1930640	1936560	thing to do is just to apply the decomposition we talked about in the beginning so basically
1937920	1945360	the flows of each of them can be written like that so i just directly applied the Helmholtz
1945360	1956320	decomposition we talked about in the beginning okay so now um let's try to understand uh how
1956320	1965040	it works let's talk about the dynamics of the system let's say that uh so there is a momentary
1965040	1972720	instantiated uh uh sensory state and let's fix let's say that the sensory states are fixed
1972720	1980080	and there is a corresponding autonomous density uh autonomous mode toward which the autonomous
1980080	1988240	states are going to converge and stay in the vicinity of the of their mode in the closed
1988240	1998080	vicinity if uh fluctuations are not too large okay but in fact sensory states with time changes
1999600	2008960	so that the the mode of the autonomous state move as well and in fact it it moves on its
2008960	2013920	corresponding autonomous manifold so i'm not going to go into the details but just
2013920	2020960	have in mind that the autonomous mode moves on a so-called autonomous manifold which can
2020960	2026160	be viewed as a statistical manifold and which can also be viewed as a so-called center or
2026160	2037280	center manifold so if i kind of rephrase what i am saying here is that the flow of the of the
2037280	2047440	autonomous states can be decomposed into uh off manifold flow and uh on manifold flow which
2047440	2054960	corresponds to the path of the mode itself on the manifold okay so just to be a bit more clear
2055520	2064480	let's say in my bottom right uh illustration diagram here the autonomous states are here
2065040	2076160	and i'm i'm interested in the the off manifold flow so basically i have the this component here
2076160	2081920	which corresponds to the gradient flow towards the manifold towards the mode basically here it's
2081920	2089120	pretty much like what we discussed in the beginning and at the same time there is here this orthogonal
2089760	2098880	component which corresponds to the solenoidal flow so that's basically the way the autonomous state
2098880	2107440	are going to reach their mode here it can be viewed as this ever decreasing cycle towards
2107440	2116560	the the manifold on which the autonomous mode move okay so that's a bit dense i guess so
2117200	2123120	i recommend to check the paper the free energy principle made simpler but not too simple which
2123120	2134800	kind of discuss all this this idea about center manifolds and stuff so here the interesting point
2134800	2144560	is that if you assume a separation of timescale between the fast flow of the manifold as opposed
2144560	2153040	to the slow flow on the manifold basically the autonomous state always are always in the vicinity
2153040	2158480	of their modes and if you want to characterize the overall dynamics of the autonomous states
2158480	2167040	you can focus on the autonomous mode on the path of the mode and in the next slides we will indeed
2167040	2177200	focus on the autonomous mode and and by definition as we already discussed the autonomous mode
2178000	2183520	the autonomous mode is or corresponds to the autonomous states which minimize
2185760	2193520	surprise here in the last two launch variations because the autonomous mode corresponds to the
2193520	2200320	least surprise of autonomous states before moving on i just want to say something
2201360	2206000	we can maybe discuss afterwards because i'm not sure to fully understand but basically
2207280	2214480	if i'm here in my bottom right schematic and so i have this gradient flow towards the manifold and
2214560	2224720	this solenoidal flow parallel to the manifold and if i remove fluctuations so all the corresponding
2224720	2231600	entries in the diffusion matrix go to zero as we saw in the beginning it means that there is no
2233120	2237920	gradient component anymore and what the system will be doing is kind of
2238560	2248240	um orbiting or oscillating around a point which is which moves on the manifold so that's
2248240	2256400	interesting and i guess that if we do the exact same reasoning but starting already on the mode
2256400	2265920	then the world flow reduces to the unmanifold flow and i guess that in that case the autonomous
2265920	2272320	states follow and in fact coincide with their mode but anyway maybe we we can discuss about that
2272320	2282240	afterwards so okay so let's use the various things we talked about and especially the notion of
2282240	2290480	synchronization map we as we said the internal mode parametrize indeed um a distribution over
2290480	2298880	the external state so mu here parametrize a distribution which by construction coincides
2298880	2306240	with the true distribution p of eta given b and in fact thanks to the conditional independence
2306240	2314800	between external states and autonomous states you can just drop the condition upon a and you
2314800	2325600	just have q mu equal p of eta given f and equivalently you can you can write it p of eta given pi
2326400	2335840	and the idea here is that you can view q mu as a variational distribution if you want you can
2336400	2345680	write its associated variational free energy so you have this this formula here the free energy
2345680	2353760	and because q mu is already already coincide with the true posterior distribution if you will
2354400	2364080	the first term here goes to zero and so that f here reduces if you will to
2365440	2371760	the surprise over particular states and surprise over particular states they appear here in the
2371760	2378240	equations of the autonomous states so we can do this identification and we realize that the
2378240	2387600	autonomous uh mode not only minimize um not only minimize surprise though but free energy in general
2388400	2396640	and the way uh mu the internal states will be updated when the sensory states will change
2396640	2405280	will always be so that this divergence here is zero so that mu is always always keeps track or
2405280	2411840	synchronized with or in fact interfere the external states so that you can interpret that
2412640	2419440	under a generative model which is here p the next entity the internal states can be viewed as
2419440	2429520	performing inference over external states and so in fact it's not only this divergence which is
2429520	2438640	minimized but it's also surprised and it's not only um only the internal states which uh minimize
2438640	2446320	free energy but also the active states so let me give an example let's say that the actual
2447360	2454400	instantiated sensory states are likely sensory states or unsurprising sensory states and by
2454400	2462240	definition in general the instantiated sensory states will be likely sensory states so mu will
2462240	2467680	will the corresponding mu will be so that this divergence will be zero as we just discussed
2468400	2476320	and at the same times the corresponding active mode will be so you can see in composition with the
2476320	2485920	third term here i of a given s and mu a this active mode will just be the one the most consistent
2485920	2492480	with this in intensiated sensory states and in fact you can view it the other way around and say that
2493440	2502320	the active mode is the mode which yield unsurprising sensory states so that the particle can be viewed
2503040	2512240	viewed as uh actively sampling unsurprising or likely sensory states or equivalently you can
2512240	2519360	say that the particle kind of um accumulate evidence for its own generative model and i'm going to
2519360	2526320	say something about the generative model in a sec but i just want first to so yeah this sentence
2526320	2534400	here just sum up what we said mu is updated so that q mu is always the the best distribution of
2534400	2542000	our external states and we refer to this as perceptual inference and the idea to in addition
2542800	2549200	trying to minimize surprise for action is called active inference so a brief note
2549840	2557440	uh we said earlier that in order to have a synchronization map of closed form it could
2557440	2566640	be necessary to work under a Laplace approximation so that in that case q mu is always is is just
2566640	2574320	the best Gaussian for instance of the target density so that the divergence here would not
2574320	2583520	be zero but it still would be minimized so that the identification here between the two gradients
2584240	2591840	still hold and nothing change um nothing changes with respect to our discussion so here i just want
2591840	2601200	to say something about this what we are doing here basically we assume that we have our agents
2601200	2607680	or organisms that survives indeed exist or persist in a given environment let's say at a
2607680	2616640	given time scale and we end up with the fact that our particle must be equipped with or must be
2616640	2625440	must embody a generative model which may or may not exactly coincide with the true generative process
2626160	2633840	and which encodes the causal structure of the world under which it tries to perform inference
2633840	2641840	and to minimize surprise to perform perceptual and active inference but the interesting thing
2641840	2648400	as well is that and i think that's something fundamental that people tend to misunderstood
2648400	2658160	i guess maybe i'm not sure is that the generative model also encodes the preferences of the system
2658160	2666080	and let me explain why if i tell you that an organism manages to survive to exist to persist
2666080	2675840	etc and so it means that such an organism manages to stay in its homeostatic life compatible
2676800	2682080	states you would be of course it almost sounds like a tautology survive equal
2684240	2690080	staying in it in in its homeostatic states that obvious right and that's exactly what we are doing
2690080	2698880	here we assume existence survival so that the likely state in which the particle will will persist
2699840	2708080	are preferred states per se so that for instance if i'm considering the prior of my generative model
2708080	2719520	over sensory inputs p of s sensory outcomes s associated with high p of s so likely or
2719520	2727760	unsurprising sensory states are preferred sensory states states hence when i'm saying that the active
2727760	2735520	states try to sample unsurprising sensory states it means trying to sample preferred sensory states
2736400	2746240	and so basically the particle appears to kind of actively accumulate evidence
2749040	2756240	for its own existence in a way it kind of sample life to sample it kind of sample life compatible
2756240	2762800	data if you will and that's exactly the definition of self-evident thing so i think
2762800	2769200	we touch here something fundamental about agency is that agents are self-evident thing
2769920	2780080	creatures in that sense okay anyway so basically i think that's the most interesting things of
2780080	2786480	the free energy principle we start from existence and we end up that such a particle which is
2786480	2794640	coupled to the world in that way must embody a generative model which encodes the causal structure
2794640	2802000	of the world and which encodes the its preferences in terms of what is life compatible if you will
2802240	2810400	okay so just to sum up what we did here this idea that free energy is minimized
2811680	2819360	you can write it that way and this is in a way a variational principle for self organization
2819360	2826880	that's a free energy principle so here i just wrote what we just discussed the agent keeps
2826880	2831680	tracks and acts on its external milieu through perceptual and active inference
2834080	2841280	and note that interestingly enough you can write such a principle as a principle of
2841280	2848240	least or stationary action where the Lagrangian which is constantly minimized along the path
2848800	2859040	is variational free energy so here are some concluding remarks i'm not going to throw all
2859040	2865120	of them but the first one is basically what we just discussed this idea that the generative model
2866720	2874400	encodes preferences if an agent maintains existence its likely states are its preferred ones per se
2875360	2883680	hence the notion of stealthily dancing and i just also want to point out that this new approach
2885520	2894960	or chapter of physics let's say consisting in describing physical systems as encoding probabilistic
2894960	2904160	beliefs is called Bayesian mechanics okay so having said that thank you very much and especially
2904400	2912880	thanks to all these guys who who helped me so much especially Len and yeah thank you for
2913840	2915360	for your your attention
2925360	2928240	I'm back thank you Richard
2928880	2939680	okay well while we're settling back in and anyone is asking questions in a live stream
2940880	2949360	what is your phd research and if this is your side project what is your main project that this
2949360	2957040	kind of relates to yes so well in fact um i kind of read about the free energy principle
2957760	2968480	in my free time whenever i i had some time and what i'm doing in my phd is so we have
2969680	2976880	a couple of projects the first project we did was really modeling bacterial evolution through
2976880	2983440	so basically we model bacterial evolution as a bias random work on genotype space with
2984320	2990960	successive mutations and and and successful fixations so that's what we are doing it's
2990960	3002240	not related to the fp at all and the second thing we have been doing is modeling so basically we
3002240	3010160	had a system where you have bacteria which can kill each other thanks to a system which is called
3010160	3017600	the t6 secretion system they kind of have needles with which they can go through the membrane of
3017600	3024480	other bacteria and and liberate toxins and they can also bind to each other so there is like a
3024480	3030960	prepredator kind of dynamics and we did like a lattice gas modeling of such systems so basically
3030960	3038240	that's what i'm doing in my phd which is not related to to Bayesian mechanics but i would like to
3038960	3043440	to transition to to the field afterwards so yeah i will see how it it goes
3045360	3048560	i remember when i thought my phd wasn't related to active inference
3051440	3061600	okay cool well the work built to an amazing crescendo that in its simplicity
3062560	3070880	even though you highlighted it's easy to fly by which is the coincidence of the preferences
3070880	3077680	and the expectations so could you maybe give a little context how else has that nexus
3078480	3087600	of preference and expectation been approached and is the fvp only and simply and always that
3087680	3093440	coincidence is that coincidence upstream or downstream of some other commitment that we make
3093440	3101600	like what are the commitments that we really make and is that um alignment the commitment or a
3101600	3112320	resulting commitment yeah so um so first of all i think the notion of um self evidencing
3112400	3118400	may be a bit refined with the next formulation but anyway it's i think that's a crucial point
3119120	3126240	about the fvp and usually it's kind of confusing because when you're reading the papers and
3126800	3134960	people are starting to write that the system um sample evidence for its own existence you're like
3134960	3141600	what i mean i'm not sure to understand what's going on here um but in fact yeah it's i i think
3142880	3153680	the way i i um introduced it this idea that by definition um a living thing is a thing which
3154960	3165360	which managed to sample live compatible uh sensory data is really what allows this
3165680	3175680	um align alignment story between the that the idea that between surprise and preferences
3175680	3184640	basically and this idea that actively sampling um unsurprising data is in fact and it's not
3184640	3192240	like a tricky wording it's in in a way that's really what's happening it is sampling uh live
3192240	3201840	compatible or preferred in that sense data hence the notion of self evidencing um but um
3202800	3211200	yeah i think the whole idea here is that we start from existence we start from the uh
3211920	3217920	from this past coupling architecture where the particle uh managed to maintain its physical
3217920	3225920	integrity managed to display a mark of blanket which uh allows the the agent to have its nice
3225920	3231120	it's um its own internal dynamics separated from the external so somehow it managed to
3231120	3240960	counter dissipation or whatever and so from there likely states are states consistent with the fact
3240960	3248480	that it is existing existing indeed so i think that's basically the the the idea but yeah in the
3248480	3254640	beginning this kind of um line of reasoning can be a bit uh confusing but in fact i think that's
3255680	3264160	very much what the FEP is all about and actually last remark um in a machine learning street talk
3264160	3273200	interview of Maxwell Ramstead he it was titled the FEP as um a physics of survival if i remember
3273200	3279600	well and i think that's that's very very much what what it is all about in a way
3282160	3289200	awesome how would you relate what you just described to reward or to reinforcement type
3289200	3298480	learning schemes yeah so i i mean i'm not an expert at all i could not uh make the bridge here
3299200	3307440	but i know that um Lance Dacosta made several uh works and interviews about the the subject
3307440	3314160	and actually i think there is a very new paper called active inference as a model of agency
3314160	3321120	you just shared actually today um so i yeah i recommend the viewers to to check them out
3321120	3327680	and as far as i know but here i'm just i'm just uh seeing what i heard is that um any
3327680	3335440	reinforcement learning algorithms can be um can be framed in terms of active inference
3336160	3346160	so i think active inference is a very um uh fundamental scheme but yeah yeah it's all good
3346160	3352800	like the reason i ask just with how you presented it is what kind of observations do we want to
3352800	3358160	sample that could be the sensory embodied interface between the agent and the environment
3358160	3364640	or you can take a more cognitivist approach and sample internal observations but those are just
3364720	3370560	external some other internal so what do we want to really sample well if you're even in a position
3370560	3376240	where you're talking about sampling from like a utility or a reward distribution you've already
3376240	3387280	specified a distribution why not just specify the existence distribution the actual attractors
3387280	3400320	and stationaries of the measurements and then um it's simpler because there's no proposal of a
3400320	3407360	secondary intermediate between the temperature and how good different temperatures are by going
3407360	3412560	and just saying it's not rewarding to be at 37 homeostatic temperature it's just expected and
3412560	3420800	likely and the ball rims downhill it's actually a lot simpler and more general yeah and i i think that
3421920	3432080	um it's way more simpler to i mean the idea here is that the agent has a kind of world model which
3432080	3439920	as you said uh specified what are the the expectation uh with regards to just existing
3440000	3445280	in a way and as opposed to designing explicitly
3449760	3450880	objective functions
3454400	3461200	with the which incorporates the notions of utility and so on so yeah i'm very much agree
3461520	3472880	um earlier when we were looking at the flows and we had the breakdown of a flow um could you maybe just
3475360	3485200	um what animal are you thinking about or what scenario can help us understand like what's the
3485200	3492160	solid black line what's the small red line what's the spiral what's like a physiological setting
3492160	3496800	that we could associate here to help us understand that kind of complex movement
3498640	3507520	yeah so uh generally speaking the first thing i could say is that this notion of solenoidal flow
3507520	3514320	so it's like in the schematic schematic in the first slide where you have you had this
3514320	3521200	either contour circulation on the next entity or here the the the component of the flow which
3521200	3533200	creates this sort of spiral here it can so that um it's this sort of um oscillations are i think
3534160	3541600	the sort of oscillations or cycles that are ubiquitous in living systems um i mean i i'm not
3542240	3548880	a biologist but you can uh or not really a biologist but you can think of the circadian
3548880	3556960	cycle or or anything in any sort of systems there is this sort of of of um attractor where
3557120	3566480	you're circulating along and so here specifically to this to this um a schematic here i think the
3566480	3577440	idea is that um um you have so you have you basically let's say that uh for a given sensory
3577440	3585120	states you have a corresponding autonomous mode and the when the sensory states change the
3585200	3593120	autonomous mode mode changes as well and in fact move on its so-called manifold so basically i guess
3593120	3603440	here you have the mode moving on its manifold and now if we take the perspective of this
3604160	3611040	autonomous states here we converge to the the manifold to the mode
3611360	3621280	um and because of the solenoidal uh component of this flow the way we will um reach it is
3621920	3632240	with this kind of uh ever-decreasing cycles um so here's the idea and i and um i really recommend
3632240	3640880	here the free energy principle simple paper you have the the flow on the manifold it's just the
3640880	3651280	path of the mode itself let's say and you have the flow of the manifold was gradient component
3651280	3662240	is the flow towards the manifold in fact um so basically so that's basically how autonomous states
3662240	3671120	kind of um reacts to to to sensory data which change the autonomous mode and i think the whole
3671920	3680240	an important idea here is to assume that the flow of the manifold is fast as opposed to the flow
3680960	3687040	on the manifold so that's basically the sensory states are always uh in the vicinity of their
3687040	3698240	mode and move with their mode and um sorry and um and um and yeah i think that's pretty much the the
3698240	3708880	idea here okay so let's just say that the black line is um our homeostatic body existence life
3708960	3718320	compatible ph oxygen blood sugar and yeah we are that light blue dot that's off that manifold
3719680	3726880	of course if we were far enough off to be dead it would be a moot question but we're off but
3726880	3735600	within a life um scaffolding a compatible zone and now as time pushes us down into the right
3736240	3746800	um there are different slices that we can trace um we could take the shortest path the gradient
3746800	3753040	flow directly towards the manifold so as that plays out through time it would look like a linear line
3753920	3761840	converging to the thick black line or pure solenoidal flow would just stay equally far away
3761840	3767040	from the thick black line and continue to spiral so that would look like a cork screw uh through
3767040	3775040	time and then here when you have the combined character of the linearized convergence towards
3775040	3784080	the manifold and the cork screw out through time we get this kind of winding spiral so
3784400	3797200	it reflects on me that the gradient flow is pragmatic value in that it aligns future observations
3797200	3806880	with preferences and the solenoidal flow has an almost epistemic character in that it circulates
3806880	3816640	amongst a set of equally valid outcomes yet here we're not looking at the pragmatic plus
3816640	3825840	epistemic decomposition of the expected free energy policy selection strategy like equation 2.6
3825840	3834080	in the 2022 textbook so is that just a concordance or where do you see some of those topics connecting
3837600	3846480	um I am not sure maybe uh but having said that on this on the the meaning of the solenoidal part
3846480	3854720	here I know that on the on the uh I don't remember if it's in the free energy principle
3854720	3863680	simpler paper or or someone else but there is an analogy I mean they discuss the the meaning
3863680	3873920	and the role of the solenoidal flow where they say that it it it kind of help um it kind of helps
3873920	3880800	mixing system the systems and you can view and they discuss the metaphor with where you want to
3880800	3890080	dilute your um your um your coffee for instance and you're going to have this sort of uh motion
3890080	3899040	in order to reach the the as fast as possible the the steady state where everything is diluted but I
3900080	3906320	I am I'm not sure I didn't think enough myself to provide any sort of interesting insight
3907440	3915200	oh good just to have composed it it's very insightful um well you made choices assembling
3915200	3924080	things like what do you feel like would have been background maybe a course or a skill what
3924080	3928960	background do you feel like you kind of conditioned upon that somebody might want to check out
3929520	3935760	and then what do you feel like you would have wanted to include in the state-based formalism
3936720	3949760	um because to to bring it into a under one hour timing is very concise so where do you feel like
3950400	3957600	somebody could fill in some background to pick up with you at the beginning and then what else
3957600	3967120	do you think would make a fuller presentation I think I mean there are a few aspects and details
3967120	3978000	I didn't really uh like fully discuss um well first of all all these um things which
3978560	3983520	here which involves like center theory a center manifold theory and stuff like that
3984240	3991520	uh we we kind of played uh qualitatively with it we didn't really go into that
3992400	4004080	and also if we want to be like full really full formally speaking um let's see maybe um
4004960	4014800	um uh well there are a couple of things where we that we kind of accept without really checking
4014800	4020240	all the assumptions and all the derivation derivation and I'm especially thinking of the
4021040	4027200	of the Helmholtz Hau decomposition of F because of course you need a steady state
4027200	4035520	net density to exist to in order to have such a decomposition so here I think it's it's there is
4036960	4045280	a lot of stuff to to check and I mean there is a nice I think it's in the appendix B of the
4045280	4053840	Bayesian mechanics of stationary process paper by Lenz where it derives the Helmholtz decomposition
4054080	4064560	uh so yeah there are quite a few things we kind of state we vote um derive so it can
4065200	4071840	if people are interested in in going further I think that's kind of interesting formal uh directions
4072320	4084720	um and um um yeah cool I think it'll be a really fun collaborative project to
4085760	4094560	axiomatize and formalize and modularize using the actin fontology and understand a lot of these um
4095360	4099920	relationships and then the other piece that that made me think about is like
4100720	4107520	what work is any of this math doing at all just kind of like the the ultimate existential question
4107520	4117120	here um and when we condition upon existence we've kind of like off sourced a lot of cognition
4117680	4125040	we don't need to make the jump or the walk or the miracle from axiom to embodied existence or to
4125040	4133680	even measured hypothetical existence so that is left unaddressed the margin was not big enough
4133680	4140880	but it wasn't even addressed and maybe there are even advantages to leaving the um
4141440	4145040	um what happens before the conditioning
4147680	4151680	you don't want to take it with you after you condition upon it that's the whole mark off
4151680	4157040	like a concept like if you're like well I'm conditioning on five years ago in the present
4157040	4161600	but also I'm carrying five years with me today well then it's like well then it wasn't conditioned
4161600	4173040	upon so to really condition upon measurements is an extremely radically simplifying maneuver
4174160	4180160	that may change the scope or the applicability of the framework
4182000	4187440	relative to a conception in which what the free energy principle does is describe how things come
4187440	4198000	to be however yeah this rather conditioning upon it opens up that discussion and more circumscribes
4198720	4206960	this very analytically tractable setting of the agent and the environment across a conditional
4206960	4217040	interface yeah by the way about about the conditional thing there is now the notion of
4217120	4224240	you know weak mark of blankets that Dalton introduced which kind of lose the approach let's say
4224960	4236400	and because indeed there is a question on I mean does it apart from the formal setting we have here
4236400	4245520	can we really apply it to real systems and stuff like that and also I think it's the physics of
4245520	4255760	survival in itself at a given survive at a given time scale there is at if I have at a given time
4255760	4261840	scale we survive indeed in the sense that there is indeed this partition or conditional independence
4261840	4268240	between the internal and external here is the physics you have to comply with but we didn't
4268240	4275120	tell you tells you how was the mark of blanket rise or whatever it's it's it's it's just not what it
4275600	4287520	is designed to to explain but I think generally speaking it's it's really informative because
4287520	4294960	for instance if you are considering the I mean the sort of approach in general I mean for instance
4294960	4302720	if you consider the pendulum effect where you put pendulum oscillating on the table and they are
4302720	4309040	going to synchronize synchronize with each other and I think that Kuiha Isomura did a paper about
4309040	4318160	that recently in order to understand what is going on and why the pendulum synchronized at some point
4318160	4325600	you just have to recycle all this line of reasoning with the synchronization map that's very what is
4325600	4331600	at play and what explains why the pendulum synchronized when they are both on the same table
4332160	4341040	so I think it really it is really informative to in order to understand what is going on when we
4341040	4349760	are talking about synchronization phenomena across sparsely coupled systems and also it gives you
4349840	4360400	I guess the sort of recipe to understand what it what it what it takes to be an agent if you want
4360960	4372960	to design your an intelligence system and but yeah the question of how much useful it is
4373920	4381680	beyond the fact that it's just some nice formal framework it's it's an interesting
4382400	4391200	interesting discussion yeah and I just two things first I would like to go back to your
4391200	4399520	previous question about what sort of things could be could be discussed further I think
4399520	4408160	an interesting point we didn't really discuss fully is the notion of synchronization map
4408720	4419280	because we didn't necessarily discuss the the hypothesis and stuff about the synchronization
4419280	4428080	map and I in fact I think there is much things that can be said for instance because we assume
4428080	4437440	injectivity thanks to the rank nullity theorem it's kind of constrain the dimension of the
4437440	4445200	internal manifold here with respect to the blanket manifold here and it kinds of constrain
4445200	4450800	in order to have injectivity thanks to the rank nullity theorem and so it kind of constrain the
4451680	4457840	the in order to say it in a qualitative fashion it kind of constrain the the complexity or
4457840	4466640	richness of the internal states which speaks nicely to other frameworks like
4470240	4477360	like HB's laws of requisite variability where you want the regulator system to be as
4478320	4485360	as sophisticated or as rich to the regulated systems and here you need the internal states to
4486160	4494080	be enough complex to or to constitute the sufficient statistics let's say to parametrize
4494080	4503440	to be able to parametrize the density indeed and this and this richness let's say is constrained by
4504080	4511760	the the cardinality of your sensory channels if you will because basically you need the internal
4512640	4520480	manifold to be to have the same dimension than the blanket manifold or the sensory manifold to be
4520480	4529200	to have the same dimensions than the autonomous manifold so I I mean I think there is many things
4529200	4538560	to discuss about this this aspect here and the last thing I would like to say about your
4539840	4546160	about your last question about the applicability of the framework and how much it's useful
4546160	4554400	as opposed to be a simple elegant formal framework I think so you know there is this
4554960	4564000	these papers about about like the Markov-Blanquet trick and stuff like that
4565520	4571920	about how much difficulties like to identify what states corresponds to the Markov-Blanquet or whatever
4572880	4584480	and I'm personally I'm not really convinced by this these critiques because to me it's like
4584480	4591280	to me it's like saying to Newton yeah I mean it's I'm not sure that I can do anything with your
4591280	4600160	framework it's it's complicated if not impossible to model systems with clearly identified and
4600160	4607840	separated rows and masses let's say okay fine but we are talking about Newton mechanics here so
4607840	4613280	I mean I think it's the same here it's if you have a sparsic coupled random domain because
4613280	4618720	systems that's the sort of behavior it will display it tells you fundamental things about
4618720	4625840	the nature of living systems and the idea that when it comes to a specific system it can be
4625840	4629600	quite tricky to to model it that's another question
4632720	4638720	and indeed when it comes to the art of modeling complex systems it's it's it's interesting and
4638720	4646400	and we can discuss about how much complicated it can be to apply the framework yeah awesome I love
4646400	4654960	that it's like the art of the science and the art of the modeling and the and the craft especially
4654960	4663520	in the kind of early hand-built largely custom stage like one thing I even wondered looking
4663520	4671680	through these slides what fraction of these representations and formalisms exist only
4672240	4678800	analytically and do or is there a code representation of this exact scenario
4678800	4687200	or you know are some of these areas equations that don't have
4689760	4693840	code realizations they're just pure existing equations
4696000	4705920	so I mean I think more or less everything here can be can be simulated even this synchronization
4705920	4715280	thing here you can perform simulations where you can really literally see within the simulations
4715280	4725760	the synchronization and I mean the the the whole thing here can be you can simulate such
4725760	4733520	sparsic coupled random dynamic systems and and kind of interprets the dynamics indeed as
4734240	4736880	the way we we frame we frame it
4739760	4748480	but but yeah that's also an interesting aspect it could be cool like in the github repo
4749200	4755520	in the journal for this transcript or something like that to to curate together
4755520	4762160	the simulations that demonstrate or a minimal specification for it
4764240	4770560	you know because it's it's actually there is a great yeah and actually there is a
4771760	4778240	I mean I think it's in the in in length paper about synchronization map the Bayesian mechanics
4778240	4787280	of stationary process processes paper there there are some simulations where he shows that
4789120	4793840	I mean he shows the the synchronization map at play and it shows that
4794640	4802240	basically you can't go back to I mean if the the the map between the blanket states to the
4802240	4810720	internet states is not injective uh and you apply the synchronization map to the actual
4810720	4817520	sensory uh to the actual internet states it gives you like some not relevant things and
4817520	4822640	there are some nice plots from simulations so that's definitely a paper to to check out
4822640	4835040	so where do we land and then how do we leap exercise relax to prepare for part two
4836640	4844960	yeah so I think here's the the world point was I mean the this world formulation is in a way
4844960	4854400	about the momentary the short day the short term and the momentary response to autonomous states to
4854400	4866080	sensory stimuli let's say if there is this uh this um I mean the the kind of instantiated active
4866160	4875200	states are so that it comes whatever but in the next uh video where we will look at the path
4875200	4882720	based formulation of the framework the world idea would be to ask what about path and what about
4883360	4894480	future path and what about the long term behavior uh and what about planning what about higher order
4894480	4904960	cognitive abilities um and we we will kind of extend the scope of what we are doing in in in
4904960	4915520	that sense um but um yeah I mean I think from a formal point of view uh here I kind of introduced
4915520	4921200	many things variational variational inference synchronization map etc one after the other
4921200	4926560	before actually deriving the free energy principle next time I think we will it will
4926560	4935520	be more straightforward but the the main concepts to to which will be at the core of the of the
4935520	4941840	framework and which can be confusing if it's the first time you you look at it is the notion of
4943280	4950480	of generalized coordinates of motion when you relax the white noise assumption and that's
4950480	4954960	something that can be confusing especially for the physicists because when you're starting
4954960	4960960	saying yeah the generalized lagrangian he plays a role of an action or whatever they are like
4960960	4966800	no but lagrangian is not an action what are you talking about etc but when you get acquainted with
4967520	4974160	the the world construction is very elegant but that definitely something people can
4974160	4982800	started look at before prior to the the live stream yeah awesome yeah well it was excellent
4982800	4991120	you you brought a lot together and a lot of trails leading off this trail and the citations and
4991120	4998800	previous um papers that that also brought things together lance's work and others
4999440	5006000	and it's going to be awesome to see part two so thank you Richard yeah thank you very much
5006000	5012000	Daniel thank you all right see ya bye bye
5028800	5030080	you
