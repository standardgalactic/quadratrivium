1
00:00:00,000 --> 00:00:15,760
Alright, hello and welcome. It's May 24th, 2024. We're in ACTIMF livestream number 57.0,

2
00:00:15,760 --> 00:00:20,840
doing background and context video for the active data selection and information seeking

3
00:00:20,840 --> 00:00:26,720
paper and series. So welcome to the ACTIMF Institute. We're a participatory online institute

4
00:00:26,720 --> 00:00:31,360
that is communicating, learning and practicing applied active inference. This is a recorded

5
00:00:31,360 --> 00:00:36,000
and archived livestream. Please provide feedback so we can improve our work. All backgrounds

6
00:00:36,000 --> 00:00:40,720
perspectives are welcome. And we'll follow video etiquette for live streams. Head over

7
00:00:40,720 --> 00:00:47,760
to active inference.org to learn more about any of the projects, including the live streams.

8
00:00:47,760 --> 00:00:56,880
Today, we're going to do together a background first pass on a very interesting paper from

9
00:00:56,880 --> 00:01:01,680
Thomas Parr, Carl Friston and Peter Seidman, active data selection and information seeking

10
00:01:01,680 --> 00:01:09,760
from 2024. In this video, we're going to introduce ourselves, talk about big questions, go through

11
00:01:09,760 --> 00:01:15,120
the keywords of the paper, then most of the sections, section by section. And as always,

12
00:01:15,120 --> 00:01:19,840
with the dot zero, it's just like a first pass. And we'll look forward to speaking with

13
00:01:19,840 --> 00:01:26,160
hopefully some of the authors in the coming weeks, and also looking what people ask about. So

14
00:01:28,000 --> 00:01:34,080
Christopher, let us introduce ourselves and go from there. Thanks a lot also for helping in

15
00:01:34,080 --> 00:01:41,120
the dot zero preparation. Happily. Yeah, so I'm Christopher Bennett. I'm a bioinformatics

16
00:01:41,120 --> 00:01:49,760
scientist. I do a lot of data mangling data analysis and that sort of thing. This paper was

17
00:01:49,760 --> 00:01:56,000
of great interest to me as we kind of go into this more data driven era in making sure that with

18
00:01:56,000 --> 00:02:01,120
such large data sets that we have, making sure that we can actually select relevant data for any of

19
00:02:01,120 --> 00:02:06,800
our applications going forward, be it machine learning or whatever we're trying to do.

20
00:02:11,440 --> 00:02:17,280
And I'm Daniel. I'm a researcher in California and also was drawn to this on one hand on the

21
00:02:17,280 --> 00:02:24,880
applied side, the idea of more efficient and effective data sampling. And then on the more

22
00:02:25,520 --> 00:02:29,440
theory side, the connection with epistemic value information gain.

23
00:02:30,800 --> 00:02:36,000
So here are some of the big questions. Why don't you add some detail to this?

24
00:02:36,960 --> 00:02:42,000
Absolutely. So there's five major big questions that I had after reading this.

25
00:02:43,520 --> 00:02:45,600
For the most part, it boils down to

26
00:02:48,160 --> 00:02:53,280
doing our sampling. You can do sampling over time and sampling of different data sets in different

27
00:02:53,280 --> 00:03:02,080
ways. Is there a way that we can intelligently select the data that we're going for the time

28
00:03:03,040 --> 00:03:09,120
the time that we're trying to select? Is there a way that we can understand how the

29
00:03:09,120 --> 00:03:17,760
time aspect helps sample through time instead of just doing a dynamic or more dynamic instead of

30
00:03:17,760 --> 00:03:24,960
doing a static like we're going to do time zero, time seven, time 14, time 21. Can we say, hey,

31
00:03:24,960 --> 00:03:30,240
the differences between time one and time two are very 10.1, time point two are very interesting.

32
00:03:30,240 --> 00:03:36,400
It's a lot of data in there alone. So we'll sample one and two and then maybe sample 10. Is

33
00:03:36,400 --> 00:03:41,280
there a way that we can intelligently select the time points that we are sampling from

34
00:03:42,080 --> 00:03:48,400
when we get into the time series aspect? The Piper mentioned a number of different

35
00:03:49,520 --> 00:03:55,200
time dimension models that you can add to the four model that they're utilizing,

36
00:03:55,840 --> 00:04:00,880
one of which was a hidden Markov model, another was they mentioned a differential equation in the

37
00:04:01,520 --> 00:04:10,560
actual model itself, in the equation itself. Is there one, are there situations that one

38
00:04:10,560 --> 00:04:16,720
performs better over than the other? Or is what they have selected to use in the paper the optimal

39
00:04:16,720 --> 00:04:24,960
solution in most cases, if not all cases? When it comes to clinical trials, that was a

40
00:04:25,120 --> 00:04:33,440
section in this that they discussed. There's a lot of FDA regulations of the clinical trials and

41
00:04:33,440 --> 00:04:41,680
it's very heavy red tape right now. Is there a way that there's minimum ends that you need in

42
00:04:41,680 --> 00:04:48,240
many clinical trials to actually be considered passing? Is there a way that you can bound this

43
00:04:49,200 --> 00:04:56,560
model that they've developed into something that you can guarantee a minimum number,

44
00:04:56,560 --> 00:05:00,480
a minimum sampling that the FDA requires or any regulatory body?

45
00:05:03,040 --> 00:05:08,960
Another point is the next step of how are we going to integrate this in with other machine

46
00:05:08,960 --> 00:05:15,600
learning models or any downstream applications that you're going with? Is there a selection method

47
00:05:15,600 --> 00:05:24,960
that we can, or how do you see these, this method kind of pre, kind of before machine learning?

48
00:05:24,960 --> 00:05:30,800
How are we going to attach these things together so that we feed the right data into machine learning?

49
00:05:32,480 --> 00:05:38,880
Being an LLM. And then scalability and computation demands. That's going to be a big one if this

50
00:05:38,880 --> 00:05:44,160
is going to be something that is used routinely in industry. We need to make sure that this is

51
00:05:44,160 --> 00:05:52,480
something that is as scalable as you can get. Go from small scale, which is a lot of what they

52
00:05:52,480 --> 00:05:56,240
show in this paper and then all the way up to the very large scale data sets that we

53
00:05:57,280 --> 00:06:03,120
use to train LLMs and other models. Those are kind of the five major points that I have.

54
00:06:05,120 --> 00:06:11,680
Thank you. Those are very insightful. Here were some of the big questions that I was excited about.

55
00:06:12,480 --> 00:06:18,400
So first, from a more general information gain, epistemic foraging perspective,

56
00:06:18,400 --> 00:06:23,520
how do we model the implicit and explicit constraints or trade-offs or dynamics of

57
00:06:23,520 --> 00:06:29,840
information seeking? Which is often addressing a question that is left unaddressed in data science

58
00:06:29,840 --> 00:06:34,080
of where the data comes from. It's just about doing analysis with the data that's there.

59
00:06:34,080 --> 00:06:38,800
But even there, as this paper will kind of get into, there's still sub-sampling and all these

60
00:06:38,800 --> 00:06:46,720
other factors to consider. The clinical trial example brings a very serious and very real plot

61
00:06:46,720 --> 00:06:55,440
twist into the paper, which moves through several levels of adding theoretical generalization and

62
00:06:55,440 --> 00:07:00,400
incorporating like the time dimension and other features. And then the plot twist is when the

63
00:07:00,400 --> 00:07:07,120
preferences for certain kinds of observations is specified, then there's all this interesting

64
00:07:07,120 --> 00:07:10,960
behavior and decisions that come into play. So I'm sure that'll be a great discussion.

65
00:07:11,920 --> 00:07:17,040
And then also in section four, they mentioned the streetlight effect, which is, quote,

66
00:07:17,040 --> 00:07:21,920
the tendency to search where data are generated in a minimally ambiguous way,

67
00:07:21,920 --> 00:07:27,040
i.e. under a street lamp compared to searching elsewhere on a darkened street. And so there it's

68
00:07:27,680 --> 00:07:32,560
an interesting scenario and there'll be some fun art coming up and also how they distinguish the

69
00:07:32,560 --> 00:07:38,800
sampling method with the full information seeking from the maximum entropy sampling

70
00:07:39,440 --> 00:07:44,800
is a very subtle but very important point that I look forward to hearing more from the authors about.

71
00:07:49,600 --> 00:07:59,120
Okay, so just to summarize, the paper is Active Data Selection and Information Seeking,

72
00:07:59,200 --> 00:08:05,200
2024, Thomas Parr, Carl Friston, Peter Seidman, and just a few of the aims and claims of the paper,

73
00:08:05,200 --> 00:08:10,480
and then Christopher will read the abstract. This paper aims to unpack the principles of

74
00:08:10,480 --> 00:08:14,960
active sampling of data by drawing from neurobiological research on animal exploration

75
00:08:15,520 --> 00:08:20,880
and from the theory of optimal experimental design. Our overall aim is to provide an intuitive

76
00:08:20,880 --> 00:08:26,080
overview of the principles that underwrite active data selection and to illustrate this with some

77
00:08:26,080 --> 00:08:32,880
simple examples. Our interest is in the selection of data, either through sampling subsets of data

78
00:08:32,880 --> 00:08:39,040
from a large data set or through optimizing experimental design based upon the models we have

79
00:08:39,040 --> 00:08:44,640
of how those data are generated. Optimizing data selection ensures we can achieve good

80
00:08:44,640 --> 00:08:51,440
inference with fewer data, saving on computational and experimental costs. So if you could read the

81
00:08:51,440 --> 00:08:59,920
abstracts. Absolutely, so the main points in the abstract are the Bayesian inference is typically

82
00:08:59,920 --> 00:09:05,680
focused on two major issues. The first one is that you have to estimate the parameters of the model

83
00:09:05,680 --> 00:09:10,880
of the data, and the second is that you need to quantify the evidence for alternative hypotheses

84
00:09:11,680 --> 00:09:18,320
and formulate an alternative model. But this paper is actually looking at a third issue,

85
00:09:18,320 --> 00:09:25,120
which is in how you're going to select the data for your models. And either through sampling

86
00:09:25,120 --> 00:09:30,160
subsets of large data is typically used or optimizing experiments of design.

87
00:09:32,320 --> 00:09:39,360
Based upon the models we have these of how these data are generated. Optimizing data selection,

88
00:09:39,360 --> 00:09:46,960
what's going into the models can achieve a very good inference with fewer data points. So you're

89
00:09:47,040 --> 00:09:51,920
saving on computational time costs, that sort of thing by actually reducing the amount of

90
00:09:51,920 --> 00:09:58,240
information that you're putting into a model. So what we're doing here is trying to unpack

91
00:09:58,240 --> 00:10:04,560
how you're going to actively select data, and I mean actively select data through a machine

92
00:10:05,680 --> 00:10:13,440
optimization protocol by drawing from some of these neurobiology concepts and trying to optimize

93
00:10:13,440 --> 00:10:22,880
the maximum information that the information can provide, maximum information gain. So they offer

94
00:10:22,880 --> 00:10:29,200
overview of some basic points from the field and illustrates the application in some of the toy

95
00:10:29,200 --> 00:10:35,520
examples that they have will go through, ranging from different approximations with basis sets

96
00:10:36,160 --> 00:10:42,000
to inference about how the process can evolve over time. And finally they'll go through and

97
00:10:42,000 --> 00:10:47,280
consider how the approach to the data selection could be applied to design of clinical trials in

98
00:10:47,280 --> 00:10:52,640
this case, and specifically Bayes adapted clinical trial, something that is more and more

99
00:10:53,680 --> 00:11:00,480
seeing headlines and it's more and more used today now that we have the technology to do it.

100
00:11:02,720 --> 00:11:09,200
Great. Okay. For the roadmap, the paper begins with introduction section,

101
00:11:10,080 --> 00:11:14,480
goes into Bayesian inference, generative models and expected information gain.

102
00:11:15,280 --> 00:11:22,240
They go through a simplest worked example, and then consider a few more ways to level up that model

103
00:11:22,240 --> 00:11:28,400
with function approximation, consideration of the time dimension with dynamic processes,

104
00:11:28,400 --> 00:11:32,720
and then bring in the preference for certain observations in the clinical trials.

105
00:11:32,720 --> 00:11:38,160
Then there's a discussion and conclusion, and they also have a paragraph explaining their

106
00:11:38,240 --> 00:11:44,800
kind of logic there. The keywords for the paper were experimental design, active sampling,

107
00:11:44,800 --> 00:11:51,040
information gain, and Bayesian inference. So the next slides are going to go into those

108
00:11:51,040 --> 00:11:57,680
four background topics. After the four background topics, we'll speed through the sections and

109
00:11:57,680 --> 00:12:02,880
just plant a few seeds for what we want to explore more. So first, experimental design.

110
00:12:03,600 --> 00:12:11,600
Here's two kind of classical views of experimental design in the active inference and free energy

111
00:12:11,600 --> 00:12:21,120
principle eras. So on the left is the statistical parametric mapping, textbook, toolbox, documentation,

112
00:12:21,120 --> 00:12:28,240
et cetera, has multiple chapters and kinds of analyses included in the package to specify

113
00:12:28,240 --> 00:12:33,360
and simulate and also to recognize data according to different experimental designs.

114
00:12:34,080 --> 00:12:41,520
And one very hallmark or common visualization of these kinds of patterns of experimental design

115
00:12:41,520 --> 00:12:49,040
are these design matrices. And it's just represented in this black to white gray scale,

116
00:12:49,920 --> 00:12:55,200
and it summarizes different kinds of measurements across different experimental settings. Like here

117
00:12:55,200 --> 00:13:01,360
might be six settings in the larger white blocks. And then there was variability within each of those

118
00:13:01,360 --> 00:13:05,760
trials. And those are the smaller row levels. So that's like where the data are collected.

119
00:13:05,760 --> 00:13:10,640
And a lot of this has to do with the linear operations that can occur on this kind of

120
00:13:10,640 --> 00:13:17,360
matrix in a general linear modeling framework. And then on the right is the experimental design

121
00:13:18,080 --> 00:13:24,880
experimenters perspective, where the experimental stimuli they output as actions are the

122
00:13:24,880 --> 00:13:31,040
observations going into the subjective model, like of the rat in the team is, and then the action

123
00:13:31,040 --> 00:13:36,960
output of the rat is the observations of the experiment of the experiment. So kind of two

124
00:13:36,960 --> 00:13:47,040
different perspectives, SPM with more of a matrix multiplication, f m r i optimal design, and then

125
00:13:47,040 --> 00:13:52,320
active inference with the more general graphical Bayesian modeling, starting to broaden the

126
00:13:52,320 --> 00:13:57,840
consideration of what optimal foraging and what information gain epistemic value mean.

127
00:13:57,840 --> 00:14:02,560
These are kind of the experimental design themes and how they connect a little bit with

128
00:14:03,360 --> 00:14:09,840
other experimental design factors. Want to add anything? Yeah, keep in mind that a lot of these

129
00:14:09,840 --> 00:14:16,320
experiments, experimental design is a very big and very important consideration when you're

130
00:14:16,320 --> 00:14:21,920
actually running any sort of science or analytics of any variety. And these experiments can actually

131
00:14:21,920 --> 00:14:29,120
get very large with huge, huge amounts of data. And all of that data is relevant for every

132
00:14:29,120 --> 00:14:34,000
application that you want. So you want to be able to design your experiment in a way that you can

133
00:14:34,000 --> 00:14:40,640
collect information in a intelligent way rather than trying to go through and just collect every

134
00:14:40,640 --> 00:14:45,600
data point that you can because humans in many cases are running some of these experiments and

135
00:14:45,600 --> 00:14:51,680
they are have limited time. I certainly do when I'm running these things. So I have to be very

136
00:14:51,680 --> 00:14:56,960
intelligent in how I set things up and how I actually collect data and what did I collect,

137
00:14:56,960 --> 00:15:00,640
because you only get in many of these cases, you only get one shot to collect the data,

138
00:15:00,640 --> 00:15:06,960
you miss it, it's over. You won't have that data point. So it's very critical that you actually

139
00:15:06,960 --> 00:15:09,920
take the experimental design seriously when you're setting these things up.

140
00:15:10,640 --> 00:15:18,880
Great. So connecting that kind of experimental design, experimenter on a budget perspective

141
00:15:18,880 --> 00:15:28,640
with a more statistical and biologically statistical based perspective, active sampling.

142
00:15:28,640 --> 00:15:33,200
So they wrote, when we look at the world around us, we are implicitly engaging in a form of active

143
00:15:33,200 --> 00:15:38,720
data sampling, also known as active sensing or active inference. So this is referencing the

144
00:15:38,800 --> 00:15:45,200
visual saccades. And just to kind of highlight how extreme the relative acuity difference is

145
00:15:45,840 --> 00:15:51,360
between the center of the eye where the gaze is focused on and the off center,

146
00:15:51,360 --> 00:15:56,640
among other visual changes. And vision is just being taken as one sensory example here.

147
00:15:57,040 --> 00:16:02,080
It could also be thought of as like looking for books within a library or any other kind of

148
00:16:02,080 --> 00:16:07,840
selection of what data are going to come in, even if it seems like all of it is going to

149
00:16:07,840 --> 00:16:14,640
all of it is coming in, that still is going to be perhaps addressed with different sensors that

150
00:16:14,640 --> 00:16:19,840
have different variability profiles, or like there's different RNA sequencing kits that you

151
00:16:19,840 --> 00:16:26,400
could buy. And so how do you balance the kind of more samples or which samples, especially as

152
00:16:26,400 --> 00:16:33,040
those spaces grow massive. And then just to contrast that, whereas digit recognition in a

153
00:16:33,040 --> 00:16:40,400
saccade based paradigm would focus on the motor patterns and the small centrally focused

154
00:16:40,400 --> 00:16:46,400
visual acuity and then the motor patterns that relate to circuiting around a digit. Whereas

155
00:16:46,400 --> 00:16:52,960
in the kind of machine learning taken all at once approach, a matrix corresponding to like the

156
00:16:52,960 --> 00:17:00,880
pixels in the MNIST dataset are simply taken in all at equivariance level. So that's just kind

157
00:17:00,960 --> 00:17:04,800
of taking in the data. There's still another higher order data selection question of like,

158
00:17:04,800 --> 00:17:10,400
which digits do you take? If there was a large number of digits in that library. So this is

159
00:17:11,120 --> 00:17:17,280
active data sampling on multiple scales, which records you pull at all, and then how the resolution

160
00:17:17,280 --> 00:17:22,160
and all the tradeoffs that are associated with using the data processing or making the experiment.

161
00:17:22,720 --> 00:17:30,000
Yeah, add more though. And, you know, keep in mind that when you're talking about something

162
00:17:30,000 --> 00:17:34,800
like the visual system, you know, our visual system has access to untold amounts of information,

163
00:17:34,800 --> 00:17:42,080
but our brain can't take advantage of all of that at once. So there's low energy usage of the brain

164
00:17:42,080 --> 00:17:46,960
that needs to optimize the relevant information. Think, you know, your nose is right at the end

165
00:17:46,960 --> 00:17:52,240
of your face. Your eyes are always seeing your nose, but your brain is filtering it out. And this

166
00:17:52,240 --> 00:17:57,040
is happening all the time at all points in time. There are literal blind spots in what you are

167
00:17:57,040 --> 00:18:05,120
actually capable of intaking and processing all at once. And then additionally, when you're

168
00:18:05,120 --> 00:18:10,560
moving away from something like your eye or biological systems and into the experiment

169
00:18:10,560 --> 00:18:15,920
design itself, you know, you oftentimes can't run a full factorial design. And there are other

170
00:18:15,920 --> 00:18:22,080
methods like a fractional factorial design. But those are random base. And this is trying to

171
00:18:22,080 --> 00:18:28,880
actually talk about actively selecting how you're going to set up that design. So it's kind of a,

172
00:18:28,880 --> 00:18:35,920
you can think of it multiple different ways. Awesome. The factor that's going to come into

173
00:18:35,920 --> 00:18:43,840
play as driving the active sampling is going to be the information gain. And there's some quotes

174
00:18:43,840 --> 00:18:50,320
here. And equation two is shown. They write, we have conditioned our model upon the variable

175
00:18:50,400 --> 00:18:55,600
pi, which represents a choice we can make in selecting our data. So data recognition,

176
00:18:55,600 --> 00:19:00,960
interpretation, analysis, and so on. It's often framed as kind of like an observation type or

177
00:19:00,960 --> 00:19:09,120
sense making type activity. Here, pi for policy, as with usual, is being framed as a control or

178
00:19:09,120 --> 00:19:17,360
an active data selection policy, we're applying to some data set. So it adds a action element

179
00:19:18,000 --> 00:19:23,200
into this sequential epistemic foraging, rather than just taking a large data set,

180
00:19:23,200 --> 00:19:29,120
and just munching it like all at once, it brings in this sequential question of where to sample,

181
00:19:29,120 --> 00:19:36,160
and potentially updating where is informative to sample through time. And that I of pi is the

182
00:19:36,800 --> 00:19:42,480
functional on that policy distribution or specific choice that can be decomposed,

183
00:19:42,480 --> 00:19:46,320
all these interesting ways that we can explore more in the coming discussions.

184
00:19:46,320 --> 00:19:48,400
What else would you add, though, about information gain?

185
00:19:49,440 --> 00:19:54,000
I think this is one of the biggest points in this whole paper is you're measuring how much

186
00:19:54,000 --> 00:19:59,440
information you are gaining in your model by adding these different variables in here and

187
00:19:59,440 --> 00:20:05,360
selecting different variables. You're effectively automatically taking out or trying to remove

188
00:20:05,360 --> 00:20:10,320
things that have high mutual information that don't add as much. So if you have parameter A

189
00:20:10,320 --> 00:20:15,680
and parameter B that are effectively just transformations of the same data, then you

190
00:20:15,680 --> 00:20:19,840
can easily remove one of those and still have all the information that you need.

191
00:20:20,800 --> 00:20:26,720
So it's a really, really powerful way of saying I'm trying to optimize and maximize the amount

192
00:20:26,720 --> 00:20:33,120
of information that I'm adding into the model by selecting data that actually has the information

193
00:20:33,120 --> 00:20:43,280
that is going to improve them. Awesome. One other interesting angle here is often in the control

194
00:20:43,280 --> 00:20:50,000
literature, utility, reinforcement learning, etc. The epistemic value component is added in,

195
00:20:51,120 --> 00:20:58,080
whereas in the structure of this paper, they start with the pure information gain perspective.

196
00:20:58,080 --> 00:21:03,520
And then in the clinical trial, they bring the preference in. So the pragmatic value

197
00:21:04,160 --> 00:21:09,520
comes in secondary to the information gain in how they build it up step by step.

198
00:21:12,000 --> 00:21:19,360
Bayesian inference is the last keyword. A lot of places to go. Here's what they showed

199
00:21:19,920 --> 00:21:25,280
for equation one. And they wrote Bayesian inference is the process of inverting

200
00:21:25,760 --> 00:21:32,640
a model of how data, why, are generated to obtain two things, the marginal likelihood

201
00:21:32,640 --> 00:21:37,520
and the posterior probability. So anything you want to say about Bayesian inference or

202
00:21:37,520 --> 00:21:42,320
do you want to say something about Bayesian networks and graphs? I think that you've kind of

203
00:21:42,320 --> 00:21:48,960
covered it here. It's, I think, barely textbook on this part. Yeah. How about graphs?

204
00:21:49,920 --> 00:21:57,680
On the Bayesian graphs side of it, there's multiple different ways that these Bayesian

205
00:21:57,680 --> 00:22:03,360
statistics is done nowadays. And the Bayesian networks and graphs is a really powerful method

206
00:22:03,360 --> 00:22:10,880
going forward. I know that right now in the Institute, we have an Rx and Fur group working

207
00:22:10,880 --> 00:22:17,040
right now, which is a Julia package for actually just building these network graphs, these Bayesian

208
00:22:17,040 --> 00:22:22,480
graphs and doing message passing between the different factors and the different nodes of

209
00:22:22,480 --> 00:22:31,440
the graph. So this is a very big up and coming area right now. It's very early in the time frame

210
00:22:31,440 --> 00:22:36,480
that this is going to become big. It's kind of on the upswing right now. And it's kind of,

211
00:22:37,440 --> 00:22:42,000
at least I would predict, going to be kind of the next big thing going forward in the next five

212
00:22:42,080 --> 00:22:50,880
years or so. Yeah. We've been having a great epistemic time and Livestream 55 explores some of

213
00:22:50,880 --> 00:22:59,360
this in more detail. Okay. That was the background now on to the paper. So first, just to get the

214
00:23:00,560 --> 00:23:06,960
last part of the paper out of the way, they have a GitHub, Thomas Parr's GitHub with the

215
00:23:06,960 --> 00:23:12,560
active data selection repo. And maybe in one of the upcoming discussions or somebody in the time

216
00:23:12,560 --> 00:23:20,960
between can explore and transform and play with the code. And also all these different

217
00:23:20,960 --> 00:23:25,760
ways that we have fun discussions around the language of the active inference model

218
00:23:26,320 --> 00:23:32,240
and how building it in different languages or using different styles like is there isn't plausible.

219
00:23:32,240 --> 00:23:38,400
These have been very fun discussions that help us get at what the core of the math really is

220
00:23:39,040 --> 00:23:43,680
and how that's independent of whether it's written in MATLAB or any other language.

221
00:23:44,640 --> 00:23:49,840
And then also as it is simulated, it's written here in MATLAB. And so that's kind of interesting.

222
00:23:50,560 --> 00:23:54,640
Any thoughts on that or just like coding in Rx and fur or or

223
00:23:55,600 --> 00:24:03,440
Yeah, I think that with Rx and fur being, I think, relatively new on the scene, you have some of

224
00:24:03,440 --> 00:24:10,960
these other traditional approaches with MATLAB and high MD and that sort of thing. It'll be very

225
00:24:10,960 --> 00:24:18,320
interesting to see how these techniques evolve over time with packages like Rx and fur really,

226
00:24:19,040 --> 00:24:25,280
I think, changing how we approach building these models and designing them. I think that it's going

227
00:24:25,280 --> 00:24:32,240
to be even more critical now in this current environment to select the data intelligently

228
00:24:32,240 --> 00:24:38,080
going in so that you're not muddying up your models or having to build two big of models that might

229
00:24:38,080 --> 00:24:46,560
have information that's not as useful to the application at hand. Yeah, great. All right,

230
00:24:46,640 --> 00:24:52,400
section one introduction. So we'll try to hit on some of the key points. I'll say something briefly

231
00:24:52,400 --> 00:24:59,840
and then feel free to add something if you want. Section one situates that inference and action

232
00:25:00,800 --> 00:25:09,520
cycle or loop or partition in terms of a statistician's job or process in modeling

233
00:25:09,520 --> 00:25:17,520
observations data as sampled and latent variables as models and the process by which there's

234
00:25:18,560 --> 00:25:26,560
kind of snapshot or bulk summarization or generativity or and how it's possible to have a

235
00:25:26,560 --> 00:25:33,360
continuous resampling of informative data or how you even evaluate how data are informative in which

236
00:25:33,360 --> 00:25:40,080
way. Want to add anything? I think you've captured that very well. I'm going to actually pull out my

237
00:25:40,080 --> 00:25:48,400
notes so that I can actually remember all the symbols. Why are going to be used for data and

238
00:25:48,400 --> 00:25:56,800
data for the latent variables? So distributions of data, distributions of latent variables

239
00:25:56,800 --> 00:26:04,080
conditioned upon data coming in. So that could be seen as just one data point sequentially or a big

240
00:26:04,080 --> 00:26:11,360
bulk vector coming in like all at once. Just continuing to move through this section, they wrote

241
00:26:12,640 --> 00:26:17,440
careful data selection is especially important when we consider the problems associated with

242
00:26:17,440 --> 00:26:22,240
very large data sets of the sort that are now ubiquitous in machine learning and artificial

243
00:26:22,240 --> 00:26:29,920
intelligence settings. So just to summarize a little bit or add a few notes that came up in

244
00:26:29,920 --> 00:26:36,080
the paper. So other than this topic being very fascinating and very integrative in terms of a

245
00:26:36,080 --> 00:26:41,520
unifying approach for information and behavior etc. Also this is definitely one of the active

246
00:26:41,520 --> 00:26:47,200
inference questions that has a lot of pragmatic relevance as dealing with with data sets of

247
00:26:47,200 --> 00:26:54,240
different kind is totally day to day. And especially the way that even the examples specify

248
00:26:54,240 --> 00:27:00,400
important settings is very clear, very direct. Though also the mathematics are very general

249
00:27:00,400 --> 00:27:08,400
about epistemics and this motivation that they lay out in the first section about how if this

250
00:27:08,400 --> 00:27:13,040
challenge could be addressed, then there will be all these kinds of benefits that could be realized

251
00:27:13,040 --> 00:27:20,000
with current systems and data sets. And then they provide the approach to at least getting

252
00:27:20,000 --> 00:27:25,280
there or towards it to optimize data selection. We first need to identify an appropriate optimality

253
00:27:25,280 --> 00:27:29,680
criterion. And so they're going to kind of go through several stages of with different

254
00:27:30,320 --> 00:27:37,920
generative models how that optimality criterion is defined. Anything else that

255
00:27:38,880 --> 00:27:44,000
And keep in mind that this is the expected information gain that they're talking about.

256
00:27:44,000 --> 00:27:49,760
It's effectively how much do we think we're going to gain by adding this information in there.

257
00:27:49,760 --> 00:27:56,160
And then you can of course train your model by looking at the actual information gain if necessary

258
00:27:56,160 --> 00:28:02,000
and go through kind of a learning cycle. But we're basing this all off of what do we expect

259
00:28:02,080 --> 00:28:08,640
to gain from this information. All right, section two, basing inference generative models and

260
00:28:08,640 --> 00:28:18,400
expected information gain. In this equation three, I won't read it all. It models the Markov blanket

261
00:28:18,400 --> 00:28:24,800
formalism in terms of upstream and downstream causal relationships in terms of messages that are

262
00:28:24,800 --> 00:28:31,200
passed along edges of a factor graph. They introduce in this paper the lambda operator

263
00:28:31,200 --> 00:28:37,920
to indicate either summation or integration. So this is across continuous variables or discrete

264
00:28:37,920 --> 00:28:44,960
variables. And we'll explore this more with the authors, hopefully anything you want to add on

265
00:28:44,960 --> 00:28:54,160
equation three. More that you know the information gain is a function of the data that you sample.

266
00:28:54,160 --> 00:28:58,480
So depending on how you sample that data, you're going to get different information gain out of

267
00:28:58,560 --> 00:29:05,360
it as you would expect. And then you start to get into the message passing, which is that base graph

268
00:29:05,360 --> 00:29:11,200
and factor graph, I guess, challenge going forward that that construct when you build

269
00:29:11,200 --> 00:29:16,720
it in a factor graph model, you have to be able to pass the messages between the nodes effectively.

270
00:29:17,680 --> 00:29:24,640
Yeah, and to kind of ground that in the data science situation, if you have a latent

271
00:29:24,640 --> 00:29:30,400
state estimate and you're generating data, generative AI, synthetic data, then the latent

272
00:29:30,400 --> 00:29:36,800
variable is upstream, causally, statistically from the data pseudo observation. But that might be

273
00:29:36,800 --> 00:29:43,040
the actual real observation if you're interested in the computer model. Whereas the data recognition

274
00:29:43,040 --> 00:29:49,440
case where the data are upstream of the estimate of a parameter, like a risk score or something like

275
00:29:49,440 --> 00:29:55,760
that, then the parents of the latent state estimate is the data. So that's the recognition

276
00:29:55,760 --> 00:30:01,680
direction. So this kind of covers the whole Bayesian update possibility spectrum in this

277
00:30:02,640 --> 00:30:09,120
essentially Markov blanket, but it could be in face space or time or a few other situations

278
00:30:09,120 --> 00:30:21,840
they explore. All right, three, a worked example. This section lays out the overall pipeline for

279
00:30:21,840 --> 00:30:29,040
how you get from the graphical notation of the Bayesian network, whether it's viewed visually

280
00:30:29,040 --> 00:30:36,160
graphically, like with a variable dependency structure, or whether it's just written out

281
00:30:36,160 --> 00:30:42,560
in terms of the plain text with the analytical, the Bayesian network is transformed into a factor

282
00:30:42,560 --> 00:30:49,440
graph, probably constrained factor graph, discussion for another day. On that graph,

283
00:30:49,440 --> 00:30:59,040
certain messages are passed at inference runtime. conditional and predictive entropies are calculated

284
00:30:59,040 --> 00:31:07,520
as part of the way that this system outputs or is described by different probability distributions

285
00:31:07,520 --> 00:31:14,000
understand in a kind of statistical mechanical way in terms of entropy. And then that is going

286
00:31:14,000 --> 00:31:20,640
to come together into calculation of the objective function, which is the expected information gain,

287
00:31:20,640 --> 00:31:26,800
which is basically conditioned upon the cognitive model of the sampler. So just because the sampling

288
00:31:26,800 --> 00:31:33,360
is active data sampling, doesn't mean that it's going to lead to like an adaptive behavior.

289
00:31:34,320 --> 00:31:40,240
It just means that where the learning rate is perceived to be highest informationally,

290
00:31:40,240 --> 00:31:48,080
iteratively, there is a ranking by which those can be, which this the space of experiments

291
00:31:48,080 --> 00:31:56,240
can be ranked by and it can connect to pragmatic value in terms of epistemic and pragmatic coming

292
00:31:56,240 --> 00:32:01,280
together for the full expected free energy like in the clinical trial. Anything else?

293
00:32:02,240 --> 00:32:09,120
And you'll notice in this story example, they are discussing here, the factors that they have in

294
00:32:09,120 --> 00:32:16,400
their graph in each of their nodes is actually a cosine. So that's why you get that kind of

295
00:32:16,400 --> 00:32:25,680
oscillation in that bottom plot there. So you'll have areas of maximal information and then areas

296
00:32:25,680 --> 00:32:30,960
of minimal information just based on the toy example they have. And this doesn't always have

297
00:32:30,960 --> 00:32:36,240
to be cosine, but in this example it is. And so it just kind of gives you a really good graphical

298
00:32:36,240 --> 00:32:46,160
understanding of how your information gain can be viewed over a sinusoidal sort of oscillation.

299
00:32:47,440 --> 00:32:52,480
Yeah, just to kind of double down on that, if you sample right here on the number line,

300
00:32:52,480 --> 00:32:59,200
or right here, the lines are indistinguishable. So the information gain is expected to be low

301
00:33:00,080 --> 00:33:05,520
under understanding the parameter family that is being generated and sampled from,

302
00:33:05,520 --> 00:33:12,080
which in this first example is the same, same type of equations. Whereas where the functions are

303
00:33:12,080 --> 00:33:18,880
maximally distinct, the information gain associated with reducing uncertainty about which one of those

304
00:33:18,960 --> 00:33:29,680
five the data point is coming from, those are the informative points at the zero on the number line

305
00:33:29,680 --> 00:33:36,880
and far out. That's where just perceiving one point uncolored would give you the most ability to

306
00:33:36,880 --> 00:33:41,360
even perfectly resolve which one of the five situations it was.

307
00:33:41,920 --> 00:33:51,280
So they're right. In effect, this model amplifies or attenuates the amplitude of the predicted

308
00:33:51,280 --> 00:33:57,840
data, depending upon a periodic function of our data sampling policy pi. So here the policy

309
00:33:57,840 --> 00:34:03,520
distribution is like that kind of around the clock direction, which is not a common setting,

310
00:34:03,520 --> 00:34:11,680
but the general idea of sampling amongst a finite set of alternatives, where a control

311
00:34:11,680 --> 00:34:18,800
variable is going to result in the most informative data point, is a theme that is going to be

312
00:34:18,800 --> 00:34:26,720
expanded upon, and also one interesting mathematical move. Once all terms that are constant with

313
00:34:26,720 --> 00:34:33,600
respect to pi are eliminated, we are left with equation six. So equation five comes down to

314
00:34:33,600 --> 00:34:42,960
equation six, or maybe not exactly only five to six, but six has removed all the variables

315
00:34:43,680 --> 00:34:49,680
that don't change as policy changes. So if the question of policy selection is taken alone,

316
00:34:49,680 --> 00:34:56,160
like gradients on policy updating, then everything that's constant with respect to it

317
00:34:56,240 --> 00:35:02,080
doesn't come into like the delta pi, delta something. So it just simplifies it down to

318
00:35:02,080 --> 00:35:07,120
only a function of policy, and that just kind of reflects how like the sense making and belief

319
00:35:07,120 --> 00:35:13,200
updating component is partitioned off from the policy selection component here.

320
00:35:15,520 --> 00:35:21,840
Yeah, you're looking for change in your belief based on the observations that you're gained.

321
00:35:21,840 --> 00:35:26,560
So if it's not changing, it's not as informative in your information model.

322
00:35:28,880 --> 00:35:35,840
Yeah, continuing on equation six there, which is modeling the policy dependent

323
00:35:35,840 --> 00:35:42,880
components of information gain as an objective function that ranks decisions about where to

324
00:35:42,880 --> 00:35:50,560
sample. Equation six is a special case of the third row of table one, which highlights analytical

325
00:35:50,560 --> 00:35:56,400
expressions for expected information gain for a few common model structures. As we might intuit,

326
00:35:56,400 --> 00:36:00,400
the most informative place is to sample data aligned with those in which differences in data

327
00:36:00,400 --> 00:36:05,360
lead to large differences in the predicted data, in which our choice of pi maximizes the sensitivity

328
00:36:05,360 --> 00:36:16,000
with which y depends on data. So here are the categorical, the Dirichlet, and other functions

329
00:36:16,000 --> 00:36:22,880
in terms of how they'd be written out in the probabilistic, like specifying a distribution

330
00:36:22,880 --> 00:36:31,840
way, and then how there's this relationship analytically to a related distribution, which is

331
00:36:32,640 --> 00:36:40,400
an objective function that ranks the information content of sampling the likelihood distribution

332
00:36:40,400 --> 00:36:47,280
in a certain way. And that's closed form in certain situations. And then also they explore

333
00:36:47,280 --> 00:36:53,280
where it's intractable formally. And so then that's where the variational approximation comes into

334
00:36:53,280 --> 00:37:03,600
play. Anything to add? No, I think that summarizes this slide. Okay, section four, function approximation.

335
00:37:04,560 --> 00:37:10,400
We next turn to a generic supervised learning problem, that of trying to approximate some

336
00:37:10,960 --> 00:37:14,880
function based upon known inputs and the observable outcomes they stochastically

337
00:37:14,880 --> 00:37:23,760
cause. Pretty general neural network or latent state observation setup.

338
00:37:24,000 --> 00:37:37,680
That information is composed and concatenated. So that there's a common variable with that's

339
00:37:37,680 --> 00:37:42,560
describing the statistical object that's going to be describing the inputs and the relationship

340
00:37:42,560 --> 00:37:53,920
with the observable outcomes. And then that function approximation from sequential data

341
00:37:53,920 --> 00:38:00,640
in figure three is simulated with random but potentially you could call all of them random.

342
00:38:00,640 --> 00:38:10,400
But this one is a flatter or a less informed and iterated model of data sampling,

343
00:38:11,120 --> 00:38:16,800
just going to show that samples of random data with even this minimal

344
00:38:17,760 --> 00:38:24,720
non information gain driven model has a certain baseline prediction that's associated with

345
00:38:24,720 --> 00:38:32,320
certain choices about sampling sequentially from this generative model. Want to add anything?

346
00:38:33,360 --> 00:38:39,680
Yeah, it's just I like that they highlighted in this that choice diagram there that you can

347
00:38:39,680 --> 00:38:45,440
actually get the inefficient sampling just by random that you start to you can randomly select

348
00:38:45,440 --> 00:38:52,800
two things very close together and you've effectively maybe not wasted a choice but

349
00:38:52,800 --> 00:38:57,600
you know not gotten the maximum gain from that choice that you could have.

350
00:38:59,440 --> 00:39:08,400
Yeah, they write a little bit more about figure three. Figure three illustrates a depiction of

351
00:39:08,400 --> 00:39:13,440
this model as a Bayesian network and a visual representation of the data generating process.

352
00:39:16,960 --> 00:39:22,960
Now they're going to bring in information gain. So they write this is where information gain

353
00:39:22,960 --> 00:39:29,760
becomes relevant into designing a more informed way to sample data than from a flat or a non

354
00:39:29,760 --> 00:39:34,800
updating prior data sampling distribution. It's like equivalent to having a policy prior that's

355
00:39:34,800 --> 00:39:42,080
fixed which might be a heuristic in certain space. They write substituting equation seven into

356
00:39:42,080 --> 00:39:53,760
equation three. So here's that Markov blanket parent child concept and here equation three is

357
00:39:53,760 --> 00:40:00,640
describing the policy dependence on the joint distribution of the observed and unobserved

358
00:40:00,640 --> 00:40:10,640
and this is combined into equation 10. To show what equation 10 does in terms of now that we're

359
00:40:10,640 --> 00:40:19,120
sampling from this distribution or like statistical distributions that this describes they'll

360
00:40:19,120 --> 00:40:23,760
differentiate figure three from figure four kind of like bring in this model change between those

361
00:40:23,760 --> 00:40:28,640
two figures. Now samples are drawn from a distribution whose log is proportional to the

362
00:40:28,640 --> 00:40:36,640
information gain in equation 10. So it takes the flat policy prior and in a fixed way has remapped it

363
00:40:36,640 --> 00:40:45,760
to be proportional to the information gain. So here's three on the right and then four on the right

364
00:40:46,880 --> 00:40:53,360
and the figure uses the same format as figure three but now each choice is sampled to maximize

365
00:40:53,360 --> 00:41:00,800
anticipated information gain and they point to some specific quantitative patterns but also

366
00:41:00,800 --> 00:41:07,120
like qualitative patterns. So want to add anything on figure four? Just that now if you focus on those

367
00:41:07,120 --> 00:41:13,120
choices because that I really did I think like that choice plot there you can see that the walks

368
00:41:13,120 --> 00:41:19,920
around kind of choices around your data space are a little bit more distributed evenly distributed

369
00:41:19,920 --> 00:41:25,680
a little bit less random but you start to get I think a more cohesive sampling of the data

370
00:41:25,680 --> 00:41:31,440
without entire randomness putting things too close together putting selections too close together.

371
00:41:34,480 --> 00:41:42,160
Yeah okay continuing on well they set up the question as this raises the question as to how

372
00:41:42,160 --> 00:41:48,960
many samples should we collect. So within a foraging bout where should one look and then at the kind

373
00:41:48,960 --> 00:41:54,480
of like pulling a layer back in the strategy when should you halt look it like if you have already

374
00:41:54,480 --> 00:42:00,720
sampled all three records from a data set then unless you had some other reason you could fully

375
00:42:00,720 --> 00:42:07,360
stop sampling there but you also might want to have a softer stopping criterion that would relate to

376
00:42:07,360 --> 00:42:12,800
how much information you're gaining from continuing to sample in that way before like halting and so

377
00:42:12,800 --> 00:42:21,280
they include that by having like an exit policy in the state space of foraging possibilities.

378
00:42:22,400 --> 00:42:27,520
So how do you resolve that and answer this question can be drawn from behavioral neuroscience in the

379
00:42:27,520 --> 00:42:36,560
so-called exploitation exploration dilemma and they introduced the notion of sampling costs

380
00:42:37,120 --> 00:42:44,960
to help decide that. So this method is still going to require parameterization and situation

381
00:42:44,960 --> 00:42:50,240
specific modeling of the relative costs versus the relative information gain however at least

382
00:42:50,240 --> 00:42:57,440
there's an accounting that includes costs into the sampling equation to give any possibility of

383
00:42:57,440 --> 00:43:02,880
exiting because if no costs are provided for sampling then the model might just converge

384
00:43:02,880 --> 00:43:08,240
and continue to eke out very small amounts of variance explained if it doesn't explicitly

385
00:43:08,240 --> 00:43:16,880
have that stop option so they take the policy vector the list of locations that can be sampled

386
00:43:16,880 --> 00:43:22,480
from and adds a zero element which reflects the information gained if we were to stop sampling

387
00:43:23,440 --> 00:43:30,160
and then there's a preference over those observations expressed in the c vector preferences

388
00:43:31,120 --> 00:43:36,320
and this brings in the information seeking and the cost averse of imperatives into the same

389
00:43:36,320 --> 00:43:42,960
objective function in 11. Anything to add on 11? Yeah eventually the idea is that it just gets to

390
00:43:42,960 --> 00:43:49,760
a point where you're no longer whatever you set you're kind of stopping like energy to be

391
00:43:51,120 --> 00:43:55,680
kind of breaking energy eventually it's just gonna get to a point where the model just says

392
00:43:55,680 --> 00:44:02,240
hey I've reached what I can you've set this you're not gaining any anything beyond this point

393
00:44:02,240 --> 00:44:07,520
we can just stop at this point which is nice since in the random selection case there's not

394
00:44:07,520 --> 00:44:13,680
necessarily a stopping parameter as Daniel mentioned you could continue to get eke out

395
00:44:13,680 --> 00:44:19,360
very very small marginal changes but you're not going to gain anything else and so you're just

396
00:44:19,360 --> 00:44:24,960
spinning your wheels for no reason so this is a very elegant way of saying hey I've reached kind

397
00:44:24,960 --> 00:44:34,720
of an inflection point of data gain I'm done. So figure five they're continuing in this genre of

398
00:44:34,720 --> 00:44:42,160
three four five and now they've added in to the policy decision which which has an upstream

399
00:44:42,160 --> 00:44:48,480
dependency on the data that's the active policy edge they add in this

400
00:44:48,880 --> 00:44:58,400
cost to sampling so we can explore more however it now includes not just the information gain

401
00:44:58,400 --> 00:45:06,880
driven choices within a trial but it includes a specific probabilistic but decisive stopping point

402
00:45:07,440 --> 00:45:13,440
for that trial as parameterized by how sensitive it is to information gain and preference

403
00:45:14,000 --> 00:45:20,080
so this is one of the most interesting parts and and discussions in the paper

404
00:45:21,040 --> 00:45:26,800
they they ask it out loud a reasonable question to ask at this stage is why bother

405
00:45:27,360 --> 00:45:33,040
with the full information seeking objective and basically how does this differ from maximum

406
00:45:33,040 --> 00:45:43,120
entropy sampling and um let's look forward to the authors or other guests but here's just a

407
00:45:43,120 --> 00:45:48,400
few notes on this because I think it'll be a great place to explore what it really means to do

408
00:45:48,400 --> 00:45:56,400
statistical and physical modeling on cognitive systems they directly contrast maximum entropy

409
00:45:56,400 --> 00:46:04,960
sampling and their whole information gain family against each other and then the rebuttal is in

410
00:46:05,520 --> 00:46:12,080
figure six so just to show figure six for a second the measurement noise increases in variance from

411
00:46:12,080 --> 00:46:19,440
the center of the function domain so the the variability profile of the function is non-uniform

412
00:46:20,080 --> 00:46:25,040
this means this means the amount of unresolvable uncertainty is heterogeneous through the domain

413
00:46:25,040 --> 00:46:33,280
of potential sampler so I in some kind of ways of thinking about what they're really getting at

414
00:46:33,280 --> 00:46:38,400
and just putting this out as a speculation or starting point for for this key technical point

415
00:46:39,120 --> 00:46:46,560
so if there were a case where the latent states were equivariants they had iid variability

416
00:46:46,560 --> 00:46:53,200
profiles then sampling the most variable sensory data is the most informative like if

417
00:46:53,200 --> 00:47:00,720
you're taking a picture of a solid black image then sampling from the noisy pixels is going to

418
00:47:00,720 --> 00:47:05,680
potentially provide more information gain you're reducing uncertainty more about something

419
00:47:05,680 --> 00:47:12,400
it might be overfitting but you can select as a heuristic wanting to sample from where variability

420
00:47:12,400 --> 00:47:20,160
is high at just kind of a first pass layer however as we start to think about richer or

421
00:47:20,160 --> 00:47:29,680
more specified statistical patterns generative models there become dependencies that are sparse

422
00:47:29,680 --> 00:47:36,960
but important amongst all different kinds of things so things that are variable from a sensory

423
00:47:36,960 --> 00:47:45,920
perspective provide high information gain potentially to one part of a generative model

424
00:47:46,800 --> 00:47:57,520
like a screen and static but then other events might be less variable from a sensory perspective

425
00:47:57,520 --> 00:48:03,600
but smaller differences even in that variable relate to some other component of uncertainty

426
00:48:04,320 --> 00:48:10,720
resolution from some other component of the the model like those are going to be the cases where

427
00:48:11,680 --> 00:48:18,640
cognitive modeling does differ from just dispersed decision-making however they're

428
00:48:18,640 --> 00:48:26,800
both going to result in dispersed decision-making profiles like looking at the choices in the

429
00:48:26,800 --> 00:48:35,520
figures but the choices to sample from the less ambiguous parts of the actual distribution

430
00:48:36,320 --> 00:48:45,600
that leads to a much narrower policy path in this cognitive control setting versus in a variability

431
00:48:45,600 --> 00:48:52,560
sampling where it would go for the areas that were just more variable but not necessarily

432
00:48:52,560 --> 00:48:55,760
providing more information question mark

433
00:48:59,280 --> 00:49:01,840
and you can add on this with the maximum entropy or anything

434
00:49:03,200 --> 00:49:10,320
and I would even highlight kind of on the next slide it effectively what it is doing is accepting

435
00:49:10,320 --> 00:49:16,640
that you're not going to gain a lot of resolution in these highly variable regions and so you don't

436
00:49:16,640 --> 00:49:22,720
really have to sample into those deeply because you've accepted that it is variable it is not

437
00:49:22,720 --> 00:49:27,840
something it is inherently variable in the data we're not going to gain a lot of information

438
00:49:27,840 --> 00:49:34,080
from these regions and it's highlighted in blue down there and I think that's one of the big highlight

439
00:49:34,080 --> 00:49:41,120
notes of this figure is this less information gain available in these highly available regions

440
00:49:41,120 --> 00:49:47,760
and that's something that makes this method more robust and powerful when you're dealing with some

441
00:49:47,760 --> 00:50:00,160
of these non-uniform variable data yeah awesome and then the the um streetlight effect is brought in

442
00:50:00,160 --> 00:50:05,360
there so the avoidance of sampling in ambiguous locations is sometime referred to as a streetlight

443
00:50:05,360 --> 00:50:10,480
effect the tendency to search where data are generated in a minimally ambiguous way i.e.

444
00:50:10,480 --> 00:50:18,000
under streetlamp compared to searching elsewhere on a darkened street so I made some GPT-40 images

445
00:50:18,800 --> 00:50:25,520
some fun streetlight and on one hand there's kind of this sense of like is it constraining to look

446
00:50:25,520 --> 00:50:30,640
under only the streetlight isn't that kind of absurd and then there's the joke about how what

447
00:50:30,640 --> 00:50:35,040
the person's looking for is elsewhere but they're still searching under the streetlight

448
00:50:35,040 --> 00:50:38,560
but they're looking for something they they know is elsewhere so that's the kind of

449
00:50:38,560 --> 00:50:44,480
tragic element of it then there's this limited element however there's also this realistic element

450
00:50:44,480 --> 00:50:51,120
which is like well are you supposed to search where you can't sense or outside of where you

451
00:50:51,120 --> 00:50:58,880
are at that moment so how could you you know say that that wasn't just and then this paper is more

452
00:50:58,880 --> 00:51:07,280
framing it as just a general condition of perception like you're in your tactile streetlight

453
00:51:07,360 --> 00:51:14,640
that is the part you can see at all you can have latent modeling of any and other things

454
00:51:14,640 --> 00:51:20,960
but if it's not grounded in some way to a measurement made in a streetlight under the

455
00:51:20,960 --> 00:51:26,080
metaphor where the light allows for observation then you're not connected to data unless you're

456
00:51:26,080 --> 00:51:31,200
connected to that streetlight so that's just a very interesting kind of topic and and reference

457
00:51:31,200 --> 00:51:36,160
that the authors use what do you think absolutely I mean it kind of boils down to you can't

458
00:51:36,160 --> 00:51:41,520
know what you don't know what you can't observe you know if you can only observe what's underneath

459
00:51:41,520 --> 00:51:46,240
the streetlight then you can't really know what else is outside of there and so your inference

460
00:51:46,240 --> 00:51:51,360
necessarily should be constrained to what you're able to actually observe you can't observe the

461
00:51:51,360 --> 00:51:57,440
unknown and so not necessarily in this case um because you don't even know if it even exists

462
00:51:57,440 --> 00:52:05,280
you have no data to confirm or to refute it all right section five dynamic processes so

463
00:52:06,080 --> 00:52:10,720
in that previous example there was a data selection challenge whether it was approached

464
00:52:10,720 --> 00:52:16,400
from the flat fixed prior or all these other kind of subsequent variants with the adaptivity

465
00:52:16,400 --> 00:52:22,320
and or with the cost now there's going to be a time element brought into the underlying

466
00:52:22,320 --> 00:52:26,960
generative model we'll just go quickly here because that's the big point they take the static

467
00:52:26,960 --> 00:52:33,120
distribution that was sampled from and now give the underlying process also variability

468
00:52:33,120 --> 00:52:40,800
through time so this is like a very SPM brain latent state causal modeling type set yeah anything

469
00:52:40,800 --> 00:52:46,880
you want to say on that before we go in oh no go ahead okay okay so they consider processes that

470
00:52:46,880 --> 00:52:52,720
evolve in time equation 12 can be interpreted similarly to equation eight in which the expectation

471
00:52:52,720 --> 00:52:57,680
of the data is treated as a function approximation which now includes a time argument so here was eight

472
00:52:58,320 --> 00:53:05,040
expectation of the data given latent state parameterization and policy equals so on

473
00:53:05,840 --> 00:53:12,880
and then here there is data also being a function of parameterization and policy

474
00:53:12,880 --> 00:53:20,480
and then also bringing in an element with a subscript tau for time uh then you mentioned in

475
00:53:20,480 --> 00:53:28,160
your big questions the different approaches that they raise here with the three ways to

476
00:53:28,960 --> 00:53:33,440
bring temporalities into a model so let's definitely talk about that but just to show

477
00:53:33,440 --> 00:53:41,920
their images seven and eight are the pair for this dynamical section so figure seven shows a

478
00:53:41,920 --> 00:53:46,560
graphical representation of the matrices involved in generating our data and the inferences obtained

479
00:53:46,560 --> 00:53:54,720
after sampling so here it is sampling from a time variance function and then figure eight goes into

480
00:53:54,720 --> 00:54:01,280
more detail and notes predictions based upon current data can be used to inform predictions

481
00:54:01,280 --> 00:54:06,400
about nearby spatial locations and to predict and post it the values of the function at different

482
00:54:06,400 --> 00:54:15,520
points in time so just like you could have a 2d plane grayscale and infer the location of the

483
00:54:15,520 --> 00:54:20,320
streetlight by pursuing like a gradient up the light and then there would be this optimal

484
00:54:20,320 --> 00:54:25,760
sampling like if you just got one observation you would want to sample on a line that was

485
00:54:25,760 --> 00:54:30,800
orthogonal to the one that you couldn't resolve lots of ways to think about this sequential

486
00:54:31,440 --> 00:54:35,120
prediction but now the underlying landscape also changes so there's some

487
00:54:36,000 --> 00:54:40,880
temporal dynamics and then that can be fit with all these different time series models and

488
00:54:41,600 --> 00:54:47,200
autocorrelation and so on however that's specified statistically in the generative model

489
00:54:47,200 --> 00:54:51,840
but this section just shows however you do make a statistical model for time

490
00:54:53,360 --> 00:54:59,760
it's basically going to be the same thing where information is going to be drawn from a distribution

491
00:54:59,760 --> 00:55:06,160
and now time is a variable in that distribution uh they write in this in the previous section we

492
00:55:06,160 --> 00:55:10,400
have demonstrated the way in which smarter optimal sampling may be used to select data

493
00:55:10,400 --> 00:55:15,440
in a manner that balances the cost of sampling or performing further experiments against the

494
00:55:15,440 --> 00:55:20,560
information gained from those samples or experiments each of these examples has relied

495
00:55:20,560 --> 00:55:25,680
upon relatively simple and analytically comfortable linear Gaussian systems next we address active

496
00:55:25,680 --> 00:55:32,640
sampling in a situation where analytical solutions are no longer possible so to highlight the key

497
00:55:33,600 --> 00:55:40,320
formalisms that they're working with in that kind of background section uh or setup section

498
00:55:41,680 --> 00:55:47,760
they kept one thing constant which was that the the generative model the generative process or

499
00:55:47,760 --> 00:55:54,720
however it's considered with the family of equations that the agent is inferring and tracking hidden

500
00:55:54,720 --> 00:56:00,080
states with and that being the same as the actual family of equations that's generating

501
00:56:00,720 --> 00:56:09,440
the function of observations and here that is relaxed so that opens it up to all empirical

502
00:56:09,440 --> 00:56:15,920
settings where you can just say right off the bat we do not have access to the generative model of

503
00:56:15,920 --> 00:56:20,800
those data so we're making a map statistical map with all the associated trade-offs and

504
00:56:20,800 --> 00:56:28,400
statuses of like that genetic data or that transcriptomic data all those different kinds

505
00:56:28,400 --> 00:56:34,960
of data sets starting from a position where it's going to have to be statistically approximated

506
00:56:35,760 --> 00:56:41,680
and it isn't going to be based unless explicitly otherwise on actual knowledge about the causal

507
00:56:41,680 --> 00:56:49,600
elements of the system any any thoughts on that well in something else that they noted in the paper

508
00:56:49,600 --> 00:56:56,240
by adding this time element when they're actually going through the time series the model itself will

509
00:56:57,040 --> 00:57:04,400
preferentially select different data beyond what it just recently selected so time point one it

510
00:57:04,400 --> 00:57:11,120
selects x and y data time point two it might select l and m data so it actually will go through and

511
00:57:11,120 --> 00:57:17,920
select different types of data and it'll take a little bit of time um what the time is variable

512
00:57:17,920 --> 00:57:23,920
but it'll take a little bit of time before it revisits some of that previous data um at a

513
00:57:24,000 --> 00:57:28,560
previous time so by this you kind of have a sliding window of data that you're selecting

514
00:57:28,560 --> 00:57:37,680
over different time periods yeah all right that's all going to come to play in this clinical trial

515
00:57:38,320 --> 00:57:45,200
which is the big final contribution section of the paper in our final example we demonstrate the

516
00:57:45,200 --> 00:57:51,600
potential utility of the ideas outlined above in the context of a more concrete example so

517
00:57:51,600 --> 00:57:59,840
they model the statistical setting here as an adaptive Bayesian clinical intervention methodology

518
00:57:59,840 --> 00:58:07,280
experiment for example the kind that was done during the 2014 West African Ebola outbreak

519
00:58:08,240 --> 00:58:13,120
the active sampling approach advocated in this paper offers two main opportunities to augment

520
00:58:13,120 --> 00:58:20,000
adaptive trial designs first it allows us to adapt the design to maximize the information we obtain

521
00:58:20,000 --> 00:58:26,240
about treatment efficacy so that's the pure sense making information gain learning sampling from

522
00:58:26,240 --> 00:58:32,320
where it's informative not from where like we habitually or prefer to look and then second

523
00:58:33,120 --> 00:58:41,440
to balance and bring together that information gain with costs and that was brought in with

524
00:58:41,440 --> 00:58:48,640
the cost of the sampling section which was done in this paper by adding the stop policy option

525
00:58:48,640 --> 00:58:54,960
which can be probabilistically selected and then as other sampling locations become less

526
00:58:54,960 --> 00:58:59,920
informative or if somebody was just sampled and you know that there's a slow decay through time

527
00:58:59,920 --> 00:59:09,440
then on that subject the stop policy cost would outweigh the information gain from an experiment

528
00:59:10,640 --> 00:59:17,440
and this is also I think will be a very interesting discussion this blows the line between clinical

529
00:59:17,440 --> 00:59:22,640
trial and public health intervention and can be seen as analogous to animal behavior that is never

530
00:59:22,640 --> 00:59:29,120
fully exploitive or explorative but is a balance between the two so how do we think about that

531
00:59:29,120 --> 00:59:35,760
in terms of biomedical and health security and all these different topics and any thoughts on this

532
00:59:35,760 --> 00:59:40,800
before we go into the formalism of the clinical trial just like about clinical trials or anything

533
00:59:40,800 --> 00:59:47,200
yeah and I think that that's going to be like that last point there is going to be a big one

534
00:59:47,200 --> 00:59:52,960
going forward of like how do you balance benefits to the patient benefits to your trial benefits to

535
00:59:54,400 --> 00:59:58,960
essentially the company like there's a lot of different benefits and costs that you have to

536
00:59:58,960 --> 01:00:05,760
weigh into this and so these models are going to get very complicated when you start to distill

537
01:00:05,840 --> 01:00:12,480
this into something especially with health related so it'll be very interesting to see how this evolves

538
01:00:15,200 --> 01:00:22,240
okay so here's how they do it our setup is as follows for each new cohort of participants

539
01:00:22,240 --> 01:00:30,640
we decide upon the randomization ratio to adopt that's the orange subscript r of policy so this

540
01:00:30,640 --> 01:00:38,480
is policy on a randomization ratio there's three options so this is a discrete but linearly ranked

541
01:00:38,480 --> 01:00:47,600
not fully categorical policy decision where one half would be the 50-50 sampling between the two

542
01:00:47,600 --> 01:00:57,920
groups whereas you know a priori that sampling in a skewed ratio is going to be less informative

543
01:00:57,920 --> 01:01:02,480
like if you sampled only from one you would obviously be maximally uninformed about the other

544
01:01:02,480 --> 01:01:10,320
however what's going to end up being reflected in the policy decision to shift to a one-third or

545
01:01:10,320 --> 01:01:16,880
a two-third which is focusing observations on one branch of the study more than the other

546
01:01:16,880 --> 01:01:22,720
is going to focus on the explicit quantitative preference for observations of survival

547
01:01:23,520 --> 01:01:29,440
so that's going to be very interesting to see how the time variable which relates to the

548
01:01:29,440 --> 01:01:38,480
experimental design but by way of modeling the death curves of the participants and how different

549
01:01:38,480 --> 01:01:45,440
preferences for complementary processes of reducing uncertainty about the treatment specific

550
01:01:45,440 --> 01:01:52,480
death curves and not preferring to see death observations because that would introduce the

551
01:01:52,480 --> 01:01:59,680
pragmatic imperative to measure low survival experiments so there's a lot of complexity

552
01:01:59,680 --> 01:02:07,120
in there from the public health side also in this very simple and interpretable way that like this

553
01:02:07,120 --> 01:02:14,240
is like a Bayesian light switch with 50-50 information seeking mode or tilt it one way or

554
01:02:14,240 --> 01:02:21,360
the other to bias observations whereas if no information had to be resolved then the policy

555
01:02:21,360 --> 01:02:28,480
selection would orient towards observing long survival whereas if that was somehow changed

556
01:02:28,480 --> 01:02:32,960
then it would have to be adaptively sampled on the fly and changing these ratios and all that

557
01:02:32,960 --> 01:02:37,360
what do you what do you think about this yeah and what we're going to kind of get into is

558
01:02:39,120 --> 01:02:44,400
especially with these sorts of health decisions you want people to survive like that's your

559
01:02:44,400 --> 01:02:49,200
that's your primary goal in a lot of these you want to see an effect you want to see a positive

560
01:02:49,200 --> 01:02:54,560
effect of your treatment one way or the other you know if it's the placebo that's the positive or

561
01:02:54,560 --> 01:02:59,600
it's the actual treatment that's the positive you want people to survive so this is kind of

562
01:02:59,600 --> 01:03:05,760
getting into that ethics of making sure that when you design these things that you're doing the

563
01:03:05,760 --> 01:03:13,600
maximum good to your participants who you know may not have you know much hope to stand on

564
01:03:14,560 --> 01:03:20,400
doing some of these crises or epidemics or whatever they are experiencing at the time

565
01:03:22,160 --> 01:03:27,840
so you want to design this in such a way that you know you keep them the patients in mind

566
01:03:27,840 --> 01:03:35,920
that is the whole point of this and so by having a Bayesian kind of preference and bias to keeping

567
01:03:35,920 --> 01:03:43,120
the patient alive and the best outcome you're maximizing how the patient's outcome in the

568
01:03:43,120 --> 01:03:50,000
patient's life thanks for adding that another point to make this is from figure nine that's

569
01:03:50,000 --> 01:03:56,960
gonna come up but it really highlights how sparse and few and interpretable the Bayesian

570
01:03:56,960 --> 01:04:02,240
graphical formalism is and message passing which a lot of the equations describe and

571
01:04:02,240 --> 01:04:08,960
the discussion about rx and fur touched upon message passing gives procedural ways to implement this

572
01:04:09,920 --> 01:04:15,200
in computational systems because it's sometimes hard to go from the simplicity of like this

573
01:04:15,200 --> 01:04:22,960
graphical model to fitting it iteratively on complex data sets but it's pretty clear to see

574
01:04:23,040 --> 01:04:29,520
how different variables are upstream or downstream of other variables and also how the time

575
01:04:31,440 --> 01:04:39,120
sampling can be shown to be which is the upstream of data sampled as these other factors are

576
01:04:40,080 --> 01:04:49,440
but it has a separable interpretable calculable epistemic value that doesn't have a certain kind

577
01:04:49,440 --> 01:04:55,440
of connection to randomization ratio for example so being able to have explicit statistical

578
01:04:55,440 --> 01:05:03,280
calculations and directnesses where the follow-up time doesn't influence the treatment group ratio

579
01:05:03,280 --> 01:05:10,320
or the randomization ratio or other processes gives a type of interpretability that the

580
01:05:10,320 --> 01:05:16,320
generative model gives us the equations for and then the pragmatic challenges are about actually

581
01:05:16,320 --> 01:05:21,440
implementing that and then even if the computational component were totally addressed and abstracted

582
01:05:21,440 --> 01:05:27,520
away that would basically center these broader questions which i think the health example is

583
01:05:27,520 --> 01:05:34,160
a great like jumping off point four yeah and uh you have probably recalled from all the other

584
01:05:34,160 --> 01:05:41,520
different uh figures despite how simple this figure is the other figures the the plots were very

585
01:05:42,000 --> 01:05:47,920
basic the models themselves like you just had the three nodes you know converging on the y so

586
01:05:47,920 --> 01:05:55,040
despite how simple this looks you are adding more complexity to these um to these systems and the more

587
01:05:56,080 --> 01:06:02,080
complexity that you add the harder it is the more computationally intensive it is and so this is

588
01:06:02,080 --> 01:06:08,560
that question of how big can you go you know how how many nodes can you add how many parameters

589
01:06:08,560 --> 01:06:13,360
can you add how much complexity can you add to the system before it starts to break down

590
01:06:13,360 --> 01:06:21,360
or not perform as well as you would hope yeah so other than bringing in that randomization ratio

591
01:06:21,360 --> 01:06:29,200
kind of expression of preference this model differs from the prior one in that it's defined

592
01:06:29,200 --> 01:06:34,240
that the kind of cognitive map is not the territory they're different families so that's

593
01:06:34,240 --> 01:06:40,880
what motivates this um approximation approach so this is a simple displacement where still it's a

594
01:06:40,880 --> 01:06:49,760
trackable problem as they'll unfold however the simulation family chosen for the for like the

595
01:06:49,760 --> 01:06:54,320
approximation basically the approximation could apply to any data set but it might be woefully

596
01:06:54,320 --> 01:07:00,880
inadequate like it might fit only one component of it so that's again part of the interesting

597
01:07:00,880 --> 01:07:08,880
question is like how similar does the statistical model have to be or what information does it really

598
01:07:08,880 --> 01:07:17,200
bring in and how to to model or work with an empirical side um but just on a more general

599
01:07:17,200 --> 01:07:25,040
statistical level equations 15 16 17 describe some of the technical details of the incremental

600
01:07:25,040 --> 01:07:31,440
optimization gradient scheme the newton optimization variational plus we'll talk to

601
01:07:31,440 --> 01:07:39,920
thomas et al figure nine is displaying the kind of before picture for the randomized control

602
01:07:39,920 --> 01:07:47,120
trial so here's where that graphical model is that was shown earlier and then here are these two

603
01:07:47,840 --> 01:07:54,640
groups and their survival through time and different sampling uh choices that are made

604
01:07:56,000 --> 01:08:04,000
then just to to jump to figure 10 has the same layout as figure nine but now using the expected

605
01:08:04,000 --> 01:08:09,520
information gain from equation 18 to guide sampling of data so this is just to show the

606
01:08:09,520 --> 01:08:15,200
impact of that active data sampling and it will drop back to the equation uh there are some notable

607
01:08:15,200 --> 01:08:24,720
differences between the choices made in figure 10 compared with nine nine choices 10 uh the most

608
01:08:24,800 --> 01:08:30,480
obvious of these is that the follow-up time selected have been moved later once optimal sampling is

609
01:08:30,480 --> 01:08:36,000
employed this makes intuitive sense as a later follow-up time is informative about the survival

610
01:08:36,000 --> 01:08:40,720
probabilities at all prior times whereas an earlier follow-up time is not informative about

611
01:08:40,720 --> 01:08:54,240
survival probabilities at later time um where it gets in the final uh simulation brings in the

612
01:08:54,240 --> 01:09:03,120
random sampling plus the preference element here's where the symmetry is broken to also want the

613
01:09:03,120 --> 01:09:08,160
measurement of survival as more likely than death which is how the preferences are specified

614
01:09:08,720 --> 01:09:18,320
in active inference um and then the policy switch is reflected in this like um part where

615
01:09:18,320 --> 01:09:24,960
the observations are shifted later because there's there's less than a threshold of information to

616
01:09:24,960 --> 01:09:31,840
gain by having them earlier and then they uh even if there is equal variance i'm not exactly sure we

617
01:09:31,840 --> 01:09:38,960
can ask between the two branches there is uh an over sampling for the group with the higher

618
01:09:38,960 --> 01:09:46,160
survival which in this case was the placebo group so anything to add on this preference element

619
01:09:46,160 --> 01:09:53,440
this is the the like the crux of the whole making sure that you optimize you know the patient's

620
01:09:53,440 --> 01:09:59,040
outcome on this because the treatments in this scenario were not um were not beneficial they're

621
01:09:59,040 --> 01:10:04,960
actually harmful and so throughout the course of the study this by utilizing this model you

622
01:10:04,960 --> 01:10:11,840
actually randomized more people into the placebo group which caused a greater survival of these

623
01:10:11,840 --> 01:10:18,640
uh individuals and so you're you can already see the effect that this sort of methodology has on

624
01:10:18,640 --> 01:10:24,720
clinical trials because you're optimizing the outcome and i think that is exactly what you want

625
01:10:24,720 --> 01:10:31,440
to do in these health decisions in these trials in these things that impact human health uh or

626
01:10:31,440 --> 01:10:38,480
humanity in general you want to optimize the outcome uh and you know in this way you're actually

627
01:10:38,480 --> 01:10:48,320
reducing the overall harm to patients yeah interesting um here's the specification for the

628
01:10:48,320 --> 01:11:00,400
information gain so uh bringing in the the form of the message is required for equation three now

629
01:11:00,400 --> 01:11:06,720
with all these extra components that have been added in with time variability demographic and the

630
01:11:06,720 --> 01:11:15,760
sampling they write out some of the technical details for the approximations in the variational

631
01:11:15,760 --> 01:11:23,680
Laplace and then some aspects about those models which we can ask about but figure 11 basically

632
01:11:23,680 --> 01:11:32,640
shows the big change which is that uh as you go from having a a flat sampling distribution

633
01:11:33,920 --> 01:11:40,640
across time and across treatment groups you can actually do better than that basically by choosing

634
01:11:40,640 --> 01:11:49,120
a sampling regime that makes sense given the costs of sampling so that's just very interesting

635
01:11:49,120 --> 01:11:54,560
because it it really does look like given the the possibility for these two lines to diverge

636
01:11:55,440 --> 01:12:01,760
their divergence would be largest later on whereas if you could only schedule like one

637
01:12:02,320 --> 01:12:07,440
check for every person if it was something that was expected to happen later in life

638
01:12:07,440 --> 01:12:16,160
then sampling all the young wouldn't even make sense so then one approach is like flat

639
01:12:16,160 --> 01:12:23,280
sampling but that is kind of sometimes erroneously called uh like unbiased or or uninformative but

640
01:12:23,280 --> 01:12:29,440
it is very informative and then this is pointing towards how there can be better sampling than

641
01:12:29,440 --> 01:12:37,840
just trying to go flat across the entire latent state estimate if there are priors relating to

642
01:12:37,840 --> 01:12:44,400
something they can be leveraged as part of the probabilistic sampling and adapted to the

643
01:12:44,400 --> 01:12:52,240
data set at the in the end however for picking prior families for the active data selection

644
01:12:52,480 --> 01:12:59,760
that's a big question about how much it will change how the algorithms work so I guess that kind of takes us to the

645
01:13:01,120 --> 01:13:07,280
discussion the paper's focus has been on illustrating how we might make use of

646
01:13:07,280 --> 01:13:12,960
information seeking objectives augmented with costs which gave kind of the exit criterion or

647
01:13:12,960 --> 01:13:19,440
preferences which gives the biased pragmatic part of data selection to choose the best data to

648
01:13:20,400 --> 01:13:28,800
optimize our inferences and they highlight that the maximum entropy would yield identical results

649
01:13:29,680 --> 01:13:34,400
in several of our examples so that'll be interesting like what were the examples where

650
01:13:34,400 --> 01:13:41,360
maximum entropy and the information gain are identical and then what are the real world

651
01:13:41,360 --> 01:13:47,520
or the statistical settings when the variance around predicted outcomes is in homogeneous

652
01:13:48,480 --> 01:13:59,040
how does the full cognitive epistemic model based objective do differently than the max and

653
01:14:00,640 --> 01:14:06,480
distribution dispersal kind of null hypothesis any thoughts on this

654
01:14:08,640 --> 01:14:15,440
no I think you've captured it very well okay then there are several technical points worth

655
01:14:15,440 --> 01:14:19,760
considering for how we might advance the concepts reviewed in this paper so let's talk about each

656
01:14:19,760 --> 01:14:26,800
of these one refinement of the active selection process two empirical evaluation of active versus

657
01:14:26,800 --> 01:14:33,520
alternative sampling methods and three identifying the appropriate cost functions so we'll talk about

658
01:14:33,520 --> 01:14:42,320
those coming up conclusion here's the entire conclusion the key ideas involved in appeal

659
01:14:42,320 --> 01:14:48,080
to foveal like sampling of small portions of the total available data to minimize computational cost

660
01:14:48,720 --> 01:14:56,080
that's a very cool way to put it and it highlights that kind of like sequential scanning but also

661
01:14:56,080 --> 01:15:03,200
opens up some very exciting directions about how efficient that could be for some but not

662
01:15:03,200 --> 01:15:08,560
other kinds of problems and how those problems could be identified or those patterns could be

663
01:15:08,560 --> 01:15:15,040
filtered for to where different kinds of succating models would be adaptive or not so like these are

664
01:15:15,040 --> 01:15:21,680
all fun discussions we'll have and then they kind of brought all the theoretical components together

665
01:15:21,680 --> 01:15:28,880
at the end with the Bayes adaptive clinical trial with the cost of sampling constraints on

666
01:15:28,880 --> 01:15:37,600
sampling and also the preference for survival so what are your overall thoughts or what are you

667
01:15:37,600 --> 01:15:43,840
excited about for the ones to come I'm excited to kind of see me I mean this is a fairly recent

668
01:15:43,840 --> 01:15:49,280
paper I'm excited to see kind of where they have gone since this paper was published you know they

669
01:15:49,280 --> 01:15:56,080
had a number of kind of next directions I would love to see what of those directions have they've

670
01:15:56,080 --> 01:16:04,880
taken what they've compared it to other other sampling techniques this show shows a lot of promise

671
01:16:04,880 --> 01:16:12,640
going forward for very complex and you know ethical situations or situations where ethics

672
01:16:12,640 --> 01:16:19,760
are going to be a huge component so kind of where that is what they're going into and kind of where

673
01:16:19,760 --> 01:16:26,160
they see you know further improvements I still kind of want to know what would happen or what

674
01:16:26,160 --> 01:16:33,440
of these other time metrics or what are the situations these time metrics would or alternative

675
01:16:33,440 --> 01:16:40,800
time models would be applicable to or if this really is like the de facto just the way it needs

676
01:16:40,800 --> 01:16:46,800
to be done totally totally fair I think that could very well be the case I would just love to hear

677
01:16:46,800 --> 01:16:52,480
exactly you know if you did a hidden Markov model how would that look you know is is there a benefit

678
01:16:52,480 --> 01:16:58,880
of that over the selection that they have is there does it provide more or less versatility in the

679
01:16:59,120 --> 01:17:04,080
models these are things that are going to be I think very interesting going forward and then

680
01:17:05,280 --> 01:17:11,680
you know how do we like the like you noted in the discussion how do you optimize those cost

681
01:17:11,680 --> 01:17:16,880
functions what's what's a cost you know you're dealing with clinical trials it's a human life

682
01:17:16,880 --> 01:17:22,960
that's a cost time it's a cost there's also just computer time how much you can actually get

683
01:17:23,520 --> 01:17:29,520
how much compute you can get and give them all the time some of these machine learning models

684
01:17:29,520 --> 01:17:35,440
that you might want to apply this to or you know select data going into sometimes takes a long

685
01:17:35,440 --> 01:17:42,800
time to train how are you going to sample data that's going into those models how are you going

686
01:17:42,800 --> 01:17:50,960
to continually feed those models appropriate data going forward so this is a huge broad category of

687
01:17:51,840 --> 01:17:59,200
um directions that you can go clinical trials was a very wonderful example of a complex situation

688
01:17:59,200 --> 01:18:06,240
that is you know right there applicable to human life um but then you also have just data science

689
01:18:06,240 --> 01:18:11,840
in general like how are you going to utilize this to you know going more broad how are you

690
01:18:11,840 --> 01:18:17,200
going to utilize this just going forward in any data sense data is growing it'll continue to grow

691
01:18:17,200 --> 01:18:22,560
it will never really stop growing so it's going to be more and more important going forward to

692
01:18:22,560 --> 01:18:31,920
have these methods more broadly used and random's nice random's really really good but this holds

693
01:18:31,920 --> 01:18:37,920
a lot of promise to being I would love to just hear their thoughts on where that's going where

694
01:18:37,920 --> 01:18:47,520
they see that yeah a lot of a lot of interesting directions a few things that made me think of

695
01:18:47,520 --> 01:18:53,040
one was about search and about relational search concepts page rank and everything

696
01:18:53,040 --> 01:19:00,480
syntactic semantic new kinds of search algorithms and personalization for search and learning and

697
01:19:00,480 --> 01:19:06,320
updating and to what extent like explicit cognitive modeling would change the way that

698
01:19:06,320 --> 01:19:13,200
different recommendation algorithms or different kinds of computer systems would work I'll read

699
01:19:13,200 --> 01:19:19,120
a question um and then any any other questions otherwise this is our our last slide so thank

700
01:19:19,120 --> 01:19:27,440
you Christopher um okay glia maximalist wrote interesting point about biased and unbiased

701
01:19:27,440 --> 01:19:32,400
sampling schemes perhaps this points out the fact that unbiased approaches are the wrong

702
01:19:32,400 --> 01:19:39,760
thing to strive for in research study design what do you think about that unbiased research

703
01:19:39,760 --> 01:19:45,920
in study design um I think there's a time and place for unbiased and I think there's a time

704
01:19:45,920 --> 01:19:52,400
and place for bias I think that but you when you accept a bias into your model or refute

705
01:19:52,400 --> 01:19:58,800
take bias out of your model you need to understand why you're doing certain bias you don't want to

706
01:19:58,800 --> 01:20:04,560
have you know researcher bias is something that's a huge bias that you want to not have for example

707
01:20:06,080 --> 01:20:11,200
but in certain cases um like in this paper where you actually do want to have a bias

708
01:20:11,920 --> 01:20:16,720
you want to make an intelligent decision know why you're making that decision call it out and then

709
01:20:16,720 --> 01:20:22,800
build it into your model that would be my problem yeah that's interesting like there are certain

710
01:20:22,800 --> 01:20:27,920
statistical distributions the bias or the constraints on which to find the research study

711
01:20:28,000 --> 01:20:34,880
whereas other ones that can have an explicitly strictly negative like data loss or something

712
01:20:34,880 --> 01:20:40,960
but then the trade-offs of how that distribution actually interacts with others can enter into

713
01:20:40,960 --> 01:20:47,200
this more complex experimental calculus that relates to like well all these different

714
01:20:47,200 --> 01:20:55,200
experimental factors and so the optimal experiment for for different labs or different

715
01:20:55,280 --> 01:21:00,080
moments for the lab could look extremely different and that's going to be the case

716
01:21:00,720 --> 01:21:03,840
there's going to be just first behavior out of the way but then the question is how is that actually

717
01:21:03,840 --> 01:21:12,880
driven in a way that is doing better than drawing from distributions however even that does interestingly

718
01:21:12,880 --> 01:21:22,400
well for the right variables and you can mind bias all over the place I bias in data design

719
01:21:22,400 --> 01:21:28,160
in experiments is can be very useful so it'll just be interesting I think it'll be case by case

720
01:21:28,160 --> 01:21:29,040
it's the way I see it

721
01:21:35,920 --> 01:21:45,120
okay well do you have any last comments I think that the main thing here is I'm just very excited

722
01:21:45,120 --> 01:21:51,040
to see this paper come out I would love to see how this is going to evolve over time

723
01:21:51,040 --> 01:21:57,920
see if this can be applied to different technologies different areas I'm really excited

724
01:21:57,920 --> 01:22:04,320
just to see where this is going because I think this is just right on the cusp of what's needed

725
01:22:06,160 --> 01:22:14,720
awesome thank you okay we will look forward to it thank you see you all right thanks guys

726
01:22:21,040 --> 01:22:22,320
you

