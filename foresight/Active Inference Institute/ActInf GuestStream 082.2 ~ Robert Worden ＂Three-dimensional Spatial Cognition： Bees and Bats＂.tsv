start	end	text
0	16240	Hello and welcome. It is June 3, 2024. We're in active inference guest stream 82.2 with
16240	22880	Robert Warden. Today we're going to be discussing three dimensional spatial cognition, bees
22880	29000	and bats. So thank you Robert for joining again. To you for the presentation and looking
29000	35000	forward to it. Thanks Dan. Okay, well as Dan said, I'm talking about three dimensional
35000	42320	spatial cognition in small animals, particularly like bees and bats for examples. And what I'm
42320	47400	going to be doing is showing you a demonstration program that does this. And so you can find
47400	51840	the demonstration program at this link at the bottom of the picture, and you can download
51840	56560	it and try it yourself. Or you can read a couple of papers about this work, which are
56560	66360	there an archive at that address. So that is the introduction to get straight into it.
66360	72000	What this work represents, I think is a challenge for classical neuroscience. And by classical
72000	78040	neuroscience, I mean the assumption that all that happens in the brain or cognition is
78040	83480	done by neurons connecting to each other by synapses and so on. And the challenge, which
83480	88800	I think comes out of this work, is that the main result is that neurons are actually not
88800	94240	capable of that. They cannot represent three dimensional space, because they're too imprecise
94240	99880	and too slow. So the resulting challenge for neuroscience is to show that this idea is
99880	105560	wrong. Everybody thinks it's wrong. Everybody thinks neurons do everything. So you have
105560	112240	to show it's wrong by building a working model of neural computation model of 3d space and
112280	118800	checking that it really scales and can perform somewhat like animals perform. I think just
118800	122480	writing papers and talking about it is not enough. You've got to build a model and show
122480	130240	it works. And for building that model, the FEP neural process model is the best starting
130240	140520	point I believe. So that's where this talk is going. It gets there by 3d spatial cognition.
140520	149040	So what is that? Spatial cognition, as first say, is a very important problem. The primary
149040	154080	task of any animal brain is to control its movements, physical movements, its limbs,
154080	160280	in 3d. And that's a 3d problem. And it has to do that at all times of the day. And for
160280	166640	most animals, most of their brain is devoted to this problem. And we believe, being Bayesian,
166800	175960	they do this by building and using Bayesian maximum likelihood model of 3d spatial space. And my
175960	181240	previous live stream was about the subject how animals build models in general. But the
181240	186920	particular 3d model of space, that's been important since the Cambrian era, when animals
186920	194800	first started having precise sense data, like good eyes and capable limbs. And that there's
194840	201760	been huge and sustained selection pressure on all animal species since then, to do it well. And
201760	207240	what we believe is that animals do do it rather well. For instance, our own conscious awareness
207240	213120	of 3d space must come from something going on in our brains. And that is a rather precise model
213120	219160	in our conscious awareness of 3d space around us. So that must be quite a good model of space
219280	225240	in our heads. And going from us to small insects, even the small insect can land very
225240	232240	skillfully on the room of a coffee cup or any other surface. So that's why I say modeling
232240	239640	3d spatial cognition is the top priority for neuroscience. And we may look at all sorts of
239640	245480	problems in neuroscience. This is the one, this is the hard part of the problem, the thing we
245480	251800	really need to get right. So how do you do it? How do animals build a 3d model of local space
251800	257560	around them? And the immediate problem is that most of their sense data in their vision is
257560	262720	two dimensional. So how do you get from two dimensional vision to three dimensional model of
262720	268840	space? There are some constraints and people obviously think of stereopsis with two eyes,
268840	274360	where you can tell the depth of things or proprioception and touch. But those constraints
274840	280280	only apply to restricted regions of the space around an animal. So for the rest of it,
281240	286120	what I believe animals do is they build a model of the space around them by moving in space. And
286120	291640	this is a form of active entrance, if you like, that you have to move in a moving space to find
291640	300040	out about space. And this is based on a very strong Bayesian probability that as an animal's move,
300760	306600	most of the things around it do not move. So the world is like a big rigid moving body
306600	312120	around the animal. So the animal can compute object locations by what is called structure from
312120	318120	motion, SFM. And when you build a computational model of this, it's actually fairly simple
318120	326280	computation to do. What you can do is fairly simple 3d matrix operations to maximize the likelihood
326360	329880	of an object being in a certain position. And that's what this program does.
330680	336920	But if you're doing that, shape from motion, structure from motion, it requires a short
336920	342120	term spatial memory of working memory for positions of things. And that's what this
342120	347400	demonstration program does. So the demonstration program
348360	354680	that gives them both the echo delay and it gives them a Doppler shift. And we'll talk about that
354680	361320	later. So both of those animals move fast among static objects. So this 3d shape from motion
361320	365320	is an applicable way of working out where the objects are. So we're going to go ahead and
365320	370520	move on to the next slide. So we're going to go ahead and move on to the next slide.
370840	376520	So this 3d shape from motion is an applicable way of working out where the objects are.
377640	381320	So the program we're going to show you builds a 3d model of space in three
382120	388440	different ways. Firstly, it can build an optimal Bayesian shape from model model model.
389080	396920	That is what I call a brute force calculation. I've discussed those in my previous live stream.
397640	402040	And it's very hard for animals to do. It's not the way we think animals do it. But
402040	406520	the interesting thing about it is it gives you the very best possible Bayesian model
407320	413640	based on the sense data. So that's the first way. The second way is by dynamical object tracking
413640	419800	where an animal makes an estimate of where each object is in three dimensions. And then it keeps
419800	425480	updating their estimate every time, from every step along the track it takes. It updates that
425480	434360	estimate from its sense data. And the third model is doing that same object tracking,
434360	440440	but doing it in the presence of neural memory noise. I should say this computational model is
440440	446520	built at Mars level, David Mars level two. That is, it's not a neural implementation,
446520	453880	but I have made it so that you can add simulated neural noise to it. So if you want to see this
453880	460680	program after you've seen demonstrated, download it from this web address and you can
460680	468440	quite simply unzip it and start it running. So I will now switch to demonstrating this program.
469960	478360	So I end the show and there is the program. That's what it looks like. And what you see is
478360	484200	three different windows, the left center and right. The left hand window is going to be a
484200	490520	three dimensional view of some space in which a B or a bat is moving. The center view is always just
490520	496920	help information and it tries to tell you how to use all these sliders and buttons and controls.
496920	502920	And the right hand view is just various graphs and we'll see some of those as we go along.
502920	509960	So what happens when you press the start button is you see some three dimensional space and inside
509960	519080	it there on the left hand side is an animal this time of B and the colored circles are objects
519080	526600	randomly spaced in that space. And so the line is going from the B to the objects are lines of
526600	532760	sight. And this is a three dimensional view so you can rotate it, see the three dimensions and
532760	539480	that's what happens when you rotate the objects rotate. And so there at the moment we've got
539480	545320	nothing about the B's internal model of space. We've only got actual space itself shown in the
545320	551960	view. In order to show the B's internal model of space we press the run button and I'll do this
551960	557240	and you can see what happens. So as you press run the B starts moving that's the green line.
557800	563800	It gets new lines of sight and from the new lines of sight it estimates the positions of all those
563800	572680	objects. So I'll restart and do that again. And what you'll see this time is that the estimates
572680	580120	of the positions appear as small circles with error bars. So the error bars are the gray lines
580120	585320	the small circles are where the B thinks the object is. So you can see the B is building
585320	591400	rather an accurate model of where the objects are from its sense data. I'll restart again and this
591400	599080	time we'll step through it one step at a time to see how the B's model of space evolves with time.
599080	606280	So one step and you can see in the very early steps we'll rotate it a bit to see show what's
606280	611960	going on. The B starts making really quite good estimates of where the objects are.
612920	619000	Each little white circle is quite close to the blue circle but the estimates have error bars
619000	624120	and the error bars are in three dimensions showing the uncertainty of the location estimate in all
624120	630920	those dimensions. So those estimates of position that enable the B to move where it wants to do
631000	635160	suppose these are flowers it can go to the flowers and get pollen or whatever it wants to do.
636120	642280	Now I said the program computes three different kinds of model and these three is always doing
642280	648200	this as you go through the steps on the track and these three models are a full Bayesian model
648200	653480	and that's what we're showing at the moment full Bayesian. We can switch to a tracking model
654200	661960	that's the object dynamic tracking and there if I switch that you can see the error bars and the
661960	668600	objects hardly move at all they do move a little bit but this is one result of the program that
668600	675160	doing that tracking model which is simpler to do than the full Bayesian model gives you nearly the
675160	682840	same estimates and same error bars and the third model it computes is a tracking model with noise
682920	690600	and I switch to this one and again it's not moving very much actually but I'll move it on a bit and
690600	697800	you'll see that noisy tracking often is very different from tracking without noise so we're
697800	706680	on tracking without any noise at the moment we step forward a bit and the B keeps updating its
706680	712920	estimates of these positions as they go and I now switch from tracking to noisy tracking
714040	719880	and you can see the noisy tracking is significantly worse than tracking they noisy
719880	726520	estimates have drifted away from the true positions of the object and that is really the second
728600	733880	by the way I'm running this with a fairly small level of neural noise at the moment you can adjust
733880	739080	the level of neural noise you're going to adjust the bees visual acuity you adjust all sorts of
739080	744680	things using these sliders and try running the program again this is running with a fairly small
744680	755400	level of noise so I keep stepping and the noisy tracking estimate keeps getting worse but I go
755400	762360	back to the tracking estimate the tracking estimate without neural noise is pretty much dead on so
763320	770440	I'll restart again and I'll run again because then we can show the graph at the end of the run
770440	774920	which shows what's happened to these errors so if I run again
775720	792840	now you look at the graph on the right and what that is doing is comparing tracking which is the
792840	800440	black curve versus noisy tracking which is the red curve and these are steps along the bees
800440	806920	track those are the same steps we saw there but these vertical axis is the level of error in the
806920	813720	depth of the bee estimates and you can see that tracking is rather small errors it homes in on
813720	819480	true position of the object whereas with memory noise you get much bigger errors and in fact the
819480	827960	errors are very unpredictable if you rerun we'll just rerun it again you find that the errors
827960	834440	coming from noisy tracking they do seem to vary quite a lot from one run to the next noisy tracking
834440	839240	is pretty unpredictable basically so there the errors have gone right up and they've come down
839240	845560	again whereas ordinary tracking without noise is nice convergence towards the true positions
846440	854120	so that is really the second key result of the simulation that is that a tracking model is a
854120	860920	realistic model of how animals estimate positions of things around them but if you add noise to it
860920	865960	even adding a small amount of noise completely messes up the tracking model now there are more
865960	872840	things you can show with this model you can show for instance how animals use their model to detect
872840	878760	what is moving around them because obviously when an animal is moving it is quite hard for it to
878840	884600	detect motion from its visual field because when it's moving everything is moving in this
884600	891240	visual field so it has to use the three dimensional model to work out what is actually moving and
891240	898680	if you also plot the efficiency of motion detection you find that too is very much poorer
898680	906760	when you add memory noise so I think I'll stop at this point the program also does a simulation
906760	911720	of bats but I won't step straight into that perhaps we could come back to that at the end of the talk
911720	918680	if somebody wants to hear about it but for the moment let's just step back and find what we
918680	931800	have concluded from the bee's model now where is my presentation now I've got to resume the
931800	938520	presentation somehow how do I do that yeah you get back to the presentation
944600	950680	so the key points that I think I may have shown you is that in the 3d view you can see the track
950680	955560	of the animal you can see it's the lines of sight you can see sorry my phone is ringing I better
955560	963320	go and shoot it up
975160	979720	I've shown you the three I've shown you where the real objects are those are the circles the
979800	986600	colored circles shown you the objects as located in the internal model I've shown you shape from
986600	993640	motion I've shown you what the error bars are and you can rotate the 3d view I've shown you
993640	998920	the three different models of 3d space the full Bayesian model the dynamic object tracking model
998920	1007320	and the tracking model with memory errors as I say when you run this program you can change
1007320	1014040	all sorts of parameters to see how it's sensitive to the parameters and I've shown you the bee's
1014040	1019080	spatial model I've shown you how the error bars are particularly the depth dimension
1019880	1030360	and I've shown you how memory noise degrades the model so here are the key results so the best
1030360	1036520	possible model and any animal could build from its sense is a very good model in fact it's more
1036520	1045240	precise than the sense data because if the animal can assume that objects don't move then over time
1045240	1050200	an animal can build up a very good understanding of where objects are better than its raw sense data
1051400	1057480	animals can't do any better than that but dynamical object tracking works pretty well it's almost as
1057480	1064840	good as the full Bayesian model and it only works if spatial memory has very high precision and I
1064840	1072120	didn't say the levels of precision that I put into the program which start to spoil the tracking model
1072120	1079560	they're about one part in a hundred and that I believe is much more precise the most neural
1079560	1085960	representation of space can give so that's the next part of this talk how do we do that modeling
1085960	1093720	with a neural model of the brain the classical neural model so how do you build a neural spatial
1093720	1101880	memory and this is a changed quote from Animal Farm where they said two legs bad four legs good
1101880	1107480	two dimensions is easy three dimensions is hard because two dimensions you can easily do a sheet
1107480	1113000	of neurons representing two dimensions whereas in three dimensions you don't have that option
1113560	1118680	and there are several possible memory designs you can have a two-dimensional sheet of neurons
1118680	1124840	and you can represent the third dimension by depth depth by the third yeah you can have some other
1124840	1130040	variable representing depth or you can have a three-dimensional clump of neurons where
1130040	1135480	position in the clump represents a 3d position or you can represent all three dimensions of
1135480	1141880	an object position by neural firing rates that none of these work well for object tracking I think
1141880	1148920	we can quite simply eliminate the 3d clump model but the other two models have a problem with neural
1148920	1154840	error rates and if neural information is encoded as firing rates of neurons
1159560	1167560	typically you have a neuron firing n times in some time interval t and then the precision
1167560	1173960	with which it can represent some real quantity is of the order of one part in square root of n
1174840	1181800	now n over t is typically five or between five and fifty pulses per second on most animal brains
1182920	1189880	but for insects and small mammals the time they've got to have to update their internal model of
1189880	1196120	space is very small typically less than a tenth of a second so if the time there's a tenth of a second
1196120	1203160	then you get n less than 10 and that gives you errors of the order of 30 percent which are much
1203160	1209880	bigger than the 1 percent errors which I said are needed for tracking structure from motion
1210920	1217000	so the conclusion of this is that the neurons when they represent space there's a trade-off
1217000	1223720	between speed and precision faster you have the less precise it is and this trade-off is just too
1223720	1234360	hard so I believe there is no working neural model of 3d spatial cognition now the three
1234360	1241000	the three points in blue I've said before they say spatial cognition is very important and animals
1241000	1247560	do it well and we've had this problem for a long time in his book vision 40 years ago
1247560	1252760	David Ma identified the challenge and he started work on it he defined what he called a two and
1252760	1259320	a half d sketch and various other models now I believe that in terms of building neural models
1259320	1264360	of how spatial cognition works people have really not moved beyond this
1266760	1271320	why I think the main reason is that the memory problem is just too hard that memory gives them
1271320	1277000	two big errors and is too slow and I suspect that over the years there have been many people who look
1277000	1284120	at this problem and they decide to move on and do something else instead but the result is that
1285560	1291080	spatial cognition is the central problem of neuroscience we don't have a model of it and so
1291080	1297960	this is rather like theory of planetary motion without a sun or a theory of the atom with no nucleus
1298840	1308040	so how does this relate to active vision I think active vision is one way to explore this problem
1308920	1316040	active vision describes how a 3d spatial model can be inferred from vision and there are quite a
1316040	1321640	few papers on it they focused on various aspects of it they focused on 2d scene classification
1322120	1328200	they focused on the trade-offs between various objectives like the choice of visual saccades
1328840	1334120	they focused on 3d robotics as far as I know none of them have really focused on how
1334120	1342040	animal brains practically build a 3d model and I believe that existing active vision models
1342040	1348520	do not address the issue of neural error rates one reason for this is that the standard active
1348600	1355640	inference toolkit in MATLAB I believe it doesn't model neural error rates it assumes I believe
1355640	1363400	an abstract perfect neuron with very precise representation of quantities and error rates
1363400	1368120	are actually not an issue for many of these applications they're not an issue for robotics
1368760	1377080	and they're not an issue really for making discrete choices but as I've said in this talk so far
1377080	1382680	the accuracy with 3d model really matters and neural error rates are the big problem
1384280	1391560	if we set that problem on one side for a moment there is the issue of active inference trade-offs
1391560	1398840	and there are many interesting trade-offs you can examine in active vision and the key trade-off I
1398840	1406760	believe is one between freezing and moving as I've shown in the demonstration the animal
1406760	1413160	has to move by has to move in order to infer the 3d positions things around it by shape from motion
1413160	1417800	it also of course has to move to achieve practical goals like feeding and fleeing and mating and
1417800	1425560	so on on the island it can freeze and freezing it may conserve energy it may be able to detect
1425560	1431480	what's moving simply directly from its visual field which is much easier and it may itself
1431480	1437480	avoid detection so these are very key trade-offs they're absolutely essential for lifetime fitness
1437480	1444520	for many animals animals have to make this trade-off or these trade-offs any moment of the day
1444520	1450600	and so we've got plenty of empirical data about it and I think it'll be a very useful area to explore
1450840	1459320	now I'm going to switch to something completely different having said that neural storage
1459320	1466040	of spatial positions is a very hard problem I'm going to talk about an alternative possible
1466040	1476040	alternative way of storing spatial data and so if you assume there's a round some round region
1476040	1484200	inside the brain of a fairly large diameter d and this holds waves with a minimum wavelength
1484200	1490840	which are called lambda and the neurons can couple to the waves both as transmitters and receivers
1490840	1497400	and the wave can persist at least for fractions of a second so the wave can act as a working memory
1497400	1503960	for positions and the number of object positions you can store in the wave can be up to d over lambda
1503960	1510280	cube and that's a can be a very large number the spatial precision which one object position
1510280	1517560	is stored can be one part in d over lambda and I think that d over lambda can be very large so
1517560	1523720	you can easily get precision better than one part in 100 which is what you need to build the spatial
1523720	1531160	model so in summary wave storage of 3d positions may have a lot of computational benefits you can
1531160	1537880	give a natural fit to the problem it can give high precision and high capability it can give you
1537880	1543720	very fast response times low spatial distortion and some other benefits which are described in the
1543720	1552440	papers so apart from its computational benefits is there any evidence for wave storage in the brain
1554760	1559320	I believe there are two quite powerful lines of evidence one of which comes from the insect
1559320	1565240	central body the central body of the insect brain is a very small part of the brain in the middle of
1565240	1571560	it and it consists of a fan shaped body and the elliptical body and it has this shape which is
1571560	1577960	remarkably well conserved across all insect species and there's an insect brain database and I've
1577960	1583160	gone to the insect's brain database and pulled from it the shapes of the central body from a few
1583160	1589240	typical insect species and here you can see the fan shaped body and the elliptical body and it's
1589240	1596280	very constant across all kinds of insects and you can see it's approximately a round shape so it's
1596280	1605640	well suited to hold three dimensional wave and it does multi-sensory integration and so it's quite
1605640	1611560	likely quite probable that it holds spatial positions and insects have very few neurons
1611560	1618840	in their brain to do it in any other way and what I think is significant is how constant and round
1618840	1623000	the insect central body is compared with all the other parts of the insect brain
1624840	1629720	so that's one piece of evidence from the insect central body the other piece of evidence comes
1629720	1637880	from the mammalian thalamus as you may know the thalamus of most mammals all animals is
1637880	1644680	approximately spherical and is connected to all sense data and all cortical reasons
1645880	1648360	but the important thing is that the shape of the thalamus
1651400	1658840	is highly conserved across all species and there's an important aspect of the thalamus anatomy
1659800	1666920	that unless you assume a wave really it doesn't make sense because the thalamus consists of a
1666920	1673480	number of independent nuclei like the pulvinar and the lgn and so on and so forth and the connections
1673480	1681800	across within the thalamus between these nuclei are very weak or even non-existent so you could
1681800	1689080	have this picture here that the thumb where's my pointer here's my pointer the thalamic
1689080	1696120	nuclei which do have white circles here they all connect in two ways the cortex but they don't
1696120	1703800	connect to each other so one thalamic nucleus here could easily start moving out to towards the
1703800	1711640	cortex and the distance the length of its axons could decrease and its other connections it doesn't
1711640	1718440	need other connections so all the nuclei could migrate outward towards the cortex and you could
1718440	1728760	still have the same neural synaptic connectivity and the same computational capability if neurons
1728760	1737640	only compute by synaptic computation so this way you could save a lot of energy in shorter axon
1737640	1744760	lengths so in summary a compact thalamus and it makes sense if all the nuclei need to be immersed
1744760	1753320	in the same wave so we now have three pieces of evidence for a wave in the brain firstly there's
1753320	1759480	the computational neuroscience that it's a very difficult problem to build a 3d model about it
1760040	1765000	but you can build a 3d spatial model if you assume there's a wave storing positions
1766440	1772600	secondly the insect's central body is nearly round in all insects very well suited to hold a
1772600	1778920	wave and it appears to be in the right part of the brain to do that and thirdly the mammalian
1778920	1786120	thalamus which again has this round shape very well suited to hold a wave and the important thing
1786120	1794360	here is that without a wave the anatomy of the thalamus doesn't make sense so I would like you
1794360	1800120	if you remember only one thing about this talk remember this slide there is quite a lot of evidence
1800120	1808520	for a wave in the brain one thing I will say is that the wave is probably not an electromagnetic
1808520	1814600	wave because there's quite a lot of interest in electromagnetic fields in the wave from researchers
1814600	1822280	like Miller and McFadden and so on but electromagnetic field can't play the role that this wave is
1822280	1828280	supposed to is needed to play in other words the key thing that this the wave is supposed to do in
1828280	1834840	this model is to store information of fraction of a second but an electromagnetic field in the
1834840	1839560	wave and there certainly are electric in the met in the brain there certainly are electromagnetic
1839560	1845720	fields in the brain they cannot store information of fractions of a second and they cannot represent
1845720	1851480	3d space like a holibra and just to say a little more about this if there's an electromagnetic
1851560	1857720	wave in the brain it has to obey Maxwell's equation so the wavelength times the frequency
1857720	1865560	is equal to the speed of light lambda f equals c and that means that 40 hertz typical frequencies
1865560	1873720	of these waves the wavelength is 8000 kilometers as large as half the earth so it's the conclusion
1873720	1881240	is that at 40 hertz electromagnetic field is not a wave it's a static field and is driven entirely
1881240	1887400	by neuron firing so it doesn't store the information so in summary we're looking for something not
1887400	1894200	electromagnetic and possibly some quantized excitation something a bit exotic um in the
1894200	1899800	field of quantum biology i think we shouldn't despair here because we know evolution is a lot
1899800	1906920	smarter than we are at discovering these things and exploding them so here are some take home
1906920	1914360	questions does 3d spatial cognition use a wave in the brain in other words in the light of the
1914360	1920280	evidence i've shown you what is the Bayesian probability of that hypothesis being true now i
1920280	1924840	say these take home questions because i didn't expect you to have an answer immediately but
1924840	1929720	perhaps you'd like to look at the papers and see what the evidence is and try and assess it in your
1929720	1935560	own mind or do you know some slam dunk killer reason why they can't be a wave in the brain
1935560	1942280	if you do know reason what is that reason and how do brains compute space how do neurons
1942280	1949080	on their own represent 3d space with enough precision on the other hand if there might be
1949080	1954600	a wave in the brain wouldn't that be a a rather exciting and revolutionary development it would
1954600	1959240	actually change the neuroscience and it could address this central unsolved problem of how
1959320	1965880	spatial cognition takes place so i believe that possibility should be explored particularly
1965880	1971480	for young researchers this is attractive it's greenfield research it's not a well-trodden path
1971480	1977640	of classical neuroscience the classical neuroscience model of maculic pits neurons and
1978200	1984920	hebbian synapses that's 75 years old now so i would like to encourage people to get out and explore
1985000	1995480	or again come back to the earlier slide here a crisis in neuroscience the result of this work
1995480	2002360	i think is that neurons can't represent 3d space because they're too imprecise and too slow so
2002360	2009880	the crisis is can you show this is wrong can you show it by building a working neural computational
2009880	2017320	model and checking its scales properly so the fep neural process model is the starting point for
2017320	2023160	that i think it's a good problem to work on because it is a crisis and big crisis big advances in
2023160	2031160	science tend to come out of crises so what i'm advocating this is my last slide is a twin track
2031160	2038840	research program to build two different active vision models of 3d spatial cognition one is a pure
2038840	2046840	neural model which is a classic fep neural process model can this be made to work or are the neural
2046840	2052520	memory errors going to kill it and secondly to try to build a hybrid wave and neural model
2053720	2058600	and when you're building those models we can explore the trade-offs that active inference
2058600	2065560	is so good at computing and particularly the trade-off between freezing and moving so
2065560	2071560	there are a couple of candidate projects for the active inference institute okay that's it
2075800	2083080	awesome thank you robert i have some questions and some people have asked questions in the
2083080	2091560	live chat so i'll uh i'll ask them so first just while i'm recropping everything how would you
2091560	2097960	connect this to the requirements equation earlier work because you mentioned that there was a
2099240	2105720	requirements equation driven calibration of the optimal navigation so what does that look like
2105720	2113720	to have the optimal navigation according to the requirements equation well to summarize on the
2113720	2122440	requirements equation you can model how brains evolve and this is the previous live stream and
2122440	2129880	you can show that they evolve towards making a purely Bayesian calculation of their best model
2129880	2138440	of the world from the sense data but that purely Bayesian calculation is rather expensive and it's
2138440	2144600	been well known in FEP that full Bayesian calculations is intractable for most animals
2145480	2151880	and so that is a very expensive calculation and it's probably not the way animals do it but it
2151880	2158680	is it can be done on digital computers and it can be done in this model i've showed you and the first
2158680	2165640	model the full Bayesian model is actually computing the requirement equation from the bees or the bats
2165640	2173000	sense data the second model a tracking model is a is an approximation to that which is a lot cheaper
2173000	2175480	but seems to give very nearly the same results
2179560	2188680	okay awesome let us dive into a few mammal and insect neuroanatomy questions so i'll start with
2188680	2194840	the set of questions from the the live chat this is going to be about mammal neuroanatomy
2195640	2202520	okay tim ritter asks do you assume this wave property for all phylimic nuclei primary and
2202520	2207640	secondary or for specific ones e.g polvanar or mediodorsal
2210360	2216200	very good question i don't know the answer i mean at this stage i believe the whole
2216200	2222600	thalamus is around spherical near spherical volume with the wave going through all of it so
2222600	2228280	they are all immersed in that same wave so even the polvanar the polvanar certainly is
2228280	2235080	even the lgn which is rather small and is a pass through nucleus i think they all are so i think
2237400	2242120	for instance i think people always say the thalamus is a relay
2243560	2250040	sense data gets the cortex by account thalamus but people don't have a very good reason why
2250040	2255960	it has to go through these relays nuclei in order to get there i think it's doing something
2256600	2262840	about locating about i think the wave has some involvement there but this is very early days
2262840	2269080	i don't know the answer at all okay another question from tim on mammalian neuroanatomy
2270200	2277400	what about 2d orientation would you expect similar waves in hippocampal instead of thalamic
2277400	2286040	regions or is 2d sufficiently easy to get by without yeah basically i believe 2d is easy enough
2286040	2291880	to get by and the hippocampus is by no means suitable to hold a wave they all sorts hippocampi
2291880	2300040	have all sorts of different shapes so yes i think that was a core theme between the mammal and
2300120	2309240	insect areas is the conserved shape and then also the allometric differences over evolution
2309880	2317960	where the size differential of the insect central body changes much less than other primary sensory
2317960	2327000	regions and that was in your paper yeah that's right yeah and that kind of implies that that small
2327080	2332760	size of the central body it's only a few percent of the whole insect brain seems to be enough
2334680	2343240	yeah and that the properties which it hosts or enables might be related to its physical
2343240	2351400	extent or like to its surface area it's a volume ratio and not a function like for example in the
2352360	2358520	antennel lobe where the olfactory information are coming in there are these little glomeruli
2358520	2364360	and different species have from several tens to several hundred of these olfactory glomeruli
2364360	2369080	like ants have many and they have more olfactory receptors in their genome and they have more
2370120	2378040	olfactory glomeruli in that region or insects with more compound eye sections they have larger
2378120	2387080	optic lobes so the primary sensory regions have very large variation amongst species but then
2387080	2396360	as you get into the central body you get much more conserved anatomy and size and then the
2396360	2400840	mushroom body on the top part of the brain is something a little bit in between that might
2400840	2408680	have more of an analogy to like mammalian cortex where there actually is the possibility to scale
2408680	2414440	its cognitive capacities through size changes because it has some kind of like repetitive or
2414440	2423560	stereotyped layout yeah I mean there are a load of fascinating questions in your anatomy which
2423560	2429240	relate to this and and if you pursue the this hypothesis then there's all those interesting
2429240	2435480	question I'm not an expert on insect or mammalian neuroanatomy but there's a load of interesting
2435480	2447480	questions in there cool so about the bee spatial cognition so we know that bees use a variety of
2447480	2454760	visual cues ranging from the landmark and the landscape recognition to polarization of light
2454760	2461560	and so on and also as you pointed out the central body does multisensory integration so
2462680	2471160	how do we think about the possibly complementary or redundant information provided by these
2471160	2477400	different aspects of the visual fields and what does your simulation focus in on
2477960	2485880	well I mean I believe that what the central body and the thalamus both do is multisensory
2485880	2492760	integration in other words animals should they they need to make the best 3d model of space they
2492760	2499000	can and they need to use all their sensitivities to use it apart from possibly smell that's an
2499000	2506280	interesting question and so both of them do multisense integration and ideally one would
2506280	2512040	put in a simulation one would have things like stereopsis one would have object recognition one
2512040	2519400	would have light polarization all sorts of sources this program only does simple vision or simple
2519400	2525640	echolocation at the moment but it should do all multisensory integration in in a single
2526040	2533320	maximum likelihood model of the whole all sense data coming in at the moment
2536200	2542120	interesting yeah with sounds or with smells it would be interesting to see how those come into
2542120	2550200	play and and how do you think about in in the simulations presented here egocentric and allocentric
2550280	2557000	navigation because you mentioned how the kind of simplifying assumption is that the world
2557000	2562760	is a rigid fixed body so you can have these kind of duality where like I'm moving and the world is
2562760	2568200	fixed and then there's sort of like I'm fixed and the world is moving so how does that relate
2568200	2576760	to that to that egocentric allocentric distinction yeah very good question I mean I think the frame
2576760	2584680	of reference used for the model should be as much allocentric as it can be because the wave has to
2584680	2591400	persist and if the wave just persists it represents an object as a constant position so you want to
2591400	2597880	have a frame of reference where most objects are at constant positions so I think that makes
2597880	2602760	allocentric but obviously has to change from time to time every few seconds it has to switch
2603080	2606120	because it can't just stay allocentric
2610760	2618920	hmm interesting so now to connect that to what you brought up about move or stay that kind of
2618920	2628360	fundamental uh animal or fundamental mobile organismal nervous system question I thought about
2629080	2638840	different body plans where the eyes or the visual component are unable to move separately from the
2638840	2647720	body like a bee can turn its body but it can't rotate its eyes whereas in humans for example we
2647720	2656360	have optic saccade so there that stay or move yes we have turning our posture and moving through
2656360	2663640	space but also we see like this microcosm where when the gaze is fixed there's high precision
2664360	2670360	and then movement in the world is associated with movement of objects and then whereas when an
2670360	2677560	eye saccade is dispatched during the saccade our visual attention is alleviated and then
2677560	2684200	it's because during that time all the movement of pixels essentially is ascribed to the movement of
2684200	2690760	the eye so we see kind of like a microcosm of the two modes of movement and stability
2691400	2698600	in motion detection in the saccading but for other organisms that don't have eye saccade
2699240	2704520	the only way that they can get that kind of alternating movement and stability is by moving
2704520	2713960	their body yeah yeah I mean I always think of eye saccades as particularly predators if you like but
2713960	2720840	want some high resolution in some direction some particular direction whereas for most insects
2720840	2728920	as you say that there is not the option of a high resolution fovea but I think of saccades as being
2728920	2736840	cheap there's I mean the freeze move trade-off is a real trade-off that if an animal moves
2737480	2745000	it can be detected as moving and it can't detect motion itself as well as if it's stationary
2745560	2751080	and so that's a real hard trade-off an animal has to make whereas saccades you can make them
2751080	2761800	cheaply whenever you like yes yes and also it's really interesting like how often the behavioral
2761800	2766760	studies just look at the direction of movement but there's this whole timing of movement and so
2766760	2775000	there's definitely a lot of empirical studies about whether fear-based movements like in a predator
2775000	2784440	prey or different kinds of movement choices where would you say attention comes into play
2785320	2790600	in the sense that the bee or the bat was just kind of taking it all in it didn't have like some
2790600	2796120	restricted scope so it's kind of like a uniform attention across objects and across space and
2796120	2804360	time but then we know that we do have this visual attention phenomena well yeah attention is very
2804360	2813400	important and I think naively it's a search time model of attention in other words the wave
2813400	2818920	representation of all space represents all the space around an animal but the animal can focus
2818920	2828040	attention on a region of the space and what that's doing is tuning the receptors in the thalamus so
2828040	2835400	they are sensitive to wave vectors in a certain region so there's a whole load of issues there
2835400	2843560	about how the wave works as to whether it can how signals are rooted from sensitive inputs to
2843560	2848760	specialist regions of the cortex and I think attention is that rooting of information
2849720	2852280	so again loads of big questions there
2855480	2862840	yes with the way if I was kind of thinking about the insect brain visual input flowing in
2863400	2871160	and also other potentially inputs and all of these are crashing on the shores of the central
2871160	2881960	body and then there's this kind of stabilized dynamical wave representation such that information
2881960	2891320	coming in differently changes the the the resting shape of the wave and then that opens up like you're
2891320	2898520	now suggesting recurrent connections or or other connections into that wave hosting region
2899320	2906680	and recurrent connections can modify the shape of the wave attentionally and then also the
2906680	2914120	oh yeah the resting shape of the wave can route or augment or suppress other sensory information
2914120	2920200	coming in that'd be like water kind of dumping to where there's already a high water point
2920760	2927320	versus water going to where there's low water yeah yeah I'm I think key role of the wave is to
2927320	2935160	persist a background model of all 3d space and then against that background model new
2935160	2943000	central information that comes in particularly movement is best evaluated a piece of nuisance
2943000	2949000	data you evaluate you much better if you compare and contrast it with what you had before that is
2949000	2957000	attention and it's it's the foulness if you like telling the cortex here pay attention to here
2957000	2961800	here's your old information from this place in space here's your new information so tell me what's
2961800	2970520	changed well this connection with frame differencing is very powerful predictive processing predictive
2970520	2978680	coding algorithms were built by computer scientists and in compression engineers looking to make
2978680	2982840	video compression work and doing the frame differencing because that's the optimal way to
2982840	2988840	compress video and then that got brought also back into neuroscience where there's a lot of
2988840	2994280	focus on things like edge detection and these other 2d visual phenomena and then as you're
2994280	3002200	pointing to there's this kind of sun at the solar systems center that's not really being discussed
3002200	3009560	which is like okay yes we have neurons in different visual regions that are excitable by
3009560	3017960	vertical lines by diagonal lines and so on but this is all flat phenomena and the question of
3018520	3024920	not just shape recognition but the question that's most approximately relevant for movement
3024920	3030280	and the fitness related decisions for the organism in the niche has to do with its
3030520	3039960	spatial navigation not it's like eyesight at the eye doctor yeah
3042840	3048280	not only is spatial navigation how it moves its limbs you know how where it puts it foot it's foot
3048280	3054120	next that sort of thing and the 3d model i think does all of that
3058280	3061000	okay i'll read a question from the live chat
3062840	3069320	how might the cicade relate to a matrix of inputs versus a human based visual system
3069880	3073080	movement on the matrix may give different spatial dynamics
3073080	3084840	i'm not sure what we mean by matrix of inputs there but as you said during a cicade visual
3084840	3091720	input is kind of blocked while the eye is getting from a to b whereas the wave persists and the 3d
3091720	3099960	spatial model stays constant and after a cicade the eye has to update the 3d spatial model in
3099960	3107880	some different place so um i'm not i don't think i've answered the question but perhaps you
3109560	3116360	i think you understand my matrix it's what you enter um
3118600	3126440	it's making me think about the experiments where the for example the fruit fly is placed on a ping
3126440	3134520	pong ball in a harness in a virtual reality setting so it's getting custom visual input
3134520	3141800	and its movements on the ping pong ball just kind of scrolls the ball so it's basically fixed but it
3141800	3151320	gives a lot of degrees of experimental freedom around the um orienting of the body and what
3151320	3158440	visual inputs it gets so i wonder if anywhere there we know about the the time
3160360	3169880	the timescale of spatial orientation updating because that would be very critical to understand
3169880	3178280	the nature of the wave but if it was something that was um for example closer to the diffusion rate
3179240	3188280	of ions then we might be looking more towards like a channel or pore-based hypothesis if it was
3188280	3195240	something that was faster than neural signaling it would suggest something more like the direct
3195240	3205320	coupling or other kinds of of action so what what makes you feel as you suggested that it is not an
3205400	3215480	electromagnetic stabilized wave field well as i say the physics i mean for electromagnetic
3215480	3222520	wave we do understand the physics and the electromagnetic waves that measured by eeg for
3222520	3229080	instance they are a purely passive consequence of neural activity they don't persist in the
3229080	3236840	information for any time at all whereas this wave i'm talking about has to persist information
3236840	3242840	for fractions of a second so this constant spatial model is kept persisted while the
3242840	3250360	circuits go on on the animal moves while it computes shape from motion so a pure electric
3250360	3256040	field we we know the physics it's Maxwell's equations and it does not store energy store
3256040	3262600	information so it's purely a passive reflection of what's going on on the neurons it's not a memory
3265320	3274520	hmm so the neurons are especially if we think about the several like thousand to tens of thousand
3274520	3283880	let's say in the insect central body there's too few and they're too sparse and noisy to in a purely
3283880	3292200	connectionist neural framework to support the kinds of empirical results that we see
3292920	3302280	on the other hand a purely field-based approach has some issues that you just laid out so it's
3302280	3309960	it's very interesting that to at least of the well-known mechanisms the local field potential
3309960	3316920	and the firing rate rate coding type models that both of them seem to have some limitations
3317800	3326120	and yet there's a very strong anatomical evidence for the functional role of that region
3327960	3337960	oh yeah it's absolutely vital region but i believe that just looking at electric fields
3337960	3342600	magnetic fields in the brain is not going to give you memory and that's the key thing
3342600	3348120	that i think is needed to do structure from motion you've got to have short-term working memory
3348840	3352600	to hold a little model of space for a fraction of a second
3355880	3362520	do you see that as a kind of special type of short-term memory or do you think this is
3363480	3374200	the same memory pool that like short-term audio memory gets entered into
3375960	3379480	oh it's it's special it's different from that yeah definitely
3381560	3386840	to say it starts from how do you can how do you conclude a 3d spatial model
3386840	3394200	or how do you do structure from motion you need short-term working memory for that purpose specifically
3400360	3406040	interesting um the kind that enables us to
3406920	3417720	check for difference in in visually changing systems or what what does this visual working memory
3419240	3419640	have
3423240	3433000	well basically it's it's not vision because it's 3d and uh checking for difference in the visual field
3433960	3439160	is you can do it quicker you can look directly at the visual field whereas this model i think
3440200	3449400	the 3d model is um it's maintained by a loop between in mammals between the thalamus and the cortex
3449400	3456520	and it's a 40 hertz cycle that maintains it so it takes time to build the 3d model
3457800	3461640	and it's a bit slower than direct visual change detection
3463560	3471800	interesting it's this tension with like visual being what is seen versus kind of a broader
3472760	3482600	imagine the imagination of vision um what about action in your model so how were the paths set
3483960	3490360	yeah i said that the model was a bit like active inference and the animal has to move in order to
3490360	3496280	understand space but it's not really the program has not modeled the kind of active
3496280	3501960	inference choices of how should i move to get the best understanding of space and you could do that
3501960	3508120	you could make the b choose this trajectory to get the best understanding of where the flowers are
3508680	3513960	or you make the b choose this trajectory for all sorts those are the active inference trade-offs
3513960	3519080	that the program has not yet looked at and which can be looked at and i think are very interesting
3519800	3525000	that's awesome yeah it's almost like the b in this situation it's like on a train
3525800	3531880	trying to reduce its uncertainty about the location of landmarks but it's just on a it's
3531880	3539080	on a rail it doesn't have policy decision whereas once we start to close that loop and ask which
3539080	3547000	direction of movement or none given the costs would reduce uncertainty about resolving this
3547960	3555080	kind of spatial relationship then that that's where the perception actions start to like come
3555080	3564040	into play in benefit of each other and potentially there's several choice successive moves can greatly
3564040	3570200	reduce uncertainty through active sampling just as we see in skating and all other situations
3571000	3578120	and that would be like a heuristic or strategy that really does work
3579720	3587000	yeah i mean another example that i use somewhere is i believe that predatory birds like hawks when
3587000	3590840	they're approaching their target they don't go in a straight line they move on a curve
3591720	3593560	to reduce the uncertainty
3595720	3601800	so that they continue to get more information continue to see the range of of the target
3603400	3607720	if they just went straight to the target they wouldn't get a range fix on it
3612760	3617640	now what about the difference between the b and the bat
3618440	3628040	whereas a b is simply receiving the reflected photons let's just say the bat is sending out
3629320	3637240	a invisible signal so how is this kind of radar echolocation setting
3638040	3640840	similar and different to the vision setting
3642520	3646120	oh it's very different i could show you that with the program if you like
3647880	3651960	what happens with the bat is from the delay of an
3652680	3658200	for a particular insect that the bat is tracking from the delay of the echo it sees
3658920	3663960	the range of the insect so it gets the insect constrained on a sphere in its 3d model
3664840	3671320	and then from the Doppler shift it actually sees the perceives the cosine of the angle between
3671320	3676360	its directional movement and the direction of the insect so what it gets there is it
3676360	3683000	constrains the sphere surface of a sphere down to one circle in space so what the bat gets is a
3683000	3689400	series of circles in space which constrain the position of the insects and i could show that
3689400	3697400	on the program if you like sure okay um well how do i do that how do i share again yeah
3699000	3704760	i'm curious is the circle something like is it like a hoop that you could throw a basketball
3704760	3713640	through or is it well i'll show you if i'm now i can't get rid of this something on my screen it's
3713640	3721560	the problem um i've got a big black screen with a two on it and i can't get rid of it
3721880	3727400	um end show it's where the end show right no
3729720	3737560	am i sharing my screen or not not yet um now how do i find where i do that how do i find
3737560	3745800	where i am in space yeah absolutely that's an interesting question also how these mechanisms
3745960	3751400	google windows somewhere zoom windows somewhere oh zm that'll be it
3753400	3762440	how are these mechanisms repurposed for digital navigation semantic navigation narrative navigation
3765080	3773960	uh just a minute let me find oh god get away oh chef screen to chef
3774920	3783080	okay right you got that we're back okay so what we do is we change from beta bat
3784280	3792360	and we start again so what you have now is the bat and several insects which are colored
3792360	3801000	circles here and what the bat has is its echolocation take the blue insect its echolocation
3801000	3807720	constrains it to a sphere in space and that's the delay of the echolocation and the Doppler shift
3807720	3813800	can constrain the sphere down to a circle so if we rotate these circles you see that blue
3813800	3822120	insect is on a circle from one point in the bats trajectory so as the bat moves it gets
3822920	3830440	successive circles of the same insect so what we have is the bat is moving and all these
3830440	3836520	circles highly confusing and it gradually locates all the insects better and better
3838600	3847800	but what if i restart and step again if i step of i've restarted right now if i step
3848840	3857480	what i can do is focus on one insect if i focus on that insect then i only see the circles from
3857480	3865000	echolocation of that one insect and i can step again and get a new circle from a new step
3865640	3871640	and all the time the bat is optimizing the position of that insect to get the best fit to
3871640	3877000	all the circles it has for that insect so it's very different from vision but it can build
3878040	3884360	a very good 3d model from its echolocation okay so to kind of confirm what's happening here
3885080	3895960	there's there's for a given snapshot ping with the sonar what is returned is a circle
3895960	3902680	of equiprobable locations that are kind of like the maximum likelihood ridge that's right
3902680	3909160	constraints these are really sort of gaussian's gaussian donuts if you like okay likelihood
3909160	3917560	and then successive pings enable you to look at the intersection point of the circles
3918360	3922040	to find out yeah through successive approximation the likeliest location
3922840	3927960	this is what's happening here on that light blue insect has got these three circles
3928680	3933880	and that's the most likely they're not very well intersecting but that's the most likely
3933960	3940600	intersection point that's i go on this bat it's it's like a gaussian mixture model you have those
3940600	3946280	three that's peaks and then when you summit those three peaks that the the point that interpolates
3946280	3952040	them or just is the the geometric average is the single maximum likelihood estimate point
3953000	3959080	that's exactly it yeah and again with the bat i can go from full basian model which is this one
3959240	3969000	full basian tracking or tracking with noise and again the noise tends to have nasty effect
3971320	3979080	or i look back at this one here that's that dark blue insect and i can rotate to see how
3979080	3988200	the circles go so how is this how is this similar or different than for example radar
3988200	3994040	navigation algorithms for planes or ships i think it's quite similar
3996440	4003800	i think yeah i mean they are making maximum likelihood inferences from radar signal
4006040	4010840	and have you with this software looked at the computational
4011720	4018360	like the runtime complexity or the resource use associated with scaling the number of insects
4018360	4025240	or scaling the resolution of vision yeah you can scale the number of insects for instance if i scale
4025240	4038680	up here the 30 insects i can run the model with 30 insects and um it's it runs perfectly well
4041720	4049320	so the model is quite efficient because what it has to do for each object
4050600	4058360	um and for each time step it simply has to do and this Gaussian optimization which turns out to be
4058360	4064600	just a 3d matrix operation three were three matrices and that's very quick to do
4065080	4073080	and the so that's one of the advantages of it that if animals are trying to
4073720	4079800	track a load of things around them which they probably are it's quite a quick efficient computation
4081080	4085320	but this is not the neural implementation the problem is going from here this
4085320	4091000	mars level 2 computational model to a neural implementation that is where i think all the
4091000	4097080	interesting problems lie at least you have at this level two model is a kind of starting one
4097080	4101160	and the basian model would be trying to implement that in your
4105400	4117480	yes makes sense this is kind of the as if basian algorithmic map and the question is what
4117480	4128040	proximate mechanisms are capable of doing these algorithms functionally and neuro anatomy has
4128040	4139960	basically localized to the region in mammals and in invertebrates and so now we're in a space of
4140920	4146360	winnowing possibilities and leaving the door open for unconventional opportunities
4146360	4152520	for how those regions actually do it it's a very targeted specific agenda
4153400	4161560	that that connects a first principles grounding about how well the navigation can proceed
4161560	4168280	with a requirements equation on through to the empirical patterns that we see
4169080	4173400	those empirical patterns might have some like behavioral experiments well
4173400	4177960	sometimes can be hard to interpret as well though for example there's a common experiment
4177960	4185800	where a wall that's shaped like an L is set up and then people will use it to test if an animal
4185800	4193960	will go on the hypotenuse to reduce the travel distance or whether it will take the the around
4193960	4200920	the wall however even if there was a conceptualization of the ability to move on the hypotenuse
4200920	4208280	direction an animal might like prefer to move along walls so then by the time you get to the
4208280	4219160	real animals movements it's very tied up with not just trying to be the optimal landmark resolving
4219160	4226520	visual algorithm it's actually engaging in all these other drives that can make it look like it's
4227320	4232120	lower efficiency or even like supernaturally efficient on a given domain
4234440	4239960	yeah i i think there's all sorts of animal experiments what one could do but interpreting them
4239960	4247080	is not easy but basically if you're looking in these experiments to to to measure how good
4247800	4254840	the animals internal 3d model is i would like to with insects for instance how good is that
4254920	4260440	movement detection if it's movement in depth that needs the 3d model to resolve it rather than
4260440	4268840	just the visual field that's very interesting especially in insects potentially where there's
4268840	4279880	little overlap between their two compound eyes yeah yes um okay i'll read a question from the chat
4279880	4288200	as we kind of head towards the end use equal wrote how would perception of ability to conceive
4288200	4293320	of other domains of time as a cognitive function change spatial awareness
4295960	4304280	um other dimensions of time i i'm not sure i understand that question other domains of time
4305000	4313000	domains what's other domains of time um well this is all a very short term
4313880	4321000	question it's fractions of a second and time outside that into all just doesn't come into it at all
4321000	4331480	really does that answer the question you think it might i think it might also be pointing to our
4332440	4341160	awareness of how we handle our perception of time and space and what does that open up or enable
4341880	4347560	for example for our perception of space if we have a different perception or conception of time
4348760	4354680	well that is a very deep question i mean i think our perception of chronological time the long
4354680	4361400	term time is something completely different from more anything else in the animal kingdom
4362120	4367880	i think most animals live in the moment really they're aware of what's happening right now
4367880	4371320	and what they got to do right now and the rest just doesn't matter
4374760	4381880	whereas we exit what matters in the moments to ruminate and speculate yeah absolutely
4382120	4392280	um well what other directions or or ways are you hoping to take this work
4394120	4401640	well one way that is particularly important i think although particularly problematic is
4401640	4408200	theories of consciousness in other words consciousness most of our consciousness
4408840	4415720	at any moment is consciousness of the space around us and it seems to come from our internal
4415720	4423560	Bayesian model of space around us so this work is very related to why we are conscious and there's
4423560	4429720	another paper and i'd like to give another live stream just on that subject so i think this gives
4429720	4435880	a way forward to a theory of consciousness that can be in many ways more satisfactory than we get
4435880	4447960	from purely classical neural models and brain that's awesome i'm also personally very excited
4447960	4456760	on the empirical insect neuroanatomy side to look oh there are a huge number of ways of
4456760	4462600	going forward i think insects are particularly productive because you know they've got to do it
4462600	4469160	with a really small number of neurons so it's really there's a lot of experimental work on
4469160	4477240	insects that can illuminate this question yeah absolutely cool yes the brains are fun to dissect
4477240	4487640	you can see it transparently all there and no backstage there and then also this on on the more
4488520	4497880	transferable outside of entomology i think the active inference loop closure with policy
4497880	4503080	selection of movements including stay go no go decisions and which way to go
4503960	4509800	and then understanding how like well here's the trajectory that would have been the most
4509880	4518760	information gain on resolving this location um here's the trajectory that maximized safety
4519480	4522840	not moving or something and then here's the trajectory that that would have um
4523560	4529400	done some other thing and then being able to look at realized empirical trajectories
4530200	4537720	and then break those down or look at their component loading according to safety visual
4537720	4544840	information gain other kinds of heuristics or or impulses to understand moments or kind of
4544840	4551160	fragments of trajectories like something looks to briefly resolve its uncertainty and then it
4551160	4557160	doesn't need then the the overall demand to resolve uncertainty drops again and then it continues
4557800	4562920	just with inertia and then maybe that's a very simple decision to make and then there's probably
4563000	4569960	all kinds of cool patterns and ways to go yeah there's a huge amount to investigate
4572280	4577880	another another topic by the way is we've looked at my most we've looked at insects right at the
4577880	4583480	officer ends of the spectrum there's a whole load of stuff in between i think octopus and
4583480	4589160	squid are particularly interesting but there's all the other species one can look at say how do
4589160	4596360	they do space they have unique bodies and different bodies but there's also bringing in there the
4596360	4606040	question of underwater or space or fluid media and then that and a bat flies but it has the mammalian
4606040	4612040	neuroanatomy so then there could be like bird neuroanatomy with its slight differences from
4612040	4618040	the mammal then there could be this question of underwater and maybe there's some mammals
4619160	4629160	that have underwater navigation maybe dolphins would be like bats but in another fluid media
4632840	4635960	i hope people download the dot zip and play around
4640280	4646840	so do i any last comments uh
4650120	4658360	not really no i think i said it all thank you thank you robert well i i am greatly enjoying
4658360	4665000	learning about the work and seeing about how the requirements equation
4667400	4678040	scopes a given problem setting and kind of puts a meter stick on whatever the inferential problem
4678040	4687880	is inference plus action problem is and then from there the mar the marian research program
4688520	4694600	is just kind of laid out you can pursue it from the mechanistic or from the algorithmic elements
4695160	4700600	but they all are connected through on one hand in theory the requirements equation
4700600	4703640	and on the other hand the empirical results that we actually see
4704120	4706120	yeah
4709640	4715720	cool so thank you again um i come back to the Feynman well Richard Feynman on his
4715720	4720120	backboard said if you can't build it you don't understand it this is all about building it
4723080	4724040	we can't build a bug
4727240	4733320	not yet um thank you robert see you for dot three
4733320	4736200	bye
