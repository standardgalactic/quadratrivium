start	end	text
0	16800	Hello. Welcome everyone to the sixth annual Turing lecture. This lecture series is a part
16800	23520	of a broader effort at Kings called the Alan Turing at Kings Initiative. And this is an
23520	30400	initiative to raise funds for studentships, fellowships, and other academic endeavors.
30960	39840	These lectures are essentially all of them are focused on topics that somehow relate
39840	47200	legacy of Alan Turing. And today's talk is going to be about what computer scientists
47200	53840	like to call formal methods. And this means applying logic and mathematics to the reasoning
53840	59200	about the correctness of programs basically, or building tools to help people do that kind of
59200	68640	thing. And our speaker Byron Cook is a professor at UCL and a vice president and distinguished
68640	78720	scientist at Amazon. And Byron has been sort of at the cutting edge of actually applying formal
78720	86720	methods in the real world. So the work he did, for example, at Intel very early on when Intel
86720	92800	was having problems with chip design, I don't know if you remember the Pentium bug, but that certainly
93760	99440	stimulated a lot of effort to use formal methods in proving the design of circuits
100080	108000	correct. Byron then went on to Microsoft where he developed a lot of verification tools that were
108000	117520	essentially solving the problems that Turing proved were unsolvable. And it turns out many of
117600	124960	them are solvable in practice. And that sort of that work got rid of the blue screen. Remember
124960	130320	the blue screen of death from Microsoft? Well, that work pretty much got rid of that blue screen
130320	138400	of death. And then from there, Byron went on to Amazon where he really spearheaded the formation
138400	145360	of formal methods groups at Amazon. And today Byron tells me there are over 600 people at Amazon
145360	151680	working on formal methods, and over 20 groups doing that kind of thing. So apparently this kind
151680	160880	of work touches every aspect of Amazon's development and rollout of their services. And I just want
160880	167600	to say that when I did my PhD in kind of in this area back in the 80s, this was considered like
167600	174240	kind of crazy stuff that no one would ever use, that was too impractical, it was focused on toy
174240	179840	problems. No one is ever going to use this stuff. And I think for me, it's very satisfying to see
181520	188560	what someone like Byron is doing now, like actually bringing these ideas and technologies
188560	195360	into the real world, making real impact with them. So I'd like to introduce Byron.
195360	203600	So we finally figured it out. And it's a huge honor for me to be invited and to be associated with
204480	209200	Alan Turing and Kings. I hope you all read the abstract and know what you've signed yourself
209200	217600	up for. So I'm going to tell you, I'm going to attempt to tell you something rather technical,
217600	222720	but I've promised to aim it at a general audience, and I think I'm going to fail horribly,
222720	229040	but let's have a good time together. So we'll see if that works. As I was preparing this talk,
229120	235840	I'm like, oh, what have I done to myself? But I think this talk brings something for everyone.
235840	243440	So I think that the technical people in the space will enjoy pieces of it. And then those of you
243440	249200	who don't come from the space, I hope you'll take away something from it. That's interesting to you.
249200	258800	So this talk takes a needle and thread through a bunch of characters that are Cambridge based.
259760	264080	I was really excited to be invited to give this talk because it's a very Cambridge story.
264080	270560	There's a King's story. So there's some characters that were King's people. Frank Ramsey is a really
270560	275360	interesting character. I mean, he's a lot less well known than Turing, but also very, very important.
276640	284640	King's person, sort of the boy of wonder actually born in Cambridge, born just on the other side of
285200	290720	Jesus' dream at the locked bridge, the house when you cross the locked bridge. He was born there.
290720	296000	And then because father was at Muddlin, and then he was here. And I think he worked with this chap
296000	305120	quite a bit. And then, unfortunately, he died. I read his new biography about him. And from what
305120	310240	I can work out from the biography, he died from a disease he caught by swimming in the camp. So
310880	317600	you need to be comfortable. And then Alan Turing, I don't think I need to introduce.
318400	324000	There's another character, which is the spinning beach ball on the top left, just above Frank
324000	328960	Ramsey. And so some of you may be familiar with this concept. So I'm going to give you a bit of
328960	334560	IT advice. So if you take nothing else away from this talk, you can take this. When you see that,
334560	340320	what you need to do is you need to go into the force quit applications of your Mac, find the
340320	345840	program, and kill it. And hopefully that will take care of it, though it might be there's an
345840	349120	infant. So then what's happening here is there's an infinite loop in one of your programs, and
349120	352560	it's causing it to hang. Hopefully it's not in the operating system, because now you're really
352560	356880	in trouble. But if it's in, but if it's in the, but if it's in like a Chrome or Outlook or something
356880	360960	like that, you'll kill it, you'll lose your data. But you know, that's, that's how it goes. And if
361040	366960	you use Windows, this is kind of what it looks like in a similar situation. If you use a phone,
367680	372800	this is what it would like to look like. But I believe the phones are designed that after a certain,
372800	379920	quite short amount of time, they just reboot the phone. So the Mac, luckily, doesn't reboot itself
379920	384080	every time that it gets stuck in an infinite loop. But the phones, I think, are designed to
384080	388800	just, just reboot. So you may, and you may not even notice the way that the phones are assigned.
389760	394320	But we also have this problem. So it turns out that our bodies get, there's little infinite loops
394320	399680	sometimes that we find very unpleasant. So this is skin cancer. And it turns out that skin cancer
399680	406480	is, in a sense, the, the, the regulatory mechanisms in your, in your body to maintain
406480	411600	cell growth and death. And so skin cancer is your bug, is your body kind of going into one of these
411680	420320	states. Okay. So the quest is to build tools that can talk now about what's going to happen in the
420320	426560	future. So we want to, we want to build a tool that takes a program and says things that usually
426560	432320	have the word eventually in them. So, hey, you know, like, when I press this button,
433200	438240	does do the rockets eventually launch? Or, or, or when, you know, like, if I ask this question,
438240	447280	will I eventually get the answer? Or if, or if I model disease as a, as a, as a system, and then
447280	452560	I want to like make a change to characterize the change, I think that we should make for, for, for
452560	457200	medicine. Now does the system eventually do the thing I wanted to do? Does the, does the, does the
457200	463920	cell growth stop and, and, and, and, and we, we reach homeostasis. So that's, that's the kind
463920	467760	of things we want to do. And we want to do this without actually running the system. We want to
467760	474080	take the system and reason about it. Because we may not have the whole whole of the entire system.
474080	478320	And also we don't want to like interact with the world, but we don't actually want to launch the
478320	483760	rockets to learn the law, rockets will be launched. We want to ask, you know, in some theoretical world
483760	489920	where we launch the rockets. Okay, so just a bit of bookkeeping. I know myself, and I'm going to use
489920	495200	all these words to mean the same thing. So I just, just, just to take a moment, the halting problem,
495200	500080	the question of program termination, finding infinite loops and talking about systems that,
500080	504080	like trying to show that systems don't hang. It's all the same thing. So when you hear me talk,
504080	509280	say, in one breath, I'm saying program termination and, you know, three breaths later, I'm talking
509280	513280	about the halting problem. It's all the same thing. This is, this is again for the, for the
513280	519680	non-technical people on the crowd. Okay, so what is program termination? So for those of you who
519680	524400	know what program termination is and know what programs are, bear with me for a moment. We're
524400	529520	going to take a one-minute tutorial on programs and program termination, but also this program will
529520	536000	show up from time to time. So, so it's sort of worth it to everybody. So here's a program. I'm sort
536000	541680	of assuming a few of you are in the, I know at least one or two people in the room don't, don't
541680	548240	know how to program because they're my family. And, and so what this, this is a program written
548240	553280	in Python, a language called Python. And what happens in this program is the first thing it
553280	561200	does is it says, this is a, a while loop. So it says, Hey, is in greater than one? If, if so,
562240	569360	go here, do what it says, come back and then ask again. Is in greater than one? Okay, go here,
569360	576080	do what it says, come back, ask again. And the idea is, is that this code here is modifying in
576080	583280	and the, and, and one would hope that eventually the code that's modifying in would make in be
583280	589920	that not greater than one, in which case now the loop would terminate. Okay, so that's the idea.
589920	594960	So this is a computer program. That's a while loop. Sometimes while loops, you want them to run
594960	600240	forever. For example, like you're, you want your actual computer to run forever, but inside the
600240	605120	computer, inside that loop is often some code that you really want to terminate. And that way
605120	609360	you can get back to the start of the loop. So often systems are written with one big while loop
609360	614880	that you want to run forever. And then code inside the while loop you want to terminate. And that
614880	623120	code may look something like this. Okay, that was your one minute tutorial. This is a really
623120	628800	interesting program. So this is a wicked little program actually. So this is called the Colatz
628800	634400	conjecture. And no one knows if this program terminates. And what I mean by that is,
635200	642080	so a program is, we would say it guarantees termination if for all possible values of in.
642080	647680	So in here actually could range over all mathematical integers. And so for all possible
647680	654000	values of in, does this program guarantee to exit? No one knows the answer to that question.
654640	659280	So program guarantee termination, if you know that's true for all possible, no one knows.
660720	664960	And this is, there's some really great quotes here. So I wonder if this has a pointer.
666320	671520	Yeah. So this is called the Colatz conjecture, but it's also called the three and plus one
672160	677920	problem. It has some great names, whereas it, the Hellstone numerals, the Thwaites conjecture.
678560	685360	And then look at this great, great quote here that from Paul Orteff. Mathematics may not be ready
685360	694720	for such problems. It's extraordinarily difficult, completely out of reach for present day mathematics.
695680	705120	Look at that innocent little program. Okay, now as an aside, my colleague in Amazon,
705120	710640	Marine Hula is so close to solving this puzzle. It's agonizing. I was really hoping I could say
710640	716400	today, oh, and by the way, at Amazon, we solved it mic drop, but, but alas, I wasn't, alas, I wasn't
716400	721920	able to. So he has this really, really fascinating paper that's very, very insightful, that combined
721920	726400	some really beautiful, it's just, it's such a beautiful paper. So they're really making some
726400	730720	serious headway on this problem that I'm very excited about. Anyways, and, and back to Cambridge,
731360	736720	back to Cambridge. So, so there's another really interesting character that's, that's, that's,
736720	742800	that's, so, so, Frank Ramsey was the Kings, Alan Turing was the Kings, and Byron Cook,
744080	751920	oh, you know, cycled by Kings. For, for six years, I cycled by Kings, and I cycled
751920	756160	by Kings on my way to Microsoft Research, which at the time was that in West Cambridge,
756160	762560	now it's by the station. And when I cycled to, to, to, to, to Microsoft Research,
763760	768720	a lot of my work was with these two jobs. So this is Andre Rybolchenko, who is my intern,
769920	774080	and then a longtime collaborator, he's actually later joined Microsoft Research, and then Andres
774080	780240	Podolski, who is his PhD student. And, and what happened was that I decided to move, I'll tell
780240	784240	you part of the story, I moved to Cambridge. And when I moved to Cambridge, a bunch of people who
784320	789280	were in Europe, you know, I moved, you can probably hear, I'm American. So when I moved
789280	793760	to Cambridge, a bunch of people who are in Europe were like, oh, wow, cool, we should work together.
793760	796880	And these, and these were one of the, one of the, one of the sets of people who do that.
796880	802000	And so I did this work with them that was really explosive. And so I ended up the, all the, all
802000	806560	these other people were like, wow, that's super cool. We should like, there were like possible ways
806560	810400	that we can solve other problems that were related. So I ended up working with a whole network of
810400	814640	people. And it was really a very, very exciting time. And many of these people spent much of their
814640	823360	time in Cambridge. And there were, of course, many scientific papers. And they all used theories
823360	828240	from Ramsey and Turing. So that's, that's, that is what we're going to talk about today.
829760	835760	Okay, let's start at the beginning. So, and here I'm going to, I'm going to do a little bit of
835760	841120	guesswork. So I, so I don't know if you know that there's this, the Greeks, the ancient Greeks had
841120	848800	this like, calculating device, right, that would, that would, that would predict eclipses, for example.
848800	853200	Meanwhile, they're also doing proofs, right? They have, they, they, they, the Pythagorean
853200	858720	theorem, you know, there's all this work kind of in the, the Greek empire. So it must be,
858720	864480	and here I'm just guessing, it must be that someone in town, sorry, some, someone in town
864480	868960	thought, hey, could we get the device to prove theorems for us, right? It's just, it's inescapable
868960	876960	that that's true. So I would believe that that must be when, you know, our, our people, our ancestors
876960	885520	first said, machines, mathematics, let's put them together, right? But what, what I do know is that
885520	891920	from the, from the, is that Leibniz explicitly asked us, right? So, and we calculate the truth
891920	898640	of any mathematical statement. That's the sort of fundamental thing we want to do. And so here's
898640	902320	what this would look like kind of in our modern world. So imagine on your phone, you have some
902320	907520	magic AI app, and you could ask it simple questions like, hey, is there a number between,
907520	912480	this is an easy one, is there a number between 10 and 20? Yes, there is, 11, try that, okay.
914640	920320	Is the Colatz conjecture valid, right? And, and the, and the idea is that the answer produced
920320	925360	must be correct. That's the game we're playing. That's, that's what Leibniz suggested. And that's
925360	931120	what, you know, we're going to talk about much of today. And, and maybe it's not an acceptable
931120	937120	answer. You can't say maybe in this sort of, in this, in this purest Leibniz world, and you can't
937680	941760	run forever trying to, as well, give me, give me some time. And I'm going to go off and compute
941760	946080	forever and just never come back, come back with an answer. No, that's not allowed either.
946640	951040	You have to answer the question, and you have to answer it in a finite amount of time. That's the
951040	956400	rules of the game. Today, we would call this automated reasoning. So if you look at like my
956400	960240	title, or like the groups that we have, the groups in Amazon, all these like 20 teams are called,
960240	965040	you know, identity automated reasoning team, or crypto automated reasoning team, storage
965040	968880	automated reasoning team. So automated reasoning is what we do. And practically, there's a few
968880	974080	people from the crowd, you're all laughing, because you, you, you know, that we've kind of given up
974080	979280	on requiring you can't say maybe or time, or time out from time to time, right? So we're
979280	983040	practical people and we're like, eh, sometimes we don't know the answer, right? But, but, but the
983040	991680	purists didn't think that. So in this, this paper, paper book by Hilbert and Ackerman named it,
991680	996320	the decision problem. And I'm not going to try and pronounce the German, right? But it's,
996320	1003280	it's called the decision problem. And this, this was came out in 1928. And this got everyone in
1003280	1008800	the mathematics logic world very, very excited. So back here in Cambridge, both Ramsey and Turing
1008800	1014720	were like, Oh, the decision problem, that's super cool. Can you automate reasoning about mathematical
1014720	1019760	logic and mathematics, such that you always get an answer, you know, super cool, super cool problem
1019760	1023440	for them. And they, and they, and they both did some interesting works. And now we're going to talk
1023440	1030080	about that. So Ramsey had this, had this very nice paper right before he died, unfortunately.
1030800	1039280	And he didn't prove or disprove the possibility of there being a general solution to the decision
1039280	1045040	problem. But he, but he did something else instead. And so what I'm going to, I'm going to, I'm going
1045040	1050240	to, we're just going to take a moment to introduce a little bit of visual notation. So there's an
1050240	1057840	idea of a graph. Graphs have nodes, graphs have edges, edges are the arrows. And the idea is you
1057840	1064000	can go from A to B if there's an arrow. Okay, that's a graph. That's a sort of fundamental
1064000	1069360	concept that you see in computer science and mathematics. And what we could do is we could
1069360	1074800	color the edges. So I could color some of them red, some of them blue, some of them green.
1075520	1080240	And then what Ramsey did is he has this really, really amazing result that's about
1081280	1086960	monochromatic subgraphs. So here's, here's, here's a monochromatic subgraph. It's, it's like the
1086960	1093600	original graph, but with only the red arrows. And there's sort of different flavors to the Ramsey
1093600	1098800	theorems, or there's a sort of Ramsey theorem is kind of a family of statements. But what's really
1098800	1104320	amazing about it is he says, if, if your graph is infinite, I can't, I can't show you an infinite
1104320	1111440	graph on this finite screen, but imagine it's infinite. If you have an infinite graph, and a
1111440	1114240	couple of other conditions are met that I don't really want to tell you about, because they
1114240	1123520	knows to turn into a math lecture, then, then there exists an infinite monochromatic subgraph.
1124560	1128640	And that's going to turn out to be a very, very powerful tool for us. So take this graph,
1128640	1133920	if it's infinite, it's also complete for those of you who know what that means, but it doesn't matter.
1133920	1140240	And, and the number of colors is finite, then there's going to be an infinite
1140240	1149600	monochromatic subgraph. Okay, remember that. Meanwhile, Alan Turing read this paper
1152400	1163760	by Kurt Gertl that was the start of the argument as to why there could be no solution to the
1163760	1169920	decision problem. And what he did was he wrote this paper that he's, you know, famous for,
1169920	1175520	I mean, it was, if you saw the exhibit today, you saw his copy of the paper. And, and I mean,
1175520	1181280	I think this is, this is probably the most studied theoretical science, theoretical computer science,
1181280	1184880	I mean, basically started theoretical computer science. So this is like absolutely fundamental
1184880	1190480	paper. And so he's, I'm going to, I'm going to frame this in terms of graphs. But he basically,
1190480	1194720	you know, you know, I don't want to overstate this too much, but you can basically invent the idea of
1194720	1201040	like the, the, the, the idea of what computation is, like, I mean, people were doing computation
1201040	1206720	before and we had machines, but, but essentially he's like, he talked about that in terms of,
1206720	1211360	he combined that to mathematics, let's say. And again, we can think of like a Turing machine,
1211360	1215200	you can think of as a graph where it's like, what are the possible transitions between,
1215200	1219120	between, between a Turing machine. So I'm going to, I'm going to explain this with my phone.
1220160	1223920	So by the way, the iPhone is like so much more powerful than anything he probably could have
1223920	1228560	possible imagined, right? So it's a really, really, it's a super computer in your, in your,
1228560	1237600	in your, in your pocket. And so, so here's me and my phone, I open up my email, I write reply,
1238560	1244960	and then, and then I hit send. Okay. And then, and then in the sort of Turing view,
1245280	1254320	each state of each configuration of my iPhone is a state, and then you have transitions between
1254320	1263040	the states. So I can go from me opening it, seeing Tim's mail, saying my reply, hitting send, that,
1263040	1267520	that's, that's a progression. And that, and that states, states and configurations. Okay,
1267520	1270960	that's a little, that was a little bit of background. Let's look at this program. Remember
1271040	1280080	this one? I've added, by the way, the, the line numbers. So you could have a state of the system
1280960	1287440	where the value of n is 20, and the location is location one. So we're at this line of the program,
1287440	1295600	and n is equal to 20. And then we can transition to the value of n being 20, and the location being
1295600	1304480	20. Okay, get it? Okay. So what he said was, is that we know that there will be, always be programs
1304480	1310240	for which we can't answer the basic question of termination. So it's, it's what we say is, it's,
1310240	1318880	it's undecidable, right? So I, the answer is no, we cannot calculate the truth of any mathematical
1318880	1326000	statement. Because if you could, the, the, the question of program termination is one of those
1326000	1332400	mathematical things. And he sort of linked up the idea of computer programs to what's computable,
1332400	1338000	to mathematics, and then said, well, this thing can't be solved and the, and he bridged the gap
1338000	1344800	over to the mathematical side. Super cool result. leaves us in a bit of a lurch, though, in terms of
1344800	1351920	like he sort of identified a sort of Achilles heel of computers. And so I'll, I'll, I'll illustrate
1351920	1358880	that by what was stressing me out in 2003. So here's a list from Microsoft.com, sorry,
1358880	1364960	and the I'm going to poke on Microsoft a little bit now that work at Amazon of, of, of device
1364960	1369200	drivers that you could download. And you could put these in these, you could put these into your
1369200	1376640	machine. And each of these device drivers is backed by source code. And the problem is that
1376640	1381520	there may be device drivers out there for which we can't answer the termination question. And boy,
1381520	1386640	when a device driver goes into an infinite loop, we're in a world of hurt, like that is a really
1386640	1391360	bad situation. Because now like you, your, all your programs are going to start hanging, like
1391360	1394960	that this can be, this can be a very, very bad situation. We don't want that to happen.
1395920	1400480	So non-terminating device drivers hang your computer and hang them often in quite bad ways.
1401760	1407440	But what's not so known, who knows about raise your hand if you know the paper, checking a
1407440	1414960	large routine by all in turn. One hand, that's staggering. Really, you don't know this paper.
1416640	1421440	People, people in automated reasoning in, in, in Amazon, pull up your hand if you don't, if you,
1421440	1425600	if you work for Amazon and you don't know this paper. That's interesting. Okay. Great. Well,
1425600	1428560	you're going to know about the paper. I think this is one of the most interesting papers there is.
1428560	1435040	This, this comes from 1949. He totally tells us how to do our job. It's amazing. So, so he gives
1435040	1445200	a very clear instruction for how to prove a program terminating. 1949, I think. And so I'm,
1445200	1450480	now I'm going to put a few words in Ellen Turing's mouth. So he doesn't quite say this, but he says,
1450720	1454560	but basically between the, read between the lines, what Ellen Turing is really saying is,
1455760	1461360	in practical cases, we can answer the termination question. And then furthermore, in cases where
1461360	1467920	we can't, we just return maybe, what's the big deal? Right? Like, it's like, yeah, yeah, yeah,
1467920	1472560	I proved the halting problem undecidable, get over it. Like, life moves on. Now we need to do
1472560	1477200	practical stuff. We have computers. Remember the war, like computers are cool. Let's, let's, let's,
1478000	1484720	let's do good things here. And so to think about this, think about like British Airways, right?
1485280	1493520	On time arrival is not guaranteed. But, and I know you're probably all winging about British
1493520	1498640	Airways right now, but they're pretty good. Like you, you do often arrive most of the time, right?
1498640	1505040	You arrive, you arrive, you get on time arrival often enough that you think, I'll fly again.
1505760	1510800	So, so, so they're, they're not horrible. So the real, the real thing that they need to do is just
1511440	1516000	to make on time arrival frequent enough to make the airline useful to their customers.
1516800	1521680	And it's the same with, with Termination Prover. So if you're building a tool to analyze termination
1521680	1528160	of program, so long as the tool answers often enough with the right answer, then, then you're
1528160	1532560	going to use it even if you're, even if you know from time to time, it's not, it's not, it's not,
1532560	1536800	it's not going to give you, it's, it's, it's not going to be able to answer it. And, but, you know,
1536800	1540560	the answers need to be correct. Yes or no answers need to be correct.
1542640	1551440	Okay. So in 2004, what, what Andreas and Andre, and I, oh, sorry, I want to say something else.
1554000	1556480	This paper on the left, the Turing's famous paper,
1556800	1568800	has kind of been a buzzkill in, in the, in the IT industry. It's, people do not, what's the,
1569760	1574400	the thing is you do an improv, you don't say no, you say yes and right. So there's a whole lot of
1574400	1578720	people who didn't study improv apparently in the IT industry. And so if ever you have some idea,
1578720	1585280	like, oh, I know we could do X, Y and Z, someone's going to be like, that's the whole thing problem,
1585280	1590720	you can't do that. And oh, I feel shame. Sorry, I suggested it. Let's not solve the problem at all.
1590720	1594080	Sorry. And that's, that happens a lot. I mean, I've seen that personally a bunch of times that
1594080	1600880	you hear that a lot. So this is like the most abused theoretical results in computer science that
1601760	1605680	because it's the halting problem, don't even try, you know, like life is too hard.
1607840	1613760	But very, very, very few people in 2004 thought it was, it was practical, even in my own field.
1614720	1619200	Like, you would talk, you would talk to people on my own field. The vast majority of people would
1619200	1623920	be like, but it's undecidable. But it's like, yeah, but so is the state space reachability problem
1623920	1629280	for infinite state systems. But they did, oh, yeah, forgot about that. So, but, but with,
1630000	1636240	with the exception of some brave souls. So there were a few brave souls that were, that were trying
1636240	1641840	to solve this problem. But the problem for them is that their tools all solved this only for
1641840	1646320	little tiny programs, like little eight-line programs, seven-line programs. So they, and they
1646320	1650880	didn't have sort of any of the actual features you'd see in real programs like pointers and
1651520	1656960	concurrency or any of that. So they were fun. They're super fun, but they weren't actually going
1656960	1663120	to solve anything. And so that's, that's where Terminator steps in. So this is a tool that Andre
1663120	1667120	and Andreas and I wrote. And by the way, if you're Cambridge people, do you know this ride?
1667760	1670800	Have you seen this? I don't know if they have this anymore. So this is at least when I lived here
1670800	1675120	in the mid-summer, common every summer, they would truck in these rides, right? And so then
1675120	1678880	this was one of the rides. So I was looking through my photos for this talk, and there's so many
1678880	1686240	photos of me in front of the Terminator ride because I did Terminator. Okay. So, so what we did
1686240	1694800	is we, is we looked at this, the Turing paper and had a good read, right? So what we realized was,
1694800	1698400	is that, hey, there's actually two parts. And I'm going to tell you about that. So there's two
1698400	1702720	parts to solve and you can still solve them with independent bits. And then, and then, and then,
1702720	1708800	and then you're done. So now I've put up a paper, I put up three paragraphs from a paper that's 74
1708800	1713760	years old, that's referring to a figure that's not included in the screenshot. So we're not going
1713760	1716960	to make it very far through this paragraph clearly. And it's written in language no one would know.
1716960	1721680	But I just draw your attention to the first line. I move over here so I can see it.
1722640	1726560	In order to assist the checker, the checker is the person doing the proof or the tool.
1727360	1731760	The programmer should make assertions about the various states that the machine,
1731760	1736880	that's the program, can reach. And the reach is a really interesting bit. So,
1737920	1743600	so imagine that these states are unreachable. Imagine these states are reachable. But that
1743600	1748560	turns out there's no path over here. And here's a little infinite loop. Here's a what is that six
1748560	1753040	states that could be repeated forever over and over and over again. So imagine this is my iPhone,
1753600	1758160	so I have six configurations of my iPhone and they're just going around and around and around
1758160	1763600	between those configurations. But it doesn't matter because it's unreachable. So there's tons
1763600	1769200	of termination bugs in your phone, tons of termination bugs in your computer that are never
1769200	1772320	going to be triggered. You're never actually going to experience them because they're unreachable.
1772320	1775760	And that first three paragraphs is all about that. It's just about reachability.
1776560	1785120	So, yeah, kind of, I think I upset that. So we were like, okay,
1786400	1792240	turns out I worked on reachability. So we know how to do this, right? So let's,
1792240	1795920	let's, so what, what, what, why was I working on reachability? So now we're going to take a
1795920	1799920	little, a little psych, we're going to move over to Seattle for a few moments. So it turned out in
1799920	1810320	2003 that 85% of crashes in Windows XP were due to device drivers. And that was a big business
1810320	1816480	problem for, for Microsoft at the time. So what we built over in Seattle area was a real world
1816480	1820160	automated reasoning tool called static driver verifier in the research community. It was called
1820160	1826080	SLAM, but for device driver writers, they knew it as static driver verifier. And what it was designed
1826160	1832720	to do was to show error states reachable or unreachable. And so if you, this is the blue
1832720	1835600	screen of death, you actually, you actually refer to that. This is the new blue screen of death,
1835600	1839280	by the way, which you don't see very often these days. But this is what you get when your machine
1839280	1846320	is like, sorry, lost all your data too bad, it sucks to be you. And this is what you would
1846320	1852400	see on a Mac. And this is what you would see on a really old Mac. And so the question is,
1852480	1858720	and I've sort of put this on purpose, is this line there or not? And remember these states,
1858720	1864800	these state spaces are typically infinite. You can't just walk them explicitly. You have to like,
1866160	1872000	you have to abstract infinite sets and do all kinds of trickery. But yes, we're trying to
1872000	1875760	figure out, are things unreachable or are they reachable? And so there was a whole bunch of
1875760	1884160	work that we did over in Seattle area. And I was involved in that. And Andrew Herbert,
1884160	1890000	who's in the room here, I was visiting Cambridge and he was like, why don't you leave Seattle and
1890000	1894800	come to Cambridge? The environment is great here and you'll have a good time. But I'm like, great,
1894800	1900640	let's do it. So we, with eight weeks difference between that conversation, five weeks difference,
1900640	1907600	my wife says, between that conversation and moving, I came, joined Microsoft Research,
1907600	1912080	started chatting to these guys and said, let's work on the termination proving. So the point
1912080	1917120	I'm making is that this problem was actually already pretty much solved. So it's just a question
1917120	1923120	of reachability. So the red part is actually about, okay, now we've found a reachable state. How do
1923120	1927280	we know that that reachable state doesn't lead to an non-terminating execution? And all the green
1927280	1936720	bit is just about how do you show that states are unreachable? Okay, so let's look at this one.
1936720	1940000	This one's fascinating. We're going to spend a little more time with this one.
1940640	1946320	Finally, the checker has to verify that the process comes to an end. That just, I'm translating,
1946320	1951280	that just means, okay, now we're going to prove termination. Again, he,
1952080	1958720	you know, he or she should be assisted by the programmer giving a further definite assertion
1958720	1964400	to be verified. So the point that he, what this he really in our, in our lingo today would be the
1964400	1971120	prover, the tool. And so this may take the form of a quantity, which is asserted to decrease
1971120	1975360	continuously and vanish. I'm going to translate all this, by the way, don't panic, and vanish
1975360	1979920	when the machine stops to the, to the pure mathematician is natural to give an ordinal
1979920	1985600	number. Don't, doesn't matter what that is. If you don't know, it doesn't matter. I love this line.
1985600	1996160	A less-hybrid form of the same thing would be two to the 80 times n minus r plus two to the 40 times
1996160	2006960	r minus, what is that, s plus k. Pretty cool, huh? Let me translate that. Can we find a function?
2006960	2011600	I'll call it a, based on the, on the state, based on the variables of the, of the state,
2012560	2019040	that will choose only positive, but also decreasing numbers. Okay. So imagine, let's look at my phone.
2019040	2024240	I took a screenshot when I was writing this talk. I had seven Slack messages at the time, unread.
2024240	2029440	So maybe the function is the number of Slack messages. One possible, it's not going to work
2029440	2035680	very well, but another one, maybe be the amount of free space left on my phone. That's a little
2035680	2042400	more reasonable. And then imagine we took a, a transition from this state to this state. I don't
2042400	2048000	know, like who knows what, internally, you can't see it, but it made some transition. Maybe the
2048000	2054960	amount of space, a free space has decreased, probably quite likely, right? Because of it,
2054960	2058800	because the phone's actually doing little logs and all kinds, like it's always sort of using a
2058800	2064560	little bit of more and more and more disk space, not disk, but you see what I mean. Whereas the
2064560	2069440	number of Slack messages, well, we can see it stayed the same. So I had seven before, seven
2069440	2074240	before, seven now. So that's not a good one. So this number didn't go down. So remember that the
2074240	2079840	point, the point we're trying to make is we want to find a function, a function, some function F,
2079840	2084480	that on every, that I'll always say this in a moment, that it finds decreasing, but positive
2084480	2090160	numbers. And so what do we, what would we do with that? Oh, I think maybe, okay. And yeah. So
2090240	2095040	here, for example, let's write a little function for this guy.
2099520	2106640	Maybe what we do is we say, oh, well, let's do in minus the location. So we were at, in this value
2106640	2113280	of 20, location is one. So maybe it's in minus X is 19. So it's just this number minus that number.
2113280	2121040	And then the next one is 18 because I've now subtracted two. Okay. So that's a positive
2121040	2124720	number and it's gone down. So that's possible. I mean, it's not going to work because no one
2124720	2130480	knows that the program terminates, but that would be a plausible starting point as you begin your
2131440	2135920	journey into this world. So the thing that we need to hold is whenever we take a transition
2135920	2140400	from one state to another state or configuration to another configuration, and we have that function
2140400	2148000	F and we map, the greater than needs to hold. So and if you, if you, if you say the pre-state is S,
2148000	2153120	and then we apply F to S, and then we say the post-state is T, and we apply F to T, you need
2153120	2156960	greater than to hold. And that's a condition that's required. So the idea of how to prove
2156960	2164400	termination, and this is Turing's idea is find a function, think about it for a bit. Then if this
2164400	2169200	condition holds for all possible transitions of your system, this holds, you're done. You've
2169200	2177520	now proved termination. Okay. Right. So if you turn your head, you can see it. 19 is greater than 18.
2178400	2183440	So now, why does this hold? So imagine a non-terminating execution. Again, this is infinite,
2183440	2187040	so I can't, I can't show it to you on the screen, but here's the first few states.
2189040	2193120	Now just begin applying this function. Oh, and by the way, we have the function. I already said that.
2193120	2197440	And this condition holds. Now let's just begin applying it. And I'm making these numbers up,
2197440	2202080	but imagine the first one's 30. We've got to choose 29 after that because it has to go down,
2202080	2207440	27, 25, et cetera, et cetera, et cetera. We're going to run out of room. It has to be positive also.
2207440	2212720	So now we're out of space. So I said, imagine we have an infinite execution, but we have
2213920	2219040	a function F that's positive and decreasing. It turns out you can't have both, right?
2219680	2225440	Right. And too far. You can't have both. You can't, you can't have a non-terminating execution
2225440	2230960	and this function. You can only have one of the other, i.e., if you want to prove termination,
2230960	2235120	find one of these, and you'll know that you don't have a non-terminating execution.
2235120	2240240	Or if you have a non-terminating execution, you can't have one of these. It's a, it's a, it's a,
2241440	2245520	there doesn't exist. If the program doesn't terminate, there cannot exist a function that
2245520	2251280	meets those conditions. And so the trick is to find the F, right? And so Turing found the posh
2251280	2260080	one and then he found the less posh one. Okay, I've kind of said already that. So now, so now
2260080	2265840	the thing that we wanted to do was to automate this. And so, so consider any reachable state
2266960	2274400	and, you know, maybe those states on my phone. And imagine we found an F, then it turns out
2274400	2281520	it's super hard to find a single F. Like, like, and this is kind of why these tools from before
2281520	2285520	weren't working, because they were trying to find single F. And why is it hard? Because you're going
2285520	2290080	to find an F that's going to pick out all these values. I'm naming these values. So A needs to be
2290080	2294240	less, greater than B, A needs to be greater than C, C needs to be greater than D, D needs to be
2294240	2300240	greater than F and E, and F and E need, both need to be greater than G. So you're, you're like solving
2300240	2305520	all these things all at once. And if you have a 10 million line program, it's just, it's going
2305520	2310000	to be impossible. You're not, you're not going to be able to do it. And so, so what we figured out
2310000	2316480	was that you could use these tools for finding proofs of toy programs. And you can find multiple
2316480	2319920	ranking functions. It's going to turn out there's one thing we're going to need to do and Ramsey's
2319920	2323520	going to solve it for us. That's going to be the punchline Ramsey's going to solve of course.
2323520	2329040	So imagine we could find one termination argument, G for this transition, and another
2329040	2336720	termination argument for, for here. We can, we can color them. So here's, I'm just going to
2336720	2343120	make my life a little bit easier. So notice, notice I've colored this transition green because I have
2343120	2348560	the green function. And here I've, I've colored it red because I have the red function. Okay.
2348560	2355360	I'm preparing for Ramsey. The problem right now is that this isn't a valid termination argument.
2355360	2359360	And the reason is, is because I have two functions, you could imagine them alternating,
2359360	2364640	and there's just no reason for the numbers to go down. So if I have two termination arguments,
2364640	2369680	it's not valid because I just alternate them. There's no reason I know, I can't know, I can't
2369680	2375600	alternate them. So, so I haven't, I haven't proved termination yet. But what we can do is we can
2375600	2380160	borrow some techniques from these papers. And now I'm going to do a construction and just believe
2380160	2387040	me. Okay. Because we don't want this to turn into a 30 minute graph theory course. Okay.
2387040	2392640	There's this idea of transitive closure. And it's really neat. And the graphs are really
2392640	2397120	amazingly, they have so many edges, it's an unbelievable, but it's a construction, you can do
2397120	2404960	it. And, and, and now what we can do is we can, and this is, and imagine this is infinite because
2404960	2408960	we're saying, oh, maybe this program doesn't terminate. And so now what we can do is we can
2408960	2414080	take the monochromatic Ramsey subgraph. For those of you who signed up for this talk,
2414080	2418320	this is kind of the worst slide, right? Sorry. That who don't know, who don't know
2418320	2422880	math and logic and that kind of thing. So we can take the monochromatic Ramsey, say that when
2422880	2428000	you go home, right? You, you, how was the, hey honey, how was the talk is like monochromatic subgraphs.
2429760	2434960	And, and, and now we can pull this trick again. So we'll, we'll, we'll do like trying, we'll say,
2434960	2442880	okay, imagine non, non-terminating, non-terminating execution, but from the monochromatic subgraphs.
2442880	2451040	So it's only the green edges. So those were only the edges where we had one function and we did
2451040	2454320	this, we did this construction and you're just going to have to believe me that sort of added a
2454320	2458960	bunch more transitions. And this is, this is a valuable thing to do. And, and, you know, ask me
2458960	2464720	later and drinks and I'll explain it to you more. The more you get drinks into me, the more I'll
2464720	2471120	explain it to you. And, and again, we, now we get to say, oh, look, you know, now it's only one
2471120	2477280	function. So we know it's going down. So voila, right? We've, we've now, we, we, we have this
2477280	2483040	thing that Turing was saying. We need, we need to find a quantity, which is asserted to decrease
2483040	2486880	continuously and will vanish when the machine, machine stops and we did it. And it was Ramsey's
2486880	2492720	theorem that helps us do it. So the payload is the summary is Ramsey's theorem. Let's us use
2492720	2501600	many simple functions rather than a, rather than a single Turing style complex one. Okay.
2501600	2507520	How am I doing for time, by the way? Does anyone keep track? Okay, 15 more minutes, but I might
2507520	2513120	run long. I don't know. There was a Q and A afterwards. So I might eat into that. Okay. So
2513200	2517680	this, that, that's the basis of Terminator. So there was this, this paper that said,
2517680	2522720	hey, everyone, we have a termination prover that works for actual programs, like programs that
2522720	2528000	people care about, device drivers. And it worked really nicely. So it, so it, so here, you know,
2528000	2531760	here, remember, I showed you this code a little bit earlier. This is a device driver code. It's
2531760	2539280	actually from the mouse. It's a piece of the mouse device driver. And, you know, it has bugs. So
2539600	2545600	one of the developers agreed. Yeah, that's a bug. And then we, and then we had a bunch of papers.
2545600	2550800	What were these papers doing? A lot of these papers were chipping away at this maybe problem,
2550800	2556560	or the, the tool Terminator itself is running forever problem. So we were able to prove some
2556560	2561280	device drivers terminating. We also found some real bugs, but then there was a whole bunch of
2561840	2567440	maybes and spinning forever. And then these papers kind of chipped away at them.
2568880	2573840	Other papers generalize Terminator. So for example, these folks together with me
2574480	2580480	generalized it. So it's, you really could say anything that had the word eventually, like, you
2580480	2587280	know, when we could ask, when, whenever this program opens a file, does it eventually close it?
2587280	2593840	And that's eventually, right? So things like that. Another thing we did. So it turns out that
2593840	2599760	a lot of programs are what we call concurrent. So you might have two copies of the program,
2600720	2605520	both operating over that variable in at the same time. And proving those programs terminating
2605520	2609920	is harder. So it turns out device drivers kind of a very special flavor. And we were able to do
2609920	2615120	something. But then the question is, can we generalize to more programs? And the answer was yes.
2615440	2620480	So then Jasmine, who's in the audience, made the following reference. Hey, Byron, she worked with
2620480	2624560	me. Well, she worked in the Microsoft research. And then after this statement, she worked with me.
2624560	2628960	So Terminator looks like something we need in the analysis of biological models.
2630240	2636000	So that was this skin cancer comment I mentioned. So then a collective of us,
2636640	2641840	including a designer from the Royal College of Arts, essentially an anthropologist,
2642800	2648880	a couple of computer scientists, and Jasmine, and others who are biologists.
2649680	2655440	The idea here is that you have your skin cells and you have genes. And there's like the genes are
2656160	2660960	talking to the other neighbor genes. And they're all as a family trying to say, hey,
2660960	2665280	we should only have, what is it, five layers of skin? Six layers? Six layers? I don't remember.
2665280	2669920	But let's keep it that number. Let's not have a whole bunch more because that's bad for our
2669920	2674880	bodies. And let's not have a whole bunch less. That's also bad news for us. And so this paper
2674880	2679600	allowed us to analyze that. So we were able to build models of various kinds of disease and then
2679600	2687520	answer questions like, hey, if we modified the model, would you get homeostasis? And the one
2687520	2692240	really neat thing about it is this tool was designed such that biologists could use it and it
2692240	2697680	had a notation very similar to what they use in their day-to-day life. And so you can use the
2697680	2702560	tool still today. It's called Biomodal Analyzer. And there's been some amazing results. And Jasmine
2702560	2710640	in her lab down at UCL now has gone on to do amazing results. And many of them found in part
2710640	2717200	with the use of this tool. Another thing I did is I got really tired of using the, so there was
2717200	2723360	these kind of formulas that we were writing that came up quite a bit. And I found that notation
2723680	2728880	kind of limiting. So Talba Auerbach, who's a friend and an artist, began working with me on new
2728880	2732720	symbols. So here's Talba in my Cambridge Microsoft Research Office trying to invent new
2732720	2739200	mathematical symbols. And if you know LaTeXa, we ended, David Reinfert, who is the guy in the
2739200	2749280	photo, implemented these new symbols in MetaFont. And we came up with something I like quite a bit.
2749280	2754800	So it's this operation. So this is the lifting of a relation, happens to be greater than, with
2754800	2760880	respect to f. And that allowed us to talk about this in a much nicer way. So this is the thing
2760880	2765520	you've seen before. And now I can say this really nicely. I can say the transition relation, this
2765520	2773040	is the graph, is a subrelation of the lifting of greater than with respect to f. And so this
2773040	2778800	showed up a lot in talks and so on at the time. And so if you know, if you don't know math and
2778800	2782800	logic, just close your eyes for a second. But if you do, then I'm going to explain what the
2782800	2788880	meaning of this is. So the lifting of the relation with respect to f is the set of pairs of states,
2788880	2794640	s and t, such that if you apply f to s and apply f to t, greater than holds, or the relation holds.
2797280	2800800	So she's a really famous artist, and there's always articles about her. But amazingly,
2800800	2810880	Terminator was in Vogue magazine. My greatest moment. Okay. And then, sort of one final
2810880	2816800	point I wanted to make. So it turns out that the layout of data structures is just unbelievably
2816800	2821280	crucial when trying to prove termination of realistic programs. And so here is a data
2821280	2825920	structure of kind of typical data structure you would see in a device driver. And I'm just
2825920	2830320	going to kind of walk you through this a little bit to get the idea. So device driver might come
2830320	2834320	here and then it come here. And now it's sort of walking this data structure. It's called the
2834320	2839920	list, right? So it's going, there's these arrows which saying it's a link to the next and the next
2839920	2845520	and the next. And here it's going back to where it was before. And if the device driver somehow gets
2845520	2850400	confused and doesn't realize it's already seen this, we're in a world of trouble. Because now
2850400	2857280	what it's going to do is it's going to just spin on this thing forever. And so what's the termination
2857280	2862800	argument? So here I've put a little picture of a post-it note in an effort to say, oh yeah,
2862800	2867200	remember this. Okay. So imagine we've been here and we've left a post-it note saying,
2867200	2871360	remember this, don't forget this. And we've gone here and we've gone here and we've gone here.
2871360	2876080	What's the termination argument? Well, there's actually two list segments. There's the part we
2876080	2882080	haven't viewed before. And there's the part that we have viewed before. And what's the size of this?
2882080	2888320	Well, it's two nodes. And the size we haven't seen yet is two nodes. And so when we go another link,
2890320	2895360	now it's three to one. And so this is where we're going to get the termination argument, right?
2895360	2901200	We can take a transition from some state to some other state and look, it went from two
2901200	2905760	to one. And that's going to be, you know, the function we're typically going to use is the
2905760	2914080	number of links back to the node that's the head of the list. So there you go. So we're mapping.
2914080	2918720	And so the termination arguments are kind of like that. So this paper sort of recognizes,
2918720	2925520	this is with Peter Ahern and his postdoc and his PhD student, for example, Josh Burdine and myself.
2926880	2930000	And then after that, we're like, hey, let's keep working together. This is pretty cool. So then I
2930000	2937760	joined this thing with gang, I guess, called the East London Massive, that that was a collective of
2937760	2945680	people interested in reasoning about data structures. And so Josh, who was his PhD student and postdoc
2945680	2951760	and Samin, who was his ex PhD, had graduated and was a PhD student and I here ended up building
2951760	2957040	this tool called Slayer, which reasoned about shapes on behalf of the termination purpose.
2957040	2964320	We'd run this ahead of time. And that was very, very powerful. And it was also very powerful
2964320	2971360	because it turns out that many of these 85% of crashes were actually shape oriented. The device
2971360	2976240	driver would come in, it would modify that list, not leave it in a good state. And then the device
2976240	2980160	driver would come back in, start walking that list, it wouldn't be in a good state. And then
2980160	2985040	horrible things would happen. And so it turned out this is a whole other research area, basically
2985040	2989120	driven by determination, proving a whole bunch of different papers, some of them related to
2989120	2994160	determination, some of them not. But that's, you know, invite me back. I'll tell you all about
2994160	2999120	that. But here's an amazing thing that happened. So, so, so, so be who's in the audience. And I'm
2999120	3006720	also married to for past 27 years, or I can't remember now, sorry. And Peter, that's this chat,
3006720	3013840	they started a company that made a Slayer like tool. And, and they sold it to Facebook. And you
3013840	3018880	can still use it today. So it's called FB infer now, that you can go to this FB infer website and
3018880	3026080	find out how to use it. And, and, and that really got me to thinking, like, maybe it's time to leave
3026080	3031040	the research lab and go take things into product really, really into production at a level that,
3031040	3037680	that, that we had, that we hadn't seen before. So, so now that we sort of realized that almost
3037680	3042640	any mathematical statement, you know, maybe as we get closer and closer and closer to that,
3042640	3046800	this becomes more and more commercially relevant. And so that's kind of where I wanted to take
3046800	3052160	things. So this was the old Terminator website. Terminator is now dead. This website's gone.
3052160	3058240	You have to go to the way back machine to find it. But what it did was pretty interesting. It
3059040	3062960	inspired a new class of tools. There's a whole bunch of termination provers now that you could use.
3062960	3067040	There's whole sessions at conferences on termination. There's a pretty healthy
3067680	3071280	international termination prover competition.
3073840	3078960	Everyone can, like, a lot of people know that termination is impossible, but now it's a much,
3078960	3086320	it's a much more nuanced situation, right? Now, most people in my field at least know
3086320	3092000	that termination is possible, but you can prove termination programs and sort of a practical
3092000	3101360	thing that can be done. But also, I think that we made pretty mean, I mean, this vogue thing is
3101360	3105680	obviously a joke. I mean, I mean, it was real, but obviously that made no material impact on the
3105680	3110720	IT community. But I think that the articles in Wired, and Economist, and Financial Times, and
3110720	3116560	Science did, and this great Sinin the Terminator article of the Scientific American. So I think
3116560	3122960	that these helped the IT community understand that termination isn't like a death sentence.
3124720	3130960	Okay, so that's the end of my Cambridge story. As I said, yeah, so I mean, I said goodbye to MSR.
3130960	3136240	I've gone on to Amazon. That's three talks. I can tell you all about that, and I'll tell you
3136240	3139920	about that at drinks if you want to know more about it. But I've tried not to talk about the
3139920	3144320	Amazon work because that's all I do all these days. So I just, I thought it'd be fun to come here
3144320	3150000	and tell you this Ramsey Turing story, and I hope you had fun. So with that, I'll
3151280	3153600	gavel this to a close, and I'm happy to take questions.
3155840	3162000	Well, thank you for that wonderful talk. Let's have some questions. And we have a microphone to
3162000	3170960	go around. So first question. Byron, great talk, fantastic talk. Thank you. Maybe it's a relief
3170960	3176320	that you didn't mention artificial intelligence because it's so much in the in both these days.
3177920	3182400	But I suppose I would have asked about that. I mean, obviously Turing was famous for that,
3182400	3186960	but I mean, how do you see maybe today's developments in artificial intelligence having an
3186960	3190640	impact on the kind of, you know, automated reasoning that you're talking about?
3190640	3196640	Yeah, I'm very excited about so the in the automated reasoning sometimes is a really terrible
3196720	3201120	name for it because it's rather not automated, right? Like there's there's a lot of tools,
3201120	3205680	there's tools like Lean, Paul Light, Isabelle, you know, I can name a whole bunch of tools,
3205680	3210320	and they require a human to sit there and poke it to make it do the right thing.
3210320	3215360	You ultimately get a proof that it's the checks, the checking is automating, but the finding is
3215360	3220640	not. And those tools are rather more powerful in theory than the fully automated tools because
3220640	3225680	the automated tools, because the problem is undecidable, cut a bunch of corners about what
3225680	3230240	they can prove. So they can prove a much more limited set of things, whereas a super genius
3230240	3234640	sitting together with one of these tools that are not automated, as automated can do incredible
3234640	3240640	things. So all of your proofs of like the four color theorem, the Kepler conjecture, you know,
3240640	3248320	that have been done with with with these tools have required a human. And so what we're seeing right
3248320	3258320	now is that the generative AI chat GPT style tools are able to do these. So that's a really
3258320	3264320	amazing time. So what they can because they're training on all the past proofs. And all the
3264320	3268240	tools and these tools are super hard to use. But guess what, all the people who were making them
3268240	3273120	able to use wrote papers about it, and provided scripts and the scripts are on GitHub and the
3273120	3277920	tools have trained on that. So now they're able to say, you know, like, hey, you know,
3277920	3283920	find me a proof and haul light of XYZ. And they're not terrible. So I so I think that's a really
3283920	3291200	amazing thing. So making the tools easier. The other the observation that I'll just sort of
3291200	3301040	put on the table there is that when LLMs lie to you, that's incorrectness. And guess what we know
3301040	3306960	how to do, right? There's there's there's statements that are incorrect. And, and, and,
3306960	3311360	and, you know, it's not escaped the notice of the community that that's something we could
3311360	3315600	potentially solve. So but that's, that's, you know, that's a whole new area.
3319040	3319920	There's a question there.
3322160	3328080	Any, any thoughts on why you explain how you took the Frank, Frank Ramsey staff and the
3328080	3332160	Turing staff, and you put it together and you move forward for a subset of the problems?
3332160	3338480	Any thoughts why Turing didn't do that himself, given that, presumably, they, they knew each
3338480	3343840	of them pretty well and charged each other intellectually? Yeah, so so as so the part where
3343840	3349920	I said, believe me, this graph, you know, we can do this thing. And then the graph got really
3349920	3355840	colorful. That would be very hard to do manually. So the paper would have been pages and pages and
3355840	3360720	pages of calculations, which computers are really good at and humans are horrible at.
3360720	3366640	So I think what, what, so the single ranking function, you just need a really smart,
3366640	3370640	insightful person to be like, Oh, I got it. I was in the shower and I realized this is it,
3370640	3376400	where, but, but in terms of automation, it's really hard to know even where to start. Whereas
3376400	3381600	this, this other approach is much more automatable. So I think that's probably, probably the reason.
3382160	3385920	We have another question there.
3390000	3395680	Thank you for the talk. So for all those twos for automated reasoning, I'm guessing those twos
3395680	3401200	are not formally verified. My question is, do you think there's any value in actually formally
3401200	3405440	verifying their correctness? Or do you think there's, it's just too much work to do so?
3406240	3414400	There are some tools that are formally verified. And what a lot of the tools do today is produce
3414400	3420800	a proof that can be audited independently. So for example, a lot, a lot of these tools boil
3420800	3426320	down to a class of tools called SAT or SMT solvers, propositional satisfiability, or, or
3426320	3432960	satisfiability of propositional logic together with other theories like arithmetic, you name it,
3433600	3441200	strings, arrays, undertropper functions. And the solvers today can produce proofs that can
3441200	3448480	be audited independently by a tool like HallLite, Lean, et cetera. And let's, let's say that we
3448480	3454400	believe HallLite. It's very small, kind of eyes have looked at it and they're like, okay, we're
3454400	3458640	going to believe that. Then these tools that are, that are doing really pretty harrowing
3459600	3463760	high performance computing to try and find the proofs, ultimately produce a proof that can
3463760	3468560	be checked with a simple thing. That's pretty believable. So yeah, so that's something that
3468560	3472480	we've pushed on really. I don't want to talk about Amazon too much today because it's like,
3472480	3477200	that's all I ever do nowadays. But at Amazon, that's something we've pushed on very, very hard.
3477200	3482640	It's actually producing auditable proofs as opposed to just some magic tool that some smart
3482640	3487280	person wrote and you just have to believe it. We have a question over here.
3489520	3495280	So it's a two-part question. You mentioned British Airways and you said that could they arrive
3495920	3501600	on time enough or frequently enough to be useful? You didn't say anything about them arriving with
3501600	3510800	a luggage. I don't suppose there's any kind of mathematics. I'm not going to take that one.
3510880	3520320	But the second thing was to think about classes of mathematical problems that may not be
3520320	3525520	where you can anticipate or hypothesize that a solution or an algorithm could exist.
3525520	3528880	So the example I was thinking of while you were talking was the traveling salesman
3529760	3533360	where, and I imagine that Amazon must have thought about this for a while, getting the
3533360	3538960	in the course you're trying to deliver, where the presumption is that an algorithm could be
3538960	3544560	found, but that actually proving it within a finite time is, or at least up to now,
3544560	3547280	hasn't been possible. There's something solved and I'm not aware of it.
3548640	3553200	Is there an extension from the kind of approach that you were taking there to prove
3553200	3560560	termination to actually tackling those class problems? Maybe try to come up with a definitive
3560560	3567440	yes, there is definitely, we can now state that there will be a finite algorithm,
3567440	3571200	even if we can't actually find it within a finite time, or even to help us to find it.
3571200	3575600	Oh yeah, I probably not quite going to answer your question, but a couple of thoughts. One of
3575600	3580400	the interesting things about Ramsey's theorem is it says you have this
3581120	3586080	arrow and graph and there exists a monochromatic subgraph, but it doesn't show it to you, so
3586080	3593360	it's not constructive. And so if you use some of these techniques, you can't actually see
3593360	3598640	the termination argument, you just know it exists. But I think your question was rooted more in a
3598640	3607600	little bit about can we synthesize or convince ourselves that algorithms exist when we don't
3607600	3613600	know what this specific algorithm is there. We surmise they do, but we can't definitively,
3613600	3621360	or at least we couldn't definitively prove it. Yes, so I think so, I mean that like,
3622720	3628480	if goal box conjecture is proved likely, it's via these methods where you don't,
3629280	3636160	like the proof is kind of non-constructive in some sense. I imagine so often non-constructive
3636160	3640720	proofs are easier than constructive proofs. So yeah, so I think that the harder part will
3640720	3647280	actually be to find the witness. We have another question in the back there.
3647280	3653040	So Byron, I'm sure you're aware there were two schools of computer science in Cambridge in the
3653040	3660240	post-war years, cheering, because there's mathematical sophistication, mostly programmed
3660240	3665360	in binary on the Manchester Malt 1 and the Pylor Ace, because he could use his mathematical
3665440	3670560	sophistication to kind of reason about the algorithms and convince himself they were correct.
3670560	3675600	So the fact that notation was a very unproductive way of writing software didn't bother him.
3676480	3680720	The engineering philosophy that kind of came from people like Wilks and other colleges in
3680720	3686800	Cambridge just down the road was give the users a symbolic notation to seduce them into the idea
3686800	3691360	that programming actually is really very easy and you could just write stuff and it would be fine.
3691680	3696880	Yeah. Kind of the symbolic world of one because we have programming languages and the effort in
3696880	3701280	programming languages has been to design languages in which you can't make mistakes,
3701280	3706880	yet you can still write useful stuff. So my kind of question is now we have the kind of tools you're
3706880	3713120	talking about. Do we need to continue investing in improving programming languages or can we just use
3713760	3717520	scruffy languages and rely on the tools like yours to prove our software is correct?
3718080	3724320	So yeah, all programming languages are scruffy, but I've never quite managed to find the perfect one.
3724320	3730320	Couple of observations there. So one observation is I think Rust is this incredible language.
3730320	3735440	And so I spent a lot of time trying to get people working on very low level system
3735440	3740880	code to adopt tools that we had that could prove memory safety of those programs.
3740880	3745680	And it was really tough learning. And then one day Rust comes along and they're all like
3745680	3750640	without me even prompting them like, oh, I started learning Rust. And Rust has a very
3750640	3757440	sophisticated prover in it, but they came for the speed. So because Rust could be faster,
3757440	3762240	they're like, I'll learn these tools, but also it was super well done that the developers of
3762240	3767600	Rust talk about ergonomics, like the ergonomics of developing and Rust is really important to them.
3767600	3774560	And I think that's been very, very powerful. So one could prove, you know, just like there's
3774560	3781760	turning completeness of you can express all programs in Rust or C or Askel or Prolog.
3781760	3785680	There's, there's sort of, you know, you can prove the same things in a lot of these systems,
3785680	3792320	but I think that Rust's ergonomics are much nicer than some of the tools like in C where you then
3792320	3797120	try and prove, prove memory safety. That's my first observation. Second observation is there's
3797200	3804320	this fascinating blog post by Ranjit Jhalla where he shows that you can take a program
3804320	3809120	in an imperative language and prove it using horror triple style reasoning. And you have,
3809120	3816400	sorry, everyone, just bear with me for a second. You have a horror triples of quantifiers and,
3816400	3823920	and, and then you just slam the, you apply these SMT solvers with quantifier support and it's,
3824000	3831120	it's so hard and it's so compute expensive. Or you could write the same program in liquid Haskell
3831920	3836160	and there's no quantifiers. You can prove the same property and it's because Hindley Milner
3836720	3841840	is somehow resolving the quantifiers for you and it's very, very low power, very easy, very
3841840	3846400	predictable. You don't make a change to your code over here and suddenly the proof stops going through.
3847040	3854240	So, so I think that there's a lot to be said for the ergonomics of the language and the IDE and
3854240	3858080	the experience, particularly developing in cloud, you know, I'm talking about Amazon, but if you're
3858080	3863120	developing programs in cloud, the ergonomics of how do you develop that and understand the program
3863120	3867920	such that you don't have to like SSH over to some other machine to find out what the machine
3867920	3872880	that's stated in, I think are very, very important. So, so I think that automated reasoning,
3873600	3879440	programming languages and the sort of software development experience go really hand in hand
3879440	3882960	and there's some very powerful experiences we can have now that we couldn't have before.
3886320	3887920	Great. Other questions?
3890720	3897120	Okay. I think it's time to thank Byron for a wonderful talk. And I believe though there are
3897120	3901280	going to be refreshments out in the chat window room again. Okay. Thank you all.
