1
00:00:00,000 --> 00:00:16,800
Hello. Welcome everyone to the sixth annual Turing lecture. This lecture series is a part

2
00:00:16,800 --> 00:00:23,520
of a broader effort at Kings called the Alan Turing at Kings Initiative. And this is an

3
00:00:23,520 --> 00:00:30,400
initiative to raise funds for studentships, fellowships, and other academic endeavors.

4
00:00:30,960 --> 00:00:39,840
These lectures are essentially all of them are focused on topics that somehow relate

5
00:00:39,840 --> 00:00:47,200
legacy of Alan Turing. And today's talk is going to be about what computer scientists

6
00:00:47,200 --> 00:00:53,840
like to call formal methods. And this means applying logic and mathematics to the reasoning

7
00:00:53,840 --> 00:00:59,200
about the correctness of programs basically, or building tools to help people do that kind of

8
00:00:59,200 --> 00:01:08,640
thing. And our speaker Byron Cook is a professor at UCL and a vice president and distinguished

9
00:01:08,640 --> 00:01:18,720
scientist at Amazon. And Byron has been sort of at the cutting edge of actually applying formal

10
00:01:18,720 --> 00:01:26,720
methods in the real world. So the work he did, for example, at Intel very early on when Intel

11
00:01:26,720 --> 00:01:32,800
was having problems with chip design, I don't know if you remember the Pentium bug, but that certainly

12
00:01:33,760 --> 00:01:39,440
stimulated a lot of effort to use formal methods in proving the design of circuits

13
00:01:40,080 --> 00:01:48,000
correct. Byron then went on to Microsoft where he developed a lot of verification tools that were

14
00:01:48,000 --> 00:01:57,520
essentially solving the problems that Turing proved were unsolvable. And it turns out many of

15
00:01:57,600 --> 00:02:04,960
them are solvable in practice. And that sort of that work got rid of the blue screen. Remember

16
00:02:04,960 --> 00:02:10,320
the blue screen of death from Microsoft? Well, that work pretty much got rid of that blue screen

17
00:02:10,320 --> 00:02:18,400
of death. And then from there, Byron went on to Amazon where he really spearheaded the formation

18
00:02:18,400 --> 00:02:25,360
of formal methods groups at Amazon. And today Byron tells me there are over 600 people at Amazon

19
00:02:25,360 --> 00:02:31,680
working on formal methods, and over 20 groups doing that kind of thing. So apparently this kind

20
00:02:31,680 --> 00:02:40,880
of work touches every aspect of Amazon's development and rollout of their services. And I just want

21
00:02:40,880 --> 00:02:47,600
to say that when I did my PhD in kind of in this area back in the 80s, this was considered like

22
00:02:47,600 --> 00:02:54,240
kind of crazy stuff that no one would ever use, that was too impractical, it was focused on toy

23
00:02:54,240 --> 00:02:59,840
problems. No one is ever going to use this stuff. And I think for me, it's very satisfying to see

24
00:03:01,520 --> 00:03:08,560
what someone like Byron is doing now, like actually bringing these ideas and technologies

25
00:03:08,560 --> 00:03:15,360
into the real world, making real impact with them. So I'd like to introduce Byron.

26
00:03:15,360 --> 00:03:23,600
So we finally figured it out. And it's a huge honor for me to be invited and to be associated with

27
00:03:24,480 --> 00:03:29,200
Alan Turing and Kings. I hope you all read the abstract and know what you've signed yourself

28
00:03:29,200 --> 00:03:37,600
up for. So I'm going to tell you, I'm going to attempt to tell you something rather technical,

29
00:03:37,600 --> 00:03:42,720
but I've promised to aim it at a general audience, and I think I'm going to fail horribly,

30
00:03:42,720 --> 00:03:49,040
but let's have a good time together. So we'll see if that works. As I was preparing this talk,

31
00:03:49,120 --> 00:03:55,840
I'm like, oh, what have I done to myself? But I think this talk brings something for everyone.

32
00:03:55,840 --> 00:04:03,440
So I think that the technical people in the space will enjoy pieces of it. And then those of you

33
00:04:03,440 --> 00:04:09,200
who don't come from the space, I hope you'll take away something from it. That's interesting to you.

34
00:04:09,200 --> 00:04:18,800
So this talk takes a needle and thread through a bunch of characters that are Cambridge based.

35
00:04:19,760 --> 00:04:24,080
I was really excited to be invited to give this talk because it's a very Cambridge story.

36
00:04:24,080 --> 00:04:30,560
There's a King's story. So there's some characters that were King's people. Frank Ramsey is a really

37
00:04:30,560 --> 00:04:35,360
interesting character. I mean, he's a lot less well known than Turing, but also very, very important.

38
00:04:36,640 --> 00:04:44,640
King's person, sort of the boy of wonder actually born in Cambridge, born just on the other side of

39
00:04:45,200 --> 00:04:50,720
Jesus' dream at the locked bridge, the house when you cross the locked bridge. He was born there.

40
00:04:50,720 --> 00:04:56,000
And then because father was at Muddlin, and then he was here. And I think he worked with this chap

41
00:04:56,000 --> 00:05:05,120
quite a bit. And then, unfortunately, he died. I read his new biography about him. And from what

42
00:05:05,120 --> 00:05:10,240
I can work out from the biography, he died from a disease he caught by swimming in the camp. So

43
00:05:10,880 --> 00:05:17,600
you need to be comfortable. And then Alan Turing, I don't think I need to introduce.

44
00:05:18,400 --> 00:05:24,000
There's another character, which is the spinning beach ball on the top left, just above Frank

45
00:05:24,000 --> 00:05:28,960
Ramsey. And so some of you may be familiar with this concept. So I'm going to give you a bit of

46
00:05:28,960 --> 00:05:34,560
IT advice. So if you take nothing else away from this talk, you can take this. When you see that,

47
00:05:34,560 --> 00:05:40,320
what you need to do is you need to go into the force quit applications of your Mac, find the

48
00:05:40,320 --> 00:05:45,840
program, and kill it. And hopefully that will take care of it, though it might be there's an

49
00:05:45,840 --> 00:05:49,120
infant. So then what's happening here is there's an infinite loop in one of your programs, and

50
00:05:49,120 --> 00:05:52,560
it's causing it to hang. Hopefully it's not in the operating system, because now you're really

51
00:05:52,560 --> 00:05:56,880
in trouble. But if it's in, but if it's in the, but if it's in like a Chrome or Outlook or something

52
00:05:56,880 --> 00:06:00,960
like that, you'll kill it, you'll lose your data. But you know, that's, that's how it goes. And if

53
00:06:01,040 --> 00:06:06,960
you use Windows, this is kind of what it looks like in a similar situation. If you use a phone,

54
00:06:07,680 --> 00:06:12,800
this is what it would like to look like. But I believe the phones are designed that after a certain,

55
00:06:12,800 --> 00:06:19,920
quite short amount of time, they just reboot the phone. So the Mac, luckily, doesn't reboot itself

56
00:06:19,920 --> 00:06:24,080
every time that it gets stuck in an infinite loop. But the phones, I think, are designed to

57
00:06:24,080 --> 00:06:28,800
just, just reboot. So you may, and you may not even notice the way that the phones are assigned.

58
00:06:29,760 --> 00:06:34,320
But we also have this problem. So it turns out that our bodies get, there's little infinite loops

59
00:06:34,320 --> 00:06:39,680
sometimes that we find very unpleasant. So this is skin cancer. And it turns out that skin cancer

60
00:06:39,680 --> 00:06:46,480
is, in a sense, the, the, the regulatory mechanisms in your, in your body to maintain

61
00:06:46,480 --> 00:06:51,600
cell growth and death. And so skin cancer is your bug, is your body kind of going into one of these

62
00:06:51,680 --> 00:07:00,320
states. Okay. So the quest is to build tools that can talk now about what's going to happen in the

63
00:07:00,320 --> 00:07:06,560
future. So we want to, we want to build a tool that takes a program and says things that usually

64
00:07:06,560 --> 00:07:12,320
have the word eventually in them. So, hey, you know, like, when I press this button,

65
00:07:13,200 --> 00:07:18,240
does do the rockets eventually launch? Or, or, or when, you know, like, if I ask this question,

66
00:07:18,240 --> 00:07:27,280
will I eventually get the answer? Or if, or if I model disease as a, as a, as a system, and then

67
00:07:27,280 --> 00:07:32,560
I want to like make a change to characterize the change, I think that we should make for, for, for

68
00:07:32,560 --> 00:07:37,200
medicine. Now does the system eventually do the thing I wanted to do? Does the, does the, does the

69
00:07:37,200 --> 00:07:43,920
cell growth stop and, and, and, and, and we, we reach homeostasis. So that's, that's the kind

70
00:07:43,920 --> 00:07:47,760
of things we want to do. And we want to do this without actually running the system. We want to

71
00:07:47,760 --> 00:07:54,080
take the system and reason about it. Because we may not have the whole whole of the entire system.

72
00:07:54,080 --> 00:07:58,320
And also we don't want to like interact with the world, but we don't actually want to launch the

73
00:07:58,320 --> 00:08:03,760
rockets to learn the law, rockets will be launched. We want to ask, you know, in some theoretical world

74
00:08:03,760 --> 00:08:09,920
where we launch the rockets. Okay, so just a bit of bookkeeping. I know myself, and I'm going to use

75
00:08:09,920 --> 00:08:15,200
all these words to mean the same thing. So I just, just, just to take a moment, the halting problem,

76
00:08:15,200 --> 00:08:20,080
the question of program termination, finding infinite loops and talking about systems that,

77
00:08:20,080 --> 00:08:24,080
like trying to show that systems don't hang. It's all the same thing. So when you hear me talk,

78
00:08:24,080 --> 00:08:29,280
say, in one breath, I'm saying program termination and, you know, three breaths later, I'm talking

79
00:08:29,280 --> 00:08:33,280
about the halting problem. It's all the same thing. This is, this is again for the, for the

80
00:08:33,280 --> 00:08:39,680
non-technical people on the crowd. Okay, so what is program termination? So for those of you who

81
00:08:39,680 --> 00:08:44,400
know what program termination is and know what programs are, bear with me for a moment. We're

82
00:08:44,400 --> 00:08:49,520
going to take a one-minute tutorial on programs and program termination, but also this program will

83
00:08:49,520 --> 00:08:56,000
show up from time to time. So, so it's sort of worth it to everybody. So here's a program. I'm sort

84
00:08:56,000 --> 00:09:01,680
of assuming a few of you are in the, I know at least one or two people in the room don't, don't

85
00:09:01,680 --> 00:09:08,240
know how to program because they're my family. And, and so what this, this is a program written

86
00:09:08,240 --> 00:09:13,280
in Python, a language called Python. And what happens in this program is the first thing it

87
00:09:13,280 --> 00:09:21,200
does is it says, this is a, a while loop. So it says, Hey, is in greater than one? If, if so,

88
00:09:22,240 --> 00:09:29,360
go here, do what it says, come back and then ask again. Is in greater than one? Okay, go here,

89
00:09:29,360 --> 00:09:36,080
do what it says, come back, ask again. And the idea is, is that this code here is modifying in

90
00:09:36,080 --> 00:09:43,280
and the, and, and one would hope that eventually the code that's modifying in would make in be

91
00:09:43,280 --> 00:09:49,920
that not greater than one, in which case now the loop would terminate. Okay, so that's the idea.

92
00:09:49,920 --> 00:09:54,960
So this is a computer program. That's a while loop. Sometimes while loops, you want them to run

93
00:09:54,960 --> 00:10:00,240
forever. For example, like you're, you want your actual computer to run forever, but inside the

94
00:10:00,240 --> 00:10:05,120
computer, inside that loop is often some code that you really want to terminate. And that way

95
00:10:05,120 --> 00:10:09,360
you can get back to the start of the loop. So often systems are written with one big while loop

96
00:10:09,360 --> 00:10:14,880
that you want to run forever. And then code inside the while loop you want to terminate. And that

97
00:10:14,880 --> 00:10:23,120
code may look something like this. Okay, that was your one minute tutorial. This is a really

98
00:10:23,120 --> 00:10:28,800
interesting program. So this is a wicked little program actually. So this is called the Colatz

99
00:10:28,800 --> 00:10:34,400
conjecture. And no one knows if this program terminates. And what I mean by that is,

100
00:10:35,200 --> 00:10:42,080
so a program is, we would say it guarantees termination if for all possible values of in.

101
00:10:42,080 --> 00:10:47,680
So in here actually could range over all mathematical integers. And so for all possible

102
00:10:47,680 --> 00:10:54,000
values of in, does this program guarantee to exit? No one knows the answer to that question.

103
00:10:54,640 --> 00:10:59,280
So program guarantee termination, if you know that's true for all possible, no one knows.

104
00:11:00,720 --> 00:11:04,960
And this is, there's some really great quotes here. So I wonder if this has a pointer.

105
00:11:06,320 --> 00:11:11,520
Yeah. So this is called the Colatz conjecture, but it's also called the three and plus one

106
00:11:12,160 --> 00:11:17,920
problem. It has some great names, whereas it, the Hellstone numerals, the Thwaites conjecture.

107
00:11:18,560 --> 00:11:25,360
And then look at this great, great quote here that from Paul Orteff. Mathematics may not be ready

108
00:11:25,360 --> 00:11:34,720
for such problems. It's extraordinarily difficult, completely out of reach for present day mathematics.

109
00:11:35,680 --> 00:11:45,120
Look at that innocent little program. Okay, now as an aside, my colleague in Amazon,

110
00:11:45,120 --> 00:11:50,640
Marine Hula is so close to solving this puzzle. It's agonizing. I was really hoping I could say

111
00:11:50,640 --> 00:11:56,400
today, oh, and by the way, at Amazon, we solved it mic drop, but, but alas, I wasn't, alas, I wasn't

112
00:11:56,400 --> 00:12:01,920
able to. So he has this really, really fascinating paper that's very, very insightful, that combined

113
00:12:01,920 --> 00:12:06,400
some really beautiful, it's just, it's such a beautiful paper. So they're really making some

114
00:12:06,400 --> 00:12:10,720
serious headway on this problem that I'm very excited about. Anyways, and, and back to Cambridge,

115
00:12:11,360 --> 00:12:16,720
back to Cambridge. So, so there's another really interesting character that's, that's, that's,

116
00:12:16,720 --> 00:12:22,800
that's, so, so, Frank Ramsey was the Kings, Alan Turing was the Kings, and Byron Cook,

117
00:12:24,080 --> 00:12:31,920
oh, you know, cycled by Kings. For, for six years, I cycled by Kings, and I cycled

118
00:12:31,920 --> 00:12:36,160
by Kings on my way to Microsoft Research, which at the time was that in West Cambridge,

119
00:12:36,160 --> 00:12:42,560
now it's by the station. And when I cycled to, to, to, to, to Microsoft Research,

120
00:12:43,760 --> 00:12:48,720
a lot of my work was with these two jobs. So this is Andre Rybolchenko, who is my intern,

121
00:12:49,920 --> 00:12:54,080
and then a longtime collaborator, he's actually later joined Microsoft Research, and then Andres

122
00:12:54,080 --> 00:13:00,240
Podolski, who is his PhD student. And, and what happened was that I decided to move, I'll tell

123
00:13:00,240 --> 00:13:04,240
you part of the story, I moved to Cambridge. And when I moved to Cambridge, a bunch of people who

124
00:13:04,320 --> 00:13:09,280
were in Europe, you know, I moved, you can probably hear, I'm American. So when I moved

125
00:13:09,280 --> 00:13:13,760
to Cambridge, a bunch of people who are in Europe were like, oh, wow, cool, we should work together.

126
00:13:13,760 --> 00:13:16,880
And these, and these were one of the, one of the, one of the sets of people who do that.

127
00:13:16,880 --> 00:13:22,000
And so I did this work with them that was really explosive. And so I ended up the, all the, all

128
00:13:22,000 --> 00:13:26,560
these other people were like, wow, that's super cool. We should like, there were like possible ways

129
00:13:26,560 --> 00:13:30,400
that we can solve other problems that were related. So I ended up working with a whole network of

130
00:13:30,400 --> 00:13:34,640
people. And it was really a very, very exciting time. And many of these people spent much of their

131
00:13:34,640 --> 00:13:43,360
time in Cambridge. And there were, of course, many scientific papers. And they all used theories

132
00:13:43,360 --> 00:13:48,240
from Ramsey and Turing. So that's, that's, that is what we're going to talk about today.

133
00:13:49,760 --> 00:13:55,760
Okay, let's start at the beginning. So, and here I'm going to, I'm going to do a little bit of

134
00:13:55,760 --> 00:14:01,120
guesswork. So I, so I don't know if you know that there's this, the Greeks, the ancient Greeks had

135
00:14:01,120 --> 00:14:08,800
this like, calculating device, right, that would, that would, that would predict eclipses, for example.

136
00:14:08,800 --> 00:14:13,200
Meanwhile, they're also doing proofs, right? They have, they, they, they, the Pythagorean

137
00:14:13,200 --> 00:14:18,720
theorem, you know, there's all this work kind of in the, the Greek empire. So it must be,

138
00:14:18,720 --> 00:14:24,480
and here I'm just guessing, it must be that someone in town, sorry, some, someone in town

139
00:14:24,480 --> 00:14:28,960
thought, hey, could we get the device to prove theorems for us, right? It's just, it's inescapable

140
00:14:28,960 --> 00:14:36,960
that that's true. So I would believe that that must be when, you know, our, our people, our ancestors

141
00:14:36,960 --> 00:14:45,520
first said, machines, mathematics, let's put them together, right? But what, what I do know is that

142
00:14:45,520 --> 00:14:51,920
from the, from the, is that Leibniz explicitly asked us, right? So, and we calculate the truth

143
00:14:51,920 --> 00:14:58,640
of any mathematical statement. That's the sort of fundamental thing we want to do. And so here's

144
00:14:58,640 --> 00:15:02,320
what this would look like kind of in our modern world. So imagine on your phone, you have some

145
00:15:02,320 --> 00:15:07,520
magic AI app, and you could ask it simple questions like, hey, is there a number between,

146
00:15:07,520 --> 00:15:12,480
this is an easy one, is there a number between 10 and 20? Yes, there is, 11, try that, okay.

147
00:15:14,640 --> 00:15:20,320
Is the Colatz conjecture valid, right? And, and the, and the idea is that the answer produced

148
00:15:20,320 --> 00:15:25,360
must be correct. That's the game we're playing. That's, that's what Leibniz suggested. And that's

149
00:15:25,360 --> 00:15:31,120
what, you know, we're going to talk about much of today. And, and maybe it's not an acceptable

150
00:15:31,120 --> 00:15:37,120
answer. You can't say maybe in this sort of, in this, in this purest Leibniz world, and you can't

151
00:15:37,680 --> 00:15:41,760
run forever trying to, as well, give me, give me some time. And I'm going to go off and compute

152
00:15:41,760 --> 00:15:46,080
forever and just never come back, come back with an answer. No, that's not allowed either.

153
00:15:46,640 --> 00:15:51,040
You have to answer the question, and you have to answer it in a finite amount of time. That's the

154
00:15:51,040 --> 00:15:56,400
rules of the game. Today, we would call this automated reasoning. So if you look at like my

155
00:15:56,400 --> 00:16:00,240
title, or like the groups that we have, the groups in Amazon, all these like 20 teams are called,

156
00:16:00,240 --> 00:16:05,040
you know, identity automated reasoning team, or crypto automated reasoning team, storage

157
00:16:05,040 --> 00:16:08,880
automated reasoning team. So automated reasoning is what we do. And practically, there's a few

158
00:16:08,880 --> 00:16:14,080
people from the crowd, you're all laughing, because you, you, you know, that we've kind of given up

159
00:16:14,080 --> 00:16:19,280
on requiring you can't say maybe or time, or time out from time to time, right? So we're

160
00:16:19,280 --> 00:16:23,040
practical people and we're like, eh, sometimes we don't know the answer, right? But, but, but the

161
00:16:23,040 --> 00:16:31,680
purists didn't think that. So in this, this paper, paper book by Hilbert and Ackerman named it,

162
00:16:31,680 --> 00:16:36,320
the decision problem. And I'm not going to try and pronounce the German, right? But it's,

163
00:16:36,320 --> 00:16:43,280
it's called the decision problem. And this, this was came out in 1928. And this got everyone in

164
00:16:43,280 --> 00:16:48,800
the mathematics logic world very, very excited. So back here in Cambridge, both Ramsey and Turing

165
00:16:48,800 --> 00:16:54,720
were like, Oh, the decision problem, that's super cool. Can you automate reasoning about mathematical

166
00:16:54,720 --> 00:16:59,760
logic and mathematics, such that you always get an answer, you know, super cool, super cool problem

167
00:16:59,760 --> 00:17:03,440
for them. And they, and they, and they both did some interesting works. And now we're going to talk

168
00:17:03,440 --> 00:17:10,080
about that. So Ramsey had this, had this very nice paper right before he died, unfortunately.

169
00:17:10,800 --> 00:17:19,280
And he didn't prove or disprove the possibility of there being a general solution to the decision

170
00:17:19,280 --> 00:17:25,040
problem. But he, but he did something else instead. And so what I'm going to, I'm going to, I'm going

171
00:17:25,040 --> 00:17:30,240
to, we're just going to take a moment to introduce a little bit of visual notation. So there's an

172
00:17:30,240 --> 00:17:37,840
idea of a graph. Graphs have nodes, graphs have edges, edges are the arrows. And the idea is you

173
00:17:37,840 --> 00:17:44,000
can go from A to B if there's an arrow. Okay, that's a graph. That's a sort of fundamental

174
00:17:44,000 --> 00:17:49,360
concept that you see in computer science and mathematics. And what we could do is we could

175
00:17:49,360 --> 00:17:54,800
color the edges. So I could color some of them red, some of them blue, some of them green.

176
00:17:55,520 --> 00:18:00,240
And then what Ramsey did is he has this really, really amazing result that's about

177
00:18:01,280 --> 00:18:06,960
monochromatic subgraphs. So here's, here's, here's a monochromatic subgraph. It's, it's like the

178
00:18:06,960 --> 00:18:13,600
original graph, but with only the red arrows. And there's sort of different flavors to the Ramsey

179
00:18:13,600 --> 00:18:18,800
theorems, or there's a sort of Ramsey theorem is kind of a family of statements. But what's really

180
00:18:18,800 --> 00:18:24,320
amazing about it is he says, if, if your graph is infinite, I can't, I can't show you an infinite

181
00:18:24,320 --> 00:18:31,440
graph on this finite screen, but imagine it's infinite. If you have an infinite graph, and a

182
00:18:31,440 --> 00:18:34,240
couple of other conditions are met that I don't really want to tell you about, because they

183
00:18:34,240 --> 00:18:43,520
knows to turn into a math lecture, then, then there exists an infinite monochromatic subgraph.

184
00:18:44,560 --> 00:18:48,640
And that's going to turn out to be a very, very powerful tool for us. So take this graph,

185
00:18:48,640 --> 00:18:53,920
if it's infinite, it's also complete for those of you who know what that means, but it doesn't matter.

186
00:18:53,920 --> 00:19:00,240
And, and the number of colors is finite, then there's going to be an infinite

187
00:19:00,240 --> 00:19:09,600
monochromatic subgraph. Okay, remember that. Meanwhile, Alan Turing read this paper

188
00:19:12,400 --> 00:19:23,760
by Kurt Gertl that was the start of the argument as to why there could be no solution to the

189
00:19:23,760 --> 00:19:29,920
decision problem. And what he did was he wrote this paper that he's, you know, famous for,

190
00:19:29,920 --> 00:19:35,520
I mean, it was, if you saw the exhibit today, you saw his copy of the paper. And, and I mean,

191
00:19:35,520 --> 00:19:41,280
I think this is, this is probably the most studied theoretical science, theoretical computer science,

192
00:19:41,280 --> 00:19:44,880
I mean, basically started theoretical computer science. So this is like absolutely fundamental

193
00:19:44,880 --> 00:19:50,480
paper. And so he's, I'm going to, I'm going to frame this in terms of graphs. But he basically,

194
00:19:50,480 --> 00:19:54,720
you know, you know, I don't want to overstate this too much, but you can basically invent the idea of

195
00:19:54,720 --> 00:20:01,040
like the, the, the, the idea of what computation is, like, I mean, people were doing computation

196
00:20:01,040 --> 00:20:06,720
before and we had machines, but, but essentially he's like, he talked about that in terms of,

197
00:20:06,720 --> 00:20:11,360
he combined that to mathematics, let's say. And again, we can think of like a Turing machine,

198
00:20:11,360 --> 00:20:15,200
you can think of as a graph where it's like, what are the possible transitions between,

199
00:20:15,200 --> 00:20:19,120
between, between a Turing machine. So I'm going to, I'm going to explain this with my phone.

200
00:20:20,160 --> 00:20:23,920
So by the way, the iPhone is like so much more powerful than anything he probably could have

201
00:20:23,920 --> 00:20:28,560
possible imagined, right? So it's a really, really, it's a super computer in your, in your,

202
00:20:28,560 --> 00:20:37,600
in your, in your pocket. And so, so here's me and my phone, I open up my email, I write reply,

203
00:20:38,560 --> 00:20:44,960
and then, and then I hit send. Okay. And then, and then in the sort of Turing view,

204
00:20:45,280 --> 00:20:54,320
each state of each configuration of my iPhone is a state, and then you have transitions between

205
00:20:54,320 --> 00:21:03,040
the states. So I can go from me opening it, seeing Tim's mail, saying my reply, hitting send, that,

206
00:21:03,040 --> 00:21:07,520
that's, that's a progression. And that, and that states, states and configurations. Okay,

207
00:21:07,520 --> 00:21:10,960
that's a little, that was a little bit of background. Let's look at this program. Remember

208
00:21:11,040 --> 00:21:20,080
this one? I've added, by the way, the, the line numbers. So you could have a state of the system

209
00:21:20,960 --> 00:21:27,440
where the value of n is 20, and the location is location one. So we're at this line of the program,

210
00:21:27,440 --> 00:21:35,600
and n is equal to 20. And then we can transition to the value of n being 20, and the location being

211
00:21:35,600 --> 00:21:44,480
20. Okay, get it? Okay. So what he said was, is that we know that there will be, always be programs

212
00:21:44,480 --> 00:21:50,240
for which we can't answer the basic question of termination. So it's, it's what we say is, it's,

213
00:21:50,240 --> 00:21:58,880
it's undecidable, right? So I, the answer is no, we cannot calculate the truth of any mathematical

214
00:21:58,880 --> 00:22:06,000
statement. Because if you could, the, the, the question of program termination is one of those

215
00:22:06,000 --> 00:22:12,400
mathematical things. And he sort of linked up the idea of computer programs to what's computable,

216
00:22:12,400 --> 00:22:18,000
to mathematics, and then said, well, this thing can't be solved and the, and he bridged the gap

217
00:22:18,000 --> 00:22:24,800
over to the mathematical side. Super cool result. leaves us in a bit of a lurch, though, in terms of

218
00:22:24,800 --> 00:22:31,920
like he sort of identified a sort of Achilles heel of computers. And so I'll, I'll, I'll illustrate

219
00:22:31,920 --> 00:22:38,880
that by what was stressing me out in 2003. So here's a list from Microsoft.com, sorry,

220
00:22:38,880 --> 00:22:44,960
and the I'm going to poke on Microsoft a little bit now that work at Amazon of, of, of device

221
00:22:44,960 --> 00:22:49,200
drivers that you could download. And you could put these in these, you could put these into your

222
00:22:49,200 --> 00:22:56,640
machine. And each of these device drivers is backed by source code. And the problem is that

223
00:22:56,640 --> 00:23:01,520
there may be device drivers out there for which we can't answer the termination question. And boy,

224
00:23:01,520 --> 00:23:06,640
when a device driver goes into an infinite loop, we're in a world of hurt, like that is a really

225
00:23:06,640 --> 00:23:11,360
bad situation. Because now like you, your, all your programs are going to start hanging, like

226
00:23:11,360 --> 00:23:14,960
that this can be, this can be a very, very bad situation. We don't want that to happen.

227
00:23:15,920 --> 00:23:20,480
So non-terminating device drivers hang your computer and hang them often in quite bad ways.

228
00:23:21,760 --> 00:23:27,440
But what's not so known, who knows about raise your hand if you know the paper, checking a

229
00:23:27,440 --> 00:23:34,960
large routine by all in turn. One hand, that's staggering. Really, you don't know this paper.

230
00:23:36,640 --> 00:23:41,440
People, people in automated reasoning in, in, in Amazon, pull up your hand if you don't, if you,

231
00:23:41,440 --> 00:23:45,600
if you work for Amazon and you don't know this paper. That's interesting. Okay. Great. Well,

232
00:23:45,600 --> 00:23:48,560
you're going to know about the paper. I think this is one of the most interesting papers there is.

233
00:23:48,560 --> 00:23:55,040
This, this comes from 1949. He totally tells us how to do our job. It's amazing. So, so he gives

234
00:23:55,040 --> 00:24:05,200
a very clear instruction for how to prove a program terminating. 1949, I think. And so I'm,

235
00:24:05,200 --> 00:24:10,480
now I'm going to put a few words in Ellen Turing's mouth. So he doesn't quite say this, but he says,

236
00:24:10,720 --> 00:24:14,560
but basically between the, read between the lines, what Ellen Turing is really saying is,

237
00:24:15,760 --> 00:24:21,360
in practical cases, we can answer the termination question. And then furthermore, in cases where

238
00:24:21,360 --> 00:24:27,920
we can't, we just return maybe, what's the big deal? Right? Like, it's like, yeah, yeah, yeah,

239
00:24:27,920 --> 00:24:32,560
I proved the halting problem undecidable, get over it. Like, life moves on. Now we need to do

240
00:24:32,560 --> 00:24:37,200
practical stuff. We have computers. Remember the war, like computers are cool. Let's, let's, let's,

241
00:24:38,000 --> 00:24:44,720
let's do good things here. And so to think about this, think about like British Airways, right?

242
00:24:45,280 --> 00:24:53,520
On time arrival is not guaranteed. But, and I know you're probably all winging about British

243
00:24:53,520 --> 00:24:58,640
Airways right now, but they're pretty good. Like you, you do often arrive most of the time, right?

244
00:24:58,640 --> 00:25:05,040
You arrive, you arrive, you get on time arrival often enough that you think, I'll fly again.

245
00:25:05,760 --> 00:25:10,800
So, so, so they're, they're not horrible. So the real, the real thing that they need to do is just

246
00:25:11,440 --> 00:25:16,000
to make on time arrival frequent enough to make the airline useful to their customers.

247
00:25:16,800 --> 00:25:21,680
And it's the same with, with Termination Prover. So if you're building a tool to analyze termination

248
00:25:21,680 --> 00:25:28,160
of program, so long as the tool answers often enough with the right answer, then, then you're

249
00:25:28,160 --> 00:25:32,560
going to use it even if you're, even if you know from time to time, it's not, it's not, it's not,

250
00:25:32,560 --> 00:25:36,800
it's not going to give you, it's, it's, it's not going to be able to answer it. And, but, you know,

251
00:25:36,800 --> 00:25:40,560
the answers need to be correct. Yes or no answers need to be correct.

252
00:25:42,640 --> 00:25:51,440
Okay. So in 2004, what, what Andreas and Andre, and I, oh, sorry, I want to say something else.

253
00:25:54,000 --> 00:25:56,480
This paper on the left, the Turing's famous paper,

254
00:25:56,800 --> 00:26:08,800
has kind of been a buzzkill in, in the, in the IT industry. It's, people do not, what's the,

255
00:26:09,760 --> 00:26:14,400
the thing is you do an improv, you don't say no, you say yes and right. So there's a whole lot of

256
00:26:14,400 --> 00:26:18,720
people who didn't study improv apparently in the IT industry. And so if ever you have some idea,

257
00:26:18,720 --> 00:26:25,280
like, oh, I know we could do X, Y and Z, someone's going to be like, that's the whole thing problem,

258
00:26:25,280 --> 00:26:30,720
you can't do that. And oh, I feel shame. Sorry, I suggested it. Let's not solve the problem at all.

259
00:26:30,720 --> 00:26:34,080
Sorry. And that's, that happens a lot. I mean, I've seen that personally a bunch of times that

260
00:26:34,080 --> 00:26:40,880
you hear that a lot. So this is like the most abused theoretical results in computer science that

261
00:26:41,760 --> 00:26:45,680
because it's the halting problem, don't even try, you know, like life is too hard.

262
00:26:47,840 --> 00:26:53,760
But very, very, very few people in 2004 thought it was, it was practical, even in my own field.

263
00:26:54,720 --> 00:26:59,200
Like, you would talk, you would talk to people on my own field. The vast majority of people would

264
00:26:59,200 --> 00:27:03,920
be like, but it's undecidable. But it's like, yeah, but so is the state space reachability problem

265
00:27:03,920 --> 00:27:09,280
for infinite state systems. But they did, oh, yeah, forgot about that. So, but, but with,

266
00:27:10,000 --> 00:27:16,240
with the exception of some brave souls. So there were a few brave souls that were, that were trying

267
00:27:16,240 --> 00:27:21,840
to solve this problem. But the problem for them is that their tools all solved this only for

268
00:27:21,840 --> 00:27:26,320
little tiny programs, like little eight-line programs, seven-line programs. So they, and they

269
00:27:26,320 --> 00:27:30,880
didn't have sort of any of the actual features you'd see in real programs like pointers and

270
00:27:31,520 --> 00:27:36,960
concurrency or any of that. So they were fun. They're super fun, but they weren't actually going

271
00:27:36,960 --> 00:27:43,120
to solve anything. And so that's, that's where Terminator steps in. So this is a tool that Andre

272
00:27:43,120 --> 00:27:47,120
and Andreas and I wrote. And by the way, if you're Cambridge people, do you know this ride?

273
00:27:47,760 --> 00:27:50,800
Have you seen this? I don't know if they have this anymore. So this is at least when I lived here

274
00:27:50,800 --> 00:27:55,120
in the mid-summer, common every summer, they would truck in these rides, right? And so then

275
00:27:55,120 --> 00:27:58,880
this was one of the rides. So I was looking through my photos for this talk, and there's so many

276
00:27:58,880 --> 00:28:06,240
photos of me in front of the Terminator ride because I did Terminator. Okay. So, so what we did

277
00:28:06,240 --> 00:28:14,800
is we, is we looked at this, the Turing paper and had a good read, right? So what we realized was,

278
00:28:14,800 --> 00:28:18,400
is that, hey, there's actually two parts. And I'm going to tell you about that. So there's two

279
00:28:18,400 --> 00:28:22,720
parts to solve and you can still solve them with independent bits. And then, and then, and then,

280
00:28:22,720 --> 00:28:28,800
and then you're done. So now I've put up a paper, I put up three paragraphs from a paper that's 74

281
00:28:28,800 --> 00:28:33,760
years old, that's referring to a figure that's not included in the screenshot. So we're not going

282
00:28:33,760 --> 00:28:36,960
to make it very far through this paragraph clearly. And it's written in language no one would know.

283
00:28:36,960 --> 00:28:41,680
But I just draw your attention to the first line. I move over here so I can see it.

284
00:28:42,640 --> 00:28:46,560
In order to assist the checker, the checker is the person doing the proof or the tool.

285
00:28:47,360 --> 00:28:51,760
The programmer should make assertions about the various states that the machine,

286
00:28:51,760 --> 00:28:56,880
that's the program, can reach. And the reach is a really interesting bit. So,

287
00:28:57,920 --> 00:29:03,600
so imagine that these states are unreachable. Imagine these states are reachable. But that

288
00:29:03,600 --> 00:29:08,560
turns out there's no path over here. And here's a little infinite loop. Here's a what is that six

289
00:29:08,560 --> 00:29:13,040
states that could be repeated forever over and over and over again. So imagine this is my iPhone,

290
00:29:13,600 --> 00:29:18,160
so I have six configurations of my iPhone and they're just going around and around and around

291
00:29:18,160 --> 00:29:23,600
between those configurations. But it doesn't matter because it's unreachable. So there's tons

292
00:29:23,600 --> 00:29:29,200
of termination bugs in your phone, tons of termination bugs in your computer that are never

293
00:29:29,200 --> 00:29:32,320
going to be triggered. You're never actually going to experience them because they're unreachable.

294
00:29:32,320 --> 00:29:35,760
And that first three paragraphs is all about that. It's just about reachability.

295
00:29:36,560 --> 00:29:45,120
So, yeah, kind of, I think I upset that. So we were like, okay,

296
00:29:46,400 --> 00:29:52,240
turns out I worked on reachability. So we know how to do this, right? So let's,

297
00:29:52,240 --> 00:29:55,920
let's, so what, what, what, why was I working on reachability? So now we're going to take a

298
00:29:55,920 --> 00:29:59,920
little, a little psych, we're going to move over to Seattle for a few moments. So it turned out in

299
00:29:59,920 --> 00:30:10,320
2003 that 85% of crashes in Windows XP were due to device drivers. And that was a big business

300
00:30:10,320 --> 00:30:16,480
problem for, for Microsoft at the time. So what we built over in Seattle area was a real world

301
00:30:16,480 --> 00:30:20,160
automated reasoning tool called static driver verifier in the research community. It was called

302
00:30:20,160 --> 00:30:26,080
SLAM, but for device driver writers, they knew it as static driver verifier. And what it was designed

303
00:30:26,160 --> 00:30:32,720
to do was to show error states reachable or unreachable. And so if you, this is the blue

304
00:30:32,720 --> 00:30:35,600
screen of death, you actually, you actually refer to that. This is the new blue screen of death,

305
00:30:35,600 --> 00:30:39,280
by the way, which you don't see very often these days. But this is what you get when your machine

306
00:30:39,280 --> 00:30:46,320
is like, sorry, lost all your data too bad, it sucks to be you. And this is what you would

307
00:30:46,320 --> 00:30:52,400
see on a Mac. And this is what you would see on a really old Mac. And so the question is,

308
00:30:52,480 --> 00:30:58,720
and I've sort of put this on purpose, is this line there or not? And remember these states,

309
00:30:58,720 --> 00:31:04,800
these state spaces are typically infinite. You can't just walk them explicitly. You have to like,

310
00:31:06,160 --> 00:31:12,000
you have to abstract infinite sets and do all kinds of trickery. But yes, we're trying to

311
00:31:12,000 --> 00:31:15,760
figure out, are things unreachable or are they reachable? And so there was a whole bunch of

312
00:31:15,760 --> 00:31:24,160
work that we did over in Seattle area. And I was involved in that. And Andrew Herbert,

313
00:31:24,160 --> 00:31:30,000
who's in the room here, I was visiting Cambridge and he was like, why don't you leave Seattle and

314
00:31:30,000 --> 00:31:34,800
come to Cambridge? The environment is great here and you'll have a good time. But I'm like, great,

315
00:31:34,800 --> 00:31:40,640
let's do it. So we, with eight weeks difference between that conversation, five weeks difference,

316
00:31:40,640 --> 00:31:47,600
my wife says, between that conversation and moving, I came, joined Microsoft Research,

317
00:31:47,600 --> 00:31:52,080
started chatting to these guys and said, let's work on the termination proving. So the point

318
00:31:52,080 --> 00:31:57,120
I'm making is that this problem was actually already pretty much solved. So it's just a question

319
00:31:57,120 --> 00:32:03,120
of reachability. So the red part is actually about, okay, now we've found a reachable state. How do

320
00:32:03,120 --> 00:32:07,280
we know that that reachable state doesn't lead to an non-terminating execution? And all the green

321
00:32:07,280 --> 00:32:16,720
bit is just about how do you show that states are unreachable? Okay, so let's look at this one.

322
00:32:16,720 --> 00:32:20,000
This one's fascinating. We're going to spend a little more time with this one.

323
00:32:20,640 --> 00:32:26,320
Finally, the checker has to verify that the process comes to an end. That just, I'm translating,

324
00:32:26,320 --> 00:32:31,280
that just means, okay, now we're going to prove termination. Again, he,

325
00:32:32,080 --> 00:32:38,720
you know, he or she should be assisted by the programmer giving a further definite assertion

326
00:32:38,720 --> 00:32:44,400
to be verified. So the point that he, what this he really in our, in our lingo today would be the

327
00:32:44,400 --> 00:32:51,120
prover, the tool. And so this may take the form of a quantity, which is asserted to decrease

328
00:32:51,120 --> 00:32:55,360
continuously and vanish. I'm going to translate all this, by the way, don't panic, and vanish

329
00:32:55,360 --> 00:32:59,920
when the machine stops to the, to the pure mathematician is natural to give an ordinal

330
00:32:59,920 --> 00:33:05,600
number. Don't, doesn't matter what that is. If you don't know, it doesn't matter. I love this line.

331
00:33:05,600 --> 00:33:16,160
A less-hybrid form of the same thing would be two to the 80 times n minus r plus two to the 40 times

332
00:33:16,160 --> 00:33:26,960
r minus, what is that, s plus k. Pretty cool, huh? Let me translate that. Can we find a function?

333
00:33:26,960 --> 00:33:31,600
I'll call it a, based on the, on the state, based on the variables of the, of the state,

334
00:33:32,560 --> 00:33:39,040
that will choose only positive, but also decreasing numbers. Okay. So imagine, let's look at my phone.

335
00:33:39,040 --> 00:33:44,240
I took a screenshot when I was writing this talk. I had seven Slack messages at the time, unread.

336
00:33:44,240 --> 00:33:49,440
So maybe the function is the number of Slack messages. One possible, it's not going to work

337
00:33:49,440 --> 00:33:55,680
very well, but another one, maybe be the amount of free space left on my phone. That's a little

338
00:33:55,680 --> 00:34:02,400
more reasonable. And then imagine we took a, a transition from this state to this state. I don't

339
00:34:02,400 --> 00:34:08,000
know, like who knows what, internally, you can't see it, but it made some transition. Maybe the

340
00:34:08,000 --> 00:34:14,960
amount of space, a free space has decreased, probably quite likely, right? Because of it,

341
00:34:14,960 --> 00:34:18,800
because the phone's actually doing little logs and all kinds, like it's always sort of using a

342
00:34:18,800 --> 00:34:24,560
little bit of more and more and more disk space, not disk, but you see what I mean. Whereas the

343
00:34:24,560 --> 00:34:29,440
number of Slack messages, well, we can see it stayed the same. So I had seven before, seven

344
00:34:29,440 --> 00:34:34,240
before, seven now. So that's not a good one. So this number didn't go down. So remember that the

345
00:34:34,240 --> 00:34:39,840
point, the point we're trying to make is we want to find a function, a function, some function F,

346
00:34:39,840 --> 00:34:44,480
that on every, that I'll always say this in a moment, that it finds decreasing, but positive

347
00:34:44,480 --> 00:34:50,160
numbers. And so what do we, what would we do with that? Oh, I think maybe, okay. And yeah. So

348
00:34:50,240 --> 00:34:55,040
here, for example, let's write a little function for this guy.

349
00:34:59,520 --> 00:35:06,640
Maybe what we do is we say, oh, well, let's do in minus the location. So we were at, in this value

350
00:35:06,640 --> 00:35:13,280
of 20, location is one. So maybe it's in minus X is 19. So it's just this number minus that number.

351
00:35:13,280 --> 00:35:21,040
And then the next one is 18 because I've now subtracted two. Okay. So that's a positive

352
00:35:21,040 --> 00:35:24,720
number and it's gone down. So that's possible. I mean, it's not going to work because no one

353
00:35:24,720 --> 00:35:30,480
knows that the program terminates, but that would be a plausible starting point as you begin your

354
00:35:31,440 --> 00:35:35,920
journey into this world. So the thing that we need to hold is whenever we take a transition

355
00:35:35,920 --> 00:35:40,400
from one state to another state or configuration to another configuration, and we have that function

356
00:35:40,400 --> 00:35:48,000
F and we map, the greater than needs to hold. So and if you, if you, if you say the pre-state is S,

357
00:35:48,000 --> 00:35:53,120
and then we apply F to S, and then we say the post-state is T, and we apply F to T, you need

358
00:35:53,120 --> 00:35:56,960
greater than to hold. And that's a condition that's required. So the idea of how to prove

359
00:35:56,960 --> 00:36:04,400
termination, and this is Turing's idea is find a function, think about it for a bit. Then if this

360
00:36:04,400 --> 00:36:09,200
condition holds for all possible transitions of your system, this holds, you're done. You've

361
00:36:09,200 --> 00:36:17,520
now proved termination. Okay. Right. So if you turn your head, you can see it. 19 is greater than 18.

362
00:36:18,400 --> 00:36:23,440
So now, why does this hold? So imagine a non-terminating execution. Again, this is infinite,

363
00:36:23,440 --> 00:36:27,040
so I can't, I can't show it to you on the screen, but here's the first few states.

364
00:36:29,040 --> 00:36:33,120
Now just begin applying this function. Oh, and by the way, we have the function. I already said that.

365
00:36:33,120 --> 00:36:37,440
And this condition holds. Now let's just begin applying it. And I'm making these numbers up,

366
00:36:37,440 --> 00:36:42,080
but imagine the first one's 30. We've got to choose 29 after that because it has to go down,

367
00:36:42,080 --> 00:36:47,440
27, 25, et cetera, et cetera, et cetera. We're going to run out of room. It has to be positive also.

368
00:36:47,440 --> 00:36:52,720
So now we're out of space. So I said, imagine we have an infinite execution, but we have

369
00:36:53,920 --> 00:36:59,040
a function F that's positive and decreasing. It turns out you can't have both, right?

370
00:36:59,680 --> 00:37:05,440
Right. And too far. You can't have both. You can't, you can't have a non-terminating execution

371
00:37:05,440 --> 00:37:10,960
and this function. You can only have one of the other, i.e., if you want to prove termination,

372
00:37:10,960 --> 00:37:15,120
find one of these, and you'll know that you don't have a non-terminating execution.

373
00:37:15,120 --> 00:37:20,240
Or if you have a non-terminating execution, you can't have one of these. It's a, it's a, it's a,

374
00:37:21,440 --> 00:37:25,520
there doesn't exist. If the program doesn't terminate, there cannot exist a function that

375
00:37:25,520 --> 00:37:31,280
meets those conditions. And so the trick is to find the F, right? And so Turing found the posh

376
00:37:31,280 --> 00:37:40,080
one and then he found the less posh one. Okay, I've kind of said already that. So now, so now

377
00:37:40,080 --> 00:37:45,840
the thing that we wanted to do was to automate this. And so, so consider any reachable state

378
00:37:46,960 --> 00:37:54,400
and, you know, maybe those states on my phone. And imagine we found an F, then it turns out

379
00:37:54,400 --> 00:38:01,520
it's super hard to find a single F. Like, like, and this is kind of why these tools from before

380
00:38:01,520 --> 00:38:05,520
weren't working, because they were trying to find single F. And why is it hard? Because you're going

381
00:38:05,520 --> 00:38:10,080
to find an F that's going to pick out all these values. I'm naming these values. So A needs to be

382
00:38:10,080 --> 00:38:14,240
less, greater than B, A needs to be greater than C, C needs to be greater than D, D needs to be

383
00:38:14,240 --> 00:38:20,240
greater than F and E, and F and E need, both need to be greater than G. So you're, you're like solving

384
00:38:20,240 --> 00:38:25,520
all these things all at once. And if you have a 10 million line program, it's just, it's going

385
00:38:25,520 --> 00:38:30,000
to be impossible. You're not, you're not going to be able to do it. And so, so what we figured out

386
00:38:30,000 --> 00:38:36,480
was that you could use these tools for finding proofs of toy programs. And you can find multiple

387
00:38:36,480 --> 00:38:39,920
ranking functions. It's going to turn out there's one thing we're going to need to do and Ramsey's

388
00:38:39,920 --> 00:38:43,520
going to solve it for us. That's going to be the punchline Ramsey's going to solve of course.

389
00:38:43,520 --> 00:38:49,040
So imagine we could find one termination argument, G for this transition, and another

390
00:38:49,040 --> 00:38:56,720
termination argument for, for here. We can, we can color them. So here's, I'm just going to

391
00:38:56,720 --> 00:39:03,120
make my life a little bit easier. So notice, notice I've colored this transition green because I have

392
00:39:03,120 --> 00:39:08,560
the green function. And here I've, I've colored it red because I have the red function. Okay.

393
00:39:08,560 --> 00:39:15,360
I'm preparing for Ramsey. The problem right now is that this isn't a valid termination argument.

394
00:39:15,360 --> 00:39:19,360
And the reason is, is because I have two functions, you could imagine them alternating,

395
00:39:19,360 --> 00:39:24,640
and there's just no reason for the numbers to go down. So if I have two termination arguments,

396
00:39:24,640 --> 00:39:29,680
it's not valid because I just alternate them. There's no reason I know, I can't know, I can't

397
00:39:29,680 --> 00:39:35,600
alternate them. So, so I haven't, I haven't proved termination yet. But what we can do is we can

398
00:39:35,600 --> 00:39:40,160
borrow some techniques from these papers. And now I'm going to do a construction and just believe

399
00:39:40,160 --> 00:39:47,040
me. Okay. Because we don't want this to turn into a 30 minute graph theory course. Okay.

400
00:39:47,040 --> 00:39:52,640
There's this idea of transitive closure. And it's really neat. And the graphs are really

401
00:39:52,640 --> 00:39:57,120
amazingly, they have so many edges, it's an unbelievable, but it's a construction, you can do

402
00:39:57,120 --> 00:40:04,960
it. And, and, and now what we can do is we can, and this is, and imagine this is infinite because

403
00:40:04,960 --> 00:40:08,960
we're saying, oh, maybe this program doesn't terminate. And so now what we can do is we can

404
00:40:08,960 --> 00:40:14,080
take the monochromatic Ramsey subgraph. For those of you who signed up for this talk,

405
00:40:14,080 --> 00:40:18,320
this is kind of the worst slide, right? Sorry. That who don't know, who don't know

406
00:40:18,320 --> 00:40:22,880
math and logic and that kind of thing. So we can take the monochromatic Ramsey, say that when

407
00:40:22,880 --> 00:40:28,000
you go home, right? You, you, how was the, hey honey, how was the talk is like monochromatic subgraphs.

408
00:40:29,760 --> 00:40:34,960
And, and, and now we can pull this trick again. So we'll, we'll, we'll do like trying, we'll say,

409
00:40:34,960 --> 00:40:42,880
okay, imagine non, non-terminating, non-terminating execution, but from the monochromatic subgraphs.

410
00:40:42,880 --> 00:40:51,040
So it's only the green edges. So those were only the edges where we had one function and we did

411
00:40:51,040 --> 00:40:54,320
this, we did this construction and you're just going to have to believe me that sort of added a

412
00:40:54,320 --> 00:40:58,960
bunch more transitions. And this is, this is a valuable thing to do. And, and, you know, ask me

413
00:40:58,960 --> 00:41:04,720
later and drinks and I'll explain it to you more. The more you get drinks into me, the more I'll

414
00:41:04,720 --> 00:41:11,120
explain it to you. And, and again, we, now we get to say, oh, look, you know, now it's only one

415
00:41:11,120 --> 00:41:17,280
function. So we know it's going down. So voila, right? We've, we've now, we, we, we have this

416
00:41:17,280 --> 00:41:23,040
thing that Turing was saying. We need, we need to find a quantity, which is asserted to decrease

417
00:41:23,040 --> 00:41:26,880
continuously and will vanish when the machine, machine stops and we did it. And it was Ramsey's

418
00:41:26,880 --> 00:41:32,720
theorem that helps us do it. So the payload is the summary is Ramsey's theorem. Let's us use

419
00:41:32,720 --> 00:41:41,600
many simple functions rather than a, rather than a single Turing style complex one. Okay.

420
00:41:41,600 --> 00:41:47,520
How am I doing for time, by the way? Does anyone keep track? Okay, 15 more minutes, but I might

421
00:41:47,520 --> 00:41:53,120
run long. I don't know. There was a Q and A afterwards. So I might eat into that. Okay. So

422
00:41:53,200 --> 00:41:57,680
this, that, that's the basis of Terminator. So there was this, this paper that said,

423
00:41:57,680 --> 00:42:02,720
hey, everyone, we have a termination prover that works for actual programs, like programs that

424
00:42:02,720 --> 00:42:08,000
people care about, device drivers. And it worked really nicely. So it, so it, so here, you know,

425
00:42:08,000 --> 00:42:11,760
here, remember, I showed you this code a little bit earlier. This is a device driver code. It's

426
00:42:11,760 --> 00:42:19,280
actually from the mouse. It's a piece of the mouse device driver. And, you know, it has bugs. So

427
00:42:19,600 --> 00:42:25,600
one of the developers agreed. Yeah, that's a bug. And then we, and then we had a bunch of papers.

428
00:42:25,600 --> 00:42:30,800
What were these papers doing? A lot of these papers were chipping away at this maybe problem,

429
00:42:30,800 --> 00:42:36,560
or the, the tool Terminator itself is running forever problem. So we were able to prove some

430
00:42:36,560 --> 00:42:41,280
device drivers terminating. We also found some real bugs, but then there was a whole bunch of

431
00:42:41,840 --> 00:42:47,440
maybes and spinning forever. And then these papers kind of chipped away at them.

432
00:42:48,880 --> 00:42:53,840
Other papers generalize Terminator. So for example, these folks together with me

433
00:42:54,480 --> 00:43:00,480
generalized it. So it's, you really could say anything that had the word eventually, like, you

434
00:43:00,480 --> 00:43:07,280
know, when we could ask, when, whenever this program opens a file, does it eventually close it?

435
00:43:07,280 --> 00:43:13,840
And that's eventually, right? So things like that. Another thing we did. So it turns out that

436
00:43:13,840 --> 00:43:19,760
a lot of programs are what we call concurrent. So you might have two copies of the program,

437
00:43:20,720 --> 00:43:25,520
both operating over that variable in at the same time. And proving those programs terminating

438
00:43:25,520 --> 00:43:29,920
is harder. So it turns out device drivers kind of a very special flavor. And we were able to do

439
00:43:29,920 --> 00:43:35,120
something. But then the question is, can we generalize to more programs? And the answer was yes.

440
00:43:35,440 --> 00:43:40,480
So then Jasmine, who's in the audience, made the following reference. Hey, Byron, she worked with

441
00:43:40,480 --> 00:43:44,560
me. Well, she worked in the Microsoft research. And then after this statement, she worked with me.

442
00:43:44,560 --> 00:43:48,960
So Terminator looks like something we need in the analysis of biological models.

443
00:43:50,240 --> 00:43:56,000
So that was this skin cancer comment I mentioned. So then a collective of us,

444
00:43:56,640 --> 00:44:01,840
including a designer from the Royal College of Arts, essentially an anthropologist,

445
00:44:02,800 --> 00:44:08,880
a couple of computer scientists, and Jasmine, and others who are biologists.

446
00:44:09,680 --> 00:44:15,440
The idea here is that you have your skin cells and you have genes. And there's like the genes are

447
00:44:16,160 --> 00:44:20,960
talking to the other neighbor genes. And they're all as a family trying to say, hey,

448
00:44:20,960 --> 00:44:25,280
we should only have, what is it, five layers of skin? Six layers? Six layers? I don't remember.

449
00:44:25,280 --> 00:44:29,920
But let's keep it that number. Let's not have a whole bunch more because that's bad for our

450
00:44:29,920 --> 00:44:34,880
bodies. And let's not have a whole bunch less. That's also bad news for us. And so this paper

451
00:44:34,880 --> 00:44:39,600
allowed us to analyze that. So we were able to build models of various kinds of disease and then

452
00:44:39,600 --> 00:44:47,520
answer questions like, hey, if we modified the model, would you get homeostasis? And the one

453
00:44:47,520 --> 00:44:52,240
really neat thing about it is this tool was designed such that biologists could use it and it

454
00:44:52,240 --> 00:44:57,680
had a notation very similar to what they use in their day-to-day life. And so you can use the

455
00:44:57,680 --> 00:45:02,560
tool still today. It's called Biomodal Analyzer. And there's been some amazing results. And Jasmine

456
00:45:02,560 --> 00:45:10,640
in her lab down at UCL now has gone on to do amazing results. And many of them found in part

457
00:45:10,640 --> 00:45:17,200
with the use of this tool. Another thing I did is I got really tired of using the, so there was

458
00:45:17,200 --> 00:45:23,360
these kind of formulas that we were writing that came up quite a bit. And I found that notation

459
00:45:23,680 --> 00:45:28,880
kind of limiting. So Talba Auerbach, who's a friend and an artist, began working with me on new

460
00:45:28,880 --> 00:45:32,720
symbols. So here's Talba in my Cambridge Microsoft Research Office trying to invent new

461
00:45:32,720 --> 00:45:39,200
mathematical symbols. And if you know LaTeXa, we ended, David Reinfert, who is the guy in the

462
00:45:39,200 --> 00:45:49,280
photo, implemented these new symbols in MetaFont. And we came up with something I like quite a bit.

463
00:45:49,280 --> 00:45:54,800
So it's this operation. So this is the lifting of a relation, happens to be greater than, with

464
00:45:54,800 --> 00:46:00,880
respect to f. And that allowed us to talk about this in a much nicer way. So this is the thing

465
00:46:00,880 --> 00:46:05,520
you've seen before. And now I can say this really nicely. I can say the transition relation, this

466
00:46:05,520 --> 00:46:13,040
is the graph, is a subrelation of the lifting of greater than with respect to f. And so this

467
00:46:13,040 --> 00:46:18,800
showed up a lot in talks and so on at the time. And so if you know, if you don't know math and

468
00:46:18,800 --> 00:46:22,800
logic, just close your eyes for a second. But if you do, then I'm going to explain what the

469
00:46:22,800 --> 00:46:28,880
meaning of this is. So the lifting of the relation with respect to f is the set of pairs of states,

470
00:46:28,880 --> 00:46:34,640
s and t, such that if you apply f to s and apply f to t, greater than holds, or the relation holds.

471
00:46:37,280 --> 00:46:40,800
So she's a really famous artist, and there's always articles about her. But amazingly,

472
00:46:40,800 --> 00:46:50,880
Terminator was in Vogue magazine. My greatest moment. Okay. And then, sort of one final

473
00:46:50,880 --> 00:46:56,800
point I wanted to make. So it turns out that the layout of data structures is just unbelievably

474
00:46:56,800 --> 00:47:01,280
crucial when trying to prove termination of realistic programs. And so here is a data

475
00:47:01,280 --> 00:47:05,920
structure of kind of typical data structure you would see in a device driver. And I'm just

476
00:47:05,920 --> 00:47:10,320
going to kind of walk you through this a little bit to get the idea. So device driver might come

477
00:47:10,320 --> 00:47:14,320
here and then it come here. And now it's sort of walking this data structure. It's called the

478
00:47:14,320 --> 00:47:19,920
list, right? So it's going, there's these arrows which saying it's a link to the next and the next

479
00:47:19,920 --> 00:47:25,520
and the next. And here it's going back to where it was before. And if the device driver somehow gets

480
00:47:25,520 --> 00:47:30,400
confused and doesn't realize it's already seen this, we're in a world of trouble. Because now

481
00:47:30,400 --> 00:47:37,280
what it's going to do is it's going to just spin on this thing forever. And so what's the termination

482
00:47:37,280 --> 00:47:42,800
argument? So here I've put a little picture of a post-it note in an effort to say, oh yeah,

483
00:47:42,800 --> 00:47:47,200
remember this. Okay. So imagine we've been here and we've left a post-it note saying,

484
00:47:47,200 --> 00:47:51,360
remember this, don't forget this. And we've gone here and we've gone here and we've gone here.

485
00:47:51,360 --> 00:47:56,080
What's the termination argument? Well, there's actually two list segments. There's the part we

486
00:47:56,080 --> 00:48:02,080
haven't viewed before. And there's the part that we have viewed before. And what's the size of this?

487
00:48:02,080 --> 00:48:08,320
Well, it's two nodes. And the size we haven't seen yet is two nodes. And so when we go another link,

488
00:48:10,320 --> 00:48:15,360
now it's three to one. And so this is where we're going to get the termination argument, right?

489
00:48:15,360 --> 00:48:21,200
We can take a transition from some state to some other state and look, it went from two

490
00:48:21,200 --> 00:48:25,760
to one. And that's going to be, you know, the function we're typically going to use is the

491
00:48:25,760 --> 00:48:34,080
number of links back to the node that's the head of the list. So there you go. So we're mapping.

492
00:48:34,080 --> 00:48:38,720
And so the termination arguments are kind of like that. So this paper sort of recognizes,

493
00:48:38,720 --> 00:48:45,520
this is with Peter Ahern and his postdoc and his PhD student, for example, Josh Burdine and myself.

494
00:48:46,880 --> 00:48:50,000
And then after that, we're like, hey, let's keep working together. This is pretty cool. So then I

495
00:48:50,000 --> 00:48:57,760
joined this thing with gang, I guess, called the East London Massive, that that was a collective of

496
00:48:57,760 --> 00:49:05,680
people interested in reasoning about data structures. And so Josh, who was his PhD student and postdoc

497
00:49:05,680 --> 00:49:11,760
and Samin, who was his ex PhD, had graduated and was a PhD student and I here ended up building

498
00:49:11,760 --> 00:49:17,040
this tool called Slayer, which reasoned about shapes on behalf of the termination purpose.

499
00:49:17,040 --> 00:49:24,320
We'd run this ahead of time. And that was very, very powerful. And it was also very powerful

500
00:49:24,320 --> 00:49:31,360
because it turns out that many of these 85% of crashes were actually shape oriented. The device

501
00:49:31,360 --> 00:49:36,240
driver would come in, it would modify that list, not leave it in a good state. And then the device

502
00:49:36,240 --> 00:49:40,160
driver would come back in, start walking that list, it wouldn't be in a good state. And then

503
00:49:40,160 --> 00:49:45,040
horrible things would happen. And so it turned out this is a whole other research area, basically

504
00:49:45,040 --> 00:49:49,120
driven by determination, proving a whole bunch of different papers, some of them related to

505
00:49:49,120 --> 00:49:54,160
determination, some of them not. But that's, you know, invite me back. I'll tell you all about

506
00:49:54,160 --> 00:49:59,120
that. But here's an amazing thing that happened. So, so, so, so be who's in the audience. And I'm

507
00:49:59,120 --> 00:50:06,720
also married to for past 27 years, or I can't remember now, sorry. And Peter, that's this chat,

508
00:50:06,720 --> 00:50:13,840
they started a company that made a Slayer like tool. And, and they sold it to Facebook. And you

509
00:50:13,840 --> 00:50:18,880
can still use it today. So it's called FB infer now, that you can go to this FB infer website and

510
00:50:18,880 --> 00:50:26,080
find out how to use it. And, and, and that really got me to thinking, like, maybe it's time to leave

511
00:50:26,080 --> 00:50:31,040
the research lab and go take things into product really, really into production at a level that,

512
00:50:31,040 --> 00:50:37,680
that, that we had, that we hadn't seen before. So, so now that we sort of realized that almost

513
00:50:37,680 --> 00:50:42,640
any mathematical statement, you know, maybe as we get closer and closer and closer to that,

514
00:50:42,640 --> 00:50:46,800
this becomes more and more commercially relevant. And so that's kind of where I wanted to take

515
00:50:46,800 --> 00:50:52,160
things. So this was the old Terminator website. Terminator is now dead. This website's gone.

516
00:50:52,160 --> 00:50:58,240
You have to go to the way back machine to find it. But what it did was pretty interesting. It

517
00:50:59,040 --> 00:51:02,960
inspired a new class of tools. There's a whole bunch of termination provers now that you could use.

518
00:51:02,960 --> 00:51:07,040
There's whole sessions at conferences on termination. There's a pretty healthy

519
00:51:07,680 --> 00:51:11,280
international termination prover competition.

520
00:51:13,840 --> 00:51:18,960
Everyone can, like, a lot of people know that termination is impossible, but now it's a much,

521
00:51:18,960 --> 00:51:26,320
it's a much more nuanced situation, right? Now, most people in my field at least know

522
00:51:26,320 --> 00:51:32,000
that termination is possible, but you can prove termination programs and sort of a practical

523
00:51:32,000 --> 00:51:41,360
thing that can be done. But also, I think that we made pretty mean, I mean, this vogue thing is

524
00:51:41,360 --> 00:51:45,680
obviously a joke. I mean, I mean, it was real, but obviously that made no material impact on the

525
00:51:45,680 --> 00:51:50,720
IT community. But I think that the articles in Wired, and Economist, and Financial Times, and

526
00:51:50,720 --> 00:51:56,560
Science did, and this great Sinin the Terminator article of the Scientific American. So I think

527
00:51:56,560 --> 00:52:02,960
that these helped the IT community understand that termination isn't like a death sentence.

528
00:52:04,720 --> 00:52:10,960
Okay, so that's the end of my Cambridge story. As I said, yeah, so I mean, I said goodbye to MSR.

529
00:52:10,960 --> 00:52:16,240
I've gone on to Amazon. That's three talks. I can tell you all about that, and I'll tell you

530
00:52:16,240 --> 00:52:19,920
about that at drinks if you want to know more about it. But I've tried not to talk about the

531
00:52:19,920 --> 00:52:24,320
Amazon work because that's all I do all these days. So I just, I thought it'd be fun to come here

532
00:52:24,320 --> 00:52:30,000
and tell you this Ramsey Turing story, and I hope you had fun. So with that, I'll

533
00:52:31,280 --> 00:52:33,600
gavel this to a close, and I'm happy to take questions.

534
00:52:35,840 --> 00:52:42,000
Well, thank you for that wonderful talk. Let's have some questions. And we have a microphone to

535
00:52:42,000 --> 00:52:50,960
go around. So first question. Byron, great talk, fantastic talk. Thank you. Maybe it's a relief

536
00:52:50,960 --> 00:52:56,320
that you didn't mention artificial intelligence because it's so much in the in both these days.

537
00:52:57,920 --> 00:53:02,400
But I suppose I would have asked about that. I mean, obviously Turing was famous for that,

538
00:53:02,400 --> 00:53:06,960
but I mean, how do you see maybe today's developments in artificial intelligence having an

539
00:53:06,960 --> 00:53:10,640
impact on the kind of, you know, automated reasoning that you're talking about?

540
00:53:10,640 --> 00:53:16,640
Yeah, I'm very excited about so the in the automated reasoning sometimes is a really terrible

541
00:53:16,720 --> 00:53:21,120
name for it because it's rather not automated, right? Like there's there's a lot of tools,

542
00:53:21,120 --> 00:53:25,680
there's tools like Lean, Paul Light, Isabelle, you know, I can name a whole bunch of tools,

543
00:53:25,680 --> 00:53:30,320
and they require a human to sit there and poke it to make it do the right thing.

544
00:53:30,320 --> 00:53:35,360
You ultimately get a proof that it's the checks, the checking is automating, but the finding is

545
00:53:35,360 --> 00:53:40,640
not. And those tools are rather more powerful in theory than the fully automated tools because

546
00:53:40,640 --> 00:53:45,680
the automated tools, because the problem is undecidable, cut a bunch of corners about what

547
00:53:45,680 --> 00:53:50,240
they can prove. So they can prove a much more limited set of things, whereas a super genius

548
00:53:50,240 --> 00:53:54,640
sitting together with one of these tools that are not automated, as automated can do incredible

549
00:53:54,640 --> 00:54:00,640
things. So all of your proofs of like the four color theorem, the Kepler conjecture, you know,

550
00:54:00,640 --> 00:54:08,320
that have been done with with with these tools have required a human. And so what we're seeing right

551
00:54:08,320 --> 00:54:18,320
now is that the generative AI chat GPT style tools are able to do these. So that's a really

552
00:54:18,320 --> 00:54:24,320
amazing time. So what they can because they're training on all the past proofs. And all the

553
00:54:24,320 --> 00:54:28,240
tools and these tools are super hard to use. But guess what, all the people who were making them

554
00:54:28,240 --> 00:54:33,120
able to use wrote papers about it, and provided scripts and the scripts are on GitHub and the

555
00:54:33,120 --> 00:54:37,920
tools have trained on that. So now they're able to say, you know, like, hey, you know,

556
00:54:37,920 --> 00:54:43,920
find me a proof and haul light of XYZ. And they're not terrible. So I so I think that's a really

557
00:54:43,920 --> 00:54:51,200
amazing thing. So making the tools easier. The other the observation that I'll just sort of

558
00:54:51,200 --> 00:55:01,040
put on the table there is that when LLMs lie to you, that's incorrectness. And guess what we know

559
00:55:01,040 --> 00:55:06,960
how to do, right? There's there's there's statements that are incorrect. And, and, and,

560
00:55:06,960 --> 00:55:11,360
and, you know, it's not escaped the notice of the community that that's something we could

561
00:55:11,360 --> 00:55:15,600
potentially solve. So but that's, that's, you know, that's a whole new area.

562
00:55:19,040 --> 00:55:19,920
There's a question there.

563
00:55:22,160 --> 00:55:28,080
Any, any thoughts on why you explain how you took the Frank, Frank Ramsey staff and the

564
00:55:28,080 --> 00:55:32,160
Turing staff, and you put it together and you move forward for a subset of the problems?

565
00:55:32,160 --> 00:55:38,480
Any thoughts why Turing didn't do that himself, given that, presumably, they, they knew each

566
00:55:38,480 --> 00:55:43,840
of them pretty well and charged each other intellectually? Yeah, so so as so the part where

567
00:55:43,840 --> 00:55:49,920
I said, believe me, this graph, you know, we can do this thing. And then the graph got really

568
00:55:49,920 --> 00:55:55,840
colorful. That would be very hard to do manually. So the paper would have been pages and pages and

569
00:55:55,840 --> 00:56:00,720
pages of calculations, which computers are really good at and humans are horrible at.

570
00:56:00,720 --> 00:56:06,640
So I think what, what, so the single ranking function, you just need a really smart,

571
00:56:06,640 --> 00:56:10,640
insightful person to be like, Oh, I got it. I was in the shower and I realized this is it,

572
00:56:10,640 --> 00:56:16,400
where, but, but in terms of automation, it's really hard to know even where to start. Whereas

573
00:56:16,400 --> 00:56:21,600
this, this other approach is much more automatable. So I think that's probably, probably the reason.

574
00:56:22,160 --> 00:56:25,920
We have another question there.

575
00:56:30,000 --> 00:56:35,680
Thank you for the talk. So for all those twos for automated reasoning, I'm guessing those twos

576
00:56:35,680 --> 00:56:41,200
are not formally verified. My question is, do you think there's any value in actually formally

577
00:56:41,200 --> 00:56:45,440
verifying their correctness? Or do you think there's, it's just too much work to do so?

578
00:56:46,240 --> 00:56:54,400
There are some tools that are formally verified. And what a lot of the tools do today is produce

579
00:56:54,400 --> 00:57:00,800
a proof that can be audited independently. So for example, a lot, a lot of these tools boil

580
00:57:00,800 --> 00:57:06,320
down to a class of tools called SAT or SMT solvers, propositional satisfiability, or, or

581
00:57:06,320 --> 00:57:12,960
satisfiability of propositional logic together with other theories like arithmetic, you name it,

582
00:57:13,600 --> 00:57:21,200
strings, arrays, undertropper functions. And the solvers today can produce proofs that can

583
00:57:21,200 --> 00:57:28,480
be audited independently by a tool like HallLite, Lean, et cetera. And let's, let's say that we

584
00:57:28,480 --> 00:57:34,400
believe HallLite. It's very small, kind of eyes have looked at it and they're like, okay, we're

585
00:57:34,400 --> 00:57:38,640
going to believe that. Then these tools that are, that are doing really pretty harrowing

586
00:57:39,600 --> 00:57:43,760
high performance computing to try and find the proofs, ultimately produce a proof that can

587
00:57:43,760 --> 00:57:48,560
be checked with a simple thing. That's pretty believable. So yeah, so that's something that

588
00:57:48,560 --> 00:57:52,480
we've pushed on really. I don't want to talk about Amazon too much today because it's like,

589
00:57:52,480 --> 00:57:57,200
that's all I ever do nowadays. But at Amazon, that's something we've pushed on very, very hard.

590
00:57:57,200 --> 00:58:02,640
It's actually producing auditable proofs as opposed to just some magic tool that some smart

591
00:58:02,640 --> 00:58:07,280
person wrote and you just have to believe it. We have a question over here.

592
00:58:09,520 --> 00:58:15,280
So it's a two-part question. You mentioned British Airways and you said that could they arrive

593
00:58:15,920 --> 00:58:21,600
on time enough or frequently enough to be useful? You didn't say anything about them arriving with

594
00:58:21,600 --> 00:58:30,800
a luggage. I don't suppose there's any kind of mathematics. I'm not going to take that one.

595
00:58:30,880 --> 00:58:40,320
But the second thing was to think about classes of mathematical problems that may not be

596
00:58:40,320 --> 00:58:45,520
where you can anticipate or hypothesize that a solution or an algorithm could exist.

597
00:58:45,520 --> 00:58:48,880
So the example I was thinking of while you were talking was the traveling salesman

598
00:58:49,760 --> 00:58:53,360
where, and I imagine that Amazon must have thought about this for a while, getting the

599
00:58:53,360 --> 00:58:58,960
in the course you're trying to deliver, where the presumption is that an algorithm could be

600
00:58:58,960 --> 00:59:04,560
found, but that actually proving it within a finite time is, or at least up to now,

601
00:59:04,560 --> 00:59:07,280
hasn't been possible. There's something solved and I'm not aware of it.

602
00:59:08,640 --> 00:59:13,200
Is there an extension from the kind of approach that you were taking there to prove

603
00:59:13,200 --> 00:59:20,560
termination to actually tackling those class problems? Maybe try to come up with a definitive

604
00:59:20,560 --> 00:59:27,440
yes, there is definitely, we can now state that there will be a finite algorithm,

605
00:59:27,440 --> 00:59:31,200
even if we can't actually find it within a finite time, or even to help us to find it.

606
00:59:31,200 --> 00:59:35,600
Oh yeah, I probably not quite going to answer your question, but a couple of thoughts. One of

607
00:59:35,600 --> 00:59:40,400
the interesting things about Ramsey's theorem is it says you have this

608
00:59:41,120 --> 00:59:46,080
arrow and graph and there exists a monochromatic subgraph, but it doesn't show it to you, so

609
00:59:46,080 --> 00:59:53,360
it's not constructive. And so if you use some of these techniques, you can't actually see

610
00:59:53,360 --> 00:59:58,640
the termination argument, you just know it exists. But I think your question was rooted more in a

611
00:59:58,640 --> 01:00:07,600
little bit about can we synthesize or convince ourselves that algorithms exist when we don't

612
01:00:07,600 --> 01:00:13,600
know what this specific algorithm is there. We surmise they do, but we can't definitively,

613
01:00:13,600 --> 01:00:21,360
or at least we couldn't definitively prove it. Yes, so I think so, I mean that like,

614
01:00:22,720 --> 01:00:28,480
if goal box conjecture is proved likely, it's via these methods where you don't,

615
01:00:29,280 --> 01:00:36,160
like the proof is kind of non-constructive in some sense. I imagine so often non-constructive

616
01:00:36,160 --> 01:00:40,720
proofs are easier than constructive proofs. So yeah, so I think that the harder part will

617
01:00:40,720 --> 01:00:47,280
actually be to find the witness. We have another question in the back there.

618
01:00:47,280 --> 01:00:53,040
So Byron, I'm sure you're aware there were two schools of computer science in Cambridge in the

619
01:00:53,040 --> 01:01:00,240
post-war years, cheering, because there's mathematical sophistication, mostly programmed

620
01:01:00,240 --> 01:01:05,360
in binary on the Manchester Malt 1 and the Pylor Ace, because he could use his mathematical

621
01:01:05,440 --> 01:01:10,560
sophistication to kind of reason about the algorithms and convince himself they were correct.

622
01:01:10,560 --> 01:01:15,600
So the fact that notation was a very unproductive way of writing software didn't bother him.

623
01:01:16,480 --> 01:01:20,720
The engineering philosophy that kind of came from people like Wilks and other colleges in

624
01:01:20,720 --> 01:01:26,800
Cambridge just down the road was give the users a symbolic notation to seduce them into the idea

625
01:01:26,800 --> 01:01:31,360
that programming actually is really very easy and you could just write stuff and it would be fine.

626
01:01:31,680 --> 01:01:36,880
Yeah. Kind of the symbolic world of one because we have programming languages and the effort in

627
01:01:36,880 --> 01:01:41,280
programming languages has been to design languages in which you can't make mistakes,

628
01:01:41,280 --> 01:01:46,880
yet you can still write useful stuff. So my kind of question is now we have the kind of tools you're

629
01:01:46,880 --> 01:01:53,120
talking about. Do we need to continue investing in improving programming languages or can we just use

630
01:01:53,760 --> 01:01:57,520
scruffy languages and rely on the tools like yours to prove our software is correct?

631
01:01:58,080 --> 01:02:04,320
So yeah, all programming languages are scruffy, but I've never quite managed to find the perfect one.

632
01:02:04,320 --> 01:02:10,320
Couple of observations there. So one observation is I think Rust is this incredible language.

633
01:02:10,320 --> 01:02:15,440
And so I spent a lot of time trying to get people working on very low level system

634
01:02:15,440 --> 01:02:20,880
code to adopt tools that we had that could prove memory safety of those programs.

635
01:02:20,880 --> 01:02:25,680
And it was really tough learning. And then one day Rust comes along and they're all like

636
01:02:25,680 --> 01:02:30,640
without me even prompting them like, oh, I started learning Rust. And Rust has a very

637
01:02:30,640 --> 01:02:37,440
sophisticated prover in it, but they came for the speed. So because Rust could be faster,

638
01:02:37,440 --> 01:02:42,240
they're like, I'll learn these tools, but also it was super well done that the developers of

639
01:02:42,240 --> 01:02:47,600
Rust talk about ergonomics, like the ergonomics of developing and Rust is really important to them.

640
01:02:47,600 --> 01:02:54,560
And I think that's been very, very powerful. So one could prove, you know, just like there's

641
01:02:54,560 --> 01:03:01,760
turning completeness of you can express all programs in Rust or C or Askel or Prolog.

642
01:03:01,760 --> 01:03:05,680
There's, there's sort of, you know, you can prove the same things in a lot of these systems,

643
01:03:05,680 --> 01:03:12,320
but I think that Rust's ergonomics are much nicer than some of the tools like in C where you then

644
01:03:12,320 --> 01:03:17,120
try and prove, prove memory safety. That's my first observation. Second observation is there's

645
01:03:17,200 --> 01:03:24,320
this fascinating blog post by Ranjit Jhalla where he shows that you can take a program

646
01:03:24,320 --> 01:03:29,120
in an imperative language and prove it using horror triple style reasoning. And you have,

647
01:03:29,120 --> 01:03:36,400
sorry, everyone, just bear with me for a second. You have a horror triples of quantifiers and,

648
01:03:36,400 --> 01:03:43,920
and, and then you just slam the, you apply these SMT solvers with quantifier support and it's,

649
01:03:44,000 --> 01:03:51,120
it's so hard and it's so compute expensive. Or you could write the same program in liquid Haskell

650
01:03:51,920 --> 01:03:56,160
and there's no quantifiers. You can prove the same property and it's because Hindley Milner

651
01:03:56,720 --> 01:04:01,840
is somehow resolving the quantifiers for you and it's very, very low power, very easy, very

652
01:04:01,840 --> 01:04:06,400
predictable. You don't make a change to your code over here and suddenly the proof stops going through.

653
01:04:07,040 --> 01:04:14,240
So, so I think that there's a lot to be said for the ergonomics of the language and the IDE and

654
01:04:14,240 --> 01:04:18,080
the experience, particularly developing in cloud, you know, I'm talking about Amazon, but if you're

655
01:04:18,080 --> 01:04:23,120
developing programs in cloud, the ergonomics of how do you develop that and understand the program

656
01:04:23,120 --> 01:04:27,920
such that you don't have to like SSH over to some other machine to find out what the machine

657
01:04:27,920 --> 01:04:32,880
that's stated in, I think are very, very important. So, so I think that automated reasoning,

658
01:04:33,600 --> 01:04:39,440
programming languages and the sort of software development experience go really hand in hand

659
01:04:39,440 --> 01:04:42,960
and there's some very powerful experiences we can have now that we couldn't have before.

660
01:04:46,320 --> 01:04:47,920
Great. Other questions?

661
01:04:50,720 --> 01:04:57,120
Okay. I think it's time to thank Byron for a wonderful talk. And I believe though there are

662
01:04:57,120 --> 01:05:01,280
going to be refreshments out in the chat window room again. Okay. Thank you all.

