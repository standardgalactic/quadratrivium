start	end	text
0	5680	A mathematical saying goes, a drunk man will find his way home, but a drunk bird may get
5680	13040	lost forever. The assumption here is that because both are drunk, they are doing random walks.
13040	18320	The difference is that the man can only walk on the surface of the earth, and so he is doing a
18320	24320	two-dimensional random walk. But for the bird, in addition to the two dimensions, it can also
24320	31920	fly up and down, and so it is doing a 3D random walk. It turns out that no matter where the
31920	39200	drunk man started, it is mathematically guaranteed that he will return home, it's only sooner or
39200	46800	later. But for the bird, there is a non-zero chance that it will get lost forever, even if it started
46800	53920	off in its own nets. Why is there such a stark difference between a 2D and a 3D random walk?
54480	58320	To answer this question, we use the framework of Markov chains.
62480	68480	A Markov chain consists of three things. The first is the state space, essentially meaning
68480	74800	where you can go. In the case of random walks, for simplicity, the state space would be just
74800	82160	those lattice points, so the drunk man or bird can only visit those lattice points. Second thing
82160	88400	is the transition probabilities, because Markov chains are not static. Let's say you are now at
88400	95760	state A, with four other neighboring states in the state space. In your next step, you can transition
95760	102880	to any other states, and in general, you might also go back to itself, depending on your setup.
103680	110480	For each possible transition, we just assign a probability to it. They are the transition
110480	118160	probabilities. For a 2D random walk, each state has four neighbors, and because we have no bias
118160	125840	towards any direction, the transition probabilities are all one quarter. Similarly, for a 3D random
125840	132400	walk, each state has six neighbors, and so the transition probabilities are all one sixth.
133280	139760	The final thing is the initial distribution. In a general Markov chain, you have the freedom to
139760	146880	choose which state to start, and so we can assign a probability to each state, indicating how likely
146880	153520	you are to start at that state. In the case of a random walk, we want to definitively start at
153520	161520	the origin, i.e. a probability 1 of starting at the origin, and 0 everywhere else. Wait,
161520	167360	didn't you say it doesn't matter where you started for the 2D case? Don't worry, I'll get there in
167360	174240	a minute. These are the three elements in the Markov chain, but there is one key feature that
174240	181360	makes it a Markov chain, the Markov property. This is a simple idea that once you have gone to a
181360	188320	particular state, you should have already forgotten how you get there, and consider the transition
188320	195040	probabilities from there without caring about the root that takes you there. So yes, that's the whole
195040	206080	setup for a Markov chain, but how does that help? Given that a random walk is random, and every time
206080	212640	you run it, it gives different results, what can we say about that? One thing we can say is whether
212640	219200	you will revisit the origin if you started there. If you are guaranteed to go back, or in other words,
219280	226880	the return probability is 1, then we call that initial state recurrent. If not, then you are not
226880	234160	guaranteed to return, and so the return probability is less than 1. In such a case, we call it a
234160	242240	transient state. Because you are either guaranteed or not guaranteed to return, a state is either
242240	250320	recurrent or transient, there is no third option. It turns out that in 2D, the origin is a recurrent
250320	256640	state, and just because this state is recurrent, we can already infer that it does not matter
256640	262880	whether drunk man started, he will go back to the origin. That takes one or two lines of reasoning,
262880	269520	which I encourage you to do in the comments. On the other hand, the origin in the 3D random walk
269520	277200	is a transient state, so the drunk bird may never return. The problem now is how to determine that
277200	284240	return probability. Here's the trick. We consider a quantity v, which is the number of returns to
284240	291200	the origin. The implicit assumption is to run the random walk to infinity, even if you have returned.
291840	298000	Our focus is the expectation of v, i.e. the expected number of returns.
298720	304960	Now for the recurrent case, we are guaranteed to go back, but if we continue to run the random walk
304960	311840	by the Markov property, we should have forgotten that we have returned, and then we will for sure
311840	320480	return to the origin again and again. So the number of returns v is guaranteed to be infinite,
320480	327840	and the expectation would also be infinite. That is when the state is recurrent. What if the state
327840	335680	is transient? Here is a very clever general trick. By definition, the expectation is zero times the
335680	342560	probability that v is zero plus one times the probability that v is one and so on. But what if
342560	350480	we write, for instance, this two times probability as actually the sum of two copies, and also do
350480	358160	this similarly for the other terms in the sum. Then instead of summing these row by row, we can
358160	365600	sum these column by column. For the first column, it is exactly the probability that v is at least
365600	372560	one. Similarly, the next column gives the probability that v is at least two and so on.
373360	381040	The reason this method is useful is that if v is at least one, that exactly means you return to
381040	387920	the origin at some point, and so this is actually the return probability. And for simplicity,
387920	395760	we denote it as r. What about the probability of returning at least twice? Well, the probability
395760	402240	that you will return is r, but again by the Markov property, you should forget that you have returned
402320	409600	and so the probability that you return again is to multiply by another r. And in general,
409600	417520	the probability of returning at least k times is r to the k. So if we go back to the expectation,
418080	425120	each column actually sums up to a power of r, and the expectation is a geometric series.
425760	431520	So we know what this should sum to if that return probability is less than one,
431520	438480	which is precisely the case when the state is transient. For now, we only need to know that
438480	446160	this is finite if r is less than one. However, we have also deduced that for a recurrent state,
446160	453840	this expected number of returns is infinite. So if the state is recurrent, we have the expectation
453840	460960	to be infinite, and if the state is transient, the expectation is finite. Because the state is
461040	468000	either recurrent or transient, no third option, if say the expectation is infinite,
468000	475840	the state could not possibly have been transient, and so we can infer that the state is recurrent.
476640	483600	So if we know whether this expectation is infinite, we are done. To do that, we need a final trick.
484400	489680	Another way of thinking about v, the number of returns, is that it is a tally.
490240	497280	We first ask the questions, have you returned at step n? If yes, then we add one to the tally,
497280	503760	and if not, then we don't do anything to it. Once we answered all these questions,
503760	509680	we add up the total, and we obtain v by just adding up all these plus ones.
510400	517920	If we are asking for the expected value of v, we add up the expected value of the first question,
518000	525920	the expected value of the second question, and so on. The expected value of these yes-no questions
525920	533360	are much easier to handle. The expected value of this question would be, by definition,
533360	539600	one times the probability that you answer yes, plus zero times that you answer no.
540320	546320	Well, that's just the probability that you answer yes. We usually denote this probability
546320	553920	as p with subscript zero zero and superscript one. The double zero denotes going from the origin to
553920	560880	the origin, i.e. revisiting the origin. And the superscript just represents at which step you
560880	568240	revisit. These probabilities will be the expected value for each question, and the sum of these
568240	576160	probabilities gives us the expected value of v. So we now have a way of explicitly computing
576160	583280	the expected value of v. Previously, we deduced that we can simply use the expected value of v
583280	590800	to infer whether the state is recurrent, and now we also know how to explicitly compute
590800	598240	that expected value. So once we know whether this series converges, then we know whether the state
598240	605200	is recurrent or transient. This whole argument actually works for all Markov chains, including
605200	615520	the random walk we are considering. In the previous chapter, we essentially devised a test for recurrence
615520	623040	or transient. A 2D random walk is recurrent, so we want to prove that the series diverges.
623040	629760	A 3D random walk is transient, so we want to prove that it converges. But whichever the case,
629760	636320	we need to compute each term. In the case of a random walk, you can't possibly go back to the
636320	642720	origin after one step, and so this probability is zero. This should not be too surprising,
642720	648880	because any return paths would have the same number of steps to the left as those to the right,
648880	655760	and of course, same number of steps downwards as those upwards. And so the total number of steps
655760	665040	here has to be even. So this nth step probability is zero, if n is odd, and so we can just focus on
665040	673120	finding the even two nth step probabilities. Let's say we want a total of 18 steps, then this is a
673120	680720	specific possible return path. This specific path has a probability of one quarter to the 18,
680720	688720	because each step is chosen with probability one quarter, and there are 18 steps you need to take.
688720	695760	Of course, this is not the only possible path that returns to the origin after 18 steps. This one
695760	703040	also does. Even though it has returned to the origin already, as long as you return at step 18,
703040	708560	it still counts, because you will still answer yes in the previous argument.
709200	716320	Anyway, the new path also has probability one quarter to the 18. More explicitly,
716320	723360	when calculating the 18th step return probability, we just add up these probabilities.
724000	730000	This part is the probability of getting a specific return path, and we then multiply
730000	738000	by the number of return paths to get the overall probability. So it all boils down to counting
738080	744960	the number of return paths. For a total of two n steps, a return path should have the same number
744960	751680	of steps to the left and to the right, and the number of steps upwards is the same as downwards.
752480	760640	Because the total number of steps is two n, we can express j in terms of i. For a return path,
760640	767200	we can imagine it as a sequence of moves. Because there are a total of two n steps,
767200	775280	in total there are two n factorial arrangements of these moves. However, if for example,
775280	782400	we just rearrange these two left moves, then the resulting path quite literally hasn't changed,
782400	789760	yet it counted as different in those two n factorial arrangements. Because there are i steps to the
789760	797280	left, there are i factorial different permutations in between them, and of course the other directions
797280	805280	have similar results. These interpermutations all counted as different in those two n factorial
805280	813040	arrangements, yet they should have been counted the same, and so the number of return paths for a
813040	821600	fixed value of i is two n factorial divided by all these factorials. So given a value of i,
822240	832080	this is the number, and i can range from zero to n, and so the final total number of return paths
832080	841600	needs to add these up for i ranging from zero to n. Finally, this two n step return probability
841680	850240	is one quarter to the two n times the total number of return paths. That's just the case in 2D.
850240	857840	What about the 3D random walk? The only difference is that transition probabilities are all one sixth,
857840	864240	and there is one more pair of directions to consider. The two n step probabilities would be
864320	872000	replacing one quarter by one sixth, and for the number of return paths we use a similar method,
872000	879040	with the only difference being there are three pairs of directions now. So similarly, for fixed
879040	887600	values of i and j, this is the number of return paths, and adding all these for i and j, ranging
887600	895360	from zero to n, will give the total number of return paths. And finally, for the two n step
895360	902560	return probability, we simply multiply by one sixth to the two n. But perhaps it might be
902560	909280	useful to remind ourselves why we care about this. We have demonstrated that a state being
909280	916400	recurrent or transient implies whether the series diverges or converges. So by knowing
916400	923040	whether this series converges, we know whether the state is transient. In this chapter,
923040	929520	we calculated those terms in the series with explicit expressions for the 2D and 3D cases
929520	937360	respectively. And what remains is to show that the series formed by the 2D case diverges,
937360	944800	and the 3D case converges. The very quick reason for it is that each term here scales
944800	952160	like 1 over n, so it diverges because the harmonic series diverges. And the other term would scale
952160	958400	like 1 over n to 3 halves, and this will lead to a convergent series instead.
959360	965440	Originally I wanted to make it into the main video, but this is a bit too much manipulation
965440	971520	of expressions, and so I ended up making it a second channel video. But I want to give a bit
971520	978960	more no calculation explanation here. We can always think of an inner and an outer region in
978960	986400	any dimension, but in higher dimensions there is much more space in the outer region, so once you
986400	994560	have gone out, it will be less likely for you to go back in higher dimensions. The exact cutoff
994560	1002560	turns out to be between 2 and 3 dimensions. However, does this inner outer region explanation
1002560	1008560	and the cutoff between 2 and 3 dimensions look familiar? If you have watched my previous video
1008560	1014960	on Stein's paradox, then you might remember that whether the ordinary estimator is admissible
1014960	1022240	has a cutoff between 2 and 3 dimensions, and we found out that recurrence of random walks
1022240	1028320	also has the same cutoff. It turns out that this is not a coincidence.
1029120	1034880	Larry Brown wrote in 1971 about the connection between these two problems,
1035440	1042000	but this is way too involved in a YouTube video. I will put a link in the description for those
1042000	1047760	who want to know more. Before you go, I just want to thank you for your support, because now I have
1047760	1054480	100k subs. To celebrate this milestone, I am going to make a Q&A video. You can ask me any
1054480	1060720	question, but do so in the google form below. And just so you are prepared for the next video,
1061280	1067360	and you might have also guessed from these two videos, I am currently a fourth year Cambridge
1067360	1074960	Math student. We call ourselves Mathmos for some unknown reason. So yes, be prepared for some
1075040	1080560	Cambridge related Math video in the future. Please consider giving on Patreon,
1080560	1086720	and thanks to the Patrons for making this video possible. As always, subscribe with the bell on,
1086720	1091200	like, comment, and share this video. See you next time!
