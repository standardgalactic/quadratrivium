{"text": " Given a particular matrix if you want to compute its trace, you will be basically adding up the diagonal entries. But this is quite an algebraic approach in thinking about trace. Can we visualize what's really happening when we add these diagonal entries? The visualization will also explain many properties of trace you might have seen. There is one particular property that I'm saving for the end of the video series, which is traceab equals traceba. However, in the majority of cases where one of a or b is invertible, we can derive it using one of the other properties. But in any case, let's start the visualization. At the end of the previous video, we have described a matrix as a vector field. Let's expand on that a little bit. If you are given a matrix a, then the vector field would be constructed by attaching every point with position vector x by the vector ax. A little note on the illustration on screen here. Technically, if this illustration really describes ax, then the vector field would look very messy because some of the vectors would be too long. So the usual thing to do is to standardize the lengths of the vectors, which will still give you the direction, and if you really need the length, then add colors to indicate how long the vector should have been. In particular, these two vectors are the important ones because they are the vectors attached to the points 1, 0 and 0, 1 respectively. The vector attached to 1, 0 would be the first column of A, while the vector attached to 0, 1 would be the second column of A. With this visualization of matrices, the intuition for trace is just one sentence. The trace of A is the divergence of this vector field created by the matrix A. We are going to see what divergence is. Now I am aware that this has been talked about on YouTube, but I want to be more quantitative, so bear with me if you already knew the visual intuition of divergence. Given a particular vector field, we can define divergence at a point, say this red dot. We now consider a very small region around this dot, and write down the area of this small region. The next thing is to let every point in this small region evolve together along the vector field. As you see, the area of this region changes. For divergence, we are interested in thinking about how quickly the area changes initially, per area, as the area of the initial region shrinks to 0. In this case, let's look at how the area evolves again. We can see that it initially decreases, and in fact keeps decreasing along the way, so because the area change is negative, we have the divergence at this red dot to also be negative. However, one reminder is that this rate of area change is per area. In this case, if we compare the final area with the initial area, we can record a change of negative 0.148 during the evolution. Now, if we quadruple the initial area and again play the same game and let this area evolve under the flow of the vector field, and this time, we record a change of negative 0.595 in area. If we compare this change to the previous area change, this is exactly a factor of 4 accounting for rounding errors in my computer simulation. So, in our intuition of divergence, the per area part is very important. So that's the divergence part, but why is this related to the trace of the matrix generating the vector field? Actually, the first question that comes up would be that the divergence is a local property. This means that if we consider another point on the vector field, the divergence could be different. So, why does this statement seem like the divergence is the same everywhere? Well, it's because it is, but just in this specific case, where everything is generated by the matrix A. To see why the divergence is the same everywhere, let's first denote this point with its position vector x and any point within our small region around x to be x plus d for small displacements d from x. Now, the vectors attached to those two points are A x and A x plus d respectively. This means that the initial displacement between these two points is d, and after a very short time epsilon, the displacement is increased by epsilon times A d. Here, A d is the difference in their velocities or the rate where they drift apart. However, notice that there is absolutely no x here. This result does not depend on x. So, if we have this exact shape of the small region, let's illustrate it with just three points, each with displacements d i from the point we try to compute the divergence of. After a short epsilon period of time, the displacements are changed to d i plus epsilon A d i. But these are independent of our position. So, even if we have this initial region elsewhere, we will still have the exact same shape after time epsilon. The change in area is the same everywhere. Because the divergence is the area change per area, divergence is the same everywhere in this case. This also means we can choose a convenient region to see how its area changes, and this region doesn't have to be infinitesimal either. This is because if we chop any normal region into very small ones, then from our intuition of divergence, each small region U i has its area changed from A i to A i times 1 plus epsilon times divergence after time epsilon. Most importantly, we know now that divergence is the same across all these regions. So, for the entire region U, which has its area being the sum of these small regions, would also scale by the same factor of 1 plus epsilon times divergence. Since we can basically choose any region to see how the area evolves, a convenient choice is the unit square containing points 1 0 and 0 1, as the initial area would automatically be 1. So, we focus on the rate of area change. If we suppose that A is the square matrix A, B, C, D, then as said before, the vector attached to 1 0 would be the first column A, C, and the vector attached to 0 1 would be the second column, B, D. Let's focus on the point 1 0 and its attached vector A, C. Here, its vertical component doesn't really matter here, because it doesn't change the area of the region. The base and height of the parallelogram have not changed. So, the vertical component doesn't matter, but what about the horizontal component? This time, it matters. The area has changed. The rate of change here is given by precisely the horizontal component of the attached vector, which is A. You can run a very similar argument on the other point 0 1 here. This time, the horizontal component does not matter, because again, the area wouldn't change in that case, and the vertical component provides the change in area. In this case, the vertical component is D. So, altogether, the rate of change in area would be A plus D, which is exactly the sum of the diagonal entries of the matrix A. So, we have demonstrated that trace is really the divergence of the vector field. Now, if you are not convinced by these horizontal component or vertical component arguments, all we are doing is computing the determinant of this slightly different matrix. The first column is where the point 1 0 moves to after time epsilon with this velocity A C. Similarly, the second column is where the point 0 1 moves to after time epsilon with the velocity B D. If you actually compute this determinant, then we see that this is really the rate of change of the area. That is also the trace. Anyway, the fact that trace is just the divergence of the vector field is very useful for understanding the many properties of trace, and these properties one by one would be the focus of the video from this point onwards. Let's first start with why trace is the sum of eigenvalues. When visualizing matrices this way with vector fields, if the position vector x is an eigenvector of A, then the vector attached to it, which is A x, would face the same or opposite direction as the position vector. In fact, once you are on this line, you will stay on this line because the position and velocity vectors are both on this line. In the case where there are two such lines, where the position vector and the velocity vector attached are on the same line, then to investigate the divergence of the vector field and hence the trace, one convenient choice of region is a parallelogram aligned with these two lines. Let's label the two lines by their eigenvalues lambda 1 and lambda 2 respectively. And let's say the side lengths of the parallelogram are A and B. Focus on this corner of the parallelogram. The length of the vector attached to it should be lambda 1A. That's because on this line, every position vector satisfies A x equals lambda 1 x. Since the position vector has length A in our notation, the vector attached to it should be with length lambda 1A. So after a very short time epsilon, we should have an extra length of epsilon lambda 1A along this line. Using the same argument on the other corner of the parallelogram, the extra length on the other line would be epsilon lambda 2B after time epsilon. In this illustration, lambda 2 is negative, so the so-called extra length is actually length lost. So after a short time epsilon, the length along this lambda 2 line would be B x 1 plus epsilon lambda 2, and similarly the length along the lambda 1 line would be A x 1 plus epsilon lambda 1. The new area is the product of the side lengths and sine theta, where theta is the angle between these two lines. Compare this with the old area, which is AB sine theta. If we now compute the divergence of this vector field, which is the rate of area change per area, then we would have this expression, which is new area minus the old area over the time period of epsilon, divided by the initial area, which is AB sine theta. If you really compute this, we would have lambda 1 plus lambda 2 plus a small bit involving epsilon. However, as epsilon tends to zero, then the epsilon bit does not contribute, and we are left with the sum of eigenvalues. So the trace is the sum of the eigenvalues in this illustration. So this is the first property of trace. The next property has something to do with the exponential of matrices, which I have described in the previous video as well. Essentially, given a vector field created by the matrix A, the flow of this point with position vector x along the vector field is precisely given by e to the ta applied to x, where t is the time elapsed when you flow along the field. The determinant of a matrix is the scale factor of this unit square under the matrix transformation. Applying the matrix e to the ta to this square is equivalent to letting the region flow along the vector field, so the area of whatever we end up with is the determinant of the matrix exponential. And we actually know how the areas evolve along this vector flow. Let's denote the area of this region as s of t, which depends on time elapsed along the vector field. The trace of a is the rate of area change per area, with the rate of change in area being the derivative of s, and the area being s of t itself. By rearranging this formula, we obtain a differential equation in s. Note that the trace of a does not depend on t, it is a constant, so the determinant s of t can be solved as e to the t times trace of a. This neatly explains why the determinant of the exponential matrix is the exponential of trace. Now let's go to the property that the trace is independent of basis vectors. Given the matrix a, as usual we consider the vector field generated. This time, we apply a linear transformation q to the whole picture. In general, where the vectors emanate from would change, and the vectors attached would also change. More specifically, what had been x is now transformed to qx, and what used to be ax is now qax. This one needs a bit of explanation. Initially, the attached vector to the point x is going from point x to x plus ax, so when we apply the transformation q on the whole picture, then the attached vector goes from qx to qx plus qax, so this attached vector is qax. Now let's call this new position vector y, then in terms of y, the attached vector is qa qinverse y, if q is invertible. So for any position vector y, the attached vector is qa qinverse y, which suggests that this is actually the vector field of another matrix, qa qinverse. Now the trace is the rate of change in area per area, but in applying q to the whole thing, all areas scale by the determinant of q, and this factor of determinant cancels when we consider the quotient. So in other words, the trace of a equals the trace of qa qinverse, or if you want to go for the usual change of basis formula p inverse ap, simply substitute the matrix q as p inverse. Using this relation, we are able to derive another famous property of trace, which starts from rewriting trace of ab. If b is invertible, then we can simply add in b inverse b, and the expression stays the same. However, written like this, we can use the property we just derived, and then we can obtain, it is the trace of ba. Now this property of trace is perhaps more well known, but we have done a bit of algebra to get here. There is a better way, but we will need to introduce the concept of lee bracket, a story for another time. So we can obtain this property of trace by transforming the whole plane by p inverse, and the final property we will see is this perhaps less famous formula. This formula is known as Jacobi's formula for a matrix A that depends on time t. Well technically, this is only true if a of t in this formula is invertible, because there is a inverse in the formula. A more general formula involves the adjoint matrix, which is defined even if a is not invertible. But for the purpose of visualization, we are going to assume a is invertible and try to understand this formula first. First off, what does the left hand side really mean? The determinant can refer to the area of a parallelogram, described by a of t acting on the two basis vectors. This area will change because a itself evolves with time. In fact, these points would also change as a changes. The rate at which these corners move is exactly a prime of t acting on the basis vectors. If we can somehow make this into a whole vector field generated by the matrix m, then we know how the area evolves. Specifically, we know that the trace of m is the rate of area change per area. In this case, the rate of area change is the derivative of determinant of a, and the area is of course just the determinant of a itself. So, if we rearrange this, then we have something that really looks like the Tobi formula. The problem now is, what is m? What is the matrix m that generates this vector field? Now, particularly at the points a of t acting on the basis vectors, we know what the vectors attached should be. To go from the position vectors to the attached vectors, we can simply apply a prime a inverse on the position vectors. So, the matrix m we are looking for is a prime a inverse. If we go back to what we have obtained previously about derivative of determinant, we simply substitute the matrix m to be a prime a inverse. This is almost the same as Jacobi's formula, just that the matrix in the trace has the other order in multiplication, a inverse before a prime here. Don't worry, there are two approaches here. Either use the property we discovered that trace a b equals trace b a for a or b being invertible, or similar to how we dealt with the previous property, we just apply a inverse to the whole picture. In that case, the corners of the parallelogram go back to the standard places 1 0 and 0 1, but the vectors attached to these places are a inverse a prime acting on the basis vectors. This is because previously they were just a prime acting on them, but we have applied a inverse to the whole picture. This means that the matrix generating the vector field would be a inverse a prime, and the matrix m to be put into the formula that we derived previously would be a inverse a prime. And this is exactly the Jacobi's formula where the matrices in the trace are in the right order. a inverse a prime. So this is the Jacobi's formula derived in the case when a is invertible. We are able to derive and understand many properties of trace visually by thinking of trace as divergence, or the rate of area change per area, when the area evolves along the vector field. As always, thanks for the patrons and please like, subscribe, comment so that more people can watch it. See you next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.76, "text": " Given a particular matrix if you want to compute its trace, you will be basically adding up the", "tokens": [50364, 18600, 257, 1729, 8141, 498, 291, 528, 281, 14722, 1080, 13508, 11, 291, 486, 312, 1936, 5127, 493, 264, 50652], "temperature": 0.0, "avg_logprob": -0.08039234891349886, "compression_ratio": 1.6127659574468085, "no_speech_prob": 3.8829894037917256e-05}, {"id": 1, "seek": 0, "start": 5.76, "end": 13.44, "text": " diagonal entries. But this is quite an algebraic approach in thinking about trace. Can we visualize", "tokens": [50652, 21539, 23041, 13, 583, 341, 307, 1596, 364, 21989, 299, 3109, 294, 1953, 466, 13508, 13, 1664, 321, 23273, 51036], "temperature": 0.0, "avg_logprob": -0.08039234891349886, "compression_ratio": 1.6127659574468085, "no_speech_prob": 3.8829894037917256e-05}, {"id": 2, "seek": 0, "start": 13.44, "end": 19.44, "text": " what's really happening when we add these diagonal entries? The visualization will also", "tokens": [51036, 437, 311, 534, 2737, 562, 321, 909, 613, 21539, 23041, 30, 440, 25801, 486, 611, 51336], "temperature": 0.0, "avg_logprob": -0.08039234891349886, "compression_ratio": 1.6127659574468085, "no_speech_prob": 3.8829894037917256e-05}, {"id": 3, "seek": 0, "start": 19.44, "end": 26.080000000000002, "text": " explain many properties of trace you might have seen. There is one particular property that I'm", "tokens": [51336, 2903, 867, 7221, 295, 13508, 291, 1062, 362, 1612, 13, 821, 307, 472, 1729, 4707, 300, 286, 478, 51668], "temperature": 0.0, "avg_logprob": -0.08039234891349886, "compression_ratio": 1.6127659574468085, "no_speech_prob": 3.8829894037917256e-05}, {"id": 4, "seek": 2608, "start": 26.08, "end": 33.44, "text": " saving for the end of the video series, which is traceab equals traceba. However,", "tokens": [50364, 6816, 337, 264, 917, 295, 264, 960, 2638, 11, 597, 307, 13508, 455, 6915, 13508, 4231, 13, 2908, 11, 50732], "temperature": 0.0, "avg_logprob": -0.09330046048728369, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.0034830213990062475}, {"id": 5, "seek": 2608, "start": 33.44, "end": 41.28, "text": " in the majority of cases where one of a or b is invertible, we can derive it using one of the other", "tokens": [50732, 294, 264, 6286, 295, 3331, 689, 472, 295, 257, 420, 272, 307, 33966, 964, 11, 321, 393, 28446, 309, 1228, 472, 295, 264, 661, 51124], "temperature": 0.0, "avg_logprob": -0.09330046048728369, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.0034830213990062475}, {"id": 6, "seek": 2608, "start": 41.28, "end": 48.959999999999994, "text": " properties. But in any case, let's start the visualization. At the end of the previous video,", "tokens": [51124, 7221, 13, 583, 294, 604, 1389, 11, 718, 311, 722, 264, 25801, 13, 1711, 264, 917, 295, 264, 3894, 960, 11, 51508], "temperature": 0.0, "avg_logprob": -0.09330046048728369, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.0034830213990062475}, {"id": 7, "seek": 2608, "start": 48.959999999999994, "end": 54.480000000000004, "text": " we have described a matrix as a vector field. Let's expand on that a little bit.", "tokens": [51508, 321, 362, 7619, 257, 8141, 382, 257, 8062, 2519, 13, 961, 311, 5268, 322, 300, 257, 707, 857, 13, 51784], "temperature": 0.0, "avg_logprob": -0.09330046048728369, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.0034830213990062475}, {"id": 8, "seek": 5448, "start": 55.199999999999996, "end": 61.519999999999996, "text": " If you are given a matrix a, then the vector field would be constructed by attaching every", "tokens": [50400, 759, 291, 366, 2212, 257, 8141, 257, 11, 550, 264, 8062, 2519, 576, 312, 17083, 538, 39074, 633, 50716], "temperature": 0.0, "avg_logprob": -0.078345039744436, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0011694488348439336}, {"id": 9, "seek": 5448, "start": 61.519999999999996, "end": 69.52, "text": " point with position vector x by the vector ax. A little note on the illustration on screen here.", "tokens": [50716, 935, 365, 2535, 8062, 2031, 538, 264, 8062, 6360, 13, 316, 707, 3637, 322, 264, 22645, 322, 2568, 510, 13, 51116], "temperature": 0.0, "avg_logprob": -0.078345039744436, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0011694488348439336}, {"id": 10, "seek": 5448, "start": 70.24, "end": 76.0, "text": " Technically, if this illustration really describes ax, then the vector field would", "tokens": [51152, 42494, 11, 498, 341, 22645, 534, 15626, 6360, 11, 550, 264, 8062, 2519, 576, 51440], "temperature": 0.0, "avg_logprob": -0.078345039744436, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0011694488348439336}, {"id": 11, "seek": 5448, "start": 76.0, "end": 82.0, "text": " look very messy because some of the vectors would be too long. So the usual thing to do", "tokens": [51440, 574, 588, 16191, 570, 512, 295, 264, 18875, 576, 312, 886, 938, 13, 407, 264, 7713, 551, 281, 360, 51740], "temperature": 0.0, "avg_logprob": -0.078345039744436, "compression_ratio": 1.7378640776699028, "no_speech_prob": 0.0011694488348439336}, {"id": 12, "seek": 8200, "start": 82.0, "end": 87.04, "text": " is to standardize the lengths of the vectors, which will still give you the direction,", "tokens": [50364, 307, 281, 3832, 1125, 264, 26329, 295, 264, 18875, 11, 597, 486, 920, 976, 291, 264, 3513, 11, 50616], "temperature": 0.0, "avg_logprob": -0.0819567550312389, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00012730780872516334}, {"id": 13, "seek": 8200, "start": 87.6, "end": 94.16, "text": " and if you really need the length, then add colors to indicate how long the vector should have been.", "tokens": [50644, 293, 498, 291, 534, 643, 264, 4641, 11, 550, 909, 4577, 281, 13330, 577, 938, 264, 8062, 820, 362, 668, 13, 50972], "temperature": 0.0, "avg_logprob": -0.0819567550312389, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00012730780872516334}, {"id": 14, "seek": 8200, "start": 94.96000000000001, "end": 100.48, "text": " In particular, these two vectors are the important ones because they are the vectors", "tokens": [51012, 682, 1729, 11, 613, 732, 18875, 366, 264, 1021, 2306, 570, 436, 366, 264, 18875, 51288], "temperature": 0.0, "avg_logprob": -0.0819567550312389, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00012730780872516334}, {"id": 15, "seek": 8200, "start": 100.48, "end": 108.96000000000001, "text": " attached to the points 1, 0 and 0, 1 respectively. The vector attached to 1, 0 would be the first", "tokens": [51288, 8570, 281, 264, 2793, 502, 11, 1958, 293, 1958, 11, 502, 25009, 13, 440, 8062, 8570, 281, 502, 11, 1958, 576, 312, 264, 700, 51712], "temperature": 0.0, "avg_logprob": -0.0819567550312389, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.00012730780872516334}, {"id": 16, "seek": 10896, "start": 108.96, "end": 115.11999999999999, "text": " column of A, while the vector attached to 0, 1 would be the second column of A.", "tokens": [50364, 7738, 295, 316, 11, 1339, 264, 8062, 8570, 281, 1958, 11, 502, 576, 312, 264, 1150, 7738, 295, 316, 13, 50672], "temperature": 0.0, "avg_logprob": -0.06688675993964785, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.00021653879957739264}, {"id": 17, "seek": 10896, "start": 116.0, "end": 122.72, "text": " With this visualization of matrices, the intuition for trace is just one sentence.", "tokens": [50716, 2022, 341, 25801, 295, 32284, 11, 264, 24002, 337, 13508, 307, 445, 472, 8174, 13, 51052], "temperature": 0.0, "avg_logprob": -0.06688675993964785, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.00021653879957739264}, {"id": 18, "seek": 10896, "start": 122.72, "end": 128.88, "text": " The trace of A is the divergence of this vector field created by the matrix A.", "tokens": [51052, 440, 13508, 295, 316, 307, 264, 47387, 295, 341, 8062, 2519, 2942, 538, 264, 8141, 316, 13, 51360], "temperature": 0.0, "avg_logprob": -0.06688675993964785, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.00021653879957739264}, {"id": 19, "seek": 10896, "start": 129.84, "end": 135.92, "text": " We are going to see what divergence is. Now I am aware that this has been talked about on YouTube,", "tokens": [51408, 492, 366, 516, 281, 536, 437, 47387, 307, 13, 823, 286, 669, 3650, 300, 341, 575, 668, 2825, 466, 322, 3088, 11, 51712], "temperature": 0.0, "avg_logprob": -0.06688675993964785, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.00021653879957739264}, {"id": 20, "seek": 13592, "start": 136.0, "end": 141.83999999999997, "text": " but I want to be more quantitative, so bear with me if you already knew the visual intuition", "tokens": [50368, 457, 286, 528, 281, 312, 544, 27778, 11, 370, 6155, 365, 385, 498, 291, 1217, 2586, 264, 5056, 24002, 50660], "temperature": 0.0, "avg_logprob": -0.06620897803195687, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0002868447045329958}, {"id": 21, "seek": 13592, "start": 141.83999999999997, "end": 148.95999999999998, "text": " of divergence. Given a particular vector field, we can define divergence at a point,", "tokens": [50660, 295, 47387, 13, 18600, 257, 1729, 8062, 2519, 11, 321, 393, 6964, 47387, 412, 257, 935, 11, 51016], "temperature": 0.0, "avg_logprob": -0.06620897803195687, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0002868447045329958}, {"id": 22, "seek": 13592, "start": 148.95999999999998, "end": 156.95999999999998, "text": " say this red dot. We now consider a very small region around this dot, and write down the area", "tokens": [51016, 584, 341, 2182, 5893, 13, 492, 586, 1949, 257, 588, 1359, 4458, 926, 341, 5893, 11, 293, 2464, 760, 264, 1859, 51416], "temperature": 0.0, "avg_logprob": -0.06620897803195687, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0002868447045329958}, {"id": 23, "seek": 13592, "start": 156.95999999999998, "end": 164.72, "text": " of this small region. The next thing is to let every point in this small region evolve together", "tokens": [51416, 295, 341, 1359, 4458, 13, 440, 958, 551, 307, 281, 718, 633, 935, 294, 341, 1359, 4458, 16693, 1214, 51804], "temperature": 0.0, "avg_logprob": -0.06620897803195687, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.0002868447045329958}, {"id": 24, "seek": 16472, "start": 164.72, "end": 172.96, "text": " along the vector field. As you see, the area of this region changes. For divergence, we are", "tokens": [50364, 2051, 264, 8062, 2519, 13, 1018, 291, 536, 11, 264, 1859, 295, 341, 4458, 2962, 13, 1171, 47387, 11, 321, 366, 50776], "temperature": 0.0, "avg_logprob": -0.062184684806399874, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0003682888636831194}, {"id": 25, "seek": 16472, "start": 172.96, "end": 180.48, "text": " interested in thinking about how quickly the area changes initially, per area, as the area of the", "tokens": [50776, 3102, 294, 1953, 466, 577, 2661, 264, 1859, 2962, 9105, 11, 680, 1859, 11, 382, 264, 1859, 295, 264, 51152], "temperature": 0.0, "avg_logprob": -0.062184684806399874, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0003682888636831194}, {"id": 26, "seek": 16472, "start": 180.48, "end": 188.48, "text": " initial region shrinks to 0. In this case, let's look at how the area evolves again. We can see", "tokens": [51152, 5883, 4458, 9884, 16431, 281, 1958, 13, 682, 341, 1389, 11, 718, 311, 574, 412, 577, 264, 1859, 43737, 797, 13, 492, 393, 536, 51552], "temperature": 0.0, "avg_logprob": -0.062184684806399874, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.0003682888636831194}, {"id": 27, "seek": 18848, "start": 188.48, "end": 195.51999999999998, "text": " that it initially decreases, and in fact keeps decreasing along the way, so because the area", "tokens": [50364, 300, 309, 9105, 24108, 11, 293, 294, 1186, 5965, 23223, 2051, 264, 636, 11, 370, 570, 264, 1859, 50716], "temperature": 0.0, "avg_logprob": -0.04571581242689446, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.0003053433320019394}, {"id": 28, "seek": 18848, "start": 195.51999999999998, "end": 203.28, "text": " change is negative, we have the divergence at this red dot to also be negative. However,", "tokens": [50716, 1319, 307, 3671, 11, 321, 362, 264, 47387, 412, 341, 2182, 5893, 281, 611, 312, 3671, 13, 2908, 11, 51104], "temperature": 0.0, "avg_logprob": -0.04571581242689446, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.0003053433320019394}, {"id": 29, "seek": 18848, "start": 203.28, "end": 211.2, "text": " one reminder is that this rate of area change is per area. In this case, if we compare the final", "tokens": [51104, 472, 13548, 307, 300, 341, 3314, 295, 1859, 1319, 307, 680, 1859, 13, 682, 341, 1389, 11, 498, 321, 6794, 264, 2572, 51500], "temperature": 0.0, "avg_logprob": -0.04571581242689446, "compression_ratio": 1.6352941176470588, "no_speech_prob": 0.0003053433320019394}, {"id": 30, "seek": 21120, "start": 211.2, "end": 218.88, "text": " area with the initial area, we can record a change of negative 0.148 during the evolution.", "tokens": [50364, 1859, 365, 264, 5883, 1859, 11, 321, 393, 2136, 257, 1319, 295, 3671, 1958, 13, 7271, 23, 1830, 264, 9303, 13, 50748], "temperature": 0.0, "avg_logprob": -0.08455284118652344, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0025507742539048195}, {"id": 31, "seek": 21120, "start": 219.6, "end": 226.72, "text": " Now, if we quadruple the initial area and again play the same game and let this area evolve", "tokens": [50784, 823, 11, 498, 321, 10787, 894, 781, 264, 5883, 1859, 293, 797, 862, 264, 912, 1216, 293, 718, 341, 1859, 16693, 51140], "temperature": 0.0, "avg_logprob": -0.08455284118652344, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0025507742539048195}, {"id": 32, "seek": 21120, "start": 226.72, "end": 235.67999999999998, "text": " under the flow of the vector field, and this time, we record a change of negative 0.595 in area.", "tokens": [51140, 833, 264, 3095, 295, 264, 8062, 2519, 11, 293, 341, 565, 11, 321, 2136, 257, 1319, 295, 3671, 1958, 13, 20, 15718, 294, 1859, 13, 51588], "temperature": 0.0, "avg_logprob": -0.08455284118652344, "compression_ratio": 1.650887573964497, "no_speech_prob": 0.0025507742539048195}, {"id": 33, "seek": 23568, "start": 236.32, "end": 244.48000000000002, "text": " If we compare this change to the previous area change, this is exactly a factor of 4 accounting", "tokens": [50396, 759, 321, 6794, 341, 1319, 281, 264, 3894, 1859, 1319, 11, 341, 307, 2293, 257, 5952, 295, 1017, 19163, 50804], "temperature": 0.0, "avg_logprob": -0.08140370383191464, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.0009697249624878168}, {"id": 34, "seek": 23568, "start": 244.48000000000002, "end": 252.48000000000002, "text": " for rounding errors in my computer simulation. So, in our intuition of divergence, the per area", "tokens": [50804, 337, 48237, 13603, 294, 452, 3820, 16575, 13, 407, 11, 294, 527, 24002, 295, 47387, 11, 264, 680, 1859, 51204], "temperature": 0.0, "avg_logprob": -0.08140370383191464, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.0009697249624878168}, {"id": 35, "seek": 23568, "start": 252.48000000000002, "end": 260.16, "text": " part is very important. So that's the divergence part, but why is this related to the trace of", "tokens": [51204, 644, 307, 588, 1021, 13, 407, 300, 311, 264, 47387, 644, 11, 457, 983, 307, 341, 4077, 281, 264, 13508, 295, 51588], "temperature": 0.0, "avg_logprob": -0.08140370383191464, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.0009697249624878168}, {"id": 36, "seek": 26016, "start": 260.16, "end": 266.72, "text": " the matrix generating the vector field? Actually, the first question that comes up would be that the", "tokens": [50364, 264, 8141, 17746, 264, 8062, 2519, 30, 5135, 11, 264, 700, 1168, 300, 1487, 493, 576, 312, 300, 264, 50692], "temperature": 0.0, "avg_logprob": -0.05507140872122227, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0008830107399262488}, {"id": 37, "seek": 26016, "start": 266.72, "end": 273.68, "text": " divergence is a local property. This means that if we consider another point on the vector field,", "tokens": [50692, 47387, 307, 257, 2654, 4707, 13, 639, 1355, 300, 498, 321, 1949, 1071, 935, 322, 264, 8062, 2519, 11, 51040], "temperature": 0.0, "avg_logprob": -0.05507140872122227, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0008830107399262488}, {"id": 38, "seek": 26016, "start": 273.68, "end": 280.32000000000005, "text": " the divergence could be different. So, why does this statement seem like the divergence is the", "tokens": [51040, 264, 47387, 727, 312, 819, 13, 407, 11, 983, 775, 341, 5629, 1643, 411, 264, 47387, 307, 264, 51372], "temperature": 0.0, "avg_logprob": -0.05507140872122227, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0008830107399262488}, {"id": 39, "seek": 26016, "start": 280.32000000000005, "end": 287.36, "text": " same everywhere? Well, it's because it is, but just in this specific case, where everything is", "tokens": [51372, 912, 5315, 30, 1042, 11, 309, 311, 570, 309, 307, 11, 457, 445, 294, 341, 2685, 1389, 11, 689, 1203, 307, 51724], "temperature": 0.0, "avg_logprob": -0.05507140872122227, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0008830107399262488}, {"id": 40, "seek": 28736, "start": 287.44, "end": 294.88, "text": " generated by the matrix A. To see why the divergence is the same everywhere, let's first denote this", "tokens": [50368, 10833, 538, 264, 8141, 316, 13, 1407, 536, 983, 264, 47387, 307, 264, 912, 5315, 11, 718, 311, 700, 45708, 341, 50740], "temperature": 0.0, "avg_logprob": -0.10724492269019557, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0008558757253922522}, {"id": 41, "seek": 28736, "start": 294.88, "end": 302.72, "text": " point with its position vector x and any point within our small region around x to be x plus d", "tokens": [50740, 935, 365, 1080, 2535, 8062, 2031, 293, 604, 935, 1951, 527, 1359, 4458, 926, 2031, 281, 312, 2031, 1804, 274, 51132], "temperature": 0.0, "avg_logprob": -0.10724492269019557, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0008558757253922522}, {"id": 42, "seek": 28736, "start": 302.72, "end": 311.6, "text": " for small displacements d from x. Now, the vectors attached to those two points are A x and A x plus", "tokens": [51132, 337, 1359, 14996, 41140, 274, 490, 2031, 13, 823, 11, 264, 18875, 8570, 281, 729, 732, 2793, 366, 316, 2031, 293, 316, 2031, 1804, 51576], "temperature": 0.0, "avg_logprob": -0.10724492269019557, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0008558757253922522}, {"id": 43, "seek": 31160, "start": 311.6, "end": 318.16, "text": " d respectively. This means that the initial displacement between these two points is d,", "tokens": [50364, 274, 25009, 13, 639, 1355, 300, 264, 5883, 21899, 1296, 613, 732, 2793, 307, 274, 11, 50692], "temperature": 0.0, "avg_logprob": -0.07927385965983073, "compression_ratio": 1.6168224299065421, "no_speech_prob": 0.010327000170946121}, {"id": 44, "seek": 31160, "start": 318.8, "end": 325.44, "text": " and after a very short time epsilon, the displacement is increased by epsilon times", "tokens": [50724, 293, 934, 257, 588, 2099, 565, 17889, 11, 264, 21899, 307, 6505, 538, 17889, 1413, 51056], "temperature": 0.0, "avg_logprob": -0.07927385965983073, "compression_ratio": 1.6168224299065421, "no_speech_prob": 0.010327000170946121}, {"id": 45, "seek": 31160, "start": 325.44, "end": 332.96000000000004, "text": " A d. Here, A d is the difference in their velocities or the rate where they drift apart.", "tokens": [51056, 316, 274, 13, 1692, 11, 316, 274, 307, 264, 2649, 294, 641, 7806, 1088, 420, 264, 3314, 689, 436, 19699, 4936, 13, 51432], "temperature": 0.0, "avg_logprob": -0.07927385965983073, "compression_ratio": 1.6168224299065421, "no_speech_prob": 0.010327000170946121}, {"id": 46, "seek": 31160, "start": 333.52000000000004, "end": 340.72, "text": " However, notice that there is absolutely no x here. This result does not depend on x.", "tokens": [51460, 2908, 11, 3449, 300, 456, 307, 3122, 572, 2031, 510, 13, 639, 1874, 775, 406, 5672, 322, 2031, 13, 51820], "temperature": 0.0, "avg_logprob": -0.07927385965983073, "compression_ratio": 1.6168224299065421, "no_speech_prob": 0.010327000170946121}, {"id": 47, "seek": 34160, "start": 341.76000000000005, "end": 348.32000000000005, "text": " So, if we have this exact shape of the small region, let's illustrate it with just three points,", "tokens": [50372, 407, 11, 498, 321, 362, 341, 1900, 3909, 295, 264, 1359, 4458, 11, 718, 311, 23221, 309, 365, 445, 1045, 2793, 11, 50700], "temperature": 0.0, "avg_logprob": -0.09465654780355733, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00013134817709214985}, {"id": 48, "seek": 34160, "start": 348.32000000000005, "end": 353.28000000000003, "text": " each with displacements d i from the point we try to compute the divergence of.", "tokens": [50700, 1184, 365, 14996, 41140, 274, 741, 490, 264, 935, 321, 853, 281, 14722, 264, 47387, 295, 13, 50948], "temperature": 0.0, "avg_logprob": -0.09465654780355733, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00013134817709214985}, {"id": 49, "seek": 34160, "start": 354.48, "end": 362.08000000000004, "text": " After a short epsilon period of time, the displacements are changed to d i plus epsilon", "tokens": [51008, 2381, 257, 2099, 17889, 2896, 295, 565, 11, 264, 14996, 41140, 366, 3105, 281, 274, 741, 1804, 17889, 51388], "temperature": 0.0, "avg_logprob": -0.09465654780355733, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00013134817709214985}, {"id": 50, "seek": 34160, "start": 362.08000000000004, "end": 371.36, "text": " A d i. But these are independent of our position. So, even if we have this initial region elsewhere,", "tokens": [51388, 316, 274, 741, 13, 583, 613, 366, 6695, 295, 527, 2535, 13, 407, 11, 754, 498, 321, 362, 341, 5883, 4458, 14517, 11, 51852], "temperature": 0.0, "avg_logprob": -0.09465654780355733, "compression_ratio": 1.6590909090909092, "no_speech_prob": 0.00013134817709214985}, {"id": 51, "seek": 37160, "start": 371.92, "end": 380.08000000000004, "text": " we will still have the exact same shape after time epsilon. The change in area is the same", "tokens": [50380, 321, 486, 920, 362, 264, 1900, 912, 3909, 934, 565, 17889, 13, 440, 1319, 294, 1859, 307, 264, 912, 50788], "temperature": 0.0, "avg_logprob": -0.03857949087696691, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.000535751401912421}, {"id": 52, "seek": 37160, "start": 380.08000000000004, "end": 387.6, "text": " everywhere. Because the divergence is the area change per area, divergence is the same", "tokens": [50788, 5315, 13, 1436, 264, 47387, 307, 264, 1859, 1319, 680, 1859, 11, 47387, 307, 264, 912, 51164], "temperature": 0.0, "avg_logprob": -0.03857949087696691, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.000535751401912421}, {"id": 53, "seek": 37160, "start": 387.6, "end": 394.88, "text": " everywhere in this case. This also means we can choose a convenient region to see how its area", "tokens": [51164, 5315, 294, 341, 1389, 13, 639, 611, 1355, 321, 393, 2826, 257, 10851, 4458, 281, 536, 577, 1080, 1859, 51528], "temperature": 0.0, "avg_logprob": -0.03857949087696691, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.000535751401912421}, {"id": 54, "seek": 39488, "start": 394.88, "end": 402.32, "text": " changes, and this region doesn't have to be infinitesimal either. This is because if we chop", "tokens": [50364, 2962, 11, 293, 341, 4458, 1177, 380, 362, 281, 312, 7193, 3324, 10650, 2139, 13, 639, 307, 570, 498, 321, 7931, 50736], "temperature": 0.0, "avg_logprob": -0.09412531230760657, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.00669238343834877}, {"id": 55, "seek": 39488, "start": 402.32, "end": 410.64, "text": " any normal region into very small ones, then from our intuition of divergence, each small region U i", "tokens": [50736, 604, 2710, 4458, 666, 588, 1359, 2306, 11, 550, 490, 527, 24002, 295, 47387, 11, 1184, 1359, 4458, 624, 741, 51152], "temperature": 0.0, "avg_logprob": -0.09412531230760657, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.00669238343834877}, {"id": 56, "seek": 39488, "start": 411.2, "end": 420.4, "text": " has its area changed from A i to A i times 1 plus epsilon times divergence after time epsilon.", "tokens": [51180, 575, 1080, 1859, 3105, 490, 316, 741, 281, 316, 741, 1413, 502, 1804, 17889, 1413, 47387, 934, 565, 17889, 13, 51640], "temperature": 0.0, "avg_logprob": -0.09412531230760657, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.00669238343834877}, {"id": 57, "seek": 42040, "start": 421.12, "end": 428.71999999999997, "text": " Most importantly, we know now that divergence is the same across all these regions. So, for the", "tokens": [50400, 4534, 8906, 11, 321, 458, 586, 300, 47387, 307, 264, 912, 2108, 439, 613, 10682, 13, 407, 11, 337, 264, 50780], "temperature": 0.0, "avg_logprob": -0.06593536974778816, "compression_ratio": 1.5879120879120878, "no_speech_prob": 0.0005702986381947994}, {"id": 58, "seek": 42040, "start": 428.71999999999997, "end": 436.71999999999997, "text": " entire region U, which has its area being the sum of these small regions, would also scale by the", "tokens": [50780, 2302, 4458, 624, 11, 597, 575, 1080, 1859, 885, 264, 2408, 295, 613, 1359, 10682, 11, 576, 611, 4373, 538, 264, 51180], "temperature": 0.0, "avg_logprob": -0.06593536974778816, "compression_ratio": 1.5879120879120878, "no_speech_prob": 0.0005702986381947994}, {"id": 59, "seek": 42040, "start": 436.71999999999997, "end": 444.56, "text": " same factor of 1 plus epsilon times divergence. Since we can basically choose any region to see", "tokens": [51180, 912, 5952, 295, 502, 1804, 17889, 1413, 47387, 13, 4162, 321, 393, 1936, 2826, 604, 4458, 281, 536, 51572], "temperature": 0.0, "avg_logprob": -0.06593536974778816, "compression_ratio": 1.5879120879120878, "no_speech_prob": 0.0005702986381947994}, {"id": 60, "seek": 44456, "start": 444.56, "end": 453.12, "text": " how the area evolves, a convenient choice is the unit square containing points 1 0 and 0 1,", "tokens": [50364, 577, 264, 1859, 43737, 11, 257, 10851, 3922, 307, 264, 4985, 3732, 19273, 2793, 502, 1958, 293, 1958, 502, 11, 50792], "temperature": 0.0, "avg_logprob": -0.1062006558457466, "compression_ratio": 1.4756756756756757, "no_speech_prob": 0.0008830152801238}, {"id": 61, "seek": 44456, "start": 453.12, "end": 459.68, "text": " as the initial area would automatically be 1. So, we focus on the rate of area change.", "tokens": [50792, 382, 264, 5883, 1859, 576, 6772, 312, 502, 13, 407, 11, 321, 1879, 322, 264, 3314, 295, 1859, 1319, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1062006558457466, "compression_ratio": 1.4756756756756757, "no_speech_prob": 0.0008830152801238}, {"id": 62, "seek": 44456, "start": 460.88, "end": 468.88, "text": " If we suppose that A is the square matrix A, B, C, D, then as said before, the vector attached", "tokens": [51180, 759, 321, 7297, 300, 316, 307, 264, 3732, 8141, 316, 11, 363, 11, 383, 11, 413, 11, 550, 382, 848, 949, 11, 264, 8062, 8570, 51580], "temperature": 0.0, "avg_logprob": -0.1062006558457466, "compression_ratio": 1.4756756756756757, "no_speech_prob": 0.0008830152801238}, {"id": 63, "seek": 46888, "start": 468.88, "end": 476.8, "text": " to 1 0 would be the first column A, C, and the vector attached to 0 1 would be the second column,", "tokens": [50364, 281, 502, 1958, 576, 312, 264, 700, 7738, 316, 11, 383, 11, 293, 264, 8062, 8570, 281, 1958, 502, 576, 312, 264, 1150, 7738, 11, 50760], "temperature": 0.0, "avg_logprob": -0.07632177847403067, "compression_ratio": 1.5913978494623655, "no_speech_prob": 0.0006461793091148138}, {"id": 64, "seek": 46888, "start": 476.8, "end": 486.8, "text": " B, D. Let's focus on the point 1 0 and its attached vector A, C. Here, its vertical component doesn't", "tokens": [50760, 363, 11, 413, 13, 961, 311, 1879, 322, 264, 935, 502, 1958, 293, 1080, 8570, 8062, 316, 11, 383, 13, 1692, 11, 1080, 9429, 6542, 1177, 380, 51260], "temperature": 0.0, "avg_logprob": -0.07632177847403067, "compression_ratio": 1.5913978494623655, "no_speech_prob": 0.0006461793091148138}, {"id": 65, "seek": 46888, "start": 486.8, "end": 493.52, "text": " really matter here, because it doesn't change the area of the region. The base and height of the", "tokens": [51260, 534, 1871, 510, 11, 570, 309, 1177, 380, 1319, 264, 1859, 295, 264, 4458, 13, 440, 3096, 293, 6681, 295, 264, 51596], "temperature": 0.0, "avg_logprob": -0.07632177847403067, "compression_ratio": 1.5913978494623655, "no_speech_prob": 0.0006461793091148138}, {"id": 66, "seek": 49352, "start": 493.52, "end": 500.08, "text": " parallelogram have not changed. So, the vertical component doesn't matter, but what about the", "tokens": [50364, 8952, 12820, 362, 406, 3105, 13, 407, 11, 264, 9429, 6542, 1177, 380, 1871, 11, 457, 437, 466, 264, 50692], "temperature": 0.0, "avg_logprob": -0.0524209613230691, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.00028684907010756433}, {"id": 67, "seek": 49352, "start": 500.08, "end": 509.2, "text": " horizontal component? This time, it matters. The area has changed. The rate of change here is given", "tokens": [50692, 12750, 6542, 30, 639, 565, 11, 309, 7001, 13, 440, 1859, 575, 3105, 13, 440, 3314, 295, 1319, 510, 307, 2212, 51148], "temperature": 0.0, "avg_logprob": -0.0524209613230691, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.00028684907010756433}, {"id": 68, "seek": 49352, "start": 509.2, "end": 517.1999999999999, "text": " by precisely the horizontal component of the attached vector, which is A. You can run a very", "tokens": [51148, 538, 13402, 264, 12750, 6542, 295, 264, 8570, 8062, 11, 597, 307, 316, 13, 509, 393, 1190, 257, 588, 51548], "temperature": 0.0, "avg_logprob": -0.0524209613230691, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.00028684907010756433}, {"id": 69, "seek": 51720, "start": 517.2800000000001, "end": 524.48, "text": " similar argument on the other point 0 1 here. This time, the horizontal component does not matter,", "tokens": [50368, 2531, 6770, 322, 264, 661, 935, 1958, 502, 510, 13, 639, 565, 11, 264, 12750, 6542, 775, 406, 1871, 11, 50728], "temperature": 0.0, "avg_logprob": -0.0841137272971017, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001098706852644682}, {"id": 70, "seek": 51720, "start": 524.48, "end": 530.88, "text": " because again, the area wouldn't change in that case, and the vertical component provides the", "tokens": [50728, 570, 797, 11, 264, 1859, 2759, 380, 1319, 294, 300, 1389, 11, 293, 264, 9429, 6542, 6417, 264, 51048], "temperature": 0.0, "avg_logprob": -0.0841137272971017, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001098706852644682}, {"id": 71, "seek": 51720, "start": 530.88, "end": 540.32, "text": " change in area. In this case, the vertical component is D. So, altogether, the rate of change in area", "tokens": [51048, 1319, 294, 1859, 13, 682, 341, 1389, 11, 264, 9429, 6542, 307, 413, 13, 407, 11, 19051, 11, 264, 3314, 295, 1319, 294, 1859, 51520], "temperature": 0.0, "avg_logprob": -0.0841137272971017, "compression_ratio": 1.6704545454545454, "no_speech_prob": 0.001098706852644682}, {"id": 72, "seek": 54032, "start": 540.32, "end": 548.5600000000001, "text": " would be A plus D, which is exactly the sum of the diagonal entries of the matrix A. So,", "tokens": [50364, 576, 312, 316, 1804, 413, 11, 597, 307, 2293, 264, 2408, 295, 264, 21539, 23041, 295, 264, 8141, 316, 13, 407, 11, 50776], "temperature": 0.0, "avg_logprob": -0.04772412022457847, "compression_ratio": 1.59375, "no_speech_prob": 0.002323083346709609}, {"id": 73, "seek": 54032, "start": 548.5600000000001, "end": 555.12, "text": " we have demonstrated that trace is really the divergence of the vector field. Now,", "tokens": [50776, 321, 362, 18772, 300, 13508, 307, 534, 264, 47387, 295, 264, 8062, 2519, 13, 823, 11, 51104], "temperature": 0.0, "avg_logprob": -0.04772412022457847, "compression_ratio": 1.59375, "no_speech_prob": 0.002323083346709609}, {"id": 74, "seek": 54032, "start": 555.12, "end": 561.2, "text": " if you are not convinced by these horizontal component or vertical component arguments,", "tokens": [51104, 498, 291, 366, 406, 12561, 538, 613, 12750, 6542, 420, 9429, 6542, 12869, 11, 51408], "temperature": 0.0, "avg_logprob": -0.04772412022457847, "compression_ratio": 1.59375, "no_speech_prob": 0.002323083346709609}, {"id": 75, "seek": 54032, "start": 561.2, "end": 568.5600000000001, "text": " all we are doing is computing the determinant of this slightly different matrix. The first column", "tokens": [51408, 439, 321, 366, 884, 307, 15866, 264, 41296, 295, 341, 4748, 819, 8141, 13, 440, 700, 7738, 51776], "temperature": 0.0, "avg_logprob": -0.04772412022457847, "compression_ratio": 1.59375, "no_speech_prob": 0.002323083346709609}, {"id": 76, "seek": 56856, "start": 568.56, "end": 576.56, "text": " is where the point 1 0 moves to after time epsilon with this velocity A C. Similarly,", "tokens": [50364, 307, 689, 264, 935, 502, 1958, 6067, 281, 934, 565, 17889, 365, 341, 9269, 316, 383, 13, 13157, 11, 50764], "temperature": 0.0, "avg_logprob": -0.08851691759549654, "compression_ratio": 1.6770186335403727, "no_speech_prob": 0.001032186090014875}, {"id": 77, "seek": 56856, "start": 576.56, "end": 584.4799999999999, "text": " the second column is where the point 0 1 moves to after time epsilon with the velocity B D.", "tokens": [50764, 264, 1150, 7738, 307, 689, 264, 935, 1958, 502, 6067, 281, 934, 565, 17889, 365, 264, 9269, 363, 413, 13, 51160], "temperature": 0.0, "avg_logprob": -0.08851691759549654, "compression_ratio": 1.6770186335403727, "no_speech_prob": 0.001032186090014875}, {"id": 78, "seek": 56856, "start": 585.4399999999999, "end": 591.8399999999999, "text": " If you actually compute this determinant, then we see that this is really the rate of change", "tokens": [51208, 759, 291, 767, 14722, 341, 41296, 11, 550, 321, 536, 300, 341, 307, 534, 264, 3314, 295, 1319, 51528], "temperature": 0.0, "avg_logprob": -0.08851691759549654, "compression_ratio": 1.6770186335403727, "no_speech_prob": 0.001032186090014875}, {"id": 79, "seek": 59184, "start": 591.84, "end": 599.2, "text": " of the area. That is also the trace. Anyway, the fact that trace is just the divergence of the", "tokens": [50364, 295, 264, 1859, 13, 663, 307, 611, 264, 13508, 13, 5684, 11, 264, 1186, 300, 13508, 307, 445, 264, 47387, 295, 264, 50732], "temperature": 0.0, "avg_logprob": -0.06695377292917735, "compression_ratio": 1.5628415300546448, "no_speech_prob": 0.003272862872108817}, {"id": 80, "seek": 59184, "start": 599.2, "end": 606.72, "text": " vector field is very useful for understanding the many properties of trace, and these properties", "tokens": [50732, 8062, 2519, 307, 588, 4420, 337, 3701, 264, 867, 7221, 295, 13508, 11, 293, 613, 7221, 51108], "temperature": 0.0, "avg_logprob": -0.06695377292917735, "compression_ratio": 1.5628415300546448, "no_speech_prob": 0.003272862872108817}, {"id": 81, "seek": 59184, "start": 606.72, "end": 613.84, "text": " one by one would be the focus of the video from this point onwards. Let's first start with why", "tokens": [51108, 472, 538, 472, 576, 312, 264, 1879, 295, 264, 960, 490, 341, 935, 34230, 13, 961, 311, 700, 722, 365, 983, 51464], "temperature": 0.0, "avg_logprob": -0.06695377292917735, "compression_ratio": 1.5628415300546448, "no_speech_prob": 0.003272862872108817}, {"id": 82, "seek": 61384, "start": 613.84, "end": 621.84, "text": " trace is the sum of eigenvalues. When visualizing matrices this way with vector fields, if the", "tokens": [50364, 13508, 307, 264, 2408, 295, 10446, 46033, 13, 1133, 5056, 3319, 32284, 341, 636, 365, 8062, 7909, 11, 498, 264, 50764], "temperature": 0.0, "avg_logprob": -0.06631269662276558, "compression_ratio": 1.7819905213270142, "no_speech_prob": 0.005729864351451397}, {"id": 83, "seek": 61384, "start": 621.84, "end": 630.0, "text": " position vector x is an eigenvector of A, then the vector attached to it, which is A x, would face", "tokens": [50764, 2535, 8062, 2031, 307, 364, 10446, 303, 1672, 295, 316, 11, 550, 264, 8062, 8570, 281, 309, 11, 597, 307, 316, 2031, 11, 576, 1851, 51172], "temperature": 0.0, "avg_logprob": -0.06631269662276558, "compression_ratio": 1.7819905213270142, "no_speech_prob": 0.005729864351451397}, {"id": 84, "seek": 61384, "start": 630.0, "end": 637.2, "text": " the same or opposite direction as the position vector. In fact, once you are on this line,", "tokens": [51172, 264, 912, 420, 6182, 3513, 382, 264, 2535, 8062, 13, 682, 1186, 11, 1564, 291, 366, 322, 341, 1622, 11, 51532], "temperature": 0.0, "avg_logprob": -0.06631269662276558, "compression_ratio": 1.7819905213270142, "no_speech_prob": 0.005729864351451397}, {"id": 85, "seek": 61384, "start": 637.2, "end": 643.12, "text": " you will stay on this line because the position and velocity vectors are both on this line.", "tokens": [51532, 291, 486, 1754, 322, 341, 1622, 570, 264, 2535, 293, 9269, 18875, 366, 1293, 322, 341, 1622, 13, 51828], "temperature": 0.0, "avg_logprob": -0.06631269662276558, "compression_ratio": 1.7819905213270142, "no_speech_prob": 0.005729864351451397}, {"id": 86, "seek": 64384, "start": 644.08, "end": 648.5600000000001, "text": " In the case where there are two such lines, where the position vector and the velocity", "tokens": [50376, 682, 264, 1389, 689, 456, 366, 732, 1270, 3876, 11, 689, 264, 2535, 8062, 293, 264, 9269, 50600], "temperature": 0.0, "avg_logprob": -0.0700195453785084, "compression_ratio": 1.7009345794392523, "no_speech_prob": 6.605036469409242e-05}, {"id": 87, "seek": 64384, "start": 648.5600000000001, "end": 654.96, "text": " vector attached are on the same line, then to investigate the divergence of the vector field", "tokens": [50600, 8062, 8570, 366, 322, 264, 912, 1622, 11, 550, 281, 15013, 264, 47387, 295, 264, 8062, 2519, 50920], "temperature": 0.0, "avg_logprob": -0.0700195453785084, "compression_ratio": 1.7009345794392523, "no_speech_prob": 6.605036469409242e-05}, {"id": 88, "seek": 64384, "start": 654.96, "end": 662.5600000000001, "text": " and hence the trace, one convenient choice of region is a parallelogram aligned with these two", "tokens": [50920, 293, 16678, 264, 13508, 11, 472, 10851, 3922, 295, 4458, 307, 257, 8952, 12820, 17962, 365, 613, 732, 51300], "temperature": 0.0, "avg_logprob": -0.0700195453785084, "compression_ratio": 1.7009345794392523, "no_speech_prob": 6.605036469409242e-05}, {"id": 89, "seek": 64384, "start": 662.5600000000001, "end": 669.6800000000001, "text": " lines. Let's label the two lines by their eigenvalues lambda 1 and lambda 2 respectively.", "tokens": [51300, 3876, 13, 961, 311, 7645, 264, 732, 3876, 538, 641, 10446, 46033, 13607, 502, 293, 13607, 568, 25009, 13, 51656], "temperature": 0.0, "avg_logprob": -0.0700195453785084, "compression_ratio": 1.7009345794392523, "no_speech_prob": 6.605036469409242e-05}, {"id": 90, "seek": 66968, "start": 670.4, "end": 678.4799999999999, "text": " And let's say the side lengths of the parallelogram are A and B. Focus on this corner of the", "tokens": [50400, 400, 718, 311, 584, 264, 1252, 26329, 295, 264, 8952, 12820, 366, 316, 293, 363, 13, 21862, 322, 341, 4538, 295, 264, 50804], "temperature": 0.0, "avg_logprob": -0.08519118853977749, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0002531503851059824}, {"id": 91, "seek": 66968, "start": 678.4799999999999, "end": 685.4399999999999, "text": " parallelogram. The length of the vector attached to it should be lambda 1A. That's because on", "tokens": [50804, 8952, 12820, 13, 440, 4641, 295, 264, 8062, 8570, 281, 309, 820, 312, 13607, 502, 32, 13, 663, 311, 570, 322, 51152], "temperature": 0.0, "avg_logprob": -0.08519118853977749, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0002531503851059824}, {"id": 92, "seek": 66968, "start": 685.4399999999999, "end": 693.76, "text": " this line, every position vector satisfies A x equals lambda 1 x. Since the position vector has", "tokens": [51152, 341, 1622, 11, 633, 2535, 8062, 44271, 316, 2031, 6915, 13607, 502, 2031, 13, 4162, 264, 2535, 8062, 575, 51568], "temperature": 0.0, "avg_logprob": -0.08519118853977749, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0002531503851059824}, {"id": 93, "seek": 69376, "start": 693.76, "end": 701.92, "text": " length A in our notation, the vector attached to it should be with length lambda 1A. So after a", "tokens": [50364, 4641, 316, 294, 527, 24657, 11, 264, 8062, 8570, 281, 309, 820, 312, 365, 4641, 13607, 502, 32, 13, 407, 934, 257, 50772], "temperature": 0.0, "avg_logprob": -0.06405813519547625, "compression_ratio": 1.7736842105263158, "no_speech_prob": 0.0005527684697881341}, {"id": 94, "seek": 69376, "start": 701.92, "end": 709.4399999999999, "text": " very short time epsilon, we should have an extra length of epsilon lambda 1A along this line.", "tokens": [50772, 588, 2099, 565, 17889, 11, 321, 820, 362, 364, 2857, 4641, 295, 17889, 13607, 502, 32, 2051, 341, 1622, 13, 51148], "temperature": 0.0, "avg_logprob": -0.06405813519547625, "compression_ratio": 1.7736842105263158, "no_speech_prob": 0.0005527684697881341}, {"id": 95, "seek": 69376, "start": 710.24, "end": 714.48, "text": " Using the same argument on the other corner of the parallelogram,", "tokens": [51188, 11142, 264, 912, 6770, 322, 264, 661, 4538, 295, 264, 8952, 12820, 11, 51400], "temperature": 0.0, "avg_logprob": -0.06405813519547625, "compression_ratio": 1.7736842105263158, "no_speech_prob": 0.0005527684697881341}, {"id": 96, "seek": 69376, "start": 714.48, "end": 721.68, "text": " the extra length on the other line would be epsilon lambda 2B after time epsilon.", "tokens": [51400, 264, 2857, 4641, 322, 264, 661, 1622, 576, 312, 17889, 13607, 568, 33, 934, 565, 17889, 13, 51760], "temperature": 0.0, "avg_logprob": -0.06405813519547625, "compression_ratio": 1.7736842105263158, "no_speech_prob": 0.0005527684697881341}, {"id": 97, "seek": 72168, "start": 722.4, "end": 729.92, "text": " In this illustration, lambda 2 is negative, so the so-called extra length is actually length", "tokens": [50400, 682, 341, 22645, 11, 13607, 568, 307, 3671, 11, 370, 264, 370, 12, 11880, 2857, 4641, 307, 767, 4641, 50776], "temperature": 0.0, "avg_logprob": -0.09388394853962001, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.0010648556053638458}, {"id": 98, "seek": 72168, "start": 729.92, "end": 736.0799999999999, "text": " lost. So after a short time epsilon, the length along this lambda 2 line would be", "tokens": [50776, 2731, 13, 407, 934, 257, 2099, 565, 17889, 11, 264, 4641, 2051, 341, 13607, 568, 1622, 576, 312, 51084], "temperature": 0.0, "avg_logprob": -0.09388394853962001, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.0010648556053638458}, {"id": 99, "seek": 72168, "start": 736.64, "end": 745.76, "text": " B x 1 plus epsilon lambda 2, and similarly the length along the lambda 1 line would be A x 1", "tokens": [51112, 363, 2031, 502, 1804, 17889, 13607, 568, 11, 293, 14138, 264, 4641, 2051, 264, 13607, 502, 1622, 576, 312, 316, 2031, 502, 51568], "temperature": 0.0, "avg_logprob": -0.09388394853962001, "compression_ratio": 1.679245283018868, "no_speech_prob": 0.0010648556053638458}, {"id": 100, "seek": 74576, "start": 745.76, "end": 754.16, "text": " plus epsilon lambda 1. The new area is the product of the side lengths and sine theta,", "tokens": [50364, 1804, 17889, 13607, 502, 13, 440, 777, 1859, 307, 264, 1674, 295, 264, 1252, 26329, 293, 18609, 9725, 11, 50784], "temperature": 0.0, "avg_logprob": -0.06951475143432617, "compression_ratio": 1.5819209039548023, "no_speech_prob": 0.0018100463785231113}, {"id": 101, "seek": 74576, "start": 754.16, "end": 762.4, "text": " where theta is the angle between these two lines. Compare this with the old area, which is AB sine", "tokens": [50784, 689, 9725, 307, 264, 5802, 1296, 613, 732, 3876, 13, 48523, 341, 365, 264, 1331, 1859, 11, 597, 307, 13838, 18609, 51196], "temperature": 0.0, "avg_logprob": -0.06951475143432617, "compression_ratio": 1.5819209039548023, "no_speech_prob": 0.0018100463785231113}, {"id": 102, "seek": 74576, "start": 762.4, "end": 769.12, "text": " theta. If we now compute the divergence of this vector field, which is the rate of area change", "tokens": [51196, 9725, 13, 759, 321, 586, 14722, 264, 47387, 295, 341, 8062, 2519, 11, 597, 307, 264, 3314, 295, 1859, 1319, 51532], "temperature": 0.0, "avg_logprob": -0.06951475143432617, "compression_ratio": 1.5819209039548023, "no_speech_prob": 0.0018100463785231113}, {"id": 103, "seek": 76912, "start": 769.12, "end": 776.88, "text": " per area, then we would have this expression, which is new area minus the old area over the", "tokens": [50364, 680, 1859, 11, 550, 321, 576, 362, 341, 6114, 11, 597, 307, 777, 1859, 3175, 264, 1331, 1859, 670, 264, 50752], "temperature": 0.0, "avg_logprob": -0.0552957330431257, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.002550804289057851}, {"id": 104, "seek": 76912, "start": 776.88, "end": 785.36, "text": " time period of epsilon, divided by the initial area, which is AB sine theta. If you really compute", "tokens": [50752, 565, 2896, 295, 17889, 11, 6666, 538, 264, 5883, 1859, 11, 597, 307, 13838, 18609, 9725, 13, 759, 291, 534, 14722, 51176], "temperature": 0.0, "avg_logprob": -0.0552957330431257, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.002550804289057851}, {"id": 105, "seek": 76912, "start": 785.36, "end": 794.88, "text": " this, we would have lambda 1 plus lambda 2 plus a small bit involving epsilon. However, as epsilon", "tokens": [51176, 341, 11, 321, 576, 362, 13607, 502, 1804, 13607, 568, 1804, 257, 1359, 857, 17030, 17889, 13, 2908, 11, 382, 17889, 51652], "temperature": 0.0, "avg_logprob": -0.0552957330431257, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.002550804289057851}, {"id": 106, "seek": 79488, "start": 794.88, "end": 800.8, "text": " tends to zero, then the epsilon bit does not contribute, and we are left with the sum of", "tokens": [50364, 12258, 281, 4018, 11, 550, 264, 17889, 857, 775, 406, 10586, 11, 293, 321, 366, 1411, 365, 264, 2408, 295, 50660], "temperature": 0.0, "avg_logprob": -0.05668611418117176, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0002531491045374423}, {"id": 107, "seek": 79488, "start": 800.8, "end": 808.96, "text": " eigenvalues. So the trace is the sum of the eigenvalues in this illustration. So this is the", "tokens": [50660, 10446, 46033, 13, 407, 264, 13508, 307, 264, 2408, 295, 264, 10446, 46033, 294, 341, 22645, 13, 407, 341, 307, 264, 51068], "temperature": 0.0, "avg_logprob": -0.05668611418117176, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0002531491045374423}, {"id": 108, "seek": 79488, "start": 808.96, "end": 816.32, "text": " first property of trace. The next property has something to do with the exponential of matrices,", "tokens": [51068, 700, 4707, 295, 13508, 13, 440, 958, 4707, 575, 746, 281, 360, 365, 264, 21510, 295, 32284, 11, 51436], "temperature": 0.0, "avg_logprob": -0.05668611418117176, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0002531491045374423}, {"id": 109, "seek": 79488, "start": 816.32, "end": 823.52, "text": " which I have described in the previous video as well. Essentially, given a vector field created by", "tokens": [51436, 597, 286, 362, 7619, 294, 264, 3894, 960, 382, 731, 13, 23596, 11, 2212, 257, 8062, 2519, 2942, 538, 51796], "temperature": 0.0, "avg_logprob": -0.05668611418117176, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0002531491045374423}, {"id": 110, "seek": 82352, "start": 823.52, "end": 832.0799999999999, "text": " the matrix A, the flow of this point with position vector x along the vector field is precisely given", "tokens": [50364, 264, 8141, 316, 11, 264, 3095, 295, 341, 935, 365, 2535, 8062, 2031, 2051, 264, 8062, 2519, 307, 13402, 2212, 50792], "temperature": 0.0, "avg_logprob": -0.0424201386315482, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0006263047689571977}, {"id": 111, "seek": 82352, "start": 832.0799999999999, "end": 839.28, "text": " by e to the ta applied to x, where t is the time elapsed when you flow along the field.", "tokens": [50792, 538, 308, 281, 264, 1846, 6456, 281, 2031, 11, 689, 256, 307, 264, 565, 806, 2382, 292, 562, 291, 3095, 2051, 264, 2519, 13, 51152], "temperature": 0.0, "avg_logprob": -0.0424201386315482, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0006263047689571977}, {"id": 112, "seek": 82352, "start": 840.0, "end": 847.04, "text": " The determinant of a matrix is the scale factor of this unit square under the matrix transformation.", "tokens": [51188, 440, 41296, 295, 257, 8141, 307, 264, 4373, 5952, 295, 341, 4985, 3732, 833, 264, 8141, 9887, 13, 51540], "temperature": 0.0, "avg_logprob": -0.0424201386315482, "compression_ratio": 1.6571428571428573, "no_speech_prob": 0.0006263047689571977}, {"id": 113, "seek": 84704, "start": 847.68, "end": 854.24, "text": " Applying the matrix e to the ta to this square is equivalent to letting the region flow along the", "tokens": [50396, 3132, 7310, 264, 8141, 308, 281, 264, 1846, 281, 341, 3732, 307, 10344, 281, 8295, 264, 4458, 3095, 2051, 264, 50724], "temperature": 0.0, "avg_logprob": -0.06585203900056727, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.00016346272605005652}, {"id": 114, "seek": 84704, "start": 854.24, "end": 861.4399999999999, "text": " vector field, so the area of whatever we end up with is the determinant of the matrix exponential.", "tokens": [50724, 8062, 2519, 11, 370, 264, 1859, 295, 2035, 321, 917, 493, 365, 307, 264, 41296, 295, 264, 8141, 21510, 13, 51084], "temperature": 0.0, "avg_logprob": -0.06585203900056727, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.00016346272605005652}, {"id": 115, "seek": 84704, "start": 862.16, "end": 868.56, "text": " And we actually know how the areas evolve along this vector flow. Let's denote the area of this", "tokens": [51120, 400, 321, 767, 458, 577, 264, 3179, 16693, 2051, 341, 8062, 3095, 13, 961, 311, 45708, 264, 1859, 295, 341, 51440], "temperature": 0.0, "avg_logprob": -0.06585203900056727, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.00016346272605005652}, {"id": 116, "seek": 86856, "start": 868.56, "end": 877.28, "text": " region as s of t, which depends on time elapsed along the vector field. The trace of a is the rate", "tokens": [50364, 4458, 382, 262, 295, 256, 11, 597, 5946, 322, 565, 806, 2382, 292, 2051, 264, 8062, 2519, 13, 440, 13508, 295, 257, 307, 264, 3314, 50800], "temperature": 0.0, "avg_logprob": -0.0553728805647956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00015843388973735273}, {"id": 117, "seek": 86856, "start": 877.28, "end": 883.3599999999999, "text": " of area change per area, with the rate of change in area being the derivative of s,", "tokens": [50800, 295, 1859, 1319, 680, 1859, 11, 365, 264, 3314, 295, 1319, 294, 1859, 885, 264, 13760, 295, 262, 11, 51104], "temperature": 0.0, "avg_logprob": -0.0553728805647956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00015843388973735273}, {"id": 118, "seek": 86856, "start": 884.0, "end": 893.04, "text": " and the area being s of t itself. By rearranging this formula, we obtain a differential equation", "tokens": [51136, 293, 264, 1859, 885, 262, 295, 256, 2564, 13, 3146, 29875, 9741, 341, 8513, 11, 321, 12701, 257, 15756, 5367, 51588], "temperature": 0.0, "avg_logprob": -0.0553728805647956, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.00015843388973735273}, {"id": 119, "seek": 89304, "start": 893.12, "end": 900.88, "text": " in s. Note that the trace of a does not depend on t, it is a constant, so the determinant s of t", "tokens": [50368, 294, 262, 13, 11633, 300, 264, 13508, 295, 257, 775, 406, 5672, 322, 256, 11, 309, 307, 257, 5754, 11, 370, 264, 41296, 262, 295, 256, 50756], "temperature": 0.0, "avg_logprob": -0.07676426140037743, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0007321605226024985}, {"id": 120, "seek": 89304, "start": 900.88, "end": 909.52, "text": " can be solved as e to the t times trace of a. This neatly explains why the determinant of the", "tokens": [50756, 393, 312, 13041, 382, 308, 281, 264, 256, 1413, 13508, 295, 257, 13, 639, 36634, 13948, 983, 264, 41296, 295, 264, 51188], "temperature": 0.0, "avg_logprob": -0.07676426140037743, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0007321605226024985}, {"id": 121, "seek": 89304, "start": 909.52, "end": 917.8399999999999, "text": " exponential matrix is the exponential of trace. Now let's go to the property that the trace is", "tokens": [51188, 21510, 8141, 307, 264, 21510, 295, 13508, 13, 823, 718, 311, 352, 281, 264, 4707, 300, 264, 13508, 307, 51604], "temperature": 0.0, "avg_logprob": -0.07676426140037743, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0007321605226024985}, {"id": 122, "seek": 91784, "start": 917.84, "end": 925.12, "text": " independent of basis vectors. Given the matrix a, as usual we consider the vector field", "tokens": [50364, 6695, 295, 5143, 18875, 13, 18600, 264, 8141, 257, 11, 382, 7713, 321, 1949, 264, 8062, 2519, 50728], "temperature": 0.0, "avg_logprob": -0.08371475094654521, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.00010229785402771086}, {"id": 123, "seek": 91784, "start": 925.12, "end": 931.6, "text": " generated. This time, we apply a linear transformation q to the whole picture.", "tokens": [50728, 10833, 13, 639, 565, 11, 321, 3079, 257, 8213, 9887, 9505, 281, 264, 1379, 3036, 13, 51052], "temperature": 0.0, "avg_logprob": -0.08371475094654521, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.00010229785402771086}, {"id": 124, "seek": 91784, "start": 932.4, "end": 939.36, "text": " In general, where the vectors emanate from would change, and the vectors attached would also change.", "tokens": [51092, 682, 2674, 11, 689, 264, 18875, 28211, 473, 490, 576, 1319, 11, 293, 264, 18875, 8570, 576, 611, 1319, 13, 51440], "temperature": 0.0, "avg_logprob": -0.08371475094654521, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.00010229785402771086}, {"id": 125, "seek": 93936, "start": 939.92, "end": 949.28, "text": " More specifically, what had been x is now transformed to qx, and what used to be ax is now", "tokens": [50392, 5048, 4682, 11, 437, 632, 668, 2031, 307, 586, 16894, 281, 9505, 87, 11, 293, 437, 1143, 281, 312, 6360, 307, 586, 50860], "temperature": 0.0, "avg_logprob": -0.0768421623441908, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.001284265541471541}, {"id": 126, "seek": 93936, "start": 949.28, "end": 957.12, "text": " qax. This one needs a bit of explanation. Initially, the attached vector to the point x", "tokens": [50860, 9505, 2797, 13, 639, 472, 2203, 257, 857, 295, 10835, 13, 29446, 11, 264, 8570, 8062, 281, 264, 935, 2031, 51252], "temperature": 0.0, "avg_logprob": -0.0768421623441908, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.001284265541471541}, {"id": 127, "seek": 93936, "start": 957.12, "end": 965.6800000000001, "text": " is going from point x to x plus ax, so when we apply the transformation q on the whole picture,", "tokens": [51252, 307, 516, 490, 935, 2031, 281, 2031, 1804, 6360, 11, 370, 562, 321, 3079, 264, 9887, 9505, 322, 264, 1379, 3036, 11, 51680], "temperature": 0.0, "avg_logprob": -0.0768421623441908, "compression_ratio": 1.5480225988700564, "no_speech_prob": 0.001284265541471541}, {"id": 128, "seek": 96568, "start": 965.76, "end": 975.8399999999999, "text": " then the attached vector goes from qx to qx plus qax, so this attached vector is qax.", "tokens": [50368, 550, 264, 8570, 8062, 1709, 490, 9505, 87, 281, 9505, 87, 1804, 9505, 2797, 11, 370, 341, 8570, 8062, 307, 9505, 2797, 13, 50872], "temperature": 0.0, "avg_logprob": -0.10394596586040422, "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.0010986772831529379}, {"id": 129, "seek": 96568, "start": 976.9599999999999, "end": 986.0799999999999, "text": " Now let's call this new position vector y, then in terms of y, the attached vector is qa", "tokens": [50928, 823, 718, 311, 818, 341, 777, 2535, 8062, 288, 11, 550, 294, 2115, 295, 288, 11, 264, 8570, 8062, 307, 9505, 64, 51384], "temperature": 0.0, "avg_logprob": -0.10394596586040422, "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.0010986772831529379}, {"id": 130, "seek": 98608, "start": 986.08, "end": 996.5600000000001, "text": " qinverse y, if q is invertible. So for any position vector y, the attached vector is qa qinverse y,", "tokens": [50364, 9505, 259, 4308, 288, 11, 498, 9505, 307, 33966, 964, 13, 407, 337, 604, 2535, 8062, 288, 11, 264, 8570, 8062, 307, 9505, 64, 9505, 259, 4308, 288, 11, 50888], "temperature": 0.0, "avg_logprob": -0.1020975601978791, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0024725368712097406}, {"id": 131, "seek": 98608, "start": 996.5600000000001, "end": 1004.32, "text": " which suggests that this is actually the vector field of another matrix, qa qinverse.", "tokens": [50888, 597, 13409, 300, 341, 307, 767, 264, 8062, 2519, 295, 1071, 8141, 11, 9505, 64, 9505, 259, 4308, 13, 51276], "temperature": 0.0, "avg_logprob": -0.1020975601978791, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0024725368712097406}, {"id": 132, "seek": 98608, "start": 1005.2800000000001, "end": 1011.84, "text": " Now the trace is the rate of change in area per area, but in applying q to the whole thing,", "tokens": [51324, 823, 264, 13508, 307, 264, 3314, 295, 1319, 294, 1859, 680, 1859, 11, 457, 294, 9275, 9505, 281, 264, 1379, 551, 11, 51652], "temperature": 0.0, "avg_logprob": -0.1020975601978791, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0024725368712097406}, {"id": 133, "seek": 101184, "start": 1012.48, "end": 1019.6, "text": " all areas scale by the determinant of q, and this factor of determinant cancels", "tokens": [50396, 439, 3179, 4373, 538, 264, 41296, 295, 9505, 11, 293, 341, 5952, 295, 41296, 393, 66, 1625, 50752], "temperature": 0.0, "avg_logprob": -0.09102294842402141, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.00225172215141356}, {"id": 134, "seek": 101184, "start": 1019.6, "end": 1028.72, "text": " when we consider the quotient. So in other words, the trace of a equals the trace of qa qinverse,", "tokens": [50752, 562, 321, 1949, 264, 9641, 1196, 13, 407, 294, 661, 2283, 11, 264, 13508, 295, 257, 6915, 264, 13508, 295, 9505, 64, 9505, 259, 4308, 11, 51208], "temperature": 0.0, "avg_logprob": -0.09102294842402141, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.00225172215141356}, {"id": 135, "seek": 101184, "start": 1029.28, "end": 1036.4, "text": " or if you want to go for the usual change of basis formula p inverse ap, simply substitute the matrix", "tokens": [51236, 420, 498, 291, 528, 281, 352, 337, 264, 7713, 1319, 295, 5143, 8513, 280, 17340, 1882, 11, 2935, 15802, 264, 8141, 51592], "temperature": 0.0, "avg_logprob": -0.09102294842402141, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.00225172215141356}, {"id": 136, "seek": 103640, "start": 1036.4, "end": 1045.2, "text": " q as p inverse. Using this relation, we are able to derive another famous property of trace,", "tokens": [50364, 9505, 382, 280, 17340, 13, 11142, 341, 9721, 11, 321, 366, 1075, 281, 28446, 1071, 4618, 4707, 295, 13508, 11, 50804], "temperature": 0.0, "avg_logprob": -0.05717499155393788, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0018101072637364268}, {"id": 137, "seek": 103640, "start": 1045.2, "end": 1053.0400000000002, "text": " which starts from rewriting trace of ab. If b is invertible, then we can simply add in", "tokens": [50804, 597, 3719, 490, 319, 19868, 13508, 295, 410, 13, 759, 272, 307, 33966, 964, 11, 550, 321, 393, 2935, 909, 294, 51196], "temperature": 0.0, "avg_logprob": -0.05717499155393788, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0018101072637364268}, {"id": 138, "seek": 103640, "start": 1053.0400000000002, "end": 1061.2800000000002, "text": " b inverse b, and the expression stays the same. However, written like this, we can use the property", "tokens": [51196, 272, 17340, 272, 11, 293, 264, 6114, 10834, 264, 912, 13, 2908, 11, 3720, 411, 341, 11, 321, 393, 764, 264, 4707, 51608], "temperature": 0.0, "avg_logprob": -0.05717499155393788, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0018101072637364268}, {"id": 139, "seek": 106128, "start": 1061.28, "end": 1069.68, "text": " we just derived, and then we can obtain, it is the trace of ba. Now this property of trace", "tokens": [50364, 321, 445, 18949, 11, 293, 550, 321, 393, 12701, 11, 309, 307, 264, 13508, 295, 4773, 13, 823, 341, 4707, 295, 13508, 50784], "temperature": 0.0, "avg_logprob": -0.06630883374056973, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.00033533957321196795}, {"id": 140, "seek": 106128, "start": 1069.68, "end": 1077.2, "text": " is perhaps more well known, but we have done a bit of algebra to get here. There is a better way,", "tokens": [50784, 307, 4317, 544, 731, 2570, 11, 457, 321, 362, 1096, 257, 857, 295, 21989, 281, 483, 510, 13, 821, 307, 257, 1101, 636, 11, 51160], "temperature": 0.0, "avg_logprob": -0.06630883374056973, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.00033533957321196795}, {"id": 141, "seek": 106128, "start": 1077.2, "end": 1083.2, "text": " but we will need to introduce the concept of lee bracket, a story for another time.", "tokens": [51160, 457, 321, 486, 643, 281, 5366, 264, 3410, 295, 46571, 16904, 11, 257, 1657, 337, 1071, 565, 13, 51460], "temperature": 0.0, "avg_logprob": -0.06630883374056973, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.00033533957321196795}, {"id": 142, "seek": 106128, "start": 1084.0, "end": 1090.48, "text": " So we can obtain this property of trace by transforming the whole plane by p inverse,", "tokens": [51500, 407, 321, 393, 12701, 341, 4707, 295, 13508, 538, 27210, 264, 1379, 5720, 538, 280, 17340, 11, 51824], "temperature": 0.0, "avg_logprob": -0.06630883374056973, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.00033533957321196795}, {"id": 143, "seek": 109048, "start": 1090.48, "end": 1098.0, "text": " and the final property we will see is this perhaps less famous formula. This formula is known as", "tokens": [50364, 293, 264, 2572, 4707, 321, 486, 536, 307, 341, 4317, 1570, 4618, 8513, 13, 639, 8513, 307, 2570, 382, 50740], "temperature": 0.0, "avg_logprob": -0.10570929084025638, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.00020341943309176713}, {"id": 144, "seek": 109048, "start": 1098.0, "end": 1106.08, "text": " Jacobi's formula for a matrix A that depends on time t. Well technically, this is only true if", "tokens": [50740, 14117, 72, 311, 8513, 337, 257, 8141, 316, 300, 5946, 322, 565, 256, 13, 1042, 12120, 11, 341, 307, 787, 2074, 498, 51144], "temperature": 0.0, "avg_logprob": -0.10570929084025638, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.00020341943309176713}, {"id": 145, "seek": 109048, "start": 1106.08, "end": 1113.2, "text": " a of t in this formula is invertible, because there is a inverse in the formula. A more general", "tokens": [51144, 257, 295, 256, 294, 341, 8513, 307, 33966, 964, 11, 570, 456, 307, 257, 17340, 294, 264, 8513, 13, 316, 544, 2674, 51500], "temperature": 0.0, "avg_logprob": -0.10570929084025638, "compression_ratio": 1.5856353591160222, "no_speech_prob": 0.00020341943309176713}, {"id": 146, "seek": 111320, "start": 1113.2, "end": 1120.64, "text": " formula involves the adjoint matrix, which is defined even if a is not invertible. But for the", "tokens": [50364, 8513, 11626, 264, 614, 48613, 8141, 11, 597, 307, 7642, 754, 498, 257, 307, 406, 33966, 964, 13, 583, 337, 264, 50736], "temperature": 0.0, "avg_logprob": -0.07838017698647319, "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.0033764364197850227}, {"id": 147, "seek": 111320, "start": 1120.64, "end": 1128.32, "text": " purpose of visualization, we are going to assume a is invertible and try to understand this formula", "tokens": [50736, 4334, 295, 25801, 11, 321, 366, 516, 281, 6552, 257, 307, 33966, 964, 293, 853, 281, 1223, 341, 8513, 51120], "temperature": 0.0, "avg_logprob": -0.07838017698647319, "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.0033764364197850227}, {"id": 148, "seek": 111320, "start": 1128.32, "end": 1136.0800000000002, "text": " first. First off, what does the left hand side really mean? The determinant can refer to the area", "tokens": [51120, 700, 13, 2386, 766, 11, 437, 775, 264, 1411, 1011, 1252, 534, 914, 30, 440, 41296, 393, 2864, 281, 264, 1859, 51508], "temperature": 0.0, "avg_logprob": -0.07838017698647319, "compression_ratio": 1.5208333333333333, "no_speech_prob": 0.0033764364197850227}, {"id": 149, "seek": 113608, "start": 1136.08, "end": 1145.12, "text": " of a parallelogram, described by a of t acting on the two basis vectors. This area will change", "tokens": [50364, 295, 257, 8952, 12820, 11, 7619, 538, 257, 295, 256, 6577, 322, 264, 732, 5143, 18875, 13, 639, 1859, 486, 1319, 50816], "temperature": 0.0, "avg_logprob": -0.08976847688916703, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.004468086175620556}, {"id": 150, "seek": 113608, "start": 1145.12, "end": 1154.8, "text": " because a itself evolves with time. In fact, these points would also change as a changes. The rate at", "tokens": [50816, 570, 257, 2564, 43737, 365, 565, 13, 682, 1186, 11, 613, 2793, 576, 611, 1319, 382, 257, 2962, 13, 440, 3314, 412, 51300], "temperature": 0.0, "avg_logprob": -0.08976847688916703, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.004468086175620556}, {"id": 151, "seek": 113608, "start": 1154.8, "end": 1163.1999999999998, "text": " which these corners move is exactly a prime of t acting on the basis vectors. If we can somehow", "tokens": [51300, 597, 613, 12413, 1286, 307, 2293, 257, 5835, 295, 256, 6577, 322, 264, 5143, 18875, 13, 759, 321, 393, 6063, 51720], "temperature": 0.0, "avg_logprob": -0.08976847688916703, "compression_ratio": 1.6132596685082874, "no_speech_prob": 0.004468086175620556}, {"id": 152, "seek": 116320, "start": 1163.2, "end": 1171.1200000000001, "text": " make this into a whole vector field generated by the matrix m, then we know how the area evolves.", "tokens": [50364, 652, 341, 666, 257, 1379, 8062, 2519, 10833, 538, 264, 8141, 275, 11, 550, 321, 458, 577, 264, 1859, 43737, 13, 50760], "temperature": 0.0, "avg_logprob": -0.066070556640625, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.001548680942505598}, {"id": 153, "seek": 116320, "start": 1171.1200000000001, "end": 1179.04, "text": " Specifically, we know that the trace of m is the rate of area change per area. In this case,", "tokens": [50760, 26058, 11, 321, 458, 300, 264, 13508, 295, 275, 307, 264, 3314, 295, 1859, 1319, 680, 1859, 13, 682, 341, 1389, 11, 51156], "temperature": 0.0, "avg_logprob": -0.066070556640625, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.001548680942505598}, {"id": 154, "seek": 116320, "start": 1179.04, "end": 1186.16, "text": " the rate of area change is the derivative of determinant of a, and the area is of course", "tokens": [51156, 264, 3314, 295, 1859, 1319, 307, 264, 13760, 295, 41296, 295, 257, 11, 293, 264, 1859, 307, 295, 1164, 51512], "temperature": 0.0, "avg_logprob": -0.066070556640625, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.001548680942505598}, {"id": 155, "seek": 118616, "start": 1186.72, "end": 1194.0, "text": " just the determinant of a itself. So, if we rearrange this, then we have something that", "tokens": [50392, 445, 264, 41296, 295, 257, 2564, 13, 407, 11, 498, 321, 39568, 341, 11, 550, 321, 362, 746, 300, 50756], "temperature": 0.0, "avg_logprob": -0.08710636562771268, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0005033219931647182}, {"id": 156, "seek": 118616, "start": 1194.0, "end": 1201.52, "text": " really looks like the Tobi formula. The problem now is, what is m? What is the matrix m that", "tokens": [50756, 534, 1542, 411, 264, 314, 19293, 8513, 13, 440, 1154, 586, 307, 11, 437, 307, 275, 30, 708, 307, 264, 8141, 275, 300, 51132], "temperature": 0.0, "avg_logprob": -0.08710636562771268, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0005033219931647182}, {"id": 157, "seek": 118616, "start": 1201.52, "end": 1208.88, "text": " generates this vector field? Now, particularly at the points a of t acting on the basis vectors,", "tokens": [51132, 23815, 341, 8062, 2519, 30, 823, 11, 4098, 412, 264, 2793, 257, 295, 256, 6577, 322, 264, 5143, 18875, 11, 51500], "temperature": 0.0, "avg_logprob": -0.08710636562771268, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0005033219931647182}, {"id": 158, "seek": 118616, "start": 1208.88, "end": 1215.52, "text": " we know what the vectors attached should be. To go from the position vectors to the attached", "tokens": [51500, 321, 458, 437, 264, 18875, 8570, 820, 312, 13, 1407, 352, 490, 264, 2535, 18875, 281, 264, 8570, 51832], "temperature": 0.0, "avg_logprob": -0.08710636562771268, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.0005033219931647182}, {"id": 159, "seek": 121552, "start": 1215.52, "end": 1224.24, "text": " vectors, we can simply apply a prime a inverse on the position vectors. So, the matrix m we are", "tokens": [50364, 18875, 11, 321, 393, 2935, 3079, 257, 5835, 257, 17340, 322, 264, 2535, 18875, 13, 407, 11, 264, 8141, 275, 321, 366, 50800], "temperature": 0.0, "avg_logprob": -0.06654192696154958, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0006262976094149053}, {"id": 160, "seek": 121552, "start": 1224.24, "end": 1232.8799999999999, "text": " looking for is a prime a inverse. If we go back to what we have obtained previously about derivative", "tokens": [50800, 1237, 337, 307, 257, 5835, 257, 17340, 13, 759, 321, 352, 646, 281, 437, 321, 362, 14879, 8046, 466, 13760, 51232], "temperature": 0.0, "avg_logprob": -0.06654192696154958, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0006262976094149053}, {"id": 161, "seek": 121552, "start": 1232.8799999999999, "end": 1242.24, "text": " of determinant, we simply substitute the matrix m to be a prime a inverse. This is almost the same", "tokens": [51232, 295, 41296, 11, 321, 2935, 15802, 264, 8141, 275, 281, 312, 257, 5835, 257, 17340, 13, 639, 307, 1920, 264, 912, 51700], "temperature": 0.0, "avg_logprob": -0.06654192696154958, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0006262976094149053}, {"id": 162, "seek": 124224, "start": 1242.24, "end": 1248.88, "text": " as Jacobi's formula, just that the matrix in the trace has the other order in multiplication,", "tokens": [50364, 382, 14117, 72, 311, 8513, 11, 445, 300, 264, 8141, 294, 264, 13508, 575, 264, 661, 1668, 294, 27290, 11, 50696], "temperature": 0.0, "avg_logprob": -0.10693327138121698, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00116943777538836}, {"id": 163, "seek": 124224, "start": 1249.52, "end": 1256.4, "text": " a inverse before a prime here. Don't worry, there are two approaches here. Either use the", "tokens": [50728, 257, 17340, 949, 257, 5835, 510, 13, 1468, 380, 3292, 11, 456, 366, 732, 11587, 510, 13, 13746, 764, 264, 51072], "temperature": 0.0, "avg_logprob": -0.10693327138121698, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00116943777538836}, {"id": 164, "seek": 124224, "start": 1256.4, "end": 1265.1200000000001, "text": " property we discovered that trace a b equals trace b a for a or b being invertible, or similar to how", "tokens": [51072, 4707, 321, 6941, 300, 13508, 257, 272, 6915, 13508, 272, 257, 337, 257, 420, 272, 885, 33966, 964, 11, 420, 2531, 281, 577, 51508], "temperature": 0.0, "avg_logprob": -0.10693327138121698, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00116943777538836}, {"id": 165, "seek": 126512, "start": 1265.12, "end": 1273.1999999999998, "text": " we dealt with the previous property, we just apply a inverse to the whole picture. In that case,", "tokens": [50364, 321, 15991, 365, 264, 3894, 4707, 11, 321, 445, 3079, 257, 17340, 281, 264, 1379, 3036, 13, 682, 300, 1389, 11, 50768], "temperature": 0.0, "avg_logprob": -0.07090526468613569, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.005384522024542093}, {"id": 166, "seek": 126512, "start": 1273.1999999999998, "end": 1281.04, "text": " the corners of the parallelogram go back to the standard places 1 0 and 0 1, but the vectors", "tokens": [50768, 264, 12413, 295, 264, 8952, 12820, 352, 646, 281, 264, 3832, 3190, 502, 1958, 293, 1958, 502, 11, 457, 264, 18875, 51160], "temperature": 0.0, "avg_logprob": -0.07090526468613569, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.005384522024542093}, {"id": 167, "seek": 126512, "start": 1281.04, "end": 1289.1999999999998, "text": " attached to these places are a inverse a prime acting on the basis vectors. This is because", "tokens": [51160, 8570, 281, 613, 3190, 366, 257, 17340, 257, 5835, 6577, 322, 264, 5143, 18875, 13, 639, 307, 570, 51568], "temperature": 0.0, "avg_logprob": -0.07090526468613569, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.005384522024542093}, {"id": 168, "seek": 128920, "start": 1289.2, "end": 1296.48, "text": " previously they were just a prime acting on them, but we have applied a inverse to the whole picture.", "tokens": [50364, 8046, 436, 645, 445, 257, 5835, 6577, 322, 552, 11, 457, 321, 362, 6456, 257, 17340, 281, 264, 1379, 3036, 13, 50728], "temperature": 0.0, "avg_logprob": -0.07524069330909035, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.0013669723412021995}, {"id": 169, "seek": 128920, "start": 1297.28, "end": 1305.2, "text": " This means that the matrix generating the vector field would be a inverse a prime, and the matrix", "tokens": [50768, 639, 1355, 300, 264, 8141, 17746, 264, 8062, 2519, 576, 312, 257, 17340, 257, 5835, 11, 293, 264, 8141, 51164], "temperature": 0.0, "avg_logprob": -0.07524069330909035, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.0013669723412021995}, {"id": 170, "seek": 128920, "start": 1305.2, "end": 1312.48, "text": " m to be put into the formula that we derived previously would be a inverse a prime. And", "tokens": [51164, 275, 281, 312, 829, 666, 264, 8513, 300, 321, 18949, 8046, 576, 312, 257, 17340, 257, 5835, 13, 400, 51528], "temperature": 0.0, "avg_logprob": -0.07524069330909035, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.0013669723412021995}, {"id": 171, "seek": 128920, "start": 1312.48, "end": 1319.04, "text": " this is exactly the Jacobi's formula where the matrices in the trace are in the right order.", "tokens": [51528, 341, 307, 2293, 264, 14117, 72, 311, 8513, 689, 264, 32284, 294, 264, 13508, 366, 294, 264, 558, 1668, 13, 51856], "temperature": 0.0, "avg_logprob": -0.07524069330909035, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.0013669723412021995}, {"id": 172, "seek": 131920, "start": 1319.52, "end": 1328.24, "text": " a inverse a prime. So this is the Jacobi's formula derived in the case when a is invertible. We are", "tokens": [50380, 257, 17340, 257, 5835, 13, 407, 341, 307, 264, 14117, 72, 311, 8513, 18949, 294, 264, 1389, 562, 257, 307, 33966, 964, 13, 492, 366, 50816], "temperature": 0.0, "avg_logprob": -0.07736862407011144, "compression_ratio": 1.5326086956521738, "no_speech_prob": 0.0003250238369219005}, {"id": 173, "seek": 131920, "start": 1328.24, "end": 1336.0, "text": " able to derive and understand many properties of trace visually by thinking of trace as divergence,", "tokens": [50816, 1075, 281, 28446, 293, 1223, 867, 7221, 295, 13508, 19622, 538, 1953, 295, 13508, 382, 47387, 11, 51204], "temperature": 0.0, "avg_logprob": -0.07736862407011144, "compression_ratio": 1.5326086956521738, "no_speech_prob": 0.0003250238369219005}, {"id": 174, "seek": 131920, "start": 1336.0, "end": 1342.88, "text": " or the rate of area change per area, when the area evolves along the vector field.", "tokens": [51204, 420, 264, 3314, 295, 1859, 1319, 680, 1859, 11, 562, 264, 1859, 43737, 2051, 264, 8062, 2519, 13, 51548], "temperature": 0.0, "avg_logprob": -0.07736862407011144, "compression_ratio": 1.5326086956521738, "no_speech_prob": 0.0003250238369219005}, {"id": 175, "seek": 134288, "start": 1343.6000000000001, "end": 1347.5200000000002, "text": " As always, thanks for the patrons and please like,", "tokens": [50400, 1018, 1009, 11, 3231, 337, 264, 27559, 293, 1767, 411, 11, 50596], "temperature": 0.0, "avg_logprob": -0.268324077129364, "compression_ratio": 1.196078431372549, "no_speech_prob": 0.05495885759592056}, {"id": 176, "seek": 134288, "start": 1347.5200000000002, "end": 1360.24, "text": " subscribe, comment so that more people can watch it. See you next time.", "tokens": [50596, 3022, 11, 2871, 370, 300, 544, 561, 393, 1159, 309, 13, 3008, 291, 958, 565, 13, 51232], "temperature": 0.0, "avg_logprob": -0.268324077129364, "compression_ratio": 1.196078431372549, "no_speech_prob": 0.05495885759592056}], "language": "en"}