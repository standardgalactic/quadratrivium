{"text": " Hello, I'm Gary Burke, a co-chair for this summit 2023 ontology summit, and it's March 8th, 2023. And we are going to be doing our second phase of our ontology summit, moving into things like ontology design patterns, wiki data, and things of that nature. First, I should say that the schedule speaker was called away on a project that he had to attend that has made a video recording. And so we were going to be playing a 35 minute or so video recording later in the session. But first, I'm going to do a few introductory slides, overviewing this part of this summit. So with that, let me turn to slide share here, screen share, and show you my first slide. So this has a working schedule for the second part of the summit, starting with modules and patterns with Kogen Shimizu from Wright State. He'll introduce himself in detail. And it shows that some of the other sessions that we have, basically things are nailed down now. So next week, we will have a design pad in discussion. So to follow up to this session, we'd call Hammer, who's now at Google, had been at IBM. We have invited some of the original people, such as Valentina Pursutit, to present, but we never heard back from her. So we had call stepping up to do that. Following that, we're going to have a session on Wikidata. I'll have a little bit more to say about that probably next week. And you can see the remaining schedule here leading up to a panel, which we still are filling in, but Pascal Hitzler will be one of the main speakers on that. So with that, let me turn to today's session. And I thought I would introduce a little bit of the topic on ontology design patterns and modular ontologies before we go to the video. So this is an example of a widely used pattern, actually that I was a bit involved with, which is called semantic trajectory, which you see on the left. And you can get an idea about what ontology design patterns are. So we have a range of concepts here. What is a semantic trajectory? How do you define it? Well, first we define it in terms of having segments that go from and to places where we do a fix, that is, we take a sensory measure. And this segment is traversed by some type of conceptually moving object. Most of the time we're thinking of a real physical object, but it may be a conceptual object. So it may be something like a disease that is essentially having a course of action over time. And we're taking measurements under disease over time. And we have a source for the, and a sensor type and a location for the fix. You'll notice that most of the boxes have a solid line. Gary. Yes, Gary. Can you go into presentation mode? Let's see if I can do that. Do you want me to go into slide mode here? Yeah, make it easier to read. How does that help a little bit? Thank you. No, not so far. All right. I'm going to go on here. My next slide tries to illustrate the range of things you might see in ODPs, ontology design patterns. On the left, you see a rather complex pattern. Actually, this is an early version dealing with sensors, the sensing things, sensing features of interest. There's actually several patterns probably composed in this, and this particular pattern, the semantic sensor network pattern, for example, has evolved over time and improved on. Slides are changing, Gary. Your slides are not changing. You don't see two ODP examples on the screen? No. You are on the first slide. Okay. I'm talking about the second slide. No, we don't see. Oh, second slide. Yeah. You do see it? Yes. Okay. But it would help if you would. Did you still see the second slide with two ODPs? There's one diagram. Okay. Well, there's two things on it. On the left side is a complex one. On the right side is a very simple pattern for transitions. We don't see that. You don't see that. Gary, I think you are sharing the original window of the thing and not what you are seeing. You want to share your screen, not an individual application? There we go. There you go. Yes. Okay. I was asked to change your mode. Do you see the two patterns now? Yes. So, again, to complete this is the complex one on the left, which is dealing with sensors information and the very simple idea of what is a transition and transition of an event has a starting time. It's a setting for a thing and it has a final state. So, transitions from a start to an end. Very, very simple design. Okay. Can you see a new slide now? Why ODPs? Yes. Okay. Fine. Okay. So, I wanted to provide a little rationale for some of the things that go into using ODPs. The original idea was that it was difficult to understand and get an overview of very large ontologies as they were growing. It was also difficult to see the effects of a change or an extension in some concepts. So, what impact it would have? And also, another thing that was said is that it's often very hard to get full agreement on all the commitments on a large ontology. And for these reasons and other reasons such as interoperability problems and alignment problems, understandability problems, people decided to look at these trade-offs and maybe it would be better to start with something smaller like some of the patterns that I showed you before. Here's a little bit more on some of this reasoning about what ontology patterns might be like. They reflect, of course, the need to capture the reality that is in data, common to patterns. Often, the patterns in data are hard to find, but if we can spend some time looking at that, we can sort of abstract some of those patterns from the data itself as opposed to a pre-developed top-level ontology. I have a quote here, roughly a quote here from Verna Kuhn early on in the era when patterns were starting to be used. For solving semantic problems, it may be more productive to agree on minimal requirements imposed on small notions like a pattern notion. So, the idea was to use small and well-engineered, coherent, minimally constrained schemas as a start for ontology that later could be combined, as I showed you with the semantic sensor net, where you might can be combining several different patterns. You can use very good documentation and design rationalities and best engineering practice for reuse over time, so you can prove things like the semantic sensor network over time. So, for all these reasons, people did try out going to modular patterns. And as they did, and roughly about 12 years ago or so, Gangamy and Presuti, who I invited to a session but haven't heard back, wrote some documentation on modular operations and just talked about five basic types of operations when reusing them and building them. So, the first is, of course, importing them, and you can use import functionality to do that into whatever you're trying to do. You can also specialize, two types of specialization. You can take an existing idea and specialize it conceptually and then go from there. Or you can have a specialization done by creating subclasses and subproperties on existing ODP classes and properties. You can also generalize an ODP in the concepts in them. And one of the most complex things, and you saw a little bit of this in the semantic sensor net, the early version, is composition, where you use multiple ODPs, small pieces, and try to compose them in a meaningful way, fitting them together. And the last one, of course, here is the idea of, well, you may not find an idea in a particular pattern that you want to use, and you might have to develop new patterns for that. And here is an example of just such a thing of an expansion. I showed you that semantic trajectory before. Here we have a portion of that trajectory on the right, but you're sort of extending it and combining it with other things, so that a particular project that NSF funded called the Geolink Projects used the trajectory for scientific expeditions. And so they had to, they specialized the idea of what is traversing the segment to a vessel that might be going on a cruise. And they also added other ideas on that, such as the data was gathered and put it into a repository, things of that nature. So this is just a small example of how patterns get built and get reused. And we'll hear more about that from Kogan and also next week from Kahl. My last slide is just a few sources on that. This is the reference to that semantic trajectory, for example. This is a tutorial sort of on how you combine patterns, make good patterns. This is something on how you document patterns and so forth. So with that, let me stop the share and let me turn the session back over to Ken, who will hopefully start the Kogan's video, which runs about 34 minutes or so, which will leave us with a little bit of time for Q&A, although he's not here this time. He promised to come back next time when call presents, he'll be available questions and answers. So if we have an important ones, we have an address here, you may be able to do it then. So this is the recording. Hopefully you'll be able to hear the sound, but it's quite redundant. You'll notice that the transcript is on the right. And you'll also see the transcript on the screen as he's speaking. Hello, everyone. Welcome to my talk. Today, I'm going to be providing a introduction to patterns and modules. And by this, I really mean patterns and modules as they exist outside of the traditional sort of formal ontology perspective. So I'm not looking at the modules and the patterns as they exist inside of say, for example, Dolce or BFO or any of the other upper fundamental foundational reference ontologies, but instead coming at this from more of the empirical data-driven side of things. We'll go over briefly the methodology and some of the resources. So very briefly, my name's Kogan Shimizu. I'm an assistant professor over at Wright State University in Dayton, Ohio. Some of you have already spoken with me at previous talks and some of you have just known me for years already. But regardless, I'm happy to be here and talk a little bit about what I'm interested in, and then also the point of the talk. So a little bit more about me is that I'm broadly interested in knowledge engineering. And I mean this from the full perspective or the full spectrum from just basic knowledge representation from any, from low expressivities of taxonomies, controlled vocabularies all way to full-blown owl ontologies. But this also encompasses some of the deployment aspects and how our knowledge graphs and these knowledge bases use. And that's a lot of where this pattern-based methodology comes from is it's not just about patterns and the knowledge, but also patterns of usage and how you can really simplify how knowledge graphs and the constituent knowledge is really utilized. And then of course the the next two things are just kind of employing knowledge engineering to do more effective open science and more effective teaching of this material. So kind of looking at knowledge engineering from the perspective of knowledge engineering in order to be a more effective teacher. But I digress by now. So without further ado, let's take a look at the rest of our talk today. There are four main pieces that we're going to dig into and I'll give briefly an motivation and then we'll again briefly kind of go over the modular ontology modeling methodology or MOMO. And then I have a few examples of what patterns look like and kind of some connections to some previous pattern work that we've seen in previous talks here. And then we'll close with some tools and resources. So the first example that I have is called the nowhere graph. The nowhere graph is a NSF-funded consortium. And I don't mean that in a more formal sense. There is no NSF consortium in this case. By this I just mean that there's a pretty huge team. I think it's over 50 collaborators at this point and that spans from all of the student researchers to the investigators, the collaborators from NGOs and private industry and government agencies. It's pretty quite expansive and with high coverage. We have a whole bunch of different data sets that come from that are contributed by the different collaborators or we're pulling them from publicly available websites and we're integrating them all and trying to provide a geospatial backbone so that way the representation of spatial integration is pre-done. We're front-loading the cost of doing the spatial integration and this came with some pretty tricky and interesting problems with how to adequately express these spatial relations and also ensure that we have provenance from all of the different data sets and all of the different features and do the semantic harmonization. And it turns out that we did wind up using a modular knowledge graph in order to do this. So this is what the schema looked like back in July of 2021 and into 2022 I believe. And each one of these little tiny boxes that you can see here are a module. We have an expertise module, we have a hazard module, we have different modules for the different data sets so climate division, soil types, storm observations, smoke plumes, things that impact the world around us by some physical phenomena and is also of interest enough that the government at a state or federal level is tracking them and providing data sets about them. And so what we did is we identified a kind of pattern that exists in this observations and it's drawn from the SOSA SSN, the sensors observations sampling actuators ontology from the semantic sensor network and kind of extracting a core piece of that and using that as a sort of template to mint new patterns which kind of turn into these modules and so on. And this strategy I think as both Nick and Chris have said in previous talks is really effective for rapidly expanding additional coverage for a domain without really having to know the ontology in and out. There's some clear connection points to these strategies. And so what this results in is as of November of 2022 is this much larger schema and I don't think this is everything either. And it's also hardly readable because it doesn't fit on the screen. It's kind of an interesting sort of catch 22. It's cool that we've been able to integrate all of these different data sets but now it doesn't fit on the slide so we can't really show it off. But anyway the evolution and maintenance of the graph comes from these patterns and these modules and being able to rapidly replace a module or add in a new module based on an older module or the same pattern is really instrumental. And we'll kind of go into this in a few slides. Another example that we have is the enslaved hub ontology. So the enslaved hub is a smaller but no less important knowledge graph. It's really about identifying, integrating and really making visible the stories of the peoples of the historical slave trade. So trying to find how a particular person might have traveled from place to place largely against their will and with different names and different personal relationships and trying to identify what actually is the ground truth because that's one of the hard things here is that integrating all of these little tiny data sets from historians across the nation and around the world even you have different interpretations of the events that occur or different interpretations of the first source, the first hand sources. And this resulted also in a modular knowledge graph. Otherwise we wouldn't be presenting it in this particular presentation. But the point is that having a way of modeling the different types of characteristics of the peoples of the historical slave trade as well as this sort of integration of the data sets is really valuable and really makes it easy to apply a pattern based method towards it. This I will not get into so much with the rest of the presentation, but if you have any questions or you want to see the schema you can go to enslave.org or if you have any questions my email is at the end of the presentation and you can go ahead and pass on questions and I'll either answer them or send them on to the team. So anyway let's go ahead and dig a little bit more into modular ontology modeling. So one of the things that I didn't really talk about is what is the difference between a knowledge graph and an ontology. And in this case we don't really mean them to be too differently except for in this case an ontology is really just the T-box of the ontology. And then we consider the knowledge graph to be the A-box coupled with the ontology which acts as a schema for the knowledge graph. Really it's just changing the different buzzwords around in order to make sure that the work is fundable sometimes or a little bit more relatable to to a broader audience. And in this case what we mean with pattern mediated methods for knowledge engineering and including these patterns is really including and using patterns as a first order or first class citizen within the modeling paradigm. So making sure that the modular ontology is directly represented using annotations and this is what really drives the ability to expand the the ontology or the knowledge graph schema based on the existing patterns within the ontology or to yank out and say we'll we don't want this one anymore let's go ahead and replace it with this new one and then finding all of the pertinent axioms and underlying instances for those for those classes is quite valuable. And so what we have here on this slide is what we call the modularity which is the patterns made out of sorry the schemas made out of patterns and then on the right hand side we have the metadata scaffolding and so this is really the the the catchy way of saying well we're just going to annotate the schema with additional information that indicates what pattern or module particular classes within the ontology belong to. So with this in mind the metadata scaffolding can really be thought of as the sort of ladder right you have a conceptual component which is an extremely human centric term which might be implemented in a number of different ways. For example space and time are great examples of this because there's so many different ways of modeling space right that we can each say that each ways of those modeling spaces is is kind of pattern is kind of like a pattern and so a spatial extent would be the conceptual component it would be represented by some set of patterns and then you choose a pattern and you turn it into something that's more apt for your use case and we call that a module. And then you have the instances of the modules which are really just the shapes of the data the actual triples or the materializations of the the data that the model module models. We use a a language called opala or opal which is the better way of of kind of turning the the acronym into into a human word which is just the ODP representation language. So OP and then A from pattern and then L. What I have here on the right is an in-progress draft of the version two of opal and what we are trying to do here is to include even more information about what is actually going on inside of the pattern. Axioms tend to follow patterns especially within the MOMO methodology but there's also different ways of thinking about patterns in terms of the representation so you can have a perspective which is really just an extremely simplified view of maybe a more expressive version of a pattern. You have documentation that's associated with it so the the pattern will have a schema diagram and all of the different ways that you want to represent a pattern we're trying to codify into the into this model. There is an additional there's a base opala or opal which was published in 2016 from a number of people from the the community and we are kind of generating a new specification currently. So modular ontology modeling now let's take a look at the actual methodology it's it's nine steps. We want to focus as I said largely on the empirical data-driven reality which means that we're not necessarily always concerned with the philosophical ramifications as we are with what can we model and what data is readily available or important to the use case at hand. So you start with designing the use case with however whichever methodology that you want with use case generation and this can you can draw from any number of knowledge elicitation frameworks. What we find to be particularly important and we call out here is the use of competency questions. I don't think this is particularly new to the ontology modeling community but it really helps you identify what the key notions are but also the interactions with the data and this is really where the the empirical or data-driven reality aspect comes in because if you can't really in natural language ask a question about it then what to what extent is it useful to model beyond that. There's probably some fighting words in that statement but at this top level sort of of this address here we can sort of gloss over that for now. The the the interesting parts now are in steps four five and six which are really kind of what differentiate MOMO from other methodologies and that's really once you have the key notions for your use case which are extracted from your data, your competency questions, your domain experts, what have you. You want to match those the conceptual components that patterns model. We have resources that I'll display later on in the presentation about sorry about of all of the different patterns that we have and can be used to sort of plug and play a schema together. The instantiation of the patterns is comes what comes next and that's really replacing the terms and properties of a pattern wholesale kind of like a template starting with maybe like madlib style. You're not subclassing a pattern you're just using the structure of the pattern over and over again. In step six we have the systematic axiomatization which is once you have your patterns and you look at the schema diagram for your different modules and your different patterns is you go edge by edge within your schema diagram and you assign the ontological meaning of what that top level intuitive conceptual relationship is. I won't get into that so much within this talk but what we have here is the modular ontology modeling published in the semantic web journal and you should be able to kind of get a lot more information on the exact processes within this methodology from there. After that you plug all of the modules together with quite literally like puzzle pieces you review the final product add any more axioms that you think are useful across the entire assembled schema and then you produce your owl artifact. So that was really Momo in a nutshell. So what I have here are a few examples three actually I think and then a brief discussion on the template based instantiation that we utilize for Momo and how it kind of connects or is quite obviously parallel to the sort of DOSP strategy employed within the oboe community. So this first pattern that we have here is a pattern for depicting causal relationships between events this is something that came out of the nowhere graph project actually the next two patterns are as well but I kind of want to show you here how you have a pattern and then you also have a module within the pattern right this abstract event compared to this events this concrete notion of event event for those of you who are familiar with the upper ontology sphere this would probably be easily modeled as your sort of perjure and endurance thing because you have a description in a situation you have this thing that exists in time and thing that exists out of time but from a pattern perspective the exact implementation of this doesn't matter and that's kind of the point you can implement this pattern using an upper ontology or you could call it whatever you want like event concrete which is maybe not a great name but kind of gets the point across. These blue boxes with the dashed lines are what we call the interfaces I said earlier conceptual components but you can kind of think of them as interfaces from software engineering because they are an implementation they are a hook within this pattern that says right here belongs anything that is a model of what an observation is or anything here can be fulfilled by something that sort of adheres to the contract of what a spatiotemporal extent is and we just note that with with the blue box and so you can replace that blue box with an entire new pattern or you can kind of just drop it away and have it something very simplistic like a stub and so on and so this is how we do that and this is also what allows it to kind of for people to kind of conceptualize these as puzzle pieces because you take your spatiotemporal extent pattern you plug it in quite literally like a puzzle piece into the spatiotemporal interface within the schema diagram and then you just build out your patterns and you modify them to your use case and then you're done right that's kind of the strength of what we're trying to do here is by leveraging these patterns and the fact that all of the ontological analysis has already been done it's really just the assembly and configuration for your use case that drives the the usefulness of this okay I accidentally reordered these sorry for flipping through a few slides there this is another example here of of a pattern we have two interfaces this time but now actually what we have here is this purple box which is really just a controlled vocabulary it's this it's it's just another sort of um technicolor idiosyncrasy for our um presentation or our schema diagram presentation and it's really just saying that the the class of organization scheme consists of strictly a set number of individuals not particularly exciting but it's something that we can model and is sometimes extremely convenient to to model even at the pattern level and then doing it explicitly like this instead of having a subsumption hierarchy somewhere in the background it means that there's really no change to the ontology when you add in a new instance for example here of the organization scheme in this case you would replace custom with whatever you want because custom kind of doesn't belong in the in the in the pattern here um keep moving on uh so this final pattern example that we have here this is a pattern for depicting features of s2 cells or any cell in a hierarchical grid so let me back up there a little bit what we have are these cells um and the cell is really just a geometry a tessellated geometry across the surface of the earth or any body really but in this case let's let's just stick with the earth and then what you have is these cells are hierarchical so four cells make up the next tessellated geometry and it just up and up and up and so s2 um is one particular version of this and that's employed by google and it's really just um four cells make up the next larger cell and then four of those make up there and um there's also a way to do this using hexagons that's called h3 using it out of uber but really what um what's interesting about this are these red arrows i mentioned earlier that sometimes it's useful to have these shortcuts within a pattern a simplified view right so when you have a cell and you want to represent it uh using geosparcle or um using some sort of uh geo informational science standard way you disconnect the cell as a concept from its geometry uh which is the literal that describes the sort of boundary points of the cell and then the spatial relations actually occur between the geometries not technically between the cells however when you're querying generally you want to know how the things are spatially related at a human level and not just these arbitrary geometries that exist um under the hood and so having a way to specifically represent these within the schema diagram useful but also logically under the hood um as a sort of roll chain is also is also useful uh and we use the opal annotations for the different um excuse me for the different shortcuts to say well this is this one's optional you don't have to actually materialize this because it's it's part of the pattern but only in so far that you may want to simplify this for for other other people um so for example going from cells the attribute of the particular feature that simplifies three hops with an inverse in there into one simple thing uh but you lose a lot of the expressiveness um and uh the ontological pitchness there so there's there are some tradeoffs uh finally um as one of our examples this here on the left is the kwg core ontology um and the sosa ssn kernel that we use uh the core is really just the four main concepts that we have and some very basic relationships it's obviously much more built out within the ontology uh itself but from a schema diagrammatic um and also from this nice compact view it's useful to only include a couple of these pieces um but it connects into this kernel and then this kernel um the sosa ssn kernel this pattern that we've extracted essentially from that ontology we just essentially mint um or not mint we stamp over and over again one per data set uh how this connects right so the feature of interest remains the same uh because it's the superclass but this observation that we have here within the kernel um i actually done to lead you the arrow to the wrong thing it should be to the climate observation and the observation and then you have the climate observable property and the observable property right this is not a particularly exciting implement or instantiation of the sosa ssn kernel template but you can see how um after you've kind of changed the names to be um more tailored to your particular sub use case right represent a us climate division and its climate observations um there's all of this additional stuff that's now hung off of it right we use has simple result instead of has result the observation has a phenomenon time and then we go out and we say okay at least with this particular diagram we say that there's hidden or additional complexity um which would be implemented by another pattern or another module elsewhere for spatial object or temporal entity all right so we're going to go ahead and start wrapping up i have a few things for the tools and resources and then we'll uh we'll end with um my slide for passing on any questions to me so the the the cool the the cool one and this is really a self insert here uh is called model uh the modular ontology design library which is a collection of curated patterns uh so on the next slide we have the ontology design patterns portal uh this is a huge collection of patterns of varying quality because it contains uh submissions of patterns which were peer reviewed but were rejected but never removed from the portal or they have wildly different sorts of uh constraints on them ontological commitments that make them very tailored to a specific use case and you would wonder whether or not they can really be called a pattern right so what we did is we took out the patterns that we thought were maximally useful um and uh polished them up new schema diagrams made sure that the axioms were consistent gave in some examples uh and and kind of organized them by category and then we described all of them using opal right so model is actually an annotation ontology of all of the different uh patterns um this what here on the right is 13 patterns in version one uh i am working on a second version which contains 32 some of them are redundant in so far that they are alternative patterns for the same conceptual component or the same interface right a couple of different spatial extent patterns a couple of different event patterns um a couple of different role patterns and and so on um and then uh model is not just an artifact it is meant to be a template model is a type of ontological collection which is a collection of patterns um i call mine model because i suppose that's my prerogative but it could be any um anybody could make a model uh finally i think i already said this is that the model encodes many inter pattern relationships so it has uh what interfaces it provides and then conversely what interface it implements what conceptual component in implements what are the different specializations and generalizations between the uh patterns and what category do they belong to uh we already talked about the portal so i'll move on what i have here is called commodity uh the comprehensive modular ontology integrated development environment quite a mouthful commodity is a plugin for protochet um i wrote this as part of my phd dissertation so it functions but it is not like production quality you know it it's something to use and um to uh leverage but you might run into a bug here there if you do uh let me know and i'll try my best to address it or help out but essentially what this does is it provides a graphical canvas uh to do modeling with all of the power of our and the coup de grace so to speak would be the uh pattern library which is the number two you can actually drag and drop all of the patterns from model directly onto the graphical canvas and it will connect them based on those uh interface points that we talked about uh and then you can also uh customize the sort of semantics that the edge um edges will generate uh what do i have here so here's a a quick example of what this looks like um oh that was wrong let me try that again uh so what you can see here is the the dragging and the dropping directly onto the thing uh it will draw the module around it um when you draw drag sorry drag the next one over it'll connect it on the obvious touch points um and then you can rename stuff and drag and drop and add your own classes and so on i'm not going to go back because this seems to be fighting me on this so thank you very much for attending this talk i'm so sorry that i couldn't be there today uh please forward any questions to me um at my email uh or go ahead and pass them on to gary and he could do this i will also be here next week um right after carl's talk uh which will have a lot of overlap with the sort of design process and we can talk there um or i can answer any questions that you might have again thank you so much and have a great day i guess i'll verbally thank kogan for this and we'll see him next week we now have about 12 to 15 minutes for discussion including questions and answers of course kogan not being here there may be limitations on what we're able to say but uh maybe we can have some discussion among ourselves here so with that i'm looking for hands raised here and uh i know there was a small amount of chat in our other uh online chat yes james you're commuted but here we go uh thanks gary and i appreciate that kogan was able to present even though he wasn't able to present so much appreciated uh it did have a bit of a hard time connecting this step up to what i do day to day when i do things that i call design patterns or usually focused on templates and csv files or tsv files that get expanded into some set of al-axioms that define a class uh but i guess my question was so i am aware that there's this larger literature about ontology design patterns that i'm not super familiar with uh i guess my my general question is how well this talk lines up with kind of the larger literature on these things uh i don't know maybe that's a question for gary but other people could uh could chime in is there like a single notion of ontology design pattern and kogan was expressing it or is it a more diverse kind of field topic keyword well it's an interesting question i'm not sure i can be definitive i have opinions of course and i am not necessarily as up to date on all the literature uh if there's somebody out here attending who who feels they are they can certainly speak up kogan mentioned setting up sort of a new a new repository uh for curated design patterns and this reflects the fact that that people have been building design patterns and posting them and uh the idea is for them to have good documentation to reuse practice to make connections to other uh design patterns and maybe upper levels and a lot of that is that is missing you know when we we talk about fairness for ontology we sometimes find that they lack some of the ingredients of fairness and so that is has been true for odps uh over time but like the the the foundry uh there's a sub community here of people like like uh pascal and kogan and uh the people involved with the nowhere where graph we're trying to pull some of this together and and provide more of a community where there are higher standards existing practices so i'd say again that maybe it isn't it isn't as large a community and maybe hasn't been uh as well funded uh as things in the biomedical field but this is an attempt to sort of do something of that level quality and i myself am very much interested in how these two communities can sort of share and cooperate i mentioned the semantic trajectory as being able to be applied to a course of disease but i'm not sure anybody has done that i'm not sure that anybody has looked at what's common about these patterns and how to how to take uh a a dead simple pattern from oboe and sort of put it in uh and compose with it along with uh odps from the other communities that would be an interesting thing to look at it and might be an interesting research article for us to consider so hopefully i've given people enough time to know maybe more about this and have things to say i just wanted to laugh at your bit about being well funded because we don't think of ourselves as well funded and being on the side of tooling side of things but we think of ourselves as stealing uh time and money to build these tools but maybe you're right a lot could be said about that it's a relative question of course and the continuity is such is very important where things get started in the question so the geolink pattern that i sort of identified came out of or built on a semantic trajectory but they didn't necessarily continue to fund more of that for other types of expeditions and things like that so some of the concepts can be reused but necessarily the projects have a you know a three year five year type of extent and and one's uncertain about the other side that's true we often have longer time frames than that you know oboe but not always thanks okay um i see something in chat so i'll just read that in addition to what james asked what ontology projects do you know and hopefully it's the community rather than just me uh use ontology design pads for practical practically during during development um again that that's a much better question to ask of both kogan and uh call uh so let's keep that question i do know that there have been studies which looked at the relative of quality of ontologies built by reusing patterns or not and unfortunately at the time of the publication i know of it wasn't great it wasn't uh a big help at that time but again things have moved along since some of those earlier studies ashaya you have your hand up yeah so maybe i just ask a clarification questions in his talk does he mean that uh the design pattern we can use no matter what top ontology that we are using and another one is so the my understanding is that the design pattern if as logo so they are not necessarily map kind of have the same using same block like but they can still connect to each other is that correct understanding yeah i can i can maybe address part of that which is the interoperability question with upper level ontologies so you notice that some of them had these stubs with the dotted lines and has he's he said i i don't remember his exact words the idea is you can plug in different things at this particular point some of them may be entire patterns some of them may be a very simple concept and so forth so the idea is that the the core of the pattern below the dotted line is gets reused and it's in common so that you can you can ask some questions across it because there's a common element a little bit like what cob is doing right cob is providing that core that other people can tap into but yes there will be variations depending on whether you tap into dulce at the top or you tap into oboe so or bfo i should say so it allows sort of some commonality and some flexibility it's a compromise there maybe somebody else has some other wisdom to add to that or or real wisdom to add to that well it design pattern each design pattern will have certain requirements for it to be applicable and that could make it impossible to use in certain with certain upper ontologies so it's but i to what extent do these design patterns have those requirements explicitly stated so this is very much a bottom up effort at times coming from what the data is saying to reflect the reality of the data as opposed to a more abstract concept above and so as long as you have common questions that can answer with the data can answer real things of interest to a domain that they feel that's that's viable now there could be of course these different philosophical distinctions at the top level the question is whether you have common questions that sort of tap into that at all they may it may not for practical purposes yeah again this is a question this is a deeper question that people who are like kogan and caulk and probably provide a better follow-up there is a there's a workshop on ontology design and patterns it's WOP it's WOP regularly WOP is an annual event and you can see that some of the people in there online the past ones are online and you can look at the at the press the papers i often do i was part of the review panel here who are active in that community who might have some comments yes we have a few minutes left so let's hear from people with different experiences on this or different ideas on this you don't have to be shy because you've heard me talk about it yeah obviously people will know more than that yeah so hello i'm chris hello chris so i was one of the co-organizers of the last rendition of the workshop on ontology design patterns so if there's anything in particular you would like me to comment on now i'm unhappy too so we may have questions what were some of the patterns about from the last or the issues at that i didn't attend right so there there were patterns from different domains one of which was particularly interesting to me which was about the design of scientific taxonomies now i don't know the details anymore because i haven't reviewed the actual pattern but each year there are a number of patterns that get published and one interesting point to notice here is that the patterns that get published are not always following the same structure so there are different ideas of what what a design pattern should consist of and also how a design pattern is supposed to be reused and this is also one of the key notions in which i personally think that the notion of the software design patterns differs from the notion of a ontology design pattern so when we talk about a software design pattern these patterns are often thought as language agnostic so they provide us with a solution that could be adopted in different languages whereas these ontology design patterns they are often tailored to a specific knowledge representation language so that it can be reused in that particular formula and that is one of the key differences that often get confused between these two different notions thank you that's a good although i do know in in his what 10 points that the less that is to produce the owl artifacts so up until then there's some degree of conceptualization more abstraction right right so um there have been different proposals for how a design pattern is supposed to be reported and one of these proposals includes this 10-step or 12-step process where you have to um list all the requirements for a particular use case and all the ways in which a pattern can be reused but that is not standardized in any way so there are different proposals of how this could be achieved and this is just one of them so again i have tried to actually empirically look at how patterns are reused and so far it doesn't seem to be the case that there are there's a standard notion of either the reuse of design pattern or standard design patterns that were used consistently throughout ontology so this is still a open question that that's a challenging observation that we want to sort of repeat next week so i hope you'll be back for that and ask again because i i agree that you know this is an we're empiricists here so we want to know what really works where things are and so forth and what can be re really reused so we we have looked at modl model they're they're curated the repository for ontologies for odp's anybody else looked at that oh right here the importance of building up a library we've got a hand raised oh okay i missed it maybe it's on the other screen oh unfortunately disappeared they have to go so hopefully they we can continue this next week yeah yes indeed and so call hammer who's now at google has been very involved in these things continually and has done a lot of practical development with them and can speak to that and can speak to methods used and since he's went from ibm to google there's probably something he's able has been able to do he may be able to speak at a different degree of abstraction but he has practical experience um so with that i think we can adjourn for today and um and hopefully see you all again next week and tell your friends i hope frisk can make it okay i'm glad to be there thanks everybody i don't know", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.08, "text": " Hello, I'm Gary Burke, a co-chair for this summit 2023 ontology summit, and it's March 8th, 2023.", "tokens": [50364, 2425, 11, 286, 478, 13788, 37396, 11, 257, 598, 12, 17892, 337, 341, 21564, 44377, 6592, 1793, 21564, 11, 293, 309, 311, 6129, 1649, 392, 11, 44377, 13, 51068], "temperature": 0.0, "avg_logprob": -0.3044670880851099, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.09916356205940247}, {"id": 1, "seek": 0, "start": 14.08, "end": 23.68, "text": " And we are going to be doing our second phase of our ontology summit, moving into things like ontology design patterns,", "tokens": [51068, 400, 321, 366, 516, 281, 312, 884, 527, 1150, 5574, 295, 527, 6592, 1793, 21564, 11, 2684, 666, 721, 411, 6592, 1793, 1715, 8294, 11, 51548], "temperature": 0.0, "avg_logprob": -0.3044670880851099, "compression_ratio": 1.4090909090909092, "no_speech_prob": 0.09916356205940247}, {"id": 2, "seek": 2368, "start": 24.0, "end": 32.8, "text": " wiki data, and things of that nature. First, I should say that the schedule speaker was called", "tokens": [50380, 261, 9850, 1412, 11, 293, 721, 295, 300, 3687, 13, 2386, 11, 286, 820, 584, 300, 264, 7567, 8145, 390, 1219, 50820], "temperature": 0.0, "avg_logprob": -0.12683980305989584, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.07253893464803696}, {"id": 3, "seek": 2368, "start": 32.8, "end": 38.4, "text": " away on a project that he had to attend that has made a video recording. And so we were going to be", "tokens": [50820, 1314, 322, 257, 1716, 300, 415, 632, 281, 6888, 300, 575, 1027, 257, 960, 6613, 13, 400, 370, 321, 645, 516, 281, 312, 51100], "temperature": 0.0, "avg_logprob": -0.12683980305989584, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.07253893464803696}, {"id": 4, "seek": 2368, "start": 38.4, "end": 46.0, "text": " playing a 35 minute or so video recording later in the session. But first, I'm going to do a few", "tokens": [51100, 2433, 257, 6976, 3456, 420, 370, 960, 6613, 1780, 294, 264, 5481, 13, 583, 700, 11, 286, 478, 516, 281, 360, 257, 1326, 51480], "temperature": 0.0, "avg_logprob": -0.12683980305989584, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.07253893464803696}, {"id": 5, "seek": 4600, "start": 46.0, "end": 56.16, "text": " introductory slides, overviewing this part of this summit. So with that, let me turn to slide", "tokens": [50364, 39048, 9788, 11, 12492, 278, 341, 644, 295, 341, 21564, 13, 407, 365, 300, 11, 718, 385, 1261, 281, 4137, 50872], "temperature": 0.0, "avg_logprob": -0.15590389796665738, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.14987534284591675}, {"id": 6, "seek": 4600, "start": 56.16, "end": 68.32, "text": " share here, screen share, and show you my first slide. So this has a working schedule for the second", "tokens": [50872, 2073, 510, 11, 2568, 2073, 11, 293, 855, 291, 452, 700, 4137, 13, 407, 341, 575, 257, 1364, 7567, 337, 264, 1150, 51480], "temperature": 0.0, "avg_logprob": -0.15590389796665738, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.14987534284591675}, {"id": 7, "seek": 4600, "start": 68.32, "end": 75.36, "text": " part of the summit, starting with modules and patterns with Kogen Shimizu from Wright State.", "tokens": [51480, 644, 295, 264, 21564, 11, 2891, 365, 16679, 293, 8294, 365, 591, 8799, 1160, 12526, 84, 490, 25578, 4533, 13, 51832], "temperature": 0.0, "avg_logprob": -0.15590389796665738, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.14987534284591675}, {"id": 8, "seek": 7536, "start": 75.36, "end": 80.48, "text": " He'll introduce himself in detail. And it shows that some of the other sessions that we have,", "tokens": [50364, 634, 603, 5366, 3647, 294, 2607, 13, 400, 309, 3110, 300, 512, 295, 264, 661, 11081, 300, 321, 362, 11, 50620], "temperature": 0.0, "avg_logprob": -0.17661631837183114, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.02749846689403057}, {"id": 9, "seek": 7536, "start": 81.12, "end": 86.24, "text": " basically things are nailed down now. So next week, we will have a design pad in discussion.", "tokens": [50652, 1936, 721, 366, 30790, 760, 586, 13, 407, 958, 1243, 11, 321, 486, 362, 257, 1715, 6887, 294, 5017, 13, 50908], "temperature": 0.0, "avg_logprob": -0.17661631837183114, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.02749846689403057}, {"id": 10, "seek": 7536, "start": 86.24, "end": 91.28, "text": " So to follow up to this session, we'd call Hammer, who's now at Google, had been at IBM.", "tokens": [50908, 407, 281, 1524, 493, 281, 341, 5481, 11, 321, 1116, 818, 33722, 11, 567, 311, 586, 412, 3329, 11, 632, 668, 412, 23487, 13, 51160], "temperature": 0.0, "avg_logprob": -0.17661631837183114, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.02749846689403057}, {"id": 11, "seek": 7536, "start": 91.28, "end": 98.56, "text": " We have invited some of the original people, such as Valentina Pursutit, to present, but we never", "tokens": [51160, 492, 362, 9185, 512, 295, 264, 3380, 561, 11, 1270, 382, 17961, 1426, 430, 2156, 325, 270, 11, 281, 1974, 11, 457, 321, 1128, 51524], "temperature": 0.0, "avg_logprob": -0.17661631837183114, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.02749846689403057}, {"id": 12, "seek": 9856, "start": 98.64, "end": 105.76, "text": " heard back from her. So we had call stepping up to do that. Following that, we're going to have", "tokens": [50368, 2198, 646, 490, 720, 13, 407, 321, 632, 818, 16821, 493, 281, 360, 300, 13, 19192, 300, 11, 321, 434, 516, 281, 362, 50724], "temperature": 0.0, "avg_logprob": -0.10634874093412149, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.2594742774963379}, {"id": 13, "seek": 9856, "start": 105.76, "end": 109.2, "text": " a session on Wikidata. I'll have a little bit more to say about that probably next week.", "tokens": [50724, 257, 5481, 322, 23377, 327, 3274, 13, 286, 603, 362, 257, 707, 857, 544, 281, 584, 466, 300, 1391, 958, 1243, 13, 50896], "temperature": 0.0, "avg_logprob": -0.10634874093412149, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.2594742774963379}, {"id": 14, "seek": 9856, "start": 110.0, "end": 117.28, "text": " And you can see the remaining schedule here leading up to a panel, which we still are filling in,", "tokens": [50936, 400, 291, 393, 536, 264, 8877, 7567, 510, 5775, 493, 281, 257, 4831, 11, 597, 321, 920, 366, 10623, 294, 11, 51300], "temperature": 0.0, "avg_logprob": -0.10634874093412149, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.2594742774963379}, {"id": 15, "seek": 9856, "start": 117.28, "end": 123.68, "text": " but Pascal Hitzler will be one of the main speakers on that. So with that, let me turn to", "tokens": [51300, 457, 41723, 389, 6862, 1918, 486, 312, 472, 295, 264, 2135, 9518, 322, 300, 13, 407, 365, 300, 11, 718, 385, 1261, 281, 51620], "temperature": 0.0, "avg_logprob": -0.10634874093412149, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.2594742774963379}, {"id": 16, "seek": 12368, "start": 123.68, "end": 130.0, "text": " today's session. And I thought I would introduce a little bit of the topic on ontology design patterns", "tokens": [50364, 965, 311, 5481, 13, 400, 286, 1194, 286, 576, 5366, 257, 707, 857, 295, 264, 4829, 322, 6592, 1793, 1715, 8294, 50680], "temperature": 0.0, "avg_logprob": -0.06980843842029572, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.06744270771741867}, {"id": 17, "seek": 12368, "start": 130.0, "end": 138.48000000000002, "text": " and modular ontologies before we go to the video. So this is an example of a widely used pattern,", "tokens": [50680, 293, 31111, 6592, 6204, 949, 321, 352, 281, 264, 960, 13, 407, 341, 307, 364, 1365, 295, 257, 13371, 1143, 5102, 11, 51104], "temperature": 0.0, "avg_logprob": -0.06980843842029572, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.06744270771741867}, {"id": 18, "seek": 12368, "start": 138.48000000000002, "end": 144.32, "text": " actually that I was a bit involved with, which is called semantic trajectory, which you see on the", "tokens": [51104, 767, 300, 286, 390, 257, 857, 3288, 365, 11, 597, 307, 1219, 47982, 21512, 11, 597, 291, 536, 322, 264, 51396], "temperature": 0.0, "avg_logprob": -0.06980843842029572, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.06744270771741867}, {"id": 19, "seek": 12368, "start": 144.32, "end": 151.52, "text": " left. And you can get an idea about what ontology design patterns are. So we have a range of concepts", "tokens": [51396, 1411, 13, 400, 291, 393, 483, 364, 1558, 466, 437, 6592, 1793, 1715, 8294, 366, 13, 407, 321, 362, 257, 3613, 295, 10392, 51756], "temperature": 0.0, "avg_logprob": -0.06980843842029572, "compression_ratio": 1.6778242677824269, "no_speech_prob": 0.06744270771741867}, {"id": 20, "seek": 15152, "start": 151.52, "end": 158.0, "text": " here. What is a semantic trajectory? How do you define it? Well, first we define it in terms of", "tokens": [50364, 510, 13, 708, 307, 257, 47982, 21512, 30, 1012, 360, 291, 6964, 309, 30, 1042, 11, 700, 321, 6964, 309, 294, 2115, 295, 50688], "temperature": 0.0, "avg_logprob": -0.09507506234305245, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.007003316190093756}, {"id": 21, "seek": 15152, "start": 158.0, "end": 164.4, "text": " having segments that go from and to places where we do a fix, that is, we take a sensory measure.", "tokens": [50688, 1419, 19904, 300, 352, 490, 293, 281, 3190, 689, 321, 360, 257, 3191, 11, 300, 307, 11, 321, 747, 257, 27233, 3481, 13, 51008], "temperature": 0.0, "avg_logprob": -0.09507506234305245, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.007003316190093756}, {"id": 22, "seek": 15152, "start": 165.76000000000002, "end": 172.48000000000002, "text": " And this segment is traversed by some type of conceptually moving object. Most of the time we're", "tokens": [51076, 400, 341, 9469, 307, 23149, 292, 538, 512, 2010, 295, 3410, 671, 2684, 2657, 13, 4534, 295, 264, 565, 321, 434, 51412], "temperature": 0.0, "avg_logprob": -0.09507506234305245, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.007003316190093756}, {"id": 23, "seek": 15152, "start": 172.48000000000002, "end": 178.48000000000002, "text": " thinking of a real physical object, but it may be a conceptual object. So it may be something like", "tokens": [51412, 1953, 295, 257, 957, 4001, 2657, 11, 457, 309, 815, 312, 257, 24106, 2657, 13, 407, 309, 815, 312, 746, 411, 51712], "temperature": 0.0, "avg_logprob": -0.09507506234305245, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.007003316190093756}, {"id": 24, "seek": 17848, "start": 178.56, "end": 184.64, "text": " a disease that is essentially having a course of action over time. And we're taking measurements", "tokens": [50368, 257, 4752, 300, 307, 4476, 1419, 257, 1164, 295, 3069, 670, 565, 13, 400, 321, 434, 1940, 15383, 50672], "temperature": 0.0, "avg_logprob": -0.1454201005909541, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.00317054009065032}, {"id": 25, "seek": 17848, "start": 184.64, "end": 192.72, "text": " under disease over time. And we have a source for the, and a sensor type and a location for the fix.", "tokens": [50672, 833, 4752, 670, 565, 13, 400, 321, 362, 257, 4009, 337, 264, 11, 293, 257, 10200, 2010, 293, 257, 4914, 337, 264, 3191, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1454201005909541, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.00317054009065032}, {"id": 26, "seek": 17848, "start": 193.76, "end": 200.0, "text": " You'll notice that most of the boxes have a solid line. Gary. Yes, Gary. Can you go into", "tokens": [51128, 509, 603, 3449, 300, 881, 295, 264, 9002, 362, 257, 5100, 1622, 13, 13788, 13, 1079, 11, 13788, 13, 1664, 291, 352, 666, 51440], "temperature": 0.0, "avg_logprob": -0.1454201005909541, "compression_ratio": 1.6067415730337078, "no_speech_prob": 0.00317054009065032}, {"id": 27, "seek": 20000, "start": 200.0, "end": 213.52, "text": " presentation mode? Let's see if I can do that. Do you want me to go into slide mode here?", "tokens": [50364, 5860, 4391, 30, 961, 311, 536, 498, 286, 393, 360, 300, 13, 1144, 291, 528, 385, 281, 352, 666, 4137, 4391, 510, 30, 51040], "temperature": 0.0, "avg_logprob": -0.17008646896907262, "compression_ratio": 1.2877697841726619, "no_speech_prob": 0.00857382919639349}, {"id": 28, "seek": 20000, "start": 214.24, "end": 215.92, "text": " Yeah, make it easier to read.", "tokens": [51076, 865, 11, 652, 309, 3571, 281, 1401, 13, 51160], "temperature": 0.0, "avg_logprob": -0.17008646896907262, "compression_ratio": 1.2877697841726619, "no_speech_prob": 0.00857382919639349}, {"id": 29, "seek": 20000, "start": 221.6, "end": 225.68, "text": " How does that help a little bit? Thank you. No, not so far.", "tokens": [51444, 1012, 775, 300, 854, 257, 707, 857, 30, 1044, 291, 13, 883, 11, 406, 370, 1400, 13, 51648], "temperature": 0.0, "avg_logprob": -0.17008646896907262, "compression_ratio": 1.2877697841726619, "no_speech_prob": 0.00857382919639349}, {"id": 30, "seek": 22568, "start": 226.0, "end": 238.16, "text": " All right. I'm going to go on here. My next slide tries to illustrate the range of things you might", "tokens": [50380, 1057, 558, 13, 286, 478, 516, 281, 352, 322, 510, 13, 1222, 958, 4137, 9898, 281, 23221, 264, 3613, 295, 721, 291, 1062, 50988], "temperature": 0.0, "avg_logprob": -0.16391179332994435, "compression_ratio": 1.489795918367347, "no_speech_prob": 0.0009541441104374826}, {"id": 31, "seek": 22568, "start": 238.16, "end": 246.88, "text": " see in ODPs, ontology design patterns. On the left, you see a rather complex pattern. Actually,", "tokens": [50988, 536, 294, 422, 11373, 82, 11, 6592, 1793, 1715, 8294, 13, 1282, 264, 1411, 11, 291, 536, 257, 2831, 3997, 5102, 13, 5135, 11, 51424], "temperature": 0.0, "avg_logprob": -0.16391179332994435, "compression_ratio": 1.489795918367347, "no_speech_prob": 0.0009541441104374826}, {"id": 32, "seek": 22568, "start": 246.88, "end": 252.8, "text": " this is an early version dealing with sensors, the sensing things, sensing features of interest.", "tokens": [51424, 341, 307, 364, 2440, 3037, 6260, 365, 14840, 11, 264, 30654, 721, 11, 30654, 4122, 295, 1179, 13, 51720], "temperature": 0.0, "avg_logprob": -0.16391179332994435, "compression_ratio": 1.489795918367347, "no_speech_prob": 0.0009541441104374826}, {"id": 33, "seek": 25280, "start": 252.8, "end": 257.68, "text": " There's actually several patterns probably composed in this, and this particular pattern,", "tokens": [50364, 821, 311, 767, 2940, 8294, 1391, 18204, 294, 341, 11, 293, 341, 1729, 5102, 11, 50608], "temperature": 0.0, "avg_logprob": -0.15077946002666767, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0009540428291074932}, {"id": 34, "seek": 25280, "start": 257.68, "end": 264.16, "text": " the semantic sensor network pattern, for example, has evolved over time and improved on. Slides are", "tokens": [50608, 264, 47982, 10200, 3209, 5102, 11, 337, 1365, 11, 575, 14178, 670, 565, 293, 9689, 322, 13, 6187, 1875, 366, 50932], "temperature": 0.0, "avg_logprob": -0.15077946002666767, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0009540428291074932}, {"id": 35, "seek": 25280, "start": 264.16, "end": 275.44, "text": " changing, Gary. Your slides are not changing. You don't see two ODP examples on the screen?", "tokens": [50932, 4473, 11, 13788, 13, 2260, 9788, 366, 406, 4473, 13, 509, 500, 380, 536, 732, 422, 11373, 5110, 322, 264, 2568, 30, 51496], "temperature": 0.0, "avg_logprob": -0.15077946002666767, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0009540428291074932}, {"id": 36, "seek": 27544, "start": 275.68, "end": 279.68, "text": " No. You are on the first slide.", "tokens": [50376, 883, 13, 509, 366, 322, 264, 700, 4137, 13, 50576], "temperature": 0.0, "avg_logprob": -0.17057502630985144, "compression_ratio": 1.5214285714285714, "no_speech_prob": 0.004068019799888134}, {"id": 37, "seek": 27544, "start": 282.08, "end": 288.08, "text": " Okay. I'm talking about the second slide. No, we don't see. Oh, second slide. Yeah.", "tokens": [50696, 1033, 13, 286, 478, 1417, 466, 264, 1150, 4137, 13, 883, 11, 321, 500, 380, 536, 13, 876, 11, 1150, 4137, 13, 865, 13, 50996], "temperature": 0.0, "avg_logprob": -0.17057502630985144, "compression_ratio": 1.5214285714285714, "no_speech_prob": 0.004068019799888134}, {"id": 38, "seek": 27544, "start": 288.96, "end": 298.72, "text": " You do see it? Yes. Okay. But it would help if you would. Did you still see the second slide with", "tokens": [51040, 509, 360, 536, 309, 30, 1079, 13, 1033, 13, 583, 309, 576, 854, 498, 291, 576, 13, 2589, 291, 920, 536, 264, 1150, 4137, 365, 51528], "temperature": 0.0, "avg_logprob": -0.17057502630985144, "compression_ratio": 1.5214285714285714, "no_speech_prob": 0.004068019799888134}, {"id": 39, "seek": 29872, "start": 298.72, "end": 309.12, "text": " two ODPs? There's one diagram. Okay. Well, there's two things on it. On the left side is a complex", "tokens": [50364, 732, 422, 11373, 82, 30, 821, 311, 472, 10686, 13, 1033, 13, 1042, 11, 456, 311, 732, 721, 322, 309, 13, 1282, 264, 1411, 1252, 307, 257, 3997, 50884], "temperature": 0.0, "avg_logprob": -0.111213265395746, "compression_ratio": 1.572192513368984, "no_speech_prob": 0.002840514527633786}, {"id": 40, "seek": 29872, "start": 309.12, "end": 317.52000000000004, "text": " one. On the right side is a very simple pattern for transitions. We don't see that. You don't see", "tokens": [50884, 472, 13, 1282, 264, 558, 1252, 307, 257, 588, 2199, 5102, 337, 23767, 13, 492, 500, 380, 536, 300, 13, 509, 500, 380, 536, 51304], "temperature": 0.0, "avg_logprob": -0.111213265395746, "compression_ratio": 1.572192513368984, "no_speech_prob": 0.002840514527633786}, {"id": 41, "seek": 29872, "start": 317.52000000000004, "end": 324.32000000000005, "text": " that. Gary, I think you are sharing the original window of the thing and not what you are seeing.", "tokens": [51304, 300, 13, 13788, 11, 286, 519, 291, 366, 5414, 264, 3380, 4910, 295, 264, 551, 293, 406, 437, 291, 366, 2577, 13, 51644], "temperature": 0.0, "avg_logprob": -0.111213265395746, "compression_ratio": 1.572192513368984, "no_speech_prob": 0.002840514527633786}, {"id": 42, "seek": 32432, "start": 325.04, "end": 329.59999999999997, "text": " You want to share your screen, not an individual application?", "tokens": [50400, 509, 528, 281, 2073, 428, 2568, 11, 406, 364, 2609, 3861, 30, 50628], "temperature": 0.0, "avg_logprob": -0.15220106972588432, "compression_ratio": 1.452513966480447, "no_speech_prob": 0.0007525757537223399}, {"id": 43, "seek": 32432, "start": 331.59999999999997, "end": 334.8, "text": " There we go. There you go. Yes. Okay.", "tokens": [50728, 821, 321, 352, 13, 821, 291, 352, 13, 1079, 13, 1033, 13, 50888], "temperature": 0.0, "avg_logprob": -0.15220106972588432, "compression_ratio": 1.452513966480447, "no_speech_prob": 0.0007525757537223399}, {"id": 44, "seek": 32432, "start": 338.0, "end": 342.64, "text": " I was asked to change your mode. Do you see the two patterns now? Yes.", "tokens": [51048, 286, 390, 2351, 281, 1319, 428, 4391, 13, 1144, 291, 536, 264, 732, 8294, 586, 30, 1079, 13, 51280], "temperature": 0.0, "avg_logprob": -0.15220106972588432, "compression_ratio": 1.452513966480447, "no_speech_prob": 0.0007525757537223399}, {"id": 45, "seek": 32432, "start": 345.03999999999996, "end": 350.08, "text": " So, again, to complete this is the complex one on the left, which is dealing with sensors", "tokens": [51400, 407, 11, 797, 11, 281, 3566, 341, 307, 264, 3997, 472, 322, 264, 1411, 11, 597, 307, 6260, 365, 14840, 51652], "temperature": 0.0, "avg_logprob": -0.15220106972588432, "compression_ratio": 1.452513966480447, "no_speech_prob": 0.0007525757537223399}, {"id": 46, "seek": 35008, "start": 350.08, "end": 356.56, "text": " information and the very simple idea of what is a transition and transition of an event has a", "tokens": [50364, 1589, 293, 264, 588, 2199, 1558, 295, 437, 307, 257, 6034, 293, 6034, 295, 364, 2280, 575, 257, 50688], "temperature": 0.0, "avg_logprob": -0.1468950080871582, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.002549193101003766}, {"id": 47, "seek": 35008, "start": 356.56, "end": 362.8, "text": " starting time. It's a setting for a thing and it has a final state. So, transitions from a start", "tokens": [50688, 2891, 565, 13, 467, 311, 257, 3287, 337, 257, 551, 293, 309, 575, 257, 2572, 1785, 13, 407, 11, 23767, 490, 257, 722, 51000], "temperature": 0.0, "avg_logprob": -0.1468950080871582, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.002549193101003766}, {"id": 48, "seek": 35008, "start": 362.8, "end": 369.2, "text": " to an end. Very, very simple design. Okay. Can you see a new slide now? Why ODPs?", "tokens": [51000, 281, 364, 917, 13, 4372, 11, 588, 2199, 1715, 13, 1033, 13, 1664, 291, 536, 257, 777, 4137, 586, 30, 1545, 422, 11373, 82, 30, 51320], "temperature": 0.0, "avg_logprob": -0.1468950080871582, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.002549193101003766}, {"id": 49, "seek": 35008, "start": 373.44, "end": 379.76, "text": " Yes. Okay. Fine. Okay. So, I wanted to provide a little rationale for some of the things that go", "tokens": [51532, 1079, 13, 1033, 13, 12024, 13, 1033, 13, 407, 11, 286, 1415, 281, 2893, 257, 707, 41989, 337, 512, 295, 264, 721, 300, 352, 51848], "temperature": 0.0, "avg_logprob": -0.1468950080871582, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.002549193101003766}, {"id": 50, "seek": 37976, "start": 379.76, "end": 386.96, "text": " into using ODPs. The original idea was that it was difficult to understand and get an overview of", "tokens": [50364, 666, 1228, 422, 11373, 82, 13, 440, 3380, 1558, 390, 300, 309, 390, 2252, 281, 1223, 293, 483, 364, 12492, 295, 50724], "temperature": 0.0, "avg_logprob": -0.11767967542012532, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0027113365940749645}, {"id": 51, "seek": 37976, "start": 386.96, "end": 392.4, "text": " very large ontologies as they were growing. It was also difficult to see the effects of a change or", "tokens": [50724, 588, 2416, 6592, 6204, 382, 436, 645, 4194, 13, 467, 390, 611, 2252, 281, 536, 264, 5065, 295, 257, 1319, 420, 50996], "temperature": 0.0, "avg_logprob": -0.11767967542012532, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0027113365940749645}, {"id": 52, "seek": 37976, "start": 392.4, "end": 398.64, "text": " an extension in some concepts. So, what impact it would have? And also, another thing that was said", "tokens": [50996, 364, 10320, 294, 512, 10392, 13, 407, 11, 437, 2712, 309, 576, 362, 30, 400, 611, 11, 1071, 551, 300, 390, 848, 51308], "temperature": 0.0, "avg_logprob": -0.11767967542012532, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0027113365940749645}, {"id": 53, "seek": 37976, "start": 398.64, "end": 404.32, "text": " is that it's often very hard to get full agreement on all the commitments on a large ontology. And", "tokens": [51308, 307, 300, 309, 311, 2049, 588, 1152, 281, 483, 1577, 8106, 322, 439, 264, 26230, 322, 257, 2416, 6592, 1793, 13, 400, 51592], "temperature": 0.0, "avg_logprob": -0.11767967542012532, "compression_ratio": 1.6431535269709543, "no_speech_prob": 0.0027113365940749645}, {"id": 54, "seek": 40432, "start": 404.32, "end": 411.28, "text": " for these reasons and other reasons such as interoperability problems and alignment problems,", "tokens": [50364, 337, 613, 4112, 293, 661, 4112, 1270, 382, 728, 7192, 2310, 2740, 293, 18515, 2740, 11, 50712], "temperature": 0.0, "avg_logprob": -0.06607176933759525, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.001205942709930241}, {"id": 55, "seek": 40432, "start": 411.28, "end": 416.08, "text": " understandability problems, people decided to look at these trade-offs and maybe it would be", "tokens": [50712, 1223, 2310, 2740, 11, 561, 3047, 281, 574, 412, 613, 4923, 12, 19231, 293, 1310, 309, 576, 312, 50952], "temperature": 0.0, "avg_logprob": -0.06607176933759525, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.001205942709930241}, {"id": 56, "seek": 40432, "start": 416.08, "end": 420.71999999999997, "text": " better to start with something smaller like some of the patterns that I showed you before.", "tokens": [50952, 1101, 281, 722, 365, 746, 4356, 411, 512, 295, 264, 8294, 300, 286, 4712, 291, 949, 13, 51184], "temperature": 0.0, "avg_logprob": -0.06607176933759525, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.001205942709930241}, {"id": 57, "seek": 40432, "start": 421.44, "end": 427.52, "text": " Here's a little bit more on some of this reasoning about what ontology patterns might be like.", "tokens": [51220, 1692, 311, 257, 707, 857, 544, 322, 512, 295, 341, 21577, 466, 437, 6592, 1793, 8294, 1062, 312, 411, 13, 51524], "temperature": 0.0, "avg_logprob": -0.06607176933759525, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.001205942709930241}, {"id": 58, "seek": 42752, "start": 428.4, "end": 437.12, "text": " They reflect, of course, the need to capture the reality that is in data, common to patterns.", "tokens": [50408, 814, 5031, 11, 295, 1164, 11, 264, 643, 281, 7983, 264, 4103, 300, 307, 294, 1412, 11, 2689, 281, 8294, 13, 50844], "temperature": 0.0, "avg_logprob": -0.08874279437678875, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.012427614070475101}, {"id": 59, "seek": 42752, "start": 437.12, "end": 441.84, "text": " Often, the patterns in data are hard to find, but if we can spend some time looking at that,", "tokens": [50844, 20043, 11, 264, 8294, 294, 1412, 366, 1152, 281, 915, 11, 457, 498, 321, 393, 3496, 512, 565, 1237, 412, 300, 11, 51080], "temperature": 0.0, "avg_logprob": -0.08874279437678875, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.012427614070475101}, {"id": 60, "seek": 42752, "start": 441.84, "end": 447.12, "text": " we can sort of abstract some of those patterns from the data itself as opposed to a pre-developed", "tokens": [51080, 321, 393, 1333, 295, 12649, 512, 295, 729, 8294, 490, 264, 1412, 2564, 382, 8851, 281, 257, 659, 12, 35464, 292, 51344], "temperature": 0.0, "avg_logprob": -0.08874279437678875, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.012427614070475101}, {"id": 61, "seek": 42752, "start": 447.12, "end": 454.08, "text": " top-level ontology. I have a quote here, roughly a quote here from Verna Kuhn early on in the era", "tokens": [51344, 1192, 12, 12418, 6592, 1793, 13, 286, 362, 257, 6513, 510, 11, 9810, 257, 6513, 510, 490, 4281, 629, 591, 3232, 77, 2440, 322, 294, 264, 4249, 51692], "temperature": 0.0, "avg_logprob": -0.08874279437678875, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.012427614070475101}, {"id": 62, "seek": 45408, "start": 454.08, "end": 459.28, "text": " when patterns were starting to be used. For solving semantic problems, it may be more productive to", "tokens": [50364, 562, 8294, 645, 2891, 281, 312, 1143, 13, 1171, 12606, 47982, 2740, 11, 309, 815, 312, 544, 13304, 281, 50624], "temperature": 0.0, "avg_logprob": -0.13602496277202258, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.013009205460548401}, {"id": 63, "seek": 45408, "start": 459.28, "end": 465.76, "text": " agree on minimal requirements imposed on small notions like a pattern notion. So, the idea was", "tokens": [50624, 3986, 322, 13206, 7728, 26491, 322, 1359, 35799, 411, 257, 5102, 10710, 13, 407, 11, 264, 1558, 390, 50948], "temperature": 0.0, "avg_logprob": -0.13602496277202258, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.013009205460548401}, {"id": 64, "seek": 45408, "start": 465.76, "end": 472.47999999999996, "text": " to use small and well-engineered, coherent, minimally constrained schemas as a start for ontology", "tokens": [50948, 281, 764, 1359, 293, 731, 12, 25609, 4073, 11, 36239, 11, 4464, 379, 38901, 22627, 296, 382, 257, 722, 337, 6592, 1793, 51284], "temperature": 0.0, "avg_logprob": -0.13602496277202258, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.013009205460548401}, {"id": 65, "seek": 45408, "start": 472.47999999999996, "end": 476.96, "text": " that later could be combined, as I showed you with the semantic sensor net, where you might", "tokens": [51284, 300, 1780, 727, 312, 9354, 11, 382, 286, 4712, 291, 365, 264, 47982, 10200, 2533, 11, 689, 291, 1062, 51508], "temperature": 0.0, "avg_logprob": -0.13602496277202258, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.013009205460548401}, {"id": 66, "seek": 47696, "start": 476.96, "end": 484.64, "text": " can be combining several different patterns. You can use very good documentation and design", "tokens": [50364, 393, 312, 21928, 2940, 819, 8294, 13, 509, 393, 764, 588, 665, 14333, 293, 1715, 50748], "temperature": 0.0, "avg_logprob": -0.12757137616475422, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.03303901106119156}, {"id": 67, "seek": 47696, "start": 484.64, "end": 491.03999999999996, "text": " rationalities and best engineering practice for reuse over time, so you can prove things", "tokens": [50748, 15090, 1088, 293, 1151, 7043, 3124, 337, 26225, 670, 565, 11, 370, 291, 393, 7081, 721, 51068], "temperature": 0.0, "avg_logprob": -0.12757137616475422, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.03303901106119156}, {"id": 68, "seek": 47696, "start": 491.03999999999996, "end": 499.59999999999997, "text": " like the semantic sensor network over time. So, for all these reasons, people did try out going to", "tokens": [51068, 411, 264, 47982, 10200, 3209, 670, 565, 13, 407, 11, 337, 439, 613, 4112, 11, 561, 630, 853, 484, 516, 281, 51496], "temperature": 0.0, "avg_logprob": -0.12757137616475422, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.03303901106119156}, {"id": 69, "seek": 49960, "start": 500.24, "end": 506.96000000000004, "text": " modular patterns. And as they did, and roughly about 12 years ago or so,", "tokens": [50396, 31111, 8294, 13, 400, 382, 436, 630, 11, 293, 9810, 466, 2272, 924, 2057, 420, 370, 11, 50732], "temperature": 0.0, "avg_logprob": -0.16693729162216187, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.1274423897266388}, {"id": 70, "seek": 49960, "start": 508.88, "end": 514.16, "text": " Gangamy and Presuti, who I invited to a session but haven't heard back,", "tokens": [50828, 17984, 7804, 293, 2718, 29161, 11, 567, 286, 9185, 281, 257, 5481, 457, 2378, 380, 2198, 646, 11, 51092], "temperature": 0.0, "avg_logprob": -0.16693729162216187, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.1274423897266388}, {"id": 71, "seek": 49960, "start": 515.12, "end": 522.4, "text": " wrote some documentation on modular operations and just talked about five basic types of", "tokens": [51140, 4114, 512, 14333, 322, 31111, 7705, 293, 445, 2825, 466, 1732, 3875, 3467, 295, 51504], "temperature": 0.0, "avg_logprob": -0.16693729162216187, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.1274423897266388}, {"id": 72, "seek": 49960, "start": 522.4, "end": 527.84, "text": " operations when reusing them and building them. So, the first is, of course, importing them,", "tokens": [51504, 7705, 562, 319, 7981, 552, 293, 2390, 552, 13, 407, 11, 264, 700, 307, 11, 295, 1164, 11, 43866, 552, 11, 51776], "temperature": 0.0, "avg_logprob": -0.16693729162216187, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.1274423897266388}, {"id": 73, "seek": 52784, "start": 528.64, "end": 534.48, "text": " and you can use import functionality to do that into whatever you're trying to do.", "tokens": [50404, 293, 291, 393, 764, 974, 14980, 281, 360, 300, 666, 2035, 291, 434, 1382, 281, 360, 13, 50696], "temperature": 0.0, "avg_logprob": -0.11267098085379895, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.002018508967012167}, {"id": 74, "seek": 52784, "start": 535.2, "end": 541.36, "text": " You can also specialize, two types of specialization. You can take an existing idea and", "tokens": [50732, 509, 393, 611, 37938, 11, 732, 3467, 295, 2121, 2144, 13, 509, 393, 747, 364, 6741, 1558, 293, 51040], "temperature": 0.0, "avg_logprob": -0.11267098085379895, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.002018508967012167}, {"id": 75, "seek": 52784, "start": 541.36, "end": 548.0, "text": " specialize it conceptually and then go from there. Or you can have a specialization done", "tokens": [51040, 37938, 309, 3410, 671, 293, 550, 352, 490, 456, 13, 1610, 291, 393, 362, 257, 2121, 2144, 1096, 51372], "temperature": 0.0, "avg_logprob": -0.11267098085379895, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.002018508967012167}, {"id": 76, "seek": 52784, "start": 548.0, "end": 553.84, "text": " by creating subclasses and subproperties on existing ODP classes and properties.", "tokens": [51372, 538, 4084, 1422, 11665, 279, 293, 1422, 4318, 610, 6097, 322, 6741, 422, 11373, 5359, 293, 7221, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11267098085379895, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.002018508967012167}, {"id": 77, "seek": 55384, "start": 554.72, "end": 563.6800000000001, "text": " You can also generalize an ODP in the concepts in them. And one of the most complex things,", "tokens": [50408, 509, 393, 611, 2674, 1125, 364, 422, 11373, 294, 264, 10392, 294, 552, 13, 400, 472, 295, 264, 881, 3997, 721, 11, 50856], "temperature": 0.0, "avg_logprob": -0.11236646224041374, "compression_ratio": 1.65625, "no_speech_prob": 0.002714161528274417}, {"id": 78, "seek": 55384, "start": 563.6800000000001, "end": 569.2, "text": " and you saw a little bit of this in the semantic sensor net, the early version, is composition,", "tokens": [50856, 293, 291, 1866, 257, 707, 857, 295, 341, 294, 264, 47982, 10200, 2533, 11, 264, 2440, 3037, 11, 307, 12686, 11, 51132], "temperature": 0.0, "avg_logprob": -0.11236646224041374, "compression_ratio": 1.65625, "no_speech_prob": 0.002714161528274417}, {"id": 79, "seek": 55384, "start": 569.84, "end": 575.6800000000001, "text": " where you use multiple ODPs, small pieces, and try to compose them in a meaningful way,", "tokens": [51164, 689, 291, 764, 3866, 422, 11373, 82, 11, 1359, 3755, 11, 293, 853, 281, 35925, 552, 294, 257, 10995, 636, 11, 51456], "temperature": 0.0, "avg_logprob": -0.11236646224041374, "compression_ratio": 1.65625, "no_speech_prob": 0.002714161528274417}, {"id": 80, "seek": 55384, "start": 575.6800000000001, "end": 580.8000000000001, "text": " fitting them together. And the last one, of course, here is the idea of, well, you may not find", "tokens": [51456, 15669, 552, 1214, 13, 400, 264, 1036, 472, 11, 295, 1164, 11, 510, 307, 264, 1558, 295, 11, 731, 11, 291, 815, 406, 915, 51712], "temperature": 0.0, "avg_logprob": -0.11236646224041374, "compression_ratio": 1.65625, "no_speech_prob": 0.002714161528274417}, {"id": 81, "seek": 58080, "start": 581.4399999999999, "end": 588.8, "text": " an idea in a particular pattern that you want to use, and you might have to develop new patterns", "tokens": [50396, 364, 1558, 294, 257, 1729, 5102, 300, 291, 528, 281, 764, 11, 293, 291, 1062, 362, 281, 1499, 777, 8294, 50764], "temperature": 0.0, "avg_logprob": -0.11257677300031795, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00218223687261343}, {"id": 82, "seek": 58080, "start": 588.8, "end": 595.92, "text": " for that. And here is an example of just such a thing of an expansion. I showed you that", "tokens": [50764, 337, 300, 13, 400, 510, 307, 364, 1365, 295, 445, 1270, 257, 551, 295, 364, 11260, 13, 286, 4712, 291, 300, 51120], "temperature": 0.0, "avg_logprob": -0.11257677300031795, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00218223687261343}, {"id": 83, "seek": 58080, "start": 596.9599999999999, "end": 603.8399999999999, "text": " semantic trajectory before. Here we have a portion of that trajectory on the right,", "tokens": [51172, 47982, 21512, 949, 13, 1692, 321, 362, 257, 8044, 295, 300, 21512, 322, 264, 558, 11, 51516], "temperature": 0.0, "avg_logprob": -0.11257677300031795, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00218223687261343}, {"id": 84, "seek": 58080, "start": 604.4, "end": 610.3199999999999, "text": " but you're sort of extending it and combining it with other things, so that a particular project", "tokens": [51544, 457, 291, 434, 1333, 295, 24360, 309, 293, 21928, 309, 365, 661, 721, 11, 370, 300, 257, 1729, 1716, 51840], "temperature": 0.0, "avg_logprob": -0.11257677300031795, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.00218223687261343}, {"id": 85, "seek": 61032, "start": 610.32, "end": 616.0, "text": " that NSF funded called the Geolink Projects used the trajectory for scientific expeditions.", "tokens": [50364, 300, 15943, 37, 14385, 1219, 264, 2876, 401, 475, 9849, 82, 1143, 264, 21512, 337, 8134, 19348, 2451, 13, 50648], "temperature": 0.0, "avg_logprob": -0.13427994840888566, "compression_ratio": 1.5924369747899159, "no_speech_prob": 0.0018375550862401724}, {"id": 86, "seek": 61032, "start": 616.0, "end": 623.5200000000001, "text": " And so they had to, they specialized the idea of what is traversing the segment to a vessel that", "tokens": [50648, 400, 370, 436, 632, 281, 11, 436, 19813, 264, 1558, 295, 437, 307, 23149, 278, 264, 9469, 281, 257, 18098, 300, 51024], "temperature": 0.0, "avg_logprob": -0.13427994840888566, "compression_ratio": 1.5924369747899159, "no_speech_prob": 0.0018375550862401724}, {"id": 87, "seek": 61032, "start": 623.5200000000001, "end": 629.9200000000001, "text": " might be going on a cruise. And they also added other ideas on that, such as the data was gathered", "tokens": [51024, 1062, 312, 516, 322, 257, 17754, 13, 400, 436, 611, 3869, 661, 3487, 322, 300, 11, 1270, 382, 264, 1412, 390, 13032, 51344], "temperature": 0.0, "avg_logprob": -0.13427994840888566, "compression_ratio": 1.5924369747899159, "no_speech_prob": 0.0018375550862401724}, {"id": 88, "seek": 61032, "start": 629.9200000000001, "end": 635.0400000000001, "text": " and put it into a repository, things of that nature. So this is just a small example of how", "tokens": [51344, 293, 829, 309, 666, 257, 25841, 11, 721, 295, 300, 3687, 13, 407, 341, 307, 445, 257, 1359, 1365, 295, 577, 51600], "temperature": 0.0, "avg_logprob": -0.13427994840888566, "compression_ratio": 1.5924369747899159, "no_speech_prob": 0.0018375550862401724}, {"id": 89, "seek": 63504, "start": 635.92, "end": 642.16, "text": " patterns get built and get reused. And we'll hear more about that from Kogan and also next week", "tokens": [50408, 8294, 483, 3094, 293, 483, 319, 4717, 13, 400, 321, 603, 1568, 544, 466, 300, 490, 591, 21576, 293, 611, 958, 1243, 50720], "temperature": 0.0, "avg_logprob": -0.1094098687171936, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0019870270043611526}, {"id": 90, "seek": 63504, "start": 642.16, "end": 648.88, "text": " from Kahl. My last slide is just a few sources on that. This is the reference to that semantic", "tokens": [50720, 490, 591, 10722, 13, 1222, 1036, 4137, 307, 445, 257, 1326, 7139, 322, 300, 13, 639, 307, 264, 6408, 281, 300, 47982, 51056], "temperature": 0.0, "avg_logprob": -0.1094098687171936, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0019870270043611526}, {"id": 91, "seek": 63504, "start": 648.88, "end": 655.76, "text": " trajectory, for example. This is a tutorial sort of on how you combine patterns, make good patterns.", "tokens": [51056, 21512, 11, 337, 1365, 13, 639, 307, 257, 7073, 1333, 295, 322, 577, 291, 10432, 8294, 11, 652, 665, 8294, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1094098687171936, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0019870270043611526}, {"id": 92, "seek": 63504, "start": 655.76, "end": 661.52, "text": " This is something on how you document patterns and so forth. So with that, let me stop the share", "tokens": [51400, 639, 307, 746, 322, 577, 291, 4166, 8294, 293, 370, 5220, 13, 407, 365, 300, 11, 718, 385, 1590, 264, 2073, 51688], "temperature": 0.0, "avg_logprob": -0.1094098687171936, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.0019870270043611526}, {"id": 93, "seek": 66152, "start": 661.52, "end": 668.88, "text": " and let me turn the session back over to Ken, who will hopefully start the Kogan's video,", "tokens": [50364, 293, 718, 385, 1261, 264, 5481, 646, 670, 281, 8273, 11, 567, 486, 4696, 722, 264, 591, 21576, 311, 960, 11, 50732], "temperature": 0.0, "avg_logprob": -0.10686512997275904, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.005380301270633936}, {"id": 94, "seek": 66152, "start": 668.88, "end": 673.92, "text": " which runs about 34 minutes or so, which will leave us with a little bit of time for Q&A,", "tokens": [50732, 597, 6676, 466, 12790, 2077, 420, 370, 11, 597, 486, 1856, 505, 365, 257, 707, 857, 295, 565, 337, 1249, 5, 32, 11, 50984], "temperature": 0.0, "avg_logprob": -0.10686512997275904, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.005380301270633936}, {"id": 95, "seek": 66152, "start": 673.92, "end": 680.48, "text": " although he's not here this time. He promised to come back next time when call presents,", "tokens": [50984, 4878, 415, 311, 406, 510, 341, 565, 13, 634, 10768, 281, 808, 646, 958, 565, 562, 818, 13533, 11, 51312], "temperature": 0.0, "avg_logprob": -0.10686512997275904, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.005380301270633936}, {"id": 96, "seek": 66152, "start": 680.48, "end": 685.52, "text": " he'll be available questions and answers. So if we have an important ones, we have an address here,", "tokens": [51312, 415, 603, 312, 2435, 1651, 293, 6338, 13, 407, 498, 321, 362, 364, 1021, 2306, 11, 321, 362, 364, 2985, 510, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10686512997275904, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.005380301270633936}, {"id": 97, "seek": 68552, "start": 685.52, "end": 695.28, "text": " you may be able to do it then. So this is the recording.", "tokens": [50364, 291, 815, 312, 1075, 281, 360, 309, 550, 13, 407, 341, 307, 264, 6613, 13, 50852], "temperature": 0.0, "avg_logprob": -0.13500826060771942, "compression_ratio": 1.5541401273885351, "no_speech_prob": 0.0020180491264909506}, {"id": 98, "seek": 68552, "start": 697.28, "end": 702.56, "text": " Hopefully you'll be able to hear the sound, but it's quite redundant. You'll notice that", "tokens": [50952, 10429, 291, 603, 312, 1075, 281, 1568, 264, 1626, 11, 457, 309, 311, 1596, 40997, 13, 509, 603, 3449, 300, 51216], "temperature": 0.0, "avg_logprob": -0.13500826060771942, "compression_ratio": 1.5541401273885351, "no_speech_prob": 0.0020180491264909506}, {"id": 99, "seek": 68552, "start": 703.6, "end": 714.24, "text": " the transcript is on the right. And you'll also see the transcript on the screen as he's speaking.", "tokens": [51268, 264, 24444, 307, 322, 264, 558, 13, 400, 291, 603, 611, 536, 264, 24444, 322, 264, 2568, 382, 415, 311, 4124, 13, 51800], "temperature": 0.0, "avg_logprob": -0.13500826060771942, "compression_ratio": 1.5541401273885351, "no_speech_prob": 0.0020180491264909506}, {"id": 100, "seek": 71552, "start": 715.84, "end": 725.76, "text": " Hello, everyone. Welcome to my talk. Today, I'm going to be providing a", "tokens": [50380, 2425, 11, 1518, 13, 4027, 281, 452, 751, 13, 2692, 11, 286, 478, 516, 281, 312, 6530, 257, 50876], "temperature": 0.0, "avg_logprob": -0.1506275563012986, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0028417909052222967}, {"id": 101, "seek": 71552, "start": 728.8, "end": 737.4399999999999, "text": " introduction to patterns and modules. And by this, I really mean patterns and modules as they", "tokens": [51028, 9339, 281, 8294, 293, 16679, 13, 400, 538, 341, 11, 286, 534, 914, 8294, 293, 16679, 382, 436, 51460], "temperature": 0.0, "avg_logprob": -0.1506275563012986, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0028417909052222967}, {"id": 102, "seek": 73744, "start": 738.08, "end": 748.4000000000001, "text": " exist outside of the traditional sort of formal ontology perspective. So I'm not looking at the", "tokens": [50396, 2514, 2380, 295, 264, 5164, 1333, 295, 9860, 6592, 1793, 4585, 13, 407, 286, 478, 406, 1237, 412, 264, 50912], "temperature": 0.0, "avg_logprob": -0.10631038181817354, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.020936913788318634}, {"id": 103, "seek": 73744, "start": 748.4000000000001, "end": 757.9200000000001, "text": " modules and the patterns as they exist inside of say, for example, Dolce or BFO or any of the other", "tokens": [50912, 16679, 293, 264, 8294, 382, 436, 2514, 1854, 295, 584, 11, 337, 1365, 11, 18786, 384, 420, 363, 18067, 420, 604, 295, 264, 661, 51388], "temperature": 0.0, "avg_logprob": -0.10631038181817354, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.020936913788318634}, {"id": 104, "seek": 73744, "start": 757.9200000000001, "end": 765.2800000000001, "text": " upper fundamental foundational reference ontologies, but instead coming at this from more of the", "tokens": [51388, 6597, 8088, 32195, 6408, 6592, 6204, 11, 457, 2602, 1348, 412, 341, 490, 544, 295, 264, 51756], "temperature": 0.0, "avg_logprob": -0.10631038181817354, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.020936913788318634}, {"id": 105, "seek": 76528, "start": 765.28, "end": 773.12, "text": " empirical data-driven side of things. We'll go over briefly the methodology and some of the resources.", "tokens": [50364, 31886, 1412, 12, 25456, 1252, 295, 721, 13, 492, 603, 352, 670, 10515, 264, 24850, 293, 512, 295, 264, 3593, 13, 50756], "temperature": 0.0, "avg_logprob": -0.13619426831807177, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.006370686460286379}, {"id": 106, "seek": 76528, "start": 774.16, "end": 780.8, "text": " So very briefly, my name's Kogan Shimizu. I'm an assistant professor over at Wright State University", "tokens": [50808, 407, 588, 10515, 11, 452, 1315, 311, 591, 21576, 1160, 12526, 84, 13, 286, 478, 364, 10994, 8304, 670, 412, 25578, 4533, 3535, 51140], "temperature": 0.0, "avg_logprob": -0.13619426831807177, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.006370686460286379}, {"id": 107, "seek": 76528, "start": 780.8, "end": 789.52, "text": " in Dayton, Ohio. Some of you have already spoken with me at previous talks and some of you have", "tokens": [51140, 294, 44718, 11, 14469, 13, 2188, 295, 291, 362, 1217, 10759, 365, 385, 412, 3894, 6686, 293, 512, 295, 291, 362, 51576], "temperature": 0.0, "avg_logprob": -0.13619426831807177, "compression_ratio": 1.4875621890547264, "no_speech_prob": 0.006370686460286379}, {"id": 108, "seek": 78952, "start": 789.52, "end": 796.3199999999999, "text": " just known me for years already. But regardless, I'm happy to be here and talk a little bit about", "tokens": [50364, 445, 2570, 385, 337, 924, 1217, 13, 583, 10060, 11, 286, 478, 2055, 281, 312, 510, 293, 751, 257, 707, 857, 466, 50704], "temperature": 0.0, "avg_logprob": -0.09708036402220367, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.02331891469657421}, {"id": 109, "seek": 78952, "start": 796.3199999999999, "end": 802.4, "text": " what I'm interested in, and then also the point of the talk. So a little bit more about me is that", "tokens": [50704, 437, 286, 478, 3102, 294, 11, 293, 550, 611, 264, 935, 295, 264, 751, 13, 407, 257, 707, 857, 544, 466, 385, 307, 300, 51008], "temperature": 0.0, "avg_logprob": -0.09708036402220367, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.02331891469657421}, {"id": 110, "seek": 78952, "start": 802.4, "end": 808.8, "text": " I'm broadly interested in knowledge engineering. And I mean this from the full perspective or the full", "tokens": [51008, 286, 478, 19511, 3102, 294, 3601, 7043, 13, 400, 286, 914, 341, 490, 264, 1577, 4585, 420, 264, 1577, 51328], "temperature": 0.0, "avg_logprob": -0.09708036402220367, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.02331891469657421}, {"id": 111, "seek": 78952, "start": 808.8, "end": 818.0, "text": " spectrum from just basic knowledge representation from any, from low expressivities of taxonomies,", "tokens": [51328, 11143, 490, 445, 3875, 3601, 10290, 490, 604, 11, 490, 2295, 5109, 43539, 295, 3366, 12481, 530, 11, 51788], "temperature": 0.0, "avg_logprob": -0.09708036402220367, "compression_ratio": 1.7008547008547008, "no_speech_prob": 0.02331891469657421}, {"id": 112, "seek": 81800, "start": 818.56, "end": 825.68, "text": " controlled vocabularies all way to full-blown owl ontologies. But this also encompasses some of the", "tokens": [50392, 10164, 2329, 455, 1040, 530, 439, 636, 281, 1577, 12, 5199, 648, 34488, 6592, 6204, 13, 583, 341, 611, 49866, 512, 295, 264, 50748], "temperature": 0.0, "avg_logprob": -0.12324695372849367, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.003592328866943717}, {"id": 113, "seek": 81800, "start": 826.32, "end": 832.96, "text": " deployment aspects and how our knowledge graphs and these knowledge bases use. And that's a lot of", "tokens": [50780, 19317, 7270, 293, 577, 527, 3601, 24877, 293, 613, 3601, 17949, 764, 13, 400, 300, 311, 257, 688, 295, 51112], "temperature": 0.0, "avg_logprob": -0.12324695372849367, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.003592328866943717}, {"id": 114, "seek": 81800, "start": 832.96, "end": 837.92, "text": " where this pattern-based methodology comes from is it's not just about patterns and the knowledge,", "tokens": [51112, 689, 341, 5102, 12, 6032, 24850, 1487, 490, 307, 309, 311, 406, 445, 466, 8294, 293, 264, 3601, 11, 51360], "temperature": 0.0, "avg_logprob": -0.12324695372849367, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.003592328866943717}, {"id": 115, "seek": 81800, "start": 837.92, "end": 845.12, "text": " but also patterns of usage and how you can really simplify how knowledge graphs and the constituent", "tokens": [51360, 457, 611, 8294, 295, 14924, 293, 577, 291, 393, 534, 20460, 577, 3601, 24877, 293, 264, 16085, 317, 51720], "temperature": 0.0, "avg_logprob": -0.12324695372849367, "compression_ratio": 1.7566371681415929, "no_speech_prob": 0.003592328866943717}, {"id": 116, "seek": 84512, "start": 845.12, "end": 852.16, "text": " knowledge is really utilized. And then of course the the next two things are just kind of employing", "tokens": [50364, 3601, 307, 534, 28158, 13, 400, 550, 295, 1164, 264, 264, 958, 732, 721, 366, 445, 733, 295, 3188, 278, 50716], "temperature": 0.0, "avg_logprob": -0.08267036676406861, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0013240259140729904}, {"id": 117, "seek": 84512, "start": 852.16, "end": 858.16, "text": " knowledge engineering to do more effective open science and more effective teaching of this", "tokens": [50716, 3601, 7043, 281, 360, 544, 4942, 1269, 3497, 293, 544, 4942, 4571, 295, 341, 51016], "temperature": 0.0, "avg_logprob": -0.08267036676406861, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0013240259140729904}, {"id": 118, "seek": 84512, "start": 858.16, "end": 863.12, "text": " material. So kind of looking at knowledge engineering from the perspective of knowledge", "tokens": [51016, 2527, 13, 407, 733, 295, 1237, 412, 3601, 7043, 490, 264, 4585, 295, 3601, 51264], "temperature": 0.0, "avg_logprob": -0.08267036676406861, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0013240259140729904}, {"id": 119, "seek": 84512, "start": 863.12, "end": 869.28, "text": " engineering in order to be a more effective teacher. But I digress by now. So without further ado,", "tokens": [51264, 7043, 294, 1668, 281, 312, 257, 544, 4942, 5027, 13, 583, 286, 2528, 735, 538, 586, 13, 407, 1553, 3052, 22450, 11, 51572], "temperature": 0.0, "avg_logprob": -0.08267036676406861, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0013240259140729904}, {"id": 120, "seek": 86928, "start": 869.28, "end": 876.0799999999999, "text": " let's take a look at the rest of our talk today. There are four main pieces that we're going to", "tokens": [50364, 718, 311, 747, 257, 574, 412, 264, 1472, 295, 527, 751, 965, 13, 821, 366, 1451, 2135, 3755, 300, 321, 434, 516, 281, 50704], "temperature": 0.0, "avg_logprob": -0.0574946403503418, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.02367941103875637}, {"id": 121, "seek": 86928, "start": 877.68, "end": 884.48, "text": " dig into and I'll give briefly an motivation and then we'll again briefly kind of go over the", "tokens": [50784, 2528, 666, 293, 286, 603, 976, 10515, 364, 12335, 293, 550, 321, 603, 797, 10515, 733, 295, 352, 670, 264, 51124], "temperature": 0.0, "avg_logprob": -0.0574946403503418, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.02367941103875637}, {"id": 122, "seek": 86928, "start": 884.48, "end": 890.48, "text": " modular ontology modeling methodology or MOMO. And then I have a few examples of what patterns", "tokens": [51124, 31111, 6592, 1793, 15983, 24850, 420, 46840, 46, 13, 400, 550, 286, 362, 257, 1326, 5110, 295, 437, 8294, 51424], "temperature": 0.0, "avg_logprob": -0.0574946403503418, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.02367941103875637}, {"id": 123, "seek": 86928, "start": 890.48, "end": 895.28, "text": " look like and kind of some connections to some previous pattern work that we've seen in previous", "tokens": [51424, 574, 411, 293, 733, 295, 512, 9271, 281, 512, 3894, 5102, 589, 300, 321, 600, 1612, 294, 3894, 51664], "temperature": 0.0, "avg_logprob": -0.0574946403503418, "compression_ratio": 1.6282051282051282, "no_speech_prob": 0.02367941103875637}, {"id": 124, "seek": 89528, "start": 895.28, "end": 903.1999999999999, "text": " talks here. And then we'll close with some tools and resources. So the first example that I have is", "tokens": [50364, 6686, 510, 13, 400, 550, 321, 603, 1998, 365, 512, 3873, 293, 3593, 13, 407, 264, 700, 1365, 300, 286, 362, 307, 50760], "temperature": 0.0, "avg_logprob": -0.10913058172298383, "compression_ratio": 1.5923913043478262, "no_speech_prob": 0.0032206829637289047}, {"id": 125, "seek": 89528, "start": 903.1999999999999, "end": 911.68, "text": " called the nowhere graph. The nowhere graph is a NSF-funded consortium. And I don't mean that in", "tokens": [50760, 1219, 264, 11159, 4295, 13, 440, 11159, 4295, 307, 257, 15943, 37, 12, 43589, 38343, 2197, 13, 400, 286, 500, 380, 914, 300, 294, 51184], "temperature": 0.0, "avg_logprob": -0.10913058172298383, "compression_ratio": 1.5923913043478262, "no_speech_prob": 0.0032206829637289047}, {"id": 126, "seek": 89528, "start": 912.56, "end": 919.36, "text": " a more formal sense. There is no NSF consortium in this case. By this I just mean that there's a", "tokens": [51228, 257, 544, 9860, 2020, 13, 821, 307, 572, 15943, 37, 38343, 2197, 294, 341, 1389, 13, 3146, 341, 286, 445, 914, 300, 456, 311, 257, 51568], "temperature": 0.0, "avg_logprob": -0.10913058172298383, "compression_ratio": 1.5923913043478262, "no_speech_prob": 0.0032206829637289047}, {"id": 127, "seek": 91936, "start": 919.36, "end": 925.84, "text": " pretty huge team. I think it's over 50 collaborators at this point and that spans from all of the", "tokens": [50364, 1238, 2603, 1469, 13, 286, 519, 309, 311, 670, 2625, 39789, 412, 341, 935, 293, 300, 44086, 490, 439, 295, 264, 50688], "temperature": 0.0, "avg_logprob": -0.07576482526717647, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.007572975941002369}, {"id": 128, "seek": 91936, "start": 926.48, "end": 935.92, "text": " student researchers to the investigators, the collaborators from NGOs and private industry", "tokens": [50720, 3107, 10309, 281, 264, 27079, 11, 264, 39789, 490, 46454, 293, 4551, 3518, 51192], "temperature": 0.0, "avg_logprob": -0.07576482526717647, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.007572975941002369}, {"id": 129, "seek": 91936, "start": 935.92, "end": 943.6800000000001, "text": " and government agencies. It's pretty quite expansive and with high coverage. We have a whole bunch of", "tokens": [51192, 293, 2463, 9504, 13, 467, 311, 1238, 1596, 46949, 293, 365, 1090, 9645, 13, 492, 362, 257, 1379, 3840, 295, 51580], "temperature": 0.0, "avg_logprob": -0.07576482526717647, "compression_ratio": 1.5263157894736843, "no_speech_prob": 0.007572975941002369}, {"id": 130, "seek": 94368, "start": 943.68, "end": 951.04, "text": " different data sets that come from that are contributed by the different collaborators or", "tokens": [50364, 819, 1412, 6352, 300, 808, 490, 300, 366, 18434, 538, 264, 819, 39789, 420, 50732], "temperature": 0.0, "avg_logprob": -0.0962441250429315, "compression_ratio": 1.6647058823529413, "no_speech_prob": 0.03674957528710365}, {"id": 131, "seek": 94368, "start": 951.04, "end": 957.92, "text": " we're pulling them from publicly available websites and we're integrating them all and trying to", "tokens": [50732, 321, 434, 8407, 552, 490, 14843, 2435, 12891, 293, 321, 434, 26889, 552, 439, 293, 1382, 281, 51076], "temperature": 0.0, "avg_logprob": -0.0962441250429315, "compression_ratio": 1.6647058823529413, "no_speech_prob": 0.03674957528710365}, {"id": 132, "seek": 94368, "start": 957.92, "end": 969.76, "text": " provide a geospatial backbone so that way the representation of spatial integration is pre-done.", "tokens": [51076, 2893, 257, 1519, 2763, 267, 831, 34889, 370, 300, 636, 264, 10290, 295, 23598, 10980, 307, 659, 12, 45939, 13, 51668], "temperature": 0.0, "avg_logprob": -0.0962441250429315, "compression_ratio": 1.6647058823529413, "no_speech_prob": 0.03674957528710365}, {"id": 133, "seek": 96976, "start": 970.24, "end": 976.72, "text": " We're front-loading the cost of doing the spatial integration and this came with some pretty tricky", "tokens": [50388, 492, 434, 1868, 12, 2907, 278, 264, 2063, 295, 884, 264, 23598, 10980, 293, 341, 1361, 365, 512, 1238, 12414, 50712], "temperature": 0.0, "avg_logprob": -0.11290585122457365, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0029782967176288366}, {"id": 134, "seek": 96976, "start": 977.28, "end": 986.8, "text": " and interesting problems with how to adequately express these spatial relations and also ensure", "tokens": [50740, 293, 1880, 2740, 365, 577, 281, 41822, 5109, 613, 23598, 2299, 293, 611, 5586, 51216], "temperature": 0.0, "avg_logprob": -0.11290585122457365, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0029782967176288366}, {"id": 135, "seek": 96976, "start": 986.8, "end": 991.6, "text": " that we have provenance from all of the different data sets and all of the different features and", "tokens": [51216, 300, 321, 362, 12785, 719, 490, 439, 295, 264, 819, 1412, 6352, 293, 439, 295, 264, 819, 4122, 293, 51456], "temperature": 0.0, "avg_logprob": -0.11290585122457365, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0029782967176288366}, {"id": 136, "seek": 96976, "start": 991.6, "end": 996.96, "text": " do the semantic harmonization. And it turns out that we did wind up using a modular knowledge", "tokens": [51456, 360, 264, 47982, 14750, 2144, 13, 400, 309, 4523, 484, 300, 321, 630, 2468, 493, 1228, 257, 31111, 3601, 51724], "temperature": 0.0, "avg_logprob": -0.11290585122457365, "compression_ratio": 1.6973684210526316, "no_speech_prob": 0.0029782967176288366}, {"id": 137, "seek": 99696, "start": 996.96, "end": 1004.8000000000001, "text": " graph in order to do this. So this is what the schema looked like back in July of 2021", "tokens": [50364, 4295, 294, 1668, 281, 360, 341, 13, 407, 341, 307, 437, 264, 34078, 2956, 411, 646, 294, 7370, 295, 7201, 50756], "temperature": 0.0, "avg_logprob": -0.10867205218992372, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.003026442602276802}, {"id": 138, "seek": 99696, "start": 1005.84, "end": 1013.0400000000001, "text": " and into 2022 I believe. And each one of these little tiny boxes that you can see here are a", "tokens": [50808, 293, 666, 20229, 286, 1697, 13, 400, 1184, 472, 295, 613, 707, 5870, 9002, 300, 291, 393, 536, 510, 366, 257, 51168], "temperature": 0.0, "avg_logprob": -0.10867205218992372, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.003026442602276802}, {"id": 139, "seek": 99696, "start": 1013.0400000000001, "end": 1020.4000000000001, "text": " module. We have an expertise module, we have a hazard module, we have different modules for the", "tokens": [51168, 10088, 13, 492, 362, 364, 11769, 10088, 11, 321, 362, 257, 20790, 10088, 11, 321, 362, 819, 16679, 337, 264, 51536], "temperature": 0.0, "avg_logprob": -0.10867205218992372, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.003026442602276802}, {"id": 140, "seek": 102040, "start": 1020.48, "end": 1027.92, "text": " different data sets so climate division, soil types, storm observations, smoke plumes, things that", "tokens": [50368, 819, 1412, 6352, 370, 5659, 10044, 11, 6704, 3467, 11, 7679, 18163, 11, 8439, 499, 10018, 11, 721, 300, 50740], "temperature": 0.0, "avg_logprob": -0.10986557163175989, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.03354937583208084}, {"id": 141, "seek": 102040, "start": 1027.92, "end": 1037.6, "text": " impact the world around us by some physical phenomena and is also of interest enough that the", "tokens": [50740, 2712, 264, 1002, 926, 505, 538, 512, 4001, 22004, 293, 307, 611, 295, 1179, 1547, 300, 264, 51224], "temperature": 0.0, "avg_logprob": -0.10986557163175989, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.03354937583208084}, {"id": 142, "seek": 102040, "start": 1037.6, "end": 1042.8, "text": " government at a state or federal level is tracking them and providing data sets about them.", "tokens": [51224, 2463, 412, 257, 1785, 420, 6019, 1496, 307, 11603, 552, 293, 6530, 1412, 6352, 466, 552, 13, 51484], "temperature": 0.0, "avg_logprob": -0.10986557163175989, "compression_ratio": 1.5604395604395604, "no_speech_prob": 0.03354937583208084}, {"id": 143, "seek": 104280, "start": 1043.44, "end": 1050.96, "text": " And so what we did is we identified a kind of pattern that exists in this observations and it's", "tokens": [50396, 400, 370, 437, 321, 630, 307, 321, 9234, 257, 733, 295, 5102, 300, 8198, 294, 341, 18163, 293, 309, 311, 50772], "temperature": 0.0, "avg_logprob": -0.10304039627758425, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.02593742124736309}, {"id": 144, "seek": 104280, "start": 1050.96, "end": 1060.24, "text": " drawn from the SOSA SSN, the sensors observations sampling actuators ontology from the semantic", "tokens": [50772, 10117, 490, 264, 318, 4367, 32, 12238, 45, 11, 264, 14840, 18163, 21179, 34964, 3391, 6592, 1793, 490, 264, 47982, 51236], "temperature": 0.0, "avg_logprob": -0.10304039627758425, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.02593742124736309}, {"id": 145, "seek": 104280, "start": 1060.24, "end": 1068.8, "text": " sensor network and kind of extracting a core piece of that and using that as a sort of template", "tokens": [51236, 10200, 3209, 293, 733, 295, 49844, 257, 4965, 2522, 295, 300, 293, 1228, 300, 382, 257, 1333, 295, 12379, 51664], "temperature": 0.0, "avg_logprob": -0.10304039627758425, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.02593742124736309}, {"id": 146, "seek": 106880, "start": 1069.44, "end": 1079.28, "text": " to mint new patterns which kind of turn into these modules and so on. And this strategy I think as", "tokens": [50396, 281, 18189, 777, 8294, 597, 733, 295, 1261, 666, 613, 16679, 293, 370, 322, 13, 400, 341, 5206, 286, 519, 382, 50888], "temperature": 0.0, "avg_logprob": -0.1311991488347288, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.00768813444301486}, {"id": 147, "seek": 106880, "start": 1079.28, "end": 1084.8799999999999, "text": " both Nick and Chris have said in previous talks is really effective for rapidly expanding", "tokens": [50888, 1293, 9449, 293, 6688, 362, 848, 294, 3894, 6686, 307, 534, 4942, 337, 12910, 14702, 51168], "temperature": 0.0, "avg_logprob": -0.1311991488347288, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.00768813444301486}, {"id": 148, "seek": 106880, "start": 1086.6399999999999, "end": 1094.3999999999999, "text": " additional coverage for a domain without really having to know the ontology in and out.", "tokens": [51256, 4497, 9645, 337, 257, 9274, 1553, 534, 1419, 281, 458, 264, 6592, 1793, 294, 293, 484, 13, 51644], "temperature": 0.0, "avg_logprob": -0.1311991488347288, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.00768813444301486}, {"id": 149, "seek": 109440, "start": 1095.3600000000001, "end": 1100.64, "text": " There's some clear connection points to these strategies. And so what this results in is as", "tokens": [50412, 821, 311, 512, 1850, 4984, 2793, 281, 613, 9029, 13, 400, 370, 437, 341, 3542, 294, 307, 382, 50676], "temperature": 0.0, "avg_logprob": -0.12054927614000109, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0085721705108881}, {"id": 150, "seek": 109440, "start": 1100.64, "end": 1108.24, "text": " of November of 2022 is this much larger schema and I don't think this is everything either.", "tokens": [50676, 295, 7674, 295, 20229, 307, 341, 709, 4833, 34078, 293, 286, 500, 380, 519, 341, 307, 1203, 2139, 13, 51056], "temperature": 0.0, "avg_logprob": -0.12054927614000109, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0085721705108881}, {"id": 151, "seek": 109440, "start": 1110.96, "end": 1116.3200000000002, "text": " And it's also hardly readable because it doesn't fit on the screen. It's kind of an interesting", "tokens": [51192, 400, 309, 311, 611, 13572, 49857, 570, 309, 1177, 380, 3318, 322, 264, 2568, 13, 467, 311, 733, 295, 364, 1880, 51460], "temperature": 0.0, "avg_logprob": -0.12054927614000109, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0085721705108881}, {"id": 152, "seek": 109440, "start": 1116.3200000000002, "end": 1122.48, "text": " sort of catch 22. It's cool that we've been able to integrate all of these different data sets but", "tokens": [51460, 1333, 295, 3745, 5853, 13, 467, 311, 1627, 300, 321, 600, 668, 1075, 281, 13365, 439, 295, 613, 819, 1412, 6352, 457, 51768], "temperature": 0.0, "avg_logprob": -0.12054927614000109, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0085721705108881}, {"id": 153, "seek": 112248, "start": 1122.48, "end": 1127.76, "text": " now it doesn't fit on the slide so we can't really show it off. But anyway the evolution and", "tokens": [50364, 586, 309, 1177, 380, 3318, 322, 264, 4137, 370, 321, 393, 380, 534, 855, 309, 766, 13, 583, 4033, 264, 9303, 293, 50628], "temperature": 0.0, "avg_logprob": -0.08660057366612446, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0015972382389008999}, {"id": 154, "seek": 112248, "start": 1127.76, "end": 1135.04, "text": " maintenance of the graph comes from these patterns and these modules and being able to rapidly", "tokens": [50628, 11258, 295, 264, 4295, 1487, 490, 613, 8294, 293, 613, 16679, 293, 885, 1075, 281, 12910, 50992], "temperature": 0.0, "avg_logprob": -0.08660057366612446, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0015972382389008999}, {"id": 155, "seek": 112248, "start": 1135.68, "end": 1142.88, "text": " replace a module or add in a new module based on an older module or the same pattern", "tokens": [51024, 7406, 257, 10088, 420, 909, 294, 257, 777, 10088, 2361, 322, 364, 4906, 10088, 420, 264, 912, 5102, 51384], "temperature": 0.0, "avg_logprob": -0.08660057366612446, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0015972382389008999}, {"id": 156, "seek": 112248, "start": 1143.92, "end": 1148.64, "text": " is really instrumental. And we'll kind of go into this in a few slides.", "tokens": [51436, 307, 534, 17388, 13, 400, 321, 603, 733, 295, 352, 666, 341, 294, 257, 1326, 9788, 13, 51672], "temperature": 0.0, "avg_logprob": -0.08660057366612446, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0015972382389008999}, {"id": 157, "seek": 114864, "start": 1149.2800000000002, "end": 1156.96, "text": " Another example that we have is the enslaved hub ontology. So the enslaved hub is a smaller", "tokens": [50396, 3996, 1365, 300, 321, 362, 307, 264, 32119, 11838, 6592, 1793, 13, 407, 264, 32119, 11838, 307, 257, 4356, 50780], "temperature": 0.0, "avg_logprob": -0.1369588057200114, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.0007788253133185208}, {"id": 158, "seek": 114864, "start": 1156.96, "end": 1164.16, "text": " but no less important knowledge graph. It's really about identifying, integrating and really", "tokens": [50780, 457, 572, 1570, 1021, 3601, 4295, 13, 467, 311, 534, 466, 16696, 11, 26889, 293, 534, 51140], "temperature": 0.0, "avg_logprob": -0.1369588057200114, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.0007788253133185208}, {"id": 159, "seek": 114864, "start": 1164.16, "end": 1170.88, "text": " making visible the stories of the peoples of the historical slave trade. So trying to find", "tokens": [51140, 1455, 8974, 264, 3676, 295, 264, 16915, 295, 264, 8584, 14777, 4923, 13, 407, 1382, 281, 915, 51476], "temperature": 0.0, "avg_logprob": -0.1369588057200114, "compression_ratio": 1.5804597701149425, "no_speech_prob": 0.0007788253133185208}, {"id": 160, "seek": 117088, "start": 1171.6000000000001, "end": 1181.3600000000001, "text": " how a particular person might have traveled from place to place largely against their will and", "tokens": [50400, 577, 257, 1729, 954, 1062, 362, 16147, 490, 1081, 281, 1081, 11611, 1970, 641, 486, 293, 50888], "temperature": 0.0, "avg_logprob": -0.1321262593539256, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.019385982304811478}, {"id": 161, "seek": 117088, "start": 1182.3200000000002, "end": 1192.24, "text": " with different names and different personal relationships and trying to identify what", "tokens": [50936, 365, 819, 5288, 293, 819, 2973, 6159, 293, 1382, 281, 5876, 437, 51432], "temperature": 0.0, "avg_logprob": -0.1321262593539256, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.019385982304811478}, {"id": 162, "seek": 117088, "start": 1192.24, "end": 1197.3600000000001, "text": " actually is the ground truth because that's one of the hard things here is that integrating", "tokens": [51432, 767, 307, 264, 2727, 3494, 570, 300, 311, 472, 295, 264, 1152, 721, 510, 307, 300, 26889, 51688], "temperature": 0.0, "avg_logprob": -0.1321262593539256, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.019385982304811478}, {"id": 163, "seek": 119736, "start": 1197.36, "end": 1203.04, "text": " all of these little tiny data sets from historians across the nation and around the world even", "tokens": [50364, 439, 295, 613, 707, 5870, 1412, 6352, 490, 26442, 2108, 264, 4790, 293, 926, 264, 1002, 754, 50648], "temperature": 0.0, "avg_logprob": -0.13973310537505568, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0008682450861670077}, {"id": 164, "seek": 119736, "start": 1204.32, "end": 1209.6, "text": " you have different interpretations of the events that occur or different interpretations of the", "tokens": [50712, 291, 362, 819, 37547, 295, 264, 3931, 300, 5160, 420, 819, 37547, 295, 264, 50976], "temperature": 0.0, "avg_logprob": -0.13973310537505568, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0008682450861670077}, {"id": 165, "seek": 119736, "start": 1212.3999999999999, "end": 1222.1599999999999, "text": " first source, the first hand sources. And this resulted also in a modular knowledge graph.", "tokens": [51116, 700, 4009, 11, 264, 700, 1011, 7139, 13, 400, 341, 18753, 611, 294, 257, 31111, 3601, 4295, 13, 51604], "temperature": 0.0, "avg_logprob": -0.13973310537505568, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0008682450861670077}, {"id": 166, "seek": 122216, "start": 1222.16, "end": 1228.16, "text": " Otherwise we wouldn't be presenting it in this particular presentation. But the point is that", "tokens": [50364, 10328, 321, 2759, 380, 312, 15578, 309, 294, 341, 1729, 5860, 13, 583, 264, 935, 307, 300, 50664], "temperature": 0.0, "avg_logprob": -0.07730751861760646, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.025158094242215157}, {"id": 167, "seek": 122216, "start": 1228.16, "end": 1234.48, "text": " having a way of modeling the different types of characteristics of the peoples of the historical", "tokens": [50664, 1419, 257, 636, 295, 15983, 264, 819, 3467, 295, 10891, 295, 264, 16915, 295, 264, 8584, 50980], "temperature": 0.0, "avg_logprob": -0.07730751861760646, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.025158094242215157}, {"id": 168, "seek": 122216, "start": 1234.48, "end": 1241.52, "text": " slave trade as well as this sort of integration of the data sets is really valuable and really", "tokens": [50980, 14777, 4923, 382, 731, 382, 341, 1333, 295, 10980, 295, 264, 1412, 6352, 307, 534, 8263, 293, 534, 51332], "temperature": 0.0, "avg_logprob": -0.07730751861760646, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.025158094242215157}, {"id": 169, "seek": 122216, "start": 1241.52, "end": 1248.3200000000002, "text": " makes it easy to apply a pattern based method towards it. This I will not get into so much", "tokens": [51332, 1669, 309, 1858, 281, 3079, 257, 5102, 2361, 3170, 3030, 309, 13, 639, 286, 486, 406, 483, 666, 370, 709, 51672], "temperature": 0.0, "avg_logprob": -0.07730751861760646, "compression_ratio": 1.613733905579399, "no_speech_prob": 0.025158094242215157}, {"id": 170, "seek": 124832, "start": 1248.3999999999999, "end": 1253.04, "text": " with the rest of the presentation, but if you have any questions or you want to see the schema", "tokens": [50368, 365, 264, 1472, 295, 264, 5860, 11, 457, 498, 291, 362, 604, 1651, 420, 291, 528, 281, 536, 264, 34078, 50600], "temperature": 0.0, "avg_logprob": -0.07459374477988795, "compression_ratio": 1.8629032258064515, "no_speech_prob": 0.00618884339928627}, {"id": 171, "seek": 124832, "start": 1253.04, "end": 1258.1599999999999, "text": " you can go to enslave.org or if you have any questions my email is at the end of the", "tokens": [50600, 291, 393, 352, 281, 3489, 27995, 13, 4646, 420, 498, 291, 362, 604, 1651, 452, 3796, 307, 412, 264, 917, 295, 264, 50856], "temperature": 0.0, "avg_logprob": -0.07459374477988795, "compression_ratio": 1.8629032258064515, "no_speech_prob": 0.00618884339928627}, {"id": 172, "seek": 124832, "start": 1258.8, "end": 1263.04, "text": " presentation and you can go ahead and pass on questions and I'll either answer them or send", "tokens": [50888, 5860, 293, 291, 393, 352, 2286, 293, 1320, 322, 1651, 293, 286, 603, 2139, 1867, 552, 420, 2845, 51100], "temperature": 0.0, "avg_logprob": -0.07459374477988795, "compression_ratio": 1.8629032258064515, "no_speech_prob": 0.00618884339928627}, {"id": 173, "seek": 124832, "start": 1263.04, "end": 1270.56, "text": " them on to the team. So anyway let's go ahead and dig a little bit more into modular ontology", "tokens": [51100, 552, 322, 281, 264, 1469, 13, 407, 4033, 718, 311, 352, 2286, 293, 2528, 257, 707, 857, 544, 666, 31111, 6592, 1793, 51476], "temperature": 0.0, "avg_logprob": -0.07459374477988795, "compression_ratio": 1.8629032258064515, "no_speech_prob": 0.00618884339928627}, {"id": 174, "seek": 124832, "start": 1270.56, "end": 1276.8799999999999, "text": " modeling. So one of the things that I didn't really talk about is what is the difference between", "tokens": [51476, 15983, 13, 407, 472, 295, 264, 721, 300, 286, 994, 380, 534, 751, 466, 307, 437, 307, 264, 2649, 1296, 51792], "temperature": 0.0, "avg_logprob": -0.07459374477988795, "compression_ratio": 1.8629032258064515, "no_speech_prob": 0.00618884339928627}, {"id": 175, "seek": 127688, "start": 1276.88, "end": 1284.0800000000002, "text": " a knowledge graph and an ontology. And in this case we don't really mean them to be too differently", "tokens": [50364, 257, 3601, 4295, 293, 364, 6592, 1793, 13, 400, 294, 341, 1389, 321, 500, 380, 534, 914, 552, 281, 312, 886, 7614, 50724], "temperature": 0.0, "avg_logprob": -0.1009662840101454, "compression_ratio": 1.825, "no_speech_prob": 0.005550691392272711}, {"id": 176, "seek": 127688, "start": 1285.2, "end": 1292.0, "text": " except for in this case an ontology is really just the T-box of the ontology. And then we", "tokens": [50780, 3993, 337, 294, 341, 1389, 364, 6592, 1793, 307, 534, 445, 264, 314, 12, 4995, 295, 264, 6592, 1793, 13, 400, 550, 321, 51120], "temperature": 0.0, "avg_logprob": -0.1009662840101454, "compression_ratio": 1.825, "no_speech_prob": 0.005550691392272711}, {"id": 177, "seek": 127688, "start": 1292.0, "end": 1299.2, "text": " consider the knowledge graph to be the A-box coupled with the ontology which acts as a schema", "tokens": [51120, 1949, 264, 3601, 4295, 281, 312, 264, 316, 12, 4995, 29482, 365, 264, 6592, 1793, 597, 10672, 382, 257, 34078, 51480], "temperature": 0.0, "avg_logprob": -0.1009662840101454, "compression_ratio": 1.825, "no_speech_prob": 0.005550691392272711}, {"id": 178, "seek": 127688, "start": 1299.2, "end": 1303.7600000000002, "text": " for the knowledge graph. Really it's just changing the different buzzwords around", "tokens": [51480, 337, 264, 3601, 4295, 13, 4083, 309, 311, 445, 4473, 264, 819, 13036, 13832, 926, 51708], "temperature": 0.0, "avg_logprob": -0.1009662840101454, "compression_ratio": 1.825, "no_speech_prob": 0.005550691392272711}, {"id": 179, "seek": 130376, "start": 1303.76, "end": 1312.8799999999999, "text": " in order to make sure that the work is fundable sometimes or a little bit more relatable to", "tokens": [50364, 294, 1668, 281, 652, 988, 300, 264, 589, 307, 2374, 712, 2171, 420, 257, 707, 857, 544, 42355, 281, 50820], "temperature": 0.0, "avg_logprob": -0.14886340156930392, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.0016469573602080345}, {"id": 180, "seek": 130376, "start": 1312.8799999999999, "end": 1320.8, "text": " to a broader audience. And in this case what we mean with pattern mediated methods for knowledge", "tokens": [50820, 281, 257, 13227, 4034, 13, 400, 294, 341, 1389, 437, 321, 914, 365, 5102, 17269, 770, 7150, 337, 3601, 51216], "temperature": 0.0, "avg_logprob": -0.14886340156930392, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.0016469573602080345}, {"id": 181, "seek": 130376, "start": 1320.8, "end": 1327.12, "text": " engineering and including these patterns is really including and using patterns as a first order", "tokens": [51216, 7043, 293, 3009, 613, 8294, 307, 534, 3009, 293, 1228, 8294, 382, 257, 700, 1668, 51532], "temperature": 0.0, "avg_logprob": -0.14886340156930392, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.0016469573602080345}, {"id": 182, "seek": 132712, "start": 1327.12, "end": 1335.4399999999998, "text": " or first class citizen within the modeling paradigm. So making sure that the modular ontology", "tokens": [50364, 420, 700, 1508, 13326, 1951, 264, 15983, 24709, 13, 407, 1455, 988, 300, 264, 31111, 6592, 1793, 50780], "temperature": 0.0, "avg_logprob": -0.09513217311794475, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.08143661916255951}, {"id": 183, "seek": 132712, "start": 1338.2399999999998, "end": 1346.8799999999999, "text": " is directly represented using annotations and this is what really drives the ability to expand", "tokens": [50920, 307, 3838, 10379, 1228, 25339, 763, 293, 341, 307, 437, 534, 11754, 264, 3485, 281, 5268, 51352], "temperature": 0.0, "avg_logprob": -0.09513217311794475, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.08143661916255951}, {"id": 184, "seek": 132712, "start": 1348.0, "end": 1354.56, "text": " the the ontology or the knowledge graph schema based on the existing patterns within the ontology", "tokens": [51408, 264, 264, 6592, 1793, 420, 264, 3601, 4295, 34078, 2361, 322, 264, 6741, 8294, 1951, 264, 6592, 1793, 51736], "temperature": 0.0, "avg_logprob": -0.09513217311794475, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.08143661916255951}, {"id": 185, "seek": 135456, "start": 1354.56, "end": 1360.32, "text": " or to yank out and say we'll we don't want this one anymore let's go ahead and replace it with this", "tokens": [50364, 420, 281, 288, 657, 484, 293, 584, 321, 603, 321, 500, 380, 528, 341, 472, 3602, 718, 311, 352, 2286, 293, 7406, 309, 365, 341, 50652], "temperature": 0.0, "avg_logprob": -0.09478747844696045, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0008826659759506583}, {"id": 186, "seek": 135456, "start": 1360.32, "end": 1366.24, "text": " new one and then finding all of the pertinent axioms and underlying instances for those for those", "tokens": [50652, 777, 472, 293, 550, 5006, 439, 295, 264, 13269, 11058, 6360, 72, 4785, 293, 14217, 14519, 337, 729, 337, 729, 50948], "temperature": 0.0, "avg_logprob": -0.09478747844696045, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0008826659759506583}, {"id": 187, "seek": 135456, "start": 1366.24, "end": 1375.2, "text": " classes is quite valuable. And so what we have here on this slide is what we call the modularity", "tokens": [50948, 5359, 307, 1596, 8263, 13, 400, 370, 437, 321, 362, 510, 322, 341, 4137, 307, 437, 321, 818, 264, 31111, 507, 51396], "temperature": 0.0, "avg_logprob": -0.09478747844696045, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0008826659759506583}, {"id": 188, "seek": 135456, "start": 1375.2, "end": 1380.72, "text": " which is the patterns made out of sorry the schemas made out of patterns and then on the right", "tokens": [51396, 597, 307, 264, 8294, 1027, 484, 295, 2597, 264, 22627, 296, 1027, 484, 295, 8294, 293, 550, 322, 264, 558, 51672], "temperature": 0.0, "avg_logprob": -0.09478747844696045, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0008826659759506583}, {"id": 189, "seek": 138072, "start": 1380.72, "end": 1386.64, "text": " hand side we have the metadata scaffolding and so this is really the the the catchy way of saying", "tokens": [50364, 1011, 1252, 321, 362, 264, 26603, 44094, 278, 293, 370, 341, 307, 534, 264, 264, 264, 47168, 636, 295, 1566, 50660], "temperature": 0.0, "avg_logprob": -0.07817625417941954, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.003374912077561021}, {"id": 190, "seek": 138072, "start": 1386.64, "end": 1391.3600000000001, "text": " well we're just going to annotate the schema with additional information that indicates what", "tokens": [50660, 731, 321, 434, 445, 516, 281, 25339, 473, 264, 34078, 365, 4497, 1589, 300, 16203, 437, 50896], "temperature": 0.0, "avg_logprob": -0.07817625417941954, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.003374912077561021}, {"id": 191, "seek": 138072, "start": 1392.24, "end": 1400.0, "text": " pattern or module particular classes within the ontology belong to. So with this in mind the", "tokens": [50940, 5102, 420, 10088, 1729, 5359, 1951, 264, 6592, 1793, 5784, 281, 13, 407, 365, 341, 294, 1575, 264, 51328], "temperature": 0.0, "avg_logprob": -0.07817625417941954, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.003374912077561021}, {"id": 192, "seek": 138072, "start": 1400.0, "end": 1405.3600000000001, "text": " metadata scaffolding can really be thought of as the sort of ladder right you have a conceptual", "tokens": [51328, 26603, 44094, 278, 393, 534, 312, 1194, 295, 382, 264, 1333, 295, 18325, 558, 291, 362, 257, 24106, 51596], "temperature": 0.0, "avg_logprob": -0.07817625417941954, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.003374912077561021}, {"id": 193, "seek": 140536, "start": 1405.4399999999998, "end": 1411.12, "text": " component which is an extremely human centric term which might be implemented in a number of", "tokens": [50368, 6542, 597, 307, 364, 4664, 1952, 1489, 1341, 1433, 597, 1062, 312, 12270, 294, 257, 1230, 295, 50652], "temperature": 0.0, "avg_logprob": -0.09509709440631631, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.033563282340765}, {"id": 194, "seek": 140536, "start": 1411.12, "end": 1418.3999999999999, "text": " different ways. For example space and time are great examples of this because there's", "tokens": [50652, 819, 2098, 13, 1171, 1365, 1901, 293, 565, 366, 869, 5110, 295, 341, 570, 456, 311, 51016], "temperature": 0.0, "avg_logprob": -0.09509709440631631, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.033563282340765}, {"id": 195, "seek": 140536, "start": 1418.3999999999999, "end": 1426.7199999999998, "text": " so many different ways of modeling space right that we can each say that each ways of those", "tokens": [51016, 370, 867, 819, 2098, 295, 15983, 1901, 558, 300, 321, 393, 1184, 584, 300, 1184, 2098, 295, 729, 51432], "temperature": 0.0, "avg_logprob": -0.09509709440631631, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.033563282340765}, {"id": 196, "seek": 140536, "start": 1426.7199999999998, "end": 1433.84, "text": " modeling spaces is is kind of pattern is kind of like a pattern and so a spatial extent would be", "tokens": [51432, 15983, 7673, 307, 307, 733, 295, 5102, 307, 733, 295, 411, 257, 5102, 293, 370, 257, 23598, 8396, 576, 312, 51788], "temperature": 0.0, "avg_logprob": -0.09509709440631631, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.033563282340765}, {"id": 197, "seek": 143384, "start": 1433.84, "end": 1439.6799999999998, "text": " the conceptual component it would be represented by some set of patterns and then you choose a", "tokens": [50364, 264, 24106, 6542, 309, 576, 312, 10379, 538, 512, 992, 295, 8294, 293, 550, 291, 2826, 257, 50656], "temperature": 0.0, "avg_logprob": -0.06477405884686638, "compression_ratio": 1.7942583732057416, "no_speech_prob": 0.003074167761951685}, {"id": 198, "seek": 143384, "start": 1439.6799999999998, "end": 1444.9599999999998, "text": " pattern and you turn it into something that's more apt for your use case and we call that a module.", "tokens": [50656, 5102, 293, 291, 1261, 309, 666, 746, 300, 311, 544, 29427, 337, 428, 764, 1389, 293, 321, 818, 300, 257, 10088, 13, 50920], "temperature": 0.0, "avg_logprob": -0.06477405884686638, "compression_ratio": 1.7942583732057416, "no_speech_prob": 0.003074167761951685}, {"id": 199, "seek": 143384, "start": 1446.1599999999999, "end": 1450.56, "text": " And then you have the instances of the modules which are really just the shapes of the data", "tokens": [50980, 400, 550, 291, 362, 264, 14519, 295, 264, 16679, 597, 366, 534, 445, 264, 10854, 295, 264, 1412, 51200], "temperature": 0.0, "avg_logprob": -0.06477405884686638, "compression_ratio": 1.7942583732057416, "no_speech_prob": 0.003074167761951685}, {"id": 200, "seek": 143384, "start": 1451.12, "end": 1458.3999999999999, "text": " the actual triples or the materializations of the the data that the model module models.", "tokens": [51228, 264, 3539, 1376, 2622, 420, 264, 2527, 14455, 295, 264, 264, 1412, 300, 264, 2316, 10088, 5245, 13, 51592], "temperature": 0.0, "avg_logprob": -0.06477405884686638, "compression_ratio": 1.7942583732057416, "no_speech_prob": 0.003074167761951685}, {"id": 201, "seek": 145840, "start": 1458.64, "end": 1470.96, "text": " We use a a language called opala or opal which is the better way of of kind of turning the", "tokens": [50376, 492, 764, 257, 257, 2856, 1219, 999, 5159, 420, 999, 304, 597, 307, 264, 1101, 636, 295, 295, 733, 295, 6246, 264, 50992], "temperature": 0.0, "avg_logprob": -0.2448175483279758, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.0035365279763936996}, {"id": 202, "seek": 145840, "start": 1470.96, "end": 1479.52, "text": " the acronym into into a human word which is just the ODP representation language. So OP", "tokens": [50992, 264, 39195, 666, 666, 257, 1952, 1349, 597, 307, 445, 264, 422, 11373, 10290, 2856, 13, 407, 23324, 51420], "temperature": 0.0, "avg_logprob": -0.2448175483279758, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.0035365279763936996}, {"id": 203, "seek": 145840, "start": 1481.0400000000002, "end": 1488.3200000000002, "text": " and then A from pattern and then L. What I have here on the right is an in-progress draft of the", "tokens": [51496, 293, 550, 316, 490, 5102, 293, 550, 441, 13, 708, 286, 362, 510, 322, 264, 558, 307, 364, 294, 12, 4318, 3091, 11206, 295, 264, 51860], "temperature": 0.0, "avg_logprob": -0.2448175483279758, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.0035365279763936996}, {"id": 204, "seek": 148840, "start": 1488.88, "end": 1497.2800000000002, "text": " version two of opal and what we are trying to do here is to include even more information about", "tokens": [50388, 3037, 732, 295, 999, 304, 293, 437, 321, 366, 1382, 281, 360, 510, 307, 281, 4090, 754, 544, 1589, 466, 50808], "temperature": 0.0, "avg_logprob": -0.10582746105429566, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.0006160740740597248}, {"id": 205, "seek": 148840, "start": 1497.2800000000002, "end": 1504.8000000000002, "text": " what is actually going on inside of the pattern. Axioms tend to follow patterns especially within", "tokens": [50808, 437, 307, 767, 516, 322, 1854, 295, 264, 5102, 13, 20118, 72, 4785, 3928, 281, 1524, 8294, 2318, 1951, 51184], "temperature": 0.0, "avg_logprob": -0.10582746105429566, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.0006160740740597248}, {"id": 206, "seek": 148840, "start": 1504.8000000000002, "end": 1511.2800000000002, "text": " the MOMO methodology but there's also different ways of thinking about patterns in terms of the", "tokens": [51184, 264, 46840, 46, 24850, 457, 456, 311, 611, 819, 2098, 295, 1953, 466, 8294, 294, 2115, 295, 264, 51508], "temperature": 0.0, "avg_logprob": -0.10582746105429566, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.0006160740740597248}, {"id": 207, "seek": 148840, "start": 1511.2800000000002, "end": 1517.92, "text": " representation so you can have a perspective which is really just an extremely simplified", "tokens": [51508, 10290, 370, 291, 393, 362, 257, 4585, 597, 307, 534, 445, 364, 4664, 26335, 51840], "temperature": 0.0, "avg_logprob": -0.10582746105429566, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.0006160740740597248}, {"id": 208, "seek": 151792, "start": 1518.0, "end": 1525.2, "text": " view of maybe a more expressive version of a pattern. You have documentation that's associated", "tokens": [50368, 1910, 295, 1310, 257, 544, 40189, 3037, 295, 257, 5102, 13, 509, 362, 14333, 300, 311, 6615, 50728], "temperature": 0.0, "avg_logprob": -0.06957007563391397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0006871369550935924}, {"id": 209, "seek": 151792, "start": 1525.2, "end": 1530.64, "text": " with it so the the pattern will have a schema diagram and all of the different ways that you", "tokens": [50728, 365, 309, 370, 264, 264, 5102, 486, 362, 257, 34078, 10686, 293, 439, 295, 264, 819, 2098, 300, 291, 51000], "temperature": 0.0, "avg_logprob": -0.06957007563391397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0006871369550935924}, {"id": 210, "seek": 151792, "start": 1530.64, "end": 1536.88, "text": " want to represent a pattern we're trying to codify into the into this model. There is an", "tokens": [51000, 528, 281, 2906, 257, 5102, 321, 434, 1382, 281, 17656, 2505, 666, 264, 666, 341, 2316, 13, 821, 307, 364, 51312], "temperature": 0.0, "avg_logprob": -0.06957007563391397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0006871369550935924}, {"id": 211, "seek": 151792, "start": 1536.88, "end": 1547.1200000000001, "text": " additional there's a base opala or opal which was published in 2016 from a number of people", "tokens": [51312, 4497, 456, 311, 257, 3096, 999, 5159, 420, 999, 304, 597, 390, 6572, 294, 6549, 490, 257, 1230, 295, 561, 51824], "temperature": 0.0, "avg_logprob": -0.06957007563391397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0006871369550935924}, {"id": 212, "seek": 154712, "start": 1547.12, "end": 1555.76, "text": " from the the community and we are kind of generating a new specification currently.", "tokens": [50364, 490, 264, 264, 1768, 293, 321, 366, 733, 295, 17746, 257, 777, 31256, 4362, 13, 50796], "temperature": 0.0, "avg_logprob": -0.08935923730173419, "compression_ratio": 1.4696132596685083, "no_speech_prob": 0.0003349892213009298}, {"id": 213, "seek": 154712, "start": 1557.76, "end": 1564.32, "text": " So modular ontology modeling now let's take a look at the actual methodology it's it's nine steps.", "tokens": [50896, 407, 31111, 6592, 1793, 15983, 586, 718, 311, 747, 257, 574, 412, 264, 3539, 24850, 309, 311, 309, 311, 4949, 4439, 13, 51224], "temperature": 0.0, "avg_logprob": -0.08935923730173419, "compression_ratio": 1.4696132596685083, "no_speech_prob": 0.0003349892213009298}, {"id": 214, "seek": 154712, "start": 1565.52, "end": 1572.8799999999999, "text": " We want to focus as I said largely on the empirical data-driven reality which means", "tokens": [51284, 492, 528, 281, 1879, 382, 286, 848, 11611, 322, 264, 31886, 1412, 12, 25456, 4103, 597, 1355, 51652], "temperature": 0.0, "avg_logprob": -0.08935923730173419, "compression_ratio": 1.4696132596685083, "no_speech_prob": 0.0003349892213009298}, {"id": 215, "seek": 157288, "start": 1572.88, "end": 1579.6000000000001, "text": " that we're not necessarily always concerned with the philosophical ramifications as we are with", "tokens": [50364, 300, 321, 434, 406, 4725, 1009, 5922, 365, 264, 25066, 10211, 7833, 382, 321, 366, 365, 50700], "temperature": 0.0, "avg_logprob": -0.09186697006225586, "compression_ratio": 1.6384180790960452, "no_speech_prob": 0.0037620982620865107}, {"id": 216, "seek": 157288, "start": 1579.6000000000001, "end": 1589.2800000000002, "text": " what can we model and what data is readily available or important to the use case at hand. So", "tokens": [50700, 437, 393, 321, 2316, 293, 437, 1412, 307, 26336, 2435, 420, 1021, 281, 264, 764, 1389, 412, 1011, 13, 407, 51184], "temperature": 0.0, "avg_logprob": -0.09186697006225586, "compression_ratio": 1.6384180790960452, "no_speech_prob": 0.0037620982620865107}, {"id": 217, "seek": 157288, "start": 1589.2800000000002, "end": 1597.2, "text": " you start with designing the use case with however whichever methodology that you want with use case", "tokens": [51184, 291, 722, 365, 14685, 264, 764, 1389, 365, 4461, 24123, 24850, 300, 291, 528, 365, 764, 1389, 51580], "temperature": 0.0, "avg_logprob": -0.09186697006225586, "compression_ratio": 1.6384180790960452, "no_speech_prob": 0.0037620982620865107}, {"id": 218, "seek": 159720, "start": 1597.2, "end": 1602.96, "text": " generation and this can you can draw from any number of knowledge elicitation frameworks.", "tokens": [50364, 5125, 293, 341, 393, 291, 393, 2642, 490, 604, 1230, 295, 3601, 806, 299, 4614, 29834, 13, 50652], "temperature": 0.0, "avg_logprob": -0.07546330117560052, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.02515491098165512}, {"id": 219, "seek": 159720, "start": 1604.16, "end": 1609.68, "text": " What we find to be particularly important and we call out here is the use of competency questions.", "tokens": [50712, 708, 321, 915, 281, 312, 4098, 1021, 293, 321, 818, 484, 510, 307, 264, 764, 295, 50097, 1651, 13, 50988], "temperature": 0.0, "avg_logprob": -0.07546330117560052, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.02515491098165512}, {"id": 220, "seek": 159720, "start": 1610.32, "end": 1613.92, "text": " I don't think this is particularly new to the ontology modeling community", "tokens": [51020, 286, 500, 380, 519, 341, 307, 4098, 777, 281, 264, 6592, 1793, 15983, 1768, 51200], "temperature": 0.0, "avg_logprob": -0.07546330117560052, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.02515491098165512}, {"id": 221, "seek": 159720, "start": 1614.96, "end": 1621.2, "text": " but it really helps you identify what the key notions are but also the interactions with the", "tokens": [51252, 457, 309, 534, 3665, 291, 5876, 437, 264, 2141, 35799, 366, 457, 611, 264, 13280, 365, 264, 51564], "temperature": 0.0, "avg_logprob": -0.07546330117560052, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.02515491098165512}, {"id": 222, "seek": 162120, "start": 1621.2, "end": 1628.24, "text": " data and this is really where the the empirical or data-driven reality aspect comes in because if", "tokens": [50364, 1412, 293, 341, 307, 534, 689, 264, 264, 31886, 420, 1412, 12, 25456, 4103, 4171, 1487, 294, 570, 498, 50716], "temperature": 0.0, "avg_logprob": -0.09044721632292776, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.02592664398252964}, {"id": 223, "seek": 162120, "start": 1628.24, "end": 1638.64, "text": " you can't really in natural language ask a question about it then what to what extent is it useful to", "tokens": [50716, 291, 393, 380, 534, 294, 3303, 2856, 1029, 257, 1168, 466, 309, 550, 437, 281, 437, 8396, 307, 309, 4420, 281, 51236], "temperature": 0.0, "avg_logprob": -0.09044721632292776, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.02592664398252964}, {"id": 224, "seek": 162120, "start": 1638.64, "end": 1646.4, "text": " model beyond that. There's probably some fighting words in that statement but at this top level", "tokens": [51236, 2316, 4399, 300, 13, 821, 311, 1391, 512, 5237, 2283, 294, 300, 5629, 457, 412, 341, 1192, 1496, 51624], "temperature": 0.0, "avg_logprob": -0.09044721632292776, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.02592664398252964}, {"id": 225, "seek": 164640, "start": 1646.48, "end": 1655.8400000000001, "text": " sort of of this address here we can sort of gloss over that for now. The the the interesting parts", "tokens": [50368, 1333, 295, 295, 341, 2985, 510, 321, 393, 1333, 295, 19574, 670, 300, 337, 586, 13, 440, 264, 264, 1880, 3166, 50836], "temperature": 0.0, "avg_logprob": -0.10043913570802603, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.003120491048321128}, {"id": 226, "seek": 164640, "start": 1655.8400000000001, "end": 1662.48, "text": " now are in steps four five and six which are really kind of what differentiate MOMO from other", "tokens": [50836, 586, 366, 294, 4439, 1451, 1732, 293, 2309, 597, 366, 534, 733, 295, 437, 23203, 46840, 46, 490, 661, 51168], "temperature": 0.0, "avg_logprob": -0.10043913570802603, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.003120491048321128}, {"id": 227, "seek": 164640, "start": 1665.2800000000002, "end": 1673.1200000000001, "text": " methodologies and that's really once you have the key notions for your use case which are extracted", "tokens": [51308, 3170, 6204, 293, 300, 311, 534, 1564, 291, 362, 264, 2141, 35799, 337, 428, 764, 1389, 597, 366, 34086, 51700], "temperature": 0.0, "avg_logprob": -0.10043913570802603, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.003120491048321128}, {"id": 228, "seek": 167312, "start": 1673.12, "end": 1678.2399999999998, "text": " from your data, your competency questions, your domain experts, what have you. You want to match", "tokens": [50364, 490, 428, 1412, 11, 428, 50097, 1651, 11, 428, 9274, 8572, 11, 437, 362, 291, 13, 509, 528, 281, 2995, 50620], "temperature": 0.0, "avg_logprob": -0.11659938587861902, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.009403458796441555}, {"id": 229, "seek": 167312, "start": 1678.2399999999998, "end": 1685.6799999999998, "text": " those the conceptual components that patterns model. We have resources that I'll display later on in", "tokens": [50620, 729, 264, 24106, 6677, 300, 8294, 2316, 13, 492, 362, 3593, 300, 286, 603, 4674, 1780, 322, 294, 50992], "temperature": 0.0, "avg_logprob": -0.11659938587861902, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.009403458796441555}, {"id": 230, "seek": 167312, "start": 1685.6799999999998, "end": 1694.6399999999999, "text": " the presentation about sorry about of all of the different patterns that we have and can be used", "tokens": [50992, 264, 5860, 466, 2597, 466, 295, 439, 295, 264, 819, 8294, 300, 321, 362, 293, 393, 312, 1143, 51440], "temperature": 0.0, "avg_logprob": -0.11659938587861902, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.009403458796441555}, {"id": 231, "seek": 167312, "start": 1695.52, "end": 1701.1999999999998, "text": " to sort of plug and play a schema together. The instantiation of the patterns is comes what", "tokens": [51484, 281, 1333, 295, 5452, 293, 862, 257, 34078, 1214, 13, 440, 9836, 6642, 295, 264, 8294, 307, 1487, 437, 51768], "temperature": 0.0, "avg_logprob": -0.11659938587861902, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.009403458796441555}, {"id": 232, "seek": 170120, "start": 1701.2, "end": 1709.52, "text": " comes next and that's really replacing the terms and properties of a pattern wholesale kind of like", "tokens": [50364, 1487, 958, 293, 300, 311, 534, 19139, 264, 2115, 293, 7221, 295, 257, 5102, 43982, 733, 295, 411, 50780], "temperature": 0.0, "avg_logprob": -0.10544560505793645, "compression_ratio": 1.5921787709497206, "no_speech_prob": 0.0010478462791070342}, {"id": 233, "seek": 170120, "start": 1709.52, "end": 1716.56, "text": " a template starting with maybe like madlib style. You're not subclassing a pattern you're just", "tokens": [50780, 257, 12379, 2891, 365, 1310, 411, 5244, 38270, 3758, 13, 509, 434, 406, 1422, 11665, 278, 257, 5102, 291, 434, 445, 51132], "temperature": 0.0, "avg_logprob": -0.10544560505793645, "compression_ratio": 1.5921787709497206, "no_speech_prob": 0.0010478462791070342}, {"id": 234, "seek": 170120, "start": 1717.28, "end": 1724.32, "text": " using the structure of the pattern over and over again. In step six we have the systematic", "tokens": [51168, 1228, 264, 3877, 295, 264, 5102, 670, 293, 670, 797, 13, 682, 1823, 2309, 321, 362, 264, 27249, 51520], "temperature": 0.0, "avg_logprob": -0.10544560505793645, "compression_ratio": 1.5921787709497206, "no_speech_prob": 0.0010478462791070342}, {"id": 235, "seek": 172432, "start": 1724.32, "end": 1732.96, "text": " axiomatization which is once you have your patterns and you look at the schema diagram", "tokens": [50364, 6360, 72, 34295, 2144, 597, 307, 1564, 291, 362, 428, 8294, 293, 291, 574, 412, 264, 34078, 10686, 50796], "temperature": 0.0, "avg_logprob": -0.06358624093326522, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.01449529454112053}, {"id": 236, "seek": 172432, "start": 1732.96, "end": 1740.0, "text": " for your different modules and your different patterns is you go edge by edge within your", "tokens": [50796, 337, 428, 819, 16679, 293, 428, 819, 8294, 307, 291, 352, 4691, 538, 4691, 1951, 428, 51148], "temperature": 0.0, "avg_logprob": -0.06358624093326522, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.01449529454112053}, {"id": 237, "seek": 172432, "start": 1740.0, "end": 1746.8, "text": " schema diagram and you assign the ontological meaning of what that top level intuitive conceptual", "tokens": [51148, 34078, 10686, 293, 291, 6269, 264, 6592, 4383, 3620, 295, 437, 300, 1192, 1496, 21769, 24106, 51488], "temperature": 0.0, "avg_logprob": -0.06358624093326522, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.01449529454112053}, {"id": 238, "seek": 172432, "start": 1746.8, "end": 1753.4399999999998, "text": " relationship is. I won't get into that so much within this talk but what we have here is the", "tokens": [51488, 2480, 307, 13, 286, 1582, 380, 483, 666, 300, 370, 709, 1951, 341, 751, 457, 437, 321, 362, 510, 307, 264, 51820], "temperature": 0.0, "avg_logprob": -0.06358624093326522, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.01449529454112053}, {"id": 239, "seek": 175344, "start": 1753.44, "end": 1758.88, "text": " modular ontology modeling published in the semantic web journal and you should be able to", "tokens": [50364, 31111, 6592, 1793, 15983, 6572, 294, 264, 47982, 3670, 6708, 293, 291, 820, 312, 1075, 281, 50636], "temperature": 0.0, "avg_logprob": -0.08878769018711188, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0007319061551243067}, {"id": 240, "seek": 175344, "start": 1758.88, "end": 1765.28, "text": " kind of get a lot more information on the exact processes within this methodology from there.", "tokens": [50636, 733, 295, 483, 257, 688, 544, 1589, 322, 264, 1900, 7555, 1951, 341, 24850, 490, 456, 13, 50956], "temperature": 0.0, "avg_logprob": -0.08878769018711188, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0007319061551243067}, {"id": 241, "seek": 175344, "start": 1766.0, "end": 1772.56, "text": " After that you plug all of the modules together with quite literally like puzzle pieces you review", "tokens": [50992, 2381, 300, 291, 5452, 439, 295, 264, 16679, 1214, 365, 1596, 3736, 411, 12805, 3755, 291, 3131, 51320], "temperature": 0.0, "avg_logprob": -0.08878769018711188, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0007319061551243067}, {"id": 242, "seek": 175344, "start": 1772.56, "end": 1779.76, "text": " the final product add any more axioms that you think are useful across the entire assembled", "tokens": [51320, 264, 2572, 1674, 909, 604, 544, 6360, 72, 4785, 300, 291, 519, 366, 4420, 2108, 264, 2302, 24204, 51680], "temperature": 0.0, "avg_logprob": -0.08878769018711188, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0007319061551243067}, {"id": 243, "seek": 177976, "start": 1780.56, "end": 1783.04, "text": " schema and then you produce your owl artifact.", "tokens": [50404, 34078, 293, 550, 291, 5258, 428, 34488, 34806, 13, 50528], "temperature": 0.0, "avg_logprob": -0.1282717330115182, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.002250105608254671}, {"id": 244, "seek": 177976, "start": 1785.44, "end": 1793.92, "text": " So that was really Momo in a nutshell. So what I have here are a few examples three actually I", "tokens": [50648, 407, 300, 390, 534, 47984, 294, 257, 37711, 13, 407, 437, 286, 362, 510, 366, 257, 1326, 5110, 1045, 767, 286, 51072], "temperature": 0.0, "avg_logprob": -0.1282717330115182, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.002250105608254671}, {"id": 245, "seek": 177976, "start": 1793.92, "end": 1801.36, "text": " think and then a brief discussion on the template based instantiation that we utilize for Momo and", "tokens": [51072, 519, 293, 550, 257, 5353, 5017, 322, 264, 12379, 2361, 9836, 6642, 300, 321, 16117, 337, 47984, 293, 51444], "temperature": 0.0, "avg_logprob": -0.1282717330115182, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.002250105608254671}, {"id": 246, "seek": 180136, "start": 1801.4399999999998, "end": 1810.7199999999998, "text": " how it kind of connects or is quite obviously parallel to the sort of DOSP strategy employed", "tokens": [50368, 577, 309, 733, 295, 16967, 420, 307, 1596, 2745, 8952, 281, 264, 1333, 295, 413, 4367, 47, 5206, 20115, 50832], "temperature": 0.0, "avg_logprob": -0.11039853383259601, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.019108714535832405}, {"id": 247, "seek": 180136, "start": 1810.7199999999998, "end": 1817.4399999999998, "text": " within the oboe community. So this first pattern that we have here is a pattern for depicting", "tokens": [50832, 1951, 264, 1111, 7921, 1768, 13, 407, 341, 700, 5102, 300, 321, 362, 510, 307, 257, 5102, 337, 1367, 21490, 51168], "temperature": 0.0, "avg_logprob": -0.11039853383259601, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.019108714535832405}, {"id": 248, "seek": 180136, "start": 1817.4399999999998, "end": 1821.52, "text": " causal relationships between events this is something that came out of the nowhere graph", "tokens": [51168, 38755, 6159, 1296, 3931, 341, 307, 746, 300, 1361, 484, 295, 264, 11159, 4295, 51372], "temperature": 0.0, "avg_logprob": -0.11039853383259601, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.019108714535832405}, {"id": 249, "seek": 180136, "start": 1822.1599999999999, "end": 1828.7199999999998, "text": " project actually the next two patterns are as well but I kind of want to show you here how you", "tokens": [51404, 1716, 767, 264, 958, 732, 8294, 366, 382, 731, 457, 286, 733, 295, 528, 281, 855, 291, 510, 577, 291, 51732], "temperature": 0.0, "avg_logprob": -0.11039853383259601, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.019108714535832405}, {"id": 250, "seek": 182872, "start": 1828.72, "end": 1834.88, "text": " have a pattern and then you also have a module within the pattern right this abstract event", "tokens": [50364, 362, 257, 5102, 293, 550, 291, 611, 362, 257, 10088, 1951, 264, 5102, 558, 341, 12649, 2280, 50672], "temperature": 0.0, "avg_logprob": -0.1335834076530055, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.005217353347688913}, {"id": 251, "seek": 182872, "start": 1835.44, "end": 1842.16, "text": " compared to this events this concrete notion of event event for those of you who are familiar with", "tokens": [50700, 5347, 281, 341, 3931, 341, 9859, 10710, 295, 2280, 2280, 337, 729, 295, 291, 567, 366, 4963, 365, 51036], "temperature": 0.0, "avg_logprob": -0.1335834076530055, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.005217353347688913}, {"id": 252, "seek": 182872, "start": 1843.84, "end": 1850.24, "text": " the upper ontology sphere this would probably be easily modeled as", "tokens": [51120, 264, 6597, 6592, 1793, 16687, 341, 576, 1391, 312, 3612, 37140, 382, 51440], "temperature": 0.0, "avg_logprob": -0.1335834076530055, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.005217353347688913}, {"id": 253, "seek": 182872, "start": 1850.88, "end": 1855.68, "text": " your sort of perjure and endurance thing because you have a description in a situation you have", "tokens": [51472, 428, 1333, 295, 680, 73, 540, 293, 30325, 551, 570, 291, 362, 257, 3855, 294, 257, 2590, 291, 362, 51712], "temperature": 0.0, "avg_logprob": -0.1335834076530055, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.005217353347688913}, {"id": 254, "seek": 185568, "start": 1855.76, "end": 1860.8, "text": " this thing that exists in time and thing that exists out of time but from a pattern perspective", "tokens": [50368, 341, 551, 300, 8198, 294, 565, 293, 551, 300, 8198, 484, 295, 565, 457, 490, 257, 5102, 4585, 50620], "temperature": 0.0, "avg_logprob": -0.05464644156969511, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.009120991453528404}, {"id": 255, "seek": 185568, "start": 1860.8, "end": 1866.0800000000002, "text": " the exact implementation of this doesn't matter and that's kind of the point you can implement", "tokens": [50620, 264, 1900, 11420, 295, 341, 1177, 380, 1871, 293, 300, 311, 733, 295, 264, 935, 291, 393, 4445, 50884], "temperature": 0.0, "avg_logprob": -0.05464644156969511, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.009120991453528404}, {"id": 256, "seek": 185568, "start": 1866.0800000000002, "end": 1871.44, "text": " this pattern using an upper ontology or you could call it whatever you want like event concrete", "tokens": [50884, 341, 5102, 1228, 364, 6597, 6592, 1793, 420, 291, 727, 818, 309, 2035, 291, 528, 411, 2280, 9859, 51152], "temperature": 0.0, "avg_logprob": -0.05464644156969511, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.009120991453528404}, {"id": 257, "seek": 185568, "start": 1871.44, "end": 1877.1200000000001, "text": " which is maybe not a great name but kind of gets the point across. These blue boxes with the dashed", "tokens": [51152, 597, 307, 1310, 406, 257, 869, 1315, 457, 733, 295, 2170, 264, 935, 2108, 13, 1981, 3344, 9002, 365, 264, 8240, 292, 51436], "temperature": 0.0, "avg_logprob": -0.05464644156969511, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.009120991453528404}, {"id": 258, "seek": 185568, "start": 1877.1200000000001, "end": 1884.48, "text": " lines are what we call the interfaces I said earlier conceptual components but you can kind", "tokens": [51436, 3876, 366, 437, 321, 818, 264, 28416, 286, 848, 3071, 24106, 6677, 457, 291, 393, 733, 51804], "temperature": 0.0, "avg_logprob": -0.05464644156969511, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.009120991453528404}, {"id": 259, "seek": 188448, "start": 1884.48, "end": 1890.64, "text": " of think of them as interfaces from software engineering because they are an implementation", "tokens": [50364, 295, 519, 295, 552, 382, 28416, 490, 4722, 7043, 570, 436, 366, 364, 11420, 50672], "temperature": 0.0, "avg_logprob": -0.05850333932005329, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.012415873818099499}, {"id": 260, "seek": 188448, "start": 1890.64, "end": 1897.04, "text": " they are a hook within this pattern that says right here belongs anything that is a model of", "tokens": [50672, 436, 366, 257, 6328, 1951, 341, 5102, 300, 1619, 558, 510, 12953, 1340, 300, 307, 257, 2316, 295, 50992], "temperature": 0.0, "avg_logprob": -0.05850333932005329, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.012415873818099499}, {"id": 261, "seek": 188448, "start": 1897.04, "end": 1903.84, "text": " what an observation is or anything here can be fulfilled by something that sort of adheres to", "tokens": [50992, 437, 364, 14816, 307, 420, 1340, 510, 393, 312, 21380, 538, 746, 300, 1333, 295, 614, 19464, 281, 51332], "temperature": 0.0, "avg_logprob": -0.05850333932005329, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.012415873818099499}, {"id": 262, "seek": 188448, "start": 1903.84, "end": 1912.32, "text": " the contract of what a spatiotemporal extent is and we just note that with with the blue box", "tokens": [51332, 264, 4364, 295, 437, 257, 15000, 6471, 11840, 304, 8396, 307, 293, 321, 445, 3637, 300, 365, 365, 264, 3344, 2424, 51756], "temperature": 0.0, "avg_logprob": -0.05850333932005329, "compression_ratio": 1.7836538461538463, "no_speech_prob": 0.012415873818099499}, {"id": 263, "seek": 191232, "start": 1913.12, "end": 1919.04, "text": " and so you can replace that blue box with an entire new pattern or you can kind of just", "tokens": [50404, 293, 370, 291, 393, 7406, 300, 3344, 2424, 365, 364, 2302, 777, 5102, 420, 291, 393, 733, 295, 445, 50700], "temperature": 0.0, "avg_logprob": -0.05320431720251324, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.020012658089399338}, {"id": 264, "seek": 191232, "start": 1919.04, "end": 1926.8, "text": " drop it away and have it something very simplistic like a stub and so on and so this", "tokens": [50700, 3270, 309, 1314, 293, 362, 309, 746, 588, 44199, 411, 257, 20266, 293, 370, 322, 293, 370, 341, 51088], "temperature": 0.0, "avg_logprob": -0.05320431720251324, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.020012658089399338}, {"id": 265, "seek": 191232, "start": 1926.8, "end": 1936.3999999999999, "text": " is how we do that and this is also what allows it to kind of for people to kind of conceptualize", "tokens": [51088, 307, 577, 321, 360, 300, 293, 341, 307, 611, 437, 4045, 309, 281, 733, 295, 337, 561, 281, 733, 295, 24106, 1125, 51568], "temperature": 0.0, "avg_logprob": -0.05320431720251324, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.020012658089399338}, {"id": 266, "seek": 191232, "start": 1936.3999999999999, "end": 1941.84, "text": " these as puzzle pieces because you take your spatiotemporal extent pattern you plug it in", "tokens": [51568, 613, 382, 12805, 3755, 570, 291, 747, 428, 15000, 6471, 11840, 304, 8396, 5102, 291, 5452, 309, 294, 51840], "temperature": 0.0, "avg_logprob": -0.05320431720251324, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.020012658089399338}, {"id": 267, "seek": 194184, "start": 1941.84, "end": 1947.28, "text": " quite literally like a puzzle piece into the spatiotemporal interface within the schema diagram", "tokens": [50364, 1596, 3736, 411, 257, 12805, 2522, 666, 264, 15000, 6471, 11840, 304, 9226, 1951, 264, 34078, 10686, 50636], "temperature": 0.0, "avg_logprob": -0.055959019550057346, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.004606395494192839}, {"id": 268, "seek": 194184, "start": 1947.28, "end": 1952.1599999999999, "text": " and then you just build out your patterns and you modify them to your use case and then you're", "tokens": [50636, 293, 550, 291, 445, 1322, 484, 428, 8294, 293, 291, 16927, 552, 281, 428, 764, 1389, 293, 550, 291, 434, 50880], "temperature": 0.0, "avg_logprob": -0.055959019550057346, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.004606395494192839}, {"id": 269, "seek": 194184, "start": 1952.1599999999999, "end": 1958.9599999999998, "text": " done right that's kind of the strength of what we're trying to do here is by leveraging these", "tokens": [50880, 1096, 558, 300, 311, 733, 295, 264, 3800, 295, 437, 321, 434, 1382, 281, 360, 510, 307, 538, 32666, 613, 51220], "temperature": 0.0, "avg_logprob": -0.055959019550057346, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.004606395494192839}, {"id": 270, "seek": 194184, "start": 1958.9599999999998, "end": 1965.36, "text": " patterns and the fact that all of the ontological analysis has already been done it's really just", "tokens": [51220, 8294, 293, 264, 1186, 300, 439, 295, 264, 6592, 4383, 5215, 575, 1217, 668, 1096, 309, 311, 534, 445, 51540], "temperature": 0.0, "avg_logprob": -0.055959019550057346, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.004606395494192839}, {"id": 271, "seek": 196536, "start": 1965.36, "end": 1971.9199999999998, "text": " the assembly and configuration for your use case that drives the the usefulness of this", "tokens": [50364, 264, 12103, 293, 11694, 337, 428, 764, 1389, 300, 11754, 264, 264, 4420, 1287, 295, 341, 50692], "temperature": 0.0, "avg_logprob": -0.09619992239433423, "compression_ratio": 1.5529411764705883, "no_speech_prob": 0.009856205433607101}, {"id": 272, "seek": 196536, "start": 1978.08, "end": 1982.1599999999999, "text": " okay I accidentally reordered these sorry for flipping through a few slides there", "tokens": [51000, 1392, 286, 15715, 319, 765, 4073, 613, 2597, 337, 26886, 807, 257, 1326, 9788, 456, 51204], "temperature": 0.0, "avg_logprob": -0.09619992239433423, "compression_ratio": 1.5529411764705883, "no_speech_prob": 0.009856205433607101}, {"id": 273, "seek": 196536, "start": 1982.1599999999999, "end": 1989.4399999999998, "text": " this is another example here of of a pattern we have two interfaces this time but now actually", "tokens": [51204, 341, 307, 1071, 1365, 510, 295, 295, 257, 5102, 321, 362, 732, 28416, 341, 565, 457, 586, 767, 51568], "temperature": 0.0, "avg_logprob": -0.09619992239433423, "compression_ratio": 1.5529411764705883, "no_speech_prob": 0.009856205433607101}, {"id": 274, "seek": 198944, "start": 1989.44, "end": 1996.16, "text": " what we have here is this purple box which is really just a controlled vocabulary it's this", "tokens": [50364, 437, 321, 362, 510, 307, 341, 9656, 2424, 597, 307, 534, 445, 257, 10164, 19864, 309, 311, 341, 50700], "temperature": 0.0, "avg_logprob": -0.10008978843688965, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036187272518873215}, {"id": 275, "seek": 198944, "start": 1996.16, "end": 2005.3600000000001, "text": " it's it's just another sort of um technicolor idiosyncrasy for our um presentation or our schema", "tokens": [50700, 309, 311, 309, 311, 445, 1071, 1333, 295, 1105, 1537, 299, 36182, 4496, 2717, 34015, 3906, 88, 337, 527, 1105, 5860, 420, 527, 34078, 51160], "temperature": 0.0, "avg_logprob": -0.10008978843688965, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036187272518873215}, {"id": 276, "seek": 198944, "start": 2005.3600000000001, "end": 2012.88, "text": " diagram presentation and it's really just saying that the the class of organization scheme consists", "tokens": [51160, 10686, 5860, 293, 309, 311, 534, 445, 1566, 300, 264, 264, 1508, 295, 4475, 12232, 14689, 51536], "temperature": 0.0, "avg_logprob": -0.10008978843688965, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.036187272518873215}, {"id": 277, "seek": 201288, "start": 2012.88, "end": 2020.48, "text": " of strictly a set number of individuals not particularly exciting but it's something that", "tokens": [50364, 295, 20792, 257, 992, 1230, 295, 5346, 406, 4098, 4670, 457, 309, 311, 746, 300, 50744], "temperature": 0.0, "avg_logprob": -0.05175578594207764, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.008184901438653469}, {"id": 278, "seek": 201288, "start": 2020.48, "end": 2030.0, "text": " we can model and is sometimes extremely convenient to to model even at the pattern level and then", "tokens": [50744, 321, 393, 2316, 293, 307, 2171, 4664, 10851, 281, 281, 2316, 754, 412, 264, 5102, 1496, 293, 550, 51220], "temperature": 0.0, "avg_logprob": -0.05175578594207764, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.008184901438653469}, {"id": 279, "seek": 201288, "start": 2030.0, "end": 2035.92, "text": " doing it explicitly like this instead of having a subsumption hierarchy somewhere in the background", "tokens": [51220, 884, 309, 20803, 411, 341, 2602, 295, 1419, 257, 2090, 449, 1695, 22333, 4079, 294, 264, 3678, 51516], "temperature": 0.0, "avg_logprob": -0.05175578594207764, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.008184901438653469}, {"id": 280, "seek": 201288, "start": 2035.92, "end": 2042.4, "text": " it means that there's really no change to the ontology when you add in a new instance for", "tokens": [51516, 309, 1355, 300, 456, 311, 534, 572, 1319, 281, 264, 6592, 1793, 562, 291, 909, 294, 257, 777, 5197, 337, 51840], "temperature": 0.0, "avg_logprob": -0.05175578594207764, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.008184901438653469}, {"id": 281, "seek": 204240, "start": 2042.4, "end": 2048.56, "text": " example here of the organization scheme in this case you would replace custom with whatever you want", "tokens": [50364, 1365, 510, 295, 264, 4475, 12232, 294, 341, 1389, 291, 576, 7406, 2375, 365, 2035, 291, 528, 50672], "temperature": 0.0, "avg_logprob": -0.08813527373016858, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00033526713377796113}, {"id": 282, "seek": 204240, "start": 2049.52, "end": 2055.12, "text": " because custom kind of doesn't belong in the in the in the pattern here um", "tokens": [50720, 570, 2375, 733, 295, 1177, 380, 5784, 294, 264, 294, 264, 294, 264, 5102, 510, 1105, 51000], "temperature": 0.0, "avg_logprob": -0.08813527373016858, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00033526713377796113}, {"id": 283, "seek": 204240, "start": 2057.28, "end": 2064.8, "text": " keep moving on uh so this final pattern example that we have here this is a pattern for depicting", "tokens": [51108, 1066, 2684, 322, 2232, 370, 341, 2572, 5102, 1365, 300, 321, 362, 510, 341, 307, 257, 5102, 337, 1367, 21490, 51484], "temperature": 0.0, "avg_logprob": -0.08813527373016858, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00033526713377796113}, {"id": 284, "seek": 206480, "start": 2064.8, "end": 2072.8, "text": " features of s2 cells or any cell in a hierarchical grid so let me back up there a little bit what we", "tokens": [50364, 4122, 295, 262, 17, 5438, 420, 604, 2815, 294, 257, 35250, 804, 10748, 370, 718, 385, 646, 493, 456, 257, 707, 857, 437, 321, 50764], "temperature": 0.0, "avg_logprob": -0.07209511513405657, "compression_ratio": 1.8439024390243903, "no_speech_prob": 0.2686708867549896}, {"id": 285, "seek": 206480, "start": 2072.8, "end": 2080.4, "text": " have are these cells um and the cell is really just a geometry a tessellated geometry across the", "tokens": [50764, 362, 366, 613, 5438, 1105, 293, 264, 2815, 307, 534, 445, 257, 18426, 257, 256, 7357, 285, 770, 18426, 2108, 264, 51144], "temperature": 0.0, "avg_logprob": -0.07209511513405657, "compression_ratio": 1.8439024390243903, "no_speech_prob": 0.2686708867549896}, {"id": 286, "seek": 206480, "start": 2080.4, "end": 2086.6400000000003, "text": " surface of the earth or any body really but in this case let's let's just stick with the earth", "tokens": [51144, 3753, 295, 264, 4120, 420, 604, 1772, 534, 457, 294, 341, 1389, 718, 311, 718, 311, 445, 2897, 365, 264, 4120, 51456], "temperature": 0.0, "avg_logprob": -0.07209511513405657, "compression_ratio": 1.8439024390243903, "no_speech_prob": 0.2686708867549896}, {"id": 287, "seek": 206480, "start": 2086.6400000000003, "end": 2092.0, "text": " and then what you have is these cells are hierarchical so four cells make up the next", "tokens": [51456, 293, 550, 437, 291, 362, 307, 613, 5438, 366, 35250, 804, 370, 1451, 5438, 652, 493, 264, 958, 51724], "temperature": 0.0, "avg_logprob": -0.07209511513405657, "compression_ratio": 1.8439024390243903, "no_speech_prob": 0.2686708867549896}, {"id": 288, "seek": 209200, "start": 2092.08, "end": 2098.56, "text": " tessellated geometry and it just up and up and up and so s2 um is one particular", "tokens": [50368, 256, 7357, 285, 770, 18426, 293, 309, 445, 493, 293, 493, 293, 493, 293, 370, 262, 17, 1105, 307, 472, 1729, 50692], "temperature": 0.0, "avg_logprob": -0.06379254659016927, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.0022864171769469976}, {"id": 289, "seek": 209200, "start": 2099.28, "end": 2105.36, "text": " version of this and that's employed by google and it's really just um four cells make up the next", "tokens": [50728, 3037, 295, 341, 293, 300, 311, 20115, 538, 20742, 293, 309, 311, 534, 445, 1105, 1451, 5438, 652, 493, 264, 958, 51032], "temperature": 0.0, "avg_logprob": -0.06379254659016927, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.0022864171769469976}, {"id": 290, "seek": 209200, "start": 2105.36, "end": 2113.04, "text": " larger cell and then four of those make up there and um there's also a way to do this using hexagons", "tokens": [51032, 4833, 2815, 293, 550, 1451, 295, 729, 652, 493, 456, 293, 1105, 456, 311, 611, 257, 636, 281, 360, 341, 1228, 23291, 559, 892, 51416], "temperature": 0.0, "avg_logprob": -0.06379254659016927, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.0022864171769469976}, {"id": 291, "seek": 209200, "start": 2113.04, "end": 2119.6, "text": " that's called h3 using it out of uber but really what um what's interesting about this", "tokens": [51416, 300, 311, 1219, 276, 18, 1228, 309, 484, 295, 344, 607, 457, 534, 437, 1105, 437, 311, 1880, 466, 341, 51744], "temperature": 0.0, "avg_logprob": -0.06379254659016927, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.0022864171769469976}, {"id": 292, "seek": 211960, "start": 2119.6, "end": 2126.4, "text": " are these red arrows i mentioned earlier that sometimes it's useful to have these", "tokens": [50364, 366, 613, 2182, 19669, 741, 2835, 3071, 300, 2171, 309, 311, 4420, 281, 362, 613, 50704], "temperature": 0.0, "avg_logprob": -0.11669684238121157, "compression_ratio": 1.5857988165680474, "no_speech_prob": 0.021928496658802032}, {"id": 293, "seek": 211960, "start": 2126.96, "end": 2134.3199999999997, "text": " shortcuts within a pattern a simplified view right so when you have a cell and you want to", "tokens": [50732, 34620, 1951, 257, 5102, 257, 26335, 1910, 558, 370, 562, 291, 362, 257, 2815, 293, 291, 528, 281, 51100], "temperature": 0.0, "avg_logprob": -0.11669684238121157, "compression_ratio": 1.5857988165680474, "no_speech_prob": 0.021928496658802032}, {"id": 294, "seek": 211960, "start": 2134.3199999999997, "end": 2145.36, "text": " represent it uh using geosparcle or um using some sort of uh geo informational science standard", "tokens": [51100, 2906, 309, 2232, 1228, 1519, 2763, 289, 2160, 420, 1105, 1228, 512, 1333, 295, 2232, 1519, 78, 49391, 3497, 3832, 51652], "temperature": 0.0, "avg_logprob": -0.11669684238121157, "compression_ratio": 1.5857988165680474, "no_speech_prob": 0.021928496658802032}, {"id": 295, "seek": 214536, "start": 2145.36, "end": 2152.32, "text": " way you disconnect the cell as a concept from its geometry uh which is the literal that describes", "tokens": [50364, 636, 291, 14299, 264, 2815, 382, 257, 3410, 490, 1080, 18426, 2232, 597, 307, 264, 20411, 300, 15626, 50712], "temperature": 0.0, "avg_logprob": -0.05743888058239901, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.037288516759872437}, {"id": 296, "seek": 214536, "start": 2152.32, "end": 2157.44, "text": " the sort of boundary points of the cell and then the spatial relations actually occur between the", "tokens": [50712, 264, 1333, 295, 12866, 2793, 295, 264, 2815, 293, 550, 264, 23598, 2299, 767, 5160, 1296, 264, 50968], "temperature": 0.0, "avg_logprob": -0.05743888058239901, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.037288516759872437}, {"id": 297, "seek": 214536, "start": 2157.44, "end": 2163.28, "text": " geometries not technically between the cells however when you're querying generally you want to", "tokens": [50968, 12956, 2244, 406, 12120, 1296, 264, 5438, 4461, 562, 291, 434, 7083, 1840, 5101, 291, 528, 281, 51260], "temperature": 0.0, "avg_logprob": -0.05743888058239901, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.037288516759872437}, {"id": 298, "seek": 214536, "start": 2164.1600000000003, "end": 2169.36, "text": " know how the things are spatially related at a human level and not just these arbitrary", "tokens": [51304, 458, 577, 264, 721, 366, 15000, 2270, 4077, 412, 257, 1952, 1496, 293, 406, 445, 613, 23211, 51564], "temperature": 0.0, "avg_logprob": -0.05743888058239901, "compression_ratio": 1.7465437788018434, "no_speech_prob": 0.037288516759872437}, {"id": 299, "seek": 216936, "start": 2169.36, "end": 2176.7200000000003, "text": " geometries that exist um under the hood and so having a way to specifically represent these", "tokens": [50364, 12956, 2244, 300, 2514, 1105, 833, 264, 13376, 293, 370, 1419, 257, 636, 281, 4682, 2906, 613, 50732], "temperature": 0.0, "avg_logprob": -0.0730321739293352, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.03306872770190239}, {"id": 300, "seek": 216936, "start": 2177.6, "end": 2183.36, "text": " within the schema diagram useful but also logically under the hood um as a sort of", "tokens": [50776, 1951, 264, 34078, 10686, 4420, 457, 611, 38887, 833, 264, 13376, 1105, 382, 257, 1333, 295, 51064], "temperature": 0.0, "avg_logprob": -0.0730321739293352, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.03306872770190239}, {"id": 301, "seek": 216936, "start": 2183.36, "end": 2191.84, "text": " roll chain is also is also useful uh and we use the opal annotations for the different um", "tokens": [51064, 3373, 5021, 307, 611, 307, 611, 4420, 2232, 293, 321, 764, 264, 999, 304, 25339, 763, 337, 264, 819, 1105, 51488], "temperature": 0.0, "avg_logprob": -0.0730321739293352, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.03306872770190239}, {"id": 302, "seek": 216936, "start": 2194.0, "end": 2198.48, "text": " excuse me for the different shortcuts to say well this is this one's optional you", "tokens": [51596, 8960, 385, 337, 264, 819, 34620, 281, 584, 731, 341, 307, 341, 472, 311, 17312, 291, 51820], "temperature": 0.0, "avg_logprob": -0.0730321739293352, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.03306872770190239}, {"id": 303, "seek": 219848, "start": 2198.48, "end": 2204.64, "text": " don't have to actually materialize this because it's it's part of the pattern but only in so far", "tokens": [50364, 500, 380, 362, 281, 767, 2527, 1125, 341, 570, 309, 311, 309, 311, 644, 295, 264, 5102, 457, 787, 294, 370, 1400, 50672], "temperature": 0.0, "avg_logprob": -0.09937127431233723, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041714415419846773}, {"id": 304, "seek": 219848, "start": 2204.64, "end": 2213.92, "text": " that you may want to simplify this for for other other people um so for example going from cells", "tokens": [50672, 300, 291, 815, 528, 281, 20460, 341, 337, 337, 661, 661, 561, 1105, 370, 337, 1365, 516, 490, 5438, 51136], "temperature": 0.0, "avg_logprob": -0.09937127431233723, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041714415419846773}, {"id": 305, "seek": 219848, "start": 2213.92, "end": 2220.32, "text": " the attribute of the particular feature that simplifies three hops with an inverse in there", "tokens": [51136, 264, 19667, 295, 264, 1729, 4111, 300, 6883, 11221, 1045, 47579, 365, 364, 17340, 294, 456, 51456], "temperature": 0.0, "avg_logprob": -0.09937127431233723, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041714415419846773}, {"id": 306, "seek": 219848, "start": 2220.32, "end": 2227.12, "text": " into one simple thing uh but you lose a lot of the expressiveness um and uh the ontological", "tokens": [51456, 666, 472, 2199, 551, 2232, 457, 291, 3624, 257, 688, 295, 264, 5109, 8477, 1105, 293, 2232, 264, 6592, 4383, 51796], "temperature": 0.0, "avg_logprob": -0.09937127431233723, "compression_ratio": 1.737327188940092, "no_speech_prob": 0.00041714415419846773}, {"id": 307, "seek": 222712, "start": 2227.12, "end": 2235.52, "text": " pitchness there so there's there are some tradeoffs uh finally um as one of our examples", "tokens": [50364, 7293, 1287, 456, 370, 456, 311, 456, 366, 512, 4923, 19231, 2232, 2721, 1105, 382, 472, 295, 527, 5110, 50784], "temperature": 0.0, "avg_logprob": -0.09996710504804339, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.001324244774878025}, {"id": 308, "seek": 222712, "start": 2235.52, "end": 2246.3199999999997, "text": " this here on the left is the kwg core ontology um and the sosa ssn kernel that we use uh the core", "tokens": [50784, 341, 510, 322, 264, 1411, 307, 264, 23846, 70, 4965, 6592, 1793, 1105, 293, 264, 262, 6447, 262, 18860, 28256, 300, 321, 764, 2232, 264, 4965, 51324], "temperature": 0.0, "avg_logprob": -0.09996710504804339, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.001324244774878025}, {"id": 309, "seek": 222712, "start": 2246.3199999999997, "end": 2252.72, "text": " is really just the four main concepts that we have and some very basic relationships it's", "tokens": [51324, 307, 534, 445, 264, 1451, 2135, 10392, 300, 321, 362, 293, 512, 588, 3875, 6159, 309, 311, 51644], "temperature": 0.0, "avg_logprob": -0.09996710504804339, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.001324244774878025}, {"id": 310, "seek": 225272, "start": 2252.72, "end": 2258.8799999999997, "text": " obviously much more built out within the ontology uh itself but from a schema diagrammatic um and", "tokens": [50364, 2745, 709, 544, 3094, 484, 1951, 264, 6592, 1793, 2232, 2564, 457, 490, 257, 34078, 10686, 25915, 1105, 293, 50672], "temperature": 0.0, "avg_logprob": -0.06285776250502642, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.004397897981107235}, {"id": 311, "seek": 225272, "start": 2258.8799999999997, "end": 2265.9199999999996, "text": " also from this nice compact view it's useful to only include a couple of these pieces um", "tokens": [50672, 611, 490, 341, 1481, 14679, 1910, 309, 311, 4420, 281, 787, 4090, 257, 1916, 295, 613, 3755, 1105, 51024], "temperature": 0.0, "avg_logprob": -0.06285776250502642, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.004397897981107235}, {"id": 312, "seek": 225272, "start": 2267.4399999999996, "end": 2273.6, "text": " but it connects into this kernel and then this kernel um the sosa ssn kernel this pattern that", "tokens": [51100, 457, 309, 16967, 666, 341, 28256, 293, 550, 341, 28256, 1105, 264, 262, 6447, 262, 18860, 28256, 341, 5102, 300, 51408], "temperature": 0.0, "avg_logprob": -0.06285776250502642, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.004397897981107235}, {"id": 313, "seek": 225272, "start": 2273.6, "end": 2280.64, "text": " we've extracted essentially from that ontology we just essentially mint um or not mint we stamp", "tokens": [51408, 321, 600, 34086, 4476, 490, 300, 6592, 1793, 321, 445, 4476, 18189, 1105, 420, 406, 18189, 321, 9921, 51760], "temperature": 0.0, "avg_logprob": -0.06285776250502642, "compression_ratio": 1.7293577981651376, "no_speech_prob": 0.004397897981107235}, {"id": 314, "seek": 228064, "start": 2280.64, "end": 2287.04, "text": " over and over again one per data set uh how this connects right so the feature of interest remains", "tokens": [50364, 670, 293, 670, 797, 472, 680, 1412, 992, 2232, 577, 341, 16967, 558, 370, 264, 4111, 295, 1179, 7023, 50684], "temperature": 0.0, "avg_logprob": -0.10003738219921406, "compression_ratio": 1.9352226720647774, "no_speech_prob": 0.0037060771137475967}, {"id": 315, "seek": 228064, "start": 2287.04, "end": 2293.04, "text": " the same uh because it's the superclass but this observation that we have here within the kernel", "tokens": [50684, 264, 912, 2232, 570, 309, 311, 264, 1687, 11665, 457, 341, 14816, 300, 321, 362, 510, 1951, 264, 28256, 50984], "temperature": 0.0, "avg_logprob": -0.10003738219921406, "compression_ratio": 1.9352226720647774, "no_speech_prob": 0.0037060771137475967}, {"id": 316, "seek": 228064, "start": 2293.04, "end": 2299.52, "text": " um i actually done to lead you the arrow to the wrong thing it should be to the climate observation", "tokens": [50984, 1105, 741, 767, 1096, 281, 1477, 291, 264, 11610, 281, 264, 2085, 551, 309, 820, 312, 281, 264, 5659, 14816, 51308], "temperature": 0.0, "avg_logprob": -0.10003738219921406, "compression_ratio": 1.9352226720647774, "no_speech_prob": 0.0037060771137475967}, {"id": 317, "seek": 228064, "start": 2299.52, "end": 2304.16, "text": " and the observation and then you have the climate observable property and the observable property", "tokens": [51308, 293, 264, 14816, 293, 550, 291, 362, 264, 5659, 9951, 712, 4707, 293, 264, 9951, 712, 4707, 51540], "temperature": 0.0, "avg_logprob": -0.10003738219921406, "compression_ratio": 1.9352226720647774, "no_speech_prob": 0.0037060771137475967}, {"id": 318, "seek": 228064, "start": 2304.16, "end": 2310.08, "text": " right this is not a particularly exciting implement or instantiation of the sosa ssn", "tokens": [51540, 558, 341, 307, 406, 257, 4098, 4670, 4445, 420, 9836, 6642, 295, 264, 262, 6447, 262, 18860, 51836], "temperature": 0.0, "avg_logprob": -0.10003738219921406, "compression_ratio": 1.9352226720647774, "no_speech_prob": 0.0037060771137475967}, {"id": 319, "seek": 231008, "start": 2310.08, "end": 2318.16, "text": " kernel template but you can see how um after you've kind of changed the names to be um more", "tokens": [50364, 28256, 12379, 457, 291, 393, 536, 577, 1105, 934, 291, 600, 733, 295, 3105, 264, 5288, 281, 312, 1105, 544, 50768], "temperature": 0.0, "avg_logprob": -0.08749933803782743, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.00132419029250741}, {"id": 320, "seek": 231008, "start": 2320.3199999999997, "end": 2326.3199999999997, "text": " tailored to your particular sub use case right represent a us climate division and its climate", "tokens": [50876, 34858, 281, 428, 1729, 1422, 764, 1389, 558, 2906, 257, 505, 5659, 10044, 293, 1080, 5659, 51176], "temperature": 0.0, "avg_logprob": -0.08749933803782743, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.00132419029250741}, {"id": 321, "seek": 231008, "start": 2326.3199999999997, "end": 2332.48, "text": " observations um there's all of this additional stuff that's now hung off of it right we use has", "tokens": [51176, 18163, 1105, 456, 311, 439, 295, 341, 4497, 1507, 300, 311, 586, 5753, 766, 295, 309, 558, 321, 764, 575, 51484], "temperature": 0.0, "avg_logprob": -0.08749933803782743, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.00132419029250741}, {"id": 322, "seek": 231008, "start": 2332.48, "end": 2338.7999999999997, "text": " simple result instead of has result the observation has a phenomenon time and then we go out and we", "tokens": [51484, 2199, 1874, 2602, 295, 575, 1874, 264, 14816, 575, 257, 14029, 565, 293, 550, 321, 352, 484, 293, 321, 51800], "temperature": 0.0, "avg_logprob": -0.08749933803782743, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.00132419029250741}, {"id": 323, "seek": 233880, "start": 2338.8, "end": 2345.2000000000003, "text": " say okay at least with this particular diagram we say that there's hidden or additional complexity", "tokens": [50364, 584, 1392, 412, 1935, 365, 341, 1729, 10686, 321, 584, 300, 456, 311, 7633, 420, 4497, 14024, 50684], "temperature": 0.0, "avg_logprob": -0.06996811003912062, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.0017538045067340136}, {"id": 324, "seek": 233880, "start": 2345.2000000000003, "end": 2350.48, "text": " um which would be implemented by another pattern or another module elsewhere for spatial object or", "tokens": [50684, 1105, 597, 576, 312, 12270, 538, 1071, 5102, 420, 1071, 10088, 14517, 337, 23598, 2657, 420, 50948], "temperature": 0.0, "avg_logprob": -0.06996811003912062, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.0017538045067340136}, {"id": 325, "seek": 233880, "start": 2350.48, "end": 2358.96, "text": " temporal entity all right so we're going to go ahead and start wrapping up i have a few things", "tokens": [50948, 30881, 13977, 439, 558, 370, 321, 434, 516, 281, 352, 2286, 293, 722, 21993, 493, 741, 362, 257, 1326, 721, 51372], "temperature": 0.0, "avg_logprob": -0.06996811003912062, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.0017538045067340136}, {"id": 326, "seek": 233880, "start": 2358.96, "end": 2364.8, "text": " for the tools and resources and then we'll uh we'll end with um my slide for passing on any", "tokens": [51372, 337, 264, 3873, 293, 3593, 293, 550, 321, 603, 2232, 321, 603, 917, 365, 1105, 452, 4137, 337, 8437, 322, 604, 51664], "temperature": 0.0, "avg_logprob": -0.06996811003912062, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.0017538045067340136}, {"id": 327, "seek": 236480, "start": 2364.8, "end": 2372.1600000000003, "text": " questions to me so the the the cool the the cool one and this is really a self insert here uh is", "tokens": [50364, 1651, 281, 385, 370, 264, 264, 264, 1627, 264, 264, 1627, 472, 293, 341, 307, 534, 257, 2698, 8969, 510, 2232, 307, 50732], "temperature": 0.0, "avg_logprob": -0.07876960436503093, "compression_ratio": 1.8840579710144927, "no_speech_prob": 0.0023947986774146557}, {"id": 328, "seek": 236480, "start": 2372.1600000000003, "end": 2379.04, "text": " called model uh the modular ontology design library which is a collection of curated patterns uh so on", "tokens": [50732, 1219, 2316, 2232, 264, 31111, 6592, 1793, 1715, 6405, 597, 307, 257, 5765, 295, 47851, 8294, 2232, 370, 322, 51076], "temperature": 0.0, "avg_logprob": -0.07876960436503093, "compression_ratio": 1.8840579710144927, "no_speech_prob": 0.0023947986774146557}, {"id": 329, "seek": 236480, "start": 2380.32, "end": 2387.1200000000003, "text": " the next slide we have the ontology design patterns portal uh this is a huge collection of", "tokens": [51140, 264, 958, 4137, 321, 362, 264, 6592, 1793, 1715, 8294, 14982, 2232, 341, 307, 257, 2603, 5765, 295, 51480], "temperature": 0.0, "avg_logprob": -0.07876960436503093, "compression_ratio": 1.8840579710144927, "no_speech_prob": 0.0023947986774146557}, {"id": 330, "seek": 236480, "start": 2387.1200000000003, "end": 2394.4, "text": " patterns of varying quality because it contains uh submissions of patterns which were peer reviewed", "tokens": [51480, 8294, 295, 22984, 3125, 570, 309, 8306, 2232, 40429, 295, 8294, 597, 645, 15108, 18429, 51844], "temperature": 0.0, "avg_logprob": -0.07876960436503093, "compression_ratio": 1.8840579710144927, "no_speech_prob": 0.0023947986774146557}, {"id": 331, "seek": 239440, "start": 2394.4, "end": 2401.2000000000003, "text": " but were rejected but never removed from the portal or they have wildly different sorts of uh", "tokens": [50364, 457, 645, 15749, 457, 1128, 7261, 490, 264, 14982, 420, 436, 362, 34731, 819, 7527, 295, 2232, 50704], "temperature": 0.0, "avg_logprob": -0.056664798317885984, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0009996580192819238}, {"id": 332, "seek": 239440, "start": 2402.7200000000003, "end": 2407.28, "text": " constraints on them ontological commitments that make them very tailored to a specific", "tokens": [50780, 18491, 322, 552, 6592, 4383, 26230, 300, 652, 552, 588, 34858, 281, 257, 2685, 51008], "temperature": 0.0, "avg_logprob": -0.056664798317885984, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0009996580192819238}, {"id": 333, "seek": 239440, "start": 2407.28, "end": 2412.8, "text": " use case and you would wonder whether or not they can really be called a pattern right so what we did", "tokens": [51008, 764, 1389, 293, 291, 576, 2441, 1968, 420, 406, 436, 393, 534, 312, 1219, 257, 5102, 558, 370, 437, 321, 630, 51284], "temperature": 0.0, "avg_logprob": -0.056664798317885984, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0009996580192819238}, {"id": 334, "seek": 239440, "start": 2412.8, "end": 2423.2000000000003, "text": " is we took out the patterns that we thought were maximally useful um and uh polished them up new", "tokens": [51284, 307, 321, 1890, 484, 264, 8294, 300, 321, 1194, 645, 5138, 379, 4420, 1105, 293, 2232, 29079, 552, 493, 777, 51804], "temperature": 0.0, "avg_logprob": -0.056664798317885984, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0009996580192819238}, {"id": 335, "seek": 242320, "start": 2423.2, "end": 2429.4399999999996, "text": " schema diagrams made sure that the axioms were consistent gave in some examples uh and and kind", "tokens": [50364, 34078, 36709, 1027, 988, 300, 264, 6360, 72, 4785, 645, 8398, 2729, 294, 512, 5110, 2232, 293, 293, 733, 50676], "temperature": 0.0, "avg_logprob": -0.0514253450162483, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.009116350673139095}, {"id": 336, "seek": 242320, "start": 2429.4399999999996, "end": 2436.3999999999996, "text": " of organized them by category and then we described all of them using opal right so model is actually", "tokens": [50676, 295, 9983, 552, 538, 7719, 293, 550, 321, 7619, 439, 295, 552, 1228, 999, 304, 558, 370, 2316, 307, 767, 51024], "temperature": 0.0, "avg_logprob": -0.0514253450162483, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.009116350673139095}, {"id": 337, "seek": 242320, "start": 2436.3999999999996, "end": 2447.2, "text": " an annotation ontology of all of the different uh patterns um this what here on the right is", "tokens": [51024, 364, 48654, 6592, 1793, 295, 439, 295, 264, 819, 2232, 8294, 1105, 341, 437, 510, 322, 264, 558, 307, 51564], "temperature": 0.0, "avg_logprob": -0.0514253450162483, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.009116350673139095}, {"id": 338, "seek": 244720, "start": 2447.2799999999997, "end": 2453.9199999999996, "text": " 13 patterns in version one uh i am working on a second version which contains 32 some of them", "tokens": [50368, 3705, 8294, 294, 3037, 472, 2232, 741, 669, 1364, 322, 257, 1150, 3037, 597, 8306, 8858, 512, 295, 552, 50700], "temperature": 0.0, "avg_logprob": -0.08767938613891602, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.054947465658187866}, {"id": 339, "seek": 244720, "start": 2453.9199999999996, "end": 2462.16, "text": " are redundant in so far that they are alternative patterns for the same conceptual component or", "tokens": [50700, 366, 40997, 294, 370, 1400, 300, 436, 366, 8535, 8294, 337, 264, 912, 24106, 6542, 420, 51112], "temperature": 0.0, "avg_logprob": -0.08767938613891602, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.054947465658187866}, {"id": 340, "seek": 244720, "start": 2462.16, "end": 2466.56, "text": " the same interface right a couple of different spatial extent patterns a couple of different", "tokens": [51112, 264, 912, 9226, 558, 257, 1916, 295, 819, 23598, 8396, 8294, 257, 1916, 295, 819, 51332], "temperature": 0.0, "avg_logprob": -0.08767938613891602, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.054947465658187866}, {"id": 341, "seek": 244720, "start": 2466.56, "end": 2476.08, "text": " event patterns um a couple of different role patterns and and so on um and then uh model is", "tokens": [51332, 2280, 8294, 1105, 257, 1916, 295, 819, 3090, 8294, 293, 293, 370, 322, 1105, 293, 550, 2232, 2316, 307, 51808], "temperature": 0.0, "avg_logprob": -0.08767938613891602, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.054947465658187866}, {"id": 342, "seek": 247608, "start": 2476.08, "end": 2483.68, "text": " not just an artifact it is meant to be a template model is a type of ontological collection which", "tokens": [50364, 406, 445, 364, 34806, 309, 307, 4140, 281, 312, 257, 12379, 2316, 307, 257, 2010, 295, 6592, 4383, 5765, 597, 50744], "temperature": 0.0, "avg_logprob": -0.04878741673060826, "compression_ratio": 1.6123595505617978, "no_speech_prob": 0.008311118930578232}, {"id": 343, "seek": 247608, "start": 2483.68, "end": 2490.72, "text": " is a collection of patterns um i call mine model because i suppose that's my prerogative but it", "tokens": [50744, 307, 257, 5765, 295, 8294, 1105, 741, 818, 3892, 2316, 570, 741, 7297, 300, 311, 452, 582, 260, 664, 1166, 457, 309, 51096], "temperature": 0.0, "avg_logprob": -0.04878741673060826, "compression_ratio": 1.6123595505617978, "no_speech_prob": 0.008311118930578232}, {"id": 344, "seek": 247608, "start": 2490.72, "end": 2501.68, "text": " could be any um anybody could make a model uh finally i think i already said this is that the", "tokens": [51096, 727, 312, 604, 1105, 4472, 727, 652, 257, 2316, 2232, 2721, 741, 519, 741, 1217, 848, 341, 307, 300, 264, 51644], "temperature": 0.0, "avg_logprob": -0.04878741673060826, "compression_ratio": 1.6123595505617978, "no_speech_prob": 0.008311118930578232}, {"id": 345, "seek": 250168, "start": 2501.68, "end": 2508.7999999999997, "text": " model encodes many inter pattern relationships so it has uh what interfaces it provides and then", "tokens": [50364, 2316, 2058, 4789, 867, 728, 5102, 6159, 370, 309, 575, 2232, 437, 28416, 309, 6417, 293, 550, 50720], "temperature": 0.0, "avg_logprob": -0.07525830391125801, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.020945079624652863}, {"id": 346, "seek": 250168, "start": 2508.7999999999997, "end": 2515.3599999999997, "text": " conversely what interface it implements what conceptual component in implements what are", "tokens": [50720, 2615, 736, 437, 9226, 309, 704, 17988, 437, 24106, 6542, 294, 704, 17988, 437, 366, 51048], "temperature": 0.0, "avg_logprob": -0.07525830391125801, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.020945079624652863}, {"id": 347, "seek": 250168, "start": 2515.3599999999997, "end": 2521.2799999999997, "text": " the different specializations and generalizations between the uh patterns and what category do", "tokens": [51048, 264, 819, 2121, 14455, 293, 2674, 14455, 1296, 264, 2232, 8294, 293, 437, 7719, 360, 51344], "temperature": 0.0, "avg_logprob": -0.07525830391125801, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.020945079624652863}, {"id": 348, "seek": 250168, "start": 2521.2799999999997, "end": 2527.68, "text": " they belong to uh we already talked about the portal so i'll move on what i have here is called", "tokens": [51344, 436, 5784, 281, 2232, 321, 1217, 2825, 466, 264, 14982, 370, 741, 603, 1286, 322, 437, 741, 362, 510, 307, 1219, 51664], "temperature": 0.0, "avg_logprob": -0.07525830391125801, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.020945079624652863}, {"id": 349, "seek": 252768, "start": 2527.68, "end": 2534.0, "text": " commodity uh the comprehensive modular ontology integrated development environment quite a mouthful", "tokens": [50364, 29125, 2232, 264, 13914, 31111, 6592, 1793, 10919, 3250, 2823, 1596, 257, 4525, 906, 50680], "temperature": 0.0, "avg_logprob": -0.12704230088454027, "compression_ratio": 1.5913978494623655, "no_speech_prob": 0.01910332776606083}, {"id": 350, "seek": 252768, "start": 2534.0, "end": 2542.3199999999997, "text": " commodity is a plugin for protochet um i wrote this as part of my phd dissertation so it functions", "tokens": [50680, 29125, 307, 257, 23407, 337, 1742, 8997, 302, 1105, 741, 4114, 341, 382, 644, 295, 452, 903, 67, 39555, 370, 309, 6828, 51096], "temperature": 0.0, "avg_logprob": -0.12704230088454027, "compression_ratio": 1.5913978494623655, "no_speech_prob": 0.01910332776606083}, {"id": 351, "seek": 252768, "start": 2542.3199999999997, "end": 2553.6, "text": " but it is not like production quality you know it it's something to use and um to uh leverage but", "tokens": [51096, 457, 309, 307, 406, 411, 4265, 3125, 291, 458, 309, 309, 311, 746, 281, 764, 293, 1105, 281, 2232, 13982, 457, 51660], "temperature": 0.0, "avg_logprob": -0.12704230088454027, "compression_ratio": 1.5913978494623655, "no_speech_prob": 0.01910332776606083}, {"id": 352, "seek": 255360, "start": 2553.6, "end": 2560.48, "text": " you might run into a bug here there if you do uh let me know and i'll try my best to address it or", "tokens": [50364, 291, 1062, 1190, 666, 257, 7426, 510, 456, 498, 291, 360, 2232, 718, 385, 458, 293, 741, 603, 853, 452, 1151, 281, 2985, 309, 420, 50708], "temperature": 0.0, "avg_logprob": -0.13497979500714472, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0480317659676075}, {"id": 353, "seek": 255360, "start": 2560.48, "end": 2568.96, "text": " help out but essentially what this does is it provides a graphical canvas uh to do modeling", "tokens": [50708, 854, 484, 457, 4476, 437, 341, 775, 307, 309, 6417, 257, 35942, 16267, 2232, 281, 360, 15983, 51132], "temperature": 0.0, "avg_logprob": -0.13497979500714472, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0480317659676075}, {"id": 354, "seek": 255360, "start": 2568.96, "end": 2577.2, "text": " with all of the power of our and the coup de grace so to speak would be the", "tokens": [51132, 365, 439, 295, 264, 1347, 295, 527, 293, 264, 8682, 368, 10042, 370, 281, 1710, 576, 312, 264, 51544], "temperature": 0.0, "avg_logprob": -0.13497979500714472, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0480317659676075}, {"id": 355, "seek": 257720, "start": 2577.3599999999997, "end": 2585.8399999999997, "text": " uh pattern library which is the number two you can actually drag and drop all of the patterns from", "tokens": [50372, 2232, 5102, 6405, 597, 307, 264, 1230, 732, 291, 393, 767, 5286, 293, 3270, 439, 295, 264, 8294, 490, 50796], "temperature": 0.0, "avg_logprob": -0.13415425921243335, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.008573110215365887}, {"id": 356, "seek": 257720, "start": 2585.8399999999997, "end": 2593.68, "text": " model directly onto the graphical canvas and it will connect them based on those uh interface", "tokens": [50796, 2316, 3838, 3911, 264, 35942, 16267, 293, 309, 486, 1745, 552, 2361, 322, 729, 2232, 9226, 51188], "temperature": 0.0, "avg_logprob": -0.13415425921243335, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.008573110215365887}, {"id": 357, "seek": 257720, "start": 2593.68, "end": 2602.3999999999996, "text": " points that we talked about uh and then you can also uh customize the sort of semantics that the", "tokens": [51188, 2793, 300, 321, 2825, 466, 2232, 293, 550, 291, 393, 611, 2232, 19734, 264, 1333, 295, 4361, 45298, 300, 264, 51624], "temperature": 0.0, "avg_logprob": -0.13415425921243335, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.008573110215365887}, {"id": 358, "seek": 260240, "start": 2602.4, "end": 2614.64, "text": " edge um edges will generate uh what do i have here so here's a a quick example of what this looks", "tokens": [50364, 4691, 1105, 8819, 486, 8460, 2232, 437, 360, 741, 362, 510, 370, 510, 311, 257, 257, 1702, 1365, 295, 437, 341, 1542, 50976], "temperature": 0.0, "avg_logprob": -0.11075234413146973, "compression_ratio": 1.5078125, "no_speech_prob": 0.004827593453228474}, {"id": 359, "seek": 260240, "start": 2614.64, "end": 2626.7200000000003, "text": " like um oh that was wrong let me try that again uh so what you can see here is the the dragging", "tokens": [50976, 411, 1105, 1954, 300, 390, 2085, 718, 385, 853, 300, 797, 2232, 370, 437, 291, 393, 536, 510, 307, 264, 264, 24385, 51580], "temperature": 0.0, "avg_logprob": -0.11075234413146973, "compression_ratio": 1.5078125, "no_speech_prob": 0.004827593453228474}, {"id": 360, "seek": 262672, "start": 2626.72, "end": 2634.3199999999997, "text": " and the dropping directly onto the thing uh it will draw the module around it um when you", "tokens": [50364, 293, 264, 13601, 3838, 3911, 264, 551, 2232, 309, 486, 2642, 264, 10088, 926, 309, 1105, 562, 291, 50744], "temperature": 0.0, "avg_logprob": -0.05647199262272228, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.10807543247938156}, {"id": 361, "seek": 262672, "start": 2635.68, "end": 2642.9599999999996, "text": " draw drag sorry drag the next one over it'll connect it on the obvious touch points um", "tokens": [50812, 2642, 5286, 2597, 5286, 264, 958, 472, 670, 309, 603, 1745, 309, 322, 264, 6322, 2557, 2793, 1105, 51176], "temperature": 0.0, "avg_logprob": -0.05647199262272228, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.10807543247938156}, {"id": 362, "seek": 262672, "start": 2642.9599999999996, "end": 2650.16, "text": " and then you can rename stuff and drag and drop and add your own classes and so on i'm not going", "tokens": [51176, 293, 550, 291, 393, 36741, 1507, 293, 5286, 293, 3270, 293, 909, 428, 1065, 5359, 293, 370, 322, 741, 478, 406, 516, 51536], "temperature": 0.0, "avg_logprob": -0.05647199262272228, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.10807543247938156}, {"id": 363, "seek": 262672, "start": 2650.16, "end": 2654.8799999999997, "text": " to go back because this seems to be fighting me on this so thank you very much for attending this", "tokens": [51536, 281, 352, 646, 570, 341, 2544, 281, 312, 5237, 385, 322, 341, 370, 1309, 291, 588, 709, 337, 15862, 341, 51772], "temperature": 0.0, "avg_logprob": -0.05647199262272228, "compression_ratio": 1.7417840375586855, "no_speech_prob": 0.10807543247938156}, {"id": 364, "seek": 265488, "start": 2654.88, "end": 2663.6, "text": " talk i'm so sorry that i couldn't be there today uh please forward any questions to me um at my", "tokens": [50364, 751, 741, 478, 370, 2597, 300, 741, 2809, 380, 312, 456, 965, 2232, 1767, 2128, 604, 1651, 281, 385, 1105, 412, 452, 50800], "temperature": 0.0, "avg_logprob": -0.10598989327748616, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.04139300808310509}, {"id": 365, "seek": 265488, "start": 2663.6, "end": 2670.48, "text": " email uh or go ahead and pass them on to gary and he could do this i will also be here next week um", "tokens": [50800, 3796, 2232, 420, 352, 2286, 293, 1320, 552, 322, 281, 290, 822, 293, 415, 727, 360, 341, 741, 486, 611, 312, 510, 958, 1243, 1105, 51144], "temperature": 0.0, "avg_logprob": -0.10598989327748616, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.04139300808310509}, {"id": 366, "seek": 265488, "start": 2672.4, "end": 2678.0, "text": " right after carl's talk uh which will have a lot of overlap with the sort of design process", "tokens": [51240, 558, 934, 1032, 75, 311, 751, 2232, 597, 486, 362, 257, 688, 295, 19959, 365, 264, 1333, 295, 1715, 1399, 51520], "temperature": 0.0, "avg_logprob": -0.10598989327748616, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.04139300808310509}, {"id": 367, "seek": 265488, "start": 2678.56, "end": 2684.1600000000003, "text": " and we can talk there um or i can answer any questions that you might have again thank you", "tokens": [51548, 293, 321, 393, 751, 456, 1105, 420, 741, 393, 1867, 604, 1651, 300, 291, 1062, 362, 797, 1309, 291, 51828], "temperature": 0.0, "avg_logprob": -0.10598989327748616, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.04139300808310509}, {"id": 368, "seek": 268416, "start": 2684.16, "end": 2690.64, "text": " so much and have a great day", "tokens": [50364, 370, 709, 293, 362, 257, 869, 786, 50688], "temperature": 0.0, "avg_logprob": -0.1329822540283203, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.002470624865964055}, {"id": 369, "seek": 268416, "start": 2693.92, "end": 2697.68, "text": " i guess i'll verbally thank kogan for this and we'll see him next week", "tokens": [50852, 741, 2041, 741, 603, 48162, 1309, 350, 21576, 337, 341, 293, 321, 603, 536, 796, 958, 1243, 51040], "temperature": 0.0, "avg_logprob": -0.1329822540283203, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.002470624865964055}, {"id": 370, "seek": 268416, "start": 2698.3199999999997, "end": 2705.3599999999997, "text": " we now have about 12 to 15 minutes for discussion including questions and answers of course", "tokens": [51072, 321, 586, 362, 466, 2272, 281, 2119, 2077, 337, 5017, 3009, 1651, 293, 6338, 295, 1164, 51424], "temperature": 0.0, "avg_logprob": -0.1329822540283203, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.002470624865964055}, {"id": 371, "seek": 268416, "start": 2706.72, "end": 2710.3999999999996, "text": " kogan not being here there may be limitations on what we're able to", "tokens": [51492, 350, 21576, 406, 885, 510, 456, 815, 312, 15705, 322, 437, 321, 434, 1075, 281, 51676], "temperature": 0.0, "avg_logprob": -0.1329822540283203, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.002470624865964055}, {"id": 372, "seek": 271040, "start": 2711.28, "end": 2715.36, "text": " say but uh maybe we can have some discussion among ourselves here", "tokens": [50408, 584, 457, 2232, 1310, 321, 393, 362, 512, 5017, 3654, 4175, 510, 50612], "temperature": 0.0, "avg_logprob": -0.09866371888380784, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.012611420825123787}, {"id": 373, "seek": 271040, "start": 2716.88, "end": 2724.64, "text": " so with that i'm looking for hands raised here and uh i know there was a small amount of chat in our", "tokens": [50688, 370, 365, 300, 741, 478, 1237, 337, 2377, 6005, 510, 293, 2232, 741, 458, 456, 390, 257, 1359, 2372, 295, 5081, 294, 527, 51076], "temperature": 0.0, "avg_logprob": -0.09866371888380784, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.012611420825123787}, {"id": 374, "seek": 271040, "start": 2724.64, "end": 2736.08, "text": " other uh online chat yes james you're commuted but here we go uh thanks gary and i appreciate", "tokens": [51076, 661, 2232, 2950, 5081, 2086, 361, 1632, 291, 434, 800, 4866, 457, 510, 321, 352, 2232, 3231, 290, 822, 293, 741, 4449, 51648], "temperature": 0.0, "avg_logprob": -0.09866371888380784, "compression_ratio": 1.5662650602409638, "no_speech_prob": 0.012611420825123787}, {"id": 375, "seek": 273608, "start": 2736.08, "end": 2741.68, "text": " that kogan was able to present even though he wasn't able to present so much appreciated uh it", "tokens": [50364, 300, 350, 21576, 390, 1075, 281, 1974, 754, 1673, 415, 2067, 380, 1075, 281, 1974, 370, 709, 17169, 2232, 309, 50644], "temperature": 0.0, "avg_logprob": -0.0969675795672691, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.049429647624492645}, {"id": 376, "seek": 273608, "start": 2741.68, "end": 2748.4, "text": " did have a bit of a hard time connecting this step up to what i do day to day when i do things that i", "tokens": [50644, 630, 362, 257, 857, 295, 257, 1152, 565, 11015, 341, 1823, 493, 281, 437, 741, 360, 786, 281, 786, 562, 741, 360, 721, 300, 741, 50980], "temperature": 0.0, "avg_logprob": -0.0969675795672691, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.049429647624492645}, {"id": 377, "seek": 273608, "start": 2748.4, "end": 2756.72, "text": " call design patterns or usually focused on templates and csv files or tsv files that get expanded into", "tokens": [50980, 818, 1715, 8294, 420, 2673, 5178, 322, 21165, 293, 28277, 85, 7098, 420, 35492, 85, 7098, 300, 483, 14342, 666, 51396], "temperature": 0.0, "avg_logprob": -0.0969675795672691, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.049429647624492645}, {"id": 378, "seek": 275672, "start": 2756.7999999999997, "end": 2763.3599999999997, "text": " some set of al-axioms that define a class uh but i guess my question was", "tokens": [50368, 512, 992, 295, 419, 12, 2797, 72, 4785, 300, 6964, 257, 1508, 2232, 457, 741, 2041, 452, 1168, 390, 50696], "temperature": 0.0, "avg_logprob": -0.11629073960440499, "compression_ratio": 1.7185929648241205, "no_speech_prob": 0.06177406758069992}, {"id": 379, "seek": 275672, "start": 2764.72, "end": 2769.2799999999997, "text": " so i am aware that there's this larger literature about ontology design patterns", "tokens": [50764, 370, 741, 669, 3650, 300, 456, 311, 341, 4833, 10394, 466, 6592, 1793, 1715, 8294, 50992], "temperature": 0.0, "avg_logprob": -0.11629073960440499, "compression_ratio": 1.7185929648241205, "no_speech_prob": 0.06177406758069992}, {"id": 380, "seek": 275672, "start": 2770.9599999999996, "end": 2777.2799999999997, "text": " that i'm not super familiar with uh i guess my my general question is how well this talk", "tokens": [51076, 300, 741, 478, 406, 1687, 4963, 365, 2232, 741, 2041, 452, 452, 2674, 1168, 307, 577, 731, 341, 751, 51392], "temperature": 0.0, "avg_logprob": -0.11629073960440499, "compression_ratio": 1.7185929648241205, "no_speech_prob": 0.06177406758069992}, {"id": 381, "seek": 275672, "start": 2777.2799999999997, "end": 2783.52, "text": " lines up with kind of the larger literature on these things uh i don't know maybe that's a question", "tokens": [51392, 3876, 493, 365, 733, 295, 264, 4833, 10394, 322, 613, 721, 2232, 741, 500, 380, 458, 1310, 300, 311, 257, 1168, 51704], "temperature": 0.0, "avg_logprob": -0.11629073960440499, "compression_ratio": 1.7185929648241205, "no_speech_prob": 0.06177406758069992}, {"id": 382, "seek": 278352, "start": 2783.52, "end": 2792.64, "text": " for gary but other people could uh could chime in is there like a single notion of ontology design", "tokens": [50364, 337, 290, 822, 457, 661, 561, 727, 2232, 727, 40921, 294, 307, 456, 411, 257, 2167, 10710, 295, 6592, 1793, 1715, 50820], "temperature": 0.0, "avg_logprob": -0.07964023676785556, "compression_ratio": 1.55, "no_speech_prob": 0.0038823287468403578}, {"id": 383, "seek": 278352, "start": 2792.64, "end": 2799.44, "text": " pattern and kogan was expressing it or is it a more diverse kind of field topic keyword", "tokens": [50820, 5102, 293, 350, 21576, 390, 22171, 309, 420, 307, 309, 257, 544, 9521, 733, 295, 2519, 4829, 20428, 51160], "temperature": 0.0, "avg_logprob": -0.07964023676785556, "compression_ratio": 1.55, "no_speech_prob": 0.0038823287468403578}, {"id": 384, "seek": 278352, "start": 2802.08, "end": 2807.52, "text": " well it's an interesting question i'm not sure i can be definitive i have opinions of course", "tokens": [51292, 731, 309, 311, 364, 1880, 1168, 741, 478, 406, 988, 741, 393, 312, 28152, 741, 362, 11819, 295, 1164, 51564], "temperature": 0.0, "avg_logprob": -0.07964023676785556, "compression_ratio": 1.55, "no_speech_prob": 0.0038823287468403578}, {"id": 385, "seek": 280752, "start": 2807.52, "end": 2813.36, "text": " and i am not necessarily as up to date on all the literature uh if there's somebody out here", "tokens": [50364, 293, 741, 669, 406, 4725, 382, 493, 281, 4002, 322, 439, 264, 10394, 2232, 498, 456, 311, 2618, 484, 510, 50656], "temperature": 0.0, "avg_logprob": -0.12602310180664061, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.010318021290004253}, {"id": 386, "seek": 280752, "start": 2813.36, "end": 2821.36, "text": " attending who who feels they are they can certainly speak up kogan mentioned setting up sort of a new", "tokens": [50656, 15862, 567, 567, 3417, 436, 366, 436, 393, 3297, 1710, 493, 350, 21576, 2835, 3287, 493, 1333, 295, 257, 777, 51056], "temperature": 0.0, "avg_logprob": -0.12602310180664061, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.010318021290004253}, {"id": 387, "seek": 280752, "start": 2822.64, "end": 2831.68, "text": " a new repository uh for curated design patterns and this reflects the fact that that people have", "tokens": [51120, 257, 777, 25841, 2232, 337, 47851, 1715, 8294, 293, 341, 18926, 264, 1186, 300, 300, 561, 362, 51572], "temperature": 0.0, "avg_logprob": -0.12602310180664061, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.010318021290004253}, {"id": 388, "seek": 283168, "start": 2831.7599999999998, "end": 2838.16, "text": " been building design patterns and posting them and uh the idea is for them to have", "tokens": [50368, 668, 2390, 1715, 8294, 293, 15978, 552, 293, 2232, 264, 1558, 307, 337, 552, 281, 362, 50688], "temperature": 0.0, "avg_logprob": -0.07439975614671583, "compression_ratio": 1.771144278606965, "no_speech_prob": 0.08996464312076569}, {"id": 389, "seek": 283168, "start": 2838.16, "end": 2844.3999999999996, "text": " good documentation to reuse practice to make connections to other uh design patterns and", "tokens": [50688, 665, 14333, 281, 26225, 3124, 281, 652, 9271, 281, 661, 2232, 1715, 8294, 293, 51000], "temperature": 0.0, "avg_logprob": -0.07439975614671583, "compression_ratio": 1.771144278606965, "no_speech_prob": 0.08996464312076569}, {"id": 390, "seek": 283168, "start": 2844.3999999999996, "end": 2849.8399999999997, "text": " maybe upper levels and a lot of that is that is missing you know when we we talk about fairness", "tokens": [51000, 1310, 6597, 4358, 293, 257, 688, 295, 300, 307, 300, 307, 5361, 291, 458, 562, 321, 321, 751, 466, 29765, 51272], "temperature": 0.0, "avg_logprob": -0.07439975614671583, "compression_ratio": 1.771144278606965, "no_speech_prob": 0.08996464312076569}, {"id": 391, "seek": 283168, "start": 2849.8399999999997, "end": 2855.68, "text": " for ontology we sometimes find that they lack some of the ingredients of fairness and so", "tokens": [51272, 337, 6592, 1793, 321, 2171, 915, 300, 436, 5011, 512, 295, 264, 6952, 295, 29765, 293, 370, 51564], "temperature": 0.0, "avg_logprob": -0.07439975614671583, "compression_ratio": 1.771144278606965, "no_speech_prob": 0.08996464312076569}, {"id": 392, "seek": 285568, "start": 2855.68, "end": 2864.16, "text": " that is has been true for odps uh over time but like the the the foundry uh there's a sub community", "tokens": [50364, 300, 307, 575, 668, 2074, 337, 3611, 1878, 2232, 670, 565, 457, 411, 264, 264, 264, 1352, 627, 2232, 456, 311, 257, 1422, 1768, 50788], "temperature": 0.0, "avg_logprob": -0.12812875617634167, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.08750703930854797}, {"id": 393, "seek": 285568, "start": 2864.16, "end": 2872.8799999999997, "text": " here of people like like uh pascal and kogan and uh the people involved with the nowhere", "tokens": [50788, 510, 295, 561, 411, 411, 2232, 1736, 9895, 293, 350, 21576, 293, 2232, 264, 561, 3288, 365, 264, 11159, 51224], "temperature": 0.0, "avg_logprob": -0.12812875617634167, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.08750703930854797}, {"id": 394, "seek": 285568, "start": 2872.8799999999997, "end": 2878.48, "text": " where graph we're trying to pull some of this together and and provide more of a community", "tokens": [51224, 689, 4295, 321, 434, 1382, 281, 2235, 512, 295, 341, 1214, 293, 293, 2893, 544, 295, 257, 1768, 51504], "temperature": 0.0, "avg_logprob": -0.12812875617634167, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.08750703930854797}, {"id": 395, "seek": 285568, "start": 2878.48, "end": 2884.24, "text": " where there are higher standards existing practices so i'd say again that maybe it isn't", "tokens": [51504, 689, 456, 366, 2946, 7787, 6741, 7525, 370, 741, 1116, 584, 797, 300, 1310, 309, 1943, 380, 51792], "temperature": 0.0, "avg_logprob": -0.12812875617634167, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.08750703930854797}, {"id": 396, "seek": 288424, "start": 2884.24, "end": 2892.0, "text": " it isn't as large a community and maybe hasn't been uh as well funded uh as things in the biomedical", "tokens": [50364, 309, 1943, 380, 382, 2416, 257, 1768, 293, 1310, 6132, 380, 668, 2232, 382, 731, 14385, 2232, 382, 721, 294, 264, 49775, 50752], "temperature": 0.0, "avg_logprob": -0.06194089662910688, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.0031208768486976624}, {"id": 397, "seek": 288424, "start": 2892.0, "end": 2899.2, "text": " field but this is an attempt to sort of do something of that level quality and i myself", "tokens": [50752, 2519, 457, 341, 307, 364, 5217, 281, 1333, 295, 360, 746, 295, 300, 1496, 3125, 293, 741, 2059, 51112], "temperature": 0.0, "avg_logprob": -0.06194089662910688, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.0031208768486976624}, {"id": 398, "seek": 288424, "start": 2899.2, "end": 2903.3599999999997, "text": " am very much interested in how these two communities can sort of share and cooperate", "tokens": [51112, 669, 588, 709, 3102, 294, 577, 613, 732, 4456, 393, 1333, 295, 2073, 293, 26667, 51320], "temperature": 0.0, "avg_logprob": -0.06194089662910688, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.0031208768486976624}, {"id": 399, "seek": 288424, "start": 2903.3599999999997, "end": 2908.8799999999997, "text": " i mentioned the semantic trajectory as being able to be applied to a course of disease", "tokens": [51320, 741, 2835, 264, 47982, 21512, 382, 885, 1075, 281, 312, 6456, 281, 257, 1164, 295, 4752, 51596], "temperature": 0.0, "avg_logprob": -0.06194089662910688, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.0031208768486976624}, {"id": 400, "seek": 288424, "start": 2909.68, "end": 2913.3599999999997, "text": " but i'm not sure anybody has done that i'm not sure that anybody has looked at", "tokens": [51636, 457, 741, 478, 406, 988, 4472, 575, 1096, 300, 741, 478, 406, 988, 300, 4472, 575, 2956, 412, 51820], "temperature": 0.0, "avg_logprob": -0.06194089662910688, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.0031208768486976624}, {"id": 401, "seek": 291336, "start": 2913.36, "end": 2920.7200000000003, "text": " what's common about these patterns and how to how to take uh a a dead simple pattern from oboe", "tokens": [50364, 437, 311, 2689, 466, 613, 8294, 293, 577, 281, 577, 281, 747, 2232, 257, 257, 3116, 2199, 5102, 490, 1111, 7921, 50732], "temperature": 0.0, "avg_logprob": -0.10221985253420743, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.0013244340661913157}, {"id": 402, "seek": 291336, "start": 2920.7200000000003, "end": 2927.76, "text": " and sort of put it in uh and compose with it along with uh odps from the other communities", "tokens": [50732, 293, 1333, 295, 829, 309, 294, 2232, 293, 35925, 365, 309, 2051, 365, 2232, 3611, 1878, 490, 264, 661, 4456, 51084], "temperature": 0.0, "avg_logprob": -0.10221985253420743, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.0013244340661913157}, {"id": 403, "seek": 291336, "start": 2927.76, "end": 2931.6800000000003, "text": " that would be an interesting thing to look at it and might be an interesting research article", "tokens": [51084, 300, 576, 312, 364, 1880, 551, 281, 574, 412, 309, 293, 1062, 312, 364, 1880, 2132, 7222, 51280], "temperature": 0.0, "avg_logprob": -0.10221985253420743, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.0013244340661913157}, {"id": 404, "seek": 291336, "start": 2932.56, "end": 2938.32, "text": " for us to consider so hopefully i've given people enough time to know maybe more about this and have", "tokens": [51324, 337, 505, 281, 1949, 370, 4696, 741, 600, 2212, 561, 1547, 565, 281, 458, 1310, 544, 466, 341, 293, 362, 51612], "temperature": 0.0, "avg_logprob": -0.10221985253420743, "compression_ratio": 1.7511520737327189, "no_speech_prob": 0.0013244340661913157}, {"id": 405, "seek": 293832, "start": 2938.32, "end": 2944.0800000000004, "text": " things to say i just wanted to laugh at your bit about being well funded because we don't think of", "tokens": [50364, 721, 281, 584, 741, 445, 1415, 281, 5801, 412, 428, 857, 466, 885, 731, 14385, 570, 321, 500, 380, 519, 295, 50652], "temperature": 0.0, "avg_logprob": -0.12239314414359428, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.06003711745142937}, {"id": 406, "seek": 293832, "start": 2944.0800000000004, "end": 2949.92, "text": " ourselves as well funded and being on the side of tooling side of things but we think of ourselves as", "tokens": [50652, 4175, 382, 731, 14385, 293, 885, 322, 264, 1252, 295, 46593, 1252, 295, 721, 457, 321, 519, 295, 4175, 382, 50944], "temperature": 0.0, "avg_logprob": -0.12239314414359428, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.06003711745142937}, {"id": 407, "seek": 293832, "start": 2949.92, "end": 2955.92, "text": " stealing uh time and money to build these tools but maybe you're right a lot could be said about", "tokens": [50944, 19757, 2232, 565, 293, 1460, 281, 1322, 613, 3873, 457, 1310, 291, 434, 558, 257, 688, 727, 312, 848, 466, 51244], "temperature": 0.0, "avg_logprob": -0.12239314414359428, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.06003711745142937}, {"id": 408, "seek": 293832, "start": 2955.92, "end": 2960.6400000000003, "text": " that it's a relative question of course and the continuity is such is very important where", "tokens": [51244, 300, 309, 311, 257, 4972, 1168, 295, 1164, 293, 264, 23807, 307, 1270, 307, 588, 1021, 689, 51480], "temperature": 0.0, "avg_logprob": -0.12239314414359428, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.06003711745142937}, {"id": 409, "seek": 293832, "start": 2960.6400000000003, "end": 2967.28, "text": " things get started in the question so the geolink pattern that i sort of identified came out of or", "tokens": [51480, 721, 483, 1409, 294, 264, 1168, 370, 264, 1519, 401, 475, 5102, 300, 741, 1333, 295, 9234, 1361, 484, 295, 420, 51812], "temperature": 0.0, "avg_logprob": -0.12239314414359428, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.06003711745142937}, {"id": 410, "seek": 296728, "start": 2967.28, "end": 2972.5600000000004, "text": " built on a semantic trajectory but they didn't necessarily continue to fund more of that for", "tokens": [50364, 3094, 322, 257, 47982, 21512, 457, 436, 994, 380, 4725, 2354, 281, 2374, 544, 295, 300, 337, 50628], "temperature": 0.0, "avg_logprob": -0.09810027647554205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.0007791062816977501}, {"id": 411, "seek": 296728, "start": 2972.5600000000004, "end": 2978.48, "text": " other types of expeditions and things like that so some of the concepts can be reused but necessarily", "tokens": [50628, 661, 3467, 295, 19348, 2451, 293, 721, 411, 300, 370, 512, 295, 264, 10392, 393, 312, 319, 4717, 457, 4725, 50924], "temperature": 0.0, "avg_logprob": -0.09810027647554205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.0007791062816977501}, {"id": 412, "seek": 296728, "start": 2978.48, "end": 2984.88, "text": " the projects have a you know a three year five year type of extent and and one's uncertain about the", "tokens": [50924, 264, 4455, 362, 257, 291, 458, 257, 1045, 1064, 1732, 1064, 2010, 295, 8396, 293, 293, 472, 311, 11308, 466, 264, 51244], "temperature": 0.0, "avg_logprob": -0.09810027647554205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.0007791062816977501}, {"id": 413, "seek": 296728, "start": 2984.88, "end": 2992.1600000000003, "text": " other side that's true we often have longer time frames than that you know oboe but not always thanks", "tokens": [51244, 661, 1252, 300, 311, 2074, 321, 2049, 362, 2854, 565, 12083, 813, 300, 291, 458, 1111, 7921, 457, 406, 1009, 3231, 51608], "temperature": 0.0, "avg_logprob": -0.09810027647554205, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.0007791062816977501}, {"id": 414, "seek": 299216, "start": 2992.16, "end": 2995.44, "text": " okay", "tokens": [50364, 1392, 50528], "temperature": 0.0, "avg_logprob": -0.13474034551364272, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0060929046012461185}, {"id": 415, "seek": 299216, "start": 3001.6, "end": 3007.2799999999997, "text": " um i see something in chat so i'll just read that in addition to what james asked what ontology", "tokens": [50836, 1105, 741, 536, 746, 294, 5081, 370, 741, 603, 445, 1401, 300, 294, 4500, 281, 437, 361, 1632, 2351, 437, 6592, 1793, 51120], "temperature": 0.0, "avg_logprob": -0.13474034551364272, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0060929046012461185}, {"id": 416, "seek": 299216, "start": 3007.2799999999997, "end": 3012.8799999999997, "text": " projects do you know and hopefully it's the community rather than just me uh use ontology design", "tokens": [51120, 4455, 360, 291, 458, 293, 4696, 309, 311, 264, 1768, 2831, 813, 445, 385, 2232, 764, 6592, 1793, 1715, 51400], "temperature": 0.0, "avg_logprob": -0.13474034551364272, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0060929046012461185}, {"id": 417, "seek": 299216, "start": 3012.8799999999997, "end": 3020.3199999999997, "text": " pads for practical practically during during development um again that that's a much better", "tokens": [51400, 19179, 337, 8496, 15667, 1830, 1830, 3250, 1105, 797, 300, 300, 311, 257, 709, 1101, 51772], "temperature": 0.0, "avg_logprob": -0.13474034551364272, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0060929046012461185}, {"id": 418, "seek": 302032, "start": 3020.32, "end": 3027.6800000000003, "text": " question to ask of both kogan and uh call uh so let's keep that question i do know that there", "tokens": [50364, 1168, 281, 1029, 295, 1293, 350, 21576, 293, 2232, 818, 2232, 370, 718, 311, 1066, 300, 1168, 741, 360, 458, 300, 456, 50732], "temperature": 0.0, "avg_logprob": -0.09500742494390252, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.00263002491556108}, {"id": 419, "seek": 302032, "start": 3027.6800000000003, "end": 3034.56, "text": " have been studies which looked at the relative of quality of ontologies built by reusing patterns or", "tokens": [50732, 362, 668, 5313, 597, 2956, 412, 264, 4972, 295, 3125, 295, 6592, 6204, 3094, 538, 319, 7981, 8294, 420, 51076], "temperature": 0.0, "avg_logprob": -0.09500742494390252, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.00263002491556108}, {"id": 420, "seek": 302032, "start": 3034.56, "end": 3043.52, "text": " not and unfortunately at the time of the publication i know of it wasn't great it wasn't uh a big help", "tokens": [51076, 406, 293, 7015, 412, 264, 565, 295, 264, 19953, 741, 458, 295, 309, 2067, 380, 869, 309, 2067, 380, 2232, 257, 955, 854, 51524], "temperature": 0.0, "avg_logprob": -0.09500742494390252, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.00263002491556108}, {"id": 421, "seek": 302032, "start": 3043.52, "end": 3047.52, "text": " at that time but again things have moved along since some of those earlier studies", "tokens": [51524, 412, 300, 565, 457, 797, 721, 362, 4259, 2051, 1670, 512, 295, 729, 3071, 5313, 51724], "temperature": 0.0, "avg_logprob": -0.09500742494390252, "compression_ratio": 1.735159817351598, "no_speech_prob": 0.00263002491556108}, {"id": 422, "seek": 304752, "start": 3048.4, "end": 3054.32, "text": " ashaya you have your hand up yeah so maybe i just ask a clarification questions", "tokens": [50408, 12588, 4427, 291, 362, 428, 1011, 493, 1338, 370, 1310, 741, 445, 1029, 257, 34449, 1651, 50704], "temperature": 0.0, "avg_logprob": -0.11443664988533395, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001031884690746665}, {"id": 423, "seek": 304752, "start": 3054.88, "end": 3062.4, "text": " in his talk does he mean that uh the design pattern we can use no matter what top ontology", "tokens": [50732, 294, 702, 751, 775, 415, 914, 300, 2232, 264, 1715, 5102, 321, 393, 764, 572, 1871, 437, 1192, 6592, 1793, 51108], "temperature": 0.0, "avg_logprob": -0.11443664988533395, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001031884690746665}, {"id": 424, "seek": 304752, "start": 3062.4, "end": 3069.12, "text": " that we are using and another one is so the my understanding is that the design pattern", "tokens": [51108, 300, 321, 366, 1228, 293, 1071, 472, 307, 370, 264, 452, 3701, 307, 300, 264, 1715, 5102, 51444], "temperature": 0.0, "avg_logprob": -0.11443664988533395, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.001031884690746665}, {"id": 425, "seek": 306912, "start": 3069.7599999999998, "end": 3077.2, "text": " if as logo so they are not necessarily map kind of have the same using same block", "tokens": [50396, 498, 382, 9699, 370, 436, 366, 406, 4725, 4471, 733, 295, 362, 264, 912, 1228, 912, 3461, 50768], "temperature": 0.0, "avg_logprob": -0.1057223654412604, "compression_ratio": 1.6732673267326732, "no_speech_prob": 0.0017541400156915188}, {"id": 426, "seek": 306912, "start": 3078.16, "end": 3084.96, "text": " like but they can still connect to each other is that correct understanding", "tokens": [50816, 411, 457, 436, 393, 920, 1745, 281, 1184, 661, 307, 300, 3006, 3701, 51156], "temperature": 0.0, "avg_logprob": -0.1057223654412604, "compression_ratio": 1.6732673267326732, "no_speech_prob": 0.0017541400156915188}, {"id": 427, "seek": 306912, "start": 3086.7999999999997, "end": 3090.96, "text": " yeah i can i can maybe address part of that which is the interoperability question with", "tokens": [51248, 1338, 741, 393, 741, 393, 1310, 2985, 644, 295, 300, 597, 307, 264, 728, 7192, 2310, 1168, 365, 51456], "temperature": 0.0, "avg_logprob": -0.1057223654412604, "compression_ratio": 1.6732673267326732, "no_speech_prob": 0.0017541400156915188}, {"id": 428, "seek": 306912, "start": 3090.96, "end": 3096.08, "text": " upper level ontologies so you notice that some of them had these stubs with the dotted lines", "tokens": [51456, 6597, 1496, 6592, 6204, 370, 291, 3449, 300, 512, 295, 552, 632, 613, 342, 5432, 365, 264, 37459, 3876, 51712], "temperature": 0.0, "avg_logprob": -0.1057223654412604, "compression_ratio": 1.6732673267326732, "no_speech_prob": 0.0017541400156915188}, {"id": 429, "seek": 309608, "start": 3096.08, "end": 3101.84, "text": " and has he's he said i i don't remember his exact words the idea is you can plug in different", "tokens": [50364, 293, 575, 415, 311, 415, 848, 741, 741, 500, 380, 1604, 702, 1900, 2283, 264, 1558, 307, 291, 393, 5452, 294, 819, 50652], "temperature": 0.0, "avg_logprob": -0.08879375457763672, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.009120013564825058}, {"id": 430, "seek": 309608, "start": 3101.84, "end": 3106.08, "text": " things at this particular point some of them may be entire patterns some of them may be a", "tokens": [50652, 721, 412, 341, 1729, 935, 512, 295, 552, 815, 312, 2302, 8294, 512, 295, 552, 815, 312, 257, 50864], "temperature": 0.0, "avg_logprob": -0.08879375457763672, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.009120013564825058}, {"id": 431, "seek": 309608, "start": 3106.08, "end": 3113.2799999999997, "text": " very simple concept and so forth so the idea is that the the core of the pattern below the dotted", "tokens": [50864, 588, 2199, 3410, 293, 370, 5220, 370, 264, 1558, 307, 300, 264, 264, 4965, 295, 264, 5102, 2507, 264, 37459, 51224], "temperature": 0.0, "avg_logprob": -0.08879375457763672, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.009120013564825058}, {"id": 432, "seek": 309608, "start": 3113.2799999999997, "end": 3119.92, "text": " line is gets reused and it's in common so that you can you can ask some questions across it", "tokens": [51224, 1622, 307, 2170, 319, 4717, 293, 309, 311, 294, 2689, 370, 300, 291, 393, 291, 393, 1029, 512, 1651, 2108, 309, 51556], "temperature": 0.0, "avg_logprob": -0.08879375457763672, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.009120013564825058}, {"id": 433, "seek": 309608, "start": 3119.92, "end": 3125.68, "text": " because there's a common element a little bit like what cob is doing right cob is providing", "tokens": [51556, 570, 456, 311, 257, 2689, 4478, 257, 707, 857, 411, 437, 39527, 307, 884, 558, 39527, 307, 6530, 51844], "temperature": 0.0, "avg_logprob": -0.08879375457763672, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.009120013564825058}, {"id": 434, "seek": 312568, "start": 3125.68, "end": 3132.8799999999997, "text": " that core that other people can tap into but yes there will be variations depending on whether", "tokens": [50364, 300, 4965, 300, 661, 561, 393, 5119, 666, 457, 2086, 456, 486, 312, 17840, 5413, 322, 1968, 50724], "temperature": 0.0, "avg_logprob": -0.09170252626592462, "compression_ratio": 1.6369047619047619, "no_speech_prob": 0.0025103227235376835}, {"id": 435, "seek": 312568, "start": 3132.8799999999997, "end": 3144.3199999999997, "text": " you tap into dulce at the top or you tap into oboe so or bfo i should say so it allows sort of", "tokens": [50724, 291, 5119, 666, 44012, 384, 412, 264, 1192, 420, 291, 5119, 666, 1111, 7921, 370, 420, 272, 16931, 741, 820, 584, 370, 309, 4045, 1333, 295, 51296], "temperature": 0.0, "avg_logprob": -0.09170252626592462, "compression_ratio": 1.6369047619047619, "no_speech_prob": 0.0025103227235376835}, {"id": 436, "seek": 312568, "start": 3144.96, "end": 3150.08, "text": " some commonality and some flexibility it's a compromise there maybe somebody else has", "tokens": [51328, 512, 2689, 1860, 293, 512, 12635, 309, 311, 257, 18577, 456, 1310, 2618, 1646, 575, 51584], "temperature": 0.0, "avg_logprob": -0.09170252626592462, "compression_ratio": 1.6369047619047619, "no_speech_prob": 0.0025103227235376835}, {"id": 437, "seek": 315008, "start": 3150.08, "end": 3153.44, "text": " some other wisdom to add to that or or real wisdom to add to that", "tokens": [50364, 512, 661, 10712, 281, 909, 281, 300, 420, 420, 957, 10712, 281, 909, 281, 300, 50532], "temperature": 0.0, "avg_logprob": -0.07940612015900789, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.001133388257585466}, {"id": 438, "seek": 315008, "start": 3157.68, "end": 3164.4, "text": " well it design pattern each design pattern will have certain requirements for it to be applicable", "tokens": [50744, 731, 309, 1715, 5102, 1184, 1715, 5102, 486, 362, 1629, 7728, 337, 309, 281, 312, 21142, 51080], "temperature": 0.0, "avg_logprob": -0.07940612015900789, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.001133388257585466}, {"id": 439, "seek": 315008, "start": 3166.48, "end": 3174.08, "text": " and that could make it impossible to use in certain with certain upper ontologies", "tokens": [51184, 293, 300, 727, 652, 309, 6243, 281, 764, 294, 1629, 365, 1629, 6597, 6592, 6204, 51564], "temperature": 0.0, "avg_logprob": -0.07940612015900789, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.001133388257585466}, {"id": 440, "seek": 317408, "start": 3174.88, "end": 3176.08, "text": " so it's", "tokens": [50404, 370, 309, 311, 50464], "temperature": 0.0, "avg_logprob": -0.2800763635074391, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.0012252416927367449}, {"id": 441, "seek": 317408, "start": 3178.08, "end": 3183.36, "text": " but i to what extent do these design patterns have those requirements explicitly stated", "tokens": [50564, 457, 741, 281, 437, 8396, 360, 613, 1715, 8294, 362, 729, 7728, 20803, 11323, 50828], "temperature": 0.0, "avg_logprob": -0.2800763635074391, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.0012252416927367449}, {"id": 442, "seek": 317408, "start": 3186.4, "end": 3194.56, "text": " so this is very much a bottom up effort at times coming from what the data is saying to reflect the", "tokens": [50980, 370, 341, 307, 588, 709, 257, 2767, 493, 4630, 412, 1413, 1348, 490, 437, 264, 1412, 307, 1566, 281, 5031, 264, 51388], "temperature": 0.0, "avg_logprob": -0.2800763635074391, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.0012252416927367449}, {"id": 443, "seek": 317408, "start": 3194.56, "end": 3202.24, "text": " reality of the data as opposed to a more abstract concept above and so as long as you have common", "tokens": [51388, 4103, 295, 264, 1412, 382, 8851, 281, 257, 544, 12649, 3410, 3673, 293, 370, 382, 938, 382, 291, 362, 2689, 51772], "temperature": 0.0, "avg_logprob": -0.2800763635074391, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.0012252416927367449}, {"id": 444, "seek": 320224, "start": 3202.24, "end": 3207.2799999999997, "text": " questions that can answer with the data can answer real things of interest to a domain", "tokens": [50364, 1651, 300, 393, 1867, 365, 264, 1412, 393, 1867, 957, 721, 295, 1179, 281, 257, 9274, 50616], "temperature": 0.0, "avg_logprob": -0.3201556905110677, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.0009684981196187437}, {"id": 445, "seek": 320224, "start": 3207.8399999999997, "end": 3215.2799999999997, "text": " that they feel that's that's viable now there could be of course these different philosophical", "tokens": [50644, 300, 436, 841, 300, 311, 300, 311, 22024, 586, 456, 727, 312, 295, 1164, 613, 819, 25066, 51016], "temperature": 0.0, "avg_logprob": -0.3201556905110677, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.0009684981196187437}, {"id": 446, "seek": 320224, "start": 3215.2799999999997, "end": 3220.4799999999996, "text": " distinctions at the top level the question is whether you have common questions that sort of tap", "tokens": [51016, 1483, 49798, 412, 264, 1192, 1496, 264, 1168, 307, 1968, 291, 362, 2689, 1651, 300, 1333, 295, 5119, 51276], "temperature": 0.0, "avg_logprob": -0.3201556905110677, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.0009684981196187437}, {"id": 447, "seek": 320224, "start": 3220.4799999999996, "end": 3221.52, "text": " into that at all", "tokens": [51276, 666, 300, 412, 439, 51328], "temperature": 0.0, "avg_logprob": -0.3201556905110677, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.0009684981196187437}, {"id": 448, "seek": 320224, "start": 3223.68, "end": 3226.08, "text": " they may it may not for practical purposes", "tokens": [51436, 436, 815, 309, 815, 406, 337, 8496, 9932, 51556], "temperature": 0.0, "avg_logprob": -0.3201556905110677, "compression_ratio": 1.7604166666666667, "no_speech_prob": 0.0009684981196187437}, {"id": 449, "seek": 322608, "start": 3226.24, "end": 3234.88, "text": " yeah again this is a question this is a deeper question that people who are like kogan and", "tokens": [50372, 1338, 797, 341, 307, 257, 1168, 341, 307, 257, 7731, 1168, 300, 561, 567, 366, 411, 350, 21576, 293, 50804], "temperature": 0.0, "avg_logprob": -0.4311230182647705, "compression_ratio": 1.4892086330935252, "no_speech_prob": 0.006899008061736822}, {"id": 450, "seek": 322608, "start": 3234.88, "end": 3237.92, "text": " caulk and probably provide a better follow-up", "tokens": [50804, 1335, 16875, 293, 1391, 2893, 257, 1101, 1524, 12, 1010, 50956], "temperature": 0.0, "avg_logprob": -0.4311230182647705, "compression_ratio": 1.4892086330935252, "no_speech_prob": 0.006899008061736822}, {"id": 451, "seek": 322608, "start": 3241.2, "end": 3247.36, "text": " there is a there's a workshop on ontology design and patterns", "tokens": [51120, 456, 307, 257, 456, 311, 257, 13541, 322, 6592, 1793, 1715, 293, 8294, 51428], "temperature": 0.0, "avg_logprob": -0.4311230182647705, "compression_ratio": 1.4892086330935252, "no_speech_prob": 0.006899008061736822}, {"id": 452, "seek": 322608, "start": 3248.96, "end": 3250.16, "text": " it's WOP", "tokens": [51508, 309, 311, 343, 12059, 51568], "temperature": 0.0, "avg_logprob": -0.4311230182647705, "compression_ratio": 1.4892086330935252, "no_speech_prob": 0.006899008061736822}, {"id": 453, "seek": 325016, "start": 3251.12, "end": 3252.64, "text": " it's WOP", "tokens": [50412, 309, 311, 343, 12059, 50488], "temperature": 0.0, "avg_logprob": -0.3884289042154948, "compression_ratio": 1.680722891566265, "no_speech_prob": 0.00413128174841404}, {"id": 454, "seek": 325016, "start": 3253.6, "end": 3258.08, "text": " regularly WOP is an annual event", "tokens": [50536, 11672, 343, 12059, 307, 364, 9784, 2280, 50760], "temperature": 0.0, "avg_logprob": -0.3884289042154948, "compression_ratio": 1.680722891566265, "no_speech_prob": 0.00413128174841404}, {"id": 455, "seek": 325016, "start": 3259.68, "end": 3263.68, "text": " and you can see that some of the people in there online the past ones are online and", "tokens": [50840, 293, 291, 393, 536, 300, 512, 295, 264, 561, 294, 456, 2950, 264, 1791, 2306, 366, 2950, 293, 51040], "temperature": 0.0, "avg_logprob": -0.3884289042154948, "compression_ratio": 1.680722891566265, "no_speech_prob": 0.00413128174841404}, {"id": 456, "seek": 325016, "start": 3263.68, "end": 3267.04, "text": " you can look at the at the press the papers i often do", "tokens": [51040, 291, 393, 574, 412, 264, 412, 264, 1886, 264, 10577, 741, 2049, 360, 51208], "temperature": 0.0, "avg_logprob": -0.3884289042154948, "compression_ratio": 1.680722891566265, "no_speech_prob": 0.00413128174841404}, {"id": 457, "seek": 325016, "start": 3268.48, "end": 3273.92, "text": " i was part of the review panel here who are active in that community", "tokens": [51280, 741, 390, 644, 295, 264, 3131, 4831, 510, 567, 366, 4967, 294, 300, 1768, 51552], "temperature": 0.0, "avg_logprob": -0.3884289042154948, "compression_ratio": 1.680722891566265, "no_speech_prob": 0.00413128174841404}, {"id": 458, "seek": 325016, "start": 3275.04, "end": 3277.44, "text": " who might have some comments", "tokens": [51608, 567, 1062, 362, 512, 3053, 51728], "temperature": 0.0, "avg_logprob": -0.3884289042154948, "compression_ratio": 1.680722891566265, "no_speech_prob": 0.00413128174841404}, {"id": 459, "seek": 327744, "start": 3278.4, "end": 3284.96, "text": " yes we have a few minutes left so let's hear from people with different experiences on this", "tokens": [50412, 2086, 321, 362, 257, 1326, 2077, 1411, 370, 718, 311, 1568, 490, 561, 365, 819, 5235, 322, 341, 50740], "temperature": 0.0, "avg_logprob": -0.1596099046560434, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001262377598322928}, {"id": 460, "seek": 327744, "start": 3284.96, "end": 3286.08, "text": " or different ideas on this", "tokens": [50740, 420, 819, 3487, 322, 341, 50796], "temperature": 0.0, "avg_logprob": -0.1596099046560434, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001262377598322928}, {"id": 461, "seek": 327744, "start": 3292.7200000000003, "end": 3297.28, "text": " you don't have to be shy because you've heard me talk about it yeah obviously people will know", "tokens": [51128, 291, 500, 380, 362, 281, 312, 12685, 570, 291, 600, 2198, 385, 751, 466, 309, 1338, 2745, 561, 486, 458, 51356], "temperature": 0.0, "avg_logprob": -0.1596099046560434, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001262377598322928}, {"id": 462, "seek": 327744, "start": 3297.28, "end": 3304.32, "text": " more than that yeah so hello i'm chris hello chris so i was one of the co-organizers of the", "tokens": [51356, 544, 813, 300, 1338, 370, 7751, 741, 478, 417, 5714, 7751, 417, 5714, 370, 741, 390, 472, 295, 264, 598, 12, 12372, 22525, 295, 264, 51708], "temperature": 0.0, "avg_logprob": -0.1596099046560434, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001262377598322928}, {"id": 463, "seek": 330432, "start": 3304.32, "end": 3308.1600000000003, "text": " last rendition of the workshop on ontology design patterns so if there's anything in", "tokens": [50364, 1036, 6125, 849, 295, 264, 13541, 322, 6592, 1793, 1715, 8294, 370, 498, 456, 311, 1340, 294, 50556], "temperature": 0.0, "avg_logprob": -0.11607298438931689, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.0010562865063548088}, {"id": 464, "seek": 330432, "start": 3308.1600000000003, "end": 3311.2000000000003, "text": " particular you would like me to comment on now i'm unhappy too", "tokens": [50556, 1729, 291, 576, 411, 385, 281, 2871, 322, 586, 741, 478, 22172, 886, 50708], "temperature": 0.0, "avg_logprob": -0.11607298438931689, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.0010562865063548088}, {"id": 465, "seek": 330432, "start": 3314.48, "end": 3319.28, "text": " so we may have questions what were some of the patterns about from the last or the issues", "tokens": [50872, 370, 321, 815, 362, 1651, 437, 645, 512, 295, 264, 8294, 466, 490, 264, 1036, 420, 264, 2663, 51112], "temperature": 0.0, "avg_logprob": -0.11607298438931689, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.0010562865063548088}, {"id": 466, "seek": 330432, "start": 3320.48, "end": 3321.76, "text": " at that i didn't attend", "tokens": [51172, 412, 300, 741, 994, 380, 6888, 51236], "temperature": 0.0, "avg_logprob": -0.11607298438931689, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.0010562865063548088}, {"id": 467, "seek": 330432, "start": 3323.84, "end": 3328.96, "text": " right so there there were patterns from different domains one of which was particularly interesting", "tokens": [51340, 558, 370, 456, 456, 645, 8294, 490, 819, 25514, 472, 295, 597, 390, 4098, 1880, 51596], "temperature": 0.0, "avg_logprob": -0.11607298438931689, "compression_ratio": 1.7109004739336493, "no_speech_prob": 0.0010562865063548088}, {"id": 468, "seek": 332896, "start": 3328.96, "end": 3334.32, "text": " to me which was about the design of scientific taxonomies now i don't know the", "tokens": [50364, 281, 385, 597, 390, 466, 264, 1715, 295, 8134, 3366, 12481, 530, 586, 741, 500, 380, 458, 264, 50632], "temperature": 0.0, "avg_logprob": -0.0771150490672318, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.01700238510966301}, {"id": 469, "seek": 332896, "start": 3335.2, "end": 3340.48, "text": " details anymore because i haven't reviewed the actual pattern but each year there are a number", "tokens": [50676, 4365, 3602, 570, 741, 2378, 380, 18429, 264, 3539, 5102, 457, 1184, 1064, 456, 366, 257, 1230, 50940], "temperature": 0.0, "avg_logprob": -0.0771150490672318, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.01700238510966301}, {"id": 470, "seek": 332896, "start": 3340.48, "end": 3345.36, "text": " of patterns that get published and one interesting point to notice here is that the patterns that", "tokens": [50940, 295, 8294, 300, 483, 6572, 293, 472, 1880, 935, 281, 3449, 510, 307, 300, 264, 8294, 300, 51184], "temperature": 0.0, "avg_logprob": -0.0771150490672318, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.01700238510966301}, {"id": 471, "seek": 332896, "start": 3345.36, "end": 3351.28, "text": " get published are not always following the same structure so there are different ideas", "tokens": [51184, 483, 6572, 366, 406, 1009, 3480, 264, 912, 3877, 370, 456, 366, 819, 3487, 51480], "temperature": 0.0, "avg_logprob": -0.0771150490672318, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.01700238510966301}, {"id": 472, "seek": 332896, "start": 3351.28, "end": 3357.6, "text": " of what what a design pattern should consist of and also how a design pattern is supposed to be", "tokens": [51480, 295, 437, 437, 257, 1715, 5102, 820, 4603, 295, 293, 611, 577, 257, 1715, 5102, 307, 3442, 281, 312, 51796], "temperature": 0.0, "avg_logprob": -0.0771150490672318, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.01700238510966301}, {"id": 473, "seek": 335760, "start": 3357.6, "end": 3362.56, "text": " reused and this is also one of the key notions in which i personally think that the notion of", "tokens": [50364, 319, 4717, 293, 341, 307, 611, 472, 295, 264, 2141, 35799, 294, 597, 741, 5665, 519, 300, 264, 10710, 295, 50612], "temperature": 0.0, "avg_logprob": -0.0642645682817624, "compression_ratio": 1.890547263681592, "no_speech_prob": 0.004233011044561863}, {"id": 474, "seek": 335760, "start": 3362.56, "end": 3368.08, "text": " the software design patterns differs from the notion of a ontology design pattern so when we", "tokens": [50612, 264, 4722, 1715, 8294, 37761, 490, 264, 10710, 295, 257, 6592, 1793, 1715, 5102, 370, 562, 321, 50888], "temperature": 0.0, "avg_logprob": -0.0642645682817624, "compression_ratio": 1.890547263681592, "no_speech_prob": 0.004233011044561863}, {"id": 475, "seek": 335760, "start": 3368.08, "end": 3375.2, "text": " talk about a software design pattern these patterns are often thought as language agnostic so they", "tokens": [50888, 751, 466, 257, 4722, 1715, 5102, 613, 8294, 366, 2049, 1194, 382, 2856, 623, 77, 19634, 370, 436, 51244], "temperature": 0.0, "avg_logprob": -0.0642645682817624, "compression_ratio": 1.890547263681592, "no_speech_prob": 0.004233011044561863}, {"id": 476, "seek": 335760, "start": 3375.2, "end": 3382.16, "text": " provide us with a solution that could be adopted in different languages whereas these ontology", "tokens": [51244, 2893, 505, 365, 257, 3827, 300, 727, 312, 12175, 294, 819, 8650, 9735, 613, 6592, 1793, 51592], "temperature": 0.0, "avg_logprob": -0.0642645682817624, "compression_ratio": 1.890547263681592, "no_speech_prob": 0.004233011044561863}, {"id": 477, "seek": 338216, "start": 3382.16, "end": 3387.68, "text": " design patterns they are often tailored to a specific knowledge representation language so", "tokens": [50364, 1715, 8294, 436, 366, 2049, 34858, 281, 257, 2685, 3601, 10290, 2856, 370, 50640], "temperature": 0.0, "avg_logprob": -0.11439878184620927, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0010964421089738607}, {"id": 478, "seek": 338216, "start": 3387.68, "end": 3392.64, "text": " that it can be reused in that particular formula and that is one of the key differences that often", "tokens": [50640, 300, 309, 393, 312, 319, 4717, 294, 300, 1729, 8513, 293, 300, 307, 472, 295, 264, 2141, 7300, 300, 2049, 50888], "temperature": 0.0, "avg_logprob": -0.11439878184620927, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0010964421089738607}, {"id": 479, "seek": 338216, "start": 3392.64, "end": 3400.16, "text": " get confused between these two different notions thank you that's a good although i do know in", "tokens": [50888, 483, 9019, 1296, 613, 732, 819, 35799, 1309, 291, 300, 311, 257, 665, 4878, 741, 360, 458, 294, 51264], "temperature": 0.0, "avg_logprob": -0.11439878184620927, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0010964421089738607}, {"id": 480, "seek": 338216, "start": 3400.16, "end": 3407.2, "text": " in his what 10 points that the less that is to produce the owl artifacts so up until then there's", "tokens": [51264, 294, 702, 437, 1266, 2793, 300, 264, 1570, 300, 307, 281, 5258, 264, 34488, 24617, 370, 493, 1826, 550, 456, 311, 51616], "temperature": 0.0, "avg_logprob": -0.11439878184620927, "compression_ratio": 1.6977777777777778, "no_speech_prob": 0.0010964421089738607}, {"id": 481, "seek": 340720, "start": 3407.2, "end": 3414.56, "text": " some degree of conceptualization more abstraction right right so um there have been different", "tokens": [50364, 512, 4314, 295, 24106, 2144, 544, 37765, 558, 558, 370, 1105, 456, 362, 668, 819, 50732], "temperature": 0.0, "avg_logprob": -0.06916141510009766, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.0020138435065746307}, {"id": 482, "seek": 340720, "start": 3414.56, "end": 3421.04, "text": " proposals for how a design pattern is supposed to be reported and one of these proposals includes", "tokens": [50732, 20198, 337, 577, 257, 1715, 5102, 307, 3442, 281, 312, 7055, 293, 472, 295, 613, 20198, 5974, 51056], "temperature": 0.0, "avg_logprob": -0.06916141510009766, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.0020138435065746307}, {"id": 483, "seek": 340720, "start": 3421.04, "end": 3426.96, "text": " this 10-step or 12-step process where you have to um list all the requirements for a particular use", "tokens": [51056, 341, 1266, 12, 16792, 420, 2272, 12, 16792, 1399, 689, 291, 362, 281, 1105, 1329, 439, 264, 7728, 337, 257, 1729, 764, 51352], "temperature": 0.0, "avg_logprob": -0.06916141510009766, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.0020138435065746307}, {"id": 484, "seek": 340720, "start": 3426.96, "end": 3432.8799999999997, "text": " case and all the ways in which a pattern can be reused but that is not standardized in any way", "tokens": [51352, 1389, 293, 439, 264, 2098, 294, 597, 257, 5102, 393, 312, 319, 4717, 457, 300, 307, 406, 31677, 294, 604, 636, 51648], "temperature": 0.0, "avg_logprob": -0.06916141510009766, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.0020138435065746307}, {"id": 485, "seek": 343288, "start": 3432.88, "end": 3438.1600000000003, "text": " so there are different proposals of how this could be achieved and this is just one of them so", "tokens": [50364, 370, 456, 366, 819, 20198, 295, 577, 341, 727, 312, 11042, 293, 341, 307, 445, 472, 295, 552, 370, 50628], "temperature": 0.0, "avg_logprob": -0.0635735442839473, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.00033364034607075155}, {"id": 486, "seek": 343288, "start": 3439.84, "end": 3446.56, "text": " again i have tried to actually empirically look at how patterns are reused and so far", "tokens": [50712, 797, 741, 362, 3031, 281, 767, 25790, 984, 574, 412, 577, 8294, 366, 319, 4717, 293, 370, 1400, 51048], "temperature": 0.0, "avg_logprob": -0.0635735442839473, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.00033364034607075155}, {"id": 487, "seek": 343288, "start": 3447.12, "end": 3452.0, "text": " it doesn't seem to be the case that there are there's a standard notion of either the reuse of", "tokens": [51076, 309, 1177, 380, 1643, 281, 312, 264, 1389, 300, 456, 366, 456, 311, 257, 3832, 10710, 295, 2139, 264, 26225, 295, 51320], "temperature": 0.0, "avg_logprob": -0.0635735442839473, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.00033364034607075155}, {"id": 488, "seek": 343288, "start": 3452.0, "end": 3457.44, "text": " design pattern or standard design patterns that were used consistently throughout ontology so this", "tokens": [51320, 1715, 5102, 420, 3832, 1715, 8294, 300, 645, 1143, 14961, 3710, 6592, 1793, 370, 341, 51592], "temperature": 0.0, "avg_logprob": -0.0635735442839473, "compression_ratio": 1.7809523809523808, "no_speech_prob": 0.00033364034607075155}, {"id": 489, "seek": 345744, "start": 3457.44, "end": 3464.16, "text": " is still a open question that that's a challenging observation that we want to sort of repeat next", "tokens": [50364, 307, 920, 257, 1269, 1168, 300, 300, 311, 257, 7595, 14816, 300, 321, 528, 281, 1333, 295, 7149, 958, 50700], "temperature": 0.0, "avg_logprob": -0.15713804960250854, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.001986356917768717}, {"id": 490, "seek": 345744, "start": 3464.16, "end": 3469.44, "text": " week so i hope you'll be back for that and ask again because i i agree that you know this is an", "tokens": [50700, 1243, 370, 741, 1454, 291, 603, 312, 646, 337, 300, 293, 1029, 797, 570, 741, 741, 3986, 300, 291, 458, 341, 307, 364, 50964], "temperature": 0.0, "avg_logprob": -0.15713804960250854, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.001986356917768717}, {"id": 491, "seek": 345744, "start": 3469.44, "end": 3474.96, "text": " we're empiricists here so we want to know what really works where things are and so forth and", "tokens": [50964, 321, 434, 25790, 299, 1751, 510, 370, 321, 528, 281, 458, 437, 534, 1985, 689, 721, 366, 293, 370, 5220, 293, 51240], "temperature": 0.0, "avg_logprob": -0.15713804960250854, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.001986356917768717}, {"id": 492, "seek": 345744, "start": 3474.96, "end": 3483.68, "text": " what can be re really reused so we we have looked at modl model they're they're curated the repository", "tokens": [51240, 437, 393, 312, 319, 534, 319, 4717, 370, 321, 321, 362, 2956, 412, 1072, 75, 2316, 436, 434, 436, 434, 47851, 264, 25841, 51676], "temperature": 0.0, "avg_logprob": -0.15713804960250854, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.001986356917768717}, {"id": 493, "seek": 348368, "start": 3483.68, "end": 3488.3999999999996, "text": " for ontologies for odp's anybody else looked at that", "tokens": [50364, 337, 6592, 6204, 337, 3611, 79, 311, 4472, 1646, 2956, 412, 300, 50600], "temperature": 0.0, "avg_logprob": -0.23374865347878976, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.009122141636908054}, {"id": 494, "seek": 348368, "start": 3492.48, "end": 3496.8799999999997, "text": " oh right here the importance of building up a library we've got a hand raised", "tokens": [50804, 1954, 558, 510, 264, 7379, 295, 2390, 493, 257, 6405, 321, 600, 658, 257, 1011, 6005, 51024], "temperature": 0.0, "avg_logprob": -0.23374865347878976, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.009122141636908054}, {"id": 495, "seek": 348368, "start": 3498.16, "end": 3500.3199999999997, "text": " oh okay i missed it maybe it's on the other screen", "tokens": [51088, 1954, 1392, 741, 6721, 309, 1310, 309, 311, 322, 264, 661, 2568, 51196], "temperature": 0.0, "avg_logprob": -0.23374865347878976, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.009122141636908054}, {"id": 496, "seek": 348368, "start": 3505.68, "end": 3511.3599999999997, "text": " oh unfortunately disappeared they have to go", "tokens": [51464, 1954, 7015, 13954, 436, 362, 281, 352, 51748], "temperature": 0.0, "avg_logprob": -0.23374865347878976, "compression_ratio": 1.477124183006536, "no_speech_prob": 0.009122141636908054}, {"id": 497, "seek": 351136, "start": 3511.76, "end": 3516.7200000000003, "text": " so hopefully they we can continue this next week yeah", "tokens": [50384, 370, 4696, 436, 321, 393, 2354, 341, 958, 1243, 1338, 50632], "temperature": 0.0, "avg_logprob": -0.15955356649450353, "compression_ratio": 1.6717948717948719, "no_speech_prob": 0.0006982108461670578}, {"id": 498, "seek": 351136, "start": 3519.1200000000003, "end": 3526.2400000000002, "text": " yes indeed and so call hammer who's now at google has been very involved in these things", "tokens": [50752, 2086, 6451, 293, 370, 818, 13017, 567, 311, 586, 412, 20742, 575, 668, 588, 3288, 294, 613, 721, 51108], "temperature": 0.0, "avg_logprob": -0.15955356649450353, "compression_ratio": 1.6717948717948719, "no_speech_prob": 0.0006982108461670578}, {"id": 499, "seek": 351136, "start": 3526.2400000000002, "end": 3532.48, "text": " continually and has done a lot of practical development with them and can speak to that", "tokens": [51108, 22277, 293, 575, 1096, 257, 688, 295, 8496, 3250, 365, 552, 293, 393, 1710, 281, 300, 51420], "temperature": 0.0, "avg_logprob": -0.15955356649450353, "compression_ratio": 1.6717948717948719, "no_speech_prob": 0.0006982108461670578}, {"id": 500, "seek": 351136, "start": 3532.48, "end": 3538.8, "text": " and can speak to methods used and since he's went from ibm to google there's probably something", "tokens": [51420, 293, 393, 1710, 281, 7150, 1143, 293, 1670, 415, 311, 1437, 490, 39073, 76, 281, 20742, 456, 311, 1391, 746, 51736], "temperature": 0.0, "avg_logprob": -0.15955356649450353, "compression_ratio": 1.6717948717948719, "no_speech_prob": 0.0006982108461670578}, {"id": 501, "seek": 353880, "start": 3538.8, "end": 3544.1600000000003, "text": " he's able has been able to do he may be able to speak at a different degree of abstraction but", "tokens": [50364, 415, 311, 1075, 575, 668, 1075, 281, 360, 415, 815, 312, 1075, 281, 1710, 412, 257, 819, 4314, 295, 37765, 457, 50632], "temperature": 0.0, "avg_logprob": -0.10930740669982074, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.004977052565664053}, {"id": 502, "seek": 353880, "start": 3544.1600000000003, "end": 3553.76, "text": " he has practical experience um so with that i think we can adjourn for today and um and hopefully", "tokens": [50632, 415, 575, 8496, 1752, 1105, 370, 365, 300, 741, 519, 321, 393, 46236, 77, 337, 965, 293, 1105, 293, 4696, 51112], "temperature": 0.0, "avg_logprob": -0.10930740669982074, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.004977052565664053}, {"id": 503, "seek": 353880, "start": 3553.76, "end": 3560.5600000000004, "text": " see you all again next week and tell your friends i hope frisk can make it okay i'm glad to be there", "tokens": [51112, 536, 291, 439, 797, 958, 1243, 293, 980, 428, 1855, 741, 1454, 431, 7797, 393, 652, 309, 1392, 741, 478, 5404, 281, 312, 456, 51452], "temperature": 0.0, "avg_logprob": -0.10930740669982074, "compression_ratio": 1.5837837837837838, "no_speech_prob": 0.004977052565664053}, {"id": 504, "seek": 356056, "start": 3560.56, "end": 3564.32, "text": " thanks everybody i don't know", "tokens": [50364, 3231, 2201, 741, 500, 380, 458, 50552], "temperature": 0.0, "avg_logprob": -0.6234700944688585, "compression_ratio": 0.7837837837837838, "no_speech_prob": 0.08832739293575287}], "language": "en"}