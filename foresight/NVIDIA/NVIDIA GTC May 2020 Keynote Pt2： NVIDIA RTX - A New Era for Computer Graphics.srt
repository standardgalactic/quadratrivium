1
00:00:00,000 --> 00:00:08,440
Computer graphics is the driving force of NVIDIA.

2
00:00:08,440 --> 00:00:12,160
It is one of the world's most computationally intensive applications.

3
00:00:12,160 --> 00:00:15,840
It has been for decades, and it will continue to be for decades to come.

4
00:00:15,840 --> 00:00:23,160
Forty years ago, one of NVIDIA's researchers wrote a seminal paper on a technique to simulate

5
00:00:23,160 --> 00:00:25,320
light we call ray tracing.

6
00:00:25,320 --> 00:00:30,640
To trace a light beam through an environment bouncing off surfaces, reflecting, refracting

7
00:00:30,640 --> 00:00:36,040
or illuminating that surface ultimately generate what is a photorealistic image.

8
00:00:36,040 --> 00:00:42,840
Two years ago, at 2018 SIGGRAPH in Vancouver, BC, we announced one of our most ambitious

9
00:00:42,840 --> 00:00:44,160
endeavors.

10
00:00:44,160 --> 00:00:46,240
We call it the NVIDIA RTX.

11
00:00:46,240 --> 00:00:50,720
NVIDIA RTX fuses two groundbreaking technologies.

12
00:00:50,720 --> 00:00:55,640
The first is accelerated ray tracing, and the second breakthrough is deep learning.

13
00:00:55,640 --> 00:01:00,040
Ray tracing is so computationally intensive, even with the amazing accelerator that we've

14
00:01:00,040 --> 00:01:03,600
created, it just simply wasn't fast enough.

15
00:01:03,600 --> 00:01:06,360
And then the breakthrough of artificial intelligence happened.

16
00:01:06,360 --> 00:01:11,360
And over the last three years, we've been piling onto this technology to solve the

17
00:01:11,360 --> 00:01:13,380
last missing piece of the puzzle.

18
00:01:13,380 --> 00:01:18,400
We use ray tracing in our programmable shaders, and the fastest possible GPUs we could make

19
00:01:18,480 --> 00:01:21,760
to generate a relatively low resolution image.

20
00:01:21,760 --> 00:01:25,440
And in this particular case, 540p, not even anti-aliased.

21
00:01:25,440 --> 00:01:28,920
It also generates, along with it, a motion vector.

22
00:01:28,920 --> 00:01:32,960
Where the pixel is and where it's traveling, that goes into an artificial intelligence

23
00:01:32,960 --> 00:01:37,540
network which tries to synthesize a higher resolution image.

24
00:01:37,540 --> 00:01:42,800
We teach this artificial intelligence network what extremely high resolution and high quality

25
00:01:42,800 --> 00:01:44,080
images look like.

26
00:01:44,080 --> 00:01:51,320
In this particular case, we use a supercomputer to render 16K anti-aliased resolution images.

27
00:01:51,320 --> 00:01:56,040
We then compare what comes out of the neural network with this ground truth.

28
00:01:56,040 --> 00:02:00,960
The difference propagates back into the network through a supercomputer, and it corrects the

29
00:02:00,960 --> 00:02:05,400
weights of the neurons as to improve its ability to guess the next time.

30
00:02:05,400 --> 00:02:07,400
We go through this trillions of times.

31
00:02:07,400 --> 00:02:13,320
Eventually, this neural network could take just a few pixels, 540p in this case, and

32
00:02:13,320 --> 00:02:16,840
synthesize what otherwise would be a beautiful image.

33
00:02:16,840 --> 00:02:18,040
Incredible.

34
00:02:18,040 --> 00:02:21,640
Then we take this neural network, we download it into your GeForce computers, particularly

35
00:02:21,640 --> 00:02:26,880
the ones with Turing, are now ready to receive this neural network and process it on the

36
00:02:26,880 --> 00:02:30,040
tensor core processor in the Turing GPU.

37
00:02:30,040 --> 00:02:35,120
We call this technology DLSS, Deep Learning Super Sampling.

38
00:02:35,120 --> 00:02:38,960
What you're looking at here is the image generated by the supercomputer.

39
00:02:38,960 --> 00:02:42,200
Its 16K resolution is completely anti-aliased.

40
00:02:42,200 --> 00:02:46,320
This is a scene from an Unreal Engine demo that Epic did called Infiltrator.

41
00:02:46,320 --> 00:02:47,600
It's really a beautiful demo.

42
00:02:47,600 --> 00:02:48,880
They did this several years ago.

43
00:02:48,880 --> 00:02:52,200
Here, what I'm showing you is 16K ground truth.

44
00:02:52,200 --> 00:02:55,960
The next scene is rendered, and it's 720p.

45
00:02:55,960 --> 00:02:56,960
Notice how blurry it is.

46
00:02:56,960 --> 00:02:59,000
Let me just go back one more time so you can see it.

47
00:02:59,000 --> 00:03:03,000
This is ground truth, 16K, look at the small lights.

48
00:03:03,000 --> 00:03:07,960
We like to look at the leaves on the trees, the clouds from afar, that is so crisp.

49
00:03:07,960 --> 00:03:09,440
The detail is incredible.

50
00:03:09,440 --> 00:03:14,480
This is rendered at 720p, and here what I'm showing you is our first try, and we call

51
00:03:14,480 --> 00:03:17,480
it DLSS 1.0.

52
00:03:17,480 --> 00:03:22,760
Notice it improves the resolution that appears, but only by a little bit.

53
00:03:22,760 --> 00:03:28,200
Most people felt that the artificial intelligence technology was not going to work, but we believed

54
00:03:28,200 --> 00:03:30,120
in it and we didn't give up.

55
00:03:30,120 --> 00:03:37,720
This is, ladies and gentlemen, DLSS 2.0, scaling from 720p, generating the pixels necessary

56
00:03:37,720 --> 00:03:41,680
to create a 1080p anti-aliased image.

57
00:03:41,680 --> 00:03:46,960
Look at that, first generation, a little blurry, second generation.

58
00:03:46,960 --> 00:03:48,560
Look at all the lights.

59
00:03:48,560 --> 00:03:50,720
It's much, much more than sharpening.

60
00:03:50,720 --> 00:03:54,000
Look at all the lights that all of a sudden appear that didn't appear before.

61
00:03:54,000 --> 00:03:57,480
How do you create content where content did not exist?

62
00:03:57,480 --> 00:04:02,320
Well, partly because the neural network has learned what the image should look like, and

63
00:04:02,320 --> 00:04:08,360
secondarily, because we have motion vectors and the pixels by observing across a few scenes,

64
00:04:08,360 --> 00:04:11,600
the neural network can predict what each scene should look like.

65
00:04:11,600 --> 00:04:16,640
Now, if you were to render this with native 1080p, using the GPU to render each and every

66
00:04:16,640 --> 00:04:19,120
pixel anti-aliased, this is what it looks like.

67
00:04:19,120 --> 00:04:23,880
This is native 1080p, and look, artificial intelligence actually does a better job going

68
00:04:23,880 --> 00:04:25,920
back to DLSS 2.0.

69
00:04:25,920 --> 00:04:30,120
Look at that, AI does a better job than 1080p native.

70
00:04:30,120 --> 00:04:32,160
That is a complete breakthrough.

71
00:04:32,160 --> 00:04:37,280
Suppose we started from 540p, and because there are so few pixels, most of the pixels

72
00:04:37,280 --> 00:04:39,640
are blurry when we scale it up to this image.

73
00:04:39,640 --> 00:04:44,960
Now imagine if we were to take this 540p image and put it into a artificial intelligence

74
00:04:44,960 --> 00:04:50,280
network, DLSS 2.0, and this neural network had learned from beautiful images that were

75
00:04:50,280 --> 00:04:55,320
generated by a supercomputer, and it's now asked to recreate that image.

76
00:04:55,320 --> 00:04:56,320
Look at that.

77
00:04:56,320 --> 00:05:02,640
This is the input, 540p, and this is the output, DLSS 2.0, 540p to 1080p.

78
00:05:02,640 --> 00:05:04,040
What an amazing breakthrough.

79
00:05:04,040 --> 00:05:10,200
Let's take a look at the combination of RTX and DLSS on the most popular game in the

80
00:05:10,200 --> 00:05:11,920
world, Minecraft.

81
00:05:11,920 --> 00:05:17,280
Because each one of the worlds are created by the gamer, it is not possible to pre-bake

82
00:05:17,280 --> 00:05:23,460
a lot of the shadows and lighting effects that you see in very big blockbuster games.

83
00:05:23,460 --> 00:05:28,500
This is created by the users themselves, and so the lighting effects can't be cheated,

84
00:05:28,500 --> 00:05:33,020
and it has to be generated by the program, which is the reason why we chose to work with

85
00:05:33,020 --> 00:05:36,060
the team at Minecraft to bring RTX to it.

86
00:05:36,060 --> 00:05:41,180
Now with this particular scene, you can see that when we render Minecraft without DLSS

87
00:05:41,180 --> 00:05:45,160
with just ray tracing, the frame rate was only 35 frames per second.

88
00:05:45,160 --> 00:05:51,460
With DLSS, we can render this beautiful image and then use DLSS to scale that low resolution

89
00:05:51,460 --> 00:05:53,980
image and still maintain the speed.

90
00:05:53,980 --> 00:06:00,300
So now you get beautiful image with ray tracing, high resolution, and high speed all at the

91
00:06:00,300 --> 00:06:04,020
same time, and that is the requirement for modern computer graphics.

92
00:06:04,020 --> 00:06:07,380
Let me show you now a video that we just made of Minecraft.

93
00:06:07,380 --> 00:06:10,540
The reception has been incredible all over the world.

94
00:06:10,540 --> 00:06:11,340
You're going to love this video.

95
00:06:51,460 --> 00:07:10,620
Oh my goodness, this looks insane.

96
00:07:10,620 --> 00:07:11,620
Look at the shiny floor.

97
00:07:11,620 --> 00:07:13,300
I feel like I'm going to slip and fall down.

98
00:07:13,300 --> 00:07:14,300
It hurt myself.

99
00:07:14,300 --> 00:07:15,300
Look at that.

100
00:07:15,300 --> 00:07:16,300
Look at that.

101
00:07:16,300 --> 00:07:17,300
Look at that.

102
00:07:17,300 --> 00:07:18,300
Look at that.

103
00:07:18,300 --> 00:07:19,300
Look at that.

104
00:07:19,460 --> 00:07:20,460
Out.

105
00:07:20,460 --> 00:07:21,460
Boom.

106
00:07:21,460 --> 00:07:27,020
Look at the way the light comes through the wall.

107
00:07:27,020 --> 00:07:29,940
It really adds just this level of depth.

108
00:07:29,940 --> 00:07:30,940
Is that mirrors?

109
00:07:30,940 --> 00:07:35,220
It's mirrors.

110
00:07:35,220 --> 00:07:40,660
Ladies and gentlemen, RTX on, ray tracing, DLSS.

111
00:07:40,660 --> 00:07:45,780
We've made possible real-time ray tracing 10 years earlier than anybody thought was

112
00:07:45,780 --> 00:07:46,780
possible.

113
00:07:46,780 --> 00:07:51,860
When we launched it, people were skeptical, but now it is very, very clear that ray tracing

114
00:07:51,860 --> 00:07:54,700
is here and it's the next big thing.

115
00:07:54,700 --> 00:07:57,140
Creating 3D content is hard.

116
00:07:57,140 --> 00:08:01,940
It takes so many different types of disciplines from artists to designers to software programmers.

117
00:08:01,940 --> 00:08:07,740
Uses all kinds of different tools from MyEd, 3D Studio Max, to Photoshop, and they're creating

118
00:08:07,740 --> 00:08:11,100
these worlds that take enormous databases.

119
00:08:11,100 --> 00:08:15,460
That's one of the reasons why it's so expensive and so hard to create world-class 3D content.

120
00:08:15,540 --> 00:08:16,740
We have a solution for that.

121
00:08:16,740 --> 00:08:22,020
We call it the NVIDIA Omniverse and it leverages all of NVIDIA's technology over the last

122
00:08:22,020 --> 00:08:23,020
10 years.

123
00:08:23,020 --> 00:08:28,500
On the foundation is our RTX server, our latest generation GPUs, then it's built on top of

124
00:08:28,500 --> 00:08:31,460
a virtual application server.

125
00:08:31,460 --> 00:08:37,020
Each one of the GPUs could be shared by many different designers using virtual quadro or

126
00:08:37,020 --> 00:08:41,180
many GPUs could gang up to accelerate one application.

127
00:08:41,180 --> 00:08:46,020
The networking is accelerated and offloaded by Melanox Nix, the smart Nix that we were

128
00:08:46,020 --> 00:08:47,420
talking about earlier.

129
00:08:47,420 --> 00:08:50,940
And then one of the virtual machines is the Omniverse Nucleus.

130
00:08:50,940 --> 00:08:56,860
This nucleus has created a shared space, a shared world, and this shared world has portals.

131
00:08:56,860 --> 00:09:02,860
The output of that portal is visualized and streamed to any device you like.

132
00:09:02,860 --> 00:09:08,220
Multiple designers could work on one design at the same time and reviewers could ask for

133
00:09:08,220 --> 00:09:10,300
changes in real time.

134
00:09:10,300 --> 00:09:13,860
The ultimate design collaboration platform.

135
00:09:13,860 --> 00:09:17,340
Let me show you a demo that's created by NVIDIA engineers.

136
00:09:17,340 --> 00:09:19,600
What I'm about to show you is really amazing.

137
00:09:19,600 --> 00:09:23,500
This was done over the course of the last couple of months.

138
00:09:23,500 --> 00:09:27,660
Artist designers from different locations and it's never been seen before.

139
00:09:27,660 --> 00:09:30,460
It is completely ray traced.

140
00:09:30,460 --> 00:09:34,300
None of the lights are baked, none of the shadows are baked, everything is completely

141
00:09:34,300 --> 00:09:36,380
lit and shadowed in real time.

142
00:09:36,460 --> 00:09:40,420
And one of the most important things is everything obeys the laws of physics.

143
00:09:40,420 --> 00:09:41,420
Let's roll it.

144
00:12:06,380 --> 00:12:13,340
Isn't that amazing?

145
00:12:13,340 --> 00:12:18,460
Real time ray tracing, physically based materials, obeys the laws of physics.

146
00:12:18,460 --> 00:12:24,220
It was created by just a few designers and engineers on top of Omniverse working remotely

147
00:12:24,220 --> 00:12:26,580
from different states.

148
00:12:26,580 --> 00:12:27,720
Incredible achievement.

149
00:12:27,720 --> 00:12:28,720
Just so beautiful.

150
00:12:28,720 --> 00:12:29,720
I love it.

151
00:12:29,720 --> 00:12:32,340
And so ladies and gentlemen, this is the NVIDIA Omniverse.

152
00:12:32,340 --> 00:12:35,820
It starts with a server with a whole bunch of RTX 8000s.

153
00:12:35,820 --> 00:12:41,140
These are the most powerful ray tracing GPUs in the world, tensor core processing to do

154
00:12:41,140 --> 00:12:46,740
AI so that we can both have beautiful images and high resolution and high performance at

155
00:12:46,740 --> 00:12:47,900
the same time.

156
00:12:47,900 --> 00:12:51,220
The servers are available from Box, Dell, HP and Supermicro.

157
00:12:51,220 --> 00:12:56,860
And it's been preconfigured with all the hypervisors necessary, the networking stack

158
00:12:56,860 --> 00:13:01,740
and the virtual quadros so that you can remotely run applications so that you could create

159
00:13:01,740 --> 00:13:04,060
portals into the shared space.

160
00:13:04,060 --> 00:13:06,020
It's really, really an amazing thing.

161
00:13:06,020 --> 00:13:11,100
In today's world where you have to work remotely and share and collaborate with large numbers

162
00:13:11,100 --> 00:13:14,300
of people, this couldn't have come at a better time.

163
00:13:14,300 --> 00:13:15,380
The NVIDIA Omniverse.

