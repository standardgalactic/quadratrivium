start	end	text
0	8000	Inference is the last stage of the machine learning pipeline.
8000	14000	This is where you take the model that you trained and deploy it into services to make predictions.
14000	20000	What comes out of the machine learning pipeline and frameworks are computational graphs that are incredibly complex.
20000	26000	These are gigantic computational graphs and there are so many different types of neural network architectures
26000	31000	that the computer science of compiling these computational graphs into a target machine
31000	38000	to run as fast as possible with all the different types of numeric precision is an incredibly complex problem.
38000	41000	We created an optimizing compiler, TensorFlow RT.
41000	48000	We're now in our seventh generation. This generation can handle CNNs and transformers and now we can handle RNNs as well.
48000	52000	TensorFlow RT 7 includes over a thousand optimized kernels.
52000	59000	And in fact, our developers could do the same for themselves and create all kinds of custom kernels and custom neural networks.
59000	65000	We support precisions from FP32, FP16 all the way to 8-bit and 4-bit integer.
65000	70000	TensorFlow RT has been a huge success. The number of developers that use TensorFlow RT increased 10x.
70000	76000	The world's top 300 internet services now have NVIDIA GPUs in their data centers to do inference.
76000	81000	It just kind of shows you how many industries deep learning and AI is going to impact.
81000	86000	One of the most important applications that we can now enable is conversational AI.
86000	93000	It is one of the most challenging inference tasks because conversational AI requires interactive performance.
93000	99000	The elements that make up a conversational AI pipeline has achieved tremendous breakthroughs recently.
99000	106000	Starting from ASR, automatic speech recognition, to natural language understanding, to text-to-speech speech synthesis.
106000	114000	And now it's possible for us to imagine for the very first time having an interactive, low-latency conversational AI pipeline.
114000	117000	However, the application is very complex still.
117000	122000	The models are state-of-the-art. Training those models take a tremendous amount of computation.
122000	130000	And the ability to put together all of the models end-to-end on top of a computing platform fully accelerated is something the world's never done before.
130000	131000	Until now.
131000	138000	Ladies and gentlemen, we're announcing today a new application framework we call Jarvis.
138000	144000	And because it has the ability to connect into Omniverse, we have the ability to create an interactive 3D chatbot.
144000	149000	One of the AI models that makes this entire experience possible is what we call audio-to-face.
149000	156000	It takes an audio input and it has learned how to animate a geometric mesh to animate facial expressions while talking.
156000	161000	That then drives our computer graphics system in Omniverse and creates an interactive chatbot.
161000	164000	Let me now show you our AI model audio-to-face.
164000	169000	The speech here is coming from a rapper, one of our employees, John Delabona.
169000	172000	And it is really fantastic. Take a look.
186000	191000	Once we have audio-to-face, we have the ability to create an interactive 3D chatbot.
191000	196000	And we have the ability to create an interactive 3D chatbot.
196000	201000	And we have the ability to create an interactive 3D chatbot.
201000	206000	And we have the ability to create an interactive 3D chatbot.
206000	211000	And we have the ability to create an interactive 3D chatbot.
211000	215000	And we have the ability to create an interactive 3D chatbot.
215000	219000	Once we have audio-to-face, then we can connect it to our conversational AI model,
219000	224000	where you can ask it a question, it would understand the question, answer the question,
224000	230000	and then synthesize speech from that, which goes into our audio-to-face model, which animates and drives a 3D model.
230000	235000	We've created a demonstration we call MISTI, our first interactive 3D chatbot.
235000	237000	Hello.
237000	239000	Hi, I'm MISTI.
239000	240000	How are you?
240000	243000	I'm doing well. Thank you for asking.
243000	244000	What are you here for?
244000	248000	I'm here to give you the latest weather information around the world.
248000	252000	Tell you interesting facts about meteorology and keep you company.
252000	254000	Should I bring an umbrella tomorrow?
254000	259000	It is not expected to rain in Santa Clara, California tomorrow afternoon.
259000	262000	What is the hottest city in the world?
262000	269000	The hottest city in the world is Mecca, in Saudi Arabia where temperatures can reach 122 degrees Fahrenheit.
269000	271000	What is the coldest city?
271000	278000	The coldest city in the world is Yakutsk in Russia with temperatures around minus 40 degrees Fahrenheit in the winter months.
282000	284000	Tell me something about lightning.
284000	288000	We see lightning first, because light travels faster than sound.
292000	294000	How come you know so much about weather?
294000	297000	I know the weather information from the internet.
297000	302000	I have lived for a long time and have been talking about the weather for as long as I know.
302000	304000	Where are you from, MISTI?
304000	306000	I'm from a place called Omniverse.
306000	308000	Who made you?
308000	311000	I'm created by the wonderful scientists of NVIDIA.
311000	313000	What powers you?
313000	318000	I'm powered by NVIDIA GPU and the CUDA neurons inside of them.
318000	319000	Thank you, MISTI.
319000	323000	Thank you. It was a pleasure talking to you.
323000	337000	As you could see, the ability to have an interactive conversation requires the conversation AI to process the speech, the natural language understanding, synthesize and also render the graphics as fast as possible.
337000	352000	And you have to process the entire pipeline end-to-end from speech recognition, language understanding, text-to-speech as well as driving and generating the computer graphics in just a few hundred milliseconds in order to feel like you're having an interactive conversation.
352000	362000	And that's what NVIDIA Jarvis is about, a multimodal conversational AI service framework that simplifies the creation and the development of conversational AI services.
362000	377000	It includes state-of-the-art models that has been pre-pipelined into these helms charts, optimized to run on NVIDIA's Triton inference server, which runs on top of our GPUs, and the performance is interactive, and the entire pipeline end-to-end is only a few hundred milliseconds.
377000	378000	But there's more.
378000	381000	Jarvis comes with pre-trained state-of-the-art models.
381000	385000	These state-of-the-art models have been trained with a great deal of data and a lot of computation.
385000	393000	In fact, what's available in NGC, the NVIDIA GPU cloud, represents several hundred thousand DGX training hours.
393000	400000	If you had one DGX, it would take you something like 10 to 20 years to be able to process all of the data necessary to train these models.
400000	401000	We've done that for you.
401000	407000	And then it comes with a new tool called NEMO, which takes the pre-trained model and augments it with your data.
407000	412000	Your data could, because of a particular domain, it could be in healthcare or insurance or financial services,
412000	420000	or maybe it's a call center for a particular business, and there's special language or special vocabulary that Jarvis needs to learn.
420000	427000	And so you would take that data and you would train, retrain the Jarvis models with this tool we call NEMO.
427000	431000	This end-to-end pipeline from pre-trained models, retraining with NEMO,
431000	441000	and then the application of all of these state-of-the-art models all put together in a Helms chart running on a service on top of trying this entire end-to-end system we call Jarvis.
441000	450000	Conversational AI is going to automate conversations and it's going to make it possible for us to deploy automated services in all kinds of new applications,
450000	453000	whether it's video conferencing, call centers, smart speakers.
453000	456000	One of my favorite applications is video conferencing.
456000	460000	When you have a group conference, one person can talk at a time.
460000	464000	It would be nice sometimes if we can kind of hear multiple people talking.
464000	465000	So it wouldn't be amazing.
465000	470000	Whenever anybody talks, it's picked up in closed caption or translated in real time,
470000	474000	or the end of a conference, a simple summary and transcription is done.
474000	479000	Video conferencing with a conversational AI agent is going to be really transformed.
479000	483000	We know that the number of people who are calling into call centers these days is growing,
483000	487000	and many of the call centers have people wait half an hour to much longer.
487000	493000	Jarvis conversational AI is going to be one of the most important real-time inference applications.
493000	495000	So that's NVIDIA AI.
495000	501000	It is now end-to-end fully accelerated from data processing with the amount of data growing exponentially.
501000	505000	Spark is more important than ever and now it's accelerated by NVIDIA.
505000	511000	Second, the deep learning and the model training pipeline, we have accelerated for a long time.
511000	516000	One of the particular applications recommender systems is so complicated,
516000	522000	we decided to create an application framework just for it so that we can democratize recommender systems.
522000	524000	We call NVIDIA Merlin.
524000	526000	And then lastly, inference.
526000	528000	TensorRT 7.0 is here.
528000	533000	The number of people who are downloading it and using it is really growing and we're super excited about that.
533000	540000	We decided to create an application framework for every company to be able to create state-of-the-art conversational AI models.
540000	542000	We call that NVIDIA Jarvis.
542000	550000	This end-to-end acceleration platform and some of the reference applications is what we call NVIDIA AI.
