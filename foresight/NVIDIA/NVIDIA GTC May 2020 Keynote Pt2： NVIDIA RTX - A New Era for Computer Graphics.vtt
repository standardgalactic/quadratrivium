WEBVTT

00:00.000 --> 00:08.440
Computer graphics is the driving force of NVIDIA.

00:08.440 --> 00:12.160
It is one of the world's most computationally intensive applications.

00:12.160 --> 00:15.840
It has been for decades, and it will continue to be for decades to come.

00:15.840 --> 00:23.160
Forty years ago, one of NVIDIA's researchers wrote a seminal paper on a technique to simulate

00:23.160 --> 00:25.320
light we call ray tracing.

00:25.320 --> 00:30.640
To trace a light beam through an environment bouncing off surfaces, reflecting, refracting

00:30.640 --> 00:36.040
or illuminating that surface ultimately generate what is a photorealistic image.

00:36.040 --> 00:42.840
Two years ago, at 2018 SIGGRAPH in Vancouver, BC, we announced one of our most ambitious

00:42.840 --> 00:44.160
endeavors.

00:44.160 --> 00:46.240
We call it the NVIDIA RTX.

00:46.240 --> 00:50.720
NVIDIA RTX fuses two groundbreaking technologies.

00:50.720 --> 00:55.640
The first is accelerated ray tracing, and the second breakthrough is deep learning.

00:55.640 --> 01:00.040
Ray tracing is so computationally intensive, even with the amazing accelerator that we've

01:00.040 --> 01:03.600
created, it just simply wasn't fast enough.

01:03.600 --> 01:06.360
And then the breakthrough of artificial intelligence happened.

01:06.360 --> 01:11.360
And over the last three years, we've been piling onto this technology to solve the

01:11.360 --> 01:13.380
last missing piece of the puzzle.

01:13.380 --> 01:18.400
We use ray tracing in our programmable shaders, and the fastest possible GPUs we could make

01:18.480 --> 01:21.760
to generate a relatively low resolution image.

01:21.760 --> 01:25.440
And in this particular case, 540p, not even anti-aliased.

01:25.440 --> 01:28.920
It also generates, along with it, a motion vector.

01:28.920 --> 01:32.960
Where the pixel is and where it's traveling, that goes into an artificial intelligence

01:32.960 --> 01:37.540
network which tries to synthesize a higher resolution image.

01:37.540 --> 01:42.800
We teach this artificial intelligence network what extremely high resolution and high quality

01:42.800 --> 01:44.080
images look like.

01:44.080 --> 01:51.320
In this particular case, we use a supercomputer to render 16K anti-aliased resolution images.

01:51.320 --> 01:56.040
We then compare what comes out of the neural network with this ground truth.

01:56.040 --> 02:00.960
The difference propagates back into the network through a supercomputer, and it corrects the

02:00.960 --> 02:05.400
weights of the neurons as to improve its ability to guess the next time.

02:05.400 --> 02:07.400
We go through this trillions of times.

02:07.400 --> 02:13.320
Eventually, this neural network could take just a few pixels, 540p in this case, and

02:13.320 --> 02:16.840
synthesize what otherwise would be a beautiful image.

02:16.840 --> 02:18.040
Incredible.

02:18.040 --> 02:21.640
Then we take this neural network, we download it into your GeForce computers, particularly

02:21.640 --> 02:26.880
the ones with Turing, are now ready to receive this neural network and process it on the

02:26.880 --> 02:30.040
tensor core processor in the Turing GPU.

02:30.040 --> 02:35.120
We call this technology DLSS, Deep Learning Super Sampling.

02:35.120 --> 02:38.960
What you're looking at here is the image generated by the supercomputer.

02:38.960 --> 02:42.200
Its 16K resolution is completely anti-aliased.

02:42.200 --> 02:46.320
This is a scene from an Unreal Engine demo that Epic did called Infiltrator.

02:46.320 --> 02:47.600
It's really a beautiful demo.

02:47.600 --> 02:48.880
They did this several years ago.

02:48.880 --> 02:52.200
Here, what I'm showing you is 16K ground truth.

02:52.200 --> 02:55.960
The next scene is rendered, and it's 720p.

02:55.960 --> 02:56.960
Notice how blurry it is.

02:56.960 --> 02:59.000
Let me just go back one more time so you can see it.

02:59.000 --> 03:03.000
This is ground truth, 16K, look at the small lights.

03:03.000 --> 03:07.960
We like to look at the leaves on the trees, the clouds from afar, that is so crisp.

03:07.960 --> 03:09.440
The detail is incredible.

03:09.440 --> 03:14.480
This is rendered at 720p, and here what I'm showing you is our first try, and we call

03:14.480 --> 03:17.480
it DLSS 1.0.

03:17.480 --> 03:22.760
Notice it improves the resolution that appears, but only by a little bit.

03:22.760 --> 03:28.200
Most people felt that the artificial intelligence technology was not going to work, but we believed

03:28.200 --> 03:30.120
in it and we didn't give up.

03:30.120 --> 03:37.720
This is, ladies and gentlemen, DLSS 2.0, scaling from 720p, generating the pixels necessary

03:37.720 --> 03:41.680
to create a 1080p anti-aliased image.

03:41.680 --> 03:46.960
Look at that, first generation, a little blurry, second generation.

03:46.960 --> 03:48.560
Look at all the lights.

03:48.560 --> 03:50.720
It's much, much more than sharpening.

03:50.720 --> 03:54.000
Look at all the lights that all of a sudden appear that didn't appear before.

03:54.000 --> 03:57.480
How do you create content where content did not exist?

03:57.480 --> 04:02.320
Well, partly because the neural network has learned what the image should look like, and

04:02.320 --> 04:08.360
secondarily, because we have motion vectors and the pixels by observing across a few scenes,

04:08.360 --> 04:11.600
the neural network can predict what each scene should look like.

04:11.600 --> 04:16.640
Now, if you were to render this with native 1080p, using the GPU to render each and every

04:16.640 --> 04:19.120
pixel anti-aliased, this is what it looks like.

04:19.120 --> 04:23.880
This is native 1080p, and look, artificial intelligence actually does a better job going

04:23.880 --> 04:25.920
back to DLSS 2.0.

04:25.920 --> 04:30.120
Look at that, AI does a better job than 1080p native.

04:30.120 --> 04:32.160
That is a complete breakthrough.

04:32.160 --> 04:37.280
Suppose we started from 540p, and because there are so few pixels, most of the pixels

04:37.280 --> 04:39.640
are blurry when we scale it up to this image.

04:39.640 --> 04:44.960
Now imagine if we were to take this 540p image and put it into a artificial intelligence

04:44.960 --> 04:50.280
network, DLSS 2.0, and this neural network had learned from beautiful images that were

04:50.280 --> 04:55.320
generated by a supercomputer, and it's now asked to recreate that image.

04:55.320 --> 04:56.320
Look at that.

04:56.320 --> 05:02.640
This is the input, 540p, and this is the output, DLSS 2.0, 540p to 1080p.

05:02.640 --> 05:04.040
What an amazing breakthrough.

05:04.040 --> 05:10.200
Let's take a look at the combination of RTX and DLSS on the most popular game in the

05:10.200 --> 05:11.920
world, Minecraft.

05:11.920 --> 05:17.280
Because each one of the worlds are created by the gamer, it is not possible to pre-bake

05:17.280 --> 05:23.460
a lot of the shadows and lighting effects that you see in very big blockbuster games.

05:23.460 --> 05:28.500
This is created by the users themselves, and so the lighting effects can't be cheated,

05:28.500 --> 05:33.020
and it has to be generated by the program, which is the reason why we chose to work with

05:33.020 --> 05:36.060
the team at Minecraft to bring RTX to it.

05:36.060 --> 05:41.180
Now with this particular scene, you can see that when we render Minecraft without DLSS

05:41.180 --> 05:45.160
with just ray tracing, the frame rate was only 35 frames per second.

05:45.160 --> 05:51.460
With DLSS, we can render this beautiful image and then use DLSS to scale that low resolution

05:51.460 --> 05:53.980
image and still maintain the speed.

05:53.980 --> 06:00.300
So now you get beautiful image with ray tracing, high resolution, and high speed all at the

06:00.300 --> 06:04.020
same time, and that is the requirement for modern computer graphics.

06:04.020 --> 06:07.380
Let me show you now a video that we just made of Minecraft.

06:07.380 --> 06:10.540
The reception has been incredible all over the world.

06:10.540 --> 06:11.340
You're going to love this video.

06:51.460 --> 07:10.620
Oh my goodness, this looks insane.

07:10.620 --> 07:11.620
Look at the shiny floor.

07:11.620 --> 07:13.300
I feel like I'm going to slip and fall down.

07:13.300 --> 07:14.300
It hurt myself.

07:14.300 --> 07:15.300
Look at that.

07:15.300 --> 07:16.300
Look at that.

07:16.300 --> 07:17.300
Look at that.

07:17.300 --> 07:18.300
Look at that.

07:18.300 --> 07:19.300
Look at that.

07:19.460 --> 07:20.460
Out.

07:20.460 --> 07:21.460
Boom.

07:21.460 --> 07:27.020
Look at the way the light comes through the wall.

07:27.020 --> 07:29.940
It really adds just this level of depth.

07:29.940 --> 07:30.940
Is that mirrors?

07:30.940 --> 07:35.220
It's mirrors.

07:35.220 --> 07:40.660
Ladies and gentlemen, RTX on, ray tracing, DLSS.

07:40.660 --> 07:45.780
We've made possible real-time ray tracing 10 years earlier than anybody thought was

07:45.780 --> 07:46.780
possible.

07:46.780 --> 07:51.860
When we launched it, people were skeptical, but now it is very, very clear that ray tracing

07:51.860 --> 07:54.700
is here and it's the next big thing.

07:54.700 --> 07:57.140
Creating 3D content is hard.

07:57.140 --> 08:01.940
It takes so many different types of disciplines from artists to designers to software programmers.

08:01.940 --> 08:07.740
Uses all kinds of different tools from MyEd, 3D Studio Max, to Photoshop, and they're creating

08:07.740 --> 08:11.100
these worlds that take enormous databases.

08:11.100 --> 08:15.460
That's one of the reasons why it's so expensive and so hard to create world-class 3D content.

08:15.540 --> 08:16.740
We have a solution for that.

08:16.740 --> 08:22.020
We call it the NVIDIA Omniverse and it leverages all of NVIDIA's technology over the last

08:22.020 --> 08:23.020
10 years.

08:23.020 --> 08:28.500
On the foundation is our RTX server, our latest generation GPUs, then it's built on top of

08:28.500 --> 08:31.460
a virtual application server.

08:31.460 --> 08:37.020
Each one of the GPUs could be shared by many different designers using virtual quadro or

08:37.020 --> 08:41.180
many GPUs could gang up to accelerate one application.

08:41.180 --> 08:46.020
The networking is accelerated and offloaded by Melanox Nix, the smart Nix that we were

08:46.020 --> 08:47.420
talking about earlier.

08:47.420 --> 08:50.940
And then one of the virtual machines is the Omniverse Nucleus.

08:50.940 --> 08:56.860
This nucleus has created a shared space, a shared world, and this shared world has portals.

08:56.860 --> 09:02.860
The output of that portal is visualized and streamed to any device you like.

09:02.860 --> 09:08.220
Multiple designers could work on one design at the same time and reviewers could ask for

09:08.220 --> 09:10.300
changes in real time.

09:10.300 --> 09:13.860
The ultimate design collaboration platform.

09:13.860 --> 09:17.340
Let me show you a demo that's created by NVIDIA engineers.

09:17.340 --> 09:19.600
What I'm about to show you is really amazing.

09:19.600 --> 09:23.500
This was done over the course of the last couple of months.

09:23.500 --> 09:27.660
Artist designers from different locations and it's never been seen before.

09:27.660 --> 09:30.460
It is completely ray traced.

09:30.460 --> 09:34.300
None of the lights are baked, none of the shadows are baked, everything is completely

09:34.300 --> 09:36.380
lit and shadowed in real time.

09:36.460 --> 09:40.420
And one of the most important things is everything obeys the laws of physics.

09:40.420 --> 09:41.420
Let's roll it.

12:06.380 --> 12:13.340
Isn't that amazing?

12:13.340 --> 12:18.460
Real time ray tracing, physically based materials, obeys the laws of physics.

12:18.460 --> 12:24.220
It was created by just a few designers and engineers on top of Omniverse working remotely

12:24.220 --> 12:26.580
from different states.

12:26.580 --> 12:27.720
Incredible achievement.

12:27.720 --> 12:28.720
Just so beautiful.

12:28.720 --> 12:29.720
I love it.

12:29.720 --> 12:32.340
And so ladies and gentlemen, this is the NVIDIA Omniverse.

12:32.340 --> 12:35.820
It starts with a server with a whole bunch of RTX 8000s.

12:35.820 --> 12:41.140
These are the most powerful ray tracing GPUs in the world, tensor core processing to do

12:41.140 --> 12:46.740
AI so that we can both have beautiful images and high resolution and high performance at

12:46.740 --> 12:47.900
the same time.

12:47.900 --> 12:51.220
The servers are available from Box, Dell, HP and Supermicro.

12:51.220 --> 12:56.860
And it's been preconfigured with all the hypervisors necessary, the networking stack

12:56.860 --> 13:01.740
and the virtual quadros so that you can remotely run applications so that you could create

13:01.740 --> 13:04.060
portals into the shared space.

13:04.060 --> 13:06.020
It's really, really an amazing thing.

13:06.020 --> 13:11.100
In today's world where you have to work remotely and share and collaborate with large numbers

13:11.100 --> 13:14.300
of people, this couldn't have come at a better time.

13:14.300 --> 13:15.380
The NVIDIA Omniverse.

