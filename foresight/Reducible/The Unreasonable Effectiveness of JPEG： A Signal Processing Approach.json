{"text": " What you see here is one part of a really elaborate process that defines the universally used JPEG image compression format. JPEG is rather complex and in this video the majority of the focus will be on understanding how computer scientists came up with an algorithmic and mathematical framework for solving the complex problems that image compression presents. But to understand the motivation behind the ideas in JPEG we'll have to dive into the inner workings of the many components involved. The perspectives we'll take will be a little bit unorthodox but my hope is that you come away with a better understanding of the big themes in image compression which apply to other compression related problems. It's not an exaggeration to say that these concepts are used every time you open an image, play a video or listen to some music. As we go through JPEG we'll interact with the wide variety of beautiful ideas in the world of data compression and signal processing that make the technology around us possible. Before we dive into JPEG let's talk about how computers represent images. The standard color space that computers use is the RGB model. Every pixel of an image stores three values from 0 to 255 with higher values representing a larger weighting of the respective color. So assuming each color component is expressed in 8 bits or a single byte of memory an image has 3 bytes per pixel. Here's an image with a little more than 5 million pixels. Based on our assumptions the total size of this image should be about 15 megabytes but with JPEG compression the actual file is only 0.8 megabytes. Same number of pixels but 5% of the expected size and the image looks absolutely beautiful. This is the real magic of JPEG compression. JPEG aggressively takes advantage of several clever ideas to achieve seemingly ridiculous amounts of compression with minimal effects on the quality of the original image. One of the primary reasons JPEG works so well is it uses lossy compression. To understand what that means let's think about compression from a big picture perspective. We start with an RGB representation of an image and then we encode it using a compression algorithm. This is what we store in memory and it's more compact but quite different than our original RGB representation. So part of a compression scheme requires also defining a decoding component that converts the stored representation of our data into the RGB format that a computer can render as an image. Part of the JPEG standard is defining how both the encoding and decoding work. A key point in JPEG is that the final decoded image is not going to be the same as the original uncompressed image. That's why we call it lossy compression. In the compression part of the pipeline we are going to deliberately lose information. To get compression on the levels of 5% there's really no other option other than to actually discard some information from our original image. Now the fun question to ask is what sort of information from an image can we get rid of and how do we get rid of it? Answering this question is going to be the primary focus of our journey into understanding JPEG. Here's an interesting image for you. If I were to ask you what colors the squares of A and B were I imagine most of you would quickly say that A is a darker shade of gray than B. But what if I told you that A and B were actually the same color? It's okay if you don't see that. This picture is designed to trick our visual system. But once we have a connector of the common color between the two squares it's much easier for us to see that they are in fact the same color. So what's going on here? Over the years scientists have developed a human visual system model through the study of our eyes and one incredibly interesting finding through experimentation is that our eyes are much more sensitive to brightness than they are to colors. And part of the JPEG compression scheme can take advantage of this. But to understand how we have to dive into the world of color spaces. As we've discussed the RGB color space is a combination of red, green, and blue color components. If we put each value on a separate axis in a three-dimensional space we can see how all the possible colors are just a point on this cube. One aspect of RGB color space is as you progress on the diagonal from the origin to the color 255, 255, 255 you get gradually brighter colors. And in fact the exact line between these points defines all possible gray scale colors which are a direct measure for brightness. This idea of separating brightness is core to another color space called YCBCR. YCBCR stands for Y, chroma blue, and chroma red. Our Y component is going to measure the luma or brightness of an image and our CB and CR components are going to encode the colors. If we look at the color space the Y can be thought of as a single vertical axis with larger values encoding more brightness. Every cross section of the space defines a range of colors at that particular brightness. For our purposes with JPEG using the color space gives us direct access to the part of color that our eyes perceive best. As a result of being more sensitive to brightness than colors one idea to compress our original image involves sampling less of the CBCR components and keeping all of the luma components. The technique is referred to as chroma down sampling or more commonly chroma subsampling. Suppose I have this 8x8 image which has the following Y, CB, and CR components. The key idea of chroma down sampling or subsampling is to take fewer samples from CB and CR components since their eyes are less sensitive to them. Here's one approach that defines a 4-2-0 chroma down sampling scheme. We go through our original 8x8 image in 2x2 blocks and simply average the group of pixels to get a shared value of the four pixels in the original image. Averaging the pixels by the way is all down sampling really means. Chroma subsampling is the same exact idea but instead of averaging we just choose one of the samples usually the top left pixel to be the color of the entire 2x2 block. Once we have these fewer samples from the color components we can merge them with the luma component which will retain the original 16 pixels and this gives us our subsampled image. In this case you can see quite a difference since our 8x8 pixel image is significantly scaled up but in real world images it's often hard to see any changes after subsampling. By merging 2x2 blocks on the CB and CR channels into one color we are left with a quarter of the original data in each color channel shrinking the total file size by 50%. We're still quite far from the 5% levels that we saw in JPEG so we're going to have to exploit more than just human perception of brightness. For the following components of JPEG let's focus on the Y channel which essentially defines grayscale images. The principles we'll discuss from here on out will also apply to the color components of an image. The next clever idea in JPEG requires looking at images in a completely different perspective, one that can be a little bit counterintuitive. One way to think about images is treating them as signals. If I slice a particular row of an image I essentially have a row of pixels each with some value between 0 and 255. If we plot these values we can get an approximation of a signal. Visualizing an image as a signal allows us to talk about frequency components within an image. Higher frequency components correspond to rapid changes between pixels while lower frequency components are related to smoother changes between pixels. There are two key aspects of frequencies within images that are incredibly important to JPEG compression. The first is that a lot of real world images shot from cameras are mostly composed of lower frequency components. In other words if I take a random portion of a realistic image it's pretty likely that the pixels in that area do not change that rapidly. And the second key fact is that from a variety of experiments the human visual system is generally less sensitive to higher frequency detail in images. JPEG takes advantage of these ideas by strategically removing less important and less common higher frequency components from an image to achieve even more compression. But there's one big problem. How do we get frequency components from an image? This is where some particularly clever and beautiful math comes into play. The answer to this question lies in a special operation called the discrete cosine transform or the DCT. The DCT works for any size input but to simplify things let's focus on an input of eight pixels. Just as we did earlier let's suppose these eight pixels form some sort of signal. We'll never be sure what exactly the signal looks like since we only have eight points but the clever and definitely not obvious idea of the DCT is to represent these eight points as sums of sampled points from cosine waves. And I really want to emphasize the fact that we only care about the discrete samples. Visually I think it's nice to see the continuous signals and cosine waves but throughout a discussion the only values that really matter are the sampled points from these functions. The DCT takes an input of sampled points from our original signal and gives us an output of the same size. We'll refer to the outputs of the DCT as coefficients. These coefficients represent the weights of cosine waves of different frequencies that contribute to the original signal. A nice analogy is to think of this as unraveling a complex signal into a weighted sum of simpler cosine waves. If you've never interacted with this type of idea before it's natural to be confused. What cosine waves do we even use? How do cosine waves relate to pixels on an image? None of it makes any sense. Don't worry these are important questions that we will answer. Let's start simple and talk about cosine waves. Here's a graph of cosine from zero to pi. I've given you this general notion that the DCT is supposed to tell us how much of a specific cosine wave is contained in a signal. So let's test this out. What happens if I provide an actual cosine wave as the input signal to the DCT? What do we expect to happen? Okay we can try this but there's a problem. To follow our existing example we need eight sampled points from the cosine wave to make this work. How exactly should we sample the cosine wave? Well there are a few options but let me present to you the most common one. What we can do is split our cosine waves domain into eight even slices and then we take the midpoint of each of these slices. This gives us the following input points which we can generalize for any number of points. But for our purposes we'll stick with the smaller n equals 8 example. So going back to our question what should we expect the output to be when we pass in sampled points from a standard cosine function? This is an interesting experiment. When we pass these points from a cosine wave into a DCT transform we get the following output. Only one coefficient has a nonzero value meaning there's only one cosine wave that contributes to our input. And that seems to make some sense since the input is literally from a cosine wave. In this case the first index is the only coefficient with a nonzero value. When trying to understand complex ideas it really helps to play around with these simple examples. A cool follow-up to our experiment is to see what happens when we change the amplitude of this cosine wave. The first index DCT coefficient increases. If we flip the cosine wave by multiplying negative one the DCT coefficient changes sign. It's exactly acting like a weight for a cosine wave. When the amplitude of the input cosine wave changes the weight correspondingly reflects that change. So taking a step back how does this relate to images? Well just as we took images and represented them as signals the reverse also works. Standard grayscale images have pixels ranging from 0 to 255. The intuition with cosine waves to images makes more sense when we shift the range of pixel values by 128. With pixel values from negative 128 to 127 we can see a better mapping between this cosine wave to an actual set of eight pixels. This particular wave is a nice way to represent a row of gradually decreasing pixel values. And the magnitude of that change as well as the direction of the change is reflected in the amplitude of the original cosine wave and consequently the DCT coefficient. So let's continue this experiment to see what else we can uncover about the DCT. We've messed with the amplitude of a cosine wave. What other parameters could we change? A simple one is to just shift the cosine wave up or down. Let's see what happens when we try that. It looks like shifting up or down the signal only affects the zeroth index coefficient. That's an interesting data point that we'll come back to. Another parameter of cosine waves is the frequency. What we're going to do now is show the DCT coefficients as we wind up the frequency of this cosine wave. I'll keep the sampling strategy we discussed earlier consistent among all frequencies. Let's see what happens. As we increase the frequencies we get a few different DCT coefficients for the respective cosine wave. That is until we get to this cosine wave. For this particular cosine wave only the second index has a non-zero coefficient. This cosine wave is actually just double the frequency of the previous cosine wave. This is super interesting. The first index of the output seems to nicely correspond with the cosine wave of frequency one while the second index correlates with a cosine wave of frequency two. Let's continue this experiment of increasing frequencies but before I continue see if you can take a guess at what frequencies the other coefficients will correspond to. Here we go. We slowly increase the frequency and boom the index three coefficient corresponds to a cosine wave of frequency three. Then frequency four comes next and this pattern continues until we get to a cosine wave of frequency seven. Pretty insane right? So for the coefficients indexed one to seven it looks like they represent the weight on a cosine wave with the frequency that matches the index. So what about the remaining index zero? We saw shifting cosine waves up and down led to a change in the zeroth index. What cosine wave does that represent? Some of you have probably figured it out but if you think about what a zero frequency cosine wave is it's just a constant signal. What that means in terms of images is it gives us a measure of the overall brightness of a set of pixels. Brighter images will have a larger zeroth coefficient than darker images. This is why shifting up a cosine wave only impacts the zeroth coefficient. Putting this all together each of these frequencies correspond to a different pattern of images and what the core DCT does is break down how each of these fundamental patterns contribute to the original image. And it turns out that all possible combinations of eight pixel values can be represented as a sum of these eight cosine waves. Why that's true is not at all obvious but we can begin to understand it once we translate this intuition to the actual math behind the DCT. If you look at the mathematical definition of the DCT we usually have a vector definition of the original signal and the output coefficients. We want to define the kth index of the coefficient vector mathematically. What you often see is something that looks like the following and with the intuition that we just built up we'll see that this equation is doing exactly what we want. Let's start with the cosine term. This function should be familiar. It's the exact representation of a sampled point from a cosine wave using our earlier sampling scheme and it incorporates the frequency of the cosine wave as well. Now what's interesting is in order to get the kth index we are actually summing over a product of each sampled point with samples from the cosine wave. Why does that make sense? This type of expression might look vaguely familiar to a lot of you. Let me rewrite this another way. We know that the original signal points can be represented as a vector but what if we rewrote the sampled points from the cosine wave as a vector as well? What does this expression mean in the context of these two vectors? It's a dot product and what we know about dot products is there a nice way to measure similarity between two vectors. That's why when we pass in sampled points from a cosine wave of frequency k as the input to the DCT we got large values at the kth index coefficient. These two vectors were just scaled versions of each other so the dot product was maximized and this perspective reveals what I think is truly the most surprising and elegant part of the DCT. By picking the points through the sampling method we can think of the entire DCT as a matrix vector product. All we're doing here is a linear transformation. The rows of the matrix are the sampled points from the cosine waves of the respective frequencies and what's truly astounding is that all row vectors in this matrix are orthogonal to each other. What I mean by that is if you take the dot product of any two row vectors representing cosine waves you will get zero if they are different rows of the matrix. Intuitively this is why in our earlier experiments when we pass in a cosine wave of a particular frequency as an input into the DCT we didn't get a contribution from any of the other coefficients which represented different frequency cosine waves. The orthogonality of the sampled points from different cosine waves generates this behavior. It's really quite beautiful. Another great property of the DCT that follows from these facts is invertibility. I've talked about the DCT as a way of decomposing a signal into a coefficient representation of weights associated with cosine waves. We can also reverse this process. If I take my coefficient representation of the signal I can apply what's called the inverse DCT to get back the original signal and it is the exact same signal. No information is lost in this step. How we do that is by multiplying our coefficient representation with the inverse of the matrix. What's cool about this is that because of the orthogonality of the vectors the inverse is just the transpose of our original matrix with some additional normalization constants. Now there's a super nice interpretation of the inverse DCT. The sample cosine wave points are now column vectors so what the inverse DCT is doing is essentially summing over a weighted combination of cosine waves directly to get the original signal. And because these columns are orthogonal to each other that's what allows us to represent any set of eight points with these eight cosine waves. Absolutely incredible. I know we spent some time and went through some fairly complex math to get here but it's precisely these details that are the most fundamental part of not only the DCT but many other similar transforms in the world of signal processing. Now that we have a good intuition on the one-dimensional DCT let's talk about how JPEG specifically uses it. JPEG takes an image and splits it into eight by eight blocks and then centers their values around zero by subtracting 128. Then we take the block and apply the DCT to each row of the block giving us eight sets of DCT coefficients. We then apply the DCT to each column of the block. This process is what defines the two-dimensional DCT. So in the end we have 64 coefficients each of which are await on a specific eight by eight pattern. Notice the first row and column correspond to the earlier one-dimensional patterns and the other elements are compositions of these patterns. And just like in the one-dimensional case the big idea here is that we can build up any eight by eight image using these 64 fundamental patterns. The same signal perspective we talked about earlier also applies here except now with 2D waveforms. What's going on here is we are plotting the pixel value on the z-axis with brighter pixels having larger values. What's fun to play around with is seeing how the waveform and image come together as we slowly put together the 64 coefficients in increasing frequencies. Seeing this in action makes you realize that one interesting property is that by the time we incorporate a small portion of the coefficients our signal and image already look pretty close to the original versions. There's an even more direct experiment we can run to quantify this notion. This particular eight by eight block was randomly picked out of the original image. If we map out the magnitude of the DCT coefficients on this block we see that most of the largest values are in the upper left section which corresponds to the original upper left section which corresponds to lower frequency components. And what's even more interesting if I take any eight by eight block on this image almost all of them have the same property. This property of the DCT is what's commonly referred to as energy compaction. After applying the DCT most of the largest values are concentrated in a few low frequency coefficients and this holds true in a lot of real world images. The concept of energy compaction is incredibly important in image compression. As we will see it's exactly the property that will allow us to aggressively compress images while still retaining high visual quality. Fun fact the original discovery the DCT centered around approximating other transforms that had better energy compaction properties but were too expensive to carry out. The DCT is just one example of a transform that has this property for real world images and we use it because it's quite easy to compute. There's a lot of complexity involved here but one of my goals in this discussion of the DCT and JPEG was directly interacting with these deep and important ideas through questions and visual experiments. Interactivity is a core part of learning and a website that does a fantastic job of interactive explanations is Brilliant the sponsor for this video. From the basics of mathematics and algorithmic thinking to more complex ideas and deep learning and probability Brilliant offers a variety of courses and learning paths for those interested in getting hands on practice. Our discussions of JPEG interacted with some linear algebra in the application of image compression and Brilliant has an entire linear algebra module that goes through the fundamentals and even shows applications of these ideas in image compression, cryptography, error correcting codes and much more. When I was a student I really enjoyed their computer science fundamentals course which has engaging visualizations of concepts and great practice problems that helped me solidify my foundations. You can get started for free by going to brilliant.org slash reducible which is linked in the description below. Brilliant is providing a special offer through this channel where the first 200 members to sign up get 20% off the annual subscription. It's a great way to learn more about the topics in these videos and also a good way to support this channel. Big thanks to Brilliant for sponsoring this video. Let's put everything we've discussed with the DCT together in one more experiment. We'll split our image into eight by eight blocks and then basically rebuild the image with each block having only a certain number of DCT coefficients. We're going to start off with zero coefficients and slowly build up the image. After one coefficient we end up with basically a blur of the original image and as we add DCT coefficients slowly notice how quickly the image starts looking like the original. By the time we get to less than 25% of the DCT coefficients you almost can't even tell the difference between the two images. This confirms the key aspects of why JPEG works for this particular image. Almost all the blocks are composed of the lowest frequency components and we are generally less sensitive to changes in high frequency details. So at this point we know we can eliminate higher frequency components from the DCT but the next natural question is how we actually do this. The process for eliminating higher frequency components in JPEG is called quantization. Quantization is a simple idea. Given an eight by eight matrix of frequency coefficients from the DCT what we're going to do is basically divide each element by a scalar value and round it to an integer. These values are defined in terms of a quantization table. Notice larger values in the bottom right of the table leading to zero values in the higher frequency components. In the decoding stage of JPEG we'll actually be multiplying this result by the same quantization matrix element by element and as you can see the final coefficient matrix will be quite different from the original one. So what that means is we're purposely losing information in this step but the key idea here is most of the lower frequency components will be retained. This is why the energy compaction property of the DCT is so useful when the largest values lie in the lowest frequencies we will end up with a lot of zeros in the less important high frequency components. These quantization tables are provided by the JPEG standard from visual experiments and are the main way for JPEG to define quality of compression. High quality compression parameters can be translated to lower quantization table values. In practice JPEG also defines a separate quantization table for both the luma and color channels. Notice that in the color channels quantization can be even more aggressive. After performing quantization we have a matrix of quantized DCT coefficients where we can now exploit redundancy to get even more compression. The last part of JPEG encoding involves a combination of run length encoding and Huffman encoding. One clever trick is that a JPEG encoder will order the coefficients in a zigzag manner to maximize the chance of a large sequence of zeros in order. Classic run length encoding can compress this fairly easily. All that's going on here is we are compressing every sequence of zeros into a count of the occurrences in a continuous sequence. JPEG actually performs something a little bit more sophisticated by keeping track of a triplet. For every coefficient this triplet encodes the number of preceding zeros, the number of bits required to encode the coefficient, and finally the actual coefficient value. We also have an end of block value to signal that everything from here on out will be zeros. This particular scheme works well with Huffman coding to further exploit redundancy. The big idea of Huffman codes is that more frequently used data can be encoded with fewer bits, and it turns out especially with the nature of quantization, these triplets can be further compressed since some of these values will be more frequent than others. However, I'm purposefully not going to go into the details of how JPEG uses Huffman codes to compress the data because it really does get quite tricky. To give you some sense of the problems, we have to deal with the encoding signs of coefficients as well as triplets for all eight by eight blocks. Most encoders also encode the top left coefficient separate from all the other coefficients. And when you handle that, you have to deal with this on both luma and color channels. And when you eventually get that working, a good chunk of your logic will break when you have to deal with the different types of chroma subsampling. Implementing an optimized fully functional JPEG encoder and decoder is no joke. I wouldn't give that task to even my worst enemies. But in terms of the big picture, all that's going on in this component is taking advantage of the redundancy that quantization creates. A JPEG decoder will be able to use the Huffman code data in the files to get back all quantized DCT coefficients that were encoded. This part of the JPEG algorithm does not lose any information. JPEG as a whole brings about an interesting discussion on the philosophy of data compression. The classic and most straightforward way to compress data is by taking advantage of redundancy. This is the basis of losses image compression algorithms such as those found in PNG file formats. In fact, for images where it's really important not to lose any information, PNG format is recommended over JPEG. But on most real world images, being aware of the medium of presentation introduces another really powerful perspective. A lot of innovation in JPEG compression comes from experiments and understanding of human visual systems. It's from these experiments that we realized human eyes are less sensitive to color and also less sensitive to higher frequencies. So we can remove that information without a significant visual impact. This is why JPEG is so much more effective at compressing images than lossless formats. You'll find these same types of techniques used in audio and video compression where algorithms use our perceptions of sound and motion respectively to remove less relevant data. In fact, variations of the discrete cosine transform and quantization show up in both audio and video compression. It really is incredible to me how people in these fields came up with the mathematical and algorithmic framework to utilize the way we actually perceive the digital technology around us. There's so much depth to these topics that I can never hope to cover in just one video, but I do hope this gives you a sense and appreciation for the complexity of the technology around us that we use on a daily basis. Thanks for watching and I'll see you all in the next one.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.2, "text": " What you see here is one part of a really elaborate process that defines the universally", "tokens": [50364, 708, 291, 536, 510, 307, 472, 644, 295, 257, 534, 20945, 1399, 300, 23122, 264, 43995, 50624], "temperature": 0.0, "avg_logprob": -0.07977476808213696, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0017003575339913368}, {"id": 1, "seek": 0, "start": 5.2, "end": 12.16, "text": " used JPEG image compression format. JPEG is rather complex and in this video the majority", "tokens": [50624, 1143, 508, 5208, 38, 3256, 19355, 7877, 13, 508, 5208, 38, 307, 2831, 3997, 293, 294, 341, 960, 264, 6286, 50972], "temperature": 0.0, "avg_logprob": -0.07977476808213696, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0017003575339913368}, {"id": 2, "seek": 0, "start": 12.16, "end": 17.2, "text": " of the focus will be on understanding how computer scientists came up with an algorithmic", "tokens": [50972, 295, 264, 1879, 486, 312, 322, 3701, 577, 3820, 7708, 1361, 493, 365, 364, 9284, 299, 51224], "temperature": 0.0, "avg_logprob": -0.07977476808213696, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0017003575339913368}, {"id": 3, "seek": 0, "start": 17.2, "end": 22.16, "text": " and mathematical framework for solving the complex problems that image compression presents.", "tokens": [51224, 293, 18894, 8388, 337, 12606, 264, 3997, 2740, 300, 3256, 19355, 13533, 13, 51472], "temperature": 0.0, "avg_logprob": -0.07977476808213696, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0017003575339913368}, {"id": 4, "seek": 0, "start": 23.2, "end": 28.72, "text": " But to understand the motivation behind the ideas in JPEG we'll have to dive into the inner", "tokens": [51524, 583, 281, 1223, 264, 12335, 2261, 264, 3487, 294, 508, 5208, 38, 321, 603, 362, 281, 9192, 666, 264, 7284, 51800], "temperature": 0.0, "avg_logprob": -0.07977476808213696, "compression_ratio": 1.7030075187969924, "no_speech_prob": 0.0017003575339913368}, {"id": 5, "seek": 2872, "start": 28.72, "end": 33.92, "text": " workings of the many components involved. The perspectives we'll take will be a little bit", "tokens": [50364, 589, 1109, 295, 264, 867, 6677, 3288, 13, 440, 16766, 321, 603, 747, 486, 312, 257, 707, 857, 50624], "temperature": 0.0, "avg_logprob": -0.059062260501789594, "compression_ratio": 1.5916955017301038, "no_speech_prob": 0.004903090186417103}, {"id": 6, "seek": 2872, "start": 33.92, "end": 39.12, "text": " unorthodox but my hope is that you come away with a better understanding of the big themes", "tokens": [50624, 517, 2652, 22189, 457, 452, 1454, 307, 300, 291, 808, 1314, 365, 257, 1101, 3701, 295, 264, 955, 13544, 50884], "temperature": 0.0, "avg_logprob": -0.059062260501789594, "compression_ratio": 1.5916955017301038, "no_speech_prob": 0.004903090186417103}, {"id": 7, "seek": 2872, "start": 39.12, "end": 44.879999999999995, "text": " in image compression which apply to other compression related problems. It's not an", "tokens": [50884, 294, 3256, 19355, 597, 3079, 281, 661, 19355, 4077, 2740, 13, 467, 311, 406, 364, 51172], "temperature": 0.0, "avg_logprob": -0.059062260501789594, "compression_ratio": 1.5916955017301038, "no_speech_prob": 0.004903090186417103}, {"id": 8, "seek": 2872, "start": 44.879999999999995, "end": 50.879999999999995, "text": " exaggeration to say that these concepts are used every time you open an image, play a video or", "tokens": [51172, 19123, 399, 281, 584, 300, 613, 10392, 366, 1143, 633, 565, 291, 1269, 364, 3256, 11, 862, 257, 960, 420, 51472], "temperature": 0.0, "avg_logprob": -0.059062260501789594, "compression_ratio": 1.5916955017301038, "no_speech_prob": 0.004903090186417103}, {"id": 9, "seek": 2872, "start": 50.879999999999995, "end": 56.8, "text": " listen to some music. As we go through JPEG we'll interact with the wide variety of beautiful ideas", "tokens": [51472, 2140, 281, 512, 1318, 13, 1018, 321, 352, 807, 508, 5208, 38, 321, 603, 4648, 365, 264, 4874, 5673, 295, 2238, 3487, 51768], "temperature": 0.0, "avg_logprob": -0.059062260501789594, "compression_ratio": 1.5916955017301038, "no_speech_prob": 0.004903090186417103}, {"id": 10, "seek": 5680, "start": 56.8, "end": 62.0, "text": " in the world of data compression and signal processing that make the technology around us", "tokens": [50364, 294, 264, 1002, 295, 1412, 19355, 293, 6358, 9007, 300, 652, 264, 2899, 926, 505, 50624], "temperature": 0.0, "avg_logprob": -0.049642327391071085, "compression_ratio": 1.5375, "no_speech_prob": 0.000804046809207648}, {"id": 11, "seek": 5680, "start": 62.0, "end": 70.0, "text": " possible. Before we dive into JPEG let's talk about how computers represent images. The standard", "tokens": [50624, 1944, 13, 4546, 321, 9192, 666, 508, 5208, 38, 718, 311, 751, 466, 577, 10807, 2906, 5267, 13, 440, 3832, 51024], "temperature": 0.0, "avg_logprob": -0.049642327391071085, "compression_ratio": 1.5375, "no_speech_prob": 0.000804046809207648}, {"id": 12, "seek": 5680, "start": 70.0, "end": 76.96, "text": " color space that computers use is the RGB model. Every pixel of an image stores three values from", "tokens": [51024, 2017, 1901, 300, 10807, 764, 307, 264, 31231, 2316, 13, 2048, 19261, 295, 364, 3256, 9512, 1045, 4190, 490, 51372], "temperature": 0.0, "avg_logprob": -0.049642327391071085, "compression_ratio": 1.5375, "no_speech_prob": 0.000804046809207648}, {"id": 13, "seek": 5680, "start": 76.96, "end": 82.24, "text": " 0 to 255 with higher values representing a larger weighting of the respective color.", "tokens": [51372, 1958, 281, 3552, 20, 365, 2946, 4190, 13460, 257, 4833, 3364, 278, 295, 264, 23649, 2017, 13, 51636], "temperature": 0.0, "avg_logprob": -0.049642327391071085, "compression_ratio": 1.5375, "no_speech_prob": 0.000804046809207648}, {"id": 14, "seek": 8224, "start": 82.8, "end": 89.28, "text": " So assuming each color component is expressed in 8 bits or a single byte of memory an image has", "tokens": [50392, 407, 11926, 1184, 2017, 6542, 307, 12675, 294, 1649, 9239, 420, 257, 2167, 40846, 295, 4675, 364, 3256, 575, 50716], "temperature": 0.0, "avg_logprob": -0.16895003940748132, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.0013669951586052775}, {"id": 15, "seek": 8224, "start": 89.28, "end": 97.28, "text": " 3 bytes per pixel. Here's an image with a little more than 5 million pixels. Based on our assumptions", "tokens": [50716, 805, 36088, 680, 19261, 13, 1692, 311, 364, 3256, 365, 257, 707, 544, 813, 1025, 2459, 18668, 13, 18785, 322, 527, 17695, 51116], "temperature": 0.0, "avg_logprob": -0.16895003940748132, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.0013669951586052775}, {"id": 16, "seek": 8224, "start": 97.28, "end": 104.39999999999999, "text": " the total size of this image should be about 15 megabytes but with JPEG compression the actual", "tokens": [51116, 264, 3217, 2744, 295, 341, 3256, 820, 312, 466, 2119, 10816, 24538, 457, 365, 508, 5208, 38, 19355, 264, 3539, 51472], "temperature": 0.0, "avg_logprob": -0.16895003940748132, "compression_ratio": 1.4747474747474747, "no_speech_prob": 0.0013669951586052775}, {"id": 17, "seek": 10440, "start": 104.64, "end": 114.64, "text": " file is only 0.8 megabytes. Same number of pixels but 5% of the expected size and the image looks", "tokens": [50376, 3991, 307, 787, 1958, 13, 23, 10816, 24538, 13, 10635, 1230, 295, 18668, 457, 1025, 4, 295, 264, 5176, 2744, 293, 264, 3256, 1542, 50876], "temperature": 0.0, "avg_logprob": -0.13906453939584584, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.017440611496567726}, {"id": 18, "seek": 10440, "start": 114.64, "end": 123.04, "text": " absolutely beautiful. This is the real magic of JPEG compression. JPEG aggressively takes advantage", "tokens": [50876, 3122, 2238, 13, 639, 307, 264, 957, 5585, 295, 508, 5208, 38, 19355, 13, 508, 5208, 38, 32024, 2516, 5002, 51296], "temperature": 0.0, "avg_logprob": -0.13906453939584584, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.017440611496567726}, {"id": 19, "seek": 10440, "start": 123.04, "end": 128.88, "text": " of several clever ideas to achieve seemingly ridiculous amounts of compression with minimal", "tokens": [51296, 295, 2940, 13494, 3487, 281, 4584, 18709, 11083, 11663, 295, 19355, 365, 13206, 51588], "temperature": 0.0, "avg_logprob": -0.13906453939584584, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.017440611496567726}, {"id": 20, "seek": 12888, "start": 129.6, "end": 135.92, "text": " effects on the quality of the original image. One of the primary reasons JPEG works so well", "tokens": [50400, 5065, 322, 264, 3125, 295, 264, 3380, 3256, 13, 1485, 295, 264, 6194, 4112, 508, 5208, 38, 1985, 370, 731, 50716], "temperature": 0.0, "avg_logprob": -0.03703291114719435, "compression_ratio": 1.575, "no_speech_prob": 0.0006878388812765479}, {"id": 21, "seek": 12888, "start": 135.92, "end": 142.07999999999998, "text": " is it uses lossy compression. To understand what that means let's think about compression from a", "tokens": [50716, 307, 309, 4960, 4470, 88, 19355, 13, 1407, 1223, 437, 300, 1355, 718, 311, 519, 466, 19355, 490, 257, 51024], "temperature": 0.0, "avg_logprob": -0.03703291114719435, "compression_ratio": 1.575, "no_speech_prob": 0.0006878388812765479}, {"id": 22, "seek": 12888, "start": 142.07999999999998, "end": 148.96, "text": " big picture perspective. We start with an RGB representation of an image and then we encode", "tokens": [51024, 955, 3036, 4585, 13, 492, 722, 365, 364, 31231, 10290, 295, 364, 3256, 293, 550, 321, 2058, 1429, 51368], "temperature": 0.0, "avg_logprob": -0.03703291114719435, "compression_ratio": 1.575, "no_speech_prob": 0.0006878388812765479}, {"id": 23, "seek": 12888, "start": 148.96, "end": 155.76, "text": " it using a compression algorithm. This is what we store in memory and it's more compact but quite", "tokens": [51368, 309, 1228, 257, 19355, 9284, 13, 639, 307, 437, 321, 3531, 294, 4675, 293, 309, 311, 544, 14679, 457, 1596, 51708], "temperature": 0.0, "avg_logprob": -0.03703291114719435, "compression_ratio": 1.575, "no_speech_prob": 0.0006878388812765479}, {"id": 24, "seek": 15576, "start": 155.76, "end": 162.72, "text": " different than our original RGB representation. So part of a compression scheme requires also", "tokens": [50364, 819, 813, 527, 3380, 31231, 10290, 13, 407, 644, 295, 257, 19355, 12232, 7029, 611, 50712], "temperature": 0.0, "avg_logprob": -0.0297239575275155, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0015011257492005825}, {"id": 25, "seek": 15576, "start": 162.72, "end": 169.76, "text": " defining a decoding component that converts the stored representation of our data into the RGB", "tokens": [50712, 17827, 257, 979, 8616, 6542, 300, 38874, 264, 12187, 10290, 295, 527, 1412, 666, 264, 31231, 51064], "temperature": 0.0, "avg_logprob": -0.0297239575275155, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0015011257492005825}, {"id": 26, "seek": 15576, "start": 169.76, "end": 176.48, "text": " format that a computer can render as an image. Part of the JPEG standard is defining how both", "tokens": [51064, 7877, 300, 257, 3820, 393, 15529, 382, 364, 3256, 13, 4100, 295, 264, 508, 5208, 38, 3832, 307, 17827, 577, 1293, 51400], "temperature": 0.0, "avg_logprob": -0.0297239575275155, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0015011257492005825}, {"id": 27, "seek": 15576, "start": 176.48, "end": 183.6, "text": " the encoding and decoding work. A key point in JPEG is that the final decoded image is not going", "tokens": [51400, 264, 43430, 293, 979, 8616, 589, 13, 316, 2141, 935, 294, 508, 5208, 38, 307, 300, 264, 2572, 979, 12340, 3256, 307, 406, 516, 51756], "temperature": 0.0, "avg_logprob": -0.0297239575275155, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0015011257492005825}, {"id": 28, "seek": 18360, "start": 183.6, "end": 190.88, "text": " to be the same as the original uncompressed image. That's why we call it lossy compression. In the", "tokens": [50364, 281, 312, 264, 912, 382, 264, 3380, 8585, 79, 3805, 3256, 13, 663, 311, 983, 321, 818, 309, 4470, 88, 19355, 13, 682, 264, 50728], "temperature": 0.0, "avg_logprob": -0.03417011429281796, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.010012821294367313}, {"id": 29, "seek": 18360, "start": 190.88, "end": 197.44, "text": " compression part of the pipeline we are going to deliberately lose information. To get compression", "tokens": [50728, 19355, 644, 295, 264, 15517, 321, 366, 516, 281, 23506, 3624, 1589, 13, 1407, 483, 19355, 51056], "temperature": 0.0, "avg_logprob": -0.03417011429281796, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.010012821294367313}, {"id": 30, "seek": 18360, "start": 197.44, "end": 203.2, "text": " on the levels of 5% there's really no other option other than to actually discard some", "tokens": [51056, 322, 264, 4358, 295, 1025, 4, 456, 311, 534, 572, 661, 3614, 661, 813, 281, 767, 31597, 512, 51344], "temperature": 0.0, "avg_logprob": -0.03417011429281796, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.010012821294367313}, {"id": 31, "seek": 18360, "start": 203.2, "end": 210.24, "text": " information from our original image. Now the fun question to ask is what sort of information", "tokens": [51344, 1589, 490, 527, 3380, 3256, 13, 823, 264, 1019, 1168, 281, 1029, 307, 437, 1333, 295, 1589, 51696], "temperature": 0.0, "avg_logprob": -0.03417011429281796, "compression_ratio": 1.7616822429906542, "no_speech_prob": 0.010012821294367313}, {"id": 32, "seek": 21024, "start": 210.24, "end": 216.96, "text": " from an image can we get rid of and how do we get rid of it? Answering this question is going to be", "tokens": [50364, 490, 364, 3256, 393, 321, 483, 3973, 295, 293, 577, 360, 321, 483, 3973, 295, 309, 30, 24545, 278, 341, 1168, 307, 516, 281, 312, 50700], "temperature": 0.0, "avg_logprob": -0.06148791994367327, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.0006878382991999388}, {"id": 33, "seek": 21024, "start": 216.96, "end": 223.76000000000002, "text": " the primary focus of our journey into understanding JPEG. Here's an interesting image for you. If I", "tokens": [50700, 264, 6194, 1879, 295, 527, 4671, 666, 3701, 508, 5208, 38, 13, 1692, 311, 364, 1880, 3256, 337, 291, 13, 759, 286, 51040], "temperature": 0.0, "avg_logprob": -0.06148791994367327, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.0006878382991999388}, {"id": 34, "seek": 21024, "start": 223.76000000000002, "end": 229.36, "text": " were to ask you what colors the squares of A and B were I imagine most of you would quickly say that", "tokens": [51040, 645, 281, 1029, 291, 437, 4577, 264, 19368, 295, 316, 293, 363, 645, 286, 3811, 881, 295, 291, 576, 2661, 584, 300, 51320], "temperature": 0.0, "avg_logprob": -0.06148791994367327, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.0006878382991999388}, {"id": 35, "seek": 21024, "start": 229.36, "end": 235.84, "text": " A is a darker shade of gray than B. But what if I told you that A and B were actually the same color?", "tokens": [51320, 316, 307, 257, 12741, 11466, 295, 10855, 813, 363, 13, 583, 437, 498, 286, 1907, 291, 300, 316, 293, 363, 645, 767, 264, 912, 2017, 30, 51644], "temperature": 0.0, "avg_logprob": -0.06148791994367327, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.0006878382991999388}, {"id": 36, "seek": 23584, "start": 236.64000000000001, "end": 242.16, "text": " It's okay if you don't see that. This picture is designed to trick our visual system. But once", "tokens": [50404, 467, 311, 1392, 498, 291, 500, 380, 536, 300, 13, 639, 3036, 307, 4761, 281, 4282, 527, 5056, 1185, 13, 583, 1564, 50680], "temperature": 0.0, "avg_logprob": -0.0652790337466122, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.012820299714803696}, {"id": 37, "seek": 23584, "start": 242.16, "end": 247.76, "text": " we have a connector of the common color between the two squares it's much easier for us to see", "tokens": [50680, 321, 362, 257, 19127, 295, 264, 2689, 2017, 1296, 264, 732, 19368, 309, 311, 709, 3571, 337, 505, 281, 536, 50960], "temperature": 0.0, "avg_logprob": -0.0652790337466122, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.012820299714803696}, {"id": 38, "seek": 23584, "start": 247.76, "end": 254.48000000000002, "text": " that they are in fact the same color. So what's going on here? Over the years scientists have", "tokens": [50960, 300, 436, 366, 294, 1186, 264, 912, 2017, 13, 407, 437, 311, 516, 322, 510, 30, 4886, 264, 924, 7708, 362, 51296], "temperature": 0.0, "avg_logprob": -0.0652790337466122, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.012820299714803696}, {"id": 39, "seek": 23584, "start": 254.48000000000002, "end": 260.0, "text": " developed a human visual system model through the study of our eyes and one incredibly interesting", "tokens": [51296, 4743, 257, 1952, 5056, 1185, 2316, 807, 264, 2979, 295, 527, 2575, 293, 472, 6252, 1880, 51572], "temperature": 0.0, "avg_logprob": -0.0652790337466122, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.012820299714803696}, {"id": 40, "seek": 26000, "start": 260.0, "end": 265.84, "text": " finding through experimentation is that our eyes are much more sensitive to brightness than they", "tokens": [50364, 5006, 807, 37142, 307, 300, 527, 2575, 366, 709, 544, 9477, 281, 21367, 813, 436, 50656], "temperature": 0.0, "avg_logprob": -0.0651169094172391, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004755066242069006}, {"id": 41, "seek": 26000, "start": 265.84, "end": 272.96, "text": " are to colors. And part of the JPEG compression scheme can take advantage of this. But to understand", "tokens": [50656, 366, 281, 4577, 13, 400, 644, 295, 264, 508, 5208, 38, 19355, 12232, 393, 747, 5002, 295, 341, 13, 583, 281, 1223, 51012], "temperature": 0.0, "avg_logprob": -0.0651169094172391, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004755066242069006}, {"id": 42, "seek": 26000, "start": 272.96, "end": 280.88, "text": " how we have to dive into the world of color spaces. As we've discussed the RGB color space is a", "tokens": [51012, 577, 321, 362, 281, 9192, 666, 264, 1002, 295, 2017, 7673, 13, 1018, 321, 600, 7152, 264, 31231, 2017, 1901, 307, 257, 51408], "temperature": 0.0, "avg_logprob": -0.0651169094172391, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004755066242069006}, {"id": 43, "seek": 26000, "start": 280.88, "end": 286.4, "text": " combination of red, green, and blue color components. If we put each value on a separate", "tokens": [51408, 6562, 295, 2182, 11, 3092, 11, 293, 3344, 2017, 6677, 13, 759, 321, 829, 1184, 2158, 322, 257, 4994, 51684], "temperature": 0.0, "avg_logprob": -0.0651169094172391, "compression_ratio": 1.5916666666666666, "no_speech_prob": 0.004755066242069006}, {"id": 44, "seek": 28640, "start": 286.4, "end": 292.32, "text": " axis in a three-dimensional space we can see how all the possible colors are just a point on this", "tokens": [50364, 10298, 294, 257, 1045, 12, 18759, 1901, 321, 393, 536, 577, 439, 264, 1944, 4577, 366, 445, 257, 935, 322, 341, 50660], "temperature": 0.0, "avg_logprob": -0.061143167902914325, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.007576843723654747}, {"id": 45, "seek": 28640, "start": 292.32, "end": 298.88, "text": " cube. One aspect of RGB color space is as you progress on the diagonal from the origin to the", "tokens": [50660, 13728, 13, 1485, 4171, 295, 31231, 2017, 1901, 307, 382, 291, 4205, 322, 264, 21539, 490, 264, 4957, 281, 264, 50988], "temperature": 0.0, "avg_logprob": -0.061143167902914325, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.007576843723654747}, {"id": 46, "seek": 28640, "start": 298.88, "end": 307.44, "text": " color 255, 255, 255 you get gradually brighter colors. And in fact the exact line between these", "tokens": [50988, 2017, 3552, 20, 11, 3552, 20, 11, 3552, 20, 291, 483, 13145, 19764, 4577, 13, 400, 294, 1186, 264, 1900, 1622, 1296, 613, 51416], "temperature": 0.0, "avg_logprob": -0.061143167902914325, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.007576843723654747}, {"id": 47, "seek": 28640, "start": 307.44, "end": 312.4, "text": " points defines all possible gray scale colors which are a direct measure for brightness.", "tokens": [51416, 2793, 23122, 439, 1944, 10855, 4373, 4577, 597, 366, 257, 2047, 3481, 337, 21367, 13, 51664], "temperature": 0.0, "avg_logprob": -0.061143167902914325, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.007576843723654747}, {"id": 48, "seek": 31240, "start": 313.12, "end": 320.71999999999997, "text": " This idea of separating brightness is core to another color space called YCBCR. YCBCR", "tokens": [50400, 639, 1558, 295, 29279, 21367, 307, 4965, 281, 1071, 2017, 1901, 1219, 398, 34, 7869, 49, 13, 398, 34, 7869, 49, 50780], "temperature": 0.0, "avg_logprob": -0.07819607853889465, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0073453690856695175}, {"id": 49, "seek": 31240, "start": 320.71999999999997, "end": 326.64, "text": " stands for Y, chroma blue, and chroma red. Our Y component is going to measure the luma or brightness", "tokens": [50780, 7382, 337, 398, 11, 16209, 64, 3344, 11, 293, 16209, 64, 2182, 13, 2621, 398, 6542, 307, 516, 281, 3481, 264, 287, 5544, 420, 21367, 51076], "temperature": 0.0, "avg_logprob": -0.07819607853889465, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0073453690856695175}, {"id": 50, "seek": 31240, "start": 326.64, "end": 332.71999999999997, "text": " of an image and our CB and CR components are going to encode the colors. If we look at the", "tokens": [51076, 295, 364, 3256, 293, 527, 18745, 293, 14123, 6677, 366, 516, 281, 2058, 1429, 264, 4577, 13, 759, 321, 574, 412, 264, 51380], "temperature": 0.0, "avg_logprob": -0.07819607853889465, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0073453690856695175}, {"id": 51, "seek": 31240, "start": 332.71999999999997, "end": 338.79999999999995, "text": " color space the Y can be thought of as a single vertical axis with larger values encoding more", "tokens": [51380, 2017, 1901, 264, 398, 393, 312, 1194, 295, 382, 257, 2167, 9429, 10298, 365, 4833, 4190, 43430, 544, 51684], "temperature": 0.0, "avg_logprob": -0.07819607853889465, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0073453690856695175}, {"id": 52, "seek": 33880, "start": 338.8, "end": 346.40000000000003, "text": " brightness. Every cross section of the space defines a range of colors at that particular", "tokens": [50364, 21367, 13, 2048, 3278, 3541, 295, 264, 1901, 23122, 257, 3613, 295, 4577, 412, 300, 1729, 50744], "temperature": 0.0, "avg_logprob": -0.045440851923931075, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0001584341371199116}, {"id": 53, "seek": 33880, "start": 346.40000000000003, "end": 353.04, "text": " brightness. For our purposes with JPEG using the color space gives us direct access to the part", "tokens": [50744, 21367, 13, 1171, 527, 9932, 365, 508, 5208, 38, 1228, 264, 2017, 1901, 2709, 505, 2047, 2105, 281, 264, 644, 51076], "temperature": 0.0, "avg_logprob": -0.045440851923931075, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0001584341371199116}, {"id": 54, "seek": 33880, "start": 353.04, "end": 359.6, "text": " of color that our eyes perceive best. As a result of being more sensitive to brightness than colors", "tokens": [51076, 295, 2017, 300, 527, 2575, 20281, 1151, 13, 1018, 257, 1874, 295, 885, 544, 9477, 281, 21367, 813, 4577, 51404], "temperature": 0.0, "avg_logprob": -0.045440851923931075, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0001584341371199116}, {"id": 55, "seek": 33880, "start": 359.6, "end": 366.48, "text": " one idea to compress our original image involves sampling less of the CBCR components and keeping", "tokens": [51404, 472, 1558, 281, 14778, 527, 3380, 3256, 11626, 21179, 1570, 295, 264, 383, 7869, 49, 6677, 293, 5145, 51748], "temperature": 0.0, "avg_logprob": -0.045440851923931075, "compression_ratio": 1.658008658008658, "no_speech_prob": 0.0001584341371199116}, {"id": 56, "seek": 36648, "start": 366.48, "end": 372.48, "text": " all of the luma components. The technique is referred to as chroma down sampling or more commonly", "tokens": [50364, 439, 295, 264, 287, 5544, 6677, 13, 440, 6532, 307, 10839, 281, 382, 16209, 64, 760, 21179, 420, 544, 12719, 50664], "temperature": 0.0, "avg_logprob": -0.06770306566487187, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002182621043175459}, {"id": 57, "seek": 36648, "start": 372.48, "end": 380.8, "text": " chroma subsampling. Suppose I have this 8x8 image which has the following Y, CB, and CR components.", "tokens": [50664, 16209, 64, 2090, 335, 11970, 13, 21360, 286, 362, 341, 1649, 87, 23, 3256, 597, 575, 264, 3480, 398, 11, 18745, 11, 293, 14123, 6677, 13, 51080], "temperature": 0.0, "avg_logprob": -0.06770306566487187, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002182621043175459}, {"id": 58, "seek": 36648, "start": 380.8, "end": 386.64000000000004, "text": " The key idea of chroma down sampling or subsampling is to take fewer samples from CB", "tokens": [51080, 440, 2141, 1558, 295, 16209, 64, 760, 21179, 420, 2090, 335, 11970, 307, 281, 747, 13366, 10938, 490, 18745, 51372], "temperature": 0.0, "avg_logprob": -0.06770306566487187, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002182621043175459}, {"id": 59, "seek": 36648, "start": 386.64000000000004, "end": 391.6, "text": " and CR components since their eyes are less sensitive to them. Here's one approach that", "tokens": [51372, 293, 14123, 6677, 1670, 641, 2575, 366, 1570, 9477, 281, 552, 13, 1692, 311, 472, 3109, 300, 51620], "temperature": 0.0, "avg_logprob": -0.06770306566487187, "compression_ratio": 1.712962962962963, "no_speech_prob": 0.002182621043175459}, {"id": 60, "seek": 39160, "start": 391.6, "end": 400.8, "text": " defines a 4-2-0 chroma down sampling scheme. We go through our original 8x8 image in 2x2 blocks", "tokens": [50364, 23122, 257, 1017, 12, 17, 12, 15, 16209, 64, 760, 21179, 12232, 13, 492, 352, 807, 527, 3380, 1649, 87, 23, 3256, 294, 568, 87, 17, 8474, 50824], "temperature": 0.0, "avg_logprob": -0.05834516402213804, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0005192986573092639}, {"id": 61, "seek": 39160, "start": 400.8, "end": 406.48, "text": " and simply average the group of pixels to get a shared value of the four pixels in the original", "tokens": [50824, 293, 2935, 4274, 264, 1594, 295, 18668, 281, 483, 257, 5507, 2158, 295, 264, 1451, 18668, 294, 264, 3380, 51108], "temperature": 0.0, "avg_logprob": -0.05834516402213804, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0005192986573092639}, {"id": 62, "seek": 39160, "start": 406.48, "end": 411.36, "text": " image. Averaging the pixels by the way is all down sampling really means.", "tokens": [51108, 3256, 13, 316, 331, 3568, 264, 18668, 538, 264, 636, 307, 439, 760, 21179, 534, 1355, 13, 51352], "temperature": 0.0, "avg_logprob": -0.05834516402213804, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0005192986573092639}, {"id": 63, "seek": 39160, "start": 413.6, "end": 419.6, "text": " Chroma subsampling is the same exact idea but instead of averaging we just choose one of the", "tokens": [51464, 1721, 6440, 2090, 335, 11970, 307, 264, 912, 1900, 1558, 457, 2602, 295, 47308, 321, 445, 2826, 472, 295, 264, 51764], "temperature": 0.0, "avg_logprob": -0.05834516402213804, "compression_ratio": 1.6272727272727272, "no_speech_prob": 0.0005192986573092639}, {"id": 64, "seek": 41960, "start": 419.6, "end": 424.88, "text": " samples usually the top left pixel to be the color of the entire 2x2 block.", "tokens": [50364, 10938, 2673, 264, 1192, 1411, 19261, 281, 312, 264, 2017, 295, 264, 2302, 568, 87, 17, 3461, 13, 50628], "temperature": 0.0, "avg_logprob": -0.06544502008528937, "compression_ratio": 1.6164383561643836, "no_speech_prob": 8.481034456053749e-05}, {"id": 65, "seek": 41960, "start": 429.12, "end": 434.64000000000004, "text": " Once we have these fewer samples from the color components we can merge them with the luma component", "tokens": [50840, 3443, 321, 362, 613, 13366, 10938, 490, 264, 2017, 6677, 321, 393, 22183, 552, 365, 264, 287, 5544, 6542, 51116], "temperature": 0.0, "avg_logprob": -0.06544502008528937, "compression_ratio": 1.6164383561643836, "no_speech_prob": 8.481034456053749e-05}, {"id": 66, "seek": 41960, "start": 434.64000000000004, "end": 440.40000000000003, "text": " which will retain the original 16 pixels and this gives us our subsampled image.", "tokens": [51116, 597, 486, 18340, 264, 3380, 3165, 18668, 293, 341, 2709, 505, 527, 2090, 335, 15551, 3256, 13, 51404], "temperature": 0.0, "avg_logprob": -0.06544502008528937, "compression_ratio": 1.6164383561643836, "no_speech_prob": 8.481034456053749e-05}, {"id": 67, "seek": 41960, "start": 440.40000000000003, "end": 446.64000000000004, "text": " In this case you can see quite a difference since our 8x8 pixel image is significantly scaled up", "tokens": [51404, 682, 341, 1389, 291, 393, 536, 1596, 257, 2649, 1670, 527, 1649, 87, 23, 19261, 3256, 307, 10591, 36039, 493, 51716], "temperature": 0.0, "avg_logprob": -0.06544502008528937, "compression_ratio": 1.6164383561643836, "no_speech_prob": 8.481034456053749e-05}, {"id": 68, "seek": 44664, "start": 446.71999999999997, "end": 451.91999999999996, "text": " but in real world images it's often hard to see any changes after subsampling.", "tokens": [50368, 457, 294, 957, 1002, 5267, 309, 311, 2049, 1152, 281, 536, 604, 2962, 934, 2090, 335, 11970, 13, 50628], "temperature": 0.0, "avg_logprob": -0.06499759774459035, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0001535595947643742}, {"id": 69, "seek": 44664, "start": 453.2, "end": 459.36, "text": " By merging 2x2 blocks on the CB and CR channels into one color we are left with a quarter of the", "tokens": [50692, 3146, 44559, 568, 87, 17, 8474, 322, 264, 18745, 293, 14123, 9235, 666, 472, 2017, 321, 366, 1411, 365, 257, 6555, 295, 264, 51000], "temperature": 0.0, "avg_logprob": -0.06499759774459035, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0001535595947643742}, {"id": 70, "seek": 44664, "start": 459.36, "end": 466.64, "text": " original data in each color channel shrinking the total file size by 50%. We're still quite far from", "tokens": [51000, 3380, 1412, 294, 1184, 2017, 2269, 41684, 264, 3217, 3991, 2744, 538, 2625, 6856, 492, 434, 920, 1596, 1400, 490, 51364], "temperature": 0.0, "avg_logprob": -0.06499759774459035, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0001535595947643742}, {"id": 71, "seek": 44664, "start": 466.64, "end": 473.2, "text": " the 5% levels that we saw in JPEG so we're going to have to exploit more than just human perception", "tokens": [51364, 264, 1025, 4, 4358, 300, 321, 1866, 294, 508, 5208, 38, 370, 321, 434, 516, 281, 362, 281, 25924, 544, 813, 445, 1952, 12860, 51692], "temperature": 0.0, "avg_logprob": -0.06499759774459035, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.0001535595947643742}, {"id": 72, "seek": 47320, "start": 473.2, "end": 480.47999999999996, "text": " of brightness. For the following components of JPEG let's focus on the Y channel which", "tokens": [50364, 295, 21367, 13, 1171, 264, 3480, 6677, 295, 508, 5208, 38, 718, 311, 1879, 322, 264, 398, 2269, 597, 50728], "temperature": 0.0, "avg_logprob": -0.06455885922467267, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.0004728460044134408}, {"id": 73, "seek": 47320, "start": 480.47999999999996, "end": 486.0, "text": " essentially defines grayscale images. The principles we'll discuss from here on out", "tokens": [50728, 4476, 23122, 677, 3772, 37088, 5267, 13, 440, 9156, 321, 603, 2248, 490, 510, 322, 484, 51004], "temperature": 0.0, "avg_logprob": -0.06455885922467267, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.0004728460044134408}, {"id": 74, "seek": 47320, "start": 486.0, "end": 492.56, "text": " will also apply to the color components of an image. The next clever idea in JPEG requires", "tokens": [51004, 486, 611, 3079, 281, 264, 2017, 6677, 295, 364, 3256, 13, 440, 958, 13494, 1558, 294, 508, 5208, 38, 7029, 51332], "temperature": 0.0, "avg_logprob": -0.06455885922467267, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.0004728460044134408}, {"id": 75, "seek": 47320, "start": 492.56, "end": 497.52, "text": " looking at images in a completely different perspective, one that can be a little bit", "tokens": [51332, 1237, 412, 5267, 294, 257, 2584, 819, 4585, 11, 472, 300, 393, 312, 257, 707, 857, 51580], "temperature": 0.0, "avg_logprob": -0.06455885922467267, "compression_ratio": 1.5491071428571428, "no_speech_prob": 0.0004728460044134408}, {"id": 76, "seek": 49752, "start": 497.52, "end": 504.47999999999996, "text": " counterintuitive. One way to think about images is treating them as signals. If I slice a particular", "tokens": [50364, 5682, 686, 48314, 13, 1485, 636, 281, 519, 466, 5267, 307, 15083, 552, 382, 12354, 13, 759, 286, 13153, 257, 1729, 50712], "temperature": 0.0, "avg_logprob": -0.06168289842276738, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.010986225679516792}, {"id": 77, "seek": 49752, "start": 504.47999999999996, "end": 511.28, "text": " row of an image I essentially have a row of pixels each with some value between 0 and 255.", "tokens": [50712, 5386, 295, 364, 3256, 286, 4476, 362, 257, 5386, 295, 18668, 1184, 365, 512, 2158, 1296, 1958, 293, 3552, 20, 13, 51052], "temperature": 0.0, "avg_logprob": -0.06168289842276738, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.010986225679516792}, {"id": 78, "seek": 49752, "start": 512.24, "end": 518.8, "text": " If we plot these values we can get an approximation of a signal. Visualizing an image as a signal", "tokens": [51100, 759, 321, 7542, 613, 4190, 321, 393, 483, 364, 28023, 295, 257, 6358, 13, 23187, 3319, 364, 3256, 382, 257, 6358, 51428], "temperature": 0.0, "avg_logprob": -0.06168289842276738, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.010986225679516792}, {"id": 79, "seek": 49752, "start": 518.8, "end": 524.3199999999999, "text": " allows us to talk about frequency components within an image. Higher frequency components", "tokens": [51428, 4045, 505, 281, 751, 466, 7893, 6677, 1951, 364, 3256, 13, 31997, 7893, 6677, 51704], "temperature": 0.0, "avg_logprob": -0.06168289842276738, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.010986225679516792}, {"id": 80, "seek": 52432, "start": 524.32, "end": 530.4000000000001, "text": " correspond to rapid changes between pixels while lower frequency components are related to smoother", "tokens": [50364, 6805, 281, 7558, 2962, 1296, 18668, 1339, 3126, 7893, 6677, 366, 4077, 281, 28640, 50668], "temperature": 0.0, "avg_logprob": -0.04744946202145347, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.001366994809359312}, {"id": 81, "seek": 52432, "start": 530.4000000000001, "end": 536.6400000000001, "text": " changes between pixels. There are two key aspects of frequencies within images that are incredibly", "tokens": [50668, 2962, 1296, 18668, 13, 821, 366, 732, 2141, 7270, 295, 20250, 1951, 5267, 300, 366, 6252, 50980], "temperature": 0.0, "avg_logprob": -0.04744946202145347, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.001366994809359312}, {"id": 82, "seek": 52432, "start": 536.6400000000001, "end": 542.8000000000001, "text": " important to JPEG compression. The first is that a lot of real world images shot from cameras are", "tokens": [50980, 1021, 281, 508, 5208, 38, 19355, 13, 440, 700, 307, 300, 257, 688, 295, 957, 1002, 5267, 3347, 490, 8622, 366, 51288], "temperature": 0.0, "avg_logprob": -0.04744946202145347, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.001366994809359312}, {"id": 83, "seek": 52432, "start": 542.8000000000001, "end": 548.6400000000001, "text": " mostly composed of lower frequency components. In other words if I take a random portion of a", "tokens": [51288, 5240, 18204, 295, 3126, 7893, 6677, 13, 682, 661, 2283, 498, 286, 747, 257, 4974, 8044, 295, 257, 51580], "temperature": 0.0, "avg_logprob": -0.04744946202145347, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.001366994809359312}, {"id": 84, "seek": 54864, "start": 548.64, "end": 554.16, "text": " realistic image it's pretty likely that the pixels in that area do not change that rapidly.", "tokens": [50364, 12465, 3256, 309, 311, 1238, 3700, 300, 264, 18668, 294, 300, 1859, 360, 406, 1319, 300, 12910, 13, 50640], "temperature": 0.0, "avg_logprob": -0.041847492193246814, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.005384760443121195}, {"id": 85, "seek": 54864, "start": 554.96, "end": 561.12, "text": " And the second key fact is that from a variety of experiments the human visual system is generally", "tokens": [50680, 400, 264, 1150, 2141, 1186, 307, 300, 490, 257, 5673, 295, 12050, 264, 1952, 5056, 1185, 307, 5101, 50988], "temperature": 0.0, "avg_logprob": -0.041847492193246814, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.005384760443121195}, {"id": 86, "seek": 54864, "start": 561.12, "end": 567.68, "text": " less sensitive to higher frequency detail in images. JPEG takes advantage of these ideas by", "tokens": [50988, 1570, 9477, 281, 2946, 7893, 2607, 294, 5267, 13, 508, 5208, 38, 2516, 5002, 295, 613, 3487, 538, 51316], "temperature": 0.0, "avg_logprob": -0.041847492193246814, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.005384760443121195}, {"id": 87, "seek": 54864, "start": 567.68, "end": 573.76, "text": " strategically removing less important and less common higher frequency components from an image", "tokens": [51316, 38061, 12720, 1570, 1021, 293, 1570, 2689, 2946, 7893, 6677, 490, 364, 3256, 51620], "temperature": 0.0, "avg_logprob": -0.041847492193246814, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.005384760443121195}, {"id": 88, "seek": 57376, "start": 573.76, "end": 581.76, "text": " to achieve even more compression. But there's one big problem. How do we get frequency components", "tokens": [50364, 281, 4584, 754, 544, 19355, 13, 583, 456, 311, 472, 955, 1154, 13, 1012, 360, 321, 483, 7893, 6677, 50764], "temperature": 0.0, "avg_logprob": -0.043383936087290444, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.001244822284206748}, {"id": 89, "seek": 57376, "start": 581.76, "end": 587.76, "text": " from an image? This is where some particularly clever and beautiful math comes into play.", "tokens": [50764, 490, 364, 3256, 30, 639, 307, 689, 512, 4098, 13494, 293, 2238, 5221, 1487, 666, 862, 13, 51064], "temperature": 0.0, "avg_logprob": -0.043383936087290444, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.001244822284206748}, {"id": 90, "seek": 57376, "start": 587.76, "end": 593.92, "text": " The answer to this question lies in a special operation called the discrete cosine transform", "tokens": [51064, 440, 1867, 281, 341, 1168, 9134, 294, 257, 2121, 6916, 1219, 264, 27706, 23565, 4088, 51372], "temperature": 0.0, "avg_logprob": -0.043383936087290444, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.001244822284206748}, {"id": 91, "seek": 57376, "start": 593.92, "end": 601.92, "text": " or the DCT. The DCT works for any size input but to simplify things let's focus on an input", "tokens": [51372, 420, 264, 9114, 51, 13, 440, 9114, 51, 1985, 337, 604, 2744, 4846, 457, 281, 20460, 721, 718, 311, 1879, 322, 364, 4846, 51772], "temperature": 0.0, "avg_logprob": -0.043383936087290444, "compression_ratio": 1.5435684647302905, "no_speech_prob": 0.001244822284206748}, {"id": 92, "seek": 60192, "start": 601.92, "end": 608.7199999999999, "text": " of eight pixels. Just as we did earlier let's suppose these eight pixels form some sort of signal.", "tokens": [50364, 295, 3180, 18668, 13, 1449, 382, 321, 630, 3071, 718, 311, 7297, 613, 3180, 18668, 1254, 512, 1333, 295, 6358, 13, 50704], "temperature": 0.0, "avg_logprob": -0.05232969371751807, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00912464875727892}, {"id": 93, "seek": 60192, "start": 609.4399999999999, "end": 614.4799999999999, "text": " We'll never be sure what exactly the signal looks like since we only have eight points", "tokens": [50740, 492, 603, 1128, 312, 988, 437, 2293, 264, 6358, 1542, 411, 1670, 321, 787, 362, 3180, 2793, 50992], "temperature": 0.0, "avg_logprob": -0.05232969371751807, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00912464875727892}, {"id": 94, "seek": 60192, "start": 615.04, "end": 622.4, "text": " but the clever and definitely not obvious idea of the DCT is to represent these eight points as", "tokens": [51020, 457, 264, 13494, 293, 2138, 406, 6322, 1558, 295, 264, 9114, 51, 307, 281, 2906, 613, 3180, 2793, 382, 51388], "temperature": 0.0, "avg_logprob": -0.05232969371751807, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00912464875727892}, {"id": 95, "seek": 60192, "start": 622.4, "end": 629.36, "text": " sums of sampled points from cosine waves. And I really want to emphasize the fact that we only", "tokens": [51388, 34499, 295, 3247, 15551, 2793, 490, 23565, 9417, 13, 400, 286, 534, 528, 281, 16078, 264, 1186, 300, 321, 787, 51736], "temperature": 0.0, "avg_logprob": -0.05232969371751807, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.00912464875727892}, {"id": 96, "seek": 62936, "start": 629.36, "end": 635.76, "text": " care about the discrete samples. Visually I think it's nice to see the continuous signals and cosine", "tokens": [50364, 1127, 466, 264, 27706, 10938, 13, 10410, 671, 286, 519, 309, 311, 1481, 281, 536, 264, 10957, 12354, 293, 23565, 50684], "temperature": 0.0, "avg_logprob": -0.050027107924557807, "compression_ratio": 1.7324561403508771, "no_speech_prob": 0.01065160147845745}, {"id": 97, "seek": 62936, "start": 635.76, "end": 642.0, "text": " waves but throughout a discussion the only values that really matter are the sampled points from", "tokens": [50684, 9417, 457, 3710, 257, 5017, 264, 787, 4190, 300, 534, 1871, 366, 264, 3247, 15551, 2793, 490, 50996], "temperature": 0.0, "avg_logprob": -0.050027107924557807, "compression_ratio": 1.7324561403508771, "no_speech_prob": 0.01065160147845745}, {"id": 98, "seek": 62936, "start": 642.0, "end": 649.6800000000001, "text": " these functions. The DCT takes an input of sampled points from our original signal and gives us an", "tokens": [50996, 613, 6828, 13, 440, 9114, 51, 2516, 364, 4846, 295, 3247, 15551, 2793, 490, 527, 3380, 6358, 293, 2709, 505, 364, 51380], "temperature": 0.0, "avg_logprob": -0.050027107924557807, "compression_ratio": 1.7324561403508771, "no_speech_prob": 0.01065160147845745}, {"id": 99, "seek": 62936, "start": 649.6800000000001, "end": 658.8000000000001, "text": " output of the same size. We'll refer to the outputs of the DCT as coefficients. These coefficients", "tokens": [51380, 5598, 295, 264, 912, 2744, 13, 492, 603, 2864, 281, 264, 23930, 295, 264, 9114, 51, 382, 31994, 13, 1981, 31994, 51836], "temperature": 0.0, "avg_logprob": -0.050027107924557807, "compression_ratio": 1.7324561403508771, "no_speech_prob": 0.01065160147845745}, {"id": 100, "seek": 65880, "start": 658.8, "end": 664.9599999999999, "text": " represent the weights of cosine waves of different frequencies that contribute to the original signal.", "tokens": [50364, 2906, 264, 17443, 295, 23565, 9417, 295, 819, 20250, 300, 10586, 281, 264, 3380, 6358, 13, 50672], "temperature": 0.0, "avg_logprob": -0.04307397021803745, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0007321580196730793}, {"id": 101, "seek": 65880, "start": 666.0, "end": 672.8, "text": " A nice analogy is to think of this as unraveling a complex signal into a weighted sum of simpler", "tokens": [50724, 316, 1481, 21663, 307, 281, 519, 295, 341, 382, 40507, 278, 257, 3997, 6358, 666, 257, 32807, 2408, 295, 18587, 51064], "temperature": 0.0, "avg_logprob": -0.04307397021803745, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0007321580196730793}, {"id": 102, "seek": 65880, "start": 672.8, "end": 679.4399999999999, "text": " cosine waves. If you've never interacted with this type of idea before it's natural to be confused.", "tokens": [51064, 23565, 9417, 13, 759, 291, 600, 1128, 49621, 365, 341, 2010, 295, 1558, 949, 309, 311, 3303, 281, 312, 9019, 13, 51396], "temperature": 0.0, "avg_logprob": -0.04307397021803745, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0007321580196730793}, {"id": 103, "seek": 65880, "start": 680.56, "end": 686.56, "text": " What cosine waves do we even use? How do cosine waves relate to pixels on an image?", "tokens": [51452, 708, 23565, 9417, 360, 321, 754, 764, 30, 1012, 360, 23565, 9417, 10961, 281, 18668, 322, 364, 3256, 30, 51752], "temperature": 0.0, "avg_logprob": -0.04307397021803745, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.0007321580196730793}, {"id": 104, "seek": 68656, "start": 687.52, "end": 693.1999999999999, "text": " None of it makes any sense. Don't worry these are important questions that we will answer.", "tokens": [50412, 14492, 295, 309, 1669, 604, 2020, 13, 1468, 380, 3292, 613, 366, 1021, 1651, 300, 321, 486, 1867, 13, 50696], "temperature": 0.0, "avg_logprob": -0.06519006127896516, "compression_ratio": 1.5271966527196652, "no_speech_prob": 0.0010322154266759753}, {"id": 105, "seek": 68656, "start": 695.3599999999999, "end": 702.4, "text": " Let's start simple and talk about cosine waves. Here's a graph of cosine from zero to pi. I've", "tokens": [50804, 961, 311, 722, 2199, 293, 751, 466, 23565, 9417, 13, 1692, 311, 257, 4295, 295, 23565, 490, 4018, 281, 3895, 13, 286, 600, 51156], "temperature": 0.0, "avg_logprob": -0.06519006127896516, "compression_ratio": 1.5271966527196652, "no_speech_prob": 0.0010322154266759753}, {"id": 106, "seek": 68656, "start": 702.4, "end": 707.68, "text": " given you this general notion that the DCT is supposed to tell us how much of a specific", "tokens": [51156, 2212, 291, 341, 2674, 10710, 300, 264, 9114, 51, 307, 3442, 281, 980, 505, 577, 709, 295, 257, 2685, 51420], "temperature": 0.0, "avg_logprob": -0.06519006127896516, "compression_ratio": 1.5271966527196652, "no_speech_prob": 0.0010322154266759753}, {"id": 107, "seek": 68656, "start": 707.68, "end": 715.5999999999999, "text": " cosine wave is contained in a signal. So let's test this out. What happens if I provide an", "tokens": [51420, 23565, 5772, 307, 16212, 294, 257, 6358, 13, 407, 718, 311, 1500, 341, 484, 13, 708, 2314, 498, 286, 2893, 364, 51816], "temperature": 0.0, "avg_logprob": -0.06519006127896516, "compression_ratio": 1.5271966527196652, "no_speech_prob": 0.0010322154266759753}, {"id": 108, "seek": 71560, "start": 715.6, "end": 721.52, "text": " actual cosine wave as the input signal to the DCT? What do we expect to happen?", "tokens": [50364, 3539, 23565, 5772, 382, 264, 4846, 6358, 281, 264, 9114, 51, 30, 708, 360, 321, 2066, 281, 1051, 30, 50660], "temperature": 0.0, "avg_logprob": -0.05733904471764198, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.0003569650580175221}, {"id": 109, "seek": 71560, "start": 722.72, "end": 728.72, "text": " Okay we can try this but there's a problem. To follow our existing example we need eight", "tokens": [50720, 1033, 321, 393, 853, 341, 457, 456, 311, 257, 1154, 13, 1407, 1524, 527, 6741, 1365, 321, 643, 3180, 51020], "temperature": 0.0, "avg_logprob": -0.05733904471764198, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.0003569650580175221}, {"id": 110, "seek": 71560, "start": 728.72, "end": 734.96, "text": " sampled points from the cosine wave to make this work. How exactly should we sample the cosine wave?", "tokens": [51020, 3247, 15551, 2793, 490, 264, 23565, 5772, 281, 652, 341, 589, 13, 1012, 2293, 820, 321, 6889, 264, 23565, 5772, 30, 51332], "temperature": 0.0, "avg_logprob": -0.05733904471764198, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.0003569650580175221}, {"id": 111, "seek": 71560, "start": 735.6, "end": 741.2, "text": " Well there are a few options but let me present to you the most common one. What we can do is", "tokens": [51364, 1042, 456, 366, 257, 1326, 3956, 457, 718, 385, 1974, 281, 291, 264, 881, 2689, 472, 13, 708, 321, 393, 360, 307, 51644], "temperature": 0.0, "avg_logprob": -0.05733904471764198, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.0003569650580175221}, {"id": 112, "seek": 74120, "start": 741.2, "end": 747.76, "text": " split our cosine waves domain into eight even slices and then we take the midpoint of each of", "tokens": [50364, 7472, 527, 23565, 9417, 9274, 666, 3180, 754, 19793, 293, 550, 321, 747, 264, 2062, 6053, 295, 1184, 295, 50692], "temperature": 0.0, "avg_logprob": -0.06254326895381628, "compression_ratio": 1.6, "no_speech_prob": 0.0010004887590184808}, {"id": 113, "seek": 74120, "start": 747.76, "end": 754.5600000000001, "text": " these slices. This gives us the following input points which we can generalize for any number of", "tokens": [50692, 613, 19793, 13, 639, 2709, 505, 264, 3480, 4846, 2793, 597, 321, 393, 2674, 1125, 337, 604, 1230, 295, 51032], "temperature": 0.0, "avg_logprob": -0.06254326895381628, "compression_ratio": 1.6, "no_speech_prob": 0.0010004887590184808}, {"id": 114, "seek": 74120, "start": 754.5600000000001, "end": 764.24, "text": " points. But for our purposes we'll stick with the smaller n equals 8 example. So going back to our", "tokens": [51032, 2793, 13, 583, 337, 527, 9932, 321, 603, 2897, 365, 264, 4356, 297, 6915, 1649, 1365, 13, 407, 516, 646, 281, 527, 51516], "temperature": 0.0, "avg_logprob": -0.06254326895381628, "compression_ratio": 1.6, "no_speech_prob": 0.0010004887590184808}, {"id": 115, "seek": 74120, "start": 764.24, "end": 770.48, "text": " question what should we expect the output to be when we pass in sampled points from a standard", "tokens": [51516, 1168, 437, 820, 321, 2066, 264, 5598, 281, 312, 562, 321, 1320, 294, 3247, 15551, 2793, 490, 257, 3832, 51828], "temperature": 0.0, "avg_logprob": -0.06254326895381628, "compression_ratio": 1.6, "no_speech_prob": 0.0010004887590184808}, {"id": 116, "seek": 77048, "start": 770.48, "end": 778.96, "text": " cosine function? This is an interesting experiment. When we pass these points from a cosine wave into", "tokens": [50364, 23565, 2445, 30, 639, 307, 364, 1880, 5120, 13, 1133, 321, 1320, 613, 2793, 490, 257, 23565, 5772, 666, 50788], "temperature": 0.0, "avg_logprob": -0.07068690486337947, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00041730524390004575}, {"id": 117, "seek": 77048, "start": 778.96, "end": 786.8000000000001, "text": " a DCT transform we get the following output. Only one coefficient has a nonzero value meaning", "tokens": [50788, 257, 9114, 51, 4088, 321, 483, 264, 3480, 5598, 13, 5686, 472, 17619, 575, 257, 2107, 32226, 2158, 3620, 51180], "temperature": 0.0, "avg_logprob": -0.07068690486337947, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00041730524390004575}, {"id": 118, "seek": 77048, "start": 786.8000000000001, "end": 793.44, "text": " there's only one cosine wave that contributes to our input. And that seems to make some sense since", "tokens": [51180, 456, 311, 787, 472, 23565, 5772, 300, 32035, 281, 527, 4846, 13, 400, 300, 2544, 281, 652, 512, 2020, 1670, 51512], "temperature": 0.0, "avg_logprob": -0.07068690486337947, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00041730524390004575}, {"id": 119, "seek": 77048, "start": 793.44, "end": 800.4, "text": " the input is literally from a cosine wave. In this case the first index is the only coefficient", "tokens": [51512, 264, 4846, 307, 3736, 490, 257, 23565, 5772, 13, 682, 341, 1389, 264, 700, 8186, 307, 264, 787, 17619, 51860], "temperature": 0.0, "avg_logprob": -0.07068690486337947, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00041730524390004575}, {"id": 120, "seek": 80040, "start": 800.4, "end": 807.04, "text": " with a nonzero value. When trying to understand complex ideas it really helps to play around", "tokens": [50364, 365, 257, 2107, 32226, 2158, 13, 1133, 1382, 281, 1223, 3997, 3487, 309, 534, 3665, 281, 862, 926, 50696], "temperature": 0.0, "avg_logprob": -0.03942936732445234, "compression_ratio": 1.5859030837004404, "no_speech_prob": 9.610114648239687e-05}, {"id": 121, "seek": 80040, "start": 807.04, "end": 812.56, "text": " with these simple examples. A cool follow-up to our experiment is to see what happens when", "tokens": [50696, 365, 613, 2199, 5110, 13, 316, 1627, 1524, 12, 1010, 281, 527, 5120, 307, 281, 536, 437, 2314, 562, 50972], "temperature": 0.0, "avg_logprob": -0.03942936732445234, "compression_ratio": 1.5859030837004404, "no_speech_prob": 9.610114648239687e-05}, {"id": 122, "seek": 80040, "start": 812.56, "end": 819.4399999999999, "text": " we change the amplitude of this cosine wave. The first index DCT coefficient increases.", "tokens": [50972, 321, 1319, 264, 27433, 295, 341, 23565, 5772, 13, 440, 700, 8186, 9114, 51, 17619, 8637, 13, 51316], "temperature": 0.0, "avg_logprob": -0.03942936732445234, "compression_ratio": 1.5859030837004404, "no_speech_prob": 9.610114648239687e-05}, {"id": 123, "seek": 80040, "start": 820.0799999999999, "end": 825.6, "text": " If we flip the cosine wave by multiplying negative one the DCT coefficient changes sign.", "tokens": [51348, 759, 321, 7929, 264, 23565, 5772, 538, 30955, 3671, 472, 264, 9114, 51, 17619, 2962, 1465, 13, 51624], "temperature": 0.0, "avg_logprob": -0.03942936732445234, "compression_ratio": 1.5859030837004404, "no_speech_prob": 9.610114648239687e-05}, {"id": 124, "seek": 82560, "start": 826.5600000000001, "end": 833.28, "text": " It's exactly acting like a weight for a cosine wave. When the amplitude of the input cosine", "tokens": [50412, 467, 311, 2293, 6577, 411, 257, 3364, 337, 257, 23565, 5772, 13, 1133, 264, 27433, 295, 264, 4846, 23565, 50748], "temperature": 0.0, "avg_logprob": -0.0772252877553304, "compression_ratio": 1.5170454545454546, "no_speech_prob": 0.0007321673328988254}, {"id": 125, "seek": 82560, "start": 833.28, "end": 841.52, "text": " wave changes the weight correspondingly reflects that change. So taking a step back", "tokens": [50748, 5772, 2962, 264, 3364, 11760, 356, 18926, 300, 1319, 13, 407, 1940, 257, 1823, 646, 51160], "temperature": 0.0, "avg_logprob": -0.0772252877553304, "compression_ratio": 1.5170454545454546, "no_speech_prob": 0.0007321673328988254}, {"id": 126, "seek": 82560, "start": 841.52, "end": 848.48, "text": " how does this relate to images? Well just as we took images and represented them as signals", "tokens": [51160, 577, 775, 341, 10961, 281, 5267, 30, 1042, 445, 382, 321, 1890, 5267, 293, 10379, 552, 382, 12354, 51508], "temperature": 0.0, "avg_logprob": -0.0772252877553304, "compression_ratio": 1.5170454545454546, "no_speech_prob": 0.0007321673328988254}, {"id": 127, "seek": 84848, "start": 848.48, "end": 855.9200000000001, "text": " the reverse also works. Standard grayscale images have pixels ranging from 0 to 255.", "tokens": [50364, 264, 9943, 611, 1985, 13, 21298, 677, 3772, 37088, 5267, 362, 18668, 25532, 490, 1958, 281, 3552, 20, 13, 50736], "temperature": 0.0, "avg_logprob": -0.06322633518892176, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.01133093610405922}, {"id": 128, "seek": 84848, "start": 856.5600000000001, "end": 862.32, "text": " The intuition with cosine waves to images makes more sense when we shift the range of pixel values", "tokens": [50768, 440, 24002, 365, 23565, 9417, 281, 5267, 1669, 544, 2020, 562, 321, 5513, 264, 3613, 295, 19261, 4190, 51056], "temperature": 0.0, "avg_logprob": -0.06322633518892176, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.01133093610405922}, {"id": 129, "seek": 84848, "start": 862.32, "end": 870.16, "text": " by 128. With pixel values from negative 128 to 127 we can see a better mapping between this", "tokens": [51056, 538, 29810, 13, 2022, 19261, 4190, 490, 3671, 29810, 281, 47561, 321, 393, 536, 257, 1101, 18350, 1296, 341, 51448], "temperature": 0.0, "avg_logprob": -0.06322633518892176, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.01133093610405922}, {"id": 130, "seek": 84848, "start": 870.16, "end": 876.64, "text": " cosine wave to an actual set of eight pixels. This particular wave is a nice way to represent", "tokens": [51448, 23565, 5772, 281, 364, 3539, 992, 295, 3180, 18668, 13, 639, 1729, 5772, 307, 257, 1481, 636, 281, 2906, 51772], "temperature": 0.0, "avg_logprob": -0.06322633518892176, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.01133093610405922}, {"id": 131, "seek": 87664, "start": 876.64, "end": 883.12, "text": " a row of gradually decreasing pixel values. And the magnitude of that change as well as the", "tokens": [50364, 257, 5386, 295, 13145, 23223, 19261, 4190, 13, 400, 264, 15668, 295, 300, 1319, 382, 731, 382, 264, 50688], "temperature": 0.0, "avg_logprob": -0.06845173203801534, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.00013551927986554801}, {"id": 132, "seek": 87664, "start": 883.12, "end": 889.84, "text": " direction of the change is reflected in the amplitude of the original cosine wave and consequently", "tokens": [50688, 3513, 295, 264, 1319, 307, 15502, 294, 264, 27433, 295, 264, 3380, 23565, 5772, 293, 47259, 51024], "temperature": 0.0, "avg_logprob": -0.06845173203801534, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.00013551927986554801}, {"id": 133, "seek": 87664, "start": 889.84, "end": 896.08, "text": " the DCT coefficient. So let's continue this experiment to see what else we can uncover", "tokens": [51024, 264, 9114, 51, 17619, 13, 407, 718, 311, 2354, 341, 5120, 281, 536, 437, 1646, 321, 393, 21694, 51336], "temperature": 0.0, "avg_logprob": -0.06845173203801534, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.00013551927986554801}, {"id": 134, "seek": 87664, "start": 896.08, "end": 901.92, "text": " about the DCT. We've messed with the amplitude of a cosine wave. What other parameters could we", "tokens": [51336, 466, 264, 9114, 51, 13, 492, 600, 16507, 365, 264, 27433, 295, 257, 23565, 5772, 13, 708, 661, 9834, 727, 321, 51628], "temperature": 0.0, "avg_logprob": -0.06845173203801534, "compression_ratio": 1.6651785714285714, "no_speech_prob": 0.00013551927986554801}, {"id": 135, "seek": 90192, "start": 901.92, "end": 909.76, "text": " change? A simple one is to just shift the cosine wave up or down. Let's see what happens when we", "tokens": [50364, 1319, 30, 316, 2199, 472, 307, 281, 445, 5513, 264, 23565, 5772, 493, 420, 760, 13, 961, 311, 536, 437, 2314, 562, 321, 50756], "temperature": 0.0, "avg_logprob": -0.04208872907905169, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.003075281623750925}, {"id": 136, "seek": 90192, "start": 909.76, "end": 917.4399999999999, "text": " try that. It looks like shifting up or down the signal only affects the zeroth index coefficient.", "tokens": [50756, 853, 300, 13, 467, 1542, 411, 17573, 493, 420, 760, 264, 6358, 787, 11807, 264, 44746, 900, 8186, 17619, 13, 51140], "temperature": 0.0, "avg_logprob": -0.04208872907905169, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.003075281623750925}, {"id": 137, "seek": 90192, "start": 918.3199999999999, "end": 923.52, "text": " That's an interesting data point that we'll come back to. Another parameter of cosine waves", "tokens": [51184, 663, 311, 364, 1880, 1412, 935, 300, 321, 603, 808, 646, 281, 13, 3996, 13075, 295, 23565, 9417, 51444], "temperature": 0.0, "avg_logprob": -0.04208872907905169, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.003075281623750925}, {"id": 138, "seek": 90192, "start": 923.52, "end": 929.8399999999999, "text": " is the frequency. What we're going to do now is show the DCT coefficients as we wind up the", "tokens": [51444, 307, 264, 7893, 13, 708, 321, 434, 516, 281, 360, 586, 307, 855, 264, 9114, 51, 31994, 382, 321, 2468, 493, 264, 51760], "temperature": 0.0, "avg_logprob": -0.04208872907905169, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.003075281623750925}, {"id": 139, "seek": 92984, "start": 929.84, "end": 936.08, "text": " frequency of this cosine wave. I'll keep the sampling strategy we discussed earlier consistent", "tokens": [50364, 7893, 295, 341, 23565, 5772, 13, 286, 603, 1066, 264, 21179, 5206, 321, 7152, 3071, 8398, 50676], "temperature": 0.0, "avg_logprob": -0.060793670607201845, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.0005192968528717756}, {"id": 140, "seek": 92984, "start": 936.08, "end": 943.0400000000001, "text": " among all frequencies. Let's see what happens. As we increase the frequencies we get a few", "tokens": [50676, 3654, 439, 20250, 13, 961, 311, 536, 437, 2314, 13, 1018, 321, 3488, 264, 20250, 321, 483, 257, 1326, 51024], "temperature": 0.0, "avg_logprob": -0.060793670607201845, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.0005192968528717756}, {"id": 141, "seek": 92984, "start": 943.0400000000001, "end": 949.9200000000001, "text": " different DCT coefficients for the respective cosine wave. That is until we get to this cosine wave.", "tokens": [51024, 819, 9114, 51, 31994, 337, 264, 23649, 23565, 5772, 13, 663, 307, 1826, 321, 483, 281, 341, 23565, 5772, 13, 51368], "temperature": 0.0, "avg_logprob": -0.060793670607201845, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.0005192968528717756}, {"id": 142, "seek": 92984, "start": 950.5600000000001, "end": 955.84, "text": " For this particular cosine wave only the second index has a non-zero coefficient.", "tokens": [51400, 1171, 341, 1729, 23565, 5772, 787, 264, 1150, 8186, 575, 257, 2107, 12, 32226, 17619, 13, 51664], "temperature": 0.0, "avg_logprob": -0.060793670607201845, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.0005192968528717756}, {"id": 143, "seek": 95584, "start": 955.84, "end": 962.88, "text": " This cosine wave is actually just double the frequency of the previous cosine wave. This is", "tokens": [50364, 639, 23565, 5772, 307, 767, 445, 3834, 264, 7893, 295, 264, 3894, 23565, 5772, 13, 639, 307, 50716], "temperature": 0.0, "avg_logprob": -0.10023693661940725, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.00039203744381666183}, {"id": 144, "seek": 95584, "start": 962.88, "end": 969.76, "text": " super interesting. The first index of the output seems to nicely correspond with the cosine wave", "tokens": [50716, 1687, 1880, 13, 440, 700, 8186, 295, 264, 5598, 2544, 281, 9594, 6805, 365, 264, 23565, 5772, 51060], "temperature": 0.0, "avg_logprob": -0.10023693661940725, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.00039203744381666183}, {"id": 145, "seek": 95584, "start": 969.76, "end": 975.76, "text": " of frequency one while the second index correlates with a cosine wave of frequency two.", "tokens": [51060, 295, 7893, 472, 1339, 264, 1150, 8186, 13983, 1024, 365, 257, 23565, 5772, 295, 7893, 732, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10023693661940725, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.00039203744381666183}, {"id": 146, "seek": 95584, "start": 977.2800000000001, "end": 982.48, "text": " Let's continue this experiment of increasing frequencies but before I continue see if you", "tokens": [51436, 961, 311, 2354, 341, 5120, 295, 5662, 20250, 457, 949, 286, 2354, 536, 498, 291, 51696], "temperature": 0.0, "avg_logprob": -0.10023693661940725, "compression_ratio": 1.8029556650246306, "no_speech_prob": 0.00039203744381666183}, {"id": 147, "seek": 98248, "start": 982.48, "end": 987.84, "text": " can take a guess at what frequencies the other coefficients will correspond to. Here we go.", "tokens": [50364, 393, 747, 257, 2041, 412, 437, 20250, 264, 661, 31994, 486, 6805, 281, 13, 1692, 321, 352, 13, 50632], "temperature": 0.0, "avg_logprob": -0.07312642203436957, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0014103272696956992}, {"id": 148, "seek": 98248, "start": 988.4, "end": 994.8000000000001, "text": " We slowly increase the frequency and boom the index three coefficient corresponds to a cosine", "tokens": [50660, 492, 5692, 3488, 264, 7893, 293, 9351, 264, 8186, 1045, 17619, 23249, 281, 257, 23565, 50980], "temperature": 0.0, "avg_logprob": -0.07312642203436957, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0014103272696956992}, {"id": 149, "seek": 98248, "start": 994.8000000000001, "end": 1002.8000000000001, "text": " wave of frequency three. Then frequency four comes next and this pattern continues until we get to a", "tokens": [50980, 5772, 295, 7893, 1045, 13, 1396, 7893, 1451, 1487, 958, 293, 341, 5102, 6515, 1826, 321, 483, 281, 257, 51380], "temperature": 0.0, "avg_logprob": -0.07312642203436957, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0014103272696956992}, {"id": 150, "seek": 98248, "start": 1002.8000000000001, "end": 1011.36, "text": " cosine wave of frequency seven. Pretty insane right? So for the coefficients indexed one to seven", "tokens": [51380, 23565, 5772, 295, 7893, 3407, 13, 10693, 10838, 558, 30, 407, 337, 264, 31994, 8186, 292, 472, 281, 3407, 51808], "temperature": 0.0, "avg_logprob": -0.07312642203436957, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.0014103272696956992}, {"id": 151, "seek": 101136, "start": 1011.36, "end": 1018.0, "text": " it looks like they represent the weight on a cosine wave with the frequency that matches the index.", "tokens": [50364, 309, 1542, 411, 436, 2906, 264, 3364, 322, 257, 23565, 5772, 365, 264, 7893, 300, 10676, 264, 8186, 13, 50696], "temperature": 0.0, "avg_logprob": -0.055345454912507135, "compression_ratio": 1.742081447963801, "no_speech_prob": 8.481018448946998e-05}, {"id": 152, "seek": 101136, "start": 1020.0, "end": 1025.84, "text": " So what about the remaining index zero? We saw shifting cosine waves up and down led to a change", "tokens": [50796, 407, 437, 466, 264, 8877, 8186, 4018, 30, 492, 1866, 17573, 23565, 9417, 493, 293, 760, 4684, 281, 257, 1319, 51088], "temperature": 0.0, "avg_logprob": -0.055345454912507135, "compression_ratio": 1.742081447963801, "no_speech_prob": 8.481018448946998e-05}, {"id": 153, "seek": 101136, "start": 1025.84, "end": 1032.8, "text": " in the zeroth index. What cosine wave does that represent? Some of you have probably figured it", "tokens": [51088, 294, 264, 44746, 900, 8186, 13, 708, 23565, 5772, 775, 300, 2906, 30, 2188, 295, 291, 362, 1391, 8932, 309, 51436], "temperature": 0.0, "avg_logprob": -0.055345454912507135, "compression_ratio": 1.742081447963801, "no_speech_prob": 8.481018448946998e-05}, {"id": 154, "seek": 101136, "start": 1032.8, "end": 1038.88, "text": " out but if you think about what a zero frequency cosine wave is it's just a constant signal.", "tokens": [51436, 484, 457, 498, 291, 519, 466, 437, 257, 4018, 7893, 23565, 5772, 307, 309, 311, 445, 257, 5754, 6358, 13, 51740], "temperature": 0.0, "avg_logprob": -0.055345454912507135, "compression_ratio": 1.742081447963801, "no_speech_prob": 8.481018448946998e-05}, {"id": 155, "seek": 103888, "start": 1039.8400000000001, "end": 1045.6000000000001, "text": " What that means in terms of images is it gives us a measure of the overall brightness of a set of", "tokens": [50412, 708, 300, 1355, 294, 2115, 295, 5267, 307, 309, 2709, 505, 257, 3481, 295, 264, 4787, 21367, 295, 257, 992, 295, 50700], "temperature": 0.0, "avg_logprob": -0.056563190051487515, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000535772938746959}, {"id": 156, "seek": 103888, "start": 1045.6000000000001, "end": 1053.7600000000002, "text": " pixels. Brighter images will have a larger zeroth coefficient than darker images. This is why shifting", "tokens": [50700, 18668, 13, 24271, 260, 5267, 486, 362, 257, 4833, 44746, 900, 17619, 813, 12741, 5267, 13, 639, 307, 983, 17573, 51108], "temperature": 0.0, "avg_logprob": -0.056563190051487515, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000535772938746959}, {"id": 157, "seek": 103888, "start": 1053.7600000000002, "end": 1060.64, "text": " up a cosine wave only impacts the zeroth coefficient. Putting this all together each", "tokens": [51108, 493, 257, 23565, 5772, 787, 11606, 264, 44746, 900, 17619, 13, 31367, 341, 439, 1214, 1184, 51452], "temperature": 0.0, "avg_logprob": -0.056563190051487515, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000535772938746959}, {"id": 158, "seek": 103888, "start": 1060.64, "end": 1066.88, "text": " of these frequencies correspond to a different pattern of images and what the core DCT does", "tokens": [51452, 295, 613, 20250, 6805, 281, 257, 819, 5102, 295, 5267, 293, 437, 264, 4965, 9114, 51, 775, 51764], "temperature": 0.0, "avg_logprob": -0.056563190051487515, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000535772938746959}, {"id": 159, "seek": 106688, "start": 1066.88, "end": 1072.3200000000002, "text": " is break down how each of these fundamental patterns contribute to the original image.", "tokens": [50364, 307, 1821, 760, 577, 1184, 295, 613, 8088, 8294, 10586, 281, 264, 3380, 3256, 13, 50636], "temperature": 0.0, "avg_logprob": -0.051153525184182556, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.000911020440980792}, {"id": 160, "seek": 106688, "start": 1073.6000000000001, "end": 1080.4, "text": " And it turns out that all possible combinations of eight pixel values can be represented as a sum", "tokens": [50700, 400, 309, 4523, 484, 300, 439, 1944, 21267, 295, 3180, 19261, 4190, 393, 312, 10379, 382, 257, 2408, 51040], "temperature": 0.0, "avg_logprob": -0.051153525184182556, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.000911020440980792}, {"id": 161, "seek": 106688, "start": 1080.4, "end": 1087.3600000000001, "text": " of these eight cosine waves. Why that's true is not at all obvious but we can begin to understand it", "tokens": [51040, 295, 613, 3180, 23565, 9417, 13, 1545, 300, 311, 2074, 307, 406, 412, 439, 6322, 457, 321, 393, 1841, 281, 1223, 309, 51388], "temperature": 0.0, "avg_logprob": -0.051153525184182556, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.000911020440980792}, {"id": 162, "seek": 106688, "start": 1087.3600000000001, "end": 1094.96, "text": " once we translate this intuition to the actual math behind the DCT. If you look at the mathematical", "tokens": [51388, 1564, 321, 13799, 341, 24002, 281, 264, 3539, 5221, 2261, 264, 9114, 51, 13, 759, 291, 574, 412, 264, 18894, 51768], "temperature": 0.0, "avg_logprob": -0.051153525184182556, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.000911020440980792}, {"id": 163, "seek": 109496, "start": 1094.96, "end": 1101.52, "text": " definition of the DCT we usually have a vector definition of the original signal and the output", "tokens": [50364, 7123, 295, 264, 9114, 51, 321, 2673, 362, 257, 8062, 7123, 295, 264, 3380, 6358, 293, 264, 5598, 50692], "temperature": 0.0, "avg_logprob": -0.064598066666547, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0008558808476664126}, {"id": 164, "seek": 109496, "start": 1101.52, "end": 1109.2, "text": " coefficients. We want to define the kth index of the coefficient vector mathematically. What you", "tokens": [50692, 31994, 13, 492, 528, 281, 6964, 264, 350, 392, 8186, 295, 264, 17619, 8062, 44003, 13, 708, 291, 51076], "temperature": 0.0, "avg_logprob": -0.064598066666547, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0008558808476664126}, {"id": 165, "seek": 109496, "start": 1109.2, "end": 1115.3600000000001, "text": " often see is something that looks like the following and with the intuition that we just built up", "tokens": [51076, 2049, 536, 307, 746, 300, 1542, 411, 264, 3480, 293, 365, 264, 24002, 300, 321, 445, 3094, 493, 51384], "temperature": 0.0, "avg_logprob": -0.064598066666547, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0008558808476664126}, {"id": 166, "seek": 109496, "start": 1115.3600000000001, "end": 1121.8400000000001, "text": " we'll see that this equation is doing exactly what we want. Let's start with the cosine term.", "tokens": [51384, 321, 603, 536, 300, 341, 5367, 307, 884, 2293, 437, 321, 528, 13, 961, 311, 722, 365, 264, 23565, 1433, 13, 51708], "temperature": 0.0, "avg_logprob": -0.064598066666547, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0008558808476664126}, {"id": 167, "seek": 112184, "start": 1121.84, "end": 1128.0, "text": " This function should be familiar. It's the exact representation of a sampled point from a cosine", "tokens": [50364, 639, 2445, 820, 312, 4963, 13, 467, 311, 264, 1900, 10290, 295, 257, 3247, 15551, 935, 490, 257, 23565, 50672], "temperature": 0.0, "avg_logprob": -0.045875690704168276, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0006070609670132399}, {"id": 168, "seek": 112184, "start": 1128.0, "end": 1133.12, "text": " wave using our earlier sampling scheme and it incorporates the frequency of the cosine wave", "tokens": [50672, 5772, 1228, 527, 3071, 21179, 12232, 293, 309, 50193, 264, 7893, 295, 264, 23565, 5772, 50928], "temperature": 0.0, "avg_logprob": -0.045875690704168276, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0006070609670132399}, {"id": 169, "seek": 112184, "start": 1133.12, "end": 1140.3999999999999, "text": " as well. Now what's interesting is in order to get the kth index we are actually summing over a", "tokens": [50928, 382, 731, 13, 823, 437, 311, 1880, 307, 294, 1668, 281, 483, 264, 350, 392, 8186, 321, 366, 767, 2408, 2810, 670, 257, 51292], "temperature": 0.0, "avg_logprob": -0.045875690704168276, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0006070609670132399}, {"id": 170, "seek": 112184, "start": 1140.3999999999999, "end": 1146.8799999999999, "text": " product of each sampled point with samples from the cosine wave. Why does that make sense?", "tokens": [51292, 1674, 295, 1184, 3247, 15551, 935, 365, 10938, 490, 264, 23565, 5772, 13, 1545, 775, 300, 652, 2020, 30, 51616], "temperature": 0.0, "avg_logprob": -0.045875690704168276, "compression_ratio": 1.6519823788546255, "no_speech_prob": 0.0006070609670132399}, {"id": 171, "seek": 114688, "start": 1147.8400000000001, "end": 1152.64, "text": " This type of expression might look vaguely familiar to a lot of you. Let me rewrite this", "tokens": [50412, 639, 2010, 295, 6114, 1062, 574, 13501, 48863, 4963, 281, 257, 688, 295, 291, 13, 961, 385, 28132, 341, 50652], "temperature": 0.0, "avg_logprob": -0.05236612195553987, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0010649457108229399}, {"id": 172, "seek": 114688, "start": 1152.64, "end": 1158.48, "text": " another way. We know that the original signal points can be represented as a vector but what", "tokens": [50652, 1071, 636, 13, 492, 458, 300, 264, 3380, 6358, 2793, 393, 312, 10379, 382, 257, 8062, 457, 437, 50944], "temperature": 0.0, "avg_logprob": -0.05236612195553987, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0010649457108229399}, {"id": 173, "seek": 114688, "start": 1158.48, "end": 1164.8000000000002, "text": " if we rewrote the sampled points from the cosine wave as a vector as well? What does this expression", "tokens": [50944, 498, 321, 319, 7449, 1370, 264, 3247, 15551, 2793, 490, 264, 23565, 5772, 382, 257, 8062, 382, 731, 30, 708, 775, 341, 6114, 51260], "temperature": 0.0, "avg_logprob": -0.05236612195553987, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0010649457108229399}, {"id": 174, "seek": 114688, "start": 1164.8000000000002, "end": 1172.3200000000002, "text": " mean in the context of these two vectors? It's a dot product and what we know about dot products is", "tokens": [51260, 914, 294, 264, 4319, 295, 613, 732, 18875, 30, 467, 311, 257, 5893, 1674, 293, 437, 321, 458, 466, 5893, 3383, 307, 51636], "temperature": 0.0, "avg_logprob": -0.05236612195553987, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0010649457108229399}, {"id": 175, "seek": 117232, "start": 1172.3999999999999, "end": 1179.52, "text": " there a nice way to measure similarity between two vectors. That's why when we pass in sampled", "tokens": [50368, 456, 257, 1481, 636, 281, 3481, 32194, 1296, 732, 18875, 13, 663, 311, 983, 562, 321, 1320, 294, 3247, 15551, 50724], "temperature": 0.0, "avg_logprob": -0.05119497474582716, "compression_ratio": 1.563265306122449, "no_speech_prob": 0.0003250318404752761}, {"id": 176, "seek": 117232, "start": 1179.52, "end": 1187.2, "text": " points from a cosine wave of frequency k as the input to the DCT we got large values at the kth", "tokens": [50724, 2793, 490, 257, 23565, 5772, 295, 7893, 350, 382, 264, 4846, 281, 264, 9114, 51, 321, 658, 2416, 4190, 412, 264, 350, 392, 51108], "temperature": 0.0, "avg_logprob": -0.05119497474582716, "compression_ratio": 1.563265306122449, "no_speech_prob": 0.0003250318404752761}, {"id": 177, "seek": 117232, "start": 1187.2, "end": 1193.84, "text": " index coefficient. These two vectors were just scaled versions of each other so the dot product", "tokens": [51108, 8186, 17619, 13, 1981, 732, 18875, 645, 445, 36039, 9606, 295, 1184, 661, 370, 264, 5893, 1674, 51440], "temperature": 0.0, "avg_logprob": -0.05119497474582716, "compression_ratio": 1.563265306122449, "no_speech_prob": 0.0003250318404752761}, {"id": 178, "seek": 117232, "start": 1193.84, "end": 1200.08, "text": " was maximized and this perspective reveals what I think is truly the most surprising and elegant", "tokens": [51440, 390, 5138, 1602, 293, 341, 4585, 20893, 437, 286, 519, 307, 4908, 264, 881, 8830, 293, 21117, 51752], "temperature": 0.0, "avg_logprob": -0.05119497474582716, "compression_ratio": 1.563265306122449, "no_speech_prob": 0.0003250318404752761}, {"id": 179, "seek": 120008, "start": 1200.08, "end": 1207.28, "text": " part of the DCT. By picking the points through the sampling method we can think of the entire DCT", "tokens": [50364, 644, 295, 264, 9114, 51, 13, 3146, 8867, 264, 2793, 807, 264, 21179, 3170, 321, 393, 519, 295, 264, 2302, 9114, 51, 50724], "temperature": 0.0, "avg_logprob": -0.04927596941099062, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.001754571101628244}, {"id": 180, "seek": 120008, "start": 1207.28, "end": 1214.08, "text": " as a matrix vector product. All we're doing here is a linear transformation. The rows of the matrix", "tokens": [50724, 382, 257, 8141, 8062, 1674, 13, 1057, 321, 434, 884, 510, 307, 257, 8213, 9887, 13, 440, 13241, 295, 264, 8141, 51064], "temperature": 0.0, "avg_logprob": -0.04927596941099062, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.001754571101628244}, {"id": 181, "seek": 120008, "start": 1214.08, "end": 1219.28, "text": " are the sampled points from the cosine waves of the respective frequencies and what's truly", "tokens": [51064, 366, 264, 3247, 15551, 2793, 490, 264, 23565, 9417, 295, 264, 23649, 20250, 293, 437, 311, 4908, 51324], "temperature": 0.0, "avg_logprob": -0.04927596941099062, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.001754571101628244}, {"id": 182, "seek": 120008, "start": 1219.28, "end": 1225.6799999999998, "text": " astounding is that all row vectors in this matrix are orthogonal to each other. What I mean by that", "tokens": [51324, 5357, 24625, 307, 300, 439, 5386, 18875, 294, 341, 8141, 366, 41488, 281, 1184, 661, 13, 708, 286, 914, 538, 300, 51644], "temperature": 0.0, "avg_logprob": -0.04927596941099062, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.001754571101628244}, {"id": 183, "seek": 122568, "start": 1225.68, "end": 1231.92, "text": " is if you take the dot product of any two row vectors representing cosine waves you will get", "tokens": [50364, 307, 498, 291, 747, 264, 5893, 1674, 295, 604, 732, 5386, 18875, 13460, 23565, 9417, 291, 486, 483, 50676], "temperature": 0.0, "avg_logprob": -0.03237461763269761, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0013249930925667286}, {"id": 184, "seek": 122568, "start": 1231.92, "end": 1238.88, "text": " zero if they are different rows of the matrix. Intuitively this is why in our earlier experiments", "tokens": [50676, 4018, 498, 436, 366, 819, 13241, 295, 264, 8141, 13, 5681, 1983, 3413, 341, 307, 983, 294, 527, 3071, 12050, 51024], "temperature": 0.0, "avg_logprob": -0.03237461763269761, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0013249930925667286}, {"id": 185, "seek": 122568, "start": 1238.88, "end": 1246.0, "text": " when we pass in a cosine wave of a particular frequency as an input into the DCT we didn't get", "tokens": [51024, 562, 321, 1320, 294, 257, 23565, 5772, 295, 257, 1729, 7893, 382, 364, 4846, 666, 264, 9114, 51, 321, 994, 380, 483, 51380], "temperature": 0.0, "avg_logprob": -0.03237461763269761, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0013249930925667286}, {"id": 186, "seek": 122568, "start": 1246.0, "end": 1252.24, "text": " a contribution from any of the other coefficients which represented different frequency cosine waves.", "tokens": [51380, 257, 13150, 490, 604, 295, 264, 661, 31994, 597, 10379, 819, 7893, 23565, 9417, 13, 51692], "temperature": 0.0, "avg_logprob": -0.03237461763269761, "compression_ratio": 1.7048458149779735, "no_speech_prob": 0.0013249930925667286}, {"id": 187, "seek": 125224, "start": 1252.88, "end": 1258.8, "text": " The orthogonality of the sampled points from different cosine waves generates this behavior.", "tokens": [50396, 440, 38130, 266, 1860, 295, 264, 3247, 15551, 2793, 490, 819, 23565, 9417, 23815, 341, 5223, 13, 50692], "temperature": 0.0, "avg_logprob": -0.06595565051567263, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0007793497061356902}, {"id": 188, "seek": 125224, "start": 1259.36, "end": 1265.6, "text": " It's really quite beautiful. Another great property of the DCT that follows from these", "tokens": [50720, 467, 311, 534, 1596, 2238, 13, 3996, 869, 4707, 295, 264, 9114, 51, 300, 10002, 490, 613, 51032], "temperature": 0.0, "avg_logprob": -0.06595565051567263, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0007793497061356902}, {"id": 189, "seek": 125224, "start": 1265.6, "end": 1272.32, "text": " facts is invertibility. I've talked about the DCT as a way of decomposing a signal into a", "tokens": [51032, 9130, 307, 33966, 2841, 13, 286, 600, 2825, 466, 264, 9114, 51, 382, 257, 636, 295, 22867, 6110, 257, 6358, 666, 257, 51368], "temperature": 0.0, "avg_logprob": -0.06595565051567263, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0007793497061356902}, {"id": 190, "seek": 125224, "start": 1272.32, "end": 1278.88, "text": " coefficient representation of weights associated with cosine waves. We can also reverse this process.", "tokens": [51368, 17619, 10290, 295, 17443, 6615, 365, 23565, 9417, 13, 492, 393, 611, 9943, 341, 1399, 13, 51696], "temperature": 0.0, "avg_logprob": -0.06595565051567263, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.0007793497061356902}, {"id": 191, "seek": 127888, "start": 1279.68, "end": 1285.0400000000002, "text": " If I take my coefficient representation of the signal I can apply what's called the inverse", "tokens": [50404, 759, 286, 747, 452, 17619, 10290, 295, 264, 6358, 286, 393, 3079, 437, 311, 1219, 264, 17340, 50672], "temperature": 0.0, "avg_logprob": -0.040684004624684654, "compression_ratio": 1.7116279069767442, "no_speech_prob": 0.0030752436723560095}, {"id": 192, "seek": 127888, "start": 1285.0400000000002, "end": 1293.44, "text": " DCT to get back the original signal and it is the exact same signal. No information is lost", "tokens": [50672, 9114, 51, 281, 483, 646, 264, 3380, 6358, 293, 309, 307, 264, 1900, 912, 6358, 13, 883, 1589, 307, 2731, 51092], "temperature": 0.0, "avg_logprob": -0.040684004624684654, "compression_ratio": 1.7116279069767442, "no_speech_prob": 0.0030752436723560095}, {"id": 193, "seek": 127888, "start": 1293.44, "end": 1300.0800000000002, "text": " in this step. How we do that is by multiplying our coefficient representation with the inverse", "tokens": [51092, 294, 341, 1823, 13, 1012, 321, 360, 300, 307, 538, 30955, 527, 17619, 10290, 365, 264, 17340, 51424], "temperature": 0.0, "avg_logprob": -0.040684004624684654, "compression_ratio": 1.7116279069767442, "no_speech_prob": 0.0030752436723560095}, {"id": 194, "seek": 127888, "start": 1300.0800000000002, "end": 1306.64, "text": " of the matrix. What's cool about this is that because of the orthogonality of the vectors", "tokens": [51424, 295, 264, 8141, 13, 708, 311, 1627, 466, 341, 307, 300, 570, 295, 264, 38130, 266, 1860, 295, 264, 18875, 51752], "temperature": 0.0, "avg_logprob": -0.040684004624684654, "compression_ratio": 1.7116279069767442, "no_speech_prob": 0.0030752436723560095}, {"id": 195, "seek": 130664, "start": 1306.64, "end": 1312.96, "text": " the inverse is just the transpose of our original matrix with some additional normalization constants.", "tokens": [50364, 264, 17340, 307, 445, 264, 25167, 295, 527, 3380, 8141, 365, 512, 4497, 2710, 2144, 35870, 13, 50680], "temperature": 0.0, "avg_logprob": -0.0657703697681427, "compression_ratio": 1.668122270742358, "no_speech_prob": 9.915185364661738e-05}, {"id": 196, "seek": 130664, "start": 1314.8000000000002, "end": 1321.2, "text": " Now there's a super nice interpretation of the inverse DCT. The sample cosine wave points are", "tokens": [50772, 823, 456, 311, 257, 1687, 1481, 14174, 295, 264, 17340, 9114, 51, 13, 440, 6889, 23565, 5772, 2793, 366, 51092], "temperature": 0.0, "avg_logprob": -0.0657703697681427, "compression_ratio": 1.668122270742358, "no_speech_prob": 9.915185364661738e-05}, {"id": 197, "seek": 130664, "start": 1321.2, "end": 1327.2, "text": " now column vectors so what the inverse DCT is doing is essentially summing over a weighted", "tokens": [51092, 586, 7738, 18875, 370, 437, 264, 17340, 9114, 51, 307, 884, 307, 4476, 2408, 2810, 670, 257, 32807, 51392], "temperature": 0.0, "avg_logprob": -0.0657703697681427, "compression_ratio": 1.668122270742358, "no_speech_prob": 9.915185364661738e-05}, {"id": 198, "seek": 130664, "start": 1327.2, "end": 1333.6000000000001, "text": " combination of cosine waves directly to get the original signal. And because these columns are", "tokens": [51392, 6562, 295, 23565, 9417, 3838, 281, 483, 264, 3380, 6358, 13, 400, 570, 613, 13766, 366, 51712], "temperature": 0.0, "avg_logprob": -0.0657703697681427, "compression_ratio": 1.668122270742358, "no_speech_prob": 9.915185364661738e-05}, {"id": 199, "seek": 133360, "start": 1333.6, "end": 1339.36, "text": " orthogonal to each other that's what allows us to represent any set of eight points with these", "tokens": [50364, 41488, 281, 1184, 661, 300, 311, 437, 4045, 505, 281, 2906, 604, 992, 295, 3180, 2793, 365, 613, 50652], "temperature": 0.0, "avg_logprob": -0.05243988037109375, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.0015011426294222474}, {"id": 200, "seek": 133360, "start": 1339.36, "end": 1345.6799999999998, "text": " eight cosine waves. Absolutely incredible. I know we spent some time and went through some fairly", "tokens": [50652, 3180, 23565, 9417, 13, 7021, 4651, 13, 286, 458, 321, 4418, 512, 565, 293, 1437, 807, 512, 6457, 50968], "temperature": 0.0, "avg_logprob": -0.05243988037109375, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.0015011426294222474}, {"id": 201, "seek": 133360, "start": 1345.6799999999998, "end": 1351.36, "text": " complex math to get here but it's precisely these details that are the most fundamental part of not", "tokens": [50968, 3997, 5221, 281, 483, 510, 457, 309, 311, 13402, 613, 4365, 300, 366, 264, 881, 8088, 644, 295, 406, 51252], "temperature": 0.0, "avg_logprob": -0.05243988037109375, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.0015011426294222474}, {"id": 202, "seek": 133360, "start": 1351.36, "end": 1359.04, "text": " only the DCT but many other similar transforms in the world of signal processing. Now that we have", "tokens": [51252, 787, 264, 9114, 51, 457, 867, 661, 2531, 35592, 294, 264, 1002, 295, 6358, 9007, 13, 823, 300, 321, 362, 51636], "temperature": 0.0, "avg_logprob": -0.05243988037109375, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.0015011426294222474}, {"id": 203, "seek": 135904, "start": 1359.04, "end": 1365.44, "text": " a good intuition on the one-dimensional DCT let's talk about how JPEG specifically uses it.", "tokens": [50364, 257, 665, 24002, 322, 264, 472, 12, 18759, 9114, 51, 718, 311, 751, 466, 577, 508, 5208, 38, 4682, 4960, 309, 13, 50684], "temperature": 0.0, "avg_logprob": -0.05678537819120619, "compression_ratio": 1.4659685863874345, "no_speech_prob": 0.0026316125877201557}, {"id": 204, "seek": 135904, "start": 1366.48, "end": 1371.84, "text": " JPEG takes an image and splits it into eight by eight blocks and then centers their values", "tokens": [50736, 508, 5208, 38, 2516, 364, 3256, 293, 37741, 309, 666, 3180, 538, 3180, 8474, 293, 550, 10898, 641, 4190, 51004], "temperature": 0.0, "avg_logprob": -0.05678537819120619, "compression_ratio": 1.4659685863874345, "no_speech_prob": 0.0026316125877201557}, {"id": 205, "seek": 135904, "start": 1371.84, "end": 1381.04, "text": " around zero by subtracting 128. Then we take the block and apply the DCT to each row of the block", "tokens": [51004, 926, 4018, 538, 16390, 278, 29810, 13, 1396, 321, 747, 264, 3461, 293, 3079, 264, 9114, 51, 281, 1184, 5386, 295, 264, 3461, 51464], "temperature": 0.0, "avg_logprob": -0.05678537819120619, "compression_ratio": 1.4659685863874345, "no_speech_prob": 0.0026316125877201557}, {"id": 206, "seek": 138104, "start": 1381.04, "end": 1389.2, "text": " giving us eight sets of DCT coefficients. We then apply the DCT to each column of the block.", "tokens": [50364, 2902, 505, 3180, 6352, 295, 9114, 51, 31994, 13, 492, 550, 3079, 264, 9114, 51, 281, 1184, 7738, 295, 264, 3461, 13, 50772], "temperature": 0.0, "avg_logprob": -0.09002400958348834, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0003682951210066676}, {"id": 207, "seek": 138104, "start": 1393.28, "end": 1396.8799999999999, "text": " This process is what defines the two-dimensional DCT.", "tokens": [50976, 639, 1399, 307, 437, 23122, 264, 732, 12, 18759, 9114, 51, 13, 51156], "temperature": 0.0, "avg_logprob": -0.09002400958348834, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0003682951210066676}, {"id": 208, "seek": 138104, "start": 1399.12, "end": 1405.76, "text": " So in the end we have 64 coefficients each of which are await on a specific eight by eight pattern.", "tokens": [51268, 407, 294, 264, 917, 321, 362, 12145, 31994, 1184, 295, 597, 366, 19670, 322, 257, 2685, 3180, 538, 3180, 5102, 13, 51600], "temperature": 0.0, "avg_logprob": -0.09002400958348834, "compression_ratio": 1.4819277108433735, "no_speech_prob": 0.0003682951210066676}, {"id": 209, "seek": 140576, "start": 1406.4, "end": 1412.0, "text": " Notice the first row and column correspond to the earlier one-dimensional patterns and the other", "tokens": [50396, 13428, 264, 700, 5386, 293, 7738, 6805, 281, 264, 3071, 472, 12, 18759, 8294, 293, 264, 661, 50676], "temperature": 0.0, "avg_logprob": -0.16051428002047252, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0020507045555859804}, {"id": 210, "seek": 140576, "start": 1412.0, "end": 1419.04, "text": " elements are compositions of these patterns. And just like in the one-dimensional case the big idea", "tokens": [50676, 4959, 366, 43401, 295, 613, 8294, 13, 400, 445, 411, 294, 264, 472, 12, 18759, 1389, 264, 955, 1558, 51028], "temperature": 0.0, "avg_logprob": -0.16051428002047252, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0020507045555859804}, {"id": 211, "seek": 140576, "start": 1419.04, "end": 1426.96, "text": " here is that we can build up any eight by eight image using these 64 fundamental patterns. The", "tokens": [51028, 510, 307, 300, 321, 393, 1322, 493, 604, 3180, 538, 3180, 3256, 1228, 613, 12145, 8088, 8294, 13, 440, 51424], "temperature": 0.0, "avg_logprob": -0.16051428002047252, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0020507045555859804}, {"id": 212, "seek": 140576, "start": 1426.96, "end": 1432.96, "text": " same signal perspective we talked about earlier also applies here except now with 2D waveforms.", "tokens": [51424, 912, 6358, 4585, 321, 2825, 466, 3071, 611, 13165, 510, 3993, 586, 365, 568, 35, 36512, 82, 13, 51724], "temperature": 0.0, "avg_logprob": -0.16051428002047252, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0020507045555859804}, {"id": 213, "seek": 143296, "start": 1432.96, "end": 1438.48, "text": " What's going on here is we are plotting the pixel value on the z-axis with brighter pixels having", "tokens": [50364, 708, 311, 516, 322, 510, 307, 321, 366, 41178, 264, 19261, 2158, 322, 264, 710, 12, 24633, 365, 19764, 18668, 1419, 50640], "temperature": 0.0, "avg_logprob": -0.12281684415886202, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.0015977867878973484}, {"id": 214, "seek": 143296, "start": 1438.48, "end": 1445.2, "text": " larger values. What's fun to play around with is seeing how the waveform and image come together", "tokens": [50640, 4833, 4190, 13, 708, 311, 1019, 281, 862, 926, 365, 307, 2577, 577, 264, 36512, 293, 3256, 808, 1214, 50976], "temperature": 0.0, "avg_logprob": -0.12281684415886202, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.0015977867878973484}, {"id": 215, "seek": 143296, "start": 1445.2, "end": 1453.2, "text": " as we slowly put together the 64 coefficients in increasing frequencies. Seeing this in action", "tokens": [50976, 382, 321, 5692, 829, 1214, 264, 12145, 31994, 294, 5662, 20250, 13, 19703, 341, 294, 3069, 51376], "temperature": 0.0, "avg_logprob": -0.12281684415886202, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.0015977867878973484}, {"id": 216, "seek": 143296, "start": 1453.2, "end": 1458.64, "text": " makes you realize that one interesting property is that by the time we incorporate a small portion", "tokens": [51376, 1669, 291, 4325, 300, 472, 1880, 4707, 307, 300, 538, 264, 565, 321, 16091, 257, 1359, 8044, 51648], "temperature": 0.0, "avg_logprob": -0.12281684415886202, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.0015977867878973484}, {"id": 217, "seek": 145864, "start": 1458.72, "end": 1463.92, "text": " of the coefficients our signal and image already look pretty close to the original versions.", "tokens": [50368, 295, 264, 31994, 527, 6358, 293, 3256, 1217, 574, 1238, 1998, 281, 264, 3380, 9606, 13, 50628], "temperature": 0.0, "avg_logprob": -0.24672116290081988, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00013551946904044598}, {"id": 218, "seek": 145864, "start": 1465.3600000000001, "end": 1470.0800000000002, "text": " There's an even more direct experiment we can run to quantify this notion.", "tokens": [50700, 821, 311, 364, 754, 544, 2047, 5120, 321, 393, 1190, 281, 40421, 341, 10710, 13, 50936], "temperature": 0.0, "avg_logprob": -0.24672116290081988, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00013551946904044598}, {"id": 219, "seek": 145864, "start": 1471.76, "end": 1476.48, "text": " This particular eight by eight block was randomly picked out of the original image.", "tokens": [51020, 639, 1729, 3180, 538, 3180, 3461, 390, 16979, 6183, 484, 295, 264, 3380, 3256, 13, 51256], "temperature": 0.0, "avg_logprob": -0.24672116290081988, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00013551946904044598}, {"id": 220, "seek": 145864, "start": 1477.2, "end": 1482.5600000000002, "text": " If we map out the magnitude of the DCT coefficients on this block we see that most", "tokens": [51292, 759, 321, 4471, 484, 264, 15668, 295, 264, 9114, 51, 31994, 322, 341, 3461, 321, 536, 300, 881, 51560], "temperature": 0.0, "avg_logprob": -0.24672116290081988, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00013551946904044598}, {"id": 221, "seek": 145864, "start": 1482.5600000000002, "end": 1486.4, "text": " of the largest values are in the upper left section which corresponds to the original", "tokens": [51560, 295, 264, 6443, 4190, 366, 294, 264, 6597, 1411, 3541, 597, 23249, 281, 264, 3380, 51752], "temperature": 0.0, "avg_logprob": -0.24672116290081988, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00013551946904044598}, {"id": 222, "seek": 148640, "start": 1486.5600000000002, "end": 1492.24, "text": " upper left section which corresponds to lower frequency components. And what's even more", "tokens": [50372, 6597, 1411, 3541, 597, 23249, 281, 3126, 7893, 6677, 13, 400, 437, 311, 754, 544, 50656], "temperature": 0.0, "avg_logprob": -0.08331354856491088, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0009110266109928489}, {"id": 223, "seek": 148640, "start": 1492.24, "end": 1498.5600000000002, "text": " interesting if I take any eight by eight block on this image almost all of them have the same", "tokens": [50656, 1880, 498, 286, 747, 604, 3180, 538, 3180, 3461, 322, 341, 3256, 1920, 439, 295, 552, 362, 264, 912, 50972], "temperature": 0.0, "avg_logprob": -0.08331354856491088, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0009110266109928489}, {"id": 224, "seek": 148640, "start": 1498.5600000000002, "end": 1504.8000000000002, "text": " property. This property of the DCT is what's commonly referred to as energy compaction.", "tokens": [50972, 4707, 13, 639, 4707, 295, 264, 9114, 51, 307, 437, 311, 12719, 10839, 281, 382, 2281, 715, 2894, 13, 51284], "temperature": 0.0, "avg_logprob": -0.08331354856491088, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0009110266109928489}, {"id": 225, "seek": 148640, "start": 1506.24, "end": 1512.3200000000002, "text": " After applying the DCT most of the largest values are concentrated in a few low frequency", "tokens": [51356, 2381, 9275, 264, 9114, 51, 881, 295, 264, 6443, 4190, 366, 21321, 294, 257, 1326, 2295, 7893, 51660], "temperature": 0.0, "avg_logprob": -0.08331354856491088, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0009110266109928489}, {"id": 226, "seek": 151232, "start": 1512.32, "end": 1519.04, "text": " coefficients and this holds true in a lot of real world images. The concept of energy compaction", "tokens": [50364, 31994, 293, 341, 9190, 2074, 294, 257, 688, 295, 957, 1002, 5267, 13, 440, 3410, 295, 2281, 715, 2894, 50700], "temperature": 0.0, "avg_logprob": -0.07529542897198652, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0005192935350351036}, {"id": 227, "seek": 151232, "start": 1519.04, "end": 1524.8799999999999, "text": " is incredibly important in image compression. As we will see it's exactly the property that", "tokens": [50700, 307, 6252, 1021, 294, 3256, 19355, 13, 1018, 321, 486, 536, 309, 311, 2293, 264, 4707, 300, 50992], "temperature": 0.0, "avg_logprob": -0.07529542897198652, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0005192935350351036}, {"id": 228, "seek": 151232, "start": 1524.8799999999999, "end": 1530.3999999999999, "text": " will allow us to aggressively compress images while still retaining high visual quality.", "tokens": [50992, 486, 2089, 505, 281, 32024, 14778, 5267, 1339, 920, 34936, 1090, 5056, 3125, 13, 51268], "temperature": 0.0, "avg_logprob": -0.07529542897198652, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0005192935350351036}, {"id": 229, "seek": 151232, "start": 1533.28, "end": 1539.28, "text": " Fun fact the original discovery the DCT centered around approximating other transforms", "tokens": [51412, 11166, 1186, 264, 3380, 12114, 264, 9114, 51, 18988, 926, 8542, 990, 661, 35592, 51712], "temperature": 0.0, "avg_logprob": -0.07529542897198652, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0005192935350351036}, {"id": 230, "seek": 153928, "start": 1539.28, "end": 1545.84, "text": " that had better energy compaction properties but were too expensive to carry out. The DCT is just", "tokens": [50364, 300, 632, 1101, 2281, 715, 2894, 7221, 457, 645, 886, 5124, 281, 3985, 484, 13, 440, 9114, 51, 307, 445, 50692], "temperature": 0.0, "avg_logprob": -0.06361070375763968, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0002165404730476439}, {"id": 231, "seek": 153928, "start": 1545.84, "end": 1551.12, "text": " one example of a transform that has this property for real world images and we use it because it's", "tokens": [50692, 472, 1365, 295, 257, 4088, 300, 575, 341, 4707, 337, 957, 1002, 5267, 293, 321, 764, 309, 570, 309, 311, 50956], "temperature": 0.0, "avg_logprob": -0.06361070375763968, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0002165404730476439}, {"id": 232, "seek": 153928, "start": 1551.12, "end": 1557.92, "text": " quite easy to compute. There's a lot of complexity involved here but one of my goals in this discussion", "tokens": [50956, 1596, 1858, 281, 14722, 13, 821, 311, 257, 688, 295, 14024, 3288, 510, 457, 472, 295, 452, 5493, 294, 341, 5017, 51296], "temperature": 0.0, "avg_logprob": -0.06361070375763968, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0002165404730476439}, {"id": 233, "seek": 153928, "start": 1557.92, "end": 1563.6, "text": " of the DCT and JPEG was directly interacting with these deep and important ideas through", "tokens": [51296, 295, 264, 9114, 51, 293, 508, 5208, 38, 390, 3838, 18017, 365, 613, 2452, 293, 1021, 3487, 807, 51580], "temperature": 0.0, "avg_logprob": -0.06361070375763968, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0002165404730476439}, {"id": 234, "seek": 156360, "start": 1563.6, "end": 1570.0, "text": " questions and visual experiments. Interactivity is a core part of learning and a website that", "tokens": [50364, 1651, 293, 5056, 12050, 13, 5751, 578, 4253, 307, 257, 4965, 644, 295, 2539, 293, 257, 3144, 300, 50684], "temperature": 0.0, "avg_logprob": -0.06674179625003895, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.008061535656452179}, {"id": 235, "seek": 156360, "start": 1570.0, "end": 1576.56, "text": " does a fantastic job of interactive explanations is Brilliant the sponsor for this video. From the", "tokens": [50684, 775, 257, 5456, 1691, 295, 15141, 28708, 307, 34007, 264, 16198, 337, 341, 960, 13, 3358, 264, 51012], "temperature": 0.0, "avg_logprob": -0.06674179625003895, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.008061535656452179}, {"id": 236, "seek": 156360, "start": 1576.56, "end": 1581.1999999999998, "text": " basics of mathematics and algorithmic thinking to more complex ideas and deep learning and", "tokens": [51012, 14688, 295, 18666, 293, 9284, 299, 1953, 281, 544, 3997, 3487, 293, 2452, 2539, 293, 51244], "temperature": 0.0, "avg_logprob": -0.06674179625003895, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.008061535656452179}, {"id": 237, "seek": 156360, "start": 1581.1999999999998, "end": 1586.48, "text": " probability Brilliant offers a variety of courses and learning paths for those interested in getting", "tokens": [51244, 8482, 34007, 7736, 257, 5673, 295, 7712, 293, 2539, 14518, 337, 729, 3102, 294, 1242, 51508], "temperature": 0.0, "avg_logprob": -0.06674179625003895, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.008061535656452179}, {"id": 238, "seek": 156360, "start": 1586.48, "end": 1592.0, "text": " hands on practice. Our discussions of JPEG interacted with some linear algebra in the", "tokens": [51508, 2377, 322, 3124, 13, 2621, 11088, 295, 508, 5208, 38, 49621, 365, 512, 8213, 21989, 294, 264, 51784], "temperature": 0.0, "avg_logprob": -0.06674179625003895, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.008061535656452179}, {"id": 239, "seek": 159200, "start": 1592.0, "end": 1597.68, "text": " application of image compression and Brilliant has an entire linear algebra module that goes", "tokens": [50364, 3861, 295, 3256, 19355, 293, 34007, 575, 364, 2302, 8213, 21989, 10088, 300, 1709, 50648], "temperature": 0.0, "avg_logprob": -0.053733311342389393, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.0013249958865344524}, {"id": 240, "seek": 159200, "start": 1597.68, "end": 1602.4, "text": " through the fundamentals and even shows applications of these ideas in image compression,", "tokens": [50648, 807, 264, 29505, 293, 754, 3110, 5821, 295, 613, 3487, 294, 3256, 19355, 11, 50884], "temperature": 0.0, "avg_logprob": -0.053733311342389393, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.0013249958865344524}, {"id": 241, "seek": 159200, "start": 1602.4, "end": 1609.12, "text": " cryptography, error correcting codes and much more. When I was a student I really enjoyed their", "tokens": [50884, 9844, 5820, 11, 6713, 47032, 14211, 293, 709, 544, 13, 1133, 286, 390, 257, 3107, 286, 534, 4626, 641, 51220], "temperature": 0.0, "avg_logprob": -0.053733311342389393, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.0013249958865344524}, {"id": 242, "seek": 159200, "start": 1609.12, "end": 1613.92, "text": " computer science fundamentals course which has engaging visualizations of concepts and great", "tokens": [51220, 3820, 3497, 29505, 1164, 597, 575, 11268, 5056, 14455, 295, 10392, 293, 869, 51460], "temperature": 0.0, "avg_logprob": -0.053733311342389393, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.0013249958865344524}, {"id": 243, "seek": 159200, "start": 1613.92, "end": 1618.8, "text": " practice problems that helped me solidify my foundations. You can get started for free by", "tokens": [51460, 3124, 2740, 300, 4254, 385, 5100, 2505, 452, 22467, 13, 509, 393, 483, 1409, 337, 1737, 538, 51704], "temperature": 0.0, "avg_logprob": -0.053733311342389393, "compression_ratio": 1.6886446886446886, "no_speech_prob": 0.0013249958865344524}, {"id": 244, "seek": 161880, "start": 1618.8, "end": 1624.72, "text": " going to brilliant.org slash reducible which is linked in the description below. Brilliant is", "tokens": [50364, 516, 281, 10248, 13, 4646, 17330, 2783, 32128, 597, 307, 9408, 294, 264, 3855, 2507, 13, 34007, 307, 50660], "temperature": 0.0, "avg_logprob": -0.05197379658523115, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.04208054021000862}, {"id": 245, "seek": 161880, "start": 1624.72, "end": 1629.84, "text": " providing a special offer through this channel where the first 200 members to sign up get 20%", "tokens": [50660, 6530, 257, 2121, 2626, 807, 341, 2269, 689, 264, 700, 2331, 2679, 281, 1465, 493, 483, 945, 4, 50916], "temperature": 0.0, "avg_logprob": -0.05197379658523115, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.04208054021000862}, {"id": 246, "seek": 161880, "start": 1629.84, "end": 1634.96, "text": " off the annual subscription. It's a great way to learn more about the topics in these videos", "tokens": [50916, 766, 264, 9784, 17231, 13, 467, 311, 257, 869, 636, 281, 1466, 544, 466, 264, 8378, 294, 613, 2145, 51172], "temperature": 0.0, "avg_logprob": -0.05197379658523115, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.04208054021000862}, {"id": 247, "seek": 161880, "start": 1634.96, "end": 1640.48, "text": " and also a good way to support this channel. Big thanks to Brilliant for sponsoring this video.", "tokens": [51172, 293, 611, 257, 665, 636, 281, 1406, 341, 2269, 13, 5429, 3231, 281, 34007, 337, 30311, 341, 960, 13, 51448], "temperature": 0.0, "avg_logprob": -0.05197379658523115, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.04208054021000862}, {"id": 248, "seek": 161880, "start": 1642.72, "end": 1647.36, "text": " Let's put everything we've discussed with the DCT together in one more experiment.", "tokens": [51560, 961, 311, 829, 1203, 321, 600, 7152, 365, 264, 9114, 51, 1214, 294, 472, 544, 5120, 13, 51792], "temperature": 0.0, "avg_logprob": -0.05197379658523115, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.04208054021000862}, {"id": 249, "seek": 164736, "start": 1648.1599999999999, "end": 1652.8, "text": " We'll split our image into eight by eight blocks and then basically rebuild the image", "tokens": [50404, 492, 603, 7472, 527, 3256, 666, 3180, 538, 3180, 8474, 293, 550, 1936, 16877, 264, 3256, 50636], "temperature": 0.0, "avg_logprob": -0.06921372001553759, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.021611511707305908}, {"id": 250, "seek": 164736, "start": 1652.8, "end": 1659.4399999999998, "text": " with each block having only a certain number of DCT coefficients. We're going to start off with", "tokens": [50636, 365, 1184, 3461, 1419, 787, 257, 1629, 1230, 295, 9114, 51, 31994, 13, 492, 434, 516, 281, 722, 766, 365, 50968], "temperature": 0.0, "avg_logprob": -0.06921372001553759, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.021611511707305908}, {"id": 251, "seek": 164736, "start": 1659.4399999999998, "end": 1666.7199999999998, "text": " zero coefficients and slowly build up the image. After one coefficient we end up with basically a", "tokens": [50968, 4018, 31994, 293, 5692, 1322, 493, 264, 3256, 13, 2381, 472, 17619, 321, 917, 493, 365, 1936, 257, 51332], "temperature": 0.0, "avg_logprob": -0.06921372001553759, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.021611511707305908}, {"id": 252, "seek": 164736, "start": 1666.7199999999998, "end": 1674.08, "text": " blur of the original image and as we add DCT coefficients slowly notice how quickly the", "tokens": [51332, 14257, 295, 264, 3380, 3256, 293, 382, 321, 909, 9114, 51, 31994, 5692, 3449, 577, 2661, 264, 51700], "temperature": 0.0, "avg_logprob": -0.06921372001553759, "compression_ratio": 1.7644230769230769, "no_speech_prob": 0.021611511707305908}, {"id": 253, "seek": 167408, "start": 1674.08, "end": 1681.6, "text": " image starts looking like the original. By the time we get to less than 25% of the DCT coefficients", "tokens": [50364, 3256, 3719, 1237, 411, 264, 3380, 13, 3146, 264, 565, 321, 483, 281, 1570, 813, 3552, 4, 295, 264, 9114, 51, 31994, 50740], "temperature": 0.0, "avg_logprob": -0.04562827131964944, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0007553884061053395}, {"id": 254, "seek": 167408, "start": 1681.6, "end": 1687.6799999999998, "text": " you almost can't even tell the difference between the two images. This confirms the key aspects of", "tokens": [50740, 291, 1920, 393, 380, 754, 980, 264, 2649, 1296, 264, 732, 5267, 13, 639, 39982, 264, 2141, 7270, 295, 51044], "temperature": 0.0, "avg_logprob": -0.04562827131964944, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0007553884061053395}, {"id": 255, "seek": 167408, "start": 1687.6799999999998, "end": 1694.48, "text": " why JPEG works for this particular image. Almost all the blocks are composed of the lowest frequency", "tokens": [51044, 983, 508, 5208, 38, 1985, 337, 341, 1729, 3256, 13, 12627, 439, 264, 8474, 366, 18204, 295, 264, 12437, 7893, 51384], "temperature": 0.0, "avg_logprob": -0.04562827131964944, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0007553884061053395}, {"id": 256, "seek": 167408, "start": 1694.48, "end": 1700.8, "text": " components and we are generally less sensitive to changes in high frequency details. So at this", "tokens": [51384, 6677, 293, 321, 366, 5101, 1570, 9477, 281, 2962, 294, 1090, 7893, 4365, 13, 407, 412, 341, 51700], "temperature": 0.0, "avg_logprob": -0.04562827131964944, "compression_ratio": 1.5490196078431373, "no_speech_prob": 0.0007553884061053395}, {"id": 257, "seek": 170080, "start": 1700.8, "end": 1706.3999999999999, "text": " point we know we can eliminate higher frequency components from the DCT but the next natural", "tokens": [50364, 935, 321, 458, 321, 393, 13819, 2946, 7893, 6677, 490, 264, 9114, 51, 457, 264, 958, 3303, 50644], "temperature": 0.0, "avg_logprob": -0.049745742664780726, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.001648429548367858}, {"id": 258, "seek": 170080, "start": 1706.3999999999999, "end": 1713.52, "text": " question is how we actually do this. The process for eliminating higher frequency components in JPEG", "tokens": [50644, 1168, 307, 577, 321, 767, 360, 341, 13, 440, 1399, 337, 31203, 2946, 7893, 6677, 294, 508, 5208, 38, 51000], "temperature": 0.0, "avg_logprob": -0.049745742664780726, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.001648429548367858}, {"id": 259, "seek": 170080, "start": 1713.52, "end": 1721.28, "text": " is called quantization. Quantization is a simple idea. Given an eight by eight matrix of frequency", "tokens": [51000, 307, 1219, 4426, 2144, 13, 26968, 2144, 307, 257, 2199, 1558, 13, 18600, 364, 3180, 538, 3180, 8141, 295, 7893, 51388], "temperature": 0.0, "avg_logprob": -0.049745742664780726, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.001648429548367858}, {"id": 260, "seek": 170080, "start": 1721.28, "end": 1727.9199999999998, "text": " coefficients from the DCT what we're going to do is basically divide each element by a scalar value", "tokens": [51388, 31994, 490, 264, 9114, 51, 437, 321, 434, 516, 281, 360, 307, 1936, 9845, 1184, 4478, 538, 257, 39684, 2158, 51720], "temperature": 0.0, "avg_logprob": -0.049745742664780726, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.001648429548367858}, {"id": 261, "seek": 172792, "start": 1727.92, "end": 1734.72, "text": " and round it to an integer. These values are defined in terms of a quantization table. Notice", "tokens": [50364, 293, 3098, 309, 281, 364, 24922, 13, 1981, 4190, 366, 7642, 294, 2115, 295, 257, 4426, 2144, 3199, 13, 13428, 50704], "temperature": 0.0, "avg_logprob": -0.03698428841524346, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0021156487055122852}, {"id": 262, "seek": 172792, "start": 1734.72, "end": 1739.8400000000001, "text": " larger values in the bottom right of the table leading to zero values in the higher frequency", "tokens": [50704, 4833, 4190, 294, 264, 2767, 558, 295, 264, 3199, 5775, 281, 4018, 4190, 294, 264, 2946, 7893, 50960], "temperature": 0.0, "avg_logprob": -0.03698428841524346, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0021156487055122852}, {"id": 263, "seek": 172792, "start": 1739.8400000000001, "end": 1747.52, "text": " components. In the decoding stage of JPEG we'll actually be multiplying this result by the same", "tokens": [50960, 6677, 13, 682, 264, 979, 8616, 3233, 295, 508, 5208, 38, 321, 603, 767, 312, 30955, 341, 1874, 538, 264, 912, 51344], "temperature": 0.0, "avg_logprob": -0.03698428841524346, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0021156487055122852}, {"id": 264, "seek": 172792, "start": 1747.52, "end": 1754.48, "text": " quantization matrix element by element and as you can see the final coefficient matrix will be quite", "tokens": [51344, 4426, 2144, 8141, 4478, 538, 4478, 293, 382, 291, 393, 536, 264, 2572, 17619, 8141, 486, 312, 1596, 51692], "temperature": 0.0, "avg_logprob": -0.03698428841524346, "compression_ratio": 1.6340425531914893, "no_speech_prob": 0.0021156487055122852}, {"id": 265, "seek": 175448, "start": 1754.48, "end": 1760.32, "text": " different from the original one. So what that means is we're purposely losing information in this step", "tokens": [50364, 819, 490, 264, 3380, 472, 13, 407, 437, 300, 1355, 307, 321, 434, 41840, 7027, 1589, 294, 341, 1823, 50656], "temperature": 0.0, "avg_logprob": -0.061289964720260263, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.010012750513851643}, {"id": 266, "seek": 175448, "start": 1761.6, "end": 1767.6, "text": " but the key idea here is most of the lower frequency components will be retained. This is", "tokens": [50720, 457, 264, 2141, 1558, 510, 307, 881, 295, 264, 3126, 7893, 6677, 486, 312, 33438, 13, 639, 307, 51020], "temperature": 0.0, "avg_logprob": -0.061289964720260263, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.010012750513851643}, {"id": 267, "seek": 175448, "start": 1767.6, "end": 1774.4, "text": " why the energy compaction property of the DCT is so useful when the largest values lie in the lowest", "tokens": [51020, 983, 264, 2281, 715, 2894, 4707, 295, 264, 9114, 51, 307, 370, 4420, 562, 264, 6443, 4190, 4544, 294, 264, 12437, 51360], "temperature": 0.0, "avg_logprob": -0.061289964720260263, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.010012750513851643}, {"id": 268, "seek": 175448, "start": 1774.4, "end": 1780.24, "text": " frequencies we will end up with a lot of zeros in the less important high frequency components.", "tokens": [51360, 20250, 321, 486, 917, 493, 365, 257, 688, 295, 35193, 294, 264, 1570, 1021, 1090, 7893, 6677, 13, 51652], "temperature": 0.0, "avg_logprob": -0.061289964720260263, "compression_ratio": 1.683982683982684, "no_speech_prob": 0.010012750513851643}, {"id": 269, "seek": 178024, "start": 1780.48, "end": 1787.76, "text": " These quantization tables are provided by the JPEG standard from visual experiments", "tokens": [50376, 1981, 4426, 2144, 8020, 366, 5649, 538, 264, 508, 5208, 38, 3832, 490, 5056, 12050, 50740], "temperature": 0.0, "avg_logprob": -0.0864100279631438, "compression_ratio": 1.732394366197183, "no_speech_prob": 0.00016864969802554697}, {"id": 270, "seek": 178024, "start": 1787.76, "end": 1794.64, "text": " and are the main way for JPEG to define quality of compression. High quality compression parameters", "tokens": [50740, 293, 366, 264, 2135, 636, 337, 508, 5208, 38, 281, 6964, 3125, 295, 19355, 13, 5229, 3125, 19355, 9834, 51084], "temperature": 0.0, "avg_logprob": -0.0864100279631438, "compression_ratio": 1.732394366197183, "no_speech_prob": 0.00016864969802554697}, {"id": 271, "seek": 178024, "start": 1794.64, "end": 1801.76, "text": " can be translated to lower quantization table values. In practice JPEG also defines a separate", "tokens": [51084, 393, 312, 16805, 281, 3126, 4426, 2144, 3199, 4190, 13, 682, 3124, 508, 5208, 38, 611, 23122, 257, 4994, 51440], "temperature": 0.0, "avg_logprob": -0.0864100279631438, "compression_ratio": 1.732394366197183, "no_speech_prob": 0.00016864969802554697}, {"id": 272, "seek": 178024, "start": 1801.76, "end": 1808.8, "text": " quantization table for both the luma and color channels. Notice that in the color channels", "tokens": [51440, 4426, 2144, 3199, 337, 1293, 264, 287, 5544, 293, 2017, 9235, 13, 13428, 300, 294, 264, 2017, 9235, 51792], "temperature": 0.0, "avg_logprob": -0.0864100279631438, "compression_ratio": 1.732394366197183, "no_speech_prob": 0.00016864969802554697}, {"id": 273, "seek": 180880, "start": 1808.8799999999999, "end": 1816.6399999999999, "text": " quantization can be even more aggressive. After performing quantization we have a matrix of quantized", "tokens": [50368, 4426, 2144, 393, 312, 754, 544, 10762, 13, 2381, 10205, 4426, 2144, 321, 362, 257, 8141, 295, 4426, 1602, 50756], "temperature": 0.0, "avg_logprob": -0.05403457685958508, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00019109592540189624}, {"id": 274, "seek": 180880, "start": 1816.6399999999999, "end": 1822.1599999999999, "text": " DCT coefficients where we can now exploit redundancy to get even more compression.", "tokens": [50756, 9114, 51, 31994, 689, 321, 393, 586, 25924, 27830, 6717, 281, 483, 754, 544, 19355, 13, 51032], "temperature": 0.0, "avg_logprob": -0.05403457685958508, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00019109592540189624}, {"id": 275, "seek": 180880, "start": 1824.0, "end": 1830.1599999999999, "text": " The last part of JPEG encoding involves a combination of run length encoding and Huffman", "tokens": [51124, 440, 1036, 644, 295, 508, 5208, 38, 43430, 11626, 257, 6562, 295, 1190, 4641, 43430, 293, 389, 1245, 1601, 51432], "temperature": 0.0, "avg_logprob": -0.05403457685958508, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00019109592540189624}, {"id": 276, "seek": 180880, "start": 1830.1599999999999, "end": 1836.8, "text": " encoding. One clever trick is that a JPEG encoder will order the coefficients in a zigzag manner", "tokens": [51432, 43430, 13, 1485, 13494, 4282, 307, 300, 257, 508, 5208, 38, 2058, 19866, 486, 1668, 264, 31994, 294, 257, 38290, 43886, 9060, 51764], "temperature": 0.0, "avg_logprob": -0.05403457685958508, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.00019109592540189624}, {"id": 277, "seek": 183680, "start": 1836.8, "end": 1843.36, "text": " to maximize the chance of a large sequence of zeros in order. Classic run length encoding can", "tokens": [50364, 281, 19874, 264, 2931, 295, 257, 2416, 8310, 295, 35193, 294, 1668, 13, 25008, 1190, 4641, 43430, 393, 50692], "temperature": 0.0, "avg_logprob": -0.02768846680136288, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0006070530507713556}, {"id": 278, "seek": 183680, "start": 1843.36, "end": 1849.6, "text": " compress this fairly easily. All that's going on here is we are compressing every sequence of zeros", "tokens": [50692, 14778, 341, 6457, 3612, 13, 1057, 300, 311, 516, 322, 510, 307, 321, 366, 14778, 278, 633, 8310, 295, 35193, 51004], "temperature": 0.0, "avg_logprob": -0.02768846680136288, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0006070530507713556}, {"id": 279, "seek": 183680, "start": 1849.6, "end": 1855.76, "text": " into a count of the occurrences in a continuous sequence. JPEG actually performs something a", "tokens": [51004, 666, 257, 1207, 295, 264, 5160, 38983, 294, 257, 10957, 8310, 13, 508, 5208, 38, 767, 26213, 746, 257, 51312], "temperature": 0.0, "avg_logprob": -0.02768846680136288, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0006070530507713556}, {"id": 280, "seek": 183680, "start": 1855.76, "end": 1861.9199999999998, "text": " little bit more sophisticated by keeping track of a triplet. For every coefficient this triplet", "tokens": [51312, 707, 857, 544, 16950, 538, 5145, 2837, 295, 257, 1376, 14657, 13, 1171, 633, 17619, 341, 1376, 14657, 51620], "temperature": 0.0, "avg_logprob": -0.02768846680136288, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0006070530507713556}, {"id": 281, "seek": 186192, "start": 1861.92, "end": 1867.68, "text": " encodes the number of preceding zeros, the number of bits required to encode the coefficient,", "tokens": [50364, 2058, 4789, 264, 1230, 295, 16969, 278, 35193, 11, 264, 1230, 295, 9239, 4739, 281, 2058, 1429, 264, 17619, 11, 50652], "temperature": 0.0, "avg_logprob": -0.05704893224379596, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.000626326072961092}, {"id": 282, "seek": 186192, "start": 1867.68, "end": 1874.0800000000002, "text": " and finally the actual coefficient value. We also have an end of block value to signal that", "tokens": [50652, 293, 2721, 264, 3539, 17619, 2158, 13, 492, 611, 362, 364, 917, 295, 3461, 2158, 281, 6358, 300, 50972], "temperature": 0.0, "avg_logprob": -0.05704893224379596, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.000626326072961092}, {"id": 283, "seek": 186192, "start": 1874.0800000000002, "end": 1883.1200000000001, "text": " everything from here on out will be zeros. This particular scheme works well with Huffman", "tokens": [50972, 1203, 490, 510, 322, 484, 486, 312, 35193, 13, 639, 1729, 12232, 1985, 731, 365, 389, 1245, 1601, 51424], "temperature": 0.0, "avg_logprob": -0.05704893224379596, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.000626326072961092}, {"id": 284, "seek": 186192, "start": 1883.1200000000001, "end": 1890.16, "text": " coding to further exploit redundancy. The big idea of Huffman codes is that more frequently", "tokens": [51424, 17720, 281, 3052, 25924, 27830, 6717, 13, 440, 955, 1558, 295, 389, 1245, 1601, 14211, 307, 300, 544, 10374, 51776], "temperature": 0.0, "avg_logprob": -0.05704893224379596, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.000626326072961092}, {"id": 285, "seek": 189016, "start": 1890.24, "end": 1897.0400000000002, "text": " used data can be encoded with fewer bits, and it turns out especially with the nature of quantization,", "tokens": [50368, 1143, 1412, 393, 312, 2058, 12340, 365, 13366, 9239, 11, 293, 309, 4523, 484, 2318, 365, 264, 3687, 295, 4426, 2144, 11, 50708], "temperature": 0.0, "avg_logprob": -0.07319235550729852, "compression_ratio": 1.588, "no_speech_prob": 0.004069932270795107}, {"id": 286, "seek": 189016, "start": 1897.0400000000002, "end": 1902.24, "text": " these triplets can be further compressed since some of these values will be more frequent than others.", "tokens": [50708, 613, 1376, 31023, 393, 312, 3052, 30353, 1670, 512, 295, 613, 4190, 486, 312, 544, 18004, 813, 2357, 13, 50968], "temperature": 0.0, "avg_logprob": -0.07319235550729852, "compression_ratio": 1.588, "no_speech_prob": 0.004069932270795107}, {"id": 287, "seek": 189016, "start": 1904.0, "end": 1909.44, "text": " However, I'm purposefully not going to go into the details of how JPEG uses Huffman codes to", "tokens": [51056, 2908, 11, 286, 478, 4334, 2277, 406, 516, 281, 352, 666, 264, 4365, 295, 577, 508, 5208, 38, 4960, 389, 1245, 1601, 14211, 281, 51328], "temperature": 0.0, "avg_logprob": -0.07319235550729852, "compression_ratio": 1.588, "no_speech_prob": 0.004069932270795107}, {"id": 288, "seek": 189016, "start": 1909.44, "end": 1915.28, "text": " compress the data because it really does get quite tricky. To give you some sense of the problems,", "tokens": [51328, 14778, 264, 1412, 570, 309, 534, 775, 483, 1596, 12414, 13, 1407, 976, 291, 512, 2020, 295, 264, 2740, 11, 51620], "temperature": 0.0, "avg_logprob": -0.07319235550729852, "compression_ratio": 1.588, "no_speech_prob": 0.004069932270795107}, {"id": 289, "seek": 191528, "start": 1915.28, "end": 1920.32, "text": " we have to deal with the encoding signs of coefficients as well as triplets for all eight", "tokens": [50364, 321, 362, 281, 2028, 365, 264, 43430, 7880, 295, 31994, 382, 731, 382, 1376, 31023, 337, 439, 3180, 50616], "temperature": 0.0, "avg_logprob": -0.08568885109641335, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.003824128769338131}, {"id": 290, "seek": 191528, "start": 1920.32, "end": 1927.12, "text": " by eight blocks. Most encoders also encode the top left coefficient separate from all the other", "tokens": [50616, 538, 3180, 8474, 13, 4534, 2058, 378, 433, 611, 2058, 1429, 264, 1192, 1411, 17619, 4994, 490, 439, 264, 661, 50956], "temperature": 0.0, "avg_logprob": -0.08568885109641335, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.003824128769338131}, {"id": 291, "seek": 191528, "start": 1927.12, "end": 1933.36, "text": " coefficients. And when you handle that, you have to deal with this on both luma and color channels.", "tokens": [50956, 31994, 13, 400, 562, 291, 4813, 300, 11, 291, 362, 281, 2028, 365, 341, 322, 1293, 287, 5544, 293, 2017, 9235, 13, 51268], "temperature": 0.0, "avg_logprob": -0.08568885109641335, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.003824128769338131}, {"id": 292, "seek": 191528, "start": 1934.32, "end": 1938.72, "text": " And when you eventually get that working, a good chunk of your logic will break when you", "tokens": [51316, 400, 562, 291, 4728, 483, 300, 1364, 11, 257, 665, 16635, 295, 428, 9952, 486, 1821, 562, 291, 51536], "temperature": 0.0, "avg_logprob": -0.08568885109641335, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.003824128769338131}, {"id": 293, "seek": 191528, "start": 1938.72, "end": 1944.48, "text": " have to deal with the different types of chroma subsampling. Implementing an optimized fully", "tokens": [51536, 362, 281, 2028, 365, 264, 819, 3467, 295, 16209, 64, 2090, 335, 11970, 13, 4331, 43704, 278, 364, 26941, 4498, 51824], "temperature": 0.0, "avg_logprob": -0.08568885109641335, "compression_ratio": 1.810077519379845, "no_speech_prob": 0.003824128769338131}, {"id": 294, "seek": 194448, "start": 1944.48, "end": 1950.64, "text": " functional JPEG encoder and decoder is no joke. I wouldn't give that task to even my worst enemies.", "tokens": [50364, 11745, 508, 5208, 38, 2058, 19866, 293, 979, 19866, 307, 572, 7647, 13, 286, 2759, 380, 976, 300, 5633, 281, 754, 452, 5855, 7805, 13, 50672], "temperature": 0.0, "avg_logprob": -0.04810859217788234, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0014102896675467491}, {"id": 295, "seek": 194448, "start": 1951.84, "end": 1956.72, "text": " But in terms of the big picture, all that's going on in this component is taking advantage", "tokens": [50732, 583, 294, 2115, 295, 264, 955, 3036, 11, 439, 300, 311, 516, 322, 294, 341, 6542, 307, 1940, 5002, 50976], "temperature": 0.0, "avg_logprob": -0.04810859217788234, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0014102896675467491}, {"id": 296, "seek": 194448, "start": 1956.72, "end": 1963.92, "text": " of the redundancy that quantization creates. A JPEG decoder will be able to use the Huffman code", "tokens": [50976, 295, 264, 27830, 6717, 300, 4426, 2144, 7829, 13, 316, 508, 5208, 38, 979, 19866, 486, 312, 1075, 281, 764, 264, 389, 1245, 1601, 3089, 51336], "temperature": 0.0, "avg_logprob": -0.04810859217788234, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0014102896675467491}, {"id": 297, "seek": 194448, "start": 1963.92, "end": 1970.72, "text": " data in the files to get back all quantized DCT coefficients that were encoded. This part", "tokens": [51336, 1412, 294, 264, 7098, 281, 483, 646, 439, 4426, 1602, 9114, 51, 31994, 300, 645, 2058, 12340, 13, 639, 644, 51676], "temperature": 0.0, "avg_logprob": -0.04810859217788234, "compression_ratio": 1.5643153526970954, "no_speech_prob": 0.0014102896675467491}, {"id": 298, "seek": 197072, "start": 1970.72, "end": 1979.6000000000001, "text": " of the JPEG algorithm does not lose any information. JPEG as a whole brings about an interesting", "tokens": [50364, 295, 264, 508, 5208, 38, 9284, 775, 406, 3624, 604, 1589, 13, 508, 5208, 38, 382, 257, 1379, 5607, 466, 364, 1880, 50808], "temperature": 0.0, "avg_logprob": -0.05577537070873172, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0017545076552778482}, {"id": 299, "seek": 197072, "start": 1979.6000000000001, "end": 1985.6000000000001, "text": " discussion on the philosophy of data compression. The classic and most straightforward way to", "tokens": [50808, 5017, 322, 264, 10675, 295, 1412, 19355, 13, 440, 7230, 293, 881, 15325, 636, 281, 51108], "temperature": 0.0, "avg_logprob": -0.05577537070873172, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0017545076552778482}, {"id": 300, "seek": 197072, "start": 1985.6000000000001, "end": 1992.24, "text": " compress data is by taking advantage of redundancy. This is the basis of losses image compression", "tokens": [51108, 14778, 1412, 307, 538, 1940, 5002, 295, 27830, 6717, 13, 639, 307, 264, 5143, 295, 15352, 3256, 19355, 51440], "temperature": 0.0, "avg_logprob": -0.05577537070873172, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0017545076552778482}, {"id": 301, "seek": 197072, "start": 1992.24, "end": 1998.88, "text": " algorithms such as those found in PNG file formats. In fact, for images where it's really important", "tokens": [51440, 14642, 1270, 382, 729, 1352, 294, 430, 30237, 3991, 25879, 13, 682, 1186, 11, 337, 5267, 689, 309, 311, 534, 1021, 51772], "temperature": 0.0, "avg_logprob": -0.05577537070873172, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.0017545076552778482}, {"id": 302, "seek": 199888, "start": 1998.88, "end": 2005.68, "text": " not to lose any information, PNG format is recommended over JPEG. But on most real world", "tokens": [50364, 406, 281, 3624, 604, 1589, 11, 430, 30237, 7877, 307, 9628, 670, 508, 5208, 38, 13, 583, 322, 881, 957, 1002, 50704], "temperature": 0.0, "avg_logprob": -0.051209825277328494, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0018100853776559234}, {"id": 303, "seek": 199888, "start": 2005.68, "end": 2011.5200000000002, "text": " images, being aware of the medium of presentation introduces another really powerful perspective.", "tokens": [50704, 5267, 11, 885, 3650, 295, 264, 6399, 295, 5860, 31472, 1071, 534, 4005, 4585, 13, 50996], "temperature": 0.0, "avg_logprob": -0.051209825277328494, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0018100853776559234}, {"id": 304, "seek": 199888, "start": 2012.64, "end": 2017.7600000000002, "text": " A lot of innovation in JPEG compression comes from experiments and understanding of human", "tokens": [51052, 316, 688, 295, 8504, 294, 508, 5208, 38, 19355, 1487, 490, 12050, 293, 3701, 295, 1952, 51308], "temperature": 0.0, "avg_logprob": -0.051209825277328494, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0018100853776559234}, {"id": 305, "seek": 199888, "start": 2017.7600000000002, "end": 2023.44, "text": " visual systems. It's from these experiments that we realized human eyes are less sensitive to color", "tokens": [51308, 5056, 3652, 13, 467, 311, 490, 613, 12050, 300, 321, 5334, 1952, 2575, 366, 1570, 9477, 281, 2017, 51592], "temperature": 0.0, "avg_logprob": -0.051209825277328494, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0018100853776559234}, {"id": 306, "seek": 202344, "start": 2023.44, "end": 2028.56, "text": " and also less sensitive to higher frequencies. So we can remove that information without a", "tokens": [50364, 293, 611, 1570, 9477, 281, 2946, 20250, 13, 407, 321, 393, 4159, 300, 1589, 1553, 257, 50620], "temperature": 0.0, "avg_logprob": -0.05107751488685608, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0017006078269332647}, {"id": 307, "seek": 202344, "start": 2028.56, "end": 2036.0800000000002, "text": " significant visual impact. This is why JPEG is so much more effective at compressing images than", "tokens": [50620, 4776, 5056, 2712, 13, 639, 307, 983, 508, 5208, 38, 307, 370, 709, 544, 4942, 412, 14778, 278, 5267, 813, 50996], "temperature": 0.0, "avg_logprob": -0.05107751488685608, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0017006078269332647}, {"id": 308, "seek": 202344, "start": 2036.0800000000002, "end": 2042.56, "text": " lossless formats. You'll find these same types of techniques used in audio and video compression", "tokens": [50996, 4470, 1832, 25879, 13, 509, 603, 915, 613, 912, 3467, 295, 7512, 1143, 294, 6278, 293, 960, 19355, 51320], "temperature": 0.0, "avg_logprob": -0.05107751488685608, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0017006078269332647}, {"id": 309, "seek": 202344, "start": 2042.56, "end": 2048.64, "text": " where algorithms use our perceptions of sound and motion respectively to remove less relevant data.", "tokens": [51320, 689, 14642, 764, 527, 35258, 295, 1626, 293, 5394, 25009, 281, 4159, 1570, 7340, 1412, 13, 51624], "temperature": 0.0, "avg_logprob": -0.05107751488685608, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.0017006078269332647}, {"id": 310, "seek": 204864, "start": 2049.52, "end": 2054.56, "text": " In fact, variations of the discrete cosine transform and quantization show up in both", "tokens": [50408, 682, 1186, 11, 17840, 295, 264, 27706, 23565, 4088, 293, 4426, 2144, 855, 493, 294, 1293, 50660], "temperature": 0.0, "avg_logprob": -0.05214744522458031, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.006903022062033415}, {"id": 311, "seek": 204864, "start": 2054.56, "end": 2061.44, "text": " audio and video compression. It really is incredible to me how people in these fields came up with the", "tokens": [50660, 6278, 293, 960, 19355, 13, 467, 534, 307, 4651, 281, 385, 577, 561, 294, 613, 7909, 1361, 493, 365, 264, 51004], "temperature": 0.0, "avg_logprob": -0.05214744522458031, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.006903022062033415}, {"id": 312, "seek": 204864, "start": 2061.44, "end": 2067.52, "text": " mathematical and algorithmic framework to utilize the way we actually perceive the digital technology", "tokens": [51004, 18894, 293, 9284, 299, 8388, 281, 16117, 264, 636, 321, 767, 20281, 264, 4562, 2899, 51308], "temperature": 0.0, "avg_logprob": -0.05214744522458031, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.006903022062033415}, {"id": 313, "seek": 204864, "start": 2067.52, "end": 2073.7599999999998, "text": " around us. There's so much depth to these topics that I can never hope to cover in just one video,", "tokens": [51308, 926, 505, 13, 821, 311, 370, 709, 7161, 281, 613, 8378, 300, 286, 393, 1128, 1454, 281, 2060, 294, 445, 472, 960, 11, 51620], "temperature": 0.0, "avg_logprob": -0.05214744522458031, "compression_ratio": 1.5685483870967742, "no_speech_prob": 0.006903022062033415}, {"id": 314, "seek": 207376, "start": 2073.76, "end": 2078.96, "text": " but I do hope this gives you a sense and appreciation for the complexity of the technology", "tokens": [50364, 457, 286, 360, 1454, 341, 2709, 291, 257, 2020, 293, 18909, 337, 264, 14024, 295, 264, 2899, 50624], "temperature": 0.0, "avg_logprob": -0.116697591284047, "compression_ratio": 1.3925925925925926, "no_speech_prob": 0.02194071374833584}, {"id": 315, "seek": 207376, "start": 2078.96, "end": 2087.5200000000004, "text": " around us that we use on a daily basis. Thanks for watching and I'll see you all in the next one.", "tokens": [50624, 926, 505, 300, 321, 764, 322, 257, 5212, 5143, 13, 2561, 337, 1976, 293, 286, 603, 536, 291, 439, 294, 264, 958, 472, 13, 51052], "temperature": 0.0, "avg_logprob": -0.116697591284047, "compression_ratio": 1.3925925925925926, "no_speech_prob": 0.02194071374833584}], "language": "en"}