WEBVTT

00:00.000 --> 00:05.200
What you see here is one part of a really elaborate process that defines the universally

00:05.200 --> 00:12.160
used JPEG image compression format. JPEG is rather complex and in this video the majority

00:12.160 --> 00:17.200
of the focus will be on understanding how computer scientists came up with an algorithmic

00:17.200 --> 00:22.160
and mathematical framework for solving the complex problems that image compression presents.

00:23.200 --> 00:28.720
But to understand the motivation behind the ideas in JPEG we'll have to dive into the inner

00:28.720 --> 00:33.920
workings of the many components involved. The perspectives we'll take will be a little bit

00:33.920 --> 00:39.120
unorthodox but my hope is that you come away with a better understanding of the big themes

00:39.120 --> 00:44.880
in image compression which apply to other compression related problems. It's not an

00:44.880 --> 00:50.880
exaggeration to say that these concepts are used every time you open an image, play a video or

00:50.880 --> 00:56.800
listen to some music. As we go through JPEG we'll interact with the wide variety of beautiful ideas

00:56.800 --> 01:02.000
in the world of data compression and signal processing that make the technology around us

01:02.000 --> 01:10.000
possible. Before we dive into JPEG let's talk about how computers represent images. The standard

01:10.000 --> 01:16.960
color space that computers use is the RGB model. Every pixel of an image stores three values from

01:16.960 --> 01:22.240
0 to 255 with higher values representing a larger weighting of the respective color.

01:22.800 --> 01:29.280
So assuming each color component is expressed in 8 bits or a single byte of memory an image has

01:29.280 --> 01:37.280
3 bytes per pixel. Here's an image with a little more than 5 million pixels. Based on our assumptions

01:37.280 --> 01:44.400
the total size of this image should be about 15 megabytes but with JPEG compression the actual

01:44.640 --> 01:54.640
file is only 0.8 megabytes. Same number of pixels but 5% of the expected size and the image looks

01:54.640 --> 02:03.040
absolutely beautiful. This is the real magic of JPEG compression. JPEG aggressively takes advantage

02:03.040 --> 02:08.880
of several clever ideas to achieve seemingly ridiculous amounts of compression with minimal

02:09.600 --> 02:15.920
effects on the quality of the original image. One of the primary reasons JPEG works so well

02:15.920 --> 02:22.080
is it uses lossy compression. To understand what that means let's think about compression from a

02:22.080 --> 02:28.960
big picture perspective. We start with an RGB representation of an image and then we encode

02:28.960 --> 02:35.760
it using a compression algorithm. This is what we store in memory and it's more compact but quite

02:35.760 --> 02:42.720
different than our original RGB representation. So part of a compression scheme requires also

02:42.720 --> 02:49.760
defining a decoding component that converts the stored representation of our data into the RGB

02:49.760 --> 02:56.480
format that a computer can render as an image. Part of the JPEG standard is defining how both

02:56.480 --> 03:03.600
the encoding and decoding work. A key point in JPEG is that the final decoded image is not going

03:03.600 --> 03:10.880
to be the same as the original uncompressed image. That's why we call it lossy compression. In the

03:10.880 --> 03:17.440
compression part of the pipeline we are going to deliberately lose information. To get compression

03:17.440 --> 03:23.200
on the levels of 5% there's really no other option other than to actually discard some

03:23.200 --> 03:30.240
information from our original image. Now the fun question to ask is what sort of information

03:30.240 --> 03:36.960
from an image can we get rid of and how do we get rid of it? Answering this question is going to be

03:36.960 --> 03:43.760
the primary focus of our journey into understanding JPEG. Here's an interesting image for you. If I

03:43.760 --> 03:49.360
were to ask you what colors the squares of A and B were I imagine most of you would quickly say that

03:49.360 --> 03:55.840
A is a darker shade of gray than B. But what if I told you that A and B were actually the same color?

03:56.640 --> 04:02.160
It's okay if you don't see that. This picture is designed to trick our visual system. But once

04:02.160 --> 04:07.760
we have a connector of the common color between the two squares it's much easier for us to see

04:07.760 --> 04:14.480
that they are in fact the same color. So what's going on here? Over the years scientists have

04:14.480 --> 04:20.000
developed a human visual system model through the study of our eyes and one incredibly interesting

04:20.000 --> 04:25.840
finding through experimentation is that our eyes are much more sensitive to brightness than they

04:25.840 --> 04:32.960
are to colors. And part of the JPEG compression scheme can take advantage of this. But to understand

04:32.960 --> 04:40.880
how we have to dive into the world of color spaces. As we've discussed the RGB color space is a

04:40.880 --> 04:46.400
combination of red, green, and blue color components. If we put each value on a separate

04:46.400 --> 04:52.320
axis in a three-dimensional space we can see how all the possible colors are just a point on this

04:52.320 --> 04:58.880
cube. One aspect of RGB color space is as you progress on the diagonal from the origin to the

04:58.880 --> 05:07.440
color 255, 255, 255 you get gradually brighter colors. And in fact the exact line between these

05:07.440 --> 05:12.400
points defines all possible gray scale colors which are a direct measure for brightness.

05:13.120 --> 05:20.720
This idea of separating brightness is core to another color space called YCBCR. YCBCR

05:20.720 --> 05:26.640
stands for Y, chroma blue, and chroma red. Our Y component is going to measure the luma or brightness

05:26.640 --> 05:32.720
of an image and our CB and CR components are going to encode the colors. If we look at the

05:32.720 --> 05:38.800
color space the Y can be thought of as a single vertical axis with larger values encoding more

05:38.800 --> 05:46.400
brightness. Every cross section of the space defines a range of colors at that particular

05:46.400 --> 05:53.040
brightness. For our purposes with JPEG using the color space gives us direct access to the part

05:53.040 --> 05:59.600
of color that our eyes perceive best. As a result of being more sensitive to brightness than colors

05:59.600 --> 06:06.480
one idea to compress our original image involves sampling less of the CBCR components and keeping

06:06.480 --> 06:12.480
all of the luma components. The technique is referred to as chroma down sampling or more commonly

06:12.480 --> 06:20.800
chroma subsampling. Suppose I have this 8x8 image which has the following Y, CB, and CR components.

06:20.800 --> 06:26.640
The key idea of chroma down sampling or subsampling is to take fewer samples from CB

06:26.640 --> 06:31.600
and CR components since their eyes are less sensitive to them. Here's one approach that

06:31.600 --> 06:40.800
defines a 4-2-0 chroma down sampling scheme. We go through our original 8x8 image in 2x2 blocks

06:40.800 --> 06:46.480
and simply average the group of pixels to get a shared value of the four pixels in the original

06:46.480 --> 06:51.360
image. Averaging the pixels by the way is all down sampling really means.

06:53.600 --> 06:59.600
Chroma subsampling is the same exact idea but instead of averaging we just choose one of the

06:59.600 --> 07:04.880
samples usually the top left pixel to be the color of the entire 2x2 block.

07:09.120 --> 07:14.640
Once we have these fewer samples from the color components we can merge them with the luma component

07:14.640 --> 07:20.400
which will retain the original 16 pixels and this gives us our subsampled image.

07:20.400 --> 07:26.640
In this case you can see quite a difference since our 8x8 pixel image is significantly scaled up

07:26.720 --> 07:31.920
but in real world images it's often hard to see any changes after subsampling.

07:33.200 --> 07:39.360
By merging 2x2 blocks on the CB and CR channels into one color we are left with a quarter of the

07:39.360 --> 07:46.640
original data in each color channel shrinking the total file size by 50%. We're still quite far from

07:46.640 --> 07:53.200
the 5% levels that we saw in JPEG so we're going to have to exploit more than just human perception

07:53.200 --> 08:00.480
of brightness. For the following components of JPEG let's focus on the Y channel which

08:00.480 --> 08:06.000
essentially defines grayscale images. The principles we'll discuss from here on out

08:06.000 --> 08:12.560
will also apply to the color components of an image. The next clever idea in JPEG requires

08:12.560 --> 08:17.520
looking at images in a completely different perspective, one that can be a little bit

08:17.520 --> 08:24.480
counterintuitive. One way to think about images is treating them as signals. If I slice a particular

08:24.480 --> 08:31.280
row of an image I essentially have a row of pixels each with some value between 0 and 255.

08:32.240 --> 08:38.800
If we plot these values we can get an approximation of a signal. Visualizing an image as a signal

08:38.800 --> 08:44.320
allows us to talk about frequency components within an image. Higher frequency components

08:44.320 --> 08:50.400
correspond to rapid changes between pixels while lower frequency components are related to smoother

08:50.400 --> 08:56.640
changes between pixels. There are two key aspects of frequencies within images that are incredibly

08:56.640 --> 09:02.800
important to JPEG compression. The first is that a lot of real world images shot from cameras are

09:02.800 --> 09:08.640
mostly composed of lower frequency components. In other words if I take a random portion of a

09:08.640 --> 09:14.160
realistic image it's pretty likely that the pixels in that area do not change that rapidly.

09:14.960 --> 09:21.120
And the second key fact is that from a variety of experiments the human visual system is generally

09:21.120 --> 09:27.680
less sensitive to higher frequency detail in images. JPEG takes advantage of these ideas by

09:27.680 --> 09:33.760
strategically removing less important and less common higher frequency components from an image

09:33.760 --> 09:41.760
to achieve even more compression. But there's one big problem. How do we get frequency components

09:41.760 --> 09:47.760
from an image? This is where some particularly clever and beautiful math comes into play.

09:47.760 --> 09:53.920
The answer to this question lies in a special operation called the discrete cosine transform

09:53.920 --> 10:01.920
or the DCT. The DCT works for any size input but to simplify things let's focus on an input

10:01.920 --> 10:08.720
of eight pixels. Just as we did earlier let's suppose these eight pixels form some sort of signal.

10:09.440 --> 10:14.480
We'll never be sure what exactly the signal looks like since we only have eight points

10:15.040 --> 10:22.400
but the clever and definitely not obvious idea of the DCT is to represent these eight points as

10:22.400 --> 10:29.360
sums of sampled points from cosine waves. And I really want to emphasize the fact that we only

10:29.360 --> 10:35.760
care about the discrete samples. Visually I think it's nice to see the continuous signals and cosine

10:35.760 --> 10:42.000
waves but throughout a discussion the only values that really matter are the sampled points from

10:42.000 --> 10:49.680
these functions. The DCT takes an input of sampled points from our original signal and gives us an

10:49.680 --> 10:58.800
output of the same size. We'll refer to the outputs of the DCT as coefficients. These coefficients

10:58.800 --> 11:04.960
represent the weights of cosine waves of different frequencies that contribute to the original signal.

11:06.000 --> 11:12.800
A nice analogy is to think of this as unraveling a complex signal into a weighted sum of simpler

11:12.800 --> 11:19.440
cosine waves. If you've never interacted with this type of idea before it's natural to be confused.

11:20.560 --> 11:26.560
What cosine waves do we even use? How do cosine waves relate to pixels on an image?

11:27.520 --> 11:33.200
None of it makes any sense. Don't worry these are important questions that we will answer.

11:35.360 --> 11:42.400
Let's start simple and talk about cosine waves. Here's a graph of cosine from zero to pi. I've

11:42.400 --> 11:47.680
given you this general notion that the DCT is supposed to tell us how much of a specific

11:47.680 --> 11:55.600
cosine wave is contained in a signal. So let's test this out. What happens if I provide an

11:55.600 --> 12:01.520
actual cosine wave as the input signal to the DCT? What do we expect to happen?

12:02.720 --> 12:08.720
Okay we can try this but there's a problem. To follow our existing example we need eight

12:08.720 --> 12:14.960
sampled points from the cosine wave to make this work. How exactly should we sample the cosine wave?

12:15.600 --> 12:21.200
Well there are a few options but let me present to you the most common one. What we can do is

12:21.200 --> 12:27.760
split our cosine waves domain into eight even slices and then we take the midpoint of each of

12:27.760 --> 12:34.560
these slices. This gives us the following input points which we can generalize for any number of

12:34.560 --> 12:44.240
points. But for our purposes we'll stick with the smaller n equals 8 example. So going back to our

12:44.240 --> 12:50.480
question what should we expect the output to be when we pass in sampled points from a standard

12:50.480 --> 12:58.960
cosine function? This is an interesting experiment. When we pass these points from a cosine wave into

12:58.960 --> 13:06.800
a DCT transform we get the following output. Only one coefficient has a nonzero value meaning

13:06.800 --> 13:13.440
there's only one cosine wave that contributes to our input. And that seems to make some sense since

13:13.440 --> 13:20.400
the input is literally from a cosine wave. In this case the first index is the only coefficient

13:20.400 --> 13:27.040
with a nonzero value. When trying to understand complex ideas it really helps to play around

13:27.040 --> 13:32.560
with these simple examples. A cool follow-up to our experiment is to see what happens when

13:32.560 --> 13:39.440
we change the amplitude of this cosine wave. The first index DCT coefficient increases.

13:40.080 --> 13:45.600
If we flip the cosine wave by multiplying negative one the DCT coefficient changes sign.

13:46.560 --> 13:53.280
It's exactly acting like a weight for a cosine wave. When the amplitude of the input cosine

13:53.280 --> 14:01.520
wave changes the weight correspondingly reflects that change. So taking a step back

14:01.520 --> 14:08.480
how does this relate to images? Well just as we took images and represented them as signals

14:08.480 --> 14:15.920
the reverse also works. Standard grayscale images have pixels ranging from 0 to 255.

14:16.560 --> 14:22.320
The intuition with cosine waves to images makes more sense when we shift the range of pixel values

14:22.320 --> 14:30.160
by 128. With pixel values from negative 128 to 127 we can see a better mapping between this

14:30.160 --> 14:36.640
cosine wave to an actual set of eight pixels. This particular wave is a nice way to represent

14:36.640 --> 14:43.120
a row of gradually decreasing pixel values. And the magnitude of that change as well as the

14:43.120 --> 14:49.840
direction of the change is reflected in the amplitude of the original cosine wave and consequently

14:49.840 --> 14:56.080
the DCT coefficient. So let's continue this experiment to see what else we can uncover

14:56.080 --> 15:01.920
about the DCT. We've messed with the amplitude of a cosine wave. What other parameters could we

15:01.920 --> 15:09.760
change? A simple one is to just shift the cosine wave up or down. Let's see what happens when we

15:09.760 --> 15:17.440
try that. It looks like shifting up or down the signal only affects the zeroth index coefficient.

15:18.320 --> 15:23.520
That's an interesting data point that we'll come back to. Another parameter of cosine waves

15:23.520 --> 15:29.840
is the frequency. What we're going to do now is show the DCT coefficients as we wind up the

15:29.840 --> 15:36.080
frequency of this cosine wave. I'll keep the sampling strategy we discussed earlier consistent

15:36.080 --> 15:43.040
among all frequencies. Let's see what happens. As we increase the frequencies we get a few

15:43.040 --> 15:49.920
different DCT coefficients for the respective cosine wave. That is until we get to this cosine wave.

15:50.560 --> 15:55.840
For this particular cosine wave only the second index has a non-zero coefficient.

15:55.840 --> 16:02.880
This cosine wave is actually just double the frequency of the previous cosine wave. This is

16:02.880 --> 16:09.760
super interesting. The first index of the output seems to nicely correspond with the cosine wave

16:09.760 --> 16:15.760
of frequency one while the second index correlates with a cosine wave of frequency two.

16:17.280 --> 16:22.480
Let's continue this experiment of increasing frequencies but before I continue see if you

16:22.480 --> 16:27.840
can take a guess at what frequencies the other coefficients will correspond to. Here we go.

16:28.400 --> 16:34.800
We slowly increase the frequency and boom the index three coefficient corresponds to a cosine

16:34.800 --> 16:42.800
wave of frequency three. Then frequency four comes next and this pattern continues until we get to a

16:42.800 --> 16:51.360
cosine wave of frequency seven. Pretty insane right? So for the coefficients indexed one to seven

16:51.360 --> 16:58.000
it looks like they represent the weight on a cosine wave with the frequency that matches the index.

17:00.000 --> 17:05.840
So what about the remaining index zero? We saw shifting cosine waves up and down led to a change

17:05.840 --> 17:12.800
in the zeroth index. What cosine wave does that represent? Some of you have probably figured it

17:12.800 --> 17:18.880
out but if you think about what a zero frequency cosine wave is it's just a constant signal.

17:19.840 --> 17:25.600
What that means in terms of images is it gives us a measure of the overall brightness of a set of

17:25.600 --> 17:33.760
pixels. Brighter images will have a larger zeroth coefficient than darker images. This is why shifting

17:33.760 --> 17:40.640
up a cosine wave only impacts the zeroth coefficient. Putting this all together each

17:40.640 --> 17:46.880
of these frequencies correspond to a different pattern of images and what the core DCT does

17:46.880 --> 17:52.320
is break down how each of these fundamental patterns contribute to the original image.

17:53.600 --> 18:00.400
And it turns out that all possible combinations of eight pixel values can be represented as a sum

18:00.400 --> 18:07.360
of these eight cosine waves. Why that's true is not at all obvious but we can begin to understand it

18:07.360 --> 18:14.960
once we translate this intuition to the actual math behind the DCT. If you look at the mathematical

18:14.960 --> 18:21.520
definition of the DCT we usually have a vector definition of the original signal and the output

18:21.520 --> 18:29.200
coefficients. We want to define the kth index of the coefficient vector mathematically. What you

18:29.200 --> 18:35.360
often see is something that looks like the following and with the intuition that we just built up

18:35.360 --> 18:41.840
we'll see that this equation is doing exactly what we want. Let's start with the cosine term.

18:41.840 --> 18:48.000
This function should be familiar. It's the exact representation of a sampled point from a cosine

18:48.000 --> 18:53.120
wave using our earlier sampling scheme and it incorporates the frequency of the cosine wave

18:53.120 --> 19:00.400
as well. Now what's interesting is in order to get the kth index we are actually summing over a

19:00.400 --> 19:06.880
product of each sampled point with samples from the cosine wave. Why does that make sense?

19:07.840 --> 19:12.640
This type of expression might look vaguely familiar to a lot of you. Let me rewrite this

19:12.640 --> 19:18.480
another way. We know that the original signal points can be represented as a vector but what

19:18.480 --> 19:24.800
if we rewrote the sampled points from the cosine wave as a vector as well? What does this expression

19:24.800 --> 19:32.320
mean in the context of these two vectors? It's a dot product and what we know about dot products is

19:32.400 --> 19:39.520
there a nice way to measure similarity between two vectors. That's why when we pass in sampled

19:39.520 --> 19:47.200
points from a cosine wave of frequency k as the input to the DCT we got large values at the kth

19:47.200 --> 19:53.840
index coefficient. These two vectors were just scaled versions of each other so the dot product

19:53.840 --> 20:00.080
was maximized and this perspective reveals what I think is truly the most surprising and elegant

20:00.080 --> 20:07.280
part of the DCT. By picking the points through the sampling method we can think of the entire DCT

20:07.280 --> 20:14.080
as a matrix vector product. All we're doing here is a linear transformation. The rows of the matrix

20:14.080 --> 20:19.280
are the sampled points from the cosine waves of the respective frequencies and what's truly

20:19.280 --> 20:25.680
astounding is that all row vectors in this matrix are orthogonal to each other. What I mean by that

20:25.680 --> 20:31.920
is if you take the dot product of any two row vectors representing cosine waves you will get

20:31.920 --> 20:38.880
zero if they are different rows of the matrix. Intuitively this is why in our earlier experiments

20:38.880 --> 20:46.000
when we pass in a cosine wave of a particular frequency as an input into the DCT we didn't get

20:46.000 --> 20:52.240
a contribution from any of the other coefficients which represented different frequency cosine waves.

20:52.880 --> 20:58.800
The orthogonality of the sampled points from different cosine waves generates this behavior.

20:59.360 --> 21:05.600
It's really quite beautiful. Another great property of the DCT that follows from these

21:05.600 --> 21:12.320
facts is invertibility. I've talked about the DCT as a way of decomposing a signal into a

21:12.320 --> 21:18.880
coefficient representation of weights associated with cosine waves. We can also reverse this process.

21:19.680 --> 21:25.040
If I take my coefficient representation of the signal I can apply what's called the inverse

21:25.040 --> 21:33.440
DCT to get back the original signal and it is the exact same signal. No information is lost

21:33.440 --> 21:40.080
in this step. How we do that is by multiplying our coefficient representation with the inverse

21:40.080 --> 21:46.640
of the matrix. What's cool about this is that because of the orthogonality of the vectors

21:46.640 --> 21:52.960
the inverse is just the transpose of our original matrix with some additional normalization constants.

21:54.800 --> 22:01.200
Now there's a super nice interpretation of the inverse DCT. The sample cosine wave points are

22:01.200 --> 22:07.200
now column vectors so what the inverse DCT is doing is essentially summing over a weighted

22:07.200 --> 22:13.600
combination of cosine waves directly to get the original signal. And because these columns are

22:13.600 --> 22:19.360
orthogonal to each other that's what allows us to represent any set of eight points with these

22:19.360 --> 22:25.680
eight cosine waves. Absolutely incredible. I know we spent some time and went through some fairly

22:25.680 --> 22:31.360
complex math to get here but it's precisely these details that are the most fundamental part of not

22:31.360 --> 22:39.040
only the DCT but many other similar transforms in the world of signal processing. Now that we have

22:39.040 --> 22:45.440
a good intuition on the one-dimensional DCT let's talk about how JPEG specifically uses it.

22:46.480 --> 22:51.840
JPEG takes an image and splits it into eight by eight blocks and then centers their values

22:51.840 --> 23:01.040
around zero by subtracting 128. Then we take the block and apply the DCT to each row of the block

23:01.040 --> 23:09.200
giving us eight sets of DCT coefficients. We then apply the DCT to each column of the block.

23:13.280 --> 23:16.880
This process is what defines the two-dimensional DCT.

23:19.120 --> 23:25.760
So in the end we have 64 coefficients each of which are await on a specific eight by eight pattern.

23:26.400 --> 23:32.000
Notice the first row and column correspond to the earlier one-dimensional patterns and the other

23:32.000 --> 23:39.040
elements are compositions of these patterns. And just like in the one-dimensional case the big idea

23:39.040 --> 23:46.960
here is that we can build up any eight by eight image using these 64 fundamental patterns. The

23:46.960 --> 23:52.960
same signal perspective we talked about earlier also applies here except now with 2D waveforms.

23:52.960 --> 23:58.480
What's going on here is we are plotting the pixel value on the z-axis with brighter pixels having

23:58.480 --> 24:05.200
larger values. What's fun to play around with is seeing how the waveform and image come together

24:05.200 --> 24:13.200
as we slowly put together the 64 coefficients in increasing frequencies. Seeing this in action

24:13.200 --> 24:18.640
makes you realize that one interesting property is that by the time we incorporate a small portion

24:18.720 --> 24:23.920
of the coefficients our signal and image already look pretty close to the original versions.

24:25.360 --> 24:30.080
There's an even more direct experiment we can run to quantify this notion.

24:31.760 --> 24:36.480
This particular eight by eight block was randomly picked out of the original image.

24:37.200 --> 24:42.560
If we map out the magnitude of the DCT coefficients on this block we see that most

24:42.560 --> 24:46.400
of the largest values are in the upper left section which corresponds to the original

24:46.560 --> 24:52.240
upper left section which corresponds to lower frequency components. And what's even more

24:52.240 --> 24:58.560
interesting if I take any eight by eight block on this image almost all of them have the same

24:58.560 --> 25:04.800
property. This property of the DCT is what's commonly referred to as energy compaction.

25:06.240 --> 25:12.320
After applying the DCT most of the largest values are concentrated in a few low frequency

25:12.320 --> 25:19.040
coefficients and this holds true in a lot of real world images. The concept of energy compaction

25:19.040 --> 25:24.880
is incredibly important in image compression. As we will see it's exactly the property that

25:24.880 --> 25:30.400
will allow us to aggressively compress images while still retaining high visual quality.

25:33.280 --> 25:39.280
Fun fact the original discovery the DCT centered around approximating other transforms

25:39.280 --> 25:45.840
that had better energy compaction properties but were too expensive to carry out. The DCT is just

25:45.840 --> 25:51.120
one example of a transform that has this property for real world images and we use it because it's

25:51.120 --> 25:57.920
quite easy to compute. There's a lot of complexity involved here but one of my goals in this discussion

25:57.920 --> 26:03.600
of the DCT and JPEG was directly interacting with these deep and important ideas through

26:03.600 --> 26:10.000
questions and visual experiments. Interactivity is a core part of learning and a website that

26:10.000 --> 26:16.560
does a fantastic job of interactive explanations is Brilliant the sponsor for this video. From the

26:16.560 --> 26:21.200
basics of mathematics and algorithmic thinking to more complex ideas and deep learning and

26:21.200 --> 26:26.480
probability Brilliant offers a variety of courses and learning paths for those interested in getting

26:26.480 --> 26:32.000
hands on practice. Our discussions of JPEG interacted with some linear algebra in the

26:32.000 --> 26:37.680
application of image compression and Brilliant has an entire linear algebra module that goes

26:37.680 --> 26:42.400
through the fundamentals and even shows applications of these ideas in image compression,

26:42.400 --> 26:49.120
cryptography, error correcting codes and much more. When I was a student I really enjoyed their

26:49.120 --> 26:53.920
computer science fundamentals course which has engaging visualizations of concepts and great

26:53.920 --> 26:58.800
practice problems that helped me solidify my foundations. You can get started for free by

26:58.800 --> 27:04.720
going to brilliant.org slash reducible which is linked in the description below. Brilliant is

27:04.720 --> 27:09.840
providing a special offer through this channel where the first 200 members to sign up get 20%

27:09.840 --> 27:14.960
off the annual subscription. It's a great way to learn more about the topics in these videos

27:14.960 --> 27:20.480
and also a good way to support this channel. Big thanks to Brilliant for sponsoring this video.

27:22.720 --> 27:27.360
Let's put everything we've discussed with the DCT together in one more experiment.

27:28.160 --> 27:32.800
We'll split our image into eight by eight blocks and then basically rebuild the image

27:32.800 --> 27:39.440
with each block having only a certain number of DCT coefficients. We're going to start off with

27:39.440 --> 27:46.720
zero coefficients and slowly build up the image. After one coefficient we end up with basically a

27:46.720 --> 27:54.080
blur of the original image and as we add DCT coefficients slowly notice how quickly the

27:54.080 --> 28:01.600
image starts looking like the original. By the time we get to less than 25% of the DCT coefficients

28:01.600 --> 28:07.680
you almost can't even tell the difference between the two images. This confirms the key aspects of

28:07.680 --> 28:14.480
why JPEG works for this particular image. Almost all the blocks are composed of the lowest frequency

28:14.480 --> 28:20.800
components and we are generally less sensitive to changes in high frequency details. So at this

28:20.800 --> 28:26.400
point we know we can eliminate higher frequency components from the DCT but the next natural

28:26.400 --> 28:33.520
question is how we actually do this. The process for eliminating higher frequency components in JPEG

28:33.520 --> 28:41.280
is called quantization. Quantization is a simple idea. Given an eight by eight matrix of frequency

28:41.280 --> 28:47.920
coefficients from the DCT what we're going to do is basically divide each element by a scalar value

28:47.920 --> 28:54.720
and round it to an integer. These values are defined in terms of a quantization table. Notice

28:54.720 --> 28:59.840
larger values in the bottom right of the table leading to zero values in the higher frequency

28:59.840 --> 29:07.520
components. In the decoding stage of JPEG we'll actually be multiplying this result by the same

29:07.520 --> 29:14.480
quantization matrix element by element and as you can see the final coefficient matrix will be quite

29:14.480 --> 29:20.320
different from the original one. So what that means is we're purposely losing information in this step

29:21.600 --> 29:27.600
but the key idea here is most of the lower frequency components will be retained. This is

29:27.600 --> 29:34.400
why the energy compaction property of the DCT is so useful when the largest values lie in the lowest

29:34.400 --> 29:40.240
frequencies we will end up with a lot of zeros in the less important high frequency components.

29:40.480 --> 29:47.760
These quantization tables are provided by the JPEG standard from visual experiments

29:47.760 --> 29:54.640
and are the main way for JPEG to define quality of compression. High quality compression parameters

29:54.640 --> 30:01.760
can be translated to lower quantization table values. In practice JPEG also defines a separate

30:01.760 --> 30:08.800
quantization table for both the luma and color channels. Notice that in the color channels

30:08.880 --> 30:16.640
quantization can be even more aggressive. After performing quantization we have a matrix of quantized

30:16.640 --> 30:22.160
DCT coefficients where we can now exploit redundancy to get even more compression.

30:24.000 --> 30:30.160
The last part of JPEG encoding involves a combination of run length encoding and Huffman

30:30.160 --> 30:36.800
encoding. One clever trick is that a JPEG encoder will order the coefficients in a zigzag manner

30:36.800 --> 30:43.360
to maximize the chance of a large sequence of zeros in order. Classic run length encoding can

30:43.360 --> 30:49.600
compress this fairly easily. All that's going on here is we are compressing every sequence of zeros

30:49.600 --> 30:55.760
into a count of the occurrences in a continuous sequence. JPEG actually performs something a

30:55.760 --> 31:01.920
little bit more sophisticated by keeping track of a triplet. For every coefficient this triplet

31:01.920 --> 31:07.680
encodes the number of preceding zeros, the number of bits required to encode the coefficient,

31:07.680 --> 31:14.080
and finally the actual coefficient value. We also have an end of block value to signal that

31:14.080 --> 31:23.120
everything from here on out will be zeros. This particular scheme works well with Huffman

31:23.120 --> 31:30.160
coding to further exploit redundancy. The big idea of Huffman codes is that more frequently

31:30.240 --> 31:37.040
used data can be encoded with fewer bits, and it turns out especially with the nature of quantization,

31:37.040 --> 31:42.240
these triplets can be further compressed since some of these values will be more frequent than others.

31:44.000 --> 31:49.440
However, I'm purposefully not going to go into the details of how JPEG uses Huffman codes to

31:49.440 --> 31:55.280
compress the data because it really does get quite tricky. To give you some sense of the problems,

31:55.280 --> 32:00.320
we have to deal with the encoding signs of coefficients as well as triplets for all eight

32:00.320 --> 32:07.120
by eight blocks. Most encoders also encode the top left coefficient separate from all the other

32:07.120 --> 32:13.360
coefficients. And when you handle that, you have to deal with this on both luma and color channels.

32:14.320 --> 32:18.720
And when you eventually get that working, a good chunk of your logic will break when you

32:18.720 --> 32:24.480
have to deal with the different types of chroma subsampling. Implementing an optimized fully

32:24.480 --> 32:30.640
functional JPEG encoder and decoder is no joke. I wouldn't give that task to even my worst enemies.

32:31.840 --> 32:36.720
But in terms of the big picture, all that's going on in this component is taking advantage

32:36.720 --> 32:43.920
of the redundancy that quantization creates. A JPEG decoder will be able to use the Huffman code

32:43.920 --> 32:50.720
data in the files to get back all quantized DCT coefficients that were encoded. This part

32:50.720 --> 32:59.600
of the JPEG algorithm does not lose any information. JPEG as a whole brings about an interesting

32:59.600 --> 33:05.600
discussion on the philosophy of data compression. The classic and most straightforward way to

33:05.600 --> 33:12.240
compress data is by taking advantage of redundancy. This is the basis of losses image compression

33:12.240 --> 33:18.880
algorithms such as those found in PNG file formats. In fact, for images where it's really important

33:18.880 --> 33:25.680
not to lose any information, PNG format is recommended over JPEG. But on most real world

33:25.680 --> 33:31.520
images, being aware of the medium of presentation introduces another really powerful perspective.

33:32.640 --> 33:37.760
A lot of innovation in JPEG compression comes from experiments and understanding of human

33:37.760 --> 33:43.440
visual systems. It's from these experiments that we realized human eyes are less sensitive to color

33:43.440 --> 33:48.560
and also less sensitive to higher frequencies. So we can remove that information without a

33:48.560 --> 33:56.080
significant visual impact. This is why JPEG is so much more effective at compressing images than

33:56.080 --> 34:02.560
lossless formats. You'll find these same types of techniques used in audio and video compression

34:02.560 --> 34:08.640
where algorithms use our perceptions of sound and motion respectively to remove less relevant data.

34:09.520 --> 34:14.560
In fact, variations of the discrete cosine transform and quantization show up in both

34:14.560 --> 34:21.440
audio and video compression. It really is incredible to me how people in these fields came up with the

34:21.440 --> 34:27.520
mathematical and algorithmic framework to utilize the way we actually perceive the digital technology

34:27.520 --> 34:33.760
around us. There's so much depth to these topics that I can never hope to cover in just one video,

34:33.760 --> 34:38.960
but I do hope this gives you a sense and appreciation for the complexity of the technology

34:38.960 --> 34:47.520
around us that we use on a daily basis. Thanks for watching and I'll see you all in the next one.

