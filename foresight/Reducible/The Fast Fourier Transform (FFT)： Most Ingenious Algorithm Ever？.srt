1
00:00:00,000 --> 00:00:05,680
The world of algorithms is vast, but we can often split them into two distinct classes.

2
00:00:05,680 --> 00:00:10,080
The first class is those that are inherently useful. Think of your standard graph algorithms

3
00:00:10,080 --> 00:00:15,280
like DFS or BFS. These algorithms show up all over the place, they are efficient,

4
00:00:15,280 --> 00:00:19,360
and as a result we like to understand them. The second class of algorithms we study are

5
00:00:19,360 --> 00:00:24,400
ones that are just purely beautiful. Think of the first time you saw the incredibly simple

6
00:00:24,400 --> 00:00:30,080
recursive implementation of towers of annoy. If you have a soul, you feel a sense of wonder,

7
00:00:30,080 --> 00:00:35,440
a sense of awe at the elegance of such an algorithm. It happens to not actually be that

8
00:00:35,440 --> 00:00:40,400
useful or efficient as a matter of fact, but we still study it just as we like to read a work

9
00:00:40,400 --> 00:00:46,720
of fiction. It inspires us and motivates out-of-the-box thinking. Today I want to talk about an algorithm

10
00:00:46,720 --> 00:00:52,160
that rightfully belongs in both classes and my personal favorite algorithm, the fast Fourier

11
00:00:52,160 --> 00:00:59,120
transform. The fast Fourier transform or FFT is without exaggeration one of the most important

12
00:00:59,120 --> 00:01:03,840
algorithms created in the last century. So much of the modern technology that we have today such as

13
00:01:03,840 --> 00:01:09,520
wireless communication, GPS, and in fact anything related to the vast field of signal processing

14
00:01:09,520 --> 00:01:16,640
relies on the insights of the FFT. But it's also one of the most beautiful algorithms you ever see.

15
00:01:16,640 --> 00:01:21,600
The depth and sheer number of brilliant ideas that went into it is just astounding.

16
00:01:22,960 --> 00:01:28,160
It's easy to miss the beauty aspect of the FFT since it's often introduced in fairly complex

17
00:01:28,160 --> 00:01:32,960
settings that require a lot of prerequisite knowledge such as the discrete Fourier transform,

18
00:01:32,960 --> 00:01:39,040
time domain to frequency domain conversions, and much more. And to be fair, to get a full

19
00:01:39,040 --> 00:01:43,520
appreciation of the applications of the FFT you can't really avoid any of these ideas.

20
00:01:44,080 --> 00:01:48,880
But I want to do something a little different. We'll take a discovery-based approach to learning

21
00:01:48,880 --> 00:01:54,480
about the FFT in a context that you are all familiar with, polynomial multiplication.

22
00:01:54,480 --> 00:01:59,360
The way I see the structure of this video, it's all about starting with some common ground and

23
00:01:59,360 --> 00:02:05,120
then slowly asking questions that will hopefully prompt you to discover the truly ingenious ideas

24
00:02:05,200 --> 00:02:08,800
behind the FFT. Alright, let's get started.

25
00:02:18,960 --> 00:02:24,400
The setup here is simple. We're given two polynomials and want to find the product.

26
00:02:24,400 --> 00:02:29,120
Our task will be to design an efficient algorithm for this problem. Mathematically,

27
00:02:29,120 --> 00:02:34,640
we know one algorithm to multiply polynomials by repeatedly applying the distributed property.

28
00:02:34,640 --> 00:02:38,800
All of you have perhaps instinctively been applying this algorithm since any algebra class.

29
00:02:39,600 --> 00:02:44,240
Before we try this idea though, the first question we have to address is representation

30
00:02:44,240 --> 00:02:50,240
of polynomials in a computer. The most natural way to represent them is through coefficients,

31
00:02:50,240 --> 00:02:55,840
where we map coefficients to lists. It helps to arrange our coefficients in the following order,

32
00:02:55,840 --> 00:03:01,520
mainly because now the coefficient of the kth index is mapped to the coefficient of the kth

33
00:03:01,520 --> 00:03:07,200
degree term. We will refer to this representation as the coefficient representation of polynomials.

34
00:03:11,520 --> 00:03:17,120
In general, given 2d degree polynomials, the product will have a degree of 2 times d.

35
00:03:17,120 --> 00:03:21,840
And the running time of this algorithm, if we actually went about implementing it with the most

36
00:03:21,840 --> 00:03:28,320
natural distributed property approach, will be O of d squared, since each term in polynomial a will

37
00:03:28,320 --> 00:03:34,480
have to be multiplied by all terms in polynomial b. The question now is, can we do better?

38
00:03:36,080 --> 00:03:41,120
The first really clever idea comes from thinking about polynomials a little bit differently.

39
00:03:41,760 --> 00:03:46,000
To see the key inside here, let's take a look at one of the simplest polynomials,

40
00:03:46,000 --> 00:03:51,760
a degree 1 polynomial or a linear function. We can represent any line with exactly two

41
00:03:51,760 --> 00:03:57,760
coefficients, one for the degree 0 term and one for the degree 1 term. The key part that makes

42
00:03:57,760 --> 00:04:04,000
this representation valid is that every representation has a one to one mapping to a unique line.

43
00:04:04,000 --> 00:04:09,120
What other representations of a line have this property? There are actually several

44
00:04:09,120 --> 00:04:14,960
reasonable representations, but the one that we are going to use is the two point representation.

45
00:04:14,960 --> 00:04:19,280
We know from geometry that any line can be represented by two distinct points.

46
00:04:19,280 --> 00:04:23,920
And turns out that there is a neat extension of this for general polynomials, which I will state here.

47
00:04:24,800 --> 00:04:31,600
Any polynomial of degree d can be uniquely represented by d plus one points. For example,

48
00:04:31,600 --> 00:04:37,040
if I gave you three random points, this means that there is exactly one quadratic function

49
00:04:37,040 --> 00:04:42,560
that goes through all three of these points. If I give you four points, there is exactly one

50
00:04:42,560 --> 00:04:47,200
cubic function that goes through all these points. This statement is perhaps a little surprising,

51
00:04:47,200 --> 00:04:53,280
so it deserves a proof. Suppose I give you d plus one unique points of a d degree polynomial p of x.

52
00:04:53,280 --> 00:04:57,280
We want to show that for these set of points, there is only one set of coefficients.

53
00:04:57,840 --> 00:05:01,760
So if we actually evaluate our polynomial at each of these points,

54
00:05:01,760 --> 00:05:06,960
we get the following set of system of equations. Whenever you have a system of equations,

55
00:05:06,960 --> 00:05:11,040
writing it as a matrix vector product is almost always helpful for analysis.

56
00:05:12,240 --> 00:05:16,880
One nice property of this matrix is that if each of our original points is unique,

57
00:05:16,880 --> 00:05:20,560
as it is in this case, the matrix will always be invertible.

58
00:05:20,560 --> 00:05:26,160
The easiest way to show this is by calculating the determinant, which you will find is non-zero,

59
00:05:26,160 --> 00:05:31,440
but I'll link a nice linear algebraic proof of this fact in the description as well for those

60
00:05:31,440 --> 00:05:37,600
interested. Anyways, what this means is that for every set of points, there exists a unique set

61
00:05:37,600 --> 00:05:45,200
of coefficients and consequently a unique polynomial. Taking a step back, what this means

62
00:05:45,200 --> 00:05:50,240
is that there are actually two ways to represent polynomials of degree d, the first of which is

63
00:05:50,240 --> 00:05:56,000
the coefficient representation and the second with just d plus one points, which we will call

64
00:05:56,000 --> 00:06:03,040
the value representation. A nice property of using the value representation is multiplication

65
00:06:03,040 --> 00:06:09,280
of polynomials is much easier. Let's say I ask you to multiply these two polynomials a of x

66
00:06:09,280 --> 00:06:16,240
and b of x. We know the resulting polynomial c of x will be of degree four, so we'll need five

67
00:06:16,240 --> 00:06:22,320
points to uniquely represent the product. What we can now do is take five points from each of the

68
00:06:22,320 --> 00:06:27,600
two polynomials and then simply multiply the function values one by one to get the value

69
00:06:27,600 --> 00:06:34,480
representation of the product of the two polynomials. Following our earlier rule,

70
00:06:34,480 --> 00:06:39,520
there is only one degree four polynomial that passes through these points. That polynomial

71
00:06:39,520 --> 00:06:44,160
happens to be the following in the coefficient representation and this is indeed the product

72
00:06:44,160 --> 00:06:50,640
of our original a of x and b of x polynomials. With the multiplication operation being performed

73
00:06:50,640 --> 00:06:56,160
using the value representation, we've now reduced the time for multiplication from our original

74
00:06:56,160 --> 00:07:04,720
d squared operations to the order of only degree d operations. Okay, so let's propose a plan for

75
00:07:04,720 --> 00:07:09,840
an improvement to polynomial multiplication. We are given two polynomials in the coefficient

76
00:07:09,840 --> 00:07:15,920
representation of degree d each. We know multiplication is faster using the value representation,

77
00:07:15,920 --> 00:07:21,680
so what we'll do is evaluate each of these polynomials at 2d plus one points, multiply each

78
00:07:21,680 --> 00:07:26,480
of these points pairwise to get the value representation of the product polynomial,

79
00:07:26,480 --> 00:07:32,720
and then finally somehow convert the value representation back to the final coefficient

80
00:07:32,720 --> 00:07:37,920
representation. This is the grand plan, but there are several pieces of the puzzle we haven't figured

81
00:07:37,920 --> 00:07:43,360
out. What we're missing is really some sort of magic box that could take polynomials in the

82
00:07:43,360 --> 00:07:49,120
coefficient representation and convert them to the value representation and then vice versa.

83
00:07:49,120 --> 00:07:54,800
That magic box my friends and trust me it is truly magical is the fast Fourier transform.

84
00:07:56,240 --> 00:08:01,280
Let's first focus on taking polynomials from the coefficient representation to the value

85
00:08:01,280 --> 00:08:07,680
representation, which we will call evaluation. We have a degree d polynomial and we want to

86
00:08:07,680 --> 00:08:13,280
evaluate the polynomial at n points where n is some number greater than d plus one.

87
00:08:13,280 --> 00:08:18,880
Let's think about the most straightforward way to do this. We can pick n random x coordinates

88
00:08:18,880 --> 00:08:25,040
and simply calculate the respective y coordinate. This works, but when we deconstruct what's

89
00:08:25,040 --> 00:08:31,760
actually going on here, we run into our old foe. Each evaluation will take o of d operations,

90
00:08:31,760 --> 00:08:37,920
making this method run in o of n times d time, which ends up being o of d squared to evaluate

91
00:08:37,920 --> 00:08:43,600
all n points. So we're back to where we started. Can we find a way to optimize this?

92
00:08:45,040 --> 00:08:50,000
Let's try to simplify the problem. Let's say instead of considering a general polynomial,

93
00:08:50,000 --> 00:08:54,720
we wanted to instead just evaluate a simple polynomial like p of x is equal to x squared

94
00:08:54,720 --> 00:09:00,400
at eight points. The question now is, which points should we pick? Is there any set of

95
00:09:00,400 --> 00:09:04,960
points when knowing the value of one point immediately implies the value of another?

96
00:09:06,480 --> 00:09:11,600
In fact, there is. If we pick the point x equals one, we immediately know the value

97
00:09:11,600 --> 00:09:17,360
of the point x equals negative one. Similarly, if we pick x equals two, we automatically know x

98
00:09:17,360 --> 00:09:22,800
equals negative two will have the same value. Extending this idea, the key property we want

99
00:09:22,800 --> 00:09:28,160
here is that our eight points should be positive negative pairs. The reason this works is due to

100
00:09:28,160 --> 00:09:33,120
the property of even functions where a function evaluated at negative x is going to equal the

101
00:09:33,120 --> 00:09:39,760
function evaluated at positive x. Okay, but then the next immediate question is, what about functions

102
00:09:39,760 --> 00:09:46,240
like x cubed? Does the same trick work? It actually kind of does, but with one caveat.

103
00:09:46,240 --> 00:09:51,680
Each positive x value will have the same value as the negative x value, but with the sign flipped.

104
00:09:52,560 --> 00:09:58,080
So in these two cases of odd and even degree single term polynomials, instead of evaluating

105
00:09:58,080 --> 00:10:04,400
eight individual points, we can actually get away with evaluating exactly four positive points,

106
00:10:04,400 --> 00:10:08,480
from which we immediately know the value of the respective negative points.

107
00:10:10,080 --> 00:10:13,680
Let's see if we can extend this idea to a more general polynomial,

108
00:10:14,320 --> 00:10:19,360
taking inspiration from our early exploration, let's split our polynomial into even and odd

109
00:10:19,360 --> 00:10:25,760
degree terms. If we factor an x from the odd degree terms, we end up having two new polynomials,

110
00:10:25,760 --> 00:10:30,560
where these new polynomials have only even degree terms. Let's actually give these

111
00:10:30,560 --> 00:10:36,000
polynomials formal names, the first representing the even terms and the second representing

112
00:10:36,000 --> 00:10:42,480
odd terms after factoring out x. This fact allows us to recycle a lot of computation between positive

113
00:10:42,480 --> 00:10:47,920
and negative pairs of points. A bonus fact is that since these even and odd polynomials are

114
00:10:47,920 --> 00:10:53,280
functions of x squared, they are polynomials of degree two, which is a much simpler problem than

115
00:10:53,280 --> 00:11:00,800
our original degree five polynomial. Generalizing these observations, if we have an n minus one

116
00:11:00,800 --> 00:11:07,120
degree polynomial that we want to evaluate at n points, we can split the polynomial into even

117
00:11:07,120 --> 00:11:13,520
and odd terms with these two smaller polynomials now having degree n over two minus one. So,

118
00:11:13,520 --> 00:11:18,160
how do we evaluate these polynomials with half the degree of our original polynomial?

119
00:11:18,160 --> 00:11:23,760
Well, what's beautiful here is that this is just another evaluation problem, but this time

120
00:11:23,760 --> 00:11:29,600
we need to evaluate the polynomials at each of our original inputs squared. And this works out

121
00:11:29,600 --> 00:11:35,440
nicely since our original points were positive negative pairs, so if we originally had n points,

122
00:11:35,520 --> 00:11:40,960
we now only end up having n over two points. This is starting to smell like the start of

123
00:11:40,960 --> 00:11:47,600
a recursive algorithm. Let's take a look at the bigger picture. We want to evaluate a polynomial

124
00:11:47,600 --> 00:11:54,960
p of x at n points where the n points are positive negative paired. We split the polynomial into odd

125
00:11:54,960 --> 00:12:01,120
and even degree components where we now have two simpler polynomials of degree n over two minus one

126
00:12:01,120 --> 00:12:07,280
that only need n over two points to evaluate. Once we recursively evaluate these smaller

127
00:12:07,280 --> 00:12:12,080
polynomials, we can then go through every point in our original set of n points and calculate the

128
00:12:12,080 --> 00:12:17,200
respective values by utilizing the relationship between the positive and negative paired points.

129
00:12:18,640 --> 00:12:25,040
This gives us the value representation of our original polynomial. If we can get this to work,

130
00:12:25,040 --> 00:12:30,960
this means we have an O of n log n recursive algorithm since the two recursive sub problems

131
00:12:30,960 --> 00:12:36,640
have half the size of the original problem and take linear time to evaluate the n points.

132
00:12:36,640 --> 00:12:40,320
This would be a huge improvement from our earlier quadratic running time,

133
00:12:40,320 --> 00:12:43,760
but there is one major problem. Can you spot the issue?

134
00:12:46,000 --> 00:12:51,120
The problem occurs at the recursive step. The entire scheme relies on the fact

135
00:12:51,120 --> 00:12:55,600
that the polynomial will have positive and negative paired points for evaluation.

136
00:12:56,160 --> 00:13:01,520
This works at the top level, but the next level we are evaluating n over two points where each

137
00:13:01,520 --> 00:13:08,320
point is a squared value. These all end up being positive so the recursion breaks. So then the natural

138
00:13:08,320 --> 00:13:15,040
question is, can we make these new set of points positive negative paired? Some of you may already

139
00:13:15,040 --> 00:13:20,400
see it, but this actually leads to the third absolutely ingenious idea behind the FFT.

140
00:13:20,960 --> 00:13:27,680
The only way this is possible is if we expand the domain of possible initial points to include

141
00:13:27,680 --> 00:13:34,160
complex numbers. For a special choice of complex numbers, the recursive relation works perfectly

142
00:13:34,160 --> 00:13:38,400
where every subsequent set of points will contain positive negative pairs.

143
00:13:39,360 --> 00:13:42,480
What possible set of initial n points has this property?

144
00:13:43,360 --> 00:13:47,440
This is a hard question and to answer it we are going to do a little bit of reverse

145
00:13:47,440 --> 00:13:52,720
engineering with an example. Let's say we have a degree 3 polynomial which requires at least

146
00:13:52,720 --> 00:13:58,400
n equals 4 points for its value representation. These points need to be positive negative pairs

147
00:13:58,400 --> 00:14:05,520
so we can write them as x1, negative x1, x2, and negative x2. We know that the recursive step

148
00:14:05,520 --> 00:14:10,800
will require that we evaluate the odd and even splits of the polynomial at two points,

149
00:14:10,880 --> 00:14:17,200
x1 squared and x2 squared. Now the key constraint here is that for the recursion to work,

150
00:14:17,200 --> 00:14:23,520
these two points also have to be positive negative pairs. So we have an equivalence between x2

151
00:14:23,520 --> 00:14:30,320
squared and negative x1 squared. At the bottom level of the recursion we'll have a single point

152
00:14:30,320 --> 00:14:37,120
x1 to the power of 4. Now what's nice is that we get to choose these points. Let's see what happens

153
00:14:37,120 --> 00:14:44,480
if we pick our initial x1 to be 1. This means two of our initial points are 1 and negative 1

154
00:14:44,480 --> 00:14:50,160
which at the next level of recursion means that x1 squared and negative x1 squared also have to be

155
00:14:50,160 --> 00:14:56,800
1 and negative 1 respectively. And at the bottom layer we have only one point which ends up being

156
00:14:56,800 --> 00:15:04,240
1. Now the question becomes what x2 should we choose so that when we square x2 we end up with

157
00:15:04,240 --> 00:15:09,520
negative 1. The answer to that is the complex number i which means that the four points that

158
00:15:09,520 --> 00:15:15,040
we need to evaluate this polynomial at are 1, negative 1, i and negative i.

159
00:15:17,280 --> 00:15:22,480
An alternate perspective to what we just did here is that we essentially just solved the equation

160
00:15:22,480 --> 00:15:27,920
x to the power of 4 equals 1. Since at the bottom layer of the recursion the value of any of our

161
00:15:27,920 --> 00:15:35,360
original points to the power of 4 was 1. We know this equation has four solutions all of which

162
00:15:35,360 --> 00:15:42,000
are encompassed by a special set of points called the fourth roots of unity. Let's see if this

163
00:15:42,000 --> 00:15:49,120
generalizes. If given a degree 5 polynomial we'll need n is greater than or equal to six points.

164
00:15:49,120 --> 00:15:54,000
Since our recursive method is splitting each problem in half it's convenient to just pick

165
00:15:54,000 --> 00:15:59,440
a power of 2 so let's pick n equals 8. Now what we need to do is to find eight points that are

166
00:15:59,440 --> 00:16:05,360
positive negative paired such that each of these points when raised to the eighth power is equal

167
00:16:05,360 --> 00:16:12,480
to 1. We see that the right points are the eighth roots of unity. Generalizing this to any d degree

168
00:16:12,480 --> 00:16:18,480
polynomial what we will do is pick n is greater than or equal to d plus 1 points such that n is

169
00:16:18,480 --> 00:16:24,560
the power of 2 and the points that we should choose are the nth roots of unity. This fact

170
00:16:24,560 --> 00:16:30,320
deserves a little bit more explanation. Why does this work? Before we answer that question let's

171
00:16:30,320 --> 00:16:35,440
formalize a few things. The nth roots of unity are the solution to the following equation

172
00:16:35,440 --> 00:16:40,320
and they are best visualized as equally spaced points on the unit circle. The angle between

173
00:16:40,320 --> 00:16:47,200
these points is 2 pi over n. With this fact a nice way to compactly write these points is with

174
00:16:47,200 --> 00:16:52,960
complex exponential notation through Euler's formula. One standard way to define the roots of

175
00:16:52,960 --> 00:16:59,760
unity is by defining this omega term as e to the power of 2 pi i over n and then what this allows

176
00:16:59,760 --> 00:17:05,360
us to do is define individual roots of unity quite compactly. Here are some examples.

177
00:17:08,240 --> 00:17:13,920
So now when we say we want to evaluate a polynomial at the nth roots of unity what that really means

178
00:17:13,920 --> 00:17:19,520
is we want to evaluate it at omega to the power of 0, omega to the power of 1, so on and so forth

179
00:17:19,520 --> 00:17:27,680
until omega to the power of n minus 1. So going back to our original question of why evaluating

180
00:17:27,680 --> 00:17:33,520
the polynomial p of x at the nth roots of unity works for a recursive algorithm there are two

181
00:17:33,520 --> 00:17:39,360
key properties at play here. For one our original set of points are positive negative paired where

182
00:17:39,360 --> 00:17:45,520
for the jth root omega to the power of j omega to the power of j plus n over 2 is going to be the

183
00:17:45,520 --> 00:17:51,920
corresponding pair. Now in our recursive step we will be squaring each of these points and passing

184
00:17:51,920 --> 00:17:57,920
them on to the even and odd degree polynomials. This is what happens when we square our original

185
00:17:57,920 --> 00:18:04,800
nth roots of unity. This reveals the second key property of the nth roots of unity. When we square

186
00:18:04,800 --> 00:18:10,720
the nth roots of unity we end up with the n over 2 roots of unity which are also positive negative

187
00:18:10,720 --> 00:18:16,080
paired and are just the right number of points for the two new polynomials of half the degree.

188
00:18:16,080 --> 00:18:21,440
This same pattern holds at every level of the recursion until we end up with just one point.

189
00:18:21,440 --> 00:18:22,560
How beautiful is that?

190
00:18:28,480 --> 00:18:33,600
All right we are now ready to outline the core fast Fourier transform algorithm. The

191
00:18:33,600 --> 00:18:39,440
FFT will take in a coefficient representation of a degree n minus one polynomial where n is the power

192
00:18:39,440 --> 00:18:46,800
of two. We will define omega as e to the power of two pi i over n to allow us to define roots of

193
00:18:46,800 --> 00:18:52,640
unity easily. The first case we need to handle is the base case which is going to be when n is equal

194
00:18:52,640 --> 00:18:59,040
to one. All this means is that we are evaluating the polynomial at one point. Our recursive case is

195
00:18:59,040 --> 00:19:05,760
two calls to the FFT. One on even degree terms and one on odd degree terms. The intention is that

196
00:19:05,760 --> 00:19:11,120
these polynomials are now half the degree of our original polynomial so they only need to be evaluated

197
00:19:11,120 --> 00:19:16,800
at n over two roots of unity. Assuming the recursion works the output of these calls will be the

198
00:19:16,800 --> 00:19:22,400
corresponding value representation of these even and odd degree term polynomials which we will label

199
00:19:22,400 --> 00:19:29,760
as y e and y o. Now on to the tricky part which is to take the output from these recursive calls

200
00:19:29,760 --> 00:19:36,000
and combine them to get the value representation of our original degree n minus one polynomial.

201
00:19:36,640 --> 00:19:41,760
We saw earlier that the key idea was to use the relationship between positive and negative pairs

202
00:19:41,760 --> 00:19:47,760
but now we have to slightly modify this logic for our roots of unity inputs. As a quick note

203
00:19:47,760 --> 00:19:52,800
yes I did modify the indexing to zero indexing because we're getting ready to write some code.

204
00:19:52,800 --> 00:19:58,080
We know the jth input point will correspond to jth root of unity which results in the following

205
00:19:58,080 --> 00:20:05,600
relationship. We also saw earlier that the paired point negative omega to the power of j is equal

206
00:20:05,600 --> 00:20:11,680
to omega to the power of j plus n over two due to the properties of the roots of unity. Using this

207
00:20:11,680 --> 00:20:18,320
fact we can modify the second equation as follows. And lastly one more fact that's nice is that the

208
00:20:18,320 --> 00:20:26,560
jth index in our y e and y o list correspond to the even and odd polynomials evaluated at omega

209
00:20:26,560 --> 00:20:32,560
to the power of two times j. What this allows us to do is rewrite our equations as follows

210
00:20:32,560 --> 00:20:38,240
which makes it much easier to implement code. As mentioned this part is tricky so I encourage

211
00:20:38,240 --> 00:20:44,800
you to take your time and verify that each of these steps is indeed true. The final step in the

212
00:20:44,800 --> 00:20:51,360
FFT algorithm is to then return the values of a polynomial p evaluated at the nth roots of unity.

213
00:20:52,000 --> 00:20:58,400
Let's now translate this outlined logic into code. Our function FFT will take an input p which is

214
00:20:58,400 --> 00:21:05,680
the coefficient representation of a polynomial p. We first define n as the length of p and we will

215
00:21:05,680 --> 00:21:12,240
assume that n is a power of two. Just to be clear there are implementations of the FFT that can handle

216
00:21:12,240 --> 00:21:18,800
n not being a power of two but those are way more complicated. The power of two cases encompass the

217
00:21:18,800 --> 00:21:24,800
core ideas of the algorithm. We now handle the base case which is just a matter of returning our

218
00:21:24,800 --> 00:21:31,360
original p. This makes sense since we only have one element making p a degree zero polynomial

219
00:21:31,360 --> 00:21:37,440
or constant. Otherwise we define omega as we have outlined and then proceed with the recursive step.

220
00:21:37,440 --> 00:21:42,240
The first part of the recursive step requires splitting the polynomial into even and odd

221
00:21:42,240 --> 00:21:47,600
degree terms which is quite easy to do. Then we recursively call our FFT function on these

222
00:21:47,600 --> 00:21:52,880
polynomials that now have half the degree of our original polynomial. We denote the outputs as

223
00:21:52,880 --> 00:21:59,920
y e and y o as we have done in the outline. Now it's time to put this all together. We initialize

224
00:21:59,920 --> 00:22:07,440
our output list which will contain the final value representation. Then for all j up to n over two

225
00:22:07,440 --> 00:22:13,440
we calculate the value representations as we have outlined. After populating all values in our list

226
00:22:13,440 --> 00:22:19,840
we then return that list and that's the FFT. Overall pretty crazy how all the ideas we talked

227
00:22:19,840 --> 00:22:26,960
about end up coming together in eleven lines of truly elegant code. Let's now take a larger

228
00:22:26,960 --> 00:22:31,760
look at our original problem of polynomial multiplication and see where we are. We now

229
00:22:31,760 --> 00:22:38,080
have a way to convert coefficient representations to value representations efficiently using the FFT.

230
00:22:38,080 --> 00:22:43,280
So now the only missing piece is the reverse process of converting from value representations

231
00:22:43,280 --> 00:22:48,880
to coefficient representations which is formally called interpolation. This is where things get

232
00:22:48,880 --> 00:22:56,400
really wild. On the surface the idea of reversing evaluation feels like a significantly harder task.

233
00:22:56,400 --> 00:22:59,760
Let's take a step back and look at this problem from another perspective.

234
00:23:00,400 --> 00:23:05,920
Evaluation and interpolation are closely connected and as we saw earlier we can express

235
00:23:05,920 --> 00:23:13,680
evaluation as a matrix vector product. We have a vector of coefficients multiplied by a matrix

236
00:23:13,680 --> 00:23:20,320
of our evaluation points to give us the value representation. Now in the FFT algorithm the

237
00:23:20,320 --> 00:23:26,320
kth evaluation point was a corresponding root of unity which allows us to rewrite the matrix

238
00:23:26,320 --> 00:23:33,600
vector product as follows. This particular matrix has a special name the discrete Fourier transform

239
00:23:33,600 --> 00:23:41,520
or DFT matrix. In most textbooks and references the FFT at its core is an algorithm for calculating

240
00:23:41,520 --> 00:23:48,000
these types of matrix vector products efficiently. Polynomial evaluation at the roots of unity happens

241
00:23:48,000 --> 00:23:53,200
to be one case where this type of matrix vector product shows up so that's why we can use the

242
00:23:53,200 --> 00:23:59,840
FFT. Anyways the nice fact about the FFT and evaluation in this context is that interpolation

243
00:23:59,840 --> 00:24:07,520
is much easier to understand. Interpolation requires inversing this DFT matrix. For interpolation we are

244
00:24:07,520 --> 00:24:13,360
given a value representation of our polynomial and we want to find the coefficient representation

245
00:24:13,360 --> 00:24:19,120
which means we have to multiply the value representation by the inverse of the DFT matrix.

246
00:24:20,000 --> 00:24:24,560
So let me show you what the inverse of this matrix looks like. I'm purposefully skipping

247
00:24:24,560 --> 00:24:29,440
a lot of important linear algebra facts here since that would be an entirely different video

248
00:24:29,440 --> 00:24:33,520
but given that this is the inverse matrix what stands out to you?

249
00:24:36,160 --> 00:24:41,200
It's really quite amazing but this inverse matrix looks almost the same as our original

250
00:24:41,200 --> 00:24:47,840
DFT matrix. In fact the only difference is that every single omega in our original DFT matrix

251
00:24:47,840 --> 00:24:54,000
is now just replaced with omega to the power of negative 1 with a normalization factor of 1 over

252
00:24:54,000 --> 00:25:00,400
n. This indicates a potential to reuse the FFT logic for interpolation since the matrix structure

253
00:25:00,400 --> 00:25:06,400
is basically the same. Let's formalize this suspicion by doing a direct comparison. In

254
00:25:06,400 --> 00:25:12,240
evaluation which involved the FFT we are given a set of coefficients and evaluate the polynomial

255
00:25:12,240 --> 00:25:17,680
at the roots of unity to get a value representation. This involved the following matrix vector product

256
00:25:17,680 --> 00:25:24,320
where we define omega as e to the power of 2 pi i divided by n. Looking at interpolation we now

257
00:25:24,320 --> 00:25:30,800
want to define what is formally called the inverse FFT algorithm. The inverse FFT will take a value

258
00:25:30,880 --> 00:25:36,160
representation where each value was evaluated at the roots of unity and gives you a set of

259
00:25:36,160 --> 00:25:41,360
coefficients for the original polynomial basically reversing what the original FFT did.

260
00:25:41,360 --> 00:25:47,280
As we just saw this requires multiplying by the inverse of the DFT matrix. We noted that each

261
00:25:47,280 --> 00:25:54,000
omega in our original DFT matrix now corresponds to 1 over n times omega to the power of negative 1.

262
00:25:54,000 --> 00:26:00,000
Now the punchline here is that what this means is we can define the inverse FFT

263
00:26:00,000 --> 00:26:07,440
as the same FFT function but now called on the value representation with omega defined as 1 over

264
00:26:07,440 --> 00:26:14,640
n times e to the negative 2 pi i divided by n. That's it. With those small changes we have

265
00:26:14,640 --> 00:26:21,040
an inverse FFT that performs interpolation. Just so we are super clear on what sorcery just happened

266
00:26:21,040 --> 00:26:25,840
let me remind you of the original FFT implementation and now let me show you the

267
00:26:25,840 --> 00:26:30,640
inverse FFT implementation which takes the value representation as an input.

268
00:26:31,920 --> 00:26:37,680
What we literally do is copy our FFT implementation, change the name of the recursive calls to

269
00:26:37,680 --> 00:26:43,680
match and then literally change one line of code. One line and that's all there is to it.

270
00:26:44,640 --> 00:26:49,680
So if your mind isn't blown you haven't been paying attention. Let's take a look at what we just

271
00:26:49,680 --> 00:26:55,440
did. We motivated the FFT through the problem of polynomial multiplication where the first

272
00:26:55,440 --> 00:27:00,640
brilliant idea came from representing and multiplying polynomials using the value representation.

273
00:27:01,360 --> 00:27:05,680
Converting polynomials to a value representation required us to come up with an appropriate

274
00:27:05,680 --> 00:27:11,680
set of evaluation points. Our first attempts at solving this problem inspired the clever idea of

275
00:27:11,680 --> 00:27:17,440
using positive negative pairs but the recursion didn't quite work unless we expanded the domain

276
00:27:17,440 --> 00:27:23,120
to complex numbers. The next brilliant idea came from using the nth roots of unity where the points

277
00:27:23,120 --> 00:27:28,480
at every level of recursion are positive negative paired. This evaluation scheme using the roots

278
00:27:28,480 --> 00:27:33,920
of unity encompassed the essence of the FFT algorithm. When confronted with the problem

279
00:27:33,920 --> 00:27:39,040
of reversing the process using interpolation we discovered something truly astounding.

280
00:27:39,040 --> 00:27:46,000
The inverse FFT is the same algorithm but with one minor adjustment. So if we take a look at what

281
00:27:46,000 --> 00:27:52,240
we just did here there's not one, not two, not three, but four absolutely mind-blowing ideas

282
00:27:52,240 --> 00:27:57,680
that come together to make this work. Do I really need to say more on why this is my favorite algorithm?

283
00:28:01,280 --> 00:28:05,360
That's all for this video and thanks for watching. If you enjoyed the content please

284
00:28:05,360 --> 00:28:10,000
hit the like button so that this content will be recommended to more people. If you want to

285
00:28:10,000 --> 00:28:14,480
see more content like this please don't forget to hit the subscribe button and if you want to

286
00:28:14,480 --> 00:28:18,960
more directly support the work of this channel please check out the Patreon page linked in the

287
00:28:18,960 --> 00:28:22,240
description below. I'll see you all in the next video.

