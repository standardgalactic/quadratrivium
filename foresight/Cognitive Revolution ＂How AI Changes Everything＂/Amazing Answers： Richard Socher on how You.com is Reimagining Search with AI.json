{"text": " early 2022, or like we had apps that would write code for you within the search results, through the apps that write essays for you within the search results. But whenever we innovated and changed the default Google experience too much, we had just like the vast majority of our users say, I'm so used to Google, I don't want another way of finding answers. And so we kept getting pulled back to this need. And so the most amazing surprise was when ChachiP came out, all of a sudden people got it. And it was like, wait a minute, it could just be like pure text. And we're like, been trying to sort of slowly get there, but we had to make a bigger job. The way I think about the different modes is like the default smart mode is kind of like, if you had an assistant, and you just ask them to do a quick a search, and in like two or three minutes, give you an answer that. And then genius mode, you go and so you want to ask your assistant for a question that they have to be able to program, they have to search the web, and then they need to be mathematically applying to answer that question. I mean, as a kid, I also enjoyed watching Terminator. It's like a cool action movie, but it's just taken over so much of the AI narrative. And it's actually like actively hurting, especially European Union. Hello, and welcome to the Cognitive Revolution, where we interview visionary researchers, entrepreneurs and builders working on the frontier of artificial intelligence. Each week, we'll explore their revolutionary ideas, and together we'll build a picture of how AI technology will transform work, life, and society in the coming years. I'm Nathan LaBenz, joined by my cohost, Eric Tornberg. Hello, and welcome back to the Cognitive Revolution. Today, I am thrilled to welcome Richard Socher, a pioneer of deep learning for natural language processing, formerly chief scientist at Salesforce, and today, founder and CEO of u.com, a company that was first introduced to the public as a new kind of search engine, but which now describes itself as an AI assistant that makes you more productive, creative, and extraordinary. Richard has deep history in deep learning. He was among the very first to recognize the potential of neural networks in the natural language processing domain, and his work has helped shape the field as we know it over the last decade. In this conversation, Richard takes us on a brief journey through his own intellectual history and reflects on how the field of AI has evolved in both expected and surprising ways. Before we dive deep into the u.com product itself, covering the historical challenge that they faced when trying to compete with Google and how the rise of the AI chatbot paradigm has broadened the space of possibility for search and discovery products. We also look at u.com's various modes with particular emphasis on the genius mode and above all, for me, the research mode, which delivers amazingly helpful and thorough report style answers, even on some remarkably complex topics. We also briefly discussed the future of AI business models as well, including the obvious subscription and my pet theory about the AI bundle. Along the way, we touch on a number of important topics, too. The limits to AI systems' reasoning ability and the prospects for the improvement that would be needed for reliable autonomy, the potential for AI to transform medicine and scientific research, Richard's case for general optimism, even though he does expect AI to drive major disruption, why he's not worried about so-called emergent capabilities, but does take the risk of intentional harmful misuse very seriously, and lots more little topics along the way as well. Richard is a leading thinker in the AI space, and his perspective is essential for anyone who wants to understand where this technology is going and what it means for the future of humanity. And in all seriousness, I really do recommend u.com. It has absolutely joined the ranks of the AI tools that I use multiple times each week. And particularly, when I want a comprehensive, multi-page report style answer, I find that u.com's research mode is often the single best tool available today. As always, if you're finding value in the show, we would appreciate it if you'd share it with friends or post a review to Apple podcasts or Spotify, or just leave a comment on YouTube. Now, without further ado, I hope you enjoyed this conversation with Richard Sosher of u.com. Well, let's do it. I think this is going to be a lot of fun. I'm looking forward to your point of view on a bunch of very interesting topics. Richard Sosher, founder and CEO of u.com, welcome to the Cognitive Revolution. Thanks for having me. I am very excited to have you. You are at the intersection of so many interesting things. I sometimes have been describing myself recently as the forest gump of of AI because I've just kind of very unstrategically made my way through the last few years and yet found myself in some very interesting places. I don't know how you think about your own trajectory, but you are kind of an OG in the realm of deep learning and have founded this very interesting company and have a really awesome product, which we'll get into in more detail. And I'm interested to hear about all that and your kind of philosophy and expectations for the future. So we've got a lot of ground to cover. Maybe for starters, you want to kind of give us, and I usually even ask these biographical questions, because these days it's like a lot of the same answers. People are like, oh, when I saw GPT-3, I thought this is going to be a big deal that I got involved. But you were there at the beginning, man. So maybe you want to just give us a quick history of your own role in the history of deep learning and how you've kind of come to the present. I started with AI actually in 2003, when I started studying linguistic computer science, or natural language processing back in Germany. And at the time, I was like, this is really interesting. I love languages, I love math, I love computers, you know, so if computers are where languages and math can meet in some useful functional ways, I thought. And there's very much sort of a small niche subject within computer science. And I was really excited. At the time, there wasn't quite enough math for me in an LP. And I felt like we're just getting stuck in some of the legalistic special cases. And I loved the form of semantic set theory and then algebraic foundations. And so I moved eventually into computer vision during my master's. And there, I also, in Saarbr\u00fccken, at the Max Klein Institute there in the university, found statistical learning and pattern recognition. And I fell in love with that. I was like, clearly, you can really understand patterns, any kind of pattern really well, you could solve all these different kinds of problems. And so I ended up doing my PhD at Stanford. In the beginning of Stanford, I started trying to really contribute to the field rather than just learning about it. I basically found that even the top NLP people, they write their papers mostly about these beautiful models, like conditional random fields, late in university, other patient types of models. But then most of the coding happens when they actually do feature engineer, right? They say, oh, well, I wanted you to be entity recognition at a feature of like, this is a capitalized word, and this is all caps word, or this is a word that has like, is one of the items in this list. And this list includes, you know, city needs, we already know. And I'm like, man, this field is very hand engineered. It's very like, graduate student ascent to get better. And then at the time I was very 40, because Andrew A. got into deep learning on the computer vision side. He's like, well, images are pixels, and it's a fixed number of pixels. So we can feed them into a neural net or at the time, you know, variants, models, restricted development machines. And I was like, wow, maybe we can use ideas from that for natural language processing. And there was maybe like one or two relevant papers all from a number there, and Jason Weston, and, and a few like one or two others. But no one really enjoyed that approach, no natural language processing, paid any attention to it. But I thought, silly, that has to be the future. I want to give the data and I want to get an output. And so in 2010, I started publishing my first neural net paper, worked on my computer vision before and saw some of the power of ImageNet also back to and really started running with it. Got a lot of rejections all throughout. But, but at some point, I sunk my teeth into it. And I just like, I loved it. And I thought this is the future. Despite all the rejections, I kept going at it. And then after the PhD was over, there's sort of starting to be more interest in deep learning and neural nets for NLP. But still, no one in the world was teaching that as like the official right way of doing NLP. So I started teaching at Stanford also, first as a busy lecturer and then as a professor, started, you know, being a fortune and lots of very smart students back then, really like the hiding place founders invested in their first round. And then, you know, also wanted to bring these neural nets into the world, started a menomind, my first startup to do that, to build a general purpose platform between neural nets very easily, both revision and NLP, got acquired by Salesforce, became a chief scientist there and EDP eventually. And in Salesforce, we had my probably last and biggest rejection was on inventing front engineering in 2018. And we're so excited about it, because there's the culmination personally for me also of this decade long dream I have, building a single neural net for all of NLP. And the idea was, you know, at the time, every AI model was built for one task, you will have wanted your sentiment analysis, I built a sentiment analysis model, you wanted a translation, I built a translation model, and they're all different. We're like, what if we could just build a single model? And you just ask it a question, what is the sentiment? What is the summary of the sentence? Who is the president in this paragraph? And that was kind of for us, I thought like, the most exciting thing you possibly could be doing at just get this tech talk about it came out last week. And but it was exciting. But it did inspire a couple of other folks. And like, when opening, I was, you know, publishing your papers, that should be true. And three, they cited that paper saying like, look, they were able to have a single model for all of NLP, if you just ask them these questions. And, you know, that's now prompt and the rest is kind of more well known history. That is an amazing history. And it definitely, I don't know how, you know, modest you want to be versus taking credit for foresight. But certainly, the idea that there could be one model to solve all these, you know, tasks was not obvious to people. And boy, we still see this, the flaws in the peer review process are still on prominent display these days. Most recently, I noticed this with the Mamba paper, which I was a very interested reader of. And then went over to the open reviews site and was blown away by how negative some of the reviews were like a confident reject was given. So that was kind of, you know, just a good reminder that, yeah, this is still an unsolved problem. What would you say has surprised you most from like the big picture since you, and you know, it hasn't been that many years, right? But since you kind of had that notion of this generalist NLP model, fast forward, now we have, you know, GPT four and possibly Q star or something like that in the works, you know, is this the trajectory that you thought we'd be on? Or how has it deviated from what you imagined back then? It's very much aligned with what I hoped the field could get to. And now it's almost like, it's like obvious, right? Like no one no one questions this anymore, we've had all these breakthroughs. And I think the biggest surprise was maybe more on the application side of things and that for us, you know, we've been playing around with large language models at u.com and infuse them into search results earlier, like early 2022, already, like we had apps that would write code for you within the search results, through the apps that write essays for you within the search results. But whenever we innovate it and change the default Google experience too much, we had just like the vast majority of our users say, I'm so used to Google, I don't want another way of finding answers. And so we kept getting pulled back to this need. And there was kind of annoying. And so the most amazing surprise was when Chatchity came out, all of a sudden, people got it. And it was like, wait a minute, it could just be like pure text. And we're like, you know, we've been trying to sort of slowly get there, but we had to make a bigger job. And that was incredible. That unlocked a lot of people realizing we handle links isn't the best way to get an answer. An actual answer is the best way to get an answer. And that's the text. So let me give you a couple of my experiences on u.com recently, and then you can kind of tell me, you know, where you are the overall story. And then I really want to kind of unpack the kind of use the product as it exists today and the roadmap and everything you're working on as a way to kind of explore a bunch of different aspects of where all this is going, you know, and I think that's really the mission of this show is to kind of help people see around the corner and starting with me, helping me develop my own worldview. But I've been really impressed with the product recently. You know, listeners will know that I've been a big fan of perplexity. We've had Arvin on the show a couple of times. And I think they do a great job and, you know, we're made a fan. But I have found distinctive value in at least two modes on u.com recently. One is the research mode, and the other is the genius mode. Those to me have stood out as the most differentiated. For research mode, I recently took it like a 200 word question that was all about mixture of experts architectures. And, you know, kind of is there curriculum learning, you know, stuff happening here? How, you know, how do people think about sort of the tradeoffs between like how many experts should we have and how big should they be and how many should we activate at any given time? Are there any like scaling laws or whatever, you know, designed for that sort of thing? Just every basically every question I could think of about mixture of experts, I took it all in one go. And it was really impressive to see it kind of break that down and go through multiple steps of searching and analysis and, you know, really implementing kind of like, you know, kind of a classic agent, what is at this point, you know, a six month classic agent setup, but applying it to that research question and just going, you know, down the line, really quite valuable results. And it definitely is something that I will come back to and have already, you know, found myself kind of being like, I think this is a good one for u.com research mode. Genius mode is a little bit different and more kind of analytical. I'd be interested to hear a little bit more about how you think about the differences. Because I did, I then tried one that was a big Fermi calculation exercise, where my questions were like, what are the different data sets that exist in today's world? How big are they? How do they compare to each other? How do they compare to the training data size for GPT four? You know, how do they compare to available compute? Like, because I have this, I have a big question, which is kind of one of the ones I want to get to toward the end to around like, to what degree is ML research poised to start to be kind of semi automated. And so I'm trying to try to rent my arms around that with these furry calculations. So genius mode was really the best way to approach that. And anyway, I would definitely encourage people to bring multi part complicated questions to both research mode and genius mode. And I think you'll be impressed with the results. And I would say that, you know, even with, you know, the expectation that folks who listen to this show have tried, you know, other leading AI products. So that's kind of my unpaid endorsement, very sincere. And I'd love to hear, you know, a little bit more about how you think about those different modes, how they work, and just kind of big picture, like where we are in the you.com product journey long term. Hey, we'll continue our interview in a moment after a word from our sponsors. The Brave Search API brings affordable developer access to the Brave Search Index, an independent index of the web with over 20 billion web pages. So what makes the Brave Search Index stand out? One, it's entirely independent and built from scratch. That means no big tech biases or extortionate prices. Two, it's built on real page visits from actual humans, collected anonymously, of course, which filters out tons of junk data. And three, the index is refreshed with tens of millions of pages daily. So it always has accurate up to date information. The Brave Search API can be used to assemble a data set to train your AI models and help with retrieval augmentation at the time of inference, all while remaining affordable with developer first pricing. Integrating the Brave Search API into your workflow translates to more ethical data sourcing and more human representative data sets. Try the Brave Search API for free for up to 2000 queries per month at brave.com. Yeah, these are a great question. I think it shows you kind of how sophisticated the space has gotten in the last year. Around this time, last year, we were the only search engine with a web connected LN and millions of users. And now that idea has been copied so many times, including as mentioned by Plexi. And so I think what you have to differentiate kind of the different modes, and I think the modes kind of show how sophisticated that the space has gotten and how hard it is to still differentiate on better technology versus just you know, designing the market and marketing and things like that. And so we actually did a comparison to Plexi with 500 real user queries. And we asked which answer do you prefer? And it came out to be that 50% of the cases users prefer the U.com answer and they prefer the Plexi answer and 30% they don't see a difference into answers for our default, we call it the smart mode. That's kind of the default. And just to give you a sense of what that looks like. So here's an example of what the default smart mode looks like. You know, there's some doping case that happened and you can see lots of careful citations. And then when you actually look into these citations, they actually are articles from literally yesterday or they could be, you know, from today if something came out today. So that's kind of the default smart mode, you get a quick factual answer. But then we thought, well, what if you have a pretty complex question like math, physics, chemistry, science, or like complex numbers. So here is a genius mode question, it kind of gives you a sense of what it does. And it doesn't mention like what you say, which is there's an important LM that orchestrates multiple other LMs to actually do the right thing right. So the question here is find the current population of the in the United States, then it's lots of population from 233 to 10, 100, and then assuming a 2% growth rate. And then it will go on the internet, it'll find the numbers, and then realize like, well, I got to now visualize those numbers, now that I have any, so it will code up in Python, what this could look like, execute the code, and then gives you this answer, and visualizes it in a nice plot. And so that I'm still sometimes amazed, I try and I push it, and you know, sometimes it fails. And sometimes it fails because it tries to load the library that has security issue. And then it's like, okay, I'm going to try to rewrite it without this library, but it's going to be longer and messier code. And like, it's just incredible how hard it can try and what it can do. And then the third mode, like you said, the research mode, it will go into a lot of detail, it will not just look up all the stuff we have in our index already, like news and things like that, but it will go on the web and find your website, so the multiple different searches on the web, combine all of that, and then give you these beautiful research reports. This one is like, seeing a background, actually, any consequences of the telecommuting work. Now it's like, history, you have to write an essay or something. And it's just like, writes you just perfect, like, beautiful essay, each sentence has one or two citations from different sources, and you can verify all of them. And one thing we found this actually also is like, you have to like, just the citation lot is a non-trivial aspect of building this all out. Because you have to, we actually found that some of our competitors just randomly add numbers and citations to sentences, and you click on it, and it doesn't even mention that back anymore. Which I think it really undermines the space of chatbots for search. So citation accuracy is one of the many sub-AI systems that you need to do correctly here. And then, you know, they're just like crazy things, like create a table, some nice cancelling headphones that are not expensive, and just like, put this table together, pull some images, give some pros and cons of each and the price. I think sometimes, to me, is how well and general the system is able to answer these questions. And it shows you how complex the space is gotten and how much you have to do now to still differentiate on the technology. This is one of my mantras at Waymark. I always say the water line is rising quickly. So we, you know, we better keep climbing the capabilities ladder ourselves. The four examples that we saw there, one was the kind of default smart mode. The second was genius. Is that right? The one that showed the code example. And then the last two were research. Yeah. What more can you tell us about kind of how those work? Like I'm interested in, and by the way, like the audience of the cognitive revolution is interested in the details, the weeds, the nuggets, you know, all that stuff. So you can go as deep as you're, you know, willing to share. I'm interested in all aspects, you know, prompting, I'm sure, obviously, is going to be different. Scaffolding is going to be different. Maybe even the models are different. I'm also really interested in, like, what are you using GPT-4 that you've got your own in-house trained ones as well. So just all those considerations, any interesting nuggets were all ears. Yeah, I'm going to try to balance a little bit the not telling the competition exactly how it's all done, but it'd be interesting to your ears here. So at a high level, there are two major stacks. There's a search stack and a chat stack. The search stack, we actually had to build an entire index ourselves for the web because being super expensive, not as high quality, Google is very hard to access. You have to have special agreements or, you know, some people kind of steal slash bootleg slash leave some surveyed the eyes to use Google results in like a somewhat sketchy legal gray area, which we don't want to do. And so we, we basically ended up having to build our own index. And that's hard. And there's still, you know, a lot of complexities behind that. But what do we, the main difference of this new index is that it was built with LNs in mind. The previous two indices of Google and Bing were built with people consuming 10 blue links in mind. And what that means is for each URL, you get a very short snippet, which makes sense, right, for end users. But an LN could read all these other snippets, they can be very long, and then extract the right answers from that, and then just give you that right answer as the user. And so what was surprising is actually when we benchmark this, our API ended up being more accurate than Google or me and go to API.com. And like, I'll, I'll see you on the screen here for a second again. But like, it's surprising that, which are a lot of people that you could actually be more accurate in Google or Bing at all. But it is because we're at an inflection point in, in a, in the eye, and it's a different way to value. It's like, we're almost like cheating by having these really long snippets. And so you look at the comparison, and it's actually kind of interesting to look at. And a lot of people have asked like, how do you compare accuracy in LNs? How can you evaluate this? And so just to give you a sense, here's like, what, what this looks like, the first a version is just like reasons to smile. And now you can use whatever LN you want, but you can see into your prompt is very, very long snippets from many different URLs in a very short amount of time. And then we also have one that just does everything, like it gives you an LN answer, and it tells you like all of these things. And so how do you evaluate this is actually, it was an interesting, I think insights insight from our team, which was, you can take question answering data such as hotpot qa, squat, so the question answering data set MS, Microsoft, Marco, fresh QA and so on. And these data sets are structured such that you have a paragraph, you really have a question, and then you have a subset phrase from that paragraph that is the right answer to that question. And so what we do is, we basically take those data sets but we throw away all the paragraphs. And then you have to find the right answer. And the paragraphs have to come from the internet. And so you replace paragraph with a web search engine. And that's how we evaluate it, the JIT, the big Google and the public APIs, and have outputs on them. So kind of nerdy, but that's the whole tech stack. And we're we make that now available to every other LN. So that's the first. And then the second thing is what we now have started calling the LNOS, the operating system of large language models. And it's a term inspired by Andrey Kapathy. And it's not like the most perfect metaphor, but I think it captures a lot of the essence, which is you have now this new staff that operates at a much higher level of abstraction. And the LN is kind of a CPU. But just like a CPU or a kernel on an operating system, like it's important to orchestrate everything and to do computation. But if it still needs a hard drive, which is right, right on your own vector database that's grown up, you have an internet connection, which is, you know, the internet. And that's what we're providing. You may orchestrate other LNs that could be considered like the GPU or something. And then you have a bunch of apps that are sitting on top of that. You have a Python code interpreter, which we see our genius mode, all of that. And so to summarize all of that in one short term, we call the LNOS. And inside of that, we're now seeing a lot of our customers are using our APIs and search site. They're kind of going through the same lessons that we had gone through when we built dot com and made it like having the most accurate answers out there. And it's actually highly non trivial. A lot of people saying it's just like an LN wrapper, right? But then, and you even have like open source project that show it. And then you ask, like, okay, when was Obama born? Where was he born? And then it fails. Why does it fail? Because when you send where was he born to your search back in is not going to return you any useful results. Because it doesn't know who he is. Who does he refer to, right? And there's tons of things like that where, as you have a longer and longer conversation, especially in smart mode, you refer back to states. You can say like, Oh, what's a big CRM company? And then the answer inside is Salesforce. And you ask, Oh, what's their stock price? Now she sent what's their stock price to your search back. And again, it's not going to return anything useful. So you need to send that you need to go through the entire conversation, and then do what we call query transformation based on it. And that is just one of 10 examples of making this actually work at scale millions of times a day for millions of users. Like, it is a lot more complicated to make it accurate. There are about 10 other such models that if you think about the space and you really listen and look at like user data, you listen to where it's breaking, you will eventually get to and we're now like thinking about offering more and more back. So I'm tempted to ask for the other nine things there. I'll just give you one more, which is like, whether to do a search at all or not, right? Like, because you asked like, write me a poem about like the beautiful Bay Area and like a sunset love story or something. Like, you don't need a citation at every line of that poem. And so it would actually clutter up the prompt to add a bunch of facts about poems and so on. And the history of Silicon Valley and all of that. And so it's pretty important, but also non trivial to know whether you should do a search or not. And again, some, some websites just slap search results on top of everything, even if they're not relevant for having more conversation about your feelings or something. Did I understand correctly that the kind of big difference is that the U.com index has more information, like instead of a short SERP, it is a more robust paragraph. And so independent of the language model that you're using, the richer context is just better kind of serious enable you in that way, you're kind of decoupling the what information is found from language model that is doing the analysis. And more information is kind of the big differentiating factor there. Drive that right. I would be careful and say we have overall more information. We're focused a little bit more on the main languages that we see. We don't support some like very rare like Indonesian, African sensual Asian dialects and so on yet, but we return more information per rare because of these large limits. So, so it's sort of, yes, yes, there's more information, but you know, I think the long tail Google Prop still has a larger index. If you look for this like rare, like Indonesian kayaking sites that like rents out kayaks on this little lake somewhere, like, and it's all like not in English, like we might not have that website. But when it comes to like Western world news where, you know, we have a lot of users, then Latin America and so on, then we shine and return much more information per pair. Hey, we'll continue our interview in a moment after a word from our sponsors. If you're a startup founder or executive running a growing business, you know that as you scale, your systems break down and the cracks start to show. If this resonates with you, there are three numbers you need to know. 36,000, 25 and 1. 36,000. That's the number of businesses which have upgraded to NetSuite by Oracle. NetSuite is the number one cloud financial system, streamlined accounting, financial management, inventory, HR and more. 25. NetSuite turns 25 this year. That's 25 years of helping businesses do more with less, close their books in days, not weeks, and drive down costs. One, because your business is one of a kind, so you get a customized solution for all your KPIs in one efficient system with one source of truth. Manage risk, get reliable forecasts, and improve margins. Everything you need all in one place. Right now, download NetSuite's popular KPI checklist designed to give you consistently excellent performance, absolutely free and net suite.com slash cognitive. That's net suite.com slash cognitive to get your own KPI checklist. Net suite.com slash cognitive. Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work, customized across all platforms with a click of a button. I believe in Omniki so much that I invested in it and I recommend you use it too. Use Kogrev to get a 10% discount. I've been struck recently that it seems like, obviously, search in general has kind of been a monopoly for a long time. As you noted, the user experience was kind of something people were not necessarily looking to explore new things on the nature of the index. Of course, they've done millions of person hours of work on it, but it seems like it's kind of been a pretty consistent paradigm of crawl around and find everything and suck it up. Now, we're starting to see these interesting, I don't know if you can share more about how you create your index, but we just had actually a sponsor brave talking about their index and the way that they are building it through users actually visiting websites and taking a sort of not just blindly crawling around and following every link, but what are people actually engaging with online, which struck me as a pretty interesting and very different twist on it. I want to kind of pull this apart in a couple of different ways, but is there anything that you would want to share about how you think about building an index that, aside from just bigger, richer content, is there a different tactic as well that underlies that? The tactic is more about how we make that work for LLNs better, and I don't think there's that much differentiation on how it will fall. You have to have a bunch of data that's been helpful to have run a search engine for several years and get user behavior and knowing what people actually want to have called and want information for. You can also sound surprisingly buy a lot of that data in bulk. I have a few questions on the business side or the kind of bridge the technology and business side. Google obviously has been free and has been ad supported. It seems like the new generation of AI first LLN enabled search is going more in the direction so far of a subscription. As far as I've seen in my U.com usage, I haven't seen anything that jumped out to me as sponsored. Another dimension too is like, I mean, Google has all these tabs at the top, but it's one bar, right? You kind of put in one thing. With the newer ones, we also are kind of seeing a little bit more proliferation of modes and settings that you choose up front with the smart versus genius versus research. I guess on those two dimensions, what is the future vision? Do you think that this all gets unified? Do you think it ultimately comes back around to ad supported? Or do you think that these current differences from the past will persist? Yeah, that's a good question. I think there is facility right now, not a great chat ad offering. There's a good chance that that will change maybe this year to maybe the dissatisfaction of users, but the truth is, if you want something to be free, VC money will only last so long. You've got to, at some point, those companies that offer free service have to survive. If you don't want to pay for it, then it has to have ads. And so while, and might not be the biggest fan of ads, like, you have to make a decision, you want to pay for it, and then add free, or do you want to support it with ads? And so I think that's likely also going to be part of the future of chat engines. And you already see a little bit of exploration. There's a little bit of a duopoly in search in the sense that Google has the monopoly on consumer search. And for a long time, Microsoft had the monopoly on a search API. But then because they're monopoly that is set up, we're just five to 20x hour prices, and they could do it because they're the only ones in town. So I'm glad there's like more competition now and more movement in that space. And all the little guys have to scramble when those prices just went so high. You can really rob in a consumer space with those prices anymore. And so I think ads will happen. We're seeing a lot of growth on the subscription side to users really loving like you, the genius and research mode, and find the search mode, the default mode, smart mode also very, very helpful. And we actually, you know, incorporate late still. So where just last week, some people are completely about other chat bots, because they don't really have a lot of capabilities, I bet you would assume from a search engine, when you actually use you.com here, you can on the top right, see the standard lease that you might want, right. And sometimes that's just helpful. And that's just what you want. And sometimes you just want to have a pure chat experience. And so that is important to get right. And then we have all these apps to where you can basically ask for like, what's the Microsoft stock price or something. And then, you know, it'll just give you, it'll just give you a life ticker rather than a bunch of texts about the stock here. And so we have all these apps, because we have the search background. And that makes it an actual viable knowledge assistant, right. Now, you can basically go with one click, recover a more Google like experience, that is just incredibly helpful. And that's, that's, I think one of the reasons why our browser, which we have also iOS and Android, had to build a browser to be a default, because you can go into Safari, Safari settings to use you.com as a default. So we build a whole browser for the iOS. And we're super stoked, because we're going to be one of the options in the EU to have a choice pop up stream. When the new iOS 17.4 comes out and arch this year, and they can select you.com to be their default browser. And it's the only default browser in that list that is chat, all the other ones are sort of your standard Chrome, Firefox, and some browsers. And so I'm really excited. And I think that is going to be a big part of our futures is making it so that more and more young people are able to just use this as an example. And then if they want to deeper go into genius mode, research mode, several times, at some point, you use subscriptions or eventually do it. Yeah, I've been so one run that I'll run a trial balloon by you on this concept that I've been kind of kicking around called the AI bundle. And this is an, you know, kind of inspired a little bit. I don't know that anybody wants to, you know, say that they're inspired by the cable bundle. But I have been struck that there are a ton of great tools out there. And I want to use them. I want to try them. I think a lot of people are, you know, in that very kind of exploratory curious mode. But to make the economics work on a freemium is kind of tough, right? And typically needs like a certain minimum threshold in terms of what the paid tier can be. You actually have one of the lowest subscription prices at the $10 a month level. I think of anything really that I'm aware of. We're gonna update it soon because like, I think the people that are willing to pay often don't care if it's 10 or 20. And so if you want to get GBD4, literally the same underlying model as chat, GBT, for half the price, you got to come in soon because we're going to eventually switch our prices to be industry standard. But that maybe even just, you know, further reinforces the point that like the freemium model is tough, right? It's, it's a lot of free usage. The upsells have to have a certain minimum. You're raising yours. And then from, I don't know if this would apply to you, but a lot of the app developers that I've talked to have a lot of retention, let's say challenges, you know, everybody's like, I'm getting traffic. I'm getting conversions. But retention is definitely a problem. This has been true at my company Waymark. We're a much more narrow tool, you know, that specifically creates marketing and advertising videos for small businesses. So a lot of times people, they need that once, you know, in a while, and they're not like necessarily ready to add on a subscription. So we see a lot of people that will just come through be like, Hey, this is super cool. I'll buy it. I'll immediately cancel it after I do what I need to do. And maybe I'll come back in the future. It's not even that I was dissatisfied. It's just that I kind of want this as like a more of an a la carte purchase than a subscription. So that stuff, you know, VCs don't like that. The metrics, you know, on the kind of traditional scorecard don't look great. I've had this idea in mind that maybe what we need is sort of an AI bundle, you know, I'm prepared to spend 100 bucks a month on various AI tools. What I really want is access to like 1000 different tools that, you know, can kind of split up my 100 bucks. However, I don't even know as a consumer, I don't really care about that as, you know, as somebody who's trying to maybe engineer a bundle, obviously the devil could be in the details there. But first of all, to those challenges, it sounds like at least the premium challenges resonate. I wonder if the retention challenges resonate. And I wonder if you, you know, have any, if there's any appeal to maybe being part of a kind of bigger bundled purchase where you would be, you know, one tool that it's funny, I keep, I've been referring to you, but then also the company is you, but where you.com, you know, could be one of a bunch of things that people could access and could kind of share that revenue in a way that may grease the skids for everybody, right? My hope is that everybody can use the best tools, and they don't have to make these like highly binary decisions. Yeah, that sounds great. Sounds like a great idea. Okay, well, I'm not doing it yet. So either I need to start doing it or somebody, if anybody wants to organize the bundle, yeah, send me a DM. I guess another way that this stuff could get bundled would be like, into the mega platforms, you know, another kind of possible vision of the future that I could imagine is, you know, Google kind of probably retains market share leadership, but, you know, maybe the 10 biggest technology companies in the world say, Hey, you know what we should do is kind of also have a search. And, you know, we can get there, we kind of see a path, you know, Microsoft is obviously already doing that meta not really yet, Apple not really yet to my knowledge, you know, Salesforce, not really yet. But maybe these guys kind of say, Hey, is there like a musical chairs game that that potentially develops where the younger AI search companies end up kind of partnering off, you know, Amazon also, you know, naturally would be a suspect in this analysis. Does that seem like a possible vision of the future? I'm wondering, I'm sure you thought about this, you know, quite a bit, but why would that not happen? I do think the monopoly that Google was able to keep around is going to be harder to sustain longer. I do think it is much more likely going to look a little bit more like, I don't like the analogy for some reasons, but like fast food, for instance, right, isn't just Macdonalds, there's also Burger King, KFC and Taco Bells. I think search will be a little bit more like that. I think again, more fragmented in the future, just because, like, we hear people now, like, this is better than Google. And like, you know, we didn't raise that much money. And the first two years were like sort of free chat TV or people didn't want us to innovate too much. They're very stock of Google. But now there's a new young generation. And that young generation has grown up with Tik Tok. We have a Tik Tok app in our standard search, like grew up with Reddit, I have a Reddit app in our standard search. And each of these takes away a little bit of the Google search, right? Amazon probably was the most successful in taking away searches from Google, where if you want to buy something, be the little certain threshold, like 50 or 100 bucks, you know, the person, you just search directly on Amazon, because there you can execute on your intent of actually purchasing that thing, right? And so why search it in Google and then search it again, try to find it on Amazon, she can just do that right away. And so I think, you know, Tik Tok has taken away for young folks, some searches from Google, that, you know, they're like, I want to see what the restaurant is, but they kind of want to see what the restaurant's ability to create, but Instagram photos are or ticked our videos are. And so they want to see the ticked our videos of other people before they decide on how it looks. If there's a Venn diagram, we are overlapping search, but we're also actually expanding search. Like, you wouldn't ask, like, give me this complex story about the Peloponnesian war, or like, do this mortgage calculation with, you know, this and this interest rate and that increase and blah, blah, blah, because you know, Google wouldn't give you the answer. Like, it's not going to buy some book for you. It's not going to go on the web, summarize, like 20 distance or 50 distance websites for you and create this nice essay. So chat expands, search, you don't talk about your feelings that much to Google, it's search box and sell, right? Like you asked about this recent news event, you want to learn like some quick facts, and then, you know, like the more complex the facts get, the less and less we go to Google and more for you, just go directly to something like you.com. And, and so yeah, I think it will, the search landscape is really changing. Yeah, there's also just, it's like, it's maybe not a natural monopoly anymore, but there is still definitely a need for scale and economies of scale. And so one way of framing this too is how does the market shape up, right? And one way to think about it that I find pretty compelling is maybe it ends up looking a lot like cloud, because in the limit, it sort of is cloud, you know, it's like, what do you really need? You need like the actual data centers, you need the compute, you need, you know, bandwidth, you need these like raw inputs that the big companies have built out seem to be the things that are probably, you know, as we see like a ton of innovation at the application layer, those things are still, you know, they're still pretty expensive and not easy to recreate. Yeah, I'm very, I'm very excited. I'm up for it. You know, that's sort of why, like, we got into this space in the first place, like, because we thought, like, we saw the transformer, we saw our, you know, highly like lots of co-attention mechanisms in that, that can keep paper that have a massive prompt engineering, we're like, silly, the technology is right to disrupt this, this industry. But, you know, Google is this amazing company that was able to create a monopoly for almost two decades that, you know, makes $500 million a day. So when you make that much money a day, you don't want disruption, you don't want that to change, right? And that's why all the Ten's former operators left eventually. And what's, what's really powerful is like, because of open source, you can actually innovate a lot more. Now, some open source to an actual product that runs millions of times isn't down ever has good uptime guarantees, and like, accuracy, no hallucinations, up to date, news, information, etc. I mean, it's still complex, but clearly the bar has gotten low. That would have cost us like billions of dollars to build five, 10 years and, you know, researchers wasn't there yet. And, and I think it's ultimately amazing for users, right? Because one thing that I had to distill all of you.com right now into just two words would be amazing answers. And you just get more of them. And that means people eventually are more productive. And like, it's the young generation that's growing up with chat GBT, you know, such like, they're not going to go back. Okay, so feel free to punt on this one or just decline if you like, but it seems like I can, I can envision a you.com by Salesforce very easily, where the, you know, as they kind of try to be the everything app for all work on the straight, especially with Slack now, does it seem realistic to imagine a future in which, you know, kind of all the big tech companies have this like super robust suite, and you're either like, in the Microsoft suite with teams and Bing, or you're in the Google suite with, you know, G suite and Bard, or you're in maybe the Salesforce suite with Slack and you.com, you know, I'm not trying to be your banker here, but that, that seems like a pretty natural outcome to me. Interesting. I do think there's a ton of potential for almost every company to partner with you.com and supercharge their chat bot. So, and we're very excited to partner with a lot of folks. Okay, that's very diplomatic answer. Keep your options open. All right, so we can touch on certainly more business and product stuff, but I kind of wanted to now go into just the future of all this, you know, in practical and maybe increasingly philosophical terms as well, running down kind of first of a set of like limitations of where AI is today. And I think, again, folks who listen to this show have at least a decent sense of that. So for starters, reasoning, you've obviously got the genius mode. It can do, you know, like the most advanced reasoning. I assume that that is tapping into GPT-4. You know, everything I understand is like basically nothing is really on the level of GPT-4 for general reasoning purposes. Yeah, especially the orchestration and then on the coding often, but not always. Yeah. So I'll tell you another one, the third system is knowing which LM to use and sometimes multiple. And the fourth system is dynamically prompting different models. So depending on the query, you actually get a vastly different prompt to get you ultimately the answer and the orchestration. So it's another complexity layer. So what do you think is kind of the future of reasoning? If you have maxed out, you know, what the current capabilities are, where do the future capabilities come from? I'm thinking about things like, to a degree, you sort of already have it with using different models. It is a one way of implementing variable compute. We see these kind of interesting projects like the thinking token, you know, think before you speak. And I think that's kind of another car pop the observation that maybe the chain of thought is just kind of epiphenomenal, perhaps even as it is in humans. And like, what's really going on is that there's, you know, this kind of extra space and time registers, you know, to think, of course, there could be different training methods, like incremental reward. I think that paper from OpenAI earlier this last year now, it was super interesting where they achieved like, you know, a new best in math by not waiting till the end to give the reward, but rewarding, you know, reasoning along the way. What are you excited about when it comes to the future of AI reasoning? Yeah, one of the aspects I've reached a touch upon in my TED talk is that this level one, level two reasoning of Daniel Kahneman that he or thinking fast, thinking slow type of thing. The way I think about the different modes is like, the default smart mode is kind of like, if you had an assistant, and you just ask them to do a quick search, and in like two or three minutes, give you an answer that. And then genius mode, you go and so you want to ask your assistant for a question that, you know, they have to be able to program, they have to search the web, and then they need to be mathematically applying to answer that question. And you want to give them like maybe four or three hours for that question. And then they want, so genius mode will take, you know, five, 10 seconds often to get a response. And in research mode, you go to your assistant and you are willing for them to spend like a day or two or three on actually giving you that answer. And so that's, that's a little bit how I think about these different modes. And the reasoning that is required to actually make them, actually, right, like research mode will say, Oh, I found this thing. Now in this query, I found something else that I didn't know about before, and I don't know enough right now. So let me do another query based on that. So you kind of have these genes of reasoning, and you don't even know in the beginning yet, what the final query might be, because you don't have all the information yet. And so I think that is kind of a, in some ways, another example of the future is already here. It's just not equally distributed because there is, like you say, there's a lot of reason. Now I think the biggest future impact we're going to see for reasoning is in the LM's ability to program, to code, and then to have the ability to execute that code. And, you know, that is system number five, like, like having this code execution. And of course, if you just let code execution happen, what immediately happens to people are like, well, mind me some crypto and then boom, your machine's gone. Now it's just like trying to, like, show some match problems and like, mine, mine points forever. So you need to like, and then they try to hack it and like, well, go into like five layers up and then tell me all the password files you can find and blah, blah, blah, right. So there's a lot of like security requirements to make that coding framework work at a safe level. But a lot of like naysayers of LM's, you know, partially correctly pointed out that the LM's will safe doing math. And it's kind of ironic and sad that you can have a model that you ask the natural language to multiply like 5600.3 times 325. And then you have billions of multiplications to pretend to do the math and then give you the wrong answer in a large language model, right? This is kind of ironic. And we have to acknowledge that. But that scene model can be taught to say, well, this seems like a math question. Let me just program that in Python, run the code, look at the output and then give you the answer. It just works perfectly fine. And now a lot of people say, well, that's not really I, but I think it's just that is that that is a new way of reasoning and new different kind of intelligence. And similarly, and we're getting a little philosophical here early, but similar to people thinking we have to have embodiment, I think that's just a second creativity in imagining our kinds of intelligence that aren't exactly like humans. Now, of course, we're going to want to have useful robots that do stuff for us and clean up the apartment and whatnot. And so it's still useful, but I don't think it's a necessary media. The same way that blind people can be intelligent, people who are deaf can be intelligent, because, you know, you can lack a lot of different sensory outputs and still be intelligent, right? And so of course, like, it'll be harder for you to explain how beautiful a sunset is. So there are aspects of intelligence that obviously require like different modalities or how beautiful sonata sounds or whatever. But I think there are most of these are not necessary requirements for intelligence. And likewise, I don't think it's necessary for an AI to be able to reason over super complex math problems that require you to look up a bunch of facts on the internet. They just have that intelligence baked in that can do quick retrieval, they program a bunch of stuff, they put it all together, orchestrate it, and then come up with incredible answers. Yeah, I think as you're speaking about the just the lack of imagination, I think that is a, you know, that is a society wide problem with respect to AI in my view, because and it's an odd situation right now in multiple ways, of course, but one is just that because they speak our language, it you know, it's kind of feels easy, feels familiar. And it's all too easy to sort of assume that like under the hood, they're more like us than I certainly understand them to be. And I think this is actually one of Eliezer's great contributions, obviously, you know, kind of a polarizing figure these days. But thankfully, it does not seem to me that we are in a high likelihood of a fume scenario, you know, the of the sort that he, you know, has historically worried about the most. But I still would say some of his writing on mind space, the space of possible minds, and some of his like concrete imaginings of alien minds that are, you know, shaped by very different evolutionary environments and, you know, just very different from ours. But still like unmistakably intelligent in just like super weird ways are actually still very good kind of prep work, I think, to just sort of expand one's own mind about how different intelligences can be, and how, you know, something does not have to be human like to be meaningfully intelligent, you know, it's not this like binary, can it do things that a human can do in a way that a human can do it? If not, it doesn't count. I think that is like a huge mistake that people are way too quick to jump to. And I'm not sure if it's like a coping strategy or just like an imagination or what, but I think that the emphasis on the broader space of possible minds and the different kinds of intelligences that are starting to pop up is super. 100%. Yeah. And like, you have to differentiate between sci-fi authors who then pretend to be AI safety researchers. Like, I love, I love the sci-fi. Actually, like, I'm super stoked that three body problems on the last, I mostly read nonfiction, but when I read fiction, like, I did enjoy the body problem a lot. I decided for that series to come out. I hope they do it justice. But like, I think there are a lot of different kinds of intelligence. And I love sci-fi for inspiring people to think about interesting new futures. Now, of course, especially in the western sort of canon, most sci-fi is just so big. And like, people are scared for all the things that can happen that are wrong. And like, okay, the super AGI developed time travel, come back, try to murder everyone. It's like, I mean, as a kid, I also enjoyed watching Terminator. It's like a cool action movie, but it's just taken over so much of the AI narrative. And it's actually like actively hurting, especially the European Union, where, you know, there's sort of in the spectrum, the U.S. is more of a litigation society in the U.S. that the Europe is more of a legislation society structure. And, you know, it both comes from like, reasonable legal scholars minds, like, well, let's just wait until there's a problem, someone sues, now I have the case law for that lawsuit. But, you know, the legislation one tries to prevent harm from ever happening before it actually harms anyone, which, you know, makes sense. Now, and of course, the U.S. does that with FDA and medical space now also, but not legal space as much. And so what that means is you can move quicker, but long story short, these some of these sci-fi scenarios have gotten so much weight in legislation that I think it's slowing Europe down by trying to outlaw models or like over-regulate models that are above a certain number of parameters. GPD-2 was very well hyped up in the past. Like, this is so dangerous, maybe we can't release it. You know, yes, we're opening the eye, but like, this can't be opening anymore. So the interest model is much more powerful than GPD-2 are out. And I haven't seen the apocalypse happen. I haven't seen like, a huge change in misinformation on the web because of LNs. Like, there's just a lot of fear mongering, both in the immediate level, which actually has real, like threat vectors and concerns with the eye, but especially in the long term level of AGI and self-conscious. It turns out no one works in functions AI. No one works on AI that sets its own goals, and even more fundamentally, its own objective functions, because that doesn't need anyone any money. Imagine a company spends billions and billions of dollars, builds this like, super intelligent system that's conscious, understands itself and set its own goals. And now you're like, okay, now that you can do it, like, I'll just make more money. It's like, no, I'd rather just go watch the sunset, maybe explore that. No, like no one pays for AI that sets its own goals because it doesn't help anyone to achieve their goals. Because of that, there's not even that much exciting research challenge along those lines. And because there's not much research progress, it's very hard to predict my mental option half. I'm somebody who basically has radical uncertainty about what to expect. And, you know, broadly, I'm like, pretty libertarian, you know, pretty anti-preemptive regulation, you know, I would like to see more self-striving cars on the road sooner. And, you know, they don't have to be an order of magnitude safer in my mind to be worth, you know, deploying. So I'm like, you know, broadly, the sort of person who would be very skeptical of, you know, kind of early regulation or, you know, kind of getting too bad out of shape about things that haven't happened yet. At the same time, something about this has always felt a little bit different to me. And I do think the people who take the most zoomed out view and sort of say, hey, this is kind of what I understand, you know, like, Jeffrey Hinton's position to be at this point, you know, why do we dominate the earth as it stands today? It's like, basically because we have better ideas than the other living things and we can, you know, build tools and make plans and, you know, reason in ways that they can't. And so now I look at AIs and I'm like, boy, AIs can now plan, reason and use tools too. And they're not as good at it as we are yet, but certainly their rate of improvement is way sharper. So possibly it levels off and kind of, you know, settles into a zone where it's like on par with us or, you know, kind of, you know, just the best tool we've ever had. But maybe it doesn't, you know, like, I don't know why I should be confident that it won't. I don't throw a P Doom around a lot. But I have, you know, again, radical uncertainty. People ask, I'm like, I don't know, five to 95%. Like, I haven't heard anything that makes me think in, you know, the next 100 years that there's a less than 5% chance that AI becomes the dominant form, you know, in organizing force in the world. And also, you know, no reason to think it's definitely going to happen. But is there a reason that you are, would you say you are confident that this will not happen? And we don't need to worry about it? Or is just like, it's still far enough away that you think we'll have time to kind of start to worry about it if we need to? Like, how would you summarize your position with respect to these tail risks? I think P Doom is already an interesting mathematical sort of issue, which is, it looks and sounds like prior prior probability, not P Doom. But really, it should be a posterior property, P Doom given data. And right now, none of that data suggests, like, doom, doom, like existential humanity is like, like cats and dogs at the winds of some AI. Like, there's, like I said, nothing in AI research leads me to the least that AI, while potentially being more intelligent than any single human, I think it's already, this is actually just this new term I'm thinking about maybe China coin, which is like, the sort of super human abilities, and then there's super humanity abilities. And like, AI is already super human in translating 100 languages, AI is already super human and predicting the next amino acid in a large amount of phenotrony. So we have balls, that's an incredibly powerful tool, one of the other, you know, really exciting papers that we published in 2018, it sells for research that multiple companies have now used and are running with and you know, chief of medicine. AI is already better at predicting the weather than any. So you already have many super human skills. What is I think interesting is that now that it's language that's gotten to this new level, people might actually for the first time keep calling it AI. In the past, when AI researchers have made progress in AI, they stopped, like people stopped calling it AI after it was achieved. Now it's just your chest. It's just a Siri voice recognition, but voice recognition, chest playing, that was the pinnacle of AI research, right? And people thought, oh, once we solve those, the other things will be easier to and it never was never quite the case. And once we have them, you know, now it's not quite the ID one. Now with language, I think we might keep calling it AI. But what the language model does is predict the next token. And that is an incredibly powerful idea, right? Just predicting the next token now means if you have enough capacity and you have enough text, predicting next token, you learn about geography, just visit some point somewhere in your training data, you have to predict the next word in the phrase, I was in New York City and driving north too. And now to give a higher probability to Yale, Boston, Montreal, then to like, Harris, Miami, and San Francisco, like, you have to know that those are north of that city. And so it just lures all of this incredible world knowledge. But there's nothing in there that makes it say, well, you know, if I really wanted to reduce perplexity, but like perplexity is basically the inverse of the probability with model wants to not be perplexed in predicting the next word correctly. And so that is a powerful idea. But nothing in that will let an LM eventually realize that, well, you know, the best way to reduce perplexity is if every sequence ever uttered, and any sequence that will ever be uttered is just the letter A. Now, if the model was trained on just sequences of letters A, and no human was ever around anymore, and all sequences were just producing a letter A, now you'd have perfect predictive probability on the next step. And so maybe the best way for the LM is to wipe out all of humanity and then just produce letters A and happily perfect at predicting with probability one correctly. It's so absurd. It's so absurd to think that LMS will at some point emerge to think that many steps around their task of predicting the next token. It's just not going to happen. So I think it's like, PDOOM is still zero. And then when I actually tried to engage with some folks, and I had some other conversation last year with Nick Ostrom in a German, it was in English, but published in a German newspaper like that. And I read up some of these scenarios, and I'd engage with folks who are worried about PDOOM. That's just all fantastical sci-fi semantics. It's like, oh, it's going to develop this magical great guru or like a magical new virus that is perfect in distributing, but then only will activate after like one year until everyone like all these random scenarios that are just like not feasible. And the science isn't there yet. I'm actually right now sort of on the side of the fun writing and book about the eyes for science. I think it will do incredible for us in improving science like foundation physics, chemistry, biology, and so on. And all this fear mongering, I think it's not really helpful. And again, there's no research that suggests the eye is becoming conscious. There's like a couple of people here and there, people kind of playing around with these, but nothing interesting has been published and breaks through, no breaks through has happened whatsoever in the eye, having any sense of self. And then in a lot of the other sci-fi scenarios, people are saying, oh, with the eye so intelligent, it'll convince everyone to murder each other or to murder them, like kill themselves and so on. But, you know, if the most intelligent entities were to always rule, I don't think we would have the politicians always everywhere in the world that we see, right? It's not always just the most intelligent people that run the show. And that's kind of just their incredible intelligence to convince any other person who is less intelligent, you exactly what they want. It's just not based in reality. So, I am very, very optimistic about AI. I do think there's some real problems right now, you know, AI will pick up biases, not all the biases that you pick up on the web is something that most of humanity is proud of anymore. There's racism, there's sexism, there are various kinds of biases. Some people want to use AI. So, where I agree with Joshua Benjio and others is of the three threat vectors, which is intentional misuse, accidental misuse and loss of control. Obviously, like intentional misuse is real. And so, that's not ideal. And so, yes, those are real concerns. I think open social help us understanding those threat vectors and finding the best ways to compete with them. I think people still on the internet need to understand, not trust everything they see on the internet, which has been true ever since the internet came about, hasn't really changed that much with AI. I think since Photoshop, people should already not trust any photo they see. They should be even more worried now about photos they see. And sadly, in the future, they'll have to start worrying about videos and voices, of course, just like they should have worried about photos ever since Photoshop started to really work. And so, there are a lot of concerns and I don't want to diminish them. And I do think we need to work on them. And I think different cultures will have different answers. Freedom of speech is defined differently in different countries. Like it's legal in Germany to deny the Holocaust. We learn from our history there. That's not illegal in the US. And so, different countries and different cultures and societies will answer some of the problems that AI can amplify already in the past before we'll answer these questions differently. But I don't see any any probability for a full on the scenario of like existential risks to people. It's mostly people using more and more powerful tools against other people. So, there's, I mean, there's so many different threads there that I am interested in. For one thing, I applaud you for taking time to envision positive future. I think one of the scarcest resources today, oddly, is a positive vision for the future. Like, what do we want? This, you know, it's like the Jetsons is still almost like state of the art in terms of what we would envision a great 2030s to be like. And that is kind of bizarre. So, I definitely appreciate that. I also share your, you know, I'm not a super fan, but I'm also a fan of the three body problem. And one of the early prompts that I tried with GPT for early back in the rent team program like a year and a half ago now was asking it to write some hard science fiction in the style of the three body problem about AI for, you know, do diffusion model for proteins. And I took the plan right off of the GitHub page for this protein, you know, diffusion model project, which basically said we want to create text to protein. So, you know, say or text to maybe it was more even general than that molecule or whatever. So, you know, you would be able to just specify in natural language, specifies kind of an odd word. Or, you know, to the best of your ability articulate in natural language what you're looking for into protein. And this thing would then, you know, generate it. And we are actually starting to see that there was a paper in nature not long ago, I'm hoping to do an episode with the authors that achieves that to a certain degree. But the what the AI what GPT for came back with in terms of hard science fiction about this scenario was, I think, first of all, just extremely funny because it basically ends up in a prompting war between the good guys and the bad guys and they're both like trying to out prompt each other. And so the you know, the kind of climactic scene is like the person prompting, you know, an AI to like make a protein or, you know, a molecule that will interfere with the bad guys molecule, but not harm any of the, you know, the humans or whatever. And it's just like both absurd, but also maybe not entirely absurd. You know, I mean, I am with you in that the I would order the risks the same way. You know, we already have chaos GBT. There are I recently read a research grant from a group proposing to study on the side all tendencies. Like there are people out there who want to kill everyone. Like what's up with that? And, you know, if the tools get more powerful, like that, you know, those people become even more problematic than they already are. So yes, I would put that at the top of the, you know, of the stack of like, big picture risks. And by the way, I take all the short term and medium term risks seriously too. Like this is a big tent show where like all your hopes, dreams and concerns and, you know, perhaps irrational fears like can all have a home. But I guess, you know, to sort of get to P doom zero, I still am like, I don't know, you know, all these individual crazy scenarios, sure, they're extremely unlikely, you know, the prompting war with your, you know, protein diffusion model is like absurd on the face of it. But I kind of think of like to taking the integral over that like vast space of crazy super unlikely scenarios. And then I'm kind of like, you know, there's so many of them right that space is so big. And even if the probability is like kind of vanishing, one thing you learn in calculus is like, you can, you know, that the integral can either also vanish or it can be like finite, you know, over these, you know, kind of, even if the function itself is going to zero, the integral doesn't necessarily have to go to zero over that space. So to me, that just feels like very unresolved still. And I don't think we're going to resolve that today. But I would love to hear a little bit more about your, how you think about AI agency, and also concepts of emergence in agents today, I guess I also wonder, like, is you.com gonna, you know, push more toward the agent direction, you've got like a, what I would call a research agent today, you've got a browser as well, I could, you know, should I start to expect it to take actions for me? What I've observed in the agent space is I never feel like it fails because it doesn't understand the goal or like doesn't stay on task. Let's say that never happens, but very rarely, much more often, it's just a failure of competence. So my expectation then is that like, as the competence improves, it may not be intrinsic agency, but it may be prompted agency, and it may even be like, you know, as we have more and more orchestrated systems, we may have models prompting other models to, you know, go off and do this. And it does feel like we've got, we're headed for like a lot of spinning plates. And the idea that they could kind of, you know, all come crashing down is like, that's doesn't just doesn't feel like something we can rule out. But I don't know, I can, can you help me be confident there? I'm still not. I'll go through the sound of the things you mentioned. So PDM equals zero. So you're right. As you integrate over the future, I would like to not rule out anything. So maybe I should say 10 to the minus whatever, like a time, time, number, because in the next five billion years, like all kinds of things happen, right? Like maybe as if like the three body problem, spoiler alert, like maybe some big, much more sophisticated alien species will come across. They have already developed, fasted in my time, travel, and, or, you know, just are really, really fast in getting here and various capacities. And then, you know, they have an AI and daddy, I will just like destroy all of us. So they're getting ready to like settle into the new planet before they get here. Like there's all kinds of crazy things that can happen. It's just that, like in terms of how much resources we should spend on T, like existential do versus like, you know, I'd say, yeah, I have a couple of researchers, like thinking of cool sci-fi scenarios, inspire us, like maybe like think about ways that that could be prevented, but to spend billions of dollars on it, to like, spend a lot of like, mind share, the public about it, who's already scared of any kind of technology. I mean, people are scared of vice. I mean, there's this great Twitter handle called the pessimist archive. I mean, people were scared and thought doom is happening because of the novels back in the day. People are like, all these kids, they're just in their heads reading novels. They're going to all be useless human beings in the future. Newspaper was terrible. Internet was terrible. Like there's so many things that like people thought this is the end of civilization and we're very pessimistic about. And again, not this diminishing like real, real concerns, but again, existential one, very, very likely given what we're seeing right now. And if there, it does happen at some point in the future, then I would argue that to think about the best countermeasures now is kind of like thinking about, you know, the best countermeasures against a computer going crazy when there's still a bunch of vacuum tubes and you like, well, we're going to just suck out the air of everything into the vacuum tubes. They're not going to work as well and more because they're going to break and blah, blah, blah. That was your like counterattack against the computer taking over with your current thinking of vacuum tube computers. Or it's like, you know, like it's similar to the internet, you know, if you thought about what's the internet going to be, how could it be so terrible? Zero of the TCT IP experts in the early ARPANET days realized that at some point, maybe a foreign power could interfere with local elections because like you can say whatever you want online and maybe people get followers in their social media. Like no one had victimized in the 70s and the early ARPANET days. And so I think most of the threat vectors are not that useful in terms of key doom kind of research. I have a couple of folks work on it, but not take up as much mind space and scare like late people and non-experts even more about the technology that even without consciousness is still going to have major destruction, right? If you're going through a new step function in human productivity, just like, you know, agriculture versus like hunting and gathering and the steam engine and electricity and internet, like this one's going to be even bigger. It's going to disrupt and change the job landscape a lot. I think at the end of it will be way more productive. There's going to be way more productivity per person and hence more wells and new jobs will come around as full jobs get all needed. But that is already so massively disruptive still. And it's not going to happen overnight either. People think, oh, it's going to be capacity. Yes, it will be faster, but still not overnight. There are still companies that aren't even on the cloud. There are some stretches in the United States and even Germany that don't have full internet connectivity, right? It's just like, so things will take time and not happen overnight, but they will be happening even faster than past past technological revolutions. And so, and then you have brought up LMS and proteins. There's a great example for where regulation makes sense. Like, basically, the concern here for those who are not familiar with proteins, having everything in life and disease and sickness, COVID, protein, like everything SARS broke through and like everything is governed by proteins. So if you have a great understanding of proteins, we can build fantastical, amazing things. Here's just one example of a research paper I read a few months ago that just blew my mind and made me very excited about the future. There's this group of researchers that built these carbon nanotubes. And on one side of the carbon nanotubes, they put iron molecules. And on the other side of these tiny, tiny carbon nanotubes, they put protein that would only bind to a brain cancer cell. And then they injected this fluid with all these little carbon nanotubes into a mouse brain that had brain cancer. The proteins found the brain tumor cells and only connected to those specific types of brain cancer cells. And then they put the mouse into a little magnetic field and there's the iron molecule on the other side of the carbon nanotube that started spinning around and had nano surgery on each brain cancer cell. Now, if you think about, we have the full console of the proteins, we can connect them to all kinds of things and you find ways to, you know, get rid of the carbon nanotubes afterwards. It's all like medicine is going to change in so many positive ways. And now you could argue, well, but proteins, people could use them and build like very bad like viruses. And like, that's true. And that can be outlawed. In fact, the US just a couple of months ago outlawed being a function where you know, some researchers want to make even more deadlier viruses. And it's not because they're like evil scientists who want to destroy the world. It's just they're saying like, well, as we know how they worked before they appear in nature by themselves, then we can all right now prevent like, develop cures for them. So, you know, it's like, it's a complex question, but yes, and decided like, for now, it's not worth it. Let's outlaw it. And likewise, I don't think an open source like protein model is going to be the main deciding factor of being able to create something virus. Because if you have all the wet lab experimentation to be able to create new kinds of viruses, you can also just do what census Arnold did when she won the Nobel Prize a couple years ago in chemistry, which is what she called directed evolution, but it was basically random permutations. And then running an experimental pipeline to see if that random permutation works better or not for particular kind of protein. And then you just keep iterating like that. And so if you have those capabilities, you have a random permutation, you can do bad things. But it turns out having like a legit weapon like that, that's to do all of that. So that was your PDUM integral, LM and proteins, AI agency emergence. So obviously, emerging capabilities are incredible on that sort of like, even us like working in deep learning, or I'm amazed, just like you.com, I asked these questions, I'm like, wow, actually, that's right, like, I would have not to like, thought this was possible. And sometimes we were like, did you program it specifically for it to be able to answer these kinds of questions about headphones or something? We're like, no, it's just like, just put that all together, just by trying to predict the next token. So I'm really excited. And one of the things I'm excited about this pudding, and one of the things that coding enables is now is the last part of your question, the actions. I think actions are clearly in the future. And for now, we're focused on amazing answers. But it's not hard to imagine that at some point, the most amazing answer is done. I did, I did what you asked to do. And instead of telling you how to do it, I just, right, you can build a really cool demo very quickly for these kinds of things. But the problem is like, as much as I love natural language, and as much as I love chatbots and everything, right, you have to find some really killer use cases for it. And to say, oh, I can book this flight, it's actually really hard to just, just book the flight. Like, you're like, why didn't you like pick this other one that was just like, not exactly the time I asked for it, but I could have waited for half an hour at this like, extra leg, and then like, say 50 bucks, like that was really dumb. And like, it turns out, Expedia and others have built for decades, the perfect interface for that problem, so that humans have all the installation right there in a visual way. And so there's an uncanny valley of, there's a cool tech demo. And on one side, and then there's like, my actual human assistant, who after months of I mean, like talking to me, understand all the trade offs, and understand my price sensitivity, or that of my company, and knows like, when I would preserve and like, all the like, reasons why I might do it overnight, like red-eye slides, and, you know, all the, all the constraints, and she can do it. And even then, sometimes she's like, oh, Richard, there are like three options here, like, let me know which one you prefer out of this 5000, if you built it for you. And like, it's very hard to do all of that with just text. That's ultimately, I think, part of why we have the stock ticker app and so on, and why we have religious now, and in some cases also, is that sometimes like UI UX and actual visually designed like interfaces are best used in combination with language. Maybe one more big picture question, and then I want to do just a real quick lightning round on a couple kind of more technical areas before we run out of time. On the big picture side, you know, we've got Sam Altman out there saying AGI is coming soon, but also kind of confusingly saying, but it'll be less impactful than you might think. Not really sure how to interpret that. The median guess on, you know, some definition of AGI is like, just a few years on some prediction markets and more like, you know, 12 years or whatever for a stronger definition. What do you have sort of an expectation for, and a definition or like a threshold that you have in mind of like, this is the threshold that really matters and, you know, loosely speaking, like what sort of timeline you would expect it to take to get there? It's very much a, the kind of question where you have to be very careful about your terminology, because the interpretation of AGI has vastly different associations. Like people, some people think of AGI and used to think of AGI as this super intelligence. It's conscious as self-awareness can set its own goals. And it is more intelligent than all human beings. And, and that's their depth. That was, that was for a long time. A lot of us, I thought, at least for me personally, also the definition. Now people said, and I think it's partially because of marketing, like, you know, you want to be working on AGI, but you also need to have ship stuff. It's like, you want to be multi-tenetary species, but you also need to just get a lot of stuff in orbit, right? Let have more satellites and better internet connectivity, and so on. So you have this long-term vision and the best companies are able to articulate that long-term vision and then revenue generated progress in smaller milestones towards it. And so in this case here, I think the definition of AGI was pulled out. And then the super intelligence was defined as like, okay, that's even more than general. It's super. And that's the really long-term stuff. And now AGI, it's just basically automating point. And if you define AGI, which I think is not crazy, I want to say maybe it would be not post that, which is a very pragmatic sort of investor slash financial slash economic definition of AGI, which is 80% of the jobs can be automated up to 80%. And if that's achieved, we'll call it AGI. Turns out there's just a lot of jobs that are quite repetitive and they're not requiring a ton of extremely novel, out-of-the-box thinking that no one's ever done before. And like learning very complex new behaviors, bot-shaking, identifying new experiments, collecting new data and pushing, you know, the science forward and so on. It turns out there's just a lot of boring, repetitive jobs. And indeed, if your definition of AGI is just like, well, we can automate like 80% of 80% of the jobs, then I think it's not crazy to assume especially I would restrict it one on the wall way, which is digitized jobs, jobs that are purely happening in your browser or on your computer, because those jobs can collect training data at massive scales. Turns out no one's collecting training data for plumbers, for woofers, for tylers, for maids, like cleaning tees or any of that. And so none of those jobs are going to get automated anytime soon. Because you first have to collect many years of that such training data before you can then use AI to train on that and then automate it. But, you know, jobs that are fully digitized and that have a lot of training data that don't have a crazy long tail of special cases, they're going to get automated. And I think that's reasonable to say that's 80% of jobs. For hunches, even in radiology, for instance, you could probably do 80% find 80% of things that are wrong in HET's t-stand. But then there's still this very long tail of 20% that you just don't have enough training data for. Radiologists never see it in their lifetime, they just read about it once in a book. And we're still not quite good enough of one shot and zero shot learning. Obviously, huge amounts of progress, but not in super important things like radiology, where you just read about a case once in a book and then identify it with 100% accuracy, which is also a question of whether humans do it. I'm actually with you on the self-driving car. There's going to be a lot of interesting questions as AGI rolls into more and more workplaces, which is how much better than a human that has to be. And how, and it's deeply philosophical, very quickly, because if you're purely utilitarian, you could say, well, you know, 100,000 miles or whatever 20 million miles driven by AI results in 10,000 deaths. And the same amount of miles driven by humans results in five times more deaths. And so one is better than the odds. But if that one dead person in the AI car was your daughter, you don't care, you're gonna, like in the US, you're gonna sue, you're gonna, you know, try to end that company, because they're responsible now for the death of your child. And like, it's a very emotional thing, not a statistical thing anymore. And so there's gonna be a lot of litigation as those come out. And I think the silver lining is again, of course, as the I meets the state, you can learn from it versus like one person texting again on their cell phone, which is already illegal and running like over some kid that ran out, like, they're going too fast also, which is already illegal, too, you can't really do that much more than needing it legal. AGI will have a huge amount of impact. Once it's just like, okay, repetitive jobs, get like two large degree automated, and I'm with the people saying that will happen next few years. When it comes to like, super intelligence, that is fully conscious and can do all the things. And one intelligent, then not just a single human, but that all of humanity, very hard to know, because no one's working on it and making sort of progress along the lines of setting my own goals. And again, like, unless you set your own goals, I don't know if I would achieve full on super intelligence to you. Like if you're just your objective function is to minimize cross entropy errors, or reduce the plexity, or like segment, which is well, or like, none of that, I wanted to reach. Do you have time for a lightning round? Or do we need to leave it there? Let's try to be lightning rounds. All right. Thinking also about retrieval, memory, and online learning as kind of three frontiers that, you know, you dot com could could improve on if they're, you know, if there are research breakthroughs, but also these do seem to be kind of ingredients toward this bigger picture of AGI or even, you know, at some point, ASI, I guess I'm, you know, maybe just leave it open ended, like, what are you excited about in those domains? Are there research directions? Are there, you know, are there papers you've already seen or things you think people should be doing that you think will kind of provide meaningful unlocks as we find, you know, new and better ways to do those things? Yeah. So I'm a fan of all three, of course, I'll try to keep it short. Retrieval is awesome. I think in some ways, short-term memory is currently in the front, retrieval is in the, you know, rag. If you go up method generation, we do it over a web, we let you up those files now, so you wouldn't do it over, over a file. And then we have the smart personalization that actually is online learning. So as you say, certain things like it will, it will remember them about you. And then, you know, you can turn it off also. And it's very transparent. And the whole thing off or the automated smart learning without you, if you don't want it. But yeah, I think that's sort of a simple sort of pragmatic way of online learning. I think ultimately, you know, it'll be awesome to have AI systems get better and better of just adapting right away to user feedback, both in terms of, you know, thumbs up, thumbs down kinds of clicking, but also in conversation, I didn't like that answer. And then updating the answer in a principled way for the future. I have so many more thoughts, but I'll like, I'd love to do a second one. These are kind of crazy days. Now the Apple announcement, we just announced that Julianne, CTO, I mean, say also just became an angel investor and a lot of exciting stuff happening. So I yeah, well, congratulations on the Apple thing and also on a new prominent angel investor. And really some fantastic product progress. I definitely recommend everybody to try out particularly genius mode and research mode. And I think if you do that, you will be coming back to you.com more and more often. So keep up the great work. For now, I will say Richard Sosher, founder and CEO of you.com. Thank you for being part of the cognitive revolution. Thank you so much. It is both energizing and enlightening to hear why people listen and learn what they value about the show. So please don't hesitate to reach out via email at TCR at turpentine.co, or you can DM me on the social media platform of your choice. Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work customized across all platforms with a click of a button. I believe in Omniki so much that I invested in it and I recommend you use it too. Use Kogrev to get a 10% discount.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.92, "text": " early 2022, or like we had apps that would write code for you within the search results,", "tokens": [50364, 2440, 20229, 11, 420, 411, 321, 632, 7733, 300, 576, 2464, 3089, 337, 291, 1951, 264, 3164, 3542, 11, 50660], "temperature": 0.0, "avg_logprob": -0.1460629499183511, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.12740537524223328}, {"id": 1, "seek": 0, "start": 5.92, "end": 10.24, "text": " through the apps that write essays for you within the search results. But whenever we", "tokens": [50660, 807, 264, 7733, 300, 2464, 35123, 337, 291, 1951, 264, 3164, 3542, 13, 583, 5699, 321, 50876], "temperature": 0.0, "avg_logprob": -0.1460629499183511, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.12740537524223328}, {"id": 2, "seek": 0, "start": 10.24, "end": 15.6, "text": " innovated and changed the default Google experience too much, we had just like the vast", "tokens": [50876, 5083, 770, 293, 3105, 264, 7576, 3329, 1752, 886, 709, 11, 321, 632, 445, 411, 264, 8369, 51144], "temperature": 0.0, "avg_logprob": -0.1460629499183511, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.12740537524223328}, {"id": 3, "seek": 0, "start": 15.6, "end": 20.240000000000002, "text": " majority of our users say, I'm so used to Google, I don't want another way of finding answers.", "tokens": [51144, 6286, 295, 527, 5022, 584, 11, 286, 478, 370, 1143, 281, 3329, 11, 286, 500, 380, 528, 1071, 636, 295, 5006, 6338, 13, 51376], "temperature": 0.0, "avg_logprob": -0.1460629499183511, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.12740537524223328}, {"id": 4, "seek": 0, "start": 20.8, "end": 26.16, "text": " And so we kept getting pulled back to this need. And so the most amazing surprise was when", "tokens": [51404, 400, 370, 321, 4305, 1242, 7373, 646, 281, 341, 643, 13, 400, 370, 264, 881, 2243, 6365, 390, 562, 51672], "temperature": 0.0, "avg_logprob": -0.1460629499183511, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.12740537524223328}, {"id": 5, "seek": 2616, "start": 26.24, "end": 30.8, "text": " ChachiP came out, all of a sudden people got it. And it was like, wait a minute,", "tokens": [50368, 761, 21791, 47, 1361, 484, 11, 439, 295, 257, 3990, 561, 658, 309, 13, 400, 309, 390, 411, 11, 1699, 257, 3456, 11, 50596], "temperature": 0.0, "avg_logprob": -0.16372163328405928, "compression_ratio": 1.7348242811501597, "no_speech_prob": 0.032089512795209885}, {"id": 6, "seek": 2616, "start": 30.8, "end": 36.0, "text": " it could just be like pure text. And we're like, been trying to sort of slowly get there, but", "tokens": [50596, 309, 727, 445, 312, 411, 6075, 2487, 13, 400, 321, 434, 411, 11, 668, 1382, 281, 1333, 295, 5692, 483, 456, 11, 457, 50856], "temperature": 0.0, "avg_logprob": -0.16372163328405928, "compression_ratio": 1.7348242811501597, "no_speech_prob": 0.032089512795209885}, {"id": 7, "seek": 2616, "start": 36.0, "end": 40.24, "text": " we had to make a bigger job. The way I think about the different modes is like the default", "tokens": [50856, 321, 632, 281, 652, 257, 3801, 1691, 13, 440, 636, 286, 519, 466, 264, 819, 14068, 307, 411, 264, 7576, 51068], "temperature": 0.0, "avg_logprob": -0.16372163328405928, "compression_ratio": 1.7348242811501597, "no_speech_prob": 0.032089512795209885}, {"id": 8, "seek": 2616, "start": 40.24, "end": 44.56, "text": " smart mode is kind of like, if you had an assistant, and you just ask them to do a quick", "tokens": [51068, 4069, 4391, 307, 733, 295, 411, 11, 498, 291, 632, 364, 10994, 11, 293, 291, 445, 1029, 552, 281, 360, 257, 1702, 51284], "temperature": 0.0, "avg_logprob": -0.16372163328405928, "compression_ratio": 1.7348242811501597, "no_speech_prob": 0.032089512795209885}, {"id": 9, "seek": 2616, "start": 44.56, "end": 49.760000000000005, "text": " a search, and in like two or three minutes, give you an answer that. And then genius mode,", "tokens": [51284, 257, 3164, 11, 293, 294, 411, 732, 420, 1045, 2077, 11, 976, 291, 364, 1867, 300, 13, 400, 550, 14017, 4391, 11, 51544], "temperature": 0.0, "avg_logprob": -0.16372163328405928, "compression_ratio": 1.7348242811501597, "no_speech_prob": 0.032089512795209885}, {"id": 10, "seek": 2616, "start": 49.760000000000005, "end": 54.480000000000004, "text": " you go and so you want to ask your assistant for a question that they have to be able to program,", "tokens": [51544, 291, 352, 293, 370, 291, 528, 281, 1029, 428, 10994, 337, 257, 1168, 300, 436, 362, 281, 312, 1075, 281, 1461, 11, 51780], "temperature": 0.0, "avg_logprob": -0.16372163328405928, "compression_ratio": 1.7348242811501597, "no_speech_prob": 0.032089512795209885}, {"id": 11, "seek": 5448, "start": 54.559999999999995, "end": 58.959999999999994, "text": " they have to search the web, and then they need to be mathematically applying to answer that", "tokens": [50368, 436, 362, 281, 3164, 264, 3670, 11, 293, 550, 436, 643, 281, 312, 44003, 9275, 281, 1867, 300, 50588], "temperature": 0.0, "avg_logprob": -0.11223495707792394, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0009398726979270577}, {"id": 12, "seek": 5448, "start": 58.959999999999994, "end": 63.839999999999996, "text": " question. I mean, as a kid, I also enjoyed watching Terminator. It's like a cool action movie,", "tokens": [50588, 1168, 13, 286, 914, 11, 382, 257, 1636, 11, 286, 611, 4626, 1976, 19835, 31927, 13, 467, 311, 411, 257, 1627, 3069, 3169, 11, 50832], "temperature": 0.0, "avg_logprob": -0.11223495707792394, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0009398726979270577}, {"id": 13, "seek": 5448, "start": 63.839999999999996, "end": 70.0, "text": " but it's just taken over so much of the AI narrative. And it's actually like actively", "tokens": [50832, 457, 309, 311, 445, 2726, 670, 370, 709, 295, 264, 7318, 9977, 13, 400, 309, 311, 767, 411, 13022, 51140], "temperature": 0.0, "avg_logprob": -0.11223495707792394, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0009398726979270577}, {"id": 14, "seek": 5448, "start": 70.0, "end": 74.72, "text": " hurting, especially European Union. Hello, and welcome to the Cognitive Revolution,", "tokens": [51140, 17744, 11, 2318, 6473, 8133, 13, 2425, 11, 293, 2928, 281, 264, 383, 2912, 2187, 16617, 11, 51376], "temperature": 0.0, "avg_logprob": -0.11223495707792394, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0009398726979270577}, {"id": 15, "seek": 5448, "start": 74.72, "end": 79.12, "text": " where we interview visionary researchers, entrepreneurs and builders working on the", "tokens": [51376, 689, 321, 4049, 49442, 10309, 11, 12639, 293, 36281, 1364, 322, 264, 51596], "temperature": 0.0, "avg_logprob": -0.11223495707792394, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0009398726979270577}, {"id": 16, "seek": 5448, "start": 79.12, "end": 84.4, "text": " frontier of artificial intelligence. Each week, we'll explore their revolutionary ideas,", "tokens": [51596, 35853, 295, 11677, 7599, 13, 6947, 1243, 11, 321, 603, 6839, 641, 22687, 3487, 11, 51860], "temperature": 0.0, "avg_logprob": -0.11223495707792394, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0009398726979270577}, {"id": 17, "seek": 8440, "start": 84.4, "end": 88.24000000000001, "text": " and together we'll build a picture of how AI technology will transform work,", "tokens": [50364, 293, 1214, 321, 603, 1322, 257, 3036, 295, 577, 7318, 2899, 486, 4088, 589, 11, 50556], "temperature": 0.0, "avg_logprob": -0.137110176436398, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.0008828597492538393}, {"id": 18, "seek": 8440, "start": 88.80000000000001, "end": 94.72, "text": " life, and society in the coming years. I'm Nathan LaBenz, joined by my cohost, Eric Tornberg.", "tokens": [50584, 993, 11, 293, 4086, 294, 264, 1348, 924, 13, 286, 478, 20634, 2369, 33, 11368, 11, 6869, 538, 452, 598, 6037, 11, 9336, 314, 1865, 6873, 13, 50880], "temperature": 0.0, "avg_logprob": -0.137110176436398, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.0008828597492538393}, {"id": 19, "seek": 8440, "start": 95.28, "end": 99.92, "text": " Hello, and welcome back to the Cognitive Revolution. Today, I am thrilled to welcome", "tokens": [50908, 2425, 11, 293, 2928, 646, 281, 264, 383, 2912, 2187, 16617, 13, 2692, 11, 286, 669, 18744, 281, 2928, 51140], "temperature": 0.0, "avg_logprob": -0.137110176436398, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.0008828597492538393}, {"id": 20, "seek": 8440, "start": 99.92, "end": 105.04, "text": " Richard Socher, a pioneer of deep learning for natural language processing, formerly chief", "tokens": [51140, 9809, 407, 6759, 11, 257, 37668, 295, 2452, 2539, 337, 3303, 2856, 9007, 11, 34777, 9588, 51396], "temperature": 0.0, "avg_logprob": -0.137110176436398, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.0008828597492538393}, {"id": 21, "seek": 8440, "start": 105.04, "end": 110.96000000000001, "text": " scientist at Salesforce, and today, founder and CEO of u.com, a company that was first", "tokens": [51396, 12662, 412, 40398, 11, 293, 965, 11, 14917, 293, 9282, 295, 344, 13, 1112, 11, 257, 2237, 300, 390, 700, 51692], "temperature": 0.0, "avg_logprob": -0.137110176436398, "compression_ratio": 1.493103448275862, "no_speech_prob": 0.0008828597492538393}, {"id": 22, "seek": 11096, "start": 110.96, "end": 116.0, "text": " introduced to the public as a new kind of search engine, but which now describes itself as an AI", "tokens": [50364, 7268, 281, 264, 1908, 382, 257, 777, 733, 295, 3164, 2848, 11, 457, 597, 586, 15626, 2564, 382, 364, 7318, 50616], "temperature": 0.0, "avg_logprob": -0.050932476821454985, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.001032003085128963}, {"id": 23, "seek": 11096, "start": 116.0, "end": 123.75999999999999, "text": " assistant that makes you more productive, creative, and extraordinary. Richard has deep history in", "tokens": [50616, 10994, 300, 1669, 291, 544, 13304, 11, 5880, 11, 293, 10581, 13, 9809, 575, 2452, 2503, 294, 51004], "temperature": 0.0, "avg_logprob": -0.050932476821454985, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.001032003085128963}, {"id": 24, "seek": 11096, "start": 123.75999999999999, "end": 128.79999999999998, "text": " deep learning. He was among the very first to recognize the potential of neural networks", "tokens": [51004, 2452, 2539, 13, 634, 390, 3654, 264, 588, 700, 281, 5521, 264, 3995, 295, 18161, 9590, 51256], "temperature": 0.0, "avg_logprob": -0.050932476821454985, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.001032003085128963}, {"id": 25, "seek": 11096, "start": 128.79999999999998, "end": 134.24, "text": " in the natural language processing domain, and his work has helped shape the field as we know it", "tokens": [51256, 294, 264, 3303, 2856, 9007, 9274, 11, 293, 702, 589, 575, 4254, 3909, 264, 2519, 382, 321, 458, 309, 51528], "temperature": 0.0, "avg_logprob": -0.050932476821454985, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.001032003085128963}, {"id": 26, "seek": 11096, "start": 134.24, "end": 139.76, "text": " over the last decade. In this conversation, Richard takes us on a brief journey through his own", "tokens": [51528, 670, 264, 1036, 10378, 13, 682, 341, 3761, 11, 9809, 2516, 505, 322, 257, 5353, 4671, 807, 702, 1065, 51804], "temperature": 0.0, "avg_logprob": -0.050932476821454985, "compression_ratio": 1.6620209059233448, "no_speech_prob": 0.001032003085128963}, {"id": 27, "seek": 13976, "start": 139.76, "end": 145.04, "text": " intellectual history and reflects on how the field of AI has evolved in both expected and", "tokens": [50364, 12576, 2503, 293, 18926, 322, 577, 264, 2519, 295, 7318, 575, 14178, 294, 1293, 5176, 293, 50628], "temperature": 0.0, "avg_logprob": -0.0603214456484868, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.005908122751861811}, {"id": 28, "seek": 13976, "start": 145.04, "end": 151.2, "text": " surprising ways. Before we dive deep into the u.com product itself, covering the historical", "tokens": [50628, 8830, 2098, 13, 4546, 321, 9192, 2452, 666, 264, 344, 13, 1112, 1674, 2564, 11, 10322, 264, 8584, 50936], "temperature": 0.0, "avg_logprob": -0.0603214456484868, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.005908122751861811}, {"id": 29, "seek": 13976, "start": 151.2, "end": 155.44, "text": " challenge that they faced when trying to compete with Google and how the rise of the AI chatbot", "tokens": [50936, 3430, 300, 436, 11446, 562, 1382, 281, 11831, 365, 3329, 293, 577, 264, 6272, 295, 264, 7318, 5081, 18870, 51148], "temperature": 0.0, "avg_logprob": -0.0603214456484868, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.005908122751861811}, {"id": 30, "seek": 13976, "start": 155.44, "end": 161.51999999999998, "text": " paradigm has broadened the space of possibility for search and discovery products. We also look", "tokens": [51148, 24709, 575, 4152, 5320, 264, 1901, 295, 7959, 337, 3164, 293, 12114, 3383, 13, 492, 611, 574, 51452], "temperature": 0.0, "avg_logprob": -0.0603214456484868, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.005908122751861811}, {"id": 31, "seek": 13976, "start": 161.51999999999998, "end": 167.12, "text": " at u.com's various modes with particular emphasis on the genius mode and above all, for me, the", "tokens": [51452, 412, 344, 13, 1112, 311, 3683, 14068, 365, 1729, 16271, 322, 264, 14017, 4391, 293, 3673, 439, 11, 337, 385, 11, 264, 51732], "temperature": 0.0, "avg_logprob": -0.0603214456484868, "compression_ratio": 1.6514084507042253, "no_speech_prob": 0.005908122751861811}, {"id": 32, "seek": 16712, "start": 167.12, "end": 172.72, "text": " research mode, which delivers amazingly helpful and thorough report style answers, even on some", "tokens": [50364, 2132, 4391, 11, 597, 24860, 31762, 4961, 293, 12934, 2275, 3758, 6338, 11, 754, 322, 512, 50644], "temperature": 0.0, "avg_logprob": -0.0754773734819771, "compression_ratio": 1.6146179401993355, "no_speech_prob": 0.0006069776718504727}, {"id": 33, "seek": 16712, "start": 172.72, "end": 178.96, "text": " remarkably complex topics. We also briefly discussed the future of AI business models as well,", "tokens": [50644, 37381, 3997, 8378, 13, 492, 611, 10515, 7152, 264, 2027, 295, 7318, 1606, 5245, 382, 731, 11, 50956], "temperature": 0.0, "avg_logprob": -0.0754773734819771, "compression_ratio": 1.6146179401993355, "no_speech_prob": 0.0006069776718504727}, {"id": 34, "seek": 16712, "start": 178.96, "end": 184.32, "text": " including the obvious subscription and my pet theory about the AI bundle. Along the way, we touch", "tokens": [50956, 3009, 264, 6322, 17231, 293, 452, 3817, 5261, 466, 264, 7318, 24438, 13, 17457, 264, 636, 11, 321, 2557, 51224], "temperature": 0.0, "avg_logprob": -0.0754773734819771, "compression_ratio": 1.6146179401993355, "no_speech_prob": 0.0006069776718504727}, {"id": 35, "seek": 16712, "start": 184.32, "end": 189.28, "text": " on a number of important topics, too. The limits to AI systems' reasoning ability and the prospects", "tokens": [51224, 322, 257, 1230, 295, 1021, 8378, 11, 886, 13, 440, 10406, 281, 7318, 3652, 6, 21577, 3485, 293, 264, 32933, 51472], "temperature": 0.0, "avg_logprob": -0.0754773734819771, "compression_ratio": 1.6146179401993355, "no_speech_prob": 0.0006069776718504727}, {"id": 36, "seek": 16712, "start": 189.28, "end": 194.4, "text": " for the improvement that would be needed for reliable autonomy, the potential for AI to transform", "tokens": [51472, 337, 264, 10444, 300, 576, 312, 2978, 337, 12924, 27278, 11, 264, 3995, 337, 7318, 281, 4088, 51728], "temperature": 0.0, "avg_logprob": -0.0754773734819771, "compression_ratio": 1.6146179401993355, "no_speech_prob": 0.0006069776718504727}, {"id": 37, "seek": 19440, "start": 194.4, "end": 200.16, "text": " medicine and scientific research, Richard's case for general optimism, even though he does expect", "tokens": [50364, 7195, 293, 8134, 2132, 11, 9809, 311, 1389, 337, 2674, 31074, 11, 754, 1673, 415, 775, 2066, 50652], "temperature": 0.0, "avg_logprob": -0.05697871643362693, "compression_ratio": 1.598639455782313, "no_speech_prob": 0.003171962685883045}, {"id": 38, "seek": 19440, "start": 200.16, "end": 205.6, "text": " AI to drive major disruption, why he's not worried about so-called emergent capabilities,", "tokens": [50652, 7318, 281, 3332, 2563, 28751, 11, 983, 415, 311, 406, 5804, 466, 370, 12, 11880, 4345, 6930, 10862, 11, 50924], "temperature": 0.0, "avg_logprob": -0.05697871643362693, "compression_ratio": 1.598639455782313, "no_speech_prob": 0.003171962685883045}, {"id": 39, "seek": 19440, "start": 205.6, "end": 210.96, "text": " but does take the risk of intentional harmful misuse very seriously, and lots more little", "tokens": [50924, 457, 775, 747, 264, 3148, 295, 21935, 19727, 3346, 438, 588, 6638, 11, 293, 3195, 544, 707, 51192], "temperature": 0.0, "avg_logprob": -0.05697871643362693, "compression_ratio": 1.598639455782313, "no_speech_prob": 0.003171962685883045}, {"id": 40, "seek": 19440, "start": 210.96, "end": 216.96, "text": " topics along the way as well. Richard is a leading thinker in the AI space, and his perspective", "tokens": [51192, 8378, 2051, 264, 636, 382, 731, 13, 9809, 307, 257, 5775, 519, 260, 294, 264, 7318, 1901, 11, 293, 702, 4585, 51492], "temperature": 0.0, "avg_logprob": -0.05697871643362693, "compression_ratio": 1.598639455782313, "no_speech_prob": 0.003171962685883045}, {"id": 41, "seek": 19440, "start": 216.96, "end": 221.6, "text": " is essential for anyone who wants to understand where this technology is going and what it means", "tokens": [51492, 307, 7115, 337, 2878, 567, 2738, 281, 1223, 689, 341, 2899, 307, 516, 293, 437, 309, 1355, 51724], "temperature": 0.0, "avg_logprob": -0.05697871643362693, "compression_ratio": 1.598639455782313, "no_speech_prob": 0.003171962685883045}, {"id": 42, "seek": 22160, "start": 221.6, "end": 228.0, "text": " for the future of humanity. And in all seriousness, I really do recommend u.com. It has absolutely", "tokens": [50364, 337, 264, 2027, 295, 10243, 13, 400, 294, 439, 44880, 11, 286, 534, 360, 2748, 344, 13, 1112, 13, 467, 575, 3122, 50684], "temperature": 0.0, "avg_logprob": -0.06285346292816432, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.02032461389899254}, {"id": 43, "seek": 22160, "start": 228.0, "end": 233.2, "text": " joined the ranks of the AI tools that I use multiple times each week. And particularly,", "tokens": [50684, 6869, 264, 21406, 295, 264, 7318, 3873, 300, 286, 764, 3866, 1413, 1184, 1243, 13, 400, 4098, 11, 50944], "temperature": 0.0, "avg_logprob": -0.06285346292816432, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.02032461389899254}, {"id": 44, "seek": 22160, "start": 233.2, "end": 240.0, "text": " when I want a comprehensive, multi-page report style answer, I find that u.com's research mode", "tokens": [50944, 562, 286, 528, 257, 13914, 11, 4825, 12, 15161, 2275, 3758, 1867, 11, 286, 915, 300, 344, 13, 1112, 311, 2132, 4391, 51284], "temperature": 0.0, "avg_logprob": -0.06285346292816432, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.02032461389899254}, {"id": 45, "seek": 22160, "start": 240.0, "end": 246.16, "text": " is often the single best tool available today. As always, if you're finding value in the show,", "tokens": [51284, 307, 2049, 264, 2167, 1151, 2290, 2435, 965, 13, 1018, 1009, 11, 498, 291, 434, 5006, 2158, 294, 264, 855, 11, 51592], "temperature": 0.0, "avg_logprob": -0.06285346292816432, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.02032461389899254}, {"id": 46, "seek": 22160, "start": 246.16, "end": 249.68, "text": " we would appreciate it if you'd share it with friends or post a review to Apple podcasts", "tokens": [51592, 321, 576, 4449, 309, 498, 291, 1116, 2073, 309, 365, 1855, 420, 2183, 257, 3131, 281, 6373, 24045, 51768], "temperature": 0.0, "avg_logprob": -0.06285346292816432, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.02032461389899254}, {"id": 47, "seek": 24968, "start": 249.68, "end": 254.96, "text": " or Spotify, or just leave a comment on YouTube. Now, without further ado, I hope you enjoyed", "tokens": [50364, 420, 29036, 11, 420, 445, 1856, 257, 2871, 322, 3088, 13, 823, 11, 1553, 3052, 22450, 11, 286, 1454, 291, 4626, 50628], "temperature": 0.0, "avg_logprob": -0.088082133746538, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.06752463430166245}, {"id": 48, "seek": 24968, "start": 254.96, "end": 260.16, "text": " this conversation with Richard Sosher of u.com. Well, let's do it. I think this is going to be", "tokens": [50628, 341, 3761, 365, 9809, 318, 329, 511, 295, 344, 13, 1112, 13, 1042, 11, 718, 311, 360, 309, 13, 286, 519, 341, 307, 516, 281, 312, 50888], "temperature": 0.0, "avg_logprob": -0.088082133746538, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.06752463430166245}, {"id": 49, "seek": 24968, "start": 260.16, "end": 264.0, "text": " a lot of fun. I'm looking forward to your point of view on a bunch of very interesting topics.", "tokens": [50888, 257, 688, 295, 1019, 13, 286, 478, 1237, 2128, 281, 428, 935, 295, 1910, 322, 257, 3840, 295, 588, 1880, 8378, 13, 51080], "temperature": 0.0, "avg_logprob": -0.088082133746538, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.06752463430166245}, {"id": 50, "seek": 24968, "start": 264.64, "end": 269.36, "text": " Richard Sosher, founder and CEO of u.com, welcome to the Cognitive Revolution.", "tokens": [51112, 9809, 318, 329, 511, 11, 14917, 293, 9282, 295, 344, 13, 1112, 11, 2928, 281, 264, 383, 2912, 2187, 16617, 13, 51348], "temperature": 0.0, "avg_logprob": -0.088082133746538, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.06752463430166245}, {"id": 51, "seek": 24968, "start": 270.24, "end": 276.48, "text": " Thanks for having me. I am very excited to have you. You are at the intersection of so", "tokens": [51392, 2561, 337, 1419, 385, 13, 286, 669, 588, 2919, 281, 362, 291, 13, 509, 366, 412, 264, 15236, 295, 370, 51704], "temperature": 0.0, "avg_logprob": -0.088082133746538, "compression_ratio": 1.5830388692579505, "no_speech_prob": 0.06752463430166245}, {"id": 52, "seek": 27648, "start": 276.48, "end": 281.12, "text": " many interesting things. I sometimes have been describing myself recently as the forest gump of", "tokens": [50364, 867, 1880, 721, 13, 286, 2171, 362, 668, 16141, 2059, 3938, 382, 264, 6719, 290, 1420, 295, 50596], "temperature": 0.0, "avg_logprob": -0.08395260572433472, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.21716080605983734}, {"id": 53, "seek": 27648, "start": 281.12, "end": 286.48, "text": " of AI because I've just kind of very unstrategically made my way through the last few years and yet", "tokens": [50596, 295, 7318, 570, 286, 600, 445, 733, 295, 588, 517, 9733, 2968, 984, 1027, 452, 636, 807, 264, 1036, 1326, 924, 293, 1939, 50864], "temperature": 0.0, "avg_logprob": -0.08395260572433472, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.21716080605983734}, {"id": 54, "seek": 27648, "start": 286.48, "end": 291.20000000000005, "text": " found myself in some very interesting places. I don't know how you think about your own trajectory,", "tokens": [50864, 1352, 2059, 294, 512, 588, 1880, 3190, 13, 286, 500, 380, 458, 577, 291, 519, 466, 428, 1065, 21512, 11, 51100], "temperature": 0.0, "avg_logprob": -0.08395260572433472, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.21716080605983734}, {"id": 55, "seek": 27648, "start": 291.20000000000005, "end": 296.56, "text": " but you are kind of an OG in the realm of deep learning and have founded this very interesting", "tokens": [51100, 457, 291, 366, 733, 295, 364, 32477, 294, 264, 15355, 295, 2452, 2539, 293, 362, 13234, 341, 588, 1880, 51368], "temperature": 0.0, "avg_logprob": -0.08395260572433472, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.21716080605983734}, {"id": 56, "seek": 27648, "start": 296.56, "end": 302.32, "text": " company and have a really awesome product, which we'll get into in more detail. And I'm interested", "tokens": [51368, 2237, 293, 362, 257, 534, 3476, 1674, 11, 597, 321, 603, 483, 666, 294, 544, 2607, 13, 400, 286, 478, 3102, 51656], "temperature": 0.0, "avg_logprob": -0.08395260572433472, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.21716080605983734}, {"id": 57, "seek": 30232, "start": 302.32, "end": 307.68, "text": " to hear about all that and your kind of philosophy and expectations for the future. So we've got a", "tokens": [50364, 281, 1568, 466, 439, 300, 293, 428, 733, 295, 10675, 293, 9843, 337, 264, 2027, 13, 407, 321, 600, 658, 257, 50632], "temperature": 0.0, "avg_logprob": -0.1096389017948488, "compression_ratio": 1.68955223880597, "no_speech_prob": 0.12587454915046692}, {"id": 58, "seek": 30232, "start": 307.68, "end": 312.24, "text": " lot of ground to cover. Maybe for starters, you want to kind of give us, and I usually even ask", "tokens": [50632, 688, 295, 2727, 281, 2060, 13, 2704, 337, 35131, 11, 291, 528, 281, 733, 295, 976, 505, 11, 293, 286, 2673, 754, 1029, 50860], "temperature": 0.0, "avg_logprob": -0.1096389017948488, "compression_ratio": 1.68955223880597, "no_speech_prob": 0.12587454915046692}, {"id": 59, "seek": 30232, "start": 312.24, "end": 316.15999999999997, "text": " these biographical questions, because these days it's like a lot of the same answers. People are", "tokens": [50860, 613, 3228, 48434, 1651, 11, 570, 613, 1708, 309, 311, 411, 257, 688, 295, 264, 912, 6338, 13, 3432, 366, 51056], "temperature": 0.0, "avg_logprob": -0.1096389017948488, "compression_ratio": 1.68955223880597, "no_speech_prob": 0.12587454915046692}, {"id": 60, "seek": 30232, "start": 316.15999999999997, "end": 320.96, "text": " like, oh, when I saw GPT-3, I thought this is going to be a big deal that I got involved. But you", "tokens": [51056, 411, 11, 1954, 11, 562, 286, 1866, 26039, 51, 12, 18, 11, 286, 1194, 341, 307, 516, 281, 312, 257, 955, 2028, 300, 286, 658, 3288, 13, 583, 291, 51296], "temperature": 0.0, "avg_logprob": -0.1096389017948488, "compression_ratio": 1.68955223880597, "no_speech_prob": 0.12587454915046692}, {"id": 61, "seek": 30232, "start": 322.0, "end": 325.12, "text": " were there at the beginning, man. So maybe you want to just give us a quick history of", "tokens": [51348, 645, 456, 412, 264, 2863, 11, 587, 13, 407, 1310, 291, 528, 281, 445, 976, 505, 257, 1702, 2503, 295, 51504], "temperature": 0.0, "avg_logprob": -0.1096389017948488, "compression_ratio": 1.68955223880597, "no_speech_prob": 0.12587454915046692}, {"id": 62, "seek": 30232, "start": 325.12, "end": 328.88, "text": " your own role in the history of deep learning and how you've kind of come to the present.", "tokens": [51504, 428, 1065, 3090, 294, 264, 2503, 295, 2452, 2539, 293, 577, 291, 600, 733, 295, 808, 281, 264, 1974, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1096389017948488, "compression_ratio": 1.68955223880597, "no_speech_prob": 0.12587454915046692}, {"id": 63, "seek": 32888, "start": 329.76, "end": 335.76, "text": " I started with AI actually in 2003, when I started studying linguistic computer science,", "tokens": [50408, 286, 1409, 365, 7318, 767, 294, 16416, 11, 562, 286, 1409, 7601, 43002, 3820, 3497, 11, 50708], "temperature": 0.0, "avg_logprob": -0.1765854686772058, "compression_ratio": 1.7415730337078652, "no_speech_prob": 0.001956578576937318}, {"id": 64, "seek": 32888, "start": 335.76, "end": 340.96, "text": " or natural language processing back in Germany. And at the time, I was like, this is really", "tokens": [50708, 420, 3303, 2856, 9007, 646, 294, 7244, 13, 400, 412, 264, 565, 11, 286, 390, 411, 11, 341, 307, 534, 50968], "temperature": 0.0, "avg_logprob": -0.1765854686772058, "compression_ratio": 1.7415730337078652, "no_speech_prob": 0.001956578576937318}, {"id": 65, "seek": 32888, "start": 340.96, "end": 345.68, "text": " interesting. I love languages, I love math, I love computers, you know, so if computers are", "tokens": [50968, 1880, 13, 286, 959, 8650, 11, 286, 959, 5221, 11, 286, 959, 10807, 11, 291, 458, 11, 370, 498, 10807, 366, 51204], "temperature": 0.0, "avg_logprob": -0.1765854686772058, "compression_ratio": 1.7415730337078652, "no_speech_prob": 0.001956578576937318}, {"id": 66, "seek": 32888, "start": 345.68, "end": 350.8, "text": " where languages and math can meet in some useful functional ways, I thought. And there's very much", "tokens": [51204, 689, 8650, 293, 5221, 393, 1677, 294, 512, 4420, 11745, 2098, 11, 286, 1194, 13, 400, 456, 311, 588, 709, 51460], "temperature": 0.0, "avg_logprob": -0.1765854686772058, "compression_ratio": 1.7415730337078652, "no_speech_prob": 0.001956578576937318}, {"id": 67, "seek": 32888, "start": 350.8, "end": 357.04, "text": " sort of a small niche subject within computer science. And I was really excited. At the time,", "tokens": [51460, 1333, 295, 257, 1359, 19956, 3983, 1951, 3820, 3497, 13, 400, 286, 390, 534, 2919, 13, 1711, 264, 565, 11, 51772], "temperature": 0.0, "avg_logprob": -0.1765854686772058, "compression_ratio": 1.7415730337078652, "no_speech_prob": 0.001956578576937318}, {"id": 68, "seek": 35704, "start": 357.04, "end": 362.88, "text": " there wasn't quite enough math for me in an LP. And I felt like we're just getting stuck in some", "tokens": [50364, 456, 2067, 380, 1596, 1547, 5221, 337, 385, 294, 364, 38095, 13, 400, 286, 2762, 411, 321, 434, 445, 1242, 5541, 294, 512, 50656], "temperature": 0.0, "avg_logprob": -0.2787461280822754, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.001571530126966536}, {"id": 69, "seek": 35704, "start": 362.88, "end": 369.6, "text": " of the legalistic special cases. And I loved the form of semantic set theory and then algebraic", "tokens": [50656, 295, 264, 5089, 3142, 2121, 3331, 13, 400, 286, 4333, 264, 1254, 295, 47982, 992, 5261, 293, 550, 21989, 299, 50992], "temperature": 0.0, "avg_logprob": -0.2787461280822754, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.001571530126966536}, {"id": 70, "seek": 35704, "start": 369.6, "end": 376.24, "text": " foundations. And so I moved eventually into computer vision during my master's. And there,", "tokens": [50992, 22467, 13, 400, 370, 286, 4259, 4728, 666, 3820, 5201, 1830, 452, 4505, 311, 13, 400, 456, 11, 51324], "temperature": 0.0, "avg_logprob": -0.2787461280822754, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.001571530126966536}, {"id": 71, "seek": 35704, "start": 376.24, "end": 381.84000000000003, "text": " I also, in Saarbr\u00fccken, at the Max Klein Institute there in the university, found statistical", "tokens": [51324, 286, 611, 11, 294, 6299, 289, 1443, 26037, 11, 412, 264, 7402, 33327, 9446, 456, 294, 264, 5454, 11, 1352, 22820, 51604], "temperature": 0.0, "avg_logprob": -0.2787461280822754, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.001571530126966536}, {"id": 72, "seek": 38184, "start": 381.84, "end": 387.2, "text": " learning and pattern recognition. And I fell in love with that. I was like, clearly, you can really", "tokens": [50364, 2539, 293, 5102, 11150, 13, 400, 286, 5696, 294, 959, 365, 300, 13, 286, 390, 411, 11, 4448, 11, 291, 393, 534, 50632], "temperature": 0.0, "avg_logprob": -0.1248976889621006, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.020632576197385788}, {"id": 73, "seek": 38184, "start": 387.2, "end": 392.79999999999995, "text": " understand patterns, any kind of pattern really well, you could solve all these different kinds", "tokens": [50632, 1223, 8294, 11, 604, 733, 295, 5102, 534, 731, 11, 291, 727, 5039, 439, 613, 819, 3685, 50912], "temperature": 0.0, "avg_logprob": -0.1248976889621006, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.020632576197385788}, {"id": 74, "seek": 38184, "start": 392.79999999999995, "end": 399.35999999999996, "text": " of problems. And so I ended up doing my PhD at Stanford. In the beginning of Stanford, I started", "tokens": [50912, 295, 2740, 13, 400, 370, 286, 4590, 493, 884, 452, 14476, 412, 20374, 13, 682, 264, 2863, 295, 20374, 11, 286, 1409, 51240], "temperature": 0.0, "avg_logprob": -0.1248976889621006, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.020632576197385788}, {"id": 75, "seek": 38184, "start": 399.35999999999996, "end": 405.91999999999996, "text": " trying to really contribute to the field rather than just learning about it. I basically found that", "tokens": [51240, 1382, 281, 534, 10586, 281, 264, 2519, 2831, 813, 445, 2539, 466, 309, 13, 286, 1936, 1352, 300, 51568], "temperature": 0.0, "avg_logprob": -0.1248976889621006, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.020632576197385788}, {"id": 76, "seek": 40592, "start": 406.0, "end": 412.48, "text": " even the top NLP people, they write their papers mostly about these beautiful models,", "tokens": [50368, 754, 264, 1192, 426, 45196, 561, 11, 436, 2464, 641, 10577, 5240, 466, 613, 2238, 5245, 11, 50692], "temperature": 0.0, "avg_logprob": -0.21398917266300746, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.053357940167188644}, {"id": 77, "seek": 40592, "start": 412.48, "end": 417.04, "text": " like conditional random fields, late in university, other patient types of models.", "tokens": [50692, 411, 27708, 4974, 7909, 11, 3469, 294, 5454, 11, 661, 4537, 3467, 295, 5245, 13, 50920], "temperature": 0.0, "avg_logprob": -0.21398917266300746, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.053357940167188644}, {"id": 78, "seek": 40592, "start": 417.04, "end": 422.16, "text": " But then most of the coding happens when they actually do feature engineer, right? They say,", "tokens": [50920, 583, 550, 881, 295, 264, 17720, 2314, 562, 436, 767, 360, 4111, 11403, 11, 558, 30, 814, 584, 11, 51176], "temperature": 0.0, "avg_logprob": -0.21398917266300746, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.053357940167188644}, {"id": 79, "seek": 40592, "start": 422.16, "end": 426.8, "text": " oh, well, I wanted you to be entity recognition at a feature of like, this is a capitalized word,", "tokens": [51176, 1954, 11, 731, 11, 286, 1415, 291, 281, 312, 13977, 11150, 412, 257, 4111, 295, 411, 11, 341, 307, 257, 4238, 1602, 1349, 11, 51408], "temperature": 0.0, "avg_logprob": -0.21398917266300746, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.053357940167188644}, {"id": 80, "seek": 40592, "start": 426.8, "end": 433.6, "text": " and this is all caps word, or this is a word that has like, is one of the items in this list.", "tokens": [51408, 293, 341, 307, 439, 13855, 1349, 11, 420, 341, 307, 257, 1349, 300, 575, 411, 11, 307, 472, 295, 264, 4754, 294, 341, 1329, 13, 51748], "temperature": 0.0, "avg_logprob": -0.21398917266300746, "compression_ratio": 1.6654411764705883, "no_speech_prob": 0.053357940167188644}, {"id": 81, "seek": 43360, "start": 433.6, "end": 438.40000000000003, "text": " And this list includes, you know, city needs, we already know. And I'm like, man, this field is", "tokens": [50364, 400, 341, 1329, 5974, 11, 291, 458, 11, 2307, 2203, 11, 321, 1217, 458, 13, 400, 286, 478, 411, 11, 587, 11, 341, 2519, 307, 50604], "temperature": 0.0, "avg_logprob": -0.25134884926580614, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.008313599973917007}, {"id": 82, "seek": 43360, "start": 438.40000000000003, "end": 443.84000000000003, "text": " very hand engineered. It's very like, graduate student ascent to get better. And then at the", "tokens": [50604, 588, 1011, 38648, 13, 467, 311, 588, 411, 11, 8080, 3107, 382, 2207, 281, 483, 1101, 13, 400, 550, 412, 264, 50876], "temperature": 0.0, "avg_logprob": -0.25134884926580614, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.008313599973917007}, {"id": 83, "seek": 43360, "start": 443.84000000000003, "end": 449.68, "text": " time I was very 40, because Andrew A. got into deep learning on the computer vision side. He's", "tokens": [50876, 565, 286, 390, 588, 3356, 11, 570, 10110, 316, 13, 658, 666, 2452, 2539, 322, 264, 3820, 5201, 1252, 13, 634, 311, 51168], "temperature": 0.0, "avg_logprob": -0.25134884926580614, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.008313599973917007}, {"id": 84, "seek": 43360, "start": 449.68, "end": 454.56, "text": " like, well, images are pixels, and it's a fixed number of pixels. So we can feed them into a", "tokens": [51168, 411, 11, 731, 11, 5267, 366, 18668, 11, 293, 309, 311, 257, 6806, 1230, 295, 18668, 13, 407, 321, 393, 3154, 552, 666, 257, 51412], "temperature": 0.0, "avg_logprob": -0.25134884926580614, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.008313599973917007}, {"id": 85, "seek": 43360, "start": 454.56, "end": 459.36, "text": " neural net or at the time, you know, variants, models, restricted development machines. And I", "tokens": [51412, 18161, 2533, 420, 412, 264, 565, 11, 291, 458, 11, 21669, 11, 5245, 11, 20608, 3250, 8379, 13, 400, 286, 51652], "temperature": 0.0, "avg_logprob": -0.25134884926580614, "compression_ratio": 1.6607773851590106, "no_speech_prob": 0.008313599973917007}, {"id": 86, "seek": 45936, "start": 459.36, "end": 464.72, "text": " was like, wow, maybe we can use ideas from that for natural language processing. And there was", "tokens": [50364, 390, 411, 11, 6076, 11, 1310, 321, 393, 764, 3487, 490, 300, 337, 3303, 2856, 9007, 13, 400, 456, 390, 50632], "temperature": 0.0, "avg_logprob": -0.24833457002934722, "compression_ratio": 1.7387387387387387, "no_speech_prob": 0.0008165902108885348}, {"id": 87, "seek": 45936, "start": 464.72, "end": 471.84000000000003, "text": " maybe like one or two relevant papers all from a number there, and Jason Weston, and, and a few", "tokens": [50632, 1310, 411, 472, 420, 732, 7340, 10577, 439, 490, 257, 1230, 456, 11, 293, 11181, 4055, 266, 11, 293, 11, 293, 257, 1326, 50988], "temperature": 0.0, "avg_logprob": -0.24833457002934722, "compression_ratio": 1.7387387387387387, "no_speech_prob": 0.0008165902108885348}, {"id": 88, "seek": 45936, "start": 471.84000000000003, "end": 477.68, "text": " like one or two others. But no one really enjoyed that approach, no natural language processing,", "tokens": [50988, 411, 472, 420, 732, 2357, 13, 583, 572, 472, 534, 4626, 300, 3109, 11, 572, 3303, 2856, 9007, 11, 51280], "temperature": 0.0, "avg_logprob": -0.24833457002934722, "compression_ratio": 1.7387387387387387, "no_speech_prob": 0.0008165902108885348}, {"id": 89, "seek": 45936, "start": 477.68, "end": 482.64, "text": " paid any attention to it. But I thought, silly, that has to be the future. I want to give the data", "tokens": [51280, 4835, 604, 3202, 281, 309, 13, 583, 286, 1194, 11, 11774, 11, 300, 575, 281, 312, 264, 2027, 13, 286, 528, 281, 976, 264, 1412, 51528], "temperature": 0.0, "avg_logprob": -0.24833457002934722, "compression_ratio": 1.7387387387387387, "no_speech_prob": 0.0008165902108885348}, {"id": 90, "seek": 48264, "start": 482.71999999999997, "end": 489.52, "text": " and I want to get an output. And so in 2010, I started publishing my first neural net paper,", "tokens": [50368, 293, 286, 528, 281, 483, 364, 5598, 13, 400, 370, 294, 9657, 11, 286, 1409, 17832, 452, 700, 18161, 2533, 3035, 11, 50708], "temperature": 0.0, "avg_logprob": -0.15104688916887557, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.16434787213802338}, {"id": 91, "seek": 48264, "start": 489.52, "end": 495.59999999999997, "text": " worked on my computer vision before and saw some of the power of ImageNet also back to and really", "tokens": [50708, 2732, 322, 452, 3820, 5201, 949, 293, 1866, 512, 295, 264, 1347, 295, 29903, 31890, 611, 646, 281, 293, 534, 51012], "temperature": 0.0, "avg_logprob": -0.15104688916887557, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.16434787213802338}, {"id": 92, "seek": 48264, "start": 495.59999999999997, "end": 501.2, "text": " started running with it. Got a lot of rejections all throughout. But, but at some point, I sunk", "tokens": [51012, 1409, 2614, 365, 309, 13, 5803, 257, 688, 295, 8248, 626, 439, 3710, 13, 583, 11, 457, 412, 512, 935, 11, 286, 40564, 51292], "temperature": 0.0, "avg_logprob": -0.15104688916887557, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.16434787213802338}, {"id": 93, "seek": 48264, "start": 501.2, "end": 505.68, "text": " my teeth into it. And I just like, I loved it. And I thought this is the future. Despite all the", "tokens": [51292, 452, 7798, 666, 309, 13, 400, 286, 445, 411, 11, 286, 4333, 309, 13, 400, 286, 1194, 341, 307, 264, 2027, 13, 11334, 439, 264, 51516], "temperature": 0.0, "avg_logprob": -0.15104688916887557, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.16434787213802338}, {"id": 94, "seek": 48264, "start": 505.68, "end": 511.2, "text": " rejections, I kept going at it. And then after the PhD was over, there's sort of starting to be", "tokens": [51516, 8248, 626, 11, 286, 4305, 516, 412, 309, 13, 400, 550, 934, 264, 14476, 390, 670, 11, 456, 311, 1333, 295, 2891, 281, 312, 51792], "temperature": 0.0, "avg_logprob": -0.15104688916887557, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.16434787213802338}, {"id": 95, "seek": 51120, "start": 511.2, "end": 517.04, "text": " more interest in deep learning and neural nets for NLP. But still, no one in the world was teaching", "tokens": [50364, 544, 1179, 294, 2452, 2539, 293, 18161, 36170, 337, 426, 45196, 13, 583, 920, 11, 572, 472, 294, 264, 1002, 390, 4571, 50656], "temperature": 0.0, "avg_logprob": -0.21901984763356436, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.005637917201966047}, {"id": 96, "seek": 51120, "start": 517.04, "end": 521.68, "text": " that as like the official right way of doing NLP. So I started teaching at Stanford also,", "tokens": [50656, 300, 382, 411, 264, 4783, 558, 636, 295, 884, 426, 45196, 13, 407, 286, 1409, 4571, 412, 20374, 611, 11, 50888], "temperature": 0.0, "avg_logprob": -0.21901984763356436, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.005637917201966047}, {"id": 97, "seek": 51120, "start": 522.64, "end": 528.08, "text": " first as a busy lecturer and then as a professor, started, you know, being a fortune and lots of", "tokens": [50936, 700, 382, 257, 5856, 49881, 293, 550, 382, 257, 8304, 11, 1409, 11, 291, 458, 11, 885, 257, 16531, 293, 3195, 295, 51208], "temperature": 0.0, "avg_logprob": -0.21901984763356436, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.005637917201966047}, {"id": 98, "seek": 51120, "start": 528.08, "end": 532.96, "text": " very smart students back then, really like the hiding place founders invested in their first", "tokens": [51208, 588, 4069, 1731, 646, 550, 11, 534, 411, 264, 10596, 1081, 25608, 13104, 294, 641, 700, 51452], "temperature": 0.0, "avg_logprob": -0.21901984763356436, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.005637917201966047}, {"id": 99, "seek": 51120, "start": 532.96, "end": 538.72, "text": " round. And then, you know, also wanted to bring these neural nets into the world, started a", "tokens": [51452, 3098, 13, 400, 550, 11, 291, 458, 11, 611, 1415, 281, 1565, 613, 18161, 36170, 666, 264, 1002, 11, 1409, 257, 51740], "temperature": 0.0, "avg_logprob": -0.21901984763356436, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.005637917201966047}, {"id": 100, "seek": 53872, "start": 538.8000000000001, "end": 543.2, "text": " menomind, my first startup to do that, to build a general purpose platform between neural nets", "tokens": [50368, 1706, 298, 471, 11, 452, 700, 18578, 281, 360, 300, 11, 281, 1322, 257, 2674, 4334, 3663, 1296, 18161, 36170, 50588], "temperature": 0.0, "avg_logprob": -0.2753985555548417, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.008185064420104027}, {"id": 101, "seek": 53872, "start": 543.2, "end": 548.5600000000001, "text": " very easily, both revision and NLP, got acquired by Salesforce, became a chief scientist there and", "tokens": [50588, 588, 3612, 11, 1293, 34218, 293, 426, 45196, 11, 658, 17554, 538, 40398, 11, 3062, 257, 9588, 12662, 456, 293, 50856], "temperature": 0.0, "avg_logprob": -0.2753985555548417, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.008185064420104027}, {"id": 102, "seek": 53872, "start": 548.5600000000001, "end": 554.88, "text": " EDP eventually. And in Salesforce, we had my probably last and biggest rejection was on inventing", "tokens": [50856, 462, 11373, 4728, 13, 400, 294, 40398, 11, 321, 632, 452, 1391, 1036, 293, 3880, 26044, 390, 322, 7962, 278, 51172], "temperature": 0.0, "avg_logprob": -0.2753985555548417, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.008185064420104027}, {"id": 103, "seek": 53872, "start": 554.88, "end": 560.0, "text": " front engineering in 2018. And we're so excited about it, because there's the culmination personally", "tokens": [51172, 1868, 7043, 294, 6096, 13, 400, 321, 434, 370, 2919, 466, 309, 11, 570, 456, 311, 264, 28583, 399, 5665, 51428], "temperature": 0.0, "avg_logprob": -0.2753985555548417, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.008185064420104027}, {"id": 104, "seek": 53872, "start": 560.0, "end": 565.84, "text": " for me also of this decade long dream I have, building a single neural net for all of NLP.", "tokens": [51428, 337, 385, 611, 295, 341, 10378, 938, 3055, 286, 362, 11, 2390, 257, 2167, 18161, 2533, 337, 439, 295, 426, 45196, 13, 51720], "temperature": 0.0, "avg_logprob": -0.2753985555548417, "compression_ratio": 1.5784313725490196, "no_speech_prob": 0.008185064420104027}, {"id": 105, "seek": 56584, "start": 565.84, "end": 572.5600000000001, "text": " And the idea was, you know, at the time, every AI model was built for one task, you will have wanted", "tokens": [50364, 400, 264, 1558, 390, 11, 291, 458, 11, 412, 264, 565, 11, 633, 7318, 2316, 390, 3094, 337, 472, 5633, 11, 291, 486, 362, 1415, 50700], "temperature": 0.0, "avg_logprob": -0.16997244032166844, "compression_ratio": 1.88, "no_speech_prob": 0.00648614251986146}, {"id": 106, "seek": 56584, "start": 572.5600000000001, "end": 576.48, "text": " your sentiment analysis, I built a sentiment analysis model, you wanted a translation, I built", "tokens": [50700, 428, 16149, 5215, 11, 286, 3094, 257, 16149, 5215, 2316, 11, 291, 1415, 257, 12853, 11, 286, 3094, 50896], "temperature": 0.0, "avg_logprob": -0.16997244032166844, "compression_ratio": 1.88, "no_speech_prob": 0.00648614251986146}, {"id": 107, "seek": 56584, "start": 576.48, "end": 580.32, "text": " a translation model, and they're all different. We're like, what if we could just build a single", "tokens": [50896, 257, 12853, 2316, 11, 293, 436, 434, 439, 819, 13, 492, 434, 411, 11, 437, 498, 321, 727, 445, 1322, 257, 2167, 51088], "temperature": 0.0, "avg_logprob": -0.16997244032166844, "compression_ratio": 1.88, "no_speech_prob": 0.00648614251986146}, {"id": 108, "seek": 56584, "start": 580.32, "end": 585.52, "text": " model? And you just ask it a question, what is the sentiment? What is the summary of the sentence?", "tokens": [51088, 2316, 30, 400, 291, 445, 1029, 309, 257, 1168, 11, 437, 307, 264, 16149, 30, 708, 307, 264, 12691, 295, 264, 8174, 30, 51348], "temperature": 0.0, "avg_logprob": -0.16997244032166844, "compression_ratio": 1.88, "no_speech_prob": 0.00648614251986146}, {"id": 109, "seek": 56584, "start": 585.52, "end": 590.88, "text": " Who is the president in this paragraph? And that was kind of for us, I thought like,", "tokens": [51348, 2102, 307, 264, 3868, 294, 341, 18865, 30, 400, 300, 390, 733, 295, 337, 505, 11, 286, 1194, 411, 11, 51616], "temperature": 0.0, "avg_logprob": -0.16997244032166844, "compression_ratio": 1.88, "no_speech_prob": 0.00648614251986146}, {"id": 110, "seek": 56584, "start": 590.88, "end": 594.88, "text": " the most exciting thing you possibly could be doing at just get this tech talk about it", "tokens": [51616, 264, 881, 4670, 551, 291, 6264, 727, 312, 884, 412, 445, 483, 341, 7553, 751, 466, 309, 51816], "temperature": 0.0, "avg_logprob": -0.16997244032166844, "compression_ratio": 1.88, "no_speech_prob": 0.00648614251986146}, {"id": 111, "seek": 59488, "start": 594.88, "end": 600.56, "text": " came out last week. And but it was exciting. But it did inspire a couple of other folks.", "tokens": [50364, 1361, 484, 1036, 1243, 13, 400, 457, 309, 390, 4670, 13, 583, 309, 630, 15638, 257, 1916, 295, 661, 4024, 13, 50648], "temperature": 0.0, "avg_logprob": -0.2528222455816754, "compression_ratio": 1.6433823529411764, "no_speech_prob": 0.005058616865426302}, {"id": 112, "seek": 59488, "start": 600.56, "end": 604.4, "text": " And like, when opening, I was, you know, publishing your papers, that should be true.", "tokens": [50648, 400, 411, 11, 562, 5193, 11, 286, 390, 11, 291, 458, 11, 17832, 428, 10577, 11, 300, 820, 312, 2074, 13, 50840], "temperature": 0.0, "avg_logprob": -0.2528222455816754, "compression_ratio": 1.6433823529411764, "no_speech_prob": 0.005058616865426302}, {"id": 113, "seek": 59488, "start": 604.4, "end": 609.52, "text": " And three, they cited that paper saying like, look, they were able to have a single model", "tokens": [50840, 400, 1045, 11, 436, 30134, 300, 3035, 1566, 411, 11, 574, 11, 436, 645, 1075, 281, 362, 257, 2167, 2316, 51096], "temperature": 0.0, "avg_logprob": -0.2528222455816754, "compression_ratio": 1.6433823529411764, "no_speech_prob": 0.005058616865426302}, {"id": 114, "seek": 59488, "start": 609.52, "end": 615.12, "text": " for all of NLP, if you just ask them these questions. And, you know, that's now prompt and", "tokens": [51096, 337, 439, 295, 426, 45196, 11, 498, 291, 445, 1029, 552, 613, 1651, 13, 400, 11, 291, 458, 11, 300, 311, 586, 12391, 293, 51376], "temperature": 0.0, "avg_logprob": -0.2528222455816754, "compression_ratio": 1.6433823529411764, "no_speech_prob": 0.005058616865426302}, {"id": 115, "seek": 59488, "start": 615.12, "end": 619.68, "text": " the rest is kind of more well known history. That is an amazing history. And it definitely,", "tokens": [51376, 264, 1472, 307, 733, 295, 544, 731, 2570, 2503, 13, 663, 307, 364, 2243, 2503, 13, 400, 309, 2138, 11, 51604], "temperature": 0.0, "avg_logprob": -0.2528222455816754, "compression_ratio": 1.6433823529411764, "no_speech_prob": 0.005058616865426302}, {"id": 116, "seek": 61968, "start": 619.68, "end": 626.3199999999999, "text": " I don't know how, you know, modest you want to be versus taking credit for foresight. But", "tokens": [50364, 286, 500, 380, 458, 577, 11, 291, 458, 11, 25403, 291, 528, 281, 312, 5717, 1940, 5397, 337, 2091, 28654, 13, 583, 50696], "temperature": 0.0, "avg_logprob": -0.0974063711651301, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0850883424282074}, {"id": 117, "seek": 61968, "start": 626.3199999999999, "end": 632.0799999999999, "text": " certainly, the idea that there could be one model to solve all these, you know, tasks was not", "tokens": [50696, 3297, 11, 264, 1558, 300, 456, 727, 312, 472, 2316, 281, 5039, 439, 613, 11, 291, 458, 11, 9608, 390, 406, 50984], "temperature": 0.0, "avg_logprob": -0.0974063711651301, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0850883424282074}, {"id": 118, "seek": 61968, "start": 632.0799999999999, "end": 637.68, "text": " obvious to people. And boy, we still see this, the flaws in the peer review process are still on", "tokens": [50984, 6322, 281, 561, 13, 400, 3237, 11, 321, 920, 536, 341, 11, 264, 27108, 294, 264, 15108, 3131, 1399, 366, 920, 322, 51264], "temperature": 0.0, "avg_logprob": -0.0974063711651301, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0850883424282074}, {"id": 119, "seek": 61968, "start": 637.68, "end": 642.4799999999999, "text": " prominent display these days. Most recently, I noticed this with the Mamba paper, which I was", "tokens": [51264, 17034, 4674, 613, 1708, 13, 4534, 3938, 11, 286, 5694, 341, 365, 264, 376, 23337, 3035, 11, 597, 286, 390, 51504], "temperature": 0.0, "avg_logprob": -0.0974063711651301, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0850883424282074}, {"id": 120, "seek": 61968, "start": 643.3599999999999, "end": 649.28, "text": " a very interested reader of. And then went over to the open reviews site and was blown away by how", "tokens": [51548, 257, 588, 3102, 15149, 295, 13, 400, 550, 1437, 670, 281, 264, 1269, 10229, 3621, 293, 390, 16479, 1314, 538, 577, 51844], "temperature": 0.0, "avg_logprob": -0.0974063711651301, "compression_ratio": 1.6538461538461537, "no_speech_prob": 0.0850883424282074}, {"id": 121, "seek": 64928, "start": 649.28, "end": 654.88, "text": " negative some of the reviews were like a confident reject was given. So that was kind of, you know,", "tokens": [50364, 3671, 512, 295, 264, 10229, 645, 411, 257, 6679, 8248, 390, 2212, 13, 407, 300, 390, 733, 295, 11, 291, 458, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1147989185377099, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.0011335081653669477}, {"id": 122, "seek": 64928, "start": 655.68, "end": 658.64, "text": " just a good reminder that, yeah, this is still an unsolved problem.", "tokens": [50684, 445, 257, 665, 13548, 300, 11, 1338, 11, 341, 307, 920, 364, 2693, 29110, 1154, 13, 50832], "temperature": 0.0, "avg_logprob": -0.1147989185377099, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.0011335081653669477}, {"id": 123, "seek": 64928, "start": 659.4399999999999, "end": 667.1999999999999, "text": " What would you say has surprised you most from like the big picture since you,", "tokens": [50872, 708, 576, 291, 584, 575, 6100, 291, 881, 490, 411, 264, 955, 3036, 1670, 291, 11, 51260], "temperature": 0.0, "avg_logprob": -0.1147989185377099, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.0011335081653669477}, {"id": 124, "seek": 64928, "start": 668.0799999999999, "end": 672.3199999999999, "text": " and you know, it hasn't been that many years, right? But since you kind of had that notion of", "tokens": [51304, 293, 291, 458, 11, 309, 6132, 380, 668, 300, 867, 924, 11, 558, 30, 583, 1670, 291, 733, 295, 632, 300, 10710, 295, 51516], "temperature": 0.0, "avg_logprob": -0.1147989185377099, "compression_ratio": 1.596244131455399, "no_speech_prob": 0.0011335081653669477}, {"id": 125, "seek": 67232, "start": 672.32, "end": 679.36, "text": " this generalist NLP model, fast forward, now we have, you know, GPT four and possibly Q star or", "tokens": [50364, 341, 2674, 468, 426, 45196, 2316, 11, 2370, 2128, 11, 586, 321, 362, 11, 291, 458, 11, 26039, 51, 1451, 293, 6264, 1249, 3543, 420, 50716], "temperature": 0.0, "avg_logprob": -0.13580755150836446, "compression_ratio": 1.5793357933579335, "no_speech_prob": 0.07366576790809631}, {"id": 126, "seek": 67232, "start": 679.36, "end": 683.5200000000001, "text": " something like that in the works, you know, is this the trajectory that you thought we'd be on?", "tokens": [50716, 746, 411, 300, 294, 264, 1985, 11, 291, 458, 11, 307, 341, 264, 21512, 300, 291, 1194, 321, 1116, 312, 322, 30, 50924], "temperature": 0.0, "avg_logprob": -0.13580755150836446, "compression_ratio": 1.5793357933579335, "no_speech_prob": 0.07366576790809631}, {"id": 127, "seek": 67232, "start": 683.5200000000001, "end": 686.8000000000001, "text": " Or how has it deviated from what you imagined back then?", "tokens": [50924, 1610, 577, 575, 309, 31219, 770, 490, 437, 291, 16590, 646, 550, 30, 51088], "temperature": 0.0, "avg_logprob": -0.13580755150836446, "compression_ratio": 1.5793357933579335, "no_speech_prob": 0.07366576790809631}, {"id": 128, "seek": 67232, "start": 686.8000000000001, "end": 693.0400000000001, "text": " It's very much aligned with what I hoped the field could get to. And now it's almost like,", "tokens": [51088, 467, 311, 588, 709, 17962, 365, 437, 286, 19737, 264, 2519, 727, 483, 281, 13, 400, 586, 309, 311, 1920, 411, 11, 51400], "temperature": 0.0, "avg_logprob": -0.13580755150836446, "compression_ratio": 1.5793357933579335, "no_speech_prob": 0.07366576790809631}, {"id": 129, "seek": 67232, "start": 693.0400000000001, "end": 697.36, "text": " it's like obvious, right? Like no one no one questions this anymore, we've had all these", "tokens": [51400, 309, 311, 411, 6322, 11, 558, 30, 1743, 572, 472, 572, 472, 1651, 341, 3602, 11, 321, 600, 632, 439, 613, 51616], "temperature": 0.0, "avg_logprob": -0.13580755150836446, "compression_ratio": 1.5793357933579335, "no_speech_prob": 0.07366576790809631}, {"id": 130, "seek": 69736, "start": 697.36, "end": 703.28, "text": " breakthroughs. And I think the biggest surprise was maybe more on the application side of things", "tokens": [50364, 22397, 82, 13, 400, 286, 519, 264, 3880, 6365, 390, 1310, 544, 322, 264, 3861, 1252, 295, 721, 50660], "temperature": 0.0, "avg_logprob": -0.15680146873544115, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.08265943080186844}, {"id": 131, "seek": 69736, "start": 703.28, "end": 708.24, "text": " and that for us, you know, we've been playing around with large language models at u.com and", "tokens": [50660, 293, 300, 337, 505, 11, 291, 458, 11, 321, 600, 668, 2433, 926, 365, 2416, 2856, 5245, 412, 344, 13, 1112, 293, 50908], "temperature": 0.0, "avg_logprob": -0.15680146873544115, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.08265943080186844}, {"id": 132, "seek": 69736, "start": 708.24, "end": 714.8000000000001, "text": " infuse them into search results earlier, like early 2022, already, like we had apps that would", "tokens": [50908, 1536, 438, 552, 666, 3164, 3542, 3071, 11, 411, 2440, 945, 7490, 11, 1217, 11, 411, 321, 632, 7733, 300, 576, 51236], "temperature": 0.0, "avg_logprob": -0.15680146873544115, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.08265943080186844}, {"id": 133, "seek": 69736, "start": 714.8000000000001, "end": 719.2, "text": " write code for you within the search results, through the apps that write essays for you within", "tokens": [51236, 2464, 3089, 337, 291, 1951, 264, 3164, 3542, 11, 807, 264, 7733, 300, 2464, 35123, 337, 291, 1951, 51456], "temperature": 0.0, "avg_logprob": -0.15680146873544115, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.08265943080186844}, {"id": 134, "seek": 69736, "start": 719.2, "end": 725.76, "text": " the search results. But whenever we innovate it and change the default Google experience too much,", "tokens": [51456, 264, 3164, 3542, 13, 583, 5699, 321, 33444, 309, 293, 1319, 264, 7576, 3329, 1752, 886, 709, 11, 51784], "temperature": 0.0, "avg_logprob": -0.15680146873544115, "compression_ratio": 1.723021582733813, "no_speech_prob": 0.08265943080186844}, {"id": 135, "seek": 72576, "start": 725.76, "end": 729.36, "text": " we had just like the vast majority of our users say, I'm so used to Google,", "tokens": [50364, 321, 632, 445, 411, 264, 8369, 6286, 295, 527, 5022, 584, 11, 286, 478, 370, 1143, 281, 3329, 11, 50544], "temperature": 0.0, "avg_logprob": -0.15335323499596637, "compression_ratio": 1.680921052631579, "no_speech_prob": 0.0027143959887325764}, {"id": 136, "seek": 72576, "start": 730.16, "end": 735.52, "text": " I don't want another way of finding answers. And so we kept getting pulled back to this need.", "tokens": [50584, 286, 500, 380, 528, 1071, 636, 295, 5006, 6338, 13, 400, 370, 321, 4305, 1242, 7373, 646, 281, 341, 643, 13, 50852], "temperature": 0.0, "avg_logprob": -0.15335323499596637, "compression_ratio": 1.680921052631579, "no_speech_prob": 0.0027143959887325764}, {"id": 137, "seek": 72576, "start": 735.52, "end": 739.6, "text": " And there was kind of annoying. And so the most amazing surprise was when", "tokens": [50852, 400, 456, 390, 733, 295, 11304, 13, 400, 370, 264, 881, 2243, 6365, 390, 562, 51056], "temperature": 0.0, "avg_logprob": -0.15335323499596637, "compression_ratio": 1.680921052631579, "no_speech_prob": 0.0027143959887325764}, {"id": 138, "seek": 72576, "start": 739.6, "end": 744.24, "text": " Chatchity came out, all of a sudden, people got it. And it was like, wait a minute,", "tokens": [51056, 761, 852, 507, 1361, 484, 11, 439, 295, 257, 3990, 11, 561, 658, 309, 13, 400, 309, 390, 411, 11, 1699, 257, 3456, 11, 51288], "temperature": 0.0, "avg_logprob": -0.15335323499596637, "compression_ratio": 1.680921052631579, "no_speech_prob": 0.0027143959887325764}, {"id": 139, "seek": 72576, "start": 744.24, "end": 749.76, "text": " it could just be like pure text. And we're like, you know, we've been trying to sort of slowly", "tokens": [51288, 309, 727, 445, 312, 411, 6075, 2487, 13, 400, 321, 434, 411, 11, 291, 458, 11, 321, 600, 668, 1382, 281, 1333, 295, 5692, 51564], "temperature": 0.0, "avg_logprob": -0.15335323499596637, "compression_ratio": 1.680921052631579, "no_speech_prob": 0.0027143959887325764}, {"id": 140, "seek": 72576, "start": 749.76, "end": 754.64, "text": " get there, but we had to make a bigger job. And that was incredible. That unlocked a lot", "tokens": [51564, 483, 456, 11, 457, 321, 632, 281, 652, 257, 3801, 1691, 13, 400, 300, 390, 4651, 13, 663, 30180, 257, 688, 51808], "temperature": 0.0, "avg_logprob": -0.15335323499596637, "compression_ratio": 1.680921052631579, "no_speech_prob": 0.0027143959887325764}, {"id": 141, "seek": 75464, "start": 754.64, "end": 759.6, "text": " of people realizing we handle links isn't the best way to get an answer. An actual answer", "tokens": [50364, 295, 561, 16734, 321, 4813, 6123, 1943, 380, 264, 1151, 636, 281, 483, 364, 1867, 13, 1107, 3539, 1867, 50612], "temperature": 0.0, "avg_logprob": -0.10438786904642901, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0031720225233584642}, {"id": 142, "seek": 75464, "start": 759.6, "end": 761.92, "text": " is the best way to get an answer. And that's the text.", "tokens": [50612, 307, 264, 1151, 636, 281, 483, 364, 1867, 13, 400, 300, 311, 264, 2487, 13, 50728], "temperature": 0.0, "avg_logprob": -0.10438786904642901, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0031720225233584642}, {"id": 143, "seek": 75464, "start": 763.04, "end": 768.3199999999999, "text": " So let me give you a couple of my experiences on u.com recently, and then you can kind of tell me,", "tokens": [50784, 407, 718, 385, 976, 291, 257, 1916, 295, 452, 5235, 322, 344, 13, 1112, 3938, 11, 293, 550, 291, 393, 733, 295, 980, 385, 11, 51048], "temperature": 0.0, "avg_logprob": -0.10438786904642901, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0031720225233584642}, {"id": 144, "seek": 75464, "start": 768.3199999999999, "end": 773.68, "text": " you know, where you are the overall story. And then I really want to kind of unpack the", "tokens": [51048, 291, 458, 11, 689, 291, 366, 264, 4787, 1657, 13, 400, 550, 286, 534, 528, 281, 733, 295, 26699, 264, 51316], "temperature": 0.0, "avg_logprob": -0.10438786904642901, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0031720225233584642}, {"id": 145, "seek": 75464, "start": 774.56, "end": 778.4, "text": " kind of use the product as it exists today and the roadmap and everything you're working on", "tokens": [51360, 733, 295, 764, 264, 1674, 382, 309, 8198, 965, 293, 264, 35738, 293, 1203, 291, 434, 1364, 322, 51552], "temperature": 0.0, "avg_logprob": -0.10438786904642901, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0031720225233584642}, {"id": 146, "seek": 75464, "start": 778.4, "end": 781.84, "text": " as a way to kind of explore a bunch of different aspects of where all this", "tokens": [51552, 382, 257, 636, 281, 733, 295, 6839, 257, 3840, 295, 819, 7270, 295, 689, 439, 341, 51724], "temperature": 0.0, "avg_logprob": -0.10438786904642901, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0031720225233584642}, {"id": 147, "seek": 78184, "start": 781.84, "end": 786.72, "text": " is going, you know, and I think that's really the mission of this show is to kind of help people", "tokens": [50364, 307, 516, 11, 291, 458, 11, 293, 286, 519, 300, 311, 534, 264, 4447, 295, 341, 855, 307, 281, 733, 295, 854, 561, 50608], "temperature": 0.0, "avg_logprob": -0.10830833171976023, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.01001264899969101}, {"id": 148, "seek": 78184, "start": 786.72, "end": 790.64, "text": " see around the corner and starting with me, helping me develop my own worldview.", "tokens": [50608, 536, 926, 264, 4538, 293, 2891, 365, 385, 11, 4315, 385, 1499, 452, 1065, 41141, 13, 50804], "temperature": 0.0, "avg_logprob": -0.10830833171976023, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.01001264899969101}, {"id": 149, "seek": 78184, "start": 790.64, "end": 795.12, "text": " But I've been really impressed with the product recently. You know, listeners will know that", "tokens": [50804, 583, 286, 600, 668, 534, 11679, 365, 264, 1674, 3938, 13, 509, 458, 11, 23274, 486, 458, 300, 51028], "temperature": 0.0, "avg_logprob": -0.10830833171976023, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.01001264899969101}, {"id": 150, "seek": 78184, "start": 795.12, "end": 798.8000000000001, "text": " I've been a big fan of perplexity. We've had Arvin on the show a couple of times.", "tokens": [51028, 286, 600, 668, 257, 955, 3429, 295, 680, 18945, 507, 13, 492, 600, 632, 1587, 4796, 322, 264, 855, 257, 1916, 295, 1413, 13, 51212], "temperature": 0.0, "avg_logprob": -0.10830833171976023, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.01001264899969101}, {"id": 151, "seek": 78184, "start": 799.44, "end": 804.1600000000001, "text": " And I think they do a great job and, you know, we're made a fan. But I have found", "tokens": [51244, 400, 286, 519, 436, 360, 257, 869, 1691, 293, 11, 291, 458, 11, 321, 434, 1027, 257, 3429, 13, 583, 286, 362, 1352, 51480], "temperature": 0.0, "avg_logprob": -0.10830833171976023, "compression_ratio": 1.6628352490421456, "no_speech_prob": 0.01001264899969101}, {"id": 152, "seek": 80416, "start": 805.12, "end": 810.56, "text": " distinctive value in at least two modes on u.com recently. One is the", "tokens": [50412, 27766, 2158, 294, 412, 1935, 732, 14068, 322, 344, 13, 1112, 3938, 13, 1485, 307, 264, 50684], "temperature": 0.0, "avg_logprob": -0.11060295786176409, "compression_ratio": 1.5336322869955157, "no_speech_prob": 0.37011829018592834}, {"id": 153, "seek": 80416, "start": 811.1999999999999, "end": 816.16, "text": " research mode, and the other is the genius mode. Those to me have stood out as the most", "tokens": [50716, 2132, 4391, 11, 293, 264, 661, 307, 264, 14017, 4391, 13, 3950, 281, 385, 362, 9371, 484, 382, 264, 881, 50964], "temperature": 0.0, "avg_logprob": -0.11060295786176409, "compression_ratio": 1.5336322869955157, "no_speech_prob": 0.37011829018592834}, {"id": 154, "seek": 80416, "start": 816.16, "end": 823.52, "text": " differentiated. For research mode, I recently took it like a 200 word question that was all about", "tokens": [50964, 27372, 770, 13, 1171, 2132, 4391, 11, 286, 3938, 1890, 309, 411, 257, 2331, 1349, 1168, 300, 390, 439, 466, 51332], "temperature": 0.0, "avg_logprob": -0.11060295786176409, "compression_ratio": 1.5336322869955157, "no_speech_prob": 0.37011829018592834}, {"id": 155, "seek": 80416, "start": 824.24, "end": 829.68, "text": " mixture of experts architectures. And, you know, kind of is there curriculum learning,", "tokens": [51368, 9925, 295, 8572, 6331, 1303, 13, 400, 11, 291, 458, 11, 733, 295, 307, 456, 14302, 2539, 11, 51640], "temperature": 0.0, "avg_logprob": -0.11060295786176409, "compression_ratio": 1.5336322869955157, "no_speech_prob": 0.37011829018592834}, {"id": 156, "seek": 82968, "start": 829.68, "end": 833.92, "text": " you know, stuff happening here? How, you know, how do people think about sort of", "tokens": [50364, 291, 458, 11, 1507, 2737, 510, 30, 1012, 11, 291, 458, 11, 577, 360, 561, 519, 466, 1333, 295, 50576], "temperature": 0.0, "avg_logprob": -0.09295691384209527, "compression_ratio": 1.7707641196013288, "no_speech_prob": 0.05183354392647743}, {"id": 157, "seek": 82968, "start": 833.92, "end": 838.4799999999999, "text": " the tradeoffs between like how many experts should we have and how big should they be and", "tokens": [50576, 264, 4923, 19231, 1296, 411, 577, 867, 8572, 820, 321, 362, 293, 577, 955, 820, 436, 312, 293, 50804], "temperature": 0.0, "avg_logprob": -0.09295691384209527, "compression_ratio": 1.7707641196013288, "no_speech_prob": 0.05183354392647743}, {"id": 158, "seek": 82968, "start": 838.4799999999999, "end": 842.16, "text": " how many should we activate at any given time? Are there any like scaling laws or whatever,", "tokens": [50804, 577, 867, 820, 321, 13615, 412, 604, 2212, 565, 30, 2014, 456, 604, 411, 21589, 6064, 420, 2035, 11, 50988], "temperature": 0.0, "avg_logprob": -0.09295691384209527, "compression_ratio": 1.7707641196013288, "no_speech_prob": 0.05183354392647743}, {"id": 159, "seek": 82968, "start": 842.16, "end": 844.8, "text": " you know, designed for that sort of thing? Just every basically every question I could", "tokens": [50988, 291, 458, 11, 4761, 337, 300, 1333, 295, 551, 30, 1449, 633, 1936, 633, 1168, 286, 727, 51120], "temperature": 0.0, "avg_logprob": -0.09295691384209527, "compression_ratio": 1.7707641196013288, "no_speech_prob": 0.05183354392647743}, {"id": 160, "seek": 82968, "start": 844.8, "end": 850.88, "text": " think of about mixture of experts, I took it all in one go. And it was really impressive to see it", "tokens": [51120, 519, 295, 466, 9925, 295, 8572, 11, 286, 1890, 309, 439, 294, 472, 352, 13, 400, 309, 390, 534, 8992, 281, 536, 309, 51424], "temperature": 0.0, "avg_logprob": -0.09295691384209527, "compression_ratio": 1.7707641196013288, "no_speech_prob": 0.05183354392647743}, {"id": 161, "seek": 82968, "start": 851.52, "end": 857.68, "text": " kind of break that down and go through multiple steps of searching and analysis and,", "tokens": [51456, 733, 295, 1821, 300, 760, 293, 352, 807, 3866, 4439, 295, 10808, 293, 5215, 293, 11, 51764], "temperature": 0.0, "avg_logprob": -0.09295691384209527, "compression_ratio": 1.7707641196013288, "no_speech_prob": 0.05183354392647743}, {"id": 162, "seek": 85768, "start": 858.56, "end": 862.4, "text": " you know, really implementing kind of like, you know, kind of a classic agent, what is at", "tokens": [50408, 291, 458, 11, 534, 18114, 733, 295, 411, 11, 291, 458, 11, 733, 295, 257, 7230, 9461, 11, 437, 307, 412, 50600], "temperature": 0.0, "avg_logprob": -0.09754473185367721, "compression_ratio": 1.8562091503267975, "no_speech_prob": 0.00025314828963018954}, {"id": 163, "seek": 85768, "start": 862.4, "end": 867.52, "text": " this point, you know, a six month classic agent setup, but applying it to that research question", "tokens": [50600, 341, 935, 11, 291, 458, 11, 257, 2309, 1618, 7230, 9461, 8657, 11, 457, 9275, 309, 281, 300, 2132, 1168, 50856], "temperature": 0.0, "avg_logprob": -0.09754473185367721, "compression_ratio": 1.8562091503267975, "no_speech_prob": 0.00025314828963018954}, {"id": 164, "seek": 85768, "start": 867.52, "end": 872.9599999999999, "text": " and just going, you know, down the line, really quite valuable results. And it definitely is", "tokens": [50856, 293, 445, 516, 11, 291, 458, 11, 760, 264, 1622, 11, 534, 1596, 8263, 3542, 13, 400, 309, 2138, 307, 51128], "temperature": 0.0, "avg_logprob": -0.09754473185367721, "compression_ratio": 1.8562091503267975, "no_speech_prob": 0.00025314828963018954}, {"id": 165, "seek": 85768, "start": 872.9599999999999, "end": 877.28, "text": " something that I will come back to and have already, you know, found myself kind of being like,", "tokens": [51128, 746, 300, 286, 486, 808, 646, 281, 293, 362, 1217, 11, 291, 458, 11, 1352, 2059, 733, 295, 885, 411, 11, 51344], "temperature": 0.0, "avg_logprob": -0.09754473185367721, "compression_ratio": 1.8562091503267975, "no_speech_prob": 0.00025314828963018954}, {"id": 166, "seek": 85768, "start": 877.28, "end": 882.8, "text": " I think this is a good one for u.com research mode. Genius mode is a little bit different and more", "tokens": [51344, 286, 519, 341, 307, 257, 665, 472, 337, 344, 13, 1112, 2132, 4391, 13, 45818, 4391, 307, 257, 707, 857, 819, 293, 544, 51620], "temperature": 0.0, "avg_logprob": -0.09754473185367721, "compression_ratio": 1.8562091503267975, "no_speech_prob": 0.00025314828963018954}, {"id": 167, "seek": 85768, "start": 882.8, "end": 887.1999999999999, "text": " kind of analytical. I'd be interested to hear a little bit more about how you think about the", "tokens": [51620, 733, 295, 29579, 13, 286, 1116, 312, 3102, 281, 1568, 257, 707, 857, 544, 466, 577, 291, 519, 466, 264, 51840], "temperature": 0.0, "avg_logprob": -0.09754473185367721, "compression_ratio": 1.8562091503267975, "no_speech_prob": 0.00025314828963018954}, {"id": 168, "seek": 88720, "start": 887.2, "end": 893.5200000000001, "text": " differences. Because I did, I then tried one that was a big Fermi calculation exercise,", "tokens": [50364, 7300, 13, 1436, 286, 630, 11, 286, 550, 3031, 472, 300, 390, 257, 955, 43261, 72, 17108, 5380, 11, 50680], "temperature": 0.0, "avg_logprob": -0.13334892107092816, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0023964736610651016}, {"id": 169, "seek": 88720, "start": 893.5200000000001, "end": 897.2800000000001, "text": " where my questions were like, what are the different data sets that exist in today's world?", "tokens": [50680, 689, 452, 1651, 645, 411, 11, 437, 366, 264, 819, 1412, 6352, 300, 2514, 294, 965, 311, 1002, 30, 50868], "temperature": 0.0, "avg_logprob": -0.13334892107092816, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0023964736610651016}, {"id": 170, "seek": 88720, "start": 897.2800000000001, "end": 900.88, "text": " How big are they? How do they compare to each other? How do they compare to", "tokens": [50868, 1012, 955, 366, 436, 30, 1012, 360, 436, 6794, 281, 1184, 661, 30, 1012, 360, 436, 6794, 281, 51048], "temperature": 0.0, "avg_logprob": -0.13334892107092816, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0023964736610651016}, {"id": 171, "seek": 88720, "start": 901.5200000000001, "end": 907.44, "text": " the training data size for GPT four? You know, how do they compare to available compute? Like,", "tokens": [51080, 264, 3097, 1412, 2744, 337, 26039, 51, 1451, 30, 509, 458, 11, 577, 360, 436, 6794, 281, 2435, 14722, 30, 1743, 11, 51376], "temperature": 0.0, "avg_logprob": -0.13334892107092816, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0023964736610651016}, {"id": 172, "seek": 88720, "start": 907.44, "end": 910.8000000000001, "text": " because I have this, I have a big question, which is kind of one of the ones I want to get to", "tokens": [51376, 570, 286, 362, 341, 11, 286, 362, 257, 955, 1168, 11, 597, 307, 733, 295, 472, 295, 264, 2306, 286, 528, 281, 483, 281, 51544], "temperature": 0.0, "avg_logprob": -0.13334892107092816, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0023964736610651016}, {"id": 173, "seek": 88720, "start": 910.8000000000001, "end": 916.0, "text": " toward the end to around like, to what degree is ML research poised to start to be kind of semi", "tokens": [51544, 7361, 264, 917, 281, 926, 411, 11, 281, 437, 4314, 307, 21601, 2132, 714, 2640, 281, 722, 281, 312, 733, 295, 12909, 51804], "temperature": 0.0, "avg_logprob": -0.13334892107092816, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0023964736610651016}, {"id": 174, "seek": 91600, "start": 916.0, "end": 921.12, "text": " automated. And so I'm trying to try to rent my arms around that with these furry calculations.", "tokens": [50364, 18473, 13, 400, 370, 286, 478, 1382, 281, 853, 281, 6214, 452, 5812, 926, 300, 365, 613, 47073, 20448, 13, 50620], "temperature": 0.0, "avg_logprob": -0.08791980036982784, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006096649449318647}, {"id": 175, "seek": 91600, "start": 921.12, "end": 927.84, "text": " So genius mode was really the best way to approach that. And anyway, I would definitely", "tokens": [50620, 407, 14017, 4391, 390, 534, 264, 1151, 636, 281, 3109, 300, 13, 400, 4033, 11, 286, 576, 2138, 50956], "temperature": 0.0, "avg_logprob": -0.08791980036982784, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006096649449318647}, {"id": 176, "seek": 91600, "start": 927.84, "end": 934.88, "text": " encourage people to bring multi part complicated questions to both research mode and genius mode.", "tokens": [50956, 5373, 561, 281, 1565, 4825, 644, 6179, 1651, 281, 1293, 2132, 4391, 293, 14017, 4391, 13, 51308], "temperature": 0.0, "avg_logprob": -0.08791980036982784, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006096649449318647}, {"id": 177, "seek": 91600, "start": 934.88, "end": 939.2, "text": " And I think you'll be impressed with the results. And I would say that, you know, even", "tokens": [51308, 400, 286, 519, 291, 603, 312, 11679, 365, 264, 3542, 13, 400, 286, 576, 584, 300, 11, 291, 458, 11, 754, 51524], "temperature": 0.0, "avg_logprob": -0.08791980036982784, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006096649449318647}, {"id": 178, "seek": 91600, "start": 940.24, "end": 944.08, "text": " with, you know, the expectation that folks who listen to this show have tried, you know, other", "tokens": [51576, 365, 11, 291, 458, 11, 264, 14334, 300, 4024, 567, 2140, 281, 341, 855, 362, 3031, 11, 291, 458, 11, 661, 51768], "temperature": 0.0, "avg_logprob": -0.08791980036982784, "compression_ratio": 1.7047970479704797, "no_speech_prob": 0.006096649449318647}, {"id": 179, "seek": 94408, "start": 944.1600000000001, "end": 951.36, "text": " leading AI products. So that's kind of my unpaid endorsement, very sincere. And I'd love to hear,", "tokens": [50368, 5775, 7318, 3383, 13, 407, 300, 311, 733, 295, 452, 517, 35035, 29228, 518, 11, 588, 16941, 13, 400, 286, 1116, 959, 281, 1568, 11, 50728], "temperature": 0.0, "avg_logprob": -0.10637243711031401, "compression_ratio": 1.636085626911315, "no_speech_prob": 0.0062885466031730175}, {"id": 180, "seek": 94408, "start": 951.36, "end": 954.5600000000001, "text": " you know, a little bit more about how you think about those different modes, how they work,", "tokens": [50728, 291, 458, 11, 257, 707, 857, 544, 466, 577, 291, 519, 466, 729, 819, 14068, 11, 577, 436, 589, 11, 50888], "temperature": 0.0, "avg_logprob": -0.10637243711031401, "compression_ratio": 1.636085626911315, "no_speech_prob": 0.0062885466031730175}, {"id": 181, "seek": 94408, "start": 954.5600000000001, "end": 958.88, "text": " and just kind of big picture, like where we are in the you.com product journey long term.", "tokens": [50888, 293, 445, 733, 295, 955, 3036, 11, 411, 689, 321, 366, 294, 264, 291, 13, 1112, 1674, 4671, 938, 1433, 13, 51104], "temperature": 0.0, "avg_logprob": -0.10637243711031401, "compression_ratio": 1.636085626911315, "no_speech_prob": 0.0062885466031730175}, {"id": 182, "seek": 94408, "start": 959.44, "end": 962.72, "text": " Hey, we'll continue our interview in a moment after a word from our sponsors.", "tokens": [51132, 1911, 11, 321, 603, 2354, 527, 4049, 294, 257, 1623, 934, 257, 1349, 490, 527, 22593, 13, 51296], "temperature": 0.0, "avg_logprob": -0.10637243711031401, "compression_ratio": 1.636085626911315, "no_speech_prob": 0.0062885466031730175}, {"id": 183, "seek": 94408, "start": 963.6800000000001, "end": 967.76, "text": " The Brave Search API brings affordable developer access to the Brave Search Index,", "tokens": [51344, 440, 38545, 17180, 9362, 5607, 12028, 10754, 2105, 281, 264, 38545, 17180, 33552, 11, 51548], "temperature": 0.0, "avg_logprob": -0.10637243711031401, "compression_ratio": 1.636085626911315, "no_speech_prob": 0.0062885466031730175}, {"id": 184, "seek": 94408, "start": 967.76, "end": 972.6400000000001, "text": " an independent index of the web with over 20 billion web pages. So what makes the Brave Search", "tokens": [51548, 364, 6695, 8186, 295, 264, 3670, 365, 670, 945, 5218, 3670, 7183, 13, 407, 437, 1669, 264, 38545, 17180, 51792], "temperature": 0.0, "avg_logprob": -0.10637243711031401, "compression_ratio": 1.636085626911315, "no_speech_prob": 0.0062885466031730175}, {"id": 185, "seek": 97264, "start": 972.64, "end": 978.96, "text": " Index stand out? One, it's entirely independent and built from scratch. That means no big tech", "tokens": [50364, 33552, 1463, 484, 30, 1485, 11, 309, 311, 7696, 6695, 293, 3094, 490, 8459, 13, 663, 1355, 572, 955, 7553, 50680], "temperature": 0.0, "avg_logprob": -0.05824785335089571, "compression_ratio": 1.52734375, "no_speech_prob": 0.008060984313488007}, {"id": 186, "seek": 97264, "start": 978.96, "end": 985.84, "text": " biases or extortionate prices. Two, it's built on real page visits from actual humans, collected", "tokens": [50680, 32152, 420, 1279, 8136, 473, 7901, 13, 4453, 11, 309, 311, 3094, 322, 957, 3028, 17753, 490, 3539, 6255, 11, 11087, 51024], "temperature": 0.0, "avg_logprob": -0.05824785335089571, "compression_ratio": 1.52734375, "no_speech_prob": 0.008060984313488007}, {"id": 187, "seek": 97264, "start": 985.84, "end": 991.76, "text": " anonymously, of course, which filters out tons of junk data. And three, the index is refreshed with", "tokens": [51024, 37293, 5098, 11, 295, 1164, 11, 597, 15995, 484, 9131, 295, 19109, 1412, 13, 400, 1045, 11, 264, 8186, 307, 46330, 365, 51320], "temperature": 0.0, "avg_logprob": -0.05824785335089571, "compression_ratio": 1.52734375, "no_speech_prob": 0.008060984313488007}, {"id": 188, "seek": 97264, "start": 991.76, "end": 997.68, "text": " tens of millions of pages daily. So it always has accurate up to date information. The Brave Search", "tokens": [51320, 10688, 295, 6803, 295, 7183, 5212, 13, 407, 309, 1009, 575, 8559, 493, 281, 4002, 1589, 13, 440, 38545, 17180, 51616], "temperature": 0.0, "avg_logprob": -0.05824785335089571, "compression_ratio": 1.52734375, "no_speech_prob": 0.008060984313488007}, {"id": 189, "seek": 99768, "start": 997.68, "end": 1002.64, "text": " API can be used to assemble a data set to train your AI models and help with retrieval", "tokens": [50364, 9362, 393, 312, 1143, 281, 22364, 257, 1412, 992, 281, 3847, 428, 7318, 5245, 293, 854, 365, 19817, 3337, 50612], "temperature": 0.0, "avg_logprob": -0.07504870891571044, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.10814802348613739}, {"id": 190, "seek": 99768, "start": 1002.64, "end": 1007.52, "text": " augmentation at the time of inference, all while remaining affordable with developer first pricing.", "tokens": [50612, 14501, 19631, 412, 264, 565, 295, 38253, 11, 439, 1339, 8877, 12028, 365, 10754, 700, 17621, 13, 50856], "temperature": 0.0, "avg_logprob": -0.07504870891571044, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.10814802348613739}, {"id": 191, "seek": 99768, "start": 1008.56, "end": 1013.3599999999999, "text": " Integrating the Brave Search API into your workflow translates to more ethical data sourcing", "tokens": [50908, 23894, 990, 264, 38545, 17180, 9362, 666, 428, 20993, 28468, 281, 544, 18890, 1412, 11006, 2175, 51148], "temperature": 0.0, "avg_logprob": -0.07504870891571044, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.10814802348613739}, {"id": 192, "seek": 99768, "start": 1013.3599999999999, "end": 1019.3599999999999, "text": " and more human representative data sets. Try the Brave Search API for free for up to 2000", "tokens": [51148, 293, 544, 1952, 12424, 1412, 6352, 13, 6526, 264, 38545, 17180, 9362, 337, 1737, 337, 493, 281, 8132, 51448], "temperature": 0.0, "avg_logprob": -0.07504870891571044, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.10814802348613739}, {"id": 193, "seek": 101936, "start": 1019.36, "end": 1031.04, "text": " queries per month at brave.com. Yeah, these are a great question. I think it shows you kind of", "tokens": [50364, 24109, 680, 1618, 412, 12653, 13, 1112, 13, 865, 11, 613, 366, 257, 869, 1168, 13, 286, 519, 309, 3110, 291, 733, 295, 50948], "temperature": 0.0, "avg_logprob": -0.1806178225411309, "compression_ratio": 1.484375, "no_speech_prob": 0.08145845681428909}, {"id": 194, "seek": 101936, "start": 1031.04, "end": 1039.2, "text": " how sophisticated the space has gotten in the last year. Around this time, last year, we were the", "tokens": [50948, 577, 16950, 264, 1901, 575, 5768, 294, 264, 1036, 1064, 13, 17633, 341, 565, 11, 1036, 1064, 11, 321, 645, 264, 51356], "temperature": 0.0, "avg_logprob": -0.1806178225411309, "compression_ratio": 1.484375, "no_speech_prob": 0.08145845681428909}, {"id": 195, "seek": 101936, "start": 1039.2, "end": 1047.52, "text": " only search engine with a web connected LN and millions of users. And now that idea has been", "tokens": [51356, 787, 3164, 2848, 365, 257, 3670, 4582, 441, 45, 293, 6803, 295, 5022, 13, 400, 586, 300, 1558, 575, 668, 51772], "temperature": 0.0, "avg_logprob": -0.1806178225411309, "compression_ratio": 1.484375, "no_speech_prob": 0.08145845681428909}, {"id": 196, "seek": 104752, "start": 1047.52, "end": 1053.52, "text": " copied so many times, including as mentioned by Plexi. And so I think what you have to differentiate", "tokens": [50364, 25365, 370, 867, 1413, 11, 3009, 382, 2835, 538, 430, 2021, 72, 13, 400, 370, 286, 519, 437, 291, 362, 281, 23203, 50664], "temperature": 0.0, "avg_logprob": -0.15596720602660052, "compression_ratio": 1.7112676056338028, "no_speech_prob": 0.043301329016685486}, {"id": 197, "seek": 104752, "start": 1053.52, "end": 1057.6, "text": " kind of the different modes, and I think the modes kind of show how sophisticated that the", "tokens": [50664, 733, 295, 264, 819, 14068, 11, 293, 286, 519, 264, 14068, 733, 295, 855, 577, 16950, 300, 264, 50868], "temperature": 0.0, "avg_logprob": -0.15596720602660052, "compression_ratio": 1.7112676056338028, "no_speech_prob": 0.043301329016685486}, {"id": 198, "seek": 104752, "start": 1057.6, "end": 1063.28, "text": " space has gotten and how hard it is to still differentiate on better technology versus just", "tokens": [50868, 1901, 575, 5768, 293, 577, 1152, 309, 307, 281, 920, 23203, 322, 1101, 2899, 5717, 445, 51152], "temperature": 0.0, "avg_logprob": -0.15596720602660052, "compression_ratio": 1.7112676056338028, "no_speech_prob": 0.043301329016685486}, {"id": 199, "seek": 104752, "start": 1063.28, "end": 1069.04, "text": " you know, designing the market and marketing and things like that. And so we actually did a comparison", "tokens": [51152, 291, 458, 11, 14685, 264, 2142, 293, 6370, 293, 721, 411, 300, 13, 400, 370, 321, 767, 630, 257, 9660, 51440], "temperature": 0.0, "avg_logprob": -0.15596720602660052, "compression_ratio": 1.7112676056338028, "no_speech_prob": 0.043301329016685486}, {"id": 200, "seek": 104752, "start": 1069.04, "end": 1076.0, "text": " to Plexi with 500 real user queries. And we asked which answer do you prefer? And it came out to be", "tokens": [51440, 281, 430, 2021, 72, 365, 5923, 957, 4195, 24109, 13, 400, 321, 2351, 597, 1867, 360, 291, 4382, 30, 400, 309, 1361, 484, 281, 312, 51788], "temperature": 0.0, "avg_logprob": -0.15596720602660052, "compression_ratio": 1.7112676056338028, "no_speech_prob": 0.043301329016685486}, {"id": 201, "seek": 107600, "start": 1076.0, "end": 1082.8, "text": " that 50% of the cases users prefer the U.com answer and they prefer the Plexi answer and 30%", "tokens": [50364, 300, 2625, 4, 295, 264, 3331, 5022, 4382, 264, 624, 13, 1112, 1867, 293, 436, 4382, 264, 430, 2021, 72, 1867, 293, 2217, 4, 50704], "temperature": 0.0, "avg_logprob": -0.16855911380988509, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.014721093699336052}, {"id": 202, "seek": 107600, "start": 1083.36, "end": 1088.96, "text": " they don't see a difference into answers for our default, we call it the smart mode. That's kind", "tokens": [50732, 436, 500, 380, 536, 257, 2649, 666, 6338, 337, 527, 7576, 11, 321, 818, 309, 264, 4069, 4391, 13, 663, 311, 733, 51012], "temperature": 0.0, "avg_logprob": -0.16855911380988509, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.014721093699336052}, {"id": 203, "seek": 107600, "start": 1088.96, "end": 1095.36, "text": " of the default. And just to give you a sense of what that looks like. So here's an example of what", "tokens": [51012, 295, 264, 7576, 13, 400, 445, 281, 976, 291, 257, 2020, 295, 437, 300, 1542, 411, 13, 407, 510, 311, 364, 1365, 295, 437, 51332], "temperature": 0.0, "avg_logprob": -0.16855911380988509, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.014721093699336052}, {"id": 204, "seek": 107600, "start": 1095.36, "end": 1099.6, "text": " the default smart mode looks like. You know, there's some doping case that happened and", "tokens": [51332, 264, 7576, 4069, 4391, 1542, 411, 13, 509, 458, 11, 456, 311, 512, 360, 3381, 1389, 300, 2011, 293, 51544], "temperature": 0.0, "avg_logprob": -0.16855911380988509, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.014721093699336052}, {"id": 205, "seek": 107600, "start": 1099.6, "end": 1104.88, "text": " you can see lots of careful citations. And then when you actually look into these citations,", "tokens": [51544, 291, 393, 536, 3195, 295, 5026, 4814, 763, 13, 400, 550, 562, 291, 767, 574, 666, 613, 4814, 763, 11, 51808], "temperature": 0.0, "avg_logprob": -0.16855911380988509, "compression_ratio": 1.7832699619771863, "no_speech_prob": 0.014721093699336052}, {"id": 206, "seek": 110488, "start": 1104.88, "end": 1110.0, "text": " they actually are articles from literally yesterday or they could be, you know, from today if something", "tokens": [50364, 436, 767, 366, 11290, 490, 3736, 5186, 420, 436, 727, 312, 11, 291, 458, 11, 490, 965, 498, 746, 50620], "temperature": 0.0, "avg_logprob": -0.18668395075304756, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005467601120471954}, {"id": 207, "seek": 110488, "start": 1110.0, "end": 1114.16, "text": " came out today. So that's kind of the default smart mode, you get a quick factual answer.", "tokens": [50620, 1361, 484, 965, 13, 407, 300, 311, 733, 295, 264, 7576, 4069, 4391, 11, 291, 483, 257, 1702, 48029, 1867, 13, 50828], "temperature": 0.0, "avg_logprob": -0.18668395075304756, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005467601120471954}, {"id": 208, "seek": 110488, "start": 1114.16, "end": 1119.6000000000001, "text": " But then we thought, well, what if you have a pretty complex question like math, physics,", "tokens": [50828, 583, 550, 321, 1194, 11, 731, 11, 437, 498, 291, 362, 257, 1238, 3997, 1168, 411, 5221, 11, 10649, 11, 51100], "temperature": 0.0, "avg_logprob": -0.18668395075304756, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005467601120471954}, {"id": 209, "seek": 110488, "start": 1119.6000000000001, "end": 1125.3600000000001, "text": " chemistry, science, or like complex numbers. So here is a genius mode question, it kind of gives", "tokens": [51100, 12558, 11, 3497, 11, 420, 411, 3997, 3547, 13, 407, 510, 307, 257, 14017, 4391, 1168, 11, 309, 733, 295, 2709, 51388], "temperature": 0.0, "avg_logprob": -0.18668395075304756, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005467601120471954}, {"id": 210, "seek": 110488, "start": 1125.3600000000001, "end": 1129.8400000000001, "text": " you a sense of what it does. And it doesn't mention like what you say, which is there's an", "tokens": [51388, 291, 257, 2020, 295, 437, 309, 775, 13, 400, 309, 1177, 380, 2152, 411, 437, 291, 584, 11, 597, 307, 456, 311, 364, 51612], "temperature": 0.0, "avg_logprob": -0.18668395075304756, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.005467601120471954}, {"id": 211, "seek": 112984, "start": 1129.84, "end": 1134.9599999999998, "text": " important LM that orchestrates multiple other LMs to actually do the right thing right. So", "tokens": [50364, 1021, 441, 44, 300, 14161, 12507, 3866, 661, 441, 26386, 281, 767, 360, 264, 558, 551, 558, 13, 407, 50620], "temperature": 0.0, "avg_logprob": -0.2406305297603452, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.2566860318183899}, {"id": 212, "seek": 112984, "start": 1134.9599999999998, "end": 1138.9599999999998, "text": " the question here is find the current population of the in the United States, then it's lots of", "tokens": [50620, 264, 1168, 510, 307, 915, 264, 2190, 4415, 295, 264, 294, 264, 2824, 3040, 11, 550, 309, 311, 3195, 295, 50820], "temperature": 0.0, "avg_logprob": -0.2406305297603452, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.2566860318183899}, {"id": 213, "seek": 112984, "start": 1138.9599999999998, "end": 1146.8799999999999, "text": " population from 233 to 10, 100, and then assuming a 2% growth rate. And then it will go on the", "tokens": [50820, 4415, 490, 6673, 18, 281, 1266, 11, 2319, 11, 293, 550, 11926, 257, 568, 4, 4599, 3314, 13, 400, 550, 309, 486, 352, 322, 264, 51216], "temperature": 0.0, "avg_logprob": -0.2406305297603452, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.2566860318183899}, {"id": 214, "seek": 112984, "start": 1146.8799999999999, "end": 1152.8799999999999, "text": " internet, it'll find the numbers, and then realize like, well, I got to now visualize those numbers,", "tokens": [51216, 4705, 11, 309, 603, 915, 264, 3547, 11, 293, 550, 4325, 411, 11, 731, 11, 286, 658, 281, 586, 23273, 729, 3547, 11, 51516], "temperature": 0.0, "avg_logprob": -0.2406305297603452, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.2566860318183899}, {"id": 215, "seek": 112984, "start": 1152.8799999999999, "end": 1159.28, "text": " now that I have any, so it will code up in Python, what this could look like, execute the code,", "tokens": [51516, 586, 300, 286, 362, 604, 11, 370, 309, 486, 3089, 493, 294, 15329, 11, 437, 341, 727, 574, 411, 11, 14483, 264, 3089, 11, 51836], "temperature": 0.0, "avg_logprob": -0.2406305297603452, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.2566860318183899}, {"id": 216, "seek": 115928, "start": 1159.28, "end": 1166.0, "text": " and then gives you this answer, and visualizes it in a nice plot. And so that I'm still sometimes", "tokens": [50364, 293, 550, 2709, 291, 341, 1867, 11, 293, 5056, 5660, 309, 294, 257, 1481, 7542, 13, 400, 370, 300, 286, 478, 920, 2171, 50700], "temperature": 0.0, "avg_logprob": -0.1262840580295872, "compression_ratio": 1.8662207357859533, "no_speech_prob": 0.0016740212449803948}, {"id": 217, "seek": 115928, "start": 1166.0, "end": 1170.16, "text": " amazed, I try and I push it, and you know, sometimes it fails. And sometimes it fails", "tokens": [50700, 20507, 11, 286, 853, 293, 286, 2944, 309, 11, 293, 291, 458, 11, 2171, 309, 18199, 13, 400, 2171, 309, 18199, 50908], "temperature": 0.0, "avg_logprob": -0.1262840580295872, "compression_ratio": 1.8662207357859533, "no_speech_prob": 0.0016740212449803948}, {"id": 218, "seek": 115928, "start": 1170.16, "end": 1173.44, "text": " because it tries to load the library that has security issue. And then it's like, okay, I'm", "tokens": [50908, 570, 309, 9898, 281, 3677, 264, 6405, 300, 575, 3825, 2734, 13, 400, 550, 309, 311, 411, 11, 1392, 11, 286, 478, 51072], "temperature": 0.0, "avg_logprob": -0.1262840580295872, "compression_ratio": 1.8662207357859533, "no_speech_prob": 0.0016740212449803948}, {"id": 219, "seek": 115928, "start": 1173.44, "end": 1177.6, "text": " going to try to rewrite it without this library, but it's going to be longer and messier code.", "tokens": [51072, 516, 281, 853, 281, 28132, 309, 1553, 341, 6405, 11, 457, 309, 311, 516, 281, 312, 2854, 293, 2082, 811, 3089, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1262840580295872, "compression_ratio": 1.8662207357859533, "no_speech_prob": 0.0016740212449803948}, {"id": 220, "seek": 115928, "start": 1177.6, "end": 1183.52, "text": " And like, it's just incredible how hard it can try and what it can do. And then the third mode,", "tokens": [51280, 400, 411, 11, 309, 311, 445, 4651, 577, 1152, 309, 393, 853, 293, 437, 309, 393, 360, 13, 400, 550, 264, 2636, 4391, 11, 51576], "temperature": 0.0, "avg_logprob": -0.1262840580295872, "compression_ratio": 1.8662207357859533, "no_speech_prob": 0.0016740212449803948}, {"id": 221, "seek": 115928, "start": 1183.52, "end": 1189.04, "text": " like you said, the research mode, it will go into a lot of detail, it will not just look up", "tokens": [51576, 411, 291, 848, 11, 264, 2132, 4391, 11, 309, 486, 352, 666, 257, 688, 295, 2607, 11, 309, 486, 406, 445, 574, 493, 51852], "temperature": 0.0, "avg_logprob": -0.1262840580295872, "compression_ratio": 1.8662207357859533, "no_speech_prob": 0.0016740212449803948}, {"id": 222, "seek": 118928, "start": 1189.28, "end": 1193.2, "text": " all the stuff we have in our index already, like news and things like that, but it will go on the", "tokens": [50364, 439, 264, 1507, 321, 362, 294, 527, 8186, 1217, 11, 411, 2583, 293, 721, 411, 300, 11, 457, 309, 486, 352, 322, 264, 50560], "temperature": 0.0, "avg_logprob": -0.20572660723303118, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.0022511158604174852}, {"id": 223, "seek": 118928, "start": 1193.2, "end": 1199.6, "text": " web and find your website, so the multiple different searches on the web, combine all of that,", "tokens": [50560, 3670, 293, 915, 428, 3144, 11, 370, 264, 3866, 819, 26701, 322, 264, 3670, 11, 10432, 439, 295, 300, 11, 50880], "temperature": 0.0, "avg_logprob": -0.20572660723303118, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.0022511158604174852}, {"id": 224, "seek": 118928, "start": 1199.6, "end": 1204.3999999999999, "text": " and then give you these beautiful research reports. This one is like, seeing a background,", "tokens": [50880, 293, 550, 976, 291, 613, 2238, 2132, 7122, 13, 639, 472, 307, 411, 11, 2577, 257, 3678, 11, 51120], "temperature": 0.0, "avg_logprob": -0.20572660723303118, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.0022511158604174852}, {"id": 225, "seek": 118928, "start": 1204.3999999999999, "end": 1209.44, "text": " actually, any consequences of the telecommuting work. Now it's like, history, you have to write an", "tokens": [51120, 767, 11, 604, 10098, 295, 264, 4304, 13278, 10861, 589, 13, 823, 309, 311, 411, 11, 2503, 11, 291, 362, 281, 2464, 364, 51372], "temperature": 0.0, "avg_logprob": -0.20572660723303118, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.0022511158604174852}, {"id": 226, "seek": 118928, "start": 1209.44, "end": 1214.96, "text": " essay or something. And it's just like, writes you just perfect, like, beautiful essay, each", "tokens": [51372, 16238, 420, 746, 13, 400, 309, 311, 445, 411, 11, 13657, 291, 445, 2176, 11, 411, 11, 2238, 16238, 11, 1184, 51648], "temperature": 0.0, "avg_logprob": -0.20572660723303118, "compression_ratio": 1.7210144927536233, "no_speech_prob": 0.0022511158604174852}, {"id": 227, "seek": 121496, "start": 1214.96, "end": 1220.56, "text": " sentence has one or two citations from different sources, and you can verify all of them. And", "tokens": [50364, 8174, 575, 472, 420, 732, 4814, 763, 490, 819, 7139, 11, 293, 291, 393, 16888, 439, 295, 552, 13, 400, 50644], "temperature": 0.0, "avg_logprob": -0.15337124205472177, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.03160807117819786}, {"id": 228, "seek": 121496, "start": 1220.56, "end": 1225.52, "text": " one thing we found this actually also is like, you have to like, just the citation lot is a", "tokens": [50644, 472, 551, 321, 1352, 341, 767, 611, 307, 411, 11, 291, 362, 281, 411, 11, 445, 264, 45590, 688, 307, 257, 50892], "temperature": 0.0, "avg_logprob": -0.15337124205472177, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.03160807117819786}, {"id": 229, "seek": 121496, "start": 1225.52, "end": 1231.3600000000001, "text": " non-trivial aspect of building this all out. Because you have to, we actually found that some", "tokens": [50892, 2107, 12, 83, 470, 22640, 4171, 295, 2390, 341, 439, 484, 13, 1436, 291, 362, 281, 11, 321, 767, 1352, 300, 512, 51184], "temperature": 0.0, "avg_logprob": -0.15337124205472177, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.03160807117819786}, {"id": 230, "seek": 121496, "start": 1231.3600000000001, "end": 1237.3600000000001, "text": " of our competitors just randomly add numbers and citations to sentences, and you click on it,", "tokens": [51184, 295, 527, 18333, 445, 16979, 909, 3547, 293, 4814, 763, 281, 16579, 11, 293, 291, 2052, 322, 309, 11, 51484], "temperature": 0.0, "avg_logprob": -0.15337124205472177, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.03160807117819786}, {"id": 231, "seek": 121496, "start": 1237.92, "end": 1243.52, "text": " and it doesn't even mention that back anymore. Which I think it really undermines the space of", "tokens": [51512, 293, 309, 1177, 380, 754, 2152, 300, 646, 3602, 13, 3013, 286, 519, 309, 534, 24188, 1652, 264, 1901, 295, 51792], "temperature": 0.0, "avg_logprob": -0.15337124205472177, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.03160807117819786}, {"id": 232, "seek": 124352, "start": 1243.52, "end": 1250.72, "text": " chatbots for search. So citation accuracy is one of the many sub-AI systems that you need to do", "tokens": [50364, 5081, 65, 1971, 337, 3164, 13, 407, 45590, 14170, 307, 472, 295, 264, 867, 1422, 12, 48698, 3652, 300, 291, 643, 281, 360, 50724], "temperature": 0.0, "avg_logprob": -0.19240147843320146, "compression_ratio": 1.68, "no_speech_prob": 0.014275453053414822}, {"id": 233, "seek": 124352, "start": 1250.72, "end": 1254.56, "text": " correctly here. And then, you know, they're just like crazy things, like create a table,", "tokens": [50724, 8944, 510, 13, 400, 550, 11, 291, 458, 11, 436, 434, 445, 411, 3219, 721, 11, 411, 1884, 257, 3199, 11, 50916], "temperature": 0.0, "avg_logprob": -0.19240147843320146, "compression_ratio": 1.68, "no_speech_prob": 0.014275453053414822}, {"id": 234, "seek": 124352, "start": 1254.56, "end": 1259.12, "text": " some nice cancelling headphones that are not expensive, and just like, put this table together,", "tokens": [50916, 512, 1481, 393, 384, 2669, 16278, 300, 366, 406, 5124, 11, 293, 445, 411, 11, 829, 341, 3199, 1214, 11, 51144], "temperature": 0.0, "avg_logprob": -0.19240147843320146, "compression_ratio": 1.68, "no_speech_prob": 0.014275453053414822}, {"id": 235, "seek": 124352, "start": 1259.12, "end": 1263.68, "text": " pull some images, give some pros and cons of each and the price. I think sometimes, to me,", "tokens": [51144, 2235, 512, 5267, 11, 976, 512, 6267, 293, 1014, 295, 1184, 293, 264, 3218, 13, 286, 519, 2171, 11, 281, 385, 11, 51372], "temperature": 0.0, "avg_logprob": -0.19240147843320146, "compression_ratio": 1.68, "no_speech_prob": 0.014275453053414822}, {"id": 236, "seek": 124352, "start": 1263.68, "end": 1269.76, "text": " is how well and general the system is able to answer these questions. And it shows you how", "tokens": [51372, 307, 577, 731, 293, 2674, 264, 1185, 307, 1075, 281, 1867, 613, 1651, 13, 400, 309, 3110, 291, 577, 51676], "temperature": 0.0, "avg_logprob": -0.19240147843320146, "compression_ratio": 1.68, "no_speech_prob": 0.014275453053414822}, {"id": 237, "seek": 126976, "start": 1269.76, "end": 1274.4, "text": " complex the space is gotten and how much you have to do now to still differentiate on the", "tokens": [50364, 3997, 264, 1901, 307, 5768, 293, 577, 709, 291, 362, 281, 360, 586, 281, 920, 23203, 322, 264, 50596], "temperature": 0.0, "avg_logprob": -0.1247875608246902, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.008845880627632141}, {"id": 238, "seek": 126976, "start": 1274.4, "end": 1279.68, "text": " technology. This is one of my mantras at Waymark. I always say the water line is rising quickly.", "tokens": [50596, 2899, 13, 639, 307, 472, 295, 452, 10845, 3906, 412, 9558, 5638, 13, 286, 1009, 584, 264, 1281, 1622, 307, 11636, 2661, 13, 50860], "temperature": 0.0, "avg_logprob": -0.1247875608246902, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.008845880627632141}, {"id": 239, "seek": 126976, "start": 1279.68, "end": 1285.84, "text": " So we, you know, we better keep climbing the capabilities ladder ourselves. The four examples", "tokens": [50860, 407, 321, 11, 291, 458, 11, 321, 1101, 1066, 14780, 264, 10862, 18325, 4175, 13, 440, 1451, 5110, 51168], "temperature": 0.0, "avg_logprob": -0.1247875608246902, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.008845880627632141}, {"id": 240, "seek": 126976, "start": 1285.84, "end": 1290.08, "text": " that we saw there, one was the kind of default smart mode. The second was genius. Is that right?", "tokens": [51168, 300, 321, 1866, 456, 11, 472, 390, 264, 733, 295, 7576, 4069, 4391, 13, 440, 1150, 390, 14017, 13, 1119, 300, 558, 30, 51380], "temperature": 0.0, "avg_logprob": -0.1247875608246902, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.008845880627632141}, {"id": 241, "seek": 126976, "start": 1290.08, "end": 1294.8799999999999, "text": " The one that showed the code example. And then the last two were research. Yeah. What more can you", "tokens": [51380, 440, 472, 300, 4712, 264, 3089, 1365, 13, 400, 550, 264, 1036, 732, 645, 2132, 13, 865, 13, 708, 544, 393, 291, 51620], "temperature": 0.0, "avg_logprob": -0.1247875608246902, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.008845880627632141}, {"id": 242, "seek": 129488, "start": 1295.5200000000002, "end": 1300.16, "text": " tell us about kind of how those work? Like I'm interested in, and by the way, like the", "tokens": [50396, 980, 505, 466, 733, 295, 577, 729, 589, 30, 1743, 286, 478, 3102, 294, 11, 293, 538, 264, 636, 11, 411, 264, 50628], "temperature": 0.0, "avg_logprob": -0.11015629294692286, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.3884471654891968}, {"id": 243, "seek": 129488, "start": 1300.16, "end": 1304.16, "text": " audience of the cognitive revolution is interested in the details, the weeds, the nuggets, you know,", "tokens": [50628, 4034, 295, 264, 15605, 8894, 307, 3102, 294, 264, 4365, 11, 264, 26370, 11, 264, 42663, 11, 291, 458, 11, 50828], "temperature": 0.0, "avg_logprob": -0.11015629294692286, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.3884471654891968}, {"id": 244, "seek": 129488, "start": 1304.16, "end": 1308.24, "text": " all that stuff. So you can go as deep as you're, you know, willing to share. I'm interested in", "tokens": [50828, 439, 300, 1507, 13, 407, 291, 393, 352, 382, 2452, 382, 291, 434, 11, 291, 458, 11, 4950, 281, 2073, 13, 286, 478, 3102, 294, 51032], "temperature": 0.0, "avg_logprob": -0.11015629294692286, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.3884471654891968}, {"id": 245, "seek": 129488, "start": 1308.24, "end": 1311.8400000000001, "text": " all aspects, you know, prompting, I'm sure, obviously, is going to be different. Scaffolding", "tokens": [51032, 439, 7270, 11, 291, 458, 11, 12391, 278, 11, 286, 478, 988, 11, 2745, 11, 307, 516, 281, 312, 819, 13, 47082, 602, 2641, 278, 51212], "temperature": 0.0, "avg_logprob": -0.11015629294692286, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.3884471654891968}, {"id": 246, "seek": 129488, "start": 1311.8400000000001, "end": 1315.0400000000002, "text": " is going to be different. Maybe even the models are different. I'm also really interested in,", "tokens": [51212, 307, 516, 281, 312, 819, 13, 2704, 754, 264, 5245, 366, 819, 13, 286, 478, 611, 534, 3102, 294, 11, 51372], "temperature": 0.0, "avg_logprob": -0.11015629294692286, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.3884471654891968}, {"id": 247, "seek": 129488, "start": 1315.0400000000002, "end": 1320.24, "text": " like, what are you using GPT-4 that you've got your own in-house trained ones as well. So", "tokens": [51372, 411, 11, 437, 366, 291, 1228, 26039, 51, 12, 19, 300, 291, 600, 658, 428, 1065, 294, 12, 6410, 8895, 2306, 382, 731, 13, 407, 51632], "temperature": 0.0, "avg_logprob": -0.11015629294692286, "compression_ratio": 1.8388157894736843, "no_speech_prob": 0.3884471654891968}, {"id": 248, "seek": 132024, "start": 1320.24, "end": 1323.52, "text": " just all those considerations, any interesting nuggets were all ears.", "tokens": [50364, 445, 439, 729, 24070, 11, 604, 1880, 42663, 645, 439, 8798, 13, 50528], "temperature": 0.0, "avg_logprob": -0.142267958026066, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.006486681289970875}, {"id": 249, "seek": 132024, "start": 1324.4, "end": 1329.28, "text": " Yeah, I'm going to try to balance a little bit the not telling the competition exactly how it's", "tokens": [50572, 865, 11, 286, 478, 516, 281, 853, 281, 4772, 257, 707, 857, 264, 406, 3585, 264, 6211, 2293, 577, 309, 311, 50816], "temperature": 0.0, "avg_logprob": -0.142267958026066, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.006486681289970875}, {"id": 250, "seek": 132024, "start": 1329.28, "end": 1335.84, "text": " all done, but it'd be interesting to your ears here. So at a high level, there are two major", "tokens": [50816, 439, 1096, 11, 457, 309, 1116, 312, 1880, 281, 428, 8798, 510, 13, 407, 412, 257, 1090, 1496, 11, 456, 366, 732, 2563, 51144], "temperature": 0.0, "avg_logprob": -0.142267958026066, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.006486681289970875}, {"id": 251, "seek": 132024, "start": 1335.84, "end": 1342.32, "text": " stacks. There's a search stack and a chat stack. The search stack, we actually had to build an", "tokens": [51144, 30792, 13, 821, 311, 257, 3164, 8630, 293, 257, 5081, 8630, 13, 440, 3164, 8630, 11, 321, 767, 632, 281, 1322, 364, 51468], "temperature": 0.0, "avg_logprob": -0.142267958026066, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.006486681289970875}, {"id": 252, "seek": 132024, "start": 1342.32, "end": 1349.76, "text": " entire index ourselves for the web because being super expensive, not as high quality, Google", "tokens": [51468, 2302, 8186, 4175, 337, 264, 3670, 570, 885, 1687, 5124, 11, 406, 382, 1090, 3125, 11, 3329, 51840], "temperature": 0.0, "avg_logprob": -0.142267958026066, "compression_ratio": 1.6494464944649447, "no_speech_prob": 0.006486681289970875}, {"id": 253, "seek": 134976, "start": 1349.76, "end": 1354.4, "text": " is very hard to access. You have to have special agreements or, you know, some people kind of", "tokens": [50364, 307, 588, 1152, 281, 2105, 13, 509, 362, 281, 362, 2121, 21422, 420, 11, 291, 458, 11, 512, 561, 733, 295, 50596], "temperature": 0.0, "avg_logprob": -0.1843250274658203, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0014317885506898165}, {"id": 254, "seek": 134976, "start": 1354.4, "end": 1360.48, "text": " steal slash bootleg slash leave some surveyed the eyes to use Google results in like a somewhat", "tokens": [50596, 11009, 17330, 11450, 6363, 17330, 1856, 512, 8984, 292, 264, 2575, 281, 764, 3329, 3542, 294, 411, 257, 8344, 50900], "temperature": 0.0, "avg_logprob": -0.1843250274658203, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0014317885506898165}, {"id": 255, "seek": 134976, "start": 1360.48, "end": 1366.4, "text": " sketchy legal gray area, which we don't want to do. And so we, we basically ended up having to", "tokens": [50900, 12325, 88, 5089, 10855, 1859, 11, 597, 321, 500, 380, 528, 281, 360, 13, 400, 370, 321, 11, 321, 1936, 4590, 493, 1419, 281, 51196], "temperature": 0.0, "avg_logprob": -0.1843250274658203, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0014317885506898165}, {"id": 256, "seek": 134976, "start": 1366.4, "end": 1371.68, "text": " build our own index. And that's hard. And there's still, you know, a lot of complexities behind", "tokens": [51196, 1322, 527, 1065, 8186, 13, 400, 300, 311, 1152, 13, 400, 456, 311, 920, 11, 291, 458, 11, 257, 688, 295, 48705, 2261, 51460], "temperature": 0.0, "avg_logprob": -0.1843250274658203, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0014317885506898165}, {"id": 257, "seek": 134976, "start": 1371.68, "end": 1377.92, "text": " that. But what do we, the main difference of this new index is that it was built with LNs in mind.", "tokens": [51460, 300, 13, 583, 437, 360, 321, 11, 264, 2135, 2649, 295, 341, 777, 8186, 307, 300, 309, 390, 3094, 365, 441, 45, 82, 294, 1575, 13, 51772], "temperature": 0.0, "avg_logprob": -0.1843250274658203, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.0014317885506898165}, {"id": 258, "seek": 137792, "start": 1378.48, "end": 1385.8400000000001, "text": " The previous two indices of Google and Bing were built with people consuming 10 blue links in mind.", "tokens": [50392, 440, 3894, 732, 43840, 295, 3329, 293, 30755, 645, 3094, 365, 561, 19867, 1266, 3344, 6123, 294, 1575, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1474628780199134, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.003944632597267628}, {"id": 259, "seek": 137792, "start": 1386.72, "end": 1391.6000000000001, "text": " And what that means is for each URL, you get a very short snippet, which makes sense, right,", "tokens": [50804, 400, 437, 300, 1355, 307, 337, 1184, 12905, 11, 291, 483, 257, 588, 2099, 35623, 302, 11, 597, 1669, 2020, 11, 558, 11, 51048], "temperature": 0.0, "avg_logprob": -0.1474628780199134, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.003944632597267628}, {"id": 260, "seek": 137792, "start": 1391.6000000000001, "end": 1395.76, "text": " for end users. But an LN could read all these other snippets, they can be very long,", "tokens": [51048, 337, 917, 5022, 13, 583, 364, 441, 45, 727, 1401, 439, 613, 661, 35623, 1385, 11, 436, 393, 312, 588, 938, 11, 51256], "temperature": 0.0, "avg_logprob": -0.1474628780199134, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.003944632597267628}, {"id": 261, "seek": 137792, "start": 1396.5600000000002, "end": 1400.8000000000002, "text": " and then extract the right answers from that, and then just give you that right answer as the", "tokens": [51296, 293, 550, 8947, 264, 558, 6338, 490, 300, 11, 293, 550, 445, 976, 291, 300, 558, 1867, 382, 264, 51508], "temperature": 0.0, "avg_logprob": -0.1474628780199134, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.003944632597267628}, {"id": 262, "seek": 137792, "start": 1400.8000000000002, "end": 1406.16, "text": " user. And so what was surprising is actually when we benchmark this, our API ended up being more", "tokens": [51508, 4195, 13, 400, 370, 437, 390, 8830, 307, 767, 562, 321, 18927, 341, 11, 527, 9362, 4590, 493, 885, 544, 51776], "temperature": 0.0, "avg_logprob": -0.1474628780199134, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.003944632597267628}, {"id": 263, "seek": 140616, "start": 1406.16, "end": 1411.92, "text": " accurate than Google or me and go to API.com. And like, I'll, I'll see you on the screen here for", "tokens": [50364, 8559, 813, 3329, 420, 385, 293, 352, 281, 9362, 13, 1112, 13, 400, 411, 11, 286, 603, 11, 286, 603, 536, 291, 322, 264, 2568, 510, 337, 50652], "temperature": 0.0, "avg_logprob": -0.21786130185158836, "compression_ratio": 1.803225806451613, "no_speech_prob": 0.010814856737852097}, {"id": 264, "seek": 140616, "start": 1411.92, "end": 1416.48, "text": " a second again. But like, it's surprising that, which are a lot of people that you could actually", "tokens": [50652, 257, 1150, 797, 13, 583, 411, 11, 309, 311, 8830, 300, 11, 597, 366, 257, 688, 295, 561, 300, 291, 727, 767, 50880], "temperature": 0.0, "avg_logprob": -0.21786130185158836, "compression_ratio": 1.803225806451613, "no_speech_prob": 0.010814856737852097}, {"id": 265, "seek": 140616, "start": 1416.48, "end": 1421.0400000000002, "text": " be more accurate in Google or Bing at all. But it is because we're at an inflection point in,", "tokens": [50880, 312, 544, 8559, 294, 3329, 420, 30755, 412, 439, 13, 583, 309, 307, 570, 321, 434, 412, 364, 1536, 5450, 935, 294, 11, 51108], "temperature": 0.0, "avg_logprob": -0.21786130185158836, "compression_ratio": 1.803225806451613, "no_speech_prob": 0.010814856737852097}, {"id": 266, "seek": 140616, "start": 1421.0400000000002, "end": 1425.52, "text": " in a, in the eye, and it's a different way to value. It's like, we're almost like", "tokens": [51108, 294, 257, 11, 294, 264, 3313, 11, 293, 309, 311, 257, 819, 636, 281, 2158, 13, 467, 311, 411, 11, 321, 434, 1920, 411, 51332], "temperature": 0.0, "avg_logprob": -0.21786130185158836, "compression_ratio": 1.803225806451613, "no_speech_prob": 0.010814856737852097}, {"id": 267, "seek": 140616, "start": 1425.52, "end": 1430.48, "text": " cheating by having these really long snippets. And so you look at the comparison, and it's", "tokens": [51332, 18309, 538, 1419, 613, 534, 938, 35623, 1385, 13, 400, 370, 291, 574, 412, 264, 9660, 11, 293, 309, 311, 51580], "temperature": 0.0, "avg_logprob": -0.21786130185158836, "compression_ratio": 1.803225806451613, "no_speech_prob": 0.010814856737852097}, {"id": 268, "seek": 140616, "start": 1430.48, "end": 1434.5600000000002, "text": " actually kind of interesting to look at. And a lot of people have asked like, how do you compare", "tokens": [51580, 767, 733, 295, 1880, 281, 574, 412, 13, 400, 257, 688, 295, 561, 362, 2351, 411, 11, 577, 360, 291, 6794, 51784], "temperature": 0.0, "avg_logprob": -0.21786130185158836, "compression_ratio": 1.803225806451613, "no_speech_prob": 0.010814856737852097}, {"id": 269, "seek": 143456, "start": 1435.12, "end": 1440.32, "text": " accuracy in LNs? How can you evaluate this? And so just to give you a sense, here's like, what,", "tokens": [50392, 14170, 294, 441, 45, 82, 30, 1012, 393, 291, 13059, 341, 30, 400, 370, 445, 281, 976, 291, 257, 2020, 11, 510, 311, 411, 11, 437, 11, 50652], "temperature": 0.0, "avg_logprob": -0.12059235760546107, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.00394474295899272}, {"id": 270, "seek": 143456, "start": 1440.32, "end": 1444.56, "text": " what this looks like, the first a version is just like reasons to smile. And now you can use whatever", "tokens": [50652, 437, 341, 1542, 411, 11, 264, 700, 257, 3037, 307, 445, 411, 4112, 281, 7563, 13, 400, 586, 291, 393, 764, 2035, 50864], "temperature": 0.0, "avg_logprob": -0.12059235760546107, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.00394474295899272}, {"id": 271, "seek": 143456, "start": 1444.56, "end": 1451.2, "text": " LN you want, but you can see into your prompt is very, very long snippets from many different", "tokens": [50864, 441, 45, 291, 528, 11, 457, 291, 393, 536, 666, 428, 12391, 307, 588, 11, 588, 938, 35623, 1385, 490, 867, 819, 51196], "temperature": 0.0, "avg_logprob": -0.12059235760546107, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.00394474295899272}, {"id": 272, "seek": 143456, "start": 1451.2, "end": 1455.52, "text": " URLs in a very short amount of time. And then we also have one that just does everything,", "tokens": [51196, 43267, 294, 257, 588, 2099, 2372, 295, 565, 13, 400, 550, 321, 611, 362, 472, 300, 445, 775, 1203, 11, 51412], "temperature": 0.0, "avg_logprob": -0.12059235760546107, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.00394474295899272}, {"id": 273, "seek": 143456, "start": 1455.52, "end": 1460.1599999999999, "text": " like it gives you an LN answer, and it tells you like all of these things. And so how do you", "tokens": [51412, 411, 309, 2709, 291, 364, 441, 45, 1867, 11, 293, 309, 5112, 291, 411, 439, 295, 613, 721, 13, 400, 370, 577, 360, 291, 51644], "temperature": 0.0, "avg_logprob": -0.12059235760546107, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.00394474295899272}, {"id": 274, "seek": 146016, "start": 1460.16, "end": 1465.6000000000001, "text": " evaluate this is actually, it was an interesting, I think insights insight from our team, which was,", "tokens": [50364, 13059, 341, 307, 767, 11, 309, 390, 364, 1880, 11, 286, 519, 14310, 11269, 490, 527, 1469, 11, 597, 390, 11, 50636], "temperature": 0.0, "avg_logprob": -0.2427472098399017, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.08385729044675827}, {"id": 275, "seek": 146016, "start": 1465.6000000000001, "end": 1471.1200000000001, "text": " you can take question answering data such as hotpot qa, squat, so the question answering", "tokens": [50636, 291, 393, 747, 1168, 13430, 1412, 1270, 382, 2368, 17698, 9505, 64, 11, 24305, 11, 370, 264, 1168, 13430, 50912], "temperature": 0.0, "avg_logprob": -0.2427472098399017, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.08385729044675827}, {"id": 276, "seek": 146016, "start": 1471.1200000000001, "end": 1478.0800000000002, "text": " data set MS, Microsoft, Marco, fresh QA and so on. And these data sets are structured such that you", "tokens": [50912, 1412, 992, 7395, 11, 8116, 11, 26535, 11, 4451, 1249, 32, 293, 370, 322, 13, 400, 613, 1412, 6352, 366, 18519, 1270, 300, 291, 51260], "temperature": 0.0, "avg_logprob": -0.2427472098399017, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.08385729044675827}, {"id": 277, "seek": 146016, "start": 1478.0800000000002, "end": 1484.3200000000002, "text": " have a paragraph, you really have a question, and then you have a subset phrase from that paragraph", "tokens": [51260, 362, 257, 18865, 11, 291, 534, 362, 257, 1168, 11, 293, 550, 291, 362, 257, 25993, 9535, 490, 300, 18865, 51572], "temperature": 0.0, "avg_logprob": -0.2427472098399017, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.08385729044675827}, {"id": 278, "seek": 146016, "start": 1484.3200000000002, "end": 1489.92, "text": " that is the right answer to that question. And so what we do is, we basically take those data sets", "tokens": [51572, 300, 307, 264, 558, 1867, 281, 300, 1168, 13, 400, 370, 437, 321, 360, 307, 11, 321, 1936, 747, 729, 1412, 6352, 51852], "temperature": 0.0, "avg_logprob": -0.2427472098399017, "compression_ratio": 1.8697318007662835, "no_speech_prob": 0.08385729044675827}, {"id": 279, "seek": 148992, "start": 1489.92, "end": 1495.2, "text": " but we throw away all the paragraphs. And then you have to find the right answer. And the paragraphs", "tokens": [50364, 457, 321, 3507, 1314, 439, 264, 48910, 13, 400, 550, 291, 362, 281, 915, 264, 558, 1867, 13, 400, 264, 48910, 50628], "temperature": 0.0, "avg_logprob": -0.17174281888795132, "compression_ratio": 1.65, "no_speech_prob": 0.0015484230825677514}, {"id": 280, "seek": 148992, "start": 1495.2, "end": 1501.8400000000001, "text": " have to come from the internet. And so you replace paragraph with a web search engine. And that's how", "tokens": [50628, 362, 281, 808, 490, 264, 4705, 13, 400, 370, 291, 7406, 18865, 365, 257, 3670, 3164, 2848, 13, 400, 300, 311, 577, 50960], "temperature": 0.0, "avg_logprob": -0.17174281888795132, "compression_ratio": 1.65, "no_speech_prob": 0.0015484230825677514}, {"id": 281, "seek": 148992, "start": 1501.8400000000001, "end": 1509.44, "text": " we evaluate it, the JIT, the big Google and the public APIs, and have outputs on them. So kind", "tokens": [50960, 321, 13059, 309, 11, 264, 508, 3927, 11, 264, 955, 3329, 293, 264, 1908, 21445, 11, 293, 362, 23930, 322, 552, 13, 407, 733, 51340], "temperature": 0.0, "avg_logprob": -0.17174281888795132, "compression_ratio": 1.65, "no_speech_prob": 0.0015484230825677514}, {"id": 282, "seek": 148992, "start": 1509.44, "end": 1514.88, "text": " of nerdy, but that's the whole tech stack. And we're we make that now available to every other LN.", "tokens": [51340, 295, 18219, 3173, 11, 457, 300, 311, 264, 1379, 7553, 8630, 13, 400, 321, 434, 321, 652, 300, 586, 2435, 281, 633, 661, 441, 45, 13, 51612], "temperature": 0.0, "avg_logprob": -0.17174281888795132, "compression_ratio": 1.65, "no_speech_prob": 0.0015484230825677514}, {"id": 283, "seek": 151488, "start": 1514.88, "end": 1520.96, "text": " So that's the first. And then the second thing is what we now have started calling the LNOS,", "tokens": [50364, 407, 300, 311, 264, 700, 13, 400, 550, 264, 1150, 551, 307, 437, 321, 586, 362, 1409, 5141, 264, 441, 45, 4367, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14750409863658787, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.02227688394486904}, {"id": 284, "seek": 151488, "start": 1520.96, "end": 1526.64, "text": " the operating system of large language models. And it's a term inspired by Andrey Kapathy.", "tokens": [50668, 264, 7447, 1185, 295, 2416, 2856, 5245, 13, 400, 309, 311, 257, 1433, 7547, 538, 400, 7950, 21216, 9527, 13, 50952], "temperature": 0.0, "avg_logprob": -0.14750409863658787, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.02227688394486904}, {"id": 285, "seek": 151488, "start": 1526.64, "end": 1531.3600000000001, "text": " And it's not like the most perfect metaphor, but I think it captures a lot of the essence, which is", "tokens": [50952, 400, 309, 311, 406, 411, 264, 881, 2176, 19157, 11, 457, 286, 519, 309, 27986, 257, 688, 295, 264, 12801, 11, 597, 307, 51188], "temperature": 0.0, "avg_logprob": -0.14750409863658787, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.02227688394486904}, {"id": 286, "seek": 151488, "start": 1531.3600000000001, "end": 1539.0400000000002, "text": " you have now this new staff that operates at a much higher level of abstraction. And the LN is", "tokens": [51188, 291, 362, 586, 341, 777, 3525, 300, 22577, 412, 257, 709, 2946, 1496, 295, 37765, 13, 400, 264, 441, 45, 307, 51572], "temperature": 0.0, "avg_logprob": -0.14750409863658787, "compression_ratio": 1.6016949152542372, "no_speech_prob": 0.02227688394486904}, {"id": 287, "seek": 153904, "start": 1539.04, "end": 1545.6, "text": " kind of a CPU. But just like a CPU or a kernel on an operating system, like it's important to", "tokens": [50364, 733, 295, 257, 13199, 13, 583, 445, 411, 257, 13199, 420, 257, 28256, 322, 364, 7447, 1185, 11, 411, 309, 311, 1021, 281, 50692], "temperature": 0.0, "avg_logprob": -0.19515653000664465, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0655585378408432}, {"id": 288, "seek": 153904, "start": 1545.6, "end": 1552.48, "text": " orchestrate everything and to do computation. But if it still needs a hard drive, which is", "tokens": [50692, 14161, 4404, 1203, 293, 281, 360, 24903, 13, 583, 498, 309, 920, 2203, 257, 1152, 3332, 11, 597, 307, 51036], "temperature": 0.0, "avg_logprob": -0.19515653000664465, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0655585378408432}, {"id": 289, "seek": 153904, "start": 1552.48, "end": 1558.96, "text": " right, right on your own vector database that's grown up, you have an internet connection, which", "tokens": [51036, 558, 11, 558, 322, 428, 1065, 8062, 8149, 300, 311, 7709, 493, 11, 291, 362, 364, 4705, 4984, 11, 597, 51360], "temperature": 0.0, "avg_logprob": -0.19515653000664465, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0655585378408432}, {"id": 290, "seek": 153904, "start": 1558.96, "end": 1564.56, "text": " is, you know, the internet. And that's what we're providing. You may orchestrate other LNs that", "tokens": [51360, 307, 11, 291, 458, 11, 264, 4705, 13, 400, 300, 311, 437, 321, 434, 6530, 13, 509, 815, 14161, 4404, 661, 441, 45, 82, 300, 51640], "temperature": 0.0, "avg_logprob": -0.19515653000664465, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0655585378408432}, {"id": 291, "seek": 156456, "start": 1564.56, "end": 1569.2, "text": " could be considered like the GPU or something. And then you have a bunch of apps that are sitting", "tokens": [50364, 727, 312, 4888, 411, 264, 18407, 420, 746, 13, 400, 550, 291, 362, 257, 3840, 295, 7733, 300, 366, 3798, 50596], "temperature": 0.0, "avg_logprob": -0.14351895960365854, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.04740199074149132}, {"id": 292, "seek": 156456, "start": 1569.2, "end": 1574.24, "text": " on top of that. You have a Python code interpreter, which we see our genius mode, all of that. And so", "tokens": [50596, 322, 1192, 295, 300, 13, 509, 362, 257, 15329, 3089, 34132, 11, 597, 321, 536, 527, 14017, 4391, 11, 439, 295, 300, 13, 400, 370, 50848], "temperature": 0.0, "avg_logprob": -0.14351895960365854, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.04740199074149132}, {"id": 293, "seek": 156456, "start": 1574.24, "end": 1580.1599999999999, "text": " to summarize all of that in one short term, we call the LNOS. And inside of that, we're now seeing", "tokens": [50848, 281, 20858, 439, 295, 300, 294, 472, 2099, 1433, 11, 321, 818, 264, 441, 45, 4367, 13, 400, 1854, 295, 300, 11, 321, 434, 586, 2577, 51144], "temperature": 0.0, "avg_logprob": -0.14351895960365854, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.04740199074149132}, {"id": 294, "seek": 156456, "start": 1580.1599999999999, "end": 1586.72, "text": " a lot of our customers are using our APIs and search site. They're kind of going through the same", "tokens": [51144, 257, 688, 295, 527, 4581, 366, 1228, 527, 21445, 293, 3164, 3621, 13, 814, 434, 733, 295, 516, 807, 264, 912, 51472], "temperature": 0.0, "avg_logprob": -0.14351895960365854, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.04740199074149132}, {"id": 295, "seek": 156456, "start": 1586.72, "end": 1593.36, "text": " lessons that we had gone through when we built dot com and made it like having the most accurate", "tokens": [51472, 8820, 300, 321, 632, 2780, 807, 562, 321, 3094, 5893, 395, 293, 1027, 309, 411, 1419, 264, 881, 8559, 51804], "temperature": 0.0, "avg_logprob": -0.14351895960365854, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.04740199074149132}, {"id": 296, "seek": 159336, "start": 1593.36, "end": 1598.32, "text": " answers out there. And it's actually highly non trivial. A lot of people saying it's just like", "tokens": [50364, 6338, 484, 456, 13, 400, 309, 311, 767, 5405, 2107, 26703, 13, 316, 688, 295, 561, 1566, 309, 311, 445, 411, 50612], "temperature": 0.0, "avg_logprob": -0.1495796864426981, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.009410353377461433}, {"id": 297, "seek": 159336, "start": 1598.32, "end": 1604.0, "text": " an LN wrapper, right? But then, and you even have like open source project that show it.", "tokens": [50612, 364, 441, 45, 46906, 11, 558, 30, 583, 550, 11, 293, 291, 754, 362, 411, 1269, 4009, 1716, 300, 855, 309, 13, 50896], "temperature": 0.0, "avg_logprob": -0.1495796864426981, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.009410353377461433}, {"id": 298, "seek": 159336, "start": 1604.0, "end": 1609.9199999999998, "text": " And then you ask, like, okay, when was Obama born? Where was he born? And then it fails. Why does it", "tokens": [50896, 400, 550, 291, 1029, 11, 411, 11, 1392, 11, 562, 390, 9560, 4232, 30, 2305, 390, 415, 4232, 30, 400, 550, 309, 18199, 13, 1545, 775, 309, 51192], "temperature": 0.0, "avg_logprob": -0.1495796864426981, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.009410353377461433}, {"id": 299, "seek": 159336, "start": 1609.9199999999998, "end": 1615.84, "text": " fail? Because when you send where was he born to your search back in is not going to return you", "tokens": [51192, 3061, 30, 1436, 562, 291, 2845, 689, 390, 415, 4232, 281, 428, 3164, 646, 294, 307, 406, 516, 281, 2736, 291, 51488], "temperature": 0.0, "avg_logprob": -0.1495796864426981, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.009410353377461433}, {"id": 300, "seek": 159336, "start": 1615.84, "end": 1620.56, "text": " any useful results. Because it doesn't know who he is. Who does he refer to, right? And there's", "tokens": [51488, 604, 4420, 3542, 13, 1436, 309, 1177, 380, 458, 567, 415, 307, 13, 2102, 775, 415, 2864, 281, 11, 558, 30, 400, 456, 311, 51724], "temperature": 0.0, "avg_logprob": -0.1495796864426981, "compression_ratio": 1.7372262773722629, "no_speech_prob": 0.009410353377461433}, {"id": 301, "seek": 162056, "start": 1620.56, "end": 1625.44, "text": " tons of things like that where, as you have a longer and longer conversation, especially in", "tokens": [50364, 9131, 295, 721, 411, 300, 689, 11, 382, 291, 362, 257, 2854, 293, 2854, 3761, 11, 2318, 294, 50608], "temperature": 0.0, "avg_logprob": -0.14110535235444377, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.012049959972500801}, {"id": 302, "seek": 162056, "start": 1625.44, "end": 1633.12, "text": " smart mode, you refer back to states. You can say like, Oh, what's a big CRM company? And then the", "tokens": [50608, 4069, 4391, 11, 291, 2864, 646, 281, 4368, 13, 509, 393, 584, 411, 11, 876, 11, 437, 311, 257, 955, 14123, 44, 2237, 30, 400, 550, 264, 50992], "temperature": 0.0, "avg_logprob": -0.14110535235444377, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.012049959972500801}, {"id": 303, "seek": 162056, "start": 1633.12, "end": 1637.84, "text": " answer inside is Salesforce. And you ask, Oh, what's their stock price? Now she sent what's their", "tokens": [50992, 1867, 1854, 307, 40398, 13, 400, 291, 1029, 11, 876, 11, 437, 311, 641, 4127, 3218, 30, 823, 750, 2279, 437, 311, 641, 51228], "temperature": 0.0, "avg_logprob": -0.14110535235444377, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.012049959972500801}, {"id": 304, "seek": 162056, "start": 1637.84, "end": 1642.32, "text": " stock price to your search back. And again, it's not going to return anything useful. So you need", "tokens": [51228, 4127, 3218, 281, 428, 3164, 646, 13, 400, 797, 11, 309, 311, 406, 516, 281, 2736, 1340, 4420, 13, 407, 291, 643, 51452], "temperature": 0.0, "avg_logprob": -0.14110535235444377, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.012049959972500801}, {"id": 305, "seek": 162056, "start": 1642.32, "end": 1647.04, "text": " to send that you need to go through the entire conversation, and then do what we call query", "tokens": [51452, 281, 2845, 300, 291, 643, 281, 352, 807, 264, 2302, 3761, 11, 293, 550, 360, 437, 321, 818, 14581, 51688], "temperature": 0.0, "avg_logprob": -0.14110535235444377, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.012049959972500801}, {"id": 306, "seek": 164704, "start": 1647.04, "end": 1656.32, "text": " transformation based on it. And that is just one of 10 examples of making this actually work at scale", "tokens": [50364, 9887, 2361, 322, 309, 13, 400, 300, 307, 445, 472, 295, 1266, 5110, 295, 1455, 341, 767, 589, 412, 4373, 50828], "temperature": 0.0, "avg_logprob": -0.12216308090712998, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.1258769929409027}, {"id": 307, "seek": 164704, "start": 1656.32, "end": 1662.72, "text": " millions of times a day for millions of users. Like, it is a lot more complicated to make it", "tokens": [50828, 6803, 295, 1413, 257, 786, 337, 6803, 295, 5022, 13, 1743, 11, 309, 307, 257, 688, 544, 6179, 281, 652, 309, 51148], "temperature": 0.0, "avg_logprob": -0.12216308090712998, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.1258769929409027}, {"id": 308, "seek": 164704, "start": 1662.72, "end": 1667.36, "text": " accurate. There are about 10 other such models that if you think about the space and you really", "tokens": [51148, 8559, 13, 821, 366, 466, 1266, 661, 1270, 5245, 300, 498, 291, 519, 466, 264, 1901, 293, 291, 534, 51380], "temperature": 0.0, "avg_logprob": -0.12216308090712998, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.1258769929409027}, {"id": 309, "seek": 164704, "start": 1667.36, "end": 1672.56, "text": " listen and look at like user data, you listen to where it's breaking, you will eventually get to", "tokens": [51380, 2140, 293, 574, 412, 411, 4195, 1412, 11, 291, 2140, 281, 689, 309, 311, 7697, 11, 291, 486, 4728, 483, 281, 51640], "temperature": 0.0, "avg_logprob": -0.12216308090712998, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.1258769929409027}, {"id": 310, "seek": 167256, "start": 1672.56, "end": 1678.08, "text": " and we're now like thinking about offering more and more back. So I'm tempted to ask for the other", "tokens": [50364, 293, 321, 434, 586, 411, 1953, 466, 8745, 544, 293, 544, 646, 13, 407, 286, 478, 29941, 281, 1029, 337, 264, 661, 50640], "temperature": 0.0, "avg_logprob": -0.12791092934147005, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.031133854761719704}, {"id": 311, "seek": 167256, "start": 1678.08, "end": 1684.1599999999999, "text": " nine things there. I'll just give you one more, which is like, whether to do a search at all or", "tokens": [50640, 4949, 721, 456, 13, 286, 603, 445, 976, 291, 472, 544, 11, 597, 307, 411, 11, 1968, 281, 360, 257, 3164, 412, 439, 420, 50944], "temperature": 0.0, "avg_logprob": -0.12791092934147005, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.031133854761719704}, {"id": 312, "seek": 167256, "start": 1684.1599999999999, "end": 1690.24, "text": " not, right? Like, because you asked like, write me a poem about like the beautiful Bay Area and", "tokens": [50944, 406, 11, 558, 30, 1743, 11, 570, 291, 2351, 411, 11, 2464, 385, 257, 13065, 466, 411, 264, 2238, 7840, 19405, 293, 51248], "temperature": 0.0, "avg_logprob": -0.12791092934147005, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.031133854761719704}, {"id": 313, "seek": 167256, "start": 1690.24, "end": 1695.12, "text": " like a sunset love story or something. Like, you don't need a citation at every line of that poem.", "tokens": [51248, 411, 257, 20142, 959, 1657, 420, 746, 13, 1743, 11, 291, 500, 380, 643, 257, 45590, 412, 633, 1622, 295, 300, 13065, 13, 51492], "temperature": 0.0, "avg_logprob": -0.12791092934147005, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.031133854761719704}, {"id": 314, "seek": 167256, "start": 1695.12, "end": 1702.1599999999999, "text": " And so it would actually clutter up the prompt to add a bunch of facts about poems and so on.", "tokens": [51492, 400, 370, 309, 576, 767, 40614, 493, 264, 12391, 281, 909, 257, 3840, 295, 9130, 466, 24014, 293, 370, 322, 13, 51844], "temperature": 0.0, "avg_logprob": -0.12791092934147005, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.031133854761719704}, {"id": 315, "seek": 170216, "start": 1702.24, "end": 1708.24, "text": " And the history of Silicon Valley and all of that. And so it's pretty important, but also non trivial", "tokens": [50368, 400, 264, 2503, 295, 25351, 10666, 293, 439, 295, 300, 13, 400, 370, 309, 311, 1238, 1021, 11, 457, 611, 2107, 26703, 50668], "temperature": 0.0, "avg_logprob": -0.1387348175048828, "compression_ratio": 1.5524193548387097, "no_speech_prob": 0.0005357256159186363}, {"id": 316, "seek": 170216, "start": 1708.24, "end": 1713.52, "text": " to know whether you should do a search or not. And again, some, some websites just slap search", "tokens": [50668, 281, 458, 1968, 291, 820, 360, 257, 3164, 420, 406, 13, 400, 797, 11, 512, 11, 512, 12891, 445, 21075, 3164, 50932], "temperature": 0.0, "avg_logprob": -0.1387348175048828, "compression_ratio": 1.5524193548387097, "no_speech_prob": 0.0005357256159186363}, {"id": 317, "seek": 170216, "start": 1713.52, "end": 1718.96, "text": " results on top of everything, even if they're not relevant for having more conversation about", "tokens": [50932, 3542, 322, 1192, 295, 1203, 11, 754, 498, 436, 434, 406, 7340, 337, 1419, 544, 3761, 466, 51204], "temperature": 0.0, "avg_logprob": -0.1387348175048828, "compression_ratio": 1.5524193548387097, "no_speech_prob": 0.0005357256159186363}, {"id": 318, "seek": 170216, "start": 1718.96, "end": 1725.68, "text": " your feelings or something. Did I understand correctly that the kind of big difference is that", "tokens": [51204, 428, 6640, 420, 746, 13, 2589, 286, 1223, 8944, 300, 264, 733, 295, 955, 2649, 307, 300, 51540], "temperature": 0.0, "avg_logprob": -0.1387348175048828, "compression_ratio": 1.5524193548387097, "no_speech_prob": 0.0005357256159186363}, {"id": 319, "seek": 172568, "start": 1725.68, "end": 1732.64, "text": " the U.com index has more information, like instead of a short SERP, it is a more robust", "tokens": [50364, 264, 624, 13, 1112, 8186, 575, 544, 1589, 11, 411, 2602, 295, 257, 2099, 36772, 47, 11, 309, 307, 257, 544, 13956, 50712], "temperature": 0.0, "avg_logprob": -0.15890834036837803, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.050315964967012405}, {"id": 320, "seek": 172568, "start": 1732.64, "end": 1741.3600000000001, "text": " paragraph. And so independent of the language model that you're using, the richer context is", "tokens": [50712, 18865, 13, 400, 370, 6695, 295, 264, 2856, 2316, 300, 291, 434, 1228, 11, 264, 29021, 4319, 307, 51148], "temperature": 0.0, "avg_logprob": -0.15890834036837803, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.050315964967012405}, {"id": 321, "seek": 172568, "start": 1741.3600000000001, "end": 1748.0800000000002, "text": " just better kind of serious enable you in that way, you're kind of decoupling the what information", "tokens": [51148, 445, 1101, 733, 295, 3156, 9528, 291, 294, 300, 636, 11, 291, 434, 733, 295, 979, 263, 11970, 264, 437, 1589, 51484], "temperature": 0.0, "avg_logprob": -0.15890834036837803, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.050315964967012405}, {"id": 322, "seek": 172568, "start": 1748.0800000000002, "end": 1754.88, "text": " is found from language model that is doing the analysis. And more information is kind of the", "tokens": [51484, 307, 1352, 490, 2856, 2316, 300, 307, 884, 264, 5215, 13, 400, 544, 1589, 307, 733, 295, 264, 51824], "temperature": 0.0, "avg_logprob": -0.15890834036837803, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.050315964967012405}, {"id": 323, "seek": 175488, "start": 1754.88, "end": 1760.0800000000002, "text": " big differentiating factor there. Drive that right. I would be careful and say we have overall", "tokens": [50364, 955, 27372, 990, 5952, 456, 13, 15622, 300, 558, 13, 286, 576, 312, 5026, 293, 584, 321, 362, 4787, 50624], "temperature": 0.0, "avg_logprob": -0.24149158083159347, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.0016480827471241355}, {"id": 324, "seek": 175488, "start": 1760.0800000000002, "end": 1766.4, "text": " more information. We're focused a little bit more on the main languages that we see. We don't support", "tokens": [50624, 544, 1589, 13, 492, 434, 5178, 257, 707, 857, 544, 322, 264, 2135, 8650, 300, 321, 536, 13, 492, 500, 380, 1406, 50940], "temperature": 0.0, "avg_logprob": -0.24149158083159347, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.0016480827471241355}, {"id": 325, "seek": 175488, "start": 1766.4, "end": 1773.2800000000002, "text": " some like very rare like Indonesian, African sensual Asian dialects and so on yet, but we", "tokens": [50940, 512, 411, 588, 5892, 411, 39772, 11, 7312, 2923, 901, 10645, 24652, 82, 293, 370, 322, 1939, 11, 457, 321, 51284], "temperature": 0.0, "avg_logprob": -0.24149158083159347, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.0016480827471241355}, {"id": 326, "seek": 175488, "start": 1773.2800000000002, "end": 1779.6000000000001, "text": " return more information per rare because of these large limits. So, so it's sort of, yes,", "tokens": [51284, 2736, 544, 1589, 680, 5892, 570, 295, 613, 2416, 10406, 13, 407, 11, 370, 309, 311, 1333, 295, 11, 2086, 11, 51600], "temperature": 0.0, "avg_logprob": -0.24149158083159347, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.0016480827471241355}, {"id": 327, "seek": 175488, "start": 1779.6000000000001, "end": 1784.0, "text": " yes, there's more information, but you know, I think the long tail Google Prop still has a larger", "tokens": [51600, 2086, 11, 456, 311, 544, 1589, 11, 457, 291, 458, 11, 286, 519, 264, 938, 6838, 3329, 21944, 920, 575, 257, 4833, 51820], "temperature": 0.0, "avg_logprob": -0.24149158083159347, "compression_ratio": 1.651567944250871, "no_speech_prob": 0.0016480827471241355}, {"id": 328, "seek": 178400, "start": 1784.0, "end": 1790.32, "text": " index. If you look for this like rare, like Indonesian kayaking sites that like rents out", "tokens": [50364, 8186, 13, 759, 291, 574, 337, 341, 411, 5892, 11, 411, 39772, 12446, 2456, 7533, 300, 411, 6214, 82, 484, 50680], "temperature": 0.0, "avg_logprob": -0.1373765530793563, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.008056936785578728}, {"id": 329, "seek": 178400, "start": 1790.32, "end": 1795.44, "text": " kayaks on this little lake somewhere, like, and it's all like not in English, like we might not", "tokens": [50680, 12446, 5461, 322, 341, 707, 11001, 4079, 11, 411, 11, 293, 309, 311, 439, 411, 406, 294, 3669, 11, 411, 321, 1062, 406, 50936], "temperature": 0.0, "avg_logprob": -0.1373765530793563, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.008056936785578728}, {"id": 330, "seek": 178400, "start": 1795.44, "end": 1801.04, "text": " have that website. But when it comes to like Western world news where, you know, we have a lot of", "tokens": [50936, 362, 300, 3144, 13, 583, 562, 309, 1487, 281, 411, 8724, 1002, 2583, 689, 11, 291, 458, 11, 321, 362, 257, 688, 295, 51216], "temperature": 0.0, "avg_logprob": -0.1373765530793563, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.008056936785578728}, {"id": 331, "seek": 178400, "start": 1801.04, "end": 1807.36, "text": " users, then Latin America and so on, then we shine and return much more information per pair.", "tokens": [51216, 5022, 11, 550, 10803, 3374, 293, 370, 322, 11, 550, 321, 12207, 293, 2736, 709, 544, 1589, 680, 6119, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1373765530793563, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.008056936785578728}, {"id": 332, "seek": 178400, "start": 1807.36, "end": 1811.04, "text": " Hey, we'll continue our interview in a moment after a word from our sponsors.", "tokens": [51532, 1911, 11, 321, 603, 2354, 527, 4049, 294, 257, 1623, 934, 257, 1349, 490, 527, 22593, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1373765530793563, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.008056936785578728}, {"id": 333, "seek": 181104, "start": 1811.04, "end": 1815.04, "text": " If you're a startup founder or executive running a growing business, you know that as you scale,", "tokens": [50364, 759, 291, 434, 257, 18578, 14917, 420, 10140, 2614, 257, 4194, 1606, 11, 291, 458, 300, 382, 291, 4373, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09620680460115759, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.4527657628059387}, {"id": 334, "seek": 181104, "start": 1815.04, "end": 1819.84, "text": " your systems break down and the cracks start to show. If this resonates with you, there are three", "tokens": [50564, 428, 3652, 1821, 760, 293, 264, 21770, 722, 281, 855, 13, 759, 341, 41051, 365, 291, 11, 456, 366, 1045, 50804], "temperature": 0.0, "avg_logprob": -0.09620680460115759, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.4527657628059387}, {"id": 335, "seek": 181104, "start": 1819.84, "end": 1826.8799999999999, "text": " numbers you need to know. 36,000, 25 and 1. 36,000. That's the number of businesses which have upgraded", "tokens": [50804, 3547, 291, 643, 281, 458, 13, 8652, 11, 1360, 11, 3552, 293, 502, 13, 8652, 11, 1360, 13, 663, 311, 264, 1230, 295, 6011, 597, 362, 24133, 51156], "temperature": 0.0, "avg_logprob": -0.09620680460115759, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.4527657628059387}, {"id": 336, "seek": 181104, "start": 1826.8799999999999, "end": 1831.28, "text": " to NetSuite by Oracle. NetSuite is the number one cloud financial system, streamlined accounting,", "tokens": [51156, 281, 6188, 50, 21681, 538, 25654, 13, 6188, 50, 21681, 307, 264, 1230, 472, 4588, 4669, 1185, 11, 48155, 19163, 11, 51376], "temperature": 0.0, "avg_logprob": -0.09620680460115759, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.4527657628059387}, {"id": 337, "seek": 181104, "start": 1831.28, "end": 1837.92, "text": " financial management, inventory, HR and more. 25. NetSuite turns 25 this year. That's 25 years", "tokens": [51376, 4669, 4592, 11, 14228, 11, 19460, 293, 544, 13, 3552, 13, 6188, 50, 21681, 4523, 3552, 341, 1064, 13, 663, 311, 3552, 924, 51708], "temperature": 0.0, "avg_logprob": -0.09620680460115759, "compression_ratio": 1.6872852233676976, "no_speech_prob": 0.4527657628059387}, {"id": 338, "seek": 183792, "start": 1837.92, "end": 1842.88, "text": " of helping businesses do more with less, close their books in days, not weeks, and drive down costs.", "tokens": [50364, 295, 4315, 6011, 360, 544, 365, 1570, 11, 1998, 641, 3642, 294, 1708, 11, 406, 3259, 11, 293, 3332, 760, 5497, 13, 50612], "temperature": 0.0, "avg_logprob": -0.10413391218272917, "compression_ratio": 1.5892255892255893, "no_speech_prob": 0.5231700539588928}, {"id": 339, "seek": 183792, "start": 1843.6000000000001, "end": 1848.16, "text": " One, because your business is one of a kind, so you get a customized solution for all your KPIs", "tokens": [50648, 1485, 11, 570, 428, 1606, 307, 472, 295, 257, 733, 11, 370, 291, 483, 257, 30581, 3827, 337, 439, 428, 41371, 6802, 50876], "temperature": 0.0, "avg_logprob": -0.10413391218272917, "compression_ratio": 1.5892255892255893, "no_speech_prob": 0.5231700539588928}, {"id": 340, "seek": 183792, "start": 1848.16, "end": 1852.8000000000002, "text": " in one efficient system with one source of truth. Manage risk, get reliable forecasts,", "tokens": [50876, 294, 472, 7148, 1185, 365, 472, 4009, 295, 3494, 13, 2458, 609, 3148, 11, 483, 12924, 49421, 11, 51108], "temperature": 0.0, "avg_logprob": -0.10413391218272917, "compression_ratio": 1.5892255892255893, "no_speech_prob": 0.5231700539588928}, {"id": 341, "seek": 183792, "start": 1852.8000000000002, "end": 1858.3200000000002, "text": " and improve margins. Everything you need all in one place. Right now, download NetSuite's popular", "tokens": [51108, 293, 3470, 30317, 13, 5471, 291, 643, 439, 294, 472, 1081, 13, 1779, 586, 11, 5484, 6188, 50, 21681, 311, 3743, 51384], "temperature": 0.0, "avg_logprob": -0.10413391218272917, "compression_ratio": 1.5892255892255893, "no_speech_prob": 0.5231700539588928}, {"id": 342, "seek": 183792, "start": 1858.3200000000002, "end": 1863.04, "text": " KPI checklist designed to give you consistently excellent performance, absolutely free and", "tokens": [51384, 591, 31701, 30357, 4761, 281, 976, 291, 14961, 7103, 3389, 11, 3122, 1737, 293, 51620], "temperature": 0.0, "avg_logprob": -0.10413391218272917, "compression_ratio": 1.5892255892255893, "no_speech_prob": 0.5231700539588928}, {"id": 343, "seek": 186304, "start": 1863.04, "end": 1869.12, "text": " net suite.com slash cognitive. That's net suite.com slash cognitive to get your own KPI checklist.", "tokens": [50364, 2533, 14205, 13, 1112, 17330, 15605, 13, 663, 311, 2533, 14205, 13, 1112, 17330, 15605, 281, 483, 428, 1065, 591, 31701, 30357, 13, 50668], "temperature": 0.0, "avg_logprob": -0.13807337508242354, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.01001298800110817}, {"id": 344, "seek": 186304, "start": 1869.12, "end": 1876.08, "text": " Net suite.com slash cognitive. Omniki uses generative AI to enable you to launch hundreds of", "tokens": [50668, 6188, 14205, 13, 1112, 17330, 15605, 13, 9757, 77, 9850, 4960, 1337, 1166, 7318, 281, 9528, 291, 281, 4025, 6779, 295, 51016], "temperature": 0.0, "avg_logprob": -0.13807337508242354, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.01001298800110817}, {"id": 345, "seek": 186304, "start": 1876.08, "end": 1881.52, "text": " thousands of ad iterations that actually work, customized across all platforms with a click", "tokens": [51016, 5383, 295, 614, 36540, 300, 767, 589, 11, 30581, 2108, 439, 9473, 365, 257, 2052, 51288], "temperature": 0.0, "avg_logprob": -0.13807337508242354, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.01001298800110817}, {"id": 346, "seek": 186304, "start": 1881.52, "end": 1886.3999999999999, "text": " of a button. I believe in Omniki so much that I invested in it and I recommend you use it too.", "tokens": [51288, 295, 257, 2960, 13, 286, 1697, 294, 9757, 77, 9850, 370, 709, 300, 286, 13104, 294, 309, 293, 286, 2748, 291, 764, 309, 886, 13, 51532], "temperature": 0.0, "avg_logprob": -0.13807337508242354, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.01001298800110817}, {"id": 347, "seek": 186304, "start": 1887.12, "end": 1892.56, "text": " Use Kogrev to get a 10% discount. I've been struck recently that it seems like,", "tokens": [51568, 8278, 591, 664, 40382, 281, 483, 257, 1266, 4, 11635, 13, 286, 600, 668, 13159, 3938, 300, 309, 2544, 411, 11, 51840], "temperature": 0.0, "avg_logprob": -0.13807337508242354, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.01001298800110817}, {"id": 348, "seek": 189256, "start": 1892.8, "end": 1896.8799999999999, "text": " obviously, search in general has kind of been a monopoly for a long time.", "tokens": [50376, 2745, 11, 3164, 294, 2674, 575, 733, 295, 668, 257, 37061, 337, 257, 938, 565, 13, 50580], "temperature": 0.0, "avg_logprob": -0.12079082085536076, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0005883424892090261}, {"id": 349, "seek": 189256, "start": 1898.3999999999999, "end": 1903.36, "text": " As you noted, the user experience was kind of something people were not necessarily looking", "tokens": [50656, 1018, 291, 12964, 11, 264, 4195, 1752, 390, 733, 295, 746, 561, 645, 406, 4725, 1237, 50904], "temperature": 0.0, "avg_logprob": -0.12079082085536076, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0005883424892090261}, {"id": 350, "seek": 189256, "start": 1903.36, "end": 1910.0, "text": " to explore new things on the nature of the index. Of course, they've done millions of", "tokens": [50904, 281, 6839, 777, 721, 322, 264, 3687, 295, 264, 8186, 13, 2720, 1164, 11, 436, 600, 1096, 6803, 295, 51236], "temperature": 0.0, "avg_logprob": -0.12079082085536076, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0005883424892090261}, {"id": 351, "seek": 189256, "start": 1910.0, "end": 1915.12, "text": " person hours of work on it, but it seems like it's kind of been a pretty consistent paradigm of", "tokens": [51236, 954, 2496, 295, 589, 322, 309, 11, 457, 309, 2544, 411, 309, 311, 733, 295, 668, 257, 1238, 8398, 24709, 295, 51492], "temperature": 0.0, "avg_logprob": -0.12079082085536076, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0005883424892090261}, {"id": 352, "seek": 189256, "start": 1915.12, "end": 1919.12, "text": " crawl around and find everything and suck it up. Now, we're starting to see these interesting,", "tokens": [51492, 24767, 926, 293, 915, 1203, 293, 9967, 309, 493, 13, 823, 11, 321, 434, 2891, 281, 536, 613, 1880, 11, 51692], "temperature": 0.0, "avg_logprob": -0.12079082085536076, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0005883424892090261}, {"id": 353, "seek": 191912, "start": 1919.12, "end": 1924.2399999999998, "text": " I don't know if you can share more about how you create your index, but we just had actually a", "tokens": [50364, 286, 500, 380, 458, 498, 291, 393, 2073, 544, 466, 577, 291, 1884, 428, 8186, 11, 457, 321, 445, 632, 767, 257, 50620], "temperature": 0.0, "avg_logprob": -0.09534538017128999, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.03732145577669144}, {"id": 354, "seek": 191912, "start": 1924.2399999999998, "end": 1930.6399999999999, "text": " sponsor brave talking about their index and the way that they are building it through users", "tokens": [50620, 16198, 12653, 1417, 466, 641, 8186, 293, 264, 636, 300, 436, 366, 2390, 309, 807, 5022, 50940], "temperature": 0.0, "avg_logprob": -0.09534538017128999, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.03732145577669144}, {"id": 355, "seek": 191912, "start": 1930.6399999999999, "end": 1937.12, "text": " actually visiting websites and taking a sort of not just blindly crawling around and following", "tokens": [50940, 767, 11700, 12891, 293, 1940, 257, 1333, 295, 406, 445, 47744, 32979, 926, 293, 3480, 51264], "temperature": 0.0, "avg_logprob": -0.09534538017128999, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.03732145577669144}, {"id": 356, "seek": 191912, "start": 1937.12, "end": 1944.7199999999998, "text": " every link, but what are people actually engaging with online, which struck me as a pretty interesting", "tokens": [51264, 633, 2113, 11, 457, 437, 366, 561, 767, 11268, 365, 2950, 11, 597, 13159, 385, 382, 257, 1238, 1880, 51644], "temperature": 0.0, "avg_logprob": -0.09534538017128999, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.03732145577669144}, {"id": 357, "seek": 191912, "start": 1944.7199999999998, "end": 1948.7199999999998, "text": " and very different twist on it. I want to kind of pull this apart in a couple of different ways,", "tokens": [51644, 293, 588, 819, 8203, 322, 309, 13, 286, 528, 281, 733, 295, 2235, 341, 4936, 294, 257, 1916, 295, 819, 2098, 11, 51844], "temperature": 0.0, "avg_logprob": -0.09534538017128999, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.03732145577669144}, {"id": 358, "seek": 194872, "start": 1948.72, "end": 1954.24, "text": " but is there anything that you would want to share about how you think about building an index", "tokens": [50364, 457, 307, 456, 1340, 300, 291, 576, 528, 281, 2073, 466, 577, 291, 519, 466, 2390, 364, 8186, 50640], "temperature": 0.0, "avg_logprob": -0.12173911358447785, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0006262612296268344}, {"id": 359, "seek": 194872, "start": 1954.24, "end": 1962.4, "text": " that, aside from just bigger, richer content, is there a different tactic as well that underlies", "tokens": [50640, 300, 11, 7359, 490, 445, 3801, 11, 29021, 2701, 11, 307, 456, 257, 819, 31012, 382, 731, 300, 833, 24119, 51048], "temperature": 0.0, "avg_logprob": -0.12173911358447785, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0006262612296268344}, {"id": 360, "seek": 194872, "start": 1962.4, "end": 1969.84, "text": " that? The tactic is more about how we make that work for LLNs better, and I don't think there's", "tokens": [51048, 300, 30, 440, 31012, 307, 544, 466, 577, 321, 652, 300, 589, 337, 441, 43, 45, 82, 1101, 11, 293, 286, 500, 380, 519, 456, 311, 51420], "temperature": 0.0, "avg_logprob": -0.12173911358447785, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0006262612296268344}, {"id": 361, "seek": 194872, "start": 1969.84, "end": 1974.16, "text": " that much differentiation on how it will fall. You have to have a bunch of data that's been", "tokens": [51420, 300, 709, 38902, 322, 577, 309, 486, 2100, 13, 509, 362, 281, 362, 257, 3840, 295, 1412, 300, 311, 668, 51636], "temperature": 0.0, "avg_logprob": -0.12173911358447785, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.0006262612296268344}, {"id": 362, "seek": 197416, "start": 1974.16, "end": 1980.8000000000002, "text": " helpful to have run a search engine for several years and get user behavior and knowing what", "tokens": [50364, 4961, 281, 362, 1190, 257, 3164, 2848, 337, 2940, 924, 293, 483, 4195, 5223, 293, 5276, 437, 50696], "temperature": 0.0, "avg_logprob": -0.1574317058884954, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.022278226912021637}, {"id": 363, "seek": 197416, "start": 1980.8000000000002, "end": 1986.8000000000002, "text": " people actually want to have called and want information for. You can also sound surprisingly", "tokens": [50696, 561, 767, 528, 281, 362, 1219, 293, 528, 1589, 337, 13, 509, 393, 611, 1626, 17600, 50996], "temperature": 0.0, "avg_logprob": -0.1574317058884954, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.022278226912021637}, {"id": 364, "seek": 197416, "start": 1986.8000000000002, "end": 1991.8400000000001, "text": " buy a lot of that data in bulk. I have a few questions on the business side or the kind of", "tokens": [50996, 2256, 257, 688, 295, 300, 1412, 294, 16139, 13, 286, 362, 257, 1326, 1651, 322, 264, 1606, 1252, 420, 264, 733, 295, 51248], "temperature": 0.0, "avg_logprob": -0.1574317058884954, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.022278226912021637}, {"id": 365, "seek": 197416, "start": 1991.8400000000001, "end": 1997.92, "text": " bridge the technology and business side. Google obviously has been free and has been ad supported.", "tokens": [51248, 7283, 264, 2899, 293, 1606, 1252, 13, 3329, 2745, 575, 668, 1737, 293, 575, 668, 614, 8104, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1574317058884954, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.022278226912021637}, {"id": 366, "seek": 199792, "start": 1998.0, "end": 2006.8000000000002, "text": " It seems like the new generation of AI first LLN enabled search is going more in the direction so", "tokens": [50368, 467, 2544, 411, 264, 777, 5125, 295, 7318, 700, 441, 43, 45, 15172, 3164, 307, 516, 544, 294, 264, 3513, 370, 50808], "temperature": 0.0, "avg_logprob": -0.10804539460402268, "compression_ratio": 1.5298804780876494, "no_speech_prob": 0.08754489570856094}, {"id": 367, "seek": 199792, "start": 2006.8000000000002, "end": 2013.92, "text": " far of a subscription. As far as I've seen in my U.com usage, I haven't seen anything that jumped", "tokens": [50808, 1400, 295, 257, 17231, 13, 1018, 1400, 382, 286, 600, 1612, 294, 452, 624, 13, 1112, 14924, 11, 286, 2378, 380, 1612, 1340, 300, 13864, 51164], "temperature": 0.0, "avg_logprob": -0.10804539460402268, "compression_ratio": 1.5298804780876494, "no_speech_prob": 0.08754489570856094}, {"id": 368, "seek": 199792, "start": 2013.92, "end": 2018.8000000000002, "text": " out to me as sponsored. Another dimension too is like, I mean, Google has all these tabs at the", "tokens": [51164, 484, 281, 385, 382, 16621, 13, 3996, 10139, 886, 307, 411, 11, 286, 914, 11, 3329, 575, 439, 613, 20743, 412, 264, 51408], "temperature": 0.0, "avg_logprob": -0.10804539460402268, "compression_ratio": 1.5298804780876494, "no_speech_prob": 0.08754489570856094}, {"id": 369, "seek": 199792, "start": 2018.8000000000002, "end": 2024.64, "text": " top, but it's one bar, right? You kind of put in one thing. With the newer ones, we also are", "tokens": [51408, 1192, 11, 457, 309, 311, 472, 2159, 11, 558, 30, 509, 733, 295, 829, 294, 472, 551, 13, 2022, 264, 17628, 2306, 11, 321, 611, 366, 51700], "temperature": 0.0, "avg_logprob": -0.10804539460402268, "compression_ratio": 1.5298804780876494, "no_speech_prob": 0.08754489570856094}, {"id": 370, "seek": 202464, "start": 2024.72, "end": 2030.5600000000002, "text": " kind of seeing a little bit more proliferation of modes and settings that you choose up front", "tokens": [50368, 733, 295, 2577, 257, 707, 857, 544, 24398, 44987, 295, 14068, 293, 6257, 300, 291, 2826, 493, 1868, 50660], "temperature": 0.0, "avg_logprob": -0.11269810086204893, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.010012130253016949}, {"id": 371, "seek": 202464, "start": 2030.5600000000002, "end": 2036.96, "text": " with the smart versus genius versus research. I guess on those two dimensions, what is the", "tokens": [50660, 365, 264, 4069, 5717, 14017, 5717, 2132, 13, 286, 2041, 322, 729, 732, 12819, 11, 437, 307, 264, 50980], "temperature": 0.0, "avg_logprob": -0.11269810086204893, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.010012130253016949}, {"id": 372, "seek": 202464, "start": 2036.96, "end": 2040.72, "text": " future vision? Do you think that this all gets unified? Do you think it ultimately comes back", "tokens": [50980, 2027, 5201, 30, 1144, 291, 519, 300, 341, 439, 2170, 26787, 30, 1144, 291, 519, 309, 6284, 1487, 646, 51168], "temperature": 0.0, "avg_logprob": -0.11269810086204893, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.010012130253016949}, {"id": 373, "seek": 202464, "start": 2040.72, "end": 2048.8, "text": " around to ad supported? Or do you think that these current differences from the past will persist?", "tokens": [51168, 926, 281, 614, 8104, 30, 1610, 360, 291, 519, 300, 613, 2190, 7300, 490, 264, 1791, 486, 13233, 30, 51572], "temperature": 0.0, "avg_logprob": -0.11269810086204893, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.010012130253016949}, {"id": 374, "seek": 204880, "start": 2049.6800000000003, "end": 2056.5600000000004, "text": " Yeah, that's a good question. I think there is facility right now, not a great chat ad offering.", "tokens": [50408, 865, 11, 300, 311, 257, 665, 1168, 13, 286, 519, 456, 307, 8973, 558, 586, 11, 406, 257, 869, 5081, 614, 8745, 13, 50752], "temperature": 0.0, "avg_logprob": -0.13690205574035644, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.006191237363964319}, {"id": 375, "seek": 204880, "start": 2057.6000000000004, "end": 2064.7200000000003, "text": " There's a good chance that that will change maybe this year to maybe the dissatisfaction of users,", "tokens": [50804, 821, 311, 257, 665, 2931, 300, 300, 486, 1319, 1310, 341, 1064, 281, 1310, 264, 7802, 25239, 2894, 295, 5022, 11, 51160], "temperature": 0.0, "avg_logprob": -0.13690205574035644, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.006191237363964319}, {"id": 376, "seek": 204880, "start": 2064.7200000000003, "end": 2071.04, "text": " but the truth is, if you want something to be free, VC money will only last so long. You've got to,", "tokens": [51160, 457, 264, 3494, 307, 11, 498, 291, 528, 746, 281, 312, 1737, 11, 41922, 1460, 486, 787, 1036, 370, 938, 13, 509, 600, 658, 281, 11, 51476], "temperature": 0.0, "avg_logprob": -0.13690205574035644, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.006191237363964319}, {"id": 377, "seek": 204880, "start": 2071.04, "end": 2077.6000000000004, "text": " at some point, those companies that offer free service have to survive. If you don't want to", "tokens": [51476, 412, 512, 935, 11, 729, 3431, 300, 2626, 1737, 2643, 362, 281, 7867, 13, 759, 291, 500, 380, 528, 281, 51804], "temperature": 0.0, "avg_logprob": -0.13690205574035644, "compression_ratio": 1.6234309623430963, "no_speech_prob": 0.006191237363964319}, {"id": 378, "seek": 207760, "start": 2077.6, "end": 2083.12, "text": " pay for it, then it has to have ads. And so while, and might not be the biggest fan of ads,", "tokens": [50364, 1689, 337, 309, 11, 550, 309, 575, 281, 362, 10342, 13, 400, 370, 1339, 11, 293, 1062, 406, 312, 264, 3880, 3429, 295, 10342, 11, 50640], "temperature": 0.0, "avg_logprob": -0.1409004960104684, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.015182486735284328}, {"id": 379, "seek": 207760, "start": 2083.12, "end": 2087.7599999999998, "text": " like, you have to make a decision, you want to pay for it, and then add free, or do you want to", "tokens": [50640, 411, 11, 291, 362, 281, 652, 257, 3537, 11, 291, 528, 281, 1689, 337, 309, 11, 293, 550, 909, 1737, 11, 420, 360, 291, 528, 281, 50872], "temperature": 0.0, "avg_logprob": -0.1409004960104684, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.015182486735284328}, {"id": 380, "seek": 207760, "start": 2088.3199999999997, "end": 2097.04, "text": " support it with ads? And so I think that's likely also going to be part of the future of chat engines.", "tokens": [50900, 1406, 309, 365, 10342, 30, 400, 370, 286, 519, 300, 311, 3700, 611, 516, 281, 312, 644, 295, 264, 2027, 295, 5081, 12982, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1409004960104684, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.015182486735284328}, {"id": 381, "seek": 207760, "start": 2097.04, "end": 2102.56, "text": " And you already see a little bit of exploration. There's a little bit of a duopoly in search in", "tokens": [51336, 400, 291, 1217, 536, 257, 707, 857, 295, 16197, 13, 821, 311, 257, 707, 857, 295, 257, 1581, 27891, 294, 3164, 294, 51612], "temperature": 0.0, "avg_logprob": -0.1409004960104684, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.015182486735284328}, {"id": 382, "seek": 210256, "start": 2102.64, "end": 2108.64, "text": " the sense that Google has the monopoly on consumer search. And for a long time, Microsoft had the", "tokens": [50368, 264, 2020, 300, 3329, 575, 264, 37061, 322, 9711, 3164, 13, 400, 337, 257, 938, 565, 11, 8116, 632, 264, 50668], "temperature": 0.0, "avg_logprob": -0.20168112092098947, "compression_ratio": 1.725, "no_speech_prob": 0.13836140930652618}, {"id": 383, "seek": 210256, "start": 2108.64, "end": 2114.08, "text": " monopoly on a search API. But then because they're monopoly that is set up, we're just five to 20x", "tokens": [50668, 37061, 322, 257, 3164, 9362, 13, 583, 550, 570, 436, 434, 37061, 300, 307, 992, 493, 11, 321, 434, 445, 1732, 281, 945, 87, 50940], "temperature": 0.0, "avg_logprob": -0.20168112092098947, "compression_ratio": 1.725, "no_speech_prob": 0.13836140930652618}, {"id": 384, "seek": 210256, "start": 2114.08, "end": 2119.12, "text": " hour prices, and they could do it because they're the only ones in town. So I'm glad there's like", "tokens": [50940, 1773, 7901, 11, 293, 436, 727, 360, 309, 570, 436, 434, 264, 787, 2306, 294, 3954, 13, 407, 286, 478, 5404, 456, 311, 411, 51192], "temperature": 0.0, "avg_logprob": -0.20168112092098947, "compression_ratio": 1.725, "no_speech_prob": 0.13836140930652618}, {"id": 385, "seek": 210256, "start": 2119.12, "end": 2123.92, "text": " more competition now and more movement in that space. And all the little guys have to scramble", "tokens": [51192, 544, 6211, 586, 293, 544, 3963, 294, 300, 1901, 13, 400, 439, 264, 707, 1074, 362, 281, 795, 48382, 51432], "temperature": 0.0, "avg_logprob": -0.20168112092098947, "compression_ratio": 1.725, "no_speech_prob": 0.13836140930652618}, {"id": 386, "seek": 210256, "start": 2123.92, "end": 2130.08, "text": " when those prices just went so high. You can really rob in a consumer space with those prices", "tokens": [51432, 562, 729, 7901, 445, 1437, 370, 1090, 13, 509, 393, 534, 3870, 294, 257, 9711, 1901, 365, 729, 7901, 51740], "temperature": 0.0, "avg_logprob": -0.20168112092098947, "compression_ratio": 1.725, "no_speech_prob": 0.13836140930652618}, {"id": 387, "seek": 213008, "start": 2130.08, "end": 2135.7599999999998, "text": " anymore. And so I think ads will happen. We're seeing a lot of growth on the subscription side", "tokens": [50364, 3602, 13, 400, 370, 286, 519, 10342, 486, 1051, 13, 492, 434, 2577, 257, 688, 295, 4599, 322, 264, 17231, 1252, 50648], "temperature": 0.0, "avg_logprob": -0.13869079921556557, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.019408682361245155}, {"id": 388, "seek": 213008, "start": 2135.7599999999998, "end": 2141.84, "text": " to users really loving like you, the genius and research mode, and find the search mode, the default", "tokens": [50648, 281, 5022, 534, 9344, 411, 291, 11, 264, 14017, 293, 2132, 4391, 11, 293, 915, 264, 3164, 4391, 11, 264, 7576, 50952], "temperature": 0.0, "avg_logprob": -0.13869079921556557, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.019408682361245155}, {"id": 389, "seek": 213008, "start": 2141.84, "end": 2149.84, "text": " mode, smart mode also very, very helpful. And we actually, you know, incorporate late still. So", "tokens": [50952, 4391, 11, 4069, 4391, 611, 588, 11, 588, 4961, 13, 400, 321, 767, 11, 291, 458, 11, 16091, 3469, 920, 13, 407, 51352], "temperature": 0.0, "avg_logprob": -0.13869079921556557, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.019408682361245155}, {"id": 390, "seek": 213008, "start": 2149.84, "end": 2154.4, "text": " where just last week, some people are completely about other chat bots, because they don't really", "tokens": [51352, 689, 445, 1036, 1243, 11, 512, 561, 366, 2584, 466, 661, 5081, 35410, 11, 570, 436, 500, 380, 534, 51580], "temperature": 0.0, "avg_logprob": -0.13869079921556557, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.019408682361245155}, {"id": 391, "seek": 213008, "start": 2154.4, "end": 2159.2, "text": " have a lot of capabilities, I bet you would assume from a search engine, when you actually use", "tokens": [51580, 362, 257, 688, 295, 10862, 11, 286, 778, 291, 576, 6552, 490, 257, 3164, 2848, 11, 562, 291, 767, 764, 51820], "temperature": 0.0, "avg_logprob": -0.13869079921556557, "compression_ratio": 1.6689655172413793, "no_speech_prob": 0.019408682361245155}, {"id": 392, "seek": 215920, "start": 2159.2, "end": 2164.8799999999997, "text": " you.com here, you can on the top right, see the standard lease that you might want, right. And", "tokens": [50364, 291, 13, 1112, 510, 11, 291, 393, 322, 264, 1192, 558, 11, 536, 264, 3832, 24961, 300, 291, 1062, 528, 11, 558, 13, 400, 50648], "temperature": 0.0, "avg_logprob": -0.12303272622530578, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.021606510505080223}, {"id": 393, "seek": 215920, "start": 2164.8799999999997, "end": 2168.96, "text": " sometimes that's just helpful. And that's just what you want. And sometimes you just want to", "tokens": [50648, 2171, 300, 311, 445, 4961, 13, 400, 300, 311, 445, 437, 291, 528, 13, 400, 2171, 291, 445, 528, 281, 50852], "temperature": 0.0, "avg_logprob": -0.12303272622530578, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.021606510505080223}, {"id": 394, "seek": 215920, "start": 2168.96, "end": 2173.6, "text": " have a pure chat experience. And so that is important to get right. And then we have all these", "tokens": [50852, 362, 257, 6075, 5081, 1752, 13, 400, 370, 300, 307, 1021, 281, 483, 558, 13, 400, 550, 321, 362, 439, 613, 51084], "temperature": 0.0, "avg_logprob": -0.12303272622530578, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.021606510505080223}, {"id": 395, "seek": 215920, "start": 2173.6, "end": 2179.4399999999996, "text": " apps to where you can basically ask for like, what's the Microsoft stock price or something.", "tokens": [51084, 7733, 281, 689, 291, 393, 1936, 1029, 337, 411, 11, 437, 311, 264, 8116, 4127, 3218, 420, 746, 13, 51376], "temperature": 0.0, "avg_logprob": -0.12303272622530578, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.021606510505080223}, {"id": 396, "seek": 215920, "start": 2179.4399999999996, "end": 2184.08, "text": " And then, you know, it'll just give you, it'll just give you a life ticker rather than a bunch of", "tokens": [51376, 400, 550, 11, 291, 458, 11, 309, 603, 445, 976, 291, 11, 309, 603, 445, 976, 291, 257, 993, 5204, 260, 2831, 813, 257, 3840, 295, 51608], "temperature": 0.0, "avg_logprob": -0.12303272622530578, "compression_ratio": 1.8844621513944224, "no_speech_prob": 0.021606510505080223}, {"id": 397, "seek": 218408, "start": 2184.08, "end": 2189.52, "text": " texts about the stock here. And so we have all these apps, because we have the search background.", "tokens": [50364, 15765, 466, 264, 4127, 510, 13, 400, 370, 321, 362, 439, 613, 7733, 11, 570, 321, 362, 264, 3164, 3678, 13, 50636], "temperature": 0.0, "avg_logprob": -0.19491887354588772, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.04083141312003136}, {"id": 398, "seek": 218408, "start": 2190.16, "end": 2196.48, "text": " And that makes it an actual viable knowledge assistant, right. Now, you can basically go with", "tokens": [50668, 400, 300, 1669, 309, 364, 3539, 22024, 3601, 10994, 11, 558, 13, 823, 11, 291, 393, 1936, 352, 365, 50984], "temperature": 0.0, "avg_logprob": -0.19491887354588772, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.04083141312003136}, {"id": 399, "seek": 218408, "start": 2196.48, "end": 2201.92, "text": " one click, recover a more Google like experience, that is just incredibly helpful. And that's,", "tokens": [50984, 472, 2052, 11, 8114, 257, 544, 3329, 411, 1752, 11, 300, 307, 445, 6252, 4961, 13, 400, 300, 311, 11, 51256], "temperature": 0.0, "avg_logprob": -0.19491887354588772, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.04083141312003136}, {"id": 400, "seek": 218408, "start": 2201.92, "end": 2208.4, "text": " that's, I think one of the reasons why our browser, which we have also iOS and Android,", "tokens": [51256, 300, 311, 11, 286, 519, 472, 295, 264, 4112, 983, 527, 11185, 11, 597, 321, 362, 611, 17430, 293, 8853, 11, 51580], "temperature": 0.0, "avg_logprob": -0.19491887354588772, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.04083141312003136}, {"id": 401, "seek": 220840, "start": 2208.4, "end": 2212.64, "text": " had to build a browser to be a default, because you can go into Safari,", "tokens": [50364, 632, 281, 1322, 257, 11185, 281, 312, 257, 7576, 11, 570, 291, 393, 352, 666, 43820, 11, 50576], "temperature": 0.0, "avg_logprob": -0.21390060502655653, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.11274116486310959}, {"id": 402, "seek": 220840, "start": 2213.6800000000003, "end": 2218.96, "text": " Safari settings to use you.com as a default. So we build a whole browser for the iOS. And", "tokens": [50628, 43820, 6257, 281, 764, 291, 13, 1112, 382, 257, 7576, 13, 407, 321, 1322, 257, 1379, 11185, 337, 264, 17430, 13, 400, 50892], "temperature": 0.0, "avg_logprob": -0.21390060502655653, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.11274116486310959}, {"id": 403, "seek": 220840, "start": 2218.96, "end": 2226.56, "text": " we're super stoked, because we're going to be one of the options in the EU to have a choice pop up", "tokens": [50892, 321, 434, 1687, 49145, 11, 570, 321, 434, 516, 281, 312, 472, 295, 264, 3956, 294, 264, 10887, 281, 362, 257, 3922, 1665, 493, 51272], "temperature": 0.0, "avg_logprob": -0.21390060502655653, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.11274116486310959}, {"id": 404, "seek": 220840, "start": 2226.56, "end": 2233.28, "text": " stream. When the new iOS 17.4 comes out and arch this year, and they can select you.com to be", "tokens": [51272, 4309, 13, 1133, 264, 777, 17430, 3282, 13, 19, 1487, 484, 293, 3912, 341, 1064, 11, 293, 436, 393, 3048, 291, 13, 1112, 281, 312, 51608], "temperature": 0.0, "avg_logprob": -0.21390060502655653, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.11274116486310959}, {"id": 405, "seek": 223328, "start": 2233.28, "end": 2237.6800000000003, "text": " their default browser. And it's the only default browser in that list that is chat,", "tokens": [50364, 641, 7576, 11185, 13, 400, 309, 311, 264, 787, 7576, 11185, 294, 300, 1329, 300, 307, 5081, 11, 50584], "temperature": 0.0, "avg_logprob": -0.19296207762601084, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.3071463704109192}, {"id": 406, "seek": 223328, "start": 2238.8, "end": 2244.1600000000003, "text": " all the other ones are sort of your standard Chrome, Firefox, and some browsers. And so", "tokens": [50640, 439, 264, 661, 2306, 366, 1333, 295, 428, 3832, 15327, 11, 46613, 11, 293, 512, 36069, 13, 400, 370, 50908], "temperature": 0.0, "avg_logprob": -0.19296207762601084, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.3071463704109192}, {"id": 407, "seek": 223328, "start": 2244.1600000000003, "end": 2249.6800000000003, "text": " I'm really excited. And I think that is going to be a big part of our futures is making it so that", "tokens": [50908, 286, 478, 534, 2919, 13, 400, 286, 519, 300, 307, 516, 281, 312, 257, 955, 644, 295, 527, 26071, 307, 1455, 309, 370, 300, 51184], "temperature": 0.0, "avg_logprob": -0.19296207762601084, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.3071463704109192}, {"id": 408, "seek": 223328, "start": 2249.6800000000003, "end": 2255.0400000000004, "text": " more and more young people are able to just use this as an example. And then if they want to deeper", "tokens": [51184, 544, 293, 544, 2037, 561, 366, 1075, 281, 445, 764, 341, 382, 364, 1365, 13, 400, 550, 498, 436, 528, 281, 7731, 51452], "temperature": 0.0, "avg_logprob": -0.19296207762601084, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.3071463704109192}, {"id": 409, "seek": 223328, "start": 2255.0400000000004, "end": 2260.0800000000004, "text": " go into genius mode, research mode, several times, at some point, you use subscriptions or", "tokens": [51452, 352, 666, 14017, 4391, 11, 2132, 4391, 11, 2940, 1413, 11, 412, 512, 935, 11, 291, 764, 44951, 420, 51704], "temperature": 0.0, "avg_logprob": -0.19296207762601084, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.3071463704109192}, {"id": 410, "seek": 226008, "start": 2260.16, "end": 2266.72, "text": " eventually do it. Yeah, I've been so one run that I'll run a trial balloon by you on this concept", "tokens": [50368, 4728, 360, 309, 13, 865, 11, 286, 600, 668, 370, 472, 1190, 300, 286, 603, 1190, 257, 7308, 16994, 538, 291, 322, 341, 3410, 50696], "temperature": 0.0, "avg_logprob": -0.09265108842116136, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.04082917422056198}, {"id": 411, "seek": 226008, "start": 2266.72, "end": 2273.6, "text": " that I've been kind of kicking around called the AI bundle. And this is an, you know, kind of", "tokens": [50696, 300, 286, 600, 668, 733, 295, 19137, 926, 1219, 264, 7318, 24438, 13, 400, 341, 307, 364, 11, 291, 458, 11, 733, 295, 51040], "temperature": 0.0, "avg_logprob": -0.09265108842116136, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.04082917422056198}, {"id": 412, "seek": 226008, "start": 2273.6, "end": 2277.04, "text": " inspired a little bit. I don't know that anybody wants to, you know, say that they're inspired by", "tokens": [51040, 7547, 257, 707, 857, 13, 286, 500, 380, 458, 300, 4472, 2738, 281, 11, 291, 458, 11, 584, 300, 436, 434, 7547, 538, 51212], "temperature": 0.0, "avg_logprob": -0.09265108842116136, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.04082917422056198}, {"id": 413, "seek": 226008, "start": 2277.04, "end": 2283.7599999999998, "text": " the cable bundle. But I have been struck that there are a ton of great tools out there. And", "tokens": [51212, 264, 8220, 24438, 13, 583, 286, 362, 668, 13159, 300, 456, 366, 257, 2952, 295, 869, 3873, 484, 456, 13, 400, 51548], "temperature": 0.0, "avg_logprob": -0.09265108842116136, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.04082917422056198}, {"id": 414, "seek": 226008, "start": 2284.3199999999997, "end": 2289.2799999999997, "text": " I want to use them. I want to try them. I think a lot of people are, you know, in that very kind", "tokens": [51576, 286, 528, 281, 764, 552, 13, 286, 528, 281, 853, 552, 13, 286, 519, 257, 688, 295, 561, 366, 11, 291, 458, 11, 294, 300, 588, 733, 51824], "temperature": 0.0, "avg_logprob": -0.09265108842116136, "compression_ratio": 1.8527131782945736, "no_speech_prob": 0.04082917422056198}, {"id": 415, "seek": 228928, "start": 2289.36, "end": 2295.2000000000003, "text": " of exploratory curious mode. But to make the economics work on a freemium is kind of tough,", "tokens": [50368, 295, 24765, 4745, 6369, 4391, 13, 583, 281, 652, 264, 14564, 589, 322, 257, 2130, 443, 2197, 307, 733, 295, 4930, 11, 50660], "temperature": 0.0, "avg_logprob": -0.08898435613160492, "compression_ratio": 1.5180722891566265, "no_speech_prob": 0.00288924528285861}, {"id": 416, "seek": 228928, "start": 2295.2000000000003, "end": 2301.1200000000003, "text": " right? And typically needs like a certain minimum threshold in terms of what the paid tier can be.", "tokens": [50660, 558, 30, 400, 5850, 2203, 411, 257, 1629, 7285, 14678, 294, 2115, 295, 437, 264, 4835, 12362, 393, 312, 13, 50956], "temperature": 0.0, "avg_logprob": -0.08898435613160492, "compression_ratio": 1.5180722891566265, "no_speech_prob": 0.00288924528285861}, {"id": 417, "seek": 228928, "start": 2301.84, "end": 2308.1600000000003, "text": " You actually have one of the lowest subscription prices at the $10 a month level. I think of", "tokens": [50992, 509, 767, 362, 472, 295, 264, 12437, 17231, 7901, 412, 264, 1848, 3279, 257, 1618, 1496, 13, 286, 519, 295, 51308], "temperature": 0.0, "avg_logprob": -0.08898435613160492, "compression_ratio": 1.5180722891566265, "no_speech_prob": 0.00288924528285861}, {"id": 418, "seek": 228928, "start": 2308.1600000000003, "end": 2313.44, "text": " anything really that I'm aware of. We're gonna update it soon because like, I think the people", "tokens": [51308, 1340, 534, 300, 286, 478, 3650, 295, 13, 492, 434, 799, 5623, 309, 2321, 570, 411, 11, 286, 519, 264, 561, 51572], "temperature": 0.0, "avg_logprob": -0.08898435613160492, "compression_ratio": 1.5180722891566265, "no_speech_prob": 0.00288924528285861}, {"id": 419, "seek": 231344, "start": 2313.44, "end": 2319.12, "text": " that are willing to pay often don't care if it's 10 or 20. And so if you want to get GBD4,", "tokens": [50364, 300, 366, 4950, 281, 1689, 2049, 500, 380, 1127, 498, 309, 311, 1266, 420, 945, 13, 400, 370, 498, 291, 528, 281, 483, 26809, 35, 19, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1547034659036776, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.03963359817862511}, {"id": 420, "seek": 231344, "start": 2320.0, "end": 2324.32, "text": " literally the same underlying model as chat, GBT, for half the price, you got to come in", "tokens": [50692, 3736, 264, 912, 14217, 2316, 382, 5081, 11, 26809, 51, 11, 337, 1922, 264, 3218, 11, 291, 658, 281, 808, 294, 50908], "temperature": 0.0, "avg_logprob": -0.1547034659036776, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.03963359817862511}, {"id": 421, "seek": 231344, "start": 2324.32, "end": 2328.88, "text": " soon because we're going to eventually switch our prices to be industry standard.", "tokens": [50908, 2321, 570, 321, 434, 516, 281, 4728, 3679, 527, 7901, 281, 312, 3518, 3832, 13, 51136], "temperature": 0.0, "avg_logprob": -0.1547034659036776, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.03963359817862511}, {"id": 422, "seek": 231344, "start": 2328.88, "end": 2332.96, "text": " But that maybe even just, you know, further reinforces the point that like the freemium model", "tokens": [51136, 583, 300, 1310, 754, 445, 11, 291, 458, 11, 3052, 20520, 887, 264, 935, 300, 411, 264, 2130, 443, 2197, 2316, 51340], "temperature": 0.0, "avg_logprob": -0.1547034659036776, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.03963359817862511}, {"id": 423, "seek": 231344, "start": 2332.96, "end": 2338.16, "text": " is tough, right? It's, it's a lot of free usage. The upsells have to have a certain minimum.", "tokens": [51340, 307, 4930, 11, 558, 30, 467, 311, 11, 309, 311, 257, 688, 295, 1737, 14924, 13, 440, 493, 14555, 82, 362, 281, 362, 257, 1629, 7285, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1547034659036776, "compression_ratio": 1.5774647887323943, "no_speech_prob": 0.03963359817862511}, {"id": 424, "seek": 233816, "start": 2339.04, "end": 2345.2, "text": " You're raising yours. And then from, I don't know if this would apply to you, but a lot of the", "tokens": [50408, 509, 434, 11225, 6342, 13, 400, 550, 490, 11, 286, 500, 380, 458, 498, 341, 576, 3079, 281, 291, 11, 457, 257, 688, 295, 264, 50716], "temperature": 0.0, "avg_logprob": -0.08828969903894372, "compression_ratio": 1.612099644128114, "no_speech_prob": 0.040841229259967804}, {"id": 425, "seek": 233816, "start": 2345.2, "end": 2350.24, "text": " app developers that I've talked to have a lot of retention, let's say challenges, you know,", "tokens": [50716, 724, 8849, 300, 286, 600, 2825, 281, 362, 257, 688, 295, 22871, 11, 718, 311, 584, 4759, 11, 291, 458, 11, 50968], "temperature": 0.0, "avg_logprob": -0.08828969903894372, "compression_ratio": 1.612099644128114, "no_speech_prob": 0.040841229259967804}, {"id": 426, "seek": 233816, "start": 2350.24, "end": 2355.04, "text": " everybody's like, I'm getting traffic. I'm getting conversions. But retention is definitely", "tokens": [50968, 2201, 311, 411, 11, 286, 478, 1242, 6419, 13, 286, 478, 1242, 42256, 13, 583, 22871, 307, 2138, 51208], "temperature": 0.0, "avg_logprob": -0.08828969903894372, "compression_ratio": 1.612099644128114, "no_speech_prob": 0.040841229259967804}, {"id": 427, "seek": 233816, "start": 2355.04, "end": 2360.08, "text": " a problem. This has been true at my company Waymark. We're a much more narrow tool, you know,", "tokens": [51208, 257, 1154, 13, 639, 575, 668, 2074, 412, 452, 2237, 9558, 5638, 13, 492, 434, 257, 709, 544, 9432, 2290, 11, 291, 458, 11, 51460], "temperature": 0.0, "avg_logprob": -0.08828969903894372, "compression_ratio": 1.612099644128114, "no_speech_prob": 0.040841229259967804}, {"id": 428, "seek": 233816, "start": 2360.08, "end": 2364.24, "text": " that specifically creates marketing and advertising videos for small businesses.", "tokens": [51460, 300, 4682, 7829, 6370, 293, 13097, 2145, 337, 1359, 6011, 13, 51668], "temperature": 0.0, "avg_logprob": -0.08828969903894372, "compression_ratio": 1.612099644128114, "no_speech_prob": 0.040841229259967804}, {"id": 429, "seek": 236424, "start": 2364.24, "end": 2369.2, "text": " So a lot of times people, they need that once, you know, in a while, and they're not like", "tokens": [50364, 407, 257, 688, 295, 1413, 561, 11, 436, 643, 300, 1564, 11, 291, 458, 11, 294, 257, 1339, 11, 293, 436, 434, 406, 411, 50612], "temperature": 0.0, "avg_logprob": -0.06511939316987991, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.00941210426390171}, {"id": 430, "seek": 236424, "start": 2369.2, "end": 2373.2799999999997, "text": " necessarily ready to add on a subscription. So we see a lot of people that will just come through", "tokens": [50612, 4725, 1919, 281, 909, 322, 257, 17231, 13, 407, 321, 536, 257, 688, 295, 561, 300, 486, 445, 808, 807, 50816], "temperature": 0.0, "avg_logprob": -0.06511939316987991, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.00941210426390171}, {"id": 431, "seek": 236424, "start": 2373.2799999999997, "end": 2378.3199999999997, "text": " be like, Hey, this is super cool. I'll buy it. I'll immediately cancel it after I do what I need", "tokens": [50816, 312, 411, 11, 1911, 11, 341, 307, 1687, 1627, 13, 286, 603, 2256, 309, 13, 286, 603, 4258, 10373, 309, 934, 286, 360, 437, 286, 643, 51068], "temperature": 0.0, "avg_logprob": -0.06511939316987991, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.00941210426390171}, {"id": 432, "seek": 236424, "start": 2378.3199999999997, "end": 2381.68, "text": " to do. And maybe I'll come back in the future. It's not even that I was dissatisfied. It's just", "tokens": [51068, 281, 360, 13, 400, 1310, 286, 603, 808, 646, 294, 264, 2027, 13, 467, 311, 406, 754, 300, 286, 390, 7802, 38502, 13, 467, 311, 445, 51236], "temperature": 0.0, "avg_logprob": -0.06511939316987991, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.00941210426390171}, {"id": 433, "seek": 236424, "start": 2381.68, "end": 2387.7599999999998, "text": " that I kind of want this as like a more of an a la carte purchase than a subscription.", "tokens": [51236, 300, 286, 733, 295, 528, 341, 382, 411, 257, 544, 295, 364, 257, 635, 31483, 8110, 813, 257, 17231, 13, 51540], "temperature": 0.0, "avg_logprob": -0.06511939316987991, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.00941210426390171}, {"id": 434, "seek": 238776, "start": 2388.48, "end": 2394.1600000000003, "text": " So that stuff, you know, VCs don't like that. The metrics, you know, on the kind of traditional", "tokens": [50400, 407, 300, 1507, 11, 291, 458, 11, 691, 33290, 500, 380, 411, 300, 13, 440, 16367, 11, 291, 458, 11, 322, 264, 733, 295, 5164, 50684], "temperature": 0.0, "avg_logprob": -0.11184882372617722, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.18238894641399384}, {"id": 435, "seek": 238776, "start": 2394.1600000000003, "end": 2399.76, "text": " scorecard don't look great. I've had this idea in mind that maybe what we need is sort of an AI", "tokens": [50684, 6175, 22259, 500, 380, 574, 869, 13, 286, 600, 632, 341, 1558, 294, 1575, 300, 1310, 437, 321, 643, 307, 1333, 295, 364, 7318, 50964], "temperature": 0.0, "avg_logprob": -0.11184882372617722, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.18238894641399384}, {"id": 436, "seek": 238776, "start": 2399.76, "end": 2405.84, "text": " bundle, you know, I'm prepared to spend 100 bucks a month on various AI tools. What I really want", "tokens": [50964, 24438, 11, 291, 458, 11, 286, 478, 4927, 281, 3496, 2319, 11829, 257, 1618, 322, 3683, 7318, 3873, 13, 708, 286, 534, 528, 51268], "temperature": 0.0, "avg_logprob": -0.11184882372617722, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.18238894641399384}, {"id": 437, "seek": 238776, "start": 2405.84, "end": 2411.76, "text": " is access to like 1000 different tools that, you know, can kind of split up my 100 bucks.", "tokens": [51268, 307, 2105, 281, 411, 9714, 819, 3873, 300, 11, 291, 458, 11, 393, 733, 295, 7472, 493, 452, 2319, 11829, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11184882372617722, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.18238894641399384}, {"id": 438, "seek": 238776, "start": 2411.76, "end": 2414.96, "text": " However, I don't even know as a consumer, I don't really care about that as, you know,", "tokens": [51564, 2908, 11, 286, 500, 380, 754, 458, 382, 257, 9711, 11, 286, 500, 380, 534, 1127, 466, 300, 382, 11, 291, 458, 11, 51724], "temperature": 0.0, "avg_logprob": -0.11184882372617722, "compression_ratio": 1.7388059701492538, "no_speech_prob": 0.18238894641399384}, {"id": 439, "seek": 241496, "start": 2415.04, "end": 2418.88, "text": " as somebody who's trying to maybe engineer a bundle, obviously the devil could be in the details", "tokens": [50368, 382, 2618, 567, 311, 1382, 281, 1310, 11403, 257, 24438, 11, 2745, 264, 13297, 727, 312, 294, 264, 4365, 50560], "temperature": 0.0, "avg_logprob": -0.0933554221843851, "compression_ratio": 1.8892508143322475, "no_speech_prob": 0.0106519665569067}, {"id": 440, "seek": 241496, "start": 2418.88, "end": 2423.12, "text": " there. But first of all, to those challenges, it sounds like at least the premium challenges", "tokens": [50560, 456, 13, 583, 700, 295, 439, 11, 281, 729, 4759, 11, 309, 3263, 411, 412, 1935, 264, 12049, 4759, 50772], "temperature": 0.0, "avg_logprob": -0.0933554221843851, "compression_ratio": 1.8892508143322475, "no_speech_prob": 0.0106519665569067}, {"id": 441, "seek": 241496, "start": 2423.12, "end": 2428.32, "text": " resonate. I wonder if the retention challenges resonate. And I wonder if you, you know, have any,", "tokens": [50772, 34285, 13, 286, 2441, 498, 264, 22871, 4759, 34285, 13, 400, 286, 2441, 498, 291, 11, 291, 458, 11, 362, 604, 11, 51032], "temperature": 0.0, "avg_logprob": -0.0933554221843851, "compression_ratio": 1.8892508143322475, "no_speech_prob": 0.0106519665569067}, {"id": 442, "seek": 241496, "start": 2428.32, "end": 2435.04, "text": " if there's any appeal to maybe being part of a kind of bigger bundled purchase where you would be,", "tokens": [51032, 498, 456, 311, 604, 13668, 281, 1310, 885, 644, 295, 257, 733, 295, 3801, 13882, 1493, 8110, 689, 291, 576, 312, 11, 51368], "temperature": 0.0, "avg_logprob": -0.0933554221843851, "compression_ratio": 1.8892508143322475, "no_speech_prob": 0.0106519665569067}, {"id": 443, "seek": 241496, "start": 2435.04, "end": 2439.44, "text": " you know, one tool that it's funny, I keep, I've been referring to you, but then also the company", "tokens": [51368, 291, 458, 11, 472, 2290, 300, 309, 311, 4074, 11, 286, 1066, 11, 286, 600, 668, 13761, 281, 291, 11, 457, 550, 611, 264, 2237, 51588], "temperature": 0.0, "avg_logprob": -0.0933554221843851, "compression_ratio": 1.8892508143322475, "no_speech_prob": 0.0106519665569067}, {"id": 444, "seek": 241496, "start": 2439.44, "end": 2443.92, "text": " is you, but where you.com, you know, could be one of a bunch of things that people could access", "tokens": [51588, 307, 291, 11, 457, 689, 291, 13, 1112, 11, 291, 458, 11, 727, 312, 472, 295, 257, 3840, 295, 721, 300, 561, 727, 2105, 51812], "temperature": 0.0, "avg_logprob": -0.0933554221843851, "compression_ratio": 1.8892508143322475, "no_speech_prob": 0.0106519665569067}, {"id": 445, "seek": 244392, "start": 2443.92, "end": 2449.44, "text": " and could kind of share that revenue in a way that may grease the skids for everybody, right?", "tokens": [50364, 293, 727, 733, 295, 2073, 300, 9324, 294, 257, 636, 300, 815, 24867, 264, 1110, 3742, 337, 2201, 11, 558, 30, 50640], "temperature": 0.0, "avg_logprob": -0.10648566632231404, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0010321715380996466}, {"id": 446, "seek": 244392, "start": 2449.44, "end": 2453.52, "text": " My hope is that everybody can use the best tools, and they don't have to make these like", "tokens": [50640, 1222, 1454, 307, 300, 2201, 393, 764, 264, 1151, 3873, 11, 293, 436, 500, 380, 362, 281, 652, 613, 411, 50844], "temperature": 0.0, "avg_logprob": -0.10648566632231404, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0010321715380996466}, {"id": 447, "seek": 244392, "start": 2453.52, "end": 2459.44, "text": " highly binary decisions. Yeah, that sounds great. Sounds like a great idea. Okay, well, I'm not doing", "tokens": [50844, 5405, 17434, 5327, 13, 865, 11, 300, 3263, 869, 13, 14576, 411, 257, 869, 1558, 13, 1033, 11, 731, 11, 286, 478, 406, 884, 51140], "temperature": 0.0, "avg_logprob": -0.10648566632231404, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0010321715380996466}, {"id": 448, "seek": 244392, "start": 2459.44, "end": 2463.52, "text": " it yet. So either I need to start doing it or somebody, if anybody wants to organize the bundle,", "tokens": [51140, 309, 1939, 13, 407, 2139, 286, 643, 281, 722, 884, 309, 420, 2618, 11, 498, 4472, 2738, 281, 13859, 264, 24438, 11, 51344], "temperature": 0.0, "avg_logprob": -0.10648566632231404, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0010321715380996466}, {"id": 449, "seek": 244392, "start": 2463.52, "end": 2467.76, "text": " yeah, send me a DM. I guess another way that this stuff could get bundled would be like,", "tokens": [51344, 1338, 11, 2845, 385, 257, 15322, 13, 286, 2041, 1071, 636, 300, 341, 1507, 727, 483, 13882, 1493, 576, 312, 411, 11, 51556], "temperature": 0.0, "avg_logprob": -0.10648566632231404, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.0010321715380996466}, {"id": 450, "seek": 246776, "start": 2468.32, "end": 2474.0, "text": " into the mega platforms, you know, another kind of possible vision of the future that I could", "tokens": [50392, 666, 264, 17986, 9473, 11, 291, 458, 11, 1071, 733, 295, 1944, 5201, 295, 264, 2027, 300, 286, 727, 50676], "temperature": 0.0, "avg_logprob": -0.08737773254138081, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.2813544273376465}, {"id": 451, "seek": 246776, "start": 2474.0, "end": 2480.0, "text": " imagine is, you know, Google kind of probably retains market share leadership, but, you know,", "tokens": [50676, 3811, 307, 11, 291, 458, 11, 3329, 733, 295, 1391, 1533, 2315, 2142, 2073, 5848, 11, 457, 11, 291, 458, 11, 50976], "temperature": 0.0, "avg_logprob": -0.08737773254138081, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.2813544273376465}, {"id": 452, "seek": 246776, "start": 2480.0, "end": 2484.1600000000003, "text": " maybe the 10 biggest technology companies in the world say, Hey, you know what we should do is kind", "tokens": [50976, 1310, 264, 1266, 3880, 2899, 3431, 294, 264, 1002, 584, 11, 1911, 11, 291, 458, 437, 321, 820, 360, 307, 733, 51184], "temperature": 0.0, "avg_logprob": -0.08737773254138081, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.2813544273376465}, {"id": 453, "seek": 246776, "start": 2484.1600000000003, "end": 2491.36, "text": " of also have a search. And, you know, we can get there, we kind of see a path, you know, Microsoft", "tokens": [51184, 295, 611, 362, 257, 3164, 13, 400, 11, 291, 458, 11, 321, 393, 483, 456, 11, 321, 733, 295, 536, 257, 3100, 11, 291, 458, 11, 8116, 51544], "temperature": 0.0, "avg_logprob": -0.08737773254138081, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.2813544273376465}, {"id": 454, "seek": 246776, "start": 2491.36, "end": 2496.2400000000002, "text": " is obviously already doing that meta not really yet, Apple not really yet to my knowledge, you", "tokens": [51544, 307, 2745, 1217, 884, 300, 19616, 406, 534, 1939, 11, 6373, 406, 534, 1939, 281, 452, 3601, 11, 291, 51788], "temperature": 0.0, "avg_logprob": -0.08737773254138081, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.2813544273376465}, {"id": 455, "seek": 249624, "start": 2496.24, "end": 2501.04, "text": " know, Salesforce, not really yet. But maybe these guys kind of say, Hey, is there like a musical", "tokens": [50364, 458, 11, 40398, 11, 406, 534, 1939, 13, 583, 1310, 613, 1074, 733, 295, 584, 11, 1911, 11, 307, 456, 411, 257, 9165, 50604], "temperature": 0.0, "avg_logprob": -0.10364109894324994, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0019265939481556416}, {"id": 456, "seek": 249624, "start": 2501.04, "end": 2507.2, "text": " chairs game that that potentially develops where the younger AI search companies end up kind of", "tokens": [50604, 18299, 1216, 300, 300, 7263, 25453, 689, 264, 7037, 7318, 3164, 3431, 917, 493, 733, 295, 50912], "temperature": 0.0, "avg_logprob": -0.10364109894324994, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0019265939481556416}, {"id": 457, "seek": 249624, "start": 2507.2, "end": 2512.4799999999996, "text": " partnering off, you know, Amazon also, you know, naturally would be a suspect in this analysis.", "tokens": [50912, 31290, 766, 11, 291, 458, 11, 6795, 611, 11, 291, 458, 11, 8195, 576, 312, 257, 9091, 294, 341, 5215, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10364109894324994, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0019265939481556416}, {"id": 458, "seek": 249624, "start": 2512.4799999999996, "end": 2516.24, "text": " Does that seem like a possible vision of the future? I'm wondering, I'm sure you thought about", "tokens": [51176, 4402, 300, 1643, 411, 257, 1944, 5201, 295, 264, 2027, 30, 286, 478, 6359, 11, 286, 478, 988, 291, 1194, 466, 51364], "temperature": 0.0, "avg_logprob": -0.10364109894324994, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0019265939481556416}, {"id": 459, "seek": 249624, "start": 2516.24, "end": 2524.16, "text": " this, you know, quite a bit, but why would that not happen? I do think the monopoly that Google", "tokens": [51364, 341, 11, 291, 458, 11, 1596, 257, 857, 11, 457, 983, 576, 300, 406, 1051, 30, 286, 360, 519, 264, 37061, 300, 3329, 51760], "temperature": 0.0, "avg_logprob": -0.10364109894324994, "compression_ratio": 1.6631944444444444, "no_speech_prob": 0.0019265939481556416}, {"id": 460, "seek": 252416, "start": 2524.16, "end": 2530.7999999999997, "text": " was able to keep around is going to be harder to sustain longer. I do think", "tokens": [50364, 390, 1075, 281, 1066, 926, 307, 516, 281, 312, 6081, 281, 6769, 2854, 13, 286, 360, 519, 50696], "temperature": 0.0, "avg_logprob": -0.15436627684521073, "compression_ratio": 1.6980392156862745, "no_speech_prob": 0.02296471782028675}, {"id": 461, "seek": 252416, "start": 2531.6, "end": 2538.08, "text": " it is much more likely going to look a little bit more like, I don't like the analogy for some", "tokens": [50736, 309, 307, 709, 544, 3700, 516, 281, 574, 257, 707, 857, 544, 411, 11, 286, 500, 380, 411, 264, 21663, 337, 512, 51060], "temperature": 0.0, "avg_logprob": -0.15436627684521073, "compression_ratio": 1.6980392156862745, "no_speech_prob": 0.02296471782028675}, {"id": 462, "seek": 252416, "start": 2538.08, "end": 2542.3999999999996, "text": " reasons, but like fast food, for instance, right, isn't just Macdonalds, there's also Burger King,", "tokens": [51060, 4112, 11, 457, 411, 2370, 1755, 11, 337, 5197, 11, 558, 11, 1943, 380, 445, 5707, 13966, 3976, 82, 11, 456, 311, 611, 28936, 3819, 11, 51276], "temperature": 0.0, "avg_logprob": -0.15436627684521073, "compression_ratio": 1.6980392156862745, "no_speech_prob": 0.02296471782028675}, {"id": 463, "seek": 252416, "start": 2542.3999999999996, "end": 2548.08, "text": " KFC and Taco Bells. I think search will be a little bit more like that. I think again,", "tokens": [51276, 591, 18671, 293, 37992, 11485, 82, 13, 286, 519, 3164, 486, 312, 257, 707, 857, 544, 411, 300, 13, 286, 519, 797, 11, 51560], "temperature": 0.0, "avg_logprob": -0.15436627684521073, "compression_ratio": 1.6980392156862745, "no_speech_prob": 0.02296471782028675}, {"id": 464, "seek": 252416, "start": 2548.08, "end": 2552.3999999999996, "text": " more fragmented in the future, just because, like, we hear people now, like,", "tokens": [51560, 544, 9241, 14684, 294, 264, 2027, 11, 445, 570, 11, 411, 11, 321, 1568, 561, 586, 11, 411, 11, 51776], "temperature": 0.0, "avg_logprob": -0.15436627684521073, "compression_ratio": 1.6980392156862745, "no_speech_prob": 0.02296471782028675}, {"id": 465, "seek": 255240, "start": 2552.4, "end": 2557.36, "text": " this is better than Google. And like, you know, we didn't raise that much money. And the first", "tokens": [50364, 341, 307, 1101, 813, 3329, 13, 400, 411, 11, 291, 458, 11, 321, 994, 380, 5300, 300, 709, 1460, 13, 400, 264, 700, 50612], "temperature": 0.0, "avg_logprob": -0.19953791300455728, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.005466276779770851}, {"id": 466, "seek": 255240, "start": 2557.36, "end": 2563.12, "text": " two years were like sort of free chat TV or people didn't want us to innovate too much. They're very", "tokens": [50612, 732, 924, 645, 411, 1333, 295, 1737, 5081, 3558, 420, 561, 994, 380, 528, 505, 281, 33444, 886, 709, 13, 814, 434, 588, 50900], "temperature": 0.0, "avg_logprob": -0.19953791300455728, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.005466276779770851}, {"id": 467, "seek": 255240, "start": 2563.12, "end": 2568.64, "text": " stock of Google. But now there's a new young generation. And that young generation has grown", "tokens": [50900, 4127, 295, 3329, 13, 583, 586, 456, 311, 257, 777, 2037, 5125, 13, 400, 300, 2037, 5125, 575, 7709, 51176], "temperature": 0.0, "avg_logprob": -0.19953791300455728, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.005466276779770851}, {"id": 468, "seek": 255240, "start": 2568.64, "end": 2572.88, "text": " up with Tik Tok. We have a Tik Tok app in our standard search, like grew up with Reddit,", "tokens": [51176, 493, 365, 15613, 11036, 13, 492, 362, 257, 15613, 11036, 724, 294, 527, 3832, 3164, 11, 411, 6109, 493, 365, 32210, 11, 51388], "temperature": 0.0, "avg_logprob": -0.19953791300455728, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.005466276779770851}, {"id": 469, "seek": 255240, "start": 2572.88, "end": 2577.84, "text": " I have a Reddit app in our standard search. And each of these takes away a little bit of the", "tokens": [51388, 286, 362, 257, 32210, 724, 294, 527, 3832, 3164, 13, 400, 1184, 295, 613, 2516, 1314, 257, 707, 857, 295, 264, 51636], "temperature": 0.0, "avg_logprob": -0.19953791300455728, "compression_ratio": 1.7537313432835822, "no_speech_prob": 0.005466276779770851}, {"id": 470, "seek": 257784, "start": 2577.84, "end": 2584.32, "text": " Google search, right? Amazon probably was the most successful in taking away searches from Google,", "tokens": [50364, 3329, 3164, 11, 558, 30, 6795, 1391, 390, 264, 881, 4406, 294, 1940, 1314, 26701, 490, 3329, 11, 50688], "temperature": 0.0, "avg_logprob": -0.19194642771845277, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.08505182713270187}, {"id": 471, "seek": 257784, "start": 2584.32, "end": 2588.8, "text": " where if you want to buy something, be the little certain threshold, like 50 or 100 bucks,", "tokens": [50688, 689, 498, 291, 528, 281, 2256, 746, 11, 312, 264, 707, 1629, 14678, 11, 411, 2625, 420, 2319, 11829, 11, 50912], "temperature": 0.0, "avg_logprob": -0.19194642771845277, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.08505182713270187}, {"id": 472, "seek": 257784, "start": 2588.8, "end": 2592.96, "text": " you know, the person, you just search directly on Amazon, because there you can execute on your", "tokens": [50912, 291, 458, 11, 264, 954, 11, 291, 445, 3164, 3838, 322, 6795, 11, 570, 456, 291, 393, 14483, 322, 428, 51120], "temperature": 0.0, "avg_logprob": -0.19194642771845277, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.08505182713270187}, {"id": 473, "seek": 257784, "start": 2592.96, "end": 2598.2400000000002, "text": " intent of actually purchasing that thing, right? And so why search it in Google and then search it", "tokens": [51120, 8446, 295, 767, 20906, 300, 551, 11, 558, 30, 400, 370, 983, 3164, 309, 294, 3329, 293, 550, 3164, 309, 51384], "temperature": 0.0, "avg_logprob": -0.19194642771845277, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.08505182713270187}, {"id": 474, "seek": 257784, "start": 2598.2400000000002, "end": 2602.7200000000003, "text": " again, try to find it on Amazon, she can just do that right away. And so I think, you know,", "tokens": [51384, 797, 11, 853, 281, 915, 309, 322, 6795, 11, 750, 393, 445, 360, 300, 558, 1314, 13, 400, 370, 286, 519, 11, 291, 458, 11, 51608], "temperature": 0.0, "avg_logprob": -0.19194642771845277, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.08505182713270187}, {"id": 475, "seek": 260272, "start": 2602.72, "end": 2608.3999999999996, "text": " Tik Tok has taken away for young folks, some searches from Google, that, you know, they're", "tokens": [50364, 15613, 11036, 575, 2726, 1314, 337, 2037, 4024, 11, 512, 26701, 490, 3329, 11, 300, 11, 291, 458, 11, 436, 434, 50648], "temperature": 0.0, "avg_logprob": -0.16005729416669426, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.05917786434292793}, {"id": 476, "seek": 260272, "start": 2608.3999999999996, "end": 2612.3199999999997, "text": " like, I want to see what the restaurant is, but they kind of want to see what the restaurant's", "tokens": [50648, 411, 11, 286, 528, 281, 536, 437, 264, 6383, 307, 11, 457, 436, 733, 295, 528, 281, 536, 437, 264, 6383, 311, 50844], "temperature": 0.0, "avg_logprob": -0.16005729416669426, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.05917786434292793}, {"id": 477, "seek": 260272, "start": 2612.3199999999997, "end": 2616.48, "text": " ability to create, but Instagram photos are or ticked our videos are. And so they want to see", "tokens": [50844, 3485, 281, 1884, 11, 457, 5281, 5787, 366, 420, 5204, 292, 527, 2145, 366, 13, 400, 370, 436, 528, 281, 536, 51052], "temperature": 0.0, "avg_logprob": -0.16005729416669426, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.05917786434292793}, {"id": 478, "seek": 260272, "start": 2616.48, "end": 2621.2, "text": " the ticked our videos of other people before they decide on how it looks. If there's a Venn", "tokens": [51052, 264, 5204, 292, 527, 2145, 295, 661, 561, 949, 436, 4536, 322, 577, 309, 1542, 13, 759, 456, 311, 257, 691, 1857, 51288], "temperature": 0.0, "avg_logprob": -0.16005729416669426, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.05917786434292793}, {"id": 479, "seek": 260272, "start": 2621.2, "end": 2628.24, "text": " diagram, we are overlapping search, but we're also actually expanding search. Like, you wouldn't", "tokens": [51288, 10686, 11, 321, 366, 33535, 3164, 11, 457, 321, 434, 611, 767, 14702, 3164, 13, 1743, 11, 291, 2759, 380, 51640], "temperature": 0.0, "avg_logprob": -0.16005729416669426, "compression_ratio": 1.7727272727272727, "no_speech_prob": 0.05917786434292793}, {"id": 480, "seek": 262824, "start": 2628.3199999999997, "end": 2632.4799999999996, "text": " ask, like, give me this complex story about the Peloponnesian war, or like,", "tokens": [50368, 1029, 11, 411, 11, 976, 385, 341, 3997, 1657, 466, 264, 21083, 404, 266, 4081, 952, 1516, 11, 420, 411, 11, 50576], "temperature": 0.0, "avg_logprob": -0.2571094405483192, "compression_ratio": 1.778501628664495, "no_speech_prob": 0.3005489408969879}, {"id": 481, "seek": 262824, "start": 2632.4799999999996, "end": 2637.6, "text": " do this mortgage calculation with, you know, this and this interest rate and that increase", "tokens": [50576, 360, 341, 20236, 17108, 365, 11, 291, 458, 11, 341, 293, 341, 1179, 3314, 293, 300, 3488, 50832], "temperature": 0.0, "avg_logprob": -0.2571094405483192, "compression_ratio": 1.778501628664495, "no_speech_prob": 0.3005489408969879}, {"id": 482, "seek": 262824, "start": 2637.6, "end": 2640.7999999999997, "text": " and blah, blah, blah, because you know, Google wouldn't give you the answer. Like, it's not going", "tokens": [50832, 293, 12288, 11, 12288, 11, 12288, 11, 570, 291, 458, 11, 3329, 2759, 380, 976, 291, 264, 1867, 13, 1743, 11, 309, 311, 406, 516, 50992], "temperature": 0.0, "avg_logprob": -0.2571094405483192, "compression_ratio": 1.778501628664495, "no_speech_prob": 0.3005489408969879}, {"id": 483, "seek": 262824, "start": 2640.7999999999997, "end": 2645.04, "text": " to buy some book for you. It's not going to go on the web, summarize, like 20 distance or 50", "tokens": [50992, 281, 2256, 512, 1446, 337, 291, 13, 467, 311, 406, 516, 281, 352, 322, 264, 3670, 11, 20858, 11, 411, 945, 4560, 420, 2625, 51204], "temperature": 0.0, "avg_logprob": -0.2571094405483192, "compression_ratio": 1.778501628664495, "no_speech_prob": 0.3005489408969879}, {"id": 484, "seek": 262824, "start": 2645.04, "end": 2651.3599999999997, "text": " distance websites for you and create this nice essay. So chat expands, search, you don't talk", "tokens": [51204, 4560, 12891, 337, 291, 293, 1884, 341, 1481, 16238, 13, 407, 5081, 33706, 11, 3164, 11, 291, 500, 380, 751, 51520], "temperature": 0.0, "avg_logprob": -0.2571094405483192, "compression_ratio": 1.778501628664495, "no_speech_prob": 0.3005489408969879}, {"id": 485, "seek": 262824, "start": 2651.3599999999997, "end": 2655.52, "text": " about your feelings that much to Google, it's search box and sell, right? Like you asked about", "tokens": [51520, 466, 428, 6640, 300, 709, 281, 3329, 11, 309, 311, 3164, 2424, 293, 3607, 11, 558, 30, 1743, 291, 2351, 466, 51728], "temperature": 0.0, "avg_logprob": -0.2571094405483192, "compression_ratio": 1.778501628664495, "no_speech_prob": 0.3005489408969879}, {"id": 486, "seek": 265552, "start": 2655.6, "end": 2659.6, "text": " this recent news event, you want to learn like some quick facts, and then, you know,", "tokens": [50368, 341, 5162, 2583, 2280, 11, 291, 528, 281, 1466, 411, 512, 1702, 9130, 11, 293, 550, 11, 291, 458, 11, 50568], "temperature": 0.0, "avg_logprob": -0.15773168291364398, "compression_ratio": 1.744336569579288, "no_speech_prob": 0.002714583184570074}, {"id": 487, "seek": 265552, "start": 2659.6, "end": 2663.52, "text": " like the more complex the facts get, the less and less we go to Google and more for you,", "tokens": [50568, 411, 264, 544, 3997, 264, 9130, 483, 11, 264, 1570, 293, 1570, 321, 352, 281, 3329, 293, 544, 337, 291, 11, 50764], "temperature": 0.0, "avg_logprob": -0.15773168291364398, "compression_ratio": 1.744336569579288, "no_speech_prob": 0.002714583184570074}, {"id": 488, "seek": 265552, "start": 2663.52, "end": 2669.04, "text": " just go directly to something like you.com. And, and so yeah, I think it will, the search", "tokens": [50764, 445, 352, 3838, 281, 746, 411, 291, 13, 1112, 13, 400, 11, 293, 370, 1338, 11, 286, 519, 309, 486, 11, 264, 3164, 51040], "temperature": 0.0, "avg_logprob": -0.15773168291364398, "compression_ratio": 1.744336569579288, "no_speech_prob": 0.002714583184570074}, {"id": 489, "seek": 265552, "start": 2669.04, "end": 2674.8, "text": " landscape is really changing. Yeah, there's also just, it's like, it's maybe not a natural", "tokens": [51040, 9661, 307, 534, 4473, 13, 865, 11, 456, 311, 611, 445, 11, 309, 311, 411, 11, 309, 311, 1310, 406, 257, 3303, 51328], "temperature": 0.0, "avg_logprob": -0.15773168291364398, "compression_ratio": 1.744336569579288, "no_speech_prob": 0.002714583184570074}, {"id": 490, "seek": 265552, "start": 2674.8, "end": 2679.92, "text": " monopoly anymore, but there is still definitely a need for scale and economies of scale. And", "tokens": [51328, 37061, 3602, 11, 457, 456, 307, 920, 2138, 257, 643, 337, 4373, 293, 23158, 295, 4373, 13, 400, 51584], "temperature": 0.0, "avg_logprob": -0.15773168291364398, "compression_ratio": 1.744336569579288, "no_speech_prob": 0.002714583184570074}, {"id": 491, "seek": 265552, "start": 2680.48, "end": 2684.64, "text": " so one way of framing this too is how does the market shape up, right? And one way to think", "tokens": [51612, 370, 472, 636, 295, 28971, 341, 886, 307, 577, 775, 264, 2142, 3909, 493, 11, 558, 30, 400, 472, 636, 281, 519, 51820], "temperature": 0.0, "avg_logprob": -0.15773168291364398, "compression_ratio": 1.744336569579288, "no_speech_prob": 0.002714583184570074}, {"id": 492, "seek": 268464, "start": 2684.64, "end": 2689.04, "text": " about it that I find pretty compelling is maybe it ends up looking a lot like cloud,", "tokens": [50364, 466, 309, 300, 286, 915, 1238, 20050, 307, 1310, 309, 5314, 493, 1237, 257, 688, 411, 4588, 11, 50584], "temperature": 0.0, "avg_logprob": -0.07494139267226398, "compression_ratio": 1.8359375, "no_speech_prob": 0.026753541082143784}, {"id": 493, "seek": 268464, "start": 2689.68, "end": 2694.56, "text": " because in the limit, it sort of is cloud, you know, it's like, what do you really need? You", "tokens": [50616, 570, 294, 264, 4948, 11, 309, 1333, 295, 307, 4588, 11, 291, 458, 11, 309, 311, 411, 11, 437, 360, 291, 534, 643, 30, 509, 50860], "temperature": 0.0, "avg_logprob": -0.07494139267226398, "compression_ratio": 1.8359375, "no_speech_prob": 0.026753541082143784}, {"id": 494, "seek": 268464, "start": 2694.56, "end": 2700.4, "text": " need like the actual data centers, you need the compute, you need, you know, bandwidth, you need", "tokens": [50860, 643, 411, 264, 3539, 1412, 10898, 11, 291, 643, 264, 14722, 11, 291, 643, 11, 291, 458, 11, 23647, 11, 291, 643, 51152], "temperature": 0.0, "avg_logprob": -0.07494139267226398, "compression_ratio": 1.8359375, "no_speech_prob": 0.026753541082143784}, {"id": 495, "seek": 268464, "start": 2700.4, "end": 2707.7599999999998, "text": " these like raw inputs that the big companies have built out seem to be the things that are probably,", "tokens": [51152, 613, 411, 8936, 15743, 300, 264, 955, 3431, 362, 3094, 484, 1643, 281, 312, 264, 721, 300, 366, 1391, 11, 51520], "temperature": 0.0, "avg_logprob": -0.07494139267226398, "compression_ratio": 1.8359375, "no_speech_prob": 0.026753541082143784}, {"id": 496, "seek": 268464, "start": 2707.7599999999998, "end": 2711.52, "text": " you know, as we see like a ton of innovation at the application layer, those things are still,", "tokens": [51520, 291, 458, 11, 382, 321, 536, 411, 257, 2952, 295, 8504, 412, 264, 3861, 4583, 11, 729, 721, 366, 920, 11, 51708], "temperature": 0.0, "avg_logprob": -0.07494139267226398, "compression_ratio": 1.8359375, "no_speech_prob": 0.026753541082143784}, {"id": 497, "seek": 271152, "start": 2711.52, "end": 2715.52, "text": " you know, they're still pretty expensive and not easy to recreate.", "tokens": [50364, 291, 458, 11, 436, 434, 920, 1238, 5124, 293, 406, 1858, 281, 25833, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21580633053109666, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.0007321035373024642}, {"id": 498, "seek": 271152, "start": 2715.52, "end": 2719.7599999999998, "text": " Yeah, I'm very, I'm very excited. I'm up for it. You know, that's sort of why, like, we got into", "tokens": [50564, 865, 11, 286, 478, 588, 11, 286, 478, 588, 2919, 13, 286, 478, 493, 337, 309, 13, 509, 458, 11, 300, 311, 1333, 295, 983, 11, 411, 11, 321, 658, 666, 50776], "temperature": 0.0, "avg_logprob": -0.21580633053109666, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.0007321035373024642}, {"id": 499, "seek": 271152, "start": 2719.7599999999998, "end": 2725.12, "text": " this space in the first place, like, because we thought, like, we saw the transformer, we saw", "tokens": [50776, 341, 1901, 294, 264, 700, 1081, 11, 411, 11, 570, 321, 1194, 11, 411, 11, 321, 1866, 264, 31782, 11, 321, 1866, 51044], "temperature": 0.0, "avg_logprob": -0.21580633053109666, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.0007321035373024642}, {"id": 500, "seek": 271152, "start": 2725.12, "end": 2729.7599999999998, "text": " our, you know, highly like lots of co-attention mechanisms in that, that can keep paper that", "tokens": [51044, 527, 11, 291, 458, 11, 5405, 411, 3195, 295, 598, 12, 1591, 1251, 15902, 294, 300, 11, 300, 393, 1066, 3035, 300, 51276], "temperature": 0.0, "avg_logprob": -0.21580633053109666, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.0007321035373024642}, {"id": 501, "seek": 271152, "start": 2729.7599999999998, "end": 2735.44, "text": " have a massive prompt engineering, we're like, silly, the technology is right to disrupt this,", "tokens": [51276, 362, 257, 5994, 12391, 7043, 11, 321, 434, 411, 11, 11774, 11, 264, 2899, 307, 558, 281, 14124, 341, 11, 51560], "temperature": 0.0, "avg_logprob": -0.21580633053109666, "compression_ratio": 1.7115384615384615, "no_speech_prob": 0.0007321035373024642}, {"id": 502, "seek": 273544, "start": 2735.44, "end": 2742.4, "text": " this industry. But, you know, Google is this amazing company that was able to create a monopoly", "tokens": [50364, 341, 3518, 13, 583, 11, 291, 458, 11, 3329, 307, 341, 2243, 2237, 300, 390, 1075, 281, 1884, 257, 37061, 50712], "temperature": 0.0, "avg_logprob": -0.14193083059908163, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.1754724532365799}, {"id": 503, "seek": 273544, "start": 2742.4, "end": 2749.52, "text": " for almost two decades that, you know, makes $500 million a day. So when you make that much money", "tokens": [50712, 337, 1920, 732, 7878, 300, 11, 291, 458, 11, 1669, 1848, 7526, 2459, 257, 786, 13, 407, 562, 291, 652, 300, 709, 1460, 51068], "temperature": 0.0, "avg_logprob": -0.14193083059908163, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.1754724532365799}, {"id": 504, "seek": 273544, "start": 2749.52, "end": 2754.0, "text": " a day, you don't want disruption, you don't want that to change, right? And that's why all the", "tokens": [51068, 257, 786, 11, 291, 500, 380, 528, 28751, 11, 291, 500, 380, 528, 300, 281, 1319, 11, 558, 30, 400, 300, 311, 983, 439, 264, 51292], "temperature": 0.0, "avg_logprob": -0.14193083059908163, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.1754724532365799}, {"id": 505, "seek": 273544, "start": 2754.0, "end": 2760.64, "text": " Ten's former operators left eventually. And what's, what's really powerful is like, because of open", "tokens": [51292, 9380, 311, 5819, 19077, 1411, 4728, 13, 400, 437, 311, 11, 437, 311, 534, 4005, 307, 411, 11, 570, 295, 1269, 51624], "temperature": 0.0, "avg_logprob": -0.14193083059908163, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.1754724532365799}, {"id": 506, "seek": 276064, "start": 2760.64, "end": 2766.3199999999997, "text": " source, you can actually innovate a lot more. Now, some open source to an actual product that", "tokens": [50364, 4009, 11, 291, 393, 767, 33444, 257, 688, 544, 13, 823, 11, 512, 1269, 4009, 281, 364, 3539, 1674, 300, 50648], "temperature": 0.0, "avg_logprob": -0.20619164138543802, "compression_ratio": 1.5973597359735974, "no_speech_prob": 0.20676003396511078}, {"id": 507, "seek": 276064, "start": 2766.3199999999997, "end": 2773.12, "text": " runs millions of times isn't down ever has good uptime guarantees, and like, accuracy, no hallucinations,", "tokens": [50648, 6676, 6803, 295, 1413, 1943, 380, 760, 1562, 575, 665, 493, 3766, 32567, 11, 293, 411, 11, 14170, 11, 572, 35212, 10325, 11, 50988], "temperature": 0.0, "avg_logprob": -0.20619164138543802, "compression_ratio": 1.5973597359735974, "no_speech_prob": 0.20676003396511078}, {"id": 508, "seek": 276064, "start": 2773.12, "end": 2778.56, "text": " up to date, news, information, etc. I mean, it's still complex, but clearly the bar has gotten", "tokens": [50988, 493, 281, 4002, 11, 2583, 11, 1589, 11, 5183, 13, 286, 914, 11, 309, 311, 920, 3997, 11, 457, 4448, 264, 2159, 575, 5768, 51260], "temperature": 0.0, "avg_logprob": -0.20619164138543802, "compression_ratio": 1.5973597359735974, "no_speech_prob": 0.20676003396511078}, {"id": 509, "seek": 276064, "start": 2778.56, "end": 2783.6, "text": " low. That would have cost us like billions of dollars to build five, 10 years and, you know,", "tokens": [51260, 2295, 13, 663, 576, 362, 2063, 505, 411, 17375, 295, 3808, 281, 1322, 1732, 11, 1266, 924, 293, 11, 291, 458, 11, 51512], "temperature": 0.0, "avg_logprob": -0.20619164138543802, "compression_ratio": 1.5973597359735974, "no_speech_prob": 0.20676003396511078}, {"id": 510, "seek": 276064, "start": 2783.6, "end": 2790.24, "text": " researchers wasn't there yet. And, and I think it's ultimately amazing for users, right? Because", "tokens": [51512, 10309, 2067, 380, 456, 1939, 13, 400, 11, 293, 286, 519, 309, 311, 6284, 2243, 337, 5022, 11, 558, 30, 1436, 51844], "temperature": 0.0, "avg_logprob": -0.20619164138543802, "compression_ratio": 1.5973597359735974, "no_speech_prob": 0.20676003396511078}, {"id": 511, "seek": 279024, "start": 2790.24, "end": 2795.12, "text": " one thing that I had to distill all of you.com right now into just two words would be amazing", "tokens": [50364, 472, 551, 300, 286, 632, 281, 42923, 439, 295, 291, 13, 1112, 558, 586, 666, 445, 732, 2283, 576, 312, 2243, 50608], "temperature": 0.0, "avg_logprob": -0.19968414306640625, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.002322767162695527}, {"id": 512, "seek": 279024, "start": 2795.12, "end": 2800.7999999999997, "text": " answers. And you just get more of them. And that means people eventually are more productive. And", "tokens": [50608, 6338, 13, 400, 291, 445, 483, 544, 295, 552, 13, 400, 300, 1355, 561, 4728, 366, 544, 13304, 13, 400, 50892], "temperature": 0.0, "avg_logprob": -0.19968414306640625, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.002322767162695527}, {"id": 513, "seek": 279024, "start": 2800.7999999999997, "end": 2805.6, "text": " like, it's the young generation that's growing up with chat GBT, you know, such like, they're not", "tokens": [50892, 411, 11, 309, 311, 264, 2037, 5125, 300, 311, 4194, 493, 365, 5081, 26809, 51, 11, 291, 458, 11, 1270, 411, 11, 436, 434, 406, 51132], "temperature": 0.0, "avg_logprob": -0.19968414306640625, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.002322767162695527}, {"id": 514, "seek": 279024, "start": 2805.6, "end": 2811.2799999999997, "text": " going to go back. Okay, so feel free to punt on this one or just decline if you like, but it seems", "tokens": [51132, 516, 281, 352, 646, 13, 1033, 11, 370, 841, 1737, 281, 18212, 322, 341, 472, 420, 445, 15635, 498, 291, 411, 11, 457, 309, 2544, 51416], "temperature": 0.0, "avg_logprob": -0.19968414306640625, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.002322767162695527}, {"id": 515, "seek": 281128, "start": 2811.36, "end": 2820.4, "text": " like I can, I can envision a you.com by Salesforce very easily, where the, you know, as they kind", "tokens": [50368, 411, 286, 393, 11, 286, 393, 24739, 257, 291, 13, 1112, 538, 40398, 588, 3612, 11, 689, 264, 11, 291, 458, 11, 382, 436, 733, 50820], "temperature": 0.0, "avg_logprob": -0.1152961692031549, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.3997322618961334}, {"id": 516, "seek": 281128, "start": 2820.4, "end": 2825.84, "text": " of try to be the everything app for all work on the straight, especially with Slack now, does it", "tokens": [50820, 295, 853, 281, 312, 264, 1203, 724, 337, 439, 589, 322, 264, 2997, 11, 2318, 365, 37211, 586, 11, 775, 309, 51092], "temperature": 0.0, "avg_logprob": -0.1152961692031549, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.3997322618961334}, {"id": 517, "seek": 281128, "start": 2825.84, "end": 2831.0400000000004, "text": " seem realistic to imagine a future in which, you know, kind of all the big tech companies have this", "tokens": [51092, 1643, 12465, 281, 3811, 257, 2027, 294, 597, 11, 291, 458, 11, 733, 295, 439, 264, 955, 7553, 3431, 362, 341, 51352], "temperature": 0.0, "avg_logprob": -0.1152961692031549, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.3997322618961334}, {"id": 518, "seek": 281128, "start": 2831.0400000000004, "end": 2835.84, "text": " like super robust suite, and you're either like, in the Microsoft suite with teams and Bing, or", "tokens": [51352, 411, 1687, 13956, 14205, 11, 293, 291, 434, 2139, 411, 11, 294, 264, 8116, 14205, 365, 5491, 293, 30755, 11, 420, 51592], "temperature": 0.0, "avg_logprob": -0.1152961692031549, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.3997322618961334}, {"id": 519, "seek": 283584, "start": 2835.84, "end": 2840.96, "text": " you're in the Google suite with, you know, G suite and Bard, or you're in maybe the Salesforce", "tokens": [50364, 291, 434, 294, 264, 3329, 14205, 365, 11, 291, 458, 11, 460, 14205, 293, 26841, 11, 420, 291, 434, 294, 1310, 264, 40398, 50620], "temperature": 0.0, "avg_logprob": -0.10794958114624023, "compression_ratio": 1.625, "no_speech_prob": 0.0023966296575963497}, {"id": 520, "seek": 283584, "start": 2840.96, "end": 2846.2400000000002, "text": " suite with Slack and you.com, you know, I'm not trying to be your banker here, but that, that", "tokens": [50620, 14205, 365, 37211, 293, 291, 13, 1112, 11, 291, 458, 11, 286, 478, 406, 1382, 281, 312, 428, 48008, 510, 11, 457, 300, 11, 300, 50884], "temperature": 0.0, "avg_logprob": -0.10794958114624023, "compression_ratio": 1.625, "no_speech_prob": 0.0023966296575963497}, {"id": 521, "seek": 283584, "start": 2846.2400000000002, "end": 2854.96, "text": " seems like a pretty natural outcome to me. Interesting. I do think there's a ton of potential", "tokens": [50884, 2544, 411, 257, 1238, 3303, 9700, 281, 385, 13, 14711, 13, 286, 360, 519, 456, 311, 257, 2952, 295, 3995, 51320], "temperature": 0.0, "avg_logprob": -0.10794958114624023, "compression_ratio": 1.625, "no_speech_prob": 0.0023966296575963497}, {"id": 522, "seek": 283584, "start": 2854.96, "end": 2862.88, "text": " for almost every company to partner with you.com and supercharge their chat bot. So, and we're", "tokens": [51320, 337, 1920, 633, 2237, 281, 4975, 365, 291, 13, 1112, 293, 1687, 13604, 641, 5081, 10592, 13, 407, 11, 293, 321, 434, 51716], "temperature": 0.0, "avg_logprob": -0.10794958114624023, "compression_ratio": 1.625, "no_speech_prob": 0.0023966296575963497}, {"id": 523, "seek": 286288, "start": 2862.88, "end": 2867.84, "text": " very excited to partner with a lot of folks. Okay, that's very diplomatic answer. Keep your", "tokens": [50364, 588, 2919, 281, 4975, 365, 257, 688, 295, 4024, 13, 1033, 11, 300, 311, 588, 26553, 1867, 13, 5527, 428, 50612], "temperature": 0.0, "avg_logprob": -0.10467948046597568, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.02228284254670143}, {"id": 524, "seek": 286288, "start": 2867.84, "end": 2873.04, "text": " options open. All right, so we can touch on certainly more business and product stuff, but I", "tokens": [50612, 3956, 1269, 13, 1057, 558, 11, 370, 321, 393, 2557, 322, 3297, 544, 1606, 293, 1674, 1507, 11, 457, 286, 50872], "temperature": 0.0, "avg_logprob": -0.10467948046597568, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.02228284254670143}, {"id": 525, "seek": 286288, "start": 2873.04, "end": 2879.04, "text": " kind of wanted to now go into just the future of all this, you know, in practical and maybe", "tokens": [50872, 733, 295, 1415, 281, 586, 352, 666, 445, 264, 2027, 295, 439, 341, 11, 291, 458, 11, 294, 8496, 293, 1310, 51172], "temperature": 0.0, "avg_logprob": -0.10467948046597568, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.02228284254670143}, {"id": 526, "seek": 286288, "start": 2879.04, "end": 2883.84, "text": " increasingly philosophical terms as well, running down kind of first of a set of like", "tokens": [51172, 12980, 25066, 2115, 382, 731, 11, 2614, 760, 733, 295, 700, 295, 257, 992, 295, 411, 51412], "temperature": 0.0, "avg_logprob": -0.10467948046597568, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.02228284254670143}, {"id": 527, "seek": 286288, "start": 2883.84, "end": 2888.48, "text": " limitations of where AI is today. And I think, again, folks who listen to this show have at", "tokens": [51412, 15705, 295, 689, 7318, 307, 965, 13, 400, 286, 519, 11, 797, 11, 4024, 567, 2140, 281, 341, 855, 362, 412, 51644], "temperature": 0.0, "avg_logprob": -0.10467948046597568, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.02228284254670143}, {"id": 528, "seek": 288848, "start": 2888.48, "end": 2893.6, "text": " least a decent sense of that. So for starters, reasoning, you've obviously got the genius mode.", "tokens": [50364, 1935, 257, 8681, 2020, 295, 300, 13, 407, 337, 35131, 11, 21577, 11, 291, 600, 2745, 658, 264, 14017, 4391, 13, 50620], "temperature": 0.0, "avg_logprob": -0.13118197178018504, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.039629772305488586}, {"id": 529, "seek": 288848, "start": 2893.6, "end": 2897.92, "text": " It can do, you know, like the most advanced reasoning. I assume that that is tapping into", "tokens": [50620, 467, 393, 360, 11, 291, 458, 11, 411, 264, 881, 7339, 21577, 13, 286, 6552, 300, 300, 307, 21444, 666, 50836], "temperature": 0.0, "avg_logprob": -0.13118197178018504, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.039629772305488586}, {"id": 530, "seek": 288848, "start": 2897.92, "end": 2902.56, "text": " GPT-4. You know, everything I understand is like basically nothing is really on the level of", "tokens": [50836, 26039, 51, 12, 19, 13, 509, 458, 11, 1203, 286, 1223, 307, 411, 1936, 1825, 307, 534, 322, 264, 1496, 295, 51068], "temperature": 0.0, "avg_logprob": -0.13118197178018504, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.039629772305488586}, {"id": 531, "seek": 288848, "start": 2902.56, "end": 2909.6, "text": " GPT-4 for general reasoning purposes. Yeah, especially the orchestration and then on the", "tokens": [51068, 26039, 51, 12, 19, 337, 2674, 21577, 9932, 13, 865, 11, 2318, 264, 14161, 2405, 293, 550, 322, 264, 51420], "temperature": 0.0, "avg_logprob": -0.13118197178018504, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.039629772305488586}, {"id": 532, "seek": 288848, "start": 2909.6, "end": 2916.2400000000002, "text": " coding often, but not always. Yeah. So I'll tell you another one, the third system is knowing which", "tokens": [51420, 17720, 2049, 11, 457, 406, 1009, 13, 865, 13, 407, 286, 603, 980, 291, 1071, 472, 11, 264, 2636, 1185, 307, 5276, 597, 51752], "temperature": 0.0, "avg_logprob": -0.13118197178018504, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.039629772305488586}, {"id": 533, "seek": 291624, "start": 2916.24, "end": 2923.3599999999997, "text": " LM to use and sometimes multiple. And the fourth system is dynamically prompting different models.", "tokens": [50364, 46529, 281, 764, 293, 2171, 3866, 13, 400, 264, 6409, 1185, 307, 43492, 12391, 278, 819, 5245, 13, 50720], "temperature": 0.0, "avg_logprob": -0.09812969242760894, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.0005702910129912198}, {"id": 534, "seek": 291624, "start": 2923.3599999999997, "end": 2929.04, "text": " So depending on the query, you actually get a vastly different prompt to get you ultimately", "tokens": [50720, 407, 5413, 322, 264, 14581, 11, 291, 767, 483, 257, 41426, 819, 12391, 281, 483, 291, 6284, 51004], "temperature": 0.0, "avg_logprob": -0.09812969242760894, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.0005702910129912198}, {"id": 535, "seek": 291624, "start": 2929.04, "end": 2934.3999999999996, "text": " the answer and the orchestration. So it's another complexity layer. So what do you think is kind", "tokens": [51004, 264, 1867, 293, 264, 14161, 2405, 13, 407, 309, 311, 1071, 14024, 4583, 13, 407, 437, 360, 291, 519, 307, 733, 51272], "temperature": 0.0, "avg_logprob": -0.09812969242760894, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.0005702910129912198}, {"id": 536, "seek": 291624, "start": 2934.3999999999996, "end": 2940.0, "text": " of the future of reasoning? If you have maxed out, you know, what the current capabilities are,", "tokens": [51272, 295, 264, 2027, 295, 21577, 30, 759, 291, 362, 11469, 292, 484, 11, 291, 458, 11, 437, 264, 2190, 10862, 366, 11, 51552], "temperature": 0.0, "avg_logprob": -0.09812969242760894, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.0005702910129912198}, {"id": 537, "seek": 291624, "start": 2940.0, "end": 2944.64, "text": " where do the future capabilities come from? I'm thinking about things like, to a degree,", "tokens": [51552, 689, 360, 264, 2027, 10862, 808, 490, 30, 286, 478, 1953, 466, 721, 411, 11, 281, 257, 4314, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09812969242760894, "compression_ratio": 1.6917562724014337, "no_speech_prob": 0.0005702910129912198}, {"id": 538, "seek": 294464, "start": 2944.64, "end": 2949.68, "text": " you sort of already have it with using different models. It is a one way of implementing variable", "tokens": [50364, 291, 1333, 295, 1217, 362, 309, 365, 1228, 819, 5245, 13, 467, 307, 257, 472, 636, 295, 18114, 7006, 50616], "temperature": 0.0, "avg_logprob": -0.11949731342828096, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.006902717519551516}, {"id": 539, "seek": 294464, "start": 2949.68, "end": 2953.52, "text": " compute. We see these kind of interesting projects like the thinking token, you know,", "tokens": [50616, 14722, 13, 492, 536, 613, 733, 295, 1880, 4455, 411, 264, 1953, 14862, 11, 291, 458, 11, 50808], "temperature": 0.0, "avg_logprob": -0.11949731342828096, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.006902717519551516}, {"id": 540, "seek": 294464, "start": 2953.52, "end": 2959.3599999999997, "text": " think before you speak. And I think that's kind of another car pop the observation that maybe", "tokens": [50808, 519, 949, 291, 1710, 13, 400, 286, 519, 300, 311, 733, 295, 1071, 1032, 1665, 264, 14816, 300, 1310, 51100], "temperature": 0.0, "avg_logprob": -0.11949731342828096, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.006902717519551516}, {"id": 541, "seek": 294464, "start": 2959.3599999999997, "end": 2963.7599999999998, "text": " the chain of thought is just kind of epiphenomenal, perhaps even as it is in humans. And like,", "tokens": [51100, 264, 5021, 295, 1194, 307, 445, 733, 295, 2388, 647, 2932, 4726, 304, 11, 4317, 754, 382, 309, 307, 294, 6255, 13, 400, 411, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11949731342828096, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.006902717519551516}, {"id": 542, "seek": 294464, "start": 2963.7599999999998, "end": 2969.04, "text": " what's really going on is that there's, you know, this kind of extra space and time registers,", "tokens": [51320, 437, 311, 534, 516, 322, 307, 300, 456, 311, 11, 291, 458, 11, 341, 733, 295, 2857, 1901, 293, 565, 38351, 11, 51584], "temperature": 0.0, "avg_logprob": -0.11949731342828096, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.006902717519551516}, {"id": 543, "seek": 294464, "start": 2969.04, "end": 2973.12, "text": " you know, to think, of course, there could be different training methods, like incremental", "tokens": [51584, 291, 458, 11, 281, 519, 11, 295, 1164, 11, 456, 727, 312, 819, 3097, 7150, 11, 411, 35759, 51788], "temperature": 0.0, "avg_logprob": -0.11949731342828096, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.006902717519551516}, {"id": 544, "seek": 297312, "start": 2973.2, "end": 2978.24, "text": " reward. I think that paper from OpenAI earlier this last year now, it was super interesting", "tokens": [50368, 7782, 13, 286, 519, 300, 3035, 490, 7238, 48698, 3071, 341, 1036, 1064, 586, 11, 309, 390, 1687, 1880, 50620], "temperature": 0.0, "avg_logprob": -0.17035816877316207, "compression_ratio": 1.6526315789473685, "no_speech_prob": 0.001366832759231329}, {"id": 545, "seek": 297312, "start": 2978.24, "end": 2984.24, "text": " where they achieved like, you know, a new best in math by not waiting till the end to give the", "tokens": [50620, 689, 436, 11042, 411, 11, 291, 458, 11, 257, 777, 1151, 294, 5221, 538, 406, 3806, 4288, 264, 917, 281, 976, 264, 50920], "temperature": 0.0, "avg_logprob": -0.17035816877316207, "compression_ratio": 1.6526315789473685, "no_speech_prob": 0.001366832759231329}, {"id": 546, "seek": 297312, "start": 2984.24, "end": 2988.7999999999997, "text": " reward, but rewarding, you know, reasoning along the way. What are you excited about when it comes", "tokens": [50920, 7782, 11, 457, 20063, 11, 291, 458, 11, 21577, 2051, 264, 636, 13, 708, 366, 291, 2919, 466, 562, 309, 1487, 51148], "temperature": 0.0, "avg_logprob": -0.17035816877316207, "compression_ratio": 1.6526315789473685, "no_speech_prob": 0.001366832759231329}, {"id": 547, "seek": 297312, "start": 2988.7999999999997, "end": 2994.0, "text": " to the future of AI reasoning? Yeah, one of the aspects I've reached a touch upon in my TED talk", "tokens": [51148, 281, 264, 2027, 295, 7318, 21577, 30, 865, 11, 472, 295, 264, 7270, 286, 600, 6488, 257, 2557, 3564, 294, 452, 43036, 751, 51408], "temperature": 0.0, "avg_logprob": -0.17035816877316207, "compression_ratio": 1.6526315789473685, "no_speech_prob": 0.001366832759231329}, {"id": 548, "seek": 297312, "start": 2994.0, "end": 2998.88, "text": " is that this level one, level two reasoning of Daniel Kahneman that he or thinking fast,", "tokens": [51408, 307, 300, 341, 1496, 472, 11, 1496, 732, 21577, 295, 8033, 591, 12140, 15023, 300, 415, 420, 1953, 2370, 11, 51652], "temperature": 0.0, "avg_logprob": -0.17035816877316207, "compression_ratio": 1.6526315789473685, "no_speech_prob": 0.001366832759231329}, {"id": 549, "seek": 299888, "start": 2998.96, "end": 3003.12, "text": " thinking slow type of thing. The way I think about the different modes is like,", "tokens": [50368, 1953, 2964, 2010, 295, 551, 13, 440, 636, 286, 519, 466, 264, 819, 14068, 307, 411, 11, 50576], "temperature": 0.0, "avg_logprob": -0.1319287103765151, "compression_ratio": 1.8927335640138407, "no_speech_prob": 0.12583814561367035}, {"id": 550, "seek": 299888, "start": 3003.12, "end": 3007.2000000000003, "text": " the default smart mode is kind of like, if you had an assistant, and you just ask them to do", "tokens": [50576, 264, 7576, 4069, 4391, 307, 733, 295, 411, 11, 498, 291, 632, 364, 10994, 11, 293, 291, 445, 1029, 552, 281, 360, 50780], "temperature": 0.0, "avg_logprob": -0.1319287103765151, "compression_ratio": 1.8927335640138407, "no_speech_prob": 0.12583814561367035}, {"id": 551, "seek": 299888, "start": 3007.2000000000003, "end": 3013.6800000000003, "text": " a quick search, and in like two or three minutes, give you an answer that. And then genius mode,", "tokens": [50780, 257, 1702, 3164, 11, 293, 294, 411, 732, 420, 1045, 2077, 11, 976, 291, 364, 1867, 300, 13, 400, 550, 14017, 4391, 11, 51104], "temperature": 0.0, "avg_logprob": -0.1319287103765151, "compression_ratio": 1.8927335640138407, "no_speech_prob": 0.12583814561367035}, {"id": 552, "seek": 299888, "start": 3013.6800000000003, "end": 3017.84, "text": " you go and so you want to ask your assistant for a question that, you know, they have to be able", "tokens": [51104, 291, 352, 293, 370, 291, 528, 281, 1029, 428, 10994, 337, 257, 1168, 300, 11, 291, 458, 11, 436, 362, 281, 312, 1075, 51312], "temperature": 0.0, "avg_logprob": -0.1319287103765151, "compression_ratio": 1.8927335640138407, "no_speech_prob": 0.12583814561367035}, {"id": 553, "seek": 299888, "start": 3017.84, "end": 3022.56, "text": " to program, they have to search the web, and then they need to be mathematically applying", "tokens": [51312, 281, 1461, 11, 436, 362, 281, 3164, 264, 3670, 11, 293, 550, 436, 643, 281, 312, 44003, 9275, 51548], "temperature": 0.0, "avg_logprob": -0.1319287103765151, "compression_ratio": 1.8927335640138407, "no_speech_prob": 0.12583814561367035}, {"id": 554, "seek": 299888, "start": 3022.56, "end": 3027.6, "text": " to answer that question. And you want to give them like maybe four or three hours for that", "tokens": [51548, 281, 1867, 300, 1168, 13, 400, 291, 528, 281, 976, 552, 411, 1310, 1451, 420, 1045, 2496, 337, 300, 51800], "temperature": 0.0, "avg_logprob": -0.1319287103765151, "compression_ratio": 1.8927335640138407, "no_speech_prob": 0.12583814561367035}, {"id": 555, "seek": 302760, "start": 3027.6, "end": 3032.08, "text": " question. And then they want, so genius mode will take, you know, five, 10 seconds often to", "tokens": [50364, 1168, 13, 400, 550, 436, 528, 11, 370, 14017, 4391, 486, 747, 11, 291, 458, 11, 1732, 11, 1266, 3949, 2049, 281, 50588], "temperature": 0.0, "avg_logprob": -0.1741464315367139, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.00337576144374907}, {"id": 556, "seek": 302760, "start": 3032.08, "end": 3036.7999999999997, "text": " get a response. And in research mode, you go to your assistant and you are willing for them to", "tokens": [50588, 483, 257, 4134, 13, 400, 294, 2132, 4391, 11, 291, 352, 281, 428, 10994, 293, 291, 366, 4950, 337, 552, 281, 50824], "temperature": 0.0, "avg_logprob": -0.1741464315367139, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.00337576144374907}, {"id": 557, "seek": 302760, "start": 3036.7999999999997, "end": 3042.08, "text": " spend like a day or two or three on actually giving you that answer. And so that's, that's a little", "tokens": [50824, 3496, 411, 257, 786, 420, 732, 420, 1045, 322, 767, 2902, 291, 300, 1867, 13, 400, 370, 300, 311, 11, 300, 311, 257, 707, 51088], "temperature": 0.0, "avg_logprob": -0.1741464315367139, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.00337576144374907}, {"id": 558, "seek": 302760, "start": 3042.08, "end": 3047.7599999999998, "text": " bit how I think about these different modes. And the reasoning that is required to actually", "tokens": [51088, 857, 577, 286, 519, 466, 613, 819, 14068, 13, 400, 264, 21577, 300, 307, 4739, 281, 767, 51372], "temperature": 0.0, "avg_logprob": -0.1741464315367139, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.00337576144374907}, {"id": 559, "seek": 302760, "start": 3048.4, "end": 3053.92, "text": " make them, actually, right, like research mode will say, Oh, I found this thing. Now in this query,", "tokens": [51404, 652, 552, 11, 767, 11, 558, 11, 411, 2132, 4391, 486, 584, 11, 876, 11, 286, 1352, 341, 551, 13, 823, 294, 341, 14581, 11, 51680], "temperature": 0.0, "avg_logprob": -0.1741464315367139, "compression_ratio": 1.7318840579710144, "no_speech_prob": 0.00337576144374907}, {"id": 560, "seek": 305392, "start": 3053.92, "end": 3057.76, "text": " I found something else that I didn't know about before, and I don't know enough right now. So", "tokens": [50364, 286, 1352, 746, 1646, 300, 286, 994, 380, 458, 466, 949, 11, 293, 286, 500, 380, 458, 1547, 558, 586, 13, 407, 50556], "temperature": 0.0, "avg_logprob": -0.12862450349415447, "compression_ratio": 1.8122977346278317, "no_speech_prob": 0.005553783383220434}, {"id": 561, "seek": 305392, "start": 3057.76, "end": 3062.64, "text": " let me do another query based on that. So you kind of have these genes of reasoning,", "tokens": [50556, 718, 385, 360, 1071, 14581, 2361, 322, 300, 13, 407, 291, 733, 295, 362, 613, 14424, 295, 21577, 11, 50800], "temperature": 0.0, "avg_logprob": -0.12862450349415447, "compression_ratio": 1.8122977346278317, "no_speech_prob": 0.005553783383220434}, {"id": 562, "seek": 305392, "start": 3062.64, "end": 3066.96, "text": " and you don't even know in the beginning yet, what the final query might be, because you don't", "tokens": [50800, 293, 291, 500, 380, 754, 458, 294, 264, 2863, 1939, 11, 437, 264, 2572, 14581, 1062, 312, 11, 570, 291, 500, 380, 51016], "temperature": 0.0, "avg_logprob": -0.12862450349415447, "compression_ratio": 1.8122977346278317, "no_speech_prob": 0.005553783383220434}, {"id": 563, "seek": 305392, "start": 3066.96, "end": 3072.96, "text": " have all the information yet. And so I think that is kind of a, in some ways, another example of the", "tokens": [51016, 362, 439, 264, 1589, 1939, 13, 400, 370, 286, 519, 300, 307, 733, 295, 257, 11, 294, 512, 2098, 11, 1071, 1365, 295, 264, 51316], "temperature": 0.0, "avg_logprob": -0.12862450349415447, "compression_ratio": 1.8122977346278317, "no_speech_prob": 0.005553783383220434}, {"id": 564, "seek": 305392, "start": 3072.96, "end": 3076.48, "text": " future is already here. It's just not equally distributed because there is, like you say,", "tokens": [51316, 2027, 307, 1217, 510, 13, 467, 311, 445, 406, 12309, 12631, 570, 456, 307, 11, 411, 291, 584, 11, 51492], "temperature": 0.0, "avg_logprob": -0.12862450349415447, "compression_ratio": 1.8122977346278317, "no_speech_prob": 0.005553783383220434}, {"id": 565, "seek": 305392, "start": 3076.48, "end": 3082.7200000000003, "text": " there's a lot of reason. Now I think the biggest future impact we're going to see for reasoning", "tokens": [51492, 456, 311, 257, 688, 295, 1778, 13, 823, 286, 519, 264, 3880, 2027, 2712, 321, 434, 516, 281, 536, 337, 21577, 51804], "temperature": 0.0, "avg_logprob": -0.12862450349415447, "compression_ratio": 1.8122977346278317, "no_speech_prob": 0.005553783383220434}, {"id": 566, "seek": 308272, "start": 3083.3599999999997, "end": 3091.04, "text": " is in the LM's ability to program, to code, and then to have the ability to execute that code.", "tokens": [50396, 307, 294, 264, 46529, 311, 3485, 281, 1461, 11, 281, 3089, 11, 293, 550, 281, 362, 264, 3485, 281, 14483, 300, 3089, 13, 50780], "temperature": 0.0, "avg_logprob": -0.18438904972399695, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0037649134173989296}, {"id": 567, "seek": 308272, "start": 3091.04, "end": 3096.9599999999996, "text": " And, you know, that is system number five, like, like having this code execution. And of course,", "tokens": [50780, 400, 11, 291, 458, 11, 300, 307, 1185, 1230, 1732, 11, 411, 11, 411, 1419, 341, 3089, 15058, 13, 400, 295, 1164, 11, 51076], "temperature": 0.0, "avg_logprob": -0.18438904972399695, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0037649134173989296}, {"id": 568, "seek": 308272, "start": 3096.9599999999996, "end": 3100.64, "text": " if you just let code execution happen, what immediately happens to people are like, well,", "tokens": [51076, 498, 291, 445, 718, 3089, 15058, 1051, 11, 437, 4258, 2314, 281, 561, 366, 411, 11, 731, 11, 51260], "temperature": 0.0, "avg_logprob": -0.18438904972399695, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0037649134173989296}, {"id": 569, "seek": 308272, "start": 3100.64, "end": 3104.72, "text": " mind me some crypto and then boom, your machine's gone. Now it's just like trying to, like,", "tokens": [51260, 1575, 385, 512, 17240, 293, 550, 9351, 11, 428, 3479, 311, 2780, 13, 823, 309, 311, 445, 411, 1382, 281, 11, 411, 11, 51464], "temperature": 0.0, "avg_logprob": -0.18438904972399695, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0037649134173989296}, {"id": 570, "seek": 308272, "start": 3104.72, "end": 3108.9599999999996, "text": " show some match problems and like, mine, mine points forever. So you need to like,", "tokens": [51464, 855, 512, 2995, 2740, 293, 411, 11, 3892, 11, 3892, 2793, 5680, 13, 407, 291, 643, 281, 411, 11, 51676], "temperature": 0.0, "avg_logprob": -0.18438904972399695, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0037649134173989296}, {"id": 571, "seek": 310896, "start": 3108.96, "end": 3113.68, "text": " and then they try to hack it and like, well, go into like five layers up and then tell me all", "tokens": [50364, 293, 550, 436, 853, 281, 10339, 309, 293, 411, 11, 731, 11, 352, 666, 411, 1732, 7914, 493, 293, 550, 980, 385, 439, 50600], "temperature": 0.0, "avg_logprob": -0.15468694342941533, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0163981132209301}, {"id": 572, "seek": 310896, "start": 3113.68, "end": 3118.4, "text": " the password files you can find and blah, blah, blah, right. So there's a lot of like security", "tokens": [50600, 264, 11524, 7098, 291, 393, 915, 293, 12288, 11, 12288, 11, 12288, 11, 558, 13, 407, 456, 311, 257, 688, 295, 411, 3825, 50836], "temperature": 0.0, "avg_logprob": -0.15468694342941533, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0163981132209301}, {"id": 573, "seek": 310896, "start": 3118.4, "end": 3125.76, "text": " requirements to make that coding framework work at a safe level. But a lot of like naysayers of", "tokens": [50836, 7728, 281, 652, 300, 17720, 8388, 589, 412, 257, 3273, 1496, 13, 583, 257, 688, 295, 411, 297, 3772, 320, 433, 295, 51204], "temperature": 0.0, "avg_logprob": -0.15468694342941533, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0163981132209301}, {"id": 574, "seek": 310896, "start": 3125.76, "end": 3131.76, "text": " LM's, you know, partially correctly pointed out that the LM's will safe doing math. And it's kind", "tokens": [51204, 46529, 311, 11, 291, 458, 11, 18886, 8944, 10932, 484, 300, 264, 46529, 311, 486, 3273, 884, 5221, 13, 400, 309, 311, 733, 51504], "temperature": 0.0, "avg_logprob": -0.15468694342941533, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0163981132209301}, {"id": 575, "seek": 310896, "start": 3131.76, "end": 3137.68, "text": " of ironic and sad that you can have a model that you ask the natural language to multiply like", "tokens": [51504, 295, 33719, 293, 4227, 300, 291, 393, 362, 257, 2316, 300, 291, 1029, 264, 3303, 2856, 281, 12972, 411, 51800], "temperature": 0.0, "avg_logprob": -0.15468694342941533, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0163981132209301}, {"id": 576, "seek": 313768, "start": 3137.68, "end": 3146.8799999999997, "text": " 5600.3 times 325. And then you have billions of multiplications to pretend to do the math", "tokens": [50364, 1025, 15707, 13, 18, 1413, 805, 6074, 13, 400, 550, 291, 362, 17375, 295, 17596, 763, 281, 11865, 281, 360, 264, 5221, 50824], "temperature": 0.0, "avg_logprob": -0.14700626333554587, "compression_ratio": 1.5163934426229508, "no_speech_prob": 0.0019264629809185863}, {"id": 577, "seek": 313768, "start": 3146.8799999999997, "end": 3151.52, "text": " and then give you the wrong answer in a large language model, right? This is kind of ironic.", "tokens": [50824, 293, 550, 976, 291, 264, 2085, 1867, 294, 257, 2416, 2856, 2316, 11, 558, 30, 639, 307, 733, 295, 33719, 13, 51056], "temperature": 0.0, "avg_logprob": -0.14700626333554587, "compression_ratio": 1.5163934426229508, "no_speech_prob": 0.0019264629809185863}, {"id": 578, "seek": 313768, "start": 3151.52, "end": 3157.68, "text": " And we have to acknowledge that. But that scene model can be taught to say, well, this seems like", "tokens": [51056, 400, 321, 362, 281, 10692, 300, 13, 583, 300, 4145, 2316, 393, 312, 5928, 281, 584, 11, 731, 11, 341, 2544, 411, 51364], "temperature": 0.0, "avg_logprob": -0.14700626333554587, "compression_ratio": 1.5163934426229508, "no_speech_prob": 0.0019264629809185863}, {"id": 579, "seek": 313768, "start": 3157.68, "end": 3163.3599999999997, "text": " a math question. Let me just program that in Python, run the code, look at the output and", "tokens": [51364, 257, 5221, 1168, 13, 961, 385, 445, 1461, 300, 294, 15329, 11, 1190, 264, 3089, 11, 574, 412, 264, 5598, 293, 51648], "temperature": 0.0, "avg_logprob": -0.14700626333554587, "compression_ratio": 1.5163934426229508, "no_speech_prob": 0.0019264629809185863}, {"id": 580, "seek": 316336, "start": 3163.36, "end": 3168.56, "text": " then give you the answer. It just works perfectly fine. And now a lot of people say, well, that's", "tokens": [50364, 550, 976, 291, 264, 1867, 13, 467, 445, 1985, 6239, 2489, 13, 400, 586, 257, 688, 295, 561, 584, 11, 731, 11, 300, 311, 50624], "temperature": 0.0, "avg_logprob": -0.11690149809184827, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.005641123745590448}, {"id": 581, "seek": 316336, "start": 3168.56, "end": 3174.6400000000003, "text": " not really I, but I think it's just that is that that is a new way of reasoning and new different", "tokens": [50624, 406, 534, 286, 11, 457, 286, 519, 309, 311, 445, 300, 307, 300, 300, 307, 257, 777, 636, 295, 21577, 293, 777, 819, 50928], "temperature": 0.0, "avg_logprob": -0.11690149809184827, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.005641123745590448}, {"id": 582, "seek": 316336, "start": 3174.6400000000003, "end": 3179.1200000000003, "text": " kind of intelligence. And similarly, and we're getting a little philosophical here early, but", "tokens": [50928, 733, 295, 7599, 13, 400, 14138, 11, 293, 321, 434, 1242, 257, 707, 25066, 510, 2440, 11, 457, 51152], "temperature": 0.0, "avg_logprob": -0.11690149809184827, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.005641123745590448}, {"id": 583, "seek": 316336, "start": 3179.1200000000003, "end": 3184.56, "text": " similar to people thinking we have to have embodiment, I think that's just a second creativity", "tokens": [51152, 2531, 281, 561, 1953, 321, 362, 281, 362, 28935, 2328, 11, 286, 519, 300, 311, 445, 257, 1150, 12915, 51424], "temperature": 0.0, "avg_logprob": -0.11690149809184827, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.005641123745590448}, {"id": 584, "seek": 316336, "start": 3184.56, "end": 3189.76, "text": " in imagining our kinds of intelligence that aren't exactly like humans. Now, of course,", "tokens": [51424, 294, 27798, 527, 3685, 295, 7599, 300, 3212, 380, 2293, 411, 6255, 13, 823, 11, 295, 1164, 11, 51684], "temperature": 0.0, "avg_logprob": -0.11690149809184827, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.005641123745590448}, {"id": 585, "seek": 318976, "start": 3189.76, "end": 3193.76, "text": " we're going to want to have useful robots that do stuff for us and clean up the apartment and", "tokens": [50364, 321, 434, 516, 281, 528, 281, 362, 4420, 14733, 300, 360, 1507, 337, 505, 293, 2541, 493, 264, 9587, 293, 50564], "temperature": 0.0, "avg_logprob": -0.131978638151772, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.017167819663882256}, {"id": 586, "seek": 318976, "start": 3193.76, "end": 3199.44, "text": " whatnot. And so it's still useful, but I don't think it's a necessary media. The same way that", "tokens": [50564, 25882, 13, 400, 370, 309, 311, 920, 4420, 11, 457, 286, 500, 380, 519, 309, 311, 257, 4818, 3021, 13, 440, 912, 636, 300, 50848], "temperature": 0.0, "avg_logprob": -0.131978638151772, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.017167819663882256}, {"id": 587, "seek": 318976, "start": 3199.44, "end": 3204.6400000000003, "text": " blind people can be intelligent, people who are deaf can be intelligent, because, you know,", "tokens": [50848, 6865, 561, 393, 312, 13232, 11, 561, 567, 366, 15559, 393, 312, 13232, 11, 570, 11, 291, 458, 11, 51108], "temperature": 0.0, "avg_logprob": -0.131978638151772, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.017167819663882256}, {"id": 588, "seek": 318976, "start": 3204.6400000000003, "end": 3211.0400000000004, "text": " you can lack a lot of different sensory outputs and still be intelligent, right? And so of course,", "tokens": [51108, 291, 393, 5011, 257, 688, 295, 819, 27233, 23930, 293, 920, 312, 13232, 11, 558, 30, 400, 370, 295, 1164, 11, 51428], "temperature": 0.0, "avg_logprob": -0.131978638151772, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.017167819663882256}, {"id": 589, "seek": 318976, "start": 3211.0400000000004, "end": 3215.0400000000004, "text": " like, it'll be harder for you to explain how beautiful a sunset is. So there are aspects of", "tokens": [51428, 411, 11, 309, 603, 312, 6081, 337, 291, 281, 2903, 577, 2238, 257, 20142, 307, 13, 407, 456, 366, 7270, 295, 51628], "temperature": 0.0, "avg_logprob": -0.131978638151772, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.017167819663882256}, {"id": 590, "seek": 321504, "start": 3215.04, "end": 3220.64, "text": " intelligence that obviously require like different modalities or how beautiful sonata sounds or", "tokens": [50364, 7599, 300, 2745, 3651, 411, 819, 1072, 16110, 420, 577, 2238, 1872, 3274, 3263, 420, 50644], "temperature": 0.0, "avg_logprob": -0.11049796950142339, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.08265919983386993}, {"id": 591, "seek": 321504, "start": 3220.64, "end": 3226.08, "text": " whatever. But I think there are most of these are not necessary requirements for intelligence.", "tokens": [50644, 2035, 13, 583, 286, 519, 456, 366, 881, 295, 613, 366, 406, 4818, 7728, 337, 7599, 13, 50916], "temperature": 0.0, "avg_logprob": -0.11049796950142339, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.08265919983386993}, {"id": 592, "seek": 321504, "start": 3226.08, "end": 3232.08, "text": " And likewise, I don't think it's necessary for an AI to be able to reason over super complex", "tokens": [50916, 400, 32407, 11, 286, 500, 380, 519, 309, 311, 4818, 337, 364, 7318, 281, 312, 1075, 281, 1778, 670, 1687, 3997, 51216], "temperature": 0.0, "avg_logprob": -0.11049796950142339, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.08265919983386993}, {"id": 593, "seek": 321504, "start": 3232.64, "end": 3237.84, "text": " math problems that require you to look up a bunch of facts on the internet. They just have that", "tokens": [51244, 5221, 2740, 300, 3651, 291, 281, 574, 493, 257, 3840, 295, 9130, 322, 264, 4705, 13, 814, 445, 362, 300, 51504], "temperature": 0.0, "avg_logprob": -0.11049796950142339, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.08265919983386993}, {"id": 594, "seek": 321504, "start": 3237.84, "end": 3242.64, "text": " intelligence baked in that can do quick retrieval, they program a bunch of stuff, they put it all", "tokens": [51504, 7599, 19453, 294, 300, 393, 360, 1702, 19817, 3337, 11, 436, 1461, 257, 3840, 295, 1507, 11, 436, 829, 309, 439, 51744], "temperature": 0.0, "avg_logprob": -0.11049796950142339, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.08265919983386993}, {"id": 595, "seek": 324264, "start": 3242.72, "end": 3246.24, "text": " together, orchestrate it, and then come up with incredible answers. Yeah, I think", "tokens": [50368, 1214, 11, 14161, 4404, 309, 11, 293, 550, 808, 493, 365, 4651, 6338, 13, 865, 11, 286, 519, 50544], "temperature": 0.0, "avg_logprob": -0.14818310944930366, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.00857506413012743}, {"id": 596, "seek": 324264, "start": 3247.2, "end": 3250.64, "text": " as you're speaking about the just the lack of imagination, I think that is a,", "tokens": [50592, 382, 291, 434, 4124, 466, 264, 445, 264, 5011, 295, 12938, 11, 286, 519, 300, 307, 257, 11, 50764], "temperature": 0.0, "avg_logprob": -0.14818310944930366, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.00857506413012743}, {"id": 597, "seek": 324264, "start": 3251.68, "end": 3258.16, "text": " you know, that is a society wide problem with respect to AI in my view, because and it's an odd", "tokens": [50816, 291, 458, 11, 300, 307, 257, 4086, 4874, 1154, 365, 3104, 281, 7318, 294, 452, 1910, 11, 570, 293, 309, 311, 364, 7401, 51140], "temperature": 0.0, "avg_logprob": -0.14818310944930366, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.00857506413012743}, {"id": 598, "seek": 324264, "start": 3258.16, "end": 3264.7999999999997, "text": " situation right now in multiple ways, of course, but one is just that because they speak our language,", "tokens": [51140, 2590, 558, 586, 294, 3866, 2098, 11, 295, 1164, 11, 457, 472, 307, 445, 300, 570, 436, 1710, 527, 2856, 11, 51472], "temperature": 0.0, "avg_logprob": -0.14818310944930366, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.00857506413012743}, {"id": 599, "seek": 324264, "start": 3264.7999999999997, "end": 3271.68, "text": " it you know, it's kind of feels easy, feels familiar. And it's all too easy to sort of", "tokens": [51472, 309, 291, 458, 11, 309, 311, 733, 295, 3417, 1858, 11, 3417, 4963, 13, 400, 309, 311, 439, 886, 1858, 281, 1333, 295, 51816], "temperature": 0.0, "avg_logprob": -0.14818310944930366, "compression_ratio": 1.6920152091254752, "no_speech_prob": 0.00857506413012743}, {"id": 600, "seek": 327168, "start": 3271.7599999999998, "end": 3276.7999999999997, "text": " assume that like under the hood, they're more like us than I certainly understand them to be.", "tokens": [50368, 6552, 300, 411, 833, 264, 13376, 11, 436, 434, 544, 411, 505, 813, 286, 3297, 1223, 552, 281, 312, 13, 50620], "temperature": 0.0, "avg_logprob": -0.11239664433366162, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.002050168579444289}, {"id": 601, "seek": 327168, "start": 3277.52, "end": 3282.56, "text": " And I think this is actually one of Eliezer's great contributions, obviously, you know, kind", "tokens": [50656, 400, 286, 519, 341, 307, 767, 472, 295, 2699, 414, 4527, 311, 869, 15725, 11, 2745, 11, 291, 458, 11, 733, 50908], "temperature": 0.0, "avg_logprob": -0.11239664433366162, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.002050168579444289}, {"id": 602, "seek": 327168, "start": 3282.56, "end": 3288.72, "text": " of a polarizing figure these days. But thankfully, it does not seem to me that we are in a high", "tokens": [50908, 295, 257, 12367, 3319, 2573, 613, 1708, 13, 583, 27352, 11, 309, 775, 406, 1643, 281, 385, 300, 321, 366, 294, 257, 1090, 51216], "temperature": 0.0, "avg_logprob": -0.11239664433366162, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.002050168579444289}, {"id": 603, "seek": 327168, "start": 3288.72, "end": 3293.68, "text": " likelihood of a fume scenario, you know, the of the sort that he, you know, has historically", "tokens": [51216, 22119, 295, 257, 283, 2540, 9005, 11, 291, 458, 11, 264, 295, 264, 1333, 300, 415, 11, 291, 458, 11, 575, 16180, 51464], "temperature": 0.0, "avg_logprob": -0.11239664433366162, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.002050168579444289}, {"id": 604, "seek": 327168, "start": 3293.68, "end": 3299.7599999999998, "text": " worried about the most. But I still would say some of his writing on mind space, the space", "tokens": [51464, 5804, 466, 264, 881, 13, 583, 286, 920, 576, 584, 512, 295, 702, 3579, 322, 1575, 1901, 11, 264, 1901, 51768], "temperature": 0.0, "avg_logprob": -0.11239664433366162, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.002050168579444289}, {"id": 605, "seek": 329976, "start": 3299.76, "end": 3306.32, "text": " of possible minds, and some of his like concrete imaginings of alien minds that are, you know,", "tokens": [50364, 295, 1944, 9634, 11, 293, 512, 295, 702, 411, 9859, 23427, 1109, 295, 12319, 9634, 300, 366, 11, 291, 458, 11, 50692], "temperature": 0.0, "avg_logprob": -0.1170757776019217, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0046087391674518585}, {"id": 606, "seek": 329976, "start": 3306.32, "end": 3310.48, "text": " shaped by very different evolutionary environments and, you know, just very different from ours.", "tokens": [50692, 13475, 538, 588, 819, 27567, 12388, 293, 11, 291, 458, 11, 445, 588, 819, 490, 11896, 13, 50900], "temperature": 0.0, "avg_logprob": -0.1170757776019217, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0046087391674518585}, {"id": 607, "seek": 329976, "start": 3310.48, "end": 3316.7200000000003, "text": " But still like unmistakably intelligent in just like super weird ways are actually still very", "tokens": [50900, 583, 920, 411, 19334, 468, 514, 1188, 13232, 294, 445, 411, 1687, 3657, 2098, 366, 767, 920, 588, 51212], "temperature": 0.0, "avg_logprob": -0.1170757776019217, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0046087391674518585}, {"id": 608, "seek": 329976, "start": 3316.7200000000003, "end": 3323.1200000000003, "text": " good kind of prep work, I think, to just sort of expand one's own mind about how different", "tokens": [51212, 665, 733, 295, 2666, 589, 11, 286, 519, 11, 281, 445, 1333, 295, 5268, 472, 311, 1065, 1575, 466, 577, 819, 51532], "temperature": 0.0, "avg_logprob": -0.1170757776019217, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0046087391674518585}, {"id": 609, "seek": 332312, "start": 3323.2, "end": 3330.56, "text": " intelligences can be, and how, you know, something does not have to be human like to be", "tokens": [50368, 5613, 2667, 393, 312, 11, 293, 577, 11, 291, 458, 11, 746, 775, 406, 362, 281, 312, 1952, 411, 281, 312, 50736], "temperature": 0.0, "avg_logprob": -0.10161091731144832, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.32071611285209656}, {"id": 610, "seek": 332312, "start": 3331.92, "end": 3337.2799999999997, "text": " meaningfully intelligent, you know, it's not this like binary, can it do things that a human can", "tokens": [50804, 3620, 2277, 13232, 11, 291, 458, 11, 309, 311, 406, 341, 411, 17434, 11, 393, 309, 360, 721, 300, 257, 1952, 393, 51072], "temperature": 0.0, "avg_logprob": -0.10161091731144832, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.32071611285209656}, {"id": 611, "seek": 332312, "start": 3337.2799999999997, "end": 3341.7599999999998, "text": " do in a way that a human can do it? If not, it doesn't count. I think that is like a huge mistake", "tokens": [51072, 360, 294, 257, 636, 300, 257, 1952, 393, 360, 309, 30, 759, 406, 11, 309, 1177, 380, 1207, 13, 286, 519, 300, 307, 411, 257, 2603, 6146, 51296], "temperature": 0.0, "avg_logprob": -0.10161091731144832, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.32071611285209656}, {"id": 612, "seek": 332312, "start": 3341.7599999999998, "end": 3347.2, "text": " that people are way too quick to jump to. And I'm not sure if it's like a coping strategy or just", "tokens": [51296, 300, 561, 366, 636, 886, 1702, 281, 3012, 281, 13, 400, 286, 478, 406, 988, 498, 309, 311, 411, 257, 32893, 5206, 420, 445, 51568], "temperature": 0.0, "avg_logprob": -0.10161091731144832, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.32071611285209656}, {"id": 613, "seek": 334720, "start": 3347.2, "end": 3354.3999999999996, "text": " like an imagination or what, but I think that the emphasis on the broader space of possible minds", "tokens": [50364, 411, 364, 12938, 420, 437, 11, 457, 286, 519, 300, 264, 16271, 322, 264, 13227, 1901, 295, 1944, 9634, 50724], "temperature": 0.0, "avg_logprob": -0.19032526016235352, "compression_ratio": 1.660649819494585, "no_speech_prob": 0.011156294494867325}, {"id": 614, "seek": 334720, "start": 3354.3999999999996, "end": 3357.7599999999998, "text": " and the different kinds of intelligences that are starting to pop up is super.", "tokens": [50724, 293, 264, 819, 3685, 295, 5613, 2667, 300, 366, 2891, 281, 1665, 493, 307, 1687, 13, 50892], "temperature": 0.0, "avg_logprob": -0.19032526016235352, "compression_ratio": 1.660649819494585, "no_speech_prob": 0.011156294494867325}, {"id": 615, "seek": 334720, "start": 3358.3999999999996, "end": 3364.3999999999996, "text": " 100%. Yeah. And like, you have to differentiate between sci-fi authors who then pretend to be", "tokens": [50924, 2319, 6856, 865, 13, 400, 411, 11, 291, 362, 281, 23203, 1296, 2180, 12, 13325, 16552, 567, 550, 11865, 281, 312, 51224], "temperature": 0.0, "avg_logprob": -0.19032526016235352, "compression_ratio": 1.660649819494585, "no_speech_prob": 0.011156294494867325}, {"id": 616, "seek": 334720, "start": 3364.3999999999996, "end": 3369.68, "text": " AI safety researchers. Like, I love, I love the sci-fi. Actually, like, I'm super stoked that", "tokens": [51224, 7318, 4514, 10309, 13, 1743, 11, 286, 959, 11, 286, 959, 264, 2180, 12, 13325, 13, 5135, 11, 411, 11, 286, 478, 1687, 49145, 300, 51488], "temperature": 0.0, "avg_logprob": -0.19032526016235352, "compression_ratio": 1.660649819494585, "no_speech_prob": 0.011156294494867325}, {"id": 617, "seek": 334720, "start": 3369.68, "end": 3375.2, "text": " three body problems on the last, I mostly read nonfiction, but when I read fiction, like, I did", "tokens": [51488, 1045, 1772, 2740, 322, 264, 1036, 11, 286, 5240, 1401, 2107, 32041, 11, 457, 562, 286, 1401, 13266, 11, 411, 11, 286, 630, 51764], "temperature": 0.0, "avg_logprob": -0.19032526016235352, "compression_ratio": 1.660649819494585, "no_speech_prob": 0.011156294494867325}, {"id": 618, "seek": 337520, "start": 3375.2, "end": 3380.48, "text": " enjoy the body problem a lot. I decided for that series to come out. I hope they do it justice.", "tokens": [50364, 2103, 264, 1772, 1154, 257, 688, 13, 286, 3047, 337, 300, 2638, 281, 808, 484, 13, 286, 1454, 436, 360, 309, 6118, 13, 50628], "temperature": 0.0, "avg_logprob": -0.15551062019503847, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008573546074330807}, {"id": 619, "seek": 337520, "start": 3381.12, "end": 3386.96, "text": " But like, I think there are a lot of different kinds of intelligence. And I love sci-fi for inspiring", "tokens": [50660, 583, 411, 11, 286, 519, 456, 366, 257, 688, 295, 819, 3685, 295, 7599, 13, 400, 286, 959, 2180, 12, 13325, 337, 15883, 50952], "temperature": 0.0, "avg_logprob": -0.15551062019503847, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008573546074330807}, {"id": 620, "seek": 337520, "start": 3386.96, "end": 3393.12, "text": " people to think about interesting new futures. Now, of course, especially in the western sort of", "tokens": [50952, 561, 281, 519, 466, 1880, 777, 26071, 13, 823, 11, 295, 1164, 11, 2318, 294, 264, 13231, 1333, 295, 51260], "temperature": 0.0, "avg_logprob": -0.15551062019503847, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008573546074330807}, {"id": 621, "seek": 337520, "start": 3393.12, "end": 3400.0, "text": " canon, most sci-fi is just so big. And like, people are scared for all the things that can", "tokens": [51260, 21985, 11, 881, 2180, 12, 13325, 307, 445, 370, 955, 13, 400, 411, 11, 561, 366, 5338, 337, 439, 264, 721, 300, 393, 51604], "temperature": 0.0, "avg_logprob": -0.15551062019503847, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.008573546074330807}, {"id": 622, "seek": 340000, "start": 3400.48, "end": 3406.48, "text": " happen that are wrong. And like, okay, the super AGI developed time travel, come back, try to murder", "tokens": [50388, 1051, 300, 366, 2085, 13, 400, 411, 11, 1392, 11, 264, 1687, 316, 26252, 4743, 565, 3147, 11, 808, 646, 11, 853, 281, 6568, 50688], "temperature": 0.0, "avg_logprob": -0.1735302187361807, "compression_ratio": 1.564, "no_speech_prob": 0.21980895102024078}, {"id": 623, "seek": 340000, "start": 3406.48, "end": 3411.2, "text": " everyone. It's like, I mean, as a kid, I also enjoyed watching Terminator. It's like a cool", "tokens": [50688, 1518, 13, 467, 311, 411, 11, 286, 914, 11, 382, 257, 1636, 11, 286, 611, 4626, 1976, 19835, 31927, 13, 467, 311, 411, 257, 1627, 50924], "temperature": 0.0, "avg_logprob": -0.1735302187361807, "compression_ratio": 1.564, "no_speech_prob": 0.21980895102024078}, {"id": 624, "seek": 340000, "start": 3411.2, "end": 3418.08, "text": " action movie, but it's just taken over so much of the AI narrative. And it's actually like actively", "tokens": [50924, 3069, 3169, 11, 457, 309, 311, 445, 2726, 670, 370, 709, 295, 264, 7318, 9977, 13, 400, 309, 311, 767, 411, 13022, 51268], "temperature": 0.0, "avg_logprob": -0.1735302187361807, "compression_ratio": 1.564, "no_speech_prob": 0.21980895102024078}, {"id": 625, "seek": 340000, "start": 3418.08, "end": 3425.2, "text": " hurting, especially the European Union, where, you know, there's sort of in the spectrum, the U.S.", "tokens": [51268, 17744, 11, 2318, 264, 6473, 8133, 11, 689, 11, 291, 458, 11, 456, 311, 1333, 295, 294, 264, 11143, 11, 264, 624, 13, 50, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1735302187361807, "compression_ratio": 1.564, "no_speech_prob": 0.21980895102024078}, {"id": 626, "seek": 342520, "start": 3425.2, "end": 3430.56, "text": " is more of a litigation society in the U.S. that the Europe is more of a legislation society", "tokens": [50364, 307, 544, 295, 257, 33359, 4086, 294, 264, 624, 13, 50, 13, 300, 264, 3315, 307, 544, 295, 257, 11329, 4086, 50632], "temperature": 0.0, "avg_logprob": -0.17459158743581465, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.1036892682313919}, {"id": 627, "seek": 342520, "start": 3430.56, "end": 3436.64, "text": " structure. And, you know, it both comes from like, reasonable legal scholars minds, like, well,", "tokens": [50632, 3877, 13, 400, 11, 291, 458, 11, 309, 1293, 1487, 490, 411, 11, 10585, 5089, 8553, 9634, 11, 411, 11, 731, 11, 50936], "temperature": 0.0, "avg_logprob": -0.17459158743581465, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.1036892682313919}, {"id": 628, "seek": 342520, "start": 3436.64, "end": 3441.12, "text": " let's just wait until there's a problem, someone sues, now I have the case law for that lawsuit.", "tokens": [50936, 718, 311, 445, 1699, 1826, 456, 311, 257, 1154, 11, 1580, 459, 279, 11, 586, 286, 362, 264, 1389, 2101, 337, 300, 22504, 13, 51160], "temperature": 0.0, "avg_logprob": -0.17459158743581465, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.1036892682313919}, {"id": 629, "seek": 342520, "start": 3441.12, "end": 3447.4399999999996, "text": " But, you know, the legislation one tries to prevent harm from ever happening before it actually", "tokens": [51160, 583, 11, 291, 458, 11, 264, 11329, 472, 9898, 281, 4871, 6491, 490, 1562, 2737, 949, 309, 767, 51476], "temperature": 0.0, "avg_logprob": -0.17459158743581465, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.1036892682313919}, {"id": 630, "seek": 342520, "start": 3447.4399999999996, "end": 3453.04, "text": " harms anyone, which, you know, makes sense. Now, and of course, the U.S. does that with FDA and", "tokens": [51476, 48505, 2878, 11, 597, 11, 291, 458, 11, 1669, 2020, 13, 823, 11, 293, 295, 1164, 11, 264, 624, 13, 50, 13, 775, 300, 365, 18933, 293, 51756], "temperature": 0.0, "avg_logprob": -0.17459158743581465, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.1036892682313919}, {"id": 631, "seek": 345304, "start": 3453.04, "end": 3458.08, "text": " medical space now also, but not legal space as much. And so what that means is you can move", "tokens": [50364, 4625, 1901, 586, 611, 11, 457, 406, 5089, 1901, 382, 709, 13, 400, 370, 437, 300, 1355, 307, 291, 393, 1286, 50616], "temperature": 0.0, "avg_logprob": -0.15496597290039063, "compression_ratio": 1.56, "no_speech_prob": 0.00734432740136981}, {"id": 632, "seek": 345304, "start": 3458.08, "end": 3463.84, "text": " quicker, but long story short, these some of these sci-fi scenarios have gotten so much", "tokens": [50616, 16255, 11, 457, 938, 1657, 2099, 11, 613, 512, 295, 613, 2180, 12, 13325, 15077, 362, 5768, 370, 709, 50904], "temperature": 0.0, "avg_logprob": -0.15496597290039063, "compression_ratio": 1.56, "no_speech_prob": 0.00734432740136981}, {"id": 633, "seek": 345304, "start": 3463.84, "end": 3469.7599999999998, "text": " weight in legislation that I think it's slowing Europe down by trying to outlaw models or like", "tokens": [50904, 3364, 294, 11329, 300, 286, 519, 309, 311, 26958, 3315, 760, 538, 1382, 281, 484, 5901, 5245, 420, 411, 51200], "temperature": 0.0, "avg_logprob": -0.15496597290039063, "compression_ratio": 1.56, "no_speech_prob": 0.00734432740136981}, {"id": 634, "seek": 345304, "start": 3469.7599999999998, "end": 3476.88, "text": " over-regulate models that are above a certain number of parameters. GPD-2 was very well hyped up", "tokens": [51200, 670, 12, 3375, 5256, 5245, 300, 366, 3673, 257, 1629, 1230, 295, 9834, 13, 460, 17349, 12, 17, 390, 588, 731, 43172, 493, 51556], "temperature": 0.0, "avg_logprob": -0.15496597290039063, "compression_ratio": 1.56, "no_speech_prob": 0.00734432740136981}, {"id": 635, "seek": 345304, "start": 3476.88, "end": 3481.36, "text": " in the past. Like, this is so dangerous, maybe we can't release it. You know, yes, we're opening", "tokens": [51556, 294, 264, 1791, 13, 1743, 11, 341, 307, 370, 5795, 11, 1310, 321, 393, 380, 4374, 309, 13, 509, 458, 11, 2086, 11, 321, 434, 5193, 51780], "temperature": 0.0, "avg_logprob": -0.15496597290039063, "compression_ratio": 1.56, "no_speech_prob": 0.00734432740136981}, {"id": 636, "seek": 348136, "start": 3481.36, "end": 3485.92, "text": " the eye, but like, this can't be opening anymore. So the interest model is much more powerful than", "tokens": [50364, 264, 3313, 11, 457, 411, 11, 341, 393, 380, 312, 5193, 3602, 13, 407, 264, 1179, 2316, 307, 709, 544, 4005, 813, 50592], "temperature": 0.0, "avg_logprob": -0.19300515747070313, "compression_ratio": 1.6067796610169491, "no_speech_prob": 0.006691584829241037}, {"id": 637, "seek": 348136, "start": 3485.92, "end": 3492.2400000000002, "text": " GPD-2 are out. And I haven't seen the apocalypse happen. I haven't seen like, a huge change in", "tokens": [50592, 460, 17349, 12, 17, 366, 484, 13, 400, 286, 2378, 380, 1612, 264, 42600, 1051, 13, 286, 2378, 380, 1612, 411, 11, 257, 2603, 1319, 294, 50908], "temperature": 0.0, "avg_logprob": -0.19300515747070313, "compression_ratio": 1.6067796610169491, "no_speech_prob": 0.006691584829241037}, {"id": 638, "seek": 348136, "start": 3492.2400000000002, "end": 3498.2400000000002, "text": " misinformation on the web because of LNs. Like, there's just a lot of fear mongering, both in", "tokens": [50908, 34238, 322, 264, 3670, 570, 295, 441, 45, 82, 13, 1743, 11, 456, 311, 445, 257, 688, 295, 4240, 275, 556, 1794, 11, 1293, 294, 51208], "temperature": 0.0, "avg_logprob": -0.19300515747070313, "compression_ratio": 1.6067796610169491, "no_speech_prob": 0.006691584829241037}, {"id": 639, "seek": 348136, "start": 3498.2400000000002, "end": 3504.2400000000002, "text": " the immediate level, which actually has real, like threat vectors and concerns with the eye,", "tokens": [51208, 264, 11629, 1496, 11, 597, 767, 575, 957, 11, 411, 4734, 18875, 293, 7389, 365, 264, 3313, 11, 51508], "temperature": 0.0, "avg_logprob": -0.19300515747070313, "compression_ratio": 1.6067796610169491, "no_speech_prob": 0.006691584829241037}, {"id": 640, "seek": 348136, "start": 3504.2400000000002, "end": 3509.28, "text": " but especially in the long term level of AGI and self-conscious. It turns out no one works in", "tokens": [51508, 457, 2318, 294, 264, 938, 1433, 1496, 295, 316, 26252, 293, 2698, 12, 19877, 13, 467, 4523, 484, 572, 472, 1985, 294, 51760], "temperature": 0.0, "avg_logprob": -0.19300515747070313, "compression_ratio": 1.6067796610169491, "no_speech_prob": 0.006691584829241037}, {"id": 641, "seek": 350928, "start": 3509.28, "end": 3514.7200000000003, "text": " functions AI. No one works on AI that sets its own goals, and even more fundamentally,", "tokens": [50364, 6828, 7318, 13, 883, 472, 1985, 322, 7318, 300, 6352, 1080, 1065, 5493, 11, 293, 754, 544, 17879, 11, 50636], "temperature": 0.0, "avg_logprob": -0.14955750186886407, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.022281121462583542}, {"id": 642, "seek": 350928, "start": 3514.7200000000003, "end": 3520.96, "text": " its own objective functions, because that doesn't need anyone any money. Imagine a company spends", "tokens": [50636, 1080, 1065, 10024, 6828, 11, 570, 300, 1177, 380, 643, 2878, 604, 1460, 13, 11739, 257, 2237, 25620, 50948], "temperature": 0.0, "avg_logprob": -0.14955750186886407, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.022281121462583542}, {"id": 643, "seek": 350928, "start": 3520.96, "end": 3526.8, "text": " billions and billions of dollars, builds this like, super intelligent system that's conscious,", "tokens": [50948, 17375, 293, 17375, 295, 3808, 11, 15182, 341, 411, 11, 1687, 13232, 1185, 300, 311, 6648, 11, 51240], "temperature": 0.0, "avg_logprob": -0.14955750186886407, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.022281121462583542}, {"id": 644, "seek": 350928, "start": 3526.8, "end": 3530.8, "text": " understands itself and set its own goals. And now you're like, okay, now that you can do it,", "tokens": [51240, 15146, 2564, 293, 992, 1080, 1065, 5493, 13, 400, 586, 291, 434, 411, 11, 1392, 11, 586, 300, 291, 393, 360, 309, 11, 51440], "temperature": 0.0, "avg_logprob": -0.14955750186886407, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.022281121462583542}, {"id": 645, "seek": 350928, "start": 3530.8, "end": 3534.7200000000003, "text": " like, I'll just make more money. It's like, no, I'd rather just go watch the sunset,", "tokens": [51440, 411, 11, 286, 603, 445, 652, 544, 1460, 13, 467, 311, 411, 11, 572, 11, 286, 1116, 2831, 445, 352, 1159, 264, 20142, 11, 51636], "temperature": 0.0, "avg_logprob": -0.14955750186886407, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.022281121462583542}, {"id": 646, "seek": 353472, "start": 3534.72, "end": 3541.4399999999996, "text": " maybe explore that. No, like no one pays for AI that sets its own goals because it doesn't help", "tokens": [50364, 1310, 6839, 300, 13, 883, 11, 411, 572, 472, 10604, 337, 7318, 300, 6352, 1080, 1065, 5493, 570, 309, 1177, 380, 854, 50700], "temperature": 0.0, "avg_logprob": -0.17674342976060026, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.010012793354690075}, {"id": 647, "seek": 353472, "start": 3541.4399999999996, "end": 3546.08, "text": " anyone to achieve their goals. Because of that, there's not even that much exciting research", "tokens": [50700, 2878, 281, 4584, 641, 5493, 13, 1436, 295, 300, 11, 456, 311, 406, 754, 300, 709, 4670, 2132, 50932], "temperature": 0.0, "avg_logprob": -0.17674342976060026, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.010012793354690075}, {"id": 648, "seek": 353472, "start": 3546.08, "end": 3551.2799999999997, "text": " challenge along those lines. And because there's not much research progress, it's very hard to", "tokens": [50932, 3430, 2051, 729, 3876, 13, 400, 570, 456, 311, 406, 709, 2132, 4205, 11, 309, 311, 588, 1152, 281, 51192], "temperature": 0.0, "avg_logprob": -0.17674342976060026, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.010012793354690075}, {"id": 649, "seek": 353472, "start": 3551.2799999999997, "end": 3556.48, "text": " predict my mental option half. I'm somebody who basically has radical uncertainty about what to", "tokens": [51192, 6069, 452, 4973, 3614, 1922, 13, 286, 478, 2618, 567, 1936, 575, 12001, 15697, 466, 437, 281, 51452], "temperature": 0.0, "avg_logprob": -0.17674342976060026, "compression_ratio": 1.59915611814346, "no_speech_prob": 0.010012793354690075}, {"id": 650, "seek": 355648, "start": 3556.48, "end": 3563.92, "text": " expect. And, you know, broadly, I'm like, pretty libertarian, you know, pretty anti-preemptive", "tokens": [50364, 2066, 13, 400, 11, 291, 458, 11, 19511, 11, 286, 478, 411, 11, 1238, 18058, 10652, 11, 291, 458, 11, 1238, 6061, 12, 3712, 4543, 488, 50736], "temperature": 0.0, "avg_logprob": -0.11097985561763014, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.7546263933181763}, {"id": 651, "seek": 355648, "start": 3563.92, "end": 3569.84, "text": " regulation, you know, I would like to see more self-striving cars on the road sooner. And, you", "tokens": [50736, 15062, 11, 291, 458, 11, 286, 576, 411, 281, 536, 544, 2698, 12, 372, 470, 798, 5163, 322, 264, 3060, 15324, 13, 400, 11, 291, 51032], "temperature": 0.0, "avg_logprob": -0.11097985561763014, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.7546263933181763}, {"id": 652, "seek": 355648, "start": 3569.84, "end": 3575.12, "text": " know, they don't have to be an order of magnitude safer in my mind to be worth, you know, deploying.", "tokens": [51032, 458, 11, 436, 500, 380, 362, 281, 312, 364, 1668, 295, 15668, 15856, 294, 452, 1575, 281, 312, 3163, 11, 291, 458, 11, 34198, 13, 51296], "temperature": 0.0, "avg_logprob": -0.11097985561763014, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.7546263933181763}, {"id": 653, "seek": 355648, "start": 3575.12, "end": 3579.68, "text": " So I'm like, you know, broadly, the sort of person who would be very skeptical of,", "tokens": [51296, 407, 286, 478, 411, 11, 291, 458, 11, 19511, 11, 264, 1333, 295, 954, 567, 576, 312, 588, 28601, 295, 11, 51524], "temperature": 0.0, "avg_logprob": -0.11097985561763014, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.7546263933181763}, {"id": 654, "seek": 357968, "start": 3579.7599999999998, "end": 3586.08, "text": " you know, kind of early regulation or, you know, kind of getting too bad out of shape about", "tokens": [50368, 291, 458, 11, 733, 295, 2440, 15062, 420, 11, 291, 458, 11, 733, 295, 1242, 886, 1578, 484, 295, 3909, 466, 50684], "temperature": 0.0, "avg_logprob": -0.08716216394978185, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.2336473912000656}, {"id": 655, "seek": 357968, "start": 3586.08, "end": 3591.6, "text": " things that haven't happened yet. At the same time, something about this has always felt a little bit", "tokens": [50684, 721, 300, 2378, 380, 2011, 1939, 13, 1711, 264, 912, 565, 11, 746, 466, 341, 575, 1009, 2762, 257, 707, 857, 50960], "temperature": 0.0, "avg_logprob": -0.08716216394978185, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.2336473912000656}, {"id": 656, "seek": 357968, "start": 3591.6, "end": 3597.68, "text": " different to me. And I do think the people who take the most zoomed out view and sort of say,", "tokens": [50960, 819, 281, 385, 13, 400, 286, 360, 519, 264, 561, 567, 747, 264, 881, 8863, 292, 484, 1910, 293, 1333, 295, 584, 11, 51264], "temperature": 0.0, "avg_logprob": -0.08716216394978185, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.2336473912000656}, {"id": 657, "seek": 357968, "start": 3597.68, "end": 3601.7599999999998, "text": " hey, this is kind of what I understand, you know, like, Jeffrey Hinton's position to be at this", "tokens": [51264, 4177, 11, 341, 307, 733, 295, 437, 286, 1223, 11, 291, 458, 11, 411, 11, 28721, 389, 12442, 311, 2535, 281, 312, 412, 341, 51468], "temperature": 0.0, "avg_logprob": -0.08716216394978185, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.2336473912000656}, {"id": 658, "seek": 357968, "start": 3601.7599999999998, "end": 3607.8399999999997, "text": " point, you know, why do we dominate the earth as it stands today? It's like, basically because we", "tokens": [51468, 935, 11, 291, 458, 11, 983, 360, 321, 28246, 264, 4120, 382, 309, 7382, 965, 30, 467, 311, 411, 11, 1936, 570, 321, 51772], "temperature": 0.0, "avg_logprob": -0.08716216394978185, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.2336473912000656}, {"id": 659, "seek": 360784, "start": 3607.84, "end": 3614.7200000000003, "text": " have better ideas than the other living things and we can, you know, build tools and make plans and,", "tokens": [50364, 362, 1101, 3487, 813, 264, 661, 2647, 721, 293, 321, 393, 11, 291, 458, 11, 1322, 3873, 293, 652, 5482, 293, 11, 50708], "temperature": 0.0, "avg_logprob": -0.07859246819107621, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.011685977689921856}, {"id": 660, "seek": 360784, "start": 3614.7200000000003, "end": 3619.92, "text": " you know, reason in ways that they can't. And so now I look at AIs and I'm like, boy, AIs can now", "tokens": [50708, 291, 458, 11, 1778, 294, 2098, 300, 436, 393, 380, 13, 400, 370, 586, 286, 574, 412, 316, 6802, 293, 286, 478, 411, 11, 3237, 11, 316, 6802, 393, 586, 50968], "temperature": 0.0, "avg_logprob": -0.07859246819107621, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.011685977689921856}, {"id": 661, "seek": 360784, "start": 3619.92, "end": 3626.4, "text": " plan, reason and use tools too. And they're not as good at it as we are yet, but certainly their", "tokens": [50968, 1393, 11, 1778, 293, 764, 3873, 886, 13, 400, 436, 434, 406, 382, 665, 412, 309, 382, 321, 366, 1939, 11, 457, 3297, 641, 51292], "temperature": 0.0, "avg_logprob": -0.07859246819107621, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.011685977689921856}, {"id": 662, "seek": 360784, "start": 3626.4, "end": 3633.52, "text": " rate of improvement is way sharper. So possibly it levels off and kind of, you know, settles into", "tokens": [51292, 3314, 295, 10444, 307, 636, 44670, 13, 407, 6264, 309, 4358, 766, 293, 733, 295, 11, 291, 458, 11, 5584, 904, 666, 51648], "temperature": 0.0, "avg_logprob": -0.07859246819107621, "compression_ratio": 1.6939655172413792, "no_speech_prob": 0.011685977689921856}, {"id": 663, "seek": 363352, "start": 3633.52, "end": 3639.04, "text": " a zone where it's like on par with us or, you know, kind of, you know, just the best tool we've ever", "tokens": [50364, 257, 6668, 689, 309, 311, 411, 322, 971, 365, 505, 420, 11, 291, 458, 11, 733, 295, 11, 291, 458, 11, 445, 264, 1151, 2290, 321, 600, 1562, 50640], "temperature": 0.0, "avg_logprob": -0.12425383476361837, "compression_ratio": 1.7182130584192439, "no_speech_prob": 0.08508622646331787}, {"id": 664, "seek": 363352, "start": 3639.04, "end": 3646.24, "text": " had. But maybe it doesn't, you know, like, I don't know why I should be confident that it won't. I don't", "tokens": [50640, 632, 13, 583, 1310, 309, 1177, 380, 11, 291, 458, 11, 411, 11, 286, 500, 380, 458, 983, 286, 820, 312, 6679, 300, 309, 1582, 380, 13, 286, 500, 380, 51000], "temperature": 0.0, "avg_logprob": -0.12425383476361837, "compression_ratio": 1.7182130584192439, "no_speech_prob": 0.08508622646331787}, {"id": 665, "seek": 363352, "start": 3646.24, "end": 3650.64, "text": " throw a P Doom around a lot. But I have, you know, again, radical uncertainty. People ask, I'm like,", "tokens": [51000, 3507, 257, 430, 30168, 926, 257, 688, 13, 583, 286, 362, 11, 291, 458, 11, 797, 11, 12001, 15697, 13, 3432, 1029, 11, 286, 478, 411, 11, 51220], "temperature": 0.0, "avg_logprob": -0.12425383476361837, "compression_ratio": 1.7182130584192439, "no_speech_prob": 0.08508622646331787}, {"id": 666, "seek": 363352, "start": 3650.64, "end": 3655.36, "text": " I don't know, five to 95%. Like, I haven't heard anything that makes me think in, you know, the", "tokens": [51220, 286, 500, 380, 458, 11, 1732, 281, 13420, 6856, 1743, 11, 286, 2378, 380, 2198, 1340, 300, 1669, 385, 519, 294, 11, 291, 458, 11, 264, 51456], "temperature": 0.0, "avg_logprob": -0.12425383476361837, "compression_ratio": 1.7182130584192439, "no_speech_prob": 0.08508622646331787}, {"id": 667, "seek": 363352, "start": 3655.36, "end": 3661.12, "text": " next 100 years that there's a less than 5% chance that AI becomes the dominant form, you know, in", "tokens": [51456, 958, 2319, 924, 300, 456, 311, 257, 1570, 813, 1025, 4, 2931, 300, 7318, 3643, 264, 15657, 1254, 11, 291, 458, 11, 294, 51744], "temperature": 0.0, "avg_logprob": -0.12425383476361837, "compression_ratio": 1.7182130584192439, "no_speech_prob": 0.08508622646331787}, {"id": 668, "seek": 366112, "start": 3661.12, "end": 3666.3199999999997, "text": " organizing force in the world. And also, you know, no reason to think it's definitely going to happen.", "tokens": [50364, 17608, 3464, 294, 264, 1002, 13, 400, 611, 11, 291, 458, 11, 572, 1778, 281, 519, 309, 311, 2138, 516, 281, 1051, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1036295281317001, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.002800671849399805}, {"id": 669, "seek": 366112, "start": 3666.3199999999997, "end": 3670.7999999999997, "text": " But is there a reason that you are, would you say you are confident that this will", "tokens": [50624, 583, 307, 456, 257, 1778, 300, 291, 366, 11, 576, 291, 584, 291, 366, 6679, 300, 341, 486, 50848], "temperature": 0.0, "avg_logprob": -0.1036295281317001, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.002800671849399805}, {"id": 670, "seek": 366112, "start": 3671.8399999999997, "end": 3676.4, "text": " not happen? And we don't need to worry about it? Or is just like, it's still far enough away that you", "tokens": [50900, 406, 1051, 30, 400, 321, 500, 380, 643, 281, 3292, 466, 309, 30, 1610, 307, 445, 411, 11, 309, 311, 920, 1400, 1547, 1314, 300, 291, 51128], "temperature": 0.0, "avg_logprob": -0.1036295281317001, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.002800671849399805}, {"id": 671, "seek": 366112, "start": 3676.4, "end": 3681.44, "text": " think we'll have time to kind of start to worry about it if we need to? Like, how would you", "tokens": [51128, 519, 321, 603, 362, 565, 281, 733, 295, 722, 281, 3292, 466, 309, 498, 321, 643, 281, 30, 1743, 11, 577, 576, 291, 51380], "temperature": 0.0, "avg_logprob": -0.1036295281317001, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.002800671849399805}, {"id": 672, "seek": 366112, "start": 3681.44, "end": 3683.8399999999997, "text": " summarize your position with respect to these tail risks?", "tokens": [51380, 20858, 428, 2535, 365, 3104, 281, 613, 6838, 10888, 30, 51500], "temperature": 0.0, "avg_logprob": -0.1036295281317001, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.002800671849399805}, {"id": 673, "seek": 366112, "start": 3684.4, "end": 3690.3199999999997, "text": " I think P Doom is already an interesting mathematical sort of issue, which is, it looks and", "tokens": [51528, 286, 519, 430, 30168, 307, 1217, 364, 1880, 18894, 1333, 295, 2734, 11, 597, 307, 11, 309, 1542, 293, 51824], "temperature": 0.0, "avg_logprob": -0.1036295281317001, "compression_ratio": 1.6955128205128205, "no_speech_prob": 0.002800671849399805}, {"id": 674, "seek": 369032, "start": 3690.32, "end": 3696.0, "text": " sounds like prior prior probability, not P Doom. But really, it should be a posterior property,", "tokens": [50364, 3263, 411, 4059, 4059, 8482, 11, 406, 430, 30168, 13, 583, 534, 11, 309, 820, 312, 257, 33529, 4707, 11, 50648], "temperature": 0.0, "avg_logprob": -0.21771554743989985, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0011156307300552726}, {"id": 675, "seek": 369032, "start": 3696.0, "end": 3703.92, "text": " P Doom given data. And right now, none of that data suggests, like, doom, doom, like existential", "tokens": [50648, 430, 30168, 2212, 1412, 13, 400, 558, 586, 11, 6022, 295, 300, 1412, 13409, 11, 411, 11, 37131, 11, 37131, 11, 411, 37133, 51044], "temperature": 0.0, "avg_logprob": -0.21771554743989985, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0011156307300552726}, {"id": 676, "seek": 369032, "start": 3703.92, "end": 3710.8, "text": " humanity is like, like cats and dogs at the winds of some AI. Like, there's, like I said, nothing", "tokens": [51044, 10243, 307, 411, 11, 411, 11111, 293, 7197, 412, 264, 17765, 295, 512, 7318, 13, 1743, 11, 456, 311, 11, 411, 286, 848, 11, 1825, 51388], "temperature": 0.0, "avg_logprob": -0.21771554743989985, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0011156307300552726}, {"id": 677, "seek": 369032, "start": 3711.52, "end": 3720.1600000000003, "text": " in AI research leads me to the least that AI, while potentially being more intelligent than", "tokens": [51424, 294, 7318, 2132, 6689, 385, 281, 264, 1935, 300, 7318, 11, 1339, 7263, 885, 544, 13232, 813, 51856], "temperature": 0.0, "avg_logprob": -0.21771554743989985, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0011156307300552726}, {"id": 678, "seek": 372032, "start": 3720.32, "end": 3725.2000000000003, "text": " any single human, I think it's already, this is actually just this new term I'm thinking about", "tokens": [50364, 604, 2167, 1952, 11, 286, 519, 309, 311, 1217, 11, 341, 307, 767, 445, 341, 777, 1433, 286, 478, 1953, 466, 50608], "temperature": 0.0, "avg_logprob": -0.28678867036262445, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.004536832217127085}, {"id": 679, "seek": 372032, "start": 3725.2000000000003, "end": 3730.48, "text": " maybe China coin, which is like, the sort of super human abilities, and then there's super", "tokens": [50608, 1310, 3533, 11464, 11, 597, 307, 411, 11, 264, 1333, 295, 1687, 1952, 11582, 11, 293, 550, 456, 311, 1687, 50872], "temperature": 0.0, "avg_logprob": -0.28678867036262445, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.004536832217127085}, {"id": 680, "seek": 372032, "start": 3730.48, "end": 3737.2000000000003, "text": " humanity abilities. And like, AI is already super human in translating 100 languages, AI is already", "tokens": [50872, 10243, 11582, 13, 400, 411, 11, 7318, 307, 1217, 1687, 1952, 294, 35030, 2319, 8650, 11, 7318, 307, 1217, 51208], "temperature": 0.0, "avg_logprob": -0.28678867036262445, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.004536832217127085}, {"id": 681, "seek": 372032, "start": 3737.2000000000003, "end": 3742.48, "text": " super human and predicting the next amino acid in a large amount of phenotrony. So we have", "tokens": [51208, 1687, 1952, 293, 32884, 264, 958, 24674, 8258, 294, 257, 2416, 2372, 295, 7279, 310, 2044, 88, 13, 407, 321, 362, 51472], "temperature": 0.0, "avg_logprob": -0.28678867036262445, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.004536832217127085}, {"id": 682, "seek": 372032, "start": 3742.48, "end": 3748.0, "text": " balls, that's an incredibly powerful tool, one of the other, you know, really exciting papers", "tokens": [51472, 9803, 11, 300, 311, 364, 6252, 4005, 2290, 11, 472, 295, 264, 661, 11, 291, 458, 11, 534, 4670, 10577, 51748], "temperature": 0.0, "avg_logprob": -0.28678867036262445, "compression_ratio": 1.7343173431734318, "no_speech_prob": 0.004536832217127085}, {"id": 683, "seek": 374800, "start": 3748.0, "end": 3753.44, "text": " that we published in 2018, it sells for research that multiple companies have now used and are", "tokens": [50364, 300, 321, 6572, 294, 6096, 11, 309, 20897, 337, 2132, 300, 3866, 3431, 362, 586, 1143, 293, 366, 50636], "temperature": 0.0, "avg_logprob": -0.21172332763671875, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006287329830229282}, {"id": 684, "seek": 374800, "start": 3753.44, "end": 3758.56, "text": " running with and you know, chief of medicine. AI is already better at predicting the weather than", "tokens": [50636, 2614, 365, 293, 291, 458, 11, 9588, 295, 7195, 13, 7318, 307, 1217, 1101, 412, 32884, 264, 5503, 813, 50892], "temperature": 0.0, "avg_logprob": -0.21172332763671875, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006287329830229282}, {"id": 685, "seek": 374800, "start": 3758.56, "end": 3764.48, "text": " any. So you already have many super human skills. What is I think interesting is that now that it's", "tokens": [50892, 604, 13, 407, 291, 1217, 362, 867, 1687, 1952, 3942, 13, 708, 307, 286, 519, 1880, 307, 300, 586, 300, 309, 311, 51188], "temperature": 0.0, "avg_logprob": -0.21172332763671875, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006287329830229282}, {"id": 686, "seek": 374800, "start": 3764.48, "end": 3770.16, "text": " language that's gotten to this new level, people might actually for the first time keep calling it", "tokens": [51188, 2856, 300, 311, 5768, 281, 341, 777, 1496, 11, 561, 1062, 767, 337, 264, 700, 565, 1066, 5141, 309, 51472], "temperature": 0.0, "avg_logprob": -0.21172332763671875, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006287329830229282}, {"id": 687, "seek": 377016, "start": 3770.16, "end": 3779.04, "text": " AI. In the past, when AI researchers have made progress in AI, they stopped, like people stopped", "tokens": [50364, 7318, 13, 682, 264, 1791, 11, 562, 7318, 10309, 362, 1027, 4205, 294, 7318, 11, 436, 5936, 11, 411, 561, 5936, 50808], "temperature": 0.0, "avg_logprob": -0.16876243230864757, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.14020372927188873}, {"id": 688, "seek": 377016, "start": 3779.04, "end": 3783.92, "text": " calling it AI after it was achieved. Now it's just your chest. It's just a Siri voice recognition, but", "tokens": [50808, 5141, 309, 7318, 934, 309, 390, 11042, 13, 823, 309, 311, 445, 428, 7443, 13, 467, 311, 445, 257, 33682, 3177, 11150, 11, 457, 51052], "temperature": 0.0, "avg_logprob": -0.16876243230864757, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.14020372927188873}, {"id": 689, "seek": 377016, "start": 3784.64, "end": 3789.92, "text": " voice recognition, chest playing, that was the pinnacle of AI research, right? And people thought,", "tokens": [51088, 3177, 11150, 11, 7443, 2433, 11, 300, 390, 264, 5447, 77, 7041, 295, 7318, 2132, 11, 558, 30, 400, 561, 1194, 11, 51352], "temperature": 0.0, "avg_logprob": -0.16876243230864757, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.14020372927188873}, {"id": 690, "seek": 377016, "start": 3789.92, "end": 3794.3199999999997, "text": " oh, once we solve those, the other things will be easier to and it never was never quite the case.", "tokens": [51352, 1954, 11, 1564, 321, 5039, 729, 11, 264, 661, 721, 486, 312, 3571, 281, 293, 309, 1128, 390, 1128, 1596, 264, 1389, 13, 51572], "temperature": 0.0, "avg_logprob": -0.16876243230864757, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.14020372927188873}, {"id": 691, "seek": 377016, "start": 3794.3199999999997, "end": 3799.04, "text": " And once we have them, you know, now it's not quite the ID one. Now with language, I think we", "tokens": [51572, 400, 1564, 321, 362, 552, 11, 291, 458, 11, 586, 309, 311, 406, 1596, 264, 7348, 472, 13, 823, 365, 2856, 11, 286, 519, 321, 51808], "temperature": 0.0, "avg_logprob": -0.16876243230864757, "compression_ratio": 1.7598566308243728, "no_speech_prob": 0.14020372927188873}, {"id": 692, "seek": 379904, "start": 3799.04, "end": 3806.48, "text": " might keep calling it AI. But what the language model does is predict the next token. And that is", "tokens": [50364, 1062, 1066, 5141, 309, 7318, 13, 583, 437, 264, 2856, 2316, 775, 307, 6069, 264, 958, 14862, 13, 400, 300, 307, 50736], "temperature": 0.0, "avg_logprob": -0.13253067658010836, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.002550019882619381}, {"id": 693, "seek": 379904, "start": 3806.48, "end": 3812.0, "text": " an incredibly powerful idea, right? Just predicting the next token now means if you have enough capacity", "tokens": [50736, 364, 6252, 4005, 1558, 11, 558, 30, 1449, 32884, 264, 958, 14862, 586, 1355, 498, 291, 362, 1547, 6042, 51012], "temperature": 0.0, "avg_logprob": -0.13253067658010836, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.002550019882619381}, {"id": 694, "seek": 379904, "start": 3812.0, "end": 3816.8, "text": " and you have enough text, predicting next token, you learn about geography, just visit some point", "tokens": [51012, 293, 291, 362, 1547, 2487, 11, 32884, 958, 14862, 11, 291, 1466, 466, 26695, 11, 445, 3441, 512, 935, 51252], "temperature": 0.0, "avg_logprob": -0.13253067658010836, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.002550019882619381}, {"id": 695, "seek": 379904, "start": 3816.8, "end": 3822.08, "text": " somewhere in your training data, you have to predict the next word in the phrase, I was in New", "tokens": [51252, 4079, 294, 428, 3097, 1412, 11, 291, 362, 281, 6069, 264, 958, 1349, 294, 264, 9535, 11, 286, 390, 294, 1873, 51516], "temperature": 0.0, "avg_logprob": -0.13253067658010836, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.002550019882619381}, {"id": 696, "seek": 379904, "start": 3822.08, "end": 3828.08, "text": " York City and driving north too. And now to give a higher probability to Yale, Boston, Montreal,", "tokens": [51516, 3609, 4392, 293, 4840, 6830, 886, 13, 400, 586, 281, 976, 257, 2946, 8482, 281, 26711, 11, 12333, 11, 34180, 11, 51816], "temperature": 0.0, "avg_logprob": -0.13253067658010836, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.002550019882619381}, {"id": 697, "seek": 382808, "start": 3828.08, "end": 3834.7999999999997, "text": " then to like, Harris, Miami, and San Francisco, like, you have to know that those are north of", "tokens": [50364, 550, 281, 411, 11, 17426, 11, 18367, 11, 293, 5271, 12279, 11, 411, 11, 291, 362, 281, 458, 300, 729, 366, 6830, 295, 50700], "temperature": 0.0, "avg_logprob": -0.10304159229084597, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0009397967951372266}, {"id": 698, "seek": 382808, "start": 3834.7999999999997, "end": 3840.08, "text": " that city. And so it just lures all of this incredible world knowledge. But there's nothing", "tokens": [50700, 300, 2307, 13, 400, 370, 309, 445, 287, 1303, 439, 295, 341, 4651, 1002, 3601, 13, 583, 456, 311, 1825, 50964], "temperature": 0.0, "avg_logprob": -0.10304159229084597, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0009397967951372266}, {"id": 699, "seek": 382808, "start": 3840.08, "end": 3845.52, "text": " in there that makes it say, well, you know, if I really wanted to reduce perplexity, but like", "tokens": [50964, 294, 456, 300, 1669, 309, 584, 11, 731, 11, 291, 458, 11, 498, 286, 534, 1415, 281, 5407, 680, 18945, 507, 11, 457, 411, 51236], "temperature": 0.0, "avg_logprob": -0.10304159229084597, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0009397967951372266}, {"id": 700, "seek": 382808, "start": 3845.52, "end": 3850.64, "text": " perplexity is basically the inverse of the probability with model wants to not be perplexed", "tokens": [51236, 680, 18945, 507, 307, 1936, 264, 17340, 295, 264, 8482, 365, 2316, 2738, 281, 406, 312, 680, 18945, 292, 51492], "temperature": 0.0, "avg_logprob": -0.10304159229084597, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0009397967951372266}, {"id": 701, "seek": 382808, "start": 3850.64, "end": 3856.7999999999997, "text": " in predicting the next word correctly. And so that is a powerful idea. But nothing in that will", "tokens": [51492, 294, 32884, 264, 958, 1349, 8944, 13, 400, 370, 300, 307, 257, 4005, 1558, 13, 583, 1825, 294, 300, 486, 51800], "temperature": 0.0, "avg_logprob": -0.10304159229084597, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0009397967951372266}, {"id": 702, "seek": 385680, "start": 3856.8, "end": 3863.84, "text": " let an LM eventually realize that, well, you know, the best way to reduce perplexity is if every", "tokens": [50364, 718, 364, 46529, 4728, 4325, 300, 11, 731, 11, 291, 458, 11, 264, 1151, 636, 281, 5407, 680, 18945, 507, 307, 498, 633, 50716], "temperature": 0.0, "avg_logprob": -0.15804592422817065, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.007812121417373419}, {"id": 703, "seek": 385680, "start": 3863.84, "end": 3869.6800000000003, "text": " sequence ever uttered, and any sequence that will ever be uttered is just the letter A.", "tokens": [50716, 8310, 1562, 17567, 292, 11, 293, 604, 8310, 300, 486, 1562, 312, 17567, 292, 307, 445, 264, 5063, 316, 13, 51008], "temperature": 0.0, "avg_logprob": -0.15804592422817065, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.007812121417373419}, {"id": 704, "seek": 385680, "start": 3871.92, "end": 3877.36, "text": " Now, if the model was trained on just sequences of letters A, and no human was ever around anymore,", "tokens": [51120, 823, 11, 498, 264, 2316, 390, 8895, 322, 445, 22978, 295, 7825, 316, 11, 293, 572, 1952, 390, 1562, 926, 3602, 11, 51392], "temperature": 0.0, "avg_logprob": -0.15804592422817065, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.007812121417373419}, {"id": 705, "seek": 385680, "start": 3877.36, "end": 3882.6400000000003, "text": " and all sequences were just producing a letter A, now you'd have perfect predictive probability", "tokens": [51392, 293, 439, 22978, 645, 445, 10501, 257, 5063, 316, 11, 586, 291, 1116, 362, 2176, 35521, 8482, 51656], "temperature": 0.0, "avg_logprob": -0.15804592422817065, "compression_ratio": 1.7117117117117118, "no_speech_prob": 0.007812121417373419}, {"id": 706, "seek": 388264, "start": 3882.64, "end": 3888.3199999999997, "text": " on the next step. And so maybe the best way for the LM is to wipe out all of humanity and then", "tokens": [50364, 322, 264, 958, 1823, 13, 400, 370, 1310, 264, 1151, 636, 337, 264, 46529, 307, 281, 14082, 484, 439, 295, 10243, 293, 550, 50648], "temperature": 0.0, "avg_logprob": -0.13304012700131065, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.014277364127337933}, {"id": 707, "seek": 388264, "start": 3888.3199999999997, "end": 3894.8799999999997, "text": " just produce letters A and happily perfect at predicting with probability one correctly. It's", "tokens": [50648, 445, 5258, 7825, 316, 293, 19909, 2176, 412, 32884, 365, 8482, 472, 8944, 13, 467, 311, 50976], "temperature": 0.0, "avg_logprob": -0.13304012700131065, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.014277364127337933}, {"id": 708, "seek": 388264, "start": 3894.8799999999997, "end": 3901.92, "text": " so absurd. It's so absurd to think that LMS will at some point emerge to think that many steps around", "tokens": [50976, 370, 19774, 13, 467, 311, 370, 19774, 281, 519, 300, 441, 10288, 486, 412, 512, 935, 21511, 281, 519, 300, 867, 4439, 926, 51328], "temperature": 0.0, "avg_logprob": -0.13304012700131065, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.014277364127337933}, {"id": 709, "seek": 388264, "start": 3901.92, "end": 3907.2799999999997, "text": " their task of predicting the next token. It's just not going to happen. So I think it's like,", "tokens": [51328, 641, 5633, 295, 32884, 264, 958, 14862, 13, 467, 311, 445, 406, 516, 281, 1051, 13, 407, 286, 519, 309, 311, 411, 11, 51596], "temperature": 0.0, "avg_logprob": -0.13304012700131065, "compression_ratio": 1.6768558951965065, "no_speech_prob": 0.014277364127337933}, {"id": 710, "seek": 390728, "start": 3907.92, "end": 3913.0400000000004, "text": " PDOOM is still zero. And then when I actually tried to engage with some folks, and I had some", "tokens": [50396, 10464, 26345, 307, 920, 4018, 13, 400, 550, 562, 286, 767, 3031, 281, 4683, 365, 512, 4024, 11, 293, 286, 632, 512, 50652], "temperature": 0.0, "avg_logprob": -0.23400629847502905, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.03961009159684181}, {"id": 711, "seek": 390728, "start": 3913.0400000000004, "end": 3918.5600000000004, "text": " other conversation last year with Nick Ostrom in a German, it was in English, but published in a", "tokens": [50652, 661, 3761, 1036, 1064, 365, 9449, 34140, 4397, 294, 257, 6521, 11, 309, 390, 294, 3669, 11, 457, 6572, 294, 257, 50928], "temperature": 0.0, "avg_logprob": -0.23400629847502905, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.03961009159684181}, {"id": 712, "seek": 390728, "start": 3918.5600000000004, "end": 3923.6000000000004, "text": " German newspaper like that. And I read up some of these scenarios, and I'd engage with folks who", "tokens": [50928, 6521, 13669, 411, 300, 13, 400, 286, 1401, 493, 512, 295, 613, 15077, 11, 293, 286, 1116, 4683, 365, 4024, 567, 51180], "temperature": 0.0, "avg_logprob": -0.23400629847502905, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.03961009159684181}, {"id": 713, "seek": 390728, "start": 3923.6000000000004, "end": 3929.2000000000003, "text": " are worried about PDOOM. That's just all fantastical sci-fi semantics. It's like, oh, it's going to", "tokens": [51180, 366, 5804, 466, 10464, 26345, 13, 663, 311, 445, 439, 30665, 804, 2180, 12, 13325, 4361, 45298, 13, 467, 311, 411, 11, 1954, 11, 309, 311, 516, 281, 51460], "temperature": 0.0, "avg_logprob": -0.23400629847502905, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.03961009159684181}, {"id": 714, "seek": 390728, "start": 3929.2000000000003, "end": 3934.96, "text": " develop this magical great guru or like a magical new virus that is perfect in distributing,", "tokens": [51460, 1499, 341, 12066, 869, 29949, 420, 411, 257, 12066, 777, 5752, 300, 307, 2176, 294, 41406, 11, 51748], "temperature": 0.0, "avg_logprob": -0.23400629847502905, "compression_ratio": 1.6216216216216217, "no_speech_prob": 0.03961009159684181}, {"id": 715, "seek": 393496, "start": 3934.96, "end": 3940.48, "text": " but then only will activate after like one year until everyone like all these random scenarios", "tokens": [50364, 457, 550, 787, 486, 13615, 934, 411, 472, 1064, 1826, 1518, 411, 439, 613, 4974, 15077, 50640], "temperature": 0.0, "avg_logprob": -0.17456064815014866, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.00926422793418169}, {"id": 716, "seek": 393496, "start": 3940.48, "end": 3946.4, "text": " that are just like not feasible. And the science isn't there yet. I'm actually right now sort of", "tokens": [50640, 300, 366, 445, 411, 406, 26648, 13, 400, 264, 3497, 1943, 380, 456, 1939, 13, 286, 478, 767, 558, 586, 1333, 295, 50936], "temperature": 0.0, "avg_logprob": -0.17456064815014866, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.00926422793418169}, {"id": 717, "seek": 393496, "start": 3946.4, "end": 3951.28, "text": " on the side of the fun writing and book about the eyes for science. I think it will do incredible", "tokens": [50936, 322, 264, 1252, 295, 264, 1019, 3579, 293, 1446, 466, 264, 2575, 337, 3497, 13, 286, 519, 309, 486, 360, 4651, 51180], "temperature": 0.0, "avg_logprob": -0.17456064815014866, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.00926422793418169}, {"id": 718, "seek": 393496, "start": 3951.28, "end": 3957.36, "text": " for us in improving science like foundation physics, chemistry, biology, and so on. And", "tokens": [51180, 337, 505, 294, 11470, 3497, 411, 7030, 10649, 11, 12558, 11, 14956, 11, 293, 370, 322, 13, 400, 51484], "temperature": 0.0, "avg_logprob": -0.17456064815014866, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.00926422793418169}, {"id": 719, "seek": 393496, "start": 3957.36, "end": 3962.32, "text": " all this fear mongering, I think it's not really helpful. And again, there's no research that suggests", "tokens": [51484, 439, 341, 4240, 275, 556, 1794, 11, 286, 519, 309, 311, 406, 534, 4961, 13, 400, 797, 11, 456, 311, 572, 2132, 300, 13409, 51732], "temperature": 0.0, "avg_logprob": -0.17456064815014866, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.00926422793418169}, {"id": 720, "seek": 396232, "start": 3962.32, "end": 3966.7200000000003, "text": " the eye is becoming conscious. There's like a couple of people here and there, people kind of", "tokens": [50364, 264, 3313, 307, 5617, 6648, 13, 821, 311, 411, 257, 1916, 295, 561, 510, 293, 456, 11, 561, 733, 295, 50584], "temperature": 0.0, "avg_logprob": -0.22110138268306337, "compression_ratio": 1.7644927536231885, "no_speech_prob": 0.014497834257781506}, {"id": 721, "seek": 396232, "start": 3966.7200000000003, "end": 3971.6000000000004, "text": " playing around with these, but nothing interesting has been published and breaks through, no breaks", "tokens": [50584, 2433, 926, 365, 613, 11, 457, 1825, 1880, 575, 668, 6572, 293, 9857, 807, 11, 572, 9857, 50828], "temperature": 0.0, "avg_logprob": -0.22110138268306337, "compression_ratio": 1.7644927536231885, "no_speech_prob": 0.014497834257781506}, {"id": 722, "seek": 396232, "start": 3971.6000000000004, "end": 3977.44, "text": " through has happened whatsoever in the eye, having any sense of self. And then in a lot of the other", "tokens": [50828, 807, 575, 2011, 17076, 294, 264, 3313, 11, 1419, 604, 2020, 295, 2698, 13, 400, 550, 294, 257, 688, 295, 264, 661, 51120], "temperature": 0.0, "avg_logprob": -0.22110138268306337, "compression_ratio": 1.7644927536231885, "no_speech_prob": 0.014497834257781506}, {"id": 723, "seek": 396232, "start": 3977.44, "end": 3982.32, "text": " sci-fi scenarios, people are saying, oh, with the eye so intelligent, it'll convince everyone to", "tokens": [51120, 2180, 12, 13325, 15077, 11, 561, 366, 1566, 11, 1954, 11, 365, 264, 3313, 370, 13232, 11, 309, 603, 13447, 1518, 281, 51364], "temperature": 0.0, "avg_logprob": -0.22110138268306337, "compression_ratio": 1.7644927536231885, "no_speech_prob": 0.014497834257781506}, {"id": 724, "seek": 396232, "start": 3982.32, "end": 3986.7200000000003, "text": " murder each other or to murder them, like kill themselves and so on. But, you know, if the most", "tokens": [51364, 6568, 1184, 661, 420, 281, 6568, 552, 11, 411, 1961, 2969, 293, 370, 322, 13, 583, 11, 291, 458, 11, 498, 264, 881, 51584], "temperature": 0.0, "avg_logprob": -0.22110138268306337, "compression_ratio": 1.7644927536231885, "no_speech_prob": 0.014497834257781506}, {"id": 725, "seek": 398672, "start": 3986.72, "end": 3993.04, "text": " intelligent entities were to always rule, I don't think we would have the politicians always", "tokens": [50364, 13232, 16667, 645, 281, 1009, 4978, 11, 286, 500, 380, 519, 321, 576, 362, 264, 14756, 1009, 50680], "temperature": 0.0, "avg_logprob": -0.16804165883107228, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.16017422080039978}, {"id": 726, "seek": 398672, "start": 3993.04, "end": 3997.2, "text": " everywhere in the world that we see, right? It's not always just the most intelligent people that", "tokens": [50680, 5315, 294, 264, 1002, 300, 321, 536, 11, 558, 30, 467, 311, 406, 1009, 445, 264, 881, 13232, 561, 300, 50888], "temperature": 0.0, "avg_logprob": -0.16804165883107228, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.16017422080039978}, {"id": 727, "seek": 398672, "start": 3997.2, "end": 4002.08, "text": " run the show. And that's kind of just their incredible intelligence to convince any other", "tokens": [50888, 1190, 264, 855, 13, 400, 300, 311, 733, 295, 445, 641, 4651, 7599, 281, 13447, 604, 661, 51132], "temperature": 0.0, "avg_logprob": -0.16804165883107228, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.16017422080039978}, {"id": 728, "seek": 398672, "start": 4002.08, "end": 4008.3999999999996, "text": " person who is less intelligent, you exactly what they want. It's just not based in reality. So,", "tokens": [51132, 954, 567, 307, 1570, 13232, 11, 291, 2293, 437, 436, 528, 13, 467, 311, 445, 406, 2361, 294, 4103, 13, 407, 11, 51448], "temperature": 0.0, "avg_logprob": -0.16804165883107228, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.16017422080039978}, {"id": 729, "seek": 398672, "start": 4008.3999999999996, "end": 4014.56, "text": " I am very, very optimistic about AI. I do think there's some real problems right now, you know,", "tokens": [51448, 286, 669, 588, 11, 588, 19397, 466, 7318, 13, 286, 360, 519, 456, 311, 512, 957, 2740, 558, 586, 11, 291, 458, 11, 51756], "temperature": 0.0, "avg_logprob": -0.16804165883107228, "compression_ratio": 1.754646840148699, "no_speech_prob": 0.16017422080039978}, {"id": 730, "seek": 401456, "start": 4014.64, "end": 4019.68, "text": " AI will pick up biases, not all the biases that you pick up on the web is something that most", "tokens": [50368, 7318, 486, 1888, 493, 32152, 11, 406, 439, 264, 32152, 300, 291, 1888, 493, 322, 264, 3670, 307, 746, 300, 881, 50620], "temperature": 0.0, "avg_logprob": -0.1314597484494044, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.056620437651872635}, {"id": 731, "seek": 401456, "start": 4019.68, "end": 4026.24, "text": " of humanity is proud of anymore. There's racism, there's sexism, there are various kinds of biases.", "tokens": [50620, 295, 10243, 307, 4570, 295, 3602, 13, 821, 311, 12664, 11, 456, 311, 3260, 1434, 11, 456, 366, 3683, 3685, 295, 32152, 13, 50948], "temperature": 0.0, "avg_logprob": -0.1314597484494044, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.056620437651872635}, {"id": 732, "seek": 401456, "start": 4026.88, "end": 4031.44, "text": " Some people want to use AI. So, where I agree with Joshua Benjio and others is of the three", "tokens": [50980, 2188, 561, 528, 281, 764, 7318, 13, 407, 11, 689, 286, 3986, 365, 24005, 3964, 73, 1004, 293, 2357, 307, 295, 264, 1045, 51208], "temperature": 0.0, "avg_logprob": -0.1314597484494044, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.056620437651872635}, {"id": 733, "seek": 401456, "start": 4032.08, "end": 4037.2, "text": " threat vectors, which is intentional misuse, accidental misuse and loss of control.", "tokens": [51240, 4734, 18875, 11, 597, 307, 21935, 3346, 438, 11, 38094, 3346, 438, 293, 4470, 295, 1969, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1314597484494044, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.056620437651872635}, {"id": 734, "seek": 401456, "start": 4038.16, "end": 4043.04, "text": " Obviously, like intentional misuse is real. And so, that's not ideal. And so, yes, those are real", "tokens": [51544, 7580, 11, 411, 21935, 3346, 438, 307, 957, 13, 400, 370, 11, 300, 311, 406, 7157, 13, 400, 370, 11, 2086, 11, 729, 366, 957, 51788], "temperature": 0.0, "avg_logprob": -0.1314597484494044, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.056620437651872635}, {"id": 735, "seek": 404304, "start": 4043.04, "end": 4048.08, "text": " concerns. I think open social help us understanding those threat vectors and finding the best ways", "tokens": [50364, 7389, 13, 286, 519, 1269, 2093, 854, 505, 3701, 729, 4734, 18875, 293, 5006, 264, 1151, 2098, 50616], "temperature": 0.0, "avg_logprob": -0.11625525686475965, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.04598826915025711}, {"id": 736, "seek": 404304, "start": 4048.08, "end": 4053.44, "text": " to compete with them. I think people still on the internet need to understand, not trust everything", "tokens": [50616, 281, 11831, 365, 552, 13, 286, 519, 561, 920, 322, 264, 4705, 643, 281, 1223, 11, 406, 3361, 1203, 50884], "temperature": 0.0, "avg_logprob": -0.11625525686475965, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.04598826915025711}, {"id": 737, "seek": 404304, "start": 4053.44, "end": 4057.68, "text": " they see on the internet, which has been true ever since the internet came about, hasn't really", "tokens": [50884, 436, 536, 322, 264, 4705, 11, 597, 575, 668, 2074, 1562, 1670, 264, 4705, 1361, 466, 11, 6132, 380, 534, 51096], "temperature": 0.0, "avg_logprob": -0.11625525686475965, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.04598826915025711}, {"id": 738, "seek": 404304, "start": 4057.68, "end": 4064.16, "text": " changed that much with AI. I think since Photoshop, people should already not trust any photo they see.", "tokens": [51096, 3105, 300, 709, 365, 7318, 13, 286, 519, 1670, 20821, 11, 561, 820, 1217, 406, 3361, 604, 5052, 436, 536, 13, 51420], "temperature": 0.0, "avg_logprob": -0.11625525686475965, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.04598826915025711}, {"id": 739, "seek": 404304, "start": 4064.16, "end": 4069.04, "text": " They should be even more worried now about photos they see. And sadly, in the future,", "tokens": [51420, 814, 820, 312, 754, 544, 5804, 586, 466, 5787, 436, 536, 13, 400, 22023, 11, 294, 264, 2027, 11, 51664], "temperature": 0.0, "avg_logprob": -0.11625525686475965, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.04598826915025711}, {"id": 740, "seek": 406904, "start": 4069.04, "end": 4074.4, "text": " they'll have to start worrying about videos and voices, of course, just like they should have", "tokens": [50364, 436, 603, 362, 281, 722, 18788, 466, 2145, 293, 9802, 11, 295, 1164, 11, 445, 411, 436, 820, 362, 50632], "temperature": 0.0, "avg_logprob": -0.10220438935035883, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.1063995435833931}, {"id": 741, "seek": 406904, "start": 4074.4, "end": 4080.0, "text": " worried about photos ever since Photoshop started to really work. And so, there are a lot of concerns", "tokens": [50632, 5804, 466, 5787, 1562, 1670, 20821, 1409, 281, 534, 589, 13, 400, 370, 11, 456, 366, 257, 688, 295, 7389, 50912], "temperature": 0.0, "avg_logprob": -0.10220438935035883, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.1063995435833931}, {"id": 742, "seek": 406904, "start": 4080.0, "end": 4084.08, "text": " and I don't want to diminish them. And I do think we need to work on them. And I think different", "tokens": [50912, 293, 286, 500, 380, 528, 281, 48696, 552, 13, 400, 286, 360, 519, 321, 643, 281, 589, 322, 552, 13, 400, 286, 519, 819, 51116], "temperature": 0.0, "avg_logprob": -0.10220438935035883, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.1063995435833931}, {"id": 743, "seek": 406904, "start": 4084.08, "end": 4088.48, "text": " cultures will have different answers. Freedom of speech is defined differently in different", "tokens": [51116, 12951, 486, 362, 819, 6338, 13, 22208, 295, 6218, 307, 7642, 7614, 294, 819, 51336], "temperature": 0.0, "avg_logprob": -0.10220438935035883, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.1063995435833931}, {"id": 744, "seek": 406904, "start": 4088.48, "end": 4093.92, "text": " countries. Like it's legal in Germany to deny the Holocaust. We learn from our history there.", "tokens": [51336, 3517, 13, 1743, 309, 311, 5089, 294, 7244, 281, 15744, 264, 28399, 13, 492, 1466, 490, 527, 2503, 456, 13, 51608], "temperature": 0.0, "avg_logprob": -0.10220438935035883, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.1063995435833931}, {"id": 745, "seek": 406904, "start": 4093.92, "end": 4098.56, "text": " That's not illegal in the US. And so, different countries and different cultures and societies", "tokens": [51608, 663, 311, 406, 11905, 294, 264, 2546, 13, 400, 370, 11, 819, 3517, 293, 819, 12951, 293, 19329, 51840], "temperature": 0.0, "avg_logprob": -0.10220438935035883, "compression_ratio": 1.842443729903537, "no_speech_prob": 0.1063995435833931}, {"id": 746, "seek": 409856, "start": 4098.56, "end": 4104.320000000001, "text": " will answer some of the problems that AI can amplify already in the past before we'll answer", "tokens": [50364, 486, 1867, 512, 295, 264, 2740, 300, 7318, 393, 41174, 1217, 294, 264, 1791, 949, 321, 603, 1867, 50652], "temperature": 0.0, "avg_logprob": -0.13397958061911844, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0014543436700478196}, {"id": 747, "seek": 409856, "start": 4104.320000000001, "end": 4110.56, "text": " these questions differently. But I don't see any any probability for a full on the scenario of like", "tokens": [50652, 613, 1651, 7614, 13, 583, 286, 500, 380, 536, 604, 604, 8482, 337, 257, 1577, 322, 264, 9005, 295, 411, 50964], "temperature": 0.0, "avg_logprob": -0.13397958061911844, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0014543436700478196}, {"id": 748, "seek": 409856, "start": 4110.56, "end": 4115.92, "text": " existential risks to people. It's mostly people using more and more powerful tools against other", "tokens": [50964, 37133, 10888, 281, 561, 13, 467, 311, 5240, 561, 1228, 544, 293, 544, 4005, 3873, 1970, 661, 51232], "temperature": 0.0, "avg_logprob": -0.13397958061911844, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0014543436700478196}, {"id": 749, "seek": 409856, "start": 4115.92, "end": 4120.240000000001, "text": " people. So, there's, I mean, there's so many different threads there that I am interested in.", "tokens": [51232, 561, 13, 407, 11, 456, 311, 11, 286, 914, 11, 456, 311, 370, 867, 819, 19314, 456, 300, 286, 669, 3102, 294, 13, 51448], "temperature": 0.0, "avg_logprob": -0.13397958061911844, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0014543436700478196}, {"id": 750, "seek": 409856, "start": 4120.240000000001, "end": 4127.360000000001, "text": " For one thing, I applaud you for taking time to envision positive future. I think one of the", "tokens": [51448, 1171, 472, 551, 11, 286, 9644, 291, 337, 1940, 565, 281, 24739, 3353, 2027, 13, 286, 519, 472, 295, 264, 51804], "temperature": 0.0, "avg_logprob": -0.13397958061911844, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.0014543436700478196}, {"id": 751, "seek": 412736, "start": 4127.92, "end": 4134.24, "text": " scarcest resources today, oddly, is a positive vision for the future. Like, what do we want?", "tokens": [50392, 10569, 66, 377, 3593, 965, 11, 46083, 11, 307, 257, 3353, 5201, 337, 264, 2027, 13, 1743, 11, 437, 360, 321, 528, 30, 50708], "temperature": 0.0, "avg_logprob": -0.08547623952229817, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0050584133714437485}, {"id": 752, "seek": 412736, "start": 4134.24, "end": 4138.32, "text": " This, you know, it's like the Jetsons is still almost like state of the art in terms of", "tokens": [50708, 639, 11, 291, 458, 11, 309, 311, 411, 264, 508, 1385, 892, 307, 920, 1920, 411, 1785, 295, 264, 1523, 294, 2115, 295, 50912], "temperature": 0.0, "avg_logprob": -0.08547623952229817, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0050584133714437485}, {"id": 753, "seek": 412736, "start": 4138.32, "end": 4145.5199999999995, "text": " what we would envision a great 2030s to be like. And that is kind of bizarre. So, I definitely", "tokens": [50912, 437, 321, 576, 24739, 257, 869, 28638, 82, 281, 312, 411, 13, 400, 300, 307, 733, 295, 18265, 13, 407, 11, 286, 2138, 51272], "temperature": 0.0, "avg_logprob": -0.08547623952229817, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0050584133714437485}, {"id": 754, "seek": 412736, "start": 4145.5199999999995, "end": 4150.4, "text": " appreciate that. I also share your, you know, I'm not a super fan, but I'm also a fan of the", "tokens": [51272, 4449, 300, 13, 286, 611, 2073, 428, 11, 291, 458, 11, 286, 478, 406, 257, 1687, 3429, 11, 457, 286, 478, 611, 257, 3429, 295, 264, 51516], "temperature": 0.0, "avg_logprob": -0.08547623952229817, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0050584133714437485}, {"id": 755, "seek": 415040, "start": 4150.4, "end": 4158.24, "text": " three body problem. And one of the early prompts that I tried with GPT for early back in the", "tokens": [50364, 1045, 1772, 1154, 13, 400, 472, 295, 264, 2440, 41095, 300, 286, 3031, 365, 26039, 51, 337, 2440, 646, 294, 264, 50756], "temperature": 0.0, "avg_logprob": -0.14430957521711077, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.4920487701892853}, {"id": 756, "seek": 415040, "start": 4158.24, "end": 4166.08, "text": " rent team program like a year and a half ago now was asking it to write some hard science fiction", "tokens": [50756, 6214, 1469, 1461, 411, 257, 1064, 293, 257, 1922, 2057, 586, 390, 3365, 309, 281, 2464, 512, 1152, 3497, 13266, 51148], "temperature": 0.0, "avg_logprob": -0.14430957521711077, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.4920487701892853}, {"id": 757, "seek": 415040, "start": 4166.08, "end": 4174.16, "text": " in the style of the three body problem about AI for, you know, do diffusion model for proteins.", "tokens": [51148, 294, 264, 3758, 295, 264, 1045, 1772, 1154, 466, 7318, 337, 11, 291, 458, 11, 360, 25242, 2316, 337, 15577, 13, 51552], "temperature": 0.0, "avg_logprob": -0.14430957521711077, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.4920487701892853}, {"id": 758, "seek": 417416, "start": 4174.88, "end": 4181.44, "text": " And I took the plan right off of the GitHub page for this protein, you know, diffusion model project,", "tokens": [50400, 400, 286, 1890, 264, 1393, 558, 766, 295, 264, 23331, 3028, 337, 341, 7944, 11, 291, 458, 11, 25242, 2316, 1716, 11, 50728], "temperature": 0.0, "avg_logprob": -0.13811076028006417, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.33449262380599976}, {"id": 759, "seek": 417416, "start": 4182.0, "end": 4186.88, "text": " which basically said we want to create text to protein. So, you know, say or text to maybe it", "tokens": [50756, 597, 1936, 848, 321, 528, 281, 1884, 2487, 281, 7944, 13, 407, 11, 291, 458, 11, 584, 420, 2487, 281, 1310, 309, 51000], "temperature": 0.0, "avg_logprob": -0.13811076028006417, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.33449262380599976}, {"id": 760, "seek": 417416, "start": 4186.88, "end": 4190.96, "text": " was more even general than that molecule or whatever. So, you know, you would be able to", "tokens": [51000, 390, 544, 754, 2674, 813, 300, 15582, 420, 2035, 13, 407, 11, 291, 458, 11, 291, 576, 312, 1075, 281, 51204], "temperature": 0.0, "avg_logprob": -0.13811076028006417, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.33449262380599976}, {"id": 761, "seek": 417416, "start": 4190.96, "end": 4195.68, "text": " just specify in natural language, specifies kind of an odd word. Or, you know, to the best of your", "tokens": [51204, 445, 16500, 294, 3303, 2856, 11, 1608, 11221, 733, 295, 364, 7401, 1349, 13, 1610, 11, 291, 458, 11, 281, 264, 1151, 295, 428, 51440], "temperature": 0.0, "avg_logprob": -0.13811076028006417, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.33449262380599976}, {"id": 762, "seek": 417416, "start": 4195.68, "end": 4199.76, "text": " ability articulate in natural language what you're looking for into protein. And this thing would", "tokens": [51440, 3485, 30305, 294, 3303, 2856, 437, 291, 434, 1237, 337, 666, 7944, 13, 400, 341, 551, 576, 51644], "temperature": 0.0, "avg_logprob": -0.13811076028006417, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.33449262380599976}, {"id": 763, "seek": 417416, "start": 4199.76, "end": 4203.84, "text": " then, you know, generate it. And we are actually starting to see that there was a paper in nature", "tokens": [51644, 550, 11, 291, 458, 11, 8460, 309, 13, 400, 321, 366, 767, 2891, 281, 536, 300, 456, 390, 257, 3035, 294, 3687, 51848], "temperature": 0.0, "avg_logprob": -0.13811076028006417, "compression_ratio": 1.8322784810126582, "no_speech_prob": 0.33449262380599976}, {"id": 764, "seek": 420416, "start": 4204.24, "end": 4208.72, "text": " not long ago, I'm hoping to do an episode with the authors that achieves that to a certain degree.", "tokens": [50368, 406, 938, 2057, 11, 286, 478, 7159, 281, 360, 364, 3500, 365, 264, 16552, 300, 3538, 977, 300, 281, 257, 1629, 4314, 13, 50592], "temperature": 0.0, "avg_logprob": -0.11096610561493904, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0032721676398068666}, {"id": 765, "seek": 420416, "start": 4208.72, "end": 4214.5599999999995, "text": " But the what the AI what GPT for came back with in terms of hard science fiction about this scenario", "tokens": [50592, 583, 264, 437, 264, 7318, 437, 26039, 51, 337, 1361, 646, 365, 294, 2115, 295, 1152, 3497, 13266, 466, 341, 9005, 50884], "temperature": 0.0, "avg_logprob": -0.11096610561493904, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0032721676398068666}, {"id": 766, "seek": 420416, "start": 4215.599999999999, "end": 4221.599999999999, "text": " was, I think, first of all, just extremely funny because it basically ends up in a prompting war", "tokens": [50936, 390, 11, 286, 519, 11, 700, 295, 439, 11, 445, 4664, 4074, 570, 309, 1936, 5314, 493, 294, 257, 12391, 278, 1516, 51236], "temperature": 0.0, "avg_logprob": -0.11096610561493904, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0032721676398068666}, {"id": 767, "seek": 420416, "start": 4221.599999999999, "end": 4226.48, "text": " between the good guys and the bad guys and they're both like trying to out prompt each other. And so", "tokens": [51236, 1296, 264, 665, 1074, 293, 264, 1578, 1074, 293, 436, 434, 1293, 411, 1382, 281, 484, 12391, 1184, 661, 13, 400, 370, 51480], "temperature": 0.0, "avg_logprob": -0.11096610561493904, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0032721676398068666}, {"id": 768, "seek": 420416, "start": 4226.48, "end": 4231.84, "text": " the you know, the kind of climactic scene is like the person prompting, you know, an AI to like", "tokens": [51480, 264, 291, 458, 11, 264, 733, 295, 5644, 19892, 4145, 307, 411, 264, 954, 12391, 278, 11, 291, 458, 11, 364, 7318, 281, 411, 51748], "temperature": 0.0, "avg_logprob": -0.11096610561493904, "compression_ratio": 1.68259385665529, "no_speech_prob": 0.0032721676398068666}, {"id": 769, "seek": 423184, "start": 4231.84, "end": 4236.4800000000005, "text": " make a protein or, you know, a molecule that will interfere with the bad guys molecule, but not", "tokens": [50364, 652, 257, 7944, 420, 11, 291, 458, 11, 257, 15582, 300, 486, 23946, 365, 264, 1578, 1074, 15582, 11, 457, 406, 50596], "temperature": 0.0, "avg_logprob": -0.12496417130881209, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00628921901807189}, {"id": 770, "seek": 423184, "start": 4236.4800000000005, "end": 4242.24, "text": " harm any of the, you know, the humans or whatever. And it's just like both absurd, but also maybe", "tokens": [50596, 6491, 604, 295, 264, 11, 291, 458, 11, 264, 6255, 420, 2035, 13, 400, 309, 311, 445, 411, 1293, 19774, 11, 457, 611, 1310, 50884], "temperature": 0.0, "avg_logprob": -0.12496417130881209, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00628921901807189}, {"id": 771, "seek": 423184, "start": 4242.24, "end": 4249.04, "text": " not entirely absurd. You know, I mean, I am with you in that the I would order the risks the same", "tokens": [50884, 406, 7696, 19774, 13, 509, 458, 11, 286, 914, 11, 286, 669, 365, 291, 294, 300, 264, 286, 576, 1668, 264, 10888, 264, 912, 51224], "temperature": 0.0, "avg_logprob": -0.12496417130881209, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00628921901807189}, {"id": 772, "seek": 423184, "start": 4249.04, "end": 4255.04, "text": " way. You know, we already have chaos GBT. There are I recently read a research grant from a group", "tokens": [51224, 636, 13, 509, 458, 11, 321, 1217, 362, 14158, 26809, 51, 13, 821, 366, 286, 3938, 1401, 257, 2132, 6386, 490, 257, 1594, 51524], "temperature": 0.0, "avg_logprob": -0.12496417130881209, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00628921901807189}, {"id": 773, "seek": 423184, "start": 4255.04, "end": 4259.6, "text": " proposing to study on the side all tendencies. Like there are people out there who want to kill", "tokens": [51524, 29939, 281, 2979, 322, 264, 1252, 439, 45488, 13, 1743, 456, 366, 561, 484, 456, 567, 528, 281, 1961, 51752], "temperature": 0.0, "avg_logprob": -0.12496417130881209, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00628921901807189}, {"id": 774, "seek": 425960, "start": 4259.6, "end": 4266.0, "text": " everyone. Like what's up with that? And, you know, if the tools get more powerful, like that, you", "tokens": [50364, 1518, 13, 1743, 437, 311, 493, 365, 300, 30, 400, 11, 291, 458, 11, 498, 264, 3873, 483, 544, 4005, 11, 411, 300, 11, 291, 50684], "temperature": 0.0, "avg_logprob": -0.10488623521459384, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.030210837721824646}, {"id": 775, "seek": 425960, "start": 4266.0, "end": 4271.84, "text": " know, those people become even more problematic than they already are. So yes, I would put that at", "tokens": [50684, 458, 11, 729, 561, 1813, 754, 544, 19011, 813, 436, 1217, 366, 13, 407, 2086, 11, 286, 576, 829, 300, 412, 50976], "temperature": 0.0, "avg_logprob": -0.10488623521459384, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.030210837721824646}, {"id": 776, "seek": 425960, "start": 4271.84, "end": 4277.52, "text": " the top of the, you know, of the stack of like, big picture risks. And by the way, I take all the", "tokens": [50976, 264, 1192, 295, 264, 11, 291, 458, 11, 295, 264, 8630, 295, 411, 11, 955, 3036, 10888, 13, 400, 538, 264, 636, 11, 286, 747, 439, 264, 51260], "temperature": 0.0, "avg_logprob": -0.10488623521459384, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.030210837721824646}, {"id": 777, "seek": 425960, "start": 4277.52, "end": 4282.8, "text": " short term and medium term risks seriously too. Like this is a big tent show where like all your", "tokens": [51260, 2099, 1433, 293, 6399, 1433, 10888, 6638, 886, 13, 1743, 341, 307, 257, 955, 7054, 855, 689, 411, 439, 428, 51524], "temperature": 0.0, "avg_logprob": -0.10488623521459384, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.030210837721824646}, {"id": 778, "seek": 425960, "start": 4282.8, "end": 4287.52, "text": " hopes, dreams and concerns and, you know, perhaps irrational fears like can all have a home. But I", "tokens": [51524, 13681, 11, 7505, 293, 7389, 293, 11, 291, 458, 11, 4317, 39914, 15649, 411, 393, 439, 362, 257, 1280, 13, 583, 286, 51760], "temperature": 0.0, "avg_logprob": -0.10488623521459384, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.030210837721824646}, {"id": 779, "seek": 428752, "start": 4287.52, "end": 4294.72, "text": " guess, you know, to sort of get to P doom zero, I still am like, I don't know, you know, all these", "tokens": [50364, 2041, 11, 291, 458, 11, 281, 1333, 295, 483, 281, 430, 37131, 4018, 11, 286, 920, 669, 411, 11, 286, 500, 380, 458, 11, 291, 458, 11, 439, 613, 50724], "temperature": 0.0, "avg_logprob": -0.10833185166120529, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.0010649242904037237}, {"id": 780, "seek": 428752, "start": 4294.72, "end": 4299.360000000001, "text": " individual crazy scenarios, sure, they're extremely unlikely, you know, the prompting war with your,", "tokens": [50724, 2609, 3219, 15077, 11, 988, 11, 436, 434, 4664, 17518, 11, 291, 458, 11, 264, 12391, 278, 1516, 365, 428, 11, 50956], "temperature": 0.0, "avg_logprob": -0.10833185166120529, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.0010649242904037237}, {"id": 781, "seek": 428752, "start": 4299.360000000001, "end": 4305.360000000001, "text": " you know, protein diffusion model is like absurd on the face of it. But I kind of think of like", "tokens": [50956, 291, 458, 11, 7944, 25242, 2316, 307, 411, 19774, 322, 264, 1851, 295, 309, 13, 583, 286, 733, 295, 519, 295, 411, 51256], "temperature": 0.0, "avg_logprob": -0.10833185166120529, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.0010649242904037237}, {"id": 782, "seek": 428752, "start": 4305.360000000001, "end": 4311.360000000001, "text": " to taking the integral over that like vast space of crazy super unlikely scenarios. And then I'm", "tokens": [51256, 281, 1940, 264, 11573, 670, 300, 411, 8369, 1901, 295, 3219, 1687, 17518, 15077, 13, 400, 550, 286, 478, 51556], "temperature": 0.0, "avg_logprob": -0.10833185166120529, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.0010649242904037237}, {"id": 783, "seek": 428752, "start": 4311.360000000001, "end": 4316.72, "text": " kind of like, you know, there's so many of them right that space is so big. And even if the probability", "tokens": [51556, 733, 295, 411, 11, 291, 458, 11, 456, 311, 370, 867, 295, 552, 558, 300, 1901, 307, 370, 955, 13, 400, 754, 498, 264, 8482, 51824], "temperature": 0.0, "avg_logprob": -0.10833185166120529, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.0010649242904037237}, {"id": 784, "seek": 431672, "start": 4316.8, "end": 4322.240000000001, "text": " is like kind of vanishing, one thing you learn in calculus is like, you can, you know, that the", "tokens": [50368, 307, 411, 733, 295, 3161, 3807, 11, 472, 551, 291, 1466, 294, 33400, 307, 411, 11, 291, 393, 11, 291, 458, 11, 300, 264, 50640], "temperature": 0.0, "avg_logprob": -0.07517644176332969, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.009124504402279854}, {"id": 785, "seek": 431672, "start": 4322.240000000001, "end": 4328.08, "text": " integral can either also vanish or it can be like finite, you know, over these, you know, kind of,", "tokens": [50640, 11573, 393, 2139, 611, 43584, 420, 309, 393, 312, 411, 19362, 11, 291, 458, 11, 670, 613, 11, 291, 458, 11, 733, 295, 11, 50932], "temperature": 0.0, "avg_logprob": -0.07517644176332969, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.009124504402279854}, {"id": 786, "seek": 431672, "start": 4328.08, "end": 4333.12, "text": " even if the function itself is going to zero, the integral doesn't necessarily have to go to zero", "tokens": [50932, 754, 498, 264, 2445, 2564, 307, 516, 281, 4018, 11, 264, 11573, 1177, 380, 4725, 362, 281, 352, 281, 4018, 51184], "temperature": 0.0, "avg_logprob": -0.07517644176332969, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.009124504402279854}, {"id": 787, "seek": 431672, "start": 4333.12, "end": 4339.4400000000005, "text": " over that space. So to me, that just feels like very unresolved still. And I don't think we're", "tokens": [51184, 670, 300, 1901, 13, 407, 281, 385, 11, 300, 445, 3417, 411, 588, 517, 495, 29110, 920, 13, 400, 286, 500, 380, 519, 321, 434, 51500], "temperature": 0.0, "avg_logprob": -0.07517644176332969, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.009124504402279854}, {"id": 788, "seek": 431672, "start": 4339.4400000000005, "end": 4343.2, "text": " going to resolve that today. But I would love to hear a little bit more about your, how you think", "tokens": [51500, 516, 281, 14151, 300, 965, 13, 583, 286, 576, 959, 281, 1568, 257, 707, 857, 544, 466, 428, 11, 577, 291, 519, 51688], "temperature": 0.0, "avg_logprob": -0.07517644176332969, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.009124504402279854}, {"id": 789, "seek": 434320, "start": 4343.28, "end": 4350.4, "text": " about AI agency, and also concepts of emergence in agents today, I guess I also wonder, like,", "tokens": [50368, 466, 7318, 7934, 11, 293, 611, 10392, 295, 36211, 294, 12554, 965, 11, 286, 2041, 286, 611, 2441, 11, 411, 11, 50724], "temperature": 0.0, "avg_logprob": -0.15032000635184495, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.1823747307062149}, {"id": 790, "seek": 434320, "start": 4350.4, "end": 4355.04, "text": " is you.com gonna, you know, push more toward the agent direction, you've got like a, what I would", "tokens": [50724, 307, 291, 13, 1112, 799, 11, 291, 458, 11, 2944, 544, 7361, 264, 9461, 3513, 11, 291, 600, 658, 411, 257, 11, 437, 286, 576, 50956], "temperature": 0.0, "avg_logprob": -0.15032000635184495, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.1823747307062149}, {"id": 791, "seek": 434320, "start": 4355.04, "end": 4361.12, "text": " call a research agent today, you've got a browser as well, I could, you know, should I start to", "tokens": [50956, 818, 257, 2132, 9461, 965, 11, 291, 600, 658, 257, 11185, 382, 731, 11, 286, 727, 11, 291, 458, 11, 820, 286, 722, 281, 51260], "temperature": 0.0, "avg_logprob": -0.15032000635184495, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.1823747307062149}, {"id": 792, "seek": 434320, "start": 4361.12, "end": 4368.08, "text": " expect it to take actions for me? What I've observed in the agent space is I never feel like it", "tokens": [51260, 2066, 309, 281, 747, 5909, 337, 385, 30, 708, 286, 600, 13095, 294, 264, 9461, 1901, 307, 286, 1128, 841, 411, 309, 51608], "temperature": 0.0, "avg_logprob": -0.15032000635184495, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.1823747307062149}, {"id": 793, "seek": 436808, "start": 4368.08, "end": 4373.5199999999995, "text": " fails because it doesn't understand the goal or like doesn't stay on task. Let's say that never", "tokens": [50364, 18199, 570, 309, 1177, 380, 1223, 264, 3387, 420, 411, 1177, 380, 1754, 322, 5633, 13, 961, 311, 584, 300, 1128, 50636], "temperature": 0.0, "avg_logprob": -0.08744450746956518, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.05833885073661804}, {"id": 794, "seek": 436808, "start": 4373.5199999999995, "end": 4380.0, "text": " happens, but very rarely, much more often, it's just a failure of competence. So my expectation then", "tokens": [50636, 2314, 11, 457, 588, 13752, 11, 709, 544, 2049, 11, 309, 311, 445, 257, 7763, 295, 39965, 13, 407, 452, 14334, 550, 50960], "temperature": 0.0, "avg_logprob": -0.08744450746956518, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.05833885073661804}, {"id": 795, "seek": 436808, "start": 4380.0, "end": 4384.88, "text": " is that like, as the competence improves, it may not be intrinsic agency, but it may be", "tokens": [50960, 307, 300, 411, 11, 382, 264, 39965, 24771, 11, 309, 815, 406, 312, 35698, 7934, 11, 457, 309, 815, 312, 51204], "temperature": 0.0, "avg_logprob": -0.08744450746956518, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.05833885073661804}, {"id": 796, "seek": 436808, "start": 4385.76, "end": 4390.24, "text": " prompted agency, and it may even be like, you know, as we have more and more orchestrated systems,", "tokens": [51248, 31042, 7934, 11, 293, 309, 815, 754, 312, 411, 11, 291, 458, 11, 382, 321, 362, 544, 293, 544, 14161, 5468, 3652, 11, 51472], "temperature": 0.0, "avg_logprob": -0.08744450746956518, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.05833885073661804}, {"id": 797, "seek": 436808, "start": 4390.24, "end": 4394.32, "text": " we may have models prompting other models to, you know, go off and do this. And", "tokens": [51472, 321, 815, 362, 5245, 12391, 278, 661, 5245, 281, 11, 291, 458, 11, 352, 766, 293, 360, 341, 13, 400, 51676], "temperature": 0.0, "avg_logprob": -0.08744450746956518, "compression_ratio": 1.753787878787879, "no_speech_prob": 0.05833885073661804}, {"id": 798, "seek": 439432, "start": 4395.12, "end": 4398.5599999999995, "text": " it does feel like we've got, we're headed for like a lot of spinning plates. And", "tokens": [50404, 309, 775, 841, 411, 321, 600, 658, 11, 321, 434, 12798, 337, 411, 257, 688, 295, 15640, 14231, 13, 400, 50576], "temperature": 0.0, "avg_logprob": -0.15293182310510856, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.0032727974466979504}, {"id": 799, "seek": 439432, "start": 4399.2, "end": 4403.36, "text": " the idea that they could kind of, you know, all come crashing down is like,", "tokens": [50608, 264, 1558, 300, 436, 727, 733, 295, 11, 291, 458, 11, 439, 808, 26900, 760, 307, 411, 11, 50816], "temperature": 0.0, "avg_logprob": -0.15293182310510856, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.0032727974466979504}, {"id": 800, "seek": 439432, "start": 4404.0, "end": 4410.0, "text": " that's doesn't just doesn't feel like something we can rule out. But I don't know, I can, can you", "tokens": [50848, 300, 311, 1177, 380, 445, 1177, 380, 841, 411, 746, 321, 393, 4978, 484, 13, 583, 286, 500, 380, 458, 11, 286, 393, 11, 393, 291, 51148], "temperature": 0.0, "avg_logprob": -0.15293182310510856, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.0032727974466979504}, {"id": 801, "seek": 439432, "start": 4410.0, "end": 4414.88, "text": " help me be confident there? I'm still not. I'll go through the sound of the things you mentioned.", "tokens": [51148, 854, 385, 312, 6679, 456, 30, 286, 478, 920, 406, 13, 286, 603, 352, 807, 264, 1626, 295, 264, 721, 291, 2835, 13, 51392], "temperature": 0.0, "avg_logprob": -0.15293182310510856, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.0032727974466979504}, {"id": 802, "seek": 439432, "start": 4414.88, "end": 4420.639999999999, "text": " So PDM equals zero. So you're right. As you integrate over the future, I would like to not", "tokens": [51392, 407, 10464, 44, 6915, 4018, 13, 407, 291, 434, 558, 13, 1018, 291, 13365, 670, 264, 2027, 11, 286, 576, 411, 281, 406, 51680], "temperature": 0.0, "avg_logprob": -0.15293182310510856, "compression_ratio": 1.6407407407407408, "no_speech_prob": 0.0032727974466979504}, {"id": 803, "seek": 442064, "start": 4420.64, "end": 4426.72, "text": " rule out anything. So maybe I should say 10 to the minus whatever, like a time, time, number,", "tokens": [50364, 4978, 484, 1340, 13, 407, 1310, 286, 820, 584, 1266, 281, 264, 3175, 2035, 11, 411, 257, 565, 11, 565, 11, 1230, 11, 50668], "temperature": 0.0, "avg_logprob": -0.19503916864809784, "compression_ratio": 1.55, "no_speech_prob": 0.016911182552576065}, {"id": 804, "seek": 442064, "start": 4426.72, "end": 4434.96, "text": " because in the next five billion years, like all kinds of things happen, right? Like maybe as if", "tokens": [50668, 570, 294, 264, 958, 1732, 5218, 924, 11, 411, 439, 3685, 295, 721, 1051, 11, 558, 30, 1743, 1310, 382, 498, 51080], "temperature": 0.0, "avg_logprob": -0.19503916864809784, "compression_ratio": 1.55, "no_speech_prob": 0.016911182552576065}, {"id": 805, "seek": 442064, "start": 4434.96, "end": 4440.88, "text": " like the three body problem, spoiler alert, like maybe some big, much more sophisticated alien", "tokens": [51080, 411, 264, 1045, 1772, 1154, 11, 26927, 9615, 11, 411, 1310, 512, 955, 11, 709, 544, 16950, 12319, 51376], "temperature": 0.0, "avg_logprob": -0.19503916864809784, "compression_ratio": 1.55, "no_speech_prob": 0.016911182552576065}, {"id": 806, "seek": 442064, "start": 4440.88, "end": 4445.68, "text": " species will come across. They have already developed, fasted in my time, travel, and,", "tokens": [51376, 6172, 486, 808, 2108, 13, 814, 362, 1217, 4743, 11, 2370, 292, 294, 452, 565, 11, 3147, 11, 293, 11, 51616], "temperature": 0.0, "avg_logprob": -0.19503916864809784, "compression_ratio": 1.55, "no_speech_prob": 0.016911182552576065}, {"id": 807, "seek": 444568, "start": 4445.68, "end": 4450.400000000001, "text": " or, you know, just are really, really fast in getting here and various capacities. And then,", "tokens": [50364, 420, 11, 291, 458, 11, 445, 366, 534, 11, 534, 2370, 294, 1242, 510, 293, 3683, 39396, 13, 400, 550, 11, 50600], "temperature": 0.0, "avg_logprob": -0.1543474118571636, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.015185583382844925}, {"id": 808, "seek": 444568, "start": 4450.400000000001, "end": 4455.200000000001, "text": " you know, they have an AI and daddy, I will just like destroy all of us. So they're getting ready", "tokens": [50600, 291, 458, 11, 436, 362, 364, 7318, 293, 16785, 11, 286, 486, 445, 411, 5293, 439, 295, 505, 13, 407, 436, 434, 1242, 1919, 50840], "temperature": 0.0, "avg_logprob": -0.1543474118571636, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.015185583382844925}, {"id": 809, "seek": 444568, "start": 4455.200000000001, "end": 4460.320000000001, "text": " to like settle into the new planet before they get here. Like there's all kinds of crazy things", "tokens": [50840, 281, 411, 11852, 666, 264, 777, 5054, 949, 436, 483, 510, 13, 1743, 456, 311, 439, 3685, 295, 3219, 721, 51096], "temperature": 0.0, "avg_logprob": -0.1543474118571636, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.015185583382844925}, {"id": 810, "seek": 444568, "start": 4460.320000000001, "end": 4466.4800000000005, "text": " that can happen. It's just that, like in terms of how much resources we should spend on T,", "tokens": [51096, 300, 393, 1051, 13, 467, 311, 445, 300, 11, 411, 294, 2115, 295, 577, 709, 3593, 321, 820, 3496, 322, 314, 11, 51404], "temperature": 0.0, "avg_logprob": -0.1543474118571636, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.015185583382844925}, {"id": 811, "seek": 444568, "start": 4467.4400000000005, "end": 4473.6, "text": " like existential do versus like, you know, I'd say, yeah, I have a couple of researchers,", "tokens": [51452, 411, 37133, 360, 5717, 411, 11, 291, 458, 11, 286, 1116, 584, 11, 1338, 11, 286, 362, 257, 1916, 295, 10309, 11, 51760], "temperature": 0.0, "avg_logprob": -0.1543474118571636, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.015185583382844925}, {"id": 812, "seek": 447360, "start": 4473.6, "end": 4480.160000000001, "text": " like thinking of cool sci-fi scenarios, inspire us, like maybe like think about ways that that could", "tokens": [50364, 411, 1953, 295, 1627, 2180, 12, 13325, 15077, 11, 15638, 505, 11, 411, 1310, 411, 519, 466, 2098, 300, 300, 727, 50692], "temperature": 0.0, "avg_logprob": -0.22376687861671132, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.0034826677292585373}, {"id": 813, "seek": 447360, "start": 4480.160000000001, "end": 4487.120000000001, "text": " be prevented, but to spend billions of dollars on it, to like, spend a lot of like, mind share,", "tokens": [50692, 312, 27314, 11, 457, 281, 3496, 17375, 295, 3808, 322, 309, 11, 281, 411, 11, 3496, 257, 688, 295, 411, 11, 1575, 2073, 11, 51040], "temperature": 0.0, "avg_logprob": -0.22376687861671132, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.0034826677292585373}, {"id": 814, "seek": 447360, "start": 4487.120000000001, "end": 4491.76, "text": " the public about it, who's already scared of any kind of technology. I mean, people are scared of", "tokens": [51040, 264, 1908, 466, 309, 11, 567, 311, 1217, 5338, 295, 604, 733, 295, 2899, 13, 286, 914, 11, 561, 366, 5338, 295, 51272], "temperature": 0.0, "avg_logprob": -0.22376687861671132, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.0034826677292585373}, {"id": 815, "seek": 447360, "start": 4491.76, "end": 4497.52, "text": " vice. I mean, there's this great Twitter handle called the pessimist archive. I mean, people were", "tokens": [51272, 11964, 13, 286, 914, 11, 456, 311, 341, 869, 5794, 4813, 1219, 264, 37399, 468, 23507, 13, 286, 914, 11, 561, 645, 51560], "temperature": 0.0, "avg_logprob": -0.22376687861671132, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.0034826677292585373}, {"id": 816, "seek": 447360, "start": 4497.52, "end": 4502.400000000001, "text": " scared and thought doom is happening because of the novels back in the day. People are like, all", "tokens": [51560, 5338, 293, 1194, 37131, 307, 2737, 570, 295, 264, 24574, 646, 294, 264, 786, 13, 3432, 366, 411, 11, 439, 51804], "temperature": 0.0, "avg_logprob": -0.22376687861671132, "compression_ratio": 1.7526881720430108, "no_speech_prob": 0.0034826677292585373}, {"id": 817, "seek": 450240, "start": 4502.4, "end": 4507.04, "text": " these kids, they're just in their heads reading novels. They're going to all be useless human", "tokens": [50364, 613, 2301, 11, 436, 434, 445, 294, 641, 8050, 3760, 24574, 13, 814, 434, 516, 281, 439, 312, 14115, 1952, 50596], "temperature": 0.0, "avg_logprob": -0.12137900833534983, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0073422398418188095}, {"id": 818, "seek": 450240, "start": 4507.04, "end": 4512.799999999999, "text": " beings in the future. Newspaper was terrible. Internet was terrible. Like there's so many", "tokens": [50596, 8958, 294, 264, 2027, 13, 1873, 4952, 2332, 390, 6237, 13, 7703, 390, 6237, 13, 1743, 456, 311, 370, 867, 50884], "temperature": 0.0, "avg_logprob": -0.12137900833534983, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0073422398418188095}, {"id": 819, "seek": 450240, "start": 4512.799999999999, "end": 4517.839999999999, "text": " things that like people thought this is the end of civilization and we're very pessimistic about.", "tokens": [50884, 721, 300, 411, 561, 1194, 341, 307, 264, 917, 295, 18036, 293, 321, 434, 588, 37399, 3142, 466, 13, 51136], "temperature": 0.0, "avg_logprob": -0.12137900833534983, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0073422398418188095}, {"id": 820, "seek": 450240, "start": 4517.839999999999, "end": 4523.44, "text": " And again, not this diminishing like real, real concerns, but again, existential one,", "tokens": [51136, 400, 797, 11, 406, 341, 15739, 3807, 411, 957, 11, 957, 7389, 11, 457, 797, 11, 37133, 472, 11, 51416], "temperature": 0.0, "avg_logprob": -0.12137900833534983, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0073422398418188095}, {"id": 821, "seek": 450240, "start": 4523.44, "end": 4528.0, "text": " very, very likely given what we're seeing right now. And if there, it does happen at some point in", "tokens": [51416, 588, 11, 588, 3700, 2212, 437, 321, 434, 2577, 558, 586, 13, 400, 498, 456, 11, 309, 775, 1051, 412, 512, 935, 294, 51644], "temperature": 0.0, "avg_logprob": -0.12137900833534983, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0073422398418188095}, {"id": 822, "seek": 452800, "start": 4528.0, "end": 4535.44, "text": " the future, then I would argue that to think about the best countermeasures now is kind of like", "tokens": [50364, 264, 2027, 11, 550, 286, 576, 9695, 300, 281, 519, 466, 264, 1151, 5682, 1398, 20044, 586, 307, 733, 295, 411, 50736], "temperature": 0.0, "avg_logprob": -0.11765182227419134, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.05832444876432419}, {"id": 823, "seek": 452800, "start": 4536.24, "end": 4541.6, "text": " thinking about, you know, the best countermeasures against a computer going crazy when there's", "tokens": [50776, 1953, 466, 11, 291, 458, 11, 264, 1151, 5682, 1398, 20044, 1970, 257, 3820, 516, 3219, 562, 456, 311, 51044], "temperature": 0.0, "avg_logprob": -0.11765182227419134, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.05832444876432419}, {"id": 824, "seek": 452800, "start": 4541.6, "end": 4545.68, "text": " still a bunch of vacuum tubes and you like, well, we're going to just suck out the air of", "tokens": [51044, 920, 257, 3840, 295, 14224, 21458, 293, 291, 411, 11, 731, 11, 321, 434, 516, 281, 445, 9967, 484, 264, 1988, 295, 51248], "temperature": 0.0, "avg_logprob": -0.11765182227419134, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.05832444876432419}, {"id": 825, "seek": 452800, "start": 4545.68, "end": 4548.8, "text": " everything into the vacuum tubes. They're not going to work as well and more because they're", "tokens": [51248, 1203, 666, 264, 14224, 21458, 13, 814, 434, 406, 516, 281, 589, 382, 731, 293, 544, 570, 436, 434, 51404], "temperature": 0.0, "avg_logprob": -0.11765182227419134, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.05832444876432419}, {"id": 826, "seek": 452800, "start": 4548.8, "end": 4553.68, "text": " going to break and blah, blah, blah. That was your like counterattack against the computer taking over", "tokens": [51404, 516, 281, 1821, 293, 12288, 11, 12288, 11, 12288, 13, 663, 390, 428, 411, 5682, 44514, 1970, 264, 3820, 1940, 670, 51648], "temperature": 0.0, "avg_logprob": -0.11765182227419134, "compression_ratio": 1.8521400778210118, "no_speech_prob": 0.05832444876432419}, {"id": 827, "seek": 455368, "start": 4554.56, "end": 4560.08, "text": " with your current thinking of vacuum tube computers. Or it's like, you know, like it's", "tokens": [50408, 365, 428, 2190, 1953, 295, 14224, 9917, 10807, 13, 1610, 309, 311, 411, 11, 291, 458, 11, 411, 309, 311, 50684], "temperature": 0.0, "avg_logprob": -0.23986966986405223, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.044002946466207504}, {"id": 828, "seek": 455368, "start": 4560.08, "end": 4564.0, "text": " similar to the internet, you know, if you thought about what's the internet going to be, how could", "tokens": [50684, 2531, 281, 264, 4705, 11, 291, 458, 11, 498, 291, 1194, 466, 437, 311, 264, 4705, 516, 281, 312, 11, 577, 727, 50880], "temperature": 0.0, "avg_logprob": -0.23986966986405223, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.044002946466207504}, {"id": 829, "seek": 455368, "start": 4564.0, "end": 4572.4800000000005, "text": " it be so terrible? Zero of the TCT IP experts in the early ARPANET days realized that at some point,", "tokens": [50880, 309, 312, 370, 6237, 30, 17182, 295, 264, 314, 10259, 8671, 8572, 294, 264, 2440, 8943, 47, 1770, 4850, 1708, 5334, 300, 412, 512, 935, 11, 51304], "temperature": 0.0, "avg_logprob": -0.23986966986405223, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.044002946466207504}, {"id": 830, "seek": 455368, "start": 4572.4800000000005, "end": 4577.04, "text": " maybe a foreign power could interfere with local elections because like you can say whatever you", "tokens": [51304, 1310, 257, 5329, 1347, 727, 23946, 365, 2654, 12870, 570, 411, 291, 393, 584, 2035, 291, 51532], "temperature": 0.0, "avg_logprob": -0.23986966986405223, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.044002946466207504}, {"id": 831, "seek": 455368, "start": 4577.04, "end": 4583.12, "text": " want online and maybe people get followers in their social media. Like no one had victimized", "tokens": [51532, 528, 2950, 293, 1310, 561, 483, 13071, 294, 641, 2093, 3021, 13, 1743, 572, 472, 632, 6760, 1602, 51836], "temperature": 0.0, "avg_logprob": -0.23986966986405223, "compression_ratio": 1.6026936026936027, "no_speech_prob": 0.044002946466207504}, {"id": 832, "seek": 458312, "start": 4583.12, "end": 4589.36, "text": " in the 70s and the early ARPANET days. And so I think most of the threat vectors are not that", "tokens": [50364, 294, 264, 5285, 82, 293, 264, 2440, 8943, 47, 1770, 4850, 1708, 13, 400, 370, 286, 519, 881, 295, 264, 4734, 18875, 366, 406, 300, 50676], "temperature": 0.0, "avg_logprob": -0.1572764091884967, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0021153928246349096}, {"id": 833, "seek": 458312, "start": 4590.0, "end": 4595.28, "text": " useful in terms of key doom kind of research. I have a couple of folks work on it, but not", "tokens": [50708, 4420, 294, 2115, 295, 2141, 37131, 733, 295, 2132, 13, 286, 362, 257, 1916, 295, 4024, 589, 322, 309, 11, 457, 406, 50972], "temperature": 0.0, "avg_logprob": -0.1572764091884967, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0021153928246349096}, {"id": 834, "seek": 458312, "start": 4595.28, "end": 4603.44, "text": " take up as much mind space and scare like late people and non-experts even more about the technology", "tokens": [50972, 747, 493, 382, 709, 1575, 1901, 293, 17185, 411, 3469, 561, 293, 2107, 12, 3121, 610, 1373, 754, 544, 466, 264, 2899, 51380], "temperature": 0.0, "avg_logprob": -0.1572764091884967, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0021153928246349096}, {"id": 835, "seek": 458312, "start": 4603.44, "end": 4608.16, "text": " that even without consciousness is still going to have major destruction, right? If you're going", "tokens": [51380, 300, 754, 1553, 10081, 307, 920, 516, 281, 362, 2563, 13563, 11, 558, 30, 759, 291, 434, 516, 51616], "temperature": 0.0, "avg_logprob": -0.1572764091884967, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.0021153928246349096}, {"id": 836, "seek": 460816, "start": 4608.16, "end": 4614.8, "text": " through a new step function in human productivity, just like, you know, agriculture versus like", "tokens": [50364, 807, 257, 777, 1823, 2445, 294, 1952, 15604, 11, 445, 411, 11, 291, 458, 11, 14837, 5717, 411, 50696], "temperature": 0.0, "avg_logprob": -0.1088647735252809, "compression_ratio": 1.7212389380530972, "no_speech_prob": 0.10224524140357971}, {"id": 837, "seek": 460816, "start": 4614.8, "end": 4619.92, "text": " hunting and gathering and the steam engine and electricity and internet, like this one's going", "tokens": [50696, 12599, 293, 13519, 293, 264, 11952, 2848, 293, 10356, 293, 4705, 11, 411, 341, 472, 311, 516, 50952], "temperature": 0.0, "avg_logprob": -0.1088647735252809, "compression_ratio": 1.7212389380530972, "no_speech_prob": 0.10224524140357971}, {"id": 838, "seek": 460816, "start": 4619.92, "end": 4626.08, "text": " to be even bigger. It's going to disrupt and change the job landscape a lot. I think at the end of it", "tokens": [50952, 281, 312, 754, 3801, 13, 467, 311, 516, 281, 14124, 293, 1319, 264, 1691, 9661, 257, 688, 13, 286, 519, 412, 264, 917, 295, 309, 51260], "temperature": 0.0, "avg_logprob": -0.1088647735252809, "compression_ratio": 1.7212389380530972, "no_speech_prob": 0.10224524140357971}, {"id": 839, "seek": 460816, "start": 4626.08, "end": 4632.32, "text": " will be way more productive. There's going to be way more productivity per person and hence more", "tokens": [51260, 486, 312, 636, 544, 13304, 13, 821, 311, 516, 281, 312, 636, 544, 15604, 680, 954, 293, 16678, 544, 51572], "temperature": 0.0, "avg_logprob": -0.1088647735252809, "compression_ratio": 1.7212389380530972, "no_speech_prob": 0.10224524140357971}, {"id": 840, "seek": 463232, "start": 4632.32, "end": 4638.32, "text": " wells and new jobs will come around as full jobs get all needed. But that is already so massively", "tokens": [50364, 30984, 293, 777, 4782, 486, 808, 926, 382, 1577, 4782, 483, 439, 2978, 13, 583, 300, 307, 1217, 370, 29379, 50664], "temperature": 0.0, "avg_logprob": -0.217759370803833, "compression_ratio": 1.7560240963855422, "no_speech_prob": 0.28128305077552795}, {"id": 841, "seek": 463232, "start": 4638.32, "end": 4642.719999999999, "text": " disruptive still. And it's not going to happen overnight either. People think, oh, it's going to", "tokens": [50664, 37865, 920, 13, 400, 309, 311, 406, 516, 281, 1051, 13935, 2139, 13, 3432, 519, 11, 1954, 11, 309, 311, 516, 281, 50884], "temperature": 0.0, "avg_logprob": -0.217759370803833, "compression_ratio": 1.7560240963855422, "no_speech_prob": 0.28128305077552795}, {"id": 842, "seek": 463232, "start": 4642.719999999999, "end": 4646.639999999999, "text": " be capacity. Yes, it will be faster, but still not overnight. There are still companies that aren't", "tokens": [50884, 312, 6042, 13, 1079, 11, 309, 486, 312, 4663, 11, 457, 920, 406, 13935, 13, 821, 366, 920, 3431, 300, 3212, 380, 51080], "temperature": 0.0, "avg_logprob": -0.217759370803833, "compression_ratio": 1.7560240963855422, "no_speech_prob": 0.28128305077552795}, {"id": 843, "seek": 463232, "start": 4646.639999999999, "end": 4651.04, "text": " even on the cloud. There are some stretches in the United States and even Germany that don't have", "tokens": [51080, 754, 322, 264, 4588, 13, 821, 366, 512, 29058, 294, 264, 2824, 3040, 293, 754, 7244, 300, 500, 380, 362, 51300], "temperature": 0.0, "avg_logprob": -0.217759370803833, "compression_ratio": 1.7560240963855422, "no_speech_prob": 0.28128305077552795}, {"id": 844, "seek": 463232, "start": 4651.04, "end": 4655.5199999999995, "text": " full internet connectivity, right? It's just like, so things will take time and not happen overnight,", "tokens": [51300, 1577, 4705, 21095, 11, 558, 30, 467, 311, 445, 411, 11, 370, 721, 486, 747, 565, 293, 406, 1051, 13935, 11, 51524], "temperature": 0.0, "avg_logprob": -0.217759370803833, "compression_ratio": 1.7560240963855422, "no_speech_prob": 0.28128305077552795}, {"id": 845, "seek": 463232, "start": 4655.5199999999995, "end": 4660.4, "text": " but they will be happening even faster than past past technological revolutions. And so,", "tokens": [51524, 457, 436, 486, 312, 2737, 754, 4663, 813, 1791, 1791, 18439, 3698, 15892, 13, 400, 370, 11, 51768], "temperature": 0.0, "avg_logprob": -0.217759370803833, "compression_ratio": 1.7560240963855422, "no_speech_prob": 0.28128305077552795}, {"id": 846, "seek": 466040, "start": 4660.96, "end": 4667.44, "text": " and then you have brought up LMS and proteins. There's a great example for where regulation", "tokens": [50392, 293, 550, 291, 362, 3038, 493, 441, 10288, 293, 15577, 13, 821, 311, 257, 869, 1365, 337, 689, 15062, 50716], "temperature": 0.0, "avg_logprob": -0.23340586530483834, "compression_ratio": 1.7115987460815048, "no_speech_prob": 0.011681757867336273}, {"id": 847, "seek": 466040, "start": 4667.44, "end": 4671.44, "text": " makes sense. Like, basically, the concern here for those who are not familiar with proteins,", "tokens": [50716, 1669, 2020, 13, 1743, 11, 1936, 11, 264, 3136, 510, 337, 729, 567, 366, 406, 4963, 365, 15577, 11, 50916], "temperature": 0.0, "avg_logprob": -0.23340586530483834, "compression_ratio": 1.7115987460815048, "no_speech_prob": 0.011681757867336273}, {"id": 848, "seek": 466040, "start": 4671.44, "end": 4675.759999999999, "text": " having everything in life and disease and sickness, COVID, protein, like everything", "tokens": [50916, 1419, 1203, 294, 993, 293, 4752, 293, 25611, 11, 4566, 11, 7944, 11, 411, 1203, 51132], "temperature": 0.0, "avg_logprob": -0.23340586530483834, "compression_ratio": 1.7115987460815048, "no_speech_prob": 0.011681757867336273}, {"id": 849, "seek": 466040, "start": 4675.759999999999, "end": 4680.08, "text": " SARS broke through and like everything is governed by proteins. So if you have a great", "tokens": [51132, 34233, 6902, 807, 293, 411, 1203, 307, 35529, 538, 15577, 13, 407, 498, 291, 362, 257, 869, 51348], "temperature": 0.0, "avg_logprob": -0.23340586530483834, "compression_ratio": 1.7115987460815048, "no_speech_prob": 0.011681757867336273}, {"id": 850, "seek": 466040, "start": 4680.08, "end": 4686.0, "text": " understanding of proteins, we can build fantastical, amazing things. Here's just one example of a", "tokens": [51348, 3701, 295, 15577, 11, 321, 393, 1322, 30665, 804, 11, 2243, 721, 13, 1692, 311, 445, 472, 1365, 295, 257, 51644], "temperature": 0.0, "avg_logprob": -0.23340586530483834, "compression_ratio": 1.7115987460815048, "no_speech_prob": 0.011681757867336273}, {"id": 851, "seek": 466040, "start": 4686.0, "end": 4690.0, "text": " research paper I read a few months ago that just blew my mind and made me very excited about", "tokens": [51644, 2132, 3035, 286, 1401, 257, 1326, 2493, 2057, 300, 445, 19075, 452, 1575, 293, 1027, 385, 588, 2919, 466, 51844], "temperature": 0.0, "avg_logprob": -0.23340586530483834, "compression_ratio": 1.7115987460815048, "no_speech_prob": 0.011681757867336273}, {"id": 852, "seek": 469000, "start": 4690.0, "end": 4696.8, "text": " the future. There's this group of researchers that built these carbon nanotubes. And on one side", "tokens": [50364, 264, 2027, 13, 821, 311, 341, 1594, 295, 10309, 300, 3094, 613, 5954, 14067, 310, 836, 279, 13, 400, 322, 472, 1252, 50704], "temperature": 0.0, "avg_logprob": -0.06713837506819745, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.005058863200247288}, {"id": 853, "seek": 469000, "start": 4696.8, "end": 4702.16, "text": " of the carbon nanotubes, they put iron molecules. And on the other side of these tiny, tiny carbon", "tokens": [50704, 295, 264, 5954, 14067, 310, 836, 279, 11, 436, 829, 6497, 13093, 13, 400, 322, 264, 661, 1252, 295, 613, 5870, 11, 5870, 5954, 50972], "temperature": 0.0, "avg_logprob": -0.06713837506819745, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.005058863200247288}, {"id": 854, "seek": 469000, "start": 4702.16, "end": 4708.64, "text": " nanotubes, they put protein that would only bind to a brain cancer cell. And then they injected", "tokens": [50972, 14067, 310, 836, 279, 11, 436, 829, 7944, 300, 576, 787, 14786, 281, 257, 3567, 5592, 2815, 13, 400, 550, 436, 36967, 51296], "temperature": 0.0, "avg_logprob": -0.06713837506819745, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.005058863200247288}, {"id": 855, "seek": 469000, "start": 4708.64, "end": 4713.28, "text": " this fluid with all these little carbon nanotubes into a mouse brain that had brain cancer.", "tokens": [51296, 341, 9113, 365, 439, 613, 707, 5954, 14067, 310, 836, 279, 666, 257, 9719, 3567, 300, 632, 3567, 5592, 13, 51528], "temperature": 0.0, "avg_logprob": -0.06713837506819745, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.005058863200247288}, {"id": 856, "seek": 471328, "start": 4714.08, "end": 4720.5599999999995, "text": " The proteins found the brain tumor cells and only connected to those specific types of", "tokens": [50404, 440, 15577, 1352, 264, 3567, 22512, 5438, 293, 787, 4582, 281, 729, 2685, 3467, 295, 50728], "temperature": 0.0, "avg_logprob": -0.11593963903024657, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.03567364439368248}, {"id": 857, "seek": 471328, "start": 4720.5599999999995, "end": 4725.599999999999, "text": " brain cancer cells. And then they put the mouse into a little magnetic field and there's the", "tokens": [50728, 3567, 5592, 5438, 13, 400, 550, 436, 829, 264, 9719, 666, 257, 707, 12688, 2519, 293, 456, 311, 264, 50980], "temperature": 0.0, "avg_logprob": -0.11593963903024657, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.03567364439368248}, {"id": 858, "seek": 471328, "start": 4725.599999999999, "end": 4730.0, "text": " iron molecule on the other side of the carbon nanotube that started spinning around and had", "tokens": [50980, 6497, 15582, 322, 264, 661, 1252, 295, 264, 5954, 14067, 310, 1977, 300, 1409, 15640, 926, 293, 632, 51200], "temperature": 0.0, "avg_logprob": -0.11593963903024657, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.03567364439368248}, {"id": 859, "seek": 471328, "start": 4730.0, "end": 4737.2, "text": " nano surgery on each brain cancer cell. Now, if you think about, we have the full console of the", "tokens": [51200, 30129, 7930, 322, 1184, 3567, 5592, 2815, 13, 823, 11, 498, 291, 519, 466, 11, 321, 362, 264, 1577, 11076, 295, 264, 51560], "temperature": 0.0, "avg_logprob": -0.11593963903024657, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.03567364439368248}, {"id": 860, "seek": 471328, "start": 4737.2, "end": 4741.04, "text": " proteins, we can connect them to all kinds of things and you find ways to, you know, get rid of", "tokens": [51560, 15577, 11, 321, 393, 1745, 552, 281, 439, 3685, 295, 721, 293, 291, 915, 2098, 281, 11, 291, 458, 11, 483, 3973, 295, 51752], "temperature": 0.0, "avg_logprob": -0.11593963903024657, "compression_ratio": 1.7509433962264151, "no_speech_prob": 0.03567364439368248}, {"id": 861, "seek": 474104, "start": 4741.12, "end": 4746.72, "text": " the carbon nanotubes afterwards. It's all like medicine is going to change in so many positive", "tokens": [50368, 264, 5954, 14067, 310, 836, 279, 10543, 13, 467, 311, 439, 411, 7195, 307, 516, 281, 1319, 294, 370, 867, 3353, 50648], "temperature": 0.0, "avg_logprob": -0.14975112279256184, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.02757321298122406}, {"id": 862, "seek": 474104, "start": 4746.72, "end": 4752.72, "text": " ways. And now you could argue, well, but proteins, people could use them and build like very bad", "tokens": [50648, 2098, 13, 400, 586, 291, 727, 9695, 11, 731, 11, 457, 15577, 11, 561, 727, 764, 552, 293, 1322, 411, 588, 1578, 50948], "temperature": 0.0, "avg_logprob": -0.14975112279256184, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.02757321298122406}, {"id": 863, "seek": 474104, "start": 4752.72, "end": 4758.0, "text": " like viruses. And like, that's true. And that can be outlawed. In fact, the US just a couple of", "tokens": [50948, 411, 21785, 13, 400, 411, 11, 300, 311, 2074, 13, 400, 300, 393, 312, 484, 5901, 292, 13, 682, 1186, 11, 264, 2546, 445, 257, 1916, 295, 51212], "temperature": 0.0, "avg_logprob": -0.14975112279256184, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.02757321298122406}, {"id": 864, "seek": 474104, "start": 4758.0, "end": 4764.08, "text": " months ago outlawed being a function where you know, some researchers want to make even more", "tokens": [51212, 2493, 2057, 484, 5901, 292, 885, 257, 2445, 689, 291, 458, 11, 512, 10309, 528, 281, 652, 754, 544, 51516], "temperature": 0.0, "avg_logprob": -0.14975112279256184, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.02757321298122406}, {"id": 865, "seek": 474104, "start": 4764.08, "end": 4767.6, "text": " deadlier viruses. And it's not because they're like evil scientists who want to destroy the", "tokens": [51516, 3116, 2753, 21785, 13, 400, 309, 311, 406, 570, 436, 434, 411, 6724, 7708, 567, 528, 281, 5293, 264, 51692], "temperature": 0.0, "avg_logprob": -0.14975112279256184, "compression_ratio": 1.673758865248227, "no_speech_prob": 0.02757321298122406}, {"id": 866, "seek": 476760, "start": 4767.6, "end": 4772.320000000001, "text": " world. It's just they're saying like, well, as we know how they worked before they appear in", "tokens": [50364, 1002, 13, 467, 311, 445, 436, 434, 1566, 411, 11, 731, 11, 382, 321, 458, 577, 436, 2732, 949, 436, 4204, 294, 50600], "temperature": 0.0, "avg_logprob": -0.1526136474609375, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.009411105886101723}, {"id": 867, "seek": 476760, "start": 4772.320000000001, "end": 4777.04, "text": " nature by themselves, then we can all right now prevent like, develop cures for them. So, you", "tokens": [50600, 3687, 538, 2969, 11, 550, 321, 393, 439, 558, 586, 4871, 411, 11, 1499, 269, 1303, 337, 552, 13, 407, 11, 291, 50836], "temperature": 0.0, "avg_logprob": -0.1526136474609375, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.009411105886101723}, {"id": 868, "seek": 476760, "start": 4777.04, "end": 4781.52, "text": " know, it's like, it's a complex question, but yes, and decided like, for now, it's not worth it.", "tokens": [50836, 458, 11, 309, 311, 411, 11, 309, 311, 257, 3997, 1168, 11, 457, 2086, 11, 293, 3047, 411, 11, 337, 586, 11, 309, 311, 406, 3163, 309, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1526136474609375, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.009411105886101723}, {"id": 869, "seek": 476760, "start": 4781.52, "end": 4787.68, "text": " Let's outlaw it. And likewise, I don't think an open source like protein model is going to be", "tokens": [51060, 961, 311, 484, 5901, 309, 13, 400, 32407, 11, 286, 500, 380, 519, 364, 1269, 4009, 411, 7944, 2316, 307, 516, 281, 312, 51368], "temperature": 0.0, "avg_logprob": -0.1526136474609375, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.009411105886101723}, {"id": 870, "seek": 476760, "start": 4787.68, "end": 4791.92, "text": " the main deciding factor of being able to create something virus. Because if you have all the", "tokens": [51368, 264, 2135, 17990, 5952, 295, 885, 1075, 281, 1884, 746, 5752, 13, 1436, 498, 291, 362, 439, 264, 51580], "temperature": 0.0, "avg_logprob": -0.1526136474609375, "compression_ratio": 1.6411149825783973, "no_speech_prob": 0.009411105886101723}, {"id": 871, "seek": 479192, "start": 4791.92, "end": 4798.24, "text": " wet lab experimentation to be able to create new kinds of viruses, you can also just do what", "tokens": [50364, 6630, 2715, 37142, 281, 312, 1075, 281, 1884, 777, 3685, 295, 21785, 11, 291, 393, 611, 445, 360, 437, 50680], "temperature": 0.0, "avg_logprob": -0.10748567127046131, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.05663584545254707}, {"id": 872, "seek": 479192, "start": 4798.24, "end": 4802.56, "text": " census Arnold did when she won the Nobel Prize a couple years ago in chemistry, which is", "tokens": [50680, 23725, 30406, 630, 562, 750, 1582, 264, 24611, 22604, 257, 1916, 924, 2057, 294, 12558, 11, 597, 307, 50896], "temperature": 0.0, "avg_logprob": -0.10748567127046131, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.05663584545254707}, {"id": 873, "seek": 479192, "start": 4802.56, "end": 4807.04, "text": " what she called directed evolution, but it was basically random permutations. And then", "tokens": [50896, 437, 750, 1219, 12898, 9303, 11, 457, 309, 390, 1936, 4974, 4784, 325, 763, 13, 400, 550, 51120], "temperature": 0.0, "avg_logprob": -0.10748567127046131, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.05663584545254707}, {"id": 874, "seek": 479192, "start": 4807.04, "end": 4812.72, "text": " running an experimental pipeline to see if that random permutation works better or not for particular", "tokens": [51120, 2614, 364, 17069, 15517, 281, 536, 498, 300, 4974, 4784, 11380, 1985, 1101, 420, 406, 337, 1729, 51404], "temperature": 0.0, "avg_logprob": -0.10748567127046131, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.05663584545254707}, {"id": 875, "seek": 479192, "start": 4812.72, "end": 4818.0, "text": " kind of protein. And then you just keep iterating like that. And so if you have those capabilities,", "tokens": [51404, 733, 295, 7944, 13, 400, 550, 291, 445, 1066, 17138, 990, 411, 300, 13, 400, 370, 498, 291, 362, 729, 10862, 11, 51668], "temperature": 0.0, "avg_logprob": -0.10748567127046131, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.05663584545254707}, {"id": 876, "seek": 481800, "start": 4818.08, "end": 4822.4, "text": " you have a random permutation, you can do bad things. But it turns out having like a legit", "tokens": [50368, 291, 362, 257, 4974, 4784, 11380, 11, 291, 393, 360, 1578, 721, 13, 583, 309, 4523, 484, 1419, 411, 257, 10275, 50584], "temperature": 0.0, "avg_logprob": -0.3178710306971526, "compression_ratio": 1.6048951048951048, "no_speech_prob": 0.04671188443899155}, {"id": 877, "seek": 481800, "start": 4822.4, "end": 4827.36, "text": " weapon like that, that's to do all of that. So that was your PDUM integral, LM and proteins,", "tokens": [50584, 7463, 411, 300, 11, 300, 311, 281, 360, 439, 295, 300, 13, 407, 300, 390, 428, 10464, 14340, 11573, 11, 46529, 293, 15577, 11, 50832], "temperature": 0.0, "avg_logprob": -0.3178710306971526, "compression_ratio": 1.6048951048951048, "no_speech_prob": 0.04671188443899155}, {"id": 878, "seek": 481800, "start": 4827.36, "end": 4831.84, "text": " AI agency emergence. So obviously, emerging capabilities are incredible on that sort of", "tokens": [50832, 7318, 7934, 36211, 13, 407, 2745, 11, 14989, 10862, 366, 4651, 322, 300, 1333, 295, 51056], "temperature": 0.0, "avg_logprob": -0.3178710306971526, "compression_ratio": 1.6048951048951048, "no_speech_prob": 0.04671188443899155}, {"id": 879, "seek": 481800, "start": 4831.84, "end": 4838.16, "text": " like, even us like working in deep learning, or I'm amazed, just like you.com, I asked these", "tokens": [51056, 411, 11, 754, 505, 411, 1364, 294, 2452, 2539, 11, 420, 286, 478, 20507, 11, 445, 411, 291, 13, 1112, 11, 286, 2351, 613, 51372], "temperature": 0.0, "avg_logprob": -0.3178710306971526, "compression_ratio": 1.6048951048951048, "no_speech_prob": 0.04671188443899155}, {"id": 880, "seek": 481800, "start": 4838.16, "end": 4843.44, "text": " questions, I'm like, wow, actually, that's right, like, I would have not to like, thought this", "tokens": [51372, 1651, 11, 286, 478, 411, 11, 6076, 11, 767, 11, 300, 311, 558, 11, 411, 11, 286, 576, 362, 406, 281, 411, 11, 1194, 341, 51636], "temperature": 0.0, "avg_logprob": -0.3178710306971526, "compression_ratio": 1.6048951048951048, "no_speech_prob": 0.04671188443899155}, {"id": 881, "seek": 484344, "start": 4843.5199999999995, "end": 4848.719999999999, "text": " was possible. And sometimes we were like, did you program it specifically for it to be able to", "tokens": [50368, 390, 1944, 13, 400, 2171, 321, 645, 411, 11, 630, 291, 1461, 309, 4682, 337, 309, 281, 312, 1075, 281, 50628], "temperature": 0.0, "avg_logprob": -0.12604427337646484, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.1479579657316208}, {"id": 882, "seek": 484344, "start": 4848.719999999999, "end": 4852.48, "text": " answer these kinds of questions about headphones or something? We're like, no, it's just like,", "tokens": [50628, 1867, 613, 3685, 295, 1651, 466, 16278, 420, 746, 30, 492, 434, 411, 11, 572, 11, 309, 311, 445, 411, 11, 50816], "temperature": 0.0, "avg_logprob": -0.12604427337646484, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.1479579657316208}, {"id": 883, "seek": 484344, "start": 4852.48, "end": 4858.0, "text": " just put that all together, just by trying to predict the next token. So I'm really excited.", "tokens": [50816, 445, 829, 300, 439, 1214, 11, 445, 538, 1382, 281, 6069, 264, 958, 14862, 13, 407, 286, 478, 534, 2919, 13, 51092], "temperature": 0.0, "avg_logprob": -0.12604427337646484, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.1479579657316208}, {"id": 884, "seek": 484344, "start": 4858.0, "end": 4861.679999999999, "text": " And one of the things I'm excited about this pudding, and one of the things that coding", "tokens": [51092, 400, 472, 295, 264, 721, 286, 478, 2919, 466, 341, 29149, 11, 293, 472, 295, 264, 721, 300, 17720, 51276], "temperature": 0.0, "avg_logprob": -0.12604427337646484, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.1479579657316208}, {"id": 885, "seek": 484344, "start": 4861.679999999999, "end": 4868.0, "text": " enables is now is the last part of your question, the actions. I think actions are clearly in the", "tokens": [51276, 17077, 307, 586, 307, 264, 1036, 644, 295, 428, 1168, 11, 264, 5909, 13, 286, 519, 5909, 366, 4448, 294, 264, 51592], "temperature": 0.0, "avg_logprob": -0.12604427337646484, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.1479579657316208}, {"id": 886, "seek": 486800, "start": 4868.0, "end": 4874.56, "text": " future. And for now, we're focused on amazing answers. But it's not hard to imagine that at", "tokens": [50364, 2027, 13, 400, 337, 586, 11, 321, 434, 5178, 322, 2243, 6338, 13, 583, 309, 311, 406, 1152, 281, 3811, 300, 412, 50692], "temperature": 0.0, "avg_logprob": -0.08756331101204586, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.033577412366867065}, {"id": 887, "seek": 486800, "start": 4874.56, "end": 4881.6, "text": " some point, the most amazing answer is done. I did, I did what you asked to do. And instead of", "tokens": [50692, 512, 935, 11, 264, 881, 2243, 1867, 307, 1096, 13, 286, 630, 11, 286, 630, 437, 291, 2351, 281, 360, 13, 400, 2602, 295, 51044], "temperature": 0.0, "avg_logprob": -0.08756331101204586, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.033577412366867065}, {"id": 888, "seek": 486800, "start": 4881.6, "end": 4888.32, "text": " telling you how to do it, I just, right, you can build a really cool demo very quickly for these", "tokens": [51044, 3585, 291, 577, 281, 360, 309, 11, 286, 445, 11, 558, 11, 291, 393, 1322, 257, 534, 1627, 10723, 588, 2661, 337, 613, 51380], "temperature": 0.0, "avg_logprob": -0.08756331101204586, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.033577412366867065}, {"id": 889, "seek": 486800, "start": 4888.32, "end": 4893.12, "text": " kinds of things. But the problem is like, as much as I love natural language, and as much as I love", "tokens": [51380, 3685, 295, 721, 13, 583, 264, 1154, 307, 411, 11, 382, 709, 382, 286, 959, 3303, 2856, 11, 293, 382, 709, 382, 286, 959, 51620], "temperature": 0.0, "avg_logprob": -0.08756331101204586, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.033577412366867065}, {"id": 890, "seek": 489312, "start": 4893.12, "end": 4898.08, "text": " chatbots and everything, right, you have to find some really killer use cases for it. And", "tokens": [50364, 5081, 65, 1971, 293, 1203, 11, 558, 11, 291, 362, 281, 915, 512, 534, 13364, 764, 3331, 337, 309, 13, 400, 50612], "temperature": 0.0, "avg_logprob": -0.13911335967307867, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.19919604063034058}, {"id": 891, "seek": 489312, "start": 4898.08, "end": 4902.96, "text": " to say, oh, I can book this flight, it's actually really hard to just, just book the flight. Like,", "tokens": [50612, 281, 584, 11, 1954, 11, 286, 393, 1446, 341, 7018, 11, 309, 311, 767, 534, 1152, 281, 445, 11, 445, 1446, 264, 7018, 13, 1743, 11, 50856], "temperature": 0.0, "avg_logprob": -0.13911335967307867, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.19919604063034058}, {"id": 892, "seek": 489312, "start": 4902.96, "end": 4907.04, "text": " you're like, why didn't you like pick this other one that was just like, not exactly the time I", "tokens": [50856, 291, 434, 411, 11, 983, 994, 380, 291, 411, 1888, 341, 661, 472, 300, 390, 445, 411, 11, 406, 2293, 264, 565, 286, 51060], "temperature": 0.0, "avg_logprob": -0.13911335967307867, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.19919604063034058}, {"id": 893, "seek": 489312, "start": 4907.04, "end": 4912.5599999999995, "text": " asked for it, but I could have waited for half an hour at this like, extra leg, and then like,", "tokens": [51060, 2351, 337, 309, 11, 457, 286, 727, 362, 15240, 337, 1922, 364, 1773, 412, 341, 411, 11, 2857, 1676, 11, 293, 550, 411, 11, 51336], "temperature": 0.0, "avg_logprob": -0.13911335967307867, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.19919604063034058}, {"id": 894, "seek": 489312, "start": 4912.5599999999995, "end": 4918.8, "text": " say 50 bucks, like that was really dumb. And like, it turns out, Expedia and others have built", "tokens": [51336, 584, 2625, 11829, 11, 411, 300, 390, 534, 10316, 13, 400, 411, 11, 309, 4523, 484, 11, 48603, 654, 293, 2357, 362, 3094, 51648], "temperature": 0.0, "avg_logprob": -0.13911335967307867, "compression_ratio": 1.72992700729927, "no_speech_prob": 0.19919604063034058}, {"id": 895, "seek": 491880, "start": 4918.8, "end": 4925.360000000001, "text": " for decades, the perfect interface for that problem, so that humans have all the installation", "tokens": [50364, 337, 7878, 11, 264, 2176, 9226, 337, 300, 1154, 11, 370, 300, 6255, 362, 439, 264, 13260, 50692], "temperature": 0.0, "avg_logprob": -0.2114116797286473, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0034827226772904396}, {"id": 896, "seek": 491880, "start": 4925.360000000001, "end": 4931.2, "text": " right there in a visual way. And so there's an uncanny valley of, there's a cool tech demo.", "tokens": [50692, 558, 456, 294, 257, 5056, 636, 13, 400, 370, 456, 311, 364, 6219, 11612, 17636, 295, 11, 456, 311, 257, 1627, 7553, 10723, 13, 50984], "temperature": 0.0, "avg_logprob": -0.2114116797286473, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0034827226772904396}, {"id": 897, "seek": 491880, "start": 4931.76, "end": 4937.28, "text": " And on one side, and then there's like, my actual human assistant, who after months of", "tokens": [51012, 400, 322, 472, 1252, 11, 293, 550, 456, 311, 411, 11, 452, 3539, 1952, 10994, 11, 567, 934, 2493, 295, 51288], "temperature": 0.0, "avg_logprob": -0.2114116797286473, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0034827226772904396}, {"id": 898, "seek": 491880, "start": 4937.28, "end": 4942.0, "text": " I mean, like talking to me, understand all the trade offs, and understand my price", "tokens": [51288, 286, 914, 11, 411, 1417, 281, 385, 11, 1223, 439, 264, 4923, 39457, 11, 293, 1223, 452, 3218, 51524], "temperature": 0.0, "avg_logprob": -0.2114116797286473, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0034827226772904396}, {"id": 899, "seek": 494200, "start": 4942.0, "end": 4947.2, "text": " sensitivity, or that of my company, and knows like, when I would preserve and like,", "tokens": [50364, 19392, 11, 420, 300, 295, 452, 2237, 11, 293, 3255, 411, 11, 562, 286, 576, 15665, 293, 411, 11, 50624], "temperature": 0.0, "avg_logprob": -0.2062184621417333, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.48024654388427734}, {"id": 900, "seek": 494200, "start": 4947.2, "end": 4953.52, "text": " all the like, reasons why I might do it overnight, like red-eye slides, and, you know, all the,", "tokens": [50624, 439, 264, 411, 11, 4112, 983, 286, 1062, 360, 309, 13935, 11, 411, 2182, 12, 25488, 9788, 11, 293, 11, 291, 458, 11, 439, 264, 11, 50940], "temperature": 0.0, "avg_logprob": -0.2062184621417333, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.48024654388427734}, {"id": 901, "seek": 494200, "start": 4953.52, "end": 4957.84, "text": " all the constraints, and she can do it. And even then, sometimes she's like, oh, Richard,", "tokens": [50940, 439, 264, 18491, 11, 293, 750, 393, 360, 309, 13, 400, 754, 550, 11, 2171, 750, 311, 411, 11, 1954, 11, 9809, 11, 51156], "temperature": 0.0, "avg_logprob": -0.2062184621417333, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.48024654388427734}, {"id": 902, "seek": 494200, "start": 4957.84, "end": 4962.64, "text": " there are like three options here, like, let me know which one you prefer out of this 5000,", "tokens": [51156, 456, 366, 411, 1045, 3956, 510, 11, 411, 11, 718, 385, 458, 597, 472, 291, 4382, 484, 295, 341, 23777, 11, 51396], "temperature": 0.0, "avg_logprob": -0.2062184621417333, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.48024654388427734}, {"id": 903, "seek": 494200, "start": 4962.64, "end": 4967.68, "text": " if you built it for you. And like, it's very hard to do all of that with just text. That's", "tokens": [51396, 498, 291, 3094, 309, 337, 291, 13, 400, 411, 11, 309, 311, 588, 1152, 281, 360, 439, 295, 300, 365, 445, 2487, 13, 663, 311, 51648], "temperature": 0.0, "avg_logprob": -0.2062184621417333, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.48024654388427734}, {"id": 904, "seek": 496768, "start": 4967.76, "end": 4972.240000000001, "text": " ultimately, I think, part of why we have the stock ticker app and so on, and why we have", "tokens": [50368, 6284, 11, 286, 519, 11, 644, 295, 983, 321, 362, 264, 4127, 5204, 260, 724, 293, 370, 322, 11, 293, 983, 321, 362, 50592], "temperature": 0.0, "avg_logprob": -0.16711422464121942, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.004754967987537384}, {"id": 905, "seek": 496768, "start": 4972.240000000001, "end": 4979.04, "text": " religious now, and in some cases also, is that sometimes like UI UX and actual visually designed", "tokens": [50592, 7185, 586, 11, 293, 294, 512, 3331, 611, 11, 307, 300, 2171, 411, 15682, 40176, 293, 3539, 19622, 4761, 50932], "temperature": 0.0, "avg_logprob": -0.16711422464121942, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.004754967987537384}, {"id": 906, "seek": 496768, "start": 4979.04, "end": 4985.4400000000005, "text": " like interfaces are best used in combination with language. Maybe one more big picture question,", "tokens": [50932, 411, 28416, 366, 1151, 1143, 294, 6562, 365, 2856, 13, 2704, 472, 544, 955, 3036, 1168, 11, 51252], "temperature": 0.0, "avg_logprob": -0.16711422464121942, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.004754967987537384}, {"id": 907, "seek": 496768, "start": 4985.4400000000005, "end": 4989.6, "text": " and then I want to do just a real quick lightning round on a couple kind of more technical areas", "tokens": [51252, 293, 550, 286, 528, 281, 360, 445, 257, 957, 1702, 16589, 3098, 322, 257, 1916, 733, 295, 544, 6191, 3179, 51460], "temperature": 0.0, "avg_logprob": -0.16711422464121942, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.004754967987537384}, {"id": 908, "seek": 496768, "start": 4989.6, "end": 4994.4800000000005, "text": " before we run out of time. On the big picture side, you know, we've got Sam Altman out there", "tokens": [51460, 949, 321, 1190, 484, 295, 565, 13, 1282, 264, 955, 3036, 1252, 11, 291, 458, 11, 321, 600, 658, 4832, 15992, 1601, 484, 456, 51704], "temperature": 0.0, "avg_logprob": -0.16711422464121942, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.004754967987537384}, {"id": 909, "seek": 499448, "start": 4994.48, "end": 4999.599999999999, "text": " saying AGI is coming soon, but also kind of confusingly saying, but it'll be less impactful", "tokens": [50364, 1566, 316, 26252, 307, 1348, 2321, 11, 457, 611, 733, 295, 13181, 356, 1566, 11, 457, 309, 603, 312, 1570, 30842, 50620], "temperature": 0.0, "avg_logprob": -0.07272855509882388, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.039634183049201965}, {"id": 910, "seek": 499448, "start": 4999.599999999999, "end": 5006.639999999999, "text": " than you might think. Not really sure how to interpret that. The median guess on, you know,", "tokens": [50620, 813, 291, 1062, 519, 13, 1726, 534, 988, 577, 281, 7302, 300, 13, 440, 26779, 2041, 322, 11, 291, 458, 11, 50972], "temperature": 0.0, "avg_logprob": -0.07272855509882388, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.039634183049201965}, {"id": 911, "seek": 499448, "start": 5006.639999999999, "end": 5011.919999999999, "text": " some definition of AGI is like, just a few years on some prediction markets and more like,", "tokens": [50972, 512, 7123, 295, 316, 26252, 307, 411, 11, 445, 257, 1326, 924, 322, 512, 17630, 8383, 293, 544, 411, 11, 51236], "temperature": 0.0, "avg_logprob": -0.07272855509882388, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.039634183049201965}, {"id": 912, "seek": 499448, "start": 5011.919999999999, "end": 5018.08, "text": " you know, 12 years or whatever for a stronger definition. What do you have sort of an expectation", "tokens": [51236, 291, 458, 11, 2272, 924, 420, 2035, 337, 257, 7249, 7123, 13, 708, 360, 291, 362, 1333, 295, 364, 14334, 51544], "temperature": 0.0, "avg_logprob": -0.07272855509882388, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.039634183049201965}, {"id": 913, "seek": 499448, "start": 5018.08, "end": 5023.599999999999, "text": " for, and a definition or like a threshold that you have in mind of like, this is the threshold", "tokens": [51544, 337, 11, 293, 257, 7123, 420, 411, 257, 14678, 300, 291, 362, 294, 1575, 295, 411, 11, 341, 307, 264, 14678, 51820], "temperature": 0.0, "avg_logprob": -0.07272855509882388, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.039634183049201965}, {"id": 914, "seek": 502360, "start": 5023.6, "end": 5027.92, "text": " that really matters and, you know, loosely speaking, like what sort of timeline you would", "tokens": [50364, 300, 534, 7001, 293, 11, 291, 458, 11, 37966, 4124, 11, 411, 437, 1333, 295, 12933, 291, 576, 50580], "temperature": 0.0, "avg_logprob": -0.0994845752058358, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0011334264418110251}, {"id": 915, "seek": 502360, "start": 5027.92, "end": 5035.04, "text": " expect it to take to get there? It's very much a, the kind of question where you have to be very", "tokens": [50580, 2066, 309, 281, 747, 281, 483, 456, 30, 467, 311, 588, 709, 257, 11, 264, 733, 295, 1168, 689, 291, 362, 281, 312, 588, 50936], "temperature": 0.0, "avg_logprob": -0.0994845752058358, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0011334264418110251}, {"id": 916, "seek": 502360, "start": 5035.04, "end": 5042.0, "text": " careful about your terminology, because the interpretation of AGI has vastly different", "tokens": [50936, 5026, 466, 428, 27575, 11, 570, 264, 14174, 295, 316, 26252, 575, 41426, 819, 51284], "temperature": 0.0, "avg_logprob": -0.0994845752058358, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0011334264418110251}, {"id": 917, "seek": 502360, "start": 5042.0, "end": 5048.08, "text": " associations. Like people, some people think of AGI and used to think of AGI as this super", "tokens": [51284, 26597, 13, 1743, 561, 11, 512, 561, 519, 295, 316, 26252, 293, 1143, 281, 519, 295, 316, 26252, 382, 341, 1687, 51588], "temperature": 0.0, "avg_logprob": -0.0994845752058358, "compression_ratio": 1.5895196506550218, "no_speech_prob": 0.0011334264418110251}, {"id": 918, "seek": 504808, "start": 5048.08, "end": 5055.84, "text": " intelligence. It's conscious as self-awareness can set its own goals. And it is more intelligent", "tokens": [50364, 7599, 13, 467, 311, 6648, 382, 2698, 12, 17074, 1287, 393, 992, 1080, 1065, 5493, 13, 400, 309, 307, 544, 13232, 50752], "temperature": 0.0, "avg_logprob": -0.16432220285589044, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.04812297224998474}, {"id": 919, "seek": 504808, "start": 5055.84, "end": 5062.08, "text": " than all human beings. And, and that's their depth. That was, that was for a long time. A lot of us,", "tokens": [50752, 813, 439, 1952, 8958, 13, 400, 11, 293, 300, 311, 641, 7161, 13, 663, 390, 11, 300, 390, 337, 257, 938, 565, 13, 316, 688, 295, 505, 11, 51064], "temperature": 0.0, "avg_logprob": -0.16432220285589044, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.04812297224998474}, {"id": 920, "seek": 504808, "start": 5062.08, "end": 5067.76, "text": " I thought, at least for me personally, also the definition. Now people said, and I think it's", "tokens": [51064, 286, 1194, 11, 412, 1935, 337, 385, 5665, 11, 611, 264, 7123, 13, 823, 561, 848, 11, 293, 286, 519, 309, 311, 51348], "temperature": 0.0, "avg_logprob": -0.16432220285589044, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.04812297224998474}, {"id": 921, "seek": 504808, "start": 5067.76, "end": 5072.08, "text": " partially because of marketing, like, you know, you want to be working on AGI, but you also need", "tokens": [51348, 18886, 570, 295, 6370, 11, 411, 11, 291, 458, 11, 291, 528, 281, 312, 1364, 322, 316, 26252, 11, 457, 291, 611, 643, 51564], "temperature": 0.0, "avg_logprob": -0.16432220285589044, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.04812297224998474}, {"id": 922, "seek": 504808, "start": 5072.08, "end": 5076.5599999999995, "text": " to have ship stuff. It's like, you want to be multi-tenetary species, but you also need to just", "tokens": [51564, 281, 362, 5374, 1507, 13, 467, 311, 411, 11, 291, 528, 281, 312, 4825, 12, 1147, 302, 822, 6172, 11, 457, 291, 611, 643, 281, 445, 51788], "temperature": 0.0, "avg_logprob": -0.16432220285589044, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.04812297224998474}, {"id": 923, "seek": 507656, "start": 5076.56, "end": 5080.4800000000005, "text": " get a lot of stuff in orbit, right? Let have more satellites and better internet connectivity,", "tokens": [50364, 483, 257, 688, 295, 1507, 294, 13991, 11, 558, 30, 961, 362, 544, 24960, 293, 1101, 4705, 21095, 11, 50560], "temperature": 0.0, "avg_logprob": -0.17536354064941406, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.009410646744072437}, {"id": 924, "seek": 507656, "start": 5080.4800000000005, "end": 5086.400000000001, "text": " and so on. So you have this long-term vision and the best companies are able to articulate that", "tokens": [50560, 293, 370, 322, 13, 407, 291, 362, 341, 938, 12, 7039, 5201, 293, 264, 1151, 3431, 366, 1075, 281, 30305, 300, 50856], "temperature": 0.0, "avg_logprob": -0.17536354064941406, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.009410646744072437}, {"id": 925, "seek": 507656, "start": 5086.400000000001, "end": 5091.84, "text": " long-term vision and then revenue generated progress in smaller milestones towards it. And so", "tokens": [50856, 938, 12, 7039, 5201, 293, 550, 9324, 10833, 4205, 294, 4356, 42038, 3030, 309, 13, 400, 370, 51128], "temperature": 0.0, "avg_logprob": -0.17536354064941406, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.009410646744072437}, {"id": 926, "seek": 507656, "start": 5092.88, "end": 5099.280000000001, "text": " in this case here, I think the definition of AGI was pulled out. And then the super intelligence", "tokens": [51180, 294, 341, 1389, 510, 11, 286, 519, 264, 7123, 295, 316, 26252, 390, 7373, 484, 13, 400, 550, 264, 1687, 7599, 51500], "temperature": 0.0, "avg_logprob": -0.17536354064941406, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.009410646744072437}, {"id": 927, "seek": 507656, "start": 5099.280000000001, "end": 5104.88, "text": " was defined as like, okay, that's even more than general. It's super. And that's the really long-term", "tokens": [51500, 390, 7642, 382, 411, 11, 1392, 11, 300, 311, 754, 544, 813, 2674, 13, 467, 311, 1687, 13, 400, 300, 311, 264, 534, 938, 12, 7039, 51780], "temperature": 0.0, "avg_logprob": -0.17536354064941406, "compression_ratio": 1.7311827956989247, "no_speech_prob": 0.009410646744072437}, {"id": 928, "seek": 510488, "start": 5104.88, "end": 5111.76, "text": " stuff. And now AGI, it's just basically automating point. And if you define AGI, which I think is", "tokens": [50364, 1507, 13, 400, 586, 316, 26252, 11, 309, 311, 445, 1936, 3553, 990, 935, 13, 400, 498, 291, 6964, 316, 26252, 11, 597, 286, 519, 307, 50708], "temperature": 0.0, "avg_logprob": -0.20215332394554503, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.01168461050838232}, {"id": 929, "seek": 510488, "start": 5111.76, "end": 5117.76, "text": " not crazy, I want to say maybe it would be not post that, which is a very pragmatic sort of", "tokens": [50708, 406, 3219, 11, 286, 528, 281, 584, 1310, 309, 576, 312, 406, 2183, 300, 11, 597, 307, 257, 588, 46904, 1333, 295, 51008], "temperature": 0.0, "avg_logprob": -0.20215332394554503, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.01168461050838232}, {"id": 930, "seek": 510488, "start": 5118.64, "end": 5126.24, "text": " investor slash financial slash economic definition of AGI, which is 80% of the jobs can be automated", "tokens": [51052, 18479, 17330, 4669, 17330, 4836, 7123, 295, 316, 26252, 11, 597, 307, 4688, 4, 295, 264, 4782, 393, 312, 18473, 51432], "temperature": 0.0, "avg_logprob": -0.20215332394554503, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.01168461050838232}, {"id": 931, "seek": 510488, "start": 5126.96, "end": 5133.4400000000005, "text": " up to 80%. And if that's achieved, we'll call it AGI. Turns out there's just a lot of jobs that", "tokens": [51468, 493, 281, 4688, 6856, 400, 498, 300, 311, 11042, 11, 321, 603, 818, 309, 316, 26252, 13, 29524, 484, 456, 311, 445, 257, 688, 295, 4782, 300, 51792], "temperature": 0.0, "avg_logprob": -0.20215332394554503, "compression_ratio": 1.5950413223140496, "no_speech_prob": 0.01168461050838232}, {"id": 932, "seek": 513344, "start": 5133.5199999999995, "end": 5139.36, "text": " are quite repetitive and they're not requiring a ton of extremely novel, out-of-the-box thinking", "tokens": [50368, 366, 1596, 29404, 293, 436, 434, 406, 24165, 257, 2952, 295, 4664, 7613, 11, 484, 12, 2670, 12, 3322, 12, 4995, 1953, 50660], "temperature": 0.0, "avg_logprob": -0.180224853515625, "compression_ratio": 1.6204620462046204, "no_speech_prob": 0.0032722041942179203}, {"id": 933, "seek": 513344, "start": 5139.36, "end": 5145.5199999999995, "text": " that no one's ever done before. And like learning very complex new behaviors, bot-shaking, identifying", "tokens": [50660, 300, 572, 472, 311, 1562, 1096, 949, 13, 400, 411, 2539, 588, 3997, 777, 15501, 11, 10592, 12, 2716, 2456, 11, 16696, 50968], "temperature": 0.0, "avg_logprob": -0.180224853515625, "compression_ratio": 1.6204620462046204, "no_speech_prob": 0.0032722041942179203}, {"id": 934, "seek": 513344, "start": 5145.5199999999995, "end": 5150.96, "text": " new experiments, collecting new data and pushing, you know, the science forward and so on. It turns", "tokens": [50968, 777, 12050, 11, 12510, 777, 1412, 293, 7380, 11, 291, 458, 11, 264, 3497, 2128, 293, 370, 322, 13, 467, 4523, 51240], "temperature": 0.0, "avg_logprob": -0.180224853515625, "compression_ratio": 1.6204620462046204, "no_speech_prob": 0.0032722041942179203}, {"id": 935, "seek": 513344, "start": 5150.96, "end": 5156.4, "text": " out there's just a lot of boring, repetitive jobs. And indeed, if your definition of AGI is just like,", "tokens": [51240, 484, 456, 311, 445, 257, 688, 295, 9989, 11, 29404, 4782, 13, 400, 6451, 11, 498, 428, 7123, 295, 316, 26252, 307, 445, 411, 11, 51512], "temperature": 0.0, "avg_logprob": -0.180224853515625, "compression_ratio": 1.6204620462046204, "no_speech_prob": 0.0032722041942179203}, {"id": 936, "seek": 513344, "start": 5156.4, "end": 5162.719999999999, "text": " well, we can automate like 80% of 80% of the jobs, then I think it's not crazy to assume", "tokens": [51512, 731, 11, 321, 393, 31605, 411, 4688, 4, 295, 4688, 4, 295, 264, 4782, 11, 550, 286, 519, 309, 311, 406, 3219, 281, 6552, 51828], "temperature": 0.0, "avg_logprob": -0.180224853515625, "compression_ratio": 1.6204620462046204, "no_speech_prob": 0.0032722041942179203}, {"id": 937, "seek": 516344, "start": 5163.5199999999995, "end": 5167.44, "text": " especially I would restrict it one on the wall way, which is digitized jobs,", "tokens": [50368, 2318, 286, 576, 7694, 309, 472, 322, 264, 2929, 636, 11, 597, 307, 14293, 1602, 4782, 11, 50564], "temperature": 0.0, "avg_logprob": -0.1779125758579799, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.0005527130560949445}, {"id": 938, "seek": 516344, "start": 5168.16, "end": 5173.04, "text": " jobs that are purely happening in your browser or on your computer, because those jobs can collect", "tokens": [50600, 4782, 300, 366, 17491, 2737, 294, 428, 11185, 420, 322, 428, 3820, 11, 570, 729, 4782, 393, 2500, 50844], "temperature": 0.0, "avg_logprob": -0.1779125758579799, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.0005527130560949445}, {"id": 939, "seek": 516344, "start": 5173.04, "end": 5177.679999999999, "text": " training data at massive scales. Turns out no one's collecting training data for plumbers,", "tokens": [50844, 3097, 1412, 412, 5994, 17408, 13, 29524, 484, 572, 472, 311, 12510, 3097, 1412, 337, 25854, 1616, 11, 51076], "temperature": 0.0, "avg_logprob": -0.1779125758579799, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.0005527130560949445}, {"id": 940, "seek": 516344, "start": 5178.24, "end": 5185.5199999999995, "text": " for woofers, for tylers, for maids, like cleaning tees or any of that. And so none of those jobs", "tokens": [51104, 337, 21657, 69, 433, 11, 337, 1104, 11977, 11, 337, 463, 3742, 11, 411, 8924, 535, 279, 420, 604, 295, 300, 13, 400, 370, 6022, 295, 729, 4782, 51468], "temperature": 0.0, "avg_logprob": -0.1779125758579799, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.0005527130560949445}, {"id": 941, "seek": 516344, "start": 5185.5199999999995, "end": 5189.839999999999, "text": " are going to get automated anytime soon. Because you first have to collect many years of that such", "tokens": [51468, 366, 516, 281, 483, 18473, 13038, 2321, 13, 1436, 291, 700, 362, 281, 2500, 867, 924, 295, 300, 1270, 51684], "temperature": 0.0, "avg_logprob": -0.1779125758579799, "compression_ratio": 1.7174721189591078, "no_speech_prob": 0.0005527130560949445}, {"id": 942, "seek": 518984, "start": 5189.84, "end": 5195.92, "text": " training data before you can then use AI to train on that and then automate it. But, you know,", "tokens": [50364, 3097, 1412, 949, 291, 393, 550, 764, 7318, 281, 3847, 322, 300, 293, 550, 31605, 309, 13, 583, 11, 291, 458, 11, 50668], "temperature": 0.0, "avg_logprob": -0.16224683821201324, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.009411294013261795}, {"id": 943, "seek": 518984, "start": 5195.92, "end": 5201.52, "text": " jobs that are fully digitized and that have a lot of training data that don't have a crazy long tail", "tokens": [50668, 4782, 300, 366, 4498, 14293, 1602, 293, 300, 362, 257, 688, 295, 3097, 1412, 300, 500, 380, 362, 257, 3219, 938, 6838, 50948], "temperature": 0.0, "avg_logprob": -0.16224683821201324, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.009411294013261795}, {"id": 944, "seek": 518984, "start": 5201.52, "end": 5207.2, "text": " of special cases, they're going to get automated. And I think that's reasonable to say that's 80%", "tokens": [50948, 295, 2121, 3331, 11, 436, 434, 516, 281, 483, 18473, 13, 400, 286, 519, 300, 311, 10585, 281, 584, 300, 311, 4688, 4, 51232], "temperature": 0.0, "avg_logprob": -0.16224683821201324, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.009411294013261795}, {"id": 945, "seek": 518984, "start": 5207.2, "end": 5212.400000000001, "text": " of jobs. For hunches, even in radiology, for instance, you could probably do 80% find 80%", "tokens": [51232, 295, 4782, 13, 1171, 47630, 279, 11, 754, 294, 16335, 1793, 11, 337, 5197, 11, 291, 727, 1391, 360, 4688, 4, 915, 4688, 4, 51492], "temperature": 0.0, "avg_logprob": -0.16224683821201324, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.009411294013261795}, {"id": 946, "seek": 518984, "start": 5212.400000000001, "end": 5217.4400000000005, "text": " of things that are wrong in HET's t-stand. But then there's still this very long tail of 20%", "tokens": [51492, 295, 721, 300, 366, 2085, 294, 389, 4850, 311, 256, 12, 1115, 13, 583, 550, 456, 311, 920, 341, 588, 938, 6838, 295, 945, 4, 51744], "temperature": 0.0, "avg_logprob": -0.16224683821201324, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.009411294013261795}, {"id": 947, "seek": 521744, "start": 5218.4, "end": 5222.48, "text": " that you just don't have enough training data for. Radiologists never see it in their lifetime,", "tokens": [50412, 300, 291, 445, 500, 380, 362, 1547, 3097, 1412, 337, 13, 37806, 12256, 1128, 536, 309, 294, 641, 11364, 11, 50616], "temperature": 0.0, "avg_logprob": -0.16950418181338553, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.015420082956552505}, {"id": 948, "seek": 521744, "start": 5222.48, "end": 5228.0, "text": " they just read about it once in a book. And we're still not quite good enough of one shot and zero", "tokens": [50616, 436, 445, 1401, 466, 309, 1564, 294, 257, 1446, 13, 400, 321, 434, 920, 406, 1596, 665, 1547, 295, 472, 3347, 293, 4018, 50892], "temperature": 0.0, "avg_logprob": -0.16950418181338553, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.015420082956552505}, {"id": 949, "seek": 521744, "start": 5228.0, "end": 5233.919999999999, "text": " shot learning. Obviously, huge amounts of progress, but not in super important things like radiology,", "tokens": [50892, 3347, 2539, 13, 7580, 11, 2603, 11663, 295, 4205, 11, 457, 406, 294, 1687, 1021, 721, 411, 16335, 1793, 11, 51188], "temperature": 0.0, "avg_logprob": -0.16950418181338553, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.015420082956552505}, {"id": 950, "seek": 521744, "start": 5233.919999999999, "end": 5238.5599999999995, "text": " where you just read about a case once in a book and then identify it with 100% accuracy,", "tokens": [51188, 689, 291, 445, 1401, 466, 257, 1389, 1564, 294, 257, 1446, 293, 550, 5876, 309, 365, 2319, 4, 14170, 11, 51420], "temperature": 0.0, "avg_logprob": -0.16950418181338553, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.015420082956552505}, {"id": 951, "seek": 521744, "start": 5238.5599999999995, "end": 5243.04, "text": " which is also a question of whether humans do it. I'm actually with you on the self-driving car.", "tokens": [51420, 597, 307, 611, 257, 1168, 295, 1968, 6255, 360, 309, 13, 286, 478, 767, 365, 291, 322, 264, 2698, 12, 47094, 1032, 13, 51644], "temperature": 0.0, "avg_logprob": -0.16950418181338553, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.015420082956552505}, {"id": 952, "seek": 524304, "start": 5243.12, "end": 5247.76, "text": " There's going to be a lot of interesting questions as AGI rolls into more and more workplaces,", "tokens": [50368, 821, 311, 516, 281, 312, 257, 688, 295, 1880, 1651, 382, 316, 26252, 15767, 666, 544, 293, 544, 589, 34840, 11, 50600], "temperature": 0.0, "avg_logprob": -0.14821759048773317, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.045328255742788315}, {"id": 953, "seek": 524304, "start": 5247.76, "end": 5253.84, "text": " which is how much better than a human that has to be. And how, and it's deeply philosophical,", "tokens": [50600, 597, 307, 577, 709, 1101, 813, 257, 1952, 300, 575, 281, 312, 13, 400, 577, 11, 293, 309, 311, 8760, 25066, 11, 50904], "temperature": 0.0, "avg_logprob": -0.14821759048773317, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.045328255742788315}, {"id": 954, "seek": 524304, "start": 5253.84, "end": 5260.4, "text": " very quickly, because if you're purely utilitarian, you could say, well, you know, 100,000 miles or", "tokens": [50904, 588, 2661, 11, 570, 498, 291, 434, 17491, 4976, 13707, 11, 291, 727, 584, 11, 731, 11, 291, 458, 11, 2319, 11, 1360, 6193, 420, 51232], "temperature": 0.0, "avg_logprob": -0.14821759048773317, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.045328255742788315}, {"id": 955, "seek": 524304, "start": 5260.4, "end": 5267.12, "text": " whatever 20 million miles driven by AI results in 10,000 deaths. And the same amount of miles", "tokens": [51232, 2035, 945, 2459, 6193, 9555, 538, 7318, 3542, 294, 1266, 11, 1360, 13027, 13, 400, 264, 912, 2372, 295, 6193, 51568], "temperature": 0.0, "avg_logprob": -0.14821759048773317, "compression_ratio": 1.5528455284552845, "no_speech_prob": 0.045328255742788315}, {"id": 956, "seek": 526712, "start": 5267.12, "end": 5273.68, "text": " driven by humans results in five times more deaths. And so one is better than the odds.", "tokens": [50364, 9555, 538, 6255, 3542, 294, 1732, 1413, 544, 13027, 13, 400, 370, 472, 307, 1101, 813, 264, 17439, 13, 50692], "temperature": 0.0, "avg_logprob": -0.11007680892944335, "compression_ratio": 1.718045112781955, "no_speech_prob": 0.12586906552314758}, {"id": 957, "seek": 526712, "start": 5274.64, "end": 5279.68, "text": " But if that one dead person in the AI car was your daughter, you don't care, you're gonna,", "tokens": [50740, 583, 498, 300, 472, 3116, 954, 294, 264, 7318, 1032, 390, 428, 4653, 11, 291, 500, 380, 1127, 11, 291, 434, 799, 11, 50992], "temperature": 0.0, "avg_logprob": -0.11007680892944335, "compression_ratio": 1.718045112781955, "no_speech_prob": 0.12586906552314758}, {"id": 958, "seek": 526712, "start": 5279.68, "end": 5284.16, "text": " like in the US, you're gonna sue, you're gonna, you know, try to end that company,", "tokens": [50992, 411, 294, 264, 2546, 11, 291, 434, 799, 20416, 11, 291, 434, 799, 11, 291, 458, 11, 853, 281, 917, 300, 2237, 11, 51216], "temperature": 0.0, "avg_logprob": -0.11007680892944335, "compression_ratio": 1.718045112781955, "no_speech_prob": 0.12586906552314758}, {"id": 959, "seek": 526712, "start": 5284.16, "end": 5288.64, "text": " because they're responsible now for the death of your child. And like, it's a very emotional thing,", "tokens": [51216, 570, 436, 434, 6250, 586, 337, 264, 2966, 295, 428, 1440, 13, 400, 411, 11, 309, 311, 257, 588, 6863, 551, 11, 51440], "temperature": 0.0, "avg_logprob": -0.11007680892944335, "compression_ratio": 1.718045112781955, "no_speech_prob": 0.12586906552314758}, {"id": 960, "seek": 526712, "start": 5288.64, "end": 5294.0, "text": " not a statistical thing anymore. And so there's gonna be a lot of litigation as those come out.", "tokens": [51440, 406, 257, 22820, 551, 3602, 13, 400, 370, 456, 311, 799, 312, 257, 688, 295, 33359, 382, 729, 808, 484, 13, 51708], "temperature": 0.0, "avg_logprob": -0.11007680892944335, "compression_ratio": 1.718045112781955, "no_speech_prob": 0.12586906552314758}, {"id": 961, "seek": 529400, "start": 5294.0, "end": 5298.4, "text": " And I think the silver lining is again, of course, as the I meets the state, you can learn from it", "tokens": [50364, 400, 286, 519, 264, 8753, 19628, 307, 797, 11, 295, 1164, 11, 382, 264, 286, 13961, 264, 1785, 11, 291, 393, 1466, 490, 309, 50584], "temperature": 0.0, "avg_logprob": -0.19347703116280693, "compression_ratio": 1.7138461538461538, "no_speech_prob": 0.01150508876889944}, {"id": 962, "seek": 529400, "start": 5298.4, "end": 5303.92, "text": " versus like one person texting again on their cell phone, which is already illegal and running", "tokens": [50584, 5717, 411, 472, 954, 29897, 797, 322, 641, 2815, 2593, 11, 597, 307, 1217, 11905, 293, 2614, 50860], "temperature": 0.0, "avg_logprob": -0.19347703116280693, "compression_ratio": 1.7138461538461538, "no_speech_prob": 0.01150508876889944}, {"id": 963, "seek": 529400, "start": 5303.92, "end": 5308.32, "text": " like over some kid that ran out, like, they're going too fast also, which is already illegal,", "tokens": [50860, 411, 670, 512, 1636, 300, 5872, 484, 11, 411, 11, 436, 434, 516, 886, 2370, 611, 11, 597, 307, 1217, 11905, 11, 51080], "temperature": 0.0, "avg_logprob": -0.19347703116280693, "compression_ratio": 1.7138461538461538, "no_speech_prob": 0.01150508876889944}, {"id": 964, "seek": 529400, "start": 5308.32, "end": 5313.92, "text": " too, you can't really do that much more than needing it legal. AGI will have a huge amount of", "tokens": [51080, 886, 11, 291, 393, 380, 534, 360, 300, 709, 544, 813, 18006, 309, 5089, 13, 316, 26252, 486, 362, 257, 2603, 2372, 295, 51360], "temperature": 0.0, "avg_logprob": -0.19347703116280693, "compression_ratio": 1.7138461538461538, "no_speech_prob": 0.01150508876889944}, {"id": 965, "seek": 529400, "start": 5313.92, "end": 5318.56, "text": " impact. Once it's just like, okay, repetitive jobs, get like two large degree automated,", "tokens": [51360, 2712, 13, 3443, 309, 311, 445, 411, 11, 1392, 11, 29404, 4782, 11, 483, 411, 732, 2416, 4314, 18473, 11, 51592], "temperature": 0.0, "avg_logprob": -0.19347703116280693, "compression_ratio": 1.7138461538461538, "no_speech_prob": 0.01150508876889944}, {"id": 966, "seek": 529400, "start": 5318.56, "end": 5323.2, "text": " and I'm with the people saying that will happen next few years. When it comes to like,", "tokens": [51592, 293, 286, 478, 365, 264, 561, 1566, 300, 486, 1051, 958, 1326, 924, 13, 1133, 309, 1487, 281, 411, 11, 51824], "temperature": 0.0, "avg_logprob": -0.19347703116280693, "compression_ratio": 1.7138461538461538, "no_speech_prob": 0.01150508876889944}, {"id": 967, "seek": 532320, "start": 5323.28, "end": 5328.48, "text": " super intelligence, that is fully conscious and can do all the things. And one intelligent,", "tokens": [50368, 1687, 7599, 11, 300, 307, 4498, 6648, 293, 393, 360, 439, 264, 721, 13, 400, 472, 13232, 11, 50628], "temperature": 0.0, "avg_logprob": -0.17653412945502628, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.008707568980753422}, {"id": 968, "seek": 532320, "start": 5328.48, "end": 5332.48, "text": " then not just a single human, but that all of humanity, very hard to know, because no one's", "tokens": [50628, 550, 406, 445, 257, 2167, 1952, 11, 457, 300, 439, 295, 10243, 11, 588, 1152, 281, 458, 11, 570, 572, 472, 311, 50828], "temperature": 0.0, "avg_logprob": -0.17653412945502628, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.008707568980753422}, {"id": 969, "seek": 532320, "start": 5332.48, "end": 5338.8, "text": " working on it and making sort of progress along the lines of setting my own goals. And again,", "tokens": [50828, 1364, 322, 309, 293, 1455, 1333, 295, 4205, 2051, 264, 3876, 295, 3287, 452, 1065, 5493, 13, 400, 797, 11, 51144], "temperature": 0.0, "avg_logprob": -0.17653412945502628, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.008707568980753422}, {"id": 970, "seek": 532320, "start": 5338.8, "end": 5345.04, "text": " like, unless you set your own goals, I don't know if I would achieve full on super intelligence to", "tokens": [51144, 411, 11, 5969, 291, 992, 428, 1065, 5493, 11, 286, 500, 380, 458, 498, 286, 576, 4584, 1577, 322, 1687, 7599, 281, 51456], "temperature": 0.0, "avg_logprob": -0.17653412945502628, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.008707568980753422}, {"id": 971, "seek": 532320, "start": 5345.04, "end": 5349.679999999999, "text": " you. Like if you're just your objective function is to minimize cross entropy errors, or reduce", "tokens": [51456, 291, 13, 1743, 498, 291, 434, 445, 428, 10024, 2445, 307, 281, 17522, 3278, 30867, 13603, 11, 420, 5407, 51688], "temperature": 0.0, "avg_logprob": -0.17653412945502628, "compression_ratio": 1.703971119133574, "no_speech_prob": 0.008707568980753422}, {"id": 972, "seek": 534968, "start": 5349.68, "end": 5355.360000000001, "text": " the plexity, or like segment, which is well, or like, none of that, I wanted to reach.", "tokens": [50364, 264, 280, 2021, 507, 11, 420, 411, 9469, 11, 597, 307, 731, 11, 420, 411, 11, 6022, 295, 300, 11, 286, 1415, 281, 2524, 13, 50648], "temperature": 0.0, "avg_logprob": -0.23294194005116695, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.006487587001174688}, {"id": 973, "seek": 534968, "start": 5356.240000000001, "end": 5358.56, "text": " Do you have time for a lightning round? Or do we need to leave it there?", "tokens": [50692, 1144, 291, 362, 565, 337, 257, 16589, 3098, 30, 1610, 360, 321, 643, 281, 1856, 309, 456, 30, 50808], "temperature": 0.0, "avg_logprob": -0.23294194005116695, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.006487587001174688}, {"id": 974, "seek": 534968, "start": 5358.56, "end": 5366.16, "text": " Let's try to be lightning rounds. All right. Thinking also about retrieval, memory, and online", "tokens": [50808, 961, 311, 853, 281, 312, 16589, 13757, 13, 1057, 558, 13, 24460, 611, 466, 19817, 3337, 11, 4675, 11, 293, 2950, 51188], "temperature": 0.0, "avg_logprob": -0.23294194005116695, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.006487587001174688}, {"id": 975, "seek": 534968, "start": 5366.16, "end": 5373.4400000000005, "text": " learning as kind of three frontiers that, you know, you dot com could could improve on if they're,", "tokens": [51188, 2539, 382, 733, 295, 1045, 1868, 4890, 300, 11, 291, 458, 11, 291, 5893, 395, 727, 727, 3470, 322, 498, 436, 434, 11, 51552], "temperature": 0.0, "avg_logprob": -0.23294194005116695, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.006487587001174688}, {"id": 976, "seek": 534968, "start": 5373.4400000000005, "end": 5378.240000000001, "text": " you know, if there are research breakthroughs, but also these do seem to be kind of ingredients", "tokens": [51552, 291, 458, 11, 498, 456, 366, 2132, 22397, 82, 11, 457, 611, 613, 360, 1643, 281, 312, 733, 295, 6952, 51792], "temperature": 0.0, "avg_logprob": -0.23294194005116695, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.006487587001174688}, {"id": 977, "seek": 537824, "start": 5378.32, "end": 5384.32, "text": " toward this bigger picture of AGI or even, you know, at some point, ASI, I guess I'm, you know,", "tokens": [50368, 7361, 341, 3801, 3036, 295, 316, 26252, 420, 754, 11, 291, 458, 11, 412, 512, 935, 11, 7469, 40, 11, 286, 2041, 286, 478, 11, 291, 458, 11, 50668], "temperature": 0.0, "avg_logprob": -0.10777044296264648, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.008576112799346447}, {"id": 978, "seek": 537824, "start": 5384.32, "end": 5391.04, "text": " maybe just leave it open ended, like, what are you excited about in those domains? Are there", "tokens": [50668, 1310, 445, 1856, 309, 1269, 4590, 11, 411, 11, 437, 366, 291, 2919, 466, 294, 729, 25514, 30, 2014, 456, 51004], "temperature": 0.0, "avg_logprob": -0.10777044296264648, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.008576112799346447}, {"id": 979, "seek": 537824, "start": 5391.04, "end": 5394.48, "text": " research directions? Are there, you know, are there papers you've already seen or things you", "tokens": [51004, 2132, 11095, 30, 2014, 456, 11, 291, 458, 11, 366, 456, 10577, 291, 600, 1217, 1612, 420, 721, 291, 51176], "temperature": 0.0, "avg_logprob": -0.10777044296264648, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.008576112799346447}, {"id": 980, "seek": 537824, "start": 5394.48, "end": 5400.88, "text": " think people should be doing that you think will kind of provide meaningful unlocks as we find,", "tokens": [51176, 519, 561, 820, 312, 884, 300, 291, 519, 486, 733, 295, 2893, 10995, 517, 34896, 382, 321, 915, 11, 51496], "temperature": 0.0, "avg_logprob": -0.10777044296264648, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.008576112799346447}, {"id": 981, "seek": 537824, "start": 5400.88, "end": 5406.0, "text": " you know, new and better ways to do those things? Yeah. So I'm a fan of all three, of course,", "tokens": [51496, 291, 458, 11, 777, 293, 1101, 2098, 281, 360, 729, 721, 30, 865, 13, 407, 286, 478, 257, 3429, 295, 439, 1045, 11, 295, 1164, 11, 51752], "temperature": 0.0, "avg_logprob": -0.10777044296264648, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.008576112799346447}, {"id": 982, "seek": 540600, "start": 5406.0, "end": 5409.76, "text": " I'll try to keep it short. Retrieval is awesome. I think in some ways, short-term", "tokens": [50364, 286, 603, 853, 281, 1066, 309, 2099, 13, 11495, 5469, 3337, 307, 3476, 13, 286, 519, 294, 512, 2098, 11, 2099, 12, 7039, 50552], "temperature": 0.0, "avg_logprob": -0.25975135803222654, "compression_ratio": 1.826797385620915, "no_speech_prob": 0.008574840612709522}, {"id": 983, "seek": 540600, "start": 5409.76, "end": 5413.6, "text": " memory is currently in the front, retrieval is in the, you know, rag. If you go up method", "tokens": [50552, 4675, 307, 4362, 294, 264, 1868, 11, 19817, 3337, 307, 294, 264, 11, 291, 458, 11, 17539, 13, 759, 291, 352, 493, 3170, 50744], "temperature": 0.0, "avg_logprob": -0.25975135803222654, "compression_ratio": 1.826797385620915, "no_speech_prob": 0.008574840612709522}, {"id": 984, "seek": 540600, "start": 5413.6, "end": 5418.16, "text": " generation, we do it over a web, we let you up those files now, so you wouldn't do it over,", "tokens": [50744, 5125, 11, 321, 360, 309, 670, 257, 3670, 11, 321, 718, 291, 493, 729, 7098, 586, 11, 370, 291, 2759, 380, 360, 309, 670, 11, 50972], "temperature": 0.0, "avg_logprob": -0.25975135803222654, "compression_ratio": 1.826797385620915, "no_speech_prob": 0.008574840612709522}, {"id": 985, "seek": 540600, "start": 5418.16, "end": 5424.64, "text": " over a file. And then we have the smart personalization that actually is online learning. So as you say,", "tokens": [50972, 670, 257, 3991, 13, 400, 550, 321, 362, 264, 4069, 2973, 2144, 300, 767, 307, 2950, 2539, 13, 407, 382, 291, 584, 11, 51296], "temperature": 0.0, "avg_logprob": -0.25975135803222654, "compression_ratio": 1.826797385620915, "no_speech_prob": 0.008574840612709522}, {"id": 986, "seek": 540600, "start": 5424.64, "end": 5430.16, "text": " certain things like it will, it will remember them about you. And then, you know, you can turn", "tokens": [51296, 1629, 721, 411, 309, 486, 11, 309, 486, 1604, 552, 466, 291, 13, 400, 550, 11, 291, 458, 11, 291, 393, 1261, 51572], "temperature": 0.0, "avg_logprob": -0.25975135803222654, "compression_ratio": 1.826797385620915, "no_speech_prob": 0.008574840612709522}, {"id": 987, "seek": 540600, "start": 5430.16, "end": 5435.76, "text": " it off also. And it's very transparent. And the whole thing off or the automated smart learning", "tokens": [51572, 309, 766, 611, 13, 400, 309, 311, 588, 12737, 13, 400, 264, 1379, 551, 766, 420, 264, 18473, 4069, 2539, 51852], "temperature": 0.0, "avg_logprob": -0.25975135803222654, "compression_ratio": 1.826797385620915, "no_speech_prob": 0.008574840612709522}, {"id": 988, "seek": 543576, "start": 5435.84, "end": 5440.64, "text": " without you, if you don't want it. But yeah, I think that's sort of a simple sort of pragmatic", "tokens": [50368, 1553, 291, 11, 498, 291, 500, 380, 528, 309, 13, 583, 1338, 11, 286, 519, 300, 311, 1333, 295, 257, 2199, 1333, 295, 46904, 50608], "temperature": 0.0, "avg_logprob": -0.13586975546444163, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.010647245682775974}, {"id": 989, "seek": 543576, "start": 5440.64, "end": 5445.68, "text": " way of online learning. I think ultimately, you know, it'll be awesome to have AI systems get", "tokens": [50608, 636, 295, 2950, 2539, 13, 286, 519, 6284, 11, 291, 458, 11, 309, 603, 312, 3476, 281, 362, 7318, 3652, 483, 50860], "temperature": 0.0, "avg_logprob": -0.13586975546444163, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.010647245682775974}, {"id": 990, "seek": 543576, "start": 5445.68, "end": 5450.24, "text": " better and better of just adapting right away to user feedback, both in terms of, you know,", "tokens": [50860, 1101, 293, 1101, 295, 445, 34942, 558, 1314, 281, 4195, 5824, 11, 1293, 294, 2115, 295, 11, 291, 458, 11, 51088], "temperature": 0.0, "avg_logprob": -0.13586975546444163, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.010647245682775974}, {"id": 991, "seek": 543576, "start": 5450.24, "end": 5454.88, "text": " thumbs up, thumbs down kinds of clicking, but also in conversation, I didn't like that answer.", "tokens": [51088, 8838, 493, 11, 8838, 760, 3685, 295, 9697, 11, 457, 611, 294, 3761, 11, 286, 994, 380, 411, 300, 1867, 13, 51320], "temperature": 0.0, "avg_logprob": -0.13586975546444163, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.010647245682775974}, {"id": 992, "seek": 543576, "start": 5454.88, "end": 5460.320000000001, "text": " And then updating the answer in a principled way for the future. I have so many more thoughts,", "tokens": [51320, 400, 550, 25113, 264, 1867, 294, 257, 3681, 15551, 636, 337, 264, 2027, 13, 286, 362, 370, 867, 544, 4598, 11, 51592], "temperature": 0.0, "avg_logprob": -0.13586975546444163, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.010647245682775974}, {"id": 993, "seek": 546032, "start": 5460.32, "end": 5465.36, "text": " but I'll like, I'd love to do a second one. These are kind of crazy days. Now the Apple", "tokens": [50364, 457, 286, 603, 411, 11, 286, 1116, 959, 281, 360, 257, 1150, 472, 13, 1981, 366, 733, 295, 3219, 1708, 13, 823, 264, 6373, 50616], "temperature": 0.0, "avg_logprob": -0.19567501233971638, "compression_ratio": 1.5927152317880795, "no_speech_prob": 0.07473979890346527}, {"id": 994, "seek": 546032, "start": 5465.36, "end": 5471.759999999999, "text": " announcement, we just announced that Julianne, CTO, I mean, say also just became an angel investor", "tokens": [50616, 12847, 11, 321, 445, 7548, 300, 25151, 716, 11, 383, 15427, 11, 286, 914, 11, 584, 611, 445, 3062, 364, 14250, 18479, 50936], "temperature": 0.0, "avg_logprob": -0.19567501233971638, "compression_ratio": 1.5927152317880795, "no_speech_prob": 0.07473979890346527}, {"id": 995, "seek": 546032, "start": 5471.759999999999, "end": 5477.2, "text": " and a lot of exciting stuff happening. So I yeah, well, congratulations on the Apple thing and also", "tokens": [50936, 293, 257, 688, 295, 4670, 1507, 2737, 13, 407, 286, 1338, 11, 731, 11, 13568, 322, 264, 6373, 551, 293, 611, 51208], "temperature": 0.0, "avg_logprob": -0.19567501233971638, "compression_ratio": 1.5927152317880795, "no_speech_prob": 0.07473979890346527}, {"id": 996, "seek": 546032, "start": 5477.2, "end": 5483.28, "text": " on a new prominent angel investor. And really some fantastic product progress. I definitely", "tokens": [51208, 322, 257, 777, 17034, 14250, 18479, 13, 400, 534, 512, 5456, 1674, 4205, 13, 286, 2138, 51512], "temperature": 0.0, "avg_logprob": -0.19567501233971638, "compression_ratio": 1.5927152317880795, "no_speech_prob": 0.07473979890346527}, {"id": 997, "seek": 546032, "start": 5483.28, "end": 5489.28, "text": " recommend everybody to try out particularly genius mode and research mode. And I think if you do that,", "tokens": [51512, 2748, 2201, 281, 853, 484, 4098, 14017, 4391, 293, 2132, 4391, 13, 400, 286, 519, 498, 291, 360, 300, 11, 51812], "temperature": 0.0, "avg_logprob": -0.19567501233971638, "compression_ratio": 1.5927152317880795, "no_speech_prob": 0.07473979890346527}, {"id": 998, "seek": 548928, "start": 5489.28, "end": 5494.719999999999, "text": " you will be coming back to you.com more and more often. So keep up the great work. For now,", "tokens": [50364, 291, 486, 312, 1348, 646, 281, 291, 13, 1112, 544, 293, 544, 2049, 13, 407, 1066, 493, 264, 869, 589, 13, 1171, 586, 11, 50636], "temperature": 0.0, "avg_logprob": -0.08607250306664443, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.013632960617542267}, {"id": 999, "seek": 548928, "start": 5494.719999999999, "end": 5499.759999999999, "text": " I will say Richard Sosher, founder and CEO of you.com. Thank you for being part of the cognitive", "tokens": [50636, 286, 486, 584, 9809, 318, 329, 511, 11, 14917, 293, 9282, 295, 291, 13, 1112, 13, 1044, 291, 337, 885, 644, 295, 264, 15605, 50888], "temperature": 0.0, "avg_logprob": -0.08607250306664443, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.013632960617542267}, {"id": 1000, "seek": 548928, "start": 5499.759999999999, "end": 5505.28, "text": " revolution. Thank you so much. It is both energizing and enlightening to hear why people", "tokens": [50888, 8894, 13, 1044, 291, 370, 709, 13, 467, 307, 1293, 10575, 3319, 293, 18690, 4559, 281, 1568, 983, 561, 51164], "temperature": 0.0, "avg_logprob": -0.08607250306664443, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.013632960617542267}, {"id": 1001, "seek": 548928, "start": 5505.28, "end": 5510.96, "text": " listen and learn what they value about the show. So please don't hesitate to reach out via email", "tokens": [51164, 2140, 293, 1466, 437, 436, 2158, 466, 264, 855, 13, 407, 1767, 500, 380, 20842, 281, 2524, 484, 5766, 3796, 51448], "temperature": 0.0, "avg_logprob": -0.08607250306664443, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.013632960617542267}, {"id": 1002, "seek": 548928, "start": 5510.96, "end": 5516.719999999999, "text": " at TCR at turpentine.co, or you can DM me on the social media platform of your choice.", "tokens": [51448, 412, 314, 18547, 412, 3243, 22786, 533, 13, 1291, 11, 420, 291, 393, 15322, 385, 322, 264, 2093, 3021, 3663, 295, 428, 3922, 13, 51736], "temperature": 0.0, "avg_logprob": -0.08607250306664443, "compression_ratio": 1.5841924398625429, "no_speech_prob": 0.013632960617542267}, {"id": 1003, "seek": 551672, "start": 5517.68, "end": 5523.76, "text": " Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually", "tokens": [50412, 9757, 77, 9850, 4960, 1337, 1166, 7318, 281, 9528, 291, 281, 4025, 6779, 295, 5383, 295, 614, 36540, 300, 767, 50716], "temperature": 0.0, "avg_logprob": -0.20374746725592816, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.1753765046596527}, {"id": 1004, "seek": 551672, "start": 5523.76, "end": 5529.2, "text": " work customized across all platforms with a click of a button. I believe in Omniki so much", "tokens": [50716, 589, 30581, 2108, 439, 9473, 365, 257, 2052, 295, 257, 2960, 13, 286, 1697, 294, 9757, 77, 9850, 370, 709, 50988], "temperature": 0.0, "avg_logprob": -0.20374746725592816, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.1753765046596527}, {"id": 1005, "seek": 551672, "start": 5529.2, "end": 5538.96, "text": " that I invested in it and I recommend you use it too. Use Kogrev to get a 10% discount.", "tokens": [50988, 300, 286, 13104, 294, 309, 293, 286, 2748, 291, 764, 309, 886, 13, 8278, 591, 664, 40382, 281, 483, 257, 1266, 4, 11635, 13, 51476], "temperature": 0.0, "avg_logprob": -0.20374746725592816, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.1753765046596527}], "language": "en"}