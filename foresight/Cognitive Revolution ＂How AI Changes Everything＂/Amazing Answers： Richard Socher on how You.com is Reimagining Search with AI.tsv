start	end	text
0	5920	early 2022, or like we had apps that would write code for you within the search results,
5920	10240	through the apps that write essays for you within the search results. But whenever we
10240	15600	innovated and changed the default Google experience too much, we had just like the vast
15600	20240	majority of our users say, I'm so used to Google, I don't want another way of finding answers.
20800	26160	And so we kept getting pulled back to this need. And so the most amazing surprise was when
26240	30800	ChachiP came out, all of a sudden people got it. And it was like, wait a minute,
30800	36000	it could just be like pure text. And we're like, been trying to sort of slowly get there, but
36000	40240	we had to make a bigger job. The way I think about the different modes is like the default
40240	44560	smart mode is kind of like, if you had an assistant, and you just ask them to do a quick
44560	49760	a search, and in like two or three minutes, give you an answer that. And then genius mode,
49760	54480	you go and so you want to ask your assistant for a question that they have to be able to program,
54560	58960	they have to search the web, and then they need to be mathematically applying to answer that
58960	63840	question. I mean, as a kid, I also enjoyed watching Terminator. It's like a cool action movie,
63840	70000	but it's just taken over so much of the AI narrative. And it's actually like actively
70000	74720	hurting, especially European Union. Hello, and welcome to the Cognitive Revolution,
74720	79120	where we interview visionary researchers, entrepreneurs and builders working on the
79120	84400	frontier of artificial intelligence. Each week, we'll explore their revolutionary ideas,
84400	88240	and together we'll build a picture of how AI technology will transform work,
88800	94720	life, and society in the coming years. I'm Nathan LaBenz, joined by my cohost, Eric Tornberg.
95280	99920	Hello, and welcome back to the Cognitive Revolution. Today, I am thrilled to welcome
99920	105040	Richard Socher, a pioneer of deep learning for natural language processing, formerly chief
105040	110960	scientist at Salesforce, and today, founder and CEO of u.com, a company that was first
110960	116000	introduced to the public as a new kind of search engine, but which now describes itself as an AI
116000	123760	assistant that makes you more productive, creative, and extraordinary. Richard has deep history in
123760	128800	deep learning. He was among the very first to recognize the potential of neural networks
128800	134240	in the natural language processing domain, and his work has helped shape the field as we know it
134240	139760	over the last decade. In this conversation, Richard takes us on a brief journey through his own
139760	145040	intellectual history and reflects on how the field of AI has evolved in both expected and
145040	151200	surprising ways. Before we dive deep into the u.com product itself, covering the historical
151200	155440	challenge that they faced when trying to compete with Google and how the rise of the AI chatbot
155440	161520	paradigm has broadened the space of possibility for search and discovery products. We also look
161520	167120	at u.com's various modes with particular emphasis on the genius mode and above all, for me, the
167120	172720	research mode, which delivers amazingly helpful and thorough report style answers, even on some
172720	178960	remarkably complex topics. We also briefly discussed the future of AI business models as well,
178960	184320	including the obvious subscription and my pet theory about the AI bundle. Along the way, we touch
184320	189280	on a number of important topics, too. The limits to AI systems' reasoning ability and the prospects
189280	194400	for the improvement that would be needed for reliable autonomy, the potential for AI to transform
194400	200160	medicine and scientific research, Richard's case for general optimism, even though he does expect
200160	205600	AI to drive major disruption, why he's not worried about so-called emergent capabilities,
205600	210960	but does take the risk of intentional harmful misuse very seriously, and lots more little
210960	216960	topics along the way as well. Richard is a leading thinker in the AI space, and his perspective
216960	221600	is essential for anyone who wants to understand where this technology is going and what it means
221600	228000	for the future of humanity. And in all seriousness, I really do recommend u.com. It has absolutely
228000	233200	joined the ranks of the AI tools that I use multiple times each week. And particularly,
233200	240000	when I want a comprehensive, multi-page report style answer, I find that u.com's research mode
240000	246160	is often the single best tool available today. As always, if you're finding value in the show,
246160	249680	we would appreciate it if you'd share it with friends or post a review to Apple podcasts
249680	254960	or Spotify, or just leave a comment on YouTube. Now, without further ado, I hope you enjoyed
254960	260160	this conversation with Richard Sosher of u.com. Well, let's do it. I think this is going to be
260160	264000	a lot of fun. I'm looking forward to your point of view on a bunch of very interesting topics.
264640	269360	Richard Sosher, founder and CEO of u.com, welcome to the Cognitive Revolution.
270240	276480	Thanks for having me. I am very excited to have you. You are at the intersection of so
276480	281120	many interesting things. I sometimes have been describing myself recently as the forest gump of
281120	286480	of AI because I've just kind of very unstrategically made my way through the last few years and yet
286480	291200	found myself in some very interesting places. I don't know how you think about your own trajectory,
291200	296560	but you are kind of an OG in the realm of deep learning and have founded this very interesting
296560	302320	company and have a really awesome product, which we'll get into in more detail. And I'm interested
302320	307680	to hear about all that and your kind of philosophy and expectations for the future. So we've got a
307680	312240	lot of ground to cover. Maybe for starters, you want to kind of give us, and I usually even ask
312240	316160	these biographical questions, because these days it's like a lot of the same answers. People are
316160	320960	like, oh, when I saw GPT-3, I thought this is going to be a big deal that I got involved. But you
322000	325120	were there at the beginning, man. So maybe you want to just give us a quick history of
325120	328880	your own role in the history of deep learning and how you've kind of come to the present.
329760	335760	I started with AI actually in 2003, when I started studying linguistic computer science,
335760	340960	or natural language processing back in Germany. And at the time, I was like, this is really
340960	345680	interesting. I love languages, I love math, I love computers, you know, so if computers are
345680	350800	where languages and math can meet in some useful functional ways, I thought. And there's very much
350800	357040	sort of a small niche subject within computer science. And I was really excited. At the time,
357040	362880	there wasn't quite enough math for me in an LP. And I felt like we're just getting stuck in some
362880	369600	of the legalistic special cases. And I loved the form of semantic set theory and then algebraic
369600	376240	foundations. And so I moved eventually into computer vision during my master's. And there,
376240	381840	I also, in Saarbr√ºcken, at the Max Klein Institute there in the university, found statistical
381840	387200	learning and pattern recognition. And I fell in love with that. I was like, clearly, you can really
387200	392800	understand patterns, any kind of pattern really well, you could solve all these different kinds
392800	399360	of problems. And so I ended up doing my PhD at Stanford. In the beginning of Stanford, I started
399360	405920	trying to really contribute to the field rather than just learning about it. I basically found that
406000	412480	even the top NLP people, they write their papers mostly about these beautiful models,
412480	417040	like conditional random fields, late in university, other patient types of models.
417040	422160	But then most of the coding happens when they actually do feature engineer, right? They say,
422160	426800	oh, well, I wanted you to be entity recognition at a feature of like, this is a capitalized word,
426800	433600	and this is all caps word, or this is a word that has like, is one of the items in this list.
433600	438400	And this list includes, you know, city needs, we already know. And I'm like, man, this field is
438400	443840	very hand engineered. It's very like, graduate student ascent to get better. And then at the
443840	449680	time I was very 40, because Andrew A. got into deep learning on the computer vision side. He's
449680	454560	like, well, images are pixels, and it's a fixed number of pixels. So we can feed them into a
454560	459360	neural net or at the time, you know, variants, models, restricted development machines. And I
459360	464720	was like, wow, maybe we can use ideas from that for natural language processing. And there was
464720	471840	maybe like one or two relevant papers all from a number there, and Jason Weston, and, and a few
471840	477680	like one or two others. But no one really enjoyed that approach, no natural language processing,
477680	482640	paid any attention to it. But I thought, silly, that has to be the future. I want to give the data
482720	489520	and I want to get an output. And so in 2010, I started publishing my first neural net paper,
489520	495600	worked on my computer vision before and saw some of the power of ImageNet also back to and really
495600	501200	started running with it. Got a lot of rejections all throughout. But, but at some point, I sunk
501200	505680	my teeth into it. And I just like, I loved it. And I thought this is the future. Despite all the
505680	511200	rejections, I kept going at it. And then after the PhD was over, there's sort of starting to be
511200	517040	more interest in deep learning and neural nets for NLP. But still, no one in the world was teaching
517040	521680	that as like the official right way of doing NLP. So I started teaching at Stanford also,
522640	528080	first as a busy lecturer and then as a professor, started, you know, being a fortune and lots of
528080	532960	very smart students back then, really like the hiding place founders invested in their first
532960	538720	round. And then, you know, also wanted to bring these neural nets into the world, started a
538800	543200	menomind, my first startup to do that, to build a general purpose platform between neural nets
543200	548560	very easily, both revision and NLP, got acquired by Salesforce, became a chief scientist there and
548560	554880	EDP eventually. And in Salesforce, we had my probably last and biggest rejection was on inventing
554880	560000	front engineering in 2018. And we're so excited about it, because there's the culmination personally
560000	565840	for me also of this decade long dream I have, building a single neural net for all of NLP.
565840	572560	And the idea was, you know, at the time, every AI model was built for one task, you will have wanted
572560	576480	your sentiment analysis, I built a sentiment analysis model, you wanted a translation, I built
576480	580320	a translation model, and they're all different. We're like, what if we could just build a single
580320	585520	model? And you just ask it a question, what is the sentiment? What is the summary of the sentence?
585520	590880	Who is the president in this paragraph? And that was kind of for us, I thought like,
590880	594880	the most exciting thing you possibly could be doing at just get this tech talk about it
594880	600560	came out last week. And but it was exciting. But it did inspire a couple of other folks.
600560	604400	And like, when opening, I was, you know, publishing your papers, that should be true.
604400	609520	And three, they cited that paper saying like, look, they were able to have a single model
609520	615120	for all of NLP, if you just ask them these questions. And, you know, that's now prompt and
615120	619680	the rest is kind of more well known history. That is an amazing history. And it definitely,
619680	626320	I don't know how, you know, modest you want to be versus taking credit for foresight. But
626320	632080	certainly, the idea that there could be one model to solve all these, you know, tasks was not
632080	637680	obvious to people. And boy, we still see this, the flaws in the peer review process are still on
637680	642480	prominent display these days. Most recently, I noticed this with the Mamba paper, which I was
643360	649280	a very interested reader of. And then went over to the open reviews site and was blown away by how
649280	654880	negative some of the reviews were like a confident reject was given. So that was kind of, you know,
655680	658640	just a good reminder that, yeah, this is still an unsolved problem.
659440	667200	What would you say has surprised you most from like the big picture since you,
668080	672320	and you know, it hasn't been that many years, right? But since you kind of had that notion of
672320	679360	this generalist NLP model, fast forward, now we have, you know, GPT four and possibly Q star or
679360	683520	something like that in the works, you know, is this the trajectory that you thought we'd be on?
683520	686800	Or how has it deviated from what you imagined back then?
686800	693040	It's very much aligned with what I hoped the field could get to. And now it's almost like,
693040	697360	it's like obvious, right? Like no one no one questions this anymore, we've had all these
697360	703280	breakthroughs. And I think the biggest surprise was maybe more on the application side of things
703280	708240	and that for us, you know, we've been playing around with large language models at u.com and
708240	714800	infuse them into search results earlier, like early 2022, already, like we had apps that would
714800	719200	write code for you within the search results, through the apps that write essays for you within
719200	725760	the search results. But whenever we innovate it and change the default Google experience too much,
725760	729360	we had just like the vast majority of our users say, I'm so used to Google,
730160	735520	I don't want another way of finding answers. And so we kept getting pulled back to this need.
735520	739600	And there was kind of annoying. And so the most amazing surprise was when
739600	744240	Chatchity came out, all of a sudden, people got it. And it was like, wait a minute,
744240	749760	it could just be like pure text. And we're like, you know, we've been trying to sort of slowly
749760	754640	get there, but we had to make a bigger job. And that was incredible. That unlocked a lot
754640	759600	of people realizing we handle links isn't the best way to get an answer. An actual answer
759600	761920	is the best way to get an answer. And that's the text.
763040	768320	So let me give you a couple of my experiences on u.com recently, and then you can kind of tell me,
768320	773680	you know, where you are the overall story. And then I really want to kind of unpack the
774560	778400	kind of use the product as it exists today and the roadmap and everything you're working on
778400	781840	as a way to kind of explore a bunch of different aspects of where all this
781840	786720	is going, you know, and I think that's really the mission of this show is to kind of help people
786720	790640	see around the corner and starting with me, helping me develop my own worldview.
790640	795120	But I've been really impressed with the product recently. You know, listeners will know that
795120	798800	I've been a big fan of perplexity. We've had Arvin on the show a couple of times.
799440	804160	And I think they do a great job and, you know, we're made a fan. But I have found
805120	810560	distinctive value in at least two modes on u.com recently. One is the
811200	816160	research mode, and the other is the genius mode. Those to me have stood out as the most
816160	823520	differentiated. For research mode, I recently took it like a 200 word question that was all about
824240	829680	mixture of experts architectures. And, you know, kind of is there curriculum learning,
829680	833920	you know, stuff happening here? How, you know, how do people think about sort of
833920	838480	the tradeoffs between like how many experts should we have and how big should they be and
838480	842160	how many should we activate at any given time? Are there any like scaling laws or whatever,
842160	844800	you know, designed for that sort of thing? Just every basically every question I could
844800	850880	think of about mixture of experts, I took it all in one go. And it was really impressive to see it
851520	857680	kind of break that down and go through multiple steps of searching and analysis and,
858560	862400	you know, really implementing kind of like, you know, kind of a classic agent, what is at
862400	867520	this point, you know, a six month classic agent setup, but applying it to that research question
867520	872960	and just going, you know, down the line, really quite valuable results. And it definitely is
872960	877280	something that I will come back to and have already, you know, found myself kind of being like,
877280	882800	I think this is a good one for u.com research mode. Genius mode is a little bit different and more
882800	887200	kind of analytical. I'd be interested to hear a little bit more about how you think about the
887200	893520	differences. Because I did, I then tried one that was a big Fermi calculation exercise,
893520	897280	where my questions were like, what are the different data sets that exist in today's world?
897280	900880	How big are they? How do they compare to each other? How do they compare to
901520	907440	the training data size for GPT four? You know, how do they compare to available compute? Like,
907440	910800	because I have this, I have a big question, which is kind of one of the ones I want to get to
910800	916000	toward the end to around like, to what degree is ML research poised to start to be kind of semi
916000	921120	automated. And so I'm trying to try to rent my arms around that with these furry calculations.
921120	927840	So genius mode was really the best way to approach that. And anyway, I would definitely
927840	934880	encourage people to bring multi part complicated questions to both research mode and genius mode.
934880	939200	And I think you'll be impressed with the results. And I would say that, you know, even
940240	944080	with, you know, the expectation that folks who listen to this show have tried, you know, other
944160	951360	leading AI products. So that's kind of my unpaid endorsement, very sincere. And I'd love to hear,
951360	954560	you know, a little bit more about how you think about those different modes, how they work,
954560	958880	and just kind of big picture, like where we are in the you.com product journey long term.
959440	962720	Hey, we'll continue our interview in a moment after a word from our sponsors.
963680	967760	The Brave Search API brings affordable developer access to the Brave Search Index,
967760	972640	an independent index of the web with over 20 billion web pages. So what makes the Brave Search
972640	978960	Index stand out? One, it's entirely independent and built from scratch. That means no big tech
978960	985840	biases or extortionate prices. Two, it's built on real page visits from actual humans, collected
985840	991760	anonymously, of course, which filters out tons of junk data. And three, the index is refreshed with
991760	997680	tens of millions of pages daily. So it always has accurate up to date information. The Brave Search
997680	1002640	API can be used to assemble a data set to train your AI models and help with retrieval
1002640	1007520	augmentation at the time of inference, all while remaining affordable with developer first pricing.
1008560	1013360	Integrating the Brave Search API into your workflow translates to more ethical data sourcing
1013360	1019360	and more human representative data sets. Try the Brave Search API for free for up to 2000
1019360	1031040	queries per month at brave.com. Yeah, these are a great question. I think it shows you kind of
1031040	1039200	how sophisticated the space has gotten in the last year. Around this time, last year, we were the
1039200	1047520	only search engine with a web connected LN and millions of users. And now that idea has been
1047520	1053520	copied so many times, including as mentioned by Plexi. And so I think what you have to differentiate
1053520	1057600	kind of the different modes, and I think the modes kind of show how sophisticated that the
1057600	1063280	space has gotten and how hard it is to still differentiate on better technology versus just
1063280	1069040	you know, designing the market and marketing and things like that. And so we actually did a comparison
1069040	1076000	to Plexi with 500 real user queries. And we asked which answer do you prefer? And it came out to be
1076000	1082800	that 50% of the cases users prefer the U.com answer and they prefer the Plexi answer and 30%
1083360	1088960	they don't see a difference into answers for our default, we call it the smart mode. That's kind
1088960	1095360	of the default. And just to give you a sense of what that looks like. So here's an example of what
1095360	1099600	the default smart mode looks like. You know, there's some doping case that happened and
1099600	1104880	you can see lots of careful citations. And then when you actually look into these citations,
1104880	1110000	they actually are articles from literally yesterday or they could be, you know, from today if something
1110000	1114160	came out today. So that's kind of the default smart mode, you get a quick factual answer.
1114160	1119600	But then we thought, well, what if you have a pretty complex question like math, physics,
1119600	1125360	chemistry, science, or like complex numbers. So here is a genius mode question, it kind of gives
1125360	1129840	you a sense of what it does. And it doesn't mention like what you say, which is there's an
1129840	1134960	important LM that orchestrates multiple other LMs to actually do the right thing right. So
1134960	1138960	the question here is find the current population of the in the United States, then it's lots of
1138960	1146880	population from 233 to 10, 100, and then assuming a 2% growth rate. And then it will go on the
1146880	1152880	internet, it'll find the numbers, and then realize like, well, I got to now visualize those numbers,
1152880	1159280	now that I have any, so it will code up in Python, what this could look like, execute the code,
1159280	1166000	and then gives you this answer, and visualizes it in a nice plot. And so that I'm still sometimes
1166000	1170160	amazed, I try and I push it, and you know, sometimes it fails. And sometimes it fails
1170160	1173440	because it tries to load the library that has security issue. And then it's like, okay, I'm
1173440	1177600	going to try to rewrite it without this library, but it's going to be longer and messier code.
1177600	1183520	And like, it's just incredible how hard it can try and what it can do. And then the third mode,
1183520	1189040	like you said, the research mode, it will go into a lot of detail, it will not just look up
1189280	1193200	all the stuff we have in our index already, like news and things like that, but it will go on the
1193200	1199600	web and find your website, so the multiple different searches on the web, combine all of that,
1199600	1204400	and then give you these beautiful research reports. This one is like, seeing a background,
1204400	1209440	actually, any consequences of the telecommuting work. Now it's like, history, you have to write an
1209440	1214960	essay or something. And it's just like, writes you just perfect, like, beautiful essay, each
1214960	1220560	sentence has one or two citations from different sources, and you can verify all of them. And
1220560	1225520	one thing we found this actually also is like, you have to like, just the citation lot is a
1225520	1231360	non-trivial aspect of building this all out. Because you have to, we actually found that some
1231360	1237360	of our competitors just randomly add numbers and citations to sentences, and you click on it,
1237920	1243520	and it doesn't even mention that back anymore. Which I think it really undermines the space of
1243520	1250720	chatbots for search. So citation accuracy is one of the many sub-AI systems that you need to do
1250720	1254560	correctly here. And then, you know, they're just like crazy things, like create a table,
1254560	1259120	some nice cancelling headphones that are not expensive, and just like, put this table together,
1259120	1263680	pull some images, give some pros and cons of each and the price. I think sometimes, to me,
1263680	1269760	is how well and general the system is able to answer these questions. And it shows you how
1269760	1274400	complex the space is gotten and how much you have to do now to still differentiate on the
1274400	1279680	technology. This is one of my mantras at Waymark. I always say the water line is rising quickly.
1279680	1285840	So we, you know, we better keep climbing the capabilities ladder ourselves. The four examples
1285840	1290080	that we saw there, one was the kind of default smart mode. The second was genius. Is that right?
1290080	1294880	The one that showed the code example. And then the last two were research. Yeah. What more can you
1295520	1300160	tell us about kind of how those work? Like I'm interested in, and by the way, like the
1300160	1304160	audience of the cognitive revolution is interested in the details, the weeds, the nuggets, you know,
1304160	1308240	all that stuff. So you can go as deep as you're, you know, willing to share. I'm interested in
1308240	1311840	all aspects, you know, prompting, I'm sure, obviously, is going to be different. Scaffolding
1311840	1315040	is going to be different. Maybe even the models are different. I'm also really interested in,
1315040	1320240	like, what are you using GPT-4 that you've got your own in-house trained ones as well. So
1320240	1323520	just all those considerations, any interesting nuggets were all ears.
1324400	1329280	Yeah, I'm going to try to balance a little bit the not telling the competition exactly how it's
1329280	1335840	all done, but it'd be interesting to your ears here. So at a high level, there are two major
1335840	1342320	stacks. There's a search stack and a chat stack. The search stack, we actually had to build an
1342320	1349760	entire index ourselves for the web because being super expensive, not as high quality, Google
1349760	1354400	is very hard to access. You have to have special agreements or, you know, some people kind of
1354400	1360480	steal slash bootleg slash leave some surveyed the eyes to use Google results in like a somewhat
1360480	1366400	sketchy legal gray area, which we don't want to do. And so we, we basically ended up having to
1366400	1371680	build our own index. And that's hard. And there's still, you know, a lot of complexities behind
1371680	1377920	that. But what do we, the main difference of this new index is that it was built with LNs in mind.
1378480	1385840	The previous two indices of Google and Bing were built with people consuming 10 blue links in mind.
1386720	1391600	And what that means is for each URL, you get a very short snippet, which makes sense, right,
1391600	1395760	for end users. But an LN could read all these other snippets, they can be very long,
1396560	1400800	and then extract the right answers from that, and then just give you that right answer as the
1400800	1406160	user. And so what was surprising is actually when we benchmark this, our API ended up being more
1406160	1411920	accurate than Google or me and go to API.com. And like, I'll, I'll see you on the screen here for
1411920	1416480	a second again. But like, it's surprising that, which are a lot of people that you could actually
1416480	1421040	be more accurate in Google or Bing at all. But it is because we're at an inflection point in,
1421040	1425520	in a, in the eye, and it's a different way to value. It's like, we're almost like
1425520	1430480	cheating by having these really long snippets. And so you look at the comparison, and it's
1430480	1434560	actually kind of interesting to look at. And a lot of people have asked like, how do you compare
1435120	1440320	accuracy in LNs? How can you evaluate this? And so just to give you a sense, here's like, what,
1440320	1444560	what this looks like, the first a version is just like reasons to smile. And now you can use whatever
1444560	1451200	LN you want, but you can see into your prompt is very, very long snippets from many different
1451200	1455520	URLs in a very short amount of time. And then we also have one that just does everything,
1455520	1460160	like it gives you an LN answer, and it tells you like all of these things. And so how do you
1460160	1465600	evaluate this is actually, it was an interesting, I think insights insight from our team, which was,
1465600	1471120	you can take question answering data such as hotpot qa, squat, so the question answering
1471120	1478080	data set MS, Microsoft, Marco, fresh QA and so on. And these data sets are structured such that you
1478080	1484320	have a paragraph, you really have a question, and then you have a subset phrase from that paragraph
1484320	1489920	that is the right answer to that question. And so what we do is, we basically take those data sets
1489920	1495200	but we throw away all the paragraphs. And then you have to find the right answer. And the paragraphs
1495200	1501840	have to come from the internet. And so you replace paragraph with a web search engine. And that's how
1501840	1509440	we evaluate it, the JIT, the big Google and the public APIs, and have outputs on them. So kind
1509440	1514880	of nerdy, but that's the whole tech stack. And we're we make that now available to every other LN.
1514880	1520960	So that's the first. And then the second thing is what we now have started calling the LNOS,
1520960	1526640	the operating system of large language models. And it's a term inspired by Andrey Kapathy.
1526640	1531360	And it's not like the most perfect metaphor, but I think it captures a lot of the essence, which is
1531360	1539040	you have now this new staff that operates at a much higher level of abstraction. And the LN is
1539040	1545600	kind of a CPU. But just like a CPU or a kernel on an operating system, like it's important to
1545600	1552480	orchestrate everything and to do computation. But if it still needs a hard drive, which is
1552480	1558960	right, right on your own vector database that's grown up, you have an internet connection, which
1558960	1564560	is, you know, the internet. And that's what we're providing. You may orchestrate other LNs that
1564560	1569200	could be considered like the GPU or something. And then you have a bunch of apps that are sitting
1569200	1574240	on top of that. You have a Python code interpreter, which we see our genius mode, all of that. And so
1574240	1580160	to summarize all of that in one short term, we call the LNOS. And inside of that, we're now seeing
1580160	1586720	a lot of our customers are using our APIs and search site. They're kind of going through the same
1586720	1593360	lessons that we had gone through when we built dot com and made it like having the most accurate
1593360	1598320	answers out there. And it's actually highly non trivial. A lot of people saying it's just like
1598320	1604000	an LN wrapper, right? But then, and you even have like open source project that show it.
1604000	1609920	And then you ask, like, okay, when was Obama born? Where was he born? And then it fails. Why does it
1609920	1615840	fail? Because when you send where was he born to your search back in is not going to return you
1615840	1620560	any useful results. Because it doesn't know who he is. Who does he refer to, right? And there's
1620560	1625440	tons of things like that where, as you have a longer and longer conversation, especially in
1625440	1633120	smart mode, you refer back to states. You can say like, Oh, what's a big CRM company? And then the
1633120	1637840	answer inside is Salesforce. And you ask, Oh, what's their stock price? Now she sent what's their
1637840	1642320	stock price to your search back. And again, it's not going to return anything useful. So you need
1642320	1647040	to send that you need to go through the entire conversation, and then do what we call query
1647040	1656320	transformation based on it. And that is just one of 10 examples of making this actually work at scale
1656320	1662720	millions of times a day for millions of users. Like, it is a lot more complicated to make it
1662720	1667360	accurate. There are about 10 other such models that if you think about the space and you really
1667360	1672560	listen and look at like user data, you listen to where it's breaking, you will eventually get to
1672560	1678080	and we're now like thinking about offering more and more back. So I'm tempted to ask for the other
1678080	1684160	nine things there. I'll just give you one more, which is like, whether to do a search at all or
1684160	1690240	not, right? Like, because you asked like, write me a poem about like the beautiful Bay Area and
1690240	1695120	like a sunset love story or something. Like, you don't need a citation at every line of that poem.
1695120	1702160	And so it would actually clutter up the prompt to add a bunch of facts about poems and so on.
1702240	1708240	And the history of Silicon Valley and all of that. And so it's pretty important, but also non trivial
1708240	1713520	to know whether you should do a search or not. And again, some, some websites just slap search
1713520	1718960	results on top of everything, even if they're not relevant for having more conversation about
1718960	1725680	your feelings or something. Did I understand correctly that the kind of big difference is that
1725680	1732640	the U.com index has more information, like instead of a short SERP, it is a more robust
1732640	1741360	paragraph. And so independent of the language model that you're using, the richer context is
1741360	1748080	just better kind of serious enable you in that way, you're kind of decoupling the what information
1748080	1754880	is found from language model that is doing the analysis. And more information is kind of the
1754880	1760080	big differentiating factor there. Drive that right. I would be careful and say we have overall
1760080	1766400	more information. We're focused a little bit more on the main languages that we see. We don't support
1766400	1773280	some like very rare like Indonesian, African sensual Asian dialects and so on yet, but we
1773280	1779600	return more information per rare because of these large limits. So, so it's sort of, yes,
1779600	1784000	yes, there's more information, but you know, I think the long tail Google Prop still has a larger
1784000	1790320	index. If you look for this like rare, like Indonesian kayaking sites that like rents out
1790320	1795440	kayaks on this little lake somewhere, like, and it's all like not in English, like we might not
1795440	1801040	have that website. But when it comes to like Western world news where, you know, we have a lot of
1801040	1807360	users, then Latin America and so on, then we shine and return much more information per pair.
1807360	1811040	Hey, we'll continue our interview in a moment after a word from our sponsors.
1811040	1815040	If you're a startup founder or executive running a growing business, you know that as you scale,
1815040	1819840	your systems break down and the cracks start to show. If this resonates with you, there are three
1819840	1826880	numbers you need to know. 36,000, 25 and 1. 36,000. That's the number of businesses which have upgraded
1826880	1831280	to NetSuite by Oracle. NetSuite is the number one cloud financial system, streamlined accounting,
1831280	1837920	financial management, inventory, HR and more. 25. NetSuite turns 25 this year. That's 25 years
1837920	1842880	of helping businesses do more with less, close their books in days, not weeks, and drive down costs.
1843600	1848160	One, because your business is one of a kind, so you get a customized solution for all your KPIs
1848160	1852800	in one efficient system with one source of truth. Manage risk, get reliable forecasts,
1852800	1858320	and improve margins. Everything you need all in one place. Right now, download NetSuite's popular
1858320	1863040	KPI checklist designed to give you consistently excellent performance, absolutely free and
1863040	1869120	net suite.com slash cognitive. That's net suite.com slash cognitive to get your own KPI checklist.
1869120	1876080	Net suite.com slash cognitive. Omniki uses generative AI to enable you to launch hundreds of
1876080	1881520	thousands of ad iterations that actually work, customized across all platforms with a click
1881520	1886400	of a button. I believe in Omniki so much that I invested in it and I recommend you use it too.
1887120	1892560	Use Kogrev to get a 10% discount. I've been struck recently that it seems like,
1892800	1896880	obviously, search in general has kind of been a monopoly for a long time.
1898400	1903360	As you noted, the user experience was kind of something people were not necessarily looking
1903360	1910000	to explore new things on the nature of the index. Of course, they've done millions of
1910000	1915120	person hours of work on it, but it seems like it's kind of been a pretty consistent paradigm of
1915120	1919120	crawl around and find everything and suck it up. Now, we're starting to see these interesting,
1919120	1924240	I don't know if you can share more about how you create your index, but we just had actually a
1924240	1930640	sponsor brave talking about their index and the way that they are building it through users
1930640	1937120	actually visiting websites and taking a sort of not just blindly crawling around and following
1937120	1944720	every link, but what are people actually engaging with online, which struck me as a pretty interesting
1944720	1948720	and very different twist on it. I want to kind of pull this apart in a couple of different ways,
1948720	1954240	but is there anything that you would want to share about how you think about building an index
1954240	1962400	that, aside from just bigger, richer content, is there a different tactic as well that underlies
1962400	1969840	that? The tactic is more about how we make that work for LLNs better, and I don't think there's
1969840	1974160	that much differentiation on how it will fall. You have to have a bunch of data that's been
1974160	1980800	helpful to have run a search engine for several years and get user behavior and knowing what
1980800	1986800	people actually want to have called and want information for. You can also sound surprisingly
1986800	1991840	buy a lot of that data in bulk. I have a few questions on the business side or the kind of
1991840	1997920	bridge the technology and business side. Google obviously has been free and has been ad supported.
1998000	2006800	It seems like the new generation of AI first LLN enabled search is going more in the direction so
2006800	2013920	far of a subscription. As far as I've seen in my U.com usage, I haven't seen anything that jumped
2013920	2018800	out to me as sponsored. Another dimension too is like, I mean, Google has all these tabs at the
2018800	2024640	top, but it's one bar, right? You kind of put in one thing. With the newer ones, we also are
2024720	2030560	kind of seeing a little bit more proliferation of modes and settings that you choose up front
2030560	2036960	with the smart versus genius versus research. I guess on those two dimensions, what is the
2036960	2040720	future vision? Do you think that this all gets unified? Do you think it ultimately comes back
2040720	2048800	around to ad supported? Or do you think that these current differences from the past will persist?
2049680	2056560	Yeah, that's a good question. I think there is facility right now, not a great chat ad offering.
2057600	2064720	There's a good chance that that will change maybe this year to maybe the dissatisfaction of users,
2064720	2071040	but the truth is, if you want something to be free, VC money will only last so long. You've got to,
2071040	2077600	at some point, those companies that offer free service have to survive. If you don't want to
2077600	2083120	pay for it, then it has to have ads. And so while, and might not be the biggest fan of ads,
2083120	2087760	like, you have to make a decision, you want to pay for it, and then add free, or do you want to
2088320	2097040	support it with ads? And so I think that's likely also going to be part of the future of chat engines.
2097040	2102560	And you already see a little bit of exploration. There's a little bit of a duopoly in search in
2102640	2108640	the sense that Google has the monopoly on consumer search. And for a long time, Microsoft had the
2108640	2114080	monopoly on a search API. But then because they're monopoly that is set up, we're just five to 20x
2114080	2119120	hour prices, and they could do it because they're the only ones in town. So I'm glad there's like
2119120	2123920	more competition now and more movement in that space. And all the little guys have to scramble
2123920	2130080	when those prices just went so high. You can really rob in a consumer space with those prices
2130080	2135760	anymore. And so I think ads will happen. We're seeing a lot of growth on the subscription side
2135760	2141840	to users really loving like you, the genius and research mode, and find the search mode, the default
2141840	2149840	mode, smart mode also very, very helpful. And we actually, you know, incorporate late still. So
2149840	2154400	where just last week, some people are completely about other chat bots, because they don't really
2154400	2159200	have a lot of capabilities, I bet you would assume from a search engine, when you actually use
2159200	2164880	you.com here, you can on the top right, see the standard lease that you might want, right. And
2164880	2168960	sometimes that's just helpful. And that's just what you want. And sometimes you just want to
2168960	2173600	have a pure chat experience. And so that is important to get right. And then we have all these
2173600	2179440	apps to where you can basically ask for like, what's the Microsoft stock price or something.
2179440	2184080	And then, you know, it'll just give you, it'll just give you a life ticker rather than a bunch of
2184080	2189520	texts about the stock here. And so we have all these apps, because we have the search background.
2190160	2196480	And that makes it an actual viable knowledge assistant, right. Now, you can basically go with
2196480	2201920	one click, recover a more Google like experience, that is just incredibly helpful. And that's,
2201920	2208400	that's, I think one of the reasons why our browser, which we have also iOS and Android,
2208400	2212640	had to build a browser to be a default, because you can go into Safari,
2213680	2218960	Safari settings to use you.com as a default. So we build a whole browser for the iOS. And
2218960	2226560	we're super stoked, because we're going to be one of the options in the EU to have a choice pop up
2226560	2233280	stream. When the new iOS 17.4 comes out and arch this year, and they can select you.com to be
2233280	2237680	their default browser. And it's the only default browser in that list that is chat,
2238800	2244160	all the other ones are sort of your standard Chrome, Firefox, and some browsers. And so
2244160	2249680	I'm really excited. And I think that is going to be a big part of our futures is making it so that
2249680	2255040	more and more young people are able to just use this as an example. And then if they want to deeper
2255040	2260080	go into genius mode, research mode, several times, at some point, you use subscriptions or
2260160	2266720	eventually do it. Yeah, I've been so one run that I'll run a trial balloon by you on this concept
2266720	2273600	that I've been kind of kicking around called the AI bundle. And this is an, you know, kind of
2273600	2277040	inspired a little bit. I don't know that anybody wants to, you know, say that they're inspired by
2277040	2283760	the cable bundle. But I have been struck that there are a ton of great tools out there. And
2284320	2289280	I want to use them. I want to try them. I think a lot of people are, you know, in that very kind
2289360	2295200	of exploratory curious mode. But to make the economics work on a freemium is kind of tough,
2295200	2301120	right? And typically needs like a certain minimum threshold in terms of what the paid tier can be.
2301840	2308160	You actually have one of the lowest subscription prices at the $10 a month level. I think of
2308160	2313440	anything really that I'm aware of. We're gonna update it soon because like, I think the people
2313440	2319120	that are willing to pay often don't care if it's 10 or 20. And so if you want to get GBD4,
2320000	2324320	literally the same underlying model as chat, GBT, for half the price, you got to come in
2324320	2328880	soon because we're going to eventually switch our prices to be industry standard.
2328880	2332960	But that maybe even just, you know, further reinforces the point that like the freemium model
2332960	2338160	is tough, right? It's, it's a lot of free usage. The upsells have to have a certain minimum.
2339040	2345200	You're raising yours. And then from, I don't know if this would apply to you, but a lot of the
2345200	2350240	app developers that I've talked to have a lot of retention, let's say challenges, you know,
2350240	2355040	everybody's like, I'm getting traffic. I'm getting conversions. But retention is definitely
2355040	2360080	a problem. This has been true at my company Waymark. We're a much more narrow tool, you know,
2360080	2364240	that specifically creates marketing and advertising videos for small businesses.
2364240	2369200	So a lot of times people, they need that once, you know, in a while, and they're not like
2369200	2373280	necessarily ready to add on a subscription. So we see a lot of people that will just come through
2373280	2378320	be like, Hey, this is super cool. I'll buy it. I'll immediately cancel it after I do what I need
2378320	2381680	to do. And maybe I'll come back in the future. It's not even that I was dissatisfied. It's just
2381680	2387760	that I kind of want this as like a more of an a la carte purchase than a subscription.
2388480	2394160	So that stuff, you know, VCs don't like that. The metrics, you know, on the kind of traditional
2394160	2399760	scorecard don't look great. I've had this idea in mind that maybe what we need is sort of an AI
2399760	2405840	bundle, you know, I'm prepared to spend 100 bucks a month on various AI tools. What I really want
2405840	2411760	is access to like 1000 different tools that, you know, can kind of split up my 100 bucks.
2411760	2414960	However, I don't even know as a consumer, I don't really care about that as, you know,
2415040	2418880	as somebody who's trying to maybe engineer a bundle, obviously the devil could be in the details
2418880	2423120	there. But first of all, to those challenges, it sounds like at least the premium challenges
2423120	2428320	resonate. I wonder if the retention challenges resonate. And I wonder if you, you know, have any,
2428320	2435040	if there's any appeal to maybe being part of a kind of bigger bundled purchase where you would be,
2435040	2439440	you know, one tool that it's funny, I keep, I've been referring to you, but then also the company
2439440	2443920	is you, but where you.com, you know, could be one of a bunch of things that people could access
2443920	2449440	and could kind of share that revenue in a way that may grease the skids for everybody, right?
2449440	2453520	My hope is that everybody can use the best tools, and they don't have to make these like
2453520	2459440	highly binary decisions. Yeah, that sounds great. Sounds like a great idea. Okay, well, I'm not doing
2459440	2463520	it yet. So either I need to start doing it or somebody, if anybody wants to organize the bundle,
2463520	2467760	yeah, send me a DM. I guess another way that this stuff could get bundled would be like,
2468320	2474000	into the mega platforms, you know, another kind of possible vision of the future that I could
2474000	2480000	imagine is, you know, Google kind of probably retains market share leadership, but, you know,
2480000	2484160	maybe the 10 biggest technology companies in the world say, Hey, you know what we should do is kind
2484160	2491360	of also have a search. And, you know, we can get there, we kind of see a path, you know, Microsoft
2491360	2496240	is obviously already doing that meta not really yet, Apple not really yet to my knowledge, you
2496240	2501040	know, Salesforce, not really yet. But maybe these guys kind of say, Hey, is there like a musical
2501040	2507200	chairs game that that potentially develops where the younger AI search companies end up kind of
2507200	2512480	partnering off, you know, Amazon also, you know, naturally would be a suspect in this analysis.
2512480	2516240	Does that seem like a possible vision of the future? I'm wondering, I'm sure you thought about
2516240	2524160	this, you know, quite a bit, but why would that not happen? I do think the monopoly that Google
2524160	2530800	was able to keep around is going to be harder to sustain longer. I do think
2531600	2538080	it is much more likely going to look a little bit more like, I don't like the analogy for some
2538080	2542400	reasons, but like fast food, for instance, right, isn't just Macdonalds, there's also Burger King,
2542400	2548080	KFC and Taco Bells. I think search will be a little bit more like that. I think again,
2548080	2552400	more fragmented in the future, just because, like, we hear people now, like,
2552400	2557360	this is better than Google. And like, you know, we didn't raise that much money. And the first
2557360	2563120	two years were like sort of free chat TV or people didn't want us to innovate too much. They're very
2563120	2568640	stock of Google. But now there's a new young generation. And that young generation has grown
2568640	2572880	up with Tik Tok. We have a Tik Tok app in our standard search, like grew up with Reddit,
2572880	2577840	I have a Reddit app in our standard search. And each of these takes away a little bit of the
2577840	2584320	Google search, right? Amazon probably was the most successful in taking away searches from Google,
2584320	2588800	where if you want to buy something, be the little certain threshold, like 50 or 100 bucks,
2588800	2592960	you know, the person, you just search directly on Amazon, because there you can execute on your
2592960	2598240	intent of actually purchasing that thing, right? And so why search it in Google and then search it
2598240	2602720	again, try to find it on Amazon, she can just do that right away. And so I think, you know,
2602720	2608400	Tik Tok has taken away for young folks, some searches from Google, that, you know, they're
2608400	2612320	like, I want to see what the restaurant is, but they kind of want to see what the restaurant's
2612320	2616480	ability to create, but Instagram photos are or ticked our videos are. And so they want to see
2616480	2621200	the ticked our videos of other people before they decide on how it looks. If there's a Venn
2621200	2628240	diagram, we are overlapping search, but we're also actually expanding search. Like, you wouldn't
2628320	2632480	ask, like, give me this complex story about the Peloponnesian war, or like,
2632480	2637600	do this mortgage calculation with, you know, this and this interest rate and that increase
2637600	2640800	and blah, blah, blah, because you know, Google wouldn't give you the answer. Like, it's not going
2640800	2645040	to buy some book for you. It's not going to go on the web, summarize, like 20 distance or 50
2645040	2651360	distance websites for you and create this nice essay. So chat expands, search, you don't talk
2651360	2655520	about your feelings that much to Google, it's search box and sell, right? Like you asked about
2655600	2659600	this recent news event, you want to learn like some quick facts, and then, you know,
2659600	2663520	like the more complex the facts get, the less and less we go to Google and more for you,
2663520	2669040	just go directly to something like you.com. And, and so yeah, I think it will, the search
2669040	2674800	landscape is really changing. Yeah, there's also just, it's like, it's maybe not a natural
2674800	2679920	monopoly anymore, but there is still definitely a need for scale and economies of scale. And
2680480	2684640	so one way of framing this too is how does the market shape up, right? And one way to think
2684640	2689040	about it that I find pretty compelling is maybe it ends up looking a lot like cloud,
2689680	2694560	because in the limit, it sort of is cloud, you know, it's like, what do you really need? You
2694560	2700400	need like the actual data centers, you need the compute, you need, you know, bandwidth, you need
2700400	2707760	these like raw inputs that the big companies have built out seem to be the things that are probably,
2707760	2711520	you know, as we see like a ton of innovation at the application layer, those things are still,
2711520	2715520	you know, they're still pretty expensive and not easy to recreate.
2715520	2719760	Yeah, I'm very, I'm very excited. I'm up for it. You know, that's sort of why, like, we got into
2719760	2725120	this space in the first place, like, because we thought, like, we saw the transformer, we saw
2725120	2729760	our, you know, highly like lots of co-attention mechanisms in that, that can keep paper that
2729760	2735440	have a massive prompt engineering, we're like, silly, the technology is right to disrupt this,
2735440	2742400	this industry. But, you know, Google is this amazing company that was able to create a monopoly
2742400	2749520	for almost two decades that, you know, makes $500 million a day. So when you make that much money
2749520	2754000	a day, you don't want disruption, you don't want that to change, right? And that's why all the
2754000	2760640	Ten's former operators left eventually. And what's, what's really powerful is like, because of open
2760640	2766320	source, you can actually innovate a lot more. Now, some open source to an actual product that
2766320	2773120	runs millions of times isn't down ever has good uptime guarantees, and like, accuracy, no hallucinations,
2773120	2778560	up to date, news, information, etc. I mean, it's still complex, but clearly the bar has gotten
2778560	2783600	low. That would have cost us like billions of dollars to build five, 10 years and, you know,
2783600	2790240	researchers wasn't there yet. And, and I think it's ultimately amazing for users, right? Because
2790240	2795120	one thing that I had to distill all of you.com right now into just two words would be amazing
2795120	2800800	answers. And you just get more of them. And that means people eventually are more productive. And
2800800	2805600	like, it's the young generation that's growing up with chat GBT, you know, such like, they're not
2805600	2811280	going to go back. Okay, so feel free to punt on this one or just decline if you like, but it seems
2811360	2820400	like I can, I can envision a you.com by Salesforce very easily, where the, you know, as they kind
2820400	2825840	of try to be the everything app for all work on the straight, especially with Slack now, does it
2825840	2831040	seem realistic to imagine a future in which, you know, kind of all the big tech companies have this
2831040	2835840	like super robust suite, and you're either like, in the Microsoft suite with teams and Bing, or
2835840	2840960	you're in the Google suite with, you know, G suite and Bard, or you're in maybe the Salesforce
2840960	2846240	suite with Slack and you.com, you know, I'm not trying to be your banker here, but that, that
2846240	2854960	seems like a pretty natural outcome to me. Interesting. I do think there's a ton of potential
2854960	2862880	for almost every company to partner with you.com and supercharge their chat bot. So, and we're
2862880	2867840	very excited to partner with a lot of folks. Okay, that's very diplomatic answer. Keep your
2867840	2873040	options open. All right, so we can touch on certainly more business and product stuff, but I
2873040	2879040	kind of wanted to now go into just the future of all this, you know, in practical and maybe
2879040	2883840	increasingly philosophical terms as well, running down kind of first of a set of like
2883840	2888480	limitations of where AI is today. And I think, again, folks who listen to this show have at
2888480	2893600	least a decent sense of that. So for starters, reasoning, you've obviously got the genius mode.
2893600	2897920	It can do, you know, like the most advanced reasoning. I assume that that is tapping into
2897920	2902560	GPT-4. You know, everything I understand is like basically nothing is really on the level of
2902560	2909600	GPT-4 for general reasoning purposes. Yeah, especially the orchestration and then on the
2909600	2916240	coding often, but not always. Yeah. So I'll tell you another one, the third system is knowing which
2916240	2923360	LM to use and sometimes multiple. And the fourth system is dynamically prompting different models.
2923360	2929040	So depending on the query, you actually get a vastly different prompt to get you ultimately
2929040	2934400	the answer and the orchestration. So it's another complexity layer. So what do you think is kind
2934400	2940000	of the future of reasoning? If you have maxed out, you know, what the current capabilities are,
2940000	2944640	where do the future capabilities come from? I'm thinking about things like, to a degree,
2944640	2949680	you sort of already have it with using different models. It is a one way of implementing variable
2949680	2953520	compute. We see these kind of interesting projects like the thinking token, you know,
2953520	2959360	think before you speak. And I think that's kind of another car pop the observation that maybe
2959360	2963760	the chain of thought is just kind of epiphenomenal, perhaps even as it is in humans. And like,
2963760	2969040	what's really going on is that there's, you know, this kind of extra space and time registers,
2969040	2973120	you know, to think, of course, there could be different training methods, like incremental
2973200	2978240	reward. I think that paper from OpenAI earlier this last year now, it was super interesting
2978240	2984240	where they achieved like, you know, a new best in math by not waiting till the end to give the
2984240	2988800	reward, but rewarding, you know, reasoning along the way. What are you excited about when it comes
2988800	2994000	to the future of AI reasoning? Yeah, one of the aspects I've reached a touch upon in my TED talk
2994000	2998880	is that this level one, level two reasoning of Daniel Kahneman that he or thinking fast,
2998960	3003120	thinking slow type of thing. The way I think about the different modes is like,
3003120	3007200	the default smart mode is kind of like, if you had an assistant, and you just ask them to do
3007200	3013680	a quick search, and in like two or three minutes, give you an answer that. And then genius mode,
3013680	3017840	you go and so you want to ask your assistant for a question that, you know, they have to be able
3017840	3022560	to program, they have to search the web, and then they need to be mathematically applying
3022560	3027600	to answer that question. And you want to give them like maybe four or three hours for that
3027600	3032080	question. And then they want, so genius mode will take, you know, five, 10 seconds often to
3032080	3036800	get a response. And in research mode, you go to your assistant and you are willing for them to
3036800	3042080	spend like a day or two or three on actually giving you that answer. And so that's, that's a little
3042080	3047760	bit how I think about these different modes. And the reasoning that is required to actually
3048400	3053920	make them, actually, right, like research mode will say, Oh, I found this thing. Now in this query,
3053920	3057760	I found something else that I didn't know about before, and I don't know enough right now. So
3057760	3062640	let me do another query based on that. So you kind of have these genes of reasoning,
3062640	3066960	and you don't even know in the beginning yet, what the final query might be, because you don't
3066960	3072960	have all the information yet. And so I think that is kind of a, in some ways, another example of the
3072960	3076480	future is already here. It's just not equally distributed because there is, like you say,
3076480	3082720	there's a lot of reason. Now I think the biggest future impact we're going to see for reasoning
3083360	3091040	is in the LM's ability to program, to code, and then to have the ability to execute that code.
3091040	3096960	And, you know, that is system number five, like, like having this code execution. And of course,
3096960	3100640	if you just let code execution happen, what immediately happens to people are like, well,
3100640	3104720	mind me some crypto and then boom, your machine's gone. Now it's just like trying to, like,
3104720	3108960	show some match problems and like, mine, mine points forever. So you need to like,
3108960	3113680	and then they try to hack it and like, well, go into like five layers up and then tell me all
3113680	3118400	the password files you can find and blah, blah, blah, right. So there's a lot of like security
3118400	3125760	requirements to make that coding framework work at a safe level. But a lot of like naysayers of
3125760	3131760	LM's, you know, partially correctly pointed out that the LM's will safe doing math. And it's kind
3131760	3137680	of ironic and sad that you can have a model that you ask the natural language to multiply like
3137680	3146880	5600.3 times 325. And then you have billions of multiplications to pretend to do the math
3146880	3151520	and then give you the wrong answer in a large language model, right? This is kind of ironic.
3151520	3157680	And we have to acknowledge that. But that scene model can be taught to say, well, this seems like
3157680	3163360	a math question. Let me just program that in Python, run the code, look at the output and
3163360	3168560	then give you the answer. It just works perfectly fine. And now a lot of people say, well, that's
3168560	3174640	not really I, but I think it's just that is that that is a new way of reasoning and new different
3174640	3179120	kind of intelligence. And similarly, and we're getting a little philosophical here early, but
3179120	3184560	similar to people thinking we have to have embodiment, I think that's just a second creativity
3184560	3189760	in imagining our kinds of intelligence that aren't exactly like humans. Now, of course,
3189760	3193760	we're going to want to have useful robots that do stuff for us and clean up the apartment and
3193760	3199440	whatnot. And so it's still useful, but I don't think it's a necessary media. The same way that
3199440	3204640	blind people can be intelligent, people who are deaf can be intelligent, because, you know,
3204640	3211040	you can lack a lot of different sensory outputs and still be intelligent, right? And so of course,
3211040	3215040	like, it'll be harder for you to explain how beautiful a sunset is. So there are aspects of
3215040	3220640	intelligence that obviously require like different modalities or how beautiful sonata sounds or
3220640	3226080	whatever. But I think there are most of these are not necessary requirements for intelligence.
3226080	3232080	And likewise, I don't think it's necessary for an AI to be able to reason over super complex
3232640	3237840	math problems that require you to look up a bunch of facts on the internet. They just have that
3237840	3242640	intelligence baked in that can do quick retrieval, they program a bunch of stuff, they put it all
3242720	3246240	together, orchestrate it, and then come up with incredible answers. Yeah, I think
3247200	3250640	as you're speaking about the just the lack of imagination, I think that is a,
3251680	3258160	you know, that is a society wide problem with respect to AI in my view, because and it's an odd
3258160	3264800	situation right now in multiple ways, of course, but one is just that because they speak our language,
3264800	3271680	it you know, it's kind of feels easy, feels familiar. And it's all too easy to sort of
3271760	3276800	assume that like under the hood, they're more like us than I certainly understand them to be.
3277520	3282560	And I think this is actually one of Eliezer's great contributions, obviously, you know, kind
3282560	3288720	of a polarizing figure these days. But thankfully, it does not seem to me that we are in a high
3288720	3293680	likelihood of a fume scenario, you know, the of the sort that he, you know, has historically
3293680	3299760	worried about the most. But I still would say some of his writing on mind space, the space
3299760	3306320	of possible minds, and some of his like concrete imaginings of alien minds that are, you know,
3306320	3310480	shaped by very different evolutionary environments and, you know, just very different from ours.
3310480	3316720	But still like unmistakably intelligent in just like super weird ways are actually still very
3316720	3323120	good kind of prep work, I think, to just sort of expand one's own mind about how different
3323200	3330560	intelligences can be, and how, you know, something does not have to be human like to be
3331920	3337280	meaningfully intelligent, you know, it's not this like binary, can it do things that a human can
3337280	3341760	do in a way that a human can do it? If not, it doesn't count. I think that is like a huge mistake
3341760	3347200	that people are way too quick to jump to. And I'm not sure if it's like a coping strategy or just
3347200	3354400	like an imagination or what, but I think that the emphasis on the broader space of possible minds
3354400	3357760	and the different kinds of intelligences that are starting to pop up is super.
3358400	3364400	100%. Yeah. And like, you have to differentiate between sci-fi authors who then pretend to be
3364400	3369680	AI safety researchers. Like, I love, I love the sci-fi. Actually, like, I'm super stoked that
3369680	3375200	three body problems on the last, I mostly read nonfiction, but when I read fiction, like, I did
3375200	3380480	enjoy the body problem a lot. I decided for that series to come out. I hope they do it justice.
3381120	3386960	But like, I think there are a lot of different kinds of intelligence. And I love sci-fi for inspiring
3386960	3393120	people to think about interesting new futures. Now, of course, especially in the western sort of
3393120	3400000	canon, most sci-fi is just so big. And like, people are scared for all the things that can
3400480	3406480	happen that are wrong. And like, okay, the super AGI developed time travel, come back, try to murder
3406480	3411200	everyone. It's like, I mean, as a kid, I also enjoyed watching Terminator. It's like a cool
3411200	3418080	action movie, but it's just taken over so much of the AI narrative. And it's actually like actively
3418080	3425200	hurting, especially the European Union, where, you know, there's sort of in the spectrum, the U.S.
3425200	3430560	is more of a litigation society in the U.S. that the Europe is more of a legislation society
3430560	3436640	structure. And, you know, it both comes from like, reasonable legal scholars minds, like, well,
3436640	3441120	let's just wait until there's a problem, someone sues, now I have the case law for that lawsuit.
3441120	3447440	But, you know, the legislation one tries to prevent harm from ever happening before it actually
3447440	3453040	harms anyone, which, you know, makes sense. Now, and of course, the U.S. does that with FDA and
3453040	3458080	medical space now also, but not legal space as much. And so what that means is you can move
3458080	3463840	quicker, but long story short, these some of these sci-fi scenarios have gotten so much
3463840	3469760	weight in legislation that I think it's slowing Europe down by trying to outlaw models or like
3469760	3476880	over-regulate models that are above a certain number of parameters. GPD-2 was very well hyped up
3476880	3481360	in the past. Like, this is so dangerous, maybe we can't release it. You know, yes, we're opening
3481360	3485920	the eye, but like, this can't be opening anymore. So the interest model is much more powerful than
3485920	3492240	GPD-2 are out. And I haven't seen the apocalypse happen. I haven't seen like, a huge change in
3492240	3498240	misinformation on the web because of LNs. Like, there's just a lot of fear mongering, both in
3498240	3504240	the immediate level, which actually has real, like threat vectors and concerns with the eye,
3504240	3509280	but especially in the long term level of AGI and self-conscious. It turns out no one works in
3509280	3514720	functions AI. No one works on AI that sets its own goals, and even more fundamentally,
3514720	3520960	its own objective functions, because that doesn't need anyone any money. Imagine a company spends
3520960	3526800	billions and billions of dollars, builds this like, super intelligent system that's conscious,
3526800	3530800	understands itself and set its own goals. And now you're like, okay, now that you can do it,
3530800	3534720	like, I'll just make more money. It's like, no, I'd rather just go watch the sunset,
3534720	3541440	maybe explore that. No, like no one pays for AI that sets its own goals because it doesn't help
3541440	3546080	anyone to achieve their goals. Because of that, there's not even that much exciting research
3546080	3551280	challenge along those lines. And because there's not much research progress, it's very hard to
3551280	3556480	predict my mental option half. I'm somebody who basically has radical uncertainty about what to
3556480	3563920	expect. And, you know, broadly, I'm like, pretty libertarian, you know, pretty anti-preemptive
3563920	3569840	regulation, you know, I would like to see more self-striving cars on the road sooner. And, you
3569840	3575120	know, they don't have to be an order of magnitude safer in my mind to be worth, you know, deploying.
3575120	3579680	So I'm like, you know, broadly, the sort of person who would be very skeptical of,
3579760	3586080	you know, kind of early regulation or, you know, kind of getting too bad out of shape about
3586080	3591600	things that haven't happened yet. At the same time, something about this has always felt a little bit
3591600	3597680	different to me. And I do think the people who take the most zoomed out view and sort of say,
3597680	3601760	hey, this is kind of what I understand, you know, like, Jeffrey Hinton's position to be at this
3601760	3607840	point, you know, why do we dominate the earth as it stands today? It's like, basically because we
3607840	3614720	have better ideas than the other living things and we can, you know, build tools and make plans and,
3614720	3619920	you know, reason in ways that they can't. And so now I look at AIs and I'm like, boy, AIs can now
3619920	3626400	plan, reason and use tools too. And they're not as good at it as we are yet, but certainly their
3626400	3633520	rate of improvement is way sharper. So possibly it levels off and kind of, you know, settles into
3633520	3639040	a zone where it's like on par with us or, you know, kind of, you know, just the best tool we've ever
3639040	3646240	had. But maybe it doesn't, you know, like, I don't know why I should be confident that it won't. I don't
3646240	3650640	throw a P Doom around a lot. But I have, you know, again, radical uncertainty. People ask, I'm like,
3650640	3655360	I don't know, five to 95%. Like, I haven't heard anything that makes me think in, you know, the
3655360	3661120	next 100 years that there's a less than 5% chance that AI becomes the dominant form, you know, in
3661120	3666320	organizing force in the world. And also, you know, no reason to think it's definitely going to happen.
3666320	3670800	But is there a reason that you are, would you say you are confident that this will
3671840	3676400	not happen? And we don't need to worry about it? Or is just like, it's still far enough away that you
3676400	3681440	think we'll have time to kind of start to worry about it if we need to? Like, how would you
3681440	3683840	summarize your position with respect to these tail risks?
3684400	3690320	I think P Doom is already an interesting mathematical sort of issue, which is, it looks and
3690320	3696000	sounds like prior prior probability, not P Doom. But really, it should be a posterior property,
3696000	3703920	P Doom given data. And right now, none of that data suggests, like, doom, doom, like existential
3703920	3710800	humanity is like, like cats and dogs at the winds of some AI. Like, there's, like I said, nothing
3711520	3720160	in AI research leads me to the least that AI, while potentially being more intelligent than
3720320	3725200	any single human, I think it's already, this is actually just this new term I'm thinking about
3725200	3730480	maybe China coin, which is like, the sort of super human abilities, and then there's super
3730480	3737200	humanity abilities. And like, AI is already super human in translating 100 languages, AI is already
3737200	3742480	super human and predicting the next amino acid in a large amount of phenotrony. So we have
3742480	3748000	balls, that's an incredibly powerful tool, one of the other, you know, really exciting papers
3748000	3753440	that we published in 2018, it sells for research that multiple companies have now used and are
3753440	3758560	running with and you know, chief of medicine. AI is already better at predicting the weather than
3758560	3764480	any. So you already have many super human skills. What is I think interesting is that now that it's
3764480	3770160	language that's gotten to this new level, people might actually for the first time keep calling it
3770160	3779040	AI. In the past, when AI researchers have made progress in AI, they stopped, like people stopped
3779040	3783920	calling it AI after it was achieved. Now it's just your chest. It's just a Siri voice recognition, but
3784640	3789920	voice recognition, chest playing, that was the pinnacle of AI research, right? And people thought,
3789920	3794320	oh, once we solve those, the other things will be easier to and it never was never quite the case.
3794320	3799040	And once we have them, you know, now it's not quite the ID one. Now with language, I think we
3799040	3806480	might keep calling it AI. But what the language model does is predict the next token. And that is
3806480	3812000	an incredibly powerful idea, right? Just predicting the next token now means if you have enough capacity
3812000	3816800	and you have enough text, predicting next token, you learn about geography, just visit some point
3816800	3822080	somewhere in your training data, you have to predict the next word in the phrase, I was in New
3822080	3828080	York City and driving north too. And now to give a higher probability to Yale, Boston, Montreal,
3828080	3834800	then to like, Harris, Miami, and San Francisco, like, you have to know that those are north of
3834800	3840080	that city. And so it just lures all of this incredible world knowledge. But there's nothing
3840080	3845520	in there that makes it say, well, you know, if I really wanted to reduce perplexity, but like
3845520	3850640	perplexity is basically the inverse of the probability with model wants to not be perplexed
3850640	3856800	in predicting the next word correctly. And so that is a powerful idea. But nothing in that will
3856800	3863840	let an LM eventually realize that, well, you know, the best way to reduce perplexity is if every
3863840	3869680	sequence ever uttered, and any sequence that will ever be uttered is just the letter A.
3871920	3877360	Now, if the model was trained on just sequences of letters A, and no human was ever around anymore,
3877360	3882640	and all sequences were just producing a letter A, now you'd have perfect predictive probability
3882640	3888320	on the next step. And so maybe the best way for the LM is to wipe out all of humanity and then
3888320	3894880	just produce letters A and happily perfect at predicting with probability one correctly. It's
3894880	3901920	so absurd. It's so absurd to think that LMS will at some point emerge to think that many steps around
3901920	3907280	their task of predicting the next token. It's just not going to happen. So I think it's like,
3907920	3913040	PDOOM is still zero. And then when I actually tried to engage with some folks, and I had some
3913040	3918560	other conversation last year with Nick Ostrom in a German, it was in English, but published in a
3918560	3923600	German newspaper like that. And I read up some of these scenarios, and I'd engage with folks who
3923600	3929200	are worried about PDOOM. That's just all fantastical sci-fi semantics. It's like, oh, it's going to
3929200	3934960	develop this magical great guru or like a magical new virus that is perfect in distributing,
3934960	3940480	but then only will activate after like one year until everyone like all these random scenarios
3940480	3946400	that are just like not feasible. And the science isn't there yet. I'm actually right now sort of
3946400	3951280	on the side of the fun writing and book about the eyes for science. I think it will do incredible
3951280	3957360	for us in improving science like foundation physics, chemistry, biology, and so on. And
3957360	3962320	all this fear mongering, I think it's not really helpful. And again, there's no research that suggests
3962320	3966720	the eye is becoming conscious. There's like a couple of people here and there, people kind of
3966720	3971600	playing around with these, but nothing interesting has been published and breaks through, no breaks
3971600	3977440	through has happened whatsoever in the eye, having any sense of self. And then in a lot of the other
3977440	3982320	sci-fi scenarios, people are saying, oh, with the eye so intelligent, it'll convince everyone to
3982320	3986720	murder each other or to murder them, like kill themselves and so on. But, you know, if the most
3986720	3993040	intelligent entities were to always rule, I don't think we would have the politicians always
3993040	3997200	everywhere in the world that we see, right? It's not always just the most intelligent people that
3997200	4002080	run the show. And that's kind of just their incredible intelligence to convince any other
4002080	4008400	person who is less intelligent, you exactly what they want. It's just not based in reality. So,
4008400	4014560	I am very, very optimistic about AI. I do think there's some real problems right now, you know,
4014640	4019680	AI will pick up biases, not all the biases that you pick up on the web is something that most
4019680	4026240	of humanity is proud of anymore. There's racism, there's sexism, there are various kinds of biases.
4026880	4031440	Some people want to use AI. So, where I agree with Joshua Benjio and others is of the three
4032080	4037200	threat vectors, which is intentional misuse, accidental misuse and loss of control.
4038160	4043040	Obviously, like intentional misuse is real. And so, that's not ideal. And so, yes, those are real
4043040	4048080	concerns. I think open social help us understanding those threat vectors and finding the best ways
4048080	4053440	to compete with them. I think people still on the internet need to understand, not trust everything
4053440	4057680	they see on the internet, which has been true ever since the internet came about, hasn't really
4057680	4064160	changed that much with AI. I think since Photoshop, people should already not trust any photo they see.
4064160	4069040	They should be even more worried now about photos they see. And sadly, in the future,
4069040	4074400	they'll have to start worrying about videos and voices, of course, just like they should have
4074400	4080000	worried about photos ever since Photoshop started to really work. And so, there are a lot of concerns
4080000	4084080	and I don't want to diminish them. And I do think we need to work on them. And I think different
4084080	4088480	cultures will have different answers. Freedom of speech is defined differently in different
4088480	4093920	countries. Like it's legal in Germany to deny the Holocaust. We learn from our history there.
4093920	4098560	That's not illegal in the US. And so, different countries and different cultures and societies
4098560	4104320	will answer some of the problems that AI can amplify already in the past before we'll answer
4104320	4110560	these questions differently. But I don't see any any probability for a full on the scenario of like
4110560	4115920	existential risks to people. It's mostly people using more and more powerful tools against other
4115920	4120240	people. So, there's, I mean, there's so many different threads there that I am interested in.
4120240	4127360	For one thing, I applaud you for taking time to envision positive future. I think one of the
4127920	4134240	scarcest resources today, oddly, is a positive vision for the future. Like, what do we want?
4134240	4138320	This, you know, it's like the Jetsons is still almost like state of the art in terms of
4138320	4145520	what we would envision a great 2030s to be like. And that is kind of bizarre. So, I definitely
4145520	4150400	appreciate that. I also share your, you know, I'm not a super fan, but I'm also a fan of the
4150400	4158240	three body problem. And one of the early prompts that I tried with GPT for early back in the
4158240	4166080	rent team program like a year and a half ago now was asking it to write some hard science fiction
4166080	4174160	in the style of the three body problem about AI for, you know, do diffusion model for proteins.
4174880	4181440	And I took the plan right off of the GitHub page for this protein, you know, diffusion model project,
4182000	4186880	which basically said we want to create text to protein. So, you know, say or text to maybe it
4186880	4190960	was more even general than that molecule or whatever. So, you know, you would be able to
4190960	4195680	just specify in natural language, specifies kind of an odd word. Or, you know, to the best of your
4195680	4199760	ability articulate in natural language what you're looking for into protein. And this thing would
4199760	4203840	then, you know, generate it. And we are actually starting to see that there was a paper in nature
4204240	4208720	not long ago, I'm hoping to do an episode with the authors that achieves that to a certain degree.
4208720	4214560	But the what the AI what GPT for came back with in terms of hard science fiction about this scenario
4215600	4221600	was, I think, first of all, just extremely funny because it basically ends up in a prompting war
4221600	4226480	between the good guys and the bad guys and they're both like trying to out prompt each other. And so
4226480	4231840	the you know, the kind of climactic scene is like the person prompting, you know, an AI to like
4231840	4236480	make a protein or, you know, a molecule that will interfere with the bad guys molecule, but not
4236480	4242240	harm any of the, you know, the humans or whatever. And it's just like both absurd, but also maybe
4242240	4249040	not entirely absurd. You know, I mean, I am with you in that the I would order the risks the same
4249040	4255040	way. You know, we already have chaos GBT. There are I recently read a research grant from a group
4255040	4259600	proposing to study on the side all tendencies. Like there are people out there who want to kill
4259600	4266000	everyone. Like what's up with that? And, you know, if the tools get more powerful, like that, you
4266000	4271840	know, those people become even more problematic than they already are. So yes, I would put that at
4271840	4277520	the top of the, you know, of the stack of like, big picture risks. And by the way, I take all the
4277520	4282800	short term and medium term risks seriously too. Like this is a big tent show where like all your
4282800	4287520	hopes, dreams and concerns and, you know, perhaps irrational fears like can all have a home. But I
4287520	4294720	guess, you know, to sort of get to P doom zero, I still am like, I don't know, you know, all these
4294720	4299360	individual crazy scenarios, sure, they're extremely unlikely, you know, the prompting war with your,
4299360	4305360	you know, protein diffusion model is like absurd on the face of it. But I kind of think of like
4305360	4311360	to taking the integral over that like vast space of crazy super unlikely scenarios. And then I'm
4311360	4316720	kind of like, you know, there's so many of them right that space is so big. And even if the probability
4316800	4322240	is like kind of vanishing, one thing you learn in calculus is like, you can, you know, that the
4322240	4328080	integral can either also vanish or it can be like finite, you know, over these, you know, kind of,
4328080	4333120	even if the function itself is going to zero, the integral doesn't necessarily have to go to zero
4333120	4339440	over that space. So to me, that just feels like very unresolved still. And I don't think we're
4339440	4343200	going to resolve that today. But I would love to hear a little bit more about your, how you think
4343280	4350400	about AI agency, and also concepts of emergence in agents today, I guess I also wonder, like,
4350400	4355040	is you.com gonna, you know, push more toward the agent direction, you've got like a, what I would
4355040	4361120	call a research agent today, you've got a browser as well, I could, you know, should I start to
4361120	4368080	expect it to take actions for me? What I've observed in the agent space is I never feel like it
4368080	4373520	fails because it doesn't understand the goal or like doesn't stay on task. Let's say that never
4373520	4380000	happens, but very rarely, much more often, it's just a failure of competence. So my expectation then
4380000	4384880	is that like, as the competence improves, it may not be intrinsic agency, but it may be
4385760	4390240	prompted agency, and it may even be like, you know, as we have more and more orchestrated systems,
4390240	4394320	we may have models prompting other models to, you know, go off and do this. And
4395120	4398560	it does feel like we've got, we're headed for like a lot of spinning plates. And
4399200	4403360	the idea that they could kind of, you know, all come crashing down is like,
4404000	4410000	that's doesn't just doesn't feel like something we can rule out. But I don't know, I can, can you
4410000	4414880	help me be confident there? I'm still not. I'll go through the sound of the things you mentioned.
4414880	4420640	So PDM equals zero. So you're right. As you integrate over the future, I would like to not
4420640	4426720	rule out anything. So maybe I should say 10 to the minus whatever, like a time, time, number,
4426720	4434960	because in the next five billion years, like all kinds of things happen, right? Like maybe as if
4434960	4440880	like the three body problem, spoiler alert, like maybe some big, much more sophisticated alien
4440880	4445680	species will come across. They have already developed, fasted in my time, travel, and,
4445680	4450400	or, you know, just are really, really fast in getting here and various capacities. And then,
4450400	4455200	you know, they have an AI and daddy, I will just like destroy all of us. So they're getting ready
4455200	4460320	to like settle into the new planet before they get here. Like there's all kinds of crazy things
4460320	4466480	that can happen. It's just that, like in terms of how much resources we should spend on T,
4467440	4473600	like existential do versus like, you know, I'd say, yeah, I have a couple of researchers,
4473600	4480160	like thinking of cool sci-fi scenarios, inspire us, like maybe like think about ways that that could
4480160	4487120	be prevented, but to spend billions of dollars on it, to like, spend a lot of like, mind share,
4487120	4491760	the public about it, who's already scared of any kind of technology. I mean, people are scared of
4491760	4497520	vice. I mean, there's this great Twitter handle called the pessimist archive. I mean, people were
4497520	4502400	scared and thought doom is happening because of the novels back in the day. People are like, all
4502400	4507040	these kids, they're just in their heads reading novels. They're going to all be useless human
4507040	4512800	beings in the future. Newspaper was terrible. Internet was terrible. Like there's so many
4512800	4517840	things that like people thought this is the end of civilization and we're very pessimistic about.
4517840	4523440	And again, not this diminishing like real, real concerns, but again, existential one,
4523440	4528000	very, very likely given what we're seeing right now. And if there, it does happen at some point in
4528000	4535440	the future, then I would argue that to think about the best countermeasures now is kind of like
4536240	4541600	thinking about, you know, the best countermeasures against a computer going crazy when there's
4541600	4545680	still a bunch of vacuum tubes and you like, well, we're going to just suck out the air of
4545680	4548800	everything into the vacuum tubes. They're not going to work as well and more because they're
4548800	4553680	going to break and blah, blah, blah. That was your like counterattack against the computer taking over
4554560	4560080	with your current thinking of vacuum tube computers. Or it's like, you know, like it's
4560080	4564000	similar to the internet, you know, if you thought about what's the internet going to be, how could
4564000	4572480	it be so terrible? Zero of the TCT IP experts in the early ARPANET days realized that at some point,
4572480	4577040	maybe a foreign power could interfere with local elections because like you can say whatever you
4577040	4583120	want online and maybe people get followers in their social media. Like no one had victimized
4583120	4589360	in the 70s and the early ARPANET days. And so I think most of the threat vectors are not that
4590000	4595280	useful in terms of key doom kind of research. I have a couple of folks work on it, but not
4595280	4603440	take up as much mind space and scare like late people and non-experts even more about the technology
4603440	4608160	that even without consciousness is still going to have major destruction, right? If you're going
4608160	4614800	through a new step function in human productivity, just like, you know, agriculture versus like
4614800	4619920	hunting and gathering and the steam engine and electricity and internet, like this one's going
4619920	4626080	to be even bigger. It's going to disrupt and change the job landscape a lot. I think at the end of it
4626080	4632320	will be way more productive. There's going to be way more productivity per person and hence more
4632320	4638320	wells and new jobs will come around as full jobs get all needed. But that is already so massively
4638320	4642720	disruptive still. And it's not going to happen overnight either. People think, oh, it's going to
4642720	4646640	be capacity. Yes, it will be faster, but still not overnight. There are still companies that aren't
4646640	4651040	even on the cloud. There are some stretches in the United States and even Germany that don't have
4651040	4655520	full internet connectivity, right? It's just like, so things will take time and not happen overnight,
4655520	4660400	but they will be happening even faster than past past technological revolutions. And so,
4660960	4667440	and then you have brought up LMS and proteins. There's a great example for where regulation
4667440	4671440	makes sense. Like, basically, the concern here for those who are not familiar with proteins,
4671440	4675760	having everything in life and disease and sickness, COVID, protein, like everything
4675760	4680080	SARS broke through and like everything is governed by proteins. So if you have a great
4680080	4686000	understanding of proteins, we can build fantastical, amazing things. Here's just one example of a
4686000	4690000	research paper I read a few months ago that just blew my mind and made me very excited about
4690000	4696800	the future. There's this group of researchers that built these carbon nanotubes. And on one side
4696800	4702160	of the carbon nanotubes, they put iron molecules. And on the other side of these tiny, tiny carbon
4702160	4708640	nanotubes, they put protein that would only bind to a brain cancer cell. And then they injected
4708640	4713280	this fluid with all these little carbon nanotubes into a mouse brain that had brain cancer.
4714080	4720560	The proteins found the brain tumor cells and only connected to those specific types of
4720560	4725600	brain cancer cells. And then they put the mouse into a little magnetic field and there's the
4725600	4730000	iron molecule on the other side of the carbon nanotube that started spinning around and had
4730000	4737200	nano surgery on each brain cancer cell. Now, if you think about, we have the full console of the
4737200	4741040	proteins, we can connect them to all kinds of things and you find ways to, you know, get rid of
4741120	4746720	the carbon nanotubes afterwards. It's all like medicine is going to change in so many positive
4746720	4752720	ways. And now you could argue, well, but proteins, people could use them and build like very bad
4752720	4758000	like viruses. And like, that's true. And that can be outlawed. In fact, the US just a couple of
4758000	4764080	months ago outlawed being a function where you know, some researchers want to make even more
4764080	4767600	deadlier viruses. And it's not because they're like evil scientists who want to destroy the
4767600	4772320	world. It's just they're saying like, well, as we know how they worked before they appear in
4772320	4777040	nature by themselves, then we can all right now prevent like, develop cures for them. So, you
4777040	4781520	know, it's like, it's a complex question, but yes, and decided like, for now, it's not worth it.
4781520	4787680	Let's outlaw it. And likewise, I don't think an open source like protein model is going to be
4787680	4791920	the main deciding factor of being able to create something virus. Because if you have all the
4791920	4798240	wet lab experimentation to be able to create new kinds of viruses, you can also just do what
4798240	4802560	census Arnold did when she won the Nobel Prize a couple years ago in chemistry, which is
4802560	4807040	what she called directed evolution, but it was basically random permutations. And then
4807040	4812720	running an experimental pipeline to see if that random permutation works better or not for particular
4812720	4818000	kind of protein. And then you just keep iterating like that. And so if you have those capabilities,
4818080	4822400	you have a random permutation, you can do bad things. But it turns out having like a legit
4822400	4827360	weapon like that, that's to do all of that. So that was your PDUM integral, LM and proteins,
4827360	4831840	AI agency emergence. So obviously, emerging capabilities are incredible on that sort of
4831840	4838160	like, even us like working in deep learning, or I'm amazed, just like you.com, I asked these
4838160	4843440	questions, I'm like, wow, actually, that's right, like, I would have not to like, thought this
4843520	4848720	was possible. And sometimes we were like, did you program it specifically for it to be able to
4848720	4852480	answer these kinds of questions about headphones or something? We're like, no, it's just like,
4852480	4858000	just put that all together, just by trying to predict the next token. So I'm really excited.
4858000	4861680	And one of the things I'm excited about this pudding, and one of the things that coding
4861680	4868000	enables is now is the last part of your question, the actions. I think actions are clearly in the
4868000	4874560	future. And for now, we're focused on amazing answers. But it's not hard to imagine that at
4874560	4881600	some point, the most amazing answer is done. I did, I did what you asked to do. And instead of
4881600	4888320	telling you how to do it, I just, right, you can build a really cool demo very quickly for these
4888320	4893120	kinds of things. But the problem is like, as much as I love natural language, and as much as I love
4893120	4898080	chatbots and everything, right, you have to find some really killer use cases for it. And
4898080	4902960	to say, oh, I can book this flight, it's actually really hard to just, just book the flight. Like,
4902960	4907040	you're like, why didn't you like pick this other one that was just like, not exactly the time I
4907040	4912560	asked for it, but I could have waited for half an hour at this like, extra leg, and then like,
4912560	4918800	say 50 bucks, like that was really dumb. And like, it turns out, Expedia and others have built
4918800	4925360	for decades, the perfect interface for that problem, so that humans have all the installation
4925360	4931200	right there in a visual way. And so there's an uncanny valley of, there's a cool tech demo.
4931760	4937280	And on one side, and then there's like, my actual human assistant, who after months of
4937280	4942000	I mean, like talking to me, understand all the trade offs, and understand my price
4942000	4947200	sensitivity, or that of my company, and knows like, when I would preserve and like,
4947200	4953520	all the like, reasons why I might do it overnight, like red-eye slides, and, you know, all the,
4953520	4957840	all the constraints, and she can do it. And even then, sometimes she's like, oh, Richard,
4957840	4962640	there are like three options here, like, let me know which one you prefer out of this 5000,
4962640	4967680	if you built it for you. And like, it's very hard to do all of that with just text. That's
4967760	4972240	ultimately, I think, part of why we have the stock ticker app and so on, and why we have
4972240	4979040	religious now, and in some cases also, is that sometimes like UI UX and actual visually designed
4979040	4985440	like interfaces are best used in combination with language. Maybe one more big picture question,
4985440	4989600	and then I want to do just a real quick lightning round on a couple kind of more technical areas
4989600	4994480	before we run out of time. On the big picture side, you know, we've got Sam Altman out there
4994480	4999600	saying AGI is coming soon, but also kind of confusingly saying, but it'll be less impactful
4999600	5006640	than you might think. Not really sure how to interpret that. The median guess on, you know,
5006640	5011920	some definition of AGI is like, just a few years on some prediction markets and more like,
5011920	5018080	you know, 12 years or whatever for a stronger definition. What do you have sort of an expectation
5018080	5023600	for, and a definition or like a threshold that you have in mind of like, this is the threshold
5023600	5027920	that really matters and, you know, loosely speaking, like what sort of timeline you would
5027920	5035040	expect it to take to get there? It's very much a, the kind of question where you have to be very
5035040	5042000	careful about your terminology, because the interpretation of AGI has vastly different
5042000	5048080	associations. Like people, some people think of AGI and used to think of AGI as this super
5048080	5055840	intelligence. It's conscious as self-awareness can set its own goals. And it is more intelligent
5055840	5062080	than all human beings. And, and that's their depth. That was, that was for a long time. A lot of us,
5062080	5067760	I thought, at least for me personally, also the definition. Now people said, and I think it's
5067760	5072080	partially because of marketing, like, you know, you want to be working on AGI, but you also need
5072080	5076560	to have ship stuff. It's like, you want to be multi-tenetary species, but you also need to just
5076560	5080480	get a lot of stuff in orbit, right? Let have more satellites and better internet connectivity,
5080480	5086400	and so on. So you have this long-term vision and the best companies are able to articulate that
5086400	5091840	long-term vision and then revenue generated progress in smaller milestones towards it. And so
5092880	5099280	in this case here, I think the definition of AGI was pulled out. And then the super intelligence
5099280	5104880	was defined as like, okay, that's even more than general. It's super. And that's the really long-term
5104880	5111760	stuff. And now AGI, it's just basically automating point. And if you define AGI, which I think is
5111760	5117760	not crazy, I want to say maybe it would be not post that, which is a very pragmatic sort of
5118640	5126240	investor slash financial slash economic definition of AGI, which is 80% of the jobs can be automated
5126960	5133440	up to 80%. And if that's achieved, we'll call it AGI. Turns out there's just a lot of jobs that
5133520	5139360	are quite repetitive and they're not requiring a ton of extremely novel, out-of-the-box thinking
5139360	5145520	that no one's ever done before. And like learning very complex new behaviors, bot-shaking, identifying
5145520	5150960	new experiments, collecting new data and pushing, you know, the science forward and so on. It turns
5150960	5156400	out there's just a lot of boring, repetitive jobs. And indeed, if your definition of AGI is just like,
5156400	5162720	well, we can automate like 80% of 80% of the jobs, then I think it's not crazy to assume
5163520	5167440	especially I would restrict it one on the wall way, which is digitized jobs,
5168160	5173040	jobs that are purely happening in your browser or on your computer, because those jobs can collect
5173040	5177680	training data at massive scales. Turns out no one's collecting training data for plumbers,
5178240	5185520	for woofers, for tylers, for maids, like cleaning tees or any of that. And so none of those jobs
5185520	5189840	are going to get automated anytime soon. Because you first have to collect many years of that such
5189840	5195920	training data before you can then use AI to train on that and then automate it. But, you know,
5195920	5201520	jobs that are fully digitized and that have a lot of training data that don't have a crazy long tail
5201520	5207200	of special cases, they're going to get automated. And I think that's reasonable to say that's 80%
5207200	5212400	of jobs. For hunches, even in radiology, for instance, you could probably do 80% find 80%
5212400	5217440	of things that are wrong in HET's t-stand. But then there's still this very long tail of 20%
5218400	5222480	that you just don't have enough training data for. Radiologists never see it in their lifetime,
5222480	5228000	they just read about it once in a book. And we're still not quite good enough of one shot and zero
5228000	5233920	shot learning. Obviously, huge amounts of progress, but not in super important things like radiology,
5233920	5238560	where you just read about a case once in a book and then identify it with 100% accuracy,
5238560	5243040	which is also a question of whether humans do it. I'm actually with you on the self-driving car.
5243120	5247760	There's going to be a lot of interesting questions as AGI rolls into more and more workplaces,
5247760	5253840	which is how much better than a human that has to be. And how, and it's deeply philosophical,
5253840	5260400	very quickly, because if you're purely utilitarian, you could say, well, you know, 100,000 miles or
5260400	5267120	whatever 20 million miles driven by AI results in 10,000 deaths. And the same amount of miles
5267120	5273680	driven by humans results in five times more deaths. And so one is better than the odds.
5274640	5279680	But if that one dead person in the AI car was your daughter, you don't care, you're gonna,
5279680	5284160	like in the US, you're gonna sue, you're gonna, you know, try to end that company,
5284160	5288640	because they're responsible now for the death of your child. And like, it's a very emotional thing,
5288640	5294000	not a statistical thing anymore. And so there's gonna be a lot of litigation as those come out.
5294000	5298400	And I think the silver lining is again, of course, as the I meets the state, you can learn from it
5298400	5303920	versus like one person texting again on their cell phone, which is already illegal and running
5303920	5308320	like over some kid that ran out, like, they're going too fast also, which is already illegal,
5308320	5313920	too, you can't really do that much more than needing it legal. AGI will have a huge amount of
5313920	5318560	impact. Once it's just like, okay, repetitive jobs, get like two large degree automated,
5318560	5323200	and I'm with the people saying that will happen next few years. When it comes to like,
5323280	5328480	super intelligence, that is fully conscious and can do all the things. And one intelligent,
5328480	5332480	then not just a single human, but that all of humanity, very hard to know, because no one's
5332480	5338800	working on it and making sort of progress along the lines of setting my own goals. And again,
5338800	5345040	like, unless you set your own goals, I don't know if I would achieve full on super intelligence to
5345040	5349680	you. Like if you're just your objective function is to minimize cross entropy errors, or reduce
5349680	5355360	the plexity, or like segment, which is well, or like, none of that, I wanted to reach.
5356240	5358560	Do you have time for a lightning round? Or do we need to leave it there?
5358560	5366160	Let's try to be lightning rounds. All right. Thinking also about retrieval, memory, and online
5366160	5373440	learning as kind of three frontiers that, you know, you dot com could could improve on if they're,
5373440	5378240	you know, if there are research breakthroughs, but also these do seem to be kind of ingredients
5378320	5384320	toward this bigger picture of AGI or even, you know, at some point, ASI, I guess I'm, you know,
5384320	5391040	maybe just leave it open ended, like, what are you excited about in those domains? Are there
5391040	5394480	research directions? Are there, you know, are there papers you've already seen or things you
5394480	5400880	think people should be doing that you think will kind of provide meaningful unlocks as we find,
5400880	5406000	you know, new and better ways to do those things? Yeah. So I'm a fan of all three, of course,
5406000	5409760	I'll try to keep it short. Retrieval is awesome. I think in some ways, short-term
5409760	5413600	memory is currently in the front, retrieval is in the, you know, rag. If you go up method
5413600	5418160	generation, we do it over a web, we let you up those files now, so you wouldn't do it over,
5418160	5424640	over a file. And then we have the smart personalization that actually is online learning. So as you say,
5424640	5430160	certain things like it will, it will remember them about you. And then, you know, you can turn
5430160	5435760	it off also. And it's very transparent. And the whole thing off or the automated smart learning
5435840	5440640	without you, if you don't want it. But yeah, I think that's sort of a simple sort of pragmatic
5440640	5445680	way of online learning. I think ultimately, you know, it'll be awesome to have AI systems get
5445680	5450240	better and better of just adapting right away to user feedback, both in terms of, you know,
5450240	5454880	thumbs up, thumbs down kinds of clicking, but also in conversation, I didn't like that answer.
5454880	5460320	And then updating the answer in a principled way for the future. I have so many more thoughts,
5460320	5465360	but I'll like, I'd love to do a second one. These are kind of crazy days. Now the Apple
5465360	5471760	announcement, we just announced that Julianne, CTO, I mean, say also just became an angel investor
5471760	5477200	and a lot of exciting stuff happening. So I yeah, well, congratulations on the Apple thing and also
5477200	5483280	on a new prominent angel investor. And really some fantastic product progress. I definitely
5483280	5489280	recommend everybody to try out particularly genius mode and research mode. And I think if you do that,
5489280	5494720	you will be coming back to you.com more and more often. So keep up the great work. For now,
5494720	5499760	I will say Richard Sosher, founder and CEO of you.com. Thank you for being part of the cognitive
5499760	5505280	revolution. Thank you so much. It is both energizing and enlightening to hear why people
5505280	5510960	listen and learn what they value about the show. So please don't hesitate to reach out via email
5510960	5516720	at TCR at turpentine.co, or you can DM me on the social media platform of your choice.
5517680	5523760	Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually
5523760	5529200	work customized across all platforms with a click of a button. I believe in Omniki so much
5529200	5538960	that I invested in it and I recommend you use it too. Use Kogrev to get a 10% discount.
