WEBVTT

00:00.000 --> 00:09.000
When I have an article idea, I'll often start with just this like really messy document full of quotes and sentences and little like things that might go into it.

00:09.000 --> 00:15.680
And then I'll be like, I don't even know where to start with this. This is crazy. And then I will just be like, can you put this into an outline?

00:15.680 --> 00:23.400
And I'll just paste the entire document into chat GT and it'll often find an outline. And like the the outlines it comes up with are like really basic.

00:23.520 --> 00:34.840
But sometimes I think what is one of the things is really good at is like pointing out the obvious solution that you missed because you're too like close to the problem.

00:34.960 --> 00:43.560
Hello, and welcome to the cognitive revolution, where we interview visionary researchers, entrepreneurs and builders working on the frontier of artificial intelligence.

00:44.160 --> 00:53.640
Each week, we'll explore their revolutionary ideas. And together, we'll build a picture of how AI technology will transform work, life and society in the coming years.

00:54.120 --> 00:57.320
I'm Nathan LaBenz, joined by my co host, Eric Torenberg.

00:57.920 --> 01:05.440
Hello, and welcome back to the cognitive revolution. Today, we're sharing an episode of the new podcast. How do you use chat GPT?

01:06.120 --> 01:14.280
How do you use chat GPT is hosted by Dan shipper, founder and CEO of every a daily newsletter that promises the best business writing on the Internet.

01:15.080 --> 01:23.360
In just his first few episodes, he's had guests on the show, including saw Hill, LaVingia, Matt Eliason, Linus Lee, and today yours truly.

01:24.640 --> 01:29.280
This conversation is both extremely practical and a real exchange of ideas.

01:29.960 --> 01:36.800
Coming into it, I had used chat GPT mostly for unfamiliar tasks where I really needed help orienting myself and getting started.

01:37.320 --> 01:41.320
And of course, I've got great value from a wide range of different use cases.

01:42.240 --> 01:47.200
But to be honest, I hadn't found chat GPT super helpful for my own writing process.

01:47.640 --> 01:53.920
So I was really interested to learn more about the methods that Dan has developed to use chat GPT as a thought partner and a writing assistant.

01:54.880 --> 01:57.840
Learning from him inspired me to do more of this for myself.

01:58.240 --> 02:02.000
Toward the end of the episode, Dan asks me what I am most excited about next.

02:02.160 --> 02:09.120
And I mentioned the new Mamba architecture and state space models more generally, which I honestly can't stop thinking and talking about.

02:09.800 --> 02:12.280
We'll have a big episode on this coming very soon.

02:12.640 --> 02:23.840
And I'm glad to report that I did use some of Dan's recommendations to help develop the strategy, the devices and the overall structure for that episode in a way that I did find legitimately very helpful.

02:24.920 --> 02:31.400
One note before we get started, there are a few points in this episode where we each shared our screens to show off content visually.

02:31.720 --> 02:38.520
And while I think you will be fine with just the audio version, if you want to see the visuals, you can check out the YouTube version of this episode.

02:39.600 --> 02:41.560
Of course, there's always lots more to learn.

02:41.560 --> 02:47.520
So if you like this sort of content, I encourage you to check out how do you use chat GPT with Dan Shipper.

02:47.920 --> 02:48.680
Welcome to the show.

02:49.520 --> 02:50.000
Thank you, Dan.

02:50.000 --> 02:50.600
Great to be here.

02:50.600 --> 02:51.360
I'm excited for this.

02:51.840 --> 02:52.640
I'm excited too.

02:52.920 --> 02:55.360
For people who don't know, you are the founder of Waymark.

02:55.400 --> 03:01.440
You are the host of the excellent podcast, Cognitive Revolution, and you were a GPT for a red teamer.

03:01.440 --> 03:10.720
So you were responsible or one of the people on a team of people who were trying to figure out how to make GPT for do bad stuff before it was released, which you had a really interesting tweet thread about.

03:11.040 --> 03:11.360
I don't know.

03:11.360 --> 03:13.720
I think a couple of weeks ago or two weeks ago, something like that.

03:14.200 --> 03:15.640
So we're very excited to have you.

03:15.640 --> 03:19.040
I think you'll have a lot of insights that I'm excited to share with everyone.

03:19.680 --> 03:35.640
I think one of the things in thinking about your work that stands out and thinking about Cognitive Revolution, in particular, the podcast that you run, is I think you have this idea that one of the values of AI is in helping us to offload Cognitive Work.

03:35.680 --> 03:47.640
So just like in the way that machines in the Industrial Revolution, we offloaded like manual physical labor, AI will augment or offload a lot of cognitive labor from humans.

03:47.640 --> 03:49.760
And I wanted you to just talk about that.

03:50.080 --> 03:51.600
Tell me more about what that means.

03:51.600 --> 03:53.960
And then tell me, is that a good thing and where is it a good thing?

03:54.640 --> 03:55.600
Well, that's a big question.

03:55.640 --> 04:03.880
I would say I talk about AI doing work and helping us in a couple of different modes for starters.

04:04.040 --> 04:22.640
We will probably spend most of our time today in what I call co-pilot mode, which is the chat GPT experience of you are as a human going through your life and going through your work and encountering situations where, especially as you get used to it, you realize, oh, AI can help me here.

04:23.000 --> 04:31.160
So you make a conscious decision in real time to switch over to interacting with AI for a second or a minute or whatever to get the help that you need.

04:31.600 --> 04:32.800
And then you proceed.

04:33.440 --> 04:38.720
But you are the agent in that situation going around and pursuing your goals.

04:39.160 --> 04:42.640
In contrast, the other mode that I think is also really interesting is delegation mode.

04:43.200 --> 04:47.760
And that is where you are truly offloading a task.

04:47.800 --> 04:58.080
And I always say the goal of delegation mode is to get the output to the point where it is consistent enough that you don't have to review every single output.

04:58.920 --> 05:06.960
And if you can get there, then you can start to really shift work to AI in a way that you no longer have to do it.

05:07.200 --> 05:09.760
And that can that can be useful in different kinds of ways, right?

05:09.760 --> 05:12.680
The co-pilot mode is about helping you be better.

05:12.680 --> 05:17.480
That's your classic symbiosis or intelligence augmentation.

05:18.120 --> 05:27.840
And then the delegation mode is more like we can save a ton of time and money on things that used to be a pain in our butts, or we can scale things that are not currently

05:27.840 --> 05:31.080
scalable. And there's a lot of that in the world, right?

05:31.360 --> 05:44.520
I think almost everybody has things where they would say, you know, if you just ask the question, is there stuff that you could be doing that would be really valuable to have done, but you just don't have time to do it?

05:44.640 --> 05:47.480
There's a lot of that that can be quite transformative.

05:48.000 --> 06:00.720
In the middle, and what's kind of missing right now still is between co-pilot mode, where you're getting this kind of real time help and deciding how to work it into whatever you're doing.

06:01.040 --> 06:13.440
And delegation mode on the other end in between is ad hoc delegation, where it's I'm going along, but I want to, ideally, I would like to delegate more and bigger sub tasks to AI on the fly.

06:13.920 --> 06:20.040
And that's where we're not quite there yet. The agents probably can't do much in the way of a significant task.

06:20.040 --> 06:34.280
So it's, you're still shoehorned into one of two scenarios where you're engaging with it in real time and getting help, or you're going through the process of doing a setup and doing a validation, setting up a workflow to where you can truly delegate.

06:34.400 --> 06:41.320
And it's that in between that I think is probably that gap gets closed over the next year as agents, quote unquote, begin to work.

06:41.560 --> 06:45.560
And then we can start to delegate bigger chunks of work on the fly.

06:46.400 --> 06:50.360
The next question was, is it good? I don't know if I have a great answer to that. I think it's largely good.

06:50.520 --> 06:58.480
It's I think it says it's good as long as it's it's good as long as humans stay in control of the overall dynamic.

06:58.800 --> 07:07.600
And I'm definitely one who considers everything to be in play for the future, both on the positive side, I don't think it's crazy to think of a post scarcity world.

07:08.200 --> 07:22.480
And on the negative side, to quote Sam Altman, I wouldn't rule out lights out for all of us. I think we are definitely playing with a force here that has the potential to be totally transformative in good and bad and probably a combination of ways.

07:23.120 --> 07:28.400
I'm thrilled by how much more productive I can be. And that's some of the stuff that we'll get into in more detail.

07:28.920 --> 07:42.000
I am thrilled by the prospect of having infinite access to expertise, and especially for people who have far less means than I do to have that kind of access to expertise.

07:42.040 --> 07:50.440
I am a pretty privileged person who can go to the doctor without really thinking twice about taking the time off from work or what that's going to cost me or whatever.

07:50.680 --> 08:02.480
Obviously, a lot of people don't have that luxury. I think there is a real way in which AI can cover a lot of those gaps, not fully yet, but already significantly and obviously more and more over time.

08:02.760 --> 08:08.760
I think that kind of stuff is going to be potentially disruptive and maybe the source of a lot of political debates and challenges.

08:09.240 --> 08:13.880
But anyway, yeah, there's there's so much upside, but I think there is very real risk.

08:13.960 --> 08:26.640
And it's very easy to hold those two perspectives at the same time, to be just thrilled by the capability, but also to be always, always keeping in mind a sort of healthy fear.

08:27.160 --> 08:38.560
I love that. I think that's such a rare perspective. And as humans, we just tend to collapse on one. Either it's horrible or it's great.

08:39.000 --> 08:48.320
And then we have these camps. And I think, like, obviously, the wise perspective is there's going to be some really amazing stuff about this.

08:48.360 --> 08:54.680
And there are dangers, like when technology changes society and change, it'll change our brains, like we will adapt to this.

08:54.720 --> 09:01.800
And in the same way that it is adapting to us, that will change things and we'll need to, like, deal with the dangers that it presents.

09:01.800 --> 09:08.320
I think that's a very wise perspective. And I ask that question, is it a good thing that cognitive work will be offloaded?

09:08.320 --> 09:17.320
Because I think that there's good and bad. But one of the things that I feel is the fear scenario is like, is quite dominant for a lot of people.

09:17.800 --> 09:27.400
And, and I think the people who are like anti fear or presenting a hopeful view are a little but they're a little bit too like rose colored glasses.

09:27.800 --> 09:45.920
And I think finding real ways and real use cases for how offloading some of this cognitive work actually helps people is just like a really important part of creating a world where AI is a force for good or force for creativity,

09:45.920 --> 09:52.000
rather than a world where it just replaces people or it creates dangers or there's all the bad scenarios.

09:52.000 --> 10:08.800
And one of the things that I've felt going back to your kind of co pilot mode versus delegation mode point, one of the things that I felt is that AI reveals to me how much drudgery there is, even in highly valuable, highly creative knowledge work.

10:09.600 --> 10:19.480
And that we sort of like lie to ourselves about the amount of drudgery because that work is so romantic compared to, I don't know, I don't know, working in a factory maybe or just any other kind of job.

10:19.880 --> 10:31.480
And it's, it's easy to look at a lawyer and be like a lawyer's job is full of drudgery or whatever. But I write, I run a business. I have a YouTube show. Now I have a podcast. There's a lot of stuff that's like just pure drudgery of that.

10:31.520 --> 10:46.720
And I find it really interesting because using chat GBT using AI tools more broadly, it has made me aware of how many repetitive or like just overall kind of brain dead things I have to do just to write something smart on the internet on every.

10:47.160 --> 10:55.560
And once it's visible, I use AI for it. And then I don't have to think about it as much anymore. And I think that's a really cool thing.

10:56.520 --> 11:16.080
Totally. For me, coding comes to mind most there when you talk about the drudgery of high value and again, pretty privileged work to be doing. But I'm not a full time coder have been for a couple short stretches in life, but more often I've been somebody who's dipped in and out of it.

11:16.320 --> 11:35.340
And it is a real pain in the butt to have to Google everything. Obviously, different people have different strengths and weaknesses. I do not remember syntax super well. Sometimes if it's been a while, I'm like, wait a second, am I, is this am I remembering JavaScript or am I remembering Python?

11:35.340 --> 11:56.260
Yeah, what exactly is going on here? Yeah. And so to be able to just have the thing type out even relatively simple stuff for me is a multiple x speed up often in terms of productivity improvements, often an improvement in just strict quality to compared to what I would have done on my own.

11:56.460 --> 12:14.940
Yeah. And makes it so much easier to get into the mode in the first place. There's this kind of, I wouldn't even call this drudgery, but it's gearing up just like somehow getting my people talk about in birdwatching getting your eyes on really focusing on what are you seeing and trying to like get that detector right.

12:14.940 --> 12:26.340
There's like a similar thing, at least for me in terms of getting into code mode. And it also just streamlines that tremendously, because next thing you know, it's writing the code and I'm reading the code reading the codes a lot easier than writing the code.

12:26.700 --> 12:43.180
So I do find, yeah, just tremendous satisfaction, you know, pleasure in just seeing this stuff like outputted for me at superhuman pace better, better than me quality, maybe not superhuman quality, but super Nathan quality. It's awesome.

12:43.420 --> 13:08.260
What you're making me think about is, because I think in large part, not all of it, but in large part what the current class, especially of text models are doing is different forms of summarizing and how like how much summarizing is involved in creative work and programming in writing in decision making a lot of it is just summarizing

13:08.260 --> 13:32.380
like in programming, you're summarizing what you find on Google. You have to decide what to summarize and you have to summarize it in the right exact way for like your specific use case. But that's a lot of times what you're doing. Same thing for writing, like a lot of the stuff in my pieces are summaries of books that I've read or conversations I've had or ideas that I found somewhere else that I'm like stringing together in a sort of unique way.

13:32.660 --> 13:53.580
And obviously, I still have to do the management overall management task of deciding which summaries to put in which order and like how they work or whatever but like a lot of it is summary. And I think that's a way that using these tools, you start to see the world a little bit differently and you're like, Oh yeah, there's a whole, there's a whole class of things I'm doing that are summaries that I don't have to do anymore. And I really think that's cool.

13:53.580 --> 14:22.580
Yeah, I should be one of the areas where I have not adopted AI as much as I probably should have is in repurposing content, making more of what I do with the podcast, because I've put out a lot of episodes, there's a lot of stuff there. And we do use AI in our workflows to, for example, create the time stamp outline right of the different discussion topics at different times throughout the show. That's the most classic.

14:23.580 --> 14:52.580
Summarization where I'm not looking for a lot of color commentary. It's literally just what was the topic at each time get it right. So we've got some stuff like that we go to pretty regularly. But I have not done as much as I probably could or should maybe this will be a New Year's resolution to bring that to all the different platforms. And it is I think it's an actually an interesting, it's partly a personal quirk. And it is also I think a limitation of the current language.

14:53.580 --> 15:22.580
And I think that's one of the other models that I never quite feel like I want them to write as me. I'm very eager to hear your thoughts on how you relate to it in the writing process. Yeah, when I put something out in my own name, I basically don't use chat GBT at all for it. I can use it I find for like voice of the show if I want to do like that time stamp outline or just create a quick summary that's in kind of a neutral voice where it's not signed Nathan and isn't supposed to be like representing my perspective.

15:22.580 --> 15:37.580
I haven't really had a great synthesis yet to help create stuff that I want to say in my own voice in my own name. So if you have tips on that, that would be something I would love to come away with a better plan of attack on because I'm not quite there.

15:37.580 --> 15:41.580
Hey, we'll continue our interview in a moment after a word from our sponsors.

15:41.580 --> 15:50.580
Real quick, what's the easiest choice you can make taking the window instead of the middle seat outsourcing business tasks that you absolutely hate? What about selling with Shopify?

15:51.580 --> 15:56.580
Shopify is the global commerce platform that helps you sell at every stage of your business.

15:56.580 --> 16:09.580
Shopify powers 10% of all e-commerce in the US and Shopify is the global force behind Allbirds, Rothes and Brooklyn and millions of other entrepreneurs of every size across 175 countries.

16:09.580 --> 16:18.580
Whether you're selling security systems or marketing memory modules, Shopify helps you sell everywhere from their all in one e-commerce platform to their in person POS system.

16:18.580 --> 16:21.580
Wherever and whatever you're selling, Shopify's got you covered.

16:21.580 --> 16:28.580
I've used it in the past at the companies I founded and when we launch Merch here at Turpentine, Shopify will be our go-to.

16:28.580 --> 16:36.580
Shopify helps turn browsers into buyers with the internet's best converting checkout up to 36% better compared to other leading commerce platforms.

16:36.580 --> 16:41.580
And Shopify helps you sell more with less effort thanks to Shopify Magic, your AI-powered All-Star.

16:41.580 --> 16:49.580
With Shopify Magic, whip up captivating content that converts from blog posts to product descriptions. Generate instant FAQ answers.

16:49.580 --> 16:55.580
Pick the perfect email send time. Plus, Shopify Magic is free for every Shopify seller.

16:55.580 --> 16:57.580
Businesses that grow, grow with Shopify.

16:57.580 --> 17:02.580
Sign up for a $1 per month trial period at Shopify.com slash Cognitive.

17:02.580 --> 17:07.580
Go to Shopify.com slash Cognitive now to grow your business no matter what stage you're in.

17:07.580 --> 17:10.580
Shopify.com slash Cognitive.

17:12.580 --> 17:20.580
I do. I definitely do. I love it. I think it goes back again to when you talk about being a co-pilot.

17:20.580 --> 17:27.580
I think that the failure mode is usually trying to use it when it's a little bit more in delegation mode.

17:27.580 --> 17:30.580
Just go do this whole thing. That's when it doesn't really work.

17:30.580 --> 17:37.580
But as a co-pilot, it really works incredibly well for specific micro tasks in writing.

17:38.580 --> 17:43.580
First example, as I just brought up, everything is a summary.

17:43.580 --> 17:48.580
I often have to explain an idea. I was writing a piece a couple months ago where I had to explain an idea.

17:48.580 --> 17:57.580
I knew the idea. I was talking about SPF and FTX's collapse and how utilitarianism and effective altruism,

17:57.580 --> 18:00.580
whether or not that philosophy contributed to the collapse.

18:00.580 --> 18:06.580
In order to write that article, I had to summarize the main tenets of utilitarianism.

18:06.580 --> 18:10.580
I studied philosophy in college and I've read a lot of Peter Singer's work.

18:10.580 --> 18:13.580
I just generally know it, but I haven't written about that in a while.

18:13.580 --> 18:20.580
Ordinarily, I would have had to spend three hours going back through all the different stuff to formulate my three or four-sentence summary.

18:20.580 --> 18:26.580
I just asked Chatcha BT and it gave me the summary in the context that I needed it in three or four sentences.

18:27.580 --> 18:33.580
I didn't use that wholesale, but it gave me basically the thing I needed to tweak it and put it into my voice.

18:33.580 --> 18:40.580
That's a really simple example, but I think you can use it in all different parts in the writing process.

18:40.580 --> 18:47.580
At the very beginning, I'll often just record myself on a walk, just spewing ideas and random thoughts reassociating.

18:47.580 --> 18:53.580
Then I'll have it transcribe it and summarize it and pull out the main things and then it'll help me find little article ideas.

18:54.580 --> 19:03.580
When I have an article idea, I'll often start with just this really messy document full of quotes and sentences and little things that might go into it.

19:03.580 --> 19:06.580
Then I'll be like, I don't even know where to start with this. This is crazy.

19:06.580 --> 19:10.580
Then I will just be like, can you put this into an outline?

19:10.580 --> 19:14.580
I'll just paste the entire document into Chatcha BT and it'll often find an outline.

19:14.580 --> 19:18.580
The outlines it comes up with are really basic.

19:18.580 --> 19:29.580
I think one of the things that's really good at is pointing out the obvious solution that you missed because you're too close to the problem.

19:29.580 --> 19:37.580
Of course, the outline for this article is set up the problem and then talk about the solution to the problem that you came up with or whatever.

19:37.580 --> 19:44.580
That's such a common format for an article, but if you're in your head about it and you're being really precious,

19:44.580 --> 19:51.580
it can be hard to be like, for this special article, it's going to be this basic thing that you've written a thousand times before, the same basic structure.

19:51.580 --> 20:01.580
Then I think one of the other really great things is it's just incredibly good for helping you figure out what you're trying to express,

20:01.580 --> 20:10.580
put into words what you're going for, and then also going through the different options of how to express what you want to express until you find something that exactly says the thing you want.

20:10.580 --> 20:13.580
For example, trying to find exactly the right metaphor.

20:13.580 --> 20:16.580
What kind of metaphor are you trying to find?

20:16.580 --> 20:18.580
What's the idea you're trying to express?

20:18.580 --> 20:23.580
Here's 50 different options of ways to express that with a metaphor.

20:23.580 --> 20:33.580
49 of them will be trash and one of them will be amazing or one of them will push you in the direction of the one that you come up with is.

20:33.580 --> 20:35.580
I have zillions of examples of that.

20:35.580 --> 20:43.580
I find that ChatGBT, it's all over my writing, but none of the stuff that makes it into the writing I publish is wholesale from ChatGBT.

20:43.580 --> 20:45.580
It's like doing some of those micro tasks for me all the time.

20:45.580 --> 20:47.580
Yeah, that's interesting.

20:47.580 --> 20:50.580
Some of the stuff that you mentioned there I have had some luck with.

20:50.580 --> 20:56.580
The talking to it on a walk is quite helpful in some cases.

20:56.580 --> 21:02.580
I've done a couple things where I tried to draft a letter and do, as you said, talk my way through it.

21:02.580 --> 21:03.580
Here's what I want to say.

21:03.580 --> 21:05.580
I'm writing here to this person.

21:05.580 --> 21:06.580
Here's a little context.

21:06.580 --> 21:08.580
Here's the key points I want to get across.

21:08.580 --> 21:09.580
Can you do a draft?

21:09.580 --> 21:13.580
And then iterating verbally on that draft.

21:13.580 --> 21:20.580
A lot of times I'll follow up and be like, okay, that's pretty good, but you can give it pre-detailed feedback too.

21:20.580 --> 21:26.580
The transcription in the app is so good that it is, again, point of privilege.

21:26.580 --> 21:29.580
It understands me extremely well.

21:29.580 --> 21:35.580
So I can literally just have to scroll through its first generation and say, in the first paragraph, I don't really want to say that.

21:35.580 --> 21:37.580
It's more like this in the second paragraph.

21:37.580 --> 21:38.580
More emphasis on this.

21:38.580 --> 21:39.580
Add this detail.

21:39.580 --> 21:40.580
Give it like eight things.

21:40.580 --> 21:43.580
You could wish it would do a little bit better on the revision.

21:43.580 --> 21:53.580
I've had a few moments there where at the end of that process, I have something like, all right, when I get back to the desk, it's not that far of a leap from that to the actual version that I'll use.

21:53.580 --> 21:55.580
It's probably still underutilized for me.

21:55.580 --> 21:56.580
I should go on more walks, honestly.

21:56.580 --> 21:59.580
Get more time away from the screen.

21:59.580 --> 22:03.580
Get the blood flowing a little bit and use a different modality.

22:03.580 --> 22:05.580
The micro tasks, I should do more, though.

22:05.580 --> 22:16.580
I think that's the tip that I'm taking here is, and there's a separation between, like, sometimes where I feel like it's hurting me is if I haven't...

22:16.580 --> 22:22.580
And this doesn't even now start to happen in Gmail or anywhere where there's this auto-complete that's popping up.

22:22.580 --> 22:28.580
Sometimes I'm on the verge of a thought that is really the thought that I'm trying to articulate.

22:28.580 --> 22:31.580
And then this auto-complete comes up and it's like, that's not right.

22:31.580 --> 22:36.580
But it can derail you at times where you're like, don't guess for me right now.

22:36.580 --> 22:38.580
Let me get the core ideas down first.

22:38.580 --> 22:44.580
If you don't have those core ideas, then for me, it's been a real struggle to get anything good.

22:44.580 --> 22:53.580
But I think I've probably not done enough experimentation in the writing process of, okay, I do have some core ideas.

22:53.580 --> 22:58.580
Can you help me order them, structure them, iterate on them?

22:58.580 --> 23:01.580
Interestingly, I also do use it at the other end often.

23:01.580 --> 23:02.580
Critique this.

23:02.580 --> 23:03.580
Here's an email.

23:03.580 --> 23:04.580
Here's a whatever.

23:04.580 --> 23:05.580
Here's an intro to a podcast.

23:05.580 --> 23:06.580
Critique it.

23:06.580 --> 23:12.580
That could be really useful if critiques are usually worthy of consideration, at least, I would say.

23:12.580 --> 23:14.580
Yeah, it truly is good at that.

23:14.580 --> 23:21.580
We have multiple editors who are highly skilled and I still use it to be like, what do you think of this intro?

23:21.580 --> 23:24.580
Because it's up at 2 a.m. when I'm a night before a deadline.

23:24.580 --> 23:26.580
Yeah, it's real hard to beat the availability.

23:26.580 --> 23:29.580
The responsiveness is clearly superhuman on that.

23:29.580 --> 23:30.580
I think the writing stuff is really fun.

23:30.580 --> 23:36.580
I would love to, if you're ready for it, I would love to start just diving into how you actually, how you use chatGBT.

23:36.580 --> 23:37.580
Sure.

23:37.580 --> 23:41.580
You sent me a doc with a bunch of historical chats and this is the first one.

23:41.580 --> 23:42.580
Give us the setup.

23:42.580 --> 23:43.580
What were you doing?

23:43.580 --> 23:48.580
At what point were you like, oh, I need to go into chatGBT and then take us from there?

23:48.580 --> 24:01.580
I am working as the AI advisor at a company called Athena, which was founded by a friend of mine named Jonathan.

24:01.580 --> 24:04.580
Is this the virtual assistant company, the Thumbtack?

24:04.580 --> 24:05.580
Yes.

24:05.580 --> 24:10.580
He used one of the founders of Thumbtack and this is a different company, but founded on

24:10.580 --> 24:13.580
some of the lessons that he learned in the Thumbtack experience.

24:13.580 --> 24:21.580
He legendarily built up like a really amazing operation powered by contractors in the Philippines.

24:21.580 --> 24:31.580
And that included hiring an assistant for himself and his role at Thumbtack, who became like a almost another key partner in his life over a long time.

24:31.580 --> 24:38.580
And then Athena was built to essentially try to scale that magic for startup founders, executives in general.

24:38.580 --> 24:42.580
They hire executive assistants in the Philippines.

24:42.580 --> 24:44.580
They pay premium wage.

24:44.580 --> 24:47.580
They're really focused on getting super high quality people.

24:47.580 --> 24:58.580
And the idea is to empower the most ambitious and most high impact people by equipping them with this ability to delegate to their assistant in a transformative way.

24:58.580 --> 24:59.580
Okay.

24:59.580 --> 25:01.580
Now we're working on what does AI mean for us, right?

25:01.580 --> 25:04.580
How do we bring that into the assistance work?

25:04.580 --> 25:11.580
So one of the things I've done is train the assistance on the use of AI.

25:11.580 --> 25:17.580
And that's been a fascinating experience, putting content together, examples, et cetera.

25:17.580 --> 25:26.580
Another thing that I've done is just worked on building a number of kind of prototype demos for what the technology of the future might start to look like.

25:26.580 --> 25:35.580
And this chat, which we call Athena chat, is basically our own custom in-house chat GPT is built on an open source project.

25:35.580 --> 25:37.580
So I didn't have to code every line of it.

25:37.580 --> 25:44.580
But it is amazing how quickly you can build things like this today with a bit of know-how.

25:44.580 --> 25:48.580
So it's been me and one other person who have built a number of these prototypes.

25:48.580 --> 26:01.580
In this case, what we wanted to do is say, can we create a long lived profile that represents the client that can assist the EA in all sorts of ways?

26:01.580 --> 26:03.580
So it's essentially a plugin.

26:03.580 --> 26:08.580
But with plugins, you have some limitations, whatever we're experimenting with this on our own.

26:08.580 --> 26:15.580
One of the big things we wanted to enable is adding information to the client profile, updating information that's already in there.

26:15.580 --> 26:27.580
So the hope is that this could be a hub where over time client preferences and history and even background context documents all can gradually find their way in there.

26:27.580 --> 26:32.580
And you have this holistic view where the assistant can go query anything they need.

26:32.580 --> 26:36.580
But again, also update add to it's in theory supposed to evolve over time.

26:36.580 --> 26:37.580
Right.

26:37.580 --> 26:38.580
So we have this chat GPT like interface.

26:38.580 --> 26:46.580
And one of the things that we've noticed is that we still see, despite our attempts at education, like it's not perfect.

26:46.580 --> 26:54.580
We still see that assistants sometimes need coaching on how to effectively prompt a language model.

26:54.580 --> 26:57.580
So that was my motivation coming into this little thing.

26:57.580 --> 27:03.580
I already had this react app, which is again, just the chat GPT like little app.

27:03.580 --> 27:08.580
And I wanted to add a module to it.

27:08.580 --> 27:11.580
The module I wanted to add was a prompt coach.

27:11.580 --> 27:26.580
So I wanted to take a put in another little layer or would look at what the assistant, the human assistant put into the chat app and send that through its own prompt to say, are you applying all the best practices?

27:26.580 --> 27:29.580
Are you telling the AI like what role you wanted to play?

27:29.580 --> 27:31.580
What job you wanted to do?

27:31.580 --> 27:36.580
Are you specifying a format that you want your response back in?

27:36.580 --> 27:48.580
Are you are you often these days will do it by default, but are you setting it up in such a way where it will do some sort of chain of thought, think out loud, think step by step reasoning before giving a final answer?

27:48.580 --> 28:00.580
That's actually one of the the most common things I see people do to shoot themselves in the foot with AI performance is prompt in such a way where it prevents the what is now the kind of trained in default behavior.

28:00.580 --> 28:05.580
Explain, analyze, think about it a little bit before getting to a final answer.

28:05.580 --> 28:07.580
So you just have a number of best practices.

28:07.580 --> 28:09.580
Let me stop you there real quick.

28:09.580 --> 28:15.580
What are people doing that would prevent the model from doing the kind of chain of thought best practice that that makes it reason the best.

28:15.580 --> 28:26.580
Anything that just sets it up in such a way where it's got to answer immediately with no ability to scratch its way through the problem is bad.

28:26.580 --> 28:30.580
And I see that very often it's common.

28:30.580 --> 28:34.580
It happens even in like academic publications, not infrequently.

28:34.580 --> 28:35.580
Yeah.

28:35.580 --> 28:39.580
Often that's a hangover from the earlier era of multi shot prompting.

28:39.580 --> 28:41.580
And obviously this is all changing super quick, right?

28:41.580 --> 28:50.580
But if you go back, the first instruction model that hit the public was open AI's text of inchy 002 in January of 2022.

28:50.580 --> 29:00.580
So we're almost on two years, but still not even two years since you could first just tell the AI write me a haiku and it would attempt to write you a haiku.

29:00.580 --> 29:03.580
At that point, it was not necessarily going to get the syllables right.

29:03.580 --> 29:11.580
The earlier generations were, you would have to say a haiku by author name colon and then hope that it would continue the pattern.

29:11.580 --> 29:13.580
That's the classic prompting.

29:13.580 --> 29:16.580
And with instructions, now you can tell it what you want to do.

29:16.580 --> 29:19.580
And obviously that's gotten better and better.

29:19.580 --> 29:32.580
But in the benchmarking in an academic context that was developed before this instruction change, typically you would have like question, answer, question, answer, question, answer, question.

29:32.580 --> 29:34.580
And the AI's job would be to give you the answer.

29:34.580 --> 29:38.580
And so they would be measured off it on five shot prompts or what have you.

29:38.580 --> 29:44.580
But a lot of that stuff was all that scaffolding was built before people had even figured out chain of thought.

29:44.580 --> 30:00.580
And so now if you take that exact structure and you bring it to a GPT-4, you're often much better off just giving it the single question with no structure, letting it spell out its reasoning because again, now it will do that by default and then give you an answer.

30:00.580 --> 30:10.580
Versus if you set up question, answer, question, answer, question, answer, it will respect to the implicit structure that you are establishing and it will jump straight to an answer.

30:10.580 --> 30:13.580
Often these are like multiple choice or they could be a number or what have you.

30:13.580 --> 30:19.580
It will jump to an answer, but the quality of the answer is much reduced compared to default behavior.

30:19.580 --> 30:22.580
If you just let it think it think itself through it.

30:22.580 --> 30:24.580
And I've even seen this in Bard.

30:24.580 --> 30:33.580
I think this is hopefully now fixed, but not too long ago, Bard would give you an answer before explanation by default.

30:33.580 --> 30:38.580
And again, that's just like you're going to have a problem so that sometimes people do that by mistake.

30:38.580 --> 30:41.580
They'll say give an answer and then explain your reasoning.

30:41.580 --> 30:43.580
You're just hurting yourself, right?

30:43.580 --> 30:48.580
Because it will explain its reasoning for a wrong answer once the wrong answer is established.

30:48.580 --> 30:52.580
So AAA is my in the EA education.

30:52.580 --> 30:57.580
It's AAA for AAA results analysis before answer always.

30:57.580 --> 30:59.580
I never heard that before. I like that.

30:59.580 --> 31:02.580
It's hopefully hopefully they'll remember it coming out.

31:02.580 --> 31:03.580
No, I like it.

31:03.580 --> 31:06.580
Hey, we'll continue our interview in a moment after a word from our sponsors.

31:06.580 --> 31:13.580
If you're a startup founder or executive running a growing business, you know that as you scale your systems break down and the cracks start to show.

31:13.580 --> 31:16.580
If this resonates with you, there are three numbers you need to know.

31:16.580 --> 31:19.580
36,000, 25, and 1.

31:19.580 --> 31:20.580
36,000.

31:20.580 --> 31:23.580
That's the number of businesses which have upgraded to NetSuite by Oracle.

31:23.580 --> 31:29.580
NetSuite is the number one cloud financial system, streamlined accounting, financial management, inventory, HR, and more.

31:29.580 --> 31:30.580
25.

31:30.580 --> 31:32.580
NetSuite turns 25 this year.

31:32.580 --> 31:38.580
That's 25 years of helping businesses do more with less, close their books in days, not weeks, and drive down costs.

31:38.580 --> 31:45.580
One, because your business is one of a kind, so you get a customized solution for all your KPIs in one efficient system with one source of truth.

31:45.580 --> 31:49.580
Manage risk, get reliable forecasts, and improve margins.

31:49.580 --> 31:51.580
Everything you need, all in one place.

31:51.580 --> 32:00.580
Right now, download NetSuite's popular KPI checklist, designed to give you consistently excellent performance, absolutely free, and netsuite.com slash cognitive.

32:00.580 --> 32:04.580
That's netsuite.com slash cognitive to get your own KPI checklist.

32:04.580 --> 32:07.580
NetSuite.com slash cognitive.

32:07.580 --> 32:17.580
Omnike uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work, customized across all platforms with a click of a button.

32:17.580 --> 32:22.580
I believe in Omnike so much that I invested in it, and I recommend you use it too.

32:22.580 --> 32:25.580
Use Kogrev to get a 10% discount.

32:25.580 --> 32:45.580
And just to summarize, I think basically what you're saying is a previous generation of prompting really encouraged in your prompt to give multiple examples of the kind of question and answer kind of thing that you wanted the model to do and then set up the last example such that the next thing the model would do is give you a direct response.

32:45.580 --> 33:02.580
But what we found over time is one other really effective thing to do is rather than have the model give a direct response or direct answer to a question or a problem posed to it is letting the model quote unquote think out loud first by reasoning through the problem just like a human would do a word problem.

33:02.580 --> 33:13.580
And then at the end of its response given answer improves the quality of the answer that you're giving and improves the quality of the result that you get from the model.

33:13.580 --> 33:21.580
And what has happened is OpenAI and other model providers have made that more of the default behavior so that you'll pretty much always do that.

33:21.580 --> 33:31.580
But using previous prompting techniques, a few shot prompting or multi shot prompting where you're giving examples might lead it to just answer directly and you should look out for that and try to avoid that.

33:31.580 --> 33:43.580
Great summary. Yes. If it is jumping directly to an answer, you are for sure leaving performance on the table for all but maybe the most trivial tasks.

33:43.580 --> 33:47.580
Yeah. And just an aside, see how much creative work is just summarizing.

33:47.580 --> 33:52.580
Important because I tend to give you the long version by default. That's my default behavior.

33:52.580 --> 33:57.580
This is one of those micro tasks that I'll just be handing off to an AI avatar version of me at some point.

33:57.580 --> 34:03.580
Okay, so let's get back to this. You're working on an app and you want to add a module to it that explains some prompting techniques.

34:03.580 --> 34:11.580
And it looks like the app itself is something that you didn't build from scratch and you're trying to get the lay of the land so you know what to do.

34:11.580 --> 34:25.580
Exactly. Yeah. And the problem is, I know how to code generally, and I've even coded in JavaScript quite a bit, but React is a JavaScript framework that has a sort of hierarchy of best practices

34:25.580 --> 34:30.580
that if you know them and you can easily apply them, then you can work quickly with the framework. That's the value of all these frameworks.

34:30.580 --> 34:38.580
But if you don't know them and you're coming in cold like I was, then where do I even go to where there's all these different folders and file structure

34:38.580 --> 34:44.580
and where exactly am I supposed to look for the kind of thing that I want to do and where do I put my new module.

34:44.580 --> 34:49.580
And so that's where this chat really starts. I have a working app. I have the code for the app.

34:49.580 --> 34:55.580
But I've never worked with a React app personally hands on before.

34:55.580 --> 35:07.580
So I literally just set up the scenario. And I don't really use too much in the way of like custom instructions or like super elaborate prompts.

35:07.580 --> 35:18.580
In my co-pilot mode work, certainly in delegation mode, then you get into a lot more detailed prompts with if this, then that, cases, structured formats, etc, etc.

35:18.580 --> 35:23.580
But I often just find a pretty naive approach is effective for things like this.

35:23.580 --> 35:28.580
And so I just start off by telling it, I'm working on this React app project and I am a bit lost.

35:28.580 --> 35:37.580
Can you explain the structure of the app? I give it a little bit more information and it starts giving me a tutorial of what it is that I'm looking at.

35:37.580 --> 35:45.580
And then you've got React and you've got Redux and then you've got these kind of additional slice JS toolkits and sagas and these frameworks

35:45.580 --> 35:56.580
and in some cases take on a life of their own where there's whole conferences, right, and companies and it's like you can be very deep down this rabbit hole and whoever like built this open source project that I'm trying to modify.

35:56.580 --> 36:02.580
They're using a bunch of different things that are not even necessarily standard but are common or whatever.

36:02.580 --> 36:05.580
So just like five different things here that I have no idea about.

36:05.580 --> 36:14.580
And without this kind of tutorial, I'd be like going off to search for, okay, what is this saga JS? What does that even do?

36:14.580 --> 36:18.580
It's able to give me that entire rundown extremely quickly.

36:18.580 --> 36:27.580
And then this I thought was a really interesting moment because I get a lot of value from things like this where I feel like it's prompting me and it wasn't exactly that here.

36:27.580 --> 36:30.580
But it gives me this general structure.

36:30.580 --> 36:31.580
Yeah.

36:31.580 --> 36:34.580
And then I was like, oh, I find it as a general pattern.

36:34.580 --> 36:42.580
If you can give it something in a format that it natively showed you, that's probably going to work pretty well.

36:42.580 --> 36:48.580
So sometimes even in kind of the delegation mode, sometimes I'll be like, I don't exactly know what structure this should have.

36:48.580 --> 36:53.580
But maybe if I have it suggest the structure, then we'll get a structure that it can naturally work well with.

36:53.580 --> 37:02.580
In this case, the structure is like dictated by the world, but it's pretty well known that, okay, this is going to be your structure of a project in this react framework.

37:02.580 --> 37:03.580
Cool.

37:03.580 --> 37:07.580
But this got me thinking, I should give it my actual structure.

37:07.580 --> 37:12.580
Like I want to print this thing out for this project that I'm working on because I didn't make it.

37:12.580 --> 37:13.580
I don't know what it is.

37:13.580 --> 37:16.580
And I want to have it help me interpret that full thing.

37:16.580 --> 37:20.580
But then again, I'm like, how do I print something like this?

37:20.580 --> 37:21.580
I don't even know how to do that.

37:21.580 --> 37:28.580
So my next question for it is, can you write me the command to print out the file structure?

37:28.580 --> 37:31.580
And this is where you're like, okay, this is magic, right?

37:31.580 --> 37:34.580
Because now again, I don't know how to do this, this tree command.

37:34.580 --> 37:36.580
I don't know if it was installed for me or not.

37:36.580 --> 37:38.580
But okay, it shows me how to do it.

37:38.580 --> 37:44.580
And next thing, oh, there's another step here of installing some package that needed to be installed.

37:44.580 --> 37:45.580
Okay, it was helping with that.

37:45.580 --> 37:47.580
So I'm just encountering all these.

37:47.580 --> 37:49.580
This is the classic developer experience.

37:49.580 --> 37:52.580
Conceptually, I have a clear idea of what I want to do.

37:52.580 --> 38:00.580
But now I'm like three levels, three nested problems down here where I'm like, oh, okay, I need to understand this framework.

38:00.580 --> 38:01.580
Right.

38:01.580 --> 38:02.580
Oh, okay.

38:02.580 --> 38:07.580
I need to print out the structure to better understand the version I'm working with in this framework.

38:07.580 --> 38:10.580
Oh, now I need to install something so I can do that print.

38:10.580 --> 38:12.580
And this is where people just time goes to die, right?

38:12.580 --> 38:16.580
It's like, yeah, you talk to programmers and you're like, yeah, you didn't get anything done today on there.

38:16.580 --> 38:21.580
But what happened was I was on the way to the market to get my app together.

38:21.580 --> 38:24.580
And then I had to install this thing and then I couldn't install.

38:24.580 --> 38:27.580
But each of these things, like it's helping me get over.

38:27.580 --> 38:30.580
And now finally I'm able to say, okay, here is my app.

38:30.580 --> 38:33.580
This is the app that I actually am working with.

38:33.580 --> 38:39.580
And now we're really getting into something good because it can now break that down.

38:39.580 --> 38:43.580
And the names of the things are like pretty semantic.

38:43.580 --> 38:45.580
I noticed I haven't even given it any code here.

38:45.580 --> 38:51.580
I've just given it the file names, but the file names have a kind of an indication of what is what.

38:51.580 --> 38:55.580
And it gets a sense just from that of what the app actually is.

38:55.580 --> 39:00.580
So let's go over to, I think I just got a link to a working version of the app.

39:00.580 --> 39:01.580
It's pretty simple.

39:01.580 --> 39:03.580
It's a chat GPT like environment.

39:03.580 --> 39:05.580
We can create these client profiles.

39:05.580 --> 39:06.580
We have our chats.

39:06.580 --> 39:08.580
We have our history, a couple of different models.

39:08.580 --> 39:14.580
And there's function calling in the background that connects the chat experience to the client profile.

39:14.580 --> 39:20.580
And what I'm trying to add is a module in the lower right hand corner, which I'm actually not sure if this version has.

39:20.580 --> 39:27.580
But the point of it is to take my prompts, run them through this meta prompt as we discussed, and then show feedback warnings.

39:27.580 --> 39:30.580
Okay, you may or may not be doing this quite right.

39:30.580 --> 39:31.580
So back to the thing.

39:31.580 --> 39:32.580
I've given the file structure.

39:32.580 --> 39:35.580
It's now able to understand the file structure.

39:35.580 --> 39:38.580
And now I'm saying, okay, here's what I'm trying to do.

39:38.580 --> 39:40.580
I'm trying to create this prompt coach.

39:40.580 --> 39:42.580
I forget exactly how I had approached this.

39:42.580 --> 39:46.580
Yeah, this is a different file.

39:46.580 --> 39:47.580
We see exactly what I'm doing here.

39:47.580 --> 39:51.580
Seems like maybe you had some sample code or something you've written or.

39:51.580 --> 39:52.580
Yeah, I did.

39:52.580 --> 39:55.580
I guess I took one stab at it myself and it didn't work.

39:55.580 --> 39:58.580
I see where I'm looking at the human version.

39:58.580 --> 40:01.580
I was looking at the same file structure and I'm like, okay, I see that there's this module.

40:01.580 --> 40:03.580
There's like a sidebar here.

40:03.580 --> 40:05.580
And as you see these names, right?

40:05.580 --> 40:12.580
So you've got sidebar and search and there's going to be like chat history here somewhere chat.

40:12.580 --> 40:16.580
I'm looking at this and I'm like, okay, I see all these different elements and I see all these things.

40:16.580 --> 40:20.580
Let me just try to copy one and mess with it a little bit and hopefully get somewhere.

40:20.580 --> 40:21.580
Right.

40:21.580 --> 40:22.580
And then I'm not getting anywhere.

40:22.580 --> 40:24.580
It's not showing up where I want to show up.

40:24.580 --> 40:25.580
I'm not seeing it.

40:25.580 --> 40:28.580
And so that's where I come to say, okay, now here's what I tried.

40:28.580 --> 40:29.580
Why isn't it working?

40:29.580 --> 40:30.580
Yeah.

40:30.580 --> 40:31.580
And I explain my problem here at the end.

40:31.580 --> 40:35.580
The problem I have is that it's being shown in the wrong place.

40:35.580 --> 40:36.580
Right.

40:36.580 --> 40:37.580
So then it explains the answer.

40:37.580 --> 40:38.580
Yeah.

40:38.580 --> 40:44.580
Next thing we're motto, it's giving me instructions with code, modify this, put it over here.

40:44.580 --> 40:45.580
This is pretty cool too.

40:45.580 --> 40:47.580
Unfortunately, we can't share the old screenshots.

40:47.580 --> 40:54.580
I don't know exactly what I used, but this is right as vision was being introduced to chat GPT as well.

40:54.580 --> 40:58.580
So I was able to then say, here's my screenshot.

40:58.580 --> 41:01.580
Here's where it is showing up and here's where I want it to show up.

41:01.580 --> 41:02.580
Right.

41:02.580 --> 41:04.580
And can you help me with that as well?

41:04.580 --> 41:10.580
So from the screenshots, from the HTML structure, basically we just work through this entire thing.

41:10.580 --> 41:17.580
I continue to run into issues where only 25% of the way through this whole thing.

41:17.580 --> 41:18.580
Oh, wow.

41:18.580 --> 41:23.580
This probably took me, I don't know, two to three hours total to get these suggestions,

41:23.580 --> 41:25.580
implement them, see what's going wrong.

41:25.580 --> 41:26.580
Yada, yada, yada.

41:26.580 --> 41:28.580
It writes all the code basically.

41:28.580 --> 41:29.580
Right.

41:29.580 --> 41:32.580
Because again, I've never written a line of React code in my life.

41:32.580 --> 41:37.580
So I don't know any of this syntax, there's a million ways to get it not quite right when

41:37.580 --> 41:39.580
you have no idea what you're doing anyway.

41:39.580 --> 41:44.580
And so it's writing all the code and just bit by bit where we're finding the experience,

41:44.580 --> 41:47.580
we're finding the interface, here we're creating some CSS.

41:47.580 --> 41:51.580
We're using, we have a particular style pack that's already built into this.

41:51.580 --> 41:54.580
So again, that's just another thing I'm not at all familiar with.

41:54.580 --> 41:59.580
You know, this is the syntax for figuring out how to use that style pack.

41:59.580 --> 42:01.580
Good luck making that up on your own.

42:01.580 --> 42:06.580
And then we go basically after a couple of hours, I got to a working module where the

42:06.580 --> 42:13.580
prompt coach, you know, would intercept your call, do the meta prompt, parse the response,

42:13.580 --> 42:18.580
identify, I had it giving the suggestions and the urgency of the suggestions.

42:18.580 --> 42:21.580
So we're color coding those suggestions as they come up.

42:21.580 --> 42:23.580
If it's serious, then you get it in red.

42:23.580 --> 42:26.580
And if it's not, you can get it in yellow or just a notice.

42:26.580 --> 42:30.580
And I would have, I would guess that this would have taken me easily order of magnitude

42:30.580 --> 42:34.580
longer in a pre chat GPT here.

42:34.580 --> 42:40.580
If this was two to three hours, it's probably two to three days of work to figure out all this stuff.

42:40.580 --> 42:46.580
And I know a lot more frustration that is because I'm not a super patient person.

42:46.580 --> 42:51.580
The feeling of a million people have done something almost exactly like this.

42:51.580 --> 42:54.580
There's nothing differentiated or special about what I'm doing.

42:54.580 --> 43:00.580
I'm just like in this phase of kind of not knowing what I'm doing and just getting constantly stuck,

43:00.580 --> 43:03.580
constantly stumbling, constantly running into friction.

43:03.580 --> 43:04.580
I really don't enjoy that.

43:04.580 --> 43:06.580
I think most people don't.

43:06.580 --> 43:09.580
This is none of that or almost none of it, right?

43:09.580 --> 43:11.580
Even just that going back to the install, right?

43:11.580 --> 43:13.580
Or the command to print out the structure.

43:13.580 --> 43:14.580
Man, this is so stupid.

43:14.580 --> 43:16.580
I know exactly what I want.

43:16.580 --> 43:18.580
I know that it is doable.

43:18.580 --> 43:21.580
I know that it's been done a million times, a million places.

43:21.580 --> 43:22.580
And yet I don't know how to do it.

43:22.580 --> 43:29.580
And then liberating me from that frustration is, it turns out, it would go to your drudgery point, right?

43:29.580 --> 43:35.580
That was probably 80 to 90% of the time in a world where I was doing this on my own.

43:35.580 --> 43:40.580
And now we're down to the two to three hours where it was really about defining what I want.

43:40.580 --> 43:43.580
This could have been one hour if I really knew React,

43:43.580 --> 43:48.580
but it taught me the ropes and did the task in probably again,

43:48.580 --> 43:53.580
80 to 90% time savings compared to the unassisted version.

43:53.580 --> 43:54.580
I love this.

43:54.580 --> 43:56.580
I think this is such a cool example.

43:56.580 --> 43:58.580
I really appreciate you bringing this.

43:58.580 --> 44:03.580
One, yeah, it's obvious that this kind of thing, which if you're not a programmer,

44:03.580 --> 44:07.580
like as a programmer looking at this, I'm like, yeah, this is so much of what you do as a programmer,

44:07.580 --> 44:11.580
especially if you're a programmer like working on startup stuff is like this kind of thing.

44:11.580 --> 44:12.580
It's like, this is doable.

44:12.580 --> 44:13.580
It's been achieved before.

44:13.580 --> 44:16.580
I just need to do it in this, in my specific context.

44:16.580 --> 44:22.580
And it's obvious that this would have taken you days or taken really anyone days to do from scratch,

44:22.580 --> 44:27.580
but with chat GBT, it makes it like the way quicker and takes away a lot of the drudgery.

44:27.580 --> 44:31.580
But I think what's really cool and really beautiful, which is like weird to say about this stuff.

44:31.580 --> 44:40.580
It's striking me right now is there's this dance happening in this chat where at the beginning,

44:40.580 --> 44:43.580
obviously you're asking it for to help you.

44:43.580 --> 44:50.580
But you are giving it what it needs and filling in the gaps that it needs in order to like help you

44:50.580 --> 44:52.580
and it is filling in the gaps for you as well.

44:52.580 --> 44:56.580
So it is explaining react to you, but you are explaining.

44:56.580 --> 45:00.580
Here is the project that I have and here are the specific details that I want done.

45:00.580 --> 45:07.580
And then there's this like dance back and forth where you're mutually filling in gaps that both of you can't on your own fill in.

45:07.580 --> 45:15.580
And I think that is like really cool to just watch that evolve where at the start you don't know react

45:15.580 --> 45:19.580
and you don't know like where to where to put your code and you don't know why it's not working.

45:19.580 --> 45:25.580
And at the start, it doesn't know who you are or what you're trying to accomplish or what the specifics of your project is.

45:25.580 --> 45:30.580
But as you build up this chat, you yourself are starting to understand things more.

45:30.580 --> 45:32.580
Like you didn't ask it, just go do this for me.

45:32.580 --> 45:35.580
You asked how does a react project work and like what is the structure.

45:35.580 --> 45:39.580
And so you learned more about react and it learned more about you.

45:39.580 --> 45:44.580
And as your mutual understanding increased, you were both able to accomplish the thing together.

45:44.580 --> 45:46.580
And I think that's really cool.

45:46.580 --> 45:48.580
Yeah, it's awesome.

45:48.580 --> 45:51.580
The next generation, it's episodic.

45:51.580 --> 45:54.580
We were still only halfway through this scroll for all the scrolling I've done.

45:54.580 --> 45:56.580
I just highlighted this. Okay, cool.

45:56.580 --> 46:00.580
This is working because at this point I'm starting to get into like refinements.

46:00.580 --> 46:06.580
Okay, now I want to dial in the styling and basically at this point, the core problems have been solved.

46:06.580 --> 46:12.580
And now again, it's just going to do the drudgery of making sure that there's padding and things are centered and so on and so forth.

46:12.580 --> 46:17.580
I try to be polite and encouraging to my AIs wherever I possibly can.

46:17.580 --> 46:19.580
But you can envision a future.

46:19.580 --> 46:28.580
And I think that future is already starting to become visible through the through the mist a little bit as more and more stuff gets published on the research side.

46:28.580 --> 46:35.580
Where this sort of episodic relationship where I started a new chat, it now knows nothing about this, right?

46:35.580 --> 46:37.580
I can continue this chat up to a limit.

46:37.580 --> 46:44.580
And obviously, superhuman expansive background knowledge, but zero contextual knowledge.

46:44.580 --> 46:48.580
And we can't retain that from one episode to the next.

46:48.580 --> 46:51.580
But I do think that is also coming soon too.

46:51.580 --> 46:54.580
And there's a couple different ways it could shape up.

46:54.580 --> 47:01.580
But I think we will, in a year, certainly not that much longer than that, I can't imagine.

47:01.580 --> 47:09.580
Start to see things where all this history is accumulated or maybe divided into different threads or whatever.

47:09.580 --> 47:17.580
But where this kind of can follow you forward into different tasks as well in a history aware way, I think will be another level of unlock.

47:17.580 --> 47:18.580
I think you're totally right.

47:18.580 --> 47:20.580
That's what custom instructions is.

47:20.580 --> 47:21.580
It's a step in that direction.

47:21.580 --> 47:24.580
Unfortunately, custom instructions is very hard to set up.

47:24.580 --> 47:26.580
But if you do set it up, it's really great.

47:26.580 --> 47:28.580
It's really nice for it to have context on you.

47:28.580 --> 47:29.580
But I do think you're right.

47:29.580 --> 47:35.580
ChatGPT will definitely have a memory that it can reference this stuff and reference the context of what you need and who you are.

47:35.580 --> 47:44.580
And that will make it, even with the same level of intelligence as the model, will make it like 10x more useful and 10x faster to get to the right answer.

47:44.580 --> 47:48.580
How much do you put into custom instructions?

47:48.580 --> 47:54.580
Because for something like this, it might be my profile, my writing sample, maybe whatever.

47:54.580 --> 48:00.580
But I probably wouldn't have, by the way, Nathan's a React novice and doesn't know how to install anything.

48:00.580 --> 48:07.580
Do you have a vision or a sort of recommendation for a custom instruction that would help me with things like this?

48:07.580 --> 48:08.580
You're asking the right person.

48:08.580 --> 48:12.580
I have a very extensive custom instruction and a lot of opinions about it.

48:12.580 --> 48:13.580
If you want, I can share them.

48:13.580 --> 48:15.580
I can share it with you right now and we can talk about it.

48:15.580 --> 48:16.580
Sure.

48:16.580 --> 48:17.580
Yeah, let's check it out.

48:17.580 --> 48:18.580
Okay.

48:18.580 --> 48:22.580
The first part of custom instructions is, what do you want ChatGPT to know about you?

48:22.580 --> 48:34.580
And I actually like really having it know a little bit about who I am because there's enough about me on the internet that it knows my name and that actually helps.

48:34.580 --> 48:37.580
Same thing with every, there's enough about every internet that it knows my name.

48:37.580 --> 48:43.580
And every once in a while, not having to explain who I am or what the company is that I run is like really useful.

48:43.580 --> 48:50.580
For example, I was thinking a couple of weeks ago about starting a course and I was working with ChatGPT to decide how to do the course and whatever.

48:50.580 --> 48:52.580
And the first problem was I want to do a course.

48:52.580 --> 48:53.580
Can you help me think about it?

48:53.580 --> 48:57.580
And with custom instructions on it knows that I'm a writer and entrepreneur and so cool.

48:57.580 --> 48:58.580
I'll help you build a course.

48:58.580 --> 49:01.580
Here's how to think about it because it knows that I'm probably going to build one.

49:01.580 --> 49:05.580
But if I turn custom instructions off, it will be like, cool, what course do you want to take?

49:05.580 --> 49:09.580
And it's those like little things that like really make a difference for me.

49:09.580 --> 49:18.580
But basically like who serious relationships in my life are I have in here, like my sister, her husband, her son, I have my girlfriend up there.

49:18.580 --> 49:29.580
Who people are at every because referencing their names is just much easier for me to be like, okay, when I'm talking about something and not have to explain who she is every single time is really helpful.

49:29.580 --> 49:35.580
I think another really interesting thing is adding into custom instructions.

49:35.580 --> 49:39.580
What are the things about you that you know that you're trying to like work on?

49:39.580 --> 49:44.580
For example, I feel like I'm I have a fear of rejecting people which causes me to be too agreeable.

49:44.580 --> 49:54.580
I'm a little bit too opportunistic and I would like to be more strategic like stuff like that is really helpful to put in custom instructions because it's these little realizations that you have every day.

49:54.580 --> 49:58.580
You're like, wow, yeah, I am a little too opportunistic.

49:58.580 --> 50:04.580
I think Chatchity is great for being the thing that can help you as you're in the moment day to day.

50:04.580 --> 50:09.580
Remember to pull back and incorporate some of these insights that you have that everyone has about themselves.

50:09.580 --> 50:19.580
And same thing for goals like having know what your goals are and bring you back to those things all the time as you're using is really helpful.

50:19.580 --> 50:20.580
Cool.

50:20.580 --> 50:21.580
Well, thanks for sharing.

50:21.580 --> 50:28.580
I think I use it a lot more for just like very unfamiliar topics.

50:28.580 --> 50:33.580
I'm very just looking at these examples right that we had queued up.

50:33.580 --> 50:42.580
Okay, there's an app in a framework that I've never touched and know nothing about working on a patent application and creating diagrams for a patent application.

50:42.580 --> 50:44.580
I don't really know how to do that at all.

50:44.580 --> 50:46.580
Is there again, I'm starting with these very basic questions.

50:46.580 --> 50:50.580
What's a good syntax that I might use to create a diagram for a patent application?

50:50.580 --> 50:52.580
I just come in so cold.

50:52.580 --> 51:05.580
But it does suggest that you are doing a lot more kind of thought partner like brainstorming about your kind of core stuff, which is interesting.

51:05.580 --> 51:15.580
I'm much more on these kind of episodic things that we're like my history and this doesn't overlap almost at all in a lot of cases.

51:15.580 --> 51:22.580
But it just goes to show how many different ways of using these tools there are too.

51:22.580 --> 51:28.580
And yeah, this could be another new year's resolution to try to bring it a little bit closer to the core of what I do.

51:28.580 --> 51:31.580
It's not to say that it's not at the core of what I do, but not in this co-pilot way.

51:31.580 --> 51:36.580
With things like Waymark, I'm working very closely with language models to make an app work well.

51:36.580 --> 51:42.580
And I feel like I have intimate knowledge of the details of how it works in that respect.

51:42.580 --> 51:51.580
It's a big project for me, but again, a different mode than the interactive dance kind of mode that you describe.

51:51.580 --> 51:52.580
Fascinating.

51:52.580 --> 51:54.580
Yeah, that makes a lot of sense.

51:54.580 --> 52:00.580
I definitely use it for some of this knowledge exploration stuff too, but yeah, it's totally a sort of thought partner for me.

52:00.580 --> 52:04.580
But I'd love to keep looking through some of the other chats you brought.

52:04.580 --> 52:05.580
Cool.

52:05.580 --> 52:08.580
Next one on working on diagrams.

52:08.580 --> 52:16.580
We're going to have a combination of a provisional patent application and the supporting diagrams for the patent application.

52:16.580 --> 52:19.580
This is something that I was doing for Waymark.

52:19.580 --> 52:26.580
And we have this ensemble method of creating advertising video for small business.

52:26.580 --> 52:30.580
Basically, folks come into the site.

52:30.580 --> 52:33.580
They get to enter a website URL.

52:33.580 --> 52:36.580
Typically, people will give like the homepage of their small business website.

52:36.580 --> 52:40.580
We have some code that goes and like grabs content off of that website.

52:40.580 --> 52:46.580
And then we build a profile on a synthetically if you're custom instructions, so to speak, within the context of our app.

52:46.580 --> 52:47.580
Who are you as a user?

52:47.580 --> 52:48.580
What's your business?

52:48.580 --> 52:49.580
What are you all about?

52:49.580 --> 52:50.580
What kind of business?

52:50.580 --> 52:51.580
What images?

52:51.580 --> 52:55.580
And then to actually create the video, you give a very specific, although it's like a super short instruction.

52:55.580 --> 53:02.580
I want to make a video for my sale this Saturday where I'm opening a new location and here's the address or whatever.

53:02.580 --> 53:05.580
This is my purpose in this moment prompt.

53:05.580 --> 53:13.580
And then we've got a pretty complicated machinery that takes all those inputs and it works with a language model to write a script.

53:13.580 --> 53:21.580
And then it has computer vision components that decide which of the images from your library should be used to complement the script and all these different points along the way.

53:21.580 --> 53:24.580
And that is, it's a pretty cool experience.

53:24.580 --> 53:31.580
Now, really compared to, again, you think about pre AI and now what we had before was an easy to use template library.

53:31.580 --> 53:34.580
And what we have now is really the AI makes you content.

53:34.580 --> 53:42.580
Like it's a phase change in terms of how easy it is to use, how quick the experience is, how much you can just rifle through ideas.

53:42.580 --> 53:47.580
If you don't like the first thing, you just ask it to do another and it's qualitatively just way more fun.

53:47.580 --> 53:51.580
People used to have to sit there and type stuff in and they were like, okay, what do I say?

53:51.580 --> 53:52.580
And I'm not sure what to say.

53:52.580 --> 53:59.580
And a lot of people are not content creators, but everybody always referred to the Mr. Burns episode from the Simpsons.

53:59.580 --> 54:06.580
This is a long time ago, but he goes to an art museum for a reveal of some piece of art and they reveal it.

54:06.580 --> 54:09.580
And he says, I'm no art critic, but I know what I hate.

54:09.580 --> 54:13.580
And that's, I feel like, exactly how our users operate.

54:13.580 --> 54:15.580
They ask for something.

54:15.580 --> 54:16.580
They wait 30 seconds.

54:16.580 --> 54:19.580
They now get to watch a video featuring their business.

54:19.580 --> 54:21.580
And if they like it, they can proceed.

54:21.580 --> 54:26.580
And if they don't like it, it's very obvious to them and they can very quickly be like, no, not that.

54:26.580 --> 54:27.580
Give me another one.

54:27.580 --> 54:29.580
And here's an alternate instruction.

54:29.580 --> 54:31.580
So anyway, this is the app that we built.

54:31.580 --> 54:35.580
And now we're like, okay, maybe we should think about filing a provisional patent on that.

54:35.580 --> 54:41.580
Like most software companies, we're never going to prosecute our patents, but we just want to make sure nobody can come in and give us a hard time.

54:41.580 --> 54:43.580
So how do I write a patent?

54:43.580 --> 54:46.580
And how do I create the diagrams?

54:46.580 --> 54:48.580
And I want to be able to update it.

54:48.580 --> 54:51.580
I want to have something that's not like just a total mess.

54:51.580 --> 54:57.580
So this was a series of different interactions that ultimately led me to these diagrams.

54:57.580 --> 55:05.580
But I provided initially basically what I just said to you, which is a rambling sort of instruction on here is my app.

55:05.580 --> 55:06.580
And here's what it does.

55:06.580 --> 55:07.580
Here's how it works.

55:07.580 --> 55:08.580
Here's some of the parts behind it.

55:08.580 --> 55:12.580
The language model writes the script and the code that's scripted from the website.

55:12.580 --> 55:20.580
And then the other part with the computer vision that figures out what I just literally tell the whole thing and say, now can you use some syntax?

55:20.580 --> 55:27.580
To make me a diagram that shows the structure of that app that I just word vomited to you.

55:27.580 --> 55:29.580
And so there's like a bunch of different structures out there.

55:29.580 --> 55:31.580
So that's the first part of that conversation as well.

55:31.580 --> 55:37.580
You could use the mermaid syntax or you could use graph viz or you could use a couple other things.

55:37.580 --> 55:41.580
But what are the pros and cons of those and can they represent certain different kinds of structures?

55:41.580 --> 55:46.580
We dialed it in on either mermaid or graph is it started to make me a thing.

55:46.580 --> 55:47.580
And then you can see here too.

55:47.580 --> 55:53.580
This is interesting because I did find in this one that at some point it got confused.

55:53.580 --> 56:00.580
I'd given it this thing and had generated this syntax, asked for refinements on the syntax because I'm taking the syntax by the way, going over to another app.

56:00.580 --> 56:05.580
What's cool about the syntax is you drop in this pure text syntax and it will render the app for you.

56:05.580 --> 56:10.580
So you've got things like this graph is diagram.

56:10.580 --> 56:11.580
What's a digraph?

56:11.580 --> 56:12.580
I don't even really know.

56:12.580 --> 56:20.580
It's called this digraph is G and it has these elements and they have these properties and they're connected in this sort of graph structure, blah, blah, blah.

56:20.580 --> 56:23.580
You load it in half a second, you know, it renders it.

56:23.580 --> 56:25.580
You're like, oh, no, that's not quite right.

56:25.580 --> 56:27.580
This point should be connected to this point.

56:27.580 --> 56:30.580
And it's it's skipping one that it's so whatever.

56:30.580 --> 56:32.580
So you give it these kind of iterations.

56:32.580 --> 56:36.580
It would make progress, but then it would also get confused.

56:36.580 --> 56:40.580
It seemed after a number of rounds because there's just maybe like too much syntax.

56:40.580 --> 56:51.580
So at some point, I did say, OK, using the episodic memory to my advantage or working around its working memory weaknesses by just wiping and starting over.

56:51.580 --> 56:53.580
I'm like, OK, here's the best one from that chat.

56:53.580 --> 56:56.580
It was closest to what I wanted it to represent.

56:56.580 --> 56:57.580
We just go have another chat.

56:57.580 --> 57:02.580
And this time we're going to skip all the part about which format do we use and skip all the word salad.

57:02.580 --> 57:04.580
And I can just be like, here's a diagram.

57:04.580 --> 57:06.580
I want to make some changes to it.

57:06.580 --> 57:10.580
And now have it do more localized edits for me.

57:10.580 --> 57:14.580
And again, a lot of little details, a lot of nuance here, but it's happy to do that.

57:14.580 --> 57:17.580
We work through a number of rounds of it.

57:17.580 --> 57:24.580
And I believe I attached the thing for you what I ended up with after or a couple chats.

57:24.580 --> 57:28.580
You even get to the point where you're like color coding and really starting to make sense of it.

57:28.580 --> 57:29.580
It's like, right.

57:29.580 --> 57:33.580
The green in this diagram now is the things that the user does.

57:33.580 --> 57:36.580
So the user tells us what their business website is.

57:36.580 --> 57:37.580
Then there's code to go scrape.

57:37.580 --> 57:42.580
Then there's this fork where we have to grab all the images and process them in various ways.

57:42.580 --> 57:48.580
One of the big challenges is which parts of this can happen in parallel and which parts depend on which parts.

57:48.580 --> 57:53.580
This is actually something that we didn't have until I did this, even for the technology team.

57:53.580 --> 57:59.580
And I'm not sure how well all the members of the technology team could have even drawn this.

57:59.580 --> 58:06.580
So now we actually have a better reference internally also to be like, hey, if we like, what depends on the image aesthetic step?

58:06.580 --> 58:08.580
Now we can go look at it and be like, oh, okay.

58:08.580 --> 58:12.580
Yeah, you can't select best images until you have the aesthetic scores.

58:12.580 --> 58:13.580
Yeah.

58:13.580 --> 58:14.580
Good.

58:14.580 --> 58:15.580
Completed.

58:15.580 --> 58:17.580
Just having that clarity is also I think just operationally useful.

58:17.580 --> 58:28.580
But this is the sort of thing that you can attach to a provisional patent application and at least begin to protect yourself from future patent rolls coming your way.

58:28.580 --> 58:29.580
Again, how long would this take?

58:29.580 --> 58:38.580
If I had drawn it freehand, I maybe could have drawn it in a somewhat comparable time to the amount of time that I spent exchange,

58:38.580 --> 58:47.580
but having the syntax and now having it in that kind of structured language way also makes this like much more maintainable,

58:47.580 --> 58:51.580
can fit in other things, even can be like more readily used in language models.

58:51.580 --> 58:53.580
The vision understanding is getting very good.

58:53.580 --> 59:01.580
But I would say it's probably still better at understanding the syntax of the graph more than this visual rendering of the graph.

59:01.580 --> 59:02.580
I think that's great.

59:02.580 --> 59:04.580
Obviously, ChatGPT has the Dolly integration.

59:04.580 --> 59:10.580
So I'm familiar with that, but I've been thinking a lot about sometimes I want to create something that looks like this,

59:10.580 --> 59:12.580
like in a graph with text and boxes and all that kind of stuff.

59:12.580 --> 59:17.580
And I didn't even think to do to have it just write graph is markup or something like that and paste it somewhere else.

59:17.580 --> 59:21.580
So I think that's a really cool thing to know it can do.

59:21.580 --> 59:26.580
And it's also pretty clear, I don't know, in a year, it'll probably just render the graph is stuff for you.

59:26.580 --> 59:34.580
And you'll be able to like move it around and do all that kind of stuff without even necessarily having to chat back and forth after the first round or something like that.

59:34.580 --> 59:39.580
I think that would be a very cool next step for ChatGPT is jump into an edit mode for something like this.

59:39.580 --> 59:45.580
Closest thing I've seen to that so far is diagram GPT.

59:45.580 --> 59:47.580
This is a slightly different notation.

59:47.580 --> 59:51.580
But basically you can prompt in natural language.

59:51.580 --> 59:56.580
Yeah, it will then generate, in this case, mermaid syntax for you in response.

59:56.580 --> 01:00:02.580
And then it'll immediately render your image and you can then edit the syntax.

01:00:02.580 --> 01:00:06.580
You can't quite like drag and drop within the interface itself.

01:00:06.580 --> 01:00:16.580
But I think this is a really interesting question around highlights and really interesting question around like what things should be in chat GPT versus what things should have their own distinct experience,

01:00:16.580 --> 01:00:20.580
even if there's still like a very AI assistant component to it.

01:00:20.580 --> 01:00:24.580
This is one actually that I would expect lives outside of chat GPT.

01:00:24.580 --> 01:00:25.580
And who knows, right?

01:00:25.580 --> 01:00:29.580
In the fullness of time, maybe you have like dynamic UI is getting generated on the fly.

01:00:29.580 --> 01:00:31.580
We're starting to see that a little bit already.

01:00:31.580 --> 01:00:41.580
But I don't think open AI is going to say what we need to do is create like a UI where people can edit these graph things.

01:00:41.580 --> 01:00:42.580
If possible, you could do that.

01:00:42.580 --> 01:00:48.580
GPTs don't really give you the ability to create like custom editor experiences yet anyway.

01:00:48.580 --> 01:00:52.580
So for now, if you want to have something like that, you have to bring it to a different app.

01:00:52.580 --> 01:00:55.580
But increasingly, these are out there as well, right?

01:00:55.580 --> 01:00:57.580
They just use chat GPT and just a renderer.

01:00:57.580 --> 01:01:06.580
So I had the AI doing all the syntax and then the renderer showing me what it actually is and then going back and continuing the dialogue with chat GPT.

01:01:06.580 --> 01:01:07.580
I think you're right.

01:01:07.580 --> 01:01:13.580
Like I could see a world where they let developers build their own renderers inside of chat GPT, not for like really serious stuff.

01:01:13.580 --> 01:01:21.580
I think like dabble in half one time or make a little video or whatever that like having something in the interface so that you can do it in there.

01:01:21.580 --> 01:01:23.580
Like a rough thing is really helpful.

01:01:23.580 --> 01:01:24.580
But then yeah, I think you're right.

01:01:24.580 --> 01:01:31.580
There will have to be other pro tools for people that all they do all day is make graphs that are not inside of chat GPT.

01:01:31.580 --> 01:01:32.580
So here's another one.

01:01:32.580 --> 01:01:44.580
This is recent episode in my life where I had to admit defeat after 10 years of swearing that I would not replace my car until the replacement was self driving.

01:01:44.580 --> 01:01:45.580
Wow.

01:01:45.580 --> 01:01:47.580
And we're not quite there.

01:01:47.580 --> 01:01:50.580
So I finally and I've had three kids in the meantime.

01:01:50.580 --> 01:01:55.580
So I finally had to break down and get a mini man like many parents of young kids.

01:01:55.580 --> 01:02:00.580
I'm like, what my kids do is they really depreciate stuff pretty quickly.

01:02:00.580 --> 01:02:08.580
So I was like, I think I'll get a used right mini man because if I get a new one, it's going to be pretty used pretty quick anyway.

01:02:08.580 --> 01:02:10.580
So let me just look at what is out there.

01:02:10.580 --> 01:02:15.580
Now, anybody who's ever shop for a used car knows that it's a total jungle, right?

01:02:15.580 --> 01:02:17.580
And the car dealer websites are terrible.

01:02:17.580 --> 01:02:21.580
What features they have is a huge question.

01:02:21.580 --> 01:02:29.580
And what you end up encountering very quickly is these trim levels, which if you're not like a car head, you may not even know what that is.

01:02:29.580 --> 01:02:38.580
But that is the sort of you've got your make, which is the brand of the car, your Chevrolet or your Toyota or whatever.

01:02:38.580 --> 01:02:42.580
You've got your model, which is the kind of car.

01:02:42.580 --> 01:02:46.580
And then the Dodge caravan is the make and model.

01:02:46.580 --> 01:02:49.580
And then you've got this trim, which is often just like a couple of letters or whatever.

01:02:49.580 --> 01:02:54.580
It's like the XRT or the SRT or the L limited or whatever.

01:02:54.580 --> 01:02:57.580
They just have all these like little and these are package levels, right?

01:02:57.580 --> 01:03:00.580
What features, what upsells have been included?

01:03:00.580 --> 01:03:02.580
Does it have a sunroof?

01:03:02.580 --> 01:03:08.580
Does it have a screen in the back that drops down out of the ceiling for the kids or whatever?

01:03:08.580 --> 01:03:09.580
Right.

01:03:09.580 --> 01:03:17.580
And it's just a jungle to even try to figure out what those things have, what levels there are and what those things have.

01:03:17.580 --> 01:03:21.580
So this is perplexity, which is a great compliment to chat GPT.

01:03:21.580 --> 01:03:26.580
It is more specifically focused on answering questions.

01:03:26.580 --> 01:03:31.580
So in this way, it's a more direct rival to a Google search.

01:03:31.580 --> 01:03:34.580
It's not so much meant to be like a brainstorming partner.

01:03:34.580 --> 01:03:41.580
They really aim for accurate answers to concrete questions, do a phenomenal job on it.

01:03:41.580 --> 01:03:45.580
So here I had a number of runs of this as well, different kinds of questions or whatever.

01:03:45.580 --> 01:03:51.580
But okay, these minivans that are like not super old, but old, pretty cheap.

01:03:51.580 --> 01:03:52.580
What do they have?

01:03:52.580 --> 01:03:53.580
What do they not have?

01:03:53.580 --> 01:03:57.580
And this would have taken, I don't even know if I had really tried, I wouldn't have done it.

01:03:57.580 --> 01:03:59.580
This is one of those things that you just, I wouldn't do.

01:03:59.580 --> 01:04:10.580
But if you had set out to go collate, okay, here's all the makes and the models and the trims and what they have, you're going to be in like user manuals or something.

01:04:10.580 --> 01:04:14.580
I don't even know really where that information is stored around truth.

01:04:15.580 --> 01:04:24.580
But just in asking that question, I was able to get the trim levels for all of the different brands for this window of time.

01:04:24.580 --> 01:04:32.580
And just easily get a handle now that I could reference back to, okay, this one on this dealer site, it doesn't have any pictures.

01:04:32.580 --> 01:04:37.580
It doesn't say anything, but it does say, for example, oh, it's an, it's a SXT.

01:04:37.580 --> 01:04:38.580
Okay, cool.

01:04:38.580 --> 01:04:42.580
Now I can at least know that is the second of however many trim levels or whatever.

01:04:42.580 --> 01:04:46.580
So the SE, that's your top one, your SXT, that's your, you can imagine, right?

01:04:46.580 --> 01:04:48.580
Trying to sort this out on your own.

01:04:48.580 --> 01:04:50.580
And then you get the AVP slash SE.

01:04:50.580 --> 01:04:52.580
Well, who comes up with this stuff?

01:04:52.580 --> 01:04:53.580
It's ridiculous.

01:04:53.580 --> 01:04:58.580
But it's super useful if you're like, I don't want to drive across Metro Detroit to go look at this minivan.

01:04:58.580 --> 01:05:01.580
If it doesn't have something that I really cared about.

01:05:01.580 --> 01:05:04.580
And the things that I were zeroed in on were like fairly basic safety features.

01:05:04.580 --> 01:05:07.580
I wanted the blind spot detection and the backup camera.

01:05:07.580 --> 01:05:15.580
So there were other questions too, like when did USB charging get introduced into cars in general?

01:05:15.580 --> 01:05:17.580
I didn't know the answer to that.

01:05:17.580 --> 01:05:22.580
I'm old enough to remember when you had to plug the thing into the lighter and I didn't want that.

01:05:22.580 --> 01:05:25.580
So I don't want a car that's that old where I have to use the lighter outlet anymore.

01:05:25.580 --> 01:05:31.580
I want a car that's at least into the like USB charger era, but when did the USB charger era begin for cars?

01:05:31.580 --> 01:05:33.580
That was another one that perplexity was able to answer.

01:05:33.580 --> 01:05:35.580
And it is so good.

01:05:36.580 --> 01:05:39.580
I think this is about to be a huge trend.

01:05:39.580 --> 01:05:42.580
If I had to guess, because I've been a big fan of this app for a while.

01:05:42.580 --> 01:05:49.580
I had the CEO, Arvind on the Cognitive Edition twice and they just they ship super fast.

01:05:49.580 --> 01:05:53.580
They win head to head comparisons for answer accuracy.

01:05:53.580 --> 01:05:55.580
The product itself is super fast.

01:05:55.580 --> 01:06:02.580
It's got great UI with these sources and others starting to become more multimodal with images as well, which is relatively new.

01:06:02.580 --> 01:06:05.580
We're just a great experience all the way around.

01:06:05.580 --> 01:06:12.580
And I see it as like setting a new standard for answers that are like I started.

01:06:12.580 --> 01:06:21.580
I'm starting to use the term per perplexity to say I'm not sure this is necessarily rock solid ground truth.

01:06:21.580 --> 01:06:27.580
Like perplexity is not always right, but it's the most accurate AI tool.

01:06:27.580 --> 01:06:30.580
It's usually right in my experience.

01:06:30.580 --> 01:06:37.580
You might be able to find something here that is wrong, but everything I ended up fact checking turned out to be true.

01:06:37.580 --> 01:06:50.580
And so there's this kind of very interesting, good enough for practical purposes standard where I don't necessarily need it to be 100, 100 percent accurate for it to be very useful.

01:06:50.580 --> 01:06:52.580
And I would make my decisions.

01:06:52.580 --> 01:06:59.580
Did I trust it enough, for example, to be confident that there was in fact going to be a USB charger in the car that I went to go look at?

01:06:59.580 --> 01:07:03.580
Yes. And in fact, it was correct about that.

01:07:03.580 --> 01:07:12.580
And so I have this kind of per perplexity standard of verification in my mind now where I'm like, yeah, it's in many situations.

01:07:12.580 --> 01:07:14.580
It's like good enough to act on.

01:07:14.580 --> 01:07:22.580
I wouldn't make life and death decisions without more fact checking, but I don't even need to follow these links in most cases now for something like this.

01:07:22.580 --> 01:07:23.580
I'll trust it.

01:07:23.580 --> 01:07:27.580
And it's an emerging like standard in the family as well.

01:07:27.580 --> 01:07:31.580
My wife asks, do we really have to get a car that's that old? Do they have this? Do they have that?

01:07:31.580 --> 01:07:37.580
And I was able to ask perplexity and send her like, yep, it should have a backup camera per perplexity.

01:07:37.580 --> 01:07:40.580
It should have a USB charger.

01:07:40.580 --> 01:07:43.580
It should have the blind spot detection.

01:07:43.580 --> 01:07:47.580
And it's an incredible time saver.

01:07:47.580 --> 01:07:54.580
I think I'm just a worthy alternative to even something like a wire cutter, which has been the standard that my wife has used for a long time.

01:07:54.580 --> 01:07:59.580
But obviously that's an editorial approach where you can't just ask any question you want to ask here.

01:07:59.580 --> 01:08:01.580
You can ask any question you want to ask.

01:08:01.580 --> 01:08:08.580
And I think you do get something oftentimes that is like a worthy rival even to a much more editorial product.

01:08:08.580 --> 01:08:10.580
No, that makes perfect sense.

01:08:10.580 --> 01:08:23.580
It reminds me of wire cutter reminds me of there are all those sites that are like Cora, but it's like for this new generation where no one had to think previously to ask this particular question.

01:08:23.580 --> 01:08:26.580
I can just gather and answer the question for you immediately.

01:08:26.580 --> 01:08:29.580
And I think that's so it's so powerful.

01:08:29.580 --> 01:08:34.580
Like it's really starting to click for me when and how I might, I might use it.

01:08:34.580 --> 01:08:41.580
There are so many questions I have this where I'm like, I basically want to get to the best answer for a fact based question, more or less.

01:08:41.580 --> 01:08:42.580
And I'm so lazy.

01:08:42.580 --> 01:08:50.580
I really don't want to do all the research and chat to BT will kind of like, it'll do one search and then sort of crib the first article.

01:08:50.580 --> 01:08:52.580
And this feels a lot better than that.

01:08:52.580 --> 01:08:53.580
Yeah, it's really good.

01:08:53.580 --> 01:08:57.580
It's faster than chat to BT on the browsing side.

01:08:57.580 --> 01:09:06.580
So you're getting to answer notably faster and marginally more accurate, just more the sort of answer that I want.

01:09:06.580 --> 01:09:15.580
A lot of times like I've had a couple of instances where I tried the same thing with chat to BT and I was able to get there, but it was like slower on the browse.

01:09:15.580 --> 01:09:18.580
Didn't give me the full answer the first time.

01:09:18.580 --> 01:09:20.580
I was like, no, but I need a little more.

01:09:20.580 --> 01:09:22.580
And then I was able to get over the hump and get there.

01:09:22.580 --> 01:09:31.580
But this was definitely just a faster, cleaner experience that I do believe is a bit more accurate as well.

01:09:31.580 --> 01:09:35.580
It goes to show that there are different roles that you want AI to play.

01:09:35.580 --> 01:09:38.580
And I think there is, it's interesting.

01:09:38.580 --> 01:09:40.580
There's forces pushing both ways, right?

01:09:40.580 --> 01:09:44.580
What makes the AIs so compelling is that they're extremely general purpose.

01:09:44.580 --> 01:09:52.580
And it seems like there is something, there is like a fundamental reality that they get really powerful at scale and to scale.

01:09:52.580 --> 01:09:54.580
They have to be the general purpose.

01:09:54.580 --> 01:09:56.580
And that kind of comes as a package.

01:09:56.580 --> 01:09:58.580
But here the scope has been narrowed.

01:09:58.580 --> 01:10:04.580
And there are a lot of things that chat to BT does for people that this is not trying to do for people.

01:10:04.580 --> 01:10:13.580
And in its specialization, it does seem to be achieving higher heights in the domain that it really attempts to be best.

01:10:14.580 --> 01:10:18.580
So I definitely recommend perplexity a lot.

01:10:18.580 --> 01:10:23.580
And I'm just old enough to remember when people were first saying that they were Googling it.

01:10:23.580 --> 01:10:32.580
And this has a similar vibe to me where it's a standard that I think people can comfortably socially transact on and feel like they're pretty solid.

01:10:32.580 --> 01:10:33.580
I love this.

01:10:33.580 --> 01:10:39.580
Like you're using it to build stuff or also really using it to fuel your curiosity.

01:10:39.580 --> 01:10:44.580
And I'm curious, like, you know, before we wrap up, what are you excited about now?

01:10:44.580 --> 01:10:46.580
What are you thinking about right now?

01:10:46.580 --> 01:10:54.580
Like what's on your radar that you think people should be paying attention to in chat to BT, maybe specifically, but like broadly in AI over the next couple years.

01:10:54.580 --> 01:11:02.580
Boy, broadly in AI over the next couple years, I think almost anything's possible.

01:11:03.580 --> 01:11:12.580
I take the leaders of the field pretty much at their word in terms of being honest reflections of their expectations.

01:11:12.580 --> 01:11:16.580
And you listen to what Sam Altman thinks might happen over the next couple years.

01:11:16.580 --> 01:11:21.580
You listen to what Dario Amade from Anthropic thinks might happen over the next couple years.

01:11:21.580 --> 01:11:30.580
And we are potentially looking at something that is superhuman in very substantial and meaningful ways.

01:11:30.580 --> 01:11:36.580
I think there's a lot of kind of conflation and talking past one another when people try to analyze this.

01:11:36.580 --> 01:11:44.580
And I do think it's important to say you can be superhuman in very consequential ways without being like omnipotent or infallible.

01:11:44.580 --> 01:11:51.580
And I think there's actually quite a lot of space right between like human performance and omnipotence or infallibility.

01:11:51.580 --> 01:11:58.580
And I kind of expect that AI is going to land there for a lot of different things over the next couple of years.

01:11:58.580 --> 01:12:05.580
So I think the value of the kinds of things that we will be engaging with it for is only headed up.

01:12:05.580 --> 01:12:17.580
Just a recent result from Google DeepMind on using their best language models for differential diagnosis was an extremely striking result.

01:12:17.580 --> 01:12:20.580
This team has been on an absolute terror.

01:12:20.580 --> 01:12:30.580
It was only maybe like a year ago that they first got a language model to like hit passing level on medical licensing tests, which hey, that's crazy.

01:12:30.580 --> 01:12:32.580
But you can just kind of say, well, it's a test.

01:12:32.580 --> 01:12:33.580
It's more structured.

01:12:33.580 --> 01:12:36.580
The real world is messy and they're only passing.

01:12:36.580 --> 01:12:37.580
You would want a doctor.

01:12:37.580 --> 01:12:38.580
It's just merely passing.

01:12:38.580 --> 01:12:39.580
OK, guess what?

01:12:39.580 --> 01:12:40.580
We didn't stop there.

01:12:40.580 --> 01:12:43.580
Next thing you know, it was hitting expert level performance on the test.

01:12:43.580 --> 01:12:51.580
Next thing you know, it's they've added multi modality and it can now do a pretty good job of reading your x-rays and other tissue slides.

01:12:51.580 --> 01:12:53.580
And again, is it perfect?

01:12:53.580 --> 01:12:58.580
No, it would be probably on the lower end of what the actual human radiologist could do.

01:12:58.580 --> 01:12:59.580
Right.

01:12:59.580 --> 01:13:00.580
Oh, they're even there.

01:13:00.580 --> 01:13:01.580
It was like 6040, I think.

01:13:01.580 --> 01:13:08.580
I think it was like 60% to 40% that the human radiologist was beating the AI radiologist.

01:13:08.580 --> 01:13:09.580
So it's OK.

01:13:09.580 --> 01:13:10.580
That's a pretty narrow margin.

01:13:10.580 --> 01:13:11.580
Obviously, we're not done.

01:13:11.580 --> 01:13:21.580
The current thing is taking case studies out of medical journals, case studies being like extreme hard to figure out cases, right?

01:13:21.580 --> 01:13:27.580
When a case gets reported in a medical journal, that's because this case, you know, is thought to be highly instructive, right?

01:13:27.580 --> 01:13:28.580
It was a confusing situation.

01:13:28.580 --> 01:13:32.580
It's an unfamiliar combination of symptoms or what have you.

01:13:32.580 --> 01:13:35.580
So they don't publish just the routine cold, right?

01:13:35.580 --> 01:13:36.580
In the journals.

01:13:36.580 --> 01:13:49.580
So they take these case studies out of journals and they had a study of comparing AI's effectiveness at doing the differential diagnosis versus human with access to AI.

01:13:49.580 --> 01:13:52.580
And AI was the best by like a significant margin.

01:13:52.580 --> 01:13:55.580
The human alone was last.

01:13:55.580 --> 01:14:05.580
And so they, in their kind of presentation of this, they're very modest and they take almost like a, in my view, almost like a two-grounded willfully bearing the lead.

01:14:05.580 --> 01:14:06.580
Almost at times, it seems.

01:14:06.580 --> 01:14:14.580
And what one of the main conclusions of the paper was we need better interfaces so that doctors can take better advantage of this.

01:14:14.580 --> 01:14:18.580
But it was like, to me, that's yes, that's one lesson I would take away from this paper.

01:14:18.580 --> 01:14:26.580
But the other lesson is that the AI is getting it right like twice as often as the human clinician, like 60% to 30%.

01:14:26.580 --> 01:14:29.580
That's another big lesson, too, that I take away from a lot of these things.

01:14:29.580 --> 01:14:32.580
We don't often measure human performance.

01:14:32.580 --> 01:14:38.580
We think because we've lived in a world for a long time, we're like, a human doctor is human.

01:14:38.580 --> 01:14:44.580
We know that like some are better than others, but we look at that as a standard, that there's a human doctor and their license and they're supposed to be good.

01:14:44.580 --> 01:14:46.580
But like, how often do they get the right diagnosis on this?

01:14:46.580 --> 01:14:50.580
It turned out in this particular data set, it was in the ballpark of 30%.

01:14:50.580 --> 01:14:52.580
So there's a lot of room for improvement.

01:14:52.580 --> 01:14:56.580
And you could perhaps say, what's the best doctor in the world do that?

01:14:56.580 --> 01:14:59.580
Best doctor in the world, I'm sure is a lot better.

01:14:59.580 --> 01:15:03.580
Maybe even better than the 60% that their language model was able to do.

01:15:03.580 --> 01:15:05.580
But you probably can't access that person.

01:15:05.580 --> 01:15:10.580
We are apparently headed for a world where you should be able to access that AI doctor.

01:15:10.580 --> 01:15:23.580
And if it's a 2x better performance on such a challenging task as differential diagnosis that I think we're headed for a world of radical access to expertise,

01:15:23.580 --> 01:15:31.580
which I think is going to be at unbelievably low prices, which I think is going to be a transformative force in society, right?

01:15:31.580 --> 01:15:39.580
It's going to be one of the greatest blows ever struck for equality of opportunity, equality of access in many ways.

01:15:39.580 --> 01:15:47.580
It's also going to change a lot of market dynamics and change what wages can be commanded for different kinds of services.

01:15:47.580 --> 01:15:48.580
I'm excited about that.

01:15:48.580 --> 01:15:54.580
I think it probably is going to be fairly disruptive and it probably is going to become more and more political.

01:15:54.580 --> 01:16:00.580
I think that the upside of that, I think is pretty clear and really extremely compelling.

01:16:00.580 --> 01:16:06.580
So I hope we do get to actually enjoy the fruits of that future.

01:16:06.580 --> 01:16:09.580
And then one other thing I'll say is just, I don't think we are it.

01:16:09.580 --> 01:16:11.580
The transformer is not the end of history.

01:16:11.580 --> 01:16:13.580
That's a chat GPT is not the end of history.

01:16:13.580 --> 01:16:16.580
It's kind of no memory AI.

01:16:16.580 --> 01:16:23.580
Just this last week or two, we've seen a flurry of activity in the state space model architecture.

01:16:23.580 --> 01:16:32.580
And again, it's been reported the headlines if you're on, if you're on Twitter and seeing this stuff, it's hey, there's a new thing that might even be better than the transformer.

01:16:32.580 --> 01:16:34.580
It might be a transformer successor.

01:16:34.580 --> 01:16:35.580
It might be a transformer alternative.

01:16:35.580 --> 01:16:37.580
It might be a transformer replacement.

01:16:37.580 --> 01:16:42.580
It has some nice properties that the transformers don't have better long term memory, better scaling, better speed, better throughput.

01:16:42.580 --> 01:16:45.580
Maybe we just all flip over from one to the other.

01:16:45.580 --> 01:16:47.580
And if the transformer was the old thing, this is the new thing.

01:16:47.580 --> 01:17:00.580
But I strongly suspect that what we are going to see is a mixture of these architectures where just like in the brain, we obviously don't have just one single unit of the brain that gets repeated over and over again.

01:17:00.580 --> 01:17:04.580
We have a lot of different modules, including some that do get repeated.

01:17:04.580 --> 01:17:15.580
It seems like we're almost for sure headed for AIs that are like composites of different kinds of architectures that bring their own strengths and weaknesses in information processing to the table.

01:17:15.580 --> 01:17:28.580
Such that as much as this has been a shocking amount of progress to get to GPT-4 from GPT-2 just four years ago, I have to say I think the next few years are going to bring at least as much more change.

01:17:28.580 --> 01:17:31.580
And it's going to be a wild ride.

01:17:31.580 --> 01:17:39.580
It's exciting. It's inspiring. I'm excited for the future and I really appreciate you taking the time to share your thoughts and show us how you use chat GPT.

01:17:39.580 --> 01:17:44.580
And I'd love to have you back and see where we are, see what new stuff comes up on the horizon.

01:17:44.580 --> 01:17:45.580
Yeah, thank you.

01:17:45.580 --> 01:17:47.580
I appreciate the opportunity Dan. This has been a lot of fun.

01:17:47.580 --> 01:17:53.580
And I definitely learned some things and was inspired to go chase down a few more use cases as well.

01:17:53.580 --> 01:17:59.580
So hopefully next time I'll have some better custom instructions and a little bit better track record in the brainstorming department.

01:17:59.580 --> 01:18:00.580
Let me submit a great exchange.

01:18:00.580 --> 01:18:02.580
That sounds great. Yeah, thanks a lot.

01:18:02.580 --> 01:18:07.580
It is both energizing and enlightening to hear why people listen and learn what they value about the show.

01:18:07.580 --> 01:18:17.580
So please don't hesitate to reach out via email at TCR at turpentine.co or you can DM me on the social media platform of your choice.

01:18:17.580 --> 01:18:27.580
Omnike uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work customized across all platforms with a click of a button.

01:18:27.580 --> 01:18:32.580
I believe in Omnike so much that I invested in it and I recommend you use it too.

01:18:32.580 --> 01:18:35.580
Use CogGrav to get a 10% discount.

