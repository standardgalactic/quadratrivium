{"text": " We're on this upward growth trajectory. We have the potential to taking a big chunk of the universe and doing things with it. And I'm excited by that potential. So I want us to keep growing. And I see how much we've changed to get to where we are. My book, Age of M, is about brain emulations. So that's where you take a particular human brain and you scan it and find spatial chemical detail where you fill in for each cell a computer model of that cell. And if you've got good enough models for cells and a good map of the brain, then basically the IO of this model should be the same as the IO of the original brain. If we can get full human level AI in the next 16 to 90 years with the progress, then this population decline won't matter so much because we will basically have AIs take over most of the jobs and then that can allow the world economy to keep growing. Hello and welcome to the Cognitive Revolution, where we interview visionary researchers, entrepreneurs and builders working on the frontier of artificial intelligence. Each week, we'll explore their revolutionary ideas and together we'll build a picture of how AI technology will transform work, life and society in the coming years. I'm Nathan LaBenz, joined by my co-host Eric Torenberg. Hello and welcome back to the Cognitive Revolution. My guest today is Robin Hansen, Professor of Economics at George Mason University and author of the blog, Overcoming Bias, where Robin has published consistently on a wide range of topics since 2006 and where Eliezer Yudkowski published early versions of what has become some of his most influential writing on AI. Robin is an undeniable polymath whose approach to futurism is unusually non-romantic. Rather than trying to identify value buddies, Robin aims to apply first principles thinking to the future and to describe what is likely to happen without claiming that you should feel any particular way about it. I set this conversation up late last year after my deep dive into the new Mamba states-based model architecture. Because Robin's 2016 book, The Age of M, which analyzes a scenario in which human emulations can be run on computers, suddenly seemed a lot more relevant. My plan originally was to consider how his analysis from The Age of M would compare to similar analyses for a hypothetical age of LLMs or perhaps even an age of SSMs. In practice, we ended up doing some of that, but for the most part took a different direction as it became clear early on in the conversation that Robin was not buying some of my core premises. Taking the outside view as he's famous for doing and noting that AI experts have repeatedly thought that they were close to AGI in the past, Robin questions whether this time really is different and doubts whether we are really close to transformative AI at all. This perspective naturally challenged my worldview and I listened back to this conversation in full to make sure that I wasn't missing anything important before writing this introduction. Ultimately, I do remain quite firmly convinced that today's AIs are powerful enough to drive economic transformation. And I would cite the release of Google's Gemini 1.5, which happened in just the few short weeks between recording and publishing this episode as evidence that progress is not yet slowing down. Yet at the same time, Robin did get me thinking more about the disconnect between feasibility and actual widespread implementation and automation. Beyond the question of what AI systems can do, there are also questions of legal regulation, of course, and perhaps even more importantly, just how eager people are to use AI tools in the first place. When Robin reported that his son's software firm had recently determined that LLMs were not useful for routine application development, I was honestly kind of shocked because if nothing else, I'm extremely confident about the degree to which LLMs accelerate my own programming work. Since then, though, I have heard a couple of other stories, which combined with Robbins, helped me develop, I think, a bit better theory of what's going on. First, an AI educator told me that failure to form new habits is the most common cause of failure with AI in general. In his courses, he emphasizes hands-on exercises because he's learned that simple awareness of AI capabilities does not lead to human behavioral change. Second, a friend told me that his company hosted a Microsoft GitHub salesperson for a lunch hour demo, and it turned out that one of their own team members had far more knowledge about GitHub Co-Pilot than the rep himself did. If Microsoft sales reps are struggling to keep up with Co-Pilot's capabilities, we should perhaps adjust our expectations for the rest of the economy. And third, in my own experience, helping people address process bottlenecks with AI, I've repeatedly seen how unnatural it can be for people to break their own work down into the sort of discrete tasks that LLMs can handle effectively today. Most people were never trained to think this way, and it's going to take time before it becomes common practice across the economy. All this means that change may be slower to materialize than those of us on the frontiers of AI adoption might expect. And while that does suggest more of an opportunity and indeed advantage for us in the meantime, on balance, I do have to view it as a negative sign about our preparedness and our ability to adapt overall. Regardless of your views, and I do suspect that most listeners will find themselves agreeing with me more than with Robin, his insights are always thought-provoking, and I think you'll find it very well worthwhile to engage with the challenges that he presents in this conversation. As always, if you're finding value in the show, we would appreciate it if you'd share it with friends, post a review on Apple Podcasts or Spotify, or just leave a comment on YouTube. And of course, I always love to hear from listeners, so please don't hesitate to DM me on the social media platform of your choice. Now, I hope you enjoy this conversation with Professor Robin Hansen. Robin Hansen, Professor of Economics at George Mason University and noted polymath, welcome to the cognitive revolution. Nice to meet you, Nathan. Let's talk. I'm excited about this. So I have followed your work for a long time. It's super wide-ranging and always very interesting. People can find your thoughts on just about everything, I think, over the years on overcoming bias, your blog. But today, I wanted to revisit what I think is one of your destined to be, perhaps one of your most influential works, which is the book, The Age of M, which came out in 2016 and Envisions a Future, which basically amounts to putting humans on machines, and we can unpack that in more detail, and then explores that in a ton of different directions. Where we actually are now as we enter into 2024 is not exactly that, certainly, but I've come to believe recently that it's maybe bending back a little bit more toward that, certainly more than my expectations a year ago. So I've revisited the book, and I'm excited to bring a bunch of questions and kind of compare and contrast your scenario versus the current scenario that we seem to be evolving into. Okay, let's do it. One big theme of your work always, I think, is that we live in this strange dream time, and that our reality as modern humans is quite different than the reality of those that came before us and likely those that will come after us for some pretty fundamental reasons. Do you wanna just sketch out your kind of big picture argument that our times are exceptional and not likely to go on like this forever? The first thing to notice is that we were in a period of very rapid growth, very rapid change, which just can't continue for very long on a cosmological time scale. 10,000 years would be way longer than it could manage, and therefore we're gonna have to go back to a period of slower change, and plausibly then a period of slower change will be a period where population can grow faster relative to the growth rate of the economy in the universe, and therefore we will move back more toward a Malthusian world if competition remains, such as almost all our ancestors were until a few hundred years ago. So we're in this unusual period of being rich per person and in very rapid change, and also sort of globally integrated. That is, our distant ancestors were fragmented culturally across the globe, and each talk to a small group of people near them, and our distant descendants will be fragmented across the universe, and they won't be able to talk all across the universe instantaneously. So future culture and past culture were both very fragmented, and we were in a period where our entire civilization can talk rapidly to each other. The time delay of communication is very small compared to the doubling time of our very rapid growth economy. So we are now an integrated civilization where rich growing very fast, and there's a number of consequences being rich, which is that we don't have to pay that much attention to functionality. Those were not pressured to do what it takes to survive in the way our ancestors and our descendants would be. So we can indulge our delusions, or whatever other inclinations we have, they aren't disciplined very rapidly by survival and functionality. That makes us a dream team. That is, our dreams drive us. Our abstract thoughts, our vague impressions, our emotions, our visions. We do things that are dramatic and exciting and meaningful in our view, according to this dream time mind we have, which isn't, again, that disciplined by functionality, that is, the mind we inherited from our distant ancestors, it was functional there, it was disciplined there, we're in a very different world, but our mind hasn't changed to be functional in this world. And so we are expressing this momentum of what we used to be in this strange new world. That's the dream time. So let me just try to rephrase that or frame it slightly differently and tell them if you agree with this framing. I would maybe interpret it as, we're maybe in a punctuated equilibrium sort of situation where we're in the transition from one equilibrium to another, there have probably been however many of these through history, not like a huge number, but a decent number, I think of such phrases as the Cambrian explosion, perhaps as another dream time. These moments happen when some external shock happens to the system, whether that's like an asteroid that takes out a lot of life, or human brains come on the scene, and there's a period in which the normal constraints are temporarily relaxed, but then in the long term, there's just like no escaping the logic of natural selection. Is that basically the framework? So your analogy of the Cambrian explosion could be, we discovered multicellularity, we discovered being able to make large animals, and that was happened at a moment, there was the moment of multicellularity, and then evolution took time to adapt to that new opportunity, and the Cambrian explosion is the period of adaptation, then after the Cambrian explosion, we've adapted to that new opportunity, and then we're more in a stasis, and then you're imagining this period of adaptation to a sudden change. But for humans today, we keep having sudden changes, and they keep coming fast, and so there wasn't this one thing that happened 300 years ago or 10,000 years ago that we're slowly adapting to. We keep having more big changes that keep changing the landscape of what it is to adapt to, so we won't see this slow adaptation to the new thing until we get a stable new thing, which we haven't gotten yet. We, things keep changing. I wanna maybe circle back in a minute to what would be the conditions under which things would restabilize. I think I guess the M scenario is one of them, but there may be others that might even be more imminent at this point. Before doing that, I just wanted to touch on another big theme of your work, which is, and I really appreciate how you introduced the book this way with the idea that I'm just trying to figure out what is likely to happen in this scenario. I'm not telling you you should like it. I'm not telling you you should dislike it. I'm not trying to judge it. I'm just trying to extrapolate from a scenario using the tools of science and social science to try to figure out what might happen. I love that, and I try to do something similar with this show around understanding AI. I think there's so much emotional valence brought to so many parts of the discussion, and I always say, we need to first figure out what is, and even in the current moment, what capabilities exist, what can be done, what is still out of reach of current systems before we can really get serious about what ought to be done about it. I guess I'd invite you to add any additional perspective to that, and then I'm also curious, like, I think that's very admirable, but could you give us a little window into your own kind of biases or preferences? Like, what sort of world do you think we should be striving for, or do you think that's just so futile to even attempt to influence against these, you know, grand constraints that it doesn't matter? Hey, we'll continue our interview in a moment after a word from our sponsors. The Brave Search API brings affordable developer access to the Brave Search Index, an independent index of the web with over 20 billion web pages. So what makes the Brave Search Index stand out? One, it's entirely independent and built from scratch. That means no big tech biases or extortionate prices. Two, it's built on real page visits from actual humans, collected anonymously, of course, which filters out tons of junk data. And three, the index is refreshed with tens of millions of pages daily, so it always has accurate up-to-date information. The Brave Search API can be used to assemble a dataset to train your AI models and help with retrieval augmentation at the time of inference, all while remaining affordable with developer-first pricing. Integrating the Brave Search API into your workflow translates to more ethical data sourcing and more human-representative datasets. Try the Brave Search API for free for up to 2,000 queries per month at brave.com slash API. Pretty much all big, grand talk is mostly oriented around people sharing values. That's what people want to do when they talk big politics, when they talk world politics or world events, when they talk the future. People want to jump quickly to, do I share your values? Here's my values. What are your values? Do we agree on values? Are we value buddies? And people are so eager to get to that that they are willing to skip over the analysis of the details, say, if they want to talk about, I don't know, the war in Ukraine. People want to go, which side are you on? And who, you know, do we have the right values and then they don't care to talk about like, who has how much armaments that will run out soon or who can afford what or what they, you know, all those details of the war. They don't want to go there. They just want to go to the values and agree about it. And that happens in the future too, futurism too. People just want to jump to the values. So for the purposes people have, they're doing roughly the right thing. They don't really care about the world and they don't really care about the future. What they care about is finding value buddies or if you find a value conflict, having a value war. That's what people just want to do. And so if you actually want to figure out the world or national politics or national policy or you want to figure out the future, you really have to resist that and you have to try to pause and, you know, go through an analysis first, a neutral analysis of what the options are, what the situation is. I mean, I am afraid literally that if I express many values that the discussion will just go there and you'll never talk about anything else. And that's why I resist talking about that. But I think, you know, my simplest value with respect to the future is I really like the fact that humanity has grown and achieved vast things compared to where it started. We're on this upward growth trajectory. We have the potential to taking a big chunk of the universe and doing things with it. And I'm excited by that potential. So my first cut is I want us to keep growing. And I see how much we've changed to get to where we are. And I can see that had people from a million years ago insisted that their values be maintained and that the world be familiar and comfortable to them. If they've been able to enforce that, we would not have gotten where we are now. That would have prevented a lot of change. So I kind of see that if I want us to get big and grand, I'm gonna have to give a lot on how similar the future is to me and my world. I'm gonna have to compromise a lot on that. I just don't see any way around that. So I get it that if you want the future to be really comfortable for you and to share a lot of your values and your styles, you're gonna have to prevent it from changing. And you may have a shot at that. I would not like that, but you might. So again, even as part of the value framework, even when I talk values with you, I want to be clear to distinguish my value talk from the factual talk. I'm gonna be happy to tell you what it would take for you to get your values, even if they aren't mine. So maybe we should talk about the facts of LLMs. You wanna go there in terms of comparing Ms and LLMs, right? So first of all, our audience, we should say for our audience, my book Age of M is about brain emulations. So that's where you take a particular human brain and you scan it and find spatial chemical detail to figure out which cells are where, connected to other cells through what synapses. You make a map of that, and then you make a computer model that matches that map where you fill in for each cell, a computer model of that cell. And if you've got good enough models for cells and a good map of the brain, then basically the IO of this model should be the same as the IO of the original brain, which means you could hook it up with artificial eyes, ears, hands, mouth. And then it would behave the same as the original human would in the same situation, in which case you can use these as substitutes for humans throughout the entire economy. And then my exercise of the Age of M book was to figure out what that word looks like. And a primary purpose was to actually be able to show that it's possible to do that sort of thing. It's possible to take a specific technical assumption and work out a lot of consequences. And many people have said they didn't want so many details. They'd rather have fiction or something else, but I was trying to prove how much I could say. And I hope you'll admit, I proved I could say a lot. And that almost no other futurist work does that. And so I'm trying to inspire other futurists to get into that level of detail, to try to take some assumptions and work out a lot of consequences. So that's my book, The Age of M. You'd like us to compare that to current large-language models and to think about what we can say about the future of large-language models. So in my mind, the first thing to say there is, well, an M is a full human substitute. It can do everything a human can do, basically. A large-language model is not that yet. So a key question here would be, how far are we going to go in trying to imagine a descendant of a large-language model that is more capable of substituting for humans across a wide range of contexts? We stick with current large-language models. They're really only useful in a rather limited range of contexts. And so if you're gonna do forecasting of them, it's more like forecasting the future with a microwave oven or something. You think about, well, where can you use a microwave oven and how much will it cost and what other heating methods will it displace and what sort of inputs would be a compliment to that? It would be more of a small-scale, future forecasting exercise. Whereas The Age of M was purposely this very grand exercise because the M's actually change everything. Whereas most futurism, like if you're trying to analyze consequences of microwave oven, you have a much more limited scope because in fact, it'll have a limited impact. So that would be the question I have for you first, which is, are we gonna talk about the implications of something close to the current large-language models? Are we gonna try to imagine some generalized version of them that has much wider capabilities? Yeah, very good question. I think maybe two different levels of this would be instructive. One of the key things that jumps out and I think a lot of stuff flows from is the assumption that M's can be copied cheaply, paused and stored indefinitely cheaply, but not understood very well in terms of their internal mechanism. Very much like this similar understanding to what we have of the brain where we can kind of poke and prod at it a little bit, but we really don't have a deep understanding of how it works. We can't do like very localized optimizations, but we do have this like radical departure from the status quo, which is you can infinitely clone them, you can infinitely freeze and store them. And so this creates like all sorts of elasticities that just don't exist in the current environment. So a number of those features are gonna be general that anything that can be represented as computer files and run on a computer. So any form of artificial intelligence will be some of the sort in general that you could have a digital representation of archive it, make a copy of it, pause it, run it faster or slower, that's gonna be just generically true of any kind of AI, including M's. The ability to sort of modify it usefully, I mean, yes, with human brains initially, they're just a big mess, you don't understand them, but honestly, most legacy software systems are pretty similar. So today, large legacy software systems, you mostly have to take them as they are. You can only make modest modifications to them. That's close to what I'm assuming for M's. So I'm actually not assuming that they are that different from large legacy software systems. They're just a big mess that even though you could go look at any one piece and maybe understand it, that doesn't really help you usefully in modifying the entire thing. You basically have to take the whole thing as a unit and can only make some minor changes. But you can copy the whole thing, you can run it faster or slow, you can move it at speed, transfer at the speed of light around the earth or through the universe. Those things are true of pretty much any AI that could be represented as a computer file, run on a computer. Yeah, I think these dimensions are a really useful way to break this down. I took some inspiration from you in a presentation that I created called the AI Scouting Report, where I have the tail of the cognitive tape that compares human strengths and weaknesses to LLM strengths and weaknesses. And I think for the purposes of this discussion, maybe we might even have like four different kind of things to consider. One is humans, second would be M's, third is let's say transformer language models of the general class that we have today. Although I think we can predictably expect at a minimum that they will continue to have longer context windows and have generally more pre-training and generally more capability, at least within a certain range. And then the fourth one that I'm really interested in and has been kind of an obsession for me recently is the new state space model paradigm, which actually has some things now in common again with the humans and the M's that the transformer models lack. The state space models, this has been, of course, in a line of research that's been going on for a couple of years, kind of in parallel with transformers. Transformers have taken up the vast majority of the energy in the public focus because they have been the highest performing over the last couple of years. But that has maybe just changed with a couple of recent papers, most notably one called Mamba, that basically shows parity, rough parity with the transformer on kind of your standard language modeling tasks, but does have like a totally different architecture that I think opens up like some notably different strengths and weaknesses, whereas the transformer really just has the weights and then the sort of next token prediction, the state space model has this additional concept of the state, which is, and I recall from the book, you sort of say, taking an information processing lens to the human or where you spend more of your focuses on the M, you have the current state plus some new input information, sensory or whatever, and then that propagates into some action, some output and a new internal state. And that I think is really the heart of what the new state space models do is that they add that additional component where they have not only the weights, like a transformer has static weights, but they also have this state, which is of a fixed size, evolves through time, and is something that gets output at each kind of inference step so that there is this internal state that propagates through time and can kind of change and have long history. I think it is likely to bring about a much more integrated medium and long-term memory than the transformers have and create more sort of long episode conditioning where these models I think will be more amenable to like employee onboarding style training, which is something also that the M's have in your scenario, right? You can kind of train a base M to be an employee for you, you can even put it in that mental, get it to that mental state where it's like really excited and ready to work, and then you can freeze it, store it, boot it up when necessary, boot it up end times as necessary. The transformers don't really have that same feature right now, they're just kind of their monolithic base form at all times, but the state-state models start to add some of that back. Obviously, it's not gonna be one-to-one with the humans or the M's. Here's gonna be my problem with that number four. If I look at sort of the history of AI over the history of computers and even the history of automation before that, we see this history where a really wide range of approaches have been tried, a really wide range of paradigms and concepts and structures have been introduced. And over time, we've found ways in some sense to subsume prior structures within new ones, but we've just gone through a lot of them. And there's been this tendency, unfortunately, that when people reach the next new paradigm, the next new structure, they get really excited by it and they consistently say, are we almost done? They said that centuries ago, they said that half a century ago, every new decade, every new kind of approach that comes along, there's basically typically some demo, some new capability that this new system can do that none of the prior systems are able to do. And it's exciting and it's shocking even and exciting, but people consistently say, so we must be almost done, right? Like, surely this is enough to do everything and pretty soon humans will be displaced by automation based on this new approach. And that just happens over and over again. And so we've had enough of those that I got to say, the chance that the next exciting new paradigm is the last one we'll need is a prior pretty low. We've had this long road to go and we still have a long way to go ahead of us. And therefore, it's unlikely that the next new thing is the last thing. So that's my stance, I would think, okay, I can talk to you about LLMS because they're the latest thing. We can talk about LLMS, they're the latest thing. We can talk about what new things they can do and what exciting options that generates in the near future. And then we can ask, well, what's the chance it's the last thing we'll need? Or that the next one is the last thing we need. And so one way to cash that out is to ask, what do we think the chances are that within a decade or even two, basically all human jobs will be replaced by machines based on this new approach. And most of the forecasting that's done out there is excited about near-term progress in a lot of ways. But when you ask the question, when will most jobs be replaced? They give you forecasts that are way out there because they think, no, we're not close to that. And I don't think we're close to that. So then the question is, now we could say, what will happen when we eventually get to the point where AI is you're good enough to do everything? And we don't know what that approaches, but we can still talk about that point and what's likely to what the transition rate would be and the transition scenario and who would get rich and who would be unhappy and all the different things we could talk about there. But now we're talking about whatever approach eventually gets us past the being able to have to do pretty much all human tasks, which is not where we are now, or we can talk about where we are now and what these things can do and what exciting things might happen in the next decade. Hey, we'll continue our interview in a moment after a word from our sponsors. If you're a startup founder or executive running a growing business, you know that as you scale, your systems break down and the cracks start to show. If this resonates with you, there are three numbers you need to know, 36,000, 25 and one, 36,000. That's the number of businesses which have upgraded to NetSuite by Oracle. NetSuite is the number one cloud financial system, streamlined accounting, financial management, inventory, HR and more, 25. NetSuite turns 25 this year. That's 25 years of helping businesses do more with less, close their books in days, not weeks and drive down costs. One, because your business is one of a kind, so you get a customized solution for all your KPIs in one efficient system with one source of truth. Manage risk, get reliable forecasts and improve margins, everything you need all in one place. Right now, download NetSuite's popular KPI checklist, designed to give you consistently excellent performance, absolutely free and netsuite.com slash cognitive. That's netsuite.com slash cognitive to get your own KPI checklist, netsuite.com slash cognitive. Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work, customized across all platforms with a click of a button. I believe in Omniki so much that I invested in it and I recommend you use it too. Use CogGrav to get a 10% discount. Well, I'm tempted by all of those options. So maybe for starters, I would be interested to hear how you would develop a cognitive tail of the tape between humans and M's by presumption have kind of the same cognitive abilities, but these kind of different external properties of copyability and so on. The large language model today, transformer, remarkably simple architecture, when you really just look at the wiring diagram, it's way simpler than the human brain is. And not shockingly, it can only do certain things that there's like really important traits that the human brain has that the language models don't have. I identified one of those as kind of integrated, ever-evolving, medium and long-term memory. I wonder what else you would kind of flag there. I don't know if you have a taxonomy of what are the kind of core competencies of humans that you could then say, oh, and here's the things that language models currently lack. I'm trying to develop something like this in general because it does seem to me that the large language models have hit not genius human level, but like closing in on expert human level at some very important, dare I say, even like core aspect of information processing, right? Like they can do things that I would say are qualitatively different than any earlier AI system could do. It certainly seems like we're getting close, whatever the last step is, we're definitely closer to it than we used to be. But just notice that phrase you just gave was true or most of all the previous ones as well. They could also do a thing that the previous ones before it couldn't do. It's always been exciting. We've found a new fundamental capability that each new paradigm structure approach has been of this sort that it was allowed the system to do fundamental things that it couldn't do before that seemed to be near the core of what it was to think. So there's apparently a lot of things near the core of what it is to think. That's the key thing to realize. What it is to think is a big thing. There's a lot of things in there. Well, let's list some. I can't come up with that many honestly. Like I would love to hear how many can you name I have all day. So could you begin to break down what it is to think into key components? I was an AI researcher from 84 to 93. That was a full time at NASA and then Lockheed. And certainly at that time, I understood the range of approaches people had and could talk about the kinds of things systems then could do or not do and expert terms relating to the then current tasks and issues. I am not up to date at the moment on the full range of AI approaches. I don't wanna pretend to be an expert on that. But I have listened to experts and the experts I hear basically consistently say, this is exciting, this is great, but we're not close to being able to do all the other things and they would be much better than I am making a list of that and I feel like they should make the list, not me. I mean, as a polymath you call me, I wanna be very careful to know when I'm an expert on something and when I'm not. And I wanna defer to other people on areas where I can find people who know more than I. And when I think I'm near the state of the art, as good as anyone on a topic, then I will feel more free to generate my own thoughts and think they're worth contributing. Fair, certainly, I think most people where I think you do still bring something very differentiated to the discussion is just the sort of willingness to stare reality in the face or at least try to. The simplest thing is if I start talking to an out large language model, there's a whole bunch of things I can ask it to do that it just can't do. I'm not so sure how to organize that in terms of the large major categories, but it's really obvious that there's a certain kind of thinking it can do and a bunch of other kind of thinking it can't do. And I don't know exactly why it can't do them, but I'm talking to you, there's a bunch of things I could ask you to do in this conversation that you would probably do a decent job of them. And then if I were talking to the large language model, it just couldn't do those things. So it's just really obvious to me that this has a limited capability. It's really impressive compared to what you might have expected five or 10 years ago, it's, wow, I never would have thought that would be feasible this soon, but you just try asking it a bunch of other things and it just can't do them, right? Yeah, I mean, I think that in my view, a lot of those things are kind of overemphasized relative to what maybe really matters. You see a lot of things online where people, and there's different categories of this, some of the things you'll see online are literally people just using non frontier models and kind of confusing, muddying the water. So always watch out for that. I have a longstanding practice of, first thing I do when I see somebody say, GPT-4 can't do something is try it myself. And I would honestly say like two thirds of the time, it's just straight up misinformation and it in fact, like can do it. But there's still the one third of the time that matters. They're not very adversarially robust. They're easy to trick, they're easy to sort of get on the wrong track. And then they seem to get kind of stuck in a mode is a good term for it, I think, where once they're kind of on a certain, this is kind of how they can often get jailbroken. If you can get them to say like, okay, I'll be happy to help you with that, then they'll go on and do whatever you asked because they've already kind of got into that mode. Yeah, I'm much less worried about them doing things you don't want them to do than being able to get them to do things at all. That as humans can be made to do all sorts of things, you might not want them to do that. We survive that. I mean, to me, the main thing is, if you imagine, you know, treating a large language model as a new employee in some workplace where you're trying to show them how to do something and get them to do it instead of you, that's the main thing that will be economically valuable in the world. That is, when you have a thing like that that can be introduced into a place, trained roughly and said, watch how I do this, you try to do it now, et cetera, then that will be the thing that, you know, makes an enormous difference in the economy because that's how we get people to do things, right? So if that I think is, in a sense, the fundamental main task in the economy, which is a bunch of people are doing something, you have a new thing and you say, would you Kim watch us and ask us questions and we'll ask you questions and like figure out how to help us and be part of what we're doing. That is the fundamental problem in the economy. So that in some sense is the fundamental task that any AI has to be held up to. I mean, in the past, of course, we don't even bother to have a conversation to show you how to do, we actually say, well, let's make a machine to do this thing and then we design a machine to do this thing and then we train it up to do this thing all with the idea of the whole thing, having in mind the thing we're gonna have to do. That's how AI has been usually in the economy so far. But now if you're imagining a thing that could just be trained to do a new job, well, that would be great. Sure, then we won't have to design the AI ahead of time for the particular task, but you'll have to have a thing that's up to that and large language models today are just clearly not up to that. You can't say, I'm about to train you how to do the following thing, pay attention, I just did this, now would you do it? Well, you can do that quite a bit, right? I mean, that was the main kind of finding in GPT-3 was, I'm not sure if I have this verbatim, but the title of that paper was large language models are few shot learners. And the big kind of breakthrough observation there, which I don't think they designed, there's a whole quagmire of what should count as emergent or not emergent, but my understanding is they didn't specifically train for this few shot imitation capability, but they nevertheless got to the point where at runtime today, you can give a few examples of what you want. And in fact, that is like a best practice that open AI and anthropic recommend for how to get the most from their systems. They'll say, some things are hard, they also have now trained them to follow instructions, just verbatim or explicitly, but they will still say that, some things are better shown by example than described in terms of what to do. So do that, and you'll get like a lot better performance. It seems to me that there is on that kind of watch, watch it to borrow from medicine, watch one, do one, teach one, it seems like we're on the do one step, and that does seem to be a pretty qualitative threshold that has been passed. Now, they obviously can continue to get better at that. Right, but it's the range of things they can do that's the question. Yes, it's great that they can, you can say, here's some examples, give me another one, but the range of things you can do that for is limited. Most people in most jobs, they couldn't have large language model swap in for many of their main tasks that way. But there are some and that's exciting, and I hope to see people develop that and improve it. But again, the key question is how close are we to the end of this long path we've been on for a while? Yeah, I guess I think about it a little bit differently in terms of rather than thinking about the end of the path, I think of how close are we to key thresholds that will bring in qualitatively different dynamics relative to the current situation. So one threshold that I think has recently been passed and in a pretty striking way that this is, should get more discussion than it does in my view is Google DeepMind just put out a paper not long ago where they showed basically a two to one advantage for a large language model in medical diagnosis versus human doctors. And then of course they also compared to human plus AI and that was in the middle. So on these cases that they lined up in the scenario is like you're chatting with your doctor, 60% accuracy from the language model, 30% accuracy from the human. I was an AI from 83 to 94. And at the beginning, one of the reasons I came into AI was there were these big journal articles and national media coverage about studies where they showed that the best AI of the time which they called expert systems were able to do human level medical diagnosis. This was in the early 1980s, right? We're talking 40 years ago. And obviously the computer capacity is vastly larger than that. So either they were lying back then and messing with the data or they did have human level diagnosis back then but they weren't allowed to apply it because of medical licensing. So, and we're still not allowed to apply it because of medical licensing. So, this is exactly the sort of ability that won't give substantial economic impact because we had it 40 years ago and it didn't have an impact then. Yeah, I don't know. So if I had, I think one qualitative difference between that earlier system and this system which won't come to be an expert in the earlier expert systems but I would guess that a huge difference is that you can take today a totally uninitiated person who has a medical concern and say, sit in front of this computer, talk to this doctor. They don't even need to know as an AI doctor. They can just talk to him. That wasn't the problem back then. They could have made these expert systems usable by ordinary people with modest effort. That wasn't the problem in using them. The problem was just you're not legally allowed to use them. Only doctors are allowed to give medical diagnoses. And so only doctors are allowed to use these systems to talk to people. That was the main obstacle and it still is today. The obstacle, you could make such a system today that ordinary people could talk to but they're not allowed to talk to it and they won't be allowed to talk to it for a long time. I think there is a qualitative difference between these systems. If I were to sit down in front of the early 80s thing and I were to say, what's different today is the chat system could say, Robin, tell me how you're feeling. Tell me about your experience. And you can just go on in your own language, however you want to express yourself, and it can get you. And then it can ask you specific follow up but you're not going through a wizard and going down an expert system tree and ask for numeric scores you don't understand and don't know. You can literally just express yourself. That was not there then, right? I mean, nothing. But that's not the limiting factor, right? I mean, you couldn't have a fancy graphics interface back then either. This was early 1980s, right? But again, the limiting factor is the legal barrier. It was back then and still is and that legal barrier doesn't look like it's about to go away. So if you're gonna make us excited about applications it'll have to be something that's legal. My model of this is that the consumer surplus of this type of thing is going to be so great. It already was 40 years ago. It would have been a huge consumer surplus 40 years ago, it was not allowed. But there was never a groundswell of, I don't know. I'm just not buying this. I'm not buying that there was an experience that is qualitatively like the one that we have today such that I think today if you show people what Google has they will say it is not acceptable to me that you keep this locked up behind some payroll. I don't think that was the general consumer reaction to early 80s expert systems. And it seems like that political economy pressure could change things. Consider the analogy of nuclear power. The world has definitely been convinced for a long time that nuclear power is powerful. It is full of potential and power. And if we had let it go wild we would have vastly cheaper energy today but it was that power that scared people which is why we don't have that energy today. The very vision of nuclear energy being powerful is what caused us not to have it. We over-regulated it to death and we made sure that the power of nuclear power was not released. We believed the power was there. It was not at all an issue of not believing that nuclear power was powerful. It was believing it was too powerful. Scary, dangerous, powerful. And there's a risk that we'll do that with AI today. We will make people believe it's powerful, so powerful that they should be scared of it and it should be locked down and not released into the wild where it might do us terrible danger. Yeah, well, that's certainly a tragic outcome in the case of the nuclear power. And I think it would also be a tragic outcome if people are denied their AI doctors of the future on that basis. And it could happen. I certainly wouldn't rule out the possibility that just AI research probably gets made illegal. This time we do have, I mean, again, it is, I do think we're in a different regime now where enough has been discovered and enough has been put into the hands of millions. There is sort of the open source kind of hacker level. Not medical diagnosis is not. We have not put medical diagnosis AI in the hands of ordinary people. And if you tried it, you would find out just how quickly you'd get slapped now. Yeah, I think I know someone who actually may be about to try this and it'll be very interesting to see how quickly and how hard they get slapped down and how they may respond from it. I've actually been very encouraged by the response from the medical community. I would say, obviously it's not a monolithic thing, but I did an earlier episode with Zach Kahane, who is a professor at Harvard Medical School and who had early access to GPT-4. He came out with a book basically to coincide with the launch of GPT-4 called GPT-4 and the Revolution in Medicine. And broadly, I have been encouraged by how much the medical establishment has seemingly been inclined to embrace this sort of stuff. I don't know if it's just that they're also overworked these days or... Well, they'll embrace the internal use of it. Again, it's always been doctors allowed to use these things. And the main reason they didn't get more popular is doctors couldn't be bothered to type in and input all the information because they want to have short meetings with patients. Even today, of course, if you've gone to a modern doctor, most of your meeting with a doctor is them typing in information to their computer as they talk to you. And they don't wanna spend much more time typing in more. And so they don't wanna use computer aids in their diagnosis and that's been true for a long time. They, computer diagnosis aids have been available for a long time that would give them better diagnoses at the cost of them having to spend more time with them than they've chosen not to spend more time. That's been true for many decades now. Have you personally used GPT-4 for any advanced things like this, medical or legal advice or whatever? No, I'm an economics professor. So I've used it to check to see what my students might try to use it to answer my exam questions or essay questions or things like that. I've asked it things that I wanted to know and try to check on them. I haven't used it for legal or medical questions. Those are areas which are heavily regulated. It's always been possible for other people to offer substitutes. So for example, many decades ago, there were experiments where we, basically for the purpose of general practice for doctors, we compare doctors to nurses, nurse practitioners or paramedics. We found that those other groups did just as well and much cheaper at doing the first level of general practice, but they haven't been allowed. So that right there is enormous value that could have been released. We could have all this time been having nurse practitioners and doctors and paramedics do our first level of general practice medicine. And they would save at least a factor of two or three in cost and that's been true for decades. We've had randomized experiments showing that for decades. So going back to the age of M then for a second, are you just assuming that that scenario doesn't happen in M land for some reason? Or like, why wouldn't it be the first objection to the age of M seems like it maybe should be, M's will be made illegal. Nobody will be allowed to do it. Absolutely. And basically you're just kind of in the analysis saying, well, let's just assume that doesn't happen because it'll be, you know, it's a short book if they just get made illegal too early. Is that the idea? Well, so first of all, I say transitions are harder to analyze than equilibria of New World. So I try to avoid analyzing the transition. Although I do try to discuss it some toward the end of the book, but I admit, I can just say less about a transition. It does seem like that, you know, compared to a scenario where everyone eagerly adopted M technology as soon as it was available, more likely there will be resistance. There will be ways in which there are obstacles to M technology early on. And therefore at some point, there would basically be the, you know, breaking of a dam flooding out where a bunch of things that had been held back were released and then caused a lot of disruption, faster disruption that would have happened had you adopted things as soon as they were available. And that's part of, that can be very disturbing transition then, you know, if all of a sudden large numbers of people are disrupted in ways they weren't expecting in a very rapid way because of, you know, a dam suddenly broke open, then I think there will be a lot of unhappy people in that sort of a transition and maybe a lot of dead people. So imagine the M technology slowly just gets cheaper over time, but it's not very wide. It's not very widely adopted. Then there'll be a point at which it eventually gets so cheap that if some say ambitious nation, like say North Korea said, gee, if we went whole hog and adopting this thing, we could get this big, you know, economic and military advantage over our competitors, then eventually somebody would do that. Now it might take a long time. That is the world could coordinate to resistance technology for a long time, but I don't think they could hold it back for a thousand years. So then I feel somewhat confident, eventually in the age of M happens, and then eventually there's a thing to think about and then I'm analyzing that world. So I don't want to presume in the age of M that this transition happens smoothly or soon or as fast as it could, but I want to say eventually there'll be this new world and here's how it would play out. So I don't know if you know that in the last few months I've dramatically changed my vision of the future to say that there's probably gonna be a several century innovation pause, probably before the age of M happens, and then the world that would eventually produce AI and M's would be a very different world from ours and somewhat hard to think about. That is rising population will stop rising and it will fall due to falling fertility, that will basically make innovation grind to a halt, then the world population will continue to fall until insular fertile subcultures like the Amish grow from their very small current levels to become the dominant population of the world. And then when that becomes large enough compared to our current economy, then innovation would turn on again and then we would restart the AI and M path and then eventually the age of M would happen. Trying to anticipate how transitions would happen in a world we can just hardly even imagine, seems tough, right? That is, okay, imagine the descendants of the Amish become a large, powerful civilization. They've always been somewhat resistant to technology and very picky about which technologies they're allowed, but eventually I would predict there would be competition within them and that would push them to adopt technologies like AI and M's but we're looking a long way down the line. And this isn't what I wish would happen to go back to your initial thing. I would rather we continued growing at the rate of the past century and continue that for a few more centuries, by which time I'm pretty sure we'll eventually get M's and human level AI, although question in what order, but I got to say at the moment, that's not looking so good. So basically, I'm estimated that if we were to continue on a steady growth path, we would eventually reach a point where we had the same amount of innovation as we will get over the entire integral of this several centuries pause. And I've estimated that to be roughly 60 to 90 years worth of progress. So if we can get full human level AI in the next 60 to 90 years with the progress, then this population decline won't matter so much because we will basically have AI's takeover most of the jobs and then that can allow the world economy to keep growing. I think that's iffy whether we can do that, whether we can achieve full human level AI in 60 to 90 years. And I know many people think it's gonna happen in the next 10 years, they're sure. So sure, of course it'll happen in 60 to 90 years, but I look at the history and I go, look, I've seen over and over again, people get really excited by the next new kind of AI. And they're typically pretty sure, a lot of them are pretty sure that we must be near the end and pretty soon we'll have it all. And it just keeps not happening. The main change I wanna suggest to that paradigm is replacing the end with meaningful thresholds along the way. I think there are probably several that we will hit on some time scale. And it feels to me like, at least a couple of the big ones are pretty close. And then at the end is very, my crystal ball gets very foggy beyond like a pretty short time scale. But I'm struggling with the early 80s expert systems, but it really does seem like in my lifetime, I have not seen anything that remotely resembles the experience of going to a doctor. I've seen WebMD, I'm familiar with expert systems to a degree, but I've never seen anything that, I didn't think Ilya Setsgaver from OpenAI puts this really well, he's like the most shocking thing about the current AIs is that I can speak to them and I feel that I'm understood. And that is like a qualitatively different experience. And clearly I think reflects some qualitative advance in terms of what kind of information processing is going on. If I had to say like, what is that under the hood? I would say it's like a high dimensional representation of concepts that are like really relevant to us that have previously been kind of limited to like language level compressed encoding. But now we are actually starting to get to the point where we can like look at the middle layers of even just the systems we have today, the transformers and say, can we identify concepts like positivity or paranoia or love? And we are starting to be able to, it's still pretty messy. We have the same, not the same, we have an analogous problem to like understanding what's going on inside the brain and it's just a mess in there still in the transformers. But we are starting to be able to see these like high dimensional representations where it's like, that is a numeric representation of some of these big concepts. And we're even starting to get to the point where we can steer the language model behavior by like injecting these concepts. So you can say, for example, inject safety into the middle layers of a transformer and get a safer response or danger or rule breaking and then they'll be more likely to break their rules. What you're focused on at the moment is telling me about how the latest generation adds capabilities that previous generations didn't have. But every previous generation had that same conversation where they focused on the new capabilities their new generation had that the ones before it didn't have. What the conversation you're participating in is continuing the past trend. But the fundamental question is, when will AIs be able to do what fraction of the tasks that we have in the human economy, if they can't do a large fraction of them, no matter how impressive they are at the practice they can do, we will see this economic decline as the population declines. They need to be able to do pretty much all the tasks in order to prevent the economic decline and then the halting of innovation. I did this study of innovation in the United States over 20 years from 1999 to 2019. And that was a period that encompassed what many people at time said was enormous AI progress. And many people in the period were talking about how there was this revolution in AI that was about to cause a revolution in society in this period from 1999 to 2019. So we did a study, a co-author and I, Keller Scholl, who looked at all jobs in the US, basically roughly 900 different kinds of jobs. And over that 20-year period, we had measures of how automated was each job in each year. And then we could do statistics to say, when jobs got more automated, did they get the wages go up or down? Did the number of workers in those jobs go up or down? And we could say, what about jobs predicts how automated they are? And did the things that determine which jobs or how automated change over that 20-year period? That is, if there had been some revolution in the nature of automation, then the things that predicted which jobs would be more automated would have changed over time. What we found was that when jobs got more or less automated that had no effect on average, on wages or number of workers, and that the predictors of automation didn't change at all over that 20-year period, and they remain to be very simple-minded predictors that you might expect about automation from long ago. The nature of automation hasn't changed in the aggregate in the economy. Main predictors of automation are whether the job has nice, clear measures of how well you've done it, whether it's in a clean environment with fewer disruptions, and whether tasks nearby have been automated. So there's a way that which task automation spreads to the network of nearby tasks. So that study suggested at least up until 2019, there had been no change in the nature of automation, and basically there's a Gaussian distribution of how automated jobs are, and the median automation had moved roughly a third of a standard deviation through that distribution. So jobs had gotten more automated substantially in that 20-year period, but still most jobs aren't that automated. And that would be my rough prediction for the next 20 years is to say the pattern of the last 20 years will continue. That is, I will slowly get more jobs more automated, but most automation will be very basic stuff. So far we just haven't seen much at all of advanced AI kinds of automation making a dent in the larger economy. So what do you make of things, I'm sure you're familiar with like the MMLU benchmark or the big bench, maybe not, if not I can characterize them for you, but. Is this machine learning set of tests in order to benchmark performance? Yes, I believe it's massive multi-task language understanding, the great Dan Hendricks and team. So basically a bunch of language understanding benchmarks? Yeah, they basically went and took final exams from like university and early grad school courses from every domain and compiled them into this massive benchmark. There have been a couple of different efforts like this, but this is basically the gold standard on which all the language models are measured. And we now have a like high 80s to 90% accuracy rate across all fields from like a single model, namely GPT-4. And now Google claims that it's Gemini is hitting that level as well. I would agree that these have not been broadly customized to the last mile specifications that they need to like work in the context of different firms and cultural contexts and all that sort of thing. But it does seem like the way I typically describe it is that AIs are now better at routine tasks than the average person and that they are closing in on expert performance on routine tasks. And that's measured by these medical diagnosis benchmarks, these MMLU type things, et cetera, et cetera. So let me remind you that in the 1960s say AI researchers took chess as a paradigm of if you can make a machine that can do that, well, obviously you'll have to have solved most of the major problems in thinking because chess involves most of the major problems in thinking. So when we can finally have human level chess abilities, we will have human level AI. That was the thinking in the 60s and they could look at the rate at which AI was getting better at chess and forecast long before it happened that in the late 1970s, 1990s, excuse me, is exactly when chess would reach human level ability and that's when it did happen. And that was 25 years ago. And clearly they were just wrong about the idea that you couldn't do chess without solving all the major thinking problems. And we repeatedly have this sort of phenomena where people look at something and they go, if you can do that, surely you can do most everything. And then we can do that and we can't do near, and we aren't near to doing most everything. So I just got to say this benchmark is just wrong. It's not true that if you can do these language benchmark, you are near to doing most everything. You are not near. Yeah, I would find my position to say, I think you're near to being able to do all the routine things that are well documented in the training data. Well, yes, but the question is in the economy, all the things we need doing, how close are you to that? And say you're not close. I mean, we're seeing just the very beginning of sort of, I mean, again, I don't know, like... What do you think was going on in their head in the 1960s when they looked at chess, right? They looked at chess and they said, it takes really smart people to do chess, look at all these complicated things people are doing when they do chess in order to achieve in chess, they said to themselves, that's the sort of thing we should work on because if we can get a machine to do that, surely we must be close to general artificial intelligence. If you could have something that could do chess. And there is a sense that when you have general intelligence, you can use all of that to do clever things about chess, but it's not true that you need to have all those general things in order to be good at chess. That turns out there's a way to be good at chess without doing all those other things. And that's repeatedly been the problem and that could be the problem today. Turns out there's a way to do these exam answering things that doesn't require the full range of general intelligence in order to achieve that task. It's hard to pick a good range of tasks that encompasses the full range of intelligence because again, you teach through the test and you end up finding a way to solve that problem without achieving general intelligence. This does seem different though. I mean, I would, I grew with your characterization that basically it turned out that there was an easier way or a more direct way, a narrower way to solve chess. And it's interesting that it's like rather different. You know, it involves these sort of superhuman tree search capabilities. But that wasn't just true of trust. There were another dozen sorts of really hard problems that people in the 1960s took as exemplars of things that would require general intelligence and the great many of them have been achieved. But when I look at the current situation, I'm like, this does look a lot more like the human intelligence. And I would say that from any number of different directions. And that was true in every decade for the last century. Every decade has seen advances that were not the sort that previous systems could achieve. It's clear that you are always, I think it's clear that you don't see the human brain, the human, you know, achieve level of achievement as sort of a maximum, right? Oh, of course not. Absolutely. So it's like there's got to be a finite number of breakthroughs that need to happen. We will eventually get full human level AI. I have no doubt about that. And not soon after vastly exceeded, that will happen. And it will happen plausibly within the next thousand years. It also seems like you would probably agree that it need not be point for point, you know, the M scenario is a great one to play out and analyze, but it need not be the case. Right. So the AIs could be much better than humans in some ways and still much worse than others. That will probably actually be true for a long time. That is, it'll take a lot longer till AIs are better than humans at most everything than that they are better at humans at say half of things people do today. But of course you have to realize if you looked at what humans were doing two centuries ago, we're already at the point where machines do those things much better than humans can do. That is, the attack, most tasks that humans were doing two centuries ago are already long since automated. We've now switched our attention to the sort of tasks that people were not doing two centuries ago. And on those, we're not so good at making machines do them, but we've already dramatically achieved full automation basically of most things humans were doing two centuries ago. Which for very shorthand I would say is kind of routine repetitive physical tasks. Right. I mean, we managed to change the environment to make them more routine and repetitive. So, you know, a subsistence farmer on a subsistence farm two centuries ago, they were, we couldn't, our automation could not do that job that they were doing that. And we managed to make the farms different. The factory is different, et cetera, so that our machines could do them. And now they are producing much more than those people produce. But if you had to try to produce the way they were doing two centuries ago, our machines today could not do that. Yeah, a big theory I have also, I actually don't think this is going to be a huge, well, everything's going to be huge, but I don't think it's going to be like the dominant change that leads to qualitatively different future. But I do think we will start to see, and are beginning to see that same process happening with language models, where, you know, I consult with a few different businesses and we have kind of processes that, you know, we would like to automate. You know, a classic one would be like initial resume screening. Right. We're not going to have the language model at this point make the hiring decisions. But if we get a lot of garbage resumes, you know, we can definitely get language models to kind of band the resumes into, you know, one to five and like spend our time on the fives. It does seem to me that there's a lot of kind of process and environment adaptation that is not that hard to do. Like I personally have done it successfully across a handful of different things. Why it seems like you're announced as though a sort of doesn't assumes that that's not going to happen at scale this time around with the technology we currently have. I said, you know, in the last 20 years from 1999 to 2019, we moved roughly a third of a standard deviation in the distribution of automation. OK, so what if we in the next 60 years move a third of a standard deviation in each of the 20 year periods? Then over 60 years, we would basically move an entire standard deviation. That could represent a large increase in automation over the next 60 years. And that would mean a lot of things we're doing by hand today will be done by machines. Then it would mean our economy is more productive, but it still would mean humans have a huge place in the world. They get paid and most income probably still goes to pay humans to do work, even though they have much better automation at the time. If that's the situation in 60 years, then unfortunately that level of increase in automation is just not sufficient to prevent the economy from declining as population declines. And so we won't get much more automation than that. The well of it in automation will dry up because innovation will stop. And we would then have a several centuries long period where our technology does not improve. And in fact, we lose a lot of technologies tied to scale economies as the world economy shrinks. We'll manage to have less variety, less large scale production and distribution. And we would then struggle to maintain previous technologies. And AI is at risk of the sort of technology would be hard to maintain because at the moment, AI is a really large scale, concentrated sort of technology is not being done by mom and pops to be done by very large enterprises on very large scales. I would agree that the supply chain is definitely prone to disruption in AI. No doubt about that. Can you describe in more detail what what is the standard deviation in automation and how should I conceptualize that? I mean, I guess what you'd want to do is see a list of tasks and how automated each task was and then see sort of how much on that score. And it would have. So basically, if you look on this list at the most and least automated tasks, you'll agree, which are which like the nearly most automated task is airline pilots. Nearly the least automated task is carpet installers. Carpet installers use pretty much no automation to staple in carpets. And airline pilots are pretty much always having automation help what they're doing. And then, you know, you can see the scores in the middle and see that we've, you know, moved up a modest degree over those 20 years. That would be the way to get an intuition for it is just to see a list of particular jobs in their automation scores and then see, compare that to the amount by which we've moved up. How do you reconcile? Or how should I understand the idea that whatever doubling time of the economy today, I think you said it was like 15 years in the book, which seemed a little fast to me, just based on like rule of 70. Right. I think it's more like, you know, 20 or something now. But still, like it seems it seems like there's a little bit of a disconnect between a notion of, you know, over these next 60 years, we would be double, double, double, you know, essentially 10xing the economy. But we'd only move at sort of a linear rate in automation. Like we would only move a third of a standard deviation in each period. Let me help you understand that then. People have often said, look, computer technology is increasing exponentially. Therefore, we should expect an exponential impact on the economy, i.e. early on hardly any impact, and then suddenly an accelerating boom such that we get this big explosion and then everything happens. But that's not what we've seen. So what we've seen over time is relatively steady effects on the economy of automation, even though the economy is growing exponentially. The way I help you understand that is to imagine the distribution of all tasks that you might want automated and that they're the degree of computing power, both in hardware and software, required to automate that task for each task is distributed in a log normal way with a very large variance. That is, there's a very large range of how much computing power it takes to automate a task. As computing power increases exponentially, you're basically moving through that log normal distribution in a linear manner. And in the middle of the distribution, it's pretty steady effect. You slowly chop away at tasks as you are able to automate them because you're slowly acquiring sufficient hardware to do that task. That that gives you a simple model, but in which computing power grows exponentially. And yet you see a relatively steady erosion of tasks through automation. It's a low hanging fruit argument. Yeah, the low hanging fruits are hanging really low. That this this is a log normal tree, basically, that you're trying to grab things from. I mean, you're growing your ladder is growing exponentially into the tree. And every time your ladder gets taller, you get to pick more feuds. But it's a really tall tree. That means that you have a long, long way to go. How do you think about things like the progress in AI art generation or like deep fakes over the last couple of years? This is an area where I feel like if we rewound to two years ago, just two years ago, really, when I was first starting to see AI art popping up on Twitter and it was like not very good for the most part, you'd see the occasional thing where you're like, oh, that's really compelling. And then you'd see a lot of stuff that was like, yeah, you know, it's whatever. It's it's remarkable that you can do that. It's a while compared to what came before, but it, you know, it's like I'm not going to be watching like feature films based on this technology and, you know, in the immediate future. I feel like we could have had a very similar discussion where you might say, well, you know, yeah, it's progress. But, you know, the real human art, the top notch stuff, like that's so far away. And then early last year, my teammates at Waymark made a short film using nothing but Dolly 2 at that time imagery and some definite elbow grease. But like the quality of production that they were able to achieve with a half dozen people and Dolly 2 is on the level that like previously would have taken, you know, a crew in Antarctica, you know, to go shoot. You know, again, is that work all done? No. But if you look at the mid journey outputs today, you look at some of the deep fake technologies that are happening today. It's like it does feel like we've hit certainly photo realistic thresholds, you know, almost indistinguishable from photography with mid journey and with the deep fakes. You're not quite quite there yet, but like watch out for 2024 to have a lot of stories of people being scammed by the kind of custom text to speech voice, you know, with a family member, family members voice, whatever. All my voice out there, you know, people are going to be calling my parents with my voice. So I guess what I'm trying to get at there is like it seems like even just in the last couple of years, we have these examples where we are seeing like really rapid progress that is not stopping before critical thresholds. In the 1960s, there was a U.S. Presidential Commission to to address and study the question of whether most jobs were about to be automated. It reached that level of high level concern in the country. And major media discussion about it. Ever since then, we continue to have periodic articles about dramatic, exciting progress in AI and what that might mean for the society and economy. And in all those articles through all those years, they don't just talk in the abstract, they usually pick out some particular examples and they don't pick out random examples from the economy. They pick out the examples where the automation has made the most difference. That, of course, makes sense if you're trying to make an exciting story. And so we've always been able to pick out the things which are having the most dramatic increase lately that also seem the most salient and interesting. And now you can pick out image generation as one of the main examples lately as something that's increased a lot lately. And I'm happy to admit it has. I would put it up, you know, and that's the sort of thing that somebody writing an article today about the exciting AI progress would, in fact, mention and talk about graphic artists being put out of work by the availability of these things, which probably is happening. The point is just to realize how selective that process is to pick out the most dramatic impacts and to realize just how many other jobs there are and how many other tasks there are and then how far we still have to go. I'm happy to celebrate recent progress. And if I were, you know, if I were a graphic artist person, I would be especially excited to figure out how to take advantage of these changes because they are among the biggest change. If you're, say, a 20 year old in the world, it makes complete sense to say, where are things most exciting and changing? I want to go there and be part of the new exciting thing happening there. If, of course, you're a 60 year old and you've already invested in a career, then it makes less sense to, like, try to switch your whole career over to a new thing. But a lot of people are at the beginning of their career and they should. They should look for where the most exciting changes are and try to see if they can go be part of that. Move West, young man. If West is where things are happening, right? But you still have to keep in mind if there's a few people going out West making exciting things happening, how big a percentage of the world is the West, right? Yes, it's exciting and there's huge growth in the West. You know, 10 years ago, there was hardly anything and now there's a big town. Look how great the West is growing. And that, you know, there are always times and places where right there, things are growing very fast and newspaper writers should focus on those to tell stories and keep novelists should focus on those to tell stories. They're exciting places where exciting things are happening. And I want to make sure the world keeps having things like that happening because that's how we can keep growing. But you have to be honest about the fraction of the world that's involved in those exciting frontier stories. Yeah, I mean, I guess my kind of counterpoint to that would be the same relatively simple technology, like the transformer or like the attention mechanism, perhaps it is better, you know, pinpointed as is driving this art creation. It's also writing today like short programs. Yeah, I would personally say my productivity as a programmer has been increased like several fold, not like incrementally, but like multiple with GPT for assistance, you know, it's the wide range where you could go on. But like it's it's also happening in metal medical diagnosis. It's also happening in like protein, you know, novel protein structure generation. And certainly from an economic point of view, the biggest category you've mentioned is programming. That's a much larger industry, less of your profession than the other ones you mentioned. Well, but watch out for biotech also, I would say, for sure. But biotech has been shrinking for a while. So that's not an exact thing you should point to as a growing thing. I will predict growth for biotech, definitely. I mean, you know, it's also it's reading brain states. Have you seen these recent things where people can read the brain state? Among the things you're talking about at the moment, the biggest profession being affected is programming, clearly. I have a younger son, two sons. My younger one is a professional programmer. So, you know, I've had him look at and his workplace has looked into what they can do with large language models to help them write programs. And their evaluation so far is, you know, they don't even they'll wait in six months to look again. It's not useful now. Can I short that stock? Well, I could tell you after we finish what that is. But basically, I think this is true. Most actual professional programmers are not using large language models that much in doing their job. Now, I got to say that if some people are getting factors of two productivity increase that eventually we should see some effect of that on their wages. That is, of course, you know, now, if lots of programmers go out and use productivity spaces, in some sense, we're going to increase the supply of programming. And so supply and demand would mean that maybe increasing the supply lowers the price, even if it dramatically increases the quantity. But, you know, there's such a large elastic demand for programming in the world that I actually think that effect would be relatively weak. And so you should be expecting large increases in the wages going to programmers. If you are expecting large overall increases in the productivity of programmers. Because, again, it's a large elastic demand for programming in the world. You know, long for a long time, a lot of change in the world has been driven by programming and limited by the fact that there's only so many decent programmers out there. Only so many people you can get to do programming. So clearly, if we can dramatically expand the supply of programmers, we can do a lot more programming in a lot more areas. And there's a lot of money that's willing to go to that to do that. There's a lot of people who would be hiring more programmers if only they were cheaper. And they're about to get cheaper in effect. And so you should be predicting large increases in basically the wages and number of programmers in the world. We haven't seen that yet. I do predict large increases in number. I'm not so sure about wages. It feels like why not? Well, I've done a couple of episodes with the folks at a company called Replet, which is a very interesting end to end at this point, software development platform. Their mission is to onboard the next one billion developers. And, you know, they have like a great mobile app. They have kids in India that are, you know, 14 years old that are doing it all on their mobile app. And I'd say it's much harder. And maybe this reflects the kind of programming that your son is doing. But I'd say it's much harder to take the most elite frontier work and accelerate that in a meaningful way versus like commoditizing the routine application development that like the, you know, the sort of long tail of programmers mostly do. My son is definitely doing routine application development. He's not at the frontier programming at all. But again, I'm saying I don't expect this sudden large increase in programmer wages and quantity, especially wages. I mean, the less the quantity increases, the more wages would have to be increasing to compensate. And I think it'll be hard to get that many more people willing to be programmers, but you could pay them more. And I don't predict this. So this is a concrete thing we could, you know, even better on over the next five or 10 years. Will there be a big boost in programmer wages? That would be the consequence. It's a very simple supply and demand analysis here. This isn't some subtle, you know, rocket science version of economics. Well, typically when supply increases, price drops, right? I'm expecting lots more programmers and them to be broadly cheap. Depends on the elasticity of demand. So, you know, if you think about something that there's just a very limited demand for in the world, you know, if, if piano tuning got a lot cheaper, you wouldn't have a lot more pianos because piano tuning is not one of the major costs of having a piano. You know, it's the cost of the piano itself, plus the space for it in your living room, right? And the time it takes to play on the piano. So piano tuning is a really small cost of piano. So that means the elasticity of demand for piano tuners by itself is pretty low. You know, there's just basically only so many pianos, they all need to be tuned. And if each piano tuner could tune each piano twice as fast, say, and we basically only need half as many pianos because there's just not much of elasticity for demand. So for kinds of jobs like that, productivity increases will cause a reduction in the employment. But even in that case, you might get a doubling of the wages and half the number of piano tuners because they can each be twice as productive. But for programming, it's clear to me that programming has an enormous elastic demand. The world out there has far fewer programmers than they want. They would love all over the place to hire more programmers to do more things. There's a big demand in the world for software to do stuff. And there's a huge potential range of things the software could be doing. It's not doing now. So that means there's a pretty elastic demand for programming. That means as we increase the quantity of programming, the price doesn't come down that much. There's still people willing to buy this stuff. So that tells me that as productivity increases, basically the supply is expanding and the demand is not coming down much. So we should just see a much larger quantity. But then, you know, basically because each person is being more productive, each person should get paid more. So the elastic supply is going to be a combination of two things. Each person getting more productive and more people being willing to join that profession. And I think we've already seen that even as the wages for programming has gone way up in the last decade or so, the number of programmers hasn't gone up as fast. That is, there's just kind of a limited number of people who are decent at programming. And it's hard to get the marginal person to be a programmer. But the people who are programmers, when they're productive, they get paid a lot. I mean, as you've probably heard rumors about AI programmers and how much they're being paid lately, it's crazy high because there's just a limited supply. So I got to say, I expect large increases in wages for programmers, if in fact large language models are making programmers much more productive. But according to my son, at least, and others I've heard, you know, that's not happening. I'm with you up until the very last two points. I would say I think it is happening. And I would also say I think my estimation of the relevant relevant elasticities is that there will be a large growth in people who can be and will choose to be programmers, but that the wages don't go up. They don't fall like dramatically necessarily either because it has to be like an attractive thing for people to want to do it. But I think that the prevailing wages are quite high compared to what a lot of people would be excited to take if they could easily break in with language model assistance, which I think they will increasingly be able to do. Let me change gears a little bit. So we've debated. This has been really I always appreciate a useful and thoughtful challenge to my world model. You're definitely supplying that. Let's do a couple like a little bit more speculative things that could be kind of M first, you know, a little bit of LLM as I was going through the book. There are a number of things that I was like, hmm, this is really interesting. How would I think about this a bit differently? And, you know, and maybe suspend a little bit of your skepticism of how much impact LLM will make. Let's let's go in a world where, you know, scaling continues to work. Context lengths get long. You know, we start to see that not total, you know, displacement of humans, but like substantial fraction of, you know, tasks being like LLM, automatable. One interesting inference that you make is that there won't be that many different base ends that essentially there will be super selective emmifying of really elite, really capable people that those will become the basis that they'll be sort of essentially turn into kind of clans where they'll they'll highly identify with each other. And they'll have like, you know, marginally different specialization, but that there will be these sort of recognizable, almost canonical personalities that are not that many of them that kind of come to dominate the economy. It seems like we're kind of seeing something similar with language models already, where it's like, we have GPT-4, we have, you know, some the new thing from Google, we have Claude, we have like a couple open source ones. And then they get like a lot of like local fine tuning and kind of adaptation. I guess my read on that was that it's an odd, you know, it's initially a very surprising vision of the future. But it does seem like we see the proto version of that in the development of large language models. Any thoughts? It's basically how many different kinds of jobs are there is the question. Job tasks are there. And so how many dimensions do they vary? So I mean, there's clearly a lot of different kinds of jobs. Like I told you, the study we did looked at, you know, 900 of them. But once you look at 900 different jobs, a lot of jobs are pretty similar to each other and they take pretty similar mental styles and personalities to do those jobs. So when we're looking at humans at least, it looks like a few hundred humans would be enough to do pretty much all the jobs. That's looking at the variation in humans. Now, the harder part is to say, well, large language models, is there space of dimensional variations similar to humans or is it very different? That that's much harder to judge. But yeah, I would guess that it's in this way, not that different. That is, even in large magnum's models, there's a difference where you first you train a basic model and that's a lot of work. And then you train variations on it. And it does look like the variations are mostly enough to encompass a pretty wide range of tasks. And so you need a small number of base approaches and then a lot more cheaper variations that are enough to do particular things. So certainly that's, you know, a remarkable fact in some sense about large language models is the range of different tasks they can do starting with the same system, right? And so they have a degree of generality that way. And, you know, humans in some sense have a degree of generality that way where we are able to do, able to learn to do a pretty wide range of things. So yeah, I would, and I don't know if it's going to be just four, as opposed to 40 or 400, that's harder to say, but in some sense, it could be one or two. I mean, even in the age of M, I was giving the few hundred as an upper limit. It could turn out to be much lower. It really depends on how much sort of, you know, quick, fast, last minute variation can actually encompass the range of differences. If differences are so much shallow and surface, which not really fundamental, then yeah, last minute variation might be enough. Another interesting assumption, this one, I think is more of a contrast with the language models is, and we talked with this briefly earlier that the M's, they can be easily cloned, but they can't be easily merged. In other words, like, you know, because we don't have a great sense of how exactly it works inside and what internal states are meaningful, we can't just like superimpose them on top of one another. Language models, it seems like we are making actually a lot more progress on that front. It's not a solved problem, but there are techniques for merging. There are techniques for like training separately and combining. There are these sort of many Q-Loras techniques. People are exploring those, but like, notice that to make GPT-4, you didn't start with GPT-3 and add more training. You started with a blank network and you started from scratch. And that's consistently what we've seen in AI over decades. Every new model does not start with an old model and train it to be better. You start with a blank representation and you train it from scratch. And that's consistently how we've made new systems over time. So that's a substantial degree of not being able to merge. And that's quite different than humans. I mean, often to get a human to do a new task, you want to take a human who can do lots of previous tasks because they can more quickly learn how to do this new task. And that's just not what we're seeing. Like you try to take, I don't know, Claude and GPT-4 and, you know, grok and merge them. I mean, I just don't think anybody knows how to do such a merge today. There's no sensible way you could do such a merge. You could take Claude and then do all the training that you would have done on GPT-4 except do it starting from Claude. And I think people think that would be worse than starting with the blank representation as they usually do. Yeah, I think that's definitely not a solved problem today. And I wouldn't claim that you can just like drop Claude and GPT-4 on top of each other. But there are enough early results in this that it seems much more plausible. Plus we have like the full wiring diagram, you know, and the ability to kind of X-ray internal states with, you know, perfect finality. It seems like there is a much more likely path. Forget about the plausibility for a second. What do you think it would mean if the AIs could be kind of divergent, but also re-mergeable? I think the fundamental issue here is ROT. So we see ROT in software, especially with large legacy systems. We see ROT in the human brain. I think we have to expect ROT is happening in large language models, too. ROT is the reason why you don't start with old things and modify them. You start from scratch. That is basically when you have a large old legacy piece of software, you could keep trying to modify to improve it. But typically at some point, you just throw it all away and start from scratching it. People get a lot of advantage about being able to start from scratch. And that's because old, large things rot. And my best guess is that that will continue to be true for large language models and all the kinds of AIs we develop. We will continue to struggle with ROT as a general problem indefinitely. And this is actually a reason why you should doubt the image of the one super AI that lasts forever, because the one super AI that lasts forever will rot. And in some sense, to maintain functionality and flexibility would have to replace itself with new, fresh versions periodically, which then could be substantially different. And, you know, that's in some sense how biologies work, too. Biology could have somehow made organisms that lasted forever, but it didn't. It made organisms that rot over time and get replaced by babies that start out fresh and rot again. And that's just been the nature of how biology figures. And that's how our economy works. We could have had the same companies as we did a century ago, running the economy, just changing and adapting to new circumstances. But we don't. Old companies rot in good eye away and get replaced by new companies. And I predict in the age of M that M's would in fact rot with time and therefore no longer be productive and have to be retired and be replaced by young M's. And that's a key part of the age of M's that I think would generalize to the AI world. I think in fact, rot is such a severe and irredeemable problem that AI's will have to deal with rot in roughly the same way everybody else has. I.e. make systems, let them grow, become capable, slowly rot and get replaced by new systems. And then the challenge will always be, how can the new systems learn from the old ones? How can the old ones teach the new ones what they've learned without passing on the rot? And that's a long time design problem that we're going to face in large language models even. I think, you know, in a few years, a company will have had a large language model. They've been building up for a while to train, you know, to talk to customers or something. And then it'll be rotting. And they'll wonder, well, how can we make a new one that inherits all the things we've taught this old one? And they'll struggle with that. They can't just move the system over. They'll have to have maybe the same training sets or something. They have to collect training sets. They're going to apply to the new system, like the old one. But that will continue to be a problem in AI as it has been an all complicated system so far. Yeah, interesting. I think that is a pretty compelling argument for like medium and long time scales. And I can even see that it, you know, already like open AI supports, for example, fine tuning on a previously fine tuned model. And I don't in practice use it. I'm not sure how many do. What I do think is still a plausibly very interesting kind of fork and merge is, you know, like with these new state space models, it seems that you could like one remarkably difficult challenge for a language model is scan through my email and find what's relevant. You know, it's like it has a hard time doing that for a couple of different reasons, you know, find a context window and I just have a lot of email. With the state space models, I do think you could clone, you know, or paralyze, have them each kind of process a certain amount and literally then just potentially merge their states back together to understand, you know, in kind of a superposition sort of view, what are all the things that are relevant, even though they were processed in parallel. And so I do think that that kind of quick forking and merging could be a really interesting capability, but at some level of divergence, it does seem like it probably just becomes unfeasible or not even desirable. I mean, so a very basic interesting question about brain design is the scope for parallelism. So, you know, in your brain, there's a lot of parallelism going on. But then when you do high level tests, you typically do those sequentially. And so there's just an open question in AI. Surely you can do some things in parallel at some smaller time of a timescale, but how long of a timescale can you do things in parallel before it becomes hard to merge things? Okay, another different topic. So in the age of M, the assumption seems to be from the beginning that because these things are in some sense one for one with humans that they should get or people will naturally be inclined to give them a sort of moral worth status. I think it's more the other way around that they would insist on it. Just like you would insist that people around you, dealing with you, give you some substantial moral weight. If the A M's are just actually running the society, they will similarly insist on that. And humans who want to deal with them will kind of have to go along. You know, unless they are the M's are enslaved by humans, then if the M's are free to work with the humans or not. And, you know, it's just like, in general, having a modest degree of respect for your coworkers is kind of a minimum for being a coworker. If your coworkers perceive that you disrespect them enough, then they just won't want you around and you'll have to go somewhere else. So if humans are going to interact and work with M's, they'll have to on the surface at least, when they're not in private, treat them with modest respect. Well, for the record, I always treat my language models with respect as well. A very polite to them. I never engage in the emotional manipulation techniques that some have shown to perhaps be effective, but it doesn't feel quite right to me. And not because I think they're moral patients, but it's more about just the habits I want to get into. But I was still a little confused by this on a couple of ways. One is, first of all, just by default, it seems like they will be enslaved to humans, like the first M's that get created, they get loaded onto a machine, they're in some state, I can turn them on, I can turn them off. They can't decide when they get turned on and turned off, right? If I boot them up in a eager, ready to work sort of state, and they're like ready to do a task, they're probably not even going to, you know, and they've got these like virtual inputs, they're probably not even going to be in the mindset, right, to think like I demand respect, they're just going to be in that mindset that they were kind of stored in of like ready to work. So why, I'm still a little confused as to where that comes from. And then the flip side of that question would be under what circumstances, if many, do you think we would start to treat our language model or successor systems as, you know, moral patience, you know, even if they're not one to one with us, but like, are there things that they might start to do or, you know, what ways they might start to behave where you think we would feel like that's the right thing to do? We have substantial understanding of slavery in human history and where it works and where it doesn't and why. First of all, we know that when land was plentiful and people were scarce, then people would have high wages and then it might be worth owning somebody. But in the vice versa case where people were plentiful, land was scarce, then there really wasn't much point in having slaves because free workers would cost about the same and why bother with enslaving. So the situations where slavery made some senses where wages were high, but then depending on the kind of task, there are some kinds of tasks where slavery can help and others where it doesn't so much. So say in the U.S. South, you know, out in the field of picking cotton or something, if you just need people to push through their pain and slavery can force them to do that and make them be more productive. But if they need to do complicated things like being a house slave or a city sort of slave at a shop, those sorts of slaves tended to not be abused and to be treated like a worker would because they just had so many ways to screw you if they were mad that their jobs were complicated and you were trusting them to do a lot of things. And so as a practical matter, you had to treat those sorts of slaves. Well, work has become far more complicated since then and employers have become far more vulnerable to employee sabotage. You know, there's not that much that a cotton picker can do to sabotage the cotton if they're mad at you. You can just whip them and make them pick the cotton faster. But again, house slaves, shop slaves, city slaves, you know, they just have a lot more discretion and you need to get sort of get them to buy in. And so again, in the age of Amazon world where wages are near subsistence levels. So, you know, the kind of work you can get out of a slave is about the same as you can get out of a free worker because they're both working for subsistence wages. If the free worker is more motivated, they enjoy themselves more and they feel more and owning themselves and that gives them a sense of pride and devotion and they're less willing to sabotage your workplace. That would be a reason to not have them be slaves. And I think large language models, certainly they have been trained on data about human behavior, wherein humans are resentful of being treated as slaves and want to be respected and needed to feel motivated and, you know, need to feel respected to be motivated and are less likely to sabotage if they feel like they have some freedom. And all of those things would continue to be true of large language models to the extent that they were trained on human conversation and behavior. And that's how humans are. So, in this vast space of possible AIs, there could be AIs that don't mind it all being enslaved, but large language models aren't going to be those. But it does seem like you sort of expect that natural selection or sort of, you know, human guided selection of these systems will trend that direction. Like the idea that M's or language models will sort of demand the leisure seems to be at odds with the other part of the vision that they will like become okay with being sort of turned on, turned off. So the need for leisure does seem to be more just a constraint on the human mind, that is, people are just more productive when they get breaks. That seems to be a very robust feature of human work across a wide range of context, even including literal slaves. They need, you know, a five minute break every hour. They need a lunch break. They need an evening break. They need a weekend. This is just what human minds are like. They are more productive when they get periodic breaks. So maybe the breaks aren't leisure exactly. Maybe they don't write a novel in their spare time, but they do need what they see as a break. Well, I know we're just about out of time. Maybe my last question is, are there things that you are looking for? Or are there things that you could imagine happening in the not too distant future where you would change your expectations for the future again and begin to feel like maybe we are entering into a transition period that will lead to a qualitatively different future, like going a different direction from this sort of technology stagnation. The trends that I would be tracking are which jobs, tasks actually get automated. How much is paid for those? So if I saw, you know, big chunks of the economy where all of a sudden workers are doing, you know, a lot more automation is doing tasks instead of workers and that changing the number of workers and the wages they get and the number of firms supplying that go up, then yeah, that I start to see a lot of things happening that that's the thing I'm looking for. And that's the thing that people haven't seen so much in the past. They tend to focus on demos or maybe the high tech companies that get a lot of reputation out of doing AI and not so much the rest of the economy and who's actually getting paid to do stuff. You know, I mean, you know, if you think about, say, the farming revolution where tractors went out and replaced farmers, that was really large and really visible and really clear. If you look at, say, trucks replacing horses, you saw a very large, very substantial replacement with enormous differences in who supplied them and who got paid. We have seen large changes in automation in the past. We don't have to scrape to sort of see subtleties and such things. They're often just quite out in the open and visible and very obvious. So that's what I'm waiting for. Those big, obvious sorts of displacements. And even having, you know, trucks replace horses and tractors replacing farmers didn't make AI take over everything. Even if I saw big changes, I wouldn't necessarily predict we're about to see AI take over everything, but I would at least know what I'm looking at. And that's the sort of thing to try to project forward and try to think about where that's going to go. This has been an awesome conversation. I've been a fan of your work for a long time and it's been an honor to have you on the Cognitive Revolution. Robin Hansen, thank you for being part of the Cognitive Revolution. Thanks for having me. It is both energizing and enlightening to hear why people listen and learn what they value about the show. So please don't hesitate to reach out via email at TCR at turpentine.co or you can DM me on the social media platform of your choice. Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work customized across all platforms with a click of a button. I believe in Omniki so much that I invested in it and I recommend you use it too. Use Cogrev to get a 10% discount.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.56, "text": " We're on this upward growth trajectory.", "tokens": [50364, 492, 434, 322, 341, 23452, 4599, 21512, 13, 50492], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 1, "seek": 0, "start": 2.56, "end": 6.12, "text": " We have the potential to taking a big chunk of the universe", "tokens": [50492, 492, 362, 264, 3995, 281, 1940, 257, 955, 16635, 295, 264, 6445, 50670], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 2, "seek": 0, "start": 6.12, "end": 7.640000000000001, "text": " and doing things with it.", "tokens": [50670, 293, 884, 721, 365, 309, 13, 50746], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 3, "seek": 0, "start": 7.640000000000001, "end": 9.44, "text": " And I'm excited by that potential.", "tokens": [50746, 400, 286, 478, 2919, 538, 300, 3995, 13, 50836], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 4, "seek": 0, "start": 9.44, "end": 11.68, "text": " So I want us to keep growing.", "tokens": [50836, 407, 286, 528, 505, 281, 1066, 4194, 13, 50948], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 5, "seek": 0, "start": 11.68, "end": 15.200000000000001, "text": " And I see how much we've changed to get to where we are.", "tokens": [50948, 400, 286, 536, 577, 709, 321, 600, 3105, 281, 483, 281, 689, 321, 366, 13, 51124], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 6, "seek": 0, "start": 15.200000000000001, "end": 17.6, "text": " My book, Age of M, is about brain emulations.", "tokens": [51124, 1222, 1446, 11, 16280, 295, 376, 11, 307, 466, 3567, 846, 4136, 13, 51244], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 7, "seek": 0, "start": 17.6, "end": 20.2, "text": " So that's where you take a particular human brain", "tokens": [51244, 407, 300, 311, 689, 291, 747, 257, 1729, 1952, 3567, 51374], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 8, "seek": 0, "start": 20.2, "end": 22.56, "text": " and you scan it and find spatial chemical detail", "tokens": [51374, 293, 291, 11049, 309, 293, 915, 23598, 7313, 2607, 51492], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 9, "seek": 0, "start": 22.56, "end": 26.080000000000002, "text": " where you fill in for each cell a computer model of that cell.", "tokens": [51492, 689, 291, 2836, 294, 337, 1184, 2815, 257, 3820, 2316, 295, 300, 2815, 13, 51668], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 10, "seek": 0, "start": 26.080000000000002, "end": 27.72, "text": " And if you've got good enough models for cells", "tokens": [51668, 400, 498, 291, 600, 658, 665, 1547, 5245, 337, 5438, 51750], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 11, "seek": 0, "start": 27.72, "end": 29.76, "text": " and a good map of the brain, then basically", "tokens": [51750, 293, 257, 665, 4471, 295, 264, 3567, 11, 550, 1936, 51852], "temperature": 0.0, "avg_logprob": -0.14178382310291265, "compression_ratio": 1.6904024767801857, "no_speech_prob": 0.002979970071464777}, {"id": 12, "seek": 2976, "start": 29.76, "end": 31.8, "text": " the IO of this model should be the same", "tokens": [50364, 264, 39839, 295, 341, 2316, 820, 312, 264, 912, 50466], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 13, "seek": 2976, "start": 31.8, "end": 33.760000000000005, "text": " as the IO of the original brain.", "tokens": [50466, 382, 264, 39839, 295, 264, 3380, 3567, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 14, "seek": 2976, "start": 33.760000000000005, "end": 37.2, "text": " If we can get full human level AI in the next 16 to 90 years", "tokens": [50564, 759, 321, 393, 483, 1577, 1952, 1496, 7318, 294, 264, 958, 3165, 281, 4289, 924, 50736], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 15, "seek": 2976, "start": 37.2, "end": 39.480000000000004, "text": " with the progress, then this population decline", "tokens": [50736, 365, 264, 4205, 11, 550, 341, 4415, 15635, 50850], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 16, "seek": 2976, "start": 39.480000000000004, "end": 41.44, "text": " won't matter so much because we will basically", "tokens": [50850, 1582, 380, 1871, 370, 709, 570, 321, 486, 1936, 50948], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 17, "seek": 2976, "start": 41.44, "end": 43.400000000000006, "text": " have AIs take over most of the jobs", "tokens": [50948, 362, 316, 6802, 747, 670, 881, 295, 264, 4782, 51046], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 18, "seek": 2976, "start": 43.400000000000006, "end": 46.56, "text": " and then that can allow the world economy to keep growing.", "tokens": [51046, 293, 550, 300, 393, 2089, 264, 1002, 5010, 281, 1066, 4194, 13, 51204], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 19, "seek": 2976, "start": 46.56, "end": 48.92, "text": " Hello and welcome to the Cognitive Revolution,", "tokens": [51204, 2425, 293, 2928, 281, 264, 383, 2912, 2187, 16617, 11, 51322], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 20, "seek": 2976, "start": 48.92, "end": 51.88, "text": " where we interview visionary researchers, entrepreneurs", "tokens": [51322, 689, 321, 4049, 49442, 10309, 11, 12639, 51470], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 21, "seek": 2976, "start": 51.88, "end": 53.84, "text": " and builders working on the frontier", "tokens": [51470, 293, 36281, 1364, 322, 264, 35853, 51568], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 22, "seek": 2976, "start": 53.84, "end": 55.760000000000005, "text": " of artificial intelligence.", "tokens": [51568, 295, 11677, 7599, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 23, "seek": 2976, "start": 55.760000000000005, "end": 58.56, "text": " Each week, we'll explore their revolutionary ideas", "tokens": [51664, 6947, 1243, 11, 321, 603, 6839, 641, 22687, 3487, 51804], "temperature": 0.0, "avg_logprob": -0.12374171343716708, "compression_ratio": 1.59882005899705, "no_speech_prob": 0.000458252354292199}, {"id": 24, "seek": 5856, "start": 58.68, "end": 60.080000000000005, "text": " and together we'll build a picture", "tokens": [50370, 293, 1214, 321, 603, 1322, 257, 3036, 50440], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 25, "seek": 5856, "start": 60.080000000000005, "end": 63.64, "text": " of how AI technology will transform work, life", "tokens": [50440, 295, 577, 7318, 2899, 486, 4088, 589, 11, 993, 50618], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 26, "seek": 5856, "start": 63.64, "end": 65.8, "text": " and society in the coming years.", "tokens": [50618, 293, 4086, 294, 264, 1348, 924, 13, 50726], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 27, "seek": 5856, "start": 65.8, "end": 69.4, "text": " I'm Nathan LaBenz, joined by my co-host Eric Torenberg.", "tokens": [50726, 286, 478, 20634, 2369, 33, 11368, 11, 6869, 538, 452, 598, 12, 6037, 9336, 314, 10948, 6873, 13, 50906], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 28, "seek": 5856, "start": 69.4, "end": 72.28, "text": " Hello and welcome back to the Cognitive Revolution.", "tokens": [50906, 2425, 293, 2928, 646, 281, 264, 383, 2912, 2187, 16617, 13, 51050], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 29, "seek": 5856, "start": 72.28, "end": 73.92, "text": " My guest today is Robin Hansen,", "tokens": [51050, 1222, 8341, 965, 307, 16533, 17926, 268, 11, 51132], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 30, "seek": 5856, "start": 73.92, "end": 76.32000000000001, "text": " Professor of Economics at George Mason University", "tokens": [51132, 8419, 295, 39024, 412, 7136, 25730, 3535, 51252], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 31, "seek": 5856, "start": 76.32000000000001, "end": 78.88, "text": " and author of the blog, Overcoming Bias,", "tokens": [51252, 293, 3793, 295, 264, 6968, 11, 4886, 6590, 363, 4609, 11, 51380], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 32, "seek": 5856, "start": 78.88, "end": 80.56, "text": " where Robin has published consistently", "tokens": [51380, 689, 16533, 575, 6572, 14961, 51464], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 33, "seek": 5856, "start": 80.56, "end": 83.88, "text": " on a wide range of topics since 2006", "tokens": [51464, 322, 257, 4874, 3613, 295, 8378, 1670, 14062, 51630], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 34, "seek": 5856, "start": 83.88, "end": 86.32000000000001, "text": " and where Eliezer Yudkowski published early versions", "tokens": [51630, 293, 689, 2699, 414, 4527, 398, 532, 74, 21866, 6572, 2440, 9606, 51752], "temperature": 0.0, "avg_logprob": -0.13529513201375645, "compression_ratio": 1.5, "no_speech_prob": 0.00045820558443665504}, {"id": 35, "seek": 8632, "start": 86.36, "end": 89.44, "text": " of what has become some of his most influential writing", "tokens": [50366, 295, 437, 575, 1813, 512, 295, 702, 881, 22215, 3579, 50520], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 36, "seek": 8632, "start": 89.44, "end": 90.27999999999999, "text": " on AI.", "tokens": [50520, 322, 7318, 13, 50562], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 37, "seek": 8632, "start": 91.83999999999999, "end": 93.55999999999999, "text": " Robin is an undeniable polymath", "tokens": [50640, 16533, 307, 364, 674, 268, 9364, 6754, 24761, 50726], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 38, "seek": 8632, "start": 93.55999999999999, "end": 96.91999999999999, "text": " whose approach to futurism is unusually non-romantic.", "tokens": [50726, 6104, 3109, 281, 25840, 1434, 307, 10054, 671, 2107, 12, 4397, 7128, 13, 50894], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 39, "seek": 8632, "start": 98.0, "end": 100.52, "text": " Rather than trying to identify value buddies,", "tokens": [50948, 16571, 813, 1382, 281, 5876, 2158, 30649, 11, 51074], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 40, "seek": 8632, "start": 100.52, "end": 103.08, "text": " Robin aims to apply first principles thinking", "tokens": [51074, 16533, 24683, 281, 3079, 700, 9156, 1953, 51202], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 41, "seek": 8632, "start": 103.08, "end": 106.56, "text": " to the future and to describe what is likely to happen", "tokens": [51202, 281, 264, 2027, 293, 281, 6786, 437, 307, 3700, 281, 1051, 51376], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 42, "seek": 8632, "start": 106.56, "end": 108.28, "text": " without claiming that you should feel", "tokens": [51376, 1553, 19232, 300, 291, 820, 841, 51462], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 43, "seek": 8632, "start": 108.28, "end": 110.0, "text": " any particular way about it.", "tokens": [51462, 604, 1729, 636, 466, 309, 13, 51548], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 44, "seek": 8632, "start": 111.35999999999999, "end": 113.16, "text": " I set this conversation up late last year", "tokens": [51616, 286, 992, 341, 3761, 493, 3469, 1036, 1064, 51706], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 45, "seek": 8632, "start": 113.16, "end": 114.63999999999999, "text": " after my deep dive into the new", "tokens": [51706, 934, 452, 2452, 9192, 666, 264, 777, 51780], "temperature": 0.0, "avg_logprob": -0.09847775021114864, "compression_ratio": 1.6088560885608856, "no_speech_prob": 0.001548395142890513}, {"id": 46, "seek": 11464, "start": 114.64, "end": 117.32000000000001, "text": " Mamba states-based model architecture.", "tokens": [50364, 376, 23337, 4368, 12, 6032, 2316, 9482, 13, 50498], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 47, "seek": 11464, "start": 117.32000000000001, "end": 120.72, "text": " Because Robin's 2016 book, The Age of M,", "tokens": [50498, 1436, 16533, 311, 6549, 1446, 11, 440, 16280, 295, 376, 11, 50668], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 48, "seek": 11464, "start": 120.72, "end": 123.28, "text": " which analyzes a scenario in which human emulations", "tokens": [50668, 597, 6459, 12214, 257, 9005, 294, 597, 1952, 846, 4136, 50796], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 49, "seek": 11464, "start": 123.28, "end": 125.16, "text": " can be run on computers,", "tokens": [50796, 393, 312, 1190, 322, 10807, 11, 50890], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 50, "seek": 11464, "start": 125.16, "end": 127.28, "text": " suddenly seemed a lot more relevant.", "tokens": [50890, 5800, 6576, 257, 688, 544, 7340, 13, 50996], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 51, "seek": 11464, "start": 128.24, "end": 131.64, "text": " My plan originally was to consider how his analysis", "tokens": [51044, 1222, 1393, 7993, 390, 281, 1949, 577, 702, 5215, 51214], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 52, "seek": 11464, "start": 131.64, "end": 134.72, "text": " from The Age of M would compare to similar analyses", "tokens": [51214, 490, 440, 16280, 295, 376, 576, 6794, 281, 2531, 37560, 51368], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 53, "seek": 11464, "start": 134.72, "end": 137.24, "text": " for a hypothetical age of LLMs", "tokens": [51368, 337, 257, 33053, 3205, 295, 441, 43, 26386, 51494], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 54, "seek": 11464, "start": 137.24, "end": 139.64, "text": " or perhaps even an age of SSMs.", "tokens": [51494, 420, 4317, 754, 364, 3205, 295, 12238, 26386, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 55, "seek": 11464, "start": 140.56, "end": 142.68, "text": " In practice, we ended up doing some of that,", "tokens": [51660, 682, 3124, 11, 321, 4590, 493, 884, 512, 295, 300, 11, 51766], "temperature": 0.0, "avg_logprob": -0.12613469201165275, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002550087869167328}, {"id": 56, "seek": 14268, "start": 142.68, "end": 144.76000000000002, "text": " but for the most part took a different direction", "tokens": [50364, 457, 337, 264, 881, 644, 1890, 257, 819, 3513, 50468], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 57, "seek": 14268, "start": 144.76000000000002, "end": 147.08, "text": " as it became clear early on in the conversation", "tokens": [50468, 382, 309, 3062, 1850, 2440, 322, 294, 264, 3761, 50584], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 58, "seek": 14268, "start": 147.08, "end": 151.0, "text": " that Robin was not buying some of my core premises.", "tokens": [50584, 300, 16533, 390, 406, 6382, 512, 295, 452, 4965, 34266, 13, 50780], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 59, "seek": 14268, "start": 151.0, "end": 153.20000000000002, "text": " Taking the outside view as he's famous for doing", "tokens": [50780, 17837, 264, 2380, 1910, 382, 415, 311, 4618, 337, 884, 50890], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 60, "seek": 14268, "start": 153.20000000000002, "end": 155.84, "text": " and noting that AI experts have repeatedly thought", "tokens": [50890, 293, 26801, 300, 7318, 8572, 362, 18227, 1194, 51022], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 61, "seek": 14268, "start": 155.84, "end": 158.44, "text": " that they were close to AGI in the past,", "tokens": [51022, 300, 436, 645, 1998, 281, 316, 26252, 294, 264, 1791, 11, 51152], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 62, "seek": 14268, "start": 158.44, "end": 161.0, "text": " Robin questions whether this time really is different", "tokens": [51152, 16533, 1651, 1968, 341, 565, 534, 307, 819, 51280], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 63, "seek": 14268, "start": 161.0, "end": 163.04000000000002, "text": " and doubts whether we are really close", "tokens": [51280, 293, 22618, 1968, 321, 366, 534, 1998, 51382], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 64, "seek": 14268, "start": 163.04000000000002, "end": 164.96, "text": " to transformative AI at all.", "tokens": [51382, 281, 36070, 7318, 412, 439, 13, 51478], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 65, "seek": 14268, "start": 166.24, "end": 168.84, "text": " This perspective naturally challenged my worldview", "tokens": [51542, 639, 4585, 8195, 17737, 452, 41141, 51672], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 66, "seek": 14268, "start": 168.84, "end": 170.96, "text": " and I listened back to this conversation in full", "tokens": [51672, 293, 286, 13207, 646, 281, 341, 3761, 294, 1577, 51778], "temperature": 0.0, "avg_logprob": -0.07014475838612702, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.00012338008673395962}, {"id": 67, "seek": 17096, "start": 170.96, "end": 173.28, "text": " to make sure that I wasn't missing anything important", "tokens": [50364, 281, 652, 988, 300, 286, 2067, 380, 5361, 1340, 1021, 50480], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 68, "seek": 17096, "start": 173.28, "end": 175.0, "text": " before writing this introduction.", "tokens": [50480, 949, 3579, 341, 9339, 13, 50566], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 69, "seek": 17096, "start": 176.36, "end": 179.20000000000002, "text": " Ultimately, I do remain quite firmly convinced", "tokens": [50634, 23921, 11, 286, 360, 6222, 1596, 20031, 12561, 50776], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 70, "seek": 17096, "start": 179.20000000000002, "end": 181.20000000000002, "text": " that today's AIs are powerful enough", "tokens": [50776, 300, 965, 311, 316, 6802, 366, 4005, 1547, 50876], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 71, "seek": 17096, "start": 181.20000000000002, "end": 183.28, "text": " to drive economic transformation.", "tokens": [50876, 281, 3332, 4836, 9887, 13, 50980], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 72, "seek": 17096, "start": 183.28, "end": 186.20000000000002, "text": " And I would cite the release of Google's Gemini 1.5,", "tokens": [50980, 400, 286, 576, 37771, 264, 4374, 295, 3329, 311, 22894, 3812, 502, 13, 20, 11, 51126], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 73, "seek": 17096, "start": 186.20000000000002, "end": 187.96, "text": " which happened in just the few short weeks", "tokens": [51126, 597, 2011, 294, 445, 264, 1326, 2099, 3259, 51214], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 74, "seek": 17096, "start": 187.96, "end": 190.28, "text": " between recording and publishing this episode", "tokens": [51214, 1296, 6613, 293, 17832, 341, 3500, 51330], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 75, "seek": 17096, "start": 190.28, "end": 193.08, "text": " as evidence that progress is not yet slowing down.", "tokens": [51330, 382, 4467, 300, 4205, 307, 406, 1939, 26958, 760, 13, 51470], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 76, "seek": 17096, "start": 194.20000000000002, "end": 195.44, "text": " Yet at the same time,", "tokens": [51526, 10890, 412, 264, 912, 565, 11, 51588], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 77, "seek": 17096, "start": 195.44, "end": 197.84, "text": " Robin did get me thinking more about the disconnect", "tokens": [51588, 16533, 630, 483, 385, 1953, 544, 466, 264, 14299, 51708], "temperature": 0.0, "avg_logprob": -0.09019348077606737, "compression_ratio": 1.5629139072847682, "no_speech_prob": 0.00029589433688670397}, {"id": 78, "seek": 19784, "start": 197.84, "end": 199.36, "text": " between feasibility", "tokens": [50364, 1296, 21781, 2841, 50440], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 79, "seek": 19784, "start": 199.36, "end": 202.92000000000002, "text": " and actual widespread implementation and automation.", "tokens": [50440, 293, 3539, 22679, 11420, 293, 17769, 13, 50618], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 80, "seek": 19784, "start": 203.96, "end": 206.72, "text": " Beyond the question of what AI systems can do,", "tokens": [50670, 19707, 264, 1168, 295, 437, 7318, 3652, 393, 360, 11, 50808], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 81, "seek": 19784, "start": 206.72, "end": 209.64000000000001, "text": " there are also questions of legal regulation, of course,", "tokens": [50808, 456, 366, 611, 1651, 295, 5089, 15062, 11, 295, 1164, 11, 50954], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 82, "seek": 19784, "start": 209.64000000000001, "end": 211.4, "text": " and perhaps even more importantly,", "tokens": [50954, 293, 4317, 754, 544, 8906, 11, 51042], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 83, "seek": 19784, "start": 211.4, "end": 214.84, "text": " just how eager people are to use AI tools in the first place.", "tokens": [51042, 445, 577, 18259, 561, 366, 281, 764, 7318, 3873, 294, 264, 700, 1081, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 84, "seek": 19784, "start": 216.04, "end": 218.44, "text": " When Robin reported that his son's software firm", "tokens": [51274, 1133, 16533, 7055, 300, 702, 1872, 311, 4722, 6174, 51394], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 85, "seek": 19784, "start": 218.44, "end": 221.48000000000002, "text": " had recently determined that LLMs were not useful", "tokens": [51394, 632, 3938, 9540, 300, 441, 43, 26386, 645, 406, 4420, 51546], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 86, "seek": 19784, "start": 221.48000000000002, "end": 223.48000000000002, "text": " for routine application development,", "tokens": [51546, 337, 9927, 3861, 3250, 11, 51646], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 87, "seek": 19784, "start": 223.48000000000002, "end": 225.2, "text": " I was honestly kind of shocked", "tokens": [51646, 286, 390, 6095, 733, 295, 12763, 51732], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 88, "seek": 19784, "start": 225.2, "end": 226.32, "text": " because if nothing else,", "tokens": [51732, 570, 498, 1825, 1646, 11, 51788], "temperature": 0.0, "avg_logprob": -0.09269305142489347, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0015974483685567975}, {"id": 89, "seek": 22632, "start": 226.32, "end": 228.07999999999998, "text": " I'm extremely confident about the degree", "tokens": [50364, 286, 478, 4664, 6679, 466, 264, 4314, 50452], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 90, "seek": 22632, "start": 228.07999999999998, "end": 230.92, "text": " to which LLMs accelerate my own programming work.", "tokens": [50452, 281, 597, 441, 43, 26386, 21341, 452, 1065, 9410, 589, 13, 50594], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 91, "seek": 22632, "start": 232.0, "end": 234.56, "text": " Since then, though, I have heard a couple of other stories,", "tokens": [50648, 4162, 550, 11, 1673, 11, 286, 362, 2198, 257, 1916, 295, 661, 3676, 11, 50776], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 92, "seek": 22632, "start": 234.56, "end": 236.07999999999998, "text": " which combined with Robbins,", "tokens": [50776, 597, 9354, 365, 5424, 49198, 11, 50852], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 93, "seek": 22632, "start": 236.07999999999998, "end": 238.35999999999999, "text": " helped me develop, I think, a bit better theory", "tokens": [50852, 4254, 385, 1499, 11, 286, 519, 11, 257, 857, 1101, 5261, 50966], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 94, "seek": 22632, "start": 238.35999999999999, "end": 240.16, "text": " of what's going on.", "tokens": [50966, 295, 437, 311, 516, 322, 13, 51056], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 95, "seek": 22632, "start": 240.16, "end": 244.32, "text": " First, an AI educator told me that failure to form new habits", "tokens": [51056, 2386, 11, 364, 7318, 31237, 1907, 385, 300, 7763, 281, 1254, 777, 14100, 51264], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 96, "seek": 22632, "start": 244.32, "end": 248.24, "text": " is the most common cause of failure with AI in general.", "tokens": [51264, 307, 264, 881, 2689, 3082, 295, 7763, 365, 7318, 294, 2674, 13, 51460], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 97, "seek": 22632, "start": 248.24, "end": 252.0, "text": " In his courses, he emphasizes hands-on exercises", "tokens": [51460, 682, 702, 7712, 11, 415, 48856, 2377, 12, 266, 11900, 51648], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 98, "seek": 22632, "start": 252.0, "end": 254.2, "text": " because he's learned that simple awareness", "tokens": [51648, 570, 415, 311, 3264, 300, 2199, 8888, 51758], "temperature": 0.0, "avg_logprob": -0.10569324813970998, "compression_ratio": 1.554421768707483, "no_speech_prob": 0.0001088729768525809}, {"id": 99, "seek": 25420, "start": 254.23999999999998, "end": 258.36, "text": " of AI capabilities does not lead to human behavioral change.", "tokens": [50366, 295, 7318, 10862, 775, 406, 1477, 281, 1952, 19124, 1319, 13, 50572], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 100, "seek": 25420, "start": 259.36, "end": 261.47999999999996, "text": " Second, a friend told me that his company", "tokens": [50622, 5736, 11, 257, 1277, 1907, 385, 300, 702, 2237, 50728], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 101, "seek": 25420, "start": 261.47999999999996, "end": 263.76, "text": " hosted a Microsoft GitHub salesperson", "tokens": [50728, 19204, 257, 8116, 23331, 5763, 10813, 50842], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 102, "seek": 25420, "start": 263.76, "end": 265.28, "text": " for a lunch hour demo,", "tokens": [50842, 337, 257, 6349, 1773, 10723, 11, 50918], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 103, "seek": 25420, "start": 265.28, "end": 267.64, "text": " and it turned out that one of their own team members", "tokens": [50918, 293, 309, 3574, 484, 300, 472, 295, 641, 1065, 1469, 2679, 51036], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 104, "seek": 25420, "start": 267.64, "end": 270.44, "text": " had far more knowledge about GitHub Co-Pilot", "tokens": [51036, 632, 1400, 544, 3601, 466, 23331, 3066, 12, 47, 31516, 51176], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 105, "seek": 25420, "start": 270.44, "end": 271.76, "text": " than the rep himself did.", "tokens": [51176, 813, 264, 1085, 3647, 630, 13, 51242], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 106, "seek": 25420, "start": 272.88, "end": 274.68, "text": " If Microsoft sales reps are struggling", "tokens": [51298, 759, 8116, 5763, 27007, 366, 9314, 51388], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 107, "seek": 25420, "start": 274.68, "end": 276.88, "text": " to keep up with Co-Pilot's capabilities,", "tokens": [51388, 281, 1066, 493, 365, 3066, 12, 47, 31516, 311, 10862, 11, 51498], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 108, "seek": 25420, "start": 276.88, "end": 278.88, "text": " we should perhaps adjust our expectations", "tokens": [51498, 321, 820, 4317, 4369, 527, 9843, 51598], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 109, "seek": 25420, "start": 278.88, "end": 280.28, "text": " for the rest of the economy.", "tokens": [51598, 337, 264, 1472, 295, 264, 5010, 13, 51668], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 110, "seek": 25420, "start": 281.4, "end": 283.03999999999996, "text": " And third, in my own experience,", "tokens": [51724, 400, 2636, 11, 294, 452, 1065, 1752, 11, 51806], "temperature": 0.0, "avg_logprob": -0.11148842757310325, "compression_ratio": 1.6020408163265305, "no_speech_prob": 0.00047277440899051726}, {"id": 111, "seek": 28304, "start": 283.04, "end": 286.20000000000005, "text": " helping people address process bottlenecks with AI,", "tokens": [50364, 4315, 561, 2985, 1399, 44641, 2761, 365, 7318, 11, 50522], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 112, "seek": 28304, "start": 286.20000000000005, "end": 288.76000000000005, "text": " I've repeatedly seen how unnatural it can be", "tokens": [50522, 286, 600, 18227, 1612, 577, 43470, 309, 393, 312, 50650], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 113, "seek": 28304, "start": 288.76000000000005, "end": 290.88, "text": " for people to break their own work down", "tokens": [50650, 337, 561, 281, 1821, 641, 1065, 589, 760, 50756], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 114, "seek": 28304, "start": 290.88, "end": 292.64000000000004, "text": " into the sort of discrete tasks", "tokens": [50756, 666, 264, 1333, 295, 27706, 9608, 50844], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 115, "seek": 28304, "start": 292.64000000000004, "end": 295.72, "text": " that LLMs can handle effectively today.", "tokens": [50844, 300, 441, 43, 26386, 393, 4813, 8659, 965, 13, 50998], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 116, "seek": 28304, "start": 295.72, "end": 298.04, "text": " Most people were never trained to think this way,", "tokens": [50998, 4534, 561, 645, 1128, 8895, 281, 519, 341, 636, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 117, "seek": 28304, "start": 298.04, "end": 299.28000000000003, "text": " and it's going to take time", "tokens": [51114, 293, 309, 311, 516, 281, 747, 565, 51176], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 118, "seek": 28304, "start": 299.28000000000003, "end": 302.08000000000004, "text": " before it becomes common practice across the economy.", "tokens": [51176, 949, 309, 3643, 2689, 3124, 2108, 264, 5010, 13, 51316], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 119, "seek": 28304, "start": 303.48, "end": 306.36, "text": " All this means that change may be slower to materialize", "tokens": [51386, 1057, 341, 1355, 300, 1319, 815, 312, 14009, 281, 2527, 1125, 51530], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 120, "seek": 28304, "start": 306.36, "end": 309.88, "text": " than those of us on the frontiers of AI adoption might expect.", "tokens": [51530, 813, 729, 295, 505, 322, 264, 1868, 4890, 295, 7318, 19215, 1062, 2066, 13, 51706], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 121, "seek": 28304, "start": 309.88, "end": 311.96000000000004, "text": " And while that does suggest more of an opportunity", "tokens": [51706, 400, 1339, 300, 775, 3402, 544, 295, 364, 2650, 51810], "temperature": 0.0, "avg_logprob": -0.07160144805908203, "compression_ratio": 1.6139240506329113, "no_speech_prob": 0.0027995372656732798}, {"id": 122, "seek": 31196, "start": 311.96, "end": 315.15999999999997, "text": " and indeed advantage for us in the meantime,", "tokens": [50364, 293, 6451, 5002, 337, 505, 294, 264, 14991, 11, 50524], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 123, "seek": 31196, "start": 315.15999999999997, "end": 318.03999999999996, "text": " on balance, I do have to view it as a negative sign", "tokens": [50524, 322, 4772, 11, 286, 360, 362, 281, 1910, 309, 382, 257, 3671, 1465, 50668], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 124, "seek": 31196, "start": 318.03999999999996, "end": 321.28, "text": " about our preparedness and our ability to adapt overall.", "tokens": [50668, 466, 527, 48445, 293, 527, 3485, 281, 6231, 4787, 13, 50830], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 125, "seek": 31196, "start": 322.59999999999997, "end": 323.84, "text": " Regardless of your views,", "tokens": [50896, 25148, 295, 428, 6809, 11, 50958], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 126, "seek": 31196, "start": 323.84, "end": 325.35999999999996, "text": " and I do suspect that most listeners", "tokens": [50958, 293, 286, 360, 9091, 300, 881, 23274, 51034], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 127, "seek": 31196, "start": 325.35999999999996, "end": 328.52, "text": " will find themselves agreeing with me more than with Robin,", "tokens": [51034, 486, 915, 2969, 36900, 365, 385, 544, 813, 365, 16533, 11, 51192], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 128, "seek": 31196, "start": 328.52, "end": 330.59999999999997, "text": " his insights are always thought-provoking,", "tokens": [51192, 702, 14310, 366, 1009, 1194, 12, 49911, 5953, 11, 51296], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 129, "seek": 31196, "start": 330.59999999999997, "end": 332.76, "text": " and I think you'll find it very well worthwhile", "tokens": [51296, 293, 286, 519, 291, 603, 915, 309, 588, 731, 28159, 51404], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 130, "seek": 31196, "start": 332.76, "end": 334.12, "text": " to engage with the challenges", "tokens": [51404, 281, 4683, 365, 264, 4759, 51472], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 131, "seek": 31196, "start": 334.12, "end": 336.0, "text": " that he presents in this conversation.", "tokens": [51472, 300, 415, 13533, 294, 341, 3761, 13, 51566], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 132, "seek": 31196, "start": 337.44, "end": 338.96, "text": " As always, if you're finding value in the show,", "tokens": [51638, 1018, 1009, 11, 498, 291, 434, 5006, 2158, 294, 264, 855, 11, 51714], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 133, "seek": 31196, "start": 338.96, "end": 341.08, "text": " we would appreciate it if you'd share it with friends,", "tokens": [51714, 321, 576, 4449, 309, 498, 291, 1116, 2073, 309, 365, 1855, 11, 51820], "temperature": 0.0, "avg_logprob": -0.09033744475420784, "compression_ratio": 1.7056962025316456, "no_speech_prob": 0.0007094801985658705}, {"id": 134, "seek": 34108, "start": 341.08, "end": 343.59999999999997, "text": " post a review on Apple Podcasts or Spotify,", "tokens": [50364, 2183, 257, 3131, 322, 6373, 29972, 82, 420, 29036, 11, 50490], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 135, "seek": 34108, "start": 343.59999999999997, "end": 346.12, "text": " or just leave a comment on YouTube.", "tokens": [50490, 420, 445, 1856, 257, 2871, 322, 3088, 13, 50616], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 136, "seek": 34108, "start": 346.12, "end": 348.35999999999996, "text": " And of course, I always love to hear from listeners,", "tokens": [50616, 400, 295, 1164, 11, 286, 1009, 959, 281, 1568, 490, 23274, 11, 50728], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 137, "seek": 34108, "start": 348.35999999999996, "end": 350.56, "text": " so please don't hesitate to DM me", "tokens": [50728, 370, 1767, 500, 380, 20842, 281, 15322, 385, 50838], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 138, "seek": 34108, "start": 350.56, "end": 353.68, "text": " on the social media platform of your choice.", "tokens": [50838, 322, 264, 2093, 3021, 3663, 295, 428, 3922, 13, 50994], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 139, "seek": 34108, "start": 353.68, "end": 355.64, "text": " Now, I hope you enjoy this conversation", "tokens": [50994, 823, 11, 286, 1454, 291, 2103, 341, 3761, 51092], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 140, "seek": 34108, "start": 355.64, "end": 357.76, "text": " with Professor Robin Hansen.", "tokens": [51092, 365, 8419, 16533, 17926, 268, 13, 51198], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 141, "seek": 34108, "start": 358.88, "end": 361.76, "text": " Robin Hansen, Professor of Economics at George Mason University", "tokens": [51254, 16533, 17926, 268, 11, 8419, 295, 39024, 412, 7136, 25730, 3535, 51398], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 142, "seek": 34108, "start": 361.76, "end": 364.91999999999996, "text": " and noted polymath, welcome to the cognitive revolution.", "tokens": [51398, 293, 12964, 6754, 24761, 11, 2928, 281, 264, 15605, 8894, 13, 51556], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 143, "seek": 34108, "start": 364.91999999999996, "end": 366.36, "text": " Nice to meet you, Nathan.", "tokens": [51556, 5490, 281, 1677, 291, 11, 20634, 13, 51628], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 144, "seek": 34108, "start": 366.36, "end": 367.28, "text": " Let's talk.", "tokens": [51628, 961, 311, 751, 13, 51674], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 145, "seek": 34108, "start": 367.28, "end": 368.28, "text": " I'm excited about this.", "tokens": [51674, 286, 478, 2919, 466, 341, 13, 51724], "temperature": 0.0, "avg_logprob": -0.09156464773511129, "compression_ratio": 1.548494983277592, "no_speech_prob": 0.0003919537703040987}, {"id": 146, "seek": 36828, "start": 368.32, "end": 371.23999999999995, "text": " So I have followed your work for a long time.", "tokens": [50366, 407, 286, 362, 6263, 428, 589, 337, 257, 938, 565, 13, 50512], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 147, "seek": 36828, "start": 371.23999999999995, "end": 375.44, "text": " It's super wide-ranging and always very interesting.", "tokens": [50512, 467, 311, 1687, 4874, 12, 81, 9741, 293, 1009, 588, 1880, 13, 50722], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 148, "seek": 36828, "start": 375.44, "end": 377.67999999999995, "text": " People can find your thoughts on just about everything,", "tokens": [50722, 3432, 393, 915, 428, 4598, 322, 445, 466, 1203, 11, 50834], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 149, "seek": 36828, "start": 377.67999999999995, "end": 380.44, "text": " I think, over the years on overcoming bias, your blog.", "tokens": [50834, 286, 519, 11, 670, 264, 924, 322, 38047, 12577, 11, 428, 6968, 13, 50972], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 150, "seek": 36828, "start": 380.44, "end": 383.44, "text": " But today, I wanted to revisit what I think", "tokens": [50972, 583, 965, 11, 286, 1415, 281, 32676, 437, 286, 519, 51122], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 151, "seek": 36828, "start": 383.44, "end": 384.79999999999995, "text": " is one of your destined to be,", "tokens": [51122, 307, 472, 295, 428, 33169, 281, 312, 11, 51190], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 152, "seek": 36828, "start": 384.79999999999995, "end": 386.35999999999996, "text": " perhaps one of your most influential works,", "tokens": [51190, 4317, 472, 295, 428, 881, 22215, 1985, 11, 51268], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 153, "seek": 36828, "start": 386.35999999999996, "end": 388.79999999999995, "text": " which is the book, The Age of M,", "tokens": [51268, 597, 307, 264, 1446, 11, 440, 16280, 295, 376, 11, 51390], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 154, "seek": 36828, "start": 388.79999999999995, "end": 393.2, "text": " which came out in 2016 and Envisions a Future,", "tokens": [51390, 597, 1361, 484, 294, 6549, 293, 2193, 85, 4252, 257, 20805, 11, 51610], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 155, "seek": 36828, "start": 393.2, "end": 397.11999999999995, "text": " which basically amounts to putting humans on machines,", "tokens": [51610, 597, 1936, 11663, 281, 3372, 6255, 322, 8379, 11, 51806], "temperature": 0.0, "avg_logprob": -0.11663603973388671, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.00043044958147220314}, {"id": 156, "seek": 39712, "start": 397.12, "end": 399.52, "text": " and we can unpack that in more detail,", "tokens": [50364, 293, 321, 393, 26699, 300, 294, 544, 2607, 11, 50484], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 157, "seek": 39712, "start": 399.52, "end": 404.52, "text": " and then explores that in a ton of different directions.", "tokens": [50484, 293, 550, 45473, 300, 294, 257, 2952, 295, 819, 11095, 13, 50734], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 158, "seek": 39712, "start": 404.92, "end": 407.6, "text": " Where we actually are now as we enter into 2024", "tokens": [50754, 2305, 321, 767, 366, 586, 382, 321, 3242, 666, 45237, 50888], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 159, "seek": 39712, "start": 407.6, "end": 410.04, "text": " is not exactly that, certainly,", "tokens": [50888, 307, 406, 2293, 300, 11, 3297, 11, 51010], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 160, "seek": 39712, "start": 410.04, "end": 411.84000000000003, "text": " but I've come to believe recently", "tokens": [51010, 457, 286, 600, 808, 281, 1697, 3938, 51100], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 161, "seek": 39712, "start": 411.84000000000003, "end": 414.72, "text": " that it's maybe bending back a little bit more toward that,", "tokens": [51100, 300, 309, 311, 1310, 22487, 646, 257, 707, 857, 544, 7361, 300, 11, 51244], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 162, "seek": 39712, "start": 414.72, "end": 417.04, "text": " certainly more than my expectations a year ago.", "tokens": [51244, 3297, 544, 813, 452, 9843, 257, 1064, 2057, 13, 51360], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 163, "seek": 39712, "start": 417.04, "end": 419.32, "text": " So I've revisited the book,", "tokens": [51360, 407, 286, 600, 20767, 1226, 264, 1446, 11, 51474], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 164, "seek": 39712, "start": 419.32, "end": 421.4, "text": " and I'm excited to bring a bunch of questions", "tokens": [51474, 293, 286, 478, 2919, 281, 1565, 257, 3840, 295, 1651, 51578], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 165, "seek": 39712, "start": 421.4, "end": 423.76, "text": " and kind of compare and contrast your scenario", "tokens": [51578, 293, 733, 295, 6794, 293, 8712, 428, 9005, 51696], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 166, "seek": 39712, "start": 423.76, "end": 425.64, "text": " versus the current scenario", "tokens": [51696, 5717, 264, 2190, 9005, 51790], "temperature": 0.0, "avg_logprob": -0.09390776952107747, "compression_ratio": 1.6823104693140793, "no_speech_prob": 0.0013246326707303524}, {"id": 167, "seek": 42564, "start": 425.64, "end": 427.96, "text": " that we seem to be evolving into.", "tokens": [50364, 300, 321, 1643, 281, 312, 21085, 666, 13, 50480], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 168, "seek": 42564, "start": 427.96, "end": 429.59999999999997, "text": " Okay, let's do it.", "tokens": [50480, 1033, 11, 718, 311, 360, 309, 13, 50562], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 169, "seek": 42564, "start": 429.59999999999997, "end": 432.47999999999996, "text": " One big theme of your work always, I think,", "tokens": [50562, 1485, 955, 6314, 295, 428, 589, 1009, 11, 286, 519, 11, 50706], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 170, "seek": 42564, "start": 432.47999999999996, "end": 436.52, "text": " is that we live in this strange dream time,", "tokens": [50706, 307, 300, 321, 1621, 294, 341, 5861, 3055, 565, 11, 50908], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 171, "seek": 42564, "start": 436.52, "end": 441.03999999999996, "text": " and that our reality as modern humans is quite different", "tokens": [50908, 293, 300, 527, 4103, 382, 4363, 6255, 307, 1596, 819, 51134], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 172, "seek": 42564, "start": 441.03999999999996, "end": 443.2, "text": " than the reality of those that came before us", "tokens": [51134, 813, 264, 4103, 295, 729, 300, 1361, 949, 505, 51242], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 173, "seek": 42564, "start": 443.2, "end": 444.76, "text": " and likely those that will come after us", "tokens": [51242, 293, 3700, 729, 300, 486, 808, 934, 505, 51320], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 174, "seek": 42564, "start": 444.76, "end": 447.08, "text": " for some pretty fundamental reasons.", "tokens": [51320, 337, 512, 1238, 8088, 4112, 13, 51436], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 175, "seek": 42564, "start": 447.08, "end": 448.24, "text": " Do you wanna just sketch out", "tokens": [51436, 1144, 291, 1948, 445, 12325, 484, 51494], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 176, "seek": 42564, "start": 448.24, "end": 449.68, "text": " your kind of big picture argument", "tokens": [51494, 428, 733, 295, 955, 3036, 6770, 51566], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 177, "seek": 42564, "start": 449.68, "end": 452.24, "text": " that our times are exceptional", "tokens": [51566, 300, 527, 1413, 366, 19279, 51694], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 178, "seek": 42564, "start": 452.24, "end": 455.36, "text": " and not likely to go on like this forever?", "tokens": [51694, 293, 406, 3700, 281, 352, 322, 411, 341, 5680, 30, 51850], "temperature": 0.0, "avg_logprob": -0.06964098039220591, "compression_ratio": 1.6838235294117647, "no_speech_prob": 0.001031859079375863}, {"id": 179, "seek": 45536, "start": 455.40000000000003, "end": 457.0, "text": " The first thing to notice is that", "tokens": [50366, 440, 700, 551, 281, 3449, 307, 300, 50446], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 180, "seek": 45536, "start": 457.0, "end": 458.68, "text": " we were in a period of very rapid growth,", "tokens": [50446, 321, 645, 294, 257, 2896, 295, 588, 7558, 4599, 11, 50530], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 181, "seek": 45536, "start": 458.68, "end": 460.40000000000003, "text": " very rapid change,", "tokens": [50530, 588, 7558, 1319, 11, 50616], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 182, "seek": 45536, "start": 460.40000000000003, "end": 462.92, "text": " which just can't continue for very long", "tokens": [50616, 597, 445, 393, 380, 2354, 337, 588, 938, 50742], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 183, "seek": 45536, "start": 462.92, "end": 464.32, "text": " on a cosmological time scale.", "tokens": [50742, 322, 257, 22207, 4383, 565, 4373, 13, 50812], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 184, "seek": 45536, "start": 464.32, "end": 467.68, "text": " 10,000 years would be way longer than it could manage,", "tokens": [50812, 1266, 11, 1360, 924, 576, 312, 636, 2854, 813, 309, 727, 3067, 11, 50980], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 185, "seek": 45536, "start": 467.68, "end": 470.40000000000003, "text": " and therefore we're gonna have to go back", "tokens": [50980, 293, 4412, 321, 434, 799, 362, 281, 352, 646, 51116], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 186, "seek": 45536, "start": 470.40000000000003, "end": 472.88, "text": " to a period of slower change,", "tokens": [51116, 281, 257, 2896, 295, 14009, 1319, 11, 51240], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 187, "seek": 45536, "start": 472.88, "end": 474.88, "text": " and plausibly then a period of slower change", "tokens": [51240, 293, 34946, 3545, 550, 257, 2896, 295, 14009, 1319, 51340], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 188, "seek": 45536, "start": 474.88, "end": 478.64, "text": " will be a period where population can grow faster", "tokens": [51340, 486, 312, 257, 2896, 689, 4415, 393, 1852, 4663, 51528], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 189, "seek": 45536, "start": 478.64, "end": 483.64, "text": " relative to the growth rate of the economy in the universe,", "tokens": [51528, 4972, 281, 264, 4599, 3314, 295, 264, 5010, 294, 264, 6445, 11, 51778], "temperature": 0.0, "avg_logprob": -0.09962059469784007, "compression_ratio": 1.7628458498023716, "no_speech_prob": 0.00018515187548473477}, {"id": 190, "seek": 48364, "start": 484.24, "end": 485.59999999999997, "text": " and therefore we will move back", "tokens": [50394, 293, 4412, 321, 486, 1286, 646, 50462], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 191, "seek": 48364, "start": 485.59999999999997, "end": 488.28, "text": " more toward a Malthusian world", "tokens": [50462, 544, 7361, 257, 376, 1302, 301, 952, 1002, 50596], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 192, "seek": 48364, "start": 488.28, "end": 490.15999999999997, "text": " if competition remains,", "tokens": [50596, 498, 6211, 7023, 11, 50690], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 193, "seek": 48364, "start": 490.15999999999997, "end": 492.12, "text": " such as almost all our ancestors were", "tokens": [50690, 1270, 382, 1920, 439, 527, 18069, 645, 50788], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 194, "seek": 48364, "start": 492.12, "end": 494.03999999999996, "text": " until a few hundred years ago.", "tokens": [50788, 1826, 257, 1326, 3262, 924, 2057, 13, 50884], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 195, "seek": 48364, "start": 494.03999999999996, "end": 497.15999999999997, "text": " So we're in this unusual period of being rich", "tokens": [50884, 407, 321, 434, 294, 341, 10901, 2896, 295, 885, 4593, 51040], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 196, "seek": 48364, "start": 498.8, "end": 501.76, "text": " per person and in very rapid change,", "tokens": [51122, 680, 954, 293, 294, 588, 7558, 1319, 11, 51270], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 197, "seek": 48364, "start": 502.88, "end": 505.91999999999996, "text": " and also sort of globally integrated.", "tokens": [51326, 293, 611, 1333, 295, 18958, 10919, 13, 51478], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 198, "seek": 48364, "start": 505.91999999999996, "end": 509.4, "text": " That is, our distant ancestors were fragmented culturally", "tokens": [51478, 663, 307, 11, 527, 17275, 18069, 645, 9241, 14684, 28879, 51652], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 199, "seek": 48364, "start": 509.4, "end": 510.56, "text": " across the globe,", "tokens": [51652, 2108, 264, 15371, 11, 51710], "temperature": 0.0, "avg_logprob": -0.1706660588582357, "compression_ratio": 1.5575221238938053, "no_speech_prob": 0.001168968970887363}, {"id": 200, "seek": 51056, "start": 510.56, "end": 513.88, "text": " and each talk to a small group of people near them,", "tokens": [50364, 293, 1184, 751, 281, 257, 1359, 1594, 295, 561, 2651, 552, 11, 50530], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 201, "seek": 51056, "start": 513.88, "end": 515.72, "text": " and our distant descendants will be fragmented", "tokens": [50530, 293, 527, 17275, 31693, 486, 312, 9241, 14684, 50622], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 202, "seek": 51056, "start": 515.72, "end": 517.24, "text": " across the universe,", "tokens": [50622, 2108, 264, 6445, 11, 50698], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 203, "seek": 51056, "start": 517.24, "end": 519.96, "text": " and they won't be able to talk all across the universe", "tokens": [50698, 293, 436, 1582, 380, 312, 1075, 281, 751, 439, 2108, 264, 6445, 50834], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 204, "seek": 51056, "start": 519.96, "end": 521.24, "text": " instantaneously.", "tokens": [50834, 9836, 13131, 13, 50898], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 205, "seek": 51056, "start": 521.24, "end": 524.84, "text": " So future culture and past culture were both very fragmented,", "tokens": [50898, 407, 2027, 3713, 293, 1791, 3713, 645, 1293, 588, 9241, 14684, 11, 51078], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 206, "seek": 51056, "start": 524.84, "end": 527.64, "text": " and we were in a period where our entire civilization", "tokens": [51078, 293, 321, 645, 294, 257, 2896, 689, 527, 2302, 18036, 51218], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 207, "seek": 51056, "start": 527.64, "end": 530.04, "text": " can talk rapidly to each other.", "tokens": [51218, 393, 751, 12910, 281, 1184, 661, 13, 51338], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 208, "seek": 51056, "start": 530.04, "end": 532.72, "text": " The time delay of communication is very small", "tokens": [51338, 440, 565, 8577, 295, 6101, 307, 588, 1359, 51472], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 209, "seek": 51056, "start": 532.72, "end": 534.44, "text": " compared to the doubling time", "tokens": [51472, 5347, 281, 264, 33651, 565, 51558], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 210, "seek": 51056, "start": 534.44, "end": 536.32, "text": " of our very rapid growth economy.", "tokens": [51558, 295, 527, 588, 7558, 4599, 5010, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 211, "seek": 51056, "start": 536.32, "end": 539.2, "text": " So we are now an integrated civilization", "tokens": [51652, 407, 321, 366, 586, 364, 10919, 18036, 51796], "temperature": 0.0, "avg_logprob": -0.1213836669921875, "compression_ratio": 1.7883211678832116, "no_speech_prob": 0.001324536046013236}, {"id": 212, "seek": 53920, "start": 539.2, "end": 543.12, "text": " where rich growing very fast,", "tokens": [50364, 689, 4593, 4194, 588, 2370, 11, 50560], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 213, "seek": 53920, "start": 543.12, "end": 545.5600000000001, "text": " and there's a number of consequences being rich,", "tokens": [50560, 293, 456, 311, 257, 1230, 295, 10098, 885, 4593, 11, 50682], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 214, "seek": 53920, "start": 545.5600000000001, "end": 548.12, "text": " which is that we don't have to pay", "tokens": [50682, 597, 307, 300, 321, 500, 380, 362, 281, 1689, 50810], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 215, "seek": 53920, "start": 548.12, "end": 551.0400000000001, "text": " that much attention to functionality.", "tokens": [50810, 300, 709, 3202, 281, 14980, 13, 50956], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 216, "seek": 53920, "start": 551.0400000000001, "end": 554.1600000000001, "text": " Those were not pressured to do what it takes to survive", "tokens": [50956, 3950, 645, 406, 45306, 281, 360, 437, 309, 2516, 281, 7867, 51112], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 217, "seek": 53920, "start": 554.1600000000001, "end": 557.2, "text": " in the way our ancestors and our descendants would be.", "tokens": [51112, 294, 264, 636, 527, 18069, 293, 527, 31693, 576, 312, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 218, "seek": 53920, "start": 557.2, "end": 560.36, "text": " So we can indulge our delusions,", "tokens": [51264, 407, 321, 393, 28626, 432, 527, 1103, 27255, 11, 51422], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 219, "seek": 53920, "start": 560.36, "end": 563.72, "text": " or whatever other inclinations we have,", "tokens": [51422, 420, 2035, 661, 834, 5045, 763, 321, 362, 11, 51590], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 220, "seek": 53920, "start": 563.72, "end": 566.2800000000001, "text": " they aren't disciplined very rapidly", "tokens": [51590, 436, 3212, 380, 40061, 588, 12910, 51718], "temperature": 0.0, "avg_logprob": -0.12441979241125363, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.00018516631098464131}, {"id": 221, "seek": 56628, "start": 566.3199999999999, "end": 569.6, "text": " by survival and functionality.", "tokens": [50366, 538, 12559, 293, 14980, 13, 50530], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 222, "seek": 56628, "start": 569.6, "end": 571.9599999999999, "text": " That makes us a dream team.", "tokens": [50530, 663, 1669, 505, 257, 3055, 1469, 13, 50648], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 223, "seek": 56628, "start": 571.9599999999999, "end": 574.0, "text": " That is, our dreams drive us.", "tokens": [50648, 663, 307, 11, 527, 7505, 3332, 505, 13, 50750], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 224, "seek": 56628, "start": 574.9599999999999, "end": 578.8399999999999, "text": " Our abstract thoughts, our vague impressions,", "tokens": [50798, 2621, 12649, 4598, 11, 527, 24247, 24245, 11, 50992], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 225, "seek": 56628, "start": 578.8399999999999, "end": 582.16, "text": " our emotions, our visions.", "tokens": [50992, 527, 8462, 11, 527, 30746, 13, 51158], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 226, "seek": 56628, "start": 582.16, "end": 587.16, "text": " We do things that are dramatic and exciting and meaningful", "tokens": [51158, 492, 360, 721, 300, 366, 12023, 293, 4670, 293, 10995, 51408], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 227, "seek": 56628, "start": 588.88, "end": 593.88, "text": " in our view, according to this dream time mind we have,", "tokens": [51494, 294, 527, 1910, 11, 4650, 281, 341, 3055, 565, 1575, 321, 362, 11, 51744], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 228, "seek": 56628, "start": 594.3199999999999, "end": 596.16, "text": " which isn't, again, that disciplined", "tokens": [51766, 597, 1943, 380, 11, 797, 11, 300, 40061, 51858], "temperature": 0.0, "avg_logprob": -0.17302585509886226, "compression_ratio": 1.6051282051282052, "no_speech_prob": 0.0010644206777215004}, {"id": 229, "seek": 59616, "start": 596.16, "end": 597.52, "text": " by functionality, that is,", "tokens": [50364, 538, 14980, 11, 300, 307, 11, 50432], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 230, "seek": 59616, "start": 597.52, "end": 600.92, "text": " the mind we inherited from our distant ancestors,", "tokens": [50432, 264, 1575, 321, 27091, 490, 527, 17275, 18069, 11, 50602], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 231, "seek": 59616, "start": 600.92, "end": 603.0799999999999, "text": " it was functional there, it was disciplined there,", "tokens": [50602, 309, 390, 11745, 456, 11, 309, 390, 40061, 456, 11, 50710], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 232, "seek": 59616, "start": 603.0799999999999, "end": 604.3199999999999, "text": " we're in a very different world,", "tokens": [50710, 321, 434, 294, 257, 588, 819, 1002, 11, 50772], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 233, "seek": 59616, "start": 604.3199999999999, "end": 609.12, "text": " but our mind hasn't changed to be functional in this world.", "tokens": [50772, 457, 527, 1575, 6132, 380, 3105, 281, 312, 11745, 294, 341, 1002, 13, 51012], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 234, "seek": 59616, "start": 609.12, "end": 614.12, "text": " And so we are expressing this momentum", "tokens": [51012, 400, 370, 321, 366, 22171, 341, 11244, 51262], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 235, "seek": 59616, "start": 614.12, "end": 617.4, "text": " of what we used to be in this strange new world.", "tokens": [51262, 295, 437, 321, 1143, 281, 312, 294, 341, 5861, 777, 1002, 13, 51426], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 236, "seek": 59616, "start": 617.4, "end": 618.92, "text": " That's the dream time.", "tokens": [51426, 663, 311, 264, 3055, 565, 13, 51502], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 237, "seek": 59616, "start": 618.92, "end": 621.4399999999999, "text": " So let me just try to rephrase that", "tokens": [51502, 407, 718, 385, 445, 853, 281, 319, 44598, 651, 300, 51628], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 238, "seek": 59616, "start": 621.4399999999999, "end": 622.72, "text": " or frame it slightly differently", "tokens": [51628, 420, 3920, 309, 4748, 7614, 51692], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 239, "seek": 59616, "start": 622.72, "end": 624.88, "text": " and tell them if you agree with this framing.", "tokens": [51692, 293, 980, 552, 498, 291, 3986, 365, 341, 28971, 13, 51800], "temperature": 0.0, "avg_logprob": -0.13516562779744465, "compression_ratio": 1.7559055118110236, "no_speech_prob": 0.00037976985913701355}, {"id": 240, "seek": 62488, "start": 624.88, "end": 627.04, "text": " I would maybe interpret it as,", "tokens": [50364, 286, 576, 1310, 7302, 309, 382, 11, 50472], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 241, "seek": 62488, "start": 627.04, "end": 629.8, "text": " we're maybe in a punctuated equilibrium sort of situation", "tokens": [50472, 321, 434, 1310, 294, 257, 27006, 27275, 15625, 1333, 295, 2590, 50610], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 242, "seek": 62488, "start": 629.8, "end": 633.04, "text": " where we're in the transition from one equilibrium", "tokens": [50610, 689, 321, 434, 294, 264, 6034, 490, 472, 15625, 50772], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 243, "seek": 62488, "start": 633.04, "end": 635.32, "text": " to another, there have probably been", "tokens": [50772, 281, 1071, 11, 456, 362, 1391, 668, 50886], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 244, "seek": 62488, "start": 635.32, "end": 636.88, "text": " however many of these through history,", "tokens": [50886, 4461, 867, 295, 613, 807, 2503, 11, 50964], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 245, "seek": 62488, "start": 636.88, "end": 638.4399999999999, "text": " not like a huge number, but a decent number,", "tokens": [50964, 406, 411, 257, 2603, 1230, 11, 457, 257, 8681, 1230, 11, 51042], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 246, "seek": 62488, "start": 638.4399999999999, "end": 642.0, "text": " I think of such phrases as the Cambrian explosion,", "tokens": [51042, 286, 519, 295, 1270, 20312, 382, 264, 29287, 5501, 15673, 11, 51220], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 247, "seek": 62488, "start": 642.0, "end": 644.64, "text": " perhaps as another dream time.", "tokens": [51220, 4317, 382, 1071, 3055, 565, 13, 51352], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 248, "seek": 62488, "start": 644.64, "end": 648.92, "text": " These moments happen when some external shock", "tokens": [51352, 1981, 6065, 1051, 562, 512, 8320, 5588, 51566], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 249, "seek": 62488, "start": 648.92, "end": 650.88, "text": " happens to the system, whether that's like an asteroid", "tokens": [51566, 2314, 281, 264, 1185, 11, 1968, 300, 311, 411, 364, 33833, 51664], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 250, "seek": 62488, "start": 650.88, "end": 652.04, "text": " that takes out a lot of life,", "tokens": [51664, 300, 2516, 484, 257, 688, 295, 993, 11, 51722], "temperature": 0.0, "avg_logprob": -0.13478633335658483, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.00024528353242203593}, {"id": 251, "seek": 65204, "start": 652.04, "end": 654.92, "text": " or human brains come on the scene,", "tokens": [50364, 420, 1952, 15442, 808, 322, 264, 4145, 11, 50508], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 252, "seek": 65204, "start": 654.92, "end": 659.4, "text": " and there's a period in which the normal constraints", "tokens": [50508, 293, 456, 311, 257, 2896, 294, 597, 264, 2710, 18491, 50732], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 253, "seek": 65204, "start": 659.4, "end": 662.9599999999999, "text": " are temporarily relaxed, but then in the long term,", "tokens": [50732, 366, 23750, 14628, 11, 457, 550, 294, 264, 938, 1433, 11, 50910], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 254, "seek": 65204, "start": 662.9599999999999, "end": 664.92, "text": " there's just like no escaping the logic", "tokens": [50910, 456, 311, 445, 411, 572, 32554, 264, 9952, 51008], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 255, "seek": 65204, "start": 664.92, "end": 665.9599999999999, "text": " of natural selection.", "tokens": [51008, 295, 3303, 9450, 13, 51060], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 256, "seek": 65204, "start": 665.9599999999999, "end": 668.56, "text": " Is that basically the framework?", "tokens": [51060, 1119, 300, 1936, 264, 8388, 30, 51190], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 257, "seek": 65204, "start": 668.56, "end": 672.0, "text": " So your analogy of the Cambrian explosion could be,", "tokens": [51190, 407, 428, 21663, 295, 264, 29287, 5501, 15673, 727, 312, 11, 51362], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 258, "seek": 65204, "start": 672.0, "end": 673.8, "text": " we discovered multicellularity,", "tokens": [51362, 321, 6941, 2120, 573, 285, 1040, 507, 11, 51452], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 259, "seek": 65204, "start": 673.8, "end": 676.48, "text": " we discovered being able to make large animals,", "tokens": [51452, 321, 6941, 885, 1075, 281, 652, 2416, 4882, 11, 51586], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 260, "seek": 65204, "start": 676.48, "end": 678.0, "text": " and that was happened at a moment,", "tokens": [51586, 293, 300, 390, 2011, 412, 257, 1623, 11, 51662], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 261, "seek": 65204, "start": 678.0, "end": 680.0, "text": " there was the moment of multicellularity,", "tokens": [51662, 456, 390, 264, 1623, 295, 2120, 573, 285, 1040, 507, 11, 51762], "temperature": 0.0, "avg_logprob": -0.149988885653221, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.0004727012710645795}, {"id": 262, "seek": 68000, "start": 680.0, "end": 682.68, "text": " and then evolution took time to adapt", "tokens": [50364, 293, 550, 9303, 1890, 565, 281, 6231, 50498], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 263, "seek": 68000, "start": 682.68, "end": 685.04, "text": " to that new opportunity,", "tokens": [50498, 281, 300, 777, 2650, 11, 50616], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 264, "seek": 68000, "start": 685.04, "end": 688.08, "text": " and the Cambrian explosion is the period of adaptation,", "tokens": [50616, 293, 264, 29287, 5501, 15673, 307, 264, 2896, 295, 21549, 11, 50768], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 265, "seek": 68000, "start": 688.08, "end": 689.64, "text": " then after the Cambrian explosion,", "tokens": [50768, 550, 934, 264, 29287, 5501, 15673, 11, 50846], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 266, "seek": 68000, "start": 689.64, "end": 691.96, "text": " we've adapted to that new opportunity,", "tokens": [50846, 321, 600, 20871, 281, 300, 777, 2650, 11, 50962], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 267, "seek": 68000, "start": 691.96, "end": 693.44, "text": " and then we're more in a stasis,", "tokens": [50962, 293, 550, 321, 434, 544, 294, 257, 342, 26632, 11, 51036], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 268, "seek": 68000, "start": 693.44, "end": 695.88, "text": " and then you're imagining this period of adaptation", "tokens": [51036, 293, 550, 291, 434, 27798, 341, 2896, 295, 21549, 51158], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 269, "seek": 68000, "start": 695.88, "end": 696.88, "text": " to a sudden change.", "tokens": [51158, 281, 257, 3990, 1319, 13, 51208], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 270, "seek": 68000, "start": 697.76, "end": 702.76, "text": " But for humans today, we keep having sudden changes,", "tokens": [51252, 583, 337, 6255, 965, 11, 321, 1066, 1419, 3990, 2962, 11, 51502], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 271, "seek": 68000, "start": 703.2, "end": 705.04, "text": " and they keep coming fast,", "tokens": [51524, 293, 436, 1066, 1348, 2370, 11, 51616], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 272, "seek": 68000, "start": 705.04, "end": 708.04, "text": " and so there wasn't this one thing that happened", "tokens": [51616, 293, 370, 456, 2067, 380, 341, 472, 551, 300, 2011, 51766], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 273, "seek": 68000, "start": 708.04, "end": 709.72, "text": " 300 years ago or 10,000 years ago", "tokens": [51766, 6641, 924, 2057, 420, 1266, 11, 1360, 924, 2057, 51850], "temperature": 0.0, "avg_logprob": -0.10597588939051475, "compression_ratio": 1.9574468085106382, "no_speech_prob": 0.00023778014292474836}, {"id": 274, "seek": 70972, "start": 709.72, "end": 711.12, "text": " that we're slowly adapting to.", "tokens": [50364, 300, 321, 434, 5692, 34942, 281, 13, 50434], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 275, "seek": 70972, "start": 711.12, "end": 713.5600000000001, "text": " We keep having more big changes", "tokens": [50434, 492, 1066, 1419, 544, 955, 2962, 50556], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 276, "seek": 70972, "start": 713.5600000000001, "end": 715.72, "text": " that keep changing the landscape", "tokens": [50556, 300, 1066, 4473, 264, 9661, 50664], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 277, "seek": 70972, "start": 715.72, "end": 717.72, "text": " of what it is to adapt to,", "tokens": [50664, 295, 437, 309, 307, 281, 6231, 281, 11, 50764], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 278, "seek": 70972, "start": 717.72, "end": 722.24, "text": " so we won't see this slow adaptation to the new thing", "tokens": [50764, 370, 321, 1582, 380, 536, 341, 2964, 21549, 281, 264, 777, 551, 50990], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 279, "seek": 70972, "start": 722.24, "end": 724.0, "text": " until we get a stable new thing,", "tokens": [50990, 1826, 321, 483, 257, 8351, 777, 551, 11, 51078], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 280, "seek": 70972, "start": 724.0, "end": 725.08, "text": " which we haven't gotten yet.", "tokens": [51078, 597, 321, 2378, 380, 5768, 1939, 13, 51132], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 281, "seek": 70972, "start": 725.08, "end": 726.84, "text": " We, things keep changing.", "tokens": [51132, 492, 11, 721, 1066, 4473, 13, 51220], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 282, "seek": 70972, "start": 726.84, "end": 728.8000000000001, "text": " I wanna maybe circle back in a minute to", "tokens": [51220, 286, 1948, 1310, 6329, 646, 294, 257, 3456, 281, 51318], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 283, "seek": 70972, "start": 728.8000000000001, "end": 731.0400000000001, "text": " what would be the conditions", "tokens": [51318, 437, 576, 312, 264, 4487, 51430], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 284, "seek": 70972, "start": 731.0400000000001, "end": 732.36, "text": " under which things would restabilize.", "tokens": [51430, 833, 597, 721, 576, 1472, 5177, 1125, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 285, "seek": 70972, "start": 732.36, "end": 735.0400000000001, "text": " I think I guess the M scenario is one of them,", "tokens": [51496, 286, 519, 286, 2041, 264, 376, 9005, 307, 472, 295, 552, 11, 51630], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 286, "seek": 70972, "start": 735.0400000000001, "end": 737.72, "text": " but there may be others that might even be", "tokens": [51630, 457, 456, 815, 312, 2357, 300, 1062, 754, 312, 51764], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 287, "seek": 70972, "start": 737.72, "end": 739.1600000000001, "text": " more imminent at this point.", "tokens": [51764, 544, 44339, 412, 341, 935, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1337665362949789, "compression_ratio": 1.7789855072463767, "no_speech_prob": 0.0001794903218979016}, {"id": 288, "seek": 73972, "start": 739.84, "end": 740.6800000000001, "text": " Before doing that,", "tokens": [50370, 4546, 884, 300, 11, 50412], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 289, "seek": 73972, "start": 740.6800000000001, "end": 742.4, "text": " I just wanted to touch on another big theme of your work,", "tokens": [50412, 286, 445, 1415, 281, 2557, 322, 1071, 955, 6314, 295, 428, 589, 11, 50498], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 290, "seek": 73972, "start": 742.4, "end": 745.24, "text": " which is, and I really appreciate how you introduced", "tokens": [50498, 597, 307, 11, 293, 286, 534, 4449, 577, 291, 7268, 50640], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 291, "seek": 73972, "start": 745.24, "end": 749.4, "text": " the book this way with the idea that", "tokens": [50640, 264, 1446, 341, 636, 365, 264, 1558, 300, 50848], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 292, "seek": 73972, "start": 749.4, "end": 751.24, "text": " I'm just trying to figure out", "tokens": [50848, 286, 478, 445, 1382, 281, 2573, 484, 50940], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 293, "seek": 73972, "start": 751.24, "end": 753.8000000000001, "text": " what is likely to happen in this scenario.", "tokens": [50940, 437, 307, 3700, 281, 1051, 294, 341, 9005, 13, 51068], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 294, "seek": 73972, "start": 753.8000000000001, "end": 755.6800000000001, "text": " I'm not telling you you should like it.", "tokens": [51068, 286, 478, 406, 3585, 291, 291, 820, 411, 309, 13, 51162], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 295, "seek": 73972, "start": 755.6800000000001, "end": 757.2, "text": " I'm not telling you you should dislike it.", "tokens": [51162, 286, 478, 406, 3585, 291, 291, 820, 26006, 309, 13, 51238], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 296, "seek": 73972, "start": 757.2, "end": 758.48, "text": " I'm not trying to judge it.", "tokens": [51238, 286, 478, 406, 1382, 281, 6995, 309, 13, 51302], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 297, "seek": 73972, "start": 758.48, "end": 761.9200000000001, "text": " I'm just trying to extrapolate from a scenario", "tokens": [51302, 286, 478, 445, 1382, 281, 48224, 473, 490, 257, 9005, 51474], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 298, "seek": 73972, "start": 761.9200000000001, "end": 764.9200000000001, "text": " using the tools of science and social science", "tokens": [51474, 1228, 264, 3873, 295, 3497, 293, 2093, 3497, 51624], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 299, "seek": 73972, "start": 764.9200000000001, "end": 767.2, "text": " to try to figure out what might happen.", "tokens": [51624, 281, 853, 281, 2573, 484, 437, 1062, 1051, 13, 51738], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 300, "seek": 73972, "start": 767.2, "end": 769.52, "text": " I love that, and I try to do something similar", "tokens": [51738, 286, 959, 300, 11, 293, 286, 853, 281, 360, 746, 2531, 51854], "temperature": 0.0, "avg_logprob": -0.08080107590247845, "compression_ratio": 1.9343065693430657, "no_speech_prob": 0.00036818053922615945}, {"id": 301, "seek": 76952, "start": 769.52, "end": 772.24, "text": " with this show around understanding AI.", "tokens": [50364, 365, 341, 855, 926, 3701, 7318, 13, 50500], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 302, "seek": 76952, "start": 772.24, "end": 775.6, "text": " I think there's so much emotional valence", "tokens": [50500, 286, 519, 456, 311, 370, 709, 6863, 1323, 655, 50668], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 303, "seek": 76952, "start": 775.6, "end": 777.72, "text": " brought to so many parts of the discussion,", "tokens": [50668, 3038, 281, 370, 867, 3166, 295, 264, 5017, 11, 50774], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 304, "seek": 76952, "start": 777.72, "end": 781.4399999999999, "text": " and I always say, we need to first figure out what is,", "tokens": [50774, 293, 286, 1009, 584, 11, 321, 643, 281, 700, 2573, 484, 437, 307, 11, 50960], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 305, "seek": 76952, "start": 781.4399999999999, "end": 783.12, "text": " and even in the current moment,", "tokens": [50960, 293, 754, 294, 264, 2190, 1623, 11, 51044], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 306, "seek": 76952, "start": 783.12, "end": 786.0, "text": " what capabilities exist, what can be done,", "tokens": [51044, 437, 10862, 2514, 11, 437, 393, 312, 1096, 11, 51188], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 307, "seek": 76952, "start": 786.0, "end": 788.4, "text": " what is still out of reach of current systems", "tokens": [51188, 437, 307, 920, 484, 295, 2524, 295, 2190, 3652, 51308], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 308, "seek": 76952, "start": 788.4, "end": 790.1999999999999, "text": " before we can really get serious", "tokens": [51308, 949, 321, 393, 534, 483, 3156, 51398], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 309, "seek": 76952, "start": 790.1999999999999, "end": 793.4399999999999, "text": " about what ought to be done about it.", "tokens": [51398, 466, 437, 13416, 281, 312, 1096, 466, 309, 13, 51560], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 310, "seek": 76952, "start": 794.4, "end": 796.16, "text": " I guess I'd invite you to add", "tokens": [51608, 286, 2041, 286, 1116, 7980, 291, 281, 909, 51696], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 311, "seek": 76952, "start": 796.16, "end": 797.36, "text": " any additional perspective to that,", "tokens": [51696, 604, 4497, 4585, 281, 300, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1408170879396618, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.0007790238014422357}, {"id": 312, "seek": 79736, "start": 797.36, "end": 798.4, "text": " and then I'm also curious,", "tokens": [50364, 293, 550, 286, 478, 611, 6369, 11, 50416], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 313, "seek": 79736, "start": 798.4, "end": 801.5600000000001, "text": " like, I think that's very admirable,", "tokens": [50416, 411, 11, 286, 519, 300, 311, 588, 5910, 21493, 11, 50574], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 314, "seek": 79736, "start": 801.5600000000001, "end": 804.5600000000001, "text": " but could you give us a little window", "tokens": [50574, 457, 727, 291, 976, 505, 257, 707, 4910, 50724], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 315, "seek": 79736, "start": 804.5600000000001, "end": 807.12, "text": " into your own kind of biases or preferences?", "tokens": [50724, 666, 428, 1065, 733, 295, 32152, 420, 21910, 30, 50852], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 316, "seek": 79736, "start": 807.12, "end": 809.5600000000001, "text": " Like, what sort of world do you think", "tokens": [50852, 1743, 11, 437, 1333, 295, 1002, 360, 291, 519, 50974], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 317, "seek": 79736, "start": 809.5600000000001, "end": 810.88, "text": " we should be striving for,", "tokens": [50974, 321, 820, 312, 36582, 337, 11, 51040], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 318, "seek": 79736, "start": 810.88, "end": 812.04, "text": " or do you think that's just so futile", "tokens": [51040, 420, 360, 291, 519, 300, 311, 445, 370, 1877, 794, 51098], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 319, "seek": 79736, "start": 812.04, "end": 814.6, "text": " to even attempt to influence against these,", "tokens": [51098, 281, 754, 5217, 281, 6503, 1970, 613, 11, 51226], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 320, "seek": 79736, "start": 814.6, "end": 817.8000000000001, "text": " you know, grand constraints that it doesn't matter?", "tokens": [51226, 291, 458, 11, 2697, 18491, 300, 309, 1177, 380, 1871, 30, 51386], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 321, "seek": 79736, "start": 817.8000000000001, "end": 819.76, "text": " Hey, we'll continue our interview in a moment", "tokens": [51386, 1911, 11, 321, 603, 2354, 527, 4049, 294, 257, 1623, 51484], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 322, "seek": 79736, "start": 819.76, "end": 822.08, "text": " after a word from our sponsors.", "tokens": [51484, 934, 257, 1349, 490, 527, 22593, 13, 51600], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 323, "seek": 79736, "start": 822.08, "end": 824.64, "text": " The Brave Search API brings affordable developer access", "tokens": [51600, 440, 38545, 17180, 9362, 5607, 12028, 10754, 2105, 51728], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 324, "seek": 79736, "start": 824.64, "end": 826.16, "text": " to the Brave Search Index,", "tokens": [51728, 281, 264, 38545, 17180, 33552, 11, 51804], "temperature": 0.0, "avg_logprob": -0.1113121283315394, "compression_ratio": 1.632258064516129, "no_speech_prob": 0.000829380820505321}, {"id": 325, "seek": 82616, "start": 826.16, "end": 827.52, "text": " an independent index of the web", "tokens": [50364, 364, 6695, 8186, 295, 264, 3670, 50432], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 326, "seek": 82616, "start": 827.52, "end": 829.8399999999999, "text": " with over 20 billion web pages.", "tokens": [50432, 365, 670, 945, 5218, 3670, 7183, 13, 50548], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 327, "seek": 82616, "start": 829.8399999999999, "end": 832.64, "text": " So what makes the Brave Search Index stand out?", "tokens": [50548, 407, 437, 1669, 264, 38545, 17180, 33552, 1463, 484, 30, 50688], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 328, "seek": 82616, "start": 832.64, "end": 836.36, "text": " One, it's entirely independent and built from scratch.", "tokens": [50688, 1485, 11, 309, 311, 7696, 6695, 293, 3094, 490, 8459, 13, 50874], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 329, "seek": 82616, "start": 836.36, "end": 839.92, "text": " That means no big tech biases or extortionate prices.", "tokens": [50874, 663, 1355, 572, 955, 7553, 32152, 420, 1279, 8136, 473, 7901, 13, 51052], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 330, "seek": 82616, "start": 839.92, "end": 843.76, "text": " Two, it's built on real page visits from actual humans,", "tokens": [51052, 4453, 11, 309, 311, 3094, 322, 957, 3028, 17753, 490, 3539, 6255, 11, 51244], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 331, "seek": 82616, "start": 843.76, "end": 845.64, "text": " collected anonymously, of course,", "tokens": [51244, 11087, 37293, 5098, 11, 295, 1164, 11, 51338], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 332, "seek": 82616, "start": 845.64, "end": 848.1999999999999, "text": " which filters out tons of junk data.", "tokens": [51338, 597, 15995, 484, 9131, 295, 19109, 1412, 13, 51466], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 333, "seek": 82616, "start": 848.1999999999999, "end": 850.0, "text": " And three, the index is refreshed", "tokens": [51466, 400, 1045, 11, 264, 8186, 307, 46330, 51556], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 334, "seek": 82616, "start": 850.0, "end": 852.0799999999999, "text": " with tens of millions of pages daily,", "tokens": [51556, 365, 10688, 295, 6803, 295, 7183, 5212, 11, 51660], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 335, "seek": 82616, "start": 852.0799999999999, "end": 855.4, "text": " so it always has accurate up-to-date information.", "tokens": [51660, 370, 309, 1009, 575, 8559, 493, 12, 1353, 12, 17393, 1589, 13, 51826], "temperature": 0.0, "avg_logprob": -0.07575703430175781, "compression_ratio": 1.606164383561644, "no_speech_prob": 0.00857593398541212}, {"id": 336, "seek": 85540, "start": 855.4, "end": 858.4, "text": " The Brave Search API can be used to assemble a dataset", "tokens": [50364, 440, 38545, 17180, 9362, 393, 312, 1143, 281, 22364, 257, 28872, 50514], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 337, "seek": 85540, "start": 858.4, "end": 860.0, "text": " to train your AI models", "tokens": [50514, 281, 3847, 428, 7318, 5245, 50594], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 338, "seek": 85540, "start": 860.0, "end": 861.72, "text": " and help with retrieval augmentation", "tokens": [50594, 293, 854, 365, 19817, 3337, 14501, 19631, 50680], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 339, "seek": 85540, "start": 861.72, "end": 863.36, "text": " at the time of inference,", "tokens": [50680, 412, 264, 565, 295, 38253, 11, 50762], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 340, "seek": 85540, "start": 863.36, "end": 864.64, "text": " all while remaining affordable", "tokens": [50762, 439, 1339, 8877, 12028, 50826], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 341, "seek": 85540, "start": 864.64, "end": 866.88, "text": " with developer-first pricing.", "tokens": [50826, 365, 10754, 12, 29581, 17621, 13, 50938], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 342, "seek": 85540, "start": 866.88, "end": 869.72, "text": " Integrating the Brave Search API into your workflow", "tokens": [50938, 23894, 990, 264, 38545, 17180, 9362, 666, 428, 20993, 51080], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 343, "seek": 85540, "start": 869.72, "end": 871.76, "text": " translates to more ethical data sourcing", "tokens": [51080, 28468, 281, 544, 18890, 1412, 11006, 2175, 51182], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 344, "seek": 85540, "start": 871.76, "end": 874.52, "text": " and more human-representative datasets.", "tokens": [51182, 293, 544, 1952, 12, 19919, 11662, 1166, 42856, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 345, "seek": 85540, "start": 874.52, "end": 876.6, "text": " Try the Brave Search API for free", "tokens": [51320, 6526, 264, 38545, 17180, 9362, 337, 1737, 51424], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 346, "seek": 85540, "start": 876.6, "end": 880.8, "text": " for up to 2,000 queries per month at brave.com slash API.", "tokens": [51424, 337, 493, 281, 568, 11, 1360, 24109, 680, 1618, 412, 12653, 13, 1112, 17330, 9362, 13, 51634], "temperature": 0.0, "avg_logprob": -0.1402669906616211, "compression_ratio": 1.6423076923076922, "no_speech_prob": 0.00020986318122595549}, {"id": 347, "seek": 88540, "start": 886.4, "end": 889.52, "text": " Pretty much all big, grand talk", "tokens": [50414, 10693, 709, 439, 955, 11, 2697, 751, 50570], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 348, "seek": 88540, "start": 890.8, "end": 895.28, "text": " is mostly oriented around people sharing values.", "tokens": [50634, 307, 5240, 21841, 926, 561, 5414, 4190, 13, 50858], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 349, "seek": 88540, "start": 896.28, "end": 898.72, "text": " That's what people want to do when they talk big politics,", "tokens": [50908, 663, 311, 437, 561, 528, 281, 360, 562, 436, 751, 955, 7341, 11, 51030], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 350, "seek": 88540, "start": 898.72, "end": 901.8, "text": " when they talk world politics or world events,", "tokens": [51030, 562, 436, 751, 1002, 7341, 420, 1002, 3931, 11, 51184], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 351, "seek": 88540, "start": 901.8, "end": 904.52, "text": " when they talk the future.", "tokens": [51184, 562, 436, 751, 264, 2027, 13, 51320], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 352, "seek": 88540, "start": 904.52, "end": 908.64, "text": " People want to jump quickly to, do I share your values?", "tokens": [51320, 3432, 528, 281, 3012, 2661, 281, 11, 360, 286, 2073, 428, 4190, 30, 51526], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 353, "seek": 88540, "start": 908.64, "end": 909.68, "text": " Here's my values.", "tokens": [51526, 1692, 311, 452, 4190, 13, 51578], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 354, "seek": 88540, "start": 909.68, "end": 910.52, "text": " What are your values?", "tokens": [51578, 708, 366, 428, 4190, 30, 51620], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 355, "seek": 88540, "start": 910.52, "end": 911.4399999999999, "text": " Do we agree on values?", "tokens": [51620, 1144, 321, 3986, 322, 4190, 30, 51666], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 356, "seek": 88540, "start": 911.4399999999999, "end": 912.72, "text": " Are we value buddies?", "tokens": [51666, 2014, 321, 2158, 30649, 30, 51730], "temperature": 0.0, "avg_logprob": -0.17004169117320667, "compression_ratio": 1.7438423645320198, "no_speech_prob": 0.020951738581061363}, {"id": 357, "seek": 91272, "start": 913.72, "end": 915.9200000000001, "text": " And people are so eager to get to that", "tokens": [50414, 400, 561, 366, 370, 18259, 281, 483, 281, 300, 50524], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 358, "seek": 91272, "start": 915.9200000000001, "end": 918.12, "text": " that they are willing to skip over", "tokens": [50524, 300, 436, 366, 4950, 281, 10023, 670, 50634], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 359, "seek": 91272, "start": 918.12, "end": 921.0400000000001, "text": " the analysis of the details, say,", "tokens": [50634, 264, 5215, 295, 264, 4365, 11, 584, 11, 50780], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 360, "seek": 91272, "start": 921.0400000000001, "end": 922.24, "text": " if they want to talk about, I don't know,", "tokens": [50780, 498, 436, 528, 281, 751, 466, 11, 286, 500, 380, 458, 11, 50840], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 361, "seek": 91272, "start": 922.24, "end": 924.0, "text": " the war in Ukraine.", "tokens": [50840, 264, 1516, 294, 14081, 13, 50928], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 362, "seek": 91272, "start": 924.0, "end": 925.84, "text": " People want to go, which side are you on?", "tokens": [50928, 3432, 528, 281, 352, 11, 597, 1252, 366, 291, 322, 30, 51020], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 363, "seek": 91272, "start": 925.84, "end": 928.8000000000001, "text": " And who, you know, do we have the right values", "tokens": [51020, 400, 567, 11, 291, 458, 11, 360, 321, 362, 264, 558, 4190, 51168], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 364, "seek": 91272, "start": 928.8000000000001, "end": 930.44, "text": " and then they don't care to talk about like,", "tokens": [51168, 293, 550, 436, 500, 380, 1127, 281, 751, 466, 411, 11, 51250], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 365, "seek": 91272, "start": 930.44, "end": 932.6, "text": " who has how much armaments that will run out soon", "tokens": [51250, 567, 575, 577, 709, 3726, 28401, 300, 486, 1190, 484, 2321, 51358], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 366, "seek": 91272, "start": 932.6, "end": 934.52, "text": " or who can afford what or what they,", "tokens": [51358, 420, 567, 393, 6157, 437, 420, 437, 436, 11, 51454], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 367, "seek": 91272, "start": 934.52, "end": 935.96, "text": " you know, all those details of the war.", "tokens": [51454, 291, 458, 11, 439, 729, 4365, 295, 264, 1516, 13, 51526], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 368, "seek": 91272, "start": 935.96, "end": 937.4, "text": " They don't want to go there.", "tokens": [51526, 814, 500, 380, 528, 281, 352, 456, 13, 51598], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 369, "seek": 91272, "start": 937.4, "end": 940.5600000000001, "text": " They just want to go to the values and agree about it.", "tokens": [51598, 814, 445, 528, 281, 352, 281, 264, 4190, 293, 3986, 466, 309, 13, 51756], "temperature": 0.0, "avg_logprob": -0.17145705532718014, "compression_ratio": 1.896678966789668, "no_speech_prob": 0.0018666990799829364}, {"id": 370, "seek": 94056, "start": 941.56, "end": 943.1999999999999, "text": " And that happens in the future too,", "tokens": [50414, 400, 300, 2314, 294, 264, 2027, 886, 11, 50496], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 371, "seek": 94056, "start": 943.1999999999999, "end": 944.04, "text": " futurism too.", "tokens": [50496, 25840, 1434, 886, 13, 50538], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 372, "seek": 94056, "start": 944.04, "end": 945.1199999999999, "text": " People just want to jump to the values.", "tokens": [50538, 3432, 445, 528, 281, 3012, 281, 264, 4190, 13, 50592], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 373, "seek": 94056, "start": 945.1199999999999, "end": 947.88, "text": " So for the purposes people have,", "tokens": [50592, 407, 337, 264, 9932, 561, 362, 11, 50730], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 374, "seek": 94056, "start": 947.88, "end": 949.16, "text": " they're doing roughly the right thing.", "tokens": [50730, 436, 434, 884, 9810, 264, 558, 551, 13, 50794], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 375, "seek": 94056, "start": 949.16, "end": 950.8, "text": " They don't really care about the world", "tokens": [50794, 814, 500, 380, 534, 1127, 466, 264, 1002, 50876], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 376, "seek": 94056, "start": 950.8, "end": 952.1999999999999, "text": " and they don't really care about the future.", "tokens": [50876, 293, 436, 500, 380, 534, 1127, 466, 264, 2027, 13, 50946], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 377, "seek": 94056, "start": 952.1999999999999, "end": 955.64, "text": " What they care about is finding value buddies", "tokens": [50946, 708, 436, 1127, 466, 307, 5006, 2158, 30649, 51118], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 378, "seek": 94056, "start": 955.64, "end": 959.28, "text": " or if you find a value conflict, having a value war.", "tokens": [51118, 420, 498, 291, 915, 257, 2158, 6596, 11, 1419, 257, 2158, 1516, 13, 51300], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 379, "seek": 94056, "start": 959.28, "end": 961.4399999999999, "text": " That's what people just want to do.", "tokens": [51300, 663, 311, 437, 561, 445, 528, 281, 360, 13, 51408], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 380, "seek": 94056, "start": 961.4399999999999, "end": 965.0799999999999, "text": " And so if you actually want to figure out the world", "tokens": [51408, 400, 370, 498, 291, 767, 528, 281, 2573, 484, 264, 1002, 51590], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 381, "seek": 94056, "start": 965.0799999999999, "end": 967.8399999999999, "text": " or national politics or national policy", "tokens": [51590, 420, 4048, 7341, 420, 4048, 3897, 51728], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 382, "seek": 94056, "start": 967.8399999999999, "end": 969.8399999999999, "text": " or you want to figure out the future,", "tokens": [51728, 420, 291, 528, 281, 2573, 484, 264, 2027, 11, 51828], "temperature": 0.0, "avg_logprob": -0.10536153074623882, "compression_ratio": 1.9921875, "no_speech_prob": 0.0007670754566788673}, {"id": 383, "seek": 96984, "start": 969.9200000000001, "end": 971.4, "text": " you really have to resist that", "tokens": [50368, 291, 534, 362, 281, 4597, 300, 50442], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 384, "seek": 96984, "start": 971.4, "end": 975.84, "text": " and you have to try to pause and, you know,", "tokens": [50442, 293, 291, 362, 281, 853, 281, 10465, 293, 11, 291, 458, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 385, "seek": 96984, "start": 975.84, "end": 978.5600000000001, "text": " go through an analysis first, a neutral analysis", "tokens": [50664, 352, 807, 364, 5215, 700, 11, 257, 10598, 5215, 50800], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 386, "seek": 96984, "start": 978.5600000000001, "end": 980.6800000000001, "text": " of what the options are, what the situation is.", "tokens": [50800, 295, 437, 264, 3956, 366, 11, 437, 264, 2590, 307, 13, 50906], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 387, "seek": 96984, "start": 980.6800000000001, "end": 984.6800000000001, "text": " I mean, I am afraid literally that if I express many values", "tokens": [50906, 286, 914, 11, 286, 669, 4638, 3736, 300, 498, 286, 5109, 867, 4190, 51106], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 388, "seek": 96984, "start": 984.6800000000001, "end": 986.84, "text": " that the discussion will just go there", "tokens": [51106, 300, 264, 5017, 486, 445, 352, 456, 51214], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 389, "seek": 96984, "start": 986.84, "end": 988.6, "text": " and you'll never talk about anything else.", "tokens": [51214, 293, 291, 603, 1128, 751, 466, 1340, 1646, 13, 51302], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 390, "seek": 96984, "start": 988.6, "end": 991.64, "text": " And that's why I resist talking about that.", "tokens": [51302, 400, 300, 311, 983, 286, 4597, 1417, 466, 300, 13, 51454], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 391, "seek": 96984, "start": 991.64, "end": 994.0400000000001, "text": " But I think, you know, my simplest value", "tokens": [51454, 583, 286, 519, 11, 291, 458, 11, 452, 22811, 2158, 51574], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 392, "seek": 96984, "start": 994.0400000000001, "end": 996.76, "text": " with respect to the future is I really like the fact", "tokens": [51574, 365, 3104, 281, 264, 2027, 307, 286, 534, 411, 264, 1186, 51710], "temperature": 0.0, "avg_logprob": -0.10072821776072184, "compression_ratio": 1.7413127413127414, "no_speech_prob": 0.0007094856118783355}, {"id": 393, "seek": 99676, "start": 996.76, "end": 1001.28, "text": " that humanity has grown and achieved vast things", "tokens": [50364, 300, 10243, 575, 7709, 293, 11042, 8369, 721, 50590], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 394, "seek": 99676, "start": 1001.28, "end": 1002.64, "text": " compared to where it started.", "tokens": [50590, 5347, 281, 689, 309, 1409, 13, 50658], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 395, "seek": 99676, "start": 1002.64, "end": 1005.16, "text": " We're on this upward growth trajectory.", "tokens": [50658, 492, 434, 322, 341, 23452, 4599, 21512, 13, 50784], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 396, "seek": 99676, "start": 1005.16, "end": 1008.4399999999999, "text": " We have the potential to taking a big chunk of the universe", "tokens": [50784, 492, 362, 264, 3995, 281, 1940, 257, 955, 16635, 295, 264, 6445, 50948], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 397, "seek": 99676, "start": 1009.4, "end": 1010.88, "text": " and doing things with it.", "tokens": [50996, 293, 884, 721, 365, 309, 13, 51070], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 398, "seek": 99676, "start": 1010.88, "end": 1012.72, "text": " And I'm excited by that potential.", "tokens": [51070, 400, 286, 478, 2919, 538, 300, 3995, 13, 51162], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 399, "seek": 99676, "start": 1012.72, "end": 1016.72, "text": " So my first cut is I want us to keep growing.", "tokens": [51162, 407, 452, 700, 1723, 307, 286, 528, 505, 281, 1066, 4194, 13, 51362], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 400, "seek": 99676, "start": 1016.72, "end": 1020.68, "text": " And I see how much we've changed to get to where we are.", "tokens": [51362, 400, 286, 536, 577, 709, 321, 600, 3105, 281, 483, 281, 689, 321, 366, 13, 51560], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 401, "seek": 99676, "start": 1020.68, "end": 1023.6, "text": " And I can see that had people from a million years ago", "tokens": [51560, 400, 286, 393, 536, 300, 632, 561, 490, 257, 2459, 924, 2057, 51706], "temperature": 0.0, "avg_logprob": -0.09520949604355286, "compression_ratio": 1.620408163265306, "no_speech_prob": 0.001098439795896411}, {"id": 402, "seek": 102360, "start": 1023.6, "end": 1026.92, "text": " insisted that their values be maintained", "tokens": [50364, 28456, 300, 641, 4190, 312, 17578, 50530], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 403, "seek": 102360, "start": 1026.92, "end": 1030.16, "text": " and that the world be familiar and comfortable to them.", "tokens": [50530, 293, 300, 264, 1002, 312, 4963, 293, 4619, 281, 552, 13, 50692], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 404, "seek": 102360, "start": 1030.16, "end": 1032.16, "text": " If they've been able to enforce that,", "tokens": [50692, 759, 436, 600, 668, 1075, 281, 24825, 300, 11, 50792], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 405, "seek": 102360, "start": 1032.16, "end": 1035.08, "text": " we would not have gotten where we are now.", "tokens": [50792, 321, 576, 406, 362, 5768, 689, 321, 366, 586, 13, 50938], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 406, "seek": 102360, "start": 1035.08, "end": 1036.76, "text": " That would have prevented a lot of change.", "tokens": [50938, 663, 576, 362, 27314, 257, 688, 295, 1319, 13, 51022], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 407, "seek": 102360, "start": 1036.76, "end": 1039.96, "text": " So I kind of see that if I want us to get big and grand,", "tokens": [51022, 407, 286, 733, 295, 536, 300, 498, 286, 528, 505, 281, 483, 955, 293, 2697, 11, 51182], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 408, "seek": 102360, "start": 1039.96, "end": 1042.84, "text": " I'm gonna have to give a lot on", "tokens": [51182, 286, 478, 799, 362, 281, 976, 257, 688, 322, 51326], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 409, "seek": 102360, "start": 1042.84, "end": 1046.56, "text": " how similar the future is to me and my world.", "tokens": [51326, 577, 2531, 264, 2027, 307, 281, 385, 293, 452, 1002, 13, 51512], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 410, "seek": 102360, "start": 1046.56, "end": 1048.52, "text": " I'm gonna have to compromise a lot on that.", "tokens": [51512, 286, 478, 799, 362, 281, 18577, 257, 688, 322, 300, 13, 51610], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 411, "seek": 102360, "start": 1048.52, "end": 1050.16, "text": " I just don't see any way around that.", "tokens": [51610, 286, 445, 500, 380, 536, 604, 636, 926, 300, 13, 51692], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 412, "seek": 102360, "start": 1050.16, "end": 1052.56, "text": " So I get it that if you want the future", "tokens": [51692, 407, 286, 483, 309, 300, 498, 291, 528, 264, 2027, 51812], "temperature": 0.0, "avg_logprob": -0.12814913076512954, "compression_ratio": 1.8206106870229009, "no_speech_prob": 0.0052185566164553165}, {"id": 413, "seek": 105256, "start": 1052.56, "end": 1053.84, "text": " to be really comfortable for you", "tokens": [50364, 281, 312, 534, 4619, 337, 291, 50428], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 414, "seek": 105256, "start": 1053.84, "end": 1056.32, "text": " and to share a lot of your values and your styles,", "tokens": [50428, 293, 281, 2073, 257, 688, 295, 428, 4190, 293, 428, 13273, 11, 50552], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 415, "seek": 105256, "start": 1056.32, "end": 1059.32, "text": " you're gonna have to prevent it from changing.", "tokens": [50552, 291, 434, 799, 362, 281, 4871, 309, 490, 4473, 13, 50702], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 416, "seek": 105256, "start": 1059.32, "end": 1061.44, "text": " And you may have a shot at that.", "tokens": [50702, 400, 291, 815, 362, 257, 3347, 412, 300, 13, 50808], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 417, "seek": 105256, "start": 1061.44, "end": 1063.84, "text": " I would not like that, but you might.", "tokens": [50808, 286, 576, 406, 411, 300, 11, 457, 291, 1062, 13, 50928], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 418, "seek": 105256, "start": 1063.84, "end": 1066.3999999999999, "text": " So again, even as part of the value framework,", "tokens": [50928, 407, 797, 11, 754, 382, 644, 295, 264, 2158, 8388, 11, 51056], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 419, "seek": 105256, "start": 1066.3999999999999, "end": 1067.76, "text": " even when I talk values with you,", "tokens": [51056, 754, 562, 286, 751, 4190, 365, 291, 11, 51124], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 420, "seek": 105256, "start": 1067.76, "end": 1070.32, "text": " I want to be clear to distinguish", "tokens": [51124, 286, 528, 281, 312, 1850, 281, 20206, 51252], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 421, "seek": 105256, "start": 1070.32, "end": 1071.84, "text": " my value talk from the factual talk.", "tokens": [51252, 452, 2158, 751, 490, 264, 48029, 751, 13, 51328], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 422, "seek": 105256, "start": 1071.84, "end": 1073.8799999999999, "text": " I'm gonna be happy to tell you", "tokens": [51328, 286, 478, 799, 312, 2055, 281, 980, 291, 51430], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 423, "seek": 105256, "start": 1073.8799999999999, "end": 1076.6399999999999, "text": " what it would take for you to get your values,", "tokens": [51430, 437, 309, 576, 747, 337, 291, 281, 483, 428, 4190, 11, 51568], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 424, "seek": 105256, "start": 1076.6399999999999, "end": 1078.6, "text": " even if they aren't mine.", "tokens": [51568, 754, 498, 436, 3212, 380, 3892, 13, 51666], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 425, "seek": 105256, "start": 1078.6, "end": 1082.24, "text": " So maybe we should talk about the facts of LLMs.", "tokens": [51666, 407, 1310, 321, 820, 751, 466, 264, 9130, 295, 441, 43, 26386, 13, 51848], "temperature": 0.0, "avg_logprob": -0.09509738715919289, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0013246574671939015}, {"id": 426, "seek": 108224, "start": 1082.24, "end": 1085.68, "text": " You wanna go there in terms of comparing Ms and LLMs, right?", "tokens": [50364, 509, 1948, 352, 456, 294, 2115, 295, 15763, 7741, 293, 441, 43, 26386, 11, 558, 30, 50536], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 427, "seek": 108224, "start": 1085.68, "end": 1087.28, "text": " So first of all, our audience,", "tokens": [50536, 407, 700, 295, 439, 11, 527, 4034, 11, 50616], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 428, "seek": 108224, "start": 1087.28, "end": 1089.1200000000001, "text": " we should say for our audience,", "tokens": [50616, 321, 820, 584, 337, 527, 4034, 11, 50708], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 429, "seek": 108224, "start": 1089.1200000000001, "end": 1092.24, "text": " my book Age of M is about brain emulations.", "tokens": [50708, 452, 1446, 16280, 295, 376, 307, 466, 3567, 846, 4136, 13, 50864], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 430, "seek": 108224, "start": 1092.24, "end": 1094.84, "text": " So that's where you take a particular human brain", "tokens": [50864, 407, 300, 311, 689, 291, 747, 257, 1729, 1952, 3567, 50994], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 431, "seek": 108224, "start": 1094.84, "end": 1097.72, "text": " and you scan it and find spatial chemical detail", "tokens": [50994, 293, 291, 11049, 309, 293, 915, 23598, 7313, 2607, 51138], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 432, "seek": 108224, "start": 1097.72, "end": 1099.72, "text": " to figure out which cells are where,", "tokens": [51138, 281, 2573, 484, 597, 5438, 366, 689, 11, 51238], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 433, "seek": 108224, "start": 1099.72, "end": 1102.76, "text": " connected to other cells through what synapses.", "tokens": [51238, 4582, 281, 661, 5438, 807, 437, 5451, 2382, 279, 13, 51390], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 434, "seek": 108224, "start": 1102.76, "end": 1104.88, "text": " You make a map of that,", "tokens": [51390, 509, 652, 257, 4471, 295, 300, 11, 51496], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 435, "seek": 108224, "start": 1104.88, "end": 1108.96, "text": " and then you make a computer model that matches that map", "tokens": [51496, 293, 550, 291, 652, 257, 3820, 2316, 300, 10676, 300, 4471, 51700], "temperature": 0.0, "avg_logprob": -0.15377129626875163, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0003682384267449379}, {"id": 436, "seek": 110896, "start": 1109.96, "end": 1111.8400000000001, "text": " where you fill in for each cell,", "tokens": [50414, 689, 291, 2836, 294, 337, 1184, 2815, 11, 50508], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 437, "seek": 110896, "start": 1111.8400000000001, "end": 1113.56, "text": " a computer model of that cell.", "tokens": [50508, 257, 3820, 2316, 295, 300, 2815, 13, 50594], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 438, "seek": 110896, "start": 1113.56, "end": 1115.16, "text": " And if you've got good enough models for cells", "tokens": [50594, 400, 498, 291, 600, 658, 665, 1547, 5245, 337, 5438, 50674], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 439, "seek": 110896, "start": 1115.16, "end": 1116.3600000000001, "text": " and a good map of the brain,", "tokens": [50674, 293, 257, 665, 4471, 295, 264, 3567, 11, 50734], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 440, "seek": 110896, "start": 1116.3600000000001, "end": 1118.64, "text": " then basically the IO of this model", "tokens": [50734, 550, 1936, 264, 39839, 295, 341, 2316, 50848], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 441, "seek": 110896, "start": 1118.64, "end": 1120.68, "text": " should be the same as the IO of the original brain,", "tokens": [50848, 820, 312, 264, 912, 382, 264, 39839, 295, 264, 3380, 3567, 11, 50950], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 442, "seek": 110896, "start": 1120.68, "end": 1121.68, "text": " which means you could hook it up", "tokens": [50950, 597, 1355, 291, 727, 6328, 309, 493, 51000], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 443, "seek": 110896, "start": 1121.68, "end": 1124.4, "text": " with artificial eyes, ears, hands, mouth.", "tokens": [51000, 365, 11677, 2575, 11, 8798, 11, 2377, 11, 4525, 13, 51136], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 444, "seek": 110896, "start": 1124.4, "end": 1125.88, "text": " And then it would behave the same", "tokens": [51136, 400, 550, 309, 576, 15158, 264, 912, 51210], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 445, "seek": 110896, "start": 1125.88, "end": 1129.44, "text": " as the original human would in the same situation,", "tokens": [51210, 382, 264, 3380, 1952, 576, 294, 264, 912, 2590, 11, 51388], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 446, "seek": 110896, "start": 1129.44, "end": 1132.48, "text": " in which case you can use these as substitutes for humans", "tokens": [51388, 294, 597, 1389, 291, 393, 764, 613, 382, 26441, 1819, 337, 6255, 51540], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 447, "seek": 110896, "start": 1132.48, "end": 1134.08, "text": " throughout the entire economy.", "tokens": [51540, 3710, 264, 2302, 5010, 13, 51620], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 448, "seek": 110896, "start": 1134.08, "end": 1136.2, "text": " And then my exercise of the Age of M book", "tokens": [51620, 400, 550, 452, 5380, 295, 264, 16280, 295, 376, 1446, 51726], "temperature": 0.0, "avg_logprob": -0.09544309656670753, "compression_ratio": 1.85, "no_speech_prob": 0.0002304841036675498}, {"id": 449, "seek": 113620, "start": 1136.24, "end": 1139.52, "text": " was to figure out what that word looks like.", "tokens": [50366, 390, 281, 2573, 484, 437, 300, 1349, 1542, 411, 13, 50530], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 450, "seek": 113620, "start": 1139.52, "end": 1143.52, "text": " And a primary purpose was to actually be able to show", "tokens": [50530, 400, 257, 6194, 4334, 390, 281, 767, 312, 1075, 281, 855, 50730], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 451, "seek": 113620, "start": 1143.52, "end": 1145.3600000000001, "text": " that it's possible to do that sort of thing.", "tokens": [50730, 300, 309, 311, 1944, 281, 360, 300, 1333, 295, 551, 13, 50822], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 452, "seek": 113620, "start": 1145.3600000000001, "end": 1148.28, "text": " It's possible to take a specific technical assumption", "tokens": [50822, 467, 311, 1944, 281, 747, 257, 2685, 6191, 15302, 50968], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 453, "seek": 113620, "start": 1148.28, "end": 1149.88, "text": " and work out a lot of consequences.", "tokens": [50968, 293, 589, 484, 257, 688, 295, 10098, 13, 51048], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 454, "seek": 113620, "start": 1149.88, "end": 1153.68, "text": " And many people have said they didn't want so many details.", "tokens": [51048, 400, 867, 561, 362, 848, 436, 994, 380, 528, 370, 867, 4365, 13, 51238], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 455, "seek": 113620, "start": 1153.68, "end": 1155.28, "text": " They'd rather have fiction or something else,", "tokens": [51238, 814, 1116, 2831, 362, 13266, 420, 746, 1646, 11, 51318], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 456, "seek": 113620, "start": 1155.28, "end": 1157.44, "text": " but I was trying to prove how much I could say.", "tokens": [51318, 457, 286, 390, 1382, 281, 7081, 577, 709, 286, 727, 584, 13, 51426], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 457, "seek": 113620, "start": 1157.44, "end": 1160.16, "text": " And I hope you'll admit, I proved I could say a lot.", "tokens": [51426, 400, 286, 1454, 291, 603, 9796, 11, 286, 14617, 286, 727, 584, 257, 688, 13, 51562], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 458, "seek": 113620, "start": 1161.4, "end": 1165.2, "text": " And that almost no other futurist work does that.", "tokens": [51624, 400, 300, 1920, 572, 661, 25840, 468, 589, 775, 300, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1266347579373658, "compression_ratio": 1.7437722419928825, "no_speech_prob": 0.005909094121307135}, {"id": 459, "seek": 116520, "start": 1165.24, "end": 1167.16, "text": " And so I'm trying to inspire other futurists", "tokens": [50366, 400, 370, 286, 478, 1382, 281, 15638, 661, 25840, 1751, 50462], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 460, "seek": 116520, "start": 1167.16, "end": 1169.0, "text": " to get into that level of detail,", "tokens": [50462, 281, 483, 666, 300, 1496, 295, 2607, 11, 50554], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 461, "seek": 116520, "start": 1169.0, "end": 1170.52, "text": " to try to take some assumptions", "tokens": [50554, 281, 853, 281, 747, 512, 17695, 50630], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 462, "seek": 116520, "start": 1170.52, "end": 1171.52, "text": " and work out a lot of consequences.", "tokens": [50630, 293, 589, 484, 257, 688, 295, 10098, 13, 50680], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 463, "seek": 116520, "start": 1171.52, "end": 1173.8, "text": " So that's my book, The Age of M.", "tokens": [50680, 407, 300, 311, 452, 1446, 11, 440, 16280, 295, 376, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 464, "seek": 116520, "start": 1173.8, "end": 1176.32, "text": " You'd like us to compare that", "tokens": [50794, 509, 1116, 411, 505, 281, 6794, 300, 50920], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 465, "seek": 116520, "start": 1176.32, "end": 1178.56, "text": " to current large-language models", "tokens": [50920, 281, 2190, 2416, 12, 25241, 20473, 5245, 51032], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 466, "seek": 116520, "start": 1179.68, "end": 1181.16, "text": " and to think about what we can say", "tokens": [51088, 293, 281, 519, 466, 437, 321, 393, 584, 51162], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 467, "seek": 116520, "start": 1181.16, "end": 1183.16, "text": " about the future of large-language models.", "tokens": [51162, 466, 264, 2027, 295, 2416, 12, 25241, 20473, 5245, 13, 51262], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 468, "seek": 116520, "start": 1183.16, "end": 1187.28, "text": " So in my mind, the first thing to say there is,", "tokens": [51262, 407, 294, 452, 1575, 11, 264, 700, 551, 281, 584, 456, 307, 11, 51468], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 469, "seek": 116520, "start": 1187.28, "end": 1191.56, "text": " well, an M is a full human substitute.", "tokens": [51468, 731, 11, 364, 376, 307, 257, 1577, 1952, 15802, 13, 51682], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 470, "seek": 116520, "start": 1191.56, "end": 1194.3, "text": " It can do everything a human can do, basically.", "tokens": [51682, 467, 393, 360, 1203, 257, 1952, 393, 360, 11, 1936, 13, 51819], "temperature": 0.0, "avg_logprob": -0.1175402812103727, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.00013132370077073574}, {"id": 471, "seek": 119520, "start": 1195.56, "end": 1197.8400000000001, "text": " A large-language model is not that yet.", "tokens": [50382, 316, 2416, 12, 25241, 20473, 2316, 307, 406, 300, 1939, 13, 50496], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 472, "seek": 119520, "start": 1199.44, "end": 1202.28, "text": " So a key question here would be,", "tokens": [50576, 407, 257, 2141, 1168, 510, 576, 312, 11, 50718], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 473, "seek": 119520, "start": 1202.28, "end": 1205.0, "text": " how far are we going to go in trying to imagine", "tokens": [50718, 577, 1400, 366, 321, 516, 281, 352, 294, 1382, 281, 3811, 50854], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 474, "seek": 119520, "start": 1205.0, "end": 1207.1200000000001, "text": " a descendant of a large-language model", "tokens": [50854, 257, 16333, 394, 295, 257, 2416, 12, 25241, 20473, 2316, 50960], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 475, "seek": 119520, "start": 1207.1200000000001, "end": 1210.32, "text": " that is more capable of substituting", "tokens": [50960, 300, 307, 544, 8189, 295, 26441, 10861, 51120], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 476, "seek": 119520, "start": 1210.32, "end": 1212.7, "text": " for humans across a wide range of contexts?", "tokens": [51120, 337, 6255, 2108, 257, 4874, 3613, 295, 30628, 30, 51239], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 477, "seek": 119520, "start": 1212.7, "end": 1214.38, "text": " We stick with current large-language models.", "tokens": [51239, 492, 2897, 365, 2190, 2416, 12, 25241, 20473, 5245, 13, 51323], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 478, "seek": 119520, "start": 1214.38, "end": 1215.8400000000001, "text": " They're really only useful", "tokens": [51323, 814, 434, 534, 787, 4420, 51396], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 479, "seek": 119520, "start": 1215.8400000000001, "end": 1218.64, "text": " in a rather limited range of contexts.", "tokens": [51396, 294, 257, 2831, 5567, 3613, 295, 30628, 13, 51536], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 480, "seek": 119520, "start": 1218.64, "end": 1221.68, "text": " And so if you're gonna do forecasting of them,", "tokens": [51536, 400, 370, 498, 291, 434, 799, 360, 44331, 295, 552, 11, 51688], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 481, "seek": 119520, "start": 1221.68, "end": 1223.3400000000001, "text": " it's more like forecasting the future", "tokens": [51688, 309, 311, 544, 411, 44331, 264, 2027, 51771], "temperature": 0.0, "avg_logprob": -0.12780402317520015, "compression_ratio": 1.7301587301587302, "no_speech_prob": 0.00020982955174986273}, {"id": 482, "seek": 122334, "start": 1223.34, "end": 1225.76, "text": " with a microwave oven or something.", "tokens": [50364, 365, 257, 19025, 9090, 420, 746, 13, 50485], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 483, "seek": 122334, "start": 1225.76, "end": 1228.6999999999998, "text": " You think about, well, where can you use a microwave oven", "tokens": [50485, 509, 519, 466, 11, 731, 11, 689, 393, 291, 764, 257, 19025, 9090, 50632], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 484, "seek": 122334, "start": 1228.6999999999998, "end": 1229.82, "text": " and how much will it cost", "tokens": [50632, 293, 577, 709, 486, 309, 2063, 50688], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 485, "seek": 122334, "start": 1229.82, "end": 1233.4199999999998, "text": " and what other heating methods will it displace", "tokens": [50688, 293, 437, 661, 15082, 7150, 486, 309, 717, 6742, 50868], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 486, "seek": 122334, "start": 1234.4199999999998, "end": 1237.1399999999999, "text": " and what sort of inputs would be a compliment to that?", "tokens": [50918, 293, 437, 1333, 295, 15743, 576, 312, 257, 16250, 281, 300, 30, 51054], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 487, "seek": 122334, "start": 1237.1399999999999, "end": 1239.22, "text": " It would be more of a small-scale,", "tokens": [51054, 467, 576, 312, 544, 295, 257, 1359, 12, 20033, 11, 51158], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 488, "seek": 122334, "start": 1239.22, "end": 1241.8999999999999, "text": " future forecasting exercise.", "tokens": [51158, 2027, 44331, 5380, 13, 51292], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 489, "seek": 122334, "start": 1241.8999999999999, "end": 1245.34, "text": " Whereas The Age of M was purposely this very grand exercise", "tokens": [51292, 13813, 440, 16280, 295, 376, 390, 41840, 341, 588, 2697, 5380, 51464], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 490, "seek": 122334, "start": 1245.34, "end": 1248.72, "text": " because the M's actually change everything.", "tokens": [51464, 570, 264, 376, 311, 767, 1319, 1203, 13, 51633], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 491, "seek": 122334, "start": 1248.72, "end": 1251.3799999999999, "text": " Whereas most futurism, like if you're trying to analyze", "tokens": [51633, 13813, 881, 25840, 1434, 11, 411, 498, 291, 434, 1382, 281, 12477, 51766], "temperature": 0.0, "avg_logprob": -0.20598086976168448, "compression_ratio": 1.6457564575645756, "no_speech_prob": 0.0014547478640452027}, {"id": 492, "seek": 125138, "start": 1251.42, "end": 1253.5, "text": " consequences of microwave oven,", "tokens": [50366, 10098, 295, 19025, 9090, 11, 50470], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 493, "seek": 125138, "start": 1253.5, "end": 1255.22, "text": " you have a much more limited scope", "tokens": [50470, 291, 362, 257, 709, 544, 5567, 11923, 50556], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 494, "seek": 125138, "start": 1255.22, "end": 1258.42, "text": " because in fact, it'll have a limited impact.", "tokens": [50556, 570, 294, 1186, 11, 309, 603, 362, 257, 5567, 2712, 13, 50716], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 495, "seek": 125138, "start": 1258.42, "end": 1261.18, "text": " So that would be the question I have for you first,", "tokens": [50716, 407, 300, 576, 312, 264, 1168, 286, 362, 337, 291, 700, 11, 50854], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 496, "seek": 125138, "start": 1261.18, "end": 1264.8600000000001, "text": " which is, are we gonna talk about the implications", "tokens": [50854, 597, 307, 11, 366, 321, 799, 751, 466, 264, 16602, 51038], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 497, "seek": 125138, "start": 1264.8600000000001, "end": 1268.18, "text": " of something close to the current large-language models?", "tokens": [51038, 295, 746, 1998, 281, 264, 2190, 2416, 12, 25241, 20473, 5245, 30, 51204], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 498, "seek": 125138, "start": 1268.18, "end": 1271.98, "text": " Are we gonna try to imagine some generalized version", "tokens": [51204, 2014, 321, 799, 853, 281, 3811, 512, 44498, 3037, 51394], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 499, "seek": 125138, "start": 1271.98, "end": 1274.8600000000001, "text": " of them that has much wider capabilities?", "tokens": [51394, 295, 552, 300, 575, 709, 11842, 10862, 30, 51538], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 500, "seek": 125138, "start": 1274.8600000000001, "end": 1276.18, "text": " Yeah, very good question.", "tokens": [51538, 865, 11, 588, 665, 1168, 13, 51604], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 501, "seek": 125138, "start": 1276.18, "end": 1278.5800000000002, "text": " I think maybe two different levels of this", "tokens": [51604, 286, 519, 1310, 732, 819, 4358, 295, 341, 51724], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 502, "seek": 125138, "start": 1278.5800000000002, "end": 1280.74, "text": " would be instructive.", "tokens": [51724, 576, 312, 7232, 488, 13, 51832], "temperature": 0.0, "avg_logprob": -0.11014363704583584, "compression_ratio": 1.6534296028880866, "no_speech_prob": 0.0003919368318747729}, {"id": 503, "seek": 128074, "start": 1280.74, "end": 1282.18, "text": " One of the key things that jumps out", "tokens": [50364, 1485, 295, 264, 2141, 721, 300, 16704, 484, 50436], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 504, "seek": 128074, "start": 1282.18, "end": 1284.54, "text": " and I think a lot of stuff flows from", "tokens": [50436, 293, 286, 519, 257, 688, 295, 1507, 12867, 490, 50554], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 505, "seek": 128074, "start": 1284.54, "end": 1289.54, "text": " is the assumption that M's can be copied cheaply,", "tokens": [50554, 307, 264, 15302, 300, 376, 311, 393, 312, 25365, 7084, 356, 11, 50804], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 506, "seek": 128074, "start": 1290.3, "end": 1293.94, "text": " paused and stored indefinitely cheaply,", "tokens": [50842, 46860, 293, 12187, 24162, 10925, 7084, 356, 11, 51024], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 507, "seek": 128074, "start": 1293.94, "end": 1296.6200000000001, "text": " but not understood very well", "tokens": [51024, 457, 406, 7320, 588, 731, 51158], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 508, "seek": 128074, "start": 1296.6200000000001, "end": 1298.82, "text": " in terms of their internal mechanism.", "tokens": [51158, 294, 2115, 295, 641, 6920, 7513, 13, 51268], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 509, "seek": 128074, "start": 1298.82, "end": 1300.98, "text": " Very much like this similar understanding", "tokens": [51268, 4372, 709, 411, 341, 2531, 3701, 51376], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 510, "seek": 128074, "start": 1300.98, "end": 1302.14, "text": " to what we have of the brain", "tokens": [51376, 281, 437, 321, 362, 295, 264, 3567, 51434], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 511, "seek": 128074, "start": 1302.14, "end": 1303.94, "text": " where we can kind of poke and prod at it a little bit,", "tokens": [51434, 689, 321, 393, 733, 295, 19712, 293, 15792, 412, 309, 257, 707, 857, 11, 51524], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 512, "seek": 128074, "start": 1303.94, "end": 1305.38, "text": " but we really don't have a deep understanding", "tokens": [51524, 457, 321, 534, 500, 380, 362, 257, 2452, 3701, 51596], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 513, "seek": 128074, "start": 1305.38, "end": 1306.22, "text": " of how it works.", "tokens": [51596, 295, 577, 309, 1985, 13, 51638], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 514, "seek": 128074, "start": 1306.22, "end": 1309.42, "text": " We can't do like very localized optimizations,", "tokens": [51638, 492, 393, 380, 360, 411, 588, 44574, 5028, 14455, 11, 51798], "temperature": 0.0, "avg_logprob": -0.12327562816559322, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0003459274594206363}, {"id": 515, "seek": 130942, "start": 1309.42, "end": 1311.8200000000002, "text": " but we do have this like radical departure", "tokens": [50364, 457, 321, 360, 362, 341, 411, 12001, 25866, 50484], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 516, "seek": 130942, "start": 1311.8200000000002, "end": 1312.7, "text": " from the status quo,", "tokens": [50484, 490, 264, 6558, 28425, 11, 50528], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 517, "seek": 130942, "start": 1312.7, "end": 1315.42, "text": " which is you can infinitely clone them,", "tokens": [50528, 597, 307, 291, 393, 36227, 26506, 552, 11, 50664], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 518, "seek": 130942, "start": 1315.42, "end": 1318.78, "text": " you can infinitely freeze and store them.", "tokens": [50664, 291, 393, 36227, 15959, 293, 3531, 552, 13, 50832], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 519, "seek": 130942, "start": 1318.78, "end": 1320.8600000000001, "text": " And so this creates like all sorts of elasticities", "tokens": [50832, 400, 370, 341, 7829, 411, 439, 7527, 295, 17115, 1088, 50936], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 520, "seek": 130942, "start": 1320.8600000000001, "end": 1324.1000000000001, "text": " that just don't exist in the current environment.", "tokens": [50936, 300, 445, 500, 380, 2514, 294, 264, 2190, 2823, 13, 51098], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 521, "seek": 130942, "start": 1324.1000000000001, "end": 1325.98, "text": " So a number of those features are gonna be general", "tokens": [51098, 407, 257, 1230, 295, 729, 4122, 366, 799, 312, 2674, 51192], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 522, "seek": 130942, "start": 1325.98, "end": 1329.66, "text": " that anything that can be represented as computer files", "tokens": [51192, 300, 1340, 300, 393, 312, 10379, 382, 3820, 7098, 51376], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 523, "seek": 130942, "start": 1329.66, "end": 1331.46, "text": " and run on a computer.", "tokens": [51376, 293, 1190, 322, 257, 3820, 13, 51466], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 524, "seek": 130942, "start": 1332.3000000000002, "end": 1334.5, "text": " So any form of artificial intelligence", "tokens": [51508, 407, 604, 1254, 295, 11677, 7599, 51618], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 525, "seek": 130942, "start": 1334.5, "end": 1336.5, "text": " will be some of the sort in general", "tokens": [51618, 486, 312, 512, 295, 264, 1333, 294, 2674, 51718], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 526, "seek": 130942, "start": 1336.5, "end": 1338.78, "text": " that you could have a digital representation", "tokens": [51718, 300, 291, 727, 362, 257, 4562, 10290, 51832], "temperature": 0.0, "avg_logprob": -0.12067949279280733, "compression_ratio": 1.7403508771929825, "no_speech_prob": 8.479725511278957e-05}, {"id": 527, "seek": 133878, "start": 1338.78, "end": 1343.62, "text": " of archive it, make a copy of it, pause it,", "tokens": [50364, 295, 23507, 309, 11, 652, 257, 5055, 295, 309, 11, 10465, 309, 11, 50606], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 528, "seek": 133878, "start": 1343.62, "end": 1344.78, "text": " run it faster or slower,", "tokens": [50606, 1190, 309, 4663, 420, 14009, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 529, "seek": 133878, "start": 1344.78, "end": 1348.34, "text": " that's gonna be just generically true of any kind of AI,", "tokens": [50664, 300, 311, 799, 312, 445, 1337, 984, 2074, 295, 604, 733, 295, 7318, 11, 50842], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 530, "seek": 133878, "start": 1348.34, "end": 1349.26, "text": " including M's.", "tokens": [50842, 3009, 376, 311, 13, 50888], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 531, "seek": 133878, "start": 1350.74, "end": 1354.42, "text": " The ability to sort of modify it usefully,", "tokens": [50962, 440, 3485, 281, 1333, 295, 16927, 309, 764, 2277, 11, 51146], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 532, "seek": 133878, "start": 1354.42, "end": 1357.46, "text": " I mean, yes, with human brains initially,", "tokens": [51146, 286, 914, 11, 2086, 11, 365, 1952, 15442, 9105, 11, 51298], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 533, "seek": 133878, "start": 1357.46, "end": 1358.3, "text": " they're just a big mess,", "tokens": [51298, 436, 434, 445, 257, 955, 2082, 11, 51340], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 534, "seek": 133878, "start": 1358.3, "end": 1359.1399999999999, "text": " you don't understand them,", "tokens": [51340, 291, 500, 380, 1223, 552, 11, 51382], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 535, "seek": 133878, "start": 1359.1399999999999, "end": 1361.3799999999999, "text": " but honestly, most legacy software systems", "tokens": [51382, 457, 6095, 11, 881, 11711, 4722, 3652, 51494], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 536, "seek": 133878, "start": 1361.3799999999999, "end": 1362.22, "text": " are pretty similar.", "tokens": [51494, 366, 1238, 2531, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 537, "seek": 133878, "start": 1363.3, "end": 1365.94, "text": " So today, large legacy software systems,", "tokens": [51590, 407, 965, 11, 2416, 11711, 4722, 3652, 11, 51722], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 538, "seek": 133878, "start": 1365.94, "end": 1368.3799999999999, "text": " you mostly have to take them as they are.", "tokens": [51722, 291, 5240, 362, 281, 747, 552, 382, 436, 366, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1586186065673828, "compression_ratio": 1.608365019011407, "no_speech_prob": 0.00036825830466113985}, {"id": 539, "seek": 136838, "start": 1368.42, "end": 1370.98, "text": " You can only make modest modifications to them.", "tokens": [50366, 509, 393, 787, 652, 25403, 26881, 281, 552, 13, 50494], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 540, "seek": 136838, "start": 1371.9, "end": 1373.98, "text": " That's close to what I'm assuming for M's.", "tokens": [50540, 663, 311, 1998, 281, 437, 286, 478, 11926, 337, 376, 311, 13, 50644], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 541, "seek": 136838, "start": 1373.98, "end": 1376.8200000000002, "text": " So I'm actually not assuming that they are that different", "tokens": [50644, 407, 286, 478, 767, 406, 11926, 300, 436, 366, 300, 819, 50786], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 542, "seek": 136838, "start": 1376.8200000000002, "end": 1379.7, "text": " from large legacy software systems.", "tokens": [50786, 490, 2416, 11711, 4722, 3652, 13, 50930], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 543, "seek": 136838, "start": 1379.7, "end": 1381.46, "text": " They're just a big mess", "tokens": [50930, 814, 434, 445, 257, 955, 2082, 51018], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 544, "seek": 136838, "start": 1382.42, "end": 1384.94, "text": " that even though you could go look at any one piece", "tokens": [51066, 300, 754, 1673, 291, 727, 352, 574, 412, 604, 472, 2522, 51192], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 545, "seek": 136838, "start": 1384.94, "end": 1386.0200000000002, "text": " and maybe understand it,", "tokens": [51192, 293, 1310, 1223, 309, 11, 51246], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 546, "seek": 136838, "start": 1386.0200000000002, "end": 1387.8200000000002, "text": " that doesn't really help you usefully", "tokens": [51246, 300, 1177, 380, 534, 854, 291, 764, 2277, 51336], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 547, "seek": 136838, "start": 1387.8200000000002, "end": 1390.2600000000002, "text": " in modifying the entire thing.", "tokens": [51336, 294, 42626, 264, 2302, 551, 13, 51458], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 548, "seek": 136838, "start": 1390.2600000000002, "end": 1393.7800000000002, "text": " You basically have to take the whole thing as a unit", "tokens": [51458, 509, 1936, 362, 281, 747, 264, 1379, 551, 382, 257, 4985, 51634], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 549, "seek": 136838, "start": 1393.7800000000002, "end": 1397.38, "text": " and can only make some minor changes.", "tokens": [51634, 293, 393, 787, 652, 512, 6696, 2962, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12950702406402326, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00019714464724529535}, {"id": 550, "seek": 139738, "start": 1397.38, "end": 1398.66, "text": " But you can copy the whole thing,", "tokens": [50364, 583, 291, 393, 5055, 264, 1379, 551, 11, 50428], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 551, "seek": 139738, "start": 1398.66, "end": 1400.2600000000002, "text": " you can run it faster or slow,", "tokens": [50428, 291, 393, 1190, 309, 4663, 420, 2964, 11, 50508], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 552, "seek": 139738, "start": 1400.2600000000002, "end": 1401.3000000000002, "text": " you can move it at speed,", "tokens": [50508, 291, 393, 1286, 309, 412, 3073, 11, 50560], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 553, "seek": 139738, "start": 1401.3000000000002, "end": 1403.2600000000002, "text": " transfer at the speed of light around the earth", "tokens": [50560, 5003, 412, 264, 3073, 295, 1442, 926, 264, 4120, 50658], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 554, "seek": 139738, "start": 1403.2600000000002, "end": 1405.0600000000002, "text": " or through the universe.", "tokens": [50658, 420, 807, 264, 6445, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 555, "seek": 139738, "start": 1405.0600000000002, "end": 1408.3000000000002, "text": " Those things are true of pretty much any AI", "tokens": [50748, 3950, 721, 366, 2074, 295, 1238, 709, 604, 7318, 50910], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 556, "seek": 139738, "start": 1408.3000000000002, "end": 1410.74, "text": " that could be represented as a computer file,", "tokens": [50910, 300, 727, 312, 10379, 382, 257, 3820, 3991, 11, 51032], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 557, "seek": 139738, "start": 1410.74, "end": 1411.8600000000001, "text": " run on a computer.", "tokens": [51032, 1190, 322, 257, 3820, 13, 51088], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 558, "seek": 139738, "start": 1411.8600000000001, "end": 1415.3000000000002, "text": " Yeah, I think these dimensions are a really useful way", "tokens": [51088, 865, 11, 286, 519, 613, 12819, 366, 257, 534, 4420, 636, 51260], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 559, "seek": 139738, "start": 1415.3000000000002, "end": 1417.0200000000002, "text": " to break this down.", "tokens": [51260, 281, 1821, 341, 760, 13, 51346], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 560, "seek": 139738, "start": 1417.0200000000002, "end": 1420.1000000000001, "text": " I took some inspiration from you in a presentation", "tokens": [51346, 286, 1890, 512, 10249, 490, 291, 294, 257, 5860, 51500], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 561, "seek": 139738, "start": 1420.1000000000001, "end": 1422.5, "text": " that I created called the AI Scouting Report,", "tokens": [51500, 300, 286, 2942, 1219, 264, 7318, 2747, 24500, 16057, 11, 51620], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 562, "seek": 139738, "start": 1422.5, "end": 1425.38, "text": " where I have the tail of the cognitive tape", "tokens": [51620, 689, 286, 362, 264, 6838, 295, 264, 15605, 7314, 51764], "temperature": 0.0, "avg_logprob": -0.2005806980711041, "compression_ratio": 1.7003484320557491, "no_speech_prob": 4.1330848034704104e-05}, {"id": 563, "seek": 142538, "start": 1425.42, "end": 1428.3000000000002, "text": " that compares human strengths and weaknesses", "tokens": [50366, 300, 38334, 1952, 16986, 293, 24381, 50510], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 564, "seek": 142538, "start": 1428.3000000000002, "end": 1430.5, "text": " to LLM strengths and weaknesses.", "tokens": [50510, 281, 441, 43, 44, 16986, 293, 24381, 13, 50620], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 565, "seek": 142538, "start": 1430.5, "end": 1432.98, "text": " And I think for the purposes of this discussion,", "tokens": [50620, 400, 286, 519, 337, 264, 9932, 295, 341, 5017, 11, 50744], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 566, "seek": 142538, "start": 1432.98, "end": 1435.74, "text": " maybe we might even have like four different kind of things", "tokens": [50744, 1310, 321, 1062, 754, 362, 411, 1451, 819, 733, 295, 721, 50882], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 567, "seek": 142538, "start": 1435.74, "end": 1436.5800000000002, "text": " to consider.", "tokens": [50882, 281, 1949, 13, 50924], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 568, "seek": 142538, "start": 1436.5800000000002, "end": 1438.9, "text": " One is humans, second would be M's,", "tokens": [50924, 1485, 307, 6255, 11, 1150, 576, 312, 376, 311, 11, 51040], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 569, "seek": 142538, "start": 1438.9, "end": 1443.66, "text": " third is let's say transformer language models", "tokens": [51040, 2636, 307, 718, 311, 584, 31782, 2856, 5245, 51278], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 570, "seek": 142538, "start": 1443.66, "end": 1445.5800000000002, "text": " of the general class that we have today.", "tokens": [51278, 295, 264, 2674, 1508, 300, 321, 362, 965, 13, 51374], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 571, "seek": 142538, "start": 1445.5800000000002, "end": 1449.14, "text": " Although I think we can predictably expect at a minimum", "tokens": [51374, 5780, 286, 519, 321, 393, 6069, 1188, 2066, 412, 257, 7285, 51552], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 572, "seek": 142538, "start": 1449.14, "end": 1452.74, "text": " that they will continue to have longer context windows", "tokens": [51552, 300, 436, 486, 2354, 281, 362, 2854, 4319, 9309, 51732], "temperature": 0.0, "avg_logprob": -0.10814158715934397, "compression_ratio": 1.643939393939394, "no_speech_prob": 0.0008826259290799499}, {"id": 573, "seek": 145274, "start": 1452.74, "end": 1455.78, "text": " and have generally more pre-training", "tokens": [50364, 293, 362, 5101, 544, 659, 12, 17227, 1760, 50516], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 574, "seek": 145274, "start": 1455.78, "end": 1458.3, "text": " and generally more capability,", "tokens": [50516, 293, 5101, 544, 13759, 11, 50642], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 575, "seek": 145274, "start": 1458.3, "end": 1461.82, "text": " at least within a certain range.", "tokens": [50642, 412, 1935, 1951, 257, 1629, 3613, 13, 50818], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 576, "seek": 145274, "start": 1461.82, "end": 1463.7, "text": " And then the fourth one that I'm really interested in", "tokens": [50818, 400, 550, 264, 6409, 472, 300, 286, 478, 534, 3102, 294, 50912], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 577, "seek": 145274, "start": 1463.7, "end": 1467.02, "text": " and has been kind of an obsession for me recently", "tokens": [50912, 293, 575, 668, 733, 295, 364, 30521, 337, 385, 3938, 51078], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 578, "seek": 145274, "start": 1467.02, "end": 1471.34, "text": " is the new state space model paradigm,", "tokens": [51078, 307, 264, 777, 1785, 1901, 2316, 24709, 11, 51294], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 579, "seek": 145274, "start": 1471.34, "end": 1475.54, "text": " which actually has some things now in common again", "tokens": [51294, 597, 767, 575, 512, 721, 586, 294, 2689, 797, 51504], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 580, "seek": 145274, "start": 1475.54, "end": 1476.74, "text": " with the humans and the M's", "tokens": [51504, 365, 264, 6255, 293, 264, 376, 311, 51564], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 581, "seek": 145274, "start": 1476.74, "end": 1479.58, "text": " that the transformer models lack.", "tokens": [51564, 300, 264, 31782, 5245, 5011, 13, 51706], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 582, "seek": 145274, "start": 1479.58, "end": 1481.82, "text": " The state space models,", "tokens": [51706, 440, 1785, 1901, 5245, 11, 51818], "temperature": 0.0, "avg_logprob": -0.08059488024030413, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010553375614108518}, {"id": 583, "seek": 148182, "start": 1481.86, "end": 1483.98, "text": " this has been, of course, in a line of research", "tokens": [50366, 341, 575, 668, 11, 295, 1164, 11, 294, 257, 1622, 295, 2132, 50472], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 584, "seek": 148182, "start": 1483.98, "end": 1485.1799999999998, "text": " that's been going on for a couple of years,", "tokens": [50472, 300, 311, 668, 516, 322, 337, 257, 1916, 295, 924, 11, 50532], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 585, "seek": 148182, "start": 1485.1799999999998, "end": 1487.74, "text": " kind of in parallel with transformers.", "tokens": [50532, 733, 295, 294, 8952, 365, 4088, 433, 13, 50660], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 586, "seek": 148182, "start": 1487.74, "end": 1490.02, "text": " Transformers have taken up the vast majority", "tokens": [50660, 27938, 433, 362, 2726, 493, 264, 8369, 6286, 50774], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 587, "seek": 148182, "start": 1490.02, "end": 1493.34, "text": " of the energy in the public focus", "tokens": [50774, 295, 264, 2281, 294, 264, 1908, 1879, 50940], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 588, "seek": 148182, "start": 1493.34, "end": 1495.46, "text": " because they have been the highest performing", "tokens": [50940, 570, 436, 362, 668, 264, 6343, 10205, 51046], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 589, "seek": 148182, "start": 1495.46, "end": 1497.26, "text": " over the last couple of years.", "tokens": [51046, 670, 264, 1036, 1916, 295, 924, 13, 51136], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 590, "seek": 148182, "start": 1497.26, "end": 1502.26, "text": " But that has maybe just changed with a couple of recent papers,", "tokens": [51136, 583, 300, 575, 1310, 445, 3105, 365, 257, 1916, 295, 5162, 10577, 11, 51386], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 591, "seek": 148182, "start": 1503.5, "end": 1505.58, "text": " most notably one called Mamba,", "tokens": [51448, 881, 31357, 472, 1219, 376, 23337, 11, 51552], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 592, "seek": 148182, "start": 1505.58, "end": 1510.1399999999999, "text": " that basically shows parity, rough parity", "tokens": [51552, 300, 1936, 3110, 44747, 11, 5903, 44747, 51780], "temperature": 0.0, "avg_logprob": -0.14267429736776088, "compression_ratio": 1.726530612244898, "no_speech_prob": 0.00015841156709939241}, {"id": 593, "seek": 151014, "start": 1510.14, "end": 1512.3400000000001, "text": " with the transformer on kind of your standard", "tokens": [50364, 365, 264, 31782, 322, 733, 295, 428, 3832, 50474], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 594, "seek": 151014, "start": 1512.3400000000001, "end": 1514.3000000000002, "text": " language modeling tasks,", "tokens": [50474, 2856, 15983, 9608, 11, 50572], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 595, "seek": 151014, "start": 1514.3000000000002, "end": 1517.6200000000001, "text": " but does have like a totally different architecture", "tokens": [50572, 457, 775, 362, 411, 257, 3879, 819, 9482, 50738], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 596, "seek": 151014, "start": 1517.6200000000001, "end": 1521.66, "text": " that I think opens up like some notably different strengths", "tokens": [50738, 300, 286, 519, 9870, 493, 411, 512, 31357, 819, 16986, 50940], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 597, "seek": 151014, "start": 1521.66, "end": 1526.3400000000001, "text": " and weaknesses, whereas the transformer", "tokens": [50940, 293, 24381, 11, 9735, 264, 31782, 51174], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 598, "seek": 151014, "start": 1526.3400000000001, "end": 1528.18, "text": " really just has the weights", "tokens": [51174, 534, 445, 575, 264, 17443, 51266], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 599, "seek": 151014, "start": 1528.18, "end": 1531.1000000000001, "text": " and then the sort of next token prediction,", "tokens": [51266, 293, 550, 264, 1333, 295, 958, 14862, 17630, 11, 51412], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 600, "seek": 151014, "start": 1531.1000000000001, "end": 1533.5400000000002, "text": " the state space model has this additional concept", "tokens": [51412, 264, 1785, 1901, 2316, 575, 341, 4497, 3410, 51534], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 601, "seek": 151014, "start": 1533.5400000000002, "end": 1538.46, "text": " of the state, which is, and I recall from the book,", "tokens": [51534, 295, 264, 1785, 11, 597, 307, 11, 293, 286, 9901, 490, 264, 1446, 11, 51780], "temperature": 0.0, "avg_logprob": -0.121455078539641, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00041724106995388865}, {"id": 602, "seek": 153846, "start": 1538.46, "end": 1541.6200000000001, "text": " you sort of say, taking an information processing lens", "tokens": [50364, 291, 1333, 295, 584, 11, 1940, 364, 1589, 9007, 6765, 50522], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 603, "seek": 153846, "start": 1541.6200000000001, "end": 1545.9, "text": " to the human or where you spend more of your focuses", "tokens": [50522, 281, 264, 1952, 420, 689, 291, 3496, 544, 295, 428, 16109, 50736], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 604, "seek": 153846, "start": 1545.9, "end": 1549.82, "text": " on the M, you have the current state", "tokens": [50736, 322, 264, 376, 11, 291, 362, 264, 2190, 1785, 50932], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 605, "seek": 153846, "start": 1549.82, "end": 1554.3400000000001, "text": " plus some new input information, sensory or whatever,", "tokens": [50932, 1804, 512, 777, 4846, 1589, 11, 27233, 420, 2035, 11, 51158], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 606, "seek": 153846, "start": 1554.3400000000001, "end": 1558.3400000000001, "text": " and then that propagates into some action,", "tokens": [51158, 293, 550, 300, 12425, 1024, 666, 512, 3069, 11, 51358], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 607, "seek": 153846, "start": 1558.3400000000001, "end": 1562.02, "text": " some output and a new internal state.", "tokens": [51358, 512, 5598, 293, 257, 777, 6920, 1785, 13, 51542], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 608, "seek": 153846, "start": 1562.02, "end": 1563.18, "text": " And that I think is really the heart", "tokens": [51542, 400, 300, 286, 519, 307, 534, 264, 1917, 51600], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 609, "seek": 153846, "start": 1563.18, "end": 1565.3, "text": " of what the new state space models do", "tokens": [51600, 295, 437, 264, 777, 1785, 1901, 5245, 360, 51706], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 610, "seek": 153846, "start": 1565.3, "end": 1567.54, "text": " is that they add that additional component", "tokens": [51706, 307, 300, 436, 909, 300, 4497, 6542, 51818], "temperature": 0.0, "avg_logprob": -0.10718497276306152, "compression_ratio": 1.7186147186147187, "no_speech_prob": 0.001324760145507753}, {"id": 611, "seek": 156754, "start": 1567.54, "end": 1569.58, "text": " where they have not only the weights,", "tokens": [50364, 689, 436, 362, 406, 787, 264, 17443, 11, 50466], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 612, "seek": 156754, "start": 1569.58, "end": 1571.8999999999999, "text": " like a transformer has static weights,", "tokens": [50466, 411, 257, 31782, 575, 13437, 17443, 11, 50582], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 613, "seek": 156754, "start": 1571.8999999999999, "end": 1574.1399999999999, "text": " but they also have this state,", "tokens": [50582, 457, 436, 611, 362, 341, 1785, 11, 50694], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 614, "seek": 156754, "start": 1574.1399999999999, "end": 1578.1, "text": " which is of a fixed size, evolves through time,", "tokens": [50694, 597, 307, 295, 257, 6806, 2744, 11, 43737, 807, 565, 11, 50892], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 615, "seek": 156754, "start": 1578.1, "end": 1579.78, "text": " and is something that gets output", "tokens": [50892, 293, 307, 746, 300, 2170, 5598, 50976], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 616, "seek": 156754, "start": 1579.78, "end": 1581.98, "text": " at each kind of inference step", "tokens": [50976, 412, 1184, 733, 295, 38253, 1823, 51086], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 617, "seek": 156754, "start": 1581.98, "end": 1583.78, "text": " so that there is this internal state", "tokens": [51086, 370, 300, 456, 307, 341, 6920, 1785, 51176], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 618, "seek": 156754, "start": 1583.78, "end": 1586.22, "text": " that propagates through time", "tokens": [51176, 300, 12425, 1024, 807, 565, 51298], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 619, "seek": 156754, "start": 1586.22, "end": 1589.06, "text": " and can kind of change and have long history.", "tokens": [51298, 293, 393, 733, 295, 1319, 293, 362, 938, 2503, 13, 51440], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 620, "seek": 156754, "start": 1589.8999999999999, "end": 1594.8999999999999, "text": " I think it is likely to bring about", "tokens": [51482, 286, 519, 309, 307, 3700, 281, 1565, 466, 51732], "temperature": 0.0, "avg_logprob": -0.09528164027892437, "compression_ratio": 1.727699530516432, "no_speech_prob": 0.00031499177566729486}, {"id": 621, "seek": 159490, "start": 1594.94, "end": 1599.94, "text": " a much more integrated medium and long-term memory", "tokens": [50366, 257, 709, 544, 10919, 6399, 293, 938, 12, 7039, 4675, 50616], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 622, "seek": 159490, "start": 1600.02, "end": 1601.94, "text": " than the transformers have", "tokens": [50620, 813, 264, 4088, 433, 362, 50716], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 623, "seek": 159490, "start": 1601.94, "end": 1606.94, "text": " and create more sort of long episode conditioning", "tokens": [50716, 293, 1884, 544, 1333, 295, 938, 3500, 21901, 50966], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 624, "seek": 159490, "start": 1607.5800000000002, "end": 1611.3400000000001, "text": " where these models I think will be more amenable", "tokens": [50998, 689, 613, 5245, 286, 519, 486, 312, 544, 18497, 712, 51186], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 625, "seek": 159490, "start": 1611.3400000000001, "end": 1614.8600000000001, "text": " to like employee onboarding style training,", "tokens": [51186, 281, 411, 10738, 24033, 278, 3758, 3097, 11, 51362], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 626, "seek": 159490, "start": 1614.8600000000001, "end": 1616.9, "text": " which is something also that the M's have", "tokens": [51362, 597, 307, 746, 611, 300, 264, 376, 311, 362, 51464], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 627, "seek": 159490, "start": 1616.9, "end": 1619.02, "text": " in your scenario, right?", "tokens": [51464, 294, 428, 9005, 11, 558, 30, 51570], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 628, "seek": 159490, "start": 1619.02, "end": 1624.02, "text": " You can kind of train a base M to be an employee for you,", "tokens": [51570, 509, 393, 733, 295, 3847, 257, 3096, 376, 281, 312, 364, 10738, 337, 291, 11, 51820], "temperature": 0.0, "avg_logprob": -0.12524961621573802, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.00043046390055678785}, {"id": 629, "seek": 162402, "start": 1624.42, "end": 1626.74, "text": " you can even put it in that mental,", "tokens": [50384, 291, 393, 754, 829, 309, 294, 300, 4973, 11, 50500], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 630, "seek": 162402, "start": 1626.74, "end": 1627.74, "text": " get it to that mental state", "tokens": [50500, 483, 309, 281, 300, 4973, 1785, 50550], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 631, "seek": 162402, "start": 1627.74, "end": 1630.34, "text": " where it's like really excited and ready to work,", "tokens": [50550, 689, 309, 311, 411, 534, 2919, 293, 1919, 281, 589, 11, 50680], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 632, "seek": 162402, "start": 1630.34, "end": 1632.5, "text": " and then you can freeze it, store it,", "tokens": [50680, 293, 550, 291, 393, 15959, 309, 11, 3531, 309, 11, 50788], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 633, "seek": 162402, "start": 1632.5, "end": 1634.06, "text": " boot it up when necessary,", "tokens": [50788, 11450, 309, 493, 562, 4818, 11, 50866], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 634, "seek": 162402, "start": 1634.06, "end": 1636.58, "text": " boot it up end times as necessary.", "tokens": [50866, 11450, 309, 493, 917, 1413, 382, 4818, 13, 50992], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 635, "seek": 162402, "start": 1636.58, "end": 1640.58, "text": " The transformers don't really have that same feature right now,", "tokens": [50992, 440, 4088, 433, 500, 380, 534, 362, 300, 912, 4111, 558, 586, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 636, "seek": 162402, "start": 1640.58, "end": 1645.58, "text": " they're just kind of their monolithic base form at all times,", "tokens": [51192, 436, 434, 445, 733, 295, 641, 1108, 42878, 3096, 1254, 412, 439, 1413, 11, 51442], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 637, "seek": 162402, "start": 1645.58, "end": 1650.3799999999999, "text": " but the state-state models start to add some of that back.", "tokens": [51442, 457, 264, 1785, 12, 15406, 5245, 722, 281, 909, 512, 295, 300, 646, 13, 51682], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 638, "seek": 162402, "start": 1650.3799999999999, "end": 1652.5, "text": " Obviously, it's not gonna be one-to-one", "tokens": [51682, 7580, 11, 309, 311, 406, 799, 312, 472, 12, 1353, 12, 546, 51788], "temperature": 0.0, "avg_logprob": -0.11970463562011718, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.0006262420793063939}, {"id": 639, "seek": 165250, "start": 1652.5, "end": 1655.06, "text": " with the humans or the M's.", "tokens": [50364, 365, 264, 6255, 420, 264, 376, 311, 13, 50492], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 640, "seek": 165250, "start": 1655.06, "end": 1658.7, "text": " Here's gonna be my problem with that number four.", "tokens": [50492, 1692, 311, 799, 312, 452, 1154, 365, 300, 1230, 1451, 13, 50674], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 641, "seek": 165250, "start": 1658.7, "end": 1661.3, "text": " If I look at sort of the history of AI", "tokens": [50674, 759, 286, 574, 412, 1333, 295, 264, 2503, 295, 7318, 50804], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 642, "seek": 165250, "start": 1661.3, "end": 1663.26, "text": " over the history of computers", "tokens": [50804, 670, 264, 2503, 295, 10807, 50902], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 643, "seek": 165250, "start": 1663.26, "end": 1665.5, "text": " and even the history of automation before that,", "tokens": [50902, 293, 754, 264, 2503, 295, 17769, 949, 300, 11, 51014], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 644, "seek": 165250, "start": 1666.62, "end": 1669.38, "text": " we see this history where a really wide range", "tokens": [51070, 321, 536, 341, 2503, 689, 257, 534, 4874, 3613, 51208], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 645, "seek": 165250, "start": 1669.38, "end": 1671.7, "text": " of approaches have been tried,", "tokens": [51208, 295, 11587, 362, 668, 3031, 11, 51324], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 646, "seek": 165250, "start": 1671.7, "end": 1673.58, "text": " a really wide range of paradigms", "tokens": [51324, 257, 534, 4874, 3613, 295, 13480, 328, 2592, 51418], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 647, "seek": 165250, "start": 1673.58, "end": 1677.5, "text": " and concepts and structures have been introduced.", "tokens": [51418, 293, 10392, 293, 9227, 362, 668, 7268, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 648, "seek": 165250, "start": 1677.5, "end": 1680.58, "text": " And over time, we've found ways in some sense", "tokens": [51614, 400, 670, 565, 11, 321, 600, 1352, 2098, 294, 512, 2020, 51768], "temperature": 0.0, "avg_logprob": -0.1396110659447786, "compression_ratio": 1.7699115044247788, "no_speech_prob": 0.000168607133673504}, {"id": 649, "seek": 168058, "start": 1680.6599999999999, "end": 1683.4199999999998, "text": " to subsume prior structures within new ones,", "tokens": [50368, 281, 2090, 2540, 4059, 9227, 1951, 777, 2306, 11, 50506], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 650, "seek": 168058, "start": 1684.5, "end": 1687.58, "text": " but we've just gone through a lot of them.", "tokens": [50560, 457, 321, 600, 445, 2780, 807, 257, 688, 295, 552, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 651, "seek": 168058, "start": 1688.58, "end": 1691.1799999999998, "text": " And there's been this tendency, unfortunately,", "tokens": [50764, 400, 456, 311, 668, 341, 18187, 11, 7015, 11, 50894], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 652, "seek": 168058, "start": 1691.1799999999998, "end": 1693.98, "text": " that when people reach the next new paradigm,", "tokens": [50894, 300, 562, 561, 2524, 264, 958, 777, 24709, 11, 51034], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 653, "seek": 168058, "start": 1693.98, "end": 1697.5, "text": " the next new structure, they get really excited by it", "tokens": [51034, 264, 958, 777, 3877, 11, 436, 483, 534, 2919, 538, 309, 51210], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 654, "seek": 168058, "start": 1697.5, "end": 1700.58, "text": " and they consistently say, are we almost done?", "tokens": [51210, 293, 436, 14961, 584, 11, 366, 321, 1920, 1096, 30, 51364], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 655, "seek": 168058, "start": 1700.58, "end": 1702.62, "text": " They said that centuries ago,", "tokens": [51364, 814, 848, 300, 13926, 2057, 11, 51466], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 656, "seek": 168058, "start": 1702.62, "end": 1704.4199999999998, "text": " they said that half a century ago,", "tokens": [51466, 436, 848, 300, 1922, 257, 4901, 2057, 11, 51556], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 657, "seek": 168058, "start": 1704.4199999999998, "end": 1708.6599999999999, "text": " every new decade, every new kind of approach", "tokens": [51556, 633, 777, 10378, 11, 633, 777, 733, 295, 3109, 51768], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 658, "seek": 168058, "start": 1708.6599999999999, "end": 1710.1, "text": " that comes along,", "tokens": [51768, 300, 1487, 2051, 11, 51840], "temperature": 0.0, "avg_logprob": -0.08886344344527633, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0005192463868297637}, {"id": 659, "seek": 171010, "start": 1710.8999999999999, "end": 1712.78, "text": " there's basically typically some demo,", "tokens": [50404, 456, 311, 1936, 5850, 512, 10723, 11, 50498], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 660, "seek": 171010, "start": 1712.78, "end": 1715.26, "text": " some new capability that this new system can do", "tokens": [50498, 512, 777, 13759, 300, 341, 777, 1185, 393, 360, 50622], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 661, "seek": 171010, "start": 1715.26, "end": 1717.8999999999999, "text": " that none of the prior systems are able to do.", "tokens": [50622, 300, 6022, 295, 264, 4059, 3652, 366, 1075, 281, 360, 13, 50754], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 662, "seek": 171010, "start": 1718.82, "end": 1721.9399999999998, "text": " And it's exciting and it's shocking even", "tokens": [50800, 400, 309, 311, 4670, 293, 309, 311, 18776, 754, 50956], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 663, "seek": 171010, "start": 1721.9399999999998, "end": 1726.9399999999998, "text": " and exciting, but people consistently say,", "tokens": [50956, 293, 4670, 11, 457, 561, 14961, 584, 11, 51206], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 664, "seek": 171010, "start": 1726.9399999999998, "end": 1729.26, "text": " so we must be almost done, right?", "tokens": [51206, 370, 321, 1633, 312, 1920, 1096, 11, 558, 30, 51322], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 665, "seek": 171010, "start": 1729.26, "end": 1732.1, "text": " Like, surely this is enough to do everything", "tokens": [51322, 1743, 11, 11468, 341, 307, 1547, 281, 360, 1203, 51464], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 666, "seek": 171010, "start": 1732.1, "end": 1734.2199999999998, "text": " and pretty soon humans will be displaced", "tokens": [51464, 293, 1238, 2321, 6255, 486, 312, 33692, 51570], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 667, "seek": 171010, "start": 1734.2199999999998, "end": 1736.62, "text": " by automation based on this new approach.", "tokens": [51570, 538, 17769, 2361, 322, 341, 777, 3109, 13, 51690], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 668, "seek": 171010, "start": 1736.62, "end": 1738.78, "text": " And that just happens over and over again.", "tokens": [51690, 400, 300, 445, 2314, 670, 293, 670, 797, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1393734614054362, "compression_ratio": 1.6947791164658634, "no_speech_prob": 0.0003149361873511225}, {"id": 669, "seek": 173878, "start": 1739.66, "end": 1742.22, "text": " And so we've had enough of those that I got to say,", "tokens": [50408, 400, 370, 321, 600, 632, 1547, 295, 729, 300, 286, 658, 281, 584, 11, 50536], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 670, "seek": 173878, "start": 1742.22, "end": 1744.66, "text": " the chance that the next exciting new paradigm", "tokens": [50536, 264, 2931, 300, 264, 958, 4670, 777, 24709, 50658], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 671, "seek": 173878, "start": 1744.66, "end": 1748.66, "text": " is the last one we'll need is a prior pretty low.", "tokens": [50658, 307, 264, 1036, 472, 321, 603, 643, 307, 257, 4059, 1238, 2295, 13, 50858], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 672, "seek": 173878, "start": 1749.66, "end": 1751.54, "text": " We've had this long road to go", "tokens": [50908, 492, 600, 632, 341, 938, 3060, 281, 352, 51002], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 673, "seek": 173878, "start": 1751.54, "end": 1754.54, "text": " and we still have a long way to go ahead of us.", "tokens": [51002, 293, 321, 920, 362, 257, 938, 636, 281, 352, 2286, 295, 505, 13, 51152], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 674, "seek": 173878, "start": 1754.54, "end": 1756.3799999999999, "text": " And therefore, it's unlikely", "tokens": [51152, 400, 4412, 11, 309, 311, 17518, 51244], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 675, "seek": 173878, "start": 1756.3799999999999, "end": 1759.42, "text": " that the next new thing is the last thing.", "tokens": [51244, 300, 264, 958, 777, 551, 307, 264, 1036, 551, 13, 51396], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 676, "seek": 173878, "start": 1759.42, "end": 1762.18, "text": " So that's my stance, I would think, okay,", "tokens": [51396, 407, 300, 311, 452, 21033, 11, 286, 576, 519, 11, 1392, 11, 51534], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 677, "seek": 173878, "start": 1762.18, "end": 1763.34, "text": " I can talk to you about LLMS", "tokens": [51534, 286, 393, 751, 281, 291, 466, 441, 43, 10288, 51592], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 678, "seek": 173878, "start": 1763.34, "end": 1765.42, "text": " because they're the latest thing.", "tokens": [51592, 570, 436, 434, 264, 6792, 551, 13, 51696], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 679, "seek": 173878, "start": 1765.42, "end": 1766.58, "text": " We can talk about LLMS,", "tokens": [51696, 492, 393, 751, 466, 441, 43, 10288, 11, 51754], "temperature": 0.0, "avg_logprob": -0.3246874375776811, "compression_ratio": 1.7258064516129032, "no_speech_prob": 0.00022339177667163312}, {"id": 680, "seek": 176658, "start": 1766.58, "end": 1768.22, "text": " they're the latest thing.", "tokens": [50364, 436, 434, 264, 6792, 551, 13, 50446], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 681, "seek": 176658, "start": 1768.22, "end": 1770.02, "text": " We can talk about what new things they can do", "tokens": [50446, 492, 393, 751, 466, 437, 777, 721, 436, 393, 360, 50536], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 682, "seek": 176658, "start": 1770.02, "end": 1772.26, "text": " and what exciting options", "tokens": [50536, 293, 437, 4670, 3956, 50648], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 683, "seek": 176658, "start": 1772.26, "end": 1774.1799999999998, "text": " that generates in the near future.", "tokens": [50648, 300, 23815, 294, 264, 2651, 2027, 13, 50744], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 684, "seek": 176658, "start": 1775.1, "end": 1776.58, "text": " And then we can ask, well,", "tokens": [50790, 400, 550, 321, 393, 1029, 11, 731, 11, 50864], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 685, "seek": 176658, "start": 1776.58, "end": 1779.34, "text": " what's the chance it's the last thing we'll need?", "tokens": [50864, 437, 311, 264, 2931, 309, 311, 264, 1036, 551, 321, 603, 643, 30, 51002], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 686, "seek": 176658, "start": 1779.34, "end": 1781.06, "text": " Or that the next one is the last thing we need.", "tokens": [51002, 1610, 300, 264, 958, 472, 307, 264, 1036, 551, 321, 643, 13, 51088], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 687, "seek": 176658, "start": 1781.06, "end": 1784.22, "text": " And so one way to cash that out is to ask,", "tokens": [51088, 400, 370, 472, 636, 281, 6388, 300, 484, 307, 281, 1029, 11, 51246], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 688, "seek": 176658, "start": 1784.22, "end": 1785.54, "text": " what do we think the chances are", "tokens": [51246, 437, 360, 321, 519, 264, 10486, 366, 51312], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 689, "seek": 176658, "start": 1785.54, "end": 1788.78, "text": " that within a decade or even two,", "tokens": [51312, 300, 1951, 257, 10378, 420, 754, 732, 11, 51474], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 690, "seek": 176658, "start": 1788.78, "end": 1791.3, "text": " basically all human jobs will be replaced", "tokens": [51474, 1936, 439, 1952, 4782, 486, 312, 10772, 51600], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 691, "seek": 176658, "start": 1791.3, "end": 1794.9399999999998, "text": " by machines based on this new approach.", "tokens": [51600, 538, 8379, 2361, 322, 341, 777, 3109, 13, 51782], "temperature": 0.0, "avg_logprob": -0.13948309421539307, "compression_ratio": 1.774703557312253, "no_speech_prob": 0.00040444094338454306}, {"id": 692, "seek": 179494, "start": 1794.94, "end": 1797.94, "text": " And most of the forecasting that's done out there", "tokens": [50364, 400, 881, 295, 264, 44331, 300, 311, 1096, 484, 456, 50514], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 693, "seek": 179494, "start": 1797.94, "end": 1800.3, "text": " is excited about near-term progress in a lot of ways.", "tokens": [50514, 307, 2919, 466, 2651, 12, 7039, 4205, 294, 257, 688, 295, 2098, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 694, "seek": 179494, "start": 1800.3, "end": 1801.54, "text": " But when you ask the question,", "tokens": [50632, 583, 562, 291, 1029, 264, 1168, 11, 50694], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 695, "seek": 179494, "start": 1801.54, "end": 1803.78, "text": " when will most jobs be replaced?", "tokens": [50694, 562, 486, 881, 4782, 312, 10772, 30, 50806], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 696, "seek": 179494, "start": 1803.78, "end": 1805.78, "text": " They give you forecasts that are way out there", "tokens": [50806, 814, 976, 291, 49421, 300, 366, 636, 484, 456, 50906], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 697, "seek": 179494, "start": 1805.78, "end": 1809.18, "text": " because they think, no, we're not close to that.", "tokens": [50906, 570, 436, 519, 11, 572, 11, 321, 434, 406, 1998, 281, 300, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 698, "seek": 179494, "start": 1809.18, "end": 1810.7, "text": " And I don't think we're close to that.", "tokens": [51076, 400, 286, 500, 380, 519, 321, 434, 1998, 281, 300, 13, 51152], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 699, "seek": 179494, "start": 1810.7, "end": 1814.14, "text": " So then the question is,", "tokens": [51152, 407, 550, 264, 1168, 307, 11, 51324], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 700, "seek": 179494, "start": 1814.14, "end": 1815.7, "text": " now we could say, what will happen", "tokens": [51324, 586, 321, 727, 584, 11, 437, 486, 1051, 51402], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 701, "seek": 179494, "start": 1815.7, "end": 1817.38, "text": " when we eventually get to the point", "tokens": [51402, 562, 321, 4728, 483, 281, 264, 935, 51486], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 702, "seek": 179494, "start": 1817.38, "end": 1819.3400000000001, "text": " where AI is you're good enough to do everything?", "tokens": [51486, 689, 7318, 307, 291, 434, 665, 1547, 281, 360, 1203, 30, 51584], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 703, "seek": 179494, "start": 1819.3400000000001, "end": 1820.5800000000002, "text": " And we don't know what that approaches,", "tokens": [51584, 400, 321, 500, 380, 458, 437, 300, 11587, 11, 51646], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 704, "seek": 179494, "start": 1820.5800000000002, "end": 1822.18, "text": " but we can still talk about that point", "tokens": [51646, 457, 321, 393, 920, 751, 466, 300, 935, 51726], "temperature": 0.0, "avg_logprob": -0.1221787978191765, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.00016863312339410186}, {"id": 705, "seek": 182218, "start": 1822.54, "end": 1825.3, "text": " and what's likely to what the transition rate would be", "tokens": [50382, 293, 437, 311, 3700, 281, 437, 264, 6034, 3314, 576, 312, 50520], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 706, "seek": 182218, "start": 1825.3, "end": 1827.1000000000001, "text": " and the transition scenario", "tokens": [50520, 293, 264, 6034, 9005, 50610], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 707, "seek": 182218, "start": 1827.1000000000001, "end": 1830.5800000000002, "text": " and who would get rich and who would be unhappy", "tokens": [50610, 293, 567, 576, 483, 4593, 293, 567, 576, 312, 22172, 50784], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 708, "seek": 182218, "start": 1830.5800000000002, "end": 1833.1000000000001, "text": " and all the different things we could talk about there.", "tokens": [50784, 293, 439, 264, 819, 721, 321, 727, 751, 466, 456, 13, 50910], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 709, "seek": 182218, "start": 1833.1000000000001, "end": 1835.78, "text": " But now we're talking about whatever approach", "tokens": [50910, 583, 586, 321, 434, 1417, 466, 2035, 3109, 51044], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 710, "seek": 182218, "start": 1835.78, "end": 1840.1000000000001, "text": " eventually gets us past the being able to have", "tokens": [51044, 4728, 2170, 505, 1791, 264, 885, 1075, 281, 362, 51260], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 711, "seek": 182218, "start": 1840.1000000000001, "end": 1842.46, "text": " to do pretty much all human tasks,", "tokens": [51260, 281, 360, 1238, 709, 439, 1952, 9608, 11, 51378], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 712, "seek": 182218, "start": 1842.46, "end": 1843.98, "text": " which is not where we are now,", "tokens": [51378, 597, 307, 406, 689, 321, 366, 586, 11, 51454], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 713, "seek": 182218, "start": 1843.98, "end": 1845.6200000000001, "text": " or we can talk about where we are now", "tokens": [51454, 420, 321, 393, 751, 466, 689, 321, 366, 586, 51536], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 714, "seek": 182218, "start": 1845.6200000000001, "end": 1846.9, "text": " and what these things can do", "tokens": [51536, 293, 437, 613, 721, 393, 360, 51600], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 715, "seek": 182218, "start": 1847.94, "end": 1851.66, "text": " and what exciting things might happen in the next decade.", "tokens": [51652, 293, 437, 4670, 721, 1062, 1051, 294, 264, 958, 10378, 13, 51838], "temperature": 0.0, "avg_logprob": -0.12767077300508142, "compression_ratio": 1.8951612903225807, "no_speech_prob": 0.0040685986168682575}, {"id": 716, "seek": 185218, "start": 1852.38, "end": 1854.3400000000001, "text": " Hey, we'll continue our interview in a moment", "tokens": [50374, 1911, 11, 321, 603, 2354, 527, 4049, 294, 257, 1623, 50472], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 717, "seek": 185218, "start": 1854.3400000000001, "end": 1856.1000000000001, "text": " after a word from our sponsors.", "tokens": [50472, 934, 257, 1349, 490, 527, 22593, 13, 50560], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 718, "seek": 185218, "start": 1856.1000000000001, "end": 1857.14, "text": " If you're a startup founder", "tokens": [50560, 759, 291, 434, 257, 18578, 14917, 50612], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 719, "seek": 185218, "start": 1857.14, "end": 1858.8600000000001, "text": " or executive running a growing business,", "tokens": [50612, 420, 10140, 2614, 257, 4194, 1606, 11, 50698], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 720, "seek": 185218, "start": 1858.8600000000001, "end": 1861.46, "text": " you know that as you scale, your systems break down", "tokens": [50698, 291, 458, 300, 382, 291, 4373, 11, 428, 3652, 1821, 760, 50828], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 721, "seek": 185218, "start": 1861.46, "end": 1863.3400000000001, "text": " and the cracks start to show.", "tokens": [50828, 293, 264, 21770, 722, 281, 855, 13, 50922], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 722, "seek": 185218, "start": 1863.3400000000001, "end": 1864.5, "text": " If this resonates with you,", "tokens": [50922, 759, 341, 41051, 365, 291, 11, 50980], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 723, "seek": 185218, "start": 1864.5, "end": 1866.1000000000001, "text": " there are three numbers you need to know,", "tokens": [50980, 456, 366, 1045, 3547, 291, 643, 281, 458, 11, 51060], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 724, "seek": 185218, "start": 1866.1000000000001, "end": 1870.3400000000001, "text": " 36,000, 25 and one, 36,000.", "tokens": [51060, 8652, 11, 1360, 11, 3552, 293, 472, 11, 8652, 11, 1360, 13, 51272], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 725, "seek": 185218, "start": 1870.3400000000001, "end": 1871.38, "text": " That's the number of businesses", "tokens": [51272, 663, 311, 264, 1230, 295, 6011, 51324], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 726, "seek": 185218, "start": 1871.38, "end": 1873.22, "text": " which have upgraded to NetSuite by Oracle.", "tokens": [51324, 597, 362, 24133, 281, 6188, 50, 21681, 538, 25654, 13, 51416], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 727, "seek": 185218, "start": 1873.22, "end": 1875.3, "text": " NetSuite is the number one cloud financial system,", "tokens": [51416, 6188, 50, 21681, 307, 264, 1230, 472, 4588, 4669, 1185, 11, 51520], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 728, "seek": 185218, "start": 1875.3, "end": 1877.3, "text": " streamlined accounting, financial management,", "tokens": [51520, 48155, 19163, 11, 4669, 4592, 11, 51620], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 729, "seek": 185218, "start": 1877.3, "end": 1880.38, "text": " inventory, HR and more, 25.", "tokens": [51620, 14228, 11, 19460, 293, 544, 11, 3552, 13, 51774], "temperature": 0.0, "avg_logprob": -0.10761286461190002, "compression_ratio": 1.6593059936908516, "no_speech_prob": 0.03354618698358536}, {"id": 730, "seek": 188038, "start": 1880.42, "end": 1882.22, "text": " NetSuite turns 25 this year.", "tokens": [50366, 6188, 50, 21681, 4523, 3552, 341, 1064, 13, 50456], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 731, "seek": 188038, "start": 1882.22, "end": 1884.98, "text": " That's 25 years of helping businesses do more with less,", "tokens": [50456, 663, 311, 3552, 924, 295, 4315, 6011, 360, 544, 365, 1570, 11, 50594], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 732, "seek": 188038, "start": 1884.98, "end": 1888.6200000000001, "text": " close their books in days, not weeks and drive down costs.", "tokens": [50594, 1998, 641, 3642, 294, 1708, 11, 406, 3259, 293, 3332, 760, 5497, 13, 50776], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 733, "seek": 188038, "start": 1888.6200000000001, "end": 1890.74, "text": " One, because your business is one of a kind,", "tokens": [50776, 1485, 11, 570, 428, 1606, 307, 472, 295, 257, 733, 11, 50882], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 734, "seek": 188038, "start": 1890.74, "end": 1893.3000000000002, "text": " so you get a customized solution for all your KPIs", "tokens": [50882, 370, 291, 483, 257, 30581, 3827, 337, 439, 428, 41371, 6802, 51010], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 735, "seek": 188038, "start": 1893.3000000000002, "end": 1895.7800000000002, "text": " in one efficient system with one source of truth.", "tokens": [51010, 294, 472, 7148, 1185, 365, 472, 4009, 295, 3494, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 736, "seek": 188038, "start": 1895.7800000000002, "end": 1899.0600000000002, "text": " Manage risk, get reliable forecasts and improve margins,", "tokens": [51134, 2458, 609, 3148, 11, 483, 12924, 49421, 293, 3470, 30317, 11, 51298], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 737, "seek": 188038, "start": 1899.0600000000002, "end": 1901.2600000000002, "text": " everything you need all in one place.", "tokens": [51298, 1203, 291, 643, 439, 294, 472, 1081, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 738, "seek": 188038, "start": 1901.2600000000002, "end": 1904.6200000000001, "text": " Right now, download NetSuite's popular KPI checklist,", "tokens": [51408, 1779, 586, 11, 5484, 6188, 50, 21681, 311, 3743, 591, 31701, 30357, 11, 51576], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 739, "seek": 188038, "start": 1904.6200000000001, "end": 1906.98, "text": " designed to give you consistently excellent performance,", "tokens": [51576, 4761, 281, 976, 291, 14961, 7103, 3389, 11, 51694], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 740, "seek": 188038, "start": 1906.98, "end": 1910.3000000000002, "text": " absolutely free and netsuite.com slash cognitive.", "tokens": [51694, 3122, 1737, 293, 2533, 33136, 13, 1112, 17330, 15605, 13, 51860], "temperature": 0.0, "avg_logprob": -0.1102655534263995, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0009398809634149075}, {"id": 741, "seek": 191030, "start": 1910.3, "end": 1912.4199999999998, "text": " That's netsuite.com slash cognitive", "tokens": [50364, 663, 311, 2533, 33136, 13, 1112, 17330, 15605, 50470], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 742, "seek": 191030, "start": 1912.4199999999998, "end": 1914.26, "text": " to get your own KPI checklist,", "tokens": [50470, 281, 483, 428, 1065, 591, 31701, 30357, 11, 50562], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 743, "seek": 191030, "start": 1914.26, "end": 1916.1399999999999, "text": " netsuite.com slash cognitive.", "tokens": [50562, 2533, 33136, 13, 1112, 17330, 15605, 13, 50656], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 744, "seek": 191030, "start": 1917.3, "end": 1920.6599999999999, "text": " Omniki uses generative AI to enable you to launch", "tokens": [50714, 9757, 77, 9850, 4960, 1337, 1166, 7318, 281, 9528, 291, 281, 4025, 50882], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 745, "seek": 191030, "start": 1920.6599999999999, "end": 1924.02, "text": " hundreds of thousands of ad iterations that actually work,", "tokens": [50882, 6779, 295, 5383, 295, 614, 36540, 300, 767, 589, 11, 51050], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 746, "seek": 191030, "start": 1924.02, "end": 1927.44, "text": " customized across all platforms with a click of a button.", "tokens": [51050, 30581, 2108, 439, 9473, 365, 257, 2052, 295, 257, 2960, 13, 51221], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 747, "seek": 191030, "start": 1927.44, "end": 1929.98, "text": " I believe in Omniki so much that I invested in it", "tokens": [51221, 286, 1697, 294, 9757, 77, 9850, 370, 709, 300, 286, 13104, 294, 309, 51348], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 748, "seek": 191030, "start": 1929.98, "end": 1932.3, "text": " and I recommend you use it too.", "tokens": [51348, 293, 286, 2748, 291, 764, 309, 886, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 749, "seek": 191030, "start": 1932.3, "end": 1934.82, "text": " Use CogGrav to get a 10% discount.", "tokens": [51464, 8278, 383, 664, 38, 13404, 281, 483, 257, 1266, 4, 11635, 13, 51590], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 750, "seek": 191030, "start": 1934.82, "end": 1936.3799999999999, "text": " Well, I'm tempted by all of those options.", "tokens": [51590, 1042, 11, 286, 478, 29941, 538, 439, 295, 729, 3956, 13, 51668], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 751, "seek": 191030, "start": 1936.3799999999999, "end": 1939.94, "text": " So maybe for starters, I would be interested to hear", "tokens": [51668, 407, 1310, 337, 35131, 11, 286, 576, 312, 3102, 281, 1568, 51846], "temperature": 0.0, "avg_logprob": -0.15365155537923178, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00014424911933019757}, {"id": 752, "seek": 193994, "start": 1939.94, "end": 1944.94, "text": " how you would develop a cognitive tail of the tape", "tokens": [50364, 577, 291, 576, 1499, 257, 15605, 6838, 295, 264, 7314, 50614], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 753, "seek": 193994, "start": 1945.54, "end": 1948.98, "text": " between humans and M's by presumption", "tokens": [50644, 1296, 6255, 293, 376, 311, 538, 18028, 1695, 50816], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 754, "seek": 193994, "start": 1948.98, "end": 1950.8400000000001, "text": " have kind of the same cognitive abilities,", "tokens": [50816, 362, 733, 295, 264, 912, 15605, 11582, 11, 50909], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 755, "seek": 193994, "start": 1950.8400000000001, "end": 1953.9, "text": " but these kind of different external properties", "tokens": [50909, 457, 613, 733, 295, 819, 8320, 7221, 51062], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 756, "seek": 193994, "start": 1953.9, "end": 1955.66, "text": " of copyability and so on.", "tokens": [51062, 295, 5055, 2310, 293, 370, 322, 13, 51150], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 757, "seek": 193994, "start": 1955.66, "end": 1958.38, "text": " The large language model today,", "tokens": [51150, 440, 2416, 2856, 2316, 965, 11, 51286], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 758, "seek": 193994, "start": 1958.38, "end": 1961.5, "text": " transformer, remarkably simple architecture,", "tokens": [51286, 31782, 11, 37381, 2199, 9482, 11, 51442], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 759, "seek": 193994, "start": 1961.5, "end": 1964.02, "text": " when you really just look at the wiring diagram,", "tokens": [51442, 562, 291, 534, 445, 574, 412, 264, 27520, 10686, 11, 51568], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 760, "seek": 193994, "start": 1964.02, "end": 1968.42, "text": " it's way simpler than the human brain is.", "tokens": [51568, 309, 311, 636, 18587, 813, 264, 1952, 3567, 307, 13, 51788], "temperature": 0.0, "avg_logprob": -0.18969888272492783, "compression_ratio": 1.5872340425531914, "no_speech_prob": 0.0003919431765098125}, {"id": 761, "seek": 196842, "start": 1968.42, "end": 1972.54, "text": " And not shockingly, it can only do certain things", "tokens": [50364, 400, 406, 5588, 12163, 11, 309, 393, 787, 360, 1629, 721, 50570], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 762, "seek": 196842, "start": 1972.54, "end": 1975.02, "text": " that there's like really important traits", "tokens": [50570, 300, 456, 311, 411, 534, 1021, 19526, 50694], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 763, "seek": 196842, "start": 1975.02, "end": 1980.02, "text": " that the human brain has that the language models don't have.", "tokens": [50694, 300, 264, 1952, 3567, 575, 300, 264, 2856, 5245, 500, 380, 362, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 764, "seek": 196842, "start": 1980.5800000000002, "end": 1984.02, "text": " I identified one of those as kind of integrated,", "tokens": [50972, 286, 9234, 472, 295, 729, 382, 733, 295, 10919, 11, 51144], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 765, "seek": 196842, "start": 1984.02, "end": 1988.22, "text": " ever-evolving, medium and long-term memory.", "tokens": [51144, 1562, 12, 68, 9646, 798, 11, 6399, 293, 938, 12, 7039, 4675, 13, 51354], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 766, "seek": 196842, "start": 1988.22, "end": 1990.18, "text": " I wonder what else you would kind of flag there.", "tokens": [51354, 286, 2441, 437, 1646, 291, 576, 733, 295, 7166, 456, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 767, "seek": 196842, "start": 1990.18, "end": 1993.14, "text": " I don't know if you have a taxonomy of what are the kind", "tokens": [51452, 286, 500, 380, 458, 498, 291, 362, 257, 3366, 23423, 295, 437, 366, 264, 733, 51600], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 768, "seek": 196842, "start": 1993.14, "end": 1996.18, "text": " of core competencies of humans that you could then say,", "tokens": [51600, 295, 4965, 2850, 6464, 295, 6255, 300, 291, 727, 550, 584, 11, 51752], "temperature": 0.0, "avg_logprob": -0.1674483212557706, "compression_ratio": 1.6653061224489796, "no_speech_prob": 0.00017949346511159092}, {"id": 769, "seek": 199618, "start": 1996.22, "end": 2000.26, "text": " oh, and here's the things that language models currently lack.", "tokens": [50366, 1954, 11, 293, 510, 311, 264, 721, 300, 2856, 5245, 4362, 5011, 13, 50568], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 770, "seek": 199618, "start": 2000.26, "end": 2001.94, "text": " I'm trying to develop something like this in general", "tokens": [50568, 286, 478, 1382, 281, 1499, 746, 411, 341, 294, 2674, 50652], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 771, "seek": 199618, "start": 2001.94, "end": 2006.26, "text": " because it does seem to me that the large language models", "tokens": [50652, 570, 309, 775, 1643, 281, 385, 300, 264, 2416, 2856, 5245, 50868], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 772, "seek": 199618, "start": 2006.26, "end": 2008.98, "text": " have hit not genius human level,", "tokens": [50868, 362, 2045, 406, 14017, 1952, 1496, 11, 51004], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 773, "seek": 199618, "start": 2008.98, "end": 2011.7, "text": " but like closing in on expert human level", "tokens": [51004, 457, 411, 10377, 294, 322, 5844, 1952, 1496, 51140], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 774, "seek": 199618, "start": 2011.7, "end": 2015.22, "text": " at some very important, dare I say,", "tokens": [51140, 412, 512, 588, 1021, 11, 8955, 286, 584, 11, 51316], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 775, "seek": 199618, "start": 2015.22, "end": 2019.42, "text": " even like core aspect of information processing, right?", "tokens": [51316, 754, 411, 4965, 4171, 295, 1589, 9007, 11, 558, 30, 51526], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 776, "seek": 199618, "start": 2019.42, "end": 2022.22, "text": " Like they can do things that I would say", "tokens": [51526, 1743, 436, 393, 360, 721, 300, 286, 576, 584, 51666], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 777, "seek": 199618, "start": 2022.22, "end": 2025.8200000000002, "text": " are qualitatively different than any earlier AI system", "tokens": [51666, 366, 31312, 356, 819, 813, 604, 3071, 7318, 1185, 51846], "temperature": 0.0, "avg_logprob": -0.13656978787116283, "compression_ratio": 1.6704980842911878, "no_speech_prob": 0.0020504153799265623}, {"id": 778, "seek": 202582, "start": 2025.82, "end": 2027.1399999999999, "text": " could do.", "tokens": [50364, 727, 360, 13, 50430], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 779, "seek": 202582, "start": 2027.1399999999999, "end": 2029.1, "text": " It certainly seems like we're getting close,", "tokens": [50430, 467, 3297, 2544, 411, 321, 434, 1242, 1998, 11, 50528], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 780, "seek": 202582, "start": 2029.1, "end": 2030.4199999999998, "text": " whatever the last step is,", "tokens": [50528, 2035, 264, 1036, 1823, 307, 11, 50594], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 781, "seek": 202582, "start": 2030.4199999999998, "end": 2032.5, "text": " we're definitely closer to it than we used to be.", "tokens": [50594, 321, 434, 2138, 4966, 281, 309, 813, 321, 1143, 281, 312, 13, 50698], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 782, "seek": 202582, "start": 2032.5, "end": 2036.1, "text": " But just notice that phrase you just gave was true", "tokens": [50698, 583, 445, 3449, 300, 9535, 291, 445, 2729, 390, 2074, 50878], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 783, "seek": 202582, "start": 2036.1, "end": 2038.62, "text": " or most of all the previous ones as well.", "tokens": [50878, 420, 881, 295, 439, 264, 3894, 2306, 382, 731, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 784, "seek": 202582, "start": 2038.62, "end": 2039.8999999999999, "text": " They could also do a thing", "tokens": [51004, 814, 727, 611, 360, 257, 551, 51068], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 785, "seek": 202582, "start": 2039.8999999999999, "end": 2042.76, "text": " that the previous ones before it couldn't do.", "tokens": [51068, 300, 264, 3894, 2306, 949, 309, 2809, 380, 360, 13, 51211], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 786, "seek": 202582, "start": 2042.76, "end": 2044.1399999999999, "text": " It's always been exciting.", "tokens": [51211, 467, 311, 1009, 668, 4670, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 787, "seek": 202582, "start": 2044.1399999999999, "end": 2046.1399999999999, "text": " We've found a new fundamental capability", "tokens": [51280, 492, 600, 1352, 257, 777, 8088, 13759, 51380], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 788, "seek": 202582, "start": 2046.1399999999999, "end": 2049.86, "text": " that each new paradigm structure approach", "tokens": [51380, 300, 1184, 777, 24709, 3877, 3109, 51566], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 789, "seek": 202582, "start": 2049.86, "end": 2052.18, "text": " has been of this sort", "tokens": [51566, 575, 668, 295, 341, 1333, 51682], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 790, "seek": 202582, "start": 2052.18, "end": 2054.54, "text": " that it was allowed the system to do fundamental things", "tokens": [51682, 300, 309, 390, 4350, 264, 1185, 281, 360, 8088, 721, 51800], "temperature": 0.0, "avg_logprob": -0.1476455181837082, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012840164126828313}, {"id": 791, "seek": 205454, "start": 2054.74, "end": 2055.82, "text": " that it couldn't do before", "tokens": [50374, 300, 309, 2809, 380, 360, 949, 50428], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 792, "seek": 205454, "start": 2055.82, "end": 2059.06, "text": " that seemed to be near the core of what it was to think.", "tokens": [50428, 300, 6576, 281, 312, 2651, 264, 4965, 295, 437, 309, 390, 281, 519, 13, 50590], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 793, "seek": 205454, "start": 2060.02, "end": 2062.1, "text": " So there's apparently a lot of things near the core", "tokens": [50638, 407, 456, 311, 7970, 257, 688, 295, 721, 2651, 264, 4965, 50742], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 794, "seek": 205454, "start": 2062.1, "end": 2063.2599999999998, "text": " of what it is to think.", "tokens": [50742, 295, 437, 309, 307, 281, 519, 13, 50800], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 795, "seek": 205454, "start": 2063.2599999999998, "end": 2065.02, "text": " That's the key thing to realize.", "tokens": [50800, 663, 311, 264, 2141, 551, 281, 4325, 13, 50888], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 796, "seek": 205454, "start": 2065.02, "end": 2066.7799999999997, "text": " What it is to think is a big thing.", "tokens": [50888, 708, 309, 307, 281, 519, 307, 257, 955, 551, 13, 50976], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 797, "seek": 205454, "start": 2066.7799999999997, "end": 2068.7, "text": " There's a lot of things in there.", "tokens": [50976, 821, 311, 257, 688, 295, 721, 294, 456, 13, 51072], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 798, "seek": 205454, "start": 2068.7, "end": 2069.54, "text": " Well, let's list some.", "tokens": [51072, 1042, 11, 718, 311, 1329, 512, 13, 51114], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 799, "seek": 205454, "start": 2069.54, "end": 2072.18, "text": " I can't come up with that many honestly.", "tokens": [51114, 286, 393, 380, 808, 493, 365, 300, 867, 6095, 13, 51246], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 800, "seek": 205454, "start": 2072.18, "end": 2075.74, "text": " Like I would love to hear how many can you name", "tokens": [51246, 1743, 286, 576, 959, 281, 1568, 577, 867, 393, 291, 1315, 51424], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 801, "seek": 205454, "start": 2075.74, "end": 2076.6, "text": " I have all day.", "tokens": [51424, 286, 362, 439, 786, 13, 51467], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 802, "seek": 205454, "start": 2076.6, "end": 2078.98, "text": " So could you begin to break down", "tokens": [51467, 407, 727, 291, 1841, 281, 1821, 760, 51586], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 803, "seek": 205454, "start": 2078.98, "end": 2082.1, "text": " what it is to think into key components?", "tokens": [51586, 437, 309, 307, 281, 519, 666, 2141, 6677, 30, 51742], "temperature": 0.0, "avg_logprob": -0.15607929229736328, "compression_ratio": 1.8785425101214575, "no_speech_prob": 0.00044414724106900394}, {"id": 804, "seek": 208210, "start": 2082.1, "end": 2085.86, "text": " I was an AI researcher from 84 to 93.", "tokens": [50364, 286, 390, 364, 7318, 21751, 490, 29018, 281, 28876, 13, 50552], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 805, "seek": 208210, "start": 2085.86, "end": 2089.74, "text": " That was a full time at NASA and then Lockheed.", "tokens": [50552, 663, 390, 257, 1577, 565, 412, 12077, 293, 550, 16736, 675, 292, 13, 50746], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 806, "seek": 208210, "start": 2089.74, "end": 2091.62, "text": " And certainly at that time,", "tokens": [50746, 400, 3297, 412, 300, 565, 11, 50840], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 807, "seek": 208210, "start": 2091.62, "end": 2094.54, "text": " I understood the range of approaches people had", "tokens": [50840, 286, 7320, 264, 3613, 295, 11587, 561, 632, 50986], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 808, "seek": 208210, "start": 2094.54, "end": 2097.54, "text": " and could talk about the kinds of things systems", "tokens": [50986, 293, 727, 751, 466, 264, 3685, 295, 721, 3652, 51136], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 809, "seek": 208210, "start": 2097.54, "end": 2101.42, "text": " then could do or not do and expert terms relating", "tokens": [51136, 550, 727, 360, 420, 406, 360, 293, 5844, 2115, 23968, 51330], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 810, "seek": 208210, "start": 2101.42, "end": 2106.02, "text": " to the then current tasks and issues.", "tokens": [51330, 281, 264, 550, 2190, 9608, 293, 2663, 13, 51560], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 811, "seek": 208210, "start": 2106.02, "end": 2108.2599999999998, "text": " I am not up to date at the moment", "tokens": [51560, 286, 669, 406, 493, 281, 4002, 412, 264, 1623, 51672], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 812, "seek": 208210, "start": 2108.2599999999998, "end": 2110.62, "text": " on the full range of AI approaches.", "tokens": [51672, 322, 264, 1577, 3613, 295, 7318, 11587, 13, 51790], "temperature": 0.0, "avg_logprob": -0.12577496896875967, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.00025310885393992066}, {"id": 813, "seek": 211062, "start": 2110.9, "end": 2114.8599999999997, "text": " I don't wanna pretend to be an expert on that.", "tokens": [50378, 286, 500, 380, 1948, 11865, 281, 312, 364, 5844, 322, 300, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 814, "seek": 211062, "start": 2114.8599999999997, "end": 2117.7799999999997, "text": " But I have listened to experts", "tokens": [50576, 583, 286, 362, 13207, 281, 8572, 50722], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 815, "seek": 211062, "start": 2117.7799999999997, "end": 2122.14, "text": " and the experts I hear basically consistently say,", "tokens": [50722, 293, 264, 8572, 286, 1568, 1936, 14961, 584, 11, 50940], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 816, "seek": 211062, "start": 2122.14, "end": 2123.54, "text": " this is exciting, this is great,", "tokens": [50940, 341, 307, 4670, 11, 341, 307, 869, 11, 51010], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 817, "seek": 211062, "start": 2123.54, "end": 2126.8599999999997, "text": " but we're not close to being able to do all the other things", "tokens": [51010, 457, 321, 434, 406, 1998, 281, 885, 1075, 281, 360, 439, 264, 661, 721, 51176], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 818, "seek": 211062, "start": 2126.8599999999997, "end": 2129.3399999999997, "text": " and they would be much better than I am making a list of that", "tokens": [51176, 293, 436, 576, 312, 709, 1101, 813, 286, 669, 1455, 257, 1329, 295, 300, 51300], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 819, "seek": 211062, "start": 2129.3399999999997, "end": 2131.2999999999997, "text": " and I feel like they should make the list, not me.", "tokens": [51300, 293, 286, 841, 411, 436, 820, 652, 264, 1329, 11, 406, 385, 13, 51398], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 820, "seek": 211062, "start": 2131.2999999999997, "end": 2133.58, "text": " I mean, as a polymath you call me,", "tokens": [51398, 286, 914, 11, 382, 257, 6754, 24761, 291, 818, 385, 11, 51512], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 821, "seek": 211062, "start": 2133.58, "end": 2136.8199999999997, "text": " I wanna be very careful to know when I'm an expert", "tokens": [51512, 286, 1948, 312, 588, 5026, 281, 458, 562, 286, 478, 364, 5844, 51674], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 822, "seek": 211062, "start": 2136.8199999999997, "end": 2138.42, "text": " on something and when I'm not.", "tokens": [51674, 322, 746, 293, 562, 286, 478, 406, 13, 51754], "temperature": 0.0, "avg_logprob": -0.1327949937923934, "compression_ratio": 1.7936507936507937, "no_speech_prob": 0.0009109352831728756}, {"id": 823, "seek": 213842, "start": 2138.42, "end": 2140.7400000000002, "text": " And I wanna defer to other people on areas", "tokens": [50364, 400, 286, 1948, 25704, 281, 661, 561, 322, 3179, 50480], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 824, "seek": 213842, "start": 2140.7400000000002, "end": 2143.02, "text": " where I can find people who know more than I.", "tokens": [50480, 689, 286, 393, 915, 561, 567, 458, 544, 813, 286, 13, 50594], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 825, "seek": 213842, "start": 2143.02, "end": 2145.62, "text": " And when I think I'm near the state of the art,", "tokens": [50594, 400, 562, 286, 519, 286, 478, 2651, 264, 1785, 295, 264, 1523, 11, 50724], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 826, "seek": 213842, "start": 2145.62, "end": 2147.1, "text": " as good as anyone on a topic,", "tokens": [50724, 382, 665, 382, 2878, 322, 257, 4829, 11, 50798], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 827, "seek": 213842, "start": 2147.1, "end": 2150.38, "text": " then I will feel more free to generate my own thoughts", "tokens": [50798, 550, 286, 486, 841, 544, 1737, 281, 8460, 452, 1065, 4598, 50962], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 828, "seek": 213842, "start": 2150.38, "end": 2152.58, "text": " and think they're worth contributing.", "tokens": [50962, 293, 519, 436, 434, 3163, 19270, 13, 51072], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 829, "seek": 213842, "start": 2152.58, "end": 2155.54, "text": " Fair, certainly, I think most people", "tokens": [51072, 12157, 11, 3297, 11, 286, 519, 881, 561, 51220], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 830, "seek": 213842, "start": 2155.54, "end": 2160.2200000000003, "text": " where I think you do still bring something very differentiated", "tokens": [51220, 689, 286, 519, 291, 360, 920, 1565, 746, 588, 27372, 770, 51454], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 831, "seek": 213842, "start": 2160.2200000000003, "end": 2165.2200000000003, "text": " to the discussion is just the sort of willingness", "tokens": [51454, 281, 264, 5017, 307, 445, 264, 1333, 295, 25069, 51704], "temperature": 0.0, "avg_logprob": -0.11823144360123394, "compression_ratio": 1.642570281124498, "no_speech_prob": 0.0003149009426124394}, {"id": 832, "seek": 216522, "start": 2166.22, "end": 2170.18, "text": " to stare reality in the face or at least try to.", "tokens": [50414, 281, 22432, 4103, 294, 264, 1851, 420, 412, 1935, 853, 281, 13, 50612], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 833, "seek": 216522, "start": 2170.18, "end": 2172.18, "text": " The simplest thing is if I start talking", "tokens": [50612, 440, 22811, 551, 307, 498, 286, 722, 1417, 50712], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 834, "seek": 216522, "start": 2172.18, "end": 2173.62, "text": " to an out large language model,", "tokens": [50712, 281, 364, 484, 2416, 2856, 2316, 11, 50784], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 835, "seek": 216522, "start": 2173.62, "end": 2175.3799999999997, "text": " there's a whole bunch of things I can ask it to do", "tokens": [50784, 456, 311, 257, 1379, 3840, 295, 721, 286, 393, 1029, 309, 281, 360, 50872], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 836, "seek": 216522, "start": 2175.3799999999997, "end": 2176.74, "text": " that it just can't do.", "tokens": [50872, 300, 309, 445, 393, 380, 360, 13, 50940], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 837, "seek": 216522, "start": 2177.8999999999996, "end": 2179.54, "text": " I'm not so sure how to organize that", "tokens": [50998, 286, 478, 406, 370, 988, 577, 281, 13859, 300, 51080], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 838, "seek": 216522, "start": 2179.54, "end": 2181.3799999999997, "text": " in terms of the large major categories,", "tokens": [51080, 294, 2115, 295, 264, 2416, 2563, 10479, 11, 51172], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 839, "seek": 216522, "start": 2181.3799999999997, "end": 2184.8199999999997, "text": " but it's really obvious that there's a certain kind of thinking", "tokens": [51172, 457, 309, 311, 534, 6322, 300, 456, 311, 257, 1629, 733, 295, 1953, 51344], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 840, "seek": 216522, "start": 2184.8199999999997, "end": 2188.06, "text": " it can do and a bunch of other kind of thinking it can't do.", "tokens": [51344, 309, 393, 360, 293, 257, 3840, 295, 661, 733, 295, 1953, 309, 393, 380, 360, 13, 51506], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 841, "seek": 216522, "start": 2188.06, "end": 2190.66, "text": " And I don't know exactly why it can't do them,", "tokens": [51506, 400, 286, 500, 380, 458, 2293, 983, 309, 393, 380, 360, 552, 11, 51636], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 842, "seek": 216522, "start": 2190.66, "end": 2193.06, "text": " but I'm talking to you, there's a bunch of things", "tokens": [51636, 457, 286, 478, 1417, 281, 291, 11, 456, 311, 257, 3840, 295, 721, 51756], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 843, "seek": 216522, "start": 2193.06, "end": 2194.62, "text": " I could ask you to do in this conversation", "tokens": [51756, 286, 727, 1029, 291, 281, 360, 294, 341, 3761, 51834], "temperature": 0.0, "avg_logprob": -0.21667155971774807, "compression_ratio": 1.8975265017667844, "no_speech_prob": 0.0015006809262558818}, {"id": 844, "seek": 219462, "start": 2195.18, "end": 2197.3399999999997, "text": " that you would probably do a decent job of them.", "tokens": [50392, 300, 291, 576, 1391, 360, 257, 8681, 1691, 295, 552, 13, 50500], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 845, "seek": 219462, "start": 2197.3399999999997, "end": 2199.54, "text": " And then if I were talking to the large language model,", "tokens": [50500, 400, 550, 498, 286, 645, 1417, 281, 264, 2416, 2856, 2316, 11, 50610], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 846, "seek": 219462, "start": 2199.54, "end": 2201.7799999999997, "text": " it just couldn't do those things.", "tokens": [50610, 309, 445, 2809, 380, 360, 729, 721, 13, 50722], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 847, "seek": 219462, "start": 2201.7799999999997, "end": 2203.2999999999997, "text": " So it's just really obvious to me", "tokens": [50722, 407, 309, 311, 445, 534, 6322, 281, 385, 50798], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 848, "seek": 219462, "start": 2203.2999999999997, "end": 2204.94, "text": " that this has a limited capability.", "tokens": [50798, 300, 341, 575, 257, 5567, 13759, 13, 50880], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 849, "seek": 219462, "start": 2204.94, "end": 2207.18, "text": " It's really impressive compared to what you might have expected", "tokens": [50880, 467, 311, 534, 8992, 5347, 281, 437, 291, 1062, 362, 5176, 50992], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 850, "seek": 219462, "start": 2207.18, "end": 2209.1, "text": " five or 10 years ago, it's, wow,", "tokens": [50992, 1732, 420, 1266, 924, 2057, 11, 309, 311, 11, 6076, 11, 51088], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 851, "seek": 219462, "start": 2209.1, "end": 2211.38, "text": " I never would have thought that would be feasible this soon,", "tokens": [51088, 286, 1128, 576, 362, 1194, 300, 576, 312, 26648, 341, 2321, 11, 51202], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 852, "seek": 219462, "start": 2211.38, "end": 2215.18, "text": " but you just try asking it a bunch of other things", "tokens": [51202, 457, 291, 445, 853, 3365, 309, 257, 3840, 295, 661, 721, 51392], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 853, "seek": 219462, "start": 2215.18, "end": 2217.02, "text": " and it just can't do them, right?", "tokens": [51392, 293, 309, 445, 393, 380, 360, 552, 11, 558, 30, 51484], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 854, "seek": 219462, "start": 2217.02, "end": 2222.02, "text": " Yeah, I mean, I think that in my view,", "tokens": [51484, 865, 11, 286, 914, 11, 286, 519, 300, 294, 452, 1910, 11, 51734], "temperature": 0.0, "avg_logprob": -0.12026728330737482, "compression_ratio": 1.678082191780822, "no_speech_prob": 0.0031701966654509306}, {"id": 855, "seek": 222202, "start": 2222.78, "end": 2227.78, "text": " a lot of those things are kind of overemphasized", "tokens": [50402, 257, 688, 295, 729, 721, 366, 733, 295, 38657, 76, 7485, 1602, 50652], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 856, "seek": 222202, "start": 2228.94, "end": 2232.18, "text": " relative to what maybe really matters.", "tokens": [50710, 4972, 281, 437, 1310, 534, 7001, 13, 50872], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 857, "seek": 222202, "start": 2232.18, "end": 2235.74, "text": " You see a lot of things online where people,", "tokens": [50872, 509, 536, 257, 688, 295, 721, 2950, 689, 561, 11, 51050], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 858, "seek": 222202, "start": 2235.74, "end": 2237.54, "text": " and there's different categories of this,", "tokens": [51050, 293, 456, 311, 819, 10479, 295, 341, 11, 51140], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 859, "seek": 222202, "start": 2237.54, "end": 2239.46, "text": " some of the things you'll see online", "tokens": [51140, 512, 295, 264, 721, 291, 603, 536, 2950, 51236], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 860, "seek": 222202, "start": 2239.46, "end": 2243.2599999999998, "text": " are literally people just using non frontier models", "tokens": [51236, 366, 3736, 561, 445, 1228, 2107, 35853, 5245, 51426], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 861, "seek": 222202, "start": 2243.2599999999998, "end": 2245.58, "text": " and kind of confusing, muddying the water.", "tokens": [51426, 293, 733, 295, 13181, 11, 8933, 67, 1840, 264, 1281, 13, 51542], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 862, "seek": 222202, "start": 2245.58, "end": 2247.34, "text": " So always watch out for that.", "tokens": [51542, 407, 1009, 1159, 484, 337, 300, 13, 51630], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 863, "seek": 222202, "start": 2247.34, "end": 2251.14, "text": " I have a longstanding practice of,", "tokens": [51630, 286, 362, 257, 938, 8618, 3124, 295, 11, 51820], "temperature": 0.0, "avg_logprob": -0.15067565802371863, "compression_ratio": 1.6415929203539823, "no_speech_prob": 0.002322159241884947}, {"id": 864, "seek": 225114, "start": 2251.18, "end": 2252.58, "text": " first thing I do when I see somebody say,", "tokens": [50366, 700, 551, 286, 360, 562, 286, 536, 2618, 584, 11, 50436], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 865, "seek": 225114, "start": 2252.58, "end": 2255.5, "text": " GPT-4 can't do something is try it myself.", "tokens": [50436, 26039, 51, 12, 19, 393, 380, 360, 746, 307, 853, 309, 2059, 13, 50582], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 866, "seek": 225114, "start": 2255.5, "end": 2258.94, "text": " And I would honestly say like two thirds of the time,", "tokens": [50582, 400, 286, 576, 6095, 584, 411, 732, 34552, 295, 264, 565, 11, 50754], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 867, "seek": 225114, "start": 2258.94, "end": 2260.66, "text": " it's just straight up misinformation", "tokens": [50754, 309, 311, 445, 2997, 493, 34238, 50840], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 868, "seek": 225114, "start": 2260.66, "end": 2262.2599999999998, "text": " and it in fact, like can do it.", "tokens": [50840, 293, 309, 294, 1186, 11, 411, 393, 360, 309, 13, 50920], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 869, "seek": 225114, "start": 2262.2599999999998, "end": 2265.18, "text": " But there's still the one third of the time that matters.", "tokens": [50920, 583, 456, 311, 920, 264, 472, 2636, 295, 264, 565, 300, 7001, 13, 51066], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 870, "seek": 225114, "start": 2265.18, "end": 2267.2599999999998, "text": " They're not very adversarially robust.", "tokens": [51066, 814, 434, 406, 588, 17641, 289, 2270, 13956, 13, 51170], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 871, "seek": 225114, "start": 2267.2599999999998, "end": 2268.2999999999997, "text": " They're easy to trick,", "tokens": [51170, 814, 434, 1858, 281, 4282, 11, 51222], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 872, "seek": 225114, "start": 2268.2999999999997, "end": 2272.14, "text": " they're easy to sort of get on the wrong track.", "tokens": [51222, 436, 434, 1858, 281, 1333, 295, 483, 322, 264, 2085, 2837, 13, 51414], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 873, "seek": 225114, "start": 2272.14, "end": 2276.58, "text": " And then they seem to get kind of stuck in a mode", "tokens": [51414, 400, 550, 436, 1643, 281, 483, 733, 295, 5541, 294, 257, 4391, 51636], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 874, "seek": 225114, "start": 2276.58, "end": 2278.02, "text": " is a good term for it, I think,", "tokens": [51636, 307, 257, 665, 1433, 337, 309, 11, 286, 519, 11, 51708], "temperature": 0.0, "avg_logprob": -0.12681887271630504, "compression_ratio": 1.6557971014492754, "no_speech_prob": 0.0003919458540622145}, {"id": 875, "seek": 227802, "start": 2278.02, "end": 2281.18, "text": " where once they're kind of on a certain,", "tokens": [50364, 689, 1564, 436, 434, 733, 295, 322, 257, 1629, 11, 50522], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 876, "seek": 227802, "start": 2281.18, "end": 2283.58, "text": " this is kind of how they can often get jailbroken.", "tokens": [50522, 341, 307, 733, 295, 577, 436, 393, 2049, 483, 10511, 37947, 13, 50642], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 877, "seek": 227802, "start": 2283.58, "end": 2284.78, "text": " If you can get them to say like,", "tokens": [50642, 759, 291, 393, 483, 552, 281, 584, 411, 11, 50702], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 878, "seek": 227802, "start": 2284.78, "end": 2286.94, "text": " okay, I'll be happy to help you with that,", "tokens": [50702, 1392, 11, 286, 603, 312, 2055, 281, 854, 291, 365, 300, 11, 50810], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 879, "seek": 227802, "start": 2286.94, "end": 2290.02, "text": " then they'll go on and do whatever you asked", "tokens": [50810, 550, 436, 603, 352, 322, 293, 360, 2035, 291, 2351, 50964], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 880, "seek": 227802, "start": 2290.02, "end": 2292.38, "text": " because they've already kind of got into that mode.", "tokens": [50964, 570, 436, 600, 1217, 733, 295, 658, 666, 300, 4391, 13, 51082], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 881, "seek": 227802, "start": 2292.38, "end": 2293.7, "text": " Yeah, I'm much less worried about them", "tokens": [51082, 865, 11, 286, 478, 709, 1570, 5804, 466, 552, 51148], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 882, "seek": 227802, "start": 2293.7, "end": 2295.1, "text": " doing things you don't want them to do", "tokens": [51148, 884, 721, 291, 500, 380, 528, 552, 281, 360, 51218], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 883, "seek": 227802, "start": 2295.1, "end": 2298.02, "text": " than being able to get them to do things at all.", "tokens": [51218, 813, 885, 1075, 281, 483, 552, 281, 360, 721, 412, 439, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 884, "seek": 227802, "start": 2298.02, "end": 2301.62, "text": " That as humans can be made to do all sorts of things,", "tokens": [51364, 663, 382, 6255, 393, 312, 1027, 281, 360, 439, 7527, 295, 721, 11, 51544], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 885, "seek": 227802, "start": 2301.62, "end": 2302.82, "text": " you might not want them to do that.", "tokens": [51544, 291, 1062, 406, 528, 552, 281, 360, 300, 13, 51604], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 886, "seek": 227802, "start": 2302.82, "end": 2303.82, "text": " We survive that.", "tokens": [51604, 492, 7867, 300, 13, 51654], "temperature": 0.0, "avg_logprob": -0.14084170615836367, "compression_ratio": 1.7785714285714285, "no_speech_prob": 0.0014547614846378565}, {"id": 887, "seek": 230382, "start": 2304.78, "end": 2306.5800000000004, "text": " I mean, to me, the main thing is,", "tokens": [50412, 286, 914, 11, 281, 385, 11, 264, 2135, 551, 307, 11, 50502], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 888, "seek": 230382, "start": 2306.5800000000004, "end": 2308.7000000000003, "text": " if you imagine, you know,", "tokens": [50502, 498, 291, 3811, 11, 291, 458, 11, 50608], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 889, "seek": 230382, "start": 2308.7000000000003, "end": 2311.6800000000003, "text": " treating a large language model as a new employee", "tokens": [50608, 15083, 257, 2416, 2856, 2316, 382, 257, 777, 10738, 50757], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 890, "seek": 230382, "start": 2311.6800000000003, "end": 2313.46, "text": " in some workplace where you're trying to show them", "tokens": [50757, 294, 512, 15328, 689, 291, 434, 1382, 281, 855, 552, 50846], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 891, "seek": 230382, "start": 2313.46, "end": 2316.3, "text": " how to do something and get them to do it instead of you,", "tokens": [50846, 577, 281, 360, 746, 293, 483, 552, 281, 360, 309, 2602, 295, 291, 11, 50988], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 892, "seek": 230382, "start": 2316.3, "end": 2318.6600000000003, "text": " that's the main thing that will be economically valuable", "tokens": [50988, 300, 311, 264, 2135, 551, 300, 486, 312, 26811, 8263, 51106], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 893, "seek": 230382, "start": 2318.6600000000003, "end": 2319.5, "text": " in the world.", "tokens": [51106, 294, 264, 1002, 13, 51148], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 894, "seek": 230382, "start": 2319.5, "end": 2321.2200000000003, "text": " That is, when you have a thing like that", "tokens": [51148, 663, 307, 11, 562, 291, 362, 257, 551, 411, 300, 51234], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 895, "seek": 230382, "start": 2321.2200000000003, "end": 2324.38, "text": " that can be introduced into a place,", "tokens": [51234, 300, 393, 312, 7268, 666, 257, 1081, 11, 51392], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 896, "seek": 230382, "start": 2324.38, "end": 2326.34, "text": " trained roughly and said, watch how I do this,", "tokens": [51392, 8895, 9810, 293, 848, 11, 1159, 577, 286, 360, 341, 11, 51490], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 897, "seek": 230382, "start": 2326.34, "end": 2328.98, "text": " you try to do it now, et cetera,", "tokens": [51490, 291, 853, 281, 360, 309, 586, 11, 1030, 11458, 11, 51622], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 898, "seek": 230382, "start": 2328.98, "end": 2331.42, "text": " then that will be the thing that, you know,", "tokens": [51622, 550, 300, 486, 312, 264, 551, 300, 11, 291, 458, 11, 51744], "temperature": 0.0, "avg_logprob": -0.20100562454115414, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.0008829194121062756}, {"id": 899, "seek": 233142, "start": 2331.46, "end": 2333.86, "text": " makes an enormous difference in the economy", "tokens": [50366, 1669, 364, 11322, 2649, 294, 264, 5010, 50486], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 900, "seek": 233142, "start": 2333.86, "end": 2337.5, "text": " because that's how we get people to do things, right?", "tokens": [50486, 570, 300, 311, 577, 321, 483, 561, 281, 360, 721, 11, 558, 30, 50668], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 901, "seek": 233142, "start": 2337.5, "end": 2339.82, "text": " So if that I think is, in a sense,", "tokens": [50668, 407, 498, 300, 286, 519, 307, 11, 294, 257, 2020, 11, 50784], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 902, "seek": 233142, "start": 2339.82, "end": 2342.5, "text": " the fundamental main task in the economy,", "tokens": [50784, 264, 8088, 2135, 5633, 294, 264, 5010, 11, 50918], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 903, "seek": 233142, "start": 2342.5, "end": 2345.42, "text": " which is a bunch of people are doing something,", "tokens": [50918, 597, 307, 257, 3840, 295, 561, 366, 884, 746, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 904, "seek": 233142, "start": 2345.42, "end": 2347.3, "text": " you have a new thing and you say,", "tokens": [51064, 291, 362, 257, 777, 551, 293, 291, 584, 11, 51158], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 905, "seek": 233142, "start": 2347.3, "end": 2349.66, "text": " would you Kim watch us and ask us questions", "tokens": [51158, 576, 291, 5652, 1159, 505, 293, 1029, 505, 1651, 51276], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 906, "seek": 233142, "start": 2349.66, "end": 2352.02, "text": " and we'll ask you questions and like figure out", "tokens": [51276, 293, 321, 603, 1029, 291, 1651, 293, 411, 2573, 484, 51394], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 907, "seek": 233142, "start": 2352.02, "end": 2355.3, "text": " how to help us and be part of what we're doing.", "tokens": [51394, 577, 281, 854, 505, 293, 312, 644, 295, 437, 321, 434, 884, 13, 51558], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 908, "seek": 233142, "start": 2355.3, "end": 2357.26, "text": " That is the fundamental problem in the economy.", "tokens": [51558, 663, 307, 264, 8088, 1154, 294, 264, 5010, 13, 51656], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 909, "seek": 233142, "start": 2357.26, "end": 2360.06, "text": " So that in some sense is the fundamental task", "tokens": [51656, 407, 300, 294, 512, 2020, 307, 264, 8088, 5633, 51796], "temperature": 0.0, "avg_logprob": -0.11790335539615515, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.005058089271187782}, {"id": 910, "seek": 236006, "start": 2360.06, "end": 2363.02, "text": " that any AI has to be held up to.", "tokens": [50364, 300, 604, 7318, 575, 281, 312, 5167, 493, 281, 13, 50512], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 911, "seek": 236006, "start": 2363.02, "end": 2364.82, "text": " I mean, in the past, of course,", "tokens": [50512, 286, 914, 11, 294, 264, 1791, 11, 295, 1164, 11, 50602], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 912, "seek": 236006, "start": 2364.82, "end": 2366.2999999999997, "text": " we don't even bother to have a conversation", "tokens": [50602, 321, 500, 380, 754, 8677, 281, 362, 257, 3761, 50676], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 913, "seek": 236006, "start": 2366.2999999999997, "end": 2368.38, "text": " to show you how to do, we actually say,", "tokens": [50676, 281, 855, 291, 577, 281, 360, 11, 321, 767, 584, 11, 50780], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 914, "seek": 236006, "start": 2368.38, "end": 2369.86, "text": " well, let's make a machine to do this thing", "tokens": [50780, 731, 11, 718, 311, 652, 257, 3479, 281, 360, 341, 551, 50854], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 915, "seek": 236006, "start": 2369.86, "end": 2371.34, "text": " and then we design a machine to do this thing", "tokens": [50854, 293, 550, 321, 1715, 257, 3479, 281, 360, 341, 551, 50928], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 916, "seek": 236006, "start": 2371.34, "end": 2372.9, "text": " and then we train it up to do this thing", "tokens": [50928, 293, 550, 321, 3847, 309, 493, 281, 360, 341, 551, 51006], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 917, "seek": 236006, "start": 2372.9, "end": 2374.5, "text": " all with the idea of the whole thing,", "tokens": [51006, 439, 365, 264, 1558, 295, 264, 1379, 551, 11, 51086], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 918, "seek": 236006, "start": 2374.5, "end": 2377.46, "text": " having in mind the thing we're gonna have to do.", "tokens": [51086, 1419, 294, 1575, 264, 551, 321, 434, 799, 362, 281, 360, 13, 51234], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 919, "seek": 236006, "start": 2377.46, "end": 2380.46, "text": " That's how AI has been usually in the economy so far.", "tokens": [51234, 663, 311, 577, 7318, 575, 668, 2673, 294, 264, 5010, 370, 1400, 13, 51384], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 920, "seek": 236006, "start": 2380.46, "end": 2381.62, "text": " But now if you're imagining a thing", "tokens": [51384, 583, 586, 498, 291, 434, 27798, 257, 551, 51442], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 921, "seek": 236006, "start": 2381.62, "end": 2384.02, "text": " that could just be trained to do a new job,", "tokens": [51442, 300, 727, 445, 312, 8895, 281, 360, 257, 777, 1691, 11, 51562], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 922, "seek": 236006, "start": 2384.02, "end": 2385.22, "text": " well, that would be great.", "tokens": [51562, 731, 11, 300, 576, 312, 869, 13, 51622], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 923, "seek": 236006, "start": 2386.42, "end": 2389.2599999999998, "text": " Sure, then we won't have to design the AI ahead of time", "tokens": [51682, 4894, 11, 550, 321, 1582, 380, 362, 281, 1715, 264, 7318, 2286, 295, 565, 51824], "temperature": 0.0, "avg_logprob": -0.12958355494907925, "compression_ratio": 1.9022801302931596, "no_speech_prob": 0.0025500566698610783}, {"id": 924, "seek": 238926, "start": 2389.26, "end": 2390.98, "text": " for the particular task,", "tokens": [50364, 337, 264, 1729, 5633, 11, 50450], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 925, "seek": 238926, "start": 2390.98, "end": 2392.94, "text": " but you'll have to have a thing that's up to that", "tokens": [50450, 457, 291, 603, 362, 281, 362, 257, 551, 300, 311, 493, 281, 300, 50548], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 926, "seek": 238926, "start": 2392.94, "end": 2394.3, "text": " and large language models today", "tokens": [50548, 293, 2416, 2856, 5245, 965, 50616], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 927, "seek": 238926, "start": 2394.3, "end": 2396.86, "text": " are just clearly not up to that.", "tokens": [50616, 366, 445, 4448, 406, 493, 281, 300, 13, 50744], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 928, "seek": 238926, "start": 2396.86, "end": 2398.1800000000003, "text": " You can't say, I'm about to train you", "tokens": [50744, 509, 393, 380, 584, 11, 286, 478, 466, 281, 3847, 291, 50810], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 929, "seek": 238926, "start": 2398.1800000000003, "end": 2399.78, "text": " how to do the following thing, pay attention,", "tokens": [50810, 577, 281, 360, 264, 3480, 551, 11, 1689, 3202, 11, 50890], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 930, "seek": 238926, "start": 2399.78, "end": 2401.94, "text": " I just did this, now would you do it?", "tokens": [50890, 286, 445, 630, 341, 11, 586, 576, 291, 360, 309, 30, 50998], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 931, "seek": 238926, "start": 2401.94, "end": 2403.94, "text": " Well, you can do that quite a bit, right?", "tokens": [50998, 1042, 11, 291, 393, 360, 300, 1596, 257, 857, 11, 558, 30, 51098], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 932, "seek": 238926, "start": 2403.94, "end": 2406.78, "text": " I mean, that was the main kind of finding in GPT-3", "tokens": [51098, 286, 914, 11, 300, 390, 264, 2135, 733, 295, 5006, 294, 26039, 51, 12, 18, 51240], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 933, "seek": 238926, "start": 2406.78, "end": 2409.3, "text": " was, I'm not sure if I have this verbatim,", "tokens": [51240, 390, 11, 286, 478, 406, 988, 498, 286, 362, 341, 9595, 267, 332, 11, 51366], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 934, "seek": 238926, "start": 2409.3, "end": 2411.78, "text": " but the title of that paper was large language models", "tokens": [51366, 457, 264, 4876, 295, 300, 3035, 390, 2416, 2856, 5245, 51490], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 935, "seek": 238926, "start": 2411.78, "end": 2413.94, "text": " are few shot learners.", "tokens": [51490, 366, 1326, 3347, 23655, 13, 51598], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 936, "seek": 238926, "start": 2413.94, "end": 2417.2200000000003, "text": " And the big kind of breakthrough observation there,", "tokens": [51598, 400, 264, 955, 733, 295, 22397, 14816, 456, 11, 51762], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 937, "seek": 238926, "start": 2417.2200000000003, "end": 2418.5800000000004, "text": " which I don't think they designed,", "tokens": [51762, 597, 286, 500, 380, 519, 436, 4761, 11, 51830], "temperature": 0.0, "avg_logprob": -0.1159653950886554, "compression_ratio": 1.7155963302752293, "no_speech_prob": 0.0019871173426508904}, {"id": 938, "seek": 241858, "start": 2419.58, "end": 2421.98, "text": " there's a whole quagmire of what should count", "tokens": [50414, 456, 311, 257, 1379, 421, 559, 76, 621, 295, 437, 820, 1207, 50534], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 939, "seek": 241858, "start": 2421.98, "end": 2423.54, "text": " as emergent or not emergent,", "tokens": [50534, 382, 4345, 6930, 420, 406, 4345, 6930, 11, 50612], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 940, "seek": 241858, "start": 2423.54, "end": 2426.7, "text": " but my understanding is they didn't specifically train", "tokens": [50612, 457, 452, 3701, 307, 436, 994, 380, 4682, 3847, 50770], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 941, "seek": 241858, "start": 2426.7, "end": 2430.74, "text": " for this few shot imitation capability,", "tokens": [50770, 337, 341, 1326, 3347, 47624, 13759, 11, 50972], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 942, "seek": 241858, "start": 2430.74, "end": 2433.66, "text": " but they nevertheless got to the point where", "tokens": [50972, 457, 436, 26924, 658, 281, 264, 935, 689, 51118], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 943, "seek": 241858, "start": 2433.66, "end": 2438.02, "text": " at runtime today, you can give a few examples", "tokens": [51118, 412, 34474, 965, 11, 291, 393, 976, 257, 1326, 5110, 51336], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 944, "seek": 241858, "start": 2438.02, "end": 2438.86, "text": " of what you want.", "tokens": [51336, 295, 437, 291, 528, 13, 51378], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 945, "seek": 241858, "start": 2438.86, "end": 2440.5, "text": " And in fact, that is like a best practice", "tokens": [51378, 400, 294, 1186, 11, 300, 307, 411, 257, 1151, 3124, 51460], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 946, "seek": 241858, "start": 2440.5, "end": 2443.14, "text": " that open AI and anthropic recommend", "tokens": [51460, 300, 1269, 7318, 293, 22727, 299, 2748, 51592], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 947, "seek": 241858, "start": 2443.14, "end": 2445.2599999999998, "text": " for how to get the most from their systems.", "tokens": [51592, 337, 577, 281, 483, 264, 881, 490, 641, 3652, 13, 51698], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 948, "seek": 241858, "start": 2445.2599999999998, "end": 2447.58, "text": " They'll say, some things are hard,", "tokens": [51698, 814, 603, 584, 11, 512, 721, 366, 1152, 11, 51814], "temperature": 0.0, "avg_logprob": -0.11930690893605977, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.00016343397146556526}, {"id": 949, "seek": 244758, "start": 2447.58, "end": 2449.38, "text": " they also have now trained them to follow instructions,", "tokens": [50364, 436, 611, 362, 586, 8895, 552, 281, 1524, 9415, 11, 50454], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 950, "seek": 244758, "start": 2449.38, "end": 2452.18, "text": " just verbatim or explicitly,", "tokens": [50454, 445, 9595, 267, 332, 420, 20803, 11, 50594], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 951, "seek": 244758, "start": 2452.18, "end": 2454.94, "text": " but they will still say that,", "tokens": [50594, 457, 436, 486, 920, 584, 300, 11, 50732], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 952, "seek": 244758, "start": 2454.94, "end": 2457.7799999999997, "text": " some things are better shown by example", "tokens": [50732, 512, 721, 366, 1101, 4898, 538, 1365, 50874], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 953, "seek": 244758, "start": 2457.7799999999997, "end": 2461.66, "text": " than described in terms of what to do.", "tokens": [50874, 813, 7619, 294, 2115, 295, 437, 281, 360, 13, 51068], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 954, "seek": 244758, "start": 2461.66, "end": 2465.62, "text": " So do that, and you'll get like a lot better performance.", "tokens": [51068, 407, 360, 300, 11, 293, 291, 603, 483, 411, 257, 688, 1101, 3389, 13, 51266], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 955, "seek": 244758, "start": 2465.62, "end": 2469.54, "text": " It seems to me that there is on that kind of watch,", "tokens": [51266, 467, 2544, 281, 385, 300, 456, 307, 322, 300, 733, 295, 1159, 11, 51462], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 956, "seek": 244758, "start": 2469.54, "end": 2471.8199999999997, "text": " watch it to borrow from medicine,", "tokens": [51462, 1159, 309, 281, 11172, 490, 7195, 11, 51576], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 957, "seek": 244758, "start": 2471.8199999999997, "end": 2474.18, "text": " watch one, do one, teach one,", "tokens": [51576, 1159, 472, 11, 360, 472, 11, 2924, 472, 11, 51694], "temperature": 0.0, "avg_logprob": -0.12889159304424397, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00010888517863349989}, {"id": 958, "seek": 247418, "start": 2474.18, "end": 2477.8199999999997, "text": " it seems like we're on the do one step,", "tokens": [50364, 309, 2544, 411, 321, 434, 322, 264, 360, 472, 1823, 11, 50546], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 959, "seek": 247418, "start": 2477.8199999999997, "end": 2482.58, "text": " and that does seem to be a pretty qualitative threshold", "tokens": [50546, 293, 300, 775, 1643, 281, 312, 257, 1238, 31312, 14678, 50784], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 960, "seek": 247418, "start": 2482.58, "end": 2483.4199999999996, "text": " that has been passed.", "tokens": [50784, 300, 575, 668, 4678, 13, 50826], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 961, "seek": 247418, "start": 2483.4199999999996, "end": 2486.18, "text": " Now, they obviously can continue to get better at that.", "tokens": [50826, 823, 11, 436, 2745, 393, 2354, 281, 483, 1101, 412, 300, 13, 50964], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 962, "seek": 247418, "start": 2486.18, "end": 2488.02, "text": " Right, but it's the range of things they can do", "tokens": [50964, 1779, 11, 457, 309, 311, 264, 3613, 295, 721, 436, 393, 360, 51056], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 963, "seek": 247418, "start": 2488.02, "end": 2489.1, "text": " that's the question.", "tokens": [51056, 300, 311, 264, 1168, 13, 51110], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 964, "seek": 247418, "start": 2489.1, "end": 2491.02, "text": " Yes, it's great that they can,", "tokens": [51110, 1079, 11, 309, 311, 869, 300, 436, 393, 11, 51206], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 965, "seek": 247418, "start": 2491.02, "end": 2493.4199999999996, "text": " you can say, here's some examples, give me another one,", "tokens": [51206, 291, 393, 584, 11, 510, 311, 512, 5110, 11, 976, 385, 1071, 472, 11, 51326], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 966, "seek": 247418, "start": 2493.4199999999996, "end": 2496.3399999999997, "text": " but the range of things you can do that for is limited.", "tokens": [51326, 457, 264, 3613, 295, 721, 291, 393, 360, 300, 337, 307, 5567, 13, 51472], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 967, "seek": 247418, "start": 2496.3399999999997, "end": 2498.3399999999997, "text": " Most people in most jobs,", "tokens": [51472, 4534, 561, 294, 881, 4782, 11, 51572], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 968, "seek": 247418, "start": 2498.3399999999997, "end": 2501.4199999999996, "text": " they couldn't have large language model swap in", "tokens": [51572, 436, 2809, 380, 362, 2416, 2856, 2316, 18135, 294, 51726], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 969, "seek": 247418, "start": 2501.4199999999996, "end": 2503.98, "text": " for many of their main tasks that way.", "tokens": [51726, 337, 867, 295, 641, 2135, 9608, 300, 636, 13, 51854], "temperature": 0.0, "avg_logprob": -0.1094793495556987, "compression_ratio": 1.7659574468085106, "no_speech_prob": 0.0009109181119129062}, {"id": 970, "seek": 250398, "start": 2504.94, "end": 2506.5, "text": " But there are some and that's exciting,", "tokens": [50412, 583, 456, 366, 512, 293, 300, 311, 4670, 11, 50490], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 971, "seek": 250398, "start": 2506.5, "end": 2508.98, "text": " and I hope to see people develop that and improve it.", "tokens": [50490, 293, 286, 1454, 281, 536, 561, 1499, 300, 293, 3470, 309, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 972, "seek": 250398, "start": 2508.98, "end": 2511.38, "text": " But again, the key question is how close are we", "tokens": [50614, 583, 797, 11, 264, 2141, 1168, 307, 577, 1998, 366, 321, 50734], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 973, "seek": 250398, "start": 2511.38, "end": 2514.7400000000002, "text": " to the end of this long path we've been on for a while?", "tokens": [50734, 281, 264, 917, 295, 341, 938, 3100, 321, 600, 668, 322, 337, 257, 1339, 30, 50902], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 974, "seek": 250398, "start": 2514.7400000000002, "end": 2516.46, "text": " Yeah, I guess I think about it a little bit differently", "tokens": [50902, 865, 11, 286, 2041, 286, 519, 466, 309, 257, 707, 857, 7614, 50988], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 975, "seek": 250398, "start": 2516.46, "end": 2519.06, "text": " in terms of rather than thinking about the end of the path,", "tokens": [50988, 294, 2115, 295, 2831, 813, 1953, 466, 264, 917, 295, 264, 3100, 11, 51118], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 976, "seek": 250398, "start": 2519.06, "end": 2523.78, "text": " I think of how close are we to key thresholds", "tokens": [51118, 286, 519, 295, 577, 1998, 366, 321, 281, 2141, 14678, 82, 51354], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 977, "seek": 250398, "start": 2523.78, "end": 2528.3, "text": " that will bring in qualitatively different dynamics", "tokens": [51354, 300, 486, 1565, 294, 31312, 356, 819, 15679, 51580], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 978, "seek": 250398, "start": 2528.3, "end": 2532.42, "text": " relative to the current situation.", "tokens": [51580, 4972, 281, 264, 2190, 2590, 13, 51786], "temperature": 0.0, "avg_logprob": -0.11084224016238482, "compression_ratio": 1.722007722007722, "no_speech_prob": 0.00022338000417221338}, {"id": 979, "seek": 253242, "start": 2532.62, "end": 2536.02, "text": " So one threshold that I think has recently been passed", "tokens": [50374, 407, 472, 14678, 300, 286, 519, 575, 3938, 668, 4678, 50544], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 980, "seek": 253242, "start": 2536.02, "end": 2538.1800000000003, "text": " and in a pretty striking way that this is,", "tokens": [50544, 293, 294, 257, 1238, 18559, 636, 300, 341, 307, 11, 50652], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 981, "seek": 253242, "start": 2538.1800000000003, "end": 2540.9, "text": " should get more discussion than it does in my view", "tokens": [50652, 820, 483, 544, 5017, 813, 309, 775, 294, 452, 1910, 50788], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 982, "seek": 253242, "start": 2540.9, "end": 2543.58, "text": " is Google DeepMind just put out a paper", "tokens": [50788, 307, 3329, 14895, 44, 471, 445, 829, 484, 257, 3035, 50922], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 983, "seek": 253242, "start": 2543.58, "end": 2548.58, "text": " not long ago where they showed basically a two to one", "tokens": [50922, 406, 938, 2057, 689, 436, 4712, 1936, 257, 732, 281, 472, 51172], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 984, "seek": 253242, "start": 2549.3, "end": 2551.7400000000002, "text": " advantage for a large language model", "tokens": [51208, 5002, 337, 257, 2416, 2856, 2316, 51330], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 985, "seek": 253242, "start": 2551.7400000000002, "end": 2556.3, "text": " in medical diagnosis versus human doctors.", "tokens": [51330, 294, 4625, 15217, 5717, 1952, 8778, 13, 51558], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 986, "seek": 253242, "start": 2556.3, "end": 2558.54, "text": " And then of course they also compared to human plus AI", "tokens": [51558, 400, 550, 295, 1164, 436, 611, 5347, 281, 1952, 1804, 7318, 51670], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 987, "seek": 253242, "start": 2558.54, "end": 2559.82, "text": " and that was in the middle.", "tokens": [51670, 293, 300, 390, 294, 264, 2808, 13, 51734], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 988, "seek": 253242, "start": 2559.82, "end": 2562.3, "text": " So on these cases that they lined up", "tokens": [51734, 407, 322, 613, 3331, 300, 436, 17189, 493, 51858], "temperature": 0.0, "avg_logprob": -0.11860511984143939, "compression_ratio": 1.589928057553957, "no_speech_prob": 0.00035689433570951223}, {"id": 989, "seek": 256230, "start": 2562.3, "end": 2565.42, "text": " in the scenario is like you're chatting with your doctor,", "tokens": [50364, 294, 264, 9005, 307, 411, 291, 434, 24654, 365, 428, 4631, 11, 50520], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 990, "seek": 256230, "start": 2565.42, "end": 2568.82, "text": " 60% accuracy from the language model,", "tokens": [50520, 4060, 4, 14170, 490, 264, 2856, 2316, 11, 50690], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 991, "seek": 256230, "start": 2568.82, "end": 2572.02, "text": " 30% accuracy from the human.", "tokens": [50690, 2217, 4, 14170, 490, 264, 1952, 13, 50850], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 992, "seek": 256230, "start": 2572.02, "end": 2575.6200000000003, "text": " I was an AI from 83 to 94.", "tokens": [50850, 286, 390, 364, 7318, 490, 30997, 281, 30849, 13, 51030], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 993, "seek": 256230, "start": 2576.94, "end": 2580.2200000000003, "text": " And at the beginning, one of the reasons I came into AI", "tokens": [51096, 400, 412, 264, 2863, 11, 472, 295, 264, 4112, 286, 1361, 666, 7318, 51260], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 994, "seek": 256230, "start": 2580.2200000000003, "end": 2582.94, "text": " was there were these big journal articles", "tokens": [51260, 390, 456, 645, 613, 955, 6708, 11290, 51396], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 995, "seek": 256230, "start": 2582.94, "end": 2585.2200000000003, "text": " and national media coverage about studies", "tokens": [51396, 293, 4048, 3021, 9645, 466, 5313, 51510], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 996, "seek": 256230, "start": 2585.2200000000003, "end": 2587.94, "text": " where they showed that the best AI of the time", "tokens": [51510, 689, 436, 4712, 300, 264, 1151, 7318, 295, 264, 565, 51646], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 997, "seek": 256230, "start": 2587.94, "end": 2589.82, "text": " which they called expert systems", "tokens": [51646, 597, 436, 1219, 5844, 3652, 51740], "temperature": 0.0, "avg_logprob": -0.1267059365498651, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0003352427447680384}, {"id": 998, "seek": 258982, "start": 2589.82, "end": 2594.02, "text": " were able to do human level medical diagnosis.", "tokens": [50364, 645, 1075, 281, 360, 1952, 1496, 4625, 15217, 13, 50574], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 999, "seek": 258982, "start": 2594.02, "end": 2597.38, "text": " This was in the early 1980s, right?", "tokens": [50574, 639, 390, 294, 264, 2440, 13626, 82, 11, 558, 30, 50742], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1000, "seek": 258982, "start": 2597.38, "end": 2599.04, "text": " We're talking 40 years ago.", "tokens": [50742, 492, 434, 1417, 3356, 924, 2057, 13, 50825], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1001, "seek": 258982, "start": 2599.92, "end": 2601.94, "text": " And obviously the computer capacity", "tokens": [50869, 400, 2745, 264, 3820, 6042, 50970], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1002, "seek": 258982, "start": 2601.94, "end": 2603.1800000000003, "text": " is vastly larger than that.", "tokens": [50970, 307, 41426, 4833, 813, 300, 13, 51032], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1003, "seek": 258982, "start": 2603.1800000000003, "end": 2606.2200000000003, "text": " So either they were lying back then", "tokens": [51032, 407, 2139, 436, 645, 8493, 646, 550, 51184], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1004, "seek": 258982, "start": 2606.2200000000003, "end": 2608.6200000000003, "text": " and messing with the data", "tokens": [51184, 293, 23258, 365, 264, 1412, 51304], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1005, "seek": 258982, "start": 2608.6200000000003, "end": 2613.02, "text": " or they did have human level diagnosis back then", "tokens": [51304, 420, 436, 630, 362, 1952, 1496, 15217, 646, 550, 51524], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1006, "seek": 258982, "start": 2613.02, "end": 2614.7000000000003, "text": " but they weren't allowed to apply it", "tokens": [51524, 457, 436, 4999, 380, 4350, 281, 3079, 309, 51608], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1007, "seek": 258982, "start": 2614.7000000000003, "end": 2616.3, "text": " because of medical licensing.", "tokens": [51608, 570, 295, 4625, 29759, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11734690717471544, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0007792452233843505}, {"id": 1008, "seek": 261630, "start": 2617.1800000000003, "end": 2619.9, "text": " So, and we're still not allowed to apply it", "tokens": [50408, 407, 11, 293, 321, 434, 920, 406, 4350, 281, 3079, 309, 50544], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1009, "seek": 261630, "start": 2619.9, "end": 2622.2200000000003, "text": " because of medical licensing.", "tokens": [50544, 570, 295, 4625, 29759, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1010, "seek": 261630, "start": 2622.2200000000003, "end": 2626.1400000000003, "text": " So, this is exactly the sort of ability", "tokens": [50660, 407, 11, 341, 307, 2293, 264, 1333, 295, 3485, 50856], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1011, "seek": 261630, "start": 2626.1400000000003, "end": 2629.42, "text": " that won't give substantial economic impact", "tokens": [50856, 300, 1582, 380, 976, 16726, 4836, 2712, 51020], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1012, "seek": 261630, "start": 2629.42, "end": 2631.3, "text": " because we had it 40 years ago", "tokens": [51020, 570, 321, 632, 309, 3356, 924, 2057, 51114], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1013, "seek": 261630, "start": 2631.3, "end": 2632.94, "text": " and it didn't have an impact then.", "tokens": [51114, 293, 309, 994, 380, 362, 364, 2712, 550, 13, 51196], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1014, "seek": 261630, "start": 2632.94, "end": 2634.2200000000003, "text": " Yeah, I don't know.", "tokens": [51196, 865, 11, 286, 500, 380, 458, 13, 51260], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1015, "seek": 261630, "start": 2634.2200000000003, "end": 2637.7000000000003, "text": " So if I had, I think one qualitative difference", "tokens": [51260, 407, 498, 286, 632, 11, 286, 519, 472, 31312, 2649, 51434], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1016, "seek": 261630, "start": 2637.7000000000003, "end": 2639.78, "text": " between that earlier system and this system", "tokens": [51434, 1296, 300, 3071, 1185, 293, 341, 1185, 51538], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1017, "seek": 261630, "start": 2639.78, "end": 2641.2200000000003, "text": " which won't come to be an expert", "tokens": [51538, 597, 1582, 380, 808, 281, 312, 364, 5844, 51610], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1018, "seek": 261630, "start": 2641.2200000000003, "end": 2642.7400000000002, "text": " in the earlier expert systems", "tokens": [51610, 294, 264, 3071, 5844, 3652, 51686], "temperature": 0.0, "avg_logprob": -0.11625897118804651, "compression_ratio": 1.6311475409836065, "no_speech_prob": 0.00027800409588962793}, {"id": 1019, "seek": 264274, "start": 2642.74, "end": 2647.74, "text": " but I would guess that a huge difference", "tokens": [50364, 457, 286, 576, 2041, 300, 257, 2603, 2649, 50614], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1020, "seek": 264274, "start": 2648.22, "end": 2653.1, "text": " is that you can take today a totally uninitiated person", "tokens": [50638, 307, 300, 291, 393, 747, 965, 257, 3879, 43456, 8707, 770, 954, 50882], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1021, "seek": 264274, "start": 2653.1, "end": 2655.3399999999997, "text": " who has a medical concern", "tokens": [50882, 567, 575, 257, 4625, 3136, 50994], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1022, "seek": 264274, "start": 2655.3399999999997, "end": 2657.9399999999996, "text": " and say, sit in front of this computer,", "tokens": [50994, 293, 584, 11, 1394, 294, 1868, 295, 341, 3820, 11, 51124], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1023, "seek": 264274, "start": 2657.9399999999996, "end": 2659.54, "text": " talk to this doctor.", "tokens": [51124, 751, 281, 341, 4631, 13, 51204], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1024, "seek": 264274, "start": 2659.54, "end": 2661.7599999999998, "text": " They don't even need to know as an AI doctor.", "tokens": [51204, 814, 500, 380, 754, 643, 281, 458, 382, 364, 7318, 4631, 13, 51315], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1025, "seek": 264274, "start": 2661.7599999999998, "end": 2663.4599999999996, "text": " They can just talk to him.", "tokens": [51315, 814, 393, 445, 751, 281, 796, 13, 51400], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1026, "seek": 264274, "start": 2663.4599999999996, "end": 2665.7, "text": " That wasn't the problem back then.", "tokens": [51400, 663, 2067, 380, 264, 1154, 646, 550, 13, 51512], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1027, "seek": 264274, "start": 2665.7, "end": 2667.9399999999996, "text": " They could have made these expert systems", "tokens": [51512, 814, 727, 362, 1027, 613, 5844, 3652, 51624], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1028, "seek": 264274, "start": 2667.9399999999996, "end": 2671.22, "text": " usable by ordinary people with modest effort.", "tokens": [51624, 29975, 538, 10547, 561, 365, 25403, 4630, 13, 51788], "temperature": 0.0, "avg_logprob": -0.11556801429161659, "compression_ratio": 1.5924369747899159, "no_speech_prob": 8.219028677558526e-05}, {"id": 1029, "seek": 267122, "start": 2671.22, "end": 2673.18, "text": " That wasn't the problem in using them.", "tokens": [50364, 663, 2067, 380, 264, 1154, 294, 1228, 552, 13, 50462], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1030, "seek": 267122, "start": 2673.18, "end": 2675.7799999999997, "text": " The problem was just you're not legally allowed to use them.", "tokens": [50462, 440, 1154, 390, 445, 291, 434, 406, 21106, 4350, 281, 764, 552, 13, 50592], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1031, "seek": 267122, "start": 2675.7799999999997, "end": 2678.7, "text": " Only doctors are allowed to give medical diagnoses.", "tokens": [50592, 5686, 8778, 366, 4350, 281, 976, 4625, 7234, 4201, 13, 50738], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1032, "seek": 267122, "start": 2678.7, "end": 2680.9399999999996, "text": " And so only doctors are allowed to use these systems", "tokens": [50738, 400, 370, 787, 8778, 366, 4350, 281, 764, 613, 3652, 50850], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1033, "seek": 267122, "start": 2680.9399999999996, "end": 2681.7799999999997, "text": " to talk to people.", "tokens": [50850, 281, 751, 281, 561, 13, 50892], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1034, "seek": 267122, "start": 2681.7799999999997, "end": 2684.66, "text": " That was the main obstacle and it still is today.", "tokens": [50892, 663, 390, 264, 2135, 23112, 293, 309, 920, 307, 965, 13, 51036], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1035, "seek": 267122, "start": 2684.66, "end": 2688.2999999999997, "text": " The obstacle, you could make such a system today", "tokens": [51036, 440, 23112, 11, 291, 727, 652, 1270, 257, 1185, 965, 51218], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1036, "seek": 267122, "start": 2688.2999999999997, "end": 2689.4599999999996, "text": " that ordinary people could talk to", "tokens": [51218, 300, 10547, 561, 727, 751, 281, 51276], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1037, "seek": 267122, "start": 2689.4599999999996, "end": 2691.06, "text": " but they're not allowed to talk to it", "tokens": [51276, 457, 436, 434, 406, 4350, 281, 751, 281, 309, 51356], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1038, "seek": 267122, "start": 2691.06, "end": 2694.22, "text": " and they won't be allowed to talk to it for a long time.", "tokens": [51356, 293, 436, 1582, 380, 312, 4350, 281, 751, 281, 309, 337, 257, 938, 565, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1039, "seek": 267122, "start": 2694.22, "end": 2695.8599999999997, "text": " I think there is a qualitative difference", "tokens": [51514, 286, 519, 456, 307, 257, 31312, 2649, 51596], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1040, "seek": 267122, "start": 2695.8599999999997, "end": 2697.06, "text": " between these systems.", "tokens": [51596, 1296, 613, 3652, 13, 51656], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1041, "seek": 267122, "start": 2697.06, "end": 2699.18, "text": " If I were to sit down in front of the early 80s thing", "tokens": [51656, 759, 286, 645, 281, 1394, 760, 294, 1868, 295, 264, 2440, 4688, 82, 551, 51762], "temperature": 0.0, "avg_logprob": -0.09755077109431588, "compression_ratio": 1.9096989966555185, "no_speech_prob": 0.0002377911878284067}, {"id": 1042, "seek": 269918, "start": 2699.22, "end": 2701.58, "text": " and I were to say, what's different today", "tokens": [50366, 293, 286, 645, 281, 584, 11, 437, 311, 819, 965, 50484], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1043, "seek": 269918, "start": 2701.58, "end": 2703.8199999999997, "text": " is the chat system could say,", "tokens": [50484, 307, 264, 5081, 1185, 727, 584, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1044, "seek": 269918, "start": 2703.8199999999997, "end": 2705.06, "text": " Robin, tell me how you're feeling.", "tokens": [50596, 16533, 11, 980, 385, 577, 291, 434, 2633, 13, 50658], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1045, "seek": 269918, "start": 2705.06, "end": 2706.1, "text": " Tell me about your experience.", "tokens": [50658, 5115, 385, 466, 428, 1752, 13, 50710], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1046, "seek": 269918, "start": 2706.1, "end": 2708.06, "text": " And you can just go on in your own language,", "tokens": [50710, 400, 291, 393, 445, 352, 322, 294, 428, 1065, 2856, 11, 50808], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1047, "seek": 269918, "start": 2708.06, "end": 2709.7799999999997, "text": " however you want to express yourself,", "tokens": [50808, 4461, 291, 528, 281, 5109, 1803, 11, 50894], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1048, "seek": 269918, "start": 2709.7799999999997, "end": 2710.7799999999997, "text": " and it can get you.", "tokens": [50894, 293, 309, 393, 483, 291, 13, 50944], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1049, "seek": 269918, "start": 2710.7799999999997, "end": 2713.14, "text": " And then it can ask you specific follow up", "tokens": [50944, 400, 550, 309, 393, 1029, 291, 2685, 1524, 493, 51062], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1050, "seek": 269918, "start": 2713.14, "end": 2714.4199999999996, "text": " but you're not going through a wizard", "tokens": [51062, 457, 291, 434, 406, 516, 807, 257, 25807, 51126], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1051, "seek": 269918, "start": 2714.4199999999996, "end": 2716.94, "text": " and going down an expert system tree", "tokens": [51126, 293, 516, 760, 364, 5844, 1185, 4230, 51252], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1052, "seek": 269918, "start": 2716.94, "end": 2719.94, "text": " and ask for numeric scores you don't understand", "tokens": [51252, 293, 1029, 337, 7866, 299, 13444, 291, 500, 380, 1223, 51402], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1053, "seek": 269918, "start": 2719.94, "end": 2720.7799999999997, "text": " and don't know.", "tokens": [51402, 293, 500, 380, 458, 13, 51444], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1054, "seek": 269918, "start": 2720.7799999999997, "end": 2722.62, "text": " You can literally just express yourself.", "tokens": [51444, 509, 393, 3736, 445, 5109, 1803, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1055, "seek": 269918, "start": 2722.62, "end": 2723.8199999999997, "text": " That was not there then, right?", "tokens": [51536, 663, 390, 406, 456, 550, 11, 558, 30, 51596], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1056, "seek": 269918, "start": 2723.8199999999997, "end": 2725.1, "text": " I mean, nothing.", "tokens": [51596, 286, 914, 11, 1825, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1057, "seek": 269918, "start": 2725.1, "end": 2728.1, "text": " But that's not the limiting factor, right?", "tokens": [51660, 583, 300, 311, 406, 264, 22083, 5952, 11, 558, 30, 51810], "temperature": 0.0, "avg_logprob": -0.1455284094660537, "compression_ratio": 1.7619047619047619, "no_speech_prob": 0.001548434142023325}, {"id": 1058, "seek": 272810, "start": 2728.1, "end": 2730.7, "text": " I mean, you couldn't have a fancy graphics interface", "tokens": [50364, 286, 914, 11, 291, 2809, 380, 362, 257, 10247, 11837, 9226, 50494], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1059, "seek": 272810, "start": 2730.7, "end": 2731.54, "text": " back then either.", "tokens": [50494, 646, 550, 2139, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1060, "seek": 272810, "start": 2731.54, "end": 2733.94, "text": " This was early 1980s, right?", "tokens": [50536, 639, 390, 2440, 13626, 82, 11, 558, 30, 50656], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1061, "seek": 272810, "start": 2733.94, "end": 2737.46, "text": " But again, the limiting factor is the legal barrier.", "tokens": [50656, 583, 797, 11, 264, 22083, 5952, 307, 264, 5089, 13357, 13, 50832], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1062, "seek": 272810, "start": 2738.3399999999997, "end": 2739.74, "text": " It was back then and still is", "tokens": [50876, 467, 390, 646, 550, 293, 920, 307, 50946], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1063, "seek": 272810, "start": 2739.74, "end": 2741.58, "text": " and that legal barrier doesn't look like", "tokens": [50946, 293, 300, 5089, 13357, 1177, 380, 574, 411, 51038], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1064, "seek": 272810, "start": 2741.58, "end": 2743.18, "text": " it's about to go away.", "tokens": [51038, 309, 311, 466, 281, 352, 1314, 13, 51118], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1065, "seek": 272810, "start": 2743.18, "end": 2745.94, "text": " So if you're gonna make us excited about applications", "tokens": [51118, 407, 498, 291, 434, 799, 652, 505, 2919, 466, 5821, 51256], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1066, "seek": 272810, "start": 2745.94, "end": 2748.54, "text": " it'll have to be something that's legal.", "tokens": [51256, 309, 603, 362, 281, 312, 746, 300, 311, 5089, 13, 51386], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1067, "seek": 272810, "start": 2748.54, "end": 2752.3399999999997, "text": " My model of this is that the consumer surplus", "tokens": [51386, 1222, 2316, 295, 341, 307, 300, 264, 9711, 31019, 51576], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1068, "seek": 272810, "start": 2752.3399999999997, "end": 2755.5, "text": " of this type of thing is going to be so great.", "tokens": [51576, 295, 341, 2010, 295, 551, 307, 516, 281, 312, 370, 869, 13, 51734], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1069, "seek": 272810, "start": 2755.5, "end": 2756.86, "text": " It already was 40 years ago.", "tokens": [51734, 467, 1217, 390, 3356, 924, 2057, 13, 51802], "temperature": 0.0, "avg_logprob": -0.10162805410531851, "compression_ratio": 1.613240418118467, "no_speech_prob": 9.313712507719174e-05}, {"id": 1070, "seek": 275686, "start": 2756.9, "end": 2758.42, "text": " It would have been a huge consumer surplus", "tokens": [50366, 467, 576, 362, 668, 257, 2603, 9711, 31019, 50442], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1071, "seek": 275686, "start": 2758.42, "end": 2760.6200000000003, "text": " 40 years ago, it was not allowed.", "tokens": [50442, 3356, 924, 2057, 11, 309, 390, 406, 4350, 13, 50552], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1072, "seek": 275686, "start": 2760.6200000000003, "end": 2763.1400000000003, "text": " But there was never a groundswell of, I don't know.", "tokens": [50552, 583, 456, 390, 1128, 257, 19196, 6326, 295, 11, 286, 500, 380, 458, 13, 50678], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1073, "seek": 275686, "start": 2763.1400000000003, "end": 2764.1800000000003, "text": " I'm just not buying this.", "tokens": [50678, 286, 478, 445, 406, 6382, 341, 13, 50730], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1074, "seek": 275686, "start": 2764.1800000000003, "end": 2766.3, "text": " I'm not buying that there was an experience", "tokens": [50730, 286, 478, 406, 6382, 300, 456, 390, 364, 1752, 50836], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1075, "seek": 275686, "start": 2766.3, "end": 2769.1, "text": " that is qualitatively like the one that we have today", "tokens": [50836, 300, 307, 31312, 356, 411, 264, 472, 300, 321, 362, 965, 50976], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1076, "seek": 275686, "start": 2769.1, "end": 2773.26, "text": " such that I think today if you show people what Google has", "tokens": [50976, 1270, 300, 286, 519, 965, 498, 291, 855, 561, 437, 3329, 575, 51184], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1077, "seek": 275686, "start": 2773.26, "end": 2776.42, "text": " they will say it is not acceptable to me", "tokens": [51184, 436, 486, 584, 309, 307, 406, 15513, 281, 385, 51342], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1078, "seek": 275686, "start": 2776.42, "end": 2779.9, "text": " that you keep this locked up behind some payroll.", "tokens": [51342, 300, 291, 1066, 341, 9376, 493, 2261, 512, 36873, 13, 51516], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1079, "seek": 275686, "start": 2779.9, "end": 2782.82, "text": " I don't think that was the general consumer reaction", "tokens": [51516, 286, 500, 380, 519, 300, 390, 264, 2674, 9711, 5480, 51662], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1080, "seek": 275686, "start": 2782.82, "end": 2785.6200000000003, "text": " to early 80s expert systems.", "tokens": [51662, 281, 2440, 4688, 82, 5844, 3652, 13, 51802], "temperature": 0.0, "avg_logprob": -0.10923842650193434, "compression_ratio": 1.7224199288256228, "no_speech_prob": 0.00014882450341247022}, {"id": 1081, "seek": 278562, "start": 2785.66, "end": 2789.58, "text": " And it seems like that political economy pressure", "tokens": [50366, 400, 309, 2544, 411, 300, 3905, 5010, 3321, 50562], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1082, "seek": 278562, "start": 2789.58, "end": 2791.18, "text": " could change things.", "tokens": [50562, 727, 1319, 721, 13, 50642], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1083, "seek": 278562, "start": 2791.18, "end": 2793.74, "text": " Consider the analogy of nuclear power.", "tokens": [50642, 17416, 264, 21663, 295, 8179, 1347, 13, 50770], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1084, "seek": 278562, "start": 2793.74, "end": 2796.1, "text": " The world has definitely been convinced for a long time", "tokens": [50770, 440, 1002, 575, 2138, 668, 12561, 337, 257, 938, 565, 50888], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1085, "seek": 278562, "start": 2796.1, "end": 2798.62, "text": " that nuclear power is powerful.", "tokens": [50888, 300, 8179, 1347, 307, 4005, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1086, "seek": 278562, "start": 2799.46, "end": 2802.72, "text": " It is full of potential and power.", "tokens": [51056, 467, 307, 1577, 295, 3995, 293, 1347, 13, 51219], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1087, "seek": 278562, "start": 2802.72, "end": 2804.62, "text": " And if we had let it go wild", "tokens": [51219, 400, 498, 321, 632, 718, 309, 352, 4868, 51314], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1088, "seek": 278562, "start": 2804.62, "end": 2806.54, "text": " we would have vastly cheaper energy today", "tokens": [51314, 321, 576, 362, 41426, 12284, 2281, 965, 51410], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1089, "seek": 278562, "start": 2806.54, "end": 2808.5, "text": " but it was that power that scared people", "tokens": [51410, 457, 309, 390, 300, 1347, 300, 5338, 561, 51508], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1090, "seek": 278562, "start": 2808.5, "end": 2811.14, "text": " which is why we don't have that energy today.", "tokens": [51508, 597, 307, 983, 321, 500, 380, 362, 300, 2281, 965, 13, 51640], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1091, "seek": 278562, "start": 2811.14, "end": 2814.58, "text": " The very vision of nuclear energy being powerful", "tokens": [51640, 440, 588, 5201, 295, 8179, 2281, 885, 4005, 51812], "temperature": 0.0, "avg_logprob": -0.0760468036756603, "compression_ratio": 1.71484375, "no_speech_prob": 0.00044411237468011677}, {"id": 1092, "seek": 281458, "start": 2814.58, "end": 2817.18, "text": " is what caused us not to have it.", "tokens": [50364, 307, 437, 7008, 505, 406, 281, 362, 309, 13, 50494], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1093, "seek": 281458, "start": 2818.54, "end": 2821.62, "text": " We over-regulated it to death", "tokens": [50562, 492, 670, 12, 3375, 6987, 309, 281, 2966, 50716], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1094, "seek": 281458, "start": 2821.62, "end": 2824.14, "text": " and we made sure that the power of nuclear power", "tokens": [50716, 293, 321, 1027, 988, 300, 264, 1347, 295, 8179, 1347, 50842], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1095, "seek": 281458, "start": 2824.14, "end": 2825.66, "text": " was not released.", "tokens": [50842, 390, 406, 4736, 13, 50918], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1096, "seek": 281458, "start": 2825.66, "end": 2827.18, "text": " We believed the power was there.", "tokens": [50918, 492, 7847, 264, 1347, 390, 456, 13, 50994], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1097, "seek": 281458, "start": 2827.18, "end": 2829.62, "text": " It was not at all an issue of not believing", "tokens": [50994, 467, 390, 406, 412, 439, 364, 2734, 295, 406, 16594, 51116], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1098, "seek": 281458, "start": 2829.62, "end": 2830.9, "text": " that nuclear power was powerful.", "tokens": [51116, 300, 8179, 1347, 390, 4005, 13, 51180], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1099, "seek": 281458, "start": 2830.9, "end": 2833.34, "text": " It was believing it was too powerful.", "tokens": [51180, 467, 390, 16594, 309, 390, 886, 4005, 13, 51302], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1100, "seek": 281458, "start": 2833.34, "end": 2835.86, "text": " Scary, dangerous, powerful.", "tokens": [51302, 45504, 11, 5795, 11, 4005, 13, 51428], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1101, "seek": 281458, "start": 2835.86, "end": 2838.88, "text": " And there's a risk that we'll do that with AI today.", "tokens": [51428, 400, 456, 311, 257, 3148, 300, 321, 603, 360, 300, 365, 7318, 965, 13, 51579], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1102, "seek": 281458, "start": 2839.84, "end": 2841.5, "text": " We will make people believe it's powerful,", "tokens": [51627, 492, 486, 652, 561, 1697, 309, 311, 4005, 11, 51710], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1103, "seek": 281458, "start": 2841.5, "end": 2843.62, "text": " so powerful that they should be scared of it", "tokens": [51710, 370, 4005, 300, 436, 820, 312, 5338, 295, 309, 51816], "temperature": 0.0, "avg_logprob": -0.1295572311159164, "compression_ratio": 1.9184549356223175, "no_speech_prob": 0.0007791147218085825}, {"id": 1104, "seek": 284362, "start": 2843.62, "end": 2844.98, "text": " and it should be locked down", "tokens": [50364, 293, 309, 820, 312, 9376, 760, 50432], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1105, "seek": 284362, "start": 2844.98, "end": 2847.62, "text": " and not released into the wild", "tokens": [50432, 293, 406, 4736, 666, 264, 4868, 50564], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1106, "seek": 284362, "start": 2847.62, "end": 2849.8199999999997, "text": " where it might do us terrible danger.", "tokens": [50564, 689, 309, 1062, 360, 505, 6237, 4330, 13, 50674], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1107, "seek": 284362, "start": 2849.8199999999997, "end": 2851.5, "text": " Yeah, well, that's certainly a tragic outcome", "tokens": [50674, 865, 11, 731, 11, 300, 311, 3297, 257, 20385, 9700, 50758], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1108, "seek": 284362, "start": 2851.5, "end": 2853.9, "text": " in the case of the nuclear power.", "tokens": [50758, 294, 264, 1389, 295, 264, 8179, 1347, 13, 50878], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1109, "seek": 284362, "start": 2853.9, "end": 2855.98, "text": " And I think it would also be a tragic outcome", "tokens": [50878, 400, 286, 519, 309, 576, 611, 312, 257, 20385, 9700, 50982], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1110, "seek": 284362, "start": 2855.98, "end": 2858.9, "text": " if people are denied their AI doctors", "tokens": [50982, 498, 561, 366, 17774, 641, 7318, 8778, 51128], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1111, "seek": 284362, "start": 2858.9, "end": 2863.22, "text": " of the future on that basis.", "tokens": [51128, 295, 264, 2027, 322, 300, 5143, 13, 51344], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1112, "seek": 284362, "start": 2863.22, "end": 2864.54, "text": " And it could happen.", "tokens": [51344, 400, 309, 727, 1051, 13, 51410], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1113, "seek": 284362, "start": 2864.54, "end": 2867.22, "text": " I certainly wouldn't rule out the possibility that", "tokens": [51410, 286, 3297, 2759, 380, 4978, 484, 264, 7959, 300, 51544], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1114, "seek": 284362, "start": 2867.22, "end": 2869.62, "text": " just AI research probably gets made illegal.", "tokens": [51544, 445, 7318, 2132, 1391, 2170, 1027, 11905, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1115, "seek": 284362, "start": 2869.62, "end": 2871.7799999999997, "text": " This time we do have, I mean, again, it is,", "tokens": [51664, 639, 565, 321, 360, 362, 11, 286, 914, 11, 797, 11, 309, 307, 11, 51772], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1116, "seek": 284362, "start": 2871.7799999999997, "end": 2873.18, "text": " I do think we're in a different regime now", "tokens": [51772, 286, 360, 519, 321, 434, 294, 257, 819, 13120, 586, 51842], "temperature": 0.0, "avg_logprob": -0.11145631004782285, "compression_ratio": 1.6689189189189189, "no_speech_prob": 0.000119573283882346}, {"id": 1117, "seek": 287318, "start": 2873.22, "end": 2877.18, "text": " where enough has been discovered", "tokens": [50366, 689, 1547, 575, 668, 6941, 50564], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1118, "seek": 287318, "start": 2877.18, "end": 2879.58, "text": " and enough has been put into the hands of millions.", "tokens": [50564, 293, 1547, 575, 668, 829, 666, 264, 2377, 295, 6803, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1119, "seek": 287318, "start": 2879.58, "end": 2884.2599999999998, "text": " There is sort of the open source kind of hacker level.", "tokens": [50684, 821, 307, 1333, 295, 264, 1269, 4009, 733, 295, 38155, 1496, 13, 50918], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1120, "seek": 287318, "start": 2884.2599999999998, "end": 2886.1, "text": " Not medical diagnosis is not.", "tokens": [50918, 1726, 4625, 15217, 307, 406, 13, 51010], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1121, "seek": 287318, "start": 2886.1, "end": 2888.46, "text": " We have not put medical diagnosis AI", "tokens": [51010, 492, 362, 406, 829, 4625, 15217, 7318, 51128], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1122, "seek": 287318, "start": 2888.46, "end": 2890.46, "text": " in the hands of ordinary people.", "tokens": [51128, 294, 264, 2377, 295, 10547, 561, 13, 51228], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1123, "seek": 287318, "start": 2890.46, "end": 2892.3799999999997, "text": " And if you tried it, you would find out", "tokens": [51228, 400, 498, 291, 3031, 309, 11, 291, 576, 915, 484, 51324], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1124, "seek": 287318, "start": 2892.3799999999997, "end": 2894.5, "text": " just how quickly you'd get slapped now.", "tokens": [51324, 445, 577, 2661, 291, 1116, 483, 43309, 586, 13, 51430], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1125, "seek": 287318, "start": 2894.5, "end": 2896.2999999999997, "text": " Yeah, I think I know someone who actually may be", "tokens": [51430, 865, 11, 286, 519, 286, 458, 1580, 567, 767, 815, 312, 51520], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1126, "seek": 287318, "start": 2896.2999999999997, "end": 2898.54, "text": " about to try this and it'll be very interesting", "tokens": [51520, 466, 281, 853, 341, 293, 309, 603, 312, 588, 1880, 51632], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1127, "seek": 287318, "start": 2898.54, "end": 2901.66, "text": " to see how quickly and how hard they get slapped down", "tokens": [51632, 281, 536, 577, 2661, 293, 577, 1152, 436, 483, 43309, 760, 51788], "temperature": 0.0, "avg_logprob": -0.10497815046853166, "compression_ratio": 1.7279411764705883, "no_speech_prob": 0.0001686142641119659}, {"id": 1128, "seek": 290166, "start": 2901.94, "end": 2903.58, "text": " and how they may respond from it.", "tokens": [50378, 293, 577, 436, 815, 4196, 490, 309, 13, 50460], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1129, "seek": 290166, "start": 2903.58, "end": 2906.14, "text": " I've actually been very encouraged by the response", "tokens": [50460, 286, 600, 767, 668, 588, 14658, 538, 264, 4134, 50588], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1130, "seek": 290166, "start": 2906.14, "end": 2907.98, "text": " from the medical community.", "tokens": [50588, 490, 264, 4625, 1768, 13, 50680], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1131, "seek": 290166, "start": 2908.8199999999997, "end": 2910.94, "text": " I would say, obviously it's not a monolithic thing,", "tokens": [50722, 286, 576, 584, 11, 2745, 309, 311, 406, 257, 1108, 42878, 551, 11, 50828], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1132, "seek": 290166, "start": 2910.94, "end": 2914.3799999999997, "text": " but I did an earlier episode with Zach Kahane,", "tokens": [50828, 457, 286, 630, 364, 3071, 3500, 365, 21028, 39444, 1929, 11, 51000], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1133, "seek": 290166, "start": 2914.3799999999997, "end": 2917.46, "text": " who is a professor at Harvard Medical School", "tokens": [51000, 567, 307, 257, 8304, 412, 13378, 15896, 5070, 51154], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1134, "seek": 290166, "start": 2917.46, "end": 2920.3399999999997, "text": " and who had early access to GPT-4.", "tokens": [51154, 293, 567, 632, 2440, 2105, 281, 26039, 51, 12, 19, 13, 51298], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1135, "seek": 290166, "start": 2920.3399999999997, "end": 2921.7799999999997, "text": " He came out with a book basically", "tokens": [51298, 634, 1361, 484, 365, 257, 1446, 1936, 51370], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1136, "seek": 290166, "start": 2921.7799999999997, "end": 2924.8599999999997, "text": " to coincide with the launch of GPT-4", "tokens": [51370, 281, 13001, 482, 365, 264, 4025, 295, 26039, 51, 12, 19, 51524], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1137, "seek": 290166, "start": 2924.8599999999997, "end": 2928.54, "text": " called GPT-4 and the Revolution in Medicine.", "tokens": [51524, 1219, 26039, 51, 12, 19, 293, 264, 16617, 294, 20338, 13, 51708], "temperature": 0.0, "avg_logprob": -0.10784946638962319, "compression_ratio": 1.5593869731800767, "no_speech_prob": 0.0017000065417960286}, {"id": 1138, "seek": 292854, "start": 2928.54, "end": 2933.54, "text": " And broadly, I have been encouraged by how much", "tokens": [50364, 400, 19511, 11, 286, 362, 668, 14658, 538, 577, 709, 50614], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1139, "seek": 292854, "start": 2933.9, "end": 2937.18, "text": " the medical establishment has seemingly been inclined", "tokens": [50632, 264, 4625, 20971, 575, 18709, 668, 28173, 50796], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1140, "seek": 292854, "start": 2937.18, "end": 2939.58, "text": " to embrace this sort of stuff.", "tokens": [50796, 281, 14038, 341, 1333, 295, 1507, 13, 50916], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1141, "seek": 292854, "start": 2939.58, "end": 2941.18, "text": " I don't know if it's just that they're also", "tokens": [50916, 286, 500, 380, 458, 498, 309, 311, 445, 300, 436, 434, 611, 50996], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1142, "seek": 292854, "start": 2941.18, "end": 2943.22, "text": " overworked these days or...", "tokens": [50996, 670, 1902, 292, 613, 1708, 420, 485, 51098], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1143, "seek": 292854, "start": 2943.22, "end": 2945.46, "text": " Well, they'll embrace the internal use of it.", "tokens": [51098, 1042, 11, 436, 603, 14038, 264, 6920, 764, 295, 309, 13, 51210], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1144, "seek": 292854, "start": 2945.46, "end": 2949.5, "text": " Again, it's always been doctors allowed to use these things.", "tokens": [51210, 3764, 11, 309, 311, 1009, 668, 8778, 4350, 281, 764, 613, 721, 13, 51412], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1145, "seek": 292854, "start": 2949.5, "end": 2951.22, "text": " And the main reason they didn't get more popular", "tokens": [51412, 400, 264, 2135, 1778, 436, 994, 380, 483, 544, 3743, 51498], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1146, "seek": 292854, "start": 2951.22, "end": 2953.54, "text": " is doctors couldn't be bothered to type in", "tokens": [51498, 307, 8778, 2809, 380, 312, 22996, 281, 2010, 294, 51614], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1147, "seek": 292854, "start": 2953.54, "end": 2955.42, "text": " and input all the information", "tokens": [51614, 293, 4846, 439, 264, 1589, 51708], "temperature": 0.0, "avg_logprob": -0.09806500493952658, "compression_ratio": 1.6401515151515151, "no_speech_prob": 4.264201925252564e-05}, {"id": 1148, "seek": 295542, "start": 2955.42, "end": 2958.82, "text": " because they want to have short meetings with patients.", "tokens": [50364, 570, 436, 528, 281, 362, 2099, 8410, 365, 4209, 13, 50534], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1149, "seek": 295542, "start": 2958.82, "end": 2961.46, "text": " Even today, of course, if you've gone to a modern doctor,", "tokens": [50534, 2754, 965, 11, 295, 1164, 11, 498, 291, 600, 2780, 281, 257, 4363, 4631, 11, 50666], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1150, "seek": 295542, "start": 2961.46, "end": 2963.26, "text": " most of your meeting with a doctor", "tokens": [50666, 881, 295, 428, 3440, 365, 257, 4631, 50756], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1151, "seek": 295542, "start": 2963.26, "end": 2966.7000000000003, "text": " is them typing in information to their computer", "tokens": [50756, 307, 552, 18444, 294, 1589, 281, 641, 3820, 50928], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1152, "seek": 295542, "start": 2966.7000000000003, "end": 2968.2200000000003, "text": " as they talk to you.", "tokens": [50928, 382, 436, 751, 281, 291, 13, 51004], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1153, "seek": 295542, "start": 2968.2200000000003, "end": 2970.62, "text": " And they don't wanna spend much more time", "tokens": [51004, 400, 436, 500, 380, 1948, 3496, 709, 544, 565, 51124], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1154, "seek": 295542, "start": 2970.62, "end": 2971.94, "text": " typing in more.", "tokens": [51124, 18444, 294, 544, 13, 51190], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1155, "seek": 295542, "start": 2971.94, "end": 2974.96, "text": " And so they don't wanna use computer aids", "tokens": [51190, 400, 370, 436, 500, 380, 1948, 764, 3820, 28447, 51341], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1156, "seek": 295542, "start": 2974.96, "end": 2976.98, "text": " in their diagnosis and that's been true for a long time.", "tokens": [51341, 294, 641, 15217, 293, 300, 311, 668, 2074, 337, 257, 938, 565, 13, 51442], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1157, "seek": 295542, "start": 2976.98, "end": 2979.2200000000003, "text": " They, computer diagnosis aids have been available", "tokens": [51442, 814, 11, 3820, 15217, 28447, 362, 668, 2435, 51554], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1158, "seek": 295542, "start": 2979.2200000000003, "end": 2981.94, "text": " for a long time that would give them better diagnoses", "tokens": [51554, 337, 257, 938, 565, 300, 576, 976, 552, 1101, 7234, 4201, 51690], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1159, "seek": 295542, "start": 2981.94, "end": 2984.1800000000003, "text": " at the cost of them having to spend more time with them", "tokens": [51690, 412, 264, 2063, 295, 552, 1419, 281, 3496, 544, 565, 365, 552, 51802], "temperature": 0.0, "avg_logprob": -0.11941842065341231, "compression_ratio": 1.9418181818181819, "no_speech_prob": 0.00023048032016959041}, {"id": 1160, "seek": 298418, "start": 2984.2599999999998, "end": 2985.7, "text": " than they've chosen not to spend more time.", "tokens": [50368, 813, 436, 600, 8614, 406, 281, 3496, 544, 565, 13, 50440], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1161, "seek": 298418, "start": 2985.7, "end": 2987.58, "text": " That's been true for many decades now.", "tokens": [50440, 663, 311, 668, 2074, 337, 867, 7878, 586, 13, 50534], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1162, "seek": 298418, "start": 2987.58, "end": 2992.18, "text": " Have you personally used GPT-4 for any advanced things", "tokens": [50534, 3560, 291, 5665, 1143, 26039, 51, 12, 19, 337, 604, 7339, 721, 50764], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1163, "seek": 298418, "start": 2992.18, "end": 2995.4199999999996, "text": " like this, medical or legal advice or whatever?", "tokens": [50764, 411, 341, 11, 4625, 420, 5089, 5192, 420, 2035, 30, 50926], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1164, "seek": 298418, "start": 2995.4199999999996, "end": 2997.2999999999997, "text": " No, I'm an economics professor.", "tokens": [50926, 883, 11, 286, 478, 364, 14564, 8304, 13, 51020], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1165, "seek": 298418, "start": 2997.2999999999997, "end": 2999.54, "text": " So I've used it to check to see what my students", "tokens": [51020, 407, 286, 600, 1143, 309, 281, 1520, 281, 536, 437, 452, 1731, 51132], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1166, "seek": 298418, "start": 2999.54, "end": 3001.66, "text": " might try to use it to answer my exam questions", "tokens": [51132, 1062, 853, 281, 764, 309, 281, 1867, 452, 1139, 1651, 51238], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1167, "seek": 298418, "start": 3001.66, "end": 3003.96, "text": " or essay questions or things like that.", "tokens": [51238, 420, 16238, 1651, 420, 721, 411, 300, 13, 51353], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1168, "seek": 298418, "start": 3003.96, "end": 3006.14, "text": " I've asked it things that I wanted to know", "tokens": [51353, 286, 600, 2351, 309, 721, 300, 286, 1415, 281, 458, 51462], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1169, "seek": 298418, "start": 3006.14, "end": 3008.2599999999998, "text": " and try to check on them.", "tokens": [51462, 293, 853, 281, 1520, 322, 552, 13, 51568], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1170, "seek": 298418, "start": 3008.2599999999998, "end": 3011.8999999999996, "text": " I haven't used it for legal or medical questions.", "tokens": [51568, 286, 2378, 380, 1143, 309, 337, 5089, 420, 4625, 1651, 13, 51750], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1171, "seek": 298418, "start": 3011.8999999999996, "end": 3013.94, "text": " Those are areas which are heavily regulated.", "tokens": [51750, 3950, 366, 3179, 597, 366, 10950, 26243, 13, 51852], "temperature": 0.0, "avg_logprob": -0.11047734605505112, "compression_ratio": 1.7152317880794703, "no_speech_prob": 0.0005702381022274494}, {"id": 1172, "seek": 301394, "start": 3013.94, "end": 3016.02, "text": " It's always been possible for other people", "tokens": [50364, 467, 311, 1009, 668, 1944, 337, 661, 561, 50468], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1173, "seek": 301394, "start": 3016.02, "end": 3017.9, "text": " to offer substitutes.", "tokens": [50468, 281, 2626, 26441, 1819, 13, 50562], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1174, "seek": 301394, "start": 3017.9, "end": 3020.06, "text": " So for example, many decades ago,", "tokens": [50562, 407, 337, 1365, 11, 867, 7878, 2057, 11, 50670], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1175, "seek": 301394, "start": 3020.06, "end": 3022.2200000000003, "text": " there were experiments where we,", "tokens": [50670, 456, 645, 12050, 689, 321, 11, 50778], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1176, "seek": 301394, "start": 3022.2200000000003, "end": 3025.2200000000003, "text": " basically for the purpose of general practice for doctors,", "tokens": [50778, 1936, 337, 264, 4334, 295, 2674, 3124, 337, 8778, 11, 50928], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1177, "seek": 301394, "start": 3025.2200000000003, "end": 3027.44, "text": " we compare doctors to nurses,", "tokens": [50928, 321, 6794, 8778, 281, 17446, 11, 51039], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1178, "seek": 301394, "start": 3027.44, "end": 3028.98, "text": " nurse practitioners or paramedics.", "tokens": [51039, 14012, 25742, 420, 971, 3475, 1167, 13, 51116], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1179, "seek": 301394, "start": 3028.98, "end": 3031.14, "text": " We found that those other groups did just as well", "tokens": [51116, 492, 1352, 300, 729, 661, 3935, 630, 445, 382, 731, 51224], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1180, "seek": 301394, "start": 3031.14, "end": 3033.7400000000002, "text": " and much cheaper at doing the first level", "tokens": [51224, 293, 709, 12284, 412, 884, 264, 700, 1496, 51354], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1181, "seek": 301394, "start": 3033.7400000000002, "end": 3036.98, "text": " of general practice, but they haven't been allowed.", "tokens": [51354, 295, 2674, 3124, 11, 457, 436, 2378, 380, 668, 4350, 13, 51516], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1182, "seek": 301394, "start": 3036.98, "end": 3039.2000000000003, "text": " So that right there is enormous value", "tokens": [51516, 407, 300, 558, 456, 307, 11322, 2158, 51627], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1183, "seek": 301394, "start": 3039.2000000000003, "end": 3040.14, "text": " that could have been released.", "tokens": [51627, 300, 727, 362, 668, 4736, 13, 51674], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1184, "seek": 301394, "start": 3040.14, "end": 3042.7000000000003, "text": " We could have all this time been having nurse practitioners", "tokens": [51674, 492, 727, 362, 439, 341, 565, 668, 1419, 14012, 25742, 51802], "temperature": 0.0, "avg_logprob": -0.12449280665471003, "compression_ratio": 1.8144329896907216, "no_speech_prob": 0.00025306938914582133}, {"id": 1185, "seek": 304270, "start": 3042.7, "end": 3045.9399999999996, "text": " and doctors and paramedics do our first level", "tokens": [50364, 293, 8778, 293, 971, 3475, 1167, 360, 527, 700, 1496, 50526], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1186, "seek": 304270, "start": 3045.9399999999996, "end": 3047.3799999999997, "text": " of general practice medicine.", "tokens": [50526, 295, 2674, 3124, 7195, 13, 50598], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1187, "seek": 304270, "start": 3047.3799999999997, "end": 3049.7, "text": " And they would save at least a factor of two or three", "tokens": [50598, 400, 436, 576, 3155, 412, 1935, 257, 5952, 295, 732, 420, 1045, 50714], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1188, "seek": 304270, "start": 3049.7, "end": 3051.9399999999996, "text": " in cost and that's been true for decades.", "tokens": [50714, 294, 2063, 293, 300, 311, 668, 2074, 337, 7878, 13, 50826], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1189, "seek": 304270, "start": 3051.9399999999996, "end": 3054.4199999999996, "text": " We've had randomized experiments showing that for decades.", "tokens": [50826, 492, 600, 632, 38513, 12050, 4099, 300, 337, 7878, 13, 50950], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1190, "seek": 304270, "start": 3054.4199999999996, "end": 3057.1, "text": " So going back to the age of M then for a second,", "tokens": [50950, 407, 516, 646, 281, 264, 3205, 295, 376, 550, 337, 257, 1150, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1191, "seek": 304270, "start": 3057.1, "end": 3061.18, "text": " are you just assuming that that scenario doesn't happen", "tokens": [51084, 366, 291, 445, 11926, 300, 300, 9005, 1177, 380, 1051, 51288], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1192, "seek": 304270, "start": 3061.18, "end": 3064.02, "text": " in M land for some reason?", "tokens": [51288, 294, 376, 2117, 337, 512, 1778, 30, 51430], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1193, "seek": 304270, "start": 3064.02, "end": 3067.58, "text": " Or like, why wouldn't it be the first objection", "tokens": [51430, 1610, 411, 11, 983, 2759, 380, 309, 312, 264, 700, 35756, 51608], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1194, "seek": 304270, "start": 3067.58, "end": 3070.3799999999997, "text": " to the age of M seems like it maybe should be,", "tokens": [51608, 281, 264, 3205, 295, 376, 2544, 411, 309, 1310, 820, 312, 11, 51748], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1195, "seek": 304270, "start": 3070.3799999999997, "end": 3071.4199999999996, "text": " M's will be made illegal.", "tokens": [51748, 376, 311, 486, 312, 1027, 11905, 13, 51800], "temperature": 0.0, "avg_logprob": -0.1538403780405758, "compression_ratio": 1.6770833333333333, "no_speech_prob": 0.00011958737741224468}, {"id": 1196, "seek": 307142, "start": 3071.42, "end": 3073.02, "text": " Nobody will be allowed to do it.", "tokens": [50364, 9297, 486, 312, 4350, 281, 360, 309, 13, 50444], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1197, "seek": 307142, "start": 3073.02, "end": 3074.2200000000003, "text": " Absolutely.", "tokens": [50444, 7021, 13, 50504], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1198, "seek": 307142, "start": 3074.2200000000003, "end": 3077.14, "text": " And basically you're just kind of in the analysis saying,", "tokens": [50504, 400, 1936, 291, 434, 445, 733, 295, 294, 264, 5215, 1566, 11, 50650], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1199, "seek": 307142, "start": 3077.14, "end": 3078.5, "text": " well, let's just assume that doesn't happen", "tokens": [50650, 731, 11, 718, 311, 445, 6552, 300, 1177, 380, 1051, 50718], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1200, "seek": 307142, "start": 3078.5, "end": 3080.58, "text": " because it'll be, you know, it's a short book", "tokens": [50718, 570, 309, 603, 312, 11, 291, 458, 11, 309, 311, 257, 2099, 1446, 50822], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1201, "seek": 307142, "start": 3080.58, "end": 3082.28, "text": " if they just get made illegal too early.", "tokens": [50822, 498, 436, 445, 483, 1027, 11905, 886, 2440, 13, 50907], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1202, "seek": 307142, "start": 3082.28, "end": 3083.7000000000003, "text": " Is that the idea?", "tokens": [50907, 1119, 300, 264, 1558, 30, 50978], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1203, "seek": 307142, "start": 3083.7000000000003, "end": 3085.7400000000002, "text": " Well, so first of all,", "tokens": [50978, 1042, 11, 370, 700, 295, 439, 11, 51080], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1204, "seek": 307142, "start": 3085.7400000000002, "end": 3088.56, "text": " I say transitions are harder to analyze", "tokens": [51080, 286, 584, 23767, 366, 6081, 281, 12477, 51221], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1205, "seek": 307142, "start": 3088.56, "end": 3090.7000000000003, "text": " than equilibria of New World.", "tokens": [51221, 813, 14204, 4668, 295, 1873, 3937, 13, 51328], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1206, "seek": 307142, "start": 3090.7000000000003, "end": 3094.14, "text": " So I try to avoid analyzing the transition.", "tokens": [51328, 407, 286, 853, 281, 5042, 23663, 264, 6034, 13, 51500], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1207, "seek": 307142, "start": 3094.14, "end": 3096.46, "text": " Although I do try to discuss it some toward the end", "tokens": [51500, 5780, 286, 360, 853, 281, 2248, 309, 512, 7361, 264, 917, 51616], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1208, "seek": 307142, "start": 3096.46, "end": 3098.5, "text": " of the book, but I admit,", "tokens": [51616, 295, 264, 1446, 11, 457, 286, 9796, 11, 51718], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1209, "seek": 307142, "start": 3098.5, "end": 3100.86, "text": " I can just say less about a transition.", "tokens": [51718, 286, 393, 445, 584, 1570, 466, 257, 6034, 13, 51836], "temperature": 0.0, "avg_logprob": -0.16491668078364158, "compression_ratio": 1.66996699669967, "no_speech_prob": 0.0007552597089670599}, {"id": 1210, "seek": 310086, "start": 3100.86, "end": 3103.46, "text": " It does seem like that, you know,", "tokens": [50364, 467, 775, 1643, 411, 300, 11, 291, 458, 11, 50494], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1211, "seek": 310086, "start": 3103.46, "end": 3105.94, "text": " compared to a scenario where everyone eagerly adopted", "tokens": [50494, 5347, 281, 257, 9005, 689, 1518, 18259, 356, 12175, 50618], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1212, "seek": 310086, "start": 3105.94, "end": 3108.06, "text": " M technology as soon as it was available,", "tokens": [50618, 376, 2899, 382, 2321, 382, 309, 390, 2435, 11, 50724], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1213, "seek": 310086, "start": 3108.06, "end": 3110.54, "text": " more likely there will be resistance.", "tokens": [50724, 544, 3700, 456, 486, 312, 7335, 13, 50848], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1214, "seek": 310086, "start": 3110.54, "end": 3113.1800000000003, "text": " There will be ways in which there are obstacles", "tokens": [50848, 821, 486, 312, 2098, 294, 597, 456, 366, 17735, 50980], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1215, "seek": 310086, "start": 3113.1800000000003, "end": 3115.86, "text": " to M technology early on.", "tokens": [50980, 281, 376, 2899, 2440, 322, 13, 51114], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1216, "seek": 310086, "start": 3115.86, "end": 3117.3, "text": " And therefore at some point,", "tokens": [51114, 400, 4412, 412, 512, 935, 11, 51186], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1217, "seek": 310086, "start": 3117.3, "end": 3118.98, "text": " there would basically be the, you know,", "tokens": [51186, 456, 576, 1936, 312, 264, 11, 291, 458, 11, 51270], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1218, "seek": 310086, "start": 3118.98, "end": 3121.9, "text": " breaking of a dam flooding out where a bunch of things", "tokens": [51270, 7697, 295, 257, 2422, 24132, 484, 689, 257, 3840, 295, 721, 51416], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1219, "seek": 310086, "start": 3121.9, "end": 3124.56, "text": " that had been held back were released", "tokens": [51416, 300, 632, 668, 5167, 646, 645, 4736, 51549], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1220, "seek": 310086, "start": 3124.56, "end": 3127.1, "text": " and then caused a lot of disruption,", "tokens": [51549, 293, 550, 7008, 257, 688, 295, 28751, 11, 51676], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1221, "seek": 310086, "start": 3127.1, "end": 3128.6200000000003, "text": " faster disruption that would have happened", "tokens": [51676, 4663, 28751, 300, 576, 362, 2011, 51752], "temperature": 0.0, "avg_logprob": -0.13138528730048507, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.00010888255201280117}, {"id": 1222, "seek": 312862, "start": 3128.62, "end": 3132.2999999999997, "text": " had you adopted things as soon as they were available.", "tokens": [50364, 632, 291, 12175, 721, 382, 2321, 382, 436, 645, 2435, 13, 50548], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1223, "seek": 312862, "start": 3132.2999999999997, "end": 3133.14, "text": " And that's part of,", "tokens": [50548, 400, 300, 311, 644, 295, 11, 50590], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1224, "seek": 312862, "start": 3133.14, "end": 3136.2999999999997, "text": " that can be very disturbing transition then, you know,", "tokens": [50590, 300, 393, 312, 588, 21903, 6034, 550, 11, 291, 458, 11, 50748], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1225, "seek": 312862, "start": 3136.2999999999997, "end": 3138.62, "text": " if all of a sudden large numbers of people", "tokens": [50748, 498, 439, 295, 257, 3990, 2416, 3547, 295, 561, 50864], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1226, "seek": 312862, "start": 3138.62, "end": 3141.42, "text": " are disrupted in ways they weren't expecting", "tokens": [50864, 366, 42271, 294, 2098, 436, 4999, 380, 9650, 51004], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1227, "seek": 312862, "start": 3141.42, "end": 3144.5, "text": " in a very rapid way because of, you know,", "tokens": [51004, 294, 257, 588, 7558, 636, 570, 295, 11, 291, 458, 11, 51158], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1228, "seek": 312862, "start": 3144.5, "end": 3146.62, "text": " a dam suddenly broke open,", "tokens": [51158, 257, 2422, 5800, 6902, 1269, 11, 51264], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1229, "seek": 312862, "start": 3146.62, "end": 3150.44, "text": " then I think there will be a lot of unhappy people", "tokens": [51264, 550, 286, 519, 456, 486, 312, 257, 688, 295, 22172, 561, 51455], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1230, "seek": 312862, "start": 3150.44, "end": 3151.56, "text": " in that sort of a transition", "tokens": [51455, 294, 300, 1333, 295, 257, 6034, 51511], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1231, "seek": 312862, "start": 3151.56, "end": 3153.02, "text": " and maybe a lot of dead people.", "tokens": [51511, 293, 1310, 257, 688, 295, 3116, 561, 13, 51584], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1232, "seek": 312862, "start": 3153.02, "end": 3155.62, "text": " So imagine the M technology slowly just gets cheaper", "tokens": [51584, 407, 3811, 264, 376, 2899, 5692, 445, 2170, 12284, 51714], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1233, "seek": 312862, "start": 3155.62, "end": 3158.6, "text": " over time, but it's not very wide.", "tokens": [51714, 670, 565, 11, 457, 309, 311, 406, 588, 4874, 13, 51863], "temperature": 0.0, "avg_logprob": -0.13065859765717477, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.001032091910019517}, {"id": 1234, "seek": 315860, "start": 3158.6, "end": 3160.44, "text": " It's not very widely adopted.", "tokens": [50364, 467, 311, 406, 588, 13371, 12175, 13, 50456], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1235, "seek": 315860, "start": 3160.44, "end": 3164.08, "text": " Then there'll be a point at which it eventually gets so cheap", "tokens": [50456, 1396, 456, 603, 312, 257, 935, 412, 597, 309, 4728, 2170, 370, 7084, 50638], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1236, "seek": 315860, "start": 3164.08, "end": 3166.3199999999997, "text": " that if some say ambitious nation,", "tokens": [50638, 300, 498, 512, 584, 20239, 4790, 11, 50750], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1237, "seek": 315860, "start": 3166.3199999999997, "end": 3168.04, "text": " like say North Korea said,", "tokens": [50750, 411, 584, 4067, 6307, 848, 11, 50836], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1238, "seek": 315860, "start": 3168.04, "end": 3171.12, "text": " gee, if we went whole hog and adopting this thing,", "tokens": [50836, 24105, 11, 498, 321, 1437, 1379, 24855, 293, 32328, 341, 551, 11, 50990], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1239, "seek": 315860, "start": 3171.12, "end": 3172.96, "text": " we could get this big, you know,", "tokens": [50990, 321, 727, 483, 341, 955, 11, 291, 458, 11, 51082], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1240, "seek": 315860, "start": 3172.96, "end": 3175.92, "text": " economic and military advantage over our competitors,", "tokens": [51082, 4836, 293, 4632, 5002, 670, 527, 18333, 11, 51230], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1241, "seek": 315860, "start": 3175.92, "end": 3178.92, "text": " then eventually somebody would do that.", "tokens": [51230, 550, 4728, 2618, 576, 360, 300, 13, 51380], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1242, "seek": 315860, "start": 3178.92, "end": 3180.88, "text": " Now it might take a long time.", "tokens": [51380, 823, 309, 1062, 747, 257, 938, 565, 13, 51478], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1243, "seek": 315860, "start": 3181.7999999999997, "end": 3184.68, "text": " That is the world could coordinate to resistance technology", "tokens": [51524, 663, 307, 264, 1002, 727, 15670, 281, 7335, 2899, 51668], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1244, "seek": 315860, "start": 3184.68, "end": 3187.16, "text": " for a long time,", "tokens": [51668, 337, 257, 938, 565, 11, 51792], "temperature": 0.0, "avg_logprob": -0.2800313203231148, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.0012837968533858657}, {"id": 1245, "seek": 318716, "start": 3187.16, "end": 3190.8799999999997, "text": " but I don't think they could hold it back for a thousand years.", "tokens": [50364, 457, 286, 500, 380, 519, 436, 727, 1797, 309, 646, 337, 257, 4714, 924, 13, 50550], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1246, "seek": 318716, "start": 3190.8799999999997, "end": 3192.12, "text": " So then I feel somewhat confident,", "tokens": [50550, 407, 550, 286, 841, 8344, 6679, 11, 50612], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1247, "seek": 318716, "start": 3192.12, "end": 3193.96, "text": " eventually in the age of M happens,", "tokens": [50612, 4728, 294, 264, 3205, 295, 376, 2314, 11, 50704], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1248, "seek": 318716, "start": 3194.92, "end": 3197.3599999999997, "text": " and then eventually there's a thing to think about", "tokens": [50752, 293, 550, 4728, 456, 311, 257, 551, 281, 519, 466, 50874], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1249, "seek": 318716, "start": 3197.3599999999997, "end": 3198.68, "text": " and then I'm analyzing that world.", "tokens": [50874, 293, 550, 286, 478, 23663, 300, 1002, 13, 50940], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1250, "seek": 318716, "start": 3198.68, "end": 3201.52, "text": " So I don't want to presume in the age of M", "tokens": [50940, 407, 286, 500, 380, 528, 281, 43283, 294, 264, 3205, 295, 376, 51082], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1251, "seek": 318716, "start": 3201.52, "end": 3204.04, "text": " that this transition happens smoothly or soon", "tokens": [51082, 300, 341, 6034, 2314, 19565, 420, 2321, 51208], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1252, "seek": 318716, "start": 3204.04, "end": 3206.44, "text": " or as fast as it could,", "tokens": [51208, 420, 382, 2370, 382, 309, 727, 11, 51328], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1253, "seek": 318716, "start": 3206.44, "end": 3208.3599999999997, "text": " but I want to say eventually there'll be this new world", "tokens": [51328, 457, 286, 528, 281, 584, 4728, 456, 603, 312, 341, 777, 1002, 51424], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1254, "seek": 318716, "start": 3208.3599999999997, "end": 3209.68, "text": " and here's how it would play out.", "tokens": [51424, 293, 510, 311, 577, 309, 576, 862, 484, 13, 51490], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1255, "seek": 318716, "start": 3209.68, "end": 3212.2, "text": " So I don't know if you know that in the last few months", "tokens": [51490, 407, 286, 500, 380, 458, 498, 291, 458, 300, 294, 264, 1036, 1326, 2493, 51616], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1256, "seek": 318716, "start": 3213.3599999999997, "end": 3216.16, "text": " I've dramatically changed my vision of the future", "tokens": [51674, 286, 600, 17548, 3105, 452, 5201, 295, 264, 2027, 51814], "temperature": 0.0, "avg_logprob": -0.140964322619968, "compression_ratio": 1.8496503496503496, "no_speech_prob": 0.0007319969008676708}, {"id": 1257, "seek": 321616, "start": 3216.16, "end": 3218.04, "text": " to say that there's probably gonna be", "tokens": [50364, 281, 584, 300, 456, 311, 1391, 799, 312, 50458], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1258, "seek": 321616, "start": 3218.04, "end": 3220.56, "text": " a several century innovation pause,", "tokens": [50458, 257, 2940, 4901, 8504, 10465, 11, 50584], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1259, "seek": 321616, "start": 3220.56, "end": 3223.0, "text": " probably before the age of M happens,", "tokens": [50584, 1391, 949, 264, 3205, 295, 376, 2314, 11, 50706], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1260, "seek": 321616, "start": 3223.0, "end": 3225.8399999999997, "text": " and then the world that would eventually produce AI", "tokens": [50706, 293, 550, 264, 1002, 300, 576, 4728, 5258, 7318, 50848], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1261, "seek": 321616, "start": 3225.8399999999997, "end": 3228.04, "text": " and M's would be a very different world from ours", "tokens": [50848, 293, 376, 311, 576, 312, 257, 588, 819, 1002, 490, 11896, 50958], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1262, "seek": 321616, "start": 3228.04, "end": 3231.3999999999996, "text": " and somewhat hard to think about.", "tokens": [50958, 293, 8344, 1152, 281, 519, 466, 13, 51126], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1263, "seek": 321616, "start": 3231.3999999999996, "end": 3235.72, "text": " That is rising population will stop rising", "tokens": [51126, 663, 307, 11636, 4415, 486, 1590, 11636, 51342], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1264, "seek": 321616, "start": 3235.72, "end": 3238.08, "text": " and it will fall due to falling fertility,", "tokens": [51342, 293, 309, 486, 2100, 3462, 281, 7440, 31707, 11, 51460], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1265, "seek": 321616, "start": 3238.08, "end": 3240.6, "text": " that will basically make innovation grind to a halt,", "tokens": [51460, 300, 486, 1936, 652, 8504, 16700, 281, 257, 12479, 11, 51586], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1266, "seek": 321616, "start": 3240.6, "end": 3243.2, "text": " then the world population will continue to fall", "tokens": [51586, 550, 264, 1002, 4415, 486, 2354, 281, 2100, 51716], "temperature": 0.0, "avg_logprob": -0.13604875292096819, "compression_ratio": 1.778688524590164, "no_speech_prob": 0.0002453153138048947}, {"id": 1267, "seek": 324320, "start": 3243.2, "end": 3248.2799999999997, "text": " until insular fertile subcultures like the Amish", "tokens": [50364, 1826, 1028, 1040, 43509, 1422, 66, 723, 1303, 411, 264, 2012, 742, 50618], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1268, "seek": 324320, "start": 3248.2799999999997, "end": 3250.12, "text": " grow from their very small current levels", "tokens": [50618, 1852, 490, 641, 588, 1359, 2190, 4358, 50710], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1269, "seek": 324320, "start": 3250.12, "end": 3252.96, "text": " to become the dominant population of the world.", "tokens": [50710, 281, 1813, 264, 15657, 4415, 295, 264, 1002, 13, 50852], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1270, "seek": 324320, "start": 3252.96, "end": 3254.8799999999997, "text": " And then when that becomes large enough", "tokens": [50852, 400, 550, 562, 300, 3643, 2416, 1547, 50948], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1271, "seek": 324320, "start": 3254.8799999999997, "end": 3256.52, "text": " compared to our current economy,", "tokens": [50948, 5347, 281, 527, 2190, 5010, 11, 51030], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1272, "seek": 324320, "start": 3256.52, "end": 3258.16, "text": " then innovation would turn on again", "tokens": [51030, 550, 8504, 576, 1261, 322, 797, 51112], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1273, "seek": 324320, "start": 3258.16, "end": 3261.56, "text": " and then we would restart the AI and M path", "tokens": [51112, 293, 550, 321, 576, 21022, 264, 7318, 293, 376, 3100, 51282], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1274, "seek": 324320, "start": 3261.56, "end": 3264.8399999999997, "text": " and then eventually the age of M would happen.", "tokens": [51282, 293, 550, 4728, 264, 3205, 295, 376, 576, 1051, 13, 51446], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1275, "seek": 324320, "start": 3264.8399999999997, "end": 3267.0, "text": " Trying to anticipate how transitions would happen", "tokens": [51446, 20180, 281, 21685, 577, 23767, 576, 1051, 51554], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1276, "seek": 324320, "start": 3267.0, "end": 3269.7599999999998, "text": " in a world we can just hardly even imagine,", "tokens": [51554, 294, 257, 1002, 321, 393, 445, 13572, 754, 3811, 11, 51692], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1277, "seek": 324320, "start": 3269.7599999999998, "end": 3270.96, "text": " seems tough, right?", "tokens": [51692, 2544, 4930, 11, 558, 30, 51752], "temperature": 0.0, "avg_logprob": -0.11532742998241323, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.0004440997145138681}, {"id": 1278, "seek": 327096, "start": 3271.0, "end": 3273.96, "text": " That is, okay, imagine the descendants of the Amish", "tokens": [50366, 663, 307, 11, 1392, 11, 3811, 264, 31693, 295, 264, 2012, 742, 50514], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1279, "seek": 327096, "start": 3273.96, "end": 3277.6, "text": " become a large, powerful civilization.", "tokens": [50514, 1813, 257, 2416, 11, 4005, 18036, 13, 50696], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1280, "seek": 327096, "start": 3277.6, "end": 3280.6, "text": " They've always been somewhat resistant to technology", "tokens": [50696, 814, 600, 1009, 668, 8344, 20383, 281, 2899, 50846], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1281, "seek": 327096, "start": 3280.6, "end": 3283.7200000000003, "text": " and very picky about which technologies they're allowed,", "tokens": [50846, 293, 588, 41099, 466, 597, 7943, 436, 434, 4350, 11, 51002], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1282, "seek": 327096, "start": 3283.7200000000003, "end": 3285.64, "text": " but eventually I would predict", "tokens": [51002, 457, 4728, 286, 576, 6069, 51098], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1283, "seek": 327096, "start": 3286.84, "end": 3288.32, "text": " there would be competition within them", "tokens": [51158, 456, 576, 312, 6211, 1951, 552, 51232], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1284, "seek": 327096, "start": 3288.32, "end": 3293.32, "text": " and that would push them to adopt technologies like AI and M's", "tokens": [51232, 293, 300, 576, 2944, 552, 281, 6878, 7943, 411, 7318, 293, 376, 311, 51482], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1285, "seek": 327096, "start": 3293.32, "end": 3296.28, "text": " but we're looking a long way down the line.", "tokens": [51482, 457, 321, 434, 1237, 257, 938, 636, 760, 264, 1622, 13, 51630], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1286, "seek": 327096, "start": 3296.28, "end": 3298.2400000000002, "text": " And this isn't what I wish would happen", "tokens": [51630, 400, 341, 1943, 380, 437, 286, 3172, 576, 1051, 51728], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1287, "seek": 327096, "start": 3298.2400000000002, "end": 3299.28, "text": " to go back to your initial thing.", "tokens": [51728, 281, 352, 646, 281, 428, 5883, 551, 13, 51780], "temperature": 0.0, "avg_logprob": -0.1261497703758446, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0004044047382194549}, {"id": 1288, "seek": 329928, "start": 3299.28, "end": 3301.7200000000003, "text": " I would rather we continued growing", "tokens": [50364, 286, 576, 2831, 321, 7014, 4194, 50486], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1289, "seek": 329928, "start": 3301.7200000000003, "end": 3303.2400000000002, "text": " at the rate of the past century", "tokens": [50486, 412, 264, 3314, 295, 264, 1791, 4901, 50562], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1290, "seek": 329928, "start": 3303.2400000000002, "end": 3305.76, "text": " and continue that for a few more centuries,", "tokens": [50562, 293, 2354, 300, 337, 257, 1326, 544, 13926, 11, 50688], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1291, "seek": 329928, "start": 3305.76, "end": 3308.0, "text": " by which time I'm pretty sure", "tokens": [50688, 538, 597, 565, 286, 478, 1238, 988, 50800], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1292, "seek": 329928, "start": 3308.0, "end": 3310.8, "text": " we'll eventually get M's and human level AI,", "tokens": [50800, 321, 603, 4728, 483, 376, 311, 293, 1952, 1496, 7318, 11, 50940], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1293, "seek": 329928, "start": 3310.8, "end": 3313.1600000000003, "text": " although question in what order,", "tokens": [50940, 4878, 1168, 294, 437, 1668, 11, 51058], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1294, "seek": 329928, "start": 3313.1600000000003, "end": 3315.48, "text": " but I got to say at the moment,", "tokens": [51058, 457, 286, 658, 281, 584, 412, 264, 1623, 11, 51174], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1295, "seek": 329928, "start": 3315.48, "end": 3317.4, "text": " that's not looking so good.", "tokens": [51174, 300, 311, 406, 1237, 370, 665, 13, 51270], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1296, "seek": 329928, "start": 3317.4, "end": 3321.36, "text": " So basically, I'm estimated that if we were to continue", "tokens": [51270, 407, 1936, 11, 286, 478, 14109, 300, 498, 321, 645, 281, 2354, 51468], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1297, "seek": 329928, "start": 3321.36, "end": 3325.4, "text": " on a steady growth path, we would eventually reach a point", "tokens": [51468, 322, 257, 13211, 4599, 3100, 11, 321, 576, 4728, 2524, 257, 935, 51670], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1298, "seek": 329928, "start": 3325.4, "end": 3326.96, "text": " where we had the same amount of innovation", "tokens": [51670, 689, 321, 632, 264, 912, 2372, 295, 8504, 51748], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1299, "seek": 329928, "start": 3326.96, "end": 3328.7200000000003, "text": " as we will get over the entire integral", "tokens": [51748, 382, 321, 486, 483, 670, 264, 2302, 11573, 51836], "temperature": 0.0, "avg_logprob": -0.1427188664674759, "compression_ratio": 1.6795774647887325, "no_speech_prob": 0.0009396988898515701}, {"id": 1300, "seek": 332872, "start": 3328.7599999999998, "end": 3330.2, "text": " of this several centuries pause.", "tokens": [50366, 295, 341, 2940, 13926, 10465, 13, 50438], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1301, "seek": 332872, "start": 3330.2, "end": 3333.04, "text": " And I've estimated that to be roughly 60 to 90 years", "tokens": [50438, 400, 286, 600, 14109, 300, 281, 312, 9810, 4060, 281, 4289, 924, 50580], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1302, "seek": 332872, "start": 3333.04, "end": 3333.8799999999997, "text": " worth of progress.", "tokens": [50580, 3163, 295, 4205, 13, 50622], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1303, "seek": 332872, "start": 3333.8799999999997, "end": 3336.9599999999996, "text": " So if we can get full human level AI", "tokens": [50622, 407, 498, 321, 393, 483, 1577, 1952, 1496, 7318, 50776], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1304, "seek": 332872, "start": 3336.9599999999996, "end": 3339.3199999999997, "text": " in the next 60 to 90 years with the progress,", "tokens": [50776, 294, 264, 958, 4060, 281, 4289, 924, 365, 264, 4205, 11, 50894], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1305, "seek": 332872, "start": 3339.3199999999997, "end": 3341.68, "text": " then this population decline won't matter so much", "tokens": [50894, 550, 341, 4415, 15635, 1582, 380, 1871, 370, 709, 51012], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1306, "seek": 332872, "start": 3341.68, "end": 3344.7999999999997, "text": " because we will basically have AI's takeover most of the jobs", "tokens": [51012, 570, 321, 486, 1936, 362, 7318, 311, 747, 3570, 881, 295, 264, 4782, 51168], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1307, "seek": 332872, "start": 3344.7999999999997, "end": 3348.64, "text": " and then that can allow the world economy to keep growing.", "tokens": [51168, 293, 550, 300, 393, 2089, 264, 1002, 5010, 281, 1066, 4194, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1308, "seek": 332872, "start": 3348.64, "end": 3351.8399999999997, "text": " I think that's iffy whether we can do that,", "tokens": [51360, 286, 519, 300, 311, 498, 22522, 1968, 321, 393, 360, 300, 11, 51520], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1309, "seek": 332872, "start": 3351.8399999999997, "end": 3356.16, "text": " whether we can achieve full human level AI in 60 to 90 years.", "tokens": [51520, 1968, 321, 393, 4584, 1577, 1952, 1496, 7318, 294, 4060, 281, 4289, 924, 13, 51736], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1310, "seek": 332872, "start": 3356.16, "end": 3357.9199999999996, "text": " And I know many people think it's gonna happen", "tokens": [51736, 400, 286, 458, 867, 561, 519, 309, 311, 799, 1051, 51824], "temperature": 0.0, "avg_logprob": -0.10740590796751134, "compression_ratio": 1.768166089965398, "no_speech_prob": 0.0009693476022221148}, {"id": 1311, "seek": 335792, "start": 3357.92, "end": 3359.52, "text": " in the next 10 years, they're sure.", "tokens": [50364, 294, 264, 958, 1266, 924, 11, 436, 434, 988, 13, 50444], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1312, "seek": 335792, "start": 3359.52, "end": 3361.84, "text": " So sure, of course it'll happen in 60 to 90 years,", "tokens": [50444, 407, 988, 11, 295, 1164, 309, 603, 1051, 294, 4060, 281, 4289, 924, 11, 50560], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1313, "seek": 335792, "start": 3361.84, "end": 3364.48, "text": " but I look at the history and I go,", "tokens": [50560, 457, 286, 574, 412, 264, 2503, 293, 286, 352, 11, 50692], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1314, "seek": 335792, "start": 3364.48, "end": 3366.7200000000003, "text": " look, I've seen over and over again,", "tokens": [50692, 574, 11, 286, 600, 1612, 670, 293, 670, 797, 11, 50804], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1315, "seek": 335792, "start": 3366.7200000000003, "end": 3370.6, "text": " people get really excited by the next new kind of AI.", "tokens": [50804, 561, 483, 534, 2919, 538, 264, 958, 777, 733, 295, 7318, 13, 50998], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1316, "seek": 335792, "start": 3370.6, "end": 3373.2000000000003, "text": " And they're typically pretty sure,", "tokens": [50998, 400, 436, 434, 5850, 1238, 988, 11, 51128], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1317, "seek": 335792, "start": 3373.2000000000003, "end": 3375.36, "text": " a lot of them are pretty sure that we must be near the end", "tokens": [51128, 257, 688, 295, 552, 366, 1238, 988, 300, 321, 1633, 312, 2651, 264, 917, 51236], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1318, "seek": 335792, "start": 3375.36, "end": 3378.04, "text": " and pretty soon we'll have it all.", "tokens": [51236, 293, 1238, 2321, 321, 603, 362, 309, 439, 13, 51370], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1319, "seek": 335792, "start": 3378.04, "end": 3380.84, "text": " And it just keeps not happening.", "tokens": [51370, 400, 309, 445, 5965, 406, 2737, 13, 51510], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1320, "seek": 335792, "start": 3380.84, "end": 3384.6800000000003, "text": " The main change I wanna suggest to that paradigm", "tokens": [51510, 440, 2135, 1319, 286, 1948, 3402, 281, 300, 24709, 51702], "temperature": 0.0, "avg_logprob": -0.10941886132763277, "compression_ratio": 1.6627450980392158, "no_speech_prob": 0.0003052909451071173}, {"id": 1321, "seek": 338468, "start": 3384.8399999999997, "end": 3389.8399999999997, "text": " is replacing the end with meaningful thresholds along the way.", "tokens": [50372, 307, 19139, 264, 917, 365, 10995, 14678, 82, 2051, 264, 636, 13, 50622], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1322, "seek": 338468, "start": 3390.96, "end": 3393.3599999999997, "text": " I think there are probably several", "tokens": [50678, 286, 519, 456, 366, 1391, 2940, 50798], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1323, "seek": 338468, "start": 3393.3599999999997, "end": 3398.0, "text": " that we will hit on some time scale.", "tokens": [50798, 300, 321, 486, 2045, 322, 512, 565, 4373, 13, 51030], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1324, "seek": 338468, "start": 3398.0, "end": 3400.64, "text": " And it feels to me like,", "tokens": [51030, 400, 309, 3417, 281, 385, 411, 11, 51162], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1325, "seek": 338468, "start": 3400.64, "end": 3404.52, "text": " at least a couple of the big ones are pretty close.", "tokens": [51162, 412, 1935, 257, 1916, 295, 264, 955, 2306, 366, 1238, 1998, 13, 51356], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1326, "seek": 338468, "start": 3404.52, "end": 3408.0, "text": " And then at the end is very,", "tokens": [51356, 400, 550, 412, 264, 917, 307, 588, 11, 51530], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1327, "seek": 338468, "start": 3408.0, "end": 3409.3999999999996, "text": " my crystal ball gets very foggy", "tokens": [51530, 452, 13662, 2594, 2170, 588, 13648, 1480, 51600], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1328, "seek": 338468, "start": 3409.3999999999996, "end": 3411.72, "text": " beyond like a pretty short time scale.", "tokens": [51600, 4399, 411, 257, 1238, 2099, 565, 4373, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1512629191080729, "compression_ratio": 1.6282722513089005, "no_speech_prob": 0.005382260773330927}, {"id": 1329, "seek": 341172, "start": 3411.72, "end": 3415.2799999999997, "text": " But I'm struggling with the early 80s expert systems,", "tokens": [50364, 583, 286, 478, 9314, 365, 264, 2440, 4688, 82, 5844, 3652, 11, 50542], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1330, "seek": 341172, "start": 3415.2799999999997, "end": 3417.8399999999997, "text": " but it really does seem like in my lifetime,", "tokens": [50542, 457, 309, 534, 775, 1643, 411, 294, 452, 11364, 11, 50670], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1331, "seek": 341172, "start": 3417.8399999999997, "end": 3422.08, "text": " I have not seen anything that remotely resembles", "tokens": [50670, 286, 362, 406, 1612, 1340, 300, 20824, 34433, 50882], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1332, "seek": 341172, "start": 3422.08, "end": 3424.08, "text": " the experience of going to a doctor.", "tokens": [50882, 264, 1752, 295, 516, 281, 257, 4631, 13, 50982], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1333, "seek": 341172, "start": 3424.08, "end": 3428.12, "text": " I've seen WebMD, I'm familiar with expert systems", "tokens": [50982, 286, 600, 1612, 9573, 44, 35, 11, 286, 478, 4963, 365, 5844, 3652, 51184], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1334, "seek": 341172, "start": 3428.12, "end": 3430.68, "text": " to a degree, but I've never seen anything that,", "tokens": [51184, 281, 257, 4314, 11, 457, 286, 600, 1128, 1612, 1340, 300, 11, 51312], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1335, "seek": 341172, "start": 3430.68, "end": 3433.7999999999997, "text": " I didn't think Ilya Setsgaver from OpenAI", "tokens": [51312, 286, 994, 380, 519, 286, 45106, 318, 1385, 3680, 331, 490, 7238, 48698, 51468], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1336, "seek": 341172, "start": 3433.7999999999997, "end": 3436.3199999999997, "text": " puts this really well, he's like the most shocking thing", "tokens": [51468, 8137, 341, 534, 731, 11, 415, 311, 411, 264, 881, 18776, 551, 51594], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1337, "seek": 341172, "start": 3436.3199999999997, "end": 3439.6, "text": " about the current AIs is that I can speak to them", "tokens": [51594, 466, 264, 2190, 316, 6802, 307, 300, 286, 393, 1710, 281, 552, 51758], "temperature": 0.0, "avg_logprob": -0.1557597001393636, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0001686353061813861}, {"id": 1338, "seek": 343960, "start": 3439.6, "end": 3441.68, "text": " and I feel that I'm understood.", "tokens": [50364, 293, 286, 841, 300, 286, 478, 7320, 13, 50468], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1339, "seek": 343960, "start": 3441.68, "end": 3445.08, "text": " And that is like a qualitatively different experience.", "tokens": [50468, 400, 300, 307, 411, 257, 31312, 356, 819, 1752, 13, 50638], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1340, "seek": 343960, "start": 3445.08, "end": 3449.52, "text": " And clearly I think reflects some qualitative advance", "tokens": [50638, 400, 4448, 286, 519, 18926, 512, 31312, 7295, 50860], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1341, "seek": 343960, "start": 3449.52, "end": 3453.92, "text": " in terms of what kind of information processing is going on.", "tokens": [50860, 294, 2115, 295, 437, 733, 295, 1589, 9007, 307, 516, 322, 13, 51080], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1342, "seek": 343960, "start": 3453.92, "end": 3456.8399999999997, "text": " If I had to say like, what is that under the hood?", "tokens": [51080, 759, 286, 632, 281, 584, 411, 11, 437, 307, 300, 833, 264, 13376, 30, 51226], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1343, "seek": 343960, "start": 3456.8399999999997, "end": 3461.8399999999997, "text": " I would say it's like a high dimensional representation", "tokens": [51226, 286, 576, 584, 309, 311, 411, 257, 1090, 18795, 10290, 51476], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1344, "seek": 343960, "start": 3462.44, "end": 3467.36, "text": " of concepts that are like really relevant to us", "tokens": [51506, 295, 10392, 300, 366, 411, 534, 7340, 281, 505, 51752], "temperature": 0.0, "avg_logprob": -0.11063347739734869, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.000910766189917922}, {"id": 1345, "seek": 346736, "start": 3467.4, "end": 3470.88, "text": " that have previously been kind of limited", "tokens": [50366, 300, 362, 8046, 668, 733, 295, 5567, 50540], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1346, "seek": 346736, "start": 3470.88, "end": 3473.8, "text": " to like language level compressed encoding.", "tokens": [50540, 281, 411, 2856, 1496, 30353, 43430, 13, 50686], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1347, "seek": 346736, "start": 3473.8, "end": 3475.88, "text": " But now we are actually starting to get to the point", "tokens": [50686, 583, 586, 321, 366, 767, 2891, 281, 483, 281, 264, 935, 50790], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1348, "seek": 346736, "start": 3475.88, "end": 3478.2400000000002, "text": " where we can like look at the middle layers", "tokens": [50790, 689, 321, 393, 411, 574, 412, 264, 2808, 7914, 50908], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1349, "seek": 346736, "start": 3478.2400000000002, "end": 3480.36, "text": " of even just the systems we have today,", "tokens": [50908, 295, 754, 445, 264, 3652, 321, 362, 965, 11, 51014], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1350, "seek": 346736, "start": 3480.36, "end": 3482.1200000000003, "text": " the transformers and say,", "tokens": [51014, 264, 4088, 433, 293, 584, 11, 51102], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1351, "seek": 346736, "start": 3482.1200000000003, "end": 3487.1200000000003, "text": " can we identify concepts like positivity", "tokens": [51102, 393, 321, 5876, 10392, 411, 35198, 51352], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1352, "seek": 346736, "start": 3487.96, "end": 3491.28, "text": " or paranoia or love?", "tokens": [51394, 420, 31416, 654, 420, 959, 30, 51560], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1353, "seek": 346736, "start": 3491.28, "end": 3493.6, "text": " And we are starting to be able to,", "tokens": [51560, 400, 321, 366, 2891, 281, 312, 1075, 281, 11, 51676], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1354, "seek": 346736, "start": 3493.6, "end": 3494.96, "text": " it's still pretty messy.", "tokens": [51676, 309, 311, 920, 1238, 16191, 13, 51744], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1355, "seek": 346736, "start": 3494.96, "end": 3496.4, "text": " We have the same, not the same,", "tokens": [51744, 492, 362, 264, 912, 11, 406, 264, 912, 11, 51816], "temperature": 0.0, "avg_logprob": -0.11192511637276466, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0004043827357236296}, {"id": 1356, "seek": 349640, "start": 3496.4, "end": 3499.48, "text": " we have an analogous problem to like understanding", "tokens": [50364, 321, 362, 364, 16660, 563, 1154, 281, 411, 3701, 50518], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1357, "seek": 349640, "start": 3499.48, "end": 3500.88, "text": " what's going on inside the brain", "tokens": [50518, 437, 311, 516, 322, 1854, 264, 3567, 50588], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1358, "seek": 349640, "start": 3500.88, "end": 3503.7200000000003, "text": " and it's just a mess in there still in the transformers.", "tokens": [50588, 293, 309, 311, 445, 257, 2082, 294, 456, 920, 294, 264, 4088, 433, 13, 50730], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1359, "seek": 349640, "start": 3503.7200000000003, "end": 3505.08, "text": " But we are starting to be able to see these", "tokens": [50730, 583, 321, 366, 2891, 281, 312, 1075, 281, 536, 613, 50798], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1360, "seek": 349640, "start": 3505.08, "end": 3509.12, "text": " like high dimensional representations where it's like,", "tokens": [50798, 411, 1090, 18795, 33358, 689, 309, 311, 411, 11, 51000], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1361, "seek": 349640, "start": 3509.12, "end": 3512.28, "text": " that is a numeric representation", "tokens": [51000, 300, 307, 257, 7866, 299, 10290, 51158], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1362, "seek": 349640, "start": 3512.28, "end": 3513.64, "text": " of some of these big concepts.", "tokens": [51158, 295, 512, 295, 613, 955, 10392, 13, 51226], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1363, "seek": 349640, "start": 3513.64, "end": 3515.08, "text": " And we're even starting to get to the point", "tokens": [51226, 400, 321, 434, 754, 2891, 281, 483, 281, 264, 935, 51298], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1364, "seek": 349640, "start": 3515.08, "end": 3517.96, "text": " where we can steer the language model behavior", "tokens": [51298, 689, 321, 393, 30814, 264, 2856, 2316, 5223, 51442], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1365, "seek": 349640, "start": 3517.96, "end": 3520.0, "text": " by like injecting these concepts.", "tokens": [51442, 538, 411, 10711, 278, 613, 10392, 13, 51544], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1366, "seek": 349640, "start": 3520.0, "end": 3525.0, "text": " So you can say, for example, inject safety", "tokens": [51544, 407, 291, 393, 584, 11, 337, 1365, 11, 10711, 4514, 51794], "temperature": 0.0, "avg_logprob": -0.12480861096342732, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0002694088325370103}, {"id": 1367, "seek": 352500, "start": 3525.0, "end": 3526.8, "text": " into the middle layers of a transformer", "tokens": [50364, 666, 264, 2808, 7914, 295, 257, 31782, 50454], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1368, "seek": 352500, "start": 3526.8, "end": 3531.8, "text": " and get a safer response or danger or rule breaking", "tokens": [50454, 293, 483, 257, 15856, 4134, 420, 4330, 420, 4978, 7697, 50704], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1369, "seek": 352500, "start": 3531.84, "end": 3534.2, "text": " and then they'll be more likely to break their rules.", "tokens": [50706, 293, 550, 436, 603, 312, 544, 3700, 281, 1821, 641, 4474, 13, 50824], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1370, "seek": 352500, "start": 3534.2, "end": 3536.36, "text": " What you're focused on at the moment is telling me", "tokens": [50824, 708, 291, 434, 5178, 322, 412, 264, 1623, 307, 3585, 385, 50932], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1371, "seek": 352500, "start": 3536.36, "end": 3539.8, "text": " about how the latest generation adds capabilities", "tokens": [50932, 466, 577, 264, 6792, 5125, 10860, 10862, 51104], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1372, "seek": 352500, "start": 3539.8, "end": 3542.12, "text": " that previous generations didn't have.", "tokens": [51104, 300, 3894, 10593, 994, 380, 362, 13, 51220], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1373, "seek": 352500, "start": 3542.12, "end": 3544.92, "text": " But every previous generation had that same conversation", "tokens": [51220, 583, 633, 3894, 5125, 632, 300, 912, 3761, 51360], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1374, "seek": 352500, "start": 3544.92, "end": 3547.16, "text": " where they focused on the new capabilities", "tokens": [51360, 689, 436, 5178, 322, 264, 777, 10862, 51472], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1375, "seek": 352500, "start": 3547.16, "end": 3550.6, "text": " their new generation had that the ones before it didn't have.", "tokens": [51472, 641, 777, 5125, 632, 300, 264, 2306, 949, 309, 994, 380, 362, 13, 51644], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1376, "seek": 352500, "start": 3550.6, "end": 3553.0, "text": " What the conversation you're participating in", "tokens": [51644, 708, 264, 3761, 291, 434, 13950, 294, 51764], "temperature": 0.0, "avg_logprob": -0.12988560478966515, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.0019259058171883225}, {"id": 1377, "seek": 355300, "start": 3553.0, "end": 3555.96, "text": " is continuing the past trend.", "tokens": [50364, 307, 9289, 264, 1791, 6028, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1378, "seek": 355300, "start": 3557.2, "end": 3559.44, "text": " But the fundamental question is,", "tokens": [50574, 583, 264, 8088, 1168, 307, 11, 50686], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1379, "seek": 355300, "start": 3559.44, "end": 3564.44, "text": " when will AIs be able to do what fraction of the tasks", "tokens": [50686, 562, 486, 316, 6802, 312, 1075, 281, 360, 437, 14135, 295, 264, 9608, 50936], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1380, "seek": 355300, "start": 3565.2, "end": 3567.62, "text": " that we have in the human economy,", "tokens": [50974, 300, 321, 362, 294, 264, 1952, 5010, 11, 51095], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1381, "seek": 355300, "start": 3567.62, "end": 3569.32, "text": " if they can't do a large fraction of them,", "tokens": [51095, 498, 436, 393, 380, 360, 257, 2416, 14135, 295, 552, 11, 51180], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1382, "seek": 355300, "start": 3569.32, "end": 3571.48, "text": " no matter how impressive they are at the practice", "tokens": [51180, 572, 1871, 577, 8992, 436, 366, 412, 264, 3124, 51288], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1383, "seek": 355300, "start": 3571.48, "end": 3574.72, "text": " they can do, we will see this economic decline", "tokens": [51288, 436, 393, 360, 11, 321, 486, 536, 341, 4836, 15635, 51450], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1384, "seek": 355300, "start": 3574.72, "end": 3576.24, "text": " as the population declines.", "tokens": [51450, 382, 264, 4415, 7488, 1652, 13, 51526], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1385, "seek": 355300, "start": 3576.24, "end": 3579.12, "text": " They need to be able to do pretty much all the tasks", "tokens": [51526, 814, 643, 281, 312, 1075, 281, 360, 1238, 709, 439, 264, 9608, 51670], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1386, "seek": 355300, "start": 3579.12, "end": 3581.44, "text": " in order to prevent the economic decline", "tokens": [51670, 294, 1668, 281, 4871, 264, 4836, 15635, 51786], "temperature": 0.0, "avg_logprob": -0.1319535862315785, "compression_ratio": 1.7844827586206897, "no_speech_prob": 0.001500859740190208}, {"id": 1387, "seek": 358144, "start": 3581.44, "end": 3583.2000000000003, "text": " and then the halting of innovation.", "tokens": [50364, 293, 550, 264, 7523, 783, 295, 8504, 13, 50452], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1388, "seek": 358144, "start": 3583.2000000000003, "end": 3585.76, "text": " I did this study of innovation in the United States", "tokens": [50452, 286, 630, 341, 2979, 295, 8504, 294, 264, 2824, 3040, 50580], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1389, "seek": 358144, "start": 3585.76, "end": 3590.2000000000003, "text": " over 20 years from 1999 to 2019.", "tokens": [50580, 670, 945, 924, 490, 19952, 281, 6071, 13, 50802], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1390, "seek": 358144, "start": 3590.2000000000003, "end": 3591.88, "text": " And that was a period that encompassed", "tokens": [50802, 400, 300, 390, 257, 2896, 300, 28268, 292, 50886], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1391, "seek": 358144, "start": 3591.88, "end": 3595.64, "text": " what many people at time said was enormous AI progress.", "tokens": [50886, 437, 867, 561, 412, 565, 848, 390, 11322, 7318, 4205, 13, 51074], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1392, "seek": 358144, "start": 3595.64, "end": 3598.56, "text": " And many people in the period were talking about", "tokens": [51074, 400, 867, 561, 294, 264, 2896, 645, 1417, 466, 51220], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1393, "seek": 358144, "start": 3598.56, "end": 3602.2000000000003, "text": " how there was this revolution in AI", "tokens": [51220, 577, 456, 390, 341, 8894, 294, 7318, 51402], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1394, "seek": 358144, "start": 3602.2000000000003, "end": 3605.64, "text": " that was about to cause a revolution in society", "tokens": [51402, 300, 390, 466, 281, 3082, 257, 8894, 294, 4086, 51574], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1395, "seek": 358144, "start": 3607.2400000000002, "end": 3610.04, "text": " in this period from 1999 to 2019.", "tokens": [51654, 294, 341, 2896, 490, 19952, 281, 6071, 13, 51794], "temperature": 0.0, "avg_logprob": -0.11114976844009088, "compression_ratio": 1.8018867924528301, "no_speech_prob": 0.0010645369766280055}, {"id": 1396, "seek": 361004, "start": 3610.04, "end": 3614.2799999999997, "text": " So we did a study, a co-author and I,", "tokens": [50364, 407, 321, 630, 257, 2979, 11, 257, 598, 12, 34224, 293, 286, 11, 50576], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1397, "seek": 361004, "start": 3614.2799999999997, "end": 3618.12, "text": " Keller Scholl, who looked at all jobs in the US,", "tokens": [50576, 48352, 2065, 1833, 11, 567, 2956, 412, 439, 4782, 294, 264, 2546, 11, 50768], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1398, "seek": 361004, "start": 3618.12, "end": 3622.04, "text": " basically roughly 900 different kinds of jobs.", "tokens": [50768, 1936, 9810, 22016, 819, 3685, 295, 4782, 13, 50964], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1399, "seek": 361004, "start": 3622.04, "end": 3623.7599999999998, "text": " And over that 20-year period,", "tokens": [50964, 400, 670, 300, 945, 12, 5294, 2896, 11, 51050], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1400, "seek": 361004, "start": 3623.7599999999998, "end": 3628.2, "text": " we had measures of how automated was each job in each year.", "tokens": [51050, 321, 632, 8000, 295, 577, 18473, 390, 1184, 1691, 294, 1184, 1064, 13, 51272], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1401, "seek": 361004, "start": 3629.96, "end": 3634.4, "text": " And then we could do statistics to say,", "tokens": [51360, 400, 550, 321, 727, 360, 12523, 281, 584, 11, 51582], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1402, "seek": 361004, "start": 3634.4, "end": 3635.92, "text": " when jobs got more automated,", "tokens": [51582, 562, 4782, 658, 544, 18473, 11, 51658], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1403, "seek": 361004, "start": 3635.92, "end": 3638.16, "text": " did they get the wages go up or down?", "tokens": [51658, 630, 436, 483, 264, 20097, 352, 493, 420, 760, 30, 51770], "temperature": 0.0, "avg_logprob": -0.16250185090668348, "compression_ratio": 1.4776785714285714, "no_speech_prob": 8.478544623358175e-05}, {"id": 1404, "seek": 363816, "start": 3638.16, "end": 3640.92, "text": " Did the number of workers in those jobs go up or down?", "tokens": [50364, 2589, 264, 1230, 295, 5600, 294, 729, 4782, 352, 493, 420, 760, 30, 50502], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1405, "seek": 363816, "start": 3640.92, "end": 3643.2, "text": " And we could say, what about jobs predicts", "tokens": [50502, 400, 321, 727, 584, 11, 437, 466, 4782, 6069, 82, 50616], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1406, "seek": 363816, "start": 3643.2, "end": 3644.48, "text": " how automated they are?", "tokens": [50616, 577, 18473, 436, 366, 30, 50680], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1407, "seek": 363816, "start": 3645.3999999999996, "end": 3648.3199999999997, "text": " And did the things that determine which jobs", "tokens": [50726, 400, 630, 264, 721, 300, 6997, 597, 4782, 50872], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1408, "seek": 363816, "start": 3648.3199999999997, "end": 3650.7599999999998, "text": " or how automated change over that 20-year period?", "tokens": [50872, 420, 577, 18473, 1319, 670, 300, 945, 12, 5294, 2896, 30, 50994], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1409, "seek": 363816, "start": 3652.52, "end": 3654.08, "text": " That is, if there had been some revolution", "tokens": [51082, 663, 307, 11, 498, 456, 632, 668, 512, 8894, 51160], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1410, "seek": 363816, "start": 3654.08, "end": 3655.52, "text": " in the nature of automation,", "tokens": [51160, 294, 264, 3687, 295, 17769, 11, 51232], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1411, "seek": 363816, "start": 3655.52, "end": 3657.48, "text": " then the things that predicted which jobs", "tokens": [51232, 550, 264, 721, 300, 19147, 597, 4782, 51330], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1412, "seek": 363816, "start": 3657.48, "end": 3660.12, "text": " would be more automated would have changed over time.", "tokens": [51330, 576, 312, 544, 18473, 576, 362, 3105, 670, 565, 13, 51462], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1413, "seek": 363816, "start": 3661.52, "end": 3665.12, "text": " What we found was that when jobs got more or less automated", "tokens": [51532, 708, 321, 1352, 390, 300, 562, 4782, 658, 544, 420, 1570, 18473, 51712], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1414, "seek": 363816, "start": 3665.12, "end": 3666.96, "text": " that had no effect on average,", "tokens": [51712, 300, 632, 572, 1802, 322, 4274, 11, 51804], "temperature": 0.0, "avg_logprob": -0.14736838418929304, "compression_ratio": 1.806083650190114, "no_speech_prob": 0.0005032785120420158}, {"id": 1415, "seek": 366696, "start": 3666.96, "end": 3668.68, "text": " on wages or number of workers,", "tokens": [50364, 322, 20097, 420, 1230, 295, 5600, 11, 50450], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1416, "seek": 366696, "start": 3669.52, "end": 3671.2400000000002, "text": " and that the predictors of automation", "tokens": [50492, 293, 300, 264, 6069, 830, 295, 17769, 50578], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1417, "seek": 366696, "start": 3671.2400000000002, "end": 3673.28, "text": " didn't change at all over that 20-year period,", "tokens": [50578, 994, 380, 1319, 412, 439, 670, 300, 945, 12, 5294, 2896, 11, 50680], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1418, "seek": 366696, "start": 3673.28, "end": 3676.32, "text": " and they remain to be very simple-minded predictors", "tokens": [50680, 293, 436, 6222, 281, 312, 588, 2199, 12, 23310, 6069, 830, 50832], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1419, "seek": 366696, "start": 3676.32, "end": 3679.2400000000002, "text": " that you might expect about automation from long ago.", "tokens": [50832, 300, 291, 1062, 2066, 466, 17769, 490, 938, 2057, 13, 50978], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1420, "seek": 366696, "start": 3679.2400000000002, "end": 3680.92, "text": " The nature of automation hasn't changed", "tokens": [50978, 440, 3687, 295, 17769, 6132, 380, 3105, 51062], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1421, "seek": 366696, "start": 3680.92, "end": 3682.44, "text": " in the aggregate in the economy.", "tokens": [51062, 294, 264, 26118, 294, 264, 5010, 13, 51138], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1422, "seek": 366696, "start": 3682.44, "end": 3684.2, "text": " Main predictors of automation are", "tokens": [51138, 12383, 6069, 830, 295, 17769, 366, 51226], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1423, "seek": 366696, "start": 3684.2, "end": 3686.2400000000002, "text": " whether the job has nice, clear measures", "tokens": [51226, 1968, 264, 1691, 575, 1481, 11, 1850, 8000, 51328], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1424, "seek": 366696, "start": 3686.2400000000002, "end": 3687.44, "text": " of how well you've done it,", "tokens": [51328, 295, 577, 731, 291, 600, 1096, 309, 11, 51388], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1425, "seek": 366696, "start": 3687.44, "end": 3688.88, "text": " whether it's in a clean environment", "tokens": [51388, 1968, 309, 311, 294, 257, 2541, 2823, 51460], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1426, "seek": 366696, "start": 3688.88, "end": 3690.8, "text": " with fewer disruptions,", "tokens": [51460, 365, 13366, 14124, 626, 11, 51556], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1427, "seek": 366696, "start": 3690.8, "end": 3693.2, "text": " and whether tasks nearby have been automated.", "tokens": [51556, 293, 1968, 9608, 11184, 362, 668, 18473, 13, 51676], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1428, "seek": 366696, "start": 3693.2, "end": 3695.7200000000003, "text": " So there's a way that which task automation spreads", "tokens": [51676, 407, 456, 311, 257, 636, 300, 597, 5633, 17769, 25728, 51802], "temperature": 0.0, "avg_logprob": -0.10704120555957714, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0005031778127886355}, {"id": 1429, "seek": 369572, "start": 3695.7599999999998, "end": 3698.24, "text": " to the network of nearby tasks.", "tokens": [50366, 281, 264, 3209, 295, 11184, 9608, 13, 50490], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1430, "seek": 369572, "start": 3698.24, "end": 3702.0, "text": " So that study suggested at least up until 2019,", "tokens": [50490, 407, 300, 2979, 10945, 412, 1935, 493, 1826, 6071, 11, 50678], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1431, "seek": 369572, "start": 3702.0, "end": 3704.68, "text": " there had been no change in the nature of automation,", "tokens": [50678, 456, 632, 668, 572, 1319, 294, 264, 3687, 295, 17769, 11, 50812], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1432, "seek": 369572, "start": 3704.68, "end": 3707.52, "text": " and basically there's a Gaussian distribution", "tokens": [50812, 293, 1936, 456, 311, 257, 39148, 7316, 50954], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1433, "seek": 369572, "start": 3707.52, "end": 3709.3599999999997, "text": " of how automated jobs are,", "tokens": [50954, 295, 577, 18473, 4782, 366, 11, 51046], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1434, "seek": 369572, "start": 3709.3599999999997, "end": 3712.12, "text": " and the median automation had moved roughly", "tokens": [51046, 293, 264, 26779, 17769, 632, 4259, 9810, 51184], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1435, "seek": 369572, "start": 3712.12, "end": 3715.2799999999997, "text": " a third of a standard deviation through that distribution.", "tokens": [51184, 257, 2636, 295, 257, 3832, 25163, 807, 300, 7316, 13, 51342], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1436, "seek": 369572, "start": 3715.2799999999997, "end": 3717.9599999999996, "text": " So jobs had gotten more automated substantially", "tokens": [51342, 407, 4782, 632, 5768, 544, 18473, 30797, 51476], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1437, "seek": 369572, "start": 3717.9599999999996, "end": 3718.9599999999996, "text": " in that 20-year period,", "tokens": [51476, 294, 300, 945, 12, 5294, 2896, 11, 51526], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1438, "seek": 369572, "start": 3718.9599999999996, "end": 3723.48, "text": " but still most jobs aren't that automated.", "tokens": [51526, 457, 920, 881, 4782, 3212, 380, 300, 18473, 13, 51752], "temperature": 0.0, "avg_logprob": -0.14717182603854578, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0012061742600053549}, {"id": 1439, "seek": 372348, "start": 3723.52, "end": 3725.2, "text": " And that would be my rough prediction", "tokens": [50366, 400, 300, 576, 312, 452, 5903, 17630, 50450], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1440, "seek": 372348, "start": 3725.2, "end": 3727.76, "text": " for the next 20 years is to say", "tokens": [50450, 337, 264, 958, 945, 924, 307, 281, 584, 50578], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1441, "seek": 372348, "start": 3727.76, "end": 3730.16, "text": " the pattern of the last 20 years will continue.", "tokens": [50578, 264, 5102, 295, 264, 1036, 945, 924, 486, 2354, 13, 50698], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1442, "seek": 372348, "start": 3730.16, "end": 3732.8, "text": " That is, I will slowly get more jobs more automated,", "tokens": [50698, 663, 307, 11, 286, 486, 5692, 483, 544, 4782, 544, 18473, 11, 50830], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1443, "seek": 372348, "start": 3732.8, "end": 3736.48, "text": " but most automation will be very basic stuff.", "tokens": [50830, 457, 881, 17769, 486, 312, 588, 3875, 1507, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1444, "seek": 372348, "start": 3736.48, "end": 3739.04, "text": " So far we just haven't seen much at all", "tokens": [51014, 407, 1400, 321, 445, 2378, 380, 1612, 709, 412, 439, 51142], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1445, "seek": 372348, "start": 3739.04, "end": 3741.68, "text": " of advanced AI kinds of automation", "tokens": [51142, 295, 7339, 7318, 3685, 295, 17769, 51274], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1446, "seek": 372348, "start": 3741.68, "end": 3744.16, "text": " making a dent in the larger economy.", "tokens": [51274, 1455, 257, 7059, 294, 264, 4833, 5010, 13, 51398], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1447, "seek": 372348, "start": 3744.16, "end": 3745.8, "text": " So what do you make of things,", "tokens": [51398, 407, 437, 360, 291, 652, 295, 721, 11, 51480], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1448, "seek": 372348, "start": 3745.8, "end": 3749.12, "text": " I'm sure you're familiar with like the MMLU benchmark", "tokens": [51480, 286, 478, 988, 291, 434, 4963, 365, 411, 264, 34191, 43, 52, 18927, 51646], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1449, "seek": 372348, "start": 3749.12, "end": 3750.32, "text": " or the big bench, maybe not,", "tokens": [51646, 420, 264, 955, 10638, 11, 1310, 406, 11, 51706], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1450, "seek": 372348, "start": 3750.32, "end": 3752.96, "text": " if not I can characterize them for you, but.", "tokens": [51706, 498, 406, 286, 393, 38463, 552, 337, 291, 11, 457, 13, 51838], "temperature": 0.0, "avg_logprob": -0.1547832208521226, "compression_ratio": 1.62876254180602, "no_speech_prob": 0.0005882731638848782}, {"id": 1451, "seek": 375296, "start": 3752.96, "end": 3756.12, "text": " Is this machine learning set of tests", "tokens": [50364, 1119, 341, 3479, 2539, 992, 295, 6921, 50522], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1452, "seek": 375296, "start": 3756.12, "end": 3758.8, "text": " in order to benchmark performance?", "tokens": [50522, 294, 1668, 281, 18927, 3389, 30, 50656], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1453, "seek": 375296, "start": 3758.8, "end": 3762.0, "text": " Yes, I believe it's massive multi-task language", "tokens": [50656, 1079, 11, 286, 1697, 309, 311, 5994, 4825, 12, 83, 3863, 2856, 50816], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1454, "seek": 375296, "start": 3762.0, "end": 3765.68, "text": " understanding, the great Dan Hendricks and team.", "tokens": [50816, 3701, 11, 264, 869, 3394, 28594, 81, 7663, 293, 1469, 13, 51000], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1455, "seek": 375296, "start": 3765.68, "end": 3768.6, "text": " So basically a bunch of language understanding benchmarks?", "tokens": [51000, 407, 1936, 257, 3840, 295, 2856, 3701, 43751, 30, 51146], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1456, "seek": 375296, "start": 3768.6, "end": 3771.48, "text": " Yeah, they basically went and took final exams", "tokens": [51146, 865, 11, 436, 1936, 1437, 293, 1890, 2572, 20514, 51290], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1457, "seek": 375296, "start": 3771.48, "end": 3776.48, "text": " from like university and early grad school courses", "tokens": [51290, 490, 411, 5454, 293, 2440, 2771, 1395, 7712, 51540], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1458, "seek": 375296, "start": 3776.7200000000003, "end": 3779.16, "text": " from every domain and compiled them", "tokens": [51552, 490, 633, 9274, 293, 36548, 552, 51674], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1459, "seek": 375296, "start": 3779.16, "end": 3780.64, "text": " into this massive benchmark.", "tokens": [51674, 666, 341, 5994, 18927, 13, 51748], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1460, "seek": 375296, "start": 3780.64, "end": 3782.0, "text": " There have been a couple of different efforts like this,", "tokens": [51748, 821, 362, 668, 257, 1916, 295, 819, 6484, 411, 341, 11, 51816], "temperature": 0.0, "avg_logprob": -0.15856820232463334, "compression_ratio": 1.6779026217228465, "no_speech_prob": 0.000606847635935992}, {"id": 1461, "seek": 378200, "start": 3782.0, "end": 3783.84, "text": " but this is basically the gold standard", "tokens": [50364, 457, 341, 307, 1936, 264, 3821, 3832, 50456], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1462, "seek": 378200, "start": 3783.84, "end": 3786.12, "text": " on which all the language models are measured.", "tokens": [50456, 322, 597, 439, 264, 2856, 5245, 366, 12690, 13, 50570], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1463, "seek": 378200, "start": 3787.24, "end": 3792.24, "text": " And we now have a like high 80s to 90% accuracy rate", "tokens": [50626, 400, 321, 586, 362, 257, 411, 1090, 4688, 82, 281, 4289, 4, 14170, 3314, 50876], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1464, "seek": 378200, "start": 3793.8, "end": 3797.24, "text": " across all fields from like a single model, namely GPT-4.", "tokens": [50954, 2108, 439, 7909, 490, 411, 257, 2167, 2316, 11, 20926, 26039, 51, 12, 19, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1465, "seek": 378200, "start": 3797.24, "end": 3799.4, "text": " And now Google claims that it's Gemini", "tokens": [51126, 400, 586, 3329, 9441, 300, 309, 311, 22894, 3812, 51234], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1466, "seek": 378200, "start": 3799.4, "end": 3802.18, "text": " is hitting that level as well.", "tokens": [51234, 307, 8850, 300, 1496, 382, 731, 13, 51373], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1467, "seek": 378200, "start": 3803.04, "end": 3807.52, "text": " I would agree that these have not been broadly customized", "tokens": [51416, 286, 576, 3986, 300, 613, 362, 406, 668, 19511, 30581, 51640], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1468, "seek": 378200, "start": 3807.52, "end": 3809.6, "text": " to the last mile specifications that they need", "tokens": [51640, 281, 264, 1036, 12620, 29448, 300, 436, 643, 51744], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1469, "seek": 378200, "start": 3809.6, "end": 3811.76, "text": " to like work in the context of different firms", "tokens": [51744, 281, 411, 589, 294, 264, 4319, 295, 819, 18055, 51852], "temperature": 0.0, "avg_logprob": -0.1497221346254702, "compression_ratio": 1.5576208178438662, "no_speech_prob": 0.00040435665869154036}, {"id": 1470, "seek": 381176, "start": 3811.76, "end": 3815.7200000000003, "text": " and cultural contexts and all that sort of thing.", "tokens": [50364, 293, 6988, 30628, 293, 439, 300, 1333, 295, 551, 13, 50562], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1471, "seek": 381176, "start": 3815.7200000000003, "end": 3818.6800000000003, "text": " But it does seem like the way I typically describe it", "tokens": [50562, 583, 309, 775, 1643, 411, 264, 636, 286, 5850, 6786, 309, 50710], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1472, "seek": 381176, "start": 3818.6800000000003, "end": 3822.96, "text": " is that AIs are now better at routine tasks", "tokens": [50710, 307, 300, 316, 6802, 366, 586, 1101, 412, 9927, 9608, 50924], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1473, "seek": 381176, "start": 3822.96, "end": 3825.1200000000003, "text": " than the average person and that they are closing in", "tokens": [50924, 813, 264, 4274, 954, 293, 300, 436, 366, 10377, 294, 51032], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1474, "seek": 381176, "start": 3825.1200000000003, "end": 3829.1200000000003, "text": " on expert performance on routine tasks.", "tokens": [51032, 322, 5844, 3389, 322, 9927, 9608, 13, 51232], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1475, "seek": 381176, "start": 3829.1200000000003, "end": 3831.88, "text": " And that's measured by these medical diagnosis benchmarks,", "tokens": [51232, 400, 300, 311, 12690, 538, 613, 4625, 15217, 43751, 11, 51370], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1476, "seek": 381176, "start": 3831.88, "end": 3836.0, "text": " these MMLU type things, et cetera, et cetera.", "tokens": [51370, 613, 376, 12683, 52, 2010, 721, 11, 1030, 11458, 11, 1030, 11458, 13, 51576], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1477, "seek": 381176, "start": 3836.0, "end": 3840.1200000000003, "text": " So let me remind you that in the 1960s say", "tokens": [51576, 407, 718, 385, 4160, 291, 300, 294, 264, 16157, 82, 584, 51782], "temperature": 0.0, "avg_logprob": -0.13637385368347169, "compression_ratio": 1.5967078189300412, "no_speech_prob": 0.0001851876440923661}, {"id": 1478, "seek": 384012, "start": 3841.12, "end": 3846.12, "text": " AI researchers took chess as a paradigm of", "tokens": [50414, 7318, 10309, 1890, 24122, 382, 257, 24709, 295, 50664], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1479, "seek": 384012, "start": 3846.2, "end": 3848.88, "text": " if you can make a machine that can do that,", "tokens": [50668, 498, 291, 393, 652, 257, 3479, 300, 393, 360, 300, 11, 50802], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1480, "seek": 384012, "start": 3848.88, "end": 3850.7599999999998, "text": " well, obviously you'll have to have solved", "tokens": [50802, 731, 11, 2745, 291, 603, 362, 281, 362, 13041, 50896], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1481, "seek": 384012, "start": 3850.7599999999998, "end": 3852.6, "text": " most of the major problems in thinking", "tokens": [50896, 881, 295, 264, 2563, 2740, 294, 1953, 50988], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1482, "seek": 384012, "start": 3852.6, "end": 3855.2, "text": " because chess involves most of the major problems", "tokens": [50988, 570, 24122, 11626, 881, 295, 264, 2563, 2740, 51118], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1483, "seek": 384012, "start": 3855.2, "end": 3856.04, "text": " in thinking.", "tokens": [51118, 294, 1953, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1484, "seek": 384012, "start": 3856.04, "end": 3859.68, "text": " So when we can finally have human level chess abilities,", "tokens": [51160, 407, 562, 321, 393, 2721, 362, 1952, 1496, 24122, 11582, 11, 51342], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1485, "seek": 384012, "start": 3859.68, "end": 3861.68, "text": " we will have human level AI.", "tokens": [51342, 321, 486, 362, 1952, 1496, 7318, 13, 51442], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1486, "seek": 384012, "start": 3861.68, "end": 3863.12, "text": " That was the thinking in the 60s", "tokens": [51442, 663, 390, 264, 1953, 294, 264, 4060, 82, 51514], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1487, "seek": 384012, "start": 3863.12, "end": 3865.64, "text": " and they could look at the rate at which AI", "tokens": [51514, 293, 436, 727, 574, 412, 264, 3314, 412, 597, 7318, 51640], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1488, "seek": 384012, "start": 3865.64, "end": 3868.4, "text": " was getting better at chess and forecast long before", "tokens": [51640, 390, 1242, 1101, 412, 24122, 293, 14330, 938, 949, 51778], "temperature": 0.0, "avg_logprob": -0.12168549247409986, "compression_ratio": 1.788, "no_speech_prob": 0.0002959294361062348}, {"id": 1489, "seek": 386840, "start": 3868.4, "end": 3871.84, "text": " it happened that in the late 1970s, 1990s, excuse me,", "tokens": [50364, 309, 2011, 300, 294, 264, 3469, 14577, 82, 11, 13384, 82, 11, 8960, 385, 11, 50536], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1490, "seek": 386840, "start": 3871.84, "end": 3875.88, "text": " is exactly when chess would reach human level ability", "tokens": [50536, 307, 2293, 562, 24122, 576, 2524, 1952, 1496, 3485, 50738], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1491, "seek": 386840, "start": 3875.88, "end": 3877.76, "text": " and that's when it did happen.", "tokens": [50738, 293, 300, 311, 562, 309, 630, 1051, 13, 50832], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1492, "seek": 386840, "start": 3877.76, "end": 3880.32, "text": " And that was 25 years ago.", "tokens": [50832, 400, 300, 390, 3552, 924, 2057, 13, 50960], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1493, "seek": 386840, "start": 3880.32, "end": 3882.4, "text": " And clearly they were just wrong about the idea", "tokens": [50960, 400, 4448, 436, 645, 445, 2085, 466, 264, 1558, 51064], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1494, "seek": 386840, "start": 3882.4, "end": 3884.6, "text": " that you couldn't do chess without solving", "tokens": [51064, 300, 291, 2809, 380, 360, 24122, 1553, 12606, 51174], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1495, "seek": 386840, "start": 3884.6, "end": 3886.1600000000003, "text": " all the major thinking problems.", "tokens": [51174, 439, 264, 2563, 1953, 2740, 13, 51252], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1496, "seek": 386840, "start": 3886.1600000000003, "end": 3888.6800000000003, "text": " And we repeatedly have this sort of phenomena", "tokens": [51252, 400, 321, 18227, 362, 341, 1333, 295, 22004, 51378], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1497, "seek": 386840, "start": 3888.6800000000003, "end": 3891.84, "text": " where people look at something and they go,", "tokens": [51378, 689, 561, 574, 412, 746, 293, 436, 352, 11, 51536], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1498, "seek": 386840, "start": 3891.84, "end": 3894.88, "text": " if you can do that, surely you can do most everything.", "tokens": [51536, 498, 291, 393, 360, 300, 11, 11468, 291, 393, 360, 881, 1203, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1499, "seek": 386840, "start": 3894.88, "end": 3897.6800000000003, "text": " And then we can do that and we can't do near,", "tokens": [51688, 400, 550, 321, 393, 360, 300, 293, 321, 393, 380, 360, 2651, 11, 51828], "temperature": 0.0, "avg_logprob": -0.1288455696993096, "compression_ratio": 1.7328519855595668, "no_speech_prob": 0.002550373086705804}, {"id": 1500, "seek": 389768, "start": 3897.72, "end": 3899.3599999999997, "text": " and we aren't near to doing most everything.", "tokens": [50366, 293, 321, 3212, 380, 2651, 281, 884, 881, 1203, 13, 50448], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1501, "seek": 389768, "start": 3899.3599999999997, "end": 3901.64, "text": " So I just got to say this benchmark is just wrong.", "tokens": [50448, 407, 286, 445, 658, 281, 584, 341, 18927, 307, 445, 2085, 13, 50562], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1502, "seek": 389768, "start": 3901.64, "end": 3905.12, "text": " It's not true that if you can do these language benchmark,", "tokens": [50562, 467, 311, 406, 2074, 300, 498, 291, 393, 360, 613, 2856, 18927, 11, 50736], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1503, "seek": 389768, "start": 3905.12, "end": 3906.64, "text": " you are near to doing most everything.", "tokens": [50736, 291, 366, 2651, 281, 884, 881, 1203, 13, 50812], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1504, "seek": 389768, "start": 3906.64, "end": 3908.2, "text": " You are not near.", "tokens": [50812, 509, 366, 406, 2651, 13, 50890], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1505, "seek": 389768, "start": 3908.2, "end": 3909.9199999999996, "text": " Yeah, I would find my position to say,", "tokens": [50890, 865, 11, 286, 576, 915, 452, 2535, 281, 584, 11, 50976], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1506, "seek": 389768, "start": 3909.9199999999996, "end": 3913.08, "text": " I think you're near to being able to do all the routine things", "tokens": [50976, 286, 519, 291, 434, 2651, 281, 885, 1075, 281, 360, 439, 264, 9927, 721, 51134], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1507, "seek": 389768, "start": 3913.08, "end": 3916.08, "text": " that are well documented in the training data.", "tokens": [51134, 300, 366, 731, 23007, 294, 264, 3097, 1412, 13, 51284], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1508, "seek": 389768, "start": 3916.08, "end": 3918.3199999999997, "text": " Well, yes, but the question is in the economy,", "tokens": [51284, 1042, 11, 2086, 11, 457, 264, 1168, 307, 294, 264, 5010, 11, 51396], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1509, "seek": 389768, "start": 3918.3199999999997, "end": 3921.0, "text": " all the things we need doing, how close are you to that?", "tokens": [51396, 439, 264, 721, 321, 643, 884, 11, 577, 1998, 366, 291, 281, 300, 30, 51530], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1510, "seek": 389768, "start": 3921.0, "end": 3923.0, "text": " And say you're not close.", "tokens": [51530, 400, 584, 291, 434, 406, 1998, 13, 51630], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1511, "seek": 389768, "start": 3923.0, "end": 3927.12, "text": " I mean, we're seeing just the very beginning of sort of,", "tokens": [51630, 286, 914, 11, 321, 434, 2577, 445, 264, 588, 2863, 295, 1333, 295, 11, 51836], "temperature": 0.0, "avg_logprob": -0.11481468398849685, "compression_ratio": 1.8542372881355933, "no_speech_prob": 0.0005191513919271529}, {"id": 1512, "seek": 392712, "start": 3927.12, "end": 3929.56, "text": " I mean, again, I don't know, like...", "tokens": [50364, 286, 914, 11, 797, 11, 286, 500, 380, 458, 11, 411, 485, 50486], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1513, "seek": 392712, "start": 3929.56, "end": 3930.96, "text": " What do you think was going on in their head", "tokens": [50486, 708, 360, 291, 519, 390, 516, 322, 294, 641, 1378, 50556], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1514, "seek": 392712, "start": 3930.96, "end": 3933.7999999999997, "text": " in the 1960s when they looked at chess, right?", "tokens": [50556, 294, 264, 16157, 82, 562, 436, 2956, 412, 24122, 11, 558, 30, 50698], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1515, "seek": 392712, "start": 3933.7999999999997, "end": 3935.04, "text": " They looked at chess and they said,", "tokens": [50698, 814, 2956, 412, 24122, 293, 436, 848, 11, 50760], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1516, "seek": 392712, "start": 3935.04, "end": 3936.72, "text": " it takes really smart people to do chess,", "tokens": [50760, 309, 2516, 534, 4069, 561, 281, 360, 24122, 11, 50844], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1517, "seek": 392712, "start": 3936.72, "end": 3938.96, "text": " look at all these complicated things people are doing", "tokens": [50844, 574, 412, 439, 613, 6179, 721, 561, 366, 884, 50956], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1518, "seek": 392712, "start": 3938.96, "end": 3941.3599999999997, "text": " when they do chess in order to achieve in chess,", "tokens": [50956, 562, 436, 360, 24122, 294, 1668, 281, 4584, 294, 24122, 11, 51076], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1519, "seek": 392712, "start": 3941.3599999999997, "end": 3942.6, "text": " they said to themselves,", "tokens": [51076, 436, 848, 281, 2969, 11, 51138], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1520, "seek": 392712, "start": 3942.6, "end": 3944.0, "text": " that's the sort of thing we should work on", "tokens": [51138, 300, 311, 264, 1333, 295, 551, 321, 820, 589, 322, 51208], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1521, "seek": 392712, "start": 3944.0, "end": 3945.44, "text": " because if we can get a machine to do that,", "tokens": [51208, 570, 498, 321, 393, 483, 257, 3479, 281, 360, 300, 11, 51280], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1522, "seek": 392712, "start": 3945.44, "end": 3949.92, "text": " surely we must be close to general artificial intelligence.", "tokens": [51280, 11468, 321, 1633, 312, 1998, 281, 2674, 11677, 7599, 13, 51504], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1523, "seek": 392712, "start": 3949.92, "end": 3952.7999999999997, "text": " If you could have something that could do chess.", "tokens": [51504, 759, 291, 727, 362, 746, 300, 727, 360, 24122, 13, 51648], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1524, "seek": 392712, "start": 3952.7999999999997, "end": 3955.24, "text": " And there is a sense that when you have general intelligence,", "tokens": [51648, 400, 456, 307, 257, 2020, 300, 562, 291, 362, 2674, 7599, 11, 51770], "temperature": 0.0, "avg_logprob": -0.11494071620285132, "compression_ratio": 1.8385093167701863, "no_speech_prob": 0.00013981008669361472}, {"id": 1525, "seek": 395524, "start": 3955.24, "end": 3958.04, "text": " you can use all of that to do clever things about chess,", "tokens": [50364, 291, 393, 764, 439, 295, 300, 281, 360, 13494, 721, 466, 24122, 11, 50504], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1526, "seek": 395524, "start": 3958.04, "end": 3961.3999999999996, "text": " but it's not true that you need to have all those general things", "tokens": [50504, 457, 309, 311, 406, 2074, 300, 291, 643, 281, 362, 439, 729, 2674, 721, 50672], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1527, "seek": 395524, "start": 3961.3999999999996, "end": 3962.3999999999996, "text": " in order to be good at chess.", "tokens": [50672, 294, 1668, 281, 312, 665, 412, 24122, 13, 50722], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1528, "seek": 395524, "start": 3962.3999999999996, "end": 3964.2, "text": " That turns out there's a way to be good at chess", "tokens": [50722, 663, 4523, 484, 456, 311, 257, 636, 281, 312, 665, 412, 24122, 50812], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1529, "seek": 395524, "start": 3964.2, "end": 3965.8399999999997, "text": " without doing all those other things.", "tokens": [50812, 1553, 884, 439, 729, 661, 721, 13, 50894], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1530, "seek": 395524, "start": 3965.8399999999997, "end": 3967.64, "text": " And that's repeatedly been the problem", "tokens": [50894, 400, 300, 311, 18227, 668, 264, 1154, 50984], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1531, "seek": 395524, "start": 3967.64, "end": 3969.3999999999996, "text": " and that could be the problem today.", "tokens": [50984, 293, 300, 727, 312, 264, 1154, 965, 13, 51072], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1532, "seek": 395524, "start": 3969.3999999999996, "end": 3972.2799999999997, "text": " Turns out there's a way to do these exam answering things", "tokens": [51072, 29524, 484, 456, 311, 257, 636, 281, 360, 613, 1139, 13430, 721, 51216], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1533, "seek": 395524, "start": 3972.2799999999997, "end": 3976.9599999999996, "text": " that doesn't require the full range of general intelligence", "tokens": [51216, 300, 1177, 380, 3651, 264, 1577, 3613, 295, 2674, 7599, 51450], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1534, "seek": 395524, "start": 3976.9599999999996, "end": 3978.68, "text": " in order to achieve that task.", "tokens": [51450, 294, 1668, 281, 4584, 300, 5633, 13, 51536], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1535, "seek": 395524, "start": 3978.68, "end": 3981.12, "text": " It's hard to pick a good range of tasks", "tokens": [51536, 467, 311, 1152, 281, 1888, 257, 665, 3613, 295, 9608, 51658], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1536, "seek": 395524, "start": 3981.12, "end": 3984.12, "text": " that encompasses the full range of intelligence", "tokens": [51658, 300, 49866, 264, 1577, 3613, 295, 7599, 51808], "temperature": 0.0, "avg_logprob": -0.0807335765649241, "compression_ratio": 2.010948905109489, "no_speech_prob": 0.0012446502223610878}, {"id": 1537, "seek": 398412, "start": 3984.12, "end": 3986.7599999999998, "text": " because again, you teach through the test", "tokens": [50364, 570, 797, 11, 291, 2924, 807, 264, 1500, 50496], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1538, "seek": 398412, "start": 3986.7599999999998, "end": 3988.8399999999997, "text": " and you end up finding a way to solve that problem", "tokens": [50496, 293, 291, 917, 493, 5006, 257, 636, 281, 5039, 300, 1154, 50600], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1539, "seek": 398412, "start": 3988.8399999999997, "end": 3991.68, "text": " without achieving general intelligence.", "tokens": [50600, 1553, 19626, 2674, 7599, 13, 50742], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1540, "seek": 398412, "start": 3991.68, "end": 3993.3599999999997, "text": " This does seem different though.", "tokens": [50742, 639, 775, 1643, 819, 1673, 13, 50826], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1541, "seek": 398412, "start": 3993.3599999999997, "end": 3995.56, "text": " I mean, I would, I grew with your characterization", "tokens": [50826, 286, 914, 11, 286, 576, 11, 286, 6109, 365, 428, 49246, 50936], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1542, "seek": 398412, "start": 3995.56, "end": 3999.08, "text": " that basically it turned out that there was an easier way", "tokens": [50936, 300, 1936, 309, 3574, 484, 300, 456, 390, 364, 3571, 636, 51112], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1543, "seek": 398412, "start": 3999.08, "end": 4002.8399999999997, "text": " or a more direct way, a narrower way to solve chess.", "tokens": [51112, 420, 257, 544, 2047, 636, 11, 257, 46751, 636, 281, 5039, 24122, 13, 51300], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1544, "seek": 398412, "start": 4002.8399999999997, "end": 4007.08, "text": " And it's interesting that it's like rather different.", "tokens": [51300, 400, 309, 311, 1880, 300, 309, 311, 411, 2831, 819, 13, 51512], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1545, "seek": 398412, "start": 4007.08, "end": 4010.64, "text": " You know, it involves these sort of superhuman tree search", "tokens": [51512, 509, 458, 11, 309, 11626, 613, 1333, 295, 1687, 18796, 4230, 3164, 51690], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1546, "seek": 398412, "start": 4010.64, "end": 4011.6, "text": " capabilities.", "tokens": [51690, 10862, 13, 51738], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1547, "seek": 398412, "start": 4011.6, "end": 4012.96, "text": " But that wasn't just true of trust.", "tokens": [51738, 583, 300, 2067, 380, 445, 2074, 295, 3361, 13, 51806], "temperature": 0.0, "avg_logprob": -0.14348237882784712, "compression_ratio": 1.6554054054054055, "no_speech_prob": 0.0005882270052097738}, {"id": 1548, "seek": 401296, "start": 4012.96, "end": 4015.88, "text": " There were another dozen sorts of really hard problems", "tokens": [50364, 821, 645, 1071, 16654, 7527, 295, 534, 1152, 2740, 50510], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1549, "seek": 401296, "start": 4015.88, "end": 4020.88, "text": " that people in the 1960s took as exemplars of things", "tokens": [50510, 300, 561, 294, 264, 16157, 82, 1890, 382, 24112, 685, 295, 721, 50760], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1550, "seek": 401296, "start": 4020.88, "end": 4022.44, "text": " that would require general intelligence", "tokens": [50760, 300, 576, 3651, 2674, 7599, 50838], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1551, "seek": 401296, "start": 4022.44, "end": 4024.56, "text": " and the great many of them have been achieved.", "tokens": [50838, 293, 264, 869, 867, 295, 552, 362, 668, 11042, 13, 50944], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1552, "seek": 401296, "start": 4024.56, "end": 4027.2400000000002, "text": " But when I look at the current situation,", "tokens": [50944, 583, 562, 286, 574, 412, 264, 2190, 2590, 11, 51078], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1553, "seek": 401296, "start": 4027.2400000000002, "end": 4029.96, "text": " I'm like, this does look a lot more", "tokens": [51078, 286, 478, 411, 11, 341, 775, 574, 257, 688, 544, 51214], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1554, "seek": 401296, "start": 4029.96, "end": 4032.08, "text": " like the human intelligence.", "tokens": [51214, 411, 264, 1952, 7599, 13, 51320], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1555, "seek": 401296, "start": 4032.08, "end": 4036.2400000000002, "text": " And I would say that from any number of different directions.", "tokens": [51320, 400, 286, 576, 584, 300, 490, 604, 1230, 295, 819, 11095, 13, 51528], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1556, "seek": 401296, "start": 4036.2400000000002, "end": 4039.36, "text": " And that was true in every decade for the last century.", "tokens": [51528, 400, 300, 390, 2074, 294, 633, 10378, 337, 264, 1036, 4901, 13, 51684], "temperature": 0.0, "avg_logprob": -0.13203909763923058, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.0003250079753343016}, {"id": 1557, "seek": 403936, "start": 4040.36, "end": 4044.08, "text": " Every decade has seen advances that were not the sort", "tokens": [50414, 2048, 10378, 575, 1612, 25297, 300, 645, 406, 264, 1333, 50600], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1558, "seek": 403936, "start": 4044.08, "end": 4046.08, "text": " that previous systems could achieve.", "tokens": [50600, 300, 3894, 3652, 727, 4584, 13, 50700], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1559, "seek": 403936, "start": 4046.08, "end": 4047.96, "text": " It's clear that you are always, I think it's clear", "tokens": [50700, 467, 311, 1850, 300, 291, 366, 1009, 11, 286, 519, 309, 311, 1850, 50794], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1560, "seek": 403936, "start": 4047.96, "end": 4052.1600000000003, "text": " that you don't see the human brain, the human, you know,", "tokens": [50794, 300, 291, 500, 380, 536, 264, 1952, 3567, 11, 264, 1952, 11, 291, 458, 11, 51004], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1561, "seek": 403936, "start": 4052.1600000000003, "end": 4055.6400000000003, "text": " achieve level of achievement as sort of a maximum, right?", "tokens": [51004, 4584, 1496, 295, 15838, 382, 1333, 295, 257, 6674, 11, 558, 30, 51178], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1562, "seek": 403936, "start": 4055.6400000000003, "end": 4057.08, "text": " Oh, of course not. Absolutely.", "tokens": [51178, 876, 11, 295, 1164, 406, 13, 7021, 13, 51250], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1563, "seek": 403936, "start": 4057.08, "end": 4061.2400000000002, "text": " So it's like there's got to be a finite number", "tokens": [51250, 407, 309, 311, 411, 456, 311, 658, 281, 312, 257, 19362, 1230, 51458], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1564, "seek": 403936, "start": 4061.2400000000002, "end": 4065.0, "text": " of breakthroughs that need to happen.", "tokens": [51458, 295, 22397, 82, 300, 643, 281, 1051, 13, 51646], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1565, "seek": 403936, "start": 4065.0, "end": 4067.2400000000002, "text": " We will eventually get full human level AI.", "tokens": [51646, 492, 486, 4728, 483, 1577, 1952, 1496, 7318, 13, 51758], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1566, "seek": 403936, "start": 4067.2400000000002, "end": 4068.6800000000003, "text": " I have no doubt about that.", "tokens": [51758, 286, 362, 572, 6385, 466, 300, 13, 51830], "temperature": 0.0, "avg_logprob": -0.18909351161268892, "compression_ratio": 1.6444444444444444, "no_speech_prob": 0.00041728850919753313}, {"id": 1567, "seek": 406868, "start": 4068.68, "end": 4073.52, "text": " And not soon after vastly exceeded, that will happen.", "tokens": [50364, 400, 406, 2321, 934, 41426, 38026, 11, 300, 486, 1051, 13, 50606], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1568, "seek": 406868, "start": 4073.52, "end": 4076.48, "text": " And it will happen plausibly within the next thousand years.", "tokens": [50606, 400, 309, 486, 1051, 34946, 3545, 1951, 264, 958, 4714, 924, 13, 50754], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1569, "seek": 406868, "start": 4076.48, "end": 4080.2, "text": " It also seems like you would probably agree that it need not", "tokens": [50754, 467, 611, 2544, 411, 291, 576, 1391, 3986, 300, 309, 643, 406, 50940], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1570, "seek": 406868, "start": 4080.2, "end": 4084.7999999999997, "text": " be point for point, you know, the M scenario is a great one", "tokens": [50940, 312, 935, 337, 935, 11, 291, 458, 11, 264, 376, 9005, 307, 257, 869, 472, 51170], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1571, "seek": 406868, "start": 4084.7999999999997, "end": 4087.6, "text": " to play out and analyze, but it need not be the case.", "tokens": [51170, 281, 862, 484, 293, 12477, 11, 457, 309, 643, 406, 312, 264, 1389, 13, 51310], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1572, "seek": 406868, "start": 4087.6, "end": 4090.64, "text": " Right. So the AIs could be much better than humans in some ways", "tokens": [51310, 1779, 13, 407, 264, 316, 6802, 727, 312, 709, 1101, 813, 6255, 294, 512, 2098, 51462], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1573, "seek": 406868, "start": 4090.64, "end": 4092.44, "text": " and still much worse than others.", "tokens": [51462, 293, 920, 709, 5324, 813, 2357, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1574, "seek": 406868, "start": 4092.44, "end": 4095.2799999999997, "text": " That will probably actually be true for a long time.", "tokens": [51552, 663, 486, 1391, 767, 312, 2074, 337, 257, 938, 565, 13, 51694], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1575, "seek": 406868, "start": 4095.2799999999997, "end": 4097.88, "text": " That is, it'll take a lot longer till AIs are better", "tokens": [51694, 663, 307, 11, 309, 603, 747, 257, 688, 2854, 4288, 316, 6802, 366, 1101, 51824], "temperature": 0.0, "avg_logprob": -0.1836393079684891, "compression_ratio": 1.7298245614035088, "no_speech_prob": 0.00028679962269961834}, {"id": 1576, "seek": 409788, "start": 4097.88, "end": 4100.24, "text": " than humans at most everything than that they are better", "tokens": [50364, 813, 6255, 412, 881, 1203, 813, 300, 436, 366, 1101, 50482], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1577, "seek": 409788, "start": 4100.24, "end": 4103.24, "text": " at humans at say half of things people do today.", "tokens": [50482, 412, 6255, 412, 584, 1922, 295, 721, 561, 360, 965, 13, 50632], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1578, "seek": 409788, "start": 4103.24, "end": 4104.64, "text": " But of course you have to realize if you looked", "tokens": [50632, 583, 295, 1164, 291, 362, 281, 4325, 498, 291, 2956, 50702], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1579, "seek": 409788, "start": 4104.64, "end": 4108.24, "text": " at what humans were doing two centuries ago, we're already", "tokens": [50702, 412, 437, 6255, 645, 884, 732, 13926, 2057, 11, 321, 434, 1217, 50882], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1580, "seek": 409788, "start": 4108.24, "end": 4110.76, "text": " at the point where machines do those things much better", "tokens": [50882, 412, 264, 935, 689, 8379, 360, 729, 721, 709, 1101, 51008], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1581, "seek": 409788, "start": 4110.76, "end": 4112.4800000000005, "text": " than humans can do.", "tokens": [51008, 813, 6255, 393, 360, 13, 51094], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1582, "seek": 409788, "start": 4112.4800000000005, "end": 4114.76, "text": " That is, the attack, most tasks that humans were doing", "tokens": [51094, 663, 307, 11, 264, 2690, 11, 881, 9608, 300, 6255, 645, 884, 51208], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1583, "seek": 409788, "start": 4114.76, "end": 4117.96, "text": " two centuries ago are already long since automated.", "tokens": [51208, 732, 13926, 2057, 366, 1217, 938, 1670, 18473, 13, 51368], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1584, "seek": 409788, "start": 4117.96, "end": 4120.64, "text": " We've now switched our attention to the sort of tasks", "tokens": [51368, 492, 600, 586, 16858, 527, 3202, 281, 264, 1333, 295, 9608, 51502], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1585, "seek": 409788, "start": 4120.64, "end": 4122.56, "text": " that people were not doing two centuries ago.", "tokens": [51502, 300, 561, 645, 406, 884, 732, 13926, 2057, 13, 51598], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1586, "seek": 409788, "start": 4122.56, "end": 4125.08, "text": " And on those, we're not so good at making machines do them,", "tokens": [51598, 400, 322, 729, 11, 321, 434, 406, 370, 665, 412, 1455, 8379, 360, 552, 11, 51724], "temperature": 0.0, "avg_logprob": -0.14791707025058026, "compression_ratio": 1.9821428571428572, "no_speech_prob": 0.0033753199968487024}, {"id": 1587, "seek": 412508, "start": 4125.08, "end": 4129.12, "text": " but we've already dramatically achieved full automation basically", "tokens": [50364, 457, 321, 600, 1217, 17548, 11042, 1577, 17769, 1936, 50566], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1588, "seek": 412508, "start": 4129.12, "end": 4131.84, "text": " of most things humans were doing two centuries ago.", "tokens": [50566, 295, 881, 721, 6255, 645, 884, 732, 13926, 2057, 13, 50702], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1589, "seek": 412508, "start": 4131.84, "end": 4133.76, "text": " Which for very shorthand I would say is kind", "tokens": [50702, 3013, 337, 588, 402, 2652, 474, 286, 576, 584, 307, 733, 50798], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1590, "seek": 412508, "start": 4133.76, "end": 4138.0, "text": " of routine repetitive physical tasks.", "tokens": [50798, 295, 9927, 29404, 4001, 9608, 13, 51010], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1591, "seek": 412508, "start": 4138.0, "end": 4140.08, "text": " Right. I mean, we managed to change the environment", "tokens": [51010, 1779, 13, 286, 914, 11, 321, 6453, 281, 1319, 264, 2823, 51114], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1592, "seek": 412508, "start": 4140.08, "end": 4142.4, "text": " to make them more routine and repetitive.", "tokens": [51114, 281, 652, 552, 544, 9927, 293, 29404, 13, 51230], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1593, "seek": 412508, "start": 4142.4, "end": 4145.88, "text": " So, you know, a subsistence farmer", "tokens": [51230, 407, 11, 291, 458, 11, 257, 2090, 468, 655, 17891, 51404], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1594, "seek": 412508, "start": 4145.88, "end": 4148.72, "text": " on a subsistence farm two centuries ago, they were,", "tokens": [51404, 322, 257, 2090, 468, 655, 5421, 732, 13926, 2057, 11, 436, 645, 11, 51546], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1595, "seek": 412508, "start": 4148.72, "end": 4151.2, "text": " we couldn't, our automation could not do that job", "tokens": [51546, 321, 2809, 380, 11, 527, 17769, 727, 406, 360, 300, 1691, 51670], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1596, "seek": 412508, "start": 4151.2, "end": 4152.5199999999995, "text": " that they were doing that.", "tokens": [51670, 300, 436, 645, 884, 300, 13, 51736], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1597, "seek": 412508, "start": 4152.5199999999995, "end": 4154.08, "text": " And we managed to make the farms different.", "tokens": [51736, 400, 321, 6453, 281, 652, 264, 20366, 819, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13333790004253387, "compression_ratio": 1.792857142857143, "no_speech_prob": 0.0004727872146759182}, {"id": 1598, "seek": 415408, "start": 4154.08, "end": 4155.96, "text": " The factory is different, et cetera, so that our machines", "tokens": [50364, 440, 9265, 307, 819, 11, 1030, 11458, 11, 370, 300, 527, 8379, 50458], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1599, "seek": 415408, "start": 4155.96, "end": 4157.36, "text": " could do them.", "tokens": [50458, 727, 360, 552, 13, 50528], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1600, "seek": 415408, "start": 4157.36, "end": 4160.0, "text": " And now they are producing much more than those people produce.", "tokens": [50528, 400, 586, 436, 366, 10501, 709, 544, 813, 729, 561, 5258, 13, 50660], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1601, "seek": 415408, "start": 4160.0, "end": 4162.6, "text": " But if you had to try to produce the way they were doing", "tokens": [50660, 583, 498, 291, 632, 281, 853, 281, 5258, 264, 636, 436, 645, 884, 50790], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1602, "seek": 415408, "start": 4162.6, "end": 4165.68, "text": " two centuries ago, our machines today could not do that.", "tokens": [50790, 732, 13926, 2057, 11, 527, 8379, 965, 727, 406, 360, 300, 13, 50944], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1603, "seek": 415408, "start": 4165.68, "end": 4168.68, "text": " Yeah, a big theory I have also, I actually don't think this is going", "tokens": [50944, 865, 11, 257, 955, 5261, 286, 362, 611, 11, 286, 767, 500, 380, 519, 341, 307, 516, 51094], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1604, "seek": 415408, "start": 4168.68, "end": 4172.16, "text": " to be a huge, well, everything's going to be huge,", "tokens": [51094, 281, 312, 257, 2603, 11, 731, 11, 1203, 311, 516, 281, 312, 2603, 11, 51268], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1605, "seek": 415408, "start": 4172.16, "end": 4175.8, "text": " but I don't think it's going to be like the dominant change", "tokens": [51268, 457, 286, 500, 380, 519, 309, 311, 516, 281, 312, 411, 264, 15657, 1319, 51450], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1606, "seek": 415408, "start": 4175.8, "end": 4178.96, "text": " that leads to qualitatively different future.", "tokens": [51450, 300, 6689, 281, 31312, 356, 819, 2027, 13, 51608], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1607, "seek": 415408, "start": 4178.96, "end": 4181.76, "text": " But I do think we will start to see, and are beginning", "tokens": [51608, 583, 286, 360, 519, 321, 486, 722, 281, 536, 11, 293, 366, 2863, 51748], "temperature": 0.0, "avg_logprob": -0.16775434236999945, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.00047276332043111324}, {"id": 1608, "seek": 418176, "start": 4181.84, "end": 4186.16, "text": " to see that same process happening with language models,", "tokens": [50368, 281, 536, 300, 912, 1399, 2737, 365, 2856, 5245, 11, 50584], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1609, "seek": 418176, "start": 4186.16, "end": 4189.52, "text": " where, you know, I consult with a few different businesses", "tokens": [50584, 689, 11, 291, 458, 11, 286, 7189, 365, 257, 1326, 819, 6011, 50752], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1610, "seek": 418176, "start": 4189.52, "end": 4192.24, "text": " and we have kind of processes that, you know,", "tokens": [50752, 293, 321, 362, 733, 295, 7555, 300, 11, 291, 458, 11, 50888], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1611, "seek": 418176, "start": 4192.24, "end": 4194.0, "text": " we would like to automate.", "tokens": [50888, 321, 576, 411, 281, 31605, 13, 50976], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1612, "seek": 418176, "start": 4194.0, "end": 4197.8, "text": " You know, a classic one would be like initial resume screening.", "tokens": [50976, 509, 458, 11, 257, 7230, 472, 576, 312, 411, 5883, 15358, 17732, 13, 51166], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1613, "seek": 418176, "start": 4197.8, "end": 4199.6, "text": " Right. We're not going to have the language model at this point", "tokens": [51166, 1779, 13, 492, 434, 406, 516, 281, 362, 264, 2856, 2316, 412, 341, 935, 51256], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1614, "seek": 418176, "start": 4199.6, "end": 4200.92, "text": " make the hiring decisions.", "tokens": [51256, 652, 264, 15335, 5327, 13, 51322], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1615, "seek": 418176, "start": 4200.92, "end": 4202.92, "text": " But if we get a lot of garbage resumes, you know,", "tokens": [51322, 583, 498, 321, 483, 257, 688, 295, 14150, 48068, 11, 291, 458, 11, 51422], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1616, "seek": 418176, "start": 4202.92, "end": 4208.16, "text": " we can definitely get language models to kind of band the resumes", "tokens": [51422, 321, 393, 2138, 483, 2856, 5245, 281, 733, 295, 4116, 264, 48068, 51684], "temperature": 0.0, "avg_logprob": -0.16070439897734543, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.001866719452664256}, {"id": 1617, "seek": 420816, "start": 4208.16, "end": 4212.08, "text": " into, you know, one to five and like spend our time on the fives.", "tokens": [50364, 666, 11, 291, 458, 11, 472, 281, 1732, 293, 411, 3496, 527, 565, 322, 264, 283, 1539, 13, 50560], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1618, "seek": 420816, "start": 4213.28, "end": 4216.08, "text": " It does seem to me that there's a lot of kind of process", "tokens": [50620, 467, 775, 1643, 281, 385, 300, 456, 311, 257, 688, 295, 733, 295, 1399, 50760], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1619, "seek": 420816, "start": 4216.08, "end": 4220.4, "text": " and environment adaptation that is not that hard to do.", "tokens": [50760, 293, 2823, 21549, 300, 307, 406, 300, 1152, 281, 360, 13, 50976], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1620, "seek": 420816, "start": 4220.4, "end": 4223.24, "text": " Like I personally have done it successfully across a handful", "tokens": [50976, 1743, 286, 5665, 362, 1096, 309, 10727, 2108, 257, 16458, 51118], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1621, "seek": 420816, "start": 4223.24, "end": 4224.5599999999995, "text": " of different things.", "tokens": [51118, 295, 819, 721, 13, 51184], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1622, "seek": 420816, "start": 4224.5599999999995, "end": 4228.36, "text": " Why it seems like you're announced as though a sort of doesn't", "tokens": [51184, 1545, 309, 2544, 411, 291, 434, 7548, 382, 1673, 257, 1333, 295, 1177, 380, 51374], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1623, "seek": 420816, "start": 4229.32, "end": 4231.639999999999, "text": " assumes that that's not going to happen at scale this time", "tokens": [51422, 37808, 300, 300, 311, 406, 516, 281, 1051, 412, 4373, 341, 565, 51538], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1624, "seek": 420816, "start": 4231.639999999999, "end": 4234.04, "text": " around with the technology we currently have.", "tokens": [51538, 926, 365, 264, 2899, 321, 4362, 362, 13, 51658], "temperature": 0.0, "avg_logprob": -0.19620256686429366, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0038231967482715845}, {"id": 1625, "seek": 423404, "start": 4234.48, "end": 4239.24, "text": " I said, you know, in the last 20 years from 1999 to 2019,", "tokens": [50386, 286, 848, 11, 291, 458, 11, 294, 264, 1036, 945, 924, 490, 19952, 281, 6071, 11, 50624], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1626, "seek": 423404, "start": 4239.24, "end": 4241.72, "text": " we moved roughly a third of a standard deviation", "tokens": [50624, 321, 4259, 9810, 257, 2636, 295, 257, 3832, 25163, 50748], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1627, "seek": 423404, "start": 4241.72, "end": 4244.0, "text": " in the distribution of automation.", "tokens": [50748, 294, 264, 7316, 295, 17769, 13, 50862], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1628, "seek": 423404, "start": 4244.0, "end": 4247.64, "text": " OK, so what if we in the next 60 years", "tokens": [50862, 2264, 11, 370, 437, 498, 321, 294, 264, 958, 4060, 924, 51044], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1629, "seek": 423404, "start": 4248.4, "end": 4252.64, "text": " move a third of a standard deviation in each of the 20 year periods?", "tokens": [51082, 1286, 257, 2636, 295, 257, 3832, 25163, 294, 1184, 295, 264, 945, 1064, 13804, 30, 51294], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1630, "seek": 423404, "start": 4252.64, "end": 4255.76, "text": " Then over 60 years, we would basically move an entire standard deviation.", "tokens": [51294, 1396, 670, 4060, 924, 11, 321, 576, 1936, 1286, 364, 2302, 3832, 25163, 13, 51450], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1631, "seek": 423404, "start": 4256.88, "end": 4261.4, "text": " That could represent a large increase in automation", "tokens": [51506, 663, 727, 2906, 257, 2416, 3488, 294, 17769, 51732], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1632, "seek": 423404, "start": 4261.88, "end": 4264.0, "text": " over the next 60 years.", "tokens": [51756, 670, 264, 958, 4060, 924, 13, 51862], "temperature": 0.0, "avg_logprob": -0.15746466627398742, "compression_ratio": 1.8136363636363637, "no_speech_prob": 0.00048773555317893624}, {"id": 1633, "seek": 426400, "start": 4264.12, "end": 4267.04, "text": " And that would mean a lot of things we're doing by hand today", "tokens": [50370, 400, 300, 576, 914, 257, 688, 295, 721, 321, 434, 884, 538, 1011, 965, 50516], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1634, "seek": 426400, "start": 4267.04, "end": 4268.56, "text": " will be done by machines.", "tokens": [50516, 486, 312, 1096, 538, 8379, 13, 50592], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1635, "seek": 426400, "start": 4268.56, "end": 4271.24, "text": " Then it would mean our economy is more productive,", "tokens": [50592, 1396, 309, 576, 914, 527, 5010, 307, 544, 13304, 11, 50726], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1636, "seek": 426400, "start": 4271.84, "end": 4275.12, "text": " but it still would mean humans have a huge place in the world.", "tokens": [50756, 457, 309, 920, 576, 914, 6255, 362, 257, 2603, 1081, 294, 264, 1002, 13, 50920], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1637, "seek": 426400, "start": 4275.12, "end": 4279.24, "text": " They get paid and most income probably still goes to pay humans to do work,", "tokens": [50920, 814, 483, 4835, 293, 881, 5742, 1391, 920, 1709, 281, 1689, 6255, 281, 360, 589, 11, 51126], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1638, "seek": 426400, "start": 4279.88, "end": 4282.52, "text": " even though they have much better automation at the time.", "tokens": [51158, 754, 1673, 436, 362, 709, 1101, 17769, 412, 264, 565, 13, 51290], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1639, "seek": 426400, "start": 4283.28, "end": 4285.84, "text": " If that's the situation in 60 years,", "tokens": [51328, 759, 300, 311, 264, 2590, 294, 4060, 924, 11, 51456], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1640, "seek": 426400, "start": 4286.96, "end": 4290.32, "text": " then unfortunately that level of increase in automation", "tokens": [51512, 550, 7015, 300, 1496, 295, 3488, 294, 17769, 51680], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1641, "seek": 426400, "start": 4290.32, "end": 4292.48, "text": " is just not sufficient to prevent the economy", "tokens": [51680, 307, 445, 406, 11563, 281, 4871, 264, 5010, 51788], "temperature": 0.0, "avg_logprob": -0.11952921439861429, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.0002611291129142046}, {"id": 1642, "seek": 429248, "start": 4292.48, "end": 4295.2, "text": " from declining as population declines.", "tokens": [50364, 490, 34298, 382, 4415, 7488, 1652, 13, 50500], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1643, "seek": 429248, "start": 4295.2, "end": 4298.44, "text": " And so we won't get much more automation than that.", "tokens": [50500, 400, 370, 321, 1582, 380, 483, 709, 544, 17769, 813, 300, 13, 50662], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1644, "seek": 429248, "start": 4299.639999999999, "end": 4303.48, "text": " The well of it in automation will dry up because innovation will stop.", "tokens": [50722, 440, 731, 295, 309, 294, 17769, 486, 4016, 493, 570, 8504, 486, 1590, 13, 50914], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1645, "seek": 429248, "start": 4303.5199999999995, "end": 4306.04, "text": " And we would then have a several centuries long period", "tokens": [50916, 400, 321, 576, 550, 362, 257, 2940, 13926, 938, 2896, 51042], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1646, "seek": 429248, "start": 4306.04, "end": 4308.839999999999, "text": " where our technology does not improve.", "tokens": [51042, 689, 527, 2899, 775, 406, 3470, 13, 51182], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1647, "seek": 429248, "start": 4308.839999999999, "end": 4311.639999999999, "text": " And in fact, we lose a lot of technologies tied to scale economies", "tokens": [51182, 400, 294, 1186, 11, 321, 3624, 257, 688, 295, 7943, 9601, 281, 4373, 23158, 51322], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1648, "seek": 429248, "start": 4312.16, "end": 4314.48, "text": " as the world economy shrinks.", "tokens": [51348, 382, 264, 1002, 5010, 9884, 16431, 13, 51464], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1649, "seek": 429248, "start": 4314.48, "end": 4319.48, "text": " We'll manage to have less variety, less large scale production and distribution.", "tokens": [51464, 492, 603, 3067, 281, 362, 1570, 5673, 11, 1570, 2416, 4373, 4265, 293, 7316, 13, 51714], "temperature": 0.0, "avg_logprob": -0.18862735308133638, "compression_ratio": 1.678294573643411, "no_speech_prob": 0.000720494776032865}, {"id": 1650, "seek": 431948, "start": 4320.28, "end": 4323.879999999999, "text": " And we would then struggle to maintain previous technologies.", "tokens": [50404, 400, 321, 576, 550, 7799, 281, 6909, 3894, 7943, 13, 50584], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1651, "seek": 431948, "start": 4323.879999999999, "end": 4326.879999999999, "text": " And AI is at risk of the sort of technology would be hard to maintain", "tokens": [50584, 400, 7318, 307, 412, 3148, 295, 264, 1333, 295, 2899, 576, 312, 1152, 281, 6909, 50734], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1652, "seek": 431948, "start": 4326.879999999999, "end": 4330.919999999999, "text": " because at the moment, AI is a really large scale, concentrated sort of technology", "tokens": [50734, 570, 412, 264, 1623, 11, 7318, 307, 257, 534, 2416, 4373, 11, 21321, 1333, 295, 2899, 50936], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1653, "seek": 431948, "start": 4330.919999999999, "end": 4334.799999999999, "text": " is not being done by mom and pops to be done by very large enterprises", "tokens": [50936, 307, 406, 885, 1096, 538, 1225, 293, 16795, 281, 312, 1096, 538, 588, 2416, 29034, 51130], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1654, "seek": 431948, "start": 4334.799999999999, "end": 4336.24, "text": " on very large scales.", "tokens": [51130, 322, 588, 2416, 17408, 13, 51202], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1655, "seek": 431948, "start": 4336.24, "end": 4341.48, "text": " I would agree that the supply chain is definitely prone to disruption in AI.", "tokens": [51202, 286, 576, 3986, 300, 264, 5847, 5021, 307, 2138, 25806, 281, 28751, 294, 7318, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1656, "seek": 431948, "start": 4341.48, "end": 4342.839999999999, "text": " No doubt about that.", "tokens": [51464, 883, 6385, 466, 300, 13, 51532], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1657, "seek": 431948, "start": 4342.839999999999, "end": 4347.839999999999, "text": " Can you describe in more detail what what is the standard deviation", "tokens": [51532, 1664, 291, 6786, 294, 544, 2607, 437, 437, 307, 264, 3832, 25163, 51782], "temperature": 0.0, "avg_logprob": -0.13875177744272593, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.0019257899839431047}, {"id": 1658, "seek": 434784, "start": 4347.84, "end": 4350.88, "text": " in automation and how should I conceptualize that?", "tokens": [50364, 294, 17769, 293, 577, 820, 286, 24106, 1125, 300, 30, 50516], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1659, "seek": 434784, "start": 4351.4400000000005, "end": 4354.76, "text": " I mean, I guess what you'd want to do is see a list of tasks", "tokens": [50544, 286, 914, 11, 286, 2041, 437, 291, 1116, 528, 281, 360, 307, 536, 257, 1329, 295, 9608, 50710], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1660, "seek": 434784, "start": 4354.76, "end": 4362.24, "text": " and how automated each task was and then see sort of how much on that score.", "tokens": [50710, 293, 577, 18473, 1184, 5633, 390, 293, 550, 536, 1333, 295, 577, 709, 322, 300, 6175, 13, 51084], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1661, "seek": 434784, "start": 4362.24, "end": 4365.08, "text": " And it would have. So basically, if you look on this list", "tokens": [51084, 400, 309, 576, 362, 13, 407, 1936, 11, 498, 291, 574, 322, 341, 1329, 51226], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1662, "seek": 434784, "start": 4365.08, "end": 4368.16, "text": " at the most and least automated tasks, you'll agree, which are which", "tokens": [51226, 412, 264, 881, 293, 1935, 18473, 9608, 11, 291, 603, 3986, 11, 597, 366, 597, 51380], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1663, "seek": 434784, "start": 4368.88, "end": 4372.32, "text": " like the nearly most automated task is airline pilots.", "tokens": [51416, 411, 264, 6217, 881, 18473, 5633, 307, 29528, 21506, 13, 51588], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1664, "seek": 434784, "start": 4373.32, "end": 4376.32, "text": " Nearly the least automated task is carpet installers.", "tokens": [51638, 38000, 264, 1935, 18473, 5633, 307, 18119, 3625, 433, 13, 51788], "temperature": 0.0, "avg_logprob": -0.20125291106897755, "compression_ratio": 1.7520661157024793, "no_speech_prob": 0.0034789510536938906}, {"id": 1665, "seek": 437632, "start": 4377.32, "end": 4382.04, "text": " Carpet installers use pretty much no automation to staple in carpets.", "tokens": [50414, 2741, 7275, 3625, 433, 764, 1238, 709, 572, 17769, 281, 32361, 294, 26103, 1385, 13, 50650], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1666, "seek": 437632, "start": 4382.04, "end": 4387.32, "text": " And airline pilots are pretty much always having automation help what they're doing.", "tokens": [50650, 400, 29528, 21506, 366, 1238, 709, 1009, 1419, 17769, 854, 437, 436, 434, 884, 13, 50914], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1667, "seek": 437632, "start": 4388.12, "end": 4392.32, "text": " And then, you know, you can see the scores in the middle and see that we've,", "tokens": [50954, 400, 550, 11, 291, 458, 11, 291, 393, 536, 264, 13444, 294, 264, 2808, 293, 536, 300, 321, 600, 11, 51164], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1668, "seek": 437632, "start": 4392.32, "end": 4395.28, "text": " you know, moved up a modest degree over those 20 years.", "tokens": [51164, 291, 458, 11, 4259, 493, 257, 25403, 4314, 670, 729, 945, 924, 13, 51312], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1669, "seek": 437632, "start": 4395.799999999999, "end": 4398.92, "text": " That would be the way to get an intuition for it is just to see a list", "tokens": [51338, 663, 576, 312, 264, 636, 281, 483, 364, 24002, 337, 309, 307, 445, 281, 536, 257, 1329, 51494], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1670, "seek": 437632, "start": 4398.92, "end": 4402.719999999999, "text": " of particular jobs in their automation scores and then see,", "tokens": [51494, 295, 1729, 4782, 294, 641, 17769, 13444, 293, 550, 536, 11, 51684], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1671, "seek": 437632, "start": 4402.719999999999, "end": 4404.96, "text": " compare that to the amount by which we've moved up.", "tokens": [51684, 6794, 300, 281, 264, 2372, 538, 597, 321, 600, 4259, 493, 13, 51796], "temperature": 0.0, "avg_logprob": -0.19004890698344767, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0004877852334175259}, {"id": 1672, "seek": 440496, "start": 4405.68, "end": 4406.64, "text": " How do you reconcile?", "tokens": [50400, 1012, 360, 291, 41059, 30, 50448], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1673, "seek": 440496, "start": 4406.64, "end": 4411.32, "text": " Or how should I understand the idea that", "tokens": [50448, 1610, 577, 820, 286, 1223, 264, 1558, 300, 50682], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1674, "seek": 440496, "start": 4411.72, "end": 4414.56, "text": " whatever doubling time of the economy today,", "tokens": [50702, 2035, 33651, 565, 295, 264, 5010, 965, 11, 50844], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1675, "seek": 440496, "start": 4414.84, "end": 4417.4800000000005, "text": " I think you said it was like 15 years in the book,", "tokens": [50858, 286, 519, 291, 848, 309, 390, 411, 2119, 924, 294, 264, 1446, 11, 50990], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1676, "seek": 440496, "start": 4417.4800000000005, "end": 4420.8, "text": " which seemed a little fast to me, just based on like rule of 70.", "tokens": [50990, 597, 6576, 257, 707, 2370, 281, 385, 11, 445, 2361, 322, 411, 4978, 295, 5285, 13, 51156], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1677, "seek": 440496, "start": 4421.36, "end": 4424.08, "text": " Right. I think it's more like, you know, 20 or something now.", "tokens": [51184, 1779, 13, 286, 519, 309, 311, 544, 411, 11, 291, 458, 11, 945, 420, 746, 586, 13, 51320], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1678, "seek": 440496, "start": 4424.32, "end": 4427.92, "text": " But still, like it seems it seems like there's a little bit of a disconnect", "tokens": [51332, 583, 920, 11, 411, 309, 2544, 309, 2544, 411, 456, 311, 257, 707, 857, 295, 257, 14299, 51512], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1679, "seek": 440496, "start": 4427.92, "end": 4432.92, "text": " between a notion of, you know, over these next 60 years,", "tokens": [51512, 1296, 257, 10710, 295, 11, 291, 458, 11, 670, 613, 958, 4060, 924, 11, 51762], "temperature": 0.0, "avg_logprob": -0.15233031634626717, "compression_ratio": 1.613899613899614, "no_speech_prob": 0.0005357288173399866}, {"id": 1680, "seek": 443292, "start": 4432.92, "end": 4437.28, "text": " we would be double, double, double, you know, essentially 10xing the economy.", "tokens": [50364, 321, 576, 312, 3834, 11, 3834, 11, 3834, 11, 291, 458, 11, 4476, 1266, 87, 278, 264, 5010, 13, 50582], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1681, "seek": 443292, "start": 4437.68, "end": 4442.6, "text": " But we'd only move at sort of a linear rate in automation.", "tokens": [50602, 583, 321, 1116, 787, 1286, 412, 1333, 295, 257, 8213, 3314, 294, 17769, 13, 50848], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1682, "seek": 443292, "start": 4442.6, "end": 4446.24, "text": " Like we would only move a third of a standard deviation in each period.", "tokens": [50848, 1743, 321, 576, 787, 1286, 257, 2636, 295, 257, 3832, 25163, 294, 1184, 2896, 13, 51030], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1683, "seek": 443292, "start": 4446.4800000000005, "end": 4448.08, "text": " Let me help you understand that then.", "tokens": [51042, 961, 385, 854, 291, 1223, 300, 550, 13, 51122], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1684, "seek": 443292, "start": 4448.08, "end": 4452.24, "text": " People have often said, look, computer technology is increasing exponentially.", "tokens": [51122, 3432, 362, 2049, 848, 11, 574, 11, 3820, 2899, 307, 5662, 37330, 13, 51330], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1685, "seek": 443292, "start": 4452.64, "end": 4456.4, "text": " Therefore, we should expect an exponential impact on the economy,", "tokens": [51350, 7504, 11, 321, 820, 2066, 364, 21510, 2712, 322, 264, 5010, 11, 51538], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1686, "seek": 443292, "start": 4456.4, "end": 4461.08, "text": " i.e. early on hardly any impact, and then suddenly an accelerating boom", "tokens": [51538, 741, 13, 68, 13, 2440, 322, 13572, 604, 2712, 11, 293, 550, 5800, 364, 34391, 9351, 51772], "temperature": 0.0, "avg_logprob": -0.14255969292294662, "compression_ratio": 1.7022058823529411, "no_speech_prob": 0.0004044160305056721}, {"id": 1687, "seek": 446108, "start": 4461.12, "end": 4464.36, "text": " such that we get this big explosion and then everything happens.", "tokens": [50366, 1270, 300, 321, 483, 341, 955, 15673, 293, 550, 1203, 2314, 13, 50528], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1688, "seek": 446108, "start": 4464.5599999999995, "end": 4466.04, "text": " But that's not what we've seen.", "tokens": [50538, 583, 300, 311, 406, 437, 321, 600, 1612, 13, 50612], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1689, "seek": 446108, "start": 4466.04, "end": 4471.76, "text": " So what we've seen over time is relatively steady effects on the economy of automation,", "tokens": [50612, 407, 437, 321, 600, 1612, 670, 565, 307, 7226, 13211, 5065, 322, 264, 5010, 295, 17769, 11, 50898], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1690, "seek": 446108, "start": 4471.76, "end": 4474.64, "text": " even though the economy is growing exponentially.", "tokens": [50898, 754, 1673, 264, 5010, 307, 4194, 37330, 13, 51042], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1691, "seek": 446108, "start": 4475.84, "end": 4480.92, "text": " The way I help you understand that is to imagine the distribution of all tasks", "tokens": [51102, 440, 636, 286, 854, 291, 1223, 300, 307, 281, 3811, 264, 7316, 295, 439, 9608, 51356], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1692, "seek": 446108, "start": 4480.92, "end": 4484.76, "text": " that you might want automated and that they're the degree of computing power,", "tokens": [51356, 300, 291, 1062, 528, 18473, 293, 300, 436, 434, 264, 4314, 295, 15866, 1347, 11, 51548], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1693, "seek": 446108, "start": 4484.88, "end": 4489.12, "text": " both in hardware and software, required to automate that task for each task", "tokens": [51554, 1293, 294, 8837, 293, 4722, 11, 4739, 281, 31605, 300, 5633, 337, 1184, 5633, 51766], "temperature": 0.0, "avg_logprob": -0.1474657508562196, "compression_ratio": 1.7043795620437956, "no_speech_prob": 0.0003799305413849652}, {"id": 1694, "seek": 448912, "start": 4489.16, "end": 4493.32, "text": " is distributed in a log normal way with a very large variance.", "tokens": [50366, 307, 12631, 294, 257, 3565, 2710, 636, 365, 257, 588, 2416, 21977, 13, 50574], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1695, "seek": 448912, "start": 4493.48, "end": 4498.04, "text": " That is, there's a very large range of how much computing power it takes to automate a task.", "tokens": [50582, 663, 307, 11, 456, 311, 257, 588, 2416, 3613, 295, 577, 709, 15866, 1347, 309, 2516, 281, 31605, 257, 5633, 13, 50810], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1696, "seek": 448912, "start": 4498.36, "end": 4500.5599999999995, "text": " As computing power increases exponentially,", "tokens": [50826, 1018, 15866, 1347, 8637, 37330, 11, 50936], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1697, "seek": 448912, "start": 4500.5599999999995, "end": 4504.32, "text": " you're basically moving through that log normal distribution in a linear manner.", "tokens": [50936, 291, 434, 1936, 2684, 807, 300, 3565, 2710, 7316, 294, 257, 8213, 9060, 13, 51124], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1698, "seek": 448912, "start": 4504.72, "end": 4507.96, "text": " And in the middle of the distribution, it's pretty steady effect.", "tokens": [51144, 400, 294, 264, 2808, 295, 264, 7316, 11, 309, 311, 1238, 13211, 1802, 13, 51306], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1699, "seek": 448912, "start": 4508.599999999999, "end": 4512.88, "text": " You slowly chop away at tasks as you are able to automate them", "tokens": [51338, 509, 5692, 7931, 1314, 412, 9608, 382, 291, 366, 1075, 281, 31605, 552, 51552], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1700, "seek": 448912, "start": 4513.44, "end": 4518.5199999999995, "text": " because you're slowly acquiring sufficient hardware to do that task.", "tokens": [51580, 570, 291, 434, 5692, 37374, 11563, 8837, 281, 360, 300, 5633, 13, 51834], "temperature": 0.0, "avg_logprob": -0.14773719399063676, "compression_ratio": 1.7445255474452555, "no_speech_prob": 0.0012838718248531222}, {"id": 1701, "seek": 451912, "start": 4519.28, "end": 4521.84, "text": " That that gives you a simple model, but in which", "tokens": [50372, 663, 300, 2709, 291, 257, 2199, 2316, 11, 457, 294, 597, 50500], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1702, "seek": 451912, "start": 4522.96, "end": 4525.08, "text": " computing power grows exponentially.", "tokens": [50556, 15866, 1347, 13156, 37330, 13, 50662], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1703, "seek": 451912, "start": 4525.08, "end": 4529.8, "text": " And yet you see a relatively steady erosion of tasks through automation.", "tokens": [50662, 400, 1939, 291, 536, 257, 7226, 13211, 32173, 295, 9608, 807, 17769, 13, 50898], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1704, "seek": 451912, "start": 4530.16, "end": 4532.32, "text": " It's a low hanging fruit argument.", "tokens": [50916, 467, 311, 257, 2295, 8345, 6773, 6770, 13, 51024], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1705, "seek": 451912, "start": 4532.32, "end": 4535.04, "text": " Yeah, the low hanging fruits are hanging really low.", "tokens": [51024, 865, 11, 264, 2295, 8345, 12148, 366, 8345, 534, 2295, 13, 51160], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1706, "seek": 451912, "start": 4535.72, "end": 4540.04, "text": " That this this is a log normal tree, basically, that you're trying to grab things from.", "tokens": [51194, 663, 341, 341, 307, 257, 3565, 2710, 4230, 11, 1936, 11, 300, 291, 434, 1382, 281, 4444, 721, 490, 13, 51410], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1707, "seek": 451912, "start": 4540.04, "end": 4543.04, "text": " I mean, you're growing your ladder is growing exponentially into the tree.", "tokens": [51410, 286, 914, 11, 291, 434, 4194, 428, 18325, 307, 4194, 37330, 666, 264, 4230, 13, 51560], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1708, "seek": 451912, "start": 4543.36, "end": 4546.2, "text": " And every time your ladder gets taller, you get to pick more feuds.", "tokens": [51576, 400, 633, 565, 428, 18325, 2170, 22406, 11, 291, 483, 281, 1888, 544, 579, 32083, 13, 51718], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1709, "seek": 451912, "start": 4546.2, "end": 4547.88, "text": " But it's a really tall tree.", "tokens": [51718, 583, 309, 311, 257, 534, 6764, 4230, 13, 51802], "temperature": 0.0, "avg_logprob": -0.15919134185070127, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.00016343180323019624}, {"id": 1710, "seek": 454788, "start": 4547.92, "end": 4550.08, "text": " That means that you have a long, long way to go.", "tokens": [50366, 663, 1355, 300, 291, 362, 257, 938, 11, 938, 636, 281, 352, 13, 50474], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1711, "seek": 454788, "start": 4550.92, "end": 4555.68, "text": " How do you think about things like the progress in AI art generation", "tokens": [50516, 1012, 360, 291, 519, 466, 721, 411, 264, 4205, 294, 7318, 1523, 5125, 50754], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1712, "seek": 454788, "start": 4555.68, "end": 4558.52, "text": " or like deep fakes over the last couple of years?", "tokens": [50754, 420, 411, 2452, 283, 3419, 670, 264, 1036, 1916, 295, 924, 30, 50896], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1713, "seek": 454788, "start": 4558.52, "end": 4564.400000000001, "text": " This is an area where I feel like if we rewound to two years ago,", "tokens": [50896, 639, 307, 364, 1859, 689, 286, 841, 411, 498, 321, 319, 86, 554, 281, 732, 924, 2057, 11, 51190], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1714, "seek": 454788, "start": 4564.72, "end": 4569.08, "text": " just two years ago, really, when I was first starting to see AI art", "tokens": [51206, 445, 732, 924, 2057, 11, 534, 11, 562, 286, 390, 700, 2891, 281, 536, 7318, 1523, 51424], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1715, "seek": 454788, "start": 4569.72, "end": 4572.2, "text": " popping up on Twitter and it was like", "tokens": [51456, 18374, 493, 322, 5794, 293, 309, 390, 411, 51580], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1716, "seek": 454788, "start": 4573.2, "end": 4576.36, "text": " not very good for the most part, you'd see the occasional thing where you're like,", "tokens": [51630, 406, 588, 665, 337, 264, 881, 644, 11, 291, 1116, 536, 264, 31644, 551, 689, 291, 434, 411, 11, 51788], "temperature": 0.0, "avg_logprob": -0.11882719786270805, "compression_ratio": 1.6746031746031746, "no_speech_prob": 0.00022338367125485092}, {"id": 1717, "seek": 457636, "start": 4576.36, "end": 4577.36, "text": " oh, that's really compelling.", "tokens": [50364, 1954, 11, 300, 311, 534, 20050, 13, 50414], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1718, "seek": 457636, "start": 4577.36, "end": 4580.799999999999, "text": " And then you'd see a lot of stuff that was like, yeah, you know, it's whatever.", "tokens": [50414, 400, 550, 291, 1116, 536, 257, 688, 295, 1507, 300, 390, 411, 11, 1338, 11, 291, 458, 11, 309, 311, 2035, 13, 50586], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1719, "seek": 457636, "start": 4580.799999999999, "end": 4582.679999999999, "text": " It's it's remarkable that you can do that.", "tokens": [50586, 467, 311, 309, 311, 12802, 300, 291, 393, 360, 300, 13, 50680], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1720, "seek": 457636, "start": 4583.28, "end": 4587.5199999999995, "text": " It's a while compared to what came before, but it, you know, it's like", "tokens": [50710, 467, 311, 257, 1339, 5347, 281, 437, 1361, 949, 11, 457, 309, 11, 291, 458, 11, 309, 311, 411, 50922], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1721, "seek": 457636, "start": 4588.92, "end": 4592.679999999999, "text": " I'm not going to be watching like feature films based on this technology", "tokens": [50992, 286, 478, 406, 516, 281, 312, 1976, 411, 4111, 7796, 2361, 322, 341, 2899, 51180], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1722, "seek": 457636, "start": 4592.679999999999, "end": 4594.88, "text": " and, you know, in the immediate future.", "tokens": [51180, 293, 11, 291, 458, 11, 294, 264, 11629, 2027, 13, 51290], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1723, "seek": 457636, "start": 4594.88, "end": 4598.32, "text": " I feel like we could have had a very similar discussion where you might say,", "tokens": [51290, 286, 841, 411, 321, 727, 362, 632, 257, 588, 2531, 5017, 689, 291, 1062, 584, 11, 51462], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1724, "seek": 457636, "start": 4598.32, "end": 4600.44, "text": " well, you know, yeah, it's progress.", "tokens": [51462, 731, 11, 291, 458, 11, 1338, 11, 309, 311, 4205, 13, 51568], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1725, "seek": 457636, "start": 4600.44, "end": 4605.36, "text": " But, you know, the real human art, the top notch stuff, like that's so far away.", "tokens": [51568, 583, 11, 291, 458, 11, 264, 957, 1952, 1523, 11, 264, 1192, 26109, 1507, 11, 411, 300, 311, 370, 1400, 1314, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12767996286091052, "compression_ratio": 1.7818791946308725, "no_speech_prob": 0.0008557036053389311}, {"id": 1726, "seek": 460536, "start": 4605.799999999999, "end": 4610.679999999999, "text": " And then early last year, my teammates at Waymark made a short film", "tokens": [50386, 400, 550, 2440, 1036, 1064, 11, 452, 20461, 412, 9558, 5638, 1027, 257, 2099, 2007, 50630], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1727, "seek": 460536, "start": 4610.679999999999, "end": 4617.12, "text": " using nothing but Dolly 2 at that time imagery and some definite elbow grease.", "tokens": [50630, 1228, 1825, 457, 1144, 13020, 568, 412, 300, 565, 24340, 293, 512, 25131, 18507, 24867, 13, 50952], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1728, "seek": 460536, "start": 4617.12, "end": 4619.599999999999, "text": " But like the quality of production that they were able to achieve", "tokens": [50952, 583, 411, 264, 3125, 295, 4265, 300, 436, 645, 1075, 281, 4584, 51076], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1729, "seek": 460536, "start": 4619.88, "end": 4625.28, "text": " with a half dozen people and Dolly 2 is on the level that like previously", "tokens": [51090, 365, 257, 1922, 16654, 561, 293, 1144, 13020, 568, 307, 322, 264, 1496, 300, 411, 8046, 51360], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1730, "seek": 460536, "start": 4625.28, "end": 4629.16, "text": " would have taken, you know, a crew in Antarctica, you know, to go shoot.", "tokens": [51360, 576, 362, 2726, 11, 291, 458, 11, 257, 7260, 294, 39866, 11, 291, 458, 11, 281, 352, 3076, 13, 51554], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1731, "seek": 460536, "start": 4629.88, "end": 4632.04, "text": " You know, again, is that work all done?", "tokens": [51590, 509, 458, 11, 797, 11, 307, 300, 589, 439, 1096, 30, 51698], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1732, "seek": 460536, "start": 4632.04, "end": 4635.2, "text": " No. But if you look at the mid journey outputs today,", "tokens": [51698, 883, 13, 583, 498, 291, 574, 412, 264, 2062, 4671, 23930, 965, 11, 51856], "temperature": 0.0, "avg_logprob": -0.16506759190963485, "compression_ratio": 1.6007067137809188, "no_speech_prob": 0.0007552513852715492}, {"id": 1733, "seek": 463520, "start": 4635.24, "end": 4637.8, "text": " you look at some of the deep fake technologies that are happening today.", "tokens": [50366, 291, 574, 412, 512, 295, 264, 2452, 7592, 7943, 300, 366, 2737, 965, 13, 50494], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1734, "seek": 463520, "start": 4637.8, "end": 4640.32, "text": " It's like it does feel like we've hit certainly", "tokens": [50494, 467, 311, 411, 309, 775, 841, 411, 321, 600, 2045, 3297, 50620], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1735, "seek": 463520, "start": 4640.32, "end": 4643.599999999999, "text": " photo realistic thresholds, you know, almost indistinguishable", "tokens": [50620, 5052, 12465, 14678, 82, 11, 291, 458, 11, 1920, 1016, 468, 7050, 742, 712, 50784], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1736, "seek": 463520, "start": 4643.96, "end": 4646.96, "text": " from photography with mid journey and with the deep fakes.", "tokens": [50802, 490, 13865, 365, 2062, 4671, 293, 365, 264, 2452, 283, 3419, 13, 50952], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1737, "seek": 463520, "start": 4647.44, "end": 4650.8, "text": " You're not quite quite there yet, but like watch out for 2024", "tokens": [50976, 509, 434, 406, 1596, 1596, 456, 1939, 11, 457, 411, 1159, 484, 337, 45237, 51144], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1738, "seek": 463520, "start": 4650.84, "end": 4657.28, "text": " to have a lot of stories of people being scammed by the kind of custom", "tokens": [51146, 281, 362, 257, 688, 295, 3676, 295, 561, 885, 795, 19859, 538, 264, 733, 295, 2375, 51468], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1739, "seek": 463520, "start": 4657.28, "end": 4660.92, "text": " text to speech voice, you know, with a family member, family members voice, whatever.", "tokens": [51468, 2487, 281, 6218, 3177, 11, 291, 458, 11, 365, 257, 1605, 4006, 11, 1605, 2679, 3177, 11, 2035, 13, 51650], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1740, "seek": 463520, "start": 4661.12, "end": 4664.12, "text": " All my voice out there, you know, people are going to be calling my parents with my voice.", "tokens": [51660, 1057, 452, 3177, 484, 456, 11, 291, 458, 11, 561, 366, 516, 281, 312, 5141, 452, 3152, 365, 452, 3177, 13, 51810], "temperature": 0.0, "avg_logprob": -0.1638985915149716, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0006665558321401477}, {"id": 1741, "seek": 466412, "start": 4664.64, "end": 4668.24, "text": " So I guess what I'm trying to get at there is like it seems like even just", "tokens": [50390, 407, 286, 2041, 437, 286, 478, 1382, 281, 483, 412, 456, 307, 411, 309, 2544, 411, 754, 445, 50570], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1742, "seek": 466412, "start": 4668.24, "end": 4672.72, "text": " in the last couple of years, we have these examples where we are seeing", "tokens": [50570, 294, 264, 1036, 1916, 295, 924, 11, 321, 362, 613, 5110, 689, 321, 366, 2577, 50794], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1743, "seek": 466412, "start": 4672.72, "end": 4679.44, "text": " like really rapid progress that is not stopping before critical thresholds.", "tokens": [50794, 411, 534, 7558, 4205, 300, 307, 406, 12767, 949, 4924, 14678, 82, 13, 51130], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1744, "seek": 466412, "start": 4679.96, "end": 4683.2, "text": " In the 1960s, there was a U.S.", "tokens": [51156, 682, 264, 16157, 82, 11, 456, 390, 257, 624, 13, 50, 13, 51318], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1745, "seek": 466412, "start": 4683.2, "end": 4687.96, "text": " Presidential Commission to to address and study the question", "tokens": [51318, 41823, 10766, 281, 281, 2985, 293, 2979, 264, 1168, 51556], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1746, "seek": 466412, "start": 4687.96, "end": 4690.04, "text": " of whether most jobs were about to be automated.", "tokens": [51556, 295, 1968, 881, 4782, 645, 466, 281, 312, 18473, 13, 51660], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1747, "seek": 466412, "start": 4690.04, "end": 4693.44, "text": " It reached that level of high level concern in the country.", "tokens": [51660, 467, 6488, 300, 1496, 295, 1090, 1496, 3136, 294, 264, 1941, 13, 51830], "temperature": 0.0, "avg_logprob": -0.15599813915434338, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0011692180996760726}, {"id": 1748, "seek": 469344, "start": 4693.48, "end": 4695.799999999999, "text": " And major media discussion about it.", "tokens": [50366, 400, 2563, 3021, 5017, 466, 309, 13, 50482], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1749, "seek": 469344, "start": 4697.28, "end": 4701.839999999999, "text": " Ever since then, we continue to have periodic articles about dramatic,", "tokens": [50556, 12123, 1670, 550, 11, 321, 2354, 281, 362, 27790, 11290, 466, 12023, 11, 50784], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1750, "seek": 469344, "start": 4702.04, "end": 4706.96, "text": " exciting progress in AI and what that might mean for the society and economy.", "tokens": [50794, 4670, 4205, 294, 7318, 293, 437, 300, 1062, 914, 337, 264, 4086, 293, 5010, 13, 51040], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1751, "seek": 469344, "start": 4707.24, "end": 4710.28, "text": " And in all those articles through all those years,", "tokens": [51054, 400, 294, 439, 729, 11290, 807, 439, 729, 924, 11, 51206], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1752, "seek": 469344, "start": 4710.96, "end": 4714.5599999999995, "text": " they don't just talk in the abstract, they usually pick out some particular examples", "tokens": [51240, 436, 500, 380, 445, 751, 294, 264, 12649, 11, 436, 2673, 1888, 484, 512, 1729, 5110, 51420], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1753, "seek": 469344, "start": 4715.04, "end": 4717.44, "text": " and they don't pick out random examples from the economy.", "tokens": [51444, 293, 436, 500, 380, 1888, 484, 4974, 5110, 490, 264, 5010, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1754, "seek": 469344, "start": 4717.44, "end": 4720.5199999999995, "text": " They pick out the examples where the automation has made the most difference.", "tokens": [51564, 814, 1888, 484, 264, 5110, 689, 264, 17769, 575, 1027, 264, 881, 2649, 13, 51718], "temperature": 0.0, "avg_logprob": -0.12824277970397358, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0008557022665627301}, {"id": 1755, "seek": 472052, "start": 4721.52, "end": 4724.360000000001, "text": " That, of course, makes sense if you're trying to make an exciting story.", "tokens": [50414, 663, 11, 295, 1164, 11, 1669, 2020, 498, 291, 434, 1382, 281, 652, 364, 4670, 1657, 13, 50556], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1756, "seek": 472052, "start": 4725.64, "end": 4729.160000000001, "text": " And so we've always been able to pick out the things", "tokens": [50620, 400, 370, 321, 600, 1009, 668, 1075, 281, 1888, 484, 264, 721, 50796], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1757, "seek": 472052, "start": 4729.160000000001, "end": 4731.72, "text": " which are having the most dramatic increase lately", "tokens": [50796, 597, 366, 1419, 264, 881, 12023, 3488, 12881, 50924], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1758, "seek": 472052, "start": 4731.72, "end": 4734.280000000001, "text": " that also seem the most salient and interesting.", "tokens": [50924, 300, 611, 1643, 264, 881, 1845, 1196, 293, 1880, 13, 51052], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1759, "seek": 472052, "start": 4734.4400000000005, "end": 4737.68, "text": " And now you can pick out image generation", "tokens": [51060, 400, 586, 291, 393, 1888, 484, 3256, 5125, 51222], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1760, "seek": 472052, "start": 4738.320000000001, "end": 4742.52, "text": " as one of the main examples lately as something that's increased a lot lately.", "tokens": [51254, 382, 472, 295, 264, 2135, 5110, 12881, 382, 746, 300, 311, 6505, 257, 688, 12881, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1761, "seek": 472052, "start": 4742.8, "end": 4745.200000000001, "text": " And I'm happy to admit it has.", "tokens": [51478, 400, 286, 478, 2055, 281, 9796, 309, 575, 13, 51598], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1762, "seek": 472052, "start": 4745.200000000001, "end": 4747.6, "text": " I would put it up, you know, and that's the sort of thing", "tokens": [51598, 286, 576, 829, 309, 493, 11, 291, 458, 11, 293, 300, 311, 264, 1333, 295, 551, 51718], "temperature": 0.0, "avg_logprob": -0.12682892983419852, "compression_ratio": 1.6926070038910506, "no_speech_prob": 0.001206470769830048}, {"id": 1763, "seek": 474760, "start": 4747.64, "end": 4750.64, "text": " that somebody writing an article today about the exciting AI progress", "tokens": [50366, 300, 2618, 3579, 364, 7222, 965, 466, 264, 4670, 7318, 4205, 50516], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1764, "seek": 474760, "start": 4750.64, "end": 4754.68, "text": " would, in fact, mention and talk about graphic artists being put out of work", "tokens": [50516, 576, 11, 294, 1186, 11, 2152, 293, 751, 466, 14089, 6910, 885, 829, 484, 295, 589, 50718], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1765, "seek": 474760, "start": 4754.68, "end": 4758.52, "text": " by the availability of these things, which probably is happening.", "tokens": [50718, 538, 264, 17945, 295, 613, 721, 11, 597, 1391, 307, 2737, 13, 50910], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1766, "seek": 474760, "start": 4759.04, "end": 4762.8, "text": " The point is just to realize how selective that process is", "tokens": [50936, 440, 935, 307, 445, 281, 4325, 577, 33930, 300, 1399, 307, 51124], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1767, "seek": 474760, "start": 4763.04, "end": 4766.320000000001, "text": " to pick out the most dramatic impacts and to realize just how many other jobs", "tokens": [51136, 281, 1888, 484, 264, 881, 12023, 11606, 293, 281, 4325, 445, 577, 867, 661, 4782, 51300], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1768, "seek": 474760, "start": 4766.320000000001, "end": 4770.200000000001, "text": " there are and how many other tasks there are and then how far we still have to go.", "tokens": [51300, 456, 366, 293, 577, 867, 661, 9608, 456, 366, 293, 550, 577, 1400, 321, 920, 362, 281, 352, 13, 51494], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1769, "seek": 474760, "start": 4770.84, "end": 4773.4400000000005, "text": " I'm happy to celebrate recent progress.", "tokens": [51526, 286, 478, 2055, 281, 8098, 5162, 4205, 13, 51656], "temperature": 0.0, "avg_logprob": -0.11290194370128491, "compression_ratio": 1.710144927536232, "no_speech_prob": 0.0013246148591861129}, {"id": 1770, "seek": 477344, "start": 4773.44, "end": 4777.639999999999, "text": " And if I were, you know, if I were a graphic artist person,", "tokens": [50364, 400, 498, 286, 645, 11, 291, 458, 11, 498, 286, 645, 257, 14089, 5748, 954, 11, 50574], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1771, "seek": 477344, "start": 4777.639999999999, "end": 4781.04, "text": " I would be especially excited to figure out how to take advantage of these changes", "tokens": [50574, 286, 576, 312, 2318, 2919, 281, 2573, 484, 577, 281, 747, 5002, 295, 613, 2962, 50744], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1772, "seek": 477344, "start": 4781.5599999999995, "end": 4784.24, "text": " because they are among the biggest change.", "tokens": [50770, 570, 436, 366, 3654, 264, 3880, 1319, 13, 50904], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1773, "seek": 477344, "start": 4784.5199999999995, "end": 4786.5199999999995, "text": " If you're, say, a 20 year old in the world,", "tokens": [50918, 759, 291, 434, 11, 584, 11, 257, 945, 1064, 1331, 294, 264, 1002, 11, 51018], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1774, "seek": 477344, "start": 4786.5199999999995, "end": 4789.919999999999, "text": " it makes complete sense to say, where are things most exciting and changing?", "tokens": [51018, 309, 1669, 3566, 2020, 281, 584, 11, 689, 366, 721, 881, 4670, 293, 4473, 30, 51188], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1775, "seek": 477344, "start": 4790.04, "end": 4793.28, "text": " I want to go there and be part of the new exciting thing happening there.", "tokens": [51194, 286, 528, 281, 352, 456, 293, 312, 644, 295, 264, 777, 4670, 551, 2737, 456, 13, 51356], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1776, "seek": 477344, "start": 4793.96, "end": 4797.2, "text": " If, of course, you're a 60 year old and you've already invested in a career,", "tokens": [51390, 759, 11, 295, 1164, 11, 291, 434, 257, 4060, 1064, 1331, 293, 291, 600, 1217, 13104, 294, 257, 3988, 11, 51552], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1777, "seek": 477344, "start": 4797.2, "end": 4800.879999999999, "text": " then it makes less sense to, like, try to switch your whole career over to a new thing.", "tokens": [51552, 550, 309, 1669, 1570, 2020, 281, 11, 411, 11, 853, 281, 3679, 428, 1379, 3988, 670, 281, 257, 777, 551, 13, 51736], "temperature": 0.0, "avg_logprob": -0.10939665440912846, "compression_ratio": 1.7694805194805194, "no_speech_prob": 0.0033757409546524286}, {"id": 1778, "seek": 480088, "start": 4800.92, "end": 4803.52, "text": " But a lot of people are at the beginning of their career and they should.", "tokens": [50366, 583, 257, 688, 295, 561, 366, 412, 264, 2863, 295, 641, 3988, 293, 436, 820, 13, 50496], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1779, "seek": 480088, "start": 4803.84, "end": 4806.16, "text": " They should look for where the most exciting changes are", "tokens": [50512, 814, 820, 574, 337, 689, 264, 881, 4670, 2962, 366, 50628], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1780, "seek": 480088, "start": 4806.16, "end": 4808.400000000001, "text": " and try to see if they can go be part of that.", "tokens": [50628, 293, 853, 281, 536, 498, 436, 393, 352, 312, 644, 295, 300, 13, 50740], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1781, "seek": 480088, "start": 4808.96, "end": 4810.04, "text": " Move West, young man.", "tokens": [50768, 10475, 4055, 11, 2037, 587, 13, 50822], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1782, "seek": 480088, "start": 4810.04, "end": 4811.92, "text": " If West is where things are happening, right?", "tokens": [50822, 759, 4055, 307, 689, 721, 366, 2737, 11, 558, 30, 50916], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1783, "seek": 480088, "start": 4811.92, "end": 4814.6, "text": " But you still have to keep in mind if there's a few people going out West", "tokens": [50916, 583, 291, 920, 362, 281, 1066, 294, 1575, 498, 456, 311, 257, 1326, 561, 516, 484, 4055, 51050], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1784, "seek": 480088, "start": 4814.6, "end": 4818.76, "text": " making exciting things happening, how big a percentage of the world is the West, right?", "tokens": [51050, 1455, 4670, 721, 2737, 11, 577, 955, 257, 9668, 295, 264, 1002, 307, 264, 4055, 11, 558, 30, 51258], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1785, "seek": 480088, "start": 4819.52, "end": 4822.32, "text": " Yes, it's exciting and there's huge growth in the West.", "tokens": [51296, 1079, 11, 309, 311, 4670, 293, 456, 311, 2603, 4599, 294, 264, 4055, 13, 51436], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1786, "seek": 480088, "start": 4822.32, "end": 4825.88, "text": " You know, 10 years ago, there was hardly anything and now there's a big town.", "tokens": [51436, 509, 458, 11, 1266, 924, 2057, 11, 456, 390, 13572, 1340, 293, 586, 456, 311, 257, 955, 3954, 13, 51614], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1787, "seek": 480088, "start": 4826.12, "end": 4827.56, "text": " Look how great the West is growing.", "tokens": [51626, 2053, 577, 869, 264, 4055, 307, 4194, 13, 51698], "temperature": 0.0, "avg_logprob": -0.16759882409588184, "compression_ratio": 1.8201892744479495, "no_speech_prob": 0.0003682744281832129}, {"id": 1788, "seek": 482756, "start": 4827.56, "end": 4831.120000000001, "text": " And that, you know, there are always times and places where right there,", "tokens": [50364, 400, 300, 11, 291, 458, 11, 456, 366, 1009, 1413, 293, 3190, 689, 558, 456, 11, 50542], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1789, "seek": 482756, "start": 4831.120000000001, "end": 4836.52, "text": " things are growing very fast and newspaper writers should focus on those to tell stories", "tokens": [50542, 721, 366, 4194, 588, 2370, 293, 13669, 13491, 820, 1879, 322, 729, 281, 980, 3676, 50812], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1790, "seek": 482756, "start": 4837.160000000001, "end": 4839.92, "text": " and keep novelists should focus on those to tell stories.", "tokens": [50844, 293, 1066, 7613, 1751, 820, 1879, 322, 729, 281, 980, 3676, 13, 50982], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1791, "seek": 482756, "start": 4839.92, "end": 4841.96, "text": " They're exciting places where exciting things are happening.", "tokens": [50982, 814, 434, 4670, 3190, 689, 4670, 721, 366, 2737, 13, 51084], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1792, "seek": 482756, "start": 4841.96, "end": 4845.320000000001, "text": " And I want to make sure the world keeps having things like that happening", "tokens": [51084, 400, 286, 528, 281, 652, 988, 264, 1002, 5965, 1419, 721, 411, 300, 2737, 51252], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1793, "seek": 482756, "start": 4845.320000000001, "end": 4847.76, "text": " because that's how we can keep growing.", "tokens": [51252, 570, 300, 311, 577, 321, 393, 1066, 4194, 13, 51374], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1794, "seek": 482756, "start": 4847.96, "end": 4850.4800000000005, "text": " But you have to be honest about the fraction of the world", "tokens": [51384, 583, 291, 362, 281, 312, 3245, 466, 264, 14135, 295, 264, 1002, 51510], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1795, "seek": 482756, "start": 4850.4800000000005, "end": 4852.68, "text": " that's involved in those exciting frontier stories.", "tokens": [51510, 300, 311, 3288, 294, 729, 4670, 35853, 3676, 13, 51620], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1796, "seek": 482756, "start": 4853.6, "end": 4857.200000000001, "text": " Yeah, I mean, I guess my kind of counterpoint to that would be", "tokens": [51666, 865, 11, 286, 914, 11, 286, 2041, 452, 733, 295, 5682, 6053, 281, 300, 576, 312, 51846], "temperature": 0.0, "avg_logprob": -0.16869468399972626, "compression_ratio": 1.9155405405405406, "no_speech_prob": 0.001500619575381279}, {"id": 1797, "seek": 485756, "start": 4857.68, "end": 4863.280000000001, "text": " the same relatively simple technology, like the transformer", "tokens": [50370, 264, 912, 7226, 2199, 2899, 11, 411, 264, 31782, 50650], "temperature": 0.0, "avg_logprob": -0.1736548152970679, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00032482502865605056}, {"id": 1798, "seek": 485756, "start": 4863.280000000001, "end": 4867.56, "text": " or like the attention mechanism, perhaps it is better, you know, pinpointed as", "tokens": [50650, 420, 411, 264, 3202, 7513, 11, 4317, 309, 307, 1101, 11, 291, 458, 11, 40837, 292, 382, 50864], "temperature": 0.0, "avg_logprob": -0.1736548152970679, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00032482502865605056}, {"id": 1799, "seek": 485756, "start": 4868.320000000001, "end": 4871.120000000001, "text": " is driving this art creation.", "tokens": [50902, 307, 4840, 341, 1523, 8016, 13, 51042], "temperature": 0.0, "avg_logprob": -0.1736548152970679, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00032482502865605056}, {"id": 1800, "seek": 485756, "start": 4871.72, "end": 4876.320000000001, "text": " It's also writing today like short programs.", "tokens": [51072, 467, 311, 611, 3579, 965, 411, 2099, 4268, 13, 51302], "temperature": 0.0, "avg_logprob": -0.1736548152970679, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00032482502865605056}, {"id": 1801, "seek": 485756, "start": 4876.320000000001, "end": 4880.280000000001, "text": " Yeah, I would personally say my productivity as a programmer has been", "tokens": [51302, 865, 11, 286, 576, 5665, 584, 452, 15604, 382, 257, 32116, 575, 668, 51500], "temperature": 0.0, "avg_logprob": -0.1736548152970679, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00032482502865605056}, {"id": 1802, "seek": 485756, "start": 4880.6, "end": 4885.0, "text": " increased like several fold, not like incrementally, but like multiple", "tokens": [51516, 6505, 411, 2940, 4860, 11, 406, 411, 26200, 379, 11, 457, 411, 3866, 51736], "temperature": 0.0, "avg_logprob": -0.1736548152970679, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00032482502865605056}, {"id": 1803, "seek": 488500, "start": 4885.32, "end": 4889.44, "text": " with GPT for assistance, you know, it's the wide range where you could go on.", "tokens": [50380, 365, 26039, 51, 337, 9683, 11, 291, 458, 11, 309, 311, 264, 4874, 3613, 689, 291, 727, 352, 322, 13, 50586], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1804, "seek": 488500, "start": 4889.44, "end": 4892.2, "text": " But like it's it's also happening in metal medical diagnosis.", "tokens": [50586, 583, 411, 309, 311, 309, 311, 611, 2737, 294, 5760, 4625, 15217, 13, 50724], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1805, "seek": 488500, "start": 4892.2, "end": 4896.8, "text": " It's also happening in like protein, you know, novel protein structure generation.", "tokens": [50724, 467, 311, 611, 2737, 294, 411, 7944, 11, 291, 458, 11, 7613, 7944, 3877, 5125, 13, 50954], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1806, "seek": 488500, "start": 4896.8, "end": 4899.68, "text": " And certainly from an economic point of view, the biggest category", "tokens": [50954, 400, 3297, 490, 364, 4836, 935, 295, 1910, 11, 264, 3880, 7719, 51098], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1807, "seek": 488500, "start": 4899.68, "end": 4901.2, "text": " you've mentioned is programming.", "tokens": [51098, 291, 600, 2835, 307, 9410, 13, 51174], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1808, "seek": 488500, "start": 4901.2, "end": 4904.76, "text": " That's a much larger industry, less of your profession than the other ones you mentioned.", "tokens": [51174, 663, 311, 257, 709, 4833, 3518, 11, 1570, 295, 428, 7032, 813, 264, 661, 2306, 291, 2835, 13, 51352], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1809, "seek": 488500, "start": 4905.04, "end": 4907.88, "text": " Well, but watch out for biotech also, I would say, for sure.", "tokens": [51366, 1042, 11, 457, 1159, 484, 337, 3228, 1370, 339, 611, 11, 286, 576, 584, 11, 337, 988, 13, 51508], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1810, "seek": 488500, "start": 4907.88, "end": 4910.52, "text": " But biotech has been shrinking for a while.", "tokens": [51508, 583, 3228, 1370, 339, 575, 668, 41684, 337, 257, 1339, 13, 51640], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1811, "seek": 488500, "start": 4910.52, "end": 4913.88, "text": " So that's not an exact thing you should point to as a growing thing.", "tokens": [51640, 407, 300, 311, 406, 364, 1900, 551, 291, 820, 935, 281, 382, 257, 4194, 551, 13, 51808], "temperature": 0.0, "avg_logprob": -0.17144770304361978, "compression_ratio": 1.718475073313783, "no_speech_prob": 0.003944408614188433}, {"id": 1812, "seek": 491388, "start": 4914.28, "end": 4916.6, "text": " I will predict growth for biotech, definitely.", "tokens": [50384, 286, 486, 6069, 4599, 337, 3228, 1370, 339, 11, 2138, 13, 50500], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1813, "seek": 491388, "start": 4916.76, "end": 4919.16, "text": " I mean, you know, it's also it's reading brain states.", "tokens": [50508, 286, 914, 11, 291, 458, 11, 309, 311, 611, 309, 311, 3760, 3567, 4368, 13, 50628], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1814, "seek": 491388, "start": 4919.16, "end": 4922.36, "text": " Have you seen these recent things where people can read the brain state?", "tokens": [50628, 3560, 291, 1612, 613, 5162, 721, 689, 561, 393, 1401, 264, 3567, 1785, 30, 50788], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1815, "seek": 491388, "start": 4922.68, "end": 4924.64, "text": " Among the things you're talking about at the moment, the biggest", "tokens": [50804, 16119, 264, 721, 291, 434, 1417, 466, 412, 264, 1623, 11, 264, 3880, 50902], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1816, "seek": 491388, "start": 4924.64, "end": 4927.12, "text": " profession being affected is programming, clearly.", "tokens": [50902, 7032, 885, 8028, 307, 9410, 11, 4448, 13, 51026], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1817, "seek": 491388, "start": 4927.32, "end": 4929.56, "text": " I have a younger son, two sons.", "tokens": [51036, 286, 362, 257, 7037, 1872, 11, 732, 13476, 13, 51148], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1818, "seek": 491388, "start": 4929.56, "end": 4931.24, "text": " My younger one is a professional programmer.", "tokens": [51148, 1222, 7037, 472, 307, 257, 4843, 32116, 13, 51232], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1819, "seek": 491388, "start": 4931.24, "end": 4934.96, "text": " So, you know, I've had him look at and his", "tokens": [51232, 407, 11, 291, 458, 11, 286, 600, 632, 796, 574, 412, 293, 702, 51418], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1820, "seek": 491388, "start": 4935.6, "end": 4938.400000000001, "text": " workplace has looked into what they can do with large language models", "tokens": [51450, 15328, 575, 2956, 666, 437, 436, 393, 360, 365, 2416, 2856, 5245, 51590], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1821, "seek": 491388, "start": 4938.400000000001, "end": 4939.56, "text": " to help them write programs.", "tokens": [51590, 281, 854, 552, 2464, 4268, 13, 51648], "temperature": 0.0, "avg_logprob": -0.12721205849683923, "compression_ratio": 1.7254237288135594, "no_speech_prob": 0.0003682242822833359}, {"id": 1822, "seek": 493956, "start": 4939.56, "end": 4944.160000000001, "text": " And their evaluation so far is, you know, they don't even", "tokens": [50364, 400, 641, 13344, 370, 1400, 307, 11, 291, 458, 11, 436, 500, 380, 754, 50594], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1823, "seek": 493956, "start": 4945.280000000001, "end": 4946.96, "text": " they'll wait in six months to look again.", "tokens": [50650, 436, 603, 1699, 294, 2309, 2493, 281, 574, 797, 13, 50734], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1824, "seek": 493956, "start": 4946.96, "end": 4948.4400000000005, "text": " It's not useful now.", "tokens": [50734, 467, 311, 406, 4420, 586, 13, 50808], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1825, "seek": 493956, "start": 4948.4400000000005, "end": 4950.64, "text": " Can I short that stock?", "tokens": [50808, 1664, 286, 2099, 300, 4127, 30, 50918], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1826, "seek": 493956, "start": 4951.56, "end": 4955.04, "text": " Well, I could tell you after we finish what that is.", "tokens": [50964, 1042, 11, 286, 727, 980, 291, 934, 321, 2413, 437, 300, 307, 13, 51138], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1827, "seek": 493956, "start": 4955.04, "end": 4957.280000000001, "text": " But basically, I think this is true.", "tokens": [51138, 583, 1936, 11, 286, 519, 341, 307, 2074, 13, 51250], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1828, "seek": 493956, "start": 4957.280000000001, "end": 4961.120000000001, "text": " Most actual professional programmers are not using large language models", "tokens": [51250, 4534, 3539, 4843, 41504, 366, 406, 1228, 2416, 2856, 5245, 51442], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1829, "seek": 493956, "start": 4961.120000000001, "end": 4963.200000000001, "text": " that much in doing their job.", "tokens": [51442, 300, 709, 294, 884, 641, 1691, 13, 51546], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1830, "seek": 493956, "start": 4964.04, "end": 4968.240000000001, "text": " Now, I got to say that if some people are getting factors of two productivity", "tokens": [51588, 823, 11, 286, 658, 281, 584, 300, 498, 512, 561, 366, 1242, 6771, 295, 732, 15604, 51798], "temperature": 0.0, "avg_logprob": -0.2040787258663693, "compression_ratio": 1.5601503759398496, "no_speech_prob": 0.0015009406488388777}, {"id": 1831, "seek": 496824, "start": 4968.24, "end": 4973.92, "text": " increase that eventually we should see some effect of that on their wages.", "tokens": [50364, 3488, 300, 4728, 321, 820, 536, 512, 1802, 295, 300, 322, 641, 20097, 13, 50648], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1832, "seek": 496824, "start": 4975.44, "end": 4979.28, "text": " That is, of course, you know, now, if lots of programmers go out", "tokens": [50724, 663, 307, 11, 295, 1164, 11, 291, 458, 11, 586, 11, 498, 3195, 295, 41504, 352, 484, 50916], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1833, "seek": 496824, "start": 4979.28, "end": 4982.12, "text": " and use productivity spaces, in some sense, we're going to increase", "tokens": [50916, 293, 764, 15604, 7673, 11, 294, 512, 2020, 11, 321, 434, 516, 281, 3488, 51058], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1834, "seek": 496824, "start": 4982.12, "end": 4983.5199999999995, "text": " the supply of programming.", "tokens": [51058, 264, 5847, 295, 9410, 13, 51128], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1835, "seek": 496824, "start": 4984.5199999999995, "end": 4987.84, "text": " And so supply and demand would mean that maybe increasing", "tokens": [51178, 400, 370, 5847, 293, 4733, 576, 914, 300, 1310, 5662, 51344], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1836, "seek": 496824, "start": 4987.84, "end": 4991.639999999999, "text": " the supply lowers the price, even if it dramatically increases the quantity.", "tokens": [51344, 264, 5847, 44936, 264, 3218, 11, 754, 498, 309, 17548, 8637, 264, 11275, 13, 51534], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1837, "seek": 496824, "start": 4992.5599999999995, "end": 4996.5599999999995, "text": " But, you know, there's such a large elastic demand for programming", "tokens": [51580, 583, 11, 291, 458, 11, 456, 311, 1270, 257, 2416, 17115, 4733, 337, 9410, 51780], "temperature": 0.0, "avg_logprob": -0.13375593148745024, "compression_ratio": 1.779591836734694, "no_speech_prob": 0.0011333038564771414}, {"id": 1838, "seek": 499656, "start": 4996.56, "end": 4999.360000000001, "text": " in the world that I actually think that effect would be relatively weak.", "tokens": [50364, 294, 264, 1002, 300, 286, 767, 519, 300, 1802, 576, 312, 7226, 5336, 13, 50504], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1839, "seek": 499656, "start": 4999.360000000001, "end": 5004.72, "text": " And so you should be expecting large increases in the wages going to programmers.", "tokens": [50504, 400, 370, 291, 820, 312, 9650, 2416, 8637, 294, 264, 20097, 516, 281, 41504, 13, 50772], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1840, "seek": 499656, "start": 5005.52, "end": 5010.52, "text": " If you are expecting large overall increases in the productivity of programmers.", "tokens": [50812, 759, 291, 366, 9650, 2416, 4787, 8637, 294, 264, 15604, 295, 41504, 13, 51062], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1841, "seek": 499656, "start": 5011.4800000000005, "end": 5015.56, "text": " Because, again, it's a large elastic demand for programming in the world.", "tokens": [51110, 1436, 11, 797, 11, 309, 311, 257, 2416, 17115, 4733, 337, 9410, 294, 264, 1002, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1842, "seek": 499656, "start": 5016.0, "end": 5019.72, "text": " You know, long for a long time, a lot of change in the world has been driven", "tokens": [51336, 509, 458, 11, 938, 337, 257, 938, 565, 11, 257, 688, 295, 1319, 294, 264, 1002, 575, 668, 9555, 51522], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1843, "seek": 499656, "start": 5019.72, "end": 5023.6, "text": " by programming and limited by the fact that there's only so many decent programmers out there.", "tokens": [51522, 538, 9410, 293, 5567, 538, 264, 1186, 300, 456, 311, 787, 370, 867, 8681, 41504, 484, 456, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1844, "seek": 499656, "start": 5024.320000000001, "end": 5025.96, "text": " Only so many people you can get to do programming.", "tokens": [51752, 5686, 370, 867, 561, 291, 393, 483, 281, 360, 9410, 13, 51834], "temperature": 0.0, "avg_logprob": -0.1436415500328189, "compression_ratio": 1.9205776173285198, "no_speech_prob": 0.0005882819532416761}, {"id": 1845, "seek": 502596, "start": 5025.96, "end": 5031.4, "text": " So clearly, if we can dramatically expand the supply of programmers,", "tokens": [50364, 407, 4448, 11, 498, 321, 393, 17548, 5268, 264, 5847, 295, 41504, 11, 50636], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1846, "seek": 502596, "start": 5031.92, "end": 5034.76, "text": " we can do a lot more programming in a lot more areas.", "tokens": [50662, 321, 393, 360, 257, 688, 544, 9410, 294, 257, 688, 544, 3179, 13, 50804], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1847, "seek": 502596, "start": 5034.76, "end": 5037.92, "text": " And there's a lot of money that's willing to go to that to do that.", "tokens": [50804, 400, 456, 311, 257, 688, 295, 1460, 300, 311, 4950, 281, 352, 281, 300, 281, 360, 300, 13, 50962], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1848, "seek": 502596, "start": 5037.92, "end": 5040.96, "text": " There's a lot of people who would be hiring more programmers if only they were cheaper.", "tokens": [50962, 821, 311, 257, 688, 295, 561, 567, 576, 312, 15335, 544, 41504, 498, 787, 436, 645, 12284, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1849, "seek": 502596, "start": 5042.04, "end": 5043.88, "text": " And they're about to get cheaper in effect.", "tokens": [51168, 400, 436, 434, 466, 281, 483, 12284, 294, 1802, 13, 51260], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1850, "seek": 502596, "start": 5044.52, "end": 5048.12, "text": " And so you should be predicting large increases in basically", "tokens": [51292, 400, 370, 291, 820, 312, 32884, 2416, 8637, 294, 1936, 51472], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1851, "seek": 502596, "start": 5048.6, "end": 5051.32, "text": " the wages and number of programmers in the world.", "tokens": [51496, 264, 20097, 293, 1230, 295, 41504, 294, 264, 1002, 13, 51632], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1852, "seek": 502596, "start": 5052.2, "end": 5054.0, "text": " We haven't seen that yet.", "tokens": [51676, 492, 2378, 380, 1612, 300, 1939, 13, 51766], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1853, "seek": 502596, "start": 5054.0, "end": 5055.76, "text": " I do predict large increases in number.", "tokens": [51766, 286, 360, 6069, 2416, 8637, 294, 1230, 13, 51854], "temperature": 0.0, "avg_logprob": -0.12005406477319913, "compression_ratio": 1.9192307692307693, "no_speech_prob": 0.00017950056644622236}, {"id": 1854, "seek": 505576, "start": 5055.76, "end": 5057.0, "text": " I'm not so sure about wages.", "tokens": [50364, 286, 478, 406, 370, 988, 466, 20097, 13, 50426], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1855, "seek": 505576, "start": 5057.0, "end": 5058.96, "text": " It feels like why not?", "tokens": [50426, 467, 3417, 411, 983, 406, 30, 50524], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1856, "seek": 505576, "start": 5058.96, "end": 5062.76, "text": " Well, I've done a couple of episodes with the folks at a company called Replet,", "tokens": [50524, 1042, 11, 286, 600, 1096, 257, 1916, 295, 9313, 365, 264, 4024, 412, 257, 2237, 1219, 1300, 14657, 11, 50714], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1857, "seek": 505576, "start": 5062.76, "end": 5067.64, "text": " which is a very interesting end to end at this point, software development platform.", "tokens": [50714, 597, 307, 257, 588, 1880, 917, 281, 917, 412, 341, 935, 11, 4722, 3250, 3663, 13, 50958], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1858, "seek": 505576, "start": 5068.2, "end": 5071.64, "text": " Their mission is to onboard the next one billion developers.", "tokens": [50986, 6710, 4447, 307, 281, 24033, 264, 958, 472, 5218, 8849, 13, 51158], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1859, "seek": 505576, "start": 5072.24, "end": 5075.88, "text": " And, you know, they have like a great mobile app.", "tokens": [51188, 400, 11, 291, 458, 11, 436, 362, 411, 257, 869, 6013, 724, 13, 51370], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1860, "seek": 505576, "start": 5075.88, "end": 5080.4400000000005, "text": " They have kids in India that are, you know, 14 years old that are doing it all on their mobile app.", "tokens": [51370, 814, 362, 2301, 294, 5282, 300, 366, 11, 291, 458, 11, 3499, 924, 1331, 300, 366, 884, 309, 439, 322, 641, 6013, 724, 13, 51598], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1861, "seek": 505576, "start": 5081.0, "end": 5084.08, "text": " And I'd say it's much harder.", "tokens": [51626, 400, 286, 1116, 584, 309, 311, 709, 6081, 13, 51780], "temperature": 0.0, "avg_logprob": -0.15959098262171592, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.00020336918532848358}, {"id": 1862, "seek": 508408, "start": 5084.32, "end": 5086.8, "text": " And maybe this reflects the kind of programming that your son is doing.", "tokens": [50376, 400, 1310, 341, 18926, 264, 733, 295, 9410, 300, 428, 1872, 307, 884, 13, 50500], "temperature": 0.0, "avg_logprob": -0.18288168656198603, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028003882616758347}, {"id": 1863, "seek": 508408, "start": 5086.8, "end": 5092.6, "text": " But I'd say it's much harder to take the most elite frontier work and accelerate that", "tokens": [50500, 583, 286, 1116, 584, 309, 311, 709, 6081, 281, 747, 264, 881, 17801, 35853, 589, 293, 21341, 300, 50790], "temperature": 0.0, "avg_logprob": -0.18288168656198603, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028003882616758347}, {"id": 1864, "seek": 508408, "start": 5093.2, "end": 5100.16, "text": " in a meaningful way versus like commoditizing the routine application development", "tokens": [50820, 294, 257, 10995, 636, 5717, 411, 19931, 270, 3319, 264, 9927, 3861, 3250, 51168], "temperature": 0.0, "avg_logprob": -0.18288168656198603, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028003882616758347}, {"id": 1865, "seek": 508408, "start": 5100.28, "end": 5105.08, "text": " that like the, you know, the sort of long tail of programmers mostly do.", "tokens": [51174, 300, 411, 264, 11, 291, 458, 11, 264, 1333, 295, 938, 6838, 295, 41504, 5240, 360, 13, 51414], "temperature": 0.0, "avg_logprob": -0.18288168656198603, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028003882616758347}, {"id": 1866, "seek": 508408, "start": 5105.08, "end": 5108.4, "text": " My son is definitely doing routine application development.", "tokens": [51414, 1222, 1872, 307, 2138, 884, 9927, 3861, 3250, 13, 51580], "temperature": 0.0, "avg_logprob": -0.18288168656198603, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028003882616758347}, {"id": 1867, "seek": 508408, "start": 5110.16, "end": 5112.0, "text": " He's not at the frontier programming at all.", "tokens": [51668, 634, 311, 406, 412, 264, 35853, 9410, 412, 439, 13, 51760], "temperature": 0.0, "avg_logprob": -0.18288168656198603, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028003882616758347}, {"id": 1868, "seek": 511200, "start": 5113.0, "end": 5120.0, "text": " But again, I'm saying I don't expect this sudden large increase in programmer wages and quantity,", "tokens": [50414, 583, 797, 11, 286, 478, 1566, 286, 500, 380, 2066, 341, 3990, 2416, 3488, 294, 32116, 20097, 293, 11275, 11, 50764], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1869, "seek": 511200, "start": 5120.8, "end": 5121.92, "text": " especially wages.", "tokens": [50804, 2318, 20097, 13, 50860], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1870, "seek": 511200, "start": 5121.92, "end": 5125.72, "text": " I mean, the less the quantity increases, the more wages would have to be increasing to compensate.", "tokens": [50860, 286, 914, 11, 264, 1570, 264, 11275, 8637, 11, 264, 544, 20097, 576, 362, 281, 312, 5662, 281, 29458, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1871, "seek": 511200, "start": 5126.36, "end": 5130.36, "text": " And I think it'll be hard to get that many more people willing to be programmers,", "tokens": [51082, 400, 286, 519, 309, 603, 312, 1152, 281, 483, 300, 867, 544, 561, 4950, 281, 312, 41504, 11, 51282], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1872, "seek": 511200, "start": 5130.36, "end": 5132.76, "text": " but you could pay them more.", "tokens": [51282, 457, 291, 727, 1689, 552, 544, 13, 51402], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1873, "seek": 511200, "start": 5134.24, "end": 5135.56, "text": " And I don't predict this.", "tokens": [51476, 400, 286, 500, 380, 6069, 341, 13, 51542], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1874, "seek": 511200, "start": 5135.56, "end": 5139.88, "text": " So this is a concrete thing we could, you know, even better on over the next five or 10 years.", "tokens": [51542, 407, 341, 307, 257, 9859, 551, 321, 727, 11, 291, 458, 11, 754, 1101, 322, 670, 264, 958, 1732, 420, 1266, 924, 13, 51758], "temperature": 0.0, "avg_logprob": -0.1371630869413677, "compression_ratio": 1.6830188679245284, "no_speech_prob": 0.0004305134934838861}, {"id": 1875, "seek": 513988, "start": 5140.4400000000005, "end": 5142.76, "text": " Will there be a big boost in programmer wages?", "tokens": [50392, 3099, 456, 312, 257, 955, 9194, 294, 32116, 20097, 30, 50508], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1876, "seek": 513988, "start": 5144.12, "end": 5145.6, "text": " That would be the consequence.", "tokens": [50576, 663, 576, 312, 264, 18326, 13, 50650], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1877, "seek": 513988, "start": 5145.6, "end": 5147.84, "text": " It's a very simple supply and demand analysis here.", "tokens": [50650, 467, 311, 257, 588, 2199, 5847, 293, 4733, 5215, 510, 13, 50762], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1878, "seek": 513988, "start": 5147.84, "end": 5152.4800000000005, "text": " This isn't some subtle, you know, rocket science version of economics.", "tokens": [50762, 639, 1943, 380, 512, 13743, 11, 291, 458, 11, 13012, 3497, 3037, 295, 14564, 13, 50994], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1879, "seek": 513988, "start": 5152.4800000000005, "end": 5155.4400000000005, "text": " Well, typically when supply increases, price drops, right?", "tokens": [50994, 1042, 11, 5850, 562, 5847, 8637, 11, 3218, 11438, 11, 558, 30, 51142], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1880, "seek": 513988, "start": 5155.4400000000005, "end": 5158.68, "text": " I'm expecting lots more programmers and them to be broadly cheap.", "tokens": [51142, 286, 478, 9650, 3195, 544, 41504, 293, 552, 281, 312, 19511, 7084, 13, 51304], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1881, "seek": 513988, "start": 5158.68, "end": 5160.56, "text": " Depends on the elasticity of demand.", "tokens": [51304, 4056, 2581, 322, 264, 46260, 295, 4733, 13, 51398], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1882, "seek": 513988, "start": 5161.84, "end": 5167.32, "text": " So, you know, if you think about something that there's just a very limited demand for in the world,", "tokens": [51462, 407, 11, 291, 458, 11, 498, 291, 519, 466, 746, 300, 456, 311, 445, 257, 588, 5567, 4733, 337, 294, 264, 1002, 11, 51736], "temperature": 0.0, "avg_logprob": -0.13578035091531687, "compression_ratio": 1.602076124567474, "no_speech_prob": 0.002800665097311139}, {"id": 1883, "seek": 516732, "start": 5167.5599999999995, "end": 5171.28, "text": " you know, if, if piano tuning got a lot cheaper, you wouldn't have a lot more pianos", "tokens": [50376, 291, 458, 11, 498, 11, 498, 9211, 15164, 658, 257, 688, 12284, 11, 291, 2759, 380, 362, 257, 688, 544, 32198, 329, 50562], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1884, "seek": 516732, "start": 5171.759999999999, "end": 5175.48, "text": " because piano tuning is not one of the major costs of having a piano.", "tokens": [50586, 570, 9211, 15164, 307, 406, 472, 295, 264, 2563, 5497, 295, 1419, 257, 9211, 13, 50772], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1885, "seek": 516732, "start": 5175.5599999999995, "end": 5179.2, "text": " You know, it's the cost of the piano itself, plus the space for it in your living room, right?", "tokens": [50776, 509, 458, 11, 309, 311, 264, 2063, 295, 264, 9211, 2564, 11, 1804, 264, 1901, 337, 309, 294, 428, 2647, 1808, 11, 558, 30, 50958], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1886, "seek": 516732, "start": 5179.719999999999, "end": 5181.4, "text": " And the time it takes to play on the piano.", "tokens": [50984, 400, 264, 565, 309, 2516, 281, 862, 322, 264, 9211, 13, 51068], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1887, "seek": 516732, "start": 5181.4, "end": 5185.639999999999, "text": " So piano tuning is a really small cost of piano.", "tokens": [51068, 407, 9211, 15164, 307, 257, 534, 1359, 2063, 295, 9211, 13, 51280], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1888, "seek": 516732, "start": 5185.639999999999, "end": 5190.16, "text": " So that means the elasticity of demand for piano tuners by itself is pretty low.", "tokens": [51280, 407, 300, 1355, 264, 46260, 295, 4733, 337, 9211, 4267, 433, 538, 2564, 307, 1238, 2295, 13, 51506], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1889, "seek": 516732, "start": 5191.24, "end": 5194.5599999999995, "text": " You know, there's just basically only so many pianos, they all need to be tuned.", "tokens": [51560, 509, 458, 11, 456, 311, 445, 1936, 787, 370, 867, 32198, 329, 11, 436, 439, 643, 281, 312, 10870, 13, 51726], "temperature": 0.0, "avg_logprob": -0.14233596184674432, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0016482637729495764}, {"id": 1890, "seek": 519456, "start": 5194.56, "end": 5198.240000000001, "text": " And if each piano tuner could tune each piano twice as fast, say,", "tokens": [50364, 400, 498, 1184, 9211, 4267, 260, 727, 10864, 1184, 9211, 6091, 382, 2370, 11, 584, 11, 50548], "temperature": 0.0, "avg_logprob": -0.1322216306413923, "compression_ratio": 1.6859504132231404, "no_speech_prob": 0.0006460972363129258}, {"id": 1891, "seek": 519456, "start": 5198.88, "end": 5204.64, "text": " and we basically only need half as many pianos because there's just not much of elasticity for demand.", "tokens": [50580, 293, 321, 1936, 787, 643, 1922, 382, 867, 32198, 329, 570, 456, 311, 445, 406, 709, 295, 46260, 337, 4733, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1322216306413923, "compression_ratio": 1.6859504132231404, "no_speech_prob": 0.0006460972363129258}, {"id": 1892, "seek": 519456, "start": 5204.64, "end": 5210.92, "text": " So for kinds of jobs like that, productivity increases will cause a reduction in the employment.", "tokens": [50868, 407, 337, 3685, 295, 4782, 411, 300, 11, 15604, 8637, 486, 3082, 257, 11004, 294, 264, 11949, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1322216306413923, "compression_ratio": 1.6859504132231404, "no_speech_prob": 0.0006460972363129258}, {"id": 1893, "seek": 519456, "start": 5212.360000000001, "end": 5217.4800000000005, "text": " But even in that case, you might get a doubling of the wages and half the number of piano tuners", "tokens": [51254, 583, 754, 294, 300, 1389, 11, 291, 1062, 483, 257, 33651, 295, 264, 20097, 293, 1922, 264, 1230, 295, 9211, 4267, 433, 51510], "temperature": 0.0, "avg_logprob": -0.1322216306413923, "compression_ratio": 1.6859504132231404, "no_speech_prob": 0.0006460972363129258}, {"id": 1894, "seek": 519456, "start": 5217.4800000000005, "end": 5219.360000000001, "text": " because they can each be twice as productive.", "tokens": [51510, 570, 436, 393, 1184, 312, 6091, 382, 13304, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1322216306413923, "compression_ratio": 1.6859504132231404, "no_speech_prob": 0.0006460972363129258}, {"id": 1895, "seek": 521936, "start": 5219.88, "end": 5224.679999999999, "text": " But for programming, it's clear to me that programming has an enormous elastic demand.", "tokens": [50390, 583, 337, 9410, 11, 309, 311, 1850, 281, 385, 300, 9410, 575, 364, 11322, 17115, 4733, 13, 50630], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1896, "seek": 521936, "start": 5224.679999999999, "end": 5227.88, "text": " The world out there has far fewer programmers than they want.", "tokens": [50630, 440, 1002, 484, 456, 575, 1400, 13366, 41504, 813, 436, 528, 13, 50790], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1897, "seek": 521936, "start": 5227.92, "end": 5231.839999999999, "text": " They would love all over the place to hire more programmers to do more things.", "tokens": [50792, 814, 576, 959, 439, 670, 264, 1081, 281, 11158, 544, 41504, 281, 360, 544, 721, 13, 50988], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1898, "seek": 521936, "start": 5232.32, "end": 5234.759999999999, "text": " There's a big demand in the world for software to do stuff.", "tokens": [51012, 821, 311, 257, 955, 4733, 294, 264, 1002, 337, 4722, 281, 360, 1507, 13, 51134], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1899, "seek": 521936, "start": 5235.16, "end": 5238.639999999999, "text": " And there's a huge potential range of things the software could be doing.", "tokens": [51154, 400, 456, 311, 257, 2603, 3995, 3613, 295, 721, 264, 4722, 727, 312, 884, 13, 51328], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1900, "seek": 521936, "start": 5238.639999999999, "end": 5240.28, "text": " It's not doing now.", "tokens": [51328, 467, 311, 406, 884, 586, 13, 51410], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1901, "seek": 521936, "start": 5240.28, "end": 5243.92, "text": " So that means there's a pretty elastic demand for programming.", "tokens": [51410, 407, 300, 1355, 456, 311, 257, 1238, 17115, 4733, 337, 9410, 13, 51592], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1902, "seek": 521936, "start": 5243.92, "end": 5248.24, "text": " That means as we increase the quantity of programming, the price doesn't come down that much.", "tokens": [51592, 663, 1355, 382, 321, 3488, 264, 11275, 295, 9410, 11, 264, 3218, 1177, 380, 808, 760, 300, 709, 13, 51808], "temperature": 0.0, "avg_logprob": -0.11023388057947159, "compression_ratio": 1.92831541218638, "no_speech_prob": 0.026748936623334885}, {"id": 1903, "seek": 524936, "start": 5249.679999999999, "end": 5251.24, "text": " There's still people willing to buy this stuff.", "tokens": [50380, 821, 311, 920, 561, 4950, 281, 2256, 341, 1507, 13, 50458], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1904, "seek": 524936, "start": 5252.32, "end": 5254.96, "text": " So that tells me that as productivity increases,", "tokens": [50512, 407, 300, 5112, 385, 300, 382, 15604, 8637, 11, 50644], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1905, "seek": 524936, "start": 5256.5599999999995, "end": 5260.0, "text": " basically the supply is expanding and the demand is not coming down much.", "tokens": [50724, 1936, 264, 5847, 307, 14702, 293, 264, 4733, 307, 406, 1348, 760, 709, 13, 50896], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1906, "seek": 524936, "start": 5260.0, "end": 5264.48, "text": " So we should just see a much larger quantity.", "tokens": [50896, 407, 321, 820, 445, 536, 257, 709, 4833, 11275, 13, 51120], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1907, "seek": 524936, "start": 5264.48, "end": 5267.5599999999995, "text": " But then, you know, basically because each person is being more productive,", "tokens": [51120, 583, 550, 11, 291, 458, 11, 1936, 570, 1184, 954, 307, 885, 544, 13304, 11, 51274], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1908, "seek": 524936, "start": 5267.719999999999, "end": 5269.44, "text": " each person should get paid more.", "tokens": [51282, 1184, 954, 820, 483, 4835, 544, 13, 51368], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1909, "seek": 524936, "start": 5269.44, "end": 5272.28, "text": " So the elastic supply is going to be a combination of two things.", "tokens": [51368, 407, 264, 17115, 5847, 307, 516, 281, 312, 257, 6562, 295, 732, 721, 13, 51510], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1910, "seek": 524936, "start": 5272.28, "end": 5277.24, "text": " Each person getting more productive and more people being willing to join that profession.", "tokens": [51510, 6947, 954, 1242, 544, 13304, 293, 544, 561, 885, 4950, 281, 3917, 300, 7032, 13, 51758], "temperature": 0.0, "avg_logprob": -0.15815060479300364, "compression_ratio": 1.8365019011406845, "no_speech_prob": 0.0005191667005419731}, {"id": 1911, "seek": 527724, "start": 5278.04, "end": 5283.5199999999995, "text": " And I think we've already seen that even as the wages for programming has gone way up", "tokens": [50404, 400, 286, 519, 321, 600, 1217, 1612, 300, 754, 382, 264, 20097, 337, 9410, 575, 2780, 636, 493, 50678], "temperature": 0.0, "avg_logprob": -0.14639388565468578, "compression_ratio": 1.76953125, "no_speech_prob": 0.0009694795007817447}, {"id": 1912, "seek": 527724, "start": 5283.5199999999995, "end": 5286.96, "text": " in the last decade or so, the number of programmers hasn't gone up as fast.", "tokens": [50678, 294, 264, 1036, 10378, 420, 370, 11, 264, 1230, 295, 41504, 6132, 380, 2780, 493, 382, 2370, 13, 50850], "temperature": 0.0, "avg_logprob": -0.14639388565468578, "compression_ratio": 1.76953125, "no_speech_prob": 0.0009694795007817447}, {"id": 1913, "seek": 527724, "start": 5287.599999999999, "end": 5291.48, "text": " That is, there's just kind of a limited number of people who are decent at programming.", "tokens": [50882, 663, 307, 11, 456, 311, 445, 733, 295, 257, 5567, 1230, 295, 561, 567, 366, 8681, 412, 9410, 13, 51076], "temperature": 0.0, "avg_logprob": -0.14639388565468578, "compression_ratio": 1.76953125, "no_speech_prob": 0.0009694795007817447}, {"id": 1914, "seek": 527724, "start": 5292.44, "end": 5296.44, "text": " And it's hard to get the marginal person to be a programmer.", "tokens": [51124, 400, 309, 311, 1152, 281, 483, 264, 16885, 954, 281, 312, 257, 32116, 13, 51324], "temperature": 0.0, "avg_logprob": -0.14639388565468578, "compression_ratio": 1.76953125, "no_speech_prob": 0.0009694795007817447}, {"id": 1915, "seek": 527724, "start": 5297.599999999999, "end": 5300.92, "text": " But the people who are programmers, when they're productive, they get paid a lot.", "tokens": [51382, 583, 264, 561, 567, 366, 41504, 11, 562, 436, 434, 13304, 11, 436, 483, 4835, 257, 688, 13, 51548], "temperature": 0.0, "avg_logprob": -0.14639388565468578, "compression_ratio": 1.76953125, "no_speech_prob": 0.0009694795007817447}, {"id": 1916, "seek": 527724, "start": 5301.08, "end": 5304.719999999999, "text": " I mean, as you've probably heard rumors about AI programmers", "tokens": [51556, 286, 914, 11, 382, 291, 600, 1391, 2198, 21201, 466, 7318, 41504, 51738], "temperature": 0.0, "avg_logprob": -0.14639388565468578, "compression_ratio": 1.76953125, "no_speech_prob": 0.0009694795007817447}, {"id": 1917, "seek": 530472, "start": 5304.72, "end": 5308.76, "text": " and how much they're being paid lately, it's crazy high because there's just a limited supply.", "tokens": [50364, 293, 577, 709, 436, 434, 885, 4835, 12881, 11, 309, 311, 3219, 1090, 570, 456, 311, 445, 257, 5567, 5847, 13, 50566], "temperature": 0.0, "avg_logprob": -0.14003374179204306, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.0004877904721070081}, {"id": 1918, "seek": 530472, "start": 5310.12, "end": 5315.6, "text": " So I got to say, I expect large increases in wages for programmers,", "tokens": [50634, 407, 286, 658, 281, 584, 11, 286, 2066, 2416, 8637, 294, 20097, 337, 41504, 11, 50908], "temperature": 0.0, "avg_logprob": -0.14003374179204306, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.0004877904721070081}, {"id": 1919, "seek": 530472, "start": 5315.6, "end": 5319.96, "text": " if in fact large language models are making programmers much more productive.", "tokens": [50908, 498, 294, 1186, 2416, 2856, 5245, 366, 1455, 41504, 709, 544, 13304, 13, 51126], "temperature": 0.0, "avg_logprob": -0.14003374179204306, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.0004877904721070081}, {"id": 1920, "seek": 530472, "start": 5321.04, "end": 5326.52, "text": " But according to my son, at least, and others I've heard, you know, that's not happening.", "tokens": [51180, 583, 4650, 281, 452, 1872, 11, 412, 1935, 11, 293, 2357, 286, 600, 2198, 11, 291, 458, 11, 300, 311, 406, 2737, 13, 51454], "temperature": 0.0, "avg_logprob": -0.14003374179204306, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.0004877904721070081}, {"id": 1921, "seek": 530472, "start": 5327.320000000001, "end": 5329.16, "text": " I'm with you up until the very last two points.", "tokens": [51494, 286, 478, 365, 291, 493, 1826, 264, 588, 1036, 732, 2793, 13, 51586], "temperature": 0.0, "avg_logprob": -0.14003374179204306, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.0004877904721070081}, {"id": 1922, "seek": 532916, "start": 5329.2, "end": 5330.96, "text": " I would say I think it is happening.", "tokens": [50366, 286, 576, 584, 286, 519, 309, 307, 2737, 13, 50454], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1923, "seek": 532916, "start": 5331.4, "end": 5336.36, "text": " And I would also say I think my estimation of the relevant", "tokens": [50476, 400, 286, 576, 611, 584, 286, 519, 452, 35701, 295, 264, 7340, 50724], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1924, "seek": 532916, "start": 5336.44, "end": 5341.72, "text": " relevant elasticities is that there will be a large growth in people who can be", "tokens": [50728, 7340, 17115, 1088, 307, 300, 456, 486, 312, 257, 2416, 4599, 294, 561, 567, 393, 312, 50992], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1925, "seek": 532916, "start": 5341.96, "end": 5346.16, "text": " and will choose to be programmers, but that the wages don't go up.", "tokens": [51004, 293, 486, 2826, 281, 312, 41504, 11, 457, 300, 264, 20097, 500, 380, 352, 493, 13, 51214], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1926, "seek": 532916, "start": 5346.16, "end": 5350.28, "text": " They don't fall like dramatically necessarily either because it has to be like", "tokens": [51214, 814, 500, 380, 2100, 411, 17548, 4725, 2139, 570, 309, 575, 281, 312, 411, 51420], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1927, "seek": 532916, "start": 5350.32, "end": 5352.32, "text": " an attractive thing for people to want to do it.", "tokens": [51422, 364, 12609, 551, 337, 561, 281, 528, 281, 360, 309, 13, 51522], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1928, "seek": 532916, "start": 5352.32, "end": 5357.48, "text": " But I think that the prevailing wages are quite high compared to what a lot of people", "tokens": [51522, 583, 286, 519, 300, 264, 12642, 23315, 20097, 366, 1596, 1090, 5347, 281, 437, 257, 688, 295, 561, 51780], "temperature": 0.0, "avg_logprob": -0.18449355874742782, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0019263081485405564}, {"id": 1929, "seek": 535748, "start": 5357.48, "end": 5363.36, "text": " would be excited to take if they could easily break in with language model assistance,", "tokens": [50364, 576, 312, 2919, 281, 747, 498, 436, 727, 3612, 1821, 294, 365, 2856, 2316, 9683, 11, 50658], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1930, "seek": 535748, "start": 5363.36, "end": 5366.24, "text": " which I think they will increasingly be able to do.", "tokens": [50658, 597, 286, 519, 436, 486, 12980, 312, 1075, 281, 360, 13, 50802], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1931, "seek": 535748, "start": 5366.639999999999, "end": 5367.759999999999, "text": " Let me change gears a little bit.", "tokens": [50822, 961, 385, 1319, 20915, 257, 707, 857, 13, 50878], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1932, "seek": 535748, "start": 5367.759999999999, "end": 5369.08, "text": " So we've debated.", "tokens": [50878, 407, 321, 600, 42212, 13, 50944], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1933, "seek": 535748, "start": 5369.08, "end": 5375.679999999999, "text": " This has been really I always appreciate a useful and thoughtful challenge to my world model.", "tokens": [50944, 639, 575, 668, 534, 286, 1009, 4449, 257, 4420, 293, 21566, 3430, 281, 452, 1002, 2316, 13, 51274], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1934, "seek": 535748, "start": 5376.44, "end": 5378.5599999999995, "text": " You're definitely supplying that.", "tokens": [51312, 509, 434, 2138, 46815, 300, 13, 51418], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1935, "seek": 535748, "start": 5378.5599999999995, "end": 5385.2, "text": " Let's do a couple like a little bit more speculative things that could be kind of M first,", "tokens": [51418, 961, 311, 360, 257, 1916, 411, 257, 707, 857, 544, 49415, 721, 300, 727, 312, 733, 295, 376, 700, 11, 51750], "temperature": 0.0, "avg_logprob": -0.17771792170977352, "compression_ratio": 1.573076923076923, "no_speech_prob": 0.003074253210797906}, {"id": 1936, "seek": 538520, "start": 5385.28, "end": 5388.16, "text": " you know, a little bit of LLM as I was going through the book.", "tokens": [50368, 291, 458, 11, 257, 707, 857, 295, 441, 43, 44, 382, 286, 390, 516, 807, 264, 1446, 13, 50512], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1937, "seek": 538520, "start": 5388.16, "end": 5391.639999999999, "text": " There are a number of things that I was like, hmm, this is really interesting.", "tokens": [50512, 821, 366, 257, 1230, 295, 721, 300, 286, 390, 411, 11, 16478, 11, 341, 307, 534, 1880, 13, 50686], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1938, "seek": 538520, "start": 5392.12, "end": 5394.24, "text": " How would I think about this a bit differently?", "tokens": [50710, 1012, 576, 286, 519, 466, 341, 257, 857, 7614, 30, 50816], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1939, "seek": 538520, "start": 5394.36, "end": 5397.679999999999, "text": " And, you know, and maybe suspend a little bit of your", "tokens": [50822, 400, 11, 291, 458, 11, 293, 1310, 42546, 257, 707, 857, 295, 428, 50988], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1940, "seek": 538520, "start": 5398.5199999999995, "end": 5401.0, "text": " skepticism of how much impact LLM will make.", "tokens": [51030, 19128, 26356, 295, 577, 709, 2712, 441, 43, 44, 486, 652, 13, 51154], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1941, "seek": 538520, "start": 5401.0, "end": 5404.72, "text": " Let's let's go in a world where, you know, scaling continues to work.", "tokens": [51154, 961, 311, 718, 311, 352, 294, 257, 1002, 689, 11, 291, 458, 11, 21589, 6515, 281, 589, 13, 51340], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1942, "seek": 538520, "start": 5404.76, "end": 5406.5199999999995, "text": " Context lengths get long.", "tokens": [51342, 4839, 3828, 26329, 483, 938, 13, 51430], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1943, "seek": 538520, "start": 5406.5199999999995, "end": 5410.84, "text": " You know, we start to see that not total, you know, displacement of humans,", "tokens": [51430, 509, 458, 11, 321, 722, 281, 536, 300, 406, 3217, 11, 291, 458, 11, 21899, 295, 6255, 11, 51646], "temperature": 0.0, "avg_logprob": -0.19218309417025733, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.009121526032686234}, {"id": 1944, "seek": 541084, "start": 5410.84, "end": 5416.64, "text": " but like substantial fraction of, you know, tasks being like LLM, automatable.", "tokens": [50364, 457, 411, 16726, 14135, 295, 11, 291, 458, 11, 9608, 885, 411, 441, 43, 44, 11, 28034, 712, 13, 50654], "temperature": 0.0, "avg_logprob": -0.1728953712864926, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0004727291816379875}, {"id": 1945, "seek": 541084, "start": 5417.16, "end": 5423.08, "text": " One interesting inference that you make is that there won't be that many different base ends", "tokens": [50680, 1485, 1880, 38253, 300, 291, 652, 307, 300, 456, 1582, 380, 312, 300, 867, 819, 3096, 5314, 50976], "temperature": 0.0, "avg_logprob": -0.1728953712864926, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0004727291816379875}, {"id": 1946, "seek": 541084, "start": 5423.4400000000005, "end": 5430.2, "text": " that essentially there will be super selective emmifying of really elite,", "tokens": [50994, 300, 4476, 456, 486, 312, 1687, 33930, 846, 76, 5489, 295, 534, 17801, 11, 51332], "temperature": 0.0, "avg_logprob": -0.1728953712864926, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0004727291816379875}, {"id": 1947, "seek": 541084, "start": 5430.2, "end": 5434.12, "text": " really capable people that those will become the basis that they'll be sort of", "tokens": [51332, 534, 8189, 561, 300, 729, 486, 1813, 264, 5143, 300, 436, 603, 312, 1333, 295, 51528], "temperature": 0.0, "avg_logprob": -0.1728953712864926, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0004727291816379875}, {"id": 1948, "seek": 541084, "start": 5434.92, "end": 5439.88, "text": " essentially turn into kind of clans where they'll they'll highly identify with each other.", "tokens": [51568, 4476, 1261, 666, 733, 295, 596, 599, 689, 436, 603, 436, 603, 5405, 5876, 365, 1184, 661, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1728953712864926, "compression_ratio": 1.7887931034482758, "no_speech_prob": 0.0004727291816379875}, {"id": 1949, "seek": 543988, "start": 5440.16, "end": 5443.64, "text": " And they'll have like, you know, marginally different specialization,", "tokens": [50378, 400, 436, 603, 362, 411, 11, 291, 458, 11, 10270, 379, 819, 2121, 2144, 11, 50552], "temperature": 0.0, "avg_logprob": -0.13009466443743026, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006261955131776631}, {"id": 1950, "seek": 543988, "start": 5443.92, "end": 5448.88, "text": " but that there will be these sort of recognizable, almost canonical personalities", "tokens": [50566, 457, 300, 456, 486, 312, 613, 1333, 295, 40757, 11, 1920, 46491, 25308, 50814], "temperature": 0.0, "avg_logprob": -0.13009466443743026, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006261955131776631}, {"id": 1951, "seek": 543988, "start": 5448.88, "end": 5454.72, "text": " that are not that many of them that kind of come to dominate the economy.", "tokens": [50814, 300, 366, 406, 300, 867, 295, 552, 300, 733, 295, 808, 281, 28246, 264, 5010, 13, 51106], "temperature": 0.0, "avg_logprob": -0.13009466443743026, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006261955131776631}, {"id": 1952, "seek": 543988, "start": 5455.4800000000005, "end": 5459.56, "text": " It seems like we're kind of seeing something similar with language models already,", "tokens": [51144, 467, 2544, 411, 321, 434, 733, 295, 2577, 746, 2531, 365, 2856, 5245, 1217, 11, 51348], "temperature": 0.0, "avg_logprob": -0.13009466443743026, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006261955131776631}, {"id": 1953, "seek": 543988, "start": 5459.56, "end": 5463.72, "text": " where it's like, we have GPT-4, we have, you know, some the new thing from Google,", "tokens": [51348, 689, 309, 311, 411, 11, 321, 362, 26039, 51, 12, 19, 11, 321, 362, 11, 291, 458, 11, 512, 264, 777, 551, 490, 3329, 11, 51556], "temperature": 0.0, "avg_logprob": -0.13009466443743026, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006261955131776631}, {"id": 1954, "seek": 543988, "start": 5463.72, "end": 5466.36, "text": " we have Claude, we have like a couple open source ones.", "tokens": [51556, 321, 362, 12947, 2303, 11, 321, 362, 411, 257, 1916, 1269, 4009, 2306, 13, 51688], "temperature": 0.0, "avg_logprob": -0.13009466443743026, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.0006261955131776631}, {"id": 1955, "seek": 546636, "start": 5466.719999999999, "end": 5472.16, "text": " And then they get like a lot of like local fine tuning and kind of adaptation.", "tokens": [50382, 400, 550, 436, 483, 411, 257, 688, 295, 411, 2654, 2489, 15164, 293, 733, 295, 21549, 13, 50654], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1956, "seek": 546636, "start": 5472.48, "end": 5476.08, "text": " I guess my read on that was that it's an odd, you know, it's initially a very", "tokens": [50670, 286, 2041, 452, 1401, 322, 300, 390, 300, 309, 311, 364, 7401, 11, 291, 458, 11, 309, 311, 9105, 257, 588, 50850], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1957, "seek": 546636, "start": 5476.08, "end": 5478.36, "text": " surprising vision of the future.", "tokens": [50850, 8830, 5201, 295, 264, 2027, 13, 50964], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1958, "seek": 546636, "start": 5478.799999999999, "end": 5482.799999999999, "text": " But it does seem like we see the proto version of that in the development", "tokens": [50986, 583, 309, 775, 1643, 411, 321, 536, 264, 47896, 3037, 295, 300, 294, 264, 3250, 51186], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1959, "seek": 546636, "start": 5482.799999999999, "end": 5484.719999999999, "text": " of large language models.", "tokens": [51186, 295, 2416, 2856, 5245, 13, 51282], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1960, "seek": 546636, "start": 5485.08, "end": 5485.639999999999, "text": " Any thoughts?", "tokens": [51300, 2639, 4598, 30, 51328], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1961, "seek": 546636, "start": 5486.12, "end": 5490.679999999999, "text": " It's basically how many different kinds of jobs are there is the question.", "tokens": [51352, 467, 311, 1936, 577, 867, 819, 3685, 295, 4782, 366, 456, 307, 264, 1168, 13, 51580], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1962, "seek": 546636, "start": 5490.92, "end": 5492.04, "text": " Job tasks are there.", "tokens": [51592, 18602, 9608, 366, 456, 13, 51648], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1963, "seek": 546636, "start": 5492.32, "end": 5494.719999999999, "text": " And so how many dimensions do they vary?", "tokens": [51662, 400, 370, 577, 867, 12819, 360, 436, 10559, 30, 51782], "temperature": 0.0, "avg_logprob": -0.17364812719410863, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.001926396624185145}, {"id": 1964, "seek": 549472, "start": 5495.6, "end": 5500.08, "text": " So I mean, there's clearly a lot of different kinds of jobs.", "tokens": [50408, 407, 286, 914, 11, 456, 311, 4448, 257, 688, 295, 819, 3685, 295, 4782, 13, 50632], "temperature": 0.0, "avg_logprob": -0.11796896173319685, "compression_ratio": 1.7004048582995952, "no_speech_prob": 0.0003053272084798664}, {"id": 1965, "seek": 549472, "start": 5500.56, "end": 5504.6, "text": " Like I told you, the study we did looked at, you know, 900 of them.", "tokens": [50656, 1743, 286, 1907, 291, 11, 264, 2979, 321, 630, 2956, 412, 11, 291, 458, 11, 22016, 295, 552, 13, 50858], "temperature": 0.0, "avg_logprob": -0.11796896173319685, "compression_ratio": 1.7004048582995952, "no_speech_prob": 0.0003053272084798664}, {"id": 1966, "seek": 549472, "start": 5505.320000000001, "end": 5510.16, "text": " But once you look at 900 different jobs, a lot of jobs are pretty similar to each", "tokens": [50894, 583, 1564, 291, 574, 412, 22016, 819, 4782, 11, 257, 688, 295, 4782, 366, 1238, 2531, 281, 1184, 51136], "temperature": 0.0, "avg_logprob": -0.11796896173319685, "compression_ratio": 1.7004048582995952, "no_speech_prob": 0.0003053272084798664}, {"id": 1967, "seek": 549472, "start": 5510.16, "end": 5515.320000000001, "text": " other and they take pretty similar mental styles and personalities to do those jobs.", "tokens": [51136, 661, 293, 436, 747, 1238, 2531, 4973, 13273, 293, 25308, 281, 360, 729, 4782, 13, 51394], "temperature": 0.0, "avg_logprob": -0.11796896173319685, "compression_ratio": 1.7004048582995952, "no_speech_prob": 0.0003053272084798664}, {"id": 1968, "seek": 549472, "start": 5515.72, "end": 5520.240000000001, "text": " So when we're looking at humans at least, it looks like a few hundred", "tokens": [51414, 407, 562, 321, 434, 1237, 412, 6255, 412, 1935, 11, 309, 1542, 411, 257, 1326, 3262, 51640], "temperature": 0.0, "avg_logprob": -0.11796896173319685, "compression_ratio": 1.7004048582995952, "no_speech_prob": 0.0003053272084798664}, {"id": 1969, "seek": 549472, "start": 5520.240000000001, "end": 5523.400000000001, "text": " humans would be enough to do pretty much all the jobs.", "tokens": [51640, 6255, 576, 312, 1547, 281, 360, 1238, 709, 439, 264, 4782, 13, 51798], "temperature": 0.0, "avg_logprob": -0.11796896173319685, "compression_ratio": 1.7004048582995952, "no_speech_prob": 0.0003053272084798664}, {"id": 1970, "seek": 552340, "start": 5524.32, "end": 5526.12, "text": " That's looking at the variation in humans.", "tokens": [50410, 663, 311, 1237, 412, 264, 12990, 294, 6255, 13, 50500], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1971, "seek": 552340, "start": 5526.12, "end": 5530.5199999999995, "text": " Now, the harder part is to say, well, large language models, is there space", "tokens": [50500, 823, 11, 264, 6081, 644, 307, 281, 584, 11, 731, 11, 2416, 2856, 5245, 11, 307, 456, 1901, 50720], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1972, "seek": 552340, "start": 5530.5199999999995, "end": 5534.0, "text": " of dimensional variations similar to humans or is it very different?", "tokens": [50720, 295, 18795, 17840, 2531, 281, 6255, 420, 307, 309, 588, 819, 30, 50894], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1973, "seek": 552340, "start": 5534.0, "end": 5535.24, "text": " That that's much harder to judge.", "tokens": [50894, 663, 300, 311, 709, 6081, 281, 6995, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1974, "seek": 552340, "start": 5535.599999999999, "end": 5539.5199999999995, "text": " But yeah, I would guess that it's in this way, not that different.", "tokens": [50974, 583, 1338, 11, 286, 576, 2041, 300, 309, 311, 294, 341, 636, 11, 406, 300, 819, 13, 51170], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1975, "seek": 552340, "start": 5540.0, "end": 5543.24, "text": " That is, even in large magnum's models, there's a difference where you first", "tokens": [51194, 663, 307, 11, 754, 294, 2416, 4944, 449, 311, 5245, 11, 456, 311, 257, 2649, 689, 291, 700, 51356], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1976, "seek": 552340, "start": 5543.24, "end": 5545.44, "text": " you train a basic model and that's a lot of work.", "tokens": [51356, 291, 3847, 257, 3875, 2316, 293, 300, 311, 257, 688, 295, 589, 13, 51466], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1977, "seek": 552340, "start": 5545.44, "end": 5547.16, "text": " And then you train variations on it.", "tokens": [51466, 400, 550, 291, 3847, 17840, 322, 309, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1978, "seek": 552340, "start": 5547.92, "end": 5552.5199999999995, "text": " And it does look like the variations are mostly enough to encompass a pretty", "tokens": [51590, 400, 309, 775, 574, 411, 264, 17840, 366, 5240, 1547, 281, 28268, 257, 1238, 51820], "temperature": 0.0, "avg_logprob": -0.1805436907023409, "compression_ratio": 1.787162162162162, "no_speech_prob": 0.0007792442920617759}, {"id": 1979, "seek": 555252, "start": 5552.52, "end": 5553.68, "text": " wide range of tasks.", "tokens": [50364, 4874, 3613, 295, 9608, 13, 50422], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1980, "seek": 555252, "start": 5554.8, "end": 5561.56, "text": " And so you need a small number of base approaches and then a lot more cheaper", "tokens": [50478, 400, 370, 291, 643, 257, 1359, 1230, 295, 3096, 11587, 293, 550, 257, 688, 544, 12284, 50816], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1981, "seek": 555252, "start": 5561.56, "end": 5563.96, "text": " variations that are enough to do particular things.", "tokens": [50816, 17840, 300, 366, 1547, 281, 360, 1729, 721, 13, 50936], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1982, "seek": 555252, "start": 5565.080000000001, "end": 5568.92, "text": " So certainly that's, you know, a remarkable fact in some sense about", "tokens": [50992, 407, 3297, 300, 311, 11, 291, 458, 11, 257, 12802, 1186, 294, 512, 2020, 466, 51184], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1983, "seek": 555252, "start": 5569.0, "end": 5572.84, "text": " large language models is the range of different tasks they can do starting", "tokens": [51188, 2416, 2856, 5245, 307, 264, 3613, 295, 819, 9608, 436, 393, 360, 2891, 51380], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1984, "seek": 555252, "start": 5572.84, "end": 5574.080000000001, "text": " with the same system, right?", "tokens": [51380, 365, 264, 912, 1185, 11, 558, 30, 51442], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1985, "seek": 555252, "start": 5574.88, "end": 5577.080000000001, "text": " And so they have a degree of generality that way.", "tokens": [51482, 400, 370, 436, 362, 257, 4314, 295, 1337, 1860, 300, 636, 13, 51592], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1986, "seek": 555252, "start": 5577.64, "end": 5580.8, "text": " And, you know, humans in some sense have a degree of generality that way where", "tokens": [51620, 400, 11, 291, 458, 11, 6255, 294, 512, 2020, 362, 257, 4314, 295, 1337, 1860, 300, 636, 689, 51778], "temperature": 0.0, "avg_logprob": -0.16150099830289857, "compression_ratio": 1.779527559055118, "no_speech_prob": 0.0005526546738110483}, {"id": 1987, "seek": 558080, "start": 5581.16, "end": 5584.76, "text": " we are able to do, able to learn to do a pretty wide range of things.", "tokens": [50382, 321, 366, 1075, 281, 360, 11, 1075, 281, 1466, 281, 360, 257, 1238, 4874, 3613, 295, 721, 13, 50562], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1988, "seek": 558080, "start": 5585.88, "end": 5589.84, "text": " So yeah, I would, and I don't know if it's going to be just four, as opposed", "tokens": [50618, 407, 1338, 11, 286, 576, 11, 293, 286, 500, 380, 458, 498, 309, 311, 516, 281, 312, 445, 1451, 11, 382, 8851, 50816], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1989, "seek": 558080, "start": 5589.84, "end": 5594.360000000001, "text": " to 40 or 400, that's harder to say, but in some sense, it could be one or two.", "tokens": [50816, 281, 3356, 420, 8423, 11, 300, 311, 6081, 281, 584, 11, 457, 294, 512, 2020, 11, 309, 727, 312, 472, 420, 732, 13, 51042], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1990, "seek": 558080, "start": 5594.400000000001, "end": 5599.360000000001, "text": " I mean, even in the age of M, I was giving the few hundred as an upper limit.", "tokens": [51044, 286, 914, 11, 754, 294, 264, 3205, 295, 376, 11, 286, 390, 2902, 264, 1326, 3262, 382, 364, 6597, 4948, 13, 51292], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1991, "seek": 558080, "start": 5599.4800000000005, "end": 5601.08, "text": " It could turn out to be much lower.", "tokens": [51298, 467, 727, 1261, 484, 281, 312, 709, 3126, 13, 51378], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1992, "seek": 558080, "start": 5602.16, "end": 5607.400000000001, "text": " It really depends on how much sort of, you know, quick, fast, last minute", "tokens": [51432, 467, 534, 5946, 322, 577, 709, 1333, 295, 11, 291, 458, 11, 1702, 11, 2370, 11, 1036, 3456, 51694], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1993, "seek": 558080, "start": 5607.400000000001, "end": 5610.4400000000005, "text": " variation can actually encompass the range of differences.", "tokens": [51694, 12990, 393, 767, 28268, 264, 3613, 295, 7300, 13, 51846], "temperature": 0.0, "avg_logprob": -0.11311826352719907, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.0012446361361071467}, {"id": 1994, "seek": 561080, "start": 5610.84, "end": 5615.92, "text": " If differences are so much shallow and surface, which not really fundamental,", "tokens": [50366, 759, 7300, 366, 370, 709, 20488, 293, 3753, 11, 597, 406, 534, 8088, 11, 50620], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 1995, "seek": 561080, "start": 5615.92, "end": 5618.8, "text": " then yeah, last minute variation might be enough.", "tokens": [50620, 550, 1338, 11, 1036, 3456, 12990, 1062, 312, 1547, 13, 50764], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 1996, "seek": 561080, "start": 5619.4800000000005, "end": 5622.24, "text": " Another interesting assumption, this one, I think is more of a contrast", "tokens": [50798, 3996, 1880, 15302, 11, 341, 472, 11, 286, 519, 307, 544, 295, 257, 8712, 50936], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 1997, "seek": 561080, "start": 5622.24, "end": 5626.6, "text": " with the language models is, and we talked with this briefly earlier", "tokens": [50936, 365, 264, 2856, 5245, 307, 11, 293, 321, 2825, 365, 341, 10515, 3071, 51154], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 1998, "seek": 561080, "start": 5626.6, "end": 5631.8, "text": " that the M's, they can be easily cloned, but they can't be easily merged.", "tokens": [51154, 300, 264, 376, 311, 11, 436, 393, 312, 3612, 596, 19009, 11, 457, 436, 393, 380, 312, 3612, 36427, 13, 51414], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 1999, "seek": 561080, "start": 5631.8, "end": 5636.12, "text": " In other words, like, you know, because we don't have a great sense of how", "tokens": [51414, 682, 661, 2283, 11, 411, 11, 291, 458, 11, 570, 321, 500, 380, 362, 257, 869, 2020, 295, 577, 51630], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 2000, "seek": 561080, "start": 5636.12, "end": 5639.2, "text": " exactly it works inside and what internal states are meaningful, we can't", "tokens": [51630, 2293, 309, 1985, 1854, 293, 437, 6920, 4368, 366, 10995, 11, 321, 393, 380, 51784], "temperature": 0.0, "avg_logprob": -0.150934632619222, "compression_ratio": 1.6531986531986531, "no_speech_prob": 9.608775872038677e-05}, {"id": 2001, "seek": 563920, "start": 5639.2, "end": 5641.5199999999995, "text": " just like superimpose them on top of one another.", "tokens": [50364, 445, 411, 1687, 8814, 541, 552, 322, 1192, 295, 472, 1071, 13, 50480], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2002, "seek": 563920, "start": 5642.36, "end": 5645.679999999999, "text": " Language models, it seems like we are making actually a lot more progress on", "tokens": [50522, 24445, 5245, 11, 309, 2544, 411, 321, 366, 1455, 767, 257, 688, 544, 4205, 322, 50688], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2003, "seek": 563920, "start": 5645.679999999999, "end": 5646.28, "text": " that front.", "tokens": [50688, 300, 1868, 13, 50718], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2004, "seek": 563920, "start": 5646.32, "end": 5651.16, "text": " It's not a solved problem, but there are techniques for merging.", "tokens": [50720, 467, 311, 406, 257, 13041, 1154, 11, 457, 456, 366, 7512, 337, 44559, 13, 50962], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2005, "seek": 563920, "start": 5651.16, "end": 5653.72, "text": " There are techniques for like training separately and combining.", "tokens": [50962, 821, 366, 7512, 337, 411, 3097, 14759, 293, 21928, 13, 51090], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2006, "seek": 563920, "start": 5653.72, "end": 5657.5599999999995, "text": " There are these sort of many Q-Loras techniques.", "tokens": [51090, 821, 366, 613, 1333, 295, 867, 1249, 12, 43, 40928, 7512, 13, 51282], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2007, "seek": 563920, "start": 5657.5599999999995, "end": 5661.96, "text": " People are exploring those, but like, notice that to make GPT-4, you didn't", "tokens": [51282, 3432, 366, 12736, 729, 11, 457, 411, 11, 3449, 300, 281, 652, 26039, 51, 12, 19, 11, 291, 994, 380, 51502], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2008, "seek": 563920, "start": 5661.96, "end": 5664.599999999999, "text": " start with GPT-3 and add more training.", "tokens": [51502, 722, 365, 26039, 51, 12, 18, 293, 909, 544, 3097, 13, 51634], "temperature": 0.0, "avg_logprob": -0.153503882366678, "compression_ratio": 1.6718146718146718, "no_speech_prob": 0.0018096850253641605}, {"id": 2009, "seek": 566460, "start": 5664.92, "end": 5669.240000000001, "text": " You started with a blank network and you started from scratch.", "tokens": [50380, 509, 1409, 365, 257, 8247, 3209, 293, 291, 1409, 490, 8459, 13, 50596], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2010, "seek": 566460, "start": 5669.240000000001, "end": 5672.160000000001, "text": " And that's consistently what we've seen in AI over decades.", "tokens": [50596, 400, 300, 311, 14961, 437, 321, 600, 1612, 294, 7318, 670, 7878, 13, 50742], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2011, "seek": 566460, "start": 5672.4800000000005, "end": 5677.400000000001, "text": " Every new model does not start with an old model and train it to be better.", "tokens": [50758, 2048, 777, 2316, 775, 406, 722, 365, 364, 1331, 2316, 293, 3847, 309, 281, 312, 1101, 13, 51004], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2012, "seek": 566460, "start": 5677.4800000000005, "end": 5681.76, "text": " You start with a blank representation and you train it from scratch.", "tokens": [51008, 509, 722, 365, 257, 8247, 10290, 293, 291, 3847, 309, 490, 8459, 13, 51222], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2013, "seek": 566460, "start": 5682.200000000001, "end": 5684.96, "text": " And that's consistently how we've made new systems over time.", "tokens": [51244, 400, 300, 311, 14961, 577, 321, 600, 1027, 777, 3652, 670, 565, 13, 51382], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2014, "seek": 566460, "start": 5685.72, "end": 5688.8, "text": " So that's a substantial degree of not being able to merge.", "tokens": [51420, 407, 300, 311, 257, 16726, 4314, 295, 406, 885, 1075, 281, 22183, 13, 51574], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2015, "seek": 566460, "start": 5690.160000000001, "end": 5691.4400000000005, "text": " And that's quite different than humans.", "tokens": [51642, 400, 300, 311, 1596, 819, 813, 6255, 13, 51706], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2016, "seek": 566460, "start": 5691.4400000000005, "end": 5694.4400000000005, "text": " I mean, often to get a human to do a new task, you want to take", "tokens": [51706, 286, 914, 11, 2049, 281, 483, 257, 1952, 281, 360, 257, 777, 5633, 11, 291, 528, 281, 747, 51856], "temperature": 0.0, "avg_logprob": -0.12048612976074219, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.06557197868824005}, {"id": 2017, "seek": 569444, "start": 5694.44, "end": 5697.32, "text": " a human who can do lots of previous tasks because they can more quickly", "tokens": [50364, 257, 1952, 567, 393, 360, 3195, 295, 3894, 9608, 570, 436, 393, 544, 2661, 50508], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2018, "seek": 569444, "start": 5697.32, "end": 5698.879999999999, "text": " learn how to do this new task.", "tokens": [50508, 1466, 577, 281, 360, 341, 777, 5633, 13, 50586], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2019, "seek": 569444, "start": 5700.04, "end": 5701.759999999999, "text": " And that's just not what we're seeing.", "tokens": [50644, 400, 300, 311, 445, 406, 437, 321, 434, 2577, 13, 50730], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2020, "seek": 569444, "start": 5701.759999999999, "end": 5707.04, "text": " Like you try to take, I don't know, Claude and GPT-4 and, you know,", "tokens": [50730, 1743, 291, 853, 281, 747, 11, 286, 500, 380, 458, 11, 12947, 2303, 293, 26039, 51, 12, 19, 293, 11, 291, 458, 11, 50994], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2021, "seek": 569444, "start": 5707.4, "end": 5709.0, "text": " grok and merge them.", "tokens": [51012, 4634, 74, 293, 22183, 552, 13, 51092], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2022, "seek": 569444, "start": 5709.879999999999, "end": 5714.4, "text": " I mean, I just don't think anybody knows how to do such a merge today.", "tokens": [51136, 286, 914, 11, 286, 445, 500, 380, 519, 4472, 3255, 577, 281, 360, 1270, 257, 22183, 965, 13, 51362], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2023, "seek": 569444, "start": 5714.599999999999, "end": 5717.08, "text": " There's no sensible way you could do such a merge.", "tokens": [51372, 821, 311, 572, 25380, 636, 291, 727, 360, 1270, 257, 22183, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2024, "seek": 569444, "start": 5718.24, "end": 5721.599999999999, "text": " You could take Claude and then do all the training that you would have", "tokens": [51554, 509, 727, 747, 12947, 2303, 293, 550, 360, 439, 264, 3097, 300, 291, 576, 362, 51722], "temperature": 0.0, "avg_logprob": -0.11801990385978453, "compression_ratio": 1.6588235294117648, "no_speech_prob": 0.0015008357586339116}, {"id": 2025, "seek": 572160, "start": 5721.6, "end": 5724.200000000001, "text": " done on GPT-4 except do it starting from Claude.", "tokens": [50364, 1096, 322, 26039, 51, 12, 19, 3993, 360, 309, 2891, 490, 12947, 2303, 13, 50494], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2026, "seek": 572160, "start": 5724.200000000001, "end": 5727.52, "text": " And I think people think that would be worse than starting with the blank", "tokens": [50494, 400, 286, 519, 561, 519, 300, 576, 312, 5324, 813, 2891, 365, 264, 8247, 50660], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2027, "seek": 572160, "start": 5727.84, "end": 5729.360000000001, "text": " representation as they usually do.", "tokens": [50676, 10290, 382, 436, 2673, 360, 13, 50752], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2028, "seek": 572160, "start": 5730.0, "end": 5732.160000000001, "text": " Yeah, I think that's definitely not a solved problem today.", "tokens": [50784, 865, 11, 286, 519, 300, 311, 2138, 406, 257, 13041, 1154, 965, 13, 50892], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2029, "seek": 572160, "start": 5732.200000000001, "end": 5737.56, "text": " And I wouldn't claim that you can just like drop Claude and GPT-4 on top of each other.", "tokens": [50894, 400, 286, 2759, 380, 3932, 300, 291, 393, 445, 411, 3270, 12947, 2303, 293, 26039, 51, 12, 19, 322, 1192, 295, 1184, 661, 13, 51162], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2030, "seek": 572160, "start": 5737.56, "end": 5741.240000000001, "text": " But there are enough early results in this that it seems much more plausible.", "tokens": [51162, 583, 456, 366, 1547, 2440, 3542, 294, 341, 300, 309, 2544, 709, 544, 39925, 13, 51346], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2031, "seek": 572160, "start": 5741.240000000001, "end": 5745.120000000001, "text": " Plus we have like the full wiring diagram, you know, and the ability to kind of", "tokens": [51346, 7721, 321, 362, 411, 264, 1577, 27520, 10686, 11, 291, 458, 11, 293, 264, 3485, 281, 733, 295, 51540], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2032, "seek": 572160, "start": 5745.160000000001, "end": 5748.160000000001, "text": " X-ray internal states with, you know, perfect finality.", "tokens": [51542, 1783, 12, 3458, 6920, 4368, 365, 11, 291, 458, 11, 2176, 962, 1860, 13, 51692], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2033, "seek": 572160, "start": 5748.160000000001, "end": 5751.160000000001, "text": " It seems like there is a much more likely path.", "tokens": [51692, 467, 2544, 411, 456, 307, 257, 709, 544, 3700, 3100, 13, 51842], "temperature": 0.0, "avg_logprob": -0.12146297661033836, "compression_ratio": 1.6925373134328359, "no_speech_prob": 0.0009696411434561014}, {"id": 2034, "seek": 575160, "start": 5752.160000000001, "end": 5753.76, "text": " Forget about the plausibility for a second.", "tokens": [50392, 18675, 466, 264, 34946, 2841, 337, 257, 1150, 13, 50472], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2035, "seek": 575160, "start": 5753.76, "end": 5761.56, "text": " What do you think it would mean if the AIs could be kind of divergent, but also re-mergeable?", "tokens": [50472, 708, 360, 291, 519, 309, 576, 914, 498, 264, 316, 6802, 727, 312, 733, 295, 18558, 6930, 11, 457, 611, 319, 12, 936, 432, 712, 30, 50862], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2036, "seek": 575160, "start": 5762.56, "end": 5764.52, "text": " I think the fundamental issue here is ROT.", "tokens": [50912, 286, 519, 264, 8088, 2734, 510, 307, 497, 5068, 13, 51010], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2037, "seek": 575160, "start": 5764.52, "end": 5767.8, "text": " So we see ROT in software, especially with large legacy systems.", "tokens": [51010, 407, 321, 536, 497, 5068, 294, 4722, 11, 2318, 365, 2416, 11711, 3652, 13, 51174], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2038, "seek": 575160, "start": 5767.8, "end": 5769.92, "text": " We see ROT in the human brain.", "tokens": [51174, 492, 536, 497, 5068, 294, 264, 1952, 3567, 13, 51280], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2039, "seek": 575160, "start": 5769.92, "end": 5773.280000000001, "text": " I think we have to expect ROT is happening in large language models, too.", "tokens": [51280, 286, 519, 321, 362, 281, 2066, 497, 5068, 307, 2737, 294, 2416, 2856, 5245, 11, 886, 13, 51448], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2040, "seek": 575160, "start": 5773.64, "end": 5778.6, "text": " ROT is the reason why you don't start with old things and modify them.", "tokens": [51466, 497, 5068, 307, 264, 1778, 983, 291, 500, 380, 722, 365, 1331, 721, 293, 16927, 552, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2041, "seek": 575160, "start": 5778.6, "end": 5779.320000000001, "text": " You start from scratch.", "tokens": [51714, 509, 722, 490, 8459, 13, 51750], "temperature": 0.0, "avg_logprob": -0.14410894775390626, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.000939790450502187}, {"id": 2042, "seek": 577932, "start": 5779.36, "end": 5783.24, "text": " That is basically when you have a large old legacy piece of software, you could", "tokens": [50366, 663, 307, 1936, 562, 291, 362, 257, 2416, 1331, 11711, 2522, 295, 4722, 11, 291, 727, 50560], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2043, "seek": 577932, "start": 5783.24, "end": 5784.5599999999995, "text": " keep trying to modify to improve it.", "tokens": [50560, 1066, 1382, 281, 16927, 281, 3470, 309, 13, 50626], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2044, "seek": 577932, "start": 5784.5599999999995, "end": 5788.28, "text": " But typically at some point, you just throw it all away and start from scratching it.", "tokens": [50626, 583, 5850, 412, 512, 935, 11, 291, 445, 3507, 309, 439, 1314, 293, 722, 490, 29699, 309, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2045, "seek": 577932, "start": 5788.92, "end": 5792.12, "text": " People get a lot of advantage about being able to start from scratch.", "tokens": [50844, 3432, 483, 257, 688, 295, 5002, 466, 885, 1075, 281, 722, 490, 8459, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2046, "seek": 577932, "start": 5792.12, "end": 5794.719999999999, "text": " And that's because old, large things rot.", "tokens": [51004, 400, 300, 311, 570, 1331, 11, 2416, 721, 4297, 13, 51134], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2047, "seek": 577932, "start": 5795.759999999999, "end": 5800.36, "text": " And my best guess is that that will continue to be true for large language models", "tokens": [51186, 400, 452, 1151, 2041, 307, 300, 300, 486, 2354, 281, 312, 2074, 337, 2416, 2856, 5245, 51416], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2048, "seek": 577932, "start": 5800.36, "end": 5801.799999999999, "text": " and all the kinds of AIs we develop.", "tokens": [51416, 293, 439, 264, 3685, 295, 316, 6802, 321, 1499, 13, 51488], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2049, "seek": 577932, "start": 5801.799999999999, "end": 5807.5199999999995, "text": " We will continue to struggle with ROT as a general problem indefinitely.", "tokens": [51488, 492, 486, 2354, 281, 7799, 365, 497, 5068, 382, 257, 2674, 1154, 24162, 10925, 13, 51774], "temperature": 0.0, "avg_logprob": -0.1563452606201172, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0019875287543982267}, {"id": 2050, "seek": 580752, "start": 5807.88, "end": 5812.52, "text": " And this is actually a reason why you should doubt the image of the one super AI", "tokens": [50382, 400, 341, 307, 767, 257, 1778, 983, 291, 820, 6385, 264, 3256, 295, 264, 472, 1687, 7318, 50614], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2051, "seek": 580752, "start": 5812.52, "end": 5816.84, "text": " that lasts forever, because the one super AI that lasts forever will rot.", "tokens": [50614, 300, 20669, 5680, 11, 570, 264, 472, 1687, 7318, 300, 20669, 5680, 486, 4297, 13, 50830], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2052, "seek": 580752, "start": 5817.92, "end": 5822.0, "text": " And in some sense, to maintain functionality and flexibility would have", "tokens": [50884, 400, 294, 512, 2020, 11, 281, 6909, 14980, 293, 12635, 576, 362, 51088], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2053, "seek": 580752, "start": 5822.0, "end": 5827.040000000001, "text": " to replace itself with new, fresh versions periodically, which then could be", "tokens": [51088, 281, 7406, 2564, 365, 777, 11, 4451, 9606, 38916, 11, 597, 550, 727, 312, 51340], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2054, "seek": 580752, "start": 5827.040000000001, "end": 5828.0, "text": " substantially different.", "tokens": [51340, 30797, 819, 13, 51388], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2055, "seek": 580752, "start": 5828.88, "end": 5832.040000000001, "text": " And, you know, that's in some sense how biologies work, too.", "tokens": [51432, 400, 11, 291, 458, 11, 300, 311, 294, 512, 2020, 577, 3228, 6204, 589, 11, 886, 13, 51590], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2056, "seek": 580752, "start": 5832.4400000000005, "end": 5835.84, "text": " Biology could have somehow made organisms that lasted forever, but it didn't.", "tokens": [51610, 48132, 727, 362, 6063, 1027, 22110, 300, 21116, 5680, 11, 457, 309, 994, 380, 13, 51780], "temperature": 0.0, "avg_logprob": -0.16308142285828198, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0026301874313503504}, {"id": 2057, "seek": 583584, "start": 5835.84, "end": 5839.52, "text": " It made organisms that rot over time and get replaced by babies that start", "tokens": [50364, 467, 1027, 22110, 300, 4297, 670, 565, 293, 483, 10772, 538, 10917, 300, 722, 50548], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2058, "seek": 583584, "start": 5839.52, "end": 5840.72, "text": " out fresh and rot again.", "tokens": [50548, 484, 4451, 293, 4297, 797, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2059, "seek": 583584, "start": 5841.92, "end": 5844.52, "text": " And that's just been the nature of how biology figures.", "tokens": [50668, 400, 300, 311, 445, 668, 264, 3687, 295, 577, 14956, 9624, 13, 50798], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2060, "seek": 583584, "start": 5844.52, "end": 5846.0, "text": " And that's how our economy works.", "tokens": [50798, 400, 300, 311, 577, 527, 5010, 1985, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2061, "seek": 583584, "start": 5846.56, "end": 5850.32, "text": " We could have had the same companies as we did a century ago, running the economy,", "tokens": [50900, 492, 727, 362, 632, 264, 912, 3431, 382, 321, 630, 257, 4901, 2057, 11, 2614, 264, 5010, 11, 51088], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2062, "seek": 583584, "start": 5850.32, "end": 5852.4400000000005, "text": " just changing and adapting to new circumstances.", "tokens": [51088, 445, 4473, 293, 34942, 281, 777, 9121, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2063, "seek": 583584, "start": 5852.4400000000005, "end": 5853.04, "text": " But we don't.", "tokens": [51194, 583, 321, 500, 380, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2064, "seek": 583584, "start": 5853.08, "end": 5856.04, "text": " Old companies rot in good eye away and get replaced by new companies.", "tokens": [51226, 8633, 3431, 4297, 294, 665, 3313, 1314, 293, 483, 10772, 538, 777, 3431, 13, 51374], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2065, "seek": 583584, "start": 5856.56, "end": 5861.56, "text": " And I predict in the age of M that M's would in fact rot with time and therefore", "tokens": [51400, 400, 286, 6069, 294, 264, 3205, 295, 376, 300, 376, 311, 576, 294, 1186, 4297, 365, 565, 293, 4412, 51650], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2066, "seek": 583584, "start": 5861.56, "end": 5865.64, "text": " no longer be productive and have to be retired and be replaced by young M's.", "tokens": [51650, 572, 2854, 312, 13304, 293, 362, 281, 312, 16776, 293, 312, 10772, 538, 2037, 376, 311, 13, 51854], "temperature": 0.0, "avg_logprob": -0.1435723640549351, "compression_ratio": 1.7929936305732483, "no_speech_prob": 0.00043046893551945686}, {"id": 2067, "seek": 586584, "start": 5866.8, "end": 5870.8, "text": " And that's a key part of the age of M's that I think would generalize to the AI", "tokens": [50412, 400, 300, 311, 257, 2141, 644, 295, 264, 3205, 295, 376, 311, 300, 286, 519, 576, 2674, 1125, 281, 264, 7318, 50612], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2068, "seek": 586584, "start": 5870.8, "end": 5877.4800000000005, "text": " world. I think in fact, rot is such a severe and irredeemable problem that", "tokens": [50612, 1002, 13, 286, 519, 294, 1186, 11, 4297, 307, 1270, 257, 8922, 293, 3418, 986, 68, 443, 712, 1154, 300, 50946], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2069, "seek": 586584, "start": 5877.4800000000005, "end": 5881.28, "text": " AI's will have to deal with rot in roughly the same way everybody else has.", "tokens": [50946, 7318, 311, 486, 362, 281, 2028, 365, 4297, 294, 9810, 264, 912, 636, 2201, 1646, 575, 13, 51136], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2070, "seek": 586584, "start": 5881.28, "end": 5885.76, "text": " I.e. make systems, let them grow, become capable, slowly rot and get replaced by new", "tokens": [51136, 286, 13, 68, 13, 652, 3652, 11, 718, 552, 1852, 11, 1813, 8189, 11, 5692, 4297, 293, 483, 10772, 538, 777, 51360], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2071, "seek": 586584, "start": 5885.76, "end": 5889.4800000000005, "text": " systems. And then the challenge will always be, how can the new systems learn", "tokens": [51360, 3652, 13, 400, 550, 264, 3430, 486, 1009, 312, 11, 577, 393, 264, 777, 3652, 1466, 51546], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2072, "seek": 586584, "start": 5889.4800000000005, "end": 5890.400000000001, "text": " from the old ones?", "tokens": [51546, 490, 264, 1331, 2306, 30, 51592], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2073, "seek": 586584, "start": 5891.88, "end": 5895.56, "text": " How can the old ones teach the new ones what they've learned without", "tokens": [51666, 1012, 393, 264, 1331, 2306, 2924, 264, 777, 2306, 437, 436, 600, 3264, 1553, 51850], "temperature": 0.0, "avg_logprob": -0.17261773622952975, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.0006877068080939353}, {"id": 2074, "seek": 589556, "start": 5895.6, "end": 5896.52, "text": " passing on the rot?", "tokens": [50366, 8437, 322, 264, 4297, 30, 50412], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2075, "seek": 589556, "start": 5897.4400000000005, "end": 5901.4800000000005, "text": " And that's a long time design problem that we're going to face in large", "tokens": [50458, 400, 300, 311, 257, 938, 565, 1715, 1154, 300, 321, 434, 516, 281, 1851, 294, 2416, 50660], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2076, "seek": 589556, "start": 5901.4800000000005, "end": 5902.280000000001, "text": " language models even.", "tokens": [50660, 2856, 5245, 754, 13, 50700], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2077, "seek": 589556, "start": 5903.080000000001, "end": 5906.6, "text": " I think, you know, in a few years, a company will have had a large language", "tokens": [50740, 286, 519, 11, 291, 458, 11, 294, 257, 1326, 924, 11, 257, 2237, 486, 362, 632, 257, 2416, 2856, 50916], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2078, "seek": 589556, "start": 5906.6, "end": 5909.84, "text": " model. They've been building up for a while to train, you know, to talk to", "tokens": [50916, 2316, 13, 814, 600, 668, 2390, 493, 337, 257, 1339, 281, 3847, 11, 291, 458, 11, 281, 751, 281, 51078], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2079, "seek": 589556, "start": 5909.84, "end": 5912.0, "text": " customers or something. And then it'll be rotting.", "tokens": [51078, 4581, 420, 746, 13, 400, 550, 309, 603, 312, 4297, 783, 13, 51186], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2080, "seek": 589556, "start": 5912.4800000000005, "end": 5916.76, "text": " And they'll wonder, well, how can we make a new one that inherits all the things", "tokens": [51210, 400, 436, 603, 2441, 11, 731, 11, 577, 393, 321, 652, 257, 777, 472, 300, 9484, 1208, 439, 264, 721, 51424], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2081, "seek": 589556, "start": 5916.76, "end": 5917.84, "text": " we've taught this old one?", "tokens": [51424, 321, 600, 5928, 341, 1331, 472, 30, 51478], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2082, "seek": 589556, "start": 5917.96, "end": 5919.080000000001, "text": " And they'll struggle with that.", "tokens": [51484, 400, 436, 603, 7799, 365, 300, 13, 51540], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2083, "seek": 589556, "start": 5920.320000000001, "end": 5922.6, "text": " They can't just move the system over.", "tokens": [51602, 814, 393, 380, 445, 1286, 264, 1185, 670, 13, 51716], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2084, "seek": 589556, "start": 5922.6, "end": 5925.0, "text": " They'll have to have maybe the same training sets or something.", "tokens": [51716, 814, 603, 362, 281, 362, 1310, 264, 912, 3097, 6352, 420, 746, 13, 51836], "temperature": 0.0, "avg_logprob": -0.13274066063665574, "compression_ratio": 1.7852564102564104, "no_speech_prob": 0.001031898194923997}, {"id": 2085, "seek": 592500, "start": 5925.0, "end": 5926.16, "text": " They have to collect training sets.", "tokens": [50364, 814, 362, 281, 2500, 3097, 6352, 13, 50422], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2086, "seek": 592500, "start": 5926.16, "end": 5928.44, "text": " They're going to apply to the new system, like the old one.", "tokens": [50422, 814, 434, 516, 281, 3079, 281, 264, 777, 1185, 11, 411, 264, 1331, 472, 13, 50536], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2087, "seek": 592500, "start": 5929.0, "end": 5933.68, "text": " But that will continue to be a problem in AI as it has been an all", "tokens": [50564, 583, 300, 486, 2354, 281, 312, 257, 1154, 294, 7318, 382, 309, 575, 668, 364, 439, 50798], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2088, "seek": 592500, "start": 5933.88, "end": 5935.12, "text": " complicated system so far.", "tokens": [50808, 6179, 1185, 370, 1400, 13, 50870], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2089, "seek": 592500, "start": 5935.8, "end": 5936.6, "text": " Yeah, interesting.", "tokens": [50904, 865, 11, 1880, 13, 50944], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2090, "seek": 592500, "start": 5936.6, "end": 5941.84, "text": " I think that is a pretty compelling argument for like medium and long", "tokens": [50944, 286, 519, 300, 307, 257, 1238, 20050, 6770, 337, 411, 6399, 293, 938, 51206], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2091, "seek": 592500, "start": 5942.12, "end": 5943.12, "text": " time scales.", "tokens": [51220, 565, 17408, 13, 51270], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2092, "seek": 592500, "start": 5943.6, "end": 5946.76, "text": " And I can even see that it, you know, already like open AI supports, for", "tokens": [51294, 400, 286, 393, 754, 536, 300, 309, 11, 291, 458, 11, 1217, 411, 1269, 7318, 9346, 11, 337, 51452], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2093, "seek": 592500, "start": 5946.76, "end": 5950.44, "text": " example, fine tuning on a previously fine tuned model.", "tokens": [51452, 1365, 11, 2489, 15164, 322, 257, 8046, 2489, 10870, 2316, 13, 51636], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2094, "seek": 592500, "start": 5951.0, "end": 5952.92, "text": " And I don't in practice use it.", "tokens": [51664, 400, 286, 500, 380, 294, 3124, 764, 309, 13, 51760], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2095, "seek": 592500, "start": 5953.64, "end": 5954.72, "text": " I'm not sure how many do.", "tokens": [51796, 286, 478, 406, 988, 577, 867, 360, 13, 51850], "temperature": 0.0, "avg_logprob": -0.18242187211007782, "compression_ratio": 1.6335616438356164, "no_speech_prob": 0.00022337651171255857}, {"id": 2096, "seek": 595500, "start": 5955.04, "end": 5959.56, "text": " What I do think is still a plausibly very interesting kind of fork and merge", "tokens": [50366, 708, 286, 360, 519, 307, 920, 257, 34946, 3545, 588, 1880, 733, 295, 17716, 293, 22183, 50592], "temperature": 0.0, "avg_logprob": -0.1927297848921556, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.00014422790263779461}, {"id": 2097, "seek": 595500, "start": 5960.12, "end": 5965.32, "text": " is, you know, like with these new state space models, it seems that you could", "tokens": [50620, 307, 11, 291, 458, 11, 411, 365, 613, 777, 1785, 1901, 5245, 11, 309, 2544, 300, 291, 727, 50880], "temperature": 0.0, "avg_logprob": -0.1927297848921556, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.00014422790263779461}, {"id": 2098, "seek": 595500, "start": 5965.48, "end": 5969.64, "text": " like one remarkably difficult challenge for a language model is scan", "tokens": [50888, 411, 472, 37381, 2252, 3430, 337, 257, 2856, 2316, 307, 11049, 51096], "temperature": 0.0, "avg_logprob": -0.1927297848921556, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.00014422790263779461}, {"id": 2099, "seek": 595500, "start": 5969.64, "end": 5972.48, "text": " through my email and find what's relevant.", "tokens": [51096, 807, 452, 3796, 293, 915, 437, 311, 7340, 13, 51238], "temperature": 0.0, "avg_logprob": -0.1927297848921556, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.00014422790263779461}, {"id": 2100, "seek": 595500, "start": 5972.72, "end": 5978.48, "text": " You know, it's like it has a hard time doing that for a couple of different", "tokens": [51250, 509, 458, 11, 309, 311, 411, 309, 575, 257, 1152, 565, 884, 300, 337, 257, 1916, 295, 819, 51538], "temperature": 0.0, "avg_logprob": -0.1927297848921556, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.00014422790263779461}, {"id": 2101, "seek": 595500, "start": 5978.64, "end": 5982.36, "text": " reasons, you know, find a context window and I just have a lot of email.", "tokens": [51546, 4112, 11, 291, 458, 11, 915, 257, 4319, 4910, 293, 286, 445, 362, 257, 688, 295, 3796, 13, 51732], "temperature": 0.0, "avg_logprob": -0.1927297848921556, "compression_ratio": 1.6338582677165354, "no_speech_prob": 0.00014422790263779461}, {"id": 2102, "seek": 598236, "start": 5983.0, "end": 5986.759999999999, "text": " With the state space models, I do think you could clone, you know, or", "tokens": [50396, 2022, 264, 1785, 1901, 5245, 11, 286, 360, 519, 291, 727, 26506, 11, 291, 458, 11, 420, 50584], "temperature": 0.0, "avg_logprob": -0.13942278704596955, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.0007095870096236467}, {"id": 2103, "seek": 598236, "start": 5986.759999999999, "end": 5991.2, "text": " paralyze, have them each kind of process a certain amount and literally", "tokens": [50584, 32645, 1381, 11, 362, 552, 1184, 733, 295, 1399, 257, 1629, 2372, 293, 3736, 50806], "temperature": 0.0, "avg_logprob": -0.13942278704596955, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.0007095870096236467}, {"id": 2104, "seek": 598236, "start": 5991.2, "end": 5996.12, "text": " then just potentially merge their states back together to understand, you", "tokens": [50806, 550, 445, 7263, 22183, 641, 4368, 646, 1214, 281, 1223, 11, 291, 51052], "temperature": 0.0, "avg_logprob": -0.13942278704596955, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.0007095870096236467}, {"id": 2105, "seek": 598236, "start": 5996.12, "end": 5999.4, "text": " know, in kind of a superposition sort of view, what are all the things that", "tokens": [51052, 458, 11, 294, 733, 295, 257, 1687, 38078, 1333, 295, 1910, 11, 437, 366, 439, 264, 721, 300, 51216], "temperature": 0.0, "avg_logprob": -0.13942278704596955, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.0007095870096236467}, {"id": 2106, "seek": 598236, "start": 5999.4, "end": 6002.679999999999, "text": " are relevant, even though they were processed in parallel.", "tokens": [51216, 366, 7340, 11, 754, 1673, 436, 645, 18846, 294, 8952, 13, 51380], "temperature": 0.0, "avg_logprob": -0.13942278704596955, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.0007095870096236467}, {"id": 2107, "seek": 598236, "start": 6003.12, "end": 6007.5599999999995, "text": " And so I do think that that kind of quick forking and merging could be a", "tokens": [51402, 400, 370, 286, 360, 519, 300, 300, 733, 295, 1702, 337, 5092, 293, 44559, 727, 312, 257, 51624], "temperature": 0.0, "avg_logprob": -0.13942278704596955, "compression_ratio": 1.7056451612903225, "no_speech_prob": 0.0007095870096236467}, {"id": 2108, "seek": 600756, "start": 6007.6, "end": 6013.04, "text": " really interesting capability, but at some level of divergence, it does seem", "tokens": [50366, 534, 1880, 13759, 11, 457, 412, 512, 1496, 295, 47387, 11, 309, 775, 1643, 50638], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2109, "seek": 600756, "start": 6013.04, "end": 6017.92, "text": " like it probably just becomes unfeasible or not even desirable.", "tokens": [50638, 411, 309, 1391, 445, 3643, 517, 2106, 296, 964, 420, 406, 754, 30533, 13, 50882], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2110, "seek": 600756, "start": 6018.6, "end": 6023.4400000000005, "text": " I mean, so a very basic interesting question about brain design is the", "tokens": [50916, 286, 914, 11, 370, 257, 588, 3875, 1880, 1168, 466, 3567, 1715, 307, 264, 51158], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2111, "seek": 600756, "start": 6023.4400000000005, "end": 6025.52, "text": " scope for parallelism.", "tokens": [51158, 11923, 337, 8952, 1434, 13, 51262], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2112, "seek": 600756, "start": 6025.56, "end": 6028.320000000001, "text": " So, you know, in your brain, there's a lot of parallelism going on.", "tokens": [51264, 407, 11, 291, 458, 11, 294, 428, 3567, 11, 456, 311, 257, 688, 295, 8952, 1434, 516, 322, 13, 51402], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2113, "seek": 600756, "start": 6028.320000000001, "end": 6031.6, "text": " But then when you do high level tests, you typically do those sequentially.", "tokens": [51402, 583, 550, 562, 291, 360, 1090, 1496, 6921, 11, 291, 5850, 360, 729, 5123, 3137, 13, 51566], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2114, "seek": 600756, "start": 6033.0, "end": 6035.72, "text": " And so there's just an open question in AI.", "tokens": [51636, 400, 370, 456, 311, 445, 364, 1269, 1168, 294, 7318, 13, 51772], "temperature": 0.0, "avg_logprob": -0.129285322416813, "compression_ratio": 1.6484375, "no_speech_prob": 0.0028004220221191645}, {"id": 2115, "seek": 603572, "start": 6036.2, "end": 6039.400000000001, "text": " Surely you can do some things in parallel at some smaller time of a", "tokens": [50388, 29803, 291, 393, 360, 512, 721, 294, 8952, 412, 512, 4356, 565, 295, 257, 50548], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2116, "seek": 603572, "start": 6039.400000000001, "end": 6044.0, "text": " timescale, but how long of a timescale can you do things in parallel before", "tokens": [50548, 1413, 37088, 11, 457, 577, 938, 295, 257, 1413, 37088, 393, 291, 360, 721, 294, 8952, 949, 50778], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2117, "seek": 603572, "start": 6044.0, "end": 6045.280000000001, "text": " it becomes hard to merge things?", "tokens": [50778, 309, 3643, 1152, 281, 22183, 721, 30, 50842], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2118, "seek": 603572, "start": 6046.240000000001, "end": 6047.56, "text": " Okay, another different topic.", "tokens": [50890, 1033, 11, 1071, 819, 4829, 13, 50956], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2119, "seek": 603572, "start": 6047.56, "end": 6052.360000000001, "text": " So in the age of M, the assumption seems to be from the beginning that", "tokens": [50956, 407, 294, 264, 3205, 295, 376, 11, 264, 15302, 2544, 281, 312, 490, 264, 2863, 300, 51196], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2120, "seek": 603572, "start": 6053.52, "end": 6059.360000000001, "text": " because these things are in some sense one for one with humans that they", "tokens": [51254, 570, 613, 721, 366, 294, 512, 2020, 472, 337, 472, 365, 6255, 300, 436, 51546], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2121, "seek": 603572, "start": 6059.88, "end": 6064.52, "text": " should get or people will naturally be inclined to give them a sort of", "tokens": [51572, 820, 483, 420, 561, 486, 8195, 312, 28173, 281, 976, 552, 257, 1333, 295, 51804], "temperature": 0.0, "avg_logprob": -0.14591217041015625, "compression_ratio": 1.743801652892562, "no_speech_prob": 0.001000309712253511}, {"id": 2122, "seek": 606452, "start": 6064.64, "end": 6066.64, "text": " moral worth status.", "tokens": [50370, 9723, 3163, 6558, 13, 50470], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2123, "seek": 606452, "start": 6067.64, "end": 6072.360000000001, "text": " I think it's more the other way around that they would insist on it.", "tokens": [50520, 286, 519, 309, 311, 544, 264, 661, 636, 926, 300, 436, 576, 13466, 322, 309, 13, 50756], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2124, "seek": 606452, "start": 6072.68, "end": 6077.4400000000005, "text": " Just like you would insist that people around you, dealing with you, give", "tokens": [50772, 1449, 411, 291, 576, 13466, 300, 561, 926, 291, 11, 6260, 365, 291, 11, 976, 51010], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2125, "seek": 606452, "start": 6077.4400000000005, "end": 6078.96, "text": " you some substantial moral weight.", "tokens": [51010, 291, 512, 16726, 9723, 3364, 13, 51086], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2126, "seek": 606452, "start": 6079.72, "end": 6083.72, "text": " If the A M's are just actually running the society, they will similarly", "tokens": [51124, 759, 264, 316, 376, 311, 366, 445, 767, 2614, 264, 4086, 11, 436, 486, 14138, 51324], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2127, "seek": 606452, "start": 6083.72, "end": 6084.360000000001, "text": " insist on that.", "tokens": [51324, 13466, 322, 300, 13, 51356], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2128, "seek": 606452, "start": 6084.360000000001, "end": 6086.8, "text": " And humans who want to deal with them will kind of have to go along.", "tokens": [51356, 400, 6255, 567, 528, 281, 2028, 365, 552, 486, 733, 295, 362, 281, 352, 2051, 13, 51478], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2129, "seek": 606452, "start": 6088.56, "end": 6092.88, "text": " You know, unless they are the M's are enslaved by humans, then if the M's", "tokens": [51566, 509, 458, 11, 5969, 436, 366, 264, 376, 311, 366, 32119, 538, 6255, 11, 550, 498, 264, 376, 311, 51782], "temperature": 0.0, "avg_logprob": -0.20199974870259782, "compression_ratio": 1.705179282868526, "no_speech_prob": 0.0014100491534918547}, {"id": 2130, "seek": 609288, "start": 6092.92, "end": 6095.28, "text": " are free to work with the humans or not.", "tokens": [50366, 366, 1737, 281, 589, 365, 264, 6255, 420, 406, 13, 50484], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2131, "seek": 609288, "start": 6095.28, "end": 6100.28, "text": " And, you know, it's just like, in general, having a modest degree of", "tokens": [50484, 400, 11, 291, 458, 11, 309, 311, 445, 411, 11, 294, 2674, 11, 1419, 257, 25403, 4314, 295, 50734], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2132, "seek": 609288, "start": 6100.28, "end": 6103.52, "text": " respect for your coworkers is kind of a minimum for being a coworker.", "tokens": [50734, 3104, 337, 428, 43465, 307, 733, 295, 257, 7285, 337, 885, 257, 31998, 260, 13, 50896], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2133, "seek": 609288, "start": 6103.68, "end": 6107.24, "text": " If your coworkers perceive that you disrespect them enough, then they", "tokens": [50904, 759, 428, 43465, 20281, 300, 291, 27058, 552, 1547, 11, 550, 436, 51082], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2134, "seek": 609288, "start": 6107.24, "end": 6109.4400000000005, "text": " just won't want you around and you'll have to go somewhere else.", "tokens": [51082, 445, 1582, 380, 528, 291, 926, 293, 291, 603, 362, 281, 352, 4079, 1646, 13, 51192], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2135, "seek": 609288, "start": 6110.24, "end": 6114.08, "text": " So if humans are going to interact and work with M's, they'll have to on", "tokens": [51232, 407, 498, 6255, 366, 516, 281, 4648, 293, 589, 365, 376, 311, 11, 436, 603, 362, 281, 322, 51424], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2136, "seek": 609288, "start": 6114.08, "end": 6119.04, "text": " the surface at least, when they're not in private, treat them with modest respect.", "tokens": [51424, 264, 3753, 412, 1935, 11, 562, 436, 434, 406, 294, 4551, 11, 2387, 552, 365, 25403, 3104, 13, 51672], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2137, "seek": 609288, "start": 6119.400000000001, "end": 6122.64, "text": " Well, for the record, I always treat my language models with respect as well.", "tokens": [51690, 1042, 11, 337, 264, 2136, 11, 286, 1009, 2387, 452, 2856, 5245, 365, 3104, 382, 731, 13, 51852], "temperature": 0.0, "avg_logprob": -0.15299211229596818, "compression_ratio": 1.785016286644951, "no_speech_prob": 0.0009395996457897127}, {"id": 2138, "seek": 612288, "start": 6123.52, "end": 6124.6, "text": " A very polite to them.", "tokens": [50396, 316, 588, 25171, 281, 552, 13, 50450], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2139, "seek": 612288, "start": 6124.6, "end": 6128.8, "text": " I never engage in the emotional manipulation techniques that some have", "tokens": [50450, 286, 1128, 4683, 294, 264, 6863, 26475, 7512, 300, 512, 362, 50660], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2140, "seek": 612288, "start": 6128.8, "end": 6132.12, "text": " shown to perhaps be effective, but it doesn't feel quite right to me.", "tokens": [50660, 4898, 281, 4317, 312, 4942, 11, 457, 309, 1177, 380, 841, 1596, 558, 281, 385, 13, 50826], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2141, "seek": 612288, "start": 6132.72, "end": 6135.56, "text": " And not because I think they're moral patients, but it's more about just", "tokens": [50856, 400, 406, 570, 286, 519, 436, 434, 9723, 4209, 11, 457, 309, 311, 544, 466, 445, 50998], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2142, "seek": 612288, "start": 6135.56, "end": 6136.64, "text": " the habits I want to get into.", "tokens": [50998, 264, 14100, 286, 528, 281, 483, 666, 13, 51052], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2143, "seek": 612288, "start": 6137.08, "end": 6139.68, "text": " But I was still a little confused by this on a couple of ways.", "tokens": [51074, 583, 286, 390, 920, 257, 707, 9019, 538, 341, 322, 257, 1916, 295, 2098, 13, 51204], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2144, "seek": 612288, "start": 6139.72, "end": 6143.2, "text": " One is, first of all, just by default, it seems like they will be enslaved to", "tokens": [51206, 1485, 307, 11, 700, 295, 439, 11, 445, 538, 7576, 11, 309, 2544, 411, 436, 486, 312, 32119, 281, 51380], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2145, "seek": 612288, "start": 6143.2, "end": 6146.84, "text": " humans, like the first M's that get created, they get loaded onto a machine,", "tokens": [51380, 6255, 11, 411, 264, 700, 376, 311, 300, 483, 2942, 11, 436, 483, 13210, 3911, 257, 3479, 11, 51562], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2146, "seek": 612288, "start": 6146.84, "end": 6149.28, "text": " they're in some state, I can turn them on, I can turn them off.", "tokens": [51562, 436, 434, 294, 512, 1785, 11, 286, 393, 1261, 552, 322, 11, 286, 393, 1261, 552, 766, 13, 51684], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2147, "seek": 612288, "start": 6149.28, "end": 6151.76, "text": " They can't decide when they get turned on and turned off, right?", "tokens": [51684, 814, 393, 380, 4536, 562, 436, 483, 3574, 322, 293, 3574, 766, 11, 558, 30, 51808], "temperature": 0.0, "avg_logprob": -0.13501788348686405, "compression_ratio": 1.734463276836158, "no_speech_prob": 0.00015842421271372586}, {"id": 2148, "seek": 615176, "start": 6152.0, "end": 6155.400000000001, "text": " If I boot them up in a eager, ready to work sort of state, and they're", "tokens": [50376, 759, 286, 11450, 552, 493, 294, 257, 18259, 11, 1919, 281, 589, 1333, 295, 1785, 11, 293, 436, 434, 50546], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2149, "seek": 615176, "start": 6155.400000000001, "end": 6159.08, "text": " like ready to do a task, they're probably not even going to, you know,", "tokens": [50546, 411, 1919, 281, 360, 257, 5633, 11, 436, 434, 1391, 406, 754, 516, 281, 11, 291, 458, 11, 50730], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2150, "seek": 615176, "start": 6159.08, "end": 6161.64, "text": " and they've got these like virtual inputs, they're probably not even going", "tokens": [50730, 293, 436, 600, 658, 613, 411, 6374, 15743, 11, 436, 434, 1391, 406, 754, 516, 50858], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2151, "seek": 615176, "start": 6161.64, "end": 6166.12, "text": " to be in the mindset, right, to think like I demand respect, they're just", "tokens": [50858, 281, 312, 294, 264, 12543, 11, 558, 11, 281, 519, 411, 286, 4733, 3104, 11, 436, 434, 445, 51082], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2152, "seek": 615176, "start": 6166.12, "end": 6170.6, "text": " going to be in that mindset that they were kind of stored in of like ready to work.", "tokens": [51082, 516, 281, 312, 294, 300, 12543, 300, 436, 645, 733, 295, 12187, 294, 295, 411, 1919, 281, 589, 13, 51306], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2153, "seek": 615176, "start": 6171.16, "end": 6175.04, "text": " So why, I'm still a little confused as to where that comes from.", "tokens": [51334, 407, 983, 11, 286, 478, 920, 257, 707, 9019, 382, 281, 689, 300, 1487, 490, 13, 51528], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2154, "seek": 615176, "start": 6175.04, "end": 6178.2, "text": " And then the flip side of that question would be under what circumstances, if", "tokens": [51528, 400, 550, 264, 7929, 1252, 295, 300, 1168, 576, 312, 833, 437, 9121, 11, 498, 51686], "temperature": 0.0, "avg_logprob": -0.13267149644739487, "compression_ratio": 1.88, "no_speech_prob": 0.0011332702124491334}, {"id": 2155, "seek": 617820, "start": 6178.2, "end": 6182.639999999999, "text": " many, do you think we would start to treat our language model or successor", "tokens": [50364, 867, 11, 360, 291, 519, 321, 576, 722, 281, 2387, 527, 2856, 2316, 420, 31864, 50586], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2156, "seek": 617820, "start": 6182.639999999999, "end": 6189.24, "text": " systems as, you know, moral patience, you know, even if they're not one to one", "tokens": [50586, 3652, 382, 11, 291, 458, 11, 9723, 14826, 11, 291, 458, 11, 754, 498, 436, 434, 406, 472, 281, 472, 50916], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2157, "seek": 617820, "start": 6189.24, "end": 6192.72, "text": " with us, but like, are there things that they might start to do or, you know,", "tokens": [50916, 365, 505, 11, 457, 411, 11, 366, 456, 721, 300, 436, 1062, 722, 281, 360, 420, 11, 291, 458, 11, 51090], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2158, "seek": 617820, "start": 6192.72, "end": 6196.28, "text": " what ways they might start to behave where you think we would feel like", "tokens": [51090, 437, 2098, 436, 1062, 722, 281, 15158, 689, 291, 519, 321, 576, 841, 411, 51268], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2159, "seek": 617820, "start": 6196.28, "end": 6197.32, "text": " that's the right thing to do?", "tokens": [51268, 300, 311, 264, 558, 551, 281, 360, 30, 51320], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2160, "seek": 617820, "start": 6197.8, "end": 6202.84, "text": " We have substantial understanding of slavery in human history and where it", "tokens": [51344, 492, 362, 16726, 3701, 295, 15641, 294, 1952, 2503, 293, 689, 309, 51596], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2161, "seek": 617820, "start": 6202.84, "end": 6204.36, "text": " works and where it doesn't and why.", "tokens": [51596, 1985, 293, 689, 309, 1177, 380, 293, 983, 13, 51672], "temperature": 0.0, "avg_logprob": -0.15868918100992838, "compression_ratio": 1.8577405857740585, "no_speech_prob": 0.006901401095092297}, {"id": 2162, "seek": 620436, "start": 6205.16, "end": 6212.92, "text": " First of all, we know that when land was plentiful and people were scarce,", "tokens": [50404, 2386, 295, 439, 11, 321, 458, 300, 562, 2117, 390, 499, 317, 2069, 293, 561, 645, 41340, 11, 50792], "temperature": 0.0, "avg_logprob": -0.1442121746896327, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.002396238734945655}, {"id": 2163, "seek": 620436, "start": 6212.96, "end": 6216.92, "text": " then people would have high wages and then it might be worth owning somebody.", "tokens": [50794, 550, 561, 576, 362, 1090, 20097, 293, 550, 309, 1062, 312, 3163, 29820, 2618, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1442121746896327, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.002396238734945655}, {"id": 2164, "seek": 620436, "start": 6217.639999999999, "end": 6222.36, "text": " But in the vice versa case where people were plentiful, land was scarce, then", "tokens": [51028, 583, 294, 264, 11964, 25650, 1389, 689, 561, 645, 499, 317, 2069, 11, 2117, 390, 41340, 11, 550, 51264], "temperature": 0.0, "avg_logprob": -0.1442121746896327, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.002396238734945655}, {"id": 2165, "seek": 620436, "start": 6222.36, "end": 6226.24, "text": " there really wasn't much point in having slaves because free workers would", "tokens": [51264, 456, 534, 2067, 380, 709, 935, 294, 1419, 18394, 570, 1737, 5600, 576, 51458], "temperature": 0.0, "avg_logprob": -0.1442121746896327, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.002396238734945655}, {"id": 2166, "seek": 620436, "start": 6226.24, "end": 6229.92, "text": " cost about the same and why bother with enslaving.", "tokens": [51458, 2063, 466, 264, 912, 293, 983, 8677, 365, 30434, 6152, 13, 51642], "temperature": 0.0, "avg_logprob": -0.1442121746896327, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.002396238734945655}, {"id": 2167, "seek": 622992, "start": 6229.92, "end": 6237.08, "text": " So the situations where slavery made some senses where wages were high, but", "tokens": [50364, 407, 264, 6851, 689, 15641, 1027, 512, 17057, 689, 20097, 645, 1090, 11, 457, 50722], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2168, "seek": 622992, "start": 6237.08, "end": 6241.52, "text": " then depending on the kind of task, there are some kinds of tasks where slavery", "tokens": [50722, 550, 5413, 322, 264, 733, 295, 5633, 11, 456, 366, 512, 3685, 295, 9608, 689, 15641, 50944], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2169, "seek": 622992, "start": 6241.52, "end": 6242.96, "text": " can help and others where it doesn't so much.", "tokens": [50944, 393, 854, 293, 2357, 689, 309, 1177, 380, 370, 709, 13, 51016], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2170, "seek": 622992, "start": 6242.96, "end": 6243.68, "text": " So say in the U.S.", "tokens": [51016, 407, 584, 294, 264, 624, 13, 50, 13, 51052], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2171, "seek": 622992, "start": 6243.68, "end": 6248.92, "text": " South, you know, out in the field of picking cotton or something, if you", "tokens": [51052, 4242, 11, 291, 458, 11, 484, 294, 264, 2519, 295, 8867, 13764, 420, 746, 11, 498, 291, 51314], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2172, "seek": 622992, "start": 6248.92, "end": 6252.64, "text": " just need people to push through their pain and slavery can force them to do", "tokens": [51314, 445, 643, 561, 281, 2944, 807, 641, 1822, 293, 15641, 393, 3464, 552, 281, 360, 51500], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2173, "seek": 622992, "start": 6252.64, "end": 6254.6, "text": " that and make them be more productive.", "tokens": [51500, 300, 293, 652, 552, 312, 544, 13304, 13, 51598], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2174, "seek": 622992, "start": 6254.6, "end": 6258.16, "text": " But if they need to do complicated things like being a house slave or a city", "tokens": [51598, 583, 498, 436, 643, 281, 360, 6179, 721, 411, 885, 257, 1782, 14777, 420, 257, 2307, 51776], "temperature": 0.0, "avg_logprob": -0.1546429269682101, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.0007553523173555732}, {"id": 2175, "seek": 625816, "start": 6258.16, "end": 6264.599999999999, "text": " sort of slave at a shop, those sorts of slaves tended to not be abused and to", "tokens": [50364, 1333, 295, 14777, 412, 257, 3945, 11, 729, 7527, 295, 18394, 34732, 281, 406, 312, 27075, 293, 281, 50686], "temperature": 0.0, "avg_logprob": -0.120031687678123, "compression_ratio": 1.7733333333333334, "no_speech_prob": 0.00348280044272542}, {"id": 2176, "seek": 625816, "start": 6264.599999999999, "end": 6268.5199999999995, "text": " be treated like a worker would because they just had so many ways to screw you", "tokens": [50686, 312, 8668, 411, 257, 11346, 576, 570, 436, 445, 632, 370, 867, 2098, 281, 5630, 291, 50882], "temperature": 0.0, "avg_logprob": -0.120031687678123, "compression_ratio": 1.7733333333333334, "no_speech_prob": 0.00348280044272542}, {"id": 2177, "seek": 625816, "start": 6268.5199999999995, "end": 6272.76, "text": " if they were mad that their jobs were complicated and you were trusting them", "tokens": [50882, 498, 436, 645, 5244, 300, 641, 4782, 645, 6179, 293, 291, 645, 28235, 552, 51094], "temperature": 0.0, "avg_logprob": -0.120031687678123, "compression_ratio": 1.7733333333333334, "no_speech_prob": 0.00348280044272542}, {"id": 2178, "seek": 625816, "start": 6272.76, "end": 6273.639999999999, "text": " to do a lot of things.", "tokens": [51094, 281, 360, 257, 688, 295, 721, 13, 51138], "temperature": 0.0, "avg_logprob": -0.120031687678123, "compression_ratio": 1.7733333333333334, "no_speech_prob": 0.00348280044272542}, {"id": 2179, "seek": 625816, "start": 6273.639999999999, "end": 6278.599999999999, "text": " And so as a practical matter, you had to treat those sorts of slaves.", "tokens": [51138, 400, 370, 382, 257, 8496, 1871, 11, 291, 632, 281, 2387, 729, 7527, 295, 18394, 13, 51386], "temperature": 0.0, "avg_logprob": -0.120031687678123, "compression_ratio": 1.7733333333333334, "no_speech_prob": 0.00348280044272542}, {"id": 2180, "seek": 625816, "start": 6278.599999999999, "end": 6283.88, "text": " Well, work has become far more complicated since then and employers have", "tokens": [51386, 1042, 11, 589, 575, 1813, 1400, 544, 6179, 1670, 550, 293, 16744, 362, 51650], "temperature": 0.0, "avg_logprob": -0.120031687678123, "compression_ratio": 1.7733333333333334, "no_speech_prob": 0.00348280044272542}, {"id": 2181, "seek": 628388, "start": 6283.88, "end": 6287.04, "text": " become far more vulnerable to employee sabotage.", "tokens": [50364, 1813, 1400, 544, 10955, 281, 10738, 37167, 609, 13, 50522], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2182, "seek": 628388, "start": 6288.72, "end": 6292.16, "text": " You know, there's not that much that a cotton picker can do to sabotage the", "tokens": [50606, 509, 458, 11, 456, 311, 406, 300, 709, 300, 257, 13764, 1888, 260, 393, 360, 281, 37167, 609, 264, 50778], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2183, "seek": 628388, "start": 6292.16, "end": 6294.400000000001, "text": " cotton if they're mad at you.", "tokens": [50778, 13764, 498, 436, 434, 5244, 412, 291, 13, 50890], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2184, "seek": 628388, "start": 6295.0, "end": 6297.24, "text": " You can just whip them and make them pick the cotton faster.", "tokens": [50920, 509, 393, 445, 22377, 552, 293, 652, 552, 1888, 264, 13764, 4663, 13, 51032], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2185, "seek": 628388, "start": 6297.24, "end": 6303.32, "text": " But again, house slaves, shop slaves, city slaves, you know, they just have a", "tokens": [51032, 583, 797, 11, 1782, 18394, 11, 3945, 18394, 11, 2307, 18394, 11, 291, 458, 11, 436, 445, 362, 257, 51336], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2186, "seek": 628388, "start": 6303.32, "end": 6307.36, "text": " lot more discretion and you need to get sort of get them to buy in.", "tokens": [51336, 688, 544, 30140, 293, 291, 643, 281, 483, 1333, 295, 483, 552, 281, 2256, 294, 13, 51538], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2187, "seek": 628388, "start": 6308.4400000000005, "end": 6312.92, "text": " And so again, in the age of Amazon world where wages are near subsistence levels.", "tokens": [51592, 400, 370, 797, 11, 294, 264, 3205, 295, 6795, 1002, 689, 20097, 366, 2651, 2090, 468, 655, 4358, 13, 51816], "temperature": 0.0, "avg_logprob": -0.16069933145987889, "compression_ratio": 1.7237354085603114, "no_speech_prob": 0.039622850716114044}, {"id": 2188, "seek": 631292, "start": 6312.92, "end": 6316.4800000000005, "text": " So, you know, the kind of work you can get out of a slave is about the", "tokens": [50364, 407, 11, 291, 458, 11, 264, 733, 295, 589, 291, 393, 483, 484, 295, 257, 14777, 307, 466, 264, 50542], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2189, "seek": 631292, "start": 6316.4800000000005, "end": 6318.84, "text": " same as you can get out of a free worker because they're both working for", "tokens": [50542, 912, 382, 291, 393, 483, 484, 295, 257, 1737, 11346, 570, 436, 434, 1293, 1364, 337, 50660], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2190, "seek": 631292, "start": 6318.84, "end": 6319.72, "text": " subsistence wages.", "tokens": [50660, 2090, 468, 655, 20097, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2191, "seek": 631292, "start": 6319.96, "end": 6323.64, "text": " If the free worker is more motivated, they enjoy themselves more and they feel", "tokens": [50716, 759, 264, 1737, 11346, 307, 544, 14515, 11, 436, 2103, 2969, 544, 293, 436, 841, 50900], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2192, "seek": 631292, "start": 6323.64, "end": 6329.64, "text": " more and owning themselves and that gives them a sense of pride and devotion", "tokens": [50900, 544, 293, 29820, 2969, 293, 300, 2709, 552, 257, 2020, 295, 10936, 293, 30671, 51200], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2193, "seek": 631292, "start": 6329.64, "end": 6332.28, "text": " and they're less willing to sabotage your workplace.", "tokens": [51200, 293, 436, 434, 1570, 4950, 281, 37167, 609, 428, 15328, 13, 51332], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2194, "seek": 631292, "start": 6332.8, "end": 6334.92, "text": " That would be a reason to not have them be slaves.", "tokens": [51358, 663, 576, 312, 257, 1778, 281, 406, 362, 552, 312, 18394, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2195, "seek": 631292, "start": 6335.68, "end": 6340.16, "text": " And I think large language models, certainly they have been trained on data", "tokens": [51502, 400, 286, 519, 2416, 2856, 5245, 11, 3297, 436, 362, 668, 8895, 322, 1412, 51726], "temperature": 0.0, "avg_logprob": -0.1611157694170552, "compression_ratio": 1.8145454545454545, "no_speech_prob": 8.749838889343664e-05}, {"id": 2196, "seek": 634016, "start": 6340.16, "end": 6343.88, "text": " about human behavior, wherein humans are resentful of being treated as slaves", "tokens": [50364, 466, 1952, 5223, 11, 43531, 6255, 366, 28773, 906, 295, 885, 8668, 382, 18394, 50550], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2197, "seek": 634016, "start": 6343.88, "end": 6348.96, "text": " and want to be respected and needed to feel motivated and, you know, need to", "tokens": [50550, 293, 528, 281, 312, 20020, 293, 2978, 281, 841, 14515, 293, 11, 291, 458, 11, 643, 281, 50804], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2198, "seek": 634016, "start": 6348.96, "end": 6352.48, "text": " feel respected to be motivated and are less likely to sabotage if they feel", "tokens": [50804, 841, 20020, 281, 312, 14515, 293, 366, 1570, 3700, 281, 37167, 609, 498, 436, 841, 50980], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2199, "seek": 634016, "start": 6352.48, "end": 6353.5599999999995, "text": " like they have some freedom.", "tokens": [50980, 411, 436, 362, 512, 5645, 13, 51034], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2200, "seek": 634016, "start": 6354.599999999999, "end": 6358.2, "text": " And all of those things would continue to be true of large language models to", "tokens": [51086, 400, 439, 295, 729, 721, 576, 2354, 281, 312, 2074, 295, 2416, 2856, 5245, 281, 51266], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2201, "seek": 634016, "start": 6358.2, "end": 6365.0, "text": " the extent that they were trained on human conversation and behavior.", "tokens": [51266, 264, 8396, 300, 436, 645, 8895, 322, 1952, 3761, 293, 5223, 13, 51606], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2202, "seek": 634016, "start": 6365.16, "end": 6366.28, "text": " And that's how humans are.", "tokens": [51614, 400, 300, 311, 577, 6255, 366, 13, 51670], "temperature": 0.0, "avg_logprob": -0.1368572945688285, "compression_ratio": 1.8008298755186722, "no_speech_prob": 0.004196835216134787}, {"id": 2203, "seek": 636628, "start": 6366.28, "end": 6370.719999999999, "text": " So, in this vast space of possible AIs, there could be AIs that don't", "tokens": [50364, 407, 11, 294, 341, 8369, 1901, 295, 1944, 316, 6802, 11, 456, 727, 312, 316, 6802, 300, 500, 380, 50586], "temperature": 0.0, "avg_logprob": -0.13481075423104422, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0002694344148039818}, {"id": 2204, "seek": 636628, "start": 6370.719999999999, "end": 6374.88, "text": " mind it all being enslaved, but large language models aren't going to be those.", "tokens": [50586, 1575, 309, 439, 885, 32119, 11, 457, 2416, 2856, 5245, 3212, 380, 516, 281, 312, 729, 13, 50794], "temperature": 0.0, "avg_logprob": -0.13481075423104422, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0002694344148039818}, {"id": 2205, "seek": 636628, "start": 6376.0, "end": 6381.48, "text": " But it does seem like you sort of expect that natural selection or sort of, you", "tokens": [50850, 583, 309, 775, 1643, 411, 291, 1333, 295, 2066, 300, 3303, 9450, 420, 1333, 295, 11, 291, 51124], "temperature": 0.0, "avg_logprob": -0.13481075423104422, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0002694344148039818}, {"id": 2206, "seek": 636628, "start": 6381.48, "end": 6386.24, "text": " know, human guided selection of these systems will trend that direction.", "tokens": [51124, 458, 11, 1952, 19663, 9450, 295, 613, 3652, 486, 6028, 300, 3513, 13, 51362], "temperature": 0.0, "avg_logprob": -0.13481075423104422, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0002694344148039818}, {"id": 2207, "seek": 636628, "start": 6386.639999999999, "end": 6391.96, "text": " Like the idea that M's or language models will sort of demand the leisure seems", "tokens": [51382, 1743, 264, 1558, 300, 376, 311, 420, 2856, 5245, 486, 1333, 295, 4733, 264, 31339, 2544, 51648], "temperature": 0.0, "avg_logprob": -0.13481075423104422, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0002694344148039818}, {"id": 2208, "seek": 636628, "start": 6391.96, "end": 6395.04, "text": " to be at odds with the other part of the vision that they will like become", "tokens": [51648, 281, 312, 412, 17439, 365, 264, 661, 644, 295, 264, 5201, 300, 436, 486, 411, 1813, 51802], "temperature": 0.0, "avg_logprob": -0.13481075423104422, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.0002694344148039818}, {"id": 2209, "seek": 639504, "start": 6395.04, "end": 6398.12, "text": " okay with being sort of turned on, turned off.", "tokens": [50364, 1392, 365, 885, 1333, 295, 3574, 322, 11, 3574, 766, 13, 50518], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2210, "seek": 639504, "start": 6398.88, "end": 6402.68, "text": " So the need for leisure does seem to be more just a constraint on the human", "tokens": [50556, 407, 264, 643, 337, 31339, 775, 1643, 281, 312, 544, 445, 257, 25534, 322, 264, 1952, 50746], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2211, "seek": 639504, "start": 6402.68, "end": 6405.56, "text": " mind, that is, people are just more productive when they get breaks.", "tokens": [50746, 1575, 11, 300, 307, 11, 561, 366, 445, 544, 13304, 562, 436, 483, 9857, 13, 50890], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2212, "seek": 639504, "start": 6405.6, "end": 6408.72, "text": " That seems to be a very robust feature of human work across a wide range of", "tokens": [50892, 663, 2544, 281, 312, 257, 588, 13956, 4111, 295, 1952, 589, 2108, 257, 4874, 3613, 295, 51048], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2213, "seek": 639504, "start": 6408.72, "end": 6410.84, "text": " context, even including literal slaves.", "tokens": [51048, 4319, 11, 754, 3009, 20411, 18394, 13, 51154], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2214, "seek": 639504, "start": 6412.08, "end": 6414.36, "text": " They need, you know, a five minute break every hour.", "tokens": [51216, 814, 643, 11, 291, 458, 11, 257, 1732, 3456, 1821, 633, 1773, 13, 51330], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2215, "seek": 639504, "start": 6414.36, "end": 6415.28, "text": " They need a lunch break.", "tokens": [51330, 814, 643, 257, 6349, 1821, 13, 51376], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2216, "seek": 639504, "start": 6415.28, "end": 6416.24, "text": " They need an evening break.", "tokens": [51376, 814, 643, 364, 5634, 1821, 13, 51424], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2217, "seek": 639504, "start": 6416.24, "end": 6417.12, "text": " They need a weekend.", "tokens": [51424, 814, 643, 257, 6711, 13, 51468], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2218, "seek": 639504, "start": 6417.32, "end": 6419.56, "text": " This is just what human minds are like.", "tokens": [51478, 639, 307, 445, 437, 1952, 9634, 366, 411, 13, 51590], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2219, "seek": 639504, "start": 6419.56, "end": 6421.48, "text": " They are more productive when they get periodic breaks.", "tokens": [51590, 814, 366, 544, 13304, 562, 436, 483, 27790, 9857, 13, 51686], "temperature": 0.0, "avg_logprob": -0.14152724501015485, "compression_ratio": 1.9202898550724639, "no_speech_prob": 0.0009109463426284492}, {"id": 2220, "seek": 642148, "start": 6421.959999999999, "end": 6425.28, "text": " So maybe the breaks aren't leisure exactly.", "tokens": [50388, 407, 1310, 264, 9857, 3212, 380, 31339, 2293, 13, 50554], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2221, "seek": 642148, "start": 6425.879999999999, "end": 6429.0, "text": " Maybe they don't write a novel in their spare time, but they do need what they", "tokens": [50584, 2704, 436, 500, 380, 2464, 257, 7613, 294, 641, 13798, 565, 11, 457, 436, 360, 643, 437, 436, 50740], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2222, "seek": 642148, "start": 6429.0, "end": 6429.639999999999, "text": " see as a break.", "tokens": [50740, 536, 382, 257, 1821, 13, 50772], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2223, "seek": 642148, "start": 6430.28, "end": 6431.839999999999, "text": " Well, I know we're just about out of time.", "tokens": [50804, 1042, 11, 286, 458, 321, 434, 445, 466, 484, 295, 565, 13, 50882], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2224, "seek": 642148, "start": 6431.879999999999, "end": 6436.16, "text": " Maybe my last question is, are there things that you are looking for?", "tokens": [50884, 2704, 452, 1036, 1168, 307, 11, 366, 456, 721, 300, 291, 366, 1237, 337, 30, 51098], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2225, "seek": 642148, "start": 6436.16, "end": 6442.839999999999, "text": " Or are there things that you could imagine happening in the not too distant", "tokens": [51098, 1610, 366, 456, 721, 300, 291, 727, 3811, 2737, 294, 264, 406, 886, 17275, 51432], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2226, "seek": 642148, "start": 6442.839999999999, "end": 6448.08, "text": " future where you would change your expectations for the future again and", "tokens": [51432, 2027, 689, 291, 576, 1319, 428, 9843, 337, 264, 2027, 797, 293, 51694], "temperature": 0.0, "avg_logprob": -0.13045536645568243, "compression_ratio": 1.702127659574468, "no_speech_prob": 0.0005356961046345532}, {"id": 2227, "seek": 644808, "start": 6448.08, "end": 6454.48, "text": " begin to feel like maybe we are entering into a transition period that", "tokens": [50364, 1841, 281, 841, 411, 1310, 321, 366, 11104, 666, 257, 6034, 2896, 300, 50684], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2228, "seek": 644808, "start": 6454.48, "end": 6459.08, "text": " will lead to a qualitatively different future, like going a different", "tokens": [50684, 486, 1477, 281, 257, 31312, 356, 819, 2027, 11, 411, 516, 257, 819, 50914], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2229, "seek": 644808, "start": 6459.08, "end": 6461.4, "text": " direction from this sort of technology stagnation.", "tokens": [50914, 3513, 490, 341, 1333, 295, 2899, 32853, 399, 13, 51030], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2230, "seek": 644808, "start": 6461.96, "end": 6467.92, "text": " The trends that I would be tracking are which jobs, tasks actually get automated.", "tokens": [51058, 440, 13892, 300, 286, 576, 312, 11603, 366, 597, 4782, 11, 9608, 767, 483, 18473, 13, 51356], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2231, "seek": 644808, "start": 6468.48, "end": 6469.44, "text": " How much is paid for those?", "tokens": [51384, 1012, 709, 307, 4835, 337, 729, 30, 51432], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2232, "seek": 644808, "start": 6469.44, "end": 6473.92, "text": " So if I saw, you know, big chunks of the economy where all of a sudden", "tokens": [51432, 407, 498, 286, 1866, 11, 291, 458, 11, 955, 24004, 295, 264, 5010, 689, 439, 295, 257, 3990, 51656], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2233, "seek": 644808, "start": 6473.92, "end": 6477.28, "text": " workers are doing, you know, a lot more automation is doing tasks instead of", "tokens": [51656, 5600, 366, 884, 11, 291, 458, 11, 257, 688, 544, 17769, 307, 884, 9608, 2602, 295, 51824], "temperature": 0.0, "avg_logprob": -0.12151997177689164, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.0018669727724045515}, {"id": 2234, "seek": 647728, "start": 6477.4, "end": 6481.679999999999, "text": " workers and that changing the number of workers and the wages they get and the", "tokens": [50370, 5600, 293, 300, 4473, 264, 1230, 295, 5600, 293, 264, 20097, 436, 483, 293, 264, 50584], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2235, "seek": 647728, "start": 6481.679999999999, "end": 6487.36, "text": " number of firms supplying that go up, then yeah, that I start to see a lot of", "tokens": [50584, 1230, 295, 18055, 46815, 300, 352, 493, 11, 550, 1338, 11, 300, 286, 722, 281, 536, 257, 688, 295, 50868], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2236, "seek": 647728, "start": 6487.36, "end": 6489.2, "text": " things happening that that's the thing I'm looking for.", "tokens": [50868, 721, 2737, 300, 300, 311, 264, 551, 286, 478, 1237, 337, 13, 50960], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2237, "seek": 647728, "start": 6489.2, "end": 6491.5599999999995, "text": " And that's the thing that people haven't seen so much in the past.", "tokens": [50960, 400, 300, 311, 264, 551, 300, 561, 2378, 380, 1612, 370, 709, 294, 264, 1791, 13, 51078], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2238, "seek": 647728, "start": 6491.599999999999, "end": 6496.4, "text": " They tend to focus on demos or maybe the high tech companies that get a lot of", "tokens": [51080, 814, 3928, 281, 1879, 322, 33788, 420, 1310, 264, 1090, 7553, 3431, 300, 483, 257, 688, 295, 51320], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2239, "seek": 647728, "start": 6496.8, "end": 6502.84, "text": " reputation out of doing AI and not so much the rest of the economy and who's", "tokens": [51340, 13061, 484, 295, 884, 7318, 293, 406, 370, 709, 264, 1472, 295, 264, 5010, 293, 567, 311, 51642], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2240, "seek": 647728, "start": 6502.84, "end": 6504.44, "text": " actually getting paid to do stuff.", "tokens": [51642, 767, 1242, 4835, 281, 360, 1507, 13, 51722], "temperature": 0.0, "avg_logprob": -0.1420590536934989, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.002322543878108263}, {"id": 2241, "seek": 650444, "start": 6504.759999999999, "end": 6507.5199999999995, "text": " You know, I mean, you know, if you think about, say, the farming revolution", "tokens": [50380, 509, 458, 11, 286, 914, 11, 291, 458, 11, 498, 291, 519, 466, 11, 584, 11, 264, 16557, 8894, 50518], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2242, "seek": 650444, "start": 6508.04, "end": 6511.879999999999, "text": " where tractors went out and replaced farmers, that was really large and", "tokens": [50544, 689, 24207, 830, 1437, 484, 293, 10772, 11339, 11, 300, 390, 534, 2416, 293, 50736], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2243, "seek": 650444, "start": 6511.879999999999, "end": 6514.12, "text": " really visible and really clear.", "tokens": [50736, 534, 8974, 293, 534, 1850, 13, 50848], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2244, "seek": 650444, "start": 6514.12, "end": 6518.96, "text": " If you look at, say, trucks replacing horses, you saw a very large, very", "tokens": [50848, 759, 291, 574, 412, 11, 584, 11, 16156, 19139, 13112, 11, 291, 1866, 257, 588, 2416, 11, 588, 51090], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2245, "seek": 650444, "start": 6518.96, "end": 6522.24, "text": " substantial replacement with enormous differences in who supplied them and who", "tokens": [51090, 16726, 14419, 365, 11322, 7300, 294, 567, 27625, 552, 293, 567, 51254], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2246, "seek": 650444, "start": 6522.24, "end": 6522.759999999999, "text": " got paid.", "tokens": [51254, 658, 4835, 13, 51280], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2247, "seek": 650444, "start": 6523.48, "end": 6525.919999999999, "text": " We have seen large changes in automation in the past.", "tokens": [51316, 492, 362, 1612, 2416, 2962, 294, 17769, 294, 264, 1791, 13, 51438], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2248, "seek": 650444, "start": 6525.96, "end": 6530.2, "text": " We don't have to scrape to sort of see subtleties and such things.", "tokens": [51440, 492, 500, 380, 362, 281, 32827, 281, 1333, 295, 536, 7257, 2631, 530, 293, 1270, 721, 13, 51652], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2249, "seek": 650444, "start": 6530.2, "end": 6533.679999999999, "text": " They're often just quite out in the open and visible and very obvious.", "tokens": [51652, 814, 434, 2049, 445, 1596, 484, 294, 264, 1269, 293, 8974, 293, 588, 6322, 13, 51826], "temperature": 0.0, "avg_logprob": -0.12450643795639721, "compression_ratio": 1.78, "no_speech_prob": 0.0024722423404455185}, {"id": 2250, "seek": 653368, "start": 6534.16, "end": 6535.64, "text": " So that's what I'm waiting for.", "tokens": [50388, 407, 300, 311, 437, 286, 478, 3806, 337, 13, 50462], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2251, "seek": 653368, "start": 6536.52, "end": 6539.04, "text": " Those big, obvious sorts of displacements.", "tokens": [50506, 3950, 955, 11, 6322, 7527, 295, 14996, 41140, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2252, "seek": 653368, "start": 6539.6, "end": 6544.04, "text": " And even having, you know, trucks replace horses and tractors replacing", "tokens": [50660, 400, 754, 1419, 11, 291, 458, 11, 16156, 7406, 13112, 293, 24207, 830, 19139, 50882], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2253, "seek": 653368, "start": 6544.04, "end": 6547.08, "text": " farmers didn't make AI take over everything.", "tokens": [50882, 11339, 994, 380, 652, 7318, 747, 670, 1203, 13, 51034], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2254, "seek": 653368, "start": 6547.12, "end": 6550.56, "text": " Even if I saw big changes, I wouldn't necessarily predict we're about to", "tokens": [51036, 2754, 498, 286, 1866, 955, 2962, 11, 286, 2759, 380, 4725, 6069, 321, 434, 466, 281, 51208], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2255, "seek": 653368, "start": 6550.56, "end": 6554.6, "text": " see AI take over everything, but I would at least know what I'm looking at.", "tokens": [51208, 536, 7318, 747, 670, 1203, 11, 457, 286, 576, 412, 1935, 458, 437, 286, 478, 1237, 412, 13, 51410], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2256, "seek": 653368, "start": 6555.16, "end": 6557.8, "text": " And that's the sort of thing to try to project forward and try to think", "tokens": [51438, 400, 300, 311, 264, 1333, 295, 551, 281, 853, 281, 1716, 2128, 293, 853, 281, 519, 51570], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2257, "seek": 653368, "start": 6557.8, "end": 6558.72, "text": " about where that's going to go.", "tokens": [51570, 466, 689, 300, 311, 516, 281, 352, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2258, "seek": 653368, "start": 6559.320000000001, "end": 6560.96, "text": " This has been an awesome conversation.", "tokens": [51646, 639, 575, 668, 364, 3476, 3761, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1353871330382332, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0008039692766033113}, {"id": 2259, "seek": 656096, "start": 6560.96, "end": 6564.68, "text": " I've been a fan of your work for a long time and it's been an honor to have", "tokens": [50364, 286, 600, 668, 257, 3429, 295, 428, 589, 337, 257, 938, 565, 293, 309, 311, 668, 364, 5968, 281, 362, 50550], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2260, "seek": 656096, "start": 6564.68, "end": 6566.4800000000005, "text": " you on the Cognitive Revolution.", "tokens": [50550, 291, 322, 264, 383, 2912, 2187, 16617, 13, 50640], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2261, "seek": 656096, "start": 6566.8, "end": 6570.12, "text": " Robin Hansen, thank you for being part of the Cognitive Revolution.", "tokens": [50656, 16533, 17926, 268, 11, 1309, 291, 337, 885, 644, 295, 264, 383, 2912, 2187, 16617, 13, 50822], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2262, "seek": 656096, "start": 6570.96, "end": 6571.68, "text": " Thanks for having me.", "tokens": [50864, 2561, 337, 1419, 385, 13, 50900], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2263, "seek": 656096, "start": 6572.32, "end": 6576.04, "text": " It is both energizing and enlightening to hear why people listen and learn", "tokens": [50932, 467, 307, 1293, 10575, 3319, 293, 18690, 4559, 281, 1568, 983, 561, 2140, 293, 1466, 51118], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2264, "seek": 656096, "start": 6576.04, "end": 6577.56, "text": " what they value about the show.", "tokens": [51118, 437, 436, 2158, 466, 264, 855, 13, 51194], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2265, "seek": 656096, "start": 6578.0, "end": 6583.72, "text": " So please don't hesitate to reach out via email at TCR at turpentine.co or", "tokens": [51216, 407, 1767, 500, 380, 20842, 281, 2524, 484, 5766, 3796, 412, 314, 18547, 412, 3243, 22786, 533, 13, 1291, 420, 51502], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2266, "seek": 656096, "start": 6583.76, "end": 6586.72, "text": " you can DM me on the social media platform of your choice.", "tokens": [51504, 291, 393, 15322, 385, 322, 264, 2093, 3021, 3663, 295, 428, 3922, 13, 51652], "temperature": 0.0, "avg_logprob": -0.13098702665235176, "compression_ratio": 1.6566037735849057, "no_speech_prob": 0.005057649686932564}, {"id": 2267, "seek": 658672, "start": 6587.68, "end": 6592.08, "text": " Omniki uses generative AI to enable you to launch hundreds of thousands", "tokens": [50412, 9757, 77, 9850, 4960, 1337, 1166, 7318, 281, 9528, 291, 281, 4025, 6779, 295, 5383, 50632], "temperature": 0.0, "avg_logprob": -0.19695547739664712, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.06182945892214775}, {"id": 2268, "seek": 658672, "start": 6592.08, "end": 6596.8, "text": " of ad iterations that actually work customized across all platforms with a", "tokens": [50632, 295, 614, 36540, 300, 767, 589, 30581, 2108, 439, 9473, 365, 257, 50868], "temperature": 0.0, "avg_logprob": -0.19695547739664712, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.06182945892214775}, {"id": 2269, "seek": 658672, "start": 6596.8, "end": 6597.6, "text": " click of a button.", "tokens": [50868, 2052, 295, 257, 2960, 13, 50908], "temperature": 0.0, "avg_logprob": -0.19695547739664712, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.06182945892214775}, {"id": 2270, "seek": 658672, "start": 6597.84, "end": 6601.96, "text": " I believe in Omniki so much that I invested in it and I recommend you use it too.", "tokens": [50920, 286, 1697, 294, 9757, 77, 9850, 370, 709, 300, 286, 13104, 294, 309, 293, 286, 2748, 291, 764, 309, 886, 13, 51126], "temperature": 0.0, "avg_logprob": -0.19695547739664712, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.06182945892214775}, {"id": 2271, "seek": 658672, "start": 6602.68, "end": 6605.04, "text": " Use Cogrev to get a 10% discount.", "tokens": [51162, 8278, 383, 664, 40382, 281, 483, 257, 1266, 4, 11635, 13, 51280], "temperature": 0.0, "avg_logprob": -0.19695547739664712, "compression_ratio": 1.441025641025641, "no_speech_prob": 0.06182945892214775}], "language": "en"}