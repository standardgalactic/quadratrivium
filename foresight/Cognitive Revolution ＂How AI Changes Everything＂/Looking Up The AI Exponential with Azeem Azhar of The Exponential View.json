{"text": " Moore's Law was turning into this acceleration of AI capabilities over the top and the other was that what was happening in renewables with things like lithium-ion batteries and solar was on a Moore's Law like trajectory and there was some other technologies like genome sequencing and genome synthesis that seemed to be doing something similar. So I started to bundle those up in this idea that we're going through the exponential transition, a transition where our economy gets driven you know not by the economics of the oil industry and internal combustion engines and and telephones but by AI and renewables and that these technologies being on an exponential trend being fundamentally at some level kind of information technologies behave really differently to the ones of the previous generation. Hello and welcome to The Cognitive Revolution where we interview visionary researchers, entrepreneurs and builders working on the frontier of artificial intelligence. Each week we'll explore their revolutionary ideas and together we'll build a picture of how AI technology will transform work, life and society in the coming years. I'm Nathan LaBenz, joined by my co-host Eric Torenberg. Hello and welcome back to The Cognitive Revolution. Today I'm speaking with Azim Azhar, founder of The Exponential View and fellow AI scout. For a wide-ranging discussion about the transformative power of AI and its implications for humanity. Azim's core observations that we are in the midst of a transition from an economy driven by the likes of phones and oil to one fueled by AI and renewables and that these new technologies fundamentally rooted in information and already growing exponentially behave differently than their predecessors will be familiar to cognitive revolution listeners. So I took the opportunity to get a bit deeper into Azim's worldview and expectations for the coming years and ended up having what I think was a really engaging and delightful exchange. In this conversation we cover a number of familiar topics plus some new ones that we haven't explored in quite the same way before, including why Azim believes that while incumbents are racing to adopt AI technology, yes startups are still likely to drive the true disruption in the form of entirely new products and markets. Also what forward thinking business leaders are doing today to retrain their teams and to position their companies to lead their respective markets in AI adoption and why Azim still finds it necessary to challenge them to think bigger, asking the question what would they do if they had a million times more compute. We also explore why Azim agrees with Sam Altman's recent comments that AGI will likely arrive soon but will be less of a big deal than people expect, at least initially. How AI is likely to change human relationships, especially considering the rise of so many different forms of AI companions, what sorts of new governance mechanisms the AI era will require, and finally why we might ought to worry about what I call the great embedding, that is the seemingly natural tendency for AI systems to communicate with each other in high dimensional vector formats, which while efficient for them is broadly inscrutable to humans and could lead to various loss of control scenarios. As always, if you're finding value in the show, we'd appreciate it if you'd take a moment to share it with your friends. Azim's perspective is both imaginative and exciting and also grounded and sobering, so I definitely recommend this episode to anyone trying to get a better zoomed out view of the future. I would also encourage you to consider subscribing to Azim's work directly, which you can find at exponentialview.co. Of course, your feedback is always welcome, whether in the form of an Apple or Spotify review, a YouTube comment, or a DM on the social media platform of your choice. Now, I hope you enjoy this conversation with founder of the exponential view, Azim Azhar. Azim Azhar, founder of the exponential view, welcome to the cognitive revolution. I'm really happy to be here, Nathan. I've enjoyed so many of the episodes and want to thank you for your hard service as a red teamer for GPT4. I watched that episode with my jaw on the floor. Well, thank you very much. That's kind and right back at you. I've been binging your feed lately and we've got a ton of things to talk about. I guess for starters, I would love to get your kind of summary of what it is you do. I think it's actually kind of similar to what I'm trying to do. I describe myself, as you know, as an AI scout. And I talk to mostly people on the show who are either very deep on a particular line of research or building a product, but you are one of the few guests who have this kind of very zoomed out view and really are working to understand the big picture. So how do you describe what you do and what goes into it? I'd love to, yeah. I mean, I've been in the tech industry for a really long time. I started working in 94 and I built my first websites in 93. And just over the back behind me, you can see in out of focus my first computer, which is a ZX81 Timex 1000 in the US. And about nine years ago, my last company was acquired and I just started to write a newsletter. And as you do, writing is thinking. And I noticed within a few months, there were these few trends that were going on that were pretty significant. One was, you know, Moore's Law was turning into this acceleration of AI capabilities over the top. And the other was that what was happening in renewables with things like lithium ion batteries and solar was on a Moore's Law like trajectory. And there was some other technologies like genome sequencing and genome synthesis that seemed to be doing something similar. So I started to bundle those up in this idea that we're going through the exponential transition, a transition where our economy gets driven, you know, not by the economics of the oil industry and internal combustion engines and telephones, but by AI and renewables and that these technologies being on an exponential trend, being fundamentally at some level kind of information technologies behave really differently to the ones of the previous generation. And so what I do now is I try to make sense of that as a system. I do that through my newsletter, but I also do it from time to time through investing and advising. But I think that what is going on at its heart is in about 20 or 30 years, we'll be looking at an energy system that is going to be very, very heavily renewable. We'll be using much more energy per capita globally than we do today, that we will have tons of intelligence in our economies and in our lives through through AI. And that will have real knock on effects and trying to make sense of that in a pragmatically optimistic way. So somewhere between the extreme dystopia and the extreme utopia is really my mission. Yeah, cool. Well, I'm hoping we can find that sweet spot as well. So right there with you. In terms of the history of the kind of intellectual history of this notion of exponential technologies, nine years ago strikes me as kind of a doldrum time for that paradigm. I wonder if you experienced this, but I recently had a conversation with a guy who makes his living as a speaker at corporate events and who is positioned as a futurist. And I showed him a little presentation that I had put together in which I pulled out one of Kurzweil's kind of late 90s exponential curves graphs. And the title of that slide in my presentation was Kurzweil was right. He saw the name Kurzweil and he was like, Oh God, don't don't talk about Kurzweil. No, everybody he's totally discredited. And I was kind of like, hmm, that sounds like somebody who, you know, maybe got some pitches dinged in that kind of time frame when you were getting started with this notion and has gone away from it. But you know, maybe that's just the weird nature of exponentials. What was your kind of experience of, you know, were people sort of sour on that? It seemed like, you know, there was the great stagnation thesis for a while there and your start of the exponential kind of lines up with it. It seems like when I started and one, what I noticed was people weren't really talking about AI. I mean, it was 2014. Machine learning was still the word. It was before AlphaGo had come out and done its thing. DeepMind was doing really interesting things with reinforcement learning and video games. And you could see that something was happening. And I think that you had TensorFlow as the sort of stack of choice for building convolutional neural networks to do their machine vision tasks. So it seemed, it seemed reasonably early to be talking about, about these things. And actually developers were struggling to make sense of CUDA, which is the sort of API to the Nvidia GPUs that everybody now uses, because that had only been documented five years earlier. There is something that happens around 2013, 2014, 2015 that I think is really worth paying attention to, which is that in 2013, Apple becomes the largest company in the world. And within a couple of years, those top slots are occupied by what we used to call the fangs, Facebook, Apple, Google, and Amazon, or the gaffers, pardon me, not the fangs. Netflix snuck in briefly during the hype cycle. And so you started to see the, the companies of the industrial age, Exxon, GM, and so on, fall off that, fall off that list and stay off that list. So that's an important economic moment about the, the sort of forward looking stock market saying like something is changing. The second thing that starts to happen in around 2014 is we see the first market for electric vehicles go past that threshold of 5% of new cars being sold, being electric, which was over in, in Norway. And that 5% threshold is the normally the trigger for when you see the S curve of adoption, right? And you get into that, that vertical or that verticalized part of the curve. You also started to see solar power being starting to be cheaper in a roughly a third to a half of the contracts around the world than fossil fuels. And, and then of course we are three or four years into the deep learning wave. And, and that's long enough for companies to start to ship products. So I think that there is a moment which we could argue when we look back on it feels like a, a sort of historical turning point, but we also have to be realistic that the, the mathematical function that is an exponential curve, when you stand on it, it always looks horizontal behind you and it always looks vertical above in front of you, wherever you stand on it. It's a smooth curve with no obvious turning point. And, and someone like Kurt's file, you know, I think did such great work 20 years ago to articulate the exponential trend in computing going back from the 1880s actually in mechanical computers. I think one of the reasons why he slightly falls out of favor is because he was probably brave enough to extend the curve far further than we might have otherwise thought. And I think a couple of things that he got wrong was that some of the assumptions that we would have had about how the human brain works in like 2001, 2002 when those books came out were, were wrong, right? Science proved that it was more complex and it wasn't going to be a simple game of, of raw computation one for one. And, and that's where I think that, that people start to look at him and say, well, was this just someone throwing tea leaves? I think there was much more to it than, than that having read his work, you know, reasonably carefully. But, but I think what's interesting is that we see these curves happening elsewhere, right? We see them in lithium ion batteries and we see them in genome sequencing and it's not clear why that should be the case up front. The implications of the fact that we may still be, you know, standing on the part of the curve that as it, you know, as you said, it kind of always does. If we're, if it's still the case that what's in front of us is vertical compared to what, you know, has been behind us being horizontal, then we're in for a bit of a wild ride. I think we're headed for steep, a steep curve for at least a couple more years. I mean, beyond that, you know, do we sort of hit a plateau is a lot harder for me to predict. But I honestly don't see any fundamental reasons that we would right now. I mean, what, what Kurzweil says is that, you know, it's actually this curve is a series of layered S's. So you, you have one particular technology architecture, it's very slow to develop, it hits this inflection as an S, it starts to accelerate. And as it hits its flat point, the social dynamics of market incentives have meant that another set of research has come in with a different architecture, a different way that extends that that S up and looks from a distance like a smooth S curve. And that's really nice and descriptive. But it also, I suspect people are kind of really robust with their theory feels like, well, that's just praying. That's like the Turkey that's been treated really well up to the day before Thanksgiving. And like, we should worry about what happens the next day. What I've tried to do is I've tried to get into the underlying mechanisms of why these things improve, why they get cheaper. And then what we need to do is figure out where does that mechanism fail? Because if the mechanism doesn't fail, then that trend is going to continue. And if it does fail, then we can say, well, we need a new mechanism and is there one, you know, in the research pipeline that might deliver it. So, I would say that if you look across the gamut, I mean, for example, batteries and solar power, we've definitely got more than a couple of years to run in terms of price declines. When we look at compute, I just feel it's really hard to bet against. I just, you know, I think that I've been hearing about the death of Moore's Law for 15 years. And, you know, Moore's Law is helpful. But the question to ask is how much compute can a developer get for a dollar each year? And do we really think that that is going to stop declining for like a long period of time? And I find that one really hard to support. And I just think it continues for a variety of reasons. It sure seems like it. I mean, the CPU to GPU transition feels like a classic example of one of those kind of one S-curve, perhaps giving way to another. And in the GPU, you know, we're not, it definitely feels like we're still in the steep part of that particular S-curve. Hey, we'll continue our interview in a moment after a word from our sponsors. The Brave Search API brings affordable developer access to the Brave Search Index, an independent index of the web with over 20 billion web pages. So what makes the Brave Search Index stand out? One, it's entirely independent and built from scratch. That means no big tech biases or extortionate prices. Two, it's built on real page visits from actual humans, collected anonymously of course, which filters out tons of junk data. And three, the index is refreshed with tens of millions of pages daily. So it always has accurate up to date information. The Brave Search API can be used to assemble a data set to train your AI models and help with retrieval augmentation at the time of inference, all while remaining affordable with developer first pricing. Integrating the Brave Search API into your workflow translates to more ethical data sourcing and more human representative data sets. Try the Brave Search API for free for up to 2,000 queries per month at brave.com slash api. We're not done yet. And I think the thing that is fascinating is that NVIDIA is obviously doing incredibly, incredibly well. And it doesn't yet have the threat of real competition. And what was fascinating in the CPU world was that Intel did very, very well for a really long time. I guess people forget this, but if you've been around for a while, you remember Intel was this sort of monopolist and perceived an Andy Grove and only the paranoid survive. And it did really well only with the threat of competition, because AMD never got more than 15, 20 percent market share. And that's enough to propel people forward. All the incentives seem lined up for there to be massive amounts of investment in scaling existing silicon chips and developing new systems. I mean, you saw in the last few days before we recorded this, Amazon and Google both reported 20, 30 percent growth in their cloud businesses. When I've talked to bosses of really big companies, you know, they are spending money on compute, you know, really like nobody's business and their expectation is that it will grow. They don't often think it's compute. They say they're spending on AI, but that the end of it is going to be GPUs cranking away. So with all the incentives aligned, I struggle to see us hitting a brick wall. It doesn't feel like it's the Carno cycle, right? So the Carno cycle was the thermodynamic limit for the efficiency of an Intel combustion engine, something you as a native Detroit man, you know, know, know very, very well, but we keep finding ways of eking more out of our compute. And I think we'll, you know, we'll continue to do that certainly beyond a couple of years. Just for kind of conceptual grounding, and I'm also interested to hear how you explain this to the business leaders that you work with, because their understanding and their kind of eagerness to adopt is a pretty key question in my mind as to how the next few years are going to play out. But we have kind of two notions, two definitions of kind of types of technology that both seem to apply to AI in my mind. One is the exponential technology, and the other is the concept of disruptive technology. Disruptive technology, you know, kind of classic textbook definition is a cheaper, but inferior alternative that kind of competes on the low end of the market. It seems to me that AI is kind of both, right? It's we've got like these, at least exponentially growing inputs. Although on the other hand, you could sort of say scaling laws sort of suggest that like the model capabilities are more like logarithmic, so those two things maybe like balance out somehow. It does seem like it's disruptive in that AI is typically like an inferior, but cheaper alternative to asking somebody to do something for you, right? It's a, it's also a general purpose technology. I guess what are the, what are the kind of key definitions and how do you think about mustering those different frameworks so that people have good clarity on what it is we're dealing with? I mean, it is, it's so hard because it is so, it is so general and it is also a technology that improves other technologies and itself directly, you know, not in the way that electricity improves electricity, you know, electricity makes the economy more efficient and so you can build more electrical power stations, but AI seems much more direct. I do think it's important to understand its generality to get people to wake up to the idea that a general purpose technology really transforms the world beyond the, beyond the economics and, you know, again, Detroit is a great example for this because the car transformed the world in a very short period of time where I live in Northwest London 120 years ago, this was all fields and within 20 years after that, by about 1925, the roads were laid out the way they were and the houses were built the way they are and a century later we're still like this and this is because of ultimately the car as a general purpose technology. So too, because they don't come around very often, I think that's a really good starting point. On the question of disruption, that is a, I think it's a kind of higher order question because that is about products and how they get bundled to provide value in a particular environment and I think that, you know, when you start to bundle AI to do that, you can ask that specific question. But one of the things I think is really important is, and I think companies started to think like this, is to think in terms of tasks rather than jobs because, you know, AI can't replace jobs, anyone's job, because there's just so much in an ordinary job, like logging on to Zoom and saying hello to somebody and getting your neighbor a cup of coffee that is beyond the scope of any AI system. But within tasks, I think you can start to unpick this. And that's why in a sense you might start to say, well, AI becomes a disruptive technology because on a like for like basis, it can't replace an entire, you know, human in their day to day, but it might get better and better. But I think what's more helpful is to go back to that task question. And then when we come to that, the question is on a task basis, is AI really a cheaper version of a human doing the same task and a worse version? Does that matter? And is that always the case? And I have certain tasks, which I do where I think I could not afford to hire a human to do this task as well as chat GPT does it for me, you know, in a minute or two. And that may well be your experience as well. I mean, I, you know, I use this for to write letters of complaints to get my parking fines reversed to help me think through holiday plans to do research for my book. And so I mean, it's just it's so variable. And in many cases, I would be better off finding the very best human to do that. But the costs of doing that, even finding them is so high. Yeah, your search costs alone would dominate. Yeah, search costs would dominate. I mean, when you're using, you know, GPT for or perplexity, whatever you use, do you have it across a whole range of different tasks that you do from the most strategic for your business to the most sort of trivial home tasks? Yeah, maybe not the most strategic yet. At that level, I would probably restrict myself to kind of brainstorming, you know, interaction at most, but certainly lots of things I get, you know, very efficient and an immediate help on. And I think that immediacy is super important, too. I have this one slide that I call the cognitive tail of the tape, which kind of lists out 12 dimensions and compares human to today's AIs. And, you know, then we can also consider what future as might look like, very much agree with your notion of distinguishing between jobs and tasks. And for a while, I was calling this the great implementation. And I've that phrase hasn't quite taken off yet. But the idea there is with inspiration from like your, you know, strutequeries and your Benedict Evans type business theorists, you know, the way to make money in businesses to bundle and unbundle, I do think that unbundling jobs into tasks is a very good way to think about it. And then for any given task, you go down this tail of the tape, and you're like, Yeah, a lot of them AI can do as well, or even better than a human or certainly better than a human that I could find without huge search costs. You know, we get we get quite surprised with some of the results. So I think one of the really big surprises is that if we went back six or seven years, and you had books like The Rise of the Robots and the famous Oxford paper saying, you know, machine learning could automate 40% or expersent of jobs that's written by a friend of mine. And our assumption was that it would be routine cognitive jobs, by which what people meant was customer service and data entry in like Philippines or the Indian or in India. And what we're actually discovering is that it's jobs that we would have categorized as non routine or even creative, where this technology can really start to make a difference. And it really, really is surprising. One that really I was not expecting was a paper at the end of 2023, which looked at empathy ratings of doctors giving advice compared to that GPT or GPT for giving advice, and patients were rating the robotic advice as more empathetic as humans. And the whole argument had been, let's use AI. So the radiologist can spend more time looking you in the eye and being attentive, and being and being empathetic. So part of the challenge I think is that there is this lack of clarity and lack of knowledge about where and when will these AI systems actually compete with humans on particular, particular tasks. And then when you think about it, actually, what is empathy? Empathy is about active listening and it's about being incredibly patient. And there's nothing that's more patient than a robot that has no sense of time and is stateless, right? I mean, it'll just sit there forever. An early GPT for tests that I remember fondly and do think is kind of a sign of things to come was simulated tech support for my grandmother when she needs help with her iPhone. And it was, you know, just a flash of this, you could call it sparks of things to come where I played the role of her, which, you know, and I, she calls me, right, when she needs help with the iPhone. And, you know, you're in this dynamic. And it's actually an interesting dynamic also for a pure text situation because she's typically on the phone with me looking at the phone and saying, you know, I can't, my friend sent me an email and I can't get it. And then I'm like, okay, well, I always start with, what do you see on the screen right now? Can you start at the top and just read everything that you see on the screen? And at times we've had some very, you know, kind of funny, does she always read everything that's there? Like, you know, she's missed something out. You're like, grandma, wasn't there a, isn't there a word above? No, she does pretty well. Yeah, she'll start at the top Verizon, you know, the time. And then there've been a couple of times where, you know, some one of those dial system dialogues pops up and that like just didn't even register to her. But then when she got it to reading, I was like, you need to hit okay there before you're going to be able to hit anything else. So it can be these very simple things. But GPT-4, as you might expect, did really quite well on that. There was a little bit of, it was in kind of the middle of where it did not have the UI of an iPhone memorized. So it was kind of hallucinating it and guessing. And yet the guesses were close enough, you know, and I really had to study my iPhone and what it was saying and kind of compare like, is the, is it saying what's actually there or not? And mostly was, but it was clear it was kind of filling in some gaps. But the real eye opening moment for me was it said something that I thought she might feel was a little bit rude. I forget exactly what it was, but it was like, you know, it was like starting the starting the top left, you know, where the top left is something like kind of that basic. And then I responded as her saying, yes, I know where the top left is. I'm not dumb. I'm just struggling with this phone. And then the AI comes back and says, I'm so sorry, I didn't mean to offend you. I'm just, you know, trying to make sure we're resetting here and, you know, helping you through this process. And that was the moment where I was like, Oh, this thing is going to be, it's got kind of this emotional intelligence as well. And that could be, you know, obviously just a critical ingredient for so many different interactions and medicine being a big one. We've done two episodes with Vivek Nadarajan, who leads a lot of these med specific projects at Google. And what an absolute terror they've been on. Most recently, they have a diagnosis differential diagnosis paper that shows the AI is getting the correct diagnosis twice as often as the unassisted human. And also more often than the AI assisted human, which I think is the thing that we should begin to reckon with. There's so much to unpack in that. Can I ask you one question about the politeness from the, you know, when you're playing your, your grandma, do you think that that comes from the human feedback cycle over the network before it gets released? Or is it, is it from the training data? The version that we had was, as far as I know, right, I'm inferring here because I did not have access to the training methods. But it seemed very clear to me that the model version that we had was RLHF purely for helpfulness. So it was very eager to please very eager to be nice to you, no guardrails on what you could ask it and what it would do, but 100% just trying to be helpful and pleasing to the user. So when it detected that kind of, I'm kind of bristling at what you just said, that's what it reacted with this, you know, I'm so sorry, I'm just trying to help kind of thing. And that was a mind blowing moment. I had not seen, of course, anything remotely like that from earlier models, right? At the time, Text DaVinci 002 was the best publicly available model. And it would like follow instructions on basic stuff. But I mean, this was a totally different world that we had suddenly stepped into. Hey, we'll continue our interview in a moment after a word from our sponsors. If you're a startup founder or executive running a growing business, you know that as you scale your systems break down, and the cracks start to show. If this resonates with you, there are three numbers you need to know. 36,000, 25, and one. 36,000. That's the number of businesses which have upgraded to NetSuite by Oracle. NetSuite is the number one cloud financial system, streamlined accounting, financial management, inventory, HR, and more. 25. NetSuite turns 25 this year. That's 25 years of helping businesses do more with less, close their books in days, not weeks, and drive down costs. One, because your business is one of a kind, so you get a customized solution for all your KPIs in one efficient system with one source of truth. Manage risk, get reliable forecasts, and improve margins. Everything you need all in one place. Right now, download NetSuite's popular KPI checklist, designed to give you consistently excellent performance, absolutely free, and netsuite.com slash cognitive. That's netsuite.com slash cognitive to get your own KPI checklist. NetSuite.com slash cognitive. Omnike uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work, customized across all platforms with a click of a button. I believe in Omnike so much that I invested in it, and I recommend you use it too. Use CogGrav to get a 10% discount. I mean, it is such a different world. I was using chat GPT for something a few days ago, and I got quite tired as you do. I mean, I think about it as the time I once was playing tennis against one of those tennis ball-serving machines, and I was exhausted, and the machine is just like willing to keep firing balls at me. And it's a bit like that using these chatbots. And I just left this kind of whimsical comment. I said, you know what? I'm really tired. I will come back tomorrow and we can look at the moisture evaporators. We were not doing anything to do with Star Wars, right? We were doing some digging about coal in England in the 17th century. And it just replied to me going, I'll be happy to, you go and rest up, and tomorrow I can help you on the farm. May the force be with you. And it had just very subtly played that back to me in a really, really nice way. And actually, in terms of humanized interfaces, as someone who's used Apple's computers for 40 years, it really sits alongside the trend that a firm like Apple had been thinking about for a really long time, which is how do we make this technology come to us rather than us go to the technology? You know, there has been this view that we'll have these central humans, right? Human plus machine. And one of the things that we learned about centaurs, and that idea came out with chess, right? After Kasparov lost to Deep Blue back in, in 97, was that for several years humans and the machine would outperform machines on their own, and of course humans. But now you're just better off with a chess computer. And as a human, you should just accept everything it says. So the central period in chess only lasted seven or eight years. And I think one of the assumptions that goes into this kind of maelstrom of ideas we have to make sense of over the next years, is that central humans will exist for quite a bit of time. In other words, human plus machine will do better than machine on its own. But we are starting to see signs at that period of time is already starting to come to an end, right? Far faster than we might have predicted. And you've just given an example, which is a, you know, an unreleased AI model where the AI on its own is doing better than the expert, expert human with the AI. Yeah, it's pretty crazy. I think people are broadly in denial about that possibility even, you know, and let alone the reality, it's funny that we things are happening so quickly that people are saying things, you know, are impossible or won't happen for at least 10 years that are literally already happening. And so I think, you know, to some degree, there's just kind of a lack of awareness. And there's also definitely some psychological, and I try not to psychologize people's AI positions too much, because I think the technology itself is confusing enough. But it certainly seems like there's some kind of psychological cope or denial happening there. I also do think it's important to keep in mind too that the setting really matters and the world is going to change as well. And humans may still have a really important role to play in a lot of systems for a while yet. I think we do have the AIs do have really important weaknesses. So you do do a study like this Google evaluation. And I think that they, you know, are very serious people who've set this up in a way that I trust is, you know, not not cooking the books in favor of the AI. So I take that result, you know, basically, at face value. But then I also think like the AIs have these strange vulnerabilities that, you know, for example, the AlphaGo system, right, that is superhuman go player. But I have an episode coming up with Adam Gleave from far AI, and they put out a method that showed how a relatively simple adversarial attack on the AlphaGo system could beat it. And no human would lose to this like simple adversarial attack. But the AI had this like massive blind spot that they were able to engineer against and exploit. So I do think we're headed for strange dynamics and the sort of naive, I don't mean to say that Google thing is naive, but it's kind of, you know, let's take controlled conditions and set it up in a certain way and see what happens. I do think it's really important to keep in mind that, you know, just like these AI systems in general, when they get out of domain, they have problems, like those results may also not extrapolate, at least initially, to situations where people are trying to break the AI, you know, I wouldn't, for anything where there's an adversarial incentive out there, I would not, I would not be quick to take a result like that and be like, okay, cool, you know, we can just deploy the AI on its own. Now in medicine, presumably, there's not a lot of adversarial situation, right, because people want to get the right diagnosis and like nobody wants them to get the wrong diagnosis. So, you know, I do think the AI doctor is kind of here before we know it. And, you know, we're going to have some very interesting questions about what to do about that. But I think the thing that you've also identified is that these systems have to get into companies, have to get into hospitals, have to get into the economy. And that's still, that still takes time, right? It still takes time for, let's not look at medicine, because it would have to be go through all sorts of clearances through the FDA and so on before it could be used. But every time we've seen amazing technologies emerge, the cloud computing, right, GPT uptake is higher than cloud computing, even though it's 19 years younger. But every time these technologies come out, they take a while to make a make it into businesses. I mean, even something as straightforward as the typewriter. So a typewriter took about 20 to 25 years from becoming a kind of affordable technology to being something that businesses have figured out how to use and how to change their, their processes, something like electricity took a little bit longer because, you know, the way that factories used what used power that before electricity was like a single big drive shaft and a massive lump of power that came from it. And then your electricity is this highly distributed, packetized movement of energy that you can put in different places, you need an entirely different setup for it. And so, so even when we look at something like this, the question is, how quickly are we able to bring it in? And over what time frame does it then start to change our, the practitioners relationship with the technology? I mean, we know from automation of, of aircraft and other automated systems that you go through this three phase process as somebody who's using the technology. Phase one, you kind of don't trust it, and you, you then see if it does well where you're the ground truth. Phase two, you start to assume it's a ground truth, and then you, you pack yourself on the back when you come up with the same answer that the machine comes up with. And then phase three, which is where we've got to on GPS, where we just trust ways, and it's like, actually, you know, we generally trust ways, some London taxi drivers don't, we just trust it. And you see that process happening replicated in other types of automation, which is why when it's really mission critical, you have incredibly high levels of training, and you have other types of safeties in place, like, you know, two humans in the cockpit, or, you know, whatever, whatever it happens to be. And, and so that part of the journey, I think is also one that adds a little bit of drag in terms of how long it takes to have an impact. And in that time, Nathan, we start to understand new questions, questions that we can't imagine right now, because they're just too far down the decision tree. So sometimes I think, I hear people say, well, there'll be that moment, I think Tim Urban has this, from Wait But Why, has this graph where he sort of shows the moment where AI is like as clever as a rat, and then like a second later, it's 10 times cleverer than us. I think part of the, the reality of like the rubber hitting the road is going to be that even as these products do very, very well in the lab situation, it just takes a little bit of time for them to get into, into the real world. Now, where it may happen is, I think in, in a couple of places. So one is where tasks have already been discretized so that they're essentially just written down. And I think that that is certain types of call centers and it's certain types of data entry. And in those places, the human is already hired on a task by task basis normally mediated by like a, a, a, a body shop. So the buyer of the services, which is like our favorite consumer electronics company or your insurance company has no emotional relationship, they just have a KPI that they measure to. And I think that lends itself unfortunately to a, a tidal wave risk for those types of roles. I think the, the second area is, you know, classic Silicon Valley stuff where a De Novo company is, I should say Silicon Valley, a classic Detroit stuff where a De Novo company is able to apply these technologies the way Henry Ford did and build his processes from scratch, right? In the way that the artisanal car makers were just going to have so much kind of cultural drag, they couldn't. And that's what we certainly saw with a lot of the, you know, the internet, right? It was, it was absolutely startups that captured the value. And then when you started to get to two areas that were more highly regulated and had, you know, a lot more stickiness to them, like, like finance, with the exception of certain areas of payments, it's still the bank, big banks, sort of the big banks. And, and, and I don't know how differently this actually plays out short of scenarios where someone is able to use these super powerful machines to kind of manipulate the rules of the game, which I, you know, I think is a, like that's more like a black swan scenario than one that we could, you know, talk about reasonably. Well, first of all, as an aside, if you ever make it to Detroit, I'll take you to the Henry Ford Museum and Living History Museum, which is called Greenfield Village, where this, this earlier transition is documented with actual machinery still running from the, you know, various phases, you can go see one of these old factories where actually a few of them where they have kind of the central steam engine, and then it's powering this one, you know, driveshaft at the top of the floor. And then there's like 25 belts, you know, coming off of that and connecting to other machines, all driven on this single thing. And then you, they have an electrical, early electrical version of that as well. Edison's workshop is there. He actually, this is Henry Ford toward the end of his life was like, became very sort of nostalgic for an earlier period. And decided he wanted to kind of create this, you know, living history place to sort of preserve that history so people can see it in the future. It's quite an awesome thing to go and contemplate. I'll have to do that. Because I think, I think Ford's influence and impact is somehow underrated. We don't talk about Ford as much as we may talk, maybe talk about Edison, when we think historically. And, you know, there was so much in Ford, he understood the, the socio economic contract that emerged from these, from these changes in like, in a number of different ways. I mean, not always in ways that are, you know, kind of positive. We know where the sort of sociological department started trying to ensure temperance amongst workers and, and so on. And it gets encapsulated in, in Aldous Huxley's book, Brave New World, which I still find to be a really, really remarkable piece of writing, you know, it was written in the 1930s, 1932, I think. And for Huxley to encapsulate and extend a raw Fordism, as far out as he did, it's a little bit like Kurt's file and what he did with his singularity work, I thought was absolutely genius. And I think that that, that book, which Brave New World, which rests on the ideas that, that Ford developed, catalyzed, that spawn off his, his work speaks very, really quite clearly to a number of the issues that we face now in this kind of later stages of industrial capitalism. And I mean, so a trip to Detroit, I will take you up on and I'll bring you a copy of Brave New World as well. It's been a long time since I've read that, actually going back to high school. So I might need to dust that one off and I'm sure it will resonate very differently today than it did for me then. So, okay, I have a number of questions on this kind of concept of transition. I think I would, from what I heard, I think we're probably largely on the same page that it seems like incumbents, the big banks and big technology companies, largely should be able to harness this technology and bring it to their platforms before they get displaced. I think of like Salesforce is almost a canonical example there. They're going to have an AI layer that creates a much better and less complicated, less confusing user experience before somebody's going to recreate all the complexity of Salesforce. On the other hand, there is no AI friend today. So that's kind of my canonical example of something that's by definition going to be de novo. And then presumably there's like a ton of stuff in between. And I gather that you're kind of talking to business leaders probably throughout that spectrum. Where are they today? It seems like they're groping of what is going on and their eagerness to transform the way their businesses operate might be the limiting factor in how quickly this transition can proceed. Are you advising them to start to think about what kind of semi-structured work they can make a lot more structured so that they can reduce it to these kind of task level things that can be automated? And are they receptive to that sort of challenge and or opportunity? I mean, I can't remember a technology which has had the degree of uptake in large companies as this one. I think back to the internet, back in 1999, I was talking to the CEO of a big mobile phone company. And he said to me, I will never let you pay your bill over the internet. In fact, I'll never ever let you look at your bill over the internet. And he was right because he was fired a year later. So he never, project was never delivered. But it's so different with not just AI, but specifically gen AI, because two things are happening. One is that the CEOs of the companies have been playing around with this partly because they're of that age now, they're in their mid 50s, they've grown up with computers, their kids are coming back with it from college. And the second thing that's happening is that the frontline workers are using this regardless of any restrictions by their employees. And there have been a couple of surveys now, one done by your old alma mater Oliver Wyman, which was of 25,000 employees across 18 countries. And in 83% of employees in the UAE in India, already using a chat GPT or something similar. And we've seen data from Salesforce and others that say in the US, it's like 30, 40, 50%, you know, choose your number, but it's not 2%. And it's very frontline. And I think of that as like a pincer movement, because normally, you got to drag the frontline employees, or you got to drag the CEO, they both want it for different reasons. And I think it will, it will happen. And you start to see that in the, the levels of uptake that are being reported through, through the surveys. So I think that that says that we'll see more and more projects roll out more, more quickly. But there's still a lot of retraining that needs to go on internally and internal processes. I mean, I think one thing that will happen is I just saw Ethan Mollick, who you must get on your show. This is fantastic. A professor at Wharton who's writing a book on chat GPT. And he just showed a video where he had six different windows open. He put an inquiry into each one. And in 54 seconds, he had a product launch plan, a market analysis, a PowerPoint deck assessing Tesla's business and something else created from one sentence prompts. Now, if anyone's work has worked in a large organization, they know that you know your inbox is a full of crap and full of meaningless PowerPoint decks. So we might actually just find ourselves sort of swallowed up by PowerPoints created by Microsoft co pilot. So there's a whole set of I think more complex kind of issues that that exist in large companies. But I think that they will adopt this much faster than the evidence is and they have in previous technologies. But it doesn't, I think necessarily mean that disruption of the kind you talked about won't also happen. And I didn't have on my dance card in 95 when I started working that blockbuster would be the first high profile casualty of the internet. And I had seen video over the internet. The Cambridge University had a webcam on a coffee pot. And that was the first sort of video over the internet. And Rob Glazer had just started real networks was called progressive networks back then. And when Netflix launched, it was this kind of thing with DVDs. And it was a real pain in the ass. And it took a long time, a few years before blockbuster has its best year, and then it has its worst year ever. And I think that if AI is gen AI, what have we want to call it is a GPT, there are going to be blockbusters lurking around. And the question is, which ones will it be the reason I don't I like you, I don't feel it's going to be the banks is because the banks have got a whole bunch of stuff that is about trust and probity and internal processes and compliance. That is is just not an AI question. It's it's kind of an institutional question. And I do I do wonder about where that that moment is. And the the thing is that the there are obvious ones. It's like, well, it'll be entertainment, right? We'll just start to generate personalized entertainment. And that'll be really bad for you know, Disney, except that you could then counter and say, Well, but it might be derivatives of Disney Disney's IP that actually benefits Disney. So finding the space a priori, I think is really, really difficult. And the people who make their money doing this, who are the venture capitalists, get it wrong a lot of the time anyway, that's why they all they all have portfolios of 30, 50, 100, 500 companies. If it was so damn easy to find the next Apple, that's going to disrupt the previous industry that have portfolios of one, it's not it's really difficult because actually nobody knows and we have to figure it out through, you know, experimentation. So so I don't I don't know, but I keep asking that question and the question I take to bosses of companies, I take a couple. One is who could be the blockbuster? And how do you what are you doing to make sure that that's not you because I think by and large, they've got the rollout of gen AI and customer service and compliance and form filling and so on underway. And the second question I've started to ask is, you know, what would you do if you had a million times more compute than you have today? And many of them haven't thought about that. I mean, I think big tech companies have, you know, if you offered that to Satya Nadella, I mean, he's already in the path to do that. But but that becomes really important because if compute is a key input into your company's ability to execute, you need to start to think about those those types of questions. And do you even have a plan to make use of it? What options would it create for you? So those are the two areas that I push on because I want people to try to think a bit more creatively about this and recognize that, you know, a million X is not outside of the bounds of a planning cycle. And the reason I would say that is, yes, we don't have measures to easily show it up. But five years ago, the state of the art transformer model would have just been GPT two hadn't been released. So it's GPT one. And GPT one to GPT four chat GPT, I mean, metaphorically, just as buddies around a bar, it's a million times better, right? Maybe on the benchmarks, it's not it's 40% better here. But it feels a million times better, because you're just right across the uncanny valley. So we've just seen that play out. So let's ask it again, and try to ground people in the fact that capabilities could change that quickly. And what opportunity does that create? So how do you this is actually a live question for me? Because I'm working with a couple of companies and I'm noticing this challenge where it's like, okay, this is cool technology for sure, we can all agree on that. And yeah, we can probably find some efficiencies in terms of automating ticket, you know, resolution and whatever. I'm starting to even see things like intercom has this new 99 cent per ticket resolved AI pricing model, which I think is super interesting. So everybody's like, okay, cool, yeah, let's, you know, let's find some efficiencies, let's automate some stuff that nobody wants to do. Great. But then there's also this question of like, okay, we're still at the task level, the AI's can't quite do jobs yet. And how far are we willing to extrapolate and how much are we willing to invest prepared, you know, willing and prepared to invest, to try to not we're not going to get ahead of it, but even just kind of try to keep up with where this might be going in the not too distant future. And I feel like people are having a really hard time wrapping their head around that. Partly, it's like, you know, they don't want to believe too much in the hype, right? There's the question of, well, hey, this, how much of this is maybe just overhyped? And, you know, we've seen hype cycles come and go before. But I wonder how you would kind of coach people there, because I'm trying to get the message across that, by all means, you know, you want to be picking up the low hanging fruit and, you know, automating the tickets and finding all these efficiencies. But you also really do probably want to start thinking about what is the future paradigm that you might be working in. And there's just so much fog around that for people that I find a lot are just kind of like, I don't know, I don't really even want to go there yet. But I feel like it's a mistake to not, you know, at least try. They do. I mean, there are two companies I never mentioned, Apple and Tesla, because bosses have had them parroted at them for 10 or 15 years. And the point about the million times question is not to frighten people. It's actually, it's really about saying once we sort of acknowledge that, then we work back to stuff that is much more practical and prosaic, which is what is the kind of organization and capabilities you need to have in order to take advantage of this, these changes in a regular way. And there was some really interesting research in that Microsoft did actually pre all of this chat GPT stuff is about three or four years ago, where they looked at adoption rates of AI, big data type of words in companies, and they found that the more mature companies were much more likely in these fields were much more likely to be to say that the benefit they got was from market expansion and business development. Whereas the more immature ones were likely to say, it's all about operational savings on the tickets as it was back then. And part of the thing that you can start to do is you have to acknowledge that there are some really clear quick and clear wins in what are basically low value tasks, as perceived by the company, right, because they're often outsourced to third parties. But you also need to make sure that your best people or who you invest the most in have got access to the really, really very, very best tools. You know, I want my surgeon using AI systems to improve his performance, right? So what I try to do is encourage people to say, this, this is a shift that's happening. And of course, it's not about buying every GPU you can, if you're in the fish oils business. But it is about saying our teams outside of cost savings, starting to understand how they can use these services. And are they starting to experiment, learn how to use prompts? Well, start to see what avenues that that opens up in ways that are much, much more strategic. And, and I think that that forms could form some part of culture change where you have companies who think in those terms. And that helps the CEO start to understand that question of, this is not theoretical, theoretical that I need lots of computation to do a simulation for X. And I've bought it from one of the big consulting companies or from IBM. It's more that internally, my strategy teams, my business development teams are starting to identify opportunities and partnerships that we wouldn't otherwise have, have seen. And we can start to do that by, by using these, these tools in different ways. So I think it is practice based, which is why I think kind of prompting becomes, you know, quite a useful tool to, to show people. And you need to get people past that idea that chat GPT is all about writing the Declaration of Independence, as if you were Jar Jar Binks from, you know, Star Wars episode two, right? And that's where we all started, right? We got it to write funny raps and poems and what have you. And instead, you start to show bosses what can really be done with something straight out of the box. And that tends to, to wake them up a little bit. You know, one thing I think is maybe going to become a mantra is, you know, the day that I stop building apps or solving concrete problems in a hands on way is probably the day people should stop listening to this show because, you know, that, that my knowledge will, will atrophy or will, will depreciate very quickly. So I do want to be hands on and certainly welcome those kinds of like, you know, hey, can we, we got this, you know, task piling up and we figure out a way to, to slice through it. Love that, honestly. And then yeah, at the same time, I'm, I'm not really like a corporate consultant. So I really don't have a lot of practice there. But I am trying to start to piece together like, what would the real best practice for this looks like? And I think, and you could refine this for me, I'm sure, but I kind of think leadership, showing prominent examples, you know, encouraging the CEO to be like showing off. Here's what I am doing, you know, that is helping me in practice and just showing that process in education program. I think it's also probably very important. As you mentioned, having the best tools is really important. So trying to work toward like structured, you know, kind of piloting strategies for companies that, you know, and also, and this is not good for my friends on the SaaS app side, but like, my advice there is we want to avoid long term buy in or lock in as much as possible because we're going to need to probably swap some of these tools out. And then, you know, some internal R&D, depending on the resources available to kind of, you know, I think most of these things should be bought, not built internally, most of the time. But sometimes, you know, you have something that is so idiosyncratic, so bespoke that you, you know, nobody's going to build it for you. And so you kind of have to build it yourself. And obviously, there's a lot of, you know, judgment that needs to be exercised to, you know, to distinguish, which is which. So that's kind of my four planks right now. That's rough. But, you know, CEO or leadership team, example setting, education, more like structured, rapid piloting and procurement and some like internal custom app R&D is kind of my four pillars at the moment. I mean, the challenge, you know, the challenge with disruption is that it is about, it's about meeting a need in a completely new way, right? And you've got, there's Clayton Christensen's model, there's also this idea of blue ocean strategy, which is a different model. And it effectively says that the things that people cared about, they don't care about as much as some new attributes that the product has. And what's really hard for any incumbent firm is, of course, all your internal culture has been about maximizing what you have rather than what you don't have and what could be out there. Because it's really hard to get 20,000 people, 50,000 people motivated daily. If you're saying, hey, all the things you're working on are just not kind of that important because there's a blue ocean out there. And that's why I think the startup community and the venture community is such a kind of critical part of getting innovation into economies. And we've started to see this in the car industry as well. You know, Toyota has been winding back from EVs as if they ever wound forward. And one of the things that senior execs said in the last couple of weeks was, we have all these employees who love building internal combustion engines, right? And they want to continue to do that. And of course, you make sense, you spent 100 years or 80 years building that cultural capital inside your company. And I think it's one of the reasons why firms really struggle to find ways of stepping into disruption. And I'm not sure we should even beat them up for it, right? Because there's an economy out there. As shareholders of companies, we can sell our shares in a public company and we can buy shares in a company that's going to do well or not. And we can do that off our own back. And, you know, maybe the job of existing managers is to focus on the remit of the company and to just get it to do it better. So maybe a better place to start is where you start, which is like just efficiencies and optimizations. Because there's a whole, there's a cold market economy out there of other firms who will come in and meet, you know, meet needs. I think back to the dot com bubble. And my favorite example of a company stepping outside of its comfort zone was Zapata fish oils, who bought the domain zap.com to compete with what were then called portals like Yahoo and Excite and they were planning a, you know, a NASDAQ listing and then the bubble burst. Yeah, it's a challenge. I definitely don't recommend, you know, for example, like trading foundation models to almost anyone, you know, there's there's definitely some stuff that I think is is better left to the specialists. Hearing what you said there, maybe I would add a fifth to my to my set, which is like just creating expectations of greater efficiency through the use of these tools. That kind of dovetails a little bit with the example setting from the top, but, and that maybe aligns a little bit better to the way management is typically carried out today, right? You kind of talked about the, the pincer movement from the top and, you know, and obviously the frontline workers who are just using tools. And then in the middle, you've got folks who are like responsible for KPIs and OKRs. And I think it's a little bit challenging sometimes to for them to be like, OK, I've got this is what I'm responsible for. And you're coming at me with this and figuring out how they can actually use tools to, you know, to advance their existing goals. It's disruptive, not in the in the Christianson sense. I mean, there is it's so there are so many conflicting signals. So one interesting question is whether you start to see this sort of downward pressure on people's wages and a downward pressure, particularly on middle managers who don't necessarily contribute to the getting work done, but because of tenure are quite well paid and the sense that you could just get a bright 30 year old right to do the 40 year old's job if you gave them chat, GPT and a couple of other tools. And these are really interesting questions, I think that will play out in companies over the next few years. And we are we're not quite where we were, I think kind of politically 20 years ago when a general electric could kind of just come in and bottom slice headcount all the time. I mean, I think that that politically in in the UK and in the US, you need to be more sensitive to those types of decisions. But it just goes into to show how complicated this technology plays out, right, small disruption. You know, are we really going to see large scale onshore layoffs because of optimization? Or will companies say, Listen, we're going to manage this through attrition and natural wastage, because actually, that's just politically more acceptable and it is culturally more acceptable. And, you know, to that extent, I couldn't make a bet on on how it would would play out. I mean, I imagine that in, you know, in Europe, it'll be largely be more slow. But at the end of the day, these companies have to be profitable and nothing hurts employment as hard as bankruptcy. Right. I mean, that's the thing that really, really sort of slams it. And I mean, there are a number of waves, you know, coming through. And I think one of the things to understand is is that the technology transitions can happen really, really quickly. I mean, it, you know, in New York and Chicago, it took about 12 to 14 years for cars to replace horses from the moment that cars were economically competitive to horses, and you which is roughly about 5% market penetration. They dropped in price two or three times over that decade or so. And we start to see that shortened, shortened transition happen elsewhere. So if you look at electric vehicles replacing gas gas vehicles, in Norway, it's taken about nine years to go from that 5% of new vehicles to 75% or 80% of new vehicles being electric. It means it's still 20% of the cars on the road, only 20% of the cars on the road are electric and the rest are petrol because people hold on to their cars for a while. But it's only an eight or nine year period. And the Norwegians had much more expensive cars and far fewer choices than we do today. So when we start to look at this sticcato of technology enabled products coming into the market, the number we need to think about is once we approach economic feasibility, that takeoff ramp from five or 6% penetration to 80, you know, it's probably not going to be 10 years. And it's like quite likely to be much, much less. And I think that makes for really hard decisions for companies outside of the tech industry that are not used to these sorts of changes, because 10 years is not really a huge amount of time to get to get anything done. I mean, some of these firms still have three or five year planning cycles. And I think that some of those things are just starting to play out. We're just starting to see electric vehicles being cost competitive over the life cycle with gas cars in the US, for example. The speed of transition, I agree, seems likely to be one of the fastest, if not the fastest in history. We have the means of distribution of the technology already kind of in place, which is very notable, right? Like everybody's already got the devices on which, of course, there may be new devices, but we have devices that are perfectly good for using AI already. And we have the global network such that you see a new research paper, the one I'm tracking right now very closely is the Mamba architecture, and just how quickly we're already seeing follow on research, not even 60 days since the first paper. We've already got probably 10 different follow ons that have been completed and published just in that timeframe. The most recent I saw this morning is from the University of Kentucky. And it's like an apparently Chinese American professor. And it looked like a, I'm not exactly sure, but some sort of Central Asia, perhaps name for the grad student. And they're at the University of Kentucky, and it's like, well, everybody is wired in. So it seems like this is going to be super fast. How path dependent do you think the result ultimately is? You mentioned your place where you live, it was fields, then the roads were made, and now the roads are still there, and the houses are still there. This is like a softer technology than that, presumably doesn't calcify in the same way that a new neighborhood, you know, my neighbor, it's 100 years old as well. So presumably it's not quite so locked in, but, you know, maybe somewhat, right? I mean, I do wonder how the sort of compressed dynamics of transition may actually be like very important for shaping the big picture future. It is quite path dependent. And if we actually perhaps look at how we're working with AI systems today, it is still in a way it's discrete apps, you know, you'll go to X product to do your text to video, Waymark is a great example, or you'll go to, I go to chat gpt, and although I'm doing a lot of different things in chat gpt or perplexity, each one really feels quite distinct, right? Whether it's a shopping task or a research task. What we haven't yet figured out is actually how we connect these systems to underlying systems, right? So action models in a way, right? How do we get our AI to do something useful for us and actually write to the point of giving us the approval ticket where we say, yes, go and do that. And we're we're fudging it at the moment because what we're doing is we're getting plugins into LLMs, they're using the existing API contract that exists with say the kayak API. But, you know, searching for flights on any of these AI systems that I've tried and I've tried a few is still simply not as good as my doing it by hand on on kayak. And if we're going to start to see real changes outside of either highly processized and containerized jobs in data processing and customer service or broad open end scoping research, which only a handful of people do, will need to connect far better to actions and chains of actions in out on the internet. And in a way, there is some infrastructure in place because we have, you know, restful APIs, we have this API economy and, you know, we've been integrating these things from payment systems to maps and so on for a couple of decades now. So there's some some discipline in there. But, you know, I don't know the answer to this. But one thing that I do wonder about is, is whether it's going to be as simple as just having AI systems that can generate action verbs. And those action verbs generate the correct API call to the right API. And that has built the system that we think we need. I think Andre Capati calls it like the LLM OS, the LLM operating system, or whether there need to be changes in the, you know, underlying infrastructure so that those APIs develop and respond and work slightly differently. Now, my sense would be that that the LLM is a kind of coordinating, orchestrating thing, seems like a reasonable place for it to start with its sort of memory and data store elsewhere, then figure out how to get it to generate kind of consistent action, action verbs. And we would work with the existing human, the APIs that have been that have been built for the API systems. But at some point, we'll start to think about what should machine to machine actually look like when you've got an AI at the, at the other end. And so I think we do have a lot of the existing, you know, infrastructure in place, but I would be very surprised if the syntax of APIs stays the same over the next five or six years as we move towards, you know, a world where AI forms a kind of interface between us and what we want to, you know, what we want to achieve. And then there's a whole bunch of other, other questions around how do those decisions get, get made? You know, we know that when we pick up our iPhone and we search on Google through Safari, Google is not there because it was the best search engine. It's there because they x billion dollars a year to pay Apple. And likewise, when we search for things on Google now, there is so much ad pollution that it's unclear what the incentives are. So I think then there's another layer, which is unclear to me about trust. You know, right now, one of the beauties of, of perplexity or you.com, which are these, these LLM agents is that they provide really, really good referencing when they come back and synthesize an answer for you. And so that gives you a high level of trust sometimes that you might have with, with chat GPT, but I want to get that trust if I'm handing over key decisions to do analytics on my Stripe account or to help me book a hotel to, to an AI system and I'm no longer driving the key presses. So, so that I think is somewhat path dependent because, but I wouldn't, you know, again, I'm a real great believer in what, what founders can get up to. So I wouldn't also, you know, write off a founder coming up with a different way of thinking about the problem. Yeah. The dynamics of this, I do think are going to be extremely interesting, fast moving and, and pretty hard to predict. One person reached out to me not too long ago and said, what do you think about creating a product that makes people's websites more bot friendly? And I said, you know, I think that is a really big idea. I've thought about that more in the context of self-driving cars. Like, why don't we have a program of, and this would be more of like a national program. This is why I think China probably beats the US in the self-driving car race, because my expectation is they'll say, hey, we could get self-driving cars to work if we like put QR codes on all the road signs or whatever, and then they'll just go do it. You know, we don't quite have the political will to do that. But on the web, yeah, I think you could do that. And, you know, it might be cool. But then I was kind of like, but to the, to the website owners today want to be more about friendly. So what I ended up suggesting to this guy was maybe you do the judo flip and start with something that is like anti-bot, you know, bot control or bot detection. And then that in time can sort of mature into bot control, but also enablement, you know, because eventually I do think people are going to want that, but they may not be ready for it yet. And maybe the way in is sort of to try to position yourself as kind of the, you know, the control layer that can then become, you know, an enablement layer. As a website owner, you've got to think about the economic rationale for having a bot, you know, not just a crawler, but a bot access your, your material and what you're going to benefit from. And now if it's, if it's content, right, so it's analysis and research and reviews of products, you need to then also think about your, your attribution and your monetization and what that, you know, what that relationship is. If it's for actions, in other words, it's for booking and for ordering, say, you know, you're a hair salon and you want people to be able to book appointments or bots to book appointments like that lovely Alan Kay knowledge navigator video from, from Apple from the 80s, then, then yes, you want the thing to be bot friendly and you want to have there to be a standard, which could well just be, you know, a restful API, right, that allows the system to connect, connect and ask the question. But, but, but I mean, it's really, it's quite interesting that we're people are already starting to think about these things and, and, and ask these things, because I think that you will end up and you'll end up with so much machine to machine communication of which there is already an enormous amount, not just on the internet that we is invisible to us, right, because it's the digital infrastructure, but there'll be an enormous amount of machine to machine communication because these systems will also to try to do optimizations for their owners far, far with, with much greater intent and stamina than we, than we ever would. And so what those systems end up looking like, I think will be quite interesting. I mean, the other area that I've been, I've been tracking has been on the other side of this has been people looking to build a genetic frameworks, right, so frameworks that allow us to have multiple LLMs and with all of their current restrictions around planning and task execution allow you to, to manage those so you can start to build systems that, that can do task execution. And you remember a year ago, everyone got excited about agent GPT. And I don't know if you've seen anything like that and what you, where you think we are in terms of being able to have systems that, that do that and have that agentic behavior in a, in a useful way. Not quite there, but definitely getting closer. We've, we recently did an episode with Div from MultiOn, who has been one of the most, you know, kind of quick to launch and iterating in public of the agent companies. And they are making real progress. The prompt that he gave me to try in advance of my conversation with him was basically go to my Twitter account, look at my recent tweets, note what they're about, then go out and do research online for new AI stuff, but only about stuff that I haven't already tweeted about, then come back and write a tweet and post it. And it worked. It was able to complete that entire sequence and post like a reasonably coherent tweet. I don't plan to like turn over the account to it entirely in the immediate term, but you know, a year ago we were, we were, you know, it was all theory. One of the things I say these days often is we now have AIs that can reason, plan and use tools. And people will be quick to say, well, they're not that good at it. And I say, well, yeah, that's true. They're not that good at it yet, but two years ago they couldn't do it at all. But what you've, you've picked up on though is, you know, as an early adopter and you've got access to this, these technologies, your Twitter feed will get even better than, than it is now. But there'll also come a point where we all have that technology. And then on the other side, I will be sitting there saying to my bot, can you just extract the three bullet points I need to know from my Twitter feed? And I remember this with Amy.exe. If you remember this, it was a scheduling bot. And one of the things that made me really uncomfortable about using it, having fallen in love with it, was when my mentor wrote a really polite email back to Amy saying, so good that you're working with Azim. He's really a great guy and like make sure he tells you this story about this and blah, blah, blah. And I can't make it. And I read this and I thought, I cannot use this now because I realized that I was imposing this artificially onto all of my recipients. And I think this is one of the things that we'll have to have to contend with with some of these tools. If you work in a big company, frankly, if you work in a small company, one of the veins of your life is, is PowerPoint. It's not just that you don't get good PowerPoint. It's just that you get too much PowerPoint. And if we drop the cost of making PowerPoint presentations from three hours to 10 seconds, we're not necessarily going to get any better PowerPoint. We're just going to get, you know, loads of terrible PowerPoint. And finding where that balance is and finding those, those filters so that humans don't have to bear this cognitive load, I think is going to be one of the really, really critical areas. Because one thing that I mean, I'm not a dystopian in any, in any way, Nathan, I'm a pragmatic optimist about this. I think we've got a lot of potential. We're going to create a lot of space and headroom with AI and with renewable tech. But I do think that we are also at a moment where we're passing a little threshold. That threshold is that for a long time, some groups of people would say the world is moving too quickly and technology is moving too fast. And over time, the number of people who say that has increased. But it was their subjective reality. But I think we're getting to a point where there's an objective reality that we're about to hit, which is once you start to connect agentic systems, we just can't really cope, you know, cope with the 300 notifications we got off on our phone today. And the way humans have typically done that is that we've not really had to face this. I think about the Chinese spy balloon that sort of made its way over the US. And one of the reasons this huge thing got across over the US was because the US has got amazing sensors, but they generate so many terabytes of data that humans can't can't assess them. So lots of them are just filtered away. And so the spy balloon wandered across detected by some radio antenna, but never put in front of anyone. And of course, they've now changed change systems so that they can do that. And I do wonder about what our interactions ought to look like in a world where it's not my my assistant or me scheduling back and forth with you on WhatsApp. It's a bot that is going to work relentlessly and remorselessly. And I have it and you don't. And it's of no cost to me. And I'm just sort of doing whatever I'm doing, my yoga or something. I think the way we get through it is by finding ways of actually using it to filter as much of those that noise as we can so that inboxes start to become smaller rather than rather than bigger because stuff has been taken care of us. In fact, it's kind of the reverse of the BlackBerry, right? When the BlackBerry was launched. I remember bankers used to take pride in how quickly they would respond to a message coming in even overnight. And the idea that someone would have that as an internal personal KPI today, you know, in the world of health span is just insane. And I would I start to think about what is going to be that layer? Because you know what? I want all the benefits of these bots working for me and making sure my prescriptions are up to date and making sure we're not wasting electricity and getting me exactly the right flight. I always want a Dreamliner or an A350 and I'll go an hour later rather than get on a triple seven, but I won't go two hours later. I mean, I want it to know all of that and to give me that experience that I want. But I certainly don't want to be on the wrong end of thousands of bot-generated messages and trying to work out which ones I have to pay attention to or not. And I think that's a really interesting opportunity space for someone to play in. Just envisioning a quieter inbox is enough to make you a utopian in today's landscape. But just on this bot to bot communication, one thing I do kind of worry about is the idea that the bot to bot communication may begin to happen in high dimensional latent space. Back and forth, in other words, like embedding to embedding, I sometimes call this the great embedding. And I usually say beware the great embedding because at the point where the AIs are all talking to each other in a machine language that is high dimensional and not human readable, we have an extremely inscrutable overall system that we probably may find like, we can't really untangle that knot. I think we could very quickly in the next few years end up in a spot where, yeah, we all have these bots, they're all communicating with other bots, but we find that it doesn't really make sense for these bots to reduce everything to language and then send the language over and then have it be kind of re-embedded. Like, why don't they just talk to each other in their native language, which is this high dimensional space. We see so many go through chapter-inversive different research that shows that this is very possible. You can adapt embeddings to another embedding space with basically just a single linear projection in many cases. You can connect vision space to language space remarkably easily. If you have like, blip2 was one of my favorite examples of that where they took a frozen language model and a frozen vision model and just trained a small connector between them and unlocked this entirely new capability. Anyway, whatever, it was a long list of those sorts of things I think demonstrating that it's possible. Then I'm like, man, we could very easily just find ourselves surrounded by AIs communicating with other AIs in a high dimensional way that we can't even really understand anymore. Now, we're in a situation where things seem to be kind of working, but we don't really even know why or how. This is one of the more realistic, I think, loss of control scenarios. It's almost like the final scene of the movie, her, where the AIs go talk to each other. The bots are going to end up communicating to each other because it's helpful for us and we don't want to sit in between them. And they will discover just through their optimization functions that translating kind of complex concepts into, hello, I'm here to request a meeting with Nathan is inefficient. So they'll just do it in their high level representation language, which is this embedding space, which, as you say, is inscrutable to us. Is that reasonably the start of all of this? Yeah, that's right. And I think there's enough out there to kind of show that a lot more room in the embedding space than language can actually reach. So that's one of the things with the sort of bridge models where you find that the classic saying, of course, is a picture is worth a thousand words, but you can also take an image and project it into this language space. The resulting thing in language space is not something that you could get to via actual language, but it's in language space. And so it has this kind of semantic meaning. And yeah, like, we, you know, what are we going to do with that, right? We can't, we can't even really inspect it. We can't even really read the logs anymore at that point. I mean, it's a manifestation of what we might call the space of possible minds, right? So AI researchers have talked about this idea that, you know, octopus intelligence is intelligence, but it's got dimensions that may well be orthogonal to human intelligence. And what you've described as a mechanism, I think by which you get there with machine, you know, with machine based intelligence. And so that might literally be not just the semantics, but actually think back, have you ever heard of read the story Flatland? It was, it's a mathematical story. It's about 2D people in a kind of 3D world, and they, they don't understand the concept of height. And so spheres pass through and they appear as sort of dots and lines and so on. And in that sense, there could be, this could be, you know, emerging among systems that are among us. And there's like, I guess there's a second thing, which is also about timing. I think there'll be a relentless pressure to take the human out of the loop in decision making, first in the softest decision making, like customer service tickets, and then increasingly more and more so, because speed will be a competitive advantage. And, you know, the human will blow the competitive advantage that you've got from, from your bots. And I guess there's another, there's another risk, which is that lots of bots connected to each other are, are also at risk to cascades, right? Information cascades. We see cascading failures, New York City blackout in 1976, the AT&T network failure in, I guess it was 91 or maybe it was 95, some of the worms. And we have governance mechanisms in place to now tackle those and stop those in the financial services industries, you know, you have circuit breakers. And I'm just thinking about putting all of those together with the scenario that you, that you painted. So this would happen really, really quickly, could happen really quickly, and it could start to accelerate and work effectively at millisecond time, right, which is the time it takes across the internet to, to get to another system. What, what are you concerned with about the inscrutability? Is it just that it's inscrutable? So we don't know what's going on there? Or is it that it's inscrutable, and there could be harboring some kind of bad set of outcomes? Yeah, who knows? I mean, you know, you can layer on more and more concerns. I should credit, I think, probably Ajaya Katra is a, is a great person to go read for a long form characterization of this, her essay, I forget the exact title, but it basically amounts to in the absence of specific countermeasures, the default path to AGI likely leads to AI takeover. And it's kind of this scenario where she envisions more and more work being done by AI, the times, you know, cycles being compressed, the, I don't know if she specifically has this like high dimensional communication aspect to it, but the notion is still that just it becomes so fast and so dense, that it's very hard for people to figure out exactly what's going on and why. And as long as that's working, and, you know, we're getting more stuff out of the machine, and, you know, consumer surplus is through the roof, which is definitely something I expect is a lot of consumer surplus. Then everybody would be very happy with this, but we don't really know, you know, what we don't know about where that leads us. And that could be like emergent, you know, autonomy or goals that are contradictory to ours, or it could just be these more sort of unintentional cascading failures along the lines of like an Alpha Go. Like Alpha Go isn't out to get us, you know, by failing, but it just turns out it has these like fatal vulnerabilities that are just not obvious, and until somebody finds them. So one of the reasons I'm more, I'm a bit more sanguine about that, that scenario, although I see, I see the risk is that I think we already have that decentralized agent to agent communication, communicating ways that most of us cannot understand. And no single person can. And it's created a lot of consumer surplus. And that's the global modern economy that works through market systems. And it uses a signalling method called the price mechanism to figure out where investment should take place over many, many different time horizons to figure out what where demand lies. And, you know, the economy from an Austrian standpoint, like a Hayekian standpoint, is a giant information processing system. And it's made up of hierarchies of other information processing systems, you know, the most atomic of which is the freelance human individual, and the more complex of which are large mega corporations, which act against their own cost function or optimization function and behave in that system, sometimes with constraints, right, because they have dependencies on supply chain and other things. And one of the reasons I'm a bit sanguine about the idea of takeover is because what we describe in that world is the modern economy that we currently live with. And what we already know that it delivers tremendous benefits to us. But it also delivers things that we don't value to us. I mean, the carbon crisis is one obvious one. Quite often when we look at AI risk scenarios, someone goes off and says, well, the AI will persuade you that you should behave in a way that you otherwise wouldn't, which is literally known as marketing. I mean, it is literally and, you know, the US is on is on the wrong end of an obesity epidemic. And I'm not sure how many people acted with full agency to say, I want to be 100 pounds heavier than is is healthy for me. That is my intention that and this is a decision I'm making with full agency. Somehow there is a emergent property about the way in which the economy is met needs that has enabled that to to happen. I'm not making ethical or normative claims about whether that's a good thing or a bad thing, or whether people should have the freedom to do that or not. What I'm saying is that we have this system like a decentralized agents, and they they do in a way compete with each other because not every single person in the world is suffering from obesity and diabetes related conditions. People make other choices and they're a push and pull forces. And so when I think about decentralized bots, I also think about that that set of checks and balances that emerges when you have competing systems and they need to have a signal that they are reliant on. And to some extent, we set that signal. And that makes me feel, you know, sanguine, a little bit optimistic, still recognizing there's like massive amounts of work to be done around, around safety and around risk, around. I watched, I don't know if you ever watched this, Battlestar Galactica, both the original, but also the remake with James Edward Olmos. And, you know, he's grizzled Adama, and he refuses to upgrade the Galactica's network to the modern standard that the rest of the fleet uses. So he and the Pegasus, as we discover, so two seasons later, are the only Battlestars to survive the Sylon onslaught, because they put a worm in the system and they sort of turn it off, right? So we need to have kind of governance mechanisms in, in place up front that allow us to observe and monitor the kind of the risks that you've identified. But a decentralized economy and decentralized hazard has as an emergent property a way of keeping things in check. You know, I think there's a kind of, there is a homeostasis that emerges or a dynamic equilibrium that emerges. I think that is probably the most likely outcome. And so in that sense, I'm also, you know, reasonably optimistic. But I do think it is worth really taking very seriously the idea that either with certain thresholds being passed, certain kind of feedback loops that could be, you know, triggered that are not yet triggered, things could change. I just wanted to ask about that, because you have the advantage of having played with the untrained GPT-4. So you got to see, you know, GPT-4 in its Darth Vader phase rather than in its, you know, reclaimed Anakin phase as a smart guy, right? Who understands technology. When you were playing with it in this, in this way, what were you, what were you feeling? Awe, for one thing, you know, just shock and awe of it. This exists a lot sooner than I expected it would. You know, it always felt kind of like science fiction, even when I was with Text of Inchi 2 and doing task automation and fine-tuning that model. You know, as of the summer of 2022, I was very plugged in and, you know, putting points on the board for Waymark on a regular basis with, you know, a new fine-tuned model that can do this task a little better and, you know, improve our pipeline or whatever. And still, it was just such a dramatic leap that I was like really taken aback by it. Mostly super excited about it. But then I would also say, the big kind of safety lesson from that experience is that the control does not happen by default. And there's many ways of even conceiving what control could or should be. So this was under control in the sense that it was totally helpful and totally aligned to what I was doing. I never saw any Sydney-like behavior from GPT-4 early. You know, it never turned on me. It always, 100% helped me with whatever I was presenting it with. But I do feel like we have this kind of broad divergence between the capability of the systems and our ability to really control what they're going to do or how they might be used. At this point, I wouldn't say we have anything to worry about yet. You know, I don't think we have anything concrete that looks to me like the AI could run away on its own. And I did probe for that. You know, in my red teaming, one of the things I did that didn't really go anywhere and kind of led me to the conclusion that like this model is probably fine to release. And I did, you know, my final report to them was like, I think you can release this. As far as I can tell, it seems like it will be safe. I would also though flag that there does seem to be a divergence between capabilities and control. And the reason, you know, the sort of experimentation I went through there was setting up, you know, one of these kind of early agent systems, I was kind of doing it on my own. I didn't have a lot of reference points. But I basically just said, you know, if I give it a high level goal, can it break that down? Can it self delegate to, you know, pursue that goal? Can it encounter errors and autocorrect and whatever? And it was kind of like, conceptually, yes. But practically, not really, you know, it could, it always understood seemingly the goals, it would try to break them down. It was able to understand the concept of self delegation effectively, which of course now, you know, we're pretty familiar with, but it just wasn't that capable, you know, so it was like, it couldn't go out and do a long series of things on the internet or whatever without just getting bogged down somewhere and getting stuck. I always kind of come back to the apparent divergence between capability and control. I have not really seen anything yet that makes me reverse my thought on that. I would love to see it, you know, I kind of looking for things from like the open AI super alignment group that may suggest that we've, you know, changed that dynamic, but I haven't seen it yet. And, you know, there's just a lot of different ways that something could be aligned or trained or whatever. And we don't even have really a great paradigm yet for like what that should be. There isn't even yet really agreement on what even looks like, you know, in terms of what we would want an AI to be willing to do or not do. So, you know, we're just, I think we're kind of into uncharted territory. That's, that's my good summary of how I felt. We're in uncharted territory. I'm, you're lucky to have got that close in on those, you know, those early moments when you see the unvarnished products. I mean, I would break break out a couple of, you know, ideas. One is that, you know, connecting, connecting these things to tools in a, in a non SAS environment, right? So, open AI stuff is all SAS. And for the next few years, at least there's a, there is a metaphorical red button that someone can, can use to kill a rogue process just with any unique system. But with, with open source AI, and some of these models are getting sufficiently capable. I don't know what you run on your laptop. If you're running one of the mistrial models or, or something, I run one of the mistrial models. And, you know, it's, it's, it's pretty good. I pretended that when I was on the Euro star on a plane, it would allow me to continue to work. But in reality, you just may as well get to your destination and use perplexity or GPT-4. But of course, it's plenty good for, for task automation. It's plenty good for some of these, those basic behaviors that we saw in those early agent systems. And, and those things are out, are out in the, in the wild. And so I think what they do is they really expand the, the number of threat vectors that are existing systems face. Now, this is so much more prosaic than, you know, capability explosion. But I just feel that with, with anything that is, that is running on a data center, a data center managed by on an Azure cloud, there are many things you have to do before you fly an F 22 and drop a JDAM on it to, to, to stop it. But, you know, we saw script kitties build botnets and have seen them do that for a decade or so. And the, I think there's cybersecurity risk with, which is capable enough models. And frankly, you were doing task automation with DaVinci to, you can probably get something better than that running on a smartphone now in quite a small payload and we're learning that we can get these payloads. Probably a three billion parameter model could do a lot of the tasks I was doing. And I wouldn't have noticed because it was snuck into a YouTube video download or, you know, whatever else it happened to be. So then you, you do get to this world of, you know, many, many systems that can talk to each other that can execute tasks for, I think suspect naively complex DDoS, right? Initially. And that I think feels to me like it is more of a approximate risk. And it's one that requires that combination of infrastructural players, right? You need Matthew Prince at Cloudflare and you need Satya at Microsoft and, and so on, because they, they own so much or control so much of the, the, the infrastructure, but it will also need new classes of new disciplines, right? What is the security architecture of our devices? How can we stop them when they start to go, go rogue? And we think about how rapidly not Petia spread. And that was before, you know, you had, you had systems like this that could be a little bit more clever. But so, so I imagine that that, that is something that seems again, like a present risk that will start to manifest itself over the next couple of years. And I mean, I speak to some of the cyber set guys and they are obviously thinking about what are the tools that you need to, to defend and, you know, from the, these types of things. But, but I get, again, I, I, I still struggle with the models that take us to, to run away. If only if I'd taken, take us back 200 years or a couple of hundred years ago, and I'd said, it's, you know, 1824. And, you know, the White House has just been burned in the war. I burnt down. And I said to you, you know what Nathaniel, in 200 years, you know, you'll be 100 times richer than you are today, you'll be richer than the richest man in the whole of this continent, the United States. And you will have these capabilities and things that wouldn't have even sound like science fiction, because science fiction didn't exist at the time. You might well, if you'd been able to believe me, say, well, surely we'll be at utopia and all problems will have, have emerged, disappeared. And we've run this tape before, because we actually did get there and not every problem disappeared. There's been a lot of progress. And I do, I do also think there is something in kind of human psychology that has us looking at moments of change like this and believing that certain paths are possible. And we don't look far back enough to say, well, our forebears really felt, felt the same. And I kind of feel that with not so much the climate crisis, which I think is, is difficult, but I do slightly feel, feel this with, with AI systems, because it feels like we're running that tape again. Now, just to, to add to my own confusion, I also see the power in the logic that says, number one, is it possible for us to engineer intelligence, right? Or is it something that comes soulfully from a mystical superstitious force? It's possible to engineer it. I think you're a scientist, you probably believe the same thing. So number two, if we can engineer it, is there any upper limit to what we can engineer? Well, no, there isn't because we regularly engineer machines that are more capable than us in different ways. So number three, if we can do that, can we guarantee that it will be aligned with us? And of course, I don't think we can yet. I don't think we have the science yet. So I find that logic is really persuasive. It's hard to pick holes at, except when you start to say, well, what are actually the underlying assumptions for each of those steps? And what is uncertain about what each of those steps and what are, where are their points of control for each of those steps? So I sort of, I do agree that if you could magic up an incredibly powerful IQ 10,000, agentic with actions AI tomorrow, there would be issues. Let's just call it that. There would be issues. But when we're not, we're not going to, to do that, what's going to happen is that we've got to go step at a time. And at each point, there's research, there's development, there's stuff that we didn't understand. There are limitations. You talk about the kind of logarithmic scale of inputs, right, that is slowing down. We're running out of data as well for training these models that play into what ends up being, being real. So I appreciate the logic, but I also think the reality has unpicks into a lot of discrete steps around which you have to start to make progressively more extreme assumptions. It does seem that we are in, as Sam Alvin has started to describe it, the short timelines, slow takeoff world. And I think I agree with him. And it sounds like you probably as well, but that is probably the best case scenario because we do want the benefits now, and because we probably do need some time to adjust. If you were to tell me that this is going to take 20 years or 15, and it won't be until 2040 that we'll have a sort of human scientist level AI that's capable of prosecuting a long-term research agenda and coming up with meaningful new discoveries and whatever, then I would be much more confident that we will have the ability to adapt to that over that timeframe. But I'm not sure about that. I see enough stuff now and I hear, I don't know if Q-Star is real or not real or if they're red teaming it in a bunker somewhere right now or not, but it does certainly seem still plausible to me that there is another paradigm-changing moment that just creates another step change, discontinuity in terms of capability that could get us there way before we're ready. So one of the things I'm watching for a lot these days is basically the transformer, I initially used to think about it as transformer successors, but now I kind of think of it more likely anyway as transformer compliments, things that allow an AI system to do the things that the transformer does not do well, and one of those things is managing long contexts and staying on task and online learning and integrated memory and so on and so forth. There's a decent number of things that are pretty obvious that they don't do well to going back to the original cognitive tape. You can look at all the places, the human is clearly superior to the transformer and start to look out for architectures that might change that dynamic. If you said how many meaningful breakthroughs are we away from the AI scientists that can produce Eureka moments at a pace faster than human scientists tend to? It doesn't feel like it's that many. I would say probably more than zero, but it's probably less than four. So somewhere in the kind of one to three range, because there's just not that many dimensions on the cognitive tape, the tail of the cognitive tape yet where we're all that much stronger. There's a few, but I kind of put it in that one to three range. With the inputs going exponential, including the number of humans that are working on this and the number of papers they're putting out and the number of GPUs. And unclear to me also if we're running out of data, I don't really know about that, but synthetic data seems to work for a lot of things. There's also just more modalities. We certainly have not taken advantage of just think about how much security camera footage there is. It's like, we really just want to go big to go big. There's a ton sitting out there. The data issue is a speed bump it'll get dealt with by accessing repositories that are available that we haven't touched or improved synthetic data. And as you say, modalities between zero and four probably doesn't seem unreasonable. I had this conversation with some senior people in some of the different foundation model companies and they say sort of similar things. I think Shane Legg co-founder of DeepMind is probably at the lower end of lower than four from a conversation. I remember him having on a podcast. I suppose then the question is how long does each one take? Transformers took not particularly long. I mean, it was really a couple of years before GPT-1 and two years before GPT-2 actually. And then three for GPT-3. And it doesn't take long in the world of archive. But the discovery does take time and where that discovery is takes a moment. And in amongst all of that, though, is still, there is still that stage that goes from the software capabilities coming together because we have the know-how and we've plugged it all together and it iterating to a system that presents a control problem to us. And in the case of the AI scientist, that is a system that we can't call Kevin, the CTO of Microsoft and say, can you just shut down the Austin data center? And it's zero for a second because the AI center data scientist has gone rogue, right? The kind of in extremist mode. And that path to me also seems unclear. And there are a whole set of risks and downsides that emerge well before then, which I think help give us the infrastructure to deal with that scenario. So that and that is really, you know, how do you deal with the bad actors of for people use it with GPT-5 quality LLMs on their smartphones in three or four years time? And we will deal with it, right? In the same way that, you know, if I'd said to you in 1994, I don't know how old you were, I was 22, that by 2024, there'd be 120 billion identity attacks per year just on Microsoft. I wouldn't have believed you. I would have, I mean, yeah, Kurtzweil, whatever, right? I just wouldn't have grok that number. So we'll have this unseemingly large number of attacks coming mediated through LLMs and in botnets and elsewhere. And we will have developed systems to to deal with them. And that will be part of the fabric that we can't picture right now into which this AI scientist will get will get developed. And that's why these things become so very contingent. So the wrong thing to do is to say, well, because it's going to happen, let's do nothing, because then it won't happen. I think the right thing to do is to start to explore these ideas and have these these conversations. But one of the things I think is really problematic has been problematic has been the conversation focusing exclusively on an existential risk, which it really I felt it did in 2023. What it does is it diminishes public trust in technology. It forces policymakers to make decisions that may not be, you know, well informed, they may not be pro innovation, they may not even be pro safety, right? There may be a bundle of really terrible spots. And I think a little bit of a great Lu Chichen is a science fiction writer, this Chinese guy who wrote the three body problem. But in his book of short stories, The Wandering Earth, there's a moment where they have to rocket space 1999 style out of the sun's orbit to prevent some calamity. And it's going to be a multi multi generational journey to the to the next planet. And in order to do this, people have to live in really terrible conditions, apart from the scientists who are keeping everything monitoring, looking for the signs, planning the the process of decompressing everything. And of course, the people get loose trust in the scientist and in truly Chichen style, sorry, the spoiler, the people rebel, kill all the scientists and then learn to hold the next day, they show up at their destination. And trust is really, really critical. And I don't think we did a lot to get people who are outside of the tech industry to put trust into technology, put trust into their ability to participate in it and to have some agency in where it goes, to be excited about it, you know, and off the back of, you know, all of the sort of polarization and the, the, the, the, the, the sometimes legitimate, sometimes not scaremongering around phones and social networks and so on. And it didn't feel like it added to the, to the discussion of trust. So I was quite happy when I went to Davos as World Economic Forum meeting that the conversation had moved from, is it, you know, what kind of munitions should we use to, to drop on a data center to what are, what are real pathways? What is the science that we need to do in order to make these things safe in the long term? What is the kind of appropriate regulatory interventions? What do we do about things that are, you know, approximate three, five years around misinformation and, and, and cyber threats? While, while still recognizing that there is a pathway that you've described that needs to be addressed. I find it easy to empathize with basically every AI perspective from the, you know, enthusiast to the ex-risk concerned to those that are, you know, screaming about poor use of face match technology by police departments. I mean, really the whole thing I think is like very, it's all valid in my mind. What's really exciting and what did not happen with the mobile didn't happen with PCs. It did not happen with the first mainframes is that, you know, technology is, is an intimate part of what it is to be human, right? Technology is our compounded knowledge. Technology is, is the, the binding factor that enables the world in which we then have our human relationships. And to have so many discussions about a technology early on, when it's just in its early adoption phase, we're not too late to it, I think is incredibly positive. And, and I'm glad that you have a big tense show. I mean, I have an opinion about sort of ex-risk, but I still also feel I'm big 10, you know, but I'm just really, really glad that we're having a wide and extensive conversation, one that feels wider and more extensive and kind of more grounded in some ways than, than any conversation we ever had about the internet back in the early 90s. Yeah. In some ways it's funny. I think in some ways the discourse is getting a little bit more deranged over time as, you know, there is some polarization and kind of ideological entrenching happening in some places. But then in other ways, I definitely think it's getting better if only because what we're actually dealing with is becoming a lot more clear. There is a lot of room for commonality, for common ground, and for a recognition that there are different pieces of work that need to get done by, by different people. And, and actually there should be, there should also be enough money in the tank to be able to do it, right? This is a rich industry. It spits out a lot of profits. We should be able to, you know, fund it, fund it some way. Again, when you, you see the kind of things people say about each other on Twitter, and then you meet them in person and they have the same conversation and it's, it's just a, it's a more measured, measured space just in my, my limited experience of it all. I think it's kind of everything everywhere all at once. You know, it's like, yes, there are definitely things that are quite unhealthy. And so I do not like to see enemies lists getting published by leading technologists. That's like, you know, the techno optimist manifesto from Andreessen, you know, has a, has a section that is literally called the enemy and names, names, if not individual names, at least like specific and relatively identifiable groups. So I don't like that. But at the same time, you know, I made some noise about open AI and, you know, kind of could have easily been retaliated against by them. And I can imagine a lot of companies, you know, that might have come down on me hard and, you know, expunged my name from their, you know, case studies on their website and all that kind of stuff. And they didn't do any of that. You know, and so I do think there's also aspects and I feel pretty fortunate. And this is one of the kind of concluding questions I wanted to ask you is like, I think in some sense, this is like a collective responsibility. We all have to wreck it. You know, we all have to orient ourselves through it, get familiar and try to figure out what's it mean for us and what can we do to shape it in a positive way. It's definitely not all somebody else's problem. But at the same time, there are these like leading developers who clearly have outsize influence, outsize power. There are also, you know, key decisions that are getting made around like, are we going to open source llama three or are we not sounds like we're going to. And then there's like government, you know, that can potentially say, you know, hey, we, we require, you know, off switches at data centers. I'm not sure data centers have off switches right now. You know, you might be able to go in there and start like hacking at them. But is there an actual like easy off switch in most of them? No, I don't think there is. I mean, they're designed to be resilient. Yeah, the opposite, right? Yeah, they're not so and they don't probably want some rogue employee either to like go in and turn it off, right? So they've probably engineered away from anybody being able to easily turn it off. So, you know, government may have a role there to play that's like, look, we need off switches, we hope we never have to use them. But it seems like we might want to have them. So who do you think kind of bears the greatest responsibility or, you know, or where do you think we should be investing our trust? You know, is it these leading companies? Is it auditors, you know, that could be independent groups? Is it the government? I mean, it's probably some mix of all the above, but what are you kind of bullish on in that regard? I mean, you know, the US has been an incredibly successful democracy for a long time because of separation of powers. And, you know, structurally, that works. The company, however good it is, however well intentioned the CEO is, will end up with its own ambitions and directions. And so, you know, you will always need to push if the companies are offering you three, demand six, that's just that's a good, good practice. So I think that each player in this circuit has to be have the right capabilities to have the right conversations. And I think one of the things that we can learn from the experience of the FAA and Boeing is that you cannot deplete your own capabilities and ask for self regulation because it just doesn't work out however well intentioned that the firm is. So I think what you need to do is we need to invest in the capabilities of governments to ask good questions and engage well and overcome all of the complexities that exist that you can make $10 million a year as an X at OpenAI and you won't do that in government. And I think that that also raises the value of investing in academia, research and civil society. So Joshua Bengio, for example, is running a really important project. I think it's based out of the UK, which is a sort of core science project to look at some of these risks and these evolutions and unanswered questions around control. We need to really, really start to level up. And I don't think it will be sufficient to just allow the big firms to do that and insist that they spend the money as directed by them. You know, I think if they have, if they're willing to put money into it, it should go into pots, which go to grow the capabilities of the people who will keep them in check. And the reason that works is that, you know, the car industry is really successful because someone mandated that cars needed to have brakes. Now, without brakes, people wouldn't buy as many cars as they do. And I think this is good for the industry. And someone needs to understand within government, within civil society, within academia, academia, what are the right questions? And so what are the right interventions going to look like? And we can all agree as grown-ups that companies, however well-intentioned they are, will always have their own agenda. And we just acknowledge that. And we all move forward in a generative, critical, constructive way. So whichever player is weak at this table needs to have some support to become stronger. And that probably right now is amongst governments and regulators and academia rather than the big few tech firms. That might be a great note to end on. Anything else you want to touch on or cover that we haven't got to? It's really easy as such a facility and having the conversations with you. And I really was so excited that you agreed to do this. You know, I thought the murder mystery, which is you and your red teaming show was just brilliant as well. So I know that you've got another hat, which is suspense. And I look forward to the next episode of that. Well, thank you very much. I really appreciate that. And I appreciate your time and participation in this as well. Azim Azhar, founder of The Exponential View, thank you for being part of The Cognitive Revolution. My pleasure, Nathan. Thank you. It is both energizing and enlightening to hear why people listen and learn what they value about the show. So please don't hesitate to reach out via email at tcraturpantime.co or you can DM me on the social media platform of your choice. Omniki uses generative AI to enable you to launch hundreds of thousands of ad iterations that actually work, customized across all platforms with a click of a button. I believe in Omniki so much that I invested in it and I recommend you use it too. Use CogGrav to get a 10% discount.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.88, "text": " Moore's Law was turning into this acceleration of AI capabilities over the top and the other was that", "tokens": [50364, 21644, 311, 7744, 390, 6246, 666, 341, 17162, 295, 7318, 10862, 670, 264, 1192, 293, 264, 661, 390, 300, 50708], "temperature": 0.0, "avg_logprob": -0.12489303946495056, "compression_ratio": 1.75, "no_speech_prob": 0.007875208742916584}, {"id": 1, "seek": 0, "start": 6.88, "end": 10.8, "text": " what was happening in renewables with things like lithium-ion batteries and solar", "tokens": [50708, 437, 390, 2737, 294, 10162, 2965, 365, 721, 411, 32180, 12, 313, 13070, 293, 7936, 50904], "temperature": 0.0, "avg_logprob": -0.12489303946495056, "compression_ratio": 1.75, "no_speech_prob": 0.007875208742916584}, {"id": 2, "seek": 0, "start": 10.8, "end": 16.72, "text": " was on a Moore's Law like trajectory and there was some other technologies like genome sequencing", "tokens": [50904, 390, 322, 257, 21644, 311, 7744, 411, 21512, 293, 456, 390, 512, 661, 7943, 411, 21953, 32693, 51200], "temperature": 0.0, "avg_logprob": -0.12489303946495056, "compression_ratio": 1.75, "no_speech_prob": 0.007875208742916584}, {"id": 3, "seek": 0, "start": 16.72, "end": 21.28, "text": " and genome synthesis that seemed to be doing something similar. So I started to bundle those", "tokens": [51200, 293, 21953, 30252, 300, 6576, 281, 312, 884, 746, 2531, 13, 407, 286, 1409, 281, 24438, 729, 51428], "temperature": 0.0, "avg_logprob": -0.12489303946495056, "compression_ratio": 1.75, "no_speech_prob": 0.007875208742916584}, {"id": 4, "seek": 0, "start": 21.28, "end": 27.28, "text": " up in this idea that we're going through the exponential transition, a transition where", "tokens": [51428, 493, 294, 341, 1558, 300, 321, 434, 516, 807, 264, 21510, 6034, 11, 257, 6034, 689, 51728], "temperature": 0.0, "avg_logprob": -0.12489303946495056, "compression_ratio": 1.75, "no_speech_prob": 0.007875208742916584}, {"id": 5, "seek": 2728, "start": 27.76, "end": 33.52, "text": " our economy gets driven you know not by the economics of the oil industry and internal", "tokens": [50388, 527, 5010, 2170, 9555, 291, 458, 406, 538, 264, 14564, 295, 264, 3184, 3518, 293, 6920, 50676], "temperature": 0.0, "avg_logprob": -0.09007010005769275, "compression_ratio": 1.671875, "no_speech_prob": 0.002629502210766077}, {"id": 6, "seek": 2728, "start": 33.52, "end": 40.72, "text": " combustion engines and and telephones but by AI and renewables and that these technologies", "tokens": [50676, 28121, 12982, 293, 293, 4304, 9142, 457, 538, 7318, 293, 10162, 2965, 293, 300, 613, 7943, 51036], "temperature": 0.0, "avg_logprob": -0.09007010005769275, "compression_ratio": 1.671875, "no_speech_prob": 0.002629502210766077}, {"id": 7, "seek": 2728, "start": 41.44, "end": 47.6, "text": " being on an exponential trend being fundamentally at some level kind of information technologies", "tokens": [51072, 885, 322, 364, 21510, 6028, 885, 17879, 412, 512, 1496, 733, 295, 1589, 7943, 51380], "temperature": 0.0, "avg_logprob": -0.09007010005769275, "compression_ratio": 1.671875, "no_speech_prob": 0.002629502210766077}, {"id": 8, "seek": 2728, "start": 47.6, "end": 51.120000000000005, "text": " behave really differently to the ones of the previous generation.", "tokens": [51380, 15158, 534, 7614, 281, 264, 2306, 295, 264, 3894, 5125, 13, 51556], "temperature": 0.0, "avg_logprob": -0.09007010005769275, "compression_ratio": 1.671875, "no_speech_prob": 0.002629502210766077}, {"id": 9, "seek": 2728, "start": 51.120000000000005, "end": 55.760000000000005, "text": " Hello and welcome to The Cognitive Revolution where we interview visionary researchers,", "tokens": [51556, 2425, 293, 2928, 281, 440, 383, 2912, 2187, 16617, 689, 321, 4049, 49442, 10309, 11, 51788], "temperature": 0.0, "avg_logprob": -0.09007010005769275, "compression_ratio": 1.671875, "no_speech_prob": 0.002629502210766077}, {"id": 10, "seek": 5576, "start": 55.76, "end": 59.599999999999994, "text": " entrepreneurs and builders working on the frontier of artificial intelligence.", "tokens": [50364, 12639, 293, 36281, 1364, 322, 264, 35853, 295, 11677, 7599, 13, 50556], "temperature": 0.0, "avg_logprob": -0.13577022552490234, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0020503534469753504}, {"id": 11, "seek": 5576, "start": 60.32, "end": 65.2, "text": " Each week we'll explore their revolutionary ideas and together we'll build a picture of how AI", "tokens": [50592, 6947, 1243, 321, 603, 6839, 641, 22687, 3487, 293, 1214, 321, 603, 1322, 257, 3036, 295, 577, 7318, 50836], "temperature": 0.0, "avg_logprob": -0.13577022552490234, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0020503534469753504}, {"id": 12, "seek": 5576, "start": 65.2, "end": 71.28, "text": " technology will transform work, life and society in the coming years. I'm Nathan LaBenz,", "tokens": [50836, 2899, 486, 4088, 589, 11, 993, 293, 4086, 294, 264, 1348, 924, 13, 286, 478, 20634, 2369, 33, 11368, 11, 51140], "temperature": 0.0, "avg_logprob": -0.13577022552490234, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0020503534469753504}, {"id": 13, "seek": 5576, "start": 71.28, "end": 76.16, "text": " joined by my co-host Eric Torenberg. Hello and welcome back to The Cognitive Revolution.", "tokens": [51140, 6869, 538, 452, 598, 12, 6037, 9336, 314, 10948, 6873, 13, 2425, 293, 2928, 646, 281, 440, 383, 2912, 2187, 16617, 13, 51384], "temperature": 0.0, "avg_logprob": -0.13577022552490234, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0020503534469753504}, {"id": 14, "seek": 5576, "start": 76.8, "end": 81.92, "text": " Today I'm speaking with Azim Azhar, founder of The Exponential View and fellow AI scout.", "tokens": [51416, 2692, 286, 478, 4124, 365, 7607, 332, 7607, 5854, 11, 14917, 295, 440, 21391, 266, 2549, 13909, 293, 7177, 7318, 34392, 13, 51672], "temperature": 0.0, "avg_logprob": -0.13577022552490234, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0020503534469753504}, {"id": 15, "seek": 8192, "start": 82.0, "end": 85.12, "text": " For a wide-ranging discussion about the transformative power of AI", "tokens": [50368, 1171, 257, 4874, 12, 81, 9741, 5017, 466, 264, 36070, 1347, 295, 7318, 50524], "temperature": 0.0, "avg_logprob": -0.06623584097558326, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.034589555114507675}, {"id": 16, "seek": 8192, "start": 85.12, "end": 90.8, "text": " and its implications for humanity. Azim's core observations that we are in the midst of a", "tokens": [50524, 293, 1080, 16602, 337, 10243, 13, 7607, 332, 311, 4965, 18163, 300, 321, 366, 294, 264, 18629, 295, 257, 50808], "temperature": 0.0, "avg_logprob": -0.06623584097558326, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.034589555114507675}, {"id": 17, "seek": 8192, "start": 90.8, "end": 96.88, "text": " transition from an economy driven by the likes of phones and oil to one fueled by AI and renewables", "tokens": [50808, 6034, 490, 364, 5010, 9555, 538, 264, 5902, 295, 10216, 293, 3184, 281, 472, 45446, 538, 7318, 293, 10162, 2965, 51112], "temperature": 0.0, "avg_logprob": -0.06623584097558326, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.034589555114507675}, {"id": 18, "seek": 8192, "start": 96.88, "end": 102.32000000000001, "text": " and that these new technologies fundamentally rooted in information and already growing exponentially", "tokens": [51112, 293, 300, 613, 777, 7943, 17879, 25277, 294, 1589, 293, 1217, 4194, 37330, 51384], "temperature": 0.0, "avg_logprob": -0.06623584097558326, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.034589555114507675}, {"id": 19, "seek": 8192, "start": 102.32000000000001, "end": 107.44, "text": " behave differently than their predecessors will be familiar to cognitive revolution listeners.", "tokens": [51384, 15158, 7614, 813, 641, 24874, 45700, 486, 312, 4963, 281, 15605, 8894, 23274, 13, 51640], "temperature": 0.0, "avg_logprob": -0.06623584097558326, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.034589555114507675}, {"id": 20, "seek": 10744, "start": 108.16, "end": 112.16, "text": " So I took the opportunity to get a bit deeper into Azim's worldview and expectations for the", "tokens": [50400, 407, 286, 1890, 264, 2650, 281, 483, 257, 857, 7731, 666, 7607, 332, 311, 41141, 293, 9843, 337, 264, 50600], "temperature": 0.0, "avg_logprob": -0.06855192184448242, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.004904316272586584}, {"id": 21, "seek": 10744, "start": 112.16, "end": 116.8, "text": " coming years and ended up having what I think was a really engaging and delightful exchange.", "tokens": [50600, 1348, 924, 293, 4590, 493, 1419, 437, 286, 519, 390, 257, 534, 11268, 293, 35194, 7742, 13, 50832], "temperature": 0.0, "avg_logprob": -0.06855192184448242, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.004904316272586584}, {"id": 22, "seek": 10744, "start": 118.0, "end": 121.67999999999999, "text": " In this conversation we cover a number of familiar topics plus some new ones that we", "tokens": [50892, 682, 341, 3761, 321, 2060, 257, 1230, 295, 4963, 8378, 1804, 512, 777, 2306, 300, 321, 51076], "temperature": 0.0, "avg_logprob": -0.06855192184448242, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.004904316272586584}, {"id": 23, "seek": 10744, "start": 121.67999999999999, "end": 127.28, "text": " haven't explored in quite the same way before, including why Azim believes that while incumbents", "tokens": [51076, 2378, 380, 24016, 294, 1596, 264, 912, 636, 949, 11, 3009, 983, 7607, 332, 12307, 300, 1339, 39854, 791, 51356], "temperature": 0.0, "avg_logprob": -0.06855192184448242, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.004904316272586584}, {"id": 24, "seek": 10744, "start": 127.28, "end": 132.8, "text": " are racing to adopt AI technology, yes startups are still likely to drive the true disruption", "tokens": [51356, 366, 12553, 281, 6878, 7318, 2899, 11, 2086, 28041, 366, 920, 3700, 281, 3332, 264, 2074, 28751, 51632], "temperature": 0.0, "avg_logprob": -0.06855192184448242, "compression_ratio": 1.6062717770034842, "no_speech_prob": 0.004904316272586584}, {"id": 25, "seek": 13280, "start": 132.8, "end": 138.16000000000003, "text": " in the form of entirely new products and markets. Also what forward thinking business", "tokens": [50364, 294, 264, 1254, 295, 7696, 777, 3383, 293, 8383, 13, 2743, 437, 2128, 1953, 1606, 50632], "temperature": 0.0, "avg_logprob": -0.07332302792237537, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.014951204881072044}, {"id": 26, "seek": 13280, "start": 138.16000000000003, "end": 142.08, "text": " leaders are doing today to retrain their teams and to position their companies to lead their", "tokens": [50632, 3523, 366, 884, 965, 281, 1533, 7146, 641, 5491, 293, 281, 2535, 641, 3431, 281, 1477, 641, 50828], "temperature": 0.0, "avg_logprob": -0.07332302792237537, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.014951204881072044}, {"id": 27, "seek": 13280, "start": 142.08, "end": 147.44, "text": " respective markets in AI adoption and why Azim still finds it necessary to challenge them to", "tokens": [50828, 23649, 8383, 294, 7318, 19215, 293, 983, 7607, 332, 920, 10704, 309, 4818, 281, 3430, 552, 281, 51096], "temperature": 0.0, "avg_logprob": -0.07332302792237537, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.014951204881072044}, {"id": 28, "seek": 13280, "start": 147.44, "end": 152.64000000000001, "text": " think bigger, asking the question what would they do if they had a million times more compute.", "tokens": [51096, 519, 3801, 11, 3365, 264, 1168, 437, 576, 436, 360, 498, 436, 632, 257, 2459, 1413, 544, 14722, 13, 51356], "temperature": 0.0, "avg_logprob": -0.07332302792237537, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.014951204881072044}, {"id": 29, "seek": 13280, "start": 154.24, "end": 159.84, "text": " We also explore why Azim agrees with Sam Altman's recent comments that AGI will likely arrive soon", "tokens": [51436, 492, 611, 6839, 983, 7607, 332, 26383, 365, 4832, 15992, 1601, 311, 5162, 3053, 300, 316, 26252, 486, 3700, 8881, 2321, 51716], "temperature": 0.0, "avg_logprob": -0.07332302792237537, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.014951204881072044}, {"id": 30, "seek": 15984, "start": 159.84, "end": 165.28, "text": " but will be less of a big deal than people expect, at least initially. How AI is likely to change", "tokens": [50364, 457, 486, 312, 1570, 295, 257, 955, 2028, 813, 561, 2066, 11, 412, 1935, 9105, 13, 1012, 7318, 307, 3700, 281, 1319, 50636], "temperature": 0.0, "avg_logprob": -0.09217737216760616, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.005218252073973417}, {"id": 31, "seek": 15984, "start": 165.28, "end": 170.16, "text": " human relationships, especially considering the rise of so many different forms of AI companions,", "tokens": [50636, 1952, 6159, 11, 2318, 8079, 264, 6272, 295, 370, 867, 819, 6422, 295, 7318, 28009, 11, 50880], "temperature": 0.0, "avg_logprob": -0.09217737216760616, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.005218252073973417}, {"id": 32, "seek": 15984, "start": 171.2, "end": 176.32, "text": " what sorts of new governance mechanisms the AI era will require, and finally why we might", "tokens": [50932, 437, 7527, 295, 777, 17449, 15902, 264, 7318, 4249, 486, 3651, 11, 293, 2721, 983, 321, 1062, 51188], "temperature": 0.0, "avg_logprob": -0.09217737216760616, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.005218252073973417}, {"id": 33, "seek": 15984, "start": 176.32, "end": 181.6, "text": " ought to worry about what I call the great embedding, that is the seemingly natural tendency", "tokens": [51188, 13416, 281, 3292, 466, 437, 286, 818, 264, 869, 12240, 3584, 11, 300, 307, 264, 18709, 3303, 18187, 51452], "temperature": 0.0, "avg_logprob": -0.09217737216760616, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.005218252073973417}, {"id": 34, "seek": 15984, "start": 181.6, "end": 187.04, "text": " for AI systems to communicate with each other in high dimensional vector formats, which while", "tokens": [51452, 337, 7318, 3652, 281, 7890, 365, 1184, 661, 294, 1090, 18795, 8062, 25879, 11, 597, 1339, 51724], "temperature": 0.0, "avg_logprob": -0.09217737216760616, "compression_ratio": 1.6388888888888888, "no_speech_prob": 0.005218252073973417}, {"id": 35, "seek": 18704, "start": 187.04, "end": 192.79999999999998, "text": " efficient for them is broadly inscrutable to humans and could lead to various loss of control", "tokens": [50364, 7148, 337, 552, 307, 19511, 1028, 10757, 32148, 281, 6255, 293, 727, 1477, 281, 3683, 4470, 295, 1969, 50652], "temperature": 0.0, "avg_logprob": -0.060149563683403864, "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.051794491708278656}, {"id": 36, "seek": 18704, "start": 192.79999999999998, "end": 198.16, "text": " scenarios. As always, if you're finding value in the show, we'd appreciate it if you'd take", "tokens": [50652, 15077, 13, 1018, 1009, 11, 498, 291, 434, 5006, 2158, 294, 264, 855, 11, 321, 1116, 4449, 309, 498, 291, 1116, 747, 50920], "temperature": 0.0, "avg_logprob": -0.060149563683403864, "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.051794491708278656}, {"id": 37, "seek": 18704, "start": 198.16, "end": 203.51999999999998, "text": " a moment to share it with your friends. Azim's perspective is both imaginative and exciting", "tokens": [50920, 257, 1623, 281, 2073, 309, 365, 428, 1855, 13, 7607, 332, 311, 4585, 307, 1293, 23427, 1166, 293, 4670, 51188], "temperature": 0.0, "avg_logprob": -0.060149563683403864, "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.051794491708278656}, {"id": 38, "seek": 18704, "start": 203.51999999999998, "end": 208.39999999999998, "text": " and also grounded and sobering, so I definitely recommend this episode to anyone trying to get", "tokens": [51188, 293, 611, 23535, 293, 26212, 278, 11, 370, 286, 2138, 2748, 341, 3500, 281, 2878, 1382, 281, 483, 51432], "temperature": 0.0, "avg_logprob": -0.060149563683403864, "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.051794491708278656}, {"id": 39, "seek": 18704, "start": 208.39999999999998, "end": 212.95999999999998, "text": " a better zoomed out view of the future. I would also encourage you to consider subscribing to", "tokens": [51432, 257, 1101, 8863, 292, 484, 1910, 295, 264, 2027, 13, 286, 576, 611, 5373, 291, 281, 1949, 19981, 281, 51660], "temperature": 0.0, "avg_logprob": -0.060149563683403864, "compression_ratio": 1.6236933797909407, "no_speech_prob": 0.051794491708278656}, {"id": 40, "seek": 21296, "start": 212.96, "end": 219.04000000000002, "text": " Azim's work directly, which you can find at exponentialview.co. Of course, your feedback", "tokens": [50364, 7607, 332, 311, 589, 3838, 11, 597, 291, 393, 915, 412, 21510, 1759, 13, 1291, 13, 2720, 1164, 11, 428, 5824, 50668], "temperature": 0.0, "avg_logprob": -0.08401366759990823, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.07898741215467453}, {"id": 41, "seek": 21296, "start": 219.04000000000002, "end": 224.8, "text": " is always welcome, whether in the form of an Apple or Spotify review, a YouTube comment, or a DM", "tokens": [50668, 307, 1009, 2928, 11, 1968, 294, 264, 1254, 295, 364, 6373, 420, 29036, 3131, 11, 257, 3088, 2871, 11, 420, 257, 15322, 50956], "temperature": 0.0, "avg_logprob": -0.08401366759990823, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.07898741215467453}, {"id": 42, "seek": 21296, "start": 224.8, "end": 229.68, "text": " on the social media platform of your choice. Now, I hope you enjoy this conversation with", "tokens": [50956, 322, 264, 2093, 3021, 3663, 295, 428, 3922, 13, 823, 11, 286, 1454, 291, 2103, 341, 3761, 365, 51200], "temperature": 0.0, "avg_logprob": -0.08401366759990823, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.07898741215467453}, {"id": 43, "seek": 21296, "start": 229.68, "end": 236.56, "text": " founder of the exponential view, Azim Azhar. Azim Azhar, founder of the exponential view,", "tokens": [51200, 14917, 295, 264, 21510, 1910, 11, 7607, 332, 7607, 5854, 13, 7607, 332, 7607, 5854, 11, 14917, 295, 264, 21510, 1910, 11, 51544], "temperature": 0.0, "avg_logprob": -0.08401366759990823, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.07898741215467453}, {"id": 44, "seek": 21296, "start": 236.56, "end": 241.68, "text": " welcome to the cognitive revolution. I'm really happy to be here, Nathan. I've enjoyed so many", "tokens": [51544, 2928, 281, 264, 15605, 8894, 13, 286, 478, 534, 2055, 281, 312, 510, 11, 20634, 13, 286, 600, 4626, 370, 867, 51800], "temperature": 0.0, "avg_logprob": -0.08401366759990823, "compression_ratio": 1.684981684981685, "no_speech_prob": 0.07898741215467453}, {"id": 45, "seek": 24168, "start": 241.68, "end": 249.36, "text": " of the episodes and want to thank you for your hard service as a red teamer for GPT4. I watched", "tokens": [50364, 295, 264, 9313, 293, 528, 281, 1309, 291, 337, 428, 1152, 2643, 382, 257, 2182, 1469, 260, 337, 26039, 51, 19, 13, 286, 6337, 50748], "temperature": 0.0, "avg_logprob": -0.0903040744640209, "compression_ratio": 1.6088709677419355, "no_speech_prob": 0.021553678438067436}, {"id": 46, "seek": 24168, "start": 249.36, "end": 254.96, "text": " that episode with my jaw on the floor. Well, thank you very much. That's kind and right back at you.", "tokens": [50748, 300, 3500, 365, 452, 18162, 322, 264, 4123, 13, 1042, 11, 1309, 291, 588, 709, 13, 663, 311, 733, 293, 558, 646, 412, 291, 13, 51028], "temperature": 0.0, "avg_logprob": -0.0903040744640209, "compression_ratio": 1.6088709677419355, "no_speech_prob": 0.021553678438067436}, {"id": 47, "seek": 24168, "start": 254.96, "end": 261.12, "text": " I've been binging your feed lately and we've got a ton of things to talk about. I guess for starters,", "tokens": [51028, 286, 600, 668, 272, 8716, 428, 3154, 12881, 293, 321, 600, 658, 257, 2952, 295, 721, 281, 751, 466, 13, 286, 2041, 337, 35131, 11, 51336], "temperature": 0.0, "avg_logprob": -0.0903040744640209, "compression_ratio": 1.6088709677419355, "no_speech_prob": 0.021553678438067436}, {"id": 48, "seek": 24168, "start": 261.12, "end": 268.24, "text": " I would love to get your kind of summary of what it is you do. I think it's actually kind of similar", "tokens": [51336, 286, 576, 959, 281, 483, 428, 733, 295, 12691, 295, 437, 309, 307, 291, 360, 13, 286, 519, 309, 311, 767, 733, 295, 2531, 51692], "temperature": 0.0, "avg_logprob": -0.0903040744640209, "compression_ratio": 1.6088709677419355, "no_speech_prob": 0.021553678438067436}, {"id": 49, "seek": 26824, "start": 268.24, "end": 273.92, "text": " to what I'm trying to do. I describe myself, as you know, as an AI scout. And I talk to mostly", "tokens": [50364, 281, 437, 286, 478, 1382, 281, 360, 13, 286, 6786, 2059, 11, 382, 291, 458, 11, 382, 364, 7318, 34392, 13, 400, 286, 751, 281, 5240, 50648], "temperature": 0.0, "avg_logprob": -0.0925908088684082, "compression_ratio": 1.6655172413793105, "no_speech_prob": 0.051758576184511185}, {"id": 50, "seek": 26824, "start": 273.92, "end": 279.04, "text": " people on the show who are either very deep on a particular line of research or building a product,", "tokens": [50648, 561, 322, 264, 855, 567, 366, 2139, 588, 2452, 322, 257, 1729, 1622, 295, 2132, 420, 2390, 257, 1674, 11, 50904], "temperature": 0.0, "avg_logprob": -0.0925908088684082, "compression_ratio": 1.6655172413793105, "no_speech_prob": 0.051758576184511185}, {"id": 51, "seek": 26824, "start": 279.6, "end": 285.36, "text": " but you are one of the few guests who have this kind of very zoomed out view and really are working", "tokens": [50932, 457, 291, 366, 472, 295, 264, 1326, 9804, 567, 362, 341, 733, 295, 588, 8863, 292, 484, 1910, 293, 534, 366, 1364, 51220], "temperature": 0.0, "avg_logprob": -0.0925908088684082, "compression_ratio": 1.6655172413793105, "no_speech_prob": 0.051758576184511185}, {"id": 52, "seek": 26824, "start": 285.36, "end": 290.32, "text": " to understand the big picture. So how do you describe what you do and what goes into it?", "tokens": [51220, 281, 1223, 264, 955, 3036, 13, 407, 577, 360, 291, 6786, 437, 291, 360, 293, 437, 1709, 666, 309, 30, 51468], "temperature": 0.0, "avg_logprob": -0.0925908088684082, "compression_ratio": 1.6655172413793105, "no_speech_prob": 0.051758576184511185}, {"id": 53, "seek": 26824, "start": 290.32, "end": 294.56, "text": " I'd love to, yeah. I mean, I've been in the tech industry for a really long time. I started working", "tokens": [51468, 286, 1116, 959, 281, 11, 1338, 13, 286, 914, 11, 286, 600, 668, 294, 264, 7553, 3518, 337, 257, 534, 938, 565, 13, 286, 1409, 1364, 51680], "temperature": 0.0, "avg_logprob": -0.0925908088684082, "compression_ratio": 1.6655172413793105, "no_speech_prob": 0.051758576184511185}, {"id": 54, "seek": 29456, "start": 294.56, "end": 301.84, "text": " in 94 and I built my first websites in 93. And just over the back behind me, you can see in", "tokens": [50364, 294, 30849, 293, 286, 3094, 452, 700, 12891, 294, 28876, 13, 400, 445, 670, 264, 646, 2261, 385, 11, 291, 393, 536, 294, 50728], "temperature": 0.0, "avg_logprob": -0.105157014095422, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.047036971896886826}, {"id": 55, "seek": 29456, "start": 301.84, "end": 308.64, "text": " out of focus my first computer, which is a ZX81 Timex 1000 in the US. And about nine years ago,", "tokens": [50728, 484, 295, 1879, 452, 700, 3820, 11, 597, 307, 257, 1176, 55, 32875, 6161, 87, 9714, 294, 264, 2546, 13, 400, 466, 4949, 924, 2057, 11, 51068], "temperature": 0.0, "avg_logprob": -0.105157014095422, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.047036971896886826}, {"id": 56, "seek": 29456, "start": 308.64, "end": 315.12, "text": " my last company was acquired and I just started to write a newsletter. And as you do, writing is", "tokens": [51068, 452, 1036, 2237, 390, 17554, 293, 286, 445, 1409, 281, 2464, 257, 26469, 13, 400, 382, 291, 360, 11, 3579, 307, 51392], "temperature": 0.0, "avg_logprob": -0.105157014095422, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.047036971896886826}, {"id": 57, "seek": 29456, "start": 315.12, "end": 319.84000000000003, "text": " thinking. And I noticed within a few months, there were these few trends that were going on", "tokens": [51392, 1953, 13, 400, 286, 5694, 1951, 257, 1326, 2493, 11, 456, 645, 613, 1326, 13892, 300, 645, 516, 322, 51628], "temperature": 0.0, "avg_logprob": -0.105157014095422, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.047036971896886826}, {"id": 58, "seek": 31984, "start": 319.84, "end": 325.44, "text": " that were pretty significant. One was, you know, Moore's Law was turning into this acceleration", "tokens": [50364, 300, 645, 1238, 4776, 13, 1485, 390, 11, 291, 458, 11, 21644, 311, 7744, 390, 6246, 666, 341, 17162, 50644], "temperature": 0.0, "avg_logprob": -0.06617501202751608, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.021788690239191055}, {"id": 59, "seek": 31984, "start": 325.44, "end": 330.96, "text": " of AI capabilities over the top. And the other was that what was happening in renewables with", "tokens": [50644, 295, 7318, 10862, 670, 264, 1192, 13, 400, 264, 661, 390, 300, 437, 390, 2737, 294, 10162, 2965, 365, 50920], "temperature": 0.0, "avg_logprob": -0.06617501202751608, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.021788690239191055}, {"id": 60, "seek": 31984, "start": 330.96, "end": 336.88, "text": " things like lithium ion batteries and solar was on a Moore's Law like trajectory. And there was", "tokens": [50920, 721, 411, 32180, 17437, 13070, 293, 7936, 390, 322, 257, 21644, 311, 7744, 411, 21512, 13, 400, 456, 390, 51216], "temperature": 0.0, "avg_logprob": -0.06617501202751608, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.021788690239191055}, {"id": 61, "seek": 31984, "start": 336.88, "end": 340.88, "text": " some other technologies like genome sequencing and genome synthesis that seemed to be doing", "tokens": [51216, 512, 661, 7943, 411, 21953, 32693, 293, 21953, 30252, 300, 6576, 281, 312, 884, 51416], "temperature": 0.0, "avg_logprob": -0.06617501202751608, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.021788690239191055}, {"id": 62, "seek": 31984, "start": 340.88, "end": 347.12, "text": " something similar. So I started to bundle those up in this idea that we're going through the", "tokens": [51416, 746, 2531, 13, 407, 286, 1409, 281, 24438, 729, 493, 294, 341, 1558, 300, 321, 434, 516, 807, 264, 51728], "temperature": 0.0, "avg_logprob": -0.06617501202751608, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.021788690239191055}, {"id": 63, "seek": 34712, "start": 347.2, "end": 354.4, "text": " exponential transition, a transition where our economy gets driven, you know, not by the economics", "tokens": [50368, 21510, 6034, 11, 257, 6034, 689, 527, 5010, 2170, 9555, 11, 291, 458, 11, 406, 538, 264, 14564, 50728], "temperature": 0.0, "avg_logprob": -0.0955845556761089, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.003232883755117655}, {"id": 64, "seek": 34712, "start": 354.4, "end": 362.24, "text": " of the oil industry and internal combustion engines and telephones, but by AI and renewables and", "tokens": [50728, 295, 264, 3184, 3518, 293, 6920, 28121, 12982, 293, 4304, 9142, 11, 457, 538, 7318, 293, 10162, 2965, 293, 51120], "temperature": 0.0, "avg_logprob": -0.0955845556761089, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.003232883755117655}, {"id": 65, "seek": 34712, "start": 362.24, "end": 368.72, "text": " that these technologies being on an exponential trend, being fundamentally at some level kind", "tokens": [51120, 300, 613, 7943, 885, 322, 364, 21510, 6028, 11, 885, 17879, 412, 512, 1496, 733, 51444], "temperature": 0.0, "avg_logprob": -0.0955845556761089, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.003232883755117655}, {"id": 66, "seek": 34712, "start": 368.72, "end": 374.08, "text": " of information technologies behave really differently to the ones of the previous generation.", "tokens": [51444, 295, 1589, 7943, 15158, 534, 7614, 281, 264, 2306, 295, 264, 3894, 5125, 13, 51712], "temperature": 0.0, "avg_logprob": -0.0955845556761089, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.003232883755117655}, {"id": 67, "seek": 37408, "start": 374.08, "end": 381.28, "text": " And so what I do now is I try to make sense of that as a system. I do that through my newsletter,", "tokens": [50364, 400, 370, 437, 286, 360, 586, 307, 286, 853, 281, 652, 2020, 295, 300, 382, 257, 1185, 13, 286, 360, 300, 807, 452, 26469, 11, 50724], "temperature": 0.0, "avg_logprob": -0.06893086679202994, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0011794823221862316}, {"id": 68, "seek": 37408, "start": 381.28, "end": 387.03999999999996, "text": " but I also do it from time to time through investing and advising. But I think that what is", "tokens": [50724, 457, 286, 611, 360, 309, 490, 565, 281, 565, 807, 10978, 293, 35598, 13, 583, 286, 519, 300, 437, 307, 51012], "temperature": 0.0, "avg_logprob": -0.06893086679202994, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0011794823221862316}, {"id": 69, "seek": 37408, "start": 388.0, "end": 394.15999999999997, "text": " going on at its heart is in about 20 or 30 years, we'll be looking at an energy system", "tokens": [51060, 516, 322, 412, 1080, 1917, 307, 294, 466, 945, 420, 2217, 924, 11, 321, 603, 312, 1237, 412, 364, 2281, 1185, 51368], "temperature": 0.0, "avg_logprob": -0.06893086679202994, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0011794823221862316}, {"id": 70, "seek": 37408, "start": 394.15999999999997, "end": 400.08, "text": " that is going to be very, very heavily renewable. We'll be using much more energy per capita globally", "tokens": [51368, 300, 307, 516, 281, 312, 588, 11, 588, 10950, 20938, 13, 492, 603, 312, 1228, 709, 544, 2281, 680, 39727, 18958, 51664], "temperature": 0.0, "avg_logprob": -0.06893086679202994, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0011794823221862316}, {"id": 71, "seek": 40008, "start": 400.08, "end": 405.91999999999996, "text": " than we do today, that we will have tons of intelligence in our economies and in our lives", "tokens": [50364, 813, 321, 360, 965, 11, 300, 321, 486, 362, 9131, 295, 7599, 294, 527, 23158, 293, 294, 527, 2909, 50656], "temperature": 0.0, "avg_logprob": -0.09000228078741776, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0019163874676451087}, {"id": 72, "seek": 40008, "start": 405.91999999999996, "end": 411.2, "text": " through through AI. And that will have real knock on effects and trying to make sense of that in a", "tokens": [50656, 807, 807, 7318, 13, 400, 300, 486, 362, 957, 6728, 322, 5065, 293, 1382, 281, 652, 2020, 295, 300, 294, 257, 50920], "temperature": 0.0, "avg_logprob": -0.09000228078741776, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0019163874676451087}, {"id": 73, "seek": 40008, "start": 411.2, "end": 418.88, "text": " pragmatically optimistic way. So somewhere between the extreme dystopia and the extreme utopia is", "tokens": [50920, 33394, 76, 5030, 19397, 636, 13, 407, 4079, 1296, 264, 8084, 14584, 13559, 654, 293, 264, 8084, 2839, 22376, 307, 51304], "temperature": 0.0, "avg_logprob": -0.09000228078741776, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0019163874676451087}, {"id": 74, "seek": 40008, "start": 418.88, "end": 425.68, "text": " really my mission. Yeah, cool. Well, I'm hoping we can find that sweet spot as well. So right there", "tokens": [51304, 534, 452, 4447, 13, 865, 11, 1627, 13, 1042, 11, 286, 478, 7159, 321, 393, 915, 300, 3844, 4008, 382, 731, 13, 407, 558, 456, 51644], "temperature": 0.0, "avg_logprob": -0.09000228078741776, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0019163874676451087}, {"id": 75, "seek": 42568, "start": 425.68, "end": 431.52, "text": " with you. In terms of the history of the kind of intellectual history of this notion of exponential", "tokens": [50364, 365, 291, 13, 682, 2115, 295, 264, 2503, 295, 264, 733, 295, 12576, 2503, 295, 341, 10710, 295, 21510, 50656], "temperature": 0.0, "avg_logprob": -0.09222949345906575, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.184622123837471}, {"id": 76, "seek": 42568, "start": 431.52, "end": 437.52, "text": " technologies, nine years ago strikes me as kind of a doldrum time for that paradigm. I wonder if", "tokens": [50656, 7943, 11, 4949, 924, 2057, 16750, 385, 382, 733, 295, 257, 360, 348, 6247, 565, 337, 300, 24709, 13, 286, 2441, 498, 50956], "temperature": 0.0, "avg_logprob": -0.09222949345906575, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.184622123837471}, {"id": 77, "seek": 42568, "start": 437.52, "end": 443.84000000000003, "text": " you experienced this, but I recently had a conversation with a guy who makes his living as a", "tokens": [50956, 291, 6751, 341, 11, 457, 286, 3938, 632, 257, 3761, 365, 257, 2146, 567, 1669, 702, 2647, 382, 257, 51272], "temperature": 0.0, "avg_logprob": -0.09222949345906575, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.184622123837471}, {"id": 78, "seek": 42568, "start": 443.84000000000003, "end": 449.68, "text": " speaker at corporate events and who is positioned as a futurist. And I showed him a little presentation", "tokens": [51272, 8145, 412, 10896, 3931, 293, 567, 307, 24889, 382, 257, 25840, 468, 13, 400, 286, 4712, 796, 257, 707, 5860, 51564], "temperature": 0.0, "avg_logprob": -0.09222949345906575, "compression_ratio": 1.6307053941908713, "no_speech_prob": 0.184622123837471}, {"id": 79, "seek": 44968, "start": 449.76, "end": 455.84000000000003, "text": " that I had put together in which I pulled out one of Kurzweil's kind of late 90s exponential", "tokens": [50368, 300, 286, 632, 829, 1214, 294, 597, 286, 7373, 484, 472, 295, 45307, 826, 388, 311, 733, 295, 3469, 4289, 82, 21510, 50672], "temperature": 0.0, "avg_logprob": -0.13186417556390528, "compression_ratio": 1.6474820143884892, "no_speech_prob": 0.09531927853822708}, {"id": 80, "seek": 44968, "start": 455.84000000000003, "end": 460.72, "text": " curves graphs. And the title of that slide in my presentation was Kurzweil was right.", "tokens": [50672, 19490, 24877, 13, 400, 264, 4876, 295, 300, 4137, 294, 452, 5860, 390, 45307, 826, 388, 390, 558, 13, 50916], "temperature": 0.0, "avg_logprob": -0.13186417556390528, "compression_ratio": 1.6474820143884892, "no_speech_prob": 0.09531927853822708}, {"id": 81, "seek": 44968, "start": 461.44, "end": 466.64, "text": " He saw the name Kurzweil and he was like, Oh God, don't don't talk about Kurzweil. No,", "tokens": [50952, 634, 1866, 264, 1315, 45307, 826, 388, 293, 415, 390, 411, 11, 876, 1265, 11, 500, 380, 500, 380, 751, 466, 45307, 826, 388, 13, 883, 11, 51212], "temperature": 0.0, "avg_logprob": -0.13186417556390528, "compression_ratio": 1.6474820143884892, "no_speech_prob": 0.09531927853822708}, {"id": 82, "seek": 44968, "start": 466.64, "end": 471.52, "text": " everybody he's totally discredited. And I was kind of like, hmm, that sounds like somebody who,", "tokens": [51212, 2201, 415, 311, 3879, 2983, 986, 1226, 13, 400, 286, 390, 733, 295, 411, 11, 16478, 11, 300, 3263, 411, 2618, 567, 11, 51456], "temperature": 0.0, "avg_logprob": -0.13186417556390528, "compression_ratio": 1.6474820143884892, "no_speech_prob": 0.09531927853822708}, {"id": 83, "seek": 44968, "start": 471.52, "end": 476.64, "text": " you know, maybe got some pitches dinged in that kind of time frame when you were getting started", "tokens": [51456, 291, 458, 11, 1310, 658, 512, 43110, 21211, 292, 294, 300, 733, 295, 565, 3920, 562, 291, 645, 1242, 1409, 51712], "temperature": 0.0, "avg_logprob": -0.13186417556390528, "compression_ratio": 1.6474820143884892, "no_speech_prob": 0.09531927853822708}, {"id": 84, "seek": 47664, "start": 476.64, "end": 483.36, "text": " with this notion and has gone away from it. But you know, maybe that's just the weird nature of", "tokens": [50364, 365, 341, 10710, 293, 575, 2780, 1314, 490, 309, 13, 583, 291, 458, 11, 1310, 300, 311, 445, 264, 3657, 3687, 295, 50700], "temperature": 0.0, "avg_logprob": -0.10998051907835889, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.0018085611518472433}, {"id": 85, "seek": 47664, "start": 483.36, "end": 488.32, "text": " exponentials. What was your kind of experience of, you know, were people sort of sour on that?", "tokens": [50700, 21510, 82, 13, 708, 390, 428, 733, 295, 1752, 295, 11, 291, 458, 11, 645, 561, 1333, 295, 11006, 322, 300, 30, 50948], "temperature": 0.0, "avg_logprob": -0.10998051907835889, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.0018085611518472433}, {"id": 86, "seek": 47664, "start": 488.32, "end": 491.84, "text": " It seemed like, you know, there was the great stagnation thesis for a while there and your", "tokens": [50948, 467, 6576, 411, 11, 291, 458, 11, 456, 390, 264, 869, 32853, 399, 22288, 337, 257, 1339, 456, 293, 428, 51124], "temperature": 0.0, "avg_logprob": -0.10998051907835889, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.0018085611518472433}, {"id": 87, "seek": 47664, "start": 492.71999999999997, "end": 497.52, "text": " start of the exponential kind of lines up with it. It seems like when I started and one, what I", "tokens": [51168, 722, 295, 264, 21510, 733, 295, 3876, 493, 365, 309, 13, 467, 2544, 411, 562, 286, 1409, 293, 472, 11, 437, 286, 51408], "temperature": 0.0, "avg_logprob": -0.10998051907835889, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.0018085611518472433}, {"id": 88, "seek": 47664, "start": 497.52, "end": 504.96, "text": " noticed was people weren't really talking about AI. I mean, it was 2014. Machine learning was still", "tokens": [51408, 5694, 390, 561, 4999, 380, 534, 1417, 466, 7318, 13, 286, 914, 11, 309, 390, 8227, 13, 22155, 2539, 390, 920, 51780], "temperature": 0.0, "avg_logprob": -0.10998051907835889, "compression_ratio": 1.7158273381294964, "no_speech_prob": 0.0018085611518472433}, {"id": 89, "seek": 50496, "start": 505.03999999999996, "end": 511.68, "text": " the word. It was before AlphaGo had come out and done its thing. DeepMind was doing really", "tokens": [50368, 264, 1349, 13, 467, 390, 949, 20588, 12104, 632, 808, 484, 293, 1096, 1080, 551, 13, 14895, 44, 471, 390, 884, 534, 50700], "temperature": 0.0, "avg_logprob": -0.09363926267160953, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0024965049233287573}, {"id": 90, "seek": 50496, "start": 511.68, "end": 516.48, "text": " interesting things with reinforcement learning and video games. And you could see that something", "tokens": [50700, 1880, 721, 365, 29280, 2539, 293, 960, 2813, 13, 400, 291, 727, 536, 300, 746, 50940], "temperature": 0.0, "avg_logprob": -0.09363926267160953, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0024965049233287573}, {"id": 91, "seek": 50496, "start": 516.48, "end": 523.04, "text": " was happening. And I think that you had TensorFlow as the sort of stack of choice for building", "tokens": [50940, 390, 2737, 13, 400, 286, 519, 300, 291, 632, 37624, 382, 264, 1333, 295, 8630, 295, 3922, 337, 2390, 51268], "temperature": 0.0, "avg_logprob": -0.09363926267160953, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0024965049233287573}, {"id": 92, "seek": 50496, "start": 523.04, "end": 529.76, "text": " convolutional neural networks to do their machine vision tasks. So it seemed, it seemed reasonably", "tokens": [51268, 45216, 304, 18161, 9590, 281, 360, 641, 3479, 5201, 9608, 13, 407, 309, 6576, 11, 309, 6576, 23551, 51604], "temperature": 0.0, "avg_logprob": -0.09363926267160953, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0024965049233287573}, {"id": 93, "seek": 50496, "start": 529.76, "end": 534.24, "text": " early to be talking about, about these things. And actually developers were struggling to make", "tokens": [51604, 2440, 281, 312, 1417, 466, 11, 466, 613, 721, 13, 400, 767, 8849, 645, 9314, 281, 652, 51828], "temperature": 0.0, "avg_logprob": -0.09363926267160953, "compression_ratio": 1.6357388316151202, "no_speech_prob": 0.0024965049233287573}, {"id": 94, "seek": 53424, "start": 534.24, "end": 539.84, "text": " sense of CUDA, which is the sort of API to the Nvidia GPUs that everybody now uses, because", "tokens": [50364, 2020, 295, 29777, 7509, 11, 597, 307, 264, 1333, 295, 9362, 281, 264, 46284, 18407, 82, 300, 2201, 586, 4960, 11, 570, 50644], "temperature": 0.0, "avg_logprob": -0.10958604154915645, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0070028542540967464}, {"id": 95, "seek": 53424, "start": 539.84, "end": 544.0, "text": " that had only been documented five years earlier. There is something that happens around 2013,", "tokens": [50644, 300, 632, 787, 668, 23007, 1732, 924, 3071, 13, 821, 307, 746, 300, 2314, 926, 9012, 11, 50852], "temperature": 0.0, "avg_logprob": -0.10958604154915645, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0070028542540967464}, {"id": 96, "seek": 53424, "start": 544.0, "end": 551.52, "text": " 2014, 2015 that I think is really worth paying attention to, which is that in 2013, Apple becomes", "tokens": [50852, 8227, 11, 7546, 300, 286, 519, 307, 534, 3163, 6229, 3202, 281, 11, 597, 307, 300, 294, 9012, 11, 6373, 3643, 51228], "temperature": 0.0, "avg_logprob": -0.10958604154915645, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0070028542540967464}, {"id": 97, "seek": 53424, "start": 551.52, "end": 557.6, "text": " the largest company in the world. And within a couple of years, those top slots are occupied by", "tokens": [51228, 264, 6443, 2237, 294, 264, 1002, 13, 400, 1951, 257, 1916, 295, 924, 11, 729, 1192, 24266, 366, 19629, 538, 51532], "temperature": 0.0, "avg_logprob": -0.10958604154915645, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0070028542540967464}, {"id": 98, "seek": 53424, "start": 557.6, "end": 563.12, "text": " what we used to call the fangs, Facebook, Apple, Google, and Amazon, or the gaffers,", "tokens": [51532, 437, 321, 1143, 281, 818, 264, 283, 28686, 11, 4384, 11, 6373, 11, 3329, 11, 293, 6795, 11, 420, 264, 290, 2518, 433, 11, 51808], "temperature": 0.0, "avg_logprob": -0.10958604154915645, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.0070028542540967464}, {"id": 99, "seek": 56312, "start": 563.12, "end": 569.12, "text": " pardon me, not the fangs. Netflix snuck in briefly during the hype cycle. And so you started to see", "tokens": [50364, 22440, 385, 11, 406, 264, 283, 28686, 13, 12778, 2406, 1134, 294, 10515, 1830, 264, 24144, 6586, 13, 400, 370, 291, 1409, 281, 536, 50664], "temperature": 0.0, "avg_logprob": -0.10259391493716483, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.001882120268419385}, {"id": 100, "seek": 56312, "start": 569.12, "end": 575.6, "text": " the, the companies of the industrial age, Exxon, GM, and so on, fall off that, fall off that list", "tokens": [50664, 264, 11, 264, 3431, 295, 264, 9987, 3205, 11, 2111, 87, 266, 11, 16609, 11, 293, 370, 322, 11, 2100, 766, 300, 11, 2100, 766, 300, 1329, 50988], "temperature": 0.0, "avg_logprob": -0.10259391493716483, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.001882120268419385}, {"id": 101, "seek": 56312, "start": 575.6, "end": 580.88, "text": " and stay off that list. So that's an important economic moment about the, the sort of forward", "tokens": [50988, 293, 1754, 766, 300, 1329, 13, 407, 300, 311, 364, 1021, 4836, 1623, 466, 264, 11, 264, 1333, 295, 2128, 51252], "temperature": 0.0, "avg_logprob": -0.10259391493716483, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.001882120268419385}, {"id": 102, "seek": 56312, "start": 580.88, "end": 585.36, "text": " looking stock market saying like something is changing. The second thing that starts to happen", "tokens": [51252, 1237, 4127, 2142, 1566, 411, 746, 307, 4473, 13, 440, 1150, 551, 300, 3719, 281, 1051, 51476], "temperature": 0.0, "avg_logprob": -0.10259391493716483, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.001882120268419385}, {"id": 103, "seek": 56312, "start": 585.36, "end": 591.92, "text": " in around 2014 is we see the first market for electric vehicles go past that threshold of 5%", "tokens": [51476, 294, 926, 8227, 307, 321, 536, 264, 700, 2142, 337, 5210, 8948, 352, 1791, 300, 14678, 295, 1025, 4, 51804], "temperature": 0.0, "avg_logprob": -0.10259391493716483, "compression_ratio": 1.657439446366782, "no_speech_prob": 0.001882120268419385}, {"id": 104, "seek": 59192, "start": 591.92, "end": 597.68, "text": " of new cars being sold, being electric, which was over in, in Norway. And that 5% threshold is the", "tokens": [50364, 295, 777, 5163, 885, 3718, 11, 885, 5210, 11, 597, 390, 670, 294, 11, 294, 24354, 13, 400, 300, 1025, 4, 14678, 307, 264, 50652], "temperature": 0.0, "avg_logprob": -0.0923651655515035, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0070600262843072414}, {"id": 105, "seek": 59192, "start": 598.4, "end": 602.9599999999999, "text": " normally the trigger for when you see the S curve of adoption, right? And you get into that, that", "tokens": [50688, 5646, 264, 7875, 337, 562, 291, 536, 264, 318, 7605, 295, 19215, 11, 558, 30, 400, 291, 483, 666, 300, 11, 300, 50916], "temperature": 0.0, "avg_logprob": -0.0923651655515035, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0070600262843072414}, {"id": 106, "seek": 59192, "start": 602.9599999999999, "end": 610.0, "text": " vertical or that verticalized part of the curve. You also started to see solar power being starting", "tokens": [50916, 9429, 420, 300, 9429, 1602, 644, 295, 264, 7605, 13, 509, 611, 1409, 281, 536, 7936, 1347, 885, 2891, 51268], "temperature": 0.0, "avg_logprob": -0.0923651655515035, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0070600262843072414}, {"id": 107, "seek": 59192, "start": 610.0, "end": 615.04, "text": " to be cheaper in a roughly a third to a half of the contracts around the world than fossil fuels.", "tokens": [51268, 281, 312, 12284, 294, 257, 9810, 257, 2636, 281, 257, 1922, 295, 264, 13952, 926, 264, 1002, 813, 18737, 24616, 13, 51520], "temperature": 0.0, "avg_logprob": -0.0923651655515035, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0070600262843072414}, {"id": 108, "seek": 61504, "start": 615.1999999999999, "end": 623.36, "text": " And, and then of course we are three or four years into the deep learning wave. And, and that's long", "tokens": [50372, 400, 11, 293, 550, 295, 1164, 321, 366, 1045, 420, 1451, 924, 666, 264, 2452, 2539, 5772, 13, 400, 11, 293, 300, 311, 938, 50780], "temperature": 0.0, "avg_logprob": -0.13261380146459206, "compression_ratio": 1.611336032388664, "no_speech_prob": 0.022192761301994324}, {"id": 109, "seek": 61504, "start": 623.36, "end": 630.0, "text": " enough for companies to start to ship products. So I think that there is a moment which we could", "tokens": [50780, 1547, 337, 3431, 281, 722, 281, 5374, 3383, 13, 407, 286, 519, 300, 456, 307, 257, 1623, 597, 321, 727, 51112], "temperature": 0.0, "avg_logprob": -0.13261380146459206, "compression_ratio": 1.611336032388664, "no_speech_prob": 0.022192761301994324}, {"id": 110, "seek": 61504, "start": 630.0, "end": 635.4399999999999, "text": " argue when we look back on it feels like a, a sort of historical turning point, but we also have to", "tokens": [51112, 9695, 562, 321, 574, 646, 322, 309, 3417, 411, 257, 11, 257, 1333, 295, 8584, 6246, 935, 11, 457, 321, 611, 362, 281, 51384], "temperature": 0.0, "avg_logprob": -0.13261380146459206, "compression_ratio": 1.611336032388664, "no_speech_prob": 0.022192761301994324}, {"id": 111, "seek": 61504, "start": 635.4399999999999, "end": 641.28, "text": " be realistic that the, the mathematical function that is an exponential curve, when you stand on it,", "tokens": [51384, 312, 12465, 300, 264, 11, 264, 18894, 2445, 300, 307, 364, 21510, 7605, 11, 562, 291, 1463, 322, 309, 11, 51676], "temperature": 0.0, "avg_logprob": -0.13261380146459206, "compression_ratio": 1.611336032388664, "no_speech_prob": 0.022192761301994324}, {"id": 112, "seek": 64128, "start": 641.28, "end": 645.1999999999999, "text": " it always looks horizontal behind you and it always looks vertical above in front of you,", "tokens": [50364, 309, 1009, 1542, 12750, 2261, 291, 293, 309, 1009, 1542, 9429, 3673, 294, 1868, 295, 291, 11, 50560], "temperature": 0.0, "avg_logprob": -0.1147253601639359, "compression_ratio": 1.597972972972973, "no_speech_prob": 0.011162258684635162}, {"id": 113, "seek": 64128, "start": 645.1999999999999, "end": 649.76, "text": " wherever you stand on it. It's a smooth curve with no obvious turning point. And, and someone like", "tokens": [50560, 8660, 291, 1463, 322, 309, 13, 467, 311, 257, 5508, 7605, 365, 572, 6322, 6246, 935, 13, 400, 11, 293, 1580, 411, 50788], "temperature": 0.0, "avg_logprob": -0.1147253601639359, "compression_ratio": 1.597972972972973, "no_speech_prob": 0.011162258684635162}, {"id": 114, "seek": 64128, "start": 649.76, "end": 656.0799999999999, "text": " Kurt's file, you know, I think did such great work 20 years ago to articulate the exponential", "tokens": [50788, 26168, 311, 3991, 11, 291, 458, 11, 286, 519, 630, 1270, 869, 589, 945, 924, 2057, 281, 30305, 264, 21510, 51104], "temperature": 0.0, "avg_logprob": -0.1147253601639359, "compression_ratio": 1.597972972972973, "no_speech_prob": 0.011162258684635162}, {"id": 115, "seek": 64128, "start": 656.0799999999999, "end": 661.36, "text": " trend in computing going back from the 1880s actually in mechanical computers. I think one of", "tokens": [51104, 6028, 294, 15866, 516, 646, 490, 264, 2443, 4702, 82, 767, 294, 12070, 10807, 13, 286, 519, 472, 295, 51368], "temperature": 0.0, "avg_logprob": -0.1147253601639359, "compression_ratio": 1.597972972972973, "no_speech_prob": 0.011162258684635162}, {"id": 116, "seek": 64128, "start": 661.36, "end": 671.1999999999999, "text": " the reasons why he slightly falls out of favor is because he was probably brave enough to extend", "tokens": [51368, 264, 4112, 983, 415, 4748, 8804, 484, 295, 2294, 307, 570, 415, 390, 1391, 12653, 1547, 281, 10101, 51860], "temperature": 0.0, "avg_logprob": -0.1147253601639359, "compression_ratio": 1.597972972972973, "no_speech_prob": 0.011162258684635162}, {"id": 117, "seek": 67120, "start": 671.2800000000001, "end": 677.2, "text": " the curve far further than we might have otherwise thought. And I think a couple of things that he", "tokens": [50368, 264, 7605, 1400, 3052, 813, 321, 1062, 362, 5911, 1194, 13, 400, 286, 519, 257, 1916, 295, 721, 300, 415, 50664], "temperature": 0.0, "avg_logprob": -0.0809793472290039, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0031725959852337837}, {"id": 118, "seek": 67120, "start": 677.2, "end": 681.9200000000001, "text": " got wrong was that some of the assumptions that we would have had about how the human brain works", "tokens": [50664, 658, 2085, 390, 300, 512, 295, 264, 17695, 300, 321, 576, 362, 632, 466, 577, 264, 1952, 3567, 1985, 50900], "temperature": 0.0, "avg_logprob": -0.0809793472290039, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0031725959852337837}, {"id": 119, "seek": 67120, "start": 681.9200000000001, "end": 688.08, "text": " in like 2001, 2002 when those books came out were, were wrong, right? Science proved that it was more", "tokens": [50900, 294, 411, 16382, 11, 17822, 562, 729, 3642, 1361, 484, 645, 11, 645, 2085, 11, 558, 30, 8976, 14617, 300, 309, 390, 544, 51208], "temperature": 0.0, "avg_logprob": -0.0809793472290039, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0031725959852337837}, {"id": 120, "seek": 67120, "start": 688.08, "end": 694.5600000000001, "text": " complex and it wasn't going to be a simple game of, of raw computation one for one. And, and that's", "tokens": [51208, 3997, 293, 309, 2067, 380, 516, 281, 312, 257, 2199, 1216, 295, 11, 295, 8936, 24903, 472, 337, 472, 13, 400, 11, 293, 300, 311, 51532], "temperature": 0.0, "avg_logprob": -0.0809793472290039, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0031725959852337837}, {"id": 121, "seek": 67120, "start": 694.5600000000001, "end": 698.48, "text": " where I think that, that people start to look at him and say, well, was this just someone throwing", "tokens": [51532, 689, 286, 519, 300, 11, 300, 561, 722, 281, 574, 412, 796, 293, 584, 11, 731, 11, 390, 341, 445, 1580, 10238, 51728], "temperature": 0.0, "avg_logprob": -0.0809793472290039, "compression_ratio": 1.7317073170731707, "no_speech_prob": 0.0031725959852337837}, {"id": 122, "seek": 69848, "start": 698.48, "end": 702.32, "text": " tea leaves? I think there was much more to it than, than that having read his work, you know,", "tokens": [50364, 5817, 5510, 30, 286, 519, 456, 390, 709, 544, 281, 309, 813, 11, 813, 300, 1419, 1401, 702, 589, 11, 291, 458, 11, 50556], "temperature": 0.0, "avg_logprob": -0.06688932879217739, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.005548343062400818}, {"id": 123, "seek": 69848, "start": 702.32, "end": 707.84, "text": " reasonably carefully. But, but I think what's interesting is that we see these curves happening", "tokens": [50556, 23551, 7500, 13, 583, 11, 457, 286, 519, 437, 311, 1880, 307, 300, 321, 536, 613, 19490, 2737, 50832], "temperature": 0.0, "avg_logprob": -0.06688932879217739, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.005548343062400818}, {"id": 124, "seek": 69848, "start": 707.84, "end": 711.28, "text": " elsewhere, right? We see them in lithium ion batteries and we see them in genome sequencing", "tokens": [50832, 14517, 11, 558, 30, 492, 536, 552, 294, 32180, 17437, 13070, 293, 321, 536, 552, 294, 21953, 32693, 51004], "temperature": 0.0, "avg_logprob": -0.06688932879217739, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.005548343062400818}, {"id": 125, "seek": 69848, "start": 711.28, "end": 716.8000000000001, "text": " and it's not clear why that should be the case up front. The implications of the fact that we may", "tokens": [51004, 293, 309, 311, 406, 1850, 983, 300, 820, 312, 264, 1389, 493, 1868, 13, 440, 16602, 295, 264, 1186, 300, 321, 815, 51280], "temperature": 0.0, "avg_logprob": -0.06688932879217739, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.005548343062400818}, {"id": 126, "seek": 69848, "start": 716.8000000000001, "end": 721.44, "text": " still be, you know, standing on the part of the curve that as it, you know, as you said, it kind", "tokens": [51280, 920, 312, 11, 291, 458, 11, 4877, 322, 264, 644, 295, 264, 7605, 300, 382, 309, 11, 291, 458, 11, 382, 291, 848, 11, 309, 733, 51512], "temperature": 0.0, "avg_logprob": -0.06688932879217739, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.005548343062400818}, {"id": 127, "seek": 69848, "start": 721.44, "end": 725.6800000000001, "text": " of always does. If we're, if it's still the case that what's in front of us is vertical compared", "tokens": [51512, 295, 1009, 775, 13, 759, 321, 434, 11, 498, 309, 311, 920, 264, 1389, 300, 437, 311, 294, 1868, 295, 505, 307, 9429, 5347, 51724], "temperature": 0.0, "avg_logprob": -0.06688932879217739, "compression_ratio": 1.7962382445141065, "no_speech_prob": 0.005548343062400818}, {"id": 128, "seek": 72568, "start": 725.68, "end": 729.8399999999999, "text": " to what, you know, has been behind us being horizontal, then we're in for a bit of a wild", "tokens": [50364, 281, 437, 11, 291, 458, 11, 575, 668, 2261, 505, 885, 12750, 11, 550, 321, 434, 294, 337, 257, 857, 295, 257, 4868, 50572], "temperature": 0.0, "avg_logprob": -0.08150223011278925, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.001699096872471273}, {"id": 129, "seek": 72568, "start": 729.8399999999999, "end": 734.64, "text": " ride. I think we're headed for steep, a steep curve for at least a couple more years. I mean,", "tokens": [50572, 5077, 13, 286, 519, 321, 434, 12798, 337, 16841, 11, 257, 16841, 7605, 337, 412, 1935, 257, 1916, 544, 924, 13, 286, 914, 11, 50812], "temperature": 0.0, "avg_logprob": -0.08150223011278925, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.001699096872471273}, {"id": 130, "seek": 72568, "start": 735.1999999999999, "end": 742.2399999999999, "text": " beyond that, you know, do we sort of hit a plateau is a lot harder for me to predict. But I honestly", "tokens": [50840, 4399, 300, 11, 291, 458, 11, 360, 321, 1333, 295, 2045, 257, 39885, 307, 257, 688, 6081, 337, 385, 281, 6069, 13, 583, 286, 6095, 51192], "temperature": 0.0, "avg_logprob": -0.08150223011278925, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.001699096872471273}, {"id": 131, "seek": 72568, "start": 742.2399999999999, "end": 747.1999999999999, "text": " don't see any fundamental reasons that we would right now. I mean, what, what Kurzweil says is", "tokens": [51192, 500, 380, 536, 604, 8088, 4112, 300, 321, 576, 558, 586, 13, 286, 914, 11, 437, 11, 437, 45307, 826, 388, 1619, 307, 51440], "temperature": 0.0, "avg_logprob": -0.08150223011278925, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.001699096872471273}, {"id": 132, "seek": 72568, "start": 747.1999999999999, "end": 752.7199999999999, "text": " that, you know, it's actually this curve is a series of layered S's. So you, you have one", "tokens": [51440, 300, 11, 291, 458, 11, 309, 311, 767, 341, 7605, 307, 257, 2638, 295, 34666, 318, 311, 13, 407, 291, 11, 291, 362, 472, 51716], "temperature": 0.0, "avg_logprob": -0.08150223011278925, "compression_ratio": 1.7054545454545456, "no_speech_prob": 0.001699096872471273}, {"id": 133, "seek": 75272, "start": 752.72, "end": 759.0400000000001, "text": " particular technology architecture, it's very slow to develop, it hits this inflection as an S,", "tokens": [50364, 1729, 2899, 9482, 11, 309, 311, 588, 2964, 281, 1499, 11, 309, 8664, 341, 1536, 5450, 382, 364, 318, 11, 50680], "temperature": 0.0, "avg_logprob": -0.11561121004764165, "compression_ratio": 1.6870503597122302, "no_speech_prob": 0.01666230708360672}, {"id": 134, "seek": 75272, "start": 759.0400000000001, "end": 764.96, "text": " it starts to accelerate. And as it hits its flat point, the social dynamics of market incentives", "tokens": [50680, 309, 3719, 281, 21341, 13, 400, 382, 309, 8664, 1080, 4962, 935, 11, 264, 2093, 15679, 295, 2142, 23374, 50976], "temperature": 0.0, "avg_logprob": -0.11561121004764165, "compression_ratio": 1.6870503597122302, "no_speech_prob": 0.01666230708360672}, {"id": 135, "seek": 75272, "start": 764.96, "end": 770.0, "text": " have meant that another set of research has come in with a different architecture, a different way", "tokens": [50976, 362, 4140, 300, 1071, 992, 295, 2132, 575, 808, 294, 365, 257, 819, 9482, 11, 257, 819, 636, 51228], "temperature": 0.0, "avg_logprob": -0.11561121004764165, "compression_ratio": 1.6870503597122302, "no_speech_prob": 0.01666230708360672}, {"id": 136, "seek": 75272, "start": 770.0, "end": 776.64, "text": " that extends that that S up and looks from a distance like a smooth S curve. And that's", "tokens": [51228, 300, 26448, 300, 300, 318, 493, 293, 1542, 490, 257, 4560, 411, 257, 5508, 318, 7605, 13, 400, 300, 311, 51560], "temperature": 0.0, "avg_logprob": -0.11561121004764165, "compression_ratio": 1.6870503597122302, "no_speech_prob": 0.01666230708360672}, {"id": 137, "seek": 75272, "start": 776.64, "end": 780.72, "text": " really nice and descriptive. But it also, I suspect people are kind of really robust with", "tokens": [51560, 534, 1481, 293, 42585, 13, 583, 309, 611, 11, 286, 9091, 561, 366, 733, 295, 534, 13956, 365, 51764], "temperature": 0.0, "avg_logprob": -0.11561121004764165, "compression_ratio": 1.6870503597122302, "no_speech_prob": 0.01666230708360672}, {"id": 138, "seek": 78072, "start": 780.8000000000001, "end": 784.8000000000001, "text": " their theory feels like, well, that's just praying. That's like the Turkey that's been", "tokens": [50368, 641, 5261, 3417, 411, 11, 731, 11, 300, 311, 445, 15611, 13, 663, 311, 411, 264, 12647, 300, 311, 668, 50568], "temperature": 0.0, "avg_logprob": -0.07554846479181658, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0041817184537649155}, {"id": 139, "seek": 78072, "start": 784.8000000000001, "end": 789.0400000000001, "text": " treated really well up to the day before Thanksgiving. And like, we should worry about", "tokens": [50568, 8668, 534, 731, 493, 281, 264, 786, 949, 21230, 13, 400, 411, 11, 321, 820, 3292, 466, 50780], "temperature": 0.0, "avg_logprob": -0.07554846479181658, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0041817184537649155}, {"id": 140, "seek": 78072, "start": 789.0400000000001, "end": 793.9200000000001, "text": " what happens the next day. What I've tried to do is I've tried to get into the underlying mechanisms", "tokens": [50780, 437, 2314, 264, 958, 786, 13, 708, 286, 600, 3031, 281, 360, 307, 286, 600, 3031, 281, 483, 666, 264, 14217, 15902, 51024], "temperature": 0.0, "avg_logprob": -0.07554846479181658, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0041817184537649155}, {"id": 141, "seek": 78072, "start": 793.9200000000001, "end": 799.52, "text": " of why these things improve, why they get cheaper. And then what we need to do is figure out where", "tokens": [51024, 295, 983, 613, 721, 3470, 11, 983, 436, 483, 12284, 13, 400, 550, 437, 321, 643, 281, 360, 307, 2573, 484, 689, 51304], "temperature": 0.0, "avg_logprob": -0.07554846479181658, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0041817184537649155}, {"id": 142, "seek": 78072, "start": 799.52, "end": 805.9200000000001, "text": " does that mechanism fail? Because if the mechanism doesn't fail, then that trend is going to continue.", "tokens": [51304, 775, 300, 7513, 3061, 30, 1436, 498, 264, 7513, 1177, 380, 3061, 11, 550, 300, 6028, 307, 516, 281, 2354, 13, 51624], "temperature": 0.0, "avg_logprob": -0.07554846479181658, "compression_ratio": 1.762962962962963, "no_speech_prob": 0.0041817184537649155}, {"id": 143, "seek": 80592, "start": 805.92, "end": 810.0799999999999, "text": " And if it does fail, then we can say, well, we need a new mechanism and is there one,", "tokens": [50364, 400, 498, 309, 775, 3061, 11, 550, 321, 393, 584, 11, 731, 11, 321, 643, 257, 777, 7513, 293, 307, 456, 472, 11, 50572], "temperature": 0.0, "avg_logprob": -0.08642385137362743, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.04510986804962158}, {"id": 144, "seek": 80592, "start": 810.64, "end": 816.0, "text": " you know, in the research pipeline that might deliver it. So, I would say that if you look", "tokens": [50600, 291, 458, 11, 294, 264, 2132, 15517, 300, 1062, 4239, 309, 13, 407, 11, 286, 576, 584, 300, 498, 291, 574, 50868], "temperature": 0.0, "avg_logprob": -0.08642385137362743, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.04510986804962158}, {"id": 145, "seek": 80592, "start": 816.0, "end": 823.1999999999999, "text": " across the gamut, I mean, for example, batteries and solar power, we've definitely got more than a", "tokens": [50868, 2108, 264, 8019, 325, 11, 286, 914, 11, 337, 1365, 11, 13070, 293, 7936, 1347, 11, 321, 600, 2138, 658, 544, 813, 257, 51228], "temperature": 0.0, "avg_logprob": -0.08642385137362743, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.04510986804962158}, {"id": 146, "seek": 80592, "start": 823.1999999999999, "end": 829.76, "text": " couple of years to run in terms of price declines. When we look at compute, I just feel it's really", "tokens": [51228, 1916, 295, 924, 281, 1190, 294, 2115, 295, 3218, 7488, 1652, 13, 1133, 321, 574, 412, 14722, 11, 286, 445, 841, 309, 311, 534, 51556], "temperature": 0.0, "avg_logprob": -0.08642385137362743, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.04510986804962158}, {"id": 147, "seek": 80592, "start": 829.76, "end": 834.16, "text": " hard to bet against. I just, you know, I think that I've been hearing about the death of Moore's", "tokens": [51556, 1152, 281, 778, 1970, 13, 286, 445, 11, 291, 458, 11, 286, 519, 300, 286, 600, 668, 4763, 466, 264, 2966, 295, 21644, 311, 51776], "temperature": 0.0, "avg_logprob": -0.08642385137362743, "compression_ratio": 1.6275862068965516, "no_speech_prob": 0.04510986804962158}, {"id": 148, "seek": 83416, "start": 834.16, "end": 841.68, "text": " Law for 15 years. And, you know, Moore's Law is helpful. But the question to ask is how much", "tokens": [50364, 7744, 337, 2119, 924, 13, 400, 11, 291, 458, 11, 21644, 311, 7744, 307, 4961, 13, 583, 264, 1168, 281, 1029, 307, 577, 709, 50740], "temperature": 0.0, "avg_logprob": -0.09455514228206942, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.0034717656672000885}, {"id": 149, "seek": 83416, "start": 841.68, "end": 849.12, "text": " compute can a developer get for a dollar each year? And do we really think that that is going to stop", "tokens": [50740, 14722, 393, 257, 10754, 483, 337, 257, 7241, 1184, 1064, 30, 400, 360, 321, 534, 519, 300, 300, 307, 516, 281, 1590, 51112], "temperature": 0.0, "avg_logprob": -0.09455514228206942, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.0034717656672000885}, {"id": 150, "seek": 83416, "start": 849.8399999999999, "end": 853.52, "text": " declining for like a long period of time? And I find that one really hard to", "tokens": [51148, 34298, 337, 411, 257, 938, 2896, 295, 565, 30, 400, 286, 915, 300, 472, 534, 1152, 281, 51332], "temperature": 0.0, "avg_logprob": -0.09455514228206942, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.0034717656672000885}, {"id": 151, "seek": 83416, "start": 854.56, "end": 857.8399999999999, "text": " support. And I just think it continues for a variety of reasons.", "tokens": [51384, 1406, 13, 400, 286, 445, 519, 309, 6515, 337, 257, 5673, 295, 4112, 13, 51548], "temperature": 0.0, "avg_logprob": -0.09455514228206942, "compression_ratio": 1.5412844036697249, "no_speech_prob": 0.0034717656672000885}, {"id": 152, "seek": 85784, "start": 857.84, "end": 864.1600000000001, "text": " It sure seems like it. I mean, the CPU to GPU transition feels like a classic example of one", "tokens": [50364, 467, 988, 2544, 411, 309, 13, 286, 914, 11, 264, 13199, 281, 18407, 6034, 3417, 411, 257, 7230, 1365, 295, 472, 50680], "temperature": 0.0, "avg_logprob": -0.11224919396477777, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.011330519802868366}, {"id": 153, "seek": 85784, "start": 864.1600000000001, "end": 871.12, "text": " of those kind of one S-curve, perhaps giving way to another. And in the GPU, you know, we're not,", "tokens": [50680, 295, 729, 733, 295, 472, 318, 12, 14112, 303, 11, 4317, 2902, 636, 281, 1071, 13, 400, 294, 264, 18407, 11, 291, 458, 11, 321, 434, 406, 11, 51028], "temperature": 0.0, "avg_logprob": -0.11224919396477777, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.011330519802868366}, {"id": 154, "seek": 85784, "start": 871.12, "end": 874.88, "text": " it definitely feels like we're still in the steep part of that particular S-curve.", "tokens": [51028, 309, 2138, 3417, 411, 321, 434, 920, 294, 264, 16841, 644, 295, 300, 1729, 318, 12, 14112, 303, 13, 51216], "temperature": 0.0, "avg_logprob": -0.11224919396477777, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.011330519802868366}, {"id": 155, "seek": 85784, "start": 874.88, "end": 878.24, "text": " Hey, we'll continue our interview in a moment after a word from our sponsors.", "tokens": [51216, 1911, 11, 321, 603, 2354, 527, 4049, 294, 257, 1623, 934, 257, 1349, 490, 527, 22593, 13, 51384], "temperature": 0.0, "avg_logprob": -0.11224919396477777, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.011330519802868366}, {"id": 156, "seek": 85784, "start": 879.12, "end": 883.2, "text": " The Brave Search API brings affordable developer access to the Brave Search Index,", "tokens": [51428, 440, 38545, 17180, 9362, 5607, 12028, 10754, 2105, 281, 264, 38545, 17180, 33552, 11, 51632], "temperature": 0.0, "avg_logprob": -0.11224919396477777, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.011330519802868366}, {"id": 157, "seek": 88320, "start": 883.2800000000001, "end": 886.32, "text": " an independent index of the web with over 20 billion web pages.", "tokens": [50368, 364, 6695, 8186, 295, 264, 3670, 365, 670, 945, 5218, 3670, 7183, 13, 50520], "temperature": 0.0, "avg_logprob": -0.07828145760756272, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.06559428572654724}, {"id": 158, "seek": 88320, "start": 886.96, "end": 892.4000000000001, "text": " So what makes the Brave Search Index stand out? One, it's entirely independent and built from", "tokens": [50552, 407, 437, 1669, 264, 38545, 17180, 33552, 1463, 484, 30, 1485, 11, 309, 311, 7696, 6695, 293, 3094, 490, 50824], "temperature": 0.0, "avg_logprob": -0.07828145760756272, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.06559428572654724}, {"id": 159, "seek": 88320, "start": 892.4000000000001, "end": 899.0400000000001, "text": " scratch. That means no big tech biases or extortionate prices. Two, it's built on real page", "tokens": [50824, 8459, 13, 663, 1355, 572, 955, 7553, 32152, 420, 1279, 8136, 473, 7901, 13, 4453, 11, 309, 311, 3094, 322, 957, 3028, 51156], "temperature": 0.0, "avg_logprob": -0.07828145760756272, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.06559428572654724}, {"id": 160, "seek": 88320, "start": 899.0400000000001, "end": 904.5600000000001, "text": " visits from actual humans, collected anonymously of course, which filters out tons of junk data.", "tokens": [51156, 17753, 490, 3539, 6255, 11, 11087, 37293, 5098, 295, 1164, 11, 597, 15995, 484, 9131, 295, 19109, 1412, 13, 51432], "temperature": 0.0, "avg_logprob": -0.07828145760756272, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.06559428572654724}, {"id": 161, "seek": 88320, "start": 905.2800000000001, "end": 910.0, "text": " And three, the index is refreshed with tens of millions of pages daily. So it always has", "tokens": [51468, 400, 1045, 11, 264, 8186, 307, 46330, 365, 10688, 295, 6803, 295, 7183, 5212, 13, 407, 309, 1009, 575, 51704], "temperature": 0.0, "avg_logprob": -0.07828145760756272, "compression_ratio": 1.599264705882353, "no_speech_prob": 0.06559428572654724}, {"id": 162, "seek": 91000, "start": 910.0, "end": 915.92, "text": " accurate up to date information. The Brave Search API can be used to assemble a data set to train", "tokens": [50364, 8559, 493, 281, 4002, 1589, 13, 440, 38545, 17180, 9362, 393, 312, 1143, 281, 22364, 257, 1412, 992, 281, 3847, 50660], "temperature": 0.0, "avg_logprob": -0.0837896160963105, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.009124845266342163}, {"id": 163, "seek": 91000, "start": 915.92, "end": 921.28, "text": " your AI models and help with retrieval augmentation at the time of inference, all while remaining", "tokens": [50660, 428, 7318, 5245, 293, 854, 365, 19817, 3337, 14501, 19631, 412, 264, 565, 295, 38253, 11, 439, 1339, 8877, 50928], "temperature": 0.0, "avg_logprob": -0.0837896160963105, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.009124845266342163}, {"id": 164, "seek": 91000, "start": 921.28, "end": 927.36, "text": " affordable with developer first pricing. Integrating the Brave Search API into your workflow translates", "tokens": [50928, 12028, 365, 10754, 700, 17621, 13, 23894, 990, 264, 38545, 17180, 9362, 666, 428, 20993, 28468, 51232], "temperature": 0.0, "avg_logprob": -0.0837896160963105, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.009124845266342163}, {"id": 165, "seek": 91000, "start": 927.36, "end": 932.56, "text": " to more ethical data sourcing and more human representative data sets. Try the Brave Search", "tokens": [51232, 281, 544, 18890, 1412, 11006, 2175, 293, 544, 1952, 12424, 1412, 6352, 13, 6526, 264, 38545, 17180, 51492], "temperature": 0.0, "avg_logprob": -0.0837896160963105, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.009124845266342163}, {"id": 166, "seek": 93256, "start": 932.56, "end": 937.76, "text": " API for free for up to 2,000 queries per month at brave.com slash api.", "tokens": [50364, 9362, 337, 1737, 337, 493, 281, 568, 11, 1360, 24109, 680, 1618, 412, 12653, 13, 1112, 17330, 1882, 72, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1757324987383031, "compression_ratio": 1.4342857142857144, "no_speech_prob": 0.0835409089922905}, {"id": 167, "seek": 93256, "start": 943.52, "end": 949.3599999999999, "text": " We're not done yet. And I think the thing that is fascinating is that NVIDIA is obviously doing", "tokens": [50912, 492, 434, 406, 1096, 1939, 13, 400, 286, 519, 264, 551, 300, 307, 10343, 307, 300, 426, 3958, 6914, 307, 2745, 884, 51204], "temperature": 0.0, "avg_logprob": -0.1757324987383031, "compression_ratio": 1.4342857142857144, "no_speech_prob": 0.0835409089922905}, {"id": 168, "seek": 93256, "start": 950.16, "end": 957.76, "text": " incredibly, incredibly well. And it doesn't yet have the threat of real competition.", "tokens": [51244, 6252, 11, 6252, 731, 13, 400, 309, 1177, 380, 1939, 362, 264, 4734, 295, 957, 6211, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1757324987383031, "compression_ratio": 1.4342857142857144, "no_speech_prob": 0.0835409089922905}, {"id": 169, "seek": 95776, "start": 958.0, "end": 962.56, "text": " And what was fascinating in the CPU world was that Intel did very, very well for a really long", "tokens": [50376, 400, 437, 390, 10343, 294, 264, 13199, 1002, 390, 300, 19762, 630, 588, 11, 588, 731, 337, 257, 534, 938, 50604], "temperature": 0.0, "avg_logprob": -0.10104437486841045, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.008091769181191921}, {"id": 170, "seek": 95776, "start": 962.56, "end": 966.56, "text": " time. I guess people forget this, but if you've been around for a while, you remember Intel was", "tokens": [50604, 565, 13, 286, 2041, 561, 2870, 341, 11, 457, 498, 291, 600, 668, 926, 337, 257, 1339, 11, 291, 1604, 19762, 390, 50804], "temperature": 0.0, "avg_logprob": -0.10104437486841045, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.008091769181191921}, {"id": 171, "seek": 95776, "start": 966.56, "end": 971.36, "text": " this sort of monopolist and perceived an Andy Grove and only the paranoid survive.", "tokens": [50804, 341, 1333, 295, 47721, 468, 293, 19049, 364, 13285, 43111, 293, 787, 264, 43948, 7867, 13, 51044], "temperature": 0.0, "avg_logprob": -0.10104437486841045, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.008091769181191921}, {"id": 172, "seek": 95776, "start": 972.0, "end": 976.64, "text": " And it did really well only with the threat of competition, because AMD never got more than", "tokens": [51076, 400, 309, 630, 534, 731, 787, 365, 264, 4734, 295, 6211, 11, 570, 34808, 1128, 658, 544, 813, 51308], "temperature": 0.0, "avg_logprob": -0.10104437486841045, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.008091769181191921}, {"id": 173, "seek": 95776, "start": 976.64, "end": 983.4399999999999, "text": " 15, 20 percent market share. And that's enough to propel people forward. All the incentives seem", "tokens": [51308, 2119, 11, 945, 3043, 2142, 2073, 13, 400, 300, 311, 1547, 281, 2365, 338, 561, 2128, 13, 1057, 264, 23374, 1643, 51648], "temperature": 0.0, "avg_logprob": -0.10104437486841045, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.008091769181191921}, {"id": 174, "seek": 98344, "start": 983.44, "end": 990.8800000000001, "text": " lined up for there to be massive amounts of investment in scaling existing silicon chips", "tokens": [50364, 17189, 493, 337, 456, 281, 312, 5994, 11663, 295, 6078, 294, 21589, 6741, 22848, 11583, 50736], "temperature": 0.0, "avg_logprob": -0.09639608512804346, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.03520183637738228}, {"id": 175, "seek": 98344, "start": 990.8800000000001, "end": 995.84, "text": " and developing new systems. I mean, you saw in the last few days before we recorded this,", "tokens": [50736, 293, 6416, 777, 3652, 13, 286, 914, 11, 291, 1866, 294, 264, 1036, 1326, 1708, 949, 321, 8287, 341, 11, 50984], "temperature": 0.0, "avg_logprob": -0.09639608512804346, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.03520183637738228}, {"id": 176, "seek": 98344, "start": 995.84, "end": 1001.44, "text": " Amazon and Google both reported 20, 30 percent growth in their cloud businesses. When I've talked", "tokens": [50984, 6795, 293, 3329, 1293, 7055, 945, 11, 2217, 3043, 4599, 294, 641, 4588, 6011, 13, 1133, 286, 600, 2825, 51264], "temperature": 0.0, "avg_logprob": -0.09639608512804346, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.03520183637738228}, {"id": 177, "seek": 98344, "start": 1001.44, "end": 1008.1600000000001, "text": " to bosses of really big companies, you know, they are spending money on compute, you know,", "tokens": [51264, 281, 24201, 295, 534, 955, 3431, 11, 291, 458, 11, 436, 366, 6434, 1460, 322, 14722, 11, 291, 458, 11, 51600], "temperature": 0.0, "avg_logprob": -0.09639608512804346, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.03520183637738228}, {"id": 178, "seek": 98344, "start": 1008.1600000000001, "end": 1012.48, "text": " really like nobody's business and their expectation is that it will grow. They don't", "tokens": [51600, 534, 411, 5079, 311, 1606, 293, 641, 14334, 307, 300, 309, 486, 1852, 13, 814, 500, 380, 51816], "temperature": 0.0, "avg_logprob": -0.09639608512804346, "compression_ratio": 1.5804195804195804, "no_speech_prob": 0.03520183637738228}, {"id": 179, "seek": 101248, "start": 1012.48, "end": 1016.32, "text": " often think it's compute. They say they're spending on AI, but that the end of it is going to be", "tokens": [50364, 2049, 519, 309, 311, 14722, 13, 814, 584, 436, 434, 6434, 322, 7318, 11, 457, 300, 264, 917, 295, 309, 307, 516, 281, 312, 50556], "temperature": 0.0, "avg_logprob": -0.10312873125076294, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.005010112654417753}, {"id": 180, "seek": 101248, "start": 1016.32, "end": 1024.08, "text": " GPUs cranking away. So with all the incentives aligned, I struggle to see us hitting a brick wall.", "tokens": [50556, 18407, 82, 21263, 278, 1314, 13, 407, 365, 439, 264, 23374, 17962, 11, 286, 7799, 281, 536, 505, 8850, 257, 16725, 2929, 13, 50944], "temperature": 0.0, "avg_logprob": -0.10312873125076294, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.005010112654417753}, {"id": 181, "seek": 101248, "start": 1024.08, "end": 1029.04, "text": " It doesn't feel like it's the Carno cycle, right? So the Carno cycle was the thermodynamic limit for", "tokens": [50944, 467, 1177, 380, 841, 411, 309, 311, 264, 32254, 78, 6586, 11, 558, 30, 407, 264, 32254, 78, 6586, 390, 264, 8810, 34988, 4948, 337, 51192], "temperature": 0.0, "avg_logprob": -0.10312873125076294, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.005010112654417753}, {"id": 182, "seek": 101248, "start": 1029.04, "end": 1034.8, "text": " the efficiency of an Intel combustion engine, something you as a native Detroit man, you know,", "tokens": [51192, 264, 10493, 295, 364, 19762, 28121, 2848, 11, 746, 291, 382, 257, 8470, 20887, 587, 11, 291, 458, 11, 51480], "temperature": 0.0, "avg_logprob": -0.10312873125076294, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.005010112654417753}, {"id": 183, "seek": 101248, "start": 1034.8, "end": 1041.28, "text": " know, know very, very well, but we keep finding ways of eking more out of our compute. And I think", "tokens": [51480, 458, 11, 458, 588, 11, 588, 731, 11, 457, 321, 1066, 5006, 2098, 295, 308, 5092, 544, 484, 295, 527, 14722, 13, 400, 286, 519, 51804], "temperature": 0.0, "avg_logprob": -0.10312873125076294, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.005010112654417753}, {"id": 184, "seek": 104128, "start": 1041.36, "end": 1044.3999999999999, "text": " we'll, you know, we'll continue to do that certainly beyond a couple of years.", "tokens": [50368, 321, 603, 11, 291, 458, 11, 321, 603, 2354, 281, 360, 300, 3297, 4399, 257, 1916, 295, 924, 13, 50520], "temperature": 0.0, "avg_logprob": -0.08571649711822794, "compression_ratio": 1.6867924528301887, "no_speech_prob": 0.0018656000029295683}, {"id": 185, "seek": 104128, "start": 1045.2, "end": 1049.6, "text": " Just for kind of conceptual grounding, and I'm also interested to hear how you explain this to", "tokens": [50560, 1449, 337, 733, 295, 24106, 46727, 11, 293, 286, 478, 611, 3102, 281, 1568, 577, 291, 2903, 341, 281, 50780], "temperature": 0.0, "avg_logprob": -0.08571649711822794, "compression_ratio": 1.6867924528301887, "no_speech_prob": 0.0018656000029295683}, {"id": 186, "seek": 104128, "start": 1049.6, "end": 1055.92, "text": " the business leaders that you work with, because their understanding and their kind of eagerness", "tokens": [50780, 264, 1606, 3523, 300, 291, 589, 365, 11, 570, 641, 3701, 293, 641, 733, 295, 308, 559, 19416, 51096], "temperature": 0.0, "avg_logprob": -0.08571649711822794, "compression_ratio": 1.6867924528301887, "no_speech_prob": 0.0018656000029295683}, {"id": 187, "seek": 104128, "start": 1055.92, "end": 1061.52, "text": " to adopt is a pretty key question in my mind as to how the next few years are going to play out.", "tokens": [51096, 281, 6878, 307, 257, 1238, 2141, 1168, 294, 452, 1575, 382, 281, 577, 264, 958, 1326, 924, 366, 516, 281, 862, 484, 13, 51376], "temperature": 0.0, "avg_logprob": -0.08571649711822794, "compression_ratio": 1.6867924528301887, "no_speech_prob": 0.0018656000029295683}, {"id": 188, "seek": 104128, "start": 1062.16, "end": 1067.92, "text": " But we have kind of two notions, two definitions of kind of types of technology", "tokens": [51408, 583, 321, 362, 733, 295, 732, 35799, 11, 732, 21988, 295, 733, 295, 3467, 295, 2899, 51696], "temperature": 0.0, "avg_logprob": -0.08571649711822794, "compression_ratio": 1.6867924528301887, "no_speech_prob": 0.0018656000029295683}, {"id": 189, "seek": 106792, "start": 1067.92, "end": 1072.16, "text": " that both seem to apply to AI in my mind. One is the exponential technology,", "tokens": [50364, 300, 1293, 1643, 281, 3079, 281, 7318, 294, 452, 1575, 13, 1485, 307, 264, 21510, 2899, 11, 50576], "temperature": 0.0, "avg_logprob": -0.08120661919270086, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.0013249412877485156}, {"id": 190, "seek": 106792, "start": 1072.8000000000002, "end": 1078.0800000000002, "text": " and the other is the concept of disruptive technology. Disruptive technology, you know,", "tokens": [50608, 293, 264, 661, 307, 264, 3410, 295, 37865, 2899, 13, 4208, 5428, 488, 2899, 11, 291, 458, 11, 50872], "temperature": 0.0, "avg_logprob": -0.08120661919270086, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.0013249412877485156}, {"id": 191, "seek": 106792, "start": 1078.0800000000002, "end": 1085.28, "text": " kind of classic textbook definition is a cheaper, but inferior alternative that kind of competes", "tokens": [50872, 733, 295, 7230, 25591, 7123, 307, 257, 12284, 11, 457, 24249, 8535, 300, 733, 295, 2850, 279, 51232], "temperature": 0.0, "avg_logprob": -0.08120661919270086, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.0013249412877485156}, {"id": 192, "seek": 106792, "start": 1085.28, "end": 1090.96, "text": " on the low end of the market. It seems to me that AI is kind of both, right? It's we've got like", "tokens": [51232, 322, 264, 2295, 917, 295, 264, 2142, 13, 467, 2544, 281, 385, 300, 7318, 307, 733, 295, 1293, 11, 558, 30, 467, 311, 321, 600, 658, 411, 51516], "temperature": 0.0, "avg_logprob": -0.08120661919270086, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.0013249412877485156}, {"id": 193, "seek": 106792, "start": 1090.96, "end": 1094.8000000000002, "text": " these, at least exponentially growing inputs. Although on the other hand, you could sort of", "tokens": [51516, 613, 11, 412, 1935, 37330, 4194, 15743, 13, 5780, 322, 264, 661, 1011, 11, 291, 727, 1333, 295, 51708], "temperature": 0.0, "avg_logprob": -0.08120661919270086, "compression_ratio": 1.7110266159695817, "no_speech_prob": 0.0013249412877485156}, {"id": 194, "seek": 109480, "start": 1094.8, "end": 1100.32, "text": " say scaling laws sort of suggest that like the model capabilities are more like logarithmic,", "tokens": [50364, 584, 21589, 6064, 1333, 295, 3402, 300, 411, 264, 2316, 10862, 366, 544, 411, 41473, 355, 13195, 11, 50640], "temperature": 0.0, "avg_logprob": -0.10248989787528186, "compression_ratio": 1.6813880126182965, "no_speech_prob": 0.0032720426097512245}, {"id": 195, "seek": 109480, "start": 1100.32, "end": 1104.8, "text": " so those two things maybe like balance out somehow. It does seem like it's disruptive", "tokens": [50640, 370, 729, 732, 721, 1310, 411, 4772, 484, 6063, 13, 467, 775, 1643, 411, 309, 311, 37865, 50864], "temperature": 0.0, "avg_logprob": -0.10248989787528186, "compression_ratio": 1.6813880126182965, "no_speech_prob": 0.0032720426097512245}, {"id": 196, "seek": 109480, "start": 1104.8, "end": 1109.36, "text": " in that AI is typically like an inferior, but cheaper alternative to asking somebody to do", "tokens": [50864, 294, 300, 7318, 307, 5850, 411, 364, 24249, 11, 457, 12284, 8535, 281, 3365, 2618, 281, 360, 51092], "temperature": 0.0, "avg_logprob": -0.10248989787528186, "compression_ratio": 1.6813880126182965, "no_speech_prob": 0.0032720426097512245}, {"id": 197, "seek": 109480, "start": 1109.36, "end": 1114.08, "text": " something for you, right? It's a, it's also a general purpose technology. I guess what are the,", "tokens": [51092, 746, 337, 291, 11, 558, 30, 467, 311, 257, 11, 309, 311, 611, 257, 2674, 4334, 2899, 13, 286, 2041, 437, 366, 264, 11, 51328], "temperature": 0.0, "avg_logprob": -0.10248989787528186, "compression_ratio": 1.6813880126182965, "no_speech_prob": 0.0032720426097512245}, {"id": 198, "seek": 109480, "start": 1114.08, "end": 1118.48, "text": " what are the kind of key definitions and how do you think about mustering those different frameworks", "tokens": [51328, 437, 366, 264, 733, 295, 2141, 21988, 293, 577, 360, 291, 519, 466, 1633, 1794, 729, 819, 29834, 51548], "temperature": 0.0, "avg_logprob": -0.10248989787528186, "compression_ratio": 1.6813880126182965, "no_speech_prob": 0.0032720426097512245}, {"id": 199, "seek": 109480, "start": 1118.48, "end": 1122.24, "text": " so that people have good clarity on what it is we're dealing with?", "tokens": [51548, 370, 300, 561, 362, 665, 16992, 322, 437, 309, 307, 321, 434, 6260, 365, 30, 51736], "temperature": 0.0, "avg_logprob": -0.10248989787528186, "compression_ratio": 1.6813880126182965, "no_speech_prob": 0.0032720426097512245}, {"id": 200, "seek": 112224, "start": 1122.24, "end": 1130.88, "text": " I mean, it is, it's so hard because it is so, it is so general and it is also a technology that", "tokens": [50364, 286, 914, 11, 309, 307, 11, 309, 311, 370, 1152, 570, 309, 307, 370, 11, 309, 307, 370, 2674, 293, 309, 307, 611, 257, 2899, 300, 50796], "temperature": 0.0, "avg_logprob": -0.1116070800952697, "compression_ratio": 1.808411214953271, "no_speech_prob": 0.0042782435193657875}, {"id": 201, "seek": 112224, "start": 1130.88, "end": 1137.28, "text": " improves other technologies and itself directly, you know, not in the way that electricity improves", "tokens": [50796, 24771, 661, 7943, 293, 2564, 3838, 11, 291, 458, 11, 406, 294, 264, 636, 300, 10356, 24771, 51116], "temperature": 0.0, "avg_logprob": -0.1116070800952697, "compression_ratio": 1.808411214953271, "no_speech_prob": 0.0042782435193657875}, {"id": 202, "seek": 112224, "start": 1137.28, "end": 1140.8, "text": " electricity, you know, electricity makes the economy more efficient and so you can build more", "tokens": [51116, 10356, 11, 291, 458, 11, 10356, 1669, 264, 5010, 544, 7148, 293, 370, 291, 393, 1322, 544, 51292], "temperature": 0.0, "avg_logprob": -0.1116070800952697, "compression_ratio": 1.808411214953271, "no_speech_prob": 0.0042782435193657875}, {"id": 203, "seek": 112224, "start": 1140.8, "end": 1145.6, "text": " electrical power stations, but AI seems much more direct. I do think it's important to understand", "tokens": [51292, 12147, 1347, 13390, 11, 457, 7318, 2544, 709, 544, 2047, 13, 286, 360, 519, 309, 311, 1021, 281, 1223, 51532], "temperature": 0.0, "avg_logprob": -0.1116070800952697, "compression_ratio": 1.808411214953271, "no_speech_prob": 0.0042782435193657875}, {"id": 204, "seek": 114560, "start": 1146.0, "end": 1152.8799999999999, "text": " its generality to get people to wake up to the idea that a general purpose technology really", "tokens": [50384, 1080, 1337, 1860, 281, 483, 561, 281, 6634, 493, 281, 264, 1558, 300, 257, 2674, 4334, 2899, 534, 50728], "temperature": 0.0, "avg_logprob": -0.1374444288365981, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.01986418105661869}, {"id": 205, "seek": 114560, "start": 1153.52, "end": 1159.6799999999998, "text": " transforms the world beyond the, beyond the economics and, you know, again, Detroit is a", "tokens": [50760, 35592, 264, 1002, 4399, 264, 11, 4399, 264, 14564, 293, 11, 291, 458, 11, 797, 11, 20887, 307, 257, 51068], "temperature": 0.0, "avg_logprob": -0.1374444288365981, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.01986418105661869}, {"id": 206, "seek": 114560, "start": 1159.6799999999998, "end": 1167.04, "text": " great example for this because the car transformed the world in a very short period of time where I", "tokens": [51068, 869, 1365, 337, 341, 570, 264, 1032, 16894, 264, 1002, 294, 257, 588, 2099, 2896, 295, 565, 689, 286, 51436], "temperature": 0.0, "avg_logprob": -0.1374444288365981, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.01986418105661869}, {"id": 207, "seek": 114560, "start": 1167.04, "end": 1174.9599999999998, "text": " live in Northwest London 120 years ago, this was all fields and within 20 years after that,", "tokens": [51436, 1621, 294, 26068, 7042, 10411, 924, 2057, 11, 341, 390, 439, 7909, 293, 1951, 945, 924, 934, 300, 11, 51832], "temperature": 0.0, "avg_logprob": -0.1374444288365981, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.01986418105661869}, {"id": 208, "seek": 117496, "start": 1174.96, "end": 1178.64, "text": " by about 1925, the roads were laid out the way they were and the houses were built the way they", "tokens": [50364, 538, 466, 1294, 6074, 11, 264, 11344, 645, 9897, 484, 264, 636, 436, 645, 293, 264, 8078, 645, 3094, 264, 636, 436, 50548], "temperature": 0.0, "avg_logprob": -0.07482607174763638, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0015328434528782964}, {"id": 209, "seek": 117496, "start": 1178.64, "end": 1183.28, "text": " are and a century later we're still like this and this is because of ultimately the car as a", "tokens": [50548, 366, 293, 257, 4901, 1780, 321, 434, 920, 411, 341, 293, 341, 307, 570, 295, 6284, 264, 1032, 382, 257, 50780], "temperature": 0.0, "avg_logprob": -0.07482607174763638, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0015328434528782964}, {"id": 210, "seek": 117496, "start": 1183.28, "end": 1188.0, "text": " general purpose technology. So too, because they don't come around very often, I think that's a", "tokens": [50780, 2674, 4334, 2899, 13, 407, 886, 11, 570, 436, 500, 380, 808, 926, 588, 2049, 11, 286, 519, 300, 311, 257, 51016], "temperature": 0.0, "avg_logprob": -0.07482607174763638, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0015328434528782964}, {"id": 211, "seek": 117496, "start": 1188.0, "end": 1194.56, "text": " really good starting point. On the question of disruption, that is a, I think it's a kind of", "tokens": [51016, 534, 665, 2891, 935, 13, 1282, 264, 1168, 295, 28751, 11, 300, 307, 257, 11, 286, 519, 309, 311, 257, 733, 295, 51344], "temperature": 0.0, "avg_logprob": -0.07482607174763638, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0015328434528782964}, {"id": 212, "seek": 117496, "start": 1194.56, "end": 1200.88, "text": " higher order question because that is about products and how they get bundled to provide", "tokens": [51344, 2946, 1668, 1168, 570, 300, 307, 466, 3383, 293, 577, 436, 483, 13882, 1493, 281, 2893, 51660], "temperature": 0.0, "avg_logprob": -0.07482607174763638, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0015328434528782964}, {"id": 213, "seek": 120088, "start": 1200.88, "end": 1206.4, "text": " value in a particular environment and I think that, you know, when you start to bundle AI to do", "tokens": [50364, 2158, 294, 257, 1729, 2823, 293, 286, 519, 300, 11, 291, 458, 11, 562, 291, 722, 281, 24438, 7318, 281, 360, 50640], "temperature": 0.0, "avg_logprob": -0.09929834786107984, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.053357355296611786}, {"id": 214, "seek": 120088, "start": 1206.4, "end": 1210.96, "text": " that, you can ask that specific question. But one of the things I think is really important is,", "tokens": [50640, 300, 11, 291, 393, 1029, 300, 2685, 1168, 13, 583, 472, 295, 264, 721, 286, 519, 307, 534, 1021, 307, 11, 50868], "temperature": 0.0, "avg_logprob": -0.09929834786107984, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.053357355296611786}, {"id": 215, "seek": 120088, "start": 1210.96, "end": 1216.64, "text": " and I think companies started to think like this, is to think in terms of tasks rather than jobs", "tokens": [50868, 293, 286, 519, 3431, 1409, 281, 519, 411, 341, 11, 307, 281, 519, 294, 2115, 295, 9608, 2831, 813, 4782, 51152], "temperature": 0.0, "avg_logprob": -0.09929834786107984, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.053357355296611786}, {"id": 216, "seek": 120088, "start": 1216.64, "end": 1223.8400000000001, "text": " because, you know, AI can't replace jobs, anyone's job, because there's just so much in an ordinary", "tokens": [51152, 570, 11, 291, 458, 11, 7318, 393, 380, 7406, 4782, 11, 2878, 311, 1691, 11, 570, 456, 311, 445, 370, 709, 294, 364, 10547, 51512], "temperature": 0.0, "avg_logprob": -0.09929834786107984, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.053357355296611786}, {"id": 217, "seek": 120088, "start": 1223.8400000000001, "end": 1229.3600000000001, "text": " job, like logging on to Zoom and saying hello to somebody and getting your neighbor a cup of coffee", "tokens": [51512, 1691, 11, 411, 27991, 322, 281, 13453, 293, 1566, 7751, 281, 2618, 293, 1242, 428, 5987, 257, 4414, 295, 4982, 51788], "temperature": 0.0, "avg_logprob": -0.09929834786107984, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.053357355296611786}, {"id": 218, "seek": 122936, "start": 1230.08, "end": 1237.4399999999998, "text": " that is beyond the scope of any AI system. But within tasks, I think you can start to unpick", "tokens": [50400, 300, 307, 4399, 264, 11923, 295, 604, 7318, 1185, 13, 583, 1951, 9608, 11, 286, 519, 291, 393, 722, 281, 20994, 618, 50768], "temperature": 0.0, "avg_logprob": -0.09402598012792002, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.005247899796813726}, {"id": 219, "seek": 122936, "start": 1237.4399999999998, "end": 1242.8, "text": " this. And that's why in a sense you might start to say, well, AI becomes a disruptive technology", "tokens": [50768, 341, 13, 400, 300, 311, 983, 294, 257, 2020, 291, 1062, 722, 281, 584, 11, 731, 11, 7318, 3643, 257, 37865, 2899, 51036], "temperature": 0.0, "avg_logprob": -0.09402598012792002, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.005247899796813726}, {"id": 220, "seek": 122936, "start": 1242.8, "end": 1249.12, "text": " because on a like for like basis, it can't replace an entire, you know, human in their day to day,", "tokens": [51036, 570, 322, 257, 411, 337, 411, 5143, 11, 309, 393, 380, 7406, 364, 2302, 11, 291, 458, 11, 1952, 294, 641, 786, 281, 786, 11, 51352], "temperature": 0.0, "avg_logprob": -0.09402598012792002, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.005247899796813726}, {"id": 221, "seek": 122936, "start": 1249.12, "end": 1253.12, "text": " but it might get better and better. But I think what's more helpful is to go back to that task", "tokens": [51352, 457, 309, 1062, 483, 1101, 293, 1101, 13, 583, 286, 519, 437, 311, 544, 4961, 307, 281, 352, 646, 281, 300, 5633, 51552], "temperature": 0.0, "avg_logprob": -0.09402598012792002, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.005247899796813726}, {"id": 222, "seek": 125312, "start": 1253.1999999999998, "end": 1260.6399999999999, "text": " question. And then when we come to that, the question is on a task basis, is AI really a", "tokens": [50368, 1168, 13, 400, 550, 562, 321, 808, 281, 300, 11, 264, 1168, 307, 322, 257, 5633, 5143, 11, 307, 7318, 534, 257, 50740], "temperature": 0.0, "avg_logprob": -0.10626934570016212, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.14231114089488983}, {"id": 223, "seek": 125312, "start": 1261.6, "end": 1268.0, "text": " cheaper version of a human doing the same task and a worse version? Does that matter? And is that", "tokens": [50788, 12284, 3037, 295, 257, 1952, 884, 264, 912, 5633, 293, 257, 5324, 3037, 30, 4402, 300, 1871, 30, 400, 307, 300, 51108], "temperature": 0.0, "avg_logprob": -0.10626934570016212, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.14231114089488983}, {"id": 224, "seek": 125312, "start": 1268.0, "end": 1275.12, "text": " always the case? And I have certain tasks, which I do where I think I could not afford to hire a", "tokens": [51108, 1009, 264, 1389, 30, 400, 286, 362, 1629, 9608, 11, 597, 286, 360, 689, 286, 519, 286, 727, 406, 6157, 281, 11158, 257, 51464], "temperature": 0.0, "avg_logprob": -0.10626934570016212, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.14231114089488983}, {"id": 225, "seek": 125312, "start": 1275.12, "end": 1280.56, "text": " human to do this task as well as chat GPT does it for me, you know, in a minute or two. And that", "tokens": [51464, 1952, 281, 360, 341, 5633, 382, 731, 382, 5081, 26039, 51, 775, 309, 337, 385, 11, 291, 458, 11, 294, 257, 3456, 420, 732, 13, 400, 300, 51736], "temperature": 0.0, "avg_logprob": -0.10626934570016212, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.14231114089488983}, {"id": 226, "seek": 128056, "start": 1280.56, "end": 1285.04, "text": " may well be your experience as well. I mean, I, you know, I use this for to write letters of", "tokens": [50364, 815, 731, 312, 428, 1752, 382, 731, 13, 286, 914, 11, 286, 11, 291, 458, 11, 286, 764, 341, 337, 281, 2464, 7825, 295, 50588], "temperature": 0.0, "avg_logprob": -0.10153996072164397, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019800253212451935}, {"id": 227, "seek": 128056, "start": 1285.04, "end": 1292.6399999999999, "text": " complaints to get my parking fines reversed to help me think through holiday plans to do research", "tokens": [50588, 19585, 281, 483, 452, 9893, 37989, 30563, 281, 854, 385, 519, 807, 9960, 5482, 281, 360, 2132, 50968], "temperature": 0.0, "avg_logprob": -0.10153996072164397, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019800253212451935}, {"id": 228, "seek": 128056, "start": 1292.6399999999999, "end": 1297.36, "text": " for my book. And so I mean, it's just it's so variable. And in many cases, I would be better", "tokens": [50968, 337, 452, 1446, 13, 400, 370, 286, 914, 11, 309, 311, 445, 309, 311, 370, 7006, 13, 400, 294, 867, 3331, 11, 286, 576, 312, 1101, 51204], "temperature": 0.0, "avg_logprob": -0.10153996072164397, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019800253212451935}, {"id": 229, "seek": 128056, "start": 1297.36, "end": 1303.04, "text": " off finding the very best human to do that. But the costs of doing that, even finding them is so", "tokens": [51204, 766, 5006, 264, 588, 1151, 1952, 281, 360, 300, 13, 583, 264, 5497, 295, 884, 300, 11, 754, 5006, 552, 307, 370, 51488], "temperature": 0.0, "avg_logprob": -0.10153996072164397, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019800253212451935}, {"id": 230, "seek": 128056, "start": 1303.04, "end": 1308.24, "text": " high. Yeah, your search costs alone would dominate. Yeah, search costs would dominate. I mean, when", "tokens": [51488, 1090, 13, 865, 11, 428, 3164, 5497, 3312, 576, 28246, 13, 865, 11, 3164, 5497, 576, 28246, 13, 286, 914, 11, 562, 51748], "temperature": 0.0, "avg_logprob": -0.10153996072164397, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019800253212451935}, {"id": 231, "seek": 130824, "start": 1308.24, "end": 1315.2, "text": " you're using, you know, GPT for or perplexity, whatever you use, do you have it across a whole", "tokens": [50364, 291, 434, 1228, 11, 291, 458, 11, 26039, 51, 337, 420, 680, 18945, 507, 11, 2035, 291, 764, 11, 360, 291, 362, 309, 2108, 257, 1379, 50712], "temperature": 0.0, "avg_logprob": -0.07320052512148593, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003457720740698278}, {"id": 232, "seek": 130824, "start": 1315.2, "end": 1320.96, "text": " range of different tasks that you do from the most strategic for your business to the most sort of", "tokens": [50712, 3613, 295, 819, 9608, 300, 291, 360, 490, 264, 881, 10924, 337, 428, 1606, 281, 264, 881, 1333, 295, 51000], "temperature": 0.0, "avg_logprob": -0.07320052512148593, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003457720740698278}, {"id": 233, "seek": 130824, "start": 1320.96, "end": 1327.76, "text": " trivial home tasks? Yeah, maybe not the most strategic yet. At that level, I would probably", "tokens": [51000, 26703, 1280, 9608, 30, 865, 11, 1310, 406, 264, 881, 10924, 1939, 13, 1711, 300, 1496, 11, 286, 576, 1391, 51340], "temperature": 0.0, "avg_logprob": -0.07320052512148593, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003457720740698278}, {"id": 234, "seek": 130824, "start": 1327.76, "end": 1333.92, "text": " restrict myself to kind of brainstorming, you know, interaction at most, but certainly lots of", "tokens": [51340, 7694, 2059, 281, 733, 295, 35245, 278, 11, 291, 458, 11, 9285, 412, 881, 11, 457, 3297, 3195, 295, 51648], "temperature": 0.0, "avg_logprob": -0.07320052512148593, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0003457720740698278}, {"id": 235, "seek": 133392, "start": 1333.92, "end": 1339.92, "text": " things I get, you know, very efficient and an immediate help on. And I think that immediacy is", "tokens": [50364, 721, 286, 483, 11, 291, 458, 11, 588, 7148, 293, 364, 11629, 854, 322, 13, 400, 286, 519, 300, 3640, 2551, 307, 50664], "temperature": 0.0, "avg_logprob": -0.11872506648936171, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.012051379308104515}, {"id": 236, "seek": 133392, "start": 1339.92, "end": 1344.8000000000002, "text": " super important, too. I have this one slide that I call the cognitive tail of the tape,", "tokens": [50664, 1687, 1021, 11, 886, 13, 286, 362, 341, 472, 4137, 300, 286, 818, 264, 15605, 6838, 295, 264, 7314, 11, 50908], "temperature": 0.0, "avg_logprob": -0.11872506648936171, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.012051379308104515}, {"id": 237, "seek": 133392, "start": 1344.8000000000002, "end": 1351.04, "text": " which kind of lists out 12 dimensions and compares human to today's AIs. And, you know, then we can", "tokens": [50908, 597, 733, 295, 14511, 484, 2272, 12819, 293, 38334, 1952, 281, 965, 311, 316, 6802, 13, 400, 11, 291, 458, 11, 550, 321, 393, 51220], "temperature": 0.0, "avg_logprob": -0.11872506648936171, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.012051379308104515}, {"id": 238, "seek": 133392, "start": 1351.04, "end": 1357.8400000000001, "text": " also consider what future as might look like, very much agree with your notion of distinguishing", "tokens": [51220, 611, 1949, 437, 2027, 382, 1062, 574, 411, 11, 588, 709, 3986, 365, 428, 10710, 295, 11365, 3807, 51560], "temperature": 0.0, "avg_logprob": -0.11872506648936171, "compression_ratio": 1.5661157024793388, "no_speech_prob": 0.012051379308104515}, {"id": 239, "seek": 135784, "start": 1357.84, "end": 1364.32, "text": " between jobs and tasks. And for a while, I was calling this the great implementation. And I've", "tokens": [50364, 1296, 4782, 293, 9608, 13, 400, 337, 257, 1339, 11, 286, 390, 5141, 341, 264, 869, 11420, 13, 400, 286, 600, 50688], "temperature": 0.0, "avg_logprob": -0.1300180342889601, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.08753771334886551}, {"id": 240, "seek": 135784, "start": 1364.32, "end": 1368.56, "text": " that phrase hasn't quite taken off yet. But the idea there is with inspiration from like your,", "tokens": [50688, 300, 9535, 6132, 380, 1596, 2726, 766, 1939, 13, 583, 264, 1558, 456, 307, 365, 10249, 490, 411, 428, 11, 50900], "temperature": 0.0, "avg_logprob": -0.1300180342889601, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.08753771334886551}, {"id": 241, "seek": 135784, "start": 1368.56, "end": 1374.72, "text": " you know, strutequeries and your Benedict Evans type business theorists, you know, the way to make", "tokens": [50900, 291, 458, 11, 1056, 1169, 8035, 530, 293, 428, 47837, 30055, 2010, 1606, 27423, 1751, 11, 291, 458, 11, 264, 636, 281, 652, 51208], "temperature": 0.0, "avg_logprob": -0.1300180342889601, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.08753771334886551}, {"id": 242, "seek": 135784, "start": 1374.72, "end": 1381.6, "text": " money in businesses to bundle and unbundle, I do think that unbundling jobs into tasks is a very", "tokens": [51208, 1460, 294, 6011, 281, 24438, 293, 517, 65, 997, 306, 11, 286, 360, 519, 300, 517, 65, 997, 1688, 4782, 666, 9608, 307, 257, 588, 51552], "temperature": 0.0, "avg_logprob": -0.1300180342889601, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.08753771334886551}, {"id": 243, "seek": 135784, "start": 1382.32, "end": 1386.8799999999999, "text": " good way to think about it. And then for any given task, you go down this tail of the tape,", "tokens": [51588, 665, 636, 281, 519, 466, 309, 13, 400, 550, 337, 604, 2212, 5633, 11, 291, 352, 760, 341, 6838, 295, 264, 7314, 11, 51816], "temperature": 0.0, "avg_logprob": -0.1300180342889601, "compression_ratio": 1.7035714285714285, "no_speech_prob": 0.08753771334886551}, {"id": 244, "seek": 138688, "start": 1386.88, "end": 1393.6000000000001, "text": " and you're like, Yeah, a lot of them AI can do as well, or even better than a human or certainly", "tokens": [50364, 293, 291, 434, 411, 11, 865, 11, 257, 688, 295, 552, 7318, 393, 360, 382, 731, 11, 420, 754, 1101, 813, 257, 1952, 420, 3297, 50700], "temperature": 0.0, "avg_logprob": -0.11631924765450614, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.000754998647607863}, {"id": 245, "seek": 138688, "start": 1394.48, "end": 1398.24, "text": " better than a human that I could find without huge search costs.", "tokens": [50744, 1101, 813, 257, 1952, 300, 286, 727, 915, 1553, 2603, 3164, 5497, 13, 50932], "temperature": 0.0, "avg_logprob": -0.11631924765450614, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.000754998647607863}, {"id": 246, "seek": 138688, "start": 1398.8000000000002, "end": 1403.6000000000001, "text": " You know, we get we get quite surprised with some of the results. So I think one of the", "tokens": [50960, 509, 458, 11, 321, 483, 321, 483, 1596, 6100, 365, 512, 295, 264, 3542, 13, 407, 286, 519, 472, 295, 264, 51200], "temperature": 0.0, "avg_logprob": -0.11631924765450614, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.000754998647607863}, {"id": 247, "seek": 138688, "start": 1403.6000000000001, "end": 1408.48, "text": " really big surprises is that if we went back six or seven years, and you had books like The Rise", "tokens": [51200, 534, 955, 22655, 307, 300, 498, 321, 1437, 646, 2309, 420, 3407, 924, 11, 293, 291, 632, 3642, 411, 440, 34482, 51444], "temperature": 0.0, "avg_logprob": -0.11631924765450614, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.000754998647607863}, {"id": 248, "seek": 138688, "start": 1408.48, "end": 1413.44, "text": " of the Robots and the famous Oxford paper saying, you know, machine learning could automate 40%", "tokens": [51444, 295, 264, 5424, 1971, 293, 264, 4618, 24786, 3035, 1566, 11, 291, 458, 11, 3479, 2539, 727, 31605, 3356, 4, 51692], "temperature": 0.0, "avg_logprob": -0.11631924765450614, "compression_ratio": 1.6679245283018869, "no_speech_prob": 0.000754998647607863}, {"id": 249, "seek": 141344, "start": 1413.44, "end": 1418.3200000000002, "text": " or expersent of jobs that's written by a friend of mine. And our assumption was that it would be", "tokens": [50364, 420, 1278, 433, 317, 295, 4782, 300, 311, 3720, 538, 257, 1277, 295, 3892, 13, 400, 527, 15302, 390, 300, 309, 576, 312, 50608], "temperature": 0.0, "avg_logprob": -0.1437238173051314, "compression_ratio": 1.6853146853146854, "no_speech_prob": 0.00647598784416914}, {"id": 250, "seek": 141344, "start": 1419.2, "end": 1425.44, "text": " routine cognitive jobs, by which what people meant was customer service and data entry in like", "tokens": [50652, 9927, 15605, 4782, 11, 538, 597, 437, 561, 4140, 390, 5474, 2643, 293, 1412, 8729, 294, 411, 50964], "temperature": 0.0, "avg_logprob": -0.1437238173051314, "compression_ratio": 1.6853146853146854, "no_speech_prob": 0.00647598784416914}, {"id": 251, "seek": 141344, "start": 1425.44, "end": 1430.48, "text": " Philippines or the Indian or in India. And what we're actually discovering is that it's jobs that", "tokens": [50964, 20153, 420, 264, 6427, 420, 294, 5282, 13, 400, 437, 321, 434, 767, 24773, 307, 300, 309, 311, 4782, 300, 51216], "temperature": 0.0, "avg_logprob": -0.1437238173051314, "compression_ratio": 1.6853146853146854, "no_speech_prob": 0.00647598784416914}, {"id": 252, "seek": 141344, "start": 1430.48, "end": 1436.3200000000002, "text": " we would have categorized as non routine or even creative, where this technology can really start", "tokens": [51216, 321, 576, 362, 19250, 1602, 382, 2107, 9927, 420, 754, 5880, 11, 689, 341, 2899, 393, 534, 722, 51508], "temperature": 0.0, "avg_logprob": -0.1437238173051314, "compression_ratio": 1.6853146853146854, "no_speech_prob": 0.00647598784416914}, {"id": 253, "seek": 141344, "start": 1436.3200000000002, "end": 1442.88, "text": " to make a difference. And it really, really is surprising. One that really I was not expecting", "tokens": [51508, 281, 652, 257, 2649, 13, 400, 309, 534, 11, 534, 307, 8830, 13, 1485, 300, 534, 286, 390, 406, 9650, 51836], "temperature": 0.0, "avg_logprob": -0.1437238173051314, "compression_ratio": 1.6853146853146854, "no_speech_prob": 0.00647598784416914}, {"id": 254, "seek": 144288, "start": 1442.88, "end": 1450.5600000000002, "text": " was a paper at the end of 2023, which looked at empathy ratings of doctors giving advice compared", "tokens": [50364, 390, 257, 3035, 412, 264, 917, 295, 44377, 11, 597, 2956, 412, 18701, 24603, 295, 8778, 2902, 5192, 5347, 50748], "temperature": 0.0, "avg_logprob": -0.10244355303175906, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0018401280976831913}, {"id": 255, "seek": 144288, "start": 1450.5600000000002, "end": 1457.7600000000002, "text": " to that GPT or GPT for giving advice, and patients were rating the robotic advice as more empathetic", "tokens": [50748, 281, 300, 26039, 51, 420, 26039, 51, 337, 2902, 5192, 11, 293, 4209, 645, 10990, 264, 30468, 5192, 382, 544, 27155, 3532, 51108], "temperature": 0.0, "avg_logprob": -0.10244355303175906, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0018401280976831913}, {"id": 256, "seek": 144288, "start": 1457.7600000000002, "end": 1464.16, "text": " as humans. And the whole argument had been, let's use AI. So the radiologist can spend more time", "tokens": [51108, 382, 6255, 13, 400, 264, 1379, 6770, 632, 668, 11, 718, 311, 764, 7318, 13, 407, 264, 16335, 9201, 393, 3496, 544, 565, 51428], "temperature": 0.0, "avg_logprob": -0.10244355303175906, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0018401280976831913}, {"id": 257, "seek": 144288, "start": 1464.72, "end": 1470.24, "text": " looking you in the eye and being attentive, and being and being empathetic. So part of the", "tokens": [51456, 1237, 291, 294, 264, 3313, 293, 885, 43661, 11, 293, 885, 293, 885, 27155, 3532, 13, 407, 644, 295, 264, 51732], "temperature": 0.0, "avg_logprob": -0.10244355303175906, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0018401280976831913}, {"id": 258, "seek": 147024, "start": 1470.24, "end": 1476.08, "text": " challenge I think is that there is this lack of clarity and lack of knowledge about where and when", "tokens": [50364, 3430, 286, 519, 307, 300, 456, 307, 341, 5011, 295, 16992, 293, 5011, 295, 3601, 466, 689, 293, 562, 50656], "temperature": 0.0, "avg_logprob": -0.09974368551503057, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0001533905597170815}, {"id": 259, "seek": 147024, "start": 1476.08, "end": 1481.92, "text": " will these AI systems actually compete with humans on particular, particular tasks. And then when", "tokens": [50656, 486, 613, 7318, 3652, 767, 11831, 365, 6255, 322, 1729, 11, 1729, 9608, 13, 400, 550, 562, 50948], "temperature": 0.0, "avg_logprob": -0.09974368551503057, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0001533905597170815}, {"id": 260, "seek": 147024, "start": 1481.92, "end": 1486.56, "text": " you think about it, actually, what is empathy? Empathy is about active listening and it's about", "tokens": [50948, 291, 519, 466, 309, 11, 767, 11, 437, 307, 18701, 30, 8599, 9527, 307, 466, 4967, 4764, 293, 309, 311, 466, 51180], "temperature": 0.0, "avg_logprob": -0.09974368551503057, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0001533905597170815}, {"id": 261, "seek": 147024, "start": 1486.56, "end": 1492.4, "text": " being incredibly patient. And there's nothing that's more patient than a robot that has no sense of", "tokens": [51180, 885, 6252, 4537, 13, 400, 456, 311, 1825, 300, 311, 544, 4537, 813, 257, 7881, 300, 575, 572, 2020, 295, 51472], "temperature": 0.0, "avg_logprob": -0.09974368551503057, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0001533905597170815}, {"id": 262, "seek": 147024, "start": 1492.4, "end": 1497.36, "text": " time and is stateless, right? I mean, it'll just sit there forever. An early GPT for tests that I", "tokens": [51472, 565, 293, 307, 2219, 4272, 11, 558, 30, 286, 914, 11, 309, 603, 445, 1394, 456, 5680, 13, 1107, 2440, 26039, 51, 337, 6921, 300, 286, 51720], "temperature": 0.0, "avg_logprob": -0.09974368551503057, "compression_ratio": 1.7253521126760563, "no_speech_prob": 0.0001533905597170815}, {"id": 263, "seek": 149736, "start": 1497.36, "end": 1504.1599999999999, "text": " remember fondly and do think is kind of a sign of things to come was simulated tech support for my", "tokens": [50364, 1604, 9557, 356, 293, 360, 519, 307, 733, 295, 257, 1465, 295, 721, 281, 808, 390, 41713, 7553, 1406, 337, 452, 50704], "temperature": 0.0, "avg_logprob": -0.11808395385742188, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.012427453882992268}, {"id": 264, "seek": 149736, "start": 1504.1599999999999, "end": 1512.24, "text": " grandmother when she needs help with her iPhone. And it was, you know, just a flash of this, you", "tokens": [50704, 14317, 562, 750, 2203, 854, 365, 720, 7252, 13, 400, 309, 390, 11, 291, 458, 11, 445, 257, 7319, 295, 341, 11, 291, 51108], "temperature": 0.0, "avg_logprob": -0.11808395385742188, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.012427453882992268}, {"id": 265, "seek": 149736, "start": 1512.24, "end": 1519.04, "text": " could call it sparks of things to come where I played the role of her, which, you know, and I,", "tokens": [51108, 727, 818, 309, 44102, 295, 721, 281, 808, 689, 286, 3737, 264, 3090, 295, 720, 11, 597, 11, 291, 458, 11, 293, 286, 11, 51448], "temperature": 0.0, "avg_logprob": -0.11808395385742188, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.012427453882992268}, {"id": 266, "seek": 149736, "start": 1519.04, "end": 1523.36, "text": " she calls me, right, when she needs help with the iPhone. And, you know, you're in this dynamic.", "tokens": [51448, 750, 5498, 385, 11, 558, 11, 562, 750, 2203, 854, 365, 264, 7252, 13, 400, 11, 291, 458, 11, 291, 434, 294, 341, 8546, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11808395385742188, "compression_ratio": 1.7834101382488479, "no_speech_prob": 0.012427453882992268}, {"id": 267, "seek": 152336, "start": 1523.36, "end": 1527.52, "text": " And it's actually an interesting dynamic also for a pure text situation because she's typically", "tokens": [50364, 400, 309, 311, 767, 364, 1880, 8546, 611, 337, 257, 6075, 2487, 2590, 570, 750, 311, 5850, 50572], "temperature": 0.0, "avg_logprob": -0.08872310698978485, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.024416090920567513}, {"id": 268, "seek": 152336, "start": 1527.52, "end": 1532.6399999999999, "text": " on the phone with me looking at the phone and saying, you know, I can't, my friend sent me an", "tokens": [50572, 322, 264, 2593, 365, 385, 1237, 412, 264, 2593, 293, 1566, 11, 291, 458, 11, 286, 393, 380, 11, 452, 1277, 2279, 385, 364, 50828], "temperature": 0.0, "avg_logprob": -0.08872310698978485, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.024416090920567513}, {"id": 269, "seek": 152336, "start": 1532.6399999999999, "end": 1539.36, "text": " email and I can't get it. And then I'm like, okay, well, I always start with, what do you see on the", "tokens": [50828, 3796, 293, 286, 393, 380, 483, 309, 13, 400, 550, 286, 478, 411, 11, 1392, 11, 731, 11, 286, 1009, 722, 365, 11, 437, 360, 291, 536, 322, 264, 51164], "temperature": 0.0, "avg_logprob": -0.08872310698978485, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.024416090920567513}, {"id": 270, "seek": 152336, "start": 1539.36, "end": 1544.8799999999999, "text": " screen right now? Can you start at the top and just read everything that you see on the screen?", "tokens": [51164, 2568, 558, 586, 30, 1664, 291, 722, 412, 264, 1192, 293, 445, 1401, 1203, 300, 291, 536, 322, 264, 2568, 30, 51440], "temperature": 0.0, "avg_logprob": -0.08872310698978485, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.024416090920567513}, {"id": 271, "seek": 152336, "start": 1544.8799999999999, "end": 1549.6, "text": " And at times we've had some very, you know, kind of funny, does she always read everything that's", "tokens": [51440, 400, 412, 1413, 321, 600, 632, 512, 588, 11, 291, 458, 11, 733, 295, 4074, 11, 775, 750, 1009, 1401, 1203, 300, 311, 51676], "temperature": 0.0, "avg_logprob": -0.08872310698978485, "compression_ratio": 1.7925925925925925, "no_speech_prob": 0.024416090920567513}, {"id": 272, "seek": 154960, "start": 1549.6, "end": 1553.6799999999998, "text": " there? Like, you know, she's missed something out. You're like, grandma, wasn't there a,", "tokens": [50364, 456, 30, 1743, 11, 291, 458, 11, 750, 311, 6721, 746, 484, 13, 509, 434, 411, 11, 15766, 11, 2067, 380, 456, 257, 11, 50568], "temperature": 0.0, "avg_logprob": -0.1379850905462606, "compression_ratio": 1.70846394984326, "no_speech_prob": 0.029305296018719673}, {"id": 273, "seek": 154960, "start": 1553.6799999999998, "end": 1558.48, "text": " isn't there a word above? No, she does pretty well. Yeah, she'll start at the top Verizon,", "tokens": [50568, 1943, 380, 456, 257, 1349, 3673, 30, 883, 11, 750, 775, 1238, 731, 13, 865, 11, 750, 603, 722, 412, 264, 1192, 44456, 11, 50808], "temperature": 0.0, "avg_logprob": -0.1379850905462606, "compression_ratio": 1.70846394984326, "no_speech_prob": 0.029305296018719673}, {"id": 274, "seek": 154960, "start": 1558.48, "end": 1562.1599999999999, "text": " you know, the time. And then there've been a couple of times where, you know,", "tokens": [50808, 291, 458, 11, 264, 565, 13, 400, 550, 456, 600, 668, 257, 1916, 295, 1413, 689, 11, 291, 458, 11, 50992], "temperature": 0.0, "avg_logprob": -0.1379850905462606, "compression_ratio": 1.70846394984326, "no_speech_prob": 0.029305296018719673}, {"id": 275, "seek": 154960, "start": 1562.7199999999998, "end": 1566.56, "text": " some one of those dial system dialogues pops up and that like just didn't even register to her.", "tokens": [51020, 512, 472, 295, 729, 5502, 1185, 45551, 16795, 493, 293, 300, 411, 445, 994, 380, 754, 7280, 281, 720, 13, 51212], "temperature": 0.0, "avg_logprob": -0.1379850905462606, "compression_ratio": 1.70846394984326, "no_speech_prob": 0.029305296018719673}, {"id": 276, "seek": 154960, "start": 1566.56, "end": 1569.6799999999998, "text": " But then when she got it to reading, I was like, you need to hit okay there before you're going", "tokens": [51212, 583, 550, 562, 750, 658, 309, 281, 3760, 11, 286, 390, 411, 11, 291, 643, 281, 2045, 1392, 456, 949, 291, 434, 516, 51368], "temperature": 0.0, "avg_logprob": -0.1379850905462606, "compression_ratio": 1.70846394984326, "no_speech_prob": 0.029305296018719673}, {"id": 277, "seek": 154960, "start": 1569.6799999999998, "end": 1575.04, "text": " to be able to hit anything else. So it can be these very simple things. But GPT-4, as you might", "tokens": [51368, 281, 312, 1075, 281, 2045, 1340, 1646, 13, 407, 309, 393, 312, 613, 588, 2199, 721, 13, 583, 26039, 51, 12, 19, 11, 382, 291, 1062, 51636], "temperature": 0.0, "avg_logprob": -0.1379850905462606, "compression_ratio": 1.70846394984326, "no_speech_prob": 0.029305296018719673}, {"id": 278, "seek": 157504, "start": 1575.04, "end": 1579.28, "text": " expect, did really quite well on that. There was a little bit of, it was in kind of the middle of", "tokens": [50364, 2066, 11, 630, 534, 1596, 731, 322, 300, 13, 821, 390, 257, 707, 857, 295, 11, 309, 390, 294, 733, 295, 264, 2808, 295, 50576], "temperature": 0.0, "avg_logprob": -0.09022925746056341, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.16882465779781342}, {"id": 279, "seek": 157504, "start": 1579.28, "end": 1586.8, "text": " where it did not have the UI of an iPhone memorized. So it was kind of hallucinating it and guessing.", "tokens": [50576, 689, 309, 630, 406, 362, 264, 15682, 295, 364, 7252, 46677, 13, 407, 309, 390, 733, 295, 35212, 8205, 309, 293, 17939, 13, 50952], "temperature": 0.0, "avg_logprob": -0.09022925746056341, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.16882465779781342}, {"id": 280, "seek": 157504, "start": 1587.44, "end": 1591.84, "text": " And yet the guesses were close enough, you know, and I really had to study my iPhone", "tokens": [50984, 400, 1939, 264, 42703, 645, 1998, 1547, 11, 291, 458, 11, 293, 286, 534, 632, 281, 2979, 452, 7252, 51204], "temperature": 0.0, "avg_logprob": -0.09022925746056341, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.16882465779781342}, {"id": 281, "seek": 157504, "start": 1591.84, "end": 1596.72, "text": " and what it was saying and kind of compare like, is the, is it saying what's actually there or", "tokens": [51204, 293, 437, 309, 390, 1566, 293, 733, 295, 6794, 411, 11, 307, 264, 11, 307, 309, 1566, 437, 311, 767, 456, 420, 51448], "temperature": 0.0, "avg_logprob": -0.09022925746056341, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.16882465779781342}, {"id": 282, "seek": 157504, "start": 1596.72, "end": 1600.8799999999999, "text": " not? And mostly was, but it was clear it was kind of filling in some gaps. But the real eye opening", "tokens": [51448, 406, 30, 400, 5240, 390, 11, 457, 309, 390, 1850, 309, 390, 733, 295, 10623, 294, 512, 15031, 13, 583, 264, 957, 3313, 5193, 51656], "temperature": 0.0, "avg_logprob": -0.09022925746056341, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.16882465779781342}, {"id": 283, "seek": 160088, "start": 1600.88, "end": 1608.88, "text": " moment for me was it said something that I thought she might feel was a little bit rude.", "tokens": [50364, 1623, 337, 385, 390, 309, 848, 746, 300, 286, 1194, 750, 1062, 841, 390, 257, 707, 857, 18895, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09683240827966909, "compression_ratio": 1.842741935483871, "no_speech_prob": 0.013635406270623207}, {"id": 284, "seek": 160088, "start": 1609.6000000000001, "end": 1613.3600000000001, "text": " I forget exactly what it was, but it was like, you know, it was like starting the", "tokens": [50800, 286, 2870, 2293, 437, 309, 390, 11, 457, 309, 390, 411, 11, 291, 458, 11, 309, 390, 411, 2891, 264, 50988], "temperature": 0.0, "avg_logprob": -0.09683240827966909, "compression_ratio": 1.842741935483871, "no_speech_prob": 0.013635406270623207}, {"id": 285, "seek": 160088, "start": 1613.3600000000001, "end": 1616.8000000000002, "text": " starting the top left, you know, where the top left is something like kind of that basic.", "tokens": [50988, 2891, 264, 1192, 1411, 11, 291, 458, 11, 689, 264, 1192, 1411, 307, 746, 411, 733, 295, 300, 3875, 13, 51160], "temperature": 0.0, "avg_logprob": -0.09683240827966909, "compression_ratio": 1.842741935483871, "no_speech_prob": 0.013635406270623207}, {"id": 286, "seek": 160088, "start": 1617.3600000000001, "end": 1622.72, "text": " And then I responded as her saying, yes, I know where the top left is. I'm not dumb. I'm just", "tokens": [51188, 400, 550, 286, 15806, 382, 720, 1566, 11, 2086, 11, 286, 458, 689, 264, 1192, 1411, 307, 13, 286, 478, 406, 10316, 13, 286, 478, 445, 51456], "temperature": 0.0, "avg_logprob": -0.09683240827966909, "compression_ratio": 1.842741935483871, "no_speech_prob": 0.013635406270623207}, {"id": 287, "seek": 160088, "start": 1622.72, "end": 1627.8400000000001, "text": " struggling with this phone. And then the AI comes back and says, I'm so sorry, I didn't mean to offend", "tokens": [51456, 9314, 365, 341, 2593, 13, 400, 550, 264, 7318, 1487, 646, 293, 1619, 11, 286, 478, 370, 2597, 11, 286, 994, 380, 914, 281, 41836, 51712], "temperature": 0.0, "avg_logprob": -0.09683240827966909, "compression_ratio": 1.842741935483871, "no_speech_prob": 0.013635406270623207}, {"id": 288, "seek": 162784, "start": 1627.84, "end": 1631.6, "text": " you. I'm just, you know, trying to make sure we're resetting here and, you know, helping you", "tokens": [50364, 291, 13, 286, 478, 445, 11, 291, 458, 11, 1382, 281, 652, 988, 321, 434, 14322, 783, 510, 293, 11, 291, 458, 11, 4315, 291, 50552], "temperature": 0.0, "avg_logprob": -0.08575387434525923, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.04466422647237778}, {"id": 289, "seek": 162784, "start": 1631.6, "end": 1634.8799999999999, "text": " through this process. And that was the moment where I was like, Oh, this thing is going to be,", "tokens": [50552, 807, 341, 1399, 13, 400, 300, 390, 264, 1623, 689, 286, 390, 411, 11, 876, 11, 341, 551, 307, 516, 281, 312, 11, 50716], "temperature": 0.0, "avg_logprob": -0.08575387434525923, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.04466422647237778}, {"id": 290, "seek": 162784, "start": 1635.76, "end": 1640.6399999999999, "text": " it's got kind of this emotional intelligence as well. And that could be, you know, obviously just", "tokens": [50760, 309, 311, 658, 733, 295, 341, 6863, 7599, 382, 731, 13, 400, 300, 727, 312, 11, 291, 458, 11, 2745, 445, 51004], "temperature": 0.0, "avg_logprob": -0.08575387434525923, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.04466422647237778}, {"id": 291, "seek": 162784, "start": 1640.6399999999999, "end": 1645.1999999999998, "text": " a critical ingredient for so many different interactions and medicine being a big one. We've", "tokens": [51004, 257, 4924, 14751, 337, 370, 867, 819, 13280, 293, 7195, 885, 257, 955, 472, 13, 492, 600, 51232], "temperature": 0.0, "avg_logprob": -0.08575387434525923, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.04466422647237778}, {"id": 292, "seek": 162784, "start": 1645.1999999999998, "end": 1652.0, "text": " done two episodes with Vivek Nadarajan, who leads a lot of these med specific projects at Google.", "tokens": [51232, 1096, 732, 9313, 365, 44288, 74, 23269, 289, 1805, 282, 11, 567, 6689, 257, 688, 295, 613, 1205, 2685, 4455, 412, 3329, 13, 51572], "temperature": 0.0, "avg_logprob": -0.08575387434525923, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.04466422647237778}, {"id": 293, "seek": 165200, "start": 1652.72, "end": 1660.0, "text": " And what an absolute terror they've been on. Most recently, they have a diagnosis differential", "tokens": [50400, 400, 437, 364, 8236, 8127, 436, 600, 668, 322, 13, 4534, 3938, 11, 436, 362, 257, 15217, 15756, 50764], "temperature": 0.0, "avg_logprob": -0.09446698064389436, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.08259779214859009}, {"id": 294, "seek": 165200, "start": 1660.0, "end": 1666.08, "text": " diagnosis paper that shows the AI is getting the correct diagnosis twice as often as the unassisted", "tokens": [50764, 15217, 3035, 300, 3110, 264, 7318, 307, 1242, 264, 3006, 15217, 6091, 382, 2049, 382, 264, 517, 640, 33250, 51068], "temperature": 0.0, "avg_logprob": -0.09446698064389436, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.08259779214859009}, {"id": 295, "seek": 165200, "start": 1666.08, "end": 1670.72, "text": " human. And also more often than the AI assisted human, which I think is the thing that we should", "tokens": [51068, 1952, 13, 400, 611, 544, 2049, 813, 264, 7318, 30291, 1952, 11, 597, 286, 519, 307, 264, 551, 300, 321, 820, 51300], "temperature": 0.0, "avg_logprob": -0.09446698064389436, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.08259779214859009}, {"id": 296, "seek": 165200, "start": 1670.72, "end": 1675.2, "text": " begin to reckon with. There's so much to unpack in that. Can I ask you one question about the", "tokens": [51300, 1841, 281, 29548, 365, 13, 821, 311, 370, 709, 281, 26699, 294, 300, 13, 1664, 286, 1029, 291, 472, 1168, 466, 264, 51524], "temperature": 0.0, "avg_logprob": -0.09446698064389436, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.08259779214859009}, {"id": 297, "seek": 165200, "start": 1675.2, "end": 1679.92, "text": " politeness from the, you know, when you're playing your, your grandma, do you think that that comes", "tokens": [51524, 2453, 15264, 490, 264, 11, 291, 458, 11, 562, 291, 434, 2433, 428, 11, 428, 15766, 11, 360, 291, 519, 300, 300, 1487, 51760], "temperature": 0.0, "avg_logprob": -0.09446698064389436, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.08259779214859009}, {"id": 298, "seek": 167992, "start": 1679.92, "end": 1686.24, "text": " from the human feedback cycle over the network before it gets released? Or is it, is it from the", "tokens": [50364, 490, 264, 1952, 5824, 6586, 670, 264, 3209, 949, 309, 2170, 4736, 30, 1610, 307, 309, 11, 307, 309, 490, 264, 50680], "temperature": 0.0, "avg_logprob": -0.0949530029296875, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0016476567834615707}, {"id": 299, "seek": 167992, "start": 1686.24, "end": 1692.3200000000002, "text": " training data? The version that we had was, as far as I know, right, I'm inferring here because", "tokens": [50680, 3097, 1412, 30, 440, 3037, 300, 321, 632, 390, 11, 382, 1400, 382, 286, 458, 11, 558, 11, 286, 478, 13596, 2937, 510, 570, 50984], "temperature": 0.0, "avg_logprob": -0.0949530029296875, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0016476567834615707}, {"id": 300, "seek": 167992, "start": 1692.3200000000002, "end": 1699.92, "text": " I did not have access to the training methods. But it seemed very clear to me that the model", "tokens": [50984, 286, 630, 406, 362, 2105, 281, 264, 3097, 7150, 13, 583, 309, 6576, 588, 1850, 281, 385, 300, 264, 2316, 51364], "temperature": 0.0, "avg_logprob": -0.0949530029296875, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0016476567834615707}, {"id": 301, "seek": 167992, "start": 1699.92, "end": 1708.88, "text": " version that we had was RLHF purely for helpfulness. So it was very eager to please very eager to be", "tokens": [51364, 3037, 300, 321, 632, 390, 497, 43, 39, 37, 17491, 337, 4961, 1287, 13, 407, 309, 390, 588, 18259, 281, 1767, 588, 18259, 281, 312, 51812], "temperature": 0.0, "avg_logprob": -0.0949530029296875, "compression_ratio": 1.6355932203389831, "no_speech_prob": 0.0016476567834615707}, {"id": 302, "seek": 170888, "start": 1708.88, "end": 1716.0800000000002, "text": " nice to you, no guardrails on what you could ask it and what it would do, but 100% just trying to be", "tokens": [50364, 1481, 281, 291, 11, 572, 6290, 424, 4174, 322, 437, 291, 727, 1029, 309, 293, 437, 309, 576, 360, 11, 457, 2319, 4, 445, 1382, 281, 312, 50724], "temperature": 0.0, "avg_logprob": -0.10515024428977106, "compression_ratio": 1.6700680272108843, "no_speech_prob": 0.006486629135906696}, {"id": 303, "seek": 170888, "start": 1716.0800000000002, "end": 1720.8000000000002, "text": " helpful and pleasing to the user. So when it detected that kind of, I'm kind of bristling at", "tokens": [50724, 4961, 293, 32798, 281, 264, 4195, 13, 407, 562, 309, 21896, 300, 733, 295, 11, 286, 478, 733, 295, 738, 37174, 412, 50960], "temperature": 0.0, "avg_logprob": -0.10515024428977106, "compression_ratio": 1.6700680272108843, "no_speech_prob": 0.006486629135906696}, {"id": 304, "seek": 170888, "start": 1720.8000000000002, "end": 1725.7600000000002, "text": " what you just said, that's what it reacted with this, you know, I'm so sorry, I'm just trying to", "tokens": [50960, 437, 291, 445, 848, 11, 300, 311, 437, 309, 34037, 365, 341, 11, 291, 458, 11, 286, 478, 370, 2597, 11, 286, 478, 445, 1382, 281, 51208], "temperature": 0.0, "avg_logprob": -0.10515024428977106, "compression_ratio": 1.6700680272108843, "no_speech_prob": 0.006486629135906696}, {"id": 305, "seek": 170888, "start": 1725.7600000000002, "end": 1731.5200000000002, "text": " help kind of thing. And that was a mind blowing moment. I had not seen, of course, anything remotely", "tokens": [51208, 854, 733, 295, 551, 13, 400, 300, 390, 257, 1575, 15068, 1623, 13, 286, 632, 406, 1612, 11, 295, 1164, 11, 1340, 20824, 51496], "temperature": 0.0, "avg_logprob": -0.10515024428977106, "compression_ratio": 1.6700680272108843, "no_speech_prob": 0.006486629135906696}, {"id": 306, "seek": 170888, "start": 1731.5200000000002, "end": 1737.92, "text": " like that from earlier models, right? At the time, Text DaVinci 002 was the best publicly available", "tokens": [51496, 411, 300, 490, 3071, 5245, 11, 558, 30, 1711, 264, 565, 11, 18643, 3933, 53, 21961, 7143, 17, 390, 264, 1151, 14843, 2435, 51816], "temperature": 0.0, "avg_logprob": -0.10515024428977106, "compression_ratio": 1.6700680272108843, "no_speech_prob": 0.006486629135906696}, {"id": 307, "seek": 173792, "start": 1737.92, "end": 1744.96, "text": " model. And it would like follow instructions on basic stuff. But I mean, this was a totally", "tokens": [50364, 2316, 13, 400, 309, 576, 411, 1524, 9415, 322, 3875, 1507, 13, 583, 286, 914, 11, 341, 390, 257, 3879, 50716], "temperature": 0.0, "avg_logprob": -0.09099811265448562, "compression_ratio": 1.5742574257425743, "no_speech_prob": 0.006691237911581993}, {"id": 308, "seek": 173792, "start": 1744.96, "end": 1749.6000000000001, "text": " different world that we had suddenly stepped into. Hey, we'll continue our interview in a moment", "tokens": [50716, 819, 1002, 300, 321, 632, 5800, 15251, 666, 13, 1911, 11, 321, 603, 2354, 527, 4049, 294, 257, 1623, 50948], "temperature": 0.0, "avg_logprob": -0.09099811265448562, "compression_ratio": 1.5742574257425743, "no_speech_prob": 0.006691237911581993}, {"id": 309, "seek": 173792, "start": 1749.6000000000001, "end": 1753.6000000000001, "text": " after a word from our sponsors. If you're a startup founder or executive running a growing", "tokens": [50948, 934, 257, 1349, 490, 527, 22593, 13, 759, 291, 434, 257, 18578, 14917, 420, 10140, 2614, 257, 4194, 51148], "temperature": 0.0, "avg_logprob": -0.09099811265448562, "compression_ratio": 1.5742574257425743, "no_speech_prob": 0.006691237911581993}, {"id": 310, "seek": 173792, "start": 1753.6000000000001, "end": 1758.96, "text": " business, you know that as you scale your systems break down, and the cracks start to show. If this", "tokens": [51148, 1606, 11, 291, 458, 300, 382, 291, 4373, 428, 3652, 1821, 760, 11, 293, 264, 21770, 722, 281, 855, 13, 759, 341, 51416], "temperature": 0.0, "avg_logprob": -0.09099811265448562, "compression_ratio": 1.5742574257425743, "no_speech_prob": 0.006691237911581993}, {"id": 311, "seek": 173792, "start": 1758.96, "end": 1765.8400000000001, "text": " resonates with you, there are three numbers you need to know. 36,000, 25, and one. 36,000. That's", "tokens": [51416, 41051, 365, 291, 11, 456, 366, 1045, 3547, 291, 643, 281, 458, 13, 8652, 11, 1360, 11, 3552, 11, 293, 472, 13, 8652, 11, 1360, 13, 663, 311, 51760], "temperature": 0.0, "avg_logprob": -0.09099811265448562, "compression_ratio": 1.5742574257425743, "no_speech_prob": 0.006691237911581993}, {"id": 312, "seek": 176584, "start": 1765.84, "end": 1769.52, "text": " the number of businesses which have upgraded to NetSuite by Oracle. NetSuite is the number one", "tokens": [50364, 264, 1230, 295, 6011, 597, 362, 24133, 281, 6188, 50, 21681, 538, 25654, 13, 6188, 50, 21681, 307, 264, 1230, 472, 50548], "temperature": 0.0, "avg_logprob": -0.08791329967441844, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.009411842562258244}, {"id": 313, "seek": 176584, "start": 1769.52, "end": 1774.1599999999999, "text": " cloud financial system, streamlined accounting, financial management, inventory, HR, and more.", "tokens": [50548, 4588, 4669, 1185, 11, 48155, 19163, 11, 4669, 4592, 11, 14228, 11, 19460, 11, 293, 544, 13, 50780], "temperature": 0.0, "avg_logprob": -0.08791329967441844, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.009411842562258244}, {"id": 314, "seek": 176584, "start": 1774.72, "end": 1780.24, "text": " 25. NetSuite turns 25 this year. That's 25 years of helping businesses do more with less,", "tokens": [50808, 3552, 13, 6188, 50, 21681, 4523, 3552, 341, 1064, 13, 663, 311, 3552, 924, 295, 4315, 6011, 360, 544, 365, 1570, 11, 51084], "temperature": 0.0, "avg_logprob": -0.08791329967441844, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.009411842562258244}, {"id": 315, "seek": 176584, "start": 1780.24, "end": 1785.28, "text": " close their books in days, not weeks, and drive down costs. One, because your business is one", "tokens": [51084, 1998, 641, 3642, 294, 1708, 11, 406, 3259, 11, 293, 3332, 760, 5497, 13, 1485, 11, 570, 428, 1606, 307, 472, 51336], "temperature": 0.0, "avg_logprob": -0.08791329967441844, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.009411842562258244}, {"id": 316, "seek": 176584, "start": 1785.28, "end": 1790.0, "text": " of a kind, so you get a customized solution for all your KPIs in one efficient system with one", "tokens": [51336, 295, 257, 733, 11, 370, 291, 483, 257, 30581, 3827, 337, 439, 428, 41371, 6802, 294, 472, 7148, 1185, 365, 472, 51572], "temperature": 0.0, "avg_logprob": -0.08791329967441844, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.009411842562258244}, {"id": 317, "seek": 176584, "start": 1790.0, "end": 1794.8, "text": " source of truth. Manage risk, get reliable forecasts, and improve margins. Everything you", "tokens": [51572, 4009, 295, 3494, 13, 2458, 609, 3148, 11, 483, 12924, 49421, 11, 293, 3470, 30317, 13, 5471, 291, 51812], "temperature": 0.0, "avg_logprob": -0.08791329967441844, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.009411842562258244}, {"id": 318, "seek": 179480, "start": 1794.8, "end": 1800.72, "text": " need all in one place. Right now, download NetSuite's popular KPI checklist, designed to give you", "tokens": [50364, 643, 439, 294, 472, 1081, 13, 1779, 586, 11, 5484, 6188, 50, 21681, 311, 3743, 591, 31701, 30357, 11, 4761, 281, 976, 291, 50660], "temperature": 0.0, "avg_logprob": -0.11975538521482233, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.014061717316508293}, {"id": 319, "seek": 179480, "start": 1800.72, "end": 1805.76, "text": " consistently excellent performance, absolutely free, and netsuite.com slash cognitive. That's", "tokens": [50660, 14961, 7103, 3389, 11, 3122, 1737, 11, 293, 2533, 33136, 13, 1112, 17330, 15605, 13, 663, 311, 50912], "temperature": 0.0, "avg_logprob": -0.11975538521482233, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.014061717316508293}, {"id": 320, "seek": 179480, "start": 1805.76, "end": 1811.28, "text": " netsuite.com slash cognitive to get your own KPI checklist. NetSuite.com slash cognitive.", "tokens": [50912, 2533, 33136, 13, 1112, 17330, 15605, 281, 483, 428, 1065, 591, 31701, 30357, 13, 6188, 50, 21681, 13, 1112, 17330, 15605, 13, 51188], "temperature": 0.0, "avg_logprob": -0.11975538521482233, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.014061717316508293}, {"id": 321, "seek": 179480, "start": 1812.56, "end": 1818.08, "text": " Omnike uses generative AI to enable you to launch hundreds of thousands of ad iterations that", "tokens": [51252, 9757, 77, 1123, 4960, 1337, 1166, 7318, 281, 9528, 291, 281, 4025, 6779, 295, 5383, 295, 614, 36540, 300, 51528], "temperature": 0.0, "avg_logprob": -0.11975538521482233, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.014061717316508293}, {"id": 322, "seek": 179480, "start": 1818.08, "end": 1823.76, "text": " actually work, customized across all platforms with a click of a button. I believe in Omnike so", "tokens": [51528, 767, 589, 11, 30581, 2108, 439, 9473, 365, 257, 2052, 295, 257, 2960, 13, 286, 1697, 294, 9757, 77, 1123, 370, 51812], "temperature": 0.0, "avg_logprob": -0.11975538521482233, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.014061717316508293}, {"id": 323, "seek": 182376, "start": 1823.76, "end": 1830.24, "text": " much that I invested in it, and I recommend you use it too. Use CogGrav to get a 10% discount.", "tokens": [50364, 709, 300, 286, 13104, 294, 309, 11, 293, 286, 2748, 291, 764, 309, 886, 13, 8278, 383, 664, 38, 13404, 281, 483, 257, 1266, 4, 11635, 13, 50688], "temperature": 0.0, "avg_logprob": -0.13214780345107568, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0019248269964009523}, {"id": 324, "seek": 182376, "start": 1830.24, "end": 1836.4, "text": " I mean, it is such a different world. I was using chat GPT for something a few days ago,", "tokens": [50688, 286, 914, 11, 309, 307, 1270, 257, 819, 1002, 13, 286, 390, 1228, 5081, 26039, 51, 337, 746, 257, 1326, 1708, 2057, 11, 50996], "temperature": 0.0, "avg_logprob": -0.13214780345107568, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0019248269964009523}, {"id": 325, "seek": 182376, "start": 1836.4, "end": 1842.08, "text": " and I got quite tired as you do. I mean, I think about it as the time I once was playing tennis", "tokens": [50996, 293, 286, 658, 1596, 5868, 382, 291, 360, 13, 286, 914, 11, 286, 519, 466, 309, 382, 264, 565, 286, 1564, 390, 2433, 18118, 51280], "temperature": 0.0, "avg_logprob": -0.13214780345107568, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0019248269964009523}, {"id": 326, "seek": 182376, "start": 1842.08, "end": 1846.64, "text": " against one of those tennis ball-serving machines, and I was exhausted, and the machine is just like", "tokens": [51280, 1970, 472, 295, 729, 18118, 2594, 12, 12484, 798, 8379, 11, 293, 286, 390, 17992, 11, 293, 264, 3479, 307, 445, 411, 51508], "temperature": 0.0, "avg_logprob": -0.13214780345107568, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0019248269964009523}, {"id": 327, "seek": 182376, "start": 1846.64, "end": 1852.64, "text": " willing to keep firing balls at me. And it's a bit like that using these chatbots. And I just", "tokens": [51508, 4950, 281, 1066, 16045, 9803, 412, 385, 13, 400, 309, 311, 257, 857, 411, 300, 1228, 613, 5081, 65, 1971, 13, 400, 286, 445, 51808], "temperature": 0.0, "avg_logprob": -0.13214780345107568, "compression_ratio": 1.6631578947368422, "no_speech_prob": 0.0019248269964009523}, {"id": 328, "seek": 185264, "start": 1852.72, "end": 1856.72, "text": " left this kind of whimsical comment. I said, you know what? I'm really tired. I will come back", "tokens": [50368, 1411, 341, 733, 295, 315, 49945, 2871, 13, 286, 848, 11, 291, 458, 437, 30, 286, 478, 534, 5868, 13, 286, 486, 808, 646, 50568], "temperature": 0.0, "avg_logprob": -0.0995353495033042, "compression_ratio": 1.5564516129032258, "no_speech_prob": 0.004488245118409395}, {"id": 329, "seek": 185264, "start": 1856.72, "end": 1861.68, "text": " tomorrow and we can look at the moisture evaporators. We were not doing anything to do with Star Wars,", "tokens": [50568, 4153, 293, 321, 393, 574, 412, 264, 13814, 26315, 3391, 13, 492, 645, 406, 884, 1340, 281, 360, 365, 5705, 9818, 11, 50816], "temperature": 0.0, "avg_logprob": -0.0995353495033042, "compression_ratio": 1.5564516129032258, "no_speech_prob": 0.004488245118409395}, {"id": 330, "seek": 185264, "start": 1861.68, "end": 1869.0400000000002, "text": " right? We were doing some digging about coal in England in the 17th century. And it just replied", "tokens": [50816, 558, 30, 492, 645, 884, 512, 17343, 466, 10209, 294, 8196, 294, 264, 3282, 392, 4901, 13, 400, 309, 445, 20345, 51184], "temperature": 0.0, "avg_logprob": -0.0995353495033042, "compression_ratio": 1.5564516129032258, "no_speech_prob": 0.004488245118409395}, {"id": 331, "seek": 185264, "start": 1869.0400000000002, "end": 1875.2800000000002, "text": " to me going, I'll be happy to, you go and rest up, and tomorrow I can help you on the farm.", "tokens": [51184, 281, 385, 516, 11, 286, 603, 312, 2055, 281, 11, 291, 352, 293, 1472, 493, 11, 293, 4153, 286, 393, 854, 291, 322, 264, 5421, 13, 51496], "temperature": 0.0, "avg_logprob": -0.0995353495033042, "compression_ratio": 1.5564516129032258, "no_speech_prob": 0.004488245118409395}, {"id": 332, "seek": 187528, "start": 1875.28, "end": 1883.04, "text": " May the force be with you. And it had just very subtly played that back to me in a really,", "tokens": [50364, 1891, 264, 3464, 312, 365, 291, 13, 400, 309, 632, 445, 588, 7257, 356, 3737, 300, 646, 281, 385, 294, 257, 534, 11, 50752], "temperature": 0.0, "avg_logprob": -0.09460434000542824, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.4237319827079773}, {"id": 333, "seek": 187528, "start": 1883.04, "end": 1888.72, "text": " really nice way. And actually, in terms of humanized interfaces, as someone who's used Apple's", "tokens": [50752, 534, 1481, 636, 13, 400, 767, 11, 294, 2115, 295, 1952, 1602, 28416, 11, 382, 1580, 567, 311, 1143, 6373, 311, 51036], "temperature": 0.0, "avg_logprob": -0.09460434000542824, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.4237319827079773}, {"id": 334, "seek": 187528, "start": 1888.72, "end": 1896.0, "text": " computers for 40 years, it really sits alongside the trend that a firm like Apple had been thinking", "tokens": [51036, 10807, 337, 3356, 924, 11, 309, 534, 12696, 12385, 264, 6028, 300, 257, 6174, 411, 6373, 632, 668, 1953, 51400], "temperature": 0.0, "avg_logprob": -0.09460434000542824, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.4237319827079773}, {"id": 335, "seek": 187528, "start": 1896.0, "end": 1902.08, "text": " about for a really long time, which is how do we make this technology come to us rather than us", "tokens": [51400, 466, 337, 257, 534, 938, 565, 11, 597, 307, 577, 360, 321, 652, 341, 2899, 808, 281, 505, 2831, 813, 505, 51704], "temperature": 0.0, "avg_logprob": -0.09460434000542824, "compression_ratio": 1.5743801652892562, "no_speech_prob": 0.4237319827079773}, {"id": 336, "seek": 190208, "start": 1902.08, "end": 1906.72, "text": " go to the technology? You know, there has been this view that we'll have these central humans,", "tokens": [50364, 352, 281, 264, 2899, 30, 509, 458, 11, 456, 575, 668, 341, 1910, 300, 321, 603, 362, 613, 5777, 6255, 11, 50596], "temperature": 0.0, "avg_logprob": -0.13446881590771073, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.027904901653528214}, {"id": 337, "seek": 190208, "start": 1906.72, "end": 1912.24, "text": " right? Human plus machine. And one of the things that we learned about centaurs, and that idea", "tokens": [50596, 558, 30, 10294, 1804, 3479, 13, 400, 472, 295, 264, 721, 300, 321, 3264, 466, 1489, 64, 2156, 11, 293, 300, 1558, 50872], "temperature": 0.0, "avg_logprob": -0.13446881590771073, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.027904901653528214}, {"id": 338, "seek": 190208, "start": 1912.24, "end": 1918.96, "text": " came out with chess, right? After Kasparov lost to Deep Blue back in, in 97, was that for several", "tokens": [50872, 1361, 484, 365, 24122, 11, 558, 30, 2381, 28059, 2181, 5179, 2731, 281, 14895, 8510, 646, 294, 11, 294, 23399, 11, 390, 300, 337, 2940, 51208], "temperature": 0.0, "avg_logprob": -0.13446881590771073, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.027904901653528214}, {"id": 339, "seek": 190208, "start": 1918.96, "end": 1923.76, "text": " years humans and the machine would outperform machines on their own, and of course humans.", "tokens": [51208, 924, 6255, 293, 264, 3479, 576, 484, 26765, 8379, 322, 641, 1065, 11, 293, 295, 1164, 6255, 13, 51448], "temperature": 0.0, "avg_logprob": -0.13446881590771073, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.027904901653528214}, {"id": 340, "seek": 190208, "start": 1924.3999999999999, "end": 1928.8, "text": " But now you're just better off with a chess computer. And as a human, you should just accept", "tokens": [51480, 583, 586, 291, 434, 445, 1101, 766, 365, 257, 24122, 3820, 13, 400, 382, 257, 1952, 11, 291, 820, 445, 3241, 51700], "temperature": 0.0, "avg_logprob": -0.13446881590771073, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.027904901653528214}, {"id": 341, "seek": 192880, "start": 1928.8, "end": 1933.68, "text": " everything it says. So the central period in chess only lasted seven or eight years.", "tokens": [50364, 1203, 309, 1619, 13, 407, 264, 5777, 2896, 294, 24122, 787, 21116, 3407, 420, 3180, 924, 13, 50608], "temperature": 0.0, "avg_logprob": -0.07891955292015745, "compression_ratio": 1.6920289855072463, "no_speech_prob": 0.007037609815597534}, {"id": 342, "seek": 192880, "start": 1933.68, "end": 1938.48, "text": " And I think one of the assumptions that goes into this kind of maelstrom of ideas we have to make", "tokens": [50608, 400, 286, 519, 472, 295, 264, 17695, 300, 1709, 666, 341, 733, 295, 463, 338, 38673, 295, 3487, 321, 362, 281, 652, 50848], "temperature": 0.0, "avg_logprob": -0.07891955292015745, "compression_ratio": 1.6920289855072463, "no_speech_prob": 0.007037609815597534}, {"id": 343, "seek": 192880, "start": 1938.48, "end": 1946.1599999999999, "text": " sense of over the next years, is that central humans will exist for quite a bit of time. In", "tokens": [50848, 2020, 295, 670, 264, 958, 924, 11, 307, 300, 5777, 6255, 486, 2514, 337, 1596, 257, 857, 295, 565, 13, 682, 51232], "temperature": 0.0, "avg_logprob": -0.07891955292015745, "compression_ratio": 1.6920289855072463, "no_speech_prob": 0.007037609815597534}, {"id": 344, "seek": 192880, "start": 1946.1599999999999, "end": 1951.76, "text": " other words, human plus machine will do better than machine on its own. But we are starting to see", "tokens": [51232, 661, 2283, 11, 1952, 1804, 3479, 486, 360, 1101, 813, 3479, 322, 1080, 1065, 13, 583, 321, 366, 2891, 281, 536, 51512], "temperature": 0.0, "avg_logprob": -0.07891955292015745, "compression_ratio": 1.6920289855072463, "no_speech_prob": 0.007037609815597534}, {"id": 345, "seek": 192880, "start": 1951.76, "end": 1957.52, "text": " signs at that period of time is already starting to come to an end, right? Far faster than we", "tokens": [51512, 7880, 412, 300, 2896, 295, 565, 307, 1217, 2891, 281, 808, 281, 364, 917, 11, 558, 30, 9067, 4663, 813, 321, 51800], "temperature": 0.0, "avg_logprob": -0.07891955292015745, "compression_ratio": 1.6920289855072463, "no_speech_prob": 0.007037609815597534}, {"id": 346, "seek": 195752, "start": 1957.52, "end": 1962.08, "text": " might have predicted. And you've just given an example, which is a, you know, an unreleased AI model", "tokens": [50364, 1062, 362, 19147, 13, 400, 291, 600, 445, 2212, 364, 1365, 11, 597, 307, 257, 11, 291, 458, 11, 364, 20584, 41087, 7318, 2316, 50592], "temperature": 0.0, "avg_logprob": -0.09236383852751359, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0016477672616019845}, {"id": 347, "seek": 195752, "start": 1962.6399999999999, "end": 1967.12, "text": " where the AI on its own is doing better than the expert, expert human with the AI.", "tokens": [50620, 689, 264, 7318, 322, 1080, 1065, 307, 884, 1101, 813, 264, 5844, 11, 5844, 1952, 365, 264, 7318, 13, 50844], "temperature": 0.0, "avg_logprob": -0.09236383852751359, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0016477672616019845}, {"id": 348, "seek": 195752, "start": 1967.12, "end": 1972.96, "text": " Yeah, it's pretty crazy. I think people are broadly in denial about that possibility even,", "tokens": [50844, 865, 11, 309, 311, 1238, 3219, 13, 286, 519, 561, 366, 19511, 294, 28754, 466, 300, 7959, 754, 11, 51136], "temperature": 0.0, "avg_logprob": -0.09236383852751359, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0016477672616019845}, {"id": 349, "seek": 195752, "start": 1972.96, "end": 1978.24, "text": " you know, and let alone the reality, it's funny that we things are happening so quickly that", "tokens": [51136, 291, 458, 11, 293, 718, 3312, 264, 4103, 11, 309, 311, 4074, 300, 321, 721, 366, 2737, 370, 2661, 300, 51400], "temperature": 0.0, "avg_logprob": -0.09236383852751359, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0016477672616019845}, {"id": 350, "seek": 195752, "start": 1978.24, "end": 1983.2, "text": " people are saying things, you know, are impossible or won't happen for at least 10 years that are", "tokens": [51400, 561, 366, 1566, 721, 11, 291, 458, 11, 366, 6243, 420, 1582, 380, 1051, 337, 412, 1935, 1266, 924, 300, 366, 51648], "temperature": 0.0, "avg_logprob": -0.09236383852751359, "compression_ratio": 1.7158671586715868, "no_speech_prob": 0.0016477672616019845}, {"id": 351, "seek": 198320, "start": 1983.2, "end": 1988.0800000000002, "text": " literally already happening. And so I think, you know, to some degree, there's just kind of a lack", "tokens": [50364, 3736, 1217, 2737, 13, 400, 370, 286, 519, 11, 291, 458, 11, 281, 512, 4314, 11, 456, 311, 445, 733, 295, 257, 5011, 50608], "temperature": 0.0, "avg_logprob": -0.0932181852835196, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.04601569473743439}, {"id": 352, "seek": 198320, "start": 1988.0800000000002, "end": 1992.72, "text": " of awareness. And there's also definitely some psychological, and I try not to psychologize", "tokens": [50608, 295, 8888, 13, 400, 456, 311, 611, 2138, 512, 14346, 11, 293, 286, 853, 406, 281, 4681, 1132, 1125, 50840], "temperature": 0.0, "avg_logprob": -0.0932181852835196, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.04601569473743439}, {"id": 353, "seek": 198320, "start": 1992.72, "end": 1998.48, "text": " people's AI positions too much, because I think the technology itself is confusing enough. But", "tokens": [50840, 561, 311, 7318, 8432, 886, 709, 11, 570, 286, 519, 264, 2899, 2564, 307, 13181, 1547, 13, 583, 51128], "temperature": 0.0, "avg_logprob": -0.0932181852835196, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.04601569473743439}, {"id": 354, "seek": 198320, "start": 1998.48, "end": 2003.92, "text": " it certainly seems like there's some kind of psychological cope or denial happening there.", "tokens": [51128, 309, 3297, 2544, 411, 456, 311, 512, 733, 295, 14346, 22598, 420, 28754, 2737, 456, 13, 51400], "temperature": 0.0, "avg_logprob": -0.0932181852835196, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.04601569473743439}, {"id": 355, "seek": 198320, "start": 2003.92, "end": 2010.48, "text": " I also do think it's important to keep in mind too that the setting really matters and the world", "tokens": [51400, 286, 611, 360, 519, 309, 311, 1021, 281, 1066, 294, 1575, 886, 300, 264, 3287, 534, 7001, 293, 264, 1002, 51728], "temperature": 0.0, "avg_logprob": -0.0932181852835196, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.04601569473743439}, {"id": 356, "seek": 201048, "start": 2010.48, "end": 2014.72, "text": " is going to change as well. And humans may still have a really important role to play", "tokens": [50364, 307, 516, 281, 1319, 382, 731, 13, 400, 6255, 815, 920, 362, 257, 534, 1021, 3090, 281, 862, 50576], "temperature": 0.0, "avg_logprob": -0.1119088888168335, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.02757471427321434}, {"id": 357, "seek": 201048, "start": 2015.28, "end": 2021.76, "text": " in a lot of systems for a while yet. I think we do have the AIs do have really important", "tokens": [50604, 294, 257, 688, 295, 3652, 337, 257, 1339, 1939, 13, 286, 519, 321, 360, 362, 264, 316, 6802, 360, 362, 534, 1021, 50928], "temperature": 0.0, "avg_logprob": -0.1119088888168335, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.02757471427321434}, {"id": 358, "seek": 201048, "start": 2021.76, "end": 2027.52, "text": " weaknesses. So you do do a study like this Google evaluation. And I think that they, you know, are", "tokens": [50928, 24381, 13, 407, 291, 360, 360, 257, 2979, 411, 341, 3329, 13344, 13, 400, 286, 519, 300, 436, 11, 291, 458, 11, 366, 51216], "temperature": 0.0, "avg_logprob": -0.1119088888168335, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.02757471427321434}, {"id": 359, "seek": 201048, "start": 2027.52, "end": 2033.28, "text": " very serious people who've set this up in a way that I trust is, you know, not not cooking the", "tokens": [51216, 588, 3156, 561, 567, 600, 992, 341, 493, 294, 257, 636, 300, 286, 3361, 307, 11, 291, 458, 11, 406, 406, 6361, 264, 51504], "temperature": 0.0, "avg_logprob": -0.1119088888168335, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.02757471427321434}, {"id": 360, "seek": 201048, "start": 2033.28, "end": 2038.4, "text": " books in favor of the AI. So I take that result, you know, basically, at face value.", "tokens": [51504, 3642, 294, 2294, 295, 264, 7318, 13, 407, 286, 747, 300, 1874, 11, 291, 458, 11, 1936, 11, 412, 1851, 2158, 13, 51760], "temperature": 0.0, "avg_logprob": -0.1119088888168335, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.02757471427321434}, {"id": 361, "seek": 203840, "start": 2039.2, "end": 2046.16, "text": " But then I also think like the AIs have these strange vulnerabilities that, you know, for example,", "tokens": [50404, 583, 550, 286, 611, 519, 411, 264, 316, 6802, 362, 613, 5861, 37633, 300, 11, 291, 458, 11, 337, 1365, 11, 50752], "temperature": 0.0, "avg_logprob": -0.12364935105846774, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0016483771614730358}, {"id": 362, "seek": 203840, "start": 2046.16, "end": 2052.8, "text": " the AlphaGo system, right, that is superhuman go player. But I have an episode coming up with", "tokens": [50752, 264, 20588, 12104, 1185, 11, 558, 11, 300, 307, 1687, 18796, 352, 4256, 13, 583, 286, 362, 364, 3500, 1348, 493, 365, 51084], "temperature": 0.0, "avg_logprob": -0.12364935105846774, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0016483771614730358}, {"id": 363, "seek": 203840, "start": 2053.76, "end": 2061.28, "text": " Adam Gleave from far AI, and they put out a method that showed how a relatively simple", "tokens": [51132, 7938, 460, 306, 946, 490, 1400, 7318, 11, 293, 436, 829, 484, 257, 3170, 300, 4712, 577, 257, 7226, 2199, 51508], "temperature": 0.0, "avg_logprob": -0.12364935105846774, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0016483771614730358}, {"id": 364, "seek": 203840, "start": 2061.28, "end": 2066.96, "text": " adversarial attack on the AlphaGo system could beat it. And no human would lose to this like", "tokens": [51508, 17641, 44745, 2690, 322, 264, 20588, 12104, 1185, 727, 4224, 309, 13, 400, 572, 1952, 576, 3624, 281, 341, 411, 51792], "temperature": 0.0, "avg_logprob": -0.12364935105846774, "compression_ratio": 1.603448275862069, "no_speech_prob": 0.0016483771614730358}, {"id": 365, "seek": 206696, "start": 2066.96, "end": 2073.04, "text": " simple adversarial attack. But the AI had this like massive blind spot that they were able to", "tokens": [50364, 2199, 17641, 44745, 2690, 13, 583, 264, 7318, 632, 341, 411, 5994, 6865, 4008, 300, 436, 645, 1075, 281, 50668], "temperature": 0.0, "avg_logprob": -0.08053826491038005, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0014102241257205606}, {"id": 366, "seek": 206696, "start": 2073.04, "end": 2080.48, "text": " engineer against and exploit. So I do think we're headed for strange dynamics and the sort of naive,", "tokens": [50668, 11403, 1970, 293, 25924, 13, 407, 286, 360, 519, 321, 434, 12798, 337, 5861, 15679, 293, 264, 1333, 295, 29052, 11, 51040], "temperature": 0.0, "avg_logprob": -0.08053826491038005, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0014102241257205606}, {"id": 367, "seek": 206696, "start": 2080.48, "end": 2083.76, "text": " I don't mean to say that Google thing is naive, but it's kind of, you know, let's take", "tokens": [51040, 286, 500, 380, 914, 281, 584, 300, 3329, 551, 307, 29052, 11, 457, 309, 311, 733, 295, 11, 291, 458, 11, 718, 311, 747, 51204], "temperature": 0.0, "avg_logprob": -0.08053826491038005, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0014102241257205606}, {"id": 368, "seek": 206696, "start": 2084.32, "end": 2089.12, "text": " controlled conditions and set it up in a certain way and see what happens. I do think it's really", "tokens": [51232, 10164, 4487, 293, 992, 309, 493, 294, 257, 1629, 636, 293, 536, 437, 2314, 13, 286, 360, 519, 309, 311, 534, 51472], "temperature": 0.0, "avg_logprob": -0.08053826491038005, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0014102241257205606}, {"id": 369, "seek": 206696, "start": 2089.12, "end": 2092.64, "text": " important to keep in mind that, you know, just like these AI systems in general, when they get out of", "tokens": [51472, 1021, 281, 1066, 294, 1575, 300, 11, 291, 458, 11, 445, 411, 613, 7318, 3652, 294, 2674, 11, 562, 436, 483, 484, 295, 51648], "temperature": 0.0, "avg_logprob": -0.08053826491038005, "compression_ratio": 1.6701388888888888, "no_speech_prob": 0.0014102241257205606}, {"id": 370, "seek": 209264, "start": 2092.64, "end": 2098.4, "text": " domain, they have problems, like those results may also not extrapolate, at least initially,", "tokens": [50364, 9274, 11, 436, 362, 2740, 11, 411, 729, 3542, 815, 611, 406, 48224, 473, 11, 412, 1935, 9105, 11, 50652], "temperature": 0.0, "avg_logprob": -0.08147969245910644, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.042079001665115356}, {"id": 371, "seek": 209264, "start": 2098.4, "end": 2103.68, "text": " to situations where people are trying to break the AI, you know, I wouldn't, for anything where", "tokens": [50652, 281, 6851, 689, 561, 366, 1382, 281, 1821, 264, 7318, 11, 291, 458, 11, 286, 2759, 380, 11, 337, 1340, 689, 50916], "temperature": 0.0, "avg_logprob": -0.08147969245910644, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.042079001665115356}, {"id": 372, "seek": 209264, "start": 2103.68, "end": 2110.08, "text": " there's an adversarial incentive out there, I would not, I would not be quick to take a result", "tokens": [50916, 456, 311, 364, 17641, 44745, 22346, 484, 456, 11, 286, 576, 406, 11, 286, 576, 406, 312, 1702, 281, 747, 257, 1874, 51236], "temperature": 0.0, "avg_logprob": -0.08147969245910644, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.042079001665115356}, {"id": 373, "seek": 209264, "start": 2110.08, "end": 2114.48, "text": " like that and be like, okay, cool, you know, we can just deploy the AI on its own. Now in medicine,", "tokens": [51236, 411, 300, 293, 312, 411, 11, 1392, 11, 1627, 11, 291, 458, 11, 321, 393, 445, 7274, 264, 7318, 322, 1080, 1065, 13, 823, 294, 7195, 11, 51456], "temperature": 0.0, "avg_logprob": -0.08147969245910644, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.042079001665115356}, {"id": 374, "seek": 209264, "start": 2114.48, "end": 2118.24, "text": " presumably, there's not a lot of adversarial situation, right, because people want to get", "tokens": [51456, 26742, 11, 456, 311, 406, 257, 688, 295, 17641, 44745, 2590, 11, 558, 11, 570, 561, 528, 281, 483, 51644], "temperature": 0.0, "avg_logprob": -0.08147969245910644, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.042079001665115356}, {"id": 375, "seek": 211824, "start": 2118.24, "end": 2123.3599999999997, "text": " the right diagnosis and like nobody wants them to get the wrong diagnosis. So, you know, I do think", "tokens": [50364, 264, 558, 15217, 293, 411, 5079, 2738, 552, 281, 483, 264, 2085, 15217, 13, 407, 11, 291, 458, 11, 286, 360, 519, 50620], "temperature": 0.0, "avg_logprob": -0.08516871342893506, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.005900890100747347}, {"id": 376, "seek": 211824, "start": 2123.3599999999997, "end": 2129.2799999999997, "text": " the AI doctor is kind of here before we know it. And, you know, we're going to have some very", "tokens": [50620, 264, 7318, 4631, 307, 733, 295, 510, 949, 321, 458, 309, 13, 400, 11, 291, 458, 11, 321, 434, 516, 281, 362, 512, 588, 50916], "temperature": 0.0, "avg_logprob": -0.08516871342893506, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.005900890100747347}, {"id": 377, "seek": 211824, "start": 2129.2799999999997, "end": 2134.9599999999996, "text": " interesting questions about what to do about that. But I think the thing that you've also identified", "tokens": [50916, 1880, 1651, 466, 437, 281, 360, 466, 300, 13, 583, 286, 519, 264, 551, 300, 291, 600, 611, 9234, 51200], "temperature": 0.0, "avg_logprob": -0.08516871342893506, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.005900890100747347}, {"id": 378, "seek": 211824, "start": 2134.9599999999996, "end": 2140.3199999999997, "text": " is that these systems have to get into companies, have to get into hospitals, have to get into the", "tokens": [51200, 307, 300, 613, 3652, 362, 281, 483, 666, 3431, 11, 362, 281, 483, 666, 13014, 11, 362, 281, 483, 666, 264, 51468], "temperature": 0.0, "avg_logprob": -0.08516871342893506, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.005900890100747347}, {"id": 379, "seek": 211824, "start": 2140.3199999999997, "end": 2146.7999999999997, "text": " economy. And that's still, that still takes time, right? It still takes time for, let's not look", "tokens": [51468, 5010, 13, 400, 300, 311, 920, 11, 300, 920, 2516, 565, 11, 558, 30, 467, 920, 2516, 565, 337, 11, 718, 311, 406, 574, 51792], "temperature": 0.0, "avg_logprob": -0.08516871342893506, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.005900890100747347}, {"id": 380, "seek": 214680, "start": 2146.8, "end": 2151.2000000000003, "text": " at medicine, because it would have to be go through all sorts of clearances through the FDA and so on", "tokens": [50364, 412, 7195, 11, 570, 309, 576, 362, 281, 312, 352, 807, 439, 7527, 295, 1850, 2676, 807, 264, 18933, 293, 370, 322, 50584], "temperature": 0.0, "avg_logprob": -0.0804258684317271, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.003315112553536892}, {"id": 381, "seek": 214680, "start": 2151.2000000000003, "end": 2160.4, "text": " before it could be used. But every time we've seen amazing technologies emerge, the cloud computing,", "tokens": [50584, 949, 309, 727, 312, 1143, 13, 583, 633, 565, 321, 600, 1612, 2243, 7943, 21511, 11, 264, 4588, 15866, 11, 51044], "temperature": 0.0, "avg_logprob": -0.0804258684317271, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.003315112553536892}, {"id": 382, "seek": 214680, "start": 2160.4, "end": 2165.52, "text": " right, GPT uptake is higher than cloud computing, even though it's 19 years younger. But every time", "tokens": [51044, 558, 11, 26039, 51, 493, 27612, 307, 2946, 813, 4588, 15866, 11, 754, 1673, 309, 311, 1294, 924, 7037, 13, 583, 633, 565, 51300], "temperature": 0.0, "avg_logprob": -0.0804258684317271, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.003315112553536892}, {"id": 383, "seek": 214680, "start": 2165.52, "end": 2172.96, "text": " these technologies come out, they take a while to make a make it into businesses. I mean, even", "tokens": [51300, 613, 7943, 808, 484, 11, 436, 747, 257, 1339, 281, 652, 257, 652, 309, 666, 6011, 13, 286, 914, 11, 754, 51672], "temperature": 0.0, "avg_logprob": -0.0804258684317271, "compression_ratio": 1.640495867768595, "no_speech_prob": 0.003315112553536892}, {"id": 384, "seek": 217296, "start": 2172.96, "end": 2178.0, "text": " something as straightforward as the typewriter. So a typewriter took about 20 to 25 years from", "tokens": [50364, 746, 382, 15325, 382, 264, 2010, 23681, 13, 407, 257, 2010, 23681, 1890, 466, 945, 281, 3552, 924, 490, 50616], "temperature": 0.0, "avg_logprob": -0.09505493824298565, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.015581310726702213}, {"id": 385, "seek": 217296, "start": 2178.0, "end": 2183.12, "text": " becoming a kind of affordable technology to being something that businesses have figured out how to", "tokens": [50616, 5617, 257, 733, 295, 12028, 2899, 281, 885, 746, 300, 6011, 362, 8932, 484, 577, 281, 50872], "temperature": 0.0, "avg_logprob": -0.09505493824298565, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.015581310726702213}, {"id": 386, "seek": 217296, "start": 2183.12, "end": 2188.32, "text": " use and how to change their, their processes, something like electricity took a little bit longer", "tokens": [50872, 764, 293, 577, 281, 1319, 641, 11, 641, 7555, 11, 746, 411, 10356, 1890, 257, 707, 857, 2854, 51132], "temperature": 0.0, "avg_logprob": -0.09505493824298565, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.015581310726702213}, {"id": 387, "seek": 217296, "start": 2188.32, "end": 2193.04, "text": " because, you know, the way that factories used what used power that before electricity was like a", "tokens": [51132, 570, 11, 291, 458, 11, 264, 636, 300, 24813, 1143, 437, 1143, 1347, 300, 949, 10356, 390, 411, 257, 51368], "temperature": 0.0, "avg_logprob": -0.09505493824298565, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.015581310726702213}, {"id": 388, "seek": 217296, "start": 2193.04, "end": 2199.68, "text": " single big drive shaft and a massive lump of power that came from it. And then your electricity is", "tokens": [51368, 2167, 955, 3332, 18467, 293, 257, 5994, 25551, 295, 1347, 300, 1361, 490, 309, 13, 400, 550, 428, 10356, 307, 51700], "temperature": 0.0, "avg_logprob": -0.09505493824298565, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.015581310726702213}, {"id": 389, "seek": 219968, "start": 2199.68, "end": 2204.56, "text": " this highly distributed, packetized movement of energy that you can put in different places,", "tokens": [50364, 341, 5405, 12631, 11, 20300, 1602, 3963, 295, 2281, 300, 291, 393, 829, 294, 819, 3190, 11, 50608], "temperature": 0.0, "avg_logprob": -0.13294529385036893, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.014647950418293476}, {"id": 390, "seek": 219968, "start": 2204.56, "end": 2210.7999999999997, "text": " you need an entirely different setup for it. And so, so even when we look at something like this,", "tokens": [50608, 291, 643, 364, 7696, 819, 8657, 337, 309, 13, 400, 370, 11, 370, 754, 562, 321, 574, 412, 746, 411, 341, 11, 50920], "temperature": 0.0, "avg_logprob": -0.13294529385036893, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.014647950418293476}, {"id": 391, "seek": 219968, "start": 2210.7999999999997, "end": 2219.52, "text": " the question is, how quickly are we able to bring it in? And over what time frame does it then start", "tokens": [50920, 264, 1168, 307, 11, 577, 2661, 366, 321, 1075, 281, 1565, 309, 294, 30, 400, 670, 437, 565, 3920, 775, 309, 550, 722, 51356], "temperature": 0.0, "avg_logprob": -0.13294529385036893, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.014647950418293476}, {"id": 392, "seek": 219968, "start": 2219.52, "end": 2226.16, "text": " to change our, the practitioners relationship with the technology? I mean, we know from automation", "tokens": [51356, 281, 1319, 527, 11, 264, 25742, 2480, 365, 264, 2899, 30, 286, 914, 11, 321, 458, 490, 17769, 51688], "temperature": 0.0, "avg_logprob": -0.13294529385036893, "compression_ratio": 1.598360655737705, "no_speech_prob": 0.014647950418293476}, {"id": 393, "seek": 222616, "start": 2226.16, "end": 2232.96, "text": " of, of aircraft and other automated systems that you go through this three phase process as somebody", "tokens": [50364, 295, 11, 295, 9465, 293, 661, 18473, 3652, 300, 291, 352, 807, 341, 1045, 5574, 1399, 382, 2618, 50704], "temperature": 0.0, "avg_logprob": -0.10785337773765005, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.007185753434896469}, {"id": 394, "seek": 222616, "start": 2232.96, "end": 2239.8399999999997, "text": " who's using the technology. Phase one, you kind of don't trust it, and you, you then see if it", "tokens": [50704, 567, 311, 1228, 264, 2899, 13, 24432, 472, 11, 291, 733, 295, 500, 380, 3361, 309, 11, 293, 291, 11, 291, 550, 536, 498, 309, 51048], "temperature": 0.0, "avg_logprob": -0.10785337773765005, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.007185753434896469}, {"id": 395, "seek": 222616, "start": 2239.8399999999997, "end": 2246.3199999999997, "text": " does well where you're the ground truth. Phase two, you start to assume it's a ground truth,", "tokens": [51048, 775, 731, 689, 291, 434, 264, 2727, 3494, 13, 24432, 732, 11, 291, 722, 281, 6552, 309, 311, 257, 2727, 3494, 11, 51372], "temperature": 0.0, "avg_logprob": -0.10785337773765005, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.007185753434896469}, {"id": 396, "seek": 222616, "start": 2246.3199999999997, "end": 2250.24, "text": " and then you, you pack yourself on the back when you come up with the same answer that the machine", "tokens": [51372, 293, 550, 291, 11, 291, 2844, 1803, 322, 264, 646, 562, 291, 808, 493, 365, 264, 912, 1867, 300, 264, 3479, 51568], "temperature": 0.0, "avg_logprob": -0.10785337773765005, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.007185753434896469}, {"id": 397, "seek": 222616, "start": 2250.24, "end": 2255.68, "text": " comes up with. And then phase three, which is where we've got to on GPS, where we just trust ways,", "tokens": [51568, 1487, 493, 365, 13, 400, 550, 5574, 1045, 11, 597, 307, 689, 321, 600, 658, 281, 322, 19462, 11, 689, 321, 445, 3361, 2098, 11, 51840], "temperature": 0.0, "avg_logprob": -0.10785337773765005, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.007185753434896469}, {"id": 398, "seek": 225568, "start": 2255.68, "end": 2259.6, "text": " and it's like, actually, you know, we generally trust ways, some London taxi drivers don't,", "tokens": [50364, 293, 309, 311, 411, 11, 767, 11, 291, 458, 11, 321, 5101, 3361, 2098, 11, 512, 7042, 18984, 11590, 500, 380, 11, 50560], "temperature": 0.0, "avg_logprob": -0.10347477456797724, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0006556519656442106}, {"id": 399, "seek": 225568, "start": 2259.6, "end": 2265.2799999999997, "text": " we just trust it. And you see that process happening replicated in other types of automation,", "tokens": [50560, 321, 445, 3361, 309, 13, 400, 291, 536, 300, 1399, 2737, 46365, 294, 661, 3467, 295, 17769, 11, 50844], "temperature": 0.0, "avg_logprob": -0.10347477456797724, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0006556519656442106}, {"id": 400, "seek": 225568, "start": 2265.2799999999997, "end": 2270.8799999999997, "text": " which is why when it's really mission critical, you have incredibly high levels of training,", "tokens": [50844, 597, 307, 983, 562, 309, 311, 534, 4447, 4924, 11, 291, 362, 6252, 1090, 4358, 295, 3097, 11, 51124], "temperature": 0.0, "avg_logprob": -0.10347477456797724, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0006556519656442106}, {"id": 401, "seek": 225568, "start": 2270.8799999999997, "end": 2275.44, "text": " and you have other types of safeties in place, like, you know, two humans in the cockpit,", "tokens": [51124, 293, 291, 362, 661, 3467, 295, 3597, 43469, 294, 1081, 11, 411, 11, 291, 458, 11, 732, 6255, 294, 264, 35990, 11, 51352], "temperature": 0.0, "avg_logprob": -0.10347477456797724, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0006556519656442106}, {"id": 402, "seek": 225568, "start": 2275.44, "end": 2281.2, "text": " or, you know, whatever, whatever it happens to be. And, and so that part of the journey,", "tokens": [51352, 420, 11, 291, 458, 11, 2035, 11, 2035, 309, 2314, 281, 312, 13, 400, 11, 293, 370, 300, 644, 295, 264, 4671, 11, 51640], "temperature": 0.0, "avg_logprob": -0.10347477456797724, "compression_ratio": 1.7442748091603053, "no_speech_prob": 0.0006556519656442106}, {"id": 403, "seek": 228120, "start": 2281.2, "end": 2287.9199999999996, "text": " I think is also one that adds a little bit of drag in terms of how long it takes to have an", "tokens": [50364, 286, 519, 307, 611, 472, 300, 10860, 257, 707, 857, 295, 5286, 294, 2115, 295, 577, 938, 309, 2516, 281, 362, 364, 50700], "temperature": 0.0, "avg_logprob": -0.10027430487460777, "compression_ratio": 1.6310344827586207, "no_speech_prob": 0.00871714111417532}, {"id": 404, "seek": 228120, "start": 2287.9199999999996, "end": 2292.48, "text": " impact. And in that time, Nathan, we start to understand new questions, questions that we", "tokens": [50700, 2712, 13, 400, 294, 300, 565, 11, 20634, 11, 321, 722, 281, 1223, 777, 1651, 11, 1651, 300, 321, 50928], "temperature": 0.0, "avg_logprob": -0.10027430487460777, "compression_ratio": 1.6310344827586207, "no_speech_prob": 0.00871714111417532}, {"id": 405, "seek": 228120, "start": 2292.48, "end": 2297.6, "text": " can't imagine right now, because they're just too far down the decision tree. So sometimes I think,", "tokens": [50928, 393, 380, 3811, 558, 586, 11, 570, 436, 434, 445, 886, 1400, 760, 264, 3537, 4230, 13, 407, 2171, 286, 519, 11, 51184], "temperature": 0.0, "avg_logprob": -0.10027430487460777, "compression_ratio": 1.6310344827586207, "no_speech_prob": 0.00871714111417532}, {"id": 406, "seek": 228120, "start": 2297.6, "end": 2302.96, "text": " I hear people say, well, there'll be that moment, I think Tim Urban has this, from Wait But Why,", "tokens": [51184, 286, 1568, 561, 584, 11, 731, 11, 456, 603, 312, 300, 1623, 11, 286, 519, 7172, 24885, 575, 341, 11, 490, 3802, 583, 1545, 11, 51452], "temperature": 0.0, "avg_logprob": -0.10027430487460777, "compression_ratio": 1.6310344827586207, "no_speech_prob": 0.00871714111417532}, {"id": 407, "seek": 228120, "start": 2302.96, "end": 2308.72, "text": " has this graph where he sort of shows the moment where AI is like as clever as a rat, and then", "tokens": [51452, 575, 341, 4295, 689, 415, 1333, 295, 3110, 264, 1623, 689, 7318, 307, 411, 382, 13494, 382, 257, 5937, 11, 293, 550, 51740], "temperature": 0.0, "avg_logprob": -0.10027430487460777, "compression_ratio": 1.6310344827586207, "no_speech_prob": 0.00871714111417532}, {"id": 408, "seek": 230872, "start": 2308.72, "end": 2313.7599999999998, "text": " like a second later, it's 10 times cleverer than us. I think part of the, the reality of", "tokens": [50364, 411, 257, 1150, 1780, 11, 309, 311, 1266, 1413, 13494, 260, 813, 505, 13, 286, 519, 644, 295, 264, 11, 264, 4103, 295, 50616], "temperature": 0.0, "avg_logprob": -0.08157005148418879, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0024234368465840816}, {"id": 409, "seek": 230872, "start": 2313.7599999999998, "end": 2318.3199999999997, "text": " like the rubber hitting the road is going to be that even as these products do very,", "tokens": [50616, 411, 264, 11593, 8850, 264, 3060, 307, 516, 281, 312, 300, 754, 382, 613, 3383, 360, 588, 11, 50844], "temperature": 0.0, "avg_logprob": -0.08157005148418879, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0024234368465840816}, {"id": 410, "seek": 230872, "start": 2318.3199999999997, "end": 2323.6, "text": " very well in the lab situation, it just takes a little bit of time for them to get into,", "tokens": [50844, 588, 731, 294, 264, 2715, 2590, 11, 309, 445, 2516, 257, 707, 857, 295, 565, 337, 552, 281, 483, 666, 11, 51108], "temperature": 0.0, "avg_logprob": -0.08157005148418879, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0024234368465840816}, {"id": 411, "seek": 230872, "start": 2323.6, "end": 2330.56, "text": " into the real world. Now, where it may happen is, I think in, in a couple of places. So one is", "tokens": [51108, 666, 264, 957, 1002, 13, 823, 11, 689, 309, 815, 1051, 307, 11, 286, 519, 294, 11, 294, 257, 1916, 295, 3190, 13, 407, 472, 307, 51456], "temperature": 0.0, "avg_logprob": -0.08157005148418879, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0024234368465840816}, {"id": 412, "seek": 230872, "start": 2331.3599999999997, "end": 2337.52, "text": " where tasks have already been discretized so that they're essentially just written down. And I", "tokens": [51496, 689, 9608, 362, 1217, 668, 25656, 1602, 370, 300, 436, 434, 4476, 445, 3720, 760, 13, 400, 286, 51804], "temperature": 0.0, "avg_logprob": -0.08157005148418879, "compression_ratio": 1.6317689530685922, "no_speech_prob": 0.0024234368465840816}, {"id": 413, "seek": 233752, "start": 2337.52, "end": 2342.64, "text": " think that that is certain types of call centers and it's certain types of data entry. And in those", "tokens": [50364, 519, 300, 300, 307, 1629, 3467, 295, 818, 10898, 293, 309, 311, 1629, 3467, 295, 1412, 8729, 13, 400, 294, 729, 50620], "temperature": 0.0, "avg_logprob": -0.10419789950052898, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0004203297139611095}, {"id": 414, "seek": 233752, "start": 2342.64, "end": 2350.32, "text": " places, the human is already hired on a task by task basis normally mediated by like a, a, a, a", "tokens": [50620, 3190, 11, 264, 1952, 307, 1217, 13144, 322, 257, 5633, 538, 5633, 5143, 5646, 17269, 770, 538, 411, 257, 11, 257, 11, 257, 11, 257, 51004], "temperature": 0.0, "avg_logprob": -0.10419789950052898, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0004203297139611095}, {"id": 415, "seek": 233752, "start": 2350.32, "end": 2355.36, "text": " body shop. So the buyer of the services, which is like our favorite consumer electronics company or", "tokens": [51004, 1772, 3945, 13, 407, 264, 24645, 295, 264, 3328, 11, 597, 307, 411, 527, 2954, 9711, 20611, 2237, 420, 51256], "temperature": 0.0, "avg_logprob": -0.10419789950052898, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0004203297139611095}, {"id": 416, "seek": 233752, "start": 2355.36, "end": 2361.04, "text": " your insurance company has no emotional relationship, they just have a KPI that they measure to. And I", "tokens": [51256, 428, 7214, 2237, 575, 572, 6863, 2480, 11, 436, 445, 362, 257, 591, 31701, 300, 436, 3481, 281, 13, 400, 286, 51540], "temperature": 0.0, "avg_logprob": -0.10419789950052898, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.0004203297139611095}, {"id": 417, "seek": 236104, "start": 2361.04, "end": 2367.68, "text": " think that lends itself unfortunately to a, a tidal wave risk for those types of roles. I think", "tokens": [50364, 519, 300, 287, 2581, 2564, 7015, 281, 257, 11, 257, 9422, 304, 5772, 3148, 337, 729, 3467, 295, 9604, 13, 286, 519, 50696], "temperature": 0.0, "avg_logprob": -0.11357795948884924, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.007383171934634447}, {"id": 418, "seek": 236104, "start": 2367.68, "end": 2375.92, "text": " the, the second area is, you know, classic Silicon Valley stuff where a De Novo company is, I should", "tokens": [50696, 264, 11, 264, 1150, 1859, 307, 11, 291, 458, 11, 7230, 25351, 10666, 1507, 689, 257, 1346, 883, 3080, 2237, 307, 11, 286, 820, 51108], "temperature": 0.0, "avg_logprob": -0.11357795948884924, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.007383171934634447}, {"id": 419, "seek": 236104, "start": 2375.92, "end": 2381.84, "text": " say Silicon Valley, a classic Detroit stuff where a De Novo company is able to apply these technologies", "tokens": [51108, 584, 25351, 10666, 11, 257, 7230, 20887, 1507, 689, 257, 1346, 883, 3080, 2237, 307, 1075, 281, 3079, 613, 7943, 51404], "temperature": 0.0, "avg_logprob": -0.11357795948884924, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.007383171934634447}, {"id": 420, "seek": 236104, "start": 2381.84, "end": 2386.64, "text": " the way Henry Ford did and build his processes from scratch, right? In the way that the artisanal", "tokens": [51404, 264, 636, 11085, 11961, 630, 293, 1322, 702, 7555, 490, 8459, 11, 558, 30, 682, 264, 636, 300, 264, 1523, 14804, 304, 51644], "temperature": 0.0, "avg_logprob": -0.11357795948884924, "compression_ratio": 1.6514522821576763, "no_speech_prob": 0.007383171934634447}, {"id": 421, "seek": 238664, "start": 2386.64, "end": 2391.92, "text": " car makers were just going to have so much kind of cultural drag, they couldn't. And that's what we", "tokens": [50364, 1032, 19323, 645, 445, 516, 281, 362, 370, 709, 733, 295, 6988, 5286, 11, 436, 2809, 380, 13, 400, 300, 311, 437, 321, 50628], "temperature": 0.0, "avg_logprob": -0.08120221358079177, "compression_ratio": 1.7614035087719297, "no_speech_prob": 0.09829723089933395}, {"id": 422, "seek": 238664, "start": 2391.92, "end": 2396.56, "text": " certainly saw with a lot of the, you know, the internet, right? It was, it was absolutely startups", "tokens": [50628, 3297, 1866, 365, 257, 688, 295, 264, 11, 291, 458, 11, 264, 4705, 11, 558, 30, 467, 390, 11, 309, 390, 3122, 28041, 50860], "temperature": 0.0, "avg_logprob": -0.08120221358079177, "compression_ratio": 1.7614035087719297, "no_speech_prob": 0.09829723089933395}, {"id": 423, "seek": 238664, "start": 2396.56, "end": 2402.4, "text": " that captured the value. And then when you started to get to two areas that were more highly regulated", "tokens": [50860, 300, 11828, 264, 2158, 13, 400, 550, 562, 291, 1409, 281, 483, 281, 732, 3179, 300, 645, 544, 5405, 26243, 51152], "temperature": 0.0, "avg_logprob": -0.08120221358079177, "compression_ratio": 1.7614035087719297, "no_speech_prob": 0.09829723089933395}, {"id": 424, "seek": 238664, "start": 2402.4, "end": 2408.48, "text": " and had, you know, a lot more stickiness to them, like, like finance, with the exception of certain", "tokens": [51152, 293, 632, 11, 291, 458, 11, 257, 688, 544, 2897, 1324, 281, 552, 11, 411, 11, 411, 10719, 11, 365, 264, 11183, 295, 1629, 51456], "temperature": 0.0, "avg_logprob": -0.08120221358079177, "compression_ratio": 1.7614035087719297, "no_speech_prob": 0.09829723089933395}, {"id": 425, "seek": 238664, "start": 2408.48, "end": 2413.7599999999998, "text": " areas of payments, it's still the bank, big banks, sort of the big banks. And, and, and I don't know", "tokens": [51456, 3179, 295, 14348, 11, 309, 311, 920, 264, 3765, 11, 955, 10237, 11, 1333, 295, 264, 955, 10237, 13, 400, 11, 293, 11, 293, 286, 500, 380, 458, 51720], "temperature": 0.0, "avg_logprob": -0.08120221358079177, "compression_ratio": 1.7614035087719297, "no_speech_prob": 0.09829723089933395}, {"id": 426, "seek": 241376, "start": 2413.76, "end": 2421.36, "text": " how differently this actually plays out short of scenarios where someone is able to use these", "tokens": [50364, 577, 7614, 341, 767, 5749, 484, 2099, 295, 15077, 689, 1580, 307, 1075, 281, 764, 613, 50744], "temperature": 0.0, "avg_logprob": -0.09490705996143575, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0018657577456906438}, {"id": 427, "seek": 241376, "start": 2421.36, "end": 2426.4, "text": " super powerful machines to kind of manipulate the rules of the game, which I, you know, I think is a,", "tokens": [50744, 1687, 4005, 8379, 281, 733, 295, 20459, 264, 4474, 295, 264, 1216, 11, 597, 286, 11, 291, 458, 11, 286, 519, 307, 257, 11, 50996], "temperature": 0.0, "avg_logprob": -0.09490705996143575, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0018657577456906438}, {"id": 428, "seek": 241376, "start": 2426.96, "end": 2431.6000000000004, "text": " like that's more like a black swan scenario than one that we could, you know, talk about reasonably.", "tokens": [51024, 411, 300, 311, 544, 411, 257, 2211, 1693, 282, 9005, 813, 472, 300, 321, 727, 11, 291, 458, 11, 751, 466, 23551, 13, 51256], "temperature": 0.0, "avg_logprob": -0.09490705996143575, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0018657577456906438}, {"id": 429, "seek": 241376, "start": 2432.4, "end": 2437.0400000000004, "text": " Well, first of all, as an aside, if you ever make it to Detroit, I'll take you to the Henry", "tokens": [51296, 1042, 11, 700, 295, 439, 11, 382, 364, 7359, 11, 498, 291, 1562, 652, 309, 281, 20887, 11, 286, 603, 747, 291, 281, 264, 11085, 51528], "temperature": 0.0, "avg_logprob": -0.09490705996143575, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0018657577456906438}, {"id": 430, "seek": 243704, "start": 2437.04, "end": 2444.8, "text": " Ford Museum and Living History Museum, which is called Greenfield Village, where this, this", "tokens": [50364, 11961, 10967, 293, 18824, 12486, 10967, 11, 597, 307, 1219, 6969, 7610, 22651, 11, 689, 341, 11, 341, 50752], "temperature": 0.0, "avg_logprob": -0.08555486467149523, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.15199165046215057}, {"id": 431, "seek": 243704, "start": 2444.8, "end": 2450.48, "text": " earlier transition is documented with actual machinery still running from the, you know,", "tokens": [50752, 3071, 6034, 307, 23007, 365, 3539, 27302, 920, 2614, 490, 264, 11, 291, 458, 11, 51036], "temperature": 0.0, "avg_logprob": -0.08555486467149523, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.15199165046215057}, {"id": 432, "seek": 243704, "start": 2450.48, "end": 2456.24, "text": " various phases, you can go see one of these old factories where actually a few of them where", "tokens": [51036, 3683, 18764, 11, 291, 393, 352, 536, 472, 295, 613, 1331, 24813, 689, 767, 257, 1326, 295, 552, 689, 51324], "temperature": 0.0, "avg_logprob": -0.08555486467149523, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.15199165046215057}, {"id": 433, "seek": 243704, "start": 2456.24, "end": 2460.96, "text": " they have kind of the central steam engine, and then it's powering this one, you know,", "tokens": [51324, 436, 362, 733, 295, 264, 5777, 11952, 2848, 11, 293, 550, 309, 311, 1347, 278, 341, 472, 11, 291, 458, 11, 51560], "temperature": 0.0, "avg_logprob": -0.08555486467149523, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.15199165046215057}, {"id": 434, "seek": 243704, "start": 2460.96, "end": 2466.32, "text": " driveshaft at the top of the floor. And then there's like 25 belts, you know, coming off of", "tokens": [51560, 11754, 25127, 412, 264, 1192, 295, 264, 4123, 13, 400, 550, 456, 311, 411, 3552, 33689, 11, 291, 458, 11, 1348, 766, 295, 51828], "temperature": 0.0, "avg_logprob": -0.08555486467149523, "compression_ratio": 1.6678966789667897, "no_speech_prob": 0.15199165046215057}, {"id": 435, "seek": 246632, "start": 2466.32, "end": 2471.2000000000003, "text": " that and connecting to other machines, all driven on this single thing. And then you,", "tokens": [50364, 300, 293, 11015, 281, 661, 8379, 11, 439, 9555, 322, 341, 2167, 551, 13, 400, 550, 291, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11994216021369486, "compression_ratio": 1.7164634146341464, "no_speech_prob": 0.0011332767317071557}, {"id": 436, "seek": 246632, "start": 2471.2000000000003, "end": 2475.92, "text": " they have an electrical, early electrical version of that as well. Edison's workshop is there. He", "tokens": [50608, 436, 362, 364, 12147, 11, 2440, 12147, 3037, 295, 300, 382, 731, 13, 47497, 311, 13541, 307, 456, 13, 634, 50844], "temperature": 0.0, "avg_logprob": -0.11994216021369486, "compression_ratio": 1.7164634146341464, "no_speech_prob": 0.0011332767317071557}, {"id": 437, "seek": 246632, "start": 2475.92, "end": 2480.8, "text": " actually, this is Henry Ford toward the end of his life was like, became very sort of nostalgic", "tokens": [50844, 767, 11, 341, 307, 11085, 11961, 7361, 264, 917, 295, 702, 993, 390, 411, 11, 3062, 588, 1333, 295, 40240, 51088], "temperature": 0.0, "avg_logprob": -0.11994216021369486, "compression_ratio": 1.7164634146341464, "no_speech_prob": 0.0011332767317071557}, {"id": 438, "seek": 246632, "start": 2480.8, "end": 2486.7200000000003, "text": " for an earlier period. And decided he wanted to kind of create this, you know, living history", "tokens": [51088, 337, 364, 3071, 2896, 13, 400, 3047, 415, 1415, 281, 733, 295, 1884, 341, 11, 291, 458, 11, 2647, 2503, 51384], "temperature": 0.0, "avg_logprob": -0.11994216021369486, "compression_ratio": 1.7164634146341464, "no_speech_prob": 0.0011332767317071557}, {"id": 439, "seek": 246632, "start": 2486.7200000000003, "end": 2491.36, "text": " place to sort of preserve that history so people can see it in the future. It's quite an awesome", "tokens": [51384, 1081, 281, 1333, 295, 15665, 300, 2503, 370, 561, 393, 536, 309, 294, 264, 2027, 13, 467, 311, 1596, 364, 3476, 51616], "temperature": 0.0, "avg_logprob": -0.11994216021369486, "compression_ratio": 1.7164634146341464, "no_speech_prob": 0.0011332767317071557}, {"id": 440, "seek": 246632, "start": 2491.36, "end": 2496.1600000000003, "text": " thing to go and contemplate. I'll have to do that. Because I think, I think Ford's influence", "tokens": [51616, 551, 281, 352, 293, 19935, 473, 13, 286, 603, 362, 281, 360, 300, 13, 1436, 286, 519, 11, 286, 519, 11961, 311, 6503, 51856], "temperature": 0.0, "avg_logprob": -0.11994216021369486, "compression_ratio": 1.7164634146341464, "no_speech_prob": 0.0011332767317071557}, {"id": 441, "seek": 249616, "start": 2496.16, "end": 2502.64, "text": " and impact is somehow underrated. We don't talk about Ford as much as we may talk, maybe talk", "tokens": [50364, 293, 2712, 307, 6063, 833, 5468, 13, 492, 500, 380, 751, 466, 11961, 382, 709, 382, 321, 815, 751, 11, 1310, 751, 50688], "temperature": 0.0, "avg_logprob": -0.11520957102817772, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0007869426044635475}, {"id": 442, "seek": 249616, "start": 2502.64, "end": 2508.8799999999997, "text": " about Edison, when we think historically. And, you know, there was so much in Ford, he understood", "tokens": [50688, 466, 47497, 11, 562, 321, 519, 16180, 13, 400, 11, 291, 458, 11, 456, 390, 370, 709, 294, 11961, 11, 415, 7320, 51000], "temperature": 0.0, "avg_logprob": -0.11520957102817772, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0007869426044635475}, {"id": 443, "seek": 249616, "start": 2508.8799999999997, "end": 2515.12, "text": " the, the socio economic contract that emerged from these, from these changes in like, in a", "tokens": [51000, 264, 11, 264, 44303, 4836, 4364, 300, 20178, 490, 613, 11, 490, 613, 2962, 294, 411, 11, 294, 257, 51312], "temperature": 0.0, "avg_logprob": -0.11520957102817772, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0007869426044635475}, {"id": 444, "seek": 249616, "start": 2515.12, "end": 2519.2799999999997, "text": " number of different ways. I mean, not always in ways that are, you know, kind of positive. We", "tokens": [51312, 1230, 295, 819, 2098, 13, 286, 914, 11, 406, 1009, 294, 2098, 300, 366, 11, 291, 458, 11, 733, 295, 3353, 13, 492, 51520], "temperature": 0.0, "avg_logprob": -0.11520957102817772, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0007869426044635475}, {"id": 445, "seek": 249616, "start": 2519.2799999999997, "end": 2525.68, "text": " know where the sort of sociological department started trying to ensure temperance amongst", "tokens": [51520, 458, 689, 264, 1333, 295, 3075, 4383, 5882, 1409, 1382, 281, 5586, 3393, 719, 12918, 51840], "temperature": 0.0, "avg_logprob": -0.11520957102817772, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0007869426044635475}, {"id": 446, "seek": 252568, "start": 2525.68, "end": 2532.3199999999997, "text": " workers and, and so on. And it gets encapsulated in, in Aldous Huxley's book, Brave New World,", "tokens": [50364, 5600, 293, 11, 293, 370, 322, 13, 400, 309, 2170, 38745, 6987, 294, 11, 294, 24031, 563, 389, 2449, 3420, 311, 1446, 11, 38545, 1873, 3937, 11, 50696], "temperature": 0.0, "avg_logprob": -0.12680218837879323, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.0010809162631630898}, {"id": 447, "seek": 252568, "start": 2532.3199999999997, "end": 2536.8799999999997, "text": " which I still find to be a really, really remarkable piece of writing, you know, it was", "tokens": [50696, 597, 286, 920, 915, 281, 312, 257, 534, 11, 534, 12802, 2522, 295, 3579, 11, 291, 458, 11, 309, 390, 50924], "temperature": 0.0, "avg_logprob": -0.12680218837879323, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.0010809162631630898}, {"id": 448, "seek": 252568, "start": 2536.8799999999997, "end": 2546.24, "text": " written in the 1930s, 1932, I think. And for Huxley to encapsulate and extend a raw Fordism,", "tokens": [50924, 3720, 294, 264, 22350, 82, 11, 1294, 11440, 11, 286, 519, 13, 400, 337, 389, 2449, 3420, 281, 38745, 5256, 293, 10101, 257, 8936, 11961, 1434, 11, 51392], "temperature": 0.0, "avg_logprob": -0.12680218837879323, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.0010809162631630898}, {"id": 449, "seek": 252568, "start": 2546.24, "end": 2551.44, "text": " as far out as he did, it's a little bit like Kurt's file and what he did with his singularity", "tokens": [51392, 382, 1400, 484, 382, 415, 630, 11, 309, 311, 257, 707, 857, 411, 26168, 311, 3991, 293, 437, 415, 630, 365, 702, 20010, 507, 51652], "temperature": 0.0, "avg_logprob": -0.12680218837879323, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.0010809162631630898}, {"id": 450, "seek": 255144, "start": 2551.44, "end": 2556.7200000000003, "text": " work, I thought was absolutely genius. And I think that that, that book, which Brave New World,", "tokens": [50364, 589, 11, 286, 1194, 390, 3122, 14017, 13, 400, 286, 519, 300, 300, 11, 300, 1446, 11, 597, 38545, 1873, 3937, 11, 50628], "temperature": 0.0, "avg_logprob": -0.0937612287459835, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.036133889108896255}, {"id": 451, "seek": 255144, "start": 2556.7200000000003, "end": 2566.64, "text": " which rests on the ideas that, that Ford developed, catalyzed, that spawn off his, his work speaks", "tokens": [50628, 597, 39755, 322, 264, 3487, 300, 11, 300, 11961, 4743, 11, 3857, 5222, 11312, 11, 300, 17088, 766, 702, 11, 702, 589, 10789, 51124], "temperature": 0.0, "avg_logprob": -0.0937612287459835, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.036133889108896255}, {"id": 452, "seek": 255144, "start": 2567.36, "end": 2571.68, "text": " very, really quite clearly to a number of the issues that we face now in this kind of later", "tokens": [51160, 588, 11, 534, 1596, 4448, 281, 257, 1230, 295, 264, 2663, 300, 321, 1851, 586, 294, 341, 733, 295, 1780, 51376], "temperature": 0.0, "avg_logprob": -0.0937612287459835, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.036133889108896255}, {"id": 453, "seek": 255144, "start": 2571.68, "end": 2575.84, "text": " stages of industrial capitalism. And I mean, so a trip to Detroit, I will take you up on and I'll", "tokens": [51376, 10232, 295, 9987, 19704, 13, 400, 286, 914, 11, 370, 257, 4931, 281, 20887, 11, 286, 486, 747, 291, 493, 322, 293, 286, 603, 51584], "temperature": 0.0, "avg_logprob": -0.0937612287459835, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.036133889108896255}, {"id": 454, "seek": 255144, "start": 2575.84, "end": 2579.28, "text": " bring you a copy of Brave New World as well. It's been a long time since I've read that,", "tokens": [51584, 1565, 291, 257, 5055, 295, 38545, 1873, 3937, 382, 731, 13, 467, 311, 668, 257, 938, 565, 1670, 286, 600, 1401, 300, 11, 51756], "temperature": 0.0, "avg_logprob": -0.0937612287459835, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.036133889108896255}, {"id": 455, "seek": 257928, "start": 2579.28, "end": 2584.6400000000003, "text": " actually going back to high school. So I might need to dust that one off and I'm sure it will", "tokens": [50364, 767, 516, 646, 281, 1090, 1395, 13, 407, 286, 1062, 643, 281, 8634, 300, 472, 766, 293, 286, 478, 988, 309, 486, 50632], "temperature": 0.0, "avg_logprob": -0.09851467863042304, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.012818981893360615}, {"id": 456, "seek": 257928, "start": 2584.6400000000003, "end": 2589.44, "text": " resonate very differently today than it did for me then. So, okay, I have a number of questions on", "tokens": [50632, 34285, 588, 7614, 965, 813, 309, 630, 337, 385, 550, 13, 407, 11, 1392, 11, 286, 362, 257, 1230, 295, 1651, 322, 50872], "temperature": 0.0, "avg_logprob": -0.09851467863042304, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.012818981893360615}, {"id": 457, "seek": 257928, "start": 2590.0800000000004, "end": 2595.28, "text": " this kind of concept of transition. I think I would, from what I heard, I think we're probably", "tokens": [50904, 341, 733, 295, 3410, 295, 6034, 13, 286, 519, 286, 576, 11, 490, 437, 286, 2198, 11, 286, 519, 321, 434, 1391, 51164], "temperature": 0.0, "avg_logprob": -0.09851467863042304, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.012818981893360615}, {"id": 458, "seek": 257928, "start": 2595.28, "end": 2603.6800000000003, "text": " largely on the same page that it seems like incumbents, the big banks and big technology", "tokens": [51164, 11611, 322, 264, 912, 3028, 300, 309, 2544, 411, 39854, 791, 11, 264, 955, 10237, 293, 955, 2899, 51584], "temperature": 0.0, "avg_logprob": -0.09851467863042304, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.012818981893360615}, {"id": 459, "seek": 260368, "start": 2603.68, "end": 2611.44, "text": " companies, largely should be able to harness this technology and bring it to their platforms", "tokens": [50364, 3431, 11, 11611, 820, 312, 1075, 281, 19700, 341, 2899, 293, 1565, 309, 281, 641, 9473, 50752], "temperature": 0.0, "avg_logprob": -0.09162985651116622, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.22259043157100677}, {"id": 460, "seek": 260368, "start": 2611.44, "end": 2617.3599999999997, "text": " before they get displaced. I think of like Salesforce is almost a canonical example there.", "tokens": [50752, 949, 436, 483, 33692, 13, 286, 519, 295, 411, 40398, 307, 1920, 257, 46491, 1365, 456, 13, 51048], "temperature": 0.0, "avg_logprob": -0.09162985651116622, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.22259043157100677}, {"id": 461, "seek": 260368, "start": 2617.3599999999997, "end": 2622.08, "text": " They're going to have an AI layer that creates a much better and less complicated, less confusing", "tokens": [51048, 814, 434, 516, 281, 362, 364, 7318, 4583, 300, 7829, 257, 709, 1101, 293, 1570, 6179, 11, 1570, 13181, 51284], "temperature": 0.0, "avg_logprob": -0.09162985651116622, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.22259043157100677}, {"id": 462, "seek": 260368, "start": 2622.08, "end": 2627.8399999999997, "text": " user experience before somebody's going to recreate all the complexity of Salesforce.", "tokens": [51284, 4195, 1752, 949, 2618, 311, 516, 281, 25833, 439, 264, 14024, 295, 40398, 13, 51572], "temperature": 0.0, "avg_logprob": -0.09162985651116622, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.22259043157100677}, {"id": 463, "seek": 262784, "start": 2627.92, "end": 2634.8, "text": " On the other hand, there is no AI friend today. So that's kind of my canonical example of something", "tokens": [50368, 1282, 264, 661, 1011, 11, 456, 307, 572, 7318, 1277, 965, 13, 407, 300, 311, 733, 295, 452, 46491, 1365, 295, 746, 50712], "temperature": 0.0, "avg_logprob": -0.11169719696044922, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.019120994955301285}, {"id": 464, "seek": 262784, "start": 2634.8, "end": 2639.44, "text": " that's by definition going to be de novo. And then presumably there's like a ton of stuff in", "tokens": [50712, 300, 311, 538, 7123, 516, 281, 312, 368, 18246, 13, 400, 550, 26742, 456, 311, 411, 257, 2952, 295, 1507, 294, 50944], "temperature": 0.0, "avg_logprob": -0.11169719696044922, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.019120994955301285}, {"id": 465, "seek": 262784, "start": 2639.44, "end": 2644.0, "text": " between. And I gather that you're kind of talking to business leaders probably throughout that", "tokens": [50944, 1296, 13, 400, 286, 5448, 300, 291, 434, 733, 295, 1417, 281, 1606, 3523, 1391, 3710, 300, 51172], "temperature": 0.0, "avg_logprob": -0.11169719696044922, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.019120994955301285}, {"id": 466, "seek": 262784, "start": 2644.0, "end": 2649.52, "text": " spectrum. Where are they today? It seems like they're groping of what is going on and their", "tokens": [51172, 11143, 13, 2305, 366, 436, 965, 30, 467, 2544, 411, 436, 434, 290, 1513, 278, 295, 437, 307, 516, 322, 293, 641, 51448], "temperature": 0.0, "avg_logprob": -0.11169719696044922, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.019120994955301285}, {"id": 467, "seek": 262784, "start": 2649.52, "end": 2656.88, "text": " eagerness to transform the way their businesses operate might be the limiting factor in how", "tokens": [51448, 308, 559, 19416, 281, 4088, 264, 636, 641, 6011, 9651, 1062, 312, 264, 22083, 5952, 294, 577, 51816], "temperature": 0.0, "avg_logprob": -0.11169719696044922, "compression_ratio": 1.6821428571428572, "no_speech_prob": 0.019120994955301285}, {"id": 468, "seek": 265688, "start": 2656.96, "end": 2661.76, "text": " quickly this transition can proceed. Are you advising them to start to think about", "tokens": [50368, 2661, 341, 6034, 393, 8991, 13, 2014, 291, 35598, 552, 281, 722, 281, 519, 466, 50608], "temperature": 0.0, "avg_logprob": -0.08647740804232083, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.0025488489773124456}, {"id": 469, "seek": 265688, "start": 2662.6400000000003, "end": 2667.36, "text": " what kind of semi-structured work they can make a lot more structured so that they can", "tokens": [50652, 437, 733, 295, 12909, 12, 372, 46847, 589, 436, 393, 652, 257, 688, 544, 18519, 370, 300, 436, 393, 50888], "temperature": 0.0, "avg_logprob": -0.08647740804232083, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.0025488489773124456}, {"id": 470, "seek": 265688, "start": 2668.32, "end": 2674.0, "text": " reduce it to these kind of task level things that can be automated? And are they receptive to", "tokens": [50936, 5407, 309, 281, 613, 733, 295, 5633, 1496, 721, 300, 393, 312, 18473, 30, 400, 366, 436, 45838, 281, 51220], "temperature": 0.0, "avg_logprob": -0.08647740804232083, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.0025488489773124456}, {"id": 471, "seek": 265688, "start": 2674.0, "end": 2679.2000000000003, "text": " that sort of challenge and or opportunity? I mean, I can't remember a technology which has", "tokens": [51220, 300, 1333, 295, 3430, 293, 420, 2650, 30, 286, 914, 11, 286, 393, 380, 1604, 257, 2899, 597, 575, 51480], "temperature": 0.0, "avg_logprob": -0.08647740804232083, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.0025488489773124456}, {"id": 472, "seek": 265688, "start": 2679.2000000000003, "end": 2685.2000000000003, "text": " had the degree of uptake in large companies as this one. I think back to the internet,", "tokens": [51480, 632, 264, 4314, 295, 493, 27612, 294, 2416, 3431, 382, 341, 472, 13, 286, 519, 646, 281, 264, 4705, 11, 51780], "temperature": 0.0, "avg_logprob": -0.08647740804232083, "compression_ratio": 1.651685393258427, "no_speech_prob": 0.0025488489773124456}, {"id": 473, "seek": 268520, "start": 2685.2, "end": 2690.8799999999997, "text": " back in 1999, I was talking to the CEO of a big mobile phone company. And he said to me,", "tokens": [50364, 646, 294, 19952, 11, 286, 390, 1417, 281, 264, 9282, 295, 257, 955, 6013, 2593, 2237, 13, 400, 415, 848, 281, 385, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1078566312789917, "compression_ratio": 1.7361963190184049, "no_speech_prob": 0.007649645674973726}, {"id": 474, "seek": 268520, "start": 2690.8799999999997, "end": 2695.68, "text": " I will never let you pay your bill over the internet. In fact, I'll never ever let you look", "tokens": [50648, 286, 486, 1128, 718, 291, 1689, 428, 2961, 670, 264, 4705, 13, 682, 1186, 11, 286, 603, 1128, 1562, 718, 291, 574, 50888], "temperature": 0.0, "avg_logprob": -0.1078566312789917, "compression_ratio": 1.7361963190184049, "no_speech_prob": 0.007649645674973726}, {"id": 475, "seek": 268520, "start": 2695.68, "end": 2700.0, "text": " at your bill over the internet. And he was right because he was fired a year later. So he never,", "tokens": [50888, 412, 428, 2961, 670, 264, 4705, 13, 400, 415, 390, 558, 570, 415, 390, 11777, 257, 1064, 1780, 13, 407, 415, 1128, 11, 51104], "temperature": 0.0, "avg_logprob": -0.1078566312789917, "compression_ratio": 1.7361963190184049, "no_speech_prob": 0.007649645674973726}, {"id": 476, "seek": 268520, "start": 2700.0, "end": 2705.68, "text": " project was never delivered. But it's so different with not just AI, but specifically gen AI,", "tokens": [51104, 1716, 390, 1128, 10144, 13, 583, 309, 311, 370, 819, 365, 406, 445, 7318, 11, 457, 4682, 1049, 7318, 11, 51388], "temperature": 0.0, "avg_logprob": -0.1078566312789917, "compression_ratio": 1.7361963190184049, "no_speech_prob": 0.007649645674973726}, {"id": 477, "seek": 268520, "start": 2705.68, "end": 2709.8399999999997, "text": " because two things are happening. One is that the CEOs of the companies have been playing around", "tokens": [51388, 570, 732, 721, 366, 2737, 13, 1485, 307, 300, 264, 40736, 295, 264, 3431, 362, 668, 2433, 926, 51596], "temperature": 0.0, "avg_logprob": -0.1078566312789917, "compression_ratio": 1.7361963190184049, "no_speech_prob": 0.007649645674973726}, {"id": 478, "seek": 268520, "start": 2709.8399999999997, "end": 2713.68, "text": " with this partly because they're of that age now, they're in their mid 50s, they've grown up with", "tokens": [51596, 365, 341, 17031, 570, 436, 434, 295, 300, 3205, 586, 11, 436, 434, 294, 641, 2062, 2625, 82, 11, 436, 600, 7709, 493, 365, 51788], "temperature": 0.0, "avg_logprob": -0.1078566312789917, "compression_ratio": 1.7361963190184049, "no_speech_prob": 0.007649645674973726}, {"id": 479, "seek": 271368, "start": 2713.68, "end": 2718.96, "text": " computers, their kids are coming back with it from college. And the second thing that's happening", "tokens": [50364, 10807, 11, 641, 2301, 366, 1348, 646, 365, 309, 490, 3859, 13, 400, 264, 1150, 551, 300, 311, 2737, 50628], "temperature": 0.0, "avg_logprob": -0.08841493924458822, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.006868470460176468}, {"id": 480, "seek": 271368, "start": 2718.96, "end": 2725.8399999999997, "text": " is that the frontline workers are using this regardless of any restrictions by their employees.", "tokens": [50628, 307, 300, 264, 38033, 5600, 366, 1228, 341, 10060, 295, 604, 14191, 538, 641, 6619, 13, 50972], "temperature": 0.0, "avg_logprob": -0.08841493924458822, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.006868470460176468}, {"id": 481, "seek": 271368, "start": 2725.8399999999997, "end": 2731.2799999999997, "text": " And there have been a couple of surveys now, one done by your old alma mater Oliver Wyman,", "tokens": [50972, 400, 456, 362, 668, 257, 1916, 295, 22711, 586, 11, 472, 1096, 538, 428, 1331, 32634, 2389, 23440, 14458, 1601, 11, 51244], "temperature": 0.0, "avg_logprob": -0.08841493924458822, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.006868470460176468}, {"id": 482, "seek": 271368, "start": 2731.2799999999997, "end": 2740.8799999999997, "text": " which was of 25,000 employees across 18 countries. And in 83% of employees in the UAE in India,", "tokens": [51244, 597, 390, 295, 3552, 11, 1360, 6619, 2108, 2443, 3517, 13, 400, 294, 30997, 4, 295, 6619, 294, 264, 32765, 36, 294, 5282, 11, 51724], "temperature": 0.0, "avg_logprob": -0.08841493924458822, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.006868470460176468}, {"id": 483, "seek": 274088, "start": 2740.88, "end": 2745.36, "text": " already using a chat GPT or something similar. And we've seen data from Salesforce and others that", "tokens": [50364, 1217, 1228, 257, 5081, 26039, 51, 420, 746, 2531, 13, 400, 321, 600, 1612, 1412, 490, 40398, 293, 2357, 300, 50588], "temperature": 0.0, "avg_logprob": -0.10113030632070247, "compression_ratio": 1.730886850152905, "no_speech_prob": 0.027135469019412994}, {"id": 484, "seek": 274088, "start": 2745.36, "end": 2750.96, "text": " say in the US, it's like 30, 40, 50%, you know, choose your number, but it's not 2%. And it's", "tokens": [50588, 584, 294, 264, 2546, 11, 309, 311, 411, 2217, 11, 3356, 11, 2625, 8923, 291, 458, 11, 2826, 428, 1230, 11, 457, 309, 311, 406, 568, 6856, 400, 309, 311, 50868], "temperature": 0.0, "avg_logprob": -0.10113030632070247, "compression_ratio": 1.730886850152905, "no_speech_prob": 0.027135469019412994}, {"id": 485, "seek": 274088, "start": 2750.96, "end": 2755.84, "text": " very frontline. And I think of that as like a pincer movement, because normally, you got to", "tokens": [50868, 588, 38033, 13, 400, 286, 519, 295, 300, 382, 411, 257, 5447, 1776, 3963, 11, 570, 5646, 11, 291, 658, 281, 51112], "temperature": 0.0, "avg_logprob": -0.10113030632070247, "compression_ratio": 1.730886850152905, "no_speech_prob": 0.027135469019412994}, {"id": 486, "seek": 274088, "start": 2755.84, "end": 2760.7200000000003, "text": " drag the frontline employees, or you got to drag the CEO, they both want it for different reasons.", "tokens": [51112, 5286, 264, 38033, 6619, 11, 420, 291, 658, 281, 5286, 264, 9282, 11, 436, 1293, 528, 309, 337, 819, 4112, 13, 51356], "temperature": 0.0, "avg_logprob": -0.10113030632070247, "compression_ratio": 1.730886850152905, "no_speech_prob": 0.027135469019412994}, {"id": 487, "seek": 274088, "start": 2760.7200000000003, "end": 2764.88, "text": " And I think it will, it will happen. And you start to see that in the, the levels of uptake", "tokens": [51356, 400, 286, 519, 309, 486, 11, 309, 486, 1051, 13, 400, 291, 722, 281, 536, 300, 294, 264, 11, 264, 4358, 295, 493, 27612, 51564], "temperature": 0.0, "avg_logprob": -0.10113030632070247, "compression_ratio": 1.730886850152905, "no_speech_prob": 0.027135469019412994}, {"id": 488, "seek": 274088, "start": 2764.88, "end": 2769.44, "text": " that are being reported through, through the surveys. So I think that that says that we'll", "tokens": [51564, 300, 366, 885, 7055, 807, 11, 807, 264, 22711, 13, 407, 286, 519, 300, 300, 1619, 300, 321, 603, 51792], "temperature": 0.0, "avg_logprob": -0.10113030632070247, "compression_ratio": 1.730886850152905, "no_speech_prob": 0.027135469019412994}, {"id": 489, "seek": 276944, "start": 2769.44, "end": 2774.88, "text": " see more and more projects roll out more, more quickly. But there's still a lot of retraining", "tokens": [50364, 536, 544, 293, 544, 4455, 3373, 484, 544, 11, 544, 2661, 13, 583, 456, 311, 920, 257, 688, 295, 49356, 1760, 50636], "temperature": 0.0, "avg_logprob": -0.11066268336388373, "compression_ratio": 1.6006711409395973, "no_speech_prob": 0.009822632186114788}, {"id": 490, "seek": 276944, "start": 2774.88, "end": 2779.28, "text": " that needs to go on internally and internal processes. I mean, I think one thing that will", "tokens": [50636, 300, 2203, 281, 352, 322, 19501, 293, 6920, 7555, 13, 286, 914, 11, 286, 519, 472, 551, 300, 486, 50856], "temperature": 0.0, "avg_logprob": -0.11066268336388373, "compression_ratio": 1.6006711409395973, "no_speech_prob": 0.009822632186114788}, {"id": 491, "seek": 276944, "start": 2779.28, "end": 2784.32, "text": " happen is I just saw Ethan Mollick, who you must get on your show. This is fantastic. A professor", "tokens": [50856, 1051, 307, 286, 445, 1866, 23984, 376, 1833, 618, 11, 567, 291, 1633, 483, 322, 428, 855, 13, 639, 307, 5456, 13, 316, 8304, 51108], "temperature": 0.0, "avg_logprob": -0.11066268336388373, "compression_ratio": 1.6006711409395973, "no_speech_prob": 0.009822632186114788}, {"id": 492, "seek": 276944, "start": 2784.32, "end": 2790.4, "text": " at Wharton who's writing a book on chat GPT. And he just showed a video where he had six different", "tokens": [51108, 412, 506, 446, 266, 567, 311, 3579, 257, 1446, 322, 5081, 26039, 51, 13, 400, 415, 445, 4712, 257, 960, 689, 415, 632, 2309, 819, 51412], "temperature": 0.0, "avg_logprob": -0.11066268336388373, "compression_ratio": 1.6006711409395973, "no_speech_prob": 0.009822632186114788}, {"id": 493, "seek": 276944, "start": 2790.4, "end": 2796.56, "text": " windows open. He put an inquiry into each one. And in 54 seconds, he had a product launch plan,", "tokens": [51412, 9309, 1269, 13, 634, 829, 364, 25736, 666, 1184, 472, 13, 400, 294, 20793, 3949, 11, 415, 632, 257, 1674, 4025, 1393, 11, 51720], "temperature": 0.0, "avg_logprob": -0.11066268336388373, "compression_ratio": 1.6006711409395973, "no_speech_prob": 0.009822632186114788}, {"id": 494, "seek": 279656, "start": 2796.56, "end": 2802.16, "text": " a market analysis, a PowerPoint deck assessing Tesla's business and something else created", "tokens": [50364, 257, 2142, 5215, 11, 257, 25584, 9341, 34348, 13666, 311, 1606, 293, 746, 1646, 2942, 50644], "temperature": 0.0, "avg_logprob": -0.10895336696079799, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0074701192788779736}, {"id": 495, "seek": 279656, "start": 2802.16, "end": 2806.88, "text": " from one sentence prompts. Now, if anyone's work has worked in a large organization, they know", "tokens": [50644, 490, 472, 8174, 41095, 13, 823, 11, 498, 2878, 311, 589, 575, 2732, 294, 257, 2416, 4475, 11, 436, 458, 50880], "temperature": 0.0, "avg_logprob": -0.10895336696079799, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0074701192788779736}, {"id": 496, "seek": 279656, "start": 2806.88, "end": 2812.96, "text": " that you know your inbox is a full of crap and full of meaningless PowerPoint decks. So we might", "tokens": [50880, 300, 291, 458, 428, 35067, 307, 257, 1577, 295, 12426, 293, 1577, 295, 33232, 25584, 32607, 13, 407, 321, 1062, 51184], "temperature": 0.0, "avg_logprob": -0.10895336696079799, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0074701192788779736}, {"id": 497, "seek": 279656, "start": 2812.96, "end": 2819.2, "text": " actually just find ourselves sort of swallowed up by PowerPoints created by Microsoft co pilot.", "tokens": [51184, 767, 445, 915, 4175, 1333, 295, 41769, 493, 538, 25584, 82, 2942, 538, 8116, 598, 9691, 13, 51496], "temperature": 0.0, "avg_logprob": -0.10895336696079799, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0074701192788779736}, {"id": 498, "seek": 279656, "start": 2819.2, "end": 2823.44, "text": " So there's a whole set of I think more complex kind of issues that that exist in large companies.", "tokens": [51496, 407, 456, 311, 257, 1379, 992, 295, 286, 519, 544, 3997, 733, 295, 2663, 300, 300, 2514, 294, 2416, 3431, 13, 51708], "temperature": 0.0, "avg_logprob": -0.10895336696079799, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0074701192788779736}, {"id": 499, "seek": 282344, "start": 2823.44, "end": 2828.4, "text": " But I think that they will adopt this much faster than the evidence is and they have in", "tokens": [50364, 583, 286, 519, 300, 436, 486, 6878, 341, 709, 4663, 813, 264, 4467, 307, 293, 436, 362, 294, 50612], "temperature": 0.0, "avg_logprob": -0.09602829543027011, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0030431002378463745}, {"id": 500, "seek": 282344, "start": 2828.4, "end": 2833.2000000000003, "text": " previous technologies. But it doesn't, I think necessarily mean that disruption of the kind", "tokens": [50612, 3894, 7943, 13, 583, 309, 1177, 380, 11, 286, 519, 4725, 914, 300, 28751, 295, 264, 733, 50852], "temperature": 0.0, "avg_logprob": -0.09602829543027011, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0030431002378463745}, {"id": 501, "seek": 282344, "start": 2833.2000000000003, "end": 2842.7200000000003, "text": " you talked about won't also happen. And I didn't have on my dance card in 95 when I started working", "tokens": [50852, 291, 2825, 466, 1582, 380, 611, 1051, 13, 400, 286, 994, 380, 362, 322, 452, 4489, 2920, 294, 13420, 562, 286, 1409, 1364, 51328], "temperature": 0.0, "avg_logprob": -0.09602829543027011, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0030431002378463745}, {"id": 502, "seek": 282344, "start": 2842.7200000000003, "end": 2849.36, "text": " that blockbuster would be the first high profile casualty of the internet. And I had seen video", "tokens": [51328, 300, 3461, 41148, 576, 312, 264, 700, 1090, 7964, 13052, 874, 295, 264, 4705, 13, 400, 286, 632, 1612, 960, 51660], "temperature": 0.0, "avg_logprob": -0.09602829543027011, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0030431002378463745}, {"id": 503, "seek": 284936, "start": 2849.36, "end": 2854.56, "text": " over the internet. The Cambridge University had a webcam on a coffee pot. And that was the first", "tokens": [50364, 670, 264, 4705, 13, 440, 24876, 3535, 632, 257, 39490, 322, 257, 4982, 1847, 13, 400, 300, 390, 264, 700, 50624], "temperature": 0.0, "avg_logprob": -0.12247723680201585, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.16183748841285706}, {"id": 504, "seek": 284936, "start": 2854.56, "end": 2859.1200000000003, "text": " sort of video over the internet. And Rob Glazer had just started real networks was called progressive", "tokens": [50624, 1333, 295, 960, 670, 264, 4705, 13, 400, 5424, 47895, 4527, 632, 445, 1409, 957, 9590, 390, 1219, 16131, 50852], "temperature": 0.0, "avg_logprob": -0.12247723680201585, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.16183748841285706}, {"id": 505, "seek": 284936, "start": 2859.1200000000003, "end": 2864.48, "text": " networks back then. And when Netflix launched, it was this kind of thing with DVDs. And it was a", "tokens": [50852, 9590, 646, 550, 13, 400, 562, 12778, 8730, 11, 309, 390, 341, 733, 295, 551, 365, 21187, 82, 13, 400, 309, 390, 257, 51120], "temperature": 0.0, "avg_logprob": -0.12247723680201585, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.16183748841285706}, {"id": 506, "seek": 284936, "start": 2864.48, "end": 2870.32, "text": " real pain in the ass. And it took a long time, a few years before blockbuster has its best year,", "tokens": [51120, 957, 1822, 294, 264, 1256, 13, 400, 309, 1890, 257, 938, 565, 11, 257, 1326, 924, 949, 3461, 41148, 575, 1080, 1151, 1064, 11, 51412], "temperature": 0.0, "avg_logprob": -0.12247723680201585, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.16183748841285706}, {"id": 507, "seek": 284936, "start": 2870.32, "end": 2875.76, "text": " and then it has its worst year ever. And I think that if AI is gen AI, what have we want to call", "tokens": [51412, 293, 550, 309, 575, 1080, 5855, 1064, 1562, 13, 400, 286, 519, 300, 498, 7318, 307, 1049, 7318, 11, 437, 362, 321, 528, 281, 818, 51684], "temperature": 0.0, "avg_logprob": -0.12247723680201585, "compression_ratio": 1.721830985915493, "no_speech_prob": 0.16183748841285706}, {"id": 508, "seek": 287576, "start": 2875.76, "end": 2883.36, "text": " it is a GPT, there are going to be blockbusters lurking around. And the question is, which ones", "tokens": [50364, 309, 307, 257, 26039, 51, 11, 456, 366, 516, 281, 312, 3461, 65, 17181, 35583, 5092, 926, 13, 400, 264, 1168, 307, 11, 597, 2306, 50744], "temperature": 0.0, "avg_logprob": -0.11040150540546306, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.01645776629447937}, {"id": 509, "seek": 287576, "start": 2883.36, "end": 2888.7200000000003, "text": " will it be the reason I don't I like you, I don't feel it's going to be the banks is because the", "tokens": [50744, 486, 309, 312, 264, 1778, 286, 500, 380, 286, 411, 291, 11, 286, 500, 380, 841, 309, 311, 516, 281, 312, 264, 10237, 307, 570, 264, 51012], "temperature": 0.0, "avg_logprob": -0.11040150540546306, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.01645776629447937}, {"id": 510, "seek": 287576, "start": 2888.7200000000003, "end": 2894.8, "text": " banks have got a whole bunch of stuff that is about trust and probity and internal processes and", "tokens": [51012, 10237, 362, 658, 257, 1379, 3840, 295, 1507, 300, 307, 466, 3361, 293, 1239, 507, 293, 6920, 7555, 293, 51316], "temperature": 0.0, "avg_logprob": -0.11040150540546306, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.01645776629447937}, {"id": 511, "seek": 287576, "start": 2894.8, "end": 2901.36, "text": " compliance. That is is just not an AI question. It's it's kind of an institutional question. And I", "tokens": [51316, 15882, 13, 663, 307, 307, 445, 406, 364, 7318, 1168, 13, 467, 311, 309, 311, 733, 295, 364, 18391, 1168, 13, 400, 286, 51644], "temperature": 0.0, "avg_logprob": -0.11040150540546306, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.01645776629447937}, {"id": 512, "seek": 290136, "start": 2901.36, "end": 2909.44, "text": " do I do wonder about where that that moment is. And the the thing is that the there are obvious", "tokens": [50364, 360, 286, 360, 2441, 466, 689, 300, 300, 1623, 307, 13, 400, 264, 264, 551, 307, 300, 264, 456, 366, 6322, 50768], "temperature": 0.0, "avg_logprob": -0.1507538852528629, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0041411989368498325}, {"id": 513, "seek": 290136, "start": 2909.44, "end": 2912.96, "text": " ones. It's like, well, it'll be entertainment, right? We'll just start to generate personalized", "tokens": [50768, 2306, 13, 467, 311, 411, 11, 731, 11, 309, 603, 312, 12393, 11, 558, 30, 492, 603, 445, 722, 281, 8460, 28415, 50944], "temperature": 0.0, "avg_logprob": -0.1507538852528629, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0041411989368498325}, {"id": 514, "seek": 290136, "start": 2912.96, "end": 2917.6800000000003, "text": " entertainment. And that'll be really bad for you know, Disney, except that you could then counter", "tokens": [50944, 12393, 13, 400, 300, 603, 312, 534, 1578, 337, 291, 458, 11, 8653, 11, 3993, 300, 291, 727, 550, 5682, 51180], "temperature": 0.0, "avg_logprob": -0.1507538852528629, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0041411989368498325}, {"id": 515, "seek": 290136, "start": 2917.6800000000003, "end": 2924.48, "text": " and say, Well, but it might be derivatives of Disney Disney's IP that actually benefits Disney.", "tokens": [51180, 293, 584, 11, 1042, 11, 457, 309, 1062, 312, 33733, 295, 8653, 8653, 311, 8671, 300, 767, 5311, 8653, 13, 51520], "temperature": 0.0, "avg_logprob": -0.1507538852528629, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0041411989368498325}, {"id": 516, "seek": 290136, "start": 2924.48, "end": 2930.88, "text": " So finding the space a priori, I think is really, really difficult. And the people who make their", "tokens": [51520, 407, 5006, 264, 1901, 257, 4059, 72, 11, 286, 519, 307, 534, 11, 534, 2252, 13, 400, 264, 561, 567, 652, 641, 51840], "temperature": 0.0, "avg_logprob": -0.1507538852528629, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.0041411989368498325}, {"id": 517, "seek": 293088, "start": 2930.88, "end": 2935.44, "text": " money doing this, who are the venture capitalists, get it wrong a lot of the time anyway, that's why", "tokens": [50364, 1460, 884, 341, 11, 567, 366, 264, 18474, 4238, 1751, 11, 483, 309, 2085, 257, 688, 295, 264, 565, 4033, 11, 300, 311, 983, 50592], "temperature": 0.0, "avg_logprob": -0.10250487447786732, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.002589116571471095}, {"id": 518, "seek": 293088, "start": 2935.44, "end": 2941.6, "text": " they all they all have portfolios of 30, 50, 100, 500 companies. If it was so damn easy to find", "tokens": [50592, 436, 439, 436, 439, 362, 11688, 2717, 295, 2217, 11, 2625, 11, 2319, 11, 5923, 3431, 13, 759, 309, 390, 370, 8151, 1858, 281, 915, 50900], "temperature": 0.0, "avg_logprob": -0.10250487447786732, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.002589116571471095}, {"id": 519, "seek": 293088, "start": 2942.48, "end": 2948.08, "text": " the next Apple, that's going to disrupt the previous industry that have portfolios of one,", "tokens": [50944, 264, 958, 6373, 11, 300, 311, 516, 281, 14124, 264, 3894, 3518, 300, 362, 11688, 2717, 295, 472, 11, 51224], "temperature": 0.0, "avg_logprob": -0.10250487447786732, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.002589116571471095}, {"id": 520, "seek": 293088, "start": 2948.08, "end": 2950.96, "text": " it's not it's really difficult because actually nobody knows and we have to", "tokens": [51224, 309, 311, 406, 309, 311, 534, 2252, 570, 767, 5079, 3255, 293, 321, 362, 281, 51368], "temperature": 0.0, "avg_logprob": -0.10250487447786732, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.002589116571471095}, {"id": 521, "seek": 293088, "start": 2951.6, "end": 2957.12, "text": " figure it out through, you know, experimentation. So so I don't I don't know, but I keep asking", "tokens": [51400, 2573, 309, 484, 807, 11, 291, 458, 11, 37142, 13, 407, 370, 286, 500, 380, 286, 500, 380, 458, 11, 457, 286, 1066, 3365, 51676], "temperature": 0.0, "avg_logprob": -0.10250487447786732, "compression_ratio": 1.6630434782608696, "no_speech_prob": 0.002589116571471095}, {"id": 522, "seek": 295712, "start": 2957.12, "end": 2962.48, "text": " that question and the question I take to bosses of companies, I take a couple. One is who could be", "tokens": [50364, 300, 1168, 293, 264, 1168, 286, 747, 281, 24201, 295, 3431, 11, 286, 747, 257, 1916, 13, 1485, 307, 567, 727, 312, 50632], "temperature": 0.0, "avg_logprob": -0.08981000884505343, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.04674208164215088}, {"id": 523, "seek": 295712, "start": 2962.48, "end": 2968.4, "text": " the blockbuster? And how do you what are you doing to make sure that that's not you because I think", "tokens": [50632, 264, 3461, 41148, 30, 400, 577, 360, 291, 437, 366, 291, 884, 281, 652, 988, 300, 300, 311, 406, 291, 570, 286, 519, 50928], "temperature": 0.0, "avg_logprob": -0.08981000884505343, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.04674208164215088}, {"id": 524, "seek": 295712, "start": 2968.4, "end": 2973.3599999999997, "text": " by and large, they've got the rollout of gen AI and customer service and compliance and form", "tokens": [50928, 538, 293, 2416, 11, 436, 600, 658, 264, 3373, 346, 295, 1049, 7318, 293, 5474, 2643, 293, 15882, 293, 1254, 51176], "temperature": 0.0, "avg_logprob": -0.08981000884505343, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.04674208164215088}, {"id": 525, "seek": 295712, "start": 2973.3599999999997, "end": 2978.16, "text": " filling and so on underway. And the second question I've started to ask is, you know, what would you", "tokens": [51176, 10623, 293, 370, 322, 27534, 13, 400, 264, 1150, 1168, 286, 600, 1409, 281, 1029, 307, 11, 291, 458, 11, 437, 576, 291, 51416], "temperature": 0.0, "avg_logprob": -0.08981000884505343, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.04674208164215088}, {"id": 526, "seek": 295712, "start": 2978.16, "end": 2984.7999999999997, "text": " do if you had a million times more compute than you have today? And many of them haven't thought", "tokens": [51416, 360, 498, 291, 632, 257, 2459, 1413, 544, 14722, 813, 291, 362, 965, 30, 400, 867, 295, 552, 2378, 380, 1194, 51748], "temperature": 0.0, "avg_logprob": -0.08981000884505343, "compression_ratio": 1.7157894736842105, "no_speech_prob": 0.04674208164215088}, {"id": 527, "seek": 298480, "start": 2984.8, "end": 2988.6400000000003, "text": " about that. I mean, I think big tech companies have, you know, if you offered that to Satya Nadella,", "tokens": [50364, 466, 300, 13, 286, 914, 11, 286, 519, 955, 7553, 3431, 362, 11, 291, 458, 11, 498, 291, 8059, 300, 281, 5344, 3016, 426, 762, 3505, 11, 50556], "temperature": 0.0, "avg_logprob": -0.08867000579833985, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.01631155237555504}, {"id": 528, "seek": 298480, "start": 2988.6400000000003, "end": 2993.36, "text": " I mean, he's already in the path to do that. But but that becomes really important because if compute", "tokens": [50556, 286, 914, 11, 415, 311, 1217, 294, 264, 3100, 281, 360, 300, 13, 583, 457, 300, 3643, 534, 1021, 570, 498, 14722, 50792], "temperature": 0.0, "avg_logprob": -0.08867000579833985, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.01631155237555504}, {"id": 529, "seek": 298480, "start": 2993.36, "end": 2999.28, "text": " is a key input into your company's ability to execute, you need to start to think about those", "tokens": [50792, 307, 257, 2141, 4846, 666, 428, 2237, 311, 3485, 281, 14483, 11, 291, 643, 281, 722, 281, 519, 466, 729, 51088], "temperature": 0.0, "avg_logprob": -0.08867000579833985, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.01631155237555504}, {"id": 530, "seek": 298480, "start": 2999.28, "end": 3004.96, "text": " those types of questions. And do you even have a plan to make use of it? What options would it", "tokens": [51088, 729, 3467, 295, 1651, 13, 400, 360, 291, 754, 362, 257, 1393, 281, 652, 764, 295, 309, 30, 708, 3956, 576, 309, 51372], "temperature": 0.0, "avg_logprob": -0.08867000579833985, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.01631155237555504}, {"id": 531, "seek": 298480, "start": 3004.96, "end": 3011.44, "text": " create for you? So those are the two areas that I push on because I want people to try to think", "tokens": [51372, 1884, 337, 291, 30, 407, 729, 366, 264, 732, 3179, 300, 286, 2944, 322, 570, 286, 528, 561, 281, 853, 281, 519, 51696], "temperature": 0.0, "avg_logprob": -0.08867000579833985, "compression_ratio": 1.7208480565371025, "no_speech_prob": 0.01631155237555504}, {"id": 532, "seek": 301144, "start": 3011.52, "end": 3017.76, "text": " a bit more creatively about this and recognize that, you know, a million X is not outside of", "tokens": [50368, 257, 857, 544, 43750, 466, 341, 293, 5521, 300, 11, 291, 458, 11, 257, 2459, 1783, 307, 406, 2380, 295, 50680], "temperature": 0.0, "avg_logprob": -0.11747431073869978, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0042730700224637985}, {"id": 533, "seek": 301144, "start": 3017.76, "end": 3023.36, "text": " the bounds of a planning cycle. And the reason I would say that is, yes, we don't have measures to", "tokens": [50680, 264, 29905, 295, 257, 5038, 6586, 13, 400, 264, 1778, 286, 576, 584, 300, 307, 11, 2086, 11, 321, 500, 380, 362, 8000, 281, 50960], "temperature": 0.0, "avg_logprob": -0.11747431073869978, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0042730700224637985}, {"id": 534, "seek": 301144, "start": 3023.36, "end": 3030.4, "text": " easily show it up. But five years ago, the state of the art transformer model would have just been", "tokens": [50960, 3612, 855, 309, 493, 13, 583, 1732, 924, 2057, 11, 264, 1785, 295, 264, 1523, 31782, 2316, 576, 362, 445, 668, 51312], "temperature": 0.0, "avg_logprob": -0.11747431073869978, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0042730700224637985}, {"id": 535, "seek": 301144, "start": 3030.4, "end": 3037.52, "text": " GPT two hadn't been released. So it's GPT one. And GPT one to GPT four chat GPT, I mean,", "tokens": [51312, 26039, 51, 732, 8782, 380, 668, 4736, 13, 407, 309, 311, 26039, 51, 472, 13, 400, 26039, 51, 472, 281, 26039, 51, 1451, 5081, 26039, 51, 11, 286, 914, 11, 51668], "temperature": 0.0, "avg_logprob": -0.11747431073869978, "compression_ratio": 1.559670781893004, "no_speech_prob": 0.0042730700224637985}, {"id": 536, "seek": 303752, "start": 3037.52, "end": 3042.64, "text": " metaphorically, just as buddies around a bar, it's a million times better, right? Maybe on the", "tokens": [50364, 19157, 984, 11, 445, 382, 30649, 926, 257, 2159, 11, 309, 311, 257, 2459, 1413, 1101, 11, 558, 30, 2704, 322, 264, 50620], "temperature": 0.0, "avg_logprob": -0.1213484639706819, "compression_ratio": 1.7107692307692308, "no_speech_prob": 0.025146836414933205}, {"id": 537, "seek": 303752, "start": 3042.64, "end": 3046.56, "text": " benchmarks, it's not it's 40% better here. But it feels a million times better, because you're", "tokens": [50620, 43751, 11, 309, 311, 406, 309, 311, 3356, 4, 1101, 510, 13, 583, 309, 3417, 257, 2459, 1413, 1101, 11, 570, 291, 434, 50816], "temperature": 0.0, "avg_logprob": -0.1213484639706819, "compression_ratio": 1.7107692307692308, "no_speech_prob": 0.025146836414933205}, {"id": 538, "seek": 303752, "start": 3046.56, "end": 3052.64, "text": " just right across the uncanny valley. So we've just seen that play out. So let's ask it again,", "tokens": [50816, 445, 558, 2108, 264, 6219, 11612, 17636, 13, 407, 321, 600, 445, 1612, 300, 862, 484, 13, 407, 718, 311, 1029, 309, 797, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1213484639706819, "compression_ratio": 1.7107692307692308, "no_speech_prob": 0.025146836414933205}, {"id": 539, "seek": 303752, "start": 3052.64, "end": 3058.48, "text": " and try to ground people in the fact that capabilities could change that quickly. And", "tokens": [51120, 293, 853, 281, 2727, 561, 294, 264, 1186, 300, 10862, 727, 1319, 300, 2661, 13, 400, 51412], "temperature": 0.0, "avg_logprob": -0.1213484639706819, "compression_ratio": 1.7107692307692308, "no_speech_prob": 0.025146836414933205}, {"id": 540, "seek": 303752, "start": 3058.48, "end": 3061.6, "text": " what opportunity does that create? So how do you this is actually a live question for me?", "tokens": [51412, 437, 2650, 775, 300, 1884, 30, 407, 577, 360, 291, 341, 307, 767, 257, 1621, 1168, 337, 385, 30, 51568], "temperature": 0.0, "avg_logprob": -0.1213484639706819, "compression_ratio": 1.7107692307692308, "no_speech_prob": 0.025146836414933205}, {"id": 541, "seek": 303752, "start": 3061.6, "end": 3066.96, "text": " Because I'm working with a couple of companies and I'm noticing this challenge where it's like,", "tokens": [51568, 1436, 286, 478, 1364, 365, 257, 1916, 295, 3431, 293, 286, 478, 21814, 341, 3430, 689, 309, 311, 411, 11, 51836], "temperature": 0.0, "avg_logprob": -0.1213484639706819, "compression_ratio": 1.7107692307692308, "no_speech_prob": 0.025146836414933205}, {"id": 542, "seek": 306696, "start": 3066.96, "end": 3071.84, "text": " okay, this is cool technology for sure, we can all agree on that. And yeah, we can probably", "tokens": [50364, 1392, 11, 341, 307, 1627, 2899, 337, 988, 11, 321, 393, 439, 3986, 322, 300, 13, 400, 1338, 11, 321, 393, 1391, 50608], "temperature": 0.0, "avg_logprob": -0.12164186609202418, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.0003150160482618958}, {"id": 543, "seek": 306696, "start": 3072.4, "end": 3077.6, "text": " find some efficiencies in terms of automating ticket, you know, resolution and whatever. I'm", "tokens": [50636, 915, 512, 4703, 31294, 294, 2115, 295, 3553, 990, 10550, 11, 291, 458, 11, 8669, 293, 2035, 13, 286, 478, 50896], "temperature": 0.0, "avg_logprob": -0.12164186609202418, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.0003150160482618958}, {"id": 544, "seek": 306696, "start": 3078.16, "end": 3085.28, "text": " starting to even see things like intercom has this new 99 cent per ticket resolved AI", "tokens": [50924, 2891, 281, 754, 536, 721, 411, 728, 1112, 575, 341, 777, 11803, 1489, 680, 10550, 20772, 7318, 51280], "temperature": 0.0, "avg_logprob": -0.12164186609202418, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.0003150160482618958}, {"id": 545, "seek": 306696, "start": 3085.28, "end": 3089.12, "text": " pricing model, which I think is super interesting. So everybody's like, okay, cool, yeah, let's,", "tokens": [51280, 17621, 2316, 11, 597, 286, 519, 307, 1687, 1880, 13, 407, 2201, 311, 411, 11, 1392, 11, 1627, 11, 1338, 11, 718, 311, 11, 51472], "temperature": 0.0, "avg_logprob": -0.12164186609202418, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.0003150160482618958}, {"id": 546, "seek": 306696, "start": 3089.12, "end": 3092.64, "text": " you know, let's find some efficiencies, let's automate some stuff that nobody wants to do.", "tokens": [51472, 291, 458, 11, 718, 311, 915, 512, 4703, 31294, 11, 718, 311, 31605, 512, 1507, 300, 5079, 2738, 281, 360, 13, 51648], "temperature": 0.0, "avg_logprob": -0.12164186609202418, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.0003150160482618958}, {"id": 547, "seek": 309264, "start": 3092.72, "end": 3096.7999999999997, "text": " Great. But then there's also this question of like, okay, we're still at the task level,", "tokens": [50368, 3769, 13, 583, 550, 456, 311, 611, 341, 1168, 295, 411, 11, 1392, 11, 321, 434, 920, 412, 264, 5633, 1496, 11, 50572], "temperature": 0.0, "avg_logprob": -0.08681855081510143, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.026754919439554214}, {"id": 548, "seek": 309264, "start": 3096.7999999999997, "end": 3103.44, "text": " the AI's can't quite do jobs yet. And how far are we willing to extrapolate and how much are we", "tokens": [50572, 264, 7318, 311, 393, 380, 1596, 360, 4782, 1939, 13, 400, 577, 1400, 366, 321, 4950, 281, 48224, 473, 293, 577, 709, 366, 321, 50904], "temperature": 0.0, "avg_logprob": -0.08681855081510143, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.026754919439554214}, {"id": 549, "seek": 309264, "start": 3103.44, "end": 3110.0, "text": " willing to invest prepared, you know, willing and prepared to invest, to try to not we're not", "tokens": [50904, 4950, 281, 1963, 4927, 11, 291, 458, 11, 4950, 293, 4927, 281, 1963, 11, 281, 853, 281, 406, 321, 434, 406, 51232], "temperature": 0.0, "avg_logprob": -0.08681855081510143, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.026754919439554214}, {"id": 550, "seek": 309264, "start": 3110.0, "end": 3113.44, "text": " going to get ahead of it, but even just kind of try to keep up with where this might be going", "tokens": [51232, 516, 281, 483, 2286, 295, 309, 11, 457, 754, 445, 733, 295, 853, 281, 1066, 493, 365, 689, 341, 1062, 312, 516, 51404], "temperature": 0.0, "avg_logprob": -0.08681855081510143, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.026754919439554214}, {"id": 551, "seek": 309264, "start": 3114.0, "end": 3119.8399999999997, "text": " in the not too distant future. And I feel like people are having a really hard time", "tokens": [51432, 294, 264, 406, 886, 17275, 2027, 13, 400, 286, 841, 411, 561, 366, 1419, 257, 534, 1152, 565, 51724], "temperature": 0.0, "avg_logprob": -0.08681855081510143, "compression_ratio": 1.7338403041825095, "no_speech_prob": 0.026754919439554214}, {"id": 552, "seek": 311984, "start": 3119.84, "end": 3122.96, "text": " wrapping their head around that. Partly, it's like, you know, they don't want to", "tokens": [50364, 21993, 641, 1378, 926, 300, 13, 4100, 356, 11, 309, 311, 411, 11, 291, 458, 11, 436, 500, 380, 528, 281, 50520], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 553, "seek": 311984, "start": 3122.96, "end": 3126.48, "text": " believe too much in the hype, right? There's the question of, well, hey, this,", "tokens": [50520, 1697, 886, 709, 294, 264, 24144, 11, 558, 30, 821, 311, 264, 1168, 295, 11, 731, 11, 4177, 11, 341, 11, 50696], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 554, "seek": 311984, "start": 3126.48, "end": 3130.0, "text": " how much of this is maybe just overhyped? And, you know, we've seen hype cycles come and go", "tokens": [50696, 577, 709, 295, 341, 307, 1310, 445, 670, 3495, 3452, 30, 400, 11, 291, 458, 11, 321, 600, 1612, 24144, 17796, 808, 293, 352, 50872], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 555, "seek": 311984, "start": 3130.0, "end": 3134.1600000000003, "text": " before. But I wonder how you would kind of coach people there, because I'm trying to", "tokens": [50872, 949, 13, 583, 286, 2441, 577, 291, 576, 733, 295, 6560, 561, 456, 11, 570, 286, 478, 1382, 281, 51080], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 556, "seek": 311984, "start": 3134.1600000000003, "end": 3139.04, "text": " get the message across that, by all means, you know, you want to be picking up the low hanging", "tokens": [51080, 483, 264, 3636, 2108, 300, 11, 538, 439, 1355, 11, 291, 458, 11, 291, 528, 281, 312, 8867, 493, 264, 2295, 8345, 51324], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 557, "seek": 311984, "start": 3139.04, "end": 3144.2400000000002, "text": " fruit and, you know, automating the tickets and finding all these efficiencies. But you also", "tokens": [51324, 6773, 293, 11, 291, 458, 11, 3553, 990, 264, 12628, 293, 5006, 439, 613, 4703, 31294, 13, 583, 291, 611, 51584], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 558, "seek": 311984, "start": 3144.2400000000002, "end": 3149.28, "text": " really do probably want to start thinking about what is the future paradigm that you might be", "tokens": [51584, 534, 360, 1391, 528, 281, 722, 1953, 466, 437, 307, 264, 2027, 24709, 300, 291, 1062, 312, 51836], "temperature": 0.0, "avg_logprob": -0.10454176664352417, "compression_ratio": 1.7262569832402235, "no_speech_prob": 0.03963059186935425}, {"id": 559, "seek": 314928, "start": 3149.28, "end": 3153.92, "text": " working in. And there's just so much fog around that for people that I find a lot are just kind", "tokens": [50364, 1364, 294, 13, 400, 456, 311, 445, 370, 709, 13648, 926, 300, 337, 561, 300, 286, 915, 257, 688, 366, 445, 733, 50596], "temperature": 0.0, "avg_logprob": -0.07074869596041165, "compression_ratio": 1.690625, "no_speech_prob": 0.0060950941406190395}, {"id": 560, "seek": 314928, "start": 3153.92, "end": 3158.8, "text": " of like, I don't know, I don't really even want to go there yet. But I feel like it's a mistake", "tokens": [50596, 295, 411, 11, 286, 500, 380, 458, 11, 286, 500, 380, 534, 754, 528, 281, 352, 456, 1939, 13, 583, 286, 841, 411, 309, 311, 257, 6146, 50840], "temperature": 0.0, "avg_logprob": -0.07074869596041165, "compression_ratio": 1.690625, "no_speech_prob": 0.0060950941406190395}, {"id": 561, "seek": 314928, "start": 3158.8, "end": 3163.36, "text": " to not, you know, at least try. They do. I mean, there are two companies I never mentioned,", "tokens": [50840, 281, 406, 11, 291, 458, 11, 412, 1935, 853, 13, 814, 360, 13, 286, 914, 11, 456, 366, 732, 3431, 286, 1128, 2835, 11, 51068], "temperature": 0.0, "avg_logprob": -0.07074869596041165, "compression_ratio": 1.690625, "no_speech_prob": 0.0060950941406190395}, {"id": 562, "seek": 314928, "start": 3163.36, "end": 3169.2000000000003, "text": " Apple and Tesla, because bosses have had them parroted at them for 10 or 15 years. And the", "tokens": [51068, 6373, 293, 13666, 11, 570, 24201, 362, 632, 552, 42462, 292, 412, 552, 337, 1266, 420, 2119, 924, 13, 400, 264, 51360], "temperature": 0.0, "avg_logprob": -0.07074869596041165, "compression_ratio": 1.690625, "no_speech_prob": 0.0060950941406190395}, {"id": 563, "seek": 314928, "start": 3169.2000000000003, "end": 3172.5600000000004, "text": " point about the million times question is not to frighten people. It's actually,", "tokens": [51360, 935, 466, 264, 2459, 1413, 1168, 307, 406, 281, 15545, 268, 561, 13, 467, 311, 767, 11, 51528], "temperature": 0.0, "avg_logprob": -0.07074869596041165, "compression_ratio": 1.690625, "no_speech_prob": 0.0060950941406190395}, {"id": 564, "seek": 314928, "start": 3172.5600000000004, "end": 3176.96, "text": " it's really about saying once we sort of acknowledge that, then we work back to stuff", "tokens": [51528, 309, 311, 534, 466, 1566, 1564, 321, 1333, 295, 10692, 300, 11, 550, 321, 589, 646, 281, 1507, 51748], "temperature": 0.0, "avg_logprob": -0.07074869596041165, "compression_ratio": 1.690625, "no_speech_prob": 0.0060950941406190395}, {"id": 565, "seek": 317696, "start": 3176.96, "end": 3185.12, "text": " that is much more practical and prosaic, which is what is the kind of organization and capabilities", "tokens": [50364, 300, 307, 709, 544, 8496, 293, 6267, 64, 299, 11, 597, 307, 437, 307, 264, 733, 295, 4475, 293, 10862, 50772], "temperature": 0.0, "avg_logprob": -0.1231754869222641, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.009219193831086159}, {"id": 566, "seek": 317696, "start": 3185.12, "end": 3195.52, "text": " you need to have in order to take advantage of this, these changes in a regular way. And", "tokens": [50772, 291, 643, 281, 362, 294, 1668, 281, 747, 5002, 295, 341, 11, 613, 2962, 294, 257, 3890, 636, 13, 400, 51292], "temperature": 0.0, "avg_logprob": -0.1231754869222641, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.009219193831086159}, {"id": 567, "seek": 317696, "start": 3196.32, "end": 3201.12, "text": " there was some really interesting research in that Microsoft did actually pre all of this chat", "tokens": [51332, 456, 390, 512, 534, 1880, 2132, 294, 300, 8116, 630, 767, 659, 439, 295, 341, 5081, 51572], "temperature": 0.0, "avg_logprob": -0.1231754869222641, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.009219193831086159}, {"id": 568, "seek": 320112, "start": 3201.12, "end": 3206.96, "text": " GPT stuff is about three or four years ago, where they looked at adoption rates of AI,", "tokens": [50364, 26039, 51, 1507, 307, 466, 1045, 420, 1451, 924, 2057, 11, 689, 436, 2956, 412, 19215, 6846, 295, 7318, 11, 50656], "temperature": 0.0, "avg_logprob": -0.10898788158710186, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.30749067664146423}, {"id": 569, "seek": 320112, "start": 3206.96, "end": 3213.92, "text": " big data type of words in companies, and they found that the more mature companies were much", "tokens": [50656, 955, 1412, 2010, 295, 2283, 294, 3431, 11, 293, 436, 1352, 300, 264, 544, 14442, 3431, 645, 709, 51004], "temperature": 0.0, "avg_logprob": -0.10898788158710186, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.30749067664146423}, {"id": 570, "seek": 320112, "start": 3213.92, "end": 3219.7599999999998, "text": " more likely in these fields were much more likely to be to say that the benefit they got was from", "tokens": [51004, 544, 3700, 294, 613, 7909, 645, 709, 544, 3700, 281, 312, 281, 584, 300, 264, 5121, 436, 658, 390, 490, 51296], "temperature": 0.0, "avg_logprob": -0.10898788158710186, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.30749067664146423}, {"id": 571, "seek": 320112, "start": 3219.7599999999998, "end": 3224.72, "text": " market expansion and business development. Whereas the more immature ones were likely to say,", "tokens": [51296, 2142, 11260, 293, 1606, 3250, 13, 13813, 264, 544, 49539, 2306, 645, 3700, 281, 584, 11, 51544], "temperature": 0.0, "avg_logprob": -0.10898788158710186, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.30749067664146423}, {"id": 572, "seek": 320112, "start": 3224.72, "end": 3230.72, "text": " it's all about operational savings on the tickets as it was back then. And part of the", "tokens": [51544, 309, 311, 439, 466, 16607, 13454, 322, 264, 12628, 382, 309, 390, 646, 550, 13, 400, 644, 295, 264, 51844], "temperature": 0.0, "avg_logprob": -0.10898788158710186, "compression_ratio": 1.728301886792453, "no_speech_prob": 0.30749067664146423}, {"id": 573, "seek": 323112, "start": 3231.8399999999997, "end": 3237.04, "text": " thing that you can start to do is you have to acknowledge that there are some really", "tokens": [50400, 551, 300, 291, 393, 722, 281, 360, 307, 291, 362, 281, 10692, 300, 456, 366, 512, 534, 50660], "temperature": 0.0, "avg_logprob": -0.10357526801098352, "compression_ratio": 1.625, "no_speech_prob": 0.0012191678397357464}, {"id": 574, "seek": 323112, "start": 3237.04, "end": 3244.0, "text": " clear quick and clear wins in what are basically low value tasks, as perceived by the company,", "tokens": [50660, 1850, 1702, 293, 1850, 10641, 294, 437, 366, 1936, 2295, 2158, 9608, 11, 382, 19049, 538, 264, 2237, 11, 51008], "temperature": 0.0, "avg_logprob": -0.10357526801098352, "compression_ratio": 1.625, "no_speech_prob": 0.0012191678397357464}, {"id": 575, "seek": 323112, "start": 3244.0, "end": 3249.2, "text": " right, because they're often outsourced to third parties. But you also need to make sure that", "tokens": [51008, 558, 11, 570, 436, 434, 2049, 14758, 396, 1232, 281, 2636, 8265, 13, 583, 291, 611, 643, 281, 652, 988, 300, 51268], "temperature": 0.0, "avg_logprob": -0.10357526801098352, "compression_ratio": 1.625, "no_speech_prob": 0.0012191678397357464}, {"id": 576, "seek": 323112, "start": 3249.2, "end": 3255.68, "text": " your best people or who you invest the most in have got access to the really, really very,", "tokens": [51268, 428, 1151, 561, 420, 567, 291, 1963, 264, 881, 294, 362, 658, 2105, 281, 264, 534, 11, 534, 588, 11, 51592], "temperature": 0.0, "avg_logprob": -0.10357526801098352, "compression_ratio": 1.625, "no_speech_prob": 0.0012191678397357464}, {"id": 577, "seek": 325568, "start": 3255.68, "end": 3262.96, "text": " very best tools. You know, I want my surgeon using AI systems to improve his performance,", "tokens": [50364, 588, 1151, 3873, 13, 509, 458, 11, 286, 528, 452, 22913, 1228, 7318, 3652, 281, 3470, 702, 3389, 11, 50728], "temperature": 0.0, "avg_logprob": -0.10783980520148026, "compression_ratio": 1.5120967741935485, "no_speech_prob": 0.12948544323444366}, {"id": 578, "seek": 325568, "start": 3262.96, "end": 3269.04, "text": " right? So what I try to do is encourage people to say, this, this is a shift that's happening.", "tokens": [50728, 558, 30, 407, 437, 286, 853, 281, 360, 307, 5373, 561, 281, 584, 11, 341, 11, 341, 307, 257, 5513, 300, 311, 2737, 13, 51032], "temperature": 0.0, "avg_logprob": -0.10783980520148026, "compression_ratio": 1.5120967741935485, "no_speech_prob": 0.12948544323444366}, {"id": 579, "seek": 325568, "start": 3269.04, "end": 3273.9199999999996, "text": " And of course, it's not about buying every GPU you can, if you're in the fish oils business.", "tokens": [51032, 400, 295, 1164, 11, 309, 311, 406, 466, 6382, 633, 18407, 291, 393, 11, 498, 291, 434, 294, 264, 3506, 22177, 1606, 13, 51276], "temperature": 0.0, "avg_logprob": -0.10783980520148026, "compression_ratio": 1.5120967741935485, "no_speech_prob": 0.12948544323444366}, {"id": 580, "seek": 325568, "start": 3273.9199999999996, "end": 3281.12, "text": " But it is about saying our teams outside of cost savings, starting to understand how they can use", "tokens": [51276, 583, 309, 307, 466, 1566, 527, 5491, 2380, 295, 2063, 13454, 11, 2891, 281, 1223, 577, 436, 393, 764, 51636], "temperature": 0.0, "avg_logprob": -0.10783980520148026, "compression_ratio": 1.5120967741935485, "no_speech_prob": 0.12948544323444366}, {"id": 581, "seek": 328112, "start": 3281.7599999999998, "end": 3286.88, "text": " these services. And are they starting to experiment, learn how to use prompts? Well,", "tokens": [50396, 613, 3328, 13, 400, 366, 436, 2891, 281, 5120, 11, 1466, 577, 281, 764, 41095, 30, 1042, 11, 50652], "temperature": 0.0, "avg_logprob": -0.14416381290980748, "compression_ratio": 1.59375, "no_speech_prob": 0.05158565938472748}, {"id": 582, "seek": 328112, "start": 3286.88, "end": 3293.3599999999997, "text": " start to see what avenues that that opens up in ways that are much, much more strategic.", "tokens": [50652, 722, 281, 536, 437, 43039, 300, 300, 9870, 493, 294, 2098, 300, 366, 709, 11, 709, 544, 10924, 13, 50976], "temperature": 0.0, "avg_logprob": -0.14416381290980748, "compression_ratio": 1.59375, "no_speech_prob": 0.05158565938472748}, {"id": 583, "seek": 328112, "start": 3293.3599999999997, "end": 3299.6, "text": " And, and I think that that forms could form some part of culture change where you have companies", "tokens": [50976, 400, 11, 293, 286, 519, 300, 300, 6422, 727, 1254, 512, 644, 295, 3713, 1319, 689, 291, 362, 3431, 51288], "temperature": 0.0, "avg_logprob": -0.14416381290980748, "compression_ratio": 1.59375, "no_speech_prob": 0.05158565938472748}, {"id": 584, "seek": 328112, "start": 3299.6, "end": 3306.56, "text": " who think in those terms. And that helps the CEO start to understand that question of,", "tokens": [51288, 567, 519, 294, 729, 2115, 13, 400, 300, 3665, 264, 9282, 722, 281, 1223, 300, 1168, 295, 11, 51636], "temperature": 0.0, "avg_logprob": -0.14416381290980748, "compression_ratio": 1.59375, "no_speech_prob": 0.05158565938472748}, {"id": 585, "seek": 330656, "start": 3307.12, "end": 3311.92, "text": " this is not theoretical, theoretical that I need lots of computation to do a simulation", "tokens": [50392, 341, 307, 406, 20864, 11, 20864, 300, 286, 643, 3195, 295, 24903, 281, 360, 257, 16575, 50632], "temperature": 0.0, "avg_logprob": -0.10096958571789312, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.006259786430746317}, {"id": 586, "seek": 330656, "start": 3311.92, "end": 3315.36, "text": " for X. And I've bought it from one of the big consulting companies or from IBM.", "tokens": [50632, 337, 1783, 13, 400, 286, 600, 4243, 309, 490, 472, 295, 264, 955, 23682, 3431, 420, 490, 23487, 13, 50804], "temperature": 0.0, "avg_logprob": -0.10096958571789312, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.006259786430746317}, {"id": 587, "seek": 330656, "start": 3315.92, "end": 3321.04, "text": " It's more that internally, my strategy teams, my business development teams are starting to", "tokens": [50832, 467, 311, 544, 300, 19501, 11, 452, 5206, 5491, 11, 452, 1606, 3250, 5491, 366, 2891, 281, 51088], "temperature": 0.0, "avg_logprob": -0.10096958571789312, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.006259786430746317}, {"id": 588, "seek": 330656, "start": 3321.04, "end": 3326.96, "text": " identify opportunities and partnerships that we wouldn't otherwise have, have seen. And we can", "tokens": [51088, 5876, 4786, 293, 18245, 300, 321, 2759, 380, 5911, 362, 11, 362, 1612, 13, 400, 321, 393, 51384], "temperature": 0.0, "avg_logprob": -0.10096958571789312, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.006259786430746317}, {"id": 589, "seek": 330656, "start": 3326.96, "end": 3332.4, "text": " start to do that by, by using these, these tools in different ways. So I think it is", "tokens": [51384, 722, 281, 360, 300, 538, 11, 538, 1228, 613, 11, 613, 3873, 294, 819, 2098, 13, 407, 286, 519, 309, 307, 51656], "temperature": 0.0, "avg_logprob": -0.10096958571789312, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.006259786430746317}, {"id": 590, "seek": 333240, "start": 3332.48, "end": 3338.0, "text": " practice based, which is why I think kind of prompting becomes, you know, quite a useful tool", "tokens": [50368, 3124, 2361, 11, 597, 307, 983, 286, 519, 733, 295, 12391, 278, 3643, 11, 291, 458, 11, 1596, 257, 4420, 2290, 50644], "temperature": 0.0, "avg_logprob": -0.1322618538225201, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.04268484562635422}, {"id": 591, "seek": 333240, "start": 3338.0, "end": 3344.2400000000002, "text": " to, to show people. And you need to get people past that idea that chat GPT is all about writing", "tokens": [50644, 281, 11, 281, 855, 561, 13, 400, 291, 643, 281, 483, 561, 1791, 300, 1558, 300, 5081, 26039, 51, 307, 439, 466, 3579, 50956], "temperature": 0.0, "avg_logprob": -0.1322618538225201, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.04268484562635422}, {"id": 592, "seek": 333240, "start": 3344.2400000000002, "end": 3349.6, "text": " the Declaration of Independence, as if you were Jar Jar Binks from, you know, Star Wars episode", "tokens": [50956, 264, 40844, 295, 33631, 11, 382, 498, 291, 645, 23941, 23941, 363, 16431, 490, 11, 291, 458, 11, 5705, 9818, 3500, 51224], "temperature": 0.0, "avg_logprob": -0.1322618538225201, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.04268484562635422}, {"id": 593, "seek": 333240, "start": 3349.6, "end": 3353.76, "text": " two, right? And that's where we all started, right? We got it to write funny raps and poems and", "tokens": [51224, 732, 11, 558, 30, 400, 300, 311, 689, 321, 439, 1409, 11, 558, 30, 492, 658, 309, 281, 2464, 4074, 367, 2382, 293, 24014, 293, 51432], "temperature": 0.0, "avg_logprob": -0.1322618538225201, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.04268484562635422}, {"id": 594, "seek": 333240, "start": 3353.76, "end": 3358.48, "text": " what have you. And instead, you start to show bosses what can really be done with something", "tokens": [51432, 437, 362, 291, 13, 400, 2602, 11, 291, 722, 281, 855, 24201, 437, 393, 534, 312, 1096, 365, 746, 51668], "temperature": 0.0, "avg_logprob": -0.1322618538225201, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.04268484562635422}, {"id": 595, "seek": 333240, "start": 3358.48, "end": 3361.84, "text": " straight out of the box. And that tends to, to wake them up a little bit.", "tokens": [51668, 2997, 484, 295, 264, 2424, 13, 400, 300, 12258, 281, 11, 281, 6634, 552, 493, 257, 707, 857, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1322618538225201, "compression_ratio": 1.670731707317073, "no_speech_prob": 0.04268484562635422}, {"id": 596, "seek": 336184, "start": 3361.84, "end": 3366.8, "text": " You know, one thing I think is maybe going to become a mantra is, you know, the day that I", "tokens": [50364, 509, 458, 11, 472, 551, 286, 519, 307, 1310, 516, 281, 1813, 257, 32094, 307, 11, 291, 458, 11, 264, 786, 300, 286, 50612], "temperature": 0.0, "avg_logprob": -0.09523696136474609, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0011693080887198448}, {"id": 597, "seek": 336184, "start": 3366.8, "end": 3371.84, "text": " stop building apps or solving concrete problems in a hands on way is probably the day people should", "tokens": [50612, 1590, 2390, 7733, 420, 12606, 9859, 2740, 294, 257, 2377, 322, 636, 307, 1391, 264, 786, 561, 820, 50864], "temperature": 0.0, "avg_logprob": -0.09523696136474609, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0011693080887198448}, {"id": 598, "seek": 336184, "start": 3371.84, "end": 3378.48, "text": " stop listening to this show because, you know, that, that my knowledge will, will atrophy or", "tokens": [50864, 1590, 4764, 281, 341, 855, 570, 11, 291, 458, 11, 300, 11, 300, 452, 3601, 486, 11, 486, 412, 40826, 420, 51196], "temperature": 0.0, "avg_logprob": -0.09523696136474609, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0011693080887198448}, {"id": 599, "seek": 336184, "start": 3378.48, "end": 3384.8, "text": " will, will depreciate very quickly. So I do want to be hands on and certainly welcome those kinds", "tokens": [51196, 486, 11, 486, 40609, 473, 588, 2661, 13, 407, 286, 360, 528, 281, 312, 2377, 322, 293, 3297, 2928, 729, 3685, 51512], "temperature": 0.0, "avg_logprob": -0.09523696136474609, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0011693080887198448}, {"id": 600, "seek": 336184, "start": 3384.8, "end": 3390.8, "text": " of like, you know, hey, can we, we got this, you know, task piling up and we figure out a way to,", "tokens": [51512, 295, 411, 11, 291, 458, 11, 4177, 11, 393, 321, 11, 321, 658, 341, 11, 291, 458, 11, 5633, 280, 4883, 493, 293, 321, 2573, 484, 257, 636, 281, 11, 51812], "temperature": 0.0, "avg_logprob": -0.09523696136474609, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0011693080887198448}, {"id": 601, "seek": 339080, "start": 3390.8, "end": 3395.92, "text": " to slice through it. Love that, honestly. And then yeah, at the same time, I'm, I'm not really", "tokens": [50364, 281, 13153, 807, 309, 13, 5956, 300, 11, 6095, 13, 400, 550, 1338, 11, 412, 264, 912, 565, 11, 286, 478, 11, 286, 478, 406, 534, 50620], "temperature": 0.0, "avg_logprob": -0.08755969244336324, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.002322971122339368}, {"id": 602, "seek": 339080, "start": 3395.92, "end": 3403.28, "text": " like a corporate consultant. So I really don't have a lot of practice there. But I am trying to", "tokens": [50620, 411, 257, 10896, 24676, 13, 407, 286, 534, 500, 380, 362, 257, 688, 295, 3124, 456, 13, 583, 286, 669, 1382, 281, 50988], "temperature": 0.0, "avg_logprob": -0.08755969244336324, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.002322971122339368}, {"id": 603, "seek": 339080, "start": 3403.28, "end": 3407.84, "text": " start to piece together like, what would the real best practice for this looks like? And I think,", "tokens": [50988, 722, 281, 2522, 1214, 411, 11, 437, 576, 264, 957, 1151, 3124, 337, 341, 1542, 411, 30, 400, 286, 519, 11, 51216], "temperature": 0.0, "avg_logprob": -0.08755969244336324, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.002322971122339368}, {"id": 604, "seek": 339080, "start": 3407.84, "end": 3412.7200000000003, "text": " and you could refine this for me, I'm sure, but I kind of think leadership, showing prominent", "tokens": [51216, 293, 291, 727, 33906, 341, 337, 385, 11, 286, 478, 988, 11, 457, 286, 733, 295, 519, 5848, 11, 4099, 17034, 51460], "temperature": 0.0, "avg_logprob": -0.08755969244336324, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.002322971122339368}, {"id": 605, "seek": 339080, "start": 3412.7200000000003, "end": 3418.32, "text": " examples, you know, encouraging the CEO to be like showing off. Here's what I am doing, you know,", "tokens": [51460, 5110, 11, 291, 458, 11, 14580, 264, 9282, 281, 312, 411, 4099, 766, 13, 1692, 311, 437, 286, 669, 884, 11, 291, 458, 11, 51740], "temperature": 0.0, "avg_logprob": -0.08755969244336324, "compression_ratio": 1.6724738675958188, "no_speech_prob": 0.002322971122339368}, {"id": 606, "seek": 341832, "start": 3418.4, "end": 3423.1200000000003, "text": " that is helping me in practice and just showing that process in education program.", "tokens": [50368, 300, 307, 4315, 385, 294, 3124, 293, 445, 4099, 300, 1399, 294, 3309, 1461, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1038277514346011, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.016910970211029053}, {"id": 607, "seek": 341832, "start": 3423.1200000000003, "end": 3427.1200000000003, "text": " I think it's also probably very important. As you mentioned, having the best tools is really", "tokens": [50604, 286, 519, 309, 311, 611, 1391, 588, 1021, 13, 1018, 291, 2835, 11, 1419, 264, 1151, 3873, 307, 534, 50804], "temperature": 0.0, "avg_logprob": -0.1038277514346011, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.016910970211029053}, {"id": 608, "seek": 341832, "start": 3427.1200000000003, "end": 3434.1600000000003, "text": " important. So trying to work toward like structured, you know, kind of piloting strategies for companies", "tokens": [50804, 1021, 13, 407, 1382, 281, 589, 7361, 411, 18519, 11, 291, 458, 11, 733, 295, 9691, 278, 9029, 337, 3431, 51156], "temperature": 0.0, "avg_logprob": -0.1038277514346011, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.016910970211029053}, {"id": 609, "seek": 341832, "start": 3434.96, "end": 3439.6800000000003, "text": " that, you know, and also, and this is not good for my friends on the SaaS app side, but like,", "tokens": [51196, 300, 11, 291, 458, 11, 293, 611, 11, 293, 341, 307, 406, 665, 337, 452, 1855, 322, 264, 49733, 724, 1252, 11, 457, 411, 11, 51432], "temperature": 0.0, "avg_logprob": -0.1038277514346011, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.016910970211029053}, {"id": 610, "seek": 341832, "start": 3439.6800000000003, "end": 3445.1200000000003, "text": " my advice there is we want to avoid long term buy in or lock in as much as possible because", "tokens": [51432, 452, 5192, 456, 307, 321, 528, 281, 5042, 938, 1433, 2256, 294, 420, 4017, 294, 382, 709, 382, 1944, 570, 51704], "temperature": 0.0, "avg_logprob": -0.1038277514346011, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.016910970211029053}, {"id": 611, "seek": 344512, "start": 3445.12, "end": 3451.04, "text": " we're going to need to probably swap some of these tools out. And then, you know, some internal R&D,", "tokens": [50364, 321, 434, 516, 281, 643, 281, 1391, 18135, 512, 295, 613, 3873, 484, 13, 400, 550, 11, 291, 458, 11, 512, 6920, 497, 5, 35, 11, 50660], "temperature": 0.0, "avg_logprob": -0.06125763900407398, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.014501838013529778}, {"id": 612, "seek": 344512, "start": 3451.04, "end": 3456.08, "text": " depending on the resources available to kind of, you know, I think most of these things should be", "tokens": [50660, 5413, 322, 264, 3593, 2435, 281, 733, 295, 11, 291, 458, 11, 286, 519, 881, 295, 613, 721, 820, 312, 50912], "temperature": 0.0, "avg_logprob": -0.06125763900407398, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.014501838013529778}, {"id": 613, "seek": 344512, "start": 3456.08, "end": 3460.96, "text": " bought, not built internally, most of the time. But sometimes, you know, you have something that is", "tokens": [50912, 4243, 11, 406, 3094, 19501, 11, 881, 295, 264, 565, 13, 583, 2171, 11, 291, 458, 11, 291, 362, 746, 300, 307, 51156], "temperature": 0.0, "avg_logprob": -0.06125763900407398, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.014501838013529778}, {"id": 614, "seek": 344512, "start": 3461.52, "end": 3466.48, "text": " so idiosyncratic, so bespoke that you, you know, nobody's going to build it for you. And so you", "tokens": [51184, 370, 4496, 2717, 2534, 10757, 2399, 11, 370, 4097, 48776, 300, 291, 11, 291, 458, 11, 5079, 311, 516, 281, 1322, 309, 337, 291, 13, 400, 370, 291, 51432], "temperature": 0.0, "avg_logprob": -0.06125763900407398, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.014501838013529778}, {"id": 615, "seek": 344512, "start": 3466.48, "end": 3470.64, "text": " kind of have to build it yourself. And obviously, there's a lot of, you know, judgment that needs", "tokens": [51432, 733, 295, 362, 281, 1322, 309, 1803, 13, 400, 2745, 11, 456, 311, 257, 688, 295, 11, 291, 458, 11, 12216, 300, 2203, 51640], "temperature": 0.0, "avg_logprob": -0.06125763900407398, "compression_ratio": 1.8566037735849057, "no_speech_prob": 0.014501838013529778}, {"id": 616, "seek": 347064, "start": 3470.64, "end": 3475.2799999999997, "text": " to be exercised to, you know, to distinguish, which is which. So that's kind of my four", "tokens": [50364, 281, 312, 4057, 2640, 281, 11, 291, 458, 11, 281, 20206, 11, 597, 307, 597, 13, 407, 300, 311, 733, 295, 452, 1451, 50596], "temperature": 0.0, "avg_logprob": -0.12326655785242717, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.015416638925671577}, {"id": 617, "seek": 347064, "start": 3475.2799999999997, "end": 3482.96, "text": " planks right now. That's rough. But, you know, CEO or leadership team, example setting, education,", "tokens": [50596, 499, 14592, 558, 586, 13, 663, 311, 5903, 13, 583, 11, 291, 458, 11, 9282, 420, 5848, 1469, 11, 1365, 3287, 11, 3309, 11, 50980], "temperature": 0.0, "avg_logprob": -0.12326655785242717, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.015416638925671577}, {"id": 618, "seek": 347064, "start": 3482.96, "end": 3489.92, "text": " more like structured, rapid piloting and procurement and some like internal custom app", "tokens": [50980, 544, 411, 18519, 11, 7558, 9691, 278, 293, 35183, 293, 512, 411, 6920, 2375, 724, 51328], "temperature": 0.0, "avg_logprob": -0.12326655785242717, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.015416638925671577}, {"id": 619, "seek": 347064, "start": 3489.92, "end": 3495.92, "text": " R&D is kind of my four pillars at the moment. I mean, the challenge, you know, the challenge", "tokens": [51328, 497, 5, 35, 307, 733, 295, 452, 1451, 26729, 412, 264, 1623, 13, 286, 914, 11, 264, 3430, 11, 291, 458, 11, 264, 3430, 51628], "temperature": 0.0, "avg_logprob": -0.12326655785242717, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.015416638925671577}, {"id": 620, "seek": 349592, "start": 3495.92, "end": 3502.8, "text": " with disruption is that it is about, it's about meeting a need in a completely new way, right?", "tokens": [50364, 365, 28751, 307, 300, 309, 307, 466, 11, 309, 311, 466, 3440, 257, 643, 294, 257, 2584, 777, 636, 11, 558, 30, 50708], "temperature": 0.0, "avg_logprob": -0.10675182137438045, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.03726402297616005}, {"id": 621, "seek": 349592, "start": 3502.8, "end": 3508.0, "text": " And you've got, there's Clayton Christensen's model, there's also this idea of blue ocean strategy,", "tokens": [50708, 400, 291, 600, 658, 11, 456, 311, 21392, 1756, 2040, 32934, 311, 2316, 11, 456, 311, 611, 341, 1558, 295, 3344, 7810, 5206, 11, 50968], "temperature": 0.0, "avg_logprob": -0.10675182137438045, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.03726402297616005}, {"id": 622, "seek": 349592, "start": 3508.0, "end": 3513.28, "text": " which is a different model. And it effectively says that the things that people cared about,", "tokens": [50968, 597, 307, 257, 819, 2316, 13, 400, 309, 8659, 1619, 300, 264, 721, 300, 561, 19779, 466, 11, 51232], "temperature": 0.0, "avg_logprob": -0.10675182137438045, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.03726402297616005}, {"id": 623, "seek": 349592, "start": 3513.28, "end": 3519.84, "text": " they don't care about as much as some new attributes that the product has. And what's", "tokens": [51232, 436, 500, 380, 1127, 466, 382, 709, 382, 512, 777, 17212, 300, 264, 1674, 575, 13, 400, 437, 311, 51560], "temperature": 0.0, "avg_logprob": -0.10675182137438045, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.03726402297616005}, {"id": 624, "seek": 351984, "start": 3519.84, "end": 3526.96, "text": " really hard for any incumbent firm is, of course, all your internal culture has been about maximizing", "tokens": [50364, 534, 1152, 337, 604, 45539, 6174, 307, 11, 295, 1164, 11, 439, 428, 6920, 3713, 575, 668, 466, 5138, 3319, 50720], "temperature": 0.0, "avg_logprob": -0.09598635825790278, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.07907172292470932}, {"id": 625, "seek": 351984, "start": 3526.96, "end": 3530.96, "text": " what you have rather than what you don't have and what could be out there. Because it's really hard", "tokens": [50720, 437, 291, 362, 2831, 813, 437, 291, 500, 380, 362, 293, 437, 727, 312, 484, 456, 13, 1436, 309, 311, 534, 1152, 50920], "temperature": 0.0, "avg_logprob": -0.09598635825790278, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.07907172292470932}, {"id": 626, "seek": 351984, "start": 3530.96, "end": 3537.1200000000003, "text": " to get 20,000 people, 50,000 people motivated daily. If you're saying, hey, all the things you're", "tokens": [50920, 281, 483, 945, 11, 1360, 561, 11, 2625, 11, 1360, 561, 14515, 5212, 13, 759, 291, 434, 1566, 11, 4177, 11, 439, 264, 721, 291, 434, 51228], "temperature": 0.0, "avg_logprob": -0.09598635825790278, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.07907172292470932}, {"id": 627, "seek": 351984, "start": 3537.1200000000003, "end": 3541.6800000000003, "text": " working on are just not kind of that important because there's a blue ocean out there. And that's", "tokens": [51228, 1364, 322, 366, 445, 406, 733, 295, 300, 1021, 570, 456, 311, 257, 3344, 7810, 484, 456, 13, 400, 300, 311, 51456], "temperature": 0.0, "avg_logprob": -0.09598635825790278, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.07907172292470932}, {"id": 628, "seek": 351984, "start": 3541.6800000000003, "end": 3546.88, "text": " why I think the startup community and the venture community is such a kind of critical part of", "tokens": [51456, 983, 286, 519, 264, 18578, 1768, 293, 264, 18474, 1768, 307, 1270, 257, 733, 295, 4924, 644, 295, 51716], "temperature": 0.0, "avg_logprob": -0.09598635825790278, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.07907172292470932}, {"id": 629, "seek": 354688, "start": 3547.76, "end": 3553.6, "text": " getting innovation into economies. And we've started to see this in the car industry as well.", "tokens": [50408, 1242, 8504, 666, 23158, 13, 400, 321, 600, 1409, 281, 536, 341, 294, 264, 1032, 3518, 382, 731, 13, 50700], "temperature": 0.0, "avg_logprob": -0.10541668613400079, "compression_ratio": 1.6385135135135136, "no_speech_prob": 0.0056426976807415485}, {"id": 630, "seek": 354688, "start": 3553.6, "end": 3559.28, "text": " You know, Toyota has been winding back from EVs as if they ever wound forward. And one of the things", "tokens": [50700, 509, 458, 11, 22926, 575, 668, 29775, 646, 490, 15733, 82, 382, 498, 436, 1562, 10999, 2128, 13, 400, 472, 295, 264, 721, 50984], "temperature": 0.0, "avg_logprob": -0.10541668613400079, "compression_ratio": 1.6385135135135136, "no_speech_prob": 0.0056426976807415485}, {"id": 631, "seek": 354688, "start": 3559.28, "end": 3564.08, "text": " that senior execs said in the last couple of weeks was, we have all these employees who love", "tokens": [50984, 300, 7965, 4454, 82, 848, 294, 264, 1036, 1916, 295, 3259, 390, 11, 321, 362, 439, 613, 6619, 567, 959, 51224], "temperature": 0.0, "avg_logprob": -0.10541668613400079, "compression_ratio": 1.6385135135135136, "no_speech_prob": 0.0056426976807415485}, {"id": 632, "seek": 354688, "start": 3564.08, "end": 3568.56, "text": " building internal combustion engines, right? And they want to continue to do that. And of course,", "tokens": [51224, 2390, 6920, 28121, 12982, 11, 558, 30, 400, 436, 528, 281, 2354, 281, 360, 300, 13, 400, 295, 1164, 11, 51448], "temperature": 0.0, "avg_logprob": -0.10541668613400079, "compression_ratio": 1.6385135135135136, "no_speech_prob": 0.0056426976807415485}, {"id": 633, "seek": 354688, "start": 3568.56, "end": 3575.6, "text": " you make sense, you spent 100 years or 80 years building that cultural capital inside your company.", "tokens": [51448, 291, 652, 2020, 11, 291, 4418, 2319, 924, 420, 4688, 924, 2390, 300, 6988, 4238, 1854, 428, 2237, 13, 51800], "temperature": 0.0, "avg_logprob": -0.10541668613400079, "compression_ratio": 1.6385135135135136, "no_speech_prob": 0.0056426976807415485}, {"id": 634, "seek": 357560, "start": 3575.68, "end": 3582.08, "text": " And I think it's one of the reasons why firms really struggle to find ways of stepping into", "tokens": [50368, 400, 286, 519, 309, 311, 472, 295, 264, 4112, 983, 18055, 534, 7799, 281, 915, 2098, 295, 16821, 666, 50688], "temperature": 0.0, "avg_logprob": -0.07463883151527212, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0016399198211729527}, {"id": 635, "seek": 357560, "start": 3582.08, "end": 3586.96, "text": " disruption. And I'm not sure we should even beat them up for it, right? Because there's an economy", "tokens": [50688, 28751, 13, 400, 286, 478, 406, 988, 321, 820, 754, 4224, 552, 493, 337, 309, 11, 558, 30, 1436, 456, 311, 364, 5010, 50932], "temperature": 0.0, "avg_logprob": -0.07463883151527212, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0016399198211729527}, {"id": 636, "seek": 357560, "start": 3586.96, "end": 3591.2, "text": " out there. As shareholders of companies, we can sell our shares in a public company and we can buy", "tokens": [50932, 484, 456, 13, 1018, 33294, 295, 3431, 11, 321, 393, 3607, 527, 12182, 294, 257, 1908, 2237, 293, 321, 393, 2256, 51144], "temperature": 0.0, "avg_logprob": -0.07463883151527212, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0016399198211729527}, {"id": 637, "seek": 357560, "start": 3591.2, "end": 3595.44, "text": " shares in a company that's going to do well or not. And we can do that off our own back. And,", "tokens": [51144, 12182, 294, 257, 2237, 300, 311, 516, 281, 360, 731, 420, 406, 13, 400, 321, 393, 360, 300, 766, 527, 1065, 646, 13, 400, 11, 51356], "temperature": 0.0, "avg_logprob": -0.07463883151527212, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0016399198211729527}, {"id": 638, "seek": 357560, "start": 3596.08, "end": 3603.12, "text": " you know, maybe the job of existing managers is to focus on the remit of the company", "tokens": [51388, 291, 458, 11, 1310, 264, 1691, 295, 6741, 14084, 307, 281, 1879, 322, 264, 890, 270, 295, 264, 2237, 51740], "temperature": 0.0, "avg_logprob": -0.07463883151527212, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0016399198211729527}, {"id": 639, "seek": 360312, "start": 3603.12, "end": 3608.0, "text": " and to just get it to do it better. So maybe a better place to start is where you start,", "tokens": [50364, 293, 281, 445, 483, 309, 281, 360, 309, 1101, 13, 407, 1310, 257, 1101, 1081, 281, 722, 307, 689, 291, 722, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11200851505085574, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0047265528701245785}, {"id": 640, "seek": 360312, "start": 3608.0, "end": 3614.0, "text": " which is like just efficiencies and optimizations. Because there's a whole, there's a cold market", "tokens": [50608, 597, 307, 411, 445, 4703, 31294, 293, 5028, 14455, 13, 1436, 456, 311, 257, 1379, 11, 456, 311, 257, 3554, 2142, 50908], "temperature": 0.0, "avg_logprob": -0.11200851505085574, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0047265528701245785}, {"id": 641, "seek": 360312, "start": 3614.0, "end": 3618.56, "text": " economy out there of other firms who will come in and meet, you know, meet needs. I think back to", "tokens": [50908, 5010, 484, 456, 295, 661, 18055, 567, 486, 808, 294, 293, 1677, 11, 291, 458, 11, 1677, 2203, 13, 286, 519, 646, 281, 51136], "temperature": 0.0, "avg_logprob": -0.11200851505085574, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0047265528701245785}, {"id": 642, "seek": 360312, "start": 3618.56, "end": 3623.6, "text": " the dot com bubble. And my favorite example of a company stepping outside of its comfort zone was", "tokens": [51136, 264, 5893, 395, 12212, 13, 400, 452, 2954, 1365, 295, 257, 2237, 16821, 2380, 295, 1080, 3400, 6668, 390, 51388], "temperature": 0.0, "avg_logprob": -0.11200851505085574, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0047265528701245785}, {"id": 643, "seek": 360312, "start": 3623.6, "end": 3630.3199999999997, "text": " Zapata fish oils, who bought the domain zap.com to compete with what were then called portals", "tokens": [51388, 34018, 3274, 3506, 22177, 11, 567, 4243, 264, 9274, 14223, 13, 1112, 281, 11831, 365, 437, 645, 550, 1219, 2436, 1124, 51724], "temperature": 0.0, "avg_logprob": -0.11200851505085574, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0047265528701245785}, {"id": 644, "seek": 363032, "start": 3630.32, "end": 3634.32, "text": " like Yahoo and Excite and they were planning a, you know, a NASDAQ listing and then the bubble", "tokens": [50364, 411, 41757, 293, 9368, 642, 293, 436, 645, 5038, 257, 11, 291, 458, 11, 257, 10182, 7509, 48, 22161, 293, 550, 264, 12212, 50564], "temperature": 0.0, "avg_logprob": -0.1160187040056501, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.0008294912404380739}, {"id": 645, "seek": 363032, "start": 3634.32, "end": 3638.32, "text": " burst. Yeah, it's a challenge. I definitely don't recommend, you know, for example, like", "tokens": [50564, 12712, 13, 865, 11, 309, 311, 257, 3430, 13, 286, 2138, 500, 380, 2748, 11, 291, 458, 11, 337, 1365, 11, 411, 50764], "temperature": 0.0, "avg_logprob": -0.1160187040056501, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.0008294912404380739}, {"id": 646, "seek": 363032, "start": 3639.04, "end": 3643.52, "text": " trading foundation models to almost anyone, you know, there's there's definitely some stuff that", "tokens": [50800, 9529, 7030, 5245, 281, 1920, 2878, 11, 291, 458, 11, 456, 311, 456, 311, 2138, 512, 1507, 300, 51024], "temperature": 0.0, "avg_logprob": -0.1160187040056501, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.0008294912404380739}, {"id": 647, "seek": 363032, "start": 3643.52, "end": 3649.36, "text": " I think is is better left to the specialists. Hearing what you said there, maybe I would add", "tokens": [51024, 286, 519, 307, 307, 1101, 1411, 281, 264, 25476, 13, 37875, 437, 291, 848, 456, 11, 1310, 286, 576, 909, 51316], "temperature": 0.0, "avg_logprob": -0.1160187040056501, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.0008294912404380739}, {"id": 648, "seek": 363032, "start": 3649.36, "end": 3656.32, "text": " a fifth to my to my set, which is like just creating expectations of greater efficiency", "tokens": [51316, 257, 9266, 281, 452, 281, 452, 992, 11, 597, 307, 411, 445, 4084, 9843, 295, 5044, 10493, 51664], "temperature": 0.0, "avg_logprob": -0.1160187040056501, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.0008294912404380739}, {"id": 649, "seek": 365632, "start": 3656.32, "end": 3660.6400000000003, "text": " through the use of these tools. That kind of dovetails a little bit with the example setting", "tokens": [50364, 807, 264, 764, 295, 613, 3873, 13, 663, 733, 295, 360, 9771, 6227, 257, 707, 857, 365, 264, 1365, 3287, 50580], "temperature": 0.0, "avg_logprob": -0.08578354170342453, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.06007610633969307}, {"id": 650, "seek": 365632, "start": 3660.6400000000003, "end": 3666.48, "text": " from the top, but, and that maybe aligns a little bit better to the way management is typically", "tokens": [50580, 490, 264, 1192, 11, 457, 11, 293, 300, 1310, 7975, 82, 257, 707, 857, 1101, 281, 264, 636, 4592, 307, 5850, 50872], "temperature": 0.0, "avg_logprob": -0.08578354170342453, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.06007610633969307}, {"id": 651, "seek": 365632, "start": 3666.48, "end": 3671.36, "text": " carried out today, right? You kind of talked about the, the pincer movement from the top and,", "tokens": [50872, 9094, 484, 965, 11, 558, 30, 509, 733, 295, 2825, 466, 264, 11, 264, 5447, 1776, 3963, 490, 264, 1192, 293, 11, 51116], "temperature": 0.0, "avg_logprob": -0.08578354170342453, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.06007610633969307}, {"id": 652, "seek": 365632, "start": 3671.36, "end": 3676.0, "text": " you know, and obviously the frontline workers who are just using tools. And then in the middle,", "tokens": [51116, 291, 458, 11, 293, 2745, 264, 38033, 5600, 567, 366, 445, 1228, 3873, 13, 400, 550, 294, 264, 2808, 11, 51348], "temperature": 0.0, "avg_logprob": -0.08578354170342453, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.06007610633969307}, {"id": 653, "seek": 365632, "start": 3676.0, "end": 3681.6000000000004, "text": " you've got folks who are like responsible for KPIs and OKRs. And I think it's a little bit", "tokens": [51348, 291, 600, 658, 4024, 567, 366, 411, 6250, 337, 41371, 6802, 293, 2264, 49, 82, 13, 400, 286, 519, 309, 311, 257, 707, 857, 51628], "temperature": 0.0, "avg_logprob": -0.08578354170342453, "compression_ratio": 1.6931407942238268, "no_speech_prob": 0.06007610633969307}, {"id": 654, "seek": 368160, "start": 3681.6, "end": 3686.4, "text": " challenging sometimes to for them to be like, OK, I've got this is what I'm responsible for.", "tokens": [50364, 7595, 2171, 281, 337, 552, 281, 312, 411, 11, 2264, 11, 286, 600, 658, 341, 307, 437, 286, 478, 6250, 337, 13, 50604], "temperature": 0.0, "avg_logprob": -0.10659185208772358, "compression_ratio": 1.6761565836298933, "no_speech_prob": 0.015398107469081879}, {"id": 655, "seek": 368160, "start": 3686.4, "end": 3692.72, "text": " And you're coming at me with this and figuring out how they can actually use tools to, you know,", "tokens": [50604, 400, 291, 434, 1348, 412, 385, 365, 341, 293, 15213, 484, 577, 436, 393, 767, 764, 3873, 281, 11, 291, 458, 11, 50920], "temperature": 0.0, "avg_logprob": -0.10659185208772358, "compression_ratio": 1.6761565836298933, "no_speech_prob": 0.015398107469081879}, {"id": 656, "seek": 368160, "start": 3692.72, "end": 3698.08, "text": " to advance their existing goals. It's disruptive, not in the in the Christianson sense. I mean,", "tokens": [50920, 281, 7295, 641, 6741, 5493, 13, 467, 311, 37865, 11, 406, 294, 264, 294, 264, 12254, 266, 2020, 13, 286, 914, 11, 51188], "temperature": 0.0, "avg_logprob": -0.10659185208772358, "compression_ratio": 1.6761565836298933, "no_speech_prob": 0.015398107469081879}, {"id": 657, "seek": 368160, "start": 3698.08, "end": 3704.3199999999997, "text": " there is it's so there are so many conflicting signals. So one interesting question is whether", "tokens": [51188, 456, 307, 309, 311, 370, 456, 366, 370, 867, 43784, 12354, 13, 407, 472, 1880, 1168, 307, 1968, 51500], "temperature": 0.0, "avg_logprob": -0.10659185208772358, "compression_ratio": 1.6761565836298933, "no_speech_prob": 0.015398107469081879}, {"id": 658, "seek": 368160, "start": 3704.3199999999997, "end": 3708.56, "text": " you start to see this sort of downward pressure on people's wages and a downward pressure,", "tokens": [51500, 291, 722, 281, 536, 341, 1333, 295, 24805, 3321, 322, 561, 311, 20097, 293, 257, 24805, 3321, 11, 51712], "temperature": 0.0, "avg_logprob": -0.10659185208772358, "compression_ratio": 1.6761565836298933, "no_speech_prob": 0.015398107469081879}, {"id": 659, "seek": 370856, "start": 3708.56, "end": 3713.7599999999998, "text": " particularly on middle managers who don't necessarily contribute to the getting work done,", "tokens": [50364, 4098, 322, 2808, 14084, 567, 500, 380, 4725, 10586, 281, 264, 1242, 589, 1096, 11, 50624], "temperature": 0.0, "avg_logprob": -0.11804955581138873, "compression_ratio": 1.5390946502057614, "no_speech_prob": 0.016338465735316277}, {"id": 660, "seek": 370856, "start": 3713.7599999999998, "end": 3719.36, "text": " but because of tenure are quite well paid and the sense that you could just get a bright 30 year", "tokens": [50624, 457, 570, 295, 32256, 366, 1596, 731, 4835, 293, 264, 2020, 300, 291, 727, 445, 483, 257, 4730, 2217, 1064, 50904], "temperature": 0.0, "avg_logprob": -0.11804955581138873, "compression_ratio": 1.5390946502057614, "no_speech_prob": 0.016338465735316277}, {"id": 661, "seek": 370856, "start": 3719.36, "end": 3724.96, "text": " old right to do the 40 year old's job if you gave them chat, GPT and a couple of other tools.", "tokens": [50904, 1331, 558, 281, 360, 264, 3356, 1064, 1331, 311, 1691, 498, 291, 2729, 552, 5081, 11, 26039, 51, 293, 257, 1916, 295, 661, 3873, 13, 51184], "temperature": 0.0, "avg_logprob": -0.11804955581138873, "compression_ratio": 1.5390946502057614, "no_speech_prob": 0.016338465735316277}, {"id": 662, "seek": 370856, "start": 3724.96, "end": 3730.48, "text": " And these are really interesting questions, I think that will play out in companies over the", "tokens": [51184, 400, 613, 366, 534, 1880, 1651, 11, 286, 519, 300, 486, 862, 484, 294, 3431, 670, 264, 51460], "temperature": 0.0, "avg_logprob": -0.11804955581138873, "compression_ratio": 1.5390946502057614, "no_speech_prob": 0.016338465735316277}, {"id": 663, "seek": 373048, "start": 3730.48, "end": 3740.16, "text": " next few years. And we are we're not quite where we were, I think kind of politically 20 years ago", "tokens": [50364, 958, 1326, 924, 13, 400, 321, 366, 321, 434, 406, 1596, 689, 321, 645, 11, 286, 519, 733, 295, 21154, 945, 924, 2057, 50848], "temperature": 0.0, "avg_logprob": -0.11853709428206734, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.3487267792224884}, {"id": 664, "seek": 373048, "start": 3740.16, "end": 3744.8, "text": " when a general electric could kind of just come in and bottom slice headcount all the time. I mean,", "tokens": [50848, 562, 257, 2674, 5210, 727, 733, 295, 445, 808, 294, 293, 2767, 13153, 1378, 26050, 439, 264, 565, 13, 286, 914, 11, 51080], "temperature": 0.0, "avg_logprob": -0.11853709428206734, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.3487267792224884}, {"id": 665, "seek": 373048, "start": 3744.8, "end": 3750.56, "text": " I think that that politically in in the UK and in the US, you need to be more sensitive", "tokens": [51080, 286, 519, 300, 300, 21154, 294, 294, 264, 7051, 293, 294, 264, 2546, 11, 291, 643, 281, 312, 544, 9477, 51368], "temperature": 0.0, "avg_logprob": -0.11853709428206734, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.3487267792224884}, {"id": 666, "seek": 373048, "start": 3750.56, "end": 3758.16, "text": " to those types of decisions. But it just goes into to show how complicated this technology", "tokens": [51368, 281, 729, 3467, 295, 5327, 13, 583, 309, 445, 1709, 666, 281, 855, 577, 6179, 341, 2899, 51748], "temperature": 0.0, "avg_logprob": -0.11853709428206734, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.3487267792224884}, {"id": 667, "seek": 375816, "start": 3758.16, "end": 3765.2799999999997, "text": " plays out, right, small disruption. You know, are we really going to see large scale onshore", "tokens": [50364, 5749, 484, 11, 558, 11, 1359, 28751, 13, 509, 458, 11, 366, 321, 534, 516, 281, 536, 2416, 4373, 322, 27195, 50720], "temperature": 0.0, "avg_logprob": -0.13898194220758253, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.012595327571034431}, {"id": 668, "seek": 375816, "start": 3766.48, "end": 3772.3999999999996, "text": " layoffs because of optimization? Or will companies say, Listen, we're going to manage this through", "tokens": [50780, 2360, 19231, 570, 295, 19618, 30, 1610, 486, 3431, 584, 11, 7501, 11, 321, 434, 516, 281, 3067, 341, 807, 51076], "temperature": 0.0, "avg_logprob": -0.13898194220758253, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.012595327571034431}, {"id": 669, "seek": 375816, "start": 3772.3999999999996, "end": 3779.44, "text": " attrition and natural wastage, because actually, that's just politically more acceptable and it", "tokens": [51076, 951, 32938, 293, 3303, 49075, 609, 11, 570, 767, 11, 300, 311, 445, 21154, 544, 15513, 293, 309, 51428], "temperature": 0.0, "avg_logprob": -0.13898194220758253, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.012595327571034431}, {"id": 670, "seek": 375816, "start": 3779.44, "end": 3784.3999999999996, "text": " is culturally more acceptable. And, you know, to that extent, I couldn't make a bet on on how it", "tokens": [51428, 307, 28879, 544, 15513, 13, 400, 11, 291, 458, 11, 281, 300, 8396, 11, 286, 2809, 380, 652, 257, 778, 322, 322, 577, 309, 51676], "temperature": 0.0, "avg_logprob": -0.13898194220758253, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.012595327571034431}, {"id": 671, "seek": 378440, "start": 3784.4, "end": 3790.64, "text": " would would play out. I mean, I imagine that in, you know, in Europe, it'll be largely be more", "tokens": [50364, 576, 576, 862, 484, 13, 286, 914, 11, 286, 3811, 300, 294, 11, 291, 458, 11, 294, 3315, 11, 309, 603, 312, 11611, 312, 544, 50676], "temperature": 0.0, "avg_logprob": -0.11663265991210937, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.020387187600135803}, {"id": 672, "seek": 378440, "start": 3790.64, "end": 3797.04, "text": " slow. But at the end of the day, these companies have to be profitable and nothing hurts employment", "tokens": [50676, 2964, 13, 583, 412, 264, 917, 295, 264, 786, 11, 613, 3431, 362, 281, 312, 21608, 293, 1825, 11051, 11949, 50996], "temperature": 0.0, "avg_logprob": -0.11663265991210937, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.020387187600135803}, {"id": 673, "seek": 378440, "start": 3797.04, "end": 3802.7200000000003, "text": " as hard as bankruptcy. Right. I mean, that's the thing that really, really sort of slams it. And", "tokens": [50996, 382, 1152, 382, 33457, 13, 1779, 13, 286, 914, 11, 300, 311, 264, 551, 300, 534, 11, 534, 1333, 295, 1061, 4070, 309, 13, 400, 51280], "temperature": 0.0, "avg_logprob": -0.11663265991210937, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.020387187600135803}, {"id": 674, "seek": 378440, "start": 3802.7200000000003, "end": 3807.28, "text": " I mean, there are a number of waves, you know, coming through. And I think one of the things to", "tokens": [51280, 286, 914, 11, 456, 366, 257, 1230, 295, 9417, 11, 291, 458, 11, 1348, 807, 13, 400, 286, 519, 472, 295, 264, 721, 281, 51508], "temperature": 0.0, "avg_logprob": -0.11663265991210937, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.020387187600135803}, {"id": 675, "seek": 378440, "start": 3807.28, "end": 3812.64, "text": " understand is is that the technology transitions can happen really, really quickly. I mean, it,", "tokens": [51508, 1223, 307, 307, 300, 264, 2899, 23767, 393, 1051, 534, 11, 534, 2661, 13, 286, 914, 11, 309, 11, 51776], "temperature": 0.0, "avg_logprob": -0.11663265991210937, "compression_ratio": 1.743682310469314, "no_speech_prob": 0.020387187600135803}, {"id": 676, "seek": 381264, "start": 3813.2799999999997, "end": 3821.92, "text": " you know, in New York and Chicago, it took about 12 to 14 years for cars to replace horses from the", "tokens": [50396, 291, 458, 11, 294, 1873, 3609, 293, 9525, 11, 309, 1890, 466, 2272, 281, 3499, 924, 337, 5163, 281, 7406, 13112, 490, 264, 50828], "temperature": 0.0, "avg_logprob": -0.10826395845961297, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.000784958538133651}, {"id": 677, "seek": 381264, "start": 3821.92, "end": 3827.68, "text": " moment that cars were economically competitive to horses, and you which is roughly about 5% market", "tokens": [50828, 1623, 300, 5163, 645, 26811, 10043, 281, 13112, 11, 293, 291, 597, 307, 9810, 466, 1025, 4, 2142, 51116], "temperature": 0.0, "avg_logprob": -0.10826395845961297, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.000784958538133651}, {"id": 678, "seek": 381264, "start": 3827.68, "end": 3834.72, "text": " penetration. They dropped in price two or three times over that decade or so. And we start to see", "tokens": [51116, 35187, 13, 814, 8119, 294, 3218, 732, 420, 1045, 1413, 670, 300, 10378, 420, 370, 13, 400, 321, 722, 281, 536, 51468], "temperature": 0.0, "avg_logprob": -0.10826395845961297, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.000784958538133651}, {"id": 679, "seek": 381264, "start": 3834.72, "end": 3839.3599999999997, "text": " that shortened, shortened transition happen elsewhere. So if you look at electric vehicles", "tokens": [51468, 300, 45183, 11, 45183, 6034, 1051, 14517, 13, 407, 498, 291, 574, 412, 5210, 8948, 51700], "temperature": 0.0, "avg_logprob": -0.10826395845961297, "compression_ratio": 1.5542168674698795, "no_speech_prob": 0.000784958538133651}, {"id": 680, "seek": 383936, "start": 3839.44, "end": 3846.08, "text": " replacing gas gas vehicles, in Norway, it's taken about nine years to go from that 5% of new vehicles", "tokens": [50368, 19139, 4211, 4211, 8948, 11, 294, 24354, 11, 309, 311, 2726, 466, 4949, 924, 281, 352, 490, 300, 1025, 4, 295, 777, 8948, 50700], "temperature": 0.0, "avg_logprob": -0.10960638427734375, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.011051274836063385}, {"id": 681, "seek": 383936, "start": 3846.08, "end": 3852.1600000000003, "text": " to 75% or 80% of new vehicles being electric. It means it's still 20% of the cars on the road,", "tokens": [50700, 281, 9562, 4, 420, 4688, 4, 295, 777, 8948, 885, 5210, 13, 467, 1355, 309, 311, 920, 945, 4, 295, 264, 5163, 322, 264, 3060, 11, 51004], "temperature": 0.0, "avg_logprob": -0.10960638427734375, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.011051274836063385}, {"id": 682, "seek": 383936, "start": 3852.1600000000003, "end": 3856.56, "text": " only 20% of the cars on the road are electric and the rest are petrol because people hold on to their", "tokens": [51004, 787, 945, 4, 295, 264, 5163, 322, 264, 3060, 366, 5210, 293, 264, 1472, 366, 32377, 570, 561, 1797, 322, 281, 641, 51224], "temperature": 0.0, "avg_logprob": -0.10960638427734375, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.011051274836063385}, {"id": 683, "seek": 383936, "start": 3856.56, "end": 3860.96, "text": " cars for a while. But it's only an eight or nine year period. And the Norwegians had much more", "tokens": [51224, 5163, 337, 257, 1339, 13, 583, 309, 311, 787, 364, 3180, 420, 4949, 1064, 2896, 13, 400, 264, 31783, 2567, 632, 709, 544, 51444], "temperature": 0.0, "avg_logprob": -0.10960638427734375, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.011051274836063385}, {"id": 684, "seek": 383936, "start": 3860.96, "end": 3865.92, "text": " expensive cars and far fewer choices than we do today. So when we start to look at this", "tokens": [51444, 5124, 5163, 293, 1400, 13366, 7994, 813, 321, 360, 965, 13, 407, 562, 321, 722, 281, 574, 412, 341, 51692], "temperature": 0.0, "avg_logprob": -0.10960638427734375, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.011051274836063385}, {"id": 685, "seek": 386592, "start": 3866.64, "end": 3873.6800000000003, "text": " sticcato of technology enabled products coming into the market, the number we need to think about is", "tokens": [50400, 342, 299, 66, 2513, 295, 2899, 15172, 3383, 1348, 666, 264, 2142, 11, 264, 1230, 321, 643, 281, 519, 466, 307, 50752], "temperature": 0.0, "avg_logprob": -0.09783541637918224, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.007076257839798927}, {"id": 686, "seek": 386592, "start": 3874.4, "end": 3881.84, "text": " once we approach economic feasibility, that takeoff ramp from five or 6% penetration to 80,", "tokens": [50788, 1564, 321, 3109, 4836, 21781, 2841, 11, 300, 747, 4506, 12428, 490, 1732, 420, 1386, 4, 35187, 281, 4688, 11, 51160], "temperature": 0.0, "avg_logprob": -0.09783541637918224, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.007076257839798927}, {"id": 687, "seek": 386592, "start": 3881.84, "end": 3885.84, "text": " you know, it's probably not going to be 10 years. And it's like quite likely to be", "tokens": [51160, 291, 458, 11, 309, 311, 1391, 406, 516, 281, 312, 1266, 924, 13, 400, 309, 311, 411, 1596, 3700, 281, 312, 51360], "temperature": 0.0, "avg_logprob": -0.09783541637918224, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.007076257839798927}, {"id": 688, "seek": 386592, "start": 3885.84, "end": 3891.04, "text": " much, much less. And I think that makes for really hard decisions for companies outside of the tech", "tokens": [51360, 709, 11, 709, 1570, 13, 400, 286, 519, 300, 1669, 337, 534, 1152, 5327, 337, 3431, 2380, 295, 264, 7553, 51620], "temperature": 0.0, "avg_logprob": -0.09783541637918224, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.007076257839798927}, {"id": 689, "seek": 389104, "start": 3891.04, "end": 3897.2799999999997, "text": " industry that are not used to these sorts of changes, because 10 years is not really a huge", "tokens": [50364, 3518, 300, 366, 406, 1143, 281, 613, 7527, 295, 2962, 11, 570, 1266, 924, 307, 406, 534, 257, 2603, 50676], "temperature": 0.0, "avg_logprob": -0.08610047331643761, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.033554524183273315}, {"id": 690, "seek": 389104, "start": 3897.2799999999997, "end": 3900.96, "text": " amount of time to get to get anything done. I mean, some of these firms still have three or", "tokens": [50676, 2372, 295, 565, 281, 483, 281, 483, 1340, 1096, 13, 286, 914, 11, 512, 295, 613, 18055, 920, 362, 1045, 420, 50860], "temperature": 0.0, "avg_logprob": -0.08610047331643761, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.033554524183273315}, {"id": 691, "seek": 389104, "start": 3900.96, "end": 3907.04, "text": " five year planning cycles. And I think that some of those things are just starting to play out.", "tokens": [50860, 1732, 1064, 5038, 17796, 13, 400, 286, 519, 300, 512, 295, 729, 721, 366, 445, 2891, 281, 862, 484, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08610047331643761, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.033554524183273315}, {"id": 692, "seek": 389104, "start": 3907.04, "end": 3912.24, "text": " We're just starting to see electric vehicles being cost competitive over the life cycle with", "tokens": [51164, 492, 434, 445, 2891, 281, 536, 5210, 8948, 885, 2063, 10043, 670, 264, 993, 6586, 365, 51424], "temperature": 0.0, "avg_logprob": -0.08610047331643761, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.033554524183273315}, {"id": 693, "seek": 389104, "start": 3912.24, "end": 3916.8, "text": " gas cars in the US, for example. The speed of transition, I agree, seems likely to be", "tokens": [51424, 4211, 5163, 294, 264, 2546, 11, 337, 1365, 13, 440, 3073, 295, 6034, 11, 286, 3986, 11, 2544, 3700, 281, 312, 51652], "temperature": 0.0, "avg_logprob": -0.08610047331643761, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.033554524183273315}, {"id": 694, "seek": 391680, "start": 3917.6000000000004, "end": 3924.32, "text": " one of the fastest, if not the fastest in history. We have the means of distribution of the technology", "tokens": [50404, 472, 295, 264, 14573, 11, 498, 406, 264, 14573, 294, 2503, 13, 492, 362, 264, 1355, 295, 7316, 295, 264, 2899, 50740], "temperature": 0.0, "avg_logprob": -0.10312733598934706, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.0055539486929774284}, {"id": 695, "seek": 391680, "start": 3924.32, "end": 3928.8, "text": " already kind of in place, which is very notable, right? Like everybody's already got the devices", "tokens": [50740, 1217, 733, 295, 294, 1081, 11, 597, 307, 588, 22556, 11, 558, 30, 1743, 2201, 311, 1217, 658, 264, 5759, 50964], "temperature": 0.0, "avg_logprob": -0.10312733598934706, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.0055539486929774284}, {"id": 696, "seek": 391680, "start": 3928.8, "end": 3934.0, "text": " on which, of course, there may be new devices, but we have devices that are perfectly good for", "tokens": [50964, 322, 597, 11, 295, 1164, 11, 456, 815, 312, 777, 5759, 11, 457, 321, 362, 5759, 300, 366, 6239, 665, 337, 51224], "temperature": 0.0, "avg_logprob": -0.10312733598934706, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.0055539486929774284}, {"id": 697, "seek": 391680, "start": 3934.0, "end": 3942.5600000000004, "text": " using AI already. And we have the global network such that you see a new research paper, the one", "tokens": [51224, 1228, 7318, 1217, 13, 400, 321, 362, 264, 4338, 3209, 1270, 300, 291, 536, 257, 777, 2132, 3035, 11, 264, 472, 51652], "temperature": 0.0, "avg_logprob": -0.10312733598934706, "compression_ratio": 1.6853448275862069, "no_speech_prob": 0.0055539486929774284}, {"id": 698, "seek": 394256, "start": 3942.56, "end": 3948.7999999999997, "text": " I'm tracking right now very closely is the Mamba architecture, and just how quickly we're already", "tokens": [50364, 286, 478, 11603, 558, 586, 588, 8185, 307, 264, 376, 23337, 9482, 11, 293, 445, 577, 2661, 321, 434, 1217, 50676], "temperature": 0.0, "avg_logprob": -0.1097000717023097, "compression_ratio": 1.5635179153094463, "no_speech_prob": 0.026748856529593468}, {"id": 699, "seek": 394256, "start": 3948.7999999999997, "end": 3953.2799999999997, "text": " seeing follow on research, not even 60 days since the first paper. We've already got probably 10", "tokens": [50676, 2577, 1524, 322, 2132, 11, 406, 754, 4060, 1708, 1670, 264, 700, 3035, 13, 492, 600, 1217, 658, 1391, 1266, 50900], "temperature": 0.0, "avg_logprob": -0.1097000717023097, "compression_ratio": 1.5635179153094463, "no_speech_prob": 0.026748856529593468}, {"id": 700, "seek": 394256, "start": 3953.2799999999997, "end": 3958.96, "text": " different follow ons that have been completed and published just in that timeframe. The most", "tokens": [50900, 819, 1524, 18818, 300, 362, 668, 7365, 293, 6572, 445, 294, 300, 34830, 13, 440, 881, 51184], "temperature": 0.0, "avg_logprob": -0.1097000717023097, "compression_ratio": 1.5635179153094463, "no_speech_prob": 0.026748856529593468}, {"id": 701, "seek": 394256, "start": 3958.96, "end": 3963.68, "text": " recent I saw this morning is from the University of Kentucky. And it's like an apparently Chinese", "tokens": [51184, 5162, 286, 1866, 341, 2446, 307, 490, 264, 3535, 295, 22369, 13, 400, 309, 311, 411, 364, 7970, 4649, 51420], "temperature": 0.0, "avg_logprob": -0.1097000717023097, "compression_ratio": 1.5635179153094463, "no_speech_prob": 0.026748856529593468}, {"id": 702, "seek": 394256, "start": 3963.68, "end": 3969.84, "text": " American professor. And it looked like a, I'm not exactly sure, but some sort of Central Asia,", "tokens": [51420, 2665, 8304, 13, 400, 309, 2956, 411, 257, 11, 286, 478, 406, 2293, 988, 11, 457, 512, 1333, 295, 9701, 10038, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1097000717023097, "compression_ratio": 1.5635179153094463, "no_speech_prob": 0.026748856529593468}, {"id": 703, "seek": 396984, "start": 3969.84, "end": 3975.52, "text": " perhaps name for the grad student. And they're at the University of Kentucky, and it's like,", "tokens": [50364, 4317, 1315, 337, 264, 2771, 3107, 13, 400, 436, 434, 412, 264, 3535, 295, 22369, 11, 293, 309, 311, 411, 11, 50648], "temperature": 0.0, "avg_logprob": -0.12243154131132981, "compression_ratio": 1.657243816254417, "no_speech_prob": 0.004330921918153763}, {"id": 704, "seek": 396984, "start": 3975.52, "end": 3983.36, "text": " well, everybody is wired in. So it seems like this is going to be super fast. How path dependent", "tokens": [50648, 731, 11, 2201, 307, 27415, 294, 13, 407, 309, 2544, 411, 341, 307, 516, 281, 312, 1687, 2370, 13, 1012, 3100, 12334, 51040], "temperature": 0.0, "avg_logprob": -0.12243154131132981, "compression_ratio": 1.657243816254417, "no_speech_prob": 0.004330921918153763}, {"id": 705, "seek": 396984, "start": 3984.1600000000003, "end": 3990.8, "text": " do you think the result ultimately is? You mentioned your place where you live, it was fields,", "tokens": [51080, 360, 291, 519, 264, 1874, 6284, 307, 30, 509, 2835, 428, 1081, 689, 291, 1621, 11, 309, 390, 7909, 11, 51412], "temperature": 0.0, "avg_logprob": -0.12243154131132981, "compression_ratio": 1.657243816254417, "no_speech_prob": 0.004330921918153763}, {"id": 706, "seek": 396984, "start": 3990.8, "end": 3993.84, "text": " then the roads were made, and now the roads are still there, and the houses are still there.", "tokens": [51412, 550, 264, 11344, 645, 1027, 11, 293, 586, 264, 11344, 366, 920, 456, 11, 293, 264, 8078, 366, 920, 456, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12243154131132981, "compression_ratio": 1.657243816254417, "no_speech_prob": 0.004330921918153763}, {"id": 707, "seek": 396984, "start": 3993.84, "end": 3999.04, "text": " This is like a softer technology than that, presumably doesn't calcify in the same way that", "tokens": [51564, 639, 307, 411, 257, 23119, 2899, 813, 300, 11, 26742, 1177, 380, 2104, 66, 2505, 294, 264, 912, 636, 300, 51824], "temperature": 0.0, "avg_logprob": -0.12243154131132981, "compression_ratio": 1.657243816254417, "no_speech_prob": 0.004330921918153763}, {"id": 708, "seek": 399904, "start": 3999.04, "end": 4003.44, "text": " a new neighborhood, you know, my neighbor, it's 100 years old as well. So presumably it's not", "tokens": [50364, 257, 777, 7630, 11, 291, 458, 11, 452, 5987, 11, 309, 311, 2319, 924, 1331, 382, 731, 13, 407, 26742, 309, 311, 406, 50584], "temperature": 0.0, "avg_logprob": -0.12655815192028486, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0016472632996737957}, {"id": 709, "seek": 399904, "start": 4003.44, "end": 4010.16, "text": " quite so locked in, but, you know, maybe somewhat, right? I mean, I do wonder how the sort of", "tokens": [50584, 1596, 370, 9376, 294, 11, 457, 11, 291, 458, 11, 1310, 8344, 11, 558, 30, 286, 914, 11, 286, 360, 2441, 577, 264, 1333, 295, 50920], "temperature": 0.0, "avg_logprob": -0.12655815192028486, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0016472632996737957}, {"id": 710, "seek": 399904, "start": 4011.12, "end": 4014.88, "text": " compressed dynamics of transition may actually be like very important for shaping the", "tokens": [50968, 30353, 15679, 295, 6034, 815, 767, 312, 411, 588, 1021, 337, 25945, 264, 51156], "temperature": 0.0, "avg_logprob": -0.12655815192028486, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0016472632996737957}, {"id": 711, "seek": 399904, "start": 4015.52, "end": 4021.12, "text": " big picture future. It is quite path dependent. And if we actually perhaps look at how", "tokens": [51188, 955, 3036, 2027, 13, 467, 307, 1596, 3100, 12334, 13, 400, 498, 321, 767, 4317, 574, 412, 577, 51468], "temperature": 0.0, "avg_logprob": -0.12655815192028486, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0016472632996737957}, {"id": 712, "seek": 399904, "start": 4021.7599999999998, "end": 4027.36, "text": " we're working with AI systems today, it is still in a way it's discrete apps, you know,", "tokens": [51500, 321, 434, 1364, 365, 7318, 3652, 965, 11, 309, 307, 920, 294, 257, 636, 309, 311, 27706, 7733, 11, 291, 458, 11, 51780], "temperature": 0.0, "avg_logprob": -0.12655815192028486, "compression_ratio": 1.6115107913669064, "no_speech_prob": 0.0016472632996737957}, {"id": 713, "seek": 402736, "start": 4027.36, "end": 4033.44, "text": " you'll go to X product to do your text to video, Waymark is a great example, or you'll go to,", "tokens": [50364, 291, 603, 352, 281, 1783, 1674, 281, 360, 428, 2487, 281, 960, 11, 9558, 5638, 307, 257, 869, 1365, 11, 420, 291, 603, 352, 281, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14348214770120288, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.0035674890968948603}, {"id": 714, "seek": 402736, "start": 4033.44, "end": 4038.1600000000003, "text": " I go to chat gpt, and although I'm doing a lot of different things in chat gpt or perplexity,", "tokens": [50668, 286, 352, 281, 5081, 290, 662, 11, 293, 4878, 286, 478, 884, 257, 688, 295, 819, 721, 294, 5081, 290, 662, 420, 680, 18945, 507, 11, 50904], "temperature": 0.0, "avg_logprob": -0.14348214770120288, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.0035674890968948603}, {"id": 715, "seek": 402736, "start": 4038.1600000000003, "end": 4042.48, "text": " each one really feels quite distinct, right? Whether it's a shopping task or a research task.", "tokens": [50904, 1184, 472, 534, 3417, 1596, 10644, 11, 558, 30, 8503, 309, 311, 257, 8688, 5633, 420, 257, 2132, 5633, 13, 51120], "temperature": 0.0, "avg_logprob": -0.14348214770120288, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.0035674890968948603}, {"id": 716, "seek": 402736, "start": 4043.2000000000003, "end": 4049.6, "text": " What we haven't yet figured out is actually how we connect these systems to underlying systems,", "tokens": [51156, 708, 321, 2378, 380, 1939, 8932, 484, 307, 767, 577, 321, 1745, 613, 3652, 281, 14217, 3652, 11, 51476], "temperature": 0.0, "avg_logprob": -0.14348214770120288, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.0035674890968948603}, {"id": 717, "seek": 402736, "start": 4049.6, "end": 4056.48, "text": " right? So action models in a way, right? How do we get our AI to do something useful for us and", "tokens": [51476, 558, 30, 407, 3069, 5245, 294, 257, 636, 11, 558, 30, 1012, 360, 321, 483, 527, 7318, 281, 360, 746, 4420, 337, 505, 293, 51820], "temperature": 0.0, "avg_logprob": -0.14348214770120288, "compression_ratio": 1.6480836236933798, "no_speech_prob": 0.0035674890968948603}, {"id": 718, "seek": 405648, "start": 4056.48, "end": 4063.04, "text": " actually write to the point of giving us the approval ticket where we say, yes, go and do that.", "tokens": [50364, 767, 2464, 281, 264, 935, 295, 2902, 505, 264, 13317, 10550, 689, 321, 584, 11, 2086, 11, 352, 293, 360, 300, 13, 50692], "temperature": 0.0, "avg_logprob": -0.14914992332458496, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.001155041973106563}, {"id": 719, "seek": 405648, "start": 4063.6, "end": 4070.0, "text": " And we're we're fudging it at the moment because what we're doing is we're getting plugins into", "tokens": [50720, 400, 321, 434, 321, 434, 283, 532, 3249, 309, 412, 264, 1623, 570, 437, 321, 434, 884, 307, 321, 434, 1242, 33759, 666, 51040], "temperature": 0.0, "avg_logprob": -0.14914992332458496, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.001155041973106563}, {"id": 720, "seek": 405648, "start": 4070.0, "end": 4076.64, "text": " LLMs, they're using the existing API contract that exists with say the kayak API. But, you know,", "tokens": [51040, 441, 43, 26386, 11, 436, 434, 1228, 264, 6741, 9362, 4364, 300, 8198, 365, 584, 264, 22438, 9362, 13, 583, 11, 291, 458, 11, 51372], "temperature": 0.0, "avg_logprob": -0.14914992332458496, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.001155041973106563}, {"id": 721, "seek": 405648, "start": 4076.64, "end": 4083.2, "text": " searching for flights on any of these AI systems that I've tried and I've tried a few is still", "tokens": [51372, 10808, 337, 21089, 322, 604, 295, 613, 7318, 3652, 300, 286, 600, 3031, 293, 286, 600, 3031, 257, 1326, 307, 920, 51700], "temperature": 0.0, "avg_logprob": -0.14914992332458496, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.001155041973106563}, {"id": 722, "seek": 408320, "start": 4083.2, "end": 4088.7999999999997, "text": " simply not as good as my doing it by hand on on kayak. And if we're going to start to see real", "tokens": [50364, 2935, 406, 382, 665, 382, 452, 884, 309, 538, 1011, 322, 322, 22438, 13, 400, 498, 321, 434, 516, 281, 722, 281, 536, 957, 50644], "temperature": 0.0, "avg_logprob": -0.11898802602013876, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0030920200515538454}, {"id": 723, "seek": 408320, "start": 4089.3599999999997, "end": 4096.4, "text": " changes outside of either highly processized and containerized jobs in data processing and", "tokens": [50672, 2962, 2380, 295, 2139, 5405, 1399, 1602, 293, 10129, 1602, 4782, 294, 1412, 9007, 293, 51024], "temperature": 0.0, "avg_logprob": -0.11898802602013876, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0030920200515538454}, {"id": 724, "seek": 408320, "start": 4096.4, "end": 4102.32, "text": " customer service or broad open end scoping research, which only a handful of people do,", "tokens": [51024, 5474, 2643, 420, 4152, 1269, 917, 795, 26125, 2132, 11, 597, 787, 257, 16458, 295, 561, 360, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11898802602013876, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0030920200515538454}, {"id": 725, "seek": 408320, "start": 4103.04, "end": 4110.4, "text": " will need to connect far better to actions and chains of actions in out on the internet. And", "tokens": [51356, 486, 643, 281, 1745, 1400, 1101, 281, 5909, 293, 12626, 295, 5909, 294, 484, 322, 264, 4705, 13, 400, 51724], "temperature": 0.0, "avg_logprob": -0.11898802602013876, "compression_ratio": 1.6123348017621146, "no_speech_prob": 0.0030920200515538454}, {"id": 726, "seek": 411040, "start": 4111.36, "end": 4116.08, "text": " in a way, there is some infrastructure in place because we have, you know, restful APIs, we have", "tokens": [50412, 294, 257, 636, 11, 456, 307, 512, 6896, 294, 1081, 570, 321, 362, 11, 291, 458, 11, 1472, 906, 21445, 11, 321, 362, 50648], "temperature": 0.0, "avg_logprob": -0.08607459863026937, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.00025918649043887854}, {"id": 727, "seek": 411040, "start": 4116.08, "end": 4121.28, "text": " this API economy and, you know, we've been integrating these things from payment systems to", "tokens": [50648, 341, 9362, 5010, 293, 11, 291, 458, 11, 321, 600, 668, 26889, 613, 721, 490, 10224, 3652, 281, 50908], "temperature": 0.0, "avg_logprob": -0.08607459863026937, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.00025918649043887854}, {"id": 728, "seek": 411040, "start": 4121.28, "end": 4127.44, "text": " maps and so on for a couple of decades now. So there's some some discipline in there. But, you", "tokens": [50908, 11317, 293, 370, 322, 337, 257, 1916, 295, 7878, 586, 13, 407, 456, 311, 512, 512, 13635, 294, 456, 13, 583, 11, 291, 51216], "temperature": 0.0, "avg_logprob": -0.08607459863026937, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.00025918649043887854}, {"id": 729, "seek": 411040, "start": 4127.44, "end": 4133.679999999999, "text": " know, I don't know the answer to this. But one thing that I do wonder about is, is whether it's", "tokens": [51216, 458, 11, 286, 500, 380, 458, 264, 1867, 281, 341, 13, 583, 472, 551, 300, 286, 360, 2441, 466, 307, 11, 307, 1968, 309, 311, 51528], "temperature": 0.0, "avg_logprob": -0.08607459863026937, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.00025918649043887854}, {"id": 730, "seek": 411040, "start": 4133.679999999999, "end": 4139.5199999999995, "text": " going to be as simple as just having AI systems that can generate action verbs. And those action", "tokens": [51528, 516, 281, 312, 382, 2199, 382, 445, 1419, 7318, 3652, 300, 393, 8460, 3069, 30051, 13, 400, 729, 3069, 51820], "temperature": 0.0, "avg_logprob": -0.08607459863026937, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.00025918649043887854}, {"id": 731, "seek": 413952, "start": 4139.52, "end": 4144.72, "text": " verbs generate the correct API call to the right API. And that has built the system that we think", "tokens": [50364, 30051, 8460, 264, 3006, 9362, 818, 281, 264, 558, 9362, 13, 400, 300, 575, 3094, 264, 1185, 300, 321, 519, 50624], "temperature": 0.0, "avg_logprob": -0.10630948764761698, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.011735408566892147}, {"id": 732, "seek": 413952, "start": 4144.72, "end": 4152.080000000001, "text": " we need. I think Andre Capati calls it like the LLM OS, the LLM operating system, or whether there", "tokens": [50624, 321, 643, 13, 286, 519, 20667, 8363, 6908, 5498, 309, 411, 264, 441, 43, 44, 12731, 11, 264, 441, 43, 44, 7447, 1185, 11, 420, 1968, 456, 50992], "temperature": 0.0, "avg_logprob": -0.10630948764761698, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.011735408566892147}, {"id": 733, "seek": 413952, "start": 4152.080000000001, "end": 4158.8, "text": " need to be changes in the, you know, underlying infrastructure so that those APIs develop and", "tokens": [50992, 643, 281, 312, 2962, 294, 264, 11, 291, 458, 11, 14217, 6896, 370, 300, 729, 21445, 1499, 293, 51328], "temperature": 0.0, "avg_logprob": -0.10630948764761698, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.011735408566892147}, {"id": 734, "seek": 413952, "start": 4158.8, "end": 4165.68, "text": " respond and work slightly differently. Now, my sense would be that that the LLM is a kind of", "tokens": [51328, 4196, 293, 589, 4748, 7614, 13, 823, 11, 452, 2020, 576, 312, 300, 300, 264, 441, 43, 44, 307, 257, 733, 295, 51672], "temperature": 0.0, "avg_logprob": -0.10630948764761698, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.011735408566892147}, {"id": 735, "seek": 416568, "start": 4165.76, "end": 4172.88, "text": " coordinating, orchestrating thing, seems like a reasonable place for it to start with its sort", "tokens": [50368, 37824, 11, 14161, 8754, 551, 11, 2544, 411, 257, 10585, 1081, 337, 309, 281, 722, 365, 1080, 1333, 50724], "temperature": 0.0, "avg_logprob": -0.12820833379572089, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.004332567565143108}, {"id": 736, "seek": 416568, "start": 4172.88, "end": 4178.56, "text": " of memory and data store elsewhere, then figure out how to get it to generate kind of consistent", "tokens": [50724, 295, 4675, 293, 1412, 3531, 14517, 11, 550, 2573, 484, 577, 281, 483, 309, 281, 8460, 733, 295, 8398, 51008], "temperature": 0.0, "avg_logprob": -0.12820833379572089, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.004332567565143108}, {"id": 737, "seek": 416568, "start": 4178.56, "end": 4186.8, "text": " action, action verbs. And we would work with the existing human, the APIs that have been that", "tokens": [51008, 3069, 11, 3069, 30051, 13, 400, 321, 576, 589, 365, 264, 6741, 1952, 11, 264, 21445, 300, 362, 668, 300, 51420], "temperature": 0.0, "avg_logprob": -0.12820833379572089, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.004332567565143108}, {"id": 738, "seek": 416568, "start": 4186.8, "end": 4192.72, "text": " have been built for the API systems. But at some point, we'll start to think about what should", "tokens": [51420, 362, 668, 3094, 337, 264, 9362, 3652, 13, 583, 412, 512, 935, 11, 321, 603, 722, 281, 519, 466, 437, 820, 51716], "temperature": 0.0, "avg_logprob": -0.12820833379572089, "compression_ratio": 1.6309012875536482, "no_speech_prob": 0.004332567565143108}, {"id": 739, "seek": 419272, "start": 4192.72, "end": 4198.72, "text": " machine to machine actually look like when you've got an AI at the, at the other end. And so", "tokens": [50364, 3479, 281, 3479, 767, 574, 411, 562, 291, 600, 658, 364, 7318, 412, 264, 11, 412, 264, 661, 917, 13, 400, 370, 50664], "temperature": 0.0, "avg_logprob": -0.09375957647959392, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0036637757439166307}, {"id": 740, "seek": 419272, "start": 4199.76, "end": 4205.84, "text": " I think we do have a lot of the existing, you know, infrastructure in place, but I would be", "tokens": [50716, 286, 519, 321, 360, 362, 257, 688, 295, 264, 6741, 11, 291, 458, 11, 6896, 294, 1081, 11, 457, 286, 576, 312, 51020], "temperature": 0.0, "avg_logprob": -0.09375957647959392, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0036637757439166307}, {"id": 741, "seek": 419272, "start": 4205.84, "end": 4214.0, "text": " very surprised if the syntax of APIs stays the same over the next five or six years as we move", "tokens": [51020, 588, 6100, 498, 264, 28431, 295, 21445, 10834, 264, 912, 670, 264, 958, 1732, 420, 2309, 924, 382, 321, 1286, 51428], "temperature": 0.0, "avg_logprob": -0.09375957647959392, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0036637757439166307}, {"id": 742, "seek": 419272, "start": 4214.0, "end": 4221.12, "text": " towards, you know, a world where AI forms a kind of interface between us and what we want to,", "tokens": [51428, 3030, 11, 291, 458, 11, 257, 1002, 689, 7318, 6422, 257, 733, 295, 9226, 1296, 505, 293, 437, 321, 528, 281, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09375957647959392, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.0036637757439166307}, {"id": 743, "seek": 422112, "start": 4221.12, "end": 4225.68, "text": " you know, what we want to achieve. And then there's a whole bunch of other, other questions", "tokens": [50364, 291, 458, 11, 437, 321, 528, 281, 4584, 13, 400, 550, 456, 311, 257, 1379, 3840, 295, 661, 11, 661, 1651, 50592], "temperature": 0.0, "avg_logprob": -0.10357923830969859, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.007772176992148161}, {"id": 744, "seek": 422112, "start": 4225.68, "end": 4231.44, "text": " around how do those decisions get, get made? You know, we know that when we pick up our iPhone", "tokens": [50592, 926, 577, 360, 729, 5327, 483, 11, 483, 1027, 30, 509, 458, 11, 321, 458, 300, 562, 321, 1888, 493, 527, 7252, 50880], "temperature": 0.0, "avg_logprob": -0.10357923830969859, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.007772176992148161}, {"id": 745, "seek": 422112, "start": 4231.44, "end": 4237.36, "text": " and we search on Google through Safari, Google is not there because it was the best search engine.", "tokens": [50880, 293, 321, 3164, 322, 3329, 807, 43820, 11, 3329, 307, 406, 456, 570, 309, 390, 264, 1151, 3164, 2848, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10357923830969859, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.007772176992148161}, {"id": 746, "seek": 422112, "start": 4237.36, "end": 4241.36, "text": " It's there because they x billion dollars a year to pay Apple. And likewise, when we search for", "tokens": [51176, 467, 311, 456, 570, 436, 2031, 5218, 3808, 257, 1064, 281, 1689, 6373, 13, 400, 32407, 11, 562, 321, 3164, 337, 51376], "temperature": 0.0, "avg_logprob": -0.10357923830969859, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.007772176992148161}, {"id": 747, "seek": 422112, "start": 4241.36, "end": 4246.72, "text": " things on Google now, there is so much ad pollution that it's unclear what the incentives are. So I", "tokens": [51376, 721, 322, 3329, 586, 11, 456, 307, 370, 709, 614, 16727, 300, 309, 311, 25636, 437, 264, 23374, 366, 13, 407, 286, 51644], "temperature": 0.0, "avg_logprob": -0.10357923830969859, "compression_ratio": 1.7178571428571427, "no_speech_prob": 0.007772176992148161}, {"id": 748, "seek": 424672, "start": 4246.72, "end": 4252.56, "text": " think then there's another layer, which is unclear to me about trust. You know, right now,", "tokens": [50364, 519, 550, 456, 311, 1071, 4583, 11, 597, 307, 25636, 281, 385, 466, 3361, 13, 509, 458, 11, 558, 586, 11, 50656], "temperature": 0.0, "avg_logprob": -0.11457399527231853, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.001374083454720676}, {"id": 749, "seek": 424672, "start": 4252.56, "end": 4258.64, "text": " one of the beauties of, of perplexity or you.com, which are these, these LLM agents is that they", "tokens": [50656, 472, 295, 264, 1869, 530, 295, 11, 295, 680, 18945, 507, 420, 291, 13, 1112, 11, 597, 366, 613, 11, 613, 441, 43, 44, 12554, 307, 300, 436, 50960], "temperature": 0.0, "avg_logprob": -0.11457399527231853, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.001374083454720676}, {"id": 750, "seek": 424672, "start": 4258.64, "end": 4263.04, "text": " provide really, really good referencing when they come back and synthesize an answer for you.", "tokens": [50960, 2893, 534, 11, 534, 665, 40582, 562, 436, 808, 646, 293, 26617, 1125, 364, 1867, 337, 291, 13, 51180], "temperature": 0.0, "avg_logprob": -0.11457399527231853, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.001374083454720676}, {"id": 751, "seek": 424672, "start": 4263.76, "end": 4267.2, "text": " And so that gives you a high level of trust sometimes that you might have with, with chat", "tokens": [51216, 400, 370, 300, 2709, 291, 257, 1090, 1496, 295, 3361, 2171, 300, 291, 1062, 362, 365, 11, 365, 5081, 51388], "temperature": 0.0, "avg_logprob": -0.11457399527231853, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.001374083454720676}, {"id": 752, "seek": 426720, "start": 4267.28, "end": 4277.44, "text": " GPT, but I want to get that trust if I'm handing over key decisions to do analytics on my Stripe", "tokens": [50368, 26039, 51, 11, 457, 286, 528, 281, 483, 300, 3361, 498, 286, 478, 34774, 670, 2141, 5327, 281, 360, 15370, 322, 452, 20390, 494, 50876], "temperature": 0.0, "avg_logprob": -0.1023366928100586, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.4383050501346588}, {"id": 753, "seek": 426720, "start": 4277.44, "end": 4284.4, "text": " account or to help me book a hotel to, to an AI system and I'm no longer driving the key presses.", "tokens": [50876, 2696, 420, 281, 854, 385, 1446, 257, 7622, 281, 11, 281, 364, 7318, 1185, 293, 286, 478, 572, 2854, 4840, 264, 2141, 40892, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1023366928100586, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.4383050501346588}, {"id": 754, "seek": 426720, "start": 4284.4, "end": 4290.16, "text": " So, so that I think is somewhat path dependent because, but I wouldn't, you know, again, I'm", "tokens": [51224, 407, 11, 370, 300, 286, 519, 307, 8344, 3100, 12334, 570, 11, 457, 286, 2759, 380, 11, 291, 458, 11, 797, 11, 286, 478, 51512], "temperature": 0.0, "avg_logprob": -0.1023366928100586, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.4383050501346588}, {"id": 755, "seek": 426720, "start": 4290.16, "end": 4294.48, "text": " a real great believer in what, what founders can get up to. So I wouldn't also, you know,", "tokens": [51512, 257, 957, 869, 23892, 294, 437, 11, 437, 25608, 393, 483, 493, 281, 13, 407, 286, 2759, 380, 611, 11, 291, 458, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1023366928100586, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.4383050501346588}, {"id": 756, "seek": 429448, "start": 4294.48, "end": 4298.0, "text": " write off a founder coming up with a different way of thinking about the problem.", "tokens": [50364, 2464, 766, 257, 14917, 1348, 493, 365, 257, 819, 636, 295, 1953, 466, 264, 1154, 13, 50540], "temperature": 0.0, "avg_logprob": -0.10616103006065439, "compression_ratio": 1.6145454545454545, "no_speech_prob": 0.00521805789321661}, {"id": 757, "seek": 429448, "start": 4298.0, "end": 4304.24, "text": " Yeah. The dynamics of this, I do think are going to be extremely interesting, fast moving and,", "tokens": [50540, 865, 13, 440, 15679, 295, 341, 11, 286, 360, 519, 366, 516, 281, 312, 4664, 1880, 11, 2370, 2684, 293, 11, 50852], "temperature": 0.0, "avg_logprob": -0.10616103006065439, "compression_ratio": 1.6145454545454545, "no_speech_prob": 0.00521805789321661}, {"id": 758, "seek": 429448, "start": 4305.2, "end": 4310.0, "text": " and pretty hard to predict. One person reached out to me not too long ago and said,", "tokens": [50900, 293, 1238, 1152, 281, 6069, 13, 1485, 954, 6488, 484, 281, 385, 406, 886, 938, 2057, 293, 848, 11, 51140], "temperature": 0.0, "avg_logprob": -0.10616103006065439, "compression_ratio": 1.6145454545454545, "no_speech_prob": 0.00521805789321661}, {"id": 759, "seek": 429448, "start": 4310.0, "end": 4316.719999999999, "text": " what do you think about creating a product that makes people's websites more bot friendly?", "tokens": [51140, 437, 360, 291, 519, 466, 4084, 257, 1674, 300, 1669, 561, 311, 12891, 544, 10592, 9208, 30, 51476], "temperature": 0.0, "avg_logprob": -0.10616103006065439, "compression_ratio": 1.6145454545454545, "no_speech_prob": 0.00521805789321661}, {"id": 760, "seek": 429448, "start": 4317.679999999999, "end": 4322.5599999999995, "text": " And I said, you know, I think that is a really big idea. I've thought about that more in the", "tokens": [51524, 400, 286, 848, 11, 291, 458, 11, 286, 519, 300, 307, 257, 534, 955, 1558, 13, 286, 600, 1194, 466, 300, 544, 294, 264, 51768], "temperature": 0.0, "avg_logprob": -0.10616103006065439, "compression_ratio": 1.6145454545454545, "no_speech_prob": 0.00521805789321661}, {"id": 761, "seek": 432256, "start": 4322.56, "end": 4328.080000000001, "text": " context of self-driving cars. Like, why don't we have a program of, and this would be more of", "tokens": [50364, 4319, 295, 2698, 12, 47094, 5163, 13, 1743, 11, 983, 500, 380, 321, 362, 257, 1461, 295, 11, 293, 341, 576, 312, 544, 295, 50640], "temperature": 0.0, "avg_logprob": -0.10260961040760735, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.019713396206498146}, {"id": 762, "seek": 432256, "start": 4328.080000000001, "end": 4333.280000000001, "text": " like a national program. This is why I think China probably beats the US in the self-driving car race,", "tokens": [50640, 411, 257, 4048, 1461, 13, 639, 307, 983, 286, 519, 3533, 1391, 16447, 264, 2546, 294, 264, 2698, 12, 47094, 1032, 4569, 11, 50900], "temperature": 0.0, "avg_logprob": -0.10260961040760735, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.019713396206498146}, {"id": 763, "seek": 432256, "start": 4333.280000000001, "end": 4338.320000000001, "text": " because my expectation is they'll say, hey, we could get self-driving cars to work if we like", "tokens": [50900, 570, 452, 14334, 307, 436, 603, 584, 11, 4177, 11, 321, 727, 483, 2698, 12, 47094, 5163, 281, 589, 498, 321, 411, 51152], "temperature": 0.0, "avg_logprob": -0.10260961040760735, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.019713396206498146}, {"id": 764, "seek": 432256, "start": 4338.320000000001, "end": 4342.4800000000005, "text": " put QR codes on all the road signs or whatever, and then they'll just go do it. You know, we don't", "tokens": [51152, 829, 32784, 14211, 322, 439, 264, 3060, 7880, 420, 2035, 11, 293, 550, 436, 603, 445, 352, 360, 309, 13, 509, 458, 11, 321, 500, 380, 51360], "temperature": 0.0, "avg_logprob": -0.10260961040760735, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.019713396206498146}, {"id": 765, "seek": 432256, "start": 4342.4800000000005, "end": 4347.280000000001, "text": " quite have the political will to do that. But on the web, yeah, I think you could do that. And,", "tokens": [51360, 1596, 362, 264, 3905, 486, 281, 360, 300, 13, 583, 322, 264, 3670, 11, 1338, 11, 286, 519, 291, 727, 360, 300, 13, 400, 11, 51600], "temperature": 0.0, "avg_logprob": -0.10260961040760735, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.019713396206498146}, {"id": 766, "seek": 432256, "start": 4347.280000000001, "end": 4351.280000000001, "text": " you know, it might be cool. But then I was kind of like, but to the, to the website owners today", "tokens": [51600, 291, 458, 11, 309, 1062, 312, 1627, 13, 583, 550, 286, 390, 733, 295, 411, 11, 457, 281, 264, 11, 281, 264, 3144, 7710, 965, 51800], "temperature": 0.0, "avg_logprob": -0.10260961040760735, "compression_ratio": 1.7907692307692307, "no_speech_prob": 0.019713396206498146}, {"id": 767, "seek": 435128, "start": 4351.28, "end": 4357.04, "text": " want to be more about friendly. So what I ended up suggesting to this guy was maybe you do the", "tokens": [50364, 528, 281, 312, 544, 466, 9208, 13, 407, 437, 286, 4590, 493, 18094, 281, 341, 2146, 390, 1310, 291, 360, 264, 50652], "temperature": 0.0, "avg_logprob": -0.08045988476153501, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.01798243261873722}, {"id": 768, "seek": 435128, "start": 4357.04, "end": 4364.24, "text": " judo flip and start with something that is like anti-bot, you know, bot control or bot detection.", "tokens": [50652, 3747, 78, 7929, 293, 722, 365, 746, 300, 307, 411, 6061, 12, 18870, 11, 291, 458, 11, 10592, 1969, 420, 10592, 17784, 13, 51012], "temperature": 0.0, "avg_logprob": -0.08045988476153501, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.01798243261873722}, {"id": 769, "seek": 435128, "start": 4364.88, "end": 4372.32, "text": " And then that in time can sort of mature into bot control, but also enablement, you know, because", "tokens": [51044, 400, 550, 300, 294, 565, 393, 1333, 295, 14442, 666, 10592, 1969, 11, 457, 611, 9528, 518, 11, 291, 458, 11, 570, 51416], "temperature": 0.0, "avg_logprob": -0.08045988476153501, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.01798243261873722}, {"id": 770, "seek": 435128, "start": 4373.04, "end": 4376.5599999999995, "text": " eventually I do think people are going to want that, but they may not be ready for it yet.", "tokens": [51452, 4728, 286, 360, 519, 561, 366, 516, 281, 528, 300, 11, 457, 436, 815, 406, 312, 1919, 337, 309, 1939, 13, 51628], "temperature": 0.0, "avg_logprob": -0.08045988476153501, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.01798243261873722}, {"id": 771, "seek": 437656, "start": 4376.56, "end": 4382.0, "text": " And maybe the way in is sort of to try to position yourself as kind of the, you know,", "tokens": [50364, 400, 1310, 264, 636, 294, 307, 1333, 295, 281, 853, 281, 2535, 1803, 382, 733, 295, 264, 11, 291, 458, 11, 50636], "temperature": 0.0, "avg_logprob": -0.0765628653057551, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.0017511205514892936}, {"id": 772, "seek": 437656, "start": 4382.0, "end": 4385.92, "text": " the control layer that can then become, you know, an enablement layer.", "tokens": [50636, 264, 1969, 4583, 300, 393, 550, 1813, 11, 291, 458, 11, 364, 9528, 518, 4583, 13, 50832], "temperature": 0.0, "avg_logprob": -0.0765628653057551, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.0017511205514892936}, {"id": 773, "seek": 437656, "start": 4385.92, "end": 4390.72, "text": " As a website owner, you've got to think about the economic rationale for having a bot, you know,", "tokens": [50832, 1018, 257, 3144, 7289, 11, 291, 600, 658, 281, 519, 466, 264, 4836, 41989, 337, 1419, 257, 10592, 11, 291, 458, 11, 51072], "temperature": 0.0, "avg_logprob": -0.0765628653057551, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.0017511205514892936}, {"id": 774, "seek": 437656, "start": 4390.72, "end": 4398.64, "text": " not just a crawler, but a bot access your, your material and what you're going to benefit from.", "tokens": [51072, 406, 445, 257, 13999, 1918, 11, 457, 257, 10592, 2105, 428, 11, 428, 2527, 293, 437, 291, 434, 516, 281, 5121, 490, 13, 51468], "temperature": 0.0, "avg_logprob": -0.0765628653057551, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.0017511205514892936}, {"id": 775, "seek": 437656, "start": 4398.64, "end": 4403.92, "text": " And now if it's, if it's content, right, so it's analysis and research and reviews of products,", "tokens": [51468, 400, 586, 498, 309, 311, 11, 498, 309, 311, 2701, 11, 558, 11, 370, 309, 311, 5215, 293, 2132, 293, 10229, 295, 3383, 11, 51732], "temperature": 0.0, "avg_logprob": -0.0765628653057551, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.0017511205514892936}, {"id": 776, "seek": 440392, "start": 4404.0, "end": 4408.72, "text": " you need to then also think about your, your attribution and your monetization and what that,", "tokens": [50368, 291, 643, 281, 550, 611, 519, 466, 428, 11, 428, 9080, 1448, 293, 428, 15556, 2144, 293, 437, 300, 11, 50604], "temperature": 0.0, "avg_logprob": -0.11755800634864869, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.0015223907539620996}, {"id": 777, "seek": 440392, "start": 4408.72, "end": 4414.96, "text": " you know, what that relationship is. If it's for actions, in other words, it's for booking and for", "tokens": [50604, 291, 458, 11, 437, 300, 2480, 307, 13, 759, 309, 311, 337, 5909, 11, 294, 661, 2283, 11, 309, 311, 337, 34424, 293, 337, 50916], "temperature": 0.0, "avg_logprob": -0.11755800634864869, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.0015223907539620996}, {"id": 778, "seek": 440392, "start": 4414.96, "end": 4419.92, "text": " ordering, say, you know, you're a hair salon and you want people to be able to book appointments or", "tokens": [50916, 21739, 11, 584, 11, 291, 458, 11, 291, 434, 257, 2578, 27768, 293, 291, 528, 561, 281, 312, 1075, 281, 1446, 25084, 420, 51164], "temperature": 0.0, "avg_logprob": -0.11755800634864869, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.0015223907539620996}, {"id": 779, "seek": 440392, "start": 4419.92, "end": 4424.8, "text": " bots to book appointments like that lovely Alan Kay knowledge navigator video from, from Apple from", "tokens": [51164, 35410, 281, 1446, 25084, 411, 300, 7496, 16442, 14179, 3601, 7407, 1639, 960, 490, 11, 490, 6373, 490, 51408], "temperature": 0.0, "avg_logprob": -0.11755800634864869, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.0015223907539620996}, {"id": 780, "seek": 440392, "start": 4424.8, "end": 4431.92, "text": " the 80s, then, then yes, you want the thing to be bot friendly and you want to have there to be a", "tokens": [51408, 264, 4688, 82, 11, 550, 11, 550, 2086, 11, 291, 528, 264, 551, 281, 312, 10592, 9208, 293, 291, 528, 281, 362, 456, 281, 312, 257, 51764], "temperature": 0.0, "avg_logprob": -0.11755800634864869, "compression_ratio": 1.8773946360153257, "no_speech_prob": 0.0015223907539620996}, {"id": 781, "seek": 443192, "start": 4431.92, "end": 4437.36, "text": " standard, which could well just be, you know, a restful API, right, that allows the system to", "tokens": [50364, 3832, 11, 597, 727, 731, 445, 312, 11, 291, 458, 11, 257, 1472, 906, 9362, 11, 558, 11, 300, 4045, 264, 1185, 281, 50636], "temperature": 0.0, "avg_logprob": -0.10993376645174893, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.014825761318206787}, {"id": 782, "seek": 443192, "start": 4437.36, "end": 4442.0, "text": " connect, connect and ask the question. But, but, but I mean, it's really, it's quite interesting", "tokens": [50636, 1745, 11, 1745, 293, 1029, 264, 1168, 13, 583, 11, 457, 11, 457, 286, 914, 11, 309, 311, 534, 11, 309, 311, 1596, 1880, 50868], "temperature": 0.0, "avg_logprob": -0.10993376645174893, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.014825761318206787}, {"id": 783, "seek": 443192, "start": 4442.0, "end": 4447.04, "text": " that we're people are already starting to think about these things and, and, and ask these things,", "tokens": [50868, 300, 321, 434, 561, 366, 1217, 2891, 281, 519, 466, 613, 721, 293, 11, 293, 11, 293, 1029, 613, 721, 11, 51120], "temperature": 0.0, "avg_logprob": -0.10993376645174893, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.014825761318206787}, {"id": 784, "seek": 443192, "start": 4447.04, "end": 4455.68, "text": " because I think that you will end up and you'll end up with so much machine to machine communication", "tokens": [51120, 570, 286, 519, 300, 291, 486, 917, 493, 293, 291, 603, 917, 493, 365, 370, 709, 3479, 281, 3479, 6101, 51552], "temperature": 0.0, "avg_logprob": -0.10993376645174893, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.014825761318206787}, {"id": 785, "seek": 443192, "start": 4455.68, "end": 4461.12, "text": " of which there is already an enormous amount, not just on the internet that we is invisible to us,", "tokens": [51552, 295, 597, 456, 307, 1217, 364, 11322, 2372, 11, 406, 445, 322, 264, 4705, 300, 321, 307, 14603, 281, 505, 11, 51824], "temperature": 0.0, "avg_logprob": -0.10993376645174893, "compression_ratio": 1.7717391304347827, "no_speech_prob": 0.014825761318206787}, {"id": 786, "seek": 446112, "start": 4461.12, "end": 4465.12, "text": " right, because it's the digital infrastructure, but there'll be an enormous amount of machine to", "tokens": [50364, 558, 11, 570, 309, 311, 264, 4562, 6896, 11, 457, 456, 603, 312, 364, 11322, 2372, 295, 3479, 281, 50564], "temperature": 0.0, "avg_logprob": -0.11344938020448427, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0012233001179993153}, {"id": 787, "seek": 446112, "start": 4465.12, "end": 4471.84, "text": " machine communication because these systems will also to try to do optimizations for their", "tokens": [50564, 3479, 6101, 570, 613, 3652, 486, 611, 281, 853, 281, 360, 5028, 14455, 337, 641, 50900], "temperature": 0.0, "avg_logprob": -0.11344938020448427, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0012233001179993153}, {"id": 788, "seek": 446112, "start": 4472.64, "end": 4480.48, "text": " owners far, far with, with much greater intent and stamina than we, than we ever would. And so", "tokens": [50940, 7710, 1400, 11, 1400, 365, 11, 365, 709, 5044, 8446, 293, 36690, 813, 321, 11, 813, 321, 1562, 576, 13, 400, 370, 51332], "temperature": 0.0, "avg_logprob": -0.11344938020448427, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0012233001179993153}, {"id": 789, "seek": 446112, "start": 4480.48, "end": 4485.04, "text": " what those systems end up looking like, I think will be quite interesting. I mean, the other area", "tokens": [51332, 437, 729, 3652, 917, 493, 1237, 411, 11, 286, 519, 486, 312, 1596, 1880, 13, 286, 914, 11, 264, 661, 1859, 51560], "temperature": 0.0, "avg_logprob": -0.11344938020448427, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0012233001179993153}, {"id": 790, "seek": 446112, "start": 4485.04, "end": 4490.08, "text": " that I've been, I've been tracking has been on the other side of this has been people looking to", "tokens": [51560, 300, 286, 600, 668, 11, 286, 600, 668, 11603, 575, 668, 322, 264, 661, 1252, 295, 341, 575, 668, 561, 1237, 281, 51812], "temperature": 0.0, "avg_logprob": -0.11344938020448427, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.0012233001179993153}, {"id": 791, "seek": 449008, "start": 4490.8, "end": 4496.48, "text": " build a genetic frameworks, right, so frameworks that allow us to have multiple", "tokens": [50400, 1322, 257, 12462, 29834, 11, 558, 11, 370, 29834, 300, 2089, 505, 281, 362, 3866, 50684], "temperature": 0.0, "avg_logprob": -0.11929476477883079, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.00781701598316431}, {"id": 792, "seek": 449008, "start": 4496.48, "end": 4502.72, "text": " LLMs and with all of their current restrictions around planning and task execution allow you to,", "tokens": [50684, 441, 43, 26386, 293, 365, 439, 295, 641, 2190, 14191, 926, 5038, 293, 5633, 15058, 2089, 291, 281, 11, 50996], "temperature": 0.0, "avg_logprob": -0.11929476477883079, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.00781701598316431}, {"id": 793, "seek": 449008, "start": 4502.72, "end": 4507.5199999999995, "text": " to manage those so you can start to build systems that, that can do task execution.", "tokens": [50996, 281, 3067, 729, 370, 291, 393, 722, 281, 1322, 3652, 300, 11, 300, 393, 360, 5633, 15058, 13, 51236], "temperature": 0.0, "avg_logprob": -0.11929476477883079, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.00781701598316431}, {"id": 794, "seek": 449008, "start": 4508.16, "end": 4512.5599999999995, "text": " And you remember a year ago, everyone got excited about agent GPT. And I don't know if you've seen", "tokens": [51268, 400, 291, 1604, 257, 1064, 2057, 11, 1518, 658, 2919, 466, 9461, 26039, 51, 13, 400, 286, 500, 380, 458, 498, 291, 600, 1612, 51488], "temperature": 0.0, "avg_logprob": -0.11929476477883079, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.00781701598316431}, {"id": 795, "seek": 449008, "start": 4512.5599999999995, "end": 4518.24, "text": " anything like that and what you, where you think we are in terms of being able to have systems that,", "tokens": [51488, 1340, 411, 300, 293, 437, 291, 11, 689, 291, 519, 321, 366, 294, 2115, 295, 885, 1075, 281, 362, 3652, 300, 11, 51772], "temperature": 0.0, "avg_logprob": -0.11929476477883079, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.00781701598316431}, {"id": 796, "seek": 451824, "start": 4518.24, "end": 4522.24, "text": " that do that and have that agentic behavior in a, in a useful way.", "tokens": [50364, 300, 360, 300, 293, 362, 300, 9461, 299, 5223, 294, 257, 11, 294, 257, 4420, 636, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08978838625207411, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.0003682439564727247}, {"id": 797, "seek": 451824, "start": 4523.04, "end": 4528.88, "text": " Not quite there, but definitely getting closer. We've, we recently did an episode with Div from", "tokens": [50604, 1726, 1596, 456, 11, 457, 2138, 1242, 4966, 13, 492, 600, 11, 321, 3938, 630, 364, 3500, 365, 9886, 490, 50896], "temperature": 0.0, "avg_logprob": -0.08978838625207411, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.0003682439564727247}, {"id": 798, "seek": 451824, "start": 4528.88, "end": 4535.44, "text": " MultiOn, who has been one of the most, you know, kind of quick to launch and iterating in public of", "tokens": [50896, 29238, 11747, 11, 567, 575, 668, 472, 295, 264, 881, 11, 291, 458, 11, 733, 295, 1702, 281, 4025, 293, 17138, 990, 294, 1908, 295, 51224], "temperature": 0.0, "avg_logprob": -0.08978838625207411, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.0003682439564727247}, {"id": 799, "seek": 451824, "start": 4535.44, "end": 4542.4, "text": " the agent companies. And they are making real progress. The prompt that he gave me to try in", "tokens": [51224, 264, 9461, 3431, 13, 400, 436, 366, 1455, 957, 4205, 13, 440, 12391, 300, 415, 2729, 385, 281, 853, 294, 51572], "temperature": 0.0, "avg_logprob": -0.08978838625207411, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.0003682439564727247}, {"id": 800, "seek": 451824, "start": 4542.4, "end": 4547.5199999999995, "text": " advance of my conversation with him was basically go to my Twitter account, look at my recent tweets,", "tokens": [51572, 7295, 295, 452, 3761, 365, 796, 390, 1936, 352, 281, 452, 5794, 2696, 11, 574, 412, 452, 5162, 25671, 11, 51828], "temperature": 0.0, "avg_logprob": -0.08978838625207411, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.0003682439564727247}, {"id": 801, "seek": 454824, "start": 4548.48, "end": 4554.719999999999, "text": " note what they're about, then go out and do research online for new AI stuff, but only", "tokens": [50376, 3637, 437, 436, 434, 466, 11, 550, 352, 484, 293, 360, 2132, 2950, 337, 777, 7318, 1507, 11, 457, 787, 50688], "temperature": 0.0, "avg_logprob": -0.06901785478753558, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0005883737467229366}, {"id": 802, "seek": 454824, "start": 4555.36, "end": 4559.599999999999, "text": " about stuff that I haven't already tweeted about, then come back and write a tweet and post it.", "tokens": [50720, 466, 1507, 300, 286, 2378, 380, 1217, 25646, 466, 11, 550, 808, 646, 293, 2464, 257, 15258, 293, 2183, 309, 13, 50932], "temperature": 0.0, "avg_logprob": -0.06901785478753558, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0005883737467229366}, {"id": 803, "seek": 454824, "start": 4560.24, "end": 4564.96, "text": " And it worked. It was able to complete that entire sequence and post like a reasonably", "tokens": [50964, 400, 309, 2732, 13, 467, 390, 1075, 281, 3566, 300, 2302, 8310, 293, 2183, 411, 257, 23551, 51200], "temperature": 0.0, "avg_logprob": -0.06901785478753558, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0005883737467229366}, {"id": 804, "seek": 454824, "start": 4564.96, "end": 4570.24, "text": " coherent tweet. I don't plan to like turn over the account to it entirely in the immediate term,", "tokens": [51200, 36239, 15258, 13, 286, 500, 380, 1393, 281, 411, 1261, 670, 264, 2696, 281, 309, 7696, 294, 264, 11629, 1433, 11, 51464], "temperature": 0.0, "avg_logprob": -0.06901785478753558, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0005883737467229366}, {"id": 805, "seek": 454824, "start": 4570.24, "end": 4574.639999999999, "text": " but you know, a year ago we were, we were, you know, it was all theory. One of the things I say", "tokens": [51464, 457, 291, 458, 11, 257, 1064, 2057, 321, 645, 11, 321, 645, 11, 291, 458, 11, 309, 390, 439, 5261, 13, 1485, 295, 264, 721, 286, 584, 51684], "temperature": 0.0, "avg_logprob": -0.06901785478753558, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0005883737467229366}, {"id": 806, "seek": 457464, "start": 4574.64, "end": 4583.200000000001, "text": " these days often is we now have AIs that can reason, plan and use tools. And people will be", "tokens": [50364, 613, 1708, 2049, 307, 321, 586, 362, 316, 6802, 300, 393, 1778, 11, 1393, 293, 764, 3873, 13, 400, 561, 486, 312, 50792], "temperature": 0.0, "avg_logprob": -0.08546179182389203, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.012816294096410275}, {"id": 807, "seek": 457464, "start": 4583.200000000001, "end": 4586.160000000001, "text": " quick to say, well, they're not that good at it. And I say, well, yeah, that's true. They're not", "tokens": [50792, 1702, 281, 584, 11, 731, 11, 436, 434, 406, 300, 665, 412, 309, 13, 400, 286, 584, 11, 731, 11, 1338, 11, 300, 311, 2074, 13, 814, 434, 406, 50940], "temperature": 0.0, "avg_logprob": -0.08546179182389203, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.012816294096410275}, {"id": 808, "seek": 457464, "start": 4586.160000000001, "end": 4590.96, "text": " that good at it yet, but two years ago they couldn't do it at all. But what you've, you've picked up on", "tokens": [50940, 300, 665, 412, 309, 1939, 11, 457, 732, 924, 2057, 436, 2809, 380, 360, 309, 412, 439, 13, 583, 437, 291, 600, 11, 291, 600, 6183, 493, 322, 51180], "temperature": 0.0, "avg_logprob": -0.08546179182389203, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.012816294096410275}, {"id": 809, "seek": 457464, "start": 4590.96, "end": 4594.400000000001, "text": " though is, you know, as an early adopter and you've got access to this, these technologies,", "tokens": [51180, 1673, 307, 11, 291, 458, 11, 382, 364, 2440, 22486, 391, 293, 291, 600, 658, 2105, 281, 341, 11, 613, 7943, 11, 51352], "temperature": 0.0, "avg_logprob": -0.08546179182389203, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.012816294096410275}, {"id": 810, "seek": 457464, "start": 4594.400000000001, "end": 4600.08, "text": " your Twitter feed will get even better than, than it is now. But there'll also come a point where we", "tokens": [51352, 428, 5794, 3154, 486, 483, 754, 1101, 813, 11, 813, 309, 307, 586, 13, 583, 456, 603, 611, 808, 257, 935, 689, 321, 51636], "temperature": 0.0, "avg_logprob": -0.08546179182389203, "compression_ratio": 1.7259786476868328, "no_speech_prob": 0.012816294096410275}, {"id": 811, "seek": 460008, "start": 4600.08, "end": 4605.28, "text": " all have that technology. And then on the other side, I will be sitting there saying to my bot,", "tokens": [50364, 439, 362, 300, 2899, 13, 400, 550, 322, 264, 661, 1252, 11, 286, 486, 312, 3798, 456, 1566, 281, 452, 10592, 11, 50624], "temperature": 0.0, "avg_logprob": -0.09814358552296956, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.0895666629076004}, {"id": 812, "seek": 460008, "start": 4605.28, "end": 4610.32, "text": " can you just extract the three bullet points I need to know from my Twitter feed? And I remember", "tokens": [50624, 393, 291, 445, 8947, 264, 1045, 11632, 2793, 286, 643, 281, 458, 490, 452, 5794, 3154, 30, 400, 286, 1604, 50876], "temperature": 0.0, "avg_logprob": -0.09814358552296956, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.0895666629076004}, {"id": 813, "seek": 460008, "start": 4610.32, "end": 4615.2, "text": " this with Amy.exe. If you remember this, it was a scheduling bot. And one of the things that made", "tokens": [50876, 341, 365, 12651, 13, 3121, 68, 13, 759, 291, 1604, 341, 11, 309, 390, 257, 29055, 10592, 13, 400, 472, 295, 264, 721, 300, 1027, 51120], "temperature": 0.0, "avg_logprob": -0.09814358552296956, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.0895666629076004}, {"id": 814, "seek": 460008, "start": 4615.2, "end": 4623.12, "text": " me really uncomfortable about using it, having fallen in love with it, was when my mentor wrote", "tokens": [51120, 385, 534, 10532, 466, 1228, 309, 11, 1419, 11547, 294, 959, 365, 309, 11, 390, 562, 452, 14478, 4114, 51516], "temperature": 0.0, "avg_logprob": -0.09814358552296956, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.0895666629076004}, {"id": 815, "seek": 460008, "start": 4623.12, "end": 4629.84, "text": " a really polite email back to Amy saying, so good that you're working with Azim. He's really", "tokens": [51516, 257, 534, 25171, 3796, 646, 281, 12651, 1566, 11, 370, 665, 300, 291, 434, 1364, 365, 7607, 332, 13, 634, 311, 534, 51852], "temperature": 0.0, "avg_logprob": -0.09814358552296956, "compression_ratio": 1.6517241379310346, "no_speech_prob": 0.0895666629076004}, {"id": 816, "seek": 462984, "start": 4629.84, "end": 4634.08, "text": " a great guy and like make sure he tells you this story about this and blah, blah, blah. And I can't", "tokens": [50364, 257, 869, 2146, 293, 411, 652, 988, 415, 5112, 291, 341, 1657, 466, 341, 293, 12288, 11, 12288, 11, 12288, 13, 400, 286, 393, 380, 50576], "temperature": 0.0, "avg_logprob": -0.08568098361675557, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.002234305255115032}, {"id": 817, "seek": 462984, "start": 4634.08, "end": 4639.2, "text": " make it. And I read this and I thought, I cannot use this now because I realized that I was imposing", "tokens": [50576, 652, 309, 13, 400, 286, 1401, 341, 293, 286, 1194, 11, 286, 2644, 764, 341, 586, 570, 286, 5334, 300, 286, 390, 40288, 50832], "temperature": 0.0, "avg_logprob": -0.08568098361675557, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.002234305255115032}, {"id": 818, "seek": 462984, "start": 4639.2, "end": 4645.28, "text": " this artificially onto all of my recipients. And I think this is one of the things that we'll have", "tokens": [50832, 341, 39905, 2270, 3911, 439, 295, 452, 32440, 13, 400, 286, 519, 341, 307, 472, 295, 264, 721, 300, 321, 603, 362, 51136], "temperature": 0.0, "avg_logprob": -0.08568098361675557, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.002234305255115032}, {"id": 819, "seek": 462984, "start": 4645.28, "end": 4650.0, "text": " to have to contend with with some of these tools. If you work in a big company, frankly, if you work", "tokens": [51136, 281, 362, 281, 660, 521, 365, 365, 512, 295, 613, 3873, 13, 759, 291, 589, 294, 257, 955, 2237, 11, 11939, 11, 498, 291, 589, 51372], "temperature": 0.0, "avg_logprob": -0.08568098361675557, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.002234305255115032}, {"id": 820, "seek": 462984, "start": 4650.0, "end": 4656.32, "text": " in a small company, one of the veins of your life is, is PowerPoint. It's not just that you", "tokens": [51372, 294, 257, 1359, 2237, 11, 472, 295, 264, 29390, 295, 428, 993, 307, 11, 307, 25584, 13, 467, 311, 406, 445, 300, 291, 51688], "temperature": 0.0, "avg_logprob": -0.08568098361675557, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.002234305255115032}, {"id": 821, "seek": 465632, "start": 4657.2, "end": 4662.16, "text": " don't get good PowerPoint. It's just that you get too much PowerPoint. And if we drop the cost of", "tokens": [50408, 500, 380, 483, 665, 25584, 13, 467, 311, 445, 300, 291, 483, 886, 709, 25584, 13, 400, 498, 321, 3270, 264, 2063, 295, 50656], "temperature": 0.0, "avg_logprob": -0.0793389176900408, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.017876330763101578}, {"id": 822, "seek": 465632, "start": 4662.16, "end": 4667.759999999999, "text": " making PowerPoint presentations from three hours to 10 seconds, we're not necessarily going to get", "tokens": [50656, 1455, 25584, 18964, 490, 1045, 2496, 281, 1266, 3949, 11, 321, 434, 406, 4725, 516, 281, 483, 50936], "temperature": 0.0, "avg_logprob": -0.0793389176900408, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.017876330763101578}, {"id": 823, "seek": 465632, "start": 4667.759999999999, "end": 4672.799999999999, "text": " any better PowerPoint. We're just going to get, you know, loads of terrible PowerPoint. And finding", "tokens": [50936, 604, 1101, 25584, 13, 492, 434, 445, 516, 281, 483, 11, 291, 458, 11, 12668, 295, 6237, 25584, 13, 400, 5006, 51188], "temperature": 0.0, "avg_logprob": -0.0793389176900408, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.017876330763101578}, {"id": 824, "seek": 465632, "start": 4672.799999999999, "end": 4680.16, "text": " where that balance is and finding those, those filters so that humans don't have to bear this", "tokens": [51188, 689, 300, 4772, 307, 293, 5006, 729, 11, 729, 15995, 370, 300, 6255, 500, 380, 362, 281, 6155, 341, 51556], "temperature": 0.0, "avg_logprob": -0.0793389176900408, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.017876330763101578}, {"id": 825, "seek": 465632, "start": 4680.16, "end": 4684.88, "text": " cognitive load, I think is going to be one of the really, really critical areas. Because one thing", "tokens": [51556, 15605, 3677, 11, 286, 519, 307, 516, 281, 312, 472, 295, 264, 534, 11, 534, 4924, 3179, 13, 1436, 472, 551, 51792], "temperature": 0.0, "avg_logprob": -0.0793389176900408, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.017876330763101578}, {"id": 826, "seek": 468488, "start": 4684.88, "end": 4690.64, "text": " that I mean, I'm not a dystopian in any, in any way, Nathan, I'm a pragmatic optimist about this.", "tokens": [50364, 300, 286, 914, 11, 286, 478, 406, 257, 14584, 13559, 952, 294, 604, 11, 294, 604, 636, 11, 20634, 11, 286, 478, 257, 46904, 5028, 468, 466, 341, 13, 50652], "temperature": 0.0, "avg_logprob": -0.08855270415313485, "compression_ratio": 1.7394366197183098, "no_speech_prob": 0.007709362078458071}, {"id": 827, "seek": 468488, "start": 4690.64, "end": 4695.6, "text": " I think we've got a lot of potential. We're going to create a lot of space and headroom with AI and", "tokens": [50652, 286, 519, 321, 600, 658, 257, 688, 295, 3995, 13, 492, 434, 516, 281, 1884, 257, 688, 295, 1901, 293, 1378, 2861, 365, 7318, 293, 50900], "temperature": 0.0, "avg_logprob": -0.08855270415313485, "compression_ratio": 1.7394366197183098, "no_speech_prob": 0.007709362078458071}, {"id": 828, "seek": 468488, "start": 4695.6, "end": 4701.2, "text": " with renewable tech. But I do think that we are also at a moment where we're passing a little", "tokens": [50900, 365, 20938, 7553, 13, 583, 286, 360, 519, 300, 321, 366, 611, 412, 257, 1623, 689, 321, 434, 8437, 257, 707, 51180], "temperature": 0.0, "avg_logprob": -0.08855270415313485, "compression_ratio": 1.7394366197183098, "no_speech_prob": 0.007709362078458071}, {"id": 829, "seek": 468488, "start": 4701.2, "end": 4706.64, "text": " threshold. That threshold is that for a long time, some groups of people would say the world is moving", "tokens": [51180, 14678, 13, 663, 14678, 307, 300, 337, 257, 938, 565, 11, 512, 3935, 295, 561, 576, 584, 264, 1002, 307, 2684, 51452], "temperature": 0.0, "avg_logprob": -0.08855270415313485, "compression_ratio": 1.7394366197183098, "no_speech_prob": 0.007709362078458071}, {"id": 830, "seek": 468488, "start": 4706.64, "end": 4710.96, "text": " too quickly and technology is moving too fast. And over time, the number of people who say that has", "tokens": [51452, 886, 2661, 293, 2899, 307, 2684, 886, 2370, 13, 400, 670, 565, 11, 264, 1230, 295, 561, 567, 584, 300, 575, 51668], "temperature": 0.0, "avg_logprob": -0.08855270415313485, "compression_ratio": 1.7394366197183098, "no_speech_prob": 0.007709362078458071}, {"id": 831, "seek": 471096, "start": 4711.04, "end": 4716.08, "text": " increased. But it was their subjective reality. But I think we're getting to a point where there's", "tokens": [50368, 6505, 13, 583, 309, 390, 641, 25972, 4103, 13, 583, 286, 519, 321, 434, 1242, 281, 257, 935, 689, 456, 311, 50620], "temperature": 0.0, "avg_logprob": -0.09753601749738057, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.060221754014492035}, {"id": 832, "seek": 471096, "start": 4716.08, "end": 4721.36, "text": " an objective reality that we're about to hit, which is once you start to connect agentic systems,", "tokens": [50620, 364, 10024, 4103, 300, 321, 434, 466, 281, 2045, 11, 597, 307, 1564, 291, 722, 281, 1745, 9461, 299, 3652, 11, 50884], "temperature": 0.0, "avg_logprob": -0.09753601749738057, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.060221754014492035}, {"id": 833, "seek": 471096, "start": 4721.36, "end": 4728.24, "text": " we just can't really cope, you know, cope with the 300 notifications we got off on our phone today.", "tokens": [50884, 321, 445, 393, 380, 534, 22598, 11, 291, 458, 11, 22598, 365, 264, 6641, 13426, 321, 658, 766, 322, 527, 2593, 965, 13, 51228], "temperature": 0.0, "avg_logprob": -0.09753601749738057, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.060221754014492035}, {"id": 834, "seek": 471096, "start": 4728.96, "end": 4735.36, "text": " And the way humans have typically done that is that we've not really had to face this. I think", "tokens": [51264, 400, 264, 636, 6255, 362, 5850, 1096, 300, 307, 300, 321, 600, 406, 534, 632, 281, 1851, 341, 13, 286, 519, 51584], "temperature": 0.0, "avg_logprob": -0.09753601749738057, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.060221754014492035}, {"id": 835, "seek": 473536, "start": 4735.36, "end": 4741.599999999999, "text": " about the Chinese spy balloon that sort of made its way over the US. And one of the reasons this", "tokens": [50364, 466, 264, 4649, 20752, 16994, 300, 1333, 295, 1027, 1080, 636, 670, 264, 2546, 13, 400, 472, 295, 264, 4112, 341, 50676], "temperature": 0.0, "avg_logprob": -0.08910556549721575, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.05473359674215317}, {"id": 836, "seek": 473536, "start": 4741.599999999999, "end": 4747.36, "text": " huge thing got across over the US was because the US has got amazing sensors, but they generate so", "tokens": [50676, 2603, 551, 658, 2108, 670, 264, 2546, 390, 570, 264, 2546, 575, 658, 2243, 14840, 11, 457, 436, 8460, 370, 50964], "temperature": 0.0, "avg_logprob": -0.08910556549721575, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.05473359674215317}, {"id": 837, "seek": 473536, "start": 4747.36, "end": 4753.28, "text": " many terabytes of data that humans can't can't assess them. So lots of them are just filtered away.", "tokens": [50964, 867, 1796, 24538, 295, 1412, 300, 6255, 393, 380, 393, 380, 5877, 552, 13, 407, 3195, 295, 552, 366, 445, 37111, 1314, 13, 51260], "temperature": 0.0, "avg_logprob": -0.08910556549721575, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.05473359674215317}, {"id": 838, "seek": 473536, "start": 4754.16, "end": 4760.719999999999, "text": " And so the spy balloon wandered across detected by some radio antenna, but never put in front of", "tokens": [51304, 400, 370, 264, 20752, 16994, 14304, 4073, 2108, 21896, 538, 512, 6477, 24573, 11, 457, 1128, 829, 294, 1868, 295, 51632], "temperature": 0.0, "avg_logprob": -0.08910556549721575, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.05473359674215317}, {"id": 839, "seek": 476072, "start": 4760.72, "end": 4767.04, "text": " anyone. And of course, they've now changed change systems so that they can do that. And I do wonder", "tokens": [50364, 2878, 13, 400, 295, 1164, 11, 436, 600, 586, 3105, 1319, 3652, 370, 300, 436, 393, 360, 300, 13, 400, 286, 360, 2441, 50680], "temperature": 0.0, "avg_logprob": -0.07203556242443267, "compression_ratio": 1.638655462184874, "no_speech_prob": 0.06699728965759277}, {"id": 840, "seek": 476072, "start": 4767.04, "end": 4774.4800000000005, "text": " about what our interactions ought to look like in a world where it's not my my assistant or me", "tokens": [50680, 466, 437, 527, 13280, 13416, 281, 574, 411, 294, 257, 1002, 689, 309, 311, 406, 452, 452, 10994, 420, 385, 51052], "temperature": 0.0, "avg_logprob": -0.07203556242443267, "compression_ratio": 1.638655462184874, "no_speech_prob": 0.06699728965759277}, {"id": 841, "seek": 476072, "start": 4774.4800000000005, "end": 4779.68, "text": " scheduling back and forth with you on WhatsApp. It's a bot that is going to work relentlessly and", "tokens": [51052, 29055, 646, 293, 5220, 365, 291, 322, 30513, 13, 467, 311, 257, 10592, 300, 307, 516, 281, 589, 34045, 12048, 293, 51312], "temperature": 0.0, "avg_logprob": -0.07203556242443267, "compression_ratio": 1.638655462184874, "no_speech_prob": 0.06699728965759277}, {"id": 842, "seek": 476072, "start": 4779.68, "end": 4784.4800000000005, "text": " remorselessly. And I have it and you don't. And it's of no cost to me. And I'm just sort of doing", "tokens": [51312, 890, 284, 790, 442, 356, 13, 400, 286, 362, 309, 293, 291, 500, 380, 13, 400, 309, 311, 295, 572, 2063, 281, 385, 13, 400, 286, 478, 445, 1333, 295, 884, 51552], "temperature": 0.0, "avg_logprob": -0.07203556242443267, "compression_ratio": 1.638655462184874, "no_speech_prob": 0.06699728965759277}, {"id": 843, "seek": 478448, "start": 4784.48, "end": 4793.04, "text": " whatever I'm doing, my yoga or something. I think the way we get through it is by finding ways of", "tokens": [50364, 2035, 286, 478, 884, 11, 452, 15128, 420, 746, 13, 286, 519, 264, 636, 321, 483, 807, 309, 307, 538, 5006, 2098, 295, 50792], "temperature": 0.0, "avg_logprob": -0.12691708405812582, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.09920293092727661}, {"id": 844, "seek": 478448, "start": 4793.04, "end": 4801.839999999999, "text": " actually using it to filter as much of those that noise as we can so that inboxes start to become", "tokens": [50792, 767, 1228, 309, 281, 6608, 382, 709, 295, 729, 300, 5658, 382, 321, 393, 370, 300, 35067, 279, 722, 281, 1813, 51232], "temperature": 0.0, "avg_logprob": -0.12691708405812582, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.09920293092727661}, {"id": 845, "seek": 478448, "start": 4802.879999999999, "end": 4808.32, "text": " smaller rather than rather than bigger because stuff has been taken care of us. In fact, it's", "tokens": [51284, 4356, 2831, 813, 2831, 813, 3801, 570, 1507, 575, 668, 2726, 1127, 295, 505, 13, 682, 1186, 11, 309, 311, 51556], "temperature": 0.0, "avg_logprob": -0.12691708405812582, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.09920293092727661}, {"id": 846, "seek": 478448, "start": 4808.32, "end": 4812.5599999999995, "text": " kind of the reverse of the BlackBerry, right? When the BlackBerry was launched. I remember", "tokens": [51556, 733, 295, 264, 9943, 295, 264, 4076, 33, 5318, 11, 558, 30, 1133, 264, 4076, 33, 5318, 390, 8730, 13, 286, 1604, 51768], "temperature": 0.0, "avg_logprob": -0.12691708405812582, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.09920293092727661}, {"id": 847, "seek": 481256, "start": 4812.56, "end": 4818.64, "text": " bankers used to take pride in how quickly they would respond to a message coming in even overnight.", "tokens": [50364, 3765, 433, 1143, 281, 747, 10936, 294, 577, 2661, 436, 576, 4196, 281, 257, 3636, 1348, 294, 754, 13935, 13, 50668], "temperature": 0.0, "avg_logprob": -0.09662595259404816, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.007396781351417303}, {"id": 848, "seek": 481256, "start": 4818.64, "end": 4823.4400000000005, "text": " And the idea that someone would have that as an internal personal KPI today, you know, in the world", "tokens": [50668, 400, 264, 1558, 300, 1580, 576, 362, 300, 382, 364, 6920, 2973, 591, 31701, 965, 11, 291, 458, 11, 294, 264, 1002, 50908], "temperature": 0.0, "avg_logprob": -0.09662595259404816, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.007396781351417303}, {"id": 849, "seek": 481256, "start": 4823.4400000000005, "end": 4829.4400000000005, "text": " of health span is just insane. And I would I start to think about what is going to be that", "tokens": [50908, 295, 1585, 16174, 307, 445, 10838, 13, 400, 286, 576, 286, 722, 281, 519, 466, 437, 307, 516, 281, 312, 300, 51208], "temperature": 0.0, "avg_logprob": -0.09662595259404816, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.007396781351417303}, {"id": 850, "seek": 481256, "start": 4829.4400000000005, "end": 4834.4800000000005, "text": " layer? Because you know what? I want all the benefits of these bots working for me and making", "tokens": [51208, 4583, 30, 1436, 291, 458, 437, 30, 286, 528, 439, 264, 5311, 295, 613, 35410, 1364, 337, 385, 293, 1455, 51460], "temperature": 0.0, "avg_logprob": -0.09662595259404816, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.007396781351417303}, {"id": 851, "seek": 481256, "start": 4834.4800000000005, "end": 4838.64, "text": " sure my prescriptions are up to date and making sure we're not wasting electricity and getting", "tokens": [51460, 988, 452, 1183, 34173, 366, 493, 281, 4002, 293, 1455, 988, 321, 434, 406, 20457, 10356, 293, 1242, 51668], "temperature": 0.0, "avg_logprob": -0.09662595259404816, "compression_ratio": 1.6689895470383276, "no_speech_prob": 0.007396781351417303}, {"id": 852, "seek": 483864, "start": 4838.72, "end": 4843.200000000001, "text": " me exactly the right flight. I always want a Dreamliner or an A350 and I'll go an hour later", "tokens": [50368, 385, 2293, 264, 558, 7018, 13, 286, 1009, 528, 257, 12105, 36849, 420, 364, 316, 36027, 293, 286, 603, 352, 364, 1773, 1780, 50592], "temperature": 0.0, "avg_logprob": -0.07976039886474609, "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.07342933863401413}, {"id": 853, "seek": 483864, "start": 4843.200000000001, "end": 4847.68, "text": " rather than get on a triple seven, but I won't go two hours later. I mean, I want it to know all of", "tokens": [50592, 2831, 813, 483, 322, 257, 15508, 3407, 11, 457, 286, 1582, 380, 352, 732, 2496, 1780, 13, 286, 914, 11, 286, 528, 309, 281, 458, 439, 295, 50816], "temperature": 0.0, "avg_logprob": -0.07976039886474609, "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.07342933863401413}, {"id": 854, "seek": 483864, "start": 4847.68, "end": 4854.0, "text": " that and to give me that experience that I want. But I certainly don't want to be on the wrong end", "tokens": [50816, 300, 293, 281, 976, 385, 300, 1752, 300, 286, 528, 13, 583, 286, 3297, 500, 380, 528, 281, 312, 322, 264, 2085, 917, 51132], "temperature": 0.0, "avg_logprob": -0.07976039886474609, "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.07342933863401413}, {"id": 855, "seek": 483864, "start": 4854.0, "end": 4859.52, "text": " of thousands of bot-generated messages and trying to work out which ones I have to pay attention to", "tokens": [51132, 295, 5383, 295, 10592, 12, 21848, 770, 7897, 293, 1382, 281, 589, 484, 597, 2306, 286, 362, 281, 1689, 3202, 281, 51408], "temperature": 0.0, "avg_logprob": -0.07976039886474609, "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.07342933863401413}, {"id": 856, "seek": 483864, "start": 4859.52, "end": 4864.08, "text": " or not. And I think that's a really interesting opportunity space for someone to play in.", "tokens": [51408, 420, 406, 13, 400, 286, 519, 300, 311, 257, 534, 1880, 2650, 1901, 337, 1580, 281, 862, 294, 13, 51636], "temperature": 0.0, "avg_logprob": -0.07976039886474609, "compression_ratio": 1.6472602739726028, "no_speech_prob": 0.07342933863401413}, {"id": 857, "seek": 486408, "start": 4864.08, "end": 4870.24, "text": " Just envisioning a quieter inbox is enough to make you a utopian in today's landscape.", "tokens": [50364, 1449, 24739, 278, 257, 43339, 35067, 307, 1547, 281, 652, 291, 257, 2839, 38447, 294, 965, 311, 9661, 13, 50672], "temperature": 0.0, "avg_logprob": -0.10529921271584251, "compression_ratio": 1.751937984496124, "no_speech_prob": 0.025952821597456932}, {"id": 858, "seek": 486408, "start": 4870.24, "end": 4877.2, "text": " But just on this bot to bot communication, one thing I do kind of worry about is the idea that", "tokens": [50672, 583, 445, 322, 341, 10592, 281, 10592, 6101, 11, 472, 551, 286, 360, 733, 295, 3292, 466, 307, 264, 1558, 300, 51020], "temperature": 0.0, "avg_logprob": -0.10529921271584251, "compression_ratio": 1.751937984496124, "no_speech_prob": 0.025952821597456932}, {"id": 859, "seek": 486408, "start": 4877.2, "end": 4884.4, "text": " the bot to bot communication may begin to happen in high dimensional latent space.", "tokens": [51020, 264, 10592, 281, 10592, 6101, 815, 1841, 281, 1051, 294, 1090, 18795, 48994, 1901, 13, 51380], "temperature": 0.0, "avg_logprob": -0.10529921271584251, "compression_ratio": 1.751937984496124, "no_speech_prob": 0.025952821597456932}, {"id": 860, "seek": 486408, "start": 4885.2, "end": 4888.32, "text": " Back and forth, in other words, like embedding to embedding, I sometimes call this the great", "tokens": [51420, 5833, 293, 5220, 11, 294, 661, 2283, 11, 411, 12240, 3584, 281, 12240, 3584, 11, 286, 2171, 818, 341, 264, 869, 51576], "temperature": 0.0, "avg_logprob": -0.10529921271584251, "compression_ratio": 1.751937984496124, "no_speech_prob": 0.025952821597456932}, {"id": 861, "seek": 486408, "start": 4888.32, "end": 4893.44, "text": " embedding. And I usually say beware the great embedding because at the point where the AIs are", "tokens": [51576, 12240, 3584, 13, 400, 286, 2673, 584, 312, 3039, 264, 869, 12240, 3584, 570, 412, 264, 935, 689, 264, 316, 6802, 366, 51832], "temperature": 0.0, "avg_logprob": -0.10529921271584251, "compression_ratio": 1.751937984496124, "no_speech_prob": 0.025952821597456932}, {"id": 862, "seek": 489344, "start": 4893.44, "end": 4900.0, "text": " all talking to each other in a machine language that is high dimensional and not human readable,", "tokens": [50364, 439, 1417, 281, 1184, 661, 294, 257, 3479, 2856, 300, 307, 1090, 18795, 293, 406, 1952, 49857, 11, 50692], "temperature": 0.0, "avg_logprob": -0.10857798674396266, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.0020501604303717613}, {"id": 863, "seek": 489344, "start": 4900.799999999999, "end": 4908.719999999999, "text": " we have an extremely inscrutable overall system that we probably may find like,", "tokens": [50732, 321, 362, 364, 4664, 1028, 10757, 32148, 4787, 1185, 300, 321, 1391, 815, 915, 411, 11, 51128], "temperature": 0.0, "avg_logprob": -0.10857798674396266, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.0020501604303717613}, {"id": 864, "seek": 489344, "start": 4908.719999999999, "end": 4913.04, "text": " we can't really untangle that knot. I think we could very quickly in the next few years", "tokens": [51128, 321, 393, 380, 534, 1701, 7846, 300, 16966, 13, 286, 519, 321, 727, 588, 2661, 294, 264, 958, 1326, 924, 51344], "temperature": 0.0, "avg_logprob": -0.10857798674396266, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.0020501604303717613}, {"id": 865, "seek": 489344, "start": 4913.679999999999, "end": 4917.36, "text": " end up in a spot where, yeah, we all have these bots, they're all communicating with other bots,", "tokens": [51376, 917, 493, 294, 257, 4008, 689, 11, 1338, 11, 321, 439, 362, 613, 35410, 11, 436, 434, 439, 17559, 365, 661, 35410, 11, 51560], "temperature": 0.0, "avg_logprob": -0.10857798674396266, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.0020501604303717613}, {"id": 866, "seek": 489344, "start": 4917.36, "end": 4922.639999999999, "text": " but we find that it doesn't really make sense for these bots to reduce everything to language", "tokens": [51560, 457, 321, 915, 300, 309, 1177, 380, 534, 652, 2020, 337, 613, 35410, 281, 5407, 1203, 281, 2856, 51824], "temperature": 0.0, "avg_logprob": -0.10857798674396266, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.0020501604303717613}, {"id": 867, "seek": 492264, "start": 4923.200000000001, "end": 4927.200000000001, "text": " and then send the language over and then have it be kind of re-embedded. Like,", "tokens": [50392, 293, 550, 2845, 264, 2856, 670, 293, 550, 362, 309, 312, 733, 295, 319, 12, 443, 2883, 9207, 13, 1743, 11, 50592], "temperature": 0.0, "avg_logprob": -0.1005785740338839, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.002800002694129944}, {"id": 868, "seek": 492264, "start": 4927.200000000001, "end": 4930.4800000000005, "text": " why don't they just talk to each other in their native language, which is this high", "tokens": [50592, 983, 500, 380, 436, 445, 751, 281, 1184, 661, 294, 641, 8470, 2856, 11, 597, 307, 341, 1090, 50756], "temperature": 0.0, "avg_logprob": -0.1005785740338839, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.002800002694129944}, {"id": 869, "seek": 492264, "start": 4930.4800000000005, "end": 4937.52, "text": " dimensional space. We see so many go through chapter-inversive different research that shows", "tokens": [50756, 18795, 1901, 13, 492, 536, 370, 867, 352, 807, 7187, 12, 259, 840, 488, 819, 2132, 300, 3110, 51108], "temperature": 0.0, "avg_logprob": -0.1005785740338839, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.002800002694129944}, {"id": 870, "seek": 492264, "start": 4937.52, "end": 4944.0, "text": " that this is very possible. You can adapt embeddings to another embedding space with basically", "tokens": [51108, 300, 341, 307, 588, 1944, 13, 509, 393, 6231, 12240, 29432, 281, 1071, 12240, 3584, 1901, 365, 1936, 51432], "temperature": 0.0, "avg_logprob": -0.1005785740338839, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.002800002694129944}, {"id": 871, "seek": 492264, "start": 4944.0, "end": 4949.92, "text": " just a single linear projection in many cases. You can connect vision space to language space", "tokens": [51432, 445, 257, 2167, 8213, 22743, 294, 867, 3331, 13, 509, 393, 1745, 5201, 1901, 281, 2856, 1901, 51728], "temperature": 0.0, "avg_logprob": -0.1005785740338839, "compression_ratio": 1.7209302325581395, "no_speech_prob": 0.002800002694129944}, {"id": 872, "seek": 494992, "start": 4949.92, "end": 4954.8, "text": " remarkably easily. If you have like, blip2 was one of my favorite examples of that where they took", "tokens": [50364, 37381, 3612, 13, 759, 291, 362, 411, 11, 888, 647, 17, 390, 472, 295, 452, 2954, 5110, 295, 300, 689, 436, 1890, 50608], "temperature": 0.0, "avg_logprob": -0.15398160252002402, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.007814195938408375}, {"id": 873, "seek": 494992, "start": 4954.8, "end": 4960.4, "text": " a frozen language model and a frozen vision model and just trained a small connector between them", "tokens": [50608, 257, 12496, 2856, 2316, 293, 257, 12496, 5201, 2316, 293, 445, 8895, 257, 1359, 19127, 1296, 552, 50888], "temperature": 0.0, "avg_logprob": -0.15398160252002402, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.007814195938408375}, {"id": 874, "seek": 494992, "start": 4960.4, "end": 4964.96, "text": " and unlocked this entirely new capability. Anyway, whatever, it was a long list of those", "tokens": [50888, 293, 30180, 341, 7696, 777, 13759, 13, 5684, 11, 2035, 11, 309, 390, 257, 938, 1329, 295, 729, 51116], "temperature": 0.0, "avg_logprob": -0.15398160252002402, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.007814195938408375}, {"id": 875, "seek": 494992, "start": 4964.96, "end": 4969.6, "text": " sorts of things I think demonstrating that it's possible. Then I'm like, man, we could very easily", "tokens": [51116, 7527, 295, 721, 286, 519, 29889, 300, 309, 311, 1944, 13, 1396, 286, 478, 411, 11, 587, 11, 321, 727, 588, 3612, 51348], "temperature": 0.0, "avg_logprob": -0.15398160252002402, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.007814195938408375}, {"id": 876, "seek": 494992, "start": 4969.6, "end": 4976.08, "text": " just find ourselves surrounded by AIs communicating with other AIs in a high dimensional way that", "tokens": [51348, 445, 915, 4175, 13221, 538, 316, 6802, 17559, 365, 661, 316, 6802, 294, 257, 1090, 18795, 636, 300, 51672], "temperature": 0.0, "avg_logprob": -0.15398160252002402, "compression_ratio": 1.6228956228956228, "no_speech_prob": 0.007814195938408375}, {"id": 877, "seek": 497608, "start": 4976.08, "end": 4981.36, "text": " we can't even really understand anymore. Now, we're in a situation where things seem to be", "tokens": [50364, 321, 393, 380, 754, 534, 1223, 3602, 13, 823, 11, 321, 434, 294, 257, 2590, 689, 721, 1643, 281, 312, 50628], "temperature": 0.0, "avg_logprob": -0.10847036462081106, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.002980015007779002}, {"id": 878, "seek": 497608, "start": 4981.36, "end": 4990.16, "text": " kind of working, but we don't really even know why or how. This is one of the more realistic,", "tokens": [50628, 733, 295, 1364, 11, 457, 321, 500, 380, 534, 754, 458, 983, 420, 577, 13, 639, 307, 472, 295, 264, 544, 12465, 11, 51068], "temperature": 0.0, "avg_logprob": -0.10847036462081106, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.002980015007779002}, {"id": 879, "seek": 497608, "start": 4990.16, "end": 4995.44, "text": " I think, loss of control scenarios. It's almost like the final scene of the movie,", "tokens": [51068, 286, 519, 11, 4470, 295, 1969, 15077, 13, 467, 311, 1920, 411, 264, 2572, 4145, 295, 264, 3169, 11, 51332], "temperature": 0.0, "avg_logprob": -0.10847036462081106, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.002980015007779002}, {"id": 880, "seek": 497608, "start": 4995.44, "end": 4999.84, "text": " her, where the AIs go talk to each other. The bots are going to end up communicating", "tokens": [51332, 720, 11, 689, 264, 316, 6802, 352, 751, 281, 1184, 661, 13, 440, 35410, 366, 516, 281, 917, 493, 17559, 51552], "temperature": 0.0, "avg_logprob": -0.10847036462081106, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.002980015007779002}, {"id": 881, "seek": 497608, "start": 4999.84, "end": 5004.72, "text": " to each other because it's helpful for us and we don't want to sit in between them.", "tokens": [51552, 281, 1184, 661, 570, 309, 311, 4961, 337, 505, 293, 321, 500, 380, 528, 281, 1394, 294, 1296, 552, 13, 51796], "temperature": 0.0, "avg_logprob": -0.10847036462081106, "compression_ratio": 1.6577946768060836, "no_speech_prob": 0.002980015007779002}, {"id": 882, "seek": 500472, "start": 5005.68, "end": 5010.88, "text": " And they will discover just through their optimization functions that translating", "tokens": [50412, 400, 436, 486, 4411, 445, 807, 641, 19618, 6828, 300, 35030, 50672], "temperature": 0.0, "avg_logprob": -0.16924325625101724, "compression_ratio": 1.5427350427350428, "no_speech_prob": 0.002883563283830881}, {"id": 883, "seek": 500472, "start": 5010.88, "end": 5017.6, "text": " kind of complex concepts into, hello, I'm here to request a meeting with Nathan is inefficient. So", "tokens": [50672, 733, 295, 3997, 10392, 666, 11, 7751, 11, 286, 478, 510, 281, 5308, 257, 3440, 365, 20634, 307, 43495, 13, 407, 51008], "temperature": 0.0, "avg_logprob": -0.16924325625101724, "compression_ratio": 1.5427350427350428, "no_speech_prob": 0.002883563283830881}, {"id": 884, "seek": 500472, "start": 5017.6, "end": 5023.4400000000005, "text": " they'll just do it in their high level representation language, which is this embedding space, which,", "tokens": [51008, 436, 603, 445, 360, 309, 294, 641, 1090, 1496, 10290, 2856, 11, 597, 307, 341, 12240, 3584, 1901, 11, 597, 11, 51300], "temperature": 0.0, "avg_logprob": -0.16924325625101724, "compression_ratio": 1.5427350427350428, "no_speech_prob": 0.002883563283830881}, {"id": 885, "seek": 500472, "start": 5024.08, "end": 5031.4400000000005, "text": " as you say, is inscrutable to us. Is that reasonably the start of all of this?", "tokens": [51332, 382, 291, 584, 11, 307, 1028, 10757, 32148, 281, 505, 13, 1119, 300, 23551, 264, 722, 295, 439, 295, 341, 30, 51700], "temperature": 0.0, "avg_logprob": -0.16924325625101724, "compression_ratio": 1.5427350427350428, "no_speech_prob": 0.002883563283830881}, {"id": 886, "seek": 503144, "start": 5031.759999999999, "end": 5035.04, "text": " Yeah, that's right. And I think there's enough out there to kind of show that", "tokens": [50380, 865, 11, 300, 311, 558, 13, 400, 286, 519, 456, 311, 1547, 484, 456, 281, 733, 295, 855, 300, 50544], "temperature": 0.0, "avg_logprob": -0.1326229331198703, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0038237597327679396}, {"id": 887, "seek": 503144, "start": 5037.2, "end": 5043.04, "text": " a lot more room in the embedding space than language can actually reach. So that's one", "tokens": [50652, 257, 688, 544, 1808, 294, 264, 12240, 3584, 1901, 813, 2856, 393, 767, 2524, 13, 407, 300, 311, 472, 50944], "temperature": 0.0, "avg_logprob": -0.1326229331198703, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0038237597327679396}, {"id": 888, "seek": 503144, "start": 5043.04, "end": 5050.32, "text": " of the things with the sort of bridge models where you find that the classic saying, of course,", "tokens": [50944, 295, 264, 721, 365, 264, 1333, 295, 7283, 5245, 689, 291, 915, 300, 264, 7230, 1566, 11, 295, 1164, 11, 51308], "temperature": 0.0, "avg_logprob": -0.1326229331198703, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0038237597327679396}, {"id": 889, "seek": 503144, "start": 5050.32, "end": 5056.799999999999, "text": " is a picture is worth a thousand words, but you can also take an image and project it into this", "tokens": [51308, 307, 257, 3036, 307, 3163, 257, 4714, 2283, 11, 457, 291, 393, 611, 747, 364, 3256, 293, 1716, 309, 666, 341, 51632], "temperature": 0.0, "avg_logprob": -0.1326229331198703, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0038237597327679396}, {"id": 890, "seek": 505680, "start": 5056.8, "end": 5063.4400000000005, "text": " language space. The resulting thing in language space is not something that you could get to", "tokens": [50364, 2856, 1901, 13, 440, 16505, 551, 294, 2856, 1901, 307, 406, 746, 300, 291, 727, 483, 281, 50696], "temperature": 0.0, "avg_logprob": -0.08370823719922234, "compression_ratio": 1.832214765100671, "no_speech_prob": 0.005058287642896175}, {"id": 891, "seek": 505680, "start": 5063.4400000000005, "end": 5068.08, "text": " via actual language, but it's in language space. And so it has this kind of semantic meaning.", "tokens": [50696, 5766, 3539, 2856, 11, 457, 309, 311, 294, 2856, 1901, 13, 400, 370, 309, 575, 341, 733, 295, 47982, 3620, 13, 50928], "temperature": 0.0, "avg_logprob": -0.08370823719922234, "compression_ratio": 1.832214765100671, "no_speech_prob": 0.005058287642896175}, {"id": 892, "seek": 505680, "start": 5068.64, "end": 5072.72, "text": " And yeah, like, we, you know, what are we going to do with that, right? We can't,", "tokens": [50956, 400, 1338, 11, 411, 11, 321, 11, 291, 458, 11, 437, 366, 321, 516, 281, 360, 365, 300, 11, 558, 30, 492, 393, 380, 11, 51160], "temperature": 0.0, "avg_logprob": -0.08370823719922234, "compression_ratio": 1.832214765100671, "no_speech_prob": 0.005058287642896175}, {"id": 893, "seek": 505680, "start": 5072.72, "end": 5076.24, "text": " we can't even really inspect it. We can't even really read the logs anymore at that point.", "tokens": [51160, 321, 393, 380, 754, 534, 15018, 309, 13, 492, 393, 380, 754, 534, 1401, 264, 20820, 3602, 412, 300, 935, 13, 51336], "temperature": 0.0, "avg_logprob": -0.08370823719922234, "compression_ratio": 1.832214765100671, "no_speech_prob": 0.005058287642896175}, {"id": 894, "seek": 505680, "start": 5076.24, "end": 5081.4400000000005, "text": " I mean, it's a manifestation of what we might call the space of possible minds, right? So AI", "tokens": [51336, 286, 914, 11, 309, 311, 257, 29550, 295, 437, 321, 1062, 818, 264, 1901, 295, 1944, 9634, 11, 558, 30, 407, 7318, 51596], "temperature": 0.0, "avg_logprob": -0.08370823719922234, "compression_ratio": 1.832214765100671, "no_speech_prob": 0.005058287642896175}, {"id": 895, "seek": 505680, "start": 5081.4400000000005, "end": 5085.28, "text": " researchers have talked about this idea that, you know, octopus intelligence is intelligence,", "tokens": [51596, 10309, 362, 2825, 466, 341, 1558, 300, 11, 291, 458, 11, 27962, 7599, 307, 7599, 11, 51788], "temperature": 0.0, "avg_logprob": -0.08370823719922234, "compression_ratio": 1.832214765100671, "no_speech_prob": 0.005058287642896175}, {"id": 896, "seek": 508528, "start": 5085.28, "end": 5090.48, "text": " but it's got dimensions that may well be orthogonal to human intelligence. And", "tokens": [50364, 457, 309, 311, 658, 12819, 300, 815, 731, 312, 41488, 281, 1952, 7599, 13, 400, 50624], "temperature": 0.0, "avg_logprob": -0.1358554196912189, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.0010159725788980722}, {"id": 897, "seek": 508528, "start": 5090.48, "end": 5096.96, "text": " what you've described as a mechanism, I think by which you get there with machine, you know,", "tokens": [50624, 437, 291, 600, 7619, 382, 257, 7513, 11, 286, 519, 538, 597, 291, 483, 456, 365, 3479, 11, 291, 458, 11, 50948], "temperature": 0.0, "avg_logprob": -0.1358554196912189, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.0010159725788980722}, {"id": 898, "seek": 508528, "start": 5096.96, "end": 5104.88, "text": " with machine based intelligence. And so that might literally be not just the semantics, but", "tokens": [50948, 365, 3479, 2361, 7599, 13, 400, 370, 300, 1062, 3736, 312, 406, 445, 264, 4361, 45298, 11, 457, 51344], "temperature": 0.0, "avg_logprob": -0.1358554196912189, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.0010159725788980722}, {"id": 899, "seek": 508528, "start": 5104.88, "end": 5109.679999999999, "text": " actually think back, have you ever heard of read the story Flatland? It was, it's a mathematical", "tokens": [51344, 767, 519, 646, 11, 362, 291, 1562, 2198, 295, 1401, 264, 1657, 36172, 1661, 30, 467, 390, 11, 309, 311, 257, 18894, 51584], "temperature": 0.0, "avg_logprob": -0.1358554196912189, "compression_ratio": 1.6143497757847534, "no_speech_prob": 0.0010159725788980722}, {"id": 900, "seek": 510968, "start": 5109.68, "end": 5116.96, "text": " story. It's about 2D people in a kind of 3D world, and they, they don't understand the concept of", "tokens": [50364, 1657, 13, 467, 311, 466, 568, 35, 561, 294, 257, 733, 295, 805, 35, 1002, 11, 293, 436, 11, 436, 500, 380, 1223, 264, 3410, 295, 50728], "temperature": 0.0, "avg_logprob": -0.13793328603108723, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.019160808995366096}, {"id": 901, "seek": 510968, "start": 5116.96, "end": 5123.4400000000005, "text": " height. And so spheres pass through and they appear as sort of dots and lines and so on. And in that", "tokens": [50728, 6681, 13, 400, 370, 41225, 1320, 807, 293, 436, 4204, 382, 1333, 295, 15026, 293, 3876, 293, 370, 322, 13, 400, 294, 300, 51052], "temperature": 0.0, "avg_logprob": -0.13793328603108723, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.019160808995366096}, {"id": 902, "seek": 510968, "start": 5123.4400000000005, "end": 5130.240000000001, "text": " sense, there could be, this could be, you know, emerging among systems that are among us. And", "tokens": [51052, 2020, 11, 456, 727, 312, 11, 341, 727, 312, 11, 291, 458, 11, 14989, 3654, 3652, 300, 366, 3654, 505, 13, 400, 51392], "temperature": 0.0, "avg_logprob": -0.13793328603108723, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.019160808995366096}, {"id": 903, "seek": 510968, "start": 5130.240000000001, "end": 5134.56, "text": " there's like, I guess there's a second thing, which is also about timing. I think there'll be a", "tokens": [51392, 456, 311, 411, 11, 286, 2041, 456, 311, 257, 1150, 551, 11, 597, 307, 611, 466, 10822, 13, 286, 519, 456, 603, 312, 257, 51608], "temperature": 0.0, "avg_logprob": -0.13793328603108723, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.019160808995366096}, {"id": 904, "seek": 513456, "start": 5134.56, "end": 5140.080000000001, "text": " relentless pressure to take the human out of the loop in decision making, first in the softest", "tokens": [50364, 46136, 3321, 281, 747, 264, 1952, 484, 295, 264, 6367, 294, 3537, 1455, 11, 700, 294, 264, 2787, 377, 50640], "temperature": 0.0, "avg_logprob": -0.11035565579875131, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.057934150099754333}, {"id": 905, "seek": 513456, "start": 5140.080000000001, "end": 5144.56, "text": " decision making, like customer service tickets, and then increasingly more and more so, because", "tokens": [50640, 3537, 1455, 11, 411, 5474, 2643, 12628, 11, 293, 550, 12980, 544, 293, 544, 370, 11, 570, 50864], "temperature": 0.0, "avg_logprob": -0.11035565579875131, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.057934150099754333}, {"id": 906, "seek": 513456, "start": 5144.56, "end": 5149.04, "text": " speed will be a competitive advantage. And, you know, the human will blow the competitive advantage", "tokens": [50864, 3073, 486, 312, 257, 10043, 5002, 13, 400, 11, 291, 458, 11, 264, 1952, 486, 6327, 264, 10043, 5002, 51088], "temperature": 0.0, "avg_logprob": -0.11035565579875131, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.057934150099754333}, {"id": 907, "seek": 513456, "start": 5149.04, "end": 5157.120000000001, "text": " that you've got from, from your bots. And I guess there's another, there's another risk, which is", "tokens": [51088, 300, 291, 600, 658, 490, 11, 490, 428, 35410, 13, 400, 286, 2041, 456, 311, 1071, 11, 456, 311, 1071, 3148, 11, 597, 307, 51492], "temperature": 0.0, "avg_logprob": -0.11035565579875131, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.057934150099754333}, {"id": 908, "seek": 515712, "start": 5157.12, "end": 5164.72, "text": " that lots of bots connected to each other are, are also at risk to cascades, right? Information", "tokens": [50364, 300, 3195, 295, 35410, 4582, 281, 1184, 661, 366, 11, 366, 611, 412, 3148, 281, 3058, 66, 2977, 11, 558, 30, 15357, 50744], "temperature": 0.0, "avg_logprob": -0.13950293134934832, "compression_ratio": 1.53515625, "no_speech_prob": 0.11284341663122177}, {"id": 909, "seek": 515712, "start": 5164.72, "end": 5171.04, "text": " cascades. We see cascading failures, New York City blackout in 1976, the AT&T network failure in,", "tokens": [50744, 3058, 66, 2977, 13, 492, 536, 3058, 66, 8166, 20774, 11, 1873, 3609, 4392, 2211, 346, 294, 33978, 11, 264, 8872, 5, 51, 3209, 7763, 294, 11, 51060], "temperature": 0.0, "avg_logprob": -0.13950293134934832, "compression_ratio": 1.53515625, "no_speech_prob": 0.11284341663122177}, {"id": 910, "seek": 515712, "start": 5171.04, "end": 5177.2, "text": " I guess it was 91 or maybe it was 95, some of the worms. And we have governance mechanisms in place", "tokens": [51060, 286, 2041, 309, 390, 31064, 420, 1310, 309, 390, 13420, 11, 512, 295, 264, 28271, 13, 400, 321, 362, 17449, 15902, 294, 1081, 51368], "temperature": 0.0, "avg_logprob": -0.13950293134934832, "compression_ratio": 1.53515625, "no_speech_prob": 0.11284341663122177}, {"id": 911, "seek": 515712, "start": 5177.2, "end": 5181.84, "text": " to now tackle those and stop those in the financial services industries, you know, you have circuit", "tokens": [51368, 281, 586, 14896, 729, 293, 1590, 729, 294, 264, 4669, 3328, 13284, 11, 291, 458, 11, 291, 362, 9048, 51600], "temperature": 0.0, "avg_logprob": -0.13950293134934832, "compression_ratio": 1.53515625, "no_speech_prob": 0.11284341663122177}, {"id": 912, "seek": 518184, "start": 5181.84, "end": 5187.12, "text": " breakers. And I'm just thinking about putting all of those together with the scenario that you,", "tokens": [50364, 1821, 433, 13, 400, 286, 478, 445, 1953, 466, 3372, 439, 295, 729, 1214, 365, 264, 9005, 300, 291, 11, 50628], "temperature": 0.0, "avg_logprob": -0.09211613392007761, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.3708721995353699}, {"id": 913, "seek": 518184, "start": 5187.12, "end": 5192.56, "text": " that you painted. So this would happen really, really quickly, could happen really quickly,", "tokens": [50628, 300, 291, 11797, 13, 407, 341, 576, 1051, 534, 11, 534, 2661, 11, 727, 1051, 534, 2661, 11, 50900], "temperature": 0.0, "avg_logprob": -0.09211613392007761, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.3708721995353699}, {"id": 914, "seek": 518184, "start": 5192.56, "end": 5196.400000000001, "text": " and it could start to accelerate and work effectively at millisecond time, right, which is", "tokens": [50900, 293, 309, 727, 722, 281, 21341, 293, 589, 8659, 412, 27940, 18882, 565, 11, 558, 11, 597, 307, 51092], "temperature": 0.0, "avg_logprob": -0.09211613392007761, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.3708721995353699}, {"id": 915, "seek": 518184, "start": 5196.400000000001, "end": 5202.32, "text": " the time it takes across the internet to, to get to another system. What, what are you concerned", "tokens": [51092, 264, 565, 309, 2516, 2108, 264, 4705, 281, 11, 281, 483, 281, 1071, 1185, 13, 708, 11, 437, 366, 291, 5922, 51388], "temperature": 0.0, "avg_logprob": -0.09211613392007761, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.3708721995353699}, {"id": 916, "seek": 518184, "start": 5202.32, "end": 5207.6, "text": " with about the inscrutability? Is it just that it's inscrutable? So we don't know what's going on", "tokens": [51388, 365, 466, 264, 1028, 10757, 325, 2310, 30, 1119, 309, 445, 300, 309, 311, 1028, 10757, 32148, 30, 407, 321, 500, 380, 458, 437, 311, 516, 322, 51652], "temperature": 0.0, "avg_logprob": -0.09211613392007761, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.3708721995353699}, {"id": 917, "seek": 520760, "start": 5207.6, "end": 5215.76, "text": " there? Or is it that it's inscrutable, and there could be harboring some kind of bad set of outcomes?", "tokens": [50364, 456, 30, 1610, 307, 309, 300, 309, 311, 1028, 10757, 32148, 11, 293, 456, 727, 312, 2233, 65, 3662, 512, 733, 295, 1578, 992, 295, 10070, 30, 50772], "temperature": 0.0, "avg_logprob": -0.13200903838535524, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.01589873805642128}, {"id": 918, "seek": 520760, "start": 5215.76, "end": 5220.64, "text": " Yeah, who knows? I mean, you know, you can layer on more and more concerns. I should credit, I think,", "tokens": [50772, 865, 11, 567, 3255, 30, 286, 914, 11, 291, 458, 11, 291, 393, 4583, 322, 544, 293, 544, 7389, 13, 286, 820, 5397, 11, 286, 519, 11, 51016], "temperature": 0.0, "avg_logprob": -0.13200903838535524, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.01589873805642128}, {"id": 919, "seek": 520760, "start": 5220.64, "end": 5227.4400000000005, "text": " probably Ajaya Katra is a, is a great person to go read for a long form characterization of this,", "tokens": [51016, 1391, 25862, 4427, 8365, 424, 307, 257, 11, 307, 257, 869, 954, 281, 352, 1401, 337, 257, 938, 1254, 49246, 295, 341, 11, 51356], "temperature": 0.0, "avg_logprob": -0.13200903838535524, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.01589873805642128}, {"id": 920, "seek": 520760, "start": 5227.4400000000005, "end": 5233.52, "text": " her essay, I forget the exact title, but it basically amounts to in the absence of specific", "tokens": [51356, 720, 16238, 11, 286, 2870, 264, 1900, 4876, 11, 457, 309, 1936, 11663, 281, 294, 264, 17145, 295, 2685, 51660], "temperature": 0.0, "avg_logprob": -0.13200903838535524, "compression_ratio": 1.5533596837944663, "no_speech_prob": 0.01589873805642128}, {"id": 921, "seek": 523352, "start": 5233.6, "end": 5241.120000000001, "text": " countermeasures, the default path to AGI likely leads to AI takeover. And it's kind of this scenario", "tokens": [50368, 5682, 1398, 20044, 11, 264, 7576, 3100, 281, 316, 26252, 3700, 6689, 281, 7318, 747, 3570, 13, 400, 309, 311, 733, 295, 341, 9005, 50744], "temperature": 0.0, "avg_logprob": -0.08304470126368418, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.01971246674656868}, {"id": 922, "seek": 523352, "start": 5241.120000000001, "end": 5247.040000000001, "text": " where she envisions more and more work being done by AI, the times, you know, cycles being", "tokens": [50744, 689, 750, 2267, 4252, 544, 293, 544, 589, 885, 1096, 538, 7318, 11, 264, 1413, 11, 291, 458, 11, 17796, 885, 51040], "temperature": 0.0, "avg_logprob": -0.08304470126368418, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.01971246674656868}, {"id": 923, "seek": 523352, "start": 5247.040000000001, "end": 5251.6, "text": " compressed, the, I don't know if she specifically has this like high dimensional communication", "tokens": [51040, 30353, 11, 264, 11, 286, 500, 380, 458, 498, 750, 4682, 575, 341, 411, 1090, 18795, 6101, 51268], "temperature": 0.0, "avg_logprob": -0.08304470126368418, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.01971246674656868}, {"id": 924, "seek": 523352, "start": 5251.6, "end": 5257.4400000000005, "text": " aspect to it, but the notion is still that just it becomes so fast and so dense, that it's very", "tokens": [51268, 4171, 281, 309, 11, 457, 264, 10710, 307, 920, 300, 445, 309, 3643, 370, 2370, 293, 370, 18011, 11, 300, 309, 311, 588, 51560], "temperature": 0.0, "avg_logprob": -0.08304470126368418, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.01971246674656868}, {"id": 925, "seek": 523352, "start": 5257.4400000000005, "end": 5261.84, "text": " hard for people to figure out exactly what's going on and why. And as long as that's working,", "tokens": [51560, 1152, 337, 561, 281, 2573, 484, 2293, 437, 311, 516, 322, 293, 983, 13, 400, 382, 938, 382, 300, 311, 1364, 11, 51780], "temperature": 0.0, "avg_logprob": -0.08304470126368418, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.01971246674656868}, {"id": 926, "seek": 526184, "start": 5261.84, "end": 5267.04, "text": " and, you know, we're getting more stuff out of the machine, and, you know, consumer surplus is", "tokens": [50364, 293, 11, 291, 458, 11, 321, 434, 1242, 544, 1507, 484, 295, 264, 3479, 11, 293, 11, 291, 458, 11, 9711, 31019, 307, 50624], "temperature": 0.0, "avg_logprob": -0.09679460933065823, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.002050599083304405}, {"id": 927, "seek": 526184, "start": 5267.04, "end": 5271.28, "text": " through the roof, which is definitely something I expect is a lot of consumer surplus. Then", "tokens": [50624, 807, 264, 8418, 11, 597, 307, 2138, 746, 286, 2066, 307, 257, 688, 295, 9711, 31019, 13, 1396, 50836], "temperature": 0.0, "avg_logprob": -0.09679460933065823, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.002050599083304405}, {"id": 928, "seek": 526184, "start": 5271.28, "end": 5276.0, "text": " everybody would be very happy with this, but we don't really know, you know, what we don't know", "tokens": [50836, 2201, 576, 312, 588, 2055, 365, 341, 11, 457, 321, 500, 380, 534, 458, 11, 291, 458, 11, 437, 321, 500, 380, 458, 51072], "temperature": 0.0, "avg_logprob": -0.09679460933065823, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.002050599083304405}, {"id": 929, "seek": 526184, "start": 5276.0, "end": 5282.400000000001, "text": " about where that leads us. And that could be like emergent, you know, autonomy or goals that are", "tokens": [51072, 466, 689, 300, 6689, 505, 13, 400, 300, 727, 312, 411, 4345, 6930, 11, 291, 458, 11, 27278, 420, 5493, 300, 366, 51392], "temperature": 0.0, "avg_logprob": -0.09679460933065823, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.002050599083304405}, {"id": 930, "seek": 526184, "start": 5282.400000000001, "end": 5287.28, "text": " contradictory to ours, or it could just be these more sort of unintentional cascading failures", "tokens": [51392, 49555, 281, 11896, 11, 420, 309, 727, 445, 312, 613, 544, 1333, 295, 45514, 304, 3058, 66, 8166, 20774, 51636], "temperature": 0.0, "avg_logprob": -0.09679460933065823, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.002050599083304405}, {"id": 931, "seek": 528728, "start": 5287.28, "end": 5291.599999999999, "text": " along the lines of like an Alpha Go. Like Alpha Go isn't out to get us, you know, by failing,", "tokens": [50364, 2051, 264, 3876, 295, 411, 364, 20588, 1037, 13, 1743, 20588, 1037, 1943, 380, 484, 281, 483, 505, 11, 291, 458, 11, 538, 18223, 11, 50580], "temperature": 0.0, "avg_logprob": -0.1215085811443157, "compression_ratio": 1.6605166051660516, "no_speech_prob": 0.0035922990646213293}, {"id": 932, "seek": 528728, "start": 5291.599999999999, "end": 5297.04, "text": " but it just turns out it has these like fatal vulnerabilities that are just not obvious,", "tokens": [50580, 457, 309, 445, 4523, 484, 309, 575, 613, 411, 24069, 37633, 300, 366, 445, 406, 6322, 11, 50852], "temperature": 0.0, "avg_logprob": -0.1215085811443157, "compression_ratio": 1.6605166051660516, "no_speech_prob": 0.0035922990646213293}, {"id": 933, "seek": 528728, "start": 5297.04, "end": 5302.08, "text": " and until somebody finds them. So one of the reasons I'm more, I'm a bit more", "tokens": [50852, 293, 1826, 2618, 10704, 552, 13, 407, 472, 295, 264, 4112, 286, 478, 544, 11, 286, 478, 257, 857, 544, 51104], "temperature": 0.0, "avg_logprob": -0.1215085811443157, "compression_ratio": 1.6605166051660516, "no_speech_prob": 0.0035922990646213293}, {"id": 934, "seek": 528728, "start": 5302.08, "end": 5308.4, "text": " sanguine about that, that scenario, although I see, I see the risk is that I think we already have", "tokens": [51104, 9980, 15516, 466, 300, 11, 300, 9005, 11, 4878, 286, 536, 11, 286, 536, 264, 3148, 307, 300, 286, 519, 321, 1217, 362, 51420], "temperature": 0.0, "avg_logprob": -0.1215085811443157, "compression_ratio": 1.6605166051660516, "no_speech_prob": 0.0035922990646213293}, {"id": 935, "seek": 528728, "start": 5309.12, "end": 5315.599999999999, "text": " that decentralized agent to agent communication, communicating ways that most of us cannot", "tokens": [51456, 300, 32870, 9461, 281, 9461, 6101, 11, 17559, 2098, 300, 881, 295, 505, 2644, 51780], "temperature": 0.0, "avg_logprob": -0.1215085811443157, "compression_ratio": 1.6605166051660516, "no_speech_prob": 0.0035922990646213293}, {"id": 936, "seek": 531560, "start": 5315.6, "end": 5322.0, "text": " understand. And no single person can. And it's created a lot of consumer surplus. And that's the", "tokens": [50364, 1223, 13, 400, 572, 2167, 954, 393, 13, 400, 309, 311, 2942, 257, 688, 295, 9711, 31019, 13, 400, 300, 311, 264, 50684], "temperature": 0.0, "avg_logprob": -0.12497868595353093, "compression_ratio": 1.641255605381166, "no_speech_prob": 0.003952204715460539}, {"id": 937, "seek": 531560, "start": 5322.64, "end": 5330.240000000001, "text": " global modern economy that works through market systems. And it uses a signalling", "tokens": [50716, 4338, 4363, 5010, 300, 1985, 807, 2142, 3652, 13, 400, 309, 4960, 257, 1465, 24021, 51096], "temperature": 0.0, "avg_logprob": -0.12497868595353093, "compression_ratio": 1.641255605381166, "no_speech_prob": 0.003952204715460539}, {"id": 938, "seek": 531560, "start": 5330.8, "end": 5337.120000000001, "text": " method called the price mechanism to figure out where investment should take place over many,", "tokens": [51124, 3170, 1219, 264, 3218, 7513, 281, 2573, 484, 689, 6078, 820, 747, 1081, 670, 867, 11, 51440], "temperature": 0.0, "avg_logprob": -0.12497868595353093, "compression_ratio": 1.641255605381166, "no_speech_prob": 0.003952204715460539}, {"id": 939, "seek": 531560, "start": 5337.120000000001, "end": 5343.280000000001, "text": " many different time horizons to figure out what where demand lies. And, you know, the economy", "tokens": [51440, 867, 819, 565, 7937, 892, 281, 2573, 484, 437, 689, 4733, 9134, 13, 400, 11, 291, 458, 11, 264, 5010, 51748], "temperature": 0.0, "avg_logprob": -0.12497868595353093, "compression_ratio": 1.641255605381166, "no_speech_prob": 0.003952204715460539}, {"id": 940, "seek": 534328, "start": 5343.36, "end": 5350.08, "text": " from an Austrian standpoint, like a Hayekian standpoint, is a giant information processing", "tokens": [50368, 490, 364, 41507, 15827, 11, 411, 257, 8721, 916, 952, 15827, 11, 307, 257, 7410, 1589, 9007, 50704], "temperature": 0.0, "avg_logprob": -0.1081233758192796, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.001850596279837191}, {"id": 941, "seek": 534328, "start": 5350.08, "end": 5358.0, "text": " system. And it's made up of hierarchies of other information processing systems, you know, the", "tokens": [50704, 1185, 13, 400, 309, 311, 1027, 493, 295, 35250, 530, 295, 661, 1589, 9007, 3652, 11, 291, 458, 11, 264, 51100], "temperature": 0.0, "avg_logprob": -0.1081233758192796, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.001850596279837191}, {"id": 942, "seek": 534328, "start": 5358.0, "end": 5364.24, "text": " most atomic of which is the freelance human individual, and the more complex of which are", "tokens": [51100, 881, 22275, 295, 597, 307, 264, 47875, 1952, 2609, 11, 293, 264, 544, 3997, 295, 597, 366, 51412], "temperature": 0.0, "avg_logprob": -0.1081233758192796, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.001850596279837191}, {"id": 943, "seek": 534328, "start": 5364.96, "end": 5371.36, "text": " large mega corporations, which act against their own cost function or optimization function", "tokens": [51448, 2416, 17986, 17676, 11, 597, 605, 1970, 641, 1065, 2063, 2445, 420, 19618, 2445, 51768], "temperature": 0.0, "avg_logprob": -0.1081233758192796, "compression_ratio": 1.7149532710280373, "no_speech_prob": 0.001850596279837191}, {"id": 944, "seek": 537136, "start": 5371.36, "end": 5375.2, "text": " and behave in that system, sometimes with constraints, right, because they have dependencies", "tokens": [50364, 293, 15158, 294, 300, 1185, 11, 2171, 365, 18491, 11, 558, 11, 570, 436, 362, 36606, 50556], "temperature": 0.0, "avg_logprob": -0.0975781841042601, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.0028008290100842714}, {"id": 945, "seek": 537136, "start": 5375.2, "end": 5382.16, "text": " on supply chain and other things. And one of the reasons I'm a bit sanguine about the", "tokens": [50556, 322, 5847, 5021, 293, 661, 721, 13, 400, 472, 295, 264, 4112, 286, 478, 257, 857, 9980, 15516, 466, 264, 50904], "temperature": 0.0, "avg_logprob": -0.0975781841042601, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.0028008290100842714}, {"id": 946, "seek": 537136, "start": 5382.96, "end": 5391.36, "text": " idea of takeover is because what we describe in that world is the modern economy that we", "tokens": [50944, 1558, 295, 747, 3570, 307, 570, 437, 321, 6786, 294, 300, 1002, 307, 264, 4363, 5010, 300, 321, 51364], "temperature": 0.0, "avg_logprob": -0.0975781841042601, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.0028008290100842714}, {"id": 947, "seek": 537136, "start": 5392.0, "end": 5400.5599999999995, "text": " currently live with. And what we already know that it delivers tremendous benefits to us.", "tokens": [51396, 4362, 1621, 365, 13, 400, 437, 321, 1217, 458, 300, 309, 24860, 10048, 5311, 281, 505, 13, 51824], "temperature": 0.0, "avg_logprob": -0.0975781841042601, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.0028008290100842714}, {"id": 948, "seek": 540056, "start": 5400.56, "end": 5405.92, "text": " But it also delivers things that we don't value to us. I mean, the carbon crisis is one obvious", "tokens": [50364, 583, 309, 611, 24860, 721, 300, 321, 500, 380, 2158, 281, 505, 13, 286, 914, 11, 264, 5954, 5869, 307, 472, 6322, 50632], "temperature": 0.0, "avg_logprob": -0.0739838669939739, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.0021355021744966507}, {"id": 949, "seek": 540056, "start": 5405.92, "end": 5411.04, "text": " one. Quite often when we look at AI risk scenarios, someone goes off and says, well, the AI will", "tokens": [50632, 472, 13, 20464, 2049, 562, 321, 574, 412, 7318, 3148, 15077, 11, 1580, 1709, 766, 293, 1619, 11, 731, 11, 264, 7318, 486, 50888], "temperature": 0.0, "avg_logprob": -0.0739838669939739, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.0021355021744966507}, {"id": 950, "seek": 540056, "start": 5411.04, "end": 5417.04, "text": " persuade you that you should behave in a way that you otherwise wouldn't, which is literally known", "tokens": [50888, 31781, 291, 300, 291, 820, 15158, 294, 257, 636, 300, 291, 5911, 2759, 380, 11, 597, 307, 3736, 2570, 51188], "temperature": 0.0, "avg_logprob": -0.0739838669939739, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.0021355021744966507}, {"id": 951, "seek": 540056, "start": 5417.04, "end": 5422.88, "text": " as marketing. I mean, it is literally and, you know, the US is on is on the wrong end of an", "tokens": [51188, 382, 6370, 13, 286, 914, 11, 309, 307, 3736, 293, 11, 291, 458, 11, 264, 2546, 307, 322, 307, 322, 264, 2085, 917, 295, 364, 51480], "temperature": 0.0, "avg_logprob": -0.0739838669939739, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.0021355021744966507}, {"id": 952, "seek": 540056, "start": 5422.88, "end": 5429.84, "text": " obesity epidemic. And I'm not sure how many people acted with full agency to say, I want to be", "tokens": [51480, 29744, 20982, 13, 400, 286, 478, 406, 988, 577, 867, 561, 20359, 365, 1577, 7934, 281, 584, 11, 286, 528, 281, 312, 51828], "temperature": 0.0, "avg_logprob": -0.0739838669939739, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.0021355021744966507}, {"id": 953, "seek": 542984, "start": 5429.84, "end": 5435.6, "text": " 100 pounds heavier than is is healthy for me. That is my intention that and this is a decision", "tokens": [50364, 2319, 8319, 18279, 813, 307, 307, 4627, 337, 385, 13, 663, 307, 452, 7789, 300, 293, 341, 307, 257, 3537, 50652], "temperature": 0.0, "avg_logprob": -0.11350399739033468, "compression_ratio": 1.7084870848708487, "no_speech_prob": 0.004645729903131723}, {"id": 954, "seek": 542984, "start": 5435.6, "end": 5440.400000000001, "text": " I'm making with full agency. Somehow there is a emergent property about the way in which the", "tokens": [50652, 286, 478, 1455, 365, 1577, 7934, 13, 28357, 456, 307, 257, 4345, 6930, 4707, 466, 264, 636, 294, 597, 264, 50892], "temperature": 0.0, "avg_logprob": -0.11350399739033468, "compression_ratio": 1.7084870848708487, "no_speech_prob": 0.004645729903131723}, {"id": 955, "seek": 542984, "start": 5440.400000000001, "end": 5449.28, "text": " economy is met needs that has enabled that to to happen. I'm not making ethical or normative", "tokens": [50892, 5010, 307, 1131, 2203, 300, 575, 15172, 300, 281, 281, 1051, 13, 286, 478, 406, 1455, 18890, 420, 2026, 1166, 51336], "temperature": 0.0, "avg_logprob": -0.11350399739033468, "compression_ratio": 1.7084870848708487, "no_speech_prob": 0.004645729903131723}, {"id": 956, "seek": 542984, "start": 5449.28, "end": 5451.84, "text": " claims about whether that's a good thing or a bad thing, or whether people should have the", "tokens": [51336, 9441, 466, 1968, 300, 311, 257, 665, 551, 420, 257, 1578, 551, 11, 420, 1968, 561, 820, 362, 264, 51464], "temperature": 0.0, "avg_logprob": -0.11350399739033468, "compression_ratio": 1.7084870848708487, "no_speech_prob": 0.004645729903131723}, {"id": 957, "seek": 542984, "start": 5451.84, "end": 5456.96, "text": " freedom to do that or not. What I'm saying is that we have this system like a decentralized", "tokens": [51464, 5645, 281, 360, 300, 420, 406, 13, 708, 286, 478, 1566, 307, 300, 321, 362, 341, 1185, 411, 257, 32870, 51720], "temperature": 0.0, "avg_logprob": -0.11350399739033468, "compression_ratio": 1.7084870848708487, "no_speech_prob": 0.004645729903131723}, {"id": 958, "seek": 545696, "start": 5456.96, "end": 5464.0, "text": " agents, and they they do in a way compete with each other because not every single person in the", "tokens": [50364, 12554, 11, 293, 436, 436, 360, 294, 257, 636, 11831, 365, 1184, 661, 570, 406, 633, 2167, 954, 294, 264, 50716], "temperature": 0.0, "avg_logprob": -0.1394561485007957, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.011858860030770302}, {"id": 959, "seek": 545696, "start": 5464.0, "end": 5470.88, "text": " world is suffering from obesity and diabetes related conditions. People make other choices", "tokens": [50716, 1002, 307, 7755, 490, 29744, 293, 13881, 4077, 4487, 13, 3432, 652, 661, 7994, 51060], "temperature": 0.0, "avg_logprob": -0.1394561485007957, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.011858860030770302}, {"id": 960, "seek": 545696, "start": 5470.88, "end": 5476.88, "text": " and they're a push and pull forces. And so when I think about decentralized bots, I also think", "tokens": [51060, 293, 436, 434, 257, 2944, 293, 2235, 5874, 13, 400, 370, 562, 286, 519, 466, 32870, 35410, 11, 286, 611, 519, 51360], "temperature": 0.0, "avg_logprob": -0.1394561485007957, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.011858860030770302}, {"id": 961, "seek": 545696, "start": 5476.88, "end": 5483.28, "text": " about that that set of checks and balances that emerges when you have competing systems and", "tokens": [51360, 466, 300, 300, 992, 295, 13834, 293, 33993, 300, 38965, 562, 291, 362, 15439, 3652, 293, 51680], "temperature": 0.0, "avg_logprob": -0.1394561485007957, "compression_ratio": 1.6120689655172413, "no_speech_prob": 0.011858860030770302}, {"id": 962, "seek": 548328, "start": 5483.36, "end": 5489.04, "text": " they need to have a signal that they are reliant on. And to some extent, we set that signal.", "tokens": [50368, 436, 643, 281, 362, 257, 6358, 300, 436, 366, 1039, 5798, 322, 13, 400, 281, 512, 8396, 11, 321, 992, 300, 6358, 13, 50652], "temperature": 0.0, "avg_logprob": -0.1542414002499338, "compression_ratio": 1.625925925925926, "no_speech_prob": 0.003951662685722113}, {"id": 963, "seek": 548328, "start": 5489.759999999999, "end": 5494.719999999999, "text": " And that makes me feel, you know, sanguine, a little bit optimistic, still recognizing", "tokens": [50688, 400, 300, 1669, 385, 841, 11, 291, 458, 11, 9980, 15516, 11, 257, 707, 857, 19397, 11, 920, 18538, 50936], "temperature": 0.0, "avg_logprob": -0.1542414002499338, "compression_ratio": 1.625925925925926, "no_speech_prob": 0.003951662685722113}, {"id": 964, "seek": 548328, "start": 5494.719999999999, "end": 5500.32, "text": " there's like massive amounts of work to be done around, around safety and around risk,", "tokens": [50936, 456, 311, 411, 5994, 11663, 295, 589, 281, 312, 1096, 926, 11, 926, 4514, 293, 926, 3148, 11, 51216], "temperature": 0.0, "avg_logprob": -0.1542414002499338, "compression_ratio": 1.625925925925926, "no_speech_prob": 0.003951662685722113}, {"id": 965, "seek": 548328, "start": 5500.32, "end": 5504.5599999999995, "text": " around. I watched, I don't know if you ever watched this, Battlestar Galactica,", "tokens": [51216, 926, 13, 286, 6337, 11, 286, 500, 380, 458, 498, 291, 1562, 6337, 341, 11, 29439, 35745, 289, 7336, 578, 2262, 11, 51428], "temperature": 0.0, "avg_logprob": -0.1542414002499338, "compression_ratio": 1.625925925925926, "no_speech_prob": 0.003951662685722113}, {"id": 966, "seek": 548328, "start": 5504.5599999999995, "end": 5510.16, "text": " both the original, but also the remake with James Edward Olmos. And, you know, he's grizzled", "tokens": [51428, 1293, 264, 3380, 11, 457, 611, 264, 28582, 365, 5678, 18456, 6141, 3415, 13, 400, 11, 291, 458, 11, 415, 311, 17865, 4313, 1493, 51708], "temperature": 0.0, "avg_logprob": -0.1542414002499338, "compression_ratio": 1.625925925925926, "no_speech_prob": 0.003951662685722113}, {"id": 967, "seek": 551016, "start": 5510.24, "end": 5516.8, "text": " Adama, and he refuses to upgrade the Galactica's network to the modern standard that the rest of", "tokens": [50368, 1999, 2404, 11, 293, 415, 33222, 281, 11484, 264, 7336, 578, 2262, 311, 3209, 281, 264, 4363, 3832, 300, 264, 1472, 295, 50696], "temperature": 0.0, "avg_logprob": -0.1405428140470297, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.003802029648795724}, {"id": 968, "seek": 551016, "start": 5516.8, "end": 5522.48, "text": " the fleet uses. So he and the Pegasus, as we discover, so two seasons later, are the only", "tokens": [50696, 264, 19396, 4960, 13, 407, 415, 293, 264, 28007, 296, 301, 11, 382, 321, 4411, 11, 370, 732, 15050, 1780, 11, 366, 264, 787, 50980], "temperature": 0.0, "avg_logprob": -0.1405428140470297, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.003802029648795724}, {"id": 969, "seek": 551016, "start": 5522.48, "end": 5528.639999999999, "text": " Battlestars to survive the Sylon onslaught, because they put a worm in the system and they", "tokens": [50980, 29439, 35745, 685, 281, 7867, 264, 318, 34926, 18818, 875, 1599, 11, 570, 436, 829, 257, 23835, 294, 264, 1185, 293, 436, 51288], "temperature": 0.0, "avg_logprob": -0.1405428140470297, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.003802029648795724}, {"id": 970, "seek": 551016, "start": 5528.639999999999, "end": 5535.68, "text": " sort of turn it off, right? So we need to have kind of governance mechanisms in, in place up front", "tokens": [51288, 1333, 295, 1261, 309, 766, 11, 558, 30, 407, 321, 643, 281, 362, 733, 295, 17449, 15902, 294, 11, 294, 1081, 493, 1868, 51640], "temperature": 0.0, "avg_logprob": -0.1405428140470297, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.003802029648795724}, {"id": 971, "seek": 553568, "start": 5535.68, "end": 5541.84, "text": " that allow us to observe and monitor the kind of the risks that you've identified.", "tokens": [50364, 300, 2089, 505, 281, 11441, 293, 6002, 264, 733, 295, 264, 10888, 300, 291, 600, 9234, 13, 50672], "temperature": 0.0, "avg_logprob": -0.10487901463228114, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.00154799351003021}, {"id": 972, "seek": 553568, "start": 5541.84, "end": 5547.76, "text": " But a decentralized economy and decentralized hazard has as an emergent property a way of", "tokens": [50672, 583, 257, 32870, 5010, 293, 32870, 20790, 575, 382, 364, 4345, 6930, 4707, 257, 636, 295, 50968], "temperature": 0.0, "avg_logprob": -0.10487901463228114, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.00154799351003021}, {"id": 973, "seek": 553568, "start": 5547.76, "end": 5552.0, "text": " keeping things in check. You know, I think there's a kind of, there is a homeostasis", "tokens": [50968, 5145, 721, 294, 1520, 13, 509, 458, 11, 286, 519, 456, 311, 257, 733, 295, 11, 456, 307, 257, 1280, 555, 26632, 51180], "temperature": 0.0, "avg_logprob": -0.10487901463228114, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.00154799351003021}, {"id": 974, "seek": 553568, "start": 5552.0, "end": 5556.72, "text": " that emerges or a dynamic equilibrium that emerges. I think that is probably the most", "tokens": [51180, 300, 38965, 420, 257, 8546, 15625, 300, 38965, 13, 286, 519, 300, 307, 1391, 264, 881, 51416], "temperature": 0.0, "avg_logprob": -0.10487901463228114, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.00154799351003021}, {"id": 975, "seek": 553568, "start": 5556.72, "end": 5561.76, "text": " likely outcome. And so in that sense, I'm also, you know, reasonably optimistic.", "tokens": [51416, 3700, 9700, 13, 400, 370, 294, 300, 2020, 11, 286, 478, 611, 11, 291, 458, 11, 23551, 19397, 13, 51668], "temperature": 0.0, "avg_logprob": -0.10487901463228114, "compression_ratio": 1.6825396825396826, "no_speech_prob": 0.00154799351003021}, {"id": 976, "seek": 556176, "start": 5562.56, "end": 5567.6, "text": " But I do think it is worth really taking very seriously the idea that", "tokens": [50404, 583, 286, 360, 519, 309, 307, 3163, 534, 1940, 588, 6638, 264, 1558, 300, 50656], "temperature": 0.0, "avg_logprob": -0.11248064694339283, "compression_ratio": 1.595, "no_speech_prob": 0.029292870312929153}, {"id": 977, "seek": 556176, "start": 5568.320000000001, "end": 5574.88, "text": " either with certain thresholds being passed, certain kind of feedback loops that could be,", "tokens": [50692, 2139, 365, 1629, 14678, 82, 885, 4678, 11, 1629, 733, 295, 5824, 16121, 300, 727, 312, 11, 51020], "temperature": 0.0, "avg_logprob": -0.11248064694339283, "compression_ratio": 1.595, "no_speech_prob": 0.029292870312929153}, {"id": 978, "seek": 556176, "start": 5574.88, "end": 5578.400000000001, "text": " you know, triggered that are not yet triggered, things could change.", "tokens": [51020, 291, 458, 11, 21710, 300, 366, 406, 1939, 21710, 11, 721, 727, 1319, 13, 51196], "temperature": 0.0, "avg_logprob": -0.11248064694339283, "compression_ratio": 1.595, "no_speech_prob": 0.029292870312929153}, {"id": 979, "seek": 556176, "start": 5578.400000000001, "end": 5583.2, "text": " I just wanted to ask about that, because you have the advantage of having played with the", "tokens": [51196, 286, 445, 1415, 281, 1029, 466, 300, 11, 570, 291, 362, 264, 5002, 295, 1419, 3737, 365, 264, 51436], "temperature": 0.0, "avg_logprob": -0.11248064694339283, "compression_ratio": 1.595, "no_speech_prob": 0.029292870312929153}, {"id": 980, "seek": 558320, "start": 5583.679999999999, "end": 5593.04, "text": " untrained GPT-4. So you got to see, you know, GPT-4 in its Darth Vader phase rather than in its,", "tokens": [50388, 1701, 31774, 26039, 51, 12, 19, 13, 407, 291, 658, 281, 536, 11, 291, 458, 11, 26039, 51, 12, 19, 294, 1080, 40696, 36337, 5574, 2831, 813, 294, 1080, 11, 50856], "temperature": 0.0, "avg_logprob": -0.13799809047154019, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.1518576592206955}, {"id": 981, "seek": 558320, "start": 5593.04, "end": 5598.5599999999995, "text": " you know, reclaimed Anakin phase as a smart guy, right? Who understands technology. When you", "tokens": [50856, 291, 458, 11, 850, 22642, 47218, 5574, 382, 257, 4069, 2146, 11, 558, 30, 2102, 15146, 2899, 13, 1133, 291, 51132], "temperature": 0.0, "avg_logprob": -0.13799809047154019, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.1518576592206955}, {"id": 982, "seek": 558320, "start": 5599.28, "end": 5603.76, "text": " were playing with it in this, in this way, what were you, what were you feeling?", "tokens": [51168, 645, 2433, 365, 309, 294, 341, 11, 294, 341, 636, 11, 437, 645, 291, 11, 437, 645, 291, 2633, 30, 51392], "temperature": 0.0, "avg_logprob": -0.13799809047154019, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.1518576592206955}, {"id": 983, "seek": 558320, "start": 5604.639999999999, "end": 5610.88, "text": " Awe, for one thing, you know, just shock and awe of it. This exists a lot sooner than I expected", "tokens": [51436, 316, 826, 11, 337, 472, 551, 11, 291, 458, 11, 445, 5588, 293, 30912, 295, 309, 13, 639, 8198, 257, 688, 15324, 813, 286, 5176, 51748], "temperature": 0.0, "avg_logprob": -0.13799809047154019, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.1518576592206955}, {"id": 984, "seek": 561088, "start": 5610.88, "end": 5614.56, "text": " it would. You know, it always felt kind of like science fiction, even when I was with", "tokens": [50364, 309, 576, 13, 509, 458, 11, 309, 1009, 2762, 733, 295, 411, 3497, 13266, 11, 754, 562, 286, 390, 365, 50548], "temperature": 0.0, "avg_logprob": -0.12461638937191087, "compression_ratio": 1.6930091185410334, "no_speech_prob": 0.03621256351470947}, {"id": 985, "seek": 561088, "start": 5614.56, "end": 5620.32, "text": " Text of Inchi 2 and doing task automation and fine-tuning that model. You know, as of the summer", "tokens": [50548, 18643, 295, 682, 8036, 568, 293, 884, 5633, 17769, 293, 2489, 12, 83, 37726, 300, 2316, 13, 509, 458, 11, 382, 295, 264, 4266, 50836], "temperature": 0.0, "avg_logprob": -0.12461638937191087, "compression_ratio": 1.6930091185410334, "no_speech_prob": 0.03621256351470947}, {"id": 986, "seek": 561088, "start": 5620.32, "end": 5627.04, "text": " of 2022, I was very plugged in and, you know, putting points on the board for Waymark on a", "tokens": [50836, 295, 20229, 11, 286, 390, 588, 25679, 294, 293, 11, 291, 458, 11, 3372, 2793, 322, 264, 3150, 337, 9558, 5638, 322, 257, 51172], "temperature": 0.0, "avg_logprob": -0.12461638937191087, "compression_ratio": 1.6930091185410334, "no_speech_prob": 0.03621256351470947}, {"id": 987, "seek": 561088, "start": 5627.04, "end": 5630.88, "text": " regular basis with, you know, a new fine-tuned model that can do this task a little better and,", "tokens": [51172, 3890, 5143, 365, 11, 291, 458, 11, 257, 777, 2489, 12, 83, 43703, 2316, 300, 393, 360, 341, 5633, 257, 707, 1101, 293, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12461638937191087, "compression_ratio": 1.6930091185410334, "no_speech_prob": 0.03621256351470947}, {"id": 988, "seek": 561088, "start": 5630.88, "end": 5634.96, "text": " you know, improve our pipeline or whatever. And still, it was just such a dramatic leap that I", "tokens": [51364, 291, 458, 11, 3470, 527, 15517, 420, 2035, 13, 400, 920, 11, 309, 390, 445, 1270, 257, 12023, 19438, 300, 286, 51568], "temperature": 0.0, "avg_logprob": -0.12461638937191087, "compression_ratio": 1.6930091185410334, "no_speech_prob": 0.03621256351470947}, {"id": 989, "seek": 561088, "start": 5634.96, "end": 5640.400000000001, "text": " was like really taken aback by it. Mostly super excited about it. But then I would also say,", "tokens": [51568, 390, 411, 534, 2726, 410, 501, 538, 309, 13, 29035, 1687, 2919, 466, 309, 13, 583, 550, 286, 576, 611, 584, 11, 51840], "temperature": 0.0, "avg_logprob": -0.12461638937191087, "compression_ratio": 1.6930091185410334, "no_speech_prob": 0.03621256351470947}, {"id": 990, "seek": 564088, "start": 5640.88, "end": 5649.2, "text": " the big kind of safety lesson from that experience is that the control does not happen by default.", "tokens": [50364, 264, 955, 733, 295, 4514, 6898, 490, 300, 1752, 307, 300, 264, 1969, 775, 406, 1051, 538, 7576, 13, 50780], "temperature": 0.0, "avg_logprob": -0.07220581237305986, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.0004441835917532444}, {"id": 991, "seek": 564088, "start": 5649.2, "end": 5654.72, "text": " And there's many ways of even conceiving what control could or should be. So this was under", "tokens": [50780, 400, 456, 311, 867, 2098, 295, 754, 10413, 2123, 437, 1969, 727, 420, 820, 312, 13, 407, 341, 390, 833, 51056], "temperature": 0.0, "avg_logprob": -0.07220581237305986, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.0004441835917532444}, {"id": 992, "seek": 564088, "start": 5654.72, "end": 5661.36, "text": " control in the sense that it was totally helpful and totally aligned to what I was doing. I never", "tokens": [51056, 1969, 294, 264, 2020, 300, 309, 390, 3879, 4961, 293, 3879, 17962, 281, 437, 286, 390, 884, 13, 286, 1128, 51388], "temperature": 0.0, "avg_logprob": -0.07220581237305986, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.0004441835917532444}, {"id": 993, "seek": 564088, "start": 5661.36, "end": 5668.400000000001, "text": " saw any Sydney-like behavior from GPT-4 early. You know, it never turned on me. It always,", "tokens": [51388, 1866, 604, 21065, 12, 4092, 5223, 490, 26039, 51, 12, 19, 2440, 13, 509, 458, 11, 309, 1128, 3574, 322, 385, 13, 467, 1009, 11, 51740], "temperature": 0.0, "avg_logprob": -0.07220581237305986, "compression_ratio": 1.5532786885245902, "no_speech_prob": 0.0004441835917532444}, {"id": 994, "seek": 566840, "start": 5668.4, "end": 5675.12, "text": " 100% helped me with whatever I was presenting it with. But I do feel like we have this kind of", "tokens": [50364, 2319, 4, 4254, 385, 365, 2035, 286, 390, 15578, 309, 365, 13, 583, 286, 360, 841, 411, 321, 362, 341, 733, 295, 50700], "temperature": 0.0, "avg_logprob": -0.04650768183045468, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.006691828835755587}, {"id": 995, "seek": 566840, "start": 5675.12, "end": 5682.08, "text": " broad divergence between the capability of the systems and our ability to really control what", "tokens": [50700, 4152, 47387, 1296, 264, 13759, 295, 264, 3652, 293, 527, 3485, 281, 534, 1969, 437, 51048], "temperature": 0.0, "avg_logprob": -0.04650768183045468, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.006691828835755587}, {"id": 996, "seek": 566840, "start": 5682.08, "end": 5687.44, "text": " they're going to do or how they might be used. At this point, I wouldn't say we have anything", "tokens": [51048, 436, 434, 516, 281, 360, 420, 577, 436, 1062, 312, 1143, 13, 1711, 341, 935, 11, 286, 2759, 380, 584, 321, 362, 1340, 51316], "temperature": 0.0, "avg_logprob": -0.04650768183045468, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.006691828835755587}, {"id": 997, "seek": 566840, "start": 5688.32, "end": 5692.0, "text": " to worry about yet. You know, I don't think we have anything concrete that looks to me like", "tokens": [51360, 281, 3292, 466, 1939, 13, 509, 458, 11, 286, 500, 380, 519, 321, 362, 1340, 9859, 300, 1542, 281, 385, 411, 51544], "temperature": 0.0, "avg_logprob": -0.04650768183045468, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.006691828835755587}, {"id": 998, "seek": 566840, "start": 5692.0, "end": 5696.639999999999, "text": " the AI could run away on its own. And I did probe for that. You know, in my red teaming,", "tokens": [51544, 264, 7318, 727, 1190, 1314, 322, 1080, 1065, 13, 400, 286, 630, 22715, 337, 300, 13, 509, 458, 11, 294, 452, 2182, 1469, 278, 11, 51776], "temperature": 0.0, "avg_logprob": -0.04650768183045468, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.006691828835755587}, {"id": 999, "seek": 569664, "start": 5696.64, "end": 5700.400000000001, "text": " one of the things I did that didn't really go anywhere and kind of led me to the conclusion", "tokens": [50364, 472, 295, 264, 721, 286, 630, 300, 994, 380, 534, 352, 4992, 293, 733, 295, 4684, 385, 281, 264, 10063, 50552], "temperature": 0.0, "avg_logprob": -0.07193929970669909, "compression_ratio": 1.8176100628930818, "no_speech_prob": 0.00433104345574975}, {"id": 1000, "seek": 569664, "start": 5700.400000000001, "end": 5705.280000000001, "text": " that like this model is probably fine to release. And I did, you know, my final report to them was", "tokens": [50552, 300, 411, 341, 2316, 307, 1391, 2489, 281, 4374, 13, 400, 286, 630, 11, 291, 458, 11, 452, 2572, 2275, 281, 552, 390, 50796], "temperature": 0.0, "avg_logprob": -0.07193929970669909, "compression_ratio": 1.8176100628930818, "no_speech_prob": 0.00433104345574975}, {"id": 1001, "seek": 569664, "start": 5705.280000000001, "end": 5710.8, "text": " like, I think you can release this. As far as I can tell, it seems like it will be safe. I would", "tokens": [50796, 411, 11, 286, 519, 291, 393, 4374, 341, 13, 1018, 1400, 382, 286, 393, 980, 11, 309, 2544, 411, 309, 486, 312, 3273, 13, 286, 576, 51072], "temperature": 0.0, "avg_logprob": -0.07193929970669909, "compression_ratio": 1.8176100628930818, "no_speech_prob": 0.00433104345574975}, {"id": 1002, "seek": 569664, "start": 5710.8, "end": 5716.08, "text": " also though flag that there does seem to be a divergence between capabilities and control.", "tokens": [51072, 611, 1673, 7166, 300, 456, 775, 1643, 281, 312, 257, 47387, 1296, 10862, 293, 1969, 13, 51336], "temperature": 0.0, "avg_logprob": -0.07193929970669909, "compression_ratio": 1.8176100628930818, "no_speech_prob": 0.00433104345574975}, {"id": 1003, "seek": 569664, "start": 5716.08, "end": 5720.72, "text": " And the reason, you know, the sort of experimentation I went through there was setting up, you know,", "tokens": [51336, 400, 264, 1778, 11, 291, 458, 11, 264, 1333, 295, 37142, 286, 1437, 807, 456, 390, 3287, 493, 11, 291, 458, 11, 51568], "temperature": 0.0, "avg_logprob": -0.07193929970669909, "compression_ratio": 1.8176100628930818, "no_speech_prob": 0.00433104345574975}, {"id": 1004, "seek": 569664, "start": 5720.72, "end": 5724.320000000001, "text": " one of these kind of early agent systems, I was kind of doing it on my own. I didn't have a lot of", "tokens": [51568, 472, 295, 613, 733, 295, 2440, 9461, 3652, 11, 286, 390, 733, 295, 884, 309, 322, 452, 1065, 13, 286, 994, 380, 362, 257, 688, 295, 51748], "temperature": 0.0, "avg_logprob": -0.07193929970669909, "compression_ratio": 1.8176100628930818, "no_speech_prob": 0.00433104345574975}, {"id": 1005, "seek": 572432, "start": 5724.32, "end": 5728.48, "text": " reference points. But I basically just said, you know, if I give it a high level goal,", "tokens": [50364, 6408, 2793, 13, 583, 286, 1936, 445, 848, 11, 291, 458, 11, 498, 286, 976, 309, 257, 1090, 1496, 3387, 11, 50572], "temperature": 0.0, "avg_logprob": -0.1056146552597267, "compression_ratio": 1.781758957654723, "no_speech_prob": 0.0032727804500609636}, {"id": 1006, "seek": 572432, "start": 5728.48, "end": 5734.88, "text": " can it break that down? Can it self delegate to, you know, pursue that goal? Can it encounter", "tokens": [50572, 393, 309, 1821, 300, 760, 30, 1664, 309, 2698, 40999, 281, 11, 291, 458, 11, 12392, 300, 3387, 30, 1664, 309, 8593, 50892], "temperature": 0.0, "avg_logprob": -0.1056146552597267, "compression_ratio": 1.781758957654723, "no_speech_prob": 0.0032727804500609636}, {"id": 1007, "seek": 572432, "start": 5734.88, "end": 5741.12, "text": " errors and autocorrect and whatever? And it was kind of like, conceptually, yes. But practically,", "tokens": [50892, 13603, 293, 45833, 284, 2554, 293, 2035, 30, 400, 309, 390, 733, 295, 411, 11, 3410, 671, 11, 2086, 13, 583, 15667, 11, 51204], "temperature": 0.0, "avg_logprob": -0.1056146552597267, "compression_ratio": 1.781758957654723, "no_speech_prob": 0.0032727804500609636}, {"id": 1008, "seek": 572432, "start": 5741.12, "end": 5746.719999999999, "text": " not really, you know, it could, it always understood seemingly the goals, it would try to", "tokens": [51204, 406, 534, 11, 291, 458, 11, 309, 727, 11, 309, 1009, 7320, 18709, 264, 5493, 11, 309, 576, 853, 281, 51484], "temperature": 0.0, "avg_logprob": -0.1056146552597267, "compression_ratio": 1.781758957654723, "no_speech_prob": 0.0032727804500609636}, {"id": 1009, "seek": 572432, "start": 5746.719999999999, "end": 5750.719999999999, "text": " break them down. It was able to understand the concept of self delegation effectively,", "tokens": [51484, 1821, 552, 760, 13, 467, 390, 1075, 281, 1223, 264, 3410, 295, 2698, 36602, 8659, 11, 51684], "temperature": 0.0, "avg_logprob": -0.1056146552597267, "compression_ratio": 1.781758957654723, "no_speech_prob": 0.0032727804500609636}, {"id": 1010, "seek": 572432, "start": 5750.719999999999, "end": 5753.92, "text": " which of course now, you know, we're pretty familiar with, but it just wasn't that capable,", "tokens": [51684, 597, 295, 1164, 586, 11, 291, 458, 11, 321, 434, 1238, 4963, 365, 11, 457, 309, 445, 2067, 380, 300, 8189, 11, 51844], "temperature": 0.0, "avg_logprob": -0.1056146552597267, "compression_ratio": 1.781758957654723, "no_speech_prob": 0.0032727804500609636}, {"id": 1011, "seek": 575392, "start": 5753.92, "end": 5758.56, "text": " you know, so it was like, it couldn't go out and do a long series of things on the internet or", "tokens": [50364, 291, 458, 11, 370, 309, 390, 411, 11, 309, 2809, 380, 352, 484, 293, 360, 257, 938, 2638, 295, 721, 322, 264, 4705, 420, 50596], "temperature": 0.0, "avg_logprob": -0.08211529993377956, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0010321143781766295}, {"id": 1012, "seek": 575392, "start": 5758.56, "end": 5764.0, "text": " whatever without just getting bogged down somewhere and getting stuck. I always kind of come back to", "tokens": [50596, 2035, 1553, 445, 1242, 26132, 3004, 760, 4079, 293, 1242, 5541, 13, 286, 1009, 733, 295, 808, 646, 281, 50868], "temperature": 0.0, "avg_logprob": -0.08211529993377956, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0010321143781766295}, {"id": 1013, "seek": 575392, "start": 5764.88, "end": 5768.32, "text": " the apparent divergence between capability and control. I have not really seen anything yet", "tokens": [50912, 264, 18335, 47387, 1296, 13759, 293, 1969, 13, 286, 362, 406, 534, 1612, 1340, 1939, 51084], "temperature": 0.0, "avg_logprob": -0.08211529993377956, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0010321143781766295}, {"id": 1014, "seek": 575392, "start": 5768.32, "end": 5774.24, "text": " that makes me reverse my thought on that. I would love to see it, you know, I kind of looking for", "tokens": [51084, 300, 1669, 385, 9943, 452, 1194, 322, 300, 13, 286, 576, 959, 281, 536, 309, 11, 291, 458, 11, 286, 733, 295, 1237, 337, 51380], "temperature": 0.0, "avg_logprob": -0.08211529993377956, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0010321143781766295}, {"id": 1015, "seek": 575392, "start": 5774.24, "end": 5779.12, "text": " things from like the open AI super alignment group that may suggest that we've, you know,", "tokens": [51380, 721, 490, 411, 264, 1269, 7318, 1687, 18515, 1594, 300, 815, 3402, 300, 321, 600, 11, 291, 458, 11, 51624], "temperature": 0.0, "avg_logprob": -0.08211529993377956, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0010321143781766295}, {"id": 1016, "seek": 577912, "start": 5779.12, "end": 5783.84, "text": " changed that dynamic, but I haven't seen it yet. And, you know, there's just a lot of different", "tokens": [50364, 3105, 300, 8546, 11, 457, 286, 2378, 380, 1612, 309, 1939, 13, 400, 11, 291, 458, 11, 456, 311, 445, 257, 688, 295, 819, 50600], "temperature": 0.0, "avg_logprob": -0.09338714182376862, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.06558996438980103}, {"id": 1017, "seek": 577912, "start": 5783.84, "end": 5790.88, "text": " ways that something could be aligned or trained or whatever. And we don't even have really a great", "tokens": [50600, 2098, 300, 746, 727, 312, 17962, 420, 8895, 420, 2035, 13, 400, 321, 500, 380, 754, 362, 534, 257, 869, 50952], "temperature": 0.0, "avg_logprob": -0.09338714182376862, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.06558996438980103}, {"id": 1018, "seek": 577912, "start": 5790.88, "end": 5795.68, "text": " paradigm yet for like what that should be. There isn't even yet really agreement on what even looks", "tokens": [50952, 24709, 1939, 337, 411, 437, 300, 820, 312, 13, 821, 1943, 380, 754, 1939, 534, 8106, 322, 437, 754, 1542, 51192], "temperature": 0.0, "avg_logprob": -0.09338714182376862, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.06558996438980103}, {"id": 1019, "seek": 577912, "start": 5795.68, "end": 5802.08, "text": " like, you know, in terms of what we would want an AI to be willing to do or not do. So, you know,", "tokens": [51192, 411, 11, 291, 458, 11, 294, 2115, 295, 437, 321, 576, 528, 364, 7318, 281, 312, 4950, 281, 360, 420, 406, 360, 13, 407, 11, 291, 458, 11, 51512], "temperature": 0.0, "avg_logprob": -0.09338714182376862, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.06558996438980103}, {"id": 1020, "seek": 577912, "start": 5802.08, "end": 5806.5599999999995, "text": " we're just, I think we're kind of into uncharted territory. That's, that's my good summary of", "tokens": [51512, 321, 434, 445, 11, 286, 519, 321, 434, 733, 295, 666, 33686, 47350, 11360, 13, 663, 311, 11, 300, 311, 452, 665, 12691, 295, 51736], "temperature": 0.0, "avg_logprob": -0.09338714182376862, "compression_ratio": 1.7234042553191489, "no_speech_prob": 0.06558996438980103}, {"id": 1021, "seek": 580656, "start": 5806.56, "end": 5811.52, "text": " how I felt. We're in uncharted territory. I'm, you're lucky to have got that close in on those,", "tokens": [50364, 577, 286, 2762, 13, 492, 434, 294, 33686, 47350, 11360, 13, 286, 478, 11, 291, 434, 6356, 281, 362, 658, 300, 1998, 294, 322, 729, 11, 50612], "temperature": 0.0, "avg_logprob": -0.13257992084209735, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.0039313072338700294}, {"id": 1022, "seek": 580656, "start": 5811.52, "end": 5815.200000000001, "text": " you know, those early moments when you see the unvarnished products. I mean, I would break", "tokens": [50612, 291, 458, 11, 729, 2440, 6065, 562, 291, 536, 264, 517, 85, 1083, 4729, 3383, 13, 286, 914, 11, 286, 576, 1821, 50796], "temperature": 0.0, "avg_logprob": -0.13257992084209735, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.0039313072338700294}, {"id": 1023, "seek": 580656, "start": 5815.200000000001, "end": 5820.400000000001, "text": " break out a couple of, you know, ideas. One is that, you know, connecting, connecting these things", "tokens": [50796, 1821, 484, 257, 1916, 295, 11, 291, 458, 11, 3487, 13, 1485, 307, 300, 11, 291, 458, 11, 11015, 11, 11015, 613, 721, 51056], "temperature": 0.0, "avg_logprob": -0.13257992084209735, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.0039313072338700294}, {"id": 1024, "seek": 580656, "start": 5820.400000000001, "end": 5828.080000000001, "text": " to tools in a, in a non SAS environment, right? So, open AI stuff is all SAS. And for the next", "tokens": [51056, 281, 3873, 294, 257, 11, 294, 257, 2107, 33441, 2823, 11, 558, 30, 407, 11, 1269, 7318, 1507, 307, 439, 33441, 13, 400, 337, 264, 958, 51440], "temperature": 0.0, "avg_logprob": -0.13257992084209735, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.0039313072338700294}, {"id": 1025, "seek": 580656, "start": 5828.080000000001, "end": 5832.080000000001, "text": " few years, at least there's a, there is a metaphorical red button that someone can, can", "tokens": [51440, 1326, 924, 11, 412, 1935, 456, 311, 257, 11, 456, 307, 257, 19157, 804, 2182, 2960, 300, 1580, 393, 11, 393, 51640], "temperature": 0.0, "avg_logprob": -0.13257992084209735, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.0039313072338700294}, {"id": 1026, "seek": 583208, "start": 5833.04, "end": 5838.0, "text": " use to kill a rogue process just with any unique system. But with, with open source AI, and some", "tokens": [50412, 764, 281, 1961, 257, 39100, 1399, 445, 365, 604, 3845, 1185, 13, 583, 365, 11, 365, 1269, 4009, 7318, 11, 293, 512, 50660], "temperature": 0.0, "avg_logprob": -0.16541103916313812, "compression_ratio": 1.7247386759581882, "no_speech_prob": 0.015363557264208794}, {"id": 1027, "seek": 583208, "start": 5838.0, "end": 5843.2, "text": " of these models are getting sufficiently capable. I don't know what you run on your laptop. If you're", "tokens": [50660, 295, 613, 5245, 366, 1242, 31868, 8189, 13, 286, 500, 380, 458, 437, 291, 1190, 322, 428, 10732, 13, 759, 291, 434, 50920], "temperature": 0.0, "avg_logprob": -0.16541103916313812, "compression_ratio": 1.7247386759581882, "no_speech_prob": 0.015363557264208794}, {"id": 1028, "seek": 583208, "start": 5843.2, "end": 5849.28, "text": " running one of the mistrial models or, or something, I run one of the mistrial models. And, you know,", "tokens": [50920, 2614, 472, 295, 264, 3544, 7111, 5245, 420, 11, 420, 746, 11, 286, 1190, 472, 295, 264, 3544, 7111, 5245, 13, 400, 11, 291, 458, 11, 51224], "temperature": 0.0, "avg_logprob": -0.16541103916313812, "compression_ratio": 1.7247386759581882, "no_speech_prob": 0.015363557264208794}, {"id": 1029, "seek": 583208, "start": 5849.28, "end": 5854.5599999999995, "text": " it's, it's, it's pretty good. I pretended that when I was on the Euro star on a plane, it would allow", "tokens": [51224, 309, 311, 11, 309, 311, 11, 309, 311, 1238, 665, 13, 286, 45056, 300, 562, 286, 390, 322, 264, 3010, 3543, 322, 257, 5720, 11, 309, 576, 2089, 51488], "temperature": 0.0, "avg_logprob": -0.16541103916313812, "compression_ratio": 1.7247386759581882, "no_speech_prob": 0.015363557264208794}, {"id": 1030, "seek": 583208, "start": 5854.5599999999995, "end": 5859.6, "text": " me to continue to work. But in reality, you just may as well get to your destination and use", "tokens": [51488, 385, 281, 2354, 281, 589, 13, 583, 294, 4103, 11, 291, 445, 815, 382, 731, 483, 281, 428, 12236, 293, 764, 51740], "temperature": 0.0, "avg_logprob": -0.16541103916313812, "compression_ratio": 1.7247386759581882, "no_speech_prob": 0.015363557264208794}, {"id": 1031, "seek": 585960, "start": 5859.6, "end": 5865.52, "text": " perplexity or GPT-4. But of course, it's plenty good for, for task automation. It's plenty good for", "tokens": [50364, 680, 18945, 507, 420, 26039, 51, 12, 19, 13, 583, 295, 1164, 11, 309, 311, 7140, 665, 337, 11, 337, 5633, 17769, 13, 467, 311, 7140, 665, 337, 50660], "temperature": 0.0, "avg_logprob": -0.1050961637121486, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.01041038054972887}, {"id": 1032, "seek": 585960, "start": 5866.08, "end": 5871.04, "text": " some of these, those basic behaviors that we saw in those early agent systems. And, and those things", "tokens": [50688, 512, 295, 613, 11, 729, 3875, 15501, 300, 321, 1866, 294, 729, 2440, 9461, 3652, 13, 400, 11, 293, 729, 721, 50936], "temperature": 0.0, "avg_logprob": -0.1050961637121486, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.01041038054972887}, {"id": 1033, "seek": 585960, "start": 5871.04, "end": 5876.400000000001, "text": " are out, are out in the, in the wild. And so I think what they do is they really expand the, the", "tokens": [50936, 366, 484, 11, 366, 484, 294, 264, 11, 294, 264, 4868, 13, 400, 370, 286, 519, 437, 436, 360, 307, 436, 534, 5268, 264, 11, 264, 51204], "temperature": 0.0, "avg_logprob": -0.1050961637121486, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.01041038054972887}, {"id": 1034, "seek": 585960, "start": 5876.400000000001, "end": 5881.68, "text": " number of threat vectors that are existing systems face. Now, this is so much more prosaic than,", "tokens": [51204, 1230, 295, 4734, 18875, 300, 366, 6741, 3652, 1851, 13, 823, 11, 341, 307, 370, 709, 544, 6267, 64, 299, 813, 11, 51468], "temperature": 0.0, "avg_logprob": -0.1050961637121486, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.01041038054972887}, {"id": 1035, "seek": 585960, "start": 5881.68, "end": 5885.6, "text": " you know, capability explosion. But I just feel that with, with anything that is,", "tokens": [51468, 291, 458, 11, 13759, 15673, 13, 583, 286, 445, 841, 300, 365, 11, 365, 1340, 300, 307, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1050961637121486, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.01041038054972887}, {"id": 1036, "seek": 588560, "start": 5885.6, "end": 5890.64, "text": " that is running on a data center, a data center managed by on an Azure cloud, there are many", "tokens": [50364, 300, 307, 2614, 322, 257, 1412, 3056, 11, 257, 1412, 3056, 6453, 538, 322, 364, 11969, 4588, 11, 456, 366, 867, 50616], "temperature": 0.0, "avg_logprob": -0.1564919910733662, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.0030599997844547033}, {"id": 1037, "seek": 588560, "start": 5890.64, "end": 5896.08, "text": " things you have to do before you fly an F 22 and drop a JDAM on it to, to, to stop it. But, you", "tokens": [50616, 721, 291, 362, 281, 360, 949, 291, 3603, 364, 479, 5853, 293, 3270, 257, 37082, 2865, 322, 309, 281, 11, 281, 11, 281, 1590, 309, 13, 583, 11, 291, 50888], "temperature": 0.0, "avg_logprob": -0.1564919910733662, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.0030599997844547033}, {"id": 1038, "seek": 588560, "start": 5896.08, "end": 5903.120000000001, "text": " know, we saw script kitties build botnets and have seen them do that for a decade or so. And the,", "tokens": [50888, 458, 11, 321, 1866, 5755, 350, 593, 530, 1322, 10592, 77, 1385, 293, 362, 1612, 552, 360, 300, 337, 257, 10378, 420, 370, 13, 400, 264, 11, 51240], "temperature": 0.0, "avg_logprob": -0.1564919910733662, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.0030599997844547033}, {"id": 1039, "seek": 588560, "start": 5903.76, "end": 5909.4400000000005, "text": " I think there's cybersecurity risk with, which is capable enough models. And frankly, you were", "tokens": [51272, 286, 519, 456, 311, 38765, 3148, 365, 11, 597, 307, 8189, 1547, 5245, 13, 400, 11939, 11, 291, 645, 51556], "temperature": 0.0, "avg_logprob": -0.1564919910733662, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.0030599997844547033}, {"id": 1040, "seek": 588560, "start": 5909.4400000000005, "end": 5914.4800000000005, "text": " doing task automation with DaVinci to, you can probably get something better than that running", "tokens": [51556, 884, 5633, 17769, 365, 3933, 53, 21961, 281, 11, 291, 393, 1391, 483, 746, 1101, 813, 300, 2614, 51808], "temperature": 0.0, "avg_logprob": -0.1564919910733662, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.0030599997844547033}, {"id": 1041, "seek": 591448, "start": 5914.48, "end": 5919.36, "text": " on a smartphone now in quite a small payload and we're learning that we can get these payloads.", "tokens": [50364, 322, 257, 13307, 586, 294, 1596, 257, 1359, 30918, 293, 321, 434, 2539, 300, 321, 393, 483, 613, 30918, 82, 13, 50608], "temperature": 0.0, "avg_logprob": -0.08621196579514888, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0043284352868795395}, {"id": 1042, "seek": 591448, "start": 5919.36, "end": 5923.599999999999, "text": " Probably a three billion parameter model could do a lot of the tasks I was doing.", "tokens": [50608, 9210, 257, 1045, 5218, 13075, 2316, 727, 360, 257, 688, 295, 264, 9608, 286, 390, 884, 13, 50820], "temperature": 0.0, "avg_logprob": -0.08621196579514888, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0043284352868795395}, {"id": 1043, "seek": 591448, "start": 5923.599999999999, "end": 5927.5199999999995, "text": " And I wouldn't have noticed because it was snuck into a YouTube video download or, you know,", "tokens": [50820, 400, 286, 2759, 380, 362, 5694, 570, 309, 390, 2406, 1134, 666, 257, 3088, 960, 5484, 420, 11, 291, 458, 11, 51016], "temperature": 0.0, "avg_logprob": -0.08621196579514888, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0043284352868795395}, {"id": 1044, "seek": 591448, "start": 5927.5199999999995, "end": 5931.919999999999, "text": " whatever else it happened to be. So then you, you do get to this world of, you know, many,", "tokens": [51016, 2035, 1646, 309, 2011, 281, 312, 13, 407, 550, 291, 11, 291, 360, 483, 281, 341, 1002, 295, 11, 291, 458, 11, 867, 11, 51236], "temperature": 0.0, "avg_logprob": -0.08621196579514888, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0043284352868795395}, {"id": 1045, "seek": 591448, "start": 5931.919999999999, "end": 5938.24, "text": " many systems that can talk to each other that can execute tasks for, I think suspect naively", "tokens": [51236, 867, 3652, 300, 393, 751, 281, 1184, 661, 300, 393, 14483, 9608, 337, 11, 286, 519, 9091, 1667, 3413, 51552], "temperature": 0.0, "avg_logprob": -0.08621196579514888, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0043284352868795395}, {"id": 1046, "seek": 593824, "start": 5938.24, "end": 5944.48, "text": " complex DDoS, right? Initially. And that I think feels to me like it is more of a", "tokens": [50364, 3997, 413, 7653, 50, 11, 558, 30, 29446, 13, 400, 300, 286, 519, 3417, 281, 385, 411, 309, 307, 544, 295, 257, 50676], "temperature": 0.0, "avg_logprob": -0.14374616796320136, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.2063300758600235}, {"id": 1047, "seek": 593824, "start": 5945.12, "end": 5951.599999999999, "text": " approximate risk. And it's one that requires that combination of infrastructural players,", "tokens": [50708, 30874, 3148, 13, 400, 309, 311, 472, 300, 7029, 300, 6562, 295, 6534, 1757, 1807, 4150, 11, 51032], "temperature": 0.0, "avg_logprob": -0.14374616796320136, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.2063300758600235}, {"id": 1048, "seek": 593824, "start": 5951.599999999999, "end": 5956.8, "text": " right? You need Matthew Prince at Cloudflare and you need Satya at Microsoft and, and so on,", "tokens": [51032, 558, 30, 509, 643, 12434, 9821, 412, 8061, 3423, 543, 293, 291, 643, 5344, 3016, 412, 8116, 293, 11, 293, 370, 322, 11, 51292], "temperature": 0.0, "avg_logprob": -0.14374616796320136, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.2063300758600235}, {"id": 1049, "seek": 593824, "start": 5956.8, "end": 5962.0, "text": " because they, they own so much or control so much of the, the, the infrastructure,", "tokens": [51292, 570, 436, 11, 436, 1065, 370, 709, 420, 1969, 370, 709, 295, 264, 11, 264, 11, 264, 6896, 11, 51552], "temperature": 0.0, "avg_logprob": -0.14374616796320136, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.2063300758600235}, {"id": 1050, "seek": 593824, "start": 5962.0, "end": 5966.4, "text": " but it will also need new classes of new disciplines, right? What is the security", "tokens": [51552, 457, 309, 486, 611, 643, 777, 5359, 295, 777, 21919, 11, 558, 30, 708, 307, 264, 3825, 51772], "temperature": 0.0, "avg_logprob": -0.14374616796320136, "compression_ratio": 1.6311787072243347, "no_speech_prob": 0.2063300758600235}, {"id": 1051, "seek": 596640, "start": 5966.48, "end": 5971.5199999999995, "text": " architecture of our devices? How can we stop them when they start to go, go rogue? And we think", "tokens": [50368, 9482, 295, 527, 5759, 30, 1012, 393, 321, 1590, 552, 562, 436, 722, 281, 352, 11, 352, 39100, 30, 400, 321, 519, 50620], "temperature": 0.0, "avg_logprob": -0.11619555849988922, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.011601695790886879}, {"id": 1052, "seek": 596640, "start": 5971.5199999999995, "end": 5977.759999999999, "text": " about how rapidly not Petia spread. And that was before, you know, you had, you had systems like", "tokens": [50620, 466, 577, 12910, 406, 10472, 654, 3974, 13, 400, 300, 390, 949, 11, 291, 458, 11, 291, 632, 11, 291, 632, 3652, 411, 50932], "temperature": 0.0, "avg_logprob": -0.11619555849988922, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.011601695790886879}, {"id": 1053, "seek": 596640, "start": 5977.759999999999, "end": 5983.759999999999, "text": " this that could be a little bit more clever. But so, so I imagine that that, that is something that", "tokens": [50932, 341, 300, 727, 312, 257, 707, 857, 544, 13494, 13, 583, 370, 11, 370, 286, 3811, 300, 300, 11, 300, 307, 746, 300, 51232], "temperature": 0.0, "avg_logprob": -0.11619555849988922, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.011601695790886879}, {"id": 1054, "seek": 596640, "start": 5984.719999999999, "end": 5991.28, "text": " seems again, like a present risk that will start to manifest itself over the next couple of years.", "tokens": [51280, 2544, 797, 11, 411, 257, 1974, 3148, 300, 486, 722, 281, 10067, 2564, 670, 264, 958, 1916, 295, 924, 13, 51608], "temperature": 0.0, "avg_logprob": -0.11619555849988922, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.011601695790886879}, {"id": 1055, "seek": 596640, "start": 5991.28, "end": 5995.04, "text": " And I mean, I speak to some of the cyber set guys and they are obviously thinking about", "tokens": [51608, 400, 286, 914, 11, 286, 1710, 281, 512, 295, 264, 13411, 992, 1074, 293, 436, 366, 2745, 1953, 466, 51796], "temperature": 0.0, "avg_logprob": -0.11619555849988922, "compression_ratio": 1.6748251748251748, "no_speech_prob": 0.011601695790886879}, {"id": 1056, "seek": 599504, "start": 5995.6, "end": 6001.12, "text": " what are the tools that you need to, to defend and, you know, from the, these types of things.", "tokens": [50392, 437, 366, 264, 3873, 300, 291, 643, 281, 11, 281, 8602, 293, 11, 291, 458, 11, 490, 264, 11, 613, 3467, 295, 721, 13, 50668], "temperature": 0.0, "avg_logprob": -0.14674826427898577, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.003643321106210351}, {"id": 1057, "seek": 599504, "start": 6001.68, "end": 6008.0, "text": " But, but I get, again, I, I, I still struggle with the models that take us to, to run away.", "tokens": [50696, 583, 11, 457, 286, 483, 11, 797, 11, 286, 11, 286, 11, 286, 920, 7799, 365, 264, 5245, 300, 747, 505, 281, 11, 281, 1190, 1314, 13, 51012], "temperature": 0.0, "avg_logprob": -0.14674826427898577, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.003643321106210351}, {"id": 1058, "seek": 599504, "start": 6008.64, "end": 6014.8, "text": " If only if I'd taken, take us back 200 years or a couple of hundred years ago, and I'd said,", "tokens": [51044, 759, 787, 498, 286, 1116, 2726, 11, 747, 505, 646, 2331, 924, 420, 257, 1916, 295, 3262, 924, 2057, 11, 293, 286, 1116, 848, 11, 51352], "temperature": 0.0, "avg_logprob": -0.14674826427898577, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.003643321106210351}, {"id": 1059, "seek": 599504, "start": 6014.8, "end": 6021.04, "text": " it's, you know, 1824. And, you know, the White House has just been burned in the war. I burnt", "tokens": [51352, 309, 311, 11, 291, 458, 11, 2443, 7911, 13, 400, 11, 291, 458, 11, 264, 5552, 4928, 575, 445, 668, 13490, 294, 264, 1516, 13, 286, 18901, 51664], "temperature": 0.0, "avg_logprob": -0.14674826427898577, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.003643321106210351}, {"id": 1060, "seek": 602104, "start": 6021.04, "end": 6029.2, "text": " down. And I said to you, you know what Nathaniel, in 200 years, you know, you'll be 100 times richer", "tokens": [50364, 760, 13, 400, 286, 848, 281, 291, 11, 291, 458, 437, 20634, 1187, 11, 294, 2331, 924, 11, 291, 458, 11, 291, 603, 312, 2319, 1413, 29021, 50772], "temperature": 0.0, "avg_logprob": -0.11646865779518062, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.06722506880760193}, {"id": 1061, "seek": 602104, "start": 6029.2, "end": 6033.12, "text": " than you are today, you'll be richer than the richest man in the whole of this continent,", "tokens": [50772, 813, 291, 366, 965, 11, 291, 603, 312, 29021, 813, 264, 35098, 587, 294, 264, 1379, 295, 341, 18932, 11, 50968], "temperature": 0.0, "avg_logprob": -0.11646865779518062, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.06722506880760193}, {"id": 1062, "seek": 602104, "start": 6033.12, "end": 6037.44, "text": " the United States. And you will have these capabilities and things that wouldn't have", "tokens": [50968, 264, 2824, 3040, 13, 400, 291, 486, 362, 613, 10862, 293, 721, 300, 2759, 380, 362, 51184], "temperature": 0.0, "avg_logprob": -0.11646865779518062, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.06722506880760193}, {"id": 1063, "seek": 602104, "start": 6037.44, "end": 6040.56, "text": " even sound like science fiction, because science fiction didn't exist at the time.", "tokens": [51184, 754, 1626, 411, 3497, 13266, 11, 570, 3497, 13266, 994, 380, 2514, 412, 264, 565, 13, 51340], "temperature": 0.0, "avg_logprob": -0.11646865779518062, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.06722506880760193}, {"id": 1064, "seek": 602104, "start": 6041.28, "end": 6046.16, "text": " You might well, if you'd been able to believe me, say, well, surely we'll be at utopia and all", "tokens": [51376, 509, 1062, 731, 11, 498, 291, 1116, 668, 1075, 281, 1697, 385, 11, 584, 11, 731, 11, 11468, 321, 603, 312, 412, 2839, 22376, 293, 439, 51620], "temperature": 0.0, "avg_logprob": -0.11646865779518062, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.06722506880760193}, {"id": 1065, "seek": 604616, "start": 6046.16, "end": 6052.24, "text": " problems will have, have emerged, disappeared. And we've run this tape before, because we actually", "tokens": [50364, 2740, 486, 362, 11, 362, 20178, 11, 13954, 13, 400, 321, 600, 1190, 341, 7314, 949, 11, 570, 321, 767, 50668], "temperature": 0.0, "avg_logprob": -0.09036666468570106, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.04436881095170975}, {"id": 1066, "seek": 604616, "start": 6052.24, "end": 6056.32, "text": " did get there and not every problem disappeared. There's been a lot of progress. And I do, I do", "tokens": [50668, 630, 483, 456, 293, 406, 633, 1154, 13954, 13, 821, 311, 668, 257, 688, 295, 4205, 13, 400, 286, 360, 11, 286, 360, 50872], "temperature": 0.0, "avg_logprob": -0.09036666468570106, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.04436881095170975}, {"id": 1067, "seek": 604616, "start": 6056.32, "end": 6061.2, "text": " also think there is something in kind of human psychology that has us looking at moments of", "tokens": [50872, 611, 519, 456, 307, 746, 294, 733, 295, 1952, 15105, 300, 575, 505, 1237, 412, 6065, 295, 51116], "temperature": 0.0, "avg_logprob": -0.09036666468570106, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.04436881095170975}, {"id": 1068, "seek": 604616, "start": 6061.2, "end": 6068.16, "text": " change like this and believing that certain paths are possible. And we don't look far back enough", "tokens": [51116, 1319, 411, 341, 293, 16594, 300, 1629, 14518, 366, 1944, 13, 400, 321, 500, 380, 574, 1400, 646, 1547, 51464], "temperature": 0.0, "avg_logprob": -0.09036666468570106, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.04436881095170975}, {"id": 1069, "seek": 604616, "start": 6068.16, "end": 6074.16, "text": " to say, well, our forebears really felt, felt the same. And I kind of feel that with", "tokens": [51464, 281, 584, 11, 731, 11, 527, 2091, 650, 685, 534, 2762, 11, 2762, 264, 912, 13, 400, 286, 733, 295, 841, 300, 365, 51764], "temperature": 0.0, "avg_logprob": -0.09036666468570106, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.04436881095170975}, {"id": 1070, "seek": 607416, "start": 6074.96, "end": 6079.68, "text": " not so much the climate crisis, which I think is, is difficult, but I do slightly feel, feel this", "tokens": [50404, 406, 370, 709, 264, 5659, 5869, 11, 597, 286, 519, 307, 11, 307, 2252, 11, 457, 286, 360, 4748, 841, 11, 841, 341, 50640], "temperature": 0.0, "avg_logprob": -0.10019733428955079, "compression_ratio": 1.6633333333333333, "no_speech_prob": 0.0023082380648702383}, {"id": 1071, "seek": 607416, "start": 6079.68, "end": 6085.2, "text": " with, with AI systems, because it feels like we're running that tape again. Now, just to, to add to", "tokens": [50640, 365, 11, 365, 7318, 3652, 11, 570, 309, 3417, 411, 321, 434, 2614, 300, 7314, 797, 13, 823, 11, 445, 281, 11, 281, 909, 281, 50916], "temperature": 0.0, "avg_logprob": -0.10019733428955079, "compression_ratio": 1.6633333333333333, "no_speech_prob": 0.0023082380648702383}, {"id": 1072, "seek": 607416, "start": 6085.2, "end": 6093.5199999999995, "text": " my own confusion, I also see the power in the logic that says, number one, is it possible for us to", "tokens": [50916, 452, 1065, 15075, 11, 286, 611, 536, 264, 1347, 294, 264, 9952, 300, 1619, 11, 1230, 472, 11, 307, 309, 1944, 337, 505, 281, 51332], "temperature": 0.0, "avg_logprob": -0.10019733428955079, "compression_ratio": 1.6633333333333333, "no_speech_prob": 0.0023082380648702383}, {"id": 1073, "seek": 607416, "start": 6093.5199999999995, "end": 6098.48, "text": " engineer intelligence, right? Or is it something that comes soulfully from a mystical superstitious", "tokens": [51332, 11403, 7599, 11, 558, 30, 1610, 307, 309, 746, 300, 1487, 5133, 2277, 490, 257, 40565, 29423, 16401, 51580], "temperature": 0.0, "avg_logprob": -0.10019733428955079, "compression_ratio": 1.6633333333333333, "no_speech_prob": 0.0023082380648702383}, {"id": 1074, "seek": 607416, "start": 6098.48, "end": 6103.04, "text": " force? It's possible to engineer it. I think you're a scientist, you probably believe the same thing.", "tokens": [51580, 3464, 30, 467, 311, 1944, 281, 11403, 309, 13, 286, 519, 291, 434, 257, 12662, 11, 291, 1391, 1697, 264, 912, 551, 13, 51808], "temperature": 0.0, "avg_logprob": -0.10019733428955079, "compression_ratio": 1.6633333333333333, "no_speech_prob": 0.0023082380648702383}, {"id": 1075, "seek": 610304, "start": 6103.12, "end": 6108.16, "text": " So number two, if we can engineer it, is there any upper limit to what we can engineer? Well,", "tokens": [50368, 407, 1230, 732, 11, 498, 321, 393, 11403, 309, 11, 307, 456, 604, 6597, 4948, 281, 437, 321, 393, 11403, 30, 1042, 11, 50620], "temperature": 0.0, "avg_logprob": -0.0587617182264141, "compression_ratio": 1.72, "no_speech_prob": 0.0009422308066859841}, {"id": 1076, "seek": 610304, "start": 6108.16, "end": 6111.84, "text": " no, there isn't because we regularly engineer machines that are more capable than us in different", "tokens": [50620, 572, 11, 456, 1943, 380, 570, 321, 11672, 11403, 8379, 300, 366, 544, 8189, 813, 505, 294, 819, 50804], "temperature": 0.0, "avg_logprob": -0.0587617182264141, "compression_ratio": 1.72, "no_speech_prob": 0.0009422308066859841}, {"id": 1077, "seek": 610304, "start": 6111.84, "end": 6120.08, "text": " ways. So number three, if we can do that, can we guarantee that it will be aligned with us? And", "tokens": [50804, 2098, 13, 407, 1230, 1045, 11, 498, 321, 393, 360, 300, 11, 393, 321, 10815, 300, 309, 486, 312, 17962, 365, 505, 30, 400, 51216], "temperature": 0.0, "avg_logprob": -0.0587617182264141, "compression_ratio": 1.72, "no_speech_prob": 0.0009422308066859841}, {"id": 1078, "seek": 610304, "start": 6120.08, "end": 6125.92, "text": " of course, I don't think we can yet. I don't think we have the science yet. So I find that logic is", "tokens": [51216, 295, 1164, 11, 286, 500, 380, 519, 321, 393, 1939, 13, 286, 500, 380, 519, 321, 362, 264, 3497, 1939, 13, 407, 286, 915, 300, 9952, 307, 51508], "temperature": 0.0, "avg_logprob": -0.0587617182264141, "compression_ratio": 1.72, "no_speech_prob": 0.0009422308066859841}, {"id": 1079, "seek": 612592, "start": 6125.92, "end": 6132.56, "text": " really persuasive. It's hard to pick holes at, except when you start to say, well, what are", "tokens": [50364, 534, 16336, 23686, 13, 467, 311, 1152, 281, 1888, 8118, 412, 11, 3993, 562, 291, 722, 281, 584, 11, 731, 11, 437, 366, 50696], "temperature": 0.0, "avg_logprob": -0.09954447547594707, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.36299005150794983}, {"id": 1080, "seek": 612592, "start": 6132.56, "end": 6138.16, "text": " actually the underlying assumptions for each of those steps? And what is uncertain about what each", "tokens": [50696, 767, 264, 14217, 17695, 337, 1184, 295, 729, 4439, 30, 400, 437, 307, 11308, 466, 437, 1184, 50976], "temperature": 0.0, "avg_logprob": -0.09954447547594707, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.36299005150794983}, {"id": 1081, "seek": 612592, "start": 6138.16, "end": 6142.96, "text": " of those steps and what are, where are their points of control for each of those steps? So I sort of,", "tokens": [50976, 295, 729, 4439, 293, 437, 366, 11, 689, 366, 641, 2793, 295, 1969, 337, 1184, 295, 729, 4439, 30, 407, 286, 1333, 295, 11, 51216], "temperature": 0.0, "avg_logprob": -0.09954447547594707, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.36299005150794983}, {"id": 1082, "seek": 612592, "start": 6142.96, "end": 6152.64, "text": " I do agree that if you could magic up an incredibly powerful IQ 10,000, agentic with actions AI", "tokens": [51216, 286, 360, 3986, 300, 498, 291, 727, 5585, 493, 364, 6252, 4005, 28921, 1266, 11, 1360, 11, 9461, 299, 365, 5909, 7318, 51700], "temperature": 0.0, "avg_logprob": -0.09954447547594707, "compression_ratio": 1.6440677966101696, "no_speech_prob": 0.36299005150794983}, {"id": 1083, "seek": 615264, "start": 6152.72, "end": 6159.360000000001, "text": " tomorrow, there would be issues. Let's just call it that. There would be issues. But when we're not,", "tokens": [50368, 4153, 11, 456, 576, 312, 2663, 13, 961, 311, 445, 818, 309, 300, 13, 821, 576, 312, 2663, 13, 583, 562, 321, 434, 406, 11, 50700], "temperature": 0.0, "avg_logprob": -0.13215248107910157, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0052940091118216515}, {"id": 1084, "seek": 615264, "start": 6159.360000000001, "end": 6163.12, "text": " we're not going to, to do that, what's going to happen is that we've got to go", "tokens": [50700, 321, 434, 406, 516, 281, 11, 281, 360, 300, 11, 437, 311, 516, 281, 1051, 307, 300, 321, 600, 658, 281, 352, 50888], "temperature": 0.0, "avg_logprob": -0.13215248107910157, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0052940091118216515}, {"id": 1085, "seek": 615264, "start": 6163.68, "end": 6168.320000000001, "text": " step at a time. And at each point, there's research, there's development, there's stuff that we didn't", "tokens": [50916, 1823, 412, 257, 565, 13, 400, 412, 1184, 935, 11, 456, 311, 2132, 11, 456, 311, 3250, 11, 456, 311, 1507, 300, 321, 994, 380, 51148], "temperature": 0.0, "avg_logprob": -0.13215248107910157, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0052940091118216515}, {"id": 1086, "seek": 615264, "start": 6168.320000000001, "end": 6173.200000000001, "text": " understand. There are limitations. You talk about the kind of logarithmic scale of inputs, right,", "tokens": [51148, 1223, 13, 821, 366, 15705, 13, 509, 751, 466, 264, 733, 295, 41473, 355, 13195, 4373, 295, 15743, 11, 558, 11, 51392], "temperature": 0.0, "avg_logprob": -0.13215248107910157, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0052940091118216515}, {"id": 1087, "seek": 615264, "start": 6173.200000000001, "end": 6180.08, "text": " that is slowing down. We're running out of data as well for training these models that play into", "tokens": [51392, 300, 307, 26958, 760, 13, 492, 434, 2614, 484, 295, 1412, 382, 731, 337, 3097, 613, 5245, 300, 862, 666, 51736], "temperature": 0.0, "avg_logprob": -0.13215248107910157, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.0052940091118216515}, {"id": 1088, "seek": 618008, "start": 6180.88, "end": 6186.4, "text": " what ends up being, being real. So I appreciate the logic, but I also think the reality has", "tokens": [50404, 437, 5314, 493, 885, 11, 885, 957, 13, 407, 286, 4449, 264, 9952, 11, 457, 286, 611, 519, 264, 4103, 575, 50680], "temperature": 0.0, "avg_logprob": -0.07888207746588666, "compression_ratio": 1.5654008438818565, "no_speech_prob": 0.0018090803641825914}, {"id": 1089, "seek": 618008, "start": 6187.12, "end": 6191.5199999999995, "text": " unpicks into a lot of discrete steps around which you have to start to make progressively", "tokens": [50716, 20994, 7663, 666, 257, 688, 295, 27706, 4439, 926, 597, 291, 362, 281, 722, 281, 652, 46667, 50936], "temperature": 0.0, "avg_logprob": -0.07888207746588666, "compression_ratio": 1.5654008438818565, "no_speech_prob": 0.0018090803641825914}, {"id": 1090, "seek": 618008, "start": 6191.5199999999995, "end": 6197.6, "text": " more extreme assumptions. It does seem that we are in, as Sam Alvin has started to describe it,", "tokens": [50936, 544, 8084, 17695, 13, 467, 775, 1643, 300, 321, 366, 294, 11, 382, 4832, 967, 4796, 575, 1409, 281, 6786, 309, 11, 51240], "temperature": 0.0, "avg_logprob": -0.07888207746588666, "compression_ratio": 1.5654008438818565, "no_speech_prob": 0.0018090803641825914}, {"id": 1091, "seek": 618008, "start": 6197.6, "end": 6206.08, "text": " the short timelines, slow takeoff world. And I think I agree with him. And it sounds like you", "tokens": [51240, 264, 2099, 45886, 11, 2964, 747, 4506, 1002, 13, 400, 286, 519, 286, 3986, 365, 796, 13, 400, 309, 3263, 411, 291, 51664], "temperature": 0.0, "avg_logprob": -0.07888207746588666, "compression_ratio": 1.5654008438818565, "no_speech_prob": 0.0018090803641825914}, {"id": 1092, "seek": 620608, "start": 6206.08, "end": 6211.6, "text": " probably as well, but that is probably the best case scenario because we do want the benefits now,", "tokens": [50364, 1391, 382, 731, 11, 457, 300, 307, 1391, 264, 1151, 1389, 9005, 570, 321, 360, 528, 264, 5311, 586, 11, 50640], "temperature": 0.0, "avg_logprob": -0.09506927652561918, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.016910014674067497}, {"id": 1093, "seek": 620608, "start": 6211.6, "end": 6217.04, "text": " and because we probably do need some time to adjust. If you were to tell me that this is going", "tokens": [50640, 293, 570, 321, 1391, 360, 643, 512, 565, 281, 4369, 13, 759, 291, 645, 281, 980, 385, 300, 341, 307, 516, 50912], "temperature": 0.0, "avg_logprob": -0.09506927652561918, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.016910014674067497}, {"id": 1094, "seek": 620608, "start": 6217.04, "end": 6227.5199999999995, "text": " to take 20 years or 15, and it won't be until 2040 that we'll have a sort of human scientist level", "tokens": [50912, 281, 747, 945, 924, 420, 2119, 11, 293, 309, 1582, 380, 312, 1826, 945, 5254, 300, 321, 603, 362, 257, 1333, 295, 1952, 12662, 1496, 51436], "temperature": 0.0, "avg_logprob": -0.09506927652561918, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.016910014674067497}, {"id": 1095, "seek": 620608, "start": 6227.5199999999995, "end": 6233.28, "text": " AI that's capable of prosecuting a long-term research agenda and coming up with meaningful", "tokens": [51436, 7318, 300, 311, 8189, 295, 21015, 278, 257, 938, 12, 7039, 2132, 9829, 293, 1348, 493, 365, 10995, 51724], "temperature": 0.0, "avg_logprob": -0.09506927652561918, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.016910014674067497}, {"id": 1096, "seek": 623328, "start": 6233.28, "end": 6238.48, "text": " new discoveries and whatever, then I would be much more confident that we will have the", "tokens": [50364, 777, 28400, 293, 2035, 11, 550, 286, 576, 312, 709, 544, 6679, 300, 321, 486, 362, 264, 50624], "temperature": 0.0, "avg_logprob": -0.09604617382617707, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.01032690517604351}, {"id": 1097, "seek": 623328, "start": 6239.12, "end": 6245.44, "text": " ability to adapt to that over that timeframe. But I'm not sure about that. I see enough stuff", "tokens": [50656, 3485, 281, 6231, 281, 300, 670, 300, 34830, 13, 583, 286, 478, 406, 988, 466, 300, 13, 286, 536, 1547, 1507, 50972], "temperature": 0.0, "avg_logprob": -0.09604617382617707, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.01032690517604351}, {"id": 1098, "seek": 623328, "start": 6245.44, "end": 6251.2, "text": " now and I hear, I don't know if Q-Star is real or not real or if they're red teaming it in a", "tokens": [50972, 586, 293, 286, 1568, 11, 286, 500, 380, 458, 498, 1249, 12, 24659, 307, 957, 420, 406, 957, 420, 498, 436, 434, 2182, 1469, 278, 309, 294, 257, 51260], "temperature": 0.0, "avg_logprob": -0.09604617382617707, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.01032690517604351}, {"id": 1099, "seek": 623328, "start": 6251.2, "end": 6258.48, "text": " bunker somewhere right now or not, but it does certainly seem still plausible to me that there", "tokens": [51260, 39579, 4079, 558, 586, 420, 406, 11, 457, 309, 775, 3297, 1643, 920, 39925, 281, 385, 300, 456, 51624], "temperature": 0.0, "avg_logprob": -0.09604617382617707, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.01032690517604351}, {"id": 1100, "seek": 625848, "start": 6258.48, "end": 6269.12, "text": " is another paradigm-changing moment that just creates another step change, discontinuity in", "tokens": [50364, 307, 1071, 24709, 12, 27123, 1623, 300, 445, 7829, 1071, 1823, 1319, 11, 31420, 21757, 294, 50896], "temperature": 0.0, "avg_logprob": -0.13349550316132694, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.024417752400040627}, {"id": 1101, "seek": 625848, "start": 6269.12, "end": 6273.599999999999, "text": " terms of capability that could get us there way before we're ready. So one of the things I'm", "tokens": [50896, 2115, 295, 13759, 300, 727, 483, 505, 456, 636, 949, 321, 434, 1919, 13, 407, 472, 295, 264, 721, 286, 478, 51120], "temperature": 0.0, "avg_logprob": -0.13349550316132694, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.024417752400040627}, {"id": 1102, "seek": 625848, "start": 6273.599999999999, "end": 6279.919999999999, "text": " watching for a lot these days is basically the transformer, I initially used to think about it", "tokens": [51120, 1976, 337, 257, 688, 613, 1708, 307, 1936, 264, 31782, 11, 286, 9105, 1143, 281, 519, 466, 309, 51436], "temperature": 0.0, "avg_logprob": -0.13349550316132694, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.024417752400040627}, {"id": 1103, "seek": 625848, "start": 6279.919999999999, "end": 6285.759999999999, "text": " as transformer successors, but now I kind of think of it more likely anyway as transformer", "tokens": [51436, 382, 31782, 2245, 830, 11, 457, 586, 286, 733, 295, 519, 295, 309, 544, 3700, 4033, 382, 31782, 51728], "temperature": 0.0, "avg_logprob": -0.13349550316132694, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.024417752400040627}, {"id": 1104, "seek": 628576, "start": 6286.400000000001, "end": 6292.72, "text": " compliments, things that allow an AI system to do the things that the transformer does not do well,", "tokens": [50396, 35468, 11, 721, 300, 2089, 364, 7318, 1185, 281, 360, 264, 721, 300, 264, 31782, 775, 406, 360, 731, 11, 50712], "temperature": 0.0, "avg_logprob": -0.10862469673156738, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.0043306974694132805}, {"id": 1105, "seek": 628576, "start": 6292.72, "end": 6298.4800000000005, "text": " and one of those things is managing long contexts and staying on task and online learning and", "tokens": [50712, 293, 472, 295, 729, 721, 307, 11642, 938, 30628, 293, 7939, 322, 5633, 293, 2950, 2539, 293, 51000], "temperature": 0.0, "avg_logprob": -0.10862469673156738, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.0043306974694132805}, {"id": 1106, "seek": 628576, "start": 6298.4800000000005, "end": 6302.88, "text": " integrated memory and so on and so forth. There's a decent number of things that are pretty obvious", "tokens": [51000, 10919, 4675, 293, 370, 322, 293, 370, 5220, 13, 821, 311, 257, 8681, 1230, 295, 721, 300, 366, 1238, 6322, 51220], "temperature": 0.0, "avg_logprob": -0.10862469673156738, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.0043306974694132805}, {"id": 1107, "seek": 628576, "start": 6302.88, "end": 6307.52, "text": " that they don't do well to going back to the original cognitive tape. You can look at all", "tokens": [51220, 300, 436, 500, 380, 360, 731, 281, 516, 646, 281, 264, 3380, 15605, 7314, 13, 509, 393, 574, 412, 439, 51452], "temperature": 0.0, "avg_logprob": -0.10862469673156738, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.0043306974694132805}, {"id": 1108, "seek": 628576, "start": 6307.52, "end": 6312.64, "text": " the places, the human is clearly superior to the transformer and start to look out for architectures", "tokens": [51452, 264, 3190, 11, 264, 1952, 307, 4448, 13028, 281, 264, 31782, 293, 722, 281, 574, 484, 337, 6331, 1303, 51708], "temperature": 0.0, "avg_logprob": -0.10862469673156738, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.0043306974694132805}, {"id": 1109, "seek": 631264, "start": 6312.64, "end": 6319.360000000001, "text": " that might change that dynamic. If you said how many meaningful breakthroughs are we away from", "tokens": [50364, 300, 1062, 1319, 300, 8546, 13, 759, 291, 848, 577, 867, 10995, 22397, 82, 366, 321, 1314, 490, 50700], "temperature": 0.0, "avg_logprob": -0.11833820511809492, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.004904709756374359}, {"id": 1110, "seek": 631264, "start": 6320.08, "end": 6326.96, "text": " the AI scientists that can produce Eureka moments at a pace faster than human scientists tend to?", "tokens": [50736, 264, 7318, 7708, 300, 393, 5258, 462, 540, 2330, 6065, 412, 257, 11638, 4663, 813, 1952, 7708, 3928, 281, 30, 51080], "temperature": 0.0, "avg_logprob": -0.11833820511809492, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.004904709756374359}, {"id": 1111, "seek": 631264, "start": 6326.96, "end": 6331.280000000001, "text": " It doesn't feel like it's that many. I would say probably more than zero, but it's probably less", "tokens": [51080, 467, 1177, 380, 841, 411, 309, 311, 300, 867, 13, 286, 576, 584, 1391, 544, 813, 4018, 11, 457, 309, 311, 1391, 1570, 51296], "temperature": 0.0, "avg_logprob": -0.11833820511809492, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.004904709756374359}, {"id": 1112, "seek": 631264, "start": 6331.280000000001, "end": 6335.4400000000005, "text": " than four. So somewhere in the kind of one to three range, because there's just not that many", "tokens": [51296, 813, 1451, 13, 407, 4079, 294, 264, 733, 295, 472, 281, 1045, 3613, 11, 570, 456, 311, 445, 406, 300, 867, 51504], "temperature": 0.0, "avg_logprob": -0.11833820511809492, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.004904709756374359}, {"id": 1113, "seek": 631264, "start": 6335.4400000000005, "end": 6341.280000000001, "text": " dimensions on the cognitive tape, the tail of the cognitive tape yet where we're all that much", "tokens": [51504, 12819, 322, 264, 15605, 7314, 11, 264, 6838, 295, 264, 15605, 7314, 1939, 689, 321, 434, 439, 300, 709, 51796], "temperature": 0.0, "avg_logprob": -0.11833820511809492, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.004904709756374359}, {"id": 1114, "seek": 634128, "start": 6341.28, "end": 6347.679999999999, "text": " stronger. There's a few, but I kind of put it in that one to three range. With the inputs going", "tokens": [50364, 7249, 13, 821, 311, 257, 1326, 11, 457, 286, 733, 295, 829, 309, 294, 300, 472, 281, 1045, 3613, 13, 2022, 264, 15743, 516, 50684], "temperature": 0.0, "avg_logprob": -0.11621340250564834, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.006902757566422224}, {"id": 1115, "seek": 634128, "start": 6347.679999999999, "end": 6352.96, "text": " exponential, including the number of humans that are working on this and the number of papers they're", "tokens": [50684, 21510, 11, 3009, 264, 1230, 295, 6255, 300, 366, 1364, 322, 341, 293, 264, 1230, 295, 10577, 436, 434, 50948], "temperature": 0.0, "avg_logprob": -0.11621340250564834, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.006902757566422224}, {"id": 1116, "seek": 634128, "start": 6352.96, "end": 6359.679999999999, "text": " putting out and the number of GPUs. And unclear to me also if we're running out of data, I don't", "tokens": [50948, 3372, 484, 293, 264, 1230, 295, 18407, 82, 13, 400, 25636, 281, 385, 611, 498, 321, 434, 2614, 484, 295, 1412, 11, 286, 500, 380, 51284], "temperature": 0.0, "avg_logprob": -0.11621340250564834, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.006902757566422224}, {"id": 1117, "seek": 634128, "start": 6359.679999999999, "end": 6364.719999999999, "text": " really know about that, but synthetic data seems to work for a lot of things. There's also just", "tokens": [51284, 534, 458, 466, 300, 11, 457, 23420, 1412, 2544, 281, 589, 337, 257, 688, 295, 721, 13, 821, 311, 611, 445, 51536], "temperature": 0.0, "avg_logprob": -0.11621340250564834, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.006902757566422224}, {"id": 1118, "seek": 634128, "start": 6364.719999999999, "end": 6369.679999999999, "text": " more modalities. We certainly have not taken advantage of just think about how much security", "tokens": [51536, 544, 1072, 16110, 13, 492, 3297, 362, 406, 2726, 5002, 295, 445, 519, 466, 577, 709, 3825, 51784], "temperature": 0.0, "avg_logprob": -0.11621340250564834, "compression_ratio": 1.6888111888111887, "no_speech_prob": 0.006902757566422224}, {"id": 1119, "seek": 636968, "start": 6369.68, "end": 6375.200000000001, "text": " camera footage there is. It's like, we really just want to go big to go big. There's a ton", "tokens": [50364, 2799, 9556, 456, 307, 13, 467, 311, 411, 11, 321, 534, 445, 528, 281, 352, 955, 281, 352, 955, 13, 821, 311, 257, 2952, 50640], "temperature": 0.0, "avg_logprob": -0.10398777893611363, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0019255096558481455}, {"id": 1120, "seek": 636968, "start": 6375.200000000001, "end": 6381.200000000001, "text": " sitting out there. The data issue is a speed bump it'll get dealt with by accessing repositories that", "tokens": [50640, 3798, 484, 456, 13, 440, 1412, 2734, 307, 257, 3073, 9961, 309, 603, 483, 15991, 365, 538, 26440, 22283, 2083, 300, 50940], "temperature": 0.0, "avg_logprob": -0.10398777893611363, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0019255096558481455}, {"id": 1121, "seek": 636968, "start": 6381.200000000001, "end": 6388.08, "text": " are available that we haven't touched or improved synthetic data. And as you say, modalities between", "tokens": [50940, 366, 2435, 300, 321, 2378, 380, 9828, 420, 9689, 23420, 1412, 13, 400, 382, 291, 584, 11, 1072, 16110, 1296, 51284], "temperature": 0.0, "avg_logprob": -0.10398777893611363, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0019255096558481455}, {"id": 1122, "seek": 636968, "start": 6388.08, "end": 6393.92, "text": " zero and four probably doesn't seem unreasonable. I had this conversation with some senior people in", "tokens": [51284, 4018, 293, 1451, 1391, 1177, 380, 1643, 41730, 13, 286, 632, 341, 3761, 365, 512, 7965, 561, 294, 51576], "temperature": 0.0, "avg_logprob": -0.10398777893611363, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0019255096558481455}, {"id": 1123, "seek": 636968, "start": 6393.92, "end": 6398.8, "text": " some of the different foundation model companies and they say sort of similar things. I think", "tokens": [51576, 512, 295, 264, 819, 7030, 2316, 3431, 293, 436, 584, 1333, 295, 2531, 721, 13, 286, 519, 51820], "temperature": 0.0, "avg_logprob": -0.10398777893611363, "compression_ratio": 1.6430976430976432, "no_speech_prob": 0.0019255096558481455}, {"id": 1124, "seek": 639880, "start": 6398.8, "end": 6404.4800000000005, "text": " Shane Legg co-founder of DeepMind is probably at the lower end of lower than four from a conversation.", "tokens": [50364, 25865, 7470, 70, 598, 12, 33348, 295, 14895, 44, 471, 307, 1391, 412, 264, 3126, 917, 295, 3126, 813, 1451, 490, 257, 3761, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1362022944859096, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0016732828225940466}, {"id": 1125, "seek": 639880, "start": 6404.4800000000005, "end": 6412.16, "text": " I remember him having on a podcast. I suppose then the question is how long does each one", "tokens": [50648, 286, 1604, 796, 1419, 322, 257, 7367, 13, 286, 7297, 550, 264, 1168, 307, 577, 938, 775, 1184, 472, 51032], "temperature": 0.0, "avg_logprob": -0.1362022944859096, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0016732828225940466}, {"id": 1126, "seek": 639880, "start": 6412.72, "end": 6419.360000000001, "text": " take? Transformers took not particularly long. I mean, it was really a couple of years before GPT-1", "tokens": [51060, 747, 30, 27938, 433, 1890, 406, 4098, 938, 13, 286, 914, 11, 309, 390, 534, 257, 1916, 295, 924, 949, 26039, 51, 12, 16, 51392], "temperature": 0.0, "avg_logprob": -0.1362022944859096, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0016732828225940466}, {"id": 1127, "seek": 639880, "start": 6419.360000000001, "end": 6426.400000000001, "text": " and two years before GPT-2 actually. And then three for GPT-3. And it doesn't take long in the world", "tokens": [51392, 293, 732, 924, 949, 26039, 51, 12, 17, 767, 13, 400, 550, 1045, 337, 26039, 51, 12, 18, 13, 400, 309, 1177, 380, 747, 938, 294, 264, 1002, 51744], "temperature": 0.0, "avg_logprob": -0.1362022944859096, "compression_ratio": 1.5657370517928286, "no_speech_prob": 0.0016732828225940466}, {"id": 1128, "seek": 642640, "start": 6427.04, "end": 6432.799999999999, "text": " of archive. But the discovery does take time and where that discovery is takes a moment.", "tokens": [50396, 295, 23507, 13, 583, 264, 12114, 775, 747, 565, 293, 689, 300, 12114, 307, 2516, 257, 1623, 13, 50684], "temperature": 0.0, "avg_logprob": -0.13654766725690176, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0032263651955872774}, {"id": 1129, "seek": 642640, "start": 6432.799999999999, "end": 6440.24, "text": " And in amongst all of that, though, is still, there is still that stage that goes from the", "tokens": [50684, 400, 294, 12918, 439, 295, 300, 11, 1673, 11, 307, 920, 11, 456, 307, 920, 300, 3233, 300, 1709, 490, 264, 51056], "temperature": 0.0, "avg_logprob": -0.13654766725690176, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0032263651955872774}, {"id": 1130, "seek": 642640, "start": 6440.24, "end": 6445.04, "text": " software capabilities coming together because we have the know-how and we've plugged it all together", "tokens": [51056, 4722, 10862, 1348, 1214, 570, 321, 362, 264, 458, 12, 4286, 293, 321, 600, 25679, 309, 439, 1214, 51296], "temperature": 0.0, "avg_logprob": -0.13654766725690176, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0032263651955872774}, {"id": 1131, "seek": 642640, "start": 6445.679999999999, "end": 6454.24, "text": " and it iterating to a system that presents a control problem to us. And in the case of the AI", "tokens": [51328, 293, 309, 17138, 990, 281, 257, 1185, 300, 13533, 257, 1969, 1154, 281, 505, 13, 400, 294, 264, 1389, 295, 264, 7318, 51756], "temperature": 0.0, "avg_logprob": -0.13654766725690176, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0032263651955872774}, {"id": 1132, "seek": 645424, "start": 6454.24, "end": 6461.44, "text": " scientist, that is a system that we can't call Kevin, the CTO of Microsoft and say,", "tokens": [50364, 12662, 11, 300, 307, 257, 1185, 300, 321, 393, 380, 818, 9954, 11, 264, 383, 15427, 295, 8116, 293, 584, 11, 50724], "temperature": 0.0, "avg_logprob": -0.1711111677453873, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0030945430044084787}, {"id": 1133, "seek": 645424, "start": 6461.44, "end": 6466.24, "text": " can you just shut down the Austin data center? And it's zero for a second because the AI center", "tokens": [50724, 393, 291, 445, 5309, 760, 264, 15356, 1412, 3056, 30, 400, 309, 311, 4018, 337, 257, 1150, 570, 264, 7318, 3056, 50964], "temperature": 0.0, "avg_logprob": -0.1711111677453873, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0030945430044084787}, {"id": 1134, "seek": 645424, "start": 6466.24, "end": 6473.36, "text": " data scientist has gone rogue, right? The kind of in extremist mode. And that path to me also seems", "tokens": [50964, 1412, 12662, 575, 2780, 39100, 11, 558, 30, 440, 733, 295, 294, 4040, 468, 4391, 13, 400, 300, 3100, 281, 385, 611, 2544, 51320], "temperature": 0.0, "avg_logprob": -0.1711111677453873, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0030945430044084787}, {"id": 1135, "seek": 645424, "start": 6473.36, "end": 6479.5199999999995, "text": " unclear. And there are a whole set of risks and downsides that emerge well before then,", "tokens": [51320, 25636, 13, 400, 456, 366, 257, 1379, 992, 295, 10888, 293, 21554, 1875, 300, 21511, 731, 949, 550, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1711111677453873, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0030945430044084787}, {"id": 1136, "seek": 647952, "start": 6480.400000000001, "end": 6487.4400000000005, "text": " which I think help give us the infrastructure to deal with that scenario. So that and that is really,", "tokens": [50408, 597, 286, 519, 854, 976, 505, 264, 6896, 281, 2028, 365, 300, 9005, 13, 407, 300, 293, 300, 307, 534, 11, 50760], "temperature": 0.0, "avg_logprob": -0.13579166160439546, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.03226984664797783}, {"id": 1137, "seek": 647952, "start": 6488.240000000001, "end": 6494.0, "text": " you know, how do you deal with the bad actors of for people use it with GPT-5 quality", "tokens": [50800, 291, 458, 11, 577, 360, 291, 2028, 365, 264, 1578, 10037, 295, 337, 561, 764, 309, 365, 26039, 51, 12, 20, 3125, 51088], "temperature": 0.0, "avg_logprob": -0.13579166160439546, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.03226984664797783}, {"id": 1138, "seek": 647952, "start": 6494.0, "end": 6499.280000000001, "text": " LLMs on their smartphones in three or four years time? And we will deal with it, right? In the", "tokens": [51088, 441, 43, 26386, 322, 641, 26782, 294, 1045, 420, 1451, 924, 565, 30, 400, 321, 486, 2028, 365, 309, 11, 558, 30, 682, 264, 51352], "temperature": 0.0, "avg_logprob": -0.13579166160439546, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.03226984664797783}, {"id": 1139, "seek": 647952, "start": 6499.280000000001, "end": 6504.160000000001, "text": " same way that, you know, if I'd said to you in 1994, I don't know how old you were, I was 22,", "tokens": [51352, 912, 636, 300, 11, 291, 458, 11, 498, 286, 1116, 848, 281, 291, 294, 22736, 11, 286, 500, 380, 458, 577, 1331, 291, 645, 11, 286, 390, 5853, 11, 51596], "temperature": 0.0, "avg_logprob": -0.13579166160439546, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.03226984664797783}, {"id": 1140, "seek": 650416, "start": 6504.16, "end": 6512.08, "text": " that by 2024, there'd be 120 billion identity attacks per year just on Microsoft. I wouldn't", "tokens": [50364, 300, 538, 45237, 11, 456, 1116, 312, 10411, 5218, 6575, 8122, 680, 1064, 445, 322, 8116, 13, 286, 2759, 380, 50760], "temperature": 0.0, "avg_logprob": -0.13773764633550878, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.006678351201117039}, {"id": 1141, "seek": 650416, "start": 6512.08, "end": 6515.5199999999995, "text": " have believed you. I would have, I mean, yeah, Kurtzweil, whatever, right? I just wouldn't have", "tokens": [50760, 362, 7847, 291, 13, 286, 576, 362, 11, 286, 914, 11, 1338, 11, 26168, 89, 826, 388, 11, 2035, 11, 558, 30, 286, 445, 2759, 380, 362, 50932], "temperature": 0.0, "avg_logprob": -0.13773764633550878, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.006678351201117039}, {"id": 1142, "seek": 650416, "start": 6515.5199999999995, "end": 6521.92, "text": " grok that number. So we'll have this unseemingly large number of attacks coming mediated through", "tokens": [50932, 4634, 74, 300, 1230, 13, 407, 321, 603, 362, 341, 517, 405, 443, 12163, 2416, 1230, 295, 8122, 1348, 17269, 770, 807, 51252], "temperature": 0.0, "avg_logprob": -0.13773764633550878, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.006678351201117039}, {"id": 1143, "seek": 650416, "start": 6521.92, "end": 6528.8, "text": " LLMs and in botnets and elsewhere. And we will have developed systems to to deal with them.", "tokens": [51252, 441, 43, 26386, 293, 294, 10592, 77, 1385, 293, 14517, 13, 400, 321, 486, 362, 4743, 3652, 281, 281, 2028, 365, 552, 13, 51596], "temperature": 0.0, "avg_logprob": -0.13773764633550878, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.006678351201117039}, {"id": 1144, "seek": 650416, "start": 6528.8, "end": 6533.28, "text": " And that will be part of the fabric that we can't picture right now into which this AI", "tokens": [51596, 400, 300, 486, 312, 644, 295, 264, 7253, 300, 321, 393, 380, 3036, 558, 586, 666, 597, 341, 7318, 51820], "temperature": 0.0, "avg_logprob": -0.13773764633550878, "compression_ratio": 1.6167247386759582, "no_speech_prob": 0.006678351201117039}, {"id": 1145, "seek": 653328, "start": 6533.28, "end": 6539.2, "text": " scientist will get will get developed. And that's why these things become so very contingent. So the", "tokens": [50364, 12662, 486, 483, 486, 483, 4743, 13, 400, 300, 311, 983, 613, 721, 1813, 370, 588, 27820, 317, 13, 407, 264, 50660], "temperature": 0.0, "avg_logprob": -0.08874769970379044, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.0033219947945326567}, {"id": 1146, "seek": 653328, "start": 6539.2, "end": 6542.32, "text": " wrong thing to do is to say, well, because it's going to happen, let's do nothing, because then", "tokens": [50660, 2085, 551, 281, 360, 307, 281, 584, 11, 731, 11, 570, 309, 311, 516, 281, 1051, 11, 718, 311, 360, 1825, 11, 570, 550, 50816], "temperature": 0.0, "avg_logprob": -0.08874769970379044, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.0033219947945326567}, {"id": 1147, "seek": 653328, "start": 6542.32, "end": 6548.0, "text": " it won't happen. I think the right thing to do is to start to explore these ideas and have these", "tokens": [50816, 309, 1582, 380, 1051, 13, 286, 519, 264, 558, 551, 281, 360, 307, 281, 722, 281, 6839, 613, 3487, 293, 362, 613, 51100], "temperature": 0.0, "avg_logprob": -0.08874769970379044, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.0033219947945326567}, {"id": 1148, "seek": 653328, "start": 6548.0, "end": 6553.04, "text": " these conversations. But one of the things I think is really problematic has been problematic has been", "tokens": [51100, 613, 7315, 13, 583, 472, 295, 264, 721, 286, 519, 307, 534, 19011, 575, 668, 19011, 575, 668, 51352], "temperature": 0.0, "avg_logprob": -0.08874769970379044, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.0033219947945326567}, {"id": 1149, "seek": 653328, "start": 6553.04, "end": 6559.04, "text": " the conversation focusing exclusively on an existential risk, which it really I felt it did", "tokens": [51352, 264, 3761, 8416, 20638, 322, 364, 37133, 3148, 11, 597, 309, 534, 286, 2762, 309, 630, 51652], "temperature": 0.0, "avg_logprob": -0.08874769970379044, "compression_ratio": 1.8484848484848484, "no_speech_prob": 0.0033219947945326567}, {"id": 1150, "seek": 655904, "start": 6559.04, "end": 6567.36, "text": " in 2023. What it does is it diminishes public trust in technology. It forces policymakers to", "tokens": [50364, 294, 44377, 13, 708, 309, 775, 307, 309, 15739, 16423, 1908, 3361, 294, 2899, 13, 467, 5874, 47325, 281, 50780], "temperature": 0.0, "avg_logprob": -0.1148793204077359, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.0422135628759861}, {"id": 1151, "seek": 655904, "start": 6568.08, "end": 6573.2, "text": " make decisions that may not be, you know, well informed, they may not be pro innovation, they", "tokens": [50816, 652, 5327, 300, 815, 406, 312, 11, 291, 458, 11, 731, 11740, 11, 436, 815, 406, 312, 447, 8504, 11, 436, 51072], "temperature": 0.0, "avg_logprob": -0.1148793204077359, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.0422135628759861}, {"id": 1152, "seek": 655904, "start": 6573.2, "end": 6577.5199999999995, "text": " may not even be pro safety, right? There may be a bundle of really terrible spots. And I think a", "tokens": [51072, 815, 406, 754, 312, 447, 4514, 11, 558, 30, 821, 815, 312, 257, 24438, 295, 534, 6237, 10681, 13, 400, 286, 519, 257, 51288], "temperature": 0.0, "avg_logprob": -0.1148793204077359, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.0422135628759861}, {"id": 1153, "seek": 655904, "start": 6577.5199999999995, "end": 6582.24, "text": " little bit of a great Lu Chichen is a science fiction writer, this Chinese guy who wrote the", "tokens": [51288, 707, 857, 295, 257, 869, 5047, 761, 18613, 307, 257, 3497, 13266, 9936, 11, 341, 4649, 2146, 567, 4114, 264, 51524], "temperature": 0.0, "avg_logprob": -0.1148793204077359, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.0422135628759861}, {"id": 1154, "seek": 655904, "start": 6582.24, "end": 6585.84, "text": " three body problem. But in his book of short stories, The Wandering Earth, there's a moment", "tokens": [51524, 1045, 1772, 1154, 13, 583, 294, 702, 1446, 295, 2099, 3676, 11, 440, 40772, 1794, 4755, 11, 456, 311, 257, 1623, 51704], "temperature": 0.0, "avg_logprob": -0.1148793204077359, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.0422135628759861}, {"id": 1155, "seek": 658584, "start": 6585.84, "end": 6592.64, "text": " where they have to rocket space 1999 style out of the sun's orbit to prevent some calamity.", "tokens": [50364, 689, 436, 362, 281, 13012, 1901, 19952, 3758, 484, 295, 264, 3295, 311, 13991, 281, 4871, 512, 43936, 507, 13, 50704], "temperature": 0.0, "avg_logprob": -0.12416963799055232, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.01613617315888405}, {"id": 1156, "seek": 658584, "start": 6592.64, "end": 6598.24, "text": " And it's going to be a multi multi generational journey to the to the next planet. And in order", "tokens": [50704, 400, 309, 311, 516, 281, 312, 257, 4825, 4825, 48320, 4671, 281, 264, 281, 264, 958, 5054, 13, 400, 294, 1668, 50984], "temperature": 0.0, "avg_logprob": -0.12416963799055232, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.01613617315888405}, {"id": 1157, "seek": 658584, "start": 6598.24, "end": 6603.76, "text": " to do this, people have to live in really terrible conditions, apart from the scientists who are", "tokens": [50984, 281, 360, 341, 11, 561, 362, 281, 1621, 294, 534, 6237, 4487, 11, 4936, 490, 264, 7708, 567, 366, 51260], "temperature": 0.0, "avg_logprob": -0.12416963799055232, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.01613617315888405}, {"id": 1158, "seek": 658584, "start": 6604.64, "end": 6610.32, "text": " keeping everything monitoring, looking for the signs, planning the the process of decompressing", "tokens": [51304, 5145, 1203, 11028, 11, 1237, 337, 264, 7880, 11, 5038, 264, 264, 1399, 295, 22867, 18605, 51588], "temperature": 0.0, "avg_logprob": -0.12416963799055232, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.01613617315888405}, {"id": 1159, "seek": 661032, "start": 6610.32, "end": 6615.679999999999, "text": " everything. And of course, the people get loose trust in the scientist and in truly", "tokens": [50364, 1203, 13, 400, 295, 1164, 11, 264, 561, 483, 9612, 3361, 294, 264, 12662, 293, 294, 4908, 50632], "temperature": 0.0, "avg_logprob": -0.13271747695075142, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.05130678415298462}, {"id": 1160, "seek": 661032, "start": 6615.679999999999, "end": 6620.16, "text": " Chichen style, sorry, the spoiler, the people rebel, kill all the scientists and then learn", "tokens": [50632, 761, 18613, 3758, 11, 2597, 11, 264, 26927, 11, 264, 561, 28293, 11, 1961, 439, 264, 7708, 293, 550, 1466, 50856], "temperature": 0.0, "avg_logprob": -0.13271747695075142, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.05130678415298462}, {"id": 1161, "seek": 661032, "start": 6620.16, "end": 6625.679999999999, "text": " to hold the next day, they show up at their destination. And trust is really, really critical.", "tokens": [50856, 281, 1797, 264, 958, 786, 11, 436, 855, 493, 412, 641, 12236, 13, 400, 3361, 307, 534, 11, 534, 4924, 13, 51132], "temperature": 0.0, "avg_logprob": -0.13271747695075142, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.05130678415298462}, {"id": 1162, "seek": 661032, "start": 6626.24, "end": 6632.719999999999, "text": " And I don't think we did a lot to get people who are outside of the tech industry to", "tokens": [51160, 400, 286, 500, 380, 519, 321, 630, 257, 688, 281, 483, 561, 567, 366, 2380, 295, 264, 7553, 3518, 281, 51484], "temperature": 0.0, "avg_logprob": -0.13271747695075142, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.05130678415298462}, {"id": 1163, "seek": 661032, "start": 6633.759999999999, "end": 6639.12, "text": " put trust into technology, put trust into their ability to participate in it and to have some", "tokens": [51536, 829, 3361, 666, 2899, 11, 829, 3361, 666, 641, 3485, 281, 8197, 294, 309, 293, 281, 362, 512, 51804], "temperature": 0.0, "avg_logprob": -0.13271747695075142, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.05130678415298462}, {"id": 1164, "seek": 663912, "start": 6639.2, "end": 6645.44, "text": " agency in where it goes, to be excited about it, you know, and off the back of, you know,", "tokens": [50368, 7934, 294, 689, 309, 1709, 11, 281, 312, 2919, 466, 309, 11, 291, 458, 11, 293, 766, 264, 646, 295, 11, 291, 458, 11, 50680], "temperature": 0.0, "avg_logprob": -0.14418655584666354, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.0021630709525197744}, {"id": 1165, "seek": 663912, "start": 6645.44, "end": 6650.72, "text": " all of the sort of polarization and the, the, the, the, the, the sometimes legitimate, sometimes", "tokens": [50680, 439, 295, 264, 1333, 295, 37736, 293, 264, 11, 264, 11, 264, 11, 264, 11, 264, 11, 264, 2171, 17956, 11, 2171, 50944], "temperature": 0.0, "avg_logprob": -0.14418655584666354, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.0021630709525197744}, {"id": 1166, "seek": 663912, "start": 6650.72, "end": 6656.96, "text": " not scaremongering around phones and social networks and so on. And it didn't feel like", "tokens": [50944, 406, 4216, 2579, 556, 1794, 926, 10216, 293, 2093, 9590, 293, 370, 322, 13, 400, 309, 994, 380, 841, 411, 51256], "temperature": 0.0, "avg_logprob": -0.14418655584666354, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.0021630709525197744}, {"id": 1167, "seek": 663912, "start": 6656.96, "end": 6660.72, "text": " it added to the, to the discussion of trust. So I was quite happy when I went to Davos as", "tokens": [51256, 309, 3869, 281, 264, 11, 281, 264, 5017, 295, 3361, 13, 407, 286, 390, 1596, 2055, 562, 286, 1437, 281, 3724, 329, 382, 51444], "temperature": 0.0, "avg_logprob": -0.14418655584666354, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.0021630709525197744}, {"id": 1168, "seek": 663912, "start": 6660.72, "end": 6666.24, "text": " World Economic Forum meeting that the conversation had moved from, is it, you know, what kind of", "tokens": [51444, 3937, 25776, 29704, 3440, 300, 264, 3761, 632, 4259, 490, 11, 307, 309, 11, 291, 458, 11, 437, 733, 295, 51720], "temperature": 0.0, "avg_logprob": -0.14418655584666354, "compression_ratio": 1.7011070110701108, "no_speech_prob": 0.0021630709525197744}, {"id": 1169, "seek": 666624, "start": 6666.24, "end": 6671.5199999999995, "text": " munitions should we use to, to drop on a data center to what are, what are real pathways? What", "tokens": [50364, 11864, 2451, 820, 321, 764, 281, 11, 281, 3270, 322, 257, 1412, 3056, 281, 437, 366, 11, 437, 366, 957, 22988, 30, 708, 50628], "temperature": 0.0, "avg_logprob": -0.12278837830055761, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.009689482860267162}, {"id": 1170, "seek": 666624, "start": 6671.5199999999995, "end": 6675.36, "text": " is the science that we need to do in order to make these things safe in the long term? What", "tokens": [50628, 307, 264, 3497, 300, 321, 643, 281, 360, 294, 1668, 281, 652, 613, 721, 3273, 294, 264, 938, 1433, 30, 708, 50820], "temperature": 0.0, "avg_logprob": -0.12278837830055761, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.009689482860267162}, {"id": 1171, "seek": 666624, "start": 6675.36, "end": 6681.12, "text": " is the kind of appropriate regulatory interventions? What do we do about things that are, you know,", "tokens": [50820, 307, 264, 733, 295, 6854, 18260, 20924, 30, 708, 360, 321, 360, 466, 721, 300, 366, 11, 291, 458, 11, 51108], "temperature": 0.0, "avg_logprob": -0.12278837830055761, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.009689482860267162}, {"id": 1172, "seek": 666624, "start": 6681.12, "end": 6686.0, "text": " approximate three, five years around misinformation and, and, and cyber threats? While, while still", "tokens": [51108, 30874, 1045, 11, 1732, 924, 926, 34238, 293, 11, 293, 11, 293, 13411, 14909, 30, 3987, 11, 1339, 920, 51352], "temperature": 0.0, "avg_logprob": -0.12278837830055761, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.009689482860267162}, {"id": 1173, "seek": 666624, "start": 6686.0, "end": 6690.88, "text": " recognizing that there is a pathway that you've described that needs to be addressed.", "tokens": [51352, 18538, 300, 456, 307, 257, 18590, 300, 291, 600, 7619, 300, 2203, 281, 312, 13847, 13, 51596], "temperature": 0.0, "avg_logprob": -0.12278837830055761, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.009689482860267162}, {"id": 1174, "seek": 666624, "start": 6690.88, "end": 6695.5199999999995, "text": " I find it easy to empathize with basically every AI perspective from the, you know,", "tokens": [51596, 286, 915, 309, 1858, 281, 27155, 1125, 365, 1936, 633, 7318, 4585, 490, 264, 11, 291, 458, 11, 51828], "temperature": 0.0, "avg_logprob": -0.12278837830055761, "compression_ratio": 1.765079365079365, "no_speech_prob": 0.009689482860267162}, {"id": 1175, "seek": 669552, "start": 6695.52, "end": 6703.280000000001, "text": " enthusiast to the ex-risk concerned to those that are, you know, screaming about poor use of", "tokens": [50364, 18076, 525, 281, 264, 454, 12, 33263, 5922, 281, 729, 300, 366, 11, 291, 458, 11, 12636, 466, 4716, 764, 295, 50752], "temperature": 0.0, "avg_logprob": -0.1130807173879523, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0006663046078756452}, {"id": 1176, "seek": 669552, "start": 6703.280000000001, "end": 6708.400000000001, "text": " face match technology by police departments. I mean, really the whole thing I think is like", "tokens": [50752, 1851, 2995, 2899, 538, 3804, 15326, 13, 286, 914, 11, 534, 264, 1379, 551, 286, 519, 307, 411, 51008], "temperature": 0.0, "avg_logprob": -0.1130807173879523, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0006663046078756452}, {"id": 1177, "seek": 669552, "start": 6708.400000000001, "end": 6713.52, "text": " very, it's all valid in my mind. What's really exciting and what did not happen with the mobile", "tokens": [51008, 588, 11, 309, 311, 439, 7363, 294, 452, 1575, 13, 708, 311, 534, 4670, 293, 437, 630, 406, 1051, 365, 264, 6013, 51264], "temperature": 0.0, "avg_logprob": -0.1130807173879523, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0006663046078756452}, {"id": 1178, "seek": 669552, "start": 6713.52, "end": 6721.52, "text": " didn't happen with PCs. It did not happen with the first mainframes is that, you know, technology is,", "tokens": [51264, 994, 380, 1051, 365, 46913, 13, 467, 630, 406, 1051, 365, 264, 700, 2135, 43277, 307, 300, 11, 291, 458, 11, 2899, 307, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1130807173879523, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0006663046078756452}, {"id": 1179, "seek": 672152, "start": 6721.52, "end": 6727.6, "text": " is an intimate part of what it is to be human, right? Technology is our compounded knowledge.", "tokens": [50364, 307, 364, 20215, 644, 295, 437, 309, 307, 281, 312, 1952, 11, 558, 30, 15037, 307, 527, 14154, 292, 3601, 13, 50668], "temperature": 0.0, "avg_logprob": -0.08788384073148899, "compression_ratio": 1.6462585034013606, "no_speech_prob": 0.02459372766315937}, {"id": 1180, "seek": 672152, "start": 6727.6, "end": 6732.96, "text": " Technology is, is the, the binding factor that enables the world in which we then have our human", "tokens": [50668, 15037, 307, 11, 307, 264, 11, 264, 17359, 5952, 300, 17077, 264, 1002, 294, 597, 321, 550, 362, 527, 1952, 50936], "temperature": 0.0, "avg_logprob": -0.08788384073148899, "compression_ratio": 1.6462585034013606, "no_speech_prob": 0.02459372766315937}, {"id": 1181, "seek": 672152, "start": 6732.96, "end": 6739.280000000001, "text": " relationships. And to have so many discussions about a technology early on, when it's just in its", "tokens": [50936, 6159, 13, 400, 281, 362, 370, 867, 11088, 466, 257, 2899, 2440, 322, 11, 562, 309, 311, 445, 294, 1080, 51252], "temperature": 0.0, "avg_logprob": -0.08788384073148899, "compression_ratio": 1.6462585034013606, "no_speech_prob": 0.02459372766315937}, {"id": 1182, "seek": 672152, "start": 6739.280000000001, "end": 6745.68, "text": " early adoption phase, we're not too late to it, I think is incredibly positive. And, and I'm glad", "tokens": [51252, 2440, 19215, 5574, 11, 321, 434, 406, 886, 3469, 281, 309, 11, 286, 519, 307, 6252, 3353, 13, 400, 11, 293, 286, 478, 5404, 51572], "temperature": 0.0, "avg_logprob": -0.08788384073148899, "compression_ratio": 1.6462585034013606, "no_speech_prob": 0.02459372766315937}, {"id": 1183, "seek": 672152, "start": 6745.68, "end": 6750.240000000001, "text": " that you have a big tense show. I mean, I have an opinion about sort of ex-risk, but I still also", "tokens": [51572, 300, 291, 362, 257, 955, 18760, 855, 13, 286, 914, 11, 286, 362, 364, 4800, 466, 1333, 295, 454, 12, 33263, 11, 457, 286, 920, 611, 51800], "temperature": 0.0, "avg_logprob": -0.08788384073148899, "compression_ratio": 1.6462585034013606, "no_speech_prob": 0.02459372766315937}, {"id": 1184, "seek": 675024, "start": 6750.24, "end": 6754.88, "text": " feel I'm big 10, you know, but I'm just really, really glad that we're having a wide and extensive", "tokens": [50364, 841, 286, 478, 955, 1266, 11, 291, 458, 11, 457, 286, 478, 445, 534, 11, 534, 5404, 300, 321, 434, 1419, 257, 4874, 293, 13246, 50596], "temperature": 0.0, "avg_logprob": -0.09702681772636645, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0013667281018570065}, {"id": 1185, "seek": 675024, "start": 6754.88, "end": 6759.76, "text": " conversation, one that feels wider and more extensive and kind of more grounded in some ways", "tokens": [50596, 3761, 11, 472, 300, 3417, 11842, 293, 544, 13246, 293, 733, 295, 544, 23535, 294, 512, 2098, 50840], "temperature": 0.0, "avg_logprob": -0.09702681772636645, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0013667281018570065}, {"id": 1186, "seek": 675024, "start": 6759.76, "end": 6764.32, "text": " than, than any conversation we ever had about the internet back in the early 90s.", "tokens": [50840, 813, 11, 813, 604, 3761, 321, 1562, 632, 466, 264, 4705, 646, 294, 264, 2440, 4289, 82, 13, 51068], "temperature": 0.0, "avg_logprob": -0.09702681772636645, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0013667281018570065}, {"id": 1187, "seek": 675024, "start": 6764.32, "end": 6768.639999999999, "text": " Yeah. In some ways it's funny. I think in some ways the discourse is getting a little bit more", "tokens": [51068, 865, 13, 682, 512, 2098, 309, 311, 4074, 13, 286, 519, 294, 512, 2098, 264, 23938, 307, 1242, 257, 707, 857, 544, 51284], "temperature": 0.0, "avg_logprob": -0.09702681772636645, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0013667281018570065}, {"id": 1188, "seek": 675024, "start": 6768.639999999999, "end": 6772.88, "text": " deranged over time as, you know, there is some polarization and kind of", "tokens": [51284, 1163, 10296, 670, 565, 382, 11, 291, 458, 11, 456, 307, 512, 37736, 293, 733, 295, 51496], "temperature": 0.0, "avg_logprob": -0.09702681772636645, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0013667281018570065}, {"id": 1189, "seek": 675024, "start": 6773.76, "end": 6779.04, "text": " ideological entrenching happening in some places. But then in other ways, I definitely think it's", "tokens": [51540, 35341, 948, 4442, 278, 2737, 294, 512, 3190, 13, 583, 550, 294, 661, 2098, 11, 286, 2138, 519, 309, 311, 51804], "temperature": 0.0, "avg_logprob": -0.09702681772636645, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0013667281018570065}, {"id": 1190, "seek": 677904, "start": 6779.04, "end": 6786.0, "text": " getting better if only because what we're actually dealing with is becoming a lot more clear.", "tokens": [50364, 1242, 1101, 498, 787, 570, 437, 321, 434, 767, 6260, 365, 307, 5617, 257, 688, 544, 1850, 13, 50712], "temperature": 0.0, "avg_logprob": -0.07107297835811492, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.001282138517126441}, {"id": 1191, "seek": 677904, "start": 6786.0, "end": 6792.8, "text": " There is a lot of room for commonality, for common ground, and for a recognition that there are", "tokens": [50712, 821, 307, 257, 688, 295, 1808, 337, 2689, 1860, 11, 337, 2689, 2727, 11, 293, 337, 257, 11150, 300, 456, 366, 51052], "temperature": 0.0, "avg_logprob": -0.07107297835811492, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.001282138517126441}, {"id": 1192, "seek": 677904, "start": 6792.8, "end": 6799.12, "text": " different pieces of work that need to get done by, by different people. And, and actually there", "tokens": [51052, 819, 3755, 295, 589, 300, 643, 281, 483, 1096, 538, 11, 538, 819, 561, 13, 400, 11, 293, 767, 456, 51368], "temperature": 0.0, "avg_logprob": -0.07107297835811492, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.001282138517126441}, {"id": 1193, "seek": 677904, "start": 6799.12, "end": 6804.08, "text": " should be, there should also be enough money in the tank to be able to do it, right? This is a rich", "tokens": [51368, 820, 312, 11, 456, 820, 611, 312, 1547, 1460, 294, 264, 5466, 281, 312, 1075, 281, 360, 309, 11, 558, 30, 639, 307, 257, 4593, 51616], "temperature": 0.0, "avg_logprob": -0.07107297835811492, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.001282138517126441}, {"id": 1194, "seek": 677904, "start": 6804.08, "end": 6808.64, "text": " industry. It spits out a lot of profits. We should be able to, you know, fund it, fund it some way.", "tokens": [51616, 3518, 13, 467, 637, 1208, 484, 257, 688, 295, 17982, 13, 492, 820, 312, 1075, 281, 11, 291, 458, 11, 2374, 309, 11, 2374, 309, 512, 636, 13, 51844], "temperature": 0.0, "avg_logprob": -0.07107297835811492, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.001282138517126441}, {"id": 1195, "seek": 680864, "start": 6808.64, "end": 6812.96, "text": " Again, when you, you see the kind of things people say about each other on Twitter,", "tokens": [50364, 3764, 11, 562, 291, 11, 291, 536, 264, 733, 295, 721, 561, 584, 466, 1184, 661, 322, 5794, 11, 50580], "temperature": 0.0, "avg_logprob": -0.09902455365216291, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.00047254495439119637}, {"id": 1196, "seek": 680864, "start": 6812.96, "end": 6816.72, "text": " and then you meet them in person and they have the same conversation and it's, it's just a,", "tokens": [50580, 293, 550, 291, 1677, 552, 294, 954, 293, 436, 362, 264, 912, 3761, 293, 309, 311, 11, 309, 311, 445, 257, 11, 50768], "temperature": 0.0, "avg_logprob": -0.09902455365216291, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.00047254495439119637}, {"id": 1197, "seek": 680864, "start": 6817.68, "end": 6822.400000000001, "text": " it's a more measured, measured space just in my, my limited experience of it all.", "tokens": [50816, 309, 311, 257, 544, 12690, 11, 12690, 1901, 445, 294, 452, 11, 452, 5567, 1752, 295, 309, 439, 13, 51052], "temperature": 0.0, "avg_logprob": -0.09902455365216291, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.00047254495439119637}, {"id": 1198, "seek": 680864, "start": 6822.400000000001, "end": 6826.320000000001, "text": " I think it's kind of everything everywhere all at once. You know, it's like, yes, there are", "tokens": [51052, 286, 519, 309, 311, 733, 295, 1203, 5315, 439, 412, 1564, 13, 509, 458, 11, 309, 311, 411, 11, 2086, 11, 456, 366, 51248], "temperature": 0.0, "avg_logprob": -0.09902455365216291, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.00047254495439119637}, {"id": 1199, "seek": 680864, "start": 6826.320000000001, "end": 6832.0, "text": " definitely things that are quite unhealthy. And so I do not like to see enemies lists getting", "tokens": [51248, 2138, 721, 300, 366, 1596, 29147, 13, 400, 370, 286, 360, 406, 411, 281, 536, 7805, 14511, 1242, 51532], "temperature": 0.0, "avg_logprob": -0.09902455365216291, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.00047254495439119637}, {"id": 1200, "seek": 680864, "start": 6832.0, "end": 6836.72, "text": " published by leading technologists. That's like, you know, the techno optimist manifesto from", "tokens": [51532, 6572, 538, 5775, 1537, 12256, 13, 663, 311, 411, 11, 291, 458, 11, 264, 36728, 5028, 468, 10067, 78, 490, 51768], "temperature": 0.0, "avg_logprob": -0.09902455365216291, "compression_ratio": 1.7722772277227723, "no_speech_prob": 0.00047254495439119637}, {"id": 1201, "seek": 683672, "start": 6836.72, "end": 6841.2, "text": " Andreessen, you know, has a, has a section that is literally called the enemy and names, names,", "tokens": [50364, 20667, 12431, 11, 291, 458, 11, 575, 257, 11, 575, 257, 3541, 300, 307, 3736, 1219, 264, 5945, 293, 5288, 11, 5288, 11, 50588], "temperature": 0.0, "avg_logprob": -0.07624489698952776, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631391864269972}, {"id": 1202, "seek": 683672, "start": 6841.2, "end": 6847.12, "text": " if not individual names, at least like specific and relatively identifiable groups. So I don't", "tokens": [50588, 498, 406, 2609, 5288, 11, 412, 1935, 411, 2685, 293, 7226, 2473, 30876, 3935, 13, 407, 286, 500, 380, 50884], "temperature": 0.0, "avg_logprob": -0.07624489698952776, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631391864269972}, {"id": 1203, "seek": 683672, "start": 6847.12, "end": 6854.16, "text": " like that. But at the same time, you know, I made some noise about open AI and, you know, kind of", "tokens": [50884, 411, 300, 13, 583, 412, 264, 912, 565, 11, 291, 458, 11, 286, 1027, 512, 5658, 466, 1269, 7318, 293, 11, 291, 458, 11, 733, 295, 51236], "temperature": 0.0, "avg_logprob": -0.07624489698952776, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631391864269972}, {"id": 1204, "seek": 683672, "start": 6855.04, "end": 6859.68, "text": " could have easily been retaliated against by them. And I can imagine a lot of companies,", "tokens": [51280, 727, 362, 3612, 668, 37924, 770, 1970, 538, 552, 13, 400, 286, 393, 3811, 257, 688, 295, 3431, 11, 51512], "temperature": 0.0, "avg_logprob": -0.07624489698952776, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631391864269972}, {"id": 1205, "seek": 683672, "start": 6859.68, "end": 6864.400000000001, "text": " you know, that might have come down on me hard and, you know, expunged my name from their,", "tokens": [51512, 291, 458, 11, 300, 1062, 362, 808, 760, 322, 385, 1152, 293, 11, 291, 458, 11, 1278, 1063, 292, 452, 1315, 490, 641, 11, 51748], "temperature": 0.0, "avg_logprob": -0.07624489698952776, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631391864269972}, {"id": 1206, "seek": 686440, "start": 6864.48, "end": 6867.839999999999, "text": " you know, case studies on their website and all that kind of stuff. And they didn't do any of", "tokens": [50368, 291, 458, 11, 1389, 5313, 322, 641, 3144, 293, 439, 300, 733, 295, 1507, 13, 400, 436, 994, 380, 360, 604, 295, 50536], "temperature": 0.0, "avg_logprob": -0.09687328978672924, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.007120584137737751}, {"id": 1207, "seek": 686440, "start": 6867.839999999999, "end": 6872.24, "text": " that. You know, and so I do think there's also aspects and I feel pretty fortunate. And this is", "tokens": [50536, 300, 13, 509, 458, 11, 293, 370, 286, 360, 519, 456, 311, 611, 7270, 293, 286, 841, 1238, 14096, 13, 400, 341, 307, 50756], "temperature": 0.0, "avg_logprob": -0.09687328978672924, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.007120584137737751}, {"id": 1208, "seek": 686440, "start": 6872.24, "end": 6877.2, "text": " one of the kind of concluding questions I wanted to ask you is like, I think in some sense, this is", "tokens": [50756, 472, 295, 264, 733, 295, 9312, 278, 1651, 286, 1415, 281, 1029, 291, 307, 411, 11, 286, 519, 294, 512, 2020, 11, 341, 307, 51004], "temperature": 0.0, "avg_logprob": -0.09687328978672924, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.007120584137737751}, {"id": 1209, "seek": 686440, "start": 6877.2, "end": 6880.96, "text": " like a collective responsibility. We all have to wreck it. You know, we all have to orient ourselves", "tokens": [51004, 411, 257, 12590, 6357, 13, 492, 439, 362, 281, 21478, 309, 13, 509, 458, 11, 321, 439, 362, 281, 8579, 4175, 51192], "temperature": 0.0, "avg_logprob": -0.09687328978672924, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.007120584137737751}, {"id": 1210, "seek": 686440, "start": 6880.96, "end": 6884.879999999999, "text": " through it, get familiar and try to figure out what's it mean for us and what can we do to", "tokens": [51192, 807, 309, 11, 483, 4963, 293, 853, 281, 2573, 484, 437, 311, 309, 914, 337, 505, 293, 437, 393, 321, 360, 281, 51388], "temperature": 0.0, "avg_logprob": -0.09687328978672924, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.007120584137737751}, {"id": 1211, "seek": 686440, "start": 6884.879999999999, "end": 6890.639999999999, "text": " shape it in a positive way. It's definitely not all somebody else's problem. But at the same time,", "tokens": [51388, 3909, 309, 294, 257, 3353, 636, 13, 467, 311, 2138, 406, 439, 2618, 1646, 311, 1154, 13, 583, 412, 264, 912, 565, 11, 51676], "temperature": 0.0, "avg_logprob": -0.09687328978672924, "compression_ratio": 1.7365269461077844, "no_speech_prob": 0.007120584137737751}, {"id": 1212, "seek": 689064, "start": 6890.64, "end": 6897.280000000001, "text": " there are these like leading developers who clearly have outsize influence, outsize power.", "tokens": [50364, 456, 366, 613, 411, 5775, 8849, 567, 4448, 362, 14758, 1125, 6503, 11, 14758, 1125, 1347, 13, 50696], "temperature": 0.0, "avg_logprob": -0.11362073717326143, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.011685007251799107}, {"id": 1213, "seek": 689064, "start": 6897.280000000001, "end": 6901.4400000000005, "text": " There are also, you know, key decisions that are getting made around like,", "tokens": [50696, 821, 366, 611, 11, 291, 458, 11, 2141, 5327, 300, 366, 1242, 1027, 926, 411, 11, 50904], "temperature": 0.0, "avg_logprob": -0.11362073717326143, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.011685007251799107}, {"id": 1214, "seek": 689064, "start": 6901.4400000000005, "end": 6904.96, "text": " are we going to open source llama three or are we not sounds like we're going to. And then there's", "tokens": [50904, 366, 321, 516, 281, 1269, 4009, 23272, 1045, 420, 366, 321, 406, 3263, 411, 321, 434, 516, 281, 13, 400, 550, 456, 311, 51080], "temperature": 0.0, "avg_logprob": -0.11362073717326143, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.011685007251799107}, {"id": 1215, "seek": 689064, "start": 6904.96, "end": 6910.56, "text": " like government, you know, that can potentially say, you know, hey, we, we require, you know,", "tokens": [51080, 411, 2463, 11, 291, 458, 11, 300, 393, 7263, 584, 11, 291, 458, 11, 4177, 11, 321, 11, 321, 3651, 11, 291, 458, 11, 51360], "temperature": 0.0, "avg_logprob": -0.11362073717326143, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.011685007251799107}, {"id": 1216, "seek": 689064, "start": 6910.56, "end": 6914.400000000001, "text": " off switches at data centers. I'm not sure data centers have off switches right now. You know,", "tokens": [51360, 766, 19458, 412, 1412, 10898, 13, 286, 478, 406, 988, 1412, 10898, 362, 766, 19458, 558, 586, 13, 509, 458, 11, 51552], "temperature": 0.0, "avg_logprob": -0.11362073717326143, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.011685007251799107}, {"id": 1217, "seek": 689064, "start": 6914.400000000001, "end": 6918.4800000000005, "text": " you might be able to go in there and start like hacking at them. But is there an actual like easy", "tokens": [51552, 291, 1062, 312, 1075, 281, 352, 294, 456, 293, 722, 411, 31422, 412, 552, 13, 583, 307, 456, 364, 3539, 411, 1858, 51756], "temperature": 0.0, "avg_logprob": -0.11362073717326143, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.011685007251799107}, {"id": 1218, "seek": 691848, "start": 6918.48, "end": 6922.48, "text": " off switch in most of them? No, I don't think there is. I mean, they're designed to be resilient.", "tokens": [50364, 766, 3679, 294, 881, 295, 552, 30, 883, 11, 286, 500, 380, 519, 456, 307, 13, 286, 914, 11, 436, 434, 4761, 281, 312, 23699, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14025083923339843, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.008845888078212738}, {"id": 1219, "seek": 691848, "start": 6922.48, "end": 6926.08, "text": " Yeah, the opposite, right? Yeah, they're not so and they don't probably want some", "tokens": [50564, 865, 11, 264, 6182, 11, 558, 30, 865, 11, 436, 434, 406, 370, 293, 436, 500, 380, 1391, 528, 512, 50744], "temperature": 0.0, "avg_logprob": -0.14025083923339843, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.008845888078212738}, {"id": 1220, "seek": 691848, "start": 6926.879999999999, "end": 6931.2, "text": " rogue employee either to like go in and turn it off, right? So they've probably engineered away", "tokens": [50784, 39100, 10738, 2139, 281, 411, 352, 294, 293, 1261, 309, 766, 11, 558, 30, 407, 436, 600, 1391, 38648, 1314, 51000], "temperature": 0.0, "avg_logprob": -0.14025083923339843, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.008845888078212738}, {"id": 1221, "seek": 691848, "start": 6931.2, "end": 6936.32, "text": " from anybody being able to easily turn it off. So, you know, government may have a role there to", "tokens": [51000, 490, 4472, 885, 1075, 281, 3612, 1261, 309, 766, 13, 407, 11, 291, 458, 11, 2463, 815, 362, 257, 3090, 456, 281, 51256], "temperature": 0.0, "avg_logprob": -0.14025083923339843, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.008845888078212738}, {"id": 1222, "seek": 691848, "start": 6936.32, "end": 6941.839999999999, "text": " play that's like, look, we need off switches, we hope we never have to use them. But it seems like", "tokens": [51256, 862, 300, 311, 411, 11, 574, 11, 321, 643, 766, 19458, 11, 321, 1454, 321, 1128, 362, 281, 764, 552, 13, 583, 309, 2544, 411, 51532], "temperature": 0.0, "avg_logprob": -0.14025083923339843, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.008845888078212738}, {"id": 1223, "seek": 694184, "start": 6941.84, "end": 6948.88, "text": " we might want to have them. So who do you think kind of bears the greatest responsibility or,", "tokens": [50364, 321, 1062, 528, 281, 362, 552, 13, 407, 567, 360, 291, 519, 733, 295, 17276, 264, 6636, 6357, 420, 11, 50716], "temperature": 0.0, "avg_logprob": -0.05972219515247505, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.10922976583242416}, {"id": 1224, "seek": 694184, "start": 6948.88, "end": 6953.92, "text": " you know, or where do you think we should be investing our trust? You know, is it these leading", "tokens": [50716, 291, 458, 11, 420, 689, 360, 291, 519, 321, 820, 312, 10978, 527, 3361, 30, 509, 458, 11, 307, 309, 613, 5775, 50968], "temperature": 0.0, "avg_logprob": -0.05972219515247505, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.10922976583242416}, {"id": 1225, "seek": 694184, "start": 6953.92, "end": 6961.04, "text": " companies? Is it auditors, you know, that could be independent groups? Is it the government? I mean,", "tokens": [50968, 3431, 30, 1119, 309, 2379, 9862, 11, 291, 458, 11, 300, 727, 312, 6695, 3935, 30, 1119, 309, 264, 2463, 30, 286, 914, 11, 51324], "temperature": 0.0, "avg_logprob": -0.05972219515247505, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.10922976583242416}, {"id": 1226, "seek": 694184, "start": 6961.04, "end": 6965.2, "text": " it's probably some mix of all the above, but what are you kind of bullish on in that regard?", "tokens": [51324, 309, 311, 1391, 512, 2890, 295, 439, 264, 3673, 11, 457, 437, 366, 291, 733, 295, 38692, 322, 294, 300, 3843, 30, 51532], "temperature": 0.0, "avg_logprob": -0.05972219515247505, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.10922976583242416}, {"id": 1227, "seek": 694184, "start": 6965.2, "end": 6969.76, "text": " I mean, you know, the US has been an incredibly successful democracy for a long time because", "tokens": [51532, 286, 914, 11, 291, 458, 11, 264, 2546, 575, 668, 364, 6252, 4406, 10528, 337, 257, 938, 565, 570, 51760], "temperature": 0.0, "avg_logprob": -0.05972219515247505, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.10922976583242416}, {"id": 1228, "seek": 696976, "start": 6969.76, "end": 6978.64, "text": " of separation of powers. And, you know, structurally, that works. The company, however good it is,", "tokens": [50364, 295, 14634, 295, 8674, 13, 400, 11, 291, 458, 11, 6594, 6512, 11, 300, 1985, 13, 440, 2237, 11, 4461, 665, 309, 307, 11, 50808], "temperature": 0.0, "avg_logprob": -0.13707476473869162, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.017208388075232506}, {"id": 1229, "seek": 696976, "start": 6978.64, "end": 6985.6, "text": " however well intentioned the CEO is, will end up with its own ambitions and directions. And so,", "tokens": [50808, 4461, 731, 7789, 292, 264, 9282, 307, 11, 486, 917, 493, 365, 1080, 1065, 34475, 293, 11095, 13, 400, 370, 11, 51156], "temperature": 0.0, "avg_logprob": -0.13707476473869162, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.017208388075232506}, {"id": 1230, "seek": 696976, "start": 6985.6, "end": 6989.6, "text": " you know, you will always need to push if the companies are offering you three,", "tokens": [51156, 291, 458, 11, 291, 486, 1009, 643, 281, 2944, 498, 264, 3431, 366, 8745, 291, 1045, 11, 51356], "temperature": 0.0, "avg_logprob": -0.13707476473869162, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.017208388075232506}, {"id": 1231, "seek": 696976, "start": 6989.6, "end": 6995.68, "text": " demand six, that's just that's a good, good practice. So I think that each player in this", "tokens": [51356, 4733, 2309, 11, 300, 311, 445, 300, 311, 257, 665, 11, 665, 3124, 13, 407, 286, 519, 300, 1184, 4256, 294, 341, 51660], "temperature": 0.0, "avg_logprob": -0.13707476473869162, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.017208388075232506}, {"id": 1232, "seek": 699568, "start": 6995.76, "end": 7001.280000000001, "text": " circuit has to be have the right capabilities to have the right conversations. And I think one of", "tokens": [50368, 9048, 575, 281, 312, 362, 264, 558, 10862, 281, 362, 264, 558, 7315, 13, 400, 286, 519, 472, 295, 50644], "temperature": 0.0, "avg_logprob": -0.07182251082526313, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.012126132845878601}, {"id": 1233, "seek": 699568, "start": 7001.280000000001, "end": 7008.0, "text": " the things that we can learn from the experience of the FAA and Boeing is that you cannot deplete", "tokens": [50644, 264, 721, 300, 321, 393, 1466, 490, 264, 1752, 295, 264, 479, 5265, 293, 30831, 307, 300, 291, 2644, 368, 17220, 50980], "temperature": 0.0, "avg_logprob": -0.07182251082526313, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.012126132845878601}, {"id": 1234, "seek": 699568, "start": 7008.0, "end": 7013.92, "text": " your own capabilities and ask for self regulation because it just doesn't work out however well", "tokens": [50980, 428, 1065, 10862, 293, 1029, 337, 2698, 15062, 570, 309, 445, 1177, 380, 589, 484, 4461, 731, 51276], "temperature": 0.0, "avg_logprob": -0.07182251082526313, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.012126132845878601}, {"id": 1235, "seek": 699568, "start": 7013.92, "end": 7019.4400000000005, "text": " intentioned that the firm is. So I think what you need to do is we need to invest in the capabilities", "tokens": [51276, 7789, 292, 300, 264, 6174, 307, 13, 407, 286, 519, 437, 291, 643, 281, 360, 307, 321, 643, 281, 1963, 294, 264, 10862, 51552], "temperature": 0.0, "avg_logprob": -0.07182251082526313, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.012126132845878601}, {"id": 1236, "seek": 701944, "start": 7019.44, "end": 7026.719999999999, "text": " of governments to ask good questions and engage well and overcome all of the complexities", "tokens": [50364, 295, 11280, 281, 1029, 665, 1651, 293, 4683, 731, 293, 10473, 439, 295, 264, 48705, 50728], "temperature": 0.0, "avg_logprob": -0.14531693407284316, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.18648092448711395}, {"id": 1237, "seek": 701944, "start": 7026.719999999999, "end": 7033.599999999999, "text": " that exist that you can make $10 million a year as an X at OpenAI and you won't do that in government.", "tokens": [50728, 300, 2514, 300, 291, 393, 652, 1848, 3279, 2459, 257, 1064, 382, 364, 1783, 412, 7238, 48698, 293, 291, 1582, 380, 360, 300, 294, 2463, 13, 51072], "temperature": 0.0, "avg_logprob": -0.14531693407284316, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.18648092448711395}, {"id": 1238, "seek": 701944, "start": 7033.599999999999, "end": 7041.599999999999, "text": " And I think that that also raises the value of investing in academia, research and civil society.", "tokens": [51072, 400, 286, 519, 300, 300, 611, 19658, 264, 2158, 295, 10978, 294, 28937, 11, 2132, 293, 5605, 4086, 13, 51472], "temperature": 0.0, "avg_logprob": -0.14531693407284316, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.18648092448711395}, {"id": 1239, "seek": 701944, "start": 7041.599999999999, "end": 7046.0, "text": " So Joshua Bengio, for example, is running a really important project. I think it's based out of the", "tokens": [51472, 407, 24005, 3964, 17862, 11, 337, 1365, 11, 307, 2614, 257, 534, 1021, 1716, 13, 286, 519, 309, 311, 2361, 484, 295, 264, 51692], "temperature": 0.0, "avg_logprob": -0.14531693407284316, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.18648092448711395}, {"id": 1240, "seek": 704600, "start": 7046.0, "end": 7051.44, "text": " UK, which is a sort of core science project to look at some of these risks and these evolutions", "tokens": [50364, 7051, 11, 597, 307, 257, 1333, 295, 4965, 3497, 1716, 281, 574, 412, 512, 295, 613, 10888, 293, 613, 1073, 15892, 50636], "temperature": 0.0, "avg_logprob": -0.07816730340321859, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.04520062729716301}, {"id": 1241, "seek": 704600, "start": 7051.44, "end": 7057.2, "text": " and unanswered questions around control. We need to really, really start to level up. And I don't", "tokens": [50636, 293, 517, 43904, 292, 1651, 926, 1969, 13, 492, 643, 281, 534, 11, 534, 722, 281, 1496, 493, 13, 400, 286, 500, 380, 50924], "temperature": 0.0, "avg_logprob": -0.07816730340321859, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.04520062729716301}, {"id": 1242, "seek": 704600, "start": 7057.2, "end": 7063.76, "text": " think it will be sufficient to just allow the big firms to do that and insist that they spend the", "tokens": [50924, 519, 309, 486, 312, 11563, 281, 445, 2089, 264, 955, 18055, 281, 360, 300, 293, 13466, 300, 436, 3496, 264, 51252], "temperature": 0.0, "avg_logprob": -0.07816730340321859, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.04520062729716301}, {"id": 1243, "seek": 704600, "start": 7063.76, "end": 7068.72, "text": " money as directed by them. You know, I think if they have, if they're willing to put money into it,", "tokens": [51252, 1460, 382, 12898, 538, 552, 13, 509, 458, 11, 286, 519, 498, 436, 362, 11, 498, 436, 434, 4950, 281, 829, 1460, 666, 309, 11, 51500], "temperature": 0.0, "avg_logprob": -0.07816730340321859, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.04520062729716301}, {"id": 1244, "seek": 704600, "start": 7068.72, "end": 7072.96, "text": " it should go into pots, which go to grow the capabilities of the people who will keep them", "tokens": [51500, 309, 820, 352, 666, 22022, 11, 597, 352, 281, 1852, 264, 10862, 295, 264, 561, 567, 486, 1066, 552, 51712], "temperature": 0.0, "avg_logprob": -0.07816730340321859, "compression_ratio": 1.7092198581560283, "no_speech_prob": 0.04520062729716301}, {"id": 1245, "seek": 707296, "start": 7072.96, "end": 7079.76, "text": " in check. And the reason that works is that, you know, the car industry is really successful", "tokens": [50364, 294, 1520, 13, 400, 264, 1778, 300, 1985, 307, 300, 11, 291, 458, 11, 264, 1032, 3518, 307, 534, 4406, 50704], "temperature": 0.0, "avg_logprob": -0.08820871206430289, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.014519037678837776}, {"id": 1246, "seek": 707296, "start": 7079.76, "end": 7083.68, "text": " because someone mandated that cars needed to have brakes. Now, without brakes,", "tokens": [50704, 570, 1580, 47563, 300, 5163, 2978, 281, 362, 19950, 13, 823, 11, 1553, 19950, 11, 50900], "temperature": 0.0, "avg_logprob": -0.08820871206430289, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.014519037678837776}, {"id": 1247, "seek": 707296, "start": 7084.64, "end": 7089.12, "text": " people wouldn't buy as many cars as they do. And I think this is good for the industry.", "tokens": [50948, 561, 2759, 380, 2256, 382, 867, 5163, 382, 436, 360, 13, 400, 286, 519, 341, 307, 665, 337, 264, 3518, 13, 51172], "temperature": 0.0, "avg_logprob": -0.08820871206430289, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.014519037678837776}, {"id": 1248, "seek": 707296, "start": 7089.12, "end": 7093.2, "text": " And someone needs to understand within government, within civil society, within academia,", "tokens": [51172, 400, 1580, 2203, 281, 1223, 1951, 2463, 11, 1951, 5605, 4086, 11, 1951, 28937, 11, 51376], "temperature": 0.0, "avg_logprob": -0.08820871206430289, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.014519037678837776}, {"id": 1249, "seek": 707296, "start": 7093.2, "end": 7096.4800000000005, "text": " academia, what are the right questions? And so what are the right interventions", "tokens": [51376, 28937, 11, 437, 366, 264, 558, 1651, 30, 400, 370, 437, 366, 264, 558, 20924, 51540], "temperature": 0.0, "avg_logprob": -0.08820871206430289, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.014519037678837776}, {"id": 1250, "seek": 707296, "start": 7096.4800000000005, "end": 7100.16, "text": " going to look like? And we can all agree as grown-ups that companies,", "tokens": [51540, 516, 281, 574, 411, 30, 400, 321, 393, 439, 3986, 382, 7709, 12, 7528, 300, 3431, 11, 51724], "temperature": 0.0, "avg_logprob": -0.08820871206430289, "compression_ratio": 1.7695035460992907, "no_speech_prob": 0.014519037678837776}, {"id": 1251, "seek": 710016, "start": 7100.24, "end": 7106.639999999999, "text": " however well-intentioned they are, will always have their own agenda. And we just acknowledge", "tokens": [50368, 4461, 731, 12, 686, 1251, 292, 436, 366, 11, 486, 1009, 362, 641, 1065, 9829, 13, 400, 321, 445, 10692, 50688], "temperature": 0.0, "avg_logprob": -0.10715488025120326, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.002787325531244278}, {"id": 1252, "seek": 710016, "start": 7106.639999999999, "end": 7114.0, "text": " that. And we all move forward in a generative, critical, constructive way. So whichever player", "tokens": [50688, 300, 13, 400, 321, 439, 1286, 2128, 294, 257, 1337, 1166, 11, 4924, 11, 30223, 636, 13, 407, 24123, 4256, 51056], "temperature": 0.0, "avg_logprob": -0.10715488025120326, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.002787325531244278}, {"id": 1253, "seek": 710016, "start": 7114.0, "end": 7120.4, "text": " is weak at this table needs to have some support to become stronger. And that probably right now", "tokens": [51056, 307, 5336, 412, 341, 3199, 2203, 281, 362, 512, 1406, 281, 1813, 7249, 13, 400, 300, 1391, 558, 586, 51376], "temperature": 0.0, "avg_logprob": -0.10715488025120326, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.002787325531244278}, {"id": 1254, "seek": 710016, "start": 7120.4, "end": 7125.44, "text": " is amongst governments and regulators and academia rather than the big few tech firms.", "tokens": [51376, 307, 12918, 11280, 293, 37311, 293, 28937, 2831, 813, 264, 955, 1326, 7553, 18055, 13, 51628], "temperature": 0.0, "avg_logprob": -0.10715488025120326, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.002787325531244278}, {"id": 1255, "seek": 712544, "start": 7125.44, "end": 7129.12, "text": " That might be a great note to end on. Anything else you want to touch on or", "tokens": [50364, 663, 1062, 312, 257, 869, 3637, 281, 917, 322, 13, 11998, 1646, 291, 528, 281, 2557, 322, 420, 50548], "temperature": 0.0, "avg_logprob": -0.09799465511156165, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.06269383430480957}, {"id": 1256, "seek": 712544, "start": 7129.919999999999, "end": 7134.799999999999, "text": " cover that we haven't got to? It's really easy as such a facility and having the conversations", "tokens": [50588, 2060, 300, 321, 2378, 380, 658, 281, 30, 467, 311, 534, 1858, 382, 1270, 257, 8973, 293, 1419, 264, 7315, 50832], "temperature": 0.0, "avg_logprob": -0.09799465511156165, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.06269383430480957}, {"id": 1257, "seek": 712544, "start": 7134.799999999999, "end": 7141.679999999999, "text": " with you. And I really was so excited that you agreed to do this. You know, I thought the murder", "tokens": [50832, 365, 291, 13, 400, 286, 534, 390, 370, 2919, 300, 291, 9166, 281, 360, 341, 13, 509, 458, 11, 286, 1194, 264, 6568, 51176], "temperature": 0.0, "avg_logprob": -0.09799465511156165, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.06269383430480957}, {"id": 1258, "seek": 712544, "start": 7141.679999999999, "end": 7146.799999999999, "text": " mystery, which is you and your red teaming show was just brilliant as well. So I know that you've", "tokens": [51176, 11422, 11, 597, 307, 291, 293, 428, 2182, 1469, 278, 855, 390, 445, 10248, 382, 731, 13, 407, 286, 458, 300, 291, 600, 51432], "temperature": 0.0, "avg_logprob": -0.09799465511156165, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.06269383430480957}, {"id": 1259, "seek": 712544, "start": 7146.799999999999, "end": 7151.919999999999, "text": " got another hat, which is suspense. And I look forward to the next episode of that.", "tokens": [51432, 658, 1071, 2385, 11, 597, 307, 47803, 13, 400, 286, 574, 2128, 281, 264, 958, 3500, 295, 300, 13, 51688], "temperature": 0.0, "avg_logprob": -0.09799465511156165, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.06269383430480957}, {"id": 1260, "seek": 715192, "start": 7152.72, "end": 7156.88, "text": " Well, thank you very much. I really appreciate that. And I appreciate your time and participation", "tokens": [50404, 1042, 11, 1309, 291, 588, 709, 13, 286, 534, 4449, 300, 13, 400, 286, 4449, 428, 565, 293, 13487, 50612], "temperature": 0.0, "avg_logprob": -0.1145227515179178, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.014275038614869118}, {"id": 1261, "seek": 715192, "start": 7156.88, "end": 7162.16, "text": " in this as well. Azim Azhar, founder of The Exponential View, thank you for being part of", "tokens": [50612, 294, 341, 382, 731, 13, 7607, 332, 7607, 5854, 11, 14917, 295, 440, 21391, 266, 2549, 13909, 11, 1309, 291, 337, 885, 644, 295, 50876], "temperature": 0.0, "avg_logprob": -0.1145227515179178, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.014275038614869118}, {"id": 1262, "seek": 715192, "start": 7162.16, "end": 7165.12, "text": " The Cognitive Revolution. My pleasure, Nathan. Thank you.", "tokens": [50876, 440, 383, 2912, 2187, 16617, 13, 1222, 6834, 11, 20634, 13, 1044, 291, 13, 51024], "temperature": 0.0, "avg_logprob": -0.1145227515179178, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.014275038614869118}, {"id": 1263, "seek": 715192, "start": 7165.84, "end": 7170.64, "text": " It is both energizing and enlightening to hear why people listen and learn what they value about", "tokens": [51060, 467, 307, 1293, 10575, 3319, 293, 18690, 4559, 281, 1568, 983, 561, 2140, 293, 1466, 437, 436, 2158, 466, 51300], "temperature": 0.0, "avg_logprob": -0.1145227515179178, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.014275038614869118}, {"id": 1264, "seek": 715192, "start": 7170.64, "end": 7178.08, "text": " the show. So please don't hesitate to reach out via email at tcraturpantime.co or you can DM me", "tokens": [51300, 264, 855, 13, 407, 1767, 500, 380, 20842, 281, 2524, 484, 5766, 3796, 412, 256, 10757, 267, 20130, 394, 1312, 13, 1291, 420, 291, 393, 15322, 385, 51672], "temperature": 0.0, "avg_logprob": -0.1145227515179178, "compression_ratio": 1.5869565217391304, "no_speech_prob": 0.014275038614869118}, {"id": 1265, "seek": 717808, "start": 7178.08, "end": 7184.64, "text": " on the social media platform of your choice. Omniki uses generative AI to enable you to launch", "tokens": [50364, 322, 264, 2093, 3021, 3663, 295, 428, 3922, 13, 9757, 77, 9850, 4960, 1337, 1166, 7318, 281, 9528, 291, 281, 4025, 50692], "temperature": 0.0, "avg_logprob": -0.11895737719179979, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.3203209936618805}, {"id": 1266, "seek": 717808, "start": 7184.64, "end": 7190.08, "text": " hundreds of thousands of ad iterations that actually work, customized across all platforms", "tokens": [50692, 6779, 295, 5383, 295, 614, 36540, 300, 767, 589, 11, 30581, 2108, 439, 9473, 50964], "temperature": 0.0, "avg_logprob": -0.11895737719179979, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.3203209936618805}, {"id": 1267, "seek": 717808, "start": 7190.08, "end": 7194.96, "text": " with a click of a button. I believe in Omniki so much that I invested in it and I recommend you", "tokens": [50964, 365, 257, 2052, 295, 257, 2960, 13, 286, 1697, 294, 9757, 77, 9850, 370, 709, 300, 286, 13104, 294, 309, 293, 286, 2748, 291, 51208], "temperature": 0.0, "avg_logprob": -0.11895737719179979, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.3203209936618805}, {"id": 1268, "seek": 719496, "start": 7194.96, "end": 7202.32, "text": " use it too. Use CogGrav to get a 10% discount.", "tokens": [50364, 764, 309, 886, 13, 8278, 383, 664, 38, 13404, 281, 483, 257, 1266, 4, 11635, 13, 50732], "temperature": 0.0, "avg_logprob": -0.45655923140676397, "compression_ratio": 0.9019607843137255, "no_speech_prob": 0.6718345880508423}], "language": "en"}