start	end	text
0	3600	This case has the potential to end the internet as we know it.
3600	7600	The internet flourishes on user-generated content. It's the backbone of the internet.
7600	12240	And if you write or say something that is illegal, you can be held liable for what you said.
12240	15920	But usually the websites that host your content are not liable.
15920	19600	And when you hear about Section 230, this is usually what we're talking about.
19600	23280	But if websites were also liable for what users say,
23280	27760	then websites would either shut down almost everything or police things so tightly
27840	31680	that there would be basically nothing even remotely objectionable.
31680	33440	Because if there's one thing that websites hate,
33440	38320	it's being on the hook for billions and billions of dollars of potential liability and attorney's fees.
38320	40720	And this isn't just some potential hypothetical.
40720	44720	In the past, when laws made websites liable for user content,
44720	47120	they just shut down the content and never came back.
47680	52240	And one case before the Supreme Court this term seeks to do exactly that,
52240	54160	but for all of the internet.
54160	58480	No joke, this has the potential to end the internet as we know it today.
59120	60400	So how did we get here?
62960	64320	Well, it started with a tragedy.
64320	67760	Noemi Gonzalez was a design major at California State University Long Beach,
67760	70080	who was spending a semester studying in Paris.
70080	72640	On the evening of November 15, 2015,
72640	75840	she was dining with friends at a cafe on the Champs-Elysees,
75840	78400	when an ISIS terrorist with a gun opened fire.
78400	81360	Gonzalez was killed along with 130 other people
81440	84720	in coordinated attacks at six locations across the city.
84720	86640	ISIS claimed responsibility for the attacks,
86640	90240	and eventually 20 men were convicted of crimes related to the massacre.
90240	93360	The lone surviving gunman was sentenced to life without parole.
93360	95280	So was justice served?
95280	97680	Well, the Gonzalez family contends that it was not,
97680	100320	because there was another perpetrator still at large.
100320	101120	YouTube.
101120	103280	The family sued Google, which owns YouTube,
103280	107040	alleging that YouTube's algorithms amplify violent videos and hateful content,
107040	110400	despite the company's efforts to ban violent accounts and limit their reach.
110400	112720	The Gonzalez family says that YouTube's recommendations
112720	115280	expose people to hateful content, radicalize viewers,
115280	117840	and encourage them to make terrorist attacks of their own.
117840	122000	Google argued that because ISIS, not YouTube, made and uploaded those videos,
122000	124480	YouTube was not the provider or developer of those videos,
124480	128800	and therefore it was immune from liability under 47 USC Section 230,
128800	132320	otherwise known as Section 230 of the Communications Decency Act.
132320	135120	Section 230 of the CDA immunizes internet services
135120	137680	for the content that its users upload,
137680	142240	and often allows websites to remove content without taking on liability.
142240	144880	But the Gonzalez plaintiffs contend that YouTube's recommendations
144880	149040	should not be covered by Section 230 because the company is acting like a content creator
149040	150480	rather than a publisher.
150480	153120	The Ninth Circuit Court of Appeals held that the Gonzalez claims
153120	156400	fell within Section 230 and Google was immune from suit.
156400	159280	The Gonzalez parties appealed and the Supreme Court granted cert
159280	161760	to answer the question of whether Section 230
161760	166960	immunizes an interactive computer service from liability for recommending other party content.
166960	168960	Now in support of their claims, plaintiffs alleged the quote
168960	171840	two of the 12 ISIS terrorists who carried out the attacks
171840	176560	used online social media platforms to post links to ISIS recruitment YouTube videos
176560	178560	and quote jihadi YouTube videos.
179280	184000	One of the men who fired at Gonzalez had appeared in an ISIS recruiting video in 2014.
184560	189280	Now the plaintiffs argue that the defendants violated the Anti-Terrorism Act, the ATA,
189280	194880	by allowing ISIS to post videos on YouTube under Section 2333 of the ATA,
194880	198000	as amended by the Justice Against Sponsors of Terrorism Act.
198000	201760	Americans who are injured by quote an act of international terrorism
201760	205200	that is committed, planned, or authorized by a terrorist organization
205200	210320	may sue any person who quote aides and abets by knowingly providing substantial assistance
210320	214320	or who conspires with a person who committed such an act of international terrorism
214320	216000	and recover trouble damages.
216000	219600	So the legal question in the lower courts was whether a social media platform
219600	223680	that was not used to commit a specific quote active international terrorism
223680	227120	may still be liable for aiding and abetting under Section 2333.
227120	228560	The plaintiffs say that the answer is yes,
228560	231440	that Google aided and abetted an act of international terrorism
231440	234560	conspired with the perpetrator of an act of international terrorism
234560	238480	and provided material support to ISIS by allowing ISIS to use YouTube.
238480	239600	And of course the defendants say no,
239600	243040	the plaintiff's claims are barred by Section 230 of the Communications Decency Act
243040	247600	which often immunizes interactive computer services, aka websites,
247600	249680	even when they make targeted recommendations.
249680	251920	The trial court and the Ninth Circuit Court of Appeals
251920	255840	sided with Google, ruling that the claims fell within Section 230 Section C
256560	260240	because ISIS, not YouTube, created or developed the relevant content.
260240	262720	The court said that YouTube quote selects the particular content
262720	265280	provided to a user based on that user's inputs.
265280	270640	The display of recommended content results from algorithms that are merely quote tools
270640	273600	meant to facilitate the communication and content of others
273600	276240	and not content in and of themselves.
276240	277520	As the lower courts noted,
277520	281520	the recommendations are based on the user's preferences, not YouTube's.
281600	285440	The plaintiffs argue that Section 230C does not apply to quote
285440	287840	activities that promote or recommend content.
287840	290560	So let's dig deeper into what all of this means.
290560	293840	First of all, the plaintiffs are not simply arguing that platforms are liable
293840	296080	because terrorists have used their services.
296080	298960	They argue that the powerful algorithms that recommend content
298960	303440	are not covered by the CDA because the recommendations are content in and of themselves.
303440	304400	And as the Ninth Circuit said,
304400	306960	the complaint alleges Google uses computer algorithms
306960	310400	to match and suggest content to users based upon their viewing history.
310400	312240	The Gonzalez plaintiffs alleged that in this way,
312240	317840	Google has recommended ISIS videos to users and enabled users to locate other videos and accounts
317840	318880	related to ISIS.
318880	321840	And that by doing so, Google assists ISIS in spreading its message.
321840	323840	So the plaintiffs claim that YouTube facilitates
323840	326320	communications between ISIS and people who watch their videos,
326320	328640	thereby aiding ISIS in recruiting new members.
328640	332320	The plaintiffs acknowledge that YouTube removed ISIS videos and suspended
332320	334560	or blocked ISIS users at various times.
334560	338080	However, the plaintiffs claim that YouTube should have been able to stop ISIS from
338080	340400	reestablishing accounts using new identities.
340400	343120	And the plaintiffs alleged that Google left some of the ISIS videos up
343120	346000	because they did not contain content violating the site's policies.
346000	348320	At other times, Google removed the offending content,
348320	350480	but did not suspend or ban the accounts.
350480	354880	Now, we've talked about Section 230 of the CDA many times on this channel.
354880	359120	Section 230 was created back in 1996 at the dawn of the Internet.
359120	360960	It has two key provisions.
360960	363600	Section 230c1 says, quote,
363600	366640	No provider or user of an interactive computer service
366640	370400	shall be treated as the publisher or speaker of any information provided by
370400	372400	another information content provider.
373040	376640	This sentence is often called the 26 words that created the Internet.
376640	380480	This section stipulates that providing access to third-party content
380480	384800	does not make an online provider the publisher or speaker of that content.
385360	389040	Now, the second major part of the law is Section 230c2,
389040	391200	the so-called Good Samaritan provision,
391200	392080	which states, quote,
392080	395360	No provider or user of an interactive computer service
395360	399520	shall be held liable on account of any action voluntarily taken in good faith
399520	402320	to restrict access to or availability of material
402320	406080	that the provider or user considers to be obscene, lewd, lascivious,
406080	409520	filthy, excessively violent, harassing, or otherwise objectionable,
409520	412880	whether or not such material is constitutionally protected.
412880	416720	So this provision gives online platforms broad immunity from liability
416720	419280	if they moderate content in good faith.
419280	422960	This provision was meant to allow websites to police itself
422960	426320	without incurring new liability because it was an issue of knowledge.
426320	429600	A website might not know what speech was hosted on that particular website,
429600	431680	in which case they wouldn't be liable for it,
431680	435520	but if they knew that illegal speech or defamatory speech
435520	437440	or some other kind of speech was hosted there
437440	441040	and then took steps to remove it from the website itself,
441040	444160	then they actively had knowledge of that particular speech
444160	447360	and thus might become liable for hosting it in the future.
447440	449760	So websites found themselves on the horns of a dilemma
449760	451840	until section 230 of the CDA was passed
451840	454720	to allow them to engage in good faith moderation
454720	456960	because there was generally a knowledge requirement
456960	459920	to be liable for things that were hosted on your website.
459920	462400	If you had no knowledge of what kind of speech
462400	464320	was on your website or platform,
464320	467280	then you generally weren't liable for it.
467280	470640	But the argument went that if you started to moderate your website,
470640	472880	then that was evidence that you knew what was on there
472880	475680	and therefore you became liable for all the stuff
475680	478000	that you were trying to remove from your website.
478000	480640	And this applied to spam, to pornography,
480640	484800	to pirated media, to defamation, you name it.
484800	487360	So the CDA was enacted in 1996
487360	489440	when the internet was still in its infancy.
489440	491360	At the time, companies like America Online,
491360	493200	CoffeeServe and Prodigy were the portals
493200	495120	that allowed people to access the internet.
495120	497280	People could share files, exchange messages,
497280	499040	and chat with each other in real time.
499040	500560	But that posed a dilemma.
500560	503920	Who would be liable if a user posted something defamatory
503920	506640	or shared something else that was illegal?
506640	508400	Would liability go beyond the person
508400	510240	that was responsible for the post?
510240	511760	Or would the internet companies
511760	514160	who hosted the content also be on the hook?
514160	515280	And that brings us to the distinction
515280	517520	between content publishers, distributors, and platforms,
517520	520000	which is often completely misunderstood.
520000	521360	In the pre-internet age,
521360	523040	publishers, distributors, and platforms
523040	524640	were treated differently under the law.
524640	528240	Publishers were newspapers, magazines, and broadcast stations.
528240	530400	They were generally liable for republishing material
530400	531520	from third parties
531520	532880	since they solicited the things
532880	535680	that they published and they could vet those materials.
535680	538000	Distributors were businesses like bookstores,
538000	539120	newsstands, and libraries,
539120	541680	which distributed material that was printed by others.
541680	543840	And distributors were not required
543840	545600	to assess every book that they sold.
545600	546800	For example, in the 1950s,
546800	549440	the Supreme Court overturned a Los Angeles ordinance that said,
549440	552240	if you have obscene material in your bookstore,
552240	553920	you can be held criminally responsible.
553920	555200	And in that case, a bookstore owner
555200	557040	was convicted of violating the ordinance
557040	559280	by selling a novel called Sweeter Than Life,
559280	560960	which tells the story of a, quote,
561040	563200	ruthless lesbian businesswoman.
563200	564640	The Supreme Court said that the bookstore
564640	565680	couldn't be responsible
565680	567200	for reviewing every single thing
567200	569360	in the book or magazine that it sells.
569360	570800	And distributors only had liability
570800	571840	if someone notified them
571840	574160	that something they carried was illegal.
574160	576560	That's sort of the origin of the knowledge requirement.
576560	577840	And platforms were common carriers
577840	580160	like phone companies and television broadcasters.
580160	582240	Platforms weren't liable for third-party content
582240	582800	that they carried.
582800	584720	So, for example, let's say AT&T found out
584720	586240	that someone's answering machine
586240	588080	had a libelous outgoing message.
588080	590160	Was AT&T required to act
590160	592720	by canceling the owner's telephone service?
592720	593680	Well, the court said no.
593680	595200	AT&T couldn't be sued for libel
595200	596640	simply because the owner used its service
596640	598000	to say something libelous.
598000	599760	And similarly, a broadcaster wasn't liable
599760	601280	for running a political candidate
601280	603680	that falsely accused someone of being a communist.
604320	606400	But then the internet came around,
606400	608320	and the internet era posed a new challenge
608320	609440	for this case law.
609440	611120	Two of the first internet service providers,
611120	612320	CompuServe and Prodigy,
612320	614160	were sued for hosting forums
614160	616320	where users posted defamatory content.
616320	617520	Now, Prodigy billed itself
617520	619520	as a family-friendly version of the internet.
619520	621280	Did you get a computer recently?
621280	622880	Well, congratulations.
622880	624880	You can now join hundreds of thousands
624880	626320	of discovered Prodigy.
626320	627840	It moderated comments,
627840	629760	removing things it thought were bad.
629760	632000	Now, CompuServe didn't moderate anything.
632000	634640	CompuServe combines the power of your computer
634640	636400	with the convenience of your telephone.
636400	637920	And both of those companies were sued
637920	639360	for defamatory statements
639360	641920	that their users posted to the service.
641920	644240	Now, the case against CompuServe was dismissed
644240	646560	because the court considered it a distributor of content
646560	648160	rather than a publisher.
648160	651120	CompuServe could only be held liable for defamation
651120	653200	if it knew or had reason to know
653200	655600	of the defamatory nature of the content.
655600	656800	And since they didn't do anything
656800	658160	to moderate their forums,
658160	659520	the company couldn't possibly know,
659520	661280	or at least argued it couldn't possibly know,
661280	663520	about what the denizens of Rumorville
663520	665200	were posting about each other.
665200	667520	But Prodigy was found liable
667520	669600	for failing to moderate enough.
669600	670640	Someone went on a forum
670640	672800	and claimed that Jordan Belfort's investment firm,
672800	673920	Stratton Oakmont,
673920	676480	committed fraud in connection with a stock IPO.
676560	678240	The firm sued Prodigy
678240	680560	and the anonymous poster for defamation.
680560	682640	And a court held that Prodigy was liable
682640	684480	as the publisher of the content
684480	686080	created by its users
686080	688320	since it exercised editorial control
688320	690160	over the messages on its bulletin board.
690160	691520	Now, if the names Jordan Belfort
691520	693520	and Stratton Oakmont ring a bell,
693520	696000	that's because they were literally scamming people
696000	697120	out of millions of dollars
697120	699200	and have gone down as some of the biggest fraudsters
699200	700960	in all of Wall Street history.
700960	702880	The movie The Wolf of Wall Street
702880	704320	is based on the fraud
704320	705520	that they were perpetrating
705520	707120	with respect to the IPOs.
707120	708560	And it's one of the biggest ironies
708560	710320	in all of First Amendment law
710320	712160	that they won this lawsuit
712160	714080	against the people that were hosting
714080	715600	presumably accurate information
715600	717600	about how they were scamming people out of money.
717600	718560	That's part of the problem
718560	721120	when websites are liable for user content
721120	724000	is that people can file lawsuits to stifle speech.
724000	726560	That's what a slap lawsuit is all about.
726560	729200	And because lawsuits are incredibly expensive,
729200	732160	sometimes even if you scammed people out of money,
732160	733840	as long as you file a lawsuit,
733840	735760	you can stifle that kind of speech.
735760	736960	But I digress.
736960	738320	As a result of these cases,
738320	739600	internet service providers
739600	742400	basically either decided to not moderate at all
742400	745280	and leave absolutely everything up
745280	747200	or basically moderate everything
747200	749120	and not allow anything to go up.
749120	750880	And basically no one was happy
750880	751840	with this state of affairs.
751840	754480	So Congress enacted the Communications Decency Act.
754480	756720	And then as now, lawmakers claim
756720	757920	to be especially worried
757920	760080	about things like harassment and obscene material.
760080	762160	So they gave online providers immunity
762160	764160	from lawsuits if they moderated content.
764160	765440	And again, the irony here
765440	766960	is that this legislation came
766960	770320	from the sort of family values type politicians,
770320	773280	the people who always want to think about the children.
773280	777360	Oh, won't somebody please think of the children?
777360	778960	They wanted to allow websites
778960	782160	to remove violent and sexual conducts
782160	784960	so that the internet could be even cleaner.
784960	786480	The same politicians who wanted
786480	788880	and got the little parental advisory
788880	791520	explicit content warnings put on rap albums.
791600	793040	But I digress again.
793600	796560	Section 230 was intended as a way
796560	798240	for internet companies to create
798240	801840	and enforce basic standards to run their websites.
801840	804720	And when the CompuServe and Prodigy cases were decided,
804720	806560	the courts only considered whether the ISPs
806560	808000	were publishers or distributors.
808000	809680	But an internet service like a website
809680	811360	didn't fit neatly into those categories.
811360	813680	A traditional publisher has total control
813680	815280	over whether to publish content.
815280	817360	A distributor can control what it buys,
817360	819120	but it wouldn't have been practical
819120	821840	for a human to fully screen every item.
821840	824400	Modern social media companies host more material
824400	826800	than any library or bookstore on earth,
826800	829760	which makes screening all of that info daunting,
829760	831120	if not impossible.
831120	832240	And without Section 230,
832240	833680	social media companies would be subject
833680	836080	to strict liability for every message and post
836080	837360	made on their services.
837360	840080	So Congress chose to give those platforms and websites
840080	841280	immunity as an incentive
841280	843680	to get them to remove offending speech.
843680	845440	Congress also chose not to dictate
845440	847760	to those companies which speech they had to remove.
847760	850400	So that brings us back to the original question in this case.
850400	852960	How should courts read Section 230?
852960	854880	The lower courts follow the tests set forth
854880	856960	in the Ninth Circuit case called Barnes vs. Yahoo.
856960	859840	And the Barnes test hues close to the text of Section 230.
859840	861920	The law specifies that only one,
861920	863840	no interactive computer service,
863840	866480	shall be two, treated as a publisher or speaker,
866480	869200	of three, content provided by another information
869200	871360	content provider, aka users.
871360	872480	Now the plaintiffs argue their claims
872480	874000	do not treat Google as a publisher,
874000	877600	but instead assert a simple duty not to support terrorists.
877600	880480	They said that the ATA prohibits Walmart from supplying
880480	883040	fertilizer, knives, or other material to ISIS.
883040	884960	And in the same way, the ATA bars Google
884960	887360	from giving ISIS a platform to communicate.
887360	889360	The Ninth Circuit found this analogy specious.
889360	891200	The idea of a duty not to support terrorists,
891200	894000	quote, overlooks that publication itself
894000	897280	is the form of support Google allegedly provided to ISIS.
897280	899520	And publication of third party content
899520	902400	is what Section 230 gives to internet services.
902400	905280	According to lower courts, publishing encompasses,
905280	907040	quote, any activity that can be boiled
907040	908880	down to deciding whether to exclude material
908880	911200	that third parties seek to post online.
911200	913120	Google says that the CDA uses the words
913120	915840	publisher or speaker in an ordinary sense,
915840	917840	quote, based on an ordinary meaning,
917840	920800	a publisher or speaker is one that publishes or speaks.
920800	922720	Google contends that when YouTube's algorithms
922720	925600	make recommendations, this activity is protected by Section 230,
925600	927680	quote, Congress underscored that publishing
927680	930560	for purposes of Section 230 includes sorting content
930560	933840	via algorithms by defining interactive computer service
933840	937040	to include tools that pick, choose, filter, search,
937040	939600	subset, organize, or reorganize content.
939600	942400	Congress intended to provide protection for these functions
942400	944560	not for simply hosting third party content.
944560	945600	And the plaintiffs disagree.
945600	948320	Their interpretation of the Section 230C defense
948320	950480	is that it requires a narrower interpretation
950480	951440	of the word publisher.
951440	954320	The Ninth Circuit previously held that Section 230C1
954320	956160	uses publisher in its everyday sense
956160	957360	and the Second Circuit agreed.
957360	959360	But the plaintiffs contend that the word publisher
959360	963040	is used in Section 230C1 with a narrower and distinct meaning,
963120	964960	which that term has in defamation law.
964960	966560	Basically, the plaintiffs are claiming that
966560	969760	anytime YouTube recommends another video,
969760	972560	it therefore becomes the speaker of that video
972560	975520	as if YouTube had produced that video itself.
975520	977920	Now, defendants say that this interpretation doesn't make sense,
977920	980320	quote, watch the World Series of Poker on YouTube
980320	983280	and YouTube's algorithms might display Texas Hold'em tutorials.
983280	985440	That does not mean that YouTube endorses gambling
985440	989040	any more than spell check endorses a suggested substitute word.
989040	991680	Westlaw endorses higher listed cases
991680	994720	or a chat room endorses posts organized by topic.
994720	995920	As the Ninth Circuit noted,
995920	998800	YouTube applies the same algorithms to all content.
998800	1000800	And it's here that I think people often misunderstand
1000800	1003520	the nature of the internet and the nature of social media.
1004080	1005760	With the case of YouTube,
1005760	1008560	people upload millions of videos a day.
1008560	1013680	If there wasn't an algorithm to sort through this deluge of videos,
1013680	1016400	the only way to sort through them would be a fire hose
1016400	1020560	of viewing every video chronologically, which nobody wants.
1020560	1024480	It would be that or doing a pointed search to try and find content.
1024480	1026560	But then you'd never be exposed to content
1026560	1027920	that you actually do want to watch,
1027920	1030000	but didn't know that you wanted to seek it out.
1030000	1031760	And the plaintiffs have tried to differentiate
1031760	1035760	between search results and other algorithmically generated results.
1035760	1038160	But there's really no principled way to distinguish between
1038160	1041600	results that are sorted when you actively search for something
1041600	1043840	versus results that are presented to you
1043840	1045600	because of a recommendation algorithm.
1045600	1048960	And people love to hate algorithms, myself included.
1048960	1050160	But the truth is,
1050160	1052640	if there weren't algorithms to help us sort through
1052640	1055280	all of the content on social media platforms,
1055280	1057120	it would be impossible to wade through it.
1057120	1057760	And then additionally,
1057760	1059840	there is the issue of the material support
1059840	1062400	related for a claim under the Anti-Terrorism Act.
1062400	1065520	Now, the Department of Justice's brief in support of the plaintiffs
1066160	1068080	argues that algorithmic recommendations
1068080	1069840	convey the website's own implicit message
1069840	1072000	that users will find the information relevant,
1072000	1073360	and that makes the website liable
1073360	1076560	because it's acting just like ISIS itself.
1076560	1078880	Now, plaintiffs didn't claim this in their original complaint,
1078880	1081440	instead they focused on how YouTube's recommendations
1081440	1082800	amplify the ISIS speech,
1082800	1084800	making it more visible to more users.
1084800	1086480	But the US government urged the Supreme Court
1086480	1089200	to adopt a narrow reading of Section 230
1089200	1090800	that would permit a finding that Google
1090800	1092240	materially contributed to the content
1092240	1094400	by matching it to user preferences.
1094400	1096720	Again, basically, the Department of Justice,
1096720	1097760	as well as the plaintiffs,
1097760	1102480	are arguing for a standard that if any website promotes content,
1102480	1105680	uses an algorithm, or recommends content to users,
1105680	1107600	that that website then becomes liable
1107680	1111040	for all of the speech contained within that recommendation.
1111040	1113440	What happens when websites are liable?
1113440	1114720	Well, remember I mentioned
1114720	1117280	that this has actually happened before?
1117280	1118240	Well, it has.
1118240	1120720	In 2018, then President Trump signed into law
1120720	1123920	two bills making it easier to fight sex trafficking online.
1123920	1126240	That was the Fight Online Sex Trafficking Act
1126240	1129040	and the Stop Enabling Sex Traffickers Act,
1129040	1130800	otherwise known as FOSTA and SESTA.
1130800	1132560	And those two laws created an exception
1132560	1134320	to Section 230's Safe Harbor Rule
1134320	1137520	by stating that websites could be held legally responsible
1137760	1140320	if third parties posted ads for prostitution
1140320	1141360	on their platforms.
1141360	1142720	The law penalizes websites
1142720	1145680	which quote, promote or facilitate prostitution.
1145680	1148080	And while this includes sites that promote illegal sex work,
1148080	1151040	it also allows the police to investigate any site
1151040	1153440	that is knowingly assisting, facilitating,
1153440	1155040	or supporting sex trafficking.
1155040	1156880	This language can be read to include sites
1156880	1159680	with content that is legal, such as escort services,
1159680	1161520	personal ads, and pornography.
1161520	1163920	Now, critics of FOSTA and SESTA warned
1163920	1165520	that the new laws were too broad
1165600	1167600	and they would end up killing internet content
1167600	1169920	that has nothing to do with sex trafficking.
1169920	1171680	And they turned out to be correct.
1171680	1173520	If a third party posts content
1173520	1175840	that is covered by FOSTA or SESTA,
1175840	1178000	and the website fails to prevent that content
1178000	1180720	from being posted, that website can be sued.
1180720	1183760	And that was simply too much legal risk for several websites.
1183760	1186320	You should have gone for the head.
1188160	1191520	Craigslist shut down its entire personal section.
1191520	1193760	Tumblr banned all adult content
1193760	1195600	and Reddit removed several subreddits
1195600	1198480	and other websites just simply shut down entirely.
1198480	1200560	So you might ask, did any of this assist
1200560	1202880	with the prosecution of sex trafficking?
1202880	1206000	Well, in 2021, the U.S. Government Accountability Office
1206000	1209280	released a report on the first three years of FOSTA and SESTA
1209280	1211040	finding that quote, over three years,
1211040	1213520	the Department of Justice filed just one case
1213520	1215040	under its rules against promoting
1215040	1217200	or recklessly disregarding sex trafficking.
1217200	1219120	So ironically, this provided essentially
1219120	1221920	the perfect natural experiment to find out what happens
1222000	1225520	when websites are liable for the speech content of its users.
1225520	1226720	One of two things will happen.
1226720	1229120	Either the website shuts down that section
1229120	1230720	or shuts down the entire department,
1231360	1234160	or the website employs an army of moderators
1234160	1236960	to remove anything even remotely offensive.
1236960	1238560	You basically either live in a world
1238560	1242320	where a website allows everything, scams, spam,
1242320	1244800	pornography, ultraviolence,
1244800	1246800	just everything that you can possibly imagine
1246800	1249840	that you probably don't want to see in your everyday life,
1249840	1253040	or you live in a world where they employed
1253040	1255200	extremely expensive moderators
1255200	1258000	who prevent anything that might possibly be offensive.
1258000	1259280	And that of course assumes that a website
1259280	1261760	can even afford to employ those moderators.
1261760	1263520	So there are those who want to see
1263520	1265760	section 230 modified or scrapped altogether
1265760	1267600	and have argued that these online services
1267600	1269440	are acting like content developers.
1269440	1271200	Now oral argument in front of the Supreme Court
1271200	1273120	is next week, and I'm putting my money
1273120	1274480	where my mouth is on this one.
1274480	1276000	I filed a brief in the Supreme Court,
1276000	1278000	along with Dr. Mike, Mythical Entertainment,
1278080	1280720	Chubby Emu, Tim Schmoyer, and The Author's Alliance,
1280720	1282400	and a bunch of other creators.
1282400	1284160	We filed an amicus brief explaining
1284160	1285840	the potential dire consequences
1285840	1287120	of a really bad ruling on this.
1287120	1288480	So we'll see how it goes.
1288480	1289280	But in the meantime,
1289280	1290960	I'll probably just be stress eating
1290960	1292160	at the end of the internet.
1292160	1294400	Unless I use today's sponsor, Factor 75,
1294400	1296560	because Factor makes meeting your nutrition goals
1296560	1298080	easier than ever by delivering fresh,
1298080	1300000	never-frozen, dietitian-approved meals
1300000	1300880	right to your doorstep,
1300880	1302880	and the meals are completely ready to eat.
1302880	1304560	Another team of gourmet chefs creates
1304560	1306400	each meal using ingredients with integrity
1306400	1308080	to help you feel your best all day long.
1308080	1309920	And I can tell you from experience,
1309920	1311920	they really are extremely delicious.
1311920	1313920	Factor supports wholesome eating, made simple.
1313920	1315280	Their menus are updated weekly
1315280	1316960	with 34 different options.
1316960	1318160	Choose your favorite meals,
1318160	1319680	or let Factor craft the order
1319680	1321840	based on your taste preferences in meal history.
1321840	1323680	Factor takes the guesswork out of grocery shopping
1323680	1324240	and meal prep,
1324240	1326240	saving you time and energy for other things.
1326240	1327920	There are no hassle-prepared foods.
1327920	1330720	Make sure you always have something nutritious on hand
1330720	1332960	when you don't have time to think about making a meal.
1332960	1335280	And sometimes I just want a good, healthy meal
1335280	1336560	without having to cook,
1336560	1338720	or obviously shop for the ingredients.
1338720	1340400	And Factor's meals arrive preprepared
1340400	1341920	and ready to eat in just two minutes.
1341920	1343120	And I can always scale up my meals
1343120	1344800	if I need the extra energy
1344800	1346320	after a long day of lawyering.
1346320	1348720	So give Factor a try by heading to Factor75.com
1348720	1350560	and use the code LegalEagle50
1350560	1353040	to get 50% off your first Factor box.
1353040	1355200	Or just click on the link that's on screen right now
1355200	1356240	or down in the description
1356240	1357920	and use the code LegalEagle50
1357920	1360240	to get 50% off your first Factor box.
1360240	1362400	And clicking that link really helps out this channel.
1362400	1363840	And after that, click on this box over here
1363840	1364800	for more LegalEagle,
1364800	1366480	or I'll see you in court.
