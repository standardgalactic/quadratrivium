WEBVTT

00:00.000 --> 00:03.600
This case has the potential to end the internet as we know it.

00:03.600 --> 00:07.600
The internet flourishes on user-generated content. It's the backbone of the internet.

00:07.600 --> 00:12.240
And if you write or say something that is illegal, you can be held liable for what you said.

00:12.240 --> 00:15.920
But usually the websites that host your content are not liable.

00:15.920 --> 00:19.600
And when you hear about Section 230, this is usually what we're talking about.

00:19.600 --> 00:23.280
But if websites were also liable for what users say,

00:23.280 --> 00:27.760
then websites would either shut down almost everything or police things so tightly

00:27.840 --> 00:31.680
that there would be basically nothing even remotely objectionable.

00:31.680 --> 00:33.440
Because if there's one thing that websites hate,

00:33.440 --> 00:38.320
it's being on the hook for billions and billions of dollars of potential liability and attorney's fees.

00:38.320 --> 00:40.720
And this isn't just some potential hypothetical.

00:40.720 --> 00:44.720
In the past, when laws made websites liable for user content,

00:44.720 --> 00:47.120
they just shut down the content and never came back.

00:47.680 --> 00:52.240
And one case before the Supreme Court this term seeks to do exactly that,

00:52.240 --> 00:54.160
but for all of the internet.

00:54.160 --> 00:58.480
No joke, this has the potential to end the internet as we know it today.

00:59.120 --> 01:00.400
So how did we get here?

01:02.960 --> 01:04.320
Well, it started with a tragedy.

01:04.320 --> 01:07.760
Noemi Gonzalez was a design major at California State University Long Beach,

01:07.760 --> 01:10.080
who was spending a semester studying in Paris.

01:10.080 --> 01:12.640
On the evening of November 15, 2015,

01:12.640 --> 01:15.840
she was dining with friends at a cafe on the Champs-Elysees,

01:15.840 --> 01:18.400
when an ISIS terrorist with a gun opened fire.

01:18.400 --> 01:21.360
Gonzalez was killed along with 130 other people

01:21.440 --> 01:24.720
in coordinated attacks at six locations across the city.

01:24.720 --> 01:26.640
ISIS claimed responsibility for the attacks,

01:26.640 --> 01:30.240
and eventually 20 men were convicted of crimes related to the massacre.

01:30.240 --> 01:33.360
The lone surviving gunman was sentenced to life without parole.

01:33.360 --> 01:35.280
So was justice served?

01:35.280 --> 01:37.680
Well, the Gonzalez family contends that it was not,

01:37.680 --> 01:40.320
because there was another perpetrator still at large.

01:40.320 --> 01:41.120
YouTube.

01:41.120 --> 01:43.280
The family sued Google, which owns YouTube,

01:43.280 --> 01:47.040
alleging that YouTube's algorithms amplify violent videos and hateful content,

01:47.040 --> 01:50.400
despite the company's efforts to ban violent accounts and limit their reach.

01:50.400 --> 01:52.720
The Gonzalez family says that YouTube's recommendations

01:52.720 --> 01:55.280
expose people to hateful content, radicalize viewers,

01:55.280 --> 01:57.840
and encourage them to make terrorist attacks of their own.

01:57.840 --> 02:02.000
Google argued that because ISIS, not YouTube, made and uploaded those videos,

02:02.000 --> 02:04.480
YouTube was not the provider or developer of those videos,

02:04.480 --> 02:08.800
and therefore it was immune from liability under 47 USC Section 230,

02:08.800 --> 02:12.320
otherwise known as Section 230 of the Communications Decency Act.

02:12.320 --> 02:15.120
Section 230 of the CDA immunizes internet services

02:15.120 --> 02:17.680
for the content that its users upload,

02:17.680 --> 02:22.240
and often allows websites to remove content without taking on liability.

02:22.240 --> 02:24.880
But the Gonzalez plaintiffs contend that YouTube's recommendations

02:24.880 --> 02:29.040
should not be covered by Section 230 because the company is acting like a content creator

02:29.040 --> 02:30.480
rather than a publisher.

02:30.480 --> 02:33.120
The Ninth Circuit Court of Appeals held that the Gonzalez claims

02:33.120 --> 02:36.400
fell within Section 230 and Google was immune from suit.

02:36.400 --> 02:39.280
The Gonzalez parties appealed and the Supreme Court granted cert

02:39.280 --> 02:41.760
to answer the question of whether Section 230

02:41.760 --> 02:46.960
immunizes an interactive computer service from liability for recommending other party content.

02:46.960 --> 02:48.960
Now in support of their claims, plaintiffs alleged the quote

02:48.960 --> 02:51.840
two of the 12 ISIS terrorists who carried out the attacks

02:51.840 --> 02:56.560
used online social media platforms to post links to ISIS recruitment YouTube videos

02:56.560 --> 02:58.560
and quote jihadi YouTube videos.

02:59.280 --> 03:04.000
One of the men who fired at Gonzalez had appeared in an ISIS recruiting video in 2014.

03:04.560 --> 03:09.280
Now the plaintiffs argue that the defendants violated the Anti-Terrorism Act, the ATA,

03:09.280 --> 03:14.880
by allowing ISIS to post videos on YouTube under Section 2333 of the ATA,

03:14.880 --> 03:18.000
as amended by the Justice Against Sponsors of Terrorism Act.

03:18.000 --> 03:21.760
Americans who are injured by quote an act of international terrorism

03:21.760 --> 03:25.200
that is committed, planned, or authorized by a terrorist organization

03:25.200 --> 03:30.320
may sue any person who quote aides and abets by knowingly providing substantial assistance

03:30.320 --> 03:34.320
or who conspires with a person who committed such an act of international terrorism

03:34.320 --> 03:36.000
and recover trouble damages.

03:36.000 --> 03:39.600
So the legal question in the lower courts was whether a social media platform

03:39.600 --> 03:43.680
that was not used to commit a specific quote active international terrorism

03:43.680 --> 03:47.120
may still be liable for aiding and abetting under Section 2333.

03:47.120 --> 03:48.560
The plaintiffs say that the answer is yes,

03:48.560 --> 03:51.440
that Google aided and abetted an act of international terrorism

03:51.440 --> 03:54.560
conspired with the perpetrator of an act of international terrorism

03:54.560 --> 03:58.480
and provided material support to ISIS by allowing ISIS to use YouTube.

03:58.480 --> 03:59.600
And of course the defendants say no,

03:59.600 --> 04:03.040
the plaintiff's claims are barred by Section 230 of the Communications Decency Act

04:03.040 --> 04:07.600
which often immunizes interactive computer services, aka websites,

04:07.600 --> 04:09.680
even when they make targeted recommendations.

04:09.680 --> 04:11.920
The trial court and the Ninth Circuit Court of Appeals

04:11.920 --> 04:15.840
sided with Google, ruling that the claims fell within Section 230 Section C

04:16.560 --> 04:20.240
because ISIS, not YouTube, created or developed the relevant content.

04:20.240 --> 04:22.720
The court said that YouTube quote selects the particular content

04:22.720 --> 04:25.280
provided to a user based on that user's inputs.

04:25.280 --> 04:30.640
The display of recommended content results from algorithms that are merely quote tools

04:30.640 --> 04:33.600
meant to facilitate the communication and content of others

04:33.600 --> 04:36.240
and not content in and of themselves.

04:36.240 --> 04:37.520
As the lower courts noted,

04:37.520 --> 04:41.520
the recommendations are based on the user's preferences, not YouTube's.

04:41.600 --> 04:45.440
The plaintiffs argue that Section 230C does not apply to quote

04:45.440 --> 04:47.840
activities that promote or recommend content.

04:47.840 --> 04:50.560
So let's dig deeper into what all of this means.

04:50.560 --> 04:53.840
First of all, the plaintiffs are not simply arguing that platforms are liable

04:53.840 --> 04:56.080
because terrorists have used their services.

04:56.080 --> 04:58.960
They argue that the powerful algorithms that recommend content

04:58.960 --> 05:03.440
are not covered by the CDA because the recommendations are content in and of themselves.

05:03.440 --> 05:04.400
And as the Ninth Circuit said,

05:04.400 --> 05:06.960
the complaint alleges Google uses computer algorithms

05:06.960 --> 05:10.400
to match and suggest content to users based upon their viewing history.

05:10.400 --> 05:12.240
The Gonzalez plaintiffs alleged that in this way,

05:12.240 --> 05:17.840
Google has recommended ISIS videos to users and enabled users to locate other videos and accounts

05:17.840 --> 05:18.880
related to ISIS.

05:18.880 --> 05:21.840
And that by doing so, Google assists ISIS in spreading its message.

05:21.840 --> 05:23.840
So the plaintiffs claim that YouTube facilitates

05:23.840 --> 05:26.320
communications between ISIS and people who watch their videos,

05:26.320 --> 05:28.640
thereby aiding ISIS in recruiting new members.

05:28.640 --> 05:32.320
The plaintiffs acknowledge that YouTube removed ISIS videos and suspended

05:32.320 --> 05:34.560
or blocked ISIS users at various times.

05:34.560 --> 05:38.080
However, the plaintiffs claim that YouTube should have been able to stop ISIS from

05:38.080 --> 05:40.400
reestablishing accounts using new identities.

05:40.400 --> 05:43.120
And the plaintiffs alleged that Google left some of the ISIS videos up

05:43.120 --> 05:46.000
because they did not contain content violating the site's policies.

05:46.000 --> 05:48.320
At other times, Google removed the offending content,

05:48.320 --> 05:50.480
but did not suspend or ban the accounts.

05:50.480 --> 05:54.880
Now, we've talked about Section 230 of the CDA many times on this channel.

05:54.880 --> 05:59.120
Section 230 was created back in 1996 at the dawn of the Internet.

05:59.120 --> 06:00.960
It has two key provisions.

06:00.960 --> 06:03.600
Section 230c1 says, quote,

06:03.600 --> 06:06.640
No provider or user of an interactive computer service

06:06.640 --> 06:10.400
shall be treated as the publisher or speaker of any information provided by

06:10.400 --> 06:12.400
another information content provider.

06:13.040 --> 06:16.640
This sentence is often called the 26 words that created the Internet.

06:16.640 --> 06:20.480
This section stipulates that providing access to third-party content

06:20.480 --> 06:24.800
does not make an online provider the publisher or speaker of that content.

06:25.360 --> 06:29.040
Now, the second major part of the law is Section 230c2,

06:29.040 --> 06:31.200
the so-called Good Samaritan provision,

06:31.200 --> 06:32.080
which states, quote,

06:32.080 --> 06:35.360
No provider or user of an interactive computer service

06:35.360 --> 06:39.520
shall be held liable on account of any action voluntarily taken in good faith

06:39.520 --> 06:42.320
to restrict access to or availability of material

06:42.320 --> 06:46.080
that the provider or user considers to be obscene, lewd, lascivious,

06:46.080 --> 06:49.520
filthy, excessively violent, harassing, or otherwise objectionable,

06:49.520 --> 06:52.880
whether or not such material is constitutionally protected.

06:52.880 --> 06:56.720
So this provision gives online platforms broad immunity from liability

06:56.720 --> 06:59.280
if they moderate content in good faith.

06:59.280 --> 07:02.960
This provision was meant to allow websites to police itself

07:02.960 --> 07:06.320
without incurring new liability because it was an issue of knowledge.

07:06.320 --> 07:09.600
A website might not know what speech was hosted on that particular website,

07:09.600 --> 07:11.680
in which case they wouldn't be liable for it,

07:11.680 --> 07:15.520
but if they knew that illegal speech or defamatory speech

07:15.520 --> 07:17.440
or some other kind of speech was hosted there

07:17.440 --> 07:21.040
and then took steps to remove it from the website itself,

07:21.040 --> 07:24.160
then they actively had knowledge of that particular speech

07:24.160 --> 07:27.360
and thus might become liable for hosting it in the future.

07:27.440 --> 07:29.760
So websites found themselves on the horns of a dilemma

07:29.760 --> 07:31.840
until section 230 of the CDA was passed

07:31.840 --> 07:34.720
to allow them to engage in good faith moderation

07:34.720 --> 07:36.960
because there was generally a knowledge requirement

07:36.960 --> 07:39.920
to be liable for things that were hosted on your website.

07:39.920 --> 07:42.400
If you had no knowledge of what kind of speech

07:42.400 --> 07:44.320
was on your website or platform,

07:44.320 --> 07:47.280
then you generally weren't liable for it.

07:47.280 --> 07:50.640
But the argument went that if you started to moderate your website,

07:50.640 --> 07:52.880
then that was evidence that you knew what was on there

07:52.880 --> 07:55.680
and therefore you became liable for all the stuff

07:55.680 --> 07:58.000
that you were trying to remove from your website.

07:58.000 --> 08:00.640
And this applied to spam, to pornography,

08:00.640 --> 08:04.800
to pirated media, to defamation, you name it.

08:04.800 --> 08:07.360
So the CDA was enacted in 1996

08:07.360 --> 08:09.440
when the internet was still in its infancy.

08:09.440 --> 08:11.360
At the time, companies like America Online,

08:11.360 --> 08:13.200
CoffeeServe and Prodigy were the portals

08:13.200 --> 08:15.120
that allowed people to access the internet.

08:15.120 --> 08:17.280
People could share files, exchange messages,

08:17.280 --> 08:19.040
and chat with each other in real time.

08:19.040 --> 08:20.560
But that posed a dilemma.

08:20.560 --> 08:23.920
Who would be liable if a user posted something defamatory

08:23.920 --> 08:26.640
or shared something else that was illegal?

08:26.640 --> 08:28.400
Would liability go beyond the person

08:28.400 --> 08:30.240
that was responsible for the post?

08:30.240 --> 08:31.760
Or would the internet companies

08:31.760 --> 08:34.160
who hosted the content also be on the hook?

08:34.160 --> 08:35.280
And that brings us to the distinction

08:35.280 --> 08:37.520
between content publishers, distributors, and platforms,

08:37.520 --> 08:40.000
which is often completely misunderstood.

08:40.000 --> 08:41.360
In the pre-internet age,

08:41.360 --> 08:43.040
publishers, distributors, and platforms

08:43.040 --> 08:44.640
were treated differently under the law.

08:44.640 --> 08:48.240
Publishers were newspapers, magazines, and broadcast stations.

08:48.240 --> 08:50.400
They were generally liable for republishing material

08:50.400 --> 08:51.520
from third parties

08:51.520 --> 08:52.880
since they solicited the things

08:52.880 --> 08:55.680
that they published and they could vet those materials.

08:55.680 --> 08:58.000
Distributors were businesses like bookstores,

08:58.000 --> 08:59.120
newsstands, and libraries,

08:59.120 --> 09:01.680
which distributed material that was printed by others.

09:01.680 --> 09:03.840
And distributors were not required

09:03.840 --> 09:05.600
to assess every book that they sold.

09:05.600 --> 09:06.800
For example, in the 1950s,

09:06.800 --> 09:09.440
the Supreme Court overturned a Los Angeles ordinance that said,

09:09.440 --> 09:12.240
if you have obscene material in your bookstore,

09:12.240 --> 09:13.920
you can be held criminally responsible.

09:13.920 --> 09:15.200
And in that case, a bookstore owner

09:15.200 --> 09:17.040
was convicted of violating the ordinance

09:17.040 --> 09:19.280
by selling a novel called Sweeter Than Life,

09:19.280 --> 09:20.960
which tells the story of a, quote,

09:21.040 --> 09:23.200
ruthless lesbian businesswoman.

09:23.200 --> 09:24.640
The Supreme Court said that the bookstore

09:24.640 --> 09:25.680
couldn't be responsible

09:25.680 --> 09:27.200
for reviewing every single thing

09:27.200 --> 09:29.360
in the book or magazine that it sells.

09:29.360 --> 09:30.800
And distributors only had liability

09:30.800 --> 09:31.840
if someone notified them

09:31.840 --> 09:34.160
that something they carried was illegal.

09:34.160 --> 09:36.560
That's sort of the origin of the knowledge requirement.

09:36.560 --> 09:37.840
And platforms were common carriers

09:37.840 --> 09:40.160
like phone companies and television broadcasters.

09:40.160 --> 09:42.240
Platforms weren't liable for third-party content

09:42.240 --> 09:42.800
that they carried.

09:42.800 --> 09:44.720
So, for example, let's say AT&T found out

09:44.720 --> 09:46.240
that someone's answering machine

09:46.240 --> 09:48.080
had a libelous outgoing message.

09:48.080 --> 09:50.160
Was AT&T required to act

09:50.160 --> 09:52.720
by canceling the owner's telephone service?

09:52.720 --> 09:53.680
Well, the court said no.

09:53.680 --> 09:55.200
AT&T couldn't be sued for libel

09:55.200 --> 09:56.640
simply because the owner used its service

09:56.640 --> 09:58.000
to say something libelous.

09:58.000 --> 09:59.760
And similarly, a broadcaster wasn't liable

09:59.760 --> 10:01.280
for running a political candidate

10:01.280 --> 10:03.680
that falsely accused someone of being a communist.

10:04.320 --> 10:06.400
But then the internet came around,

10:06.400 --> 10:08.320
and the internet era posed a new challenge

10:08.320 --> 10:09.440
for this case law.

10:09.440 --> 10:11.120
Two of the first internet service providers,

10:11.120 --> 10:12.320
CompuServe and Prodigy,

10:12.320 --> 10:14.160
were sued for hosting forums

10:14.160 --> 10:16.320
where users posted defamatory content.

10:16.320 --> 10:17.520
Now, Prodigy billed itself

10:17.520 --> 10:19.520
as a family-friendly version of the internet.

10:19.520 --> 10:21.280
Did you get a computer recently?

10:21.280 --> 10:22.880
Well, congratulations.

10:22.880 --> 10:24.880
You can now join hundreds of thousands

10:24.880 --> 10:26.320
of discovered Prodigy.

10:26.320 --> 10:27.840
It moderated comments,

10:27.840 --> 10:29.760
removing things it thought were bad.

10:29.760 --> 10:32.000
Now, CompuServe didn't moderate anything.

10:32.000 --> 10:34.640
CompuServe combines the power of your computer

10:34.640 --> 10:36.400
with the convenience of your telephone.

10:36.400 --> 10:37.920
And both of those companies were sued

10:37.920 --> 10:39.360
for defamatory statements

10:39.360 --> 10:41.920
that their users posted to the service.

10:41.920 --> 10:44.240
Now, the case against CompuServe was dismissed

10:44.240 --> 10:46.560
because the court considered it a distributor of content

10:46.560 --> 10:48.160
rather than a publisher.

10:48.160 --> 10:51.120
CompuServe could only be held liable for defamation

10:51.120 --> 10:53.200
if it knew or had reason to know

10:53.200 --> 10:55.600
of the defamatory nature of the content.

10:55.600 --> 10:56.800
And since they didn't do anything

10:56.800 --> 10:58.160
to moderate their forums,

10:58.160 --> 10:59.520
the company couldn't possibly know,

10:59.520 --> 11:01.280
or at least argued it couldn't possibly know,

11:01.280 --> 11:03.520
about what the denizens of Rumorville

11:03.520 --> 11:05.200
were posting about each other.

11:05.200 --> 11:07.520
But Prodigy was found liable

11:07.520 --> 11:09.600
for failing to moderate enough.

11:09.600 --> 11:10.640
Someone went on a forum

11:10.640 --> 11:12.800
and claimed that Jordan Belfort's investment firm,

11:12.800 --> 11:13.920
Stratton Oakmont,

11:13.920 --> 11:16.480
committed fraud in connection with a stock IPO.

11:16.560 --> 11:18.240
The firm sued Prodigy

11:18.240 --> 11:20.560
and the anonymous poster for defamation.

11:20.560 --> 11:22.640
And a court held that Prodigy was liable

11:22.640 --> 11:24.480
as the publisher of the content

11:24.480 --> 11:26.080
created by its users

11:26.080 --> 11:28.320
since it exercised editorial control

11:28.320 --> 11:30.160
over the messages on its bulletin board.

11:30.160 --> 11:31.520
Now, if the names Jordan Belfort

11:31.520 --> 11:33.520
and Stratton Oakmont ring a bell,

11:33.520 --> 11:36.000
that's because they were literally scamming people

11:36.000 --> 11:37.120
out of millions of dollars

11:37.120 --> 11:39.200
and have gone down as some of the biggest fraudsters

11:39.200 --> 11:40.960
in all of Wall Street history.

11:40.960 --> 11:42.880
The movie The Wolf of Wall Street

11:42.880 --> 11:44.320
is based on the fraud

11:44.320 --> 11:45.520
that they were perpetrating

11:45.520 --> 11:47.120
with respect to the IPOs.

11:47.120 --> 11:48.560
And it's one of the biggest ironies

11:48.560 --> 11:50.320
in all of First Amendment law

11:50.320 --> 11:52.160
that they won this lawsuit

11:52.160 --> 11:54.080
against the people that were hosting

11:54.080 --> 11:55.600
presumably accurate information

11:55.600 --> 11:57.600
about how they were scamming people out of money.

11:57.600 --> 11:58.560
That's part of the problem

11:58.560 --> 12:01.120
when websites are liable for user content

12:01.120 --> 12:04.000
is that people can file lawsuits to stifle speech.

12:04.000 --> 12:06.560
That's what a slap lawsuit is all about.

12:06.560 --> 12:09.200
And because lawsuits are incredibly expensive,

12:09.200 --> 12:12.160
sometimes even if you scammed people out of money,

12:12.160 --> 12:13.840
as long as you file a lawsuit,

12:13.840 --> 12:15.760
you can stifle that kind of speech.

12:15.760 --> 12:16.960
But I digress.

12:16.960 --> 12:18.320
As a result of these cases,

12:18.320 --> 12:19.600
internet service providers

12:19.600 --> 12:22.400
basically either decided to not moderate at all

12:22.400 --> 12:25.280
and leave absolutely everything up

12:25.280 --> 12:27.200
or basically moderate everything

12:27.200 --> 12:29.120
and not allow anything to go up.

12:29.120 --> 12:30.880
And basically no one was happy

12:30.880 --> 12:31.840
with this state of affairs.

12:31.840 --> 12:34.480
So Congress enacted the Communications Decency Act.

12:34.480 --> 12:36.720
And then as now, lawmakers claim

12:36.720 --> 12:37.920
to be especially worried

12:37.920 --> 12:40.080
about things like harassment and obscene material.

12:40.080 --> 12:42.160
So they gave online providers immunity

12:42.160 --> 12:44.160
from lawsuits if they moderated content.

12:44.160 --> 12:45.440
And again, the irony here

12:45.440 --> 12:46.960
is that this legislation came

12:46.960 --> 12:50.320
from the sort of family values type politicians,

12:50.320 --> 12:53.280
the people who always want to think about the children.

12:53.280 --> 12:57.360
Oh, won't somebody please think of the children?

12:57.360 --> 12:58.960
They wanted to allow websites

12:58.960 --> 13:02.160
to remove violent and sexual conducts

13:02.160 --> 13:04.960
so that the internet could be even cleaner.

13:04.960 --> 13:06.480
The same politicians who wanted

13:06.480 --> 13:08.880
and got the little parental advisory

13:08.880 --> 13:11.520
explicit content warnings put on rap albums.

13:11.600 --> 13:13.040
But I digress again.

13:13.600 --> 13:16.560
Section 230 was intended as a way

13:16.560 --> 13:18.240
for internet companies to create

13:18.240 --> 13:21.840
and enforce basic standards to run their websites.

13:21.840 --> 13:24.720
And when the CompuServe and Prodigy cases were decided,

13:24.720 --> 13:26.560
the courts only considered whether the ISPs

13:26.560 --> 13:28.000
were publishers or distributors.

13:28.000 --> 13:29.680
But an internet service like a website

13:29.680 --> 13:31.360
didn't fit neatly into those categories.

13:31.360 --> 13:33.680
A traditional publisher has total control

13:33.680 --> 13:35.280
over whether to publish content.

13:35.280 --> 13:37.360
A distributor can control what it buys,

13:37.360 --> 13:39.120
but it wouldn't have been practical

13:39.120 --> 13:41.840
for a human to fully screen every item.

13:41.840 --> 13:44.400
Modern social media companies host more material

13:44.400 --> 13:46.800
than any library or bookstore on earth,

13:46.800 --> 13:49.760
which makes screening all of that info daunting,

13:49.760 --> 13:51.120
if not impossible.

13:51.120 --> 13:52.240
And without Section 230,

13:52.240 --> 13:53.680
social media companies would be subject

13:53.680 --> 13:56.080
to strict liability for every message and post

13:56.080 --> 13:57.360
made on their services.

13:57.360 --> 14:00.080
So Congress chose to give those platforms and websites

14:00.080 --> 14:01.280
immunity as an incentive

14:01.280 --> 14:03.680
to get them to remove offending speech.

14:03.680 --> 14:05.440
Congress also chose not to dictate

14:05.440 --> 14:07.760
to those companies which speech they had to remove.

14:07.760 --> 14:10.400
So that brings us back to the original question in this case.

14:10.400 --> 14:12.960
How should courts read Section 230?

14:12.960 --> 14:14.880
The lower courts follow the tests set forth

14:14.880 --> 14:16.960
in the Ninth Circuit case called Barnes vs. Yahoo.

14:16.960 --> 14:19.840
And the Barnes test hues close to the text of Section 230.

14:19.840 --> 14:21.920
The law specifies that only one,

14:21.920 --> 14:23.840
no interactive computer service,

14:23.840 --> 14:26.480
shall be two, treated as a publisher or speaker,

14:26.480 --> 14:29.200
of three, content provided by another information

14:29.200 --> 14:31.360
content provider, aka users.

14:31.360 --> 14:32.480
Now the plaintiffs argue their claims

14:32.480 --> 14:34.000
do not treat Google as a publisher,

14:34.000 --> 14:37.600
but instead assert a simple duty not to support terrorists.

14:37.600 --> 14:40.480
They said that the ATA prohibits Walmart from supplying

14:40.480 --> 14:43.040
fertilizer, knives, or other material to ISIS.

14:43.040 --> 14:44.960
And in the same way, the ATA bars Google

14:44.960 --> 14:47.360
from giving ISIS a platform to communicate.

14:47.360 --> 14:49.360
The Ninth Circuit found this analogy specious.

14:49.360 --> 14:51.200
The idea of a duty not to support terrorists,

14:51.200 --> 14:54.000
quote, overlooks that publication itself

14:54.000 --> 14:57.280
is the form of support Google allegedly provided to ISIS.

14:57.280 --> 14:59.520
And publication of third party content

14:59.520 --> 15:02.400
is what Section 230 gives to internet services.

15:02.400 --> 15:05.280
According to lower courts, publishing encompasses,

15:05.280 --> 15:07.040
quote, any activity that can be boiled

15:07.040 --> 15:08.880
down to deciding whether to exclude material

15:08.880 --> 15:11.200
that third parties seek to post online.

15:11.200 --> 15:13.120
Google says that the CDA uses the words

15:13.120 --> 15:15.840
publisher or speaker in an ordinary sense,

15:15.840 --> 15:17.840
quote, based on an ordinary meaning,

15:17.840 --> 15:20.800
a publisher or speaker is one that publishes or speaks.

15:20.800 --> 15:22.720
Google contends that when YouTube's algorithms

15:22.720 --> 15:25.600
make recommendations, this activity is protected by Section 230,

15:25.600 --> 15:27.680
quote, Congress underscored that publishing

15:27.680 --> 15:30.560
for purposes of Section 230 includes sorting content

15:30.560 --> 15:33.840
via algorithms by defining interactive computer service

15:33.840 --> 15:37.040
to include tools that pick, choose, filter, search,

15:37.040 --> 15:39.600
subset, organize, or reorganize content.

15:39.600 --> 15:42.400
Congress intended to provide protection for these functions

15:42.400 --> 15:44.560
not for simply hosting third party content.

15:44.560 --> 15:45.600
And the plaintiffs disagree.

15:45.600 --> 15:48.320
Their interpretation of the Section 230C defense

15:48.320 --> 15:50.480
is that it requires a narrower interpretation

15:50.480 --> 15:51.440
of the word publisher.

15:51.440 --> 15:54.320
The Ninth Circuit previously held that Section 230C1

15:54.320 --> 15:56.160
uses publisher in its everyday sense

15:56.160 --> 15:57.360
and the Second Circuit agreed.

15:57.360 --> 15:59.360
But the plaintiffs contend that the word publisher

15:59.360 --> 16:03.040
is used in Section 230C1 with a narrower and distinct meaning,

16:03.120 --> 16:04.960
which that term has in defamation law.

16:04.960 --> 16:06.560
Basically, the plaintiffs are claiming that

16:06.560 --> 16:09.760
anytime YouTube recommends another video,

16:09.760 --> 16:12.560
it therefore becomes the speaker of that video

16:12.560 --> 16:15.520
as if YouTube had produced that video itself.

16:15.520 --> 16:17.920
Now, defendants say that this interpretation doesn't make sense,

16:17.920 --> 16:20.320
quote, watch the World Series of Poker on YouTube

16:20.320 --> 16:23.280
and YouTube's algorithms might display Texas Hold'em tutorials.

16:23.280 --> 16:25.440
That does not mean that YouTube endorses gambling

16:25.440 --> 16:29.040
any more than spell check endorses a suggested substitute word.

16:29.040 --> 16:31.680
Westlaw endorses higher listed cases

16:31.680 --> 16:34.720
or a chat room endorses posts organized by topic.

16:34.720 --> 16:35.920
As the Ninth Circuit noted,

16:35.920 --> 16:38.800
YouTube applies the same algorithms to all content.

16:38.800 --> 16:40.800
And it's here that I think people often misunderstand

16:40.800 --> 16:43.520
the nature of the internet and the nature of social media.

16:44.080 --> 16:45.760
With the case of YouTube,

16:45.760 --> 16:48.560
people upload millions of videos a day.

16:48.560 --> 16:53.680
If there wasn't an algorithm to sort through this deluge of videos,

16:53.680 --> 16:56.400
the only way to sort through them would be a fire hose

16:56.400 --> 17:00.560
of viewing every video chronologically, which nobody wants.

17:00.560 --> 17:04.480
It would be that or doing a pointed search to try and find content.

17:04.480 --> 17:06.560
But then you'd never be exposed to content

17:06.560 --> 17:07.920
that you actually do want to watch,

17:07.920 --> 17:10.000
but didn't know that you wanted to seek it out.

17:10.000 --> 17:11.760
And the plaintiffs have tried to differentiate

17:11.760 --> 17:15.760
between search results and other algorithmically generated results.

17:15.760 --> 17:18.160
But there's really no principled way to distinguish between

17:18.160 --> 17:21.600
results that are sorted when you actively search for something

17:21.600 --> 17:23.840
versus results that are presented to you

17:23.840 --> 17:25.600
because of a recommendation algorithm.

17:25.600 --> 17:28.960
And people love to hate algorithms, myself included.

17:28.960 --> 17:30.160
But the truth is,

17:30.160 --> 17:32.640
if there weren't algorithms to help us sort through

17:32.640 --> 17:35.280
all of the content on social media platforms,

17:35.280 --> 17:37.120
it would be impossible to wade through it.

17:37.120 --> 17:37.760
And then additionally,

17:37.760 --> 17:39.840
there is the issue of the material support

17:39.840 --> 17:42.400
related for a claim under the Anti-Terrorism Act.

17:42.400 --> 17:45.520
Now, the Department of Justice's brief in support of the plaintiffs

17:46.160 --> 17:48.080
argues that algorithmic recommendations

17:48.080 --> 17:49.840
convey the website's own implicit message

17:49.840 --> 17:52.000
that users will find the information relevant,

17:52.000 --> 17:53.360
and that makes the website liable

17:53.360 --> 17:56.560
because it's acting just like ISIS itself.

17:56.560 --> 17:58.880
Now, plaintiffs didn't claim this in their original complaint,

17:58.880 --> 18:01.440
instead they focused on how YouTube's recommendations

18:01.440 --> 18:02.800
amplify the ISIS speech,

18:02.800 --> 18:04.800
making it more visible to more users.

18:04.800 --> 18:06.480
But the US government urged the Supreme Court

18:06.480 --> 18:09.200
to adopt a narrow reading of Section 230

18:09.200 --> 18:10.800
that would permit a finding that Google

18:10.800 --> 18:12.240
materially contributed to the content

18:12.240 --> 18:14.400
by matching it to user preferences.

18:14.400 --> 18:16.720
Again, basically, the Department of Justice,

18:16.720 --> 18:17.760
as well as the plaintiffs,

18:17.760 --> 18:22.480
are arguing for a standard that if any website promotes content,

18:22.480 --> 18:25.680
uses an algorithm, or recommends content to users,

18:25.680 --> 18:27.600
that that website then becomes liable

18:27.680 --> 18:31.040
for all of the speech contained within that recommendation.

18:31.040 --> 18:33.440
What happens when websites are liable?

18:33.440 --> 18:34.720
Well, remember I mentioned

18:34.720 --> 18:37.280
that this has actually happened before?

18:37.280 --> 18:38.240
Well, it has.

18:38.240 --> 18:40.720
In 2018, then President Trump signed into law

18:40.720 --> 18:43.920
two bills making it easier to fight sex trafficking online.

18:43.920 --> 18:46.240
That was the Fight Online Sex Trafficking Act

18:46.240 --> 18:49.040
and the Stop Enabling Sex Traffickers Act,

18:49.040 --> 18:50.800
otherwise known as FOSTA and SESTA.

18:50.800 --> 18:52.560
And those two laws created an exception

18:52.560 --> 18:54.320
to Section 230's Safe Harbor Rule

18:54.320 --> 18:57.520
by stating that websites could be held legally responsible

18:57.760 --> 19:00.320
if third parties posted ads for prostitution

19:00.320 --> 19:01.360
on their platforms.

19:01.360 --> 19:02.720
The law penalizes websites

19:02.720 --> 19:05.680
which quote, promote or facilitate prostitution.

19:05.680 --> 19:08.080
And while this includes sites that promote illegal sex work,

19:08.080 --> 19:11.040
it also allows the police to investigate any site

19:11.040 --> 19:13.440
that is knowingly assisting, facilitating,

19:13.440 --> 19:15.040
or supporting sex trafficking.

19:15.040 --> 19:16.880
This language can be read to include sites

19:16.880 --> 19:19.680
with content that is legal, such as escort services,

19:19.680 --> 19:21.520
personal ads, and pornography.

19:21.520 --> 19:23.920
Now, critics of FOSTA and SESTA warned

19:23.920 --> 19:25.520
that the new laws were too broad

19:25.600 --> 19:27.600
and they would end up killing internet content

19:27.600 --> 19:29.920
that has nothing to do with sex trafficking.

19:29.920 --> 19:31.680
And they turned out to be correct.

19:31.680 --> 19:33.520
If a third party posts content

19:33.520 --> 19:35.840
that is covered by FOSTA or SESTA,

19:35.840 --> 19:38.000
and the website fails to prevent that content

19:38.000 --> 19:40.720
from being posted, that website can be sued.

19:40.720 --> 19:43.760
And that was simply too much legal risk for several websites.

19:43.760 --> 19:46.320
You should have gone for the head.

19:48.160 --> 19:51.520
Craigslist shut down its entire personal section.

19:51.520 --> 19:53.760
Tumblr banned all adult content

19:53.760 --> 19:55.600
and Reddit removed several subreddits

19:55.600 --> 19:58.480
and other websites just simply shut down entirely.

19:58.480 --> 20:00.560
So you might ask, did any of this assist

20:00.560 --> 20:02.880
with the prosecution of sex trafficking?

20:02.880 --> 20:06.000
Well, in 2021, the U.S. Government Accountability Office

20:06.000 --> 20:09.280
released a report on the first three years of FOSTA and SESTA

20:09.280 --> 20:11.040
finding that quote, over three years,

20:11.040 --> 20:13.520
the Department of Justice filed just one case

20:13.520 --> 20:15.040
under its rules against promoting

20:15.040 --> 20:17.200
or recklessly disregarding sex trafficking.

20:17.200 --> 20:19.120
So ironically, this provided essentially

20:19.120 --> 20:21.920
the perfect natural experiment to find out what happens

20:22.000 --> 20:25.520
when websites are liable for the speech content of its users.

20:25.520 --> 20:26.720
One of two things will happen.

20:26.720 --> 20:29.120
Either the website shuts down that section

20:29.120 --> 20:30.720
or shuts down the entire department,

20:31.360 --> 20:34.160
or the website employs an army of moderators

20:34.160 --> 20:36.960
to remove anything even remotely offensive.

20:36.960 --> 20:38.560
You basically either live in a world

20:38.560 --> 20:42.320
where a website allows everything, scams, spam,

20:42.320 --> 20:44.800
pornography, ultraviolence,

20:44.800 --> 20:46.800
just everything that you can possibly imagine

20:46.800 --> 20:49.840
that you probably don't want to see in your everyday life,

20:49.840 --> 20:53.040
or you live in a world where they employed

20:53.040 --> 20:55.200
extremely expensive moderators

20:55.200 --> 20:58.000
who prevent anything that might possibly be offensive.

20:58.000 --> 20:59.280
And that of course assumes that a website

20:59.280 --> 21:01.760
can even afford to employ those moderators.

21:01.760 --> 21:03.520
So there are those who want to see

21:03.520 --> 21:05.760
section 230 modified or scrapped altogether

21:05.760 --> 21:07.600
and have argued that these online services

21:07.600 --> 21:09.440
are acting like content developers.

21:09.440 --> 21:11.200
Now oral argument in front of the Supreme Court

21:11.200 --> 21:13.120
is next week, and I'm putting my money

21:13.120 --> 21:14.480
where my mouth is on this one.

21:14.480 --> 21:16.000
I filed a brief in the Supreme Court,

21:16.000 --> 21:18.000
along with Dr. Mike, Mythical Entertainment,

21:18.080 --> 21:20.720
Chubby Emu, Tim Schmoyer, and The Author's Alliance,

21:20.720 --> 21:22.400
and a bunch of other creators.

21:22.400 --> 21:24.160
We filed an amicus brief explaining

21:24.160 --> 21:25.840
the potential dire consequences

21:25.840 --> 21:27.120
of a really bad ruling on this.

21:27.120 --> 21:28.480
So we'll see how it goes.

21:28.480 --> 21:29.280
But in the meantime,

21:29.280 --> 21:30.960
I'll probably just be stress eating

21:30.960 --> 21:32.160
at the end of the internet.

21:32.160 --> 21:34.400
Unless I use today's sponsor, Factor 75,

21:34.400 --> 21:36.560
because Factor makes meeting your nutrition goals

21:36.560 --> 21:38.080
easier than ever by delivering fresh,

21:38.080 --> 21:40.000
never-frozen, dietitian-approved meals

21:40.000 --> 21:40.880
right to your doorstep,

21:40.880 --> 21:42.880
and the meals are completely ready to eat.

21:42.880 --> 21:44.560
Another team of gourmet chefs creates

21:44.560 --> 21:46.400
each meal using ingredients with integrity

21:46.400 --> 21:48.080
to help you feel your best all day long.

21:48.080 --> 21:49.920
And I can tell you from experience,

21:49.920 --> 21:51.920
they really are extremely delicious.

21:51.920 --> 21:53.920
Factor supports wholesome eating, made simple.

21:53.920 --> 21:55.280
Their menus are updated weekly

21:55.280 --> 21:56.960
with 34 different options.

21:56.960 --> 21:58.160
Choose your favorite meals,

21:58.160 --> 21:59.680
or let Factor craft the order

21:59.680 --> 22:01.840
based on your taste preferences in meal history.

22:01.840 --> 22:03.680
Factor takes the guesswork out of grocery shopping

22:03.680 --> 22:04.240
and meal prep,

22:04.240 --> 22:06.240
saving you time and energy for other things.

22:06.240 --> 22:07.920
There are no hassle-prepared foods.

22:07.920 --> 22:10.720
Make sure you always have something nutritious on hand

22:10.720 --> 22:12.960
when you don't have time to think about making a meal.

22:12.960 --> 22:15.280
And sometimes I just want a good, healthy meal

22:15.280 --> 22:16.560
without having to cook,

22:16.560 --> 22:18.720
or obviously shop for the ingredients.

22:18.720 --> 22:20.400
And Factor's meals arrive preprepared

22:20.400 --> 22:21.920
and ready to eat in just two minutes.

22:21.920 --> 22:23.120
And I can always scale up my meals

22:23.120 --> 22:24.800
if I need the extra energy

22:24.800 --> 22:26.320
after a long day of lawyering.

22:26.320 --> 22:28.720
So give Factor a try by heading to Factor75.com

22:28.720 --> 22:30.560
and use the code LegalEagle50

22:30.560 --> 22:33.040
to get 50% off your first Factor box.

22:33.040 --> 22:35.200
Or just click on the link that's on screen right now

22:35.200 --> 22:36.240
or down in the description

22:36.240 --> 22:37.920
and use the code LegalEagle50

22:37.920 --> 22:40.240
to get 50% off your first Factor box.

22:40.240 --> 22:42.400
And clicking that link really helps out this channel.

22:42.400 --> 22:43.840
And after that, click on this box over here

22:43.840 --> 22:44.800
for more LegalEagle,

22:44.800 --> 22:46.480
or I'll see you in court.

