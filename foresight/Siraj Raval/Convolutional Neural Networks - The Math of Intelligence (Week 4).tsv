start	end	text
0	5840	Hello world, it's Siraj and we're going to build a convolutional network using no libraries,
5840	11520	I mean just NumPy, but no libraries, no TensorFlow, no PyTorch, none of it. We're going to look at
11520	17040	the math behind it and we're going to build it with just NumPy for matrix math in Python.
17040	21520	Okay and what it's going to be able to do, let me just start off with this demo to start off with,
21520	26720	what it's going to be able to do is recognize any character that you type in or not type in but draw
26800	32400	in with your mouse. So you could draw a six like that and then hit submit, it'll start working
33040	36640	and then it'll say it's a six and then if you don't want to use a six you could say a letter like
36640	42320	a any number or letter it's going to be able to detect slash predict. So it's going to be really
42320	48080	cool because we basically were wrapping it into a web app using the Flask web framework. So it's
48080	51680	going to be it's going to be super awesome. Okay so that's what we're going to do today
51680	56160	and this is our first neural network that we're building in this course from scratch.
56160	61040	I mean we made one in the weekly video but this is the real you know hardcore convolutional network
61040	66640	with all the layers all the functions everything. Okay so let's start off with what it's inspired by.
66640	72960	Well it's inspired by Jan Lacoon, the genius, no it's not. So Jan Lacoon is a director of AI at
72960	80480	Facebook. He's a total G, he is awesome because he was inspired by these original two guys right here
81360	88320	who published a paper in I think 68 or early 60s or 70s but the paper was on the mammalian
88320	93280	visual cortex and the idea they had was and so here's a great image of it let me make it a lot
93280	100800	bigger this has to be a lot bigger. So the idea they had was that mammals all see in a very similar
100800	106400	way and that way is hierarchical. So you have a collection of cells and these cells are neurons
106400	111520	and these cells cluster and and these clusters represent different features that are learned.
111520	117360	Okay so here in terms of neuroscience they call these clusters v1 v2 you know they have names
117360	122480	for all these clusters in the brain these clusters of neurons before it posterior all this
122480	127440	neuroscience terminology but what we need to know is that at a high level what's happening is every
127440	135680	time you see something a a series of clusters or layers of neurons are being activated whenever
135680	140960	you see something whenever you detect something to be more accurate. So if I detect a dog or a
140960	146640	you know face or whatever it's going to be a series of layers or clusters of neurons that fire
146640	151840	and each of these clusters are going to detect a set of features okay and these features are going
151840	157600	to be more abstract the the higher up the hierarchy of clusters you could think of it as a vertical
157600	162160	hierarchy or even a horizontal hierarchy what it doesn't matter but the idea is that there is a
162160	167520	hierarchy of features and at the start these features are very simple they're lines and edges
167520	173120	but then they get more abstract then they become shapes and then they become more complex shapes
173120	178240	and then eventually at the at the highest level at the highest cluster level exist the entire face
178240	185680	or the entire dog or whatever it is and this is how the mammalian visual cortex worked and so
185680	192240	what Yanlacun said and his team in 98 when they published probably the landmark paper of convolutional
192240	197520	nets which is kind of arguable I guess because Khrtchevsky's ImageNet paper was pretty good in
198080	204880	in I think 2012 but anyway Yanlacun is a G I just wanted to say that he had the idea to be inspired
204880	211520	by three things three features of the human or the mammalian visual cortex local connections
211520	216640	and that means the clusters between neurons how each neuron each set of neurons in a cluster
216640	221120	cluster are connected to each other and they represent some set of features and then the
221120	228240	idea of layering how these how there's a hierarchy of features that are learned and spatial invariance
228240	233040	what does this mean this word spatial invariance it means that whenever you or I detect something
233040	238080	whether it's let's say we're detecting a shoe right we if you see a shoe you know it's a shoe
238080	243520	right if it's a Yeezy if it's uh you know Adidas whatever it is you know it's a shoe
243520	249120	it could be shaped this way or this way it could be rotated or transformed no matter how it varies
249920	255920	we still can detect that it's a shoe we know it's a shoe so we are it is the way its position is
255920	263520	it's spatially invariant we can still detect what it is and so those three concepts were what inspired
263520	268720	the birth of convolutional neural networks programmatic neural networks designed to mimic
268720	274960	the mammalian visual cortex how cool is that that's so cool so how does this thing work
274960	280480	let's look at how this works so we have a set of layers okay and we'll talk about what these layers
280480	288480	mean right what is layer a layer in each case is a series it's a series of operations that we're
289040	293360	okay so let's let's talk about this right so we have some input image so let's see
294080	298480	this is the orange that's the image and you'll notice by the way that this image this is a
298480	302960	convolutional network by the way this is what we're building okay you'll notice that this image
302960	307760	right here or this image of the convolutional network isn't what you normally look at when
307760	311280	you think of neural network right you always see that image of the circles and everything's
311280	317520	connected so why is it different for convolutional networks because every layer in a convolutional
317520	324080	network isn't connected to every so every neuron in every layer isn't connected to every other neuron
324080	330480	in the next layer why because that would be too computationally expensive i'll go over that in
330480	335360	a second but the idea is that if you if you see here there is a part of the image that is connected
335360	340880	it's this little square of that orange and that is called the receptive field okay i'm going to go
340880	343840	over all this it's going to make more and more sense you're going to be more confused it's going
344160	348800	it's going to make more and more sense as as i go further and further in depth here so so so stay
348800	354880	with me here so we have a receptive field okay that is some part of the image that we are focused on
354880	360320	we are by focused i mean that is the part of the image that we apply a convolution operation to
360960	366320	okay and we take that receptive field and we slide it across the image okay you're going to see
366320	370720	exactly what i'm talking about in a second i'm just going to go over at a high level we slide
370720	376480	over the image we are applying a dot product between our weight matrix at a layer and every
376480	382160	part of that image iteratively okay and so that the reason that they look different the convolutional
382160	388000	networks look different is two reasons really the first reason is that not every neuron in each
388000	392720	layer is connected to every other neuron in the next layer it's only a part of that because it
392720	399040	would be a to borrow from discrete math a combinatorial explosion to connect every single pixel
399040	405040	value in an image to every single pixel value in the next layer of features right it would be
405040	410880	just a huge amount so what we do instead is we take a part of that image and we iteratively slide
410880	415360	over it okay so at a high level you understand the sliding part right think of it as a flashlight
415360	420560	okay think of it think of the uh the filter at each layer that shines over the receptive field
420560	426080	that box as a flashlight and you're shining over the image and you're and you're applying dot products
426080	430800	to all of these numbers okay just like that okay i'm going to keep going into this that was just
430800	434080	the highest level you're not supposed to understand it all yet okay that was that was very high level
434080	438800	we're still going deeper we're going deep we're going deep okay so check out this beautiful image
438800	442880	right here isn't it beautiful it's very beautiful also you're beautiful for watching this so thank
442880	449280	you for watching this okay so i love my fans so much seriously you guys are amazing seriously
449280	455280	you guys are the reason i do this every week okay so i by the way i want to say one more thing
455280	461120	to go on a tangent the people who subscribe to my channel no one thought they existed we are
461120	467680	programmers who are smart and we are also cool no one thought these people existed but we exist
467680	473760	okay we are smart and we are cool so you are amazing okay anyway back to this what this is
473760	477120	is another way of looking at the network right we're just looking at different ways we're looking
477120	483120	at different ways so we can build a spatially invariant image in our head of what a convolutional
483120	488800	network is like right no matter what that image is we're going to learn to recognize a convolutional
488800	493440	network when we see one i'm just trying to you know meta applying this logic to what we're learning
493440	498640	so what happens is that each layer we are applying a series of dot products between the
498640	505040	weight matrices and the input matrix okay and so what happens is let's look at a third image okay
505040	510960	so this is a third image what happens is we perform a series of operations okay at each layer
511040	516000	and so we could think of of different we could think of splitting up a convolutional network
516000	521760	into two separate categories the first category is feature learning and that's what's happening at the
521760	528000	at the at the head of the the head to the middle to almost the tail end of the network and at the
528000	533200	very tail end is classification so there's two parts there's the feature learning part and then
533200	538240	there's the classification part and so for the feature learning part what happens are three
538240	544480	operations over and over and over again and we can call them convolutional blocks let's just call
544480	550080	them convolutional blocks i'm coining the term so what happens is we first apply convolution
550080	557040	then we apply relu or any kind of activation and then we apply pooling and we repeat that that's
557040	563360	that's a single block three operations in a single convolutional block okay so convolution relu pooling
563360	569360	repeat convolution relu pooling repeat convolution relu pooling okay and usually you know you have
569360	574560	three blocks at least unless you're building inception by google then you have 15 15 of these
575440	579520	but you you know you have these convolutional blocks and at the very end then you flatten
579520	585680	that output into a smaller dimensional vector and then you apply a fully connected layer to it so
585680	590880	that means that you then connect all the neurons in one layer to the next one just because we want to
590880	596160	then harness all of the learnings that we've learned so far that's why we fully connect at the end
596160	602080	and then we take those learnings and we squash it into a set of probability values with our last
602080	607600	softmax function and then we take the max value of those probabilities and each of these probabilities
607600	613440	is a probability for a for specific class that it could be and we take the max value let's say 72
613440	619440	percent as and we'll say okay well 72 percent for banana and now we know it's a banana okay so
620160	624480	hopefully you get some of it but it's very confusing still i know we're about to go even
624480	629760	deeper okay so get ready for this i haven't even started yet so i haven't even started yet okay so
629760	637040	anyway step one so for step one we are preparing a data set of images right so when you think of an
637040	642240	image you think of a matrix hopefully a matrix of pixel values if you don't think of it that way
642240	646960	think of it think of it that way now you're thinking of an image as a matrix of pixel values
646960	650640	rowed by columns and each of these um each of these uh
653040	660080	points in the matrix represent a pixel right between 0 and 255 but it's actually better
660080	664560	in terms of convolutional networks to think of an an image as a three-dimensional matrix
664560	669600	and you're like what no what it's no so it's three dimensions so the first dimension is the length
669600	674320	of the image the second dimension is the width and the third dimension is the depth so wait what
674320	680080	is the depth because the depth represents the channels and there are three channels for images
680080	684320	red green and blue unless you're talking about gray scale then there's black then there's you
684320	688480	know black and white but we're talking about color images okay so there are three channels and you
688480	694560	have these dimensions for each of the channels so these values in each of these um in each of these
694560	702720	2d matrices for and there are three of them represent the the amount of redness or the amount of
702800	708560	greenness or the amount of blueness between 0 and 255 so in terms of convolutional nets we think of
708560	713600	images as three-dimensional pixels okay so i wanted to say that part okay so that's that's
713600	719200	that's what we think of our image as our input image and it has an associated label right we're
719200	723360	talking about supervised learning learning the mapping between the input data and the output
723360	728880	label dog image dog label learn the mapping given a new dog image what is a label well you just
728880	734320	learned it right so and we learn it through back propagation back propagate to update
734320	739280	weights remember the rhyme you know what it is hey i haven't wrapped yet in the series but i will
739280	745360	don't worry it's coming anyway so every image is a matrix of pixel values we know this we know this
745360	753360	between 0 and 255 and we can use several training data sets there are two really popular ones there's
753440	758400	seafar and there's cocoa and there's a bunch of other ones as well but basically these are
758400	764000	huge data sets and you can find smaller versions of them and each of these images they're dogs
764000	769200	they're cars they're airplanes they're people whatever they all have labels for them handmade
769200	774960	labels by humans which is great for us okay so that's that's it that's step one step one is to
774960	780160	get your training data which is your images which are your images step two is to perform convolution
780160	785360	now you might be asking what is convolution well i'm here to tell you that convolution is an
785360	790800	operation that is dope as f here's why it's dope because it's not just used in computer science
790800	795680	and machine learning it's used in almost every field of engineering think of convolution as two
795680	800400	paint buckets you have one paint bucket which is red another one which is blue and what you do
800400	804720	is just smear it all over yourself no you don't do that what you do is you take these two paint
804720	809360	buckets and you combine them into one paint bucket and that new paint bucket is going to be a new
809360	816160	color whatever that combination of colors is that's convolution convolution is taking two separate
816160	822800	types of data or two matrices and then apply and then it's an operation that combines them so you
822800	827680	could think of convolution as synonymous to combination okay and why do we apply why do we
827680	834160	say that for convolutional networks because what we're doing is we are combining the values for
834160	839840	each of these layers with the input matrix so think of the input as that matrix right and so
839840	844640	well it's a three-dimensional it's a it's a it's a it's a 3d tensor right but we're applying it to
844640	848800	each of these dimensions right so three of them so just think of it as a matrix for right now
848800	856800	and so what we do is we take this so at each layer at each layer there is a weight so by the way
856800	861920	okay so there's a lot of interchangeable terms in machine learning and it's easy to get confused
861920	868080	here but i want to set the record straight for a second weight is the same as feature matrix is
868080	875600	the same as feature map is the same as a filter in this case in for convolutional networks so you
875600	880480	see these or even kernel kernel is a different one there's actually five interchangeable terms so i
880480	886560	can see how it can be confusing but if you get the basic idea of you have an input matrix which is
886560	892880	your image and then you have a set of matrices which are your features that are learned you know
892880	901360	edges shapes more abstract shapes that's it that's that's all it is matrix dot product matrices that
901360	905760	are being multiplied by matrices all the way through that's that's all it is matrices that are
905760	909680	being multiplied by matrices all the way through just a chain of them okay so what happens for
909680	915360	convolution is we take a matrix and we multiply it by all the values in this matrix at a certain
915360	919520	region right and so this is what i was talking about when i was saying we have a receptive field
919520	924320	because we don't just multiply it all at once we multiply by a little part of it okay the receptive
924320	929120	field and we slide it and we can define what that interval is that sliding window i know i'm talking
929120	933040	a lot without coding the coding is coming believe me the coding is coming but just check this out
933040	939920	for a second we got to learn this uh conceptually first so we are multiplying the the feature matrix
939920	944000	by that input image just for every row and every column we're just multiplying multiply
944000	949440	multiply and what happens is we have this new matrix that results the output and that output
949440	954880	is considered the convolved feature okay and so what we do is we use that output as the input
954880	959360	for the to the next layer and we repeat the process over and over and over again obviously
959360	964480	there's two more parts here there's the activation the relu and then there's the pooling which i'll
964480	969040	talk about as well but that's the basic idea between convolution and that's why we call it
969120	975760	convolution because we are combining or convolving the weight matrix or filter or kernel whatever
975760	980640	you want to call it feature map by that input we're combining it using the out and using that
980640	986800	output as the input for the next layer after activating it and and pooling it okay so that's
986800	993680	convolution and also um right so we apply it to all of those dimensions for that for that input
993680	999040	matrix okay and that gives us our activation map or feature map or filter right so many different
999040	1005120	interchangeable terms here so anyway so it's computed using the dot product so you might be
1005120	1010720	thinking well okay i see how there is a dot product i see how there's matrix multiplication
1010720	1014960	but how does that really tell us what features there are i still you're still not making the
1014960	1022240	connection probably why understandably why this these series of matrix operations help us detect
1022240	1027600	features well here's what happens what happens is this and here's the great thing about matrices
1028320	1037360	and having several of them when we learn a filter or a weight whatever you want to call it well this
1037360	1040960	you know what moving forward let's just call it filter okay i'm just saying let's just call it
1040960	1045280	filter moving forward for the rest of this video when we learn a filter over time by
1045280	1049600	training it on mouse mouth pictures for example a filter is going to look like this at let's say
1049680	1053440	at the first layer we we learn a filter for detecting a curve that looks like this right
1053440	1056960	this curve right here and so what's what this filter is going to look like for detecting
1056960	1061840	the specific type of curve is it's going to be a very sparse filter that means there's a lot of
1061840	1067920	zeros except so there's all these zeros except for right here you see this 30 30 30 30 and notice
1067920	1074160	that these values represent the shape they go in this direction of a shape and so what happens is
1074160	1080720	when we take this filter and perform the dot product you know we convolve it with whatever part
1080720	1088560	of the mouse if it's over a part of the mouse that matches that feature exactly then we when we
1088560	1093760	multiply all of those uh when we when we perform the dot product between all those values and sum
1093760	1100000	them up that's the convolution operation right there okay just it's going to be a big number
1100000	1104320	okay and so then we know that we've detected a feature because we've we've multiplied it sum it
1104320	1110160	up and there's a large number and if there's not if we multiply if let's let's say we have that
1110160	1115040	receptive field over a different part of the mouse and that that curve doesn't exist then it's going
1115040	1120640	to be zero right because if you look between these 30 30 30 values and that the equivalent
1121360	1127360	locations on this pixel representation of the mouse image these are zeros and so what happens
1127360	1134000	when you multiply zero by 30 you get zero right so that's why it's important to make the rest of the
1134000	1140320	so the data that's irrelevant we want it to be zero right in the in the feature maps or in the
1140320	1144960	filters that we learn in the filters that we learn we want the irrelevant parts to be zero
1144960	1154240	and in the images okay and and in the input images so I so I could actually go even more into
1154240	1158800	convolution but it's not really necessary but it's it is super dope it is super dope though
1158800	1163200	this is a great blog post by the way I definitely encourage you to read this blog post it's linked
1163200	1168720	in the notebook but this dude Tim Tim he goes into these this idea of convolution and he talks about
1168720	1177920	how it's applied to all these different engineering fields and he goes into the formula the formula
1177920	1182880	for the convolutional theorem is what he called is what it's called okay and I'm just going to go
1182880	1189200	over this at a high level but the convolution theorem is this general theorem for discrete well
1189200	1194240	there's a discrete version and a continuous version right discrete is if there's you know one or zero
1194240	1199600	black or white you know definite classes that something could be whereas continuous is if it
1199600	1205520	could be an infinite amount of values between zero and one point five point two five you know
1205520	1210160	point seven infinity in that direction but here's the here's the formula for it and so
1210880	1214720	let me make it bigger just really quickly and then we'll get back to it because it's
1214720	1222000	it's really cool but the convolution theorem states that we and so in it's a general theorem
1222000	1229360	that can be applied to any any any set of problems but in terms of what's relevant to us is is the
1229360	1236320	convolutional theorem applied to matrix operations so what we can do is we can say what it what it
1236320	1241440	says is it's the input times the kernel and it's the dot product it's a dot product between
1241440	1246560	two different matrices and we perform that for every value in all of those matrices and we do that
1246560	1250480	for all of the values that we have and we sum them up together and that's what the sigma term
1250480	1255280	represents and we and we actually express that right here right this operation right here this
1255280	1259680	multiplication and summation it's the same thing but it's a more complex way of looking at it or
1259680	1266640	more mathematically accurate way and also the fast Fourier transform is is brought up by this and
1267840	1273040	the fast Fourier transform takes some spatial data and it converts it into Fourier space which is
1273040	1278880	like a waveform and you see this a lot in your day-to-day life whenever you're looking at some
1278880	1283120	sound you know you're listening to some sound and you look at your mp3 player and you see the waves
1283120	1287360	that's a that's a Fourier transform happening but i won't go into that that's that's for sound and
1287360	1291840	audio but anyway it's a really cool blog post definitely check it out okay so back to this
1293920	1298560	so we talked about convolution now we're going to talk about pooling right so what is pooling so
1299280	1303440	whenever we apply convolution to some image what's going to happen at every layer
1303440	1309360	is we're going to get a series of feature of so each of the weights are going to consist of
1309360	1316480	multiple images and each of these images are going to be at every layer there's going to be more
1316480	1322160	and smaller images so the first few layers are going to be these huge images right and then at the
1322160	1324880	next few layers are going to be more of those but they're going to be smaller and it's just going to
1324880	1329600	get just like that okay and at the end we squash it with some fully connected layer so we get some
1329600	1336560	probability values with a softmax but anyway what pooling does is it is it dense is it makes
1336560	1344000	the matrix the matrices that we learn more dense here's what i mean so if you if you perform convolution
1344080	1351680	between an input and a feature matrix or a weight matrix or filter it's going to result in a matrix
1351680	1356480	right but this matrix is going to be pretty big it's going to be a pretty big matrix what we can do
1356480	1362480	is we can take the most important parts of that matrix and pass that on and what that's going to
1362480	1368240	do is it's going to reduce the computational complexity of our model okay so that's what pooling
1368240	1373440	is all about it's a pooling set so there's different types of pooling max pooling is the most used
1373440	1380160	type of pooling by the way so basically multiply so what happens is we we strive we have some we
1380160	1385520	define some window size and then some stride size so how what are the intervals that we look at
1385520	1391600	and we say okay so for each of these windows let's take the max value so for so for uh this one right
1391600	1396720	here four six zero eight the max value would be eight and so for one three twelve nine it'd be
1396720	1400720	twelve right so we just take the biggest number it's really simple actually we just take the biggest
1400720	1405120	number and we just do that for all of them and so that that's what pooling is all about and so
1405120	1411680	it's going to just give us that the most relevant parts of the image and if you if you think of these
1411680	1418800	these very these values in in the in the matrix as pixel intensities by taking the maximum intense
1418800	1423520	the the pixel with the most intensity or the the highest intensity we're getting that feature that
1423520	1428960	is the most relevant if you see what I'm saying it's a least opaque feature to use a term from
1429280	1437680	image um math anyway so we so we talked about pooling and we talked about uh we talked about
1438400	1440160	activation and so now
1442880	1446800	no we talked about convolution and we talked about pooling and so now the third part
1446800	1452960	is normalization or activation so remember how I said how it would be it's so important that we
1452960	1458480	have these values that are not related to our image be zero we want it to be zero so the result
1458480	1464960	is zero if the if the feature is not detected well the way we do that is using relu and so relu
1464960	1471120	stands for rectified linear unit it's an activation function it's an activation function okay we use
1471120	1476960	activation functions throughout neural networks and we use them because it is you can also call
1476960	1483920	them non-linearities because they they make our model able to learn non-linear functions not just
1483920	1488880	linear functions but non-linear functions so any kind of function right the universal function
1488880	1494400	approximation theorem we talked about that activation functions help make this happen and
1494400	1499760	so relu is a is a special kind of activation function that turns all negative numbers into
1500720	1504960	zero so that's why it's going to make the math easier it won't make the math break
1504960	1509760	for our convolutional network so we'll apply a relu so basically what we do is for every single pixel
1509760	1515120	value in the in the input to this relu activation function we turn it if it's a negative we just
1515120	1519200	say make it zero it's super simple it'll be one line of code you'll see exactly what i'm talking about
1520400	1524880	okay so that's that's those are our blocks so that's how our convolutional blocks work
1525760	1530320	however there is another step that I didn't talk about that is a nice to have and state of the
1530320	1535920	our convolutional networks always use it and that's called dropout so Jeffrey Hinton the guy who invented
1536480	1542800	neural networks invented a feature invented a technique called dropout and what dropout is
1542800	1549200	is a good analogy is old people or not old people but people who are stuck in their ways let me let
1549200	1555520	me okay so what dropout does is it turns neurons on and off randomly what do I mean by that that I
1555520	1562080	mean the the matrices for each weight value is converted to zero randomly at some layer of the
1562080	1567600	network and so what happens is by doing this our network is forced to learn new representations
1567600	1572880	for the data new pathways that that data has to flow through it can't always flow through this neuron
1572880	1577680	and the reason we use it is to prevent overfitting right we want to prevent overfitting we want to
1577680	1582560	prevent being too fit to the data think of it as you know the older you get the more set in your
1582560	1588240	ways of thinking your you are right and so it's harder to think of new ways of of of thinking
1588240	1593360	right because you're so set in some ways so a way to prevent that is to have a novel crazy
1593360	1598160	experience whether it's skydiving or ticking psychedelics or whatever it is and what that
1598160	1603280	does is it creates new pathways so you're not so you're kind of forced your brain is forced to make
1603280	1610480	new pathways and this increases your generalization ability and you're not so overfit that's a very
1610480	1616240	rough abstract analogy but basically dropout is not as complex as that sounds dropout can be
1616240	1621040	done in three lines of code so definitely check out this blog post as well that I've linked
1621040	1627600	but what it does is it just randomly picks some neurons in a layer to set to zero right so it's
1627600	1632240	just it's just three lines okay and you can look at it in this notebook right so that's and then our
1632240	1637760	last step is probability conversion so we've got this huge set of values right all these little
1637760	1642960	small images that are represented by this huge output matrix and we want to take this huge set
1642960	1647920	of values and make some sense out of it we want to make probabilities out of it and the way we do
1647920	1653440	that is using a soft max at the end a soft max is a type of function and it looks like this this
1653440	1658160	this is a soft max function right here but what we do is we plug these values into the soft max
1658160	1663600	function and it's going to output a set of probability values discrete probability values
1663600	1668240	for each of the classes that we're trying to predict okay and then what we'll do is given
1668240	1674560	all those probability values will pick the biggest one using arg max the arg max function in numpy
1674560	1680160	and that's going to give us the most likely class okay those are the seven steps of a
1680160	1686880	full forward pass through a convolutional network looks like that and so now you might be wondering
1686880	1693040	well okay so how do we train this thing well using gradient descent right and when applied to neural
1693040	1700320	networks gradient gradient descent is called back propagation exactly i hope you got that right
1700320	1705920	anyway okay so how do we learn these magic numbers right how do we learn what these weight values
1705920	1711600	should be what the feature should be back propagation is how we do it right and so we've talked quite a
1711600	1716480	bit about back propagation and gradient descent but i'll do a little i'll go over it again um
1717440	1722160	but the idea is that we have some error that we're computing right this is super this is
1722160	1727440	supervised learning we have a we have a human label right for some data so we put in a dog image
1727440	1732160	or a bicycle image to look at the summit to to relate to this image here we put in a bicycle
1732160	1737040	image and the bike label we pass it through the each layer dot product dot product dot you know
1737040	1742960	dot product activation function pool dot product repeat repeat soft max or squash into probability
1742960	1747680	values pick the biggest one and we have some prediction value and what we do is we compare
1747680	1752480	the prediction value to the out the actual value and we get an error and we take our error
1752480	1756720	and we compute the partial derivative of the error with respect to each weight value
1756720	1763280	going backwards in the network okay like this okay and so for regression we use the mean squared
1763280	1768960	error if we're using linear regression regression and for classification we use the softmax function
1768960	1773440	so remember how in the first neural network we built and in their linear regression example
1773440	1779920	we used a uh we use mean squared error to compute the error and now we're using the softmax
1779920	1783760	so we'll take the so we'll take the partial derivative of the error with respect to our
1783760	1788480	weights and then that's going to give us the gradient value that we then update each of those
1788480	1794000	weight values recursively going backward in the network and that's how it learns what this features
1794000	1799440	what the ideal feature the weight matrix value should be but what about the other
1800560	1804560	what about the other magic numbers what about the number of neurons and the number of features
1804560	1809200	and the size of those features and the pooling window size and the window stride well those that
1809200	1814560	is an active area of research there are best practices for values that you should use for those
1814560	1820560	for those hyper parameters right the tuning knobs of our network and andrew karpathy has some great
1820560	1824320	material on this and he's probably the leading source for convolutional networks right now in
1824320	1831520	terms of um written contents and uh yeah i mean this is an active area of research finding out
1831520	1835360	what the ideal hyper parameters for our neural network should be and we're still learning what
1835360	1840560	it should be what what what what how we can get them rather than just guessing and checking which
1840560	1846480	is what we do right now which is kind of like you know not it's not as optimal right so anyway
1847280	1850800	last two things and then we're gonna get started with the code when is a good time to use this
1850800	1854880	well we know to classify images we've talked about that but you can also use them to generate
1854880	1859520	images and that's for later on that's a little more advanced but to give you a little spoiler
1859520	1863760	a little teaser in fact this is in my intro to deep learning playlist you take a convolutional
1863760	1867680	network you flip it and then you call it a deconvolutional network and then you can take
1867680	1875040	some text and create an image out of text how crazy is that okay there's also generative models
1875040	1878800	where you have two networks fighting each other and you can generate new images a whole bunch
1878800	1884320	of really cool crazy stuff you can do but anyway when should you use a convolutional network
1884320	1890640	anytime you have spatial 2d or 3d data what do i mean well obviously images are spatial the word
1890640	1897760	spatial implies that the space the positioning of the data matters so sound you can apply to sound
1897760	1904080	images or text where the the the position of the text matters right because we have a flashlight
1904160	1910000	our filter and we're convolving over an image right but if you have some data like say customer
1910000	1914400	data where if you were to just flip the rows and columns it doesn't matter what order they're in
1914400	1919840	they're still you know they're still features so a good rule of thumb is if you swap out the rows
1919840	1925600	and columns of your data set and it's just as useful like the space doesn't matter then you
1925600	1930720	don't want to use a cnn else you do okay and a great and last thing the great example of using
1930720	1935760	cnn's are for robot learning you can use a cnn for object detection and you can use a cnn for
1935760	1940560	grasp learning and combine the two and then you can get a robot that cooks which is really cool
1940560	1945680	i've got a great tensorflow example and a great adversarial network example okay let's go into
1945680	1951760	the code now and so what i'm going to do is i'm going to look at the class for the convolutional
1951760	1956880	network in numpy as well as the prediction class there's two classes here okay so these are our
1956880	1963280	three inputs pickle is for saving and loading our serialized model what do i mean pickle is
1963280	1968880	python's way of having a platform or language agnostic way of saving data so you can load it
1968880	1974160	up later tensorflow uses it a bunch of other libraries use it as well numpy is for matrix math
1974160	1978400	and we've got our own little custom class for pre-processing the data because we don't care
1978400	1984480	about that part we care about the machine learning part okay so let's talk about our light ocr or
1984560	1989360	object optical character recognition class in our initialized function we're going to load the
1989360	1993840	weights from the pickle file and then store and then store all the labels that we've loaded
1993840	1999040	we'll define how many rows and columns in an image load up our convolutional network using the light
1999040	2004240	cnn function with our saved weights so assuming we've already trained our network we load it with
2004240	2009840	the saved weights from the pickle file and then we define the number of pooling layers okay so once
2009840	2015200	we have that then we can use this predict function so given some new image we'll reshape the image so
2015200	2020480	it's in the correct size to perform the dot product between that image and the first layer of our
2020480	2026880	convolutional network and we'll we'll we'll put it we'll feed it into our network and it's going to
2026880	2031600	output a prediction probability for a class and we'll return it okay super high level we haven't
2031600	2037280	even coded our cnn that's that's our first class that's our prediction class now now we're going
2037280	2041200	to look at the convolutional network class and what i'm going to do is i'm going to i'm going to
2041200	2048240	go over the code and i'm going to code some parts of it so now we'll look at our convolutional
2048240	2054160	network class okay so in our initialized function we'll initialize two lists one to store the layers
2054160	2059520	that we've learned the the weights of each layer and then the size of the pooling area for max pooling
2059520	2065360	okay we'll load up our weights from our pickle file just like this and then we have our predict
2065360	2069520	function now in our predict function that's where the real magic is happening right let's
2069520	2074080	code what this looks like so given some input x we're going to feed it through all of these
2074640	2082880	layers right so what happens is we will say okay so the first layer is going to be a convolutional
2082880	2087280	layer okay and we're going to define what all of these functions look like look like but the first
2087280	2091680	layer is going to be that convolutional layer we'll feed in that first image and we'll say okay
2091680	2096640	well this is the first layer so it's a zeroth layer we'll say border mode equals full and i'll
2096640	2102000	talk about that part later on but that's it for that and so what happens is x equals this layer
2102000	2107760	okay so that's our first layer and then our next layer is going to be relu so we'll say okay now
2107760	2114400	let's apply an activation to the output of the previous layer okay and then we'll set it equal
2114400	2120080	to that okay so we'll set the output from the previous layer equal to the input of this layer
2120080	2125840	and then we keep going we say okay so we've got another uh cnn we have another convolutional layer
2125840	2131440	and we do the same thing here we say okay take the in output from the previous layer we'll define
2131440	2136080	what the uh name of this layer is as well as the border mode which i'll talk about the very end of
2136080	2143600	this we have a border mode which is valid and then we say okay well we'll set the output of that
2143600	2148800	equal to the input of this and just keep repeating now it's time for us to apply a
2149600	2154720	another non-linearity so we'll just go ahead and apply our non-linearity again remember these are
2154720	2162000	convolutional blocks oh and we also want to pool so also the the order with which you can do this
2162000	2166960	varies right you can do this in different ways and yeah so i'm doing it a certain way right now
2166960	2171840	you know we could change it around it would change our result but the order map the ordering within
2171840	2178000	the block can be can be different okay so right so we're going to pool it we're going to pick the
2178000	2185840	the most relevant features from from that uh from that output and then we're going to perform drop
2185840	2191680	out to prevent overfitting and we're going to say there's going to be a 0.25 chance that a neuron
2191680	2196960	is going to be deactivated that will turn it off set it to zero and that's our dropout probability
2196960	2204880	value and then now we're getting into our our the second category of our network not the feature
2204880	2208640	learning part but the classification part and we'll say okay so let's flatten this layer let's
2208640	2216000	reduce the dimensionality of all of that that data so it's something that we can then learn from
2216000	2222160	and we'll say well let's let's set it equal to seven and then we'll say once again turn that output
2222160	2230240	into our uh inputs here okay and so then we have another dense layer we just we just keep going
2230240	2234640	with or our first dense layer and that means we are going to it's a fully connected layer so we're
2234640	2239760	combining everything that we've learned because we're getting really close to squashing these values
2239760	2244800	into a set of probability values so we want to take all of our learnings and combine them
2244800	2250000	with a fully connected layer and so we'll combine them with a fully connected layer
2250720	2259760	and then uh we'll squash it now with our sigmoid or no not our sigmoid our softmax function okay
2259760	2264480	and then that's going to give us our output probability and then we're going to say well
2264480	2269520	which of the probabilities do we want we want the max one right we want the max probability
2269520	2275440	and we'll classify it just like that and return that value okay that's the highest level and so if
2275440	2279840	you were using keras or one of these high level libraries this is all your code would look like
2279840	2284000	but what we're going to do is we're going to look at these functions as well okay so let's look at
2284000	2290800	these functions so we'll start off with the convolutional layer function and have your
2290800	2295120	notebook open with me as well so you could go over this the the link is in the description if you
2295120	2300400	don't know now you know if you don't know now you know so for our convolutional layer given some
2300400	2305120	input image we're going to say well we'll store our feature maps and the bias value in these two
2305120	2310480	variables features and bias will define how big our filter or patch is going to be how many features
2310480	2316720	do we want how big is our image how many channels rgb so three and then how many images do we have
2316720	2322720	so given those values we'll define a border mode so a border mode so is so when you apply
2322720	2327760	fold to border mode in this case it means that the filter has to go outside the bounds of the input
2327760	2333120	by filter size divided by two the area outside of the input is normally padded with zeros and
2333120	2337680	the border mode valid is when you get an output that is smaller than the input because the convolution
2337680	2343680	is only computed where the input and the filter fully overlap okay and they'll give us different
2344720	2350400	they'll give us different classification results accuracy results and it's good to test both
2350400	2355680	options so what we'll do is we'll initialize our feature matrix for this layer as conv as convolve
2355680	2360000	zeros it's going to be a bunch of zeros and then we'll say okay so for every image that we have
2360000	2365120	for every feature in that image let's initialize a convolved image as empty and then for each
2365120	2369840	channel so we're doing this for each of the three channels let's extract a feature from our feature
2369840	2375760	map define a channel specific part of our image and then perform convolution on our image using
2375760	2381280	that given feature filter so notice this convolved 2d function it's where the actual convolution
2381280	2387520	operation is happening this is more of a wrapper for that actual mathematical operation so once
2387520	2392160	we have that we'll add a bias and a bias acts as our anchor for our network it's kind of like the
2392160	2398080	y intercept it's kind of like a starting point for our model to exist and then we'll add it to our
2398080	2402960	list of convolved features for this for this layer okay and we'll return that as the as our feature
2402960	2409440	map our set of filter values our weight matrices and so let's look at this convolved 2d function so
2409440	2414320	in our convolved 2d function we'll define the tensor dimension of the image and the feature
2414320	2422960	we'll get a target dimension and then these two lines perform this this operation this convolutional
2422960	2426960	theorem that we defined right here we're performing the dot product between the input
2426960	2434480	and the kernel or feature for for all of those weight values and then we're summing them all up
2434480	2440720	and that's going to be our output and so the fast Fourier function in numpy does this very well
2440720	2446240	and so we can just use that as fft2 but that's it's a multiplication and a summation operation
2446800	2452480	okay and so then we have our target value and then once we have our target value we could say
2452480	2456800	okay let's have a starting point and an ending point and our target value is going to be within
2456800	2462880	that range of what we want to return as the convolved feature right so we have some bounding
2462880	2468320	box that we want to apply this to okay so then so we have that so what else do we have so we start
2468320	2475440	off with our convolutional layer and then we had our relu so what is relu relu super simple relu
2476000	2483360	relu is just forgive so for for some matrix of zeros it will go through every single pixel value
2483360	2488560	in the input matrix and if it's a negative number we just turn it into zero that's it that's relu okay
2489360	2493360	and then so we have we have talked about relu we've talked about convolution we have to talk
2493360	2499440	about pooling so what does max pooling look like so given our learned features and our images
2499440	2504640	let's initialize our more dense feature list as empty and so here's what we do we're going to
2504640	2509680	we're going to take the max values of all of those parts of the input image right so we're
2509680	2514240	going to say we're going to say for each image and for each feature map begin by the row define a
2514240	2519840	starting and ending point okay which we define with our pool size hyper parameter and so for each
2519920	2524800	column so we've got a set of rows and columns for each image there's a notice a lot of nesting
2524800	2529120	happening here we're going to define starting end points for the columns as well and then we're
2529120	2534800	going to say define a patch given our defined starting and ending point so some some bounding box
2534800	2541360	and then take the max value from that patch using nmp.max and that patch is what moves around right
2542800	2547520	for all parts of that image and then we return that and we're going to store all of that in our
2547520	2553520	pooled features matrix right here and we return that as the output and that's what we pass on in
2553520	2559200	the convolutional network okay so that's what max pooling is okay so we've talked about convolution
2559200	2567920	relu max pooling and then dropout so for dropout right we have our probability value that we define
2567920	2573440	as 0.25 and we just multiply it by the input okay and that what that's going to do is it's going to
2573440	2578960	turn on or off some part of the matrix into so by on and off I mean zero it'll make it either
2578960	2584640	zero or not zero so it'll so then our data will have to learn to either be multiplied by it or
2584640	2590800	find a different pathway and that's for dropout and then we talked about dropout and convolution
2591360	2597120	flattening dense and softmax so for flattening it's just a it's a tensor transformation we just
2597200	2602560	reduce the dimensionality of the input okay and then for our
2605440	2610720	dense layer our denses are fully connected layer now this is the generic layer that you would see
2610720	2616560	in a feedforward network input times weight uh and then you add a bias right which is the dot
2616560	2620720	product right here this is this is a dense layer we just take our input times our weight at a bias
2620720	2625200	so that means we we just perform the dot product between the full weight matrix and the full weight
2625200	2630000	matrix instead of doing it at all the layers because that would be way too computationally
2630000	2636080	expensive for image data we perform it at one fully one fully connected or dense layer at the end
2636080	2639360	and that's a way for us to combine all of our learnings together so we can then
2639920	2648880	promptly squash it with a softmax function okay so then for our softmax layer and then we have
2648880	2656160	classify so for our softmax layer we will uh so this is the this is the formula for softmax
2656160	2661440	programmatically speaking uh but what it does is going to output a set of probability values
2661440	2665680	and then we'll classify those values by taking the arg max the largest probability
2665680	2674160	and that is our output okay so that is our forward pass through the network okay and so
2674160	2679600	yes that is our forward pass through the network
2687760	2692480	so back so back propagation works pretty much the same way as i've talked about before several
2692480	2696640	times gradient descent back propagation works the same way we take the partial derivative of our
2696640	2700960	error with respect to our weights and then recursively update our weights using that gradient
2700960	2706080	value that we gradient equals partial derivative equals delta interchangeable words but here's
2706080	2712400	a great simple example right here where we after the forward pass we do the same thing in reverse
2712400	2716560	order so we calculate the gradient of those weights and then back and then multiply them by
2716560	2723520	the previous layer and then for our javascript portion we are taking the drawing from the user
2723520	2728640	here's the main code for that paint window in a canvas and we are going to say capture the
2728640	2733520	mouse's positions capture all those points in that image with an event listener and then we're
2733520	2737920	going to say on paint so whenever the user actually starts moving that painting whenever that mouse
2737920	2742560	stops clicking and then the user hits the submit button we'll save that snapshot of that image and
2742560	2747920	then feed that into the network and that's our flask app we'll define two routes one for our home
2747920	2752080	and then one for that image for the network we can deploy to the web there's a heroku app you
2752080	2756400	could definitely check out the link link is in the description as well check out the notebook
2756400	2759760	and yeah that's it please subscribe for more programming videos and for now
2759760	2763440	i've got to do a 4a transform so thanks for watching
