{"text": " Hello world, it's Siraj and we're going to build a convolutional network using no libraries, I mean just NumPy, but no libraries, no TensorFlow, no PyTorch, none of it. We're going to look at the math behind it and we're going to build it with just NumPy for matrix math in Python. Okay and what it's going to be able to do, let me just start off with this demo to start off with, what it's going to be able to do is recognize any character that you type in or not type in but draw in with your mouse. So you could draw a six like that and then hit submit, it'll start working and then it'll say it's a six and then if you don't want to use a six you could say a letter like a any number or letter it's going to be able to detect slash predict. So it's going to be really cool because we basically were wrapping it into a web app using the Flask web framework. So it's going to be it's going to be super awesome. Okay so that's what we're going to do today and this is our first neural network that we're building in this course from scratch. I mean we made one in the weekly video but this is the real you know hardcore convolutional network with all the layers all the functions everything. Okay so let's start off with what it's inspired by. Well it's inspired by Jan Lacoon, the genius, no it's not. So Jan Lacoon is a director of AI at Facebook. He's a total G, he is awesome because he was inspired by these original two guys right here who published a paper in I think 68 or early 60s or 70s but the paper was on the mammalian visual cortex and the idea they had was and so here's a great image of it let me make it a lot bigger this has to be a lot bigger. So the idea they had was that mammals all see in a very similar way and that way is hierarchical. So you have a collection of cells and these cells are neurons and these cells cluster and and these clusters represent different features that are learned. Okay so here in terms of neuroscience they call these clusters v1 v2 you know they have names for all these clusters in the brain these clusters of neurons before it posterior all this neuroscience terminology but what we need to know is that at a high level what's happening is every time you see something a a series of clusters or layers of neurons are being activated whenever you see something whenever you detect something to be more accurate. So if I detect a dog or a you know face or whatever it's going to be a series of layers or clusters of neurons that fire and each of these clusters are going to detect a set of features okay and these features are going to be more abstract the the higher up the hierarchy of clusters you could think of it as a vertical hierarchy or even a horizontal hierarchy what it doesn't matter but the idea is that there is a hierarchy of features and at the start these features are very simple they're lines and edges but then they get more abstract then they become shapes and then they become more complex shapes and then eventually at the at the highest level at the highest cluster level exist the entire face or the entire dog or whatever it is and this is how the mammalian visual cortex worked and so what Yanlacun said and his team in 98 when they published probably the landmark paper of convolutional nets which is kind of arguable I guess because Khrtchevsky's ImageNet paper was pretty good in in I think 2012 but anyway Yanlacun is a G I just wanted to say that he had the idea to be inspired by three things three features of the human or the mammalian visual cortex local connections and that means the clusters between neurons how each neuron each set of neurons in a cluster cluster are connected to each other and they represent some set of features and then the idea of layering how these how there's a hierarchy of features that are learned and spatial invariance what does this mean this word spatial invariance it means that whenever you or I detect something whether it's let's say we're detecting a shoe right we if you see a shoe you know it's a shoe right if it's a Yeezy if it's uh you know Adidas whatever it is you know it's a shoe it could be shaped this way or this way it could be rotated or transformed no matter how it varies we still can detect that it's a shoe we know it's a shoe so we are it is the way its position is it's spatially invariant we can still detect what it is and so those three concepts were what inspired the birth of convolutional neural networks programmatic neural networks designed to mimic the mammalian visual cortex how cool is that that's so cool so how does this thing work let's look at how this works so we have a set of layers okay and we'll talk about what these layers mean right what is layer a layer in each case is a series it's a series of operations that we're okay so let's let's talk about this right so we have some input image so let's see this is the orange that's the image and you'll notice by the way that this image this is a convolutional network by the way this is what we're building okay you'll notice that this image right here or this image of the convolutional network isn't what you normally look at when you think of neural network right you always see that image of the circles and everything's connected so why is it different for convolutional networks because every layer in a convolutional network isn't connected to every so every neuron in every layer isn't connected to every other neuron in the next layer why because that would be too computationally expensive i'll go over that in a second but the idea is that if you if you see here there is a part of the image that is connected it's this little square of that orange and that is called the receptive field okay i'm going to go over all this it's going to make more and more sense you're going to be more confused it's going it's going to make more and more sense as as i go further and further in depth here so so so stay with me here so we have a receptive field okay that is some part of the image that we are focused on we are by focused i mean that is the part of the image that we apply a convolution operation to okay and we take that receptive field and we slide it across the image okay you're going to see exactly what i'm talking about in a second i'm just going to go over at a high level we slide over the image we are applying a dot product between our weight matrix at a layer and every part of that image iteratively okay and so that the reason that they look different the convolutional networks look different is two reasons really the first reason is that not every neuron in each layer is connected to every other neuron in the next layer it's only a part of that because it would be a to borrow from discrete math a combinatorial explosion to connect every single pixel value in an image to every single pixel value in the next layer of features right it would be just a huge amount so what we do instead is we take a part of that image and we iteratively slide over it okay so at a high level you understand the sliding part right think of it as a flashlight okay think of it think of the uh the filter at each layer that shines over the receptive field that box as a flashlight and you're shining over the image and you're and you're applying dot products to all of these numbers okay just like that okay i'm going to keep going into this that was just the highest level you're not supposed to understand it all yet okay that was that was very high level we're still going deeper we're going deep we're going deep okay so check out this beautiful image right here isn't it beautiful it's very beautiful also you're beautiful for watching this so thank you for watching this okay so i love my fans so much seriously you guys are amazing seriously you guys are the reason i do this every week okay so i by the way i want to say one more thing to go on a tangent the people who subscribe to my channel no one thought they existed we are programmers who are smart and we are also cool no one thought these people existed but we exist okay we are smart and we are cool so you are amazing okay anyway back to this what this is is another way of looking at the network right we're just looking at different ways we're looking at different ways so we can build a spatially invariant image in our head of what a convolutional network is like right no matter what that image is we're going to learn to recognize a convolutional network when we see one i'm just trying to you know meta applying this logic to what we're learning so what happens is that each layer we are applying a series of dot products between the weight matrices and the input matrix okay and so what happens is let's look at a third image okay so this is a third image what happens is we perform a series of operations okay at each layer and so we could think of of different we could think of splitting up a convolutional network into two separate categories the first category is feature learning and that's what's happening at the at the at the head of the the head to the middle to almost the tail end of the network and at the very tail end is classification so there's two parts there's the feature learning part and then there's the classification part and so for the feature learning part what happens are three operations over and over and over again and we can call them convolutional blocks let's just call them convolutional blocks i'm coining the term so what happens is we first apply convolution then we apply relu or any kind of activation and then we apply pooling and we repeat that that's that's a single block three operations in a single convolutional block okay so convolution relu pooling repeat convolution relu pooling repeat convolution relu pooling okay and usually you know you have three blocks at least unless you're building inception by google then you have 15 15 of these but you you know you have these convolutional blocks and at the very end then you flatten that output into a smaller dimensional vector and then you apply a fully connected layer to it so that means that you then connect all the neurons in one layer to the next one just because we want to then harness all of the learnings that we've learned so far that's why we fully connect at the end and then we take those learnings and we squash it into a set of probability values with our last softmax function and then we take the max value of those probabilities and each of these probabilities is a probability for a for specific class that it could be and we take the max value let's say 72 percent as and we'll say okay well 72 percent for banana and now we know it's a banana okay so hopefully you get some of it but it's very confusing still i know we're about to go even deeper okay so get ready for this i haven't even started yet so i haven't even started yet okay so anyway step one so for step one we are preparing a data set of images right so when you think of an image you think of a matrix hopefully a matrix of pixel values if you don't think of it that way think of it think of it that way now you're thinking of an image as a matrix of pixel values rowed by columns and each of these um each of these uh points in the matrix represent a pixel right between 0 and 255 but it's actually better in terms of convolutional networks to think of an an image as a three-dimensional matrix and you're like what no what it's no so it's three dimensions so the first dimension is the length of the image the second dimension is the width and the third dimension is the depth so wait what is the depth because the depth represents the channels and there are three channels for images red green and blue unless you're talking about gray scale then there's black then there's you know black and white but we're talking about color images okay so there are three channels and you have these dimensions for each of the channels so these values in each of these um in each of these 2d matrices for and there are three of them represent the the amount of redness or the amount of greenness or the amount of blueness between 0 and 255 so in terms of convolutional nets we think of images as three-dimensional pixels okay so i wanted to say that part okay so that's that's that's what we think of our image as our input image and it has an associated label right we're talking about supervised learning learning the mapping between the input data and the output label dog image dog label learn the mapping given a new dog image what is a label well you just learned it right so and we learn it through back propagation back propagate to update weights remember the rhyme you know what it is hey i haven't wrapped yet in the series but i will don't worry it's coming anyway so every image is a matrix of pixel values we know this we know this between 0 and 255 and we can use several training data sets there are two really popular ones there's seafar and there's cocoa and there's a bunch of other ones as well but basically these are huge data sets and you can find smaller versions of them and each of these images they're dogs they're cars they're airplanes they're people whatever they all have labels for them handmade labels by humans which is great for us okay so that's that's it that's step one step one is to get your training data which is your images which are your images step two is to perform convolution now you might be asking what is convolution well i'm here to tell you that convolution is an operation that is dope as f here's why it's dope because it's not just used in computer science and machine learning it's used in almost every field of engineering think of convolution as two paint buckets you have one paint bucket which is red another one which is blue and what you do is just smear it all over yourself no you don't do that what you do is you take these two paint buckets and you combine them into one paint bucket and that new paint bucket is going to be a new color whatever that combination of colors is that's convolution convolution is taking two separate types of data or two matrices and then apply and then it's an operation that combines them so you could think of convolution as synonymous to combination okay and why do we apply why do we say that for convolutional networks because what we're doing is we are combining the values for each of these layers with the input matrix so think of the input as that matrix right and so well it's a three-dimensional it's a it's a it's a it's a 3d tensor right but we're applying it to each of these dimensions right so three of them so just think of it as a matrix for right now and so what we do is we take this so at each layer at each layer there is a weight so by the way okay so there's a lot of interchangeable terms in machine learning and it's easy to get confused here but i want to set the record straight for a second weight is the same as feature matrix is the same as feature map is the same as a filter in this case in for convolutional networks so you see these or even kernel kernel is a different one there's actually five interchangeable terms so i can see how it can be confusing but if you get the basic idea of you have an input matrix which is your image and then you have a set of matrices which are your features that are learned you know edges shapes more abstract shapes that's it that's that's all it is matrix dot product matrices that are being multiplied by matrices all the way through that's that's all it is matrices that are being multiplied by matrices all the way through just a chain of them okay so what happens for convolution is we take a matrix and we multiply it by all the values in this matrix at a certain region right and so this is what i was talking about when i was saying we have a receptive field because we don't just multiply it all at once we multiply by a little part of it okay the receptive field and we slide it and we can define what that interval is that sliding window i know i'm talking a lot without coding the coding is coming believe me the coding is coming but just check this out for a second we got to learn this uh conceptually first so we are multiplying the the feature matrix by that input image just for every row and every column we're just multiplying multiply multiply and what happens is we have this new matrix that results the output and that output is considered the convolved feature okay and so what we do is we use that output as the input for the to the next layer and we repeat the process over and over and over again obviously there's two more parts here there's the activation the relu and then there's the pooling which i'll talk about as well but that's the basic idea between convolution and that's why we call it convolution because we are combining or convolving the weight matrix or filter or kernel whatever you want to call it feature map by that input we're combining it using the out and using that output as the input for the next layer after activating it and and pooling it okay so that's convolution and also um right so we apply it to all of those dimensions for that for that input matrix okay and that gives us our activation map or feature map or filter right so many different interchangeable terms here so anyway so it's computed using the dot product so you might be thinking well okay i see how there is a dot product i see how there's matrix multiplication but how does that really tell us what features there are i still you're still not making the connection probably why understandably why this these series of matrix operations help us detect features well here's what happens what happens is this and here's the great thing about matrices and having several of them when we learn a filter or a weight whatever you want to call it well this you know what moving forward let's just call it filter okay i'm just saying let's just call it filter moving forward for the rest of this video when we learn a filter over time by training it on mouse mouth pictures for example a filter is going to look like this at let's say at the first layer we we learn a filter for detecting a curve that looks like this right this curve right here and so what's what this filter is going to look like for detecting the specific type of curve is it's going to be a very sparse filter that means there's a lot of zeros except so there's all these zeros except for right here you see this 30 30 30 30 and notice that these values represent the shape they go in this direction of a shape and so what happens is when we take this filter and perform the dot product you know we convolve it with whatever part of the mouse if it's over a part of the mouse that matches that feature exactly then we when we multiply all of those uh when we when we perform the dot product between all those values and sum them up that's the convolution operation right there okay just it's going to be a big number okay and so then we know that we've detected a feature because we've we've multiplied it sum it up and there's a large number and if there's not if we multiply if let's let's say we have that receptive field over a different part of the mouse and that that curve doesn't exist then it's going to be zero right because if you look between these 30 30 30 values and that the equivalent locations on this pixel representation of the mouse image these are zeros and so what happens when you multiply zero by 30 you get zero right so that's why it's important to make the rest of the so the data that's irrelevant we want it to be zero right in the in the feature maps or in the filters that we learn in the filters that we learn we want the irrelevant parts to be zero and in the images okay and and in the input images so I so I could actually go even more into convolution but it's not really necessary but it's it is super dope it is super dope though this is a great blog post by the way I definitely encourage you to read this blog post it's linked in the notebook but this dude Tim Tim he goes into these this idea of convolution and he talks about how it's applied to all these different engineering fields and he goes into the formula the formula for the convolutional theorem is what he called is what it's called okay and I'm just going to go over this at a high level but the convolution theorem is this general theorem for discrete well there's a discrete version and a continuous version right discrete is if there's you know one or zero black or white you know definite classes that something could be whereas continuous is if it could be an infinite amount of values between zero and one point five point two five you know point seven infinity in that direction but here's the here's the formula for it and so let me make it bigger just really quickly and then we'll get back to it because it's it's really cool but the convolution theorem states that we and so in it's a general theorem that can be applied to any any any set of problems but in terms of what's relevant to us is is the convolutional theorem applied to matrix operations so what we can do is we can say what it what it says is it's the input times the kernel and it's the dot product it's a dot product between two different matrices and we perform that for every value in all of those matrices and we do that for all of the values that we have and we sum them up together and that's what the sigma term represents and we and we actually express that right here right this operation right here this multiplication and summation it's the same thing but it's a more complex way of looking at it or more mathematically accurate way and also the fast Fourier transform is is brought up by this and the fast Fourier transform takes some spatial data and it converts it into Fourier space which is like a waveform and you see this a lot in your day-to-day life whenever you're looking at some sound you know you're listening to some sound and you look at your mp3 player and you see the waves that's a that's a Fourier transform happening but i won't go into that that's that's for sound and audio but anyway it's a really cool blog post definitely check it out okay so back to this so we talked about convolution now we're going to talk about pooling right so what is pooling so whenever we apply convolution to some image what's going to happen at every layer is we're going to get a series of feature of so each of the weights are going to consist of multiple images and each of these images are going to be at every layer there's going to be more and smaller images so the first few layers are going to be these huge images right and then at the next few layers are going to be more of those but they're going to be smaller and it's just going to get just like that okay and at the end we squash it with some fully connected layer so we get some probability values with a softmax but anyway what pooling does is it is it dense is it makes the matrix the matrices that we learn more dense here's what i mean so if you if you perform convolution between an input and a feature matrix or a weight matrix or filter it's going to result in a matrix right but this matrix is going to be pretty big it's going to be a pretty big matrix what we can do is we can take the most important parts of that matrix and pass that on and what that's going to do is it's going to reduce the computational complexity of our model okay so that's what pooling is all about it's a pooling set so there's different types of pooling max pooling is the most used type of pooling by the way so basically multiply so what happens is we we strive we have some we define some window size and then some stride size so how what are the intervals that we look at and we say okay so for each of these windows let's take the max value so for so for uh this one right here four six zero eight the max value would be eight and so for one three twelve nine it'd be twelve right so we just take the biggest number it's really simple actually we just take the biggest number and we just do that for all of them and so that that's what pooling is all about and so it's going to just give us that the most relevant parts of the image and if you if you think of these these very these values in in the in the matrix as pixel intensities by taking the maximum intense the the pixel with the most intensity or the the highest intensity we're getting that feature that is the most relevant if you see what I'm saying it's a least opaque feature to use a term from image um math anyway so we so we talked about pooling and we talked about uh we talked about activation and so now no we talked about convolution and we talked about pooling and so now the third part is normalization or activation so remember how I said how it would be it's so important that we have these values that are not related to our image be zero we want it to be zero so the result is zero if the if the feature is not detected well the way we do that is using relu and so relu stands for rectified linear unit it's an activation function it's an activation function okay we use activation functions throughout neural networks and we use them because it is you can also call them non-linearities because they they make our model able to learn non-linear functions not just linear functions but non-linear functions so any kind of function right the universal function approximation theorem we talked about that activation functions help make this happen and so relu is a is a special kind of activation function that turns all negative numbers into zero so that's why it's going to make the math easier it won't make the math break for our convolutional network so we'll apply a relu so basically what we do is for every single pixel value in the in the input to this relu activation function we turn it if it's a negative we just say make it zero it's super simple it'll be one line of code you'll see exactly what i'm talking about okay so that's that's those are our blocks so that's how our convolutional blocks work however there is another step that I didn't talk about that is a nice to have and state of the our convolutional networks always use it and that's called dropout so Jeffrey Hinton the guy who invented neural networks invented a feature invented a technique called dropout and what dropout is is a good analogy is old people or not old people but people who are stuck in their ways let me let me okay so what dropout does is it turns neurons on and off randomly what do I mean by that that I mean the the matrices for each weight value is converted to zero randomly at some layer of the network and so what happens is by doing this our network is forced to learn new representations for the data new pathways that that data has to flow through it can't always flow through this neuron and the reason we use it is to prevent overfitting right we want to prevent overfitting we want to prevent being too fit to the data think of it as you know the older you get the more set in your ways of thinking your you are right and so it's harder to think of new ways of of of thinking right because you're so set in some ways so a way to prevent that is to have a novel crazy experience whether it's skydiving or ticking psychedelics or whatever it is and what that does is it creates new pathways so you're not so you're kind of forced your brain is forced to make new pathways and this increases your generalization ability and you're not so overfit that's a very rough abstract analogy but basically dropout is not as complex as that sounds dropout can be done in three lines of code so definitely check out this blog post as well that I've linked but what it does is it just randomly picks some neurons in a layer to set to zero right so it's just it's just three lines okay and you can look at it in this notebook right so that's and then our last step is probability conversion so we've got this huge set of values right all these little small images that are represented by this huge output matrix and we want to take this huge set of values and make some sense out of it we want to make probabilities out of it and the way we do that is using a soft max at the end a soft max is a type of function and it looks like this this this is a soft max function right here but what we do is we plug these values into the soft max function and it's going to output a set of probability values discrete probability values for each of the classes that we're trying to predict okay and then what we'll do is given all those probability values will pick the biggest one using arg max the arg max function in numpy and that's going to give us the most likely class okay those are the seven steps of a full forward pass through a convolutional network looks like that and so now you might be wondering well okay so how do we train this thing well using gradient descent right and when applied to neural networks gradient gradient descent is called back propagation exactly i hope you got that right anyway okay so how do we learn these magic numbers right how do we learn what these weight values should be what the feature should be back propagation is how we do it right and so we've talked quite a bit about back propagation and gradient descent but i'll do a little i'll go over it again um but the idea is that we have some error that we're computing right this is super this is supervised learning we have a we have a human label right for some data so we put in a dog image or a bicycle image to look at the summit to to relate to this image here we put in a bicycle image and the bike label we pass it through the each layer dot product dot product dot you know dot product activation function pool dot product repeat repeat soft max or squash into probability values pick the biggest one and we have some prediction value and what we do is we compare the prediction value to the out the actual value and we get an error and we take our error and we compute the partial derivative of the error with respect to each weight value going backwards in the network okay like this okay and so for regression we use the mean squared error if we're using linear regression regression and for classification we use the softmax function so remember how in the first neural network we built and in their linear regression example we used a uh we use mean squared error to compute the error and now we're using the softmax so we'll take the so we'll take the partial derivative of the error with respect to our weights and then that's going to give us the gradient value that we then update each of those weight values recursively going backward in the network and that's how it learns what this features what the ideal feature the weight matrix value should be but what about the other what about the other magic numbers what about the number of neurons and the number of features and the size of those features and the pooling window size and the window stride well those that is an active area of research there are best practices for values that you should use for those for those hyper parameters right the tuning knobs of our network and andrew karpathy has some great material on this and he's probably the leading source for convolutional networks right now in terms of um written contents and uh yeah i mean this is an active area of research finding out what the ideal hyper parameters for our neural network should be and we're still learning what it should be what what what what how we can get them rather than just guessing and checking which is what we do right now which is kind of like you know not it's not as optimal right so anyway last two things and then we're gonna get started with the code when is a good time to use this well we know to classify images we've talked about that but you can also use them to generate images and that's for later on that's a little more advanced but to give you a little spoiler a little teaser in fact this is in my intro to deep learning playlist you take a convolutional network you flip it and then you call it a deconvolutional network and then you can take some text and create an image out of text how crazy is that okay there's also generative models where you have two networks fighting each other and you can generate new images a whole bunch of really cool crazy stuff you can do but anyway when should you use a convolutional network anytime you have spatial 2d or 3d data what do i mean well obviously images are spatial the word spatial implies that the space the positioning of the data matters so sound you can apply to sound images or text where the the the position of the text matters right because we have a flashlight our filter and we're convolving over an image right but if you have some data like say customer data where if you were to just flip the rows and columns it doesn't matter what order they're in they're still you know they're still features so a good rule of thumb is if you swap out the rows and columns of your data set and it's just as useful like the space doesn't matter then you don't want to use a cnn else you do okay and a great and last thing the great example of using cnn's are for robot learning you can use a cnn for object detection and you can use a cnn for grasp learning and combine the two and then you can get a robot that cooks which is really cool i've got a great tensorflow example and a great adversarial network example okay let's go into the code now and so what i'm going to do is i'm going to look at the class for the convolutional network in numpy as well as the prediction class there's two classes here okay so these are our three inputs pickle is for saving and loading our serialized model what do i mean pickle is python's way of having a platform or language agnostic way of saving data so you can load it up later tensorflow uses it a bunch of other libraries use it as well numpy is for matrix math and we've got our own little custom class for pre-processing the data because we don't care about that part we care about the machine learning part okay so let's talk about our light ocr or object optical character recognition class in our initialized function we're going to load the weights from the pickle file and then store and then store all the labels that we've loaded we'll define how many rows and columns in an image load up our convolutional network using the light cnn function with our saved weights so assuming we've already trained our network we load it with the saved weights from the pickle file and then we define the number of pooling layers okay so once we have that then we can use this predict function so given some new image we'll reshape the image so it's in the correct size to perform the dot product between that image and the first layer of our convolutional network and we'll we'll we'll put it we'll feed it into our network and it's going to output a prediction probability for a class and we'll return it okay super high level we haven't even coded our cnn that's that's our first class that's our prediction class now now we're going to look at the convolutional network class and what i'm going to do is i'm going to i'm going to go over the code and i'm going to code some parts of it so now we'll look at our convolutional network class okay so in our initialized function we'll initialize two lists one to store the layers that we've learned the the weights of each layer and then the size of the pooling area for max pooling okay we'll load up our weights from our pickle file just like this and then we have our predict function now in our predict function that's where the real magic is happening right let's code what this looks like so given some input x we're going to feed it through all of these layers right so what happens is we will say okay so the first layer is going to be a convolutional layer okay and we're going to define what all of these functions look like look like but the first layer is going to be that convolutional layer we'll feed in that first image and we'll say okay well this is the first layer so it's a zeroth layer we'll say border mode equals full and i'll talk about that part later on but that's it for that and so what happens is x equals this layer okay so that's our first layer and then our next layer is going to be relu so we'll say okay now let's apply an activation to the output of the previous layer okay and then we'll set it equal to that okay so we'll set the output from the previous layer equal to the input of this layer and then we keep going we say okay so we've got another uh cnn we have another convolutional layer and we do the same thing here we say okay take the in output from the previous layer we'll define what the uh name of this layer is as well as the border mode which i'll talk about the very end of this we have a border mode which is valid and then we say okay well we'll set the output of that equal to the input of this and just keep repeating now it's time for us to apply a another non-linearity so we'll just go ahead and apply our non-linearity again remember these are convolutional blocks oh and we also want to pool so also the the order with which you can do this varies right you can do this in different ways and yeah so i'm doing it a certain way right now you know we could change it around it would change our result but the order map the ordering within the block can be can be different okay so right so we're going to pool it we're going to pick the the most relevant features from from that uh from that output and then we're going to perform drop out to prevent overfitting and we're going to say there's going to be a 0.25 chance that a neuron is going to be deactivated that will turn it off set it to zero and that's our dropout probability value and then now we're getting into our our the second category of our network not the feature learning part but the classification part and we'll say okay so let's flatten this layer let's reduce the dimensionality of all of that that data so it's something that we can then learn from and we'll say well let's let's set it equal to seven and then we'll say once again turn that output into our uh inputs here okay and so then we have another dense layer we just we just keep going with or our first dense layer and that means we are going to it's a fully connected layer so we're combining everything that we've learned because we're getting really close to squashing these values into a set of probability values so we want to take all of our learnings and combine them with a fully connected layer and so we'll combine them with a fully connected layer and then uh we'll squash it now with our sigmoid or no not our sigmoid our softmax function okay and then that's going to give us our output probability and then we're going to say well which of the probabilities do we want we want the max one right we want the max probability and we'll classify it just like that and return that value okay that's the highest level and so if you were using keras or one of these high level libraries this is all your code would look like but what we're going to do is we're going to look at these functions as well okay so let's look at these functions so we'll start off with the convolutional layer function and have your notebook open with me as well so you could go over this the the link is in the description if you don't know now you know if you don't know now you know so for our convolutional layer given some input image we're going to say well we'll store our feature maps and the bias value in these two variables features and bias will define how big our filter or patch is going to be how many features do we want how big is our image how many channels rgb so three and then how many images do we have so given those values we'll define a border mode so a border mode so is so when you apply fold to border mode in this case it means that the filter has to go outside the bounds of the input by filter size divided by two the area outside of the input is normally padded with zeros and the border mode valid is when you get an output that is smaller than the input because the convolution is only computed where the input and the filter fully overlap okay and they'll give us different they'll give us different classification results accuracy results and it's good to test both options so what we'll do is we'll initialize our feature matrix for this layer as conv as convolve zeros it's going to be a bunch of zeros and then we'll say okay so for every image that we have for every feature in that image let's initialize a convolved image as empty and then for each channel so we're doing this for each of the three channels let's extract a feature from our feature map define a channel specific part of our image and then perform convolution on our image using that given feature filter so notice this convolved 2d function it's where the actual convolution operation is happening this is more of a wrapper for that actual mathematical operation so once we have that we'll add a bias and a bias acts as our anchor for our network it's kind of like the y intercept it's kind of like a starting point for our model to exist and then we'll add it to our list of convolved features for this for this layer okay and we'll return that as the as our feature map our set of filter values our weight matrices and so let's look at this convolved 2d function so in our convolved 2d function we'll define the tensor dimension of the image and the feature we'll get a target dimension and then these two lines perform this this operation this convolutional theorem that we defined right here we're performing the dot product between the input and the kernel or feature for for all of those weight values and then we're summing them all up and that's going to be our output and so the fast Fourier function in numpy does this very well and so we can just use that as fft2 but that's it's a multiplication and a summation operation okay and so then we have our target value and then once we have our target value we could say okay let's have a starting point and an ending point and our target value is going to be within that range of what we want to return as the convolved feature right so we have some bounding box that we want to apply this to okay so then so we have that so what else do we have so we start off with our convolutional layer and then we had our relu so what is relu relu super simple relu relu is just forgive so for for some matrix of zeros it will go through every single pixel value in the input matrix and if it's a negative number we just turn it into zero that's it that's relu okay and then so we have we have talked about relu we've talked about convolution we have to talk about pooling so what does max pooling look like so given our learned features and our images let's initialize our more dense feature list as empty and so here's what we do we're going to we're going to take the max values of all of those parts of the input image right so we're going to say we're going to say for each image and for each feature map begin by the row define a starting and ending point okay which we define with our pool size hyper parameter and so for each column so we've got a set of rows and columns for each image there's a notice a lot of nesting happening here we're going to define starting end points for the columns as well and then we're going to say define a patch given our defined starting and ending point so some some bounding box and then take the max value from that patch using nmp.max and that patch is what moves around right for all parts of that image and then we return that and we're going to store all of that in our pooled features matrix right here and we return that as the output and that's what we pass on in the convolutional network okay so that's what max pooling is okay so we've talked about convolution relu max pooling and then dropout so for dropout right we have our probability value that we define as 0.25 and we just multiply it by the input okay and that what that's going to do is it's going to turn on or off some part of the matrix into so by on and off I mean zero it'll make it either zero or not zero so it'll so then our data will have to learn to either be multiplied by it or find a different pathway and that's for dropout and then we talked about dropout and convolution flattening dense and softmax so for flattening it's just a it's a tensor transformation we just reduce the dimensionality of the input okay and then for our dense layer our denses are fully connected layer now this is the generic layer that you would see in a feedforward network input times weight uh and then you add a bias right which is the dot product right here this is this is a dense layer we just take our input times our weight at a bias so that means we we just perform the dot product between the full weight matrix and the full weight matrix instead of doing it at all the layers because that would be way too computationally expensive for image data we perform it at one fully one fully connected or dense layer at the end and that's a way for us to combine all of our learnings together so we can then promptly squash it with a softmax function okay so then for our softmax layer and then we have classify so for our softmax layer we will uh so this is the this is the formula for softmax programmatically speaking uh but what it does is going to output a set of probability values and then we'll classify those values by taking the arg max the largest probability and that is our output okay so that is our forward pass through the network okay and so yes that is our forward pass through the network so back so back propagation works pretty much the same way as i've talked about before several times gradient descent back propagation works the same way we take the partial derivative of our error with respect to our weights and then recursively update our weights using that gradient value that we gradient equals partial derivative equals delta interchangeable words but here's a great simple example right here where we after the forward pass we do the same thing in reverse order so we calculate the gradient of those weights and then back and then multiply them by the previous layer and then for our javascript portion we are taking the drawing from the user here's the main code for that paint window in a canvas and we are going to say capture the mouse's positions capture all those points in that image with an event listener and then we're going to say on paint so whenever the user actually starts moving that painting whenever that mouse stops clicking and then the user hits the submit button we'll save that snapshot of that image and then feed that into the network and that's our flask app we'll define two routes one for our home and then one for that image for the network we can deploy to the web there's a heroku app you could definitely check out the link link is in the description as well check out the notebook and yeah that's it please subscribe for more programming videos and for now i've got to do a 4a transform so thanks for watching", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.84, "text": " Hello world, it's Siraj and we're going to build a convolutional network using no libraries,", "tokens": [50364, 2425, 1002, 11, 309, 311, 6144, 1805, 293, 321, 434, 516, 281, 1322, 257, 45216, 304, 3209, 1228, 572, 15148, 11, 50656], "temperature": 0.0, "avg_logprob": -0.1307671482401683, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.042028266936540604}, {"id": 1, "seek": 0, "start": 5.84, "end": 11.52, "text": " I mean just NumPy, but no libraries, no TensorFlow, no PyTorch, none of it. We're going to look at", "tokens": [50656, 286, 914, 445, 22592, 47, 88, 11, 457, 572, 15148, 11, 572, 37624, 11, 572, 9953, 51, 284, 339, 11, 6022, 295, 309, 13, 492, 434, 516, 281, 574, 412, 50940], "temperature": 0.0, "avg_logprob": -0.1307671482401683, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.042028266936540604}, {"id": 2, "seek": 0, "start": 11.52, "end": 17.04, "text": " the math behind it and we're going to build it with just NumPy for matrix math in Python.", "tokens": [50940, 264, 5221, 2261, 309, 293, 321, 434, 516, 281, 1322, 309, 365, 445, 22592, 47, 88, 337, 8141, 5221, 294, 15329, 13, 51216], "temperature": 0.0, "avg_logprob": -0.1307671482401683, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.042028266936540604}, {"id": 3, "seek": 0, "start": 17.04, "end": 21.52, "text": " Okay and what it's going to be able to do, let me just start off with this demo to start off with,", "tokens": [51216, 1033, 293, 437, 309, 311, 516, 281, 312, 1075, 281, 360, 11, 718, 385, 445, 722, 766, 365, 341, 10723, 281, 722, 766, 365, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1307671482401683, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.042028266936540604}, {"id": 4, "seek": 0, "start": 21.52, "end": 26.72, "text": " what it's going to be able to do is recognize any character that you type in or not type in but draw", "tokens": [51440, 437, 309, 311, 516, 281, 312, 1075, 281, 360, 307, 5521, 604, 2517, 300, 291, 2010, 294, 420, 406, 2010, 294, 457, 2642, 51700], "temperature": 0.0, "avg_logprob": -0.1307671482401683, "compression_ratio": 1.8643410852713178, "no_speech_prob": 0.042028266936540604}, {"id": 5, "seek": 2672, "start": 26.799999999999997, "end": 32.4, "text": " in with your mouse. So you could draw a six like that and then hit submit, it'll start working", "tokens": [50368, 294, 365, 428, 9719, 13, 407, 291, 727, 2642, 257, 2309, 411, 300, 293, 550, 2045, 10315, 11, 309, 603, 722, 1364, 50648], "temperature": 0.0, "avg_logprob": -0.084970132235823, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.03513485565781593}, {"id": 6, "seek": 2672, "start": 33.04, "end": 36.64, "text": " and then it'll say it's a six and then if you don't want to use a six you could say a letter like", "tokens": [50680, 293, 550, 309, 603, 584, 309, 311, 257, 2309, 293, 550, 498, 291, 500, 380, 528, 281, 764, 257, 2309, 291, 727, 584, 257, 5063, 411, 50860], "temperature": 0.0, "avg_logprob": -0.084970132235823, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.03513485565781593}, {"id": 7, "seek": 2672, "start": 36.64, "end": 42.32, "text": " a any number or letter it's going to be able to detect slash predict. So it's going to be really", "tokens": [50860, 257, 604, 1230, 420, 5063, 309, 311, 516, 281, 312, 1075, 281, 5531, 17330, 6069, 13, 407, 309, 311, 516, 281, 312, 534, 51144], "temperature": 0.0, "avg_logprob": -0.084970132235823, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.03513485565781593}, {"id": 8, "seek": 2672, "start": 42.32, "end": 48.08, "text": " cool because we basically were wrapping it into a web app using the Flask web framework. So it's", "tokens": [51144, 1627, 570, 321, 1936, 645, 21993, 309, 666, 257, 3670, 724, 1228, 264, 3235, 3863, 3670, 8388, 13, 407, 309, 311, 51432], "temperature": 0.0, "avg_logprob": -0.084970132235823, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.03513485565781593}, {"id": 9, "seek": 2672, "start": 48.08, "end": 51.68, "text": " going to be it's going to be super awesome. Okay so that's what we're going to do today", "tokens": [51432, 516, 281, 312, 309, 311, 516, 281, 312, 1687, 3476, 13, 1033, 370, 300, 311, 437, 321, 434, 516, 281, 360, 965, 51612], "temperature": 0.0, "avg_logprob": -0.084970132235823, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.03513485565781593}, {"id": 10, "seek": 2672, "start": 51.68, "end": 56.16, "text": " and this is our first neural network that we're building in this course from scratch.", "tokens": [51612, 293, 341, 307, 527, 700, 18161, 3209, 300, 321, 434, 2390, 294, 341, 1164, 490, 8459, 13, 51836], "temperature": 0.0, "avg_logprob": -0.084970132235823, "compression_ratio": 1.9047619047619047, "no_speech_prob": 0.03513485565781593}, {"id": 11, "seek": 5616, "start": 56.16, "end": 61.04, "text": " I mean we made one in the weekly video but this is the real you know hardcore convolutional network", "tokens": [50364, 286, 914, 321, 1027, 472, 294, 264, 12460, 960, 457, 341, 307, 264, 957, 291, 458, 28196, 45216, 304, 3209, 50608], "temperature": 0.0, "avg_logprob": -0.12814557670366647, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0023229634389281273}, {"id": 12, "seek": 5616, "start": 61.04, "end": 66.64, "text": " with all the layers all the functions everything. Okay so let's start off with what it's inspired by.", "tokens": [50608, 365, 439, 264, 7914, 439, 264, 6828, 1203, 13, 1033, 370, 718, 311, 722, 766, 365, 437, 309, 311, 7547, 538, 13, 50888], "temperature": 0.0, "avg_logprob": -0.12814557670366647, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0023229634389281273}, {"id": 13, "seek": 5616, "start": 66.64, "end": 72.96, "text": " Well it's inspired by Jan Lacoon, the genius, no it's not. So Jan Lacoon is a director of AI at", "tokens": [50888, 1042, 309, 311, 7547, 538, 4956, 40113, 4106, 11, 264, 14017, 11, 572, 309, 311, 406, 13, 407, 4956, 40113, 4106, 307, 257, 5391, 295, 7318, 412, 51204], "temperature": 0.0, "avg_logprob": -0.12814557670366647, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0023229634389281273}, {"id": 14, "seek": 5616, "start": 72.96, "end": 80.47999999999999, "text": " Facebook. He's a total G, he is awesome because he was inspired by these original two guys right here", "tokens": [51204, 4384, 13, 634, 311, 257, 3217, 460, 11, 415, 307, 3476, 570, 415, 390, 7547, 538, 613, 3380, 732, 1074, 558, 510, 51580], "temperature": 0.0, "avg_logprob": -0.12814557670366647, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0023229634389281273}, {"id": 15, "seek": 8048, "start": 81.36, "end": 88.32000000000001, "text": " who published a paper in I think 68 or early 60s or 70s but the paper was on the mammalian", "tokens": [50408, 567, 6572, 257, 3035, 294, 286, 519, 23317, 420, 2440, 4060, 82, 420, 5285, 82, 457, 264, 3035, 390, 322, 264, 49312, 952, 50756], "temperature": 0.0, "avg_logprob": -0.05870031588005297, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.048854537308216095}, {"id": 16, "seek": 8048, "start": 88.32000000000001, "end": 93.28, "text": " visual cortex and the idea they had was and so here's a great image of it let me make it a lot", "tokens": [50756, 5056, 33312, 293, 264, 1558, 436, 632, 390, 293, 370, 510, 311, 257, 869, 3256, 295, 309, 718, 385, 652, 309, 257, 688, 51004], "temperature": 0.0, "avg_logprob": -0.05870031588005297, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.048854537308216095}, {"id": 17, "seek": 8048, "start": 93.28, "end": 100.80000000000001, "text": " bigger this has to be a lot bigger. So the idea they had was that mammals all see in a very similar", "tokens": [51004, 3801, 341, 575, 281, 312, 257, 688, 3801, 13, 407, 264, 1558, 436, 632, 390, 300, 35408, 439, 536, 294, 257, 588, 2531, 51380], "temperature": 0.0, "avg_logprob": -0.05870031588005297, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.048854537308216095}, {"id": 18, "seek": 8048, "start": 100.80000000000001, "end": 106.4, "text": " way and that way is hierarchical. So you have a collection of cells and these cells are neurons", "tokens": [51380, 636, 293, 300, 636, 307, 35250, 804, 13, 407, 291, 362, 257, 5765, 295, 5438, 293, 613, 5438, 366, 22027, 51660], "temperature": 0.0, "avg_logprob": -0.05870031588005297, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.048854537308216095}, {"id": 19, "seek": 10640, "start": 106.4, "end": 111.52000000000001, "text": " and these cells cluster and and these clusters represent different features that are learned.", "tokens": [50364, 293, 613, 5438, 13630, 293, 293, 613, 23313, 2906, 819, 4122, 300, 366, 3264, 13, 50620], "temperature": 0.0, "avg_logprob": -0.09677180858573528, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.014502312988042831}, {"id": 20, "seek": 10640, "start": 111.52000000000001, "end": 117.36000000000001, "text": " Okay so here in terms of neuroscience they call these clusters v1 v2 you know they have names", "tokens": [50620, 1033, 370, 510, 294, 2115, 295, 42762, 436, 818, 613, 23313, 371, 16, 371, 17, 291, 458, 436, 362, 5288, 50912], "temperature": 0.0, "avg_logprob": -0.09677180858573528, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.014502312988042831}, {"id": 21, "seek": 10640, "start": 117.36000000000001, "end": 122.48, "text": " for all these clusters in the brain these clusters of neurons before it posterior all this", "tokens": [50912, 337, 439, 613, 23313, 294, 264, 3567, 613, 23313, 295, 22027, 949, 309, 33529, 439, 341, 51168], "temperature": 0.0, "avg_logprob": -0.09677180858573528, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.014502312988042831}, {"id": 22, "seek": 10640, "start": 122.48, "end": 127.44, "text": " neuroscience terminology but what we need to know is that at a high level what's happening is every", "tokens": [51168, 42762, 27575, 457, 437, 321, 643, 281, 458, 307, 300, 412, 257, 1090, 1496, 437, 311, 2737, 307, 633, 51416], "temperature": 0.0, "avg_logprob": -0.09677180858573528, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.014502312988042831}, {"id": 23, "seek": 10640, "start": 127.44, "end": 135.68, "text": " time you see something a a series of clusters or layers of neurons are being activated whenever", "tokens": [51416, 565, 291, 536, 746, 257, 257, 2638, 295, 23313, 420, 7914, 295, 22027, 366, 885, 18157, 5699, 51828], "temperature": 0.0, "avg_logprob": -0.09677180858573528, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.014502312988042831}, {"id": 24, "seek": 13568, "start": 135.68, "end": 140.96, "text": " you see something whenever you detect something to be more accurate. So if I detect a dog or a", "tokens": [50364, 291, 536, 746, 5699, 291, 5531, 746, 281, 312, 544, 8559, 13, 407, 498, 286, 5531, 257, 3000, 420, 257, 50628], "temperature": 0.0, "avg_logprob": -0.09034616296941583, "compression_ratio": 1.9437751004016064, "no_speech_prob": 0.00609701918438077}, {"id": 25, "seek": 13568, "start": 140.96, "end": 146.64000000000001, "text": " you know face or whatever it's going to be a series of layers or clusters of neurons that fire", "tokens": [50628, 291, 458, 1851, 420, 2035, 309, 311, 516, 281, 312, 257, 2638, 295, 7914, 420, 23313, 295, 22027, 300, 2610, 50912], "temperature": 0.0, "avg_logprob": -0.09034616296941583, "compression_ratio": 1.9437751004016064, "no_speech_prob": 0.00609701918438077}, {"id": 26, "seek": 13568, "start": 146.64000000000001, "end": 151.84, "text": " and each of these clusters are going to detect a set of features okay and these features are going", "tokens": [50912, 293, 1184, 295, 613, 23313, 366, 516, 281, 5531, 257, 992, 295, 4122, 1392, 293, 613, 4122, 366, 516, 51172], "temperature": 0.0, "avg_logprob": -0.09034616296941583, "compression_ratio": 1.9437751004016064, "no_speech_prob": 0.00609701918438077}, {"id": 27, "seek": 13568, "start": 151.84, "end": 157.60000000000002, "text": " to be more abstract the the higher up the hierarchy of clusters you could think of it as a vertical", "tokens": [51172, 281, 312, 544, 12649, 264, 264, 2946, 493, 264, 22333, 295, 23313, 291, 727, 519, 295, 309, 382, 257, 9429, 51460], "temperature": 0.0, "avg_logprob": -0.09034616296941583, "compression_ratio": 1.9437751004016064, "no_speech_prob": 0.00609701918438077}, {"id": 28, "seek": 13568, "start": 157.60000000000002, "end": 162.16, "text": " hierarchy or even a horizontal hierarchy what it doesn't matter but the idea is that there is a", "tokens": [51460, 22333, 420, 754, 257, 12750, 22333, 437, 309, 1177, 380, 1871, 457, 264, 1558, 307, 300, 456, 307, 257, 51688], "temperature": 0.0, "avg_logprob": -0.09034616296941583, "compression_ratio": 1.9437751004016064, "no_speech_prob": 0.00609701918438077}, {"id": 29, "seek": 16216, "start": 162.16, "end": 167.52, "text": " hierarchy of features and at the start these features are very simple they're lines and edges", "tokens": [50364, 22333, 295, 4122, 293, 412, 264, 722, 613, 4122, 366, 588, 2199, 436, 434, 3876, 293, 8819, 50632], "temperature": 0.0, "avg_logprob": -0.0843759280879323, "compression_ratio": 2.0157894736842104, "no_speech_prob": 0.012052885256707668}, {"id": 30, "seek": 16216, "start": 167.52, "end": 173.12, "text": " but then they get more abstract then they become shapes and then they become more complex shapes", "tokens": [50632, 457, 550, 436, 483, 544, 12649, 550, 436, 1813, 10854, 293, 550, 436, 1813, 544, 3997, 10854, 50912], "temperature": 0.0, "avg_logprob": -0.0843759280879323, "compression_ratio": 2.0157894736842104, "no_speech_prob": 0.012052885256707668}, {"id": 31, "seek": 16216, "start": 173.12, "end": 178.24, "text": " and then eventually at the at the highest level at the highest cluster level exist the entire face", "tokens": [50912, 293, 550, 4728, 412, 264, 412, 264, 6343, 1496, 412, 264, 6343, 13630, 1496, 2514, 264, 2302, 1851, 51168], "temperature": 0.0, "avg_logprob": -0.0843759280879323, "compression_ratio": 2.0157894736842104, "no_speech_prob": 0.012052885256707668}, {"id": 32, "seek": 16216, "start": 178.24, "end": 185.68, "text": " or the entire dog or whatever it is and this is how the mammalian visual cortex worked and so", "tokens": [51168, 420, 264, 2302, 3000, 420, 2035, 309, 307, 293, 341, 307, 577, 264, 49312, 952, 5056, 33312, 2732, 293, 370, 51540], "temperature": 0.0, "avg_logprob": -0.0843759280879323, "compression_ratio": 2.0157894736842104, "no_speech_prob": 0.012052885256707668}, {"id": 33, "seek": 18568, "start": 185.68, "end": 192.24, "text": " what Yanlacun said and his team in 98 when they published probably the landmark paper of convolutional", "tokens": [50364, 437, 13633, 75, 326, 409, 848, 293, 702, 1469, 294, 20860, 562, 436, 6572, 1391, 264, 26962, 3035, 295, 45216, 304, 50692], "temperature": 0.0, "avg_logprob": -0.15149796869336946, "compression_ratio": 1.5234375, "no_speech_prob": 0.014955203980207443}, {"id": 34, "seek": 18568, "start": 192.24, "end": 197.52, "text": " nets which is kind of arguable I guess because Khrtchevsky's ImageNet paper was pretty good in", "tokens": [50692, 36170, 597, 307, 733, 295, 10171, 712, 286, 2041, 570, 591, 1703, 83, 1876, 85, 25810, 311, 29903, 31890, 3035, 390, 1238, 665, 294, 50956], "temperature": 0.0, "avg_logprob": -0.15149796869336946, "compression_ratio": 1.5234375, "no_speech_prob": 0.014955203980207443}, {"id": 35, "seek": 18568, "start": 198.08, "end": 204.88, "text": " in I think 2012 but anyway Yanlacun is a G I just wanted to say that he had the idea to be inspired", "tokens": [50984, 294, 286, 519, 9125, 457, 4033, 13633, 75, 326, 409, 307, 257, 460, 286, 445, 1415, 281, 584, 300, 415, 632, 264, 1558, 281, 312, 7547, 51324], "temperature": 0.0, "avg_logprob": -0.15149796869336946, "compression_ratio": 1.5234375, "no_speech_prob": 0.014955203980207443}, {"id": 36, "seek": 18568, "start": 204.88, "end": 211.52, "text": " by three things three features of the human or the mammalian visual cortex local connections", "tokens": [51324, 538, 1045, 721, 1045, 4122, 295, 264, 1952, 420, 264, 49312, 952, 5056, 33312, 2654, 9271, 51656], "temperature": 0.0, "avg_logprob": -0.15149796869336946, "compression_ratio": 1.5234375, "no_speech_prob": 0.014955203980207443}, {"id": 37, "seek": 21152, "start": 211.52, "end": 216.64000000000001, "text": " and that means the clusters between neurons how each neuron each set of neurons in a cluster", "tokens": [50364, 293, 300, 1355, 264, 23313, 1296, 22027, 577, 1184, 34090, 1184, 992, 295, 22027, 294, 257, 13630, 50620], "temperature": 0.0, "avg_logprob": -0.039615257731023826, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.08508467674255371}, {"id": 38, "seek": 21152, "start": 216.64000000000001, "end": 221.12, "text": " cluster are connected to each other and they represent some set of features and then the", "tokens": [50620, 13630, 366, 4582, 281, 1184, 661, 293, 436, 2906, 512, 992, 295, 4122, 293, 550, 264, 50844], "temperature": 0.0, "avg_logprob": -0.039615257731023826, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.08508467674255371}, {"id": 39, "seek": 21152, "start": 221.12, "end": 228.24, "text": " idea of layering how these how there's a hierarchy of features that are learned and spatial invariance", "tokens": [50844, 1558, 295, 40754, 577, 613, 577, 456, 311, 257, 22333, 295, 4122, 300, 366, 3264, 293, 23598, 33270, 719, 51200], "temperature": 0.0, "avg_logprob": -0.039615257731023826, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.08508467674255371}, {"id": 40, "seek": 21152, "start": 228.24, "end": 233.04000000000002, "text": " what does this mean this word spatial invariance it means that whenever you or I detect something", "tokens": [51200, 437, 775, 341, 914, 341, 1349, 23598, 33270, 719, 309, 1355, 300, 5699, 291, 420, 286, 5531, 746, 51440], "temperature": 0.0, "avg_logprob": -0.039615257731023826, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.08508467674255371}, {"id": 41, "seek": 21152, "start": 233.04000000000002, "end": 238.08, "text": " whether it's let's say we're detecting a shoe right we if you see a shoe you know it's a shoe", "tokens": [51440, 1968, 309, 311, 718, 311, 584, 321, 434, 40237, 257, 12796, 558, 321, 498, 291, 536, 257, 12796, 291, 458, 309, 311, 257, 12796, 51692], "temperature": 0.0, "avg_logprob": -0.039615257731023826, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.08508467674255371}, {"id": 42, "seek": 23808, "start": 238.08, "end": 243.52, "text": " right if it's a Yeezy if it's uh you know Adidas whatever it is you know it's a shoe", "tokens": [50364, 558, 498, 309, 311, 257, 835, 68, 1229, 498, 309, 311, 2232, 291, 458, 1999, 11382, 2035, 309, 307, 291, 458, 309, 311, 257, 12796, 50636], "temperature": 0.0, "avg_logprob": -0.08348087273021736, "compression_ratio": 1.8774509803921569, "no_speech_prob": 0.0071209268644452095}, {"id": 43, "seek": 23808, "start": 243.52, "end": 249.12, "text": " it could be shaped this way or this way it could be rotated or transformed no matter how it varies", "tokens": [50636, 309, 727, 312, 13475, 341, 636, 420, 341, 636, 309, 727, 312, 42146, 420, 16894, 572, 1871, 577, 309, 21716, 50916], "temperature": 0.0, "avg_logprob": -0.08348087273021736, "compression_ratio": 1.8774509803921569, "no_speech_prob": 0.0071209268644452095}, {"id": 44, "seek": 23808, "start": 249.92000000000002, "end": 255.92000000000002, "text": " we still can detect that it's a shoe we know it's a shoe so we are it is the way its position is", "tokens": [50956, 321, 920, 393, 5531, 300, 309, 311, 257, 12796, 321, 458, 309, 311, 257, 12796, 370, 321, 366, 309, 307, 264, 636, 1080, 2535, 307, 51256], "temperature": 0.0, "avg_logprob": -0.08348087273021736, "compression_ratio": 1.8774509803921569, "no_speech_prob": 0.0071209268644452095}, {"id": 45, "seek": 23808, "start": 255.92000000000002, "end": 263.52000000000004, "text": " it's spatially invariant we can still detect what it is and so those three concepts were what inspired", "tokens": [51256, 309, 311, 15000, 2270, 33270, 394, 321, 393, 920, 5531, 437, 309, 307, 293, 370, 729, 1045, 10392, 645, 437, 7547, 51636], "temperature": 0.0, "avg_logprob": -0.08348087273021736, "compression_ratio": 1.8774509803921569, "no_speech_prob": 0.0071209268644452095}, {"id": 46, "seek": 26352, "start": 263.52, "end": 268.71999999999997, "text": " the birth of convolutional neural networks programmatic neural networks designed to mimic", "tokens": [50364, 264, 3965, 295, 45216, 304, 18161, 9590, 1461, 25915, 18161, 9590, 4761, 281, 31075, 50624], "temperature": 0.0, "avg_logprob": -0.05018015883185647, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.1732124537229538}, {"id": 47, "seek": 26352, "start": 268.71999999999997, "end": 274.96, "text": " the mammalian visual cortex how cool is that that's so cool so how does this thing work", "tokens": [50624, 264, 49312, 952, 5056, 33312, 577, 1627, 307, 300, 300, 311, 370, 1627, 370, 577, 775, 341, 551, 589, 50936], "temperature": 0.0, "avg_logprob": -0.05018015883185647, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.1732124537229538}, {"id": 48, "seek": 26352, "start": 274.96, "end": 280.47999999999996, "text": " let's look at how this works so we have a set of layers okay and we'll talk about what these layers", "tokens": [50936, 718, 311, 574, 412, 577, 341, 1985, 370, 321, 362, 257, 992, 295, 7914, 1392, 293, 321, 603, 751, 466, 437, 613, 7914, 51212], "temperature": 0.0, "avg_logprob": -0.05018015883185647, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.1732124537229538}, {"id": 49, "seek": 26352, "start": 280.47999999999996, "end": 288.47999999999996, "text": " mean right what is layer a layer in each case is a series it's a series of operations that we're", "tokens": [51212, 914, 558, 437, 307, 4583, 257, 4583, 294, 1184, 1389, 307, 257, 2638, 309, 311, 257, 2638, 295, 7705, 300, 321, 434, 51612], "temperature": 0.0, "avg_logprob": -0.05018015883185647, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.1732124537229538}, {"id": 50, "seek": 28848, "start": 289.04, "end": 293.36, "text": " okay so let's let's talk about this right so we have some input image so let's see", "tokens": [50392, 1392, 370, 718, 311, 718, 311, 751, 466, 341, 558, 370, 321, 362, 512, 4846, 3256, 370, 718, 311, 536, 50608], "temperature": 0.0, "avg_logprob": -0.04111080699496799, "compression_ratio": 2.1865079365079363, "no_speech_prob": 0.250823974609375}, {"id": 51, "seek": 28848, "start": 294.08000000000004, "end": 298.48, "text": " this is the orange that's the image and you'll notice by the way that this image this is a", "tokens": [50644, 341, 307, 264, 7671, 300, 311, 264, 3256, 293, 291, 603, 3449, 538, 264, 636, 300, 341, 3256, 341, 307, 257, 50864], "temperature": 0.0, "avg_logprob": -0.04111080699496799, "compression_ratio": 2.1865079365079363, "no_speech_prob": 0.250823974609375}, {"id": 52, "seek": 28848, "start": 298.48, "end": 302.96000000000004, "text": " convolutional network by the way this is what we're building okay you'll notice that this image", "tokens": [50864, 45216, 304, 3209, 538, 264, 636, 341, 307, 437, 321, 434, 2390, 1392, 291, 603, 3449, 300, 341, 3256, 51088], "temperature": 0.0, "avg_logprob": -0.04111080699496799, "compression_ratio": 2.1865079365079363, "no_speech_prob": 0.250823974609375}, {"id": 53, "seek": 28848, "start": 302.96000000000004, "end": 307.76, "text": " right here or this image of the convolutional network isn't what you normally look at when", "tokens": [51088, 558, 510, 420, 341, 3256, 295, 264, 45216, 304, 3209, 1943, 380, 437, 291, 5646, 574, 412, 562, 51328], "temperature": 0.0, "avg_logprob": -0.04111080699496799, "compression_ratio": 2.1865079365079363, "no_speech_prob": 0.250823974609375}, {"id": 54, "seek": 28848, "start": 307.76, "end": 311.28000000000003, "text": " you think of neural network right you always see that image of the circles and everything's", "tokens": [51328, 291, 519, 295, 18161, 3209, 558, 291, 1009, 536, 300, 3256, 295, 264, 13040, 293, 1203, 311, 51504], "temperature": 0.0, "avg_logprob": -0.04111080699496799, "compression_ratio": 2.1865079365079363, "no_speech_prob": 0.250823974609375}, {"id": 55, "seek": 28848, "start": 311.28000000000003, "end": 317.52000000000004, "text": " connected so why is it different for convolutional networks because every layer in a convolutional", "tokens": [51504, 4582, 370, 983, 307, 309, 819, 337, 45216, 304, 9590, 570, 633, 4583, 294, 257, 45216, 304, 51816], "temperature": 0.0, "avg_logprob": -0.04111080699496799, "compression_ratio": 2.1865079365079363, "no_speech_prob": 0.250823974609375}, {"id": 56, "seek": 31752, "start": 317.52, "end": 324.08, "text": " network isn't connected to every so every neuron in every layer isn't connected to every other neuron", "tokens": [50364, 3209, 1943, 380, 4582, 281, 633, 370, 633, 34090, 294, 633, 4583, 1943, 380, 4582, 281, 633, 661, 34090, 50692], "temperature": 0.0, "avg_logprob": -0.061789031686453985, "compression_ratio": 2.0246913580246915, "no_speech_prob": 0.005729710217565298}, {"id": 57, "seek": 31752, "start": 324.08, "end": 330.47999999999996, "text": " in the next layer why because that would be too computationally expensive i'll go over that in", "tokens": [50692, 294, 264, 958, 4583, 983, 570, 300, 576, 312, 886, 24903, 379, 5124, 741, 603, 352, 670, 300, 294, 51012], "temperature": 0.0, "avg_logprob": -0.061789031686453985, "compression_ratio": 2.0246913580246915, "no_speech_prob": 0.005729710217565298}, {"id": 58, "seek": 31752, "start": 330.47999999999996, "end": 335.35999999999996, "text": " a second but the idea is that if you if you see here there is a part of the image that is connected", "tokens": [51012, 257, 1150, 457, 264, 1558, 307, 300, 498, 291, 498, 291, 536, 510, 456, 307, 257, 644, 295, 264, 3256, 300, 307, 4582, 51256], "temperature": 0.0, "avg_logprob": -0.061789031686453985, "compression_ratio": 2.0246913580246915, "no_speech_prob": 0.005729710217565298}, {"id": 59, "seek": 31752, "start": 335.35999999999996, "end": 340.88, "text": " it's this little square of that orange and that is called the receptive field okay i'm going to go", "tokens": [51256, 309, 311, 341, 707, 3732, 295, 300, 7671, 293, 300, 307, 1219, 264, 45838, 2519, 1392, 741, 478, 516, 281, 352, 51532], "temperature": 0.0, "avg_logprob": -0.061789031686453985, "compression_ratio": 2.0246913580246915, "no_speech_prob": 0.005729710217565298}, {"id": 60, "seek": 31752, "start": 340.88, "end": 343.84, "text": " over all this it's going to make more and more sense you're going to be more confused it's going", "tokens": [51532, 670, 439, 341, 309, 311, 516, 281, 652, 544, 293, 544, 2020, 291, 434, 516, 281, 312, 544, 9019, 309, 311, 516, 51680], "temperature": 0.0, "avg_logprob": -0.061789031686453985, "compression_ratio": 2.0246913580246915, "no_speech_prob": 0.005729710217565298}, {"id": 61, "seek": 34384, "start": 344.15999999999997, "end": 348.79999999999995, "text": " it's going to make more and more sense as as i go further and further in depth here so so so stay", "tokens": [50380, 309, 311, 516, 281, 652, 544, 293, 544, 2020, 382, 382, 741, 352, 3052, 293, 3052, 294, 7161, 510, 370, 370, 370, 1754, 50612], "temperature": 0.0, "avg_logprob": -0.06859396285369616, "compression_ratio": 2.008298755186722, "no_speech_prob": 0.008061380125582218}, {"id": 62, "seek": 34384, "start": 348.79999999999995, "end": 354.88, "text": " with me here so we have a receptive field okay that is some part of the image that we are focused on", "tokens": [50612, 365, 385, 510, 370, 321, 362, 257, 45838, 2519, 1392, 300, 307, 512, 644, 295, 264, 3256, 300, 321, 366, 5178, 322, 50916], "temperature": 0.0, "avg_logprob": -0.06859396285369616, "compression_ratio": 2.008298755186722, "no_speech_prob": 0.008061380125582218}, {"id": 63, "seek": 34384, "start": 354.88, "end": 360.32, "text": " we are by focused i mean that is the part of the image that we apply a convolution operation to", "tokens": [50916, 321, 366, 538, 5178, 741, 914, 300, 307, 264, 644, 295, 264, 3256, 300, 321, 3079, 257, 45216, 6916, 281, 51188], "temperature": 0.0, "avg_logprob": -0.06859396285369616, "compression_ratio": 2.008298755186722, "no_speech_prob": 0.008061380125582218}, {"id": 64, "seek": 34384, "start": 360.96, "end": 366.32, "text": " okay and we take that receptive field and we slide it across the image okay you're going to see", "tokens": [51220, 1392, 293, 321, 747, 300, 45838, 2519, 293, 321, 4137, 309, 2108, 264, 3256, 1392, 291, 434, 516, 281, 536, 51488], "temperature": 0.0, "avg_logprob": -0.06859396285369616, "compression_ratio": 2.008298755186722, "no_speech_prob": 0.008061380125582218}, {"id": 65, "seek": 34384, "start": 366.32, "end": 370.71999999999997, "text": " exactly what i'm talking about in a second i'm just going to go over at a high level we slide", "tokens": [51488, 2293, 437, 741, 478, 1417, 466, 294, 257, 1150, 741, 478, 445, 516, 281, 352, 670, 412, 257, 1090, 1496, 321, 4137, 51708], "temperature": 0.0, "avg_logprob": -0.06859396285369616, "compression_ratio": 2.008298755186722, "no_speech_prob": 0.008061380125582218}, {"id": 66, "seek": 37072, "start": 370.72, "end": 376.48, "text": " over the image we are applying a dot product between our weight matrix at a layer and every", "tokens": [50364, 670, 264, 3256, 321, 366, 9275, 257, 5893, 1674, 1296, 527, 3364, 8141, 412, 257, 4583, 293, 633, 50652], "temperature": 0.0, "avg_logprob": -0.03473749756813049, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.007815415039658546}, {"id": 67, "seek": 37072, "start": 376.48, "end": 382.16, "text": " part of that image iteratively okay and so that the reason that they look different the convolutional", "tokens": [50652, 644, 295, 300, 3256, 17138, 19020, 1392, 293, 370, 300, 264, 1778, 300, 436, 574, 819, 264, 45216, 304, 50936], "temperature": 0.0, "avg_logprob": -0.03473749756813049, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.007815415039658546}, {"id": 68, "seek": 37072, "start": 382.16, "end": 388.0, "text": " networks look different is two reasons really the first reason is that not every neuron in each", "tokens": [50936, 9590, 574, 819, 307, 732, 4112, 534, 264, 700, 1778, 307, 300, 406, 633, 34090, 294, 1184, 51228], "temperature": 0.0, "avg_logprob": -0.03473749756813049, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.007815415039658546}, {"id": 69, "seek": 37072, "start": 388.0, "end": 392.72, "text": " layer is connected to every other neuron in the next layer it's only a part of that because it", "tokens": [51228, 4583, 307, 4582, 281, 633, 661, 34090, 294, 264, 958, 4583, 309, 311, 787, 257, 644, 295, 300, 570, 309, 51464], "temperature": 0.0, "avg_logprob": -0.03473749756813049, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.007815415039658546}, {"id": 70, "seek": 37072, "start": 392.72, "end": 399.04, "text": " would be a to borrow from discrete math a combinatorial explosion to connect every single pixel", "tokens": [51464, 576, 312, 257, 281, 11172, 490, 27706, 5221, 257, 2512, 31927, 831, 15673, 281, 1745, 633, 2167, 19261, 51780], "temperature": 0.0, "avg_logprob": -0.03473749756813049, "compression_ratio": 1.8532818532818534, "no_speech_prob": 0.007815415039658546}, {"id": 71, "seek": 39904, "start": 399.04, "end": 405.04, "text": " value in an image to every single pixel value in the next layer of features right it would be", "tokens": [50364, 2158, 294, 364, 3256, 281, 633, 2167, 19261, 2158, 294, 264, 958, 4583, 295, 4122, 558, 309, 576, 312, 50664], "temperature": 0.0, "avg_logprob": -0.050325925371288195, "compression_ratio": 1.924901185770751, "no_speech_prob": 0.003945125732570887}, {"id": 72, "seek": 39904, "start": 405.04, "end": 410.88, "text": " just a huge amount so what we do instead is we take a part of that image and we iteratively slide", "tokens": [50664, 445, 257, 2603, 2372, 370, 437, 321, 360, 2602, 307, 321, 747, 257, 644, 295, 300, 3256, 293, 321, 17138, 19020, 4137, 50956], "temperature": 0.0, "avg_logprob": -0.050325925371288195, "compression_ratio": 1.924901185770751, "no_speech_prob": 0.003945125732570887}, {"id": 73, "seek": 39904, "start": 410.88, "end": 415.36, "text": " over it okay so at a high level you understand the sliding part right think of it as a flashlight", "tokens": [50956, 670, 309, 1392, 370, 412, 257, 1090, 1496, 291, 1223, 264, 21169, 644, 558, 519, 295, 309, 382, 257, 30835, 51180], "temperature": 0.0, "avg_logprob": -0.050325925371288195, "compression_ratio": 1.924901185770751, "no_speech_prob": 0.003945125732570887}, {"id": 74, "seek": 39904, "start": 415.36, "end": 420.56, "text": " okay think of it think of the uh the filter at each layer that shines over the receptive field", "tokens": [51180, 1392, 519, 295, 309, 519, 295, 264, 2232, 264, 6608, 412, 1184, 4583, 300, 28056, 670, 264, 45838, 2519, 51440], "temperature": 0.0, "avg_logprob": -0.050325925371288195, "compression_ratio": 1.924901185770751, "no_speech_prob": 0.003945125732570887}, {"id": 75, "seek": 39904, "start": 420.56, "end": 426.08000000000004, "text": " that box as a flashlight and you're shining over the image and you're and you're applying dot products", "tokens": [51440, 300, 2424, 382, 257, 30835, 293, 291, 434, 18269, 670, 264, 3256, 293, 291, 434, 293, 291, 434, 9275, 5893, 3383, 51716], "temperature": 0.0, "avg_logprob": -0.050325925371288195, "compression_ratio": 1.924901185770751, "no_speech_prob": 0.003945125732570887}, {"id": 76, "seek": 42608, "start": 426.08, "end": 430.8, "text": " to all of these numbers okay just like that okay i'm going to keep going into this that was just", "tokens": [50364, 281, 439, 295, 613, 3547, 1392, 445, 411, 300, 1392, 741, 478, 516, 281, 1066, 516, 666, 341, 300, 390, 445, 50600], "temperature": 0.0, "avg_logprob": -0.04319029914008247, "compression_ratio": 2.108303249097473, "no_speech_prob": 0.061864983290433884}, {"id": 77, "seek": 42608, "start": 430.8, "end": 434.08, "text": " the highest level you're not supposed to understand it all yet okay that was that was very high level", "tokens": [50600, 264, 6343, 1496, 291, 434, 406, 3442, 281, 1223, 309, 439, 1939, 1392, 300, 390, 300, 390, 588, 1090, 1496, 50764], "temperature": 0.0, "avg_logprob": -0.04319029914008247, "compression_ratio": 2.108303249097473, "no_speech_prob": 0.061864983290433884}, {"id": 78, "seek": 42608, "start": 434.08, "end": 438.8, "text": " we're still going deeper we're going deep we're going deep okay so check out this beautiful image", "tokens": [50764, 321, 434, 920, 516, 7731, 321, 434, 516, 2452, 321, 434, 516, 2452, 1392, 370, 1520, 484, 341, 2238, 3256, 51000], "temperature": 0.0, "avg_logprob": -0.04319029914008247, "compression_ratio": 2.108303249097473, "no_speech_prob": 0.061864983290433884}, {"id": 79, "seek": 42608, "start": 438.8, "end": 442.88, "text": " right here isn't it beautiful it's very beautiful also you're beautiful for watching this so thank", "tokens": [51000, 558, 510, 1943, 380, 309, 2238, 309, 311, 588, 2238, 611, 291, 434, 2238, 337, 1976, 341, 370, 1309, 51204], "temperature": 0.0, "avg_logprob": -0.04319029914008247, "compression_ratio": 2.108303249097473, "no_speech_prob": 0.061864983290433884}, {"id": 80, "seek": 42608, "start": 442.88, "end": 449.28, "text": " you for watching this okay so i love my fans so much seriously you guys are amazing seriously", "tokens": [51204, 291, 337, 1976, 341, 1392, 370, 741, 959, 452, 4499, 370, 709, 6638, 291, 1074, 366, 2243, 6638, 51524], "temperature": 0.0, "avg_logprob": -0.04319029914008247, "compression_ratio": 2.108303249097473, "no_speech_prob": 0.061864983290433884}, {"id": 81, "seek": 42608, "start": 449.28, "end": 455.28, "text": " you guys are the reason i do this every week okay so i by the way i want to say one more thing", "tokens": [51524, 291, 1074, 366, 264, 1778, 741, 360, 341, 633, 1243, 1392, 370, 741, 538, 264, 636, 741, 528, 281, 584, 472, 544, 551, 51824], "temperature": 0.0, "avg_logprob": -0.04319029914008247, "compression_ratio": 2.108303249097473, "no_speech_prob": 0.061864983290433884}, {"id": 82, "seek": 45528, "start": 455.28, "end": 461.11999999999995, "text": " to go on a tangent the people who subscribe to my channel no one thought they existed we are", "tokens": [50364, 281, 352, 322, 257, 27747, 264, 561, 567, 3022, 281, 452, 2269, 572, 472, 1194, 436, 13135, 321, 366, 50656], "temperature": 0.0, "avg_logprob": -0.02836049149889465, "compression_ratio": 1.9467213114754098, "no_speech_prob": 0.02095867693424225}, {"id": 83, "seek": 45528, "start": 461.11999999999995, "end": 467.67999999999995, "text": " programmers who are smart and we are also cool no one thought these people existed but we exist", "tokens": [50656, 41504, 567, 366, 4069, 293, 321, 366, 611, 1627, 572, 472, 1194, 613, 561, 13135, 457, 321, 2514, 50984], "temperature": 0.0, "avg_logprob": -0.02836049149889465, "compression_ratio": 1.9467213114754098, "no_speech_prob": 0.02095867693424225}, {"id": 84, "seek": 45528, "start": 467.67999999999995, "end": 473.76, "text": " okay we are smart and we are cool so you are amazing okay anyway back to this what this is", "tokens": [50984, 1392, 321, 366, 4069, 293, 321, 366, 1627, 370, 291, 366, 2243, 1392, 4033, 646, 281, 341, 437, 341, 307, 51288], "temperature": 0.0, "avg_logprob": -0.02836049149889465, "compression_ratio": 1.9467213114754098, "no_speech_prob": 0.02095867693424225}, {"id": 85, "seek": 45528, "start": 473.76, "end": 477.11999999999995, "text": " is another way of looking at the network right we're just looking at different ways we're looking", "tokens": [51288, 307, 1071, 636, 295, 1237, 412, 264, 3209, 558, 321, 434, 445, 1237, 412, 819, 2098, 321, 434, 1237, 51456], "temperature": 0.0, "avg_logprob": -0.02836049149889465, "compression_ratio": 1.9467213114754098, "no_speech_prob": 0.02095867693424225}, {"id": 86, "seek": 45528, "start": 477.11999999999995, "end": 483.11999999999995, "text": " at different ways so we can build a spatially invariant image in our head of what a convolutional", "tokens": [51456, 412, 819, 2098, 370, 321, 393, 1322, 257, 15000, 2270, 33270, 394, 3256, 294, 527, 1378, 295, 437, 257, 45216, 304, 51756], "temperature": 0.0, "avg_logprob": -0.02836049149889465, "compression_ratio": 1.9467213114754098, "no_speech_prob": 0.02095867693424225}, {"id": 87, "seek": 48312, "start": 483.12, "end": 488.8, "text": " network is like right no matter what that image is we're going to learn to recognize a convolutional", "tokens": [50364, 3209, 307, 411, 558, 572, 1871, 437, 300, 3256, 307, 321, 434, 516, 281, 1466, 281, 5521, 257, 45216, 304, 50648], "temperature": 0.0, "avg_logprob": -0.05946111241611866, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.09264416992664337}, {"id": 88, "seek": 48312, "start": 488.8, "end": 493.44, "text": " network when we see one i'm just trying to you know meta applying this logic to what we're learning", "tokens": [50648, 3209, 562, 321, 536, 472, 741, 478, 445, 1382, 281, 291, 458, 19616, 9275, 341, 9952, 281, 437, 321, 434, 2539, 50880], "temperature": 0.0, "avg_logprob": -0.05946111241611866, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.09264416992664337}, {"id": 89, "seek": 48312, "start": 493.44, "end": 498.64, "text": " so what happens is that each layer we are applying a series of dot products between the", "tokens": [50880, 370, 437, 2314, 307, 300, 1184, 4583, 321, 366, 9275, 257, 2638, 295, 5893, 3383, 1296, 264, 51140], "temperature": 0.0, "avg_logprob": -0.05946111241611866, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.09264416992664337}, {"id": 90, "seek": 48312, "start": 498.64, "end": 505.04, "text": " weight matrices and the input matrix okay and so what happens is let's look at a third image okay", "tokens": [51140, 3364, 32284, 293, 264, 4846, 8141, 1392, 293, 370, 437, 2314, 307, 718, 311, 574, 412, 257, 2636, 3256, 1392, 51460], "temperature": 0.0, "avg_logprob": -0.05946111241611866, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.09264416992664337}, {"id": 91, "seek": 48312, "start": 505.04, "end": 510.96, "text": " so this is a third image what happens is we perform a series of operations okay at each layer", "tokens": [51460, 370, 341, 307, 257, 2636, 3256, 437, 2314, 307, 321, 2042, 257, 2638, 295, 7705, 1392, 412, 1184, 4583, 51756], "temperature": 0.0, "avg_logprob": -0.05946111241611866, "compression_ratio": 1.9591836734693877, "no_speech_prob": 0.09264416992664337}, {"id": 92, "seek": 51096, "start": 511.03999999999996, "end": 516.0, "text": " and so we could think of of different we could think of splitting up a convolutional network", "tokens": [50368, 293, 370, 321, 727, 519, 295, 295, 819, 321, 727, 519, 295, 30348, 493, 257, 45216, 304, 3209, 50616], "temperature": 0.0, "avg_logprob": -0.07209023521060036, "compression_ratio": 2.206422018348624, "no_speech_prob": 0.007120552938431501}, {"id": 93, "seek": 51096, "start": 516.0, "end": 521.76, "text": " into two separate categories the first category is feature learning and that's what's happening at the", "tokens": [50616, 666, 732, 4994, 10479, 264, 700, 7719, 307, 4111, 2539, 293, 300, 311, 437, 311, 2737, 412, 264, 50904], "temperature": 0.0, "avg_logprob": -0.07209023521060036, "compression_ratio": 2.206422018348624, "no_speech_prob": 0.007120552938431501}, {"id": 94, "seek": 51096, "start": 521.76, "end": 528.0, "text": " at the at the head of the the head to the middle to almost the tail end of the network and at the", "tokens": [50904, 412, 264, 412, 264, 1378, 295, 264, 264, 1378, 281, 264, 2808, 281, 1920, 264, 6838, 917, 295, 264, 3209, 293, 412, 264, 51216], "temperature": 0.0, "avg_logprob": -0.07209023521060036, "compression_ratio": 2.206422018348624, "no_speech_prob": 0.007120552938431501}, {"id": 95, "seek": 51096, "start": 528.0, "end": 533.1999999999999, "text": " very tail end is classification so there's two parts there's the feature learning part and then", "tokens": [51216, 588, 6838, 917, 307, 21538, 370, 456, 311, 732, 3166, 456, 311, 264, 4111, 2539, 644, 293, 550, 51476], "temperature": 0.0, "avg_logprob": -0.07209023521060036, "compression_ratio": 2.206422018348624, "no_speech_prob": 0.007120552938431501}, {"id": 96, "seek": 51096, "start": 533.1999999999999, "end": 538.24, "text": " there's the classification part and so for the feature learning part what happens are three", "tokens": [51476, 456, 311, 264, 21538, 644, 293, 370, 337, 264, 4111, 2539, 644, 437, 2314, 366, 1045, 51728], "temperature": 0.0, "avg_logprob": -0.07209023521060036, "compression_ratio": 2.206422018348624, "no_speech_prob": 0.007120552938431501}, {"id": 97, "seek": 53824, "start": 538.24, "end": 544.48, "text": " operations over and over and over again and we can call them convolutional blocks let's just call", "tokens": [50364, 7705, 670, 293, 670, 293, 670, 797, 293, 321, 393, 818, 552, 45216, 304, 8474, 718, 311, 445, 818, 50676], "temperature": 0.0, "avg_logprob": -0.06329127643885238, "compression_ratio": 2.1135135135135137, "no_speech_prob": 0.009708019904792309}, {"id": 98, "seek": 53824, "start": 544.48, "end": 550.08, "text": " them convolutional blocks i'm coining the term so what happens is we first apply convolution", "tokens": [50676, 552, 45216, 304, 8474, 741, 478, 598, 1760, 264, 1433, 370, 437, 2314, 307, 321, 700, 3079, 45216, 50956], "temperature": 0.0, "avg_logprob": -0.06329127643885238, "compression_ratio": 2.1135135135135137, "no_speech_prob": 0.009708019904792309}, {"id": 99, "seek": 53824, "start": 550.08, "end": 557.04, "text": " then we apply relu or any kind of activation and then we apply pooling and we repeat that that's", "tokens": [50956, 550, 321, 3079, 1039, 84, 420, 604, 733, 295, 24433, 293, 550, 321, 3079, 7005, 278, 293, 321, 7149, 300, 300, 311, 51304], "temperature": 0.0, "avg_logprob": -0.06329127643885238, "compression_ratio": 2.1135135135135137, "no_speech_prob": 0.009708019904792309}, {"id": 100, "seek": 53824, "start": 557.04, "end": 563.36, "text": " that's a single block three operations in a single convolutional block okay so convolution relu pooling", "tokens": [51304, 300, 311, 257, 2167, 3461, 1045, 7705, 294, 257, 2167, 45216, 304, 3461, 1392, 370, 45216, 1039, 84, 7005, 278, 51620], "temperature": 0.0, "avg_logprob": -0.06329127643885238, "compression_ratio": 2.1135135135135137, "no_speech_prob": 0.009708019904792309}, {"id": 101, "seek": 56336, "start": 563.36, "end": 569.36, "text": " repeat convolution relu pooling repeat convolution relu pooling okay and usually you know you have", "tokens": [50364, 7149, 45216, 1039, 84, 7005, 278, 7149, 45216, 1039, 84, 7005, 278, 1392, 293, 2673, 291, 458, 291, 362, 50664], "temperature": 0.0, "avg_logprob": -0.06913764971607136, "compression_ratio": 1.9673469387755103, "no_speech_prob": 0.03409741446375847}, {"id": 102, "seek": 56336, "start": 569.36, "end": 574.5600000000001, "text": " three blocks at least unless you're building inception by google then you have 15 15 of these", "tokens": [50664, 1045, 8474, 412, 1935, 5969, 291, 434, 2390, 49834, 538, 20742, 550, 291, 362, 2119, 2119, 295, 613, 50924], "temperature": 0.0, "avg_logprob": -0.06913764971607136, "compression_ratio": 1.9673469387755103, "no_speech_prob": 0.03409741446375847}, {"id": 103, "seek": 56336, "start": 575.44, "end": 579.52, "text": " but you you know you have these convolutional blocks and at the very end then you flatten", "tokens": [50968, 457, 291, 291, 458, 291, 362, 613, 45216, 304, 8474, 293, 412, 264, 588, 917, 550, 291, 24183, 51172], "temperature": 0.0, "avg_logprob": -0.06913764971607136, "compression_ratio": 1.9673469387755103, "no_speech_prob": 0.03409741446375847}, {"id": 104, "seek": 56336, "start": 579.52, "end": 585.6800000000001, "text": " that output into a smaller dimensional vector and then you apply a fully connected layer to it so", "tokens": [51172, 300, 5598, 666, 257, 4356, 18795, 8062, 293, 550, 291, 3079, 257, 4498, 4582, 4583, 281, 309, 370, 51480], "temperature": 0.0, "avg_logprob": -0.06913764971607136, "compression_ratio": 1.9673469387755103, "no_speech_prob": 0.03409741446375847}, {"id": 105, "seek": 56336, "start": 585.6800000000001, "end": 590.88, "text": " that means that you then connect all the neurons in one layer to the next one just because we want to", "tokens": [51480, 300, 1355, 300, 291, 550, 1745, 439, 264, 22027, 294, 472, 4583, 281, 264, 958, 472, 445, 570, 321, 528, 281, 51740], "temperature": 0.0, "avg_logprob": -0.06913764971607136, "compression_ratio": 1.9673469387755103, "no_speech_prob": 0.03409741446375847}, {"id": 106, "seek": 59088, "start": 590.88, "end": 596.16, "text": " then harness all of the learnings that we've learned so far that's why we fully connect at the end", "tokens": [50364, 550, 19700, 439, 295, 264, 2539, 82, 300, 321, 600, 3264, 370, 1400, 300, 311, 983, 321, 4498, 1745, 412, 264, 917, 50628], "temperature": 0.0, "avg_logprob": -0.04921718301444218, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.007121086586266756}, {"id": 107, "seek": 59088, "start": 596.16, "end": 602.08, "text": " and then we take those learnings and we squash it into a set of probability values with our last", "tokens": [50628, 293, 550, 321, 747, 729, 2539, 82, 293, 321, 30725, 309, 666, 257, 992, 295, 8482, 4190, 365, 527, 1036, 50924], "temperature": 0.0, "avg_logprob": -0.04921718301444218, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.007121086586266756}, {"id": 108, "seek": 59088, "start": 602.08, "end": 607.6, "text": " softmax function and then we take the max value of those probabilities and each of these probabilities", "tokens": [50924, 2787, 41167, 2445, 293, 550, 321, 747, 264, 11469, 2158, 295, 729, 33783, 293, 1184, 295, 613, 33783, 51200], "temperature": 0.0, "avg_logprob": -0.04921718301444218, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.007121086586266756}, {"id": 109, "seek": 59088, "start": 607.6, "end": 613.4399999999999, "text": " is a probability for a for specific class that it could be and we take the max value let's say 72", "tokens": [51200, 307, 257, 8482, 337, 257, 337, 2685, 1508, 300, 309, 727, 312, 293, 321, 747, 264, 11469, 2158, 718, 311, 584, 18731, 51492], "temperature": 0.0, "avg_logprob": -0.04921718301444218, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.007121086586266756}, {"id": 110, "seek": 59088, "start": 613.4399999999999, "end": 619.44, "text": " percent as and we'll say okay well 72 percent for banana and now we know it's a banana okay so", "tokens": [51492, 3043, 382, 293, 321, 603, 584, 1392, 731, 18731, 3043, 337, 14194, 293, 586, 321, 458, 309, 311, 257, 14194, 1392, 370, 51792], "temperature": 0.0, "avg_logprob": -0.04921718301444218, "compression_ratio": 1.9959349593495934, "no_speech_prob": 0.007121086586266756}, {"id": 111, "seek": 61944, "start": 620.1600000000001, "end": 624.48, "text": " hopefully you get some of it but it's very confusing still i know we're about to go even", "tokens": [50400, 4696, 291, 483, 512, 295, 309, 457, 309, 311, 588, 13181, 920, 741, 458, 321, 434, 466, 281, 352, 754, 50616], "temperature": 0.0, "avg_logprob": -0.04262954097683147, "compression_ratio": 2.1106194690265485, "no_speech_prob": 0.00017952578491531312}, {"id": 112, "seek": 61944, "start": 624.48, "end": 629.7600000000001, "text": " deeper okay so get ready for this i haven't even started yet so i haven't even started yet okay so", "tokens": [50616, 7731, 1392, 370, 483, 1919, 337, 341, 741, 2378, 380, 754, 1409, 1939, 370, 741, 2378, 380, 754, 1409, 1939, 1392, 370, 50880], "temperature": 0.0, "avg_logprob": -0.04262954097683147, "compression_ratio": 2.1106194690265485, "no_speech_prob": 0.00017952578491531312}, {"id": 113, "seek": 61944, "start": 629.7600000000001, "end": 637.0400000000001, "text": " anyway step one so for step one we are preparing a data set of images right so when you think of an", "tokens": [50880, 4033, 1823, 472, 370, 337, 1823, 472, 321, 366, 10075, 257, 1412, 992, 295, 5267, 558, 370, 562, 291, 519, 295, 364, 51244], "temperature": 0.0, "avg_logprob": -0.04262954097683147, "compression_ratio": 2.1106194690265485, "no_speech_prob": 0.00017952578491531312}, {"id": 114, "seek": 61944, "start": 637.0400000000001, "end": 642.24, "text": " image you think of a matrix hopefully a matrix of pixel values if you don't think of it that way", "tokens": [51244, 3256, 291, 519, 295, 257, 8141, 4696, 257, 8141, 295, 19261, 4190, 498, 291, 500, 380, 519, 295, 309, 300, 636, 51504], "temperature": 0.0, "avg_logprob": -0.04262954097683147, "compression_ratio": 2.1106194690265485, "no_speech_prob": 0.00017952578491531312}, {"id": 115, "seek": 61944, "start": 642.24, "end": 646.96, "text": " think of it think of it that way now you're thinking of an image as a matrix of pixel values", "tokens": [51504, 519, 295, 309, 519, 295, 309, 300, 636, 586, 291, 434, 1953, 295, 364, 3256, 382, 257, 8141, 295, 19261, 4190, 51740], "temperature": 0.0, "avg_logprob": -0.04262954097683147, "compression_ratio": 2.1106194690265485, "no_speech_prob": 0.00017952578491531312}, {"id": 116, "seek": 64696, "start": 646.96, "end": 650.64, "text": " rowed by columns and each of these um each of these uh", "tokens": [50364, 5386, 292, 538, 13766, 293, 1184, 295, 613, 1105, 1184, 295, 613, 2232, 50548], "temperature": 0.0, "avg_logprob": -0.10210790821150237, "compression_ratio": 1.8565217391304347, "no_speech_prob": 0.02930709347128868}, {"id": 117, "seek": 64696, "start": 653.0400000000001, "end": 660.08, "text": " points in the matrix represent a pixel right between 0 and 255 but it's actually better", "tokens": [50668, 2793, 294, 264, 8141, 2906, 257, 19261, 558, 1296, 1958, 293, 3552, 20, 457, 309, 311, 767, 1101, 51020], "temperature": 0.0, "avg_logprob": -0.10210790821150237, "compression_ratio": 1.8565217391304347, "no_speech_prob": 0.02930709347128868}, {"id": 118, "seek": 64696, "start": 660.08, "end": 664.5600000000001, "text": " in terms of convolutional networks to think of an an image as a three-dimensional matrix", "tokens": [51020, 294, 2115, 295, 45216, 304, 9590, 281, 519, 295, 364, 364, 3256, 382, 257, 1045, 12, 18759, 8141, 51244], "temperature": 0.0, "avg_logprob": -0.10210790821150237, "compression_ratio": 1.8565217391304347, "no_speech_prob": 0.02930709347128868}, {"id": 119, "seek": 64696, "start": 664.5600000000001, "end": 669.6, "text": " and you're like what no what it's no so it's three dimensions so the first dimension is the length", "tokens": [51244, 293, 291, 434, 411, 437, 572, 437, 309, 311, 572, 370, 309, 311, 1045, 12819, 370, 264, 700, 10139, 307, 264, 4641, 51496], "temperature": 0.0, "avg_logprob": -0.10210790821150237, "compression_ratio": 1.8565217391304347, "no_speech_prob": 0.02930709347128868}, {"id": 120, "seek": 64696, "start": 669.6, "end": 674.32, "text": " of the image the second dimension is the width and the third dimension is the depth so wait what", "tokens": [51496, 295, 264, 3256, 264, 1150, 10139, 307, 264, 11402, 293, 264, 2636, 10139, 307, 264, 7161, 370, 1699, 437, 51732], "temperature": 0.0, "avg_logprob": -0.10210790821150237, "compression_ratio": 1.8565217391304347, "no_speech_prob": 0.02930709347128868}, {"id": 121, "seek": 67432, "start": 674.32, "end": 680.08, "text": " is the depth because the depth represents the channels and there are three channels for images", "tokens": [50364, 307, 264, 7161, 570, 264, 7161, 8855, 264, 9235, 293, 456, 366, 1045, 9235, 337, 5267, 50652], "temperature": 0.0, "avg_logprob": -0.050955193065037235, "compression_ratio": 2.230414746543779, "no_speech_prob": 0.0013249852927401662}, {"id": 122, "seek": 67432, "start": 680.08, "end": 684.32, "text": " red green and blue unless you're talking about gray scale then there's black then there's you", "tokens": [50652, 2182, 3092, 293, 3344, 5969, 291, 434, 1417, 466, 10855, 4373, 550, 456, 311, 2211, 550, 456, 311, 291, 50864], "temperature": 0.0, "avg_logprob": -0.050955193065037235, "compression_ratio": 2.230414746543779, "no_speech_prob": 0.0013249852927401662}, {"id": 123, "seek": 67432, "start": 684.32, "end": 688.48, "text": " know black and white but we're talking about color images okay so there are three channels and you", "tokens": [50864, 458, 2211, 293, 2418, 457, 321, 434, 1417, 466, 2017, 5267, 1392, 370, 456, 366, 1045, 9235, 293, 291, 51072], "temperature": 0.0, "avg_logprob": -0.050955193065037235, "compression_ratio": 2.230414746543779, "no_speech_prob": 0.0013249852927401662}, {"id": 124, "seek": 67432, "start": 688.48, "end": 694.5600000000001, "text": " have these dimensions for each of the channels so these values in each of these um in each of these", "tokens": [51072, 362, 613, 12819, 337, 1184, 295, 264, 9235, 370, 613, 4190, 294, 1184, 295, 613, 1105, 294, 1184, 295, 613, 51376], "temperature": 0.0, "avg_logprob": -0.050955193065037235, "compression_ratio": 2.230414746543779, "no_speech_prob": 0.0013249852927401662}, {"id": 125, "seek": 67432, "start": 694.5600000000001, "end": 702.72, "text": " 2d matrices for and there are three of them represent the the amount of redness or the amount of", "tokens": [51376, 568, 67, 32284, 337, 293, 456, 366, 1045, 295, 552, 2906, 264, 264, 2372, 295, 2182, 1287, 420, 264, 2372, 295, 51784], "temperature": 0.0, "avg_logprob": -0.050955193065037235, "compression_ratio": 2.230414746543779, "no_speech_prob": 0.0013249852927401662}, {"id": 126, "seek": 70272, "start": 702.8000000000001, "end": 708.5600000000001, "text": " greenness or the amount of blueness between 0 and 255 so in terms of convolutional nets we think of", "tokens": [50368, 3092, 1287, 420, 264, 2372, 295, 3344, 1287, 1296, 1958, 293, 3552, 20, 370, 294, 2115, 295, 45216, 304, 36170, 321, 519, 295, 50656], "temperature": 0.0, "avg_logprob": -0.06321687264875932, "compression_ratio": 1.9, "no_speech_prob": 0.015187068842351437}, {"id": 127, "seek": 70272, "start": 708.5600000000001, "end": 713.6, "text": " images as three-dimensional pixels okay so i wanted to say that part okay so that's that's", "tokens": [50656, 5267, 382, 1045, 12, 18759, 18668, 1392, 370, 741, 1415, 281, 584, 300, 644, 1392, 370, 300, 311, 300, 311, 50908], "temperature": 0.0, "avg_logprob": -0.06321687264875932, "compression_ratio": 1.9, "no_speech_prob": 0.015187068842351437}, {"id": 128, "seek": 70272, "start": 713.6, "end": 719.2, "text": " that's what we think of our image as our input image and it has an associated label right we're", "tokens": [50908, 300, 311, 437, 321, 519, 295, 527, 3256, 382, 527, 4846, 3256, 293, 309, 575, 364, 6615, 7645, 558, 321, 434, 51188], "temperature": 0.0, "avg_logprob": -0.06321687264875932, "compression_ratio": 1.9, "no_speech_prob": 0.015187068842351437}, {"id": 129, "seek": 70272, "start": 719.2, "end": 723.36, "text": " talking about supervised learning learning the mapping between the input data and the output", "tokens": [51188, 1417, 466, 46533, 2539, 2539, 264, 18350, 1296, 264, 4846, 1412, 293, 264, 5598, 51396], "temperature": 0.0, "avg_logprob": -0.06321687264875932, "compression_ratio": 1.9, "no_speech_prob": 0.015187068842351437}, {"id": 130, "seek": 70272, "start": 723.36, "end": 728.88, "text": " label dog image dog label learn the mapping given a new dog image what is a label well you just", "tokens": [51396, 7645, 3000, 3256, 3000, 7645, 1466, 264, 18350, 2212, 257, 777, 3000, 3256, 437, 307, 257, 7645, 731, 291, 445, 51672], "temperature": 0.0, "avg_logprob": -0.06321687264875932, "compression_ratio": 1.9, "no_speech_prob": 0.015187068842351437}, {"id": 131, "seek": 72888, "start": 728.88, "end": 734.32, "text": " learned it right so and we learn it through back propagation back propagate to update", "tokens": [50364, 3264, 309, 558, 370, 293, 321, 1466, 309, 807, 646, 38377, 646, 48256, 281, 5623, 50636], "temperature": 0.0, "avg_logprob": -0.07019386934430412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.03732290118932724}, {"id": 132, "seek": 72888, "start": 734.32, "end": 739.28, "text": " weights remember the rhyme you know what it is hey i haven't wrapped yet in the series but i will", "tokens": [50636, 17443, 1604, 264, 34753, 291, 458, 437, 309, 307, 4177, 741, 2378, 380, 14226, 1939, 294, 264, 2638, 457, 741, 486, 50884], "temperature": 0.0, "avg_logprob": -0.07019386934430412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.03732290118932724}, {"id": 133, "seek": 72888, "start": 739.28, "end": 745.36, "text": " don't worry it's coming anyway so every image is a matrix of pixel values we know this we know this", "tokens": [50884, 500, 380, 3292, 309, 311, 1348, 4033, 370, 633, 3256, 307, 257, 8141, 295, 19261, 4190, 321, 458, 341, 321, 458, 341, 51188], "temperature": 0.0, "avg_logprob": -0.07019386934430412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.03732290118932724}, {"id": 134, "seek": 72888, "start": 745.36, "end": 753.36, "text": " between 0 and 255 and we can use several training data sets there are two really popular ones there's", "tokens": [51188, 1296, 1958, 293, 3552, 20, 293, 321, 393, 764, 2940, 3097, 1412, 6352, 456, 366, 732, 534, 3743, 2306, 456, 311, 51588], "temperature": 0.0, "avg_logprob": -0.07019386934430412, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.03732290118932724}, {"id": 135, "seek": 75336, "start": 753.44, "end": 758.4, "text": " seafar and there's cocoa and there's a bunch of other ones as well but basically these are", "tokens": [50368, 369, 47030, 293, 456, 311, 30634, 293, 456, 311, 257, 3840, 295, 661, 2306, 382, 731, 457, 1936, 613, 366, 50616], "temperature": 0.0, "avg_logprob": -0.08253870097869033, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.03021160699427128}, {"id": 136, "seek": 75336, "start": 758.4, "end": 764.0, "text": " huge data sets and you can find smaller versions of them and each of these images they're dogs", "tokens": [50616, 2603, 1412, 6352, 293, 291, 393, 915, 4356, 9606, 295, 552, 293, 1184, 295, 613, 5267, 436, 434, 7197, 50896], "temperature": 0.0, "avg_logprob": -0.08253870097869033, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.03021160699427128}, {"id": 137, "seek": 75336, "start": 764.0, "end": 769.2, "text": " they're cars they're airplanes they're people whatever they all have labels for them handmade", "tokens": [50896, 436, 434, 5163, 436, 434, 32947, 436, 434, 561, 2035, 436, 439, 362, 16949, 337, 552, 39446, 51156], "temperature": 0.0, "avg_logprob": -0.08253870097869033, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.03021160699427128}, {"id": 138, "seek": 75336, "start": 769.2, "end": 774.96, "text": " labels by humans which is great for us okay so that's that's it that's step one step one is to", "tokens": [51156, 16949, 538, 6255, 597, 307, 869, 337, 505, 1392, 370, 300, 311, 300, 311, 309, 300, 311, 1823, 472, 1823, 472, 307, 281, 51444], "temperature": 0.0, "avg_logprob": -0.08253870097869033, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.03021160699427128}, {"id": 139, "seek": 75336, "start": 774.96, "end": 780.16, "text": " get your training data which is your images which are your images step two is to perform convolution", "tokens": [51444, 483, 428, 3097, 1412, 597, 307, 428, 5267, 597, 366, 428, 5267, 1823, 732, 307, 281, 2042, 45216, 51704], "temperature": 0.0, "avg_logprob": -0.08253870097869033, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.03021160699427128}, {"id": 140, "seek": 78016, "start": 780.16, "end": 785.36, "text": " now you might be asking what is convolution well i'm here to tell you that convolution is an", "tokens": [50364, 586, 291, 1062, 312, 3365, 437, 307, 45216, 731, 741, 478, 510, 281, 980, 291, 300, 45216, 307, 364, 50624], "temperature": 0.0, "avg_logprob": -0.03449689893794239, "compression_ratio": 2.0319148936170213, "no_speech_prob": 0.038458630442619324}, {"id": 141, "seek": 78016, "start": 785.36, "end": 790.8, "text": " operation that is dope as f here's why it's dope because it's not just used in computer science", "tokens": [50624, 6916, 300, 307, 23383, 382, 283, 510, 311, 983, 309, 311, 23383, 570, 309, 311, 406, 445, 1143, 294, 3820, 3497, 50896], "temperature": 0.0, "avg_logprob": -0.03449689893794239, "compression_ratio": 2.0319148936170213, "no_speech_prob": 0.038458630442619324}, {"id": 142, "seek": 78016, "start": 790.8, "end": 795.68, "text": " and machine learning it's used in almost every field of engineering think of convolution as two", "tokens": [50896, 293, 3479, 2539, 309, 311, 1143, 294, 1920, 633, 2519, 295, 7043, 519, 295, 45216, 382, 732, 51140], "temperature": 0.0, "avg_logprob": -0.03449689893794239, "compression_ratio": 2.0319148936170213, "no_speech_prob": 0.038458630442619324}, {"id": 143, "seek": 78016, "start": 795.68, "end": 800.4, "text": " paint buckets you have one paint bucket which is red another one which is blue and what you do", "tokens": [51140, 4225, 32191, 291, 362, 472, 4225, 13058, 597, 307, 2182, 1071, 472, 597, 307, 3344, 293, 437, 291, 360, 51376], "temperature": 0.0, "avg_logprob": -0.03449689893794239, "compression_ratio": 2.0319148936170213, "no_speech_prob": 0.038458630442619324}, {"id": 144, "seek": 78016, "start": 800.4, "end": 804.72, "text": " is just smear it all over yourself no you don't do that what you do is you take these two paint", "tokens": [51376, 307, 445, 899, 14881, 309, 439, 670, 1803, 572, 291, 500, 380, 360, 300, 437, 291, 360, 307, 291, 747, 613, 732, 4225, 51592], "temperature": 0.0, "avg_logprob": -0.03449689893794239, "compression_ratio": 2.0319148936170213, "no_speech_prob": 0.038458630442619324}, {"id": 145, "seek": 78016, "start": 804.72, "end": 809.36, "text": " buckets and you combine them into one paint bucket and that new paint bucket is going to be a new", "tokens": [51592, 32191, 293, 291, 10432, 552, 666, 472, 4225, 13058, 293, 300, 777, 4225, 13058, 307, 516, 281, 312, 257, 777, 51824], "temperature": 0.0, "avg_logprob": -0.03449689893794239, "compression_ratio": 2.0319148936170213, "no_speech_prob": 0.038458630442619324}, {"id": 146, "seek": 80936, "start": 809.36, "end": 816.16, "text": " color whatever that combination of colors is that's convolution convolution is taking two separate", "tokens": [50364, 2017, 2035, 300, 6562, 295, 4577, 307, 300, 311, 45216, 45216, 307, 1940, 732, 4994, 50704], "temperature": 0.0, "avg_logprob": -0.06447503007488486, "compression_ratio": 1.915, "no_speech_prob": 0.011330682784318924}, {"id": 147, "seek": 80936, "start": 816.16, "end": 822.8000000000001, "text": " types of data or two matrices and then apply and then it's an operation that combines them so you", "tokens": [50704, 3467, 295, 1412, 420, 732, 32284, 293, 550, 3079, 293, 550, 309, 311, 364, 6916, 300, 29520, 552, 370, 291, 51036], "temperature": 0.0, "avg_logprob": -0.06447503007488486, "compression_ratio": 1.915, "no_speech_prob": 0.011330682784318924}, {"id": 148, "seek": 80936, "start": 822.8000000000001, "end": 827.6800000000001, "text": " could think of convolution as synonymous to combination okay and why do we apply why do we", "tokens": [51036, 727, 519, 295, 45216, 382, 5451, 18092, 281, 6562, 1392, 293, 983, 360, 321, 3079, 983, 360, 321, 51280], "temperature": 0.0, "avg_logprob": -0.06447503007488486, "compression_ratio": 1.915, "no_speech_prob": 0.011330682784318924}, {"id": 149, "seek": 80936, "start": 827.6800000000001, "end": 834.16, "text": " say that for convolutional networks because what we're doing is we are combining the values for", "tokens": [51280, 584, 300, 337, 45216, 304, 9590, 570, 437, 321, 434, 884, 307, 321, 366, 21928, 264, 4190, 337, 51604], "temperature": 0.0, "avg_logprob": -0.06447503007488486, "compression_ratio": 1.915, "no_speech_prob": 0.011330682784318924}, {"id": 150, "seek": 83416, "start": 834.16, "end": 839.8399999999999, "text": " each of these layers with the input matrix so think of the input as that matrix right and so", "tokens": [50364, 1184, 295, 613, 7914, 365, 264, 4846, 8141, 370, 519, 295, 264, 4846, 382, 300, 8141, 558, 293, 370, 50648], "temperature": 0.0, "avg_logprob": -0.05822976942985288, "compression_ratio": 2.00418410041841, "no_speech_prob": 0.14801178872585297}, {"id": 151, "seek": 83416, "start": 839.8399999999999, "end": 844.64, "text": " well it's a three-dimensional it's a it's a it's a it's a 3d tensor right but we're applying it to", "tokens": [50648, 731, 309, 311, 257, 1045, 12, 18759, 309, 311, 257, 309, 311, 257, 309, 311, 257, 309, 311, 257, 805, 67, 40863, 558, 457, 321, 434, 9275, 309, 281, 50888], "temperature": 0.0, "avg_logprob": -0.05822976942985288, "compression_ratio": 2.00418410041841, "no_speech_prob": 0.14801178872585297}, {"id": 152, "seek": 83416, "start": 844.64, "end": 848.8, "text": " each of these dimensions right so three of them so just think of it as a matrix for right now", "tokens": [50888, 1184, 295, 613, 12819, 558, 370, 1045, 295, 552, 370, 445, 519, 295, 309, 382, 257, 8141, 337, 558, 586, 51096], "temperature": 0.0, "avg_logprob": -0.05822976942985288, "compression_ratio": 2.00418410041841, "no_speech_prob": 0.14801178872585297}, {"id": 153, "seek": 83416, "start": 848.8, "end": 856.8, "text": " and so what we do is we take this so at each layer at each layer there is a weight so by the way", "tokens": [51096, 293, 370, 437, 321, 360, 307, 321, 747, 341, 370, 412, 1184, 4583, 412, 1184, 4583, 456, 307, 257, 3364, 370, 538, 264, 636, 51496], "temperature": 0.0, "avg_logprob": -0.05822976942985288, "compression_ratio": 2.00418410041841, "no_speech_prob": 0.14801178872585297}, {"id": 154, "seek": 83416, "start": 856.8, "end": 861.92, "text": " okay so there's a lot of interchangeable terms in machine learning and it's easy to get confused", "tokens": [51496, 1392, 370, 456, 311, 257, 688, 295, 30358, 712, 2115, 294, 3479, 2539, 293, 309, 311, 1858, 281, 483, 9019, 51752], "temperature": 0.0, "avg_logprob": -0.05822976942985288, "compression_ratio": 2.00418410041841, "no_speech_prob": 0.14801178872585297}, {"id": 155, "seek": 86192, "start": 861.92, "end": 868.0799999999999, "text": " here but i want to set the record straight for a second weight is the same as feature matrix is", "tokens": [50364, 510, 457, 741, 528, 281, 992, 264, 2136, 2997, 337, 257, 1150, 3364, 307, 264, 912, 382, 4111, 8141, 307, 50672], "temperature": 0.0, "avg_logprob": -0.07772579918736996, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.02595418505370617}, {"id": 156, "seek": 86192, "start": 868.0799999999999, "end": 875.5999999999999, "text": " the same as feature map is the same as a filter in this case in for convolutional networks so you", "tokens": [50672, 264, 912, 382, 4111, 4471, 307, 264, 912, 382, 257, 6608, 294, 341, 1389, 294, 337, 45216, 304, 9590, 370, 291, 51048], "temperature": 0.0, "avg_logprob": -0.07772579918736996, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.02595418505370617}, {"id": 157, "seek": 86192, "start": 875.5999999999999, "end": 880.4799999999999, "text": " see these or even kernel kernel is a different one there's actually five interchangeable terms so i", "tokens": [51048, 536, 613, 420, 754, 28256, 28256, 307, 257, 819, 472, 456, 311, 767, 1732, 30358, 712, 2115, 370, 741, 51292], "temperature": 0.0, "avg_logprob": -0.07772579918736996, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.02595418505370617}, {"id": 158, "seek": 86192, "start": 880.4799999999999, "end": 886.56, "text": " can see how it can be confusing but if you get the basic idea of you have an input matrix which is", "tokens": [51292, 393, 536, 577, 309, 393, 312, 13181, 457, 498, 291, 483, 264, 3875, 1558, 295, 291, 362, 364, 4846, 8141, 597, 307, 51596], "temperature": 0.0, "avg_logprob": -0.07772579918736996, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.02595418505370617}, {"id": 159, "seek": 88656, "start": 886.56, "end": 892.88, "text": " your image and then you have a set of matrices which are your features that are learned you know", "tokens": [50364, 428, 3256, 293, 550, 291, 362, 257, 992, 295, 32284, 597, 366, 428, 4122, 300, 366, 3264, 291, 458, 50680], "temperature": 0.0, "avg_logprob": -0.029491223670818186, "compression_ratio": 2.13215859030837, "no_speech_prob": 0.01566283218562603}, {"id": 160, "seek": 88656, "start": 892.88, "end": 901.3599999999999, "text": " edges shapes more abstract shapes that's it that's that's all it is matrix dot product matrices that", "tokens": [50680, 8819, 10854, 544, 12649, 10854, 300, 311, 309, 300, 311, 300, 311, 439, 309, 307, 8141, 5893, 1674, 32284, 300, 51104], "temperature": 0.0, "avg_logprob": -0.029491223670818186, "compression_ratio": 2.13215859030837, "no_speech_prob": 0.01566283218562603}, {"id": 161, "seek": 88656, "start": 901.3599999999999, "end": 905.76, "text": " are being multiplied by matrices all the way through that's that's all it is matrices that are", "tokens": [51104, 366, 885, 17207, 538, 32284, 439, 264, 636, 807, 300, 311, 300, 311, 439, 309, 307, 32284, 300, 366, 51324], "temperature": 0.0, "avg_logprob": -0.029491223670818186, "compression_ratio": 2.13215859030837, "no_speech_prob": 0.01566283218562603}, {"id": 162, "seek": 88656, "start": 905.76, "end": 909.68, "text": " being multiplied by matrices all the way through just a chain of them okay so what happens for", "tokens": [51324, 885, 17207, 538, 32284, 439, 264, 636, 807, 445, 257, 5021, 295, 552, 1392, 370, 437, 2314, 337, 51520], "temperature": 0.0, "avg_logprob": -0.029491223670818186, "compression_ratio": 2.13215859030837, "no_speech_prob": 0.01566283218562603}, {"id": 163, "seek": 88656, "start": 909.68, "end": 915.3599999999999, "text": " convolution is we take a matrix and we multiply it by all the values in this matrix at a certain", "tokens": [51520, 45216, 307, 321, 747, 257, 8141, 293, 321, 12972, 309, 538, 439, 264, 4190, 294, 341, 8141, 412, 257, 1629, 51804], "temperature": 0.0, "avg_logprob": -0.029491223670818186, "compression_ratio": 2.13215859030837, "no_speech_prob": 0.01566283218562603}, {"id": 164, "seek": 91536, "start": 915.36, "end": 919.52, "text": " region right and so this is what i was talking about when i was saying we have a receptive field", "tokens": [50364, 4458, 558, 293, 370, 341, 307, 437, 741, 390, 1417, 466, 562, 741, 390, 1566, 321, 362, 257, 45838, 2519, 50572], "temperature": 0.0, "avg_logprob": -0.0655436261009624, "compression_ratio": 1.9863945578231292, "no_speech_prob": 0.010651723481714725}, {"id": 165, "seek": 91536, "start": 919.52, "end": 924.32, "text": " because we don't just multiply it all at once we multiply by a little part of it okay the receptive", "tokens": [50572, 570, 321, 500, 380, 445, 12972, 309, 439, 412, 1564, 321, 12972, 538, 257, 707, 644, 295, 309, 1392, 264, 45838, 50812], "temperature": 0.0, "avg_logprob": -0.0655436261009624, "compression_ratio": 1.9863945578231292, "no_speech_prob": 0.010651723481714725}, {"id": 166, "seek": 91536, "start": 924.32, "end": 929.12, "text": " field and we slide it and we can define what that interval is that sliding window i know i'm talking", "tokens": [50812, 2519, 293, 321, 4137, 309, 293, 321, 393, 6964, 437, 300, 15035, 307, 300, 21169, 4910, 741, 458, 741, 478, 1417, 51052], "temperature": 0.0, "avg_logprob": -0.0655436261009624, "compression_ratio": 1.9863945578231292, "no_speech_prob": 0.010651723481714725}, {"id": 167, "seek": 91536, "start": 929.12, "end": 933.04, "text": " a lot without coding the coding is coming believe me the coding is coming but just check this out", "tokens": [51052, 257, 688, 1553, 17720, 264, 17720, 307, 1348, 1697, 385, 264, 17720, 307, 1348, 457, 445, 1520, 341, 484, 51248], "temperature": 0.0, "avg_logprob": -0.0655436261009624, "compression_ratio": 1.9863945578231292, "no_speech_prob": 0.010651723481714725}, {"id": 168, "seek": 91536, "start": 933.04, "end": 939.9200000000001, "text": " for a second we got to learn this uh conceptually first so we are multiplying the the feature matrix", "tokens": [51248, 337, 257, 1150, 321, 658, 281, 1466, 341, 2232, 3410, 671, 700, 370, 321, 366, 30955, 264, 264, 4111, 8141, 51592], "temperature": 0.0, "avg_logprob": -0.0655436261009624, "compression_ratio": 1.9863945578231292, "no_speech_prob": 0.010651723481714725}, {"id": 169, "seek": 91536, "start": 939.9200000000001, "end": 944.0, "text": " by that input image just for every row and every column we're just multiplying multiply", "tokens": [51592, 538, 300, 4846, 3256, 445, 337, 633, 5386, 293, 633, 7738, 321, 434, 445, 30955, 12972, 51796], "temperature": 0.0, "avg_logprob": -0.0655436261009624, "compression_ratio": 1.9863945578231292, "no_speech_prob": 0.010651723481714725}, {"id": 170, "seek": 94400, "start": 944.0, "end": 949.44, "text": " multiply and what happens is we have this new matrix that results the output and that output", "tokens": [50364, 12972, 293, 437, 2314, 307, 321, 362, 341, 777, 8141, 300, 3542, 264, 5598, 293, 300, 5598, 50636], "temperature": 0.0, "avg_logprob": -0.054071780738480596, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.004905128385871649}, {"id": 171, "seek": 94400, "start": 949.44, "end": 954.88, "text": " is considered the convolved feature okay and so what we do is we use that output as the input", "tokens": [50636, 307, 4888, 264, 3754, 29110, 4111, 1392, 293, 370, 437, 321, 360, 307, 321, 764, 300, 5598, 382, 264, 4846, 50908], "temperature": 0.0, "avg_logprob": -0.054071780738480596, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.004905128385871649}, {"id": 172, "seek": 94400, "start": 954.88, "end": 959.36, "text": " for the to the next layer and we repeat the process over and over and over again obviously", "tokens": [50908, 337, 264, 281, 264, 958, 4583, 293, 321, 7149, 264, 1399, 670, 293, 670, 293, 670, 797, 2745, 51132], "temperature": 0.0, "avg_logprob": -0.054071780738480596, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.004905128385871649}, {"id": 173, "seek": 94400, "start": 959.36, "end": 964.48, "text": " there's two more parts here there's the activation the relu and then there's the pooling which i'll", "tokens": [51132, 456, 311, 732, 544, 3166, 510, 456, 311, 264, 24433, 264, 1039, 84, 293, 550, 456, 311, 264, 7005, 278, 597, 741, 603, 51388], "temperature": 0.0, "avg_logprob": -0.054071780738480596, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.004905128385871649}, {"id": 174, "seek": 94400, "start": 964.48, "end": 969.04, "text": " talk about as well but that's the basic idea between convolution and that's why we call it", "tokens": [51388, 751, 466, 382, 731, 457, 300, 311, 264, 3875, 1558, 1296, 45216, 293, 300, 311, 983, 321, 818, 309, 51616], "temperature": 0.0, "avg_logprob": -0.054071780738480596, "compression_ratio": 1.941908713692946, "no_speech_prob": 0.004905128385871649}, {"id": 175, "seek": 96904, "start": 969.12, "end": 975.76, "text": " convolution because we are combining or convolving the weight matrix or filter or kernel whatever", "tokens": [50368, 45216, 570, 321, 366, 21928, 420, 3754, 401, 798, 264, 3364, 8141, 420, 6608, 420, 28256, 2035, 50700], "temperature": 0.0, "avg_logprob": -0.07292242937309798, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.02675521932542324}, {"id": 176, "seek": 96904, "start": 975.76, "end": 980.64, "text": " you want to call it feature map by that input we're combining it using the out and using that", "tokens": [50700, 291, 528, 281, 818, 309, 4111, 4471, 538, 300, 4846, 321, 434, 21928, 309, 1228, 264, 484, 293, 1228, 300, 50944], "temperature": 0.0, "avg_logprob": -0.07292242937309798, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.02675521932542324}, {"id": 177, "seek": 96904, "start": 980.64, "end": 986.8, "text": " output as the input for the next layer after activating it and and pooling it okay so that's", "tokens": [50944, 5598, 382, 264, 4846, 337, 264, 958, 4583, 934, 42481, 309, 293, 293, 7005, 278, 309, 1392, 370, 300, 311, 51252], "temperature": 0.0, "avg_logprob": -0.07292242937309798, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.02675521932542324}, {"id": 178, "seek": 96904, "start": 986.8, "end": 993.68, "text": " convolution and also um right so we apply it to all of those dimensions for that for that input", "tokens": [51252, 45216, 293, 611, 1105, 558, 370, 321, 3079, 309, 281, 439, 295, 729, 12819, 337, 300, 337, 300, 4846, 51596], "temperature": 0.0, "avg_logprob": -0.07292242937309798, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.02675521932542324}, {"id": 179, "seek": 99368, "start": 993.68, "end": 999.04, "text": " matrix okay and that gives us our activation map or feature map or filter right so many different", "tokens": [50364, 8141, 1392, 293, 300, 2709, 505, 527, 24433, 4471, 420, 4111, 4471, 420, 6608, 558, 370, 867, 819, 50632], "temperature": 0.0, "avg_logprob": -0.05298980712890625, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.1480136662721634}, {"id": 180, "seek": 99368, "start": 999.04, "end": 1005.12, "text": " interchangeable terms here so anyway so it's computed using the dot product so you might be", "tokens": [50632, 30358, 712, 2115, 510, 370, 4033, 370, 309, 311, 40610, 1228, 264, 5893, 1674, 370, 291, 1062, 312, 50936], "temperature": 0.0, "avg_logprob": -0.05298980712890625, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.1480136662721634}, {"id": 181, "seek": 99368, "start": 1005.12, "end": 1010.7199999999999, "text": " thinking well okay i see how there is a dot product i see how there's matrix multiplication", "tokens": [50936, 1953, 731, 1392, 741, 536, 577, 456, 307, 257, 5893, 1674, 741, 536, 577, 456, 311, 8141, 27290, 51216], "temperature": 0.0, "avg_logprob": -0.05298980712890625, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.1480136662721634}, {"id": 182, "seek": 99368, "start": 1010.7199999999999, "end": 1014.9599999999999, "text": " but how does that really tell us what features there are i still you're still not making the", "tokens": [51216, 457, 577, 775, 300, 534, 980, 505, 437, 4122, 456, 366, 741, 920, 291, 434, 920, 406, 1455, 264, 51428], "temperature": 0.0, "avg_logprob": -0.05298980712890625, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.1480136662721634}, {"id": 183, "seek": 99368, "start": 1014.9599999999999, "end": 1022.24, "text": " connection probably why understandably why this these series of matrix operations help us detect", "tokens": [51428, 4984, 1391, 983, 1223, 1188, 983, 341, 613, 2638, 295, 8141, 7705, 854, 505, 5531, 51792], "temperature": 0.0, "avg_logprob": -0.05298980712890625, "compression_ratio": 1.8326848249027237, "no_speech_prob": 0.1480136662721634}, {"id": 184, "seek": 102224, "start": 1022.24, "end": 1027.6, "text": " features well here's what happens what happens is this and here's the great thing about matrices", "tokens": [50364, 4122, 731, 510, 311, 437, 2314, 437, 2314, 307, 341, 293, 510, 311, 264, 869, 551, 466, 32284, 50632], "temperature": 0.0, "avg_logprob": -0.0654448194241305, "compression_ratio": 2.043103448275862, "no_speech_prob": 0.004198605660349131}, {"id": 185, "seek": 102224, "start": 1028.32, "end": 1037.36, "text": " and having several of them when we learn a filter or a weight whatever you want to call it well this", "tokens": [50668, 293, 1419, 2940, 295, 552, 562, 321, 1466, 257, 6608, 420, 257, 3364, 2035, 291, 528, 281, 818, 309, 731, 341, 51120], "temperature": 0.0, "avg_logprob": -0.0654448194241305, "compression_ratio": 2.043103448275862, "no_speech_prob": 0.004198605660349131}, {"id": 186, "seek": 102224, "start": 1037.36, "end": 1040.96, "text": " you know what moving forward let's just call it filter okay i'm just saying let's just call it", "tokens": [51120, 291, 458, 437, 2684, 2128, 718, 311, 445, 818, 309, 6608, 1392, 741, 478, 445, 1566, 718, 311, 445, 818, 309, 51300], "temperature": 0.0, "avg_logprob": -0.0654448194241305, "compression_ratio": 2.043103448275862, "no_speech_prob": 0.004198605660349131}, {"id": 187, "seek": 102224, "start": 1040.96, "end": 1045.28, "text": " filter moving forward for the rest of this video when we learn a filter over time by", "tokens": [51300, 6608, 2684, 2128, 337, 264, 1472, 295, 341, 960, 562, 321, 1466, 257, 6608, 670, 565, 538, 51516], "temperature": 0.0, "avg_logprob": -0.0654448194241305, "compression_ratio": 2.043103448275862, "no_speech_prob": 0.004198605660349131}, {"id": 188, "seek": 102224, "start": 1045.28, "end": 1049.6, "text": " training it on mouse mouth pictures for example a filter is going to look like this at let's say", "tokens": [51516, 3097, 309, 322, 9719, 4525, 5242, 337, 1365, 257, 6608, 307, 516, 281, 574, 411, 341, 412, 718, 311, 584, 51732], "temperature": 0.0, "avg_logprob": -0.0654448194241305, "compression_ratio": 2.043103448275862, "no_speech_prob": 0.004198605660349131}, {"id": 189, "seek": 104960, "start": 1049.6799999999998, "end": 1053.4399999999998, "text": " at the first layer we we learn a filter for detecting a curve that looks like this right", "tokens": [50368, 412, 264, 700, 4583, 321, 321, 1466, 257, 6608, 337, 40237, 257, 7605, 300, 1542, 411, 341, 558, 50556], "temperature": 0.0, "avg_logprob": -0.04680329400139886, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.022283712401986122}, {"id": 190, "seek": 104960, "start": 1053.4399999999998, "end": 1056.9599999999998, "text": " this curve right here and so what's what this filter is going to look like for detecting", "tokens": [50556, 341, 7605, 558, 510, 293, 370, 437, 311, 437, 341, 6608, 307, 516, 281, 574, 411, 337, 40237, 50732], "temperature": 0.0, "avg_logprob": -0.04680329400139886, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.022283712401986122}, {"id": 191, "seek": 104960, "start": 1056.9599999999998, "end": 1061.84, "text": " the specific type of curve is it's going to be a very sparse filter that means there's a lot of", "tokens": [50732, 264, 2685, 2010, 295, 7605, 307, 309, 311, 516, 281, 312, 257, 588, 637, 11668, 6608, 300, 1355, 456, 311, 257, 688, 295, 50976], "temperature": 0.0, "avg_logprob": -0.04680329400139886, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.022283712401986122}, {"id": 192, "seek": 104960, "start": 1061.84, "end": 1067.9199999999998, "text": " zeros except so there's all these zeros except for right here you see this 30 30 30 30 and notice", "tokens": [50976, 35193, 3993, 370, 456, 311, 439, 613, 35193, 3993, 337, 558, 510, 291, 536, 341, 2217, 2217, 2217, 2217, 293, 3449, 51280], "temperature": 0.0, "avg_logprob": -0.04680329400139886, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.022283712401986122}, {"id": 193, "seek": 104960, "start": 1067.9199999999998, "end": 1074.1599999999999, "text": " that these values represent the shape they go in this direction of a shape and so what happens is", "tokens": [51280, 300, 613, 4190, 2906, 264, 3909, 436, 352, 294, 341, 3513, 295, 257, 3909, 293, 370, 437, 2314, 307, 51592], "temperature": 0.0, "avg_logprob": -0.04680329400139886, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.022283712401986122}, {"id": 194, "seek": 107416, "start": 1074.16, "end": 1080.72, "text": " when we take this filter and perform the dot product you know we convolve it with whatever part", "tokens": [50364, 562, 321, 747, 341, 6608, 293, 2042, 264, 5893, 1674, 291, 458, 321, 3754, 37361, 309, 365, 2035, 644, 50692], "temperature": 0.0, "avg_logprob": -0.05276187441565774, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.01065195631235838}, {"id": 195, "seek": 107416, "start": 1080.72, "end": 1088.5600000000002, "text": " of the mouse if it's over a part of the mouse that matches that feature exactly then we when we", "tokens": [50692, 295, 264, 9719, 498, 309, 311, 670, 257, 644, 295, 264, 9719, 300, 10676, 300, 4111, 2293, 550, 321, 562, 321, 51084], "temperature": 0.0, "avg_logprob": -0.05276187441565774, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.01065195631235838}, {"id": 196, "seek": 107416, "start": 1088.5600000000002, "end": 1093.76, "text": " multiply all of those uh when we when we perform the dot product between all those values and sum", "tokens": [51084, 12972, 439, 295, 729, 2232, 562, 321, 562, 321, 2042, 264, 5893, 1674, 1296, 439, 729, 4190, 293, 2408, 51344], "temperature": 0.0, "avg_logprob": -0.05276187441565774, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.01065195631235838}, {"id": 197, "seek": 107416, "start": 1093.76, "end": 1100.0, "text": " them up that's the convolution operation right there okay just it's going to be a big number", "tokens": [51344, 552, 493, 300, 311, 264, 45216, 6916, 558, 456, 1392, 445, 309, 311, 516, 281, 312, 257, 955, 1230, 51656], "temperature": 0.0, "avg_logprob": -0.05276187441565774, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.01065195631235838}, {"id": 198, "seek": 110000, "start": 1100.0, "end": 1104.32, "text": " okay and so then we know that we've detected a feature because we've we've multiplied it sum it", "tokens": [50364, 1392, 293, 370, 550, 321, 458, 300, 321, 600, 21896, 257, 4111, 570, 321, 600, 321, 600, 17207, 309, 2408, 309, 50580], "temperature": 0.0, "avg_logprob": -0.06637887696962098, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.0009399181581102312}, {"id": 199, "seek": 110000, "start": 1104.32, "end": 1110.16, "text": " up and there's a large number and if there's not if we multiply if let's let's say we have that", "tokens": [50580, 493, 293, 456, 311, 257, 2416, 1230, 293, 498, 456, 311, 406, 498, 321, 12972, 498, 718, 311, 718, 311, 584, 321, 362, 300, 50872], "temperature": 0.0, "avg_logprob": -0.06637887696962098, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.0009399181581102312}, {"id": 200, "seek": 110000, "start": 1110.16, "end": 1115.04, "text": " receptive field over a different part of the mouse and that that curve doesn't exist then it's going", "tokens": [50872, 45838, 2519, 670, 257, 819, 644, 295, 264, 9719, 293, 300, 300, 7605, 1177, 380, 2514, 550, 309, 311, 516, 51116], "temperature": 0.0, "avg_logprob": -0.06637887696962098, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.0009399181581102312}, {"id": 201, "seek": 110000, "start": 1115.04, "end": 1120.64, "text": " to be zero right because if you look between these 30 30 30 values and that the equivalent", "tokens": [51116, 281, 312, 4018, 558, 570, 498, 291, 574, 1296, 613, 2217, 2217, 2217, 4190, 293, 300, 264, 10344, 51396], "temperature": 0.0, "avg_logprob": -0.06637887696962098, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.0009399181581102312}, {"id": 202, "seek": 110000, "start": 1121.36, "end": 1127.36, "text": " locations on this pixel representation of the mouse image these are zeros and so what happens", "tokens": [51432, 9253, 322, 341, 19261, 10290, 295, 264, 9719, 3256, 613, 366, 35193, 293, 370, 437, 2314, 51732], "temperature": 0.0, "avg_logprob": -0.06637887696962098, "compression_ratio": 1.8416988416988418, "no_speech_prob": 0.0009399181581102312}, {"id": 203, "seek": 112736, "start": 1127.36, "end": 1134.0, "text": " when you multiply zero by 30 you get zero right so that's why it's important to make the rest of the", "tokens": [50364, 562, 291, 12972, 4018, 538, 2217, 291, 483, 4018, 558, 370, 300, 311, 983, 309, 311, 1021, 281, 652, 264, 1472, 295, 264, 50696], "temperature": 0.0, "avg_logprob": -0.07594350551037078, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.010327200405299664}, {"id": 204, "seek": 112736, "start": 1134.0, "end": 1140.32, "text": " so the data that's irrelevant we want it to be zero right in the in the feature maps or in the", "tokens": [50696, 370, 264, 1412, 300, 311, 28682, 321, 528, 309, 281, 312, 4018, 558, 294, 264, 294, 264, 4111, 11317, 420, 294, 264, 51012], "temperature": 0.0, "avg_logprob": -0.07594350551037078, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.010327200405299664}, {"id": 205, "seek": 112736, "start": 1140.32, "end": 1144.9599999999998, "text": " filters that we learn in the filters that we learn we want the irrelevant parts to be zero", "tokens": [51012, 15995, 300, 321, 1466, 294, 264, 15995, 300, 321, 1466, 321, 528, 264, 28682, 3166, 281, 312, 4018, 51244], "temperature": 0.0, "avg_logprob": -0.07594350551037078, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.010327200405299664}, {"id": 206, "seek": 112736, "start": 1144.9599999999998, "end": 1154.24, "text": " and in the images okay and and in the input images so I so I could actually go even more into", "tokens": [51244, 293, 294, 264, 5267, 1392, 293, 293, 294, 264, 4846, 5267, 370, 286, 370, 286, 727, 767, 352, 754, 544, 666, 51708], "temperature": 0.0, "avg_logprob": -0.07594350551037078, "compression_ratio": 1.9791666666666667, "no_speech_prob": 0.010327200405299664}, {"id": 207, "seek": 115424, "start": 1154.24, "end": 1158.8, "text": " convolution but it's not really necessary but it's it is super dope it is super dope though", "tokens": [50364, 45216, 457, 309, 311, 406, 534, 4818, 457, 309, 311, 309, 307, 1687, 23383, 309, 307, 1687, 23383, 1673, 50592], "temperature": 0.0, "avg_logprob": -0.05910072582108634, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0533914640545845}, {"id": 208, "seek": 115424, "start": 1158.8, "end": 1163.2, "text": " this is a great blog post by the way I definitely encourage you to read this blog post it's linked", "tokens": [50592, 341, 307, 257, 869, 6968, 2183, 538, 264, 636, 286, 2138, 5373, 291, 281, 1401, 341, 6968, 2183, 309, 311, 9408, 50812], "temperature": 0.0, "avg_logprob": -0.05910072582108634, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0533914640545845}, {"id": 209, "seek": 115424, "start": 1163.2, "end": 1168.72, "text": " in the notebook but this dude Tim Tim he goes into these this idea of convolution and he talks about", "tokens": [50812, 294, 264, 21060, 457, 341, 6449, 7172, 7172, 415, 1709, 666, 613, 341, 1558, 295, 45216, 293, 415, 6686, 466, 51088], "temperature": 0.0, "avg_logprob": -0.05910072582108634, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0533914640545845}, {"id": 210, "seek": 115424, "start": 1168.72, "end": 1177.92, "text": " how it's applied to all these different engineering fields and he goes into the formula the formula", "tokens": [51088, 577, 309, 311, 6456, 281, 439, 613, 819, 7043, 7909, 293, 415, 1709, 666, 264, 8513, 264, 8513, 51548], "temperature": 0.0, "avg_logprob": -0.05910072582108634, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0533914640545845}, {"id": 211, "seek": 115424, "start": 1177.92, "end": 1182.88, "text": " for the convolutional theorem is what he called is what it's called okay and I'm just going to go", "tokens": [51548, 337, 264, 45216, 304, 20904, 307, 437, 415, 1219, 307, 437, 309, 311, 1219, 1392, 293, 286, 478, 445, 516, 281, 352, 51796], "temperature": 0.0, "avg_logprob": -0.05910072582108634, "compression_ratio": 1.9027237354085602, "no_speech_prob": 0.0533914640545845}, {"id": 212, "seek": 118288, "start": 1182.88, "end": 1189.2, "text": " over this at a high level but the convolution theorem is this general theorem for discrete well", "tokens": [50364, 670, 341, 412, 257, 1090, 1496, 457, 264, 45216, 20904, 307, 341, 2674, 20904, 337, 27706, 731, 50680], "temperature": 0.0, "avg_logprob": -0.06948878977558401, "compression_ratio": 1.9957627118644068, "no_speech_prob": 0.0035934485495090485}, {"id": 213, "seek": 118288, "start": 1189.2, "end": 1194.24, "text": " there's a discrete version and a continuous version right discrete is if there's you know one or zero", "tokens": [50680, 456, 311, 257, 27706, 3037, 293, 257, 10957, 3037, 558, 27706, 307, 498, 456, 311, 291, 458, 472, 420, 4018, 50932], "temperature": 0.0, "avg_logprob": -0.06948878977558401, "compression_ratio": 1.9957627118644068, "no_speech_prob": 0.0035934485495090485}, {"id": 214, "seek": 118288, "start": 1194.24, "end": 1199.6000000000001, "text": " black or white you know definite classes that something could be whereas continuous is if it", "tokens": [50932, 2211, 420, 2418, 291, 458, 25131, 5359, 300, 746, 727, 312, 9735, 10957, 307, 498, 309, 51200], "temperature": 0.0, "avg_logprob": -0.06948878977558401, "compression_ratio": 1.9957627118644068, "no_speech_prob": 0.0035934485495090485}, {"id": 215, "seek": 118288, "start": 1199.6000000000001, "end": 1205.5200000000002, "text": " could be an infinite amount of values between zero and one point five point two five you know", "tokens": [51200, 727, 312, 364, 13785, 2372, 295, 4190, 1296, 4018, 293, 472, 935, 1732, 935, 732, 1732, 291, 458, 51496], "temperature": 0.0, "avg_logprob": -0.06948878977558401, "compression_ratio": 1.9957627118644068, "no_speech_prob": 0.0035934485495090485}, {"id": 216, "seek": 118288, "start": 1205.5200000000002, "end": 1210.16, "text": " point seven infinity in that direction but here's the here's the formula for it and so", "tokens": [51496, 935, 3407, 13202, 294, 300, 3513, 457, 510, 311, 264, 510, 311, 264, 8513, 337, 309, 293, 370, 51728], "temperature": 0.0, "avg_logprob": -0.06948878977558401, "compression_ratio": 1.9957627118644068, "no_speech_prob": 0.0035934485495090485}, {"id": 217, "seek": 121016, "start": 1210.88, "end": 1214.72, "text": " let me make it bigger just really quickly and then we'll get back to it because it's", "tokens": [50400, 718, 385, 652, 309, 3801, 445, 534, 2661, 293, 550, 321, 603, 483, 646, 281, 309, 570, 309, 311, 50592], "temperature": 0.0, "avg_logprob": -0.05655931640457321, "compression_ratio": 1.8564356435643565, "no_speech_prob": 0.0001852248824434355}, {"id": 218, "seek": 121016, "start": 1214.72, "end": 1222.0, "text": " it's really cool but the convolution theorem states that we and so in it's a general theorem", "tokens": [50592, 309, 311, 534, 1627, 457, 264, 45216, 20904, 4368, 300, 321, 293, 370, 294, 309, 311, 257, 2674, 20904, 50956], "temperature": 0.0, "avg_logprob": -0.05655931640457321, "compression_ratio": 1.8564356435643565, "no_speech_prob": 0.0001852248824434355}, {"id": 219, "seek": 121016, "start": 1222.0, "end": 1229.3600000000001, "text": " that can be applied to any any any set of problems but in terms of what's relevant to us is is the", "tokens": [50956, 300, 393, 312, 6456, 281, 604, 604, 604, 992, 295, 2740, 457, 294, 2115, 295, 437, 311, 7340, 281, 505, 307, 307, 264, 51324], "temperature": 0.0, "avg_logprob": -0.05655931640457321, "compression_ratio": 1.8564356435643565, "no_speech_prob": 0.0001852248824434355}, {"id": 220, "seek": 121016, "start": 1229.3600000000001, "end": 1236.3200000000002, "text": " convolutional theorem applied to matrix operations so what we can do is we can say what it what it", "tokens": [51324, 45216, 304, 20904, 6456, 281, 8141, 7705, 370, 437, 321, 393, 360, 307, 321, 393, 584, 437, 309, 437, 309, 51672], "temperature": 0.0, "avg_logprob": -0.05655931640457321, "compression_ratio": 1.8564356435643565, "no_speech_prob": 0.0001852248824434355}, {"id": 221, "seek": 123632, "start": 1236.32, "end": 1241.4399999999998, "text": " says is it's the input times the kernel and it's the dot product it's a dot product between", "tokens": [50364, 1619, 307, 309, 311, 264, 4846, 1413, 264, 28256, 293, 309, 311, 264, 5893, 1674, 309, 311, 257, 5893, 1674, 1296, 50620], "temperature": 0.0, "avg_logprob": -0.03264376876551077, "compression_ratio": 2.0, "no_speech_prob": 0.0116862952709198}, {"id": 222, "seek": 123632, "start": 1241.4399999999998, "end": 1246.56, "text": " two different matrices and we perform that for every value in all of those matrices and we do that", "tokens": [50620, 732, 819, 32284, 293, 321, 2042, 300, 337, 633, 2158, 294, 439, 295, 729, 32284, 293, 321, 360, 300, 50876], "temperature": 0.0, "avg_logprob": -0.03264376876551077, "compression_ratio": 2.0, "no_speech_prob": 0.0116862952709198}, {"id": 223, "seek": 123632, "start": 1246.56, "end": 1250.48, "text": " for all of the values that we have and we sum them up together and that's what the sigma term", "tokens": [50876, 337, 439, 295, 264, 4190, 300, 321, 362, 293, 321, 2408, 552, 493, 1214, 293, 300, 311, 437, 264, 12771, 1433, 51072], "temperature": 0.0, "avg_logprob": -0.03264376876551077, "compression_ratio": 2.0, "no_speech_prob": 0.0116862952709198}, {"id": 224, "seek": 123632, "start": 1250.48, "end": 1255.28, "text": " represents and we and we actually express that right here right this operation right here this", "tokens": [51072, 8855, 293, 321, 293, 321, 767, 5109, 300, 558, 510, 558, 341, 6916, 558, 510, 341, 51312], "temperature": 0.0, "avg_logprob": -0.03264376876551077, "compression_ratio": 2.0, "no_speech_prob": 0.0116862952709198}, {"id": 225, "seek": 123632, "start": 1255.28, "end": 1259.6799999999998, "text": " multiplication and summation it's the same thing but it's a more complex way of looking at it or", "tokens": [51312, 27290, 293, 28811, 309, 311, 264, 912, 551, 457, 309, 311, 257, 544, 3997, 636, 295, 1237, 412, 309, 420, 51532], "temperature": 0.0, "avg_logprob": -0.03264376876551077, "compression_ratio": 2.0, "no_speech_prob": 0.0116862952709198}, {"id": 226, "seek": 125968, "start": 1259.68, "end": 1266.64, "text": " more mathematically accurate way and also the fast Fourier transform is is brought up by this and", "tokens": [50364, 544, 44003, 8559, 636, 293, 611, 264, 2370, 36810, 4088, 307, 307, 3038, 493, 538, 341, 293, 50712], "temperature": 0.0, "avg_logprob": -0.0806267199308976, "compression_ratio": 1.9959183673469387, "no_speech_prob": 0.15199849009513855}, {"id": 227, "seek": 125968, "start": 1267.8400000000001, "end": 1273.04, "text": " the fast Fourier transform takes some spatial data and it converts it into Fourier space which is", "tokens": [50772, 264, 2370, 36810, 4088, 2516, 512, 23598, 1412, 293, 309, 38874, 309, 666, 36810, 1901, 597, 307, 51032], "temperature": 0.0, "avg_logprob": -0.0806267199308976, "compression_ratio": 1.9959183673469387, "no_speech_prob": 0.15199849009513855}, {"id": 228, "seek": 125968, "start": 1273.04, "end": 1278.88, "text": " like a waveform and you see this a lot in your day-to-day life whenever you're looking at some", "tokens": [51032, 411, 257, 36512, 293, 291, 536, 341, 257, 688, 294, 428, 786, 12, 1353, 12, 810, 993, 5699, 291, 434, 1237, 412, 512, 51324], "temperature": 0.0, "avg_logprob": -0.0806267199308976, "compression_ratio": 1.9959183673469387, "no_speech_prob": 0.15199849009513855}, {"id": 229, "seek": 125968, "start": 1278.88, "end": 1283.1200000000001, "text": " sound you know you're listening to some sound and you look at your mp3 player and you see the waves", "tokens": [51324, 1626, 291, 458, 291, 434, 4764, 281, 512, 1626, 293, 291, 574, 412, 428, 275, 79, 18, 4256, 293, 291, 536, 264, 9417, 51536], "temperature": 0.0, "avg_logprob": -0.0806267199308976, "compression_ratio": 1.9959183673469387, "no_speech_prob": 0.15199849009513855}, {"id": 230, "seek": 125968, "start": 1283.1200000000001, "end": 1287.3600000000001, "text": " that's a that's a Fourier transform happening but i won't go into that that's that's for sound and", "tokens": [51536, 300, 311, 257, 300, 311, 257, 36810, 4088, 2737, 457, 741, 1582, 380, 352, 666, 300, 300, 311, 300, 311, 337, 1626, 293, 51748], "temperature": 0.0, "avg_logprob": -0.0806267199308976, "compression_ratio": 1.9959183673469387, "no_speech_prob": 0.15199849009513855}, {"id": 231, "seek": 128736, "start": 1287.36, "end": 1291.84, "text": " audio but anyway it's a really cool blog post definitely check it out okay so back to this", "tokens": [50364, 6278, 457, 4033, 309, 311, 257, 534, 1627, 6968, 2183, 2138, 1520, 309, 484, 1392, 370, 646, 281, 341, 50588], "temperature": 0.0, "avg_logprob": -0.048093831097638165, "compression_ratio": 1.9826839826839826, "no_speech_prob": 0.0076952967792749405}, {"id": 232, "seek": 128736, "start": 1293.9199999999998, "end": 1298.56, "text": " so we talked about convolution now we're going to talk about pooling right so what is pooling so", "tokens": [50692, 370, 321, 2825, 466, 45216, 586, 321, 434, 516, 281, 751, 466, 7005, 278, 558, 370, 437, 307, 7005, 278, 370, 50924], "temperature": 0.0, "avg_logprob": -0.048093831097638165, "compression_ratio": 1.9826839826839826, "no_speech_prob": 0.0076952967792749405}, {"id": 233, "seek": 128736, "start": 1299.28, "end": 1303.4399999999998, "text": " whenever we apply convolution to some image what's going to happen at every layer", "tokens": [50960, 5699, 321, 3079, 45216, 281, 512, 3256, 437, 311, 516, 281, 1051, 412, 633, 4583, 51168], "temperature": 0.0, "avg_logprob": -0.048093831097638165, "compression_ratio": 1.9826839826839826, "no_speech_prob": 0.0076952967792749405}, {"id": 234, "seek": 128736, "start": 1303.4399999999998, "end": 1309.36, "text": " is we're going to get a series of feature of so each of the weights are going to consist of", "tokens": [51168, 307, 321, 434, 516, 281, 483, 257, 2638, 295, 4111, 295, 370, 1184, 295, 264, 17443, 366, 516, 281, 4603, 295, 51464], "temperature": 0.0, "avg_logprob": -0.048093831097638165, "compression_ratio": 1.9826839826839826, "no_speech_prob": 0.0076952967792749405}, {"id": 235, "seek": 128736, "start": 1309.36, "end": 1316.4799999999998, "text": " multiple images and each of these images are going to be at every layer there's going to be more", "tokens": [51464, 3866, 5267, 293, 1184, 295, 613, 5267, 366, 516, 281, 312, 412, 633, 4583, 456, 311, 516, 281, 312, 544, 51820], "temperature": 0.0, "avg_logprob": -0.048093831097638165, "compression_ratio": 1.9826839826839826, "no_speech_prob": 0.0076952967792749405}, {"id": 236, "seek": 131648, "start": 1316.48, "end": 1322.16, "text": " and smaller images so the first few layers are going to be these huge images right and then at the", "tokens": [50364, 293, 4356, 5267, 370, 264, 700, 1326, 7914, 366, 516, 281, 312, 613, 2603, 5267, 558, 293, 550, 412, 264, 50648], "temperature": 0.0, "avg_logprob": -0.07696503044193627, "compression_ratio": 1.9224806201550388, "no_speech_prob": 0.0032728235237300396}, {"id": 237, "seek": 131648, "start": 1322.16, "end": 1324.88, "text": " next few layers are going to be more of those but they're going to be smaller and it's just going to", "tokens": [50648, 958, 1326, 7914, 366, 516, 281, 312, 544, 295, 729, 457, 436, 434, 516, 281, 312, 4356, 293, 309, 311, 445, 516, 281, 50784], "temperature": 0.0, "avg_logprob": -0.07696503044193627, "compression_ratio": 1.9224806201550388, "no_speech_prob": 0.0032728235237300396}, {"id": 238, "seek": 131648, "start": 1324.88, "end": 1329.6, "text": " get just like that okay and at the end we squash it with some fully connected layer so we get some", "tokens": [50784, 483, 445, 411, 300, 1392, 293, 412, 264, 917, 321, 30725, 309, 365, 512, 4498, 4582, 4583, 370, 321, 483, 512, 51020], "temperature": 0.0, "avg_logprob": -0.07696503044193627, "compression_ratio": 1.9224806201550388, "no_speech_prob": 0.0032728235237300396}, {"id": 239, "seek": 131648, "start": 1329.6, "end": 1336.56, "text": " probability values with a softmax but anyway what pooling does is it is it dense is it makes", "tokens": [51020, 8482, 4190, 365, 257, 2787, 41167, 457, 4033, 437, 7005, 278, 775, 307, 309, 307, 309, 18011, 307, 309, 1669, 51368], "temperature": 0.0, "avg_logprob": -0.07696503044193627, "compression_ratio": 1.9224806201550388, "no_speech_prob": 0.0032728235237300396}, {"id": 240, "seek": 131648, "start": 1336.56, "end": 1344.0, "text": " the matrix the matrices that we learn more dense here's what i mean so if you if you perform convolution", "tokens": [51368, 264, 8141, 264, 32284, 300, 321, 1466, 544, 18011, 510, 311, 437, 741, 914, 370, 498, 291, 498, 291, 2042, 45216, 51740], "temperature": 0.0, "avg_logprob": -0.07696503044193627, "compression_ratio": 1.9224806201550388, "no_speech_prob": 0.0032728235237300396}, {"id": 241, "seek": 134400, "start": 1344.08, "end": 1351.68, "text": " between an input and a feature matrix or a weight matrix or filter it's going to result in a matrix", "tokens": [50368, 1296, 364, 4846, 293, 257, 4111, 8141, 420, 257, 3364, 8141, 420, 6608, 309, 311, 516, 281, 1874, 294, 257, 8141, 50748], "temperature": 0.0, "avg_logprob": -0.04344463742468968, "compression_ratio": 2.111587982832618, "no_speech_prob": 0.02843117155134678}, {"id": 242, "seek": 134400, "start": 1351.68, "end": 1356.48, "text": " right but this matrix is going to be pretty big it's going to be a pretty big matrix what we can do", "tokens": [50748, 558, 457, 341, 8141, 307, 516, 281, 312, 1238, 955, 309, 311, 516, 281, 312, 257, 1238, 955, 8141, 437, 321, 393, 360, 50988], "temperature": 0.0, "avg_logprob": -0.04344463742468968, "compression_ratio": 2.111587982832618, "no_speech_prob": 0.02843117155134678}, {"id": 243, "seek": 134400, "start": 1356.48, "end": 1362.48, "text": " is we can take the most important parts of that matrix and pass that on and what that's going to", "tokens": [50988, 307, 321, 393, 747, 264, 881, 1021, 3166, 295, 300, 8141, 293, 1320, 300, 322, 293, 437, 300, 311, 516, 281, 51288], "temperature": 0.0, "avg_logprob": -0.04344463742468968, "compression_ratio": 2.111587982832618, "no_speech_prob": 0.02843117155134678}, {"id": 244, "seek": 134400, "start": 1362.48, "end": 1368.24, "text": " do is it's going to reduce the computational complexity of our model okay so that's what pooling", "tokens": [51288, 360, 307, 309, 311, 516, 281, 5407, 264, 28270, 14024, 295, 527, 2316, 1392, 370, 300, 311, 437, 7005, 278, 51576], "temperature": 0.0, "avg_logprob": -0.04344463742468968, "compression_ratio": 2.111587982832618, "no_speech_prob": 0.02843117155134678}, {"id": 245, "seek": 134400, "start": 1368.24, "end": 1373.44, "text": " is all about it's a pooling set so there's different types of pooling max pooling is the most used", "tokens": [51576, 307, 439, 466, 309, 311, 257, 7005, 278, 992, 370, 456, 311, 819, 3467, 295, 7005, 278, 11469, 7005, 278, 307, 264, 881, 1143, 51836], "temperature": 0.0, "avg_logprob": -0.04344463742468968, "compression_ratio": 2.111587982832618, "no_speech_prob": 0.02843117155134678}, {"id": 246, "seek": 137344, "start": 1373.44, "end": 1380.16, "text": " type of pooling by the way so basically multiply so what happens is we we strive we have some we", "tokens": [50364, 2010, 295, 7005, 278, 538, 264, 636, 370, 1936, 12972, 370, 437, 2314, 307, 321, 321, 23829, 321, 362, 512, 321, 50700], "temperature": 0.0, "avg_logprob": -0.04733497260982155, "compression_ratio": 1.9140625, "no_speech_prob": 0.0019266592571511865}, {"id": 247, "seek": 137344, "start": 1380.16, "end": 1385.52, "text": " define some window size and then some stride size so how what are the intervals that we look at", "tokens": [50700, 6964, 512, 4910, 2744, 293, 550, 512, 1056, 482, 2744, 370, 577, 437, 366, 264, 26651, 300, 321, 574, 412, 50968], "temperature": 0.0, "avg_logprob": -0.04733497260982155, "compression_ratio": 1.9140625, "no_speech_prob": 0.0019266592571511865}, {"id": 248, "seek": 137344, "start": 1385.52, "end": 1391.6000000000001, "text": " and we say okay so for each of these windows let's take the max value so for so for uh this one right", "tokens": [50968, 293, 321, 584, 1392, 370, 337, 1184, 295, 613, 9309, 718, 311, 747, 264, 11469, 2158, 370, 337, 370, 337, 2232, 341, 472, 558, 51272], "temperature": 0.0, "avg_logprob": -0.04733497260982155, "compression_ratio": 1.9140625, "no_speech_prob": 0.0019266592571511865}, {"id": 249, "seek": 137344, "start": 1391.6000000000001, "end": 1396.72, "text": " here four six zero eight the max value would be eight and so for one three twelve nine it'd be", "tokens": [51272, 510, 1451, 2309, 4018, 3180, 264, 11469, 2158, 576, 312, 3180, 293, 370, 337, 472, 1045, 14390, 4949, 309, 1116, 312, 51528], "temperature": 0.0, "avg_logprob": -0.04733497260982155, "compression_ratio": 1.9140625, "no_speech_prob": 0.0019266592571511865}, {"id": 250, "seek": 137344, "start": 1396.72, "end": 1400.72, "text": " twelve right so we just take the biggest number it's really simple actually we just take the biggest", "tokens": [51528, 14390, 558, 370, 321, 445, 747, 264, 3880, 1230, 309, 311, 534, 2199, 767, 321, 445, 747, 264, 3880, 51728], "temperature": 0.0, "avg_logprob": -0.04733497260982155, "compression_ratio": 1.9140625, "no_speech_prob": 0.0019266592571511865}, {"id": 251, "seek": 140072, "start": 1400.72, "end": 1405.1200000000001, "text": " number and we just do that for all of them and so that that's what pooling is all about and so", "tokens": [50364, 1230, 293, 321, 445, 360, 300, 337, 439, 295, 552, 293, 370, 300, 300, 311, 437, 7005, 278, 307, 439, 466, 293, 370, 50584], "temperature": 0.0, "avg_logprob": -0.07751896034958017, "compression_ratio": 2.029045643153527, "no_speech_prob": 0.012053192593157291}, {"id": 252, "seek": 140072, "start": 1405.1200000000001, "end": 1411.68, "text": " it's going to just give us that the most relevant parts of the image and if you if you think of these", "tokens": [50584, 309, 311, 516, 281, 445, 976, 505, 300, 264, 881, 7340, 3166, 295, 264, 3256, 293, 498, 291, 498, 291, 519, 295, 613, 50912], "temperature": 0.0, "avg_logprob": -0.07751896034958017, "compression_ratio": 2.029045643153527, "no_speech_prob": 0.012053192593157291}, {"id": 253, "seek": 140072, "start": 1411.68, "end": 1418.8, "text": " these very these values in in the in the matrix as pixel intensities by taking the maximum intense", "tokens": [50912, 613, 588, 613, 4190, 294, 294, 264, 294, 264, 8141, 382, 19261, 14056, 1088, 538, 1940, 264, 6674, 9447, 51268], "temperature": 0.0, "avg_logprob": -0.07751896034958017, "compression_ratio": 2.029045643153527, "no_speech_prob": 0.012053192593157291}, {"id": 254, "seek": 140072, "start": 1418.8, "end": 1423.52, "text": " the the pixel with the most intensity or the the highest intensity we're getting that feature that", "tokens": [51268, 264, 264, 19261, 365, 264, 881, 13749, 420, 264, 264, 6343, 13749, 321, 434, 1242, 300, 4111, 300, 51504], "temperature": 0.0, "avg_logprob": -0.07751896034958017, "compression_ratio": 2.029045643153527, "no_speech_prob": 0.012053192593157291}, {"id": 255, "seek": 140072, "start": 1423.52, "end": 1428.96, "text": " is the most relevant if you see what I'm saying it's a least opaque feature to use a term from", "tokens": [51504, 307, 264, 881, 7340, 498, 291, 536, 437, 286, 478, 1566, 309, 311, 257, 1935, 42687, 4111, 281, 764, 257, 1433, 490, 51776], "temperature": 0.0, "avg_logprob": -0.07751896034958017, "compression_ratio": 2.029045643153527, "no_speech_prob": 0.012053192593157291}, {"id": 256, "seek": 142896, "start": 1429.28, "end": 1437.68, "text": " image um math anyway so we so we talked about pooling and we talked about uh we talked about", "tokens": [50380, 3256, 1105, 5221, 4033, 370, 321, 370, 321, 2825, 466, 7005, 278, 293, 321, 2825, 466, 2232, 321, 2825, 466, 50800], "temperature": 0.0, "avg_logprob": -0.12351033028135909, "compression_ratio": 1.955, "no_speech_prob": 0.005384640768170357}, {"id": 257, "seek": 142896, "start": 1438.4, "end": 1440.16, "text": " activation and so now", "tokens": [50836, 24433, 293, 370, 586, 50924], "temperature": 0.0, "avg_logprob": -0.12351033028135909, "compression_ratio": 1.955, "no_speech_prob": 0.005384640768170357}, {"id": 258, "seek": 142896, "start": 1442.88, "end": 1446.8, "text": " no we talked about convolution and we talked about pooling and so now the third part", "tokens": [51060, 572, 321, 2825, 466, 45216, 293, 321, 2825, 466, 7005, 278, 293, 370, 586, 264, 2636, 644, 51256], "temperature": 0.0, "avg_logprob": -0.12351033028135909, "compression_ratio": 1.955, "no_speech_prob": 0.005384640768170357}, {"id": 259, "seek": 142896, "start": 1446.8, "end": 1452.96, "text": " is normalization or activation so remember how I said how it would be it's so important that we", "tokens": [51256, 307, 2710, 2144, 420, 24433, 370, 1604, 577, 286, 848, 577, 309, 576, 312, 309, 311, 370, 1021, 300, 321, 51564], "temperature": 0.0, "avg_logprob": -0.12351033028135909, "compression_ratio": 1.955, "no_speech_prob": 0.005384640768170357}, {"id": 260, "seek": 142896, "start": 1452.96, "end": 1458.48, "text": " have these values that are not related to our image be zero we want it to be zero so the result", "tokens": [51564, 362, 613, 4190, 300, 366, 406, 4077, 281, 527, 3256, 312, 4018, 321, 528, 309, 281, 312, 4018, 370, 264, 1874, 51840], "temperature": 0.0, "avg_logprob": -0.12351033028135909, "compression_ratio": 1.955, "no_speech_prob": 0.005384640768170357}, {"id": 261, "seek": 145848, "start": 1458.48, "end": 1464.96, "text": " is zero if the if the feature is not detected well the way we do that is using relu and so relu", "tokens": [50364, 307, 4018, 498, 264, 498, 264, 4111, 307, 406, 21896, 731, 264, 636, 321, 360, 300, 307, 1228, 1039, 84, 293, 370, 1039, 84, 50688], "temperature": 0.0, "avg_logprob": -0.06326203935601737, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.007814839482307434}, {"id": 262, "seek": 145848, "start": 1464.96, "end": 1471.1200000000001, "text": " stands for rectified linear unit it's an activation function it's an activation function okay we use", "tokens": [50688, 7382, 337, 11048, 2587, 8213, 4985, 309, 311, 364, 24433, 2445, 309, 311, 364, 24433, 2445, 1392, 321, 764, 50996], "temperature": 0.0, "avg_logprob": -0.06326203935601737, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.007814839482307434}, {"id": 263, "seek": 145848, "start": 1471.1200000000001, "end": 1476.96, "text": " activation functions throughout neural networks and we use them because it is you can also call", "tokens": [50996, 24433, 6828, 3710, 18161, 9590, 293, 321, 764, 552, 570, 309, 307, 291, 393, 611, 818, 51288], "temperature": 0.0, "avg_logprob": -0.06326203935601737, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.007814839482307434}, {"id": 264, "seek": 145848, "start": 1476.96, "end": 1483.92, "text": " them non-linearities because they they make our model able to learn non-linear functions not just", "tokens": [51288, 552, 2107, 12, 28263, 1088, 570, 436, 436, 652, 527, 2316, 1075, 281, 1466, 2107, 12, 28263, 6828, 406, 445, 51636], "temperature": 0.0, "avg_logprob": -0.06326203935601737, "compression_ratio": 1.9306930693069306, "no_speech_prob": 0.007814839482307434}, {"id": 265, "seek": 148392, "start": 1483.92, "end": 1488.88, "text": " linear functions but non-linear functions so any kind of function right the universal function", "tokens": [50364, 8213, 6828, 457, 2107, 12, 28263, 6828, 370, 604, 733, 295, 2445, 558, 264, 11455, 2445, 50612], "temperature": 0.0, "avg_logprob": -0.058013859361705215, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.019122224301099777}, {"id": 266, "seek": 148392, "start": 1488.88, "end": 1494.4, "text": " approximation theorem we talked about that activation functions help make this happen and", "tokens": [50612, 28023, 20904, 321, 2825, 466, 300, 24433, 6828, 854, 652, 341, 1051, 293, 50888], "temperature": 0.0, "avg_logprob": -0.058013859361705215, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.019122224301099777}, {"id": 267, "seek": 148392, "start": 1494.4, "end": 1499.76, "text": " so relu is a is a special kind of activation function that turns all negative numbers into", "tokens": [50888, 370, 1039, 84, 307, 257, 307, 257, 2121, 733, 295, 24433, 2445, 300, 4523, 439, 3671, 3547, 666, 51156], "temperature": 0.0, "avg_logprob": -0.058013859361705215, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.019122224301099777}, {"id": 268, "seek": 148392, "start": 1500.72, "end": 1504.96, "text": " zero so that's why it's going to make the math easier it won't make the math break", "tokens": [51204, 4018, 370, 300, 311, 983, 309, 311, 516, 281, 652, 264, 5221, 3571, 309, 1582, 380, 652, 264, 5221, 1821, 51416], "temperature": 0.0, "avg_logprob": -0.058013859361705215, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.019122224301099777}, {"id": 269, "seek": 148392, "start": 1504.96, "end": 1509.76, "text": " for our convolutional network so we'll apply a relu so basically what we do is for every single pixel", "tokens": [51416, 337, 527, 45216, 304, 3209, 370, 321, 603, 3079, 257, 1039, 84, 370, 1936, 437, 321, 360, 307, 337, 633, 2167, 19261, 51656], "temperature": 0.0, "avg_logprob": -0.058013859361705215, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.019122224301099777}, {"id": 270, "seek": 150976, "start": 1509.76, "end": 1515.12, "text": " value in the in the input to this relu activation function we turn it if it's a negative we just", "tokens": [50364, 2158, 294, 264, 294, 264, 4846, 281, 341, 1039, 84, 24433, 2445, 321, 1261, 309, 498, 309, 311, 257, 3671, 321, 445, 50632], "temperature": 0.0, "avg_logprob": -0.08361160855333344, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0495816171169281}, {"id": 271, "seek": 150976, "start": 1515.12, "end": 1519.2, "text": " say make it zero it's super simple it'll be one line of code you'll see exactly what i'm talking about", "tokens": [50632, 584, 652, 309, 4018, 309, 311, 1687, 2199, 309, 603, 312, 472, 1622, 295, 3089, 291, 603, 536, 2293, 437, 741, 478, 1417, 466, 50836], "temperature": 0.0, "avg_logprob": -0.08361160855333344, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0495816171169281}, {"id": 272, "seek": 150976, "start": 1520.4, "end": 1524.8799999999999, "text": " okay so that's that's those are our blocks so that's how our convolutional blocks work", "tokens": [50896, 1392, 370, 300, 311, 300, 311, 729, 366, 527, 8474, 370, 300, 311, 577, 527, 45216, 304, 8474, 589, 51120], "temperature": 0.0, "avg_logprob": -0.08361160855333344, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0495816171169281}, {"id": 273, "seek": 150976, "start": 1525.76, "end": 1530.32, "text": " however there is another step that I didn't talk about that is a nice to have and state of the", "tokens": [51164, 4461, 456, 307, 1071, 1823, 300, 286, 994, 380, 751, 466, 300, 307, 257, 1481, 281, 362, 293, 1785, 295, 264, 51392], "temperature": 0.0, "avg_logprob": -0.08361160855333344, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0495816171169281}, {"id": 274, "seek": 150976, "start": 1530.32, "end": 1535.92, "text": " our convolutional networks always use it and that's called dropout so Jeffrey Hinton the guy who invented", "tokens": [51392, 527, 45216, 304, 9590, 1009, 764, 309, 293, 300, 311, 1219, 3270, 346, 370, 28721, 389, 12442, 264, 2146, 567, 14479, 51672], "temperature": 0.0, "avg_logprob": -0.08361160855333344, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.0495816171169281}, {"id": 275, "seek": 153592, "start": 1536.48, "end": 1542.8000000000002, "text": " neural networks invented a feature invented a technique called dropout and what dropout is", "tokens": [50392, 18161, 9590, 14479, 257, 4111, 14479, 257, 6532, 1219, 3270, 346, 293, 437, 3270, 346, 307, 50708], "temperature": 0.0, "avg_logprob": -0.0762903502817904, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.035137176513671875}, {"id": 276, "seek": 153592, "start": 1542.8000000000002, "end": 1549.2, "text": " is a good analogy is old people or not old people but people who are stuck in their ways let me let", "tokens": [50708, 307, 257, 665, 21663, 307, 1331, 561, 420, 406, 1331, 561, 457, 561, 567, 366, 5541, 294, 641, 2098, 718, 385, 718, 51028], "temperature": 0.0, "avg_logprob": -0.0762903502817904, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.035137176513671875}, {"id": 277, "seek": 153592, "start": 1549.2, "end": 1555.52, "text": " me okay so what dropout does is it turns neurons on and off randomly what do I mean by that that I", "tokens": [51028, 385, 1392, 370, 437, 3270, 346, 775, 307, 309, 4523, 22027, 322, 293, 766, 16979, 437, 360, 286, 914, 538, 300, 300, 286, 51344], "temperature": 0.0, "avg_logprob": -0.0762903502817904, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.035137176513671875}, {"id": 278, "seek": 153592, "start": 1555.52, "end": 1562.0800000000002, "text": " mean the the matrices for each weight value is converted to zero randomly at some layer of the", "tokens": [51344, 914, 264, 264, 32284, 337, 1184, 3364, 2158, 307, 16424, 281, 4018, 16979, 412, 512, 4583, 295, 264, 51672], "temperature": 0.0, "avg_logprob": -0.0762903502817904, "compression_ratio": 1.794392523364486, "no_speech_prob": 0.035137176513671875}, {"id": 279, "seek": 156208, "start": 1562.08, "end": 1567.6, "text": " network and so what happens is by doing this our network is forced to learn new representations", "tokens": [50364, 3209, 293, 370, 437, 2314, 307, 538, 884, 341, 527, 3209, 307, 7579, 281, 1466, 777, 33358, 50640], "temperature": 0.0, "avg_logprob": -0.05275946078093156, "compression_ratio": 2.020746887966805, "no_speech_prob": 0.06559181958436966}, {"id": 280, "seek": 156208, "start": 1567.6, "end": 1572.8799999999999, "text": " for the data new pathways that that data has to flow through it can't always flow through this neuron", "tokens": [50640, 337, 264, 1412, 777, 22988, 300, 300, 1412, 575, 281, 3095, 807, 309, 393, 380, 1009, 3095, 807, 341, 34090, 50904], "temperature": 0.0, "avg_logprob": -0.05275946078093156, "compression_ratio": 2.020746887966805, "no_speech_prob": 0.06559181958436966}, {"id": 281, "seek": 156208, "start": 1572.8799999999999, "end": 1577.6799999999998, "text": " and the reason we use it is to prevent overfitting right we want to prevent overfitting we want to", "tokens": [50904, 293, 264, 1778, 321, 764, 309, 307, 281, 4871, 670, 69, 2414, 558, 321, 528, 281, 4871, 670, 69, 2414, 321, 528, 281, 51144], "temperature": 0.0, "avg_logprob": -0.05275946078093156, "compression_ratio": 2.020746887966805, "no_speech_prob": 0.06559181958436966}, {"id": 282, "seek": 156208, "start": 1577.6799999999998, "end": 1582.56, "text": " prevent being too fit to the data think of it as you know the older you get the more set in your", "tokens": [51144, 4871, 885, 886, 3318, 281, 264, 1412, 519, 295, 309, 382, 291, 458, 264, 4906, 291, 483, 264, 544, 992, 294, 428, 51388], "temperature": 0.0, "avg_logprob": -0.05275946078093156, "compression_ratio": 2.020746887966805, "no_speech_prob": 0.06559181958436966}, {"id": 283, "seek": 156208, "start": 1582.56, "end": 1588.24, "text": " ways of thinking your you are right and so it's harder to think of new ways of of of thinking", "tokens": [51388, 2098, 295, 1953, 428, 291, 366, 558, 293, 370, 309, 311, 6081, 281, 519, 295, 777, 2098, 295, 295, 295, 1953, 51672], "temperature": 0.0, "avg_logprob": -0.05275946078093156, "compression_ratio": 2.020746887966805, "no_speech_prob": 0.06559181958436966}, {"id": 284, "seek": 158824, "start": 1588.24, "end": 1593.36, "text": " right because you're so set in some ways so a way to prevent that is to have a novel crazy", "tokens": [50364, 558, 570, 291, 434, 370, 992, 294, 512, 2098, 370, 257, 636, 281, 4871, 300, 307, 281, 362, 257, 7613, 3219, 50620], "temperature": 0.0, "avg_logprob": -0.045563483023428705, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.011331052519381046}, {"id": 285, "seek": 158824, "start": 1593.36, "end": 1598.16, "text": " experience whether it's skydiving or ticking psychedelics or whatever it is and what that", "tokens": [50620, 1752, 1968, 309, 311, 5443, 67, 2123, 420, 33999, 47732, 1167, 420, 2035, 309, 307, 293, 437, 300, 50860], "temperature": 0.0, "avg_logprob": -0.045563483023428705, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.011331052519381046}, {"id": 286, "seek": 158824, "start": 1598.16, "end": 1603.28, "text": " does is it creates new pathways so you're not so you're kind of forced your brain is forced to make", "tokens": [50860, 775, 307, 309, 7829, 777, 22988, 370, 291, 434, 406, 370, 291, 434, 733, 295, 7579, 428, 3567, 307, 7579, 281, 652, 51116], "temperature": 0.0, "avg_logprob": -0.045563483023428705, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.011331052519381046}, {"id": 287, "seek": 158824, "start": 1603.28, "end": 1610.48, "text": " new pathways and this increases your generalization ability and you're not so overfit that's a very", "tokens": [51116, 777, 22988, 293, 341, 8637, 428, 2674, 2144, 3485, 293, 291, 434, 406, 370, 670, 6845, 300, 311, 257, 588, 51476], "temperature": 0.0, "avg_logprob": -0.045563483023428705, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.011331052519381046}, {"id": 288, "seek": 158824, "start": 1610.48, "end": 1616.24, "text": " rough abstract analogy but basically dropout is not as complex as that sounds dropout can be", "tokens": [51476, 5903, 12649, 21663, 457, 1936, 3270, 346, 307, 406, 382, 3997, 382, 300, 3263, 3270, 346, 393, 312, 51764], "temperature": 0.0, "avg_logprob": -0.045563483023428705, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.011331052519381046}, {"id": 289, "seek": 161624, "start": 1616.24, "end": 1621.04, "text": " done in three lines of code so definitely check out this blog post as well that I've linked", "tokens": [50364, 1096, 294, 1045, 3876, 295, 3089, 370, 2138, 1520, 484, 341, 6968, 2183, 382, 731, 300, 286, 600, 9408, 50604], "temperature": 0.0, "avg_logprob": -0.04681422029222761, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.06559064239263535}, {"id": 290, "seek": 161624, "start": 1621.04, "end": 1627.6, "text": " but what it does is it just randomly picks some neurons in a layer to set to zero right so it's", "tokens": [50604, 457, 437, 309, 775, 307, 309, 445, 16979, 16137, 512, 22027, 294, 257, 4583, 281, 992, 281, 4018, 558, 370, 309, 311, 50932], "temperature": 0.0, "avg_logprob": -0.04681422029222761, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.06559064239263535}, {"id": 291, "seek": 161624, "start": 1627.6, "end": 1632.24, "text": " just it's just three lines okay and you can look at it in this notebook right so that's and then our", "tokens": [50932, 445, 309, 311, 445, 1045, 3876, 1392, 293, 291, 393, 574, 412, 309, 294, 341, 21060, 558, 370, 300, 311, 293, 550, 527, 51164], "temperature": 0.0, "avg_logprob": -0.04681422029222761, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.06559064239263535}, {"id": 292, "seek": 161624, "start": 1632.24, "end": 1637.76, "text": " last step is probability conversion so we've got this huge set of values right all these little", "tokens": [51164, 1036, 1823, 307, 8482, 14298, 370, 321, 600, 658, 341, 2603, 992, 295, 4190, 558, 439, 613, 707, 51440], "temperature": 0.0, "avg_logprob": -0.04681422029222761, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.06559064239263535}, {"id": 293, "seek": 161624, "start": 1637.76, "end": 1642.96, "text": " small images that are represented by this huge output matrix and we want to take this huge set", "tokens": [51440, 1359, 5267, 300, 366, 10379, 538, 341, 2603, 5598, 8141, 293, 321, 528, 281, 747, 341, 2603, 992, 51700], "temperature": 0.0, "avg_logprob": -0.04681422029222761, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.06559064239263535}, {"id": 294, "seek": 164296, "start": 1642.96, "end": 1647.92, "text": " of values and make some sense out of it we want to make probabilities out of it and the way we do", "tokens": [50364, 295, 4190, 293, 652, 512, 2020, 484, 295, 309, 321, 528, 281, 652, 33783, 484, 295, 309, 293, 264, 636, 321, 360, 50612], "temperature": 0.0, "avg_logprob": -0.049664337023169594, "compression_ratio": 2.0, "no_speech_prob": 0.10967985540628433}, {"id": 295, "seek": 164296, "start": 1647.92, "end": 1653.44, "text": " that is using a soft max at the end a soft max is a type of function and it looks like this this", "tokens": [50612, 300, 307, 1228, 257, 2787, 11469, 412, 264, 917, 257, 2787, 11469, 307, 257, 2010, 295, 2445, 293, 309, 1542, 411, 341, 341, 50888], "temperature": 0.0, "avg_logprob": -0.049664337023169594, "compression_ratio": 2.0, "no_speech_prob": 0.10967985540628433}, {"id": 296, "seek": 164296, "start": 1653.44, "end": 1658.16, "text": " this is a soft max function right here but what we do is we plug these values into the soft max", "tokens": [50888, 341, 307, 257, 2787, 11469, 2445, 558, 510, 457, 437, 321, 360, 307, 321, 5452, 613, 4190, 666, 264, 2787, 11469, 51124], "temperature": 0.0, "avg_logprob": -0.049664337023169594, "compression_ratio": 2.0, "no_speech_prob": 0.10967985540628433}, {"id": 297, "seek": 164296, "start": 1658.16, "end": 1663.6000000000001, "text": " function and it's going to output a set of probability values discrete probability values", "tokens": [51124, 2445, 293, 309, 311, 516, 281, 5598, 257, 992, 295, 8482, 4190, 27706, 8482, 4190, 51396], "temperature": 0.0, "avg_logprob": -0.049664337023169594, "compression_ratio": 2.0, "no_speech_prob": 0.10967985540628433}, {"id": 298, "seek": 164296, "start": 1663.6000000000001, "end": 1668.24, "text": " for each of the classes that we're trying to predict okay and then what we'll do is given", "tokens": [51396, 337, 1184, 295, 264, 5359, 300, 321, 434, 1382, 281, 6069, 1392, 293, 550, 437, 321, 603, 360, 307, 2212, 51628], "temperature": 0.0, "avg_logprob": -0.049664337023169594, "compression_ratio": 2.0, "no_speech_prob": 0.10967985540628433}, {"id": 299, "seek": 166824, "start": 1668.24, "end": 1674.56, "text": " all those probability values will pick the biggest one using arg max the arg max function in numpy", "tokens": [50364, 439, 729, 8482, 4190, 486, 1888, 264, 3880, 472, 1228, 3882, 11469, 264, 3882, 11469, 2445, 294, 1031, 8200, 50680], "temperature": 0.0, "avg_logprob": -0.0685813398922191, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01542346365749836}, {"id": 300, "seek": 166824, "start": 1674.56, "end": 1680.16, "text": " and that's going to give us the most likely class okay those are the seven steps of a", "tokens": [50680, 293, 300, 311, 516, 281, 976, 505, 264, 881, 3700, 1508, 1392, 729, 366, 264, 3407, 4439, 295, 257, 50960], "temperature": 0.0, "avg_logprob": -0.0685813398922191, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01542346365749836}, {"id": 301, "seek": 166824, "start": 1680.16, "end": 1686.88, "text": " full forward pass through a convolutional network looks like that and so now you might be wondering", "tokens": [50960, 1577, 2128, 1320, 807, 257, 45216, 304, 3209, 1542, 411, 300, 293, 370, 586, 291, 1062, 312, 6359, 51296], "temperature": 0.0, "avg_logprob": -0.0685813398922191, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01542346365749836}, {"id": 302, "seek": 166824, "start": 1686.88, "end": 1693.04, "text": " well okay so how do we train this thing well using gradient descent right and when applied to neural", "tokens": [51296, 731, 1392, 370, 577, 360, 321, 3847, 341, 551, 731, 1228, 16235, 23475, 558, 293, 562, 6456, 281, 18161, 51604], "temperature": 0.0, "avg_logprob": -0.0685813398922191, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.01542346365749836}, {"id": 303, "seek": 169304, "start": 1693.04, "end": 1700.32, "text": " networks gradient gradient descent is called back propagation exactly i hope you got that right", "tokens": [50364, 9590, 16235, 16235, 23475, 307, 1219, 646, 38377, 2293, 741, 1454, 291, 658, 300, 558, 50728], "temperature": 0.0, "avg_logprob": -0.07576175068700036, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0311405248939991}, {"id": 304, "seek": 169304, "start": 1700.32, "end": 1705.92, "text": " anyway okay so how do we learn these magic numbers right how do we learn what these weight values", "tokens": [50728, 4033, 1392, 370, 577, 360, 321, 1466, 613, 5585, 3547, 558, 577, 360, 321, 1466, 437, 613, 3364, 4190, 51008], "temperature": 0.0, "avg_logprob": -0.07576175068700036, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0311405248939991}, {"id": 305, "seek": 169304, "start": 1705.92, "end": 1711.6, "text": " should be what the feature should be back propagation is how we do it right and so we've talked quite a", "tokens": [51008, 820, 312, 437, 264, 4111, 820, 312, 646, 38377, 307, 577, 321, 360, 309, 558, 293, 370, 321, 600, 2825, 1596, 257, 51292], "temperature": 0.0, "avg_logprob": -0.07576175068700036, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0311405248939991}, {"id": 306, "seek": 169304, "start": 1711.6, "end": 1716.48, "text": " bit about back propagation and gradient descent but i'll do a little i'll go over it again um", "tokens": [51292, 857, 466, 646, 38377, 293, 16235, 23475, 457, 741, 603, 360, 257, 707, 741, 603, 352, 670, 309, 797, 1105, 51536], "temperature": 0.0, "avg_logprob": -0.07576175068700036, "compression_ratio": 1.9166666666666667, "no_speech_prob": 0.0311405248939991}, {"id": 307, "seek": 171648, "start": 1717.44, "end": 1722.16, "text": " but the idea is that we have some error that we're computing right this is super this is", "tokens": [50412, 457, 264, 1558, 307, 300, 321, 362, 512, 6713, 300, 321, 434, 15866, 558, 341, 307, 1687, 341, 307, 50648], "temperature": 0.0, "avg_logprob": -0.10446380009160977, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.030211836099624634}, {"id": 308, "seek": 171648, "start": 1722.16, "end": 1727.44, "text": " supervised learning we have a we have a human label right for some data so we put in a dog image", "tokens": [50648, 46533, 2539, 321, 362, 257, 321, 362, 257, 1952, 7645, 558, 337, 512, 1412, 370, 321, 829, 294, 257, 3000, 3256, 50912], "temperature": 0.0, "avg_logprob": -0.10446380009160977, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.030211836099624634}, {"id": 309, "seek": 171648, "start": 1727.44, "end": 1732.16, "text": " or a bicycle image to look at the summit to to relate to this image here we put in a bicycle", "tokens": [50912, 420, 257, 20888, 3256, 281, 574, 412, 264, 21564, 281, 281, 10961, 281, 341, 3256, 510, 321, 829, 294, 257, 20888, 51148], "temperature": 0.0, "avg_logprob": -0.10446380009160977, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.030211836099624634}, {"id": 310, "seek": 171648, "start": 1732.16, "end": 1737.04, "text": " image and the bike label we pass it through the each layer dot product dot product dot you know", "tokens": [51148, 3256, 293, 264, 5656, 7645, 321, 1320, 309, 807, 264, 1184, 4583, 5893, 1674, 5893, 1674, 5893, 291, 458, 51392], "temperature": 0.0, "avg_logprob": -0.10446380009160977, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.030211836099624634}, {"id": 311, "seek": 171648, "start": 1737.04, "end": 1742.96, "text": " dot product activation function pool dot product repeat repeat soft max or squash into probability", "tokens": [51392, 5893, 1674, 24433, 2445, 7005, 5893, 1674, 7149, 7149, 2787, 11469, 420, 30725, 666, 8482, 51688], "temperature": 0.0, "avg_logprob": -0.10446380009160977, "compression_ratio": 1.9957805907172996, "no_speech_prob": 0.030211836099624634}, {"id": 312, "seek": 174296, "start": 1742.96, "end": 1747.68, "text": " values pick the biggest one and we have some prediction value and what we do is we compare", "tokens": [50364, 4190, 1888, 264, 3880, 472, 293, 321, 362, 512, 17630, 2158, 293, 437, 321, 360, 307, 321, 6794, 50600], "temperature": 0.0, "avg_logprob": -0.05162722173363271, "compression_ratio": 1.974468085106383, "no_speech_prob": 0.01691288687288761}, {"id": 313, "seek": 174296, "start": 1747.68, "end": 1752.48, "text": " the prediction value to the out the actual value and we get an error and we take our error", "tokens": [50600, 264, 17630, 2158, 281, 264, 484, 264, 3539, 2158, 293, 321, 483, 364, 6713, 293, 321, 747, 527, 6713, 50840], "temperature": 0.0, "avg_logprob": -0.05162722173363271, "compression_ratio": 1.974468085106383, "no_speech_prob": 0.01691288687288761}, {"id": 314, "seek": 174296, "start": 1752.48, "end": 1756.72, "text": " and we compute the partial derivative of the error with respect to each weight value", "tokens": [50840, 293, 321, 14722, 264, 14641, 13760, 295, 264, 6713, 365, 3104, 281, 1184, 3364, 2158, 51052], "temperature": 0.0, "avg_logprob": -0.05162722173363271, "compression_ratio": 1.974468085106383, "no_speech_prob": 0.01691288687288761}, {"id": 315, "seek": 174296, "start": 1756.72, "end": 1763.28, "text": " going backwards in the network okay like this okay and so for regression we use the mean squared", "tokens": [51052, 516, 12204, 294, 264, 3209, 1392, 411, 341, 1392, 293, 370, 337, 24590, 321, 764, 264, 914, 8889, 51380], "temperature": 0.0, "avg_logprob": -0.05162722173363271, "compression_ratio": 1.974468085106383, "no_speech_prob": 0.01691288687288761}, {"id": 316, "seek": 174296, "start": 1763.28, "end": 1768.96, "text": " error if we're using linear regression regression and for classification we use the softmax function", "tokens": [51380, 6713, 498, 321, 434, 1228, 8213, 24590, 24590, 293, 337, 21538, 321, 764, 264, 2787, 41167, 2445, 51664], "temperature": 0.0, "avg_logprob": -0.05162722173363271, "compression_ratio": 1.974468085106383, "no_speech_prob": 0.01691288687288761}, {"id": 317, "seek": 176896, "start": 1768.96, "end": 1773.44, "text": " so remember how in the first neural network we built and in their linear regression example", "tokens": [50364, 370, 1604, 577, 294, 264, 700, 18161, 3209, 321, 3094, 293, 294, 641, 8213, 24590, 1365, 50588], "temperature": 0.0, "avg_logprob": -0.05063321703956241, "compression_ratio": 1.8452380952380953, "no_speech_prob": 0.0007553811301477253}, {"id": 318, "seek": 176896, "start": 1773.44, "end": 1779.92, "text": " we used a uh we use mean squared error to compute the error and now we're using the softmax", "tokens": [50588, 321, 1143, 257, 2232, 321, 764, 914, 8889, 6713, 281, 14722, 264, 6713, 293, 586, 321, 434, 1228, 264, 2787, 41167, 50912], "temperature": 0.0, "avg_logprob": -0.05063321703956241, "compression_ratio": 1.8452380952380953, "no_speech_prob": 0.0007553811301477253}, {"id": 319, "seek": 176896, "start": 1779.92, "end": 1783.76, "text": " so we'll take the so we'll take the partial derivative of the error with respect to our", "tokens": [50912, 370, 321, 603, 747, 264, 370, 321, 603, 747, 264, 14641, 13760, 295, 264, 6713, 365, 3104, 281, 527, 51104], "temperature": 0.0, "avg_logprob": -0.05063321703956241, "compression_ratio": 1.8452380952380953, "no_speech_prob": 0.0007553811301477253}, {"id": 320, "seek": 176896, "start": 1783.76, "end": 1788.48, "text": " weights and then that's going to give us the gradient value that we then update each of those", "tokens": [51104, 17443, 293, 550, 300, 311, 516, 281, 976, 505, 264, 16235, 2158, 300, 321, 550, 5623, 1184, 295, 729, 51340], "temperature": 0.0, "avg_logprob": -0.05063321703956241, "compression_ratio": 1.8452380952380953, "no_speech_prob": 0.0007553811301477253}, {"id": 321, "seek": 176896, "start": 1788.48, "end": 1794.0, "text": " weight values recursively going backward in the network and that's how it learns what this features", "tokens": [51340, 3364, 4190, 20560, 3413, 516, 23897, 294, 264, 3209, 293, 300, 311, 577, 309, 27152, 437, 341, 4122, 51616], "temperature": 0.0, "avg_logprob": -0.05063321703956241, "compression_ratio": 1.8452380952380953, "no_speech_prob": 0.0007553811301477253}, {"id": 322, "seek": 179400, "start": 1794.0, "end": 1799.44, "text": " what the ideal feature the weight matrix value should be but what about the other", "tokens": [50364, 437, 264, 7157, 4111, 264, 3364, 8141, 2158, 820, 312, 457, 437, 466, 264, 661, 50636], "temperature": 0.0, "avg_logprob": -0.10307871126661114, "compression_ratio": 2.0303030303030303, "no_speech_prob": 0.031140100210905075}, {"id": 323, "seek": 179400, "start": 1800.56, "end": 1804.56, "text": " what about the other magic numbers what about the number of neurons and the number of features", "tokens": [50692, 437, 466, 264, 661, 5585, 3547, 437, 466, 264, 1230, 295, 22027, 293, 264, 1230, 295, 4122, 50892], "temperature": 0.0, "avg_logprob": -0.10307871126661114, "compression_ratio": 2.0303030303030303, "no_speech_prob": 0.031140100210905075}, {"id": 324, "seek": 179400, "start": 1804.56, "end": 1809.2, "text": " and the size of those features and the pooling window size and the window stride well those that", "tokens": [50892, 293, 264, 2744, 295, 729, 4122, 293, 264, 7005, 278, 4910, 2744, 293, 264, 4910, 1056, 482, 731, 729, 300, 51124], "temperature": 0.0, "avg_logprob": -0.10307871126661114, "compression_ratio": 2.0303030303030303, "no_speech_prob": 0.031140100210905075}, {"id": 325, "seek": 179400, "start": 1809.2, "end": 1814.56, "text": " is an active area of research there are best practices for values that you should use for those", "tokens": [51124, 307, 364, 4967, 1859, 295, 2132, 456, 366, 1151, 7525, 337, 4190, 300, 291, 820, 764, 337, 729, 51392], "temperature": 0.0, "avg_logprob": -0.10307871126661114, "compression_ratio": 2.0303030303030303, "no_speech_prob": 0.031140100210905075}, {"id": 326, "seek": 179400, "start": 1814.56, "end": 1820.56, "text": " for those hyper parameters right the tuning knobs of our network and andrew karpathy has some great", "tokens": [51392, 337, 729, 9848, 9834, 558, 264, 15164, 46999, 295, 527, 3209, 293, 293, 2236, 350, 6529, 9527, 575, 512, 869, 51692], "temperature": 0.0, "avg_logprob": -0.10307871126661114, "compression_ratio": 2.0303030303030303, "no_speech_prob": 0.031140100210905075}, {"id": 327, "seek": 182056, "start": 1820.56, "end": 1824.32, "text": " material on this and he's probably the leading source for convolutional networks right now in", "tokens": [50364, 2527, 322, 341, 293, 415, 311, 1391, 264, 5775, 4009, 337, 45216, 304, 9590, 558, 586, 294, 50552], "temperature": 0.0, "avg_logprob": -0.06066802312742989, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.06186409294605255}, {"id": 328, "seek": 182056, "start": 1824.32, "end": 1831.52, "text": " terms of um written contents and uh yeah i mean this is an active area of research finding out", "tokens": [50552, 2115, 295, 1105, 3720, 15768, 293, 2232, 1338, 741, 914, 341, 307, 364, 4967, 1859, 295, 2132, 5006, 484, 50912], "temperature": 0.0, "avg_logprob": -0.06066802312742989, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.06186409294605255}, {"id": 329, "seek": 182056, "start": 1831.52, "end": 1835.36, "text": " what the ideal hyper parameters for our neural network should be and we're still learning what", "tokens": [50912, 437, 264, 7157, 9848, 9834, 337, 527, 18161, 3209, 820, 312, 293, 321, 434, 920, 2539, 437, 51104], "temperature": 0.0, "avg_logprob": -0.06066802312742989, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.06186409294605255}, {"id": 330, "seek": 182056, "start": 1835.36, "end": 1840.56, "text": " it should be what what what what how we can get them rather than just guessing and checking which", "tokens": [51104, 309, 820, 312, 437, 437, 437, 437, 577, 321, 393, 483, 552, 2831, 813, 445, 17939, 293, 8568, 597, 51364], "temperature": 0.0, "avg_logprob": -0.06066802312742989, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.06186409294605255}, {"id": 331, "seek": 182056, "start": 1840.56, "end": 1846.48, "text": " is what we do right now which is kind of like you know not it's not as optimal right so anyway", "tokens": [51364, 307, 437, 321, 360, 558, 586, 597, 307, 733, 295, 411, 291, 458, 406, 309, 311, 406, 382, 16252, 558, 370, 4033, 51660], "temperature": 0.0, "avg_logprob": -0.06066802312742989, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.06186409294605255}, {"id": 332, "seek": 184648, "start": 1847.28, "end": 1850.8, "text": " last two things and then we're gonna get started with the code when is a good time to use this", "tokens": [50404, 1036, 732, 721, 293, 550, 321, 434, 799, 483, 1409, 365, 264, 3089, 562, 307, 257, 665, 565, 281, 764, 341, 50580], "temperature": 0.0, "avg_logprob": -0.05015958600969457, "compression_ratio": 1.91156462585034, "no_speech_prob": 0.034094445407390594}, {"id": 333, "seek": 184648, "start": 1850.8, "end": 1854.88, "text": " well we know to classify images we've talked about that but you can also use them to generate", "tokens": [50580, 731, 321, 458, 281, 33872, 5267, 321, 600, 2825, 466, 300, 457, 291, 393, 611, 764, 552, 281, 8460, 50784], "temperature": 0.0, "avg_logprob": -0.05015958600969457, "compression_ratio": 1.91156462585034, "no_speech_prob": 0.034094445407390594}, {"id": 334, "seek": 184648, "start": 1854.88, "end": 1859.52, "text": " images and that's for later on that's a little more advanced but to give you a little spoiler", "tokens": [50784, 5267, 293, 300, 311, 337, 1780, 322, 300, 311, 257, 707, 544, 7339, 457, 281, 976, 291, 257, 707, 26927, 51016], "temperature": 0.0, "avg_logprob": -0.05015958600969457, "compression_ratio": 1.91156462585034, "no_speech_prob": 0.034094445407390594}, {"id": 335, "seek": 184648, "start": 1859.52, "end": 1863.76, "text": " a little teaser in fact this is in my intro to deep learning playlist you take a convolutional", "tokens": [51016, 257, 707, 35326, 294, 1186, 341, 307, 294, 452, 12897, 281, 2452, 2539, 16788, 291, 747, 257, 45216, 304, 51228], "temperature": 0.0, "avg_logprob": -0.05015958600969457, "compression_ratio": 1.91156462585034, "no_speech_prob": 0.034094445407390594}, {"id": 336, "seek": 184648, "start": 1863.76, "end": 1867.68, "text": " network you flip it and then you call it a deconvolutional network and then you can take", "tokens": [51228, 3209, 291, 7929, 309, 293, 550, 291, 818, 309, 257, 979, 266, 85, 3386, 304, 3209, 293, 550, 291, 393, 747, 51424], "temperature": 0.0, "avg_logprob": -0.05015958600969457, "compression_ratio": 1.91156462585034, "no_speech_prob": 0.034094445407390594}, {"id": 337, "seek": 184648, "start": 1867.68, "end": 1875.04, "text": " some text and create an image out of text how crazy is that okay there's also generative models", "tokens": [51424, 512, 2487, 293, 1884, 364, 3256, 484, 295, 2487, 577, 3219, 307, 300, 1392, 456, 311, 611, 1337, 1166, 5245, 51792], "temperature": 0.0, "avg_logprob": -0.05015958600969457, "compression_ratio": 1.91156462585034, "no_speech_prob": 0.034094445407390594}, {"id": 338, "seek": 187504, "start": 1875.04, "end": 1878.8, "text": " where you have two networks fighting each other and you can generate new images a whole bunch", "tokens": [50364, 689, 291, 362, 732, 9590, 5237, 1184, 661, 293, 291, 393, 8460, 777, 5267, 257, 1379, 3840, 50552], "temperature": 0.0, "avg_logprob": -0.06530128534023578, "compression_ratio": 1.8932806324110671, "no_speech_prob": 0.03963154926896095}, {"id": 339, "seek": 187504, "start": 1878.8, "end": 1884.32, "text": " of really cool crazy stuff you can do but anyway when should you use a convolutional network", "tokens": [50552, 295, 534, 1627, 3219, 1507, 291, 393, 360, 457, 4033, 562, 820, 291, 764, 257, 45216, 304, 3209, 50828], "temperature": 0.0, "avg_logprob": -0.06530128534023578, "compression_ratio": 1.8932806324110671, "no_speech_prob": 0.03963154926896095}, {"id": 340, "seek": 187504, "start": 1884.32, "end": 1890.6399999999999, "text": " anytime you have spatial 2d or 3d data what do i mean well obviously images are spatial the word", "tokens": [50828, 13038, 291, 362, 23598, 568, 67, 420, 805, 67, 1412, 437, 360, 741, 914, 731, 2745, 5267, 366, 23598, 264, 1349, 51144], "temperature": 0.0, "avg_logprob": -0.06530128534023578, "compression_ratio": 1.8932806324110671, "no_speech_prob": 0.03963154926896095}, {"id": 341, "seek": 187504, "start": 1890.6399999999999, "end": 1897.76, "text": " spatial implies that the space the positioning of the data matters so sound you can apply to sound", "tokens": [51144, 23598, 18779, 300, 264, 1901, 264, 26381, 295, 264, 1412, 7001, 370, 1626, 291, 393, 3079, 281, 1626, 51500], "temperature": 0.0, "avg_logprob": -0.06530128534023578, "compression_ratio": 1.8932806324110671, "no_speech_prob": 0.03963154926896095}, {"id": 342, "seek": 187504, "start": 1897.76, "end": 1904.08, "text": " images or text where the the the position of the text matters right because we have a flashlight", "tokens": [51500, 5267, 420, 2487, 689, 264, 264, 264, 2535, 295, 264, 2487, 7001, 558, 570, 321, 362, 257, 30835, 51816], "temperature": 0.0, "avg_logprob": -0.06530128534023578, "compression_ratio": 1.8932806324110671, "no_speech_prob": 0.03963154926896095}, {"id": 343, "seek": 190408, "start": 1904.1599999999999, "end": 1910.0, "text": " our filter and we're convolving over an image right but if you have some data like say customer", "tokens": [50368, 527, 6608, 293, 321, 434, 3754, 401, 798, 670, 364, 3256, 558, 457, 498, 291, 362, 512, 1412, 411, 584, 5474, 50660], "temperature": 0.0, "avg_logprob": -0.04711779826829413, "compression_ratio": 1.908, "no_speech_prob": 0.008576564490795135}, {"id": 344, "seek": 190408, "start": 1910.0, "end": 1914.3999999999999, "text": " data where if you were to just flip the rows and columns it doesn't matter what order they're in", "tokens": [50660, 1412, 689, 498, 291, 645, 281, 445, 7929, 264, 13241, 293, 13766, 309, 1177, 380, 1871, 437, 1668, 436, 434, 294, 50880], "temperature": 0.0, "avg_logprob": -0.04711779826829413, "compression_ratio": 1.908, "no_speech_prob": 0.008576564490795135}, {"id": 345, "seek": 190408, "start": 1914.3999999999999, "end": 1919.84, "text": " they're still you know they're still features so a good rule of thumb is if you swap out the rows", "tokens": [50880, 436, 434, 920, 291, 458, 436, 434, 920, 4122, 370, 257, 665, 4978, 295, 9298, 307, 498, 291, 18135, 484, 264, 13241, 51152], "temperature": 0.0, "avg_logprob": -0.04711779826829413, "compression_ratio": 1.908, "no_speech_prob": 0.008576564490795135}, {"id": 346, "seek": 190408, "start": 1919.84, "end": 1925.6, "text": " and columns of your data set and it's just as useful like the space doesn't matter then you", "tokens": [51152, 293, 13766, 295, 428, 1412, 992, 293, 309, 311, 445, 382, 4420, 411, 264, 1901, 1177, 380, 1871, 550, 291, 51440], "temperature": 0.0, "avg_logprob": -0.04711779826829413, "compression_ratio": 1.908, "no_speech_prob": 0.008576564490795135}, {"id": 347, "seek": 190408, "start": 1925.6, "end": 1930.72, "text": " don't want to use a cnn else you do okay and a great and last thing the great example of using", "tokens": [51440, 500, 380, 528, 281, 764, 257, 269, 26384, 1646, 291, 360, 1392, 293, 257, 869, 293, 1036, 551, 264, 869, 1365, 295, 1228, 51696], "temperature": 0.0, "avg_logprob": -0.04711779826829413, "compression_ratio": 1.908, "no_speech_prob": 0.008576564490795135}, {"id": 348, "seek": 193072, "start": 1930.72, "end": 1935.76, "text": " cnn's are for robot learning you can use a cnn for object detection and you can use a cnn for", "tokens": [50364, 269, 26384, 311, 366, 337, 7881, 2539, 291, 393, 764, 257, 269, 26384, 337, 2657, 17784, 293, 291, 393, 764, 257, 269, 26384, 337, 50616], "temperature": 0.0, "avg_logprob": -0.045875136591807135, "compression_ratio": 1.908, "no_speech_prob": 0.046023011207580566}, {"id": 349, "seek": 193072, "start": 1935.76, "end": 1940.56, "text": " grasp learning and combine the two and then you can get a robot that cooks which is really cool", "tokens": [50616, 21743, 2539, 293, 10432, 264, 732, 293, 550, 291, 393, 483, 257, 7881, 300, 30709, 597, 307, 534, 1627, 50856], "temperature": 0.0, "avg_logprob": -0.045875136591807135, "compression_ratio": 1.908, "no_speech_prob": 0.046023011207580566}, {"id": 350, "seek": 193072, "start": 1940.56, "end": 1945.68, "text": " i've got a great tensorflow example and a great adversarial network example okay let's go into", "tokens": [50856, 741, 600, 658, 257, 869, 40863, 10565, 1365, 293, 257, 869, 17641, 44745, 3209, 1365, 1392, 718, 311, 352, 666, 51112], "temperature": 0.0, "avg_logprob": -0.045875136591807135, "compression_ratio": 1.908, "no_speech_prob": 0.046023011207580566}, {"id": 351, "seek": 193072, "start": 1945.68, "end": 1951.76, "text": " the code now and so what i'm going to do is i'm going to look at the class for the convolutional", "tokens": [51112, 264, 3089, 586, 293, 370, 437, 741, 478, 516, 281, 360, 307, 741, 478, 516, 281, 574, 412, 264, 1508, 337, 264, 45216, 304, 51416], "temperature": 0.0, "avg_logprob": -0.045875136591807135, "compression_ratio": 1.908, "no_speech_prob": 0.046023011207580566}, {"id": 352, "seek": 193072, "start": 1951.76, "end": 1956.88, "text": " network in numpy as well as the prediction class there's two classes here okay so these are our", "tokens": [51416, 3209, 294, 1031, 8200, 382, 731, 382, 264, 17630, 1508, 456, 311, 732, 5359, 510, 1392, 370, 613, 366, 527, 51672], "temperature": 0.0, "avg_logprob": -0.045875136591807135, "compression_ratio": 1.908, "no_speech_prob": 0.046023011207580566}, {"id": 353, "seek": 195688, "start": 1956.88, "end": 1963.2800000000002, "text": " three inputs pickle is for saving and loading our serialized model what do i mean pickle is", "tokens": [50364, 1045, 15743, 31433, 307, 337, 6816, 293, 15114, 527, 17436, 1602, 2316, 437, 360, 741, 914, 31433, 307, 50684], "temperature": 0.0, "avg_logprob": -0.05015038607413309, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.023328538984060287}, {"id": 354, "seek": 195688, "start": 1963.2800000000002, "end": 1968.88, "text": " python's way of having a platform or language agnostic way of saving data so you can load it", "tokens": [50684, 38797, 311, 636, 295, 1419, 257, 3663, 420, 2856, 623, 77, 19634, 636, 295, 6816, 1412, 370, 291, 393, 3677, 309, 50964], "temperature": 0.0, "avg_logprob": -0.05015038607413309, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.023328538984060287}, {"id": 355, "seek": 195688, "start": 1968.88, "end": 1974.16, "text": " up later tensorflow uses it a bunch of other libraries use it as well numpy is for matrix math", "tokens": [50964, 493, 1780, 40863, 10565, 4960, 309, 257, 3840, 295, 661, 15148, 764, 309, 382, 731, 1031, 8200, 307, 337, 8141, 5221, 51228], "temperature": 0.0, "avg_logprob": -0.05015038607413309, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.023328538984060287}, {"id": 356, "seek": 195688, "start": 1974.16, "end": 1978.4, "text": " and we've got our own little custom class for pre-processing the data because we don't care", "tokens": [51228, 293, 321, 600, 658, 527, 1065, 707, 2375, 1508, 337, 659, 12, 41075, 278, 264, 1412, 570, 321, 500, 380, 1127, 51440], "temperature": 0.0, "avg_logprob": -0.05015038607413309, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.023328538984060287}, {"id": 357, "seek": 195688, "start": 1978.4, "end": 1984.48, "text": " about that part we care about the machine learning part okay so let's talk about our light ocr or", "tokens": [51440, 466, 300, 644, 321, 1127, 466, 264, 3479, 2539, 644, 1392, 370, 718, 311, 751, 466, 527, 1442, 10409, 81, 420, 51744], "temperature": 0.0, "avg_logprob": -0.05015038607413309, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.023328538984060287}, {"id": 358, "seek": 198448, "start": 1984.56, "end": 1989.3600000000001, "text": " object optical character recognition class in our initialized function we're going to load the", "tokens": [50368, 2657, 20674, 2517, 11150, 1508, 294, 527, 5883, 1602, 2445, 321, 434, 516, 281, 3677, 264, 50608], "temperature": 0.0, "avg_logprob": -0.05602629525320871, "compression_ratio": 1.9322709163346614, "no_speech_prob": 0.010327138938009739}, {"id": 359, "seek": 198448, "start": 1989.3600000000001, "end": 1993.84, "text": " weights from the pickle file and then store and then store all the labels that we've loaded", "tokens": [50608, 17443, 490, 264, 31433, 3991, 293, 550, 3531, 293, 550, 3531, 439, 264, 16949, 300, 321, 600, 13210, 50832], "temperature": 0.0, "avg_logprob": -0.05602629525320871, "compression_ratio": 1.9322709163346614, "no_speech_prob": 0.010327138938009739}, {"id": 360, "seek": 198448, "start": 1993.84, "end": 1999.04, "text": " we'll define how many rows and columns in an image load up our convolutional network using the light", "tokens": [50832, 321, 603, 6964, 577, 867, 13241, 293, 13766, 294, 364, 3256, 3677, 493, 527, 45216, 304, 3209, 1228, 264, 1442, 51092], "temperature": 0.0, "avg_logprob": -0.05602629525320871, "compression_ratio": 1.9322709163346614, "no_speech_prob": 0.010327138938009739}, {"id": 361, "seek": 198448, "start": 1999.04, "end": 2004.24, "text": " cnn function with our saved weights so assuming we've already trained our network we load it with", "tokens": [51092, 269, 26384, 2445, 365, 527, 6624, 17443, 370, 11926, 321, 600, 1217, 8895, 527, 3209, 321, 3677, 309, 365, 51352], "temperature": 0.0, "avg_logprob": -0.05602629525320871, "compression_ratio": 1.9322709163346614, "no_speech_prob": 0.010327138938009739}, {"id": 362, "seek": 198448, "start": 2004.24, "end": 2009.84, "text": " the saved weights from the pickle file and then we define the number of pooling layers okay so once", "tokens": [51352, 264, 6624, 17443, 490, 264, 31433, 3991, 293, 550, 321, 6964, 264, 1230, 295, 7005, 278, 7914, 1392, 370, 1564, 51632], "temperature": 0.0, "avg_logprob": -0.05602629525320871, "compression_ratio": 1.9322709163346614, "no_speech_prob": 0.010327138938009739}, {"id": 363, "seek": 200984, "start": 2009.84, "end": 2015.1999999999998, "text": " we have that then we can use this predict function so given some new image we'll reshape the image so", "tokens": [50364, 321, 362, 300, 550, 321, 393, 764, 341, 6069, 2445, 370, 2212, 512, 777, 3256, 321, 603, 725, 42406, 264, 3256, 370, 50632], "temperature": 0.0, "avg_logprob": -0.04389135376745913, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.015423725359141827}, {"id": 364, "seek": 200984, "start": 2015.1999999999998, "end": 2020.48, "text": " it's in the correct size to perform the dot product between that image and the first layer of our", "tokens": [50632, 309, 311, 294, 264, 3006, 2744, 281, 2042, 264, 5893, 1674, 1296, 300, 3256, 293, 264, 700, 4583, 295, 527, 50896], "temperature": 0.0, "avg_logprob": -0.04389135376745913, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.015423725359141827}, {"id": 365, "seek": 200984, "start": 2020.48, "end": 2026.8799999999999, "text": " convolutional network and we'll we'll we'll put it we'll feed it into our network and it's going to", "tokens": [50896, 45216, 304, 3209, 293, 321, 603, 321, 603, 321, 603, 829, 309, 321, 603, 3154, 309, 666, 527, 3209, 293, 309, 311, 516, 281, 51216], "temperature": 0.0, "avg_logprob": -0.04389135376745913, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.015423725359141827}, {"id": 366, "seek": 200984, "start": 2026.8799999999999, "end": 2031.6, "text": " output a prediction probability for a class and we'll return it okay super high level we haven't", "tokens": [51216, 5598, 257, 17630, 8482, 337, 257, 1508, 293, 321, 603, 2736, 309, 1392, 1687, 1090, 1496, 321, 2378, 380, 51452], "temperature": 0.0, "avg_logprob": -0.04389135376745913, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.015423725359141827}, {"id": 367, "seek": 200984, "start": 2031.6, "end": 2037.28, "text": " even coded our cnn that's that's our first class that's our prediction class now now we're going", "tokens": [51452, 754, 34874, 527, 269, 26384, 300, 311, 300, 311, 527, 700, 1508, 300, 311, 527, 17630, 1508, 586, 586, 321, 434, 516, 51736], "temperature": 0.0, "avg_logprob": -0.04389135376745913, "compression_ratio": 1.9409448818897639, "no_speech_prob": 0.015423725359141827}, {"id": 368, "seek": 203728, "start": 2037.28, "end": 2041.2, "text": " to look at the convolutional network class and what i'm going to do is i'm going to i'm going to", "tokens": [50364, 281, 574, 412, 264, 45216, 304, 3209, 1508, 293, 437, 741, 478, 516, 281, 360, 307, 741, 478, 516, 281, 741, 478, 516, 281, 50560], "temperature": 0.0, "avg_logprob": -0.0428002975026115, "compression_ratio": 2.0543933054393304, "no_speech_prob": 0.004331301432102919}, {"id": 369, "seek": 203728, "start": 2041.2, "end": 2048.24, "text": " go over the code and i'm going to code some parts of it so now we'll look at our convolutional", "tokens": [50560, 352, 670, 264, 3089, 293, 741, 478, 516, 281, 3089, 512, 3166, 295, 309, 370, 586, 321, 603, 574, 412, 527, 45216, 304, 50912], "temperature": 0.0, "avg_logprob": -0.0428002975026115, "compression_ratio": 2.0543933054393304, "no_speech_prob": 0.004331301432102919}, {"id": 370, "seek": 203728, "start": 2048.24, "end": 2054.16, "text": " network class okay so in our initialized function we'll initialize two lists one to store the layers", "tokens": [50912, 3209, 1508, 1392, 370, 294, 527, 5883, 1602, 2445, 321, 603, 5883, 1125, 732, 14511, 472, 281, 3531, 264, 7914, 51208], "temperature": 0.0, "avg_logprob": -0.0428002975026115, "compression_ratio": 2.0543933054393304, "no_speech_prob": 0.004331301432102919}, {"id": 371, "seek": 203728, "start": 2054.16, "end": 2059.52, "text": " that we've learned the the weights of each layer and then the size of the pooling area for max pooling", "tokens": [51208, 300, 321, 600, 3264, 264, 264, 17443, 295, 1184, 4583, 293, 550, 264, 2744, 295, 264, 7005, 278, 1859, 337, 11469, 7005, 278, 51476], "temperature": 0.0, "avg_logprob": -0.0428002975026115, "compression_ratio": 2.0543933054393304, "no_speech_prob": 0.004331301432102919}, {"id": 372, "seek": 203728, "start": 2059.52, "end": 2065.36, "text": " okay we'll load up our weights from our pickle file just like this and then we have our predict", "tokens": [51476, 1392, 321, 603, 3677, 493, 527, 17443, 490, 527, 31433, 3991, 445, 411, 341, 293, 550, 321, 362, 527, 6069, 51768], "temperature": 0.0, "avg_logprob": -0.0428002975026115, "compression_ratio": 2.0543933054393304, "no_speech_prob": 0.004331301432102919}, {"id": 373, "seek": 206536, "start": 2065.36, "end": 2069.52, "text": " function now in our predict function that's where the real magic is happening right let's", "tokens": [50364, 2445, 586, 294, 527, 6069, 2445, 300, 311, 689, 264, 957, 5585, 307, 2737, 558, 718, 311, 50572], "temperature": 0.0, "avg_logprob": -0.05004254762116853, "compression_ratio": 2.0833333333333335, "no_speech_prob": 0.009124687872827053}, {"id": 374, "seek": 206536, "start": 2069.52, "end": 2074.08, "text": " code what this looks like so given some input x we're going to feed it through all of these", "tokens": [50572, 3089, 437, 341, 1542, 411, 370, 2212, 512, 4846, 2031, 321, 434, 516, 281, 3154, 309, 807, 439, 295, 613, 50800], "temperature": 0.0, "avg_logprob": -0.05004254762116853, "compression_ratio": 2.0833333333333335, "no_speech_prob": 0.009124687872827053}, {"id": 375, "seek": 206536, "start": 2074.6400000000003, "end": 2082.88, "text": " layers right so what happens is we will say okay so the first layer is going to be a convolutional", "tokens": [50828, 7914, 558, 370, 437, 2314, 307, 321, 486, 584, 1392, 370, 264, 700, 4583, 307, 516, 281, 312, 257, 45216, 304, 51240], "temperature": 0.0, "avg_logprob": -0.05004254762116853, "compression_ratio": 2.0833333333333335, "no_speech_prob": 0.009124687872827053}, {"id": 376, "seek": 206536, "start": 2082.88, "end": 2087.28, "text": " layer okay and we're going to define what all of these functions look like look like but the first", "tokens": [51240, 4583, 1392, 293, 321, 434, 516, 281, 6964, 437, 439, 295, 613, 6828, 574, 411, 574, 411, 457, 264, 700, 51460], "temperature": 0.0, "avg_logprob": -0.05004254762116853, "compression_ratio": 2.0833333333333335, "no_speech_prob": 0.009124687872827053}, {"id": 377, "seek": 206536, "start": 2087.28, "end": 2091.6800000000003, "text": " layer is going to be that convolutional layer we'll feed in that first image and we'll say okay", "tokens": [51460, 4583, 307, 516, 281, 312, 300, 45216, 304, 4583, 321, 603, 3154, 294, 300, 700, 3256, 293, 321, 603, 584, 1392, 51680], "temperature": 0.0, "avg_logprob": -0.05004254762116853, "compression_ratio": 2.0833333333333335, "no_speech_prob": 0.009124687872827053}, {"id": 378, "seek": 209168, "start": 2091.68, "end": 2096.64, "text": " well this is the first layer so it's a zeroth layer we'll say border mode equals full and i'll", "tokens": [50364, 731, 341, 307, 264, 700, 4583, 370, 309, 311, 257, 44746, 900, 4583, 321, 603, 584, 7838, 4391, 6915, 1577, 293, 741, 603, 50612], "temperature": 0.0, "avg_logprob": -0.04082377354303996, "compression_ratio": 2.0606060606060606, "no_speech_prob": 0.01590459793806076}, {"id": 379, "seek": 209168, "start": 2096.64, "end": 2102.0, "text": " talk about that part later on but that's it for that and so what happens is x equals this layer", "tokens": [50612, 751, 466, 300, 644, 1780, 322, 457, 300, 311, 309, 337, 300, 293, 370, 437, 2314, 307, 2031, 6915, 341, 4583, 50880], "temperature": 0.0, "avg_logprob": -0.04082377354303996, "compression_ratio": 2.0606060606060606, "no_speech_prob": 0.01590459793806076}, {"id": 380, "seek": 209168, "start": 2102.0, "end": 2107.7599999999998, "text": " okay so that's our first layer and then our next layer is going to be relu so we'll say okay now", "tokens": [50880, 1392, 370, 300, 311, 527, 700, 4583, 293, 550, 527, 958, 4583, 307, 516, 281, 312, 1039, 84, 370, 321, 603, 584, 1392, 586, 51168], "temperature": 0.0, "avg_logprob": -0.04082377354303996, "compression_ratio": 2.0606060606060606, "no_speech_prob": 0.01590459793806076}, {"id": 381, "seek": 209168, "start": 2107.7599999999998, "end": 2114.3999999999996, "text": " let's apply an activation to the output of the previous layer okay and then we'll set it equal", "tokens": [51168, 718, 311, 3079, 364, 24433, 281, 264, 5598, 295, 264, 3894, 4583, 1392, 293, 550, 321, 603, 992, 309, 2681, 51500], "temperature": 0.0, "avg_logprob": -0.04082377354303996, "compression_ratio": 2.0606060606060606, "no_speech_prob": 0.01590459793806076}, {"id": 382, "seek": 209168, "start": 2114.3999999999996, "end": 2120.08, "text": " to that okay so we'll set the output from the previous layer equal to the input of this layer", "tokens": [51500, 281, 300, 1392, 370, 321, 603, 992, 264, 5598, 490, 264, 3894, 4583, 2681, 281, 264, 4846, 295, 341, 4583, 51784], "temperature": 0.0, "avg_logprob": -0.04082377354303996, "compression_ratio": 2.0606060606060606, "no_speech_prob": 0.01590459793806076}, {"id": 383, "seek": 212008, "start": 2120.08, "end": 2125.84, "text": " and then we keep going we say okay so we've got another uh cnn we have another convolutional layer", "tokens": [50364, 293, 550, 321, 1066, 516, 321, 584, 1392, 370, 321, 600, 658, 1071, 2232, 269, 26384, 321, 362, 1071, 45216, 304, 4583, 50652], "temperature": 0.0, "avg_logprob": -0.05492070256447305, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.003945117816329002}, {"id": 384, "seek": 212008, "start": 2125.84, "end": 2131.44, "text": " and we do the same thing here we say okay take the in output from the previous layer we'll define", "tokens": [50652, 293, 321, 360, 264, 912, 551, 510, 321, 584, 1392, 747, 264, 294, 5598, 490, 264, 3894, 4583, 321, 603, 6964, 50932], "temperature": 0.0, "avg_logprob": -0.05492070256447305, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.003945117816329002}, {"id": 385, "seek": 212008, "start": 2131.44, "end": 2136.08, "text": " what the uh name of this layer is as well as the border mode which i'll talk about the very end of", "tokens": [50932, 437, 264, 2232, 1315, 295, 341, 4583, 307, 382, 731, 382, 264, 7838, 4391, 597, 741, 603, 751, 466, 264, 588, 917, 295, 51164], "temperature": 0.0, "avg_logprob": -0.05492070256447305, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.003945117816329002}, {"id": 386, "seek": 212008, "start": 2136.08, "end": 2143.6, "text": " this we have a border mode which is valid and then we say okay well we'll set the output of that", "tokens": [51164, 341, 321, 362, 257, 7838, 4391, 597, 307, 7363, 293, 550, 321, 584, 1392, 731, 321, 603, 992, 264, 5598, 295, 300, 51540], "temperature": 0.0, "avg_logprob": -0.05492070256447305, "compression_ratio": 1.9310344827586208, "no_speech_prob": 0.003945117816329002}, {"id": 387, "seek": 214360, "start": 2143.6, "end": 2148.7999999999997, "text": " equal to the input of this and just keep repeating now it's time for us to apply a", "tokens": [50364, 2681, 281, 264, 4846, 295, 341, 293, 445, 1066, 18617, 586, 309, 311, 565, 337, 505, 281, 3079, 257, 50624], "temperature": 0.0, "avg_logprob": -0.06345668591951069, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.5270311832427979}, {"id": 388, "seek": 214360, "start": 2149.6, "end": 2154.72, "text": " another non-linearity so we'll just go ahead and apply our non-linearity again remember these are", "tokens": [50664, 1071, 2107, 12, 1889, 17409, 370, 321, 603, 445, 352, 2286, 293, 3079, 527, 2107, 12, 1889, 17409, 797, 1604, 613, 366, 50920], "temperature": 0.0, "avg_logprob": -0.06345668591951069, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.5270311832427979}, {"id": 389, "seek": 214360, "start": 2154.72, "end": 2162.0, "text": " convolutional blocks oh and we also want to pool so also the the order with which you can do this", "tokens": [50920, 45216, 304, 8474, 1954, 293, 321, 611, 528, 281, 7005, 370, 611, 264, 264, 1668, 365, 597, 291, 393, 360, 341, 51284], "temperature": 0.0, "avg_logprob": -0.06345668591951069, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.5270311832427979}, {"id": 390, "seek": 214360, "start": 2162.0, "end": 2166.96, "text": " varies right you can do this in different ways and yeah so i'm doing it a certain way right now", "tokens": [51284, 21716, 558, 291, 393, 360, 341, 294, 819, 2098, 293, 1338, 370, 741, 478, 884, 309, 257, 1629, 636, 558, 586, 51532], "temperature": 0.0, "avg_logprob": -0.06345668591951069, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.5270311832427979}, {"id": 391, "seek": 214360, "start": 2166.96, "end": 2171.8399999999997, "text": " you know we could change it around it would change our result but the order map the ordering within", "tokens": [51532, 291, 458, 321, 727, 1319, 309, 926, 309, 576, 1319, 527, 1874, 457, 264, 1668, 4471, 264, 21739, 1951, 51776], "temperature": 0.0, "avg_logprob": -0.06345668591951069, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.5270311832427979}, {"id": 392, "seek": 217184, "start": 2171.84, "end": 2178.0, "text": " the block can be can be different okay so right so we're going to pool it we're going to pick the", "tokens": [50364, 264, 3461, 393, 312, 393, 312, 819, 1392, 370, 558, 370, 321, 434, 516, 281, 7005, 309, 321, 434, 516, 281, 1888, 264, 50672], "temperature": 0.0, "avg_logprob": -0.08013483490606751, "compression_ratio": 1.8450704225352113, "no_speech_prob": 0.007815361954271793}, {"id": 393, "seek": 217184, "start": 2178.0, "end": 2185.84, "text": " the most relevant features from from that uh from that output and then we're going to perform drop", "tokens": [50672, 264, 881, 7340, 4122, 490, 490, 300, 2232, 490, 300, 5598, 293, 550, 321, 434, 516, 281, 2042, 3270, 51064], "temperature": 0.0, "avg_logprob": -0.08013483490606751, "compression_ratio": 1.8450704225352113, "no_speech_prob": 0.007815361954271793}, {"id": 394, "seek": 217184, "start": 2185.84, "end": 2191.6800000000003, "text": " out to prevent overfitting and we're going to say there's going to be a 0.25 chance that a neuron", "tokens": [51064, 484, 281, 4871, 670, 69, 2414, 293, 321, 434, 516, 281, 584, 456, 311, 516, 281, 312, 257, 1958, 13, 6074, 2931, 300, 257, 34090, 51356], "temperature": 0.0, "avg_logprob": -0.08013483490606751, "compression_ratio": 1.8450704225352113, "no_speech_prob": 0.007815361954271793}, {"id": 395, "seek": 217184, "start": 2191.6800000000003, "end": 2196.96, "text": " is going to be deactivated that will turn it off set it to zero and that's our dropout probability", "tokens": [51356, 307, 516, 281, 312, 45428, 770, 300, 486, 1261, 309, 766, 992, 309, 281, 4018, 293, 300, 311, 527, 3270, 346, 8482, 51620], "temperature": 0.0, "avg_logprob": -0.08013483490606751, "compression_ratio": 1.8450704225352113, "no_speech_prob": 0.007815361954271793}, {"id": 396, "seek": 219696, "start": 2196.96, "end": 2204.88, "text": " value and then now we're getting into our our the second category of our network not the feature", "tokens": [50364, 2158, 293, 550, 586, 321, 434, 1242, 666, 527, 527, 264, 1150, 7719, 295, 527, 3209, 406, 264, 4111, 50760], "temperature": 0.0, "avg_logprob": -0.057216701300247856, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.06186923757195473}, {"id": 397, "seek": 219696, "start": 2204.88, "end": 2208.64, "text": " learning part but the classification part and we'll say okay so let's flatten this layer let's", "tokens": [50760, 2539, 644, 457, 264, 21538, 644, 293, 321, 603, 584, 1392, 370, 718, 311, 24183, 341, 4583, 718, 311, 50948], "temperature": 0.0, "avg_logprob": -0.057216701300247856, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.06186923757195473}, {"id": 398, "seek": 219696, "start": 2208.64, "end": 2216.0, "text": " reduce the dimensionality of all of that that data so it's something that we can then learn from", "tokens": [50948, 5407, 264, 10139, 1860, 295, 439, 295, 300, 300, 1412, 370, 309, 311, 746, 300, 321, 393, 550, 1466, 490, 51316], "temperature": 0.0, "avg_logprob": -0.057216701300247856, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.06186923757195473}, {"id": 399, "seek": 219696, "start": 2216.0, "end": 2222.16, "text": " and we'll say well let's let's set it equal to seven and then we'll say once again turn that output", "tokens": [51316, 293, 321, 603, 584, 731, 718, 311, 718, 311, 992, 309, 2681, 281, 3407, 293, 550, 321, 603, 584, 1564, 797, 1261, 300, 5598, 51624], "temperature": 0.0, "avg_logprob": -0.057216701300247856, "compression_ratio": 1.8046511627906976, "no_speech_prob": 0.06186923757195473}, {"id": 400, "seek": 222216, "start": 2222.16, "end": 2230.24, "text": " into our uh inputs here okay and so then we have another dense layer we just we just keep going", "tokens": [50364, 666, 527, 2232, 15743, 510, 1392, 293, 370, 550, 321, 362, 1071, 18011, 4583, 321, 445, 321, 445, 1066, 516, 50768], "temperature": 0.0, "avg_logprob": -0.047859236879168814, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.024421175941824913}, {"id": 401, "seek": 222216, "start": 2230.24, "end": 2234.64, "text": " with or our first dense layer and that means we are going to it's a fully connected layer so we're", "tokens": [50768, 365, 420, 527, 700, 18011, 4583, 293, 300, 1355, 321, 366, 516, 281, 309, 311, 257, 4498, 4582, 4583, 370, 321, 434, 50988], "temperature": 0.0, "avg_logprob": -0.047859236879168814, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.024421175941824913}, {"id": 402, "seek": 222216, "start": 2234.64, "end": 2239.7599999999998, "text": " combining everything that we've learned because we're getting really close to squashing these values", "tokens": [50988, 21928, 1203, 300, 321, 600, 3264, 570, 321, 434, 1242, 534, 1998, 281, 2339, 11077, 613, 4190, 51244], "temperature": 0.0, "avg_logprob": -0.047859236879168814, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.024421175941824913}, {"id": 403, "seek": 222216, "start": 2239.7599999999998, "end": 2244.7999999999997, "text": " into a set of probability values so we want to take all of our learnings and combine them", "tokens": [51244, 666, 257, 992, 295, 8482, 4190, 370, 321, 528, 281, 747, 439, 295, 527, 2539, 82, 293, 10432, 552, 51496], "temperature": 0.0, "avg_logprob": -0.047859236879168814, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.024421175941824913}, {"id": 404, "seek": 222216, "start": 2244.7999999999997, "end": 2250.0, "text": " with a fully connected layer and so we'll combine them with a fully connected layer", "tokens": [51496, 365, 257, 4498, 4582, 4583, 293, 370, 321, 603, 10432, 552, 365, 257, 4498, 4582, 4583, 51756], "temperature": 0.0, "avg_logprob": -0.047859236879168814, "compression_ratio": 1.9872881355932204, "no_speech_prob": 0.024421175941824913}, {"id": 405, "seek": 225000, "start": 2250.72, "end": 2259.76, "text": " and then uh we'll squash it now with our sigmoid or no not our sigmoid our softmax function okay", "tokens": [50400, 293, 550, 2232, 321, 603, 30725, 309, 586, 365, 527, 4556, 3280, 327, 420, 572, 406, 527, 4556, 3280, 327, 527, 2787, 41167, 2445, 1392, 50852], "temperature": 0.0, "avg_logprob": -0.06128036334950437, "compression_ratio": 1.8894472361809045, "no_speech_prob": 0.0032728950027376413}, {"id": 406, "seek": 225000, "start": 2259.76, "end": 2264.48, "text": " and then that's going to give us our output probability and then we're going to say well", "tokens": [50852, 293, 550, 300, 311, 516, 281, 976, 505, 527, 5598, 8482, 293, 550, 321, 434, 516, 281, 584, 731, 51088], "temperature": 0.0, "avg_logprob": -0.06128036334950437, "compression_ratio": 1.8894472361809045, "no_speech_prob": 0.0032728950027376413}, {"id": 407, "seek": 225000, "start": 2264.48, "end": 2269.52, "text": " which of the probabilities do we want we want the max one right we want the max probability", "tokens": [51088, 597, 295, 264, 33783, 360, 321, 528, 321, 528, 264, 11469, 472, 558, 321, 528, 264, 11469, 8482, 51340], "temperature": 0.0, "avg_logprob": -0.06128036334950437, "compression_ratio": 1.8894472361809045, "no_speech_prob": 0.0032728950027376413}, {"id": 408, "seek": 225000, "start": 2269.52, "end": 2275.44, "text": " and we'll classify it just like that and return that value okay that's the highest level and so if", "tokens": [51340, 293, 321, 603, 33872, 309, 445, 411, 300, 293, 2736, 300, 2158, 1392, 300, 311, 264, 6343, 1496, 293, 370, 498, 51636], "temperature": 0.0, "avg_logprob": -0.06128036334950437, "compression_ratio": 1.8894472361809045, "no_speech_prob": 0.0032728950027376413}, {"id": 409, "seek": 227544, "start": 2275.44, "end": 2279.84, "text": " you were using keras or one of these high level libraries this is all your code would look like", "tokens": [50364, 291, 645, 1228, 350, 6985, 420, 472, 295, 613, 1090, 1496, 15148, 341, 307, 439, 428, 3089, 576, 574, 411, 50584], "temperature": 0.0, "avg_logprob": -0.04599118232727051, "compression_ratio": 2.0464285714285713, "no_speech_prob": 0.00406999234110117}, {"id": 410, "seek": 227544, "start": 2279.84, "end": 2284.0, "text": " but what we're going to do is we're going to look at these functions as well okay so let's look at", "tokens": [50584, 457, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 574, 412, 613, 6828, 382, 731, 1392, 370, 718, 311, 574, 412, 50792], "temperature": 0.0, "avg_logprob": -0.04599118232727051, "compression_ratio": 2.0464285714285713, "no_speech_prob": 0.00406999234110117}, {"id": 411, "seek": 227544, "start": 2284.0, "end": 2290.8, "text": " these functions so we'll start off with the convolutional layer function and have your", "tokens": [50792, 613, 6828, 370, 321, 603, 722, 766, 365, 264, 45216, 304, 4583, 2445, 293, 362, 428, 51132], "temperature": 0.0, "avg_logprob": -0.04599118232727051, "compression_ratio": 2.0464285714285713, "no_speech_prob": 0.00406999234110117}, {"id": 412, "seek": 227544, "start": 2290.8, "end": 2295.12, "text": " notebook open with me as well so you could go over this the the link is in the description if you", "tokens": [51132, 21060, 1269, 365, 385, 382, 731, 370, 291, 727, 352, 670, 341, 264, 264, 2113, 307, 294, 264, 3855, 498, 291, 51348], "temperature": 0.0, "avg_logprob": -0.04599118232727051, "compression_ratio": 2.0464285714285713, "no_speech_prob": 0.00406999234110117}, {"id": 413, "seek": 227544, "start": 2295.12, "end": 2300.4, "text": " don't know now you know if you don't know now you know so for our convolutional layer given some", "tokens": [51348, 500, 380, 458, 586, 291, 458, 498, 291, 500, 380, 458, 586, 291, 458, 370, 337, 527, 45216, 304, 4583, 2212, 512, 51612], "temperature": 0.0, "avg_logprob": -0.04599118232727051, "compression_ratio": 2.0464285714285713, "no_speech_prob": 0.00406999234110117}, {"id": 414, "seek": 227544, "start": 2300.4, "end": 2305.12, "text": " input image we're going to say well we'll store our feature maps and the bias value in these two", "tokens": [51612, 4846, 3256, 321, 434, 516, 281, 584, 731, 321, 603, 3531, 527, 4111, 11317, 293, 264, 12577, 2158, 294, 613, 732, 51848], "temperature": 0.0, "avg_logprob": -0.04599118232727051, "compression_ratio": 2.0464285714285713, "no_speech_prob": 0.00406999234110117}, {"id": 415, "seek": 230512, "start": 2305.12, "end": 2310.48, "text": " variables features and bias will define how big our filter or patch is going to be how many features", "tokens": [50364, 9102, 4122, 293, 12577, 486, 6964, 577, 955, 527, 6608, 420, 9972, 307, 516, 281, 312, 577, 867, 4122, 50632], "temperature": 0.0, "avg_logprob": -0.0471131241839865, "compression_ratio": 1.932, "no_speech_prob": 0.00941137969493866}, {"id": 416, "seek": 230512, "start": 2310.48, "end": 2316.72, "text": " do we want how big is our image how many channels rgb so three and then how many images do we have", "tokens": [50632, 360, 321, 528, 577, 955, 307, 527, 3256, 577, 867, 9235, 367, 70, 65, 370, 1045, 293, 550, 577, 867, 5267, 360, 321, 362, 50944], "temperature": 0.0, "avg_logprob": -0.0471131241839865, "compression_ratio": 1.932, "no_speech_prob": 0.00941137969493866}, {"id": 417, "seek": 230512, "start": 2316.72, "end": 2322.72, "text": " so given those values we'll define a border mode so a border mode so is so when you apply", "tokens": [50944, 370, 2212, 729, 4190, 321, 603, 6964, 257, 7838, 4391, 370, 257, 7838, 4391, 370, 307, 370, 562, 291, 3079, 51244], "temperature": 0.0, "avg_logprob": -0.0471131241839865, "compression_ratio": 1.932, "no_speech_prob": 0.00941137969493866}, {"id": 418, "seek": 230512, "start": 2322.72, "end": 2327.7599999999998, "text": " fold to border mode in this case it means that the filter has to go outside the bounds of the input", "tokens": [51244, 4860, 281, 7838, 4391, 294, 341, 1389, 309, 1355, 300, 264, 6608, 575, 281, 352, 2380, 264, 29905, 295, 264, 4846, 51496], "temperature": 0.0, "avg_logprob": -0.0471131241839865, "compression_ratio": 1.932, "no_speech_prob": 0.00941137969493866}, {"id": 419, "seek": 230512, "start": 2327.7599999999998, "end": 2333.12, "text": " by filter size divided by two the area outside of the input is normally padded with zeros and", "tokens": [51496, 538, 6608, 2744, 6666, 538, 732, 264, 1859, 2380, 295, 264, 4846, 307, 5646, 6887, 9207, 365, 35193, 293, 51764], "temperature": 0.0, "avg_logprob": -0.0471131241839865, "compression_ratio": 1.932, "no_speech_prob": 0.00941137969493866}, {"id": 420, "seek": 233312, "start": 2333.12, "end": 2337.68, "text": " the border mode valid is when you get an output that is smaller than the input because the convolution", "tokens": [50364, 264, 7838, 4391, 7363, 307, 562, 291, 483, 364, 5598, 300, 307, 4356, 813, 264, 4846, 570, 264, 45216, 50592], "temperature": 0.0, "avg_logprob": -0.05485909635370428, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0008558828849345446}, {"id": 421, "seek": 233312, "start": 2337.68, "end": 2343.68, "text": " is only computed where the input and the filter fully overlap okay and they'll give us different", "tokens": [50592, 307, 787, 40610, 689, 264, 4846, 293, 264, 6608, 4498, 19959, 1392, 293, 436, 603, 976, 505, 819, 50892], "temperature": 0.0, "avg_logprob": -0.05485909635370428, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0008558828849345446}, {"id": 422, "seek": 233312, "start": 2344.72, "end": 2350.4, "text": " they'll give us different classification results accuracy results and it's good to test both", "tokens": [50944, 436, 603, 976, 505, 819, 21538, 3542, 14170, 3542, 293, 309, 311, 665, 281, 1500, 1293, 51228], "temperature": 0.0, "avg_logprob": -0.05485909635370428, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0008558828849345446}, {"id": 423, "seek": 233312, "start": 2350.4, "end": 2355.68, "text": " options so what we'll do is we'll initialize our feature matrix for this layer as conv as convolve", "tokens": [51228, 3956, 370, 437, 321, 603, 360, 307, 321, 603, 5883, 1125, 527, 4111, 8141, 337, 341, 4583, 382, 3754, 382, 3754, 37361, 51492], "temperature": 0.0, "avg_logprob": -0.05485909635370428, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0008558828849345446}, {"id": 424, "seek": 233312, "start": 2355.68, "end": 2360.0, "text": " zeros it's going to be a bunch of zeros and then we'll say okay so for every image that we have", "tokens": [51492, 35193, 309, 311, 516, 281, 312, 257, 3840, 295, 35193, 293, 550, 321, 603, 584, 1392, 370, 337, 633, 3256, 300, 321, 362, 51708], "temperature": 0.0, "avg_logprob": -0.05485909635370428, "compression_ratio": 1.830827067669173, "no_speech_prob": 0.0008558828849345446}, {"id": 425, "seek": 236000, "start": 2360.0, "end": 2365.12, "text": " for every feature in that image let's initialize a convolved image as empty and then for each", "tokens": [50364, 337, 633, 4111, 294, 300, 3256, 718, 311, 5883, 1125, 257, 3754, 29110, 3256, 382, 6707, 293, 550, 337, 1184, 50620], "temperature": 0.0, "avg_logprob": -0.049539876215666245, "compression_ratio": 1.9593495934959348, "no_speech_prob": 0.005219750106334686}, {"id": 426, "seek": 236000, "start": 2365.12, "end": 2369.84, "text": " channel so we're doing this for each of the three channels let's extract a feature from our feature", "tokens": [50620, 2269, 370, 321, 434, 884, 341, 337, 1184, 295, 264, 1045, 9235, 718, 311, 8947, 257, 4111, 490, 527, 4111, 50856], "temperature": 0.0, "avg_logprob": -0.049539876215666245, "compression_ratio": 1.9593495934959348, "no_speech_prob": 0.005219750106334686}, {"id": 427, "seek": 236000, "start": 2369.84, "end": 2375.76, "text": " map define a channel specific part of our image and then perform convolution on our image using", "tokens": [50856, 4471, 6964, 257, 2269, 2685, 644, 295, 527, 3256, 293, 550, 2042, 45216, 322, 527, 3256, 1228, 51152], "temperature": 0.0, "avg_logprob": -0.049539876215666245, "compression_ratio": 1.9593495934959348, "no_speech_prob": 0.005219750106334686}, {"id": 428, "seek": 236000, "start": 2375.76, "end": 2381.28, "text": " that given feature filter so notice this convolved 2d function it's where the actual convolution", "tokens": [51152, 300, 2212, 4111, 6608, 370, 3449, 341, 3754, 29110, 568, 67, 2445, 309, 311, 689, 264, 3539, 45216, 51428], "temperature": 0.0, "avg_logprob": -0.049539876215666245, "compression_ratio": 1.9593495934959348, "no_speech_prob": 0.005219750106334686}, {"id": 429, "seek": 236000, "start": 2381.28, "end": 2387.52, "text": " operation is happening this is more of a wrapper for that actual mathematical operation so once", "tokens": [51428, 6916, 307, 2737, 341, 307, 544, 295, 257, 46906, 337, 300, 3539, 18894, 6916, 370, 1564, 51740], "temperature": 0.0, "avg_logprob": -0.049539876215666245, "compression_ratio": 1.9593495934959348, "no_speech_prob": 0.005219750106334686}, {"id": 430, "seek": 238752, "start": 2387.52, "end": 2392.16, "text": " we have that we'll add a bias and a bias acts as our anchor for our network it's kind of like the", "tokens": [50364, 321, 362, 300, 321, 603, 909, 257, 12577, 293, 257, 12577, 10672, 382, 527, 18487, 337, 527, 3209, 309, 311, 733, 295, 411, 264, 50596], "temperature": 0.0, "avg_logprob": -0.06570793183381893, "compression_ratio": 2.0, "no_speech_prob": 0.0012842722935602069}, {"id": 431, "seek": 238752, "start": 2392.16, "end": 2398.08, "text": " y intercept it's kind of like a starting point for our model to exist and then we'll add it to our", "tokens": [50596, 288, 24700, 309, 311, 733, 295, 411, 257, 2891, 935, 337, 527, 2316, 281, 2514, 293, 550, 321, 603, 909, 309, 281, 527, 50892], "temperature": 0.0, "avg_logprob": -0.06570793183381893, "compression_ratio": 2.0, "no_speech_prob": 0.0012842722935602069}, {"id": 432, "seek": 238752, "start": 2398.08, "end": 2402.96, "text": " list of convolved features for this for this layer okay and we'll return that as the as our feature", "tokens": [50892, 1329, 295, 3754, 29110, 4122, 337, 341, 337, 341, 4583, 1392, 293, 321, 603, 2736, 300, 382, 264, 382, 527, 4111, 51136], "temperature": 0.0, "avg_logprob": -0.06570793183381893, "compression_ratio": 2.0, "no_speech_prob": 0.0012842722935602069}, {"id": 433, "seek": 238752, "start": 2402.96, "end": 2409.44, "text": " map our set of filter values our weight matrices and so let's look at this convolved 2d function so", "tokens": [51136, 4471, 527, 992, 295, 6608, 4190, 527, 3364, 32284, 293, 370, 718, 311, 574, 412, 341, 3754, 29110, 568, 67, 2445, 370, 51460], "temperature": 0.0, "avg_logprob": -0.06570793183381893, "compression_ratio": 2.0, "no_speech_prob": 0.0012842722935602069}, {"id": 434, "seek": 238752, "start": 2409.44, "end": 2414.32, "text": " in our convolved 2d function we'll define the tensor dimension of the image and the feature", "tokens": [51460, 294, 527, 3754, 29110, 568, 67, 2445, 321, 603, 6964, 264, 40863, 10139, 295, 264, 3256, 293, 264, 4111, 51704], "temperature": 0.0, "avg_logprob": -0.06570793183381893, "compression_ratio": 2.0, "no_speech_prob": 0.0012842722935602069}, {"id": 435, "seek": 241432, "start": 2414.32, "end": 2422.96, "text": " we'll get a target dimension and then these two lines perform this this operation this convolutional", "tokens": [50364, 321, 603, 483, 257, 3779, 10139, 293, 550, 613, 732, 3876, 2042, 341, 341, 6916, 341, 45216, 304, 50796], "temperature": 0.0, "avg_logprob": -0.07210023543413947, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.009124997071921825}, {"id": 436, "seek": 241432, "start": 2422.96, "end": 2426.96, "text": " theorem that we defined right here we're performing the dot product between the input", "tokens": [50796, 20904, 300, 321, 7642, 558, 510, 321, 434, 10205, 264, 5893, 1674, 1296, 264, 4846, 50996], "temperature": 0.0, "avg_logprob": -0.07210023543413947, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.009124997071921825}, {"id": 437, "seek": 241432, "start": 2426.96, "end": 2434.48, "text": " and the kernel or feature for for all of those weight values and then we're summing them all up", "tokens": [50996, 293, 264, 28256, 420, 4111, 337, 337, 439, 295, 729, 3364, 4190, 293, 550, 321, 434, 2408, 2810, 552, 439, 493, 51372], "temperature": 0.0, "avg_logprob": -0.07210023543413947, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.009124997071921825}, {"id": 438, "seek": 241432, "start": 2434.48, "end": 2440.7200000000003, "text": " and that's going to be our output and so the fast Fourier function in numpy does this very well", "tokens": [51372, 293, 300, 311, 516, 281, 312, 527, 5598, 293, 370, 264, 2370, 36810, 2445, 294, 1031, 8200, 775, 341, 588, 731, 51684], "temperature": 0.0, "avg_logprob": -0.07210023543413947, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.009124997071921825}, {"id": 439, "seek": 244072, "start": 2440.72, "end": 2446.24, "text": " and so we can just use that as fft2 but that's it's a multiplication and a summation operation", "tokens": [50364, 293, 370, 321, 393, 445, 764, 300, 382, 283, 844, 17, 457, 300, 311, 309, 311, 257, 27290, 293, 257, 28811, 6916, 50640], "temperature": 0.0, "avg_logprob": -0.04341933686854476, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.003707099938765168}, {"id": 440, "seek": 244072, "start": 2446.7999999999997, "end": 2452.48, "text": " okay and so then we have our target value and then once we have our target value we could say", "tokens": [50668, 1392, 293, 370, 550, 321, 362, 527, 3779, 2158, 293, 550, 1564, 321, 362, 527, 3779, 2158, 321, 727, 584, 50952], "temperature": 0.0, "avg_logprob": -0.04341933686854476, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.003707099938765168}, {"id": 441, "seek": 244072, "start": 2452.48, "end": 2456.7999999999997, "text": " okay let's have a starting point and an ending point and our target value is going to be within", "tokens": [50952, 1392, 718, 311, 362, 257, 2891, 935, 293, 364, 8121, 935, 293, 527, 3779, 2158, 307, 516, 281, 312, 1951, 51168], "temperature": 0.0, "avg_logprob": -0.04341933686854476, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.003707099938765168}, {"id": 442, "seek": 244072, "start": 2456.7999999999997, "end": 2462.8799999999997, "text": " that range of what we want to return as the convolved feature right so we have some bounding", "tokens": [51168, 300, 3613, 295, 437, 321, 528, 281, 2736, 382, 264, 3754, 29110, 4111, 558, 370, 321, 362, 512, 5472, 278, 51472], "temperature": 0.0, "avg_logprob": -0.04341933686854476, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.003707099938765168}, {"id": 443, "seek": 244072, "start": 2462.8799999999997, "end": 2468.3199999999997, "text": " box that we want to apply this to okay so then so we have that so what else do we have so we start", "tokens": [51472, 2424, 300, 321, 528, 281, 3079, 341, 281, 1392, 370, 550, 370, 321, 362, 300, 370, 437, 1646, 360, 321, 362, 370, 321, 722, 51744], "temperature": 0.0, "avg_logprob": -0.04341933686854476, "compression_ratio": 1.99163179916318, "no_speech_prob": 0.003707099938765168}, {"id": 444, "seek": 246832, "start": 2468.32, "end": 2475.44, "text": " off with our convolutional layer and then we had our relu so what is relu relu super simple relu", "tokens": [50364, 766, 365, 527, 45216, 304, 4583, 293, 550, 321, 632, 527, 1039, 84, 370, 437, 307, 1039, 84, 1039, 84, 1687, 2199, 1039, 84, 50720], "temperature": 0.0, "avg_logprob": -0.0857204283126677, "compression_ratio": 1.8349056603773586, "no_speech_prob": 0.029308391734957695}, {"id": 445, "seek": 246832, "start": 2476.0, "end": 2483.36, "text": " relu is just forgive so for for some matrix of zeros it will go through every single pixel value", "tokens": [50748, 1039, 84, 307, 445, 10718, 370, 337, 337, 512, 8141, 295, 35193, 309, 486, 352, 807, 633, 2167, 19261, 2158, 51116], "temperature": 0.0, "avg_logprob": -0.0857204283126677, "compression_ratio": 1.8349056603773586, "no_speech_prob": 0.029308391734957695}, {"id": 446, "seek": 246832, "start": 2483.36, "end": 2488.56, "text": " in the input matrix and if it's a negative number we just turn it into zero that's it that's relu okay", "tokens": [51116, 294, 264, 4846, 8141, 293, 498, 309, 311, 257, 3671, 1230, 321, 445, 1261, 309, 666, 4018, 300, 311, 309, 300, 311, 1039, 84, 1392, 51376], "temperature": 0.0, "avg_logprob": -0.0857204283126677, "compression_ratio": 1.8349056603773586, "no_speech_prob": 0.029308391734957695}, {"id": 447, "seek": 246832, "start": 2489.36, "end": 2493.36, "text": " and then so we have we have talked about relu we've talked about convolution we have to talk", "tokens": [51416, 293, 550, 370, 321, 362, 321, 362, 2825, 466, 1039, 84, 321, 600, 2825, 466, 45216, 321, 362, 281, 751, 51616], "temperature": 0.0, "avg_logprob": -0.0857204283126677, "compression_ratio": 1.8349056603773586, "no_speech_prob": 0.029308391734957695}, {"id": 448, "seek": 249336, "start": 2493.36, "end": 2499.44, "text": " about pooling so what does max pooling look like so given our learned features and our images", "tokens": [50364, 466, 7005, 278, 370, 437, 775, 11469, 7005, 278, 574, 411, 370, 2212, 527, 3264, 4122, 293, 527, 5267, 50668], "temperature": 0.0, "avg_logprob": -0.059009029154191935, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.05260898917913437}, {"id": 449, "seek": 249336, "start": 2499.44, "end": 2504.6400000000003, "text": " let's initialize our more dense feature list as empty and so here's what we do we're going to", "tokens": [50668, 718, 311, 5883, 1125, 527, 544, 18011, 4111, 1329, 382, 6707, 293, 370, 510, 311, 437, 321, 360, 321, 434, 516, 281, 50928], "temperature": 0.0, "avg_logprob": -0.059009029154191935, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.05260898917913437}, {"id": 450, "seek": 249336, "start": 2504.6400000000003, "end": 2509.6800000000003, "text": " we're going to take the max values of all of those parts of the input image right so we're", "tokens": [50928, 321, 434, 516, 281, 747, 264, 11469, 4190, 295, 439, 295, 729, 3166, 295, 264, 4846, 3256, 558, 370, 321, 434, 51180], "temperature": 0.0, "avg_logprob": -0.059009029154191935, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.05260898917913437}, {"id": 451, "seek": 249336, "start": 2509.6800000000003, "end": 2514.2400000000002, "text": " going to say we're going to say for each image and for each feature map begin by the row define a", "tokens": [51180, 516, 281, 584, 321, 434, 516, 281, 584, 337, 1184, 3256, 293, 337, 1184, 4111, 4471, 1841, 538, 264, 5386, 6964, 257, 51408], "temperature": 0.0, "avg_logprob": -0.059009029154191935, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.05260898917913437}, {"id": 452, "seek": 249336, "start": 2514.2400000000002, "end": 2519.84, "text": " starting and ending point okay which we define with our pool size hyper parameter and so for each", "tokens": [51408, 2891, 293, 8121, 935, 1392, 597, 321, 6964, 365, 527, 7005, 2744, 9848, 13075, 293, 370, 337, 1184, 51688], "temperature": 0.0, "avg_logprob": -0.059009029154191935, "compression_ratio": 1.9268292682926829, "no_speech_prob": 0.05260898917913437}, {"id": 453, "seek": 251984, "start": 2519.92, "end": 2524.8, "text": " column so we've got a set of rows and columns for each image there's a notice a lot of nesting", "tokens": [50368, 7738, 370, 321, 600, 658, 257, 992, 295, 13241, 293, 13766, 337, 1184, 3256, 456, 311, 257, 3449, 257, 688, 295, 297, 8714, 50612], "temperature": 0.0, "avg_logprob": -0.07415853810106587, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.009125137701630592}, {"id": 454, "seek": 251984, "start": 2524.8, "end": 2529.1200000000003, "text": " happening here we're going to define starting end points for the columns as well and then we're", "tokens": [50612, 2737, 510, 321, 434, 516, 281, 6964, 2891, 917, 2793, 337, 264, 13766, 382, 731, 293, 550, 321, 434, 50828], "temperature": 0.0, "avg_logprob": -0.07415853810106587, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.009125137701630592}, {"id": 455, "seek": 251984, "start": 2529.1200000000003, "end": 2534.8, "text": " going to say define a patch given our defined starting and ending point so some some bounding box", "tokens": [50828, 516, 281, 584, 6964, 257, 9972, 2212, 527, 7642, 2891, 293, 8121, 935, 370, 512, 512, 5472, 278, 2424, 51112], "temperature": 0.0, "avg_logprob": -0.07415853810106587, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.009125137701630592}, {"id": 456, "seek": 251984, "start": 2534.8, "end": 2541.36, "text": " and then take the max value from that patch using nmp.max and that patch is what moves around right", "tokens": [51112, 293, 550, 747, 264, 11469, 2158, 490, 300, 9972, 1228, 297, 2455, 13, 41167, 293, 300, 9972, 307, 437, 6067, 926, 558, 51440], "temperature": 0.0, "avg_logprob": -0.07415853810106587, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.009125137701630592}, {"id": 457, "seek": 251984, "start": 2542.8, "end": 2547.52, "text": " for all parts of that image and then we return that and we're going to store all of that in our", "tokens": [51512, 337, 439, 3166, 295, 300, 3256, 293, 550, 321, 2736, 300, 293, 321, 434, 516, 281, 3531, 439, 295, 300, 294, 527, 51748], "temperature": 0.0, "avg_logprob": -0.07415853810106587, "compression_ratio": 2.0251046025104604, "no_speech_prob": 0.009125137701630592}, {"id": 458, "seek": 254752, "start": 2547.52, "end": 2553.52, "text": " pooled features matrix right here and we return that as the output and that's what we pass on in", "tokens": [50364, 7005, 292, 4122, 8141, 558, 510, 293, 321, 2736, 300, 382, 264, 5598, 293, 300, 311, 437, 321, 1320, 322, 294, 50664], "temperature": 0.0, "avg_logprob": -0.07326246512056601, "compression_ratio": 1.8, "no_speech_prob": 0.0050600431859493256}, {"id": 459, "seek": 254752, "start": 2553.52, "end": 2559.2, "text": " the convolutional network okay so that's what max pooling is okay so we've talked about convolution", "tokens": [50664, 264, 45216, 304, 3209, 1392, 370, 300, 311, 437, 11469, 7005, 278, 307, 1392, 370, 321, 600, 2825, 466, 45216, 50948], "temperature": 0.0, "avg_logprob": -0.07326246512056601, "compression_ratio": 1.8, "no_speech_prob": 0.0050600431859493256}, {"id": 460, "seek": 254752, "start": 2559.2, "end": 2567.92, "text": " relu max pooling and then dropout so for dropout right we have our probability value that we define", "tokens": [50948, 1039, 84, 11469, 7005, 278, 293, 550, 3270, 346, 370, 337, 3270, 346, 558, 321, 362, 527, 8482, 2158, 300, 321, 6964, 51384], "temperature": 0.0, "avg_logprob": -0.07326246512056601, "compression_ratio": 1.8, "no_speech_prob": 0.0050600431859493256}, {"id": 461, "seek": 254752, "start": 2567.92, "end": 2573.44, "text": " as 0.25 and we just multiply it by the input okay and that what that's going to do is it's going to", "tokens": [51384, 382, 1958, 13, 6074, 293, 321, 445, 12972, 309, 538, 264, 4846, 1392, 293, 300, 437, 300, 311, 516, 281, 360, 307, 309, 311, 516, 281, 51660], "temperature": 0.0, "avg_logprob": -0.07326246512056601, "compression_ratio": 1.8, "no_speech_prob": 0.0050600431859493256}, {"id": 462, "seek": 257344, "start": 2573.44, "end": 2578.96, "text": " turn on or off some part of the matrix into so by on and off I mean zero it'll make it either", "tokens": [50364, 1261, 322, 420, 766, 512, 644, 295, 264, 8141, 666, 370, 538, 322, 293, 766, 286, 914, 4018, 309, 603, 652, 309, 2139, 50640], "temperature": 0.0, "avg_logprob": -0.054622188367341694, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.020962223410606384}, {"id": 463, "seek": 257344, "start": 2578.96, "end": 2584.64, "text": " zero or not zero so it'll so then our data will have to learn to either be multiplied by it or", "tokens": [50640, 4018, 420, 406, 4018, 370, 309, 603, 370, 550, 527, 1412, 486, 362, 281, 1466, 281, 2139, 312, 17207, 538, 309, 420, 50924], "temperature": 0.0, "avg_logprob": -0.054622188367341694, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.020962223410606384}, {"id": 464, "seek": 257344, "start": 2584.64, "end": 2590.8, "text": " find a different pathway and that's for dropout and then we talked about dropout and convolution", "tokens": [50924, 915, 257, 819, 18590, 293, 300, 311, 337, 3270, 346, 293, 550, 321, 2825, 466, 3270, 346, 293, 45216, 51232], "temperature": 0.0, "avg_logprob": -0.054622188367341694, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.020962223410606384}, {"id": 465, "seek": 257344, "start": 2591.36, "end": 2597.12, "text": " flattening dense and softmax so for flattening it's just a it's a tensor transformation we just", "tokens": [51260, 24183, 278, 18011, 293, 2787, 41167, 370, 337, 24183, 278, 309, 311, 445, 257, 309, 311, 257, 40863, 9887, 321, 445, 51548], "temperature": 0.0, "avg_logprob": -0.054622188367341694, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.020962223410606384}, {"id": 466, "seek": 259712, "start": 2597.2, "end": 2602.56, "text": " reduce the dimensionality of the input okay and then for our", "tokens": [50368, 5407, 264, 10139, 1860, 295, 264, 4846, 1392, 293, 550, 337, 527, 50636], "temperature": 0.0, "avg_logprob": -0.08325525857869862, "compression_ratio": 2.0315315315315314, "no_speech_prob": 0.10667416453361511}, {"id": 467, "seek": 259712, "start": 2605.44, "end": 2610.72, "text": " dense layer our denses are fully connected layer now this is the generic layer that you would see", "tokens": [50780, 18011, 4583, 527, 24505, 279, 366, 4498, 4582, 4583, 586, 341, 307, 264, 19577, 4583, 300, 291, 576, 536, 51044], "temperature": 0.0, "avg_logprob": -0.08325525857869862, "compression_ratio": 2.0315315315315314, "no_speech_prob": 0.10667416453361511}, {"id": 468, "seek": 259712, "start": 2610.72, "end": 2616.56, "text": " in a feedforward network input times weight uh and then you add a bias right which is the dot", "tokens": [51044, 294, 257, 3154, 13305, 3209, 4846, 1413, 3364, 2232, 293, 550, 291, 909, 257, 12577, 558, 597, 307, 264, 5893, 51336], "temperature": 0.0, "avg_logprob": -0.08325525857869862, "compression_ratio": 2.0315315315315314, "no_speech_prob": 0.10667416453361511}, {"id": 469, "seek": 259712, "start": 2616.56, "end": 2620.72, "text": " product right here this is this is a dense layer we just take our input times our weight at a bias", "tokens": [51336, 1674, 558, 510, 341, 307, 341, 307, 257, 18011, 4583, 321, 445, 747, 527, 4846, 1413, 527, 3364, 412, 257, 12577, 51544], "temperature": 0.0, "avg_logprob": -0.08325525857869862, "compression_ratio": 2.0315315315315314, "no_speech_prob": 0.10667416453361511}, {"id": 470, "seek": 259712, "start": 2620.72, "end": 2625.2, "text": " so that means we we just perform the dot product between the full weight matrix and the full weight", "tokens": [51544, 370, 300, 1355, 321, 321, 445, 2042, 264, 5893, 1674, 1296, 264, 1577, 3364, 8141, 293, 264, 1577, 3364, 51768], "temperature": 0.0, "avg_logprob": -0.08325525857869862, "compression_ratio": 2.0315315315315314, "no_speech_prob": 0.10667416453361511}, {"id": 471, "seek": 262520, "start": 2625.2, "end": 2630.0, "text": " matrix instead of doing it at all the layers because that would be way too computationally", "tokens": [50364, 8141, 2602, 295, 884, 309, 412, 439, 264, 7914, 570, 300, 576, 312, 636, 886, 24903, 379, 50604], "temperature": 0.0, "avg_logprob": -0.060047340393066403, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.004754956811666489}, {"id": 472, "seek": 262520, "start": 2630.0, "end": 2636.08, "text": " expensive for image data we perform it at one fully one fully connected or dense layer at the end", "tokens": [50604, 5124, 337, 3256, 1412, 321, 2042, 309, 412, 472, 4498, 472, 4498, 4582, 420, 18011, 4583, 412, 264, 917, 50908], "temperature": 0.0, "avg_logprob": -0.060047340393066403, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.004754956811666489}, {"id": 473, "seek": 262520, "start": 2636.08, "end": 2639.3599999999997, "text": " and that's a way for us to combine all of our learnings together so we can then", "tokens": [50908, 293, 300, 311, 257, 636, 337, 505, 281, 10432, 439, 295, 527, 2539, 82, 1214, 370, 321, 393, 550, 51072], "temperature": 0.0, "avg_logprob": -0.060047340393066403, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.004754956811666489}, {"id": 474, "seek": 262520, "start": 2639.9199999999996, "end": 2648.8799999999997, "text": " promptly squash it with a softmax function okay so then for our softmax layer and then we have", "tokens": [51100, 48594, 30725, 309, 365, 257, 2787, 41167, 2445, 1392, 370, 550, 337, 527, 2787, 41167, 4583, 293, 550, 321, 362, 51548], "temperature": 0.0, "avg_logprob": -0.060047340393066403, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.004754956811666489}, {"id": 475, "seek": 264888, "start": 2648.88, "end": 2656.1600000000003, "text": " classify so for our softmax layer we will uh so this is the this is the formula for softmax", "tokens": [50364, 33872, 370, 337, 527, 2787, 41167, 4583, 321, 486, 2232, 370, 341, 307, 264, 341, 307, 264, 8513, 337, 2787, 41167, 50728], "temperature": 0.0, "avg_logprob": -0.06109564392654984, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.07584577798843384}, {"id": 476, "seek": 264888, "start": 2656.1600000000003, "end": 2661.44, "text": " programmatically speaking uh but what it does is going to output a set of probability values", "tokens": [50728, 37648, 5030, 4124, 2232, 457, 437, 309, 775, 307, 516, 281, 5598, 257, 992, 295, 8482, 4190, 50992], "temperature": 0.0, "avg_logprob": -0.06109564392654984, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.07584577798843384}, {"id": 477, "seek": 264888, "start": 2661.44, "end": 2665.6800000000003, "text": " and then we'll classify those values by taking the arg max the largest probability", "tokens": [50992, 293, 550, 321, 603, 33872, 729, 4190, 538, 1940, 264, 3882, 11469, 264, 6443, 8482, 51204], "temperature": 0.0, "avg_logprob": -0.06109564392654984, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.07584577798843384}, {"id": 478, "seek": 264888, "start": 2665.6800000000003, "end": 2674.1600000000003, "text": " and that is our output okay so that is our forward pass through the network okay and so", "tokens": [51204, 293, 300, 307, 527, 5598, 1392, 370, 300, 307, 527, 2128, 1320, 807, 264, 3209, 1392, 293, 370, 51628], "temperature": 0.0, "avg_logprob": -0.06109564392654984, "compression_ratio": 1.8112244897959184, "no_speech_prob": 0.07584577798843384}, {"id": 479, "seek": 267416, "start": 2674.16, "end": 2679.6, "text": " yes that is our forward pass through the network", "tokens": [50364, 2086, 300, 307, 527, 2128, 1320, 807, 264, 3209, 50636], "temperature": 0.0, "avg_logprob": -0.0965587159861689, "compression_ratio": 1.7956989247311828, "no_speech_prob": 3.763626955333166e-05}, {"id": 480, "seek": 267416, "start": 2687.7599999999998, "end": 2692.48, "text": " so back so back propagation works pretty much the same way as i've talked about before several", "tokens": [51044, 370, 646, 370, 646, 38377, 1985, 1238, 709, 264, 912, 636, 382, 741, 600, 2825, 466, 949, 2940, 51280], "temperature": 0.0, "avg_logprob": -0.0965587159861689, "compression_ratio": 1.7956989247311828, "no_speech_prob": 3.763626955333166e-05}, {"id": 481, "seek": 267416, "start": 2692.48, "end": 2696.64, "text": " times gradient descent back propagation works the same way we take the partial derivative of our", "tokens": [51280, 1413, 16235, 23475, 646, 38377, 1985, 264, 912, 636, 321, 747, 264, 14641, 13760, 295, 527, 51488], "temperature": 0.0, "avg_logprob": -0.0965587159861689, "compression_ratio": 1.7956989247311828, "no_speech_prob": 3.763626955333166e-05}, {"id": 482, "seek": 267416, "start": 2696.64, "end": 2700.96, "text": " error with respect to our weights and then recursively update our weights using that gradient", "tokens": [51488, 6713, 365, 3104, 281, 527, 17443, 293, 550, 20560, 3413, 5623, 527, 17443, 1228, 300, 16235, 51704], "temperature": 0.0, "avg_logprob": -0.0965587159861689, "compression_ratio": 1.7956989247311828, "no_speech_prob": 3.763626955333166e-05}, {"id": 483, "seek": 270096, "start": 2700.96, "end": 2706.08, "text": " value that we gradient equals partial derivative equals delta interchangeable words but here's", "tokens": [50364, 2158, 300, 321, 16235, 6915, 14641, 13760, 6915, 8289, 30358, 712, 2283, 457, 510, 311, 50620], "temperature": 0.0, "avg_logprob": -0.045425644107893404, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.02161094918847084}, {"id": 484, "seek": 270096, "start": 2706.08, "end": 2712.4, "text": " a great simple example right here where we after the forward pass we do the same thing in reverse", "tokens": [50620, 257, 869, 2199, 1365, 558, 510, 689, 321, 934, 264, 2128, 1320, 321, 360, 264, 912, 551, 294, 9943, 50936], "temperature": 0.0, "avg_logprob": -0.045425644107893404, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.02161094918847084}, {"id": 485, "seek": 270096, "start": 2712.4, "end": 2716.56, "text": " order so we calculate the gradient of those weights and then back and then multiply them by", "tokens": [50936, 1668, 370, 321, 8873, 264, 16235, 295, 729, 17443, 293, 550, 646, 293, 550, 12972, 552, 538, 51144], "temperature": 0.0, "avg_logprob": -0.045425644107893404, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.02161094918847084}, {"id": 486, "seek": 270096, "start": 2716.56, "end": 2723.52, "text": " the previous layer and then for our javascript portion we are taking the drawing from the user", "tokens": [51144, 264, 3894, 4583, 293, 550, 337, 527, 361, 37331, 5944, 8044, 321, 366, 1940, 264, 6316, 490, 264, 4195, 51492], "temperature": 0.0, "avg_logprob": -0.045425644107893404, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.02161094918847084}, {"id": 487, "seek": 270096, "start": 2723.52, "end": 2728.64, "text": " here's the main code for that paint window in a canvas and we are going to say capture the", "tokens": [51492, 510, 311, 264, 2135, 3089, 337, 300, 4225, 4910, 294, 257, 16267, 293, 321, 366, 516, 281, 584, 7983, 264, 51748], "temperature": 0.0, "avg_logprob": -0.045425644107893404, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.02161094918847084}, {"id": 488, "seek": 272864, "start": 2728.64, "end": 2733.52, "text": " mouse's positions capture all those points in that image with an event listener and then we're", "tokens": [50364, 9719, 311, 8432, 7983, 439, 729, 2793, 294, 300, 3256, 365, 364, 2280, 31569, 293, 550, 321, 434, 50608], "temperature": 0.0, "avg_logprob": -0.05639736412107482, "compression_ratio": 1.9828767123287672, "no_speech_prob": 0.1365068256855011}, {"id": 489, "seek": 272864, "start": 2733.52, "end": 2737.92, "text": " going to say on paint so whenever the user actually starts moving that painting whenever that mouse", "tokens": [50608, 516, 281, 584, 322, 4225, 370, 5699, 264, 4195, 767, 3719, 2684, 300, 5370, 5699, 300, 9719, 50828], "temperature": 0.0, "avg_logprob": -0.05639736412107482, "compression_ratio": 1.9828767123287672, "no_speech_prob": 0.1365068256855011}, {"id": 490, "seek": 272864, "start": 2737.92, "end": 2742.56, "text": " stops clicking and then the user hits the submit button we'll save that snapshot of that image and", "tokens": [50828, 10094, 9697, 293, 550, 264, 4195, 8664, 264, 10315, 2960, 321, 603, 3155, 300, 30163, 295, 300, 3256, 293, 51060], "temperature": 0.0, "avg_logprob": -0.05639736412107482, "compression_ratio": 1.9828767123287672, "no_speech_prob": 0.1365068256855011}, {"id": 491, "seek": 272864, "start": 2742.56, "end": 2747.92, "text": " then feed that into the network and that's our flask app we'll define two routes one for our home", "tokens": [51060, 550, 3154, 300, 666, 264, 3209, 293, 300, 311, 527, 932, 3863, 724, 321, 603, 6964, 732, 18242, 472, 337, 527, 1280, 51328], "temperature": 0.0, "avg_logprob": -0.05639736412107482, "compression_ratio": 1.9828767123287672, "no_speech_prob": 0.1365068256855011}, {"id": 492, "seek": 272864, "start": 2747.92, "end": 2752.08, "text": " and then one for that image for the network we can deploy to the web there's a heroku app you", "tokens": [51328, 293, 550, 472, 337, 300, 3256, 337, 264, 3209, 321, 393, 7274, 281, 264, 3670, 456, 311, 257, 720, 13275, 724, 291, 51536], "temperature": 0.0, "avg_logprob": -0.05639736412107482, "compression_ratio": 1.9828767123287672, "no_speech_prob": 0.1365068256855011}, {"id": 493, "seek": 272864, "start": 2752.08, "end": 2756.4, "text": " could definitely check out the link link is in the description as well check out the notebook", "tokens": [51536, 727, 2138, 1520, 484, 264, 2113, 2113, 307, 294, 264, 3855, 382, 731, 1520, 484, 264, 21060, 51752], "temperature": 0.0, "avg_logprob": -0.05639736412107482, "compression_ratio": 1.9828767123287672, "no_speech_prob": 0.1365068256855011}, {"id": 494, "seek": 275640, "start": 2756.4, "end": 2759.76, "text": " and yeah that's it please subscribe for more programming videos and for now", "tokens": [50364, 293, 1338, 300, 311, 309, 1767, 3022, 337, 544, 9410, 2145, 293, 337, 586, 50532], "temperature": 0.0, "avg_logprob": -0.16282925009727478, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.03675216808915138}, {"id": 495, "seek": 275640, "start": 2759.76, "end": 2763.44, "text": " i've got to do a 4a transform so thanks for watching", "tokens": [50532, 741, 600, 658, 281, 360, 257, 1017, 64, 4088, 370, 3231, 337, 1976, 50716], "temperature": 0.0, "avg_logprob": -0.16282925009727478, "compression_ratio": 1.2549019607843137, "no_speech_prob": 0.03675216808915138}], "language": "en"}