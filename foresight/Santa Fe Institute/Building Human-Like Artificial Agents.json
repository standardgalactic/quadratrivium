{"text": " dynamic decision-making laboratory. She has made various contributions to theories models and empirical research on individual and group decision-making, in particular in complex and dynamic situations, which is what drew me to her work and also your texture as one of the most important quality scientists today. And I think it's been working also a lot, and she's writing to Human Air Coordination and Cybersecurity, and she co-directs one of these new NSF national air research institutes. This one is called Alliance for Societal Decision-Making. She is a fellow authority science society, human factors ergonomic society editor of various leading journals, and she has been leading a wide range of multi-million and multi-year collaborative efforts to guarantee industry, such as multi-university research, initiative grants from Army research laboratories in Army research office, and large collaborative projects with Dartmouth. And she has visited SFI a number of times. It's one of the lead authors on the paper on collective adaptation. That is the background for the workshop. That was just happening at SFI, and I'm glad to hear your talk. Thank you. Thank you so very much for having me here. I've been to Santa Fe in the past, and every time I come here, I'm like in heaven. I feel that I can relax, finally, even for a little short time. So what I'm going to talk about today is work that basically I've been doing all my life, all my research life, and it's this idea of building agents that look at, are like humans in terms of the thinking and the cognition and the decisions these agents make. But in particular, I am interested in studying very complex dynamic situations. We call these situations situations of dynamic decision making. So in conditions like the examples you see here, there are more than one decisions that need to be made. We make multiple interdependent decisions under a lot of stress and time constraints. There is usually high uncertainty on the way we make decisions and take, for example, the disaster management case. So there are multiple actors working in trying to allocate resources in a very constrained environment. Those resources are usually limited. And so figuring out how to allocate those resources on time to save the victims is a real challenge. Obviously, a challenge in which the individual human cognitive abilities also play a big role. We cannot remember everything. We have to sleep. We are stressed. We feel the time pressure, et cetera. So these are the type of situations I'm interested in helping humans make better decisions. And AI, at least one of the initial goals of AI, was to create agents that would be undistinguishable from humans. So be able to create agents that would make decisions like humans do. But in reality, the current view of AI, at least, is about machine learning algorithms that are trained on data. And they are trained to optimize decisions that is very much not human-like because humans are not optimal at how we make decisions. So the goal of these AI tools has been to create these elements of optimal decision-making, faster and better than humans. And in fact, many times, we see competitions between humans and AI. And of course, they are amazing and they are fantastic and we need them. And they have amazing applications now with increasingly complex data sets and features. And be able now, obviously, to generate content from PROM, which is really incredible. So things are advancing very fast. However, I still believe that to be able to address complex problems like the one I have been talking about, we need more than algorithms that are optimal. I believe that these generation patterns can help in situations like this, but they are really not capable of making decisions on their own, at least not in the way humans would do it. Because the kind of situations humans have to confront are more than just economic, are more than just optimizing an objective value. They are about various factors and consequences, including ethical and moral trade-offs, that are very hard to emulate or to optimize. So I think the ultimate responsibility for decision making in these type of situations is human. And therefore, we need to figure out how we can use these tools together with tools that emulate human behavior so that we can help humans in these situations. So our goal, should I take questions now? Okay, go ahead. Yeah, I was just wondering about the previous slide and how you said that ethical and moral considerations. It seems that there is a fundamental assumption that you cannot quantify it or you cannot encode it as part of an objective function, but I wonder where does it come from? Yeah, I wouldn't say that we cannot. It's simply we haven't found out how. How to consider all the different trade-offs and the different type of demands that humans need to live when they are making decisions in these kind of situations. So that's precisely where we need to make progress. I just wanted to follow up. The idea about ethics and morals though is that they kind of can't be quantified because they are subjective and relative and it really is contextual and you define things very down to make it morally right or wrong. I guess that's a huge like complex web of trade-offs, I guess. But I guess like you said, it's not impossible. Yeah, I'm not saying it's impossible. I think we are going to get there, but I think we need more research on precisely how humans make decisions in these complex situations before we even attempt to create any computer program that tries to emulate that process. So that has been my goal, yes. I make complex decisions where I don't exactly know what are the outcomes. It also depends on my risk attitudes and how important it is. I mean people, for example, during pregnancy, there are very strong opinions and you are not allowed to do this and this varies over countries. But at the end, Emily Oster wrote this nice book just to know what are the facts and then everyone has to judge on his own or her own how to trade drinking wine against the low risk of, you know, whatever that would be. So these things are probably not part of... No, they are all part. They are all part. But you are going to see next how I make a distinction between sort of the traditional risk assessment and dynamic situations and how I believe we make decisions in dynamic tasks. Across individuals. Across individuals, across situations, absolutely. So my goal has been to improve and speed up human dynamic decision making. And we want to do that by building algorithms that emulate the human cognitive processes and that they can inform other tools like AI optimization algorithms so that we together can make better decisions in these kind of situations. I plan or I want to go beyond just being inspired by humans, which is what usually, you know, computer scientists would do. They do care about humans and they do observe what humans do, but usually they take humans as an inspiration only. What I'm saying is we need to go beyond just taking humans as an inspiration, but really understanding their cognitive processes and being able to emulate that process that is creating this algorithms that can emulate the decision processes, including the biases and errors. So I actually believe that being able to replicate human biases is essential, because the only way we can on bias humans is by being able to understand where the biases come from and then be able to use other tools to help humans make more correct decisions. So sometimes the process of using simple heuristics has been shown to be more effective in these dynamic complex tasks than even very complex reasoning or data sets that, you know, large amounts of data and algorithms that come from large amount of data often are not as good as human experience. So this is sort of the idea of using not the traditional approach to AI, but really to promote the idea of we need representations that can replicate the cognitive process. Why cognitive algorithms? Well, it's a little bit repetitive, I guess, here is we are not trying to create super humans, but we're trying to imitate cognition. And here are some of the advantages and some ways in which these type of algorithms can be used. So they can help explain the cognitive process of decisions on their uncertainty. They are also dynamic and they can learn, presumably like humans learn to make better decisions. They can inform other decision aids or other autonomous systems to help humans. They can also be synchronized with the humans. So for example, if I want to emulate Mirta's decision processes, I will need some information about Mirta's past experience, but I can trace Mirta's decisions over time to be able to predict what Mirta is going to do in a particular situation. So we can do that with these models. And we can also make them be collaborators with others. So if I can emulate Mirta's decision, then I can predict what Mirta is going to do when she collaborates with me. So that's in general the idea of why cognitive algorithms are different from traditional or at least currently traditional AI. So I have been trying to pursue these two essential questions. My whole research career is about how do human make decisions learn and adapt in dynamic tasks. And the second is how can I represent such process computationally. So I'm going to go with the first one too. And when I came to Carnegie Mellon, which was late 90s and beginning 2000, I started as a professor. The concept that I observed about decision making was very different from what I had in mind. It was static decision making, economics decision making. But I was inspired by many people, including this quote by Edward Edwards, where he said that static decision theories have only a limited future. Human beings learn and probabilities and values change. These facts mean that the really applicable kinds of decision theories will be dynamic and not static. So I was stubborn enough to pursue the idea that we want to study dynamic decision making even though nobody in my department understood what the hell I was talking about. This is what they were talking about. And this is a more traditional approach of classical decision making. It's a linear process where you have alternatives. The alternatives are usually well established, meaning they are obviously provided to you. You have option A and option B, usually represented as a decision tree, and then calculated based on expected value what humans should do. Expected value concept, of course, is an extremely useful today and always will be, I think, a concept on optimal decision making. But of course, very soon people realize that humans don't make decisions optimally. And so this famous theory by Kanieman and Taversky, which is still very popular and very influential today, what they essentially did was to modify the concept of expected value into functions that are more human-like. And of course, they supported these functions based on human behavior. So humans are not optimal. Instead, humans are behaving according to these other functions. And that's how you can find out what humans are going to do. And yeah, that's fantastic and still influential. But this type of theory is just not applicable to dynamic situations that are constantly adapting according to various factors over time. Now, if we go completely to the other extreme of what I was studying early 2000, I worked with Gary Klein in a very big project for the army research laboratories. And Gary was the opposite of all the behavioral economics. At that time, it wasn't behavioral, it was just economics. So Gary Klein was studying naturalistic situations, in particular firefighters. So there are books about naturalistic decision making. There is a conference. There are lots of people interested in this area. But essentially what you do in this case is you actually go to the place where decisions are made. Let's say firefighters. And he describes in his book how he would get on the trucks with the firefighters to find out how they make decisions in those very constrained tasks. And then he found out that they don't make decisions. At least that's what they express the firefighters. They just said, I just know what to do. I just get in there. I've seen these situations so many times in the past. I just know what to do. So he documents in his book all the stories about the many firefighters making decisions. And this type of approach has been used in hospitals and in many other naturalistic situations. So out of that work came a model that he called the recognition prime decision model, which was very influential to me. The essential element of recognition prime decision model is recognition. What is recognition is our ability to determine the similarity between a situation we are confronting and what we have confronted in the past. And so he proposes how such a match determines whether we know a situation is typical or not typical. And then based on that, we engage in some sort of mental simulation to figure out different courses of action. This presumably happens very fast. And then you are able to finally decide what to do and implement a course of action. So very inspiring. It made a lot of sense to me, but it wasn't computational. And it hasn't been as far as I know up to now. There has been many attempts to make this sort of theory computational, but to my knowledge, none of them have been really successful. So what I do is sort of in the middle of these two extremes. Dynamic decision making, I sort of realized that I'm not going to make a lot of progress if I go and get on the trucks with firefighters. So instead, I'm going to take the approach that others have taken like Brent Bremmer and Joaquin Funke to create micro worlds. So these are reductions of these real world situations in which we can actually use experimentation. And to me, it was very important to be able to see the cause and effect relationships, not only rely on observations. And so this is just a whole lot of the many micro worlds we have developed and used in my lab through the various years. Initially, I used and developed this and it took many, many years to develop. It's a water purification plant task that has all the major elements of dynamic decision making. It's a dynamic resource allocation with limitations of time, et cetera. So we developed a theory, we gathered a lot of information based on that task. But then the main question was like, well, whatever you are doing is only applicable to this task. You haven't shown me that what your models and your things that you are doing can be applicable to many tasks. So then we went wild and then we just developed all kinds of micro worlds and started to apply to many other tasks to demonstrate that our theory and our ideas were more general than just that particular task. Now, this is a summary of behavioral phenomena that came out of experimental work with many different micro worlds. So I'm going to go over it but relatively quickly given the time. So the first thing is when I arrived to this area, the picture was very frustratingly negative. So all humans are very poor at making decisions in dynamic environments. Even when you give them full feedback and you give them unlimited time incentives, extensive practice, we are born with something that doesn't allow us to make good decisions in these very complex environments. People are generally poor at handling systems with long feedback delays. A lot of people where Bremer, including basically almost all his work, was about demonstrating of long feedback delays and the effect of that on decision making. So the longer the delay is, the poorer decisions we make. So, okay, I was taking all that and I was in agreement with all that, but at the same time, I could observe that people in the real world, some of them are pretty good at making very complex decisions. So how can we explain that? And my response to that is that it's in the learning process. It's in understanding how we go from not knowing how to make decisions to really making very good decisions in really complex environments. So I started to study different things. For example, I found that if we give headroom, meaning space for learning to individual decision makers, then they are able to adapt to more difficult decision situations. For example, putting someone in a low time constraint is going to help for that person to perform under high time constraints more than those that are always trained under high time constraints. So the headroom is needed for learning. Heterogeneity, experiencing different variety of situations are going to help us to adapt to novel situations and we have several studies on that. The ability to pattern match is extremely important. At that time, we collected our ability to pattern match with the Raven progressive matrices test, which is essentially a pattern matching test. And we demonstrated how the score in that test is very predictive of the quality of the decisions that human makes in these micro worlds. And we also found how to provide feedback in a way that would be more useful to individuals by particularly providing observing behavior of an expert was extremely helpful for people to learn and to adapt even after removing that feedback. So this is a list of some of the phenomena and all the things that we have found. I think all over that list, there are two essential elements of dynamic decision making and they keep coming over and over. One of them was recognition. So I was convinced that similarity and our ability to detect similarity is essential for making good decisions and memory. That is our ability to create context specific knowledge. So very different from traditional cognitive theories that believe that humans with experience generate heuristics. I actually believed it was the other way around that humans use heuristics when they don't have knowledge. And as you acquire more context specific knowledge, you actually depart from those heuristics that are not good to start with. They are only approximate. And so you move away from those heuristics and you start to apply context specific knowledge. So let me move to the second question which is how to represent those things computationally. My approach is on cognitive architectures and in large part because I was at CMU. And in CMU is the birth part place of cognitive architectures and in many ways of AI too. So in particular, I was inspired by the work of Allen Newell and Herb Simon that wanted to do had this idea of creating unified theories of cognition. They imagine or envision this complete program that would be capable of making all the activities that human mind was able to make. So they imagine to represent all these cognitive steps and be able to explain all the components of the mind and how they work and produce cognition together. Many books that are very inspiring coming from this tradition. My personal view of this is that it is very utopic. It is an extremely complex problem and therefore is very hard to accomplish. So it was accomplished partly by the actor unified theory of cognition. So John Anderson at Carnegie Mellon and Christian LeVier, one of John Anderson's students and then postdoc and now faculty, research faculty has been working on this idea from Allen Newell and Herb Simon. And if you look at the history of actor, you are going to see that it has just become more complex with over the years. And in my personal opinion, also less useful. So what I did was to grab what I felt was useful from that cognitive architecture. And this is essentially the way knowledge is represented in declarative and procedural forms that is with facts or with rules and in symbolic or sub symbolic ways. That is with formulas that would explain how those facts or rules are going to evolve and change over time. So that's what I did and basically I took that to develop my own mini architecture, if you will. So this theory called instance-based learning theory is essentially a dynamic decision making process that is represented in a learning loop. So I'm going to go over this process and this is sort of the corresponding picture of RPM, the recognition prime, but my own and there are also many differences obviously. So the first step is again decisions are made by recognizing the similar situations and mapping with decisions that have been made in the past to be able to retrieve something that worked in the past. And that happens in this recognition process. We evaluate the new actions according to the utility of the past decisions which are retrieved from memory. And then we explore mentally all the possible alternatives. As you can see this is very similar to the mental simulation that Gary Klein was talking about. And then finally we make execute decision that is the highest up to that point and that execution is going to modify the environment. And finally whenever we get feedback we can reevaluate the utility of those decisions we have made in the past. So that's conceptually what the theory, the learning loop is about. Now let me tell you about the representations. So the idea is that decisions are stored over time in memory in the form of instances and those instances are triplets. Those triplets are the associations of the features that are necessary for that decision, the action that is taken and the outcome. The outcome can be the observed or the expected utility that is calculated about making that decision. Now for each potential action, action one or action two, instances when you try to make a new decision, instances will be blended according to the similarity of the features. And then the action that has the maximum blended value, in this case let's assume it's action two, is chosen. At that moment a new instance is created with the blended value. And then when feedback is received that blended value is changed for the actual feedback outcome that was received. So that's the algorithm in the in the representational form. And this is the algorithm in the mathematical form. So the most important equation I think in this algorithm is the activation, which is not developed by me at all, is borrowed from ACTAAR. So ACTAAR has backed up evidence for each part of this equation with a lot of experiments regarding how humans process information. So this activation equation has three parts. This part is called the base level equation. This part is the partial matching idea and this part is noise. And essentially this equation takes into account the frequency of events. So we tend to believe that something is going to happen more often and actually to retrieve more that information faster when it happens more often. So frequency of events matters a lot for our ability to retrieve information from memory. And so that is represented here. We also tend to forget. So things that happened yesterday I can remember faster than things that happened many years ago. And that is represented by this nonlinear decay function. And then this part here represents the partial matching equation for each feature in the instance. We can determine a particular similarity function, which is then aggregated across all the features and then sort of penalized or exacerbated with a partial matching parameter. And then finally the noise, which this is just noise. Right now there is not a lot of theory about what doesn't fit in this part. This part here is a draw from a random distribution or other type of distributions. And this one is one of the parameters. So for each instance you calculate the activation at each point of time. And then you can calculate the probability of retrieving that instance from memory, which is essentially the activation relative to the activation of all the instances in memory. And then this is the magic I guess of IVLT. What we do is essentially combine all those instances that belong to a particular choice option in the form of an expected value. So this is the probability times the outcome. But obviously this probability is a cognitive probability. It's not the actual probability of an event. And it's a probability that is calculated all the way from here. Right. So in this way we are accounting for the cognition of how do we forget information, how similar the information is, etc. Okay. And we create this expected utility value that we call blending. And then we select the option that has the maximum expected value. So that's it. Now I have been interested as I said before in figuring out how general this theory is across many decision-making situations. And how human-like this algorithm is by comparing the predictions from an IVL model to the results from an experiment in a particular task. What I'm going to show you now is a set of examples of human likeness of IVL agents. And it is important to know that all these examples that I selected here do not fit data. That is in none of these examples, I first collect the data and then I fit the model to the data and then I present the results. Anybody can fit data. All these examples come from the theory. So we do simulations with our theory and then we look at the data and we see how close we are to the data. Okay. But we don't fit data. That being said, doesn't mean that we cannot fit data. We of course can fit data. And that is only going to make things better, right? So we can fit data and we can fit data at the global level, at the individual level, whatever level you want. We can fit the data, but that's not the point of the examples I'm going to show you. So because I started with a very complicated task and nobody understood what the guy was doing, something happened on the way that made me realize I need to simplify things to make things understandable. And so I went to the root of decision making, which is binary choice. But in this case, it was not going to be just the decision tree. It was going to be a dynamic binary choice task. By the way, what I'm going to show since even that there are many examples, it's just a snippet of the various examples. And if you want to go in more detail in any of them, I can, but I wanted to show a good variety of these examples. So the first one is binary choice. And essentially in this case, this is sort of an example of the task. People just have two buttons and they receive an outcome after clicking on a button. And then they go on and on each of these buttons have a particular distribution of outcomes assigned to it. And so the idea is that over time, people are going to learn how to obtain more points out of the right button, the bottom that is the maximum expected value, right, but from experience. So what this figure is, of course, not readable, but the idea is to demonstrate how each of these squares are different problems with different distributions in the two buttons. And it shows the proportion of maximization is a Y axis. And it shows two lines in each of these things. The dotted line is the observed. Actually, it's not the maximization, it's the risky rate. So the proportion of times you choose a risky option. So the dotted line is the human data observed in an experiment. And the black line is ideal predictions. And so the idea of this figure is just to show that in a large variety of problems of these tasks, the model just from simulation is able to predict the learning process that humans follow in this particular task. So the next sort of complication in this journey was to actually demonstrate that if the probabilities change over time, the model was still going to be able to predict that trend that humans would be able to do when they were performing a changing task. So in this particular example, this shows the binary options and the change in probability during a particular time period. And so humans are doing still that binary choice task, but the probability changes of one of the options. And so the figures show the rate of observed choices, again in the dotted line, from human behavior and the predictions from the IVL model. Numerically, we can calculate the actual relationship between human and model with some metrics, but I'm going to come back to that later on. Another example is a collaboration, a cooperation between two agents in the prisoner's dilemma. This is some of the data I presented also the other day in the workshop, but I'm expanding these figures now a little bit. So the idea was that if we can emulate the choice, binary choice in this case of a particular individual, can we emulate the behavior, the collective behavior in this case, cooperation, emergent cooperation of two individuals working together in particular in the prisoner's dilemma in this example. So we created copies of the IVL model, one representing player one, the other one representing player two, and we put them to work in the prisoner's dilemma, and we did different levels of information provided to the players. So what we observe here is again the model, in this case the model is the lighter color and the human behavior, and this is the proportion of the collective cooperation of the pair. And what you see here is actually the strategies, the sequential strategies. So for example, mistrust is the number of times that a player defects after the two players have defected. Forgiveness is the proportion of cooperation after the other player defected even though I cooperated, etc. So the point of this is that the model also captures the sequential strategies over time. So it's not just capturing the outcome metric, but also the effects of the sequential strategies and also does it with different levels of information. We did have to change the blending equation to capture the descriptive information. I can tell you more about that. I explained that in our talk the other day. Okay, so the next sort of escalation of these examples is whether it can capture the effects, the collective effects of groups. So for this what we did was to create different networks with different numbers of connections, and we used two different pay-off matrices, and this came from the work of Valier and colleagues on a taxonomy of two by two games. So we chose the extremes of those two by two games, the independence and the interdependence games, and we run simulations with our IVL models to play with 16 players in this case, making collective decisions, and then we aggregated their results. And what we observe is that in the independence matrix, the collectives are able to figure out what is the best option for everybody, that is this 5.5, actually faster the more connections there are. So they are pretty good at finding the right option pretty quickly, almost immediately we can see this, but it's faster the more connections there are. However, when there is the interdependence that is when the outcome I'm going to get depends on the other person, that's not the case, that is more connections actually resulted in less ability or inability to determine what is the best action for both of us, the AA action. So this was curious for us, and you know this particular degradation of performance based on the number of connections that the agents had, and so we wanted to see whether this in fact happens with actual humans. So we run the study with teams, yes. What is the mechanism? What is the mechanism? Why is interdependence so bad on? Yeah, so the why which you know I'm not going to show you all the evidence for that, but the why has to do with our ability to know the one-to-one correspondence of the actions. So if I play with all of you, I need to keep track of what you did to me last time, and what Henrik did to me last time, and what everybody did to me. It's very hard to learn that, right? So next time when I meet you again, then I need to figure it out or remember, right? Oh, she did B, I should do A with her, right? It's very hard to keep track of that, the more connections you have. The first one is not difficult because it's very easy to find that regardless of how many connections you have, if you pick A, that's what everybody should pick. But doesn't it depend on the payoff structure specifically of this interdependence pattern? I think it does. Okay, I secure myself. You could have a slightly different payoff structure, you could have the default. I don't remember what she did, but it does in a pro-social way. Yeah, it does. It would go up. It does, and I mean, this is an example that it does, right? But in addition to that, Valier et al. have a whole taxonomy of two by two games, and we run this model in the whole taxonomy, and this was the only, there were other things that happened, but this was the only one in which we saw this effect. So this paper is still, I haven't published this paper, but it's still in process. By the way, sorry, I had to step out of it. That was my doctor call. So the mechanism you just described seems to depend sensitively on the internal structure of these computational agents on their memory capacity. I mean, if they have a representation which does simply record what every other player did, then this wouldn't happen. So there are some choices here of kind of the parameters and the structure, and maybe even your definition of similarity, right? So, I mean, similarity would only ask what's the, what happened the last time that Catrine played that way as opposed to recognizing that I can learn about my interactions from Catrine, from my interactions with Iname, Hi, Iname. So, I mean, the, so there are a lot of choices underneath here. I mean, the choices are very transparent in the equations of the model. That's the choices. In this particular task, the binary choice, you don't even have attributes. You know A in an outcome. So there is not even a similarity in this case, but the frequency and the recency play a role, and that's just organic in the model. There is no, yeah, there is a choice of the parameter of the K, but we don't in, I forgot to say that, in one of these results, we are manipulating that parameter. We are using the default parameter that is used in Act R. So it's just coming from, these predictions are coming from the theory. But in this setting, aren't there some choices about how I represent past events? Very good. Yeah, in every setting. And that is the major point. I'm going to come back to that later if you don't mind. But that is exactly the major, one of the major things that we need to improve. The main choice is the designer of the model on what to represent in the instance. We say that we don't represent anything that is not fully available to the human. And it's true. That's what we try to be very committed to do. But still there are choices on what to represent in the instance. This case is not that case because it's very simple. You just see A or B. There is no attributes and the outcome. I can come back to the issue of representation. I know there are many questions. Do you think you could wrap up in like five minutes? Okay. And then so there is still time for more discussion. Then here is where my strategy to cut a lot of stuff comes. So I'm going to show a few more things. I'm going to wrap up in five minutes then. Okay. So again, we run the exercise with human participants in groups. And the human participants in this case were groups of six because running 16 was a lot more complicated. But we managed to gather a good number of groups in each of the conditions. And this is what we observed. So the main effect that we predicted was verified with the human data. Okay. The next example is a little bit more complicated and is more realistic too. And in this example, there are many features. It's about phishing. And it's about our human decision to whether let pass phishing email or not. So we use a data set that was collected by someone else, not us. And that data set was collected in this form. So there were a bunch of emails that they created and some of them were real. So real phishing and real ham. Those are real emails. And then they simulated some phishing and ham emails. And then they asked people to rate the phishing, the emails, whether they were definitely safe to definitely suspicious. And so what we did is we plotted the human data. It's here. We emulated the same decision with our model. And it's here. And we can see that the distributions of the model are very similar to that of the human. And finally, an even more complex task because this is a very popular theme of research is cybersecurity. And in this particular case, we are emulating the decisions of a defender in an individual task. And there is a network that the defender needs to keep safe. And there are some strategies of red agents or red attackers. Two strategies are implemented. And the strategies vary in the way they explore the network to reach the objective, which is this operational server. The interface that the humans use to do this task is what you see here. And we again run and publish a paper with just the predictions of what the model does against as defending against two attacker strategies, the meander and the other more direct strategy. And this is our results from the human experiment. Again, we cannot run 2000 episodes in that case. So we run seven episodes, but we see how our human experiment emulates the predictions from that model. So, okay, given the time, I think I would like to conclude with this, which is our reflection of human likeness. So I think what I have been talking about now regarding human likeness is based on outcome metrics. So I emulate the decisions of the human, and then I compare the outcome of the model to the outcome of the human. Usually we use generic metrics like MSE. Often they are used at the aggregate level to be able to say, hey, our model is doing very well, and that's what every cognitive modeler does. But I think that's wrong. I think we really need to improve this metric, especially that we have the mechanisms to be able to compare at a much lower level. We should always at least compare at the individual level and be able to evaluate the steps, each of the steps at the individual level. Let me say just that we are using now these models more directly in some applications to be able to help prevent the biases that humans have, and to be able to help humans make better decisions. For example, connecting these models with machine learning models and optimization models, and using our cognitive models as human collaborators. This is one of the ways in which we are actually using our models in cybersecurity. By emulating the actions of an attacker or an end user in the case of phishing, we can actually provide the predictions of what these humans are going to do to heavy machine learning algorithms that are being used as defender strategy. By providing these predictions, these defender strategies are being adapted to be able to modify, in these cases, a stalker per security game, modify the allocation of defense resources. The other way in which we are using these models is by making them work with the human, along with the human. Instead of having one individual making decisions in the cybersecurity task, now we have a team. The team is an AI and a human making decisions in this type of security task. They collaborate with each other and they are able to accomplish the task better than a human alone can do. In conclusion, our current focus of AI, I thought I had it. I'm almost finished though, but I thought I had it. Maybe I never, oh, it's not connected. Our current focus on AI is on algorithms that aim at making faster and better decisions. The current focus of AI is on creating algorithms that compete with the human and that are able to make faster and better decisions than humans do. Our goal in contrast is to build learning algorithms that can emulate the cognitive processes and can inform those optimization algorithms to be able to speed up the human decision process. There is evidence of human likeness in these IPL algorithms, but we know that we need to improve the metrics of human likeness. What do we really mean by human likeness? We need to develop this evaluation of human likeness at the cognitive level steps. That is what I think is required to demonstrate some of the usefulness of these models. Yeah, thank you. Maybe some people may believe, but who can stay, please go ahead. Thank you for this talk. You mentioned the prospect theory of Kahneman and Tversky, and one of the strengths of that was not only trying to match human data on specific examples, but also being able to abstract out very general biases, human cognitive biases. Kahneman wrote a whole book about it. Can this also abstract out from your data, very general human biases in these dynamic situations? Some, but we haven't done a lot of work on that, but confirmation bias, for example, is something that we can definitely predict. The big difference is that we are interested in biases from experience. That's in very sharp contrast, because in their theory, they rely on descriptions of the options. Having the descriptions is very different than just acting and observing the outcomes. We only focus on biases from experience, and one of them is confirmation biases, and yes, our model can predict that. There is quite a lot of work to do on characterizing those biases that we can predict from experience that we haven't done. There's a question from Tenda. Can I just go up on this? One of the things that Kahneman and Tversky most rarely or ever implemented computational is basically just a verbal re-description of what's going on and something really disputed. But this basically, you are showing computational what can emerge, and maybe there is no general class even for some of them. I'm a little frustrated with the heuristic and biases situation, because it cannot grow longer because there is no more paper, I guess. I don't know. It just keeps growing and growing, and new biases are emerging. I was very much in line with the initial idea. I really like it, and I think it's still powerful. But now everybody wants to bring a bias out. It's like the 20 questions, right? The idea of Alain Newell is we are doing all these very tiny experiments, but we are forgetting about the global picture. Definitely, there is a lot more work to do on biases from experience. I was wondering about the previous slide of where I don't... Write the previous to this one? So I'm wondering if there's a little bit of cluster clarity, but in a way, on the one hand, we want machines to make that for humans. On the other hand, we're evaluating machines, and there's similarity with human decision-making. So it seems that there needs to be some kind of decomposition of human decision-making in terms of what do we actually want to extract from it? What comes from human limitations, just cognitive limitations, not being able to evaluate everything? How do we split that, I guess? I had a lot of slides going step by step in the process. Actually, a paper that is coming out in PPS does that, so if you are interested, I can send you that. But yeah, so basically, I would break out... I broke out each of the steps in the IVLT process to analyze what we know and what we need to know. And definitely, one of those things are evidence for particular similarity metrics. So in our model, for example, we often use just linear similarity, and sometimes if it doesn't work well, we change it. There is not a lot of theory, even though there is quite a lot of work on similarity judgments, but how to translate that empirical warning to a computational mathematical form and then be able to test it within the realm of the model, we haven't done that work, and that's one of the areas we need to work on. Koti, there is a question for Daniel then. Yes. Thank you for a very interesting paper. There are two points that I wasn't sure I understood. First of all, I want to applaud the idea that you want to enhance human decision-making and make it rather than make it slavishly dependent on AI decision-making. This is a theme that I've been discussing for years. I call it the difference between the Nautilus machine and the bulldozer. The bulldozer lets you move mountains, but you're still a 98-pound weakling. The Nautilus machine, you actually develop the strength yourself. The technology is being used to improve your abilities and make you less dependent on the technology. So I picked that point up. I want to see if you stress it the same way I do. But the question that I really want to ask you about is consider the notorious, rueful, reflective remark of somebody who says, well, it seemed like a good idea at the time. And this requires memory of your past decision-making in detail and memory of your evaluation and the grounds for that evaluation. Now that seems to me to be a very important part of human decision-making, that is the capacity to be self-critical and reflective and to learn from your mistakes by being able to debug your past performances. I didn't think that I saw any sign of that reflective capacity in your presentation, but maybe I just missed it the way you were saying it. Yeah, let me address the second point before I forget. My memory has a large decay. So yes, you are correct that I didn't address that point very concretely in my presentation. But that idea is essentially expressive. You can see this slide in the feedback mechanism. And so what happens is that usually the feedback is delayed and there is nothing we can do about it. And furthermore, we can make many decisions and then get one outcome. And we don't know which of the decisions we made is responsible for that outcome. So we use a concept that is well-known in AI of credit assignment. So how do we associate that outcome to the various decisions that were made? This is the other major area of research. We have a paper that we've been having trouble to publish, but it's made available online where we test various mechanisms of credit assignment, including the TD mechanism in reinforcement learning. So this is a very important part of learning because it's the only way that you can modify the expected utility with the actual utility of the decisions you are making and how you do that process will determine a lot how the learning is done. So we usually just do equal credit until this paper that we are still exploring and figuring out different credit assignments and trying to figure out how humans do that credit assignment. And so there's quite a lot of research that is needed in that area. And to go back to your first point of the bulldozer and dependency on technology, I think we are going to be dependent on technology no matter what. And I think that's a good thing. I don't have anything against technology, but the essence of human life is the human and the essence of any decision making in any complex environments I think will continue to be the human. So I think we should use the technology to empower the human to be able to help the human improve their decisions. And learning mechanisms is essential for that, but figuring out how. So it's not like I give you what you want now. It's like a spoon feeding you on what you need right now. It needs to be a lot more global than that. Thank you. Let me just comment. I think if you try, I'm trying to imagine your systems acting as sort of tutors for human beings and tutors that have good models of how the human beings are making decisions because they are also models about how the tutors are making decisions. And so that in effect the tutor can say, yeah, I'm making this up now. Yeah, I was tempted by that way of thinking about this problem. You are absolutely correct. One of the most successful programs from ACTAAR has been on cognitive tutors. So being able to use ACTAAR to help children learn mathematics. So you are absolutely right. We are using tutors of a different kind, we can say. It's not about mathematics. It's about making choices in some complex environments. But that is exactly how we are using it. We can trace, as I was saying before, we can trace specific students, decision makers and their history and therefore we can make predictions about the decisions that particular person is going to make in the next opportunity. And then we can use other tools, machine learning included or any other AI tools to support that decision making process. There are maybe a couple more questions from people who want to. You choose. We've talked about crisis and errors and we can only say if you see that as something like ACTAAR, in a way they have to agree with the evidence. They have an adaptation to the world in which we live or have lived. So in your conception of a dynamic environment, is it also part of the idea to change the environment to have what we call biases not occur as biases in shortcomings? We will have interventions on those biases. Yes. So a particular program which hasn't started yet is from IRPA. So I am about to start a very big program in IRPA on cybersecurity and it's about predicting the biases of the attackers. The idea is, of course, that we can modify the situation from the defense side so that we can trap the attacker. And given that the attackers are as humans as the defenders are, we can trace down and predict when they are falling trap of certain biases and then be able to react according to that. So yeah, I think biases are emergent. Again, there are some biases that are not emergent related to Melanie's question. There are some biases that are based on information, the explicit information, but the ones that we are able to handle are the ones that are emergent from experience. And yeah, we are working on that too. Yeah, it's a question about decision making and science. So you are trying to emulate the way people actually make decisions, but we lack a lot of detailed knowledge. We wish we had about the neurophysiological mechanisms that realize the procedures that make the decisions. And so you are necessarily sort of, you have to go beyond that and you are making decisions that are under-determined by evidence. And I wonder what kind of commitments or maybe even heuristics you use when it's, you have to make these decisions about what kind of a learner or what kind of a decision maker a human is. Does that question make sense? Let me try to interpret it. I am going to answer based on what I understood. Our type of modeling is symbolic. And so what that means is I don't really go into the neuro part of it. ATAR, that's right. In my personal opinion, that is why it became very complex because now ATAR is trying to map particular mechanisms to activation in certain part of the brains. While that can be very important and necessary, that is not what I do. So I stay at this symbolic level. So that is one thing, but there was another part in your question. I know Kelly, you will meet with Koti now. Maybe these two guys could go. Because maybe you would not be able to talk for a while. Unfortunately, my afternoon is full. So here's my question. So one way to learn to imitate human decision makers would be machine learning. And I know some people are doing that too. And just treat the human's behavior as a thing to be predicted. And I generally much prefer mechanistic models to machine learning. On the other hand, when you have a mechanistic model, then you are in a position of having to either defend the specific mechanism or argue that you're only trying to understand the typical behavior of a wide variety of mechanisms. So when I look at the model, the mathematical model you showed, and maybe there's something I'm missing, I'm not an expert in this area, it looked like a kind of standard online learning model, but with the delay from time. And I know that scientists have tried to figure out, do people forget things exponentially fast, or is it a power law, etc. But then at least some of the examples you showed, like shifting this one where the expected outcomes of the two alternatives were changing. Honestly, I felt like a very wide variety of models that would update their behavior and forget old data to some extent would have produced very similar things. So that made me not so convinced that the specific mechanistic model you wrote down is really the right one. Although certainly some aspects of it, like forgetting the past so you can learn about new things, is surely part of it. But I guess that on the other hand, when I think about humans in dynamic situations, I think that their notion of similarity can be much more general than, for instance, looking at kind of individual attributes of the instance. People do all kinds of analogy making and, you know, like, oh, that bit of grass which is still smoldering, which might flare up again. Oh, that's kind of like there might be a tiger there, or it's kind of like maybe there's an ambush being played by my enemies or whatever. So I don't know, the mechanism seems both impoverished in a way, and maybe over committed to specificity in a way. So at the same time, I'm glad that you're doing something mechanistic instead of just saying, I'll have a year old network, watch for human, and then predict what the human would do, which is the kind of thing which is far too popular nowadays. So I'm such a long question, and maybe it's a long answer. No, I love these type of questions. Let me just answer with what other two people have said. The first one is all models are wrong, right? And I totally no accept a priority that this model cannot be perfect in any way, right? So all models are wrong, but some models are useful. So I like to concentrate on the usefulness of these models, what it can teach us, what it can do, right? And then the other quote is about using models as your toothbrush. And yes, we have the tendency to use our models only and forget about other people's models. We have done comparison, model comparison, and there are including a site review paper of the comparison of our model with another 16 models. I mean, the proliferation of models for this kind of thing is huge, right? So many. But there was a competition, modeling competition, and we tested our model against the winners of that competition and many other of the more typical models. And our model comes to be more general, and it comes to be more predictive than most of them. So again, am I using my own toothbrush? Maybe. I like to use my own toothbrush. The other part is regarding the machine learning. Yeah, I think human likeness depends on what you want to do, right? So if you just want to predict a particular outcome, of course, having a large amount of data can help. As I said, everything I presented is predictions from theory. I didn't use any data before I made the predictions. No human machine learning algorithm would be able to do that. They need the data. In fact, the less data they have, the worse they are, right? Okay. Thank you. Thanks for your time. I want to ask, in a different way, the same question that was already asked three times at the beginning, which is the question of ethics. Because, well, two things. It seems that this is a visibly important question in decision-making and situations of warfare or juridical situations. And secondly, it belongs to philosophy, right? To the Western tradition that runs from Aristotle, through Emmanuel Levinas, and so on. And the one consensus that the big players within this tradition all share, it seems to me, is that from the Greek, you know, Pyrenees and their idea of Epoche is as vertiginous suspension of all decidability all the way through to Walter Benjamin's idea of mystical origins of justice. The consensus seems to be that the ethical or just decision can only come from a place of radical undecidability, right? From non-calculability, right? Law is about calculus, but justice comes from the incalculable. So, in that sense, the distinction to be made would not be between humans and machines. It would be between calculability and non-calculability. If you can calculate ethics or justice, it's not ethics or justice anymore. It's just control, right? I just wanted, that would be the provocation I would put to you in the name of philosophy, right? So, it's a different language game that we're working at using. As soon as you deal with ethics, necessarily you're taking that on board, right? I think that is a world or a controlled world. I guess that is a philosophical question for our model to be able to account for ethical issues. There needs to be calculability. And so, you know, philosophically, that moves us out of the ethics realm. I would accept it because there is nothing else we can do without calculability. Thank you very much.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.76, "text": " dynamic decision-making laboratory. She has made various contributions to theories models and empirical", "tokens": [50364, 8546, 3537, 12, 12402, 16523, 13, 1240, 575, 1027, 3683, 15725, 281, 13667, 5245, 293, 31886, 50652], "temperature": 0.0, "avg_logprob": -0.2958008388303361, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.10865936428308487}, {"id": 1, "seek": 0, "start": 5.76, "end": 10.96, "text": " research on individual and group decision-making, in particular in complex and dynamic situations,", "tokens": [50652, 2132, 322, 2609, 293, 1594, 3537, 12, 12402, 11, 294, 1729, 294, 3997, 293, 8546, 6851, 11, 50912], "temperature": 0.0, "avg_logprob": -0.2958008388303361, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.10865936428308487}, {"id": 2, "seek": 0, "start": 10.96, "end": 17.04, "text": " which is what drew me to her work and also your texture as one of the most important", "tokens": [50912, 597, 307, 437, 12804, 385, 281, 720, 589, 293, 611, 428, 8091, 382, 472, 295, 264, 881, 1021, 51216], "temperature": 0.0, "avg_logprob": -0.2958008388303361, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.10865936428308487}, {"id": 3, "seek": 0, "start": 17.04, "end": 22.32, "text": " quality scientists today. And I think it's been working also a lot, and she's writing to Human", "tokens": [51216, 3125, 7708, 965, 13, 400, 286, 519, 309, 311, 668, 1364, 611, 257, 688, 11, 293, 750, 311, 3579, 281, 10294, 51480], "temperature": 0.0, "avg_logprob": -0.2958008388303361, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.10865936428308487}, {"id": 4, "seek": 0, "start": 22.32, "end": 29.28, "text": " Air Coordination and Cybersecurity, and she co-directs one of these new NSF national air", "tokens": [51480, 5774, 3066, 765, 2486, 293, 22935, 31004, 11, 293, 750, 598, 12, 44868, 82, 472, 295, 613, 777, 15943, 37, 4048, 1988, 51828], "temperature": 0.0, "avg_logprob": -0.2958008388303361, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.10865936428308487}, {"id": 5, "seek": 2928, "start": 29.28, "end": 35.2, "text": " research institutes. This one is called Alliance for Societal Decision-Making. She is a fellow", "tokens": [50364, 2132, 4348, 1819, 13, 639, 472, 307, 1219, 21859, 337, 12276, 302, 304, 12427, 1991, 12, 44, 2456, 13, 1240, 307, 257, 7177, 50660], "temperature": 0.0, "avg_logprob": -0.26948878639622736, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.014767536893486977}, {"id": 6, "seek": 2928, "start": 35.2, "end": 40.160000000000004, "text": " authority science society, human factors ergonomic society editor of various leading journals,", "tokens": [50660, 8281, 3497, 4086, 11, 1952, 6771, 42735, 21401, 4086, 9839, 295, 3683, 5775, 29621, 11, 50908], "temperature": 0.0, "avg_logprob": -0.26948878639622736, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.014767536893486977}, {"id": 7, "seek": 2928, "start": 40.160000000000004, "end": 44.400000000000006, "text": " and she has been leading a wide range of multi-million and multi-year collaborative", "tokens": [50908, 293, 750, 575, 668, 5775, 257, 4874, 3613, 295, 4825, 12, 40388, 293, 4825, 12, 5294, 16555, 51120], "temperature": 0.0, "avg_logprob": -0.26948878639622736, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.014767536893486977}, {"id": 8, "seek": 2928, "start": 44.400000000000006, "end": 49.68000000000001, "text": " efforts to guarantee industry, such as multi-university research, initiative grants from", "tokens": [51120, 6484, 281, 10815, 3518, 11, 1270, 382, 4825, 12, 409, 2550, 2132, 11, 11552, 16101, 490, 51384], "temperature": 0.0, "avg_logprob": -0.26948878639622736, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.014767536893486977}, {"id": 9, "seek": 2928, "start": 49.68000000000001, "end": 54.88, "text": " Army research laboratories in Army research office, and large collaborative projects", "tokens": [51384, 9583, 2132, 41013, 294, 9583, 2132, 3398, 11, 293, 2416, 16555, 4455, 51644], "temperature": 0.0, "avg_logprob": -0.26948878639622736, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.014767536893486977}, {"id": 10, "seek": 5488, "start": 54.88, "end": 59.84, "text": " with Dartmouth. And she has visited SFI a number of times. It's one of the lead authors on the", "tokens": [50364, 365, 47883, 13, 400, 750, 575, 11220, 318, 38568, 257, 1230, 295, 1413, 13, 467, 311, 472, 295, 264, 1477, 16552, 322, 264, 50612], "temperature": 0.0, "avg_logprob": -0.22755101147819967, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.012791771441698074}, {"id": 11, "seek": 5488, "start": 59.84, "end": 63.040000000000006, "text": " paper on collective adaptation. That is the background for the workshop. That was just", "tokens": [50612, 3035, 322, 12590, 21549, 13, 663, 307, 264, 3678, 337, 264, 13541, 13, 663, 390, 445, 50772], "temperature": 0.0, "avg_logprob": -0.22755101147819967, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.012791771441698074}, {"id": 12, "seek": 5488, "start": 63.040000000000006, "end": 70.0, "text": " happening at SFI, and I'm glad to hear your talk. Thank you. Thank you so very much for having me", "tokens": [50772, 2737, 412, 318, 38568, 11, 293, 286, 478, 5404, 281, 1568, 428, 751, 13, 1044, 291, 13, 1044, 291, 370, 588, 709, 337, 1419, 385, 51120], "temperature": 0.0, "avg_logprob": -0.22755101147819967, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.012791771441698074}, {"id": 13, "seek": 5488, "start": 70.0, "end": 76.56, "text": " here. I've been to Santa Fe in the past, and every time I come here, I'm like in heaven. I feel that", "tokens": [51120, 510, 13, 286, 600, 668, 281, 9933, 3697, 294, 264, 1791, 11, 293, 633, 565, 286, 808, 510, 11, 286, 478, 411, 294, 7162, 13, 286, 841, 300, 51448], "temperature": 0.0, "avg_logprob": -0.22755101147819967, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.012791771441698074}, {"id": 14, "seek": 7656, "start": 76.56, "end": 84.32000000000001, "text": " I can relax, finally, even for a little short time. So what I'm going to talk about today is", "tokens": [50364, 286, 393, 5789, 11, 2721, 11, 754, 337, 257, 707, 2099, 565, 13, 407, 437, 286, 478, 516, 281, 751, 466, 965, 307, 50752], "temperature": 0.0, "avg_logprob": -0.12384284032534247, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.009344521909952164}, {"id": 15, "seek": 7656, "start": 85.12, "end": 92.24000000000001, "text": " work that basically I've been doing all my life, all my research life, and it's this idea of building", "tokens": [50792, 589, 300, 1936, 286, 600, 668, 884, 439, 452, 993, 11, 439, 452, 2132, 993, 11, 293, 309, 311, 341, 1558, 295, 2390, 51148], "temperature": 0.0, "avg_logprob": -0.12384284032534247, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.009344521909952164}, {"id": 16, "seek": 7656, "start": 92.88, "end": 102.88, "text": " agents that look at, are like humans in terms of the thinking and the cognition and the decisions", "tokens": [51180, 12554, 300, 574, 412, 11, 366, 411, 6255, 294, 2115, 295, 264, 1953, 293, 264, 46905, 293, 264, 5327, 51680], "temperature": 0.0, "avg_logprob": -0.12384284032534247, "compression_ratio": 1.5698924731182795, "no_speech_prob": 0.009344521909952164}, {"id": 17, "seek": 10288, "start": 103.67999999999999, "end": 113.03999999999999, "text": " these agents make. But in particular, I am interested in studying very complex dynamic", "tokens": [50404, 613, 12554, 652, 13, 583, 294, 1729, 11, 286, 669, 3102, 294, 7601, 588, 3997, 8546, 50872], "temperature": 0.0, "avg_logprob": -0.08989545165515336, "compression_ratio": 1.5865921787709498, "no_speech_prob": 0.000486517179524526}, {"id": 18, "seek": 10288, "start": 113.03999999999999, "end": 121.19999999999999, "text": " situations. We call these situations situations of dynamic decision making. So in conditions like", "tokens": [50872, 6851, 13, 492, 818, 613, 6851, 6851, 295, 8546, 3537, 1455, 13, 407, 294, 4487, 411, 51280], "temperature": 0.0, "avg_logprob": -0.08989545165515336, "compression_ratio": 1.5865921787709498, "no_speech_prob": 0.000486517179524526}, {"id": 19, "seek": 10288, "start": 121.19999999999999, "end": 131.04, "text": " the examples you see here, there are more than one decisions that need to be made. We make multiple", "tokens": [51280, 264, 5110, 291, 536, 510, 11, 456, 366, 544, 813, 472, 5327, 300, 643, 281, 312, 1027, 13, 492, 652, 3866, 51772], "temperature": 0.0, "avg_logprob": -0.08989545165515336, "compression_ratio": 1.5865921787709498, "no_speech_prob": 0.000486517179524526}, {"id": 20, "seek": 13104, "start": 131.04, "end": 139.92, "text": " interdependent decisions under a lot of stress and time constraints. There is usually high uncertainty", "tokens": [50364, 728, 36763, 317, 5327, 833, 257, 688, 295, 4244, 293, 565, 18491, 13, 821, 307, 2673, 1090, 15697, 50808], "temperature": 0.0, "avg_logprob": -0.08404827117919922, "compression_ratio": 1.6, "no_speech_prob": 0.002921362640336156}, {"id": 21, "seek": 13104, "start": 139.92, "end": 147.2, "text": " on the way we make decisions and take, for example, the disaster management case. So there are multiple", "tokens": [50808, 322, 264, 636, 321, 652, 5327, 293, 747, 11, 337, 1365, 11, 264, 11293, 4592, 1389, 13, 407, 456, 366, 3866, 51172], "temperature": 0.0, "avg_logprob": -0.08404827117919922, "compression_ratio": 1.6, "no_speech_prob": 0.002921362640336156}, {"id": 22, "seek": 13104, "start": 147.2, "end": 154.23999999999998, "text": " actors working in trying to allocate resources in a very constrained environment. Those resources", "tokens": [51172, 10037, 1364, 294, 1382, 281, 35713, 3593, 294, 257, 588, 38901, 2823, 13, 3950, 3593, 51524], "temperature": 0.0, "avg_logprob": -0.08404827117919922, "compression_ratio": 1.6, "no_speech_prob": 0.002921362640336156}, {"id": 23, "seek": 15424, "start": 154.48000000000002, "end": 162.24, "text": " are usually limited. And so figuring out how to allocate those resources on time to save the victims", "tokens": [50376, 366, 2673, 5567, 13, 400, 370, 15213, 484, 577, 281, 35713, 729, 3593, 322, 565, 281, 3155, 264, 11448, 50764], "temperature": 0.0, "avg_logprob": -0.1247216137972745, "compression_ratio": 1.5, "no_speech_prob": 0.008569511584937572}, {"id": 24, "seek": 15424, "start": 162.24, "end": 168.72, "text": " is a real challenge. Obviously, a challenge in which the individual human cognitive abilities", "tokens": [50764, 307, 257, 957, 3430, 13, 7580, 11, 257, 3430, 294, 597, 264, 2609, 1952, 15605, 11582, 51088], "temperature": 0.0, "avg_logprob": -0.1247216137972745, "compression_ratio": 1.5, "no_speech_prob": 0.008569511584937572}, {"id": 25, "seek": 15424, "start": 168.72, "end": 177.44, "text": " also play a big role. We cannot remember everything. We have to sleep. We are stressed. We feel the", "tokens": [51088, 611, 862, 257, 955, 3090, 13, 492, 2644, 1604, 1203, 13, 492, 362, 281, 2817, 13, 492, 366, 14471, 13, 492, 841, 264, 51524], "temperature": 0.0, "avg_logprob": -0.1247216137972745, "compression_ratio": 1.5, "no_speech_prob": 0.008569511584937572}, {"id": 26, "seek": 17744, "start": 177.52, "end": 185.44, "text": " time pressure, et cetera. So these are the type of situations I'm interested in helping humans", "tokens": [50368, 565, 3321, 11, 1030, 11458, 13, 407, 613, 366, 264, 2010, 295, 6851, 286, 478, 3102, 294, 4315, 6255, 50764], "temperature": 0.0, "avg_logprob": -0.1110693475474482, "compression_ratio": 1.625, "no_speech_prob": 0.004219087306410074}, {"id": 27, "seek": 17744, "start": 185.44, "end": 195.52, "text": " make better decisions. And AI, at least one of the initial goals of AI, was to create agents", "tokens": [50764, 652, 1101, 5327, 13, 400, 7318, 11, 412, 1935, 472, 295, 264, 5883, 5493, 295, 7318, 11, 390, 281, 1884, 12554, 51268], "temperature": 0.0, "avg_logprob": -0.1110693475474482, "compression_ratio": 1.625, "no_speech_prob": 0.004219087306410074}, {"id": 28, "seek": 17744, "start": 195.52, "end": 201.76, "text": " that would be undistinguishable from humans. So be able to create agents that would make decisions", "tokens": [51268, 300, 576, 312, 674, 468, 7050, 742, 712, 490, 6255, 13, 407, 312, 1075, 281, 1884, 12554, 300, 576, 652, 5327, 51580], "temperature": 0.0, "avg_logprob": -0.1110693475474482, "compression_ratio": 1.625, "no_speech_prob": 0.004219087306410074}, {"id": 29, "seek": 20176, "start": 201.76, "end": 209.84, "text": " like humans do. But in reality, the current view of AI, at least, is about machine learning", "tokens": [50364, 411, 6255, 360, 13, 583, 294, 4103, 11, 264, 2190, 1910, 295, 7318, 11, 412, 1935, 11, 307, 466, 3479, 2539, 50768], "temperature": 0.0, "avg_logprob": -0.08070879824021283, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.002734539331868291}, {"id": 30, "seek": 20176, "start": 209.84, "end": 218.72, "text": " algorithms that are trained on data. And they are trained to optimize decisions that is very much", "tokens": [50768, 14642, 300, 366, 8895, 322, 1412, 13, 400, 436, 366, 8895, 281, 19719, 5327, 300, 307, 588, 709, 51212], "temperature": 0.0, "avg_logprob": -0.08070879824021283, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.002734539331868291}, {"id": 31, "seek": 20176, "start": 218.72, "end": 227.84, "text": " not human-like because humans are not optimal at how we make decisions. So the goal of these AI", "tokens": [51212, 406, 1952, 12, 4092, 570, 6255, 366, 406, 16252, 412, 577, 321, 652, 5327, 13, 407, 264, 3387, 295, 613, 7318, 51668], "temperature": 0.0, "avg_logprob": -0.08070879824021283, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.002734539331868291}, {"id": 32, "seek": 22784, "start": 227.84, "end": 236.4, "text": " tools has been to create these elements of optimal decision-making, faster and better than humans.", "tokens": [50364, 3873, 575, 668, 281, 1884, 613, 4959, 295, 16252, 3537, 12, 12402, 11, 4663, 293, 1101, 813, 6255, 13, 50792], "temperature": 0.0, "avg_logprob": -0.1294019258939303, "compression_ratio": 1.5988700564971752, "no_speech_prob": 0.0013357257703319192}, {"id": 33, "seek": 22784, "start": 236.4, "end": 244.96, "text": " And in fact, many times, we see competitions between humans and AI. And of course, they are", "tokens": [50792, 400, 294, 1186, 11, 867, 1413, 11, 321, 536, 26185, 1296, 6255, 293, 7318, 13, 400, 295, 1164, 11, 436, 366, 51220], "temperature": 0.0, "avg_logprob": -0.1294019258939303, "compression_ratio": 1.5988700564971752, "no_speech_prob": 0.0013357257703319192}, {"id": 34, "seek": 22784, "start": 244.96, "end": 252.88, "text": " amazing and they are fantastic and we need them. And they have amazing applications now with", "tokens": [51220, 2243, 293, 436, 366, 5456, 293, 321, 643, 552, 13, 400, 436, 362, 2243, 5821, 586, 365, 51616], "temperature": 0.0, "avg_logprob": -0.1294019258939303, "compression_ratio": 1.5988700564971752, "no_speech_prob": 0.0013357257703319192}, {"id": 35, "seek": 25288, "start": 252.96, "end": 262.88, "text": " increasingly complex data sets and features. And be able now, obviously, to generate content", "tokens": [50368, 12980, 3997, 1412, 6352, 293, 4122, 13, 400, 312, 1075, 586, 11, 2745, 11, 281, 8460, 2701, 50864], "temperature": 0.0, "avg_logprob": -0.12001703655908978, "compression_ratio": 1.4322916666666667, "no_speech_prob": 0.0020999587140977383}, {"id": 36, "seek": 25288, "start": 262.88, "end": 271.6, "text": " from PROM, which is really incredible. So things are advancing very fast. However, I still", "tokens": [50864, 490, 11568, 5251, 11, 597, 307, 534, 4651, 13, 407, 721, 366, 27267, 588, 2370, 13, 2908, 11, 286, 920, 51300], "temperature": 0.0, "avg_logprob": -0.12001703655908978, "compression_ratio": 1.4322916666666667, "no_speech_prob": 0.0020999587140977383}, {"id": 37, "seek": 25288, "start": 272.32, "end": 280.08, "text": " believe that to be able to address complex problems like the one I have been talking about,", "tokens": [51336, 1697, 300, 281, 312, 1075, 281, 2985, 3997, 2740, 411, 264, 472, 286, 362, 668, 1417, 466, 11, 51724], "temperature": 0.0, "avg_logprob": -0.12001703655908978, "compression_ratio": 1.4322916666666667, "no_speech_prob": 0.0020999587140977383}, {"id": 38, "seek": 28008, "start": 281.03999999999996, "end": 291.2, "text": " we need more than algorithms that are optimal. I believe that these generation patterns can help", "tokens": [50412, 321, 643, 544, 813, 14642, 300, 366, 16252, 13, 286, 1697, 300, 613, 5125, 8294, 393, 854, 50920], "temperature": 0.0, "avg_logprob": -0.10504788444155738, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0024438227992504835}, {"id": 39, "seek": 28008, "start": 291.2, "end": 297.76, "text": " in situations like this, but they are really not capable of making decisions on their own,", "tokens": [50920, 294, 6851, 411, 341, 11, 457, 436, 366, 534, 406, 8189, 295, 1455, 5327, 322, 641, 1065, 11, 51248], "temperature": 0.0, "avg_logprob": -0.10504788444155738, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0024438227992504835}, {"id": 40, "seek": 28008, "start": 298.32, "end": 305.12, "text": " at least not in the way humans would do it. Because the kind of situations humans have to confront", "tokens": [51276, 412, 1935, 406, 294, 264, 636, 6255, 576, 360, 309, 13, 1436, 264, 733, 295, 6851, 6255, 362, 281, 12422, 51616], "temperature": 0.0, "avg_logprob": -0.10504788444155738, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.0024438227992504835}, {"id": 41, "seek": 30512, "start": 305.84000000000003, "end": 312.72, "text": " are more than just economic, are more than just optimizing an objective value.", "tokens": [50400, 366, 544, 813, 445, 4836, 11, 366, 544, 813, 445, 40425, 364, 10024, 2158, 13, 50744], "temperature": 0.0, "avg_logprob": -0.12098197426114764, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0050466908141970634}, {"id": 42, "seek": 30512, "start": 313.28000000000003, "end": 320.4, "text": " They are about various factors and consequences, including ethical and moral trade-offs,", "tokens": [50772, 814, 366, 466, 3683, 6771, 293, 10098, 11, 3009, 18890, 293, 9723, 4923, 12, 19231, 11, 51128], "temperature": 0.0, "avg_logprob": -0.12098197426114764, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0050466908141970634}, {"id": 43, "seek": 30512, "start": 320.4, "end": 330.16, "text": " that are very hard to emulate or to optimize. So I think the ultimate responsibility for", "tokens": [51128, 300, 366, 588, 1152, 281, 45497, 420, 281, 19719, 13, 407, 286, 519, 264, 9705, 6357, 337, 51616], "temperature": 0.0, "avg_logprob": -0.12098197426114764, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0050466908141970634}, {"id": 44, "seek": 33016, "start": 330.16, "end": 337.28000000000003, "text": " decision making in these type of situations is human. And therefore, we need to figure out", "tokens": [50364, 3537, 1455, 294, 613, 2010, 295, 6851, 307, 1952, 13, 400, 4412, 11, 321, 643, 281, 2573, 484, 50720], "temperature": 0.0, "avg_logprob": -0.13752681016921997, "compression_ratio": 1.5397727272727273, "no_speech_prob": 0.02196572907269001}, {"id": 45, "seek": 33016, "start": 337.28000000000003, "end": 345.52000000000004, "text": " how we can use these tools together with tools that emulate human behavior so that we can help", "tokens": [50720, 577, 321, 393, 764, 613, 3873, 1214, 365, 3873, 300, 45497, 1952, 5223, 370, 300, 321, 393, 854, 51132], "temperature": 0.0, "avg_logprob": -0.13752681016921997, "compression_ratio": 1.5397727272727273, "no_speech_prob": 0.02196572907269001}, {"id": 46, "seek": 33016, "start": 345.52000000000004, "end": 353.84000000000003, "text": " humans in these situations. So our goal, should I take questions now? Okay, go ahead.", "tokens": [51132, 6255, 294, 613, 6851, 13, 407, 527, 3387, 11, 820, 286, 747, 1651, 586, 30, 1033, 11, 352, 2286, 13, 51548], "temperature": 0.0, "avg_logprob": -0.13752681016921997, "compression_ratio": 1.5397727272727273, "no_speech_prob": 0.02196572907269001}, {"id": 47, "seek": 35384, "start": 353.84, "end": 368.64, "text": " Yeah, I was just wondering about the previous slide and how you said that ethical and moral", "tokens": [50364, 865, 11, 286, 390, 445, 6359, 466, 264, 3894, 4137, 293, 577, 291, 848, 300, 18890, 293, 9723, 51104], "temperature": 0.0, "avg_logprob": -0.22181627485487196, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.03957498073577881}, {"id": 48, "seek": 35384, "start": 368.64, "end": 373.2, "text": " considerations. It seems that there is a fundamental assumption that you cannot quantify it or you", "tokens": [51104, 24070, 13, 467, 2544, 300, 456, 307, 257, 8088, 15302, 300, 291, 2644, 40421, 309, 420, 291, 51332], "temperature": 0.0, "avg_logprob": -0.22181627485487196, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.03957498073577881}, {"id": 49, "seek": 35384, "start": 373.2, "end": 377.59999999999997, "text": " cannot encode it as part of an objective function, but I wonder where does it come from?", "tokens": [51332, 2644, 2058, 1429, 309, 382, 644, 295, 364, 10024, 2445, 11, 457, 286, 2441, 689, 775, 309, 808, 490, 30, 51552], "temperature": 0.0, "avg_logprob": -0.22181627485487196, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.03957498073577881}, {"id": 50, "seek": 37760, "start": 378.56, "end": 385.28000000000003, "text": " Yeah, I wouldn't say that we cannot. It's simply we haven't found out how. How to", "tokens": [50412, 865, 11, 286, 2759, 380, 584, 300, 321, 2644, 13, 467, 311, 2935, 321, 2378, 380, 1352, 484, 577, 13, 1012, 281, 50748], "temperature": 0.0, "avg_logprob": -0.14633661327940045, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0042299241758883}, {"id": 51, "seek": 37760, "start": 386.32000000000005, "end": 391.92, "text": " consider all the different trade-offs and the different type of demands that humans need to", "tokens": [50800, 1949, 439, 264, 819, 4923, 12, 19231, 293, 264, 819, 2010, 295, 15107, 300, 6255, 643, 281, 51080], "temperature": 0.0, "avg_logprob": -0.14633661327940045, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0042299241758883}, {"id": 52, "seek": 37760, "start": 393.44, "end": 400.16, "text": " live when they are making decisions in these kind of situations. So that's precisely where we need", "tokens": [51156, 1621, 562, 436, 366, 1455, 5327, 294, 613, 733, 295, 6851, 13, 407, 300, 311, 13402, 689, 321, 643, 51492], "temperature": 0.0, "avg_logprob": -0.14633661327940045, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0042299241758883}, {"id": 53, "seek": 40016, "start": 400.16, "end": 409.6, "text": " to make progress. I just wanted to follow up. The idea about ethics and morals though is that", "tokens": [50364, 281, 652, 4205, 13, 286, 445, 1415, 281, 1524, 493, 13, 440, 1558, 466, 19769, 293, 46849, 1673, 307, 300, 50836], "temperature": 0.0, "avg_logprob": -0.15349275238659918, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.015850011259317398}, {"id": 54, "seek": 40016, "start": 409.6, "end": 414.64000000000004, "text": " they kind of can't be quantified because they are subjective and relative and it really is contextual", "tokens": [50836, 436, 733, 295, 393, 380, 312, 4426, 2587, 570, 436, 366, 25972, 293, 4972, 293, 309, 534, 307, 35526, 51088], "temperature": 0.0, "avg_logprob": -0.15349275238659918, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.015850011259317398}, {"id": 55, "seek": 40016, "start": 414.64000000000004, "end": 420.64000000000004, "text": " and you define things very down to make it morally right or wrong. I guess that's a huge like complex", "tokens": [51088, 293, 291, 6964, 721, 588, 760, 281, 652, 309, 38622, 558, 420, 2085, 13, 286, 2041, 300, 311, 257, 2603, 411, 3997, 51388], "temperature": 0.0, "avg_logprob": -0.15349275238659918, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.015850011259317398}, {"id": 56, "seek": 40016, "start": 421.36, "end": 426.72, "text": " web of trade-offs, I guess. But I guess like you said, it's not impossible. Yeah, I'm not saying", "tokens": [51424, 3670, 295, 4923, 12, 19231, 11, 286, 2041, 13, 583, 286, 2041, 411, 291, 848, 11, 309, 311, 406, 6243, 13, 865, 11, 286, 478, 406, 1566, 51692], "temperature": 0.0, "avg_logprob": -0.15349275238659918, "compression_ratio": 1.5697211155378485, "no_speech_prob": 0.015850011259317398}, {"id": 57, "seek": 42672, "start": 426.72, "end": 433.6, "text": " it's impossible. I think we are going to get there, but I think we need more research on precisely", "tokens": [50364, 309, 311, 6243, 13, 286, 519, 321, 366, 516, 281, 483, 456, 11, 457, 286, 519, 321, 643, 544, 2132, 322, 13402, 50708], "temperature": 0.0, "avg_logprob": -0.09835885063050286, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.0025673035997897387}, {"id": 58, "seek": 42672, "start": 433.6, "end": 440.48, "text": " how humans make decisions in these complex situations before we even attempt to create any", "tokens": [50708, 577, 6255, 652, 5327, 294, 613, 3997, 6851, 949, 321, 754, 5217, 281, 1884, 604, 51052], "temperature": 0.0, "avg_logprob": -0.09835885063050286, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.0025673035997897387}, {"id": 59, "seek": 42672, "start": 440.48, "end": 447.68, "text": " computer program that tries to emulate that process. So that has been my goal, yes.", "tokens": [51052, 3820, 1461, 300, 9898, 281, 45497, 300, 1399, 13, 407, 300, 575, 668, 452, 3387, 11, 2086, 13, 51412], "temperature": 0.0, "avg_logprob": -0.09835885063050286, "compression_ratio": 1.5166666666666666, "no_speech_prob": 0.0025673035997897387}, {"id": 60, "seek": 44768, "start": 447.84000000000003, "end": 457.84000000000003, "text": " I make complex decisions where I don't exactly know what are the outcomes. It also depends", "tokens": [50372, 286, 652, 3997, 5327, 689, 286, 500, 380, 2293, 458, 437, 366, 264, 10070, 13, 467, 611, 5946, 50872], "temperature": 0.0, "avg_logprob": -0.21603027257052335, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.019602933898568153}, {"id": 61, "seek": 44768, "start": 457.84000000000003, "end": 464.64, "text": " on my risk attitudes and how important it is. I mean people, for example, during pregnancy,", "tokens": [50872, 322, 452, 3148, 25853, 293, 577, 1021, 309, 307, 13, 286, 914, 561, 11, 337, 1365, 11, 1830, 16120, 11, 51212], "temperature": 0.0, "avg_logprob": -0.21603027257052335, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.019602933898568153}, {"id": 62, "seek": 44768, "start": 464.64, "end": 469.36, "text": " there are very strong opinions and you are not allowed to do this and this varies over countries.", "tokens": [51212, 456, 366, 588, 2068, 11819, 293, 291, 366, 406, 4350, 281, 360, 341, 293, 341, 21716, 670, 3517, 13, 51448], "temperature": 0.0, "avg_logprob": -0.21603027257052335, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.019602933898568153}, {"id": 63, "seek": 44768, "start": 469.36, "end": 476.72, "text": " But at the end, Emily Oster wrote this nice book just to know what are the facts and then", "tokens": [51448, 583, 412, 264, 917, 11, 15034, 422, 3120, 4114, 341, 1481, 1446, 445, 281, 458, 437, 366, 264, 9130, 293, 550, 51816], "temperature": 0.0, "avg_logprob": -0.21603027257052335, "compression_ratio": 1.6017316017316017, "no_speech_prob": 0.019602933898568153}, {"id": 64, "seek": 47672, "start": 477.28000000000003, "end": 485.04, "text": " everyone has to judge on his own or her own how to trade drinking wine against the low risk of,", "tokens": [50392, 1518, 575, 281, 6995, 322, 702, 1065, 420, 720, 1065, 577, 281, 4923, 7583, 7209, 1970, 264, 2295, 3148, 295, 11, 50780], "temperature": 0.0, "avg_logprob": -0.13944872447422574, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.002819715067744255}, {"id": 65, "seek": 47672, "start": 485.04, "end": 490.64000000000004, "text": " you know, whatever that would be. So these things are probably not part of...", "tokens": [50780, 291, 458, 11, 2035, 300, 576, 312, 13, 407, 613, 721, 366, 1391, 406, 644, 295, 485, 51060], "temperature": 0.0, "avg_logprob": -0.13944872447422574, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.002819715067744255}, {"id": 66, "seek": 47672, "start": 491.68, "end": 499.36, "text": " No, they are all part. They are all part. But you are going to see next how I make a distinction", "tokens": [51112, 883, 11, 436, 366, 439, 644, 13, 814, 366, 439, 644, 13, 583, 291, 366, 516, 281, 536, 958, 577, 286, 652, 257, 16844, 51496], "temperature": 0.0, "avg_logprob": -0.13944872447422574, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.002819715067744255}, {"id": 67, "seek": 49936, "start": 499.36, "end": 507.68, "text": " between sort of the traditional risk assessment and dynamic situations and how I believe we make", "tokens": [50364, 1296, 1333, 295, 264, 5164, 3148, 9687, 293, 8546, 6851, 293, 577, 286, 1697, 321, 652, 50780], "temperature": 0.0, "avg_logprob": -0.14928331531462122, "compression_ratio": 1.646067415730337, "no_speech_prob": 0.008659048937261105}, {"id": 68, "seek": 49936, "start": 507.68, "end": 517.04, "text": " decisions in dynamic tasks. Across individuals. Across individuals, across situations, absolutely.", "tokens": [50780, 5327, 294, 8546, 9608, 13, 34527, 5346, 13, 34527, 5346, 11, 2108, 6851, 11, 3122, 13, 51248], "temperature": 0.0, "avg_logprob": -0.14928331531462122, "compression_ratio": 1.646067415730337, "no_speech_prob": 0.008659048937261105}, {"id": 69, "seek": 49936, "start": 519.2, "end": 527.04, "text": " So my goal has been to improve and speed up human dynamic decision making. And we want to do that", "tokens": [51356, 407, 452, 3387, 575, 668, 281, 3470, 293, 3073, 493, 1952, 8546, 3537, 1455, 13, 400, 321, 528, 281, 360, 300, 51748], "temperature": 0.0, "avg_logprob": -0.14928331531462122, "compression_ratio": 1.646067415730337, "no_speech_prob": 0.008659048937261105}, {"id": 70, "seek": 52704, "start": 527.04, "end": 534.0, "text": " by building algorithms that emulate the human cognitive processes and that they can inform", "tokens": [50364, 538, 2390, 14642, 300, 45497, 264, 1952, 15605, 7555, 293, 300, 436, 393, 1356, 50712], "temperature": 0.0, "avg_logprob": -0.09601879119873047, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.0017120090778917074}, {"id": 71, "seek": 52704, "start": 534.88, "end": 544.24, "text": " other tools like AI optimization algorithms so that we together can make better decisions", "tokens": [50756, 661, 3873, 411, 7318, 19618, 14642, 370, 300, 321, 1214, 393, 652, 1101, 5327, 51224], "temperature": 0.0, "avg_logprob": -0.09601879119873047, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.0017120090778917074}, {"id": 72, "seek": 52704, "start": 544.24, "end": 552.3199999999999, "text": " in these kind of situations. I plan or I want to go beyond just being inspired by humans,", "tokens": [51224, 294, 613, 733, 295, 6851, 13, 286, 1393, 420, 286, 528, 281, 352, 4399, 445, 885, 7547, 538, 6255, 11, 51628], "temperature": 0.0, "avg_logprob": -0.09601879119873047, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.0017120090778917074}, {"id": 73, "seek": 55232, "start": 552.32, "end": 559.5200000000001, "text": " which is what usually, you know, computer scientists would do. They do care about humans and", "tokens": [50364, 597, 307, 437, 2673, 11, 291, 458, 11, 3820, 7708, 576, 360, 13, 814, 360, 1127, 466, 6255, 293, 50724], "temperature": 0.0, "avg_logprob": -0.1093148098716253, "compression_ratio": 1.7393364928909953, "no_speech_prob": 0.0013349599903449416}, {"id": 74, "seek": 55232, "start": 559.5200000000001, "end": 566.5600000000001, "text": " they do observe what humans do, but usually they take humans as an inspiration only.", "tokens": [50724, 436, 360, 11441, 437, 6255, 360, 11, 457, 2673, 436, 747, 6255, 382, 364, 10249, 787, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1093148098716253, "compression_ratio": 1.7393364928909953, "no_speech_prob": 0.0013349599903449416}, {"id": 75, "seek": 55232, "start": 567.2, "end": 573.12, "text": " What I'm saying is we need to go beyond just taking humans as an inspiration, but really", "tokens": [51108, 708, 286, 478, 1566, 307, 321, 643, 281, 352, 4399, 445, 1940, 6255, 382, 364, 10249, 11, 457, 534, 51404], "temperature": 0.0, "avg_logprob": -0.1093148098716253, "compression_ratio": 1.7393364928909953, "no_speech_prob": 0.0013349599903449416}, {"id": 76, "seek": 55232, "start": 573.12, "end": 581.5200000000001, "text": " understanding their cognitive processes and being able to emulate that process that is creating this", "tokens": [51404, 3701, 641, 15605, 7555, 293, 885, 1075, 281, 45497, 300, 1399, 300, 307, 4084, 341, 51824], "temperature": 0.0, "avg_logprob": -0.1093148098716253, "compression_ratio": 1.7393364928909953, "no_speech_prob": 0.0013349599903449416}, {"id": 77, "seek": 58232, "start": 582.5600000000001, "end": 591.9200000000001, "text": " algorithms that can emulate the decision processes, including the biases and errors.", "tokens": [50376, 14642, 300, 393, 45497, 264, 3537, 7555, 11, 3009, 264, 32152, 293, 13603, 13, 50844], "temperature": 0.0, "avg_logprob": -0.12341407429088246, "compression_ratio": 1.6125, "no_speech_prob": 0.0005233242409303784}, {"id": 78, "seek": 58232, "start": 591.9200000000001, "end": 599.36, "text": " So I actually believe that being able to replicate human biases is essential,", "tokens": [50844, 407, 286, 767, 1697, 300, 885, 1075, 281, 25356, 1952, 32152, 307, 7115, 11, 51216], "temperature": 0.0, "avg_logprob": -0.12341407429088246, "compression_ratio": 1.6125, "no_speech_prob": 0.0005233242409303784}, {"id": 79, "seek": 58232, "start": 599.36, "end": 607.5200000000001, "text": " because the only way we can on bias humans is by being able to understand where the biases come", "tokens": [51216, 570, 264, 787, 636, 321, 393, 322, 12577, 6255, 307, 538, 885, 1075, 281, 1223, 689, 264, 32152, 808, 51624], "temperature": 0.0, "avg_logprob": -0.12341407429088246, "compression_ratio": 1.6125, "no_speech_prob": 0.0005233242409303784}, {"id": 80, "seek": 60752, "start": 607.52, "end": 614.88, "text": " from and then be able to use other tools to help humans make more correct decisions.", "tokens": [50364, 490, 293, 550, 312, 1075, 281, 764, 661, 3873, 281, 854, 6255, 652, 544, 3006, 5327, 13, 50732], "temperature": 0.0, "avg_logprob": -0.07702867984771729, "compression_ratio": 1.5229885057471264, "no_speech_prob": 0.001424399553798139}, {"id": 81, "seek": 60752, "start": 615.6, "end": 622.96, "text": " So sometimes the process of using simple heuristics has been shown to be more effective", "tokens": [50768, 407, 2171, 264, 1399, 295, 1228, 2199, 415, 374, 6006, 575, 668, 4898, 281, 312, 544, 4942, 51136], "temperature": 0.0, "avg_logprob": -0.07702867984771729, "compression_ratio": 1.5229885057471264, "no_speech_prob": 0.001424399553798139}, {"id": 82, "seek": 60752, "start": 622.96, "end": 631.68, "text": " in these dynamic complex tasks than even very complex reasoning or data sets that, you know,", "tokens": [51136, 294, 613, 8546, 3997, 9608, 813, 754, 588, 3997, 21577, 420, 1412, 6352, 300, 11, 291, 458, 11, 51572], "temperature": 0.0, "avg_logprob": -0.07702867984771729, "compression_ratio": 1.5229885057471264, "no_speech_prob": 0.001424399553798139}, {"id": 83, "seek": 63168, "start": 632.4, "end": 640.2399999999999, "text": " large amounts of data and algorithms that come from large amount of data often are not as good", "tokens": [50400, 2416, 11663, 295, 1412, 293, 14642, 300, 808, 490, 2416, 2372, 295, 1412, 2049, 366, 406, 382, 665, 50792], "temperature": 0.0, "avg_logprob": -0.07654766958267963, "compression_ratio": 1.5852272727272727, "no_speech_prob": 0.0014230468077585101}, {"id": 84, "seek": 63168, "start": 640.2399999999999, "end": 651.1999999999999, "text": " as human experience. So this is sort of the idea of using not the traditional approach to AI,", "tokens": [50792, 382, 1952, 1752, 13, 407, 341, 307, 1333, 295, 264, 1558, 295, 1228, 406, 264, 5164, 3109, 281, 7318, 11, 51340], "temperature": 0.0, "avg_logprob": -0.07654766958267963, "compression_ratio": 1.5852272727272727, "no_speech_prob": 0.0014230468077585101}, {"id": 85, "seek": 63168, "start": 651.1999999999999, "end": 658.56, "text": " but really to promote the idea of we need representations that can replicate the cognitive", "tokens": [51340, 457, 534, 281, 9773, 264, 1558, 295, 321, 643, 33358, 300, 393, 25356, 264, 15605, 51708], "temperature": 0.0, "avg_logprob": -0.07654766958267963, "compression_ratio": 1.5852272727272727, "no_speech_prob": 0.0014230468077585101}, {"id": 86, "seek": 65856, "start": 658.56, "end": 666.88, "text": " process. Why cognitive algorithms? Well, it's a little bit repetitive, I guess, here is we", "tokens": [50364, 1399, 13, 1545, 15605, 14642, 30, 1042, 11, 309, 311, 257, 707, 857, 29404, 11, 286, 2041, 11, 510, 307, 321, 50780], "temperature": 0.0, "avg_logprob": -0.10192430430445178, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0014227100182324648}, {"id": 87, "seek": 65856, "start": 666.88, "end": 673.1999999999999, "text": " are not trying to create super humans, but we're trying to imitate cognition. And here are some", "tokens": [50780, 366, 406, 1382, 281, 1884, 1687, 6255, 11, 457, 321, 434, 1382, 281, 35556, 46905, 13, 400, 510, 366, 512, 51096], "temperature": 0.0, "avg_logprob": -0.10192430430445178, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0014227100182324648}, {"id": 88, "seek": 65856, "start": 673.1999999999999, "end": 681.28, "text": " of the advantages and some ways in which these type of algorithms can be used. So they can help", "tokens": [51096, 295, 264, 14906, 293, 512, 2098, 294, 597, 613, 2010, 295, 14642, 393, 312, 1143, 13, 407, 436, 393, 854, 51500], "temperature": 0.0, "avg_logprob": -0.10192430430445178, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0014227100182324648}, {"id": 89, "seek": 65856, "start": 681.28, "end": 688.16, "text": " explain the cognitive process of decisions on their uncertainty. They are also dynamic and they", "tokens": [51500, 2903, 264, 15605, 1399, 295, 5327, 322, 641, 15697, 13, 814, 366, 611, 8546, 293, 436, 51844], "temperature": 0.0, "avg_logprob": -0.10192430430445178, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0014227100182324648}, {"id": 90, "seek": 68816, "start": 688.16, "end": 697.76, "text": " can learn, presumably like humans learn to make better decisions. They can inform other decision", "tokens": [50364, 393, 1466, 11, 26742, 411, 6255, 1466, 281, 652, 1101, 5327, 13, 814, 393, 1356, 661, 3537, 50844], "temperature": 0.0, "avg_logprob": -0.09467838704586029, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.0012111305259168148}, {"id": 91, "seek": 68816, "start": 697.76, "end": 707.4399999999999, "text": " aids or other autonomous systems to help humans. They can also be synchronized with the humans.", "tokens": [50844, 28447, 420, 661, 23797, 3652, 281, 854, 6255, 13, 814, 393, 611, 312, 19331, 1602, 365, 264, 6255, 13, 51328], "temperature": 0.0, "avg_logprob": -0.09467838704586029, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.0012111305259168148}, {"id": 92, "seek": 68816, "start": 707.4399999999999, "end": 716.56, "text": " So for example, if I want to emulate Mirta's decision processes, I will need some information", "tokens": [51328, 407, 337, 1365, 11, 498, 286, 528, 281, 45497, 9421, 1328, 311, 3537, 7555, 11, 286, 486, 643, 512, 1589, 51784], "temperature": 0.0, "avg_logprob": -0.09467838704586029, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.0012111305259168148}, {"id": 93, "seek": 71656, "start": 716.56, "end": 725.28, "text": " about Mirta's past experience, but I can trace Mirta's decisions over time to be able to predict", "tokens": [50364, 466, 9421, 1328, 311, 1791, 1752, 11, 457, 286, 393, 13508, 9421, 1328, 311, 5327, 670, 565, 281, 312, 1075, 281, 6069, 50800], "temperature": 0.0, "avg_logprob": -0.06849684666112527, "compression_ratio": 1.8480392156862746, "no_speech_prob": 0.0016386478673666716}, {"id": 94, "seek": 71656, "start": 725.28, "end": 730.88, "text": " what Mirta is going to do in a particular situation. So we can do that with these models.", "tokens": [50800, 437, 9421, 1328, 307, 516, 281, 360, 294, 257, 1729, 2590, 13, 407, 321, 393, 360, 300, 365, 613, 5245, 13, 51080], "temperature": 0.0, "avg_logprob": -0.06849684666112527, "compression_ratio": 1.8480392156862746, "no_speech_prob": 0.0016386478673666716}, {"id": 95, "seek": 71656, "start": 731.4399999999999, "end": 738.8, "text": " And we can also make them be collaborators with others. So if I can emulate Mirta's decision,", "tokens": [51108, 400, 321, 393, 611, 652, 552, 312, 39789, 365, 2357, 13, 407, 498, 286, 393, 45497, 9421, 1328, 311, 3537, 11, 51476], "temperature": 0.0, "avg_logprob": -0.06849684666112527, "compression_ratio": 1.8480392156862746, "no_speech_prob": 0.0016386478673666716}, {"id": 96, "seek": 71656, "start": 738.8, "end": 744.16, "text": " then I can predict what Mirta is going to do when she collaborates with me. So that's in general", "tokens": [51476, 550, 286, 393, 6069, 437, 9421, 1328, 307, 516, 281, 360, 562, 750, 5091, 1024, 365, 385, 13, 407, 300, 311, 294, 2674, 51744], "temperature": 0.0, "avg_logprob": -0.06849684666112527, "compression_ratio": 1.8480392156862746, "no_speech_prob": 0.0016386478673666716}, {"id": 97, "seek": 74416, "start": 744.9599999999999, "end": 750.8, "text": " the idea of why cognitive algorithms are different from traditional or at least", "tokens": [50404, 264, 1558, 295, 983, 15605, 14642, 366, 819, 490, 5164, 420, 412, 1935, 50696], "temperature": 0.0, "avg_logprob": -0.14568811730493472, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.0009903620230033994}, {"id": 98, "seek": 74416, "start": 750.8, "end": 759.28, "text": " currently traditional AI. So I have been trying to pursue these two essential questions. My whole", "tokens": [50696, 4362, 5164, 7318, 13, 407, 286, 362, 668, 1382, 281, 12392, 613, 732, 7115, 1651, 13, 1222, 1379, 51120], "temperature": 0.0, "avg_logprob": -0.14568811730493472, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.0009903620230033994}, {"id": 99, "seek": 74416, "start": 760.0, "end": 766.56, "text": " research career is about how do human make decisions learn and adapt in dynamic tasks.", "tokens": [51156, 2132, 3988, 307, 466, 577, 360, 1952, 652, 5327, 1466, 293, 6231, 294, 8546, 9608, 13, 51484], "temperature": 0.0, "avg_logprob": -0.14568811730493472, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.0009903620230033994}, {"id": 100, "seek": 74416, "start": 766.56, "end": 772.8, "text": " And the second is how can I represent such process computationally. So I'm going to go with the first", "tokens": [51484, 400, 264, 1150, 307, 577, 393, 286, 2906, 1270, 1399, 24903, 379, 13, 407, 286, 478, 516, 281, 352, 365, 264, 700, 51796], "temperature": 0.0, "avg_logprob": -0.14568811730493472, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.0009903620230033994}, {"id": 101, "seek": 77280, "start": 772.8, "end": 780.8, "text": " one too. And when I came to Carnegie Mellon, which was late 90s and beginning 2000, I started as a", "tokens": [50364, 472, 886, 13, 400, 562, 286, 1361, 281, 47301, 376, 898, 266, 11, 597, 390, 3469, 4289, 82, 293, 2863, 8132, 11, 286, 1409, 382, 257, 50764], "temperature": 0.0, "avg_logprob": -0.0960331780569894, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0013266591122373939}, {"id": 102, "seek": 77280, "start": 780.8, "end": 789.92, "text": " professor. The concept that I observed about decision making was very different from what I had in", "tokens": [50764, 8304, 13, 440, 3410, 300, 286, 13095, 466, 3537, 1455, 390, 588, 819, 490, 437, 286, 632, 294, 51220], "temperature": 0.0, "avg_logprob": -0.0960331780569894, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0013266591122373939}, {"id": 103, "seek": 77280, "start": 789.92, "end": 798.3199999999999, "text": " mind. It was static decision making, economics decision making. But I was inspired by many", "tokens": [51220, 1575, 13, 467, 390, 13437, 3537, 1455, 11, 14564, 3537, 1455, 13, 583, 286, 390, 7547, 538, 867, 51640], "temperature": 0.0, "avg_logprob": -0.0960331780569894, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0013266591122373939}, {"id": 104, "seek": 79832, "start": 798.32, "end": 803.7600000000001, "text": " people, including this quote by Edward Edwards, where he said that static decision", "tokens": [50364, 561, 11, 3009, 341, 6513, 538, 18456, 35836, 11, 689, 415, 848, 300, 13437, 3537, 50636], "temperature": 0.0, "avg_logprob": -0.1390531973405318, "compression_ratio": 1.5, "no_speech_prob": 0.0017736573936417699}, {"id": 105, "seek": 79832, "start": 804.48, "end": 812.24, "text": " theories have only a limited future. Human beings learn and probabilities and values change.", "tokens": [50672, 13667, 362, 787, 257, 5567, 2027, 13, 10294, 8958, 1466, 293, 33783, 293, 4190, 1319, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1390531973405318, "compression_ratio": 1.5, "no_speech_prob": 0.0017736573936417699}, {"id": 106, "seek": 79832, "start": 812.88, "end": 819.84, "text": " These facts mean that the really applicable kinds of decision theories will be dynamic and not", "tokens": [51092, 1981, 9130, 914, 300, 264, 534, 21142, 3685, 295, 3537, 13667, 486, 312, 8546, 293, 406, 51440], "temperature": 0.0, "avg_logprob": -0.1390531973405318, "compression_ratio": 1.5, "no_speech_prob": 0.0017736573936417699}, {"id": 107, "seek": 81984, "start": 819.84, "end": 829.12, "text": " static. So I was stubborn enough to pursue the idea that we want to study dynamic decision making", "tokens": [50364, 13437, 13, 407, 286, 390, 24137, 1547, 281, 12392, 264, 1558, 300, 321, 528, 281, 2979, 8546, 3537, 1455, 50828], "temperature": 0.0, "avg_logprob": -0.05893550163660294, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.003262993646785617}, {"id": 108, "seek": 81984, "start": 829.12, "end": 832.96, "text": " even though nobody in my department understood what the hell I was talking about.", "tokens": [50828, 754, 1673, 5079, 294, 452, 5882, 7320, 437, 264, 4921, 286, 390, 1417, 466, 13, 51020], "temperature": 0.0, "avg_logprob": -0.05893550163660294, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.003262993646785617}, {"id": 109, "seek": 81984, "start": 834.5600000000001, "end": 840.64, "text": " This is what they were talking about. And this is a more traditional approach of classical", "tokens": [51100, 639, 307, 437, 436, 645, 1417, 466, 13, 400, 341, 307, 257, 544, 5164, 3109, 295, 13735, 51404], "temperature": 0.0, "avg_logprob": -0.05893550163660294, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.003262993646785617}, {"id": 110, "seek": 81984, "start": 840.64, "end": 847.36, "text": " decision making. It's a linear process where you have alternatives. The alternatives are usually", "tokens": [51404, 3537, 1455, 13, 467, 311, 257, 8213, 1399, 689, 291, 362, 20478, 13, 440, 20478, 366, 2673, 51740], "temperature": 0.0, "avg_logprob": -0.05893550163660294, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.003262993646785617}, {"id": 111, "seek": 84736, "start": 847.36, "end": 853.52, "text": " well established, meaning they are obviously provided to you. You have option A and option", "tokens": [50364, 731, 7545, 11, 3620, 436, 366, 2745, 5649, 281, 291, 13, 509, 362, 3614, 316, 293, 3614, 50672], "temperature": 0.0, "avg_logprob": -0.14296380211325252, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0015617858152836561}, {"id": 112, "seek": 84736, "start": 853.52, "end": 860.4, "text": " B, usually represented as a decision tree, and then calculated based on expected value what", "tokens": [50672, 363, 11, 2673, 10379, 382, 257, 3537, 4230, 11, 293, 550, 15598, 2361, 322, 5176, 2158, 437, 51016], "temperature": 0.0, "avg_logprob": -0.14296380211325252, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0015617858152836561}, {"id": 113, "seek": 84736, "start": 860.4, "end": 868.08, "text": " humans should do. Expected value concept, of course, is an extremely useful today and always will be,", "tokens": [51016, 6255, 820, 360, 13, 2111, 10729, 2158, 3410, 11, 295, 1164, 11, 307, 364, 4664, 4420, 965, 293, 1009, 486, 312, 11, 51400], "temperature": 0.0, "avg_logprob": -0.14296380211325252, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0015617858152836561}, {"id": 114, "seek": 84736, "start": 868.08, "end": 875.28, "text": " I think, a concept on optimal decision making. But of course, very soon people realize that", "tokens": [51400, 286, 519, 11, 257, 3410, 322, 16252, 3537, 1455, 13, 583, 295, 1164, 11, 588, 2321, 561, 4325, 300, 51760], "temperature": 0.0, "avg_logprob": -0.14296380211325252, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.0015617858152836561}, {"id": 115, "seek": 87528, "start": 876.0, "end": 884.16, "text": " humans don't make decisions optimally. And so this famous theory by Kanieman and Taversky,", "tokens": [50400, 6255, 500, 380, 652, 5327, 5028, 379, 13, 400, 370, 341, 4618, 5261, 538, 591, 7155, 1601, 293, 6551, 840, 4133, 11, 50808], "temperature": 0.0, "avg_logprob": -0.16995484901197028, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.0016298837726935744}, {"id": 116, "seek": 87528, "start": 884.16, "end": 892.4, "text": " which is still very popular and very influential today, what they essentially did was to modify", "tokens": [50808, 597, 307, 920, 588, 3743, 293, 588, 22215, 965, 11, 437, 436, 4476, 630, 390, 281, 16927, 51220], "temperature": 0.0, "avg_logprob": -0.16995484901197028, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.0016298837726935744}, {"id": 117, "seek": 87528, "start": 892.4, "end": 899.68, "text": " the concept of expected value into functions that are more human-like. And of course, they", "tokens": [51220, 264, 3410, 295, 5176, 2158, 666, 6828, 300, 366, 544, 1952, 12, 4092, 13, 400, 295, 1164, 11, 436, 51584], "temperature": 0.0, "avg_logprob": -0.16995484901197028, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.0016298837726935744}, {"id": 118, "seek": 89968, "start": 899.68, "end": 905.76, "text": " supported these functions based on human behavior. So humans are not optimal. Instead,", "tokens": [50364, 8104, 613, 6828, 2361, 322, 1952, 5223, 13, 407, 6255, 366, 406, 16252, 13, 7156, 11, 50668], "temperature": 0.0, "avg_logprob": -0.10610035487583705, "compression_ratio": 1.6198830409356726, "no_speech_prob": 0.003203279571607709}, {"id": 119, "seek": 89968, "start": 905.76, "end": 912.2399999999999, "text": " humans are behaving according to these other functions. And that's how you can find out what", "tokens": [50668, 6255, 366, 35263, 4650, 281, 613, 661, 6828, 13, 400, 300, 311, 577, 291, 393, 915, 484, 437, 50992], "temperature": 0.0, "avg_logprob": -0.10610035487583705, "compression_ratio": 1.6198830409356726, "no_speech_prob": 0.003203279571607709}, {"id": 120, "seek": 89968, "start": 912.2399999999999, "end": 920.4799999999999, "text": " humans are going to do. And yeah, that's fantastic and still influential. But this type of theory", "tokens": [50992, 6255, 366, 516, 281, 360, 13, 400, 1338, 11, 300, 311, 5456, 293, 920, 22215, 13, 583, 341, 2010, 295, 5261, 51404], "temperature": 0.0, "avg_logprob": -0.10610035487583705, "compression_ratio": 1.6198830409356726, "no_speech_prob": 0.003203279571607709}, {"id": 121, "seek": 92048, "start": 921.12, "end": 926.5600000000001, "text": " is just not applicable to dynamic situations that are constantly", "tokens": [50396, 307, 445, 406, 21142, 281, 8546, 6851, 300, 366, 6460, 50668], "temperature": 0.0, "avg_logprob": -0.07484998021806989, "compression_ratio": 1.398876404494382, "no_speech_prob": 0.0028287158347666264}, {"id": 122, "seek": 92048, "start": 927.44, "end": 936.32, "text": " adapting according to various factors over time. Now, if we go completely to the other extreme", "tokens": [50712, 34942, 4650, 281, 3683, 6771, 670, 565, 13, 823, 11, 498, 321, 352, 2584, 281, 264, 661, 8084, 51156], "temperature": 0.0, "avg_logprob": -0.07484998021806989, "compression_ratio": 1.398876404494382, "no_speech_prob": 0.0028287158347666264}, {"id": 123, "seek": 92048, "start": 936.32, "end": 944.5600000000001, "text": " of what I was studying early 2000, I worked with Gary Klein in a very big project for the", "tokens": [51156, 295, 437, 286, 390, 7601, 2440, 8132, 11, 286, 2732, 365, 13788, 33327, 294, 257, 588, 955, 1716, 337, 264, 51568], "temperature": 0.0, "avg_logprob": -0.07484998021806989, "compression_ratio": 1.398876404494382, "no_speech_prob": 0.0028287158347666264}, {"id": 124, "seek": 94456, "start": 944.56, "end": 950.8, "text": " army research laboratories. And Gary was the opposite of all the behavioral economics. At", "tokens": [50364, 7267, 2132, 41013, 13, 400, 13788, 390, 264, 6182, 295, 439, 264, 19124, 14564, 13, 1711, 50676], "temperature": 0.0, "avg_logprob": -0.11025669574737548, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002957407385110855}, {"id": 125, "seek": 94456, "start": 950.8, "end": 957.92, "text": " that time, it wasn't behavioral, it was just economics. So Gary Klein was studying naturalistic", "tokens": [50676, 300, 565, 11, 309, 2067, 380, 19124, 11, 309, 390, 445, 14564, 13, 407, 13788, 33327, 390, 7601, 3303, 3142, 51032], "temperature": 0.0, "avg_logprob": -0.11025669574737548, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002957407385110855}, {"id": 126, "seek": 94456, "start": 957.92, "end": 964.8, "text": " situations, in particular firefighters. So there are books about naturalistic decision making.", "tokens": [51032, 6851, 11, 294, 1729, 37218, 13, 407, 456, 366, 3642, 466, 3303, 3142, 3537, 1455, 13, 51376], "temperature": 0.0, "avg_logprob": -0.11025669574737548, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002957407385110855}, {"id": 127, "seek": 94456, "start": 964.8, "end": 970.9599999999999, "text": " There is a conference. There are lots of people interested in this area. But essentially what", "tokens": [51376, 821, 307, 257, 7586, 13, 821, 366, 3195, 295, 561, 3102, 294, 341, 1859, 13, 583, 4476, 437, 51684], "temperature": 0.0, "avg_logprob": -0.11025669574737548, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002957407385110855}, {"id": 128, "seek": 97096, "start": 971.0400000000001, "end": 978.08, "text": " you do in this case is you actually go to the place where decisions are made. Let's say", "tokens": [50368, 291, 360, 294, 341, 1389, 307, 291, 767, 352, 281, 264, 1081, 689, 5327, 366, 1027, 13, 961, 311, 584, 50720], "temperature": 0.0, "avg_logprob": -0.08214047311366289, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.003309197025373578}, {"id": 129, "seek": 97096, "start": 978.08, "end": 984.96, "text": " firefighters. And he describes in his book how he would get on the trucks with the firefighters to", "tokens": [50720, 37218, 13, 400, 415, 15626, 294, 702, 1446, 577, 415, 576, 483, 322, 264, 16156, 365, 264, 37218, 281, 51064], "temperature": 0.0, "avg_logprob": -0.08214047311366289, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.003309197025373578}, {"id": 130, "seek": 97096, "start": 984.96, "end": 991.36, "text": " find out how they make decisions in those very constrained tasks. And then he found out that", "tokens": [51064, 915, 484, 577, 436, 652, 5327, 294, 729, 588, 38901, 9608, 13, 400, 550, 415, 1352, 484, 300, 51384], "temperature": 0.0, "avg_logprob": -0.08214047311366289, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.003309197025373578}, {"id": 131, "seek": 97096, "start": 992.24, "end": 998.24, "text": " they don't make decisions. At least that's what they express the firefighters. They just said,", "tokens": [51428, 436, 500, 380, 652, 5327, 13, 1711, 1935, 300, 311, 437, 436, 5109, 264, 37218, 13, 814, 445, 848, 11, 51728], "temperature": 0.0, "avg_logprob": -0.08214047311366289, "compression_ratio": 1.7476635514018692, "no_speech_prob": 0.003309197025373578}, {"id": 132, "seek": 99824, "start": 998.24, "end": 1005.6, "text": " I just know what to do. I just get in there. I've seen these situations so many times in the past.", "tokens": [50364, 286, 445, 458, 437, 281, 360, 13, 286, 445, 483, 294, 456, 13, 286, 600, 1612, 613, 6851, 370, 867, 1413, 294, 264, 1791, 13, 50732], "temperature": 0.0, "avg_logprob": -0.07931060109819685, "compression_ratio": 1.6079545454545454, "no_speech_prob": 0.0017411942826583982}, {"id": 133, "seek": 99824, "start": 1005.6, "end": 1015.6800000000001, "text": " I just know what to do. So he documents in his book all the stories about the many firefighters", "tokens": [50732, 286, 445, 458, 437, 281, 360, 13, 407, 415, 8512, 294, 702, 1446, 439, 264, 3676, 466, 264, 867, 37218, 51236], "temperature": 0.0, "avg_logprob": -0.07931060109819685, "compression_ratio": 1.6079545454545454, "no_speech_prob": 0.0017411942826583982}, {"id": 134, "seek": 99824, "start": 1015.6800000000001, "end": 1023.12, "text": " making decisions. And this type of approach has been used in hospitals and in many other", "tokens": [51236, 1455, 5327, 13, 400, 341, 2010, 295, 3109, 575, 668, 1143, 294, 13014, 293, 294, 867, 661, 51608], "temperature": 0.0, "avg_logprob": -0.07931060109819685, "compression_ratio": 1.6079545454545454, "no_speech_prob": 0.0017411942826583982}, {"id": 135, "seek": 102312, "start": 1023.12, "end": 1032.08, "text": " naturalistic situations. So out of that work came a model that he called the recognition", "tokens": [50364, 3303, 3142, 6851, 13, 407, 484, 295, 300, 589, 1361, 257, 2316, 300, 415, 1219, 264, 11150, 50812], "temperature": 0.0, "avg_logprob": -0.07451036169722274, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0022352661471813917}, {"id": 136, "seek": 102312, "start": 1032.08, "end": 1038.64, "text": " prime decision model, which was very influential to me. The essential element of recognition", "tokens": [50812, 5835, 3537, 2316, 11, 597, 390, 588, 22215, 281, 385, 13, 440, 7115, 4478, 295, 11150, 51140], "temperature": 0.0, "avg_logprob": -0.07451036169722274, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0022352661471813917}, {"id": 137, "seek": 102312, "start": 1038.64, "end": 1045.12, "text": " prime decision model is recognition. What is recognition is our ability to determine the", "tokens": [51140, 5835, 3537, 2316, 307, 11150, 13, 708, 307, 11150, 307, 527, 3485, 281, 6997, 264, 51464], "temperature": 0.0, "avg_logprob": -0.07451036169722274, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0022352661471813917}, {"id": 138, "seek": 102312, "start": 1045.12, "end": 1051.6, "text": " similarity between a situation we are confronting and what we have confronted in the past.", "tokens": [51464, 32194, 1296, 257, 2590, 321, 366, 47449, 293, 437, 321, 362, 31257, 294, 264, 1791, 13, 51788], "temperature": 0.0, "avg_logprob": -0.07451036169722274, "compression_ratio": 1.7871287128712872, "no_speech_prob": 0.0022352661471813917}, {"id": 139, "seek": 105160, "start": 1052.56, "end": 1060.3999999999999, "text": " And so he proposes how such a match determines whether we know a situation is typical or not", "tokens": [50412, 400, 370, 415, 2365, 4201, 577, 1270, 257, 2995, 24799, 1968, 321, 458, 257, 2590, 307, 7476, 420, 406, 50804], "temperature": 0.0, "avg_logprob": -0.05398566382271903, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.0015116011491045356}, {"id": 140, "seek": 105160, "start": 1060.3999999999999, "end": 1069.4399999999998, "text": " typical. And then based on that, we engage in some sort of mental simulation to figure out", "tokens": [50804, 7476, 13, 400, 550, 2361, 322, 300, 11, 321, 4683, 294, 512, 1333, 295, 4973, 16575, 281, 2573, 484, 51256], "temperature": 0.0, "avg_logprob": -0.05398566382271903, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.0015116011491045356}, {"id": 141, "seek": 105160, "start": 1070.48, "end": 1077.12, "text": " different courses of action. This presumably happens very fast. And then you are able to", "tokens": [51308, 819, 7712, 295, 3069, 13, 639, 26742, 2314, 588, 2370, 13, 400, 550, 291, 366, 1075, 281, 51640], "temperature": 0.0, "avg_logprob": -0.05398566382271903, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.0015116011491045356}, {"id": 142, "seek": 107712, "start": 1077.12, "end": 1085.36, "text": " finally decide what to do and implement a course of action. So very inspiring. It made", "tokens": [50364, 2721, 4536, 437, 281, 360, 293, 4445, 257, 1164, 295, 3069, 13, 407, 588, 15883, 13, 467, 1027, 50776], "temperature": 0.0, "avg_logprob": -0.1097610567657041, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.000892611569724977}, {"id": 143, "seek": 107712, "start": 1085.36, "end": 1093.4399999999998, "text": " a lot of sense to me, but it wasn't computational. And it hasn't been as far as I know up to now.", "tokens": [50776, 257, 688, 295, 2020, 281, 385, 11, 457, 309, 2067, 380, 28270, 13, 400, 309, 6132, 380, 668, 382, 1400, 382, 286, 458, 493, 281, 586, 13, 51180], "temperature": 0.0, "avg_logprob": -0.1097610567657041, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.000892611569724977}, {"id": 144, "seek": 107712, "start": 1093.4399999999998, "end": 1100.8, "text": " There has been many attempts to make this sort of theory computational, but to my knowledge,", "tokens": [51180, 821, 575, 668, 867, 15257, 281, 652, 341, 1333, 295, 5261, 28270, 11, 457, 281, 452, 3601, 11, 51548], "temperature": 0.0, "avg_logprob": -0.1097610567657041, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.000892611569724977}, {"id": 145, "seek": 110080, "start": 1100.8, "end": 1109.84, "text": " none of them have been really successful. So what I do is sort of in the middle of these two", "tokens": [50364, 6022, 295, 552, 362, 668, 534, 4406, 13, 407, 437, 286, 360, 307, 1333, 295, 294, 264, 2808, 295, 613, 732, 50816], "temperature": 0.0, "avg_logprob": -0.0914382865463478, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0018875140231102705}, {"id": 146, "seek": 110080, "start": 1109.84, "end": 1116.0, "text": " extremes. Dynamic decision making, I sort of realized that I'm not going to make a lot of", "tokens": [50816, 41119, 13, 45440, 3537, 1455, 11, 286, 1333, 295, 5334, 300, 286, 478, 406, 516, 281, 652, 257, 688, 295, 51124], "temperature": 0.0, "avg_logprob": -0.0914382865463478, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0018875140231102705}, {"id": 147, "seek": 110080, "start": 1116.0, "end": 1122.72, "text": " progress if I go and get on the trucks with firefighters. So instead, I'm going to take", "tokens": [51124, 4205, 498, 286, 352, 293, 483, 322, 264, 16156, 365, 37218, 13, 407, 2602, 11, 286, 478, 516, 281, 747, 51460], "temperature": 0.0, "avg_logprob": -0.0914382865463478, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.0018875140231102705}, {"id": 148, "seek": 112272, "start": 1122.72, "end": 1132.08, "text": " the approach that others have taken like Brent Bremmer and Joaquin Funke to create micro worlds.", "tokens": [50364, 264, 3109, 300, 2357, 362, 2726, 411, 31665, 363, 2579, 936, 293, 3139, 23761, 259, 11166, 330, 281, 1884, 4532, 13401, 13, 50832], "temperature": 0.0, "avg_logprob": -0.1471084247935902, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.008671996183693409}, {"id": 149, "seek": 112272, "start": 1132.8, "end": 1141.6000000000001, "text": " So these are reductions of these real world situations in which we can actually use experimentation.", "tokens": [50868, 407, 613, 366, 40296, 295, 613, 957, 1002, 6851, 294, 597, 321, 393, 767, 764, 37142, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1471084247935902, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.008671996183693409}, {"id": 150, "seek": 112272, "start": 1141.6000000000001, "end": 1147.6000000000001, "text": " And to me, it was very important to be able to see the cause and effect relationships,", "tokens": [51308, 400, 281, 385, 11, 309, 390, 588, 1021, 281, 312, 1075, 281, 536, 264, 3082, 293, 1802, 6159, 11, 51608], "temperature": 0.0, "avg_logprob": -0.1471084247935902, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.008671996183693409}, {"id": 151, "seek": 114760, "start": 1147.6, "end": 1157.6, "text": " not only rely on observations. And so this is just a whole lot of the many micro worlds we", "tokens": [50364, 406, 787, 10687, 322, 18163, 13, 400, 370, 341, 307, 445, 257, 1379, 688, 295, 264, 867, 4532, 13401, 321, 50864], "temperature": 0.0, "avg_logprob": -0.1356535384904093, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0013392282417044044}, {"id": 152, "seek": 114760, "start": 1157.6, "end": 1166.56, "text": " have developed and used in my lab through the various years. Initially, I used and developed", "tokens": [50864, 362, 4743, 293, 1143, 294, 452, 2715, 807, 264, 3683, 924, 13, 29446, 11, 286, 1143, 293, 4743, 51312], "temperature": 0.0, "avg_logprob": -0.1356535384904093, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0013392282417044044}, {"id": 153, "seek": 114760, "start": 1166.56, "end": 1176.24, "text": " this and it took many, many years to develop. It's a water purification plant task that has", "tokens": [51312, 341, 293, 309, 1890, 867, 11, 867, 924, 281, 1499, 13, 467, 311, 257, 1281, 1864, 3774, 3709, 5633, 300, 575, 51796], "temperature": 0.0, "avg_logprob": -0.1356535384904093, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.0013392282417044044}, {"id": 154, "seek": 117624, "start": 1176.32, "end": 1182.32, "text": " all the major elements of dynamic decision making. It's a dynamic resource allocation with", "tokens": [50368, 439, 264, 2563, 4959, 295, 8546, 3537, 1455, 13, 467, 311, 257, 8546, 7684, 27599, 365, 50668], "temperature": 0.0, "avg_logprob": -0.11310725376523774, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.000515134772285819}, {"id": 155, "seek": 117624, "start": 1182.32, "end": 1189.04, "text": " limitations of time, et cetera. So we developed a theory, we gathered a lot of information based", "tokens": [50668, 15705, 295, 565, 11, 1030, 11458, 13, 407, 321, 4743, 257, 5261, 11, 321, 13032, 257, 688, 295, 1589, 2361, 51004], "temperature": 0.0, "avg_logprob": -0.11310725376523774, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.000515134772285819}, {"id": 156, "seek": 117624, "start": 1189.04, "end": 1195.36, "text": " on that task. But then the main question was like, well, whatever you are doing is only applicable", "tokens": [51004, 322, 300, 5633, 13, 583, 550, 264, 2135, 1168, 390, 411, 11, 731, 11, 2035, 291, 366, 884, 307, 787, 21142, 51320], "temperature": 0.0, "avg_logprob": -0.11310725376523774, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.000515134772285819}, {"id": 157, "seek": 117624, "start": 1195.36, "end": 1200.56, "text": " to this task. You haven't shown me that what your models and your things that you are doing", "tokens": [51320, 281, 341, 5633, 13, 509, 2378, 380, 4898, 385, 300, 437, 428, 5245, 293, 428, 721, 300, 291, 366, 884, 51580], "temperature": 0.0, "avg_logprob": -0.11310725376523774, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.000515134772285819}, {"id": 158, "seek": 120056, "start": 1201.36, "end": 1209.04, "text": " can be applicable to many tasks. So then we went wild and then we just developed all kinds of", "tokens": [50404, 393, 312, 21142, 281, 867, 9608, 13, 407, 550, 321, 1437, 4868, 293, 550, 321, 445, 4743, 439, 3685, 295, 50788], "temperature": 0.0, "avg_logprob": -0.07332955300807953, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.003001558594405651}, {"id": 159, "seek": 120056, "start": 1209.04, "end": 1215.76, "text": " micro worlds and started to apply to many other tasks to demonstrate that our theory and our ideas", "tokens": [50788, 4532, 13401, 293, 1409, 281, 3079, 281, 867, 661, 9608, 281, 11698, 300, 527, 5261, 293, 527, 3487, 51124], "temperature": 0.0, "avg_logprob": -0.07332955300807953, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.003001558594405651}, {"id": 160, "seek": 120056, "start": 1215.76, "end": 1226.24, "text": " were more general than just that particular task. Now, this is a summary of behavioral phenomena", "tokens": [51124, 645, 544, 2674, 813, 445, 300, 1729, 5633, 13, 823, 11, 341, 307, 257, 12691, 295, 19124, 22004, 51648], "temperature": 0.0, "avg_logprob": -0.07332955300807953, "compression_ratio": 1.5621621621621622, "no_speech_prob": 0.003001558594405651}, {"id": 161, "seek": 122624, "start": 1226.32, "end": 1233.28, "text": " that came out of experimental work with many different micro worlds. So I'm going to go over it", "tokens": [50368, 300, 1361, 484, 295, 17069, 589, 365, 867, 819, 4532, 13401, 13, 407, 286, 478, 516, 281, 352, 670, 309, 50716], "temperature": 0.0, "avg_logprob": -0.09022502601146698, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.0007996580097824335}, {"id": 162, "seek": 122624, "start": 1233.28, "end": 1241.68, "text": " but relatively quickly given the time. So the first thing is when I arrived to this area, the", "tokens": [50716, 457, 7226, 2661, 2212, 264, 565, 13, 407, 264, 700, 551, 307, 562, 286, 6678, 281, 341, 1859, 11, 264, 51136], "temperature": 0.0, "avg_logprob": -0.09022502601146698, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.0007996580097824335}, {"id": 163, "seek": 122624, "start": 1243.28, "end": 1253.68, "text": " picture was very frustratingly negative. So all humans are very poor at making decisions", "tokens": [51216, 3036, 390, 588, 16522, 356, 3671, 13, 407, 439, 6255, 366, 588, 4716, 412, 1455, 5327, 51736], "temperature": 0.0, "avg_logprob": -0.09022502601146698, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.0007996580097824335}, {"id": 164, "seek": 125368, "start": 1253.68, "end": 1260.64, "text": " in dynamic environments. Even when you give them full feedback and you give them unlimited time", "tokens": [50364, 294, 8546, 12388, 13, 2754, 562, 291, 976, 552, 1577, 5824, 293, 291, 976, 552, 21950, 565, 50712], "temperature": 0.0, "avg_logprob": -0.11184773528785036, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.001191608840599656}, {"id": 165, "seek": 125368, "start": 1260.64, "end": 1267.76, "text": " incentives, extensive practice, we are born with something that doesn't allow us to make", "tokens": [50712, 23374, 11, 13246, 3124, 11, 321, 366, 4232, 365, 746, 300, 1177, 380, 2089, 505, 281, 652, 51068], "temperature": 0.0, "avg_logprob": -0.11184773528785036, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.001191608840599656}, {"id": 166, "seek": 125368, "start": 1268.4, "end": 1276.88, "text": " good decisions in these very complex environments. People are generally poor at handling systems", "tokens": [51100, 665, 5327, 294, 613, 588, 3997, 12388, 13, 3432, 366, 5101, 4716, 412, 13175, 3652, 51524], "temperature": 0.0, "avg_logprob": -0.11184773528785036, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.001191608840599656}, {"id": 167, "seek": 127688, "start": 1276.88, "end": 1284.72, "text": " with long feedback delays. A lot of people where Bremer, including basically almost all his work,", "tokens": [50364, 365, 938, 5824, 28610, 13, 316, 688, 295, 561, 689, 7090, 936, 11, 3009, 1936, 1920, 439, 702, 589, 11, 50756], "temperature": 0.0, "avg_logprob": -0.1496183122907366, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.007505279034376144}, {"id": 168, "seek": 127688, "start": 1284.72, "end": 1291.7600000000002, "text": " was about demonstrating of long feedback delays and the effect of that on decision making. So the", "tokens": [50756, 390, 466, 29889, 295, 938, 5824, 28610, 293, 264, 1802, 295, 300, 322, 3537, 1455, 13, 407, 264, 51108], "temperature": 0.0, "avg_logprob": -0.1496183122907366, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.007505279034376144}, {"id": 169, "seek": 127688, "start": 1291.7600000000002, "end": 1300.88, "text": " longer the delay is, the poorer decisions we make. So, okay, I was taking all that and I was in", "tokens": [51108, 2854, 264, 8577, 307, 11, 264, 49740, 5327, 321, 652, 13, 407, 11, 1392, 11, 286, 390, 1940, 439, 300, 293, 286, 390, 294, 51564], "temperature": 0.0, "avg_logprob": -0.1496183122907366, "compression_ratio": 1.6166666666666667, "no_speech_prob": 0.007505279034376144}, {"id": 170, "seek": 130088, "start": 1300.88, "end": 1307.5200000000002, "text": " agreement with all that, but at the same time, I could observe that people in the real world,", "tokens": [50364, 8106, 365, 439, 300, 11, 457, 412, 264, 912, 565, 11, 286, 727, 11441, 300, 561, 294, 264, 957, 1002, 11, 50696], "temperature": 0.0, "avg_logprob": -0.08588211644779552, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.004886568523943424}, {"id": 171, "seek": 130088, "start": 1307.5200000000002, "end": 1313.8400000000001, "text": " some of them are pretty good at making very complex decisions. So how can we explain that?", "tokens": [50696, 512, 295, 552, 366, 1238, 665, 412, 1455, 588, 3997, 5327, 13, 407, 577, 393, 321, 2903, 300, 30, 51012], "temperature": 0.0, "avg_logprob": -0.08588211644779552, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.004886568523943424}, {"id": 172, "seek": 130088, "start": 1314.5600000000002, "end": 1322.88, "text": " And my response to that is that it's in the learning process. It's in understanding how we go from not", "tokens": [51048, 400, 452, 4134, 281, 300, 307, 300, 309, 311, 294, 264, 2539, 1399, 13, 467, 311, 294, 3701, 577, 321, 352, 490, 406, 51464], "temperature": 0.0, "avg_logprob": -0.08588211644779552, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.004886568523943424}, {"id": 173, "seek": 130088, "start": 1322.88, "end": 1330.0, "text": " knowing how to make decisions to really making very good decisions in really complex environments.", "tokens": [51464, 5276, 577, 281, 652, 5327, 281, 534, 1455, 588, 665, 5327, 294, 534, 3997, 12388, 13, 51820], "temperature": 0.0, "avg_logprob": -0.08588211644779552, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.004886568523943424}, {"id": 174, "seek": 133088, "start": 1330.88, "end": 1338.24, "text": " So I started to study different things. For example, I found that if we give headroom, meaning", "tokens": [50364, 407, 286, 1409, 281, 2979, 819, 721, 13, 1171, 1365, 11, 286, 1352, 300, 498, 321, 976, 1378, 2861, 11, 3620, 50732], "temperature": 0.0, "avg_logprob": -0.09200997579665411, "compression_ratio": 1.5326086956521738, "no_speech_prob": 0.0006108279339969158}, {"id": 175, "seek": 133088, "start": 1338.24, "end": 1344.8000000000002, "text": " space for learning to individual decision makers, then they are able to adapt to more", "tokens": [50732, 1901, 337, 2539, 281, 2609, 3537, 19323, 11, 550, 436, 366, 1075, 281, 6231, 281, 544, 51060], "temperature": 0.0, "avg_logprob": -0.09200997579665411, "compression_ratio": 1.5326086956521738, "no_speech_prob": 0.0006108279339969158}, {"id": 176, "seek": 133088, "start": 1345.3600000000001, "end": 1353.1200000000001, "text": " difficult decision situations. For example, putting someone in a low time constraint is going to help", "tokens": [51088, 2252, 3537, 6851, 13, 1171, 1365, 11, 3372, 1580, 294, 257, 2295, 565, 25534, 307, 516, 281, 854, 51476], "temperature": 0.0, "avg_logprob": -0.09200997579665411, "compression_ratio": 1.5326086956521738, "no_speech_prob": 0.0006108279339969158}, {"id": 177, "seek": 135312, "start": 1353.84, "end": 1360.4799999999998, "text": " for that person to perform under high time constraints more than those that are always", "tokens": [50400, 337, 300, 954, 281, 2042, 833, 1090, 565, 18491, 544, 813, 729, 300, 366, 1009, 50732], "temperature": 0.0, "avg_logprob": -0.1240218769420277, "compression_ratio": 1.6012658227848102, "no_speech_prob": 0.0024536510463804007}, {"id": 178, "seek": 135312, "start": 1360.4799999999998, "end": 1365.9199999999998, "text": " trained under high time constraints. So the headroom is needed for learning.", "tokens": [50732, 8895, 833, 1090, 565, 18491, 13, 407, 264, 1378, 2861, 307, 2978, 337, 2539, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1240218769420277, "compression_ratio": 1.6012658227848102, "no_speech_prob": 0.0024536510463804007}, {"id": 179, "seek": 135312, "start": 1367.12, "end": 1375.6, "text": " Heterogeneity, experiencing different variety of situations are going to help us to adapt", "tokens": [51064, 389, 2398, 23360, 507, 11, 11139, 819, 5673, 295, 6851, 366, 516, 281, 854, 505, 281, 6231, 51488], "temperature": 0.0, "avg_logprob": -0.1240218769420277, "compression_ratio": 1.6012658227848102, "no_speech_prob": 0.0024536510463804007}, {"id": 180, "seek": 137560, "start": 1375.6, "end": 1383.76, "text": " to novel situations and we have several studies on that. The ability to pattern match is extremely", "tokens": [50364, 281, 7613, 6851, 293, 321, 362, 2940, 5313, 322, 300, 13, 440, 3485, 281, 5102, 2995, 307, 4664, 50772], "temperature": 0.0, "avg_logprob": -0.1449002916850741, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003449986921623349}, {"id": 181, "seek": 137560, "start": 1383.76, "end": 1391.6, "text": " important. At that time, we collected our ability to pattern match with the Raven progressive matrices", "tokens": [50772, 1021, 13, 1711, 300, 565, 11, 321, 11087, 527, 3485, 281, 5102, 2995, 365, 264, 28956, 16131, 32284, 51164], "temperature": 0.0, "avg_logprob": -0.1449002916850741, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003449986921623349}, {"id": 182, "seek": 137560, "start": 1392.24, "end": 1399.76, "text": " test, which is essentially a pattern matching test. And we demonstrated how the score in that test", "tokens": [51196, 1500, 11, 597, 307, 4476, 257, 5102, 14324, 1500, 13, 400, 321, 18772, 577, 264, 6175, 294, 300, 1500, 51572], "temperature": 0.0, "avg_logprob": -0.1449002916850741, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003449986921623349}, {"id": 183, "seek": 139976, "start": 1399.76, "end": 1405.92, "text": " is very predictive of the quality of the decisions that human makes in these micro worlds.", "tokens": [50364, 307, 588, 35521, 295, 264, 3125, 295, 264, 5327, 300, 1952, 1669, 294, 613, 4532, 13401, 13, 50672], "temperature": 0.0, "avg_logprob": -0.1032135590263035, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.0024589220993220806}, {"id": 184, "seek": 139976, "start": 1406.56, "end": 1411.92, "text": " And we also found how to provide feedback in a way that would be more useful", "tokens": [50704, 400, 321, 611, 1352, 577, 281, 2893, 5824, 294, 257, 636, 300, 576, 312, 544, 4420, 50972], "temperature": 0.0, "avg_logprob": -0.1032135590263035, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.0024589220993220806}, {"id": 185, "seek": 139976, "start": 1412.96, "end": 1419.6, "text": " to individuals by particularly providing observing behavior of an expert was extremely", "tokens": [51024, 281, 5346, 538, 4098, 6530, 22107, 5223, 295, 364, 5844, 390, 4664, 51356], "temperature": 0.0, "avg_logprob": -0.1032135590263035, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.0024589220993220806}, {"id": 186, "seek": 139976, "start": 1419.6, "end": 1425.52, "text": " helpful for people to learn and to adapt even after removing that feedback.", "tokens": [51356, 4961, 337, 561, 281, 1466, 293, 281, 6231, 754, 934, 12720, 300, 5824, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1032135590263035, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.0024589220993220806}, {"id": 187, "seek": 142552, "start": 1426.32, "end": 1431.44, "text": " So this is a list of some of the phenomena and all the things that we have found.", "tokens": [50404, 407, 341, 307, 257, 1329, 295, 512, 295, 264, 22004, 293, 439, 264, 721, 300, 321, 362, 1352, 13, 50660], "temperature": 0.0, "avg_logprob": -0.10163693200974237, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0005170598742552102}, {"id": 188, "seek": 142552, "start": 1433.28, "end": 1440.72, "text": " I think all over that list, there are two essential elements of dynamic decision making and", "tokens": [50752, 286, 519, 439, 670, 300, 1329, 11, 456, 366, 732, 7115, 4959, 295, 8546, 3537, 1455, 293, 51124], "temperature": 0.0, "avg_logprob": -0.10163693200974237, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0005170598742552102}, {"id": 189, "seek": 142552, "start": 1440.72, "end": 1449.52, "text": " they keep coming over and over. One of them was recognition. So I was convinced that similarity", "tokens": [51124, 436, 1066, 1348, 670, 293, 670, 13, 1485, 295, 552, 390, 11150, 13, 407, 286, 390, 12561, 300, 32194, 51564], "temperature": 0.0, "avg_logprob": -0.10163693200974237, "compression_ratio": 1.5459770114942528, "no_speech_prob": 0.0005170598742552102}, {"id": 190, "seek": 144952, "start": 1449.6, "end": 1457.28, "text": " and our ability to detect similarity is essential for making good decisions and memory.", "tokens": [50368, 293, 527, 3485, 281, 5531, 32194, 307, 7115, 337, 1455, 665, 5327, 293, 4675, 13, 50752], "temperature": 0.0, "avg_logprob": -0.09449658075968424, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.004945761524140835}, {"id": 191, "seek": 144952, "start": 1457.28, "end": 1466.24, "text": " That is our ability to create context specific knowledge. So very different from traditional", "tokens": [50752, 663, 307, 527, 3485, 281, 1884, 4319, 2685, 3601, 13, 407, 588, 819, 490, 5164, 51200], "temperature": 0.0, "avg_logprob": -0.09449658075968424, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.004945761524140835}, {"id": 192, "seek": 144952, "start": 1466.24, "end": 1472.8799999999999, "text": " cognitive theories that believe that humans with experience generate heuristics. I actually", "tokens": [51200, 15605, 13667, 300, 1697, 300, 6255, 365, 1752, 8460, 415, 374, 6006, 13, 286, 767, 51532], "temperature": 0.0, "avg_logprob": -0.09449658075968424, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.004945761524140835}, {"id": 193, "seek": 144952, "start": 1472.8799999999999, "end": 1478.56, "text": " believed it was the other way around that humans use heuristics when they don't have knowledge.", "tokens": [51532, 7847, 309, 390, 264, 661, 636, 926, 300, 6255, 764, 415, 374, 6006, 562, 436, 500, 380, 362, 3601, 13, 51816], "temperature": 0.0, "avg_logprob": -0.09449658075968424, "compression_ratio": 1.665158371040724, "no_speech_prob": 0.004945761524140835}, {"id": 194, "seek": 147856, "start": 1479.28, "end": 1485.76, "text": " And as you acquire more context specific knowledge, you actually depart from those", "tokens": [50400, 400, 382, 291, 20001, 544, 4319, 2685, 3601, 11, 291, 767, 9110, 490, 729, 50724], "temperature": 0.0, "avg_logprob": -0.09456898272037506, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0007951015722937882}, {"id": 195, "seek": 147856, "start": 1485.76, "end": 1492.96, "text": " heuristics that are not good to start with. They are only approximate. And so you move away from", "tokens": [50724, 415, 374, 6006, 300, 366, 406, 665, 281, 722, 365, 13, 814, 366, 787, 30874, 13, 400, 370, 291, 1286, 1314, 490, 51084], "temperature": 0.0, "avg_logprob": -0.09456898272037506, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0007951015722937882}, {"id": 196, "seek": 147856, "start": 1492.96, "end": 1500.96, "text": " those heuristics and you start to apply context specific knowledge. So let me move to the second", "tokens": [51084, 729, 415, 374, 6006, 293, 291, 722, 281, 3079, 4319, 2685, 3601, 13, 407, 718, 385, 1286, 281, 264, 1150, 51484], "temperature": 0.0, "avg_logprob": -0.09456898272037506, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.0007951015722937882}, {"id": 197, "seek": 150096, "start": 1500.96, "end": 1508.8, "text": " question which is how to represent those things computationally. My approach is on cognitive", "tokens": [50364, 1168, 597, 307, 577, 281, 2906, 729, 721, 24903, 379, 13, 1222, 3109, 307, 322, 15605, 50756], "temperature": 0.0, "avg_logprob": -0.13963493178872502, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.0143239451572299}, {"id": 198, "seek": 150096, "start": 1508.8, "end": 1522.24, "text": " architectures and in large part because I was at CMU. And in CMU is the birth part place", "tokens": [50756, 6331, 1303, 293, 294, 2416, 644, 570, 286, 390, 412, 20424, 52, 13, 400, 294, 20424, 52, 307, 264, 3965, 644, 1081, 51428], "temperature": 0.0, "avg_logprob": -0.13963493178872502, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.0143239451572299}, {"id": 199, "seek": 150096, "start": 1522.24, "end": 1530.0, "text": " of cognitive architectures and in many ways of AI too. So in particular, I was inspired by the work", "tokens": [51428, 295, 15605, 6331, 1303, 293, 294, 867, 2098, 295, 7318, 886, 13, 407, 294, 1729, 11, 286, 390, 7547, 538, 264, 589, 51816], "temperature": 0.0, "avg_logprob": -0.13963493178872502, "compression_ratio": 1.5524861878453038, "no_speech_prob": 0.0143239451572299}, {"id": 200, "seek": 153000, "start": 1530.0, "end": 1536.96, "text": " of Allen Newell and Herb Simon that wanted to do had this idea of creating unified theories of", "tokens": [50364, 295, 17160, 1734, 6326, 293, 3204, 65, 13193, 300, 1415, 281, 360, 632, 341, 1558, 295, 4084, 26787, 13667, 295, 50712], "temperature": 0.0, "avg_logprob": -0.15891916521133914, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0016873162239789963}, {"id": 201, "seek": 153000, "start": 1536.96, "end": 1547.76, "text": " cognition. They imagine or envision this complete program that would be capable of making all the", "tokens": [50712, 46905, 13, 814, 3811, 420, 24739, 341, 3566, 1461, 300, 576, 312, 8189, 295, 1455, 439, 264, 51252], "temperature": 0.0, "avg_logprob": -0.15891916521133914, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0016873162239789963}, {"id": 202, "seek": 153000, "start": 1549.04, "end": 1556.88, "text": " activities that human mind was able to make. So they imagine to represent all these cognitive", "tokens": [51316, 5354, 300, 1952, 1575, 390, 1075, 281, 652, 13, 407, 436, 3811, 281, 2906, 439, 613, 15605, 51708], "temperature": 0.0, "avg_logprob": -0.15891916521133914, "compression_ratio": 1.5376344086021505, "no_speech_prob": 0.0016873162239789963}, {"id": 203, "seek": 155688, "start": 1556.96, "end": 1565.1200000000001, "text": " steps and be able to explain all the components of the mind and how they work and produce cognition", "tokens": [50368, 4439, 293, 312, 1075, 281, 2903, 439, 264, 6677, 295, 264, 1575, 293, 577, 436, 589, 293, 5258, 46905, 50776], "temperature": 0.0, "avg_logprob": -0.08478044718503952, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.001671503996476531}, {"id": 204, "seek": 155688, "start": 1565.1200000000001, "end": 1574.4, "text": " together. Many books that are very inspiring coming from this tradition. My personal view of this", "tokens": [50776, 1214, 13, 5126, 3642, 300, 366, 588, 15883, 1348, 490, 341, 6994, 13, 1222, 2973, 1910, 295, 341, 51240], "temperature": 0.0, "avg_logprob": -0.08478044718503952, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.001671503996476531}, {"id": 205, "seek": 155688, "start": 1574.4, "end": 1582.5600000000002, "text": " is that it is very utopic. It is an extremely complex problem and therefore is very hard", "tokens": [51240, 307, 300, 309, 307, 588, 2839, 40216, 13, 467, 307, 364, 4664, 3997, 1154, 293, 4412, 307, 588, 1152, 51648], "temperature": 0.0, "avg_logprob": -0.08478044718503952, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.001671503996476531}, {"id": 206, "seek": 158256, "start": 1582.56, "end": 1591.36, "text": " to accomplish. So it was accomplished partly by the actor unified theory of cognition.", "tokens": [50364, 281, 9021, 13, 407, 309, 390, 15419, 17031, 538, 264, 8747, 26787, 5261, 295, 46905, 13, 50804], "temperature": 0.0, "avg_logprob": -0.24074280261993408, "compression_ratio": 1.4864864864864864, "no_speech_prob": 0.001153398654423654}, {"id": 207, "seek": 158256, "start": 1592.1599999999999, "end": 1598.8, "text": " So John Anderson at Carnegie Mellon and Christian LeVier, one of John Anderson's students and then", "tokens": [50844, 407, 2619, 18768, 412, 47301, 376, 898, 266, 293, 5778, 1456, 53, 811, 11, 472, 295, 2619, 18768, 311, 1731, 293, 550, 51176], "temperature": 0.0, "avg_logprob": -0.24074280261993408, "compression_ratio": 1.4864864864864864, "no_speech_prob": 0.001153398654423654}, {"id": 208, "seek": 158256, "start": 1598.8, "end": 1606.72, "text": " postdoc and now faculty, research faculty has been working on this idea from Allen Newell", "tokens": [51176, 2183, 39966, 293, 586, 6389, 11, 2132, 6389, 575, 668, 1364, 322, 341, 1558, 490, 17160, 1734, 6326, 51572], "temperature": 0.0, "avg_logprob": -0.24074280261993408, "compression_ratio": 1.4864864864864864, "no_speech_prob": 0.001153398654423654}, {"id": 209, "seek": 160672, "start": 1606.72, "end": 1615.44, "text": " and Herb Simon. And if you look at the history of actor, you are going to see that it has", "tokens": [50364, 293, 3204, 65, 13193, 13, 400, 498, 291, 574, 412, 264, 2503, 295, 8747, 11, 291, 366, 516, 281, 536, 300, 309, 575, 50800], "temperature": 0.0, "avg_logprob": -0.1282540730067662, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0010103585664182901}, {"id": 210, "seek": 160672, "start": 1615.44, "end": 1623.1200000000001, "text": " just become more complex with over the years. And in my personal opinion, also less useful.", "tokens": [50800, 445, 1813, 544, 3997, 365, 670, 264, 924, 13, 400, 294, 452, 2973, 4800, 11, 611, 1570, 4420, 13, 51184], "temperature": 0.0, "avg_logprob": -0.1282540730067662, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0010103585664182901}, {"id": 211, "seek": 160672, "start": 1624.64, "end": 1633.84, "text": " So what I did was to grab what I felt was useful from that cognitive architecture. And this is", "tokens": [51260, 407, 437, 286, 630, 390, 281, 4444, 437, 286, 2762, 390, 4420, 490, 300, 15605, 9482, 13, 400, 341, 307, 51720], "temperature": 0.0, "avg_logprob": -0.1282540730067662, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0010103585664182901}, {"id": 212, "seek": 163384, "start": 1633.84, "end": 1640.08, "text": " essentially the way knowledge is represented in declarative and procedural forms that is with", "tokens": [50364, 4476, 264, 636, 3601, 307, 10379, 294, 16694, 1166, 293, 43951, 6422, 300, 307, 365, 50676], "temperature": 0.0, "avg_logprob": -0.10757357175232934, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0033395730424672365}, {"id": 213, "seek": 163384, "start": 1640.08, "end": 1649.52, "text": " facts or with rules and in symbolic or sub symbolic ways. That is with formulas that would", "tokens": [50676, 9130, 420, 365, 4474, 293, 294, 25755, 420, 1422, 25755, 2098, 13, 663, 307, 365, 30546, 300, 576, 51148], "temperature": 0.0, "avg_logprob": -0.10757357175232934, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0033395730424672365}, {"id": 214, "seek": 163384, "start": 1649.52, "end": 1658.56, "text": " explain how those facts or rules are going to evolve and change over time. So that's what I", "tokens": [51148, 2903, 577, 729, 9130, 420, 4474, 366, 516, 281, 16693, 293, 1319, 670, 565, 13, 407, 300, 311, 437, 286, 51600], "temperature": 0.0, "avg_logprob": -0.10757357175232934, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0033395730424672365}, {"id": 215, "seek": 165856, "start": 1658.56, "end": 1666.08, "text": " did and basically I took that to develop my own mini architecture, if you will. So this", "tokens": [50364, 630, 293, 1936, 286, 1890, 300, 281, 1499, 452, 1065, 8382, 9482, 11, 498, 291, 486, 13, 407, 341, 50740], "temperature": 0.0, "avg_logprob": -0.1145355385470103, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.002825547708198428}, {"id": 216, "seek": 165856, "start": 1666.8799999999999, "end": 1673.44, "text": " theory called instance-based learning theory is essentially a dynamic decision making process", "tokens": [50780, 5261, 1219, 5197, 12, 6032, 2539, 5261, 307, 4476, 257, 8546, 3537, 1455, 1399, 51108], "temperature": 0.0, "avg_logprob": -0.1145355385470103, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.002825547708198428}, {"id": 217, "seek": 165856, "start": 1673.44, "end": 1680.72, "text": " that is represented in a learning loop. So I'm going to go over this process and this is sort of", "tokens": [51108, 300, 307, 10379, 294, 257, 2539, 6367, 13, 407, 286, 478, 516, 281, 352, 670, 341, 1399, 293, 341, 307, 1333, 295, 51472], "temperature": 0.0, "avg_logprob": -0.1145355385470103, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.002825547708198428}, {"id": 218, "seek": 165856, "start": 1680.72, "end": 1687.84, "text": " the corresponding picture of RPM, the recognition prime, but my own and there are also many", "tokens": [51472, 264, 11760, 3036, 295, 37389, 11, 264, 11150, 5835, 11, 457, 452, 1065, 293, 456, 366, 611, 867, 51828], "temperature": 0.0, "avg_logprob": -0.1145355385470103, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.002825547708198428}, {"id": 219, "seek": 168784, "start": 1687.84, "end": 1696.0, "text": " differences obviously. So the first step is again decisions are made by recognizing the", "tokens": [50364, 7300, 2745, 13, 407, 264, 700, 1823, 307, 797, 5327, 366, 1027, 538, 18538, 264, 50772], "temperature": 0.0, "avg_logprob": -0.09060638745625814, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0009770276956260204}, {"id": 220, "seek": 168784, "start": 1696.0, "end": 1704.6399999999999, "text": " similar situations and mapping with decisions that have been made in the past to be able to retrieve", "tokens": [50772, 2531, 6851, 293, 18350, 365, 5327, 300, 362, 668, 1027, 294, 264, 1791, 281, 312, 1075, 281, 30254, 51204], "temperature": 0.0, "avg_logprob": -0.09060638745625814, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0009770276956260204}, {"id": 221, "seek": 168784, "start": 1704.6399999999999, "end": 1711.84, "text": " something that worked in the past. And that happens in this recognition process. We evaluate the new", "tokens": [51204, 746, 300, 2732, 294, 264, 1791, 13, 400, 300, 2314, 294, 341, 11150, 1399, 13, 492, 13059, 264, 777, 51564], "temperature": 0.0, "avg_logprob": -0.09060638745625814, "compression_ratio": 1.6055555555555556, "no_speech_prob": 0.0009770276956260204}, {"id": 222, "seek": 171184, "start": 1711.84, "end": 1719.1999999999998, "text": " actions according to the utility of the past decisions which are retrieved from memory.", "tokens": [50364, 5909, 4650, 281, 264, 14877, 295, 264, 1791, 5327, 597, 366, 19817, 937, 490, 4675, 13, 50732], "temperature": 0.0, "avg_logprob": -0.08105337821831138, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.004024818539619446}, {"id": 223, "seek": 171184, "start": 1720.1599999999999, "end": 1729.04, "text": " And then we explore mentally all the possible alternatives. As you can see this is very similar", "tokens": [50780, 400, 550, 321, 6839, 17072, 439, 264, 1944, 20478, 13, 1018, 291, 393, 536, 341, 307, 588, 2531, 51224], "temperature": 0.0, "avg_logprob": -0.08105337821831138, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.004024818539619446}, {"id": 224, "seek": 171184, "start": 1729.04, "end": 1736.72, "text": " to the mental simulation that Gary Klein was talking about. And then finally we make execute", "tokens": [51224, 281, 264, 4973, 16575, 300, 13788, 33327, 390, 1417, 466, 13, 400, 550, 2721, 321, 652, 14483, 51608], "temperature": 0.0, "avg_logprob": -0.08105337821831138, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.004024818539619446}, {"id": 225, "seek": 173672, "start": 1737.44, "end": 1746.4, "text": " decision that is the highest up to that point and that execution is going to modify the environment.", "tokens": [50400, 3537, 300, 307, 264, 6343, 493, 281, 300, 935, 293, 300, 15058, 307, 516, 281, 16927, 264, 2823, 13, 50848], "temperature": 0.0, "avg_logprob": -0.07928358224722055, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.0012781989062204957}, {"id": 226, "seek": 173672, "start": 1746.4, "end": 1754.16, "text": " And finally whenever we get feedback we can reevaluate the utility of those decisions we", "tokens": [50848, 400, 2721, 5699, 321, 483, 5824, 321, 393, 43060, 3337, 10107, 264, 14877, 295, 729, 5327, 321, 51236], "temperature": 0.0, "avg_logprob": -0.07928358224722055, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.0012781989062204957}, {"id": 227, "seek": 173672, "start": 1754.16, "end": 1761.76, "text": " have made in the past. So that's conceptually what the theory, the learning loop is about.", "tokens": [51236, 362, 1027, 294, 264, 1791, 13, 407, 300, 311, 3410, 671, 437, 264, 5261, 11, 264, 2539, 6367, 307, 466, 13, 51616], "temperature": 0.0, "avg_logprob": -0.07928358224722055, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.0012781989062204957}, {"id": 228, "seek": 176176, "start": 1762.48, "end": 1772.08, "text": " Now let me tell you about the representations. So the idea is that decisions are stored over time", "tokens": [50400, 823, 718, 385, 980, 291, 466, 264, 33358, 13, 407, 264, 1558, 307, 300, 5327, 366, 12187, 670, 565, 50880], "temperature": 0.0, "avg_logprob": -0.07539385364901635, "compression_ratio": 1.7134146341463414, "no_speech_prob": 0.0022730822674930096}, {"id": 229, "seek": 176176, "start": 1772.08, "end": 1779.84, "text": " in memory in the form of instances and those instances are triplets. Those triplets are the", "tokens": [50880, 294, 4675, 294, 264, 1254, 295, 14519, 293, 729, 14519, 366, 1376, 31023, 13, 3950, 1376, 31023, 366, 264, 51268], "temperature": 0.0, "avg_logprob": -0.07539385364901635, "compression_ratio": 1.7134146341463414, "no_speech_prob": 0.0022730822674930096}, {"id": 230, "seek": 176176, "start": 1779.84, "end": 1788.64, "text": " associations of the features that are necessary for that decision, the action that is taken", "tokens": [51268, 26597, 295, 264, 4122, 300, 366, 4818, 337, 300, 3537, 11, 264, 3069, 300, 307, 2726, 51708], "temperature": 0.0, "avg_logprob": -0.07539385364901635, "compression_ratio": 1.7134146341463414, "no_speech_prob": 0.0022730822674930096}, {"id": 231, "seek": 178864, "start": 1789.2800000000002, "end": 1797.1200000000001, "text": " and the outcome. The outcome can be the observed or the expected utility that is calculated", "tokens": [50396, 293, 264, 9700, 13, 440, 9700, 393, 312, 264, 13095, 420, 264, 5176, 14877, 300, 307, 15598, 50788], "temperature": 0.0, "avg_logprob": -0.07566187745433743, "compression_ratio": 1.6319018404907975, "no_speech_prob": 0.0020276913419365883}, {"id": 232, "seek": 178864, "start": 1797.1200000000001, "end": 1804.88, "text": " about making that decision. Now for each potential action, action one or action two,", "tokens": [50788, 466, 1455, 300, 3537, 13, 823, 337, 1184, 3995, 3069, 11, 3069, 472, 420, 3069, 732, 11, 51176], "temperature": 0.0, "avg_logprob": -0.07566187745433743, "compression_ratio": 1.6319018404907975, "no_speech_prob": 0.0020276913419365883}, {"id": 233, "seek": 178864, "start": 1805.44, "end": 1812.5600000000002, "text": " instances when you try to make a new decision, instances will be blended according to the", "tokens": [51204, 14519, 562, 291, 853, 281, 652, 257, 777, 3537, 11, 14519, 486, 312, 27048, 4650, 281, 264, 51560], "temperature": 0.0, "avg_logprob": -0.07566187745433743, "compression_ratio": 1.6319018404907975, "no_speech_prob": 0.0020276913419365883}, {"id": 234, "seek": 181256, "start": 1812.6399999999999, "end": 1823.6, "text": " similarity of the features. And then the action that has the maximum blended value,", "tokens": [50368, 32194, 295, 264, 4122, 13, 400, 550, 264, 3069, 300, 575, 264, 6674, 27048, 2158, 11, 50916], "temperature": 0.0, "avg_logprob": -0.12551619112491608, "compression_ratio": 1.6975308641975309, "no_speech_prob": 0.003610772080719471}, {"id": 235, "seek": 181256, "start": 1823.6, "end": 1832.56, "text": " in this case let's assume it's action two, is chosen. At that moment a new instance is created", "tokens": [50916, 294, 341, 1389, 718, 311, 6552, 309, 311, 3069, 732, 11, 307, 8614, 13, 1711, 300, 1623, 257, 777, 5197, 307, 2942, 51364], "temperature": 0.0, "avg_logprob": -0.12551619112491608, "compression_ratio": 1.6975308641975309, "no_speech_prob": 0.003610772080719471}, {"id": 236, "seek": 181256, "start": 1832.56, "end": 1841.28, "text": " with the blended value. And then when feedback is received that blended value is changed for the", "tokens": [51364, 365, 264, 27048, 2158, 13, 400, 550, 562, 5824, 307, 4613, 300, 27048, 2158, 307, 3105, 337, 264, 51800], "temperature": 0.0, "avg_logprob": -0.12551619112491608, "compression_ratio": 1.6975308641975309, "no_speech_prob": 0.003610772080719471}, {"id": 237, "seek": 184128, "start": 1841.28, "end": 1848.0, "text": " actual feedback outcome that was received. So that's the algorithm in the in the", "tokens": [50364, 3539, 5824, 9700, 300, 390, 4613, 13, 407, 300, 311, 264, 9284, 294, 264, 294, 264, 50700], "temperature": 0.0, "avg_logprob": -0.14198565873943392, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0010908551048487425}, {"id": 238, "seek": 184128, "start": 1848.0, "end": 1855.92, "text": " representational form. And this is the algorithm in the mathematical form. So the most important", "tokens": [50700, 2906, 1478, 1254, 13, 400, 341, 307, 264, 9284, 294, 264, 18894, 1254, 13, 407, 264, 881, 1021, 51096], "temperature": 0.0, "avg_logprob": -0.14198565873943392, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0010908551048487425}, {"id": 239, "seek": 184128, "start": 1855.92, "end": 1864.48, "text": " equation I think in this algorithm is the activation, which is not developed by me at all,", "tokens": [51096, 5367, 286, 519, 294, 341, 9284, 307, 264, 24433, 11, 597, 307, 406, 4743, 538, 385, 412, 439, 11, 51524], "temperature": 0.0, "avg_logprob": -0.14198565873943392, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.0010908551048487425}, {"id": 240, "seek": 186448, "start": 1864.48, "end": 1874.08, "text": " is borrowed from ACTAAR. So ACTAAR has backed up evidence for each part of this equation", "tokens": [50364, 307, 26805, 490, 8157, 8241, 1899, 13, 407, 8157, 8241, 1899, 575, 20391, 493, 4467, 337, 1184, 644, 295, 341, 5367, 50844], "temperature": 0.0, "avg_logprob": -0.09582193314083039, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0050794766284525394}, {"id": 241, "seek": 186448, "start": 1874.08, "end": 1882.08, "text": " with a lot of experiments regarding how humans process information. So this activation equation", "tokens": [50844, 365, 257, 688, 295, 12050, 8595, 577, 6255, 1399, 1589, 13, 407, 341, 24433, 5367, 51244], "temperature": 0.0, "avg_logprob": -0.09582193314083039, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0050794766284525394}, {"id": 242, "seek": 186448, "start": 1882.08, "end": 1888.72, "text": " has three parts. This part is called the base level equation. This part is the partial matching", "tokens": [51244, 575, 1045, 3166, 13, 639, 644, 307, 1219, 264, 3096, 1496, 5367, 13, 639, 644, 307, 264, 14641, 14324, 51576], "temperature": 0.0, "avg_logprob": -0.09582193314083039, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0050794766284525394}, {"id": 243, "seek": 188872, "start": 1889.6000000000001, "end": 1898.0, "text": " idea and this part is noise. And essentially this equation takes into account the frequency", "tokens": [50408, 1558, 293, 341, 644, 307, 5658, 13, 400, 4476, 341, 5367, 2516, 666, 2696, 264, 7893, 50828], "temperature": 0.0, "avg_logprob": -0.08567464957802982, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.002236082684248686}, {"id": 244, "seek": 188872, "start": 1898.0, "end": 1906.0, "text": " of events. So we tend to believe that something is going to happen more often and actually to", "tokens": [50828, 295, 3931, 13, 407, 321, 3928, 281, 1697, 300, 746, 307, 516, 281, 1051, 544, 2049, 293, 767, 281, 51228], "temperature": 0.0, "avg_logprob": -0.08567464957802982, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.002236082684248686}, {"id": 245, "seek": 188872, "start": 1906.0, "end": 1914.96, "text": " retrieve more that information faster when it happens more often. So frequency of events matters", "tokens": [51228, 30254, 544, 300, 1589, 4663, 562, 309, 2314, 544, 2049, 13, 407, 7893, 295, 3931, 7001, 51676], "temperature": 0.0, "avg_logprob": -0.08567464957802982, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.002236082684248686}, {"id": 246, "seek": 191496, "start": 1914.96, "end": 1921.3600000000001, "text": " a lot for our ability to retrieve information from memory. And so that is represented here.", "tokens": [50364, 257, 688, 337, 527, 3485, 281, 30254, 1589, 490, 4675, 13, 400, 370, 300, 307, 10379, 510, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10070823487781343, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0012186900712549686}, {"id": 247, "seek": 191496, "start": 1922.24, "end": 1928.88, "text": " We also tend to forget. So things that happened yesterday I can remember faster than things that", "tokens": [50728, 492, 611, 3928, 281, 2870, 13, 407, 721, 300, 2011, 5186, 286, 393, 1604, 4663, 813, 721, 300, 51060], "temperature": 0.0, "avg_logprob": -0.10070823487781343, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0012186900712549686}, {"id": 248, "seek": 191496, "start": 1928.88, "end": 1938.32, "text": " happened many years ago. And that is represented by this nonlinear decay function. And then this", "tokens": [51060, 2011, 867, 924, 2057, 13, 400, 300, 307, 10379, 538, 341, 2107, 28263, 21039, 2445, 13, 400, 550, 341, 51532], "temperature": 0.0, "avg_logprob": -0.10070823487781343, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0012186900712549686}, {"id": 249, "seek": 193832, "start": 1938.3999999999999, "end": 1945.28, "text": " part here represents the partial matching equation for each feature in the instance. We can", "tokens": [50368, 644, 510, 8855, 264, 14641, 14324, 5367, 337, 1184, 4111, 294, 264, 5197, 13, 492, 393, 50712], "temperature": 0.0, "avg_logprob": -0.10592968422069884, "compression_ratio": 1.5706214689265536, "no_speech_prob": 0.0027353200130164623}, {"id": 250, "seek": 193832, "start": 1945.9199999999998, "end": 1954.8, "text": " determine a particular similarity function, which is then aggregated across all the features", "tokens": [50744, 6997, 257, 1729, 32194, 2445, 11, 597, 307, 550, 16743, 770, 2108, 439, 264, 4122, 51188], "temperature": 0.0, "avg_logprob": -0.10592968422069884, "compression_ratio": 1.5706214689265536, "no_speech_prob": 0.0027353200130164623}, {"id": 251, "seek": 193832, "start": 1954.8, "end": 1965.28, "text": " and then sort of penalized or exacerbated with a partial matching parameter. And then finally", "tokens": [51188, 293, 550, 1333, 295, 13661, 1602, 420, 38819, 770, 365, 257, 14641, 14324, 13075, 13, 400, 550, 2721, 51712], "temperature": 0.0, "avg_logprob": -0.10592968422069884, "compression_ratio": 1.5706214689265536, "no_speech_prob": 0.0027353200130164623}, {"id": 252, "seek": 196528, "start": 1965.28, "end": 1970.48, "text": " the noise, which this is just noise. Right now there is not a lot of theory about", "tokens": [50364, 264, 5658, 11, 597, 341, 307, 445, 5658, 13, 1779, 586, 456, 307, 406, 257, 688, 295, 5261, 466, 50624], "temperature": 0.0, "avg_logprob": -0.12045028805732727, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.0022025424987077713}, {"id": 253, "seek": 196528, "start": 1971.44, "end": 1979.28, "text": " what doesn't fit in this part. This part here is a draw from a random distribution or", "tokens": [50672, 437, 1177, 380, 3318, 294, 341, 644, 13, 639, 644, 510, 307, 257, 2642, 490, 257, 4974, 7316, 420, 51064], "temperature": 0.0, "avg_logprob": -0.12045028805732727, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.0022025424987077713}, {"id": 254, "seek": 196528, "start": 1979.84, "end": 1988.8799999999999, "text": " other type of distributions. And this one is one of the parameters. So for each instance", "tokens": [51092, 661, 2010, 295, 37870, 13, 400, 341, 472, 307, 472, 295, 264, 9834, 13, 407, 337, 1184, 5197, 51544], "temperature": 0.0, "avg_logprob": -0.12045028805732727, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.0022025424987077713}, {"id": 255, "seek": 198888, "start": 1988.96, "end": 1999.68, "text": " you calculate the activation at each point of time. And then you can calculate the probability", "tokens": [50368, 291, 8873, 264, 24433, 412, 1184, 935, 295, 565, 13, 400, 550, 291, 393, 8873, 264, 8482, 50904], "temperature": 0.0, "avg_logprob": -0.10232886672019958, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.0018162551568821073}, {"id": 256, "seek": 198888, "start": 1999.68, "end": 2007.44, "text": " of retrieving that instance from memory, which is essentially the activation relative to the", "tokens": [50904, 295, 19817, 798, 300, 5197, 490, 4675, 11, 597, 307, 4476, 264, 24433, 4972, 281, 264, 51292], "temperature": 0.0, "avg_logprob": -0.10232886672019958, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.0018162551568821073}, {"id": 257, "seek": 198888, "start": 2007.44, "end": 2016.88, "text": " activation of all the instances in memory. And then this is the magic I guess of IVLT. What we", "tokens": [51292, 24433, 295, 439, 264, 14519, 294, 4675, 13, 400, 550, 341, 307, 264, 5585, 286, 2041, 295, 15967, 43, 51, 13, 708, 321, 51764], "temperature": 0.0, "avg_logprob": -0.10232886672019958, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.0018162551568821073}, {"id": 258, "seek": 201688, "start": 2016.88, "end": 2024.3200000000002, "text": " do is essentially combine all those instances that belong to a particular choice option", "tokens": [50364, 360, 307, 4476, 10432, 439, 729, 14519, 300, 5784, 281, 257, 1729, 3922, 3614, 50736], "temperature": 0.0, "avg_logprob": -0.09461714770342852, "compression_ratio": 1.68, "no_speech_prob": 0.002847567666321993}, {"id": 259, "seek": 201688, "start": 2025.2, "end": 2031.2, "text": " in the form of an expected value. So this is the probability times the outcome.", "tokens": [50780, 294, 264, 1254, 295, 364, 5176, 2158, 13, 407, 341, 307, 264, 8482, 1413, 264, 9700, 13, 51080], "temperature": 0.0, "avg_logprob": -0.09461714770342852, "compression_ratio": 1.68, "no_speech_prob": 0.002847567666321993}, {"id": 260, "seek": 201688, "start": 2032.5600000000002, "end": 2038.96, "text": " But obviously this probability is a cognitive probability. It's not the actual probability", "tokens": [51148, 583, 2745, 341, 8482, 307, 257, 15605, 8482, 13, 467, 311, 406, 264, 3539, 8482, 51468], "temperature": 0.0, "avg_logprob": -0.09461714770342852, "compression_ratio": 1.68, "no_speech_prob": 0.002847567666321993}, {"id": 261, "seek": 201688, "start": 2038.96, "end": 2043.7600000000002, "text": " of an event. And it's a probability that is calculated all the way from here.", "tokens": [51468, 295, 364, 2280, 13, 400, 309, 311, 257, 8482, 300, 307, 15598, 439, 264, 636, 490, 510, 13, 51708], "temperature": 0.0, "avg_logprob": -0.09461714770342852, "compression_ratio": 1.68, "no_speech_prob": 0.002847567666321993}, {"id": 262, "seek": 204376, "start": 2044.16, "end": 2052.16, "text": " Right. So in this way we are accounting for the cognition of how do we forget information,", "tokens": [50384, 1779, 13, 407, 294, 341, 636, 321, 366, 19163, 337, 264, 46905, 295, 577, 360, 321, 2870, 1589, 11, 50784], "temperature": 0.0, "avg_logprob": -0.14244814061406832, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.000395435985410586}, {"id": 263, "seek": 204376, "start": 2052.16, "end": 2059.68, "text": " how similar the information is, etc. Okay. And we create this expected utility value that we", "tokens": [50784, 577, 2531, 264, 1589, 307, 11, 5183, 13, 1033, 13, 400, 321, 1884, 341, 5176, 14877, 2158, 300, 321, 51160], "temperature": 0.0, "avg_logprob": -0.14244814061406832, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.000395435985410586}, {"id": 264, "seek": 204376, "start": 2059.68, "end": 2066.48, "text": " call blending. And then we select the option that has the maximum expected value. So that's it.", "tokens": [51160, 818, 23124, 13, 400, 550, 321, 3048, 264, 3614, 300, 575, 264, 6674, 5176, 2158, 13, 407, 300, 311, 309, 13, 51500], "temperature": 0.0, "avg_logprob": -0.14244814061406832, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.000395435985410586}, {"id": 265, "seek": 206648, "start": 2067.28, "end": 2077.76, "text": " Now I have been interested as I said before in figuring out how general this theory is", "tokens": [50404, 823, 286, 362, 668, 3102, 382, 286, 848, 949, 294, 15213, 484, 577, 2674, 341, 5261, 307, 50928], "temperature": 0.0, "avg_logprob": -0.19072680473327636, "compression_ratio": 1.3233082706766917, "no_speech_prob": 0.00203228578902781}, {"id": 266, "seek": 206648, "start": 2078.56, "end": 2087.84, "text": " across many decision-making situations. And how human-like this algorithm is by comparing", "tokens": [50968, 2108, 867, 3537, 12, 12402, 6851, 13, 400, 577, 1952, 12, 4092, 341, 9284, 307, 538, 15763, 51432], "temperature": 0.0, "avg_logprob": -0.19072680473327636, "compression_ratio": 1.3233082706766917, "no_speech_prob": 0.00203228578902781}, {"id": 267, "seek": 208784, "start": 2088.8, "end": 2098.88, "text": " the predictions from an IVL model to the results from an experiment in a particular task.", "tokens": [50412, 264, 21264, 490, 364, 15967, 43, 2316, 281, 264, 3542, 490, 364, 5120, 294, 257, 1729, 5633, 13, 50916], "temperature": 0.0, "avg_logprob": -0.08683248776108471, "compression_ratio": 1.5, "no_speech_prob": 0.002571793971583247}, {"id": 268, "seek": 208784, "start": 2100.48, "end": 2107.92, "text": " What I'm going to show you now is a set of examples of human likeness of IVL agents.", "tokens": [50996, 708, 286, 478, 516, 281, 855, 291, 586, 307, 257, 992, 295, 5110, 295, 1952, 36946, 442, 295, 15967, 43, 12554, 13, 51368], "temperature": 0.0, "avg_logprob": -0.08683248776108471, "compression_ratio": 1.5, "no_speech_prob": 0.002571793971583247}, {"id": 269, "seek": 208784, "start": 2109.36, "end": 2116.8, "text": " And it is important to know that all these examples that I selected here do not fit data.", "tokens": [51440, 400, 309, 307, 1021, 281, 458, 300, 439, 613, 5110, 300, 286, 8209, 510, 360, 406, 3318, 1412, 13, 51812], "temperature": 0.0, "avg_logprob": -0.08683248776108471, "compression_ratio": 1.5, "no_speech_prob": 0.002571793971583247}, {"id": 270, "seek": 211680, "start": 2116.88, "end": 2122.96, "text": " That is in none of these examples, I first collect the data and then I fit the model to the data and", "tokens": [50368, 663, 307, 294, 6022, 295, 613, 5110, 11, 286, 700, 2500, 264, 1412, 293, 550, 286, 3318, 264, 2316, 281, 264, 1412, 293, 50672], "temperature": 0.0, "avg_logprob": -0.10105479847301137, "compression_ratio": 1.8104265402843602, "no_speech_prob": 0.0008787534316070378}, {"id": 271, "seek": 211680, "start": 2122.96, "end": 2130.48, "text": " then I present the results. Anybody can fit data. All these examples come from the theory.", "tokens": [50672, 550, 286, 1974, 264, 3542, 13, 19082, 393, 3318, 1412, 13, 1057, 613, 5110, 808, 490, 264, 5261, 13, 51048], "temperature": 0.0, "avg_logprob": -0.10105479847301137, "compression_ratio": 1.8104265402843602, "no_speech_prob": 0.0008787534316070378}, {"id": 272, "seek": 211680, "start": 2130.48, "end": 2138.0800000000004, "text": " So we do simulations with our theory and then we look at the data and we see how close we are", "tokens": [51048, 407, 321, 360, 35138, 365, 527, 5261, 293, 550, 321, 574, 412, 264, 1412, 293, 321, 536, 577, 1998, 321, 366, 51428], "temperature": 0.0, "avg_logprob": -0.10105479847301137, "compression_ratio": 1.8104265402843602, "no_speech_prob": 0.0008787534316070378}, {"id": 273, "seek": 211680, "start": 2138.0800000000004, "end": 2144.88, "text": " to the data. Okay. But we don't fit data. That being said, doesn't mean that we cannot fit data.", "tokens": [51428, 281, 264, 1412, 13, 1033, 13, 583, 321, 500, 380, 3318, 1412, 13, 663, 885, 848, 11, 1177, 380, 914, 300, 321, 2644, 3318, 1412, 13, 51768], "temperature": 0.0, "avg_logprob": -0.10105479847301137, "compression_ratio": 1.8104265402843602, "no_speech_prob": 0.0008787534316070378}, {"id": 274, "seek": 214488, "start": 2144.88, "end": 2150.7200000000003, "text": " We of course can fit data. And that is only going to make things better, right? So we can", "tokens": [50364, 492, 295, 1164, 393, 3318, 1412, 13, 400, 300, 307, 787, 516, 281, 652, 721, 1101, 11, 558, 30, 407, 321, 393, 50656], "temperature": 0.0, "avg_logprob": -0.10321762206706595, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.0004565212002489716}, {"id": 275, "seek": 214488, "start": 2150.7200000000003, "end": 2156.8, "text": " fit data and we can fit data at the global level, at the individual level, whatever level you want.", "tokens": [50656, 3318, 1412, 293, 321, 393, 3318, 1412, 412, 264, 4338, 1496, 11, 412, 264, 2609, 1496, 11, 2035, 1496, 291, 528, 13, 50960], "temperature": 0.0, "avg_logprob": -0.10321762206706595, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.0004565212002489716}, {"id": 276, "seek": 214488, "start": 2156.8, "end": 2160.56, "text": " We can fit the data, but that's not the point of the examples I'm going to show you.", "tokens": [50960, 492, 393, 3318, 264, 1412, 11, 457, 300, 311, 406, 264, 935, 295, 264, 5110, 286, 478, 516, 281, 855, 291, 13, 51148], "temperature": 0.0, "avg_logprob": -0.10321762206706595, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.0004565212002489716}, {"id": 277, "seek": 214488, "start": 2161.6800000000003, "end": 2168.32, "text": " So because I started with a very complicated task and nobody understood what the guy was doing,", "tokens": [51204, 407, 570, 286, 1409, 365, 257, 588, 6179, 5633, 293, 5079, 7320, 437, 264, 2146, 390, 884, 11, 51536], "temperature": 0.0, "avg_logprob": -0.10321762206706595, "compression_ratio": 1.6972477064220184, "no_speech_prob": 0.0004565212002489716}, {"id": 278, "seek": 216832, "start": 2168.56, "end": 2176.0800000000004, "text": " something happened on the way that made me realize I need to simplify things to make things", "tokens": [50376, 746, 2011, 322, 264, 636, 300, 1027, 385, 4325, 286, 643, 281, 20460, 721, 281, 652, 721, 50752], "temperature": 0.0, "avg_logprob": -0.12488296296861437, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.00702144717797637}, {"id": 279, "seek": 216832, "start": 2176.0800000000004, "end": 2182.88, "text": " understandable. And so I went to the root of decision making, which is binary choice.", "tokens": [50752, 25648, 13, 400, 370, 286, 1437, 281, 264, 5593, 295, 3537, 1455, 11, 597, 307, 17434, 3922, 13, 51092], "temperature": 0.0, "avg_logprob": -0.12488296296861437, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.00702144717797637}, {"id": 280, "seek": 216832, "start": 2184.0, "end": 2189.52, "text": " But in this case, it was not going to be just the decision tree. It was going to be a dynamic", "tokens": [51148, 583, 294, 341, 1389, 11, 309, 390, 406, 516, 281, 312, 445, 264, 3537, 4230, 13, 467, 390, 516, 281, 312, 257, 8546, 51424], "temperature": 0.0, "avg_logprob": -0.12488296296861437, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.00702144717797637}, {"id": 281, "seek": 216832, "start": 2189.52, "end": 2195.2000000000003, "text": " binary choice task. By the way, what I'm going to show since even that there are many examples,", "tokens": [51424, 17434, 3922, 5633, 13, 3146, 264, 636, 11, 437, 286, 478, 516, 281, 855, 1670, 754, 300, 456, 366, 867, 5110, 11, 51708], "temperature": 0.0, "avg_logprob": -0.12488296296861437, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.00702144717797637}, {"id": 282, "seek": 219520, "start": 2195.7599999999998, "end": 2203.3599999999997, "text": " it's just a snippet of the various examples. And if you want to go in more detail in any of them,", "tokens": [50392, 309, 311, 445, 257, 35623, 302, 295, 264, 3683, 5110, 13, 400, 498, 291, 528, 281, 352, 294, 544, 2607, 294, 604, 295, 552, 11, 50772], "temperature": 0.0, "avg_logprob": -0.08046816816233625, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0017433188622817397}, {"id": 283, "seek": 219520, "start": 2203.3599999999997, "end": 2210.7999999999997, "text": " I can, but I wanted to show a good variety of these examples. So the first one is binary choice.", "tokens": [50772, 286, 393, 11, 457, 286, 1415, 281, 855, 257, 665, 5673, 295, 613, 5110, 13, 407, 264, 700, 472, 307, 17434, 3922, 13, 51144], "temperature": 0.0, "avg_logprob": -0.08046816816233625, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0017433188622817397}, {"id": 284, "seek": 219520, "start": 2210.7999999999997, "end": 2216.7999999999997, "text": " And essentially in this case, this is sort of an example of the task. People just have two", "tokens": [51144, 400, 4476, 294, 341, 1389, 11, 341, 307, 1333, 295, 364, 1365, 295, 264, 5633, 13, 3432, 445, 362, 732, 51444], "temperature": 0.0, "avg_logprob": -0.08046816816233625, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0017433188622817397}, {"id": 285, "seek": 219520, "start": 2216.7999999999997, "end": 2224.48, "text": " buttons and they receive an outcome after clicking on a button. And then they go on and on each of", "tokens": [51444, 9905, 293, 436, 4774, 364, 9700, 934, 9697, 322, 257, 2960, 13, 400, 550, 436, 352, 322, 293, 322, 1184, 295, 51828], "temperature": 0.0, "avg_logprob": -0.08046816816233625, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.0017433188622817397}, {"id": 286, "seek": 222448, "start": 2224.48, "end": 2231.92, "text": " these buttons have a particular distribution of outcomes assigned to it. And so the idea is that", "tokens": [50364, 613, 9905, 362, 257, 1729, 7316, 295, 10070, 13279, 281, 309, 13, 400, 370, 264, 1558, 307, 300, 50736], "temperature": 0.0, "avg_logprob": -0.08557226346886676, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0007613908383063972}, {"id": 287, "seek": 222448, "start": 2231.92, "end": 2237.84, "text": " over time, people are going to learn how to obtain more points out of the right button, the bottom", "tokens": [50736, 670, 565, 11, 561, 366, 516, 281, 1466, 577, 281, 12701, 544, 2793, 484, 295, 264, 558, 2960, 11, 264, 2767, 51032], "temperature": 0.0, "avg_logprob": -0.08557226346886676, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0007613908383063972}, {"id": 288, "seek": 222448, "start": 2237.84, "end": 2247.2, "text": " that is the maximum expected value, right, but from experience. So what this figure is, of course,", "tokens": [51032, 300, 307, 264, 6674, 5176, 2158, 11, 558, 11, 457, 490, 1752, 13, 407, 437, 341, 2573, 307, 11, 295, 1164, 11, 51500], "temperature": 0.0, "avg_logprob": -0.08557226346886676, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0007613908383063972}, {"id": 289, "seek": 224720, "start": 2247.2, "end": 2255.52, "text": " not readable, but the idea is to demonstrate how each of these squares are different problems", "tokens": [50364, 406, 49857, 11, 457, 264, 1558, 307, 281, 11698, 577, 1184, 295, 613, 19368, 366, 819, 2740, 50780], "temperature": 0.0, "avg_logprob": -0.10017659515142441, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009188731200993061}, {"id": 290, "seek": 224720, "start": 2255.52, "end": 2263.7599999999998, "text": " with different distributions in the two buttons. And it shows the proportion of maximization", "tokens": [50780, 365, 819, 37870, 294, 264, 732, 9905, 13, 400, 309, 3110, 264, 16068, 295, 5138, 2144, 51192], "temperature": 0.0, "avg_logprob": -0.10017659515142441, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009188731200993061}, {"id": 291, "seek": 224720, "start": 2264.48, "end": 2272.7999999999997, "text": " is a Y axis. And it shows two lines in each of these things. The dotted line is the observed.", "tokens": [51228, 307, 257, 398, 10298, 13, 400, 309, 3110, 732, 3876, 294, 1184, 295, 613, 721, 13, 440, 37459, 1622, 307, 264, 13095, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10017659515142441, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.009188731200993061}, {"id": 292, "seek": 227280, "start": 2273.76, "end": 2280.5600000000004, "text": " Actually, it's not the maximization, it's the risky rate. So the proportion of times you choose a", "tokens": [50412, 5135, 11, 309, 311, 406, 264, 5138, 2144, 11, 309, 311, 264, 21137, 3314, 13, 407, 264, 16068, 295, 1413, 291, 2826, 257, 50752], "temperature": 0.0, "avg_logprob": -0.13870290207536254, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.00042185813072137535}, {"id": 293, "seek": 227280, "start": 2280.5600000000004, "end": 2290.0800000000004, "text": " risky option. So the dotted line is the human data observed in an experiment. And the black line is", "tokens": [50752, 21137, 3614, 13, 407, 264, 37459, 1622, 307, 264, 1952, 1412, 13095, 294, 364, 5120, 13, 400, 264, 2211, 1622, 307, 51228], "temperature": 0.0, "avg_logprob": -0.13870290207536254, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.00042185813072137535}, {"id": 294, "seek": 227280, "start": 2290.0800000000004, "end": 2297.6800000000003, "text": " ideal predictions. And so the idea of this figure is just to show that in a large variety of problems", "tokens": [51228, 7157, 21264, 13, 400, 370, 264, 1558, 295, 341, 2573, 307, 445, 281, 855, 300, 294, 257, 2416, 5673, 295, 2740, 51608], "temperature": 0.0, "avg_logprob": -0.13870290207536254, "compression_ratio": 1.5989304812834224, "no_speech_prob": 0.00042185813072137535}, {"id": 295, "seek": 229768, "start": 2297.68, "end": 2308.3199999999997, "text": " of these tasks, the model just from simulation is able to predict the learning process that humans", "tokens": [50364, 295, 613, 9608, 11, 264, 2316, 445, 490, 16575, 307, 1075, 281, 6069, 264, 2539, 1399, 300, 6255, 50896], "temperature": 0.0, "avg_logprob": -0.11513690061347429, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.0006034269463270903}, {"id": 296, "seek": 229768, "start": 2308.96, "end": 2320.96, "text": " follow in this particular task. So the next sort of complication in this journey was to actually", "tokens": [50928, 1524, 294, 341, 1729, 5633, 13, 407, 264, 958, 1333, 295, 1209, 8758, 294, 341, 4671, 390, 281, 767, 51528], "temperature": 0.0, "avg_logprob": -0.11513690061347429, "compression_ratio": 1.4233576642335766, "no_speech_prob": 0.0006034269463270903}, {"id": 297, "seek": 232096, "start": 2320.96, "end": 2331.12, "text": " demonstrate that if the probabilities change over time, the model was still going to be able to", "tokens": [50364, 11698, 300, 498, 264, 33783, 1319, 670, 565, 11, 264, 2316, 390, 920, 516, 281, 312, 1075, 281, 50872], "temperature": 0.0, "avg_logprob": -0.06904032230377197, "compression_ratio": 1.6, "no_speech_prob": 0.0012981698382645845}, {"id": 298, "seek": 232096, "start": 2331.12, "end": 2339.2, "text": " predict that trend that humans would be able to do when they were performing a changing task.", "tokens": [50872, 6069, 300, 6028, 300, 6255, 576, 312, 1075, 281, 360, 562, 436, 645, 10205, 257, 4473, 5633, 13, 51276], "temperature": 0.0, "avg_logprob": -0.06904032230377197, "compression_ratio": 1.6, "no_speech_prob": 0.0012981698382645845}, {"id": 299, "seek": 232096, "start": 2339.76, "end": 2347.68, "text": " So in this particular example, this shows the binary options and the change in probability", "tokens": [51304, 407, 294, 341, 1729, 1365, 11, 341, 3110, 264, 17434, 3956, 293, 264, 1319, 294, 8482, 51700], "temperature": 0.0, "avg_logprob": -0.06904032230377197, "compression_ratio": 1.6, "no_speech_prob": 0.0012981698382645845}, {"id": 300, "seek": 234768, "start": 2347.7599999999998, "end": 2354.3199999999997, "text": " during a particular time period. And so humans are doing still that binary choice task,", "tokens": [50368, 1830, 257, 1729, 565, 2896, 13, 400, 370, 6255, 366, 884, 920, 300, 17434, 3922, 5633, 11, 50696], "temperature": 0.0, "avg_logprob": -0.10649172721370574, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00062029022956267}, {"id": 301, "seek": 234768, "start": 2354.3199999999997, "end": 2363.2, "text": " but the probability changes of one of the options. And so the figures show the rate of", "tokens": [50696, 457, 264, 8482, 2962, 295, 472, 295, 264, 3956, 13, 400, 370, 264, 9624, 855, 264, 3314, 295, 51140], "temperature": 0.0, "avg_logprob": -0.10649172721370574, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00062029022956267}, {"id": 302, "seek": 234768, "start": 2363.2, "end": 2370.56, "text": " observed choices, again in the dotted line, from human behavior and the predictions from the IVL", "tokens": [51140, 13095, 7994, 11, 797, 294, 264, 37459, 1622, 11, 490, 1952, 5223, 293, 264, 21264, 490, 264, 15967, 43, 51508], "temperature": 0.0, "avg_logprob": -0.10649172721370574, "compression_ratio": 1.5224719101123596, "no_speech_prob": 0.00062029022956267}, {"id": 303, "seek": 237056, "start": 2370.64, "end": 2379.68, "text": " model. Numerically, we can calculate the actual relationship between human and model with some", "tokens": [50368, 2316, 13, 426, 15583, 984, 11, 321, 393, 8873, 264, 3539, 2480, 1296, 1952, 293, 2316, 365, 512, 50820], "temperature": 0.0, "avg_logprob": -0.12225785622229943, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.0021355124190449715}, {"id": 304, "seek": 237056, "start": 2379.68, "end": 2389.36, "text": " metrics, but I'm going to come back to that later on. Another example is a collaboration,", "tokens": [50820, 16367, 11, 457, 286, 478, 516, 281, 808, 646, 281, 300, 1780, 322, 13, 3996, 1365, 307, 257, 9363, 11, 51304], "temperature": 0.0, "avg_logprob": -0.12225785622229943, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.0021355124190449715}, {"id": 305, "seek": 237056, "start": 2389.36, "end": 2397.04, "text": " a cooperation between two agents in the prisoner's dilemma. This is some of the data I presented", "tokens": [51304, 257, 14968, 1296, 732, 12554, 294, 264, 28114, 311, 34312, 13, 639, 307, 512, 295, 264, 1412, 286, 8212, 51688], "temperature": 0.0, "avg_logprob": -0.12225785622229943, "compression_ratio": 1.4946808510638299, "no_speech_prob": 0.0021355124190449715}, {"id": 306, "seek": 239704, "start": 2397.04, "end": 2405.2799999999997, "text": " also the other day in the workshop, but I'm expanding these figures now a little bit. So the", "tokens": [50364, 611, 264, 661, 786, 294, 264, 13541, 11, 457, 286, 478, 14702, 613, 9624, 586, 257, 707, 857, 13, 407, 264, 50776], "temperature": 0.0, "avg_logprob": -0.11930708587169647, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0010207121958956122}, {"id": 307, "seek": 239704, "start": 2405.2799999999997, "end": 2414.32, "text": " idea was that if we can emulate the choice, binary choice in this case of a particular individual,", "tokens": [50776, 1558, 390, 300, 498, 321, 393, 45497, 264, 3922, 11, 17434, 3922, 294, 341, 1389, 295, 257, 1729, 2609, 11, 51228], "temperature": 0.0, "avg_logprob": -0.11930708587169647, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0010207121958956122}, {"id": 308, "seek": 239704, "start": 2414.88, "end": 2422.16, "text": " can we emulate the behavior, the collective behavior in this case, cooperation,", "tokens": [51256, 393, 321, 45497, 264, 5223, 11, 264, 12590, 5223, 294, 341, 1389, 11, 14968, 11, 51620], "temperature": 0.0, "avg_logprob": -0.11930708587169647, "compression_ratio": 1.5941176470588236, "no_speech_prob": 0.0010207121958956122}, {"id": 309, "seek": 242216, "start": 2422.16, "end": 2429.12, "text": " emergent cooperation of two individuals working together in particular in the prisoner's dilemma", "tokens": [50364, 4345, 6930, 14968, 295, 732, 5346, 1364, 1214, 294, 1729, 294, 264, 28114, 311, 34312, 50712], "temperature": 0.0, "avg_logprob": -0.10463887453079224, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.0007512524607591331}, {"id": 310, "seek": 242216, "start": 2429.12, "end": 2437.68, "text": " in this example. So we created copies of the IVL model, one representing player one, the other", "tokens": [50712, 294, 341, 1365, 13, 407, 321, 2942, 14341, 295, 264, 15967, 43, 2316, 11, 472, 13460, 4256, 472, 11, 264, 661, 51140], "temperature": 0.0, "avg_logprob": -0.10463887453079224, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.0007512524607591331}, {"id": 311, "seek": 242216, "start": 2437.68, "end": 2444.48, "text": " one representing player two, and we put them to work in the prisoner's dilemma, and we did", "tokens": [51140, 472, 13460, 4256, 732, 11, 293, 321, 829, 552, 281, 589, 294, 264, 28114, 311, 34312, 11, 293, 321, 630, 51480], "temperature": 0.0, "avg_logprob": -0.10463887453079224, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.0007512524607591331}, {"id": 312, "seek": 242216, "start": 2444.48, "end": 2450.96, "text": " different levels of information provided to the players. So what we observe here", "tokens": [51480, 819, 4358, 295, 1589, 5649, 281, 264, 4150, 13, 407, 437, 321, 11441, 510, 51804], "temperature": 0.0, "avg_logprob": -0.10463887453079224, "compression_ratio": 1.7451923076923077, "no_speech_prob": 0.0007512524607591331}, {"id": 313, "seek": 245096, "start": 2451.6, "end": 2458.08, "text": " is again the model, in this case the model is the lighter color and the human behavior,", "tokens": [50396, 307, 797, 264, 2316, 11, 294, 341, 1389, 264, 2316, 307, 264, 11546, 2017, 293, 264, 1952, 5223, 11, 50720], "temperature": 0.0, "avg_logprob": -0.09318826879773821, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0017927322769537568}, {"id": 314, "seek": 245096, "start": 2458.08, "end": 2465.92, "text": " and this is the proportion of the collective cooperation of the pair. And what you see here", "tokens": [50720, 293, 341, 307, 264, 16068, 295, 264, 12590, 14968, 295, 264, 6119, 13, 400, 437, 291, 536, 510, 51112], "temperature": 0.0, "avg_logprob": -0.09318826879773821, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0017927322769537568}, {"id": 315, "seek": 245096, "start": 2465.92, "end": 2472.96, "text": " is actually the strategies, the sequential strategies. So for example, mistrust is the", "tokens": [51112, 307, 767, 264, 9029, 11, 264, 42881, 9029, 13, 407, 337, 1365, 11, 3544, 22326, 307, 264, 51464], "temperature": 0.0, "avg_logprob": -0.09318826879773821, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0017927322769537568}, {"id": 316, "seek": 245096, "start": 2472.96, "end": 2480.08, "text": " number of times that a player defects after the two players have defected. Forgiveness is the", "tokens": [51464, 1230, 295, 1413, 300, 257, 4256, 32655, 934, 264, 732, 4150, 362, 16445, 292, 13, 1171, 70, 8477, 307, 264, 51820], "temperature": 0.0, "avg_logprob": -0.09318826879773821, "compression_ratio": 1.722488038277512, "no_speech_prob": 0.0017927322769537568}, {"id": 317, "seek": 248008, "start": 2480.08, "end": 2488.24, "text": " proportion of cooperation after the other player defected even though I cooperated, etc. So the", "tokens": [50364, 16068, 295, 14968, 934, 264, 661, 4256, 16445, 292, 754, 1673, 286, 13414, 770, 11, 5183, 13, 407, 264, 50772], "temperature": 0.0, "avg_logprob": -0.09432993237934416, "compression_ratio": 1.660919540229885, "no_speech_prob": 0.0006793357315473258}, {"id": 318, "seek": 248008, "start": 2488.24, "end": 2495.52, "text": " point of this is that the model also captures the sequential strategies over time. So it's not", "tokens": [50772, 935, 295, 341, 307, 300, 264, 2316, 611, 27986, 264, 42881, 9029, 670, 565, 13, 407, 309, 311, 406, 51136], "temperature": 0.0, "avg_logprob": -0.09432993237934416, "compression_ratio": 1.660919540229885, "no_speech_prob": 0.0006793357315473258}, {"id": 319, "seek": 248008, "start": 2495.52, "end": 2503.36, "text": " just capturing the outcome metric, but also the effects of the sequential strategies and also does", "tokens": [51136, 445, 23384, 264, 9700, 20678, 11, 457, 611, 264, 5065, 295, 264, 42881, 9029, 293, 611, 775, 51528], "temperature": 0.0, "avg_logprob": -0.09432993237934416, "compression_ratio": 1.660919540229885, "no_speech_prob": 0.0006793357315473258}, {"id": 320, "seek": 250336, "start": 2503.44, "end": 2513.1200000000003, "text": " it with different levels of information. We did have to change the blending equation to capture", "tokens": [50368, 309, 365, 819, 4358, 295, 1589, 13, 492, 630, 362, 281, 1319, 264, 23124, 5367, 281, 7983, 50852], "temperature": 0.0, "avg_logprob": -0.09831869068430431, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.004242131020873785}, {"id": 321, "seek": 250336, "start": 2513.1200000000003, "end": 2518.32, "text": " the descriptive information. I can tell you more about that. I explained that in our talk the other", "tokens": [50852, 264, 42585, 1589, 13, 286, 393, 980, 291, 544, 466, 300, 13, 286, 8825, 300, 294, 527, 751, 264, 661, 51112], "temperature": 0.0, "avg_logprob": -0.09831869068430431, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.004242131020873785}, {"id": 322, "seek": 250336, "start": 2518.32, "end": 2527.84, "text": " day. Okay, so the next sort of escalation of these examples is whether it can capture the effects,", "tokens": [51112, 786, 13, 1033, 11, 370, 264, 958, 1333, 295, 17871, 399, 295, 613, 5110, 307, 1968, 309, 393, 7983, 264, 5065, 11, 51588], "temperature": 0.0, "avg_logprob": -0.09831869068430431, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.004242131020873785}, {"id": 323, "seek": 252784, "start": 2527.84, "end": 2536.32, "text": " the collective effects of groups. So for this what we did was to create different networks", "tokens": [50364, 264, 12590, 5065, 295, 3935, 13, 407, 337, 341, 437, 321, 630, 390, 281, 1884, 819, 9590, 50788], "temperature": 0.0, "avg_logprob": -0.15230669513825448, "compression_ratio": 1.572289156626506, "no_speech_prob": 0.004552273545414209}, {"id": 324, "seek": 252784, "start": 2536.88, "end": 2544.56, "text": " with different numbers of connections, and we used two different pay-off matrices,", "tokens": [50816, 365, 819, 3547, 295, 9271, 11, 293, 321, 1143, 732, 819, 1689, 12, 4506, 32284, 11, 51200], "temperature": 0.0, "avg_logprob": -0.15230669513825448, "compression_ratio": 1.572289156626506, "no_speech_prob": 0.004552273545414209}, {"id": 325, "seek": 252784, "start": 2544.56, "end": 2551.92, "text": " and this came from the work of Valier and colleagues on a taxonomy of two by two games.", "tokens": [51200, 293, 341, 1361, 490, 264, 589, 295, 7188, 811, 293, 7734, 322, 257, 3366, 23423, 295, 732, 538, 732, 2813, 13, 51568], "temperature": 0.0, "avg_logprob": -0.15230669513825448, "compression_ratio": 1.572289156626506, "no_speech_prob": 0.004552273545414209}, {"id": 326, "seek": 255192, "start": 2552.48, "end": 2560.56, "text": " So we chose the extremes of those two by two games, the independence and the interdependence", "tokens": [50392, 407, 321, 5111, 264, 41119, 295, 729, 732, 538, 732, 2813, 11, 264, 14640, 293, 264, 728, 36763, 655, 50796], "temperature": 0.0, "avg_logprob": -0.16751858682343454, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.0019498984329402447}, {"id": 327, "seek": 255192, "start": 2561.12, "end": 2570.16, "text": " games, and we run simulations with our IVL models to play with 16 players in this case,", "tokens": [50824, 2813, 11, 293, 321, 1190, 35138, 365, 527, 15967, 43, 5245, 281, 862, 365, 3165, 4150, 294, 341, 1389, 11, 51276], "temperature": 0.0, "avg_logprob": -0.16751858682343454, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.0019498984329402447}, {"id": 328, "seek": 255192, "start": 2571.04, "end": 2579.28, "text": " making collective decisions, and then we aggregated their results. And what we observe is that in", "tokens": [51320, 1455, 12590, 5327, 11, 293, 550, 321, 16743, 770, 641, 3542, 13, 400, 437, 321, 11441, 307, 300, 294, 51732], "temperature": 0.0, "avg_logprob": -0.16751858682343454, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.0019498984329402447}, {"id": 329, "seek": 257928, "start": 2579.28, "end": 2587.92, "text": " the independence matrix, the collectives are able to figure out what is the best option for", "tokens": [50364, 264, 14640, 8141, 11, 264, 2500, 1539, 366, 1075, 281, 2573, 484, 437, 307, 264, 1151, 3614, 337, 50796], "temperature": 0.0, "avg_logprob": -0.12694595109170942, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.0010921709472313523}, {"id": 330, "seek": 257928, "start": 2587.92, "end": 2597.2000000000003, "text": " everybody, that is this 5.5, actually faster the more connections there are. So they are pretty", "tokens": [50796, 2201, 11, 300, 307, 341, 1025, 13, 20, 11, 767, 4663, 264, 544, 9271, 456, 366, 13, 407, 436, 366, 1238, 51260], "temperature": 0.0, "avg_logprob": -0.12694595109170942, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.0010921709472313523}, {"id": 331, "seek": 257928, "start": 2597.2000000000003, "end": 2604.0, "text": " good at finding the right option pretty quickly, almost immediately we can see this, but it's faster", "tokens": [51260, 665, 412, 5006, 264, 558, 3614, 1238, 2661, 11, 1920, 4258, 321, 393, 536, 341, 11, 457, 309, 311, 4663, 51600], "temperature": 0.0, "avg_logprob": -0.12694595109170942, "compression_ratio": 1.5401069518716577, "no_speech_prob": 0.0010921709472313523}, {"id": 332, "seek": 260400, "start": 2604.0, "end": 2611.12, "text": " the more connections there are. However, when there is the interdependence that is when the outcome", "tokens": [50364, 264, 544, 9271, 456, 366, 13, 2908, 11, 562, 456, 307, 264, 728, 36763, 655, 300, 307, 562, 264, 9700, 50720], "temperature": 0.0, "avg_logprob": -0.0948244503566197, "compression_ratio": 1.6836158192090396, "no_speech_prob": 0.00314823049120605}, {"id": 333, "seek": 260400, "start": 2611.12, "end": 2618.72, "text": " I'm going to get depends on the other person, that's not the case, that is more connections actually", "tokens": [50720, 286, 478, 516, 281, 483, 5946, 322, 264, 661, 954, 11, 300, 311, 406, 264, 1389, 11, 300, 307, 544, 9271, 767, 51100], "temperature": 0.0, "avg_logprob": -0.0948244503566197, "compression_ratio": 1.6836158192090396, "no_speech_prob": 0.00314823049120605}, {"id": 334, "seek": 260400, "start": 2618.72, "end": 2627.6, "text": " resulted in less ability or inability to determine what is the best action for both of us, the AA", "tokens": [51100, 18753, 294, 1570, 3485, 420, 33162, 281, 6997, 437, 307, 264, 1151, 3069, 337, 1293, 295, 505, 11, 264, 30680, 51544], "temperature": 0.0, "avg_logprob": -0.0948244503566197, "compression_ratio": 1.6836158192090396, "no_speech_prob": 0.00314823049120605}, {"id": 335, "seek": 262760, "start": 2628.08, "end": 2636.88, "text": " action. So this was curious for us, and you know this particular degradation of performance based", "tokens": [50388, 3069, 13, 407, 341, 390, 6369, 337, 505, 11, 293, 291, 458, 341, 1729, 40519, 295, 3389, 2361, 50828], "temperature": 0.0, "avg_logprob": -0.17703923312100497, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.004034349694848061}, {"id": 336, "seek": 262760, "start": 2636.88, "end": 2645.44, "text": " on the number of connections that the agents had, and so we wanted to see whether this in fact happens", "tokens": [50828, 322, 264, 1230, 295, 9271, 300, 264, 12554, 632, 11, 293, 370, 321, 1415, 281, 536, 1968, 341, 294, 1186, 2314, 51256], "temperature": 0.0, "avg_logprob": -0.17703923312100497, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.004034349694848061}, {"id": 337, "seek": 262760, "start": 2645.44, "end": 2654.72, "text": " with actual humans. So we run the study with teams, yes. What is the mechanism?", "tokens": [51256, 365, 3539, 6255, 13, 407, 321, 1190, 264, 2979, 365, 5491, 11, 2086, 13, 708, 307, 264, 7513, 30, 51720], "temperature": 0.0, "avg_logprob": -0.17703923312100497, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.004034349694848061}, {"id": 338, "seek": 265472, "start": 2654.7999999999997, "end": 2658.8799999999997, "text": " What is the mechanism? Why is interdependence so bad on?", "tokens": [50368, 708, 307, 264, 7513, 30, 1545, 307, 728, 36763, 655, 370, 1578, 322, 30, 50572], "temperature": 0.0, "avg_logprob": -0.1858927823495174, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00158126640599221}, {"id": 339, "seek": 265472, "start": 2660.3999999999996, "end": 2667.8399999999997, "text": " Yeah, so the why which you know I'm not going to show you all the evidence for that, but the why has", "tokens": [50648, 865, 11, 370, 264, 983, 597, 291, 458, 286, 478, 406, 516, 281, 855, 291, 439, 264, 4467, 337, 300, 11, 457, 264, 983, 575, 51020], "temperature": 0.0, "avg_logprob": -0.1858927823495174, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00158126640599221}, {"id": 340, "seek": 265472, "start": 2667.8399999999997, "end": 2678.3999999999996, "text": " to do with our ability to know the one-to-one correspondence of the actions. So if I play", "tokens": [51020, 281, 360, 365, 527, 3485, 281, 458, 264, 472, 12, 1353, 12, 546, 38135, 295, 264, 5909, 13, 407, 498, 286, 862, 51548], "temperature": 0.0, "avg_logprob": -0.1858927823495174, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.00158126640599221}, {"id": 341, "seek": 267840, "start": 2678.48, "end": 2687.76, "text": " with all of you, I need to keep track of what you did to me last time, and what Henrik did to me", "tokens": [50368, 365, 439, 295, 291, 11, 286, 643, 281, 1066, 2837, 295, 437, 291, 630, 281, 385, 1036, 565, 11, 293, 437, 8651, 14456, 630, 281, 385, 50832], "temperature": 0.0, "avg_logprob": -0.13507676679034566, "compression_ratio": 1.646067415730337, "no_speech_prob": 0.027863889932632446}, {"id": 342, "seek": 267840, "start": 2687.76, "end": 2696.08, "text": " last time, and what everybody did to me. It's very hard to learn that, right? So next time when I", "tokens": [50832, 1036, 565, 11, 293, 437, 2201, 630, 281, 385, 13, 467, 311, 588, 1152, 281, 1466, 300, 11, 558, 30, 407, 958, 565, 562, 286, 51248], "temperature": 0.0, "avg_logprob": -0.13507676679034566, "compression_ratio": 1.646067415730337, "no_speech_prob": 0.027863889932632446}, {"id": 343, "seek": 267840, "start": 2696.08, "end": 2704.88, "text": " meet you again, then I need to figure it out or remember, right? Oh, she did B, I should do A with", "tokens": [51248, 1677, 291, 797, 11, 550, 286, 643, 281, 2573, 309, 484, 420, 1604, 11, 558, 30, 876, 11, 750, 630, 363, 11, 286, 820, 360, 316, 365, 51688], "temperature": 0.0, "avg_logprob": -0.13507676679034566, "compression_ratio": 1.646067415730337, "no_speech_prob": 0.027863889932632446}, {"id": 344, "seek": 270488, "start": 2704.88, "end": 2712.8, "text": " her, right? It's very hard to keep track of that, the more connections you have. The first one is not", "tokens": [50364, 720, 11, 558, 30, 467, 311, 588, 1152, 281, 1066, 2837, 295, 300, 11, 264, 544, 9271, 291, 362, 13, 440, 700, 472, 307, 406, 50760], "temperature": 0.0, "avg_logprob": -0.10626561590965758, "compression_ratio": 1.5867768595041323, "no_speech_prob": 0.005440898705273867}, {"id": 345, "seek": 270488, "start": 2712.8, "end": 2717.6800000000003, "text": " difficult because it's very easy to find that regardless of how many connections you have,", "tokens": [50760, 2252, 570, 309, 311, 588, 1858, 281, 915, 300, 10060, 295, 577, 867, 9271, 291, 362, 11, 51004], "temperature": 0.0, "avg_logprob": -0.10626561590965758, "compression_ratio": 1.5867768595041323, "no_speech_prob": 0.005440898705273867}, {"id": 346, "seek": 270488, "start": 2717.6800000000003, "end": 2724.56, "text": " if you pick A, that's what everybody should pick. But doesn't it depend on the payoff structure", "tokens": [51004, 498, 291, 1888, 316, 11, 300, 311, 437, 2201, 820, 1888, 13, 583, 1177, 380, 309, 5672, 322, 264, 46547, 3877, 51348], "temperature": 0.0, "avg_logprob": -0.10626561590965758, "compression_ratio": 1.5867768595041323, "no_speech_prob": 0.005440898705273867}, {"id": 347, "seek": 270488, "start": 2724.56, "end": 2732.2400000000002, "text": " specifically of this interdependence pattern? I think it does. Okay, I secure myself. You could", "tokens": [51348, 4682, 295, 341, 728, 36763, 655, 5102, 30, 286, 519, 309, 775, 13, 1033, 11, 286, 7144, 2059, 13, 509, 727, 51732], "temperature": 0.0, "avg_logprob": -0.10626561590965758, "compression_ratio": 1.5867768595041323, "no_speech_prob": 0.005440898705273867}, {"id": 348, "seek": 273224, "start": 2732.24, "end": 2737.6, "text": " have a slightly different payoff structure, you could have the default. I don't remember what she", "tokens": [50364, 362, 257, 4748, 819, 46547, 3877, 11, 291, 727, 362, 264, 7576, 13, 286, 500, 380, 1604, 437, 750, 50632], "temperature": 0.0, "avg_logprob": -0.16946699908960647, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.006634206976741552}, {"id": 349, "seek": 273224, "start": 2737.6, "end": 2746.56, "text": " did, but it does in a pro-social way. Yeah, it does. It would go up. It does, and I mean, this is", "tokens": [50632, 630, 11, 457, 309, 775, 294, 257, 447, 12, 48600, 636, 13, 865, 11, 309, 775, 13, 467, 576, 352, 493, 13, 467, 775, 11, 293, 286, 914, 11, 341, 307, 51080], "temperature": 0.0, "avg_logprob": -0.16946699908960647, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.006634206976741552}, {"id": 350, "seek": 273224, "start": 2746.56, "end": 2754.08, "text": " an example that it does, right? But in addition to that, Valier et al. have a whole taxonomy", "tokens": [51080, 364, 1365, 300, 309, 775, 11, 558, 30, 583, 294, 4500, 281, 300, 11, 7188, 811, 1030, 419, 13, 362, 257, 1379, 3366, 23423, 51456], "temperature": 0.0, "avg_logprob": -0.16946699908960647, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.006634206976741552}, {"id": 351, "seek": 273224, "start": 2754.08, "end": 2760.4799999999996, "text": " of two by two games, and we run this model in the whole taxonomy, and this was the only,", "tokens": [51456, 295, 732, 538, 732, 2813, 11, 293, 321, 1190, 341, 2316, 294, 264, 1379, 3366, 23423, 11, 293, 341, 390, 264, 787, 11, 51776], "temperature": 0.0, "avg_logprob": -0.16946699908960647, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.006634206976741552}, {"id": 352, "seek": 276048, "start": 2760.56, "end": 2766.32, "text": " there were other things that happened, but this was the only one in which we saw this effect.", "tokens": [50368, 456, 645, 661, 721, 300, 2011, 11, 457, 341, 390, 264, 787, 472, 294, 597, 321, 1866, 341, 1802, 13, 50656], "temperature": 0.0, "avg_logprob": -0.09496442387613017, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.0008250373066402972}, {"id": 353, "seek": 276048, "start": 2767.12, "end": 2772.8, "text": " So this paper is still, I haven't published this paper, but it's still in process.", "tokens": [50696, 407, 341, 3035, 307, 920, 11, 286, 2378, 380, 6572, 341, 3035, 11, 457, 309, 311, 920, 294, 1399, 13, 50980], "temperature": 0.0, "avg_logprob": -0.09496442387613017, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.0008250373066402972}, {"id": 354, "seek": 276048, "start": 2774.4, "end": 2779.92, "text": " By the way, sorry, I had to step out of it. That was my doctor call. So the mechanism you just", "tokens": [51060, 3146, 264, 636, 11, 2597, 11, 286, 632, 281, 1823, 484, 295, 309, 13, 663, 390, 452, 4631, 818, 13, 407, 264, 7513, 291, 445, 51336], "temperature": 0.0, "avg_logprob": -0.09496442387613017, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.0008250373066402972}, {"id": 355, "seek": 276048, "start": 2779.92, "end": 2787.76, "text": " described seems to depend sensitively on the internal structure of these computational agents", "tokens": [51336, 7619, 2544, 281, 5672, 9477, 356, 322, 264, 6920, 3877, 295, 613, 28270, 12554, 51728], "temperature": 0.0, "avg_logprob": -0.09496442387613017, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.0008250373066402972}, {"id": 356, "seek": 278776, "start": 2788.48, "end": 2792.96, "text": " on their memory capacity. I mean, if they have a representation which does", "tokens": [50400, 322, 641, 4675, 6042, 13, 286, 914, 11, 498, 436, 362, 257, 10290, 597, 775, 50624], "temperature": 0.0, "avg_logprob": -0.14295930247153005, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.004964547697454691}, {"id": 357, "seek": 278776, "start": 2793.76, "end": 2802.5600000000004, "text": " simply record what every other player did, then this wouldn't happen. So there are some choices here", "tokens": [50664, 2935, 2136, 437, 633, 661, 4256, 630, 11, 550, 341, 2759, 380, 1051, 13, 407, 456, 366, 512, 7994, 510, 51104], "temperature": 0.0, "avg_logprob": -0.14295930247153005, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.004964547697454691}, {"id": 358, "seek": 278776, "start": 2803.6800000000003, "end": 2809.28, "text": " of kind of the parameters and the structure, and maybe even your definition of similarity, right?", "tokens": [51160, 295, 733, 295, 264, 9834, 293, 264, 3877, 11, 293, 1310, 754, 428, 7123, 295, 32194, 11, 558, 30, 51440], "temperature": 0.0, "avg_logprob": -0.14295930247153005, "compression_ratio": 1.467741935483871, "no_speech_prob": 0.004964547697454691}, {"id": 359, "seek": 280928, "start": 2809.28, "end": 2819.2000000000003, "text": " So, I mean, similarity would only ask what's the, what happened the last time that Catrine played", "tokens": [50364, 407, 11, 286, 914, 11, 32194, 576, 787, 1029, 437, 311, 264, 11, 437, 2011, 264, 1036, 565, 300, 9565, 15140, 3737, 50860], "temperature": 0.0, "avg_logprob": -0.2502840643059717, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.005709286779165268}, {"id": 360, "seek": 280928, "start": 2819.2000000000003, "end": 2826.7200000000003, "text": " that way as opposed to recognizing that I can learn about my interactions from Catrine,", "tokens": [50860, 300, 636, 382, 8851, 281, 18538, 300, 286, 393, 1466, 466, 452, 13280, 490, 9565, 15140, 11, 51236], "temperature": 0.0, "avg_logprob": -0.2502840643059717, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.005709286779165268}, {"id": 361, "seek": 280928, "start": 2826.7200000000003, "end": 2834.6400000000003, "text": " from my interactions with Iname, Hi, Iname. So, I mean, the, so there are a lot of choices", "tokens": [51236, 490, 452, 13280, 365, 682, 529, 11, 2421, 11, 682, 529, 13, 407, 11, 286, 914, 11, 264, 11, 370, 456, 366, 257, 688, 295, 7994, 51632], "temperature": 0.0, "avg_logprob": -0.2502840643059717, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.005709286779165268}, {"id": 362, "seek": 283464, "start": 2834.64, "end": 2841.44, "text": " underneath here. I mean, the choices are very transparent in the equations of the model.", "tokens": [50364, 7223, 510, 13, 286, 914, 11, 264, 7994, 366, 588, 12737, 294, 264, 11787, 295, 264, 2316, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1203931377780053, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0020688080694526434}, {"id": 363, "seek": 283464, "start": 2841.44, "end": 2849.7599999999998, "text": " That's the choices. In this particular task, the binary choice, you don't even have attributes.", "tokens": [50704, 663, 311, 264, 7994, 13, 682, 341, 1729, 5633, 11, 264, 17434, 3922, 11, 291, 500, 380, 754, 362, 17212, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1203931377780053, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0020688080694526434}, {"id": 364, "seek": 283464, "start": 2849.7599999999998, "end": 2856.16, "text": " You know A in an outcome. So there is not even a similarity in this case, but the frequency", "tokens": [51120, 509, 458, 316, 294, 364, 9700, 13, 407, 456, 307, 406, 754, 257, 32194, 294, 341, 1389, 11, 457, 264, 7893, 51440], "temperature": 0.0, "avg_logprob": -0.1203931377780053, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0020688080694526434}, {"id": 365, "seek": 283464, "start": 2856.16, "end": 2862.96, "text": " and the recency play a role, and that's just organic in the model. There is no, yeah,", "tokens": [51440, 293, 264, 850, 3020, 862, 257, 3090, 11, 293, 300, 311, 445, 10220, 294, 264, 2316, 13, 821, 307, 572, 11, 1338, 11, 51780], "temperature": 0.0, "avg_logprob": -0.1203931377780053, "compression_ratio": 1.6605504587155964, "no_speech_prob": 0.0020688080694526434}, {"id": 366, "seek": 286296, "start": 2862.96, "end": 2869.2, "text": " there is a choice of the parameter of the K, but we don't in, I forgot to say that, in one of these", "tokens": [50364, 456, 307, 257, 3922, 295, 264, 13075, 295, 264, 591, 11, 457, 321, 500, 380, 294, 11, 286, 5298, 281, 584, 300, 11, 294, 472, 295, 613, 50676], "temperature": 0.0, "avg_logprob": -0.15150256686740451, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0004716052790172398}, {"id": 367, "seek": 286296, "start": 2869.2, "end": 2875.6, "text": " results, we are manipulating that parameter. We are using the default parameter that is used in", "tokens": [50676, 3542, 11, 321, 366, 40805, 300, 13075, 13, 492, 366, 1228, 264, 7576, 13075, 300, 307, 1143, 294, 50996], "temperature": 0.0, "avg_logprob": -0.15150256686740451, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0004716052790172398}, {"id": 368, "seek": 286296, "start": 2875.6, "end": 2881.44, "text": " Act R. So it's just coming from, these predictions are coming from the theory.", "tokens": [50996, 3251, 497, 13, 407, 309, 311, 445, 1348, 490, 11, 613, 21264, 366, 1348, 490, 264, 5261, 13, 51288], "temperature": 0.0, "avg_logprob": -0.15150256686740451, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0004716052790172398}, {"id": 369, "seek": 286296, "start": 2882.4, "end": 2890.2400000000002, "text": " But in this setting, aren't there some choices about how I represent past events?", "tokens": [51336, 583, 294, 341, 3287, 11, 3212, 380, 456, 512, 7994, 466, 577, 286, 2906, 1791, 3931, 30, 51728], "temperature": 0.0, "avg_logprob": -0.15150256686740451, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.0004716052790172398}, {"id": 370, "seek": 289024, "start": 2890.3199999999997, "end": 2897.12, "text": " Very good. Yeah, in every setting. And that is the major point. I'm going to come back to that", "tokens": [50368, 4372, 665, 13, 865, 11, 294, 633, 3287, 13, 400, 300, 307, 264, 2563, 935, 13, 286, 478, 516, 281, 808, 646, 281, 300, 50708], "temperature": 0.0, "avg_logprob": -0.10135250706826487, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.003740428015589714}, {"id": 371, "seek": 289024, "start": 2897.12, "end": 2903.52, "text": " later if you don't mind. But that is exactly the major, one of the major things that we need to", "tokens": [50708, 1780, 498, 291, 500, 380, 1575, 13, 583, 300, 307, 2293, 264, 2563, 11, 472, 295, 264, 2563, 721, 300, 321, 643, 281, 51028], "temperature": 0.0, "avg_logprob": -0.10135250706826487, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.003740428015589714}, {"id": 372, "seek": 289024, "start": 2903.52, "end": 2910.08, "text": " improve. The main choice is the designer of the model on what to represent in the instance.", "tokens": [51028, 3470, 13, 440, 2135, 3922, 307, 264, 11795, 295, 264, 2316, 322, 437, 281, 2906, 294, 264, 5197, 13, 51356], "temperature": 0.0, "avg_logprob": -0.10135250706826487, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.003740428015589714}, {"id": 373, "seek": 289024, "start": 2911.2, "end": 2917.6, "text": " We say that we don't represent anything that is not fully available to the human.", "tokens": [51412, 492, 584, 300, 321, 500, 380, 2906, 1340, 300, 307, 406, 4498, 2435, 281, 264, 1952, 13, 51732], "temperature": 0.0, "avg_logprob": -0.10135250706826487, "compression_ratio": 1.6697247706422018, "no_speech_prob": 0.003740428015589714}, {"id": 374, "seek": 291760, "start": 2917.6, "end": 2923.36, "text": " And it's true. That's what we try to be very committed to do. But still there are choices", "tokens": [50364, 400, 309, 311, 2074, 13, 663, 311, 437, 321, 853, 281, 312, 588, 7784, 281, 360, 13, 583, 920, 456, 366, 7994, 50652], "temperature": 0.0, "avg_logprob": -0.1553297241528829, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0008514166693203151}, {"id": 375, "seek": 291760, "start": 2923.36, "end": 2929.12, "text": " on what to represent in the instance. This case is not that case because it's very simple.", "tokens": [50652, 322, 437, 281, 2906, 294, 264, 5197, 13, 639, 1389, 307, 406, 300, 1389, 570, 309, 311, 588, 2199, 13, 50940], "temperature": 0.0, "avg_logprob": -0.1553297241528829, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0008514166693203151}, {"id": 376, "seek": 291760, "start": 2929.12, "end": 2938.3199999999997, "text": " You just see A or B. There is no attributes and the outcome. I can come back to the issue of", "tokens": [50940, 509, 445, 536, 316, 420, 363, 13, 821, 307, 572, 17212, 293, 264, 9700, 13, 286, 393, 808, 646, 281, 264, 2734, 295, 51400], "temperature": 0.0, "avg_logprob": -0.1553297241528829, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0008514166693203151}, {"id": 377, "seek": 291760, "start": 2938.3199999999997, "end": 2943.92, "text": " representation. I know there are many questions. Do you think you could wrap up in like five minutes?", "tokens": [51400, 10290, 13, 286, 458, 456, 366, 867, 1651, 13, 1144, 291, 519, 291, 727, 7019, 493, 294, 411, 1732, 2077, 30, 51680], "temperature": 0.0, "avg_logprob": -0.1553297241528829, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0008514166693203151}, {"id": 378, "seek": 294392, "start": 2944.16, "end": 2951.76, "text": " Okay. And then so there is still time for more discussion. Then here is where my strategy to", "tokens": [50376, 1033, 13, 400, 550, 370, 456, 307, 920, 565, 337, 544, 5017, 13, 1396, 510, 307, 689, 452, 5206, 281, 50756], "temperature": 0.0, "avg_logprob": -0.17896692911783854, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.007800047751516104}, {"id": 379, "seek": 294392, "start": 2951.76, "end": 2958.96, "text": " cut a lot of stuff comes. So I'm going to show a few more things. I'm going to wrap up in five", "tokens": [50756, 1723, 257, 688, 295, 1507, 1487, 13, 407, 286, 478, 516, 281, 855, 257, 1326, 544, 721, 13, 286, 478, 516, 281, 7019, 493, 294, 1732, 51116], "temperature": 0.0, "avg_logprob": -0.17896692911783854, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.007800047751516104}, {"id": 380, "seek": 294392, "start": 2958.96, "end": 2971.6800000000003, "text": " minutes then. Okay. So again, we run the exercise with human participants in groups. And the human", "tokens": [51116, 2077, 550, 13, 1033, 13, 407, 797, 11, 321, 1190, 264, 5380, 365, 1952, 10503, 294, 3935, 13, 400, 264, 1952, 51752], "temperature": 0.0, "avg_logprob": -0.17896692911783854, "compression_ratio": 1.5212765957446808, "no_speech_prob": 0.007800047751516104}, {"id": 381, "seek": 297168, "start": 2971.7599999999998, "end": 2978.64, "text": " participants in this case were groups of six because running 16 was a lot more complicated.", "tokens": [50368, 10503, 294, 341, 1389, 645, 3935, 295, 2309, 570, 2614, 3165, 390, 257, 688, 544, 6179, 13, 50712], "temperature": 0.0, "avg_logprob": -0.10632609172039721, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.001506913686171174}, {"id": 382, "seek": 297168, "start": 2978.64, "end": 2984.3199999999997, "text": " But we managed to gather a good number of groups in each of the conditions. And this is what we", "tokens": [50712, 583, 321, 6453, 281, 5448, 257, 665, 1230, 295, 3935, 294, 1184, 295, 264, 4487, 13, 400, 341, 307, 437, 321, 50996], "temperature": 0.0, "avg_logprob": -0.10632609172039721, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.001506913686171174}, {"id": 383, "seek": 297168, "start": 2984.3199999999997, "end": 2992.24, "text": " observed. So the main effect that we predicted was verified with the human data.", "tokens": [50996, 13095, 13, 407, 264, 2135, 1802, 300, 321, 19147, 390, 31197, 365, 264, 1952, 1412, 13, 51392], "temperature": 0.0, "avg_logprob": -0.10632609172039721, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.001506913686171174}, {"id": 384, "seek": 297168, "start": 2993.9199999999996, "end": 3000.48, "text": " Okay. The next example is a little bit more complicated and is more realistic too. And in", "tokens": [51476, 1033, 13, 440, 958, 1365, 307, 257, 707, 857, 544, 6179, 293, 307, 544, 12465, 886, 13, 400, 294, 51804], "temperature": 0.0, "avg_logprob": -0.10632609172039721, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.001506913686171174}, {"id": 385, "seek": 300048, "start": 3000.48, "end": 3007.68, "text": " this example, there are many features. It's about phishing. And it's about our human decision to", "tokens": [50364, 341, 1365, 11, 456, 366, 867, 4122, 13, 467, 311, 466, 903, 3807, 13, 400, 309, 311, 466, 527, 1952, 3537, 281, 50724], "temperature": 0.0, "avg_logprob": -0.11412262670772592, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.0015392819186672568}, {"id": 386, "seek": 300048, "start": 3008.72, "end": 3016.72, "text": " whether let pass phishing email or not. So we use a data set that was collected by someone else,", "tokens": [50776, 1968, 718, 1320, 903, 3807, 3796, 420, 406, 13, 407, 321, 764, 257, 1412, 992, 300, 390, 11087, 538, 1580, 1646, 11, 51176], "temperature": 0.0, "avg_logprob": -0.11412262670772592, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.0015392819186672568}, {"id": 387, "seek": 300048, "start": 3016.72, "end": 3023.68, "text": " not us. And that data set was collected in this form. So there were a bunch of emails that they", "tokens": [51176, 406, 505, 13, 400, 300, 1412, 992, 390, 11087, 294, 341, 1254, 13, 407, 456, 645, 257, 3840, 295, 12524, 300, 436, 51524], "temperature": 0.0, "avg_logprob": -0.11412262670772592, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.0015392819186672568}, {"id": 388, "seek": 300048, "start": 3023.68, "end": 3029.52, "text": " created and some of them were real. So real phishing and real ham. Those are real emails.", "tokens": [51524, 2942, 293, 512, 295, 552, 645, 957, 13, 407, 957, 903, 3807, 293, 957, 7852, 13, 3950, 366, 957, 12524, 13, 51816], "temperature": 0.0, "avg_logprob": -0.11412262670772592, "compression_ratio": 1.7710280373831775, "no_speech_prob": 0.0015392819186672568}, {"id": 389, "seek": 302952, "start": 3029.52, "end": 3038.96, "text": " And then they simulated some phishing and ham emails. And then they asked people to rate the", "tokens": [50364, 400, 550, 436, 41713, 512, 903, 3807, 293, 7852, 12524, 13, 400, 550, 436, 2351, 561, 281, 3314, 264, 50836], "temperature": 0.0, "avg_logprob": -0.11764292521019505, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.0007868754328228533}, {"id": 390, "seek": 302952, "start": 3039.7599999999998, "end": 3047.68, "text": " phishing, the emails, whether they were definitely safe to definitely suspicious. And so what we did", "tokens": [50876, 903, 3807, 11, 264, 12524, 11, 1968, 436, 645, 2138, 3273, 281, 2138, 17931, 13, 400, 370, 437, 321, 630, 51272], "temperature": 0.0, "avg_logprob": -0.11764292521019505, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.0007868754328228533}, {"id": 391, "seek": 302952, "start": 3047.68, "end": 3057.92, "text": " is we plotted the human data. It's here. We emulated the same decision with our model. And it's here.", "tokens": [51272, 307, 321, 43288, 264, 1952, 1412, 13, 467, 311, 510, 13, 492, 846, 6987, 264, 912, 3537, 365, 527, 2316, 13, 400, 309, 311, 510, 13, 51784], "temperature": 0.0, "avg_logprob": -0.11764292521019505, "compression_ratio": 1.6761363636363635, "no_speech_prob": 0.0007868754328228533}, {"id": 392, "seek": 305792, "start": 3057.92, "end": 3064.16, "text": " And we can see that the distributions of the model are very similar to that of the human.", "tokens": [50364, 400, 321, 393, 536, 300, 264, 37870, 295, 264, 2316, 366, 588, 2531, 281, 300, 295, 264, 1952, 13, 50676], "temperature": 0.0, "avg_logprob": -0.1227276623249054, "compression_ratio": 1.5895953757225434, "no_speech_prob": 0.0006431339425034821}, {"id": 393, "seek": 305792, "start": 3065.12, "end": 3071.04, "text": " And finally, an even more complex task because this is a very popular theme of research is", "tokens": [50724, 400, 2721, 11, 364, 754, 544, 3997, 5633, 570, 341, 307, 257, 588, 3743, 6314, 295, 2132, 307, 51020], "temperature": 0.0, "avg_logprob": -0.1227276623249054, "compression_ratio": 1.5895953757225434, "no_speech_prob": 0.0006431339425034821}, {"id": 394, "seek": 305792, "start": 3071.04, "end": 3078.7200000000003, "text": " cybersecurity. And in this particular case, we are emulating the decisions of a defender in an", "tokens": [51020, 38765, 13, 400, 294, 341, 1729, 1389, 11, 321, 366, 846, 12162, 264, 5327, 295, 257, 26537, 294, 364, 51404], "temperature": 0.0, "avg_logprob": -0.1227276623249054, "compression_ratio": 1.5895953757225434, "no_speech_prob": 0.0006431339425034821}, {"id": 395, "seek": 307872, "start": 3078.7999999999997, "end": 3089.6, "text": " individual task. And there is a network that the defender needs to keep safe. And there are some", "tokens": [50368, 2609, 5633, 13, 400, 456, 307, 257, 3209, 300, 264, 26537, 2203, 281, 1066, 3273, 13, 400, 456, 366, 512, 50908], "temperature": 0.0, "avg_logprob": -0.12090289025079637, "compression_ratio": 1.5702479338842976, "no_speech_prob": 0.01957404613494873}, {"id": 396, "seek": 307872, "start": 3090.24, "end": 3103.3599999999997, "text": " strategies of red agents or red attackers. Two strategies are implemented. And the strategies", "tokens": [50940, 9029, 295, 2182, 12554, 420, 2182, 45129, 13, 4453, 9029, 366, 12270, 13, 400, 264, 9029, 51596], "temperature": 0.0, "avg_logprob": -0.12090289025079637, "compression_ratio": 1.5702479338842976, "no_speech_prob": 0.01957404613494873}, {"id": 397, "seek": 310336, "start": 3103.36, "end": 3110.1600000000003, "text": " vary in the way they explore the network to reach the objective, which is this operational server.", "tokens": [50364, 10559, 294, 264, 636, 436, 6839, 264, 3209, 281, 2524, 264, 10024, 11, 597, 307, 341, 16607, 7154, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1255171000957489, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.003444572677835822}, {"id": 398, "seek": 310336, "start": 3111.04, "end": 3120.08, "text": " The interface that the humans use to do this task is what you see here. And we again run", "tokens": [50748, 440, 9226, 300, 264, 6255, 764, 281, 360, 341, 5633, 307, 437, 291, 536, 510, 13, 400, 321, 797, 1190, 51200], "temperature": 0.0, "avg_logprob": -0.1255171000957489, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.003444572677835822}, {"id": 399, "seek": 310336, "start": 3120.08, "end": 3129.1200000000003, "text": " and publish a paper with just the predictions of what the model does against as defending against", "tokens": [51200, 293, 11374, 257, 3035, 365, 445, 264, 21264, 295, 437, 264, 2316, 775, 1970, 382, 21377, 1970, 51652], "temperature": 0.0, "avg_logprob": -0.1255171000957489, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.003444572677835822}, {"id": 400, "seek": 312912, "start": 3129.44, "end": 3142.4, "text": " two attacker strategies, the meander and the other more direct strategy. And this is our results", "tokens": [50380, 732, 35871, 9029, 11, 264, 385, 4483, 293, 264, 661, 544, 2047, 5206, 13, 400, 341, 307, 527, 3542, 51028], "temperature": 0.0, "avg_logprob": -0.10543109500218951, "compression_ratio": 1.5771428571428572, "no_speech_prob": 0.002320722443982959}, {"id": 401, "seek": 312912, "start": 3142.4, "end": 3150.7999999999997, "text": " from the human experiment. Again, we cannot run 2000 episodes in that case. So we run seven episodes,", "tokens": [51028, 490, 264, 1952, 5120, 13, 3764, 11, 321, 2644, 1190, 8132, 9313, 294, 300, 1389, 13, 407, 321, 1190, 3407, 9313, 11, 51448], "temperature": 0.0, "avg_logprob": -0.10543109500218951, "compression_ratio": 1.5771428571428572, "no_speech_prob": 0.002320722443982959}, {"id": 402, "seek": 312912, "start": 3150.7999999999997, "end": 3158.24, "text": " but we see how our human experiment emulates the predictions from that model.", "tokens": [51448, 457, 321, 536, 577, 527, 1952, 5120, 846, 26192, 264, 21264, 490, 300, 2316, 13, 51820], "temperature": 0.0, "avg_logprob": -0.10543109500218951, "compression_ratio": 1.5771428571428572, "no_speech_prob": 0.002320722443982959}, {"id": 403, "seek": 315912, "start": 3159.52, "end": 3165.7599999999998, "text": " So, okay, given the time, I think I would like to conclude with this, which is", "tokens": [50384, 407, 11, 1392, 11, 2212, 264, 565, 11, 286, 519, 286, 576, 411, 281, 16886, 365, 341, 11, 597, 307, 50696], "temperature": 0.0, "avg_logprob": -0.1365815330954159, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008443623664788902}, {"id": 404, "seek": 315912, "start": 3167.04, "end": 3176.56, "text": " our reflection of human likeness. So I think what I have been talking about now regarding human", "tokens": [50760, 527, 12914, 295, 1952, 36946, 442, 13, 407, 286, 519, 437, 286, 362, 668, 1417, 466, 586, 8595, 1952, 51236], "temperature": 0.0, "avg_logprob": -0.1365815330954159, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008443623664788902}, {"id": 405, "seek": 315912, "start": 3176.56, "end": 3186.48, "text": " likeness is based on outcome metrics. So I emulate the decisions of the human, and then I compare", "tokens": [51236, 36946, 442, 307, 2361, 322, 9700, 16367, 13, 407, 286, 45497, 264, 5327, 295, 264, 1952, 11, 293, 550, 286, 6794, 51732], "temperature": 0.0, "avg_logprob": -0.1365815330954159, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008443623664788902}, {"id": 406, "seek": 318648, "start": 3186.48, "end": 3193.6, "text": " the outcome of the model to the outcome of the human. Usually we use generic metrics like MSE.", "tokens": [50364, 264, 9700, 295, 264, 2316, 281, 264, 9700, 295, 264, 1952, 13, 11419, 321, 764, 19577, 16367, 411, 376, 5879, 13, 50720], "temperature": 0.0, "avg_logprob": -0.09746564428011577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0026035832706838846}, {"id": 407, "seek": 318648, "start": 3194.32, "end": 3200.32, "text": " Often they are used at the aggregate level to be able to say, hey, our model is doing very well,", "tokens": [50756, 20043, 436, 366, 1143, 412, 264, 26118, 1496, 281, 312, 1075, 281, 584, 11, 4177, 11, 527, 2316, 307, 884, 588, 731, 11, 51056], "temperature": 0.0, "avg_logprob": -0.09746564428011577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0026035832706838846}, {"id": 408, "seek": 318648, "start": 3200.32, "end": 3205.92, "text": " and that's what every cognitive modeler does. But I think that's wrong. I think we really need to", "tokens": [51056, 293, 300, 311, 437, 633, 15605, 2316, 260, 775, 13, 583, 286, 519, 300, 311, 2085, 13, 286, 519, 321, 534, 643, 281, 51336], "temperature": 0.0, "avg_logprob": -0.09746564428011577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0026035832706838846}, {"id": 409, "seek": 318648, "start": 3205.92, "end": 3215.12, "text": " improve this metric, especially that we have the mechanisms to be able to compare at a much lower", "tokens": [51336, 3470, 341, 20678, 11, 2318, 300, 321, 362, 264, 15902, 281, 312, 1075, 281, 6794, 412, 257, 709, 3126, 51796], "temperature": 0.0, "avg_logprob": -0.09746564428011577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0026035832706838846}, {"id": 410, "seek": 321512, "start": 3215.12, "end": 3222.4, "text": " level. We should always at least compare at the individual level and be able to evaluate the steps,", "tokens": [50364, 1496, 13, 492, 820, 1009, 412, 1935, 6794, 412, 264, 2609, 1496, 293, 312, 1075, 281, 13059, 264, 4439, 11, 50728], "temperature": 0.0, "avg_logprob": -0.1162182559137759, "compression_ratio": 1.5196850393700787, "no_speech_prob": 0.0005841206293553114}, {"id": 411, "seek": 321512, "start": 3222.4, "end": 3236.96, "text": " each of the steps at the individual level. Let me say just that we are using now these models", "tokens": [50728, 1184, 295, 264, 4439, 412, 264, 2609, 1496, 13, 961, 385, 584, 445, 300, 321, 366, 1228, 586, 613, 5245, 51456], "temperature": 0.0, "avg_logprob": -0.1162182559137759, "compression_ratio": 1.5196850393700787, "no_speech_prob": 0.0005841206293553114}, {"id": 412, "seek": 323696, "start": 3237.52, "end": 3246.48, "text": " more directly in some applications to be able to help prevent the biases that humans have,", "tokens": [50392, 544, 3838, 294, 512, 5821, 281, 312, 1075, 281, 854, 4871, 264, 32152, 300, 6255, 362, 11, 50840], "temperature": 0.0, "avg_logprob": -0.08734564195599473, "compression_ratio": 1.621301775147929, "no_speech_prob": 0.012522298842668533}, {"id": 413, "seek": 323696, "start": 3247.04, "end": 3253.76, "text": " and to be able to help humans make better decisions. For example, connecting these models", "tokens": [50868, 293, 281, 312, 1075, 281, 854, 6255, 652, 1101, 5327, 13, 1171, 1365, 11, 11015, 613, 5245, 51204], "temperature": 0.0, "avg_logprob": -0.08734564195599473, "compression_ratio": 1.621301775147929, "no_speech_prob": 0.012522298842668533}, {"id": 414, "seek": 323696, "start": 3253.76, "end": 3262.4, "text": " with machine learning models and optimization models, and using our cognitive models as human", "tokens": [51204, 365, 3479, 2539, 5245, 293, 19618, 5245, 11, 293, 1228, 527, 15605, 5245, 382, 1952, 51636], "temperature": 0.0, "avg_logprob": -0.08734564195599473, "compression_ratio": 1.621301775147929, "no_speech_prob": 0.012522298842668533}, {"id": 415, "seek": 326240, "start": 3262.48, "end": 3273.28, "text": " collaborators. This is one of the ways in which we are actually using our models in cybersecurity.", "tokens": [50368, 39789, 13, 639, 307, 472, 295, 264, 2098, 294, 597, 321, 366, 767, 1228, 527, 5245, 294, 38765, 13, 50908], "temperature": 0.0, "avg_logprob": -0.09999548105093149, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.00035534705966711044}, {"id": 416, "seek": 326240, "start": 3274.48, "end": 3283.36, "text": " By emulating the actions of an attacker or an end user in the case of phishing, we can actually", "tokens": [50968, 3146, 846, 12162, 264, 5909, 295, 364, 35871, 420, 364, 917, 4195, 294, 264, 1389, 295, 903, 3807, 11, 321, 393, 767, 51412], "temperature": 0.0, "avg_logprob": -0.09999548105093149, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.00035534705966711044}, {"id": 417, "seek": 326240, "start": 3283.36, "end": 3291.52, "text": " provide the predictions of what these humans are going to do to heavy machine learning algorithms", "tokens": [51412, 2893, 264, 21264, 295, 437, 613, 6255, 366, 516, 281, 360, 281, 4676, 3479, 2539, 14642, 51820], "temperature": 0.0, "avg_logprob": -0.09999548105093149, "compression_ratio": 1.5614973262032086, "no_speech_prob": 0.00035534705966711044}, {"id": 418, "seek": 329152, "start": 3291.52, "end": 3299.52, "text": " that are being used as defender strategy. By providing these predictions, these defender", "tokens": [50364, 300, 366, 885, 1143, 382, 26537, 5206, 13, 3146, 6530, 613, 21264, 11, 613, 26537, 50764], "temperature": 0.0, "avg_logprob": -0.12098973696349097, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.00038976460928097367}, {"id": 419, "seek": 329152, "start": 3299.52, "end": 3307.52, "text": " strategies are being adapted to be able to modify, in these cases, a stalker per security game,", "tokens": [50764, 9029, 366, 885, 20871, 281, 312, 1075, 281, 16927, 11, 294, 613, 3331, 11, 257, 21789, 260, 680, 3825, 1216, 11, 51164], "temperature": 0.0, "avg_logprob": -0.12098973696349097, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.00038976460928097367}, {"id": 420, "seek": 329152, "start": 3307.52, "end": 3315.6, "text": " modify the allocation of defense resources. The other way in which we are using these models", "tokens": [51164, 16927, 264, 27599, 295, 7654, 3593, 13, 440, 661, 636, 294, 597, 321, 366, 1228, 613, 5245, 51568], "temperature": 0.0, "avg_logprob": -0.12098973696349097, "compression_ratio": 1.6294117647058823, "no_speech_prob": 0.00038976460928097367}, {"id": 421, "seek": 331560, "start": 3315.6, "end": 3325.04, "text": " is by making them work with the human, along with the human. Instead of having one individual", "tokens": [50364, 307, 538, 1455, 552, 589, 365, 264, 1952, 11, 2051, 365, 264, 1952, 13, 7156, 295, 1419, 472, 2609, 50836], "temperature": 0.0, "avg_logprob": -0.11538236324603741, "compression_ratio": 1.6726190476190477, "no_speech_prob": 0.0034645560663193464}, {"id": 422, "seek": 331560, "start": 3325.04, "end": 3334.0, "text": " making decisions in the cybersecurity task, now we have a team. The team is an AI and a human", "tokens": [50836, 1455, 5327, 294, 264, 38765, 5633, 11, 586, 321, 362, 257, 1469, 13, 440, 1469, 307, 364, 7318, 293, 257, 1952, 51284], "temperature": 0.0, "avg_logprob": -0.11538236324603741, "compression_ratio": 1.6726190476190477, "no_speech_prob": 0.0034645560663193464}, {"id": 423, "seek": 331560, "start": 3334.0, "end": 3341.92, "text": " making decisions in this type of security task. They collaborate with each other and they are", "tokens": [51284, 1455, 5327, 294, 341, 2010, 295, 3825, 5633, 13, 814, 18338, 365, 1184, 661, 293, 436, 366, 51680], "temperature": 0.0, "avg_logprob": -0.11538236324603741, "compression_ratio": 1.6726190476190477, "no_speech_prob": 0.0034645560663193464}, {"id": 424, "seek": 334192, "start": 3341.92, "end": 3352.88, "text": " able to accomplish the task better than a human alone can do. In conclusion, our current focus of", "tokens": [50364, 1075, 281, 9021, 264, 5633, 1101, 813, 257, 1952, 3312, 393, 360, 13, 682, 10063, 11, 527, 2190, 1879, 295, 50912], "temperature": 0.0, "avg_logprob": -0.1495964527130127, "compression_ratio": 1.1829268292682926, "no_speech_prob": 0.006726765539497137}, {"id": 425, "seek": 335288, "start": 3352.96, "end": 3363.92, "text": " AI, I thought I had it. I'm almost finished though, but I thought I had it. Maybe I never,", "tokens": [50368, 7318, 11, 286, 1194, 286, 632, 309, 13, 286, 478, 1920, 4335, 1673, 11, 457, 286, 1194, 286, 632, 309, 13, 2704, 286, 1128, 11, 50916], "temperature": 0.0, "avg_logprob": -0.33468358270053206, "compression_ratio": 1.267605633802817, "no_speech_prob": 0.15196730196475983}, {"id": 426, "seek": 336392, "start": 3364.08, "end": 3366.96, "text": " oh, it's not connected.", "tokens": [50372, 1954, 11, 309, 311, 406, 4582, 13, 50516], "temperature": 0.0, "avg_logprob": -0.3490820546304026, "compression_ratio": 1.1717171717171717, "no_speech_prob": 0.009236179292201996}, {"id": 427, "seek": 336392, "start": 3380.08, "end": 3387.6, "text": " Our current focus on AI is on algorithms that aim at making faster and better decisions. The", "tokens": [51172, 2621, 2190, 1879, 322, 7318, 307, 322, 14642, 300, 5939, 412, 1455, 4663, 293, 1101, 5327, 13, 440, 51548], "temperature": 0.0, "avg_logprob": -0.3490820546304026, "compression_ratio": 1.1717171717171717, "no_speech_prob": 0.009236179292201996}, {"id": 428, "seek": 338760, "start": 3387.6, "end": 3394.72, "text": " current focus of AI is on creating algorithms that compete with the human and that are able to", "tokens": [50364, 2190, 1879, 295, 7318, 307, 322, 4084, 14642, 300, 11831, 365, 264, 1952, 293, 300, 366, 1075, 281, 50720], "temperature": 0.0, "avg_logprob": -0.08859316078392235, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0035112847108393908}, {"id": 429, "seek": 338760, "start": 3394.72, "end": 3402.4, "text": " make faster and better decisions than humans do. Our goal in contrast is to build learning", "tokens": [50720, 652, 4663, 293, 1101, 5327, 813, 6255, 360, 13, 2621, 3387, 294, 8712, 307, 281, 1322, 2539, 51104], "temperature": 0.0, "avg_logprob": -0.08859316078392235, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0035112847108393908}, {"id": 430, "seek": 338760, "start": 3402.4, "end": 3408.48, "text": " algorithms that can emulate the cognitive processes and can inform those optimization", "tokens": [51104, 14642, 300, 393, 45497, 264, 15605, 7555, 293, 393, 1356, 729, 19618, 51408], "temperature": 0.0, "avg_logprob": -0.08859316078392235, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0035112847108393908}, {"id": 431, "seek": 338760, "start": 3408.48, "end": 3415.2799999999997, "text": " algorithms to be able to speed up the human decision process. There is evidence of human", "tokens": [51408, 14642, 281, 312, 1075, 281, 3073, 493, 264, 1952, 3537, 1399, 13, 821, 307, 4467, 295, 1952, 51748], "temperature": 0.0, "avg_logprob": -0.08859316078392235, "compression_ratio": 1.7061611374407584, "no_speech_prob": 0.0035112847108393908}, {"id": 432, "seek": 341528, "start": 3415.28, "end": 3422.96, "text": " likeness in these IPL algorithms, but we know that we need to improve the metrics of human likeness.", "tokens": [50364, 36946, 442, 294, 613, 8671, 43, 14642, 11, 457, 321, 458, 300, 321, 643, 281, 3470, 264, 16367, 295, 1952, 36946, 442, 13, 50748], "temperature": 0.0, "avg_logprob": -0.11963693646417148, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.006107242312282324}, {"id": 433, "seek": 341528, "start": 3422.96, "end": 3431.76, "text": " What do we really mean by human likeness? We need to develop this evaluation of human", "tokens": [50748, 708, 360, 321, 534, 914, 538, 1952, 36946, 442, 30, 492, 643, 281, 1499, 341, 13344, 295, 1952, 51188], "temperature": 0.0, "avg_logprob": -0.11963693646417148, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.006107242312282324}, {"id": 434, "seek": 341528, "start": 3431.76, "end": 3440.1600000000003, "text": " likeness at the cognitive level steps. That is what I think is required to demonstrate some of the", "tokens": [51188, 36946, 442, 412, 264, 15605, 1496, 4439, 13, 663, 307, 437, 286, 519, 307, 4739, 281, 11698, 512, 295, 264, 51608], "temperature": 0.0, "avg_logprob": -0.11963693646417148, "compression_ratio": 1.601123595505618, "no_speech_prob": 0.006107242312282324}, {"id": 435, "seek": 344016, "start": 3440.16, "end": 3447.44, "text": " usefulness of these models. Yeah, thank you.", "tokens": [50364, 4420, 1287, 295, 613, 5245, 13, 865, 11, 1309, 291, 13, 50728], "temperature": 0.0, "avg_logprob": -0.5055714845657349, "compression_ratio": 1.1458333333333333, "no_speech_prob": 0.014963522553443909}, {"id": 436, "seek": 344016, "start": 3452.16, "end": 3454.96, "text": " Maybe some people may believe, but who can stay, please go ahead.", "tokens": [50964, 2704, 512, 561, 815, 1697, 11, 457, 567, 393, 1754, 11, 1767, 352, 2286, 13, 51104], "temperature": 0.0, "avg_logprob": -0.5055714845657349, "compression_ratio": 1.1458333333333333, "no_speech_prob": 0.014963522553443909}, {"id": 437, "seek": 345496, "start": 3454.96, "end": 3469.12, "text": " Thank you for this talk. You mentioned the prospect theory of Kahneman and Tversky,", "tokens": [50364, 1044, 291, 337, 341, 751, 13, 509, 2835, 264, 15005, 5261, 295, 591, 12140, 15023, 293, 314, 840, 4133, 11, 51072], "temperature": 0.0, "avg_logprob": -0.19723536891321983, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.010959726758301258}, {"id": 438, "seek": 345496, "start": 3469.12, "end": 3476.0, "text": " and one of the strengths of that was not only trying to match human data on specific examples,", "tokens": [51072, 293, 472, 295, 264, 16986, 295, 300, 390, 406, 787, 1382, 281, 2995, 1952, 1412, 322, 2685, 5110, 11, 51416], "temperature": 0.0, "avg_logprob": -0.19723536891321983, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.010959726758301258}, {"id": 439, "seek": 345496, "start": 3476.0, "end": 3482.8, "text": " but also being able to abstract out very general biases, human cognitive biases.", "tokens": [51416, 457, 611, 885, 1075, 281, 12649, 484, 588, 2674, 32152, 11, 1952, 15605, 32152, 13, 51756], "temperature": 0.0, "avg_logprob": -0.19723536891321983, "compression_ratio": 1.4971098265895955, "no_speech_prob": 0.010959726758301258}, {"id": 440, "seek": 348280, "start": 3483.76, "end": 3494.0, "text": " Kahneman wrote a whole book about it. Can this also abstract out from your data,", "tokens": [50412, 591, 12140, 15023, 4114, 257, 1379, 1446, 466, 309, 13, 1664, 341, 611, 12649, 484, 490, 428, 1412, 11, 50924], "temperature": 0.0, "avg_logprob": -0.11156456094039113, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0009369325125589967}, {"id": 441, "seek": 348280, "start": 3494.0, "end": 3497.52, "text": " very general human biases in these dynamic situations?", "tokens": [50924, 588, 2674, 1952, 32152, 294, 613, 8546, 6851, 30, 51100], "temperature": 0.0, "avg_logprob": -0.11156456094039113, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0009369325125589967}, {"id": 442, "seek": 348280, "start": 3497.52, "end": 3503.28, "text": " Some, but we haven't done a lot of work on that, but confirmation bias, for example,", "tokens": [51100, 2188, 11, 457, 321, 2378, 380, 1096, 257, 688, 295, 589, 322, 300, 11, 457, 21871, 12577, 11, 337, 1365, 11, 51388], "temperature": 0.0, "avg_logprob": -0.11156456094039113, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0009369325125589967}, {"id": 443, "seek": 348280, "start": 3503.28, "end": 3510.32, "text": " is something that we can definitely predict. The big difference is that we are interested in", "tokens": [51388, 307, 746, 300, 321, 393, 2138, 6069, 13, 440, 955, 2649, 307, 300, 321, 366, 3102, 294, 51740], "temperature": 0.0, "avg_logprob": -0.11156456094039113, "compression_ratio": 1.4904761904761905, "no_speech_prob": 0.0009369325125589967}, {"id": 444, "seek": 351032, "start": 3510.32, "end": 3518.32, "text": " biases from experience. That's in very sharp contrast, because in their theory, they rely on", "tokens": [50364, 32152, 490, 1752, 13, 663, 311, 294, 588, 8199, 8712, 11, 570, 294, 641, 5261, 11, 436, 10687, 322, 50764], "temperature": 0.0, "avg_logprob": -0.1068730634801528, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.0032701613381505013}, {"id": 445, "seek": 351032, "start": 3518.32, "end": 3526.7200000000003, "text": " descriptions of the options. Having the descriptions is very different than just acting and observing", "tokens": [50764, 24406, 295, 264, 3956, 13, 10222, 264, 24406, 307, 588, 819, 813, 445, 6577, 293, 22107, 51184], "temperature": 0.0, "avg_logprob": -0.1068730634801528, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.0032701613381505013}, {"id": 446, "seek": 351032, "start": 3526.7200000000003, "end": 3532.1600000000003, "text": " the outcomes. We only focus on biases from experience, and one of them is confirmation", "tokens": [51184, 264, 10070, 13, 492, 787, 1879, 322, 32152, 490, 1752, 11, 293, 472, 295, 552, 307, 21871, 51456], "temperature": 0.0, "avg_logprob": -0.1068730634801528, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.0032701613381505013}, {"id": 447, "seek": 351032, "start": 3532.1600000000003, "end": 3538.48, "text": " biases, and yes, our model can predict that. There is quite a lot of work to do on characterizing", "tokens": [51456, 32152, 11, 293, 2086, 11, 527, 2316, 393, 6069, 300, 13, 821, 307, 1596, 257, 688, 295, 589, 281, 360, 322, 2517, 3319, 51772], "temperature": 0.0, "avg_logprob": -0.1068730634801528, "compression_ratio": 1.6844444444444444, "no_speech_prob": 0.0032701613381505013}, {"id": 448, "seek": 353848, "start": 3538.48, "end": 3542.96, "text": " those biases that we can predict from experience that we haven't done.", "tokens": [50364, 729, 32152, 300, 321, 393, 6069, 490, 1752, 300, 321, 2378, 380, 1096, 13, 50588], "temperature": 0.0, "avg_logprob": -0.3466898124908733, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.012365667149424553}, {"id": 449, "seek": 353848, "start": 3542.96, "end": 3544.96, "text": " There's a question from Tenda.", "tokens": [50588, 821, 311, 257, 1168, 490, 314, 7639, 13, 50688], "temperature": 0.0, "avg_logprob": -0.3466898124908733, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.012365667149424553}, {"id": 450, "seek": 353848, "start": 3544.96, "end": 3552.56, "text": " Can I just go up on this? One of the things that Kahneman and Tversky most rarely or", "tokens": [50688, 1664, 286, 445, 352, 493, 322, 341, 30, 1485, 295, 264, 721, 300, 591, 12140, 15023, 293, 314, 840, 4133, 881, 13752, 420, 51068], "temperature": 0.0, "avg_logprob": -0.3466898124908733, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.012365667149424553}, {"id": 451, "seek": 353848, "start": 3552.56, "end": 3556.72, "text": " ever implemented computational is basically just a verbal re-description of what's going on", "tokens": [51068, 1562, 12270, 28270, 307, 1936, 445, 257, 24781, 319, 12, 14792, 12432, 295, 437, 311, 516, 322, 51276], "temperature": 0.0, "avg_logprob": -0.3466898124908733, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.012365667149424553}, {"id": 452, "seek": 353848, "start": 3557.44, "end": 3562.32, "text": " and something really disputed. But this basically, you are showing computational what can emerge,", "tokens": [51312, 293, 746, 534, 37669, 292, 13, 583, 341, 1936, 11, 291, 366, 4099, 28270, 437, 393, 21511, 11, 51556], "temperature": 0.0, "avg_logprob": -0.3466898124908733, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.012365667149424553}, {"id": 453, "seek": 353848, "start": 3562.32, "end": 3564.88, "text": " and maybe there is no general class even for some of them.", "tokens": [51556, 293, 1310, 456, 307, 572, 2674, 1508, 754, 337, 512, 295, 552, 13, 51684], "temperature": 0.0, "avg_logprob": -0.3466898124908733, "compression_ratio": 1.6292134831460674, "no_speech_prob": 0.012365667149424553}, {"id": 454, "seek": 356488, "start": 3565.76, "end": 3572.08, "text": " I'm a little frustrated with the heuristic and biases situation, because it cannot", "tokens": [50408, 286, 478, 257, 707, 15751, 365, 264, 415, 374, 3142, 293, 32152, 2590, 11, 570, 309, 2644, 50724], "temperature": 0.0, "avg_logprob": -0.15514082604266227, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.003212469397112727}, {"id": 455, "seek": 356488, "start": 3572.08, "end": 3577.52, "text": " grow longer because there is no more paper, I guess. I don't know. It just keeps growing and", "tokens": [50724, 1852, 2854, 570, 456, 307, 572, 544, 3035, 11, 286, 2041, 13, 286, 500, 380, 458, 13, 467, 445, 5965, 4194, 293, 50996], "temperature": 0.0, "avg_logprob": -0.15514082604266227, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.003212469397112727}, {"id": 456, "seek": 356488, "start": 3577.52, "end": 3584.7200000000003, "text": " growing, and new biases are emerging. I was very much in line with the initial idea. I really", "tokens": [50996, 4194, 11, 293, 777, 32152, 366, 14989, 13, 286, 390, 588, 709, 294, 1622, 365, 264, 5883, 1558, 13, 286, 534, 51356], "temperature": 0.0, "avg_logprob": -0.15514082604266227, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.003212469397112727}, {"id": 457, "seek": 356488, "start": 3584.7200000000003, "end": 3590.48, "text": " like it, and I think it's still powerful. But now everybody wants to bring a bias out. It's like", "tokens": [51356, 411, 309, 11, 293, 286, 519, 309, 311, 920, 4005, 13, 583, 586, 2201, 2738, 281, 1565, 257, 12577, 484, 13, 467, 311, 411, 51644], "temperature": 0.0, "avg_logprob": -0.15514082604266227, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.003212469397112727}, {"id": 458, "seek": 359048, "start": 3590.8, "end": 3601.36, "text": " the 20 questions, right? The idea of Alain Newell is we are doing all these very tiny experiments,", "tokens": [50380, 264, 945, 1651, 11, 558, 30, 440, 1558, 295, 967, 491, 1734, 6326, 307, 321, 366, 884, 439, 613, 588, 5870, 12050, 11, 50908], "temperature": 0.0, "avg_logprob": -0.33350649746981537, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.001172365853562951}, {"id": 459, "seek": 359048, "start": 3601.36, "end": 3608.2400000000002, "text": " but we are forgetting about the global picture. Definitely, there is a lot more work to do on", "tokens": [50908, 457, 321, 366, 25428, 466, 264, 4338, 3036, 13, 12151, 11, 456, 307, 257, 688, 544, 589, 281, 360, 322, 51252], "temperature": 0.0, "avg_logprob": -0.33350649746981537, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.001172365853562951}, {"id": 460, "seek": 359048, "start": 3608.2400000000002, "end": 3609.76, "text": " biases from experience.", "tokens": [51252, 32152, 490, 1752, 13, 51328], "temperature": 0.0, "avg_logprob": -0.33350649746981537, "compression_ratio": 1.375796178343949, "no_speech_prob": 0.001172365853562951}, {"id": 461, "seek": 360976, "start": 3609.76, "end": 3618.5600000000004, "text": " I was wondering about the previous slide of where I don't...", "tokens": [50364, 286, 390, 6359, 466, 264, 3894, 4137, 295, 689, 286, 500, 380, 485, 50804], "temperature": 0.0, "avg_logprob": -0.38322666713169645, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0387764535844326}, {"id": 462, "seek": 360976, "start": 3619.84, "end": 3621.1200000000003, "text": " Write the previous to this one?", "tokens": [50868, 23499, 264, 3894, 281, 341, 472, 30, 50932], "temperature": 0.0, "avg_logprob": -0.38322666713169645, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0387764535844326}, {"id": 463, "seek": 360976, "start": 3624.4, "end": 3631.28, "text": " So I'm wondering if there's a little bit of cluster clarity, but in a way, on the one hand,", "tokens": [51096, 407, 286, 478, 6359, 498, 456, 311, 257, 707, 857, 295, 13630, 16992, 11, 457, 294, 257, 636, 11, 322, 264, 472, 1011, 11, 51440], "temperature": 0.0, "avg_logprob": -0.38322666713169645, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0387764535844326}, {"id": 464, "seek": 360976, "start": 3631.28, "end": 3635.76, "text": " we want machines to make that for humans. On the other hand, we're", "tokens": [51440, 321, 528, 8379, 281, 652, 300, 337, 6255, 13, 1282, 264, 661, 1011, 11, 321, 434, 51664], "temperature": 0.0, "avg_logprob": -0.38322666713169645, "compression_ratio": 1.5029940119760479, "no_speech_prob": 0.0387764535844326}, {"id": 465, "seek": 363576, "start": 3636.48, "end": 3639.6800000000003, "text": " evaluating machines, and there's similarity with human decision-making.", "tokens": [50400, 27479, 8379, 11, 293, 456, 311, 32194, 365, 1952, 3537, 12, 12402, 13, 50560], "temperature": 0.0, "avg_logprob": -0.29057655334472654, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.005344582721590996}, {"id": 466, "seek": 363576, "start": 3644.1600000000003, "end": 3647.5200000000004, "text": " So it seems that there needs to be some kind of decomposition of human decision-making in", "tokens": [50784, 407, 309, 2544, 300, 456, 2203, 281, 312, 512, 733, 295, 48356, 295, 1952, 3537, 12, 12402, 294, 50952], "temperature": 0.0, "avg_logprob": -0.29057655334472654, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.005344582721590996}, {"id": 467, "seek": 363576, "start": 3647.5200000000004, "end": 3652.0, "text": " terms of what do we actually want to extract from it? What comes from human limitations,", "tokens": [50952, 2115, 295, 437, 360, 321, 767, 528, 281, 8947, 490, 309, 30, 708, 1487, 490, 1952, 15705, 11, 51176], "temperature": 0.0, "avg_logprob": -0.29057655334472654, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.005344582721590996}, {"id": 468, "seek": 363576, "start": 3652.0, "end": 3656.5600000000004, "text": " just cognitive limitations, not being able to evaluate everything? How do we split that, I guess?", "tokens": [51176, 445, 15605, 15705, 11, 406, 885, 1075, 281, 13059, 1203, 30, 1012, 360, 321, 7472, 300, 11, 286, 2041, 30, 51404], "temperature": 0.0, "avg_logprob": -0.29057655334472654, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.005344582721590996}, {"id": 469, "seek": 363576, "start": 3657.6800000000003, "end": 3665.5200000000004, "text": " I had a lot of slides going step by step in the process. Actually, a paper that", "tokens": [51460, 286, 632, 257, 688, 295, 9788, 516, 1823, 538, 1823, 294, 264, 1399, 13, 5135, 11, 257, 3035, 300, 51852], "temperature": 0.0, "avg_logprob": -0.29057655334472654, "compression_ratio": 1.6784313725490196, "no_speech_prob": 0.005344582721590996}, {"id": 470, "seek": 366552, "start": 3665.52, "end": 3672.0, "text": " is coming out in PPS does that, so if you are interested, I can send you that.", "tokens": [50364, 307, 1348, 484, 294, 430, 6273, 775, 300, 11, 370, 498, 291, 366, 3102, 11, 286, 393, 2845, 291, 300, 13, 50688], "temperature": 0.0, "avg_logprob": -0.14906520059663955, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.0009472005185671151}, {"id": 471, "seek": 366552, "start": 3672.8, "end": 3682.56, "text": " But yeah, so basically, I would break out... I broke out each of the steps in the IVLT process", "tokens": [50728, 583, 1338, 11, 370, 1936, 11, 286, 576, 1821, 484, 485, 286, 6902, 484, 1184, 295, 264, 4439, 294, 264, 15967, 43, 51, 1399, 51216], "temperature": 0.0, "avg_logprob": -0.14906520059663955, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.0009472005185671151}, {"id": 472, "seek": 366552, "start": 3682.56, "end": 3688.4, "text": " to analyze what we know and what we need to know. And definitely, one of those things are", "tokens": [51216, 281, 12477, 437, 321, 458, 293, 437, 321, 643, 281, 458, 13, 400, 2138, 11, 472, 295, 729, 721, 366, 51508], "temperature": 0.0, "avg_logprob": -0.14906520059663955, "compression_ratio": 1.4530386740331491, "no_speech_prob": 0.0009472005185671151}, {"id": 473, "seek": 368840, "start": 3689.28, "end": 3696.96, "text": " evidence for particular similarity metrics. So in our model, for example, we often use just", "tokens": [50408, 4467, 337, 1729, 32194, 16367, 13, 407, 294, 527, 2316, 11, 337, 1365, 11, 321, 2049, 764, 445, 50792], "temperature": 0.0, "avg_logprob": -0.10738604409354073, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.003930282313376665}, {"id": 474, "seek": 368840, "start": 3696.96, "end": 3704.08, "text": " linear similarity, and sometimes if it doesn't work well, we change it. There is not a lot of", "tokens": [50792, 8213, 32194, 11, 293, 2171, 498, 309, 1177, 380, 589, 731, 11, 321, 1319, 309, 13, 821, 307, 406, 257, 688, 295, 51148], "temperature": 0.0, "avg_logprob": -0.10738604409354073, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.003930282313376665}, {"id": 475, "seek": 368840, "start": 3704.08, "end": 3710.32, "text": " theory, even though there is quite a lot of work on similarity judgments, but how to translate", "tokens": [51148, 5261, 11, 754, 1673, 456, 307, 1596, 257, 688, 295, 589, 322, 32194, 40337, 11, 457, 577, 281, 13799, 51460], "temperature": 0.0, "avg_logprob": -0.10738604409354073, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.003930282313376665}, {"id": 476, "seek": 368840, "start": 3710.32, "end": 3716.7200000000003, "text": " that empirical warning to a computational mathematical form and then be able to test it", "tokens": [51460, 300, 31886, 9164, 281, 257, 28270, 18894, 1254, 293, 550, 312, 1075, 281, 1500, 309, 51780], "temperature": 0.0, "avg_logprob": -0.10738604409354073, "compression_ratio": 1.6355555555555557, "no_speech_prob": 0.003930282313376665}, {"id": 477, "seek": 371672, "start": 3716.72, "end": 3722.24, "text": " within the realm of the model, we haven't done that work, and that's one of the areas we need to", "tokens": [50364, 1951, 264, 15355, 295, 264, 2316, 11, 321, 2378, 380, 1096, 300, 589, 11, 293, 300, 311, 472, 295, 264, 3179, 321, 643, 281, 50640], "temperature": 0.0, "avg_logprob": -0.11782048298762395, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0010777090210467577}, {"id": 478, "seek": 371672, "start": 3722.24, "end": 3731.6, "text": " work on. Koti, there is a question for Daniel then. Yes. Thank you for a very interesting paper.", "tokens": [50640, 589, 322, 13, 591, 8206, 11, 456, 307, 257, 1168, 337, 8033, 550, 13, 1079, 13, 1044, 291, 337, 257, 588, 1880, 3035, 13, 51108], "temperature": 0.0, "avg_logprob": -0.11782048298762395, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0010777090210467577}, {"id": 479, "seek": 371672, "start": 3731.6, "end": 3742.72, "text": " There are two points that I wasn't sure I understood. First of all, I want to applaud the idea", "tokens": [51108, 821, 366, 732, 2793, 300, 286, 2067, 380, 988, 286, 7320, 13, 2386, 295, 439, 11, 286, 528, 281, 9644, 264, 1558, 51664], "temperature": 0.0, "avg_logprob": -0.11782048298762395, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0010777090210467577}, {"id": 480, "seek": 374272, "start": 3743.52, "end": 3751.12, "text": " that you want to enhance human decision-making and make it rather than make it", "tokens": [50404, 300, 291, 528, 281, 11985, 1952, 3537, 12, 12402, 293, 652, 309, 2831, 813, 652, 309, 50784], "temperature": 0.0, "avg_logprob": -0.17337887103740984, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.023202991113066673}, {"id": 481, "seek": 374272, "start": 3752.16, "end": 3761.8399999999997, "text": " slavishly dependent on AI decision-making. This is a theme that I've been discussing for years.", "tokens": [50836, 1061, 706, 742, 356, 12334, 322, 7318, 3537, 12, 12402, 13, 639, 307, 257, 6314, 300, 286, 600, 668, 10850, 337, 924, 13, 51320], "temperature": 0.0, "avg_logprob": -0.17337887103740984, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.023202991113066673}, {"id": 482, "seek": 374272, "start": 3764.0, "end": 3770.08, "text": " I call it the difference between the Nautilus machine and the bulldozer.", "tokens": [51428, 286, 818, 309, 264, 2649, 1296, 264, 426, 1375, 388, 301, 3479, 293, 264, 4693, 2595, 4527, 13, 51732], "temperature": 0.0, "avg_logprob": -0.17337887103740984, "compression_ratio": 1.4529411764705882, "no_speech_prob": 0.023202991113066673}, {"id": 483, "seek": 377008, "start": 3771.04, "end": 3778.72, "text": " The bulldozer lets you move mountains, but you're still a 98-pound weakling. The Nautilus machine,", "tokens": [50412, 440, 4693, 2595, 4527, 6653, 291, 1286, 10233, 11, 457, 291, 434, 920, 257, 20860, 12, 44806, 5336, 1688, 13, 440, 426, 1375, 388, 301, 3479, 11, 50796], "temperature": 0.0, "avg_logprob": -0.1318574297255364, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.0017492631450295448}, {"id": 484, "seek": 377008, "start": 3780.4, "end": 3786.48, "text": " you actually develop the strength yourself. The technology is being used to improve your", "tokens": [50880, 291, 767, 1499, 264, 3800, 1803, 13, 440, 2899, 307, 885, 1143, 281, 3470, 428, 51184], "temperature": 0.0, "avg_logprob": -0.1318574297255364, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.0017492631450295448}, {"id": 485, "seek": 377008, "start": 3786.48, "end": 3796.08, "text": " abilities and make you less dependent on the technology. So I picked that point up. I want", "tokens": [51184, 11582, 293, 652, 291, 1570, 12334, 322, 264, 2899, 13, 407, 286, 6183, 300, 935, 493, 13, 286, 528, 51664], "temperature": 0.0, "avg_logprob": -0.1318574297255364, "compression_ratio": 1.4404145077720207, "no_speech_prob": 0.0017492631450295448}, {"id": 486, "seek": 379608, "start": 3796.08, "end": 3804.3199999999997, "text": " to see if you stress it the same way I do. But the question that I really want to ask you about is", "tokens": [50364, 281, 536, 498, 291, 4244, 309, 264, 912, 636, 286, 360, 13, 583, 264, 1168, 300, 286, 534, 528, 281, 1029, 291, 466, 307, 50776], "temperature": 0.0, "avg_logprob": -0.19659064797794118, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.002079425845295191}, {"id": 487, "seek": 379608, "start": 3810.72, "end": 3819.7599999999998, "text": " consider the notorious, rueful, reflective remark of somebody who says, well, it seemed like a good", "tokens": [51096, 1949, 264, 38045, 11, 43919, 906, 11, 28931, 7942, 295, 2618, 567, 1619, 11, 731, 11, 309, 6576, 411, 257, 665, 51548], "temperature": 0.0, "avg_logprob": -0.19659064797794118, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.002079425845295191}, {"id": 488, "seek": 381976, "start": 3819.76, "end": 3827.92, "text": " idea at the time. And this requires memory of your past decision-making in detail", "tokens": [50364, 1558, 412, 264, 565, 13, 400, 341, 7029, 4675, 295, 428, 1791, 3537, 12, 12402, 294, 2607, 50772], "temperature": 0.0, "avg_logprob": -0.09954242706298828, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.04391249641776085}, {"id": 489, "seek": 381976, "start": 3829.36, "end": 3837.0400000000004, "text": " and memory of your evaluation and the grounds for that evaluation. Now that seems to me to", "tokens": [50844, 293, 4675, 295, 428, 13344, 293, 264, 19196, 337, 300, 13344, 13, 823, 300, 2544, 281, 385, 281, 51228], "temperature": 0.0, "avg_logprob": -0.09954242706298828, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.04391249641776085}, {"id": 490, "seek": 381976, "start": 3837.0400000000004, "end": 3844.2400000000002, "text": " be a very important part of human decision-making, that is the capacity to be self-critical and", "tokens": [51228, 312, 257, 588, 1021, 644, 295, 1952, 3537, 12, 12402, 11, 300, 307, 264, 6042, 281, 312, 2698, 12, 32255, 804, 293, 51588], "temperature": 0.0, "avg_logprob": -0.09954242706298828, "compression_ratio": 1.6242424242424243, "no_speech_prob": 0.04391249641776085}, {"id": 491, "seek": 384424, "start": 3844.24, "end": 3854.0, "text": " reflective and to learn from your mistakes by being able to debug your past performances.", "tokens": [50364, 28931, 293, 281, 1466, 490, 428, 8038, 538, 885, 1075, 281, 24083, 428, 1791, 16087, 13, 50852], "temperature": 0.0, "avg_logprob": -0.11596549302339554, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.023198865354061127}, {"id": 492, "seek": 384424, "start": 3854.64, "end": 3865.3599999999997, "text": " I didn't think that I saw any sign of that reflective capacity in your presentation,", "tokens": [50884, 286, 994, 380, 519, 300, 286, 1866, 604, 1465, 295, 300, 28931, 6042, 294, 428, 5860, 11, 51420], "temperature": 0.0, "avg_logprob": -0.11596549302339554, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.023198865354061127}, {"id": 493, "seek": 384424, "start": 3865.3599999999997, "end": 3872.72, "text": " but maybe I just missed it the way you were saying it. Yeah, let me address the second point before I", "tokens": [51420, 457, 1310, 286, 445, 6721, 309, 264, 636, 291, 645, 1566, 309, 13, 865, 11, 718, 385, 2985, 264, 1150, 935, 949, 286, 51788], "temperature": 0.0, "avg_logprob": -0.11596549302339554, "compression_ratio": 1.4838709677419355, "no_speech_prob": 0.023198865354061127}, {"id": 494, "seek": 387272, "start": 3872.72, "end": 3883.4399999999996, "text": " forget. My memory has a large decay. So yes, you are correct that I didn't address that point", "tokens": [50364, 2870, 13, 1222, 4675, 575, 257, 2416, 21039, 13, 407, 2086, 11, 291, 366, 3006, 300, 286, 994, 380, 2985, 300, 935, 50900], "temperature": 0.0, "avg_logprob": -0.13294665813446044, "compression_ratio": 1.2845528455284554, "no_speech_prob": 0.002619046252220869}, {"id": 495, "seek": 387272, "start": 3883.4399999999996, "end": 3890.48, "text": " very concretely in my presentation. But that idea is essentially", "tokens": [50900, 588, 39481, 736, 294, 452, 5860, 13, 583, 300, 1558, 307, 4476, 51252], "temperature": 0.0, "avg_logprob": -0.13294665813446044, "compression_ratio": 1.2845528455284554, "no_speech_prob": 0.002619046252220869}, {"id": 496, "seek": 389048, "start": 3890.64, "end": 3903.12, "text": " expressive. You can see this slide in the feedback mechanism. And so what happens is that", "tokens": [50372, 40189, 13, 509, 393, 536, 341, 4137, 294, 264, 5824, 7513, 13, 400, 370, 437, 2314, 307, 300, 50996], "temperature": 0.0, "avg_logprob": -0.13425610282204367, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.013771072030067444}, {"id": 497, "seek": 389048, "start": 3904.8, "end": 3910.96, "text": " usually the feedback is delayed and there is nothing we can do about it. And furthermore,", "tokens": [51080, 2673, 264, 5824, 307, 20268, 293, 456, 307, 1825, 321, 393, 360, 466, 309, 13, 400, 3052, 3138, 11, 51388], "temperature": 0.0, "avg_logprob": -0.13425610282204367, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.013771072030067444}, {"id": 498, "seek": 389048, "start": 3910.96, "end": 3918.56, "text": " we can make many decisions and then get one outcome. And we don't know which of the decisions we", "tokens": [51388, 321, 393, 652, 867, 5327, 293, 550, 483, 472, 9700, 13, 400, 321, 500, 380, 458, 597, 295, 264, 5327, 321, 51768], "temperature": 0.0, "avg_logprob": -0.13425610282204367, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.013771072030067444}, {"id": 499, "seek": 391856, "start": 3918.56, "end": 3926.64, "text": " made is responsible for that outcome. So we use a concept that is well-known in AI of credit", "tokens": [50364, 1027, 307, 6250, 337, 300, 9700, 13, 407, 321, 764, 257, 3410, 300, 307, 731, 12, 6861, 294, 7318, 295, 5397, 50768], "temperature": 0.0, "avg_logprob": -0.08924829598629114, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.0016039430629462004}, {"id": 500, "seek": 391856, "start": 3926.64, "end": 3935.84, "text": " assignment. So how do we associate that outcome to the various decisions that were made? This is", "tokens": [50768, 15187, 13, 407, 577, 360, 321, 14644, 300, 9700, 281, 264, 3683, 5327, 300, 645, 1027, 30, 639, 307, 51228], "temperature": 0.0, "avg_logprob": -0.08924829598629114, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.0016039430629462004}, {"id": 501, "seek": 391856, "start": 3935.84, "end": 3941.2799999999997, "text": " the other major area of research. We have a paper that we've been having trouble to", "tokens": [51228, 264, 661, 2563, 1859, 295, 2132, 13, 492, 362, 257, 3035, 300, 321, 600, 668, 1419, 5253, 281, 51500], "temperature": 0.0, "avg_logprob": -0.08924829598629114, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.0016039430629462004}, {"id": 502, "seek": 394128, "start": 3941.84, "end": 3949.0400000000004, "text": " publish, but it's made available online where we test various mechanisms of credit assignment,", "tokens": [50392, 11374, 11, 457, 309, 311, 1027, 2435, 2950, 689, 321, 1500, 3683, 15902, 295, 5397, 15187, 11, 50752], "temperature": 0.0, "avg_logprob": -0.10195311853441141, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.0025907419621944427}, {"id": 503, "seek": 394128, "start": 3949.0400000000004, "end": 3959.1200000000003, "text": " including the TD mechanism in reinforcement learning. So this is a very important part of", "tokens": [50752, 3009, 264, 42606, 7513, 294, 29280, 2539, 13, 407, 341, 307, 257, 588, 1021, 644, 295, 51256], "temperature": 0.0, "avg_logprob": -0.10195311853441141, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.0025907419621944427}, {"id": 504, "seek": 394128, "start": 3959.1200000000003, "end": 3966.6400000000003, "text": " learning because it's the only way that you can modify the expected utility with the actual utility", "tokens": [51256, 2539, 570, 309, 311, 264, 787, 636, 300, 291, 393, 16927, 264, 5176, 14877, 365, 264, 3539, 14877, 51632], "temperature": 0.0, "avg_logprob": -0.10195311853441141, "compression_ratio": 1.5268817204301075, "no_speech_prob": 0.0025907419621944427}, {"id": 505, "seek": 396664, "start": 3966.64, "end": 3974.16, "text": " of the decisions you are making and how you do that process will determine a lot how the learning", "tokens": [50364, 295, 264, 5327, 291, 366, 1455, 293, 577, 291, 360, 300, 1399, 486, 6997, 257, 688, 577, 264, 2539, 50740], "temperature": 0.0, "avg_logprob": -0.0591305133908294, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.0005162435118108988}, {"id": 506, "seek": 396664, "start": 3974.16, "end": 3983.2799999999997, "text": " is done. So we usually just do equal credit until this paper that we are still exploring and", "tokens": [50740, 307, 1096, 13, 407, 321, 2673, 445, 360, 2681, 5397, 1826, 341, 3035, 300, 321, 366, 920, 12736, 293, 51196], "temperature": 0.0, "avg_logprob": -0.0591305133908294, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.0005162435118108988}, {"id": 507, "seek": 396664, "start": 3983.2799999999997, "end": 3989.52, "text": " figuring out different credit assignments and trying to figure out how humans do that credit", "tokens": [51196, 15213, 484, 819, 5397, 22546, 293, 1382, 281, 2573, 484, 577, 6255, 360, 300, 5397, 51508], "temperature": 0.0, "avg_logprob": -0.0591305133908294, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.0005162435118108988}, {"id": 508, "seek": 396664, "start": 3989.52, "end": 3996.3199999999997, "text": " assignment. And so there's quite a lot of research that is needed in that area. And to go back to", "tokens": [51508, 15187, 13, 400, 370, 456, 311, 1596, 257, 688, 295, 2132, 300, 307, 2978, 294, 300, 1859, 13, 400, 281, 352, 646, 281, 51848], "temperature": 0.0, "avg_logprob": -0.0591305133908294, "compression_ratio": 1.7397260273972603, "no_speech_prob": 0.0005162435118108988}, {"id": 509, "seek": 399632, "start": 3996.32, "end": 4005.04, "text": " your first point of the bulldozer and dependency on technology, I think we are going to be dependent", "tokens": [50364, 428, 700, 935, 295, 264, 4693, 2595, 4527, 293, 33621, 322, 2899, 11, 286, 519, 321, 366, 516, 281, 312, 12334, 50800], "temperature": 0.0, "avg_logprob": -0.12524503820082722, "compression_ratio": 1.6589595375722543, "no_speech_prob": 0.0029792580753564835}, {"id": 510, "seek": 399632, "start": 4005.04, "end": 4012.0800000000004, "text": " on technology no matter what. And I think that's a good thing. I don't have anything against", "tokens": [50800, 322, 2899, 572, 1871, 437, 13, 400, 286, 519, 300, 311, 257, 665, 551, 13, 286, 500, 380, 362, 1340, 1970, 51152], "temperature": 0.0, "avg_logprob": -0.12524503820082722, "compression_ratio": 1.6589595375722543, "no_speech_prob": 0.0029792580753564835}, {"id": 511, "seek": 399632, "start": 4012.8, "end": 4023.28, "text": " technology, but the essence of human life is the human and the essence of any decision making", "tokens": [51188, 2899, 11, 457, 264, 12801, 295, 1952, 993, 307, 264, 1952, 293, 264, 12801, 295, 604, 3537, 1455, 51712], "temperature": 0.0, "avg_logprob": -0.12524503820082722, "compression_ratio": 1.6589595375722543, "no_speech_prob": 0.0029792580753564835}, {"id": 512, "seek": 402328, "start": 4023.28, "end": 4030.6400000000003, "text": " in any complex environments I think will continue to be the human. So I think we should use the", "tokens": [50364, 294, 604, 3997, 12388, 286, 519, 486, 2354, 281, 312, 264, 1952, 13, 407, 286, 519, 321, 820, 764, 264, 50732], "temperature": 0.0, "avg_logprob": -0.15038869040352956, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.00030244843219406903}, {"id": 513, "seek": 402328, "start": 4030.6400000000003, "end": 4039.0400000000004, "text": " technology to empower the human to be able to help the human improve their decisions. And learning", "tokens": [50732, 2899, 281, 11071, 264, 1952, 281, 312, 1075, 281, 854, 264, 1952, 3470, 641, 5327, 13, 400, 2539, 51152], "temperature": 0.0, "avg_logprob": -0.15038869040352956, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.00030244843219406903}, {"id": 514, "seek": 402328, "start": 4039.0400000000004, "end": 4046.2400000000002, "text": " mechanisms is essential for that, but figuring out how. So it's not like I give you what you want now.", "tokens": [51152, 15902, 307, 7115, 337, 300, 11, 457, 15213, 484, 577, 13, 407, 309, 311, 406, 411, 286, 976, 291, 437, 291, 528, 586, 13, 51512], "temperature": 0.0, "avg_logprob": -0.15038869040352956, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.00030244843219406903}, {"id": 515, "seek": 404624, "start": 4046.64, "end": 4054.3999999999996, "text": " It's like a spoon feeding you on what you need right now. It needs to be a lot more global than", "tokens": [50384, 467, 311, 411, 257, 12453, 12919, 291, 322, 437, 291, 643, 558, 586, 13, 467, 2203, 281, 312, 257, 688, 544, 4338, 813, 50772], "temperature": 0.0, "avg_logprob": -0.17487126130324143, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.006059500388801098}, {"id": 516, "seek": 404624, "start": 4054.3999999999996, "end": 4073.68, "text": " that. Thank you. Let me just comment. I think if you try, I'm trying to imagine your systems", "tokens": [50772, 300, 13, 1044, 291, 13, 961, 385, 445, 2871, 13, 286, 519, 498, 291, 853, 11, 286, 478, 1382, 281, 3811, 428, 3652, 51736], "temperature": 0.0, "avg_logprob": -0.17487126130324143, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.006059500388801098}, {"id": 517, "seek": 407368, "start": 4074.56, "end": 4085.2, "text": " acting as sort of tutors for human beings and tutors that have good models of how the human", "tokens": [50408, 6577, 382, 1333, 295, 3672, 830, 337, 1952, 8958, 293, 3672, 830, 300, 362, 665, 5245, 295, 577, 264, 1952, 50940], "temperature": 0.0, "avg_logprob": -0.12165066328915683, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.0068953935988247395}, {"id": 518, "seek": 407368, "start": 4085.2, "end": 4093.44, "text": " beings are making decisions because they are also models about how the tutors are making decisions.", "tokens": [50940, 8958, 366, 1455, 5327, 570, 436, 366, 611, 5245, 466, 577, 264, 3672, 830, 366, 1455, 5327, 13, 51352], "temperature": 0.0, "avg_logprob": -0.12165066328915683, "compression_ratio": 1.7053571428571428, "no_speech_prob": 0.0068953935988247395}, {"id": 519, "seek": 409344, "start": 4094.32, "end": 4105.84, "text": " And so that in effect the tutor can say, yeah, I'm making this up now. Yeah, I was tempted by that", "tokens": [50408, 400, 370, 300, 294, 1802, 264, 35613, 393, 584, 11, 1338, 11, 286, 478, 1455, 341, 493, 586, 13, 865, 11, 286, 390, 29941, 538, 300, 50984], "temperature": 0.0, "avg_logprob": -0.186447980452557, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.05382362753152847}, {"id": 520, "seek": 409344, "start": 4107.12, "end": 4114.64, "text": " way of thinking about this problem. You are absolutely correct. One of the most successful", "tokens": [51048, 636, 295, 1953, 466, 341, 1154, 13, 509, 366, 3122, 3006, 13, 1485, 295, 264, 881, 4406, 51424], "temperature": 0.0, "avg_logprob": -0.186447980452557, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.05382362753152847}, {"id": 521, "seek": 411464, "start": 4114.72, "end": 4122.160000000001, "text": " programs from ACTAAR has been on cognitive tutors. So being able to use ACTAAR to", "tokens": [50368, 4268, 490, 8157, 8241, 1899, 575, 668, 322, 15605, 3672, 830, 13, 407, 885, 1075, 281, 764, 8157, 8241, 1899, 281, 50740], "temperature": 0.0, "avg_logprob": -0.11737031936645508, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.03095175512135029}, {"id": 522, "seek": 411464, "start": 4123.280000000001, "end": 4130.08, "text": " help children learn mathematics. So you are absolutely right. We are using tutors of a", "tokens": [50796, 854, 2227, 1466, 18666, 13, 407, 291, 366, 3122, 558, 13, 492, 366, 1228, 3672, 830, 295, 257, 51136], "temperature": 0.0, "avg_logprob": -0.11737031936645508, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.03095175512135029}, {"id": 523, "seek": 411464, "start": 4130.08, "end": 4136.160000000001, "text": " different kind, we can say. It's not about mathematics. It's about making choices in some", "tokens": [51136, 819, 733, 11, 321, 393, 584, 13, 467, 311, 406, 466, 18666, 13, 467, 311, 466, 1455, 7994, 294, 512, 51440], "temperature": 0.0, "avg_logprob": -0.11737031936645508, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.03095175512135029}, {"id": 524, "seek": 411464, "start": 4136.160000000001, "end": 4143.6, "text": " complex environments. But that is exactly how we are using it. We can trace, as I was saying", "tokens": [51440, 3997, 12388, 13, 583, 300, 307, 2293, 577, 321, 366, 1228, 309, 13, 492, 393, 13508, 11, 382, 286, 390, 1566, 51812], "temperature": 0.0, "avg_logprob": -0.11737031936645508, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.03095175512135029}, {"id": 525, "seek": 414360, "start": 4143.6, "end": 4150.88, "text": " before, we can trace specific students, decision makers and their history and therefore we can", "tokens": [50364, 949, 11, 321, 393, 13508, 2685, 1731, 11, 3537, 19323, 293, 641, 2503, 293, 4412, 321, 393, 50728], "temperature": 0.0, "avg_logprob": -0.12070969877571895, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.0039725336246192455}, {"id": 526, "seek": 414360, "start": 4150.88, "end": 4157.52, "text": " make predictions about the decisions that particular person is going to make in the next", "tokens": [50728, 652, 21264, 466, 264, 5327, 300, 1729, 954, 307, 516, 281, 652, 294, 264, 958, 51060], "temperature": 0.0, "avg_logprob": -0.12070969877571895, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.0039725336246192455}, {"id": 527, "seek": 414360, "start": 4158.160000000001, "end": 4166.400000000001, "text": " opportunity. And then we can use other tools, machine learning included or any other AI tools", "tokens": [51092, 2650, 13, 400, 550, 321, 393, 764, 661, 3873, 11, 3479, 2539, 5556, 420, 604, 661, 7318, 3873, 51504], "temperature": 0.0, "avg_logprob": -0.12070969877571895, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.0039725336246192455}, {"id": 528, "seek": 416640, "start": 4166.4, "end": 4169.04, "text": " to support that decision making process.", "tokens": [50364, 281, 1406, 300, 3537, 1455, 1399, 13, 50496], "temperature": 0.0, "avg_logprob": -0.39376199656519395, "compression_ratio": 1.1818181818181819, "no_speech_prob": 0.030808882787823677}, {"id": 529, "seek": 416640, "start": 4172.799999999999, "end": 4178.5599999999995, "text": " There are maybe a couple more questions from people who want to. You choose.", "tokens": [50684, 821, 366, 1310, 257, 1916, 544, 1651, 490, 561, 567, 528, 281, 13, 509, 2826, 13, 50972], "temperature": 0.0, "avg_logprob": -0.39376199656519395, "compression_ratio": 1.1818181818181819, "no_speech_prob": 0.030808882787823677}, {"id": 530, "seek": 417856, "start": 4178.56, "end": 4185.52, "text": " We've talked about crisis and errors and we can only say if you see that as something", "tokens": [50364, 492, 600, 2825, 466, 5869, 293, 13603, 293, 321, 393, 787, 584, 498, 291, 536, 300, 382, 746, 50712], "temperature": 0.0, "avg_logprob": -0.5112176425215127, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.07545164227485657}, {"id": 531, "seek": 417856, "start": 4185.52, "end": 4194.400000000001, "text": " like ACTAAR, in a way they have to agree with the evidence. They have an adaptation to the world", "tokens": [50712, 411, 8157, 8241, 1899, 11, 294, 257, 636, 436, 362, 281, 3986, 365, 264, 4467, 13, 814, 362, 364, 21549, 281, 264, 1002, 51156], "temperature": 0.0, "avg_logprob": -0.5112176425215127, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.07545164227485657}, {"id": 532, "seek": 417856, "start": 4194.400000000001, "end": 4202.4800000000005, "text": " in which we live or have lived. So in your conception of a dynamic environment, is it also", "tokens": [51156, 294, 597, 321, 1621, 420, 362, 5152, 13, 407, 294, 428, 30698, 295, 257, 8546, 2823, 11, 307, 309, 611, 51560], "temperature": 0.0, "avg_logprob": -0.5112176425215127, "compression_ratio": 1.4598930481283423, "no_speech_prob": 0.07545164227485657}, {"id": 533, "seek": 420248, "start": 4202.48, "end": 4214.799999999999, "text": " part of the idea to change the environment to have what we call biases not occur as biases", "tokens": [50364, 644, 295, 264, 1558, 281, 1319, 264, 2823, 281, 362, 437, 321, 818, 32152, 406, 5160, 382, 32152, 50980], "temperature": 0.0, "avg_logprob": -0.14999901547151454, "compression_ratio": 1.4945054945054945, "no_speech_prob": 0.0042824167758226395}, {"id": 534, "seek": 420248, "start": 4214.799999999999, "end": 4221.5199999999995, "text": " in shortcomings? We will have interventions on those biases. Yes. So a particular program", "tokens": [50980, 294, 2099, 49886, 30, 492, 486, 362, 20924, 322, 729, 32152, 13, 1079, 13, 407, 257, 1729, 1461, 51316], "temperature": 0.0, "avg_logprob": -0.14999901547151454, "compression_ratio": 1.4945054945054945, "no_speech_prob": 0.0042824167758226395}, {"id": 535, "seek": 420248, "start": 4221.5199999999995, "end": 4230.48, "text": " which hasn't started yet is from IRPA. So I am about to start a very big program in IRPA on", "tokens": [51316, 597, 6132, 380, 1409, 1939, 307, 490, 16486, 10297, 13, 407, 286, 669, 466, 281, 722, 257, 588, 955, 1461, 294, 16486, 10297, 322, 51764], "temperature": 0.0, "avg_logprob": -0.14999901547151454, "compression_ratio": 1.4945054945054945, "no_speech_prob": 0.0042824167758226395}, {"id": 536, "seek": 423048, "start": 4230.48, "end": 4238.4, "text": " cybersecurity and it's about predicting the biases of the attackers. The idea is, of course,", "tokens": [50364, 38765, 293, 309, 311, 466, 32884, 264, 32152, 295, 264, 45129, 13, 440, 1558, 307, 11, 295, 1164, 11, 50760], "temperature": 0.0, "avg_logprob": -0.12003766244916773, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.00291039957664907}, {"id": 537, "seek": 423048, "start": 4238.4, "end": 4247.12, "text": " that we can modify the situation from the defense side so that we can trap the attacker. And given", "tokens": [50760, 300, 321, 393, 16927, 264, 2590, 490, 264, 7654, 1252, 370, 300, 321, 393, 11487, 264, 35871, 13, 400, 2212, 51196], "temperature": 0.0, "avg_logprob": -0.12003766244916773, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.00291039957664907}, {"id": 538, "seek": 423048, "start": 4247.12, "end": 4254.879999999999, "text": " that the attackers are as humans as the defenders are, we can trace down and predict when they are", "tokens": [51196, 300, 264, 45129, 366, 382, 6255, 382, 264, 36063, 366, 11, 321, 393, 13508, 760, 293, 6069, 562, 436, 366, 51584], "temperature": 0.0, "avg_logprob": -0.12003766244916773, "compression_ratio": 1.7261904761904763, "no_speech_prob": 0.00291039957664907}, {"id": 539, "seek": 425488, "start": 4254.88, "end": 4261.4400000000005, "text": " falling trap of certain biases and then be able to react according to that. So yeah, I think", "tokens": [50364, 7440, 11487, 295, 1629, 32152, 293, 550, 312, 1075, 281, 4515, 4650, 281, 300, 13, 407, 1338, 11, 286, 519, 50692], "temperature": 0.0, "avg_logprob": -0.1325046799399636, "compression_ratio": 1.86, "no_speech_prob": 0.005397255532443523}, {"id": 540, "seek": 425488, "start": 4261.4400000000005, "end": 4267.2, "text": " biases are emergent. Again, there are some biases that are not emergent related to Melanie's", "tokens": [50692, 32152, 366, 4345, 6930, 13, 3764, 11, 456, 366, 512, 32152, 300, 366, 406, 4345, 6930, 4077, 281, 42798, 311, 50980], "temperature": 0.0, "avg_logprob": -0.1325046799399636, "compression_ratio": 1.86, "no_speech_prob": 0.005397255532443523}, {"id": 541, "seek": 425488, "start": 4268.4800000000005, "end": 4274.96, "text": " question. There are some biases that are based on information, the explicit information, but the", "tokens": [51044, 1168, 13, 821, 366, 512, 32152, 300, 366, 2361, 322, 1589, 11, 264, 13691, 1589, 11, 457, 264, 51368], "temperature": 0.0, "avg_logprob": -0.1325046799399636, "compression_ratio": 1.86, "no_speech_prob": 0.005397255532443523}, {"id": 542, "seek": 425488, "start": 4274.96, "end": 4281.68, "text": " ones that we are able to handle are the ones that are emergent from experience. And yeah,", "tokens": [51368, 2306, 300, 321, 366, 1075, 281, 4813, 366, 264, 2306, 300, 366, 4345, 6930, 490, 1752, 13, 400, 1338, 11, 51704], "temperature": 0.0, "avg_logprob": -0.1325046799399636, "compression_ratio": 1.86, "no_speech_prob": 0.005397255532443523}, {"id": 543, "seek": 428168, "start": 4281.68, "end": 4287.84, "text": " we are working on that too. Yeah, it's a question about decision making and science.", "tokens": [50364, 321, 366, 1364, 322, 300, 886, 13, 865, 11, 309, 311, 257, 1168, 466, 3537, 1455, 293, 3497, 13, 50672], "temperature": 0.0, "avg_logprob": -0.16661126753863167, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0037502613849937916}, {"id": 544, "seek": 428168, "start": 4289.200000000001, "end": 4295.68, "text": " So you are trying to emulate the way people actually make decisions, but we lack a lot of", "tokens": [50740, 407, 291, 366, 1382, 281, 45497, 264, 636, 561, 767, 652, 5327, 11, 457, 321, 5011, 257, 688, 295, 51064], "temperature": 0.0, "avg_logprob": -0.16661126753863167, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0037502613849937916}, {"id": 545, "seek": 428168, "start": 4295.68, "end": 4300.400000000001, "text": " detailed knowledge. We wish we had about the neurophysiological mechanisms that realize the", "tokens": [51064, 9942, 3601, 13, 492, 3172, 321, 632, 466, 264, 16499, 950, 749, 72, 4383, 15902, 300, 4325, 264, 51300], "temperature": 0.0, "avg_logprob": -0.16661126753863167, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0037502613849937916}, {"id": 546, "seek": 428168, "start": 4300.400000000001, "end": 4306.96, "text": " procedures that make the decisions. And so you are necessarily sort of, you have to go beyond", "tokens": [51300, 13846, 300, 652, 264, 5327, 13, 400, 370, 291, 366, 4725, 1333, 295, 11, 291, 362, 281, 352, 4399, 51628], "temperature": 0.0, "avg_logprob": -0.16661126753863167, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0037502613849937916}, {"id": 547, "seek": 430696, "start": 4307.84, "end": 4310.88, "text": " that and you are making decisions that are under-determined by evidence.", "tokens": [50408, 300, 293, 291, 366, 1455, 5327, 300, 366, 833, 12, 49136, 2001, 538, 4467, 13, 50560], "temperature": 0.0, "avg_logprob": -0.15984994714910333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0046590352430939674}, {"id": 548, "seek": 430696, "start": 4311.92, "end": 4318.56, "text": " And I wonder what kind of commitments or maybe even heuristics you use when it's, you have to", "tokens": [50612, 400, 286, 2441, 437, 733, 295, 26230, 420, 1310, 754, 415, 374, 6006, 291, 764, 562, 309, 311, 11, 291, 362, 281, 50944], "temperature": 0.0, "avg_logprob": -0.15984994714910333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0046590352430939674}, {"id": 549, "seek": 430696, "start": 4318.56, "end": 4324.88, "text": " make these decisions about what kind of a learner or what kind of a decision maker a human is.", "tokens": [50944, 652, 613, 5327, 466, 437, 733, 295, 257, 33347, 420, 437, 733, 295, 257, 3537, 17127, 257, 1952, 307, 13, 51260], "temperature": 0.0, "avg_logprob": -0.15984994714910333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0046590352430939674}, {"id": 550, "seek": 430696, "start": 4326.16, "end": 4331.6, "text": " Does that question make sense? Let me try to interpret it. I am going to answer based on what", "tokens": [51324, 4402, 300, 1168, 652, 2020, 30, 961, 385, 853, 281, 7302, 309, 13, 286, 669, 516, 281, 1867, 2361, 322, 437, 51596], "temperature": 0.0, "avg_logprob": -0.15984994714910333, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0046590352430939674}, {"id": 551, "seek": 433160, "start": 4331.6, "end": 4341.92, "text": " I understood. Our type of modeling is symbolic. And so what that means is I don't really go into", "tokens": [50364, 286, 7320, 13, 2621, 2010, 295, 15983, 307, 25755, 13, 400, 370, 437, 300, 1355, 307, 286, 500, 380, 534, 352, 666, 50880], "temperature": 0.0, "avg_logprob": -0.1710183305560418, "compression_ratio": 1.3133333333333332, "no_speech_prob": 0.0013175051426514983}, {"id": 552, "seek": 433160, "start": 4341.92, "end": 4352.160000000001, "text": " the neuro part of it. ATAR, that's right. In my personal opinion, that is why it became very complex", "tokens": [50880, 264, 16499, 644, 295, 309, 13, 8872, 1899, 11, 300, 311, 558, 13, 682, 452, 2973, 4800, 11, 300, 307, 983, 309, 3062, 588, 3997, 51392], "temperature": 0.0, "avg_logprob": -0.1710183305560418, "compression_ratio": 1.3133333333333332, "no_speech_prob": 0.0013175051426514983}, {"id": 553, "seek": 435216, "start": 4352.88, "end": 4361.92, "text": " because now ATAR is trying to map particular mechanisms to activation in certain part of the", "tokens": [50400, 570, 586, 8872, 1899, 307, 1382, 281, 4471, 1729, 15902, 281, 24433, 294, 1629, 644, 295, 264, 50852], "temperature": 0.0, "avg_logprob": -0.15193419022993607, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.029951056465506554}, {"id": 554, "seek": 435216, "start": 4361.92, "end": 4368.88, "text": " brains. While that can be very important and necessary, that is not what I do. So I stay at", "tokens": [50852, 15442, 13, 3987, 300, 393, 312, 588, 1021, 293, 4818, 11, 300, 307, 406, 437, 286, 360, 13, 407, 286, 1754, 412, 51200], "temperature": 0.0, "avg_logprob": -0.15193419022993607, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.029951056465506554}, {"id": 555, "seek": 435216, "start": 4368.88, "end": 4375.44, "text": " this symbolic level. So that is one thing, but there was another part in your question.", "tokens": [51200, 341, 25755, 1496, 13, 407, 300, 307, 472, 551, 11, 457, 456, 390, 1071, 644, 294, 428, 1168, 13, 51528], "temperature": 0.0, "avg_logprob": -0.15193419022993607, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.029951056465506554}, {"id": 556, "seek": 437544, "start": 4376.4, "end": 4381.759999999999, "text": " I know Kelly, you will meet with Koti now. Maybe these two guys could go.", "tokens": [50412, 286, 458, 12345, 11, 291, 486, 1677, 365, 591, 8206, 586, 13, 2704, 613, 732, 1074, 727, 352, 13, 50680], "temperature": 0.0, "avg_logprob": -0.3106233596801758, "compression_ratio": 1.4834123222748816, "no_speech_prob": 0.018438126891851425}, {"id": 557, "seek": 437544, "start": 4382.799999999999, "end": 4384.96, "text": " Because maybe you would not be able to talk for a while.", "tokens": [50732, 1436, 1310, 291, 576, 406, 312, 1075, 281, 751, 337, 257, 1339, 13, 50840], "temperature": 0.0, "avg_logprob": -0.3106233596801758, "compression_ratio": 1.4834123222748816, "no_speech_prob": 0.018438126891851425}, {"id": 558, "seek": 437544, "start": 4386.879999999999, "end": 4394.48, "text": " Unfortunately, my afternoon is full. So here's my question. So one way to learn to imitate", "tokens": [50936, 8590, 11, 452, 6499, 307, 1577, 13, 407, 510, 311, 452, 1168, 13, 407, 472, 636, 281, 1466, 281, 35556, 51316], "temperature": 0.0, "avg_logprob": -0.3106233596801758, "compression_ratio": 1.4834123222748816, "no_speech_prob": 0.018438126891851425}, {"id": 559, "seek": 437544, "start": 4394.48, "end": 4399.36, "text": " human decision makers would be machine learning. And I know some people are doing that too.", "tokens": [51316, 1952, 3537, 19323, 576, 312, 3479, 2539, 13, 400, 286, 458, 512, 561, 366, 884, 300, 886, 13, 51560], "temperature": 0.0, "avg_logprob": -0.3106233596801758, "compression_ratio": 1.4834123222748816, "no_speech_prob": 0.018438126891851425}, {"id": 560, "seek": 439936, "start": 4400.08, "end": 4405.2, "text": " And just treat the human's behavior as a thing to be predicted.", "tokens": [50400, 400, 445, 2387, 264, 1952, 311, 5223, 382, 257, 551, 281, 312, 19147, 13, 50656], "temperature": 0.0, "avg_logprob": -0.12414218584696451, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.00911223329603672}, {"id": 561, "seek": 439936, "start": 4407.599999999999, "end": 4413.5199999999995, "text": " And I generally much prefer mechanistic models to machine learning. On the other hand, when you", "tokens": [50776, 400, 286, 5101, 709, 4382, 4236, 3142, 5245, 281, 3479, 2539, 13, 1282, 264, 661, 1011, 11, 562, 291, 51072], "temperature": 0.0, "avg_logprob": -0.12414218584696451, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.00911223329603672}, {"id": 562, "seek": 439936, "start": 4413.5199999999995, "end": 4420.799999999999, "text": " have a mechanistic model, then you are in a position of having to either defend the specific", "tokens": [51072, 362, 257, 4236, 3142, 2316, 11, 550, 291, 366, 294, 257, 2535, 295, 1419, 281, 2139, 8602, 264, 2685, 51436], "temperature": 0.0, "avg_logprob": -0.12414218584696451, "compression_ratio": 1.5089820359281436, "no_speech_prob": 0.00911223329603672}, {"id": 563, "seek": 442080, "start": 4420.88, "end": 4431.76, "text": " mechanism or argue that you're only trying to understand the typical behavior of a wide", "tokens": [50368, 7513, 420, 9695, 300, 291, 434, 787, 1382, 281, 1223, 264, 7476, 5223, 295, 257, 4874, 50912], "temperature": 0.0, "avg_logprob": -0.12118488369566022, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.017680132761597633}, {"id": 564, "seek": 442080, "start": 4431.76, "end": 4437.52, "text": " variety of mechanisms. So when I look at the model, the mathematical model you showed,", "tokens": [50912, 5673, 295, 15902, 13, 407, 562, 286, 574, 412, 264, 2316, 11, 264, 18894, 2316, 291, 4712, 11, 51200], "temperature": 0.0, "avg_logprob": -0.12118488369566022, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.017680132761597633}, {"id": 565, "seek": 442080, "start": 4438.8, "end": 4443.6, "text": " and maybe there's something I'm missing, I'm not an expert in this area, it looked like a kind of", "tokens": [51264, 293, 1310, 456, 311, 746, 286, 478, 5361, 11, 286, 478, 406, 364, 5844, 294, 341, 1859, 11, 309, 2956, 411, 257, 733, 295, 51504], "temperature": 0.0, "avg_logprob": -0.12118488369566022, "compression_ratio": 1.4863387978142077, "no_speech_prob": 0.017680132761597633}, {"id": 566, "seek": 444360, "start": 4444.56, "end": 4451.280000000001, "text": " standard online learning model, but with the delay from time. And I know that scientists", "tokens": [50412, 3832, 2950, 2539, 2316, 11, 457, 365, 264, 8577, 490, 565, 13, 400, 286, 458, 300, 7708, 50748], "temperature": 0.0, "avg_logprob": -0.22965591709788252, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.013003326952457428}, {"id": 567, "seek": 444360, "start": 4451.280000000001, "end": 4457.360000000001, "text": " have tried to figure out, do people forget things exponentially fast, or is it a power law, etc.", "tokens": [50748, 362, 3031, 281, 2573, 484, 11, 360, 561, 2870, 721, 37330, 2370, 11, 420, 307, 309, 257, 1347, 2101, 11, 5183, 13, 51052], "temperature": 0.0, "avg_logprob": -0.22965591709788252, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.013003326952457428}, {"id": 568, "seek": 444360, "start": 4458.88, "end": 4464.88, "text": " But then at least some of the examples you showed, like shifting this one where the", "tokens": [51128, 583, 550, 412, 1935, 512, 295, 264, 5110, 291, 4712, 11, 411, 17573, 341, 472, 689, 264, 51428], "temperature": 0.0, "avg_logprob": -0.22965591709788252, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.013003326952457428}, {"id": 569, "seek": 444360, "start": 4464.88, "end": 4473.200000000001, "text": " expected outcomes of the two alternatives were changing. Honestly, I felt like a very", "tokens": [51428, 5176, 10070, 295, 264, 732, 20478, 645, 4473, 13, 12348, 11, 286, 2762, 411, 257, 588, 51844], "temperature": 0.0, "avg_logprob": -0.22965591709788252, "compression_ratio": 1.5434782608695652, "no_speech_prob": 0.013003326952457428}, {"id": 570, "seek": 447320, "start": 4473.2, "end": 4481.12, "text": " wide variety of models that would update their behavior and forget old data to some extent", "tokens": [50364, 4874, 5673, 295, 5245, 300, 576, 5623, 641, 5223, 293, 2870, 1331, 1412, 281, 512, 8396, 50760], "temperature": 0.0, "avg_logprob": -0.09148958325386047, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010150737361982465}, {"id": 571, "seek": 447320, "start": 4481.12, "end": 4489.84, "text": " would have produced very similar things. So that made me not so convinced that the specific", "tokens": [50760, 576, 362, 7126, 588, 2531, 721, 13, 407, 300, 1027, 385, 406, 370, 12561, 300, 264, 2685, 51196], "temperature": 0.0, "avg_logprob": -0.09148958325386047, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010150737361982465}, {"id": 572, "seek": 447320, "start": 4489.84, "end": 4497.36, "text": " mechanistic model you wrote down is really the right one. Although certainly some aspects of it,", "tokens": [51196, 4236, 3142, 2316, 291, 4114, 760, 307, 534, 264, 558, 472, 13, 5780, 3297, 512, 7270, 295, 309, 11, 51572], "temperature": 0.0, "avg_logprob": -0.09148958325386047, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010150737361982465}, {"id": 573, "seek": 447320, "start": 4497.36, "end": 4501.84, "text": " like forgetting the past so you can learn about new things, is surely part of it.", "tokens": [51572, 411, 25428, 264, 1791, 370, 291, 393, 1466, 466, 777, 721, 11, 307, 11468, 644, 295, 309, 13, 51796], "temperature": 0.0, "avg_logprob": -0.09148958325386047, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010150737361982465}, {"id": 574, "seek": 450184, "start": 4501.92, "end": 4508.96, "text": " But I guess that on the other hand, when I think about humans in dynamic situations,", "tokens": [50368, 583, 286, 2041, 300, 322, 264, 661, 1011, 11, 562, 286, 519, 466, 6255, 294, 8546, 6851, 11, 50720], "temperature": 0.0, "avg_logprob": -0.15871286392211914, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.0019242471316829324}, {"id": 575, "seek": 450184, "start": 4510.96, "end": 4518.56, "text": " I think that their notion of similarity can be much more general than, for instance,", "tokens": [50820, 286, 519, 300, 641, 10710, 295, 32194, 393, 312, 709, 544, 2674, 813, 11, 337, 5197, 11, 51200], "temperature": 0.0, "avg_logprob": -0.15871286392211914, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.0019242471316829324}, {"id": 576, "seek": 450184, "start": 4518.56, "end": 4524.8, "text": " looking at kind of individual attributes of the instance. People do all kinds of analogy making", "tokens": [51200, 1237, 412, 733, 295, 2609, 17212, 295, 264, 5197, 13, 3432, 360, 439, 3685, 295, 21663, 1455, 51512], "temperature": 0.0, "avg_logprob": -0.15871286392211914, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.0019242471316829324}, {"id": 577, "seek": 450184, "start": 4524.8, "end": 4530.400000000001, "text": " and, you know, like, oh, that bit of grass which is still smoldering, which might flare up again.", "tokens": [51512, 293, 11, 291, 458, 11, 411, 11, 1954, 11, 300, 857, 295, 8054, 597, 307, 920, 899, 2641, 1794, 11, 597, 1062, 32446, 493, 797, 13, 51792], "temperature": 0.0, "avg_logprob": -0.15871286392211914, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.0019242471316829324}, {"id": 578, "seek": 453040, "start": 4530.96, "end": 4535.2, "text": " Oh, that's kind of like there might be a tiger there, or it's kind of like", "tokens": [50392, 876, 11, 300, 311, 733, 295, 411, 456, 1062, 312, 257, 21432, 456, 11, 420, 309, 311, 733, 295, 411, 50604], "temperature": 0.0, "avg_logprob": -0.15039764038503986, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.002712871180847287}, {"id": 579, "seek": 453040, "start": 4536.08, "end": 4543.92, "text": " maybe there's an ambush being played by my enemies or whatever. So I don't know, the mechanism seems", "tokens": [50648, 1310, 456, 311, 364, 38143, 885, 3737, 538, 452, 7805, 420, 2035, 13, 407, 286, 500, 380, 458, 11, 264, 7513, 2544, 51040], "temperature": 0.0, "avg_logprob": -0.15039764038503986, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.002712871180847287}, {"id": 580, "seek": 453040, "start": 4545.679999999999, "end": 4555.04, "text": " both impoverished in a way, and maybe over committed to specificity in a way. So at the same", "tokens": [51128, 1293, 704, 3570, 4729, 294, 257, 636, 11, 293, 1310, 670, 7784, 281, 2685, 507, 294, 257, 636, 13, 407, 412, 264, 912, 51596], "temperature": 0.0, "avg_logprob": -0.15039764038503986, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.002712871180847287}, {"id": 581, "seek": 455504, "start": 4555.84, "end": 4559.12, "text": " time, I'm glad that you're doing something mechanistic instead of just saying,", "tokens": [50404, 565, 11, 286, 478, 5404, 300, 291, 434, 884, 746, 4236, 3142, 2602, 295, 445, 1566, 11, 50568], "temperature": 0.0, "avg_logprob": -0.19185282276794974, "compression_ratio": 1.6213235294117647, "no_speech_prob": 0.011281867511570454}, {"id": 582, "seek": 455504, "start": 4559.84, "end": 4563.68, "text": " I'll have a year old network, watch for human, and then predict what the human would do,", "tokens": [50604, 286, 603, 362, 257, 1064, 1331, 3209, 11, 1159, 337, 1952, 11, 293, 550, 6069, 437, 264, 1952, 576, 360, 11, 50796], "temperature": 0.0, "avg_logprob": -0.19185282276794974, "compression_ratio": 1.6213235294117647, "no_speech_prob": 0.011281867511570454}, {"id": 583, "seek": 455504, "start": 4564.4, "end": 4570.48, "text": " which is the kind of thing which is far too popular nowadays. So I'm such a long question,", "tokens": [50832, 597, 307, 264, 733, 295, 551, 597, 307, 1400, 886, 3743, 13434, 13, 407, 286, 478, 1270, 257, 938, 1168, 11, 51136], "temperature": 0.0, "avg_logprob": -0.19185282276794974, "compression_ratio": 1.6213235294117647, "no_speech_prob": 0.011281867511570454}, {"id": 584, "seek": 455504, "start": 4570.48, "end": 4576.96, "text": " and maybe it's a long answer. No, I love these type of questions. Let me just answer with what", "tokens": [51136, 293, 1310, 309, 311, 257, 938, 1867, 13, 883, 11, 286, 959, 613, 2010, 295, 1651, 13, 961, 385, 445, 1867, 365, 437, 51460], "temperature": 0.0, "avg_logprob": -0.19185282276794974, "compression_ratio": 1.6213235294117647, "no_speech_prob": 0.011281867511570454}, {"id": 585, "seek": 455504, "start": 4576.96, "end": 4583.76, "text": " other two people have said. The first one is all models are wrong, right? And I totally", "tokens": [51460, 661, 732, 561, 362, 848, 13, 440, 700, 472, 307, 439, 5245, 366, 2085, 11, 558, 30, 400, 286, 3879, 51800], "temperature": 0.0, "avg_logprob": -0.19185282276794974, "compression_ratio": 1.6213235294117647, "no_speech_prob": 0.011281867511570454}, {"id": 586, "seek": 458504, "start": 4585.92, "end": 4594.24, "text": " no accept a priority that this model cannot be perfect in any way, right? So all models are", "tokens": [50408, 572, 3241, 257, 9365, 300, 341, 2316, 2644, 312, 2176, 294, 604, 636, 11, 558, 30, 407, 439, 5245, 366, 50824], "temperature": 0.0, "avg_logprob": -0.09860087765587701, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0009341861004941165}, {"id": 587, "seek": 458504, "start": 4594.24, "end": 4600.32, "text": " wrong, but some models are useful. So I like to concentrate on the usefulness of these models,", "tokens": [50824, 2085, 11, 457, 512, 5245, 366, 4420, 13, 407, 286, 411, 281, 18089, 322, 264, 4420, 1287, 295, 613, 5245, 11, 51128], "temperature": 0.0, "avg_logprob": -0.09860087765587701, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0009341861004941165}, {"id": 588, "seek": 458504, "start": 4600.32, "end": 4609.36, "text": " what it can teach us, what it can do, right? And then the other quote is about using models as", "tokens": [51128, 437, 309, 393, 2924, 505, 11, 437, 309, 393, 360, 11, 558, 30, 400, 550, 264, 661, 6513, 307, 466, 1228, 5245, 382, 51580], "temperature": 0.0, "avg_logprob": -0.09860087765587701, "compression_ratio": 1.6242774566473988, "no_speech_prob": 0.0009341861004941165}, {"id": 589, "seek": 460936, "start": 4609.36, "end": 4617.28, "text": " your toothbrush. And yes, we have the tendency to use our models only and forget about other people's", "tokens": [50364, 428, 37568, 13, 400, 2086, 11, 321, 362, 264, 18187, 281, 764, 527, 5245, 787, 293, 2870, 466, 661, 561, 311, 50760], "temperature": 0.0, "avg_logprob": -0.10944294929504395, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.008038366213440895}, {"id": 590, "seek": 460936, "start": 4617.28, "end": 4628.799999999999, "text": " models. We have done comparison, model comparison, and there are including a site review paper of", "tokens": [50760, 5245, 13, 492, 362, 1096, 9660, 11, 2316, 9660, 11, 293, 456, 366, 3009, 257, 3621, 3131, 3035, 295, 51336], "temperature": 0.0, "avg_logprob": -0.10944294929504395, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.008038366213440895}, {"id": 591, "seek": 460936, "start": 4628.799999999999, "end": 4634.96, "text": " the comparison of our model with another 16 models. I mean, the proliferation of models", "tokens": [51336, 264, 9660, 295, 527, 2316, 365, 1071, 3165, 5245, 13, 286, 914, 11, 264, 24398, 44987, 295, 5245, 51644], "temperature": 0.0, "avg_logprob": -0.10944294929504395, "compression_ratio": 1.6306818181818181, "no_speech_prob": 0.008038366213440895}, {"id": 592, "seek": 463496, "start": 4634.96, "end": 4641.52, "text": " for this kind of thing is huge, right? So many. But there was a competition, modeling competition,", "tokens": [50364, 337, 341, 733, 295, 551, 307, 2603, 11, 558, 30, 407, 867, 13, 583, 456, 390, 257, 6211, 11, 15983, 6211, 11, 50692], "temperature": 0.0, "avg_logprob": -0.1007181779662175, "compression_ratio": 1.7378048780487805, "no_speech_prob": 0.0013137880014255643}, {"id": 593, "seek": 463496, "start": 4642.24, "end": 4648.72, "text": " and we tested our model against the winners of that competition and many other of the more", "tokens": [50728, 293, 321, 8246, 527, 2316, 1970, 264, 17193, 295, 300, 6211, 293, 867, 661, 295, 264, 544, 51052], "temperature": 0.0, "avg_logprob": -0.1007181779662175, "compression_ratio": 1.7378048780487805, "no_speech_prob": 0.0013137880014255643}, {"id": 594, "seek": 463496, "start": 4648.72, "end": 4655.92, "text": " typical models. And our model comes to be more general, and it comes to be more predictive than", "tokens": [51052, 7476, 5245, 13, 400, 527, 2316, 1487, 281, 312, 544, 2674, 11, 293, 309, 1487, 281, 312, 544, 35521, 813, 51412], "temperature": 0.0, "avg_logprob": -0.1007181779662175, "compression_ratio": 1.7378048780487805, "no_speech_prob": 0.0013137880014255643}, {"id": 595, "seek": 465592, "start": 4656.0, "end": 4665.52, "text": " most of them. So again, am I using my own toothbrush? Maybe. I like to use my own toothbrush.", "tokens": [50368, 881, 295, 552, 13, 407, 797, 11, 669, 286, 1228, 452, 1065, 37568, 30, 2704, 13, 286, 411, 281, 764, 452, 1065, 37568, 13, 50844], "temperature": 0.0, "avg_logprob": -0.11336307525634766, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.00511782756075263}, {"id": 596, "seek": 465592, "start": 4666.16, "end": 4673.4400000000005, "text": " The other part is regarding the machine learning. Yeah, I think human likeness depends on what you", "tokens": [50876, 440, 661, 644, 307, 8595, 264, 3479, 2539, 13, 865, 11, 286, 519, 1952, 36946, 442, 5946, 322, 437, 291, 51240], "temperature": 0.0, "avg_logprob": -0.11336307525634766, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.00511782756075263}, {"id": 597, "seek": 465592, "start": 4673.4400000000005, "end": 4681.6, "text": " want to do, right? So if you just want to predict a particular outcome, of course, having a large", "tokens": [51240, 528, 281, 360, 11, 558, 30, 407, 498, 291, 445, 528, 281, 6069, 257, 1729, 9700, 11, 295, 1164, 11, 1419, 257, 2416, 51648], "temperature": 0.0, "avg_logprob": -0.11336307525634766, "compression_ratio": 1.4948453608247423, "no_speech_prob": 0.00511782756075263}, {"id": 598, "seek": 468160, "start": 4681.6, "end": 4689.68, "text": " amount of data can help. As I said, everything I presented is predictions from theory. I didn't", "tokens": [50364, 2372, 295, 1412, 393, 854, 13, 1018, 286, 848, 11, 1203, 286, 8212, 307, 21264, 490, 5261, 13, 286, 994, 380, 50768], "temperature": 0.0, "avg_logprob": -0.1231431289457939, "compression_ratio": 1.5, "no_speech_prob": 0.012059503234922886}, {"id": 599, "seek": 468160, "start": 4689.68, "end": 4696.400000000001, "text": " use any data before I made the predictions. No human machine learning algorithm would be able", "tokens": [50768, 764, 604, 1412, 949, 286, 1027, 264, 21264, 13, 883, 1952, 3479, 2539, 9284, 576, 312, 1075, 51104], "temperature": 0.0, "avg_logprob": -0.1231431289457939, "compression_ratio": 1.5, "no_speech_prob": 0.012059503234922886}, {"id": 600, "seek": 468160, "start": 4696.400000000001, "end": 4701.92, "text": " to do that. They need the data. In fact, the less data they have, the worse they are, right?", "tokens": [51104, 281, 360, 300, 13, 814, 643, 264, 1412, 13, 682, 1186, 11, 264, 1570, 1412, 436, 362, 11, 264, 5324, 436, 366, 11, 558, 30, 51380], "temperature": 0.0, "avg_logprob": -0.1231431289457939, "compression_ratio": 1.5, "no_speech_prob": 0.012059503234922886}, {"id": 601, "seek": 470192, "start": 4702.4800000000005, "end": 4705.68, "text": " Okay. Thank you. Thanks for your time.", "tokens": [50392, 1033, 13, 1044, 291, 13, 2561, 337, 428, 565, 13, 50552], "temperature": 0.0, "avg_logprob": -0.2115483003504136, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.04037543013691902}, {"id": 602, "seek": 470192, "start": 4709.6, "end": 4713.4400000000005, "text": " I want to ask, in a different way, the same question that was already asked three times", "tokens": [50748, 286, 528, 281, 1029, 11, 294, 257, 819, 636, 11, 264, 912, 1168, 300, 390, 1217, 2351, 1045, 1413, 50940], "temperature": 0.0, "avg_logprob": -0.2115483003504136, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.04037543013691902}, {"id": 603, "seek": 470192, "start": 4713.4400000000005, "end": 4718.0, "text": " at the beginning, which is the question of ethics. Because, well, two things. It seems that this is", "tokens": [50940, 412, 264, 2863, 11, 597, 307, 264, 1168, 295, 19769, 13, 1436, 11, 731, 11, 732, 721, 13, 467, 2544, 300, 341, 307, 51168], "temperature": 0.0, "avg_logprob": -0.2115483003504136, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.04037543013691902}, {"id": 604, "seek": 470192, "start": 4718.0, "end": 4723.92, "text": " a visibly important question in decision-making and situations of warfare or juridical situations.", "tokens": [51168, 257, 1452, 3545, 1021, 1168, 294, 3537, 12, 12402, 293, 6851, 295, 24490, 420, 12721, 327, 804, 6851, 13, 51464], "temperature": 0.0, "avg_logprob": -0.2115483003504136, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.04037543013691902}, {"id": 605, "seek": 470192, "start": 4724.64, "end": 4731.76, "text": " And secondly, it belongs to philosophy, right? To the Western tradition that runs from Aristotle,", "tokens": [51500, 400, 26246, 11, 309, 12953, 281, 10675, 11, 558, 30, 1407, 264, 8724, 6994, 300, 6676, 490, 42368, 11, 51856], "temperature": 0.0, "avg_logprob": -0.2115483003504136, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.04037543013691902}, {"id": 606, "seek": 473176, "start": 4731.76, "end": 4738.0, "text": " through Emmanuel Levinas, and so on. And the one consensus that the big players within this", "tokens": [50364, 807, 44421, 1456, 4796, 296, 11, 293, 370, 322, 13, 400, 264, 472, 19115, 300, 264, 955, 4150, 1951, 341, 50676], "temperature": 0.0, "avg_logprob": -0.1675585897345292, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.0022030805703252554}, {"id": 607, "seek": 473176, "start": 4738.0, "end": 4744.08, "text": " tradition all share, it seems to me, is that from the Greek, you know, Pyrenees and their idea of", "tokens": [50676, 6994, 439, 2073, 11, 309, 2544, 281, 385, 11, 307, 300, 490, 264, 10281, 11, 291, 458, 11, 9953, 32252, 279, 293, 641, 1558, 295, 50980], "temperature": 0.0, "avg_logprob": -0.1675585897345292, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.0022030805703252554}, {"id": 608, "seek": 473176, "start": 4744.08, "end": 4751.04, "text": " Epoche is as vertiginous suspension of all decidability all the way through to Walter Benjamin's", "tokens": [50980, 462, 2259, 1876, 307, 382, 6509, 328, 259, 563, 15771, 295, 439, 21937, 2310, 439, 264, 636, 807, 281, 21572, 22231, 311, 51328], "temperature": 0.0, "avg_logprob": -0.1675585897345292, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.0022030805703252554}, {"id": 609, "seek": 473176, "start": 4751.04, "end": 4760.8, "text": " idea of mystical origins of justice. The consensus seems to be that the ethical or just decision", "tokens": [51328, 1558, 295, 40565, 22721, 295, 6118, 13, 440, 19115, 2544, 281, 312, 300, 264, 18890, 420, 445, 3537, 51816], "temperature": 0.0, "avg_logprob": -0.1675585897345292, "compression_ratio": 1.6092436974789917, "no_speech_prob": 0.0022030805703252554}, {"id": 610, "seek": 476080, "start": 4760.8, "end": 4769.360000000001, "text": " can only come from a place of radical undecidability, right? From non-calculability, right? Law is", "tokens": [50364, 393, 787, 808, 490, 257, 1081, 295, 12001, 674, 3045, 327, 2310, 11, 558, 30, 3358, 2107, 12, 9895, 2444, 2310, 11, 558, 30, 7744, 307, 50792], "temperature": 0.0, "avg_logprob": -0.07045167119879471, "compression_ratio": 1.8078817733990147, "no_speech_prob": 0.001690988545306027}, {"id": 611, "seek": 476080, "start": 4769.360000000001, "end": 4776.24, "text": " about calculus, but justice comes from the incalculable. So, in that sense, the distinction", "tokens": [50792, 466, 33400, 11, 457, 6118, 1487, 490, 264, 834, 304, 2444, 712, 13, 407, 11, 294, 300, 2020, 11, 264, 16844, 51136], "temperature": 0.0, "avg_logprob": -0.07045167119879471, "compression_ratio": 1.8078817733990147, "no_speech_prob": 0.001690988545306027}, {"id": 612, "seek": 476080, "start": 4776.24, "end": 4781.4400000000005, "text": " to be made would not be between humans and machines. It would be between calculability", "tokens": [51136, 281, 312, 1027, 576, 406, 312, 1296, 6255, 293, 8379, 13, 467, 576, 312, 1296, 4322, 2310, 51396], "temperature": 0.0, "avg_logprob": -0.07045167119879471, "compression_ratio": 1.8078817733990147, "no_speech_prob": 0.001690988545306027}, {"id": 613, "seek": 476080, "start": 4781.4400000000005, "end": 4788.08, "text": " and non-calculability. If you can calculate ethics or justice, it's not ethics or justice", "tokens": [51396, 293, 2107, 12, 9895, 2444, 2310, 13, 759, 291, 393, 8873, 19769, 420, 6118, 11, 309, 311, 406, 19769, 420, 6118, 51728], "temperature": 0.0, "avg_logprob": -0.07045167119879471, "compression_ratio": 1.8078817733990147, "no_speech_prob": 0.001690988545306027}, {"id": 614, "seek": 478808, "start": 4788.08, "end": 4794.8, "text": " anymore. It's just control, right? I just wanted, that would be the provocation I would put to you", "tokens": [50364, 3602, 13, 467, 311, 445, 1969, 11, 558, 30, 286, 445, 1415, 11, 300, 576, 312, 264, 24568, 399, 286, 576, 829, 281, 291, 50700], "temperature": 0.0, "avg_logprob": -0.17853291829427084, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008685662411153316}, {"id": 615, "seek": 478808, "start": 4795.44, "end": 4800.4, "text": " in the name of philosophy, right? So, it's a different language game that we're working", "tokens": [50732, 294, 264, 1315, 295, 10675, 11, 558, 30, 407, 11, 309, 311, 257, 819, 2856, 1216, 300, 321, 434, 1364, 50980], "temperature": 0.0, "avg_logprob": -0.17853291829427084, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008685662411153316}, {"id": 616, "seek": 478808, "start": 4800.4, "end": 4805.04, "text": " at using. As soon as you deal with ethics, necessarily you're taking that on board, right?", "tokens": [50980, 412, 1228, 13, 1018, 2321, 382, 291, 2028, 365, 19769, 11, 4725, 291, 434, 1940, 300, 322, 3150, 11, 558, 30, 51212], "temperature": 0.0, "avg_logprob": -0.17853291829427084, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008685662411153316}, {"id": 617, "seek": 478808, "start": 4805.04, "end": 4811.84, "text": " I think that is a world or a controlled world. I guess that is a philosophical question", "tokens": [51212, 286, 519, 300, 307, 257, 1002, 420, 257, 10164, 1002, 13, 286, 2041, 300, 307, 257, 25066, 1168, 51552], "temperature": 0.0, "avg_logprob": -0.17853291829427084, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008685662411153316}, {"id": 618, "seek": 481184, "start": 4811.92, "end": 4819.2, "text": " for our model to be able to account for ethical issues. There needs to be", "tokens": [50368, 337, 527, 2316, 281, 312, 1075, 281, 2696, 337, 18890, 2663, 13, 821, 2203, 281, 312, 50732], "temperature": 0.0, "avg_logprob": -0.16975588876692976, "compression_ratio": 1.4817073170731707, "no_speech_prob": 0.010677523910999298}, {"id": 619, "seek": 481184, "start": 4819.2, "end": 4832.16, "text": " calculability. And so, you know, philosophically, that moves us out of the ethics realm. I would", "tokens": [50732, 4322, 2310, 13, 400, 370, 11, 291, 458, 11, 14529, 984, 11, 300, 6067, 505, 484, 295, 264, 19769, 15355, 13, 286, 576, 51380], "temperature": 0.0, "avg_logprob": -0.16975588876692976, "compression_ratio": 1.4817073170731707, "no_speech_prob": 0.010677523910999298}, {"id": 620, "seek": 481184, "start": 4832.16, "end": 4836.56, "text": " accept it because there is nothing else we can do without calculability.", "tokens": [51380, 3241, 309, 570, 456, 307, 1825, 1646, 321, 393, 360, 1553, 4322, 2310, 13, 51600], "temperature": 0.0, "avg_logprob": -0.16975588876692976, "compression_ratio": 1.4817073170731707, "no_speech_prob": 0.010677523910999298}, {"id": 621, "seek": 483656, "start": 4836.56, "end": 4839.280000000001, "text": " Thank you very much.", "tokens": [50400, 1044, 291, 588, 709, 13, 50500], "temperature": 0.0, "avg_logprob": -0.4324710965156555, "compression_ratio": 0.7142857142857143, "no_speech_prob": 0.0476224459707737}], "language": "en"}