Are you still a reader in mathematical neuroscience? Is that still accurate?
I've changed all our titles a little bit. Okay, so a man of many titles.
Whatever I was at Bristol, I know you were the head of the Computational Neuroscience Unit,
and he was also an examiner for my PhD five. So super, super happy to have him here today.
Thank you, Connor. Brilliant. Sorry, one second. Cool. Well, I'm super excited to be here. This has
always been kind of a legendary location for me. I've always wanted to visit, and
it's really blown me away. It's an amazing looking place. It's my first time in New Mexico, and oh
my god, the countryside here is just incredible. I assume that it's traditional to start talks here
with some reminiscence about the time that you met Murray Gaumann. So I met Murray Gaumann 20
years ago. I was still a particle physicist then. He was coming through 20 College Dublin,
where I was working at the time, and he asked me where I was from, and I said I'm from Galway,
which is true. And he said, oh yes, Galway, home of this, Galway, off whose coast the Spanish Armada
founded in the storm, saving the British Navy the trouble of sinking it. Home too, he said,
to the myth that the lusty sailors thus wrecked, swam ashore, and bred with the local women to
create the black haired Irish. Something he said that is not true, the black haired Irish are
presumably the remnants of the indigenous population, the population there before
and accounts of population whose traditions and cultures we know from archaeology,
but whose language is wholly lost and unknown. And I was just incredibly impressed by the whole
thing. I mean, he knew where Galway was. He knew that we had this link with Spain. He knew about
the Spanish Armada sinking. He knew that we all believed, as it turns out incorrectly, that the
Spanish sailors had created these sort of black haired folk in Galway. And he told me this
interesting thing about how these black haired folk are probably the remnants of the indigenous
population. And I was always intrigued by this idea that there was a language that they spoke,
which is now completely lost. The idea of these completely lost languages is lovely.
It also struck me with something of a show off, but that's true too. But it was very impressive.
And so I'm very, very, very glad to be in the Murray Gilman building. I was, I did start life
as a particle physicist and then became a neuroscientist and only started working on language
recently. So I don't know that much about it. But the reason I started working on language was I
read this kind of bizarre quote from Novichonsky, which says, in their essential properties,
and even down to fine details, languages are cast in the same mold. At the Martian scientists,
my reasons we conclude that there's a single human language with differences only at the margins.
And that just seemed so, so wrong to me. And, you know, I thought
that maybe that is an accident of not, you know, thinking about how different languages are. It
seemed to me, you know, the languages are incredibly different from each other. And I'm
looking with where I'm from to know a little bit of Irish. And Irish is, you know, although an
inter-European language is more different to, you know, English than maybe French and so on is.
I mean, for starters, it has a different word order. One of the more striking features is the,
it doesn't have a verb possession. So here, this is the Irish for, I have a newspaper, Thon,
Newton, Ogham. And what's happening there is that there's no, the Thon is just the verb is. So the
literal translation of that sentence is the newspaper is at me. The Ogham is a preposition
combined with the pronoun, which is a feature of Irish. And prepositions do a lot of work in Irish
that it's done by other parts of speech in other languages. So instead of saying that you have
a newspaper, you say the newspaper is at you. And similarly, Thon, Newton, Ogham, the new
newspapers from me is how you'd say that you wanted the newspaper. So it's strongly that,
you know, that languages are very different from each other. And that it's wrong to
presuppose that languages all spring from the brain in the way that Chomsky is suggesting.
Because, you know, his idea is that the languages bear the imprint of the human mechanism. Whereas,
for me, as a neuroscientist, at the time, somebody knew about how vision worked and so on,
it seemed that languages were much more likely to just be the unfolding of some
search for statistical structure. And maybe something to do with the properties of the world
around us, the fact that there are actions, and there are, and hence verbs, and there are objects,
and hence nouns. But of course, I'm no longer sure that I was right in thinking that. And I've
begun to appreciate something of the wisdom of what Chomsky said. And of course, another example
from Irish Thon, Newton Thum, the newspaper is under me. That's how you'd say the newspaper is
about me. But there you can see that even in English, the same work is being done by the
prepositional construction as is being done in the Irish. In other words, although, you know,
the Irish uses a different preposition and prepositions tend to vary as you probably know
a lot from language to language. The idea of using a preposition where you might otherwise
have a different verb is not so unique to Irish. And so maybe languages are somewhat similar to
each other. And it struck me, or strikes me, as I'm sure it strikes you, that this is a really
important question. I love this sign because it says that the vehicles will be prosecuted without
warning. But this is a warning sign. So of course, it makes it impossible for them to do that.
And I have here started to remind me to comment on the idea that language is complicated because
some aspects of language are to do with what's in the world. The structure of language is structured
by its use case, by communication. And some parts of language presumably are to do with the
human ability to communicate, or our ability to perceive, or the calculations we do in
producing, interpreting meaning and in producing meaning. And some parts might be more idiosyncratic
to do with some linguistic mechanism. And deciding between these, deciding, you know,
recognizing the fact that we can say something like this, which logically makes no sense at all,
but which, you know, in a Wisconsinian fashion, quite clearly communicates something. It is a
property, you know, is something that's deeply rooted in who we are, and our language is a part
of how we conceive of ourselves as conscious individuals. And separating what's special
about language, what's special about us, what's special about, with, you know, what language
necessarily has as a communication medium, seems an interesting and an important challenge.
So, of course, as a neuroscientist, when I decided I was interested in this, the first
inclination was to do EEG experiments. And I wanted to start talking a little bit about that
before talking a little bit more about models of language evolution. I started off actually
trying to do EEG experiments on Irish speakers. I don't know how much you know about Ireland
that Irish speakers, but it turns out that trying to do EEG experiments on Irish speakers
is very difficult, because lots of people who claim they can speak Irish actually really can't.
As I did a whole series of experiments on people who claim they can speak Irish and
discovered, in fact, the EEG just told me that they were lying. So I went back to working on
English speakers. And I was interested in testing this idea that the brain does privilege grammatical
structure over mere statistical structure. Now, if any of you have done EEG experiments,
you'll know just how damn difficult they are. I mean, the idea that we detect
electrical fields outside the brain is actually slightly surprising, because you'd expect
all the electrical fields to cancel out. And the only reason we can detect anything at all
is that there's a slight preponderance of synapses pointing one way around another.
And then, of course, you bathe the whole thing in salty fluid, which makes it hard to detect
anything. For cognitive experiments, the difficulty is still greater still. And I'll refer to this a
few times. This EEG data is obviously showing somebody having an epileptic fit and they were
induced by tooth brushing, so they started brushing their teeth, and here they have the fit.
And you can see that it's a very pronounced activity. But for cognitive tasks, of course,
not only is the activity not so pronounced, I mean, epilepsy is distinguished by the
synchrony of neural activity. So that's exactly the thing that's recently easy to detect.
Cognitive things aren't so distinguished. And secondly, of course, when you're
doing an EEG experiment, when you're a participant, you tend to sort of think other things. You're
there, the stimulus is being played to you. You're supposed to be thinking about the stimulus,
but in fact, you're thinking, oh my god, I wish I wasn't doing this experiment anymore. Oh my god,
this is really boring. Oh my god, all people are immortal. I'm going to die someday. I wonder
what I'll have for dinner. I mean, it's very hard to detect cognitive stuff with EEG. So
the thing that we did, again, following a paradigm that was introduced by David Peeble and Naiding
and his co-workers, was a frequency tag experiment. So in a frequency tag experiment, to try and
separate a signal from noise, you concentrate your stimulus at a particular frequency. And so that
you know, noise tends to stuff that you're not interested in, people thinking about their mortal
end or the end of the experiment, that happens at all sorts of frequencies. But if your stimulus
is at a particular frequency, then you can use Fourier transform or whatever to concentrate
on the thing that you're interested in. So in this experiment, we play people
adjective noun sentences. We've choose the adjectives and nouns, so they're single syllable.
We record them and then coerce them a little bit so they're all exactly the same length.
We play the syllables at 3.125 hertz. That just turns out to be a particularly good
frequency for, it's a comfortable frequency for listening to syllables. We have long, long streams
of these things. I mean, we have old rats, that man, ill wife. It goes on and on forever.
And we choose the adjective nouns quite carefully so that the
bigrams between old and rat and rat and sad are roughly the same. You can't get them exactly
the same, but you try and keep the statistical structure the same. And then what you see here
is that obviously there's going to be a response in the EG to the stimulus at 3.125 hertz. But
there's something else happening, which is the noun phrase. So if there's a response at 1.5625
hertz, that's a response to something that's not directly in the stimulus, but is related to the
meaning of the words. And what interpretation is that that's because the brain privileges noun phrases
over not noun phrases. And the other example is an adjective verb stream. In the adjective verb
stream, we make sure we have the same sort of biogram structures as we had for the adjective
noun. It's likely to come beside each other as old and man or whatever it was I had before.
But now there is no grammatical structure. So if we see a response at 1.5625 hertz
for the first stimulus and not for the second, that's indicative of the brain responding hopefully.
It's indicative to the brain privileging a grammatical structure, which was I guess the
one thing to be interested in. It turns out these data are quite hard to analyze.
You know, you think all you have to do then is take the Fourier transform and look at the size
of the peak at those particular frequencies. But EG is extremely noisy. And so if you do that,
you don't see anything. What you have to do is look for the phase locked component of the response.
So you play lots of these streams, so you make each stream five seconds long. You play repeatedly
the stream. And then you look for that portion of the response, you know, once you've taken the
transform, that portion of the response which has a similar phase. And the complication, of course,
is that the overall phase is not so important. It depends on how big your head is and where the
electrode is and all sorts of other things. And so the actual phase of people's responses
at whatever frequency, at one point, whatever it is, isn't important. And you can see that here.
So this is just each of these dots, each of these lines corresponds to a participant.
We had 16 participants in this experiment. And then for each participant, we've got all the
different electrodes. And this is the average phase of the response averaged across. It was 10 trials
for each participant for each stimulus. So this is the adjective noun, stimulus. And in the dot
is for the 32 electrodes. And just for convenience, for ease of comparison, three of the electrodes
have been picked out and are cut at the same across the participants. And basically all you can
see is that the actual overall phase is quite different. And so what's interesting is, you
know, each of these dots hides the fact that there's 20 trials. Each trial has its own phase.
And the signal is in the degree of alignment of that phase. And so to analyze these data,
well, the easiest way to do it, it turns out, is to make some complicated Bayesian models. So we
imagine the phase is being drawn from some distribution. In this case, it's circular
Cauchy distribution, which turns out to be the nicest. The circular Cauchy distribution is quite
cool. It's just a wrapped Cauchy distribution. And when you do the wrapping, you can set some
of the theories and come up with an analytic formula for it. You say the data is kind of noisy,
right? Immensely. Yeah. So the Fourier transform is also like pretty noisy.
Yes. Yes. So you have to go through several steps. So, you know, obviously,
for start using the frequency tag experiment makes it less noisy because, you know, the other stuff
is happening at different frequencies. But even then you have to do this sort of phase lock analysis,
which I'm briefly reviewing. I don't want to spend too long on it. If you're interested in the
analysis of EEG data, we've been thinking about it a lot. And I can talk to you about it afterwards.
But basically, in summary, we make a big Bayesian model of the results. What we're looking for,
we imagine the phases have been drawn from a wrapped distribution. We have some prior for the
variance of that distribution, some prior for the mean, that doesn't matter. And so the signal
will be in this, the posterior distribution of this phase of this variance for the phase.
And so this basically is the result. Here, we're looking at the, it basically is the inverse of
this variance, what they call the mean circular resultant against frequency. And so, sorry,
I'm standing in front of the camera. And so what we're seeing here is the
different frequencies. This is the frequency of the syllables. This is the frequency of the phase.
For the adjective verb condition, you see that there's a big response at the syllable rate,
as there is for all of these conditions. These are other conditions. This is mixed lexical,
mixed phrase, random. We did six different conditions, but we'll just concentrate on these two.
For both the adjective noun and the adjective verb, there's a response at the syllable rate,
showing up as a reduction in the variance of the phases. But for only the adjective noun,
are you seeing a response at the noun, at the, at the phrase rate? This, on the right,
this is some basic equivalent of the usual bar and star type graph. All it's really indicating
is that the adjective noun condition shows substantially, or you might say significantly more
response, which is, again, a significantly more mean resultant, just like the inverse of variance,
than these other conditions, which is basically showing that the brain has a response to the
grammar. That we can't just think of the brain as performing a statistical inference on the
sentences, trying to extract meaning and so on. It does something every time it hears a noun phrase,
and it doesn't do anything every time it hears an adjective verb word pairing, because that
isn't a grammatical object, or at least that's the interpretation. So, you know, having done this,
I was, I was kind of amazed. It shows that there is sort of stuff happening in the brain that,
that is more formal or more, more akin to a grammatical manipulation than, than you might
have expected, and shows sort of the presence in, in, in this, you know, in this discussion as to
what part of language is about the world, what part of language is about communication, what
part of language is about the machinery the brain has to deal, to deal with language. There's more
in that sort of brain part than you might think, and it's certainly, will it be of interest to
start to consider grammar, and the brain's view of grammar. Now, of course, these,
these stimuli that we were dealing with are, are quite new that we were using, as I said,
following this idea of people in a ding, this frequency tagged paradigm, where you are playing
the stimulus at a set frequency in order to be able to extract the EG signal of interest. But
it's very hard to, to, to come up with, you know, there's lots of things that you can't do with that.
We were able to examine the presence of noun phrases, etc. But what you'd really like is to
use free text like this, with like complicated, you know, sentences, different types of grammar,
and so on. This would be better as well, because one problem with the, the frequency tagged
experiments is that they are quite, quite boring and annoying to, to, to be a participant in those
experiments. And it doesn't encourage this kind of thinking away from what you're supposed to be
thinking. The problem here is the, is the difficulty in, in, in analyzing the data and, and trying to
show a relationship between the EG response and, and, and what's going on. So, you know, what,
what we'd like to do, I think, is to understand what grammar looks like to the brain. You know,
we, we know what Grammaticians think grammar looks like, but we don't know, you know, but
I often think about the phrenology skills that people were interested in in the 19th century.
The pseudoscience phenology divided the brain up into regions of the brain that did different
things, which is actually true. There are regions of the brain that do different things,
but they got it completely wrong. You know, they, they thought that the cerebellum was the organ
of amethyst, which is bizarre. In fact, it had some role to do with predicting the consequence of
motor commands or something. So, you know, the, the, the ideas we have about grammar might be
quite different from what grammar actually looks like. And to, to probe that, about one thing
certainly to do would be to, to, to do EG experiments with free text.
So, Connor, like, so just to kind of get an idea of the experiment itself. So you'd have like,
I know you said this is going to be like really complicated, but in principle, you'd have your
participants in a room reading this out loud and you'd just be looking at the brain signals. Is
that the, you would be reading it to them and you'd be reading the two brain signals. Yeah.
So, so, I mean, here, here's the results. So, I mean, there are people, you know,
it's not just us that's trying to do this. There are lots of labs doing experiments along these
lines. Stephen Frank in Namegun, for example. You have measures of kind of comprehensive,
like some behavioral output, you know, did like, what is, what's the point of the brain responding
to these things? Are you, are you measuring that as well? Like in the previous experiment,
you showed that there was a response better, but like, why, right? Like, what is that,
what is that, what is that doing for? I mean, what we do do is we make sure people are paying
attention. Okay. So we have a detention trap. We introduce particular words that they're supposed
to press a button to show that they're still paying attention. We, one advantage of the
Bayesian analysis is you can check the participants are, you know, you can, there's terms in the,
in the, you know, you have a big Bayesian model. There's a term to do with the participants,
you know, attentiveness. You can see that some of the participants are clearly not paying attention.
You can look at them through the window and see they're not paying attention as well.
You know, I guess I'm asking like a deeper question about, you know, you're asking what,
what is language for, what's the brain for? Just like some of these responses,
I'm always skeptical, particularly, I mean, I'd know the fMRI literature much better than the
EEG literature of where you just record a response and you say, okay, this brain,
this part of the brain, there's a response to something, but without some sort of behavioral
output that you're measuring connected to that response, I'm always skeptical of
how much, how much does that actually tell us about,
you know, what's actually happening and why, why we should care that there's a response there.
I mean, we should care there's a response there, because it shows that we are responding to the
noun phrases. And that's part of a story where, you know, we want to understand how the brain
understands language. How do we answer that? Well, I'm not sure. And, and you, you know,
people try behavioral experiments, they try manipulations to see how it changes people's
understanding and so on. There's, you know, there's a long history of this. But it hasn't
yet produced an account of language. And I'm not to answer your question going to produce one either.
But that's absolutely what we need to do. I mean, so I guess my idea at the moment
is that we start, that we use the EEG response as some sort of proxy for, for what's happening.
And we try and see, well, just let me say what we've done here, for example. So again, we're
looking at the EEG response to free text. We're doing some big regression, and we're trying to see
how people are responding to different types of words. And what we can see what this is showing
is that for part of the EEG response, there is a difference in how people are responding to
words according to the categorization of the words into function and content. And so we can see that
people's brains respond differently to some particular categorization of word. And so
what you might be optimistic about is that if you've got better at this, you could try different
categorizations and match them to different ideas about how the brain might approach parsing language.
But I agree. You can hear that then to maybe the grammars of the linguistics.
Yeah. And then separately, of course. Mel asked me not to mention transformers,
but then separately, you look at, you can probe how large language models deal with language. You
can probe the grammatician's approach to language. You can probe the whole linguistic
tradition of our accounts of how language is dealt with. And then this gives a sort of neural
account, the neural view of what grammar is like. But whether that's going to work or exactly the
details of that, I don't know. And so certainly what I would advocate is that we could collect a
big data set, you know, with lots of dots of different languages. The little prince, as maybe
you know, is the non-religious text that has been translated into the most languages. It exists in
300 languages. It exists as an audiobook in 50 or 60 languages. And so it's been suggested by these
folk here, Jinxing Lee, Brennan, Haile and some of their co-workers, that we collect a large
corpus of different varying qualities, some, you know, some MEG, which is, you know,
very high quality, some consumer EEG, but with many more participants across lots of languages.
And we start trying to understand, from the point of view of the brain, what grammar looks like.
So far, this hasn't been done. And I guess people are trying to raise money to do it and have failed.
So that's, you know, that's just by way of sort of motivation. That's where I came into thinking
about language. And, you know, my interest in language is trying to understand, you know,
how is language, what's special about language, what makes language, language. And of course,
when you start thinking about this, you start asking these questions, how do we do these
experiments? And it strikes you that there's a whole sort of separate story to language,
which is to do with evolution. And maybe the hope that if we think a little bit about evolution,
about how languages arise from evolution, the species point of view, and then separately,
how languages change, it would be, it might tell us something about the innate structure of language.
And maybe we can then think about how language, why languages might have to be the way they are,
compared to other ways they could be. And I think this is, you know, a very interesting question.
One of the sort of striking things is that, well, you know, we know from Creole languages and
sign languages and so on that languages do arise with a large amount of their structure
already present. But it's still an open question as to whether there are parts of language
that develop through time, you know, as languages evolve, do they, do they change in a consistent
way? Or are they the same from the very start? So near where I work, there's a museum, the Bristol
Museum, and Art Gallery, I left that bit out. And they have some of these freezes from Nimrod.
So the palace at Nimrod was broken up by people who went there and they took the panels and sent
them all around the world in, I guess, an act of gross theft, although what was left in Nimrod
has since been destroyed, so in the way it was quite lucky. And these panels do have this kind
of cuneiform script written across them. It's a standard inscription. And it's Ashnirah. Ashnirah
is basically showing off in this description. So this standard inscription here in cuneiform
explains what a great person he is. And some of it's quite sort of bloody as this bit is,
there are men young and old, I took prisoners of some I cut off their feet and hands of others
I cut off the ears, noses and lips of the young men's ears. I made a heap of the old men's beads
I made him heads, I made him in a rash, et cetera, et cetera, et cetera. Some of it's much nicer.
It's about making pleasure palaces and beautiful things, et cetera. But I couldn't find any of
that in an easily cut and pasted form. So I had to get this rather bloody bit instead.
It says something about our civilization. But the point anyway, is that what is striking
in the text is the lack of sort of the normal clause structure. There's very few instances or
no instances of the sort of clauses that you might expect where there's who and which is
and so on linking together the sentences. Instead, it's this rolling list, this very sort of list
like structure. And so you wonder is that because the language has not at this point
evolved all the structures of modern language, the sort of merge and clause structures that we
have now, or is it just that that's how they like to write in their ceremonial functions.
So just striking that there's a lot to be gained from trying to understand
something about the evolution of language. And so that's what I wanted to talk a little bit about
now. And so the first thing I wanted to talk about is really is to urge a return considering
the iterative language model that Simon Kirby and his co-workers came up with about 20 years ago.
So I don't know if you know the iterative language model, it's a language, it's a model for the
evolution of languages. The story is that Kirby and his co-workers discovered it. They simulated
a little bit, but they came quickly hard up against the computational limitations at the
time. It is quite computationally expensive. And so they worked on it and then they kind of abandoned
it and went on to try and do the same experiment that they'd done in simulation in real people.
And so Simon Kirby has very successfully spent the last 20 years using toy languages and toy
language learning as a pro into how people learn languages, but hasn't considered much beyond the
original work, the iterative language model itself. And now that we've got faster computers and so on,
it might I think be very interesting to go back and think about this much more. So in the iterative
language model, basically you have a teacher and the teacher teaches a pupil and then the pupil
becomes the teacher and teaches another pupil and so on. So it's a chain of learnings, teachings
and learnings. And the idea is that the language progresses or changes through this teaching and
learning. The hope is that we might learn something about how the structured language arises by seeing
if it arises through this simulation of the teaching and learning process. And the crucial point,
as we'll see, is that there is a bottleneck. So the agent has a language, the teacher, they teach
only a number of exemplars to the learner, to the pupil. And then the pupil in turn, the pupil
becomes the teacher, the pupil is teaching the next learner and they have to extrapolate from the,
well, they've extrapolated from the few examples, exemplars they've been taught, a whole language,
and then they choose other exemplars from that language to teach the next pupil. And it's this
process of bottleneck and extrapolation from the bottleneck that Simon Kirby hoped and in fact found
did produce some of the properties that we believe languages should have. And so again,
this just summarizes it. The teacher provides signals and meanings. So they say, you know,
cat and then shows a cat, just like in cartoons. The cartoon idea about how we teach children,
although people who work on children point out that that's not actually what happens,
that we very rarely teach children language in this supervised way. But here, we do have this
naive picture. The teacher provides signals and meanings. The learner learns the mapping from signals
to meanings. And then when they reach maturity, they use that to, they then use a version,
which I'm going to talk about in a minute, to invert that map. So they get a map from
meanings back to signals. And then they choose some random meanings, produce the signals for,
as an example, to the new learner. And the process continues. And
the idea is that the language that's produced should have some of these nice properties. So
the properties they have that we're to look for are expressivity, stability and compositionality.
Expressivity is basically, can all meanings be expressed? In other words, if you map signals,
set of signals onto the space of meanings, how onto is that map? If a completely expressive
language is one where the map from signals to meanings is onto, if the signals all map to the
same meaning, that would be not at all expressive. And expressivity is just a sort of counting of,
I mean, basically it's a counting of the map of the signal space into the, into the meaning space
divided by the size of the meaning space. Stability, that's just how after the languages
have time to mature, is it roughly stable from, from iteration from generation to generation.
And then compositionality, of course, is the sort of more difficult one. That's what makes
languages languages, what makes a language a language, the idea that a part of the signal
should consistently code for some aspect of meaning. So, you know, in this case here,
we have the word for orange. I think funny to make this as an example when I was making these
slides, but of course it's the worst possible example. So, so the idea is we have a word for
orange, the color. You can see my problem, I'm really screwed myself, but yeah, we have a word
for orange, the color, and it's used here to describe orange, the fruit, and then we have blue
used to describe the blueness of the orange on the right. And the idea of compositionality is that
the word orange, it means the color orange when referring to the color of an orange, or it means
orange when referring to the color of a high-vis jacket. And one of the things, you know, the
people have learned in trying to make agent models of language evolution is that compositionality is
actually quite hard to enforce. So, you know, if you have two reinforcement learning agents and
they're playing what they call the Lewis signaling game, they're trying to learn a way of telling
each other about things, what tends to happen is that, you know, if you don't, if you restrict
their signal space, so they just don't have a separate word for every possible combination of
attribute and object, et cetera, but rather they're forced to have some symbol for attribution, some
symbol for what's being described, they have to have a word for the color and a word for the
object. You can do that, but they don't consistently use the same color word. You know, they might use
orange to mean orange when describing oranges, but they might use blue to mean orange when
describing high-vis jackets. It's enough for the communication between agents, you know,
reinforcement learning agents, that there is a word to distinguish potential colors of the
orange fruit. But that word, the word for orange, doesn't have to be the same word. It doesn't have
to match to the same color as when you're using it to describe something else. You know, we do this
a little bit ourselves. I mean, you know, when we're talking about horses, we use the word chestnut
for what we would call brown in other instances. But generally speaking, the main property of
language is compositionality, and the idea is to seek that here. So in this version, in the simple
version of the iterated language model, we just have eight bits of meaning and eight bits of signal.
So the meaning space is just 256 potential meanings, and the signal space is 256 potential
signals. And then the learner has a simple neural network. You can see that this all dates back to
the year 2000. So it's a two-layer network. Signals come in. So the teacher says a signal
and then provides a meaning. And then the learner, perhaps using a sigmoid
non-linearity. So probability of ones and zeros for all the potential meanings compares it to the
actual meaning backpropagates and thus learns to map from signals to meaning. So that's the plot.
And of course, the thing about this is that this neural net has been trained on only these
exemplars, the small part of the space of meanings that form the teaching event from the teacher to
the learner. But the mechanism, of course, provides a map from any signal to a meaning.
So that's the first part of the teaching. But then the next part, which is that the
learner has to also get a map from meanings to signals. And so the way that's done is using a
version without worrying about it too much. Here's a two-bit example. So here we have a signal
mapping to a meaning, using the neural net. So what the learner is learning is the correct
mapping. So maybe the correct mapping here, the mapping that the teacher is trying to teach,
is that one zero goes to one one. But literally speaking, the learner can provide from this
mapping, coming from their neural net, a probability for all four potential meanings.
And this is a contrived example, so that the probabilities are 0.1, 0.1, 0.7, and 0.1, if you
obviously multiply P1 by P2, or 1 minus P2, or whatever. And so in that way, the learner can
produce a table of all possible maps from signal to meaning. So here are the signals,
and these are the probabilities that give meanings. And in a version, all you do,
you run the table the other way. So basically, if you're given one one one, so if you see the
signal one zero, your neural net tells you these are the probabilities of the different meanings.
And to get a map from the other way from a meaning to a signal, you look across this way and see
that 0.7 is the largest number. And then you decide that in your aversion, in your inverting of the
map for meanings to signals, you'll map one one to one zero, because that's associated with the
highest probability. So that's the process of aversion. You read across each of these lines,
you put a one there, and then this gives you the map. So zero zero will map to one one. So if the
learner wants to randomly decides to teach the next learner the signal from zero zero,
they'll say zero zero, sorry, they'll say one one, that's the signal, and they'll point out that
that corresponds to the meaning zero zero. So that's the that's the iterated language model. You can
see that this aspect of it is completely unrealistic and something that you might want to get rid of.
But it's the thing that seems to work. And what the reason, of course, it's unrealistic is that it
requires that the learner on reaching maturity goes through all potential, all potential signals
and all potential meanings, works out the corresponding probabilities, and then does this aversion map.
And that's obviously not true of language. The whole point of language is that you can't go through,
you know, you don't have to go through all meanings and all signals. And even from a
computational point of view, it's extremely resource heavy. And even with modern computers,
it means that you couldn't. So the hope is that you could look at this iterated language model
far beyond the sort of eight bit examples they're doing here, maybe even use it,
you know, on language itself. So replace the set of meanings with actual sentences and
force the agents to come up with their own internal languages and see what happens.
But so anyway, with this aversion process, you do get a way of mapping. And so you can run the
iterated language model. This is just us recapitulating what Kirby and co-workers saw 20 years ago.
You can see that if you do this, you know, with a suitable size of bottleneck, so 256 meanings,
you allow 50 of them to be taught, you run it across generations, the expressivity goes up,
stability. So this is the instability, the opposite of stability, that goes down.
And more remarkably still, the compositionality increases. So this I think is intriguing and
worth sort of reminding us. Sorry, this is just some, you know, interview. There's two different
measures here going on of compositionality. But it's basically measure of positionality
based on entropy. But I mean, I do think it's remarkable. And I think it's worth us going back
to the iterated language model and trying to see what it tells us about language evolution.
To get rid of the inverter, it turns out, you think it's going to be easy. So for example,
you think that you can just add another, you know, in the learning process, you can think that the
learner could have, you know, a meaning and then also learn its inversion at the same time,
stick in as an objective function, getting the right meaning, but also recovering the original
signal. That seems like it would almost certainly work. And I guess this is one of the sort of
few original results we have in this area. And it's a sort of a negative one, which is that
it turns out that a version, although clunky, something that you hope might just be a convenient
way of doing the inversion is necessary. It creates some sort of pressure which drives
apart the mapping and makes the mapping from signals to meanings onto and produces expressivity.
So if you just replace it with a recurrent neural network, well, what you might call a recurrent
neural network, with this architecture here, you lose that expressivity. I think that it's,
so what we're seeing basically is that the bottleneck, which forces the neural net to
generalize or sorry, the agents to generalize is producing compositionality. But the aversion
is also required for expressivity. The bottleneck also tends to cause this pushing together of the
mapping, which loses the impressiveness of the language. And so I think there's ways around
that. I think, you know, maybe if you think the whole thing is a sort of Bayesian reconstruction
problem, you can come up with a new objective function, which has a sort of contrastive term,
which forces it not only to get the right mapping from signals to meanings, but also punish it for
other meanings being close in probability. When you started doing that, it hasn't worked yet.
It's still not producing the expressive map. It goes up for a while and then something happens.
I'm sure we can sort that out. But the plan here, the hope, the conclusion is that there's
a lot going on in trying to understand how compositionality and expressivity kind of
rise in these simple agent models. It would be nice to have a sort of working example first and
then try and decide, you know, could we generalize it to much larger, more difficult cases? But I
think, you know, the problem is that, this slide is just to remind me to sort of announce the problem,
which is that, you know, with these models, you're starting to worry about how much you just
follow your own footsteps. You start putting things into the models to produce some sort of
behavior. And then you start to worry about exactly what we can compare to when we look,
you know, how we compare the model to the actual behavior of languages, how easy it will be to
decide, you know, whether the model is a good one or not, and then work out from whether the model
is a good one or not, you know, what is it about it that it tells it? What does it tell us about
the brain? I mean, one thing we sort of, one of the things we try, obviously, is look at how it affects
language, language synchrony between different communities. So here we've, we've taken the
iterated language model, and we've stopped it being a simple learner to, to, teacher-to-learner
interaction, but rather have some sort of web of interactions where a learner has a privileged
teacher, but also learns from, from their community. And then we take networks where there's
greater connectivity within, within a cave. It's, you know, it's one of these cave people
graphs. So there's greater connectivity inside a cave, then across the caves, and we look at
how the languages evolve and stabilize. And we discovered that you can, you know, depending
on your parameter choices, you can end up with, you know, five different languages in six caves,
this cave, they don't even have their own language, or a case where there's, everybody speaks the
same language, or where some languages are shared and some of them are different, or where there's
two different languages. And so you can use this model to try and understand properties of the
distribution or the sizes of language, languages. But the problem there, of course, is that there's
millions of parameters, you have to work out how to, how to, you know, what the network should
look like, how to structure the teaching events, how to, how to structure the size of the bottlenecks
compared to all possible being single pairs, etc. And so the model, although intended as a very
simple one, when you start trying to apply it in ways that can give you data that you could
compare to the real world, the model becomes still simple, too simple to produce something,
you know, directly comparable to language, but much too complicated to draw easy conclusions from.
And so it struck me at this point that we should try and think of what the very simplest model
of language evolution is. And that's what I wanted to finish by talking about briefly. So the idea,
here, is that we want to look at language change and look at the, the, the most personmonious
description of what goes on as languages change. And so, obviously, one property that languages
have to have is alignment. If you're talking to someone, you want their language to be almost
the same as your own, or else you won't have, you won't be able to understand them. And the closer
their language is to yours, the less sort of cognitive low communication will play,
will place on you. So I think the first properties of languages as they change is that they should,
should align. The second property is the converse, this inclination towards change. You know,
obviously, teenagers do this all the time. I have teenagers, they, they, they use words in
different ways. They, they delight in language invention. I mean, weirdly, my, my mother is
almost the very opposite of a teenager. It's the same. She's forever making up new words and
new ways of saying things, often based on puns. And then the puns turn into words. And then she
just uses them in everyday conversation, expects people to, to follow. And she just does it in
a, out of a sheer delight in language invention. There's also a kind of a more strategic point
to language invention, which is to find shorthands for saying things, auxiliary words are pushed in
with the words that their exiliaries to pronunciations are changed. People say small phrases to mean
more complicated, large phrase things, et cetera. So there, there, there, there are these two sort
of competing forces that work in language changes. The third one as well, which is an
inclination towards consistency. That's exactly the sort of thing that the bottom leg in the
iterated language model deals with. And I'm not going to deal with that one here. That's the idea
that, you know, if, if in one sentence you put, you know, if at some point you decide that the
verb goes at the end of the sentence, it does that for, for, you know, that can sit that,
that rule doesn't just apply to one, one's type of sentence, but rolls through the language. So
once something starts changing, other parts of language change to suit it. So that's an inclination
towards consistency. You know, and it's obviously kind of amazing. I mean, if you think of how
how, how noun and verb modifications work with Arabic and Hebrew, I mean, it's just incredible
the way that, you know, everything has three, three consonants, and then you've got the verbs and
the endings and, you know, how did that happen? I mean, it's just some, some small changes then
became rules. And so that is obviously an important part, but not one we'll talk about now. So
obviously agreement alignment between speakers and spontaneous change. You probably guessed
when we're going with this, that that's a nising model. So in the nising model, it's a model of
magnetism, as you'll all know, at different lattice sites, you've got a spin, the spin goes
upwards or downwards. And there's an energy associated with, with the alignment of the
spins. It's a lower energy state. If the spins are aligned, then if they're not aligned. And so
you would obviously expect an nising model to evolve towards total alignment. But there's also
in the nising model thermal effect. So in an nising model, this is the metropolis
formulation of the nising model, what you do to evolve the model is you choose a random, you
choose a site, and then you consider what would happen if you, if you flip the spin. So we'll
label the spins plus one and minus one. And if the, if the consequence of flipping the spin
can be written down like that, I hope I have the signs right there. But basically, if the spins
become more aligned on average with the neighbors, so the one site, these are the four, for example,
neighbors of the middle site, if it becomes an average more aligned with them, then a DE will
be negative, and you'll accept the change. If it becomes less aligned, you'll still accept the
change. And this is the terrible part with some probability given by the exponential of minus
DE divided by T. And so DE is positive in this case. If DE is negative, as I said, you always
accept the change. T is the temperature. In the case of when you're modeling magnetism, it's
literally the temperature. If T is very large, then this is always one, you always accept the
change. And so you just get a random up and down. If T is very small, then this will be near to zero.
You'll never accept the change. And you'll just get it flowing to total alignment. And so you get
these different patterns. This is the very random. This is the very aligned. And this is the critical
point in between. So this is a model of a phase change. And at the phase point, at the critical
point, you have scaling behavior at the cluster size. And that's what people are interested in
the IC model. So obviously, we can map these two things, the movement towards alignment,
towards the idea that you're trying to lower the energy. And the spontaneous change is like the
thermal fluctuations. But clearly, of course, if you had only one spin, then you'd have only two
languages, the upper language and the down language. And that wouldn't be very interesting.
So what we do instead is we've got a vector of spins, d dimensions, where d is some number,
you have to be chosen. And we imagine that these are coding for different properties
of the language. So one spin might be, how do you say father? And obviously in lots of languages
like Latin, German, Irish, the word is almost the same as that would be plus one. Do you use
derivative of pattern for the word for father? And minus one would be languages where you don't.
I don't know any languages that don't use pattern like derivatives. Anyway, not a good example.
Or it could be something to do with word order. So here you see the word order in English,
subject followed by, followed by verb and adjective followed by noun, whereas in Irish,
it's verb followed by subject, noun followed by adjective, and they would be, you know,
correspond to two further spins. And then a further complication is that that choice
tends to be the same. So if the subject comes before the verb, the adjective comes before the
the noun. If the subject comes after the verb, it's the other way around.
And so you can imagine there might be two spins, one for this part of the word order,
one for that part of the word order, and then in some elaborations model,
there'd be some relationship between them. But that's basically the model we have.
We have, as it were, in this first idea, we've got D independent ising models, and a given set of
plus ones and minus ones constitutes a language, we choose some temperature,
we run it forward and we get some behavior. I do have a graph in a minute, I'll show you.
But the main thing that you do see is that because it's lots of interlocking patches,
one for each of the D dimensions, you tend to see language continuum. And language
continuum are a property of languages. So, you know, these days, everything's a bit more complicated,
national boundaries and official, you know, government documents and radio stations and so on.
But in the olden days, you tended to have no hard language barriers, boundaries. So if you
walked from, you know, Portugal all the way to Sicily, well, Portuguese would be very different
from Sicilian, but as you do it, you'd never actually be somewhere where we're, well, depending
on your route, and that's going to be the point, if you go this way, you're never going to be
somewhere where people in nearby villages can't understand each other. The languages gradually
change one to the other. And so that property of language distributions is well reflected by
this ising model of language, and obviously the temperature determines how big these clusters
are and so on. And that's something that you might try and fit against some knowledge of
the distribution of languages. But the problem, as you could probably anticipate, occurs here,
which is the Basque country. And if you, if you instead of walking from
Portugal through Galician and Castilian and Arganese, you kept along the coast as well,
you might, particularly if you're a pilgrim. Well, if you're a pilgrim, you're going the other way.
But either way, if you strayed into the Basque country, you would encounter a linguistic barrier.
Basque is quite, quite different from, it's not an Indo-European language. This is a sign,
remarkably, in French Gascon, which is a Pocotin language. And Basque, the Basque is this here.
And you can see that it's very different from the others. This is Basque here as well.
And so there is, in real languages, a language barrier. There is the possibility of language
barriers. And also, of course, you know that we don't have to be able to talk to everybody.
You know, we, we can have neighbors who speak a different language. And we can talk to them
without necessarily aligning our language to theirs. We can speak to them, for example,
through a lingua franca. These days, using translation by using somebody who's bilingual
or being bilingual ourselves. This is an example of Kiswahili, which is a language that, you know,
100 million people, that's not a bit much, a large number of 10 million people can speak
as a second language, but only a million as a first language. And because it exists as a
lingua franca, allowing people who don't have a mutual language to live beside each other.
So the next version of the language evolution model is this preference sizing model. So the idea
here is to run the same sort of dynamics, alignment and thermal change, but only allow or only have
each side interact with which of the ever of the four sides around it, in the simplest case,
has the most similar language to its own. So, so the idea is that for each of the, for each pair
of, of sites, each pair of speakers, I guess, you can work out the difference between their
languages. And then you could, you need to, you only run the sizing model between the speaker
you've randomly chosen to consider changing one of their plus ones and minus ones, and whichever
neighbor is closest to it. And so that is the idea being that you only speak to the people
who speak the same language as you. And so that's the new version, there's a paper about it there,
in ALI. And it kind of works. So there's lots more to be done on this, but this is, this is the basic
idea. This is the originalizing model. And here is a histogram of, so this is only five dimensions,
you can run it in far more, you know, five different language attributes, you can run in
far higher dimensions. But in the case of the first sizing model, you can see that this is the
number of different, average number of differences between the speaker and their neighbor. And you
can see that the speakers and their neighbors tend to have very similar languages. And very few
people, very few pairs of people have languages that have very little in common. In other words,
this version of the model does not allow for linguistic borders. Whereas in this preference
model, where a comparison, the dynamics is only relative to whichever neighbor has the closest
language to you, you do have lots of pairs where people speak the same language or very
similar languages, but you do have pairs where people speak very different languages. So this is
the, this is my proposal of the simplest possible model of language evolution. This work has only
just started, but the idea is to consider, you know, consider different structures of preference
and how many neighbors you interact with and so on, and then try and find different temperatures
and then find the structure of the size of language groups there and compare it to real
day clear. And so that's something that we'll do in the future. And that's it. Thank you very much.
So I was assuming throughout this presentation that the bottleneck in the iterative model kind of
corresponds to Chomsky's poverty of stimulus argument about language learning. Is that
right? Corresponds to, I mean, it's, it's, it's meant to be representative of the fact that
people, children only like experience a very limited amount of, but it adds something extra
to what Chomsky says. So Chomsky uses the poverty of stimulus as evidence that the brain must have,
you know, linguistic things, linguistic things. Whereas here, the poverty of, the poverty of
stimulus is a mechanism for, it says that the structure of language is a response to the
poverty of stimulus. So it changes that. I mean, that's what I think is really nice about this
model. It turns that language upside down and says that in fact, it's not that the brain has some
special language mechanism, it's that language has, has evolved so that we can generalize from a,
from a poverty of stimulus. I was interested in, because I can imagine a more innate style person
saying, you know, it's this convergence from the statistics to just a definite mapping in the
aversion process that is leading to compositionality, but maybe there is some sort of innate
mechanism, which is responsible for something that has the same effect as aversion.
Yeah, no, but do you think that the, the work you're doing with this model,
is there something that makes you lean more towards the, the empiricist take on this?
So, I mean, I think one of, one of the things that we're learning at the moment, you know,
you know, obviously, you know, the objection to transformers as a model of language is that
they require this massive stimulus. But conversely, they, they, they are very sophisticated at learning
grammar. You can see that if you back away from the, from the learning aspect, and you just look
at the ability of these models to perform grammatical tasks, it's quite incredible. We do, we do, you
know, we do do experiments now where we ask, you know, a transformer or an LSTM or something,
can you learn gender agreement? And so I have a student Priyanka who's teaching new words to,
to an LSTM. So she takes an LSTM, it's pre-trained. She freezes everything but the
representations. She teaches it a new word. She gives it some grammatical context, gender context.
So she doesn't French, obviously. So she says, you know, la, we use the word trilobie for some
reason, because it's the least common word in the vocabulary list that we're using. So we take
the word trilobie, we cut off its representations, we reintroduce it somewhere else in the
representation space, and we train just the representation space on a few examples where
you use the word la or la, describing trilobie, and then you ask it to do other gender agreement
tasks and it does it completely well. So even though it's learning one aspect of gender,
it's been taught the gender of the word through one aspect of gender, and it's been tested on
another, it has abstracted the, the abstract category of gender. And so, you know, the initial
bias that you had, that you needed, you needed special mechanisms, you know, Chomsky and
mechanisms to allow the brain to perform the form of manipulations associated with grammar.
That, I think, has been demonstrably made false by, by large language models. They,
they have this very, I mean, the structure of transformers seems completely bizarrely crappy,
right? And yet they do these amazing things. And so, it's quite possible for these, you know,
simple network models that are doing statistical learning to learn this stuff.
But that's not the same as saying that it can learn it against a poverty of stimulus.
But what I think the iterated language model is maybe indicating, and again, we need to start
using the iterated language model on much bigger examples. It's, it's indicating that you don't
have to put much more in, you know, you, you, you, you, once you start thinking about a version or
exactly what the objective function is, and the needs to, to generalize, it's possible that it's
not just that the, it's possible that the language that evolved, that you could evolve the language
where you can learn from a, from a poverty of stimulus. Does that make sense? I said that in
the very roundabout way, but I mean, I think I'm essentially agreeing with your initial, initial
point. Feel where you're coming from. Thank you. Thanks for the lovely talk. I think we could have
done this at home some day. No, no, no. But yeah, I was wondering, are you, are you thinking with
the Schelling model, are you thinking of maybe looking at the, or maybe already have the different
patterns of, like actually taking different patterns of like verb order and, and so on, and
kind of encoding them and plugging them into this model and seeing what you get out. Because I think,
I mean, one, like one thing is, I think with, you know, subject verb, object ordering, there are
certain patterns and some patterns are more frequent than others. For example, I don't know.
And I guess that wouldn't. I mean, it's, it's very hard to know because we tend to think that the
patterns represented by the Indo-European languages are, are much more common. I mean,
just to answer that specific point, it is, you know, so you think, for, well, for example, the,
the claim is that verb object is much more common than anything else. But that's only if you can't
buy speakers, if you can't buy languages, that's maybe not so obviously true. Okay. And Irish,
of course, that was one of my original interests is a language where verb and objects aren't beside
each other. So, you know, I mean, I think the point with the ISI model is to make the simplest
possible model. And so we, you know, I don't think you can retain that advantage to the model,
while at the same time tying your coding to specific features, but rather the idea would be
to introduce into these dynamics some abstract version of these features. So,
so you could include some sense of consistency, which would be an interaction between the spins.
So not only are, is a speaker interacting with the, with their neighbors, but there's also an
interaction within the spins themselves. And that would be the idea that once you flip one thing,
other things should flip as well. But, but I think, you know, there's sort of two, two types
of models here. There's one that you might, the iterated language model, where you might actually
try and use that to probe actual properties of actual languages. But with the difficulty that,
you know, it's, it's, it's not a completely parsimonious model. You always have the problem
when you're doing ancient modeling of deciding whether you're looking at your own model or
you're looking at the world. And then there's the ISI model, which is supposed to be that there's
a simplest possible language, a model of language evolution. And the idea there would be to look
at very simple properties such as cluster size, cluster distribution, et cetera,
and compare them to real languages, which hasn't been done yet. But that's, that's where we're going.
So it could be wrong in assuming this, but sort of tying together the start and the middle of the
talk. And in the iterated learning model, you have this mapping between meaning and sensations.
And in the EEG experiments, I guess, is, is the, is the purpose there to try to uncover
how that mapping is established in the brain and how, you know, maybe, you know, neurophysiology or
segregation in the brain biases or influences that mapping itself. Like, is that what you're
trying to get at with the EEG experiments? Yeah. I mean, as, as he pointed out, we're a long way
from actually doing any of this, but the, that the sort of overall picture is you language has
structure. We can discover that structure. How do we discover that structure? Probably, I think
the best way to do it is by looking at EEG responses. You know, we do have commentaries on
language invented by grammaticians. That's really them trying to impose what they've learned about
Latin onto other languages. And it's probably sort of quite naive compared to how the brain
considers parts of speech and the relationships between parts of speech. But the parts of speech
and their relationships are probably important either as a reflection of, you know, and again,
the discussion there is relevant of the mechanisms the brain uses for producing language and
understanding language, or the language that the, that's the languages that have had to evolve so
that we can learn them despite the poverty of stimulus that we experience as children.
And so the iterated language model is trying to find out what, I mean, potentially is trying to
find out what those properties of language might be. And we'd like to compare them to the real
properties of language, which we discover through EEG. That's the big plan. Where my thoughts were
going with that, I was just wondering if there are any, you know, takeaways from that EEG research
or from, you know, the neuroscience realm that could perhaps be brought back over to the
iterated learning model, but specifically, so in that bottleneck layer and your
representational bottleneck in the meaning. Can you take any principles from neuroscience to
apply, you know, to constrain that, you know, the structure of the bottleneck?
But I mean, the story of my life is that when I started working in neuroscience, I thought, you
know, we really want to map from actual neural networks to what they're doing, you know, we want
to go from, you know, this is a neuron and this is what it's connected to, this is how it works.
And so, you know, I ended up working on tadpoles, because I thought tadpoles are really simple
creatures, maybe we can understand tadpoles. And tadpoles, neonatal tadpoles make a decision. So
basically, older tadpoles are fearsome hunting animals, but the very, very young ones, when they've
just emerged from the egg, and they're still carrying, they carry with them kind of an egg pouch.
So the material from the egg that they grew in, so they don't have to eat for a couple of days.
And these animals are very, very simple. So you touch them and they swim away.
You grab them, they struggle. So there's exactly one decision they have to make,
which is whether they've been grabbed or touched. And I thought this is the simplest
decision that any creature makes. And there's like eight different neurons involved in this.
Maybe we could go from the network to understanding the decision. And I had a PhD student who
worked on this model for, you know, four years, reduced it all to two dimensions so we could
draw a phase diagrams. And it was like just the most unbelievable mess. And in the end,
you know, we just knew nothing about tadpoles, yet alone, you know. So I think, you know, I just
don't think that's, I think we're so far away from, you know, something as complicated as language
and mapping anything but the broadest principles of neural dynamics to the cognitive dynamics.
I think the gulf between, you know, the neural substrate and the cognitive function is so great
that I would be trying to stay away from that. The idea is rather to look at the structure of
language and ask, look for the structure of language in EEG. So the mechanism there is only
to try and find out what the brain regards as grammar. And then to compare that to the
iterated language model and how it might, or some other model and how it might treat grammar,
basically. Which is not to say that people are, you know, I mean, maybe the cerebellum, you know,
maybe the hippocampus. But if you can't understand tadpoles, what could you do?
I mean, basically we disproved the existence of tadpoles, I think.
I'm sorry, Seth. Do you worry that expanding kind of this type of EEG work to a much broader set of
structures would result in the same sort of mess?
Yes. I mean, I think it's a good strategy. I agree with you that it seems promising and much
simpler than that or some of the stuff that's been done mapping kind of semantic content into the
brain with MEG and fMRI. But it turns out like the tadpoles, it's a mess. Yeah, it seems more
promising. But I mean, who knows? I mean, yeah, I mean, we, what we've done compared to what we
want to do is tiny. So it seems to me to be the most straightforward strategy. But, you know,
at the moment, I can't even get my little prince experiment funded. And not only an eye, but these
are greater people who are trying to get money for the same thing and get it done. So, but, you know,
yeah, I said they're building in Bristol an instrumented museum, an instrumented cinema,
so it'll be possible to do simultaneous EEG experiments on 100 people at once with consumer
level EEG. So, and I think they're building this thing without any clue what they're going to use
it for. So I think, I think there's a potential to persuade, you know, to get hundreds of recordings
of people listening to the little prince and lots of different languages. And you can help
it feel that you can discover something that way. Because languages are just so different, you know,
I mean, you know, if we could get Malay speakers, they don't, they don't, it's an isolating language,
they don't change the words for the plural, you know, if we can get speakers of, you know,
Irish, they put the verb at a different place. I mean, it's just, there's such a variety,
it'll be really interesting to see what we can see. But I agree, you can probably turn
into a mess. And I think the way that you can turn into a mess is to try and
find things that are too detailed. We have to try and find the very broad principles,
you know, because even that's unknown. Is this cinema? Like... Yeah, yeah, they're building this,
they've built it. They got funding for something called the Future Institute. And it's good to
have this instrumented cinema where people wear EEG and they'll watch films, basically.
So, like, when all the new films come out, you can have like the EEG response.
Exactly. Yeah, exactly. I mean, I think that's how they solve it. Yeah. I mean, it's nothing to do
with me. I mean, it's people in the psychology department. And the idea is that I think they'll
have, you know, all sorts of instrumentation, right? They'll have, you know, we have to work out how
sweaty people are and the heart rates and, you know, how much they're breathing, you know,
and their EEG. So, I mean, it sounds like one of those things that sounds really cool. So,
they were able to get money for it. But I think when it comes down to it, they're going to
struggle to find experiments. So, hopefully, they'll do experiments for me.
Nightmare giving a talk in that room. You can track in real time.
Yeah, there's lots of cool things you can do like that. Yeah.
Cool.
Thanks for coming in.
