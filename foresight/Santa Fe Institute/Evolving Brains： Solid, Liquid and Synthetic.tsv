start	end	text
0	6720	This public lecture series.
6720	11840	Many of the most cherished books in science, Einstein's relativity, Schrodinger's What
11840	17820	Is Like, Richard Feynman's QED, were all based on public lectures.
17820	24420	In this spirit, we want to welcome you here tonight, this public lecture.
24420	29800	In the special series beginning tonight, the ULAM lectures, we bring a notable scientist
29800	36000	to illuminate a cutting-edge topic in honor of the late theoretical mathematician Stanislaw
36000	37560	Ulam.
37560	42280	All of our public lectures are underwritten by the McKinnon Family Foundation, who allow
42280	47080	us to continue to provide the lectures at no cost, and we want to take a moment to thank
47080	54840	them first.
54840	59160	We are additionally supported by the Santa Fe Reporter and this Lenzick Performing Arts
59160	65680	Center.
65680	70600	Stanislaw Ulam was long associated with Los Alamos National Laboratory, and is highly
70600	74520	regarded by the Santa Fe Institute scientific community.
74520	79840	Former SFI vice president Mike Simmons said, the enormous range of Ulam's scientific thought
79840	85680	encompassed not only mathematics, but also physics, computation, biology, and much else.
85680	90000	He would have been very much at home in the present day Santa Fe Institute.
90000	96060	In this tradition, I am proud to introduce Ricard Soleil, our speaker tonight.
96060	101640	Simply put, Ricard is one of the most abundant and interesting theorists alive.
101640	108780	Ricard leads Icreia, the complex systems lab at the Universitat Pompeo Fabra in Barcelona.
108780	113760	He is also an external faculty member here at the Santa Fe Institute.
113760	118780	Ricard originally studied both physics and biology and undergraduate before achieving
118780	120900	a Ph.D. in physics.
120900	125900	His work touches on everything from how life originated to present day ecology to the very
125900	127920	nature of thought.
127920	132800	In the late 90s, Ricard connected ecology and mathematics by demonstrating the fractal
132800	138040	structure of forest canopies, and that these structures emerge from the statistical dynamics
138040	140060	of self-organization.
140060	145860	This is a fundamental idea in ecology, and the full extent of the impact of these ideas
145860	149940	are still being woven into our study and predictions of forests today.
149940	154900	They are ideas that inform and inspire my own work constantly.
154900	160540	Ricard has worked on other fundamental mathematical questions related to complex networks.
160540	165540	More broadly, he is interested in how life works, spanning from how cells first originated
165540	171200	in our past, to how brains developed to know and observe those same cells today, to how
171200	178720	technological societies network brains to design new cells and engage in global bioengineering.
178720	183480	And it is necessary to point out that Ricard's aggregate breadth of study is never at the
183480	185360	expense of depth.
185360	190560	This combination of expansive topics pursued with deep rigor is one of the rarest talents
190560	192520	in science.
192520	196860	In my own interactions with Ricard, we often discuss literature, and I am the fortunate
196860	203020	recipient of many quotes from novels, biographies, and historical scientific works.
203020	207980	The wonderful drawings that you are looking at tonight are made by the man himself.
207980	212420	This shows that his imagination is constantly in motion, and it is a pleasure to discuss
212420	214080	any topic with him.
214080	218780	He is a true polymath and an ideal speaker for this lecture series.
218780	223000	With that, please help me welcome Ricard Soleil.
223000	225000	Hello.
225000	231120	You hear me?
231120	235040	Thanks for coming tonight.
235040	240520	It's a real honor to be here delivering the Olam lectures this year.
240520	244720	Thanks, Chris, for this great introduction.
245080	252060	My talks have to do with a very exciting domain of research, which is mapping the space of
252060	254020	cognitions.
254020	259820	Not only the cognitions that we are familiar with, what I call the solid brains, but trying
259820	266340	to understand what is there, what is what I call the cognitive biosphere, what is there,
266340	272340	how much is complex, and whether or not we can understand the evolutionary dynamics that
272360	279360	brings us, and if we can maybe go beyond evolution and try to engineer that complexity.
280880	285520	So, before I go to that, since this is an Olam lecture, I want to say a little thing
285520	292720	about that, because when I was in high school, I stumbled into this book, The Monte Carlo
292720	293720	Method.
294700	304700	It was a tiny book edited by the former Soviet Union in a series of little books with all
304700	311200	kinds of things, where I discovered that Stan Olam, along with John von Neumann, invented
311200	317220	this method that physicists use all the time to actually model complexity that has to do
317220	320540	with some kind of randomness.
320540	323880	And that brought me into play myself.
323880	331040	It was the time of, there were no computers, so I'm old enough to say that, and so I had
331040	336400	a calculator, I have a coin, and I did a model of a gas.
336400	343960	You can see this is written with a typewriter, and I elaborated with that using that book.
343960	349960	And one of the things that I learned is that there's a lot of power in being able to approach
349960	355340	reality using, let's say, synthetic approximations.
355340	360940	And the other thing I learned is that it's something about popularity.
360940	367540	This series is called Popular Lessons in Mathematics.
367540	370340	Did that make me popular at all?
370340	371340	No?
371720	376960	And I understood that popularity is not exactly that kind of stuff.
376960	383760	But the other thing that I did connect is, I was mentioning Ulam and von Neumann, which
383760	385800	you can see there on the left.
385800	389040	In the middle we have Richard Feynman, another big name.
389040	392080	It was important in my life.
392080	399720	And von Neumann, and I will mention him today and tomorrow, brought me also into something
399720	400720	else.
401100	406420	This book by Michael Arby, Brains, Machines, and Mathematics, and again, I was still in
406420	407420	high school.
407420	410940	I found out that there was people thinking in the brains using mathematics that you could
410940	414300	approach actually brain complexity using mathematics.
414300	418060	I found out extremely fascinating.
418060	426300	And over time, I got involved in trying to figure out how to solve some of the interesting
426300	427300	questions.
428280	434520	There are plenty of good things that we would like to understand from the question of why
434520	435520	brains?
435520	442400	Why brains is part of a more broad complex, a more general question on complexity?
442400	448440	Because some people said that why the biosphere is not just made of microorganisms.
448440	449440	They are cheap.
449440	450440	They reproduce.
450440	453040	They propagate and proliferate.
453100	460580	Thinking that it adds complexity and brain is a lot of complexity with a cost seems to
460580	461580	be superfluous.
461580	463820	Why actually is any complexity?
463820	466660	And brains are especially important.
466660	467660	What kind of brains?
467660	471700	That's one of the big questions we'll try to bring.
471700	473380	Are there other minds?
473380	475900	It's a very hot topic these days.
475900	479820	What is a mind and how do we define and what we can find out?
479820	482900	All the way up into the artificial.
482900	489040	So whether or not beyond evolution, beyond what we see, beyond what we can infer about
489040	496600	how nature happened to construct complexity, whether we can actually create new things.
496600	501840	And that connects with the big question of the major evolutionary transitions, namely
501840	506160	how the big innovation happens in the real world.
506160	512600	Many years ago, Eosia Smadi and Don Minersmith made this list of transitions that had to
512600	518540	do with the origins of cells, the origins of information, the code, et cetera, et cetera,
518540	522020	all the way up to language.
522020	524060	Of course, the list is more complex.
524060	528100	You could ask yourself, what is the origin of consciousness?
528100	529900	Why do we have consciousness?
529900	530900	I will address that.
530900	536700	I don't have an answer, which might be wrong, but you'll see.
536700	541940	And in the middle of all this discussion about what is the nature of innovation and how innovations
541960	549600	happen, is precisely this special thing of biology, the special status of information
549600	550920	in biology.
550920	560040	And Eva Javlonka and Marion Lam made this beautiful work where they bring precisely this idea.
560040	562680	Cognitive agents bring something extraordinary.
562680	567720	In evolution, you have genetic information dominating the story of life for a very long
567720	568720	time.
568900	573100	Information that is based on something that is not genetic has enormous advantages.
573100	578060	Information that can be shared, can be propagated, and for us humans can be propagated beyond
578060	580460	ourselves.
580460	583660	So that's the main thing I want to address.
583660	594020	And the first part of the story is to actually ask ourselves, how likely is a brain to happen?
594020	599880	And that connects with something that is fundamental in evolutionary biology, but goes beyond that
599880	606240	and percolates into many other areas of knowledge, which is the role of randomness and contingency
606240	613720	and history versus the possibility that there are very strong laws that constrain a lot
613720	615360	what is possible.
615360	619600	And I put two views here.
619600	624780	Here on the left, Stephen Jay Gould was a strong advocate of the idea that evolution
624780	632660	is so historical that any kind of little change that you put in place will modify the outcome.
632660	638420	And he made, he used this mental experiment based on this movie that, sure, you have seen.
638420	645060	I mean, I don't know here, but in Barcelona, you see every single Christmas, we have wonderful
645060	648420	life at some point, right, on TV.
648420	650440	And I remember for you the story.
650440	655400	It's this guy, a very, very nice guy who had a lot of trouble for a very unfair reason
655400	660640	that at some point he decides that his life is worthless and says to himself, the world
660640	663280	will be better if I haven't been born.
663280	669480	And then comes this angel, which is a kind of quite annoying character, which is proposing
669480	672760	the experiment of, okay, let's do it, let's do the experiment.
672760	674160	You haven't been born, right?
674160	675280	What happens?
675280	677660	And he shows this, all this chain of events.
677660	682540	He didn't save his brother, who fell in a frozen lake and died.
682540	688740	And because of that, his brother in the war, in the second war, couldn't save a whole company.
688740	690500	And so on and so forth.
690500	695740	And eventually, the city where they live is very crappy.
695740	700660	So the message is, any single event can change everything.
700660	708120	And Steve Gould used that in the context of evolution, saying if we were able to replay
708120	714080	again the tape of evolution, like starting 600 million years ago, the biosphere that
714080	717080	we'll see now will be totally different, right?
717080	719800	It will be an alien biosphere.
719800	721400	I don't think that's the case, right?
721400	722960	But this is the idea.
722960	727720	Other people like Jack Monod also brought the idea that randomness plays a very, very
727720	730420	important role in evolution.
730420	736220	And more recently, I'm very much a book person and a movie person, and my students know that
736220	740100	very well, and I'll make recommendations.
740100	746740	Recently, Sean Carroll, the biologist, wrote this beautiful book where he kind of puts
746740	749500	these random events that seem to be relevant.
749500	752500	But this randomness really is so important.
752500	754780	Let me show you the other part of the story.
754780	761040	In fact, when we look at the natural world, we find out that very often the same solutions
761040	768800	appear again and again and again independently in very different groups of organisms.
768800	770640	I put the eyes here.
770640	777040	The complex eye that we have, this camera eye, has been invented in evolution probably
777040	781080	about 25 times in a totally independent way.
781080	786860	We have this eye, and Octopy, for example, they have an eye that is essentially the same.
786860	790420	In fact, it's better than ours, right?
790420	796460	And this is what we call convergence, that the reason that these solutions appear again
796460	801500	and again and again is that there are very, very strong constraints, even maybe mathematical
801500	804820	laws that limit the possible, right?
804820	809900	This is a book, Life Solution, sounds like a self-help book, but this is a book of evolution.
809920	815600	It gives a lot of very interesting examples that go from cells and codes, genetic codes,
815600	817480	to minds, right?
817480	825160	And here is the Catalan scientist, Per Alberg, who unfortunately I met him years ago and
825160	830640	died very, very soon, and he made the argument that even when you look at the structure of
830640	836720	monstrosities, when you take the terephthalgists in, for example, in nature, you see that they
836720	838000	are very well organized.
838000	844420	You can make a taxonomy that is very well organized because not everything is possible.
844420	852380	So in the context of brains, we wanted to do something about that because, and as one
852380	858420	of the ambitions of the Santa Fe Institute, right, that think in really broad terms and
858420	860740	ask ourselves difficult questions.
860740	866760	So at some point, we talk about the idea of why not to try to make a kind of a space
866760	870040	of brains, of cognitions.
870040	877040	And in particular, it was clear that we have these solid brains, right?
877040	882360	Brains that I'm going to go into that in a moment, brains that are made by neurons located
882360	888880	in specific positions, right, and connected, and everything happens in the connections.
888880	894700	But uncolonies are a kind of brain of brains that are moving around, they're liquid.
894700	901540	Your immune system is a class of network that in many ways is like a neural network, right?
901540	904940	But the cells are moving all the time.
904940	905940	And so on and so forth.
905940	909220	So what happens with all these cognitions?
909220	911580	How likely are they?
911580	914180	How powerful they can be, all right?
914180	919800	So we decided to organize a little workshop with my colleagues, Melanie Moses and Stephanie
919800	922800	Forrest, about liquid brains, solid brains.
922800	928240	This is kind of a very ambitious idea because we brought together this group of very, very
928240	929760	interesting people.
929760	935120	But of course, we didn't know what was the outcome of this because we didn't have even
935120	938480	a definition of liquid brains, right?
938480	946820	So it was like our St. Patron Colma McCarthy said once, we met together to have more fun
946820	948520	that should be legal.
948520	956180	But the idea was actually to come out from that, from a first roadmap of cognitions.
956180	962180	I put it here, this was a special issue that came from this, a list of examples, right,
962180	967180	that include the microbiome, include plants, we'll talk about plants also because they're
967180	970200	kind of a solid organism.
970200	976920	And in around everything, we look for regularities.
976920	981880	They are common laws that we can use, common languages that we can use, and networks appear
981880	985000	to be the key here.
985000	992320	In a standard brain, right, you have the, as I was saying, fixed positions for neurons.
992320	997260	In a non-colony, your individual scarring brains are moving around, right?
997260	1002100	So they are no constant connections, the connections are broken and formed all the time.
1002100	1005180	And the same happens for the immune system.
1005180	1009560	So first question, why brains, right?
1009560	1016980	What is the evolutionary force that actually pushes things towards complexity towards brains?
1016980	1024000	This is one very nice hypothesis that we'll use in several times, which is the moving hypothesis.
1024000	1030280	It essentially says that if you live in an environment, when you need to search, an uncertain
1030280	1034640	environment, you look to search for resources, you don't know what resources are, you need
1034640	1039280	to move, you need to detect, you need to sense, brains are great for that, right?
1039280	1044700	They centralize information and centralize the way you move, okay?
1044720	1047600	So that's important for a number of reasons.
1047600	1053520	And the other way of looking at that is that brains, to a very large extent, are prediction
1053520	1054520	systems.
1054520	1060020	Some people say prediction machines, but they want to avoid the machine metaphor in the
1060020	1063640	sense that prediction is absolutely fundamental.
1063640	1066920	We predict all the time, right?
1066920	1073960	Okay, so first of all, and it will be totally unfair with our brains, right?
1073980	1075660	Because we don't have time.
1075660	1078820	But I brought a brain, okay?
1078820	1084540	Yeah, my family was so happy when I said that I had a brain, finally.
1084540	1088020	So this is kind of a very good model, right?
1088020	1091980	It kind of weights kind of a real brain.
1091980	1097340	The human brain is a spectacular combination of accidents.
1097340	1101420	So there are things that have been occurring over time.
1101420	1104240	Many things we don't understand, right?
1104240	1105240	But also of optimization.
1105240	1107600	There's optimized circuits.
1107600	1112600	As you probably know, it consumes a lot of the energy that we bring into our bodies,
1112600	1117560	about 25%, which means that it has to be important, right?
1117560	1122240	Not everyone uses that much, but it's important, right?
1122240	1128760	And it's made of, we know now, 86 billion neurons.
1129180	1133940	It was the Susana Eculano in Brazil, found out the way of counting.
1133940	1138820	And it works in a very dynamical way, right?
1138820	1142300	At any time, you record the activity of the brain,
1142300	1144860	you will see waves moving around.
1144860	1148980	We know now that these waves happen to occur between order and disorder,
1148980	1151020	in what we call a critical point.
1151020	1153660	And allow synchronize the system so
1153680	1159480	that you can actually put together information for different places, right?
1159480	1163200	And so have specialized areas working together, right?
1163200	1166760	It's a compromise between try to modularize the system and
1166760	1169800	try to put everything in place.
1169800	1174720	So there are several brains that correspond to this solid picture.
1174720	1179720	Very simple brains like Hydra, which is kind of a simple network.
1180700	1186060	Some more complex nervous systems, right?
1186060	1191140	But brains by themselves come later on in the evolutionary history.
1191140	1197140	And again, going into this idea of randomness versus strong laws.
1199180	1200540	Is the brain unique?
1200540	1204140	Could be very different ways of generating brains.
1204140	1208540	And in the recent years, people have been trying to think about that.
1208560	1212600	Well, we can make a theory of that and try to understand what makes the brain
1212600	1218480	special or maybe what makes the brain inevitable, all right?
1218480	1222480	So we could say, but if you want to build a revolutionary story of brains,
1222480	1224880	that's a difficult task, isn't it?
1224880	1230040	Because, for example, in terms of language or
1230040	1234640	the mind, you could say language, which is very central.
1234660	1237620	In the next lecture, we'll see how important is this and
1237620	1241300	how robots can help understand the origins of language.
1241300	1247260	But language, for example, somebody could say, it doesn't leave fossils.
1247260	1248500	The mind doesn't leave fossils.
1248500	1250860	Well, it's not completely true.
1250860	1254260	This is an example that I wanted to bring because it's simple.
1254260	1258420	But it brings an idea of what kind of things we can recognize.
1258420	1260900	Does anybody see that there's a strong regularity here?
1265620	1269460	These are hands of different people, right?
1269460	1274220	That painted is the cave of the hands in Argentina.
1274220	1280860	And what happens here is that if you look, it's all left hands, all of them, right?
1280860	1286900	Because the people who use whatever they use to paint, you're using the right hand, right?
1286900	1292460	And you know that nowadays, most people is right handed, okay?
1292680	1295520	And that symmetry was there already.
1295520	1299080	So we can see there's a trace of that particular thing.
1299080	1301120	But brains do spectacular things.
1301120	1305480	And particularly human brain with a visual cortex,
1305480	1312280	which is an amazing system that we have been using to do a lot of
1312280	1314400	very important things that we will discuss.
1314400	1317640	But one particular experiment we can bring and
1317640	1323060	that allows me to go into how we make theories of the brain is this, right?
1323060	1328300	In the left, you have a picture which has been kind of pixelated and
1328300	1332620	you only retain part of the texture, right?
1332620	1333780	Everybody sees what is there?
1335460	1336780	There's a dock.
1338380	1341100	The usual thing, it's a pattern here, right?
1341100	1342500	We don't know exactly why.
1342500	1345100	The pattern is some people already know.
1345120	1347880	Some people see the dock, right?
1347880	1350240	It's kind of like a Dalmatian.
1350240	1354680	Some people doesn't see anything, but when you say there's a dock, right?
1354680	1357200	The brain finds out, okay?
1357200	1360800	And then there's people who don't see it, right?
1360800	1362320	It's okay.
1362320	1366600	But the thing is that that kind of pattern recognition system,
1366600	1372640	which is extremely effective, we use constantly since we are toddlers almost,
1372660	1377220	is impossible to simulate with a standard program.
1377220	1380580	You cannot write a computer program to do this, right?
1382700	1390740	On the right part, what I'm putting is also the fact that once you recognize
1390740	1396660	that particular pattern here, it's going to be stuck in your brain forever.
1396660	1402020	So one day you go, in ten years ahead, you go to the house of a friend and
1402040	1407440	on top of the table is this picture covered in part, right?
1407440	1411080	It's very likely that those of you who recognize that say,
1411080	1417200	look, this is from that great lecture I went, right?
1418720	1422240	So how do we actually make a model of this, right?
1422240	1426520	It would appear that it has to be a very complex, very complicated model.
1426520	1433180	And everything starts and comes from the work of these two amazing characters,
1433180	1439140	Warren McCulloch and Walter Pitts, who actually came about with
1439140	1442820	the first formal model of a neuron.
1442820	1448740	And from that comes out all the neural networks that we use in
1448740	1452820	all the artificial neural applications, chat GPT and everything else.
1453760	1458200	We don't have time to talk about them, but if you search a little bit,
1458200	1464760	in particular Pete's on the right, he was a child prodigy.
1464760	1467120	He has a very, very interesting story.
1467120	1468560	They figure out how to do it.
1468560	1471480	And what they did was to transform a neuron,
1471480	1476400	which is a really complex system itself, into a mathematical representation.
1476400	1480200	To make the long story short, the idea is you have a neuron,
1480220	1483780	you have inputs from other neurons that set signals.
1483780	1488300	The signals can be positive, trying to make you to activate, or
1488300	1492340	can be negative, try to make you put down, getting active.
1492340	1494180	And you wait everything.
1494180	1496820	And once you wait, you have a threshold.
1496820	1500060	And if you go beyond the threshold, you activate, right?
1500060	1504460	And then the neuron sends another signal somewhere else, okay?
1504460	1508740	You can bring that mathematically in a very elegant way, okay?
1508740	1512200	And you can use now that for modeling a lot of things.
1512200	1517320	For example, John Hopfield, this amazing model,
1517320	1522240	which I will put in a nutshell as follows.
1522240	1524560	Imagine you have a collection of neurons.
1524560	1529200	For me, my neurons will be elements that they just are on and off, right?
1529200	1531360	They are active or inactive.
1531360	1534920	And I can put them to the dimensional layer,
1534940	1539260	like in a retina, like it's something that detects images, okay?
1540420	1544500	Now, it's possible to show, I connect everyone with everyone.
1544500	1548340	I use the maculok pits, threshold units, right?
1548340	1552860	And then it's possible to train the network, show images,
1552860	1555140	letters, whatever it is, okay?
1555140	1561460	So the network learns how, well, the rule is very simple.
1561460	1564860	If two neurons receive the same information, for example,
1564860	1569240	two black pixels, they reinforce their connection.
1569240	1574680	If they receive contradictory signals, black pixel, white pixel,
1574680	1577640	the connection between them is reduced.
1579000	1584120	That's all, no long computer program, nothing.
1584120	1588960	And you can show, using this, that this network is capable of doing
1588960	1591960	precisely what I was showing you before, right?
1591980	1595780	It's possible to show that in a space that is highly dimensional,
1595780	1598180	that depends on the number of connections, right?
1598180	1601900	You create kind of valleys, right?
1601900	1607300	This abstract space, valleys where the bottom of the valleys are the memories.
1607300	1611820	The things that you have made the network to learn.
1611820	1618060	For example, imagine that I have trained the network to learn only two images, right?
1618060	1619940	This one here, that one here.
1619960	1622400	You will create two valleys, and
1622400	1625440	in the bottom of the valleys you have the memories.
1625440	1626560	In what sense?
1626560	1631760	In the sense that, if now I show an image that is incomplete,
1631760	1634240	is the form, is distorted, right?
1634240	1637000	The network, just using the dynamics of my Culloch and
1637000	1640520	Pitts goes down the valley, right?
1640520	1643120	And reconstruct all the information, right?
1644320	1647400	I think this is totally amazing, right?
1647400	1651580	And shows the power of artificial neural networks.
1651580	1656780	But of course, this corresponds to a given model for
1656780	1658860	a given class of brains.
1658860	1663900	What about the potential universe possibilities, right?
1663900	1665020	I could imagine things.
1665020	1669980	These are, my drawing is about four things that we don't observe,
1669980	1671660	don't exist, right?
1671660	1672220	We'll offer them.
1672220	1677040	And in my lecture today,
1677040	1682760	I want to explore this idea of what kind of brains are there.
1684360	1686560	Whether there are very strong constraints, whether or
1686560	1692680	not brains are expected or there's a lot of possibilities.
1692680	1696040	And I'm going to use, there's a huge amount of examples here.
1696040	1699400	I'm going to use ants as one example.
1699400	1703420	Fissarum, which is kind of a very alien creature.
1704700	1707140	Discuss about plants, because there's been a lot of discussion in
1707140	1709900	the recent years about plant intelligence.
1709900	1714900	And show you that we can start to think in a space of possible
1714900	1717780	conditions, and how we do it, right?
1719020	1724660	So a very important point, liquid versus solid, right?
1725080	1731560	On the right hand side, you have a very small part of a neural
1731560	1733600	network of neurons connected.
1733600	1736880	Again, their locations remain the same over time.
1736880	1746000	And on the left, it's a very tiny part of a swarm of army ants, right?
1746000	1748760	I was very impressed when I was in Panama years ago,
1748760	1752560	seeing the army ants, which are blind.
1752560	1757940	They communicate in simple ways with their nest mates.
1757940	1764100	But forming these huge forms that, if you look from the distance,
1764100	1767620	look like a single organism moving around, right?
1767620	1770340	Swarming in the middle of the forest, quite a thing.
1771460	1777580	And so we want to see how we approach all these problems.
1777580	1781580	And in particular, one good question is, is a liquid brain
1781600	1784640	able to be as complex as a solid brain?
1786140	1790000	And the question is, is it relevant for a number of reasons?
1791800	1796200	One of the reasons is, let me see this, oops, there's a movie here.
1798200	1800720	Oh, yes, okay, sorry.
1806320	1806840	Let me see.
1806840	1812180	And the question is, in particular, because one good comparison we
1812180	1814620	can make is about us, right?
1814620	1818780	The, oh, man, what's happened?
1823280	1823780	Let me see.
1826980	1827500	Get into me.
1827500	1836820	And the question, of course, for a colony of ants is who is in charge?
1837140	1839860	I mean, ants are moving around, right?
1839860	1844300	It's not like a centralized system saying you have to do these and
1844300	1845540	that and that, right?
1845540	1852140	It's not such a thing as a queen giving orders to everyone else, right?
1852140	1858540	The queens in a way, as in European monarchies, are very useless,
1858540	1861700	except in this case, to put X, right?
1861700	1863380	So how do you control that?
1863380	1869200	And this sentence by Deborah Gordon, I think, is very to the point, right?
1869200	1871960	And for those of you who are fans of Richard Feynman,
1871960	1875360	Richard Feynman himself was interested in ants and
1875360	1880040	started to bring quite interesting questions about how ants work, right?
1880040	1881200	Well, two important things to say.
1883040	1886280	What makes ants and termites and social insects,
1886280	1890040	I can only address a few things, special.
1890040	1895100	And what do they do that is close to the brains that we were discussing,
1895100	1896820	the human brain, for example?
1896820	1901860	Well, on the one hand, they have managed to modify their environments.
1901860	1905340	They do what we call extended minds, right?
1905340	1910860	They create superstructures and the nests are the clear example.
1910860	1914580	And the nests can be extremely large compared with the single organisms.
1914580	1918780	In a termite nest, in some cases, you can have the very tiny,
1918800	1925160	homilimetric organisms, whereas the nest for termites in some parts of
1925160	1928520	Africa can be three, four meters high, right?
1928520	1931640	So ten orders of magnitude larger.
1931640	1933440	How do you build that?
1933440	1936280	Of course, termites don't know anything about that.
1936280	1937840	Again, they are blind.
1937840	1941120	They communicate in simple ways with chemistry.
1941120	1946320	So whatever creates the organization comes out from a collective phenomenon,
1946340	1951780	from self-organization, or what we call in complexity, emerging phenomena.
1951780	1956580	Phenomena that we can describe that even scale, network architecture,
1956580	1959900	or in our brains, consciousness, memory.
1959900	1964460	And that cannot be reduced to the properties of the individual parts.
1964460	1967940	You can spend your whole life studying single termites.
1967940	1970900	You'll never understand how they build the nests, right?
1970900	1976020	The key is that the collective behavior, the fact that the interaction between,
1976020	1981600	for example, termites and the material they use creates amplification phenomena
1981600	1986840	that lead to self-organization, in particular, to order patterns.
1986840	1993920	That picture there is a small part of the fungi factory that you have in
1993920	1996360	termite nest, in some cases, right?
1996360	2001240	And the explanation of the mathematics comes from what's called tuning structures.
2001240	2004080	But it emerges from the interactions, right?
2004080	2005520	In a liquid brain.
2005520	2008340	Another thing that is quite fascinating is,
2008340	2012460	ants can solve the problem of finding out the shortest distance.
2012460	2014960	How?
2014960	2018140	Imagine you have the ants like in the movie, right?
2018140	2023060	That are in the lab, you put a food source somewhere, and here is the nest.
2023060	2028820	If some ant detects that there's food here, they deliver a chemical signal,
2028820	2034060	which other ants find out reinforce, and eventually you create a signal
2034060	2036460	that goes beyond the individuals, right?
2036460	2039740	And individuals in the signal interact in nonlinear ways, and
2039740	2044100	you make this trail of ants that exploit the source very quickly.
2044100	2045140	What happens if you put two?
2046300	2051900	Well, the things can also be dependent on its scenario and its species.
2051900	2055140	But for example, if I have more food here than here,
2055140	2062340	they split at the beginning, but the source that is more abandoned is reinforced.
2062340	2065900	What happens if you make an experiment like the following?
2065900	2070700	Imagine you have the nest, you have the resource, the food here,
2070700	2072900	and you have a double bridge, right?
2072900	2075700	So there are two branches, and one is longer than the other.
2076740	2082540	Okay, individual ants are unable to know that, if this is longer or shorter.
2082540	2085580	But since they leave a chemical trail, right?
2085580	2090220	The longer part will lose, because of course,
2090220	2095740	the chemical signal is dissipated, is evaporated, will lose more by evaporation.
2095740	2100140	And eventually, everyone will go into the shorter chain, right?
2100140	2104620	So you need a collective phenomenon here to actually solve the problem of
2104620	2106100	the shortest path, okay?
2107700	2109660	And then you go into the question.
2110700	2116380	Is an an colony going to be as complex in terms of cognition as a brain?
2118380	2120140	I think the answer is no.
2120140	2124340	And the reason is, you can represent ants in different ways.
2124340	2128740	And I want to remember you that the ants have brains, right?
2128740	2131540	They are not neurons, they are brains.
2131540	2135740	But in brains, they can be half a million neurons, so it's not small.
2137260	2141460	But interestingly, when you make models of how the ants solve the shortest path
2141460	2145940	problem, how they build their nest, you can represent the ants in extremely simple
2145940	2146820	ways, right?
2146820	2150500	Sometimes even in on and off systems.
2150500	2155380	And so you can use that, you can represent the ants in this way.
2155380	2160940	And instead of using the McCulloch-Pitts model where neurons exchange things
2160940	2166900	in a fixed way, you can actually make what we call a liquid brain.
2166900	2171340	Here, for me, each ant can be, for example, an active or
2171340	2175060	an inactive neuron, they move around, right?
2175060	2179620	And over time, they interact exactly the same way that neural networks,
2179620	2182940	except that now they are changing in time, they are moving.
2182940	2189980	And one of the beautiful examples that we have explored comes from a war by
2189980	2194180	Deborah Gordon and colleagues, where actually they have these ants that
2194180	2199420	live in the desert, and you can see the ants doing special tasks, right?
2199420	2203420	They are exactly the same morphological identical, but they do different tasks.
2203420	2208380	They can forage, they can have nest maintenance, they patrol.
2208380	2213660	And you see that the same ants, over time, they might change task, right?
2213660	2219540	And also, if you are a bad person and you take, for example, all the foragers, right?
2219540	2220820	And see what happens.
2220820	2223660	What happens is the colony reorganizes.
2223660	2230660	So some ants that maybe were just making nest maintenance become foragers.
2230660	2235620	It reorganizes in such a way that it optimized the number of individuals that
2235620	2237340	do each task.
2237340	2241340	But then if you represent that with a mathematical model, etc., what you realize
2241340	2247860	is, remember the model I showed you with these ballies that were the memories, right?
2247860	2249860	Here you have also ballies.
2249860	2255380	But in this landscape, what is in the bottom is the number of ants that
2255380	2257340	are involved in each task.
2257340	2262500	Which is something that is much, much, much less rich, right?
2262500	2268900	You are not exploring a hyper-dimensional space of connections, because the connections
2268900	2271060	are destroyed all the time.
2271060	2275260	You generate something that has to do with the average number of things needed so that
2275260	2276860	the colony works.
2276860	2286740	Which for us, suggests that things like that depend on liquidity may be very limited.
2286740	2291860	In the science fiction literature, or in the movies, for example, Star Trek, I'm not
2291860	2295220	a tricky person, but it's an interesting example.
2295220	2296820	They propose this idea, the Borgs.
2296820	2304420	The Borgs is kind of a race of cyborgs, each one with a big brain, right?
2304420	2310620	With a queen that has a big brain and controls some things, right?
2310620	2318580	But the thing is, right, why do we don't see, for example, what I call brainy ants?
2318580	2321860	We don't see ants with a large brain, right?
2321860	2324980	It's a possibility in the space of what we can imagine.
2324980	2330660	And what we find out is, although the theory has to be developed, is that actually, if
2330660	2336380	you look closely, you find some things that are extremely interesting.
2336380	2345620	For example, it seems to be a trend for colonies that in a nutshell, the pattern is, you have
2345620	2349740	a very small colony, individuals can be complex.
2349740	2351540	I saw them in Panama also.
2351540	2358660	I saw these groups of ants, colonies with 100 individuals only, very large ants, everybody
2358660	2361380	warned us, don't touch them, right?
2361380	2366260	Because they are called 24 hours, that's the time we'll suffer the pain.
2366260	2373500	So I believe that, one of my colleagues didn't, and the experimental method.
2373500	2377580	And it was interesting because you approach the colony and the ants were outside with
2377580	2381300	big eyes, and clearly they saw us.
2381300	2386260	And if you look at the individuals, they were more or less making their decisions without
2386260	2388620	much worrying about anything else.
2388620	2394500	But if you take very large colonies where the colony itself can do extremely complex
2394580	2400060	things, interestingly, individuals get more and more and more dumb.
2400060	2402620	As if there was a trade of fear.
2402620	2406500	This has been called the complexity drain.
2406500	2409780	The complexity drain is something that we need to develop the theory of that.
2409780	2415740	Essentially, we'll say that the more complex the society, the less complex the individuals,
2415740	2416740	right?
2416740	2420940	Don't try to apply that to our societies, okay?
2420940	2427940	Anyways, my second example, my second example has to do with an extraordinary organism.
2428140	2430380	And I wanted to start with this.
2430380	2437380	This is a labyrinth that is in Barcelona in the orta quarter that is a replica of the
2437380	2442300	famous labyrinth of Gnosis, the minotaur, right?
2442300	2446740	Labyrinths have been something that mathematicians and all kinds of people have been fascinated
2446740	2447740	in.
2447740	2449540	How do you escape from a labyrinth?
2449540	2453780	Or is this the entrance and is this the exit?
2453780	2457300	How do you find the shortest path, for example, okay?
2457300	2459300	So Fissarum is able to do that.
2459300	2466300	Fissarum is not an animal, not a plant, is a slime mold, is a very simple creature.
2468060	2475060	And actually, some people describe it as a single cell, is a whole thing with many nuclei
2476060	2482900	inside, but essentially it is a single cell, except that it is extremely large, right?
2482900	2484100	You can see it in the forest.
2484100	2490700	And actually, when it was found many years ago in the time of the Sputnik, the people
2490700	2495540	who found out that blob, which is yellowish as it is like this, and it can be large as
2495540	2500460	my hand, found in the forest, they thought that it was kind of an alien thing, right?
2500460	2503100	That came with a spacecraft, of course.
2503460	2509500	Fissarum is amazing, it shifts all the time, has these network structures, sometimes looks
2509500	2515180	like a neural network, and searches in space looking for resources, right?
2515180	2519700	And if part of Fissarum finds something that is very rich, and he finds out that it's not
2519700	2523180	so rich, it deviates everything in this direction.
2523180	2529100	So you have all these tubes that pulsate over time, it's quite a thing.
2529100	2533900	And that gets thicker and thicker as you approach something that is richer.
2533900	2538340	And somebody used that in a very clever way, right?
2538340	2546580	So since Fissarum is so easy to cultivate, one thing I can do is take pieces of Fissarum,
2546580	2551900	put it within a labyrinth, an amaze, right, like here.
2551900	2558140	And then I'm going to use what Fissarum likes a lot, which is flakes, right?
2558140	2565620	One at the entrance, A, one at the exit, B. And over time, what you see in the movie
2565620	2568580	is that Fissarum is detecting two sources, right?
2568580	2574020	It's totally distributed, there's no centralized mind, there's no neurons at all, okay?
2574020	2577180	And what happens is that it's an amplification phenomenon.
2577180	2582180	As you go over time, you see that close to entrance and exit, right?
2582180	2588980	The tubes that Fissarum forms, that is what they need to actually push forward the detection
2588980	2591340	and exploitation, right?
2591340	2594220	They have these nice waves.
2594220	2601820	Eventually what happens is that you get in a single tube that goes all over the place
2601820	2606820	in the shortest path from the entrance to the exit, okay?
2606820	2610940	But if you want to model Fissarum, it's possible to do it.
2610940	2613420	You model it with a network, a network of what?
2613420	2616660	Of tubes connected like a fluid, all right?
2616660	2621780	And interestingly, the mathematics that is behind is a threshold network, right?
2621780	2626940	Even in that case, you need to use one mathematics that might be universal.
2626940	2630420	Fissarum has been used in a number of applications, mazes.
2630420	2635820	You can actually find out a network of roads.
2635820	2641180	You take a country, for example, you put flakes in the locations of different cities.
2641180	2644460	Fissarum is distributed all over the place.
2644460	2651540	And then the tubes that reinforce the connections between different pairs of sources, right?
2651540	2657820	Eventually draw this map, which you find out that is more optimal than the ones that engineers
2657820	2659060	built.
2659060	2663900	And it's been also used to actually map dark matter, right?
2663900	2668940	Some astrophysicists find out the way of actually use Fissarum to make a large-scale
2668940	2674180	model of the universe and infer the distribution of dark matter.
2674180	2676300	But I want to make a point.
2676300	2681540	Very often, and you can make logic gates and many things, very often it's said, look, Fissarum
2681540	2684860	can solve complex mathematical models.
2684860	2690980	And that is a distortion a little bit of what really happens.
2690980	2697380	We exploit the properties of Fissarum, this extraordinary capacity of searching around.
2697380	2703420	And this special capacity that, and that's very important, is based in a way of computing
2703420	2708020	things, a computation that has nothing to do with the standard computation we use.
2708020	2711020	The computation is the form, the shape.
2711020	2714700	The final shape is what is being computed.
2714700	2718820	But of course, we, the humans, we put what in physics, we say the boundary conditions
2718820	2719820	or in mathematics, right?
2719820	2726620	We put in place things and Fissarum just goes on with its dynamics, right?
2726620	2729660	So Fissarum doesn't solve problems in nature.
2729660	2734620	Solve problems that have to do with resources, but not mathematics, okay?
2734620	2736900	What about plants, right?
2736900	2741380	I hope there are not so many enthusiasts here of plant intelligence.
2741380	2744100	I'm a skeptic.
2744100	2749380	In the literature also, we have this, I don't know if everyone knows, the day of the triphids.
2749380	2752220	It's a classic novel science fiction.
2752220	2756660	We have these plants that are capable of moving, right?
2756660	2761340	And that, well, I don't want to spoil anything.
2761340	2762340	Just read it.
2762340	2764140	It's really cool.
2764140	2767060	So are plants intelligent?
2767060	2771300	Well, let me say first something.
2771300	2772780	Plants are extraordinary.
2772780	2775900	They have really transformed completely the planet.
2775900	2779340	When they invade land, they invented the sorts.
2779340	2781300	They created the forests.
2781300	2786140	They have this system of photosynthesis that creates quite an amazing super molecular system
2786140	2789660	with quantum properties that we're still trying to understand.
2789660	2792140	So they are amazing by themselves, right?
2792140	2796340	Do we need them to like Mozart?
2796340	2797340	Maybe not.
2797340	2798340	Maybe not.
2798340	2804420	Have in mind that plants, on the one hand, have this extraordinary capacity of changing
2804420	2809700	morphology, of adapting in a way that animals cannot do.
2809700	2812660	They give them a lot of advantage.
2812660	2818980	The thing is, when you look at plants and plants in the context, right?
2818980	2821060	Like in a forest.
2821060	2826500	Of course, there's a lot of complexity that has to do with things that we know from ecology.
2826580	2835180	Competition, competition, mutually is in place a very, very important role in many ways.
2835180	2839380	We start to uncover a lot of complexities there.
2839380	2843460	But is really this connected to cognition?
2843460	2846220	And I think it's important to go and look closely.
2846220	2848340	What do we have?
2848340	2854300	Plant cells, and there's a big constant with animal cells, are very rigid.
2854300	2861540	We have this wall that makes connections between them extremely constrained, right?
2861540	2868140	Connections, plasma of this matter, like that on the right in the upper picture is an electron
2868140	2873060	microscope picture of a channel that connects to plant cells.
2873060	2876460	But the architecture constrains a lot what happens there.
2876460	2881980	Of course, there are no neurons, it's been told that there are analogies, but no neurons.
2882980	2885780	Everything very much goes into two directions.
2885780	2887500	One is growth.
2887500	2890820	I have to grow and grow in a plastic way.
2890820	2892980	Another is defense, right?
2892980	2901420	Plants have developed a huge battery of chemical signals that connect them with the challenge
2901420	2904780	that we have from insect herbivores in particular, right?
2904780	2906580	There's a lot of investment in that.
2906580	2910740	And it shows, it shows very much.
2910740	2916780	On the other hand, one thing I wanted to mention, we will discuss that in the second lecture,
2916780	2923820	but John von Neumann, the mathematician that I showed you before, in his studies about
2923820	2929460	brains, unfortunately it wasn't at the end of his life, of brains versus computers, he
2929460	2932060	made this the following point.
2932060	2937500	At that time, the computers, these very big electronic computers, were very prone to fail
2937500	2941820	because the basic components were not much reliable, right?
2941820	2946500	And if a vacuum tube failed, the computer could fail.
2946500	2948820	And they knew that brains don't work like that.
2948820	2952100	Your neurons, every day you lose neurons.
2952100	2958380	And you can even have a big loss of neurons and the brains capable of have plasticity
2958380	2963420	to return the system to the previous state, not computers.
2963540	2969540	He ended up in a conclusion which was, maybe we need systems that are very redundant, right?
2969540	2970620	Very, very redundant.
2970620	2972420	That's part of the solution, really.
2972420	2976100	But if you look at plants and compare with animals, what is the difference?
2976100	2977980	Well, many differences, right?
2977980	2982260	On the one hand, they stack in the same place, right?
2982260	2987140	So you think in the moving hypothesis, if I have to move, I need brains.
2987140	2992340	If I don't, maybe I don't need brains.
2992340	2994780	On the other hand, for example, you think in organs.
2994780	3000260	If I ask you how many organs you have, you are not going to say, well, I don't know exactly.
3000260	3002140	You do know, right?
3002140	3003860	You do.
3003860	3006500	One heart, two kidneys, et cetera, et cetera.
3006500	3010380	And all of this is decided in embryogenesis.
3010380	3012220	In plants, we see a very different situation.
3012220	3015060	How many organs we have?
3015060	3016060	Many.
3016060	3018620	Every single leaf is an organ, right?
3019500	3024260	They are formed and degrade and happen all the time.
3024260	3029660	And also, for example, at the level of leaves, we have discovered that if you analyze the
3029660	3035100	network of transport within leaves, which is a beautiful structure, you can see that
3035100	3038740	it's optimized for doing two things.
3038740	3045940	One, deliver the nutrients everywhere, right, in the most efficient way.
3046700	3052060	To protect themselves from damage, an insect can make a hole.
3052060	3057340	You have seen, for sure, leaves that are damaged in different ways, but you want to warranty
3057340	3058620	that you get there.
3058620	3061060	The transport keeps going well.
3061060	3064660	If you have loops, the right amount of loops, you can do it.
3064660	3072660	And this is a picture of one of these damage experiments where using a kind of fluorescent
3072660	3073780	marker.
3073780	3079220	You can see how it propagates and goes into the whole leaf again using the loops.
3079220	3080220	And it's optimized.
3080220	3081900	You can do a theory of that.
3081900	3089100	So you have many organs that can be lost, are essentially redundant, so you don't really
3089100	3092780	need to have a central control system.
3092780	3096940	In the second lecture, I'll try to convince you that this is probably the case, right,
3096940	3102180	that plants, because of they don't need that, and they are extraordinarily well-adapted
3102180	3107940	in different ways, right, might not have anything like brains or intelligence.
3107940	3115580	So fissurum, plants, brains, ants, how do we put this together?
3115580	3122020	And the idea, still work in progress, right, is to create what we call a morphospace, a
3122020	3124100	space of possibilities.
3124100	3129060	In this particular example that we used some years ago, I used three axes.
3129060	3131980	The vertical axis is how important is development.
3131980	3133300	Design is very important.
3133300	3135180	Nature constructs things, right?
3135180	3140540	You have embryos that develop and get into complex architectures.
3140540	3147500	In the horizontal axis is the liquid to solid, right, the state of matter that we have.
3147500	3153380	And in the other axis is how complex is your cognition, how complex are your decision-making
3153380	3158620	and how diverse is the way you actually sense and respond to the environment.
3158620	3163700	We locate things here in relative positions, okay?
3163700	3170740	For example, organs are kind of simple cognitive systems, right, or we could put, they are
3170740	3176740	the outcome of development, they might be just responding to simple signals, or they
3176740	3180580	might involve feedbacks that are more complex.
3180580	3183820	This is the artificial part of the story.
3183820	3188980	Organisms and organs have a counterpart in bioengineering, which is organoids, right,
3188980	3194780	which opens the possibilities that we will discuss in the second lecture.
3194780	3201620	Of course, brains, and of course, you can see I put a single sphere here representing
3201620	3206900	all solid neural networks, right, this is an oversimplification.
3206900	3213620	The immune system, which is a system that can learn where cells can have memories, where
3213620	3219980	collectively you have phenomena that remind us a brain, right, but they are liquid, they
3219980	3220980	move around, right.
3220980	3225940	We are living in a very interesting time now where it seems that because our understanding
3225940	3230580	of these networks, we might actually fight cancer and other things in a very effective
3230580	3231580	way.
3231580	3237020	And of course, I put hands in the middle between liquid and solid, high development because
3237020	3243020	an uncolline actually, if you look at how it generates, it comes from the queen, the
3243020	3251020	first X, the first individuals, the structure that goes emerges in a totally predictable
3251020	3256420	way and ends up into something that is the structure plus the colony that is inside kind
3256420	3261020	of a liquid system, right.
3261020	3268780	The microbiome, the millions and millions of bacteria that we carry out that makes us
3268780	3274580	something that is not anymore a single species, the idea that we are one species, we have
3274580	3278540	to abandon because we really are much more than that.
3278540	3283420	The microbiome, we'll talk about that also in the second lecture, has been co-evolving
3283420	3285460	with us.
3285460	3290940	The more we know, the more clear it is that many diseases we couldn't understand but it
3290940	3296060	was how they work are connected with the microbiome and the great thing is that we can intervene,
3296060	3301260	change the microbiome and maybe fight those diseases, right.
3301260	3306740	And this microbiome interacts with the immune system and with the brain, right, which means
3306740	3310820	that we have a lot of things at play.
3310820	3316020	Fissarum, somewhere also in the middle between liquid and solid, okay.
3316020	3321420	And this is kind of the big picture and they want to bring to your attention something
3321420	3327540	that is quite visible, is this big sphere that occupies a lot of space.
3327540	3334460	This big sphere is what we say is a void in the morpho space, meaning that when you look
3334460	3339540	at the natural world, you don't see anything there.
3339540	3340940	Why is that?
3340940	3344300	Because it's forbidden.
3344300	3351060	Because evolution for some reason is unable to get there, that's a big question.
3351060	3358100	For many of us, it is an indication that is a lot, is plenty of space to explore and
3358100	3363260	that if you are able to engineer things, we might go right there, right.
3363260	3365500	And I'll show you examples soon.
3365500	3367340	Okay.
3367340	3371500	So now I just give you all these examples but I'm sure that some of you are thinking,
3371500	3376260	yeah, yeah, but there's one particular example that you are not talking about, right.
3376260	3381900	And that is quite bizarre, right.
3381900	3385740	Of course, yeah, octopus.
3385740	3391660	Octopus has been receiving a lot of attention over the last two decades.
3391660	3392660	Why?
3392660	3398740	Well, it's on the one hand is an extraordinary example of how evolution creates in a totally
3398740	3409140	different trajectory in the tree of life, a mind that is remarkable, right.
3409140	3413820	Octopi, they can learn, they have memory.
3413820	3417900	You can see that they repeat the same words, right.
3417900	3420940	But they also have clearly curiosity.
3420940	3426460	There's been described many times that the octopus can be really interested and engaged
3426580	3435580	into approaching humans, for example, and trying to, I don't know, figure out what we're doing.
3435580	3441780	In the lab, it's been discovered that they recognize particular people, or sometimes
3441780	3446980	that they can escape from the fish tank by night because there's a camera recording.
3446980	3451140	Go to another fish tank to visit someone, I guess.
3451140	3453820	And get back.
3453820	3454820	Why they get back?
3455580	3459740	There's plenty of things that we don't understand.
3459740	3464700	And not surprisingly, it has been used often in the context of science fiction.
3464700	3474740	This comes from a snapshot from the movie The Arrival, where this is the question of
3474740	3476740	the language we'll discuss tomorrow.
3476740	3479740	Language is the big thing, right.
3479740	3484800	And you could say this is totally bizarre, totally different, totally alien.
3485720	3488720	But, well, not that much.
3488720	3493720	The interesting thing I want to bring is, if you analyze the brain of an octopus, right,
3493720	3498280	you can have the microscope, you make slices, see what's the architecture.
3498280	3501320	If you ask a histologist, what do you see here, right?
3501320	3505080	You might not have seen any time an octopus' brain.
3505080	3513240	But he will say, okay, this is a brain, probably some vertebrate, because I see the neurons.
3513240	3517920	The neurons are these amazing structures that have the polarity, you have this special
3517920	3518920	structure.
3518920	3521560	When you look at the shape of a neuron, what do you see?
3521560	3524760	You see a cell that is trying to connect, right?
3524760	3526680	This is a big function.
3526680	3528920	You see multilayers.
3528920	3535480	So interestingly, in a different universe of possibilities, in invertebrates, a totally
3535480	3542680	different branch, you generate an animal that has the same kind of eyes we have, that has
3543640	3549280	a neural architecture that resembles things that we are very familiar with, okay?
3549280	3555120	Of course, they are peculiarities, they have the central brain and something that acts
3555120	3561280	like eight autonomous brains, one for each tentacle, right?
3561280	3568800	But what this brings is that, again, it looks like maybe the space of possibilities is not
3568800	3569800	that big.
3569840	3573200	Even in that case, where you have this amazing animal, right?
3573200	3577560	So why octopus are not more complex, right?
3577560	3578560	They are interesting.
3578560	3579960	They are clearly interesting.
3579960	3587720	But for example, why cephalopod in general have not gone into using tools, for example.
3587720	3593680	And it comes this interesting constraint that has to do with the life of these animals.
3593680	3597040	Unfortunately, octopi don't live much.
3597040	3603680	In some species, one year, in some two years, maybe three, but that's all.
3603680	3612200	So thinking in the bioengineering, the possibilities in the future, you cannot avoid to think.
3612200	3617040	What if we were able to make an octopus to live more, right?
3617040	3623120	An animal that clearly learns over time has a brain that has this potential, right?
3623360	3631240	And that brings me into, and I am trying to attract you to the second lecture, okay?
3631240	3639160	Of course, to answer the questions I'm making about how brains originated, why brains will
3639160	3643600	require to have a picture of evolution, what happened, really.
3643600	3645760	We don't have a time machine.
3645760	3652800	But we have an alternative, which is extremely interesting, and I will show you, provides
3652800	3659200	very new fundamental questions that I think in the future might solve the questions that
3659200	3662280	we have been making before.
3662280	3663280	And that will be all.
3663280	3664280	Thank you.
3664280	3677480	Do we have time for questions?
3677480	3689880	Maybe I can try, oh, there we go.
3689880	3692080	So we have time for some questions.
3692080	3712360	I would like to know how that plant or whatever it was, you're not to laugh at me, got in
3712360	3714240	and out of that maze.
3714240	3719600	How did something go into the maze and find its way out?
3719600	3722600	You mean for the organism I was mentioning?
3722600	3728240	Yeah, there was Fissarum, it was this single cell organism.
3728240	3735080	And in nature, you have, for example, imagine you put Fissarum in some place, you have different
3735080	3737400	sources of food, right?
3737400	3743720	Fissarum is all the time expanding, like I'm searching around space.
3743720	3749000	And then this information about the different resources comes to the collective, it's kind
3749000	3754720	of integrating information all the time and making decisions about which one is richer
3754720	3757400	and minimizing the trajectories.
3757400	3763520	You don't want to make a lot of channels and invest energy and resources to create tubes.
3763520	3766400	You want to, well, this is necessary.
3766400	3771680	So what happened in the maze is that you put these two resources in those particular places
3771680	3774560	that have sense for us.
3774560	3776560	We know this is the entrance, this is the exit.
3776560	3778520	Fissarum doesn't know anything.
3778520	3783880	But then the amplification that is made here creates these tubes that are very strong here,
3783880	3784880	right?
3784880	3786480	And the same principle applies.
3786480	3792280	In the end, you try to exploit which is really rich, right?
3792280	3798480	And connect these sources in the shortest path you can make.
3798480	3800520	And that solves the maze.
3800520	3805640	But again, have in mind that we humans put the maze there, right?
3805640	3825720	To prepare the problem, it's an important difference.
3825720	3827200	Thanks for a brilliant lecture.
3827200	3829760	Your drawings are like Leonardo da Vinci, really.
3829760	3830760	Thank you.
3830760	3831760	Fantastic.
3832160	3836920	This is a question that's very stupid, but I've been asking it since I was six years old,
3836920	3841800	which is today, of course, it seems completely obvious to all of us that we think with our
3841800	3843200	brains.
3843200	3849000	But I wonder whether early man knew that they think with their brains.
3849000	3854520	Because if you look at all the cave paintings we have, you have the hands, you have animals,
3854520	3855520	you have human figures.
3855960	3863480	But you don't have heads necessarily as being more important than any other body feature.
3863480	3868760	So I just wonder if there's any history in the scientific research of when we began to
3868760	3873200	realize that we think with our brain.
3873200	3877520	You mean as rational creatures that we knew that there was a brain?
3877520	3881440	Or when the brain become became relevant?
3881440	3884000	I think back to earliest human beings.
3884000	3889600	The earliest development of communication, language, hunting, coordination, whatever
3889600	3895080	it was, did they realize that this was what was working?
3895080	3896080	Okay.
3896080	3897080	Okay.
3897080	3898080	It's not a stupid question.
3898080	3901360	It always happens in all the talks when somebody brings it.
3901360	3906160	This is going to be a stupid question and it's not at all.
3906160	3911520	In fact, tomorrow I'm going to bring a little bit about what part of the singularity of
3911520	3916320	the human brain is there.
3916320	3920600	I will make a bit of spoilers here.
3920600	3926160	The human brain is interesting for a number of reasons and had a very important impact
3926160	3928280	in an evolutionary history.
3928280	3930760	Just to mention a few things.
3930760	3935400	One is language, of course.
3935400	3937560	Language is a pretty extraordinary piece.
3937640	3946160	These days of chat GPT, chat GPT for a number of reasons is not intelligent but brings some
3946160	3953840	interesting ideas about the importance of language in evolving reasoning.
3953840	3959000	One thing that I find extraordinary is very, very important and we also bring that tomorrow.
3959000	3960500	It's time.
3960500	3966280	Somebody said that we are mental time travelers.
3967280	3969400	You remember what we mentioned before.
3969400	3971720	We are prediction machines.
3971720	3975360	The brain is something that tries to predict what's going next.
3975360	3981200	This is very, very important because in the end what makes brains worth is that we are
3981200	3984880	able to reduce uncertainty.
3984880	3992920	We make us more prepared to actually be understanding what's next, what's going to happen.
3993040	3997640	We had this cortex that expanded so much.
3997640	4004120	This kind of understanding of time became something that was the narrative.
4004120	4009880	We became able to make narratives, not only one feature.
4009880	4015320	We can imagine many possible features.
4015320	4018200	It's very interesting to see how it happens in evolution.
4018200	4023480	Somebody said you all know that memory is faulty.
4023480	4025520	Memory sometimes fails.
4025520	4032720	Sometimes you have memories that are not real, memories that are being constructed.
4032720	4035160	Somebody can say, why is that?
4035160	4038520	Because natural selection doesn't care about that.
4038520	4041120	Natural selection wants you to predict the future.
4041120	4043360	The future is important.
4043360	4047920	If you remember well or not the past is not so important.
4047920	4050520	An important thing that connects maybe more with your question.
4050520	4058440	One of the things that made us successful, as ants are successful because they cooperate,
4058440	4062080	some days it doesn't seem so, but we are cooperators.
4062080	4065520	Being a cooperative species made a big difference.
4065520	4071960	One of the drivers of that was our amazing capacity of understanding the mind of the
4071960	4073960	other.
4073960	4082720	Understanding that somebody that is looking at me is suffering or is scared or is something
4082720	4084400	that can create trouble.
4084400	4087800	I can put myself in the mind of the other.
4087800	4095080	When you combine all this stuff, we have a singularity plus a lot of other things like
4095080	4096680	mental diseases.
4096680	4098880	But it's a whole story.
4098880	4102800	I don't want to spoil because as I was saying, one of the things I want to bring tomorrow
4102800	4110320	is when you try to approach the complexities of the human mind, there's a kind of a synthetic
4110320	4126120	or artificial path that can bring a lot of understanding.
4126120	4131600	At one point, you were talking about ants, I think, and their colonies and that the
4131600	4140080	more complex the society, the less complex the individuals needed to be.
4140080	4144200	But we shouldn't apply that to humans.
4144200	4147200	But you said we shouldn't apply that to humans.
4147200	4149360	I think, why?
4149360	4158320	Well, I mean, not every day I feel like the human race deserves good words.
4158320	4168360	But individual humans are spectacularly complex, provided that you're being immersed in the
4168360	4169360	cultural thing.
4169360	4174240	Our brains are nothing unless you are in a society that goes from language to almost
4174240	4177520	everything else.
4177520	4184720	But I think that on the one hand, because of the evolutionary pressures that apply for
4184720	4194360	ant colonies, that had to do with the warranty of the colony works, and eventually that reproduces.
4194360	4197920	It's a different story for us in many ways.
4197920	4203160	I also try to bring that tomorrow and make a good comparison.
4203160	4209040	I must say that this trend we observed, but we still don't have a good theory for the
4209040	4211480	complexity drain.
4211480	4217960	But definitely, I remember that Michael Lachman, which was a faculty also at Santa Fe Institute
4217960	4223560	one day, we were discussing about this, the brain of humans, and he brought me to something
4223560	4232120	that is, in a way, is trivial, but it's interesting, is that you isolate a human from society and
4232240	4237960	the brain, this extraordinary potential machine is worthless.
4237960	4244880	You might survive, maybe, as some kids survive with wolves, but all the potential of the
4244880	4247840	brain is never going to develop.
4247840	4253720	So it again says something about the fact that we are also cultural animals, and that
4253760	4255760	makes a difference.
4255760	4262760	I understand the utilitarian and the intellectual reasons, like that you do experiments with
4285760	4293760	animals on octopus, octopi, but aren't there ethical considerations on how we do all these
4293760	4297520	studies on sentient beings that aren't us?
4297520	4304640	Yeah, that's a very good point, and I'm sure you know that there's a hot topic these days.
4304640	4310760	The more we know about some species, the more clearly we need to have ethic criteria of
4310760	4316760	what is reasonable and what is not for the next experiments.
4316760	4322760	Even if we will say that, because we don't know, to what extent we can talk about that
4322760	4325760	sentience and consciousness, etc., we still don't know.
4325760	4332760	But the precursors of a complex mind, clearly we are seeing it in many species, right?
4332760	4338760	The elephants clearly mourn, they kind of feel the loss of others.
4338760	4343760	In the octopi, we see that kind of extraordinary curiosity.
4343760	4345760	What brings that there?
4345760	4347760	So this is on the table.
4347760	4353760	It's a hot discussion, because one thing, as you can imagine, is that to make you want
4353760	4359760	decisions about what is ethically reasonable or not, we first need to actually have good
4359760	4364760	definitions of whether or not you have sentience.
4364760	4367760	Can these be measured in some way?
4367760	4382760	So it's a good point and it's a relevant research problem now.
4382760	4384760	I have a question too.
4384760	4387760	Are you wondering about instinct?
4387760	4394760	Is that also part of the brain or is the instinct separate from the brain?
4394760	4399760	Which you have kind of not mentioned in your lecture so far.
4399760	4400760	I don't know if you understand.
4400760	4402760	You say, insect brains?
4402760	4407760	The instinct, the instinct that living organisms have.
4407760	4415760	I mean, is that part of the brain or is that something else?
4415760	4418760	You mean for, you say, insect?
4418760	4419760	Instinct.
4419760	4420760	Oh, instinct.
4420760	4421760	Sorry, sorry, sorry.
4421760	4428760	But you have to, I mean, I came here, you don't know that, but I came straight from
4428760	4433760	Barcelona, 26 hours, and I was brought here.
4433760	4437760	My brain is not as good as it should.
4437760	4439760	Yeah, actually, that's a good point.
4439760	4445760	Instinct clearly is something that is part of the machinery, right?
4445760	4452760	In many cases, you see that working in a very almost algorithmic way, right?
4452760	4465760	This is a famous example of these wasps that kill, no, sorry, that use their stings to
4465760	4470760	actually put the eggs inside prey that are paralyzed, right?
4470760	4473760	Could be spiders, could be something else.
4473760	4482760	And they first make a hole, and then they hunt, they take, I don't know, could be larvae
4482760	4484760	or whatever it is.
4484760	4489760	They go there, they leave the prey there, which is paralyzed.
4489760	4492760	They go inside, check out that everything is okay.
4492760	4496760	Go out, take the larvae, put it inside.
4496760	4502760	But then what happens is, if you, while this is happening, imagine that you are a mean entomologist.
4503760	4511760	And you are looking, and then when it goes inside, you move the prey, which is paralyzed, right?
4511760	4512760	Somewhere else.
4512760	4517760	So you see the wasps coming out, finding out that something has changed.
4517760	4519760	They kind of managed to touch a little bit.
4519760	4522760	They go inside again.
4522760	4526760	And if you can repeat that operation as much as you want.
4526760	4530760	It's like an algorithm which clearly goes from instinct, right?
4530760	4536760	But on the other hand, in insects, we also been finding in the last 20 years many unexpected things.
4536760	4540760	Like some wasps recognize the face of others.
4540760	4544760	There are asymmetries, apparently, in the brains of some ants.
4544760	4548760	So it's plenty of still of things we need to know.
4551760	4556760	So it was a question here, and another there.
4557760	4562760	You defined, you defined some really interesting questions that are very simple.
4562760	4565760	Like why brains, and what kinds of brains.
4565760	4572760	But I didn't hear you say what constitutes being a brain.
4572760	4575760	Like what's your definition of a brain?
4575760	4577760	So how do you define a brain?
4577760	4578760	Okay.
4578760	4583760	I try to avoid that question, right?
4584760	4598760	I mean, in a simple way, a brain is a collective of neurons that centralizes the activity of an organism, right?
4598760	4603760	So for a hydra, for example, you have a net of neurons,
4603760	4607760	or for a jellyfish, you have a ring and a distributed thing.
4607760	4615760	But you don't have really a core of neurons that are playing a role of kind of integrating information, right?
4615760	4623760	So that would be a kind of, I think, a potential definition, but it's disputed, right?
4623760	4626760	I think for me, it's satisfactory.
4627760	4644760	When you were showing the example of the ants who managed to figure out the shortest route to the food,
4644760	4653760	or the termites who end up creating something that is a benefit to the society,
4653760	4661760	or the single-celled organisms that find the shortest route to the flakes in the maze,
4661760	4669760	it seems like more often than not, in these experiments, you have similar sort of outcomes
4669760	4675760	that the ants are successful in doing this, the termites are successful in doing this,
4675760	4680760	and the single-celled organisms are successful in doing this.
4680760	4688760	But when you take humans acting like a liquid brain,
4688760	4697760	they often come out to solutions that are harmful to the organism as a whole,
4697760	4709760	especially in the area of finance, where if you have a lot of individuals here coming to conclusions,
4709760	4717760	they're more likely to come to this wrong conclusion, which ends up making a few people very rich
4717760	4725760	and other people very poor, and I'm puzzled by this.
4725760	4728760	Okay.
4728760	4738760	Well, it's not an easy question, so it requires a long answer, so close the doors.
4738760	4741760	No, I am now seriously.
4741760	4744760	Yeah, when we go into humans, it's interesting to see two things.
4744760	4755760	One is what you mentioned, because humans, as you move beyond pure commission and you have society,
4755760	4761760	with all the biases that some can deal with, incomplete information,
4761760	4764760	plus the big problems we have about polarization and everything,
4764760	4769760	which is something that in complex systems we want to solve, but it looks like very, very difficult.
4769760	4777760	But on the other hand, it's just a small part of research, but it's interesting for the insight it brings.
4777760	4787760	When humans are under the situation of panic, you can make very well-defined models,
4787760	4794760	which essentially is like particles moving by forces and amplifying phenomena.
4794760	4796760	Things that we see and have consequences.
4796760	4805760	For example, in a stadium, you have two exits, and this has happened unfortunately a number of times.
4805760	4807760	It's panic.
4807760	4808760	It's a panic attack.
4808760	4810760	We don't reason there.
4810760	4812760	We just want to survive.
4812760	4821760	A typical trend is that the more people go into one exit, the more people go there, which of course is harmful,
4821760	4823760	because there's another exit.
4823760	4831760	You can model that, and it's interesting to see that you do the same experiment of panic with ants and with humans,
4831760	4835760	and that's one place where you can compare.
4835760	4839760	Very unfortunately, we behave like ants.
4839760	4843760	If we move beyond that, and it's a legitimate question,
4843760	4851760	under what conditions we can actually be described as systems like collective intelligence in ants,
4851760	4859760	and what is the threshold that separates from that and gets into society and all the conflicts that you're mentioning?
4859760	4862760	But this is a whole area of research.
4862760	4864760	So, good point.
4864760	4873760	One thing that we need to actually figure out is to what extent these ideas of collective intelligence apply to humans.
4873760	4883760	And if theory develops, whether we could actually explore the insight of the theory to actually help us to exploit common knowledge,
4883760	4885760	that clearly now is underexploited.
4885760	4889760	So maybe a third lecture on third day?
4889760	4893760	Thirdly, you have to be in Barcelona.
4893760	4909760	Okay, we have time for one more question.
4909760	4916760	Hi, I was interested in your chart where you have your three dimensions,
4916760	4920760	and you have this big sphere of the unknown or the unexplored,
4920760	4924760	and I wanted to know, it was like, yes, that's the one.
4924760	4933760	So, what we're missing is cognitively complex and developmentally complex as well, or maybe that doesn't matter.
4933760	4937760	But I'm wondering what you think that could look like.
4937760	4942760	You said that we might be able to manufacture it, something in that space.
4942760	4944760	I said what, sorry.
4944760	4952760	I thought I caught you saying, sneakily, maybe that in this unexplored space,
4952760	4959760	maybe that's where we have space to manufacture some sort of brain-like thing.
4959760	4963760	I'm just wondering what you think is in that space that we're missing.
4963760	4970760	Okay, if you come to the second lecture, I think I have the answer for that.
4970760	4974760	I don't want to make more spoilers.
4974760	4976760	Alright, thank you so much.
