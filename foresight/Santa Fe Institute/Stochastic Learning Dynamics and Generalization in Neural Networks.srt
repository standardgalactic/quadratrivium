1
00:00:00,000 --> 00:00:04,320
What I'm going to tell you about is some recent work

2
00:00:04,320 --> 00:00:06,560
we have done in trying to understand the learning

3
00:00:06,560 --> 00:00:10,160
dynamics in the neural network, feed forward neural network,

4
00:00:10,160 --> 00:00:12,880
from your based on a statistical physics point of view.

5
00:00:12,880 --> 00:00:16,080
So you will see.

6
00:00:16,080 --> 00:00:18,480
Got it, OK.

7
00:00:18,480 --> 00:00:23,240
OK, so I will start with some basic introduction.

8
00:00:23,240 --> 00:00:26,600
What I call the central dogma of machine learning.

9
00:00:26,600 --> 00:00:28,520
Focus on two main things, but I think

10
00:00:28,520 --> 00:00:31,040
is very important, which I think physicists

11
00:00:31,040 --> 00:00:34,640
can contribute to optimization and generalization,

12
00:00:34,640 --> 00:00:36,000
to understand these two things.

13
00:00:36,000 --> 00:00:39,080
And then I'll talk along and talk about the topic.

14
00:00:39,080 --> 00:00:42,280
One is really about the dynamics of learning in feed

15
00:00:42,280 --> 00:00:43,960
forward neural network.

