{"text": " What I'm going to tell you about is some recent work we have done in trying to understand the learning dynamics in the neural network, feed forward neural network, from your based on a statistical physics point of view. So you will see. Got it, OK. OK, so I will start with some basic introduction. What I call the central dogma of machine learning. Focus on two main things, but I think is very important, which I think physicists can contribute to optimization and generalization, to understand these two things. And then I'll talk along and talk about the topic. One is really about the dynamics of learning in feed forward neural network.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.32, "text": " What I'm going to tell you about is some recent work", "tokens": [50364, 708, 286, 478, 516, 281, 980, 291, 466, 307, 512, 5162, 589, 50580], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 1, "seek": 0, "start": 4.32, "end": 6.5600000000000005, "text": " we have done in trying to understand the learning", "tokens": [50580, 321, 362, 1096, 294, 1382, 281, 1223, 264, 2539, 50692], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 2, "seek": 0, "start": 6.5600000000000005, "end": 10.16, "text": " dynamics in the neural network, feed forward neural network,", "tokens": [50692, 15679, 294, 264, 18161, 3209, 11, 3154, 2128, 18161, 3209, 11, 50872], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 3, "seek": 0, "start": 10.16, "end": 12.88, "text": " from your based on a statistical physics point of view.", "tokens": [50872, 490, 428, 2361, 322, 257, 22820, 10649, 935, 295, 1910, 13, 51008], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 4, "seek": 0, "start": 12.88, "end": 16.080000000000002, "text": " So you will see.", "tokens": [51008, 407, 291, 486, 536, 13, 51168], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 5, "seek": 0, "start": 16.080000000000002, "end": 18.48, "text": " Got it, OK.", "tokens": [51168, 5803, 309, 11, 2264, 13, 51288], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 6, "seek": 0, "start": 18.48, "end": 23.240000000000002, "text": " OK, so I will start with some basic introduction.", "tokens": [51288, 2264, 11, 370, 286, 486, 722, 365, 512, 3875, 9339, 13, 51526], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 7, "seek": 0, "start": 23.240000000000002, "end": 26.6, "text": " What I call the central dogma of machine learning.", "tokens": [51526, 708, 286, 818, 264, 5777, 3000, 1696, 295, 3479, 2539, 13, 51694], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 8, "seek": 0, "start": 26.6, "end": 28.52, "text": " Focus on two main things, but I think", "tokens": [51694, 21862, 322, 732, 2135, 721, 11, 457, 286, 519, 51790], "temperature": 0.0, "avg_logprob": -0.29120316872229945, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.019931143149733543}, {"id": 9, "seek": 2852, "start": 28.52, "end": 31.04, "text": " is very important, which I think physicists", "tokens": [50364, 307, 588, 1021, 11, 597, 286, 519, 48716, 50490], "temperature": 0.0, "avg_logprob": -0.35186292304367317, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.006536283530294895}, {"id": 10, "seek": 2852, "start": 31.04, "end": 34.64, "text": " can contribute to optimization and generalization,", "tokens": [50490, 393, 10586, 281, 19618, 293, 2674, 2144, 11, 50670], "temperature": 0.0, "avg_logprob": -0.35186292304367317, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.006536283530294895}, {"id": 11, "seek": 2852, "start": 34.64, "end": 36.0, "text": " to understand these two things.", "tokens": [50670, 281, 1223, 613, 732, 721, 13, 50738], "temperature": 0.0, "avg_logprob": -0.35186292304367317, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.006536283530294895}, {"id": 12, "seek": 2852, "start": 36.0, "end": 39.08, "text": " And then I'll talk along and talk about the topic.", "tokens": [50738, 400, 550, 286, 603, 751, 2051, 293, 751, 466, 264, 4829, 13, 50892], "temperature": 0.0, "avg_logprob": -0.35186292304367317, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.006536283530294895}, {"id": 13, "seek": 2852, "start": 39.08, "end": 42.28, "text": " One is really about the dynamics of learning in feed", "tokens": [50892, 1485, 307, 534, 466, 264, 15679, 295, 2539, 294, 3154, 51052], "temperature": 0.0, "avg_logprob": -0.35186292304367317, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.006536283530294895}, {"id": 14, "seek": 2852, "start": 42.28, "end": 43.96, "text": " forward neural network.", "tokens": [51052, 2128, 18161, 3209, 13, 51136], "temperature": 0.0, "avg_logprob": -0.35186292304367317, "compression_ratio": 1.4514285714285715, "no_speech_prob": 0.006536283530294895}], "language": "en"}