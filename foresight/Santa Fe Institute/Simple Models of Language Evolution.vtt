WEBVTT

00:00.000 --> 00:04.640
Are you still a reader in mathematical neuroscience? Is that still accurate?

00:04.640 --> 00:07.520
I've changed all our titles a little bit. Okay, so a man of many titles.

00:09.440 --> 00:13.520
Whatever I was at Bristol, I know you were the head of the Computational Neuroscience Unit,

00:13.520 --> 00:19.520
and he was also an examiner for my PhD five. So super, super happy to have him here today.

00:19.520 --> 00:25.040
Thank you, Connor. Brilliant. Sorry, one second. Cool. Well, I'm super excited to be here. This has

00:25.040 --> 00:28.720
always been kind of a legendary location for me. I've always wanted to visit, and

00:30.320 --> 00:34.880
it's really blown me away. It's an amazing looking place. It's my first time in New Mexico, and oh

00:34.880 --> 00:40.080
my god, the countryside here is just incredible. I assume that it's traditional to start talks here

00:40.080 --> 00:45.360
with some reminiscence about the time that you met Murray Gaumann. So I met Murray Gaumann 20

00:45.360 --> 00:49.360
years ago. I was still a particle physicist then. He was coming through 20 College Dublin,

00:49.360 --> 00:53.040
where I was working at the time, and he asked me where I was from, and I said I'm from Galway,

00:53.040 --> 00:59.120
which is true. And he said, oh yes, Galway, home of this, Galway, off whose coast the Spanish Armada

00:59.680 --> 01:04.160
founded in the storm, saving the British Navy the trouble of sinking it. Home too, he said,

01:04.160 --> 01:09.840
to the myth that the lusty sailors thus wrecked, swam ashore, and bred with the local women to

01:09.840 --> 01:17.040
create the black haired Irish. Something he said that is not true, the black haired Irish are

01:17.040 --> 01:21.840
presumably the remnants of the indigenous population, the population there before

01:21.920 --> 01:26.960
and accounts of population whose traditions and cultures we know from archaeology,

01:26.960 --> 01:31.280
but whose language is wholly lost and unknown. And I was just incredibly impressed by the whole

01:31.280 --> 01:36.240
thing. I mean, he knew where Galway was. He knew that we had this link with Spain. He knew about

01:36.240 --> 01:40.320
the Spanish Armada sinking. He knew that we all believed, as it turns out incorrectly, that the

01:40.320 --> 01:48.800
Spanish sailors had created these sort of black haired folk in Galway. And he told me this

01:48.800 --> 01:52.560
interesting thing about how these black haired folk are probably the remnants of the indigenous

01:52.560 --> 01:57.520
population. And I was always intrigued by this idea that there was a language that they spoke,

01:57.520 --> 02:01.680
which is now completely lost. The idea of these completely lost languages is lovely.

02:01.680 --> 02:06.880
It also struck me with something of a show off, but that's true too. But it was very impressive.

02:06.880 --> 02:13.520
And so I'm very, very, very glad to be in the Murray Gilman building. I was, I did start life

02:13.520 --> 02:17.440
as a particle physicist and then became a neuroscientist and only started working on language

02:17.440 --> 02:22.560
recently. So I don't know that much about it. But the reason I started working on language was I

02:22.560 --> 02:27.840
read this kind of bizarre quote from Novichonsky, which says, in their essential properties,

02:27.840 --> 02:31.920
and even down to fine details, languages are cast in the same mold. At the Martian scientists,

02:31.920 --> 02:36.080
my reasons we conclude that there's a single human language with differences only at the margins.

02:36.080 --> 02:41.920
And that just seemed so, so wrong to me. And, you know, I thought

02:42.880 --> 02:49.840
that maybe that is an accident of not, you know, thinking about how different languages are. It

02:49.840 --> 02:53.040
seemed to me, you know, the languages are incredibly different from each other. And I'm

02:53.040 --> 02:57.680
looking with where I'm from to know a little bit of Irish. And Irish is, you know, although an

02:57.680 --> 03:04.720
inter-European language is more different to, you know, English than maybe French and so on is.

03:04.720 --> 03:08.320
I mean, for starters, it has a different word order. One of the more striking features is the,

03:09.280 --> 03:14.480
it doesn't have a verb possession. So here, this is the Irish for, I have a newspaper, Thon,

03:14.480 --> 03:21.280
Newton, Ogham. And what's happening there is that there's no, the Thon is just the verb is. So the

03:21.280 --> 03:26.640
literal translation of that sentence is the newspaper is at me. The Ogham is a preposition

03:26.640 --> 03:30.880
combined with the pronoun, which is a feature of Irish. And prepositions do a lot of work in Irish

03:30.880 --> 03:35.360
that it's done by other parts of speech in other languages. So instead of saying that you have

03:35.360 --> 03:40.320
a newspaper, you say the newspaper is at you. And similarly, Thon, Newton, Ogham, the new

03:40.320 --> 03:44.160
newspapers from me is how you'd say that you wanted the newspaper. So it's strongly that,

03:44.160 --> 03:51.040
you know, that languages are very different from each other. And that it's wrong to

03:51.040 --> 03:57.600
presuppose that languages all spring from the brain in the way that Chomsky is suggesting.

03:58.320 --> 04:06.800
Because, you know, his idea is that the languages bear the imprint of the human mechanism. Whereas,

04:06.800 --> 04:10.800
for me, as a neuroscientist, at the time, somebody knew about how vision worked and so on,

04:10.800 --> 04:14.320
it seemed that languages were much more likely to just be the unfolding of some

04:14.880 --> 04:20.560
search for statistical structure. And maybe something to do with the properties of the world

04:20.560 --> 04:25.200
around us, the fact that there are actions, and there are, and hence verbs, and there are objects,

04:25.200 --> 04:30.800
and hence nouns. But of course, I'm no longer sure that I was right in thinking that. And I've

04:30.800 --> 04:35.440
begun to appreciate something of the wisdom of what Chomsky said. And of course, another example

04:35.440 --> 04:40.480
from Irish Thon, Newton Thum, the newspaper is under me. That's how you'd say the newspaper is

04:40.480 --> 04:46.000
about me. But there you can see that even in English, the same work is being done by the

04:46.000 --> 04:52.240
prepositional construction as is being done in the Irish. In other words, although, you know,

04:52.240 --> 04:56.000
the Irish uses a different preposition and prepositions tend to vary as you probably know

04:56.000 --> 05:01.280
a lot from language to language. The idea of using a preposition where you might otherwise

05:01.280 --> 05:09.840
have a different verb is not so unique to Irish. And so maybe languages are somewhat similar to

05:09.840 --> 05:13.840
each other. And it struck me, or strikes me, as I'm sure it strikes you, that this is a really

05:13.840 --> 05:19.680
important question. I love this sign because it says that the vehicles will be prosecuted without

05:19.680 --> 05:24.480
warning. But this is a warning sign. So of course, it makes it impossible for them to do that.

05:24.480 --> 05:31.360
And I have here started to remind me to comment on the idea that language is complicated because

05:31.360 --> 05:37.440
some aspects of language are to do with what's in the world. The structure of language is structured

05:37.440 --> 05:43.600
by its use case, by communication. And some parts of language presumably are to do with the

05:43.680 --> 05:51.520
human ability to communicate, or our ability to perceive, or the calculations we do in

05:51.520 --> 05:57.120
producing, interpreting meaning and in producing meaning. And some parts might be more idiosyncratic

05:57.120 --> 06:02.880
to do with some linguistic mechanism. And deciding between these, deciding, you know,

06:02.880 --> 06:08.160
recognizing the fact that we can say something like this, which logically makes no sense at all,

06:08.160 --> 06:14.240
but which, you know, in a Wisconsinian fashion, quite clearly communicates something. It is a

06:14.240 --> 06:20.560
property, you know, is something that's deeply rooted in who we are, and our language is a part

06:20.560 --> 06:25.760
of how we conceive of ourselves as conscious individuals. And separating what's special

06:25.760 --> 06:30.720
about language, what's special about us, what's special about, with, you know, what language

06:30.720 --> 06:36.400
necessarily has as a communication medium, seems an interesting and an important challenge.

06:36.880 --> 06:43.200
So, of course, as a neuroscientist, when I decided I was interested in this, the first

06:43.200 --> 06:50.240
inclination was to do EEG experiments. And I wanted to start talking a little bit about that

06:50.240 --> 06:56.240
before talking a little bit more about models of language evolution. I started off actually

06:56.240 --> 07:00.720
trying to do EEG experiments on Irish speakers. I don't know how much you know about Ireland

07:00.720 --> 07:04.480
that Irish speakers, but it turns out that trying to do EEG experiments on Irish speakers

07:04.480 --> 07:07.920
is very difficult, because lots of people who claim they can speak Irish actually really can't.

07:09.440 --> 07:12.240
As I did a whole series of experiments on people who claim they can speak Irish and

07:12.240 --> 07:17.680
discovered, in fact, the EEG just told me that they were lying. So I went back to working on

07:17.680 --> 07:23.600
English speakers. And I was interested in testing this idea that the brain does privilege grammatical

07:23.600 --> 07:28.480
structure over mere statistical structure. Now, if any of you have done EEG experiments,

07:28.480 --> 07:31.680
you'll know just how damn difficult they are. I mean, the idea that we detect

07:32.560 --> 07:36.320
electrical fields outside the brain is actually slightly surprising, because you'd expect

07:36.320 --> 07:40.400
all the electrical fields to cancel out. And the only reason we can detect anything at all

07:40.400 --> 07:44.080
is that there's a slight preponderance of synapses pointing one way around another.

07:44.080 --> 07:50.240
And then, of course, you bathe the whole thing in salty fluid, which makes it hard to detect

07:50.240 --> 07:56.000
anything. For cognitive experiments, the difficulty is still greater still. And I'll refer to this a

07:56.000 --> 08:02.640
few times. This EEG data is obviously showing somebody having an epileptic fit and they were

08:02.640 --> 08:06.480
induced by tooth brushing, so they started brushing their teeth, and here they have the fit.

08:06.480 --> 08:11.360
And you can see that it's a very pronounced activity. But for cognitive tasks, of course,

08:11.360 --> 08:16.400
not only is the activity not so pronounced, I mean, epilepsy is distinguished by the

08:16.400 --> 08:22.080
synchrony of neural activity. So that's exactly the thing that's recently easy to detect.

08:22.080 --> 08:27.520
Cognitive things aren't so distinguished. And secondly, of course, when you're

08:27.520 --> 08:32.400
doing an EEG experiment, when you're a participant, you tend to sort of think other things. You're

08:32.400 --> 08:35.760
there, the stimulus is being played to you. You're supposed to be thinking about the stimulus,

08:35.760 --> 08:39.600
but in fact, you're thinking, oh my god, I wish I wasn't doing this experiment anymore. Oh my god,

08:39.600 --> 08:43.200
this is really boring. Oh my god, all people are immortal. I'm going to die someday. I wonder

08:43.200 --> 08:50.400
what I'll have for dinner. I mean, it's very hard to detect cognitive stuff with EEG. So

08:51.360 --> 08:57.440
the thing that we did, again, following a paradigm that was introduced by David Peeble and Naiding

08:57.440 --> 09:03.040
and his co-workers, was a frequency tag experiment. So in a frequency tag experiment, to try and

09:03.040 --> 09:10.560
separate a signal from noise, you concentrate your stimulus at a particular frequency. And so that

09:10.560 --> 09:15.360
you know, noise tends to stuff that you're not interested in, people thinking about their mortal

09:15.360 --> 09:20.000
end or the end of the experiment, that happens at all sorts of frequencies. But if your stimulus

09:20.000 --> 09:24.480
is at a particular frequency, then you can use Fourier transform or whatever to concentrate

09:24.480 --> 09:27.760
on the thing that you're interested in. So in this experiment, we play people

09:28.400 --> 09:32.560
adjective noun sentences. We've choose the adjectives and nouns, so they're single syllable.

09:32.560 --> 09:36.240
We record them and then coerce them a little bit so they're all exactly the same length.

09:36.240 --> 09:40.480
We play the syllables at 3.125 hertz. That just turns out to be a particularly good

09:40.480 --> 09:44.800
frequency for, it's a comfortable frequency for listening to syllables. We have long, long streams

09:44.800 --> 09:48.480
of these things. I mean, we have old rats, that man, ill wife. It goes on and on forever.

09:49.440 --> 09:53.120
And we choose the adjective nouns quite carefully so that the

09:54.400 --> 09:59.120
bigrams between old and rat and rat and sad are roughly the same. You can't get them exactly

09:59.120 --> 10:03.200
the same, but you try and keep the statistical structure the same. And then what you see here

10:03.200 --> 10:08.640
is that obviously there's going to be a response in the EG to the stimulus at 3.125 hertz. But

10:08.640 --> 10:14.640
there's something else happening, which is the noun phrase. So if there's a response at 1.5625

10:14.640 --> 10:19.840
hertz, that's a response to something that's not directly in the stimulus, but is related to the

10:19.840 --> 10:25.200
meaning of the words. And what interpretation is that that's because the brain privileges noun phrases

10:25.200 --> 10:31.840
over not noun phrases. And the other example is an adjective verb stream. In the adjective verb

10:31.840 --> 10:38.880
stream, we make sure we have the same sort of biogram structures as we had for the adjective

10:38.880 --> 10:43.520
noun. It's likely to come beside each other as old and man or whatever it was I had before.

10:44.960 --> 10:52.640
But now there is no grammatical structure. So if we see a response at 1.5625 hertz

10:54.400 --> 10:59.760
for the first stimulus and not for the second, that's indicative of the brain responding hopefully.

10:59.760 --> 11:04.480
It's indicative to the brain privileging a grammatical structure, which was I guess the

11:04.480 --> 11:09.200
one thing to be interested in. It turns out these data are quite hard to analyze.

11:10.000 --> 11:13.520
You know, you think all you have to do then is take the Fourier transform and look at the size

11:13.520 --> 11:20.720
of the peak at those particular frequencies. But EG is extremely noisy. And so if you do that,

11:20.720 --> 11:27.200
you don't see anything. What you have to do is look for the phase locked component of the response.

11:27.200 --> 11:33.760
So you play lots of these streams, so you make each stream five seconds long. You play repeatedly

11:33.760 --> 11:38.480
the stream. And then you look for that portion of the response, you know, once you've taken the

11:38.960 --> 11:45.280
transform, that portion of the response which has a similar phase. And the complication, of course,

11:45.280 --> 11:51.120
is that the overall phase is not so important. It depends on how big your head is and where the

11:51.120 --> 11:59.120
electrode is and all sorts of other things. And so the actual phase of people's responses

11:59.840 --> 12:05.920
at whatever frequency, at one point, whatever it is, isn't important. And you can see that here.

12:05.920 --> 12:10.400
So this is just each of these dots, each of these lines corresponds to a participant.

12:10.400 --> 12:14.960
We had 16 participants in this experiment. And then for each participant, we've got all the

12:14.960 --> 12:20.960
different electrodes. And this is the average phase of the response averaged across. It was 10 trials

12:22.640 --> 12:29.120
for each participant for each stimulus. So this is the adjective noun, stimulus. And in the dot

12:29.120 --> 12:34.480
is for the 32 electrodes. And just for convenience, for ease of comparison, three of the electrodes

12:34.480 --> 12:38.800
have been picked out and are cut at the same across the participants. And basically all you can

12:38.800 --> 12:44.160
see is that the actual overall phase is quite different. And so what's interesting is, you

12:44.160 --> 12:49.760
know, each of these dots hides the fact that there's 20 trials. Each trial has its own phase.

12:49.760 --> 12:56.240
And the signal is in the degree of alignment of that phase. And so to analyze these data,

12:56.240 --> 13:00.240
well, the easiest way to do it, it turns out, is to make some complicated Bayesian models. So we

13:00.240 --> 13:04.400
imagine the phase is being drawn from some distribution. In this case, it's circular

13:04.400 --> 13:09.280
Cauchy distribution, which turns out to be the nicest. The circular Cauchy distribution is quite

13:09.280 --> 13:15.120
cool. It's just a wrapped Cauchy distribution. And when you do the wrapping, you can set some

13:15.120 --> 13:22.320
of the theories and come up with an analytic formula for it. You say the data is kind of noisy,

13:22.320 --> 13:27.280
right? Immensely. Yeah. So the Fourier transform is also like pretty noisy.

13:27.280 --> 13:31.440
Yes. Yes. So you have to go through several steps. So, you know, obviously,

13:32.240 --> 13:36.480
for start using the frequency tag experiment makes it less noisy because, you know, the other stuff

13:36.480 --> 13:40.720
is happening at different frequencies. But even then you have to do this sort of phase lock analysis,

13:40.720 --> 13:45.760
which I'm briefly reviewing. I don't want to spend too long on it. If you're interested in the

13:45.760 --> 13:50.480
analysis of EEG data, we've been thinking about it a lot. And I can talk to you about it afterwards.

13:50.480 --> 13:56.480
But basically, in summary, we make a big Bayesian model of the results. What we're looking for,

13:56.560 --> 14:03.040
we imagine the phases have been drawn from a wrapped distribution. We have some prior for the

14:03.040 --> 14:07.440
variance of that distribution, some prior for the mean, that doesn't matter. And so the signal

14:07.440 --> 14:14.320
will be in this, the posterior distribution of this phase of this variance for the phase.

14:14.320 --> 14:22.240
And so this basically is the result. Here, we're looking at the, it basically is the inverse of

14:22.240 --> 14:28.320
this variance, what they call the mean circular resultant against frequency. And so, sorry,

14:28.320 --> 14:32.880
I'm standing in front of the camera. And so what we're seeing here is the

14:34.640 --> 14:39.280
different frequencies. This is the frequency of the syllables. This is the frequency of the phase.

14:39.840 --> 14:45.040
For the adjective verb condition, you see that there's a big response at the syllable rate,

14:45.040 --> 14:48.720
as there is for all of these conditions. These are other conditions. This is mixed lexical,

14:48.720 --> 14:54.240
mixed phrase, random. We did six different conditions, but we'll just concentrate on these two.

14:55.280 --> 14:59.520
For both the adjective noun and the adjective verb, there's a response at the syllable rate,

15:00.320 --> 15:05.920
showing up as a reduction in the variance of the phases. But for only the adjective noun,

15:05.920 --> 15:12.400
are you seeing a response at the noun, at the, at the phrase rate? This, on the right,

15:12.400 --> 15:18.160
this is some basic equivalent of the usual bar and star type graph. All it's really indicating

15:18.160 --> 15:23.920
is that the adjective noun condition shows substantially, or you might say significantly more

15:26.800 --> 15:32.800
response, which is, again, a significantly more mean resultant, just like the inverse of variance,

15:33.760 --> 15:40.720
than these other conditions, which is basically showing that the brain has a response to the

15:40.720 --> 15:46.320
grammar. That we can't just think of the brain as performing a statistical inference on the

15:46.320 --> 15:53.120
sentences, trying to extract meaning and so on. It does something every time it hears a noun phrase,

15:53.120 --> 15:59.120
and it doesn't do anything every time it hears an adjective verb word pairing, because that

15:59.120 --> 16:06.160
isn't a grammatical object, or at least that's the interpretation. So, you know, having done this,

16:06.160 --> 16:11.440
I was, I was kind of amazed. It shows that there is sort of stuff happening in the brain that,

16:11.440 --> 16:18.480
that is more formal or more, more akin to a grammatical manipulation than, than you might

16:18.480 --> 16:25.280
have expected, and shows sort of the presence in, in, in this, you know, in this discussion as to

16:25.280 --> 16:28.960
what part of language is about the world, what part of language is about communication, what

16:28.960 --> 16:33.520
part of language is about the machinery the brain has to deal, to deal with language. There's more

16:33.520 --> 16:37.920
in that sort of brain part than you might think, and it's certainly, will it be of interest to

16:37.920 --> 16:44.640
start to consider grammar, and the brain's view of grammar. Now, of course, these,

16:46.480 --> 16:51.520
these stimuli that we were dealing with are, are quite new that we were using, as I said,

16:51.520 --> 16:58.160
following this idea of people in a ding, this frequency tagged paradigm, where you are playing

16:58.160 --> 17:04.960
the stimulus at a set frequency in order to be able to extract the EG signal of interest. But

17:04.960 --> 17:09.280
it's very hard to, to, to come up with, you know, there's lots of things that you can't do with that.

17:09.280 --> 17:16.000
We were able to examine the presence of noun phrases, etc. But what you'd really like is to

17:16.000 --> 17:21.520
use free text like this, with like complicated, you know, sentences, different types of grammar,

17:21.520 --> 17:29.280
and so on. This would be better as well, because one problem with the, the frequency tagged

17:29.280 --> 17:34.240
experiments is that they are quite, quite boring and annoying to, to, to be a participant in those

17:34.240 --> 17:39.600
experiments. And it doesn't encourage this kind of thinking away from what you're supposed to be

17:39.600 --> 17:47.760
thinking. The problem here is the, is the difficulty in, in, in analyzing the data and, and trying to

17:47.760 --> 17:54.080
show a relationship between the EG response and, and, and what's going on. So, you know, what,

17:54.080 --> 17:59.600
what we'd like to do, I think, is to understand what grammar looks like to the brain. You know,

17:59.600 --> 18:04.560
we, we know what Grammaticians think grammar looks like, but we don't know, you know, but

18:04.560 --> 18:08.640
I often think about the phrenology skills that people were interested in in the 19th century.

18:08.640 --> 18:13.120
The pseudoscience phenology divided the brain up into regions of the brain that did different

18:13.120 --> 18:16.560
things, which is actually true. There are regions of the brain that do different things,

18:16.560 --> 18:20.160
but they got it completely wrong. You know, they, they thought that the cerebellum was the organ

18:20.160 --> 18:25.600
of amethyst, which is bizarre. In fact, it had some role to do with predicting the consequence of

18:25.600 --> 18:30.560
motor commands or something. So, you know, the, the, the ideas we have about grammar might be

18:30.560 --> 18:35.440
quite different from what grammar actually looks like. And to, to probe that, about one thing

18:35.440 --> 18:39.280
certainly to do would be to, to, to do EG experiments with free text.

18:39.280 --> 18:45.280
So, Connor, like, so just to kind of get an idea of the experiment itself. So you'd have like,

18:45.280 --> 18:48.320
I know you said this is going to be like really complicated, but in principle, you'd have your

18:48.320 --> 18:52.800
participants in a room reading this out loud and you'd just be looking at the brain signals. Is

18:52.800 --> 18:56.720
that the, you would be reading it to them and you'd be reading the two brain signals. Yeah.

18:56.720 --> 19:01.040
So, so, I mean, here, here's the results. So, I mean, there are people, you know,

19:01.040 --> 19:05.680
it's not just us that's trying to do this. There are lots of labs doing experiments along these

19:05.680 --> 19:13.040
lines. Stephen Frank in Namegun, for example. You have measures of kind of comprehensive,

19:13.040 --> 19:18.160
like some behavioral output, you know, did like, what is, what's the point of the brain responding

19:18.240 --> 19:23.760
to these things? Are you, are you measuring that as well? Like in the previous experiment,

19:23.760 --> 19:27.360
you showed that there was a response better, but like, why, right? Like, what is that,

19:28.000 --> 19:31.440
what is that, what is that doing for? I mean, what we do do is we make sure people are paying

19:31.440 --> 19:36.720
attention. Okay. So we have a detention trap. We introduce particular words that they're supposed

19:36.720 --> 19:42.400
to press a button to show that they're still paying attention. We, one advantage of the

19:42.400 --> 19:48.160
Bayesian analysis is you can check the participants are, you know, you can, there's terms in the,

19:48.160 --> 19:51.440
in the, you know, you have a big Bayesian model. There's a term to do with the participants,

19:51.440 --> 19:55.520
you know, attentiveness. You can see that some of the participants are clearly not paying attention.

19:55.520 --> 19:58.000
You can look at them through the window and see they're not paying attention as well.

19:59.040 --> 20:07.840
You know, I guess I'm asking like a deeper question about, you know, you're asking what,

20:07.840 --> 20:12.000
what is language for, what's the brain for? Just like some of these responses,

20:13.920 --> 20:18.240
I'm always skeptical, particularly, I mean, I'd know the fMRI literature much better than the

20:18.240 --> 20:22.400
EEG literature of where you just record a response and you say, okay, this brain,

20:22.400 --> 20:26.960
this part of the brain, there's a response to something, but without some sort of behavioral

20:26.960 --> 20:30.000
output that you're measuring connected to that response, I'm always skeptical of

20:30.800 --> 20:32.880
how much, how much does that actually tell us about,

20:33.120 --> 20:40.400
you know, what's actually happening and why, why we should care that there's a response there.

20:40.400 --> 20:44.000
I mean, we should care there's a response there, because it shows that we are responding to the

20:44.000 --> 20:50.000
noun phrases. And that's part of a story where, you know, we want to understand how the brain

20:50.000 --> 20:56.320
understands language. How do we answer that? Well, I'm not sure. And, and you, you know,

20:56.320 --> 21:01.120
people try behavioral experiments, they try manipulations to see how it changes people's

21:01.120 --> 21:06.080
understanding and so on. There's, you know, there's a long history of this. But it hasn't

21:06.080 --> 21:13.120
yet produced an account of language. And I'm not to answer your question going to produce one either.

21:14.960 --> 21:22.320
But that's absolutely what we need to do. I mean, so I guess my idea at the moment

21:22.320 --> 21:30.400
is that we start, that we use the EEG response as some sort of proxy for, for what's happening.

21:30.400 --> 21:37.120
And we try and see, well, just let me say what we've done here, for example. So again, we're

21:37.120 --> 21:43.200
looking at the EEG response to free text. We're doing some big regression, and we're trying to see

21:43.840 --> 21:48.400
how people are responding to different types of words. And what we can see what this is showing

21:48.400 --> 21:53.680
is that for part of the EEG response, there is a difference in how people are responding to

21:53.680 --> 21:59.120
words according to the categorization of the words into function and content. And so we can see that

21:59.920 --> 22:05.200
people's brains respond differently to some particular categorization of word. And so

22:05.200 --> 22:09.680
what you might be optimistic about is that if you've got better at this, you could try different

22:09.680 --> 22:17.280
categorizations and match them to different ideas about how the brain might approach parsing language.

22:18.560 --> 22:24.160
But I agree. You can hear that then to maybe the grammars of the linguistics.

22:24.160 --> 22:28.080
Yeah. And then separately, of course. Mel asked me not to mention transformers,

22:28.080 --> 22:34.400
but then separately, you look at, you can probe how large language models deal with language. You

22:34.400 --> 22:39.920
can probe the grammatician's approach to language. You can probe the whole linguistic

22:39.920 --> 22:44.960
tradition of our accounts of how language is dealt with. And then this gives a sort of neural

22:44.960 --> 22:50.160
account, the neural view of what grammar is like. But whether that's going to work or exactly the

22:50.160 --> 22:55.920
details of that, I don't know. And so certainly what I would advocate is that we could collect a

22:55.920 --> 23:03.840
big data set, you know, with lots of dots of different languages. The little prince, as maybe

23:03.840 --> 23:09.040
you know, is the non-religious text that has been translated into the most languages. It exists in

23:09.040 --> 23:14.960
300 languages. It exists as an audiobook in 50 or 60 languages. And so it's been suggested by these

23:14.960 --> 23:21.040
folk here, Jinxing Lee, Brennan, Haile and some of their co-workers, that we collect a large

23:21.680 --> 23:26.080
corpus of different varying qualities, some, you know, some MEG, which is, you know,

23:26.080 --> 23:31.280
very high quality, some consumer EEG, but with many more participants across lots of languages.

23:31.280 --> 23:36.880
And we start trying to understand, from the point of view of the brain, what grammar looks like.

23:38.080 --> 23:43.840
So far, this hasn't been done. And I guess people are trying to raise money to do it and have failed.

23:44.800 --> 23:51.520
So that's, you know, that's just by way of sort of motivation. That's where I came into thinking

23:51.520 --> 23:56.480
about language. And, you know, my interest in language is trying to understand, you know,

23:56.480 --> 24:02.240
how is language, what's special about language, what makes language, language. And of course,

24:02.240 --> 24:05.520
when you start thinking about this, you start asking these questions, how do we do these

24:05.520 --> 24:08.960
experiments? And it strikes you that there's a whole sort of separate story to language,

24:08.960 --> 24:13.520
which is to do with evolution. And maybe the hope that if we think a little bit about evolution,

24:13.600 --> 24:19.120
about how languages arise from evolution, the species point of view, and then separately,

24:19.120 --> 24:26.240
how languages change, it would be, it might tell us something about the innate structure of language.

24:26.240 --> 24:30.480
And maybe we can then think about how language, why languages might have to be the way they are,

24:30.480 --> 24:36.480
compared to other ways they could be. And I think this is, you know, a very interesting question.

24:36.480 --> 24:42.720
One of the sort of striking things is that, well, you know, we know from Creole languages and

24:44.720 --> 24:51.360
sign languages and so on that languages do arise with a large amount of their structure

24:51.360 --> 24:55.920
already present. But it's still an open question as to whether there are parts of language

24:55.920 --> 25:01.520
that develop through time, you know, as languages evolve, do they, do they change in a consistent

25:01.520 --> 25:08.480
way? Or are they the same from the very start? So near where I work, there's a museum, the Bristol

25:08.480 --> 25:15.680
Museum, and Art Gallery, I left that bit out. And they have some of these freezes from Nimrod.

25:15.680 --> 25:21.040
So the palace at Nimrod was broken up by people who went there and they took the panels and sent

25:21.040 --> 25:27.440
them all around the world in, I guess, an act of gross theft, although what was left in Nimrod

25:27.440 --> 25:32.800
has since been destroyed, so in the way it was quite lucky. And these panels do have this kind

25:32.800 --> 25:39.360
of cuneiform script written across them. It's a standard inscription. And it's Ashnirah. Ashnirah

25:40.880 --> 25:46.320
is basically showing off in this description. So this standard inscription here in cuneiform

25:46.320 --> 25:51.360
explains what a great person he is. And some of it's quite sort of bloody as this bit is,

25:51.360 --> 25:55.360
there are men young and old, I took prisoners of some I cut off their feet and hands of others

25:55.360 --> 26:00.400
I cut off the ears, noses and lips of the young men's ears. I made a heap of the old men's beads

26:00.400 --> 26:05.360
I made him heads, I made him in a rash, et cetera, et cetera, et cetera. Some of it's much nicer.

26:05.360 --> 26:11.040
It's about making pleasure palaces and beautiful things, et cetera. But I couldn't find any of

26:11.040 --> 26:15.520
that in an easily cut and pasted form. So I had to get this rather bloody bit instead.

26:16.480 --> 26:23.440
It says something about our civilization. But the point anyway, is that what is striking

26:24.080 --> 26:31.040
in the text is the lack of sort of the normal clause structure. There's very few instances or

26:31.040 --> 26:35.360
no instances of the sort of clauses that you might expect where there's who and which is

26:36.000 --> 26:42.400
and so on linking together the sentences. Instead, it's this rolling list, this very sort of list

26:42.400 --> 26:47.280
like structure. And so you wonder is that because the language has not at this point

26:47.280 --> 26:51.520
evolved all the structures of modern language, the sort of merge and clause structures that we

26:51.520 --> 26:58.240
have now, or is it just that that's how they like to write in their ceremonial functions.

26:58.240 --> 27:02.480
So just striking that there's a lot to be gained from trying to understand

27:02.480 --> 27:07.920
something about the evolution of language. And so that's what I wanted to talk a little bit about

27:08.640 --> 27:15.520
now. And so the first thing I wanted to talk about is really is to urge a return considering

27:15.520 --> 27:22.320
the iterative language model that Simon Kirby and his co-workers came up with about 20 years ago.

27:22.320 --> 27:28.000
So I don't know if you know the iterative language model, it's a language, it's a model for the

27:28.000 --> 27:37.520
evolution of languages. The story is that Kirby and his co-workers discovered it. They simulated

27:37.520 --> 27:43.200
a little bit, but they came quickly hard up against the computational limitations at the

27:43.200 --> 27:50.480
time. It is quite computationally expensive. And so they worked on it and then they kind of abandoned

27:50.480 --> 27:56.320
it and went on to try and do the same experiment that they'd done in simulation in real people.

27:56.320 --> 28:01.920
And so Simon Kirby has very successfully spent the last 20 years using toy languages and toy

28:01.920 --> 28:09.280
language learning as a pro into how people learn languages, but hasn't considered much beyond the

28:09.280 --> 28:14.000
original work, the iterative language model itself. And now that we've got faster computers and so on,

28:14.000 --> 28:19.120
it might I think be very interesting to go back and think about this much more. So in the iterative

28:19.120 --> 28:24.880
language model, basically you have a teacher and the teacher teaches a pupil and then the pupil

28:24.880 --> 28:32.400
becomes the teacher and teaches another pupil and so on. So it's a chain of learnings, teachings

28:32.400 --> 28:37.120
and learnings. And the idea is that the language progresses or changes through this teaching and

28:37.120 --> 28:43.520
learning. The hope is that we might learn something about how the structured language arises by seeing

28:43.520 --> 28:48.880
if it arises through this simulation of the teaching and learning process. And the crucial point,

28:48.880 --> 28:55.680
as we'll see, is that there is a bottleneck. So the agent has a language, the teacher, they teach

28:55.680 --> 29:04.000
only a number of exemplars to the learner, to the pupil. And then the pupil in turn, the pupil

29:04.000 --> 29:09.760
becomes the teacher, the pupil is teaching the next learner and they have to extrapolate from the,

29:09.760 --> 29:14.720
well, they've extrapolated from the few examples, exemplars they've been taught, a whole language,

29:14.720 --> 29:20.560
and then they choose other exemplars from that language to teach the next pupil. And it's this

29:20.560 --> 29:27.440
process of bottleneck and extrapolation from the bottleneck that Simon Kirby hoped and in fact found

29:27.440 --> 29:34.160
did produce some of the properties that we believe languages should have. And so again,

29:34.160 --> 29:39.200
this just summarizes it. The teacher provides signals and meanings. So they say, you know,

29:39.200 --> 29:45.200
cat and then shows a cat, just like in cartoons. The cartoon idea about how we teach children,

29:45.200 --> 29:48.800
although people who work on children point out that that's not actually what happens,

29:48.800 --> 29:55.760
that we very rarely teach children language in this supervised way. But here, we do have this

29:55.760 --> 30:01.120
naive picture. The teacher provides signals and meanings. The learner learns the mapping from signals

30:01.120 --> 30:06.160
to meanings. And then when they reach maturity, they use that to, they then use a version,

30:06.160 --> 30:09.920
which I'm going to talk about in a minute, to invert that map. So they get a map from

30:09.920 --> 30:15.680
meanings back to signals. And then they choose some random meanings, produce the signals for,

30:16.640 --> 30:23.760
as an example, to the new learner. And the process continues. And

30:25.200 --> 30:29.840
the idea is that the language that's produced should have some of these nice properties. So

30:29.840 --> 30:36.640
the properties they have that we're to look for are expressivity, stability and compositionality.

30:36.640 --> 30:43.680
Expressivity is basically, can all meanings be expressed? In other words, if you map signals,

30:44.640 --> 30:48.880
set of signals onto the space of meanings, how onto is that map? If a completely expressive

30:48.880 --> 30:54.240
language is one where the map from signals to meanings is onto, if the signals all map to the

30:54.240 --> 30:59.360
same meaning, that would be not at all expressive. And expressivity is just a sort of counting of,

30:59.360 --> 31:04.080
I mean, basically it's a counting of the map of the signal space into the, into the meaning space

31:04.080 --> 31:09.600
divided by the size of the meaning space. Stability, that's just how after the languages

31:10.160 --> 31:15.760
have time to mature, is it roughly stable from, from iteration from generation to generation.

31:15.760 --> 31:21.440
And then compositionality, of course, is the sort of more difficult one. That's what makes

31:21.440 --> 31:26.960
languages languages, what makes a language a language, the idea that a part of the signal

31:26.960 --> 31:31.920
should consistently code for some aspect of meaning. So, you know, in this case here,

31:31.920 --> 31:38.800
we have the word for orange. I think funny to make this as an example when I was making these

31:38.800 --> 31:43.760
slides, but of course it's the worst possible example. So, so the idea is we have a word for

31:43.760 --> 31:48.720
orange, the color. You can see my problem, I'm really screwed myself, but yeah, we have a word

31:48.720 --> 31:53.280
for orange, the color, and it's used here to describe orange, the fruit, and then we have blue

31:54.000 --> 32:00.720
used to describe the blueness of the orange on the right. And the idea of compositionality is that

32:00.720 --> 32:06.880
the word orange, it means the color orange when referring to the color of an orange, or it means

32:06.880 --> 32:11.120
orange when referring to the color of a high-vis jacket. And one of the things, you know, the

32:11.120 --> 32:17.120
people have learned in trying to make agent models of language evolution is that compositionality is

32:17.120 --> 32:22.560
actually quite hard to enforce. So, you know, if you have two reinforcement learning agents and

32:22.560 --> 32:27.200
they're playing what they call the Lewis signaling game, they're trying to learn a way of telling

32:27.200 --> 32:32.880
each other about things, what tends to happen is that, you know, if you don't, if you restrict

32:32.960 --> 32:37.120
their signal space, so they just don't have a separate word for every possible combination of

32:37.120 --> 32:43.440
attribute and object, et cetera, but rather they're forced to have some symbol for attribution, some

32:43.440 --> 32:48.000
symbol for what's being described, they have to have a word for the color and a word for the

32:48.000 --> 32:54.720
object. You can do that, but they don't consistently use the same color word. You know, they might use

32:54.720 --> 32:58.320
orange to mean orange when describing oranges, but they might use blue to mean orange when

32:58.880 --> 33:05.680
describing high-vis jackets. It's enough for the communication between agents, you know,

33:05.680 --> 33:12.880
reinforcement learning agents, that there is a word to distinguish potential colors of the

33:12.880 --> 33:20.080
orange fruit. But that word, the word for orange, doesn't have to be the same word. It doesn't have

33:20.080 --> 33:25.200
to match to the same color as when you're using it to describe something else. You know, we do this

33:25.200 --> 33:32.480
a little bit ourselves. I mean, you know, when we're talking about horses, we use the word chestnut

33:33.680 --> 33:39.200
for what we would call brown in other instances. But generally speaking, the main property of

33:39.200 --> 33:44.400
language is compositionality, and the idea is to seek that here. So in this version, in the simple

33:44.400 --> 33:48.560
version of the iterated language model, we just have eight bits of meaning and eight bits of signal.

33:49.200 --> 33:54.960
So the meaning space is just 256 potential meanings, and the signal space is 256 potential

33:55.440 --> 34:01.840
signals. And then the learner has a simple neural network. You can see that this all dates back to

34:01.840 --> 34:08.800
the year 2000. So it's a two-layer network. Signals come in. So the teacher says a signal

34:09.440 --> 34:16.560
and then provides a meaning. And then the learner, perhaps using a sigmoid

34:17.120 --> 34:22.720
non-linearity. So probability of ones and zeros for all the potential meanings compares it to the

34:22.720 --> 34:30.320
actual meaning backpropagates and thus learns to map from signals to meaning. So that's the plot.

34:30.320 --> 34:36.320
And of course, the thing about this is that this neural net has been trained on only these

34:36.320 --> 34:43.600
exemplars, the small part of the space of meanings that form the teaching event from the teacher to

34:43.600 --> 34:49.600
the learner. But the mechanism, of course, provides a map from any signal to a meaning.

34:50.400 --> 34:55.440
So that's the first part of the teaching. But then the next part, which is that the

34:56.720 --> 35:03.680
learner has to also get a map from meanings to signals. And so the way that's done is using a

35:03.680 --> 35:11.200
version without worrying about it too much. Here's a two-bit example. So here we have a signal

35:11.200 --> 35:19.440
mapping to a meaning, using the neural net. So what the learner is learning is the correct

35:19.440 --> 35:23.280
mapping. So maybe the correct mapping here, the mapping that the teacher is trying to teach,

35:23.280 --> 35:32.320
is that one zero goes to one one. But literally speaking, the learner can provide from this

35:32.320 --> 35:38.640
mapping, coming from their neural net, a probability for all four potential meanings.

35:38.720 --> 35:46.000
And this is a contrived example, so that the probabilities are 0.1, 0.1, 0.7, and 0.1, if you

35:46.000 --> 35:52.880
obviously multiply P1 by P2, or 1 minus P2, or whatever. And so in that way, the learner can

35:52.880 --> 36:02.880
produce a table of all possible maps from signal to meaning. So here are the signals,

36:02.880 --> 36:06.960
and these are the probabilities that give meanings. And in a version, all you do,

36:07.440 --> 36:14.480
you run the table the other way. So basically, if you're given one one one, so if you see the

36:14.480 --> 36:19.120
signal one zero, your neural net tells you these are the probabilities of the different meanings.

36:19.120 --> 36:24.640
And to get a map from the other way from a meaning to a signal, you look across this way and see

36:24.640 --> 36:32.640
that 0.7 is the largest number. And then you decide that in your aversion, in your inverting of the

36:32.640 --> 36:38.080
map for meanings to signals, you'll map one one to one zero, because that's associated with the

36:38.080 --> 36:43.760
highest probability. So that's the process of aversion. You read across each of these lines,

36:43.760 --> 36:49.200
you put a one there, and then this gives you the map. So zero zero will map to one one. So if the

36:49.200 --> 36:58.320
learner wants to randomly decides to teach the next learner the signal from zero zero,

36:58.320 --> 37:02.880
they'll say zero zero, sorry, they'll say one one, that's the signal, and they'll point out that

37:02.880 --> 37:09.280
that corresponds to the meaning zero zero. So that's the that's the iterated language model. You can

37:09.280 --> 37:13.840
see that this aspect of it is completely unrealistic and something that you might want to get rid of.

37:14.880 --> 37:21.520
But it's the thing that seems to work. And what the reason, of course, it's unrealistic is that it

37:21.520 --> 37:30.000
requires that the learner on reaching maturity goes through all potential, all potential signals

37:30.000 --> 37:35.600
and all potential meanings, works out the corresponding probabilities, and then does this aversion map.

37:35.600 --> 37:40.880
And that's obviously not true of language. The whole point of language is that you can't go through,

37:40.880 --> 37:45.280
you know, you don't have to go through all meanings and all signals. And even from a

37:45.280 --> 37:51.840
computational point of view, it's extremely resource heavy. And even with modern computers,

37:51.840 --> 37:56.240
it means that you couldn't. So the hope is that you could look at this iterated language model

37:56.240 --> 38:00.080
far beyond the sort of eight bit examples they're doing here, maybe even use it,

38:00.080 --> 38:05.120
you know, on language itself. So replace the set of meanings with actual sentences and

38:05.120 --> 38:08.880
force the agents to come up with their own internal languages and see what happens.

38:09.440 --> 38:18.160
But so anyway, with this aversion process, you do get a way of mapping. And so you can run the

38:18.160 --> 38:26.000
iterated language model. This is just us recapitulating what Kirby and co-workers saw 20 years ago.

38:26.000 --> 38:32.160
You can see that if you do this, you know, with a suitable size of bottleneck, so 256 meanings,

38:32.160 --> 38:37.760
you allow 50 of them to be taught, you run it across generations, the expressivity goes up,

38:37.840 --> 38:42.800
stability. So this is the instability, the opposite of stability, that goes down.

38:43.360 --> 38:50.880
And more remarkably still, the compositionality increases. So this I think is intriguing and

38:50.880 --> 38:55.120
worth sort of reminding us. Sorry, this is just some, you know, interview. There's two different

38:55.120 --> 39:01.760
measures here going on of compositionality. But it's basically measure of positionality

39:01.760 --> 39:06.880
based on entropy. But I mean, I do think it's remarkable. And I think it's worth us going back

39:06.880 --> 39:11.360
to the iterated language model and trying to see what it tells us about language evolution.

39:12.480 --> 39:17.440
To get rid of the inverter, it turns out, you think it's going to be easy. So for example,

39:17.440 --> 39:22.560
you think that you can just add another, you know, in the learning process, you can think that the

39:22.560 --> 39:28.240
learner could have, you know, a meaning and then also learn its inversion at the same time,

39:28.240 --> 39:32.880
stick in as an objective function, getting the right meaning, but also recovering the original

39:32.880 --> 39:39.360
signal. That seems like it would almost certainly work. And I guess this is one of the sort of

39:39.360 --> 39:44.960
few original results we have in this area. And it's a sort of a negative one, which is that

39:45.520 --> 39:51.120
it turns out that a version, although clunky, something that you hope might just be a convenient

39:51.120 --> 39:58.800
way of doing the inversion is necessary. It creates some sort of pressure which drives

39:58.880 --> 40:05.520
apart the mapping and makes the mapping from signals to meanings onto and produces expressivity.

40:05.520 --> 40:09.920
So if you just replace it with a recurrent neural network, well, what you might call a recurrent

40:09.920 --> 40:15.760
neural network, with this architecture here, you lose that expressivity. I think that it's,

40:16.720 --> 40:21.360
so what we're seeing basically is that the bottleneck, which forces the neural net to

40:21.360 --> 40:26.880
generalize or sorry, the agents to generalize is producing compositionality. But the aversion

40:26.880 --> 40:33.120
is also required for expressivity. The bottleneck also tends to cause this pushing together of the

40:33.120 --> 40:37.840
mapping, which loses the impressiveness of the language. And so I think there's ways around

40:37.840 --> 40:41.120
that. I think, you know, maybe if you think the whole thing is a sort of Bayesian reconstruction

40:41.120 --> 40:47.680
problem, you can come up with a new objective function, which has a sort of contrastive term,

40:47.680 --> 40:53.440
which forces it not only to get the right mapping from signals to meanings, but also punish it for

40:54.000 --> 40:59.520
other meanings being close in probability. When you started doing that, it hasn't worked yet.

41:00.080 --> 41:03.280
It's still not producing the expressive map. It goes up for a while and then something happens.

41:03.920 --> 41:10.560
I'm sure we can sort that out. But the plan here, the hope, the conclusion is that there's

41:11.840 --> 41:16.880
a lot going on in trying to understand how compositionality and expressivity kind of

41:16.880 --> 41:23.200
rise in these simple agent models. It would be nice to have a sort of working example first and

41:23.200 --> 41:28.480
then try and decide, you know, could we generalize it to much larger, more difficult cases? But I

41:28.480 --> 41:32.960
think, you know, the problem is that, this slide is just to remind me to sort of announce the problem,

41:32.960 --> 41:37.040
which is that, you know, with these models, you're starting to worry about how much you just

41:37.040 --> 41:40.960
follow your own footsteps. You start putting things into the models to produce some sort of

41:41.520 --> 41:46.480
behavior. And then you start to worry about exactly what we can compare to when we look,

41:46.480 --> 41:53.360
you know, how we compare the model to the actual behavior of languages, how easy it will be to

41:54.240 --> 42:00.720
decide, you know, whether the model is a good one or not, and then work out from whether the model

42:00.720 --> 42:06.320
is a good one or not, you know, what is it about it that it tells it? What does it tell us about

42:06.320 --> 42:12.160
the brain? I mean, one thing we sort of, one of the things we try, obviously, is look at how it affects

42:13.120 --> 42:18.880
language, language synchrony between different communities. So here we've, we've taken the

42:18.880 --> 42:25.760
iterated language model, and we've stopped it being a simple learner to, to, teacher-to-learner

42:25.760 --> 42:29.920
interaction, but rather have some sort of web of interactions where a learner has a privileged

42:29.920 --> 42:34.320
teacher, but also learns from, from their community. And then we take networks where there's

42:34.320 --> 42:39.520
greater connectivity within, within a cave. It's, you know, it's one of these cave people

42:40.160 --> 42:44.800
graphs. So there's greater connectivity inside a cave, then across the caves, and we look at

42:44.800 --> 42:49.440
how the languages evolve and stabilize. And we discovered that you can, you know, depending

42:49.440 --> 42:55.680
on your parameter choices, you can end up with, you know, five different languages in six caves,

42:55.680 --> 42:59.920
this cave, they don't even have their own language, or a case where there's, everybody speaks the

42:59.920 --> 43:05.280
same language, or where some languages are shared and some of them are different, or where there's

43:05.360 --> 43:11.920
two different languages. And so you can use this model to try and understand properties of the

43:11.920 --> 43:17.200
distribution or the sizes of language, languages. But the problem there, of course, is that there's

43:17.200 --> 43:21.680
millions of parameters, you have to work out how to, how to, you know, what the network should

43:21.680 --> 43:27.920
look like, how to structure the teaching events, how to, how to structure the size of the bottlenecks

43:27.920 --> 43:32.560
compared to all possible being single pairs, etc. And so the model, although intended as a very

43:32.560 --> 43:36.640
simple one, when you start trying to apply it in ways that can give you data that you could

43:36.640 --> 43:43.520
compare to the real world, the model becomes still simple, too simple to produce something,

43:43.520 --> 43:50.000
you know, directly comparable to language, but much too complicated to draw easy conclusions from.

43:50.000 --> 43:56.960
And so it struck me at this point that we should try and think of what the very simplest model

43:56.960 --> 44:01.760
of language evolution is. And that's what I wanted to finish by talking about briefly. So the idea,

44:01.760 --> 44:09.920
here, is that we want to look at language change and look at the, the, the most personmonious

44:09.920 --> 44:15.840
description of what goes on as languages change. And so, obviously, one property that languages

44:15.840 --> 44:20.320
have to have is alignment. If you're talking to someone, you want their language to be almost

44:20.320 --> 44:24.240
the same as your own, or else you won't have, you won't be able to understand them. And the closer

44:24.240 --> 44:28.800
their language is to yours, the less sort of cognitive low communication will play,

44:29.440 --> 44:35.120
will place on you. So I think the first properties of languages as they change is that they should,

44:35.120 --> 44:42.880
should align. The second property is the converse, this inclination towards change. You know,

44:42.880 --> 44:48.880
obviously, teenagers do this all the time. I have teenagers, they, they, they use words in

44:48.880 --> 44:54.720
different ways. They, they delight in language invention. I mean, weirdly, my, my mother is

44:54.800 --> 45:00.080
almost the very opposite of a teenager. It's the same. She's forever making up new words and

45:00.080 --> 45:04.240
new ways of saying things, often based on puns. And then the puns turn into words. And then she

45:04.240 --> 45:08.560
just uses them in everyday conversation, expects people to, to follow. And she just does it in

45:08.560 --> 45:14.080
a, out of a sheer delight in language invention. There's also a kind of a more strategic point

45:14.720 --> 45:19.760
to language invention, which is to find shorthands for saying things, auxiliary words are pushed in

45:19.760 --> 45:25.680
with the words that their exiliaries to pronunciations are changed. People say small phrases to mean

45:25.680 --> 45:29.760
more complicated, large phrase things, et cetera. So there, there, there, there are these two sort

45:29.760 --> 45:35.200
of competing forces that work in language changes. The third one as well, which is an

45:35.200 --> 45:39.760
inclination towards consistency. That's exactly the sort of thing that the bottom leg in the

45:39.760 --> 45:44.160
iterated language model deals with. And I'm not going to deal with that one here. That's the idea

45:44.160 --> 45:50.240
that, you know, if, if in one sentence you put, you know, if at some point you decide that the

45:50.240 --> 45:55.440
verb goes at the end of the sentence, it does that for, for, you know, that can sit that,

45:55.440 --> 46:00.000
that rule doesn't just apply to one, one's type of sentence, but rolls through the language. So

46:00.000 --> 46:05.680
once something starts changing, other parts of language change to suit it. So that's an inclination

46:05.680 --> 46:11.680
towards consistency. You know, and it's obviously kind of amazing. I mean, if you think of how

46:12.000 --> 46:19.680
how, how noun and verb modifications work with Arabic and Hebrew, I mean, it's just incredible

46:19.680 --> 46:23.760
the way that, you know, everything has three, three consonants, and then you've got the verbs and

46:23.760 --> 46:28.080
the endings and, you know, how did that happen? I mean, it's just some, some small changes then

46:28.080 --> 46:33.120
became rules. And so that is obviously an important part, but not one we'll talk about now. So

46:33.120 --> 46:39.200
obviously agreement alignment between speakers and spontaneous change. You probably guessed

46:39.200 --> 46:45.200
when we're going with this, that that's a nising model. So in the nising model, it's a model of

46:45.200 --> 46:51.760
magnetism, as you'll all know, at different lattice sites, you've got a spin, the spin goes

46:51.760 --> 46:57.120
upwards or downwards. And there's an energy associated with, with the alignment of the

46:57.120 --> 47:03.840
spins. It's a lower energy state. If the spins are aligned, then if they're not aligned. And so

47:04.640 --> 47:10.240
you would obviously expect an nising model to evolve towards total alignment. But there's also

47:10.240 --> 47:15.600
in the nising model thermal effect. So in an nising model, this is the metropolis

47:16.400 --> 47:20.640
formulation of the nising model, what you do to evolve the model is you choose a random, you

47:20.640 --> 47:24.960
choose a site, and then you consider what would happen if you, if you flip the spin. So we'll

47:24.960 --> 47:30.560
label the spins plus one and minus one. And if the, if the consequence of flipping the spin

47:30.560 --> 47:37.520
can be written down like that, I hope I have the signs right there. But basically, if the spins

47:37.520 --> 47:43.280
become more aligned on average with the neighbors, so the one site, these are the four, for example,

47:43.280 --> 47:48.160
neighbors of the middle site, if it becomes an average more aligned with them, then a DE will

47:48.160 --> 47:52.880
be negative, and you'll accept the change. If it becomes less aligned, you'll still accept the

47:52.880 --> 47:57.680
change. And this is the terrible part with some probability given by the exponential of minus

47:57.680 --> 48:03.840
DE divided by T. And so DE is positive in this case. If DE is negative, as I said, you always

48:03.840 --> 48:09.120
accept the change. T is the temperature. In the case of when you're modeling magnetism, it's

48:09.120 --> 48:13.600
literally the temperature. If T is very large, then this is always one, you always accept the

48:13.600 --> 48:20.000
change. And so you just get a random up and down. If T is very small, then this will be near to zero.

48:20.000 --> 48:24.240
You'll never accept the change. And you'll just get it flowing to total alignment. And so you get

48:24.240 --> 48:31.360
these different patterns. This is the very random. This is the very aligned. And this is the critical

48:31.360 --> 48:37.680
point in between. So this is a model of a phase change. And at the phase point, at the critical

48:37.680 --> 48:42.560
point, you have scaling behavior at the cluster size. And that's what people are interested in

48:42.560 --> 48:47.680
the IC model. So obviously, we can map these two things, the movement towards alignment,

48:47.680 --> 48:52.160
towards the idea that you're trying to lower the energy. And the spontaneous change is like the

48:52.160 --> 48:58.880
thermal fluctuations. But clearly, of course, if you had only one spin, then you'd have only two

48:58.880 --> 49:02.560
languages, the upper language and the down language. And that wouldn't be very interesting.

49:02.560 --> 49:08.240
So what we do instead is we've got a vector of spins, d dimensions, where d is some number,

49:08.240 --> 49:13.200
you have to be chosen. And we imagine that these are coding for different properties

49:13.840 --> 49:19.920
of the language. So one spin might be, how do you say father? And obviously in lots of languages

49:19.920 --> 49:27.440
like Latin, German, Irish, the word is almost the same as that would be plus one. Do you use

49:27.440 --> 49:32.560
derivative of pattern for the word for father? And minus one would be languages where you don't.

49:34.080 --> 49:40.160
I don't know any languages that don't use pattern like derivatives. Anyway, not a good example.

49:40.160 --> 49:45.200
Or it could be something to do with word order. So here you see the word order in English,

49:46.000 --> 49:52.480
subject followed by, followed by verb and adjective followed by noun, whereas in Irish,

49:52.480 --> 49:58.880
it's verb followed by subject, noun followed by adjective, and they would be, you know,

49:58.880 --> 50:02.480
correspond to two further spins. And then a further complication is that that choice

50:02.480 --> 50:08.320
tends to be the same. So if the subject comes before the verb, the adjective comes before the

50:09.280 --> 50:14.880
the noun. If the subject comes after the verb, it's the other way around.

50:16.720 --> 50:19.920
And so you can imagine there might be two spins, one for this part of the word order,

50:19.920 --> 50:22.560
one for that part of the word order, and then in some elaborations model,

50:22.560 --> 50:26.320
there'd be some relationship between them. But that's basically the model we have.

50:27.280 --> 50:34.000
We have, as it were, in this first idea, we've got D independent ising models, and a given set of

50:34.000 --> 50:38.480
plus ones and minus ones constitutes a language, we choose some temperature,

50:38.480 --> 50:43.120
we run it forward and we get some behavior. I do have a graph in a minute, I'll show you.

50:43.120 --> 50:49.040
But the main thing that you do see is that because it's lots of interlocking patches,

50:49.040 --> 50:54.080
one for each of the D dimensions, you tend to see language continuum. And language

50:54.080 --> 51:00.240
continuum are a property of languages. So, you know, these days, everything's a bit more complicated,

51:00.320 --> 51:06.640
national boundaries and official, you know, government documents and radio stations and so on.

51:06.640 --> 51:12.800
But in the olden days, you tended to have no hard language barriers, boundaries. So if you

51:12.800 --> 51:18.640
walked from, you know, Portugal all the way to Sicily, well, Portuguese would be very different

51:18.640 --> 51:23.440
from Sicilian, but as you do it, you'd never actually be somewhere where we're, well, depending

51:23.440 --> 51:27.040
on your route, and that's going to be the point, if you go this way, you're never going to be

51:27.040 --> 51:31.120
somewhere where people in nearby villages can't understand each other. The languages gradually

51:31.120 --> 51:39.200
change one to the other. And so that property of language distributions is well reflected by

51:40.000 --> 51:44.800
this ising model of language, and obviously the temperature determines how big these clusters

51:44.800 --> 51:48.240
are and so on. And that's something that you might try and fit against some knowledge of

51:48.240 --> 51:54.240
the distribution of languages. But the problem, as you could probably anticipate, occurs here,

51:54.240 --> 51:58.160
which is the Basque country. And if you, if you instead of walking from

51:58.160 --> 52:03.280
Portugal through Galician and Castilian and Arganese, you kept along the coast as well,

52:03.280 --> 52:07.440
you might, particularly if you're a pilgrim. Well, if you're a pilgrim, you're going the other way.

52:07.440 --> 52:12.400
But either way, if you strayed into the Basque country, you would encounter a linguistic barrier.

52:13.280 --> 52:18.080
Basque is quite, quite different from, it's not an Indo-European language. This is a sign,

52:18.720 --> 52:28.160
remarkably, in French Gascon, which is a Pocotin language. And Basque, the Basque is this here.

52:28.160 --> 52:32.480
And you can see that it's very different from the others. This is Basque here as well.

52:34.160 --> 52:40.000
And so there is, in real languages, a language barrier. There is the possibility of language

52:40.000 --> 52:46.080
barriers. And also, of course, you know that we don't have to be able to talk to everybody.

52:46.880 --> 52:51.760
You know, we, we can have neighbors who speak a different language. And we can talk to them

52:51.760 --> 52:56.400
without necessarily aligning our language to theirs. We can speak to them, for example,

52:56.400 --> 53:00.720
through a lingua franca. These days, using translation by using somebody who's bilingual

53:00.720 --> 53:05.440
or being bilingual ourselves. This is an example of Kiswahili, which is a language that, you know,

53:05.440 --> 53:10.000
100 million people, that's not a bit much, a large number of 10 million people can speak

53:10.000 --> 53:14.400
as a second language, but only a million as a first language. And because it exists as a

53:14.400 --> 53:18.880
lingua franca, allowing people who don't have a mutual language to live beside each other.

53:18.880 --> 53:26.240
So the next version of the language evolution model is this preference sizing model. So the idea

53:26.240 --> 53:35.120
here is to run the same sort of dynamics, alignment and thermal change, but only allow or only have

53:35.120 --> 53:40.720
each side interact with which of the ever of the four sides around it, in the simplest case,

53:40.720 --> 53:47.840
has the most similar language to its own. So, so the idea is that for each of the, for each pair

53:47.840 --> 53:52.880
of, of sites, each pair of speakers, I guess, you can work out the difference between their

53:52.880 --> 53:57.760
languages. And then you could, you need to, you only run the sizing model between the speaker

53:57.760 --> 54:03.440
you've randomly chosen to consider changing one of their plus ones and minus ones, and whichever

54:03.440 --> 54:07.600
neighbor is closest to it. And so that is the idea being that you only speak to the people

54:07.600 --> 54:11.840
who speak the same language as you. And so that's the new version, there's a paper about it there,

54:11.840 --> 54:19.440
in ALI. And it kind of works. So there's lots more to be done on this, but this is, this is the basic

54:19.440 --> 54:26.160
idea. This is the originalizing model. And here is a histogram of, so this is only five dimensions,

54:26.160 --> 54:30.320
you can run it in far more, you know, five different language attributes, you can run in

54:30.320 --> 54:36.960
far higher dimensions. But in the case of the first sizing model, you can see that this is the

54:36.960 --> 54:41.120
number of different, average number of differences between the speaker and their neighbor. And you

54:41.120 --> 54:47.200
can see that the speakers and their neighbors tend to have very similar languages. And very few

54:47.200 --> 54:53.200
people, very few pairs of people have languages that have very little in common. In other words,

54:53.200 --> 54:58.000
this version of the model does not allow for linguistic borders. Whereas in this preference

54:58.000 --> 55:04.240
model, where a comparison, the dynamics is only relative to whichever neighbor has the closest

55:04.240 --> 55:08.960
language to you, you do have lots of pairs where people speak the same language or very

55:08.960 --> 55:13.440
similar languages, but you do have pairs where people speak very different languages. So this is

55:13.440 --> 55:21.120
the, this is my proposal of the simplest possible model of language evolution. This work has only

55:21.120 --> 55:29.360
just started, but the idea is to consider, you know, consider different structures of preference

55:29.360 --> 55:35.680
and how many neighbors you interact with and so on, and then try and find different temperatures

55:35.680 --> 55:40.800
and then find the structure of the size of language groups there and compare it to real

55:40.800 --> 55:45.680
day clear. And so that's something that we'll do in the future. And that's it. Thank you very much.

55:45.840 --> 56:01.040
So I was assuming throughout this presentation that the bottleneck in the iterative model kind of

56:01.040 --> 56:06.320
corresponds to Chomsky's poverty of stimulus argument about language learning. Is that

56:07.600 --> 56:13.920
right? Corresponds to, I mean, it's, it's, it's meant to be representative of the fact that

56:14.800 --> 56:20.240
people, children only like experience a very limited amount of, but it adds something extra

56:20.240 --> 56:26.880
to what Chomsky says. So Chomsky uses the poverty of stimulus as evidence that the brain must have,

56:26.880 --> 56:31.760
you know, linguistic things, linguistic things. Whereas here, the poverty of, the poverty of

56:31.760 --> 56:38.000
stimulus is a mechanism for, it says that the structure of language is a response to the

56:38.000 --> 56:42.080
poverty of stimulus. So it changes that. I mean, that's what I think is really nice about this

56:42.080 --> 56:47.200
model. It turns that language upside down and says that in fact, it's not that the brain has some

56:47.200 --> 56:54.640
special language mechanism, it's that language has, has evolved so that we can generalize from a,

56:54.640 --> 57:00.720
from a poverty of stimulus. I was interested in, because I can imagine a more innate style person

57:01.840 --> 57:09.920
saying, you know, it's this convergence from the statistics to just a definite mapping in the

57:10.000 --> 57:16.400
aversion process that is leading to compositionality, but maybe there is some sort of innate

57:16.400 --> 57:21.440
mechanism, which is responsible for something that has the same effect as aversion.

57:23.040 --> 57:27.040
Yeah, no, but do you think that the, the work you're doing with this model,

57:28.080 --> 57:34.800
is there something that makes you lean more towards the, the empiricist take on this?

57:35.680 --> 57:44.080
So, I mean, I think one of, one of the things that we're learning at the moment, you know,

57:47.360 --> 57:51.760
you know, obviously, you know, the objection to transformers as a model of language is that

57:51.760 --> 57:59.200
they require this massive stimulus. But conversely, they, they, they are very sophisticated at learning

57:59.200 --> 58:05.440
grammar. You can see that if you back away from the, from the learning aspect, and you just look

58:05.440 --> 58:11.760
at the ability of these models to perform grammatical tasks, it's quite incredible. We do, we do, you

58:11.760 --> 58:17.600
know, we do do experiments now where we ask, you know, a transformer or an LSTM or something,

58:17.600 --> 58:24.560
can you learn gender agreement? And so I have a student Priyanka who's teaching new words to,

58:24.560 --> 58:29.280
to an LSTM. So she takes an LSTM, it's pre-trained. She freezes everything but the

58:29.280 --> 58:36.080
representations. She teaches it a new word. She gives it some grammatical context, gender context.

58:36.080 --> 58:42.080
So she doesn't French, obviously. So she says, you know, la, we use the word trilobie for some

58:42.080 --> 58:46.320
reason, because it's the least common word in the vocabulary list that we're using. So we take

58:46.320 --> 58:50.560
the word trilobie, we cut off its representations, we reintroduce it somewhere else in the

58:50.560 --> 58:56.560
representation space, and we train just the representation space on a few examples where

58:56.560 --> 59:01.440
you use the word la or la, describing trilobie, and then you ask it to do other gender agreement

59:01.440 --> 59:06.400
tasks and it does it completely well. So even though it's learning one aspect of gender,

59:06.400 --> 59:10.000
it's been taught the gender of the word through one aspect of gender, and it's been tested on

59:10.000 --> 59:15.360
another, it has abstracted the, the abstract category of gender. And so, you know, the initial

59:15.760 --> 59:24.960
bias that you had, that you needed, you needed special mechanisms, you know, Chomsky and

59:25.520 --> 59:31.280
mechanisms to allow the brain to perform the form of manipulations associated with grammar.

59:31.280 --> 59:36.560
That, I think, has been demonstrably made false by, by large language models. They,

59:36.560 --> 59:41.680
they have this very, I mean, the structure of transformers seems completely bizarrely crappy,

59:41.760 --> 59:48.640
right? And yet they do these amazing things. And so, it's quite possible for these, you know,

59:48.640 --> 59:53.120
simple network models that are doing statistical learning to learn this stuff.

59:54.400 --> 59:59.040
But that's not the same as saying that it can learn it against a poverty of stimulus.

01:00:02.640 --> 01:00:06.480
But what I think the iterated language model is maybe indicating, and again, we need to start

01:00:06.480 --> 01:00:11.680
using the iterated language model on much bigger examples. It's, it's indicating that you don't

01:00:11.680 --> 01:00:17.680
have to put much more in, you know, you, you, you, you, once you start thinking about a version or

01:00:17.680 --> 01:00:22.880
exactly what the objective function is, and the needs to, to generalize, it's possible that it's

01:00:22.880 --> 01:00:28.080
not just that the, it's possible that the language that evolved, that you could evolve the language

01:00:28.080 --> 01:00:34.160
where you can learn from a, from a poverty of stimulus. Does that make sense? I said that in

01:00:34.160 --> 01:00:37.440
the very roundabout way, but I mean, I think I'm essentially agreeing with your initial, initial

01:00:37.440 --> 01:00:47.200
point. Feel where you're coming from. Thank you. Thanks for the lovely talk. I think we could have

01:00:47.200 --> 01:00:53.840
done this at home some day. No, no, no. But yeah, I was wondering, are you, are you thinking with

01:00:53.840 --> 01:00:59.680
the Schelling model, are you thinking of maybe looking at the, or maybe already have the different

01:00:59.680 --> 01:01:06.880
patterns of, like actually taking different patterns of like verb order and, and so on, and

01:01:06.880 --> 01:01:12.080
kind of encoding them and plugging them into this model and seeing what you get out. Because I think,

01:01:12.800 --> 01:01:19.520
I mean, one, like one thing is, I think with, you know, subject verb, object ordering, there are

01:01:19.520 --> 01:01:25.840
certain patterns and some patterns are more frequent than others. For example, I don't know.

01:01:25.840 --> 01:01:30.800
And I guess that wouldn't. I mean, it's, it's very hard to know because we tend to think that the

01:01:30.800 --> 01:01:34.960
patterns represented by the Indo-European languages are, are much more common. I mean,

01:01:34.960 --> 01:01:40.800
just to answer that specific point, it is, you know, so you think, for, well, for example, the,

01:01:41.360 --> 01:01:45.440
the claim is that verb object is much more common than anything else. But that's only if you can't

01:01:45.440 --> 01:01:50.640
buy speakers, if you can't buy languages, that's maybe not so obviously true. Okay. And Irish,

01:01:50.640 --> 01:01:55.120
of course, that was one of my original interests is a language where verb and objects aren't beside

01:01:55.120 --> 01:02:02.240
each other. So, you know, I mean, I think the point with the ISI model is to make the simplest

01:02:02.240 --> 01:02:07.280
possible model. And so we, you know, I don't think you can retain that advantage to the model,

01:02:07.920 --> 01:02:13.680
while at the same time tying your coding to specific features, but rather the idea would be

01:02:13.680 --> 01:02:22.000
to introduce into these dynamics some abstract version of these features. So,

01:02:22.560 --> 01:02:29.840
so you could include some sense of consistency, which would be an interaction between the spins.

01:02:29.840 --> 01:02:35.200
So not only are, is a speaker interacting with the, with their neighbors, but there's also an

01:02:35.200 --> 01:02:40.240
interaction within the spins themselves. And that would be the idea that once you flip one thing,

01:02:40.240 --> 01:02:46.800
other things should flip as well. But, but I think, you know, there's sort of two, two types

01:02:46.800 --> 01:02:49.840
of models here. There's one that you might, the iterated language model, where you might actually

01:02:49.840 --> 01:02:59.520
try and use that to probe actual properties of actual languages. But with the difficulty that,

01:03:00.720 --> 01:03:07.360
you know, it's, it's, it's not a completely parsimonious model. You always have the problem

01:03:07.360 --> 01:03:11.120
when you're doing ancient modeling of deciding whether you're looking at your own model or

01:03:11.120 --> 01:03:14.480
you're looking at the world. And then there's the ISI model, which is supposed to be that there's

01:03:14.480 --> 01:03:18.720
a simplest possible language, a model of language evolution. And the idea there would be to look

01:03:18.880 --> 01:03:22.800
at very simple properties such as cluster size, cluster distribution, et cetera,

01:03:22.800 --> 01:03:27.680
and compare them to real languages, which hasn't been done yet. But that's, that's where we're going.

01:03:30.160 --> 01:03:35.760
So it could be wrong in assuming this, but sort of tying together the start and the middle of the

01:03:35.760 --> 01:03:43.200
talk. And in the iterated learning model, you have this mapping between meaning and sensations.

01:03:43.920 --> 01:03:55.360
And in the EEG experiments, I guess, is, is the, is the purpose there to try to uncover

01:03:56.560 --> 01:04:04.240
how that mapping is established in the brain and how, you know, maybe, you know, neurophysiology or

01:04:05.120 --> 01:04:10.480
segregation in the brain biases or influences that mapping itself. Like, is that what you're

01:04:10.480 --> 01:04:15.440
trying to get at with the EEG experiments? Yeah. I mean, as, as he pointed out, we're a long way

01:04:15.440 --> 01:04:22.720
from actually doing any of this, but the, that the sort of overall picture is you language has

01:04:22.720 --> 01:04:27.360
structure. We can discover that structure. How do we discover that structure? Probably, I think

01:04:27.360 --> 01:04:32.160
the best way to do it is by looking at EEG responses. You know, we do have commentaries on

01:04:32.160 --> 01:04:38.560
language invented by grammaticians. That's really them trying to impose what they've learned about

01:04:38.560 --> 01:04:43.760
Latin onto other languages. And it's probably sort of quite naive compared to how the brain

01:04:43.760 --> 01:04:49.360
considers parts of speech and the relationships between parts of speech. But the parts of speech

01:04:49.360 --> 01:04:55.120
and their relationships are probably important either as a reflection of, you know, and again,

01:04:55.120 --> 01:05:00.480
the discussion there is relevant of the mechanisms the brain uses for producing language and

01:05:00.480 --> 01:05:05.920
understanding language, or the language that the, that's the languages that have had to evolve so

01:05:05.920 --> 01:05:11.040
that we can learn them despite the poverty of stimulus that we experience as children.

01:05:12.560 --> 01:05:18.400
And so the iterated language model is trying to find out what, I mean, potentially is trying to

01:05:18.400 --> 01:05:22.160
find out what those properties of language might be. And we'd like to compare them to the real

01:05:22.160 --> 01:05:29.280
properties of language, which we discover through EEG. That's the big plan. Where my thoughts were

01:05:29.280 --> 01:05:33.760
going with that, I was just wondering if there are any, you know, takeaways from that EEG research

01:05:33.760 --> 01:05:39.520
or from, you know, the neuroscience realm that could perhaps be brought back over to the

01:05:40.880 --> 01:05:45.280
iterated learning model, but specifically, so in that bottleneck layer and your

01:05:45.280 --> 01:05:53.520
representational bottleneck in the meaning. Can you take any principles from neuroscience to

01:05:53.520 --> 01:05:58.400
apply, you know, to constrain that, you know, the structure of the bottleneck?

01:05:58.400 --> 01:06:08.000
But I mean, the story of my life is that when I started working in neuroscience, I thought, you

01:06:08.000 --> 01:06:14.400
know, we really want to map from actual neural networks to what they're doing, you know, we want

01:06:14.400 --> 01:06:20.160
to go from, you know, this is a neuron and this is what it's connected to, this is how it works.

01:06:20.240 --> 01:06:25.120
And so, you know, I ended up working on tadpoles, because I thought tadpoles are really simple

01:06:25.120 --> 01:06:31.360
creatures, maybe we can understand tadpoles. And tadpoles, neonatal tadpoles make a decision. So

01:06:31.360 --> 01:06:35.760
basically, older tadpoles are fearsome hunting animals, but the very, very young ones, when they've

01:06:35.760 --> 01:06:41.520
just emerged from the egg, and they're still carrying, they carry with them kind of an egg pouch.

01:06:41.520 --> 01:06:45.040
So the material from the egg that they grew in, so they don't have to eat for a couple of days.

01:06:45.600 --> 01:06:49.520
And these animals are very, very simple. So you touch them and they swim away.

01:06:49.600 --> 01:06:54.400
You grab them, they struggle. So there's exactly one decision they have to make,

01:06:54.400 --> 01:06:58.320
which is whether they've been grabbed or touched. And I thought this is the simplest

01:06:58.880 --> 01:07:03.120
decision that any creature makes. And there's like eight different neurons involved in this.

01:07:03.120 --> 01:07:07.440
Maybe we could go from the network to understanding the decision. And I had a PhD student who

01:07:07.440 --> 01:07:13.200
worked on this model for, you know, four years, reduced it all to two dimensions so we could

01:07:13.200 --> 01:07:17.680
draw a phase diagrams. And it was like just the most unbelievable mess. And in the end,

01:07:17.680 --> 01:07:22.640
you know, we just knew nothing about tadpoles, yet alone, you know. So I think, you know, I just

01:07:22.640 --> 01:07:27.600
don't think that's, I think we're so far away from, you know, something as complicated as language

01:07:27.600 --> 01:07:34.800
and mapping anything but the broadest principles of neural dynamics to the cognitive dynamics.

01:07:34.800 --> 01:07:42.160
I think the gulf between, you know, the neural substrate and the cognitive function is so great

01:07:42.160 --> 01:07:46.800
that I would be trying to stay away from that. The idea is rather to look at the structure of

01:07:46.800 --> 01:07:51.520
language and ask, look for the structure of language in EEG. So the mechanism there is only

01:07:51.520 --> 01:07:58.080
to try and find out what the brain regards as grammar. And then to compare that to the

01:07:58.080 --> 01:08:02.320
iterated language model and how it might, or some other model and how it might treat grammar,

01:08:02.320 --> 01:08:06.400
basically. Which is not to say that people are, you know, I mean, maybe the cerebellum, you know,

01:08:06.400 --> 01:08:10.400
maybe the hippocampus. But if you can't understand tadpoles, what could you do?

01:08:11.920 --> 01:08:14.880
I mean, basically we disproved the existence of tadpoles, I think.

01:08:17.360 --> 01:08:27.520
I'm sorry, Seth. Do you worry that expanding kind of this type of EEG work to a much broader set of

01:08:28.400 --> 01:08:31.120
structures would result in the same sort of mess?

01:08:32.960 --> 01:08:42.480
Yes. I mean, I think it's a good strategy. I agree with you that it seems promising and much

01:08:43.040 --> 01:08:48.720
simpler than that or some of the stuff that's been done mapping kind of semantic content into the

01:08:48.720 --> 01:08:55.600
brain with MEG and fMRI. But it turns out like the tadpoles, it's a mess. Yeah, it seems more

01:08:55.600 --> 01:09:01.520
promising. But I mean, who knows? I mean, yeah, I mean, we, what we've done compared to what we

01:09:01.520 --> 01:09:06.560
want to do is tiny. So it seems to me to be the most straightforward strategy. But, you know,

01:09:06.560 --> 01:09:11.760
at the moment, I can't even get my little prince experiment funded. And not only an eye, but these

01:09:11.760 --> 01:09:16.560
are greater people who are trying to get money for the same thing and get it done. So, but, you know,

01:09:19.840 --> 01:09:27.600
yeah, I said they're building in Bristol an instrumented museum, an instrumented cinema,

01:09:27.600 --> 01:09:32.160
so it'll be possible to do simultaneous EEG experiments on 100 people at once with consumer

01:09:32.160 --> 01:09:36.640
level EEG. So, and I think they're building this thing without any clue what they're going to use

01:09:36.640 --> 01:09:41.120
it for. So I think, I think there's a potential to persuade, you know, to get hundreds of recordings

01:09:41.120 --> 01:09:44.400
of people listening to the little prince and lots of different languages. And you can help

01:09:44.400 --> 01:09:49.600
it feel that you can discover something that way. Because languages are just so different, you know,

01:09:49.600 --> 01:09:57.360
I mean, you know, if we could get Malay speakers, they don't, they don't, it's an isolating language,

01:09:57.360 --> 01:10:02.080
they don't change the words for the plural, you know, if we can get speakers of, you know,

01:10:02.080 --> 01:10:06.240
Irish, they put the verb at a different place. I mean, it's just, there's such a variety,

01:10:06.240 --> 01:10:10.720
it'll be really interesting to see what we can see. But I agree, you can probably turn

01:10:10.720 --> 01:10:14.000
into a mess. And I think the way that you can turn into a mess is to try and

01:10:16.000 --> 01:10:21.360
find things that are too detailed. We have to try and find the very broad principles,

01:10:21.360 --> 01:10:27.280
you know, because even that's unknown. Is this cinema? Like... Yeah, yeah, they're building this,

01:10:27.280 --> 01:10:33.360
they've built it. They got funding for something called the Future Institute. And it's good to

01:10:33.360 --> 01:10:38.800
have this instrumented cinema where people wear EEG and they'll watch films, basically.

01:10:38.800 --> 01:10:42.400
So, like, when all the new films come out, you can have like the EEG response.

01:10:42.400 --> 01:10:46.160
Exactly. Yeah, exactly. I mean, I think that's how they solve it. Yeah. I mean, it's nothing to do

01:10:46.160 --> 01:10:50.960
with me. I mean, it's people in the psychology department. And the idea is that I think they'll

01:10:50.960 --> 01:10:55.040
have, you know, all sorts of instrumentation, right? They'll have, you know, we have to work out how

01:10:55.040 --> 01:10:59.200
sweaty people are and the heart rates and, you know, how much they're breathing, you know,

01:11:01.520 --> 01:11:06.000
and their EEG. So, I mean, it sounds like one of those things that sounds really cool. So,

01:11:06.000 --> 01:11:09.040
they were able to get money for it. But I think when it comes down to it, they're going to

01:11:09.040 --> 01:11:12.240
struggle to find experiments. So, hopefully, they'll do experiments for me.

01:11:13.920 --> 01:11:16.480
Nightmare giving a talk in that room. You can track in real time.

01:11:19.920 --> 01:11:22.160
Yeah, there's lots of cool things you can do like that. Yeah.

01:11:26.960 --> 01:11:27.600
Cool.

01:11:27.600 --> 01:11:29.200
Thanks for coming in.

