This public lecture series.
Many of the most cherished books in science, Einstein's relativity, Schrodinger's What
Is Like, Richard Feynman's QED, were all based on public lectures.
In this spirit, we want to welcome you here tonight, this public lecture.
In the special series beginning tonight, the ULAM lectures, we bring a notable scientist
to illuminate a cutting-edge topic in honor of the late theoretical mathematician Stanislaw
Ulam.
All of our public lectures are underwritten by the McKinnon Family Foundation, who allow
us to continue to provide the lectures at no cost, and we want to take a moment to thank
them first.
We are additionally supported by the Santa Fe Reporter and this Lenzick Performing Arts
Center.
Stanislaw Ulam was long associated with Los Alamos National Laboratory, and is highly
regarded by the Santa Fe Institute scientific community.
Former SFI vice president Mike Simmons said, the enormous range of Ulam's scientific thought
encompassed not only mathematics, but also physics, computation, biology, and much else.
He would have been very much at home in the present day Santa Fe Institute.
In this tradition, I am proud to introduce Ricard Soleil, our speaker tonight.
Simply put, Ricard is one of the most abundant and interesting theorists alive.
Ricard leads Icreia, the complex systems lab at the Universitat Pompeo Fabra in Barcelona.
He is also an external faculty member here at the Santa Fe Institute.
Ricard originally studied both physics and biology and undergraduate before achieving
a Ph.D. in physics.
His work touches on everything from how life originated to present day ecology to the very
nature of thought.
In the late 90s, Ricard connected ecology and mathematics by demonstrating the fractal
structure of forest canopies, and that these structures emerge from the statistical dynamics
of self-organization.
This is a fundamental idea in ecology, and the full extent of the impact of these ideas
are still being woven into our study and predictions of forests today.
They are ideas that inform and inspire my own work constantly.
Ricard has worked on other fundamental mathematical questions related to complex networks.
More broadly, he is interested in how life works, spanning from how cells first originated
in our past, to how brains developed to know and observe those same cells today, to how
technological societies network brains to design new cells and engage in global bioengineering.
And it is necessary to point out that Ricard's aggregate breadth of study is never at the
expense of depth.
This combination of expansive topics pursued with deep rigor is one of the rarest talents
in science.
In my own interactions with Ricard, we often discuss literature, and I am the fortunate
recipient of many quotes from novels, biographies, and historical scientific works.
The wonderful drawings that you are looking at tonight are made by the man himself.
This shows that his imagination is constantly in motion, and it is a pleasure to discuss
any topic with him.
He is a true polymath and an ideal speaker for this lecture series.
With that, please help me welcome Ricard Soleil.
Hello.
You hear me?
Thanks for coming tonight.
It's a real honor to be here delivering the Olam lectures this year.
Thanks, Chris, for this great introduction.
My talks have to do with a very exciting domain of research, which is mapping the space of
cognitions.
Not only the cognitions that we are familiar with, what I call the solid brains, but trying
to understand what is there, what is what I call the cognitive biosphere, what is there,
how much is complex, and whether or not we can understand the evolutionary dynamics that
brings us, and if we can maybe go beyond evolution and try to engineer that complexity.
So, before I go to that, since this is an Olam lecture, I want to say a little thing
about that, because when I was in high school, I stumbled into this book, The Monte Carlo
Method.
It was a tiny book edited by the former Soviet Union in a series of little books with all
kinds of things, where I discovered that Stan Olam, along with John von Neumann, invented
this method that physicists use all the time to actually model complexity that has to do
with some kind of randomness.
And that brought me into play myself.
It was the time of, there were no computers, so I'm old enough to say that, and so I had
a calculator, I have a coin, and I did a model of a gas.
You can see this is written with a typewriter, and I elaborated with that using that book.
And one of the things that I learned is that there's a lot of power in being able to approach
reality using, let's say, synthetic approximations.
And the other thing I learned is that it's something about popularity.
This series is called Popular Lessons in Mathematics.
Did that make me popular at all?
No?
And I understood that popularity is not exactly that kind of stuff.
But the other thing that I did connect is, I was mentioning Ulam and von Neumann, which
you can see there on the left.
In the middle we have Richard Feynman, another big name.
It was important in my life.
And von Neumann, and I will mention him today and tomorrow, brought me also into something
else.
This book by Michael Arby, Brains, Machines, and Mathematics, and again, I was still in
high school.
I found out that there was people thinking in the brains using mathematics that you could
approach actually brain complexity using mathematics.
I found out extremely fascinating.
And over time, I got involved in trying to figure out how to solve some of the interesting
questions.
There are plenty of good things that we would like to understand from the question of why
brains?
Why brains is part of a more broad complex, a more general question on complexity?
Because some people said that why the biosphere is not just made of microorganisms.
They are cheap.
They reproduce.
They propagate and proliferate.
Thinking that it adds complexity and brain is a lot of complexity with a cost seems to
be superfluous.
Why actually is any complexity?
And brains are especially important.
What kind of brains?
That's one of the big questions we'll try to bring.
Are there other minds?
It's a very hot topic these days.
What is a mind and how do we define and what we can find out?
All the way up into the artificial.
So whether or not beyond evolution, beyond what we see, beyond what we can infer about
how nature happened to construct complexity, whether we can actually create new things.
And that connects with the big question of the major evolutionary transitions, namely
how the big innovation happens in the real world.
Many years ago, Eosia Smadi and Don Minersmith made this list of transitions that had to
do with the origins of cells, the origins of information, the code, et cetera, et cetera,
all the way up to language.
Of course, the list is more complex.
You could ask yourself, what is the origin of consciousness?
Why do we have consciousness?
I will address that.
I don't have an answer, which might be wrong, but you'll see.
And in the middle of all this discussion about what is the nature of innovation and how innovations
happen, is precisely this special thing of biology, the special status of information
in biology.
And Eva Javlonka and Marion Lam made this beautiful work where they bring precisely this idea.
Cognitive agents bring something extraordinary.
In evolution, you have genetic information dominating the story of life for a very long
time.
Information that is based on something that is not genetic has enormous advantages.
Information that can be shared, can be propagated, and for us humans can be propagated beyond
ourselves.
So that's the main thing I want to address.
And the first part of the story is to actually ask ourselves, how likely is a brain to happen?
And that connects with something that is fundamental in evolutionary biology, but goes beyond that
and percolates into many other areas of knowledge, which is the role of randomness and contingency
and history versus the possibility that there are very strong laws that constrain a lot
what is possible.
And I put two views here.
Here on the left, Stephen Jay Gould was a strong advocate of the idea that evolution
is so historical that any kind of little change that you put in place will modify the outcome.
And he made, he used this mental experiment based on this movie that, sure, you have seen.
I mean, I don't know here, but in Barcelona, you see every single Christmas, we have wonderful
life at some point, right, on TV.
And I remember for you the story.
It's this guy, a very, very nice guy who had a lot of trouble for a very unfair reason
that at some point he decides that his life is worthless and says to himself, the world
will be better if I haven't been born.
And then comes this angel, which is a kind of quite annoying character, which is proposing
the experiment of, okay, let's do it, let's do the experiment.
You haven't been born, right?
What happens?
And he shows this, all this chain of events.
He didn't save his brother, who fell in a frozen lake and died.
And because of that, his brother in the war, in the second war, couldn't save a whole company.
And so on and so forth.
And eventually, the city where they live is very crappy.
So the message is, any single event can change everything.
And Steve Gould used that in the context of evolution, saying if we were able to replay
again the tape of evolution, like starting 600 million years ago, the biosphere that
we'll see now will be totally different, right?
It will be an alien biosphere.
I don't think that's the case, right?
But this is the idea.
Other people like Jack Monod also brought the idea that randomness plays a very, very
important role in evolution.
And more recently, I'm very much a book person and a movie person, and my students know that
very well, and I'll make recommendations.
Recently, Sean Carroll, the biologist, wrote this beautiful book where he kind of puts
these random events that seem to be relevant.
But this randomness really is so important.
Let me show you the other part of the story.
In fact, when we look at the natural world, we find out that very often the same solutions
appear again and again and again independently in very different groups of organisms.
I put the eyes here.
The complex eye that we have, this camera eye, has been invented in evolution probably
about 25 times in a totally independent way.
We have this eye, and Octopy, for example, they have an eye that is essentially the same.
In fact, it's better than ours, right?
And this is what we call convergence, that the reason that these solutions appear again
and again and again is that there are very, very strong constraints, even maybe mathematical
laws that limit the possible, right?
This is a book, Life Solution, sounds like a self-help book, but this is a book of evolution.
It gives a lot of very interesting examples that go from cells and codes, genetic codes,
to minds, right?
And here is the Catalan scientist, Per Alberg, who unfortunately I met him years ago and
died very, very soon, and he made the argument that even when you look at the structure of
monstrosities, when you take the terephthalgists in, for example, in nature, you see that they
are very well organized.
You can make a taxonomy that is very well organized because not everything is possible.
So in the context of brains, we wanted to do something about that because, and as one
of the ambitions of the Santa Fe Institute, right, that think in really broad terms and
ask ourselves difficult questions.
So at some point, we talk about the idea of why not to try to make a kind of a space
of brains, of cognitions.
And in particular, it was clear that we have these solid brains, right?
Brains that I'm going to go into that in a moment, brains that are made by neurons located
in specific positions, right, and connected, and everything happens in the connections.
But uncolonies are a kind of brain of brains that are moving around, they're liquid.
Your immune system is a class of network that in many ways is like a neural network, right?
But the cells are moving all the time.
And so on and so forth.
So what happens with all these cognitions?
How likely are they?
How powerful they can be, all right?
So we decided to organize a little workshop with my colleagues, Melanie Moses and Stephanie
Forrest, about liquid brains, solid brains.
This is kind of a very ambitious idea because we brought together this group of very, very
interesting people.
But of course, we didn't know what was the outcome of this because we didn't have even
a definition of liquid brains, right?
So it was like our St. Patron Colma McCarthy said once, we met together to have more fun
that should be legal.
But the idea was actually to come out from that, from a first roadmap of cognitions.
I put it here, this was a special issue that came from this, a list of examples, right,
that include the microbiome, include plants, we'll talk about plants also because they're
kind of a solid organism.
And in around everything, we look for regularities.
They are common laws that we can use, common languages that we can use, and networks appear
to be the key here.
In a standard brain, right, you have the, as I was saying, fixed positions for neurons.
In a non-colony, your individual scarring brains are moving around, right?
So they are no constant connections, the connections are broken and formed all the time.
And the same happens for the immune system.
So first question, why brains, right?
What is the evolutionary force that actually pushes things towards complexity towards brains?
This is one very nice hypothesis that we'll use in several times, which is the moving hypothesis.
It essentially says that if you live in an environment, when you need to search, an uncertain
environment, you look to search for resources, you don't know what resources are, you need
to move, you need to detect, you need to sense, brains are great for that, right?
They centralize information and centralize the way you move, okay?
So that's important for a number of reasons.
And the other way of looking at that is that brains, to a very large extent, are prediction
systems.
Some people say prediction machines, but they want to avoid the machine metaphor in the
sense that prediction is absolutely fundamental.
We predict all the time, right?
Okay, so first of all, and it will be totally unfair with our brains, right?
Because we don't have time.
But I brought a brain, okay?
Yeah, my family was so happy when I said that I had a brain, finally.
So this is kind of a very good model, right?
It kind of weights kind of a real brain.
The human brain is a spectacular combination of accidents.
So there are things that have been occurring over time.
Many things we don't understand, right?
But also of optimization.
There's optimized circuits.
As you probably know, it consumes a lot of the energy that we bring into our bodies,
about 25%, which means that it has to be important, right?
Not everyone uses that much, but it's important, right?
And it's made of, we know now, 86 billion neurons.
It was the Susana Eculano in Brazil, found out the way of counting.
And it works in a very dynamical way, right?
At any time, you record the activity of the brain,
you will see waves moving around.
We know now that these waves happen to occur between order and disorder,
in what we call a critical point.
And allow synchronize the system so
that you can actually put together information for different places, right?
And so have specialized areas working together, right?
It's a compromise between try to modularize the system and
try to put everything in place.
So there are several brains that correspond to this solid picture.
Very simple brains like Hydra, which is kind of a simple network.
Some more complex nervous systems, right?
But brains by themselves come later on in the evolutionary history.
And again, going into this idea of randomness versus strong laws.
Is the brain unique?
Could be very different ways of generating brains.
And in the recent years, people have been trying to think about that.
Well, we can make a theory of that and try to understand what makes the brain
special or maybe what makes the brain inevitable, all right?
So we could say, but if you want to build a revolutionary story of brains,
that's a difficult task, isn't it?
Because, for example, in terms of language or
the mind, you could say language, which is very central.
In the next lecture, we'll see how important is this and
how robots can help understand the origins of language.
But language, for example, somebody could say, it doesn't leave fossils.
The mind doesn't leave fossils.
Well, it's not completely true.
This is an example that I wanted to bring because it's simple.
But it brings an idea of what kind of things we can recognize.
Does anybody see that there's a strong regularity here?
These are hands of different people, right?
That painted is the cave of the hands in Argentina.
And what happens here is that if you look, it's all left hands, all of them, right?
Because the people who use whatever they use to paint, you're using the right hand, right?
And you know that nowadays, most people is right handed, okay?
And that symmetry was there already.
So we can see there's a trace of that particular thing.
But brains do spectacular things.
And particularly human brain with a visual cortex,
which is an amazing system that we have been using to do a lot of
very important things that we will discuss.
But one particular experiment we can bring and
that allows me to go into how we make theories of the brain is this, right?
In the left, you have a picture which has been kind of pixelated and
you only retain part of the texture, right?
Everybody sees what is there?
There's a dock.
The usual thing, it's a pattern here, right?
We don't know exactly why.
The pattern is some people already know.
Some people see the dock, right?
It's kind of like a Dalmatian.
Some people doesn't see anything, but when you say there's a dock, right?
The brain finds out, okay?
And then there's people who don't see it, right?
It's okay.
But the thing is that that kind of pattern recognition system,
which is extremely effective, we use constantly since we are toddlers almost,
is impossible to simulate with a standard program.
You cannot write a computer program to do this, right?
On the right part, what I'm putting is also the fact that once you recognize
that particular pattern here, it's going to be stuck in your brain forever.
So one day you go, in ten years ahead, you go to the house of a friend and
on top of the table is this picture covered in part, right?
It's very likely that those of you who recognize that say,
look, this is from that great lecture I went, right?
So how do we actually make a model of this, right?
It would appear that it has to be a very complex, very complicated model.
And everything starts and comes from the work of these two amazing characters,
Warren McCulloch and Walter Pitts, who actually came about with
the first formal model of a neuron.
And from that comes out all the neural networks that we use in
all the artificial neural applications, chat GPT and everything else.
We don't have time to talk about them, but if you search a little bit,
in particular Pete's on the right, he was a child prodigy.
He has a very, very interesting story.
They figure out how to do it.
And what they did was to transform a neuron,
which is a really complex system itself, into a mathematical representation.
To make the long story short, the idea is you have a neuron,
you have inputs from other neurons that set signals.
The signals can be positive, trying to make you to activate, or
can be negative, try to make you put down, getting active.
And you wait everything.
And once you wait, you have a threshold.
And if you go beyond the threshold, you activate, right?
And then the neuron sends another signal somewhere else, okay?
You can bring that mathematically in a very elegant way, okay?
And you can use now that for modeling a lot of things.
For example, John Hopfield, this amazing model,
which I will put in a nutshell as follows.
Imagine you have a collection of neurons.
For me, my neurons will be elements that they just are on and off, right?
They are active or inactive.
And I can put them to the dimensional layer,
like in a retina, like it's something that detects images, okay?
Now, it's possible to show, I connect everyone with everyone.
I use the maculok pits, threshold units, right?
And then it's possible to train the network, show images,
letters, whatever it is, okay?
So the network learns how, well, the rule is very simple.
If two neurons receive the same information, for example,
two black pixels, they reinforce their connection.
If they receive contradictory signals, black pixel, white pixel,
the connection between them is reduced.
That's all, no long computer program, nothing.
And you can show, using this, that this network is capable of doing
precisely what I was showing you before, right?
It's possible to show that in a space that is highly dimensional,
that depends on the number of connections, right?
You create kind of valleys, right?
This abstract space, valleys where the bottom of the valleys are the memories.
The things that you have made the network to learn.
For example, imagine that I have trained the network to learn only two images, right?
This one here, that one here.
You will create two valleys, and
in the bottom of the valleys you have the memories.
In what sense?
In the sense that, if now I show an image that is incomplete,
is the form, is distorted, right?
The network, just using the dynamics of my Culloch and
Pitts goes down the valley, right?
And reconstruct all the information, right?
I think this is totally amazing, right?
And shows the power of artificial neural networks.
But of course, this corresponds to a given model for
a given class of brains.
What about the potential universe possibilities, right?
I could imagine things.
These are, my drawing is about four things that we don't observe,
don't exist, right?
We'll offer them.
And in my lecture today,
I want to explore this idea of what kind of brains are there.
Whether there are very strong constraints, whether or
not brains are expected or there's a lot of possibilities.
And I'm going to use, there's a huge amount of examples here.
I'm going to use ants as one example.
Fissarum, which is kind of a very alien creature.
Discuss about plants, because there's been a lot of discussion in
the recent years about plant intelligence.
And show you that we can start to think in a space of possible
conditions, and how we do it, right?
So a very important point, liquid versus solid, right?
On the right hand side, you have a very small part of a neural
network of neurons connected.
Again, their locations remain the same over time.
And on the left, it's a very tiny part of a swarm of army ants, right?
I was very impressed when I was in Panama years ago,
seeing the army ants, which are blind.
They communicate in simple ways with their nest mates.
But forming these huge forms that, if you look from the distance,
look like a single organism moving around, right?
Swarming in the middle of the forest, quite a thing.
And so we want to see how we approach all these problems.
And in particular, one good question is, is a liquid brain
able to be as complex as a solid brain?
And the question is, is it relevant for a number of reasons?
One of the reasons is, let me see this, oops, there's a movie here.
Oh, yes, okay, sorry.
Let me see.
And the question is, in particular, because one good comparison we
can make is about us, right?
The, oh, man, what's happened?
Let me see.
Get into me.
And the question, of course, for a colony of ants is who is in charge?
I mean, ants are moving around, right?
It's not like a centralized system saying you have to do these and
that and that, right?
It's not such a thing as a queen giving orders to everyone else, right?
The queens in a way, as in European monarchies, are very useless,
except in this case, to put X, right?
So how do you control that?
And this sentence by Deborah Gordon, I think, is very to the point, right?
And for those of you who are fans of Richard Feynman,
Richard Feynman himself was interested in ants and
started to bring quite interesting questions about how ants work, right?
Well, two important things to say.
What makes ants and termites and social insects,
I can only address a few things, special.
And what do they do that is close to the brains that we were discussing,
the human brain, for example?
Well, on the one hand, they have managed to modify their environments.
They do what we call extended minds, right?
They create superstructures and the nests are the clear example.
And the nests can be extremely large compared with the single organisms.
In a termite nest, in some cases, you can have the very tiny,
homilimetric organisms, whereas the nest for termites in some parts of
Africa can be three, four meters high, right?
So ten orders of magnitude larger.
How do you build that?
Of course, termites don't know anything about that.
Again, they are blind.
They communicate in simple ways with chemistry.
So whatever creates the organization comes out from a collective phenomenon,
from self-organization, or what we call in complexity, emerging phenomena.
Phenomena that we can describe that even scale, network architecture,
or in our brains, consciousness, memory.
And that cannot be reduced to the properties of the individual parts.
You can spend your whole life studying single termites.
You'll never understand how they build the nests, right?
The key is that the collective behavior, the fact that the interaction between,
for example, termites and the material they use creates amplification phenomena
that lead to self-organization, in particular, to order patterns.
That picture there is a small part of the fungi factory that you have in
termite nest, in some cases, right?
And the explanation of the mathematics comes from what's called tuning structures.
But it emerges from the interactions, right?
In a liquid brain.
Another thing that is quite fascinating is,
ants can solve the problem of finding out the shortest distance.
How?
Imagine you have the ants like in the movie, right?
That are in the lab, you put a food source somewhere, and here is the nest.
If some ant detects that there's food here, they deliver a chemical signal,
which other ants find out reinforce, and eventually you create a signal
that goes beyond the individuals, right?
And individuals in the signal interact in nonlinear ways, and
you make this trail of ants that exploit the source very quickly.
What happens if you put two?
Well, the things can also be dependent on its scenario and its species.
But for example, if I have more food here than here,
they split at the beginning, but the source that is more abandoned is reinforced.
What happens if you make an experiment like the following?
Imagine you have the nest, you have the resource, the food here,
and you have a double bridge, right?
So there are two branches, and one is longer than the other.
Okay, individual ants are unable to know that, if this is longer or shorter.
But since they leave a chemical trail, right?
The longer part will lose, because of course,
the chemical signal is dissipated, is evaporated, will lose more by evaporation.
And eventually, everyone will go into the shorter chain, right?
So you need a collective phenomenon here to actually solve the problem of
the shortest path, okay?
And then you go into the question.
Is an an colony going to be as complex in terms of cognition as a brain?
I think the answer is no.
And the reason is, you can represent ants in different ways.
And I want to remember you that the ants have brains, right?
They are not neurons, they are brains.
But in brains, they can be half a million neurons, so it's not small.
But interestingly, when you make models of how the ants solve the shortest path
problem, how they build their nest, you can represent the ants in extremely simple
ways, right?
Sometimes even in on and off systems.
And so you can use that, you can represent the ants in this way.
And instead of using the McCulloch-Pitts model where neurons exchange things
in a fixed way, you can actually make what we call a liquid brain.
Here, for me, each ant can be, for example, an active or
an inactive neuron, they move around, right?
And over time, they interact exactly the same way that neural networks,
except that now they are changing in time, they are moving.
And one of the beautiful examples that we have explored comes from a war by
Deborah Gordon and colleagues, where actually they have these ants that
live in the desert, and you can see the ants doing special tasks, right?
They are exactly the same morphological identical, but they do different tasks.
They can forage, they can have nest maintenance, they patrol.
And you see that the same ants, over time, they might change task, right?
And also, if you are a bad person and you take, for example, all the foragers, right?
And see what happens.
What happens is the colony reorganizes.
So some ants that maybe were just making nest maintenance become foragers.
It reorganizes in such a way that it optimized the number of individuals that
do each task.
But then if you represent that with a mathematical model, etc., what you realize
is, remember the model I showed you with these ballies that were the memories, right?
Here you have also ballies.
But in this landscape, what is in the bottom is the number of ants that
are involved in each task.
Which is something that is much, much, much less rich, right?
You are not exploring a hyper-dimensional space of connections, because the connections
are destroyed all the time.
You generate something that has to do with the average number of things needed so that
the colony works.
Which for us, suggests that things like that depend on liquidity may be very limited.
In the science fiction literature, or in the movies, for example, Star Trek, I'm not
a tricky person, but it's an interesting example.
They propose this idea, the Borgs.
The Borgs is kind of a race of cyborgs, each one with a big brain, right?
With a queen that has a big brain and controls some things, right?
But the thing is, right, why do we don't see, for example, what I call brainy ants?
We don't see ants with a large brain, right?
It's a possibility in the space of what we can imagine.
And what we find out is, although the theory has to be developed, is that actually, if
you look closely, you find some things that are extremely interesting.
For example, it seems to be a trend for colonies that in a nutshell, the pattern is, you have
a very small colony, individuals can be complex.
I saw them in Panama also.
I saw these groups of ants, colonies with 100 individuals only, very large ants, everybody
warned us, don't touch them, right?
Because they are called 24 hours, that's the time we'll suffer the pain.
So I believe that, one of my colleagues didn't, and the experimental method.
And it was interesting because you approach the colony and the ants were outside with
big eyes, and clearly they saw us.
And if you look at the individuals, they were more or less making their decisions without
much worrying about anything else.
But if you take very large colonies where the colony itself can do extremely complex
things, interestingly, individuals get more and more and more dumb.
As if there was a trade of fear.
This has been called the complexity drain.
The complexity drain is something that we need to develop the theory of that.
Essentially, we'll say that the more complex the society, the less complex the individuals,
right?
Don't try to apply that to our societies, okay?
Anyways, my second example, my second example has to do with an extraordinary organism.
And I wanted to start with this.
This is a labyrinth that is in Barcelona in the orta quarter that is a replica of the
famous labyrinth of Gnosis, the minotaur, right?
Labyrinths have been something that mathematicians and all kinds of people have been fascinated
in.
How do you escape from a labyrinth?
Or is this the entrance and is this the exit?
How do you find the shortest path, for example, okay?
So Fissarum is able to do that.
Fissarum is not an animal, not a plant, is a slime mold, is a very simple creature.
And actually, some people describe it as a single cell, is a whole thing with many nuclei
inside, but essentially it is a single cell, except that it is extremely large, right?
You can see it in the forest.
And actually, when it was found many years ago in the time of the Sputnik, the people
who found out that blob, which is yellowish as it is like this, and it can be large as
my hand, found in the forest, they thought that it was kind of an alien thing, right?
That came with a spacecraft, of course.
Fissarum is amazing, it shifts all the time, has these network structures, sometimes looks
like a neural network, and searches in space looking for resources, right?
And if part of Fissarum finds something that is very rich, and he finds out that it's not
so rich, it deviates everything in this direction.
So you have all these tubes that pulsate over time, it's quite a thing.
And that gets thicker and thicker as you approach something that is richer.
And somebody used that in a very clever way, right?
So since Fissarum is so easy to cultivate, one thing I can do is take pieces of Fissarum,
put it within a labyrinth, an amaze, right, like here.
And then I'm going to use what Fissarum likes a lot, which is flakes, right?
One at the entrance, A, one at the exit, B. And over time, what you see in the movie
is that Fissarum is detecting two sources, right?
It's totally distributed, there's no centralized mind, there's no neurons at all, okay?
And what happens is that it's an amplification phenomenon.
As you go over time, you see that close to entrance and exit, right?
The tubes that Fissarum forms, that is what they need to actually push forward the detection
and exploitation, right?
They have these nice waves.
Eventually what happens is that you get in a single tube that goes all over the place
in the shortest path from the entrance to the exit, okay?
But if you want to model Fissarum, it's possible to do it.
You model it with a network, a network of what?
Of tubes connected like a fluid, all right?
And interestingly, the mathematics that is behind is a threshold network, right?
Even in that case, you need to use one mathematics that might be universal.
Fissarum has been used in a number of applications, mazes.
You can actually find out a network of roads.
You take a country, for example, you put flakes in the locations of different cities.
Fissarum is distributed all over the place.
And then the tubes that reinforce the connections between different pairs of sources, right?
Eventually draw this map, which you find out that is more optimal than the ones that engineers
built.
And it's been also used to actually map dark matter, right?
Some astrophysicists find out the way of actually use Fissarum to make a large-scale
model of the universe and infer the distribution of dark matter.
But I want to make a point.
Very often, and you can make logic gates and many things, very often it's said, look, Fissarum
can solve complex mathematical models.
And that is a distortion a little bit of what really happens.
We exploit the properties of Fissarum, this extraordinary capacity of searching around.
And this special capacity that, and that's very important, is based in a way of computing
things, a computation that has nothing to do with the standard computation we use.
The computation is the form, the shape.
The final shape is what is being computed.
But of course, we, the humans, we put what in physics, we say the boundary conditions
or in mathematics, right?
We put in place things and Fissarum just goes on with its dynamics, right?
So Fissarum doesn't solve problems in nature.
Solve problems that have to do with resources, but not mathematics, okay?
What about plants, right?
I hope there are not so many enthusiasts here of plant intelligence.
I'm a skeptic.
In the literature also, we have this, I don't know if everyone knows, the day of the triphids.
It's a classic novel science fiction.
We have these plants that are capable of moving, right?
And that, well, I don't want to spoil anything.
Just read it.
It's really cool.
So are plants intelligent?
Well, let me say first something.
Plants are extraordinary.
They have really transformed completely the planet.
When they invade land, they invented the sorts.
They created the forests.
They have this system of photosynthesis that creates quite an amazing super molecular system
with quantum properties that we're still trying to understand.
So they are amazing by themselves, right?
Do we need them to like Mozart?
Maybe not.
Maybe not.
Have in mind that plants, on the one hand, have this extraordinary capacity of changing
morphology, of adapting in a way that animals cannot do.
They give them a lot of advantage.
The thing is, when you look at plants and plants in the context, right?
Like in a forest.
Of course, there's a lot of complexity that has to do with things that we know from ecology.
Competition, competition, mutually is in place a very, very important role in many ways.
We start to uncover a lot of complexities there.
But is really this connected to cognition?
And I think it's important to go and look closely.
What do we have?
Plant cells, and there's a big constant with animal cells, are very rigid.
We have this wall that makes connections between them extremely constrained, right?
Connections, plasma of this matter, like that on the right in the upper picture is an electron
microscope picture of a channel that connects to plant cells.
But the architecture constrains a lot what happens there.
Of course, there are no neurons, it's been told that there are analogies, but no neurons.
Everything very much goes into two directions.
One is growth.
I have to grow and grow in a plastic way.
Another is defense, right?
Plants have developed a huge battery of chemical signals that connect them with the challenge
that we have from insect herbivores in particular, right?
There's a lot of investment in that.
And it shows, it shows very much.
On the other hand, one thing I wanted to mention, we will discuss that in the second lecture,
but John von Neumann, the mathematician that I showed you before, in his studies about
brains, unfortunately it wasn't at the end of his life, of brains versus computers, he
made this the following point.
At that time, the computers, these very big electronic computers, were very prone to fail
because the basic components were not much reliable, right?
And if a vacuum tube failed, the computer could fail.
And they knew that brains don't work like that.
Your neurons, every day you lose neurons.
And you can even have a big loss of neurons and the brains capable of have plasticity
to return the system to the previous state, not computers.
He ended up in a conclusion which was, maybe we need systems that are very redundant, right?
Very, very redundant.
That's part of the solution, really.
But if you look at plants and compare with animals, what is the difference?
Well, many differences, right?
On the one hand, they stack in the same place, right?
So you think in the moving hypothesis, if I have to move, I need brains.
If I don't, maybe I don't need brains.
On the other hand, for example, you think in organs.
If I ask you how many organs you have, you are not going to say, well, I don't know exactly.
You do know, right?
You do.
One heart, two kidneys, et cetera, et cetera.
And all of this is decided in embryogenesis.
In plants, we see a very different situation.
How many organs we have?
Many.
Every single leaf is an organ, right?
They are formed and degrade and happen all the time.
And also, for example, at the level of leaves, we have discovered that if you analyze the
network of transport within leaves, which is a beautiful structure, you can see that
it's optimized for doing two things.
One, deliver the nutrients everywhere, right, in the most efficient way.
To protect themselves from damage, an insect can make a hole.
You have seen, for sure, leaves that are damaged in different ways, but you want to warranty
that you get there.
The transport keeps going well.
If you have loops, the right amount of loops, you can do it.
And this is a picture of one of these damage experiments where using a kind of fluorescent
marker.
You can see how it propagates and goes into the whole leaf again using the loops.
And it's optimized.
You can do a theory of that.
So you have many organs that can be lost, are essentially redundant, so you don't really
need to have a central control system.
In the second lecture, I'll try to convince you that this is probably the case, right,
that plants, because of they don't need that, and they are extraordinarily well-adapted
in different ways, right, might not have anything like brains or intelligence.
So fissurum, plants, brains, ants, how do we put this together?
And the idea, still work in progress, right, is to create what we call a morphospace, a
space of possibilities.
In this particular example that we used some years ago, I used three axes.
The vertical axis is how important is development.
Design is very important.
Nature constructs things, right?
You have embryos that develop and get into complex architectures.
In the horizontal axis is the liquid to solid, right, the state of matter that we have.
And in the other axis is how complex is your cognition, how complex are your decision-making
and how diverse is the way you actually sense and respond to the environment.
We locate things here in relative positions, okay?
For example, organs are kind of simple cognitive systems, right, or we could put, they are
the outcome of development, they might be just responding to simple signals, or they
might involve feedbacks that are more complex.
This is the artificial part of the story.
Organisms and organs have a counterpart in bioengineering, which is organoids, right,
which opens the possibilities that we will discuss in the second lecture.
Of course, brains, and of course, you can see I put a single sphere here representing
all solid neural networks, right, this is an oversimplification.
The immune system, which is a system that can learn where cells can have memories, where
collectively you have phenomena that remind us a brain, right, but they are liquid, they
move around, right.
We are living in a very interesting time now where it seems that because our understanding
of these networks, we might actually fight cancer and other things in a very effective
way.
And of course, I put hands in the middle between liquid and solid, high development because
an uncolline actually, if you look at how it generates, it comes from the queen, the
first X, the first individuals, the structure that goes emerges in a totally predictable
way and ends up into something that is the structure plus the colony that is inside kind
of a liquid system, right.
The microbiome, the millions and millions of bacteria that we carry out that makes us
something that is not anymore a single species, the idea that we are one species, we have
to abandon because we really are much more than that.
The microbiome, we'll talk about that also in the second lecture, has been co-evolving
with us.
The more we know, the more clear it is that many diseases we couldn't understand but it
was how they work are connected with the microbiome and the great thing is that we can intervene,
change the microbiome and maybe fight those diseases, right.
And this microbiome interacts with the immune system and with the brain, right, which means
that we have a lot of things at play.
Fissarum, somewhere also in the middle between liquid and solid, okay.
And this is kind of the big picture and they want to bring to your attention something
that is quite visible, is this big sphere that occupies a lot of space.
This big sphere is what we say is a void in the morpho space, meaning that when you look
at the natural world, you don't see anything there.
Why is that?
Because it's forbidden.
Because evolution for some reason is unable to get there, that's a big question.
For many of us, it is an indication that is a lot, is plenty of space to explore and
that if you are able to engineer things, we might go right there, right.
And I'll show you examples soon.
Okay.
So now I just give you all these examples but I'm sure that some of you are thinking,
yeah, yeah, but there's one particular example that you are not talking about, right.
And that is quite bizarre, right.
Of course, yeah, octopus.
Octopus has been receiving a lot of attention over the last two decades.
Why?
Well, it's on the one hand is an extraordinary example of how evolution creates in a totally
different trajectory in the tree of life, a mind that is remarkable, right.
Octopi, they can learn, they have memory.
You can see that they repeat the same words, right.
But they also have clearly curiosity.
There's been described many times that the octopus can be really interested and engaged
into approaching humans, for example, and trying to, I don't know, figure out what we're doing.
In the lab, it's been discovered that they recognize particular people, or sometimes
that they can escape from the fish tank by night because there's a camera recording.
Go to another fish tank to visit someone, I guess.
And get back.
Why they get back?
There's plenty of things that we don't understand.
And not surprisingly, it has been used often in the context of science fiction.
This comes from a snapshot from the movie The Arrival, where this is the question of
the language we'll discuss tomorrow.
Language is the big thing, right.
And you could say this is totally bizarre, totally different, totally alien.
But, well, not that much.
The interesting thing I want to bring is, if you analyze the brain of an octopus, right,
you can have the microscope, you make slices, see what's the architecture.
If you ask a histologist, what do you see here, right?
You might not have seen any time an octopus' brain.
But he will say, okay, this is a brain, probably some vertebrate, because I see the neurons.
The neurons are these amazing structures that have the polarity, you have this special
structure.
When you look at the shape of a neuron, what do you see?
You see a cell that is trying to connect, right?
This is a big function.
You see multilayers.
So interestingly, in a different universe of possibilities, in invertebrates, a totally
different branch, you generate an animal that has the same kind of eyes we have, that has
a neural architecture that resembles things that we are very familiar with, okay?
Of course, they are peculiarities, they have the central brain and something that acts
like eight autonomous brains, one for each tentacle, right?
But what this brings is that, again, it looks like maybe the space of possibilities is not
that big.
Even in that case, where you have this amazing animal, right?
So why octopus are not more complex, right?
They are interesting.
They are clearly interesting.
But for example, why cephalopod in general have not gone into using tools, for example.
And it comes this interesting constraint that has to do with the life of these animals.
Unfortunately, octopi don't live much.
In some species, one year, in some two years, maybe three, but that's all.
So thinking in the bioengineering, the possibilities in the future, you cannot avoid to think.
What if we were able to make an octopus to live more, right?
An animal that clearly learns over time has a brain that has this potential, right?
And that brings me into, and I am trying to attract you to the second lecture, okay?
Of course, to answer the questions I'm making about how brains originated, why brains will
require to have a picture of evolution, what happened, really.
We don't have a time machine.
But we have an alternative, which is extremely interesting, and I will show you, provides
very new fundamental questions that I think in the future might solve the questions that
we have been making before.
And that will be all.
Thank you.
Do we have time for questions?
Maybe I can try, oh, there we go.
So we have time for some questions.
I would like to know how that plant or whatever it was, you're not to laugh at me, got in
and out of that maze.
How did something go into the maze and find its way out?
You mean for the organism I was mentioning?
Yeah, there was Fissarum, it was this single cell organism.
And in nature, you have, for example, imagine you put Fissarum in some place, you have different
sources of food, right?
Fissarum is all the time expanding, like I'm searching around space.
And then this information about the different resources comes to the collective, it's kind
of integrating information all the time and making decisions about which one is richer
and minimizing the trajectories.
You don't want to make a lot of channels and invest energy and resources to create tubes.
You want to, well, this is necessary.
So what happened in the maze is that you put these two resources in those particular places
that have sense for us.
We know this is the entrance, this is the exit.
Fissarum doesn't know anything.
But then the amplification that is made here creates these tubes that are very strong here,
right?
And the same principle applies.
In the end, you try to exploit which is really rich, right?
And connect these sources in the shortest path you can make.
And that solves the maze.
But again, have in mind that we humans put the maze there, right?
To prepare the problem, it's an important difference.
Thanks for a brilliant lecture.
Your drawings are like Leonardo da Vinci, really.
Thank you.
Fantastic.
This is a question that's very stupid, but I've been asking it since I was six years old,
which is today, of course, it seems completely obvious to all of us that we think with our
brains.
But I wonder whether early man knew that they think with their brains.
Because if you look at all the cave paintings we have, you have the hands, you have animals,
you have human figures.
But you don't have heads necessarily as being more important than any other body feature.
So I just wonder if there's any history in the scientific research of when we began to
realize that we think with our brain.
You mean as rational creatures that we knew that there was a brain?
Or when the brain become became relevant?
I think back to earliest human beings.
The earliest development of communication, language, hunting, coordination, whatever
it was, did they realize that this was what was working?
Okay.
Okay.
It's not a stupid question.
It always happens in all the talks when somebody brings it.
This is going to be a stupid question and it's not at all.
In fact, tomorrow I'm going to bring a little bit about what part of the singularity of
the human brain is there.
I will make a bit of spoilers here.
The human brain is interesting for a number of reasons and had a very important impact
in an evolutionary history.
Just to mention a few things.
One is language, of course.
Language is a pretty extraordinary piece.
These days of chat GPT, chat GPT for a number of reasons is not intelligent but brings some
interesting ideas about the importance of language in evolving reasoning.
One thing that I find extraordinary is very, very important and we also bring that tomorrow.
It's time.
Somebody said that we are mental time travelers.
You remember what we mentioned before.
We are prediction machines.
The brain is something that tries to predict what's going next.
This is very, very important because in the end what makes brains worth is that we are
able to reduce uncertainty.
We make us more prepared to actually be understanding what's next, what's going to happen.
We had this cortex that expanded so much.
This kind of understanding of time became something that was the narrative.
We became able to make narratives, not only one feature.
We can imagine many possible features.
It's very interesting to see how it happens in evolution.
Somebody said you all know that memory is faulty.
Memory sometimes fails.
Sometimes you have memories that are not real, memories that are being constructed.
Somebody can say, why is that?
Because natural selection doesn't care about that.
Natural selection wants you to predict the future.
The future is important.
If you remember well or not the past is not so important.
An important thing that connects maybe more with your question.
One of the things that made us successful, as ants are successful because they cooperate,
some days it doesn't seem so, but we are cooperators.
Being a cooperative species made a big difference.
One of the drivers of that was our amazing capacity of understanding the mind of the
other.
Understanding that somebody that is looking at me is suffering or is scared or is something
that can create trouble.
I can put myself in the mind of the other.
When you combine all this stuff, we have a singularity plus a lot of other things like
mental diseases.
But it's a whole story.
I don't want to spoil because as I was saying, one of the things I want to bring tomorrow
is when you try to approach the complexities of the human mind, there's a kind of a synthetic
or artificial path that can bring a lot of understanding.
At one point, you were talking about ants, I think, and their colonies and that the
more complex the society, the less complex the individuals needed to be.
But we shouldn't apply that to humans.
But you said we shouldn't apply that to humans.
I think, why?
Well, I mean, not every day I feel like the human race deserves good words.
But individual humans are spectacularly complex, provided that you're being immersed in the
cultural thing.
Our brains are nothing unless you are in a society that goes from language to almost
everything else.
But I think that on the one hand, because of the evolutionary pressures that apply for
ant colonies, that had to do with the warranty of the colony works, and eventually that reproduces.
It's a different story for us in many ways.
I also try to bring that tomorrow and make a good comparison.
I must say that this trend we observed, but we still don't have a good theory for the
complexity drain.
But definitely, I remember that Michael Lachman, which was a faculty also at Santa Fe Institute
one day, we were discussing about this, the brain of humans, and he brought me to something
that is, in a way, is trivial, but it's interesting, is that you isolate a human from society and
the brain, this extraordinary potential machine is worthless.
You might survive, maybe, as some kids survive with wolves, but all the potential of the
brain is never going to develop.
So it again says something about the fact that we are also cultural animals, and that
makes a difference.
I understand the utilitarian and the intellectual reasons, like that you do experiments with
animals on octopus, octopi, but aren't there ethical considerations on how we do all these
studies on sentient beings that aren't us?
Yeah, that's a very good point, and I'm sure you know that there's a hot topic these days.
The more we know about some species, the more clearly we need to have ethic criteria of
what is reasonable and what is not for the next experiments.
Even if we will say that, because we don't know, to what extent we can talk about that
sentience and consciousness, etc., we still don't know.
But the precursors of a complex mind, clearly we are seeing it in many species, right?
The elephants clearly mourn, they kind of feel the loss of others.
In the octopi, we see that kind of extraordinary curiosity.
What brings that there?
So this is on the table.
It's a hot discussion, because one thing, as you can imagine, is that to make you want
decisions about what is ethically reasonable or not, we first need to actually have good
definitions of whether or not you have sentience.
Can these be measured in some way?
So it's a good point and it's a relevant research problem now.
I have a question too.
Are you wondering about instinct?
Is that also part of the brain or is the instinct separate from the brain?
Which you have kind of not mentioned in your lecture so far.
I don't know if you understand.
You say, insect brains?
The instinct, the instinct that living organisms have.
I mean, is that part of the brain or is that something else?
You mean for, you say, insect?
Instinct.
Oh, instinct.
Sorry, sorry, sorry.
But you have to, I mean, I came here, you don't know that, but I came straight from
Barcelona, 26 hours, and I was brought here.
My brain is not as good as it should.
Yeah, actually, that's a good point.
Instinct clearly is something that is part of the machinery, right?
In many cases, you see that working in a very almost algorithmic way, right?
This is a famous example of these wasps that kill, no, sorry, that use their stings to
actually put the eggs inside prey that are paralyzed, right?
Could be spiders, could be something else.
And they first make a hole, and then they hunt, they take, I don't know, could be larvae
or whatever it is.
They go there, they leave the prey there, which is paralyzed.
They go inside, check out that everything is okay.
Go out, take the larvae, put it inside.
But then what happens is, if you, while this is happening, imagine that you are a mean entomologist.
And you are looking, and then when it goes inside, you move the prey, which is paralyzed, right?
Somewhere else.
So you see the wasps coming out, finding out that something has changed.
They kind of managed to touch a little bit.
They go inside again.
And if you can repeat that operation as much as you want.
It's like an algorithm which clearly goes from instinct, right?
But on the other hand, in insects, we also been finding in the last 20 years many unexpected things.
Like some wasps recognize the face of others.
There are asymmetries, apparently, in the brains of some ants.
So it's plenty of still of things we need to know.
So it was a question here, and another there.
You defined, you defined some really interesting questions that are very simple.
Like why brains, and what kinds of brains.
But I didn't hear you say what constitutes being a brain.
Like what's your definition of a brain?
So how do you define a brain?
Okay.
I try to avoid that question, right?
I mean, in a simple way, a brain is a collective of neurons that centralizes the activity of an organism, right?
So for a hydra, for example, you have a net of neurons,
or for a jellyfish, you have a ring and a distributed thing.
But you don't have really a core of neurons that are playing a role of kind of integrating information, right?
So that would be a kind of, I think, a potential definition, but it's disputed, right?
I think for me, it's satisfactory.
When you were showing the example of the ants who managed to figure out the shortest route to the food,
or the termites who end up creating something that is a benefit to the society,
or the single-celled organisms that find the shortest route to the flakes in the maze,
it seems like more often than not, in these experiments, you have similar sort of outcomes
that the ants are successful in doing this, the termites are successful in doing this,
and the single-celled organisms are successful in doing this.
But when you take humans acting like a liquid brain,
they often come out to solutions that are harmful to the organism as a whole,
especially in the area of finance, where if you have a lot of individuals here coming to conclusions,
they're more likely to come to this wrong conclusion, which ends up making a few people very rich
and other people very poor, and I'm puzzled by this.
Okay.
Well, it's not an easy question, so it requires a long answer, so close the doors.
No, I am now seriously.
Yeah, when we go into humans, it's interesting to see two things.
One is what you mentioned, because humans, as you move beyond pure commission and you have society,
with all the biases that some can deal with, incomplete information,
plus the big problems we have about polarization and everything,
which is something that in complex systems we want to solve, but it looks like very, very difficult.
But on the other hand, it's just a small part of research, but it's interesting for the insight it brings.
When humans are under the situation of panic, you can make very well-defined models,
which essentially is like particles moving by forces and amplifying phenomena.
Things that we see and have consequences.
For example, in a stadium, you have two exits, and this has happened unfortunately a number of times.
It's panic.
It's a panic attack.
We don't reason there.
We just want to survive.
A typical trend is that the more people go into one exit, the more people go there, which of course is harmful,
because there's another exit.
You can model that, and it's interesting to see that you do the same experiment of panic with ants and with humans,
and that's one place where you can compare.
Very unfortunately, we behave like ants.
If we move beyond that, and it's a legitimate question,
under what conditions we can actually be described as systems like collective intelligence in ants,
and what is the threshold that separates from that and gets into society and all the conflicts that you're mentioning?
But this is a whole area of research.
So, good point.
One thing that we need to actually figure out is to what extent these ideas of collective intelligence apply to humans.
And if theory develops, whether we could actually explore the insight of the theory to actually help us to exploit common knowledge,
that clearly now is underexploited.
So maybe a third lecture on third day?
Thirdly, you have to be in Barcelona.
Okay, we have time for one more question.
Hi, I was interested in your chart where you have your three dimensions,
and you have this big sphere of the unknown or the unexplored,
and I wanted to know, it was like, yes, that's the one.
So, what we're missing is cognitively complex and developmentally complex as well, or maybe that doesn't matter.
But I'm wondering what you think that could look like.
You said that we might be able to manufacture it, something in that space.
I said what, sorry.
I thought I caught you saying, sneakily, maybe that in this unexplored space,
maybe that's where we have space to manufacture some sort of brain-like thing.
I'm just wondering what you think is in that space that we're missing.
Okay, if you come to the second lecture, I think I have the answer for that.
I don't want to make more spoilers.
Alright, thank you so much.
