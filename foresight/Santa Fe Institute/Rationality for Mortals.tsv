start	end	text
0	8520	And the director of Hardin's really great because Gerd is one of the originator of the
8520	13520	theory of ecological rationality at the simple computational models of rules, algorithms
13520	17240	that people use to make decisions in different contexts.
17240	22960	And he's basically introduced complex system science to psychology, cognitive science because
22960	28680	his main thesis is that we cannot understand cognition without looking at its social and
28680	34080	physical environment, only by careful analysis of both the environment and the algorithms
34080	36760	people use to make decisions and solve various problems.
36760	40880	We can understand how people behave and why people behave in different situations.
40880	45640	Gerd is a recipient of numerous awards.
45640	51600	He is member of the Academy of German Academy of Sciences, author of numerous books translated
51600	52600	in many different languages.
52600	53600	And he plays banjo.
53600	60600	So we need to have a closer look at the question.
60600	67200	All right, thank you.
67200	70200	Thanks Mirta.
70200	75280	Today I will talk about how to make good decisions.
75280	83240	If you open a book on rationality in neoclassical economics, behavioral economics, or psychology
83240	89080	of philosophy, you likely encounter the following message.
89080	96120	Good decisions follow the laws of logic, the calculus of Bayesian probability and the maximization
96120	99320	of expected utility.
99320	106840	This is beautiful mathematical theory, but it does not describe how most people actually
106840	113680	make decisions, not even those who write these books.
113680	116120	Let me start with a story.
116120	123120	A professor of decision theory at Columbia University in New York had an offer from a
123120	125400	rival university.
125400	127320	It was Harvard.
127320	130360	And he could not make up his mind.
130360	131360	Should he stay?
131360	132360	Should he leave?
132360	133360	Should he accept?
133360	134360	Reject.
135040	140040	A colleague took him aside and said, what's your problem?
140040	144520	Just maximize your subjective expected utility.
144520	148640	You always write about that.
148640	157960	Exasperated, the professor responded, come on, this is serious.
157960	164520	I'll invite you today in a short tour in our research at the Max Planck Institute for
164520	169640	Human Development on how people actually make decisions.
169640	180760	And I'll start with a key distinction between risk and uncertainty.
180760	190200	A situation of risk is a well-defined, stable, small world where the agents know the exhaustive
190200	196680	and mutually exclusive set of all future states and the exhaustive and mutually exclusive
196680	205920	set of their actions, of the consequences given their actions and states.
205920	213640	Jimmy Savage, who is often referred to as the father of modern Bayesian decision theory,
213640	219800	called this a small world.
219800	221760	There are examples for the small worlds.
221760	230960	If this evening you go to the casino in Santa Fe, if there is one, and play roulette, you
230960	233480	are in a small world.
233480	241400	You know every possible state that can happen, from zero to 36, all the consequences and
241400	245400	probabilities.
245400	253240	The tools for dealing with risk or maximizing expected utility, Bayesian probability updating
253240	257160	and many more.
257160	264280	In a small world, by definition, nothing new can happen.
264280	273320	I had the quote from Fjodor Dostoevsky, who said, in this world, if everyone would be
273320	276560	rational, he said, nothing would happen.
276560	283400	With amazing foresight, he had seen the development of rationality.
283400	290280	Now there are two, most of the problems have to do with, however, with some aspect and some
290280	293080	amount of uncertainty.
293080	301400	Uncertainty is a vast sea of situations where there is no small world where we either cannot
301400	307800	know all future possible states or their consequences.
307800	315200	It's not just about probabilities, it's about the state space.
315200	317680	Researchers have two ways to go.
317680	328360	One is to take an everyday problem, like investment, whom to hire, or whom to marry.
328360	336360	These are all situations of uncertainty because things can happen that you had not anticipated.
336360	345240	Then go one way, reduce it to a small world where everything is known and you can maximize.
345240	353120	That's the way that most theories in neoclassical economics, also behavioral economics, at
353120	356000	least the standards, are going.
356000	365560	The other option is to take uncertainty seriously, face it, and develop and study the tools that
365560	371920	actual people use to make decisions in an uncertain world.
371920	376600	Here by definition, optimization is not possible.
376600	386520	You cannot construct even a subjective probability distribution over a set that you don't know,
386520	390160	that you don't know completely.
390160	397960	I will talk today about one class of tools that are useful under uncertainty, and these
397960	401120	are heuristics.
401120	412360	Heuristics are rules that embody the art to focus on the important and ignore the rest.
412360	423600	Heuristics can lead to good decisions in a world where we cannot forecast the best decisions.
423600	430600	Examples are Herbert Simon's satisfying, Boston Fruity Trees, imitation, agent-based
430600	441680	models who use simple rules like the flocking of starlings, the beautiful models.
441680	448480	I will today go a different way than most of the models are going.
448480	455600	For instance, even behavioral economics, who criticizes neoclassical economics, criticizes
455600	465600	not normative standard, not homo-economics, not the maximization of expected utility,
465600	473160	rather takes a standard to evaluate people, and if there is a discrepancy, the blame is
473160	475760	never on the theory.
475760	478560	It's always on the people.
478560	485480	And then you get the list of biases that are all in your minds, and explain why you all
485480	493200	make these strange decisions, and stubbornly have no insight in your failures.
493200	495120	This is not my message.
495120	502440	I want to study how people make decisions and formalize the heuristics, and then find
502440	509120	out in what situation do they work and where do they not work.
509120	513680	That's the question of ecological rationality.
513680	521760	Rationality is not in the mind, but in the adaptation of mental strategies to certain
521760	523640	environments.
523640	530400	Let me start with an example that makes the difference clear between a model made for
530400	538400	risk and model made for uncertainty.
538400	547240	Every Markowitz got the Nobel Memorial Prize in economics for solving a certain problem.
547240	555640	The problem is you have a number of N assets, and you want to invest your money, and you
555640	561200	want to diversify, not put everything in one pocket, but how?
561200	565040	The answer is the so-called mean variance model.
565040	567440	It's a standard probability model.
567440	575520	You need to estimate all the future returns, their variances, and covariances.
575520	582080	When Harry Markowitz made his own decisions about the time of his retirement, he used
582080	585800	his Nobel Prize winning optimization method.
585800	590680	So we might think, no, he did not.
590680	599840	He used a simple heuristic that we call 1 over N. N is the number of assets or options.
599840	604280	So if it's 2, you do 50-50.
604280	609840	If it's 3, a third, a third, a third, and so on.
609840	615040	Now 1 over N is a heuristic.
615040	619040	The mean variance model is an optimization model.
619040	625200	The mean variance model assumes we are in a world that is stable, where we can estimate
625200	631320	the parameters to some degree of precision.
631320	637280	Number of studies have looked at 1 over N.
637280	645240	And for instance, the study by D. Miguel here has looked at seven real-world investments
645240	654360	and found that in six of the seven cases, 1 over N made more money than Markowitz's optimization
654360	660280	as measured by sharp ratios and similar ones.
660280	668880	The results have been found when exchange-traded funds were tested, ETFs which are close to
668880	673080	1 over N, they're very hard to beat.
673080	678760	Now there is a battle in the literature, which one is better?
678760	681440	Complex optimization or simple heuristic?
681440	684280	This is the wrong question.
684280	685840	None of this is better.
685840	688000	No algorithm is the best.
688000	690520	We need to ask a different question.
690520	701200	So can we identify the environment, the conditions where a simple heuristic like that does better
701200	707760	than another one, another model, and where it's the opposite?
707760	714160	The answer to this question of ecological rationality is not known.
714280	716120	Some of you might figure it out.
716120	719000	Here's some hypothesis.
719000	729080	So if you think in terms of the bias variance decomposition, then 1 over N has probably
729080	739600	a strong bias but makes no error due to variance because it doesn't estimate any parameters.
739600	745680	So the error due to variance means that you get different results depending on what sample
745680	748600	you make your estimates.
748600	759640	So the real question to solve here is when is the bias that 1 over N has larger than
759640	770200	the total error that mean variance makes, that is both bias and variance.
770200	774840	So this is the way I would like to think here.
774840	779000	Excuse me, did Markowitz ever say why he chose 1 over N?
779000	780000	Yes, he did.
780000	783760	He had a psychological explanation.
783760	793200	He said if I would, his choice was between the typical retirement situation, just stocks
793200	794200	or bonds.
794200	801320	If I would put everything in bonds and they would go down, I would feel bad.
801320	803120	If the opposite, I would also feel bad.
803120	804960	I would have regret.
804960	813240	So I just did 50-50 to avoid regret, but it's very different.
813240	821120	He was actually very interested when we and others showed that he wasn't at least where
821120	822120	his experiments are.
822120	831280	It's just stocks, a slightly different situation that was shown that simply can do better.
831280	841440	So the confusion between situations of uncertainty with risk, the idea that every situation of
841440	847960	what uncertainty is one of risk is called the turkey illusion.
847960	849960	So why?
849960	853240	Assume you are a turkey.
853240	860880	It is the first day of your life and a man comes in and you fear he will kill me, but
860880	861880	he feeds you.
861880	867680	The second day of your life, the man comes again, you fear he might kill me, but he feeds
867680	868680	you.
869320	871480	Third day of your life, same thing.
871480	878800	If you do Bayesian updating or any similar model, the probability that the man feeds
878800	883320	you and doesn't kill you gets higher every day.
883320	891200	And on day 100, it is higher than ever before, but it's the day before Thanksgiving and you
891200	893200	are dead meat.
893200	897880	So the turkey was not in a situation of risk.
897880	901600	He missed important information.
901600	904520	There was an option he could not think.
904520	913360	Now the turkey illusion is probably not so often committed by turkeys, but more often
913360	915680	by people.
915680	921360	And here's one example.
921360	929480	In 2003, in his presidential address to the American Economic Association, Robert Lucas,
929480	937040	the macroeconomist, argued that one has learned from earlier depressions and macroeconomics
937040	938880	models take care.
938880	944880	So he said, my thesis in this lecture is that macroeconomics has succeeded.
944880	951720	Its central problem of depression prevention has been solved for all practical purposes.
951720	961560	Now what you get is an illusion of certainty if you apply the models that are based on
961560	964640	assumptions of risk to one of uncertainty.
964640	967640	I've shown you just the illustration here.
967640	975920	In the year 2003, when he gave this talk, the Volateli Index, we are X, went down and
975920	976920	down and down.
976920	982280	So it got better and better and better and better, safer, until shortly before the crisis
982280	984960	hit.
984960	990240	And that's the same thing as the mass modeling models they used.
990240	996760	By the way, the models that Lucas described in his presidential address all assumed a
996760	1002640	stable and unchanging structure of the economy.
1002640	1005600	So what's the alternative?
1005600	1011000	And here's the research program I and my research group has been following up.
1011000	1012640	And it has three questions.
1012640	1014880	The first one is descriptive.
1014880	1023200	What is in the adaptive toolbox of an individual, an organization, or a species?
1023200	1030440	So what are the heuristics they use, the cognitive capacities that the heuristics exploit?
1030440	1033320	And what's the building blocks?
1033320	1042200	And the goal is to use, to develop algorithmic models of these heuristics, not labels.
1042200	1049560	We have since the 1970s a tradition in the heuristics and biases program of labels, like
1049560	1054080	availability representative, nobody knows what exactly they mean.
1054080	1061160	And they used never to make predictions, but always to explain something after the fact.
1061160	1068680	The same is with system one and system two, which is just a list of dichotomies.
1068680	1078520	And the dichotomies is where a science should start and go to good models.
1078520	1085280	And this is a case where we went from models to dichotomies, to backwards.
1085280	1089560	Trusky had models of heuristics like elimination bias.
1089560	1098400	But then after Trusky died, Kahneman sided with this dual system theories that has been
1098480	1102760	long criticized in psychology before.
1102760	1113960	Alan Newell said, in a famous paper in 1957, you can't ask 20 questions to nature.
1113960	1122200	And criticizing the tendency to not do models, but to do dichotomies, serial versus parallel,
1122200	1127640	unconscious versus conscious, fast versus slow, and so on.
1127640	1133920	And all this is so intuitive that one forgets that one does science.
1133920	1139120	So the second question is, no, it's a prescriptive question.
1139120	1141640	When should we use heuristics?
1141640	1142480	And when not?
1142480	1144560	And what heuristic?
1144560	1148040	And then, certainly, it's heuristics all the way down.
1148040	1149840	There's no option.
1149840	1151880	The real question is, what is a smart?
1151880	1155520	Is a smart to imitate?
1155520	1162400	The peers, when searching for a research topic, or should I think myself?
1162400	1170400	So here the question is, can we prove mathematical or at least with computer simulations show
1170400	1176720	under which condition, for instance, one way in works, where does imitation work, and so on?
1176720	1179600	And the final question is one of application.
1179600	1185480	It's doing intuitive design using all these insights.
1185480	1188920	So I'll start with the adaptive toolbox.
1188920	1195000	And here is a few on part of the toolbox.
1195000	1198840	There are core capacities that humans have.
1198840	1202880	On that basis, the heuristics can be simple.
1202880	1212440	The core capacities are quite complex, meaning it's very hard to build a brain that can't do that.
1212440	1213840	Let me start.
1213840	1218800	So there are, I can only give you some examples today.
1218800	1227560	And on the left side, there are social heuristics like imitation, word of mouse, which are highly powerful.
1227560	1230080	There would be no culture without imitation.
1230080	1239000	Mike Tomasella has shown in his beautiful research that children, human children, imitate much more precise
1239000	1243040	and much more general than primate infants.
1243040	1250680	And it's one of our big advantages that builds culture that one doesn't have to learn from scratch all the time.
1250680	1255320	It's also one of our greatest dangers.
1255320	1259760	So let me start with recognition.
1259760	1264160	Recognition is a fundamental ability of the human mind.
1264160	1266240	We can recognize faces.
1266240	1269200	We can recognize names.
1269200	1273080	And recognition is different from recall.
1273080	1278200	If you cannot recall the name of a good friend, that happens.
1278200	1284280	Particularly when you get older or when you're a jet lag like me at this moment.
1284920	1293080	But if you do not recognize the name of a good friend, then you're a clinical case.
1293080	1306480	So the recognition heuristic exploits this capability to make inferences in situations where you don't know much.
1306480	1309120	Let me do a demonstration with you.
1309120	1311120	Are you ready?
1311120	1323040	Okay, assume you are in a TV show called Who Wants to be a Millionaire?
1323040	1324280	And you made it through the end.
1324280	1328040	And here is the million dollar question.
1328040	1330840	Which US city has more inhabitants?
1330840	1333120	Detroit or Milwaukee?
1333120	1334480	Time is ticking.
1334480	1336560	Who of you thinks it's Detroit?
1336560	1338560	Hands up.
1338560	1341600	Who of you thinks it's Milwaukee?
1341600	1344400	Hands up.
1344400	1349440	A rough estimate, 60% of you got it right.
1349440	1353280	It's Detroit.
1353280	1363480	When we did experiments with undergraduates at the University of Chicago, who think there is more or less in the country,
1363480	1365480	we got the same result.
1365480	1367200	60%.
1367200	1375760	And then Dane Goldstein and I asked students in Germany, what do you think?
1375760	1382640	So not just this one question, but all questions about large American cities.
1382640	1384040	What do you think?
1384040	1388920	How many Germans got the right?
1388920	1391760	More than 60.
1391760	1393040	More than 60.
1393040	1394680	And why do you think that?
1394680	1396720	Because otherwise I wouldn't ask you.
1396720	1400520	They relied on the heuristic of recognition.
1400520	1401240	Right, yeah.
1401240	1403400	And trust that a lot too.
1403400	1404720	You're right.
1404720	1410320	Or this is when you give a talk with two people who have already your work.
1410320	1411560	OK.
1411560	1417040	The point is, many of the Germans have never heard of Milwaukee.
1417040	1422040	And the recognition heuristic tells you, choose the option you recognize.
1422040	1424040	And they were right.
1424040	1427080	Now, let me test you the other way around.
1427080	1428680	OK, ready?
1428680	1432360	Which German city has more inhabitants?
1432360	1434680	Bielefeld or Hannover?
1434680	1437440	Who is for Bielefeld?
1437440	1438480	You.
1438480	1440400	Who is for Hannover?
1440400	1442360	You got it right.
1442360	1446760	I think the two suspected that I want to fool them.
1446760	1450840	You shouldn't think too much.
1450840	1456000	If I ask the same question to Germans, many of them get it wrong.
1456000	1457440	Because they had heard of both.
1457440	1461600	And they need to retrieve knowledge about that.
1461600	1462920	See the point?
1462920	1465960	And we had just a less-is-more effect here.
1465960	1473840	You got more questions right about the German cities than about America.
1473840	1477040	Although you know more about the Americans than the Germans.
1477040	1478880	So how does this work?
1478880	1481800	So here's the study of ecological rationality.
1481800	1485240	So think you have a test of a hundred of these questions.
1485240	1488160	Maybe the hundred largest cities in the US.
1488160	1492280	And consider the lowest coefficient.
1492280	1499520	If you haven't heard of any of the cities, your performance is 50%.
1499520	1501440	Yeah, you just guess.
1501440	1506320	If you've heard of all of them on the other side, it's also 50%.
1506320	1509160	Because you cannot use the recognition tool.
1509160	1511880	You're seeing both cases that have no knowledge.
1511880	1515320	Now assume the person has knowledge.
1515320	1517960	And the knowledge is defined here.
1517960	1524840	It's defined as the number of answers you get right in cases where you've heard of both.
1524840	1526840	Like before, it was 60%.
1526840	1532120	And actually, the curve here, the second curve, is about knowledge relative of 60%.
1532120	1540280	Person B recognizes all American cities like you and gets 60% right.
1540280	1542520	This is knowledge.
1542520	1546800	Person A recognizes only half of them.
1546800	1552080	Can apply the recognition here and gets more right.
1552080	1558520	The curves are drawn for recognition validity of 0.8.
1558520	1564760	Meaning that the number of correct inferences in all cases,
1564760	1569240	where you have recognized one and not the other.
1569240	1571120	So you can measure all these things.
1571120	1574680	There's no parameter fitting game here.
1574680	1585280	And if the knowledge validity is at least as big as the recognition validity,
1585280	1588600	there is no lesses more effect in it.
1588600	1593240	So the lesses more effect you find on this three curves below,
1593240	1598960	it means that on the right side of the curve, performance goes down,
1598960	1602560	despite you either no more or recognize more.
1602560	1610960	So this is an illustration how we can model and can actually make quantitative predictions.
1610960	1618560	And we have used this, for instance, in predicting maybe more interesting things in cities,
1618560	1621880	unless you are on a million dollar question.
1621880	1633000	Like you can how to predict the outcomes of all Wimbledon gentlemen's single games.
1633000	1639160	There are 128 contestants, there are 127 games.
1639200	1641000	And you make a prediction for everyone.
1641000	1648240	And you can do this with the ADP rankings or with the Wimbledon seedings or with ignorant people.
1648240	1653880	Exactly partially ignorant, because fully ignorant cannot use the heuristics.
1653880	1659040	And again, from here you can see, you need to find people that have heard about half of them.
1659040	1660480	And not if there was one.
1660480	1667040	And these were German amateur players and they made in two studies
1667040	1674160	more correct predictions than the ADP rankings or the Wimbledon experts.
1674160	1683480	And if you change that to those who recognize less, then they will not make more predictions.
1683480	1689560	So this is just an example how one can analyze the ecological rationality of a heuristic.
1689560	1693320	You can easily tell when the heuristic is worthless,
1693320	1699760	when the recognition validity is a change level, that is noting.
1699760	1709000	And we also have a way to make earlier concepts like availability into something precise.
1709000	1716560	That is useful and also illustrates some of the amazing capabilities of the human mind
1716560	1721440	to exploit one's own ignorance.
1721440	1724840	Second example, fluency.
1724840	1729320	Fluency presumes recognition.
1729320	1737520	And it can be measured by the time an option comes to your mind.
1737520	1751400	And the point I'm making with the next example is that a human intuition using fluency,
1752360	1756720	creates no speed accuracy trade-off.
1756720	1758920	What is the speed accuracy trade-off?
1758920	1765640	That's usually something that if you make judgments fast, then you lose on accuracy.
1765640	1771560	That's the story about fast versus slow thinking fast versus slow and so on.
1771560	1779560	A speed accuracy trade-off, you get them if you test undergraduates with problems I've never heard.
1779560	1787360	But if you test experts, it's the opposite.
1787360	1790480	So here's the example.
1790480	1804600	The example is there are experienced handball players and some of my postdocs put them in
1804600	1808760	the uniform with a ball in the hand in front of a video.
1808760	1814800	And the instruction was there will be a top handball game, running for 10 seconds, then
1814800	1821960	it will be frozen, and tell me immediately what the player with the ball should do.
1821960	1827880	So they looked at that, it was frozen, and they would say I'll pass to the left here
1827880	1831560	or shoot at the goal or something else.
1831560	1842160	Then they had 45 seconds more time to study the still frozen image carefully.
1842160	1848760	And they were instructed, if other options come to your mind, please tell us.
1848760	1853080	And then one of them said, oh, I didn't see the guy on the right side, passed, that would
1853080	1854760	be a good one.
1854760	1864360	And after all of this was done, the options were plotted against the quality, as measured
1864360	1868440	by the best coaches we have in the country.
1868440	1870640	And what you see is very interesting.
1870640	1874560	On average, the first option that comes to your mind is the best one, the second is the
1874560	1877960	second best, the third is the, and so on.
1877960	1886560	That means if an experienced player goes with the first option, he or she is most likely
1886560	1888760	right.
1888760	1894320	And we also found that when we asked them at the end of the 45 seconds they had studied,
1894320	1901080	what would you do now, about 40% change their mind, and got into a worse option.
1901080	1906600	So here we have a case where we have no speed, accuracy, trade-off.
1906600	1914040	Country, it's better, on average, to act on your first impulse.
1914040	1916960	In a game you have to do this.
1916960	1923240	But in the experiment, you have to change the thing longer, but it doesn't help.
1923240	1925280	It regularly hurts.
1925280	1928560	Remember, this only works for experts.
1928560	1934960	If you have amateur players, the curves, they're not going down, they're just stator.
1934960	1939600	So this has an important insight.
1939600	1949120	So intuition, as I define it, is based on years of experience, what you want to do comes
1949120	1952760	quickly to your mind, and you don't know why.
1952760	1958480	And the fluency heuristic is an explanation how this works.
1959400	1965720	The reason why the research has come to the conclusion that what the general speed, accuracy,
1965720	1973200	trade-off is mainly because one studies undergraduates with problems they've never seen before.
1973200	1981120	Gary Klein, who studies fire furthers, finds the same results.
1981120	1987520	So the third and last category, I want to give you examples, is an interesting one,
1987520	1999840	where it is about the human capacity to order things in importance, and these are heuristics
1999840	2006960	that are based, that base the decision on a single cue.
2006960	2012120	And let's give you an example about hiring.
2012120	2021160	When Elon Musk was still young, and Tesla was young, Elon Musk did the hiring himself,
2021160	2024280	and he reported how he did it.
2024280	2027920	He did not get an assessment center.
2027920	2035720	He did not study CVs, but he, according to himself, he relied only on a single cue.
2035720	2045520	Just a person possesses some exceptional ability, like a banjo player.
2045520	2051400	And if not, no hire, if yes, hire.
2051400	2055920	Now you might wonder why not more cues.
2055920	2065360	But look, exceptional ability is something that has some kind of redundancy with other
2065360	2066640	things.
2066640	2074720	So a person who has this to get there needs to know how to persevere, how to concentrate,
2074720	2079320	how to sweat, and not give up.
2079320	2086000	And so that's the spirit behind that.
2086000	2094480	It also illustrates that these heuristics are adapted to certain problems that will not
2094480	2099160	work well when the company, like Tesla, had grown.
2099160	2103360	Because then you need people who do routine work.
2103360	2108640	One needs to adapt that, and that's the idea in the adaptive toolbox.
2108640	2120760	Now here is another hiring heuristic, and that's what we call a fast and frugal tree.
2120760	2128240	A fast and frugal tree is an incomplete tree that has an exit on each of the questions
2128240	2130400	or cues.
2130400	2137000	So if the number of cues or questions are n, it has n plus 1 exits, while a complete
2137000	2142760	tree is in the case of dichotomous 2 to the n.
2142760	2149280	So when Abbason was young, a Jeff Bezos also reported about how he did make the description,
2149280	2153920	and we reconstructed that in the form of a fast and frugal tree.
2153920	2156040	So note it's sequential.
2156040	2161600	It doesn't integrate as rational theories usually assume.
2161600	2165720	Interestingly, his first question was the same.
2165720	2168440	So does the person have an exceptional ability?
2168440	2171040	But if yes, it wasn't enough.
2171040	2177080	Second question, will you admire this person, which is a quite unusual question?
2177800	2185440	We explained that if he, Bezos, admires a person, he will learn from that person.
2185440	2193840	But that was also not enough, and only if that person raises the average level in the
2193840	2198440	unit where he or she will be, that's being hired.
2198440	2206480	So the properties of these trees are of a lexicographic nature.
2206480	2215000	A lexicographic strategist cannot be mapped into a utility, into a smooth utility function.
2215000	2222560	And that's why classical books like Luce and Wreifer have always ignored them and looked
2222560	2224600	down at them.
2224600	2231280	But people use these strategies, and we have shown that there are certain situations where
2231280	2235840	a fast and frugal tree can outperform random forests.
2235840	2240720	And the interesting question is, again, can we prove this situation?
2240720	2245000	Can we identify them where that works?
2245000	2251680	So I'll show you one way to, about how to model such a tree.
2251680	2262080	If you use these three questions in the order, how many trees are possible by changing the
2262080	2263080	exits?
2263080	2264080	Sorry.
2264080	2265080	Four.
2265080	2266080	Oh.
2266080	2267080	It's four.
2267080	2269600	You tell me later, the other two.
2269600	2270600	The same and changing.
2270600	2271600	Yeah, the same, yeah?
2271600	2272600	The same cues in the same order, yeah?
2272600	2273600	Otherwise, it would be more.
2273600	2274600	Correct.
2274600	2280720	Bezos tree is on the left side.
2280720	2287520	So any classification can make one of two errors, like making an offer to a person whom
2287520	2293840	you should not have made an offer that's a false positive, or not making an offer to
2293840	2297440	a person whom you should, that's a miss.
2297440	2303360	The Bezos tree minimizes false positives, yeah?
2303360	2307840	He only makes an offer after long, yeah?
2307840	2314520	These four trees do a balance between false positives and misses.
2314520	2322520	On the right side, you have a tree that maximizes false positives relative to miss.
2323520	2331960	And in the middle, you have very interesting trees that have a zigzag structure.
2331960	2338640	An example for a tree on the right side, I'll show you from our work with the Bank
2338640	2339640	of England.
2339640	2346640	So the Bank of England has a problem how to identify vulnerable banks.
2346640	2348920	How do you do that?
2348920	2359680	Now the classical method is in the so-called Basel or Basel two and three programs, and
2359680	2365280	where the banks calculate a value at risk.
2365280	2372680	And if you've ever done that, so if you are the CEO of a large bank, you have to estimate
2372680	2374760	thousands of risk factors.
2374760	2378120	That means a covariance matrix in the order of millions.
2378120	2384520	And you can't use more than five, ten years of data because before something strange
2384520	2389160	would happen.
2389160	2392200	These calculations are impressive.
2392200	2398920	They have prevented, they've never prevented any crisis and probably will never prevent
2398920	2400560	any crisis.
2400560	2403520	It's another Turkey illusion.
2403520	2409920	This standard probability theory applied to the situation of uncertainty.
2409920	2420520	I once gave a talk to the European Central Bank and said, the calculation that you do
2420520	2424800	border on astrology.
2424800	2432440	And I was waiting for someone to say, no, the answer was, yes, but what else should
2432440	2434680	we do?
2434680	2439400	Here is what else could be done and systemically be studied.
2439400	2441280	So this is now a fast and frugal tree.
2441280	2444520	That's the same structure as the one that's seen before.
2444520	2452800	And it asks just three questions, for instance, leverage ratio below a certain percentage
2452800	2457040	and if it's lower, red flag.
2457040	2461000	If not, it goes on and asks two more questions.
2461000	2465480	I'm not going into the details here, but you see the structure.
2465480	2471200	It's important that it works very different from standard rational models.
2471200	2480520	So for instance, the Swiss bank, UBS, had failed before the crisis on the first item.
2480520	2486360	So the leverage ratio was much less than half of that.
2486360	2489880	That would have identified it immediately.
2489880	2500680	UBS did marvelous on the other criteria, but the trees are non-compensatory.
2500680	2503520	It's like the human body.
2503520	2506920	If your heart fails, a good lung doesn't help you.
2506920	2508920	You can't compensate that.
2508920	2511560	So it's a very different model.
2511560	2516920	And the reason why this type of strategy cannot be mapped into a smooth utility function,
2516920	2519840	who cares about that?
2519840	2528840	It has to work and not to follow some mathematical doctrine.
2528840	2536880	Again importantly, it reflects sequential thinking and has a few other advantages.
2536880	2539360	Bankers can understand that.
2539360	2548560	And also, the banks, the regulators are more safe that the banks cannot game the system.
2548560	2554440	If you have to estimate millions of co-variants, you have plenty of room to game.
2554440	2557320	Here, it's much easier.
2557320	2562280	It's much more difficult to game the system.
2562280	2566160	So can I just ask you something unconfused?
2566160	2572720	So this is a risk-minimizing structure that can be calculated based on known states.
2572720	2579400	Earlier, you started by talking about heuristics as being solutions to the uncertainty problem.
2579400	2582960	This looks like a risk problem.
2582960	2588080	The uncertainty is in what banks are doing.
2588080	2593280	So the model is a heuristic.
2593280	2597360	It's not an optimizing model.
2597360	2602440	And your right, it goes, it's the rightmost tree.
2602440	2606280	It tries to minimize the misses.
2606280	2608400	You want not to overseas.
2608400	2611240	And the costs are false alarms.
2611240	2614040	That's what the decision is.
2614040	2621760	How we build the trees is a mixture between, so the economists at the Bank of England,
2621760	2628680	they identify the variables on base and we check them down on empirical data.
2628680	2633560	So for instance, the cutoff points, it's all empirical data.
2633560	2635520	We deliver the structure.
2635520	2638640	Now, don't put this in a regression.
2638640	2640120	Think about this structure.
2640120	2644240	That's the way this is being done.
2644240	2647760	And then it needs to be tested how well it works.
2647760	2651440	The advantage is transparency.
2651440	2659800	That it can easily be understood and it can be changed in cases there is a problem.
2659800	2664320	And it's an alternative that can be systematically studied.
2664320	2665320	Yeah.
2665320	2673800	Well, I'm not going to, the states are still all nine points, but the state outside of the
2673800	2675880	system or the framework.
2675880	2681400	Whereas when you had the opening definition of risk and uncertainty, there's something
2681400	2685560	about the small world about these states.
2685560	2687560	It's a good question.
2687560	2698480	So the world of finance here has incredibly and also unknown uncertainties.
2698480	2704520	So the numbers that the Bank of England gets from the banks, you can count that they're
2704520	2708720	not the real numbers, they're polished.
2709280	2715840	The other source of uncertainty is in what's actually happening in the financial systems.
2715840	2719440	And there could be another Russian default or something.
2719440	2721680	This is the uncertainty I mean.
2721680	2728200	And this is a model how to deal with that uncertainty.
2728200	2733320	And there's no claim about optimization or maximization for anything.
2733320	2737520	It's just an attempt to do better than what one has.
2737880	2749720	Here is a book we've done, which is how to build these trees from empirical data.
2749720	2753440	And what's the alternative in case that's of interest.
2753440	2759000	But the uncertainty in the financial system is enormous.
2759000	2762640	Is that, sorry, let's take it a little bit.
2762760	2769920	So I was sympathetic to your critique of the dichotomizing approach that you've adopted
2769920	2775200	it yourself in the heuristics versus the optimizations.
2775200	2781600	And is it possible actually, given the observation that we just made, in fact, what you're calling
2781600	2786240	a heuristic is just on the spectrum towards full optimization.
2786240	2787240	Yeah.
2787240	2788240	Yes.
2788240	2789240	Okay.
2789240	2790240	Yeah.
2790240	2796480	I mean, if you do Bayesian, they're Bayesian usual optimization model, then you start with
2796480	2797480	uniform priors.
2797480	2798480	That's a heuristic.
2798480	2801440	You're totally right.
2801440	2806480	It is, I just make it simple.
2806480	2811320	But it's very clear that one should pay attention, I think, to the heuristics.
2811320	2812320	Yeah?
2812320	2815920	There's a bit of a category error here.
2815920	2817800	You actually mentioned ROC curves.
2817800	2826000	The whole point of ROC curves is, which are middle of standard machine learning, is that
2826000	2827000	they are an alternative.
2827000	2828840	You don't come up with one.
2828840	2832160	You set your own level on an ROC curve.
2832160	2837680	And you're simply saying, go on ROC curve in a way that you're less likely to screw
2837680	2838680	up.
2838680	2839680	Sure.
2839680	2843840	That makes perfect sense.
2843840	2849160	But I don't think it's really got to do with optimization versus heuristics, just using
2849160	2854360	an ROC curve over, and the points that David is making in the fellow over there, is it's
2854360	2861000	a very high level coarse grain space as opposed to these banks are being stupid and are using
2861000	2863960	a fine grain space where you can't measure the variables.
2863960	2869160	But the point is, is an ROC curve doesn't give you a single answer.
2869160	2873360	You're putting in that I don't like the chance of screwing up.
2873360	2879480	Therefore, I'm going to set my threshold in the ROC curve and go over to this side.
2879480	2880880	Okay.
2880880	2886880	What you picked this point here, the one-game map, the fast and frugal degrees onto an ROC
2886880	2888400	curve, onto four points.
2888400	2893560	And that's a direct connection between an optimization model.
2893560	2899840	Then the question is, whether the optimization model helps you for a certain problem.
2899840	2908960	The name and Pearson theory, which is below the foundation of the ROC curves, makes a
2908960	2915480	number of assumptions about the distributions which are not necessary here.
2915480	2927440	I see a point here, and also it's difficult for the ROC curves to deal with more than
2927440	2928440	one variable.
2928440	2932200	Can be done, gets very complex.
2932200	2937080	Here it's relatively easy to deal with them.
2937080	2942080	So there are differences between these two curves, but you also write and we showed that
2942080	2953320	in this paper here, that the heuristic can be mapped into an optimization model, right?
2953320	2958600	So I'll end with a few remarks about ecological rationality.
2958600	2967360	So the idea of ecological rationality is from Herbert Simon, and that's a famous quote from
2967360	2971160	him where he says, this is a analogy.
2971160	2976640	It basically says, in order to evaluate the rationality of behavior, you need to look
2976640	2983080	both at cognition, the strategies, the heuristics, anything else, and the environment, and how
2983080	2985520	they match.
2985520	2998680	It also means the standard definition of rationality is following the laws, say, axioms of consistency
2998680	3006760	or maximization of expected utility is an internal definition.
3006760	3012560	It doesn't take account how these things work in the world outside.
3012560	3020800	And for instance, that part of behavioral economics, who has adopted the heuristics
3020800	3025360	and biases program, uses a single internal definition.
3025360	3031400	There is to be a law of logic or probability, and people are measured against that.
3031400	3038520	And what I'm arguing, we need to measure behavior against the real world, against the
3038520	3043360	measure heuristic against the real world or the success.
3043360	3052680	What I'll show you now at the end is just a simple and intuitive answer to the question,
3052680	3057400	can we, I've shown you a few heuristics that just rely on one reason.
3057400	3067200	Can we identify the conditions under which relying on one reason cannot be beaten by
3067200	3073560	a linear equation that has more reasons, including the one reason?
3073560	3076920	Clear?
3076920	3084800	So do you have an idea?
3084800	3089920	I'm just asking you before, because afterwards it's so evident that we knew it all along.
3089920	3093680	To be clear, it's a subset of that larger space, right?
3093680	3096520	Yeah, it's a subset.
3096520	3098440	So think about it.
3098440	3106320	A binary decision, higher or not higher, there is Elon Musk has one reason.
3106320	3115560	The question is, under what conditions will relying on this one reason always lead to
3115560	3126640	the same results that a linear model that includes many valid reasons, they're all valid,
3126640	3127640	including the one.
3127640	3128640	Clear?
3128640	3129640	It's a subset.
3129640	3130640	Yeah?
3131640	3137600	Here's a simple condition, and it's if there is a dominant queue.
3137600	3145080	But it means that the weights of binary queues form a dominant queue structure.
3145080	3150440	And so the weights are like regression weights, it's the additional contribution to the first
3150440	3151440	one.
3151440	3157280	So if the weight of the first one is larger than the sum of all the others, you can intuitively
3157280	3162720	see it will not get to any other decision.
3162720	3166240	And then the next question is, how often does this happen?
3166240	3174480	We have looked at machine learning data sets, and it happens quite often, astonishingly
3174480	3175640	often.
3175640	3182400	So this is not the only condition, it's just a sufficient conditions.
3182400	3190920	And we've looked at three conditions, and in the median value is that in 90% of all
3190920	3194720	comparisons in the data set, this condition holds.
3194720	3204040	So if you take half of the data sets, in 90% or more, it holds, and the other is not.
3204040	3210640	And then the next question is, what are the other conditions?
3210640	3219880	And I'm not going into this at this moment, but end with a more general view that's probably
3219880	3221760	known to many of us.
3221760	3226200	So this is a standard justification for why people use heuristics.
3226200	3229040	It's an accuracy effort trade-off.
3229040	3235640	So people are a little bit lazy, or they don't make the effort, and they pay for that in
3235640	3237360	accuracy.
3237360	3246760	That you will find in the Kahneman book, on justifying why biases need to be eliminated,
3246760	3251600	or in the Kahneman-Siperni and Sunstein book, by noses.
3251600	3261480	So we have read a very interesting exchange between two David's here, and the Kahneman-Siperni
3261480	3271560	and Sunstein, where David Wolpert and David Krocker point out, really, that noise has
3271560	3276920	often a function, and we should not try to eliminate that.
3276920	3285040	Your examples were mainly from not about the examples that Kahneman has in mind, but they
3285040	3298760	apply equally to the key topics of the noise book, which is sentencing, so how much, what's
3298760	3307880	the punishment for a certain crime, and also pricing annuities.
3307880	3320360	And it is not that sentencing is like Bull's Eye, where there is a right answer, and different
3320360	3325120	experts with different opinions should converge on one.
3325120	3326520	You can have many things.
3326520	3328280	You want to punish the person.
3328280	3332400	You want to be low on things and give the person a chance.
3332400	3340040	You can have many reasons, and it's also an issue where variability is a motor about
3340040	3343160	change in societies.
3343160	3354720	And so, again, both of these views assume that there is a truce that is singular, that
3354720	3362280	is known, and the biases, the difference to the truce, and also the variability on the
3362280	3369800	truce should all be canceled, and that's the key idea behind that.
3369800	3373480	And the answer, this is not the case.
3373480	3378960	We have a bias variance trade-off, and where we have not only a bias, but also variance
3378960	3382440	plus noise, it's illustrated here.
3382440	3389200	You have two darts, and on the left side, the player throws systematically too far to
3389200	3395200	the right and low, but the variance is, the variability is small.
3395200	3402240	On the right side, there is a player who has no bias.
3402240	3408000	Bias is zero, meaning that on average, the darts are in the middle, but only on average.
3408000	3418960	Variability is high, and we can see that the real idea is not to reduce bias to zero,
3419720	3428280	as the typical messages, but to find some reasonable compromise between the trembling
3428280	3430520	hand and the bias.
3430520	3439800	Juristics, if they have zero free parameter, like one over n, have a bias, like on the
3439800	3448120	left side, but no error due to variance, they always hit the same point in this image.
3448120	3452720	And that's a way to understand why simple can help.
3452720	3456920	And it's also a way to understand when simple does not help.
3456920	3463480	For instance, in that thing, if you have really large amounts of data and the world is stable,
3463480	3471200	then the simple solution will have too much bias, because the amount of data will reduce
3471200	3472200	variance.
3472280	3479680	Can you say a little bit about, in bias variance, if I just go from bias and variance or expectation
3479680	3488320	values over both your decision algorithm and also the real world, if I go one over n and
3488320	3494680	the real world is varying, I can have a very high variance, I'm not sure in what sense.
3494680	3501680	One over n gives you, it doesn't do estimations, so if your algorithm doesn't estimate anything,
3501680	3503960	you cannot make estimation errors.
3503960	3507480	But we can talk afterwards.
3507480	3508960	Okay, let's do this.
3508960	3510960	From how it's, yeah.
3510960	3511960	It's districts.
3511960	3522640	Though I'm happy to talk about that, but in this image, the variability is due to different
3522640	3527880	samples on which the same algorithm estimates its parameters.
3527880	3533080	And if you change the samples, you get different ones, in particular if the samples are small,
3533080	3535160	the variability is higher.
3535160	3538200	And that's the idea behind it.
3538200	3544760	The bias variance dilemma, and that may also behind your question, applies to situations
3544760	3550920	that are situations of risk, where we only have to estimate the probabilities.
3550920	3552400	It's assumed as stable.
3552400	3564120	In this sense, it's just an analogy to understand what's, why the heuristics, when they fail
3564120	3565880	and when they work.
3565880	3572360	Let me finish with three methodology principles.
3572360	3578440	It is very important to have algorithmic model of heuristics, not labels, not system one
3578440	3583160	and other things, that we do not know what they predict.
3583160	3588000	Second, it is very important to do competitive testing.
3588000	3595320	Like to test a heuristic model against maybe some machine learning model.
3595320	3602320	We have still parts in, for instance, economics, but it's very little competitive testing.
3603120	3608920	At best, you eliminate a factor from your regression.
3608920	3614520	But really, to test against a different class of models, really be done.
3614520	3623240	And particularly, it's important to learn whether a very highly complicated algorithm really pays.
3623240	3626440	And we often have a complexity illusion.
3626440	3630760	And think that something that is simple is nothing worse.
3630760	3639440	For instance, Harry Markowitz would have not gotten an economics Nobel Prize for one over N.
3643520	3653320	And finally, it's also important to do not only out of sample prediction as it is regularly
3653320	3659360	done in machine learning, but also out of population prediction.
3659360	3666440	So the studies that I reported that being, you know, of investment where one over N is very simple.
3666440	3674880	They are not out of sample, but they are real forecasting in the future.
3674880	3681840	And the mean variance model or the Bayesian models in, they are not,
3681840	3686720	their parameters are not done by out of sample.
3686720	3690520	Because out of sample creates a stable world, a fairly stable world.
3690520	3699040	But they are estimated in the first time interval, and then they're predicted in the next one.
3699040	3706800	And as we know from certain machine learning, techniques that prove very successful in diagnosing
3706800	3710320	may lung diseases.
3710320	3714960	When they were used in a different hospital, they failed.
3714960	3719120	And that's a problem with out of sample prediction.
3719120	3728400	And predicting, doing the prediction in a different hospital, then is out of population.
3728400	3732480	So I was talking today about three misconceptions.
3732480	3735400	Complex models are always better than simple heuristics.
3735400	3739320	They are sometimes better, but not always.
3739320	3744280	Slow thinking is always more accurate than fast, intuitive decision making.
3744280	3747520	No, particularly not by experts.
3747520	3757120	Even chess masters, when the best, so the international masters have been studied,
3757120	3765240	for instance, when they have time constraints, they do about as well as without time constraints.
3765280	3772600	If you have excellent chess players, but not at this level, then the difference gets bigger.
3772600	3778400	And finally, it is not correct that people rely on heuristics because they're biased,
3778400	3784880	lazy, or irrational, as the typical message still is.
3784880	3793960	So I invited you today to a voyage into our studies on Homo heuristicius.
3793960	3796840	And I've made three points.
3796840	3803320	Risk is not the same as uncertainty, although often the term uncertainty is used for risk.
3803320	3808600	For instance, most of behavioral economics talks about uncertainty, but it's all problems of risk.
3808600	3815440	And you detect the problem of risk immediately because the reason to know what's right in search.
3815440	3817920	And the uncertainty, you don't know that.
3817920	3826160	Second, logically rationality, the consistency axioms, the expected utility maximization
3826160	3829360	is not the same as the ecological rationality.
3829360	3840160	The ecological rationality is much harder to model, to analyze, and it's about the adaptation to the real world.
3840160	3843760	And in, under uncertainty, less can be more.
3843760	3851320	And one way to understand that is it's not an accuracy effort trade-off, but a bias variance trade-off.
3851320	3858240	And finally, human intelligence evolve to deal with situations of uncertainty.
3858240	3861080	And so did animal.
3861080	3863240	Not with risk.
3863240	3869360	And one of the reason is that we are not very good at calculating.
3869360	3871520	Let's just show a start here.
3871600	3878880	And also, some people think we need to get rid of uncertainty.
3878880	3887560	I've often heard from well-known economists, so when Reinhard Zeldin had his 80s birthday,
3887560	3893760	I gave one of the four keynotes, and another economist who, the Nobel laureate,
3893760	3902800	afterwards came to me and said, interesting talk, but I don't like uncertainty.
3902800	3911040	That's a matter of taste, but just imagine if we would know everything, if we would live in a world
3911040	3918640	where every possible situation that can occur, the consequence that everything is known,
3918640	3924000	and all is just about the probabilities, which were all the uncertainty strain.
3924000	3928440	Would that be an interesting world to live?
3928440	3934440	It would be, as Frank Knight has pointed out, would be no innovation, no profit.
3934440	3936760	And there would be no fun.
3936760	3946440	And life would be like in the movie where you wake up in the morning and everything goes back.
3946440	3953680	Or as Dostoevsky said, if everything would be rational, nothing would happen.
3953680	3955440	Thank you for your attention.
3961880	3962680	Thank you, Gerd.
3962680	3965680	We are actually at time, so who needs to go, let's go.
3965680	3969520	And otherwise, if you have any questions, maybe you can take them.
3969520	3970400	What should I do?
3970400	3972760	Take your own questions, if you like.
3972760	3974680	No, no, you take them.
3974680	3978600	OK, all right.
3978600	3980160	Good stuff.
3980160	3985000	I think there's really supposed to be a lot of that, really.
3985000	3992400	So I'm wondering, actually, so you've got your statistics and you showed, like, that you might have different ones.
3992400	4000280	And I'm thinking, in any one situation, you can apply a multitude of your statistics.
4000280	4010520	So my question is, is there any computational principle by which you decide which heuristic is allocated control of behavior?
4010520	4017040	Because they are operating in parallel or subsets of them are operating.
4017040	4021280	They may conflict in terms of the final behavior or choice that's exerted.
4021280	4028200	So is there any framework for deciding the allocation of control of which heuristic gets to control?
4028240	4030360	This is a very good question.
4030360	4034800	So there are two or three models about how to model that.
4034800	4044000	One is reinforcement learning, so that you learn a hierarchy of heuristics, like imitate or do something else.
4044000	4052720	And depending on the reinforcement and the ego, and that makes the order.
4052720	4059840	That is, there's a paper by Rieskamp and Otto on that showing that an experimental paper.
4059840	4065720	The selection problem is not really being solved here.
4065720	4071200	And you might think about a heuristic that decides about the application of heuristic.
4071200	4074240	We may just do reinforcement learning or something else.
4079240	4082200	Unfortunately, I won't be able to meet with you if I had time to meet with you.
4082200	4083920	This is what I would ask.
4083920	4092080	So in the mathematics and computer science of risk assessment in criminal justice, for instance,
4092080	4093560	there are very similar debates.
4093560	4106400	And you may know of a computer scientist named Cynthia Rudin argues that we should use simple decision trends rather than more sophisticated algorithms.
4106400	4121320	And her argument is partly because partly that more sophisticated algorithms in that domain are typically only marginally better in accuracy than the simple decision trees.
4121320	4127040	But also, as you referred to, in that you made, there's a demand for transparency.
4127040	4135280	If your government is going to put you in jail, you deserve a very simple, clear explanation of why.
4135280	4146720	And so I guess I wanted to ask you, so I think with some of the other commenters that in some sense what you're talking about is simply a different space of models that can be optimized.
4146720	4157680	I mean, with, you know, you can choose the structure of the tree with their hands and orders, whether they're, you know, the order of the questions in the banking example.
4157680	4166680	There were parameters that I assume had to be set in some way, the threshold parameters.
4166680	4186160	But so I guess my question is, when do you think that, in what domains do you think there is a strong argument for simplicity and transparency, even if something more complicated is somewhat more accurate?
4186160	4191840	And by the way, I also agree with you that that ladder plane is often made when it is not true.
4191840	4192400	Yeah.
4192400	4197120	But in the cases when it is true, sometimes we still prefer the simpler thing.
4197120	4200480	So I agree with Cynthia Rudin.
4200480	4216120	And she and us, we have shown that in sentencing or bail decisions, very simple arguments that look at three various typically like age and previous sentences.
4216960	4231880	Are about as good as complicated things or often black box, like compass and where nobody knows exactly what's in it and what's not.
4231880	4238160	And also that these are situations where transparency is another important thing.
4238160	4245800	So, for instance, in the European Union at this moment, there's a decision being made about the AI Act.
4245800	4259720	And the AI Act is in part about ask for transparency of algorithms that are so-called high-risk algorithm and sentences is one of these examples.
4259720	4269680	And the EU Union, if they don't change now things, they're voting about it, will not allow black box algorithm.
4269680	4278000	And I've worked with the German shoe farm, which is like the American feet, so credit rating.
4278000	4280720	They have immensely complex algorithms.
4280720	4287040	If you make them simple, simple arguments do as well.
4287040	4298280	And so in many of your questions, when can we expect that complex AI will work and not.
4298320	4301840	It's very similar to the distinction between risk and uncertainty.
4301840	4308760	If a situation is stable and well-defined, AI is much better than human.
4308760	4313200	So like a classical example or a chess and go.
4313200	4322680	If a situation is highly uncertain, like how can you predict whether bail decisions about whether the guy will actually come back when they.
4322680	4324280	That's very difficult.
4324280	4338840	So many factors, uncertainty in these cases, we have little evidence that say deep neural networks would do consider better than humans.
4338840	4342560	But we know that it's black box.
4342560	4351480	Right, I guess my question is, in some cases, we want, we should use the simpler thing, even if the more complicated is more accurate.
4351480	4355720	For other reasons, because maximizing accuracy is not the least that matters.
4355720	4363320	Right, and also, so for instance, in my, in our work with the shoe farm, so this is the German fecal.
4363320	4371680	It turns out that they're using variables that I'd better not telling anyone just to get a Yota male accuracy.
4371680	4376840	For instance, when you ask for your credit score, your credit score goes down.
4376840	4379560	Yes, we don't want to tell the speed, right?
4379560	4386440	So it is not acceptable, but it helps to predict.
4386440	4402120	So the compromise will be get rid of these aggressions, make them simpler, and you may lose an Yota in prediction, but there's more than just predicting accuracy.
4402120	4407880	There are human rights about transparency.
4407880	4418160	So this is very, very, I have a slightly provocative question that it sort of hints at what we are doing.
4418160	4422440	You like the logical rationality is not equal to ecological rationality.
4422440	4429880	I don't mean this just semantically, but aren't you letting people off a bit too lightly with this distinction?
4429880	4440520	I mean, surely there must be something wrong with logical rationality if it leads you to ecologically irrational decisions.
4440520	4455080	I feel that our program looks at logical rationality and asks, come on, there is something wrong with this because it doesn't, basically it doesn't work in the real world.
4455080	4459640	So are you being diplomatic by making this distinction?
4459640	4467880	Do you really mean there's something wrong with logical rationality and we should really think of rationality as a different thing?
4467880	4470440	Yes.
4470440	4476480	So logic is a system that's very useful, but not for everything.
4476480	4478640	That's the point.
4478640	4481200	You wouldn't even understand language.
4481200	4491560	When Kahneman and Tversky asked people about Linda, the bank teller, what is more probable?
4491560	4495800	The term probable does not map into mathematical probability.
4495800	4499320	It is, if you look in the OECD, it says, is there evidence?
4499320	4502000	No, there's no evidence that she's a bank teller.
4502000	4502960	Does it make sense?
4502960	4503920	No.
4503920	4510240	So to impose logical rationality on everything, that's me.
4510240	4512320	This is no good.
4512320	4515440	And it, and it mistakes the human intelligence.
4515440	4517360	We make an inference from the content.
4517360	4520520	What do these problems terms mean?
4520520	4523960	Similarly, Linda is a bank teller and a feminist.
4523960	4533480	So an end in everyday language, the end means sometimes logically ends, sometimes something different.
4533520	4538240	And we have an amazing intuitive capability to infer it.
4538240	4543600	For instance, when I say this evening, I invite friends and colleagues.
4543600	4546840	You don't think it's the intersection.
4546840	4548880	It's the logical or.
4548880	4552320	So these are the real interesting questions.
4552320	4557480	How does the human mind make this stunning inferences?
4557480	4561400	Rather than declare it's an error, it's conjunction fallacy.
4561400	4566520	Although what you're saying there is about language and not about actions.
4566520	4568480	This is about language.
4568480	4574800	So I have one example that is becoming a favorite of mine.
4574800	4580800	We can show that a, so this is totally small world logical rationality.
4580800	4589120	If you like, someone who maximizes expected utility does not maximize utility over time.
4589280	4596200	To me is a catastrophe in the logical structure that you're building a theory where you say,
4596200	4600280	well, we can't really tell you what you should do until you tell me what it is that you really want.
4600280	4601560	And that is your utility.
4601560	4603120	And then we give you a protocol.
4603120	4610800	Now I start behaving according to this protocol and I don't get the thing that I asked for.
4610800	4617520	So I don't maximize my utility over time because we're using the wrong, you know, what happens over time is not what happens in expectation.
4617520	4623680	So these to me are real problems, logical problems within logical rationality.
4623680	4627800	It's about taking the expectation of the logarithm instead as with fitness.
4627800	4630520	It depends on what you just depends on what your dynamics are.
4630520	4632040	Yeah, I mean, that's an example.
4632040	4639720	There are a number of papers by biologists who come to a similar conclusion that if animals would maximize something,
4639720	4642360	it's always, well, what do you maximize?
4642360	4644760	Then they actually lose on fitness.
4644760	4646680	Yes, sir.
4646680	4647400	Thank you again.
4647400	4648800	That was great.
4648800	4651720	You can leave it to informal discussions and.
