start	end	text
0	5240	Hello, everyone. Welcome back to your course Learning for Arts,
5240	9360	Aesthetics, and Creativity. Our specialist speaker, Tom
9360	15040	White, is here today to tell us about his exploration in art
15040	22120	and creativity in AI. He is an artist who actually creates
23080	31120	art with computers and AI, and I should let him to tell us more
31120	34600	about his background. But he has done very interesting and
34600	38680	fascinating work. And I think that he also has some new
39080	46800	galleries about what he has created his journey of arts. So
46800	51040	please, Tom, let us know what you are up to, what you're doing.
52200	55560	Sure. Thank you, Ali. I really appreciate you letting me
55560	61440	participate. I've often turned down talking invitations, but I'm
61440	65080	an MIT alum. I really appreciate, I like your research,
65080	67680	and so I appreciate your invitation. But I also really
67680	73080	like IEP. When I look back at MIT, that was like the IEP courses
73080	75840	that I took were really great. And so I can tell your students
75840	78640	that you might not remember everything you're doing at MIT,
78680	80880	but I'm pretty sure you're going to remember some of your great
80880	86680	IEP courses. So my background is fairly eclectic, as you might
86680	90680	imagine. I was undergraduate in math, and I went to the media
90680	95560	lab about 20 years ago at MIT. And I was part of a group that
95560	100440	was doing sort of incorporating graphic design into programming.
100760	105120	This was sort of exploring, exploring that space. And so
106600	108960	I'll talk a little bit in my talk about about some of the
108960	113480	precedents that we did there. But I was coming into that sort of
113520	117080	looking at ways that people could think more about coding as a
117080	123720	creative discipline. There's a lot of tools now that didn't
123720	126240	exist in, and there's even the idea of creative coding. And a
126240	132400	lot of that came out of the work that we did in our group. After
132400	136720	leaving MIT, I sort of went off into industry for many years. I
136720	141840	was always interested in AI and art and the sort of intersection
141840	144960	of those. But it was kind of the AI winner. And it was, you know,
145200	149560	I got out of school, went into industry, but when deep learning
149560	152840	started getting exciting, you know, maybe about five to 10 years
152840	156000	ago, that's when I re-vectored back into space. And so I found
156320	161760	I stuff back in academia and have a wearable hat. So I, you know,
161760	165240	I have my own research students here, and I'll speak a little bit
165280	168680	of my talk about some of the research we do. So there's like
168680	171360	Rebecca was saying, there's a lot of number of practical tools
171360	175240	you can build that will help other people use the medium
175240	178320	creatively. And I do some of that research. But as you alluded
178320	182040	to on the side, I also have my own separate arts practice. And
182160	184520	most of my talk is going to be about that. Hopefully that'll
184520	187240	be a good, I think everyone's art practice is different. But I
187240	190360	think seeing seeing that might be hopefully inspirational for
190360	193560	some students that are wondering what that's about or how they
193560	195360	might one day get into something like that.
196800	200080	Yeah, definitely. That would be actually very great. I think
200080	208520	that maybe, yeah, I think you and also work off the work that
208520	213280	Rebecca details give us some taste about what it really means
213280	218160	from the art practitioners as well as, you know, the computer
218160	220320	scientists. So please go ahead.
221320	226320	Okay, I will try to share my slides and we'll get started. Okay,
226320	230560	so I will briefly just reintroduce myself for the video. So my
230560	234200	name is Tom White. You can find me online on my handle trip
234200	238520	net. And there's my website trip.net. And as I said, I'm an
238520	242160	artist and lecturer at Victoria University of Wellington School
242480	252080	of Design. And in my work here, I teach classes on creative
252080	254200	coding. So I teach primarily in the context of an art and
254200	258720	design school to students that are interested in, it might be
258720	261200	that they're interested in special effects, or that they're
261200	264880	interested in web design, but they want to sort of incorporate
266240	268880	programming into their into their tool set, because there's a
268880	272680	lot of capabilities and things that have a lot. So in the past,
272680	275960	where someone might, you know, learn charcoal drawing or
275960	279120	search specific techniques, more and more today, students want to
279120	282040	learn programming. So I teach programming, but not computer
282040	285960	science angle, kind of creative coding angle. I also have
285960	289000	research which I do with my graduate students. And I'll touch
289000	292000	upon that briefly in the talk as well, where we make creative
292000	295840	tools using some of these, these technologies and in that
295840	302880	context, I also have a workshop at the NeurIPS conference
303440	306160	creativity and design that I do with other co-hosts, where we
306160	309400	post a lot of this research. What my talk today is about is
309400	312120	about a lot of my artwork, and specifically the artwork that I've
312120	316240	been doing the last three to five years. And I'm going to sort
316240	318720	of go through and give you a background of myself and then
318720	322800	talk about that a little bit. Let's see if I can get my first
323040	326840	slide. There we go. So, so this is the outline of the talk. I'm
326840	329960	going to give basically a three minute version of the talk, the
329960	332920	TLDR, like what's the point of this talk, so you can sort of
332960	337080	understand it all at once what this is. Then I'm going to back
337080	339680	up and give you a little bit more background about where I'm
339680	345000	coming from, my background in MIT, and since then, I'm going to
345000	347160	spend a little bit of time talking about the precedents at
347160	351880	art. So when you're doing artwork, similar to, you know, if
351920	354280	you're writing a research paper, you have your references at the
354280	357200	end, and that contextualizes and talks about how you're
357200	360040	building on things in the past, I think it's important. In
360040	362600	art, I think a lot of times it's implicit to be here, I'm
362600	365400	going to make it a little bit more explicit about what my
365400	368720	precedents are, and what I find inspirational, and what I'm
368720	374240	trying to, what I'm using as reference points. Then I'm going
374240	376360	to get into the meat of the talks. The meat of the talk is
376360	380160	really, or the core of my talk here is about AI representation
380160	384080	and abstraction, and specifically, my investigations
384080	388240	into kind of exploring what these neural net vision systems,
388400	393000	what their representations are, and how to convey that in an
393000	397240	artistic context. I will talk a little bit about other AI art
397240	401360	approaches, including, you know, other peers that I have that
401360	403960	are in this space, and I'll touch a little bit about my
403960	408400	research there. And then I'll close out by talking about the
408800	413400	sort of like some of the implications of the artwork. So
414000	419160	what is, what happens when the systems, when we're using these
419160	423880	systems more and more as our kind of auxiliary eyes? So that's
423880	427400	the outline of the talk. This is the core of it. So this is the
427760	431840	sort of the summary that my ideas of our artwork is that
431840	436000	machines have their own way of seeing. So they, they see things
436880	441600	they're very, they're very accurate in classifiers. But I
441600	445000	think they also, importantly, have slightly different ways of
445000	449080	seeing the world. And so what I'm trying to do in my artwork is
449080	454080	trying to expose that to a wider audience and trying to
454080	457600	investigate how it is that these machines see the world and how
457600	461640	it might be the same or different as us. So as a sort of a
461640	464960	corollary of that, because they see things differently, I'm, I
465000	468200	believe we can create or this kind of core and buy machines. In
468200	471400	other words, you could use the machine perception to create
471400	474400	different types of art, which actually the machines themselves
474400	480240	have some opinions about. So I'll talk a little bit more about
480240	484040	what that means. And so the summary there is that through art,
484040	487560	we can actually appreciate ways the machines can perceive the
487560	492040	world. So similar to you might encounter a new culture that you
492080	495920	hadn't before, and you might explore the art of that culture.
496080	500840	I'm trying to explore the art that's created when we introduce
500840	507760	machine perception into into the process. So I'm very, so the
507760	510600	one line version of that is I'm interested in how machines read
510600	514080	images. So that's kind of the point of what I'm doing. Here's
514080	518560	three prints that I've done the one on the left is an eye and
518560	520840	that was created from a data set of eyes and I'll talk a little
520840	525120	bit about that later. The one all the way on the right is it's
525120	527600	actually a face and that was made not so much for a class
527600	530480	environment for facial recognition system. The first step in
530480	535720	facial recognition is a detector. And so that was made to look
535720	539600	like a face to a face detection system. And the one in the
539600	542120	center here, which I'll make a little bit bigger is a screen
542120	546960	print of two chickens. And so this is all of these are based on
547000	549920	pure images. And I'll get as you can imagine more into the
549960	552880	details of how this happens as I go through the paper or go
552880	557280	through the talk. But this is based on a data set of many
557320	561960	actual images of chickens, the system created this this output.
562520	565920	And we can actually turn it around and we can show this to
565920	568560	the system again and look at its imagination of what it
568560	573120	visualizes. And we get kind of this so it can actually introduce
573120	576280	diagnostics into the process and say, Well, what is it that the
576280	579720	computer sees when they look at this print? And that is a
579720	583800	some kind of indication of the richer inner world, these neural
583800	589720	networks. So that is my, I guess, you know, three minute version
589720	592560	of the whole talk. And now we're going to sort of back up and go
592560	595560	through that and a little bit more, a little bit more detail.
596080	599360	And I'll start off talking a little bit more about myself. So
599360	603920	this is made in my studio, currently, where I do my
603920	608720	printing. And I'm here in Wellington, New Zealand, I'm
608720	611960	going to go back and talk about not everything I've done, but
611960	616080	maybe some of course, precedence along the way for getting to
616240	619000	sort of just this stage of my art making.
620600	625760	25 years ago at SIGGRAPH, I did in sort of using machine
625760	628760	learning techniques of the time artificial evolution to make
628760	633600	these real time video filters that processed video and then
633600	636440	showed that on a screen. And you could also manipulate the
636480	639200	evolution process to create different filters.
640880	646760	In 1998, I finished my master's thesis at MIT. And so, like I
646760	650520	said, I was in a group at MIT, John Midas Aesthetics and
650520	655840	Computation Group. I was there with many kind of inspired
656240	660320	people that were coming in from both design and computer
660320	664560	programming, software engineering. And I was interested
664560	667200	at the time on better human computer human interfaces. So I
667200	671880	built a custom hand interface because I was interested in
671880	674720	multi-touch. So multi-touch wasn't really a big idea in the
674720	678760	90s. So I had to, there wasn't any interfaces that did that. So I
678760	682520	built a camera optics based interface. So it's this liquid
682520	685280	pad. And when you pushed on it, you would get this handprint
685760	688160	that you see in the bottom right. And then on top of that, I
688160	692720	built various interfaces, for example, sliding left to right
692720	699640	to move, to move something, or there's various very different
699640	703480	ways you could you could interact based on having more than a
703480	705960	mouse. So I think this is common sort of ideas now, but this
705960	709280	was something that we did in the Media Lab and I did for my
709280	713280	thesis. But maybe one of the, one of the one of the other
713280	716960	things at this time, as I did another art project, which is
716960	718880	still pretty well known, which is called Stream of
718880	724400	Consciousness, which in which I incorporated this handpad, which
724400	728000	could measure sort of pressure across the whole pad into this
728160	732440	interactive exhibit where words were flowing through a stream,
732480	734880	and it was called Stream of Consciousness. One sort of
734880	738280	interesting footnote about this is that as the words were going
738280	740760	through, you could push on a word, and it would spring out
740760	744760	related words. So if you were looking at the word, you know,
745280	747920	university, and you pushed on it, it might say faculty or
747960	751960	school, or academia or something like that. And we used
751960	755520	wordnet at the time, that was part of the programming idea to
755520	759200	kind of find out interesting related words, first anonyms and
759200	762080	synonyms and kind of its sense that that it uses, which is the
762080	766400	basis for ImageNet, which is a lot of the artwork I do today. So
766400	769760	this was kind of a, again, using AI techniques at the time,
770200	775480	incorporating it in these, these interactive exhibitions. But
775480	778120	one of the, one of the interesting legacies, and I think
778120	782320	another bit that feeds into my, my current practice is that one
782320	784560	of the interesting legacies of this group is that we made a lot
784560	788520	of interesting sort of core software that enabled a lot of
788520	791120	people to do different things. So there was a handful of
791120	796320	researchers, and I, and Ben Fry, and Jared Chiffman were
796320	799200	students in the group, and we're responsible for creating and
799200	803920	maintaining this core library called ACU. And the library was
803920	808600	so that basically we could conduct our experiments. And it was
808600	813200	constructed such that it was easy to do kind of a sketch, a
813200	816440	software sketch. And the reason I bring this up is that this
816440	821600	software was the basis for other systems that have come since.
821600	826360	So Ben, who worked on this and Casey later adapted some of
826360	830520	these ideas and made a version of this called Processing, which
830560	835760	is actually quite popular still as a creative toolkit. And then
835800	839240	later, another group of students took actually the code for
839240	844200	this and made a new toolkit called Open Frameworks, which
844360	847440	uses a lot of a lot of some of the code in this ends up in Open
847440	849840	Frameworks. And then they, of course, built upon it and built
849840	857240	a community around it. But many of the conventions and cliches of
857240	863480	this programming style kind of live on today. And this is, it's
863480	865800	interesting as it alludes to my current work, because what we
865800	868160	were doing at the time, we were just trying to figure out how
868160	873080	to make it easy for people to create sketches or drawings on
873080	876240	the computer. And I feel that that's a lot of what I'm doing
876280	879600	currently is just my audience is no longer other people, it's
879600	884400	actually machine learning processes. And then I did other
884400	886960	things and worked in industry, but for the purpose of this talk,
887000	890320	we'll just, you know, chalk that off to the AI winner. And I'll
890320	893920	come back to that in a little bit. So there's, after that, I
893920	898960	graduated from school, I did some other things. I'm going to
898960	902000	also open the chat over here in case other people had feedback
902000	905280	that I can secretly see. Okay, so now I'm going to talk about
905280	911160	precedence and art and and some of the background looking at it
911160	914040	from a slightly different angle of what it is I'm trying to do.
914480	917520	I'm going to go all the way back to 1927. And there's an artist
917520	921600	called Stuart Davis that I admired his technique. And what he
921600	927240	was doing, or what he did for kind of his central core
927240	930200	inspiration for his work is that there was one year that he did
930200	932840	the egg beater series. And the egg beater series was his attempt
932840	936240	to look at the world in a new way. And the way he did that, his
936240	939120	technique for that was he took some common everyday objects, he
939120	943560	took an electric fan, a rubber glove and an egg beater. And he
944280	948000	nailed those to a tabletop and basically forced himself to paint
948000	951000	those things over and over and over until he thought he was
951000	955720	doing something different and new. His, in his own words, what
955720	958400	he said his intent was in doing this was to strip a subject
958400	962440	down to the real physical source of its stimulus. So here's one
962440	965880	of his egg beater works where he's, you know, taking these
965880	970320	common objects and trying to find something new in them. And I
970560	974200	think that that's some of the that alludes to sort of some of
974200	976600	the work that I'm doing. And I'll sort of touch on that in a
976600	982080	little bit. Another precedent for me was Harold Cohen, who, for
982080	985600	many years, experimented with generative drawing systems, and
985640	989440	is arguably the first kind of AI artist. He came at this from a
989440	991800	different angle. He is a very successful visual artist and
991800	997600	painter. And he decided in the early 70s that he wanted to go
997680	1001000	into programming into an artificial intelligence to see if he
1001000	1007320	could codify some of his ideas on, on mark making in a, in a
1007320	1012240	formal way. So here's an example of one of his programs and he
1012600	1015840	initially set out to build an autonomous program. And he called
1015840	1018520	the program Aaron and Aaron would kind of encompass all the
1018520	1025080	ideas he had about how to generate visual works. So I
1025120	1029040	visited Harold a couple of times and this is me visiting him.
1029120	1032640	And when he's working on some of his later works, and I think
1032640	1037320	it's also interesting to discuss like, even though he had these
1037320	1041680	ideas that the the artworks were being creative autonomously
1041680	1045360	initially, later in life, he was working more as a collaborator
1045360	1049320	with these systems. So he was sort of working a little bit or
1049320	1052920	finding ways where it was more of a co creation process.
1055440	1060600	But across all of his, all of his different phases, his core
1060600	1063080	question across this, and this is what I kind of share his
1063080	1066840	inspiration is, what is what he his question was, what is an
1066840	1071120	image? And the way he didn't mean that like technically what is
1071120	1073720	an image, but he meant like, what is the minimum condition
1073960	1077640	under which a set of marks on a page functions as an image or
1077640	1082920	conveys meaningful information. This is a sketch he had from one
1082960	1085720	of his papers. And I would kind of rephrase this in a machine
1085720	1090560	learning context is saying, what is it that in what is it that
1090560	1093800	images could do kind of central to representation and
1093800	1097360	extraction, like what makes simplification work? How is it
1097360	1101120	that simple drawings can be evocative and seem to stand for
1101360	1107720	something else? So I think that this is kind of a core, a core
1108360	1113360	concern of Harold's that that I also share. And then one last
1113400	1117160	kind of precedent and art that I think is important for me is
1117160	1121240	just talking a little bit about pop artists. This is not so much
1121240	1127680	as a from the, the content side, but from the form side, this
1127680	1130560	is actually, I share some techniques with many of the
1130560	1135680	pop artists like Andy Warhol, Roy Lichtenstein, and how I
1135720	1138920	execute my artwork. So for anyone that's not familiar with
1138920	1143320	screen printing, if I'm making this chicken image over here on
1143320	1146240	the right, that's actually printed, but it's printed from
1146240	1149600	two layers of ink. And so these are essentially stencils that I
1149600	1154400	have to mix inks for, and then put onto the page. So what I'm
1154400	1157400	showing on the left are the masks that generate the
1157400	1162320	stencils to give you the image on the right. So the stencils
1162320	1164840	themselves get burned, transferred onto screens. These
1164880	1168800	are physical kind of stencil, it's like a stencil, except it
1168800	1171600	can have holes on it, there's a mesh there. And then you just
1171600	1176160	sort of pour ink across the, across this, this screen, and
1176160	1179200	you smash some ink through it. And that's the kind of physical
1179200	1183520	process of, of making these, these prints. Here's a little
1183520	1185800	slideshow I have where I'm starting off with a blank canvas.
1185800	1188960	It's actually a blank, we base coated a color onto it, we put
1188960	1192920	a screen down, I put some ink on top of it, I spread the ink out
1192920	1195800	that's called the flood, then you smash the ink through and you
1195800	1198640	get a layer. And then the more colors you want, the more layers
1198640	1201240	you have to do that. So for the second color, you have to do
1201240	1204920	another screen and another layer. For the third color, it's
1204920	1210000	another screen, that's me pushing ink through that layer. And
1210000	1214280	then there's a fourth color there. Put the ink on the screen,
1214280	1217040	spread it out and push it through. So just kind of
1217080	1223400	emphasizing that there's a kind of a, a specific technique I'm
1223400	1227880	using that has, you know, precedent for getting these
1227880	1230960	are acrylic on canvas works or acrylic on paper, but it's
1231000	1233360	instead of a brush technique, it's a screen printing technique.
1235960	1238400	And here's the result of some of that. So this is kind of just
1238400	1242000	showing you what happens at the end is that I have these prints,
1242760	1246240	and the prints end up kind of, you know, in an exhibition or in
1246400	1253800	some type of art context. So that's kind of the precedence, the
1253800	1257680	art precedence. I think it's useful kind of now to talk about
1257680	1261320	more what this artwork is and what it is I'm trying to say with
1261320	1266280	this with my art pieces. So I'm going to get into the sort of
1266280	1269400	the main section here, which is the AI representation and
1269400	1272280	abstraction, like how is it I actually create these, these
1272280	1275840	works and what is it that they stand for. So just going back
1275880	1280640	to revisiting Stuart Davis. So in my mind, Stuart Davis spent a
1280640	1284640	year basically learning how to perceive and represent familiar
1284640	1288600	objects in new ways. So he, you know, imagine going in every
1288600	1291560	day and staring at these same three or four objects of
1291560	1294840	rubber glove and electric fan until finally you're seeing
1294920	1297000	there have been ways you hadn't before, and then you're trying
1297000	1301360	to put that on the page. And my kind of core question is, is
1301360	1305360	can we similarly use computer vision to introduce new ways of
1305360	1307760	perceiving or representing familiar objects? So instead of
1307760	1311920	going in kind of going to this meditative trance, can we kind
1311920	1315080	of look at things through the eyes of the computer vision
1315080	1319360	systems and see if that causes us to see familiar things in new
1319360	1324800	ways. So appropriately enough, one of my first experiments in
1324800	1328480	this was an electric fan. So this is an electric fan training
1328480	1331640	set. So this is the input into the system where you have
1332640	1335600	computer vision systems, as you probably know, you know, need
1336120	1339320	hundreds of thousands of images. So I believe in the image net
1339320	1343640	electric fan data, there is, you know, over 1000 images of an
1343640	1346520	electric fan. And this is just quickly paging through some of
1346520	1349720	those. And then what I did with that is I made a system that
1349720	1353760	optimized perceptually for creating something that looked
1353760	1358800	like an electric fan to multiple, multiple trained neural
1359040	1363000	networks. And so here I'm showing the print that I made. I'm an
1363000	1366240	electric fan, it was created using a similar technique done in
1366240	1369960	layers. And this is on the on the right side, these are in the
1369960	1373800	middle, I guess, is the graph showing what the opinions of
1373800	1378080	this print are when shown to different networks like Inception
1378080	1382480	or ResNet or VGG. And they all are very confident that they're
1382480	1386440	looking at electric fans. So this, this is using techniques
1386440	1391000	also from like adversarial examples. So that's some that
1391000	1394480	these are computer search security techniques, where you try
1394480	1397280	to essentially fool a computer into thinking it's seeing
1397280	1400600	something. But in my instance, I don't, I'm not tricking it, I'm
1400600	1404000	actually just trying to make a super stimulus or stimulus that
1404000	1407800	is most evocative of that category that it knows. And so
1407800	1412400	this is an example of me trying to see how these computer AI
1412480	1417200	algorithms receive these common objects. Here's an example of
1417240	1420440	the the drawing system, sort of in progress, as you can imagine,
1420440	1423400	it's an optimization, it starts off kind of putting lines on the
1423400	1428000	page where it thinks they're most needed. And then it's, it kind
1428000	1432160	of anneals or optimizes over that, and makes the image look
1432160	1436240	more and more like the target class that it's, it's trying to
1436240	1439840	make. And one way that I contextualize this and or talk
1439880	1444280	about this in my writing, is that for me, it kind of inverts
1444280	1447920	the computer as a tool stereotype. So for for many,
1447920	1451680	many years, we've seen the computer as kind of a way to
1451680	1455960	execute someone's vision. So use it down and use Photoshop and
1455960	1459120	you have an idea and you kind of do it, you know, use the tool
1459120	1461960	to express your idea. What I'm trying to do here is I'm kind of
1461960	1465160	inverting that and I've made it a tool that the computer vision
1465160	1470800	systems themselves can use to create their own visual outputs.
1470960	1475120	So so the I'm sort of making the tool for the perception
1475120	1481240	systems. So after I finished some of those, I did a series of
1481240	1484360	10 of these. And I'm going to talk a little bit about them to
1484360	1488000	talk about how they're made, but also what machine learning
1488000	1493280	concepts are kind of bubbling through. So this is this is a
1493280	1496600	print called binoculars, again, using the sort of same two layer
1496600	1499960	technique. This is the data set on the right. And then this is
1499960	1502960	the print on the left. One interesting thing I thought about
1502960	1506160	the way this print turned out is that it's viewing the binoculars
1506160	1509560	in three quarter view, which is kind of an interesting angle,
1509560	1512920	because you can see all of the features pretty easily from from
1513120	1515600	kind of not instead of a straight on view as much of the
1515600	1520360	data is. This is a shark specifically a hammerhead shark,
1520360	1525240	which is one of the categories of the image net. And here it's
1525360	1529200	done a very few number of strokes to kind of try to represent
1529200	1533240	that the essence of the shark outlines. In fact, we can kind
1533240	1537400	of count the strokes. I believe it's about 14 or so. So this is
1537400	1540960	a little animation which is showing the strokes one by one
1540960	1545720	just so you can see the number of primitives. So from, you know,
1545720	1547520	from a programming point of view, you might think if this is
1547520	1551880	the number of parameters in the space, but this is also kind of
1551960	1554480	defining the complexity of the image that that it's able to
1554480	1559360	produce. After the shark, I did a different one, which is iron
1559400	1562520	again, kind of an interesting view it took it to this kind of
1563560	1566680	perpendicular view, which is where you might get the most
1566800	1570720	characteristic view of the iron. The iron uses the same number
1570720	1575080	of strokes as the shark does. So one fun thing we can do is we
1575080	1577640	can actually start with the shark. And then we can move the
1577640	1582160	strokes around so that they create the iron. And I did this
1582200	1586360	in software. And then at each step, at the end steps, I show
1586360	1588640	this to the networks to see what they're thinking what what
1588640	1592440	they believe they're looking at. And on one side here, you can
1592440	1594560	see the six networks are very convinced they're looking at an
1594560	1598160	iron. And then we move the strokes around and they're
1598640	1603640	so they're looking at a hammerhead shark. I did this a
1603640	1606320	couple of years ago as a demo, there's a lot of debate in the
1606320	1608440	deep learning community how these models work. And there's a
1609960	1612320	there's a camp, or there's a group of people that actually
1612520	1617120	were proposing that deep learning was mainly triggering on
1617120	1620160	textures and didn't have any global structure information. So I
1620160	1623000	think this is a pretty compelling counter example that says,
1623000	1625800	well, no, these deep learning systems might preference
1625800	1629120	structure or texture or might use texture, but they do seem to
1629120	1633600	have some global structure information in their vision
1633600	1639560	systems. Just a couple more of these. This is a cello. Or I
1639560	1645120	should say this is the the the label cello, which as you can
1645120	1649320	imagine has not only cellos, but cellists and other things in
1649320	1653560	the photos that are the used for classification. And it's
1653560	1657560	interesting to try to not I don't have any I don't have any
1657560	1661440	special insight into the the drawing that is produced by the
1661440	1663800	system. So I don't know. People ask me what is it
1663800	1666720	representing? And I don't know specifically, but I can go into
1666720	1671280	the data and poke around and take my best guess. So to me, this
1671280	1674360	cello image looks like this, these kind of characteristic
1674360	1677800	photos in the data. So you might call this a mode of the data
1677800	1683080	or a or about 25% of the data has this general shape where you
1683080	1687120	have a cellist behind the cello playing and I'll point out a
1687120	1690760	couple of things that I think I see that resemble these training
1690800	1693760	examples. And I'll point out one thing that's very different. So
1693760	1696880	you might try to figure out in the 30 seconds that it needs me
1696880	1698960	to get there, whether you can find the thing that's different in
1698960	1701960	those. But the things that are the same as I see this like
1701960	1705560	light colored object kind of looming behind this darker one.
1707280	1711720	I see that maybe fingers curled around a fretboard, which was
1711720	1715120	kind of surprising to me. But the one thing that's very
1715120	1718760	different about the image that it drew and all the cellists that
1718760	1721120	I saw on the data set is all the cellists in the data set are
1721120	1723720	right handed. And all these that I just kind of pulled out
1723720	1727240	randomly are, but improbably the cellist it decided to draw was
1727240	1731240	left handed. And that's relevant because, you know, I'm
1731240	1733880	interested in how these computer vision systems see and they're
1733880	1736160	actually because of the way they're trained, they're blind and
1736160	1740840	left right symmetry. So because of image augmentation to offer
1740840	1744040	the data sets, they, they cannot see or they're not aware of
1744040	1748680	any features that are that are not that are that are dependent on
1748680	1751480	left right symmetries. And so it chose to kind of invert this
1751480	1753880	one and draw a left handed challenge, which I thought was
1753920	1758280	was interesting. And then there's a there's two more. So this is
1758280	1762160	one that's measuring cup, not too surprising here seeing the
1762160	1765880	other ones where it's it's drawn a measuring cup that you might
1765880	1770720	see in your kitchen. The thing that I haven't sort of so in
1770720	1773160	addition to choosing the shapes for these drawings, it's also
1773200	1775360	choosing the colors. And I thought it was really strange that
1775360	1777960	it chose this bright green color, because I've never seen a
1777960	1781480	green measuring cup. So again, I dove into the data. And I found
1781480	1785680	that the data set actually had a large number of examples where
1785680	1788920	there were green measuring cups. And I dug into this little bit
1788920	1792120	more. And it turns out that there's this collectible measuring
1792120	1794720	cup called depression glass measuring cups. This was made
1795520	1798640	around World War One. And for whatever reason, people were
1798640	1803080	putting uranium in the glass. And these were collectible. And
1803080	1805000	so there's a lot of these post donal onward people are
1805000	1807760	training them because they're collectible. And this is an
1807760	1811880	example of sampling bias. So arguably, this measuring cup is
1811880	1815640	not very commonly green. But because of the way this data is
1815640	1818080	kind of farmed off of the web, there's a lot of green ones that
1818080	1821720	end up in the training set. So to this computer vision system,
1821760	1824640	it's actually quite likely that there would be a green measuring
1824640	1828960	cup. So this is again, kind of showing how the machine learning
1829600	1833480	techniques are bubbling through it in the results. And then the
1833480	1836520	last one I'll show here is tick. So tick is one of my least
1836520	1839840	popular, at least by sales prints that I've done. No one wants
1839840	1844560	to put a tick in their in their home, I guess, on the wall. But
1844560	1848400	this one I'm pointing out because in addition to sort of the
1849080	1852440	the print itself, it actually had a really strong response
1852440	1856840	across many networks. And so I decided to quantify that. And the
1856840	1860440	gold standard on this is to take the validation set of the data
1860440	1864360	set itself. And so I took the the validation set for ImageNet
1864360	1867320	and I took a network that wasn't involved in the creation of
1867320	1871440	this. It was inception ResNet. And I scored all of the
1872400	1876560	validation examples. And they fell into two classes, basically
1876560	1879880	things that were ticks and things that weren't ticks. But the
1879880	1882440	short of it is, is that this image of a tick registers
1882440	1885680	stronger than all of the validation examples, which is
1885720	1888680	fairly surprising. Like the tick response here is kind of like I
1888680	1892360	said, a super stimulus or a stronger example of a tick to
1892360	1895040	these networks and even pictures of the tick from the
1895080	1900480	validation set. But this has precedent in art and design as
1900480	1905120	well. Scott McLeod in his series in his book, Understanding
1905120	1907240	Comics, talks about amplification through
1907240	1911040	simplification and how if you're trying to represent, say a man,
1911200	1915160	then you're maybe not well served by using a particular photo of
1915160	1918200	a particular man, because that's that doesn't well fit the
1918200	1923240	concept. It's too specific to, to one particular person. And
1923240	1926640	actually by abstracting and removing some details, you
1926640	1930800	can come up with a drawing or sketch that better represents a
1930800	1934440	man or a person or, you know, different levels of abstraction
1934440	1938840	in the in concepts. And so, arguably, I think that might be
1938840	1940960	what we're seeing here, where we're taking a real tick and
1940960	1945280	we're removing some of the some of the some features and leaving
1945280	1949400	the most salient ones. This is also just as a footnote, kind of
1949400	1953080	how symbolic abstraction and writing started. So Sumerian
1953080	1957040	writing starts if you owe someone three oxes, you write, you
1957040	1960520	know, a picture of three oxes in your play tablet and overtime
1960520	1965280	that evolves into kind of symbolic abstractions. So that was
1965280	1968480	my my series, Perception Engines, which is two prints, I'm
1968520	1971080	going to talk briefly about some other series that I've done
1971080	1974600	since then. There's one that I did after that called synthetic
1974600	1978520	abstractions. I've covered it here because as a as a warning,
1978760	1982840	this is technically not safe for work imagery. So if you are
1982840	1987120	uncomfortable looking at images that at least vision systems
1987120	1991520	say are explicit imagery, I encourage you to pause your video
1991520	1996440	or look away now. So here we go. These are these are these are
1996480	2000240	abstract prints that I made, specifically looking at not so
2000240	2003760	much systems for ImageNet, but these systems that impact us all
2003800	2006680	online. So, you know, we have Google Safe Search, and we have
2006680	2009960	these other systems that try to shield us from certain images.
2009960	2013920	And I'm wondering, like, well, are there abstract versions of
2013920	2018720	what it is that that that that seems to trigger these filters? So
2018720	2021480	as an example of one of these, I made this print Mustard Dream,
2021640	2024160	it's on mustard colored paper, and it's just black and white
2024200	2028720	ink. And when you show a print, this a picture of this print
2028720	2032640	to three division systems like Google Safe Search, it'll register
2032640	2036160	as a as adult or racy. Similarly, Amazon thinks it's
2036160	2041000	explicit nudity and Yahoo thinks it's not safe for work. So here
2041000	2044240	I am exhibiting that print. I did a series of these. There was
2044240	2048040	another one pitch stream, another one composition with red,
2048040	2050960	blue, and yellow. That's kind of an an art joke here, because
2050960	2056600	it's a riff on a well known other work, except my arrangement
2056640	2062600	of inks triggers these these algorithms, these filter
2062600	2066960	algorithms. I have done some similar canvas baked works more
2066960	2070280	recently in Spain. So these are two newer ones where I'm
2070280	2073400	actually trying to, you know, I don't know what it is. And the
2073400	2075240	other one, so people ask me, Well, what is it the computer
2075240	2078520	season? I don't know. Like I said, I don't have any kind of
2078840	2082000	knowledge. And maybe I wouldn't want to know. I'd like that we
2082000	2084520	don't have interpretable ML where we can ask the system what it
2084520	2087960	sees. Here I'm actually trying to steer the data set a little bit
2087960	2093920	more by influencing it with with influence the result by data
2093920	2096760	set. And so this is, for example, one of those I actually
2096760	2101240	called this one illustrated nude, which I'll talk a little bit
2101240	2105160	later about why I changed the title of it. But that's because
2105160	2107200	you know, when you show this to Amazon, that's what it
2107200	2110720	classifies it at. It says, you know, it thinks it's looking at
2110720	2114040	it in an illustrated nude and it's fairly high confidence. And
2114200	2116920	similarly, Google safe search again, thinks it's a racy or
2116920	2121600	adult image. So if you are searching for this, you insert
2121600	2125040	safe search, you wouldn't see it. And if you got an email, it
2125040	2128960	might go in your spam folder, for example. Okay, so I'm going to
2128960	2131600	talk, I'm just going to go a few more examples just to kind of
2131600	2135520	get a gist of how this so after that, I made sure my systems
2135520	2139480	were working kind of in the large with these online API. So
2139480	2143480	this is a data set for killer whale, a painting of the killer
2143480	2147920	whale, and then the responses from Google's online vision API.
2147920	2150640	So you can see it thinks it's a killer whale or marine mammal.
2151200	2154480	Part of the interest here is also what the ontology or the
2154480	2158960	labels for the these different systems are. Similarly, here's a
2158960	2162640	penguin. So we're looking at the data set on the left, thousands
2162680	2167480	of images of penguins, the version of a penguin that ended up
2167480	2171400	being printed. And then you can see the Google API sees this as
2171400	2174800	a penguin, or a flightless bird, or even particular types of
2174800	2180720	penguins like Emperor penguin. As I mentioned before, there's
2180720	2185040	the ability to do custom data sets. And so as a commission
2185360	2189000	collaboration I did with yacht for their album artwork, I did a
2189000	2192480	series of custom data sets. This is one from from that series.
2192680	2195840	Where we had a data set of eyes, and we trained the system to
2195840	2202040	make a synthetic eye. And as you can see, when Google looks at
2202040	2204920	this, it thinks it's seeing a face, or a nose, or eyebrow, or
2204920	2207920	eyelash, there's sort of eye features coming through in the
2207920	2211880	labels. And then, and this is another one I did, similarly,
2211880	2217800	where it's pictures of rabbits. So it's this one is a various
2217800	2221280	kind of simple rendition of a rabbit. And again, it's kind of
2221320	2224760	funny what the Google labels for this end up being evidently
2224760	2228600	they have separate labels for hair, rabbit, rabbit and hairs
2228600	2231520	and domestic rabbit, it kind of triggers all of those different
2231520	2237920	labels in its API response. More recently, and this is kind of
2237960	2240360	getting up to what I've been doing the last year, I've been
2240400	2244360	exhibiting these in groups. I found that instead of showing
2244360	2249520	one example, it actually is more enlightening to see many of
2249560	2251680	these at once, because you can kind of get a feel for what the
2251680	2254680	visual language or the common elements are. So these are six
2254680	2259240	chickens and six eyes, which I exhibited about this time last
2259280	2264080	year at Separ Gallery. This is something I did subsequently,
2264080	2266600	where I took that kind of even a step further, and there's kind of
2266600	2270160	this room full of images, the computer thinks are knots. And
2270160	2276280	so we have different shape and color combinations, all all
2276320	2281240	being different images that the computer thinks are reminding
2281240	2283320	it of and I think knots is kind of an interesting one, because
2283320	2286240	it's kind of this amorphous shape, but there seems to be some
2286240	2290000	commonality visually to what what the computer thinks is a
2290000	2293920	knot. And then this is one I have this in progress. Maybe I'll
2293920	2297240	give you about 10 seconds to think about what these might be.
2297680	2300480	But these are actually this looks like it might be computer
2301320	2303840	images, but these are actually photos of canvases, which I've
2303840	2307320	taken where I'm starting to organize these into groups. And
2307320	2310000	these are all the canvases that are just given completed. And
2310000	2314800	this is for an upcoming exhibition on ants. And so all of
2314800	2318880	these are shapes that will will trigger in computer vision
2318880	2322720	systems, to different extents, in thinking that it's looking at
2322760	2327640	at an ant. So that's kind of a summary of my work. I'm going to
2327640	2330480	spend the remainder of my talk talking about other approaches
2330480	2337920	and a little bit about and a little bit about my research,
2337920	2341360	and then I'll just briefly talk about how my my artwork impacts
2341360	2344920	the real world, or effects it has once it gets out into the
2344920	2348840	world. So as a lot of the other speakers have mentioned is these
2348840	2351520	generative techniques, and I think these are very relevant, and
2351520	2355280	they're used on other approaches, but there's also this idea that
2355720	2359040	other AI art approaches had different narratives. So I want
2359080	2363120	to talk a little bit about that. So my interest, so when I came
2363120	2366200	into when I started getting interested in modern deep learning
2366200	2369200	actually got into generative networks as well. And for a
2369200	2372200	while, I was doing a lot of important research on this or
2372200	2375520	research that I enjoyed digging into how these things works in
2375520	2380520	2015 and 2016. This is an artwork I did in 2016. It was just
2380520	2384360	large, like two meter by one meter print. Here's a zoom in
2384560	2388160	showing this. And this was images of faces. So at the time,
2388160	2393080	these were really high quality neural net outputs for faces,
2393120	2395680	you know, before we had style again, and these other more
2395680	2399280	modern networks. And I was interested in kind of the space
2399320	2405000	of faces that could be created. And I, and I wrote a paper talking
2405000	2407520	about some of these techniques and how you could sample these
2407520	2412680	networks to get some of the best, the best outputs from those. I
2412680	2416080	also, since subsequent to that have continued looking at these
2416080	2418480	generative networks in more of a research sense. So in my
2418480	2421960	research capacity at the university, I work, I work, for
2421960	2425520	example, in this system with my graduate student, as Rebecca
2425520	2430920	alluded to, it's, there's a interesting kind of getting these
2430920	2434240	out to tools to other creators. And so one of the ideas I have
2434240	2436840	with this graduate student was to make a spreadsheet tool where
2436840	2438720	instead of numbers in a spreadsheet, you actually had
2438720	2442480	samples from a generative model. And could you do use this as a
2442480	2447480	way of giving people sort of their own create creativity tool
2447520	2451120	through the interface of a spreadsheet. So it's looking at
2451120	2453960	at some of these generative models. But in the context of
2453960	2457480	this art talk, it's, it's, I mainly just wanted to say, this
2457480	2461160	is a tool other people are using. So Helena Saren is using
2461160	2464400	these Mario Klingerman, Helena is using these in a way that,
2464720	2467800	again, Rebecca alluded to where she's using these small data
2467800	2470760	sets and essentially overfitting those data sets and changing the
2470760	2474880	data set to get the result that she's looking for. Mario
2474880	2478840	Klingerman in this project, Neural Glitch, was training one of
2478840	2482000	these, and then he intentionally kind of damages the network, and
2482000	2486640	then displays how that damage comes through visually in his
2486640	2489760	artwork. So it's the idea that there's a sort of an intentional
2489760	2493760	glitch in there. There's two other artists that that all
2493760	2498720	mentioned that that one is Robbie Barrett, who did this
2498720	2502680	project a few years ago called RDCGAN, where he looked at using
2503280	2506840	these, these generic networks to specifically create portraits.
2507120	2510240	And there's another well known, at least in a art precedent,
2510240	2512840	which is obvious is Edmond de Bellamy, that's well known,
2512840	2515160	mainly because it went up for auction for a very high amount
2515160	2519760	of money, a Sotheby's a couple of years ago. These actually, I'm
2519880	2522880	putting up mainly because they use very, very similar techniques.
2522880	2525960	In fact, they share some code and techniques across them, but
2525960	2528080	they have very different narratives behind them. And so I
2528320	2531360	wanted to kind of point out, and the narrative here is I mean,
2531360	2534640	like what the story is behind how these are made. So when Robbie
2534640	2538080	is, is, and when I'm, you know, showing my work, it's very much
2538240	2541120	talking about using these things as a tool or as a collaboration.
2541400	2545200	But there is a strong push or there's a lot of people in the
2545200	2548520	art community that more say that, no, it's the, the computer is
2548520	2551080	autonomous and it's making these artworks. And that was the
2551400	2554560	kind of stance that obvious took. And it's one that resonates
2554600	2558160	with people. I think taken to an extreme, what you get is you
2558160	2563920	get a lot of people making work with robots. So it's common for
2563920	2566320	people to make these robot artists. And here's just one
2566320	2571680	example of that. But these have a long history. So there's
2571680	2575680	actually a long history of making these drawing automatons. And
2575680	2580680	here's one, you know, that's 200 years old, where it's basically
2581680	2585640	being driven by gears. And so I just mentioned this is that I
2585640	2588360	see this as a slippery slope. And so I said, kind of stay away
2588360	2592200	from this and intentionally don't use any, at least for now,
2592440	2595600	kind of drawing automaton, because I want to contextualize
2595600	2599360	what I'm doing as a, as a collaboration between what I'm
2599360	2602800	doing. So going back kind of again to, to Harold Cohen and
2602800	2607800	his work, and most of the artists in the space. This is a what
2608240	2611320	I'm what I'm doing is not so much me handing over full autonomy
2611320	2613880	and saying the computer is the artist, but coming up with a
2613880	2617880	co creation process where the there's a role for me and
2617880	2622840	there's a role for these systems that I'm making. Okay, and in
2622840	2626480	the last five minutes here, I'm going to spend, I'm going to
2626480	2628760	talk a little bit about what happens when we put these things
2628760	2632400	out in the wild, and how how these are some of my artwork, how
2632400	2635520	it's kind of how we can understand it. So of course,
2635600	2638560	there's, we can ask the machine what it sees, we can use
2638560	2641120	visualization techniques, but the one I'm highlighting most
2641120	2644080	here is these unintended consequences, like what, what
2644080	2648160	surprises has happened. And keep in mind that for from the eyes
2648160	2651360	of the computer perception system, this is Magritte's
2651520	2654120	trajectory of images where he was kind of pointing out like a
2654120	2657280	picture of a pipe is not a pipe. But that distinction often is
2657280	2660600	lost with these perception systems, like if they see
2660600	2663880	something in a representation of something, they more or less
2663920	2668440	think it's that thing. So the first way you can tell or
2668440	2670840	interpret or think about my artwork is you can ask a system
2670840	2674280	what it sees. So if I take this picture I took of me with my
2674320	2678440	artwork six chickens, and I feed it to the Amazon API, it will
2678440	2681280	come back and so very diligently that it found a
2681280	2684640	chicken and a chicken and a bird and etc. And there's a person
2684640	2686960	over on the side. And I think that's one way to kind of
2686960	2692480	understand how these systems are viewing or understanding these
2692480	2696080	artworks. So the computer, the systems themselves. There was
2696080	2698280	another way that I talked about in the beginning where you can
2698280	2701640	actually use visualization techniques. So this is using some
2701640	2704480	research from open AI where they have visualization techniques
2704480	2708320	similar to deep dream, where they take, I can take one of my
2708320	2710920	prints and feed it to one of these systems and ask it to kind
2710920	2716120	of imagine how it relates. So here's the print to chickens.
2716440	2720360	Here's kind of the, the inner imagination or visualization of
2720360	2723280	what the computer sees when it sees that. And you can even take
2723280	2726400	that a little bit further and try to visualize that in 3D. So
2726400	2729240	this is a little slideshow where it attempts to add some fake
2729280	2735960	depth to that to that image so that it can kind of understand
2736120	2739400	understand it. But I think what's most interesting is how
2739400	2742440	these things kind of accidentally kind of bump into real world
2742440	2746000	systems. So I'm going to talk about a couple of those to close
2746000	2749840	out. So this is an exhibition I talked about in 2018. I had
2749840	2754360	these prints that were supposed to trigger various safe search
2754360	2756480	filters. And this is an exhibition on the left. I have this
2756520	2759920	not so great photo of it with a lot of glare and stuff. And I
2759920	2761760	actually took a picture of this and was going to post it to
2761760	2765360	Tumblr. And it didn't allow me to post it to Tumblr. The actual
2765360	2768440	post failed and it said this post contains adult content, which
2768440	2771440	violates our community guidelines. I was flagged as adult
2771440	2774160	content and it was not displayed. So I think that's one
2774160	2777400	example of it kind of bumping up against these real world
2777400	2781360	systems. Similarly, I had another work in that series,
2781400	2783760	Architectural Digest wanted to put a print in one of their
2783760	2787720	magazines. I showed them some prints and they wanted the most
2787720	2791920	colorful one, which was Lime Dream. Again, maybe not the most
2791920	2794600	appropriate because it's supposed to be explicit imagery, but
2794600	2798440	it they decided to go with it anyway. And so when I got a copy
2798440	2803640	of the magazine, I took a great picture of the magazine, and I
2803640	2806520	fit into the Amazon API and it was still convinced it was
2806520	2809600	looking at explicit nudity. So I think this might be the first
2809600	2814600	example of a cybernetic centerfold like a basically a photo of
2814600	2819760	a nude made for these kind of vision systems that has appeared
2819760	2824680	in a magazine. Similarly, like the art gets sold in weird ways.
2824680	2830080	And so I had a print at a gallery and they sold off without my
2830080	2833960	knowledge, one of these prints to Sloan Kettering when so if you
2833960	2836480	go to their academic offices in New York, you can actually see
2836480	2841400	one of these prints. Again, I don't know that I would that it
2841400	2843760	might be the most appropriate for this environment. And in
2843760	2846400	fact, that's one of the reasons I alluded to earlier, I gave
2846400	2850360	these initially kind of these vague names. But now I've called
2850360	2853240	them illustrated nudes explicitly because I want if
2853240	2856000	someone buys or sees one of these, I want them to know what
2856000	2857920	it's supposed to represent. And so the only way for me to
2857920	2861480	package that is to put it in the title where it can't be missed.
2862480	2868360	I did a print a couple of years ago that I took to NeurIPS. I
2868360	2872440	was stretching it in my hotel room and hanging it up. And when I
2872440	2875320	went to take a picture of it, I was very happy. This is my
2875320	2880200	camera interface. When this little yellow rectangle appeared.
2880200	2883040	So I think if anyone has a phone, they know this is when your
2883040	2886200	camera's trying to focus on a face. And so just the fact that
2886200	2889960	this was a shape intended to trigger a face and machine
2890000	2893720	learning algorithms, kind of pulled the focus onto onto this
2893720	2897520	because it thought there was a face in the scene. And then the
2897520	2899880	last one of these is just getting ready for this talk. So as
2899880	2902520	you can imagine, getting ready for this talk, I'm trying to find
2902520	2905560	images of my artwork. And I'm pulling them on my phone. And
2905560	2908800	lo and behold, when I pull up my phone, down at the bottom, it
2908800	2912440	says we have several people and places in categories of things.
2912680	2915280	And here's the categories of things that I've kind of
2916240	2918400	partitioned for you that you might be interested in, like
2918440	2921040	your animals and your food. So of course, these aren't real
2921040	2924880	animals and food. If I search for banana, it thinks it's you
2924880	2927680	know, I've done a print of banana and when I'm working in
2927680	2929480	the print, I take a lot of pictures of it. So these have
2929480	2934080	gotten classified as bananas or scorpions. This is a sombrero
2934080	2936320	print. I was working on it. It's funny too, because it kind of
2936320	2939400	mixes the real this is a picture of mine, a friend in a funny
2939400	2942960	hat, and it ends up putting that in the picture with the artwork.
2943240	2945760	Again, like I'm saying, the computer doesn't have a concept
2945760	2948760	of what a lot of times is a representation of something
2948760	2952720	versus what is the real thing. So if I do a search for syringe,
2953000	2955440	not only do I get this weird photo that I took and I don't
2955440	2958880	remember why I have a real syringe, but it probably I get
2958880	2962200	this like really wacky, hypercolour syringe print that I
2962200	2964680	was working on a few years ago. So I think it's interesting how
2964680	2969640	these kind of get collapsed in the in these vision systems as
2969640	2974440	being kind of the same thing. So that's it. Those just to
2974440	2977160	recap the core ideas of my artwork is that the machines have
2977160	2982240	their own way of seeing. We can create art for and by machines,
2982600	2985760	which is what I'm trying to do is trying to use the the
2986080	2988720	capabilities of machines and understand art through their
2988720	2994720	eyes. And that and through art, we and by we, I mean, like,
2995920	2998360	people knowledgeable about deep learning, but also people who
2998360	3001240	might not have any background in machine learning can appreciate
3001240	3005640	the ways that that machines perceive the world. So thanks,
3005640	3010400	that's my online handle for Twitter and my web page. I'm
3010440	3013120	open for taking questions that I will also say for questions that
3013120	3016560	I'm very open for things that were part of the talk, but also
3016560	3019200	might have been things only loosely alluded to in the talk,
3019200	3023880	if you had questions on, you know, more about research tools or
3023920	3028160	the community, I think that I'm happy to take any sort of a
3028160	3030280	broad range of questions. Thank you.
3031480	3038360	Thank you so much, Tom. It was so great. So I was wondering if
3038360	3040000	students have questions.
3042760	3046840	This is from very early on in the talk, but I'm wondering why you
3046840	3050880	chose screen printing as your medium of choice.
3056120	3058920	Great question. Sorry, I had to take a second.
3059040	3063120	So, yeah, so there's I wanted to actually make physical work. And
3063120	3065800	I thought that was, you know, it's actually easier for me to make
3067120	3070800	work that is on the computer, but it takes a kind of a step
3070800	3075040	further to create something that's printed. And that's also
3076320	3078120	something there's two parts of the question, why make physical
3078120	3081120	work at all? And then if you're making physical work, why have
3081120	3084240	it be screen printed? So I think that that two reasons for
3084240	3087040	making physical work. One is, I think that there's a lot of
3087080	3089280	reasons for making physical work. One is, I think that people
3089280	3092800	relate to physical work differently and when they go into
3092800	3095680	a gallery and art setting. So for years, I did these interactive
3095680	3098600	installations with screens and things. And I think that people
3098600	3102800	come into those little bit of the defensive because sort of
3102800	3104920	this technology right away, like you go in and you see the
3104920	3108040	screen, you see, you know, this camera looking at you or
3108040	3111800	something. And I think it sets a tone for how this is for what's
3111800	3117000	to be expected. And so I really wanted to do a physical print
3117360	3126480	that sort of was more more about the was more about how the
3126480	3129720	computer sees it than about the short putting the process in
3129720	3131840	the gallery. But the purpose for doing the screen printers, I
3131840	3135240	wanted something that was very exact. So I could I actually have
3135240	3137080	done some prints that there weren't part of the software I've
3137080	3140160	experimented with other techniques, brush techniques. And
3140160	3142360	so it's not really critical to use screen printing, but screen
3142400	3148960	printing allows me to with some level of very precision, like
3149720	3154440	make a traditional artwork. So and it has precedent kind of in
3154440	3157480	the art world through through these pop artists. So I felt it
3157480	3160480	was kind of a good, a good middle ground for kind of
3160480	3163040	executing these I could of course print them out on a printer
3163040	3166400	or something else. But I think that I wanted to kind of
3166400	3168720	constrain my way, you might think in the same ways that
3168720	3171600	artists in the past, it could strain themselves. So it makes
3171640	3175640	it more easy to compare my works with existing artists, if I'm
3175640	3178840	kind of operating with the same constraints are under the same
3178840	3181880	interface, you might think of it. One thing I'll say too about
3181880	3184920	making physical work is it makes it much more difficult to
3184920	3188760	pull off these techniques, these kind of adversarial techniques
3188760	3191360	because I don't know what the lighting or the angle of the
3191360	3195880	photo is. So I try I have to make these these results work for
3195880	3201320	a distribution of possible photos that might be taken. So if
3201360	3203760	that's a part of you know, if you look at adversarial images
3203760	3206440	research, there's kind of doing it on the computer and there's
3206440	3208720	doing it in the physical world. And it's always kind of more
3208720	3211320	difficult challenge to take these to the physical world. But
3211320	3213720	that's kind of where I was interested in taking this.
3218560	3220080	Cool. Thank you so much.
3220080	3236600	Excellent. Are there are there other questions? I think that
3236600	3240800	this is very interesting how thinking in art and you know,
3240800	3248440	having this dual view of computers and arts can inspire
3249000	3253120	such an interesting work. For instance, we see that, you know,
3253120	3255720	as you said, one of the applications of this could be
3255720	3260560	really adversarial attack and, you know, cyber security, which
3261240	3266800	is really hard to think about it. If you only want to think about
3267240	3273960	security and exclude this type of artistic practices, I never
3273960	3281840	thought about it in this way, like how art can help for better
3281840	3285720	understanding of, for instance, data bias or algorithmic
3285720	3292120	bias, or other aspects of AI. So I thought that was very
3292120	3292840	interesting.
3294320	3297440	Thanks a lot. Yeah, that actually came through in my in my
3297440	3299440	original generative work. So when I was working with
3299440	3301960	generative networks, I found that they were actually really
3302000	3306360	good at visualizing bias. So if you go back in my paper, I
3306360	3311080	talked a little bit about how the celeb a data set has a label
3311080	3316560	for for smiling. But in that data set, and I talk about ways that
3316560	3320040	you can build dialers where you can turn up the smiling and
3320040	3323240	down the smiling by using the labels on the data set. But
3323240	3325680	there's bias in the data set where women are much more
3325680	3330000	likely than men to be smiling. Just as a product of how the
3330000	3332360	data was collected, like twice, almost twice as likely as
3332360	3335240	like 1.5 or something like that. And so as you build these
3335240	3339280	tools that are that are intended, or as you look at as you
3339280	3341880	tell the network that you want to make an image smile more,
3341880	3344320	you're actually also changing some of the masculine feminine
3344320	3348080	characteristics of the image. And I thought it was a very
3348080	3351280	visceral way to kind of see some of the machine learning bias.
3352120	3354200	So that can come through in these general networks. But
3354200	3358240	yeah, I think it also comes through in the visualization of
3358240	3363080	these. And I'm kind of careful not to to couch my work too much
3363080	3365400	in adversarial examples, because I think that I certainly use
3365400	3368560	some of their techniques. But where I depart from them is that
3368560	3371320	is they're always trying to do something imperceptible, or
3371320	3375040	something that is, well, it's adversarial, like in the name,
3375040	3377600	they're trying to trick the system, whereas I'm more using
3377600	3381040	it as a visualization or kind of getting under the hood and
3381040	3385320	kind of understanding what the stimulus is are that that might
3385320	3387360	trigger the these in the first place.
3388560	3393560	Yeah, also, it is very interesting how you know, doing by
3393560	3399760	minimal strokes, you could achieve these things. And this is
3399760	3403120	another way of thinking of compression, for instance, which
3403120	3406000	was, as you said, inspired from art.
3409160	3411120	Yeah, I know that's that's a really good point. Yeah. And I
3411120	3413920	think that so there's there's a very practical reason to do that
3413960	3418640	too is because I'm not using any really advanced techniques for
3418640	3422840	generating these. I'm basically doing like random search or
3423080	3426200	genetic algorithm. So it's basically doing a search over
3426200	3428920	the space of outputs, and it just move, you know, it does a
3428920	3433200	search estimating the gradient. So the fewer parameters you have
3433200	3437120	the easier job you're going to have sort of hill climbing in
3437120	3440880	that aspect. So it benefits me to have a simple representation
3440880	3443320	for this. And there's other things about my drawing style
3443360	3446440	when I talk about making a dry system for for these, like I
3446440	3448560	can't have too many discontinuities and things like
3448560	3451960	that. And the drawing styles that have but but yeah, I think
3451960	3455080	it's also very interesting to come up with these kind of tight
3455400	3458440	like for the shark, you know, it's 12 strokes to kind of
3458440	3464000	represent a shape that when shown to the system still seems to
3464000	3466840	be a strong stimulus for that category.
3467960	3472680	Yeah, that also reminds me of the work that scientists did in
3472760	3476560	computer vision, for instance, a work of Antonio Trouble, where
3476920	3481000	the question is how many pixels do you need the minimum number
3481000	3486920	of pixels to show to a computer, for instance, and in terms of
3486920	3492440	images to see what is this object or get a gist of this
3492440	3496880	object, you know, for instance, the experiment that set up only
3497520	3503800	between 32 picture pixels. And they found that, you know, you
3503800	3509560	can get a gist of what is going on in this instance, image is
3509600	3513960	this computer vision techniques. So that is also very
3513960	3514720	interesting.
3515520	3518280	Yeah, it's also similar to I don't remember the researchers
3518280	3521360	that did the psychology research where they take face images
3521360	3524320	and they put them in very low like they basically make icons
3524320	3527520	where they're, you know, like eight by eight pixels or 16 by
3527520	3530840	16 pixels. And you can still represent you can still recognize
3530840	3533920	Abraham Lincoln or these famous figures in these very low
3533920	3538200	resolution, resolution format. So I think people also have
3538200	3542360	this ability to decipher these very, these very low
3542360	3544840	information images as well.
3545880	3551760	Yeah, very interesting. Excellent. Thank you so much, Tom. It
3551760	3558600	was great and really inspiring work. And I appreciate that.
3559440	3561680	Thanks so much for having me. And if anyone else has any
3561920	3565520	questions, I'm happy to, you know, if you send me an email and
3565560	3567840	follow up from the class, I know not everyone likes asking
3567840	3572320	questions. I'm happy to follow up on, you know, you know, every
3572320	3574520	artist is a little bit different. And so there's no
3574520	3578280	common. There's no common template, I think you can follow.
3578280	3581800	But hopefully this will be a good, this is one good example
3581800	3584160	of a path that someone else might be interested in taking.
3584960	3590160	Certainly. And then also, Tom has been involved with the
3590160	3596240	workshop of machine learning for art and creativity at New
3596240	3602520	Ribs for several years. So that's also an interesting and
3602520	3607520	valuable contribution that he's making. So if any questions
3609160	3611760	Yeah, exactly. So I do know a lot of that research and can
3611760	3614280	direct you to those. And I would encourage you, if you are
3614280	3617080	interested in a space, you can, I believe, still access a lot of
3617080	3620080	the videos, for example, from this past year's workshop, just
3620080	3623320	to get an overview of going a little bit deeper into some of
3623320	3623960	these talks.
3625640	3629400	Excellent. Thank you so much, Tom. Thank you. Thank you.
3629400	3631440	Have a good one. Thanks, everybody.
