start	end	text
0	6760	Hello, everyone. Welcome to your course, Deep Learning for Art, Statistics and Creativity.
6760	13140	Today, we have two special speakers. First, we serve as Dr. Jeff Klun, who is an associate
13140	20440	professor in computer science at the University of British Columbia and also a research team
20440	28640	leader at OpenAI. And he's going to talk about towards creating endlessly creative,
28640	35400	open-ended innovation engines. I think this is a very exciting direction because so far
35400	43000	we have talked about the interaction between art and AI. We said that how AI can help us
43000	50120	to create and express ourselves and democratize the creativity in a sense. But also, the other
50120	62240	direction is how our creativity can help us create better AI. For instance, how we learn
62240	71840	by creating, how we define problems and find solutions for them and generalize to solve bigger
71840	80640	problems and so on and so forth. So today is one of those, I would say, a realization of such a
80640	90480	great idea that you will see as a gist of what Jeff has been working on. So please go ahead.
90480	97840	And also, another question that we often ask in the class is that students are interested to know
97840	105360	a little more about your background because they always feel inspired by seeing great scientists
105360	113040	and what, for instance, got you to working on AI would be very interesting for them if you don't
113040	121480	mind sharing. Great. Thank you for the introduction. Let me share my screen here and make sure that
121760	140320	is working. So are you able to see my screen? Yeah. And the presentation? Yes. Okay. And can you see my
140320	148960	mouse cursor? Yes. Okay. Hello, everyone. My name is Jeff Klune. And I want to talk to you today
148960	155320	about trying to take on like an extremely big research challenge. I think it's a grand challenge
155320	163360	of AI. And that is trying to create what we call open-ended algorithms. I wasn't planning on telling
163360	167320	you a little bit about my background. I guess in brief, I started out on a quest just to understand
167320	173760	two twin questions, which is how did natural evolution produce all the complexity on Earth,
173760	179480	including the human brain? It's astounding. And we don't know how that process happened really. We
179480	184000	don't know how to recreate it. And you'll see a lot of work towards that today. And then also, I'm
184000	188360	interested in trying to figure out how does thinking happen and how can we create it in machines? And
188360	193560	I think in many ways, these questions are very intertwined, as you'll see also today. So I started
193560	198080	out in philosophy, actually, because I thought they had the market cornered on thinking, but really
198080	202520	quickly kind of, or actually not quickly, slowly learned throughout the course of my life that the
202560	207000	best way to tackle these challenges is to try to build these systems and recreate these systems
207000	212000	computationally. Motivated by the wonderful quote by Richard Feynman, which is, that which I cannot
212000	217480	build, I do not understand. So we understand by building. And that has certainly been true in my
217480	223600	life that I understand more and more by being forced to turn speculation into code and into
223600	231400	algorithms. So with that, I'm going to begin. So this talk is really going to be in two parts.
232360	236920	The main part is going to be the first part. And it's about creating open-ended innovation engines.
237560	242200	And if there's time, which I hope there will be, I'm going to rush through a series of work that
242200	246840	we've done that I call AI neuroscience at the end. And then throughout all of this, what you're
246840	251720	going to find is that this is a bit of a meandering intellectual story, because throughout my career,
251720	258040	different research has kind of unintentionally produced different aesthetic artifacts of interest.
258040	262360	And I kind of want to walk through some of the things and touch as many of these places where I
262360	266440	think our work has produced things that are aesthetically interesting, as well as scientifically
266440	277080	interesting. So the first thing I want to motivate is, you know, the idea of open-ended algorithms.
277080	282200	So these are things that endlessly innovate. They just keep going forever. So if you think
282200	287320	about natural evolution, look at the Tree of Life there, and think about all of the marvelous
287320	293560	engineering designs that nature has brought and continues to create in an ever-going fashion,
293560	298920	you know, jaguars, hawks, the human mind, everything that we know on Earth. You know,
298920	304520	in most situations, we cannot rival these things with engineering. And so what's fascinating is
304520	309400	that, you know, a very simple algorithm that Darwinian evolutionary algorithm, plus the context
309400	313880	it's been placed in, continues to innovate for billions and billions of years. And I think it's
313880	318440	really fruitful to think to yourself, you know, could you create an algorithm that you would want
318440	323480	to run for billions and billions of years and come back and check whether or not it's interesting?
323480	328680	Currently, as scientists, we have zero ability to produce things that are interesting even after
328680	334200	a few months of running them on a computer, let alone billions and billions of years. So natural
334200	337560	evolution is what we, you know, one of these open-ended algorithms. And another one is human
337560	342760	culture, which just endlessly innovates and produce innovation on innovation and innovation. That's
342760	346680	both true in science and technology, but it's also true in the arts, where you get, you know,
346680	351400	impressionism after you get the classical paintings, and then you get, you know, post-modernism or
351400	357320	Jackson Pollock or all the different kind of evolution of genres. So, you know, we started
357320	363640	with the idea, when we try and wanted to try to work on this, is that natural evolution and human
363640	368440	culture are what we call innovation engines. And that is that there's kind of this simple recipe
368440	375000	that they follow that allows them to be creative. And that is that they start with a set of things,
375000	379720	it could be an empty set, and then they generate a new thing. And then if that's interesting,
379720	383720	they keep it and add it to the set. And then they take something out of that set, they change it a
383720	388120	little bit, they permute it somehow, and they see if that is interesting. And if that's interesting,
388120	392760	they add that to the set. And you have this growing set of things, these archives of things
392760	397880	you've already produced that are interesting. And then each one of those is a stepping stone to new
397880	402600	potential innovations or solutions. And if you think deeply about it, that's true both of human
402600	407400	culture and natural evolution. And so the question is, with that kind of mental framework, can we
407400	414120	create algorithms that do that process automatically? And so, you know, at the core, there's really kind
414120	418360	of these two simple steps. The first one is you have to have something that generates new things
418360	423480	based on previous things. That's the green box on the left. And then you have to evaluate whether
423480	427400	not those things are interesting. And if they are, then you add them to the set and you just keep
427400	433480	repeating this process. So in the long run, what we'd love to do is take, you know, humans out of
433480	438200	the loop if possible, label data out of the loop, and you just have some sort of generator like a
438200	444040	neural network that can generate new things like poems or codes or mathematical proofs or images,
444760	449160	or, you know, technological artifacts, something, maybe another deep neural net that is trained
449160	454360	to recognize what's interesting somehow, and then that process could just iterate. Now, for example,
454440	459480	you could imagine that you take like the orange box here is an autoencoder. And it looks at everything
459480	463560	that it's seen before, it compresses them down to a low dimensional bottleneck space, and then it has
463560	467880	to uncompress them. And then if you get some new latent vector that's new that you've never seen
467880	471800	before, you call that interesting. And that might be one thing that could kick off this problem.
472360	476840	And if you could do that, you would have an innovations arms race in any domain, you could
476840	481000	unleash this thing anywhere. And that would be amazing. And a lot of these ideas date back to
481000	487320	Schmidt-Huber ideas from the early 90s. However, the problem is that when you do that, you typically
487320	492040	do get new things forever, but you don't get new interesting things forever. You, for example,
492040	495880	might get white noise, just an endless stream of different patterns of white noise, because those
495880	500760	are uncompressible. So really, at its core, the biggest challenge in this field is kind of how
500760	505800	do you avoid generating uninteresting novelty, and how do you only generate interesting novelty?
506600	511400	And here's one example by a friend of mine, Josh Auerbach, who tried to basically take the same
511400	515160	encoding that I'm going to tell you about later, and a similar system is trying to automatically
515160	520280	generate images and try to produce new interesting images forever. And these images are interesting,
520280	524120	they're pretty cool, but they're not nearly as interesting as they could be, right? They're not
524120	529000	like what artists would do over the course of centuries. You would expect and hope that things
529000	532440	would ultimately break out of these kind of abstract patterns. And that's because these
532440	539240	things are optimized to produce information theoretic metrics like compression or mutual
539240	545720	information and things like that. So what we thought in this work is that one insight you could
545720	551160	have is that recognizing a new type of thing is like being able to recognize a new class of thing.
551160	555960	If you've never seen a palm tree before, that's a distinct kind of trees. And if you've never
555960	561480	seen a tree before, trees are distinct from dogs and roses and statues. And so
562200	568440	one way to think about being able to recognize an infinite number of new classes is to approximate
568440	574760	that by having a neural net just recognize a very large number of classes. And so if you could
574760	580200	recognize, you know, a million classes, for example, then as the generator produces new
580200	584280	instances of those classes, maybe the process could like start going out and generating each of
584280	589640	these classes. And that allows us to then use supervised learning because we know how to recognize
589640	596440	new classes of things. So this is an approximation to the overall goal and to try to see if this
596440	600440	system can work. So the way that we wanted to approximate this, and this is all the way back
600440	605800	in 2015 before image generation really worked that well, is we said, let's take a deep neural net
605800	611960	that is trained on ImageNet, which is relatively new around that time. It has 1000 different classes
611960	615320	and it's really good at recognizing these different classes. And then we'll have, we'll use that as
615320	621080	our evaluator, which is the generator's job is to generate instances of that class. And then the
621080	625800	question is, what are we going to use for this, the green box here, the generator side. So what we
625800	631800	need is an algorithm that can recognize either an improvement on a current class, or when a new
631800	637400	class is generated. And so we decided to use this algorithm that I'm excited to tell you about,
637400	640920	because it has a lot of really interesting motivations behind it. It's called map elites.
641880	647240	And it has one bin per ImageNet class. And I'll tell you what map elites is right now.
647240	651800	But to tell you about map elites, I kind of want to motivate this whole field of a new kind of
651800	656200	type of algorithm that my colleagues and I have been working on. And it starts with this recognition,
656200	660840	which is that there's a paradox in life, which is that if you try too hard to solve a problem,
660840	666920	you'll fail. However, if you ignore the objective, then you're much more likely to succeed. So imagine
667000	672040	that you're in this maze here, and you're starting here, and your job is to get here. And you might
672040	677160	say, well, okay, make the robot who's here, make its objective, getting as close as possible to
677160	681080	the goal. Well, if you do that, and you get points here, these are all the points that get generated
681080	685560	by that search algorithm, because and most of them just go straight north, because that lowers the
685560	690760	distance to the goal. But then they just butt their head against that wall forever. This is a
690760	695880	classic local optimus, you're familiar with these things in search. However, if you simply switch
695880	700840	away from the paradigm of always try to optimize toward a goal, and you just say, let's just go
700840	706200	to new places, just seek novelty. That's what you get here. And eventually this search stops
706200	710760	focusing on just going north. It doesn't actually care more about north than going east. And eventually
710760	716200	it winds its way around, and it solves the problem. And this right here is a metaphor for every single
716200	722040	hard thing we want to do in search. If there are local optimal in space, if we need to explore
722040	726760	to discover this thing, then we probably should seek novelty more than an objective. And it's
726760	732520	even a metaphor for things beyond algorithmic search. It's also a metaphor for human culture
732520	738360	and even natural evolution. And the idea is that almost every major scientific breakthrough,
739400	743880	if you trace its lineage back, it's not a straight path to that solution. Instead,
743880	749000	it's a winding, circuitous route. So for example, if you went back in time centuries and you said,
749000	754680	I have this way of cooking food, and what I want is a faster way to cook food that doesn't produce
754680	761800	any smoke, then you would never, if you only funded work into improved cooking technology that can
761800	766760	accomplish those goals of heating things faster, you would never invent the microwave, which is a
766760	771800	magical invention. Because to invent the microwave, you had to have been working on radar technology
771800	776840	and recognize the chocolate bar melted in your pocket. Similarly, if you went back millennia
776840	782040	to this abacus and you said, that thing does computation, I want more computation. And you
782040	787080	only funded researchers who improved against the objective of producing more computation,
787080	792920	you might get abacuses with like longer rods, more beads, something like that. But you would never
792920	797880	invent the modern computer because to do that, you had to work on things like electricity and
797880	803480	vacuum tubes, which were decidedly not produced because they improved computation, although
803480	808760	they later proved instrumental to doing that. The same is true for going from this kind of energy
808760	813000	to clean energy, where you have to be thinking about things like space and time that were not
813000	819080	thought about because they would produce new ways of producing clean energy. So the conjecture here
819080	823480	is that the only way to solve really hard problems may be to create problems while you solve them
823480	829080	and goals switch between them. And so goal switching is this idea that if you're trying to solve one
829080	835320	task, and you make progress on a different task, then you should also start optimizing and getting
835320	839960	better on that different task. So if this robot here, this scientist here wants to make a walking
839960	844600	robot, and all of a sudden during optimization, the robot starts crawling or starts balancing on
844600	850840	one leg, you shouldn't throw that out as a failure because it's not helping you walk or making forward
850840	855160	progress. Instead, you should start getting better at those skills to add those to the set of things
855160	860120	that you work on. And ultimately, those might be stepping stones to get you to this walking robot.
861080	868360	So my colleagues and I have been creating this new subfield of algorithms of AI
868360	872760	called quality diversity algorithms. And this family of algorithms is trying not just to get
872760	876520	the single best solution to a problem. It's trying to do something very different. It's
876520	883160	trying to get a large set of diverse solutions, but where every solution is as good as possible
883160	889160	for that type of solution. You want the tallest in the giraffe or the fastest ant,
889160	894440	but you don't let an ant who's not that fast kind of get precluded by the fact that a cheetah is
894440	901800	faster. You still want the fastest ant and the best ant you can find. So probably the most popular
901800	906680	algorithm in this family at this point is this algorithm called map elites, which was invented
906680	912200	by Jean-Baptiste Morel, a great colleague and friend of mine, as well as myself in 2015. And
912200	915720	it's very, very simple. And the idea here is if you're going to solve a problem,
915720	922120	want to first choose or learn, but we started off by choosing dimensions of interest that you find
922120	926920	that you yourself like. So imagine if you're trying to make a car, for example, you might choose
926920	932200	safety and fuel efficiency as two dimensions of interest. And then you just discretize these
933320	937400	dimensions. And you look for the best solution, according to some criteria, like maybe it's the
937400	943400	fastest car at each point in this grid. And what you want at the end of the day is not just to get
943400	949640	the fastest car possible, but the fastest car for every possible tradeoff between safety and fuel
949640	956120	efficiency. So here's an example problem we tried this on. This is generating soft robot morphologies,
956120	961640	which is like the bodies of robots. So we gave this optimization algorithm those four materials
961640	966200	there. They're kind of voxels that can pulse at different times. And some are soft and some are
966200	973080	hard. And we said, you know, go fast. And, you know, first we did this without map elites,
973080	977080	we just did this with a canonical optimization algorithm or a genetic algorithm in this case,
977080	982280	which is just trying to optimize for speed. And what you see here is this kind of really
982280	986920	interesting parade, this Noah's Ark of very different solutions and very different creatures.
987800	992120	And, you know, people got really excited when we put this online and it's super fun.
992120	995400	But I think one of the things that people thought really interesting about this work,
995400	1001000	including myself is the huge diversity of designs that you see here. You know, it starts to evoke
1001000	1005960	nature where you see a lot of different designs. The problem is there is a trick to this. And that
1005960	1011640	is that all of the designs that you just saw, each of those came from a different run of optimization.
1011640	1017160	The only way you got a diversity was by starting the run again and doing a massive search to find
1017160	1021880	one solution. But if you look within that population of creatures, they're all almost identical.
1021880	1025880	And that's not what we want. What we want on is an algorithm that will generate a huge diversity
1025880	1029800	of things within one run so that you can run it for billions of years and it would continue to
1029800	1034520	produce interesting new stuff as opposed to converging to one type of solution and getting
1034520	1039240	stuck on that kind of local optimal. So we took the map elites algorithm that I just described
1039240	1044760	to you and we applied it to the same software last problem. And what we did there, you know,
1044760	1049320	is we have to pick the dimensions and we chose to pick the number of voxels and then amount
1049400	1054440	of this dark blue material because previously it hadn't been using this kind of bone-like material
1054440	1059960	and we wanted to see it play with that resource more. And if you look at classic optimization,
1059960	1064280	this could have been RL, but in this case it's a genetic algorithm. Any optimization,
1064280	1068920	what you find is that it doesn't actually search the space very well. And so it has low performing
1068920	1073720	points and it didn't do a lot of exploration. If you add diversity, which we know historically
1073720	1078360	helps, you do get higher performing points. So you see these yellow points here, but it still
1078360	1082520	did not explore a lot of the space, even though it's incentivized to literally explore in these
1082520	1088440	two dimensions. Map elites is a qualitatively different algorithm. It's a sea change in terms
1088440	1092840	of what happens within the algorithm. If you look here, you see this rich exploration where it
1092840	1098040	fanned out and searched the entire search space and it taught you more about this search space.
1098040	1102440	It tells you, hey, there's not very high performing points up here. There's a little bunch of optima
1102440	1106280	over here. There's also this separate little area here that you probably would never have normally
1106280	1110440	found, et cetera, et cetera. I'm doing these interesting points over here that you can go
1110440	1116680	investigate. And what's interesting is it often finds a better overall high performing solution
1116680	1121400	than if you just do direct optimization because it's doing such a better job of exploring the
1121400	1128280	space of possibilities. So if you look at any individual final point, you can trace back its
1128280	1134280	lineage through time to see where those solutions visited in the search space. And what you can
1134280	1139320	see here is that they don't just kind of mine one area of the space and get better and better and
1139320	1143400	better at that corner of the search space, that particular tradeoff between these two dimensions.
1143400	1149240	But instead, the overall lineage takes these long, circuitous paths to their final destination.
1149240	1153800	Just as to get a human, you had to go through an intermediate stage of being a tapeworm and then
1153800	1158040	being like a tree dwelling. Actually, I don't know if we were a tree doubling, but kind of
1158040	1162840	something that looked more like an ape and all sorts of intermediate steps along the way.
1163640	1169320	So going back to the idea of an innovation engine, we now can recognize the algorithm that we're
1169320	1173560	going to use here. There's one final thing I need to tell you about, which is how are we going to
1173560	1178040	encode the images we're going to search for. And I'm going to tell you what I mean by the word
1178040	1181880	encoding, because I think especially for people who are interested in aesthetics, this is one of
1181880	1187160	the most important choices you can make. And you'll see this show up in Joel's work later as well.
1187160	1190920	So I'm going to tell you about the encoding that we use, which is a CPPN. So first,
1190920	1194600	I've been throwing around these terms, genetic algorithm and evolutionary algorithms. You may
1194600	1200280	not know what they are. I'm going to very briefly explain them. If you want to search for a problem,
1200280	1203880	this is also true in deep learning. The first choice you have to make is how to encode the
1203880	1208280	problem. So imagine if you wanted to search for tables. Well, you could decide I'm going to store
1208280	1213640	the length of each leg separately as a number on a parameter vector. We in evolutionary algorithms,
1213640	1217720	we call this a genome, but in deep machine learning, it's often called a parameter vector.
1217720	1221480	So you store the length of each leg separately and the width and the length of the surface of
1221480	1226760	the table maybe on this string of numbers, this parameter vector. Once you've made that encoding
1226760	1231800	choice, you then can score the population. First, you create a population at random by generating
1231800	1235960	random strings of numbers. You score this population to see how good they are. You select
1235960	1240680	which ones are better according to some scoring function, which could be your reward function.
1240680	1246040	And then you just take these things here, take their parameter vectors, and you perturb them
1246040	1251400	in a little way somehow. And then you get a new thing and then you repeat the process.
1251400	1254200	In the gradient-based method, this is kind of like where you take the learning
1254200	1259000	step based on the gradient of the scoring function. And then you repeat the problem.
1259000	1264040	So when I talk about an encoding, it's this first choice, which is how do we decide what is the search
1264040	1269720	space that we will search in the parameter vector and how does that map to the final solution?
1269800	1276200	And that is in evolutionary language, the process of going from a genotype to a phenotype,
1276840	1280760	or machine learning a parameter vector to a final agent or policy or artifact.
1281640	1287480	So there is this notion of a direct encoding versus a generative encoding. And a direct encoding,
1287480	1292520	you basically have one number on your parameter vector for every single thing in your final artifact.
1292520	1296200	So if you're searching for the weights of a neural net, then you search separately for a
1296200	1299960	number for each weight or for a table you search separately for the length of each leg.
1300760	1304920	If you think about how perturbations affect these parameter vectors, though,
1304920	1311480	they are mostly likely to produce non-regular phenotypes. So most changes are not going to
1311480	1316920	lead to a table that has to be flat and hold your coffee. And so that makes kind of a local
1316920	1320760	optimum between this solution and this solution. You have to go through this intermediate thing
1320760	1326760	unless you get lucky enough to generate a regular phenotype. If you have a generative encoding,
1326760	1332600	you reuse information in the parameter vector to produce the final thing. So you might just
1332600	1338040	specify the length of legs once and then reuse that for these four lengths of tables. And now
1338040	1344520	every single change to that parameter vector is going to produce a regular flat table. However,
1344520	1349880	you've lost something. You've lost the ability to express this type of table up here. And so this
1349880	1355640	is like a really, really essential choice when you go to produce any solution with search.
1355640	1359960	So generative encodings, you know, my colleagues and I and many others have been focusing for a
1359960	1364840	long time on why these types of encodings are really interesting. And some of the desirable
1364840	1369160	properties that we want is that you can get regularity, which means you can get patterns in
1369160	1374760	the final artifact. It might be the architecture of a neural net, or here is the hands on your,
1374760	1379640	you know, in your body. And what you see is there's a repeating theme in your hands. That's the
1379640	1385000	regular pattern. But it also has variation. Each of your fingers is a variation on a concept or a
1385000	1389400	theme. And that's kind of one thing that you might want while you search. There are some others
1389400	1395080	benefits here, but I'm not going to get into those. So this is something that I just think is really
1395080	1399480	fascinating to think about, especially if you're interested in aesthetics. And it also ends up
1399480	1403000	being helpful algorithmically. And it's going to factor into a lot of Joel's work, I assume,
1403000	1408360	depending on what he talks about. And this is this question of how does nature build the
1408360	1414600	astronomically elegant, complex creatures that you see in the natural world? Like a question
1414600	1417640	that I'm not sure if you've ever stopped and thought about, but it's a fascinating one to think
1417640	1424360	about is how does every cell in your body know what kind of cell to become? You have, you know,
1424360	1431080	the same software is being run in every one of your cells, the same DNA, yet some of your cells
1431080	1436280	turn into hair cells or spleen cells or liver cells or eye cells. How does it do that? How does
1436280	1441640	every cell know what kind of cell to become? Well, it turns out that nature is using a generative
1441640	1447080	encoding where it reuses information, where the cell fate, which is the type of cell, is a function
1447080	1452520	of its geometric location in the body. It's almost as if the body wanted to know the XYZ
1452520	1457720	GPS coordinates of each cell so that it could tell you, oh, if you're like up here, left of the
1457720	1462200	midline, three quarters of the way up the y-axis, then become a heart cell, for example.
1463320	1468200	So if you look through developmental biology textbooks, what you find is that these kinds
1468200	1473640	of geometric patterns are the lingua franca of developmental biology. So here's this beautiful
1473640	1478920	cartoon by Sean Carroll. So here's your DNA which has these genes on it. And in this developing
1478920	1484040	embryo are currently three different chemical patterns. They're called morphogens. They're
1484040	1490200	literally some protein that's sitting diffused inside this embryo. And if this gene here says
1490200	1496840	that protein A is present and B and C are not present, then this gene expresses and produces
1496840	1502280	a new protein, only where that's true. And so now you've combined these three pre-existing
1502280	1507560	patterns to produce this fourth new pattern. And this might therefore tell the vertebra and a spine
1507560	1513080	that they should turn into vertebra cells. You get this repeating theme down the middle, but only
1513480	1517640	the left half of the embryo. And if you look through that, go ahead.
1517640	1522040	Would I be able to interject real quick? Sure. My research is actually focusing on exactly this
1522040	1526680	same kind of problem, but in mammals. And so in mammals, the morphogen model explains some stuff,
1526680	1532200	but it's actually even more complex. It is much more complex. Everything in nature is much more
1532200	1539240	complex than we know. So I am simplifying here because I'm flying through this material. And
1539320	1544200	not all of the, not, it's not to say that the only thing that's happening is geometric patterning,
1544200	1551960	but it is, basically, I think it's the backbone of the way this stuff gets built. And so by capturing
1551960	1557560	that power and putting it into our search processes, we've gone a long way towards the power of
1557560	1563320	developmental biology. And you could argue that you've skipped out on a lot of the extra complexity
1563320	1567560	that would be very computationally difficult to simulate by doing these things efficiently.
1569320	1570520	Yeah. All right. That's a good point.
1573240	1580200	Cool. Thank you for the question. So getting to the issue I was just talking about, which is how
1580200	1586840	can we efficiently make this sort of a process happen? So what we don't want to do computationally
1586840	1591800	is have, like, diffusing chemicals in some chemical simulator, because that would be
1591800	1597080	really, really expensive. And so Ken Stanley, my longtime friend and colleague figured out,
1597080	1603080	is that you can actually abstract a lot of the power of this system without any of the underlying
1603960	1609800	chemistry and in physics in these things that are called CPPNs or compositional pattern producing
1609800	1615240	networks. And the idea is, is just like in nature, we're going to encode phenotypic elements as a
1615240	1621720	function of their geometric location. So here's how it works. You take a thing that you want to
1622840	1626920	optimize. This could be a neural network, it could be a robot morphology, it could be a
1626920	1633640	picture. And you provide coordinates for everything in the artifact. So imagine it's easiest to think
1633640	1638440	about pictures. So imagine you give every pixel an x, y coordinate, then you literally pass the
1638440	1644440	number, then those numbers into this function. So first you put in one, one for this pixel,
1644440	1650520	and then one, two, and then one, three. And you ask the genome as a function of those two numbers
1650520	1655640	to spit out the value at that location. And if this is a random function,
1655640	1661720	then you're going to get a random picture. But if this function here has mathematical functions
1661720	1666840	that, you know, have regularities in them, then you're going to get a regular artifact.
1666840	1673560	So for example, if you want left-right symmetry, you can pass the x-axis through a Gaussian here,
1673560	1677400	and then everything downstream of that Gaussian node will have left-right symmetry.
1678120	1683640	Similarly, you could have in the y-axis, if you wanted a repeating theme like segmentation,
1683640	1688680	you could pass the y through a sine function, and then everything downstream of that node will be
1689400	1694520	regular in that way. You can also add in linear things. You could say, I want to follow the sine,
1694520	1699800	but only add in a linear component, so like shift it or warp it or bend it in certain ways. So you
1699800	1705560	can mix and match asymmetric and symmetric and repeating themes to produce arbitrary complexity
1705560	1712040	using these geometric functions. And kind of what was really amazing at the time,
1712040	1716600	because image generation wasn't working very well, was the kind of images that would pop out of
1716600	1721160	these systems. So all of these images here were produced on a website called Pickbrier, where
1721160	1726680	humans manually choose which ones they find interesting, but the underlying encoding is a CPPN.
1727800	1731080	And Jill's going to tell you a lot more about like a modern version of this website.
1731640	1737720	So these images here are all encoded with CPPNs, and what you can see is very, very natural like
1737800	1743560	shapes, like things like left-right symmetry, repeating motifs, and the lineages as you kind of
1743560	1748200	permute and mutate these things. You go from a butterfly to a bat with these kind of beautiful
1748200	1755240	gradations and interpolations that are nice to see. Myself and my postdoc advisor, I took the
1755240	1758920	same exact idea and we just put it in three dimensions, and what you get are these nice
1758920	1764360	three-dimensional shapes, which also show a lot of these regularities. And then we went off and we
1764360	1769560	built this website called endlessforms.com, where you can go on, it's basically Pickbrier but in 3D.
1769560	1775160	You can take an individual shape and you can say, I want to further evolve or optimize that shape.
1775720	1780680	Let's see if this plays. Here, for example, you might take this lamp and you are presented with
1780680	1785160	a bunch of variants on the lamp, and then you pick the one that you like and you see the next
1785160	1790760	generation and you can kind of crawl through three-dimensional lamp space. And importantly,
1790760	1794600	if you find one that you like, then you can publish it to the website and other people can
1794600	1799720	pick it up and branch off of that. This is how you get that growing archive of stepping stones
1800520	1803800	that allows us to produce kind of an interesting exploration of the space.
1805480	1810200	Here are some of the other designs that popped out of this system, and here's kind of repeating
1810200	1816680	segmentation, left-right symmetry, radial symmetry, and mostly a lot of the things just look really
1816680	1822440	natural and interesting. So this is kind of a fun aesthetic space to be playing in using these CPPNs.
1825320	1830200	Because we could, we 3D printed the objects and allowed users on the website to 3D print them,
1830200	1834600	so it's kind of fun to hold these things in your hand, and you can therefore help people who have
1834600	1840360	no knowledge of CAD and design to produce arbitrarily complex images and then 3D print them
1840360	1843960	for whatever they want, like a chessboard or something. So when we put this out there,
1843960	1849240	people really found this interesting, which I think just goes to the to the fact that if you can
1849240	1854760	automate the design, if you can help people produce really interesting things that they're curious
1854760	1859480	about and they find exciting, but eliminate all the technical barriers to doing so, then people
1859480	1865480	get really excited about those tools, and Joel's website as a, you know, GAN breeder is a testament
1865480	1870280	to that as well. So going back to the overall scientific question here, which is can we use
1870280	1875400	this to create an open-ended algorithm? Now you know all the pieces of the puzzles. So we're
1875400	1880120	going to have AlexNet, which is an early image net network that was quite good at the time,
1880120	1883240	be able to recognize a thousand different classes, and then we're going to have an optimization
1883240	1887400	algorithm that's going to generate these little tiny CPPN networks that are trying to produce
1887400	1893000	images that light, that the DNN, the deep neural net, thinks represent, you know, are classified
1893000	1898920	as each one of the thousand bins in image net. So the idea hopefully is that you'll get goal
1898920	1904040	switching. So if one of the networks is the best dog we've ever seen, or particular dog,
1904040	1908760	and then a permutation on that produces the best fish we've ever seen, then now that network can
1908760	1913880	go to hop over to that bin and start optimizing to become a better fish. And maybe that produces a
1913880	1919400	better stepping stone for a cat and then a bird, etc. And the hypothesis that we wanted to test
1919400	1926600	is, is that better than separately optimizing for each one of the bins in image net? So here is
1926600	1932360	the performance over time. Time here, training goes from bottom to top, and the category of
1932360	1937320	thousand image net classes are along the x-axis. What you can see is that over time performance
1937320	1942280	rises with training all the way up to one, you know, red in most places, which means that the
1942280	1947240	deep neural net is certain that this thing is a lion, and this is a starfish, and this is a guitar.
1947880	1953240	So my question to you is, knowing that the deep neural net thinks that each one of these things
1953320	1958520	is in that category, you know, what do you think they look like? And if you had asked this question
1958520	1964680	in 2015, 2016, people would have said they look like electric, you know, starfish and guitars,
1964680	1970360	but you probably now, because you guys are, we've had the benefit of a few years, you probably are
1970360	1975160	used to the idea that what you do, what you get is not that, but you get these things that are called
1975160	1980840	fooling images or adversarial images, which is to say that the deep neural net is absolutely
1980840	1986280	certain that this is a starfish, and this is a peacock, and this is a king penguin, and this is
1986280	1991560	an electric guitar, even though they obviously are not those things. So at the time, this was a,
1991560	1996680	this, we published this paper, deep neural nets are easily fooled, and it was a really big wake-up
1996680	2001960	call to the community that AI sees the world differently. There are huge security concerns
2001960	2008040	here, and this generated a tremendous amount of discussion and awareness amongst the scientific
2008040	2011720	community, the machinery community, and also the broader public about the fact that these new
2011720	2016040	tools that we're building have a lot of deep flaws within them that we need to worry about.
2016680	2022120	Nowadays, everyone's very familiar with adversarial images. At the time, this was not very well known,
2023480	2029080	and so I thought that was interesting. However, I also think from an aesthetic perspective,
2029080	2032680	it's interesting that we were trying to generate innovation engines and generate images. We weren't
2032680	2036600	trying to study neural nets and whether they had flaws, and then this just kind of popped out,
2036600	2041960	so I thought that was an interesting story. But while some of the images didn't look anything
2041960	2046280	like the categories of interest, another thing that we found interesting is that many of them
2046280	2050280	did, and from an aesthetic perspective, this is pretty cool because now you're getting an automated
2050280	2056440	art generator. So for example, matchstick, television, and bagel, they pretty much do look
2056440	2061640	like those things. However, I also think from an aesthetic perspective that some of these really
2062200	2068120	evokes an artistic interpretation of what that abstract platonic concept represented by that
2068120	2077640	class is. For me, this image of a prison cell evokes more than just a picture of a prison cell.
2077640	2082600	It seems to me like an artist decided to represent the bleakness but also the hope or
2082600	2087160	something about this prison cell. And so even though there is no artist that was trying to
2087160	2091400	capture that behind here, there's a neural network that's kind of captured the platonic
2091400	2097720	concept of a prison cell, and that somehow leads to its own dialing in of what is central and
2097720	2103000	essential about that concept, or at least evokes those kind of reactions in us and allows us to
2103000	2109720	explore potentially new types of artistic and aesthetic connections to concepts. So if you
2109720	2114520	look through the diversity of the images that were generated, I do think this kind of really hit
2114520	2119880	the mark in terms of a quality diversity algorithm. You've got this huge set of images as all comes
2119880	2125800	from, you know, one run. And at least I'm not, I think that they are, they might have been pulled
2125800	2130840	from a couple of different runs in this case. But each one produces this giant, this diverse set
2130840	2134680	of images, and many of them I think are really aesthetically interesting, like I think this
2134680	2140040	volcano or this beacon, or this cup, I could actually imagine a coffee shop where this is this
2140040	2145720	logo, your comments on a mask and a banana, etc. So we really, really thought it was cool to see
2145720	2151640	kind of this pop out of an automated system back in 2015. Scientifically, we're also really
2151640	2155640	interested in like whether or not goal switching was playing a huge role in these networks. And so
2155640	2161080	we have, if you optimize for a single class only, like the water tower class, what we see is that
2161080	2166280	you do indeed get stuck on a local optima. It lands on this particular pattern really early in the
2166280	2171160	run. And then it just does minor tweets on that idea and gets stuck on it until eventually it kind
2171160	2176760	of maxes out what you can do in that corner of the search space. In contrast with map elites,
2176760	2182120	what you see is that early on it locks on this half dome moon image, and it does okay, but then
2182120	2186440	it kind of gets stuck. And then from a totally different class, something that happened to have
2186440	2192280	been produced to for the beacon class, actually ends up looking like a better water tower and
2192440	2196920	goal switches in, it invades this class. And then with further optimization to look like a water
2196920	2202520	tower ends up making the DNN think with 98% confidence that this is a water tower. And you
2202520	2208680	can kind of see why. And we see this lesson over and over and over again. There's many goal switches
2208680	2214760	happening within this population of networks. And we think that's a big reason why performance is
2214760	2221560	much higher than when you optimize for a single class. So what's really interesting about goal
2221560	2226440	switching is that it allows what what are what biologists call adaptive radiations. So you come
2226440	2231640	up with a good idea like maybe a more efficient way to metabolize oxygen in one lake in Africa.
2231640	2237000	And then that idea will spread to all of the surrounding lakes in Africa. And then on top of
2237000	2243080	that technological foundation, those fish will respecialize to their particular niche and adapt
2243080	2247080	that innovative incorporate that innovation. The same thing happened with Darwin's finches,
2247080	2253160	which radiated out from one from one couple of finches to all of these diverse finches.
2253160	2257400	And we see the same thing in technology where computers, for example, were invented for one
2257400	2262040	purpose and then kind of spread throughout an ecosystem and are now embedded in all sorts of
2262040	2267560	technological devices in our lives. So what's really nice is you can see these adaptive radiations
2267560	2271880	happen in these quality diversity algorithms. So this is one of my favorite plots from all of
2271960	2277400	the science I've done in my entire career. Inside one of these innovation engine runs,
2277400	2281960	you've got this early innovation, which is this dome against a background, a colored background.
2281960	2288520	And that thing, which looked up the abaya class, then radiates out and it's children because this
2288520	2293800	is a population. So these literally are descendants of each other. It's descendants kind of produce
2293800	2299320	a phylogenetic tree, just like we see in nature. And ultimately, this innovation turned into a
2299320	2306600	volcano, a mosque, a water tower, a beacon, a yurt, a church, a planetarium, an obelisk, and a dome.
2306600	2310920	And it's just awesome to see an innovation then get rid of that concept, get rift upon and kind
2310920	2316600	of radiate out into a huge explosion of diversity. So if you study the history of biology, you'll see
2316600	2319880	that there were many moments in the history of biology where something similar happened. We got
2319880	2325400	like, you know, single multicellular organisms or rate or bilateral symmetry or the four-legged
2325400	2330200	body plan. And then you see this explosion of diversity that descends from that central innovation.
2330200	2333400	So I think it's beautiful to see that happening inside of our algorithms.
2334760	2340120	We ended up submitting the art that was produced by this algorithm to a competition at the University
2340120	2344360	of Wyoming where I was a professor. And every year, art students work for a year and they submit
2344360	2348360	their best project to this competition. And then there's a judges who decide which of them get
2348360	2353800	hung on the wall and accepted into the competition. So we did not tell them this is AI-generated art,
2353800	2358600	we just submitted it. And not only was the art accepted, it was also given an award.
2358600	2363000	So here you see people having wine and cheese. And I was like eavesdropping as they're discussing
2363000	2367640	the intent of the artist behind producing all of these different images, not knowing that it was
2367640	2373000	an AI algorithm behind it, which I thought was pretty cool. So in some sense, this passed the
2373000	2380360	artistic turning test. Sample size one. FYI, in case you're interested, there is much more work on
2380360	2385320	CPPNs that are more modern. So nowadays, a lot of people are playing with differentiable CPPNs
2385320	2389880	instead of using evolution. I have to because it's so beautiful. Quickly look at the work of Alex
2389880	2395080	here, which I highly recommend you check out. All of these things here are different CPPN
2396120	2401000	represented networks that are doing deep visualization, which is the technique I'm
2401000	2405240	going to tell you about later. So I encourage you to check that out. There's also, you can
2405240	2409560	use CPPNs to encode neural networks. I did that a lot in my dissertation and now you can do that
2409560	2415400	with Backprop. David Ha has been pushing that and there's much more work in this vein. Okay,
2415400	2420760	so getting back to QD, I think that I hopefully have convinced you that it has all of these nice
2420760	2426360	properties, like a diverse set of high performing solutions that it produces, it has goal switching,
2426360	2430920	and it allows you to kind of illuminate the entire search space and learn a lot about what's possible.
2432040	2436200	Just quickly, I want to say that these ideas really have given us a lot of leverage on hard
2436280	2441640	technical problems. So in this paper that we had in Nature, we use these ideas to have robots that
2441640	2446040	could adapt to damage within one to two minutes to get up and continue on with their mission,
2446040	2450920	even if they're extremely damaged. And then we also use these ideas behind the algorithm GoExplore,
2450920	2455720	which you may have heard of, which completely solved the Atari benchmark suite, including
2455720	2460760	solving really hard exploration challenges like mono zoom as revenge and pitfall. You can see all
2460760	2464920	the previous attempts to solve this heartless game, which became kind of its own grand challenge
2464920	2469240	of the field, do not perform very well. And then this is the difference once you start adding in
2469240	2474200	these ideas from quality diversity algorithms. Ultimately, we ended up beating the human world
2474200	2480920	record on this game. Oh, and as a quick little teaser, this paper was also recently accepted
2480920	2484680	to a really nice journal. I can't quite tell you which one, but if I'll share that information
2484680	2488280	on Twitter in the next couple of weeks, if you are interested to get the final version
2488280	2493720	and the updated version of this paper. So I think QD algorithms are really interesting.
2493720	2497480	I think the question that we should always ask though is what's missing where, you know,
2497480	2501880	they're not yet open-ended algorithms. So the thing that I think is missing is that while these
2501880	2506360	things can produce a large diverse set of interesting solutions within one domain,
2506920	2510600	ultimately, their ability to innovate is constrained because they're stuck in this one
2510600	2515160	particular setting that we put them in. But what we really want is these open-ended algorithms that
2515160	2520680	just keep going and kind of generating wildly different solutions as they run. So traditionally
2520680	2525080	in ML, we pick a particular challenge like Chester, Gro or Dota or Starcraft and we bang
2525080	2529720	away on it for a while. But the intriguing possibility that I want all of you to consider
2529720	2534760	today is could we create an algorithm that generates its own challenges and solves them?
2535640	2541960	Just as nature arguably created the challenge or the opportunity of leaves on the top of trees,
2541960	2546520	and then the solution to that challenge, which is giraffes or caterpillars that can eat them.
2547400	2551000	So, you know, this kind of a thing might produce something that's interesting
2551000	2555720	after a billion years. So our most recent work on this is in this algorithm called Poet,
2555720	2561160	which is the paired open-ended trailblazer. And the idea here is that we're going to try to endlessly
2561160	2565480	generate interesting, complex and diverse learning environments and their solutions.
2566360	2572280	So the idea is again quite simple and you'll recognize it. It's basically we want to
2572280	2577400	generate new learning environments and we're going to add them to this set of our population of
2577400	2582680	environments if they're not too easy and not too hard for the current population of agents.
2582680	2585880	And if they're novel, there's something about them that's unique and different.
2585880	2589720	And then we'll optimize agents to better solve each of these challenges and we'll allow goal
2589720	2595880	switching between them. So the example task that we used here is obstacle courses. So this little
2595880	2601160	creature here has to run as fast as possible without falling over. And here's the general idea.
2601160	2604920	You start with an easy environment. So first you have to make that encoding choice. How are you
2604920	2610760	going to encode an environment on a parameter vector? Here we have things like the number of
2611320	2615240	whether or not there are gaps, whether or not there are stumps, the ruggedness of the terrain,
2615240	2619800	et cetera. So you can start with an easy one of those, which is maybe just flat terrain.
2619800	2624600	And then you start having an agent, which has its own parameter vector. This is a neural network
2624600	2629640	and is learning via RL to solve this task. And once it gets good enough on that task,
2629720	2635160	then we copy phi 1, the parameter vector of the environment, to make phi 2. And then we'll try
2635160	2640680	this agent via transfer and goal switching. It goes and it starts optimizing here. Now,
2640680	2645400	we are simultaneously continuing to optimize this parameter vector on this environment and this
2645400	2651240	parameter vector on this environment. We keep going. Maybe eventually this environment gets
2651240	2656920	solved well enough by this parameter vector. So we copy it and we now make phi 3 a new environment.
2657000	2663000	Turns out that's too hard for either theta 1 or theta 2. So we throw that out. We generate,
2663000	2668200	we try again, we get a new environment and we test this one and this one. We take the better of those
2668200	2673640	to you on this new environment to seed training. And in this case, it was theta 2. So it goes in
2673640	2678040	there. This does not have to be a linear chain. At any point, any one of the environments in the
2678040	2683800	set can produce a new environment. And then we'll try all of the current agents on that environment
2683800	2689160	to see if they're the best and if they are, they get to start. And the process can keep going like
2689160	2694040	this. Now, imagine eventually we generate a really, really hard challenge like phi 6 here.
2694600	2700680	And initially the best parameter vector, we try all of them on this environment was theta 5. It
2700680	2705640	was the best stepping stone. So we start optimizing a copy of theta 5 in this environment and it gets
2705640	2709960	better and better and better. But it maybe hits a local optimal and it can't break through and
2709960	2714440	really, really do well on this environment. But in the meantime, we're still optimizing theta 4 on
2714440	2719080	this environment. Maybe it has an innovation that makes it better on this environment. So it invades
2719080	2724040	this environment, just like a species in nature could invade a new niche, kicks out that parameter
2724040	2729480	vector. And now we start building on the back of this innovation here. And then that maybe with a
2729480	2734040	little bit more optimization comes up with an innovation that then transfers in and becomes
2734040	2738760	the best thing we've ever seen on phi 6. And maybe that gets us off the local optimal and solves that
2738760	2745000	problem. So that is kind of the nature of goal switching. So here we use evolution strategies,
2745000	2752440	but any RL algorithm would work. And you can see this little agent here. And it is traversing this
2752440	2757960	course. And what you can see is at the beginning, all of the challenges are quite simple. They're
2757960	2764440	a little tiny stumps, little gaps, just a little ruggedness in the terrain. But over time, the
2764440	2770040	agent gets better and better. And the environments automatically start getting harder and harder.
2770040	2778120	So it's kind of like a natural curriculum generation. And you can still, the algorithm
2778120	2783400	is here is kind of still pushing in separate dimensions, like taller gaps or more ruggedness
2783400	2789960	or wider gaps. Sorry, I didn't tell her stumps. Later in time, with more training, the algorithm
2789960	2794680	starts to put together these challenges. Sorry, my dog is barking. So you get things like bigger
2794680	2800120	gaps and stumps and ruggedness all put together. And ultimately, these environments get really,
2800120	2806840	really, really difficult for this little robot to traverse. Here's another challenge that was
2806840	2813400	invented and solved by this algorithm. So I think from an aesthetic point of view, it's kind of cool
2813400	2817800	because you can think about each one of these robots as its own little creation. It's kind of a
2817800	2823240	curiosity. Just like animals in the world, we love to watch nature shows and see different animals
2823240	2827560	and how they're different and what they can accomplish and how their bodies are different,
2827560	2832040	et cetera. So you can kind of think of the agents produced by these things as really interesting
2832040	2836920	aesthetic artifacts. Scientifically, we wanted to see whether or not goal switching in this
2836920	2841000	domain was paying off. And so we did direct optimization in each one of these environments
2841000	2845880	and found that it failed miserably. That's down here. And with Poet and the goal switching,
2845880	2850600	what you see is much, much better performance in each one of these environments. This is the only
2850600	2856360	way that we know of to go solve these hard problems. And in the paper, there's more of a
2856360	2861400	detailed study about that claim if you're interested. So I want to show you one anecdote of what popped
2861400	2865480	out in the system. So I think it's so interesting. So here in the simplest possible environment,
2865480	2869880	a flat ground, you get this agent here that is optimized for a really long time and it's got
2869880	2876600	this knee-dragging behavior. And eventually, the system generates a permutation of this
2876600	2880600	environment, which is a harder challenge that has little tiny stumps. And this knee-dragging
2880600	2885720	behavior is not very good because it keeps tripping up on these little stumps. So with
2885720	2891400	some more optimization in that environment, the agent learns to stand up and it gets faster at
2891400	2895880	that. Now, because the algorithm is always checking any solution to see whether or not it's better
2895880	2901560	at invading some other niche, this descendant actually goes back automatically and invades that
2901560	2907160	flat ground, replacing this knee-drager. Now that it knows how to stand up, as you can see here,
2907160	2912760	it gets much better performance in that new environment. And then with further optimization,
2912760	2917160	it ends up with much better performance. Now, because this is a computational system,
2917160	2921960	we could do the counterfactual. We went back to this original agent in the top left and we optimized
2921960	2927400	it for an equal amount of computation in that flat ground environment. And it just never learns to
2927400	2933160	stand up. It's just on a local optimal and it's stuck in its ways. It was only by going into a
2933160	2939000	harder environment and coming back that it learned a better behavior and a better strategy. And this
2939000	2943560	is why I think that it's so hard to design curricula. You would never, as a human, say that you're
2943560	2948040	going to take something to a harder environment just to have it solve a simpler environment.
2948120	2951240	But in this case, that's exactly what was needed to solve this problem.
2952520	2958440	So we go through a quantifying algorithm that goal switching is essential to solve the hardest
2958440	2964840	challenges generated by this system. So future work in this domain, I think there's all sorts of
2964840	2971480	stuff you could do. Obviously, you could just take it into more complex rich simulators. So,
2971480	2976360	you know, you could have more complex encodings as well. But here is like the world's from deep
2976360	2982040	mind. But I think it's really kind of pumps my intuition is to watch, you know, what's possible,
2982040	2986680	what will be possible in the future with more computation. Like imagine what Poet could do
2986680	2991480	in a world this complicated, where it has to do with flying creatures and climbing and talking
2991480	2996840	to other agents, maybe negotiating trades in a market, you know, and if you were doing all of
2996840	3001400	this, you know, what might pop out of the system, I think it's fascinating to consider, both from
3001480	3007320	a static perspective and from a machine learning perspective. You also could optimize the bodies
3007320	3011400	of the creatures themselves. So in the bottom in the right, you see, you know, I showed you some
3011400	3016680	work that we did in that vein a while back, but not with Poet. And David Ha has done that in
3016680	3021480	particular environments that are handcrafted. But imagine if you paired body optimization with
3021480	3025160	environment generation, then you could really get weird things like you see in nature, where you
3025160	3029320	have a particular kind of like cave dwelling spider that's optimized to that environment,
3029320	3033640	which is very different from birds that are flying up in the Pacific Northwest.
3034600	3037800	So another thing that I think would be interesting would be to combine innovation
3037800	3043400	engines with modern tools. So imagine if you took something like Dolly, which is this amazing
3043400	3049560	new thing produced by my colleagues here at OpenAI. And not only did you have humans asking for
3049560	3054520	particular innovations or particular images from Dolly, but you have the algorithm invent the
3054520	3058920	challenge and the solution. So the challenge could be, you know, can you create this? Can you create
3059640	3063640	this? Dolly would then create them. And if they're interesting, you add it to a set. And then you
3063640	3067720	have something that looks at the set of things that are already produced and produces completely new
3067720	3072760	types of images. That would be awesome to see. And that doesn't have to be limited to images. You
3072760	3078040	could use then the same technology to do it in different modalities, such as videos and music
3078040	3083240	and poetry or algorithmic space. Again, the challenge that remains is how do you detect
3083240	3087560	what's interestingly new? I'll throw it out there that I think you probably with a lot of data could
3087560	3092520	learn a function of what humans consider interesting. In fact, if Joel remembers, I sent him a giant
3092520	3096200	email saying that I think we should do this with his website, GanReader. We haven't done it yet,
3096200	3101560	but it'd be a great project for a student to take on. So I want to quickly check the time here.
3102600	3106760	Yeah. So we started a little bit late. So I'm going to race through this because I think you'll
3106760	3111640	find it interesting, but I won't be able to go into any detail here. But part two of the talk,
3112520	3116280	which I'll do very quickly, is I wanted to tell you about this entire other arc of research that
3116280	3121560	we did called AI neuroscience, which is how much we want to study. Just like neuroscientists try to
3121560	3125480	study the human brain, we want to study how much the deep neural nets understand about the images
3125480	3132040	that they classify. So we're all familiar with deep neural nets, but they tend to be a black box.
3132040	3137880	We don't really know what each neuron in the deep neural net does. But one way neuroscientists probe
3137880	3143400	this question is they literally put probes into your neurons and they look for which neurons light
3143400	3148120	up in response to which images. For example, they found neurons that light up in response to
3148120	3153240	Kobe Bryant or Bill Clinton, for example. And people have called these things like a Kobe Bryant
3153240	3157480	neuron, for example, and they respond to very different modalities, such as the name Kobe Bryant,
3157480	3162200	a line drawing him in the Lakers uniform. The question is, you don't really know just because
3162200	3166920	the response to those images, if it's a Kobe Bryant neuron, it could be an LA Laker neuron
3166920	3172680	instead of a Kobe Bryant image neuron, for example. So we thought the ideal task would be to synthesize
3172680	3177560	the images that maximally activate that neuron. And if you did that and you got these images,
3177560	3182200	then you'd know, oh, that's a Laker neuron, not a Kobe Bryant neuron. But if you got these images,
3182200	3187400	you'd know it's a Kobe Bryant neuron. So this is actually possible with artificial neural networks,
3187400	3192120	but you can do is you can take a neural net and then you could have like an artist, an AI artist
3192120	3198280	that's trying to generate an image to activate this particular neuron here. And what you can do is
3198280	3202280	you can use backprop. So the artist generates an image and then you just follow the gradient to
3202280	3206520	increase this neuron until you get an image that lights up that neuron, and it might look like this.
3206520	3211000	And you can do the same technique for all the intermediate neurons in the neural net.
3211720	3217000	We call this deep visualization. Our first attempt at this actually was that same paper,
3217000	3222760	deep neural nets are easily fooled when we did it with CPPNs here or a direct encoding on the left
3222760	3228440	here, or with backprop on the right, we got images that did not look at all like things that they're
3228440	3234440	supposed to, but the neural net was perfectly sure is a peacock or chimpanzee. And you know what
3234440	3239240	happened with that paper. We then went on and started asking questions like why are these neural
3239240	3243800	nets easily fooled? And I don't have time to get into a lot of the details here, but what we basically
3243800	3249960	thought is that maybe deep neural nets do recognize the images they're supposed to like a lion or a
3249960	3256040	dolphin, but maybe they recognize a whole lot of other things also as in that class unnatural images.
3256040	3261800	So if we could stop the artist from generating unnatural images and only stay to the space of
3261800	3267480	natural images, then we might find out what that neuron really is for and what it's been trained
3267480	3272520	to see within the space of natural images. So skipping over some of the details here,
3273480	3277880	the fooling work started out saying maybe these deep neural nets don't really understand at all
3277880	3281880	what they're classifying. They're just locking on to spurious correlations like that there's a
3281960	3285960	orange texture. If you see orange, you know, this kind of orange texture next to blue color
3285960	3290680	of starfish, but they never learned like what a five-legged starfish is because they didn't
3290680	3294840	need to to solve the problem. We wanted to see whether or not there is that notion of like a
3294840	3300120	five-legged starfish in the network. So in take two, what we tried to do is we added more manual
3300120	3305720	priors to try to constrain the image generator, the artist, to generate only natural images. And
3305720	3311000	when we add that extra constraint, then we get images, you know, previously people had done that
3311000	3317640	and they kind of looked like this. You start to see dumbbells and dolomations. These are the
3317640	3322120	ones that we got with slightly better priors. And you can start to see that the network does
3322120	3327080	actually kind of know what a flamingo is or a beetle. It's an interesting historical side note.
3327080	3332120	These images here in this work inspire deep dream, which is also done by Alex over at Google.
3332120	3337560	And that stuff is super cool if you haven't seen it. And then third take, we tried to add even
3337560	3343880	better priors, manually designed priors, and what you get are these images here. And I want to stop
3343880	3348120	for a moment and kind of reflect on this from an aesthetic perspective. We're trying to do better
3348120	3354360	and better science. We're creating different algorithms or different hand-coded priors to
3354360	3359400	kind of accomplish the scientific quest. But if you look at the different images, each one of them
3359400	3364200	has a different style. And I think it's kind of interesting that like slight tweaks to algorithms
3364200	3368680	produce wildly different artistic styles. It's like all these different artists are out there
3368680	3371960	and you just kind of are searching through the space of artists kind of accidentally
3371960	3376040	while you're doing your science. So this style is very different from this style. And I actually
3376040	3380360	think this is just really beautiful. Like if I saw this in an art museum, I would think that this
3380360	3384120	is beautiful art, even though it was produced purely for scientific reasons and we had no
3384120	3389720	intention of producing images in this style. We then went on for one more take at this. We tried
3389720	3395800	to say, okay, we're machine learning researchers instead of manually encoding what characterizes
3395800	3400440	a natural image. Let's learn it. And so we start learning the natural image priors and our papers
3400440	3405080	are full of lots of details on this. And the way that we do this, we have a generator kind of like
3405080	3410520	the generator in a GAN. We hook it up to the target network we're interrogating. And then we try to
3410520	3414760	search in a latent code to produce an image that activates a certain neuron in question.
3415400	3420280	And when we did that, we got these images, which at the time were some of the most realistic images
3420280	3425880	deep neural nets had ever produced. You were seeing realistic lawnmowers and lemons and barns
3425880	3432360	and candles. These images are not great by modern standards, but this is 2016. Here are other images
3432360	3438120	in this class. And for the first time ever, the images were starting to look photorealistic.
3438120	3442200	Like these are the synthetic images for this class. And these are the real images.
3442200	3445960	And, you know, I don't think that you would really be able to tell the difference if I had swapped
3445960	3451640	them unless you look very carefully. So compared to the best work at the time, which is on the left,
3451640	3458040	these images were a big step up. And they helped us confirm this hypothesis, which is basically,
3458040	3461800	if this is the space of natural images, these networks do understand what it means to be a
3461800	3468520	lawnmower. Like if this blue line here is the class of lawnmowers, then they do stay to, if you
3468520	3473480	keep them in the natural, if you only generate images in the natural image space, then you do
3473480	3478360	get a lawnmower. But if you let it generate images anywhere in the space, like all the way out here,
3478360	3483080	then it also, the network will similarly say this garbage here is in the class of what it
3483080	3487400	means to be a lawnmower. And so if we want for aesthetic purposes to have neural nets generate
3487400	3493000	realistic stuff, we got to get it focused on something that both is natural and activates
3493000	3497720	the network's classification as opposed to way out here. And GANs do this also, but they do it
3497720	3502680	via a very different mechanism. So I told you, you could look at each individual neuron within
3502680	3507320	the network. I don't have time to go through this now, but if you're interested, then I encourage
3507320	3511080	you to kind of go into the paper and look, you could kind of fly around the neural net and see
3511080	3516200	that you get things like cargill grill detectors and buckets and bird heads. And as you go up in
3516200	3520680	the network, you get these really weird concepts like one-eyed turtles and like arches over water
3520680	3525080	until you eventually get the class neurons where we know what they are because we've grounded them
3525080	3530120	via our labels. The one final thing I'll mention here is that the one problem with our technique
3530120	3535800	is that it generates very, very little diversity. So these are synthetic images produced by our
3535800	3541560	network for this class. And they look a lot like the images that most highly activate that neuron
3541560	3546920	from the real world from the real data set, but they don't represent the diversity of images in
3546920	3552520	that class. And so we did a lot of work, including adding with Yashua Benji on these things called
3552520	3557160	plug-and-play generative networks, where we wanted to add a lot more diversity. And so you could
3557160	3561000	take the same network and you can light up a bunch of different classes that it's never even seen
3561000	3565480	before. That's a bit of an aside like ballrooms and art galleries, but mostly we were interested in
3565480	3571800	getting more diversity. And the takeaway message is we were able to accomplish that. So here is PPGNs,
3571800	3576200	which is the one that has more diversity. And you can see a much more diversity in this set of
3576200	3582440	images versus DGNAMV1, which are the images over here. And this diversity better represents
3582520	3587720	kind of the diversity of the natural class. So with the original attempt, DGN, you got volcanoes
3587720	3592360	that look like this. It kind of goes and finds one type of volcano, like a local optima, and it
3592360	3597400	sits on it. But the plug-and-play generative networks are much more kind of like an open-ended
3597400	3602200	algorithm, at least within this class, where it samples new versions of volcanoes over and over
3602200	3608600	again. And so you get all this big diversity of volcanoes out of this new sampling technique.
3609320	3614600	So to conclude this, the AI neuroscience part, I won't actually get into these details, but it
3614600	3619160	taught us a lot about what neural nets, you know, what's going on inside neural nets, it taught us
3619160	3624120	whether or not they really recognize and learn about the concepts in our world. Like we did find
3624120	3628120	in the end that they do know what a volcano is, and you know the five-legged nature of a starshow,
3628120	3632760	and what a lawnmower is, even though they also are susceptible to producing and recognizing
3632760	3637800	these adversarial fooling images as being part of the class. And it was cool to see the rapid
3637800	3644520	progress just within my own team of collaborators from 2015 to 2017. And since then, I highly
3644520	3650200	recommend the work of Chris Ola, who's continued to push in this direction. And very, very soon,
3650200	3655240	Gabriel Go and Chris and others have new work coming out of OpenAI that will blow your mind.
3655240	3660200	So I encourage you to watch the OpenAI blog in the coming weeks for this new result that you
3660200	3665560	really like. You could do all of this stuff in different modes, like speech and video, etc.
3665560	3668760	I won't dive into this. I want to just highlight one thing. This is my future work slide all the
3668760	3673640	way back in 2016, and I thought it would be awesome to do this with real animal brains.
3676680	3680280	Since then, actually, somebody has done that. They took our algorithm for DGN,
3680280	3684120	they applied it to a real monkey brain, and they synthetically are generating images that activate
3684120	3688600	neurons within the monkey brain, specifically within the face recognition part of the monkey
3688600	3693720	brain. And you do in fact get a synthetic monkey-looking face, which is pretty amazing.
3693720	3698760	So to conclude my overall talk, I think innovation engines are really interesting because they kind
3698760	3704200	of push on this question of can we automatically produce an open-ended creative process that in
3704200	3710120	any sort of modality like art or music or invention will just endlessly generate interesting new
3710120	3714280	things. We've got a long way to go to accomplish that goal, but my colleagues and I, like Ken Stanley
3714280	3718360	and Joe Layman and myself are really, really focused on this goal and trying to pull that off,
3718360	3724280	including now at OpenAI, where all those people are. And I also showed you very, very quickly some
3724280	3727720	of our work in AI neuroscience, which we were doing for scientific reasons, but produce these
3727720	3731800	interesting aesthetic artifacts. And I'll just leave you with one final thought, which is that I find
3731800	3736440	it surprising how often science produces aesthetic artifacts. Almost none of the work that I was
3736440	3741720	doing was trying to do it just for aesthetic purposes, but along the way, it produced these
3741720	3746440	things that I think are beautiful and interesting, and could be kind of aesthetic artifacts in their
3746440	3749960	own right. And so I think it's nice because you don't have to choose between being an artist and
3749960	3754840	a scientist. You kind of kind of can do both nowadays, especially with the modern tools and
3754840	3759160	machine learning. And I'm sure that's kind of a realization that is being reinforced over and
3759160	3763480	over again with all the different lectures in this wonderful class that you are participating in.
3763480	3767800	So with that, I want to say thank you, and I'll turn it over to either questions or Joel, depending
3767800	3775080	on what you want to do, Ali. Thank you so much. I appreciate it. It was really interesting and
3775080	3782840	inspiring to me, and I'm sure for many of us in this class, this comment that you also made about
3782840	3791720	science and creating and art, I think that it also is very well aligned with some of the other
3792280	3797560	insight that we learned from other speakers. For instance, Alyosha, of course, was mentioning that
3797560	3803560	when I asked this question, he was mentioning that he also thinks that, you know, creativity is
3803560	3810360	a different tier of our evolution. So that really resonated with me what you were talking today.
3811880	3822520	And I think that this is very exciting for us. One question that I have is if students want to,
3823560	3830280	because this is a very interesting topic, and especially that type of poet or open-endedness
3830840	3839720	area, if a student wants to join you in this sort of mission, what do you recommend to them to work on?
3841320	3846840	Yeah. So one thing I would recommend is we had an ICML tutorial, I think about a year ago, that
3846840	3853160	really covered a lot of this work in more depth. It's an ICML tutorial on population-based methods.
3853160	3859560	So then you can see, can Joel and myself kind of going through, this is Joel Lehmann, not Joel Simon,
3859720	3865480	going through a lot of the work that we've done in this field. And I recommend reading a lot of the
3865480	3870920	work of both Ken and Joel, as well as you can look into some of the work that we've done in this area.
3870920	3875480	And then in terms of what I recommend you work on, there's so many things, it's like,
3875480	3880760	there's so many options that it's fun. You could apply a lot of these algorithms in a new domain,
3880760	3887080	for example, that you find interesting, you know, a new kind of art. You could take more modern tools
3887080	3892120	that work really well and weave them into these ideas, or you could invent new ideas, you know,
3892120	3897560	like I still think if people, if anyone out here can crack the question of how can you automatically
3897560	3904520	recognize newly interesting things, that I think is like a Turing award-winning innovation that will
3904520	3911160	catalyze and propel so much algorithmic advance, including potentially advancing our push to
3911160	3916200	artificial general intelligence. Like that might be one of the key stepping stones that gets us there.
3916200	3919880	So I have this paper called AI Generating Algorithms, which I recommend people check out if
3919880	3925080	they're interested. And it basically talks about how these sorts of ideas may do the fastest path
3925080	3932120	to produce general AI. So that's not an aesthetic quest, it's more of a scientific quest. And but
3932120	3935800	if you're interested in that, I think that's fascinating. But I also just think, just literally
3935800	3940840	take all these ideas and go like do Poet, but do it in some totally wild and crazy different domain,
3940840	3946440	or do an innovation engine in, you know, like architecture or poetry and see what happens,
3946440	3952120	you know, you can use new tools like GPT-3 or Dolly, etc. So I think there's just a lot of
3952120	3958120	low-hanging fruit here to be explored. Certainly. And that also reminds me of what you mentioned,
3958120	3965320	we didn't optimize to create a microwave. We explored different things and I think that
3965320	3972440	your advice is quite in that direction. Also, Joseph has a question. Joseph, would you like to
3973880	3981080	ask it yourself or? I wasn't able to get my mic working earlier. Let me just
3982280	3990360	fix that. Hi, Jeff. I was just wondering if you've explored anything on Poet in multi-agent settings
3990360	3995240	to this point. Yeah, the short answer there is that we have a lot of really exciting ideas.
3996120	3999720	For how we want to take advantage of that. I can't share those specific ideas
4000760	4005800	because we may or may not be working on them. But I also think in the spirit of the talk that
4005800	4011320	the best way to make advances is to have a community of people with different ideas pushing
4011320	4015560	different directions because you never know what's going to unlock. So I almost don't want to give you
4015560	4018760	too many ideas either because I don't want to cause conversion thinking. I think it's almost
4018760	4022760	better if there's so many different ways you could apply the concepts of Poet to multi-agent
4022760	4028280	settings that I don't think you can go wrong. I think if many different people and groups push
4028280	4033880	on that, really good things will happen. Fair. We also may or may not be working on that, right?
4036760	4041800	The one thing I wanted to ask you specifically about that is whether you figured out one,
4041800	4047880	maybe you can't tell me, but any way to get around the problem where in multi-agent settings,
4047880	4053800	sometimes you don't have a single evaluation metric that correlates the environment difficulty
4053800	4058840	with agent performance because you add more agents in, well, then the performance goes down
4058840	4062920	because there are more of them and they're all doing smarter things. So that sort of thing has
4062920	4068920	thrown a wrench in the whole annex measure. Yeah, that's right. So one of the things you could switch
4068920	4077240	to is a notion of agent versus agent. Like if an agent is as opposed to doing better on that
4077240	4083480	environment, it's that agent versus other agents or agents that have come before. Another thing
4083480	4087960	you could do is you could switch to more of a learning progress metric, which is if they're
4087960	4096200	getting better, are they learning? According to some measure, like does their value function,
4097480	4102120	their prediction of how well they're going to do, is that wrong? It's because they were either
4102120	4105880	better or worse in that situation and versus those opponents than they thought they were,
4105880	4110440	and measures like that could really catalyze, recognizing this is still an interesting environment
4110440	4113800	because they're learning. This is still an interesting matchup between this opponent and
4113800	4118040	this opponent because they're learning. I mean, we've been actually trying to do something very
4118040	4124440	similar there. It still seems to run into the same sort of issue though, right? If you can't
4124440	4128840	measure absolute performance, it can still be difficult to then measure relative performance
4128840	4134440	because your reward peak can be going down even if you are learning because so are all the other
4134440	4139240	agents. Sometimes you have to run as fast as you can just to remain in the same place.
4139800	4148920	Yeah, pretty much. That's the red queen quote from Alison Wonderland. Yeah, these are all challenges
4148920	4152200	and it's the kind of challenge that happens once you get into the multi-agent setting.
4152200	4156600	So I think this is just for a lot of experimentation and hard thinking has to happen. I don't think
4156600	4162120	there's a really super, short, easy, obvious answer. It's just going to require research.
4162120	4166280	Well, I mean, I look forward to seeing what setting it is that you're trying that out in
4166280	4169480	whenever that gets published. Likewise, yeah, with your work.
4171960	4177480	Thanks. Excellent. Are there questions? Any more questions?
4185400	4191480	Guys, don't be shy. If you have questions, just go ahead. Of course, if Jeff has time.
4192360	4196360	I have time. I just also want to be cognizant of Joel and giving him his proper time.
4197960	4207640	Excellent. Okay, cool. Thank you. All right, then let's thank you again, Jeff. It was really,
4207640	4209320	really interesting and inspiring.
