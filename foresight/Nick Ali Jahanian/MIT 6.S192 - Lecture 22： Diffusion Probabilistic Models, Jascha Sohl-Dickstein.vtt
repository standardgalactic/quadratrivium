WEBVTT

00:00.000 --> 00:03.000
This meeting is being recorded.

00:03.000 --> 00:11.000
Hello, everyone. Welcome to your course, AI for Art, Aesthetics, and Creativity.

00:11.000 --> 00:22.000
Today we have a very special speaker, Joshua Soldiksten, who is a Senior Research Scientist

00:22.000 --> 00:34.000
at Google Brain, and he is one of the pioneers of diffusion models and deep learning.

00:34.000 --> 00:43.000
At least in the, as far as I can see in the literature for the area of deep learning,

00:43.000 --> 00:49.000
but he can tell me more and correct, tell us more and correct us.

00:49.000 --> 01:04.000
So let's ask Joshua to, if you would like to share a little more about his interest and what he inspires him, and then start from there.

01:04.000 --> 01:13.000
Great. Yeah, so I wasn't prepared for the interest question, but I've done a lot of different things.

01:13.000 --> 01:22.000
I mean, most in the science, but I worked on the Mars rovers after graduation, and then I went into the PhD in biophysics, and then I did computational neuroscience,

01:22.000 --> 01:27.000
and then I worked in the computational neuroscience lab, and then I started doing machine learning.

01:27.000 --> 01:36.000
And so I don't know if there's like any single coherent thread, except that I'm chasing things that I think are really, really cool.

01:36.000 --> 01:44.000
And I will say I get like an amazing sense of satisfaction from figuring things out that like no one has ever figured out before.

01:44.000 --> 01:50.000
And I think that might be one of my driving motivations.

01:50.000 --> 02:05.000
And so I think creating something new is maybe one of the most satisfying parts I feel about science, and maybe something else, something that you also feel if you're like creating art.

02:05.000 --> 02:11.000
Cool. So thanks for the invitation for being here. I hope this will be a fun talk.

02:11.000 --> 02:23.000
I'm going to tell you about diffusion probabilistic models, especially I'm going to tell you about content from these two papers in the lower right.

02:23.000 --> 02:32.000
Ali already said this a few times, but pretty please interrupt me with questions through the talk. It's like so good to get feedback from the audience from giving a remote talk.

02:32.000 --> 02:41.000
I also actually left time in the talk for questions. So if you don't ask any questions, then we're going to end up comfortably early.

02:41.000 --> 02:46.000
Cool.

02:46.000 --> 03:06.000
So before I dive in at all, I just want to start by calling out my collaborators, especially Eric and Eru and Surya on the 2015 paper and Abhishek, Ben, Dirk, Stefano and Yang on the 2021 paper.

03:06.000 --> 03:28.000
Maybe a particular call out to Yang Song, who was the first author on the most recent ICLR paper and did like an absolutely incredible job, as well as to maybe Ben Pool, who was Yang's primary mentor, and also deserves an outsize share of the credit.

03:28.000 --> 03:36.000
I'm going to spend most of this talk diving into the nuts and bolts of this class of models.

03:36.000 --> 03:47.000
Since this is an AI plus creativity class though I wanted to just start by sharing some of the ways this kind of model is already being used to create art.

03:47.000 --> 04:07.000
Maybe the first of these is there is this group of artists on Twitter, and I suppose probably in real life too, using classic techniques called guided diffusion to generate amazing images conditioned on textual pumps.

04:07.000 --> 04:17.000
And so here we see two different examples of this. Here we see the prompt is a surreal album cover depicting a boost of eternal dread, hashtag pixel art.

04:17.000 --> 04:27.000
And actually putting things in pixel art in the prompt tends to make it the model produced images that might be more likely to appear with that hashtag, and so that's actually part of the prompt.

04:27.000 --> 04:47.000
And you get some images that could be interpreted as a boost of eternal dread, or on the right you prompt is a snowstorm in Los Angeles, and you are able to produce some images that are like the models imagining what a snowstorm might look like in Los Angeles.

04:47.000 --> 05:01.000
And at least to my eyes I'm surprised and impressed by the quality of the results they can get in this way.

05:01.000 --> 05:11.000
The second of these maybe more creative uses that I'm aware of is work that uses diffusion to turn very rough sketches into high quality images.

05:11.000 --> 05:31.000
So here in the top you can see some rough sketches of a few different scenes, and then in the bottom you can see the fusion process running to turn those rough sketches into detailed imagined scenes.

05:31.000 --> 05:49.000
So I also think that this is a pretty cool example of the potential for creative use of this class of models.

05:49.000 --> 06:02.000
Okay, so shared some creative uses of diffusion models, but structure for the rest of the talk is going to look something like this.

06:02.000 --> 06:10.000
I am going to provide some physical intuition for what we're going to be doing.

06:10.000 --> 06:14.000
Then I'm going to work to make that physical intuition more mathematically precise.

06:14.000 --> 06:26.000
Then I'll show how we can generate samples from the model, and then I'll tell you about some surprising connections between diffusion processes and neural ODS, which you may or may not have already heard about.

06:26.000 --> 06:33.000
And then I'll show how we can sample and evaluate conditional distributions.

06:34.000 --> 06:42.000
At a super high level, we're going to use diffusion to destroy any structure in our training data.

06:42.000 --> 06:55.000
Then we're going to carefully characterize this destruction of structure, and we're going to reverse time, and we're going to run the destructive process backwards to build a generative model of the data.

06:55.000 --> 07:08.000
Training a model to reverse time maybe sounds a little bit crazy, but there may be two observations we can make that highlight its causability.

07:08.000 --> 07:19.000
The first of these observations is that we can use diffusion to destroy the structure in our data distribution.

07:19.000 --> 07:28.000
Here I want you to imagine, and this is going to be very much trying to ground this on my physical intuition, which if you have a physics background you might like, otherwise I apologize.

07:28.000 --> 07:38.000
Here I want you to imagine that the density of dye molecules represents a probability density, and our goal here is to learn this probability density.

07:38.000 --> 07:43.000
This is typically a very challenging thing to do.

07:43.000 --> 07:56.000
But even if we can't build a model of the structure in our data distribution directly, what we can do is we can map our data distribution to a much simpler distribution that we can model.

07:56.000 --> 08:12.000
So in this physical example, if we allow diffusion to continue long enough, then eventually the dye molecule would be evenly distributed in the jar, and we'd have a uniform distribution.

08:12.000 --> 08:29.000
It's maybe not immediately clear that this is helpful, but what if we could reverse time and run this process backwards? What if we could start at a uniform distribution and generate the data distribution?

08:29.000 --> 08:36.000
In physics, this is overwhelmingly unlikely to happen spontaneously.

08:36.000 --> 08:48.000
Liquids don't spontaneously unmix any more than a shattered glass will spontaneously reassemble, but we can maybe use machine learning to do it.

08:48.000 --> 09:00.000
And to see our first clue as to why this might be possible, let's zoom in on a small volume of fluid here.

09:00.000 --> 09:12.000
So Q super exciting keynote zoom effect.

09:12.000 --> 09:34.000
So the first clue that time reversal might be possible is that although there's this concept of macroscopic irreversibility where the reverse trajectory is overwhelmingly less probable than the forward trajectory from the microscopic perspective.

09:34.000 --> 09:39.000
The picture is completely different and is symmetric.

09:39.000 --> 09:47.000
So here we've zoomed in and now each bright spec corresponds to a single dye molecule undergoing diffusion.

09:47.000 --> 09:57.000
And if we were in person, I'd ask you whether this video was like being played forwards or backwards, but I'm just going to tell you that this video is being played backwards in time.

09:57.000 --> 09:59.000
And here I'll flip it around.

09:59.000 --> 10:04.000
And now it's the same video, but it's being played forwards in time.

10:04.000 --> 10:19.000
And you can see that despite like flipping the arrow of time, the motion of the dye molecules, the behavior of the dye molecules looks looks completely identical and make that more concrete.

10:19.000 --> 10:25.000
The diffusion kernel has the same functional form both both forwards and backwards in in time.

10:25.000 --> 10:41.000
So at every time step, the next time molecule position is drawn from a very small Gaussian centered around its current position and more generally depending on situation might also be be a drift run.

10:42.000 --> 11:03.000
This is really great for us, because it means that if our forward diffusion process was a sequence of small Gaussians, then our reverse diffusion process is also going to be a sequence of small Gaussians.

11:03.000 --> 11:17.000
And I'm showing this in continuous state space. I'm not going to talk about it today, but you can do the same thing for like diffusion over binary variables.

11:17.000 --> 11:29.000
All right, this is probably a good time to pause for questions for a question and also barking dog, which you may or may not be able to hear.

11:29.000 --> 11:34.000
Yes, you can definitely hear the dog.

11:34.000 --> 11:40.000
Cool.

11:40.000 --> 11:47.000
So just to maybe do a summary slide away, I told you we're going to use the fusion process to destroy all the structure in the data.

11:47.000 --> 11:53.000
And then we're going to learn the reversal of this diffusion process.

11:53.000 --> 12:06.000
And learning the reversal of this fusion process is going to end up being requiring estimating a function for the mean and covariance of each step of the process.

12:06.000 --> 12:27.000
And that reverse diffusion process is going to form our model of the data.

12:27.000 --> 12:37.000
So maybe just to illustrate what this means for real data, we might start with data points corresponding to images on the left.

12:37.000 --> 12:44.000
And running diffusion on these data points will correspond to mixing in more and more and more random noise to the images.

12:44.000 --> 12:53.000
And after some amount of time will be left, we'll erase all the structure and we'll just be left with a color of noise.

12:53.000 --> 13:16.000
In the right image, we see a 1D example. Here the x-axis is time and we are diffusing a 1D bimodal distribution into a 1D Gaussian.

13:16.000 --> 13:27.000
And we're going to learn the time reversal of this process. We'll be able to generate data samples by running the diffusion process that starts at noise and ends at the data distribution.

13:27.000 --> 13:36.000
And here we see this go through the images where a noise sample corresponds just a color noise image and ends up as a sampled image.

13:36.000 --> 13:47.000
And on the right you can see this for the simple 1D distribution.

13:47.000 --> 14:00.000
Okay, so I've just tried to provide intuition for what is going to happen and I'm about to dive into a bunch of math.

14:00.000 --> 14:24.000
So this is an excellent time to pause and poll for questions if anyone has anything they want to ask about.

14:24.000 --> 14:30.000
Maybe I can ask a question. If you could please go to the previous slide.

14:30.000 --> 14:51.000
In order to understand a little more of this slide. So you are saying you are sort of introducing noise in 1D. Does it mean that you are showing the noise that over time you're adding to each pixel?

14:51.000 --> 15:01.000
Yeah, so maybe something that's implicit in the slide which I should describe explicitly.

15:01.000 --> 15:12.000
So here on the right pane we're showing the evolution of samples in like a 1D distribution.

15:12.000 --> 15:19.000
So in the left in the right pane just like in the left pane there are four samples and they're evolving in 1D.

15:19.000 --> 15:31.000
If you take an image you can think of an image as being like a really long vector of length like number of pixels times number of colors.

15:31.000 --> 15:40.000
So if you have like a thousand by a thousand image with three colors then it will be like a vector of length like three million.

15:40.000 --> 15:49.000
And so then what we're doing is we're doing the same thing we're doing on the right but we're doing it in this like three million dimensional space instead of this like one dimensional space.

15:49.000 --> 15:58.000
So like you can think of that image as being a point in this three million dimensional space and we're just diffusing the image like through the space.

15:58.000 --> 16:13.000
And if you look at what that looks like that looks like noise being mixed into the image as you like take the image and like diffuse each of its coordinates by this process.

16:13.000 --> 16:16.000
Perfect, thank you so much.

16:16.000 --> 16:24.000
Thank you for the question.

16:24.000 --> 16:30.000
Yeah, so so making this a little bit more mathematical.

16:30.000 --> 16:36.000
We're going to start with samples from a data distribution Q of X zero.

16:36.000 --> 16:48.000
So Q of X zero might for instance be like the distribution over natural images so it might be many many many examples of images.

16:48.000 --> 17:02.000
And for every forward diffusion step, we are going to decay the slide sample slightly towards the origin and add a small amount of Gaussian noise.

17:02.000 --> 17:21.000
And this this corresponds to diffusion in a quadratic well or harmonic well. And if you run this for enough steps, then at the end we're going to end up with an identity covariance Gaussian distribution centered at at the origin.

17:21.000 --> 17:38.000
So this is going to be our forward diffusion process, which is going to take your sample X zero and destroy all destruction your sample X zero until by X capital T, you just have like a random noise vector.

17:38.000 --> 17:47.000
And here once again illustrating this we're going to start with a whole bunch of points. And here you've seen a one day example and like a three million D example and here's like a 2D example.

17:47.000 --> 17:57.000
Here we're taking a bunch of points that originally have some like structure and we're mixing diffusing them until they have no structure left.

17:57.000 --> 18:04.000
Now for the reverse process, we're going to start at the identity covariance Gaussian.

18:04.000 --> 18:10.000
And because we know that the reverse process is the same functional form as the board process.

18:11.000 --> 18:24.000
We know that the reverse distribution of trajectories can match the forward distribution. If we also make it a sequence of small Gaussians.

18:24.000 --> 18:35.000
And so here we have to do is we have to learn the mean and the covariance of these Gaussians.

18:35.000 --> 18:42.000
And so if we find the right functions f mu and sigma and you make our step size small enough.

18:42.000 --> 18:52.000
Then then after running like big T steps of the reverse diffusion process will end up back at our data distribution.

18:53.000 --> 19:03.000
F mu and sigma here are going to be like super complicated functions. These are these are like the outputs of like state of the art neural networks.

19:03.000 --> 19:15.000
But what's nice about this is we've like transformed the problem of building a density model into the problem of learning functions for the mean and the covariance of a sequence of Gaussians.

19:15.000 --> 19:23.000
You can see in a second that this is basically going to be a supervised regression problem.

19:23.000 --> 19:37.000
You can see this this illustrated. So you start with a noise sample and your general process is going to like run a diffusion process which which turns that noise sample into into samples of the data.

19:37.000 --> 19:45.000
Here's just illustrating the same thing with like a cartoon panel.

19:45.000 --> 19:55.000
Ah, the well that we ended up at I called it a quadratic well. That's that's to respond to a to a question in the chat.

19:55.000 --> 20:00.000
Or or in physics sometimes they call it a harmonic well.

20:00.000 --> 20:19.000
So basically if you run if you run diffusion diffusion and energy landscape, which is a quadratic, then then the particles rather than just like drifting away to infinity will like will like, you know, diffuse and drift, but they'll kind of stay roughly around the origin because the quadratic energy landscape likes

20:19.000 --> 20:23.000
pulse them back in.

20:23.000 --> 20:29.000
Okay, so this is going to be the mathematical high water part our watermark probably.

20:29.000 --> 20:41.000
So how do we train these things. We're going to do it using using a variational bound that's essentially identical to that in in hierarchical days.

20:41.000 --> 20:53.000
So the probability that the generative model assigns to a data point can be found by integrating over all trajectories that end at that data point.

20:53.000 --> 21:04.000
This integral is intractable to compute, but we can borrow a technique called called an important sampling to to

21:04.000 --> 21:17.000
multiply and divide by the probability of the four diffusion trajectory, which which is Q of x one the capital T given X zero

21:17.000 --> 21:28.000
P X zero is now an expectation over the ratio of the four in reverse trajectory probabilities averaged over for trajectories.

21:28.000 --> 21:37.000
We want to train our model by maximizing the log likelihood of the data under the model.

21:37.000 --> 21:43.000
And this this corresponds to taking the average over the data distribution Q X zero.

21:44.000 --> 21:56.000
This up after the data distribution Q X zero of the log of P X zero and here I just substituted in this form up here into the log of P X zero.

21:56.000 --> 22:00.000
Intervals inside logs are pain in the ass.

22:00.000 --> 22:13.000
So we use Jensen's inequality to lower bound the log likelihood and and bring the integral outside the log.

22:13.000 --> 22:18.000
If the forward and reverse distributions over trajectories exactly overlap.

22:18.000 --> 22:28.000
So if the P and Q distributions describe exactly the same trajectory, then distribution of trajectories in this lower bound becomes becomes type.

22:28.000 --> 22:39.000
This everything we've just done is also equivalent to writing down the variational bound for like a very, very, very deep variational encoder.

22:39.000 --> 22:45.000
We're each time step here corresponds to a layer of the variational encoder.

22:45.000 --> 22:54.000
And and where the inference distribution Q is fixed and we're only learning the general distribution P.

22:54.000 --> 23:01.000
Yeah, Q is the the, let me go back a second.

23:01.000 --> 23:18.000
Q is the forward diffusion process Q is the distribution over over X at every time step that starts from your data and injects a little bit of Gaussian noise at every time step until until you get to the model.

23:18.000 --> 23:33.000
I'm sorry until you get to the prior until you get to like the isotropic Gaussian.

23:33.000 --> 23:37.000
Okay, where worry.

23:37.000 --> 23:41.000
So, if we do a little bit more algebra on this.

23:41.000 --> 23:58.000
You can rearrange this into a some over kale divergences between the, the posterior from the forward trajectory, which is that first term inside the kale.

23:58.000 --> 24:09.000
And the reverse trajectory, which is that second term inside inside the kale.

24:09.000 --> 24:19.000
And this is just a sum over this across across every time step. And the beautiful thing about this is that both of these distributions are Gaussian.

24:19.000 --> 24:32.000
The second one is Gaussian because like the entire forward diffusion process conditioned on the data sample is Gaussian. And so this is just a conditional distribution of that big joint Gaussian distribution, which is also a Gaussian.

24:32.000 --> 24:50.000
And the second one is Gaussian, because we know it has the same functional form, the reverse process of the same functional form and supported process. And just as reminder, this is the functional form of the reverse diffusion process.

24:50.000 --> 25:15.000
So we can write down our training objective. And our training objective is to minimize an expectation over training data and over time steps of this kale divergence between the forward posterior and reverse distribution for a single for a single step.

25:15.000 --> 25:26.000
And the kale divergence between two oceans has a super simple functional form, which basically just reduces to to regression.

25:26.000 --> 25:43.000
So, so we've transformed our like unstructured unsupervised learning problem into into a supervised regression problem. And, and we know how to, we know how to solve those.

25:43.000 --> 26:01.000
So this is the hardest part in the whole talk. So I'm going to pause here for like, like 15 seconds.

26:01.000 --> 26:06.000
Could you give a short refresher on the kale distance.

26:07.000 --> 26:20.000
The kale distance between two distributions is a information theoretic measurement of how similar the two distributions are to each other.

26:20.000 --> 26:25.000
It has some some nice properties.

26:25.000 --> 26:28.000
One of those properties is

26:29.000 --> 26:56.000
So one interpretation of the kale between like Q and P is it tells you how many bits it would, how many, how inefficient, how many bits you would lose if you tried to describe distribution P, but thought it was distribution Q.

26:56.000 --> 27:04.000
So it tells you like by how many bits your model is like an efficient inefficient.

27:04.000 --> 27:18.000
It also is like closely connected to log likelihood in that if you take the kale divergence between the data distribution, the model distribution. This is equal to

27:18.000 --> 27:24.000
a constant minus the log likelihood of the model.

27:24.000 --> 27:35.000
But I think just in general you should think of KL as being a measure of distance between two probability distributions.

27:35.000 --> 27:54.000
So you mentioned the, I guess, beautiful property of the kale distance of two Gaussians can simplify the problem. So what if, you know, there'll be let's say a different type of noise, then I guess it wouldn't necessarily simplify.

27:54.000 --> 28:08.000
Yeah, yeah, if you had if you had different types of noise, you would, depending on type of noise you very likely would not be able to just like analytically write down the form, you would still be able to optimize it.

28:08.000 --> 28:15.000
You would just have to use

28:15.000 --> 28:23.000
the thing that you can do analytically here is we can marginalize over over X of t minus one

28:23.000 --> 28:37.000
in in this expression and this this I haven't I haven't written down the order of this but but the reason that the calibrating two Gaussians is really nice is because you've been just like marginalized out the X t minus one and that gives you a much lower variance estimate

28:37.000 --> 28:55.000
of the loss in the radium. If you use a different form for the noise, then you would probably have to sample X of t minus one, and that would probably be a much higher variance estimate for for your learning signal, but but you could probably

28:55.000 --> 28:57.000
still do it.

28:57.000 --> 29:01.000
And something like heavy tail noise might be might be really interesting.

29:01.000 --> 29:07.000
There's a question for why we do KLQP instead of KLPQ.

29:07.000 --> 29:11.000
So,

29:11.000 --> 29:16.000
in general, we tend to do KL from the data to the model.

29:16.000 --> 29:23.000
And the reason for that is probably because of the connection between KL divergence and log likelihood.

29:23.000 --> 29:43.000
What we're often interested in is the log probability of the data points under model, and that means you have to take an expectation over over the data. So you want to like average over your training data of the difference between the two.

29:43.000 --> 29:54.000
I think also, it can be very difficult to compute the other way around, because we don't know what the log like we're trying to fit the log probability of the training data.

29:54.000 --> 30:11.000
And if you flip the KL around, then you have terms that look like samples from the model of the log of the data distribution, and we don't know how to evaluate those in general, which is another reason that we usually go from from Q to P using our formulation

30:11.000 --> 30:14.000
here.

30:14.000 --> 30:30.000
Yeah, so this optimization process, or at least the specific loss that we get depends on us having defined the noise like we chose the noise right like we we chose that the noise is is a bunch of like small Gaussian

30:30.000 --> 30:51.000
perturbations. And, and that's what makes the specific form possible is if you use this for your noise than the entire forward trajectory. So like Q of X of one to X capital T given X zero is just one big joint Gaussian, and a lot of things become easier once once your entire forward

30:51.000 --> 31:04.000
trajectory is one big joint Gaussian.

31:04.000 --> 31:11.000
Cool. Alright, so now I'm going to connect this to stochastic differential equations.

31:11.000 --> 31:16.000
So I just presented this in in discrete time.

31:16.000 --> 31:30.000
But if we take the step sizes to be smaller and smaller and smaller, then we can turn this discrete diffusion process into a limiting stochastic differential equation.

31:30.000 --> 31:45.000
It turns out to be extremely useful and to have some some very nice properties as as before, we're going to gradually mix noise into our data distribution until it turns into Gaussian.

31:45.000 --> 31:53.000
And, and as I just said, this is the continuous time limit of the discrete diffusion process I saw the moment ago.

31:53.000 --> 32:01.000
So here our data distribution is P sub zero. This is a slight change in notation, not a big one.

32:01.000 --> 32:19.000
And P sub T is the intermediate distribution from running this stochastic process for a time interval T, and then P capital T is the final final distribution which should look like just noise.

32:19.000 --> 32:31.000
So and little T here is between zero and big T. And so an SDE is a generalization of ordinary differential equations.

32:31.000 --> 32:39.000
And so we can write it down like this. And here the green term is what you would normally have in an ODE.

32:39.000 --> 32:44.000
And it governs the deterministic properties of the stochastic process select the drift.

32:44.000 --> 32:53.000
And the red term is the noise that the red term controls like the stochastic fluctuations of the process.

32:53.000 --> 33:04.000
So here you should think of DW as being infinitesimal Gaussian noise or like Brownian motion.

33:04.000 --> 33:12.000
So we've now replaced the forward process with its continuous time limit, which is stochastic differential equation.

33:12.000 --> 33:16.000
And we can do the same thing with the reverse process.

33:16.000 --> 33:30.000
One really surprising aspect of stochastic differential equations is that given their equation forward of time and given the marginal distribution PT at time T,

33:30.000 --> 33:37.000
the time reversal of the SDE has a very simple analytic form.

33:37.000 --> 33:46.000
In reverse SDE, here DT is going to be an infinitesimal negative time step.

33:46.000 --> 33:51.000
And DT is going to be an infinitesimal negative time step.

33:51.000 --> 34:01.000
And DW is still Brownian motion or DW is still Brownian motion or like little Gaussian perturbations.

34:01.000 --> 34:16.000
And if we know the gradient of log PFT with respect to X, then that's all the information we need to like define the reverse SDE, the time reversal of the SDE.

34:16.000 --> 34:25.000
And here the gradient of log PFT is the quantity which is often known as the score function.

34:25.000 --> 34:34.000
And so we can train an approximation S of theta to this score function.

34:34.000 --> 34:47.000
And the way in which you train this is using the continuous time limit of the same variational down to the log likelihood I showed like in the previous section.

34:47.000 --> 34:57.000
So basically you can train this thing exactly the same way that you train the discrete time version.

34:57.000 --> 35:03.000
There's also connection to denoising score matching, but I don't think it really matters here.

35:03.000 --> 35:13.000
You can train this using the same way.

35:13.000 --> 35:22.000
So okay, so this is just the continuous time limit of the discrete time diffusion for that version before.

35:22.000 --> 35:36.000
And maybe the thing that's really neat about it is we can now link these like drift terms that we were estimating to this thing called a score function,

35:36.000 --> 35:46.000
which is like a simple and known property of the distribution PFT.

35:46.000 --> 35:51.000
Okay, and so now we've defined the model two different ways.

35:51.000 --> 35:53.000
And we've talked about how to train the model.

35:53.000 --> 35:56.000
So let's talk about how to sample.

35:56.000 --> 36:04.000
And then let's look at some some pretty samples.

36:04.000 --> 36:10.000
So after training our model, I mean the sweet timer score base, I'm going to show you a score base here.

36:10.000 --> 36:18.000
So score base, we generate samples by, by just numerically integrating the reverse SD.

36:18.000 --> 36:26.000
So, so mind you, we've approximated grading of log PFT with our function s.

36:26.000 --> 36:32.000
And you can use any off the shelf SD integrator to solve this.

36:32.000 --> 36:40.000
The simplest of these is, is called the Euler-Mariama solver.

36:40.000 --> 36:52.000
And this is just the, the discrete time discretization of this SD, which actually maps us back to the discrete time diffusion process,

36:52.000 --> 37:07.000
where at every, at every time step, you like change X, you change your sample by that looks like this term times a finite changing T.

37:07.000 --> 37:15.000
And then you add a little noise with variance proportional to delta T.

37:15.000 --> 37:24.000
And you just run this over and over and over again, until you get back a sample.

37:24.000 --> 37:33.000
So this is, this is the, maybe the most naive discretization of the SD.

37:33.000 --> 37:37.000
Okay.

37:38.000 --> 37:54.000
If you maybe went at the sample generation procedure the right way, then, then we're actually training and generating samples with a neural network, which is like thousands of layers deep, where each layer is like a time step into the diffusion process.

37:54.000 --> 38:01.000
And, and so this can be interpreted as like an extraordinarily deep general model.

38:01.000 --> 38:15.000
If you squint that at a slightly different length, then we're proposing a general model, which has like thousands of times the compute cost of most general models, which is maybe not quite as exciting as saying thousands of layers deep.

38:15.000 --> 38:22.000
But, but it will turn out there are ways to make, to make the sampling process more efficient.

38:22.000 --> 38:26.000
And I'm going to show you one of them in the talk.

38:26.000 --> 38:30.000
Okay, so, so what can you do with this thing?

38:30.000 --> 38:34.000
Well, here are some example samples.

38:34.000 --> 38:41.000
These are samples from a diffusion model that we built trained on celebe HQ.

38:41.000 --> 38:45.000
These are 1024 by 1024 images.

38:45.000 --> 38:52.000
I don't know how high resolution they are after after some to me, these are like in this English full from from real human beings.

38:52.000 --> 38:59.000
So, so, so we've like crossed over the uncanny valley.

38:59.000 --> 39:08.000
So, numerically, this class of models currently beats autoregressive models.

39:08.000 --> 39:17.000
In terms of log likelihood where autoregressive models were the winners. This is not my work. This is a paper of dirt King was in Tim Solomon's.

39:17.000 --> 39:28.000
They also began in terms of like at by the inception score on some data sets. So, for instance, image that five full by five fall, again, not my work.

39:28.000 --> 39:37.000
So these things seem to be remarkably good generative models of images.

39:37.000 --> 39:46.000
They also enable you to do some cool things that you can't do with with other other techniques.

39:46.000 --> 39:49.000
Let me actually just to time this.

39:49.000 --> 39:57.000
Should I expect to end sharply attend or should I expect to take them extra like.

39:57.000 --> 39:59.000
Yeah, take your time.

39:59.000 --> 40:14.000
You know, as much as you would like because typically we end this course, even after you are done with your lecture, we may stay a little more and chat about things.

40:15.000 --> 40:24.000
Okay, cool. I will not take forever, but I will I will not try to do to the last last slides in four minutes as well.

40:24.000 --> 40:41.000
I'm actually it's probably really good time for me to pause for a second and see if there are any questions. So,

40:41.000 --> 40:49.000
Okay, I'm going to keep on going. I'm going to tell you about these stuff.

40:49.000 --> 41:04.000
One really cool thing is that any SD can be transformed into a corresponding ordinary differential equations non stochastic differential equation.

41:04.000 --> 41:17.000
Without changing the marginal distributions pt of x, that is, there is an ODE, which has the same distribution over x at all times t.

41:17.000 --> 41:25.000
And so this corresponding ODE would allow us to sample from the same distribution starting from the same prior distribution.

41:25.000 --> 41:32.000
But by solving ODE instead of an SD, this is this is here is what the ODE looks like.

41:32.000 --> 41:43.000
We show the SDH trajectories in red, and the ODE trajectories in, in white, and they both the SD and the ODE are starting from the same points.

41:43.000 --> 41:55.000
And you can see that the SD is a stochastic trajectory that converts the starting distribution final distribution easy the ODE.

41:55.000 --> 42:12.000
Similarly, trace has the same marginal distribution at every time point, so it starts from the same distribution, and then it ends up the same distribution, but it does this in a deterministic way.

42:12.000 --> 42:22.000
Given the SDE, the corresponding ODE, this is just the general general relationship between SDEs and ODE's.

42:22.000 --> 42:37.000
Given the SDE, the corresponding ODE, like once again only depends on the score function of pt, for which we already learned, we've already learned the estimator for the score functions.

42:37.000 --> 42:58.000
So, so this is just S of, S of theta. So, if we want to generate samples, we can generate samples by integrating this ODE instead of by integrating the SDE.

42:58.000 --> 43:06.000
This kind of blew my, so Yang is the one who realized you could do this, and this kind of completely blew my mind when he shared that we could do this.

43:06.000 --> 43:27.000
So, so I hope, I hope at least some fraction of you are similarly like scandalized that you can turn SDEs and ODE's like this.

43:27.000 --> 43:46.000
So, the question is, are there benefits to modeling with an SDE if there is an ODE equivalent, and the, the two parts to, to the answer.

43:47.000 --> 43:59.000
Part number one is the SDE formulation is what allows us to train it. So, so we have to at least like conceptually go through, through SDE space in order to train it.

43:59.000 --> 44:17.000
Part number two is that we're training this function S theta to match the score function, but in practice, this function S of theta probably does not correspond to the gradient of any well defined like log probability distribution.

44:17.000 --> 44:28.000
Like if we were to train S of theta perfectly, then we would have S of theta is equal to like gradient of X of log P of t, but in actuality S of theta, it's just like a vector.

44:28.000 --> 44:35.000
And it probably is not a vector that actually corresponds to the gradient of the log probability.

44:36.000 --> 44:52.000
And, and because of that inconsistency in the definition of S of theta, you actually get slightly different distributions if you integrate the ODE and integrate the SDE.

44:52.000 --> 44:58.000
And visually, if you integrate the SDE, the samples tend to look just a tiny bit better.

44:59.000 --> 45:15.000
But, but I think we don't, we don't fully understand why, but the, the reason distributions are a little bit different is because we're violating this assumption that like S of theta is actually the, the gradient of, of the log marginal density.

45:22.000 --> 45:36.000
Okay, so we have this ODE. If you've heard of neural ODE, you can think of this as being like a specific example of a neural ODE, because like S of theta is a super complicated neural network.

45:37.000 --> 45:50.000
What's really cool is once you have an ODE, you can use just like off the shelf ODE solvers to, to generate samples and like ODE solvers are like really remarkably good.

45:50.000 --> 46:03.000
I didn't, I didn't realize quite how good they were in that they can like just off the shelf ones can just like generate like a few million dimensional like samples from a super high dimensional ODE.

46:04.000 --> 46:16.000
So here, for instance, is the samples you get from running the an adaptive ODE sampler with a different allowed number of samples.

46:16.000 --> 46:32.000
And you can see that after maybe like 86 this samples from the ODE solvers, so allowing the ODE solver to evaluate the, the ODE equation at like 86 time points.

46:32.000 --> 46:38.000
You get what's a pretty high quality image, whereas it takes like thousands for, for the SDE.

46:38.000 --> 46:54.000
The other thing you can do with ODE is you can compute an exact log probability for four data points, which means that you can get exactly like this.

46:54.000 --> 46:57.000
We can, I can show you a table of performance.

46:58.000 --> 47:03.000
Our numbers are bold. This table is now like almost a year old because our paper is now almost a year old.

47:03.000 --> 47:16.000
But, but take home message is this class of techniques works like surprising the well both in terms of log likelihood and in terms of measures of perceptual performance like like FID.

47:16.000 --> 47:25.000
And I want to tell you about one more thing before, before I break, but maybe this is another good place to pause for a second.

47:25.000 --> 47:27.000
If there are any questions about the ODE.

47:27.000 --> 47:56.000
Okay, cool. Let me tell you about one more thing, which may actually be one of the most relevant things if you want to use this class of models for, for like creative applications, which is that there is a very well motivated way to control generation under under this class of models.

47:58.000 --> 48:05.000
So, just to back up a second.

48:05.000 --> 48:15.000
At training time, we return our data sample X zero by running our SDE and we get a noise sample.

48:15.000 --> 48:20.000
We want to perform control generation at test time.

48:20.000 --> 48:27.000
So we want to be given, we're going to be given a control signal, which I'm going to know is why here.

48:27.000 --> 48:33.000
So, for instance, why might be a class label.

48:33.000 --> 48:43.000
And so the forward diffusion process will then perturb a conditional data sample X zero given why to complete noise.

48:44.000 --> 48:48.000
And by reversing this procedure.

48:48.000 --> 49:09.000
We should be able to start from isotropic Gaussian noise ball and obtain a sample X zero given why the reverse time procedure condition and why can be given by the following conditional reverse time SDE.

49:09.000 --> 49:20.000
So here, all we've done is we've just replaced the score function of PT with the score function of PT of X, given why.

49:20.000 --> 49:22.000
So this is nice.

49:22.000 --> 49:33.000
But at first sight, this seems like you have to train a whole bunch of like an entirely new model, because the conditional distribution is function of T is unknown.

49:33.000 --> 49:38.000
But what we can do is we can apply basis rule to this.

49:38.000 --> 49:45.000
So the first term is just the unconditional score function.

49:45.000 --> 49:56.000
And is what we like already spent the rest of the talk talking about how to train exactly the same as what we were training before.

49:56.000 --> 50:02.000
The second term can be trained completely separately.

50:02.000 --> 50:09.000
From the score base model, or even sometimes can just be like written down in in close form using using the main knowledge.

50:09.000 --> 50:21.000
And so, and so the product of these two terms plus the constant is equal to to the log P of T of X given why.

50:21.000 --> 50:26.000
And I'm sorry, because these are logs, I should have said that some of these two terms.

50:26.000 --> 50:33.000
This is just this. This is just base rule applied to PT of X given why.

50:33.000 --> 50:46.000
And so, this is a particularly cool capability, because it's not something you can do at test time for like gams or VES or autoregressive models or any of these.

50:46.000 --> 50:55.000
Here we can train a ginormous like unsupervised model images, and then we can train a little classifier like PT of Y given X later.

50:55.000 --> 51:01.000
And we can use that little classifier to like guide our image generation.

51:01.000 --> 51:12.000
So one example of this is here we have a here we're making PT we're making why the actual class.

51:12.000 --> 51:24.000
And so we can use this to do like post hoc sampling of CFR 10 images that come from the class bird on the left or come from the class deer on the right.

51:24.000 --> 51:26.000
You can also do this for in painting.

51:26.000 --> 51:39.000
So here, why is the part of the image that you know, and you want to generate the entire image like conditioned on the part of the image that you actually know.

51:39.000 --> 51:43.000
And so here are the first column is the true image, the ground truth image.

51:43.000 --> 51:50.000
The second column, we've thrown away all but the part of the image that you can actually see.

51:50.000 --> 51:55.000
So you've thrown away all we've thrown away the surround or the center.

51:55.000 --> 52:04.000
And then in the remaining columns, we're showing independent samples of in painting all the missing content in in these images.

52:04.000 --> 52:15.000
And you can see that an off the shelf diffusion model not trained to do in painting can can still do a good job in painting.

52:15.000 --> 52:19.000
You can also see that there's like diversity in the images that it generates.

52:19.000 --> 52:33.000
It doesn't generate same bedroom over and over and over again it generates like a sequence of plausible in paintings of missing information.

52:34.000 --> 52:40.000
We can do this for colorization.

52:40.000 --> 52:46.000
So we can take an image we can make grayscale and then we can infer infer the colors.

52:46.000 --> 52:50.000
Cool.

52:50.000 --> 52:55.000
This also let me just actually jump way back to being talking again.

52:55.000 --> 53:01.000
This is also the same technique essentially that's used to generate these these art examples.

53:01.000 --> 53:08.000
So they're rather than using some pt of y given X as a guiding signal.

53:08.000 --> 53:14.000
They're using the output of like the clip classifier as the guiding signal and they're like multiply by some scalar.

53:14.000 --> 53:23.000
But but they are guiding the diffusion generation in the same way as as I just showed.

53:23.000 --> 53:30.000
And then using it to create novel artistic creations.

53:30.000 --> 53:36.000
Cool. Okay, so to summarize.

53:36.000 --> 53:40.000
I have shown you a general model based on diffusion processes.

53:40.000 --> 53:44.000
We first corrupt data to a known noise distribution using diffusion.

53:44.000 --> 53:51.000
And then we learn the time reversal of this diffusion process in either discrete or continuous time.

53:51.000 --> 53:59.000
And we can then generate samples by drawing a random noise vector and simulating the reverse diffusion process.

53:59.000 --> 54:03.000
There are some advantages of our framework.

54:03.000 --> 54:08.000
First, image quality is super duper high.

54:08.000 --> 54:19.000
Second, there's equivalence to neural OVs or flow models, which allows us to do things like like exact likelihood computation.

54:19.000 --> 54:27.000
I didn't get a chance to talk about this, but but I actually talked about it very briefly before before the talk proper, but

54:27.000 --> 54:35.000
our encoding is also uniquely identifiable, meaning that every well trained model will have identical latent codes for identical input data points.

54:35.000 --> 54:41.000
This is either a positive or negative depending on how you look at it, but it is a unique property of this class of models.

54:41.000 --> 54:47.000
And finally, we can do controllable generation without without retraining the model.

54:47.000 --> 54:51.000
Examples like include like class conditional generation.

54:51.000 --> 54:59.000
Including some of LA clip guided diffusion measure at the beginning.

54:59.000 --> 55:01.000
Yeah.

55:01.000 --> 55:05.000
Okay, that's what I got. Thank you so much for listening.

55:05.000 --> 55:08.000
Thank you so much. This was awesome.

55:08.000 --> 55:12.000
Really helpful.

55:12.000 --> 55:27.000
Seems that this controllable generation is really cool because once you have the sort of probability of X and then you can.

55:27.000 --> 55:44.000
So that is sort of task agnostic in a way and then whatever task you want, learn it and then use that sort of backbone that you have already trained will learn from the data.

55:44.000 --> 55:46.000
This is, this is really cool.

55:46.000 --> 56:14.000
And then I think that this fact that you can identify encoding or do the reverse process is also very cool because there is a great deal of how to, for instance, take my image and then map it to the latent space of again, so that I can modify it.

56:14.000 --> 56:17.000
Yeah.

56:17.000 --> 56:23.000
People have been trying to train inverters.

56:23.000 --> 56:31.000
They are getting better and better, but it seems that in this case, the inverter comes for free.

56:31.000 --> 56:34.000
Yeah, yeah.

56:34.000 --> 56:41.000
That's very cool. So are there questions?

56:41.000 --> 57:05.000
I think more on a high level. I mean, what, I guess, having a physics background clearly probably helped come with an idea that is, let's say, kind of, I mean, yeah, based on physical intuition, but it's so different from I guess the GAN architecture.

57:05.000 --> 57:28.000
So like, in terms of more like human creativity, like how do we have to look more into the nature to find more inspiration for those, maybe even other models that or other paradigms or what is your suggestion for people who are interested in this field?

57:28.000 --> 57:33.000
Yeah, you mean like in machine learning, how do you come up with creative different ideas?

57:33.000 --> 57:34.000
Yeah.

57:34.000 --> 57:55.000
Yeah, I mean, so definitely, I mean, I'm biased on my own background, so my answer is going to be be like me, which is not really a good answer. But no, one thing I do think is really actually good, though, is I think it's good to have, I think it's good to have a background, which is not the straight machine learning background.

57:55.000 --> 58:02.000
I think having exposure to ideas and having a novel perspective like definitely helps.

58:02.000 --> 58:24.000
I think probably even more important than that is like talking with and collaborating with people with different ideas than you. Like whatever your background is, if you can like work on a team and work closely and talk closely with people that have a very different background, then you're going to come up with ideas that no one else is going to come up with.

58:24.000 --> 58:31.000
And so I think, yeah.

58:31.000 --> 58:34.000
Very cool. I think there are questions on the chat.

58:34.000 --> 58:38.000
Yeah, I just say, yeah, I think I just saw that as well.

58:38.000 --> 58:56.000
Okay, so one question is like just out of curiosity, what happens if the initial input X zero is out of distribution. And so before the fusion process, the process that takes X zero and turns it in the noise is a is a fixed process.

58:56.000 --> 59:02.000
So it will take an action. Maybe let me open up for a second.

59:02.000 --> 59:07.000
So, um,

59:07.000 --> 59:12.000
Yeah, so just to be the

59:12.000 --> 59:15.000
Good thing.

59:15.000 --> 59:27.000
Okay, so the forward process is is a fixed process. So any sample X zero on the left here is going to get turned into a sample from an unimole calcium.

59:27.000 --> 59:36.000
And I should I should one subtle to cure which is pretty important is that every sample on the left gets mapped to the entire distribution on the right.

59:36.000 --> 59:46.000
So if you were to start from the same same sample on the left over and over and over again and run the diffusion process again, like every time you ran the diffusion process, you would get a different trajectory, and you would get a different sample on the right.

59:46.000 --> 59:58.000
So the forward process maps every single like possible input sample to the entire like PT like like isotropic calcium prior sample.

59:58.000 --> 01:00:09.000
And the reverse is also true. If you start with a sample on the right and you run the SD then you will get a sample from your model of the distribution.

01:00:09.000 --> 01:00:17.000
But if you run if you were to start from the same sample on the right over and over and over again. Every time you did that you get a different sample from your distribution.

01:00:17.000 --> 01:00:24.000
And so every sample from the prior is actually also mapped to the entire distribution.

01:00:24.000 --> 01:00:36.000
And so it's not like there, unless you're using OD formalism, there's not like the one to one correspondence between the image space and the latent space.

01:00:36.000 --> 01:00:48.000
And so and so you would turn X zero into the same sample from the same latent distribution and then when you came back to the image, you wouldn't know anything X zero anymore.

01:00:48.000 --> 01:00:56.000
There's another question here. Is it possible to work with multiple classes within one diffusion probabilistic model.

01:00:56.000 --> 01:01:12.000
And I mean the answer is, so you can train your diffusion model on any distribution that you want to train on, I guess, so so I think the answer is yes, I think, I think the more precise answer would depend on exactly what you wanted to do.

01:01:12.000 --> 01:01:23.000
But, but there's no reason that multiple classes should be harder than one class.

01:01:23.000 --> 01:01:25.000
Okay, great.

01:01:25.000 --> 01:01:32.000
Maybe I can stop there recording here and if there are more questions, you can ask.

