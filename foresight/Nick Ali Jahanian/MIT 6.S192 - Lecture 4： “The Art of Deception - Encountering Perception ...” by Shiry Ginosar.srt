1
00:00:00,000 --> 00:00:08,360
Yeah, and we have our another specialist speaker today.

2
00:00:08,360 --> 00:00:16,320
This is such a pleasure for me to have Shiri Ghinosar.

3
00:00:16,320 --> 00:00:22,920
She's a computing innovation postdoctoral fellow at UC Berkeley.

4
00:00:22,920 --> 00:00:25,520
And she has done so many interesting work

5
00:00:25,520 --> 00:00:34,120
and very creative these models of current ARs.

6
00:00:34,120 --> 00:00:37,480
Many interesting projects that she will hopefully

7
00:00:37,480 --> 00:00:39,800
share a gist of that with us.

8
00:00:39,800 --> 00:00:45,520
I can tell you about understanding

9
00:00:45,520 --> 00:00:48,920
the evolution of her images that was very striking to me,

10
00:00:48,920 --> 00:00:52,200
as well as the dance project that she did,

11
00:00:52,200 --> 00:00:54,520
and other interesting things that she

12
00:00:54,520 --> 00:00:59,720
tries to go beyond the only pixels.

13
00:00:59,720 --> 00:01:06,000
So Shiri, go ahead and please start your talk.

14
00:01:06,000 --> 00:01:07,840
Oh, thank you so much.

15
00:01:07,840 --> 00:01:10,880
So hi, I'm Shiri.

16
00:01:10,880 --> 00:01:15,880
And I'd like to talk to you today about the art of deception,

17
00:01:15,880 --> 00:01:20,880
or basically using perception as a creative material.

18
00:01:20,880 --> 00:01:24,680
And I have a lot of material, but I want this.

19
00:01:24,680 --> 00:01:27,600
I know it's kind of strange to do this over Zoom.

20
00:01:27,600 --> 00:01:32,280
People are kind of shy to budge in.

21
00:01:32,280 --> 00:01:35,160
But it can really be a conversation.

22
00:01:35,160 --> 00:01:38,240
We can take it this anywhere that you want.

23
00:01:38,240 --> 00:01:40,320
It could be kind of like a fireside chat.

24
00:01:40,320 --> 00:01:42,960
It could be, you know, we can make it this into different things.

25
00:01:42,960 --> 00:01:45,680
But so I want to encourage you, if you have questions,

26
00:01:45,680 --> 00:01:49,840
you could just start talking, because I don't have the chat on,

27
00:01:49,840 --> 00:01:51,360
and I can't man all these things.

28
00:01:51,360 --> 00:01:55,360
But just feel free to just stop me at any point.

29
00:01:55,360 --> 00:01:58,440
And I want to say that, because I know that it's, you know,

30
00:01:58,440 --> 00:02:02,080
this whole remote thing is kind of, you know, strange.

31
00:02:02,080 --> 00:02:03,800
So OK, so let's start talking.

32
00:02:03,800 --> 00:02:05,800
And I want to get you into the mood.

33
00:02:05,800 --> 00:02:09,200
So I want us to look at a video together to start with.

34
00:02:09,200 --> 00:02:15,360
And this is a really nice music video by Michel Gondry

35
00:02:15,360 --> 00:02:17,720
that he made for the Chemical Brothers.

36
00:02:17,720 --> 00:02:19,880
And I want you to really notice what is going on.

37
00:02:19,880 --> 00:02:24,160
I want you to listen and I want you to look at what is going

38
00:02:24,160 --> 00:02:26,040
at what is going on in this video.

39
00:03:47,720 --> 00:04:01,040
OK, so if you zoned out a little bit in the beginning there,

40
00:04:01,040 --> 00:04:02,720
because, you know, you look at this thing

41
00:04:02,720 --> 00:04:05,560
and you think to yourself, OK, I'm looking out the window,

42
00:04:05,560 --> 00:04:08,800
I'm a train, I've been there, it's kind of nice and relaxing,

43
00:04:08,800 --> 00:04:10,280
but it's also a little bit mind-numbing.

44
00:04:10,280 --> 00:04:13,320
So you kind of zone out and you're like, OK.

45
00:04:13,320 --> 00:04:16,440
But then suddenly it hits you that there's a surprise here.

46
00:04:16,480 --> 00:04:20,720
So actually all the visuals are, yes.

47
00:04:20,720 --> 00:04:25,480
I think that did you want the student to tell you what they think

48
00:04:25,480 --> 00:04:29,400
or you just want to tell them?

49
00:04:29,400 --> 00:04:33,320
They can tell me what I, I can't really see you guys.

50
00:04:33,320 --> 00:04:34,920
I can only see you.

51
00:04:34,920 --> 00:04:37,640
OK, so if you want to say something, just like say it.

52
00:04:37,640 --> 00:04:40,960
Yeah, if you please, if your students want to say something,

53
00:04:40,960 --> 00:04:42,680
just unmute and say it.

54
00:04:42,680 --> 00:04:46,200
I can also actually, before you do that, now that we've stopped,

55
00:04:46,200 --> 00:04:50,240
I want to ask the audio, is it reasonable?

56
00:04:50,240 --> 00:04:50,960
Is it too loud?

57
00:04:50,960 --> 00:04:53,880
Is it too low of the of the videos?

58
00:04:53,880 --> 00:04:55,440
It's a good time to fix this

59
00:04:55,440 --> 00:04:58,160
because we're going to have a lot of audio and videos.

60
00:04:58,160 --> 00:05:04,440
I think it was reasonable, maybe a little, maybe a little less like.

61
00:05:04,440 --> 00:05:06,400
But it was good.

62
00:05:09,000 --> 00:05:11,120
So OK, we made a little bit less loud.

63
00:05:11,120 --> 00:05:13,000
If it's not going forward, complain.

64
00:05:13,000 --> 00:05:14,760
Yes, excellent.

65
00:05:14,760 --> 00:05:20,080
So if anyone wants to say what they think or should I read it?

66
00:05:20,080 --> 00:05:26,280
So Ben says, it's repeating scene in sync to the music sections,

67
00:05:26,280 --> 00:05:31,240
moving on to the next loop of the scene

68
00:05:31,240 --> 00:05:34,440
as the track moves to the next section.

69
00:05:34,440 --> 00:05:39,200
Simon says, the camera feels like it is bouncing in rhythm.

70
00:05:41,320 --> 00:05:43,560
That is, that is, that is wonderful.

71
00:05:43,640 --> 00:05:45,160
Those are wonderful observations.

72
00:05:45,160 --> 00:05:49,080
But like, guys, just turn on your microphones and just talk.

73
00:05:49,080 --> 00:05:51,480
OK, don't make Ali read all of your all of your things.

74
00:05:52,040 --> 00:05:55,360
So it will be more just more interactive, you know.

75
00:05:57,120 --> 00:05:59,720
OK, so yes, that's exactly what's going on.

76
00:05:59,920 --> 00:06:03,880
Everything is being repeated and is synced to the music and sync to the beat.

77
00:06:04,160 --> 00:06:06,040
And Michel Goudre is very good at this.

78
00:06:06,040 --> 00:06:09,040
He did this a couple of times and amazingly, he did this by hand.

79
00:06:09,040 --> 00:06:12,480
So there's a very interesting YouTube video.

80
00:06:12,520 --> 00:06:16,440
It's kind of like a documentary about the making of this video.

81
00:06:16,440 --> 00:06:21,120
And you see how they charted out the entire score of the music

82
00:06:21,360 --> 00:06:23,840
and planned out exactly what they're going to show.

83
00:06:25,840 --> 00:06:29,360
Individuals and literally, literally compose this by hand.

84
00:06:29,360 --> 00:06:31,200
There's no, there's no AI here or anything like that.

85
00:06:31,800 --> 00:06:36,840
So the interesting thing is that this kind of combination

86
00:06:36,840 --> 00:06:41,440
between your different senses plays a trick on you and gives you this surprise,

87
00:06:41,440 --> 00:06:43,000
which makes it interesting.

88
00:06:43,000 --> 00:06:46,360
But if you didn't notice what was going on, you would think, oh, yeah, you know,

89
00:06:46,360 --> 00:06:48,280
it looks like it's real, but it's not.

90
00:06:48,280 --> 00:06:49,560
There's nothing real about this.

91
00:06:49,560 --> 00:06:51,160
It's completely composed.

92
00:06:52,160 --> 00:06:55,840
OK, so so let's take a step back and talk a little about

93
00:06:55,840 --> 00:06:59,800
but put ourselves in context and look at the history of what people did

94
00:06:59,800 --> 00:07:04,040
in order to depict the world from the very beginning of art.

95
00:07:04,960 --> 00:07:08,840
The main goal of art was to, you know,

96
00:07:09,280 --> 00:07:12,120
capture the world realistically.

97
00:07:12,120 --> 00:07:15,960
So they started with with cave drawings of prehistoric people

98
00:07:15,960 --> 00:07:20,080
who saw these big cows with the big big horns

99
00:07:20,080 --> 00:07:24,880
and wanted to wanted to capture them with coal on the on the

100
00:07:25,920 --> 00:07:28,600
walls of their caves.

101
00:07:28,600 --> 00:07:32,320
And going forward, many, many years, people got more sophisticated.

102
00:07:33,040 --> 00:07:38,080
This is a very nice mosaic from the Byzantine time.

103
00:07:38,080 --> 00:07:42,760
And there's already a lot of dress here and different people and a lot of details.

104
00:07:43,880 --> 00:07:47,800
But at this time, all of the depiction of people was very, very flat.

105
00:07:47,920 --> 00:07:52,360
So there's almost no depth in the image and everybody is kind of frontal

106
00:07:52,600 --> 00:07:57,320
and has a very just nondescript

107
00:07:58,680 --> 00:08:04,160
facial emotions that everybody's kind of like severe going forward.

108
00:08:04,280 --> 00:08:06,480
You know, this is the beginning of the Renaissance.

109
00:08:06,480 --> 00:08:07,720
So this is Giotto.

110
00:08:07,720 --> 00:08:11,520
And this is one of the first times that depth appears in an image.

111
00:08:11,840 --> 00:08:14,480
And the way he does it is kind of it's a nice trick.

112
00:08:14,480 --> 00:08:18,680
He puts this person in green in front of Christ.

113
00:08:19,040 --> 00:08:23,000
And it kind of draws your attention inwards into the image.

114
00:08:23,240 --> 00:08:25,960
And you can notice, you know, people are not frontal here anymore.

115
00:08:25,960 --> 00:08:28,920
This is kind of diverging

116
00:08:31,040 --> 00:08:33,520
style from from the Byzantine style.

117
00:08:33,800 --> 00:08:36,080
And you can see motion in their faces.

118
00:08:36,080 --> 00:08:38,440
So it's becoming more and more realistic.

119
00:08:39,680 --> 00:08:42,040
Things get even better in the Renaissance.

120
00:08:42,040 --> 00:08:45,440
Here we already have linear perspective.

121
00:08:45,440 --> 00:08:49,160
We have the little people in the back, you know, are smaller.

122
00:08:49,160 --> 00:08:51,480
And we have people in the front, which are bigger.

123
00:08:51,480 --> 00:08:55,920
And it kind of makes you feel like everything is going into the image.

124
00:08:55,920 --> 00:08:58,160
And you can kind of walk into the scene.

125
00:08:58,960 --> 00:09:03,640
And, of course, going a little bit forward, you know, we almost achieved

126
00:09:04,560 --> 00:09:06,400
perfection in painting.

127
00:09:06,400 --> 00:09:08,320
So this is Van Eyck.

128
00:09:08,760 --> 00:09:14,360
And this is a beautiful painting where he has here geometric

129
00:09:14,600 --> 00:09:16,480
orthogonal perspective.

130
00:09:16,480 --> 00:09:20,600
And there's, you know, you can really walk into this image.

131
00:09:20,800 --> 00:09:25,240
There's a lot of detail if you blow up, for example, the chandelier.

132
00:09:25,240 --> 00:09:28,280
You can see how the light is bouncing on the metal.

133
00:09:28,640 --> 00:09:34,640
The little flames of the candles are very, very nicely painted.

134
00:09:34,640 --> 00:09:37,800
Everything is very realistic and even better.

135
00:09:37,800 --> 00:09:42,280
He puts a mirror behind those those two people who are getting married here.

136
00:09:42,600 --> 00:09:45,840
And you can get even a double depth in the image.

137
00:09:45,840 --> 00:09:49,520
So you can walk into the image and you can even see the backs of the people

138
00:09:49,520 --> 00:09:52,600
and the people who are looking at the people who are getting married.

139
00:09:53,760 --> 00:09:55,560
So this is is really wonderful.

140
00:09:55,760 --> 00:10:01,440
And even you can see the the little beads, the glass, the glass beads

141
00:10:01,440 --> 00:10:02,760
that are hanging up.

142
00:10:02,760 --> 00:10:05,320
It just is is almost perfect.

143
00:10:07,960 --> 00:10:10,520
Of course, all of this this perfection

144
00:10:11,840 --> 00:10:13,960
basically ended with the invention of the camera

145
00:10:14,280 --> 00:10:17,480
because then you could just walk out or look out of your window

146
00:10:17,480 --> 00:10:19,520
and take a snapshot and you're done, right?

147
00:10:19,520 --> 00:10:21,040
You know, this is like, there you go.

148
00:10:21,040 --> 00:10:24,000
This is the world, the world, you know, it is this is it.

149
00:10:24,400 --> 00:10:27,400
Anything you want, you could take a picture of and it kind of

150
00:10:28,800 --> 00:10:32,520
made this this break in the art world because suddenly,

151
00:10:33,040 --> 00:10:36,400
you know, the people who would do your your portrait for a lot of money,

152
00:10:36,400 --> 00:10:38,760
we're out of we're out of we're out of work in a way.

153
00:10:39,680 --> 00:10:42,280
Of course, this raises different questions.

154
00:10:42,280 --> 00:10:47,200
So once you have an image that you can take and the pixels are real,

155
00:10:47,400 --> 00:10:51,640
then the question can become about whether whether is this a real picture?

156
00:10:51,640 --> 00:10:55,040
Is this fake? You know, is this kiss that happened in Paris?

157
00:10:55,040 --> 00:10:57,560
Was it was it really did it really happen for real?

158
00:10:57,560 --> 00:11:00,080
Or was it a stage? This one was staged, by the way.

159
00:11:01,640 --> 00:11:05,080
Are aliens actually descending on New York or is this a movie?

160
00:11:05,080 --> 00:11:07,120
You know, is this a conspiracy theory?

161
00:11:07,120 --> 00:11:09,240
Are the people actually land on the moon?

162
00:11:09,240 --> 00:11:13,000
Or, you know, can I believe the pixels of the camera or not?

163
00:11:15,360 --> 00:11:20,360
And interestingly and interestingly for us,

164
00:11:21,240 --> 00:11:25,880
artists didn't actually give up after the invention of the camera.

165
00:11:26,440 --> 00:11:28,760
They actually became more sophisticated.

166
00:11:28,760 --> 00:11:32,560
So here there is a nice example from Monet.

167
00:11:32,560 --> 00:11:36,640
It's an impressionist painting and you can see a parade in Paris.

168
00:11:36,640 --> 00:11:40,280
There's a lot of people going and walking in the street.

169
00:11:40,600 --> 00:11:44,640
And, you know, let's try let's try to get you talking a little bit.

170
00:11:44,640 --> 00:11:48,320
So like, what do you notice in this image in this painting?

171
00:11:51,360 --> 00:11:54,520
Anybody? What's interesting about it?

172
00:11:54,520 --> 00:11:56,520
There's a lot of flags.

173
00:11:56,520 --> 00:11:58,520
There's a lot of flags, yes.

174
00:11:58,520 --> 00:12:01,520
And what's happening to the flags?

175
00:12:01,520 --> 00:12:03,040
Oh, they're waving.

176
00:12:03,040 --> 00:12:07,120
So it's like depicting motion and they're kind of blown in the wind.

177
00:12:08,200 --> 00:12:09,880
Why do you think they're blowing in the wind?

178
00:12:09,880 --> 00:12:11,880
What makes you think that?

179
00:12:13,280 --> 00:12:15,480
They're blurry.

180
00:12:15,480 --> 00:12:17,480
That's true. They are blurry.

181
00:12:18,480 --> 00:12:20,360
But are they really blurry?

182
00:12:20,360 --> 00:12:23,680
Like, is it is it fuzzy, like a Gaussian filter on top of them?

183
00:12:24,280 --> 00:12:26,520
We're really like blow up a section here.

184
00:12:29,720 --> 00:12:33,760
They're not like blurry in the in the normal sense,

185
00:12:33,760 --> 00:12:36,680
but they're not rigidly defined.

186
00:12:36,680 --> 00:12:39,920
So like the looseness of the brushstrokes

187
00:12:40,280 --> 00:12:45,720
and the way that they all kind of have that implies the wind and the motion.

188
00:12:46,520 --> 00:12:48,160
Exactly, exactly.

189
00:12:48,160 --> 00:12:55,040
So these flags are basically built out of strips of blue and yellow and red,

190
00:12:55,040 --> 00:13:00,160
which is the French plan, but they're not it's spatially imprecise.

191
00:13:00,160 --> 00:13:03,000
They're kind of jumbled strokes of paint,

192
00:13:03,000 --> 00:13:05,400
even though each stroke of paint is not blurry,

193
00:13:05,800 --> 00:13:08,800
the juxtaposition of them is kind of all over the place.

194
00:13:09,440 --> 00:13:13,960
And the interesting thing about this is that

195
00:13:14,960 --> 00:13:20,600
this kind of matches really nicely to our peripheral vision.

196
00:13:20,600 --> 00:13:28,200
So in our peripheral vision, we see things kind of in a spatially imprecise way.

197
00:13:28,200 --> 00:13:30,200
It's not that we see things blurry.

198
00:13:30,200 --> 00:13:33,960
It's just that we don't really care where exactly they are in the image.

199
00:13:33,960 --> 00:13:39,440
So if you kind of look at this painting in a glance,

200
00:13:39,440 --> 00:13:42,000
you kind of think to yourself, oh, everything is fine.

201
00:13:43,000 --> 00:13:47,200
But when you actually look and take a very close look at it,

202
00:13:47,200 --> 00:13:50,560
you see that everything is really, really jumbled because you're using your

203
00:13:51,440 --> 00:13:57,200
your actual, you know, attentive vision in the middle of your of your of your viewing field.

204
00:13:57,200 --> 00:14:01,920
And that is more takes more into account the spatial arrangement of stuff.

205
00:14:02,240 --> 00:14:05,520
And so really to get a sense of this painting, you have to kind of look

206
00:14:05,680 --> 00:14:10,440
in every time you take a good look at it, you get a different sense of what's going on

207
00:14:10,440 --> 00:14:14,560
because your periphery is giving you a different a different sensation.

208
00:14:14,680 --> 00:14:17,600
And that's what kind of gives this this vibrant motion.

209
00:14:17,960 --> 00:14:21,600
So in a way, you know, you get an impression.

210
00:14:21,600 --> 00:14:24,760
That's why they call it impressionist because you get an impression of what's going on

211
00:14:24,760 --> 00:14:26,920
at every glance, but it's not really correct.

212
00:14:27,280 --> 00:14:30,000
And this is how Monet is playing with your visual system

213
00:14:30,000 --> 00:14:32,880
and making you feel like there's something real here like motion,

214
00:14:32,880 --> 00:14:35,040
which is really not in the pixels themselves.

215
00:14:36,640 --> 00:14:39,920
OK, so, you know, fast forward many, many years.

216
00:14:39,920 --> 00:14:41,880
And we have computer graphics.

217
00:14:44,400 --> 00:14:47,000
Can I interrupt and be a little perfectionist?

218
00:14:47,000 --> 00:14:50,240
I think that I really love these slides.

219
00:14:50,400 --> 00:14:53,280
There is this panel

220
00:14:53,520 --> 00:14:58,800
built order from, you know, that maybe you want to close it.

221
00:14:59,280 --> 00:15:03,200
Oh, no. Oh, no, thank you.

222
00:15:03,960 --> 00:15:06,640
You know, this happened to me before and I should know this already.

223
00:15:07,640 --> 00:15:11,280
OK, OK, thank you, thank you.

224
00:15:12,000 --> 00:15:13,920
Oh, why don't you say something before?

225
00:15:13,920 --> 00:15:18,200
OK, good to make a postman always, always close the build order.

226
00:15:20,400 --> 00:15:23,760
OK, so we went to computer graphics, right?

227
00:15:24,080 --> 00:15:27,200
And suddenly, oh, no, no, I don't have my little timer.

228
00:15:27,200 --> 00:15:30,840
OK, I'm going to have to look at the clock and suddenly.

229
00:15:32,520 --> 00:15:35,880
You could model the world physically, right?

230
00:15:35,880 --> 00:15:41,000
You can make a physical model of the light and the and the objects

231
00:15:41,000 --> 00:15:43,520
and the scene and you can render them perfectly.

232
00:15:44,360 --> 00:15:48,600
But you could almost render them too perfect.

233
00:15:49,320 --> 00:15:53,160
This is, you know, what you get out of of graphics a lot of the time

234
00:15:53,480 --> 00:15:55,800
is super, super real.

235
00:15:55,800 --> 00:16:01,280
But it kind of makes you feel and gives you a strange feeling.

236
00:16:01,280 --> 00:16:02,960
It's kind of too realistic.

237
00:16:02,960 --> 00:16:05,440
You know, everything is a little bit too clean.

238
00:16:06,080 --> 00:16:08,080
Everything is a little bit too robotic.

239
00:16:09,000 --> 00:16:11,000
Do you know why that is?

240
00:16:11,000 --> 00:16:13,640
Why does it make you feel that way?

241
00:16:18,880 --> 00:16:21,400
OK, so I'll give you my idea.

242
00:16:21,400 --> 00:16:25,320
My idea is that what's missing is the noise.

243
00:16:25,480 --> 00:16:29,920
What's missing is the junk, is the dirt, is the cracks in the sidewalk

244
00:16:29,920 --> 00:16:35,040
that are kind of random, the suit on the buildings, you know,

245
00:16:35,040 --> 00:16:38,440
all the all the all the noise, all the junk, basically,

246
00:16:39,280 --> 00:16:44,720
where our visual system is really used to seeing all this noise

247
00:16:44,720 --> 00:16:49,080
in in the outside world, and there's a lot of beauty in this complexity

248
00:16:49,440 --> 00:16:52,880
that when you take it away because you can't model it physically,

249
00:16:52,880 --> 00:16:57,000
it's too complex to model, you know, our visual system just jumps in

250
00:16:57,000 --> 00:16:59,520
and is like, oh, something is really wrong with this image.

251
00:17:00,760 --> 00:17:02,760
And so this is very important perceptually.

252
00:17:02,760 --> 00:17:08,840
And a lot of what I do is try to capture this complexity of the of the visual world.

253
00:17:10,120 --> 00:17:12,160
OK, so we talked a little bit of our perception.

254
00:17:12,880 --> 00:17:17,240
I want to make one more note about it, is that a lot of perception

255
00:17:17,240 --> 00:17:20,080
is really in your head. It's not really what you see.

256
00:17:20,400 --> 00:17:22,520
OK, so here's an example.

257
00:17:22,520 --> 00:17:28,040
And if you look at this image and you look at the at the thing

258
00:17:28,040 --> 00:17:31,040
that's that's in a red box, what is what do you see?

259
00:17:33,760 --> 00:17:42,920
A soccer player, a player, yes, soccer player, yes, great soccer player.

260
00:17:43,360 --> 00:17:45,800
But do you really think that there's a soccer player there?

261
00:17:45,800 --> 00:17:48,800
Like if I take him and I magnify him.

262
00:17:49,760 --> 00:17:51,960
Eh, it's just a bunch of pixels, right?

263
00:17:51,960 --> 00:17:54,000
It's like there's white pixels, there's black pixels.

264
00:17:54,000 --> 00:17:55,320
You can't really see the head.

265
00:17:55,320 --> 00:17:57,760
There's a little bit of legs there, but there's really, you know,

266
00:17:58,160 --> 00:18:00,400
there's there's really no player here, right?

267
00:18:00,400 --> 00:18:01,680
Do you agree?

268
00:18:01,680 --> 00:18:07,680
Like if you look at this and this, it's like, so a lot of what makes you think

269
00:18:07,680 --> 00:18:09,880
there's a soccer player here is actually the context.

270
00:18:09,880 --> 00:18:13,160
You know, there's a soccer field, it's in situation.

271
00:18:13,160 --> 00:18:15,280
You're kind of like filling in the details.

272
00:18:16,000 --> 00:18:17,160
Here's another example.

273
00:18:17,160 --> 00:18:20,520
This is an image from a video that Antonio shot.

274
00:18:21,280 --> 00:18:26,320
And it's kind of blurry, but but your brain can fill in the details.

275
00:18:26,320 --> 00:18:28,720
What are you? What do you see here?

276
00:18:31,400 --> 00:18:37,200
A man sitting at a computer with like a phone to his ear.

277
00:18:37,720 --> 00:18:38,800
Exactly.

278
00:18:38,800 --> 00:18:43,960
But if I show you the details, you suddenly see that everything is wrong.

279
00:18:43,960 --> 00:18:45,160
White, he's not talking on the phone.

280
00:18:45,160 --> 00:18:47,800
He's talking in the shoe and he's not looking at a computer.

281
00:18:47,800 --> 00:18:50,000
He's looking at a at a garbage can.

282
00:18:50,000 --> 00:18:53,400
OK, and the mouse is actually a stapler and there's a toaster there.

283
00:18:53,400 --> 00:18:58,120
So everything is wrong, but the spatial configuration of the scene is fine.

284
00:18:58,280 --> 00:19:01,160
And if you blur it out, your brain is just like, oh, this is fine.

285
00:19:01,160 --> 00:19:02,920
You know, I'm just going to fill in the details.

286
00:19:03,840 --> 00:19:07,520
So there are these loopholes of perception.

287
00:19:08,000 --> 00:19:10,840
And this is a great opportunity for design.

288
00:19:11,520 --> 00:19:17,160
And this is how we're going to weave in things that are not real,

289
00:19:17,440 --> 00:19:21,280
but kind of make you think that they are as long as we're careful

290
00:19:21,280 --> 00:19:22,840
to guard the important bits.

291
00:19:22,840 --> 00:19:26,520
There are some there are some anchors of perception that we should care about.

292
00:19:26,960 --> 00:19:31,000
And we have to make sure that they're there and your brain is going to do the rest.

293
00:19:31,560 --> 00:19:40,560
OK, so what I'm going to cover today is I'm going to look at multiple examples of this.

294
00:19:40,560 --> 00:19:43,280
So we're going to look a little bit at work that

295
00:19:44,720 --> 00:19:47,400
looks at different senses and putting them together.

296
00:19:47,400 --> 00:19:50,880
So here we're going to talk about audio and motion, so vision and hearing.

297
00:19:51,600 --> 00:19:54,280
We're going to talk about modeling these complexities.

298
00:19:54,280 --> 00:19:58,600
So the very, very fine details of individual appearance.

299
00:19:59,120 --> 00:20:04,400
And we're going to talk about using time or using the passion,

300
00:20:04,400 --> 00:20:09,720
the passing of time as a creative material.

301
00:20:10,400 --> 00:20:14,040
I'll stop here and ask if there's any questions or complaints, and then I will continue.

302
00:20:16,240 --> 00:20:20,760
OK, so let's talk first about audio and motion.

303
00:20:21,760 --> 00:20:26,160
We're going to talk about how people move when they speak.

304
00:20:26,160 --> 00:20:30,120
And it's the the what I'm talking about is going to look something like this.

305
00:20:34,320 --> 00:20:36,120
I know how was it the personality travels?

306
00:20:36,120 --> 00:20:38,560
Well, maybe there'll be some sort of physical explanation for it.

307
00:20:38,560 --> 00:20:44,360
So people move when they speak and these are called conversational gestures.

308
00:20:44,360 --> 00:20:47,440
OK, there's the kind of stuff that we do when when we speak.

309
00:20:47,440 --> 00:20:50,440
And we never do basically when we don't when we don't talk.

310
00:20:51,080 --> 00:20:56,080
And this type of gesture is not the only form of communicative gesture.

311
00:20:56,080 --> 00:21:00,080
There's a continuum from language that accompanies speech, sorry,

312
00:21:00,080 --> 00:21:05,000
language that accompanies motion that accompanies language to motion

313
00:21:05,000 --> 00:21:06,240
that replaces language.

314
00:21:06,240 --> 00:21:09,600
So, for example, sign language is a language of its own.

315
00:21:09,840 --> 00:21:12,760
It doesn't need speech to go with it.

316
00:21:12,760 --> 00:21:17,280
And blends are like Italian, like there's all kinds of things that Italians do,

317
00:21:17,280 --> 00:21:20,400
which kind of have meanings that people agree upon.

318
00:21:20,400 --> 00:21:23,000
So it's almost like a language.

319
00:21:23,000 --> 00:21:24,840
But we're not going to talk about these things.

320
00:21:24,840 --> 00:21:29,400
We're going to talk about the motion that accompanies speech when you do talk.

321
00:21:32,640 --> 00:21:37,120
So what we want here is you want to learn about how people use gestures

322
00:21:37,120 --> 00:21:42,840
when they speak and to do that, we're going to take in a raw audio signal of speech.

323
00:21:42,840 --> 00:21:44,640
So literally the waveform.

324
00:21:44,640 --> 00:21:48,160
And from that, we want to directly predict hand and arm gestures.

325
00:21:48,200 --> 00:21:49,960
So it's going to look something like this.

326
00:21:55,280 --> 00:21:57,400
So this is a really, really hard question.

327
00:21:57,400 --> 00:21:59,720
OK, it's an ill-defined problem.

328
00:21:59,960 --> 00:22:03,760
There's not a one to one correspondence between the audio and the motion

329
00:22:03,760 --> 00:22:06,640
because I can say something today and move in a particular way

330
00:22:06,640 --> 00:22:08,840
and do it a completely different tomorrow.

331
00:22:09,920 --> 00:22:11,920
It's not synchronous.

332
00:22:11,920 --> 00:22:16,640
The motion is often not synchronous to the related utterance.

333
00:22:17,120 --> 00:22:21,760
And it's also a task that would be really hard for people to do or even to annotate for you.

334
00:22:21,760 --> 00:22:25,600
So getting supervised learning in this setup is really, really hard.

335
00:22:27,480 --> 00:22:33,480
And what we want to do is we want to, you know, learn about this in kind of in the wild setting.

336
00:22:33,680 --> 00:22:39,040
So what we did is we went and collected a large data set of people who are speaking.

337
00:22:39,480 --> 00:22:46,160
And for each frame, we annotated it automatically using an out of the box

338
00:22:47,040 --> 00:22:48,640
2D pose detection.

339
00:22:48,640 --> 00:22:52,960
So it kind of finds the pose of the arms of the hand and the hands of the people.

340
00:22:53,320 --> 00:22:55,120
And the data looks kind of like this.

341
00:23:01,000 --> 00:23:03,200
Waiting outside. Why are you telling me all this?

342
00:23:03,200 --> 00:23:05,160
And you're not going to believe what they said they want to do.

343
00:23:06,240 --> 00:23:08,640
Isn't that disgusting? It's 2012.

344
00:23:08,840 --> 00:23:11,200
We're still not on the.

345
00:23:11,200 --> 00:23:14,040
And then report it to the police.

346
00:23:14,040 --> 00:23:18,640
Even Lauer's conversations light more photons per second.

347
00:23:19,320 --> 00:23:22,840
Still none of the two young to be vaccinated.

348
00:23:22,840 --> 00:23:25,120
And why would you choose not to do that?

349
00:23:25,120 --> 00:23:29,320
So you can already see that people are very different in how they gesticulate.

350
00:23:29,600 --> 00:23:32,400
But within a person, there's a lot of repetition.

351
00:23:32,400 --> 00:23:37,640
And here I'm showing clusters in in the rows of clusters of gestures.

352
00:23:38,720 --> 00:23:42,720
And this is because people just tend to perform the same motions over and over again,

353
00:23:42,840 --> 00:23:45,000
because they have their typical style.

354
00:23:45,560 --> 00:23:48,040
And that's great because it gives us a learning signal.

355
00:23:48,040 --> 00:23:51,640
And so what we're going to do here is we're going to model each person individually.

356
00:23:52,520 --> 00:23:56,160
And the way we're going to predict gestures from audio is we're literally going to take

357
00:23:56,160 --> 00:23:58,200
the raw audio as input.

358
00:23:58,200 --> 00:23:59,680
We're going to treat it like an image.

359
00:23:59,680 --> 00:24:02,080
So we're going to think about it as a spectrogram.

360
00:24:02,120 --> 00:24:07,200
We're going to stick it into a neural network and we're going to output a temporal series of poses.

361
00:24:07,640 --> 00:24:11,400
And what each one of these really is, is just a vector of numbers.

362
00:24:11,560 --> 00:24:15,640
But they represent the pose of the arms and hands of a person.

363
00:24:17,240 --> 00:24:18,680
And the result looks like this.

364
00:24:23,080 --> 00:24:25,320
So, you know, try and separate the two.

365
00:24:25,960 --> 00:24:32,280
OK. Now the good news is the one thing to notice is, you know, for this given audio,

366
00:24:32,480 --> 00:24:36,720
we predict a stack of these poses and we have two kinds of losses.

367
00:24:36,760 --> 00:24:40,880
One is the regression loss to this pseudo ground truth of 2D poses that we have.

368
00:24:41,480 --> 00:24:47,880
But what we really want is we want to generate motion according to the style of this particular person.

369
00:24:48,720 --> 00:24:58,080
And so we add another adversarial loss that will tell us whether the motion is real or not with respect

370
00:24:58,080 --> 00:25:04,360
to this person. And this makes a really big difference perceptually, because I'm going to show you here

371
00:25:04,360 --> 00:25:09,560
on the left, you're going to see the result when you only have a regression.

372
00:25:09,560 --> 00:25:14,600
And what happens when you do that is that you kind of get something that's very close to the mean.

373
00:25:14,600 --> 00:25:16,560
So the motion is just very, very slow.

374
00:25:16,560 --> 00:25:18,520
It's kind of like you're going through honey.

375
00:25:19,120 --> 00:25:25,040
And when you add this adversarial loss, you kind of snap to one mode of the output because, you know,

376
00:25:25,040 --> 00:25:29,640
I could have predicted different gestures, but I'm going to pick just one and make it look real.

377
00:25:29,800 --> 00:25:31,680
OK. So that's going to be on the right hand side.

378
00:25:32,640 --> 00:25:39,240
So, you know, it makes us feel a little bit better about what we're seeing.

379
00:25:39,240 --> 00:25:42,080
And here, by the way, I'm pasting in the face.

380
00:25:42,080 --> 00:25:46,640
I'm not predicting the face in this work, but I'm pasting in the ground truth face to give you more

381
00:25:46,640 --> 00:25:51,040
perceptual context to see what, to kind of understand what you're seeing.

382
00:25:52,040 --> 00:25:58,240
OK. So we can also look at prediction results for different people and just look at what it looks like.

383
00:25:58,800 --> 00:26:03,960
Talking about the instantaneous rate, the rate, just when the concentration and I'm putting the ground truth

384
00:26:03,960 --> 00:26:10,400
video on the bottom right, even though, you know, I could really have predicted any realistic motion.

385
00:26:10,400 --> 00:26:13,880
I don't really want to predict the real one, but it's just for reference.

386
00:26:13,880 --> 00:26:20,880
Energy to boil. Higher kinetic energy, higher temperature.

387
00:26:21,880 --> 00:26:25,880
Logo in order to make it more modern. Yeah.

388
00:26:28,880 --> 00:26:30,880
Yeah. Appropriate noise for that. Thank you.

389
00:26:30,880 --> 00:26:35,880
That is where this method fails. So we're only taking audio as input.

390
00:26:35,880 --> 00:26:40,880
There's no, like, there's no, you know, text, there's no semantics.

391
00:26:40,880 --> 00:26:50,880
So the main limitation here is that even though we're using hours of data for training, we really, there's really not enough data to capture.

392
00:26:50,880 --> 00:26:56,880
The cement, you know, fine grain semantics in order to predict metaphoric testers.

393
00:26:56,880 --> 00:26:58,880
So I'm going to show you a video here.

394
00:26:58,880 --> 00:27:01,880
And I want you to notice what happens when he says the word random.

395
00:27:02,880 --> 00:27:09,880
So we, we don't get the circular motion that goes with random. We just can't predict that.

396
00:27:09,880 --> 00:27:18,880
But we do predict the beat motion, which is these up and down repetitive motion that kind of comes with random motion.

397
00:27:18,880 --> 00:27:21,880
So we don't get the circular motion that goes with random.

398
00:27:22,880 --> 00:27:39,880
We just can't predict that. But we do predict the beat motion, which is these up and down repetitive motion that kind of cut the sentence temporally and make us feel like the person is actually moving while they're talking, which is, which is nice.

399
00:27:40,880 --> 00:27:51,880
Another thing that's, that's interesting about this is that it's a little bit hard to do this kind of work the way that I described it.

400
00:27:51,880 --> 00:27:59,880
And that is because the most important part of the body when you're speaking with your hands basically is, is the hands, right.

401
00:27:59,880 --> 00:28:16,880
And the hands are very, very small in an image. And they're very articulated the fingers. And we're just not there yet in terms of computer vision 3D reconstruction techniques to get really good hand estimations.

402
00:28:16,880 --> 00:28:35,880
And so our entire everything we did depends on the fact that we have good, good, you know, detections of body pose and that's not the case. So here's an example, just a randomly picked example from Ellen, Ellen's videos and you can see what happens if you just use an image based system to get the hand reconstructions.

403
00:28:36,880 --> 00:28:48,880
To a CBS for one item. And the receipt was so long that I couldn't even believe it. I called it outrageous. I called it mind boggling. I called it long.

404
00:28:48,880 --> 00:28:56,880
Okay, so this is complete junk, right, like if you try to request to this and everything would with fail miserably. So what do you do.

405
00:28:56,880 --> 00:29:07,880
One thing that we noticed that is actually super interesting is that there is a really high correlation between the motion of the arms and the shape of the hand.

406
00:29:07,880 --> 00:29:29,880
So we're going to do a trick and we're going to take as input not only the audio. If we want to get better hands but you can look at just taking the arms as input, and only from the arms, the arm motion, you can predict a pretty good shape of the hands which is which is almost seems magical.

407
00:29:29,880 --> 00:29:38,880
And so if you do this body to hand thing, what you get looks like this.

408
00:29:38,880 --> 00:29:40,880
Electrons around it.

409
00:29:40,880 --> 00:29:55,880
The atomic oxygen would have six. So it has two more than it normally has. So there's like there's no pixel going in there's no audio going into here there's literally just the motion of the arms and it's it's amazing that it even works.

410
00:29:56,880 --> 00:30:04,880
Again, there's not enough information right so it's not enough to capture metaphoric so if you see here.

411
00:30:04,880 --> 00:30:08,880
She's got this.

412
00:30:09,880 --> 00:30:15,880
And this is the ground truth video okay.

413
00:30:15,880 --> 00:30:28,880
To a CBS for one item. And if you just take the arms, you're not going to get that it looks like this.

414
00:30:29,880 --> 00:30:43,880
And so you can do an extra trick and you can say okay well I can take in the body but I can also just look at the input images because that's what image based reconstruction does anyways.

415
00:30:43,880 --> 00:30:48,880
And together with this body prior, I can get a much better hand reconstruction.

416
00:30:48,880 --> 00:31:00,880
So here on the left is the is the body only input no audio no pixels. And on the right, I have the body and the image together.

417
00:31:00,880 --> 00:31:09,880
To a CBS for one item. And the receipt was so long that I couldn't even believe it I called it outrageous I called it mind boggling I called it long.

418
00:31:09,880 --> 00:31:17,880
So this is already better this time like, you know, this is stuff that we can work with already and it looks much more realistic.

419
00:31:17,880 --> 00:31:23,880
Are there any basic restrictions according to just like human anatomy that are also used within the model.

420
00:31:23,880 --> 00:31:25,880
Sorry saying it.

421
00:31:25,880 --> 00:31:35,880
Are there any just base restrictions on what movement is possible according to human anatomy like you can't completely I don't know. Yeah.

422
00:31:35,880 --> 00:31:38,880
And not.

423
00:31:38,880 --> 00:31:44,880
Sorry, I'm speaking to you from the garage so there's there's exciting background noise.

424
00:31:44,880 --> 00:31:53,880
And not in my model. Okay, but there is in those.

425
00:31:53,880 --> 00:32:03,880
So when we use, when we use ground truth that's coming from 2D reconstruction of key points or 3D reconstruction of hands in this case.

426
00:32:03,880 --> 00:32:10,880
Those models have a lot of, you know, human pose priors built into them.

427
00:32:10,880 --> 00:32:28,880
But we don't. So we're at we're kind of the goal of the, of the body to hands angle is to add an additional fire but one that is not based on, you know, physics that you might calculate from human bodies but it is based on a data driven prior.

428
00:32:28,880 --> 00:32:34,880
So if you've seen enough bodies, you can infer this automatically. Does that answer your question.

429
00:32:34,880 --> 00:32:35,880
Yes, thank you.

430
00:32:35,880 --> 00:32:44,880
Cool. All right. So, let's see what time is it when do we stop at on the hour right.

431
00:32:44,880 --> 00:32:52,880
Yeah, I mean we could, we could go a little further if you want. No, no, no, I'm just like I can I can I have a lot of stuff but I'm just going to cut accordingly.

432
00:32:52,880 --> 00:33:00,880
So I'm going to show you the more interesting. I think that we said 2pm for students but it's. Yeah, that's fine. Okay.

433
00:33:00,880 --> 00:33:14,880
So, okay, so in this work, we really only care to predict 2D motion because we that's what we were, we were interested in. And these stick figures are a nice output representation.

434
00:33:14,880 --> 00:33:24,880
But they don't really provide you enough perceptual context as a viewer to actually see that what the result looks like if we do a good job. Okay.

435
00:33:24,880 --> 00:33:37,880
So instead we can synthesize a video, an actual video the speaker so we what are we going to do we're going to take a real video of the speaker and

436
00:33:37,880 --> 00:33:54,880
right, we can do the same trick where we get a 2d pose detection. And our goal is to learn the mapping between these 2d pose skeletons back to the real frame of the person and this is based on picks to picks you know you probably

437
00:33:54,880 --> 00:33:59,880
you know we stole us so this is this is based on his work, but we're going to do this for a video.

438
00:33:59,880 --> 00:34:13,880
So if you do that, what you get is something like this, where again, I'm pasting in the ground truth face key points because I'm not predicting that but I need them to make a video right so it's going to look like this.

439
00:34:13,880 --> 00:34:30,880
Try and separate the two. Now, now the good news is, these days, very few people will say they are completely and I just want to like focus you on this. This is a completely fake video. Okay, it's completely synthesized there is like, there's nothing real about it.

440
00:34:30,880 --> 00:34:49,880
And it's actually being predicted from raw audio with this 2d, you know system that gives us only the pose. And, and that's kind of amazing. It's, it's the coolest thing about this is that not only can we synthesize a realistically looking

441
00:34:50,880 --> 00:34:57,880
video, but we also managed to capture a very convincing motion of the person.

442
00:34:57,880 --> 00:35:15,880
Mostly what what makes you think that it's good is those beat gestures it's like okay I'm talking and I'm chopping up my sentence and there's kind of going with the same rhythm as my voice and not as convincing enough for people to think that that this is real.

443
00:35:15,880 --> 00:35:18,880
Okay.

444
00:35:18,880 --> 00:35:31,880
We're making fake videos, basically. Okay, so it's interesting to think about what can we do in order to decide whether a video was faked or not.

445
00:35:31,880 --> 00:35:44,880
And it turns out that the same kind of idea can be applied to forensics as well. So I'm going to show you an example let's look at Obama and like look at this is from his address to the nation which he used to do every week.

446
00:35:44,880 --> 00:35:52,880
And I want you to say to see what he does when he says you know hello everybody.

447
00:35:52,880 --> 00:36:13,880
Hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, he has this like upward motion. And basically, if you have the right words, and you have the right motion together, then it's Obama.

448
00:36:13,880 --> 00:36:29,880
But if you try to do some deep fake of him and you try to change his lips and you know make him say something different, you wouldn't get the right motion to go with this. And this is like a great signal to see that something is fake.

449
00:36:29,880 --> 00:36:49,880
And this is a really nice line of work that shorty did you see broccoli with honey for a while they look at exactly this kind of thing so it uses the, you know the whole of the person all of the details in multiple modalities to detect things that are fake.

450
00:36:50,880 --> 00:37:00,880
All right, I'm going to move a little bit to something else if there's any question this is a good time.

451
00:37:00,880 --> 00:37:09,880
Okay, so let's talk a little bit more about this idea of learning on the little details of a person, a person's appearance.

452
00:37:09,880 --> 00:37:18,880
We're going to consider a very special style of gesture which is dance. And it's an art for it's been around since the beginning of time.

453
00:37:18,880 --> 00:37:34,880
But frankly, nobody's really figured out how to capture the little subtleties of it. And what we're going to do is we're going to start we're just going to start directly by looking at a demo. Okay, so look at what what we can do.

454
00:37:40,880 --> 00:37:42,880
Oh

455
00:37:45,880 --> 00:37:47,880
Oh

456
00:37:48,880 --> 00:37:50,880
To me

457
00:37:51,880 --> 00:37:53,880
Close

458
00:37:54,880 --> 00:38:01,880
If I tell my heart I'll still feel pain Whatever I do still feels the same

459
00:38:02,880 --> 00:38:04,880
Nothing but tell me now

460
00:38:07,880 --> 00:38:10,880
Everything we had well it's gone to waste

461
00:38:13,880 --> 00:38:22,880
What we're doing here is we're taking this source video, we're detecting its pose and we're puppeting our target person to dance in the same way.

462
00:38:22,880 --> 00:38:35,880
And it looks really nice, but I'm actually using a trick on you I'm using a perceptual loophole and and this is really interesting we usually don't show this but it turns out that the music is very helpful.

463
00:38:35,880 --> 00:38:41,880
Okay, I'm going to show you exactly the same result without the audio and I want you to notice if it looks different to you.

464
00:38:52,880 --> 00:38:54,880
Okay.

465
00:39:18,880 --> 00:39:20,880
Okay, anyone

466
00:39:20,880 --> 00:39:26,880
Mostly just look super unnatural where before it looked like it actually like was dancing.

467
00:39:26,880 --> 00:39:42,880
It's awful right it's like everything is moving it's kind of wobbly and like, you know, just, just not right right. And it's really interesting it's exactly the same pixels okay I just turned off the audio, but when I show it to you with audio.

468
00:39:43,880 --> 00:39:50,880
Your perceptual system is like whoa there's like music and there's dancing and it's together and you're filling in the holes.

469
00:39:50,880 --> 00:40:04,880
You really are. And it's very important it turns out when you're showing a demo if you guys go and do things and design or and even an AI to kind of set it up in a way that that makes people be in their happy places.

470
00:40:04,880 --> 00:40:19,880
And use multiple senses when they're when they're looking at something and it actually makes it look better than that it really is. And our goal here is actually not to make a perfect video I don't really want to be in the business of making people do things that they

471
00:40:19,880 --> 00:40:30,880
didn't do our goal is to study you know the statistics and whatever, but that it is very helpful to use this different senses. Okay, so what are we doing here.

472
00:40:30,880 --> 00:40:45,880
In a way, it turns out that we can use the same technology we talked about before to transfer dance motion from one person who knows how to dance to a different person who is a terrible dancer, like my co author here, think way.

473
00:40:46,880 --> 00:40:52,880
And this is basically motion that's not conditioned on audio it's conditioned on different people.

474
00:40:52,880 --> 00:40:58,880
And training is the same we train a cycle from you to your stick figure and back to you.

475
00:40:58,880 --> 00:41:09,880
And you can think about it as trying to go from you to full reconstruction of you through this tiny little bottleneck, which is these 2d poses that are not learned.

476
00:41:09,880 --> 00:41:18,880
And the idea here is to get learned a really good mapping from this stick figure back to the appearance of the person.

477
00:41:18,880 --> 00:41:30,880
Because I really want to model what he looks like. I want to capture all the little minute details of his body and the way that he kind of, you know, looks when he's moving.

478
00:41:30,880 --> 00:41:44,880
And I want to get the stuff that you can river really annotate and want to get all the complexity this this beauty in the details. This is what I want. So the goal here is not to start from a single image of a person and make them dance.

479
00:41:44,880 --> 00:41:52,880
The goal is to actually model this person and for that I need a bunch of training data of this person from different poses.

480
00:41:52,880 --> 00:42:00,880
And at test time, we unwrap the cycle, and we put a different person on the other hand.

481
00:42:00,880 --> 00:42:06,880
So here test and training are not the same in purpose and this is different from a lot of other methods.

482
00:42:06,880 --> 00:42:20,880
And these stick figures are a nicer presentation in the middle, because you're kind of agnostic for appearance like you could be, you know, bigger or smaller and width, but but it doesn't really matter for for your skeletal structure.

483
00:42:20,880 --> 00:42:31,880
So if we managed to learn a good model of our target guy, we should be able to sample any new pose from this ballerina and synthesize a new image of the way.

484
00:42:31,880 --> 00:42:38,880
And this is good because a good model of appearance to generalize to new poses.

485
00:42:38,880 --> 00:42:49,880
So I'm using video synthesis kind of like at school it's like show your work, you know the generated video is as is a test of whether our modeling or perception of this guy really worked.

486
00:42:49,880 --> 00:43:09,880
Okay, so we do some tricks to make this not you know frame by frame and achieve a temporal coherence which is which is important perceptually, but I actually want to talk about something else I want to talk about the fact that the face is very important perceptually.

487
00:43:09,880 --> 00:43:26,880
Okay, and we didn't affect this this is, this is Renoir, and there's something really interesting about this painting, which is basically that there's different resolution of painting between different parts of the image right.

488
00:43:26,880 --> 00:43:37,880
The face is very, very sharp, and the eyes are extremely sharp you can even see like the the glint of the of the lighting reflecting on her pupil.

489
00:43:37,880 --> 00:43:43,880
But everything else is fuzzy, and it's kind of like the flags we saw before it's like not really in place.

490
00:43:43,880 --> 00:44:04,880
This is something very, very interesting, it makes you draw your gaze to her eyes, which are the most expressive part of the face, it gives you an emotional reaction, and it makes you ignore everything else because everything else is in your periphery which is not really

491
00:44:04,880 --> 00:44:13,880
attuned to spatial relationships anyways, and it kind of mimics our own perceptual experience.

492
00:44:13,880 --> 00:44:23,880
When we gaze into someone else's eyes like somebody that we really love or somebody that we really want to listen to it's always you know everything else about their body is in the periphery.

493
00:44:23,880 --> 00:44:39,880
So, so this is kind of the trick that Renoir is doing is playing on you, and we're going to play the same trick. Okay, so, so, you know this is this was done before amazing gans were around and so we didn't have the technology to make everything look perfect.

494
00:44:39,880 --> 00:44:53,880
Okay, the face is important. If we get the face right, people will say oh this looks nice. So we actually devote a special again just to the face region, in order to correct it and more realistic.

495
00:44:53,880 --> 00:45:09,880
It makes a big difference. So, if this is the baseline, this is after temporal swathing, this is what happens when we add an additional again for the face itself and it kind of looks almost like Caroline, who used to be my undergrad and did this work.

496
00:45:09,880 --> 00:45:15,880
And now she's, she's a full grown PhD with you guys at MIT.

497
00:45:15,880 --> 00:45:43,880
And, and you can see her dancing in all of these videos, like this one.

498
00:45:43,880 --> 00:45:54,880
Okay, and we can also do the same thing we take a motion one person and we can apply it to many people. And there, when it's small of course the face matters less.

499
00:46:13,880 --> 00:46:34,880
And we turn it into a controllable interactive application that got a lot of attention to the field of image and video synthesis. It appeared in popular press it exhibited and museums, it was incorporated into stage performances.

500
00:46:34,880 --> 00:46:45,880
And now my co author, the same guy who doesn't know how to dance, even turn this into an app that you can download for free from the app store and you can dance and tick tock and whatever you want with it.

501
00:46:46,880 --> 00:47:04,880
And this is interesting. But another direction that we kind of have been discussing a word to take this technology is to provide a platform for capturing performance as a form of intellectual property for for choreography.

502
00:47:04,880 --> 00:47:12,880
Because it turns out that unlike musical score that can be copyrighted, there's no way to copyright dance.

503
00:47:12,880 --> 00:47:27,880
In fact, there wasn't even a way to capture dance in the West until the 20th century. So most of the belays that we know of like Swan Lake and you know, all of these even the famous ones, haven't really survived in their original form.

504
00:47:27,880 --> 00:47:41,880
Until this day there isn't an agreed upon notation of dance and this is just one example which is called the monetization, but all of the, all of the forms of notation.

505
00:47:41,880 --> 00:47:54,880
They don't have a way to accurately capture all the small details. They're not parametric they're not scalable every time you come up with a different move you have to come up with a different notation.

506
00:47:54,880 --> 00:48:08,880
And our, our idea is that capturing things the way that we do can can try and get to these to these issues and maybe offer a new solution.

507
00:48:08,880 --> 00:48:13,880
So we talked a little bit about the fact that there is artifacts but

508
00:48:14,880 --> 00:48:29,880
Actually, it turns out that that is the interesting part about this technology to a lot of artists. So here's, here's one example where the same team plays little company had a gig where they made this music video.

509
00:48:29,880 --> 00:48:37,880
It's really celebrating the problems in this technology and making them into art.

510
00:48:37,880 --> 00:49:06,880
And here's another example that I really love. This isn't actually using our work it's using that to bid but it's very, very similar so you can ignore the differences and just focus on what this person is doing with this.

511
00:49:37,880 --> 00:49:54,880
Thank you.

512
00:50:07,880 --> 00:50:08,880
Thank you.

513
00:50:37,880 --> 00:51:01,880
Thank you.

514
00:51:01,880 --> 00:51:26,880
Perfect. But Jake here really loves those and he's actually pushing it like to the extreme extreme so there's all this hair and the feathers which are really, really hard to capture for guns, but that he's just like let's throw it all in and just let it, you know, be artistic and and and this is kind of what he's been looking for in using these technologies.

515
00:51:26,880 --> 00:51:47,880
Okay, but, but there's also a limitation on how you can use this kind of stuff for art, because essentially what we're doing when we generate images or we generate video or motion using again is that we're always using a training set which is real.

516
00:51:47,880 --> 00:52:06,880
Okay, and we're trying to teach AI how to make us more of this real thing. Okay, so, so we want to, you know, maybe generalize out of the distribution of the training set but not by much we still want to keep things realistic that's our training signal.

517
00:52:06,880 --> 00:52:20,880
And this is this becomes a limitation when you want to do something like this so so these are visuals from New York's tabula bassa music video.

518
00:52:20,880 --> 00:52:29,880
And this actually goes with a with a large performance and show that she had a year ago.

519
00:52:29,880 --> 00:52:42,880
And what they wanted here and they actually came to us to ask for help in order to do this and we couldn't help them what they wanted to do is they wanted to have this marriage between a human and an orchid.

520
00:52:42,880 --> 00:52:54,880
So, so they want the motion and they use mocap for this but they want the motion to come from a human but the visuals and kind of the embellishment to come from a flower.

521
00:52:54,880 --> 00:53:14,880
And there's nothing that we can do to help them, because we don't yet have this ability to do this compositionality between different realistic things to make something to make a new kind of life for him if you may.

522
00:53:14,880 --> 00:53:24,880
We just can't do there's we don't know how to do this. So this is something that is that is a limitation of training to do realism.

523
00:53:24,880 --> 00:53:38,880
And it's a very interesting future direction from work if you're looking for something really cool to do this this kind of idea can give you can give you a nice direction that we don't know how to solve yet.

524
00:53:38,880 --> 00:53:44,880
So how did they do that. How did they did it by hand they did it by hand so.

525
00:53:44,880 --> 00:53:56,880
So they, this is a really cool artist. He's also a professor I think in Hong Kong or one something like that. And they did motion capture on the people.

526
00:53:56,880 --> 00:54:18,880
They have the motion signatures, but everything else is hand designed, you know, 3D models and add motion that is that is basically put together with with its dressed, you know, it's, it's dressed on top of the human motion.

527
00:54:19,880 --> 00:54:32,880
What they wanted would have been similar to people who are here in the class. The other day there was some AI that could make pictures out of like the texture of the skin of an elephant or something.

528
00:54:32,880 --> 00:54:36,880
Like the texture of noodles would have been similar to that.

529
00:54:36,880 --> 00:54:45,880
Like you had a face and then you draw it with the texture of say noodles and then you change the noodles to make it look like it's talking.

530
00:54:45,880 --> 00:54:57,880
So that's one. So you mean like the Geiger paper, right. The counterfactual paper. And there's also, I know you guys looked yesterday at the Lee. So there's different.

531
00:54:57,880 --> 00:55:11,880
Yeah, that's one approach to do that. It's a little bit right now that technology is not yet.

532
00:55:12,880 --> 00:55:28,880
But if you take those noodles and you make them in the shape of a dog or whatever, it's still noodles, you know, and you just cut them into dog. There's nothing that really takes the texture and like kind of applies it onto the 3D form.

533
00:55:28,880 --> 00:55:36,880
So you see here if you look at the at the texture of the flower, it really changes with the articulation of the flower, right.

534
00:55:37,880 --> 00:55:52,880
If you just take noodles and you, you know, you make the right mask for them, it's still it's not yet realistic, right. And this is again something we don't know how to do we don't know if you look at the cycle again results for example.

535
00:55:52,880 --> 00:56:10,880
It doesn't conform to the 3D shape of the object. It doesn't actually respect that. So, yes, that's in the right direction, but it's not yet there. All of this is open problems.

536
00:56:10,880 --> 00:56:13,880
Answer your question.

537
00:56:13,880 --> 00:56:17,880
Yeah, yeah, just stuff to think about it's neat neat stuff.

538
00:56:17,880 --> 00:56:32,880
This is really cool. I don't know how to solve this but it's this is a cool, this is a cool, cool idea, cool, cool direction. Okay, I literally have three minutes so I am going to have more stuff so

539
00:56:32,880 --> 00:56:45,880
the rest of the stuff I wanted to talk about would have been kind of designing with with time using time was as an interesting medium.

540
00:56:45,880 --> 00:56:59,880
And I guess what I can do is just just tell you two different highlights. Okay, so I'm not going to really walk you through all of the story here, but

541
00:56:59,880 --> 00:57:10,880
let's see. If we think about if we think about time and we think about images not from video but like large collections of images.

542
00:57:10,880 --> 00:57:22,880
There's something really interesting about them and the interesting things is that a lot of the time when you think about historical data you think about text, but but you don't really write everything down.

543
00:57:22,880 --> 00:57:35,880
And, and those are things that are really captured in images, and we're lucky we're very, very lucky that we have now basically more than 100 years of historical visual record.

544
00:57:35,880 --> 00:57:50,880
And the things that you get from that are things that are you know you can look at this image and kind of think to yourself you know if 100 years from now somebody wanted to explain in a history book, what are hipsters, it would be really

545
00:57:50,880 --> 00:58:04,880
really hard, because, you know, here you can see the difference between nerds and hipsters and you know what is it that makes these guys look cool is it is it hats, is it the scarves that the Instagram filter that was slapped on the image like is you know what is.

546
00:58:05,880 --> 00:58:08,880
It's really hard to say in words.

547
00:58:08,880 --> 00:58:14,880
And in any case we don't really bother to talk about these things when we write stuff down.

548
00:58:14,880 --> 00:58:19,880
And so historical images kind of captured this for us.

549
00:58:19,880 --> 00:58:31,880
But of course then we kind of you know if you took a collection of historical images you kind of end up with you know a bunch of historical images that you need to sort through and you end up selling in the garage sale because it's too much work.

550
00:58:31,880 --> 00:58:48,880
So if there is a way to automatically get, you know, how do things change over time from images that would be really cool. And that's stuff that we've done a couple of times here this is work with historical yearbooks high school

551
00:58:48,880 --> 00:58:58,880
yearbooks, which is a really nice source of data because there's spaces and they always stay the same but what changes is fashions and social norms.

552
00:58:58,880 --> 00:59:15,880
And what you can do with with a lot of data like this that has kind of a consistent subject matter but changes over time is something like Jason Sullivan here who is an artist has done with his graduating class versus his mother so he graduated

553
00:59:15,880 --> 00:59:31,880
in 1988 from Fort Worth in Texas. And on the left you see an average image of all the people in his classroom the women and the men versus on the right the ones that came from his mother's class of 67 and you can already see that there's big differences

554
00:59:31,880 --> 00:59:48,880
right people used to look different these to stress a little bit different. They used to treat the camera a little bit differently. And we did the same thing with our data, where we took, you know, 100 years of photographs and we looked at averages of men versus

555
00:59:48,880 --> 01:00:01,880
women over time and you can notice that people, you know, look a little bit different that the hair is different they smile more than they used to, you can quantify this kind of thing.

556
01:00:01,880 --> 01:00:17,880
You can look for other characteristic elements for different decades like different hairstyles that are very distinctive.

557
01:00:17,880 --> 01:00:28,880
And this gives you tools for analysis of creativity and fashion, but we're not going to look at this but instead what we're going to say is, okay.

558
01:00:28,880 --> 01:00:44,880
This is interesting you can do this with spaces everything is very online you can look at fashion but what happens if you want to think about time and in the real world in the outdoor world how can you use a time as a, as a, as a creative medium.

559
01:00:44,880 --> 01:01:03,880
And so one thing we did afterwards is we went and looked at a lot of data coming from street view images, and we looked at whether we can say okay let's say I want to travel in time I'm stuck in a pandemic and I want to go visit New York but I want to make sure that I did it on a particular

560
01:01:03,880 --> 01:01:16,880
Sunday afternoon in 2011 okay how can I do this is so maybe I can use flicker images if I want to go to Columbus Circle, but if I want to go to some random corner there's just not.

561
01:01:16,880 --> 01:01:19,880
There's just not the people just don't take pictures there.

562
01:01:19,880 --> 01:01:38,880
So what we did is we went and looked at the Google time machine, which is basically your normal street view interface but they actually keep historical images of the previous runs of the of the cars through the city, and that gives you a single location with

563
01:01:38,880 --> 01:01:50,880
different riding conditions and different weather conditions. And this is really cool because you can collect this at a really large scale, like, you know, all of New York or basically the entire world.

564
01:01:50,880 --> 01:02:05,880
And then for each location you have multiple snapshots of that place, only there's still very sparse, and to go to this place in a particular day and time you have to learn how to fill in the gaps.

565
01:02:05,880 --> 01:02:12,880
Okay, because you know the buildings stay the same, but the weather conditions might change.

566
01:02:12,880 --> 01:02:20,880
So the travel and time you want to take a particular image and you want to be able to change the lighting and the, and the weather.

567
01:02:20,880 --> 01:02:28,880
So basically what you want to do is you need to disentangle or learn to disentangle the things that are varying temporally versus the things that are permanent.

568
01:02:28,880 --> 01:02:41,880
And if you can do that, then you can use time basically to synthesize new things that you know you never really captured they might have existed but you don't know because you weren't there.

569
01:02:41,880 --> 01:02:50,880
And so for a particular scene, you can do things like you can rotate the sun around and this is completely synthetic right this is a result of what we do.

570
01:02:50,880 --> 01:03:07,880
Or you can copy and paste buildings, for example, so you can modify the permanent factor, and that would look something like this right here's here's an inserted building it looks perfect but but it's completely fake.

571
01:03:07,880 --> 01:03:18,880
And I'm not going I'm going to, you know, just not going to go into the technical detail of how it's done but basically the thing that helps us is that we've seen the same place over and over again.

572
01:03:18,880 --> 01:03:23,880
The one thing I do want to talk about is that the nugget.

573
01:03:23,880 --> 01:03:39,880
The technical nugget that we use here is that we can use a decomposition of the scene into two things that graphics tells us that are, you know,

574
01:03:39,880 --> 01:03:50,880
the correct, which is the difference between shading and reflectance where shading kind of captures the shadows and the effects of the illumination on the scene.

575
01:03:50,880 --> 01:04:03,880
And the reflectance is the actual color so I'm wearing an actual blue sweater, that would be the reflectance of the sweater and then there's the effects of the light on it that puts in the shadow.

576
01:04:03,880 --> 01:04:19,880
The thing about about these this this shadow representations this the shading representation is that we're we in our mind we think about the fact that maybe shadows are gray is like if you think about them as grayscale but they're actually not.

577
01:04:19,880 --> 01:04:22,880
Okay, and this this is the interesting thing for sexually here.

578
01:04:22,880 --> 01:04:35,880
And you can see this in this nice painting by Monet. Okay, so, so Monet is painting a grain stack that is sitting in a set of snow on the ground so the snow should be white the ground is white.

579
01:04:35,880 --> 01:04:39,880
But there's actually two colors for the illumination.

580
01:04:39,880 --> 01:04:42,880
There's blue from the sky.

581
01:04:42,880 --> 01:04:46,880
And that is kind of an indirect diffuse light.

582
01:04:46,880 --> 01:04:50,880
And there is a direct light that is yellow from the sun.

583
01:04:50,880 --> 01:04:56,880
And if you look at the shadow that's being cast on the snow.

584
01:04:56,880 --> 01:05:08,880
In the shadow, it's blue, because the direct light doesn't hit doesn't hit the snow and so you mostly get the indirect illumination from the sky.

585
01:05:08,880 --> 01:05:23,880
So the blue then the surrounding light, which has the yellow mixed into it. And when I was doing a trick here where he's actually coloring with the yellow to complement the blue just in the border to make it even more clear to your, your, you know, your center

586
01:05:23,880 --> 01:05:37,880
surround cells and your in your eyes that this is what's happening. Okay, so, so the trick here to get everything to look realistic was to say okay, people before I have kind of thought about shading as a grayscale thing.

587
01:05:38,880 --> 01:05:52,880
And most of the color in their models have gone to the reflectance images, but we actually use a two toned shading where we take separately into account the blue and the yellow.

588
01:05:52,880 --> 01:06:05,880
And we are trying to really capture a lot of the blue of the sky in the shading model and not in the reflectance model. And that kind of makes everything come more together and look more realistic.

589
01:06:05,880 --> 01:06:22,880
And then we can say okay and you know we generalize we take an image from a completely unseen place like Paris we've never been to Paris we didn't train on Paris this is like a one image example and we can relate it and make it look like you've been there and whenever you want, basically.

590
01:06:22,880 --> 01:06:34,880
Okay, so now I am very much over time. So I am going to stop here we've looked at audio motion we've looked at details we've looked at visual patterns over time.

591
01:06:35,880 --> 01:06:46,880
There's there's some food for thought you can take out of here like, you know, for example, AI and perception we can use it to create tools for art design.

592
01:06:46,880 --> 01:06:53,880
There's good and bad implications you have to think about what happens when you make synthetic or fake content.

593
01:06:53,880 --> 01:07:00,880
And we've talked about modeling all kinds of complex things and multimodal stuff.

594
01:07:00,880 --> 01:07:04,880
But there's a lot of stuff that's left to be done.

595
01:07:04,880 --> 01:07:20,880
For example, the example of the person in the orchid and compositionality. And there's also the question of how do you not only provide tools that are creative, but also create creative machines and I think you're going to learn about that more later this week.

596
01:07:20,880 --> 01:07:29,880
One final note is, if you want to learn more about perception and art. This is a great book by Margaret Livingston from Harvard.

597
01:07:29,880 --> 01:07:34,880
And these are collaborators, thank you all collaborators and that's about it.

598
01:07:34,880 --> 01:07:37,880
Thank you.

599
01:07:37,880 --> 01:07:44,880
Thank you so much that was very, very interesting and intriguing and inspiring.

600
01:07:44,880 --> 01:07:47,880
Oh, I'm sorry I went a little bit over time.

601
01:07:47,880 --> 01:07:49,880
I was trying to like, lower the details.

602
01:07:49,880 --> 01:08:03,880
I'm sure that there are many interesting things I personally learned and also students hopefully inspired their thoughts and the future work.

603
01:08:03,880 --> 01:08:09,880
Is there any question from students.

604
01:08:09,880 --> 01:08:14,880
I think that most of them are thanking you and I see that in the chat.

605
01:08:14,880 --> 01:08:17,880
Oh chat. Okay.

606
01:08:17,880 --> 01:08:20,880
Yeah, I think that.

607
01:08:20,880 --> 01:08:24,880
Okay, cool.

608
01:08:24,880 --> 01:08:26,880
Excellent.

609
01:08:26,880 --> 01:08:29,880
Thank you again. It was a great talk.

610
01:08:29,880 --> 01:08:30,880
Thank you.

611
01:08:30,880 --> 01:08:39,880
I'm very excited to, you know, put this online so everyone can benefit from it.

612
01:08:39,880 --> 01:08:41,880
Cool.

613
01:08:41,880 --> 01:08:43,880
Thank you so much.

614
01:08:43,880 --> 01:08:44,880
Bye.

615
01:08:44,880 --> 01:08:45,880
Bye now.

