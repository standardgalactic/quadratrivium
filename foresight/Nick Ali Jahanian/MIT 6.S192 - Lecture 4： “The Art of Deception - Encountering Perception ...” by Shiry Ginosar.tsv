start	end	text
0	8360	Yeah, and we have our another specialist speaker today.
8360	16320	This is such a pleasure for me to have Shiri Ghinosar.
16320	22920	She's a computing innovation postdoctoral fellow at UC Berkeley.
22920	25520	And she has done so many interesting work
25520	34120	and very creative these models of current ARs.
34120	37480	Many interesting projects that she will hopefully
37480	39800	share a gist of that with us.
39800	45520	I can tell you about understanding
45520	48920	the evolution of her images that was very striking to me,
48920	52200	as well as the dance project that she did,
52200	54520	and other interesting things that she
54520	59720	tries to go beyond the only pixels.
59720	66000	So Shiri, go ahead and please start your talk.
66000	67840	Oh, thank you so much.
67840	70880	So hi, I'm Shiri.
70880	75880	And I'd like to talk to you today about the art of deception,
75880	80880	or basically using perception as a creative material.
80880	84680	And I have a lot of material, but I want this.
84680	87600	I know it's kind of strange to do this over Zoom.
87600	92280	People are kind of shy to budge in.
92280	95160	But it can really be a conversation.
95160	98240	We can take it this anywhere that you want.
98240	100320	It could be kind of like a fireside chat.
100320	102960	It could be, you know, we can make it this into different things.
102960	105680	But so I want to encourage you, if you have questions,
105680	109840	you could just start talking, because I don't have the chat on,
109840	111360	and I can't man all these things.
111360	115360	But just feel free to just stop me at any point.
115360	118440	And I want to say that, because I know that it's, you know,
118440	122080	this whole remote thing is kind of, you know, strange.
122080	123800	So OK, so let's start talking.
123800	125800	And I want to get you into the mood.
125800	129200	So I want us to look at a video together to start with.
129200	135360	And this is a really nice music video by Michel Gondry
135360	137720	that he made for the Chemical Brothers.
137720	139880	And I want you to really notice what is going on.
139880	144160	I want you to listen and I want you to look at what is going
144160	146040	at what is going on in this video.
227720	241040	OK, so if you zoned out a little bit in the beginning there,
241040	242720	because, you know, you look at this thing
242720	245560	and you think to yourself, OK, I'm looking out the window,
245560	248800	I'm a train, I've been there, it's kind of nice and relaxing,
248800	250280	but it's also a little bit mind-numbing.
250280	253320	So you kind of zone out and you're like, OK.
253320	256440	But then suddenly it hits you that there's a surprise here.
256480	260720	So actually all the visuals are, yes.
260720	265480	I think that did you want the student to tell you what they think
265480	269400	or you just want to tell them?
269400	273320	They can tell me what I, I can't really see you guys.
273320	274920	I can only see you.
274920	277640	OK, so if you want to say something, just like say it.
277640	280960	Yeah, if you please, if your students want to say something,
280960	282680	just unmute and say it.
282680	286200	I can also actually, before you do that, now that we've stopped,
286200	290240	I want to ask the audio, is it reasonable?
290240	290960	Is it too loud?
290960	293880	Is it too low of the of the videos?
293880	295440	It's a good time to fix this
295440	298160	because we're going to have a lot of audio and videos.
298160	304440	I think it was reasonable, maybe a little, maybe a little less like.
304440	306400	But it was good.
309000	311120	So OK, we made a little bit less loud.
311120	313000	If it's not going forward, complain.
313000	314760	Yes, excellent.
314760	320080	So if anyone wants to say what they think or should I read it?
320080	326280	So Ben says, it's repeating scene in sync to the music sections,
326280	331240	moving on to the next loop of the scene
331240	334440	as the track moves to the next section.
334440	339200	Simon says, the camera feels like it is bouncing in rhythm.
341320	343560	That is, that is, that is wonderful.
343640	345160	Those are wonderful observations.
345160	349080	But like, guys, just turn on your microphones and just talk.
349080	351480	OK, don't make Ali read all of your all of your things.
352040	355360	So it will be more just more interactive, you know.
357120	359720	OK, so yes, that's exactly what's going on.
359920	363880	Everything is being repeated and is synced to the music and sync to the beat.
364160	366040	And Michel Goudre is very good at this.
366040	369040	He did this a couple of times and amazingly, he did this by hand.
369040	372480	So there's a very interesting YouTube video.
372520	376440	It's kind of like a documentary about the making of this video.
376440	381120	And you see how they charted out the entire score of the music
381360	383840	and planned out exactly what they're going to show.
385840	389360	Individuals and literally, literally compose this by hand.
389360	391200	There's no, there's no AI here or anything like that.
391800	396840	So the interesting thing is that this kind of combination
396840	401440	between your different senses plays a trick on you and gives you this surprise,
401440	403000	which makes it interesting.
403000	406360	But if you didn't notice what was going on, you would think, oh, yeah, you know,
406360	408280	it looks like it's real, but it's not.
408280	409560	There's nothing real about this.
409560	411160	It's completely composed.
412160	415840	OK, so so let's take a step back and talk a little about
415840	419800	but put ourselves in context and look at the history of what people did
419800	424040	in order to depict the world from the very beginning of art.
424960	428840	The main goal of art was to, you know,
429280	432120	capture the world realistically.
432120	435960	So they started with with cave drawings of prehistoric people
435960	440080	who saw these big cows with the big big horns
440080	444880	and wanted to wanted to capture them with coal on the on the
445920	448600	walls of their caves.
448600	452320	And going forward, many, many years, people got more sophisticated.
453040	458080	This is a very nice mosaic from the Byzantine time.
458080	462760	And there's already a lot of dress here and different people and a lot of details.
463880	467800	But at this time, all of the depiction of people was very, very flat.
467920	472360	So there's almost no depth in the image and everybody is kind of frontal
472600	477320	and has a very just nondescript
478680	484160	facial emotions that everybody's kind of like severe going forward.
484280	486480	You know, this is the beginning of the Renaissance.
486480	487720	So this is Giotto.
487720	491520	And this is one of the first times that depth appears in an image.
491840	494480	And the way he does it is kind of it's a nice trick.
494480	498680	He puts this person in green in front of Christ.
499040	503000	And it kind of draws your attention inwards into the image.
503240	505960	And you can notice, you know, people are not frontal here anymore.
505960	508920	This is kind of diverging
511040	513520	style from from the Byzantine style.
513800	516080	And you can see motion in their faces.
516080	518440	So it's becoming more and more realistic.
519680	522040	Things get even better in the Renaissance.
522040	525440	Here we already have linear perspective.
525440	529160	We have the little people in the back, you know, are smaller.
529160	531480	And we have people in the front, which are bigger.
531480	535920	And it kind of makes you feel like everything is going into the image.
535920	538160	And you can kind of walk into the scene.
538960	543640	And, of course, going a little bit forward, you know, we almost achieved
544560	546400	perfection in painting.
546400	548320	So this is Van Eyck.
548760	554360	And this is a beautiful painting where he has here geometric
554600	556480	orthogonal perspective.
556480	560600	And there's, you know, you can really walk into this image.
560800	565240	There's a lot of detail if you blow up, for example, the chandelier.
565240	568280	You can see how the light is bouncing on the metal.
568640	574640	The little flames of the candles are very, very nicely painted.
574640	577800	Everything is very realistic and even better.
577800	582280	He puts a mirror behind those those two people who are getting married here.
582600	585840	And you can get even a double depth in the image.
585840	589520	So you can walk into the image and you can even see the backs of the people
589520	592600	and the people who are looking at the people who are getting married.
593760	595560	So this is is really wonderful.
595760	601440	And even you can see the the little beads, the glass, the glass beads
601440	602760	that are hanging up.
602760	605320	It just is is almost perfect.
607960	610520	Of course, all of this this perfection
611840	613960	basically ended with the invention of the camera
614280	617480	because then you could just walk out or look out of your window
617480	619520	and take a snapshot and you're done, right?
619520	621040	You know, this is like, there you go.
621040	624000	This is the world, the world, you know, it is this is it.
624400	627400	Anything you want, you could take a picture of and it kind of
628800	632520	made this this break in the art world because suddenly,
633040	636400	you know, the people who would do your your portrait for a lot of money,
636400	638760	we're out of we're out of we're out of work in a way.
639680	642280	Of course, this raises different questions.
642280	647200	So once you have an image that you can take and the pixels are real,
647400	651640	then the question can become about whether whether is this a real picture?
651640	655040	Is this fake? You know, is this kiss that happened in Paris?
655040	657560	Was it was it really did it really happen for real?
657560	660080	Or was it a stage? This one was staged, by the way.
661640	665080	Are aliens actually descending on New York or is this a movie?
665080	667120	You know, is this a conspiracy theory?
667120	669240	Are the people actually land on the moon?
669240	673000	Or, you know, can I believe the pixels of the camera or not?
675360	680360	And interestingly and interestingly for us,
681240	685880	artists didn't actually give up after the invention of the camera.
686440	688760	They actually became more sophisticated.
688760	692560	So here there is a nice example from Monet.
692560	696640	It's an impressionist painting and you can see a parade in Paris.
696640	700280	There's a lot of people going and walking in the street.
700600	704640	And, you know, let's try let's try to get you talking a little bit.
704640	708320	So like, what do you notice in this image in this painting?
711360	714520	Anybody? What's interesting about it?
714520	716520	There's a lot of flags.
716520	718520	There's a lot of flags, yes.
718520	721520	And what's happening to the flags?
721520	723040	Oh, they're waving.
723040	727120	So it's like depicting motion and they're kind of blown in the wind.
728200	729880	Why do you think they're blowing in the wind?
729880	731880	What makes you think that?
733280	735480	They're blurry.
735480	737480	That's true. They are blurry.
738480	740360	But are they really blurry?
740360	743680	Like, is it is it fuzzy, like a Gaussian filter on top of them?
744280	746520	We're really like blow up a section here.
749720	753760	They're not like blurry in the in the normal sense,
753760	756680	but they're not rigidly defined.
756680	759920	So like the looseness of the brushstrokes
760280	765720	and the way that they all kind of have that implies the wind and the motion.
766520	768160	Exactly, exactly.
768160	775040	So these flags are basically built out of strips of blue and yellow and red,
775040	780160	which is the French plan, but they're not it's spatially imprecise.
780160	783000	They're kind of jumbled strokes of paint,
783000	785400	even though each stroke of paint is not blurry,
785800	788800	the juxtaposition of them is kind of all over the place.
789440	793960	And the interesting thing about this is that
794960	800600	this kind of matches really nicely to our peripheral vision.
800600	808200	So in our peripheral vision, we see things kind of in a spatially imprecise way.
808200	810200	It's not that we see things blurry.
810200	813960	It's just that we don't really care where exactly they are in the image.
813960	819440	So if you kind of look at this painting in a glance,
819440	822000	you kind of think to yourself, oh, everything is fine.
823000	827200	But when you actually look and take a very close look at it,
827200	830560	you see that everything is really, really jumbled because you're using your
831440	837200	your actual, you know, attentive vision in the middle of your of your of your viewing field.
837200	841920	And that is more takes more into account the spatial arrangement of stuff.
842240	845520	And so really to get a sense of this painting, you have to kind of look
845680	850440	in every time you take a good look at it, you get a different sense of what's going on
850440	854560	because your periphery is giving you a different a different sensation.
854680	857600	And that's what kind of gives this this vibrant motion.
857960	861600	So in a way, you know, you get an impression.
861600	864760	That's why they call it impressionist because you get an impression of what's going on
864760	866920	at every glance, but it's not really correct.
867280	870000	And this is how Monet is playing with your visual system
870000	872880	and making you feel like there's something real here like motion,
872880	875040	which is really not in the pixels themselves.
876640	879920	OK, so, you know, fast forward many, many years.
879920	881880	And we have computer graphics.
884400	887000	Can I interrupt and be a little perfectionist?
887000	890240	I think that I really love these slides.
890400	893280	There is this panel
893520	898800	built order from, you know, that maybe you want to close it.
899280	903200	Oh, no. Oh, no, thank you.
903960	906640	You know, this happened to me before and I should know this already.
907640	911280	OK, OK, thank you, thank you.
912000	913920	Oh, why don't you say something before?
913920	918200	OK, good to make a postman always, always close the build order.
920400	923760	OK, so we went to computer graphics, right?
924080	927200	And suddenly, oh, no, no, I don't have my little timer.
927200	930840	OK, I'm going to have to look at the clock and suddenly.
932520	935880	You could model the world physically, right?
935880	941000	You can make a physical model of the light and the and the objects
941000	943520	and the scene and you can render them perfectly.
944360	948600	But you could almost render them too perfect.
949320	953160	This is, you know, what you get out of of graphics a lot of the time
953480	955800	is super, super real.
955800	961280	But it kind of makes you feel and gives you a strange feeling.
961280	962960	It's kind of too realistic.
962960	965440	You know, everything is a little bit too clean.
966080	968080	Everything is a little bit too robotic.
969000	971000	Do you know why that is?
971000	973640	Why does it make you feel that way?
978880	981400	OK, so I'll give you my idea.
981400	985320	My idea is that what's missing is the noise.
985480	989920	What's missing is the junk, is the dirt, is the cracks in the sidewalk
989920	995040	that are kind of random, the suit on the buildings, you know,
995040	998440	all the all the all the noise, all the junk, basically,
999280	1004720	where our visual system is really used to seeing all this noise
1004720	1009080	in in the outside world, and there's a lot of beauty in this complexity
1009440	1012880	that when you take it away because you can't model it physically,
1012880	1017000	it's too complex to model, you know, our visual system just jumps in
1017000	1019520	and is like, oh, something is really wrong with this image.
1020760	1022760	And so this is very important perceptually.
1022760	1028840	And a lot of what I do is try to capture this complexity of the of the visual world.
1030120	1032160	OK, so we talked a little bit of our perception.
1032880	1037240	I want to make one more note about it, is that a lot of perception
1037240	1040080	is really in your head. It's not really what you see.
1040400	1042520	OK, so here's an example.
1042520	1048040	And if you look at this image and you look at the at the thing
1048040	1051040	that's that's in a red box, what is what do you see?
1053760	1062920	A soccer player, a player, yes, soccer player, yes, great soccer player.
1063360	1065800	But do you really think that there's a soccer player there?
1065800	1068800	Like if I take him and I magnify him.
1069760	1071960	Eh, it's just a bunch of pixels, right?
1071960	1074000	It's like there's white pixels, there's black pixels.
1074000	1075320	You can't really see the head.
1075320	1077760	There's a little bit of legs there, but there's really, you know,
1078160	1080400	there's there's really no player here, right?
1080400	1081680	Do you agree?
1081680	1087680	Like if you look at this and this, it's like, so a lot of what makes you think
1087680	1089880	there's a soccer player here is actually the context.
1089880	1093160	You know, there's a soccer field, it's in situation.
1093160	1095280	You're kind of like filling in the details.
1096000	1097160	Here's another example.
1097160	1100520	This is an image from a video that Antonio shot.
1101280	1106320	And it's kind of blurry, but but your brain can fill in the details.
1106320	1108720	What are you? What do you see here?
1111400	1117200	A man sitting at a computer with like a phone to his ear.
1117720	1118800	Exactly.
1118800	1123960	But if I show you the details, you suddenly see that everything is wrong.
1123960	1125160	White, he's not talking on the phone.
1125160	1127800	He's talking in the shoe and he's not looking at a computer.
1127800	1130000	He's looking at a at a garbage can.
1130000	1133400	OK, and the mouse is actually a stapler and there's a toaster there.
1133400	1138120	So everything is wrong, but the spatial configuration of the scene is fine.
1138280	1141160	And if you blur it out, your brain is just like, oh, this is fine.
1141160	1142920	You know, I'm just going to fill in the details.
1143840	1147520	So there are these loopholes of perception.
1148000	1150840	And this is a great opportunity for design.
1151520	1157160	And this is how we're going to weave in things that are not real,
1157440	1161280	but kind of make you think that they are as long as we're careful
1161280	1162840	to guard the important bits.
1162840	1166520	There are some there are some anchors of perception that we should care about.
1166960	1171000	And we have to make sure that they're there and your brain is going to do the rest.
1171560	1180560	OK, so what I'm going to cover today is I'm going to look at multiple examples of this.
1180560	1183280	So we're going to look a little bit at work that
1184720	1187400	looks at different senses and putting them together.
1187400	1190880	So here we're going to talk about audio and motion, so vision and hearing.
1191600	1194280	We're going to talk about modeling these complexities.
1194280	1198600	So the very, very fine details of individual appearance.
1199120	1204400	And we're going to talk about using time or using the passion,
1204400	1209720	the passing of time as a creative material.
1210400	1214040	I'll stop here and ask if there's any questions or complaints, and then I will continue.
1216240	1220760	OK, so let's talk first about audio and motion.
1221760	1226160	We're going to talk about how people move when they speak.
1226160	1230120	And it's the the what I'm talking about is going to look something like this.
1234320	1236120	I know how was it the personality travels?
1236120	1238560	Well, maybe there'll be some sort of physical explanation for it.
1238560	1244360	So people move when they speak and these are called conversational gestures.
1244360	1247440	OK, there's the kind of stuff that we do when when we speak.
1247440	1250440	And we never do basically when we don't when we don't talk.
1251080	1256080	And this type of gesture is not the only form of communicative gesture.
1256080	1260080	There's a continuum from language that accompanies speech, sorry,
1260080	1265000	language that accompanies motion that accompanies language to motion
1265000	1266240	that replaces language.
1266240	1269600	So, for example, sign language is a language of its own.
1269840	1272760	It doesn't need speech to go with it.
1272760	1277280	And blends are like Italian, like there's all kinds of things that Italians do,
1277280	1280400	which kind of have meanings that people agree upon.
1280400	1283000	So it's almost like a language.
1283000	1284840	But we're not going to talk about these things.
1284840	1289400	We're going to talk about the motion that accompanies speech when you do talk.
1292640	1297120	So what we want here is you want to learn about how people use gestures
1297120	1302840	when they speak and to do that, we're going to take in a raw audio signal of speech.
1302840	1304640	So literally the waveform.
1304640	1308160	And from that, we want to directly predict hand and arm gestures.
1308200	1309960	So it's going to look something like this.
1315280	1317400	So this is a really, really hard question.
1317400	1319720	OK, it's an ill-defined problem.
1319960	1323760	There's not a one to one correspondence between the audio and the motion
1323760	1326640	because I can say something today and move in a particular way
1326640	1328840	and do it a completely different tomorrow.
1329920	1331920	It's not synchronous.
1331920	1336640	The motion is often not synchronous to the related utterance.
1337120	1341760	And it's also a task that would be really hard for people to do or even to annotate for you.
1341760	1345600	So getting supervised learning in this setup is really, really hard.
1347480	1353480	And what we want to do is we want to, you know, learn about this in kind of in the wild setting.
1353680	1359040	So what we did is we went and collected a large data set of people who are speaking.
1359480	1366160	And for each frame, we annotated it automatically using an out of the box
1367040	1368640	2D pose detection.
1368640	1372960	So it kind of finds the pose of the arms of the hand and the hands of the people.
1373320	1375120	And the data looks kind of like this.
1381000	1383200	Waiting outside. Why are you telling me all this?
1383200	1385160	And you're not going to believe what they said they want to do.
1386240	1388640	Isn't that disgusting? It's 2012.
1388840	1391200	We're still not on the.
1391200	1394040	And then report it to the police.
1394040	1398640	Even Lauer's conversations light more photons per second.
1399320	1402840	Still none of the two young to be vaccinated.
1402840	1405120	And why would you choose not to do that?
1405120	1409320	So you can already see that people are very different in how they gesticulate.
1409600	1412400	But within a person, there's a lot of repetition.
1412400	1417640	And here I'm showing clusters in in the rows of clusters of gestures.
1418720	1422720	And this is because people just tend to perform the same motions over and over again,
1422840	1425000	because they have their typical style.
1425560	1428040	And that's great because it gives us a learning signal.
1428040	1431640	And so what we're going to do here is we're going to model each person individually.
1432520	1436160	And the way we're going to predict gestures from audio is we're literally going to take
1436160	1438200	the raw audio as input.
1438200	1439680	We're going to treat it like an image.
1439680	1442080	So we're going to think about it as a spectrogram.
1442120	1447200	We're going to stick it into a neural network and we're going to output a temporal series of poses.
1447640	1451400	And what each one of these really is, is just a vector of numbers.
1451560	1455640	But they represent the pose of the arms and hands of a person.
1457240	1458680	And the result looks like this.
1463080	1465320	So, you know, try and separate the two.
1465960	1472280	OK. Now the good news is the one thing to notice is, you know, for this given audio,
1472480	1476720	we predict a stack of these poses and we have two kinds of losses.
1476760	1480880	One is the regression loss to this pseudo ground truth of 2D poses that we have.
1481480	1487880	But what we really want is we want to generate motion according to the style of this particular person.
1488720	1498080	And so we add another adversarial loss that will tell us whether the motion is real or not with respect
1498080	1504360	to this person. And this makes a really big difference perceptually, because I'm going to show you here
1504360	1509560	on the left, you're going to see the result when you only have a regression.
1509560	1514600	And what happens when you do that is that you kind of get something that's very close to the mean.
1514600	1516560	So the motion is just very, very slow.
1516560	1518520	It's kind of like you're going through honey.
1519120	1525040	And when you add this adversarial loss, you kind of snap to one mode of the output because, you know,
1525040	1529640	I could have predicted different gestures, but I'm going to pick just one and make it look real.
1529800	1531680	OK. So that's going to be on the right hand side.
1532640	1539240	So, you know, it makes us feel a little bit better about what we're seeing.
1539240	1542080	And here, by the way, I'm pasting in the face.
1542080	1546640	I'm not predicting the face in this work, but I'm pasting in the ground truth face to give you more
1546640	1551040	perceptual context to see what, to kind of understand what you're seeing.
1552040	1558240	OK. So we can also look at prediction results for different people and just look at what it looks like.
1558800	1563960	Talking about the instantaneous rate, the rate, just when the concentration and I'm putting the ground truth
1563960	1570400	video on the bottom right, even though, you know, I could really have predicted any realistic motion.
1570400	1573880	I don't really want to predict the real one, but it's just for reference.
1573880	1580880	Energy to boil. Higher kinetic energy, higher temperature.
1581880	1585880	Logo in order to make it more modern. Yeah.
1588880	1590880	Yeah. Appropriate noise for that. Thank you.
1590880	1595880	That is where this method fails. So we're only taking audio as input.
1595880	1600880	There's no, like, there's no, you know, text, there's no semantics.
1600880	1610880	So the main limitation here is that even though we're using hours of data for training, we really, there's really not enough data to capture.
1610880	1616880	The cement, you know, fine grain semantics in order to predict metaphoric testers.
1616880	1618880	So I'm going to show you a video here.
1618880	1621880	And I want you to notice what happens when he says the word random.
1622880	1629880	So we, we don't get the circular motion that goes with random. We just can't predict that.
1629880	1638880	But we do predict the beat motion, which is these up and down repetitive motion that kind of comes with random motion.
1638880	1641880	So we don't get the circular motion that goes with random.
1642880	1659880	We just can't predict that. But we do predict the beat motion, which is these up and down repetitive motion that kind of cut the sentence temporally and make us feel like the person is actually moving while they're talking, which is, which is nice.
1660880	1671880	Another thing that's, that's interesting about this is that it's a little bit hard to do this kind of work the way that I described it.
1671880	1679880	And that is because the most important part of the body when you're speaking with your hands basically is, is the hands, right.
1679880	1696880	And the hands are very, very small in an image. And they're very articulated the fingers. And we're just not there yet in terms of computer vision 3D reconstruction techniques to get really good hand estimations.
1696880	1715880	And so our entire everything we did depends on the fact that we have good, good, you know, detections of body pose and that's not the case. So here's an example, just a randomly picked example from Ellen, Ellen's videos and you can see what happens if you just use an image based system to get the hand reconstructions.
1716880	1728880	To a CBS for one item. And the receipt was so long that I couldn't even believe it. I called it outrageous. I called it mind boggling. I called it long.
1728880	1736880	Okay, so this is complete junk, right, like if you try to request to this and everything would with fail miserably. So what do you do.
1736880	1747880	One thing that we noticed that is actually super interesting is that there is a really high correlation between the motion of the arms and the shape of the hand.
1747880	1769880	So we're going to do a trick and we're going to take as input not only the audio. If we want to get better hands but you can look at just taking the arms as input, and only from the arms, the arm motion, you can predict a pretty good shape of the hands which is which is almost seems magical.
1769880	1778880	And so if you do this body to hand thing, what you get looks like this.
1778880	1780880	Electrons around it.
1780880	1795880	The atomic oxygen would have six. So it has two more than it normally has. So there's like there's no pixel going in there's no audio going into here there's literally just the motion of the arms and it's it's amazing that it even works.
1796880	1804880	Again, there's not enough information right so it's not enough to capture metaphoric so if you see here.
1804880	1808880	She's got this.
1809880	1815880	And this is the ground truth video okay.
1815880	1828880	To a CBS for one item. And if you just take the arms, you're not going to get that it looks like this.
1829880	1843880	And so you can do an extra trick and you can say okay well I can take in the body but I can also just look at the input images because that's what image based reconstruction does anyways.
1843880	1848880	And together with this body prior, I can get a much better hand reconstruction.
1848880	1860880	So here on the left is the is the body only input no audio no pixels. And on the right, I have the body and the image together.
1860880	1869880	To a CBS for one item. And the receipt was so long that I couldn't even believe it I called it outrageous I called it mind boggling I called it long.
1869880	1877880	So this is already better this time like, you know, this is stuff that we can work with already and it looks much more realistic.
1877880	1883880	Are there any basic restrictions according to just like human anatomy that are also used within the model.
1883880	1885880	Sorry saying it.
1885880	1895880	Are there any just base restrictions on what movement is possible according to human anatomy like you can't completely I don't know. Yeah.
1895880	1898880	And not.
1898880	1904880	Sorry, I'm speaking to you from the garage so there's there's exciting background noise.
1904880	1913880	And not in my model. Okay, but there is in those.
1913880	1923880	So when we use, when we use ground truth that's coming from 2D reconstruction of key points or 3D reconstruction of hands in this case.
1923880	1930880	Those models have a lot of, you know, human pose priors built into them.
1930880	1948880	But we don't. So we're at we're kind of the goal of the, of the body to hands angle is to add an additional fire but one that is not based on, you know, physics that you might calculate from human bodies but it is based on a data driven prior.
1948880	1954880	So if you've seen enough bodies, you can infer this automatically. Does that answer your question.
1954880	1955880	Yes, thank you.
1955880	1964880	Cool. All right. So, let's see what time is it when do we stop at on the hour right.
1964880	1972880	Yeah, I mean we could, we could go a little further if you want. No, no, no, I'm just like I can I can I have a lot of stuff but I'm just going to cut accordingly.
1972880	1980880	So I'm going to show you the more interesting. I think that we said 2pm for students but it's. Yeah, that's fine. Okay.
1980880	1994880	So, okay, so in this work, we really only care to predict 2D motion because we that's what we were, we were interested in. And these stick figures are a nice output representation.
1994880	2004880	But they don't really provide you enough perceptual context as a viewer to actually see that what the result looks like if we do a good job. Okay.
2004880	2017880	So instead we can synthesize a video, an actual video the speaker so we what are we going to do we're going to take a real video of the speaker and
2017880	2034880	right, we can do the same trick where we get a 2d pose detection. And our goal is to learn the mapping between these 2d pose skeletons back to the real frame of the person and this is based on picks to picks you know you probably
2034880	2039880	you know we stole us so this is this is based on his work, but we're going to do this for a video.
2039880	2053880	So if you do that, what you get is something like this, where again, I'm pasting in the ground truth face key points because I'm not predicting that but I need them to make a video right so it's going to look like this.
2053880	2070880	Try and separate the two. Now, now the good news is, these days, very few people will say they are completely and I just want to like focus you on this. This is a completely fake video. Okay, it's completely synthesized there is like, there's nothing real about it.
2070880	2089880	And it's actually being predicted from raw audio with this 2d, you know system that gives us only the pose. And, and that's kind of amazing. It's, it's the coolest thing about this is that not only can we synthesize a realistically looking
2090880	2097880	video, but we also managed to capture a very convincing motion of the person.
2097880	2115880	Mostly what what makes you think that it's good is those beat gestures it's like okay I'm talking and I'm chopping up my sentence and there's kind of going with the same rhythm as my voice and not as convincing enough for people to think that that this is real.
2115880	2118880	Okay.
2118880	2131880	We're making fake videos, basically. Okay, so it's interesting to think about what can we do in order to decide whether a video was faked or not.
2131880	2144880	And it turns out that the same kind of idea can be applied to forensics as well. So I'm going to show you an example let's look at Obama and like look at this is from his address to the nation which he used to do every week.
2144880	2152880	And I want you to say to see what he does when he says you know hello everybody.
2152880	2173880	Hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, hi everybody, he has this like upward motion. And basically, if you have the right words, and you have the right motion together, then it's Obama.
2173880	2189880	But if you try to do some deep fake of him and you try to change his lips and you know make him say something different, you wouldn't get the right motion to go with this. And this is like a great signal to see that something is fake.
2189880	2209880	And this is a really nice line of work that shorty did you see broccoli with honey for a while they look at exactly this kind of thing so it uses the, you know the whole of the person all of the details in multiple modalities to detect things that are fake.
2210880	2220880	All right, I'm going to move a little bit to something else if there's any question this is a good time.
2220880	2229880	Okay, so let's talk a little bit more about this idea of learning on the little details of a person, a person's appearance.
2229880	2238880	We're going to consider a very special style of gesture which is dance. And it's an art for it's been around since the beginning of time.
2238880	2254880	But frankly, nobody's really figured out how to capture the little subtleties of it. And what we're going to do is we're going to start we're just going to start directly by looking at a demo. Okay, so look at what what we can do.
2260880	2262880	Oh
2265880	2267880	Oh
2268880	2270880	To me
2271880	2273880	Close
2274880	2281880	If I tell my heart I'll still feel pain Whatever I do still feels the same
2282880	2284880	Nothing but tell me now
2287880	2290880	Everything we had well it's gone to waste
2293880	2302880	What we're doing here is we're taking this source video, we're detecting its pose and we're puppeting our target person to dance in the same way.
2302880	2315880	And it looks really nice, but I'm actually using a trick on you I'm using a perceptual loophole and and this is really interesting we usually don't show this but it turns out that the music is very helpful.
2315880	2321880	Okay, I'm going to show you exactly the same result without the audio and I want you to notice if it looks different to you.
2332880	2334880	Okay.
2358880	2360880	Okay, anyone
2360880	2366880	Mostly just look super unnatural where before it looked like it actually like was dancing.
2366880	2382880	It's awful right it's like everything is moving it's kind of wobbly and like, you know, just, just not right right. And it's really interesting it's exactly the same pixels okay I just turned off the audio, but when I show it to you with audio.
2383880	2390880	Your perceptual system is like whoa there's like music and there's dancing and it's together and you're filling in the holes.
2390880	2404880	You really are. And it's very important it turns out when you're showing a demo if you guys go and do things and design or and even an AI to kind of set it up in a way that that makes people be in their happy places.
2404880	2419880	And use multiple senses when they're when they're looking at something and it actually makes it look better than that it really is. And our goal here is actually not to make a perfect video I don't really want to be in the business of making people do things that they
2419880	2430880	didn't do our goal is to study you know the statistics and whatever, but that it is very helpful to use this different senses. Okay, so what are we doing here.
2430880	2445880	In a way, it turns out that we can use the same technology we talked about before to transfer dance motion from one person who knows how to dance to a different person who is a terrible dancer, like my co author here, think way.
2446880	2452880	And this is basically motion that's not conditioned on audio it's conditioned on different people.
2452880	2458880	And training is the same we train a cycle from you to your stick figure and back to you.
2458880	2469880	And you can think about it as trying to go from you to full reconstruction of you through this tiny little bottleneck, which is these 2d poses that are not learned.
2469880	2478880	And the idea here is to get learned a really good mapping from this stick figure back to the appearance of the person.
2478880	2490880	Because I really want to model what he looks like. I want to capture all the little minute details of his body and the way that he kind of, you know, looks when he's moving.
2490880	2504880	And I want to get the stuff that you can river really annotate and want to get all the complexity this this beauty in the details. This is what I want. So the goal here is not to start from a single image of a person and make them dance.
2504880	2512880	The goal is to actually model this person and for that I need a bunch of training data of this person from different poses.
2512880	2520880	And at test time, we unwrap the cycle, and we put a different person on the other hand.
2520880	2526880	So here test and training are not the same in purpose and this is different from a lot of other methods.
2526880	2540880	And these stick figures are a nicer presentation in the middle, because you're kind of agnostic for appearance like you could be, you know, bigger or smaller and width, but but it doesn't really matter for for your skeletal structure.
2540880	2551880	So if we managed to learn a good model of our target guy, we should be able to sample any new pose from this ballerina and synthesize a new image of the way.
2551880	2558880	And this is good because a good model of appearance to generalize to new poses.
2558880	2569880	So I'm using video synthesis kind of like at school it's like show your work, you know the generated video is as is a test of whether our modeling or perception of this guy really worked.
2569880	2589880	Okay, so we do some tricks to make this not you know frame by frame and achieve a temporal coherence which is which is important perceptually, but I actually want to talk about something else I want to talk about the fact that the face is very important perceptually.
2589880	2606880	Okay, and we didn't affect this this is, this is Renoir, and there's something really interesting about this painting, which is basically that there's different resolution of painting between different parts of the image right.
2606880	2617880	The face is very, very sharp, and the eyes are extremely sharp you can even see like the the glint of the of the lighting reflecting on her pupil.
2617880	2623880	But everything else is fuzzy, and it's kind of like the flags we saw before it's like not really in place.
2623880	2644880	This is something very, very interesting, it makes you draw your gaze to her eyes, which are the most expressive part of the face, it gives you an emotional reaction, and it makes you ignore everything else because everything else is in your periphery which is not really
2644880	2653880	attuned to spatial relationships anyways, and it kind of mimics our own perceptual experience.
2653880	2663880	When we gaze into someone else's eyes like somebody that we really love or somebody that we really want to listen to it's always you know everything else about their body is in the periphery.
2663880	2679880	So, so this is kind of the trick that Renoir is doing is playing on you, and we're going to play the same trick. Okay, so, so, you know this is this was done before amazing gans were around and so we didn't have the technology to make everything look perfect.
2679880	2693880	Okay, the face is important. If we get the face right, people will say oh this looks nice. So we actually devote a special again just to the face region, in order to correct it and more realistic.
2693880	2709880	It makes a big difference. So, if this is the baseline, this is after temporal swathing, this is what happens when we add an additional again for the face itself and it kind of looks almost like Caroline, who used to be my undergrad and did this work.
2709880	2715880	And now she's, she's a full grown PhD with you guys at MIT.
2715880	2743880	And, and you can see her dancing in all of these videos, like this one.
2743880	2754880	Okay, and we can also do the same thing we take a motion one person and we can apply it to many people. And there, when it's small of course the face matters less.
2773880	2794880	And we turn it into a controllable interactive application that got a lot of attention to the field of image and video synthesis. It appeared in popular press it exhibited and museums, it was incorporated into stage performances.
2794880	2805880	And now my co author, the same guy who doesn't know how to dance, even turn this into an app that you can download for free from the app store and you can dance and tick tock and whatever you want with it.
2806880	2824880	And this is interesting. But another direction that we kind of have been discussing a word to take this technology is to provide a platform for capturing performance as a form of intellectual property for for choreography.
2824880	2832880	Because it turns out that unlike musical score that can be copyrighted, there's no way to copyright dance.
2832880	2847880	In fact, there wasn't even a way to capture dance in the West until the 20th century. So most of the belays that we know of like Swan Lake and you know, all of these even the famous ones, haven't really survived in their original form.
2847880	2861880	Until this day there isn't an agreed upon notation of dance and this is just one example which is called the monetization, but all of the, all of the forms of notation.
2861880	2874880	They don't have a way to accurately capture all the small details. They're not parametric they're not scalable every time you come up with a different move you have to come up with a different notation.
2874880	2888880	And our, our idea is that capturing things the way that we do can can try and get to these to these issues and maybe offer a new solution.
2888880	2893880	So we talked a little bit about the fact that there is artifacts but
2894880	2909880	Actually, it turns out that that is the interesting part about this technology to a lot of artists. So here's, here's one example where the same team plays little company had a gig where they made this music video.
2909880	2917880	It's really celebrating the problems in this technology and making them into art.
2917880	2946880	And here's another example that I really love. This isn't actually using our work it's using that to bid but it's very, very similar so you can ignore the differences and just focus on what this person is doing with this.
2977880	2994880	Thank you.
3007880	3008880	Thank you.
3037880	3061880	Thank you.
3061880	3086880	Perfect. But Jake here really loves those and he's actually pushing it like to the extreme extreme so there's all this hair and the feathers which are really, really hard to capture for guns, but that he's just like let's throw it all in and just let it, you know, be artistic and and and this is kind of what he's been looking for in using these technologies.
3086880	3107880	Okay, but, but there's also a limitation on how you can use this kind of stuff for art, because essentially what we're doing when we generate images or we generate video or motion using again is that we're always using a training set which is real.
3107880	3126880	Okay, and we're trying to teach AI how to make us more of this real thing. Okay, so, so we want to, you know, maybe generalize out of the distribution of the training set but not by much we still want to keep things realistic that's our training signal.
3126880	3140880	And this is this becomes a limitation when you want to do something like this so so these are visuals from New York's tabula bassa music video.
3140880	3149880	And this actually goes with a with a large performance and show that she had a year ago.
3149880	3162880	And what they wanted here and they actually came to us to ask for help in order to do this and we couldn't help them what they wanted to do is they wanted to have this marriage between a human and an orchid.
3162880	3174880	So, so they want the motion and they use mocap for this but they want the motion to come from a human but the visuals and kind of the embellishment to come from a flower.
3174880	3194880	And there's nothing that we can do to help them, because we don't yet have this ability to do this compositionality between different realistic things to make something to make a new kind of life for him if you may.
3194880	3204880	We just can't do there's we don't know how to do this. So this is something that is that is a limitation of training to do realism.
3204880	3218880	And it's a very interesting future direction from work if you're looking for something really cool to do this this kind of idea can give you can give you a nice direction that we don't know how to solve yet.
3218880	3224880	So how did they do that. How did they did it by hand they did it by hand so.
3224880	3236880	So they, this is a really cool artist. He's also a professor I think in Hong Kong or one something like that. And they did motion capture on the people.
3236880	3258880	They have the motion signatures, but everything else is hand designed, you know, 3D models and add motion that is that is basically put together with with its dressed, you know, it's, it's dressed on top of the human motion.
3259880	3272880	What they wanted would have been similar to people who are here in the class. The other day there was some AI that could make pictures out of like the texture of the skin of an elephant or something.
3272880	3276880	Like the texture of noodles would have been similar to that.
3276880	3285880	Like you had a face and then you draw it with the texture of say noodles and then you change the noodles to make it look like it's talking.
3285880	3297880	So that's one. So you mean like the Geiger paper, right. The counterfactual paper. And there's also, I know you guys looked yesterday at the Lee. So there's different.
3297880	3311880	Yeah, that's one approach to do that. It's a little bit right now that technology is not yet.
3312880	3328880	But if you take those noodles and you make them in the shape of a dog or whatever, it's still noodles, you know, and you just cut them into dog. There's nothing that really takes the texture and like kind of applies it onto the 3D form.
3328880	3336880	So you see here if you look at the at the texture of the flower, it really changes with the articulation of the flower, right.
3337880	3352880	If you just take noodles and you, you know, you make the right mask for them, it's still it's not yet realistic, right. And this is again something we don't know how to do we don't know if you look at the cycle again results for example.
3352880	3370880	It doesn't conform to the 3D shape of the object. It doesn't actually respect that. So, yes, that's in the right direction, but it's not yet there. All of this is open problems.
3370880	3373880	Answer your question.
3373880	3377880	Yeah, yeah, just stuff to think about it's neat neat stuff.
3377880	3392880	This is really cool. I don't know how to solve this but it's this is a cool, this is a cool, cool idea, cool, cool direction. Okay, I literally have three minutes so I am going to have more stuff so
3392880	3405880	the rest of the stuff I wanted to talk about would have been kind of designing with with time using time was as an interesting medium.
3405880	3419880	And I guess what I can do is just just tell you two different highlights. Okay, so I'm not going to really walk you through all of the story here, but
3419880	3430880	let's see. If we think about if we think about time and we think about images not from video but like large collections of images.
3430880	3442880	There's something really interesting about them and the interesting things is that a lot of the time when you think about historical data you think about text, but but you don't really write everything down.
3442880	3455880	And, and those are things that are really captured in images, and we're lucky we're very, very lucky that we have now basically more than 100 years of historical visual record.
3455880	3470880	And the things that you get from that are things that are you know you can look at this image and kind of think to yourself you know if 100 years from now somebody wanted to explain in a history book, what are hipsters, it would be really
3470880	3484880	really hard, because, you know, here you can see the difference between nerds and hipsters and you know what is it that makes these guys look cool is it is it hats, is it the scarves that the Instagram filter that was slapped on the image like is you know what is.
3485880	3488880	It's really hard to say in words.
3488880	3494880	And in any case we don't really bother to talk about these things when we write stuff down.
3494880	3499880	And so historical images kind of captured this for us.
3499880	3511880	But of course then we kind of you know if you took a collection of historical images you kind of end up with you know a bunch of historical images that you need to sort through and you end up selling in the garage sale because it's too much work.
3511880	3528880	So if there is a way to automatically get, you know, how do things change over time from images that would be really cool. And that's stuff that we've done a couple of times here this is work with historical yearbooks high school
3528880	3538880	yearbooks, which is a really nice source of data because there's spaces and they always stay the same but what changes is fashions and social norms.
3538880	3555880	And what you can do with with a lot of data like this that has kind of a consistent subject matter but changes over time is something like Jason Sullivan here who is an artist has done with his graduating class versus his mother so he graduated
3555880	3571880	in 1988 from Fort Worth in Texas. And on the left you see an average image of all the people in his classroom the women and the men versus on the right the ones that came from his mother's class of 67 and you can already see that there's big differences
3571880	3588880	right people used to look different these to stress a little bit different. They used to treat the camera a little bit differently. And we did the same thing with our data, where we took, you know, 100 years of photographs and we looked at averages of men versus
3588880	3601880	women over time and you can notice that people, you know, look a little bit different that the hair is different they smile more than they used to, you can quantify this kind of thing.
3601880	3617880	You can look for other characteristic elements for different decades like different hairstyles that are very distinctive.
3617880	3628880	And this gives you tools for analysis of creativity and fashion, but we're not going to look at this but instead what we're going to say is, okay.
3628880	3644880	This is interesting you can do this with spaces everything is very online you can look at fashion but what happens if you want to think about time and in the real world in the outdoor world how can you use a time as a, as a, as a creative medium.
3644880	3663880	And so one thing we did afterwards is we went and looked at a lot of data coming from street view images, and we looked at whether we can say okay let's say I want to travel in time I'm stuck in a pandemic and I want to go visit New York but I want to make sure that I did it on a particular
3663880	3676880	Sunday afternoon in 2011 okay how can I do this is so maybe I can use flicker images if I want to go to Columbus Circle, but if I want to go to some random corner there's just not.
3676880	3679880	There's just not the people just don't take pictures there.
3679880	3698880	So what we did is we went and looked at the Google time machine, which is basically your normal street view interface but they actually keep historical images of the previous runs of the of the cars through the city, and that gives you a single location with
3698880	3710880	different riding conditions and different weather conditions. And this is really cool because you can collect this at a really large scale, like, you know, all of New York or basically the entire world.
3710880	3725880	And then for each location you have multiple snapshots of that place, only there's still very sparse, and to go to this place in a particular day and time you have to learn how to fill in the gaps.
3725880	3732880	Okay, because you know the buildings stay the same, but the weather conditions might change.
3732880	3740880	So the travel and time you want to take a particular image and you want to be able to change the lighting and the, and the weather.
3740880	3748880	So basically what you want to do is you need to disentangle or learn to disentangle the things that are varying temporally versus the things that are permanent.
3748880	3761880	And if you can do that, then you can use time basically to synthesize new things that you know you never really captured they might have existed but you don't know because you weren't there.
3761880	3770880	And so for a particular scene, you can do things like you can rotate the sun around and this is completely synthetic right this is a result of what we do.
3770880	3787880	Or you can copy and paste buildings, for example, so you can modify the permanent factor, and that would look something like this right here's here's an inserted building it looks perfect but but it's completely fake.
3787880	3798880	And I'm not going I'm going to, you know, just not going to go into the technical detail of how it's done but basically the thing that helps us is that we've seen the same place over and over again.
3798880	3803880	The one thing I do want to talk about is that the nugget.
3803880	3819880	The technical nugget that we use here is that we can use a decomposition of the scene into two things that graphics tells us that are, you know,
3819880	3830880	the correct, which is the difference between shading and reflectance where shading kind of captures the shadows and the effects of the illumination on the scene.
3830880	3843880	And the reflectance is the actual color so I'm wearing an actual blue sweater, that would be the reflectance of the sweater and then there's the effects of the light on it that puts in the shadow.
3843880	3859880	The thing about about these this this shadow representations this the shading representation is that we're we in our mind we think about the fact that maybe shadows are gray is like if you think about them as grayscale but they're actually not.
3859880	3862880	Okay, and this this is the interesting thing for sexually here.
3862880	3875880	And you can see this in this nice painting by Monet. Okay, so, so Monet is painting a grain stack that is sitting in a set of snow on the ground so the snow should be white the ground is white.
3875880	3879880	But there's actually two colors for the illumination.
3879880	3882880	There's blue from the sky.
3882880	3886880	And that is kind of an indirect diffuse light.
3886880	3890880	And there is a direct light that is yellow from the sun.
3890880	3896880	And if you look at the shadow that's being cast on the snow.
3896880	3908880	In the shadow, it's blue, because the direct light doesn't hit doesn't hit the snow and so you mostly get the indirect illumination from the sky.
3908880	3923880	So the blue then the surrounding light, which has the yellow mixed into it. And when I was doing a trick here where he's actually coloring with the yellow to complement the blue just in the border to make it even more clear to your, your, you know, your center
3923880	3937880	surround cells and your in your eyes that this is what's happening. Okay, so, so the trick here to get everything to look realistic was to say okay, people before I have kind of thought about shading as a grayscale thing.
3938880	3952880	And most of the color in their models have gone to the reflectance images, but we actually use a two toned shading where we take separately into account the blue and the yellow.
3952880	3965880	And we are trying to really capture a lot of the blue of the sky in the shading model and not in the reflectance model. And that kind of makes everything come more together and look more realistic.
3965880	3982880	And then we can say okay and you know we generalize we take an image from a completely unseen place like Paris we've never been to Paris we didn't train on Paris this is like a one image example and we can relate it and make it look like you've been there and whenever you want, basically.
3982880	3994880	Okay, so now I am very much over time. So I am going to stop here we've looked at audio motion we've looked at details we've looked at visual patterns over time.
3995880	4006880	There's there's some food for thought you can take out of here like, you know, for example, AI and perception we can use it to create tools for art design.
4006880	4013880	There's good and bad implications you have to think about what happens when you make synthetic or fake content.
4013880	4020880	And we've talked about modeling all kinds of complex things and multimodal stuff.
4020880	4024880	But there's a lot of stuff that's left to be done.
4024880	4040880	For example, the example of the person in the orchid and compositionality. And there's also the question of how do you not only provide tools that are creative, but also create creative machines and I think you're going to learn about that more later this week.
4040880	4049880	One final note is, if you want to learn more about perception and art. This is a great book by Margaret Livingston from Harvard.
4049880	4054880	And these are collaborators, thank you all collaborators and that's about it.
4054880	4057880	Thank you.
4057880	4064880	Thank you so much that was very, very interesting and intriguing and inspiring.
4064880	4067880	Oh, I'm sorry I went a little bit over time.
4067880	4069880	I was trying to like, lower the details.
4069880	4083880	I'm sure that there are many interesting things I personally learned and also students hopefully inspired their thoughts and the future work.
4083880	4089880	Is there any question from students.
4089880	4094880	I think that most of them are thanking you and I see that in the chat.
4094880	4097880	Oh chat. Okay.
4097880	4100880	Yeah, I think that.
4100880	4104880	Okay, cool.
4104880	4106880	Excellent.
4106880	4109880	Thank you again. It was a great talk.
4109880	4110880	Thank you.
4110880	4119880	I'm very excited to, you know, put this online so everyone can benefit from it.
4119880	4121880	Cool.
4121880	4123880	Thank you so much.
4123880	4124880	Bye.
4124880	4125880	Bye now.
