The special speaker that we have today is Professor Ahmed
Al-Gamal.
He's a professor in the Department of Computer Science
at Rutgers University and also the founder of the Art
and Artificial Intelligence Lab at Rutgers.
So let us ask Professor Al-Gamal to be a little more
introduce themselves and give us a little background
and talk.
One thing that I wanted to mention
is that his talk is today is about the shape of the art
history in the eyes of the machine.
And I think that he has done many interesting work
in the realm of understanding the patterns and evolution
of art through the history.
Please go ahead.
Thank you.
Thank you very much.
Thank you for inviting me and thank everybody who is here.
I'll start by answering a question you asked earlier
about why I'm doing this.
And I think it will be more also clear during the talk.
Basically, during my high school years,
I mean, I was raised up in Alexandria, Egypt.
And when you raise up in the country,
it all has to be like that.
You see a lot of archaeology and history and art.
And I really wanted to study archaeology and art history.
That was really my passion.
But at the same time, computer science
was something totally new at that time around the 1990s.
And I was fascinated by it.
I had to choose a major.
So everybody would tell me, if you go to archaeology,
art history, you'll have no career and make no money.
And I went to study computer science.
And for the last 25 years, I've been doing AI.
But I find that actually my passion is really in art.
Every time I go to the division conference,
I escape 90% of the conference.
And I go to galleries and museums rather than
attending the sessions.
And I realize I have to do something about it.
And it will be clear in the talk basically
how I moved into doing that and why I moved to do that.
So let me just start right away by sharing my screen.
So basically, as an AI researcher,
or when I look at images like that,
I mean, we'll be very happy if the machine will recognize
there's a man, there's a woman, there's fruits, there's trees.
There are trees and things like that.
That's what we do in vision.
And that's what I've been doing for a long time also.
However, basically, we realize that art, when you look at art,
is much more than that.
There are layers and layers of historical context,
social context, understanding.
There are emotions that happens.
I mean, art is not about object recognition or anything like that.
We see it as recognition.
It's much more.
And since the ultimate goal of AI research
is to make the machine, make machine
that have perceptual, cognitive, and intellectual abilities
similar to those of humans, I find
that analysis of paintings, whatever analysis means,
involve actually all these tasks, perception, cognition,
and intellectual abilities.
And that's why I think it's very important to advance AI
to look at art and try to understand art the same way human does.
So basically, I find that the ability to understand and generate
human-level creative products, such as poetry, stories,
jokes, music, paintings, is fundamental
to show that artificial intelligence algorithm
are actually intelligence.
And the first question that always
being asked when I give talks, especially in humanities,
with audience from humanities, is how to combine art and AI.
Basically, art is a judgment, which is subjective,
and science is objective.
How can this be combined?
And that's a very important question.
And actually, it's rooted in Western philosophy.
Basically, Western philosophy has blazed aesthetic comprehension
in the realm of subjectivity.
And we can trace that back to Immanuel Kant in 18th century
when in his book about critique of the judgment,
when he basically argued that the judgment of taste
is not cognitive judgment, it's not logical,
but aesthetic, which means that it's
one whose determinant ground cannot be other than subjective.
And that actually shaped the separation between art and science
in the last two centuries.
So another quote here from Colin Martindale,
who is a psychology professor at University of Maine,
who has a totally different, opposite point of view.
As a scientist, I feel that if everything in the universe
is governed by laws, then art history must be as well.
So totally scientific approach, basically nothing is subjective.
And another viewpoint from Eric Kindle,
who's a neuroscientist and winner of Nobel Prize,
by examining perception of art as an interpretation of science
we experience, scientific eyes can, in principle,
describe how the brain perceives and responds to art.
And let me go into basically saying, can any aspect of art,
which is creative and subjective experience,
be studied objectively?
And finally, a quote from an art historian,
which is very unusual art historian.
His name is George Kubler from his book, The Shape of Time,
which I'm going to talk about in the talk a little bit later.
He's saying basically that art history could
move to contain unexpected potentiality
as a predictive science.
This is very uncommon view in art history.
So my goal is really to understand
what art the implication of looking at art
through the eyes of the machine.
And by that I mean AI in particular.
That's why I started the AI lab about maybe eight years ago
at Rutgers, really focusing on advancing AI by looking at art
and also seeing what can we do about art if we do AI.
And here are some of my collaborators from art history,
from fine art, and have been blessed to work
with many students from Rutgers and from other universities
as well.
And these are some of the activities
that have been done through the years, many others.
And these are some things I'm going to talk about today.
Building models to understand art style, genre,
doing art specification, try to understand influences
between artists, try to understand creativity,
how to quantify creativity, how to generate art,
how to understand the evolution of art history.
Many things have been done during these years.
But let me start by the basics, basically.
So how artists talk about art.
So if you look at an artwork like this amazing Renoir
painting, basically artists doesn't look at this
and tell you there are multiple people
or people are eating food or things like that.
Basically talk about artists talk about elements of art,
the space, the texture, the form, the shape, the color,
things like that, principles of art, the movement, the unity,
the harmony, balance, contrast.
Other topics like subject matter, brushstrokes,
meaning, historical context, social context.
All these things are basically what artists talk about when
talk about art.
Their least concern is things like object or scene
classification and things like that or genre caption.
So our goal really was in the last few years
is trying to quantify each of these elements.
And we have done a lot of work on quantifying each of these
elements.
How to do visual encoding of the image
in order to be able to quantify these elements
and principles of art.
And in particular, one of the very, very important things
in art is the topic of style.
So what is style?
So basically here, this is a depiction of the last suburb.
So basically the famous painting by DaVinci.
But DaVinci's painting here is just one of them.
This is much earlier to a version,
a mini version by many artists, to 20th century versions.
And really in here, you can see what
is the meaning of style in one slide like that.
We're basically depicting the subject matter
in two different ways, depending on historical point
in what happened in art history that
specify how the artist will depict the scene.
And here's the fair thing.
I mean, if you look at this and what artists mean by style
and compare that to what we in computer vision or AI do
when you do things like style transfer and things like that,
to theorize, basically, it's a joke that the way we do
style transfer in machine learning and computer vision,
which is mainly basically meaning taking the ballot
from one image to another or a texture from one image
to another has nothing to do with the concept of style
in reality, because the concept of style
is much more deeper than just these simple things.
So the question really is what characterizes the sequence
and evolution of art style change over time?
How can we characterize these changes?
And actually what factors drive these changes
of style over time?
Why even artists change style over time?
When that happened, what triggers it
and how to characterize it when it happens?
Can we build conventional models
that can help answer these questions?
So we started very early with a very simple thing,
which is painting style classification.
You have a bunch of images and you have style labels on them.
So it's really a simple supervised machine learning
problem and you wanna classify the painting to think classes
like Renaissance, Baroque, Impressionism, Cubism,
abstract things like that.
So very simple problem.
And we take a painting, we have visual encoding
using different pictures, trying to capture
the low-level, mid-level, semantic-level picture,
which are parallel to different concept art, as I mentioned,
and trying different machine learning techniques on them
and doing supervised learning to classify style.
And basically this is so progress over the years
from the year 2012, maybe three years ago,
where we have been really trying any new things
that have happened in machine learning and see what it adds.
Things from the time of the bag of words and classmates
and HOGs, if you really remember that,
till the time of CNNs and deep learning.
The number of style classes that have been basically
increasing the number of classes over time,
trying to get deeper.
But basically how to monitor the progress
is how to convey to random guess
how much better you can do than the random guess,
starting from four times random guess
to 12 times random guess.
So, okay, and can do better than that.
All right, so we do classification.
The machine can classify style at the level
of maybe a first-year art history students.
If you give it an artwork, it can tell you this is Cubism,
this is Impressionism, this is Renaissance.
Good, the machine can do that.
So what, why that's even important?
So when I talk to Arthur Historian
about machine classifying style,
he asked me, so what, why that's even important?
And here's why I think it's important.
Classifying style by the machine
is not what Arthur Historian,
but actually instead what the important is,
what are that tell us about the characteristics of style
and what drives style changes?
And we know that if the machine can classify style successfully
that implies that the machine has learned
some internal representation that encodes some features,
some discriminative features
through its visual analysis of these art.
However, we also know that the machine uses visual feature
that's always very hard to interpret by humans.
So especially if you're doing learning,
so we have to interpret these visual features.
So it's very hard to understand
how the machine did the execution of style
to start with to get something useful.
So we went into studying basically
how the machine identify style
and if there are a relation between the way
the machine internally represents style
and the way Arthur Historian think about style.
And for that is very important to look at
what, how Arthur Historian look at style.
Here, this is Henrich Wolblin,
one of the founding father of art history, modern art history.
And he basically have a theory about style.
In particular, he looked at how style,
how to separate the study of subject matter
from the study of the visual form, which is style.
And in his book, basically he really studied
the difference between Renaissance and Baroque.
So in the top here is Renaissance artwork
and in the bottom is a Baroque artwork.
And he suggested basically some visual schema
that you can tell the difference
between Renaissance art and Baroque art.
Basically, he mentioned five bears of elements.
For example, linear versus binterly.
In Renaissance art, if you look at the contours,
they are very sharp and while in Baroque,
it's very fuzzy contours.
That was it linear versus binterly.
In Renaissance, if all the subjects are in one plane,
while in Baroque, there are depth in the scene.
So this is Blainer versus Recessional.
In Renaissance, everything seemed to be within canvas
while in Baroque, basically you see like a cropped image
from a bigger scene.
So this is called closed form versus open form.
In Baroque, in Renaissance,
basically every subject by himself or by herself.
So this multiplicity versus in Baroque, this unity here,
you can see the old subject are part of one unit.
In Renaissance, everything has absolute clarity.
All the scene, everything's in focus
while in Baroque, artists start to have relative clarity.
There are depth, there are things that are in focus,
things that are out of focus,
depending on what the artist is trying to do.
So he suggested that these five bears
is really what make the difference
between Renaissance and Baroque.
And he even went to say that basically these five bears
are the kind of feature that can classify any style.
So any style variation really goes along these elements.
However, this is very interesting.
However, this is a theory in art history,
which is what we call in math or science,
basically a congestion, not a theory,
because there is no proof of that.
How can we even prove these theories,
especially if you want to generalize it to old styles?
So what we did is really is we're trying to look
at this internal representation of how the machine
classifies style and draw the parallel
to what Wolverine suggested.
So what we did is basically we trained several models,
several CNN models, and we keep doing that.
So things like AlexNet, when they appeared,
VGGNet, ResNet, every CNN model that comes around,
we try that as well.
And the goal is basically to train the machine
to do a style classification in a supervised manner.
But the goal is really is not classification,
the goal is to look at what has been learned here.
So analyze the internal representation
and do some statistical analysis
and some visualization on top of that.
So after the machine learned style with acceptable accuracy,
we kind of start adding layers in the middle here
to increase the interpretability of the representation.
Basically go down to as small as number
of internal nodes as possible here
to have more interpretable representation,
doing things like principle component analysis
on the activation, source separation, ICA,
understand looking at the manifolds of activations,
doing correlation with time, correlation with Wolverine,
there's all these kinds of analysis we have done
to understand the representation
and basically some of the results that we found.
So this is the first thing that's very interesting.
We used either B-trained model on ImageNet
that we fine-tuned on Art Collection,
we use WikiArt Collection,
about 70,000 images in our studies.
And by doing that, we reach a accuracy of classification
is about 60% more or less by all these networks.
If you use a data from scratch,
you can actually get 10% less, 50%,
only in 77,000 images out,
they need to be trained on a million ImageNet.
All right, so that's interesting
so we can get reasonable results
even without any pre-training.
But the interesting thing is this,
looking at the filters that the machine learned
if you trained from scratch on style,
you look very different from the filter
that you typically see in object recognition CNNs.
You know in object recognition CNNs,
you always get these Gabor filters
and this edge-like, oriented edge-like filters.
If you look at how the machine look at style only,
look at style construction only, nothing like that.
We don't see almost any edges,
maybe only one filter looks like a horizontal horizon
or something like that.
But other than that,
it's very hard to interpret these filters,
but definitely they are not edge-like filters.
We should tell you if you wanna classify style,
there's nothing about object or composition that matters.
There's something else, but what is it?
We don't know.
So this is one thing to keep in mind.
The most important finding is that
looking at activation of the internal layers,
we find that a small number of factors
can explain most of the variants
in all art history that we studied.
We look at many at Western art history
or last 500 years, just to be clear.
We didn't include any Asian art
or African art or other cultures.
So between six and 10 factors
can explain 95% of the variants in the data.
And actually the first two modes of variations
explain about 75% of the variants,
depending on the network.
And this is common in all the networks we have tried,
whether it's Alexnest or complex networks like Resnet.
You can see that 75% of variants up to 75% of variants
can only explain in the first two modes of variations.
So what are these?
So here, for example, we visualize a small set
of maybe 1700 images.
Every image is a dot in this graph
and is the first two modes of variation
of the activation of the layers before the final layer.
And here we color code them
based on the time of the artwork.
And so what you see here is Renaissance art is here
and then Baroque art comes here
and then all the way 19th century
and all the way till the impressionism here.
And then you can see what's happening in 20th century
coming here, pubism and abstraction
and what art and things like that.
That's amazing.
Why that's amazing?
Basically the machine put art in an arrangement
in a chronological arrangement by itself.
Although we never tell the machine anything about
when the art was made.
The only information the machine sees
is the image and the style label.
You don't tell the machine that Renaissance happened
before Baroque or Baroque happened before impressionism
or anything like that.
But the machine to learn to classify style
by itself has to make the arrangements
that correct historical arrangement of artworks.
So we find that basically there is 0.7 correlation
coefficient with time if you go clockwise in this graph here.
And each of these axes
there is also a high correlation with time as well.
So that's very interesting.
So the machine basically, why that's important?
Because that actually was one of Wolblin theories
which he said basically that style change
in a smooth way over time
exactly like a rock rolling down a hill.
That's basically his metaphor.
And that's what we see here that the machine
find out that in order to understand this concept of style
it had to put the art in order historically
although we didn't get any historical context
but it really find that by itself.
So that's really confirmed that styles are not just bends
that are classification classes that are isolated.
It's smooth transition between them
is one of the very important things.
And this common and old representation
if you look at any of the network that we look at
whether it's be trained or trained from scratch
can find this high correlation with time in the representation.
And as I mentioned basically this is a confirmed
by Henry Wolblin congestion about that.
So the question now is what are these two factors
that explain 75% of what happened in art history?
So if you look at this and try to interpret it
it's very hard to really find one interpretation
people can have different interpretations.
But we look at basically how these axes
correlate with the five pairs that I mentioned by Wolblin
Binterley versus linear recession versus Blainer
things like that.
And we find that all the time the first mode of variation
the most important mode of variation
is being recessional versus Blainer.
And the second all the time the second most important
mode of variation is correlated the most ways
linear versus Binterley.
And then give us a very nice way to look at what happened
in art history over the last 500 years.
So basically what happened is here at Renaissance time
art was totally Blainer and basically linear
every all the contour was linear and sharp
and came Renaissance came Baroque
and things start to be recessional depth
and art becomes Binterley and the contour become fuzzy.
All the way till impressionism
where that's the ultimate Binterley experience
in impressionism all the strokes are just fuzzy
and we don't see any contours.
So this is the ultimate Binterley experience
but you can see that you still have depth artists
looking at scenes and things are still recessional.
And then came Cezanne and came 20th century art
where basically things become flat
artists start flattening the canvas again
and becoming to be Blainer again like Renaissance.
And basically most of 20th century is in the Blainer side
of things but coming to be linear again.
So if you look at Bob art like Warhol or abstract art
you can find that arts become linear again in the contours.
So basically art history went into a full 360 degree cycle
over the last 500 years in Western civilization
which really captured by this one diagram
that really came from the representation
the machine learned from looking at art style.
And again, some other interesting things
that we found in this representation
if you look at two of the modes of variation
I think these are the fifth and sixth
or maybe fourth and fifth modes of variation
and he's the one that correlates more
with the discrimination between Renaissance and Baroque.
So you can see Baroque in the top here
and Renaissance in the bottom here.
And you can see that basically these two factors
are created the most with the bears of Wolverine.
So basically Wolverine was correct in suggesting
that these bears are a good way
to discriminate between Renaissance and Baroque.
However, we also found that he's not correct
when he said that this can tell the difference
between all other styles.
All other styles basically are spanned by these five factors
because we find that we cannot tell the difference
between the inversionism and most inversionism
by looking at any of these factors.
There is none of them correlate with this discrimination.
Another very interesting thing that we find is
when we look at the activation manifolds
of these networks, in terms of representation
of these networks, we look at the activation manifolds.
And again here we're visualizing different artworks
based on the time of creation from 1400 to 2000.
You can see also the movement of art history
and how things have changed
and you can find interesting connections.
So you can see basically Renaissance here
moving into Baroque,
moving into a new classicism in 19th century,
moving into realism,
and then moving into inversionism here.
And from inversionism basically,
both the inversionism went in two direction,
one direction that go to exhibitionism
and one direction went to abstraction.
So you can see Cubism and abstraction here.
So that really tell us much about what happened in art history
and we find very interesting things when we look at this.
For example, if you look at this figure here,
look at this connection between inversionism
and what happened after.
And if you look carefully here,
we find that this connection is mainly Cézanne's work.
So all the circled artwork here are work by Cézanne.
So at the bottom here you can find the inversionism
and that's Cézanne and that connect to abstraction
and Cubism.
So that's interesting.
So you can see here Cubism and abstraction
in the early 20th century happening after Cézanne.
Here's another representation where really here are,
here is Cézanne work and this is inversionism
and basically this is Cubism, Picasso and Grace
and other Cubists.
And you can see how Cézanne's connection here,
by making the connection between inversionism
moving into 20th century and how special his artwork.
And you can see that in the data, you can even touch it.
You can see how Cézanne is a bridge here.
And the interesting thing is that obviously being
a naive person when it comes to art history,
I always go to Wikipedia when I learned about something.
When I go to Wikipedia, I'm learning more about Cézanne.
I found this in this encode.
Cézanne is said to have formed the bridge
between 19th century inversionism
and 20th century's artistic inquiries in Cubism
and both Matisse and Picasso are said to have remarked Cézanne
as their father, basically.
And that's very interesting
because this is not only a metaphor,
like a bridge here is not a metaphor like in art history,
but actually it's something that you can almost touch
in the data, in the visualization.
You can see how Cézanne is really connecting this.
Not only that, but I mean, another interesting thing here,
if you look at this manifold representation,
you can see many artworks here are renaissance artworks
that are built away from the Renaissance crowd
because the way manifold learning work,
manifold learning, you're building a graph,
connecting all nodes and you do embedding of that graph.
So you see here that these renaissance paintings
are embedded away from Renaissance.
When you look carefully about this,
you find that basically these are particular artists
that keep appearing again and again here.
In particular, we find El Greco and Durer,
the German artist.
So it's clearly that El Greco and Durer
has influenced modern art
and many modern artists have really influenced by them.
And that's very clear in the case of El Greco
because of the way he draw in a very deformed way,
which really affected exhibitionism and even cubism.
And that's very clear here,
why I see El Greco work built away from Renaissance
close to modernity, modern art.
In Durer, it's very hard to understand really
how Durer influenced modern art history,
but also Durer is very well known
that he's influenced art history in the 20th century,
but not clearly exactly how.
So that's very interesting.
All these tell us about how to characterize style changes,
but let's dig deeper into that.
And our work that I'm gonna talk about now,
back from 2014, six years ago,
was about confine creativity in art networks.
How can we quantify creativity in art?
And you will understand a little bit
how that relates to style changes,
how that characterize style changes as well.
So basically you wanted to develop algorithm
that assess creativity of a painting
given its context and art history.
That might seem to be silly question for some people,
but I think it's very important
because if you wanna build creative agents,
that's able, it has to have its ability
to assess creativity by itself.
Because at this point, at this point,
when a machine create art or music,
it's always the human that assess creativity of this machine.
You do human subject studies,
we give it to judges, things like that.
But can the machine on one day
be able to assess its own creativity?
And for that, we need to develop this algorithm
to quantify creativity.
But that did us the question,
what's creativity to start with?
How can we define creativity
in a way that's this quantifiable?
So there is a historically long and ongoing debate
on how to define creativity.
We can describe a person to be creative,
like Mozart is creative or Warhol is creative.
Or we can describe a product to be creative.
So we can say, for example,
the Mona Lisa was a creative artwork.
Or some people refer to characterize
the mental process to be creative.
So there are different ways to describe creativity.
We focus on novelty of a product in particular,
whether something is creative or not.
So how can we do that in an objective way?
So it seems to be the two main condition
for some product to be called creative.
This product has to be novel compared to prior work,
but also has to be of some value.
So we will take note of it and become influential.
Which exactly what happens in scientific community
when you write a paper, right?
I mean, you have to be novel
compared to prior research.
And it doesn't make a difference
if nobody cites your work.
So basically that tells us it's not influential
and not that creative.
This is a quote from a very good book,
which is a collection of essays about creativity,
which basically concluded that
although there are different ways to define creativity,
these are the most common essence of what creativity is.
And that actually relates back to Kant philosophy.
If you go to Kant philosophy,
he defined five elements of what he called artistic genius.
And the very first two of them is originality.
The originality must be its primary characteristic
and influence.
Its product must at the same time be modeled or exemplary.
So other artists would start to get influenced by that.
So these are the two fundamental reasons
behind what he called artistic genius or creativity.
Let's move forward to the 20th century.
One person in the audience asked a question
referring to Margaret Bowden.
So Margaret Bowden suggested basically
two distinct notion of creativity,
the psychological creativity or be creativity,
which assists the novelty of idea
with respect to its creator.
Versus historical creativity,
which is assessing the novelty
with respect to the whole human history
is what I'm creating valuable and novel
compared to all what happened in history.
So this is the objective measure.
The psychological creativity is more of a subjective measure.
But historical creativity is a objective measure.
So basically that's what we're trying to do.
We're trying to align ourselves
with historical creativity of product
and try to define an algorithm to do that.
So we propose an algorithm to assess creativity
that's basically unsupervised,
meaning that we don't have any creativity labels.
We just have a bunch of artworks.
And the only information we're gonna have
is the date that artwork was done.
So these are two information,
the image and the date, nothing else.
And we're trying to infer from that
something about creativity.
Some fundamental issues we have to think about
before even we start deriving any algorithm about creativity
because these are common problems.
These are common problems that will face
any algorithm that will look at creativity.
So we have an algorithm that assess creativity.
That algorithm looking at an artwork
and try to judge whether it's creative or not.
Obviously that cannot be done in a vacuum.
The algorithm has to look at the context
of that art history to judge, right?
So this one limitation that the algorithm
only see a part of art history,
that whatever digitized, whatever reached us
and digitized and available as a dataset, right?
So that's one problem.
So these are closed,
what I call the closed world limitation.
And then the algorithm look at the art
through some visual encoding, which also add limitation.
So there are some concepts and elements
that are being quantified here through these visual features.
And there are others that might not.
So that's basically another limitation,
which I call the artistic concept quantification limitation.
And then any algorithm has parameters
and this parameter will influence the output.
So we can get different results
by changing the parameters.
So how can we make use of that?
So, however, these are all limitation should not stop us
because first the closed world limitation
will always go away.
We have more and more art being digitized
and more data we can get.
So this will go away.
We have advances every day in visual encoding
and become less blind and have better encoding.
And the parameters actually are not a limitation
because the parameter actually,
we can really give creativity scores
and understand exactly how the parameters affect the scores
in a way to understand what we are measuring.
Are we measuring creativity based on certain settings
related to composition or are you measuring
visibility to brush stroke work or color?
So all that allow us to reach way to understand K-division.
So the bottom line is we wanna derive an algorithm
that look at art pieces, images and their timestamp
and give us a score.
So that's basically the input and output.
And what we do is that we start creating a directed graph
between all paintings in our collection,
where there is an edge between each two paintings
with a weight reflecting the visual similarity
according to the visual encoding that we are using,
how similar these two paintings are.
And it's directed based on the time basically
if BI comes before BJ, so it's directed in that way.
And now let's think about assemble inference we can do.
Suppose you look at these two arts,
Caravaggio from 1602 and a less known artist from 1800,
almost 200 years later.
If you look at these two artworks side by side,
you can realize basically that this second artwork
is very close to that in terms of body bowls,
in terms of light, in terms of composition,
subject matter, everything's basically, right?
So it's clear that that work is a derivative of Caravaggio.
So in one sense that artwork is not as novel
compared to Caravaggio.
And in another sense, Caravaggio has an influence
in that way to that artist.
So high similarity between two artworks in the network
imply that creativity of the earlier work has to go up
and creativity of the later artwork has to go down.
These go down because it's derivative
and these go up because it's influential,
at least on these two bears.
Compared to another case like that,
these are precisely from 1883
and this Picasso from maybe 20 years later from 1907,
they are very different,
had nothing to do with each other,
different ways of using color, composition,
totally different, right?
So very little similarity between them,
of course, depending on the future you are looking for,
but still very low similarity.
And that imply that Cicely was not influential
on Picasso, at least in a direct way.
And Picasso was basically novel in making that art
compared to this work.
So that low similarity implies lower creativity
for that artwork by Cicely
and higher creativity for that work by Picasso.
So if you take these two elements of influence
and start building a formulation for creativity,
what you can do, we can write down a formulation like that,
where the creativity of any node can be described
as the creativity of all nodes connected to it.
In this formula here, alpha is a factor
that indicate the probability that the similarity
between painting can be just a coincidence.
And the way to interpret this formula is like that.
Any node in the graph collect influence
from all its outgoing connection
in this submission here.
And for any node in the graph,
it distributes its creativity tokens
among all incoming connections.
So you reach this formula that you can write
where this formula actually, if you look at it,
it's basically an instance
of what's called network centrality problems.
So you can see how many other algorithms
are special cases for this,
or at least a special case for others.
So you can think of this as a random work
in a Markov chain.
If you set alpha to be one, this term will vanish
and you have this term only,
which is called basically eigenvector centrality.
You can think of it as a weighted variant
of Hubel centrality.
If you're familiar with this body of work,
basically network centrality.
But basically, network centrality is very fundamental
in studying social networks in the days,
in studying pandemics, propagation, things like that.
Even in the Bej rank algorithm,
by Google is basically a network centrality problem.
And you can think of this formulation
as basically inverted weighted variants of Bej rank.
So we can even extend this in a way
to separate originality from influence.
So we can see that basically originality
can be controlled by another parameter,
is we can measure originality
or can measure influence in particular.
So the question is, how can you even evaluate that?
If everything is so unsupervised here,
you don't have any creativity labels,
you can show results to 10 art history
and everybody will have different opinions.
So how can we even evaluate this algorithm?
So we worked on different datasets,
the wiki art datasets
and something called archive datasets much older.
And at that time, we did this work on 7.14.
And at that time, this is the art in the vision
was mainly things like jest and bag of words
and things like that.
And that was really excellent
because we really wanted to use features
that are not trained on art at all.
So these are of the shelf features.
Class me, it was a feature
that basically encode object representation in images.
So it's a very good way to encode subject matter
in particular, just come from MIT,
basically comes from MIT,
which encode texture and other things
to object and scene classification.
So we thought that these two features are very useful.
They are not trained on art,
they are generic,
the capture things that we can relate to in art
with a subject matter or brushstrokes or scene composition.
So let's use them
and try to make sense of those based on that.
So here's one chart that show basically time
of x axis from 1400 till 2000.
And every artwork here is blotted with its creativity score.
So the higher the score,
the y axis is the creativity score.
And you have to remember that the formulation
is a zero one game,
meaning that if some artwork,
if you give it a set of artworks,
the sum has to be a constant.
So for some artwork to score high,
another has to score low.
Everything that we give to the algorithm
are master pieces of artwork anyway.
So nothing here is really scrambled
by somebody in the street.
All these are master pieces.
But the way to look and interpret this,
we essentially are using in particular class me
and just we are really trying to look at creativity
with this subject matter,
how creative were artists in depicting
the subject matter over time.
So we can see, for example,
what scores low in 19th centuries
is art by the amazing artist,
Prince of Hungary.
Why this score low?
Because basically according to subject matter,
there's nothing really innovative
about having a portrait of a woman in 19th century
because this has been done a lot in Renaissance
and broke all the time.
So subject matter was not re novel.
While in the same time what scored very high
was things like a monk,
the scream or money,
haystack, very early version of that and others.
So when we look carefully on the 100 years
from 1850 to 1950,
when we have a lot of data digitized
and a lot of artwork,
we can find that the machine makes sense
a lot about what happened in art history in that time.
So you can see the machine identifying things like
mink, the scream, giving very high score,
climp booster,
things like cubism and things like that.
So that makes sense.
I hear deeper into that.
If you look at the first 10 years of 20th century,
the first 10 years of 20th century,
the highest scoring artwork, for example,
is Picasso, Ladies of Abinon.
I didn't know much about that artwork other than I like it,
but I didn't know much about its history at the time.
But when I look at its history,
I find that art history now agrees
that basically artwork was the beginning of cubism.
Very early, even before cubism become a thing.
And what you see in this graph here,
the machine give this a very high score
and what's stopping that in 1912 is actually cubism itself.
So these are artworks when basically
in the very early cubism exhibitions
by Picasso and Brock.
And you can see here that before that,
that was the high scoring one.
And this is stopping that.
What's stopping that even more in 1915,
artwork by Malevich,
what's called supremist art movement,
which is totally abstraction in 1915.
That's stopping even cubism.
Okay, anyway, all that's nice,
but how can we even say that it works or not?
It's all in total evidence, right?
I mean, here is what's something very interesting.
What was that artwork
that giving very high score in that short here?
And when you look at curfew at that artwork in particular,
you find it's an artwork by Mondrian
that was dated in our dataset to be in 1910.
And that was very interesting.
Obviously, when you find something that you have to look at
and see why this is scoring very high.
And I find something very interesting
that basically Mondrian didn't bend this in 1910.
Mondrian bent this in 1932, I guess, I don't remember.
So that was a mistake in the dataset.
So the dataset itself has something wrong
that would say basically Mondrian went into that in 1910.
And if Mondrian would have painted that in 1910,
that would have been even before cubism,
before abstraction
and would have been the most creative artist in his time.
But obviously that's not.
But that mistake actually give us a very interesting idea
about how to even evaluate this.
So there are many results here, I'm gonna skip that.
And the way we evaluate this is what's called art time machine.
So the idea is this very, very simple idea
that come from this mistaken, the dating of that artwork.
So what happened if you take an artwork from Barak
or Renaissance and move it forward in time
and change its date to, let's say, 19th century
or 20th century, what do you expect?
Give the algorithm work that the creativity of score
for that artwork has to go down
because if you create an Renaissance artwork
in 19th century, you are not creative.
In the same time, you take an artwork from 19th century
or 20th century and move it back to 1400 or 1500,
you expect its creative score to be going very up
because it would have been very different
from what happened in the time
and very early influence to what happened much later.
So we expect its creativity score to go up.
And that's what we did.
So what we did is basically many experiments
where we take only 10 artworks, change their timestamp
randomly, either moving them backward to 1600
from modern schools or moving forward to 1900
for Renaissance and Barak.
Or basically as a baseline, just to move them
around 1600 randomly.
We basically find that that's interesting,
but if you move forward, Renaissance and Barak artwork
to 19th century, you can see consistent drop
of creativity by eight to 10%.
So it's consistent when we did these experiments.
If you move modern artwork from 19th and 20th century
back to 1600, you can see that the creativity score increase.
However, with varying degrees depending on the art movement
and that makes a lot of sense.
For example, if you're looking at exhibitionism
or cubism or post-embranches,
we can find a huge increase in creativity
if you move them back to 1600, compared to a new class system.
A new class system basically is a reinvention
of Renaissance in 19th century.
So if you move it back to 1600, you have only a 5% increase
compared to 16% increase for post-embranches.
So that's right.
How we tell us basically the algorithm
is really doing something making sense
in terms of quantifying creativity
and giving us a score that really captured
the novelty and influence that we're looking for.
When I showed these results to my art historian collaborator,
Maria Mazzoni at the College of Charleston,
she was interested in the result
and gave me this book, basically,
Shev's Art History, which I quoted from in the beginning
by George Kubler, who's an art historian.
And in this book, basically, Kubler had a theory
about how art history evolved.
So basically saying that artists copy ideas
from each other all the time.
That's what happened all the time, within a style.
Until, basically, some artists come
and makes some artwork that is really different for some reason.
And that's what he called primary objects,
really give birth to a new style.
And if other artists start to take a note of that
and start replicating this new style,
that becomes a new style.
So, basically, he focused on this concept of prime objects,
which are iconic artwork, and replica mass,
as opposed to that really drive style moving forward,
within a style.
And I even find very interesting quotes in his book
that say, basically, primary objects here.
Prime objects resemble prime numbers of mathematics,
because no conclusive rules is known
to govern the appearance of either,
although such a rule may be found.
So, basically, this is a very amazing analogy.
You make the analogy between these prime objects
in art history and prime numbers.
The prime numbers cannot be divided by a number before them,
but they divide many numbers that comes after them.
And that analogy really gives me thinking about
the algorithm that describes the graph inference algorithm.
If we can start with this graph,
and the nodes are numbers,
and the arrows are divisibility,
the algorithm, basically, will give you a high score
to prime numbers by definition.
By construction, you find that that algorithm
will give high score to prime numbers.
So, really, he's very, very correct in this analogy
that prime object is actually very similar
to the concept of prime numbers.
And what you're actually doing in this network
by giving creative score,
we are identifying what are the prime objects
in art history, things like Montesquim,
or Picasso, ladies have been on.
So, when art historians tell us that this artwork is major,
or basically the population think of Montesquim,
or Monet, his tag as really a masterpiece,
this is totally not subjective.
There is some unconscious reasons for that.
And this can be quantified by this kind of networks.
And they are really a changing moment in history
where something totally different happened
and artists start taking notice.
So, because of the time,
I just wanna go very fast toward the next topic,
which I'll try to finish in two minutes,
which is basically how can we actually use AI
to generate art?
And if the machine generate images,
would that be considered art or not?
These are very big topic.
And I know that other speakers in this series
will talk about that in detail.
Aaron is gonna be speaking,
or maybe has been already in this series.
But basically our work from three years ago,
called Creative Adversarial Network,
can, which basically we try to make a variant of GAN
that was new at that time to really generate a novel art.
We call it generating art by deviating from style known,
by learning about style and being from style known.
These are some of the art that this network is generating.
So, basically wanna, here's the story.
Obviously, the audience here know deep learning
and know GANs and know how they work.
I don't have to go through that.
And for example, GANs have been very successful
in generating these images of bedrooms
and other assets, very interesting things like that.
So, one question would be,
what happened if you train GANs on art images?
Suppose you give it art history images
and you train GANs on that, would it generate art?
And actually there was some trials in the early days of GANs
where people trained it on board trays
and still lifes and things like that.
However, this fundamental problem,
the generator in GAN is trained to generate samples
that pulls the discriminator to believe
they're coming from the same distribution as the inputs.
So, that's basically,
we can think about Chinese room problem here.
Imagine the generator have access to actual images
and can sheet.
So, you can take actual images of art
and just generate it right away
and give it to the discriminator.
So, actually, the discriminator this way
can be pulled right away
that thinking and generating these art works.
However, this is basically the Chinese room problem.
So, there is no motivation for the generator
actually to generate anything that's creative.
The generator is just trying to generate something
from the same distribution.
The only creativity it can do
is just to generate something
that was not generated before from the distribution.
But it's basically, if you give it artworks of board trays,
it will generate some different board tray,
but still a board tray that's very similar to what it sees.
There's no force, the bush, again, to be creative.
How can you change that?
There's some background here
that I have to go very fast over
from coming from the field of aesthetic evolution
and psychology.
Basically, these three in one slide
say that artists keep making the same kind of art all the time.
Like, if artists in Renaissance
keep doing the same kind of Renaissance all the time,
because of habituation,
we get bored of that as the viewer get bored of that.
And that become not exciting for the artist,
not exciting for the critic,
not exciting for the viewer anymore.
So, artist has to innovate all the time
to go to bush against habituation.
However, if artists innovate too much,
if artists imagine because I did that in Renaissance time,
or even when he did that in 20th century,
that's too shocking.
That people will not like that.
And people actually didn't like that.
Most people till now didn't like that.
Because basically according to what's called
one curve in psychology,
too much arousal relates to negative hedonics.
Basically, people start to unlike what they see.
So, in one sense, artists have to bush against habituation
in what's called basically least efforts.
So, artists really have to really bush the envelope
with the least minimum amount
to bush against habituation
without falling into the negative part of that curve.
So, that basically the concept that we're trying to bush,
how can we bush the network to be innovative,
but keep it within the distribution,
bush the boundary basically.
So, the way we did it is basically,
in particular, we're trying to go out of style
by appealing style ambiguity.
So, the network here is again,
we still have the real false, real fake loss,
which is in that case, art or not art
because you're training on art.
Then the network has a style classification.
The discriminator also learn about style
and try to classify styles.
We give it style labels.
And we added style ambiguity loss,
which basically mean that the discriminator
trying to see if the art as a generator fits within styles
or ambiguous in terms of satisfying style.
And we're trying to basically maximize style ambiguity
at the same time minimizing the typical loss
in real fake formulation.
So, basically, this is the loss
and we have art or not art.
We have style classification loss
and we have this style ambiguity,
which I think is very essential
because this style ambiguity bushes against art, not art.
Art, not art loss, typical gun loss,
will try to boost things into the distribution.
And style ambiguity will try to boost things
away from distribution,
but keeping that will put it back.
So, the dilemma between this almost objective
really boost the machine to try to explore the boundary.
And that's why we started getting
this very interesting artwork
that have very nice composition.
Here we train the machine on art history
from the last 500 years of art history,
all subject matter, all style, we didn't do any curation.
The goal is if the machine see all that art,
what will it generate?
Will it generate similar artworks or something novel?
And the interesting thing,
most of the things I'm machine generate
actually abstract artwork.
It didn't give us much board trace
or landscape mainly abstract.
And that was very interesting question.
If we remove the style ambiguity loss,
these what kind of things you can get,
which are basically things that looks like
mainly repetition of art history.
The machine here again is just basically trying to
generate things that looks like the distribution.
Adding style ambiguity to the different results.
Trying to, you can see it keep the aesthetic,
it learned the aesthetics trying to keep it to be
in the distribution of what's appealing,
but trying to come up with new compositions
and new combination of colors, new interesting things.
And we did a lot of experiments.
There's much time to go over them in details,
but here is the conclusion.
When we show these two human subjects
combined with artwork from Art Basel 2016,
which is a flagship art fair in contemporary artists
and also combined with another set of abstract exhibitions,
famous artworks as a baseline.
And to our surprise,
basically human subject thought art done by Cannes,
the machine basically has done by human 75% of the time
compared to 85% of the time for the case of abstract.
And only 48% of the time for art from the Art Basel.
Collection.
This doesn't take anything about creativity of the art.
It's basically a touring test to tell whether a human
can tell what art is made by a human or by a Gann.
And at that time, basically most art that is done by Gann
has this uncanny look that right away you can tell it's a Gann.
It's the format for trace,
the format so you can tell it's a machine,
but for Cannes work, you cannot tell the difference.
It's given these high scores.
And moreover, they give it described by words like intentional,
has a composition, rules, has communication inspirational.
Give it high score in all these as with the same as art made
by human.
One last thing is why it works?
Why style ambiguity work?
And that connects to what I talked about earlier.
It is not biased with the data,
because maybe you have less abstract art work in your collection
and that's why it's generating abstracts.
And it is not because all the schools here
we combine them into bins to make them uniform.
So according to our laws, if these are the solution
and these are the styles,
those are a plenty of room in between to create something
that belongs to art and doesn't belong to styles.
The machine tried to find out these spaces.
However, if you look at this figure from before,
that's renaissance, Baroque,
impressionism, realism and things like that.
You can see that there's no relation art history.
Everything has been moving smoothly.
And if you want to move forward,
obviously this two-dimension block here,
but the space is much bigger.
If we really move forward,
you cannot really get something just between renaissance
and Baroque.
You have really a budget trajectory forward,
not insert something in between.
And that's exactly why it works.
So, and that's why it tends to generate more abstract
than more uncanny repetition of the best
because it's figured out basically in the 19th century,
things are moving in that direction
and there are more space to make creating abstract art works
and studio art works without having to go
and creating board trays and battle field
and landscapes that the students can tell right away.
It's renaissance and Baroque.
So that's at least my understanding of this board.
Anyway, I'll have to stop here
because I went over time and I'm very sorry about that.
The conclusion is we just sketched the surface.
These are not to be discovered in art history
by looking at art at a macro level using the science and AI.
And also they are to be discovered
by trying to boost the AI to be created.
Thank you very much.
Thank you very much, Professor Elgamal.
It was very interesting discussion and analysis
over history of art.
I really appreciate that.
I think that if anyone has any question,
otherwise excellent.
I think it was very interesting.
It was very interesting.
I liked hearing about all of the art history
and then relating it to the computer science aspects.
Thank you.
I hope it wasn't boring from the perspective.
It was very interesting, especially trying
to quantify creativity was interesting
and kind of related to the previous talk as well.
I also find it very important that there is a separation
between science and humanities.
What we are doing in computer vision
and if you talk about being creative
and doing machine creativity
and you are disconnected from what's happening
in art history or rural art history,
we are making a big mistake.
As I said, I mean, for example,
the concept of style transfer in vision
and machine learning, totally nonsense.
When it comes to artists and it comes to art history
and we still keep doing that.
We find like hundreds and hundreds of people
come every year about style transfer.
We should keep doing the same thing.
It was totally nonsense to me
because that's not style
and that's not what interests artists
and what interests art history.
So this connect is really not good.
Thank you so much for sharing your interest with us.
I think that this is very intriguing for anyone
in the class who wants to believe myself,
who wants to explore more in this direction.
So I appreciate your time and talk.
Thank you so much.
Okay, I think that we can stop you eating your nap.
Thank you.
Okay, have a good time.
You too.
Thank you very much.
