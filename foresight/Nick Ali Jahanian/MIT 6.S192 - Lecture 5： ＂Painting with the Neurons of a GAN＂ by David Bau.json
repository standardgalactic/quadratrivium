{"text": " Hello, everyone, welcome back to our course, a deep learning for art, acetic and creativity. Today, it is our pleasure to have very a specialist speaker, David Bao, and I just let him to introduce him a little more, because I think it's very inspiring for many students, the path that he has come to this point and for future. Please go ahead. So I was, I want to give a little background since I am a post industry academic, I spent a bunch of years as a software engineer at Google before coming back to MIT. And I want to give a little bit of insight in my thinking there. So, you know, the reason it's really interesting to be in computer science right now is because the field is changing. The dream of having self programmed computers is one of the oldest dreams in computer science, but it's never been a reality. Even though we've studied machine learning for a long time, I think that until just a few years ago, machine learning was really more accurately called, it would have been more accurately called the art of accurate counting. You know, statistics, you know, understanding the statistics of, you know, how frequent words are and by grams or, you know, certain image statistics or something like that. And, and, and if you if you understand statistics well, then, then, then, then, you know, you could do some nice tricks. But I think that until recently really calling these things sort of self programmed systems would have been an overstatement. But I don't think it's really an overstatement anymore. I think that these machine learning models are really learning non trivial things. And it leads to all sorts of questions about, you know, what should we be doing as programmers? What does it mean to do software engineering? And so I thought it was very interesting time to come back to academia. That's, that's why I'm here. And I actually think that that's one of the choices you face when you're trying to decide between industry and academia. And I think in industry, you will have lots of resources to make things work to make the next widget or the application. And, you know, there are great places, Google is a great place, we can really push state of the art in that and do really neat stuff. I think that there's less of a push in industry to ask the question, Why? You know, why do things work? Why are we doing what we're doing? Where is it going to lead in either unintended consequences and things like that? You know, we, we tend not to ask those questions too much industry, because there's so much to emphasize on, you know, the how of how to how to get it to work. And so, and so, so I thought it was a time to, to switch tracks and start asking why because the field is changing so dramatically. And I think that, you know, I'd encourage people who have an interest in these type of questions to, to realize you can really make a real contribution by taking the academic track as well. So okay, so let me introduce my talk. So it's about painting with neurons of general adversarial networks. It comes out of work from asking why, you know, why do these networks do what they do? And so, so let me, let me advance here. Am I in full screen? So do you see the, do you see the like the full screen slideshow I can't see what I'm projecting? Or do you see like all my notes and all that stuff? Yeah, I can see it. But also maybe a student can tell us. Yeah, okay. That's fine. Is everything okay? Yeah, it's a full screen slide. Hopefully, it's okay. So, so, okay. So the main problem that we're looking at here, and I'm not sure why the, the images are overlapped in the right way. Hopefully, the layout will get fixed. So we're going to next slides. But the, the, the, the, the main problem surrounding my talk is image generation. And so, for the last few years, there's been this question, how do you make a state of the art program to generate realistic images? And, you know, the general process is first you want to collect a data set of real images, like these pictures of buildings on the right. And, and then you want to, you know, train some sort of program, some sort of generator network to generate those programs. And so, so, you know, it's been a puzzle. There's a lot of different ways you could imagine doing this. And so people have been puzzling, how do you train such a thing? How do you even supervise it? You know, what should the, what should the inputs and the outputs of the network be? And, and, and the thing that has really been working the best in recent years is, you know, in architecture, you guys have all heard of called GANs, generative adversarial networks. And the trick for GANs is to reduce it down to a simpler problem that we know what we're doing. And so the simpler problem that they're recognized when designing GANs was that generating images, we don't really know how to do, but classifying images, gosh, that is an easy problem. We can classify images. And so, so what we could do is we could train a classifier on this really easy task, which is given two sets of pixels, which image is real, and which image is not a real photograph. And it turns out that for most arrangements of pixels, this is a very easy task to train a discriminator on it gets very good, you know, very quickly, we'll start getting 100% accurately on that. And so, so but the neat thing is that once we have a discriminator that can tell the difference between a fake image and a real image, then we can hook it up to our generator, and we can say, All right, we didn't know how to tell you, generator, how to make a real image. But you know what this discriminator can tell you, because all you have to do is generate patterns of pixels that fool the discriminator, if you can make the discriminator think it's real, then it must be better than random. Now, the problem is that, even though the discriminator can get very accurate at telling what's real, they, the generator will also be very good at learning how to fool the discriminator without working very hard, it'll realize that aha, the only thing I need to do to make the discriminator think is real is put some blue sky in there and put some texture that kind of looks like, you know, building texture. And, and the discriminator will say, Well, that totally looks real, there's a sky, you know, there's, there's the right, the right colors for buildings and some vertical lines and things. Ah, that's totally real. But as a human, we look at that, we think, Oh, that's not a very realistic image at all. So the trick is to iterate this process to go back and forth after the generator can generate sort of halfway looking real images, then have the discriminator say, Ah, well, that's actually fake. And we're going to tell the difference between those new fakes, those better fakes, and actual real photographs, and the discriminator has to now work harder at getting better. And so if you, if you alternate these processes, then, then you end up very conversion to very, very good generators that can generate very realistic images. And they, you know, the typical learning process is actually just to do only one step of iteration between the discriminator and generator and just alternate that. So by the time you're done, you've played this game, you know, millions and millions of times back and forth between the generator and the discriminator. But the new thing that's happening here is that it can generate these images that look very realistic in the end. But let's see. So Oh, here's another picture. So we'll get this images out that look very realistic in the end. And we'll get this generator, which is just a deterministic function that takes actually the input of the generator is actually just a random vector. So we'll take these relatively small random vectors like 512 dimensional random vector, and we'll put it into this thing. And it's been trained so that no matter what it outputs, it will look very realistic, like this example image here. Or if I change a vector, I'll get a different image out and it will again look very realistic, even if it looks completely different. And so it's just a deterministic function that really wants to make realistic images. And, and so here's like a sample of like output from a generator. And you can see that after millions of these sort of generative training steps, where it's pitted against a discriminator, it actually gets to be pretty good. And so this is a style game v2. It's a model that was published last year. And, and it's, you know, currently the state of the art in generating realistic images of certain certain types of image distributions. And, and so when when you look at a collection of images like this, you might think, actually, the first time I looked at the output of some of these state of the organs, I was confused between the training set, and the generated output, this is not the training set, this is actually what the generator is producing. And so, so you see all sorts of interesting effects here. And so the one of the questions to ask is, what the heck is the model doing inside? Can we understand the underlying algorithm? And what the characteristics of that algorithm is like, why does this work? And so one of the funny things that you'll notice is that some of the images have these strange artifacts, like take a look at this one here. So this, this scan is pretty good. It's this generator is so good that it actually has noticed that the training distribution that is imitating has some percentage of images that were stolen off of shutter stock. And they still have the watermark on them. And, and, and, and the generator says, well, if I want to make things look realistic, I better put watermarks on some percentage of my images too. It learns it's got to protect its own copyright. So, so it, it does that. And so something like 6% of the output images from state of the art style, again, will have these kind of artifacts that show the same type of watermarks that were on the training set. This is the Elson Church training set. And so, so yeah, this kind of watermarks like this. But the reason I thought this was cool was that it, it's this very clear thing that the image generator does, but it doesn't always do it. Like most of the time when it generates images, it generates images without a watermark, but sometimes you get these watermarks. And so, and so it's, it's almost like this binary decision. It's like, there must be a switch that the network has at some point where it decides whether it's going to put a watermark on an image or not. And so we can kind of ask the question, where's that switch? Is there a neuron somewhere in this network, which is, which is controlling the watermarkness. And so, so I went on a hunt for this, this, this particular network has about 30 million parameters, which sounds like a lot, but it's just a deterministic computer program in the end. And, and it's not that hard to go hunting for things like this, you just, you can make an algorithm that has a heuristic that determines whether it's a watermark or not and just go hunting for, for things that correlate with that. And so I'll show you what I found. So at layer five, I found this very interesting neuron that did correlate with watermarks a lot. It was activating whenever images look like this in the end. And, and not only that, but because it's at layer five, it has a has a location for where the image activates. And I'll show you where, where it's activating. So, so this neuron is activating, you know, at these middle parts of images, whenever the image is showing a watermark. And there are other neurons that have similar behavior, like so for example, there's this neuron 234 at the same layer. And it activates in regions like this, both in the middle watermark and the bottom bar that shows up. And there's about, if you hunt through the neural network, you find about 30 neurons that are similar and behave like this. And so that's, that's pretty cool. So then the question is, well, do these things really act like a switch? What if we've removed these neurons from the network? What if we force them all off? What if we turn, what if we force these neurons to be off all the time? That will happen. So normally, we think of these neural networks as completely opaque systems. We train them end to end, they're just, you know, these big black box functions. And we normally think of the functions as computing things where everything depends on everything. And so if you randomly rip through the function and remove some of its operations, then maybe you expect to get total nonsense out just garbage or noise. But we found these particular neurons that really correlate to this thing. So let's see what happens when we turn them off. Do we get anything intelligible at all? So this is what the network generated before these are the watermark images I showed you before. And I'll show you what happens if I turn off these 30 watermark neurons. So I'm going to give the network the same input. But turn off these neurons during its computation, and you can see what the output looks like. So you can see before chain, you know, forcing these neurons off and after forcing those neurons off. The images are still very intelligible, they look realistic still. But now the watermarks are gone. So I thought I was when I when I saw this, I was pretty excited, because it's like, Oh, there are switches inside the networks. And these networks are doing all sorts of amazing things, not just like showing watermarks. You know, so when I first found this, it was on Progressive GAN, which is a year earlier than a couple years earlier, the images didn't look quite as good. But but still in Progressive GAN, they do all sorts of amazing things, like they will arrange a scene with a river and trees and grass and, you know, building architectures with all sorts of different features. And you can ask, you know, is there a switch to turn on and off clouds in the skies or switch to turn on and off trees or windows and buildings? And, and so I went hunting for that. And, and, and the way I went hunting is I tested every neuron one at a time I inverted the test. So basically, I look at each neuron, and I say, Where is it activating? And, and I asked a question, is it activating an interesting part of different images? So for example, if I took this one neuron here, and I see where it's activating when it's generating this image, you can see it's very hot on the right and on the left, but not much up in the sky. And on this very same neuron, when we generate a different image with a different input, this very same neuron is not activating very much anywhere in this this image. But if we generate another image, then it will activate in a specific area here, mostly on the lower left part of this image. And you can see what's on the lower left. There's a, there's a tree there. And so it kind of gives you the hypothesis that maybe this neuron is correlated with trees somehow. So obviously, we can, we can do this, we can collect this information over thousands of examples of generated images by looking at where the neuron is activating, we can ask what what kind of thing is in the image, what kind of objects, what are the semantics of the image in the location that the the neurons are in. And we can just repeat that test process, you know, thousands of times to see if the neuron is agreeing with any particular kind of semantics that are in the images. So if, if the, if the neurons are showing up where the trees are all the time, we can just count and see if if that's if that's true in general. And we can also look for correlations with other things. So what I did is I, I searched for correlations with thousands of different, you know, hundreds of different, different types of semantics and object classes, different parts of buildings or, or objects or other things that can show up in a scene. And so what do we find? Well, we do find, you know, there's a neuron that correlates with trees, just like the one I was showing you. There's actually a few that are like that. And there's also neurons that correlate with other things like domes, or, or other building parts like windows and doors. And, and if you change the model to look at other things, then you can find neurons that correlate with things like windows, or chairs, or other things that they show up in, in the scene. And so this is actually pretty neat, because this model was trained unsupervised by any labels. All we did is we told it, generate realistic looking scenes, realistic looking photos. And, and, and we did not train it with any labels, we didn't tell it that these are photos of scenes that have big windows, and these are photos of scenes that have little windows or anything like that. Or, or, or here's where the windows are. But what happened was, the network discovered that it had to, you know, learn a representation, where windows are represented differently from the way chairs are represented. But somehow, even though, you know, windows can look very different from each other and chairs can look very different from each other, that the network has this represent this this component of this representation, this neuron that activates on all these chairs, despite the amazing amount of diversity that it shows, like none of these chairs really look similar to each other, they have different colors and different textures, and they're oriented in different ways. And yet, the same neuron is activating on all of them, the same thing goes for other things that show up in these images. So does anybody have any questions about, about, about this? I'd love this to be a little bit more interactive than the way I'm doing the talk. So let me open the floor for a question for a minute. Has anybody tried playing with the internals of GANs yet? I'd love to see if has anybody like generated images using a GAN before? No, but I do have a question. Yes. So what was like the end goal or the larger reason behind finding all of these neurons that correspond to different objects or features? Well, when I was originally looking at it, my original goal was just to understand how these models did their computation. So asking the question why. But the neat thing is that after I found this structure, then it became clear that there are new applications that you can build on top of it. And I think that's one of the cool things that comes out of this sort of academic style inquiry is, you know, originally, I was just looking to make catalogs like this. This is a catalog of all the different types of correlations that I found with neurons inside a model for generating kitchens, and the kinds of, you know, the patterns you see. And, and, you know, I've done this before for classifiers. And, you know, when you do for generators, you get different patterns. And so I was just really interested in making these maps of seeing what is computed at what layer, you know, where and how accurately. So this is, you know, the progressive gain has, depending on the resolution has about 15 layers. And if you sort of chart what you see in different layers, you can see this this really interesting thing phenomenon where it's in the middle layers that you get these highly semantic correlated neurons. But then as you get to the later layers, then they tend to be more physical. And there's not as many semantic objects. So it's like in layer five, we have things that really correlate with ovens and chairs and windows and doors, even though like a window kind of looks like an oven. The model clearly has different neurons that correlate with windows from ones that look like ovens. And so so that so that's that's that so I was originally interested in just mapping things out. But the correlations were so striking that it leads to these interesting applications that you can build. And I can I'll show you some in the next step. Let me before I do that, let me see if anybody else has a question as well. Yeah, David, I was hoping that you could also show us the application at some point, which I think these are very good to see why you asked this question. I mean, yes, it's more That's great. Let me let me zoom out to the application. So so the the neat thing is that just like we could turn off watermarks, we can turn on and off things in image generation. So for example, if I find all the neurons that correlate with trees, and I turn them off, you can see what happens. I'm going to turn them off sort of one at a time here. And so originally, the image will just be generated this. But if I turn off some tree neurons, you can see that we can actually remove the trees from the scene. And the cool thing is that this is different from Photoshop. If you went and you tried to erase trees from an image, then you'd have this puzzle of what would happen about stuff that was occluded by the trees like what's going on behind there. And so this image generator is actually it's got this latent model that has an understanding of what the scene is. And so, and even has an understanding of things that is not explicitly drawing. So if you remove the trees from the scene, then it'll come up with a reasonable looking, you know, image to draw what was behind the trees, or you can do the opposite. Which is you can take neurons that were not originally on in a generated scene and turn them on. So if I take a set of neurons that correlate with doors, and I turn them on in a certain location, and you can see what happens in the generated image, you know, I'll get this door in the scene, not only will it just be a door, but it'll be it'll have like an appropriate size and your orientation and style for for the building that it's in. So if I take exactly the same neurons, and I activate them in a different location like here in this building, then even though it's exactly the same neurons exactly the same activation that I've done, I get a different door that is like a much smaller has a different style and so on. It's appropriate to the building that it's in. If I if I try to put a door in a place that would make sense, like by turning on neurons up in the sky, then it like will like not do anything. This is this is the actual output of what happens if I turn on the exact same neurons up in this location. So there's a lot of interesting context sensitivity that you can measure. But one of the cool things that you can do is you can actually hook this up to a paintbrush user interface, like I can find neurons that correlate with domes or doors or things. And if I want to add doors to a building, I can just sort of paint them on. And the doors will show up and you can see the orientation of the doors is appropriate to the wall that you put them in. If I just say I want trees, it'll put trunks and leaves, you know, in the right place in the trees or plants with a plant, plant them on the ground. If I take grass and I can turn the grass neurons off and remove grass from the scene and it'll come up with what the scene should look like instead. And so I can kind of do these semantic manipulations directly. Oh, here we're turning on domes and you can see it will turn the top of the the church from a spiral to a dome, but it also sort of stitched the dome into place to make it look good here. I'm removing grass again. We can like put a door in the scene. And if I if I put you know, sort of put a door in the wall, then it'll it'll come up with like the appropriate location and style orientation for the door even if I draw very roughly. So when I'm drawing, every time I touch the surface here, what I'm really doing is I'm just turning on a few neurons. And and I'm letting the the math of the GAN generator deal with all of the the details of how to arrange the actual pixel. So does that does that sort of give you a sense? Does that answer your question for like, you know, what kinds of things you can do with this by understanding what's going on in the interior of the model? Maybe now I should stop it. Oh, yes, go ahead. Are these different neurons for like doors in different areas? No, no. So when I when you click on the door button on the left, I am picking 20 neurons that are the door neurons. So by doing the statistical analysis ahead of time that I showed you earlier, I've identified 20 neurons that correlate very strongly with the presence of doors. And when you click on the button on the left, I am picking those neurons. Now, it's a convolutional network. So there's this translation and depends those neurons appear at every pixel. And so what you can do is you can just turn on those neurons in random pixels that you touch. Changing where the neurons are, that was what I didn't understand. Does that make sense? So, so because it's a convolutional network, so it's actually it's it's like the neural network is cloned at every location. It's the same neural network that's being used to process every, you know, patch or patch of pixels in the image. And, and so if I asked for a door in a place that wouldn't really make sense, then it won't put a door there. If I asked for a door in a place that makes sense, it'll make a big intervention, it'll stick a big door there, which you can see. So I could be very rough about where I put a door and it'll like put it in the right place. So that's that's the idea. So let me let me zoom around here, I'll show you a couple other things that you can do. So now there's some limitations to this. And I'll just show you some of the techniques that you can use to get around the limitation. So one of the problems is that, you know, we can do all this cool editing, but we can do this editing of a randomly generated image. And, and so, so when I posted this demo on on the web, you know, an artist called me and said, Hey, you know, I love how you can edit images, I can edit this image of a kitchen here. But that's not the kitchen I want to edit, I want to edit my own kitchen, right? Like here's a photo of my kitchen. And I want to edit that one. And I had to explain to them, you know, they said, Oh, can you just load into your demo? My my kitchen instead of yours. And I had to explain, no, no, no, that's not how GANs work. They're unconditional generators. You know, you give it a random vector of 512 numbers. And it decides what image to make. And then once it decides what image to make, then you can edit it. And so I'm sorry, I can't edit your kitchen. And so they were very disappointed by that because they had all sorts of ideas of things they wanted to do. And so now the problem is that, you know, the problem could be solved if we could find the random vector, some random vector that that output the kitchen image or the specific real photo that I wanted. The problem is how do I find it 512 dimensional vectors as pretty big vector space. And and so I don't know if my GAN can actually generate this image or not. So one of the things you can do is you can just treat this as a as an inversion problem. You can take the neural network and you can learn how to run it backwards. Basically, you know, think of the neural network as a function G, and you want to learn G inverse. So you can treat that as another training problem. And there's a bunch of tricks and I won't go into all the tricks here. But but basically, the idea is that you can actually find a Z that comes closest to generating your image by by training and doing a couple other tricks. And you can actually get a Z that will generate your image pretty closely. But the thing that's a little bit sad is it also reveals things that the network cannot do. So so this network is capable of generating this image that I'm showing you here. But the original kitchen that I started with look like this. So you can see what the differences are. I've lost a lot of stuff. Right. So, you know, I can use the GAN to edit this image. But this image is not exactly what I started with. And so. So one of the pieces of science that that I did is I asked a question, you know, is there some way that we can actually make this work? Can we actually, you know, get the network to output a real photo that that the user gave us? We get the network to output this sort of simplified version of it. It turns out that if I modify the weights of the network, I can actually fine tune the network to get it so that a very, very nearby network with weights that are almost the same as the original actually hits this target image. Exactly. And so so there's a bunch of details in the right way of doing this. But it turns out that, you know, you don't actually have to change much if you change the fine grained weights of a network. You can you can change a lot of the details of what images actually get generated. And and and if you are given a target image to get you can actually tweak tweak any network to generate exactly that target image if we want. And so so you know, so yeah, we can get all the objects back. But the new thing is we haven't really changed the network much. So we can still do editing. So like if we take the window correlated neurons, we can take our modified network, we can turn them on. And and now we can like add a window. Let's see if we show that. Yeah, so this here's outlook. So we get this nice window here. And the scene is began is doing its cool tricks of orienting the window properly, doing some reasonable things. And it has some really interesting effects that are non trivial here. Some of them are good and some are bad. So for example, all I did was turn on the neurons in this location saying I want windows. And it did it. But look what else it did. It also added these reflections right here on the counter. And so this this kitchen guy does this a lot like adds adds non local reflections where it thinks that there's a shiny table. And so the cool thing here is that after I did all the inversion and stuff, this guy actually thinks that there's a shiny table here and it's right. And it thinks that if I add a window here, they should add reflection. That's right. Also, but look what else happened up here. See this lamp up here. When I first lifted this in low resolution, I thought, Oh, maybe it turned off the lamp because once you have windows, you don't need the light on. But no, it didn't do that. It just messed up the lamp. It's just total it took this whole area up here and just and just distorted it badly. And so so that that's a little dissatisfying. It means that this fine tuning thing, where we get again to, you know, target a specific user image, when I do when I try to teach it all the details, I'm not really teaching it what the lamp was, I was just sort of showing it how to arrange the pixels. And again, made its best guess on how to generalize how the image should look differently. If I change something like out of window, but with only one example of a lamp that looks like this, it generalized wrong, it has no idea what should happen to that lamp when I when I add a window. So this is this question of like how to make changes in a network with with with achieving good generalization is, which is a good question. And it was, there was something that puzzled me for a year after doing this work. But but the work is still pretty cool, you can still use it for modifying real photos. So here's like a photo of I got off of Wikipedia of like some real locations. And you can you can edit them, I can add grass, I can add doors, I can add domes, you know, just like, just like the the the other campaign app, except I can actually start with a real photo that you give me. And I can invert that photo through the network, get a good starting image, fine tune the network to make it make it output, you know, the target image and edit that image, add bigger domes, and it'll sort of match the architectural style. And, and, and, you know, do different things like that, I can add domes, remove domes, add doors, you know, things like that. Let me see if I can get this video here to show. So this is the status center. Let's add some doors here. So you get the idea, I'm doing exactly the same intervention that I did before. And it's it's opinion just like before, it will not add doors in places that it doesn't think are not good places for a door, it has some opinions about where doors are allowed, it likes to put them in brick walls. It thinks it's okay to put a door in a tower, like that architectural detail. Oh, I put domes here. It's happy to put domes on top of buildings. It's not happy to put a dome like in the middle of the sky. It's not happy to put a door in the middle of the sky. But you know, it put trees in different places. And, and so there are things that it understands, there are things that it doesn't understand very well, it's sort of making a guess of what the structure of the image is. It doesn't know what to make of my advisor, you know, sort of planting grass in front of him. And that's not very realistic. But you kind of get a feel for what the structure and knowledge of the model is by doing these kind of interventions. So this was really cool. I think it got a lot of people's attention. Adobe noticed this stuff, and has been busy trying to make different painting applications using, you know, GAN technology that are I think partially inspired by by by this kind of discovery. So David, I have a question. Yep. This is really cool. Question is, when you modify, for instance, churches, I assume you have trained your GAN on a church data set. Yes, that's correct. What about when you do it on the real images, for instance, in this case, you know, your advisor? Yes. So actually, both of these are using the church data set as well. So the church data set, interesting that even you have trained again on church, you can depict a person. Yes. So this is so the GAN. Now, you have to keep in mind that what I've done here is I fine tuned the GAN. So you can actually, you know, you can actually get you can actually get a GAN to do a lot of things by fine tuning it. So I've I've told the GAN, please basically overfit on this target image. So the GAN, you know, has 30 million parameters. And, and you know, an image only has, you know, 10,000 pixels, and it has plenty of excess capacity to memorize the details that I might want to do. And so what I've done is this as I've taken the image, I've asked again, through my inversion techniques, what is the closest church image that you can generate that looks like my thing. And you get a different image. I don't have the image to show you here, but you get an image that looks kind of more church like it's a little bit, it'll be architectural have the right kind of shape, the kind of right textures. But you know, it won't show my advisor here and things like that. It'll be, it'll be this rough approximation for that my my image, but that is in the domain of what the GAN can actually generate. Then I say, Okay, that's not what I want to do. I want to actually edit this photo. So let's fine tune that network so that so that given that same Z instead of generating the church that you would normally generate, I want you to generate this image, change the weight slightly, get it so that that Z targets this. And, and so that's what I've done here. But I've tried I've done that in a way where I try not to change the weights too much. I just try to change the weights. I change the fine grained layers. And I don't change the coarse grain layers. And I, and I have a regularizer to make sure the weights don't change too much. And that you are changing the pre trained weights, or you are putting some extra weights, and then you place them. Oh, here, I'm actually changing the pre trained weights. So the network has 15 layers. I'm actually going and I'm changing some of those layers. I'm not adding anything new to the network. I'm just changing the weights in the network itself. Now, now what I've done here is I've overfit the network to this one image. The network is not generalizing this knowledge. So for example, you can draw Antonio in this one image. But if I look in the network, if I probe it a lot and see, can it ever generate Antonio in a different setting in a different image? It cannot. In fact, you know, as much as we probe things, it really doesn't look like we've changed the output of the network in any meaningful way for any image, except for this one. It's almost like, you know, the network generates this really complicated manifold of realistic images. And we've told we've picked up one point of the manifold, and we've dragged it over to pass to this point. But we've done it in a very local way. So it's really not affected any other points of what the GAN is generating. And so so but but for the purposes of doing this kind of application, it doesn't matter that it's not generalizing because the user doesn't care about a different photo, they just care about their own photo. So it's a pretty cool. It's pretty cool technique anyway, even though it's sort of not the classical goal of machine learning. Does that make sense? Yeah, it does. And I wonder if the user has more images of themselves with that over time, and make the network even better in generation? Yes, this is the big question. And I played with this for many months, and I haven't got it to work. And if anybody can figure out how to get to work, I feel like it's one of the holy grails of like how to add a new thing to a generator. So like, the generator knows about all these things that knows about trees and knows about all these architectural pieces, you know. But what if I came along with something new? What if I was what if my what if I what if I work for GM and I want to sell Cadillacs, then I then I might come to one of these models and say, you know what, you should draw cars. In fact, I want you to draw specific cars. I want you to draw Cadillacs in front of all these buildings. How would I add Cadillacs to my model or add Antonio to my model or something like that? And we don't know how to do that yet. Although I'm going to show you a little bit of work, where we can do something that's very similar. And if I don't know if I have time to, to go over this, but I'm going to I'm going to zoom through this because I'm so excited by this work. So, so, so it's motivated by this, this sort of question, which is, you know, we have a model of like drawing towers, let's say, right? But there are things in the world that we might want to model that we don't have a data set for. For example, you know, in in in Decatur County, Illinois, there's this courthouse that has a tree growing out the top of the tower. It started growing out there by accident, but the people in the town love it. And so but it's but there's no so like if I want to get a generative model to draw trees growing out of tops of towers, I can't do that in a classical way because I can't create a big data set of a million buildings that have trees growing on the top of the towers, because they don't exist. It's just this one. And so now if if the point is I want to generate images of this type, you know, well, I could use a regular image editor, I can take any building of a tower, and of course, I can stick a tree on it, right? I could use my, you know, again, painting method to, you know, activate tree neurons or something like that. But no, no, that's not what I'm asking. I'm asking this other question of like, how can we stick tree towers into my model? How do I modify the model to have this new concept in it? Like I start with this model that has all these weights that encode all these rules for how buildings look and things like that. And I want to create a new model that has new weights that encode new rules. So for example, the old model could generate all these buildings that of towers that look normal have spires, you know, pointy tops. And I want to make a new model that has weights, they encode a different rule, so that like, they have trees growing out the top, right, or any rule that I choose, right? And it turns out that this is actually possible. So this is different from the technique that I showed you before, because in this technique, it's actually generalizing. This is, you know, if you use this technique, not only you change the output of one image of the GAN to have like some effect, but we can actually change the outputs for a whole class of, you know, a large subset of the outputs of the GANs to follow a different rule, like any pointy tower output will have trees instead of pointy towers. And so so I'll just show you a little bit of like the interaction here of what it looks like when you get our method into an application. So I let's see if I can get this to work. So here, what I'm showing you is the output of a style GAN be to generating churches, you can kind of, and there are three parts of this UI, there's an image viewer, then what you do is you can select a rule that you want to change, and then you can specify how you want to change your rule. So there's three parts of this little user interface. And I'll just show you sort of how how the effect looks by showing you one of the interactions. So you can kind of use the image viewer to scroll through lots of examples of of what the the generator is capable of generating. And then we can go to these examples and we can say, Hey, you know what I'm really interested in? I'm interested in this rule of how to generate pointy towers. And so I can select a few pointy towers. And you can think of this as what I'm looking for is the neurons that are responsible for the shape. And so I can select a few examples and I can say, Hey, what other, what other outputs of the GAN share the same representation? And, and it'll show me, Oh, yes, the GAN is generalizing this way, these other pointy towers are represented the same way as the ones that you chose. And then I can go and I can say, All right, I want to redefine how these pointy towers are rendered by this generator, I want them to be rendered like this tree here. So I can copy the tree from one output of the generator, and I can paste it into where I would like that tree to show up. I wanted to show up instead of pointy towers. And then I can say, Okay, now insert this new rule into the model, compute what the right changes to change the model. And then after I do that, that takes about a second to do the math to figure out how to change a rule. And then after I do that, then I get the GAN to generate new images. And, and they look like this, you know, like the tops of the towers, now have trees on them instead. So you can see how that looks. And it's not just affecting that one image, it's affecting all the pointy tower images. I can do a little search for more pointy tower images. And, and do I have that here in my thing? Yeah, so here's a search for more pointy tower images. And you can see they, you know, they all have gotten these trees sprouting out the top of it, like some sort of dystopian tree world where vegetation is taking over the planet. And, and so you can do this in a bunch of things, I'm gonna skip over some of the technical things here, or some of the other examples of what you can do here. You can edit reflections and things like that. I've got other videos that you can look for on the internet. But I wanted to show you a sense for what we're doing inside when we do this kind of thing. So like I showed you before that again, has is like, got all these convolutional layers stacked up, it's about 15 layers. And what what, what, what the discovery was that led to this application was that each one of those layers can be thought of as solving a very simple, separate problem from the other layers. And what is that simple problem? It, it can be treated like a memory, where the layer is solving this problem of matching key value pairs that it's memorized. So every location has a feature vector that you can think of as a key. And what and the key each key like, you know, represents a certain type of context, like, you know, the middles of towers or the tops of towers or something like that. And what you can think of the map as as as storing is what should be what is like the pattern of features that should be rendered whenever that context comes up. Right. So you can think of it as just basically key value store. And and so so this whole idea of using a matrix as a key value stores and it's like the oldest idea in neural networks. People observe back in the 1970s, that if you have a single layer neural network, you can treat it as a as an approximate key value store that remembers keys with minimal error. And and so if you had a set of keys and a set of values you want to store, and you ask what is the optimal single layer neural network that you'd use to store it. It's actually, you know, classical linear algebra, it's like the solution to a least squares problem. So what we can hypothesize is that in these very, very fancy, you know, 2020, you know, 50 years later, deep neural networks, actually, each layer is just acting as one of these. Now, which keys are being stored and what values were being stored? We don't know. But we could hypothesize that there is some set of things that are being memorized, some set of keys and values. And so that that maybe this weight matrix that we have is the solution to the assembly squares problem. So the cool thing that we can do is we can say we can ask the question, what would the weight matrix look like if we changed one of the rules? What if we had one new key value pair that we wanted to change? Then what would the weight matrix be? Instead, we want all the other things that the network has memorized to still be memorized with minimal error, just as before, except we're going to give this new constraint, we want to write a new key value pair into it. And it turns out that that's also least squares problems and constrained least squares problem, we can write down the solution in this form. And the cool thing about these two, the squares problems is that they cancel each other out. Most of the terms are the same. And, and, and we can actually ask the question, how would the weights have to change if we add a new key value pair, without knowing which values were written into the network before, we don't actually have to know what the old key value pairs were, we can just assume that the network was optimal as storing all these key value pairs. And, and the math for like how to write a new key value pair comes out the same anyway. So, so that's there's there's a little bit of a mathematical insight and trick here. But what it allows us to do is it allows us to find exactly what we want to do to change one thing that the network is memorized, you do this rank one update in a specific direction. And, and you can take a key and change it to any value you want. And that will, you know, the same form will minimize error for, for other keys, regardless of what value we write, it's almost like it really is a form of memory, that we're changing. So our method is basically you find a key by asking the user to select a few contexts that look the same, we average them to get a good key. Then we ask for a copy paste example to get a goal. That's the new value that we want to write into the key of the memory. And then we do this math to, to find how to change w in the direction of the key only, we find a rank one update that does this. And so, and so that avoids changing other rules. So we can do this on a bunch of different GAN models. And, and so you can see, like, you know, people like to change people's expressions here. So what we're doing is a little different from what you normally do to change people's expressions. And again, what we're doing is we're actually going to rewrite the GAN. So it only outputs people who are smiling, we're going to take all the frowns, we're saying, okay, there's, there's a rule for frowns, we're going to change that to a rule for smiles by showing an example. And so by patching frowns to smiles, now we have a model that just outputs people who are smiling. Now we live in a happy world. So that's, that's, that's pretty cool. And now, of course, we could have done that by, you know, changing the training set by collecting only training data of people who are smiling. But the neat thing is that you can also do this for things where you don't have a training set that looks like it. So for example, there's a, there's a rule in the model for how eyebrows should look on kids. So you can see that kids have these very wispy light eyebrows that don't have much hair. So we can find that rule by identifying a few examples that gives us a rank one direction in the weight matrix. And then we can redefine it, we can write a new thing into it and say, you know what, we want the eyebrows to look like this, like that's very bushy much sash. And, you know, paste into one example, do the math. And then now we can change weights in a way that generalizes. So now all the kids had these very bushy, you know, eyebrows. And it's something that we wouldn't have been able to get by collecting training set because we don't have kids that look like this in the real world. It's something that just comes out of our imagination. So this is kind of the thing. I kind of feel like this is the big reason why, why, why be interested in how these models are working inside. And the reason to be so interested in it is because as long as we don't look inside our models, then we're really constrained. Because the only thing that our models can really do is imitate the real world. We can collect huge amounts of data. And the models that we create, we'll just get better and better at imitating the way that the data is the way the world is today. And I kind of feel like it goes a little bit against why I was interested in computer science years ago when I entered it in the first place. Because the amazing thing about computer science is that you can use it to create algorithms that represent things in the world that don't exist yet, things that you can only imagine. And so machine learning is sort of on this path right now, where we're getting very, very good at replicating the way the world is. And we're going to be confronted with this question of how do we use these techniques to actually create new worlds that don't exist yet that are the way that we want them to be. And I think that this really going to require us to not just get models that are just really good at imitating, but also models that are understandable to people so that we can change their rules inside, and then use them to create things that are based on our imagination instead of just the training data. And so here's a fun thing here, I think, if I want to be fair to the horses, you notice that none of the horses in this horse generating GAN get to wear hats even though all the people get to wear hats. So we can change that by taking a hat from a person and inserting it into our GAN's model of what a horse's head should look like. And now horses get to wear hats, right? And so, so let's build a better world. And, and allow people to change the rules of the world by making the rules more visible and and manipulatable by humans. That's that's sort of the goal of the whole thing. So any questions? Any questions? I have a question. Yes. Does this method work with multiple different models? Or is it only successful when like, taking a hat from within this model and put it on a horse? So right now, this, this method is only able to take it, it's it's only able to rewire one model. So I can take one part of a model and rewire it to a different model, you're sort of asking the transplant question. So I'm sort of at the point where, you know, it's like a surgeon, I can like connect one blood vessel to another blood vessel in the same human, right? And you're sort of asking the question, well, can I do a heart transplant? Can I take a heart out of one person put another one? And I cannot do that yet. It turns out to be harder. And, but I but it is a it is an obvious goal. And I, and I feel confident that if we understand well enough, all the things that make these computations work, what is needed for the care and feeding of a computational module? What is a computational module inside a big learning system? Then we should, you know, it should be a goal to be able to move a piece of computation from one neural network to another one. Does that make sense? Yes, thank you. Yep. That's a really great question, by the way. I think it's, I think it's fundamental. Any other questions? This is not too well articulated question. I was just curious what you, what are your thoughts about this? I think this is this like neural nets have tendency to like avoid the responsibility of the results, like everything is done in the hidden layers and sort of shrug off shrug off the responsibility about the results. And I thought it was like interesting how you set the objective towards something as abstract as realistic. And here, like how you define the concept of being realistic is based on the big data you collected from the web, but but oftentimes some like fake images sometimes look even more realistic than real images. And I don't know, like tree growing on top of the building may look fairly realistic for some people, but maybe for plant experts, maybe it would not. Right. So I don't know, like, I think this might result in like the blurring between the it's making us hard to distinguish between the real and the fake or something like that. I don't know. Yes, yes. No, I think that there are so so the we're we're unaccustomed to making it easy for making programs that make such realistic renderings of the world. And it's actually a concern. I think that, you know, people have misused this technology already that we you know, we use we you know, there's the whole deep fakes phenomenon. But even without like faking videos, people people have you know, used face generators to make lots of fake Facebook profiles and things like that, you know, pretending there are millions of people that exist that don't actually exist and things like that. So so even before you sort of do manipulations of the world, I think that there's already this problem of of of, you know, pretending that there's a lot of data that there actually isn't by using these generator models. And so I think that there's you know, the whole the whole question of fakes is a very serious question, like how do we how do we function society if we don't know what's real and what's fake. Now, it's not a totally new issue. You don't need a state of the art deep learning model to make fake, you know, people have made fake photoshopped by hand forever, people write can write text that has all sorts of lies forever. In fact, that's probably more effective than you know, trying to train a deep learning model and, you know, sort of make it work. But I think it's I think it's a, you know, it's still an important question because the easier we make it to make fakes, you start to get issues like a scalable fakes, where it's not just one, one photo that is a lie or one article is lie, you could generate millions. And I think that there are serious issues with that. So there's some pretty interesting work in forensics for detecting fakes, and things like that. That I think is important to invest in as well as as we as we advance the state of the art and this kind of thing. So I so so I don't want to minimize the implications of this type of thing. I think that for the type of work that I'm doing, I think that you observe that the tree kind of looks realistic, it's not super realistic. You know, if you're a plant expert, it's just sort of, you know, sort of there. I think the same thing with hats, they don't really super look like hats. And so I think that we're, we're sort of the stage where they're really exciting where the implication of what I've done here, I think is the idea that the, you know, learning how these models are working inside, by understanding what the internal structure of the models is, is really the, that the the exciting part that that it's starting to give a little insight on how we might untangle and disassemble what the internal logic is, that is being learned by these, these deep networks. And, and I'm actually, I feel like this is, I feel like there's a different issue other than fakes, which is actually has some ethical implications, which is transparency of deep networks. Because one thing that they're not really good at doing is when you have a deep network do something amazing, they're really not good at answering the question, why? Why did you do that? Why did you choose to render it this way? Why did you choose to pick these objects to put in the scene? Or why did you choose to deny me some credit or to, you know, to make some other decision that we were at, you know, depending on neural networks to do. And I think that if we can understand how to disassemble the rules that are being applied inside the network for it to make its decision, then I think that we'll will be, we'll have a way of asking why. And by looking at the computation directly. So that's my, that's one of my goals and one of my hopes in doing this kind of work. Definitely, I can see some of the worst of you about like, about the transparency of the neural network, especially when you, when you show the example where you detected a single neuron that contributes to the watermark thing, I think that it was really interesting. Yeah, I think so too. I was surprised that it worked because we normally think of neural X is very, very, very opaque. I also have a small question regarding artifacts. So I think in the beginning, you talked about how you segmented the network with like masks that were classified before by mapping neurons and beginning layers, which create things. But could like, can that be also used to figure out where artifacts or anomalies are generated to make gains better? Yeah, actually, I don't have a picture of it here. But in my work where I was looking for neurons, originally, it's called the paper is called GAN dissection, you can you can Google for it. And, and I showed that in that paper, we analyze some of the pre trained GANs that came from a previous work from NVIDIA called progressive GAN, we analyzed some of the pre trained models, and we found that they actually are neurons that correlate with bad looking artifacts in a scene. And if you turn those neurons off, you can actually not only improve the quality of the output of the GAN, just qualitatively like you can get these artifacts to not show up but using standard measures of GAN, you know, statistical measures of GAN image fidelity at large scale. By removing these neurons, you can actually improve the what we call the FID scores of these GANs when we tested on like 50,000 images. And so, so that's actually very weird to me, that's, it was a big surprise. Because, because we, we train these things using, you know, powerful optimization techniques, using, you know, billions of floating point operations, you know, training these things on big expensive GPUs for a long period of time. And the idea that a human can come along, and do a simple looking visualization, pick out a few neurons based on things that don't look good. And improve the model by turning those neurons off. It was like it shouldn't be possible, right? If it was so easy to improve the model that way, why couldn't the optimizer find it? And so, so I think that was, that was, that was pretty interesting. I have not repeated that experiment on the latest GANs, which are actually much better the style GANs. To architecture, they went back and they analyzed a bunch of the artifacts that show up in this, this family of GANs. And they, they found that there are certain learning methods that they can do to remove the artifacts or reduce them somewhat. And so I don't know if a human can still beat the current generation of GANs, it'd be worth going back and seeing that phenomenon is still there. That's pretty cool. Thank you. Yep. Okay, excellent. Thank you so much, David. It was really fascinating topic and talk and more interesting to me, asking the right questions, asking questions and learning to ask the right questions. It's really interesting. And I think that it opened paths to many of us. Excellent. Hey, thank you for the opportunity to talk to the group here today. I always enjoy the, the chance to interact with folks about this. If anybody wants to send other questions about it, of course, you can always send me a note. And, you know, I love this stuff. Yeah, definitely. I think that it would be great to follow follow your work on your GitHub and your website, and especially for students who play with the tools that you have, so they have them get an understanding of how these two work and make them curious about the work. Cool. Excellent. Thank you so much. Thank you, Ali. Thank you, everybody. Thank you. Bye now.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.88, "text": " Hello, everyone, welcome back to our course, a deep learning", "tokens": [50364, 2425, 11, 1518, 11, 2928, 646, 281, 527, 1164, 11, 257, 2452, 2539, 50608], "temperature": 0.0, "avg_logprob": -0.24440808839435818, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.0028722616843879223}, {"id": 1, "seek": 0, "start": 4.88, "end": 12.84, "text": " for art, acetic and creativity. Today, it is our pleasure to", "tokens": [50608, 337, 1523, 11, 696, 3532, 293, 12915, 13, 2692, 11, 309, 307, 527, 6834, 281, 51006], "temperature": 0.0, "avg_logprob": -0.24440808839435818, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.0028722616843879223}, {"id": 2, "seek": 0, "start": 12.84, "end": 18.28, "text": " have very a specialist speaker, David Bao, and I just let him", "tokens": [51006, 362, 588, 257, 17008, 8145, 11, 4389, 42099, 11, 293, 286, 445, 718, 796, 51278], "temperature": 0.0, "avg_logprob": -0.24440808839435818, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.0028722616843879223}, {"id": 3, "seek": 0, "start": 18.28, "end": 22.64, "text": " to introduce him a little more, because I think it's very", "tokens": [51278, 281, 5366, 796, 257, 707, 544, 11, 570, 286, 519, 309, 311, 588, 51496], "temperature": 0.0, "avg_logprob": -0.24440808839435818, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.0028722616843879223}, {"id": 4, "seek": 0, "start": 22.64, "end": 29.400000000000002, "text": " inspiring for many students, the path that he has come to", "tokens": [51496, 15883, 337, 867, 1731, 11, 264, 3100, 300, 415, 575, 808, 281, 51834], "temperature": 0.0, "avg_logprob": -0.24440808839435818, "compression_ratio": 1.4801980198019802, "no_speech_prob": 0.0028722616843879223}, {"id": 5, "seek": 2940, "start": 29.4, "end": 35.04, "text": " this point and for future. Please go ahead. So I was, I", "tokens": [50364, 341, 935, 293, 337, 2027, 13, 2555, 352, 2286, 13, 407, 286, 390, 11, 286, 50646], "temperature": 0.0, "avg_logprob": -0.1956945566030649, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.012790601700544357}, {"id": 6, "seek": 2940, "start": 35.04, "end": 43.92, "text": " want to give a little background since I am a post", "tokens": [50646, 528, 281, 976, 257, 707, 3678, 1670, 286, 669, 257, 2183, 51090], "temperature": 0.0, "avg_logprob": -0.1956945566030649, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.012790601700544357}, {"id": 7, "seek": 2940, "start": 44.12, "end": 46.76, "text": " industry academic, I spent a bunch of years as a software", "tokens": [51100, 3518, 7778, 11, 286, 4418, 257, 3840, 295, 924, 382, 257, 4722, 51232], "temperature": 0.0, "avg_logprob": -0.1956945566030649, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.012790601700544357}, {"id": 8, "seek": 2940, "start": 46.76, "end": 50.76, "text": " engineer at Google before coming back to MIT. And I want to", "tokens": [51232, 11403, 412, 3329, 949, 1348, 646, 281, 13100, 13, 400, 286, 528, 281, 51432], "temperature": 0.0, "avg_logprob": -0.1956945566030649, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.012790601700544357}, {"id": 9, "seek": 2940, "start": 51.0, "end": 56.72, "text": " give a little bit of insight in my thinking there. So, you know,", "tokens": [51444, 976, 257, 707, 857, 295, 11269, 294, 452, 1953, 456, 13, 407, 11, 291, 458, 11, 51730], "temperature": 0.0, "avg_logprob": -0.1956945566030649, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.012790601700544357}, {"id": 10, "seek": 2940, "start": 56.72, "end": 58.32, "text": " the reason it's really interesting to be in computer", "tokens": [51730, 264, 1778, 309, 311, 534, 1880, 281, 312, 294, 3820, 51810], "temperature": 0.0, "avg_logprob": -0.1956945566030649, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.012790601700544357}, {"id": 11, "seek": 5832, "start": 58.32, "end": 61.6, "text": " science right now is because the field is changing. The dream", "tokens": [50364, 3497, 558, 586, 307, 570, 264, 2519, 307, 4473, 13, 440, 3055, 50528], "temperature": 0.0, "avg_logprob": -0.10015123030718635, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.011653535068035126}, {"id": 12, "seek": 5832, "start": 61.64, "end": 66.0, "text": " of having self programmed computers is one of the oldest", "tokens": [50530, 295, 1419, 2698, 31092, 10807, 307, 472, 295, 264, 14026, 50748], "temperature": 0.0, "avg_logprob": -0.10015123030718635, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.011653535068035126}, {"id": 13, "seek": 5832, "start": 66.0, "end": 72.2, "text": " dreams in computer science, but it's never been a reality. Even", "tokens": [50748, 7505, 294, 3820, 3497, 11, 457, 309, 311, 1128, 668, 257, 4103, 13, 2754, 51058], "temperature": 0.0, "avg_logprob": -0.10015123030718635, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.011653535068035126}, {"id": 14, "seek": 5832, "start": 72.2, "end": 75.64, "text": " though we've studied machine learning for a long time, I think", "tokens": [51058, 1673, 321, 600, 9454, 3479, 2539, 337, 257, 938, 565, 11, 286, 519, 51230], "temperature": 0.0, "avg_logprob": -0.10015123030718635, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.011653535068035126}, {"id": 15, "seek": 5832, "start": 75.64, "end": 79.12, "text": " that until just a few years ago, machine learning was really", "tokens": [51230, 300, 1826, 445, 257, 1326, 924, 2057, 11, 3479, 2539, 390, 534, 51404], "temperature": 0.0, "avg_logprob": -0.10015123030718635, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.011653535068035126}, {"id": 16, "seek": 5832, "start": 79.12, "end": 82.92, "text": " more accurately called, it would have been more accurately", "tokens": [51404, 544, 20095, 1219, 11, 309, 576, 362, 668, 544, 20095, 51594], "temperature": 0.0, "avg_logprob": -0.10015123030718635, "compression_ratio": 1.6222222222222222, "no_speech_prob": 0.011653535068035126}, {"id": 17, "seek": 8292, "start": 82.92, "end": 87.52, "text": " called the art of accurate counting. You know, statistics,", "tokens": [50364, 1219, 264, 1523, 295, 8559, 13251, 13, 509, 458, 11, 12523, 11, 50594], "temperature": 0.0, "avg_logprob": -0.13877652553801842, "compression_ratio": 1.8426395939086295, "no_speech_prob": 0.013406675308942795}, {"id": 18, "seek": 8292, "start": 89.16, "end": 93.16, "text": " you know, understanding the statistics of, you know, how", "tokens": [50676, 291, 458, 11, 3701, 264, 12523, 295, 11, 291, 458, 11, 577, 50876], "temperature": 0.0, "avg_logprob": -0.13877652553801842, "compression_ratio": 1.8426395939086295, "no_speech_prob": 0.013406675308942795}, {"id": 19, "seek": 8292, "start": 93.16, "end": 97.08, "text": " frequent words are and by grams or, you know, certain image", "tokens": [50876, 18004, 2283, 366, 293, 538, 11899, 420, 11, 291, 458, 11, 1629, 3256, 51072], "temperature": 0.0, "avg_logprob": -0.13877652553801842, "compression_ratio": 1.8426395939086295, "no_speech_prob": 0.013406675308942795}, {"id": 20, "seek": 8292, "start": 97.08, "end": 101.76, "text": " statistics or something like that. And, and, and if you if you", "tokens": [51072, 12523, 420, 746, 411, 300, 13, 400, 11, 293, 11, 293, 498, 291, 498, 291, 51306], "temperature": 0.0, "avg_logprob": -0.13877652553801842, "compression_ratio": 1.8426395939086295, "no_speech_prob": 0.013406675308942795}, {"id": 21, "seek": 8292, "start": 101.76, "end": 105.6, "text": " understand statistics well, then, then, then, then, you know,", "tokens": [51306, 1223, 12523, 731, 11, 550, 11, 550, 11, 550, 11, 550, 11, 291, 458, 11, 51498], "temperature": 0.0, "avg_logprob": -0.13877652553801842, "compression_ratio": 1.8426395939086295, "no_speech_prob": 0.013406675308942795}, {"id": 22, "seek": 8292, "start": 105.6, "end": 110.92, "text": " you could do some nice tricks. But I think that until recently", "tokens": [51498, 291, 727, 360, 512, 1481, 11733, 13, 583, 286, 519, 300, 1826, 3938, 51764], "temperature": 0.0, "avg_logprob": -0.13877652553801842, "compression_ratio": 1.8426395939086295, "no_speech_prob": 0.013406675308942795}, {"id": 23, "seek": 11092, "start": 110.96000000000001, "end": 115.76, "text": " really calling these things sort of self programmed systems", "tokens": [50366, 534, 5141, 613, 721, 1333, 295, 2698, 31092, 3652, 50606], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 24, "seek": 11092, "start": 116.4, "end": 118.68, "text": " would have been an overstatement. But I don't think it's", "tokens": [50638, 576, 362, 668, 364, 670, 19435, 1712, 13, 583, 286, 500, 380, 519, 309, 311, 50752], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 25, "seek": 11092, "start": 118.68, "end": 121.96000000000001, "text": " really an overstatement anymore. I think that these machine", "tokens": [50752, 534, 364, 670, 19435, 1712, 3602, 13, 286, 519, 300, 613, 3479, 50916], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 26, "seek": 11092, "start": 121.96000000000001, "end": 127.64, "text": " learning models are really learning non trivial things. And", "tokens": [50916, 2539, 5245, 366, 534, 2539, 2107, 26703, 721, 13, 400, 51200], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 27, "seek": 11092, "start": 127.68, "end": 130.6, "text": " it leads to all sorts of questions about, you know,", "tokens": [51202, 309, 6689, 281, 439, 7527, 295, 1651, 466, 11, 291, 458, 11, 51348], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 28, "seek": 11092, "start": 130.68, "end": 134.84, "text": " what should we be doing as programmers? What does it mean", "tokens": [51352, 437, 820, 321, 312, 884, 382, 41504, 30, 708, 775, 309, 914, 51560], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 29, "seek": 11092, "start": 134.84, "end": 137.28, "text": " to do software engineering? And so I thought it was very", "tokens": [51560, 281, 360, 4722, 7043, 30, 400, 370, 286, 1194, 309, 390, 588, 51682], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 30, "seek": 11092, "start": 137.28, "end": 140.84, "text": " interesting time to come back to academia. That's, that's why", "tokens": [51682, 1880, 565, 281, 808, 646, 281, 28937, 13, 663, 311, 11, 300, 311, 983, 51860], "temperature": 0.0, "avg_logprob": -0.1199019331681101, "compression_ratio": 1.684782608695652, "no_speech_prob": 0.0015721243107691407}, {"id": 31, "seek": 14084, "start": 140.88, "end": 144.92000000000002, "text": " I'm here. And I actually think that that's one of the choices", "tokens": [50366, 286, 478, 510, 13, 400, 286, 767, 519, 300, 300, 311, 472, 295, 264, 7994, 50568], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 32, "seek": 14084, "start": 144.96, "end": 148.20000000000002, "text": " you face when you're trying to decide between industry and", "tokens": [50570, 291, 1851, 562, 291, 434, 1382, 281, 4536, 1296, 3518, 293, 50732], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 33, "seek": 14084, "start": 148.20000000000002, "end": 153.4, "text": " academia. And I think in industry, you will have lots of", "tokens": [50732, 28937, 13, 400, 286, 519, 294, 3518, 11, 291, 486, 362, 3195, 295, 50992], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 34, "seek": 14084, "start": 153.4, "end": 157.92000000000002, "text": " resources to make things work to make the next widget or the", "tokens": [50992, 3593, 281, 652, 721, 589, 281, 652, 264, 958, 34047, 420, 264, 51218], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 35, "seek": 14084, "start": 157.92000000000002, "end": 162.16, "text": " application. And, you know, there are great places, Google is a", "tokens": [51218, 3861, 13, 400, 11, 291, 458, 11, 456, 366, 869, 3190, 11, 3329, 307, 257, 51430], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 36, "seek": 14084, "start": 162.16, "end": 164.84, "text": " great place, we can really push state of the art in that and", "tokens": [51430, 869, 1081, 11, 321, 393, 534, 2944, 1785, 295, 264, 1523, 294, 300, 293, 51564], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 37, "seek": 14084, "start": 164.84, "end": 169.48000000000002, "text": " do really neat stuff. I think that there's less of a push in", "tokens": [51564, 360, 534, 10654, 1507, 13, 286, 519, 300, 456, 311, 1570, 295, 257, 2944, 294, 51796], "temperature": 0.0, "avg_logprob": -0.12572664827913851, "compression_ratio": 1.7448559670781894, "no_speech_prob": 0.002181400777772069}, {"id": 38, "seek": 16948, "start": 169.48, "end": 173.79999999999998, "text": " industry to ask the question, Why? You know, why do things", "tokens": [50364, 3518, 281, 1029, 264, 1168, 11, 1545, 30, 509, 458, 11, 983, 360, 721, 50580], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 39, "seek": 16948, "start": 173.79999999999998, "end": 177.44, "text": " work? Why are we doing what we're doing? Where is it going to", "tokens": [50580, 589, 30, 1545, 366, 321, 884, 437, 321, 434, 884, 30, 2305, 307, 309, 516, 281, 50762], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 40, "seek": 16948, "start": 177.44, "end": 180.04, "text": " lead in either unintended consequences and things like", "tokens": [50762, 1477, 294, 2139, 49902, 10098, 293, 721, 411, 50892], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 41, "seek": 16948, "start": 180.04, "end": 182.79999999999998, "text": " that? You know, we, we tend not to ask those questions too much", "tokens": [50892, 300, 30, 509, 458, 11, 321, 11, 321, 3928, 406, 281, 1029, 729, 1651, 886, 709, 51030], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 42, "seek": 16948, "start": 182.79999999999998, "end": 186.16, "text": " industry, because there's so much to emphasize on, you know, the", "tokens": [51030, 3518, 11, 570, 456, 311, 370, 709, 281, 16078, 322, 11, 291, 458, 11, 264, 51198], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 43, "seek": 16948, "start": 186.16, "end": 192.64, "text": " how of how to how to get it to work. And so, and so, so I", "tokens": [51198, 577, 295, 577, 281, 577, 281, 483, 309, 281, 589, 13, 400, 370, 11, 293, 370, 11, 370, 286, 51522], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 44, "seek": 16948, "start": 192.64, "end": 197.01999999999998, "text": " thought it was a time to, to switch tracks and start asking", "tokens": [51522, 1194, 309, 390, 257, 565, 281, 11, 281, 3679, 10218, 293, 722, 3365, 51741], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 45, "seek": 16948, "start": 197.01999999999998, "end": 199.2, "text": " why because the field is changing so dramatically. And I", "tokens": [51741, 983, 570, 264, 2519, 307, 4473, 370, 17548, 13, 400, 286, 51850], "temperature": 0.0, "avg_logprob": -0.15558738708496095, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00555101502686739}, {"id": 46, "seek": 19920, "start": 199.2, "end": 203.28, "text": " think that, you know, I'd encourage people who have an", "tokens": [50364, 519, 300, 11, 291, 458, 11, 286, 1116, 5373, 561, 567, 362, 364, 50568], "temperature": 0.0, "avg_logprob": -0.1649718392979015, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0005524652660824358}, {"id": 47, "seek": 19920, "start": 203.28, "end": 208.83999999999997, "text": " interest in these type of questions to, to realize you", "tokens": [50568, 1179, 294, 613, 2010, 295, 1651, 281, 11, 281, 4325, 291, 50846], "temperature": 0.0, "avg_logprob": -0.1649718392979015, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0005524652660824358}, {"id": 48, "seek": 19920, "start": 208.83999999999997, "end": 211.48, "text": " can really make a real contribution by taking the", "tokens": [50846, 393, 534, 652, 257, 957, 13150, 538, 1940, 264, 50978], "temperature": 0.0, "avg_logprob": -0.1649718392979015, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0005524652660824358}, {"id": 49, "seek": 19920, "start": 211.48, "end": 216.48, "text": " academic track as well. So okay, so let me introduce my talk.", "tokens": [50978, 7778, 2837, 382, 731, 13, 407, 1392, 11, 370, 718, 385, 5366, 452, 751, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1649718392979015, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0005524652660824358}, {"id": 50, "seek": 19920, "start": 216.48, "end": 219.76, "text": " So it's about painting with neurons of general adversarial", "tokens": [51228, 407, 309, 311, 466, 5370, 365, 22027, 295, 2674, 17641, 44745, 51392], "temperature": 0.0, "avg_logprob": -0.1649718392979015, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0005524652660824358}, {"id": 51, "seek": 19920, "start": 219.76, "end": 225.72, "text": " networks. It comes out of work from asking why, you know, why", "tokens": [51392, 9590, 13, 467, 1487, 484, 295, 589, 490, 3365, 983, 11, 291, 458, 11, 983, 51690], "temperature": 0.0, "avg_logprob": -0.1649718392979015, "compression_ratio": 1.5475113122171946, "no_speech_prob": 0.0005524652660824358}, {"id": 52, "seek": 22572, "start": 225.76, "end": 233.6, "text": " do these networks do what they do? And so, so let me, let me", "tokens": [50366, 360, 613, 9590, 360, 437, 436, 360, 30, 400, 370, 11, 370, 718, 385, 11, 718, 385, 50758], "temperature": 0.0, "avg_logprob": -0.21923084648288027, "compression_ratio": 1.598984771573604, "no_speech_prob": 0.010155681520700455}, {"id": 53, "seek": 22572, "start": 233.6, "end": 238.32, "text": " advance here. Am I in full screen? So do you see the, do you", "tokens": [50758, 7295, 510, 13, 2012, 286, 294, 1577, 2568, 30, 407, 360, 291, 536, 264, 11, 360, 291, 50994], "temperature": 0.0, "avg_logprob": -0.21923084648288027, "compression_ratio": 1.598984771573604, "no_speech_prob": 0.010155681520700455}, {"id": 54, "seek": 22572, "start": 238.32, "end": 241.44, "text": " see the like the full screen slideshow I can't see what I'm", "tokens": [50994, 536, 264, 411, 264, 1577, 2568, 9788, 4286, 286, 393, 380, 536, 437, 286, 478, 51150], "temperature": 0.0, "avg_logprob": -0.21923084648288027, "compression_ratio": 1.598984771573604, "no_speech_prob": 0.010155681520700455}, {"id": 55, "seek": 22572, "start": 241.44, "end": 244.07999999999998, "text": " projecting? Or do you see like all my notes and all that stuff?", "tokens": [51150, 43001, 30, 1610, 360, 291, 536, 411, 439, 452, 5570, 293, 439, 300, 1507, 30, 51282], "temperature": 0.0, "avg_logprob": -0.21923084648288027, "compression_ratio": 1.598984771573604, "no_speech_prob": 0.010155681520700455}, {"id": 56, "seek": 22572, "start": 244.2, "end": 248.12, "text": " Yeah, I can see it. But also maybe a student can tell us.", "tokens": [51288, 865, 11, 286, 393, 536, 309, 13, 583, 611, 1310, 257, 3107, 393, 980, 505, 13, 51484], "temperature": 0.0, "avg_logprob": -0.21923084648288027, "compression_ratio": 1.598984771573604, "no_speech_prob": 0.010155681520700455}, {"id": 57, "seek": 22572, "start": 249.4, "end": 250.0, "text": " Yeah, okay.", "tokens": [51548, 865, 11, 1392, 13, 51578], "temperature": 0.0, "avg_logprob": -0.21923084648288027, "compression_ratio": 1.598984771573604, "no_speech_prob": 0.010155681520700455}, {"id": 58, "seek": 25000, "start": 250.36, "end": 251.0, "text": " That's fine.", "tokens": [50382, 663, 311, 2489, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 59, "seek": 25000, "start": 251.4, "end": 256.48, "text": " Is everything okay? Yeah, it's a full screen slide. Hopefully,", "tokens": [50434, 1119, 1203, 1392, 30, 865, 11, 309, 311, 257, 1577, 2568, 4137, 13, 10429, 11, 50688], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 60, "seek": 25000, "start": 256.52, "end": 261.68, "text": " it's okay. So, so, okay. So the main problem that we're looking", "tokens": [50690, 309, 311, 1392, 13, 407, 11, 370, 11, 1392, 13, 407, 264, 2135, 1154, 300, 321, 434, 1237, 50948], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 61, "seek": 25000, "start": 261.68, "end": 265.52, "text": " at here, and I'm not sure why the, the images are overlapped in", "tokens": [50948, 412, 510, 11, 293, 286, 478, 406, 988, 983, 264, 11, 264, 5267, 366, 670, 875, 3320, 294, 51140], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 62, "seek": 25000, "start": 265.52, "end": 269.4, "text": " the right way. Hopefully, the layout will get fixed. So we're", "tokens": [51140, 264, 558, 636, 13, 10429, 11, 264, 13333, 486, 483, 6806, 13, 407, 321, 434, 51334], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 63, "seek": 25000, "start": 269.4, "end": 273.92, "text": " going to next slides. But the, the, the, the, the main problem", "tokens": [51334, 516, 281, 958, 9788, 13, 583, 264, 11, 264, 11, 264, 11, 264, 11, 264, 2135, 1154, 51560], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 64, "seek": 25000, "start": 274.16, "end": 279.16, "text": " surrounding my talk is image generation. And so, for the last", "tokens": [51572, 11498, 452, 751, 307, 3256, 5125, 13, 400, 370, 11, 337, 264, 1036, 51822], "temperature": 0.0, "avg_logprob": -0.2377033069215972, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002672018250450492}, {"id": 65, "seek": 27916, "start": 279.20000000000005, "end": 281.56, "text": " few years, there's been this question, how do you make a", "tokens": [50366, 1326, 924, 11, 456, 311, 668, 341, 1168, 11, 577, 360, 291, 652, 257, 50484], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 66, "seek": 27916, "start": 281.56, "end": 286.96000000000004, "text": " state of the art program to generate realistic images? And,", "tokens": [50484, 1785, 295, 264, 1523, 1461, 281, 8460, 12465, 5267, 30, 400, 11, 50754], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 67, "seek": 27916, "start": 287.32000000000005, "end": 289.56, "text": " you know, the general process is first you want to collect a", "tokens": [50772, 291, 458, 11, 264, 2674, 1399, 307, 700, 291, 528, 281, 2500, 257, 50884], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 68, "seek": 27916, "start": 289.56, "end": 292.64000000000004, "text": " data set of real images, like these pictures of buildings on", "tokens": [50884, 1412, 992, 295, 957, 5267, 11, 411, 613, 5242, 295, 7446, 322, 51038], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 69, "seek": 27916, "start": 292.64000000000004, "end": 299.16, "text": " the right. And, and then you want to, you know, train some sort", "tokens": [51038, 264, 558, 13, 400, 11, 293, 550, 291, 528, 281, 11, 291, 458, 11, 3847, 512, 1333, 51364], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 70, "seek": 27916, "start": 299.16, "end": 302.20000000000005, "text": " of program, some sort of generator network to generate", "tokens": [51364, 295, 1461, 11, 512, 1333, 295, 19265, 3209, 281, 8460, 51516], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 71, "seek": 27916, "start": 302.76000000000005, "end": 306.04, "text": " those programs. And so, so, you know, it's been a puzzle. There's", "tokens": [51544, 729, 4268, 13, 400, 370, 11, 370, 11, 291, 458, 11, 309, 311, 668, 257, 12805, 13, 821, 311, 51708], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 72, "seek": 27916, "start": 306.04, "end": 308.92, "text": " a lot of different ways you could imagine doing this. And so", "tokens": [51708, 257, 688, 295, 819, 2098, 291, 727, 3811, 884, 341, 13, 400, 370, 51852], "temperature": 0.0, "avg_logprob": -0.13450224697589874, "compression_ratio": 1.8544061302681993, "no_speech_prob": 0.001926077646203339}, {"id": 73, "seek": 30892, "start": 309.76, "end": 312.68, "text": " people have been puzzling, how do you train such a thing? How do", "tokens": [50406, 561, 362, 668, 18741, 1688, 11, 577, 360, 291, 3847, 1270, 257, 551, 30, 1012, 360, 50552], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 74, "seek": 30892, "start": 312.68, "end": 315.24, "text": " you even supervise it? You know, what should the, what should", "tokens": [50552, 291, 754, 37971, 908, 309, 30, 509, 458, 11, 437, 820, 264, 11, 437, 820, 50680], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 75, "seek": 30892, "start": 315.24, "end": 319.56, "text": " the inputs and the outputs of the network be? And, and, and the", "tokens": [50680, 264, 15743, 293, 264, 23930, 295, 264, 3209, 312, 30, 400, 11, 293, 11, 293, 264, 50896], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 76, "seek": 30892, "start": 319.56, "end": 322.20000000000005, "text": " thing that has really been working the best in recent", "tokens": [50896, 551, 300, 575, 534, 668, 1364, 264, 1151, 294, 5162, 51028], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 77, "seek": 30892, "start": 322.20000000000005, "end": 324.64000000000004, "text": " years is, you know, in architecture, you guys have all", "tokens": [51028, 924, 307, 11, 291, 458, 11, 294, 9482, 11, 291, 1074, 362, 439, 51150], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 78, "seek": 30892, "start": 324.64000000000004, "end": 328.76, "text": " heard of called GANs, generative adversarial networks. And the", "tokens": [51150, 2198, 295, 1219, 460, 1770, 82, 11, 1337, 1166, 17641, 44745, 9590, 13, 400, 264, 51356], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 79, "seek": 30892, "start": 328.76, "end": 332.40000000000003, "text": " trick for GANs is to reduce it down to a simpler problem that", "tokens": [51356, 4282, 337, 460, 1770, 82, 307, 281, 5407, 309, 760, 281, 257, 18587, 1154, 300, 51538], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 80, "seek": 30892, "start": 332.40000000000003, "end": 336.24, "text": " we know what we're doing. And so the simpler problem that", "tokens": [51538, 321, 458, 437, 321, 434, 884, 13, 400, 370, 264, 18587, 1154, 300, 51730], "temperature": 0.0, "avg_logprob": -0.11439463200459954, "compression_ratio": 1.7851851851851852, "no_speech_prob": 0.00016343043535016477}, {"id": 81, "seek": 33624, "start": 336.24, "end": 340.16, "text": " they're recognized when designing GANs was that", "tokens": [50364, 436, 434, 9823, 562, 14685, 460, 1770, 82, 390, 300, 50560], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 82, "seek": 33624, "start": 340.44, "end": 342.88, "text": " generating images, we don't really know how to do, but", "tokens": [50574, 17746, 5267, 11, 321, 500, 380, 534, 458, 577, 281, 360, 11, 457, 50696], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 83, "seek": 33624, "start": 342.88, "end": 346.32, "text": " classifying images, gosh, that is an easy problem. We can", "tokens": [50696, 1508, 5489, 5267, 11, 6502, 11, 300, 307, 364, 1858, 1154, 13, 492, 393, 50868], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 84, "seek": 33624, "start": 346.32, "end": 351.24, "text": " classify images. And so, so what we could do is we could train a", "tokens": [50868, 33872, 5267, 13, 400, 370, 11, 370, 437, 321, 727, 360, 307, 321, 727, 3847, 257, 51114], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 85, "seek": 33624, "start": 351.24, "end": 355.96000000000004, "text": " classifier on this really easy task, which is given two sets", "tokens": [51114, 1508, 9902, 322, 341, 534, 1858, 5633, 11, 597, 307, 2212, 732, 6352, 51350], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 86, "seek": 33624, "start": 356.0, "end": 361.04, "text": " of pixels, which image is real, and which image is not a real", "tokens": [51352, 295, 18668, 11, 597, 3256, 307, 957, 11, 293, 597, 3256, 307, 406, 257, 957, 51604], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 87, "seek": 33624, "start": 361.04, "end": 365.48, "text": " photograph. And it turns out that for most arrangements of", "tokens": [51604, 8348, 13, 400, 309, 4523, 484, 300, 337, 881, 22435, 295, 51826], "temperature": 0.0, "avg_logprob": -0.09610156659726743, "compression_ratio": 1.702928870292887, "no_speech_prob": 0.001673982827924192}, {"id": 88, "seek": 36548, "start": 365.48, "end": 368.56, "text": " pixels, this is a very easy task to train a discriminator on", "tokens": [50364, 18668, 11, 341, 307, 257, 588, 1858, 5633, 281, 3847, 257, 20828, 1639, 322, 50518], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 89, "seek": 36548, "start": 368.56, "end": 371.56, "text": " it gets very good, you know, very quickly, we'll start getting", "tokens": [50518, 309, 2170, 588, 665, 11, 291, 458, 11, 588, 2661, 11, 321, 603, 722, 1242, 50668], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 90, "seek": 36548, "start": 371.56, "end": 376.52000000000004, "text": " 100% accurately on that. And so, so but the neat thing is that", "tokens": [50668, 2319, 4, 20095, 322, 300, 13, 400, 370, 11, 370, 457, 264, 10654, 551, 307, 300, 50916], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 91, "seek": 36548, "start": 376.52000000000004, "end": 378.32, "text": " once we have a discriminator that can tell the difference", "tokens": [50916, 1564, 321, 362, 257, 20828, 1639, 300, 393, 980, 264, 2649, 51006], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 92, "seek": 36548, "start": 378.32, "end": 382.36, "text": " between a fake image and a real image, then we can hook it up", "tokens": [51006, 1296, 257, 7592, 3256, 293, 257, 957, 3256, 11, 550, 321, 393, 6328, 309, 493, 51208], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 93, "seek": 36548, "start": 382.36, "end": 385.6, "text": " to our generator, and we can say, All right, we didn't know how", "tokens": [51208, 281, 527, 19265, 11, 293, 321, 393, 584, 11, 1057, 558, 11, 321, 994, 380, 458, 577, 51370], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 94, "seek": 36548, "start": 385.6, "end": 389.56, "text": " to tell you, generator, how to make a real image. But you know", "tokens": [51370, 281, 980, 291, 11, 19265, 11, 577, 281, 652, 257, 957, 3256, 13, 583, 291, 458, 51568], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 95, "seek": 36548, "start": 389.56, "end": 392.48, "text": " what this discriminator can tell you, because all you have to do", "tokens": [51568, 437, 341, 20828, 1639, 393, 980, 291, 11, 570, 439, 291, 362, 281, 360, 51714], "temperature": 0.0, "avg_logprob": -0.11278161581824808, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0011692700209096074}, {"id": 96, "seek": 39248, "start": 392.48, "end": 396.52000000000004, "text": " is generate patterns of pixels that fool the discriminator, if", "tokens": [50364, 307, 8460, 8294, 295, 18668, 300, 7979, 264, 20828, 1639, 11, 498, 50566], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 97, "seek": 39248, "start": 396.52000000000004, "end": 400.52000000000004, "text": " you can make the discriminator think it's real, then it must be", "tokens": [50566, 291, 393, 652, 264, 20828, 1639, 519, 309, 311, 957, 11, 550, 309, 1633, 312, 50766], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 98, "seek": 39248, "start": 400.8, "end": 406.96000000000004, "text": " better than random. Now, the problem is that, even though the", "tokens": [50780, 1101, 813, 4974, 13, 823, 11, 264, 1154, 307, 300, 11, 754, 1673, 264, 51088], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 99, "seek": 39248, "start": 406.96000000000004, "end": 409.92, "text": " discriminator can get very accurate at telling what's real,", "tokens": [51088, 20828, 1639, 393, 483, 588, 8559, 412, 3585, 437, 311, 957, 11, 51236], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 100, "seek": 39248, "start": 411.20000000000005, "end": 414.72, "text": " they, the generator will also be very good at learning how to", "tokens": [51300, 436, 11, 264, 19265, 486, 611, 312, 588, 665, 412, 2539, 577, 281, 51476], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 101, "seek": 39248, "start": 414.72, "end": 417.8, "text": " fool the discriminator without working very hard, it'll realize", "tokens": [51476, 7979, 264, 20828, 1639, 1553, 1364, 588, 1152, 11, 309, 603, 4325, 51630], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 102, "seek": 39248, "start": 418.0, "end": 420.96000000000004, "text": " that aha, the only thing I need to do to make the discriminator", "tokens": [51640, 300, 47340, 11, 264, 787, 551, 286, 643, 281, 360, 281, 652, 264, 20828, 1639, 51788], "temperature": 0.0, "avg_logprob": -0.14508814330494732, "compression_ratio": 1.8798283261802575, "no_speech_prob": 0.0027140334714204073}, {"id": 103, "seek": 42096, "start": 420.96, "end": 424.35999999999996, "text": " think is real is put some blue sky in there and put some texture", "tokens": [50364, 519, 307, 957, 307, 829, 512, 3344, 5443, 294, 456, 293, 829, 512, 8091, 50534], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 104, "seek": 42096, "start": 424.35999999999996, "end": 427.44, "text": " that kind of looks like, you know, building texture. And, and", "tokens": [50534, 300, 733, 295, 1542, 411, 11, 291, 458, 11, 2390, 8091, 13, 400, 11, 293, 50688], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 105, "seek": 42096, "start": 427.44, "end": 429.64, "text": " the discriminator will say, Well, that totally looks real,", "tokens": [50688, 264, 20828, 1639, 486, 584, 11, 1042, 11, 300, 3879, 1542, 957, 11, 50798], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 106, "seek": 42096, "start": 429.64, "end": 433.12, "text": " there's a sky, you know, there's, there's the right, the right", "tokens": [50798, 456, 311, 257, 5443, 11, 291, 458, 11, 456, 311, 11, 456, 311, 264, 558, 11, 264, 558, 50972], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 107, "seek": 42096, "start": 433.12, "end": 436.12, "text": " colors for buildings and some vertical lines and things. Ah,", "tokens": [50972, 4577, 337, 7446, 293, 512, 9429, 3876, 293, 721, 13, 2438, 11, 51122], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 108, "seek": 42096, "start": 436.12, "end": 438.76, "text": " that's totally real. But as a human, we look at that, we think,", "tokens": [51122, 300, 311, 3879, 957, 13, 583, 382, 257, 1952, 11, 321, 574, 412, 300, 11, 321, 519, 11, 51254], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 109, "seek": 42096, "start": 438.76, "end": 441.88, "text": " Oh, that's not a very realistic image at all. So the trick is to", "tokens": [51254, 876, 11, 300, 311, 406, 257, 588, 12465, 3256, 412, 439, 13, 407, 264, 4282, 307, 281, 51410], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 110, "seek": 42096, "start": 441.88, "end": 444.56, "text": " iterate this process to go back and forth after the generator", "tokens": [51410, 44497, 341, 1399, 281, 352, 646, 293, 5220, 934, 264, 19265, 51544], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 111, "seek": 42096, "start": 444.56, "end": 449.0, "text": " can generate sort of halfway looking real images, then have", "tokens": [51544, 393, 8460, 1333, 295, 15461, 1237, 957, 5267, 11, 550, 362, 51766], "temperature": 0.0, "avg_logprob": -0.12974435691065436, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.0006460484000854194}, {"id": 112, "seek": 44900, "start": 449.0, "end": 452.68, "text": " the discriminator say, Ah, well, that's actually fake. And", "tokens": [50364, 264, 20828, 1639, 584, 11, 2438, 11, 731, 11, 300, 311, 767, 7592, 13, 400, 50548], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 113, "seek": 44900, "start": 452.68, "end": 455.12, "text": " we're going to tell the difference between those new fakes,", "tokens": [50548, 321, 434, 516, 281, 980, 264, 2649, 1296, 729, 777, 283, 3419, 11, 50670], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 114, "seek": 44900, "start": 455.12, "end": 458.2, "text": " those better fakes, and actual real photographs, and the", "tokens": [50670, 729, 1101, 283, 3419, 11, 293, 3539, 957, 17649, 11, 293, 264, 50824], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 115, "seek": 44900, "start": 458.2, "end": 461.12, "text": " discriminator has to now work harder at getting better. And so", "tokens": [50824, 20828, 1639, 575, 281, 586, 589, 6081, 412, 1242, 1101, 13, 400, 370, 50970], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 116, "seek": 44900, "start": 461.12, "end": 465.0, "text": " if you, if you alternate these processes, then, then you end up", "tokens": [50970, 498, 291, 11, 498, 291, 18873, 613, 7555, 11, 550, 11, 550, 291, 917, 493, 51164], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 117, "seek": 44900, "start": 465.0, "end": 468.28, "text": " very conversion to very, very good generators that can generate", "tokens": [51164, 588, 14298, 281, 588, 11, 588, 665, 38662, 300, 393, 8460, 51328], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 118, "seek": 44900, "start": 468.28, "end": 475.6, "text": " very realistic images. And they, you know, the typical learning", "tokens": [51328, 588, 12465, 5267, 13, 400, 436, 11, 291, 458, 11, 264, 7476, 2539, 51694], "temperature": 0.0, "avg_logprob": -0.12145214610629612, "compression_ratio": 1.799163179916318, "no_speech_prob": 0.0006561582558788359}, {"id": 119, "seek": 47560, "start": 475.6, "end": 479.44, "text": " process is actually just to do only one step of iteration", "tokens": [50364, 1399, 307, 767, 445, 281, 360, 787, 472, 1823, 295, 24784, 50556], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 120, "seek": 47560, "start": 480.04, "end": 483.24, "text": " between the discriminator and generator and just alternate that.", "tokens": [50586, 1296, 264, 20828, 1639, 293, 19265, 293, 445, 18873, 300, 13, 50746], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 121, "seek": 47560, "start": 483.24, "end": 486.36, "text": " So by the time you're done, you've played this game, you", "tokens": [50746, 407, 538, 264, 565, 291, 434, 1096, 11, 291, 600, 3737, 341, 1216, 11, 291, 50902], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 122, "seek": 47560, "start": 486.36, "end": 488.52000000000004, "text": " know, millions and millions of times back and forth between", "tokens": [50902, 458, 11, 6803, 293, 6803, 295, 1413, 646, 293, 5220, 1296, 51010], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 123, "seek": 47560, "start": 488.52000000000004, "end": 491.20000000000005, "text": " the generator and the discriminator. But the new thing", "tokens": [51010, 264, 19265, 293, 264, 20828, 1639, 13, 583, 264, 777, 551, 51144], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 124, "seek": 47560, "start": 491.24, "end": 494.36, "text": " that's happening here is that it can generate these images that", "tokens": [51146, 300, 311, 2737, 510, 307, 300, 309, 393, 8460, 613, 5267, 300, 51302], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 125, "seek": 47560, "start": 494.36, "end": 500.8, "text": " look very realistic in the end. But let's see. So Oh, here's", "tokens": [51302, 574, 588, 12465, 294, 264, 917, 13, 583, 718, 311, 536, 13, 407, 876, 11, 510, 311, 51624], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 126, "seek": 47560, "start": 500.8, "end": 505.0, "text": " another picture. So we'll get this images out that look very", "tokens": [51624, 1071, 3036, 13, 407, 321, 603, 483, 341, 5267, 484, 300, 574, 588, 51834], "temperature": 0.0, "avg_logprob": -0.09587049083549436, "compression_ratio": 1.8461538461538463, "no_speech_prob": 0.01149892807006836}, {"id": 127, "seek": 50500, "start": 505.0, "end": 508.4, "text": " realistic in the end. And we'll get this generator, which is", "tokens": [50364, 12465, 294, 264, 917, 13, 400, 321, 603, 483, 341, 19265, 11, 597, 307, 50534], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 128, "seek": 50500, "start": 508.4, "end": 512.44, "text": " just a deterministic function that takes actually the input of", "tokens": [50534, 445, 257, 15957, 3142, 2445, 300, 2516, 767, 264, 4846, 295, 50736], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 129, "seek": 50500, "start": 512.44, "end": 516.48, "text": " the generator is actually just a random vector. So we'll take", "tokens": [50736, 264, 19265, 307, 767, 445, 257, 4974, 8062, 13, 407, 321, 603, 747, 50938], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 130, "seek": 50500, "start": 516.48, "end": 519.68, "text": " these relatively small random vectors like 512 dimensional", "tokens": [50938, 613, 7226, 1359, 4974, 18875, 411, 1025, 4762, 18795, 51098], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 131, "seek": 50500, "start": 519.68, "end": 522.48, "text": " random vector, and we'll put it into this thing. And it's been", "tokens": [51098, 4974, 8062, 11, 293, 321, 603, 829, 309, 666, 341, 551, 13, 400, 309, 311, 668, 51238], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 132, "seek": 50500, "start": 522.48, "end": 525.76, "text": " trained so that no matter what it outputs, it will look very", "tokens": [51238, 8895, 370, 300, 572, 1871, 437, 309, 23930, 11, 309, 486, 574, 588, 51402], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 133, "seek": 50500, "start": 525.76, "end": 528.72, "text": " realistic, like this example image here. Or if I change a", "tokens": [51402, 12465, 11, 411, 341, 1365, 3256, 510, 13, 1610, 498, 286, 1319, 257, 51550], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 134, "seek": 50500, "start": 528.72, "end": 531.68, "text": " vector, I'll get a different image out and it will again look", "tokens": [51550, 8062, 11, 286, 603, 483, 257, 819, 3256, 484, 293, 309, 486, 797, 574, 51698], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 135, "seek": 50500, "start": 531.68, "end": 534.44, "text": " very realistic, even if it looks completely different. And so", "tokens": [51698, 588, 12465, 11, 754, 498, 309, 1542, 2584, 819, 13, 400, 370, 51836], "temperature": 0.0, "avg_logprob": -0.10506627824571398, "compression_ratio": 1.8835616438356164, "no_speech_prob": 0.001500579877756536}, {"id": 136, "seek": 53444, "start": 534.48, "end": 537.08, "text": " it's just a deterministic function that really wants to", "tokens": [50366, 309, 311, 445, 257, 15957, 3142, 2445, 300, 534, 2738, 281, 50496], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 137, "seek": 53444, "start": 537.08, "end": 541.9200000000001, "text": " make realistic images. And, and so here's like a sample of like", "tokens": [50496, 652, 12465, 5267, 13, 400, 11, 293, 370, 510, 311, 411, 257, 6889, 295, 411, 50738], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 138, "seek": 53444, "start": 542.32, "end": 545.6400000000001, "text": " output from a generator. And you can see that after millions of", "tokens": [50758, 5598, 490, 257, 19265, 13, 400, 291, 393, 536, 300, 934, 6803, 295, 50924], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 139, "seek": 53444, "start": 545.6400000000001, "end": 549.9200000000001, "text": " these sort of generative training steps, where it's", "tokens": [50924, 613, 1333, 295, 1337, 1166, 3097, 4439, 11, 689, 309, 311, 51138], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 140, "seek": 53444, "start": 549.9200000000001, "end": 552.8000000000001, "text": " pitted against a discriminator, it actually gets to be pretty", "tokens": [51138, 280, 3944, 1970, 257, 20828, 1639, 11, 309, 767, 2170, 281, 312, 1238, 51282], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 141, "seek": 53444, "start": 552.8000000000001, "end": 556.84, "text": " good. And so this is a style game v2. It's a model that was", "tokens": [51282, 665, 13, 400, 370, 341, 307, 257, 3758, 1216, 371, 17, 13, 467, 311, 257, 2316, 300, 390, 51484], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 142, "seek": 53444, "start": 556.84, "end": 562.0400000000001, "text": " published last year. And, and it's, you know, currently the", "tokens": [51484, 6572, 1036, 1064, 13, 400, 11, 293, 309, 311, 11, 291, 458, 11, 4362, 264, 51744], "temperature": 0.0, "avg_logprob": -0.11660120316914149, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.00033005131990648806}, {"id": 143, "seek": 56204, "start": 562.04, "end": 566.24, "text": " state of the art in generating realistic images of certain", "tokens": [50364, 1785, 295, 264, 1523, 294, 17746, 12465, 5267, 295, 1629, 50574], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 144, "seek": 56204, "start": 566.8, "end": 571.0, "text": " certain types of image distributions. And, and so when", "tokens": [50602, 1629, 3467, 295, 3256, 37870, 13, 400, 11, 293, 370, 562, 50812], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 145, "seek": 56204, "start": 571.04, "end": 573.8399999999999, "text": " when you look at a collection of images like this, you might", "tokens": [50814, 562, 291, 574, 412, 257, 5765, 295, 5267, 411, 341, 11, 291, 1062, 50954], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 146, "seek": 56204, "start": 573.8399999999999, "end": 576.88, "text": " think, actually, the first time I looked at the output of some of", "tokens": [50954, 519, 11, 767, 11, 264, 700, 565, 286, 2956, 412, 264, 5598, 295, 512, 295, 51106], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 147, "seek": 56204, "start": 576.88, "end": 582.8399999999999, "text": " these state of the organs, I was confused between the training", "tokens": [51106, 613, 1785, 295, 264, 20659, 11, 286, 390, 9019, 1296, 264, 3097, 51404], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 148, "seek": 56204, "start": 582.8399999999999, "end": 586.36, "text": " set, and the generated output, this is not the training set,", "tokens": [51404, 992, 11, 293, 264, 10833, 5598, 11, 341, 307, 406, 264, 3097, 992, 11, 51580], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 149, "seek": 56204, "start": 586.36, "end": 591.28, "text": " this is actually what the generator is producing. And so, so", "tokens": [51580, 341, 307, 767, 437, 264, 19265, 307, 10501, 13, 400, 370, 11, 370, 51826], "temperature": 0.0, "avg_logprob": -0.1516804420031034, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.007687736768275499}, {"id": 150, "seek": 59128, "start": 591.28, "end": 595.6, "text": " you see all sorts of interesting effects here. And so the one of", "tokens": [50364, 291, 536, 439, 7527, 295, 1880, 5065, 510, 13, 400, 370, 264, 472, 295, 50580], "temperature": 0.0, "avg_logprob": -0.1384538628838279, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.000379896693630144}, {"id": 151, "seek": 59128, "start": 595.6, "end": 600.1999999999999, "text": " the questions to ask is, what the heck is the model doing", "tokens": [50580, 264, 1651, 281, 1029, 307, 11, 437, 264, 12872, 307, 264, 2316, 884, 50810], "temperature": 0.0, "avg_logprob": -0.1384538628838279, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.000379896693630144}, {"id": 152, "seek": 59128, "start": 600.1999999999999, "end": 603.28, "text": " inside? Can we understand the underlying algorithm? And what", "tokens": [50810, 1854, 30, 1664, 321, 1223, 264, 14217, 9284, 30, 400, 437, 50964], "temperature": 0.0, "avg_logprob": -0.1384538628838279, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.000379896693630144}, {"id": 153, "seek": 59128, "start": 603.28, "end": 606.76, "text": " the characteristics of that algorithm is like, why does this", "tokens": [50964, 264, 10891, 295, 300, 9284, 307, 411, 11, 983, 775, 341, 51138], "temperature": 0.0, "avg_logprob": -0.1384538628838279, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.000379896693630144}, {"id": 154, "seek": 59128, "start": 606.76, "end": 613.04, "text": " work? And so one of the funny things that you'll notice is", "tokens": [51138, 589, 30, 400, 370, 472, 295, 264, 4074, 721, 300, 291, 603, 3449, 307, 51452], "temperature": 0.0, "avg_logprob": -0.1384538628838279, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.000379896693630144}, {"id": 155, "seek": 59128, "start": 613.48, "end": 616.68, "text": " that some of the images have these strange artifacts, like", "tokens": [51474, 300, 512, 295, 264, 5267, 362, 613, 5861, 24617, 11, 411, 51634], "temperature": 0.0, "avg_logprob": -0.1384538628838279, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.000379896693630144}, {"id": 156, "seek": 61668, "start": 616.68, "end": 622.4399999999999, "text": " take a look at this one here. So this, this scan is pretty good.", "tokens": [50364, 747, 257, 574, 412, 341, 472, 510, 13, 407, 341, 11, 341, 11049, 307, 1238, 665, 13, 50652], "temperature": 0.0, "avg_logprob": -0.14493715519807776, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0010647313902154565}, {"id": 157, "seek": 61668, "start": 622.56, "end": 628.3599999999999, "text": " It's this generator is so good that it actually has noticed that", "tokens": [50658, 467, 311, 341, 19265, 307, 370, 665, 300, 309, 767, 575, 5694, 300, 50948], "temperature": 0.0, "avg_logprob": -0.14493715519807776, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0010647313902154565}, {"id": 158, "seek": 61668, "start": 628.3599999999999, "end": 633.7199999999999, "text": " the training distribution that is imitating has some percentage", "tokens": [50948, 264, 3097, 7316, 300, 307, 566, 16350, 575, 512, 9668, 51216], "temperature": 0.0, "avg_logprob": -0.14493715519807776, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0010647313902154565}, {"id": 159, "seek": 61668, "start": 633.7199999999999, "end": 639.04, "text": " of images that were stolen off of shutter stock. And they still", "tokens": [51216, 295, 5267, 300, 645, 15900, 766, 295, 25517, 4127, 13, 400, 436, 920, 51482], "temperature": 0.0, "avg_logprob": -0.14493715519807776, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0010647313902154565}, {"id": 160, "seek": 61668, "start": 639.04, "end": 643.5999999999999, "text": " have the watermark on them. And, and, and, and the generator", "tokens": [51482, 362, 264, 1281, 5638, 322, 552, 13, 400, 11, 293, 11, 293, 11, 293, 264, 19265, 51710], "temperature": 0.0, "avg_logprob": -0.14493715519807776, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0010647313902154565}, {"id": 161, "seek": 61668, "start": 643.5999999999999, "end": 646.66, "text": " says, well, if I want to make things look realistic, I better", "tokens": [51710, 1619, 11, 731, 11, 498, 286, 528, 281, 652, 721, 574, 12465, 11, 286, 1101, 51863], "temperature": 0.0, "avg_logprob": -0.14493715519807776, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0010647313902154565}, {"id": 162, "seek": 64666, "start": 647.14, "end": 651.5799999999999, "text": " put watermarks on some percentage of my images too. It", "tokens": [50388, 829, 1281, 37307, 322, 512, 9668, 295, 452, 5267, 886, 13, 467, 50610], "temperature": 0.0, "avg_logprob": -0.2016946692215769, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0005526843015104532}, {"id": 163, "seek": 64666, "start": 651.5799999999999, "end": 655.74, "text": " learns it's got to protect its own copyright. So, so it, it", "tokens": [50610, 27152, 309, 311, 658, 281, 2371, 1080, 1065, 17996, 13, 407, 11, 370, 309, 11, 309, 50818], "temperature": 0.0, "avg_logprob": -0.2016946692215769, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0005526843015104532}, {"id": 164, "seek": 64666, "start": 655.74, "end": 661.9, "text": " does that. And so something like 6% of the output images from", "tokens": [50818, 775, 300, 13, 400, 370, 746, 411, 1386, 4, 295, 264, 5598, 5267, 490, 51126], "temperature": 0.0, "avg_logprob": -0.2016946692215769, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0005526843015104532}, {"id": 165, "seek": 64666, "start": 662.3, "end": 665.14, "text": " state of the art style, again, will have these kind of", "tokens": [51146, 1785, 295, 264, 1523, 3758, 11, 797, 11, 486, 362, 613, 733, 295, 51288], "temperature": 0.0, "avg_logprob": -0.2016946692215769, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0005526843015104532}, {"id": 166, "seek": 64666, "start": 665.14, "end": 669.62, "text": " artifacts that show the same type of watermarks that were on", "tokens": [51288, 24617, 300, 855, 264, 912, 2010, 295, 1281, 37307, 300, 645, 322, 51512], "temperature": 0.0, "avg_logprob": -0.2016946692215769, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0005526843015104532}, {"id": 167, "seek": 64666, "start": 669.62, "end": 674.18, "text": " the training set. This is the Elson Church training set. And", "tokens": [51512, 264, 3097, 992, 13, 639, 307, 264, 2699, 3015, 7882, 3097, 992, 13, 400, 51740], "temperature": 0.0, "avg_logprob": -0.2016946692215769, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.0005526843015104532}, {"id": 168, "seek": 67418, "start": 674.2199999999999, "end": 677.78, "text": " so, so yeah, this kind of watermarks like this. But the", "tokens": [50366, 370, 11, 370, 1338, 11, 341, 733, 295, 1281, 37307, 411, 341, 13, 583, 264, 50544], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 169, "seek": 67418, "start": 677.78, "end": 682.26, "text": " reason I thought this was cool was that it, it's this very", "tokens": [50544, 1778, 286, 1194, 341, 390, 1627, 390, 300, 309, 11, 309, 311, 341, 588, 50768], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 170, "seek": 67418, "start": 682.26, "end": 685.7399999999999, "text": " clear thing that the image generator does, but it doesn't", "tokens": [50768, 1850, 551, 300, 264, 3256, 19265, 775, 11, 457, 309, 1177, 380, 50942], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 171, "seek": 67418, "start": 685.7399999999999, "end": 689.5799999999999, "text": " always do it. Like most of the time when it generates images,", "tokens": [50942, 1009, 360, 309, 13, 1743, 881, 295, 264, 565, 562, 309, 23815, 5267, 11, 51134], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 172, "seek": 67418, "start": 689.8599999999999, "end": 693.26, "text": " it generates images without a watermark, but sometimes you get", "tokens": [51148, 309, 23815, 5267, 1553, 257, 1281, 5638, 11, 457, 2171, 291, 483, 51318], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 173, "seek": 67418, "start": 693.26, "end": 697.9, "text": " these watermarks. And so, and so it's, it's almost like this", "tokens": [51318, 613, 1281, 37307, 13, 400, 370, 11, 293, 370, 309, 311, 11, 309, 311, 1920, 411, 341, 51550], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 174, "seek": 67418, "start": 697.9, "end": 704.02, "text": " binary decision. It's like, there must be a switch that the", "tokens": [51550, 17434, 3537, 13, 467, 311, 411, 11, 456, 1633, 312, 257, 3679, 300, 264, 51856], "temperature": 0.0, "avg_logprob": -0.16535922937225878, "compression_ratio": 1.793991416309013, "no_speech_prob": 0.00026115565560758114}, {"id": 175, "seek": 70402, "start": 704.02, "end": 707.9399999999999, "text": " network has at some point where it decides whether it's going to", "tokens": [50364, 3209, 575, 412, 512, 935, 689, 309, 14898, 1968, 309, 311, 516, 281, 50560], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 176, "seek": 70402, "start": 707.9399999999999, "end": 711.3, "text": " put a watermark on an image or not. And so we can kind of ask", "tokens": [50560, 829, 257, 1281, 5638, 322, 364, 3256, 420, 406, 13, 400, 370, 321, 393, 733, 295, 1029, 50728], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 177, "seek": 70402, "start": 711.3, "end": 713.9, "text": " the question, where's that switch? Is there a neuron", "tokens": [50728, 264, 1168, 11, 689, 311, 300, 3679, 30, 1119, 456, 257, 34090, 50858], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 178, "seek": 70402, "start": 713.9, "end": 718.42, "text": " somewhere in this network, which is, which is controlling the", "tokens": [50858, 4079, 294, 341, 3209, 11, 597, 307, 11, 597, 307, 14905, 264, 51084], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 179, "seek": 70402, "start": 718.42, "end": 722.6999999999999, "text": " watermarkness. And so, so I went on a hunt for this, this,", "tokens": [51084, 1281, 5638, 1287, 13, 400, 370, 11, 370, 286, 1437, 322, 257, 12454, 337, 341, 11, 341, 11, 51298], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 180, "seek": 70402, "start": 722.6999999999999, "end": 725.14, "text": " this particular network has about 30 million parameters,", "tokens": [51298, 341, 1729, 3209, 575, 466, 2217, 2459, 9834, 11, 51420], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 181, "seek": 70402, "start": 725.14, "end": 729.26, "text": " which sounds like a lot, but it's just a deterministic computer", "tokens": [51420, 597, 3263, 411, 257, 688, 11, 457, 309, 311, 445, 257, 15957, 3142, 3820, 51626], "temperature": 0.0, "avg_logprob": -0.12395486745748434, "compression_ratio": 1.6907630522088353, "no_speech_prob": 0.0006261821836233139}, {"id": 182, "seek": 72926, "start": 729.26, "end": 734.3, "text": " program in the end. And, and it's not that hard to go hunting", "tokens": [50364, 1461, 294, 264, 917, 13, 400, 11, 293, 309, 311, 406, 300, 1152, 281, 352, 12599, 50616], "temperature": 0.0, "avg_logprob": -0.13266258047084617, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.002844388596713543}, {"id": 183, "seek": 72926, "start": 734.34, "end": 737.78, "text": " for things like this, you just, you can make an algorithm that", "tokens": [50618, 337, 721, 411, 341, 11, 291, 445, 11, 291, 393, 652, 364, 9284, 300, 50790], "temperature": 0.0, "avg_logprob": -0.13266258047084617, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.002844388596713543}, {"id": 184, "seek": 72926, "start": 738.38, "end": 741.02, "text": " has a heuristic that determines whether it's a watermark or not", "tokens": [50820, 575, 257, 415, 374, 3142, 300, 24799, 1968, 309, 311, 257, 1281, 5638, 420, 406, 50952], "temperature": 0.0, "avg_logprob": -0.13266258047084617, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.002844388596713543}, {"id": 185, "seek": 72926, "start": 741.02, "end": 745.34, "text": " and just go hunting for, for things that correlate with that.", "tokens": [50952, 293, 445, 352, 12599, 337, 11, 337, 721, 300, 48742, 365, 300, 13, 51168], "temperature": 0.0, "avg_logprob": -0.13266258047084617, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.002844388596713543}, {"id": 186, "seek": 72926, "start": 745.9, "end": 752.06, "text": " And so I'll show you what I found. So at layer five, I found", "tokens": [51196, 400, 370, 286, 603, 855, 291, 437, 286, 1352, 13, 407, 412, 4583, 1732, 11, 286, 1352, 51504], "temperature": 0.0, "avg_logprob": -0.13266258047084617, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.002844388596713543}, {"id": 187, "seek": 72926, "start": 752.06, "end": 757.14, "text": " this very interesting neuron that did correlate with watermarks", "tokens": [51504, 341, 588, 1880, 34090, 300, 630, 48742, 365, 1281, 37307, 51758], "temperature": 0.0, "avg_logprob": -0.13266258047084617, "compression_ratio": 1.7523364485981308, "no_speech_prob": 0.002844388596713543}, {"id": 188, "seek": 75714, "start": 757.14, "end": 762.18, "text": " a lot. It was activating whenever images look like this in", "tokens": [50364, 257, 688, 13, 467, 390, 42481, 5699, 5267, 574, 411, 341, 294, 50616], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 189, "seek": 75714, "start": 762.18, "end": 766.34, "text": " the end. And, and not only that, but because it's at layer five,", "tokens": [50616, 264, 917, 13, 400, 11, 293, 406, 787, 300, 11, 457, 570, 309, 311, 412, 4583, 1732, 11, 50824], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 190, "seek": 75714, "start": 766.98, "end": 771.34, "text": " it has a has a location for where the image activates. And I'll", "tokens": [50856, 309, 575, 257, 575, 257, 4914, 337, 689, 264, 3256, 43869, 13, 400, 286, 603, 51074], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 191, "seek": 75714, "start": 771.34, "end": 775.34, "text": " show you where, where it's activating. So, so this neuron", "tokens": [51074, 855, 291, 689, 11, 689, 309, 311, 42481, 13, 407, 11, 370, 341, 34090, 51274], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 192, "seek": 75714, "start": 775.34, "end": 778.22, "text": " is activating, you know, at these middle parts of images,", "tokens": [51274, 307, 42481, 11, 291, 458, 11, 412, 613, 2808, 3166, 295, 5267, 11, 51418], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 193, "seek": 75714, "start": 778.22, "end": 780.8199999999999, "text": " whenever the image is showing a watermark. And there are other", "tokens": [51418, 5699, 264, 3256, 307, 4099, 257, 1281, 5638, 13, 400, 456, 366, 661, 51548], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 194, "seek": 75714, "start": 780.8199999999999, "end": 783.54, "text": " neurons that have similar behavior, like so for example,", "tokens": [51548, 22027, 300, 362, 2531, 5223, 11, 411, 370, 337, 1365, 11, 51684], "temperature": 0.0, "avg_logprob": -0.14372352191380092, "compression_ratio": 1.7479338842975207, "no_speech_prob": 0.0020183490123599768}, {"id": 195, "seek": 78354, "start": 783.54, "end": 788.9, "text": " there's this neuron 234 at the same layer. And it activates in", "tokens": [50364, 456, 311, 341, 34090, 6673, 19, 412, 264, 912, 4583, 13, 400, 309, 43869, 294, 50632], "temperature": 0.0, "avg_logprob": -0.13991325378417968, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0024715312756597996}, {"id": 196, "seek": 78354, "start": 788.9, "end": 791.5799999999999, "text": " regions like this, both in the middle watermark and the bottom", "tokens": [50632, 10682, 411, 341, 11, 1293, 294, 264, 2808, 1281, 5638, 293, 264, 2767, 50766], "temperature": 0.0, "avg_logprob": -0.13991325378417968, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0024715312756597996}, {"id": 197, "seek": 78354, "start": 792.02, "end": 796.8199999999999, "text": " bar that shows up. And there's about, if you hunt through the", "tokens": [50788, 2159, 300, 3110, 493, 13, 400, 456, 311, 466, 11, 498, 291, 12454, 807, 264, 51028], "temperature": 0.0, "avg_logprob": -0.13991325378417968, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0024715312756597996}, {"id": 198, "seek": 78354, "start": 796.8199999999999, "end": 801.62, "text": " neural network, you find about 30 neurons that are similar and", "tokens": [51028, 18161, 3209, 11, 291, 915, 466, 2217, 22027, 300, 366, 2531, 293, 51268], "temperature": 0.0, "avg_logprob": -0.13991325378417968, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0024715312756597996}, {"id": 199, "seek": 78354, "start": 801.66, "end": 808.2199999999999, "text": " behave like this. And so that's, that's pretty cool. So then the", "tokens": [51270, 15158, 411, 341, 13, 400, 370, 300, 311, 11, 300, 311, 1238, 1627, 13, 407, 550, 264, 51598], "temperature": 0.0, "avg_logprob": -0.13991325378417968, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0024715312756597996}, {"id": 200, "seek": 78354, "start": 808.2199999999999, "end": 811.78, "text": " question is, well, do these things really act like a switch?", "tokens": [51598, 1168, 307, 11, 731, 11, 360, 613, 721, 534, 605, 411, 257, 3679, 30, 51776], "temperature": 0.0, "avg_logprob": -0.13991325378417968, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0024715312756597996}, {"id": 201, "seek": 81178, "start": 811.8199999999999, "end": 815.26, "text": " What if we've removed these neurons from the network? What if", "tokens": [50366, 708, 498, 321, 600, 7261, 613, 22027, 490, 264, 3209, 30, 708, 498, 50538], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 202, "seek": 81178, "start": 815.26, "end": 819.06, "text": " we force them all off? What if we turn, what if we force these", "tokens": [50538, 321, 3464, 552, 439, 766, 30, 708, 498, 321, 1261, 11, 437, 498, 321, 3464, 613, 50728], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 203, "seek": 81178, "start": 819.06, "end": 823.22, "text": " neurons to be off all the time? That will happen. So normally,", "tokens": [50728, 22027, 281, 312, 766, 439, 264, 565, 30, 663, 486, 1051, 13, 407, 5646, 11, 50936], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 204, "seek": 81178, "start": 823.22, "end": 827.42, "text": " we think of these neural networks as completely opaque", "tokens": [50936, 321, 519, 295, 613, 18161, 9590, 382, 2584, 42687, 51146], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 205, "seek": 81178, "start": 827.42, "end": 831.98, "text": " systems. We train them end to end, they're just, you know,", "tokens": [51146, 3652, 13, 492, 3847, 552, 917, 281, 917, 11, 436, 434, 445, 11, 291, 458, 11, 51374], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 206, "seek": 81178, "start": 832.06, "end": 835.42, "text": " these big black box functions. And we normally think of the", "tokens": [51378, 613, 955, 2211, 2424, 6828, 13, 400, 321, 5646, 519, 295, 264, 51546], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 207, "seek": 81178, "start": 835.42, "end": 838.78, "text": " functions as computing things where everything depends on", "tokens": [51546, 6828, 382, 15866, 721, 689, 1203, 5946, 322, 51714], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 208, "seek": 81178, "start": 838.78, "end": 840.8199999999999, "text": " everything. And so if you randomly rip through the", "tokens": [51714, 1203, 13, 400, 370, 498, 291, 16979, 12782, 807, 264, 51816], "temperature": 0.0, "avg_logprob": -0.1111308611356295, "compression_ratio": 1.821705426356589, "no_speech_prob": 0.0011876072967424989}, {"id": 209, "seek": 84082, "start": 840.82, "end": 845.1800000000001, "text": " function and remove some of its operations, then maybe you", "tokens": [50364, 2445, 293, 4159, 512, 295, 1080, 7705, 11, 550, 1310, 291, 50582], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 210, "seek": 84082, "start": 845.1800000000001, "end": 848.98, "text": " expect to get total nonsense out just garbage or noise. But we", "tokens": [50582, 2066, 281, 483, 3217, 14925, 484, 445, 14150, 420, 5658, 13, 583, 321, 50772], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 211, "seek": 84082, "start": 848.98, "end": 851.58, "text": " found these particular neurons that really correlate to this", "tokens": [50772, 1352, 613, 1729, 22027, 300, 534, 48742, 281, 341, 50902], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 212, "seek": 84082, "start": 851.58, "end": 854.1, "text": " thing. So let's see what happens when we turn them off. Do we", "tokens": [50902, 551, 13, 407, 718, 311, 536, 437, 2314, 562, 321, 1261, 552, 766, 13, 1144, 321, 51028], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 213, "seek": 84082, "start": 854.1, "end": 858.1800000000001, "text": " get anything intelligible at all? So this is what the network", "tokens": [51028, 483, 1340, 5613, 964, 412, 439, 30, 407, 341, 307, 437, 264, 3209, 51232], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 214, "seek": 84082, "start": 858.1800000000001, "end": 861.7800000000001, "text": " generated before these are the watermark images I showed you", "tokens": [51232, 10833, 949, 613, 366, 264, 1281, 5638, 5267, 286, 4712, 291, 51412], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 215, "seek": 84082, "start": 861.7800000000001, "end": 865.1400000000001, "text": " before. And I'll show you what happens if I turn off these 30", "tokens": [51412, 949, 13, 400, 286, 603, 855, 291, 437, 2314, 498, 286, 1261, 766, 613, 2217, 51580], "temperature": 0.0, "avg_logprob": -0.11899876594543457, "compression_ratio": 1.625, "no_speech_prob": 0.0010481426725164056}, {"id": 216, "seek": 86514, "start": 865.6999999999999, "end": 871.06, "text": " watermark neurons. So I'm going to give the network the same", "tokens": [50392, 1281, 5638, 22027, 13, 407, 286, 478, 516, 281, 976, 264, 3209, 264, 912, 50660], "temperature": 0.0, "avg_logprob": -0.1658210643502169, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.001926283584907651}, {"id": 217, "seek": 86514, "start": 871.06, "end": 875.02, "text": " input. But turn off these neurons during its computation,", "tokens": [50660, 4846, 13, 583, 1261, 766, 613, 22027, 1830, 1080, 24903, 11, 50858], "temperature": 0.0, "avg_logprob": -0.1658210643502169, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.001926283584907651}, {"id": 218, "seek": 86514, "start": 875.02, "end": 877.06, "text": " and you can see what the output looks like. So you can see", "tokens": [50858, 293, 291, 393, 536, 437, 264, 5598, 1542, 411, 13, 407, 291, 393, 536, 50960], "temperature": 0.0, "avg_logprob": -0.1658210643502169, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.001926283584907651}, {"id": 219, "seek": 86514, "start": 877.5, "end": 881.02, "text": " before chain, you know, forcing these neurons off and after", "tokens": [50982, 949, 5021, 11, 291, 458, 11, 19030, 613, 22027, 766, 293, 934, 51158], "temperature": 0.0, "avg_logprob": -0.1658210643502169, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.001926283584907651}, {"id": 220, "seek": 86514, "start": 881.02, "end": 885.66, "text": " forcing those neurons off. The images are still very", "tokens": [51158, 19030, 729, 22027, 766, 13, 440, 5267, 366, 920, 588, 51390], "temperature": 0.0, "avg_logprob": -0.1658210643502169, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.001926283584907651}, {"id": 221, "seek": 86514, "start": 885.78, "end": 890.34, "text": " intelligible, they look realistic still. But now the", "tokens": [51396, 5613, 964, 11, 436, 574, 12465, 920, 13, 583, 586, 264, 51624], "temperature": 0.0, "avg_logprob": -0.1658210643502169, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.001926283584907651}, {"id": 222, "seek": 89034, "start": 890.38, "end": 894.62, "text": " watermarks are gone. So I thought I was when I when I saw", "tokens": [50366, 1281, 37307, 366, 2780, 13, 407, 286, 1194, 286, 390, 562, 286, 562, 286, 1866, 50578], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 223, "seek": 89034, "start": 894.62, "end": 898.1, "text": " this, I was pretty excited, because it's like, Oh, there are", "tokens": [50578, 341, 11, 286, 390, 1238, 2919, 11, 570, 309, 311, 411, 11, 876, 11, 456, 366, 50752], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 224, "seek": 89034, "start": 898.1, "end": 900.98, "text": " switches inside the networks. And these networks are doing all", "tokens": [50752, 19458, 1854, 264, 9590, 13, 400, 613, 9590, 366, 884, 439, 50896], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 225, "seek": 89034, "start": 900.98, "end": 903.94, "text": " sorts of amazing things, not just like showing watermarks. You", "tokens": [50896, 7527, 295, 2243, 721, 11, 406, 445, 411, 4099, 1281, 37307, 13, 509, 51044], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 226, "seek": 89034, "start": 903.94, "end": 906.38, "text": " know, so when I first found this, it was on Progressive GAN,", "tokens": [51044, 458, 11, 370, 562, 286, 700, 1352, 341, 11, 309, 390, 322, 32587, 488, 460, 1770, 11, 51166], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 227, "seek": 89034, "start": 906.38, "end": 909.5, "text": " which is a year earlier than a couple years earlier, the images", "tokens": [51166, 597, 307, 257, 1064, 3071, 813, 257, 1916, 924, 3071, 11, 264, 5267, 51322], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 228, "seek": 89034, "start": 909.5, "end": 912.98, "text": " didn't look quite as good. But but still in Progressive GAN,", "tokens": [51322, 994, 380, 574, 1596, 382, 665, 13, 583, 457, 920, 294, 32587, 488, 460, 1770, 11, 51496], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 229, "seek": 89034, "start": 912.98, "end": 917.46, "text": " they do all sorts of amazing things, like they will arrange a", "tokens": [51496, 436, 360, 439, 7527, 295, 2243, 721, 11, 411, 436, 486, 9424, 257, 51720], "temperature": 0.0, "avg_logprob": -0.13719453233661075, "compression_ratio": 1.7571428571428571, "no_speech_prob": 0.0050583635456860065}, {"id": 230, "seek": 91746, "start": 917.46, "end": 921.7, "text": " scene with a river and trees and grass and, you know, building", "tokens": [50364, 4145, 365, 257, 6810, 293, 5852, 293, 8054, 293, 11, 291, 458, 11, 2390, 50576], "temperature": 0.0, "avg_logprob": -0.14736291885375977, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.006900669541209936}, {"id": 231, "seek": 91746, "start": 921.7, "end": 925.14, "text": " architectures with all sorts of different features. And you can", "tokens": [50576, 6331, 1303, 365, 439, 7527, 295, 819, 4122, 13, 400, 291, 393, 50748], "temperature": 0.0, "avg_logprob": -0.14736291885375977, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.006900669541209936}, {"id": 232, "seek": 91746, "start": 925.14, "end": 928.46, "text": " ask, you know, is there a switch to turn on and off clouds in", "tokens": [50748, 1029, 11, 291, 458, 11, 307, 456, 257, 3679, 281, 1261, 322, 293, 766, 12193, 294, 50914], "temperature": 0.0, "avg_logprob": -0.14736291885375977, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.006900669541209936}, {"id": 233, "seek": 91746, "start": 928.46, "end": 932.5400000000001, "text": " the skies or switch to turn on and off trees or windows and", "tokens": [50914, 264, 25861, 420, 3679, 281, 1261, 322, 293, 766, 5852, 420, 9309, 293, 51118], "temperature": 0.0, "avg_logprob": -0.14736291885375977, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.006900669541209936}, {"id": 234, "seek": 91746, "start": 932.5400000000001, "end": 940.5, "text": " buildings? And, and so I went hunting for that. And, and, and", "tokens": [51118, 7446, 30, 400, 11, 293, 370, 286, 1437, 12599, 337, 300, 13, 400, 11, 293, 11, 293, 51516], "temperature": 0.0, "avg_logprob": -0.14736291885375977, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.006900669541209936}, {"id": 235, "seek": 91746, "start": 940.5, "end": 944.22, "text": " the way I went hunting is I tested every neuron one at a time", "tokens": [51516, 264, 636, 286, 1437, 12599, 307, 286, 8246, 633, 34090, 472, 412, 257, 565, 51702], "temperature": 0.0, "avg_logprob": -0.14736291885375977, "compression_ratio": 1.7971014492753623, "no_speech_prob": 0.006900669541209936}, {"id": 236, "seek": 94422, "start": 944.22, "end": 946.78, "text": " I inverted the test. So basically, I look at each neuron,", "tokens": [50364, 286, 38969, 264, 1500, 13, 407, 1936, 11, 286, 574, 412, 1184, 34090, 11, 50492], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 237, "seek": 94422, "start": 947.14, "end": 951.02, "text": " and I say, Where is it activating? And, and I asked a", "tokens": [50510, 293, 286, 584, 11, 2305, 307, 309, 42481, 30, 400, 11, 293, 286, 2351, 257, 50704], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 238, "seek": 94422, "start": 951.02, "end": 955.4200000000001, "text": " question, is it activating an interesting part of different", "tokens": [50704, 1168, 11, 307, 309, 42481, 364, 1880, 644, 295, 819, 50924], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 239, "seek": 94422, "start": 955.4200000000001, "end": 959.02, "text": " images? So for example, if I took this one neuron here, and I", "tokens": [50924, 5267, 30, 407, 337, 1365, 11, 498, 286, 1890, 341, 472, 34090, 510, 11, 293, 286, 51104], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 240, "seek": 94422, "start": 959.02, "end": 962.1, "text": " see where it's activating when it's generating this image, you", "tokens": [51104, 536, 689, 309, 311, 42481, 562, 309, 311, 17746, 341, 3256, 11, 291, 51258], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 241, "seek": 94422, "start": 962.1, "end": 966.34, "text": " can see it's very hot on the right and on the left, but not", "tokens": [51258, 393, 536, 309, 311, 588, 2368, 322, 264, 558, 293, 322, 264, 1411, 11, 457, 406, 51470], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 242, "seek": 94422, "start": 966.34, "end": 971.58, "text": " much up in the sky. And on this very same neuron, when we", "tokens": [51470, 709, 493, 294, 264, 5443, 13, 400, 322, 341, 588, 912, 34090, 11, 562, 321, 51732], "temperature": 0.0, "avg_logprob": -0.11595477228579314, "compression_ratio": 1.7468354430379747, "no_speech_prob": 0.008310189470648766}, {"id": 243, "seek": 97158, "start": 971.58, "end": 976.0600000000001, "text": " generate a different image with a different input, this very same", "tokens": [50364, 8460, 257, 819, 3256, 365, 257, 819, 4846, 11, 341, 588, 912, 50588], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 244, "seek": 97158, "start": 976.0600000000001, "end": 979.14, "text": " neuron is not activating very much anywhere in this this image.", "tokens": [50588, 34090, 307, 406, 42481, 588, 709, 4992, 294, 341, 341, 3256, 13, 50742], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 245, "seek": 97158, "start": 979.98, "end": 983.46, "text": " But if we generate another image, then it will activate in a", "tokens": [50784, 583, 498, 321, 8460, 1071, 3256, 11, 550, 309, 486, 13615, 294, 257, 50958], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 246, "seek": 97158, "start": 983.46, "end": 988.14, "text": " specific area here, mostly on the lower left part of this image.", "tokens": [50958, 2685, 1859, 510, 11, 5240, 322, 264, 3126, 1411, 644, 295, 341, 3256, 13, 51192], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 247, "seek": 97158, "start": 988.14, "end": 990.5, "text": " And you can see what's on the lower left. There's a, there's a", "tokens": [51192, 400, 291, 393, 536, 437, 311, 322, 264, 3126, 1411, 13, 821, 311, 257, 11, 456, 311, 257, 51310], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 248, "seek": 97158, "start": 990.5, "end": 994.34, "text": " tree there. And so it kind of gives you the hypothesis that", "tokens": [51310, 4230, 456, 13, 400, 370, 309, 733, 295, 2709, 291, 264, 17291, 300, 51502], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 249, "seek": 97158, "start": 994.34, "end": 997.7, "text": " maybe this neuron is correlated with trees somehow. So", "tokens": [51502, 1310, 341, 34090, 307, 38574, 365, 5852, 6063, 13, 407, 51670], "temperature": 0.0, "avg_logprob": -0.10357598905210141, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0026307704392820597}, {"id": 250, "seek": 99770, "start": 997.7, "end": 1000.98, "text": " obviously, we can, we can do this, we can collect this", "tokens": [50364, 2745, 11, 321, 393, 11, 321, 393, 360, 341, 11, 321, 393, 2500, 341, 50528], "temperature": 0.0, "avg_logprob": -0.13554387451500022, "compression_ratio": 1.83, "no_speech_prob": 0.0014545313315466046}, {"id": 251, "seek": 99770, "start": 1001.22, "end": 1005.86, "text": " information over thousands of examples of generated images by", "tokens": [50540, 1589, 670, 5383, 295, 5110, 295, 10833, 5267, 538, 50772], "temperature": 0.0, "avg_logprob": -0.13554387451500022, "compression_ratio": 1.83, "no_speech_prob": 0.0014545313315466046}, {"id": 252, "seek": 99770, "start": 1005.86, "end": 1010.6600000000001, "text": " looking at where the neuron is activating, we can ask what what", "tokens": [50772, 1237, 412, 689, 264, 34090, 307, 42481, 11, 321, 393, 1029, 437, 437, 51012], "temperature": 0.0, "avg_logprob": -0.13554387451500022, "compression_ratio": 1.83, "no_speech_prob": 0.0014545313315466046}, {"id": 253, "seek": 99770, "start": 1010.6600000000001, "end": 1014.3000000000001, "text": " kind of thing is in the image, what kind of objects, what are", "tokens": [51012, 733, 295, 551, 307, 294, 264, 3256, 11, 437, 733, 295, 6565, 11, 437, 366, 51194], "temperature": 0.0, "avg_logprob": -0.13554387451500022, "compression_ratio": 1.83, "no_speech_prob": 0.0014545313315466046}, {"id": 254, "seek": 99770, "start": 1014.3000000000001, "end": 1018.1800000000001, "text": " the semantics of the image in the location that the the neurons", "tokens": [51194, 264, 4361, 45298, 295, 264, 3256, 294, 264, 4914, 300, 264, 264, 22027, 51388], "temperature": 0.0, "avg_logprob": -0.13554387451500022, "compression_ratio": 1.83, "no_speech_prob": 0.0014545313315466046}, {"id": 255, "seek": 99770, "start": 1018.1800000000001, "end": 1023.74, "text": " are in. And we can just repeat that test process, you know,", "tokens": [51388, 366, 294, 13, 400, 321, 393, 445, 7149, 300, 1500, 1399, 11, 291, 458, 11, 51666], "temperature": 0.0, "avg_logprob": -0.13554387451500022, "compression_ratio": 1.83, "no_speech_prob": 0.0014545313315466046}, {"id": 256, "seek": 102374, "start": 1023.78, "end": 1028.34, "text": " thousands of times to see if the neuron is agreeing with any", "tokens": [50366, 5383, 295, 1413, 281, 536, 498, 264, 34090, 307, 36900, 365, 604, 50594], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 257, "seek": 102374, "start": 1028.34, "end": 1032.7, "text": " particular kind of semantics that are in the images. So if, if", "tokens": [50594, 1729, 733, 295, 4361, 45298, 300, 366, 294, 264, 5267, 13, 407, 498, 11, 498, 50812], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 258, "seek": 102374, "start": 1032.7, "end": 1035.74, "text": " the, if the neurons are showing up where the trees are all the", "tokens": [50812, 264, 11, 498, 264, 22027, 366, 4099, 493, 689, 264, 5852, 366, 439, 264, 50964], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 259, "seek": 102374, "start": 1035.74, "end": 1039.78, "text": " time, we can just count and see if if that's if that's true in", "tokens": [50964, 565, 11, 321, 393, 445, 1207, 293, 536, 498, 498, 300, 311, 498, 300, 311, 2074, 294, 51166], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 260, "seek": 102374, "start": 1039.78, "end": 1043.82, "text": " general. And we can also look for correlations with other", "tokens": [51166, 2674, 13, 400, 321, 393, 611, 574, 337, 13983, 763, 365, 661, 51368], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 261, "seek": 102374, "start": 1043.82, "end": 1047.58, "text": " things. So what I did is I, I searched for correlations with", "tokens": [51368, 721, 13, 407, 437, 286, 630, 307, 286, 11, 286, 22961, 337, 13983, 763, 365, 51556], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 262, "seek": 102374, "start": 1047.58, "end": 1050.34, "text": " thousands of different, you know, hundreds of different,", "tokens": [51556, 5383, 295, 819, 11, 291, 458, 11, 6779, 295, 819, 11, 51694], "temperature": 0.0, "avg_logprob": -0.09710123709269933, "compression_ratio": 1.8162393162393162, "no_speech_prob": 0.005379331298172474}, {"id": 263, "seek": 105034, "start": 1051.1399999999999, "end": 1054.34, "text": " different types of semantics and object classes, different parts", "tokens": [50404, 819, 3467, 295, 4361, 45298, 293, 2657, 5359, 11, 819, 3166, 50564], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 264, "seek": 105034, "start": 1054.34, "end": 1057.6599999999999, "text": " of buildings or, or objects or other things that can show up", "tokens": [50564, 295, 7446, 420, 11, 420, 6565, 420, 661, 721, 300, 393, 855, 493, 50730], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 265, "seek": 105034, "start": 1057.6599999999999, "end": 1061.1, "text": " in a scene. And so what do we find? Well, we do find, you", "tokens": [50730, 294, 257, 4145, 13, 400, 370, 437, 360, 321, 915, 30, 1042, 11, 321, 360, 915, 11, 291, 50902], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 266, "seek": 105034, "start": 1061.1, "end": 1063.26, "text": " know, there's a neuron that correlates with trees, just like", "tokens": [50902, 458, 11, 456, 311, 257, 34090, 300, 13983, 1024, 365, 5852, 11, 445, 411, 51010], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 267, "seek": 105034, "start": 1063.26, "end": 1066.3, "text": " the one I was showing you. There's actually a few that are", "tokens": [51010, 264, 472, 286, 390, 4099, 291, 13, 821, 311, 767, 257, 1326, 300, 366, 51162], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 268, "seek": 105034, "start": 1066.3, "end": 1069.3799999999999, "text": " like that. And there's also neurons that correlate with", "tokens": [51162, 411, 300, 13, 400, 456, 311, 611, 22027, 300, 48742, 365, 51316], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 269, "seek": 105034, "start": 1069.3799999999999, "end": 1073.54, "text": " other things like domes, or, or other building parts like", "tokens": [51316, 661, 721, 411, 3285, 279, 11, 420, 11, 420, 661, 2390, 3166, 411, 51524], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 270, "seek": 105034, "start": 1073.54, "end": 1077.98, "text": " windows and doors. And, and if you change the model to look at", "tokens": [51524, 9309, 293, 8077, 13, 400, 11, 293, 498, 291, 1319, 264, 2316, 281, 574, 412, 51746], "temperature": 0.0, "avg_logprob": -0.09402527396134504, "compression_ratio": 1.8250950570342206, "no_speech_prob": 0.0015483066672459245}, {"id": 271, "seek": 107798, "start": 1077.98, "end": 1081.22, "text": " other things, then you can find neurons that correlate with", "tokens": [50364, 661, 721, 11, 550, 291, 393, 915, 22027, 300, 48742, 365, 50526], "temperature": 0.0, "avg_logprob": -0.13997423021416916, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.000910828122869134}, {"id": 272, "seek": 107798, "start": 1081.22, "end": 1086.78, "text": " things like windows, or chairs, or other things that they show", "tokens": [50526, 721, 411, 9309, 11, 420, 18299, 11, 420, 661, 721, 300, 436, 855, 50804], "temperature": 0.0, "avg_logprob": -0.13997423021416916, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.000910828122869134}, {"id": 273, "seek": 107798, "start": 1086.78, "end": 1090.42, "text": " up in, in the scene. And so this is actually pretty neat,", "tokens": [50804, 493, 294, 11, 294, 264, 4145, 13, 400, 370, 341, 307, 767, 1238, 10654, 11, 50986], "temperature": 0.0, "avg_logprob": -0.13997423021416916, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.000910828122869134}, {"id": 274, "seek": 107798, "start": 1090.42, "end": 1097.26, "text": " because this model was trained unsupervised by any labels. All", "tokens": [50986, 570, 341, 2316, 390, 8895, 2693, 12879, 24420, 538, 604, 16949, 13, 1057, 51328], "temperature": 0.0, "avg_logprob": -0.13997423021416916, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.000910828122869134}, {"id": 275, "seek": 107798, "start": 1097.26, "end": 1102.3, "text": " we did is we told it, generate realistic looking scenes,", "tokens": [51328, 321, 630, 307, 321, 1907, 309, 11, 8460, 12465, 1237, 8026, 11, 51580], "temperature": 0.0, "avg_logprob": -0.13997423021416916, "compression_ratio": 1.5873015873015872, "no_speech_prob": 0.000910828122869134}, {"id": 276, "seek": 110230, "start": 1102.6599999999999, "end": 1108.7, "text": " realistic looking photos. And, and, and we did not train it", "tokens": [50382, 12465, 1237, 5787, 13, 400, 11, 293, 11, 293, 321, 630, 406, 3847, 309, 50684], "temperature": 0.0, "avg_logprob": -0.0997186271093225, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.005728333257138729}, {"id": 277, "seek": 110230, "start": 1108.7, "end": 1113.46, "text": " with any labels, we didn't tell it that these are photos of", "tokens": [50684, 365, 604, 16949, 11, 321, 994, 380, 980, 309, 300, 613, 366, 5787, 295, 50922], "temperature": 0.0, "avg_logprob": -0.0997186271093225, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.005728333257138729}, {"id": 278, "seek": 110230, "start": 1115.3799999999999, "end": 1119.1, "text": " scenes that have big windows, and these are photos of scenes", "tokens": [51018, 8026, 300, 362, 955, 9309, 11, 293, 613, 366, 5787, 295, 8026, 51204], "temperature": 0.0, "avg_logprob": -0.0997186271093225, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.005728333257138729}, {"id": 279, "seek": 110230, "start": 1119.1, "end": 1121.98, "text": " that have little windows or anything like that. Or, or, or", "tokens": [51204, 300, 362, 707, 9309, 420, 1340, 411, 300, 13, 1610, 11, 420, 11, 420, 51348], "temperature": 0.0, "avg_logprob": -0.0997186271093225, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.005728333257138729}, {"id": 280, "seek": 110230, "start": 1121.98, "end": 1125.3, "text": " here's where the windows are. But what happened was, the", "tokens": [51348, 510, 311, 689, 264, 9309, 366, 13, 583, 437, 2011, 390, 11, 264, 51514], "temperature": 0.0, "avg_logprob": -0.0997186271093225, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.005728333257138729}, {"id": 281, "seek": 110230, "start": 1125.3, "end": 1129.22, "text": " network discovered that it had to, you know, learn a", "tokens": [51514, 3209, 6941, 300, 309, 632, 281, 11, 291, 458, 11, 1466, 257, 51710], "temperature": 0.0, "avg_logprob": -0.0997186271093225, "compression_ratio": 1.7897435897435898, "no_speech_prob": 0.005728333257138729}, {"id": 282, "seek": 112922, "start": 1129.22, "end": 1135.9, "text": " representation, where windows are represented differently from", "tokens": [50364, 10290, 11, 689, 9309, 366, 10379, 7614, 490, 50698], "temperature": 0.0, "avg_logprob": -0.1727201783811891, "compression_ratio": 1.988888888888889, "no_speech_prob": 0.0020499047823250294}, {"id": 283, "seek": 112922, "start": 1135.9, "end": 1142.26, "text": " the way chairs are represented. But somehow, even though, you", "tokens": [50698, 264, 636, 18299, 366, 10379, 13, 583, 6063, 11, 754, 1673, 11, 291, 51016], "temperature": 0.0, "avg_logprob": -0.1727201783811891, "compression_ratio": 1.988888888888889, "no_speech_prob": 0.0020499047823250294}, {"id": 284, "seek": 112922, "start": 1142.26, "end": 1144.5, "text": " know, windows can look very different from each other and", "tokens": [51016, 458, 11, 9309, 393, 574, 588, 819, 490, 1184, 661, 293, 51128], "temperature": 0.0, "avg_logprob": -0.1727201783811891, "compression_ratio": 1.988888888888889, "no_speech_prob": 0.0020499047823250294}, {"id": 285, "seek": 112922, "start": 1144.5, "end": 1146.8600000000001, "text": " chairs can look very different from each other, that the", "tokens": [51128, 18299, 393, 574, 588, 819, 490, 1184, 661, 11, 300, 264, 51246], "temperature": 0.0, "avg_logprob": -0.1727201783811891, "compression_ratio": 1.988888888888889, "no_speech_prob": 0.0020499047823250294}, {"id": 286, "seek": 112922, "start": 1146.8600000000001, "end": 1149.38, "text": " network has this represent this this component of this", "tokens": [51246, 3209, 575, 341, 2906, 341, 341, 6542, 295, 341, 51372], "temperature": 0.0, "avg_logprob": -0.1727201783811891, "compression_ratio": 1.988888888888889, "no_speech_prob": 0.0020499047823250294}, {"id": 287, "seek": 112922, "start": 1149.38, "end": 1156.58, "text": " representation, this neuron that activates on all these chairs,", "tokens": [51372, 10290, 11, 341, 34090, 300, 43869, 322, 439, 613, 18299, 11, 51732], "temperature": 0.0, "avg_logprob": -0.1727201783811891, "compression_ratio": 1.988888888888889, "no_speech_prob": 0.0020499047823250294}, {"id": 288, "seek": 115658, "start": 1156.82, "end": 1159.6599999999999, "text": " despite the amazing amount of diversity that it shows, like", "tokens": [50376, 7228, 264, 2243, 2372, 295, 8811, 300, 309, 3110, 11, 411, 50518], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 289, "seek": 115658, "start": 1159.6999999999998, "end": 1163.6999999999998, "text": " none of these chairs really look similar to each other, they", "tokens": [50520, 6022, 295, 613, 18299, 534, 574, 2531, 281, 1184, 661, 11, 436, 50720], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 290, "seek": 115658, "start": 1163.6999999999998, "end": 1166.06, "text": " have different colors and different textures, and they're", "tokens": [50720, 362, 819, 4577, 293, 819, 24501, 11, 293, 436, 434, 50838], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 291, "seek": 115658, "start": 1166.06, "end": 1170.1399999999999, "text": " oriented in different ways. And yet, the same neuron is", "tokens": [50838, 21841, 294, 819, 2098, 13, 400, 1939, 11, 264, 912, 34090, 307, 51042], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 292, "seek": 115658, "start": 1170.1399999999999, "end": 1173.26, "text": " activating on all of them, the same thing goes for other", "tokens": [51042, 42481, 322, 439, 295, 552, 11, 264, 912, 551, 1709, 337, 661, 51198], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 293, "seek": 115658, "start": 1173.26, "end": 1177.1, "text": " things that show up in these images. So does anybody have", "tokens": [51198, 721, 300, 855, 493, 294, 613, 5267, 13, 407, 775, 4472, 362, 51390], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 294, "seek": 115658, "start": 1177.1, "end": 1180.06, "text": " any questions about, about, about this? I'd love this to be a", "tokens": [51390, 604, 1651, 466, 11, 466, 11, 466, 341, 30, 286, 1116, 959, 341, 281, 312, 257, 51538], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 295, "seek": 115658, "start": 1180.06, "end": 1181.86, "text": " little bit more interactive than the way I'm doing the talk.", "tokens": [51538, 707, 857, 544, 15141, 813, 264, 636, 286, 478, 884, 264, 751, 13, 51628], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 296, "seek": 115658, "start": 1181.86, "end": 1184.86, "text": " So let me open the floor for a question for a minute.", "tokens": [51628, 407, 718, 385, 1269, 264, 4123, 337, 257, 1168, 337, 257, 3456, 13, 51778], "temperature": 0.0, "avg_logprob": -0.10750988446749174, "compression_ratio": 1.7891156462585034, "no_speech_prob": 0.0031207865104079247}, {"id": 297, "seek": 118658, "start": 1187.4199999999998, "end": 1192.1399999999999, "text": " Has anybody tried playing with the internals of GANs yet? I'd", "tokens": [50406, 8646, 4472, 3031, 2433, 365, 264, 2154, 1124, 295, 460, 1770, 82, 1939, 30, 286, 1116, 50642], "temperature": 0.0, "avg_logprob": -0.25064839107889525, "compression_ratio": 1.4157303370786516, "no_speech_prob": 0.0009245447581633925}, {"id": 298, "seek": 118658, "start": 1192.1399999999999, "end": 1198.82, "text": " love to see if has anybody like generated images using a GAN", "tokens": [50642, 959, 281, 536, 498, 575, 4472, 411, 10833, 5267, 1228, 257, 460, 1770, 50976], "temperature": 0.0, "avg_logprob": -0.25064839107889525, "compression_ratio": 1.4157303370786516, "no_speech_prob": 0.0009245447581633925}, {"id": 299, "seek": 118658, "start": 1198.82, "end": 1199.34, "text": " before?", "tokens": [50976, 949, 30, 51002], "temperature": 0.0, "avg_logprob": -0.25064839107889525, "compression_ratio": 1.4157303370786516, "no_speech_prob": 0.0009245447581633925}, {"id": 300, "seek": 118658, "start": 1201.8999999999999, "end": 1208.6999999999998, "text": " No, but I do have a question. Yes. So what was like the end goal", "tokens": [51130, 883, 11, 457, 286, 360, 362, 257, 1168, 13, 1079, 13, 407, 437, 390, 411, 264, 917, 3387, 51470], "temperature": 0.0, "avg_logprob": -0.25064839107889525, "compression_ratio": 1.4157303370786516, "no_speech_prob": 0.0009245447581633925}, {"id": 301, "seek": 118658, "start": 1208.6999999999998, "end": 1213.46, "text": " or the larger reason behind finding all of these neurons", "tokens": [51470, 420, 264, 4833, 1778, 2261, 5006, 439, 295, 613, 22027, 51708], "temperature": 0.0, "avg_logprob": -0.25064839107889525, "compression_ratio": 1.4157303370786516, "no_speech_prob": 0.0009245447581633925}, {"id": 302, "seek": 121346, "start": 1213.9, "end": 1218.82, "text": " that correspond to different objects or features?", "tokens": [50386, 300, 6805, 281, 819, 6565, 420, 4122, 30, 50632], "temperature": 0.0, "avg_logprob": -0.17996764528578607, "compression_ratio": 1.4873096446700507, "no_speech_prob": 0.0008555960957892239}, {"id": 303, "seek": 121346, "start": 1219.54, "end": 1224.3, "text": " Well, when I was originally looking at it, my original goal", "tokens": [50668, 1042, 11, 562, 286, 390, 7993, 1237, 412, 309, 11, 452, 3380, 3387, 50906], "temperature": 0.0, "avg_logprob": -0.17996764528578607, "compression_ratio": 1.4873096446700507, "no_speech_prob": 0.0008555960957892239}, {"id": 304, "seek": 121346, "start": 1224.3, "end": 1230.3400000000001, "text": " was just to understand how these models did their computation.", "tokens": [50906, 390, 445, 281, 1223, 577, 613, 5245, 630, 641, 24903, 13, 51208], "temperature": 0.0, "avg_logprob": -0.17996764528578607, "compression_ratio": 1.4873096446700507, "no_speech_prob": 0.0008555960957892239}, {"id": 305, "seek": 121346, "start": 1230.54, "end": 1236.18, "text": " So asking the question why. But the neat thing is that after I", "tokens": [51218, 407, 3365, 264, 1168, 983, 13, 583, 264, 10654, 551, 307, 300, 934, 286, 51500], "temperature": 0.0, "avg_logprob": -0.17996764528578607, "compression_ratio": 1.4873096446700507, "no_speech_prob": 0.0008555960957892239}, {"id": 306, "seek": 121346, "start": 1236.18, "end": 1239.74, "text": " found this structure, then it became clear that there are", "tokens": [51500, 1352, 341, 3877, 11, 550, 309, 3062, 1850, 300, 456, 366, 51678], "temperature": 0.0, "avg_logprob": -0.17996764528578607, "compression_ratio": 1.4873096446700507, "no_speech_prob": 0.0008555960957892239}, {"id": 307, "seek": 123974, "start": 1239.74, "end": 1244.78, "text": " new applications that you can build on top of it. And I think", "tokens": [50364, 777, 5821, 300, 291, 393, 1322, 322, 1192, 295, 309, 13, 400, 286, 519, 50616], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 308, "seek": 123974, "start": 1244.78, "end": 1246.78, "text": " that's one of the cool things that comes out of this sort of", "tokens": [50616, 300, 311, 472, 295, 264, 1627, 721, 300, 1487, 484, 295, 341, 1333, 295, 50716], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 309, "seek": 123974, "start": 1246.78, "end": 1250.66, "text": " academic style inquiry is, you know, originally, I was just", "tokens": [50716, 7778, 3758, 25736, 307, 11, 291, 458, 11, 7993, 11, 286, 390, 445, 50910], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 310, "seek": 123974, "start": 1250.66, "end": 1252.98, "text": " looking to make catalogs like this. This is a catalog of all", "tokens": [50910, 1237, 281, 652, 19746, 82, 411, 341, 13, 639, 307, 257, 19746, 295, 439, 51026], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 311, "seek": 123974, "start": 1252.98, "end": 1255.54, "text": " the different types of correlations that I found with", "tokens": [51026, 264, 819, 3467, 295, 13983, 763, 300, 286, 1352, 365, 51154], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 312, "seek": 123974, "start": 1255.54, "end": 1258.22, "text": " neurons inside a model for generating kitchens, and the", "tokens": [51154, 22027, 1854, 257, 2316, 337, 17746, 350, 47314, 11, 293, 264, 51288], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 313, "seek": 123974, "start": 1258.22, "end": 1261.86, "text": " kinds of, you know, the patterns you see. And, and, you know,", "tokens": [51288, 3685, 295, 11, 291, 458, 11, 264, 8294, 291, 536, 13, 400, 11, 293, 11, 291, 458, 11, 51470], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 314, "seek": 123974, "start": 1261.86, "end": 1264.5, "text": " I've done this before for classifiers. And, you know, when", "tokens": [51470, 286, 600, 1096, 341, 949, 337, 1508, 23463, 13, 400, 11, 291, 458, 11, 562, 51602], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 315, "seek": 123974, "start": 1264.5, "end": 1266.7, "text": " you do for generators, you get different patterns. And so I was", "tokens": [51602, 291, 360, 337, 38662, 11, 291, 483, 819, 8294, 13, 400, 370, 286, 390, 51712], "temperature": 0.0, "avg_logprob": -0.11716382486836893, "compression_ratio": 1.8487972508591066, "no_speech_prob": 0.0031217553187161684}, {"id": 316, "seek": 126670, "start": 1266.74, "end": 1269.98, "text": " just really interested in making these maps of seeing what is", "tokens": [50366, 445, 534, 3102, 294, 1455, 613, 11317, 295, 2577, 437, 307, 50528], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 317, "seek": 126670, "start": 1269.98, "end": 1274.46, "text": " computed at what layer, you know, where and how accurately. So", "tokens": [50528, 40610, 412, 437, 4583, 11, 291, 458, 11, 689, 293, 577, 20095, 13, 407, 50752], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 318, "seek": 126670, "start": 1274.46, "end": 1279.02, "text": " this is, you know, the progressive gain has, depending", "tokens": [50752, 341, 307, 11, 291, 458, 11, 264, 16131, 6052, 575, 11, 5413, 50980], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 319, "seek": 126670, "start": 1279.02, "end": 1282.5, "text": " on the resolution has about 15 layers. And if you sort of", "tokens": [50980, 322, 264, 8669, 575, 466, 2119, 7914, 13, 400, 498, 291, 1333, 295, 51154], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 320, "seek": 126670, "start": 1282.5, "end": 1285.74, "text": " chart what you see in different layers, you can see this this", "tokens": [51154, 6927, 437, 291, 536, 294, 819, 7914, 11, 291, 393, 536, 341, 341, 51316], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 321, "seek": 126670, "start": 1285.74, "end": 1288.46, "text": " really interesting thing phenomenon where it's in the", "tokens": [51316, 534, 1880, 551, 14029, 689, 309, 311, 294, 264, 51452], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 322, "seek": 126670, "start": 1288.46, "end": 1292.94, "text": " middle layers that you get these highly semantic correlated", "tokens": [51452, 2808, 7914, 300, 291, 483, 613, 5405, 47982, 38574, 51676], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 323, "seek": 126670, "start": 1292.94, "end": 1296.3, "text": " neurons. But then as you get to the later layers, then they", "tokens": [51676, 22027, 13, 583, 550, 382, 291, 483, 281, 264, 1780, 7914, 11, 550, 436, 51844], "temperature": 0.0, "avg_logprob": -0.12545095291812863, "compression_ratio": 1.7984790874524714, "no_speech_prob": 0.0015480085276067257}, {"id": 324, "seek": 129630, "start": 1296.34, "end": 1299.26, "text": " tend to be more physical. And there's not as many semantic", "tokens": [50366, 3928, 281, 312, 544, 4001, 13, 400, 456, 311, 406, 382, 867, 47982, 50512], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 325, "seek": 129630, "start": 1299.26, "end": 1302.3799999999999, "text": " objects. So it's like in layer five, we have things that really", "tokens": [50512, 6565, 13, 407, 309, 311, 411, 294, 4583, 1732, 11, 321, 362, 721, 300, 534, 50668], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 326, "seek": 129630, "start": 1302.3799999999999, "end": 1305.82, "text": " correlate with ovens and chairs and windows and doors, even", "tokens": [50668, 48742, 365, 9090, 82, 293, 18299, 293, 9309, 293, 8077, 11, 754, 50840], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 327, "seek": 129630, "start": 1305.82, "end": 1309.86, "text": " though like a window kind of looks like an oven. The model", "tokens": [50840, 1673, 411, 257, 4910, 733, 295, 1542, 411, 364, 9090, 13, 440, 2316, 51042], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 328, "seek": 129630, "start": 1310.22, "end": 1313.7, "text": " clearly has different neurons that correlate with windows from", "tokens": [51060, 4448, 575, 819, 22027, 300, 48742, 365, 9309, 490, 51234], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 329, "seek": 129630, "start": 1313.7, "end": 1318.7, "text": " ones that look like ovens. And so so that so that's that's that", "tokens": [51234, 2306, 300, 574, 411, 9090, 82, 13, 400, 370, 370, 300, 370, 300, 311, 300, 311, 300, 51484], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 330, "seek": 129630, "start": 1318.7, "end": 1322.5, "text": " so I was originally interested in just mapping things out. But", "tokens": [51484, 370, 286, 390, 7993, 3102, 294, 445, 18350, 721, 484, 13, 583, 51674], "temperature": 0.0, "avg_logprob": -0.13956539653172004, "compression_ratio": 1.7379032258064515, "no_speech_prob": 0.0018090958474203944}, {"id": 331, "seek": 132250, "start": 1323.46, "end": 1327.42, "text": " the correlations were so striking that it leads to these", "tokens": [50412, 264, 13983, 763, 645, 370, 18559, 300, 309, 6689, 281, 613, 50610], "temperature": 0.0, "avg_logprob": -0.2498268085521656, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.00032488780561834574}, {"id": 332, "seek": 132250, "start": 1327.42, "end": 1330.58, "text": " interesting applications that you can build. And I can I'll show", "tokens": [50610, 1880, 5821, 300, 291, 393, 1322, 13, 400, 286, 393, 286, 603, 855, 50768], "temperature": 0.0, "avg_logprob": -0.2498268085521656, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.00032488780561834574}, {"id": 333, "seek": 132250, "start": 1330.58, "end": 1336.22, "text": " you some in the next step. Let me before I do that, let me see", "tokens": [50768, 291, 512, 294, 264, 958, 1823, 13, 961, 385, 949, 286, 360, 300, 11, 718, 385, 536, 51050], "temperature": 0.0, "avg_logprob": -0.2498268085521656, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.00032488780561834574}, {"id": 334, "seek": 132250, "start": 1336.22, "end": 1338.22, "text": " if anybody else has a question as well.", "tokens": [51050, 498, 4472, 1646, 575, 257, 1168, 382, 731, 13, 51150], "temperature": 0.0, "avg_logprob": -0.2498268085521656, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.00032488780561834574}, {"id": 335, "seek": 132250, "start": 1341.34, "end": 1345.42, "text": " Yeah, David, I was hoping that you could also show us the", "tokens": [51306, 865, 11, 4389, 11, 286, 390, 7159, 300, 291, 727, 611, 855, 505, 264, 51510], "temperature": 0.0, "avg_logprob": -0.2498268085521656, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.00032488780561834574}, {"id": 336, "seek": 132250, "start": 1345.42, "end": 1349.74, "text": " application at some point, which I think these are very good to", "tokens": [51510, 3861, 412, 512, 935, 11, 597, 286, 519, 613, 366, 588, 665, 281, 51726], "temperature": 0.0, "avg_logprob": -0.2498268085521656, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.00032488780561834574}, {"id": 337, "seek": 134974, "start": 1349.78, "end": 1354.98, "text": " see why you asked this question. I mean, yes, it's more", "tokens": [50366, 536, 983, 291, 2351, 341, 1168, 13, 286, 914, 11, 2086, 11, 309, 311, 544, 50626], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 338, "seek": 134974, "start": 1355.78, "end": 1358.6200000000001, "text": " That's great. Let me let me zoom out to the application. So", "tokens": [50666, 663, 311, 869, 13, 961, 385, 718, 385, 8863, 484, 281, 264, 3861, 13, 407, 50808], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 339, "seek": 134974, "start": 1360.06, "end": 1363.22, "text": " so the the neat thing is that just like we could turn off", "tokens": [50880, 370, 264, 264, 10654, 551, 307, 300, 445, 411, 321, 727, 1261, 766, 51038], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 340, "seek": 134974, "start": 1363.22, "end": 1367.86, "text": " watermarks, we can turn on and off things in image generation.", "tokens": [51038, 1281, 37307, 11, 321, 393, 1261, 322, 293, 766, 721, 294, 3256, 5125, 13, 51270], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 341, "seek": 134974, "start": 1367.86, "end": 1370.06, "text": " So for example, if I find all the neurons that correlate with", "tokens": [51270, 407, 337, 1365, 11, 498, 286, 915, 439, 264, 22027, 300, 48742, 365, 51380], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 342, "seek": 134974, "start": 1370.06, "end": 1373.74, "text": " trees, and I turn them off, you can see what happens. I'm going", "tokens": [51380, 5852, 11, 293, 286, 1261, 552, 766, 11, 291, 393, 536, 437, 2314, 13, 286, 478, 516, 51564], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 343, "seek": 134974, "start": 1373.74, "end": 1377.9, "text": " to turn them off sort of one at a time here. And so originally,", "tokens": [51564, 281, 1261, 552, 766, 1333, 295, 472, 412, 257, 565, 510, 13, 400, 370, 7993, 11, 51772], "temperature": 0.0, "avg_logprob": -0.2449771496428161, "compression_ratio": 1.6447876447876448, "no_speech_prob": 0.0008551314240321517}, {"id": 344, "seek": 137790, "start": 1378.3400000000001, "end": 1381.46, "text": " the image will just be generated this. But if I turn off some", "tokens": [50386, 264, 3256, 486, 445, 312, 10833, 341, 13, 583, 498, 286, 1261, 766, 512, 50542], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 345, "seek": 137790, "start": 1381.46, "end": 1385.98, "text": " tree neurons, you can see that we can actually remove the trees", "tokens": [50542, 4230, 22027, 11, 291, 393, 536, 300, 321, 393, 767, 4159, 264, 5852, 50768], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 346, "seek": 137790, "start": 1385.98, "end": 1389.46, "text": " from the scene. And the cool thing is that this is different", "tokens": [50768, 490, 264, 4145, 13, 400, 264, 1627, 551, 307, 300, 341, 307, 819, 50942], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 347, "seek": 137790, "start": 1389.46, "end": 1393.42, "text": " from Photoshop. If you went and you tried to erase trees from an", "tokens": [50942, 490, 20821, 13, 759, 291, 1437, 293, 291, 3031, 281, 23525, 5852, 490, 364, 51140], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 348, "seek": 137790, "start": 1393.42, "end": 1397.18, "text": " image, then you'd have this puzzle of what would happen", "tokens": [51140, 3256, 11, 550, 291, 1116, 362, 341, 12805, 295, 437, 576, 1051, 51328], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 349, "seek": 137790, "start": 1397.22, "end": 1400.3000000000002, "text": " about stuff that was occluded by the trees like what's going on", "tokens": [51330, 466, 1507, 300, 390, 2678, 44412, 538, 264, 5852, 411, 437, 311, 516, 322, 51484], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 350, "seek": 137790, "start": 1400.3000000000002, "end": 1404.66, "text": " behind there. And so this image generator is actually it's got", "tokens": [51484, 2261, 456, 13, 400, 370, 341, 3256, 19265, 307, 767, 309, 311, 658, 51702], "temperature": 0.0, "avg_logprob": -0.10274321879815618, "compression_ratio": 1.736, "no_speech_prob": 0.002395666902884841}, {"id": 351, "seek": 140466, "start": 1404.7, "end": 1407.94, "text": " this latent model that has an understanding of what the scene", "tokens": [50366, 341, 48994, 2316, 300, 575, 364, 3701, 295, 437, 264, 4145, 50528], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 352, "seek": 140466, "start": 1407.94, "end": 1411.3400000000001, "text": " is. And so, and even has an understanding of things that is", "tokens": [50528, 307, 13, 400, 370, 11, 293, 754, 575, 364, 3701, 295, 721, 300, 307, 50698], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 353, "seek": 140466, "start": 1411.3400000000001, "end": 1415.1000000000001, "text": " not explicitly drawing. So if you remove the trees from the scene,", "tokens": [50698, 406, 20803, 6316, 13, 407, 498, 291, 4159, 264, 5852, 490, 264, 4145, 11, 50886], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 354, "seek": 140466, "start": 1415.38, "end": 1419.22, "text": " then it'll come up with a reasonable looking, you know,", "tokens": [50900, 550, 309, 603, 808, 493, 365, 257, 10585, 1237, 11, 291, 458, 11, 51092], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 355, "seek": 140466, "start": 1419.46, "end": 1424.3400000000001, "text": " image to draw what was behind the trees, or you can do the", "tokens": [51104, 3256, 281, 2642, 437, 390, 2261, 264, 5852, 11, 420, 291, 393, 360, 264, 51348], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 356, "seek": 140466, "start": 1424.3400000000001, "end": 1429.3400000000001, "text": " opposite. Which is you can take neurons that were not originally", "tokens": [51348, 6182, 13, 3013, 307, 291, 393, 747, 22027, 300, 645, 406, 7993, 51598], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 357, "seek": 140466, "start": 1429.3400000000001, "end": 1433.78, "text": " on in a generated scene and turn them on. So if I take a set of", "tokens": [51598, 322, 294, 257, 10833, 4145, 293, 1261, 552, 322, 13, 407, 498, 286, 747, 257, 992, 295, 51820], "temperature": 0.0, "avg_logprob": -0.11490564947729712, "compression_ratio": 1.7349397590361446, "no_speech_prob": 0.001324567012488842}, {"id": 358, "seek": 143378, "start": 1433.78, "end": 1436.66, "text": " neurons that correlate with doors, and I turn them on in a", "tokens": [50364, 22027, 300, 48742, 365, 8077, 11, 293, 286, 1261, 552, 322, 294, 257, 50508], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 359, "seek": 143378, "start": 1436.66, "end": 1439.54, "text": " certain location, and you can see what happens in the generated", "tokens": [50508, 1629, 4914, 11, 293, 291, 393, 536, 437, 2314, 294, 264, 10833, 50652], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 360, "seek": 143378, "start": 1439.54, "end": 1442.3799999999999, "text": " image, you know, I'll get this door in the scene, not only", "tokens": [50652, 3256, 11, 291, 458, 11, 286, 603, 483, 341, 2853, 294, 264, 4145, 11, 406, 787, 50794], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 361, "seek": 143378, "start": 1442.3799999999999, "end": 1445.8999999999999, "text": " will it just be a door, but it'll be it'll have like an", "tokens": [50794, 486, 309, 445, 312, 257, 2853, 11, 457, 309, 603, 312, 309, 603, 362, 411, 364, 50970], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 362, "seek": 143378, "start": 1445.8999999999999, "end": 1451.22, "text": " appropriate size and your orientation and style for for", "tokens": [50970, 6854, 2744, 293, 428, 14764, 293, 3758, 337, 337, 51236], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 363, "seek": 143378, "start": 1451.22, "end": 1453.94, "text": " the building that it's in. So if I take exactly the same neurons,", "tokens": [51236, 264, 2390, 300, 309, 311, 294, 13, 407, 498, 286, 747, 2293, 264, 912, 22027, 11, 51372], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 364, "seek": 143378, "start": 1454.46, "end": 1457.82, "text": " and I activate them in a different location like here in", "tokens": [51398, 293, 286, 13615, 552, 294, 257, 819, 4914, 411, 510, 294, 51566], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 365, "seek": 143378, "start": 1457.82, "end": 1461.1399999999999, "text": " this building, then even though it's exactly the same neurons", "tokens": [51566, 341, 2390, 11, 550, 754, 1673, 309, 311, 2293, 264, 912, 22027, 51732], "temperature": 0.0, "avg_logprob": -0.11880630400122666, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.0038230002392083406}, {"id": 366, "seek": 146114, "start": 1461.14, "end": 1464.74, "text": " exactly the same activation that I've done, I get a different", "tokens": [50364, 2293, 264, 912, 24433, 300, 286, 600, 1096, 11, 286, 483, 257, 819, 50544], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 367, "seek": 146114, "start": 1464.74, "end": 1468.1000000000001, "text": " door that is like a much smaller has a different style and so on.", "tokens": [50544, 2853, 300, 307, 411, 257, 709, 4356, 575, 257, 819, 3758, 293, 370, 322, 13, 50712], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 368, "seek": 146114, "start": 1468.1000000000001, "end": 1471.66, "text": " It's appropriate to the building that it's in. If I if I try to", "tokens": [50712, 467, 311, 6854, 281, 264, 2390, 300, 309, 311, 294, 13, 759, 286, 498, 286, 853, 281, 50890], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 369, "seek": 146114, "start": 1471.66, "end": 1475.14, "text": " put a door in a place that would make sense, like by turning on", "tokens": [50890, 829, 257, 2853, 294, 257, 1081, 300, 576, 652, 2020, 11, 411, 538, 6246, 322, 51064], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 370, "seek": 146114, "start": 1475.14, "end": 1479.8200000000002, "text": " neurons up in the sky, then it like will like not do anything.", "tokens": [51064, 22027, 493, 294, 264, 5443, 11, 550, 309, 411, 486, 411, 406, 360, 1340, 13, 51298], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 371, "seek": 146114, "start": 1480.8600000000001, "end": 1484.3000000000002, "text": " This is this is the actual output of what happens if I turn on", "tokens": [51350, 639, 307, 341, 307, 264, 3539, 5598, 295, 437, 2314, 498, 286, 1261, 322, 51522], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 372, "seek": 146114, "start": 1484.3000000000002, "end": 1488.18, "text": " the exact same neurons up in this location. So there's a lot of", "tokens": [51522, 264, 1900, 912, 22027, 493, 294, 341, 4914, 13, 407, 456, 311, 257, 688, 295, 51716], "temperature": 0.0, "avg_logprob": -0.10245728492736816, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.0009108640952035785}, {"id": 373, "seek": 148818, "start": 1488.22, "end": 1492.3400000000001, "text": " interesting context sensitivity that you can measure. But one of", "tokens": [50366, 1880, 4319, 19392, 300, 291, 393, 3481, 13, 583, 472, 295, 50572], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 374, "seek": 148818, "start": 1492.3400000000001, "end": 1494.38, "text": " the cool things that you can do is you can actually hook this up", "tokens": [50572, 264, 1627, 721, 300, 291, 393, 360, 307, 291, 393, 767, 6328, 341, 493, 50674], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 375, "seek": 148818, "start": 1494.38, "end": 1499.9, "text": " to a paintbrush user interface, like I can find neurons that", "tokens": [50674, 281, 257, 4225, 21330, 4195, 9226, 11, 411, 286, 393, 915, 22027, 300, 50950], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 376, "seek": 148818, "start": 1499.9, "end": 1503.7, "text": " correlate with domes or doors or things. And if I want to add", "tokens": [50950, 48742, 365, 3285, 279, 420, 8077, 420, 721, 13, 400, 498, 286, 528, 281, 909, 51140], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 377, "seek": 148818, "start": 1503.7, "end": 1506.3, "text": " doors to a building, I can just sort of paint them on. And the", "tokens": [51140, 8077, 281, 257, 2390, 11, 286, 393, 445, 1333, 295, 4225, 552, 322, 13, 400, 264, 51270], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 378, "seek": 148818, "start": 1506.3, "end": 1509.38, "text": " doors will show up and you can see the orientation of the doors", "tokens": [51270, 8077, 486, 855, 493, 293, 291, 393, 536, 264, 14764, 295, 264, 8077, 51424], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 379, "seek": 148818, "start": 1509.38, "end": 1512.98, "text": " is appropriate to the wall that you put them in. If I just say I", "tokens": [51424, 307, 6854, 281, 264, 2929, 300, 291, 829, 552, 294, 13, 759, 286, 445, 584, 286, 51604], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 380, "seek": 148818, "start": 1512.98, "end": 1516.78, "text": " want trees, it'll put trunks and leaves, you know, in the right", "tokens": [51604, 528, 5852, 11, 309, 603, 829, 504, 17627, 293, 5510, 11, 291, 458, 11, 294, 264, 558, 51794], "temperature": 0.0, "avg_logprob": -0.08769992598913666, "compression_ratio": 1.8405797101449275, "no_speech_prob": 0.0009695105836726725}, {"id": 381, "seek": 151678, "start": 1516.78, "end": 1519.1, "text": " place in the trees or plants with a plant, plant them on the", "tokens": [50364, 1081, 294, 264, 5852, 420, 5972, 365, 257, 3709, 11, 3709, 552, 322, 264, 50480], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 382, "seek": 151678, "start": 1519.1, "end": 1522.7, "text": " ground. If I take grass and I can turn the grass neurons off and", "tokens": [50480, 2727, 13, 759, 286, 747, 8054, 293, 286, 393, 1261, 264, 8054, 22027, 766, 293, 50660], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 383, "seek": 151678, "start": 1522.7, "end": 1526.18, "text": " remove grass from the scene and it'll come up with what the", "tokens": [50660, 4159, 8054, 490, 264, 4145, 293, 309, 603, 808, 493, 365, 437, 264, 50834], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 384, "seek": 151678, "start": 1526.18, "end": 1529.26, "text": " scene should look like instead. And so I can kind of do these", "tokens": [50834, 4145, 820, 574, 411, 2602, 13, 400, 370, 286, 393, 733, 295, 360, 613, 50988], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 385, "seek": 151678, "start": 1530.22, "end": 1533.8999999999999, "text": " semantic manipulations directly. Oh, here we're turning on domes", "tokens": [51036, 47982, 9258, 4136, 3838, 13, 876, 11, 510, 321, 434, 6246, 322, 3285, 279, 51220], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 386, "seek": 151678, "start": 1533.8999999999999, "end": 1540.22, "text": " and you can see it will turn the top of the the church from a", "tokens": [51220, 293, 291, 393, 536, 309, 486, 1261, 264, 1192, 295, 264, 264, 4128, 490, 257, 51536], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 387, "seek": 151678, "start": 1540.22, "end": 1544.1399999999999, "text": " spiral to a dome, but it also sort of stitched the dome into", "tokens": [51536, 25165, 281, 257, 27191, 11, 457, 309, 611, 1333, 295, 48992, 264, 27191, 666, 51732], "temperature": 0.0, "avg_logprob": -0.1917591426683509, "compression_ratio": 1.7330677290836654, "no_speech_prob": 0.001454685116186738}, {"id": 388, "seek": 154414, "start": 1544.14, "end": 1547.74, "text": " place to make it look good here. I'm removing grass again. We", "tokens": [50364, 1081, 281, 652, 309, 574, 665, 510, 13, 286, 478, 12720, 8054, 797, 13, 492, 50544], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 389, "seek": 154414, "start": 1547.74, "end": 1553.0200000000002, "text": " can like put a door in the scene. And if I if I put you know,", "tokens": [50544, 393, 411, 829, 257, 2853, 294, 264, 4145, 13, 400, 498, 286, 498, 286, 829, 291, 458, 11, 50808], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 390, "seek": 154414, "start": 1553.0200000000002, "end": 1556.5400000000002, "text": " sort of put a door in the wall, then it'll it'll come up with", "tokens": [50808, 1333, 295, 829, 257, 2853, 294, 264, 2929, 11, 550, 309, 603, 309, 603, 808, 493, 365, 50984], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 391, "seek": 154414, "start": 1556.5400000000002, "end": 1559.9, "text": " like the appropriate location and style orientation for the door", "tokens": [50984, 411, 264, 6854, 4914, 293, 3758, 14764, 337, 264, 2853, 51152], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 392, "seek": 154414, "start": 1559.9, "end": 1564.94, "text": " even if I draw very roughly. So when I'm drawing, every time I", "tokens": [51152, 754, 498, 286, 2642, 588, 9810, 13, 407, 562, 286, 478, 6316, 11, 633, 565, 286, 51404], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 393, "seek": 154414, "start": 1564.94, "end": 1567.9, "text": " touch the surface here, what I'm really doing is I'm just turning", "tokens": [51404, 2557, 264, 3753, 510, 11, 437, 286, 478, 534, 884, 307, 286, 478, 445, 6246, 51552], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 394, "seek": 154414, "start": 1567.9, "end": 1573.14, "text": " on a few neurons. And and I'm letting the the math of the", "tokens": [51552, 322, 257, 1326, 22027, 13, 400, 293, 286, 478, 8295, 264, 264, 5221, 295, 264, 51814], "temperature": 0.0, "avg_logprob": -0.10846301375842485, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.0009694932377897203}, {"id": 395, "seek": 157314, "start": 1573.14, "end": 1579.7800000000002, "text": " GAN generator deal with all of the the details of how to arrange", "tokens": [50364, 460, 1770, 19265, 2028, 365, 439, 295, 264, 264, 4365, 295, 577, 281, 9424, 50696], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 396, "seek": 157314, "start": 1579.7800000000002, "end": 1582.18, "text": " the actual pixel. So does that does that sort of give you a", "tokens": [50696, 264, 3539, 19261, 13, 407, 775, 300, 775, 300, 1333, 295, 976, 291, 257, 50816], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 397, "seek": 157314, "start": 1582.18, "end": 1585.26, "text": " sense? Does that answer your question for like, you know,", "tokens": [50816, 2020, 30, 4402, 300, 1867, 428, 1168, 337, 411, 11, 291, 458, 11, 50970], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 398, "seek": 157314, "start": 1585.26, "end": 1588.3400000000001, "text": " what kinds of things you can do with this by understanding what's", "tokens": [50970, 437, 3685, 295, 721, 291, 393, 360, 365, 341, 538, 3701, 437, 311, 51124], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 399, "seek": 157314, "start": 1588.3400000000001, "end": 1591.3000000000002, "text": " going on in the interior of the model? Maybe now I should stop", "tokens": [51124, 516, 322, 294, 264, 10636, 295, 264, 2316, 30, 2704, 586, 286, 820, 1590, 51272], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 400, "seek": 157314, "start": 1591.3000000000002, "end": 1596.0600000000002, "text": " it. Oh, yes, go ahead. Are these different neurons for like", "tokens": [51272, 309, 13, 876, 11, 2086, 11, 352, 2286, 13, 2014, 613, 819, 22027, 337, 411, 51510], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 401, "seek": 157314, "start": 1596.0600000000002, "end": 1601.0600000000002, "text": " doors in different areas? No, no. So when I when you click on the", "tokens": [51510, 8077, 294, 819, 3179, 30, 883, 11, 572, 13, 407, 562, 286, 562, 291, 2052, 322, 264, 51760], "temperature": 0.0, "avg_logprob": -0.17992835209287447, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.0017542366404086351}, {"id": 402, "seek": 160106, "start": 1601.06, "end": 1607.78, "text": " door button on the left, I am picking 20 neurons that are", "tokens": [50364, 2853, 2960, 322, 264, 1411, 11, 286, 669, 8867, 945, 22027, 300, 366, 50700], "temperature": 0.0, "avg_logprob": -0.1357741874197255, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0056394473649561405}, {"id": 403, "seek": 160106, "start": 1607.78, "end": 1611.54, "text": " the door neurons. So by doing the statistical analysis ahead of", "tokens": [50700, 264, 2853, 22027, 13, 407, 538, 884, 264, 22820, 5215, 2286, 295, 50888], "temperature": 0.0, "avg_logprob": -0.1357741874197255, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0056394473649561405}, {"id": 404, "seek": 160106, "start": 1611.54, "end": 1615.34, "text": " time that I showed you earlier, I've identified 20 neurons that", "tokens": [50888, 565, 300, 286, 4712, 291, 3071, 11, 286, 600, 9234, 945, 22027, 300, 51078], "temperature": 0.0, "avg_logprob": -0.1357741874197255, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0056394473649561405}, {"id": 405, "seek": 160106, "start": 1615.34, "end": 1619.86, "text": " correlate very strongly with the presence of doors. And when you", "tokens": [51078, 48742, 588, 10613, 365, 264, 6814, 295, 8077, 13, 400, 562, 291, 51304], "temperature": 0.0, "avg_logprob": -0.1357741874197255, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0056394473649561405}, {"id": 406, "seek": 160106, "start": 1620.02, "end": 1624.02, "text": " click on the button on the left, I am picking those neurons. Now,", "tokens": [51312, 2052, 322, 264, 2960, 322, 264, 1411, 11, 286, 669, 8867, 729, 22027, 13, 823, 11, 51512], "temperature": 0.0, "avg_logprob": -0.1357741874197255, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0056394473649561405}, {"id": 407, "seek": 160106, "start": 1624.22, "end": 1626.54, "text": " it's a convolutional network. So there's this translation", "tokens": [51522, 309, 311, 257, 45216, 304, 3209, 13, 407, 456, 311, 341, 12853, 51638], "temperature": 0.0, "avg_logprob": -0.1357741874197255, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.0056394473649561405}, {"id": 408, "seek": 162654, "start": 1626.54, "end": 1631.46, "text": " and depends those neurons appear at every pixel. And so what you", "tokens": [50364, 293, 5946, 729, 22027, 4204, 412, 633, 19261, 13, 400, 370, 437, 291, 50610], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 409, "seek": 162654, "start": 1631.46, "end": 1634.6599999999999, "text": " can do is you can just turn on those neurons in random pixels", "tokens": [50610, 393, 360, 307, 291, 393, 445, 1261, 322, 729, 22027, 294, 4974, 18668, 50770], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 410, "seek": 162654, "start": 1634.6599999999999, "end": 1635.46, "text": " that you touch.", "tokens": [50770, 300, 291, 2557, 13, 50810], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 411, "seek": 162654, "start": 1636.98, "end": 1639.18, "text": " Changing where the neurons are, that was what I didn't", "tokens": [50886, 45773, 689, 264, 22027, 366, 11, 300, 390, 437, 286, 994, 380, 50996], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 412, "seek": 162654, "start": 1639.18, "end": 1641.86, "text": " understand. Does that make sense? So, so because it's a", "tokens": [50996, 1223, 13, 4402, 300, 652, 2020, 30, 407, 11, 370, 570, 309, 311, 257, 51130], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 413, "seek": 162654, "start": 1641.86, "end": 1644.8999999999999, "text": " convolutional network, so it's actually it's it's like the neural", "tokens": [51130, 45216, 304, 3209, 11, 370, 309, 311, 767, 309, 311, 309, 311, 411, 264, 18161, 51282], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 414, "seek": 162654, "start": 1644.8999999999999, "end": 1649.02, "text": " network is cloned at every location. It's the same neural", "tokens": [51282, 3209, 307, 596, 19009, 412, 633, 4914, 13, 467, 311, 264, 912, 18161, 51488], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 415, "seek": 162654, "start": 1649.02, "end": 1652.82, "text": " network that's being used to process every, you know, patch", "tokens": [51488, 3209, 300, 311, 885, 1143, 281, 1399, 633, 11, 291, 458, 11, 9972, 51678], "temperature": 0.0, "avg_logprob": -0.16021194458007812, "compression_ratio": 1.7764227642276422, "no_speech_prob": 0.004536776803433895}, {"id": 416, "seek": 165282, "start": 1652.82, "end": 1657.7, "text": " or patch of pixels in the image. And, and so if I asked for a", "tokens": [50364, 420, 9972, 295, 18668, 294, 264, 3256, 13, 400, 11, 293, 370, 498, 286, 2351, 337, 257, 50608], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 417, "seek": 165282, "start": 1657.7, "end": 1660.3, "text": " door in a place that wouldn't really make sense, then it", "tokens": [50608, 2853, 294, 257, 1081, 300, 2759, 380, 534, 652, 2020, 11, 550, 309, 50738], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 418, "seek": 165282, "start": 1660.3, "end": 1663.1799999999998, "text": " won't put a door there. If I asked for a door in a place that", "tokens": [50738, 1582, 380, 829, 257, 2853, 456, 13, 759, 286, 2351, 337, 257, 2853, 294, 257, 1081, 300, 50882], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 419, "seek": 165282, "start": 1663.1799999999998, "end": 1665.4199999999998, "text": " makes sense, it'll make a big intervention, it'll stick a big", "tokens": [50882, 1669, 2020, 11, 309, 603, 652, 257, 955, 13176, 11, 309, 603, 2897, 257, 955, 50994], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 420, "seek": 165282, "start": 1665.4199999999998, "end": 1668.5, "text": " door there, which you can see. So I could be very rough about", "tokens": [50994, 2853, 456, 11, 597, 291, 393, 536, 13, 407, 286, 727, 312, 588, 5903, 466, 51148], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 421, "seek": 165282, "start": 1668.5, "end": 1673.6599999999999, "text": " where I put a door and it'll like put it in the right place. So", "tokens": [51148, 689, 286, 829, 257, 2853, 293, 309, 603, 411, 829, 309, 294, 264, 558, 1081, 13, 407, 51406], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 422, "seek": 165282, "start": 1673.6599999999999, "end": 1679.1, "text": " that's that's the idea. So let me let me zoom around here, I'll", "tokens": [51406, 300, 311, 300, 311, 264, 1558, 13, 407, 718, 385, 718, 385, 8863, 926, 510, 11, 286, 603, 51678], "temperature": 0.0, "avg_logprob": -0.13829463720321655, "compression_ratio": 1.8782608695652174, "no_speech_prob": 0.005908740684390068}, {"id": 423, "seek": 167910, "start": 1679.1, "end": 1684.2199999999998, "text": " show you a couple other things that you can do. So now there's", "tokens": [50364, 855, 291, 257, 1916, 661, 721, 300, 291, 393, 360, 13, 407, 586, 456, 311, 50620], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 424, "seek": 167910, "start": 1684.2199999999998, "end": 1687.34, "text": " some limitations to this. And I'll just show you some of the", "tokens": [50620, 512, 15705, 281, 341, 13, 400, 286, 603, 445, 855, 291, 512, 295, 264, 50776], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 425, "seek": 167910, "start": 1687.34, "end": 1689.3, "text": " techniques that you can use to get around the limitation. So one", "tokens": [50776, 7512, 300, 291, 393, 764, 281, 483, 926, 264, 27432, 13, 407, 472, 50874], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 426, "seek": 167910, "start": 1689.3, "end": 1692.1, "text": " of the problems is that, you know, we can do all this cool", "tokens": [50874, 295, 264, 2740, 307, 300, 11, 291, 458, 11, 321, 393, 360, 439, 341, 1627, 51014], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 427, "seek": 167910, "start": 1692.1, "end": 1695.8999999999999, "text": " editing, but we can do this editing of a randomly generated", "tokens": [51014, 10000, 11, 457, 321, 393, 360, 341, 10000, 295, 257, 16979, 10833, 51204], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 428, "seek": 167910, "start": 1695.8999999999999, "end": 1701.2199999999998, "text": " image. And, and so, so when I posted this demo on on the web,", "tokens": [51204, 3256, 13, 400, 11, 293, 370, 11, 370, 562, 286, 9437, 341, 10723, 322, 322, 264, 3670, 11, 51470], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 429, "seek": 167910, "start": 1701.26, "end": 1703.6599999999999, "text": " you know, an artist called me and said, Hey, you know, I love", "tokens": [51472, 291, 458, 11, 364, 5748, 1219, 385, 293, 848, 11, 1911, 11, 291, 458, 11, 286, 959, 51592], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 430, "seek": 167910, "start": 1703.6599999999999, "end": 1707.06, "text": " how you can edit images, I can edit this image of a kitchen", "tokens": [51592, 577, 291, 393, 8129, 5267, 11, 286, 393, 8129, 341, 3256, 295, 257, 6525, 51762], "temperature": 0.0, "avg_logprob": -0.10524529569289263, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.000666569103486836}, {"id": 431, "seek": 170706, "start": 1707.06, "end": 1710.78, "text": " here. But that's not the kitchen I want to edit, I want to edit", "tokens": [50364, 510, 13, 583, 300, 311, 406, 264, 6525, 286, 528, 281, 8129, 11, 286, 528, 281, 8129, 50550], "temperature": 0.0, "avg_logprob": -0.1561711345400129, "compression_ratio": 1.7242990654205608, "no_speech_prob": 0.0033758196514099836}, {"id": 432, "seek": 170706, "start": 1710.78, "end": 1716.1, "text": " my own kitchen, right? Like here's a photo of my kitchen. And I", "tokens": [50550, 452, 1065, 6525, 11, 558, 30, 1743, 510, 311, 257, 5052, 295, 452, 6525, 13, 400, 286, 50816], "temperature": 0.0, "avg_logprob": -0.1561711345400129, "compression_ratio": 1.7242990654205608, "no_speech_prob": 0.0033758196514099836}, {"id": 433, "seek": 170706, "start": 1716.1, "end": 1721.74, "text": " want to edit that one. And I had to explain to them, you know,", "tokens": [50816, 528, 281, 8129, 300, 472, 13, 400, 286, 632, 281, 2903, 281, 552, 11, 291, 458, 11, 51098], "temperature": 0.0, "avg_logprob": -0.1561711345400129, "compression_ratio": 1.7242990654205608, "no_speech_prob": 0.0033758196514099836}, {"id": 434, "seek": 170706, "start": 1721.74, "end": 1725.6599999999999, "text": " they said, Oh, can you just load into your demo? My my kitchen", "tokens": [51098, 436, 848, 11, 876, 11, 393, 291, 445, 3677, 666, 428, 10723, 30, 1222, 452, 6525, 51294], "temperature": 0.0, "avg_logprob": -0.1561711345400129, "compression_ratio": 1.7242990654205608, "no_speech_prob": 0.0033758196514099836}, {"id": 435, "seek": 170706, "start": 1725.6599999999999, "end": 1729.34, "text": " instead of yours. And I had to explain, no, no, no, that's not", "tokens": [51294, 2602, 295, 6342, 13, 400, 286, 632, 281, 2903, 11, 572, 11, 572, 11, 572, 11, 300, 311, 406, 51478], "temperature": 0.0, "avg_logprob": -0.1561711345400129, "compression_ratio": 1.7242990654205608, "no_speech_prob": 0.0033758196514099836}, {"id": 436, "seek": 170706, "start": 1729.34, "end": 1733.46, "text": " how GANs work. They're unconditional generators. You", "tokens": [51478, 577, 460, 1770, 82, 589, 13, 814, 434, 47916, 38662, 13, 509, 51684], "temperature": 0.0, "avg_logprob": -0.1561711345400129, "compression_ratio": 1.7242990654205608, "no_speech_prob": 0.0033758196514099836}, {"id": 437, "seek": 173346, "start": 1733.46, "end": 1739.54, "text": " know, you give it a random vector of 512 numbers. And it", "tokens": [50364, 458, 11, 291, 976, 309, 257, 4974, 8062, 295, 1025, 4762, 3547, 13, 400, 309, 50668], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 438, "seek": 173346, "start": 1739.54, "end": 1743.9, "text": " decides what image to make. And then once it decides what image", "tokens": [50668, 14898, 437, 3256, 281, 652, 13, 400, 550, 1564, 309, 14898, 437, 3256, 50886], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 439, "seek": 173346, "start": 1743.9, "end": 1746.78, "text": " to make, then you can edit it. And so I'm sorry, I can't edit", "tokens": [50886, 281, 652, 11, 550, 291, 393, 8129, 309, 13, 400, 370, 286, 478, 2597, 11, 286, 393, 380, 8129, 51030], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 440, "seek": 173346, "start": 1746.78, "end": 1749.98, "text": " your kitchen. And so they were very disappointed by that", "tokens": [51030, 428, 6525, 13, 400, 370, 436, 645, 588, 13856, 538, 300, 51190], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 441, "seek": 173346, "start": 1749.98, "end": 1752.14, "text": " because they had all sorts of ideas of things they wanted to", "tokens": [51190, 570, 436, 632, 439, 7527, 295, 3487, 295, 721, 436, 1415, 281, 51298], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 442, "seek": 173346, "start": 1752.14, "end": 1758.26, "text": " do. And so now the problem is that, you know, the problem", "tokens": [51298, 360, 13, 400, 370, 586, 264, 1154, 307, 300, 11, 291, 458, 11, 264, 1154, 51604], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 443, "seek": 173346, "start": 1758.26, "end": 1762.38, "text": " could be solved if we could find the random vector, some random", "tokens": [51604, 727, 312, 13041, 498, 321, 727, 915, 264, 4974, 8062, 11, 512, 4974, 51810], "temperature": 0.0, "avg_logprob": -0.09319873441729629, "compression_ratio": 1.8189655172413792, "no_speech_prob": 0.00170034053735435}, {"id": 444, "seek": 176238, "start": 1762.42, "end": 1766.42, "text": " vector that that output the kitchen image or the specific", "tokens": [50366, 8062, 300, 300, 5598, 264, 6525, 3256, 420, 264, 2685, 50566], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 445, "seek": 176238, "start": 1766.42, "end": 1771.38, "text": " real photo that I wanted. The problem is how do I find it 512", "tokens": [50566, 957, 5052, 300, 286, 1415, 13, 440, 1154, 307, 577, 360, 286, 915, 309, 1025, 4762, 50814], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 446, "seek": 176238, "start": 1771.38, "end": 1776.8600000000001, "text": " dimensional vectors as pretty big vector space. And and so I", "tokens": [50814, 18795, 18875, 382, 1238, 955, 8062, 1901, 13, 400, 293, 370, 286, 51088], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 447, "seek": 176238, "start": 1776.8600000000001, "end": 1780.7, "text": " don't know if my GAN can actually generate this image or not. So", "tokens": [51088, 500, 380, 458, 498, 452, 460, 1770, 393, 767, 8460, 341, 3256, 420, 406, 13, 407, 51280], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 448, "seek": 176238, "start": 1780.7, "end": 1784.2600000000002, "text": " one of the things you can do is you can just treat this as a as", "tokens": [51280, 472, 295, 264, 721, 291, 393, 360, 307, 291, 393, 445, 2387, 341, 382, 257, 382, 51458], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 449, "seek": 176238, "start": 1784.2600000000002, "end": 1787.5, "text": " an inversion problem. You can take the neural network and you", "tokens": [51458, 364, 43576, 1154, 13, 509, 393, 747, 264, 18161, 3209, 293, 291, 51620], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 450, "seek": 176238, "start": 1787.5, "end": 1791.9, "text": " can learn how to run it backwards. Basically, you know,", "tokens": [51620, 393, 1466, 577, 281, 1190, 309, 12204, 13, 8537, 11, 291, 458, 11, 51840], "temperature": 0.0, "avg_logprob": -0.14931697673625774, "compression_ratio": 1.6113207547169812, "no_speech_prob": 0.0016478666802868247}, {"id": 451, "seek": 179190, "start": 1792.3000000000002, "end": 1795.3400000000001, "text": " think of the neural network as a function G, and you want to", "tokens": [50384, 519, 295, 264, 18161, 3209, 382, 257, 2445, 460, 11, 293, 291, 528, 281, 50536], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 452, "seek": 179190, "start": 1795.3400000000001, "end": 1798.3000000000002, "text": " learn G inverse. So you can treat that as another training", "tokens": [50536, 1466, 460, 17340, 13, 407, 291, 393, 2387, 300, 382, 1071, 3097, 50684], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 453, "seek": 179190, "start": 1798.3000000000002, "end": 1800.5800000000002, "text": " problem. And there's a bunch of tricks and I won't go into all", "tokens": [50684, 1154, 13, 400, 456, 311, 257, 3840, 295, 11733, 293, 286, 1582, 380, 352, 666, 439, 50798], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 454, "seek": 179190, "start": 1800.5800000000002, "end": 1804.74, "text": " the tricks here. But but basically, the idea is that you", "tokens": [50798, 264, 11733, 510, 13, 583, 457, 1936, 11, 264, 1558, 307, 300, 291, 51006], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 455, "seek": 179190, "start": 1804.74, "end": 1808.14, "text": " can actually find a Z that comes closest to generating your image", "tokens": [51006, 393, 767, 915, 257, 1176, 300, 1487, 13699, 281, 17746, 428, 3256, 51176], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 456, "seek": 179190, "start": 1808.14, "end": 1813.5800000000002, "text": " by by training and doing a couple other tricks. And you can", "tokens": [51176, 538, 538, 3097, 293, 884, 257, 1916, 661, 11733, 13, 400, 291, 393, 51448], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 457, "seek": 179190, "start": 1813.5800000000002, "end": 1818.66, "text": " actually get a Z that will generate your image pretty", "tokens": [51448, 767, 483, 257, 1176, 300, 486, 8460, 428, 3256, 1238, 51702], "temperature": 0.0, "avg_logprob": -0.11307405075936947, "compression_ratio": 1.7531380753138075, "no_speech_prob": 0.0007552632596343756}, {"id": 458, "seek": 181866, "start": 1818.66, "end": 1823.46, "text": " closely. But the thing that's a little bit sad is it also", "tokens": [50364, 8185, 13, 583, 264, 551, 300, 311, 257, 707, 857, 4227, 307, 309, 611, 50604], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 459, "seek": 181866, "start": 1823.46, "end": 1827.8600000000001, "text": " reveals things that the network cannot do. So so this network", "tokens": [50604, 20893, 721, 300, 264, 3209, 2644, 360, 13, 407, 370, 341, 3209, 50824], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 460, "seek": 181866, "start": 1828.74, "end": 1831.66, "text": " is capable of generating this image that I'm showing you here.", "tokens": [50868, 307, 8189, 295, 17746, 341, 3256, 300, 286, 478, 4099, 291, 510, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 461, "seek": 181866, "start": 1832.22, "end": 1835.3400000000001, "text": " But the original kitchen that I started with look like this. So", "tokens": [51042, 583, 264, 3380, 6525, 300, 286, 1409, 365, 574, 411, 341, 13, 407, 51198], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 462, "seek": 181866, "start": 1835.3400000000001, "end": 1837.42, "text": " you can see what the differences are. I've lost a lot of", "tokens": [51198, 291, 393, 536, 437, 264, 7300, 366, 13, 286, 600, 2731, 257, 688, 295, 51302], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 463, "seek": 181866, "start": 1837.42, "end": 1842.7, "text": " stuff. Right. So, you know, I can use the GAN to edit this", "tokens": [51302, 1507, 13, 1779, 13, 407, 11, 291, 458, 11, 286, 393, 764, 264, 460, 1770, 281, 8129, 341, 51566], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 464, "seek": 181866, "start": 1842.7, "end": 1846.94, "text": " image. But this image is not exactly what I started with. And", "tokens": [51566, 3256, 13, 583, 341, 3256, 307, 406, 2293, 437, 286, 1409, 365, 13, 400, 51778], "temperature": 0.0, "avg_logprob": -0.10869182620132178, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0032718991860747337}, {"id": 465, "seek": 184694, "start": 1846.94, "end": 1853.98, "text": " so. So one of the pieces of science that that I did is I", "tokens": [50364, 370, 13, 407, 472, 295, 264, 3755, 295, 3497, 300, 300, 286, 630, 307, 286, 50716], "temperature": 0.0, "avg_logprob": -0.12841462587055408, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0003682207898236811}, {"id": 466, "seek": 184694, "start": 1853.98, "end": 1858.26, "text": " asked a question, you know, is there some way that we can", "tokens": [50716, 2351, 257, 1168, 11, 291, 458, 11, 307, 456, 512, 636, 300, 321, 393, 50930], "temperature": 0.0, "avg_logprob": -0.12841462587055408, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0003682207898236811}, {"id": 467, "seek": 184694, "start": 1858.26, "end": 1861.5, "text": " actually make this work? Can we actually, you know, get the", "tokens": [50930, 767, 652, 341, 589, 30, 1664, 321, 767, 11, 291, 458, 11, 483, 264, 51092], "temperature": 0.0, "avg_logprob": -0.12841462587055408, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0003682207898236811}, {"id": 468, "seek": 184694, "start": 1861.5, "end": 1866.6200000000001, "text": " network to output a real photo that that the user gave us? We", "tokens": [51092, 3209, 281, 5598, 257, 957, 5052, 300, 300, 264, 4195, 2729, 505, 30, 492, 51348], "temperature": 0.0, "avg_logprob": -0.12841462587055408, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0003682207898236811}, {"id": 469, "seek": 184694, "start": 1866.6200000000001, "end": 1870.06, "text": " get the network to output this sort of simplified version of", "tokens": [51348, 483, 264, 3209, 281, 5598, 341, 1333, 295, 26335, 3037, 295, 51520], "temperature": 0.0, "avg_logprob": -0.12841462587055408, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0003682207898236811}, {"id": 470, "seek": 184694, "start": 1870.06, "end": 1875.06, "text": " it. It turns out that if I modify the weights of the", "tokens": [51520, 309, 13, 467, 4523, 484, 300, 498, 286, 16927, 264, 17443, 295, 264, 51770], "temperature": 0.0, "avg_logprob": -0.12841462587055408, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.0003682207898236811}, {"id": 471, "seek": 187506, "start": 1875.06, "end": 1881.46, "text": " network, I can actually fine tune the network to get it so that", "tokens": [50364, 3209, 11, 286, 393, 767, 2489, 10864, 264, 3209, 281, 483, 309, 370, 300, 50684], "temperature": 0.0, "avg_logprob": -0.11818093441902323, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.0014546221354976296}, {"id": 472, "seek": 187506, "start": 1881.46, "end": 1884.8999999999999, "text": " a very, very nearby network with weights that are almost the", "tokens": [50684, 257, 588, 11, 588, 11184, 3209, 365, 17443, 300, 366, 1920, 264, 50856], "temperature": 0.0, "avg_logprob": -0.11818093441902323, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.0014546221354976296}, {"id": 473, "seek": 187506, "start": 1884.8999999999999, "end": 1891.06, "text": " same as the original actually hits this target image. Exactly.", "tokens": [50856, 912, 382, 264, 3380, 767, 8664, 341, 3779, 3256, 13, 7587, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11818093441902323, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.0014546221354976296}, {"id": 474, "seek": 187506, "start": 1891.82, "end": 1896.8999999999999, "text": " And so so there's a bunch of details in the right way of", "tokens": [51202, 400, 370, 370, 456, 311, 257, 3840, 295, 4365, 294, 264, 558, 636, 295, 51456], "temperature": 0.0, "avg_logprob": -0.11818093441902323, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.0014546221354976296}, {"id": 475, "seek": 187506, "start": 1896.8999999999999, "end": 1899.62, "text": " doing this. But it turns out that, you know, you don't actually", "tokens": [51456, 884, 341, 13, 583, 309, 4523, 484, 300, 11, 291, 458, 11, 291, 500, 380, 767, 51592], "temperature": 0.0, "avg_logprob": -0.11818093441902323, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.0014546221354976296}, {"id": 476, "seek": 187506, "start": 1899.62, "end": 1902.78, "text": " have to change much if you change the fine grained weights", "tokens": [51592, 362, 281, 1319, 709, 498, 291, 1319, 264, 2489, 1295, 2001, 17443, 51750], "temperature": 0.0, "avg_logprob": -0.11818093441902323, "compression_ratio": 1.6990740740740742, "no_speech_prob": 0.0014546221354976296}, {"id": 477, "seek": 190278, "start": 1902.8999999999999, "end": 1907.3, "text": " of a network. You can you can change a lot of the details of", "tokens": [50370, 295, 257, 3209, 13, 509, 393, 291, 393, 1319, 257, 688, 295, 264, 4365, 295, 50590], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 478, "seek": 190278, "start": 1908.34, "end": 1912.5, "text": " what images actually get generated. And and and if you", "tokens": [50642, 437, 5267, 767, 483, 10833, 13, 400, 293, 293, 498, 291, 50850], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 479, "seek": 190278, "start": 1912.54, "end": 1917.18, "text": " are given a target image to get you can actually tweak tweak any", "tokens": [50852, 366, 2212, 257, 3779, 3256, 281, 483, 291, 393, 767, 29879, 29879, 604, 51084], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 480, "seek": 190278, "start": 1917.18, "end": 1921.74, "text": " network to generate exactly that target image if we want. And", "tokens": [51084, 3209, 281, 8460, 2293, 300, 3779, 3256, 498, 321, 528, 13, 400, 51312], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 481, "seek": 190278, "start": 1921.74, "end": 1922.1, "text": " so", "tokens": [51312, 370, 51330], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 482, "seek": 190278, "start": 1924.1, "end": 1927.7, "text": " so you know, so yeah, we can get all the objects back. But the", "tokens": [51430, 370, 291, 458, 11, 370, 1338, 11, 321, 393, 483, 439, 264, 6565, 646, 13, 583, 264, 51610], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 483, "seek": 190278, "start": 1927.7, "end": 1929.82, "text": " new thing is we haven't really changed the network much. So we", "tokens": [51610, 777, 551, 307, 321, 2378, 380, 534, 3105, 264, 3209, 709, 13, 407, 321, 51716], "temperature": 0.0, "avg_logprob": -0.15192163833464034, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.002251347526907921}, {"id": 484, "seek": 192982, "start": 1929.82, "end": 1933.3, "text": " can still do editing. So like if we take the window correlated", "tokens": [50364, 393, 920, 360, 10000, 13, 407, 411, 498, 321, 747, 264, 4910, 38574, 50538], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 485, "seek": 192982, "start": 1933.3, "end": 1936.34, "text": " neurons, we can take our modified network, we can turn them", "tokens": [50538, 22027, 11, 321, 393, 747, 527, 15873, 3209, 11, 321, 393, 1261, 552, 50690], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 486, "seek": 192982, "start": 1936.34, "end": 1942.1799999999998, "text": " on. And and now we can like add a window. Let's see if we show", "tokens": [50690, 322, 13, 400, 293, 586, 321, 393, 411, 909, 257, 4910, 13, 961, 311, 536, 498, 321, 855, 50982], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 487, "seek": 192982, "start": 1942.1799999999998, "end": 1944.3799999999999, "text": " that. Yeah, so this here's outlook. So we get this nice", "tokens": [50982, 300, 13, 865, 11, 370, 341, 510, 311, 26650, 13, 407, 321, 483, 341, 1481, 51092], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 488, "seek": 192982, "start": 1944.3799999999999, "end": 1948.8999999999999, "text": " window here. And the scene is began is doing its cool tricks of", "tokens": [51092, 4910, 510, 13, 400, 264, 4145, 307, 4283, 307, 884, 1080, 1627, 11733, 295, 51318], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 489, "seek": 192982, "start": 1948.8999999999999, "end": 1951.86, "text": " orienting the window properly, doing some reasonable things. And", "tokens": [51318, 8579, 278, 264, 4910, 6108, 11, 884, 512, 10585, 721, 13, 400, 51466], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 490, "seek": 192982, "start": 1951.86, "end": 1955.62, "text": " it has some really interesting effects that are non trivial", "tokens": [51466, 309, 575, 512, 534, 1880, 5065, 300, 366, 2107, 26703, 51654], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 491, "seek": 192982, "start": 1955.62, "end": 1958.82, "text": " here. Some of them are good and some are bad. So for example,", "tokens": [51654, 510, 13, 2188, 295, 552, 366, 665, 293, 512, 366, 1578, 13, 407, 337, 1365, 11, 51814], "temperature": 0.0, "avg_logprob": -0.12823236450668454, "compression_ratio": 1.7634408602150538, "no_speech_prob": 0.004330238327383995}, {"id": 492, "seek": 195882, "start": 1958.86, "end": 1961.74, "text": " all I did was turn on the neurons in this location saying I", "tokens": [50366, 439, 286, 630, 390, 1261, 322, 264, 22027, 294, 341, 4914, 1566, 286, 50510], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 493, "seek": 195882, "start": 1961.74, "end": 1967.46, "text": " want windows. And it did it. But look what else it did. It also", "tokens": [50510, 528, 9309, 13, 400, 309, 630, 309, 13, 583, 574, 437, 1646, 309, 630, 13, 467, 611, 50796], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 494, "seek": 195882, "start": 1967.46, "end": 1970.02, "text": " added these reflections right here on the counter. And so this", "tokens": [50796, 3869, 613, 30679, 558, 510, 322, 264, 5682, 13, 400, 370, 341, 50924], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 495, "seek": 195882, "start": 1970.34, "end": 1974.1399999999999, "text": " this kitchen guy does this a lot like adds adds non local", "tokens": [50940, 341, 6525, 2146, 775, 341, 257, 688, 411, 10860, 10860, 2107, 2654, 51130], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 496, "seek": 195882, "start": 1974.1399999999999, "end": 1976.6599999999999, "text": " reflections where it thinks that there's a shiny table. And so", "tokens": [51130, 30679, 689, 309, 7309, 300, 456, 311, 257, 16997, 3199, 13, 400, 370, 51256], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 497, "seek": 195882, "start": 1976.6599999999999, "end": 1979.3, "text": " the cool thing here is that after I did all the inversion and", "tokens": [51256, 264, 1627, 551, 510, 307, 300, 934, 286, 630, 439, 264, 43576, 293, 51388], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 498, "seek": 195882, "start": 1979.3, "end": 1982.34, "text": " stuff, this guy actually thinks that there's a shiny table here", "tokens": [51388, 1507, 11, 341, 2146, 767, 7309, 300, 456, 311, 257, 16997, 3199, 510, 51540], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 499, "seek": 195882, "start": 1982.34, "end": 1984.86, "text": " and it's right. And it thinks that if I add a window here,", "tokens": [51540, 293, 309, 311, 558, 13, 400, 309, 7309, 300, 498, 286, 909, 257, 4910, 510, 11, 51666], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 500, "seek": 195882, "start": 1984.86, "end": 1987.34, "text": " they should add reflection. That's right. Also, but look", "tokens": [51666, 436, 820, 909, 12914, 13, 663, 311, 558, 13, 2743, 11, 457, 574, 51790], "temperature": 0.0, "avg_logprob": -0.12694396435374944, "compression_ratio": 2.0036496350364965, "no_speech_prob": 0.0002780103241093457}, {"id": 501, "seek": 198734, "start": 1987.34, "end": 1990.86, "text": " what else happened up here. See this lamp up here. When I first", "tokens": [50364, 437, 1646, 2011, 493, 510, 13, 3008, 341, 12684, 493, 510, 13, 1133, 286, 700, 50540], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 502, "seek": 198734, "start": 1990.86, "end": 1992.98, "text": " lifted this in low resolution, I thought, Oh, maybe it turned off", "tokens": [50540, 17854, 341, 294, 2295, 8669, 11, 286, 1194, 11, 876, 11, 1310, 309, 3574, 766, 50646], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 503, "seek": 198734, "start": 1992.98, "end": 1995.06, "text": " the lamp because once you have windows, you don't need the light", "tokens": [50646, 264, 12684, 570, 1564, 291, 362, 9309, 11, 291, 500, 380, 643, 264, 1442, 50750], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 504, "seek": 198734, "start": 1995.06, "end": 1998.6999999999998, "text": " on. But no, it didn't do that. It just messed up the lamp. It's", "tokens": [50750, 322, 13, 583, 572, 11, 309, 994, 380, 360, 300, 13, 467, 445, 16507, 493, 264, 12684, 13, 467, 311, 50932], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 505, "seek": 198734, "start": 1998.6999999999998, "end": 2002.82, "text": " just total it took this whole area up here and just and just", "tokens": [50932, 445, 3217, 309, 1890, 341, 1379, 1859, 493, 510, 293, 445, 293, 445, 51138], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 506, "seek": 198734, "start": 2002.82, "end": 2007.58, "text": " distorted it badly. And so so that that's a little dissatisfying.", "tokens": [51138, 33431, 309, 13425, 13, 400, 370, 370, 300, 300, 311, 257, 707, 7802, 25239, 1840, 13, 51376], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 507, "seek": 198734, "start": 2007.58, "end": 2012.02, "text": " It means that this fine tuning thing, where we get again to,", "tokens": [51376, 467, 1355, 300, 341, 2489, 15164, 551, 11, 689, 321, 483, 797, 281, 11, 51598], "temperature": 0.0, "avg_logprob": -0.18506839411045478, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.0023960794787853956}, {"id": 508, "seek": 201202, "start": 2013.02, "end": 2017.66, "text": " you know, target a specific user image, when I do when I try to", "tokens": [50414, 291, 458, 11, 3779, 257, 2685, 4195, 3256, 11, 562, 286, 360, 562, 286, 853, 281, 50646], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 509, "seek": 201202, "start": 2017.66, "end": 2020.58, "text": " teach it all the details, I'm not really teaching it what the lamp", "tokens": [50646, 2924, 309, 439, 264, 4365, 11, 286, 478, 406, 534, 4571, 309, 437, 264, 12684, 50792], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 510, "seek": 201202, "start": 2020.58, "end": 2024.62, "text": " was, I was just sort of showing it how to arrange the pixels. And", "tokens": [50792, 390, 11, 286, 390, 445, 1333, 295, 4099, 309, 577, 281, 9424, 264, 18668, 13, 400, 50994], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 511, "seek": 201202, "start": 2024.62, "end": 2029.54, "text": " again, made its best guess on how to generalize how the image", "tokens": [50994, 797, 11, 1027, 1080, 1151, 2041, 322, 577, 281, 2674, 1125, 577, 264, 3256, 51240], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 512, "seek": 201202, "start": 2029.54, "end": 2032.18, "text": " should look differently. If I change something like out of", "tokens": [51240, 820, 574, 7614, 13, 759, 286, 1319, 746, 411, 484, 295, 51372], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 513, "seek": 201202, "start": 2032.18, "end": 2035.34, "text": " window, but with only one example of a lamp that looks like", "tokens": [51372, 4910, 11, 457, 365, 787, 472, 1365, 295, 257, 12684, 300, 1542, 411, 51530], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 514, "seek": 201202, "start": 2035.34, "end": 2037.86, "text": " this, it generalized wrong, it has no idea what should happen to", "tokens": [51530, 341, 11, 309, 44498, 2085, 11, 309, 575, 572, 1558, 437, 820, 1051, 281, 51656], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 515, "seek": 201202, "start": 2037.86, "end": 2040.94, "text": " that lamp when I when I add a window. So this is this question", "tokens": [51656, 300, 12684, 562, 286, 562, 286, 909, 257, 4910, 13, 407, 341, 307, 341, 1168, 51810], "temperature": 0.0, "avg_logprob": -0.11832031336697665, "compression_ratio": 1.7474048442906573, "no_speech_prob": 0.005058872513473034}, {"id": 516, "seek": 204094, "start": 2040.98, "end": 2045.3400000000001, "text": " of like how to make changes in a network with with with", "tokens": [50366, 295, 411, 577, 281, 652, 2962, 294, 257, 3209, 365, 365, 365, 50584], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 517, "seek": 204094, "start": 2045.3400000000001, "end": 2050.26, "text": " achieving good generalization is, which is a good question. And", "tokens": [50584, 19626, 665, 2674, 2144, 307, 11, 597, 307, 257, 665, 1168, 13, 400, 50830], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 518, "seek": 204094, "start": 2050.3, "end": 2053.82, "text": " it was, there was something that puzzled me for a year after", "tokens": [50832, 309, 390, 11, 456, 390, 746, 300, 18741, 1493, 385, 337, 257, 1064, 934, 51008], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 519, "seek": 204094, "start": 2053.82, "end": 2057.38, "text": " doing this work. But but the work is still pretty cool, you can", "tokens": [51008, 884, 341, 589, 13, 583, 457, 264, 589, 307, 920, 1238, 1627, 11, 291, 393, 51186], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 520, "seek": 204094, "start": 2057.38, "end": 2061.46, "text": " still use it for modifying real photos. So here's like a photo of", "tokens": [51186, 920, 764, 309, 337, 42626, 957, 5787, 13, 407, 510, 311, 411, 257, 5052, 295, 51390], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 521, "seek": 204094, "start": 2062.02, "end": 2066.7000000000003, "text": " I got off of Wikipedia of like some real locations. And you can", "tokens": [51418, 286, 658, 766, 295, 28999, 295, 411, 512, 957, 9253, 13, 400, 291, 393, 51652], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 522, "seek": 204094, "start": 2066.7400000000002, "end": 2069.86, "text": " you can edit them, I can add grass, I can add doors, I can add", "tokens": [51654, 291, 393, 8129, 552, 11, 286, 393, 909, 8054, 11, 286, 393, 909, 8077, 11, 286, 393, 909, 51810], "temperature": 0.0, "avg_logprob": -0.13886456611828926, "compression_ratio": 1.7341269841269842, "no_speech_prob": 0.0020499560050666332}, {"id": 523, "seek": 206986, "start": 2069.86, "end": 2073.86, "text": " domes, you know, just like, just like the the the other", "tokens": [50364, 3285, 279, 11, 291, 458, 11, 445, 411, 11, 445, 411, 264, 264, 264, 661, 50564], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 524, "seek": 206986, "start": 2073.86, "end": 2076.38, "text": " campaign app, except I can actually start with a real photo", "tokens": [50564, 5129, 724, 11, 3993, 286, 393, 767, 722, 365, 257, 957, 5052, 50690], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 525, "seek": 206986, "start": 2076.38, "end": 2078.98, "text": " that you give me. And I can invert that photo through the", "tokens": [50690, 300, 291, 976, 385, 13, 400, 286, 393, 33966, 300, 5052, 807, 264, 50820], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 526, "seek": 206986, "start": 2078.98, "end": 2081.82, "text": " network, get a good starting image, fine tune the network to", "tokens": [50820, 3209, 11, 483, 257, 665, 2891, 3256, 11, 2489, 10864, 264, 3209, 281, 50962], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 527, "seek": 206986, "start": 2081.86, "end": 2085.54, "text": " make it make it output, you know, the target image and edit that", "tokens": [50964, 652, 309, 652, 309, 5598, 11, 291, 458, 11, 264, 3779, 3256, 293, 8129, 300, 51148], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 528, "seek": 206986, "start": 2085.54, "end": 2088.54, "text": " image, add bigger domes, and it'll sort of match the", "tokens": [51148, 3256, 11, 909, 3801, 3285, 279, 11, 293, 309, 603, 1333, 295, 2995, 264, 51298], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 529, "seek": 206986, "start": 2088.54, "end": 2092.78, "text": " architectural style. And, and, and, you know, do different things", "tokens": [51298, 26621, 3758, 13, 400, 11, 293, 11, 293, 11, 291, 458, 11, 360, 819, 721, 51510], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 530, "seek": 206986, "start": 2092.78, "end": 2095.7000000000003, "text": " like that, I can add domes, remove domes, add doors, you", "tokens": [51510, 411, 300, 11, 286, 393, 909, 3285, 279, 11, 4159, 3285, 279, 11, 909, 8077, 11, 291, 51656], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 531, "seek": 206986, "start": 2095.7000000000003, "end": 2098.9, "text": " know, things like that. Let me see if I can get this video here", "tokens": [51656, 458, 11, 721, 411, 300, 13, 961, 385, 536, 498, 286, 393, 483, 341, 960, 510, 51816], "temperature": 0.0, "avg_logprob": -0.12507890065511068, "compression_ratio": 1.9388489208633093, "no_speech_prob": 0.0028883805498480797}, {"id": 532, "seek": 209890, "start": 2098.94, "end": 2104.14, "text": " to show. So this is the status center. Let's add some doors", "tokens": [50366, 281, 855, 13, 407, 341, 307, 264, 6558, 3056, 13, 961, 311, 909, 512, 8077, 50626], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 533, "seek": 209890, "start": 2104.14, "end": 2108.38, "text": " here. So you get the idea, I'm doing exactly the same", "tokens": [50626, 510, 13, 407, 291, 483, 264, 1558, 11, 286, 478, 884, 2293, 264, 912, 50838], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 534, "seek": 209890, "start": 2108.38, "end": 2111.82, "text": " intervention that I did before. And it's it's opinion just like", "tokens": [50838, 13176, 300, 286, 630, 949, 13, 400, 309, 311, 309, 311, 4800, 445, 411, 51010], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 535, "seek": 209890, "start": 2111.82, "end": 2115.26, "text": " before, it will not add doors in places that it doesn't think are", "tokens": [51010, 949, 11, 309, 486, 406, 909, 8077, 294, 3190, 300, 309, 1177, 380, 519, 366, 51182], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 536, "seek": 209890, "start": 2115.3, "end": 2117.9, "text": " not good places for a door, it has some opinions about where", "tokens": [51184, 406, 665, 3190, 337, 257, 2853, 11, 309, 575, 512, 11819, 466, 689, 51314], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 537, "seek": 209890, "start": 2117.9, "end": 2120.7400000000002, "text": " doors are allowed, it likes to put them in brick walls. It", "tokens": [51314, 8077, 366, 4350, 11, 309, 5902, 281, 829, 552, 294, 16725, 7920, 13, 467, 51456], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 538, "seek": 209890, "start": 2120.7400000000002, "end": 2125.78, "text": " thinks it's okay to put a door in a tower, like that architectural", "tokens": [51456, 7309, 309, 311, 1392, 281, 829, 257, 2853, 294, 257, 10567, 11, 411, 300, 26621, 51708], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 539, "seek": 209890, "start": 2125.78, "end": 2128.88, "text": " detail. Oh, I put domes here. It's happy to put domes on top of", "tokens": [51708, 2607, 13, 876, 11, 286, 829, 3285, 279, 510, 13, 467, 311, 2055, 281, 829, 3285, 279, 322, 1192, 295, 51863], "temperature": 0.0, "avg_logprob": -0.1499138707699983, "compression_ratio": 1.789855072463768, "no_speech_prob": 0.0011333689326420426}, {"id": 540, "seek": 212888, "start": 2128.88, "end": 2131.56, "text": " buildings. It's not happy to put a dome like in the middle of the", "tokens": [50364, 7446, 13, 467, 311, 406, 2055, 281, 829, 257, 27191, 411, 294, 264, 2808, 295, 264, 50498], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 541, "seek": 212888, "start": 2131.56, "end": 2135.52, "text": " sky. It's not happy to put a door in the middle of the sky. But", "tokens": [50498, 5443, 13, 467, 311, 406, 2055, 281, 829, 257, 2853, 294, 264, 2808, 295, 264, 5443, 13, 583, 50696], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 542, "seek": 212888, "start": 2135.52, "end": 2140.76, "text": " you know, it put trees in different places. And, and so", "tokens": [50696, 291, 458, 11, 309, 829, 5852, 294, 819, 3190, 13, 400, 11, 293, 370, 50958], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 543, "seek": 212888, "start": 2140.76, "end": 2142.1600000000003, "text": " there are things that it understands, there are things", "tokens": [50958, 456, 366, 721, 300, 309, 15146, 11, 456, 366, 721, 51028], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 544, "seek": 212888, "start": 2142.1600000000003, "end": 2144.32, "text": " that it doesn't understand very well, it's sort of making a", "tokens": [51028, 300, 309, 1177, 380, 1223, 588, 731, 11, 309, 311, 1333, 295, 1455, 257, 51136], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 545, "seek": 212888, "start": 2144.32, "end": 2147.1600000000003, "text": " guess of what the structure of the image is. It doesn't know what", "tokens": [51136, 2041, 295, 437, 264, 3877, 295, 264, 3256, 307, 13, 467, 1177, 380, 458, 437, 51278], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 546, "seek": 212888, "start": 2147.1600000000003, "end": 2150.48, "text": " to make of my advisor, you know, sort of planting grass in front", "tokens": [51278, 281, 652, 295, 452, 19161, 11, 291, 458, 11, 1333, 295, 20585, 8054, 294, 1868, 51444], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 547, "seek": 212888, "start": 2150.48, "end": 2153.92, "text": " of him. And that's not very realistic. But you kind of get", "tokens": [51444, 295, 796, 13, 400, 300, 311, 406, 588, 12465, 13, 583, 291, 733, 295, 483, 51616], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 548, "seek": 212888, "start": 2153.92, "end": 2157.28, "text": " a feel for what the structure and knowledge of the model is by", "tokens": [51616, 257, 841, 337, 437, 264, 3877, 293, 3601, 295, 264, 2316, 307, 538, 51784], "temperature": 0.0, "avg_logprob": -0.1144577153523763, "compression_ratio": 2.0711610486891385, "no_speech_prob": 0.0010644365102052689}, {"id": 549, "seek": 215728, "start": 2157.28, "end": 2159.5600000000004, "text": " doing these kind of interventions. So this was really", "tokens": [50364, 884, 613, 733, 295, 20924, 13, 407, 341, 390, 534, 50478], "temperature": 0.0, "avg_logprob": -0.18264845143193784, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00326588680036366}, {"id": 550, "seek": 215728, "start": 2159.5600000000004, "end": 2162.84, "text": " cool. I think it got a lot of people's attention. Adobe", "tokens": [50478, 1627, 13, 286, 519, 309, 658, 257, 688, 295, 561, 311, 3202, 13, 24862, 50642], "temperature": 0.0, "avg_logprob": -0.18264845143193784, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00326588680036366}, {"id": 551, "seek": 215728, "start": 2162.84, "end": 2167.0800000000004, "text": " noticed this stuff, and has been busy trying to make different", "tokens": [50642, 5694, 341, 1507, 11, 293, 575, 668, 5856, 1382, 281, 652, 819, 50854], "temperature": 0.0, "avg_logprob": -0.18264845143193784, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00326588680036366}, {"id": 552, "seek": 215728, "start": 2167.0800000000004, "end": 2172.28, "text": " painting applications using, you know, GAN technology that are", "tokens": [50854, 5370, 5821, 1228, 11, 291, 458, 11, 460, 1770, 2899, 300, 366, 51114], "temperature": 0.0, "avg_logprob": -0.18264845143193784, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00326588680036366}, {"id": 553, "seek": 215728, "start": 2172.32, "end": 2177.1600000000003, "text": " I think partially inspired by by by this kind of discovery. So", "tokens": [51116, 286, 519, 18886, 7547, 538, 538, 538, 341, 733, 295, 12114, 13, 407, 51358], "temperature": 0.0, "avg_logprob": -0.18264845143193784, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00326588680036366}, {"id": 554, "seek": 215728, "start": 2177.44, "end": 2182.92, "text": " David, I have a question. Yep. This is really cool. Question is,", "tokens": [51372, 4389, 11, 286, 362, 257, 1168, 13, 7010, 13, 639, 307, 534, 1627, 13, 14464, 307, 11, 51646], "temperature": 0.0, "avg_logprob": -0.18264845143193784, "compression_ratio": 1.5512820512820513, "no_speech_prob": 0.00326588680036366}, {"id": 555, "seek": 218292, "start": 2183.28, "end": 2188.2400000000002, "text": " when you modify, for instance, churches, I assume you have", "tokens": [50382, 562, 291, 16927, 11, 337, 5197, 11, 15381, 11, 286, 6552, 291, 362, 50630], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 556, "seek": 218292, "start": 2188.6, "end": 2193.8, "text": " trained your GAN on a church data set. Yes, that's correct.", "tokens": [50648, 8895, 428, 460, 1770, 322, 257, 4128, 1412, 992, 13, 1079, 11, 300, 311, 3006, 13, 50908], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 557, "seek": 218292, "start": 2193.84, "end": 2197.6800000000003, "text": " What about when you do it on the real images, for instance, in", "tokens": [50910, 708, 466, 562, 291, 360, 309, 322, 264, 957, 5267, 11, 337, 5197, 11, 294, 51102], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 558, "seek": 218292, "start": 2197.6800000000003, "end": 2202.92, "text": " this case, you know, your advisor? Yes. So actually, both of", "tokens": [51102, 341, 1389, 11, 291, 458, 11, 428, 19161, 30, 1079, 13, 407, 767, 11, 1293, 295, 51364], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 559, "seek": 218292, "start": 2202.92, "end": 2205.88, "text": " these are using the church data set as well. So the church", "tokens": [51364, 613, 366, 1228, 264, 4128, 1412, 992, 382, 731, 13, 407, 264, 4128, 51512], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 560, "seek": 218292, "start": 2205.88, "end": 2206.4, "text": " data set,", "tokens": [51512, 1412, 992, 11, 51538], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 561, "seek": 218292, "start": 2206.44, "end": 2210.76, "text": " interesting that even you have trained again on church, you", "tokens": [51540, 1880, 300, 754, 291, 362, 8895, 797, 322, 4128, 11, 291, 51756], "temperature": 0.0, "avg_logprob": -0.19075901068530035, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.00154761818703264}, {"id": 562, "seek": 221076, "start": 2210.76, "end": 2212.48, "text": " can depict a person.", "tokens": [50364, 393, 31553, 257, 954, 13, 50450], "temperature": 0.0, "avg_logprob": -0.15007370297271427, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.0010645812144502997}, {"id": 563, "seek": 221076, "start": 2213.28, "end": 2218.32, "text": " Yes. So this is so the GAN. Now, you have to keep in mind that", "tokens": [50490, 1079, 13, 407, 341, 307, 370, 264, 460, 1770, 13, 823, 11, 291, 362, 281, 1066, 294, 1575, 300, 50742], "temperature": 0.0, "avg_logprob": -0.15007370297271427, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.0010645812144502997}, {"id": 564, "seek": 221076, "start": 2218.32, "end": 2222.48, "text": " what I've done here is I fine tuned the GAN. So you can", "tokens": [50742, 437, 286, 600, 1096, 510, 307, 286, 2489, 10870, 264, 460, 1770, 13, 407, 291, 393, 50950], "temperature": 0.0, "avg_logprob": -0.15007370297271427, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.0010645812144502997}, {"id": 565, "seek": 221076, "start": 2222.48, "end": 2225.28, "text": " actually, you know, you can actually get you can actually", "tokens": [50950, 767, 11, 291, 458, 11, 291, 393, 767, 483, 291, 393, 767, 51090], "temperature": 0.0, "avg_logprob": -0.15007370297271427, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.0010645812144502997}, {"id": 566, "seek": 221076, "start": 2225.28, "end": 2231.1600000000003, "text": " get a GAN to do a lot of things by fine tuning it. So I've I've", "tokens": [51090, 483, 257, 460, 1770, 281, 360, 257, 688, 295, 721, 538, 2489, 15164, 309, 13, 407, 286, 600, 286, 600, 51384], "temperature": 0.0, "avg_logprob": -0.15007370297271427, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.0010645812144502997}, {"id": 567, "seek": 221076, "start": 2231.1600000000003, "end": 2236.2400000000002, "text": " told the GAN, please basically overfit on this target image. So", "tokens": [51384, 1907, 264, 460, 1770, 11, 1767, 1936, 670, 6845, 322, 341, 3779, 3256, 13, 407, 51638], "temperature": 0.0, "avg_logprob": -0.15007370297271427, "compression_ratio": 1.6839378238341969, "no_speech_prob": 0.0010645812144502997}, {"id": 568, "seek": 223624, "start": 2236.24, "end": 2243.8799999999997, "text": " the GAN, you know, has 30 million parameters. And, and you", "tokens": [50364, 264, 460, 1770, 11, 291, 458, 11, 575, 2217, 2459, 9834, 13, 400, 11, 293, 291, 50746], "temperature": 0.0, "avg_logprob": -0.14039155208703244, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.0002377941709710285}, {"id": 569, "seek": 223624, "start": 2243.8799999999997, "end": 2247.2, "text": " know, an image only has, you know, 10,000 pixels, and it has", "tokens": [50746, 458, 11, 364, 3256, 787, 575, 11, 291, 458, 11, 1266, 11, 1360, 18668, 11, 293, 309, 575, 50912], "temperature": 0.0, "avg_logprob": -0.14039155208703244, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.0002377941709710285}, {"id": 570, "seek": 223624, "start": 2247.2, "end": 2251.52, "text": " plenty of excess capacity to memorize the details that I", "tokens": [50912, 7140, 295, 9310, 6042, 281, 27478, 264, 4365, 300, 286, 51128], "temperature": 0.0, "avg_logprob": -0.14039155208703244, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.0002377941709710285}, {"id": 571, "seek": 223624, "start": 2251.52, "end": 2256.3199999999997, "text": " might want to do. And so what I've done is this as I've taken", "tokens": [51128, 1062, 528, 281, 360, 13, 400, 370, 437, 286, 600, 1096, 307, 341, 382, 286, 600, 2726, 51368], "temperature": 0.0, "avg_logprob": -0.14039155208703244, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.0002377941709710285}, {"id": 572, "seek": 223624, "start": 2256.3199999999997, "end": 2260.3999999999996, "text": " the image, I've asked again, through my inversion techniques,", "tokens": [51368, 264, 3256, 11, 286, 600, 2351, 797, 11, 807, 452, 43576, 7512, 11, 51572], "temperature": 0.0, "avg_logprob": -0.14039155208703244, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.0002377941709710285}, {"id": 573, "seek": 223624, "start": 2260.4399999999996, "end": 2264.8799999999997, "text": " what is the closest church image that you can generate that", "tokens": [51574, 437, 307, 264, 13699, 4128, 3256, 300, 291, 393, 8460, 300, 51796], "temperature": 0.0, "avg_logprob": -0.14039155208703244, "compression_ratio": 1.592920353982301, "no_speech_prob": 0.0002377941709710285}, {"id": 574, "seek": 226488, "start": 2264.88, "end": 2268.0, "text": " looks like my thing. And you get a different image. I don't", "tokens": [50364, 1542, 411, 452, 551, 13, 400, 291, 483, 257, 819, 3256, 13, 286, 500, 380, 50520], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 575, "seek": 226488, "start": 2268.0, "end": 2271.2400000000002, "text": " have the image to show you here, but you get an image that looks", "tokens": [50520, 362, 264, 3256, 281, 855, 291, 510, 11, 457, 291, 483, 364, 3256, 300, 1542, 50682], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 576, "seek": 226488, "start": 2271.2400000000002, "end": 2273.8, "text": " kind of more church like it's a little bit, it'll be", "tokens": [50682, 733, 295, 544, 4128, 411, 309, 311, 257, 707, 857, 11, 309, 603, 312, 50810], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 577, "seek": 226488, "start": 2273.8, "end": 2276.8, "text": " architectural have the right kind of shape, the kind of right", "tokens": [50810, 26621, 362, 264, 558, 733, 295, 3909, 11, 264, 733, 295, 558, 50960], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 578, "seek": 226488, "start": 2276.8, "end": 2280.28, "text": " textures. But you know, it won't show my advisor here and", "tokens": [50960, 24501, 13, 583, 291, 458, 11, 309, 1582, 380, 855, 452, 19161, 510, 293, 51134], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 579, "seek": 226488, "start": 2280.28, "end": 2283.7200000000003, "text": " things like that. It'll be, it'll be this rough approximation", "tokens": [51134, 721, 411, 300, 13, 467, 603, 312, 11, 309, 603, 312, 341, 5903, 28023, 51306], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 580, "seek": 226488, "start": 2284.2400000000002, "end": 2290.04, "text": " for that my my image, but that is in the domain of what the GAN", "tokens": [51332, 337, 300, 452, 452, 3256, 11, 457, 300, 307, 294, 264, 9274, 295, 437, 264, 460, 1770, 51622], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 581, "seek": 226488, "start": 2290.04, "end": 2294.28, "text": " can actually generate. Then I say, Okay, that's not what I", "tokens": [51622, 393, 767, 8460, 13, 1396, 286, 584, 11, 1033, 11, 300, 311, 406, 437, 286, 51834], "temperature": 0.0, "avg_logprob": -0.14869504900120978, "compression_ratio": 1.7338129496402879, "no_speech_prob": 0.0007792277610860765}, {"id": 582, "seek": 229428, "start": 2294.28, "end": 2297.5600000000004, "text": " want to do. I want to actually edit this photo. So let's fine", "tokens": [50364, 528, 281, 360, 13, 286, 528, 281, 767, 8129, 341, 5052, 13, 407, 718, 311, 2489, 50528], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 583, "seek": 229428, "start": 2297.5600000000004, "end": 2304.6800000000003, "text": " tune that network so that so that given that same Z instead of", "tokens": [50528, 10864, 300, 3209, 370, 300, 370, 300, 2212, 300, 912, 1176, 2602, 295, 50884], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 584, "seek": 229428, "start": 2304.6800000000003, "end": 2307.4, "text": " generating the church that you would normally generate, I want", "tokens": [50884, 17746, 264, 4128, 300, 291, 576, 5646, 8460, 11, 286, 528, 51020], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 585, "seek": 229428, "start": 2307.4, "end": 2311.5600000000004, "text": " you to generate this image, change the weight slightly, get it", "tokens": [51020, 291, 281, 8460, 341, 3256, 11, 1319, 264, 3364, 4748, 11, 483, 309, 51228], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 586, "seek": 229428, "start": 2311.5600000000004, "end": 2316.52, "text": " so that that Z targets this. And, and so that's what I've done", "tokens": [51228, 370, 300, 300, 1176, 12911, 341, 13, 400, 11, 293, 370, 300, 311, 437, 286, 600, 1096, 51476], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 587, "seek": 229428, "start": 2316.52, "end": 2319.32, "text": " here. But I've tried I've done that in a way where I try not to", "tokens": [51476, 510, 13, 583, 286, 600, 3031, 286, 600, 1096, 300, 294, 257, 636, 689, 286, 853, 406, 281, 51616], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 588, "seek": 229428, "start": 2319.32, "end": 2322.2400000000002, "text": " change the weights too much. I just try to change the weights. I", "tokens": [51616, 1319, 264, 17443, 886, 709, 13, 286, 445, 853, 281, 1319, 264, 17443, 13, 286, 51762], "temperature": 0.0, "avg_logprob": -0.12208218133750082, "compression_ratio": 1.8493723849372385, "no_speech_prob": 0.0030743242241442204}, {"id": 589, "seek": 232224, "start": 2322.2799999999997, "end": 2324.7999999999997, "text": " change the fine grained layers. And I don't change the coarse", "tokens": [50366, 1319, 264, 2489, 1295, 2001, 7914, 13, 400, 286, 500, 380, 1319, 264, 39312, 50492], "temperature": 0.0, "avg_logprob": -0.16492857251848494, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.0007316063856706023}, {"id": 590, "seek": 232224, "start": 2324.7999999999997, "end": 2328.3199999999997, "text": " grain layers. And I, and I have a regularizer to make sure the", "tokens": [50492, 12837, 7914, 13, 400, 286, 11, 293, 286, 362, 257, 3890, 6545, 281, 652, 988, 264, 50668], "temperature": 0.0, "avg_logprob": -0.16492857251848494, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.0007316063856706023}, {"id": 591, "seek": 232224, "start": 2328.3199999999997, "end": 2333.7599999999998, "text": " weights don't change too much. And that you are changing the", "tokens": [50668, 17443, 500, 380, 1319, 886, 709, 13, 400, 300, 291, 366, 4473, 264, 50940], "temperature": 0.0, "avg_logprob": -0.16492857251848494, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.0007316063856706023}, {"id": 592, "seek": 232224, "start": 2333.7999999999997, "end": 2339.4399999999996, "text": " pre trained weights, or you are putting some extra weights, and", "tokens": [50942, 659, 8895, 17443, 11, 420, 291, 366, 3372, 512, 2857, 17443, 11, 293, 51224], "temperature": 0.0, "avg_logprob": -0.16492857251848494, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.0007316063856706023}, {"id": 593, "seek": 232224, "start": 2339.4399999999996, "end": 2343.9599999999996, "text": " then you place them. Oh, here, I'm actually changing the pre", "tokens": [51224, 550, 291, 1081, 552, 13, 876, 11, 510, 11, 286, 478, 767, 4473, 264, 659, 51450], "temperature": 0.0, "avg_logprob": -0.16492857251848494, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.0007316063856706023}, {"id": 594, "seek": 232224, "start": 2343.9599999999996, "end": 2348.64, "text": " trained weights. So the network has 15 layers. I'm actually", "tokens": [51450, 8895, 17443, 13, 407, 264, 3209, 575, 2119, 7914, 13, 286, 478, 767, 51684], "temperature": 0.0, "avg_logprob": -0.16492857251848494, "compression_ratio": 1.8974358974358974, "no_speech_prob": 0.0007316063856706023}, {"id": 595, "seek": 234864, "start": 2348.64, "end": 2352.48, "text": " going and I'm changing some of those layers. I'm not adding", "tokens": [50364, 516, 293, 286, 478, 4473, 512, 295, 729, 7914, 13, 286, 478, 406, 5127, 50556], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 596, "seek": 234864, "start": 2352.48, "end": 2356.92, "text": " anything new to the network. I'm just changing the weights in", "tokens": [50556, 1340, 777, 281, 264, 3209, 13, 286, 478, 445, 4473, 264, 17443, 294, 50778], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 597, "seek": 234864, "start": 2356.92, "end": 2361.48, "text": " the network itself. Now, now what I've done here is I've", "tokens": [50778, 264, 3209, 2564, 13, 823, 11, 586, 437, 286, 600, 1096, 510, 307, 286, 600, 51006], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 598, "seek": 234864, "start": 2361.48, "end": 2365.72, "text": " overfit the network to this one image. The network is not", "tokens": [51006, 670, 6845, 264, 3209, 281, 341, 472, 3256, 13, 440, 3209, 307, 406, 51218], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 599, "seek": 234864, "start": 2365.7999999999997, "end": 2370.04, "text": " generalizing this knowledge. So for example, you can draw", "tokens": [51222, 2674, 3319, 341, 3601, 13, 407, 337, 1365, 11, 291, 393, 2642, 51434], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 600, "seek": 234864, "start": 2370.04, "end": 2374.72, "text": " Antonio in this one image. But if I look in the network, if I", "tokens": [51434, 22527, 294, 341, 472, 3256, 13, 583, 498, 286, 574, 294, 264, 3209, 11, 498, 286, 51668], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 601, "seek": 234864, "start": 2374.72, "end": 2377.8399999999997, "text": " probe it a lot and see, can it ever generate Antonio in a", "tokens": [51668, 22715, 309, 257, 688, 293, 536, 11, 393, 309, 1562, 8460, 22527, 294, 257, 51824], "temperature": 0.0, "avg_logprob": -0.1083285914058179, "compression_ratio": 1.8078602620087336, "no_speech_prob": 0.006486379541456699}, {"id": 602, "seek": 237784, "start": 2377.84, "end": 2381.96, "text": " different setting in a different image? It cannot. In", "tokens": [50364, 819, 3287, 294, 257, 819, 3256, 30, 467, 2644, 13, 682, 50570], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 603, "seek": 237784, "start": 2381.96, "end": 2386.6400000000003, "text": " fact, you know, as much as we probe things, it really doesn't", "tokens": [50570, 1186, 11, 291, 458, 11, 382, 709, 382, 321, 22715, 721, 11, 309, 534, 1177, 380, 50804], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 604, "seek": 237784, "start": 2386.6400000000003, "end": 2389.1600000000003, "text": " look like we've changed the output of the network in any", "tokens": [50804, 574, 411, 321, 600, 3105, 264, 5598, 295, 264, 3209, 294, 604, 50930], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 605, "seek": 237784, "start": 2389.1600000000003, "end": 2393.7200000000003, "text": " meaningful way for any image, except for this one. It's almost", "tokens": [50930, 10995, 636, 337, 604, 3256, 11, 3993, 337, 341, 472, 13, 467, 311, 1920, 51158], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 606, "seek": 237784, "start": 2393.7200000000003, "end": 2397.48, "text": " like, you know, the network generates this really complicated", "tokens": [51158, 411, 11, 291, 458, 11, 264, 3209, 23815, 341, 534, 6179, 51346], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 607, "seek": 237784, "start": 2397.48, "end": 2401.52, "text": " manifold of realistic images. And we've told we've picked up one", "tokens": [51346, 47138, 295, 12465, 5267, 13, 400, 321, 600, 1907, 321, 600, 6183, 493, 472, 51548], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 608, "seek": 237784, "start": 2401.52, "end": 2404.6800000000003, "text": " point of the manifold, and we've dragged it over to pass to", "tokens": [51548, 935, 295, 264, 47138, 11, 293, 321, 600, 25717, 309, 670, 281, 1320, 281, 51706], "temperature": 0.0, "avg_logprob": -0.10120066890010128, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.000969382468611002}, {"id": 609, "seek": 240468, "start": 2404.68, "end": 2408.16, "text": " this point. But we've done it in a very local way. So it's", "tokens": [50364, 341, 935, 13, 583, 321, 600, 1096, 309, 294, 257, 588, 2654, 636, 13, 407, 309, 311, 50538], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 610, "seek": 240468, "start": 2408.16, "end": 2411.2799999999997, "text": " really not affected any other points of what the GAN is", "tokens": [50538, 534, 406, 8028, 604, 661, 2793, 295, 437, 264, 460, 1770, 307, 50694], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 611, "seek": 240468, "start": 2411.2799999999997, "end": 2418.2, "text": " generating. And so so but but for the purposes of doing this", "tokens": [50694, 17746, 13, 400, 370, 370, 457, 457, 337, 264, 9932, 295, 884, 341, 51040], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 612, "seek": 240468, "start": 2418.2, "end": 2420.12, "text": " kind of application, it doesn't matter that it's not", "tokens": [51040, 733, 295, 3861, 11, 309, 1177, 380, 1871, 300, 309, 311, 406, 51136], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 613, "seek": 240468, "start": 2420.12, "end": 2422.6, "text": " generalizing because the user doesn't care about a different", "tokens": [51136, 2674, 3319, 570, 264, 4195, 1177, 380, 1127, 466, 257, 819, 51260], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 614, "seek": 240468, "start": 2422.6, "end": 2425.0, "text": " photo, they just care about their own photo. So it's a pretty", "tokens": [51260, 5052, 11, 436, 445, 1127, 466, 641, 1065, 5052, 13, 407, 309, 311, 257, 1238, 51380], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 615, "seek": 240468, "start": 2425.0, "end": 2429.04, "text": " cool. It's pretty cool technique anyway, even though it's sort", "tokens": [51380, 1627, 13, 467, 311, 1238, 1627, 6532, 4033, 11, 754, 1673, 309, 311, 1333, 51582], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 616, "seek": 240468, "start": 2429.04, "end": 2432.9199999999996, "text": " of not the classical goal of machine learning. Does that make", "tokens": [51582, 295, 406, 264, 13735, 3387, 295, 3479, 2539, 13, 4402, 300, 652, 51776], "temperature": 0.0, "avg_logprob": -0.11347420753971223, "compression_ratio": 1.6701754385964913, "no_speech_prob": 0.0034817964769899845}, {"id": 617, "seek": 243292, "start": 2432.96, "end": 2437.84, "text": " sense? Yeah, it does. And I wonder if the user has more", "tokens": [50366, 2020, 30, 865, 11, 309, 775, 13, 400, 286, 2441, 498, 264, 4195, 575, 544, 50610], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 618, "seek": 243292, "start": 2437.84, "end": 2443.76, "text": " images of themselves with that over time, and make the network", "tokens": [50610, 5267, 295, 2969, 365, 300, 670, 565, 11, 293, 652, 264, 3209, 50906], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 619, "seek": 243292, "start": 2443.8, "end": 2445.64, "text": " even better in generation?", "tokens": [50908, 754, 1101, 294, 5125, 30, 51000], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 620, "seek": 243292, "start": 2447.44, "end": 2450.48, "text": " Yes, this is the big question. And I played with this for many", "tokens": [51090, 1079, 11, 341, 307, 264, 955, 1168, 13, 400, 286, 3737, 365, 341, 337, 867, 51242], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 621, "seek": 243292, "start": 2450.48, "end": 2452.7200000000003, "text": " months, and I haven't got it to work. And if anybody can figure", "tokens": [51242, 2493, 11, 293, 286, 2378, 380, 658, 309, 281, 589, 13, 400, 498, 4472, 393, 2573, 51354], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 622, "seek": 243292, "start": 2452.7200000000003, "end": 2454.76, "text": " out how to get to work, I feel like it's one of the holy grails", "tokens": [51354, 484, 577, 281, 483, 281, 589, 11, 286, 841, 411, 309, 311, 472, 295, 264, 10622, 1295, 4174, 51456], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 623, "seek": 243292, "start": 2455.16, "end": 2458.16, "text": " of like how to add a new thing to a generator. So like, the", "tokens": [51476, 295, 411, 577, 281, 909, 257, 777, 551, 281, 257, 19265, 13, 407, 411, 11, 264, 51626], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 624, "seek": 243292, "start": 2458.16, "end": 2461.12, "text": " generator knows about all these things that knows about trees", "tokens": [51626, 19265, 3255, 466, 439, 613, 721, 300, 3255, 466, 5852, 51774], "temperature": 0.0, "avg_logprob": -0.12010752105712891, "compression_ratio": 1.741444866920152, "no_speech_prob": 0.001837906427681446}, {"id": 625, "seek": 246112, "start": 2461.12, "end": 2466.4, "text": " and knows about all these architectural pieces, you know. But", "tokens": [50364, 293, 3255, 466, 439, 613, 26621, 3755, 11, 291, 458, 13, 583, 50628], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 626, "seek": 246112, "start": 2466.4, "end": 2468.88, "text": " what if I came along with something new? What if I was", "tokens": [50628, 437, 498, 286, 1361, 2051, 365, 746, 777, 30, 708, 498, 286, 390, 50752], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 627, "seek": 246112, "start": 2470.68, "end": 2474.3599999999997, "text": " what if my what if I what if I work for GM and I want to sell", "tokens": [50842, 437, 498, 452, 437, 498, 286, 437, 498, 286, 589, 337, 16609, 293, 286, 528, 281, 3607, 51026], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 628, "seek": 246112, "start": 2474.3599999999997, "end": 2477.04, "text": " Cadillacs, then I then I might come to one of these models and", "tokens": [51026, 22323, 373, 44937, 11, 550, 286, 550, 286, 1062, 808, 281, 472, 295, 613, 5245, 293, 51160], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 629, "seek": 246112, "start": 2477.04, "end": 2479.64, "text": " say, you know what, you should draw cars. In fact, I want you to", "tokens": [51160, 584, 11, 291, 458, 437, 11, 291, 820, 2642, 5163, 13, 682, 1186, 11, 286, 528, 291, 281, 51290], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 630, "seek": 246112, "start": 2479.64, "end": 2482.68, "text": " draw specific cars. I want you to draw Cadillacs in front of all", "tokens": [51290, 2642, 2685, 5163, 13, 286, 528, 291, 281, 2642, 22323, 373, 44937, 294, 1868, 295, 439, 51442], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 631, "seek": 246112, "start": 2482.68, "end": 2487.7599999999998, "text": " these buildings. How would I add Cadillacs to my model or add", "tokens": [51442, 613, 7446, 13, 1012, 576, 286, 909, 22323, 373, 44937, 281, 452, 2316, 420, 909, 51696], "temperature": 0.0, "avg_logprob": -0.14533089428413204, "compression_ratio": 1.819327731092437, "no_speech_prob": 0.0005527248722501099}, {"id": 632, "seek": 248776, "start": 2487.76, "end": 2491.1200000000003, "text": " Antonio to my model or something like that? And we don't know how", "tokens": [50364, 22527, 281, 452, 2316, 420, 746, 411, 300, 30, 400, 321, 500, 380, 458, 577, 50532], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 633, "seek": 248776, "start": 2491.1200000000003, "end": 2493.4, "text": " to do that yet. Although I'm going to show you a little bit of", "tokens": [50532, 281, 360, 300, 1939, 13, 5780, 286, 478, 516, 281, 855, 291, 257, 707, 857, 295, 50646], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 634, "seek": 248776, "start": 2493.4, "end": 2498.2000000000003, "text": " work, where we can do something that's very similar. And if I", "tokens": [50646, 589, 11, 689, 321, 393, 360, 746, 300, 311, 588, 2531, 13, 400, 498, 286, 50886], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 635, "seek": 248776, "start": 2498.2000000000003, "end": 2501.1200000000003, "text": " don't know if I have time to, to go over this, but I'm going to", "tokens": [50886, 500, 380, 458, 498, 286, 362, 565, 281, 11, 281, 352, 670, 341, 11, 457, 286, 478, 516, 281, 51032], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 636, "seek": 248776, "start": 2501.1600000000003, "end": 2503.44, "text": " I'm going to zoom through this because I'm so excited by this", "tokens": [51034, 286, 478, 516, 281, 8863, 807, 341, 570, 286, 478, 370, 2919, 538, 341, 51148], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 637, "seek": 248776, "start": 2503.44, "end": 2510.6800000000003, "text": " work. So, so, so it's motivated by this, this sort of question,", "tokens": [51148, 589, 13, 407, 11, 370, 11, 370, 309, 311, 14515, 538, 341, 11, 341, 1333, 295, 1168, 11, 51510], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 638, "seek": 248776, "start": 2510.7200000000003, "end": 2515.6400000000003, "text": " which is, you know, we have a model of like drawing towers,", "tokens": [51512, 597, 307, 11, 291, 458, 11, 321, 362, 257, 2316, 295, 411, 6316, 25045, 11, 51758], "temperature": 0.0, "avg_logprob": -0.10639014095067978, "compression_ratio": 1.76, "no_speech_prob": 0.007118006236851215}, {"id": 639, "seek": 251564, "start": 2515.64, "end": 2519.4, "text": " let's say, right? But there are things in the world that we might", "tokens": [50364, 718, 311, 584, 11, 558, 30, 583, 456, 366, 721, 294, 264, 1002, 300, 321, 1062, 50552], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 640, "seek": 251564, "start": 2519.4, "end": 2523.4, "text": " want to model that we don't have a data set for. For example, you", "tokens": [50552, 528, 281, 2316, 300, 321, 500, 380, 362, 257, 1412, 992, 337, 13, 1171, 1365, 11, 291, 50752], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 641, "seek": 251564, "start": 2523.4, "end": 2527.08, "text": " know, in in in Decatur County, Illinois, there's this courthouse", "tokens": [50752, 458, 11, 294, 294, 294, 12427, 19493, 6658, 11, 17508, 11, 456, 311, 341, 1005, 392, 1316, 50936], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 642, "seek": 251564, "start": 2527.08, "end": 2529.8799999999997, "text": " that has a tree growing out the top of the tower. It started", "tokens": [50936, 300, 575, 257, 4230, 4194, 484, 264, 1192, 295, 264, 10567, 13, 467, 1409, 51076], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 643, "seek": 251564, "start": 2529.8799999999997, "end": 2532.7999999999997, "text": " growing out there by accident, but the people in the town love", "tokens": [51076, 4194, 484, 456, 538, 6398, 11, 457, 264, 561, 294, 264, 3954, 959, 51222], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 644, "seek": 251564, "start": 2532.7999999999997, "end": 2536.24, "text": " it. And so but it's but there's no so like if I want to get a", "tokens": [51222, 309, 13, 400, 370, 457, 309, 311, 457, 456, 311, 572, 370, 411, 498, 286, 528, 281, 483, 257, 51394], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 645, "seek": 251564, "start": 2536.24, "end": 2540.3599999999997, "text": " generative model to draw trees growing out of tops of towers, I", "tokens": [51394, 1337, 1166, 2316, 281, 2642, 5852, 4194, 484, 295, 22836, 295, 25045, 11, 286, 51600], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 646, "seek": 251564, "start": 2540.3599999999997, "end": 2544.24, "text": " can't do that in a classical way because I can't create a big", "tokens": [51600, 393, 380, 360, 300, 294, 257, 13735, 636, 570, 286, 393, 380, 1884, 257, 955, 51794], "temperature": 0.0, "avg_logprob": -0.10710242078020855, "compression_ratio": 1.745704467353952, "no_speech_prob": 0.0006262031383812428}, {"id": 647, "seek": 254424, "start": 2544.24, "end": 2547.8399999999997, "text": " data set of a million buildings that have trees growing on the", "tokens": [50364, 1412, 992, 295, 257, 2459, 7446, 300, 362, 5852, 4194, 322, 264, 50544], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 648, "seek": 254424, "start": 2547.8399999999997, "end": 2550.52, "text": " top of the towers, because they don't exist. It's just this one.", "tokens": [50544, 1192, 295, 264, 25045, 11, 570, 436, 500, 380, 2514, 13, 467, 311, 445, 341, 472, 13, 50678], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 649, "seek": 254424, "start": 2551.3599999999997, "end": 2556.64, "text": " And so now if if the point is I want to generate images of this", "tokens": [50720, 400, 370, 586, 498, 498, 264, 935, 307, 286, 528, 281, 8460, 5267, 295, 341, 50984], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 650, "seek": 254424, "start": 2556.64, "end": 2560.8399999999997, "text": " type, you know, well, I could use a regular image editor, I", "tokens": [50984, 2010, 11, 291, 458, 11, 731, 11, 286, 727, 764, 257, 3890, 3256, 9839, 11, 286, 51194], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 651, "seek": 254424, "start": 2560.8399999999997, "end": 2563.2, "text": " can take any building of a tower, and of course, I can stick a", "tokens": [51194, 393, 747, 604, 2390, 295, 257, 10567, 11, 293, 295, 1164, 11, 286, 393, 2897, 257, 51312], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 652, "seek": 254424, "start": 2563.2, "end": 2567.0, "text": " tree on it, right? I could use my, you know, again, painting", "tokens": [51312, 4230, 322, 309, 11, 558, 30, 286, 727, 764, 452, 11, 291, 458, 11, 797, 11, 5370, 51502], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 653, "seek": 254424, "start": 2567.0, "end": 2570.08, "text": " method to, you know, activate tree neurons or something like", "tokens": [51502, 3170, 281, 11, 291, 458, 11, 13615, 4230, 22027, 420, 746, 411, 51656], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 654, "seek": 254424, "start": 2570.08, "end": 2573.2799999999997, "text": " that. But no, no, that's not what I'm asking. I'm asking this", "tokens": [51656, 300, 13, 583, 572, 11, 572, 11, 300, 311, 406, 437, 286, 478, 3365, 13, 286, 478, 3365, 341, 51816], "temperature": 0.0, "avg_logprob": -0.15826802858164613, "compression_ratio": 1.7473684210526317, "no_speech_prob": 0.0005192494136281312}, {"id": 655, "seek": 257328, "start": 2573.28, "end": 2577.2400000000002, "text": " other question of like, how can we stick tree towers into my", "tokens": [50364, 661, 1168, 295, 411, 11, 577, 393, 321, 2897, 4230, 25045, 666, 452, 50562], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 656, "seek": 257328, "start": 2577.2400000000002, "end": 2581.1600000000003, "text": " model? How do I modify the model to have this new concept in it?", "tokens": [50562, 2316, 30, 1012, 360, 286, 16927, 264, 2316, 281, 362, 341, 777, 3410, 294, 309, 30, 50758], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 657, "seek": 257328, "start": 2581.48, "end": 2583.88, "text": " Like I start with this model that has all these weights that", "tokens": [50774, 1743, 286, 722, 365, 341, 2316, 300, 575, 439, 613, 17443, 300, 50894], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 658, "seek": 257328, "start": 2583.92, "end": 2586.8, "text": " encode all these rules for how buildings look and things like", "tokens": [50896, 2058, 1429, 439, 613, 4474, 337, 577, 7446, 574, 293, 721, 411, 51040], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 659, "seek": 257328, "start": 2586.8, "end": 2591.0800000000004, "text": " that. And I want to create a new model that has new weights that", "tokens": [51040, 300, 13, 400, 286, 528, 281, 1884, 257, 777, 2316, 300, 575, 777, 17443, 300, 51254], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 660, "seek": 257328, "start": 2591.0800000000004, "end": 2594.1200000000003, "text": " encode new rules. So for example, the old model could generate", "tokens": [51254, 2058, 1429, 777, 4474, 13, 407, 337, 1365, 11, 264, 1331, 2316, 727, 8460, 51406], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 661, "seek": 257328, "start": 2594.1200000000003, "end": 2597.2000000000003, "text": " all these buildings that of towers that look normal have", "tokens": [51406, 439, 613, 7446, 300, 295, 25045, 300, 574, 2710, 362, 51560], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 662, "seek": 257328, "start": 2597.2000000000003, "end": 2600.88, "text": " spires, you know, pointy tops. And I want to make a new model", "tokens": [51560, 637, 3145, 11, 291, 458, 11, 935, 88, 22836, 13, 400, 286, 528, 281, 652, 257, 777, 2316, 51744], "temperature": 0.0, "avg_logprob": -0.10002516955137253, "compression_ratio": 1.875, "no_speech_prob": 0.001648196135647595}, {"id": 663, "seek": 260088, "start": 2600.88, "end": 2604.56, "text": " that has weights, they encode a different rule, so that like,", "tokens": [50364, 300, 575, 17443, 11, 436, 2058, 1429, 257, 819, 4978, 11, 370, 300, 411, 11, 50548], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 664, "seek": 260088, "start": 2604.6800000000003, "end": 2608.2000000000003, "text": " they have trees growing out the top, right, or any rule that I", "tokens": [50554, 436, 362, 5852, 4194, 484, 264, 1192, 11, 558, 11, 420, 604, 4978, 300, 286, 50730], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 665, "seek": 260088, "start": 2608.2000000000003, "end": 2612.8, "text": " choose, right? And it turns out that this is actually possible.", "tokens": [50730, 2826, 11, 558, 30, 400, 309, 4523, 484, 300, 341, 307, 767, 1944, 13, 50960], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 666, "seek": 260088, "start": 2612.8, "end": 2616.1600000000003, "text": " So this is different from the technique that I showed you", "tokens": [50960, 407, 341, 307, 819, 490, 264, 6532, 300, 286, 4712, 291, 51128], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 667, "seek": 260088, "start": 2616.1600000000003, "end": 2619.08, "text": " before, because in this technique, it's actually", "tokens": [51128, 949, 11, 570, 294, 341, 6532, 11, 309, 311, 767, 51274], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 668, "seek": 260088, "start": 2619.08, "end": 2623.2400000000002, "text": " generalizing. This is, you know, if you use this technique, not", "tokens": [51274, 2674, 3319, 13, 639, 307, 11, 291, 458, 11, 498, 291, 764, 341, 6532, 11, 406, 51482], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 669, "seek": 260088, "start": 2623.2400000000002, "end": 2628.12, "text": " only you change the output of one image of the GAN to have like", "tokens": [51482, 787, 291, 1319, 264, 5598, 295, 472, 3256, 295, 264, 460, 1770, 281, 362, 411, 51726], "temperature": 0.0, "avg_logprob": -0.15209707192012242, "compression_ratio": 1.7195121951219512, "no_speech_prob": 0.0013248514151200652}, {"id": 670, "seek": 262812, "start": 2628.12, "end": 2633.48, "text": " some effect, but we can actually change the outputs for a whole", "tokens": [50364, 512, 1802, 11, 457, 321, 393, 767, 1319, 264, 23930, 337, 257, 1379, 50632], "temperature": 0.0, "avg_logprob": -0.11349463708621939, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.003536840435117483}, {"id": 671, "seek": 262812, "start": 2633.48, "end": 2638.3599999999997, "text": " class of, you know, a large subset of the outputs of the GANs to", "tokens": [50632, 1508, 295, 11, 291, 458, 11, 257, 2416, 25993, 295, 264, 23930, 295, 264, 460, 1770, 82, 281, 50876], "temperature": 0.0, "avg_logprob": -0.11349463708621939, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.003536840435117483}, {"id": 672, "seek": 262812, "start": 2638.3599999999997, "end": 2644.0, "text": " follow a different rule, like any pointy tower output will have", "tokens": [50876, 1524, 257, 819, 4978, 11, 411, 604, 935, 88, 10567, 5598, 486, 362, 51158], "temperature": 0.0, "avg_logprob": -0.11349463708621939, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.003536840435117483}, {"id": 673, "seek": 262812, "start": 2644.04, "end": 2648.0, "text": " trees instead of pointy towers. And so so I'll just show you a", "tokens": [51160, 5852, 2602, 295, 935, 88, 25045, 13, 400, 370, 370, 286, 603, 445, 855, 291, 257, 51358], "temperature": 0.0, "avg_logprob": -0.11349463708621939, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.003536840435117483}, {"id": 674, "seek": 262812, "start": 2648.0, "end": 2650.3599999999997, "text": " little bit of like the interaction here of what it", "tokens": [51358, 707, 857, 295, 411, 264, 9285, 510, 295, 437, 309, 51476], "temperature": 0.0, "avg_logprob": -0.11349463708621939, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.003536840435117483}, {"id": 675, "seek": 262812, "start": 2650.3599999999997, "end": 2655.2799999999997, "text": " looks like when you get our method into an application. So I", "tokens": [51476, 1542, 411, 562, 291, 483, 527, 3170, 666, 364, 3861, 13, 407, 286, 51722], "temperature": 0.0, "avg_logprob": -0.11349463708621939, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.003536840435117483}, {"id": 676, "seek": 265528, "start": 2656.2000000000003, "end": 2658.6800000000003, "text": " let's see if I can get this to work. So here, what I'm showing", "tokens": [50410, 718, 311, 536, 498, 286, 393, 483, 341, 281, 589, 13, 407, 510, 11, 437, 286, 478, 4099, 50534], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 677, "seek": 265528, "start": 2658.6800000000003, "end": 2662.84, "text": " you is the output of a style GAN be to generating churches, you", "tokens": [50534, 291, 307, 264, 5598, 295, 257, 3758, 460, 1770, 312, 281, 17746, 15381, 11, 291, 50742], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 678, "seek": 265528, "start": 2662.84, "end": 2666.6800000000003, "text": " can kind of, and there are three parts of this UI, there's an", "tokens": [50742, 393, 733, 295, 11, 293, 456, 366, 1045, 3166, 295, 341, 15682, 11, 456, 311, 364, 50934], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 679, "seek": 265528, "start": 2666.6800000000003, "end": 2670.92, "text": " image viewer, then what you do is you can select a rule that you", "tokens": [50934, 3256, 16767, 11, 550, 437, 291, 360, 307, 291, 393, 3048, 257, 4978, 300, 291, 51146], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 680, "seek": 265528, "start": 2670.92, "end": 2673.44, "text": " want to change, and then you can specify how you want to change", "tokens": [51146, 528, 281, 1319, 11, 293, 550, 291, 393, 16500, 577, 291, 528, 281, 1319, 51272], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 681, "seek": 265528, "start": 2673.44, "end": 2675.8, "text": " your rule. So there's three parts of this little user", "tokens": [51272, 428, 4978, 13, 407, 456, 311, 1045, 3166, 295, 341, 707, 4195, 51390], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 682, "seek": 265528, "start": 2675.8, "end": 2679.0400000000004, "text": " interface. And I'll just show you sort of how how the effect", "tokens": [51390, 9226, 13, 400, 286, 603, 445, 855, 291, 1333, 295, 577, 577, 264, 1802, 51552], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 683, "seek": 265528, "start": 2679.0400000000004, "end": 2683.52, "text": " looks by showing you one of the interactions. So you can kind of", "tokens": [51552, 1542, 538, 4099, 291, 472, 295, 264, 13280, 13, 407, 291, 393, 733, 295, 51776], "temperature": 0.0, "avg_logprob": -0.1734942688661463, "compression_ratio": 1.8544776119402986, "no_speech_prob": 0.0042615775018930435}, {"id": 684, "seek": 268352, "start": 2683.52, "end": 2688.56, "text": " use the image viewer to scroll through lots of examples of of", "tokens": [50364, 764, 264, 3256, 16767, 281, 11369, 807, 3195, 295, 5110, 295, 295, 50616], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 685, "seek": 268352, "start": 2688.56, "end": 2692.4, "text": " what the the generator is capable of generating. And then we", "tokens": [50616, 437, 264, 264, 19265, 307, 8189, 295, 17746, 13, 400, 550, 321, 50808], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 686, "seek": 268352, "start": 2692.4, "end": 2694.8, "text": " can go to these examples and we can say, Hey, you know what I'm", "tokens": [50808, 393, 352, 281, 613, 5110, 293, 321, 393, 584, 11, 1911, 11, 291, 458, 437, 286, 478, 50928], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 687, "seek": 268352, "start": 2694.8, "end": 2698.7599999999998, "text": " really interested in? I'm interested in this rule of how", "tokens": [50928, 534, 3102, 294, 30, 286, 478, 3102, 294, 341, 4978, 295, 577, 51126], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 688, "seek": 268352, "start": 2698.7599999999998, "end": 2702.2, "text": " to generate pointy towers. And so I can select a few pointy", "tokens": [51126, 281, 8460, 935, 88, 25045, 13, 400, 370, 286, 393, 3048, 257, 1326, 935, 88, 51298], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 689, "seek": 268352, "start": 2702.2, "end": 2706.32, "text": " towers. And you can think of this as what I'm looking for is", "tokens": [51298, 25045, 13, 400, 291, 393, 519, 295, 341, 382, 437, 286, 478, 1237, 337, 307, 51504], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 690, "seek": 268352, "start": 2706.32, "end": 2709.36, "text": " the neurons that are responsible for the shape. And so I can", "tokens": [51504, 264, 22027, 300, 366, 6250, 337, 264, 3909, 13, 400, 370, 286, 393, 51656], "temperature": 0.0, "avg_logprob": -0.11126790727887835, "compression_ratio": 1.8398268398268398, "no_speech_prob": 0.0018097244901582599}, {"id": 691, "seek": 270936, "start": 2709.36, "end": 2713.92, "text": " select a few examples and I can say, Hey, what other, what other", "tokens": [50364, 3048, 257, 1326, 5110, 293, 286, 393, 584, 11, 1911, 11, 437, 661, 11, 437, 661, 50592], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 692, "seek": 270936, "start": 2713.92, "end": 2717.6, "text": " outputs of the GAN share the same representation? And, and it'll", "tokens": [50592, 23930, 295, 264, 460, 1770, 2073, 264, 912, 10290, 30, 400, 11, 293, 309, 603, 50776], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 693, "seek": 270936, "start": 2717.6, "end": 2720.1200000000003, "text": " show me, Oh, yes, the GAN is generalizing this way, these", "tokens": [50776, 855, 385, 11, 876, 11, 2086, 11, 264, 460, 1770, 307, 2674, 3319, 341, 636, 11, 613, 50902], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 694, "seek": 270936, "start": 2720.1200000000003, "end": 2723.52, "text": " other pointy towers are represented the same way as the", "tokens": [50902, 661, 935, 88, 25045, 366, 10379, 264, 912, 636, 382, 264, 51072], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 695, "seek": 270936, "start": 2723.52, "end": 2727.04, "text": " ones that you chose. And then I can go and I can say, All right,", "tokens": [51072, 2306, 300, 291, 5111, 13, 400, 550, 286, 393, 352, 293, 286, 393, 584, 11, 1057, 558, 11, 51248], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 696, "seek": 270936, "start": 2727.04, "end": 2733.4, "text": " I want to redefine how these pointy towers are rendered by", "tokens": [51248, 286, 528, 281, 38818, 533, 577, 613, 935, 88, 25045, 366, 28748, 538, 51566], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 697, "seek": 270936, "start": 2733.4, "end": 2736.6400000000003, "text": " this generator, I want them to be rendered like this tree here.", "tokens": [51566, 341, 19265, 11, 286, 528, 552, 281, 312, 28748, 411, 341, 4230, 510, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1467205047607422, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.0046084607020020485}, {"id": 698, "seek": 273664, "start": 2736.64, "end": 2741.24, "text": " So I can copy the tree from one output of the generator, and I", "tokens": [50364, 407, 286, 393, 5055, 264, 4230, 490, 472, 5598, 295, 264, 19265, 11, 293, 286, 50594], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 699, "seek": 273664, "start": 2741.24, "end": 2745.68, "text": " can paste it into where I would like that tree to show up. I", "tokens": [50594, 393, 9163, 309, 666, 689, 286, 576, 411, 300, 4230, 281, 855, 493, 13, 286, 50816], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 700, "seek": 273664, "start": 2745.68, "end": 2749.44, "text": " wanted to show up instead of pointy towers. And then I can", "tokens": [50816, 1415, 281, 855, 493, 2602, 295, 935, 88, 25045, 13, 400, 550, 286, 393, 51004], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 701, "seek": 273664, "start": 2749.44, "end": 2754.0, "text": " say, Okay, now insert this new rule into the model, compute", "tokens": [51004, 584, 11, 1033, 11, 586, 8969, 341, 777, 4978, 666, 264, 2316, 11, 14722, 51232], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 702, "seek": 273664, "start": 2754.0, "end": 2757.8399999999997, "text": " what the right changes to change the model. And then after I do", "tokens": [51232, 437, 264, 558, 2962, 281, 1319, 264, 2316, 13, 400, 550, 934, 286, 360, 51424], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 703, "seek": 273664, "start": 2757.8399999999997, "end": 2762.24, "text": " that, that takes about a second to do the math to figure out how", "tokens": [51424, 300, 11, 300, 2516, 466, 257, 1150, 281, 360, 264, 5221, 281, 2573, 484, 577, 51644], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 704, "seek": 273664, "start": 2762.24, "end": 2766.08, "text": " to change a rule. And then after I do that, then I get the GAN to", "tokens": [51644, 281, 1319, 257, 4978, 13, 400, 550, 934, 286, 360, 300, 11, 550, 286, 483, 264, 460, 1770, 281, 51836], "temperature": 0.0, "avg_logprob": -0.10739102129076349, "compression_ratio": 1.8284518828451883, "no_speech_prob": 0.0010985027765855193}, {"id": 705, "seek": 276608, "start": 2766.12, "end": 2770.48, "text": " generate new images. And, and they look like this, you know,", "tokens": [50366, 8460, 777, 5267, 13, 400, 11, 293, 436, 574, 411, 341, 11, 291, 458, 11, 50584], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 706, "seek": 276608, "start": 2770.52, "end": 2774.7599999999998, "text": " like the tops of the towers, now have trees on them instead. So", "tokens": [50586, 411, 264, 22836, 295, 264, 25045, 11, 586, 362, 5852, 322, 552, 2602, 13, 407, 50798], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 707, "seek": 276608, "start": 2774.7599999999998, "end": 2777.6, "text": " you can see how that looks. And it's not just affecting that", "tokens": [50798, 291, 393, 536, 577, 300, 1542, 13, 400, 309, 311, 406, 445, 17476, 300, 50940], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 708, "seek": 276608, "start": 2777.6, "end": 2782.68, "text": " one image, it's affecting all the pointy tower images. I can do a", "tokens": [50940, 472, 3256, 11, 309, 311, 17476, 439, 264, 935, 88, 10567, 5267, 13, 286, 393, 360, 257, 51194], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 709, "seek": 276608, "start": 2782.68, "end": 2786.4, "text": " little search for more pointy tower images. And, and do I have", "tokens": [51194, 707, 3164, 337, 544, 935, 88, 10567, 5267, 13, 400, 11, 293, 360, 286, 362, 51380], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 710, "seek": 276608, "start": 2786.4, "end": 2789.7599999999998, "text": " that here in my thing? Yeah, so here's a search for more pointy", "tokens": [51380, 300, 510, 294, 452, 551, 30, 865, 11, 370, 510, 311, 257, 3164, 337, 544, 935, 88, 51548], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 711, "seek": 276608, "start": 2789.7599999999998, "end": 2792.12, "text": " tower images. And you can see they, you know, they all have", "tokens": [51548, 10567, 5267, 13, 400, 291, 393, 536, 436, 11, 291, 458, 11, 436, 439, 362, 51666], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 712, "seek": 276608, "start": 2792.12, "end": 2796.04, "text": " gotten these trees sprouting out the top of it, like some sort", "tokens": [51666, 5768, 613, 5852, 6103, 24500, 484, 264, 1192, 295, 309, 11, 411, 512, 1333, 51862], "temperature": 0.0, "avg_logprob": -0.10985249110630581, "compression_ratio": 2.0201612903225805, "no_speech_prob": 0.004752764478325844}, {"id": 713, "seek": 279604, "start": 2796.04, "end": 2801.88, "text": " of dystopian tree world where vegetation is taking over the", "tokens": [50364, 295, 14584, 13559, 952, 4230, 1002, 689, 28769, 307, 1940, 670, 264, 50656], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 714, "seek": 279604, "start": 2801.88, "end": 2806.6, "text": " planet. And, and so you can do this in a bunch of things, I'm", "tokens": [50656, 5054, 13, 400, 11, 293, 370, 291, 393, 360, 341, 294, 257, 3840, 295, 721, 11, 286, 478, 50892], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 715, "seek": 279604, "start": 2806.6, "end": 2810.88, "text": " gonna skip over some of the technical things here, or some", "tokens": [50892, 799, 10023, 670, 512, 295, 264, 6191, 721, 510, 11, 420, 512, 51106], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 716, "seek": 279604, "start": 2810.88, "end": 2813.64, "text": " of the other examples of what you can do here. You can edit", "tokens": [51106, 295, 264, 661, 5110, 295, 437, 291, 393, 360, 510, 13, 509, 393, 8129, 51244], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 717, "seek": 279604, "start": 2813.64, "end": 2816.6, "text": " reflections and things like that. I've got other videos that you", "tokens": [51244, 30679, 293, 721, 411, 300, 13, 286, 600, 658, 661, 2145, 300, 291, 51392], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 718, "seek": 279604, "start": 2816.6, "end": 2819.4, "text": " can look for on the internet. But I wanted to show you a sense", "tokens": [51392, 393, 574, 337, 322, 264, 4705, 13, 583, 286, 1415, 281, 855, 291, 257, 2020, 51532], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 719, "seek": 279604, "start": 2819.4, "end": 2822.8, "text": " for what we're doing inside when we do this kind of thing. So", "tokens": [51532, 337, 437, 321, 434, 884, 1854, 562, 321, 360, 341, 733, 295, 551, 13, 407, 51702], "temperature": 0.0, "avg_logprob": -0.12943572998046876, "compression_ratio": 1.7269076305220883, "no_speech_prob": 0.0014544965233653784}, {"id": 720, "seek": 282280, "start": 2822.88, "end": 2827.28, "text": " like I showed you before that again, has is like, got all these", "tokens": [50368, 411, 286, 4712, 291, 949, 300, 797, 11, 575, 307, 411, 11, 658, 439, 613, 50588], "temperature": 0.0, "avg_logprob": -0.1649970907914011, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.003271940629929304}, {"id": 721, "seek": 282280, "start": 2827.28, "end": 2831.92, "text": " convolutional layers stacked up, it's about 15 layers. And what", "tokens": [50588, 45216, 304, 7914, 28867, 493, 11, 309, 311, 466, 2119, 7914, 13, 400, 437, 50820], "temperature": 0.0, "avg_logprob": -0.1649970907914011, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.003271940629929304}, {"id": 722, "seek": 282280, "start": 2831.92, "end": 2836.1200000000003, "text": " what, what, what the discovery was that led to this application", "tokens": [50820, 437, 11, 437, 11, 437, 264, 12114, 390, 300, 4684, 281, 341, 3861, 51030], "temperature": 0.0, "avg_logprob": -0.1649970907914011, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.003271940629929304}, {"id": 723, "seek": 282280, "start": 2836.6400000000003, "end": 2840.92, "text": " was that each one of those layers can be thought of as", "tokens": [51056, 390, 300, 1184, 472, 295, 729, 7914, 393, 312, 1194, 295, 382, 51270], "temperature": 0.0, "avg_logprob": -0.1649970907914011, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.003271940629929304}, {"id": 724, "seek": 282280, "start": 2840.92, "end": 2846.0, "text": " solving a very simple, separate problem from the other layers.", "tokens": [51270, 12606, 257, 588, 2199, 11, 4994, 1154, 490, 264, 661, 7914, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1649970907914011, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.003271940629929304}, {"id": 725, "seek": 282280, "start": 2846.36, "end": 2849.8, "text": " And what is that simple problem? It, it can be treated like a", "tokens": [51542, 400, 437, 307, 300, 2199, 1154, 30, 467, 11, 309, 393, 312, 8668, 411, 257, 51714], "temperature": 0.0, "avg_logprob": -0.1649970907914011, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.003271940629929304}, {"id": 726, "seek": 284980, "start": 2849.8, "end": 2854.84, "text": " memory, where the layer is solving this problem of matching", "tokens": [50364, 4675, 11, 689, 264, 4583, 307, 12606, 341, 1154, 295, 14324, 50616], "temperature": 0.0, "avg_logprob": -0.11701729477092784, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0015007604379206896}, {"id": 727, "seek": 284980, "start": 2854.84, "end": 2859.6800000000003, "text": " key value pairs that it's memorized. So every location", "tokens": [50616, 2141, 2158, 15494, 300, 309, 311, 46677, 13, 407, 633, 4914, 50858], "temperature": 0.0, "avg_logprob": -0.11701729477092784, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0015007604379206896}, {"id": 728, "seek": 284980, "start": 2859.76, "end": 2864.32, "text": " has a feature vector that you can think of as a key. And what", "tokens": [50862, 575, 257, 4111, 8062, 300, 291, 393, 519, 295, 382, 257, 2141, 13, 400, 437, 51090], "temperature": 0.0, "avg_logprob": -0.11701729477092784, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0015007604379206896}, {"id": 729, "seek": 284980, "start": 2864.36, "end": 2866.76, "text": " and the key each key like, you know, represents a certain", "tokens": [51092, 293, 264, 2141, 1184, 2141, 411, 11, 291, 458, 11, 8855, 257, 1629, 51212], "temperature": 0.0, "avg_logprob": -0.11701729477092784, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0015007604379206896}, {"id": 730, "seek": 284980, "start": 2866.76, "end": 2869.36, "text": " type of context, like, you know, the middles of towers or the", "tokens": [51212, 2010, 295, 4319, 11, 411, 11, 291, 458, 11, 264, 2062, 21915, 295, 25045, 420, 264, 51342], "temperature": 0.0, "avg_logprob": -0.11701729477092784, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0015007604379206896}, {"id": 731, "seek": 284980, "start": 2869.36, "end": 2872.6400000000003, "text": " tops of towers or something like that. And what you can think", "tokens": [51342, 22836, 295, 25045, 420, 746, 411, 300, 13, 400, 437, 291, 393, 519, 51506], "temperature": 0.0, "avg_logprob": -0.11701729477092784, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0015007604379206896}, {"id": 732, "seek": 287264, "start": 2872.68, "end": 2880.68, "text": " of the map as as as storing is what should be what is like the", "tokens": [50366, 295, 264, 4471, 382, 382, 382, 26085, 307, 437, 820, 312, 437, 307, 411, 264, 50766], "temperature": 0.0, "avg_logprob": -0.17288589477539062, "compression_ratio": 1.6284153005464481, "no_speech_prob": 0.006096214056015015}, {"id": 733, "seek": 287264, "start": 2880.68, "end": 2885.0, "text": " pattern of features that should be rendered whenever that", "tokens": [50766, 5102, 295, 4122, 300, 820, 312, 28748, 5699, 300, 50982], "temperature": 0.0, "avg_logprob": -0.17288589477539062, "compression_ratio": 1.6284153005464481, "no_speech_prob": 0.006096214056015015}, {"id": 734, "seek": 287264, "start": 2885.0, "end": 2888.12, "text": " context comes up. Right. So you can think of it as just", "tokens": [50982, 4319, 1487, 493, 13, 1779, 13, 407, 291, 393, 519, 295, 309, 382, 445, 51138], "temperature": 0.0, "avg_logprob": -0.17288589477539062, "compression_ratio": 1.6284153005464481, "no_speech_prob": 0.006096214056015015}, {"id": 735, "seek": 287264, "start": 2888.12, "end": 2894.7599999999998, "text": " basically key value store. And and so so this whole idea of", "tokens": [51138, 1936, 2141, 2158, 3531, 13, 400, 293, 370, 370, 341, 1379, 1558, 295, 51470], "temperature": 0.0, "avg_logprob": -0.17288589477539062, "compression_ratio": 1.6284153005464481, "no_speech_prob": 0.006096214056015015}, {"id": 736, "seek": 287264, "start": 2894.7999999999997, "end": 2897.8799999999997, "text": " using a matrix as a key value stores and it's like the oldest", "tokens": [51472, 1228, 257, 8141, 382, 257, 2141, 2158, 9512, 293, 309, 311, 411, 264, 14026, 51626], "temperature": 0.0, "avg_logprob": -0.17288589477539062, "compression_ratio": 1.6284153005464481, "no_speech_prob": 0.006096214056015015}, {"id": 737, "seek": 289788, "start": 2897.88, "end": 2903.56, "text": " idea in neural networks. People observe back in the 1970s,", "tokens": [50364, 1558, 294, 18161, 9590, 13, 3432, 11441, 646, 294, 264, 14577, 82, 11, 50648], "temperature": 0.0, "avg_logprob": -0.13142916976764638, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0026722324546426535}, {"id": 738, "seek": 289788, "start": 2904.08, "end": 2908.36, "text": " that if you have a single layer neural network, you can treat", "tokens": [50674, 300, 498, 291, 362, 257, 2167, 4583, 18161, 3209, 11, 291, 393, 2387, 50888], "temperature": 0.0, "avg_logprob": -0.13142916976764638, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0026722324546426535}, {"id": 739, "seek": 289788, "start": 2908.36, "end": 2912.32, "text": " it as a as an approximate key value store that remembers keys", "tokens": [50888, 309, 382, 257, 382, 364, 30874, 2141, 2158, 3531, 300, 26228, 9317, 51086], "temperature": 0.0, "avg_logprob": -0.13142916976764638, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0026722324546426535}, {"id": 740, "seek": 289788, "start": 2912.32, "end": 2918.32, "text": " with minimal error. And and so if you had a set of keys and a", "tokens": [51086, 365, 13206, 6713, 13, 400, 293, 370, 498, 291, 632, 257, 992, 295, 9317, 293, 257, 51386], "temperature": 0.0, "avg_logprob": -0.13142916976764638, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0026722324546426535}, {"id": 741, "seek": 289788, "start": 2918.32, "end": 2921.32, "text": " set of values you want to store, and you ask what is the", "tokens": [51386, 992, 295, 4190, 291, 528, 281, 3531, 11, 293, 291, 1029, 437, 307, 264, 51536], "temperature": 0.0, "avg_logprob": -0.13142916976764638, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0026722324546426535}, {"id": 742, "seek": 289788, "start": 2921.32, "end": 2924.48, "text": " optimal single layer neural network that you'd use to store", "tokens": [51536, 16252, 2167, 4583, 18161, 3209, 300, 291, 1116, 764, 281, 3531, 51694], "temperature": 0.0, "avg_logprob": -0.13142916976764638, "compression_ratio": 1.7783251231527093, "no_speech_prob": 0.0026722324546426535}, {"id": 743, "seek": 292448, "start": 2924.48, "end": 2928.84, "text": " it. It's actually, you know, classical linear algebra, it's", "tokens": [50364, 309, 13, 467, 311, 767, 11, 291, 458, 11, 13735, 8213, 21989, 11, 309, 311, 50582], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 744, "seek": 292448, "start": 2928.84, "end": 2931.84, "text": " like the solution to a least squares problem. So what we can", "tokens": [50582, 411, 264, 3827, 281, 257, 1935, 19368, 1154, 13, 407, 437, 321, 393, 50732], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 745, "seek": 292448, "start": 2931.84, "end": 2936.88, "text": " hypothesize is that in these very, very fancy, you know, 2020,", "tokens": [50732, 14276, 1125, 307, 300, 294, 613, 588, 11, 588, 10247, 11, 291, 458, 11, 4808, 11, 50984], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 746, "seek": 292448, "start": 2936.92, "end": 2942.68, "text": " you know, 50 years later, deep neural networks, actually, each", "tokens": [50986, 291, 458, 11, 2625, 924, 1780, 11, 2452, 18161, 9590, 11, 767, 11, 1184, 51274], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 747, "seek": 292448, "start": 2942.68, "end": 2945.92, "text": " layer is just acting as one of these. Now, which keys are being", "tokens": [51274, 4583, 307, 445, 6577, 382, 472, 295, 613, 13, 823, 11, 597, 9317, 366, 885, 51436], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 748, "seek": 292448, "start": 2945.92, "end": 2949.6, "text": " stored and what values were being stored? We don't know. But", "tokens": [51436, 12187, 293, 437, 4190, 645, 885, 12187, 30, 492, 500, 380, 458, 13, 583, 51620], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 749, "seek": 292448, "start": 2949.6, "end": 2952.2400000000002, "text": " we could hypothesize that there is some set of things that are", "tokens": [51620, 321, 727, 14276, 1125, 300, 456, 307, 512, 992, 295, 721, 300, 366, 51752], "temperature": 0.0, "avg_logprob": -0.1268946384561473, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.0024719061329960823}, {"id": 750, "seek": 295224, "start": 2952.24, "end": 2956.68, "text": " being memorized, some set of keys and values. And so that that", "tokens": [50364, 885, 46677, 11, 512, 992, 295, 9317, 293, 4190, 13, 400, 370, 300, 300, 50586], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 751, "seek": 295224, "start": 2956.68, "end": 2959.56, "text": " maybe this weight matrix that we have is the solution to the", "tokens": [50586, 1310, 341, 3364, 8141, 300, 321, 362, 307, 264, 3827, 281, 264, 50730], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 752, "seek": 295224, "start": 2959.56, "end": 2963.2, "text": " assembly squares problem. So the cool thing that we can do is we", "tokens": [50730, 12103, 19368, 1154, 13, 407, 264, 1627, 551, 300, 321, 393, 360, 307, 321, 50912], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 753, "seek": 295224, "start": 2963.2, "end": 2965.8799999999997, "text": " can say we can ask the question, what would the weight matrix", "tokens": [50912, 393, 584, 321, 393, 1029, 264, 1168, 11, 437, 576, 264, 3364, 8141, 51046], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 754, "seek": 295224, "start": 2965.8799999999997, "end": 2970.12, "text": " look like if we changed one of the rules? What if we had one new", "tokens": [51046, 574, 411, 498, 321, 3105, 472, 295, 264, 4474, 30, 708, 498, 321, 632, 472, 777, 51258], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 755, "seek": 295224, "start": 2970.12, "end": 2974.2799999999997, "text": " key value pair that we wanted to change? Then what would the", "tokens": [51258, 2141, 2158, 6119, 300, 321, 1415, 281, 1319, 30, 1396, 437, 576, 264, 51466], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 756, "seek": 295224, "start": 2974.2799999999997, "end": 2978.12, "text": " weight matrix be? Instead, we want all the other things that", "tokens": [51466, 3364, 8141, 312, 30, 7156, 11, 321, 528, 439, 264, 661, 721, 300, 51658], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 757, "seek": 295224, "start": 2978.12, "end": 2981.68, "text": " the network has memorized to still be memorized with minimal", "tokens": [51658, 264, 3209, 575, 46677, 281, 920, 312, 46677, 365, 13206, 51836], "temperature": 0.0, "avg_logprob": -0.12147864675134178, "compression_ratio": 1.8721804511278195, "no_speech_prob": 0.0018672291189432144}, {"id": 758, "seek": 298168, "start": 2981.72, "end": 2985.0, "text": " error, just as before, except we're going to give this new", "tokens": [50366, 6713, 11, 445, 382, 949, 11, 3993, 321, 434, 516, 281, 976, 341, 777, 50530], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 759, "seek": 298168, "start": 2985.0, "end": 2988.3599999999997, "text": " constraint, we want to write a new key value pair into it. And it", "tokens": [50530, 25534, 11, 321, 528, 281, 2464, 257, 777, 2141, 2158, 6119, 666, 309, 13, 400, 309, 50698], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 760, "seek": 298168, "start": 2988.3599999999997, "end": 2990.3199999999997, "text": " turns out that that's also least squares problems and", "tokens": [50698, 4523, 484, 300, 300, 311, 611, 1935, 19368, 2740, 293, 50796], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 761, "seek": 298168, "start": 2990.3199999999997, "end": 2991.7999999999997, "text": " constrained least squares problem, we can write down the", "tokens": [50796, 38901, 1935, 19368, 1154, 11, 321, 393, 2464, 760, 264, 50870], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 762, "seek": 298168, "start": 2991.7999999999997, "end": 2995.3199999999997, "text": " solution in this form. And the cool thing about these two, the", "tokens": [50870, 3827, 294, 341, 1254, 13, 400, 264, 1627, 551, 466, 613, 732, 11, 264, 51046], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 763, "seek": 298168, "start": 2995.3199999999997, "end": 2998.64, "text": " squares problems is that they cancel each other out. Most of", "tokens": [51046, 19368, 2740, 307, 300, 436, 10373, 1184, 661, 484, 13, 4534, 295, 51212], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 764, "seek": 298168, "start": 2998.64, "end": 3003.08, "text": " the terms are the same. And, and, and we can actually ask the", "tokens": [51212, 264, 2115, 366, 264, 912, 13, 400, 11, 293, 11, 293, 321, 393, 767, 1029, 264, 51434], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 765, "seek": 298168, "start": 3003.08, "end": 3007.3599999999997, "text": " question, how would the weights have to change if we add a new", "tokens": [51434, 1168, 11, 577, 576, 264, 17443, 362, 281, 1319, 498, 321, 909, 257, 777, 51648], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 766, "seek": 298168, "start": 3007.3599999999997, "end": 3011.48, "text": " key value pair, without knowing which values were written into", "tokens": [51648, 2141, 2158, 6119, 11, 1553, 5276, 597, 4190, 645, 3720, 666, 51854], "temperature": 0.0, "avg_logprob": -0.12124392934089159, "compression_ratio": 1.8605442176870748, "no_speech_prob": 0.0007320766453631222}, {"id": 767, "seek": 301148, "start": 3011.48, "end": 3015.36, "text": " the network before, we don't actually have to know what the", "tokens": [50364, 264, 3209, 949, 11, 321, 500, 380, 767, 362, 281, 458, 437, 264, 50558], "temperature": 0.0, "avg_logprob": -0.10647853539914501, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0006877045962028205}, {"id": 768, "seek": 301148, "start": 3015.36, "end": 3020.6, "text": " old key value pairs were, we can just assume that the network", "tokens": [50558, 1331, 2141, 2158, 15494, 645, 11, 321, 393, 445, 6552, 300, 264, 3209, 50820], "temperature": 0.0, "avg_logprob": -0.10647853539914501, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0006877045962028205}, {"id": 769, "seek": 301148, "start": 3020.6, "end": 3025.32, "text": " was optimal as storing all these key value pairs. And, and the", "tokens": [50820, 390, 16252, 382, 26085, 439, 613, 2141, 2158, 15494, 13, 400, 11, 293, 264, 51056], "temperature": 0.0, "avg_logprob": -0.10647853539914501, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0006877045962028205}, {"id": 770, "seek": 301148, "start": 3025.32, "end": 3029.64, "text": " math for like how to write a new key value pair comes out the", "tokens": [51056, 5221, 337, 411, 577, 281, 2464, 257, 777, 2141, 2158, 6119, 1487, 484, 264, 51272], "temperature": 0.0, "avg_logprob": -0.10647853539914501, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0006877045962028205}, {"id": 771, "seek": 301148, "start": 3029.64, "end": 3032.12, "text": " same anyway. So, so that's there's there's a little bit of a", "tokens": [51272, 912, 4033, 13, 407, 11, 370, 300, 311, 456, 311, 456, 311, 257, 707, 857, 295, 257, 51396], "temperature": 0.0, "avg_logprob": -0.10647853539914501, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0006877045962028205}, {"id": 772, "seek": 301148, "start": 3032.12, "end": 3037.32, "text": " mathematical insight and trick here. But what it allows us to do", "tokens": [51396, 18894, 11269, 293, 4282, 510, 13, 583, 437, 309, 4045, 505, 281, 360, 51656], "temperature": 0.0, "avg_logprob": -0.10647853539914501, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.0006877045962028205}, {"id": 773, "seek": 303732, "start": 3037.32, "end": 3042.44, "text": " is it allows us to find exactly what we want to do to change one", "tokens": [50364, 307, 309, 4045, 505, 281, 915, 2293, 437, 321, 528, 281, 360, 281, 1319, 472, 50620], "temperature": 0.0, "avg_logprob": -0.16204456329345704, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.002714020200073719}, {"id": 774, "seek": 303732, "start": 3042.44, "end": 3044.7200000000003, "text": " thing that the network is memorized, you do this rank one", "tokens": [50620, 551, 300, 264, 3209, 307, 46677, 11, 291, 360, 341, 6181, 472, 50734], "temperature": 0.0, "avg_logprob": -0.16204456329345704, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.002714020200073719}, {"id": 775, "seek": 303732, "start": 3044.7200000000003, "end": 3050.6000000000004, "text": " update in a specific direction. And, and you can take a key and", "tokens": [50734, 5623, 294, 257, 2685, 3513, 13, 400, 11, 293, 291, 393, 747, 257, 2141, 293, 51028], "temperature": 0.0, "avg_logprob": -0.16204456329345704, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.002714020200073719}, {"id": 776, "seek": 303732, "start": 3050.6000000000004, "end": 3054.2000000000003, "text": " change it to any value you want. And that will, you know, the", "tokens": [51028, 1319, 309, 281, 604, 2158, 291, 528, 13, 400, 300, 486, 11, 291, 458, 11, 264, 51208], "temperature": 0.0, "avg_logprob": -0.16204456329345704, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.002714020200073719}, {"id": 777, "seek": 303732, "start": 3054.2000000000003, "end": 3059.76, "text": " same form will minimize error for, for other keys, regardless of", "tokens": [51208, 912, 1254, 486, 17522, 6713, 337, 11, 337, 661, 9317, 11, 10060, 295, 51486], "temperature": 0.0, "avg_logprob": -0.16204456329345704, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.002714020200073719}, {"id": 778, "seek": 303732, "start": 3059.76, "end": 3063.4, "text": " what value we write, it's almost like it really is a form of", "tokens": [51486, 437, 2158, 321, 2464, 11, 309, 311, 1920, 411, 309, 534, 307, 257, 1254, 295, 51668], "temperature": 0.0, "avg_logprob": -0.16204456329345704, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.002714020200073719}, {"id": 779, "seek": 306340, "start": 3063.44, "end": 3067.32, "text": " memory, that we're changing. So our method is basically you", "tokens": [50366, 4675, 11, 300, 321, 434, 4473, 13, 407, 527, 3170, 307, 1936, 291, 50560], "temperature": 0.0, "avg_logprob": -0.12215869866528557, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.004068436101078987}, {"id": 780, "seek": 306340, "start": 3067.32, "end": 3073.08, "text": " find a key by asking the user to select a few contexts that look", "tokens": [50560, 915, 257, 2141, 538, 3365, 264, 4195, 281, 3048, 257, 1326, 30628, 300, 574, 50848], "temperature": 0.0, "avg_logprob": -0.12215869866528557, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.004068436101078987}, {"id": 781, "seek": 306340, "start": 3073.08, "end": 3076.04, "text": " the same, we average them to get a good key. Then we ask for a", "tokens": [50848, 264, 912, 11, 321, 4274, 552, 281, 483, 257, 665, 2141, 13, 1396, 321, 1029, 337, 257, 50996], "temperature": 0.0, "avg_logprob": -0.12215869866528557, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.004068436101078987}, {"id": 782, "seek": 306340, "start": 3076.04, "end": 3079.2400000000002, "text": " copy paste example to get a goal. That's the new value that we", "tokens": [50996, 5055, 9163, 1365, 281, 483, 257, 3387, 13, 663, 311, 264, 777, 2158, 300, 321, 51156], "temperature": 0.0, "avg_logprob": -0.12215869866528557, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.004068436101078987}, {"id": 783, "seek": 306340, "start": 3079.2400000000002, "end": 3081.84, "text": " want to write into the key of the memory. And then we do this", "tokens": [51156, 528, 281, 2464, 666, 264, 2141, 295, 264, 4675, 13, 400, 550, 321, 360, 341, 51286], "temperature": 0.0, "avg_logprob": -0.12215869866528557, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.004068436101078987}, {"id": 784, "seek": 306340, "start": 3081.84, "end": 3088.0, "text": " math to, to find how to change w in the direction of the key", "tokens": [51286, 5221, 281, 11, 281, 915, 577, 281, 1319, 261, 294, 264, 3513, 295, 264, 2141, 51594], "temperature": 0.0, "avg_logprob": -0.12215869866528557, "compression_ratio": 1.6359649122807018, "no_speech_prob": 0.004068436101078987}, {"id": 785, "seek": 308800, "start": 3088.0, "end": 3093.52, "text": " only, we find a rank one update that does this. And so, and so", "tokens": [50364, 787, 11, 321, 915, 257, 6181, 472, 5623, 300, 775, 341, 13, 400, 370, 11, 293, 370, 50640], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 786, "seek": 308800, "start": 3093.52, "end": 3095.48, "text": " that avoids changing other rules. So we can do this on a bunch", "tokens": [50640, 300, 3641, 3742, 4473, 661, 4474, 13, 407, 321, 393, 360, 341, 322, 257, 3840, 50738], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 787, "seek": 308800, "start": 3095.48, "end": 3099.12, "text": " of different GAN models. And, and so you can see, like, you", "tokens": [50738, 295, 819, 460, 1770, 5245, 13, 400, 11, 293, 370, 291, 393, 536, 11, 411, 11, 291, 50920], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 788, "seek": 308800, "start": 3099.12, "end": 3104.52, "text": " know, people like to change people's expressions here. So", "tokens": [50920, 458, 11, 561, 411, 281, 1319, 561, 311, 15277, 510, 13, 407, 51190], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 789, "seek": 308800, "start": 3104.52, "end": 3107.28, "text": " what we're doing is a little different from what you normally", "tokens": [51190, 437, 321, 434, 884, 307, 257, 707, 819, 490, 437, 291, 5646, 51328], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 790, "seek": 308800, "start": 3107.28, "end": 3109.16, "text": " do to change people's expressions. And again, what", "tokens": [51328, 360, 281, 1319, 561, 311, 15277, 13, 400, 797, 11, 437, 51422], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 791, "seek": 308800, "start": 3109.16, "end": 3111.44, "text": " we're doing is we're actually going to rewrite the GAN. So it", "tokens": [51422, 321, 434, 884, 307, 321, 434, 767, 516, 281, 28132, 264, 460, 1770, 13, 407, 309, 51536], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 792, "seek": 308800, "start": 3111.44, "end": 3113.52, "text": " only outputs people who are smiling, we're going to take all", "tokens": [51536, 787, 23930, 561, 567, 366, 16005, 11, 321, 434, 516, 281, 747, 439, 51640], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 793, "seek": 308800, "start": 3113.52, "end": 3115.88, "text": " the frowns, we're saying, okay, there's, there's a rule for", "tokens": [51640, 264, 431, 648, 82, 11, 321, 434, 1566, 11, 1392, 11, 456, 311, 11, 456, 311, 257, 4978, 337, 51758], "temperature": 0.0, "avg_logprob": -0.10943485561170076, "compression_ratio": 1.9045936395759717, "no_speech_prob": 0.02516033872961998}, {"id": 794, "seek": 311588, "start": 3115.88, "end": 3118.04, "text": " frowns, we're going to change that to a rule for smiles by", "tokens": [50364, 431, 648, 82, 11, 321, 434, 516, 281, 1319, 300, 281, 257, 4978, 337, 28083, 538, 50472], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 795, "seek": 311588, "start": 3118.04, "end": 3121.6800000000003, "text": " showing an example. And so by patching frowns to smiles, now", "tokens": [50472, 4099, 364, 1365, 13, 400, 370, 538, 9972, 278, 431, 648, 82, 281, 28083, 11, 586, 50654], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 796, "seek": 311588, "start": 3121.6800000000003, "end": 3124.88, "text": " we have a model that just outputs people who are smiling. Now", "tokens": [50654, 321, 362, 257, 2316, 300, 445, 23930, 561, 567, 366, 16005, 13, 823, 50814], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 797, "seek": 311588, "start": 3124.88, "end": 3128.44, "text": " we live in a happy world. So that's, that's, that's pretty", "tokens": [50814, 321, 1621, 294, 257, 2055, 1002, 13, 407, 300, 311, 11, 300, 311, 11, 300, 311, 1238, 50992], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 798, "seek": 311588, "start": 3128.44, "end": 3131.08, "text": " cool. And now, of course, we could have done that by, you", "tokens": [50992, 1627, 13, 400, 586, 11, 295, 1164, 11, 321, 727, 362, 1096, 300, 538, 11, 291, 51124], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 799, "seek": 311588, "start": 3131.08, "end": 3135.08, "text": " know, changing the training set by collecting only training", "tokens": [51124, 458, 11, 4473, 264, 3097, 992, 538, 12510, 787, 3097, 51324], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 800, "seek": 311588, "start": 3135.08, "end": 3137.48, "text": " data of people who are smiling. But the neat thing is that you", "tokens": [51324, 1412, 295, 561, 567, 366, 16005, 13, 583, 264, 10654, 551, 307, 300, 291, 51444], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 801, "seek": 311588, "start": 3137.48, "end": 3140.56, "text": " can also do this for things where you don't have a training", "tokens": [51444, 393, 611, 360, 341, 337, 721, 689, 291, 500, 380, 362, 257, 3097, 51598], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 802, "seek": 311588, "start": 3140.56, "end": 3143.08, "text": " set that looks like it. So for example, there's a, there's a", "tokens": [51598, 992, 300, 1542, 411, 309, 13, 407, 337, 1365, 11, 456, 311, 257, 11, 456, 311, 257, 51724], "temperature": 0.0, "avg_logprob": -0.10332021587773373, "compression_ratio": 1.8689655172413793, "no_speech_prob": 0.00280030001886189}, {"id": 803, "seek": 314308, "start": 3143.08, "end": 3147.16, "text": " rule in the model for how eyebrows should look on kids. So", "tokens": [50364, 4978, 294, 264, 2316, 337, 577, 19916, 820, 574, 322, 2301, 13, 407, 50568], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 804, "seek": 314308, "start": 3147.16, "end": 3151.08, "text": " you can see that kids have these very wispy light eyebrows that", "tokens": [50568, 291, 393, 536, 300, 2301, 362, 613, 588, 261, 7631, 88, 1442, 19916, 300, 50764], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 805, "seek": 314308, "start": 3151.08, "end": 3154.48, "text": " don't have much hair. So we can find that rule by identifying a", "tokens": [50764, 500, 380, 362, 709, 2578, 13, 407, 321, 393, 915, 300, 4978, 538, 16696, 257, 50934], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 806, "seek": 314308, "start": 3154.48, "end": 3157.4, "text": " few examples that gives us a rank one direction in the weight", "tokens": [50934, 1326, 5110, 300, 2709, 505, 257, 6181, 472, 3513, 294, 264, 3364, 51080], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 807, "seek": 314308, "start": 3157.4, "end": 3161.0, "text": " matrix. And then we can redefine it, we can write a new thing", "tokens": [51080, 8141, 13, 400, 550, 321, 393, 38818, 533, 309, 11, 321, 393, 2464, 257, 777, 551, 51260], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 808, "seek": 314308, "start": 3161.0, "end": 3163.2799999999997, "text": " into it and say, you know what, we want the eyebrows to look", "tokens": [51260, 666, 309, 293, 584, 11, 291, 458, 437, 11, 321, 528, 264, 19916, 281, 574, 51374], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 809, "seek": 314308, "start": 3163.2799999999997, "end": 3167.0, "text": " like this, like that's very bushy much sash. And, you know,", "tokens": [51374, 411, 341, 11, 411, 300, 311, 588, 1255, 3495, 709, 43780, 13, 400, 11, 291, 458, 11, 51560], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 810, "seek": 314308, "start": 3167.0, "end": 3171.0, "text": " paste into one example, do the math. And then now we can change", "tokens": [51560, 9163, 666, 472, 1365, 11, 360, 264, 5221, 13, 400, 550, 586, 321, 393, 1319, 51760], "temperature": 0.0, "avg_logprob": -0.12407006157769097, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.008574061095714569}, {"id": 811, "seek": 317100, "start": 3171.04, "end": 3174.0, "text": " weights in a way that generalizes. So now all the kids had", "tokens": [50366, 17443, 294, 257, 636, 300, 2674, 5660, 13, 407, 586, 439, 264, 2301, 632, 50514], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 812, "seek": 317100, "start": 3174.0, "end": 3178.44, "text": " these very bushy, you know, eyebrows. And it's something", "tokens": [50514, 613, 588, 1255, 3495, 11, 291, 458, 11, 19916, 13, 400, 309, 311, 746, 50736], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 813, "seek": 317100, "start": 3178.44, "end": 3181.52, "text": " that we wouldn't have been able to get by collecting training", "tokens": [50736, 300, 321, 2759, 380, 362, 668, 1075, 281, 483, 538, 12510, 3097, 50890], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 814, "seek": 317100, "start": 3181.52, "end": 3183.8, "text": " set because we don't have kids that look like this in the real", "tokens": [50890, 992, 570, 321, 500, 380, 362, 2301, 300, 574, 411, 341, 294, 264, 957, 51004], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 815, "seek": 317100, "start": 3183.8, "end": 3187.28, "text": " world. It's something that just comes out of our imagination. So", "tokens": [51004, 1002, 13, 467, 311, 746, 300, 445, 1487, 484, 295, 527, 12938, 13, 407, 51178], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 816, "seek": 317100, "start": 3187.28, "end": 3191.72, "text": " this is kind of the thing. I kind of feel like this is the big", "tokens": [51178, 341, 307, 733, 295, 264, 551, 13, 286, 733, 295, 841, 411, 341, 307, 264, 955, 51400], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 817, "seek": 317100, "start": 3191.72, "end": 3195.72, "text": " reason why, why, why be interested in how these models", "tokens": [51400, 1778, 983, 11, 983, 11, 983, 312, 3102, 294, 577, 613, 5245, 51600], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 818, "seek": 317100, "start": 3195.72, "end": 3200.64, "text": " are working inside. And the reason to be so interested in it is", "tokens": [51600, 366, 1364, 1854, 13, 400, 264, 1778, 281, 312, 370, 3102, 294, 309, 307, 51846], "temperature": 0.0, "avg_logprob": -0.10308575630187988, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.006094689015299082}, {"id": 819, "seek": 320064, "start": 3200.64, "end": 3204.56, "text": " because as long as we don't look inside our models, then we're", "tokens": [50364, 570, 382, 938, 382, 321, 500, 380, 574, 1854, 527, 5245, 11, 550, 321, 434, 50560], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 820, "seek": 320064, "start": 3204.56, "end": 3207.96, "text": " really constrained. Because the only thing that our models can", "tokens": [50560, 534, 38901, 13, 1436, 264, 787, 551, 300, 527, 5245, 393, 50730], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 821, "seek": 320064, "start": 3207.96, "end": 3212.48, "text": " really do is imitate the real world. We can collect huge", "tokens": [50730, 534, 360, 307, 35556, 264, 957, 1002, 13, 492, 393, 2500, 2603, 50956], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 822, "seek": 320064, "start": 3212.48, "end": 3216.04, "text": " amounts of data. And the models that we create, we'll just get", "tokens": [50956, 11663, 295, 1412, 13, 400, 264, 5245, 300, 321, 1884, 11, 321, 603, 445, 483, 51134], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 823, "seek": 320064, "start": 3216.04, "end": 3219.68, "text": " better and better at imitating the way that the data is the way", "tokens": [51134, 1101, 293, 1101, 412, 566, 16350, 264, 636, 300, 264, 1412, 307, 264, 636, 51316], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 824, "seek": 320064, "start": 3219.68, "end": 3223.48, "text": " the world is today. And I kind of feel like it goes a little bit", "tokens": [51316, 264, 1002, 307, 965, 13, 400, 286, 733, 295, 841, 411, 309, 1709, 257, 707, 857, 51506], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 825, "seek": 320064, "start": 3223.48, "end": 3226.6, "text": " against why I was interested in computer science years ago when I", "tokens": [51506, 1970, 983, 286, 390, 3102, 294, 3820, 3497, 924, 2057, 562, 286, 51662], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 826, "seek": 320064, "start": 3226.6, "end": 3229.2, "text": " entered it in the first place. Because the amazing thing about", "tokens": [51662, 9065, 309, 294, 264, 700, 1081, 13, 1436, 264, 2243, 551, 466, 51792], "temperature": 0.0, "avg_logprob": -0.07460580444335937, "compression_ratio": 1.7711267605633803, "no_speech_prob": 0.00015840580454096198}, {"id": 827, "seek": 322920, "start": 3229.2, "end": 3233.3599999999997, "text": " computer science is that you can use it to create algorithms", "tokens": [50364, 3820, 3497, 307, 300, 291, 393, 764, 309, 281, 1884, 14642, 50572], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 828, "seek": 322920, "start": 3233.3599999999997, "end": 3236.48, "text": " that represent things in the world that don't exist yet,", "tokens": [50572, 300, 2906, 721, 294, 264, 1002, 300, 500, 380, 2514, 1939, 11, 50728], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 829, "seek": 322920, "start": 3236.52, "end": 3239.52, "text": " things that you can only imagine. And so machine learning is", "tokens": [50730, 721, 300, 291, 393, 787, 3811, 13, 400, 370, 3479, 2539, 307, 50880], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 830, "seek": 322920, "start": 3239.52, "end": 3242.3999999999996, "text": " sort of on this path right now, where we're getting very, very", "tokens": [50880, 1333, 295, 322, 341, 3100, 558, 586, 11, 689, 321, 434, 1242, 588, 11, 588, 51024], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 831, "seek": 322920, "start": 3242.3999999999996, "end": 3246.64, "text": " good at replicating the way the world is. And we're going to be", "tokens": [51024, 665, 412, 3248, 30541, 264, 636, 264, 1002, 307, 13, 400, 321, 434, 516, 281, 312, 51236], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 832, "seek": 322920, "start": 3246.64, "end": 3250.2799999999997, "text": " confronted with this question of how do we use these techniques", "tokens": [51236, 31257, 365, 341, 1168, 295, 577, 360, 321, 764, 613, 7512, 51418], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 833, "seek": 322920, "start": 3250.4399999999996, "end": 3254.08, "text": " to actually create new worlds that don't exist yet that are the", "tokens": [51426, 281, 767, 1884, 777, 13401, 300, 500, 380, 2514, 1939, 300, 366, 264, 51608], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 834, "seek": 322920, "start": 3254.08, "end": 3258.3999999999996, "text": " way that we want them to be. And I think that this really", "tokens": [51608, 636, 300, 321, 528, 552, 281, 312, 13, 400, 286, 519, 300, 341, 534, 51824], "temperature": 0.0, "avg_logprob": -0.08774826956576988, "compression_ratio": 1.8740458015267176, "no_speech_prob": 0.004068288486450911}, {"id": 835, "seek": 325840, "start": 3258.4, "end": 3263.88, "text": " going to require us to not just get models that are just really", "tokens": [50364, 516, 281, 3651, 505, 281, 406, 445, 483, 5245, 300, 366, 445, 534, 50638], "temperature": 0.0, "avg_logprob": -0.15328860592532467, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0005440253298729658}, {"id": 836, "seek": 325840, "start": 3263.88, "end": 3267.7200000000003, "text": " good at imitating, but also models that are understandable to", "tokens": [50638, 665, 412, 566, 16350, 11, 457, 611, 5245, 300, 366, 25648, 281, 50830], "temperature": 0.0, "avg_logprob": -0.15328860592532467, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0005440253298729658}, {"id": 837, "seek": 325840, "start": 3267.7200000000003, "end": 3273.1600000000003, "text": " people so that we can change their rules inside, and then use", "tokens": [50830, 561, 370, 300, 321, 393, 1319, 641, 4474, 1854, 11, 293, 550, 764, 51102], "temperature": 0.0, "avg_logprob": -0.15328860592532467, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0005440253298729658}, {"id": 838, "seek": 325840, "start": 3273.1600000000003, "end": 3276.48, "text": " them to create things that are based on our imagination instead", "tokens": [51102, 552, 281, 1884, 721, 300, 366, 2361, 322, 527, 12938, 2602, 51268], "temperature": 0.0, "avg_logprob": -0.15328860592532467, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0005440253298729658}, {"id": 839, "seek": 325840, "start": 3276.48, "end": 3284.32, "text": " of just the training data. And so here's a fun thing here, I", "tokens": [51268, 295, 445, 264, 3097, 1412, 13, 400, 370, 510, 311, 257, 1019, 551, 510, 11, 286, 51660], "temperature": 0.0, "avg_logprob": -0.15328860592532467, "compression_ratio": 1.6335078534031413, "no_speech_prob": 0.0005440253298729658}, {"id": 840, "seek": 328432, "start": 3284.36, "end": 3290.56, "text": " think, if I want to be fair to the horses, you notice that none", "tokens": [50366, 519, 11, 498, 286, 528, 281, 312, 3143, 281, 264, 13112, 11, 291, 3449, 300, 6022, 50676], "temperature": 0.0, "avg_logprob": -0.13461545370157482, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.010321146808564663}, {"id": 841, "seek": 328432, "start": 3290.56, "end": 3295.0800000000004, "text": " of the horses in this horse generating GAN get to wear hats", "tokens": [50676, 295, 264, 13112, 294, 341, 6832, 17746, 460, 1770, 483, 281, 3728, 20549, 50902], "temperature": 0.0, "avg_logprob": -0.13461545370157482, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.010321146808564663}, {"id": 842, "seek": 328432, "start": 3295.1200000000003, "end": 3298.56, "text": " even though all the people get to wear hats. So we can change", "tokens": [50904, 754, 1673, 439, 264, 561, 483, 281, 3728, 20549, 13, 407, 321, 393, 1319, 51076], "temperature": 0.0, "avg_logprob": -0.13461545370157482, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.010321146808564663}, {"id": 843, "seek": 328432, "start": 3298.56, "end": 3303.28, "text": " that by taking a hat from a person and inserting it into our", "tokens": [51076, 300, 538, 1940, 257, 2385, 490, 257, 954, 293, 46567, 309, 666, 527, 51312], "temperature": 0.0, "avg_logprob": -0.13461545370157482, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.010321146808564663}, {"id": 844, "seek": 328432, "start": 3303.28, "end": 3306.44, "text": " GAN's model of what a horse's head should look like. And now", "tokens": [51312, 460, 1770, 311, 2316, 295, 437, 257, 6832, 311, 1378, 820, 574, 411, 13, 400, 586, 51470], "temperature": 0.0, "avg_logprob": -0.13461545370157482, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.010321146808564663}, {"id": 845, "seek": 328432, "start": 3306.44, "end": 3311.6800000000003, "text": " horses get to wear hats, right? And so, so let's build a better", "tokens": [51470, 13112, 483, 281, 3728, 20549, 11, 558, 30, 400, 370, 11, 370, 718, 311, 1322, 257, 1101, 51732], "temperature": 0.0, "avg_logprob": -0.13461545370157482, "compression_ratio": 1.6711711711711712, "no_speech_prob": 0.010321146808564663}, {"id": 846, "seek": 331168, "start": 3311.68, "end": 3318.0, "text": " world. And, and allow people to change the rules of the world by", "tokens": [50364, 1002, 13, 400, 11, 293, 2089, 561, 281, 1319, 264, 4474, 295, 264, 1002, 538, 50680], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 847, "seek": 331168, "start": 3318.0, "end": 3322.3599999999997, "text": " making the rules more visible and and manipulatable by humans.", "tokens": [50680, 1455, 264, 4474, 544, 8974, 293, 293, 9258, 425, 31415, 538, 6255, 13, 50898], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 848, "seek": 331168, "start": 3322.7599999999998, "end": 3328.64, "text": " That's that's sort of the goal of the whole thing. So any", "tokens": [50918, 663, 311, 300, 311, 1333, 295, 264, 3387, 295, 264, 1379, 551, 13, 407, 604, 51212], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 849, "seek": 331168, "start": 3328.64, "end": 3329.96, "text": " questions? Any questions?", "tokens": [51212, 1651, 30, 2639, 1651, 30, 51278], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 850, "seek": 331168, "start": 3330.2799999999997, "end": 3331.96, "text": " I have a question. Yes.", "tokens": [51294, 286, 362, 257, 1168, 13, 1079, 13, 51378], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 851, "seek": 331168, "start": 3332.08, "end": 3335.9199999999996, "text": " Does this method work with multiple different models? Or is", "tokens": [51384, 4402, 341, 3170, 589, 365, 3866, 819, 5245, 30, 1610, 307, 51576], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 852, "seek": 331168, "start": 3335.9199999999996, "end": 3339.6, "text": " it only successful when like, taking a hat from within this", "tokens": [51576, 309, 787, 4406, 562, 411, 11, 1940, 257, 2385, 490, 1951, 341, 51760], "temperature": 0.0, "avg_logprob": -0.22310362470910905, "compression_ratio": 1.5707964601769913, "no_speech_prob": 0.010803083889186382}, {"id": 853, "seek": 333960, "start": 3339.6, "end": 3342.08, "text": " model and put it on a horse?", "tokens": [50364, 2316, 293, 829, 309, 322, 257, 6832, 30, 50488], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 854, "seek": 333960, "start": 3342.16, "end": 3349.0, "text": " So right now, this, this method is only able to take it, it's", "tokens": [50492, 407, 558, 586, 11, 341, 11, 341, 3170, 307, 787, 1075, 281, 747, 309, 11, 309, 311, 50834], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 855, "seek": 333960, "start": 3349.24, "end": 3353.12, "text": " it's only able to rewire one model. So I can take one part of a", "tokens": [50846, 309, 311, 787, 1075, 281, 319, 42689, 472, 2316, 13, 407, 286, 393, 747, 472, 644, 295, 257, 51040], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 856, "seek": 333960, "start": 3353.12, "end": 3356.72, "text": " model and rewire it to a different model, you're sort of", "tokens": [51040, 2316, 293, 319, 42689, 309, 281, 257, 819, 2316, 11, 291, 434, 1333, 295, 51220], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 857, "seek": 333960, "start": 3356.72, "end": 3359.2, "text": " asking the transplant question. So I'm sort of at the point", "tokens": [51220, 3365, 264, 20662, 1168, 13, 407, 286, 478, 1333, 295, 412, 264, 935, 51344], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 858, "seek": 333960, "start": 3359.2, "end": 3363.52, "text": " where, you know, it's like a surgeon, I can like connect one", "tokens": [51344, 689, 11, 291, 458, 11, 309, 311, 411, 257, 22913, 11, 286, 393, 411, 1745, 472, 51560], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 859, "seek": 333960, "start": 3363.52, "end": 3365.72, "text": " blood vessel to another blood vessel in the same human, right?", "tokens": [51560, 3390, 18098, 281, 1071, 3390, 18098, 294, 264, 912, 1952, 11, 558, 30, 51670], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 860, "seek": 333960, "start": 3365.72, "end": 3367.48, "text": " And you're sort of asking the question, well, can I do a heart", "tokens": [51670, 400, 291, 434, 1333, 295, 3365, 264, 1168, 11, 731, 11, 393, 286, 360, 257, 1917, 51758], "temperature": 0.0, "avg_logprob": -0.13615046049419202, "compression_ratio": 1.832, "no_speech_prob": 0.0009847318287938833}, {"id": 861, "seek": 336748, "start": 3367.48, "end": 3370.2400000000002, "text": " transplant? Can I take a heart out of one person put another one?", "tokens": [50364, 20662, 30, 1664, 286, 747, 257, 1917, 484, 295, 472, 954, 829, 1071, 472, 30, 50502], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 862, "seek": 336748, "start": 3370.56, "end": 3375.72, "text": " And I cannot do that yet. It turns out to be harder. And, but I", "tokens": [50518, 400, 286, 2644, 360, 300, 1939, 13, 467, 4523, 484, 281, 312, 6081, 13, 400, 11, 457, 286, 50776], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 863, "seek": 336748, "start": 3375.76, "end": 3380.68, "text": " but it is a it is an obvious goal. And I, and I feel confident", "tokens": [50778, 457, 309, 307, 257, 309, 307, 364, 6322, 3387, 13, 400, 286, 11, 293, 286, 841, 6679, 51024], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 864, "seek": 336748, "start": 3380.68, "end": 3385.2, "text": " that if we understand well enough, all the things that make", "tokens": [51024, 300, 498, 321, 1223, 731, 1547, 11, 439, 264, 721, 300, 652, 51250], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 865, "seek": 336748, "start": 3385.2, "end": 3388.4, "text": " these computations work, what is needed for the care and", "tokens": [51250, 613, 2807, 763, 589, 11, 437, 307, 2978, 337, 264, 1127, 293, 51410], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 866, "seek": 336748, "start": 3388.4, "end": 3391.6, "text": " feeding of a computational module? What is a computational", "tokens": [51410, 12919, 295, 257, 28270, 10088, 30, 708, 307, 257, 28270, 51570], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 867, "seek": 336748, "start": 3391.6, "end": 3395.2, "text": " module inside a big learning system? Then we should, you", "tokens": [51570, 10088, 1854, 257, 955, 2539, 1185, 30, 1396, 321, 820, 11, 291, 51750], "temperature": 0.0, "avg_logprob": -0.12895387411117554, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0018379855901002884}, {"id": 868, "seek": 339520, "start": 3395.24, "end": 3398.64, "text": " know, it should be a goal to be able to move a piece of", "tokens": [50366, 458, 11, 309, 820, 312, 257, 3387, 281, 312, 1075, 281, 1286, 257, 2522, 295, 50536], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 869, "seek": 339520, "start": 3398.64, "end": 3403.16, "text": " computation from one neural network to another one. Does that", "tokens": [50536, 24903, 490, 472, 18161, 3209, 281, 1071, 472, 13, 4402, 300, 50762], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 870, "seek": 339520, "start": 3403.16, "end": 3403.64, "text": " make sense?", "tokens": [50762, 652, 2020, 30, 50786], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 871, "seek": 339520, "start": 3405.48, "end": 3406.04, "text": " Yes, thank you.", "tokens": [50878, 1079, 11, 1309, 291, 13, 50906], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 872, "seek": 339520, "start": 3406.3999999999996, "end": 3409.8399999999997, "text": " Yep. That's a really great question, by the way. I think", "tokens": [50924, 7010, 13, 663, 311, 257, 534, 869, 1168, 11, 538, 264, 636, 13, 286, 519, 51096], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 873, "seek": 339520, "start": 3409.8399999999997, "end": 3415.12, "text": " it's, I think it's fundamental. Any other questions?", "tokens": [51096, 309, 311, 11, 286, 519, 309, 311, 8088, 13, 2639, 661, 1651, 30, 51360], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 874, "seek": 339520, "start": 3419.2799999999997, "end": 3424.52, "text": " This is not too well articulated question. I was just", "tokens": [51568, 639, 307, 406, 886, 731, 43322, 1168, 13, 286, 390, 445, 51830], "temperature": 0.0, "avg_logprob": -0.1678646280524436, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.0008955625235103071}, {"id": 875, "seek": 342452, "start": 3424.52, "end": 3428.44, "text": " curious what you, what are your thoughts about this? I think", "tokens": [50364, 6369, 437, 291, 11, 437, 366, 428, 4598, 466, 341, 30, 286, 519, 50560], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 876, "seek": 342452, "start": 3428.44, "end": 3434.0, "text": " this is this like neural nets have tendency to like avoid the", "tokens": [50560, 341, 307, 341, 411, 18161, 36170, 362, 18187, 281, 411, 5042, 264, 50838], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 877, "seek": 342452, "start": 3434.0, "end": 3436.7599999999998, "text": " responsibility of the results, like everything is done in the", "tokens": [50838, 6357, 295, 264, 3542, 11, 411, 1203, 307, 1096, 294, 264, 50976], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 878, "seek": 342452, "start": 3436.8, "end": 3439.92, "text": " hidden layers and sort of shrug off shrug off the", "tokens": [50978, 7633, 7914, 293, 1333, 295, 9884, 697, 766, 9884, 697, 766, 264, 51134], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 879, "seek": 342452, "start": 3439.92, "end": 3443.6, "text": " responsibility about the results. And I thought it was like", "tokens": [51134, 6357, 466, 264, 3542, 13, 400, 286, 1194, 309, 390, 411, 51318], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 880, "seek": 342452, "start": 3443.6, "end": 3448.16, "text": " interesting how you set the objective towards something as", "tokens": [51318, 1880, 577, 291, 992, 264, 10024, 3030, 746, 382, 51546], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 881, "seek": 342452, "start": 3448.2, "end": 3453.4, "text": " abstract as realistic. And here, like how you define the concept", "tokens": [51548, 12649, 382, 12465, 13, 400, 510, 11, 411, 577, 291, 6964, 264, 3410, 51808], "temperature": 0.0, "avg_logprob": -0.15594659392366705, "compression_ratio": 1.8253275109170306, "no_speech_prob": 0.0014538932591676712}, {"id": 882, "seek": 345340, "start": 3453.4, "end": 3457.6, "text": " of being realistic is based on the big data you collected from", "tokens": [50364, 295, 885, 12465, 307, 2361, 322, 264, 955, 1412, 291, 11087, 490, 50574], "temperature": 0.0, "avg_logprob": -0.14964037356169327, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0011507333256304264}, {"id": 883, "seek": 345340, "start": 3457.6, "end": 3462.6800000000003, "text": " the web, but but oftentimes some like fake images sometimes", "tokens": [50574, 264, 3670, 11, 457, 457, 18349, 512, 411, 7592, 5267, 2171, 50828], "temperature": 0.0, "avg_logprob": -0.14964037356169327, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0011507333256304264}, {"id": 884, "seek": 345340, "start": 3462.6800000000003, "end": 3468.08, "text": " look even more realistic than real images. And I don't know,", "tokens": [50828, 574, 754, 544, 12465, 813, 957, 5267, 13, 400, 286, 500, 380, 458, 11, 51098], "temperature": 0.0, "avg_logprob": -0.14964037356169327, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0011507333256304264}, {"id": 885, "seek": 345340, "start": 3468.08, "end": 3471.28, "text": " like tree growing on top of the building may look fairly", "tokens": [51098, 411, 4230, 4194, 322, 1192, 295, 264, 2390, 815, 574, 6457, 51258], "temperature": 0.0, "avg_logprob": -0.14964037356169327, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0011507333256304264}, {"id": 886, "seek": 345340, "start": 3471.28, "end": 3476.6800000000003, "text": " realistic for some people, but maybe for plant experts, maybe", "tokens": [51258, 12465, 337, 512, 561, 11, 457, 1310, 337, 3709, 8572, 11, 1310, 51528], "temperature": 0.0, "avg_logprob": -0.14964037356169327, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0011507333256304264}, {"id": 887, "seek": 345340, "start": 3476.7200000000003, "end": 3482.48, "text": " it would not. Right. So I don't know, like, I think this might", "tokens": [51530, 309, 576, 406, 13, 1779, 13, 407, 286, 500, 380, 458, 11, 411, 11, 286, 519, 341, 1062, 51818], "temperature": 0.0, "avg_logprob": -0.14964037356169327, "compression_ratio": 1.7136150234741785, "no_speech_prob": 0.0011507333256304264}, {"id": 888, "seek": 348248, "start": 3482.64, "end": 3487.28, "text": " result in like the blurring between the it's making us hard", "tokens": [50372, 1874, 294, 411, 264, 14257, 2937, 1296, 264, 309, 311, 1455, 505, 1152, 50604], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 889, "seek": 348248, "start": 3487.28, "end": 3490.04, "text": " to distinguish between the real and the fake or something like", "tokens": [50604, 281, 20206, 1296, 264, 957, 293, 264, 7592, 420, 746, 411, 50742], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 890, "seek": 348248, "start": 3490.04, "end": 3490.56, "text": " that. I don't know.", "tokens": [50742, 300, 13, 286, 500, 380, 458, 13, 50768], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 891, "seek": 348248, "start": 3491.12, "end": 3497.4, "text": " Yes, yes. No, I think that there are so so the we're we're", "tokens": [50796, 1079, 11, 2086, 13, 883, 11, 286, 519, 300, 456, 366, 370, 370, 264, 321, 434, 321, 434, 51110], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 892, "seek": 348248, "start": 3497.4, "end": 3502.6, "text": " unaccustomed to making it easy for making programs that make", "tokens": [51110, 517, 8476, 34977, 281, 1455, 309, 1858, 337, 1455, 4268, 300, 652, 51370], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 893, "seek": 348248, "start": 3502.6, "end": 3506.04, "text": " such realistic renderings of the world. And it's actually a", "tokens": [51370, 1270, 12465, 15529, 1109, 295, 264, 1002, 13, 400, 309, 311, 767, 257, 51542], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 894, "seek": 348248, "start": 3506.04, "end": 3510.68, "text": " concern. I think that, you know, people have misused this", "tokens": [51542, 3136, 13, 286, 519, 300, 11, 291, 458, 11, 561, 362, 3346, 4717, 341, 51774], "temperature": 0.0, "avg_logprob": -0.15303930869469276, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0016723526641726494}, {"id": 895, "seek": 351068, "start": 3510.72, "end": 3513.72, "text": " technology already that we you know, we use we you know, there's", "tokens": [50366, 2899, 1217, 300, 321, 291, 458, 11, 321, 764, 321, 291, 458, 11, 456, 311, 50516], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 896, "seek": 351068, "start": 3513.72, "end": 3518.96, "text": " the whole deep fakes phenomenon. But even without like faking", "tokens": [50516, 264, 1379, 2452, 283, 3419, 14029, 13, 583, 754, 1553, 411, 283, 2456, 50778], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 897, "seek": 351068, "start": 3518.96, "end": 3526.04, "text": " videos, people people have you know, used face generators to", "tokens": [50778, 2145, 11, 561, 561, 362, 291, 458, 11, 1143, 1851, 38662, 281, 51132], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 898, "seek": 351068, "start": 3526.04, "end": 3529.16, "text": " make lots of fake Facebook profiles and things like that,", "tokens": [51132, 652, 3195, 295, 7592, 4384, 23693, 293, 721, 411, 300, 11, 51288], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 899, "seek": 351068, "start": 3529.16, "end": 3532.24, "text": " you know, pretending there are millions of people that exist", "tokens": [51288, 291, 458, 11, 22106, 456, 366, 6803, 295, 561, 300, 2514, 51442], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 900, "seek": 351068, "start": 3532.24, "end": 3536.24, "text": " that don't actually exist and things like that. So so even", "tokens": [51442, 300, 500, 380, 767, 2514, 293, 721, 411, 300, 13, 407, 370, 754, 51642], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 901, "seek": 351068, "start": 3536.2799999999997, "end": 3538.64, "text": " before you sort of do manipulations of the world, I", "tokens": [51644, 949, 291, 1333, 295, 360, 9258, 4136, 295, 264, 1002, 11, 286, 51762], "temperature": 0.0, "avg_logprob": -0.1510026987316539, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0030264430679380894}, {"id": 902, "seek": 353864, "start": 3538.64, "end": 3543.72, "text": " think that there's already this problem of of of, you know,", "tokens": [50364, 519, 300, 456, 311, 1217, 341, 1154, 295, 295, 295, 11, 291, 458, 11, 50618], "temperature": 0.0, "avg_logprob": -0.14837842047968997, "compression_ratio": 1.7231638418079096, "no_speech_prob": 0.0007790078525431454}, {"id": 903, "seek": 353864, "start": 3543.72, "end": 3548.2, "text": " pretending that there's a lot of data that there actually isn't", "tokens": [50618, 22106, 300, 456, 311, 257, 688, 295, 1412, 300, 456, 767, 1943, 380, 50842], "temperature": 0.0, "avg_logprob": -0.14837842047968997, "compression_ratio": 1.7231638418079096, "no_speech_prob": 0.0007790078525431454}, {"id": 904, "seek": 353864, "start": 3548.24, "end": 3551.12, "text": " by using these generator models. And so I think that there's", "tokens": [50844, 538, 1228, 613, 19265, 5245, 13, 400, 370, 286, 519, 300, 456, 311, 50988], "temperature": 0.0, "avg_logprob": -0.14837842047968997, "compression_ratio": 1.7231638418079096, "no_speech_prob": 0.0007790078525431454}, {"id": 905, "seek": 353864, "start": 3553.64, "end": 3558.0, "text": " you know, the whole the whole question of fakes is a very", "tokens": [51114, 291, 458, 11, 264, 1379, 264, 1379, 1168, 295, 283, 3419, 307, 257, 588, 51332], "temperature": 0.0, "avg_logprob": -0.14837842047968997, "compression_ratio": 1.7231638418079096, "no_speech_prob": 0.0007790078525431454}, {"id": 906, "seek": 353864, "start": 3558.0, "end": 3565.16, "text": " serious question, like how do we how do we function society if", "tokens": [51332, 3156, 1168, 11, 411, 577, 360, 321, 577, 360, 321, 2445, 4086, 498, 51690], "temperature": 0.0, "avg_logprob": -0.14837842047968997, "compression_ratio": 1.7231638418079096, "no_speech_prob": 0.0007790078525431454}, {"id": 907, "seek": 356516, "start": 3565.16, "end": 3569.68, "text": " we don't know what's real and what's fake. Now, it's not a", "tokens": [50364, 321, 500, 380, 458, 437, 311, 957, 293, 437, 311, 7592, 13, 823, 11, 309, 311, 406, 257, 50590], "temperature": 0.0, "avg_logprob": -0.14147936567968253, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.006286755204200745}, {"id": 908, "seek": 356516, "start": 3569.68, "end": 3575.72, "text": " totally new issue. You don't need a state of the art deep", "tokens": [50590, 3879, 777, 2734, 13, 509, 500, 380, 643, 257, 1785, 295, 264, 1523, 2452, 50892], "temperature": 0.0, "avg_logprob": -0.14147936567968253, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.006286755204200745}, {"id": 909, "seek": 356516, "start": 3575.7599999999998, "end": 3579.7599999999998, "text": " learning model to make fake, you know, people have made fake", "tokens": [50894, 2539, 2316, 281, 652, 7592, 11, 291, 458, 11, 561, 362, 1027, 7592, 51094], "temperature": 0.0, "avg_logprob": -0.14147936567968253, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.006286755204200745}, {"id": 910, "seek": 356516, "start": 3579.7599999999998, "end": 3583.7599999999998, "text": " photoshopped by hand forever, people write can write text that", "tokens": [51094, 2409, 18000, 3452, 538, 1011, 5680, 11, 561, 2464, 393, 2464, 2487, 300, 51294], "temperature": 0.0, "avg_logprob": -0.14147936567968253, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.006286755204200745}, {"id": 911, "seek": 356516, "start": 3583.7599999999998, "end": 3587.64, "text": " has all sorts of lies forever. In fact, that's probably more", "tokens": [51294, 575, 439, 7527, 295, 9134, 5680, 13, 682, 1186, 11, 300, 311, 1391, 544, 51488], "temperature": 0.0, "avg_logprob": -0.14147936567968253, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.006286755204200745}, {"id": 912, "seek": 356516, "start": 3587.64, "end": 3591.56, "text": " effective than you know, trying to train a deep learning model", "tokens": [51488, 4942, 813, 291, 458, 11, 1382, 281, 3847, 257, 2452, 2539, 2316, 51684], "temperature": 0.0, "avg_logprob": -0.14147936567968253, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.006286755204200745}, {"id": 913, "seek": 359156, "start": 3591.56, "end": 3595.04, "text": " and, you know, sort of make it work. But I think it's I think", "tokens": [50364, 293, 11, 291, 458, 11, 1333, 295, 652, 309, 589, 13, 583, 286, 519, 309, 311, 286, 519, 50538], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 914, "seek": 359156, "start": 3595.04, "end": 3597.56, "text": " it's a, you know, it's still an important question because the", "tokens": [50538, 309, 311, 257, 11, 291, 458, 11, 309, 311, 920, 364, 1021, 1168, 570, 264, 50664], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 915, "seek": 359156, "start": 3597.56, "end": 3602.0, "text": " easier we make it to make fakes, you start to get issues like a", "tokens": [50664, 3571, 321, 652, 309, 281, 652, 283, 3419, 11, 291, 722, 281, 483, 2663, 411, 257, 50886], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 916, "seek": 359156, "start": 3602.0, "end": 3606.16, "text": " scalable fakes, where it's not just one, one photo that is a lie", "tokens": [50886, 38481, 283, 3419, 11, 689, 309, 311, 406, 445, 472, 11, 472, 5052, 300, 307, 257, 4544, 51094], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 917, "seek": 359156, "start": 3606.16, "end": 3609.92, "text": " or one article is lie, you could generate millions. And I think", "tokens": [51094, 420, 472, 7222, 307, 4544, 11, 291, 727, 8460, 6803, 13, 400, 286, 519, 51282], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 918, "seek": 359156, "start": 3609.92, "end": 3612.56, "text": " that there are serious issues with that. So there's some pretty", "tokens": [51282, 300, 456, 366, 3156, 2663, 365, 300, 13, 407, 456, 311, 512, 1238, 51414], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 919, "seek": 359156, "start": 3612.56, "end": 3617.36, "text": " interesting work in forensics for detecting fakes, and things", "tokens": [51414, 1880, 589, 294, 32034, 1167, 337, 40237, 283, 3419, 11, 293, 721, 51654], "temperature": 0.0, "avg_logprob": -0.13533182380613218, "compression_ratio": 1.7791164658634537, "no_speech_prob": 0.01150110550224781}, {"id": 920, "seek": 361736, "start": 3617.36, "end": 3621.48, "text": " like that. That I think is important to invest in as well", "tokens": [50364, 411, 300, 13, 663, 286, 519, 307, 1021, 281, 1963, 294, 382, 731, 50570], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 921, "seek": 361736, "start": 3621.48, "end": 3625.2400000000002, "text": " as as we as we advance the state of the art and this kind of", "tokens": [50570, 382, 382, 321, 382, 321, 7295, 264, 1785, 295, 264, 1523, 293, 341, 733, 295, 50758], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 922, "seek": 361736, "start": 3625.2400000000002, "end": 3631.04, "text": " thing. So I so so I don't want to minimize the implications of", "tokens": [50758, 551, 13, 407, 286, 370, 370, 286, 500, 380, 528, 281, 17522, 264, 16602, 295, 51048], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 923, "seek": 361736, "start": 3631.04, "end": 3634.1200000000003, "text": " this type of thing. I think that for the type of work that I'm", "tokens": [51048, 341, 2010, 295, 551, 13, 286, 519, 300, 337, 264, 2010, 295, 589, 300, 286, 478, 51202], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 924, "seek": 361736, "start": 3634.1200000000003, "end": 3636.52, "text": " doing, I think that you observe that the tree kind of looks", "tokens": [51202, 884, 11, 286, 519, 300, 291, 11441, 300, 264, 4230, 733, 295, 1542, 51322], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 925, "seek": 361736, "start": 3636.52, "end": 3638.96, "text": " realistic, it's not super realistic. You know, if you're a", "tokens": [51322, 12465, 11, 309, 311, 406, 1687, 12465, 13, 509, 458, 11, 498, 291, 434, 257, 51444], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 926, "seek": 361736, "start": 3638.96, "end": 3645.0, "text": " plant expert, it's just sort of, you know, sort of there. I", "tokens": [51444, 3709, 5844, 11, 309, 311, 445, 1333, 295, 11, 291, 458, 11, 1333, 295, 456, 13, 286, 51746], "temperature": 0.0, "avg_logprob": -0.12953563531239828, "compression_ratio": 1.8232758620689655, "no_speech_prob": 0.043321628123521805}, {"id": 927, "seek": 364500, "start": 3645.04, "end": 3647.4, "text": " think the same thing with hats, they don't really super look", "tokens": [50366, 519, 264, 912, 551, 365, 20549, 11, 436, 500, 380, 534, 1687, 574, 50484], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 928, "seek": 364500, "start": 3647.4, "end": 3650.12, "text": " like hats. And so I think that we're, we're sort of the stage", "tokens": [50484, 411, 20549, 13, 400, 370, 286, 519, 300, 321, 434, 11, 321, 434, 1333, 295, 264, 3233, 50620], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 929, "seek": 364500, "start": 3650.12, "end": 3654.0, "text": " where they're really exciting where the implication of what", "tokens": [50620, 689, 436, 434, 534, 4670, 689, 264, 37814, 295, 437, 50814], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 930, "seek": 364500, "start": 3654.0, "end": 3660.48, "text": " I've done here, I think is the idea that the, you know, learning", "tokens": [50814, 286, 600, 1096, 510, 11, 286, 519, 307, 264, 1558, 300, 264, 11, 291, 458, 11, 2539, 51138], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 931, "seek": 364500, "start": 3660.84, "end": 3664.44, "text": " how these models are working inside, by understanding what", "tokens": [51156, 577, 613, 5245, 366, 1364, 1854, 11, 538, 3701, 437, 51336], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 932, "seek": 364500, "start": 3664.44, "end": 3667.72, "text": " the internal structure of the models is, is really the, that", "tokens": [51336, 264, 6920, 3877, 295, 264, 5245, 307, 11, 307, 534, 264, 11, 300, 51500], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 933, "seek": 364500, "start": 3667.96, "end": 3671.88, "text": " the the exciting part that that it's starting to give a little", "tokens": [51512, 264, 264, 4670, 644, 300, 300, 309, 311, 2891, 281, 976, 257, 707, 51708], "temperature": 0.0, "avg_logprob": -0.15055707179078268, "compression_ratio": 1.7916666666666667, "no_speech_prob": 0.004606866743415594}, {"id": 934, "seek": 367188, "start": 3671.88, "end": 3677.2400000000002, "text": " insight on how we might untangle and disassemble what the", "tokens": [50364, 11269, 322, 577, 321, 1062, 1701, 7846, 293, 717, 37319, 437, 264, 50632], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 935, "seek": 367188, "start": 3677.2400000000002, "end": 3681.56, "text": " internal logic is, that is being learned by these, these deep", "tokens": [50632, 6920, 9952, 307, 11, 300, 307, 885, 3264, 538, 613, 11, 613, 2452, 50848], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 936, "seek": 367188, "start": 3681.56, "end": 3686.4, "text": " networks. And, and I'm actually, I feel like this is, I feel", "tokens": [50848, 9590, 13, 400, 11, 293, 286, 478, 767, 11, 286, 841, 411, 341, 307, 11, 286, 841, 51090], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 937, "seek": 367188, "start": 3686.4, "end": 3688.4, "text": " like there's a different issue other than fakes, which is", "tokens": [51090, 411, 456, 311, 257, 819, 2734, 661, 813, 283, 3419, 11, 597, 307, 51190], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 938, "seek": 367188, "start": 3688.4, "end": 3692.6400000000003, "text": " actually has some ethical implications, which is transparency", "tokens": [51190, 767, 575, 512, 18890, 16602, 11, 597, 307, 17131, 51402], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 939, "seek": 367188, "start": 3692.6400000000003, "end": 3695.2000000000003, "text": " of deep networks. Because one thing that they're not really", "tokens": [51402, 295, 2452, 9590, 13, 1436, 472, 551, 300, 436, 434, 406, 534, 51530], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 940, "seek": 367188, "start": 3695.2000000000003, "end": 3698.6800000000003, "text": " good at doing is when you have a deep network do something", "tokens": [51530, 665, 412, 884, 307, 562, 291, 362, 257, 2452, 3209, 360, 746, 51704], "temperature": 0.0, "avg_logprob": -0.09946689238915077, "compression_ratio": 1.7385892116182573, "no_speech_prob": 0.003481905674561858}, {"id": 941, "seek": 369868, "start": 3698.68, "end": 3701.96, "text": " amazing, they're really not good at answering the question, why?", "tokens": [50364, 2243, 11, 436, 434, 534, 406, 665, 412, 13430, 264, 1168, 11, 983, 30, 50528], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 942, "seek": 369868, "start": 3702.3199999999997, "end": 3705.7999999999997, "text": " Why did you do that? Why did you choose to render it this way?", "tokens": [50546, 1545, 630, 291, 360, 300, 30, 1545, 630, 291, 2826, 281, 15529, 309, 341, 636, 30, 50720], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 943, "seek": 369868, "start": 3705.7999999999997, "end": 3709.68, "text": " Why did you choose to pick these objects to put in the scene?", "tokens": [50720, 1545, 630, 291, 2826, 281, 1888, 613, 6565, 281, 829, 294, 264, 4145, 30, 50914], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 944, "seek": 369868, "start": 3709.68, "end": 3713.56, "text": " Or why did you choose to deny me some credit or to, you know, to", "tokens": [50914, 1610, 983, 630, 291, 2826, 281, 15744, 385, 512, 5397, 420, 281, 11, 291, 458, 11, 281, 51108], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 945, "seek": 369868, "start": 3713.56, "end": 3716.9199999999996, "text": " make some other decision that we were at, you know, depending on", "tokens": [51108, 652, 512, 661, 3537, 300, 321, 645, 412, 11, 291, 458, 11, 5413, 322, 51276], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 946, "seek": 369868, "start": 3716.9199999999996, "end": 3720.6, "text": " neural networks to do. And I think that if we can understand", "tokens": [51276, 18161, 9590, 281, 360, 13, 400, 286, 519, 300, 498, 321, 393, 1223, 51460], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 947, "seek": 369868, "start": 3721.3199999999997, "end": 3725.56, "text": " how to disassemble the rules that are being applied inside the", "tokens": [51496, 577, 281, 717, 37319, 264, 4474, 300, 366, 885, 6456, 1854, 264, 51708], "temperature": 0.0, "avg_logprob": -0.11220354869447906, "compression_ratio": 1.7649402390438247, "no_speech_prob": 0.013212024234235287}, {"id": 948, "seek": 372556, "start": 3725.56, "end": 3728.44, "text": " network for it to make its decision, then I think that we'll", "tokens": [50364, 3209, 337, 309, 281, 652, 1080, 3537, 11, 550, 286, 519, 300, 321, 603, 50508], "temperature": 0.0, "avg_logprob": -0.17391795108192845, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.001431203680112958}, {"id": 949, "seek": 372556, "start": 3728.48, "end": 3733.24, "text": " will be, we'll have a way of asking why. And by looking at", "tokens": [50510, 486, 312, 11, 321, 603, 362, 257, 636, 295, 3365, 983, 13, 400, 538, 1237, 412, 50748], "temperature": 0.0, "avg_logprob": -0.17391795108192845, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.001431203680112958}, {"id": 950, "seek": 372556, "start": 3733.24, "end": 3736.32, "text": " the computation directly. So that's my, that's one of my", "tokens": [50748, 264, 24903, 3838, 13, 407, 300, 311, 452, 11, 300, 311, 472, 295, 452, 50902], "temperature": 0.0, "avg_logprob": -0.17391795108192845, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.001431203680112958}, {"id": 951, "seek": 372556, "start": 3736.32, "end": 3738.24, "text": " goals and one of my hopes in doing this kind of work.", "tokens": [50902, 5493, 293, 472, 295, 452, 13681, 294, 884, 341, 733, 295, 589, 13, 50998], "temperature": 0.0, "avg_logprob": -0.17391795108192845, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.001431203680112958}, {"id": 952, "seek": 372556, "start": 3741.72, "end": 3746.52, "text": " Definitely, I can see some of the worst of you about like,", "tokens": [51172, 12151, 11, 286, 393, 536, 512, 295, 264, 5855, 295, 291, 466, 411, 11, 51412], "temperature": 0.0, "avg_logprob": -0.17391795108192845, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.001431203680112958}, {"id": 953, "seek": 372556, "start": 3747.96, "end": 3751.24, "text": " about the transparency of the neural network, especially when", "tokens": [51484, 466, 264, 17131, 295, 264, 18161, 3209, 11, 2318, 562, 51648], "temperature": 0.0, "avg_logprob": -0.17391795108192845, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.001431203680112958}, {"id": 954, "seek": 375124, "start": 3751.24, "end": 3756.12, "text": " you, when you show the example where you detected a single", "tokens": [50364, 291, 11, 562, 291, 855, 264, 1365, 689, 291, 21896, 257, 2167, 50608], "temperature": 0.0, "avg_logprob": -0.24816202830119305, "compression_ratio": 1.613861386138614, "no_speech_prob": 0.0016962047666311264}, {"id": 955, "seek": 375124, "start": 3756.12, "end": 3760.12, "text": " neuron that contributes to the watermark thing, I think that", "tokens": [50608, 34090, 300, 32035, 281, 264, 1281, 5638, 551, 11, 286, 519, 300, 50808], "temperature": 0.0, "avg_logprob": -0.24816202830119305, "compression_ratio": 1.613861386138614, "no_speech_prob": 0.0016962047666311264}, {"id": 956, "seek": 375124, "start": 3761.3599999999997, "end": 3762.3999999999996, "text": " it was really interesting.", "tokens": [50870, 309, 390, 534, 1880, 13, 50922], "temperature": 0.0, "avg_logprob": -0.24816202830119305, "compression_ratio": 1.613861386138614, "no_speech_prob": 0.0016962047666311264}, {"id": 957, "seek": 375124, "start": 3763.72, "end": 3767.4399999999996, "text": " Yeah, I think so too. I was surprised that it worked because", "tokens": [50988, 865, 11, 286, 519, 370, 886, 13, 286, 390, 6100, 300, 309, 2732, 570, 51174], "temperature": 0.0, "avg_logprob": -0.24816202830119305, "compression_ratio": 1.613861386138614, "no_speech_prob": 0.0016962047666311264}, {"id": 958, "seek": 375124, "start": 3767.4399999999996, "end": 3770.2799999999997, "text": " we normally think of neural X is very, very, very opaque.", "tokens": [51174, 321, 5646, 519, 295, 18161, 1783, 307, 588, 11, 588, 11, 588, 42687, 13, 51316], "temperature": 0.0, "avg_logprob": -0.24816202830119305, "compression_ratio": 1.613861386138614, "no_speech_prob": 0.0016962047666311264}, {"id": 959, "seek": 375124, "start": 3774.16, "end": 3779.3199999999997, "text": " I also have a small question regarding artifacts. So I think", "tokens": [51510, 286, 611, 362, 257, 1359, 1168, 8595, 24617, 13, 407, 286, 519, 51768], "temperature": 0.0, "avg_logprob": -0.24816202830119305, "compression_ratio": 1.613861386138614, "no_speech_prob": 0.0016962047666311264}, {"id": 960, "seek": 377932, "start": 3779.56, "end": 3784.1600000000003, "text": " in the beginning, you talked about how you segmented the", "tokens": [50376, 294, 264, 2863, 11, 291, 2825, 466, 577, 291, 9469, 292, 264, 50606], "temperature": 0.0, "avg_logprob": -0.23124625077888147, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.001064214389771223}, {"id": 961, "seek": 377932, "start": 3784.2400000000002, "end": 3790.6000000000004, "text": " network with like masks that were classified before by mapping", "tokens": [50610, 3209, 365, 411, 11830, 300, 645, 20627, 949, 538, 18350, 50928], "temperature": 0.0, "avg_logprob": -0.23124625077888147, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.001064214389771223}, {"id": 962, "seek": 377932, "start": 3790.7200000000003, "end": 3795.7200000000003, "text": " neurons and beginning layers, which create things. But could", "tokens": [50934, 22027, 293, 2863, 7914, 11, 597, 1884, 721, 13, 583, 727, 51184], "temperature": 0.0, "avg_logprob": -0.23124625077888147, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.001064214389771223}, {"id": 963, "seek": 377932, "start": 3795.76, "end": 3800.36, "text": " like, can that be also used to figure out where artifacts or", "tokens": [51186, 411, 11, 393, 300, 312, 611, 1143, 281, 2573, 484, 689, 24617, 420, 51416], "temperature": 0.0, "avg_logprob": -0.23124625077888147, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.001064214389771223}, {"id": 964, "seek": 377932, "start": 3800.36, "end": 3804.4, "text": " anomalies are generated to make gains better?", "tokens": [51416, 24769, 48872, 366, 10833, 281, 652, 16823, 1101, 30, 51618], "temperature": 0.0, "avg_logprob": -0.23124625077888147, "compression_ratio": 1.5265957446808511, "no_speech_prob": 0.001064214389771223}, {"id": 965, "seek": 380440, "start": 3804.96, "end": 3810.88, "text": " Yeah, actually, I don't have a picture of it here. But in my", "tokens": [50392, 865, 11, 767, 11, 286, 500, 380, 362, 257, 3036, 295, 309, 510, 13, 583, 294, 452, 50688], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 966, "seek": 380440, "start": 3810.88, "end": 3814.64, "text": " work where I was looking for neurons, originally, it's called", "tokens": [50688, 589, 689, 286, 390, 1237, 337, 22027, 11, 7993, 11, 309, 311, 1219, 50876], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 967, "seek": 380440, "start": 3814.92, "end": 3817.4, "text": " the paper is called GAN dissection, you can you can", "tokens": [50890, 264, 3035, 307, 1219, 460, 1770, 717, 11963, 11, 291, 393, 291, 393, 51014], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 968, "seek": 380440, "start": 3817.4, "end": 3822.76, "text": " Google for it. And, and I showed that in that paper, we", "tokens": [51014, 3329, 337, 309, 13, 400, 11, 293, 286, 4712, 300, 294, 300, 3035, 11, 321, 51282], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 969, "seek": 380440, "start": 3822.76, "end": 3825.8, "text": " analyze some of the pre trained GANs that came from a previous", "tokens": [51282, 12477, 512, 295, 264, 659, 8895, 460, 1770, 82, 300, 1361, 490, 257, 3894, 51434], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 970, "seek": 380440, "start": 3826.0, "end": 3830.28, "text": " work from NVIDIA called progressive GAN, we analyzed", "tokens": [51444, 589, 490, 426, 3958, 6914, 1219, 16131, 460, 1770, 11, 321, 28181, 51658], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 971, "seek": 380440, "start": 3830.28, "end": 3832.88, "text": " some of the pre trained models, and we found that they actually", "tokens": [51658, 512, 295, 264, 659, 8895, 5245, 11, 293, 321, 1352, 300, 436, 767, 51788], "temperature": 0.0, "avg_logprob": -0.21007104046576847, "compression_ratio": 1.7226890756302522, "no_speech_prob": 0.0015484646428376436}, {"id": 972, "seek": 383288, "start": 3832.88, "end": 3836.56, "text": " are neurons that correlate with bad looking artifacts in a", "tokens": [50364, 366, 22027, 300, 48742, 365, 1578, 1237, 24617, 294, 257, 50548], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 973, "seek": 383288, "start": 3836.56, "end": 3840.2400000000002, "text": " scene. And if you turn those neurons off, you can actually", "tokens": [50548, 4145, 13, 400, 498, 291, 1261, 729, 22027, 766, 11, 291, 393, 767, 50732], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 974, "seek": 383288, "start": 3840.6400000000003, "end": 3845.08, "text": " not only improve the quality of the output of the GAN, just", "tokens": [50752, 406, 787, 3470, 264, 3125, 295, 264, 5598, 295, 264, 460, 1770, 11, 445, 50974], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 975, "seek": 383288, "start": 3845.08, "end": 3848.76, "text": " qualitatively like you can get these artifacts to not show up", "tokens": [50974, 31312, 356, 411, 291, 393, 483, 613, 24617, 281, 406, 855, 493, 51158], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 976, "seek": 383288, "start": 3848.76, "end": 3853.76, "text": " but using standard measures of GAN, you know, statistical", "tokens": [51158, 457, 1228, 3832, 8000, 295, 460, 1770, 11, 291, 458, 11, 22820, 51408], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 977, "seek": 383288, "start": 3853.76, "end": 3857.7200000000003, "text": " measures of GAN image fidelity at large scale. By removing these", "tokens": [51408, 8000, 295, 460, 1770, 3256, 46404, 412, 2416, 4373, 13, 3146, 12720, 613, 51606], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 978, "seek": 383288, "start": 3857.7200000000003, "end": 3861.28, "text": " neurons, you can actually improve the what we call the FID", "tokens": [51606, 22027, 11, 291, 393, 767, 3470, 264, 437, 321, 818, 264, 479, 2777, 51784], "temperature": 0.0, "avg_logprob": -0.1263509398525201, "compression_ratio": 1.7541666666666667, "no_speech_prob": 0.0018671447178348899}, {"id": 979, "seek": 386128, "start": 3861.28, "end": 3865.1200000000003, "text": " scores of these GANs when we tested on like 50,000 images. And", "tokens": [50364, 13444, 295, 613, 460, 1770, 82, 562, 321, 8246, 322, 411, 2625, 11, 1360, 5267, 13, 400, 50556], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 980, "seek": 386128, "start": 3865.1200000000003, "end": 3869.32, "text": " so, so that's actually very weird to me, that's, it was a big", "tokens": [50556, 370, 11, 370, 300, 311, 767, 588, 3657, 281, 385, 11, 300, 311, 11, 309, 390, 257, 955, 50766], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 981, "seek": 386128, "start": 3869.32, "end": 3875.76, "text": " surprise. Because, because we, we train these things using, you", "tokens": [50766, 6365, 13, 1436, 11, 570, 321, 11, 321, 3847, 613, 721, 1228, 11, 291, 51088], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 982, "seek": 386128, "start": 3875.76, "end": 3879.7200000000003, "text": " know, powerful optimization techniques, using, you know,", "tokens": [51088, 458, 11, 4005, 19618, 7512, 11, 1228, 11, 291, 458, 11, 51286], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 983, "seek": 386128, "start": 3879.92, "end": 3882.6000000000004, "text": " billions of floating point operations, you know, training", "tokens": [51296, 17375, 295, 12607, 935, 7705, 11, 291, 458, 11, 3097, 51430], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 984, "seek": 386128, "start": 3882.6000000000004, "end": 3886.0400000000004, "text": " these things on big expensive GPUs for a long period of time. And", "tokens": [51430, 613, 721, 322, 955, 5124, 18407, 82, 337, 257, 938, 2896, 295, 565, 13, 400, 51602], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 985, "seek": 386128, "start": 3886.0400000000004, "end": 3890.0, "text": " the idea that a human can come along, and do a simple looking", "tokens": [51602, 264, 1558, 300, 257, 1952, 393, 808, 2051, 11, 293, 360, 257, 2199, 1237, 51800], "temperature": 0.0, "avg_logprob": -0.1463032100511634, "compression_ratio": 1.6264150943396227, "no_speech_prob": 0.0016223900020122528}, {"id": 986, "seek": 389000, "start": 3890.12, "end": 3893.04, "text": " visualization, pick out a few neurons based on things that", "tokens": [50370, 25801, 11, 1888, 484, 257, 1326, 22027, 2361, 322, 721, 300, 50516], "temperature": 0.0, "avg_logprob": -0.16344105467504386, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0022511922288686037}, {"id": 987, "seek": 389000, "start": 3893.16, "end": 3897.12, "text": " don't look good. And improve the model by turning those neurons", "tokens": [50522, 500, 380, 574, 665, 13, 400, 3470, 264, 2316, 538, 6246, 729, 22027, 50720], "temperature": 0.0, "avg_logprob": -0.16344105467504386, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0022511922288686037}, {"id": 988, "seek": 389000, "start": 3897.12, "end": 3901.92, "text": " off. It was like it shouldn't be possible, right? If it was so", "tokens": [50720, 766, 13, 467, 390, 411, 309, 4659, 380, 312, 1944, 11, 558, 30, 759, 309, 390, 370, 50960], "temperature": 0.0, "avg_logprob": -0.16344105467504386, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0022511922288686037}, {"id": 989, "seek": 389000, "start": 3901.92, "end": 3905.36, "text": " easy to improve the model that way, why couldn't the optimizer", "tokens": [50960, 1858, 281, 3470, 264, 2316, 300, 636, 11, 983, 2809, 380, 264, 5028, 6545, 51132], "temperature": 0.0, "avg_logprob": -0.16344105467504386, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0022511922288686037}, {"id": 990, "seek": 389000, "start": 3905.92, "end": 3910.52, "text": " find it? And so, so I think that was, that was, that was pretty", "tokens": [51160, 915, 309, 30, 400, 370, 11, 370, 286, 519, 300, 390, 11, 300, 390, 11, 300, 390, 1238, 51390], "temperature": 0.0, "avg_logprob": -0.16344105467504386, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0022511922288686037}, {"id": 991, "seek": 389000, "start": 3910.52, "end": 3917.24, "text": " interesting. I have not repeated that experiment on the latest", "tokens": [51390, 1880, 13, 286, 362, 406, 10477, 300, 5120, 322, 264, 6792, 51726], "temperature": 0.0, "avg_logprob": -0.16344105467504386, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0022511922288686037}, {"id": 992, "seek": 391724, "start": 3917.2799999999997, "end": 3921.2799999999997, "text": " GANs, which are actually much better the style GANs. To", "tokens": [50366, 460, 1770, 82, 11, 597, 366, 767, 709, 1101, 264, 3758, 460, 1770, 82, 13, 1407, 50566], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 993, "seek": 391724, "start": 3921.2799999999997, "end": 3925.2799999999997, "text": " architecture, they went back and they analyzed a bunch of the", "tokens": [50566, 9482, 11, 436, 1437, 646, 293, 436, 28181, 257, 3840, 295, 264, 50766], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 994, "seek": 391724, "start": 3925.2799999999997, "end": 3929.9199999999996, "text": " artifacts that show up in this, this family of GANs. And they,", "tokens": [50766, 24617, 300, 855, 493, 294, 341, 11, 341, 1605, 295, 460, 1770, 82, 13, 400, 436, 11, 50998], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 995, "seek": 391724, "start": 3929.9599999999996, "end": 3931.9199999999996, "text": " they found that there are certain learning methods that they", "tokens": [51000, 436, 1352, 300, 456, 366, 1629, 2539, 7150, 300, 436, 51098], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 996, "seek": 391724, "start": 3931.9199999999996, "end": 3935.3999999999996, "text": " can do to remove the artifacts or reduce them somewhat. And so I", "tokens": [51098, 393, 360, 281, 4159, 264, 24617, 420, 5407, 552, 8344, 13, 400, 370, 286, 51272], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 997, "seek": 391724, "start": 3935.3999999999996, "end": 3940.3999999999996, "text": " don't know if a human can still beat the current generation of", "tokens": [51272, 500, 380, 458, 498, 257, 1952, 393, 920, 4224, 264, 2190, 5125, 295, 51522], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 998, "seek": 391724, "start": 3940.3999999999996, "end": 3943.52, "text": " GANs, it'd be worth going back and seeing that phenomenon is", "tokens": [51522, 460, 1770, 82, 11, 309, 1116, 312, 3163, 516, 646, 293, 2577, 300, 14029, 307, 51678], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 999, "seek": 391724, "start": 3943.52, "end": 3944.0, "text": " still there.", "tokens": [51678, 920, 456, 13, 51702], "temperature": 0.0, "avg_logprob": -0.14648978993044062, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.007008570712059736}, {"id": 1000, "seek": 394400, "start": 3944.88, "end": 3947.0, "text": " That's pretty cool. Thank you. Yep.", "tokens": [50408, 663, 311, 1238, 1627, 13, 1044, 291, 13, 7010, 13, 50514], "temperature": 0.0, "avg_logprob": -0.38236547197614396, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.0013222002889961004}, {"id": 1001, "seek": 394400, "start": 3951.0, "end": 3955.0, "text": " Okay, excellent. Thank you so much, David. It was really", "tokens": [50714, 1033, 11, 7103, 13, 1044, 291, 370, 709, 11, 4389, 13, 467, 390, 534, 50914], "temperature": 0.0, "avg_logprob": -0.38236547197614396, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.0013222002889961004}, {"id": 1002, "seek": 394400, "start": 3955.24, "end": 3962.4, "text": " fascinating topic and talk and more interesting to me, asking", "tokens": [50926, 10343, 4829, 293, 751, 293, 544, 1880, 281, 385, 11, 3365, 51284], "temperature": 0.0, "avg_logprob": -0.38236547197614396, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.0013222002889961004}, {"id": 1003, "seek": 394400, "start": 3962.4, "end": 3966.6, "text": " the right questions, asking questions and learning to ask", "tokens": [51284, 264, 558, 1651, 11, 3365, 1651, 293, 2539, 281, 1029, 51494], "temperature": 0.0, "avg_logprob": -0.38236547197614396, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.0013222002889961004}, {"id": 1004, "seek": 394400, "start": 3966.6, "end": 3970.16, "text": " the right questions. It's really interesting. And I think that", "tokens": [51494, 264, 558, 1651, 13, 467, 311, 534, 1880, 13, 400, 286, 519, 300, 51672], "temperature": 0.0, "avg_logprob": -0.38236547197614396, "compression_ratio": 1.6467065868263473, "no_speech_prob": 0.0013222002889961004}, {"id": 1005, "seek": 397016, "start": 3970.2799999999997, "end": 3973.2799999999997, "text": " it opened paths to many of us.", "tokens": [50370, 309, 5625, 14518, 281, 867, 295, 505, 13, 50520], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1006, "seek": 397016, "start": 3974.04, "end": 3977.3999999999996, "text": " Excellent. Hey, thank you for the opportunity to talk to the", "tokens": [50558, 16723, 13, 1911, 11, 1309, 291, 337, 264, 2650, 281, 751, 281, 264, 50726], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1007, "seek": 397016, "start": 3977.3999999999996, "end": 3983.6, "text": " group here today. I always enjoy the, the chance to interact", "tokens": [50726, 1594, 510, 965, 13, 286, 1009, 2103, 264, 11, 264, 2931, 281, 4648, 51036], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1008, "seek": 397016, "start": 3983.6, "end": 3987.2, "text": " with folks about this. If anybody wants to send other questions", "tokens": [51036, 365, 4024, 466, 341, 13, 759, 4472, 2738, 281, 2845, 661, 1651, 51216], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1009, "seek": 397016, "start": 3987.2, "end": 3992.3599999999997, "text": " about it, of course, you can always send me a note. And, you", "tokens": [51216, 466, 309, 11, 295, 1164, 11, 291, 393, 1009, 2845, 385, 257, 3637, 13, 400, 11, 291, 51474], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1010, "seek": 397016, "start": 3992.3599999999997, "end": 3993.52, "text": " know, I love this stuff.", "tokens": [51474, 458, 11, 286, 959, 341, 1507, 13, 51532], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1011, "seek": 397016, "start": 3993.7999999999997, "end": 3998.2799999999997, "text": " Yeah, definitely. I think that it would be great to follow", "tokens": [51546, 865, 11, 2138, 13, 286, 519, 300, 309, 576, 312, 869, 281, 1524, 51770], "temperature": 0.0, "avg_logprob": -0.33745478620432845, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.0014982501743361354}, {"id": 1012, "seek": 399828, "start": 3998.6400000000003, "end": 4003.96, "text": " follow your work on your GitHub and your website, and", "tokens": [50382, 1524, 428, 589, 322, 428, 23331, 293, 428, 3144, 11, 293, 50648], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1013, "seek": 399828, "start": 4003.96, "end": 4007.1600000000003, "text": " especially for students who play with the tools that you have,", "tokens": [50648, 2318, 337, 1731, 567, 862, 365, 264, 3873, 300, 291, 362, 11, 50808], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1014, "seek": 399828, "start": 4007.1600000000003, "end": 4010.52, "text": " so they have them get an understanding of how these two", "tokens": [50808, 370, 436, 362, 552, 483, 364, 3701, 295, 577, 613, 732, 50976], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1015, "seek": 399828, "start": 4010.52, "end": 4013.36, "text": " work and make them curious about the work.", "tokens": [50976, 589, 293, 652, 552, 6369, 466, 264, 589, 13, 51118], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1016, "seek": 399828, "start": 4013.88, "end": 4014.36, "text": " Cool.", "tokens": [51144, 8561, 13, 51168], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1017, "seek": 399828, "start": 4015.0800000000004, "end": 4016.5600000000004, "text": " Excellent. Thank you so much.", "tokens": [51204, 16723, 13, 1044, 291, 370, 709, 13, 51278], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1018, "seek": 399828, "start": 4017.32, "end": 4018.84, "text": " Thank you, Ali. Thank you, everybody.", "tokens": [51316, 1044, 291, 11, 12020, 13, 1044, 291, 11, 2201, 13, 51392], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}, {"id": 1019, "seek": 399828, "start": 4019.44, "end": 4021.48, "text": " Thank you. Bye now.", "tokens": [51422, 1044, 291, 13, 4621, 586, 13, 51524], "temperature": 0.0, "avg_logprob": -0.22027318617876837, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.0008147826883941889}], "language": "en"}