WEBVTT

00:00.000 --> 00:04.160
The special speaker that we have today is Professor Ahmed

00:04.160 --> 00:05.600
Al-Gamal.

00:05.600 --> 00:09.540
He's a professor in the Department of Computer Science

00:09.540 --> 00:14.560
at Rutgers University and also the founder of the Art

00:14.560 --> 00:19.200
and Artificial Intelligence Lab at Rutgers.

00:19.200 --> 00:26.920
So let us ask Professor Al-Gamal to be a little more

00:26.920 --> 00:30.040
introduce themselves and give us a little background

00:30.040 --> 00:31.480
and talk.

00:31.480 --> 00:33.040
One thing that I wanted to mention

00:33.040 --> 00:37.840
is that his talk is today is about the shape of the art

00:37.840 --> 00:41.240
history in the eyes of the machine.

00:41.240 --> 00:44.320
And I think that he has done many interesting work

00:44.320 --> 00:50.680
in the realm of understanding the patterns and evolution

00:50.680 --> 00:53.920
of art through the history.

00:53.920 --> 00:54.680
Please go ahead.

00:54.680 --> 00:55.640
Thank you.

00:55.640 --> 00:56.320
Thank you very much.

00:56.320 --> 01:00.680
Thank you for inviting me and thank everybody who is here.

01:00.680 --> 01:03.280
I'll start by answering a question you asked earlier

01:03.280 --> 01:05.360
about why I'm doing this.

01:05.360 --> 01:09.640
And I think it will be more also clear during the talk.

01:09.640 --> 01:13.960
Basically, during my high school years,

01:13.960 --> 01:16.440
I mean, I was raised up in Alexandria, Egypt.

01:16.440 --> 01:18.280
And when you raise up in the country,

01:18.280 --> 01:19.400
it all has to be like that.

01:19.400 --> 01:22.840
You see a lot of archaeology and history and art.

01:22.840 --> 01:26.640
And I really wanted to study archaeology and art history.

01:26.640 --> 01:28.200
That was really my passion.

01:28.200 --> 01:30.240
But at the same time, computer science

01:30.240 --> 01:34.920
was something totally new at that time around the 1990s.

01:34.920 --> 01:36.520
And I was fascinated by it.

01:36.520 --> 01:38.080
I had to choose a major.

01:38.080 --> 01:40.320
So everybody would tell me, if you go to archaeology,

01:40.320 --> 01:43.560
art history, you'll have no career and make no money.

01:43.560 --> 01:46.320
And I went to study computer science.

01:46.320 --> 01:49.920
And for the last 25 years, I've been doing AI.

01:49.960 --> 01:53.000
But I find that actually my passion is really in art.

01:53.000 --> 01:56.120
Every time I go to the division conference,

01:56.120 --> 01:58.440
I escape 90% of the conference.

01:58.440 --> 02:00.800
And I go to galleries and museums rather than

02:00.800 --> 02:01.720
attending the sessions.

02:01.720 --> 02:04.280
And I realize I have to do something about it.

02:04.280 --> 02:07.320
And it will be clear in the talk basically

02:07.320 --> 02:10.720
how I moved into doing that and why I moved to do that.

02:10.720 --> 02:14.560
So let me just start right away by sharing my screen.

02:14.560 --> 02:17.120
So basically, as an AI researcher,

02:17.120 --> 02:22.120
or when I look at images like that,

02:22.120 --> 02:25.440
I mean, we'll be very happy if the machine will recognize

02:25.440 --> 02:28.920
there's a man, there's a woman, there's fruits, there's trees.

02:28.920 --> 02:31.440
There are trees and things like that.

02:31.440 --> 02:34.120
That's what we do in vision.

02:34.120 --> 02:36.080
And that's what I've been doing for a long time also.

02:36.080 --> 02:39.840
However, basically, we realize that art, when you look at art,

02:39.840 --> 02:40.640
is much more than that.

02:40.640 --> 02:45.120
There are layers and layers of historical context,

02:45.120 --> 02:47.880
social context, understanding.

02:47.880 --> 02:49.960
There are emotions that happens.

02:49.960 --> 02:53.080
I mean, art is not about object recognition or anything like that.

02:53.080 --> 02:53.920
We see it as recognition.

02:53.920 --> 02:55.600
It's much more.

02:55.600 --> 02:57.440
And since the ultimate goal of AI research

02:57.440 --> 03:00.080
is to make the machine, make machine

03:00.080 --> 03:03.440
that have perceptual, cognitive, and intellectual abilities

03:03.440 --> 03:06.240
similar to those of humans, I find

03:06.240 --> 03:10.280
that analysis of paintings, whatever analysis means,

03:10.280 --> 03:14.400
involve actually all these tasks, perception, cognition,

03:14.400 --> 03:16.240
and intellectual abilities.

03:16.240 --> 03:20.160
And that's why I think it's very important to advance AI

03:20.160 --> 03:27.360
to look at art and try to understand art the same way human does.

03:27.360 --> 03:33.120
So basically, I find that the ability to understand and generate

03:33.120 --> 03:36.440
human-level creative products, such as poetry, stories,

03:36.440 --> 03:38.880
jokes, music, paintings, is fundamental

03:38.880 --> 03:43.160
to show that artificial intelligence algorithm

03:43.200 --> 03:45.440
are actually intelligence.

03:45.440 --> 03:47.680
And the first question that always

03:47.680 --> 03:51.840
being asked when I give talks, especially in humanities,

03:51.840 --> 03:55.720
with audience from humanities, is how to combine art and AI.

03:55.720 --> 04:00.080
Basically, art is a judgment, which is subjective,

04:00.080 --> 04:01.400
and science is objective.

04:01.400 --> 04:03.760
How can this be combined?

04:03.760 --> 04:05.120
And that's a very important question.

04:05.120 --> 04:09.440
And actually, it's rooted in Western philosophy.

04:09.440 --> 04:14.320
Basically, Western philosophy has blazed aesthetic comprehension

04:14.320 --> 04:16.120
in the realm of subjectivity.

04:16.120 --> 04:22.760
And we can trace that back to Immanuel Kant in 18th century

04:22.760 --> 04:27.240
when in his book about critique of the judgment,

04:27.240 --> 04:31.240
when he basically argued that the judgment of taste

04:31.240 --> 04:35.080
is not cognitive judgment, it's not logical,

04:35.080 --> 04:38.520
but aesthetic, which means that it's

04:38.520 --> 04:42.600
one whose determinant ground cannot be other than subjective.

04:42.600 --> 04:45.720
And that actually shaped the separation between art and science

04:45.720 --> 04:47.040
in the last two centuries.

04:47.040 --> 04:50.320
So another quote here from Colin Martindale,

04:50.320 --> 04:53.600
who is a psychology professor at University of Maine,

04:53.600 --> 04:56.880
who has a totally different, opposite point of view.

04:56.880 --> 05:00.600
As a scientist, I feel that if everything in the universe

05:00.600 --> 05:03.680
is governed by laws, then art history must be as well.

05:03.680 --> 05:09.040
So totally scientific approach, basically nothing is subjective.

05:09.040 --> 05:11.840
And another viewpoint from Eric Kindle,

05:11.840 --> 05:16.200
who's a neuroscientist and winner of Nobel Prize,

05:16.200 --> 05:20.240
by examining perception of art as an interpretation of science

05:20.240 --> 05:23.840
we experience, scientific eyes can, in principle,

05:23.840 --> 05:26.680
describe how the brain perceives and responds to art.

05:26.680 --> 05:30.160
And let me go into basically saying, can any aspect of art,

05:30.160 --> 05:33.760
which is creative and subjective experience,

05:33.760 --> 05:36.600
be studied objectively?

05:36.600 --> 05:39.000
And finally, a quote from an art historian,

05:39.000 --> 05:41.240
which is very unusual art historian.

05:41.240 --> 05:46.280
His name is George Kubler from his book, The Shape of Time,

05:46.280 --> 05:49.520
which I'm going to talk about in the talk a little bit later.

05:49.520 --> 05:50.960
He's saying basically that art history could

05:50.960 --> 05:53.320
move to contain unexpected potentiality

05:53.320 --> 05:55.000
as a predictive science.

05:55.000 --> 05:58.800
This is very uncommon view in art history.

05:58.800 --> 06:01.200
So my goal is really to understand

06:01.200 --> 06:03.280
what art the implication of looking at art

06:03.280 --> 06:05.360
through the eyes of the machine.

06:05.360 --> 06:08.800
And by that I mean AI in particular.

06:08.800 --> 06:12.200
That's why I started the AI lab about maybe eight years ago

06:12.200 --> 06:15.640
at Rutgers, really focusing on advancing AI by looking at art

06:15.640 --> 06:20.880
and also seeing what can we do about art if we do AI.

06:20.880 --> 06:24.120
And here are some of my collaborators from art history,

06:24.120 --> 06:28.400
from fine art, and have been blessed to work

06:28.400 --> 06:31.000
with many students from Rutgers and from other universities

06:31.000 --> 06:32.480
as well.

06:32.480 --> 06:34.760
And these are some of the activities

06:34.760 --> 06:37.480
that have been done through the years, many others.

06:37.480 --> 06:40.040
And these are some things I'm going to talk about today.

06:40.040 --> 06:44.720
Building models to understand art style, genre,

06:44.720 --> 06:48.280
doing art specification, try to understand influences

06:48.280 --> 06:52.400
between artists, try to understand creativity,

06:52.400 --> 06:57.240
how to quantify creativity, how to generate art,

06:57.240 --> 06:59.720
how to understand the evolution of art history.

06:59.720 --> 07:03.640
Many things have been done during these years.

07:03.640 --> 07:06.560
But let me start by the basics, basically.

07:06.560 --> 07:08.720
So how artists talk about art.

07:08.720 --> 07:12.360
So if you look at an artwork like this amazing Renoir

07:12.360 --> 07:15.560
painting, basically artists doesn't look at this

07:15.560 --> 07:19.040
and tell you there are multiple people

07:19.040 --> 07:21.080
or people are eating food or things like that.

07:21.080 --> 07:24.400
Basically talk about artists talk about elements of art,

07:24.400 --> 07:26.840
the space, the texture, the form, the shape, the color,

07:26.840 --> 07:30.160
things like that, principles of art, the movement, the unity,

07:30.160 --> 07:33.520
the harmony, balance, contrast.

07:33.520 --> 07:35.920
Other topics like subject matter, brushstrokes,

07:35.920 --> 07:39.200
meaning, historical context, social context.

07:39.200 --> 07:41.600
All these things are basically what artists talk about when

07:41.600 --> 07:42.640
talk about art.

07:42.640 --> 07:45.320
Their least concern is things like object or scene

07:45.320 --> 07:49.240
classification and things like that or genre caption.

07:49.240 --> 07:53.120
So our goal really was in the last few years

07:53.120 --> 07:54.680
is trying to quantify each of these elements.

07:54.680 --> 07:57.360
And we have done a lot of work on quantifying each of these

07:57.360 --> 07:59.240
elements.

07:59.240 --> 08:03.560
How to do visual encoding of the image

08:03.560 --> 08:06.520
in order to be able to quantify these elements

08:06.520 --> 08:08.520
and principles of art.

08:08.520 --> 08:10.760
And in particular, one of the very, very important things

08:10.760 --> 08:14.000
in art is the topic of style.

08:14.000 --> 08:15.120
So what is style?

08:15.120 --> 08:20.640
So basically here, this is a depiction of the last suburb.

08:20.640 --> 08:22.800
So basically the famous painting by DaVinci.

08:22.800 --> 08:25.560
But DaVinci's painting here is just one of them.

08:25.560 --> 08:28.960
This is much earlier to a version,

08:28.960 --> 08:33.320
a mini version by many artists, to 20th century versions.

08:33.320 --> 08:35.920
And really in here, you can see what

08:35.920 --> 08:38.120
is the meaning of style in one slide like that.

08:38.120 --> 08:42.040
We're basically depicting the subject matter

08:42.040 --> 08:46.400
in two different ways, depending on historical point

08:46.400 --> 08:50.120
in what happened in art history that

08:50.160 --> 08:54.840
specify how the artist will depict the scene.

08:54.840 --> 08:55.800
And here's the fair thing.

08:55.800 --> 08:59.640
I mean, if you look at this and what artists mean by style

08:59.640 --> 09:05.000
and compare that to what we in computer vision or AI do

09:05.000 --> 09:07.520
when you do things like style transfer and things like that,

09:07.520 --> 09:10.400
to theorize, basically, it's a joke that the way we do

09:10.400 --> 09:13.200
style transfer in machine learning and computer vision,

09:13.200 --> 09:15.440
which is mainly basically meaning taking the ballot

09:15.440 --> 09:17.760
from one image to another or a texture from one image

09:17.760 --> 09:20.240
to another has nothing to do with the concept of style

09:20.240 --> 09:22.040
in reality, because the concept of style

09:22.040 --> 09:25.560
is much more deeper than just these simple things.

09:26.520 --> 09:30.880
So the question really is what characterizes the sequence

09:30.880 --> 09:34.160
and evolution of art style change over time?

09:34.160 --> 09:36.080
How can we characterize these changes?

09:36.080 --> 09:38.920
And actually what factors drive these changes

09:38.920 --> 09:39.760
of style over time?

09:39.760 --> 09:42.200
Why even artists change style over time?

09:42.200 --> 09:45.120
When that happened, what triggers it

09:45.120 --> 09:47.880
and how to characterize it when it happens?

09:47.880 --> 09:49.400
Can we build conventional models

09:49.400 --> 09:51.880
that can help answer these questions?

09:53.400 --> 09:55.720
So we started very early with a very simple thing,

09:55.720 --> 09:58.560
which is painting style classification.

09:58.560 --> 10:02.360
You have a bunch of images and you have style labels on them.

10:02.360 --> 10:05.600
So it's really a simple supervised machine learning

10:05.600 --> 10:08.640
problem and you wanna classify the painting to think classes

10:08.640 --> 10:11.080
like Renaissance, Baroque, Impressionism, Cubism,

10:11.080 --> 10:12.600
abstract things like that.

10:12.600 --> 10:14.600
So very simple problem.

10:14.600 --> 10:18.920
And we take a painting, we have visual encoding

10:18.920 --> 10:22.720
using different pictures, trying to capture

10:22.720 --> 10:25.000
the low-level, mid-level, semantic-level picture,

10:25.000 --> 10:28.440
which are parallel to different concept art, as I mentioned,

10:28.440 --> 10:32.160
and trying different machine learning techniques on them

10:32.160 --> 10:35.440
and doing supervised learning to classify style.

10:35.440 --> 10:38.160
And basically this is so progress over the years

10:38.160 --> 10:42.840
from the year 2012, maybe three years ago,

10:42.880 --> 10:45.760
where we have been really trying any new things

10:45.760 --> 10:49.520
that have happened in machine learning and see what it adds.

10:50.760 --> 10:54.200
Things from the time of the bag of words and classmates

10:54.200 --> 10:56.960
and HOGs, if you really remember that,

10:58.280 --> 11:03.280
till the time of CNNs and deep learning.

11:03.520 --> 11:07.160
The number of style classes that have been basically

11:07.160 --> 11:11.840
increasing the number of classes over time,

11:11.840 --> 11:12.840
trying to get deeper.

11:12.840 --> 11:15.000
But basically how to monitor the progress

11:15.000 --> 11:17.360
is how to convey to random guess

11:17.360 --> 11:19.200
how much better you can do than the random guess,

11:19.200 --> 11:21.200
starting from four times random guess

11:21.200 --> 11:22.560
to 12 times random guess.

11:22.560 --> 11:25.880
So, okay, and can do better than that.

11:25.880 --> 11:27.360
All right, so we do classification.

11:27.360 --> 11:30.600
The machine can classify style at the level

11:30.600 --> 11:34.360
of maybe a first-year art history students.

11:34.360 --> 11:36.560
If you give it an artwork, it can tell you this is Cubism,

11:36.560 --> 11:39.400
this is Impressionism, this is Renaissance.

11:39.400 --> 11:41.440
Good, the machine can do that.

11:41.440 --> 11:43.800
So what, why that's even important?

11:43.800 --> 11:44.960
So when I talk to Arthur Historian

11:44.960 --> 11:46.520
about machine classifying style,

11:46.520 --> 11:49.640
he asked me, so what, why that's even important?

11:49.640 --> 11:53.040
And here's why I think it's important.

11:53.920 --> 11:55.320
Classifying style by the machine

11:55.320 --> 11:57.240
is not what Arthur Historian,

11:57.240 --> 11:59.680
but actually instead what the important is,

11:59.680 --> 12:02.960
what are that tell us about the characteristics of style

12:02.960 --> 12:05.200
and what drives style changes?

12:05.200 --> 12:07.880
And we know that if the machine can classify style successfully

12:07.880 --> 12:10.240
that implies that the machine has learned

12:10.240 --> 12:14.360
some internal representation that encodes some features,

12:14.360 --> 12:16.480
some discriminative features

12:16.480 --> 12:19.160
through its visual analysis of these art.

12:19.160 --> 12:24.080
However, we also know that the machine uses visual feature

12:24.080 --> 12:26.560
that's always very hard to interpret by humans.

12:26.560 --> 12:28.480
So especially if you're doing learning,

12:28.480 --> 12:31.720
so we have to interpret these visual features.

12:31.720 --> 12:33.160
So it's very hard to understand

12:33.160 --> 12:35.400
how the machine did the execution of style

12:35.400 --> 12:38.120
to start with to get something useful.

12:38.120 --> 12:40.600
So we went into studying basically

12:40.600 --> 12:42.240
how the machine identify style

12:42.240 --> 12:44.240
and if there are a relation between the way

12:45.560 --> 12:48.200
the machine internally represents style

12:48.200 --> 12:52.160
and the way Arthur Historian think about style.

12:52.160 --> 12:54.520
And for that is very important to look at

12:54.520 --> 12:57.400
what, how Arthur Historian look at style.

12:57.400 --> 12:59.240
Here, this is Henrich Wolblin,

12:59.240 --> 13:02.800
one of the founding father of art history, modern art history.

13:02.800 --> 13:05.960
And he basically have a theory about style.

13:05.960 --> 13:10.480
In particular, he looked at how style,

13:10.480 --> 13:14.280
how to separate the study of subject matter

13:14.280 --> 13:17.960
from the study of the visual form, which is style.

13:17.960 --> 13:20.640
And in his book, basically he really studied

13:20.640 --> 13:23.160
the difference between Renaissance and Baroque.

13:23.160 --> 13:25.240
So in the top here is Renaissance artwork

13:25.240 --> 13:27.120
and in the bottom is a Baroque artwork.

13:27.120 --> 13:29.640
And he suggested basically some visual schema

13:29.640 --> 13:31.000
that you can tell the difference

13:31.000 --> 13:33.440
between Renaissance art and Baroque art.

13:34.360 --> 13:39.360
Basically, he mentioned five bears of elements.

13:39.760 --> 13:41.960
For example, linear versus binterly.

13:41.960 --> 13:45.320
In Renaissance art, if you look at the contours,

13:45.320 --> 13:50.320
they are very sharp and while in Baroque,

13:50.800 --> 13:51.920
it's very fuzzy contours.

13:51.920 --> 13:54.320
That was it linear versus binterly.

13:54.320 --> 13:58.160
In Renaissance, if all the subjects are in one plane,

13:58.160 --> 14:02.360
while in Baroque, there are depth in the scene.

14:02.360 --> 14:04.680
So this is Blainer versus Recessional.

14:04.680 --> 14:09.680
In Renaissance, everything seemed to be within canvas

14:09.680 --> 14:13.800
while in Baroque, basically you see like a cropped image

14:13.800 --> 14:15.400
from a bigger scene.

14:15.400 --> 14:17.920
So this is called closed form versus open form.

14:19.040 --> 14:20.640
In Baroque, in Renaissance,

14:20.640 --> 14:23.000
basically every subject by himself or by herself.

14:23.000 --> 14:26.600
So this multiplicity versus in Baroque, this unity here,

14:26.600 --> 14:30.240
you can see the old subject are part of one unit.

14:31.240 --> 14:35.400
In Renaissance, everything has absolute clarity.

14:37.040 --> 14:39.840
All the scene, everything's in focus

14:39.840 --> 14:43.200
while in Baroque, artists start to have relative clarity.

14:43.200 --> 14:45.920
There are depth, there are things that are in focus,

14:45.920 --> 14:47.920
things that are out of focus,

14:47.920 --> 14:49.880
depending on what the artist is trying to do.

14:49.880 --> 14:51.640
So he suggested that these five bears

14:51.640 --> 14:54.520
is really what make the difference

14:54.520 --> 14:56.640
between Renaissance and Baroque.

14:56.640 --> 14:58.880
And he even went to say that basically these five bears

14:59.160 --> 15:04.160
are the kind of feature that can classify any style.

15:04.320 --> 15:08.600
So any style variation really goes along these elements.

15:08.600 --> 15:09.760
However, this is very interesting.

15:09.760 --> 15:13.080
However, this is a theory in art history,

15:13.080 --> 15:15.720
which is what we call in math or science,

15:15.720 --> 15:16.960
basically a congestion, not a theory,

15:16.960 --> 15:18.760
because there is no proof of that.

15:18.760 --> 15:22.160
How can we even prove these theories,

15:22.160 --> 15:25.520
especially if you want to generalize it to old styles?

15:26.520 --> 15:30.320
So what we did is really is we're trying to look

15:30.320 --> 15:32.440
at this internal representation of how the machine

15:32.440 --> 15:34.600
classifies style and draw the parallel

15:34.600 --> 15:38.080
to what Wolverine suggested.

15:38.080 --> 15:41.520
So what we did is basically we trained several models,

15:41.520 --> 15:44.560
several CNN models, and we keep doing that.

15:44.560 --> 15:47.520
So things like AlexNet, when they appeared,

15:47.520 --> 15:52.520
VGGNet, ResNet, every CNN model that comes around,

15:52.560 --> 15:54.280
we try that as well.

15:54.400 --> 15:56.240
And the goal is basically to train the machine

15:56.240 --> 15:59.040
to do a style classification in a supervised manner.

15:59.040 --> 16:01.400
But the goal is really is not classification,

16:01.400 --> 16:03.560
the goal is to look at what has been learned here.

16:03.560 --> 16:05.840
So analyze the internal representation

16:05.840 --> 16:07.880
and do some statistical analysis

16:07.880 --> 16:09.880
and some visualization on top of that.

16:09.880 --> 16:14.880
So after the machine learned style with acceptable accuracy,

16:14.960 --> 16:17.320
we kind of start adding layers in the middle here

16:17.320 --> 16:20.880
to increase the interpretability of the representation.

16:21.880 --> 16:25.160
Basically go down to as small as number

16:25.160 --> 16:28.000
of internal nodes as possible here

16:28.000 --> 16:31.200
to have more interpretable representation,

16:31.200 --> 16:35.720
doing things like principle component analysis

16:35.720 --> 16:40.720
on the activation, source separation, ICA,

16:41.480 --> 16:44.640
understand looking at the manifolds of activations,

16:44.640 --> 16:47.520
doing correlation with time, correlation with Wolverine,

16:47.520 --> 16:49.800
there's all these kinds of analysis we have done

16:49.880 --> 16:51.120
to understand the representation

16:51.120 --> 16:54.360
and basically some of the results that we found.

16:54.360 --> 16:57.680
So this is the first thing that's very interesting.

16:57.680 --> 17:00.760
We used either B-trained model on ImageNet

17:00.760 --> 17:04.480
that we fine-tuned on Art Collection,

17:04.480 --> 17:06.200
we use WikiArt Collection,

17:06.200 --> 17:09.120
about 70,000 images in our studies.

17:10.280 --> 17:13.400
And by doing that, we reach a accuracy of classification

17:13.400 --> 17:16.600
is about 60% more or less by all these networks.

17:16.600 --> 17:19.480
If you use a data from scratch,

17:19.480 --> 17:22.720
you can actually get 10% less, 50%,

17:22.720 --> 17:25.360
only in 77,000 images out,

17:25.360 --> 17:27.680
they need to be trained on a million ImageNet.

17:28.880 --> 17:31.120
All right, so that's interesting

17:31.120 --> 17:32.440
so we can get reasonable results

17:32.440 --> 17:34.320
even without any pre-training.

17:34.320 --> 17:36.200
But the interesting thing is this,

17:36.200 --> 17:39.800
looking at the filters that the machine learned

17:39.800 --> 17:42.040
if you trained from scratch on style,

17:42.040 --> 17:44.160
you look very different from the filter

17:44.160 --> 17:48.840
that you typically see in object recognition CNNs.

17:48.880 --> 17:50.240
You know in object recognition CNNs,

17:50.240 --> 17:51.800
you always get these Gabor filters

17:51.800 --> 17:56.800
and this edge-like, oriented edge-like filters.

17:57.400 --> 17:59.880
If you look at how the machine look at style only,

17:59.880 --> 18:02.480
look at style construction only, nothing like that.

18:02.480 --> 18:05.080
We don't see almost any edges,

18:05.080 --> 18:08.520
maybe only one filter looks like a horizontal horizon

18:08.520 --> 18:09.680
or something like that.

18:09.680 --> 18:10.960
But other than that,

18:10.960 --> 18:12.400
it's very hard to interpret these filters,

18:12.400 --> 18:14.640
but definitely they are not edge-like filters.

18:14.640 --> 18:16.920
We should tell you if you wanna classify style,

18:17.360 --> 18:22.360
there's nothing about object or composition that matters.

18:22.480 --> 18:24.120
There's something else, but what is it?

18:24.120 --> 18:25.680
We don't know.

18:25.680 --> 18:27.720
So this is one thing to keep in mind.

18:28.720 --> 18:31.240
The most important finding is that

18:31.240 --> 18:33.920
looking at activation of the internal layers,

18:33.920 --> 18:36.120
we find that a small number of factors

18:36.120 --> 18:38.560
can explain most of the variants

18:38.560 --> 18:40.400
in all art history that we studied.

18:40.400 --> 18:42.520
We look at many at Western art history

18:42.520 --> 18:44.760
or last 500 years, just to be clear.

18:44.760 --> 18:46.080
We didn't include any Asian art

18:46.080 --> 18:48.360
or African art or other cultures.

18:49.680 --> 18:51.080
So between six and 10 factors

18:51.080 --> 18:54.640
can explain 95% of the variants in the data.

18:54.640 --> 18:56.840
And actually the first two modes of variations

18:56.840 --> 18:59.640
explain about 75% of the variants,

18:59.640 --> 19:01.240
depending on the network.

19:01.240 --> 19:03.440
And this is common in all the networks we have tried,

19:03.440 --> 19:07.280
whether it's Alexnest or complex networks like Resnet.

19:07.280 --> 19:12.280
You can see that 75% of variants up to 75% of variants

19:13.240 --> 19:15.880
can only explain in the first two modes of variations.

19:17.080 --> 19:17.920
So what are these?

19:17.920 --> 19:21.120
So here, for example, we visualize a small set

19:21.120 --> 19:23.320
of maybe 1700 images.

19:24.520 --> 19:26.960
Every image is a dot in this graph

19:26.960 --> 19:30.240
and is the first two modes of variation

19:30.240 --> 19:34.040
of the activation of the layers before the final layer.

19:35.400 --> 19:37.360
And here we color code them

19:37.360 --> 19:39.240
based on the time of the artwork.

19:40.080 --> 19:43.240
And so what you see here is Renaissance art is here

19:43.240 --> 19:45.040
and then Baroque art comes here

19:45.040 --> 19:49.840
and then all the way 19th century

19:49.840 --> 19:52.480
and all the way till the impressionism here.

19:52.480 --> 19:55.040
And then you can see what's happening in 20th century

19:55.040 --> 19:57.800
coming here, pubism and abstraction

19:57.800 --> 19:59.640
and what art and things like that.

19:59.640 --> 20:00.600
That's amazing.

20:00.600 --> 20:01.920
Why that's amazing?

20:01.920 --> 20:05.480
Basically the machine put art in an arrangement

20:05.480 --> 20:07.920
in a chronological arrangement by itself.

20:07.920 --> 20:10.320
Although we never tell the machine anything about

20:10.320 --> 20:11.440
when the art was made.

20:11.440 --> 20:12.840
The only information the machine sees

20:12.840 --> 20:15.400
is the image and the style label.

20:15.400 --> 20:17.320
You don't tell the machine that Renaissance happened

20:17.320 --> 20:19.440
before Baroque or Baroque happened before impressionism

20:19.440 --> 20:20.880
or anything like that.

20:20.880 --> 20:24.760
But the machine to learn to classify style

20:24.760 --> 20:26.920
by itself has to make the arrangements

20:26.920 --> 20:29.760
that correct historical arrangement of artworks.

20:29.760 --> 20:34.760
So we find that basically there is 0.7 correlation

20:35.000 --> 20:40.000
coefficient with time if you go clockwise in this graph here.

20:43.040 --> 20:44.320
And each of these axes

20:44.320 --> 20:47.240
there is also a high correlation with time as well.

20:47.240 --> 20:48.080
So that's very interesting.

20:48.080 --> 20:51.160
So the machine basically, why that's important?

20:51.160 --> 20:56.160
Because that actually was one of Wolblin theories

20:57.000 --> 21:01.120
which he said basically that style change

21:01.160 --> 21:03.400
in a smooth way over time

21:03.400 --> 21:06.200
exactly like a rock rolling down a hill.

21:06.200 --> 21:07.720
That's basically his metaphor.

21:07.720 --> 21:10.960
And that's what we see here that the machine

21:10.960 --> 21:15.520
find out that in order to understand this concept of style

21:15.520 --> 21:19.640
it had to put the art in order historically

21:19.640 --> 21:21.920
although we didn't get any historical context

21:21.920 --> 21:24.200
but it really find that by itself.

21:24.200 --> 21:27.360
So that's really confirmed that styles are not just bends

21:27.360 --> 21:32.360
that are classification classes that are isolated.

21:33.160 --> 21:35.160
It's smooth transition between them

21:35.160 --> 21:38.120
is one of the very important things.

21:38.120 --> 21:40.000
And this common and old representation

21:40.000 --> 21:43.200
if you look at any of the network that we look at

21:43.200 --> 21:45.640
whether it's be trained or trained from scratch

21:45.640 --> 21:49.720
can find this high correlation with time in the representation.

21:50.960 --> 21:53.560
And as I mentioned basically this is a confirmed

21:53.560 --> 21:57.840
by Henry Wolblin congestion about that.

21:57.840 --> 22:00.840
So the question now is what are these two factors

22:00.840 --> 22:04.640
that explain 75% of what happened in art history?

22:06.440 --> 22:10.000
So if you look at this and try to interpret it

22:10.000 --> 22:12.000
it's very hard to really find one interpretation

22:12.000 --> 22:14.040
people can have different interpretations.

22:15.200 --> 22:18.200
But we look at basically how these axes

22:18.200 --> 22:21.320
correlate with the five pairs that I mentioned by Wolblin

22:21.320 --> 22:26.320
Binterley versus linear recession versus Blainer

22:29.960 --> 22:30.880
things like that.

22:30.880 --> 22:35.240
And we find that all the time the first mode of variation

22:35.240 --> 22:36.560
the most important mode of variation

22:36.560 --> 22:39.080
is being recessional versus Blainer.

22:39.080 --> 22:42.920
And the second all the time the second most important

22:42.920 --> 22:46.120
mode of variation is correlated the most ways

22:46.120 --> 22:48.040
linear versus Binterley.

22:48.040 --> 22:50.440
And then give us a very nice way to look at what happened

22:50.440 --> 22:52.640
in art history over the last 500 years.

22:52.640 --> 22:57.360
So basically what happened is here at Renaissance time

22:57.360 --> 23:01.880
art was totally Blainer and basically linear

23:01.880 --> 23:05.160
every all the contour was linear and sharp

23:05.160 --> 23:07.240
and came Renaissance came Baroque

23:07.240 --> 23:11.480
and things start to be recessional depth

23:11.480 --> 23:16.480
and art becomes Binterley and the contour become fuzzy.

23:17.480 --> 23:20.840
All the way till impressionism

23:20.840 --> 23:22.960
where that's the ultimate Binterley experience

23:22.960 --> 23:25.880
in impressionism all the strokes are just fuzzy

23:25.880 --> 23:28.080
and we don't see any contours.

23:28.080 --> 23:30.880
So this is the ultimate Binterley experience

23:30.880 --> 23:35.880
but you can see that you still have depth artists

23:38.880 --> 23:43.760
looking at scenes and things are still recessional.

23:43.760 --> 23:47.920
And then came Cezanne and came 20th century art

23:47.920 --> 23:50.480
where basically things become flat

23:50.480 --> 23:52.200
artists start flattening the canvas again

23:52.200 --> 23:55.480
and becoming to be Blainer again like Renaissance.

23:55.480 --> 23:59.080
And basically most of 20th century is in the Blainer side

23:59.080 --> 24:01.640
of things but coming to be linear again.

24:01.640 --> 24:06.640
So if you look at Bob art like Warhol or abstract art

24:07.000 --> 24:10.440
you can find that arts become linear again in the contours.

24:10.440 --> 24:15.160
So basically art history went into a full 360 degree cycle

24:15.160 --> 24:18.040
over the last 500 years in Western civilization

24:18.040 --> 24:20.680
which really captured by this one diagram

24:20.680 --> 24:22.400
that really came from the representation

24:22.400 --> 24:25.600
the machine learned from looking at art style.

24:28.320 --> 24:31.120
And again, some other interesting things

24:31.120 --> 24:32.760
that we found in this representation

24:32.760 --> 24:35.880
if you look at two of the modes of variation

24:35.880 --> 24:37.360
I think these are the fifth and sixth

24:37.360 --> 24:39.920
or maybe fourth and fifth modes of variation

24:39.920 --> 24:41.640
and he's the one that correlates more

24:41.640 --> 24:44.080
with the discrimination between Renaissance and Baroque.

24:44.080 --> 24:45.680
So you can see Baroque in the top here

24:45.680 --> 24:47.920
and Renaissance in the bottom here.

24:47.920 --> 24:52.920
And you can see that basically these two factors

24:54.480 --> 24:59.480
are created the most with the bears of Wolverine.

24:59.760 --> 25:02.880
So basically Wolverine was correct in suggesting

25:02.880 --> 25:06.000
that these bears are a good way

25:06.000 --> 25:08.240
to discriminate between Renaissance and Baroque.

25:08.240 --> 25:10.400
However, we also found that he's not correct

25:10.400 --> 25:13.360
when he said that this can tell the difference

25:13.360 --> 25:15.320
between all other styles.

25:15.320 --> 25:20.320
All other styles basically are spanned by these five factors

25:20.400 --> 25:22.360
because we find that we cannot tell the difference

25:22.360 --> 25:24.080
between the inversionism and most inversionism

25:24.080 --> 25:26.520
by looking at any of these factors.

25:26.520 --> 25:29.280
There is none of them correlate with this discrimination.

25:31.720 --> 25:34.440
Another very interesting thing that we find is

25:35.440 --> 25:40.440
when we look at the activation manifolds

25:41.240 --> 25:45.520
of these networks, in terms of representation

25:45.520 --> 25:47.640
of these networks, we look at the activation manifolds.

25:47.640 --> 25:50.200
And again here we're visualizing different artworks

25:50.200 --> 25:55.040
based on the time of creation from 1400 to 2000.

25:55.040 --> 25:57.320
You can see also the movement of art history

25:57.320 --> 25:59.760
and how things have changed

25:59.760 --> 26:01.320
and you can find interesting connections.

26:01.320 --> 26:04.280
So you can see basically Renaissance here

26:04.400 --> 26:06.160
moving into Baroque,

26:06.160 --> 26:10.320
moving into a new classicism in 19th century,

26:10.320 --> 26:12.080
moving into realism,

26:12.080 --> 26:14.240
and then moving into inversionism here.

26:14.240 --> 26:15.560
And from inversionism basically,

26:15.560 --> 26:17.080
both the inversionism went in two direction,

26:17.080 --> 26:19.760
one direction that go to exhibitionism

26:19.760 --> 26:22.160
and one direction went to abstraction.

26:22.160 --> 26:24.920
So you can see Cubism and abstraction here.

26:24.920 --> 26:27.840
So that really tell us much about what happened in art history

26:27.840 --> 26:31.480
and we find very interesting things when we look at this.

26:31.480 --> 26:33.560
For example, if you look at this figure here,

26:33.640 --> 26:35.280
look at this connection between inversionism

26:35.280 --> 26:36.600
and what happened after.

26:36.600 --> 26:37.520
And if you look carefully here,

26:37.520 --> 26:42.120
we find that this connection is mainly Cézanne's work.

26:42.120 --> 26:45.400
So all the circled artwork here are work by Cézanne.

26:45.400 --> 26:47.800
So at the bottom here you can find the inversionism

26:47.800 --> 26:50.640
and that's Cézanne and that connect to abstraction

26:50.640 --> 26:52.080
and Cubism.

26:52.080 --> 26:53.640
So that's interesting.

26:53.640 --> 26:55.680
So you can see here Cubism and abstraction

26:55.680 --> 26:59.360
in the early 20th century happening after Cézanne.

26:59.360 --> 27:02.520
Here's another representation where really here are,

27:02.680 --> 27:05.960
here is Cézanne work and this is inversionism

27:05.960 --> 27:10.160
and basically this is Cubism, Picasso and Grace

27:10.160 --> 27:11.640
and other Cubists.

27:11.640 --> 27:14.120
And you can see how Cézanne's connection here,

27:14.120 --> 27:16.200
by making the connection between inversionism

27:16.200 --> 27:19.880
moving into 20th century and how special his artwork.

27:19.880 --> 27:22.760
And you can see that in the data, you can even touch it.

27:23.960 --> 27:25.880
You can see how Cézanne is a bridge here.

27:25.880 --> 27:28.880
And the interesting thing is that obviously being

27:28.880 --> 27:32.800
a naive person when it comes to art history,

27:32.800 --> 27:36.280
I always go to Wikipedia when I learned about something.

27:36.280 --> 27:38.800
When I go to Wikipedia, I'm learning more about Cézanne.

27:38.800 --> 27:39.840
I found this in this encode.

27:39.840 --> 27:41.960
Cézanne is said to have formed the bridge

27:41.960 --> 27:43.440
between 19th century inversionism

27:43.440 --> 27:48.440
and 20th century's artistic inquiries in Cubism

27:48.520 --> 27:53.520
and both Matisse and Picasso are said to have remarked Cézanne

27:53.760 --> 27:55.320
as their father, basically.

27:56.440 --> 27:57.560
And that's very interesting

27:57.560 --> 27:59.440
because this is not only a metaphor,

27:59.440 --> 28:02.800
like a bridge here is not a metaphor like in art history,

28:02.800 --> 28:05.240
but actually it's something that you can almost touch

28:05.240 --> 28:07.040
in the data, in the visualization.

28:07.040 --> 28:10.320
You can see how Cézanne is really connecting this.

28:11.480 --> 28:13.760
Not only that, but I mean, another interesting thing here,

28:13.760 --> 28:17.080
if you look at this manifold representation,

28:17.080 --> 28:19.960
you can see many artworks here are renaissance artworks

28:19.960 --> 28:22.920
that are built away from the Renaissance crowd

28:22.920 --> 28:25.120
because the way manifold learning work,

28:25.120 --> 28:26.800
manifold learning, you're building a graph,

28:26.840 --> 28:31.120
connecting all nodes and you do embedding of that graph.

28:31.120 --> 28:33.760
So you see here that these renaissance paintings

28:33.760 --> 28:36.200
are embedded away from Renaissance.

28:36.200 --> 28:37.480
When you look carefully about this,

28:37.480 --> 28:41.400
you find that basically these are particular artists

28:41.400 --> 28:43.880
that keep appearing again and again here.

28:43.880 --> 28:48.880
In particular, we find El Greco and Durer,

28:50.440 --> 28:51.640
the German artist.

28:52.640 --> 28:55.760
So it's clearly that El Greco and Durer

28:55.760 --> 28:58.160
has influenced modern art

28:58.160 --> 29:01.160
and many modern artists have really influenced by them.

29:01.160 --> 29:02.920
And that's very clear in the case of El Greco

29:02.920 --> 29:06.440
because of the way he draw in a very deformed way,

29:06.440 --> 29:10.280
which really affected exhibitionism and even cubism.

29:10.280 --> 29:11.440
And that's very clear here,

29:11.440 --> 29:14.520
why I see El Greco work built away from Renaissance

29:14.520 --> 29:16.720
close to modernity, modern art.

29:17.560 --> 29:21.320
In Durer, it's very hard to understand really

29:21.560 --> 29:23.680
how Durer influenced modern art history,

29:23.680 --> 29:27.720
but also Durer is very well known

29:27.720 --> 29:31.800
that he's influenced art history in the 20th century,

29:31.800 --> 29:33.880
but not clearly exactly how.

29:35.280 --> 29:37.320
So that's very interesting.

29:37.320 --> 29:42.320
All these tell us about how to characterize style changes,

29:42.440 --> 29:44.920
but let's dig deeper into that.

29:44.920 --> 29:48.040
And our work that I'm gonna talk about now,

29:48.040 --> 29:51.080
back from 2014, six years ago,

29:51.080 --> 29:53.800
was about confine creativity in art networks.

29:53.800 --> 29:56.760
How can we quantify creativity in art?

29:57.840 --> 29:59.640
And you will understand a little bit

29:59.640 --> 30:02.800
how that relates to style changes,

30:02.800 --> 30:05.200
how that characterize style changes as well.

30:05.200 --> 30:10.000
So basically you wanted to develop algorithm

30:10.000 --> 30:13.160
that assess creativity of a painting

30:13.160 --> 30:16.200
given its context and art history.

30:16.320 --> 30:18.960
That might seem to be silly question for some people,

30:20.160 --> 30:21.640
but I think it's very important

30:22.680 --> 30:25.040
because if you wanna build creative agents,

30:25.040 --> 30:27.280
that's able, it has to have its ability

30:27.280 --> 30:29.800
to assess creativity by itself.

30:29.800 --> 30:31.280
Because at this point, at this point,

30:31.280 --> 30:34.600
when a machine create art or music,

30:34.600 --> 30:37.560
it's always the human that assess creativity of this machine.

30:37.560 --> 30:39.160
You do human subject studies,

30:39.160 --> 30:41.280
we give it to judges, things like that.

30:41.280 --> 30:43.040
But can the machine on one day

30:43.040 --> 30:45.640
be able to assess its own creativity?

30:45.640 --> 30:47.480
And for that, we need to develop this algorithm

30:47.480 --> 30:48.720
to quantify creativity.

30:50.160 --> 30:51.240
But that did us the question,

30:51.240 --> 30:52.600
what's creativity to start with?

30:52.600 --> 30:53.760
How can we define creativity

30:53.760 --> 30:56.880
in a way that's this quantifiable?

30:56.880 --> 31:00.640
So there is a historically long and ongoing debate

31:00.640 --> 31:03.400
on how to define creativity.

31:03.400 --> 31:05.920
We can describe a person to be creative,

31:05.920 --> 31:10.120
like Mozart is creative or Warhol is creative.

31:10.120 --> 31:12.720
Or we can describe a product to be creative.

31:12.720 --> 31:14.160
So we can say, for example,

31:15.160 --> 31:18.240
the Mona Lisa was a creative artwork.

31:18.240 --> 31:20.160
Or some people refer to characterize

31:20.160 --> 31:24.280
the mental process to be creative.

31:24.280 --> 31:27.080
So there are different ways to describe creativity.

31:27.960 --> 31:30.760
We focus on novelty of a product in particular,

31:30.760 --> 31:32.680
whether something is creative or not.

31:33.800 --> 31:37.240
So how can we do that in an objective way?

31:37.240 --> 31:42.240
So it seems to be the two main condition

31:42.440 --> 31:45.480
for some product to be called creative.

31:46.480 --> 31:50.200
This product has to be novel compared to prior work,

31:50.200 --> 31:53.320
but also has to be of some value.

31:53.320 --> 31:56.080
So we will take note of it and become influential.

31:56.080 --> 31:58.880
Which exactly what happens in scientific community

31:58.880 --> 31:59.800
when you write a paper, right?

31:59.800 --> 32:00.760
I mean, you have to be novel

32:00.760 --> 32:03.240
compared to prior research.

32:03.240 --> 32:04.760
And it doesn't make a difference

32:04.760 --> 32:06.200
if nobody cites your work.

32:06.200 --> 32:08.960
So basically that tells us it's not influential

32:08.960 --> 32:10.000
and not that creative.

32:11.000 --> 32:13.520
This is a quote from a very good book,

32:13.520 --> 32:16.040
which is a collection of essays about creativity,

32:18.120 --> 32:20.080
which basically concluded that

32:20.080 --> 32:22.840
although there are different ways to define creativity,

32:22.840 --> 32:26.520
these are the most common essence of what creativity is.

32:27.760 --> 32:30.440
And that actually relates back to Kant philosophy.

32:30.440 --> 32:31.880
If you go to Kant philosophy,

32:31.880 --> 32:35.280
he defined five elements of what he called artistic genius.

32:35.280 --> 32:38.920
And the very first two of them is originality.

32:38.960 --> 32:42.280
The originality must be its primary characteristic

32:42.280 --> 32:43.960
and influence.

32:43.960 --> 32:48.960
Its product must at the same time be modeled or exemplary.

32:49.200 --> 32:54.200
So other artists would start to get influenced by that.

32:55.640 --> 32:57.720
So these are the two fundamental reasons

32:57.720 --> 33:01.280
behind what he called artistic genius or creativity.

33:02.480 --> 33:04.560
Let's move forward to the 20th century.

33:05.480 --> 33:09.360
One person in the audience asked a question

33:09.360 --> 33:11.080
referring to Margaret Bowden.

33:11.080 --> 33:13.680
So Margaret Bowden suggested basically

33:13.680 --> 33:16.360
two distinct notion of creativity,

33:16.360 --> 33:20.000
the psychological creativity or be creativity,

33:20.000 --> 33:22.080
which assists the novelty of idea

33:22.080 --> 33:23.240
with respect to its creator.

33:24.360 --> 33:26.200
Versus historical creativity,

33:26.200 --> 33:28.760
which is assessing the novelty

33:28.760 --> 33:31.280
with respect to the whole human history

33:31.280 --> 33:34.320
is what I'm creating valuable and novel

33:34.320 --> 33:36.520
compared to all what happened in history.

33:37.800 --> 33:39.920
So this is the objective measure.

33:39.920 --> 33:43.640
The psychological creativity is more of a subjective measure.

33:43.640 --> 33:47.120
But historical creativity is a objective measure.

33:47.120 --> 33:48.880
So basically that's what we're trying to do.

33:48.880 --> 33:50.760
We're trying to align ourselves

33:50.760 --> 33:53.000
with historical creativity of product

33:53.000 --> 33:55.120
and try to define an algorithm to do that.

33:57.400 --> 34:00.680
So we propose an algorithm to assess creativity

34:00.680 --> 34:02.040
that's basically unsupervised,

34:02.040 --> 34:05.440
meaning that we don't have any creativity labels.

34:05.440 --> 34:07.880
We just have a bunch of artworks.

34:07.880 --> 34:09.240
And the only information we're gonna have

34:09.240 --> 34:12.160
is the date that artwork was done.

34:12.160 --> 34:13.200
So these are two information,

34:13.200 --> 34:15.720
the image and the date, nothing else.

34:15.720 --> 34:17.680
And we're trying to infer from that

34:17.680 --> 34:19.040
something about creativity.

34:20.480 --> 34:22.280
Some fundamental issues we have to think about

34:22.280 --> 34:26.080
before even we start deriving any algorithm about creativity

34:26.080 --> 34:27.880
because these are common problems.

34:29.480 --> 34:31.320
These are common problems that will face

34:31.320 --> 34:35.000
any algorithm that will look at creativity.

34:35.000 --> 34:37.640
So we have an algorithm that assess creativity.

34:37.640 --> 34:39.480
That algorithm looking at an artwork

34:39.480 --> 34:42.760
and try to judge whether it's creative or not.

34:42.760 --> 34:45.120
Obviously that cannot be done in a vacuum.

34:45.120 --> 34:49.400
The algorithm has to look at the context

34:49.400 --> 34:53.800
of that art history to judge, right?

34:53.800 --> 34:55.680
So this one limitation that the algorithm

34:55.680 --> 34:58.240
only see a part of art history,

34:58.240 --> 35:00.280
that whatever digitized, whatever reached us

35:00.280 --> 35:02.880
and digitized and available as a dataset, right?

35:02.880 --> 35:04.960
So that's one problem.

35:04.960 --> 35:06.440
So these are closed,

35:06.440 --> 35:09.280
what I call the closed world limitation.

35:09.280 --> 35:11.240
And then the algorithm look at the art

35:11.240 --> 35:14.000
through some visual encoding, which also add limitation.

35:14.000 --> 35:16.440
So there are some concepts and elements

35:16.440 --> 35:21.440
that are being quantified here through these visual features.

35:21.880 --> 35:24.080
And there are others that might not.

35:24.080 --> 35:26.280
So that's basically another limitation,

35:26.280 --> 35:30.000
which I call the artistic concept quantification limitation.

35:30.720 --> 35:32.320
And then any algorithm has parameters

35:32.320 --> 35:33.880
and this parameter will influence the output.

35:33.880 --> 35:36.480
So we can get different results

35:36.480 --> 35:37.440
by changing the parameters.

35:37.440 --> 35:40.200
So how can we make use of that?

35:42.080 --> 35:46.840
So, however, these are all limitation should not stop us

35:46.840 --> 35:50.000
because first the closed world limitation

35:50.000 --> 35:51.800
will always go away.

35:51.800 --> 35:53.520
We have more and more art being digitized

35:53.520 --> 35:56.200
and more data we can get.

35:56.200 --> 35:59.120
So this will go away.

35:59.120 --> 36:02.160
We have advances every day in visual encoding

36:02.160 --> 36:06.800
and become less blind and have better encoding.

36:06.800 --> 36:08.760
And the parameters actually are not a limitation

36:08.760 --> 36:10.400
because the parameter actually,

36:10.400 --> 36:13.320
we can really give creativity scores

36:13.320 --> 36:17.400
and understand exactly how the parameters affect the scores

36:17.400 --> 36:20.720
in a way to understand what we are measuring.

36:20.720 --> 36:23.680
Are we measuring creativity based on certain settings

36:23.680 --> 36:26.280
related to composition or are you measuring

36:26.600 --> 36:30.320
visibility to brush stroke work or color?

36:30.320 --> 36:35.320
So all that allow us to reach way to understand K-division.

36:36.440 --> 36:39.480
So the bottom line is we wanna derive an algorithm

36:39.480 --> 36:44.480
that look at art pieces, images and their timestamp

36:44.800 --> 36:46.280
and give us a score.

36:47.320 --> 36:49.840
So that's basically the input and output.

36:49.840 --> 36:53.560
And what we do is that we start creating a directed graph

36:53.560 --> 36:55.800
between all paintings in our collection,

36:55.800 --> 36:59.440
where there is an edge between each two paintings

36:59.440 --> 37:01.800
with a weight reflecting the visual similarity

37:01.800 --> 37:03.600
according to the visual encoding that we are using,

37:03.600 --> 37:05.840
how similar these two paintings are.

37:05.840 --> 37:08.160
And it's directed based on the time basically

37:08.160 --> 37:12.480
if BI comes before BJ, so it's directed in that way.

37:12.480 --> 37:16.320
And now let's think about assemble inference we can do.

37:16.320 --> 37:17.840
Suppose you look at these two arts,

37:17.840 --> 37:22.120
Caravaggio from 1602 and a less known artist from 1800,

37:22.120 --> 37:24.160
almost 200 years later.

37:24.200 --> 37:26.160
If you look at these two artworks side by side,

37:26.160 --> 37:28.480
you can realize basically that this second artwork

37:28.480 --> 37:30.800
is very close to that in terms of body bowls,

37:30.800 --> 37:33.320
in terms of light, in terms of composition,

37:33.320 --> 37:36.000
subject matter, everything's basically, right?

37:36.000 --> 37:39.400
So it's clear that that work is a derivative of Caravaggio.

37:39.400 --> 37:42.800
So in one sense that artwork is not as novel

37:42.800 --> 37:44.600
compared to Caravaggio.

37:44.600 --> 37:48.840
And in another sense, Caravaggio has an influence

37:48.840 --> 37:51.160
in that way to that artist.

37:52.120 --> 37:56.000
So high similarity between two artworks in the network

37:56.000 --> 38:00.360
imply that creativity of the earlier work has to go up

38:00.360 --> 38:04.480
and creativity of the later artwork has to go down.

38:04.480 --> 38:05.880
These go down because it's derivative

38:05.880 --> 38:08.400
and these go up because it's influential,

38:08.400 --> 38:10.760
at least on these two bears.

38:10.760 --> 38:12.640
Compared to another case like that,

38:12.640 --> 38:15.600
these are precisely from 1883

38:15.600 --> 38:20.600
and this Picasso from maybe 20 years later from 1907,

38:20.880 --> 38:22.160
they are very different,

38:22.160 --> 38:24.280
had nothing to do with each other,

38:24.280 --> 38:26.520
different ways of using color, composition,

38:28.240 --> 38:29.200
totally different, right?

38:29.200 --> 38:30.680
So very little similarity between them,

38:30.680 --> 38:32.960
of course, depending on the future you are looking for,

38:32.960 --> 38:35.480
but still very low similarity.

38:35.480 --> 38:39.080
And that imply that Cicely was not influential

38:39.080 --> 38:41.080
on Picasso, at least in a direct way.

38:41.080 --> 38:44.320
And Picasso was basically novel in making that art

38:44.320 --> 38:45.520
compared to this work.

38:45.520 --> 38:49.520
So that low similarity implies lower creativity

38:49.520 --> 38:51.120
for that artwork by Cicely

38:51.120 --> 38:54.120
and higher creativity for that work by Picasso.

38:54.120 --> 38:57.600
So if you take these two elements of influence

38:57.600 --> 39:01.800
and start building a formulation for creativity,

39:01.800 --> 39:04.440
what you can do, we can write down a formulation like that,

39:04.440 --> 39:07.040
where the creativity of any node can be described

39:07.040 --> 39:10.720
as the creativity of all nodes connected to it.

39:10.720 --> 39:14.480
In this formula here, alpha is a factor

39:14.480 --> 39:16.480
that indicate the probability that the similarity

39:16.480 --> 39:18.720
between painting can be just a coincidence.

39:20.360 --> 39:23.640
And the way to interpret this formula is like that.

39:24.680 --> 39:28.040
Any node in the graph collect influence

39:28.040 --> 39:29.960
from all its outgoing connection

39:31.120 --> 39:32.920
in this submission here.

39:32.920 --> 39:34.800
And for any node in the graph,

39:34.800 --> 39:38.560
it distributes its creativity tokens

39:38.560 --> 39:40.880
among all incoming connections.

39:40.880 --> 39:44.240
So you reach this formula that you can write

39:44.280 --> 39:47.640
where this formula actually, if you look at it,

39:47.640 --> 39:49.680
it's basically an instance

39:49.680 --> 39:51.840
of what's called network centrality problems.

39:52.760 --> 39:55.440
So you can see how many other algorithms

39:55.440 --> 39:56.640
are special cases for this,

39:56.640 --> 39:58.160
or at least a special case for others.

39:58.160 --> 39:59.680
So you can think of this as a random work

39:59.680 --> 40:00.840
in a Markov chain.

40:00.840 --> 40:04.160
If you set alpha to be one, this term will vanish

40:04.160 --> 40:05.800
and you have this term only,

40:05.800 --> 40:09.000
which is called basically eigenvector centrality.

40:09.760 --> 40:12.680
You can think of it as a weighted variant

40:12.680 --> 40:14.480
of Hubel centrality.

40:14.480 --> 40:17.000
If you're familiar with this body of work,

40:17.000 --> 40:18.920
basically network centrality.

40:18.920 --> 40:21.040
But basically, network centrality is very fundamental

40:21.040 --> 40:23.160
in studying social networks in the days,

40:23.160 --> 40:25.800
in studying pandemics, propagation, things like that.

40:25.800 --> 40:28.240
Even in the Bej rank algorithm,

40:28.240 --> 40:32.600
by Google is basically a network centrality problem.

40:32.600 --> 40:34.360
And you can think of this formulation

40:34.360 --> 40:38.480
as basically inverted weighted variants of Bej rank.

40:40.000 --> 40:44.160
So we can even extend this in a way

40:44.160 --> 40:48.240
to separate originality from influence.

40:48.240 --> 40:50.360
So we can see that basically originality

40:50.360 --> 40:52.800
can be controlled by another parameter,

40:52.800 --> 40:53.960
is we can measure originality

40:53.960 --> 40:56.600
or can measure influence in particular.

40:56.600 --> 40:59.760
So the question is, how can you even evaluate that?

40:59.760 --> 41:02.120
If everything is so unsupervised here,

41:02.120 --> 41:04.640
you don't have any creativity labels,

41:04.640 --> 41:06.280
you can show results to 10 art history

41:06.280 --> 41:08.080
and everybody will have different opinions.

41:08.080 --> 41:12.360
So how can we even evaluate this algorithm?

41:12.360 --> 41:15.760
So we worked on different datasets,

41:15.760 --> 41:16.640
the wiki art datasets

41:16.640 --> 41:19.640
and something called archive datasets much older.

41:20.800 --> 41:24.520
And at that time, we did this work on 7.14.

41:24.520 --> 41:28.640
And at that time, this is the art in the vision

41:28.640 --> 41:31.720
was mainly things like jest and bag of words

41:31.720 --> 41:32.560
and things like that.

41:32.560 --> 41:33.400
And that was really excellent

41:33.400 --> 41:35.520
because we really wanted to use features

41:35.520 --> 41:37.360
that are not trained on art at all.

41:37.360 --> 41:39.800
So these are of the shelf features.

41:39.800 --> 41:41.240
Class me, it was a feature

41:41.240 --> 41:46.240
that basically encode object representation in images.

41:46.520 --> 41:50.840
So it's a very good way to encode subject matter

41:50.840 --> 41:54.840
in particular, just come from MIT,

41:54.840 --> 41:56.160
basically comes from MIT,

41:56.160 --> 41:59.720
which encode texture and other things

41:59.720 --> 42:02.200
to object and scene classification.

42:02.200 --> 42:05.920
So we thought that these two features are very useful.

42:05.920 --> 42:06.960
They are not trained on art,

42:06.960 --> 42:08.160
they are generic,

42:08.160 --> 42:10.840
the capture things that we can relate to in art

42:10.840 --> 42:15.840
with a subject matter or brushstrokes or scene composition.

42:16.800 --> 42:17.800
So let's use them

42:17.800 --> 42:20.840
and try to make sense of those based on that.

42:20.840 --> 42:24.480
So here's one chart that show basically time

42:24.480 --> 42:28.520
of x axis from 1400 till 2000.

42:28.520 --> 42:32.720
And every artwork here is blotted with its creativity score.

42:32.720 --> 42:34.840
So the higher the score,

42:34.840 --> 42:37.880
the y axis is the creativity score.

42:39.160 --> 42:41.040
And you have to remember that the formulation

42:41.040 --> 42:41.960
is a zero one game,

42:41.960 --> 42:44.000
meaning that if some artwork,

42:44.000 --> 42:45.960
if you give it a set of artworks,

42:45.960 --> 42:47.840
the sum has to be a constant.

42:47.840 --> 42:50.680
So for some artwork to score high,

42:50.680 --> 42:52.840
another has to score low.

42:52.840 --> 42:54.960
Everything that we give to the algorithm

42:54.960 --> 42:56.680
are master pieces of artwork anyway.

42:56.680 --> 42:59.560
So nothing here is really scrambled

42:59.560 --> 43:01.480
by somebody in the street.

43:01.480 --> 43:04.880
All these are master pieces.

43:04.880 --> 43:07.000
But the way to look and interpret this,

43:07.000 --> 43:09.880
we essentially are using in particular class me

43:09.880 --> 43:14.400
and just we are really trying to look at creativity

43:14.400 --> 43:15.640
with this subject matter,

43:15.640 --> 43:18.360
how creative were artists in depicting

43:18.360 --> 43:20.680
the subject matter over time.

43:22.560 --> 43:24.240
So we can see, for example,

43:24.240 --> 43:26.160
what scores low in 19th centuries

43:26.160 --> 43:30.120
is art by the amazing artist,

43:30.120 --> 43:31.560
Prince of Hungary.

43:32.640 --> 43:34.360
Why this score low?

43:34.360 --> 43:36.440
Because basically according to subject matter,

43:36.440 --> 43:38.920
there's nothing really innovative

43:38.920 --> 43:42.480
about having a portrait of a woman in 19th century

43:42.480 --> 43:44.640
because this has been done a lot in Renaissance

43:44.640 --> 43:45.480
and broke all the time.

43:45.480 --> 43:47.800
So subject matter was not re novel.

43:47.800 --> 43:50.000
While in the same time what scored very high

43:50.000 --> 43:52.440
was things like a monk,

43:52.440 --> 43:54.320
the scream or money,

43:55.360 --> 43:58.240
haystack, very early version of that and others.

43:58.240 --> 44:03.240
So when we look carefully on the 100 years

44:04.080 --> 44:05.600
from 1850 to 1950,

44:05.600 --> 44:07.760
when we have a lot of data digitized

44:07.760 --> 44:09.480
and a lot of artwork,

44:09.480 --> 44:10.720
we can find that the machine makes sense

44:10.720 --> 44:13.240
a lot about what happened in art history in that time.

44:13.240 --> 44:15.560
So you can see the machine identifying things like

44:15.560 --> 44:17.720
mink, the scream, giving very high score,

44:18.920 --> 44:20.160
climp booster,

44:22.960 --> 44:25.840
things like cubism and things like that.

44:25.840 --> 44:29.920
So that makes sense.

44:29.920 --> 44:32.160
I hear deeper into that.

44:32.160 --> 44:35.040
If you look at the first 10 years of 20th century,

44:35.960 --> 44:37.920
the first 10 years of 20th century,

44:37.920 --> 44:40.560
the highest scoring artwork, for example,

44:40.560 --> 44:42.960
is Picasso, Ladies of Abinon.

44:44.080 --> 44:46.520
I didn't know much about that artwork other than I like it,

44:46.520 --> 44:49.200
but I didn't know much about its history at the time.

44:50.640 --> 44:52.160
But when I look at its history,

44:52.160 --> 44:53.880
I find that art history now agrees

44:53.880 --> 44:57.160
that basically artwork was the beginning of cubism.

44:57.160 --> 44:59.440
Very early, even before cubism become a thing.

44:59.440 --> 45:01.080
And what you see in this graph here,

45:01.080 --> 45:03.240
the machine give this a very high score

45:03.240 --> 45:08.240
and what's stopping that in 1912 is actually cubism itself.

45:08.440 --> 45:10.920
So these are artworks when basically

45:10.920 --> 45:14.560
in the very early cubism exhibitions

45:14.560 --> 45:19.560
by Picasso and Brock.

45:19.840 --> 45:21.840
And you can see here that before that,

45:21.840 --> 45:23.440
that was the high scoring one.

45:23.440 --> 45:25.040
And this is stopping that.

45:25.040 --> 45:28.840
What's stopping that even more in 1915,

45:28.840 --> 45:30.800
artwork by Malevich,

45:30.800 --> 45:33.640
what's called supremist art movement,

45:33.640 --> 45:36.640
which is totally abstraction in 1915.

45:36.640 --> 45:39.040
That's stopping even cubism.

45:39.040 --> 45:40.920
Okay, anyway, all that's nice,

45:40.920 --> 45:45.920
but how can we even say that it works or not?

45:46.640 --> 45:48.160
It's all in total evidence, right?

45:48.160 --> 45:51.840
I mean, here is what's something very interesting.

45:51.840 --> 45:53.320
What was that artwork

45:53.320 --> 45:55.840
that giving very high score in that short here?

45:55.840 --> 45:59.080
And when you look at curfew at that artwork in particular,

45:59.080 --> 46:01.480
you find it's an artwork by Mondrian

46:02.440 --> 46:06.680
that was dated in our dataset to be in 1910.

46:06.680 --> 46:08.760
And that was very interesting.

46:08.760 --> 46:10.560
Obviously, when you find something that you have to look at

46:10.560 --> 46:14.040
and see why this is scoring very high.

46:14.040 --> 46:15.680
And I find something very interesting

46:15.680 --> 46:18.560
that basically Mondrian didn't bend this in 1910.

46:18.800 --> 46:22.400
Mondrian bent this in 1932, I guess, I don't remember.

46:22.400 --> 46:26.040
So that was a mistake in the dataset.

46:26.040 --> 46:27.840
So the dataset itself has something wrong

46:27.840 --> 46:30.840
that would say basically Mondrian went into that in 1910.

46:30.840 --> 46:34.120
And if Mondrian would have painted that in 1910,

46:34.120 --> 46:35.800
that would have been even before cubism,

46:35.800 --> 46:36.640
before abstraction

46:36.640 --> 46:40.360
and would have been the most creative artist in his time.

46:40.360 --> 46:42.160
But obviously that's not.

46:42.160 --> 46:45.680
But that mistake actually give us a very interesting idea

46:45.680 --> 46:48.520
about how to even evaluate this.

46:48.560 --> 46:50.480
So there are many results here, I'm gonna skip that.

46:50.480 --> 46:55.480
And the way we evaluate this is what's called art time machine.

46:58.680 --> 47:02.400
So the idea is this very, very simple idea

47:02.400 --> 47:06.200
that come from this mistaken, the dating of that artwork.

47:06.200 --> 47:09.400
So what happened if you take an artwork from Barak

47:09.400 --> 47:13.000
or Renaissance and move it forward in time

47:13.000 --> 47:15.240
and change its date to, let's say, 19th century

47:15.240 --> 47:17.280
or 20th century, what do you expect?

47:17.280 --> 47:21.560
Give the algorithm work that the creativity of score

47:21.560 --> 47:22.960
for that artwork has to go down

47:22.960 --> 47:24.800
because if you create an Renaissance artwork

47:24.800 --> 47:27.200
in 19th century, you are not creative.

47:27.200 --> 47:29.080
In the same time, you take an artwork from 19th century

47:29.080 --> 47:32.320
or 20th century and move it back to 1400 or 1500,

47:33.360 --> 47:37.520
you expect its creative score to be going very up

47:37.520 --> 47:39.160
because it would have been very different

47:39.160 --> 47:40.720
from what happened in the time

47:40.720 --> 47:45.400
and very early influence to what happened much later.

47:45.400 --> 47:48.240
So we expect its creativity score to go up.

47:48.240 --> 47:49.160
And that's what we did.

47:49.160 --> 47:51.920
So what we did is basically many experiments

47:51.920 --> 47:56.240
where we take only 10 artworks, change their timestamp

47:56.240 --> 48:00.560
randomly, either moving them backward to 1600

48:00.560 --> 48:05.560
from modern schools or moving forward to 1900

48:05.840 --> 48:07.680
for Renaissance and Barak.

48:07.680 --> 48:09.600
Or basically as a baseline, just to move them

48:09.600 --> 48:13.400
around 1600 randomly.

48:13.400 --> 48:15.480
We basically find that that's interesting,

48:15.480 --> 48:19.840
but if you move forward, Renaissance and Barak artwork

48:19.840 --> 48:22.880
to 19th century, you can see consistent drop

48:22.880 --> 48:26.080
of creativity by eight to 10%.

48:26.080 --> 48:30.000
So it's consistent when we did these experiments.

48:31.040 --> 48:34.640
If you move modern artwork from 19th and 20th century

48:34.640 --> 48:39.240
back to 1600, you can see that the creativity score increase.

48:39.240 --> 48:42.200
However, with varying degrees depending on the art movement

48:42.200 --> 48:43.640
and that makes a lot of sense.

48:43.640 --> 48:46.000
For example, if you're looking at exhibitionism

48:46.000 --> 48:48.160
or cubism or post-embranches,

48:48.160 --> 48:50.400
we can find a huge increase in creativity

48:50.400 --> 48:55.080
if you move them back to 1600, compared to a new class system.

48:55.080 --> 48:57.080
A new class system basically is a reinvention

48:57.080 --> 49:00.360
of Renaissance in 19th century.

49:00.360 --> 49:03.480
So if you move it back to 1600, you have only a 5% increase

49:04.720 --> 49:08.240
compared to 16% increase for post-embranches.

49:08.240 --> 49:09.080
So that's right.

49:09.080 --> 49:10.080
How we tell us basically the algorithm

49:10.080 --> 49:11.800
is really doing something making sense

49:11.800 --> 49:14.520
in terms of quantifying creativity

49:14.520 --> 49:16.520
and giving us a score that really captured

49:16.520 --> 49:18.720
the novelty and influence that we're looking for.

49:20.040 --> 49:25.040
When I showed these results to my art historian collaborator,

49:25.760 --> 49:27.760
Maria Mazzoni at the College of Charleston,

49:27.760 --> 49:29.280
she was interested in the result

49:29.280 --> 49:30.560
and gave me this book, basically,

49:30.560 --> 49:32.760
Shev's Art History, which I quoted from in the beginning

49:32.760 --> 49:35.080
by George Kubler, who's an art historian.

49:35.080 --> 49:37.600
And in this book, basically, Kubler had a theory

49:37.600 --> 49:41.560
about how art history evolved.

49:41.560 --> 49:46.320
So basically saying that artists copy ideas

49:46.320 --> 49:47.680
from each other all the time.

49:47.680 --> 49:51.400
That's what happened all the time, within a style.

49:51.400 --> 49:53.320
Until, basically, some artists come

49:53.320 --> 49:58.320
and makes some artwork that is really different for some reason.

50:00.640 --> 50:04.720
And that's what he called primary objects,

50:04.720 --> 50:08.320
really give birth to a new style.

50:08.320 --> 50:10.480
And if other artists start to take a note of that

50:10.480 --> 50:14.880
and start replicating this new style,

50:14.880 --> 50:16.840
that becomes a new style.

50:16.840 --> 50:21.160
So, basically, he focused on this concept of prime objects,

50:21.160 --> 50:25.000
which are iconic artwork, and replica mass,

50:25.000 --> 50:30.000
as opposed to that really drive style moving forward,

50:31.680 --> 50:32.920
within a style.

50:32.920 --> 50:36.680
And I even find very interesting quotes in his book

50:36.680 --> 50:40.080
that say, basically, primary objects here.

50:40.080 --> 50:43.880
Prime objects resemble prime numbers of mathematics,

50:43.880 --> 50:46.320
because no conclusive rules is known

50:46.320 --> 50:49.600
to govern the appearance of either,

50:49.600 --> 50:52.240
although such a rule may be found.

50:53.280 --> 50:56.080
So, basically, this is a very amazing analogy.

50:56.080 --> 50:57.800
You make the analogy between these prime objects

50:57.800 --> 51:00.360
in art history and prime numbers.

51:00.360 --> 51:04.080
The prime numbers cannot be divided by a number before them,

51:04.080 --> 51:06.640
but they divide many numbers that comes after them.

51:07.640 --> 51:12.640
And that analogy really gives me thinking about

51:13.320 --> 51:16.880
the algorithm that describes the graph inference algorithm.

51:18.000 --> 51:20.080
If we can start with this graph,

51:20.080 --> 51:21.760
and the nodes are numbers,

51:21.760 --> 51:24.560
and the arrows are divisibility,

51:24.560 --> 51:27.520
the algorithm, basically, will give you a high score

51:27.520 --> 51:29.960
to prime numbers by definition.

51:29.960 --> 51:32.680
By construction, you find that that algorithm

51:32.680 --> 51:35.440
will give high score to prime numbers.

51:35.480 --> 51:38.080
So, really, he's very, very correct in this analogy

51:38.080 --> 51:41.760
that prime object is actually very similar

51:41.760 --> 51:42.840
to the concept of prime numbers.

51:42.840 --> 51:45.720
And what you're actually doing in this network

51:45.720 --> 51:47.400
by giving creative score,

51:47.400 --> 51:51.960
we are identifying what are the prime objects

51:51.960 --> 51:53.800
in art history, things like Montesquim,

51:53.800 --> 51:55.760
or Picasso, ladies have been on.

51:55.760 --> 51:59.400
So, when art historians tell us that this artwork is major,

51:59.400 --> 52:03.480
or basically the population think of Montesquim,

52:03.520 --> 52:08.520
or Monet, his tag as really a masterpiece,

52:08.720 --> 52:10.600
this is totally not subjective.

52:10.600 --> 52:14.280
There is some unconscious reasons for that.

52:14.280 --> 52:18.440
And this can be quantified by this kind of networks.

52:18.440 --> 52:21.520
And they are really a changing moment in history

52:21.520 --> 52:23.320
where something totally different happened

52:23.320 --> 52:26.200
and artists start taking notice.

52:27.160 --> 52:28.640
So, because of the time,

52:28.640 --> 52:32.800
I just wanna go very fast toward the next topic,

52:32.800 --> 52:34.760
which I'll try to finish in two minutes,

52:34.760 --> 52:37.840
which is basically how can we actually use AI

52:37.840 --> 52:38.840
to generate art?

52:39.760 --> 52:42.560
And if the machine generate images,

52:42.560 --> 52:44.880
would that be considered art or not?

52:45.960 --> 52:47.880
These are very big topic.

52:47.880 --> 52:50.440
And I know that other speakers in this series

52:50.440 --> 52:52.520
will talk about that in detail.

52:55.080 --> 52:56.480
Aaron is gonna be speaking,

52:56.480 --> 52:59.160
or maybe has been already in this series.

52:59.160 --> 53:03.320
But basically our work from three years ago,

53:03.320 --> 53:05.280
called Creative Adversarial Network,

53:05.280 --> 53:08.840
can, which basically we try to make a variant of GAN

53:08.840 --> 53:13.400
that was new at that time to really generate a novel art.

53:13.400 --> 53:17.120
We call it generating art by deviating from style known,

53:18.360 --> 53:21.360
by learning about style and being from style known.

53:21.360 --> 53:24.480
These are some of the art that this network is generating.

53:24.480 --> 53:27.000
So, basically wanna, here's the story.

53:27.000 --> 53:29.560
Obviously, the audience here know deep learning

53:29.560 --> 53:31.280
and know GANs and know how they work.

53:31.280 --> 53:33.680
I don't have to go through that.

53:33.680 --> 53:36.640
And for example, GANs have been very successful

53:36.640 --> 53:38.120
in generating these images of bedrooms

53:38.120 --> 53:42.960
and other assets, very interesting things like that.

53:44.360 --> 53:46.560
So, one question would be,

53:46.560 --> 53:48.840
what happened if you train GANs on art images?

53:48.840 --> 53:51.960
Suppose you give it art history images

53:51.960 --> 53:55.040
and you train GANs on that, would it generate art?

53:55.040 --> 54:00.040
And actually there was some trials in the early days of GANs

54:01.120 --> 54:04.000
where people trained it on board trays

54:04.000 --> 54:07.320
and still lifes and things like that.

54:09.760 --> 54:12.460
However, this fundamental problem,

54:13.360 --> 54:17.000
the generator in GAN is trained to generate samples

54:17.000 --> 54:18.640
that pulls the discriminator to believe

54:18.640 --> 54:22.720
they're coming from the same distribution as the inputs.

54:22.760 --> 54:24.640
So, that's basically,

54:24.640 --> 54:27.120
we can think about Chinese room problem here.

54:27.120 --> 54:32.120
Imagine the generator have access to actual images

54:32.400 --> 54:33.640
and can sheet.

54:33.640 --> 54:35.280
So, you can take actual images of art

54:35.280 --> 54:37.880
and just generate it right away

54:37.880 --> 54:39.320
and give it to the discriminator.

54:39.320 --> 54:41.160
So, actually, the discriminator this way

54:41.160 --> 54:42.360
can be pulled right away

54:42.360 --> 54:45.160
that thinking and generating these art works.

54:46.040 --> 54:49.880
However, this is basically the Chinese room problem.

54:49.880 --> 54:52.920
So, there is no motivation for the generator

54:52.920 --> 54:54.640
actually to generate anything that's creative.

54:54.640 --> 54:56.080
The generator is just trying to generate something

54:56.080 --> 54:57.680
from the same distribution.

54:57.680 --> 54:59.720
The only creativity it can do

54:59.720 --> 55:00.520
is just to generate something

55:00.520 --> 55:04.000
that was not generated before from the distribution.

55:04.000 --> 55:09.000
But it's basically, if you give it artworks of board trays,

55:10.920 --> 55:12.720
it will generate some different board tray,

55:12.720 --> 55:15.720
but still a board tray that's very similar to what it sees.

55:16.720 --> 55:20.840
There's no force, the bush, again, to be creative.

55:20.840 --> 55:22.000
How can you change that?

55:23.000 --> 55:24.120
There's some background here

55:24.120 --> 55:26.320
that I have to go very fast over

55:26.320 --> 55:31.080
from coming from the field of aesthetic evolution

55:31.080 --> 55:31.920
and psychology.

55:32.840 --> 55:35.480
Basically, these three in one slide

55:35.480 --> 55:40.480
say that artists keep making the same kind of art all the time.

55:43.000 --> 55:44.200
Like, if artists in Renaissance

55:44.200 --> 55:46.800
keep doing the same kind of Renaissance all the time,

55:46.800 --> 55:48.200
because of habituation,

55:48.200 --> 55:50.880
we get bored of that as the viewer get bored of that.

55:50.880 --> 55:52.800
And that become not exciting for the artist,

55:52.800 --> 55:53.800
not exciting for the critic,

55:53.800 --> 55:55.720
not exciting for the viewer anymore.

55:55.720 --> 55:58.000
So, artist has to innovate all the time

55:58.000 --> 56:01.080
to go to bush against habituation.

56:01.080 --> 56:03.280
However, if artists innovate too much,

56:03.280 --> 56:07.400
if artists imagine because I did that in Renaissance time,

56:07.400 --> 56:10.520
or even when he did that in 20th century,

56:10.520 --> 56:11.680
that's too shocking.

56:11.680 --> 56:13.680
That people will not like that.

56:13.680 --> 56:15.760
And people actually didn't like that.

56:15.760 --> 56:17.800
Most people till now didn't like that.

56:17.800 --> 56:19.960
Because basically according to what's called

56:19.960 --> 56:21.600
one curve in psychology,

56:22.480 --> 56:27.480
too much arousal relates to negative hedonics.

56:28.720 --> 56:31.880
Basically, people start to unlike what they see.

56:31.880 --> 56:35.400
So, in one sense, artists have to bush against habituation

56:35.400 --> 56:37.800
in what's called basically least efforts.

56:37.800 --> 56:41.120
So, artists really have to really bush the envelope

56:41.120 --> 56:43.480
with the least minimum amount

56:43.480 --> 56:44.480
to bush against habituation

56:44.480 --> 56:48.080
without falling into the negative part of that curve.

56:48.080 --> 56:50.120
So, that basically the concept that we're trying to bush,

56:50.120 --> 56:53.840
how can we bush the network to be innovative,

56:53.840 --> 56:56.280
but keep it within the distribution,

56:56.280 --> 56:58.480
bush the boundary basically.

56:58.480 --> 57:02.080
So, the way we did it is basically,

57:02.080 --> 57:05.320
in particular, we're trying to go out of style

57:05.320 --> 57:07.240
by appealing style ambiguity.

57:07.240 --> 57:10.120
So, the network here is again,

57:11.120 --> 57:15.840
we still have the real false, real fake loss,

57:15.840 --> 57:17.560
which is in that case, art or not art

57:17.560 --> 57:19.720
because you're training on art.

57:19.720 --> 57:22.560
Then the network has a style classification.

57:22.560 --> 57:24.560
The discriminator also learn about style

57:24.560 --> 57:26.360
and try to classify styles.

57:26.360 --> 57:28.040
We give it style labels.

57:28.040 --> 57:32.520
And we added style ambiguity loss,

57:32.520 --> 57:35.960
which basically mean that the discriminator

57:35.960 --> 57:39.680
trying to see if the art as a generator fits within styles

57:39.720 --> 57:42.960
or ambiguous in terms of satisfying style.

57:42.960 --> 57:46.240
And we're trying to basically maximize style ambiguity

57:46.240 --> 57:49.920
at the same time minimizing the typical loss

57:49.920 --> 57:54.920
in real fake formulation.

57:57.720 --> 58:00.040
So, basically, this is the loss

58:00.040 --> 58:01.720
and we have art or not art.

58:01.720 --> 58:03.760
We have style classification loss

58:03.760 --> 58:08.440
and we have this style ambiguity,

58:08.440 --> 58:09.520
which I think is very essential

58:09.520 --> 58:14.520
because this style ambiguity bushes against art, not art.

58:14.920 --> 58:17.280
Art, not art loss, typical gun loss,

58:17.280 --> 58:20.440
will try to boost things into the distribution.

58:20.440 --> 58:23.640
And style ambiguity will try to boost things

58:23.640 --> 58:24.480
away from distribution,

58:24.480 --> 58:27.800
but keeping that will put it back.

58:27.800 --> 58:31.080
So, the dilemma between this almost objective

58:31.080 --> 58:34.720
really boost the machine to try to explore the boundary.

58:34.720 --> 58:36.400
And that's why we started getting

58:36.400 --> 58:39.400
this very interesting artwork

58:39.400 --> 58:41.520
that have very nice composition.

58:41.520 --> 58:43.360
Here we train the machine on art history

58:43.360 --> 58:45.600
from the last 500 years of art history,

58:45.600 --> 58:49.640
all subject matter, all style, we didn't do any curation.

58:49.640 --> 58:51.720
The goal is if the machine see all that art,

58:51.720 --> 58:52.800
what will it generate?

58:52.800 --> 58:56.240
Will it generate similar artworks or something novel?

58:56.240 --> 58:57.080
And the interesting thing,

58:57.080 --> 58:58.520
most of the things I'm machine generate

58:58.520 --> 59:00.120
actually abstract artwork.

59:00.120 --> 59:01.680
It didn't give us much board trace

59:01.680 --> 59:04.400
or landscape mainly abstract.

59:04.400 --> 59:06.840
And that was very interesting question.

59:06.840 --> 59:11.840
If we remove the style ambiguity loss,

59:12.400 --> 59:14.360
these what kind of things you can get,

59:14.360 --> 59:18.240
which are basically things that looks like

59:18.240 --> 59:20.760
mainly repetition of art history.

59:20.760 --> 59:24.000
The machine here again is just basically trying to

59:24.000 --> 59:26.440
generate things that looks like the distribution.

59:26.440 --> 59:29.880
Adding style ambiguity to the different results.

59:29.880 --> 59:33.640
Trying to, you can see it keep the aesthetic,

59:33.640 --> 59:35.240
it learned the aesthetics trying to keep it to be

59:35.240 --> 59:37.160
in the distribution of what's appealing,

59:37.160 --> 59:39.120
but trying to come up with new compositions

59:39.120 --> 59:43.040
and new combination of colors, new interesting things.

59:43.040 --> 59:46.000
And we did a lot of experiments.

59:46.000 --> 59:48.520
There's much time to go over them in details,

59:48.520 --> 59:50.240
but here is the conclusion.

59:50.240 --> 59:52.640
When we show these two human subjects

59:52.640 --> 59:56.000
combined with artwork from Art Basel 2016,

59:56.000 --> 01:00:01.000
which is a flagship art fair in contemporary artists

01:00:01.080 --> 01:00:06.080
and also combined with another set of abstract exhibitions,

01:00:07.200 --> 01:00:09.600
famous artworks as a baseline.

01:00:09.600 --> 01:00:11.880
And to our surprise,

01:00:11.880 --> 01:00:15.680
basically human subject thought art done by Cannes,

01:00:15.680 --> 01:00:20.520
the machine basically has done by human 75% of the time

01:00:20.520 --> 01:00:24.000
compared to 85% of the time for the case of abstract.

01:00:24.000 --> 01:00:29.000
And only 48% of the time for art from the Art Basel.

01:00:31.840 --> 01:00:32.960
Collection.

01:00:32.960 --> 01:00:35.120
This doesn't take anything about creativity of the art.

01:00:35.120 --> 01:00:37.280
It's basically a touring test to tell whether a human

01:00:37.280 --> 01:00:42.120
can tell what art is made by a human or by a Gann.

01:00:42.120 --> 01:00:45.080
And at that time, basically most art that is done by Gann

01:00:45.080 --> 01:00:49.400
has this uncanny look that right away you can tell it's a Gann.

01:00:49.400 --> 01:00:50.600
It's the format for trace,

01:00:50.600 --> 01:00:53.040
the format so you can tell it's a machine,

01:00:53.040 --> 01:00:56.240
but for Cannes work, you cannot tell the difference.

01:00:56.240 --> 01:00:57.560
It's given these high scores.

01:00:57.560 --> 01:01:04.560
And moreover, they give it described by words like intentional,

01:01:04.560 --> 01:01:09.560
has a composition, rules, has communication inspirational.

01:01:10.200 --> 01:01:13.320
Give it high score in all these as with the same as art made

01:01:13.320 --> 01:01:14.160
by human.

01:01:15.000 --> 01:01:17.120
One last thing is why it works?

01:01:17.120 --> 01:01:18.640
Why style ambiguity work?

01:01:19.720 --> 01:01:22.400
And that connects to what I talked about earlier.

01:01:23.960 --> 01:01:25.080
It is not biased with the data,

01:01:25.240 --> 01:01:28.960
because maybe you have less abstract art work in your collection

01:01:28.960 --> 01:01:30.880
and that's why it's generating abstracts.

01:01:30.880 --> 01:01:34.840
And it is not because all the schools here

01:01:36.280 --> 01:01:39.360
we combine them into bins to make them uniform.

01:01:42.240 --> 01:01:44.880
So according to our laws, if these are the solution

01:01:44.880 --> 01:01:46.600
and these are the styles,

01:01:46.600 --> 01:01:50.080
those are a plenty of room in between to create something

01:01:50.080 --> 01:01:53.240
that belongs to art and doesn't belong to styles.

01:01:53.240 --> 01:01:55.160
The machine tried to find out these spaces.

01:01:55.160 --> 01:01:58.680
However, if you look at this figure from before,

01:01:58.680 --> 01:01:59.920
that's renaissance, Baroque,

01:01:59.920 --> 01:02:01.640
impressionism, realism and things like that.

01:02:01.640 --> 01:02:03.880
You can see that there's no relation art history.

01:02:03.880 --> 01:02:06.080
Everything has been moving smoothly.

01:02:06.080 --> 01:02:09.560
And if you want to move forward,

01:02:09.560 --> 01:02:11.160
obviously this two-dimension block here,

01:02:11.160 --> 01:02:12.920
but the space is much bigger.

01:02:12.920 --> 01:02:14.440
If we really move forward,

01:02:14.440 --> 01:02:17.040
you cannot really get something just between renaissance

01:02:17.040 --> 01:02:17.880
and Baroque.

01:02:17.880 --> 01:02:19.200
You have really a budget trajectory forward,

01:02:19.200 --> 01:02:22.480
not insert something in between.

01:02:22.480 --> 01:02:25.480
And that's exactly why it works.

01:02:25.480 --> 01:02:29.920
So, and that's why it tends to generate more abstract

01:02:29.920 --> 01:02:32.120
than more uncanny repetition of the best

01:02:32.120 --> 01:02:34.960
because it's figured out basically in the 19th century,

01:02:34.960 --> 01:02:36.160
things are moving in that direction

01:02:36.160 --> 01:02:39.920
and there are more space to make creating abstract art works

01:02:39.920 --> 01:02:42.360
and studio art works without having to go

01:02:42.360 --> 01:02:46.440
and creating board trays and battle field

01:02:46.440 --> 01:02:49.280
and landscapes that the students can tell right away.

01:02:49.280 --> 01:02:51.200
It's renaissance and Baroque.

01:02:51.200 --> 01:02:54.000
So that's at least my understanding of this board.

01:02:54.000 --> 01:02:55.680
Anyway, I'll have to stop here

01:02:55.680 --> 01:02:58.440
because I went over time and I'm very sorry about that.

01:02:58.440 --> 01:03:00.840
The conclusion is we just sketched the surface.

01:03:00.840 --> 01:03:03.400
These are not to be discovered in art history

01:03:03.400 --> 01:03:08.400
by looking at art at a macro level using the science and AI.

01:03:08.520 --> 01:03:11.120
And also they are to be discovered

01:03:11.120 --> 01:03:14.040
by trying to boost the AI to be created.

01:03:14.040 --> 01:03:15.040
Thank you very much.

01:03:15.800 --> 01:03:18.600
Thank you very much, Professor Elgamal.

01:03:18.600 --> 01:03:22.600
It was very interesting discussion and analysis

01:03:22.600 --> 01:03:25.240
over history of art.

01:03:25.240 --> 01:03:27.240
I really appreciate that.

01:03:28.240 --> 01:03:33.240
I think that if anyone has any question,

01:03:33.240 --> 01:03:36.240
otherwise excellent.

01:03:40.240 --> 01:03:43.240
I think it was very interesting.

01:03:43.240 --> 01:03:45.240
It was very interesting.

01:03:45.240 --> 01:03:47.960
I liked hearing about all of the art history

01:03:47.960 --> 01:03:52.160
and then relating it to the computer science aspects.

01:03:53.680 --> 01:03:55.200
Thank you.

01:03:55.200 --> 01:03:57.760
I hope it wasn't boring from the perspective.

01:03:57.760 --> 01:04:00.960
It was very interesting, especially trying

01:04:00.960 --> 01:04:04.280
to quantify creativity was interesting

01:04:04.280 --> 01:04:07.840
and kind of related to the previous talk as well.

01:04:09.400 --> 01:04:12.960
I also find it very important that there is a separation

01:04:12.960 --> 01:04:16.240
between science and humanities.

01:04:17.120 --> 01:04:19.280
What we are doing in computer vision

01:04:19.280 --> 01:04:22.880
and if you talk about being creative

01:04:22.880 --> 01:04:25.000
and doing machine creativity

01:04:26.320 --> 01:04:29.000
and you are disconnected from what's happening

01:04:29.000 --> 01:04:31.600
in art history or rural art history,

01:04:31.600 --> 01:04:33.160
we are making a big mistake.

01:04:33.160 --> 01:04:34.600
As I said, I mean, for example,

01:04:34.600 --> 01:04:37.160
the concept of style transfer in vision

01:04:37.160 --> 01:04:39.200
and machine learning, totally nonsense.

01:04:39.200 --> 01:04:41.920
When it comes to artists and it comes to art history

01:04:41.920 --> 01:04:43.040
and we still keep doing that.

01:04:43.040 --> 01:04:45.120
We find like hundreds and hundreds of people

01:04:45.120 --> 01:04:47.800
come every year about style transfer.

01:04:47.800 --> 01:04:49.520
We should keep doing the same thing.

01:04:49.520 --> 01:04:51.400
It was totally nonsense to me

01:04:51.400 --> 01:04:52.360
because that's not style

01:04:52.360 --> 01:04:54.320
and that's not what interests artists

01:04:54.320 --> 01:04:56.640
and what interests art history.

01:04:56.640 --> 01:05:00.360
So this connect is really not good.

01:05:02.040 --> 01:05:04.680
Thank you so much for sharing your interest with us.

01:05:04.680 --> 01:05:09.560
I think that this is very intriguing for anyone

01:05:09.680 --> 01:05:12.520
in the class who wants to believe myself,

01:05:12.520 --> 01:05:16.280
who wants to explore more in this direction.

01:05:17.120 --> 01:05:21.480
So I appreciate your time and talk.

01:05:21.480 --> 01:05:22.480
Thank you so much.

01:05:24.960 --> 01:05:29.960
Okay, I think that we can stop you eating your nap.

01:05:30.640 --> 01:05:32.120
Thank you.

01:05:32.120 --> 01:05:33.680
Okay, have a good time.

01:05:33.680 --> 01:05:34.520
You too.

01:05:34.520 --> 01:05:35.360
Thank you very much.

