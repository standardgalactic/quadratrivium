WEBVTT

00:00.000 --> 00:06.760
Hello, everyone. Welcome to your course, Deep Learning for Art, Statistics and Creativity.

00:06.760 --> 00:13.140
Today, we have two special speakers. First, we serve as Dr. Jeff Klun, who is an associate

00:13.140 --> 00:20.440
professor in computer science at the University of British Columbia and also a research team

00:20.440 --> 00:28.640
leader at OpenAI. And he's going to talk about towards creating endlessly creative,

00:28.640 --> 00:35.400
open-ended innovation engines. I think this is a very exciting direction because so far

00:35.400 --> 00:43.000
we have talked about the interaction between art and AI. We said that how AI can help us

00:43.000 --> 00:50.120
to create and express ourselves and democratize the creativity in a sense. But also, the other

00:50.120 --> 01:02.240
direction is how our creativity can help us create better AI. For instance, how we learn

01:02.240 --> 01:11.840
by creating, how we define problems and find solutions for them and generalize to solve bigger

01:11.840 --> 01:20.640
problems and so on and so forth. So today is one of those, I would say, a realization of such a

01:20.640 --> 01:30.480
great idea that you will see as a gist of what Jeff has been working on. So please go ahead.

01:30.480 --> 01:37.840
And also, another question that we often ask in the class is that students are interested to know

01:37.840 --> 01:45.360
a little more about your background because they always feel inspired by seeing great scientists

01:45.360 --> 01:53.040
and what, for instance, got you to working on AI would be very interesting for them if you don't

01:53.040 --> 02:01.480
mind sharing. Great. Thank you for the introduction. Let me share my screen here and make sure that

02:01.760 --> 02:20.320
is working. So are you able to see my screen? Yeah. And the presentation? Yes. Okay. And can you see my

02:20.320 --> 02:28.960
mouse cursor? Yes. Okay. Hello, everyone. My name is Jeff Klune. And I want to talk to you today

02:28.960 --> 02:35.320
about trying to take on like an extremely big research challenge. I think it's a grand challenge

02:35.320 --> 02:43.360
of AI. And that is trying to create what we call open-ended algorithms. I wasn't planning on telling

02:43.360 --> 02:47.320
you a little bit about my background. I guess in brief, I started out on a quest just to understand

02:47.320 --> 02:53.760
two twin questions, which is how did natural evolution produce all the complexity on Earth,

02:53.760 --> 02:59.480
including the human brain? It's astounding. And we don't know how that process happened really. We

02:59.480 --> 03:04.000
don't know how to recreate it. And you'll see a lot of work towards that today. And then also, I'm

03:04.000 --> 03:08.360
interested in trying to figure out how does thinking happen and how can we create it in machines? And

03:08.360 --> 03:13.560
I think in many ways, these questions are very intertwined, as you'll see also today. So I started

03:13.560 --> 03:18.080
out in philosophy, actually, because I thought they had the market cornered on thinking, but really

03:18.080 --> 03:22.520
quickly kind of, or actually not quickly, slowly learned throughout the course of my life that the

03:22.560 --> 03:27.000
best way to tackle these challenges is to try to build these systems and recreate these systems

03:27.000 --> 03:32.000
computationally. Motivated by the wonderful quote by Richard Feynman, which is, that which I cannot

03:32.000 --> 03:37.480
build, I do not understand. So we understand by building. And that has certainly been true in my

03:37.480 --> 03:43.600
life that I understand more and more by being forced to turn speculation into code and into

03:43.600 --> 03:51.400
algorithms. So with that, I'm going to begin. So this talk is really going to be in two parts.

03:52.360 --> 03:56.920
The main part is going to be the first part. And it's about creating open-ended innovation engines.

03:57.560 --> 04:02.200
And if there's time, which I hope there will be, I'm going to rush through a series of work that

04:02.200 --> 04:06.840
we've done that I call AI neuroscience at the end. And then throughout all of this, what you're

04:06.840 --> 04:11.720
going to find is that this is a bit of a meandering intellectual story, because throughout my career,

04:11.720 --> 04:18.040
different research has kind of unintentionally produced different aesthetic artifacts of interest.

04:18.040 --> 04:22.360
And I kind of want to walk through some of the things and touch as many of these places where I

04:22.360 --> 04:26.440
think our work has produced things that are aesthetically interesting, as well as scientifically

04:26.440 --> 04:37.080
interesting. So the first thing I want to motivate is, you know, the idea of open-ended algorithms.

04:37.080 --> 04:42.200
So these are things that endlessly innovate. They just keep going forever. So if you think

04:42.200 --> 04:47.320
about natural evolution, look at the Tree of Life there, and think about all of the marvelous

04:47.320 --> 04:53.560
engineering designs that nature has brought and continues to create in an ever-going fashion,

04:53.560 --> 04:58.920
you know, jaguars, hawks, the human mind, everything that we know on Earth. You know,

04:58.920 --> 05:04.520
in most situations, we cannot rival these things with engineering. And so what's fascinating is

05:04.520 --> 05:09.400
that, you know, a very simple algorithm that Darwinian evolutionary algorithm, plus the context

05:09.400 --> 05:13.880
it's been placed in, continues to innovate for billions and billions of years. And I think it's

05:13.880 --> 05:18.440
really fruitful to think to yourself, you know, could you create an algorithm that you would want

05:18.440 --> 05:23.480
to run for billions and billions of years and come back and check whether or not it's interesting?

05:23.480 --> 05:28.680
Currently, as scientists, we have zero ability to produce things that are interesting even after

05:28.680 --> 05:34.200
a few months of running them on a computer, let alone billions and billions of years. So natural

05:34.200 --> 05:37.560
evolution is what we, you know, one of these open-ended algorithms. And another one is human

05:37.560 --> 05:42.760
culture, which just endlessly innovates and produce innovation on innovation and innovation. That's

05:42.760 --> 05:46.680
both true in science and technology, but it's also true in the arts, where you get, you know,

05:46.680 --> 05:51.400
impressionism after you get the classical paintings, and then you get, you know, post-modernism or

05:51.400 --> 05:57.320
Jackson Pollock or all the different kind of evolution of genres. So, you know, we started

05:57.320 --> 06:03.640
with the idea, when we try and wanted to try to work on this, is that natural evolution and human

06:03.640 --> 06:08.440
culture are what we call innovation engines. And that is that there's kind of this simple recipe

06:08.440 --> 06:15.000
that they follow that allows them to be creative. And that is that they start with a set of things,

06:15.000 --> 06:19.720
it could be an empty set, and then they generate a new thing. And then if that's interesting,

06:19.720 --> 06:23.720
they keep it and add it to the set. And then they take something out of that set, they change it a

06:23.720 --> 06:28.120
little bit, they permute it somehow, and they see if that is interesting. And if that's interesting,

06:28.120 --> 06:32.760
they add that to the set. And you have this growing set of things, these archives of things

06:32.760 --> 06:37.880
you've already produced that are interesting. And then each one of those is a stepping stone to new

06:37.880 --> 06:42.600
potential innovations or solutions. And if you think deeply about it, that's true both of human

06:42.600 --> 06:47.400
culture and natural evolution. And so the question is, with that kind of mental framework, can we

06:47.400 --> 06:54.120
create algorithms that do that process automatically? And so, you know, at the core, there's really kind

06:54.120 --> 06:58.360
of these two simple steps. The first one is you have to have something that generates new things

06:58.360 --> 07:03.480
based on previous things. That's the green box on the left. And then you have to evaluate whether

07:03.480 --> 07:07.400
not those things are interesting. And if they are, then you add them to the set and you just keep

07:07.400 --> 07:13.480
repeating this process. So in the long run, what we'd love to do is take, you know, humans out of

07:13.480 --> 07:18.200
the loop if possible, label data out of the loop, and you just have some sort of generator like a

07:18.200 --> 07:24.040
neural network that can generate new things like poems or codes or mathematical proofs or images,

07:24.760 --> 07:29.160
or, you know, technological artifacts, something, maybe another deep neural net that is trained

07:29.160 --> 07:34.360
to recognize what's interesting somehow, and then that process could just iterate. Now, for example,

07:34.440 --> 07:39.480
you could imagine that you take like the orange box here is an autoencoder. And it looks at everything

07:39.480 --> 07:43.560
that it's seen before, it compresses them down to a low dimensional bottleneck space, and then it has

07:43.560 --> 07:47.880
to uncompress them. And then if you get some new latent vector that's new that you've never seen

07:47.880 --> 07:51.800
before, you call that interesting. And that might be one thing that could kick off this problem.

07:52.360 --> 07:56.840
And if you could do that, you would have an innovations arms race in any domain, you could

07:56.840 --> 08:01.000
unleash this thing anywhere. And that would be amazing. And a lot of these ideas date back to

08:01.000 --> 08:07.320
Schmidt-Huber ideas from the early 90s. However, the problem is that when you do that, you typically

08:07.320 --> 08:12.040
do get new things forever, but you don't get new interesting things forever. You, for example,

08:12.040 --> 08:15.880
might get white noise, just an endless stream of different patterns of white noise, because those

08:15.880 --> 08:20.760
are uncompressible. So really, at its core, the biggest challenge in this field is kind of how

08:20.760 --> 08:25.800
do you avoid generating uninteresting novelty, and how do you only generate interesting novelty?

08:26.600 --> 08:31.400
And here's one example by a friend of mine, Josh Auerbach, who tried to basically take the same

08:31.400 --> 08:35.160
encoding that I'm going to tell you about later, and a similar system is trying to automatically

08:35.160 --> 08:40.280
generate images and try to produce new interesting images forever. And these images are interesting,

08:40.280 --> 08:44.120
they're pretty cool, but they're not nearly as interesting as they could be, right? They're not

08:44.120 --> 08:49.000
like what artists would do over the course of centuries. You would expect and hope that things

08:49.000 --> 08:52.440
would ultimately break out of these kind of abstract patterns. And that's because these

08:52.440 --> 08:59.240
things are optimized to produce information theoretic metrics like compression or mutual

08:59.240 --> 09:05.720
information and things like that. So what we thought in this work is that one insight you could

09:05.720 --> 09:11.160
have is that recognizing a new type of thing is like being able to recognize a new class of thing.

09:11.160 --> 09:15.960
If you've never seen a palm tree before, that's a distinct kind of trees. And if you've never

09:15.960 --> 09:21.480
seen a tree before, trees are distinct from dogs and roses and statues. And so

09:22.200 --> 09:28.440
one way to think about being able to recognize an infinite number of new classes is to approximate

09:28.440 --> 09:34.760
that by having a neural net just recognize a very large number of classes. And so if you could

09:34.760 --> 09:40.200
recognize, you know, a million classes, for example, then as the generator produces new

09:40.200 --> 09:44.280
instances of those classes, maybe the process could like start going out and generating each of

09:44.280 --> 09:49.640
these classes. And that allows us to then use supervised learning because we know how to recognize

09:49.640 --> 09:56.440
new classes of things. So this is an approximation to the overall goal and to try to see if this

09:56.440 --> 10:00.440
system can work. So the way that we wanted to approximate this, and this is all the way back

10:00.440 --> 10:05.800
in 2015 before image generation really worked that well, is we said, let's take a deep neural net

10:05.800 --> 10:11.960
that is trained on ImageNet, which is relatively new around that time. It has 1000 different classes

10:11.960 --> 10:15.320
and it's really good at recognizing these different classes. And then we'll have, we'll use that as

10:15.320 --> 10:21.080
our evaluator, which is the generator's job is to generate instances of that class. And then the

10:21.080 --> 10:25.800
question is, what are we going to use for this, the green box here, the generator side. So what we

10:25.800 --> 10:31.800
need is an algorithm that can recognize either an improvement on a current class, or when a new

10:31.800 --> 10:37.400
class is generated. And so we decided to use this algorithm that I'm excited to tell you about,

10:37.400 --> 10:40.920
because it has a lot of really interesting motivations behind it. It's called map elites.

10:41.880 --> 10:47.240
And it has one bin per ImageNet class. And I'll tell you what map elites is right now.

10:47.240 --> 10:51.800
But to tell you about map elites, I kind of want to motivate this whole field of a new kind of

10:51.800 --> 10:56.200
type of algorithm that my colleagues and I have been working on. And it starts with this recognition,

10:56.200 --> 11:00.840
which is that there's a paradox in life, which is that if you try too hard to solve a problem,

11:00.840 --> 11:06.920
you'll fail. However, if you ignore the objective, then you're much more likely to succeed. So imagine

11:07.000 --> 11:12.040
that you're in this maze here, and you're starting here, and your job is to get here. And you might

11:12.040 --> 11:17.160
say, well, okay, make the robot who's here, make its objective, getting as close as possible to

11:17.160 --> 11:21.080
the goal. Well, if you do that, and you get points here, these are all the points that get generated

11:21.080 --> 11:25.560
by that search algorithm, because and most of them just go straight north, because that lowers the

11:25.560 --> 11:30.760
distance to the goal. But then they just butt their head against that wall forever. This is a

11:30.760 --> 11:35.880
classic local optimus, you're familiar with these things in search. However, if you simply switch

11:35.880 --> 11:40.840
away from the paradigm of always try to optimize toward a goal, and you just say, let's just go

11:40.840 --> 11:46.200
to new places, just seek novelty. That's what you get here. And eventually this search stops

11:46.200 --> 11:50.760
focusing on just going north. It doesn't actually care more about north than going east. And eventually

11:50.760 --> 11:56.200
it winds its way around, and it solves the problem. And this right here is a metaphor for every single

11:56.200 --> 12:02.040
hard thing we want to do in search. If there are local optimal in space, if we need to explore

12:02.040 --> 12:06.760
to discover this thing, then we probably should seek novelty more than an objective. And it's

12:06.760 --> 12:12.520
even a metaphor for things beyond algorithmic search. It's also a metaphor for human culture

12:12.520 --> 12:18.360
and even natural evolution. And the idea is that almost every major scientific breakthrough,

12:19.400 --> 12:23.880
if you trace its lineage back, it's not a straight path to that solution. Instead,

12:23.880 --> 12:29.000
it's a winding, circuitous route. So for example, if you went back in time centuries and you said,

12:29.000 --> 12:34.680
I have this way of cooking food, and what I want is a faster way to cook food that doesn't produce

12:34.680 --> 12:41.800
any smoke, then you would never, if you only funded work into improved cooking technology that can

12:41.800 --> 12:46.760
accomplish those goals of heating things faster, you would never invent the microwave, which is a

12:46.760 --> 12:51.800
magical invention. Because to invent the microwave, you had to have been working on radar technology

12:51.800 --> 12:56.840
and recognize the chocolate bar melted in your pocket. Similarly, if you went back millennia

12:56.840 --> 13:02.040
to this abacus and you said, that thing does computation, I want more computation. And you

13:02.040 --> 13:07.080
only funded researchers who improved against the objective of producing more computation,

13:07.080 --> 13:12.920
you might get abacuses with like longer rods, more beads, something like that. But you would never

13:12.920 --> 13:17.880
invent the modern computer because to do that, you had to work on things like electricity and

13:17.880 --> 13:23.480
vacuum tubes, which were decidedly not produced because they improved computation, although

13:23.480 --> 13:28.760
they later proved instrumental to doing that. The same is true for going from this kind of energy

13:28.760 --> 13:33.000
to clean energy, where you have to be thinking about things like space and time that were not

13:33.000 --> 13:39.080
thought about because they would produce new ways of producing clean energy. So the conjecture here

13:39.080 --> 13:43.480
is that the only way to solve really hard problems may be to create problems while you solve them

13:43.480 --> 13:49.080
and goals switch between them. And so goal switching is this idea that if you're trying to solve one

13:49.080 --> 13:55.320
task, and you make progress on a different task, then you should also start optimizing and getting

13:55.320 --> 13:59.960
better on that different task. So if this robot here, this scientist here wants to make a walking

13:59.960 --> 14:04.600
robot, and all of a sudden during optimization, the robot starts crawling or starts balancing on

14:04.600 --> 14:10.840
one leg, you shouldn't throw that out as a failure because it's not helping you walk or making forward

14:10.840 --> 14:15.160
progress. Instead, you should start getting better at those skills to add those to the set of things

14:15.160 --> 14:20.120
that you work on. And ultimately, those might be stepping stones to get you to this walking robot.

14:21.080 --> 14:28.360
So my colleagues and I have been creating this new subfield of algorithms of AI

14:28.360 --> 14:32.760
called quality diversity algorithms. And this family of algorithms is trying not just to get

14:32.760 --> 14:36.520
the single best solution to a problem. It's trying to do something very different. It's

14:36.520 --> 14:43.160
trying to get a large set of diverse solutions, but where every solution is as good as possible

14:43.160 --> 14:49.160
for that type of solution. You want the tallest in the giraffe or the fastest ant,

14:49.160 --> 14:54.440
but you don't let an ant who's not that fast kind of get precluded by the fact that a cheetah is

14:54.440 --> 15:01.800
faster. You still want the fastest ant and the best ant you can find. So probably the most popular

15:01.800 --> 15:06.680
algorithm in this family at this point is this algorithm called map elites, which was invented

15:06.680 --> 15:12.200
by Jean-Baptiste Morel, a great colleague and friend of mine, as well as myself in 2015. And

15:12.200 --> 15:15.720
it's very, very simple. And the idea here is if you're going to solve a problem,

15:15.720 --> 15:22.120
want to first choose or learn, but we started off by choosing dimensions of interest that you find

15:22.120 --> 15:26.920
that you yourself like. So imagine if you're trying to make a car, for example, you might choose

15:26.920 --> 15:32.200
safety and fuel efficiency as two dimensions of interest. And then you just discretize these

15:33.320 --> 15:37.400
dimensions. And you look for the best solution, according to some criteria, like maybe it's the

15:37.400 --> 15:43.400
fastest car at each point in this grid. And what you want at the end of the day is not just to get

15:43.400 --> 15:49.640
the fastest car possible, but the fastest car for every possible tradeoff between safety and fuel

15:49.640 --> 15:56.120
efficiency. So here's an example problem we tried this on. This is generating soft robot morphologies,

15:56.120 --> 16:01.640
which is like the bodies of robots. So we gave this optimization algorithm those four materials

16:01.640 --> 16:06.200
there. They're kind of voxels that can pulse at different times. And some are soft and some are

16:06.200 --> 16:13.080
hard. And we said, you know, go fast. And, you know, first we did this without map elites,

16:13.080 --> 16:17.080
we just did this with a canonical optimization algorithm or a genetic algorithm in this case,

16:17.080 --> 16:22.280
which is just trying to optimize for speed. And what you see here is this kind of really

16:22.280 --> 16:26.920
interesting parade, this Noah's Ark of very different solutions and very different creatures.

16:27.800 --> 16:32.120
And, you know, people got really excited when we put this online and it's super fun.

16:32.120 --> 16:35.400
But I think one of the things that people thought really interesting about this work,

16:35.400 --> 16:41.000
including myself is the huge diversity of designs that you see here. You know, it starts to evoke

16:41.000 --> 16:45.960
nature where you see a lot of different designs. The problem is there is a trick to this. And that

16:45.960 --> 16:51.640
is that all of the designs that you just saw, each of those came from a different run of optimization.

16:51.640 --> 16:57.160
The only way you got a diversity was by starting the run again and doing a massive search to find

16:57.160 --> 17:01.880
one solution. But if you look within that population of creatures, they're all almost identical.

17:01.880 --> 17:05.880
And that's not what we want. What we want on is an algorithm that will generate a huge diversity

17:05.880 --> 17:09.800
of things within one run so that you can run it for billions of years and it would continue to

17:09.800 --> 17:14.520
produce interesting new stuff as opposed to converging to one type of solution and getting

17:14.520 --> 17:19.240
stuck on that kind of local optimal. So we took the map elites algorithm that I just described

17:19.240 --> 17:24.760
to you and we applied it to the same software last problem. And what we did there, you know,

17:24.760 --> 17:29.320
is we have to pick the dimensions and we chose to pick the number of voxels and then amount

17:29.400 --> 17:34.440
of this dark blue material because previously it hadn't been using this kind of bone-like material

17:34.440 --> 17:39.960
and we wanted to see it play with that resource more. And if you look at classic optimization,

17:39.960 --> 17:44.280
this could have been RL, but in this case it's a genetic algorithm. Any optimization,

17:44.280 --> 17:48.920
what you find is that it doesn't actually search the space very well. And so it has low performing

17:48.920 --> 17:53.720
points and it didn't do a lot of exploration. If you add diversity, which we know historically

17:53.720 --> 17:58.360
helps, you do get higher performing points. So you see these yellow points here, but it still

17:58.360 --> 18:02.520
did not explore a lot of the space, even though it's incentivized to literally explore in these

18:02.520 --> 18:08.440
two dimensions. Map elites is a qualitatively different algorithm. It's a sea change in terms

18:08.440 --> 18:12.840
of what happens within the algorithm. If you look here, you see this rich exploration where it

18:12.840 --> 18:18.040
fanned out and searched the entire search space and it taught you more about this search space.

18:18.040 --> 18:22.440
It tells you, hey, there's not very high performing points up here. There's a little bunch of optima

18:22.440 --> 18:26.280
over here. There's also this separate little area here that you probably would never have normally

18:26.280 --> 18:30.440
found, et cetera, et cetera. I'm doing these interesting points over here that you can go

18:30.440 --> 18:36.680
investigate. And what's interesting is it often finds a better overall high performing solution

18:36.680 --> 18:41.400
than if you just do direct optimization because it's doing such a better job of exploring the

18:41.400 --> 18:48.280
space of possibilities. So if you look at any individual final point, you can trace back its

18:48.280 --> 18:54.280
lineage through time to see where those solutions visited in the search space. And what you can

18:54.280 --> 18:59.320
see here is that they don't just kind of mine one area of the space and get better and better and

18:59.320 --> 19:03.400
better at that corner of the search space, that particular tradeoff between these two dimensions.

19:03.400 --> 19:09.240
But instead, the overall lineage takes these long, circuitous paths to their final destination.

19:09.240 --> 19:13.800
Just as to get a human, you had to go through an intermediate stage of being a tapeworm and then

19:13.800 --> 19:18.040
being like a tree dwelling. Actually, I don't know if we were a tree doubling, but kind of

19:18.040 --> 19:22.840
something that looked more like an ape and all sorts of intermediate steps along the way.

19:23.640 --> 19:29.320
So going back to the idea of an innovation engine, we now can recognize the algorithm that we're

19:29.320 --> 19:33.560
going to use here. There's one final thing I need to tell you about, which is how are we going to

19:33.560 --> 19:38.040
encode the images we're going to search for. And I'm going to tell you what I mean by the word

19:38.040 --> 19:41.880
encoding, because I think especially for people who are interested in aesthetics, this is one of

19:41.880 --> 19:47.160
the most important choices you can make. And you'll see this show up in Joel's work later as well.

19:47.160 --> 19:50.920
So I'm going to tell you about the encoding that we use, which is a CPPN. So first,

19:50.920 --> 19:54.600
I've been throwing around these terms, genetic algorithm and evolutionary algorithms. You may

19:54.600 --> 20:00.280
not know what they are. I'm going to very briefly explain them. If you want to search for a problem,

20:00.280 --> 20:03.880
this is also true in deep learning. The first choice you have to make is how to encode the

20:03.880 --> 20:08.280
problem. So imagine if you wanted to search for tables. Well, you could decide I'm going to store

20:08.280 --> 20:13.640
the length of each leg separately as a number on a parameter vector. We in evolutionary algorithms,

20:13.640 --> 20:17.720
we call this a genome, but in deep machine learning, it's often called a parameter vector.

20:17.720 --> 20:21.480
So you store the length of each leg separately and the width and the length of the surface of

20:21.480 --> 20:26.760
the table maybe on this string of numbers, this parameter vector. Once you've made that encoding

20:26.760 --> 20:31.800
choice, you then can score the population. First, you create a population at random by generating

20:31.800 --> 20:35.960
random strings of numbers. You score this population to see how good they are. You select

20:35.960 --> 20:40.680
which ones are better according to some scoring function, which could be your reward function.

20:40.680 --> 20:46.040
And then you just take these things here, take their parameter vectors, and you perturb them

20:46.040 --> 20:51.400
in a little way somehow. And then you get a new thing and then you repeat the process.

20:51.400 --> 20:54.200
In the gradient-based method, this is kind of like where you take the learning

20:54.200 --> 20:59.000
step based on the gradient of the scoring function. And then you repeat the problem.

20:59.000 --> 21:04.040
So when I talk about an encoding, it's this first choice, which is how do we decide what is the search

21:04.040 --> 21:09.720
space that we will search in the parameter vector and how does that map to the final solution?

21:09.800 --> 21:16.200
And that is in evolutionary language, the process of going from a genotype to a phenotype,

21:16.840 --> 21:20.760
or machine learning a parameter vector to a final agent or policy or artifact.

21:21.640 --> 21:27.480
So there is this notion of a direct encoding versus a generative encoding. And a direct encoding,

21:27.480 --> 21:32.520
you basically have one number on your parameter vector for every single thing in your final artifact.

21:32.520 --> 21:36.200
So if you're searching for the weights of a neural net, then you search separately for a

21:36.200 --> 21:39.960
number for each weight or for a table you search separately for the length of each leg.

21:40.760 --> 21:44.920
If you think about how perturbations affect these parameter vectors, though,

21:44.920 --> 21:51.480
they are mostly likely to produce non-regular phenotypes. So most changes are not going to

21:51.480 --> 21:56.920
lead to a table that has to be flat and hold your coffee. And so that makes kind of a local

21:56.920 --> 22:00.760
optimum between this solution and this solution. You have to go through this intermediate thing

22:00.760 --> 22:06.760
unless you get lucky enough to generate a regular phenotype. If you have a generative encoding,

22:06.760 --> 22:12.600
you reuse information in the parameter vector to produce the final thing. So you might just

22:12.600 --> 22:18.040
specify the length of legs once and then reuse that for these four lengths of tables. And now

22:18.040 --> 22:24.520
every single change to that parameter vector is going to produce a regular flat table. However,

22:24.520 --> 22:29.880
you've lost something. You've lost the ability to express this type of table up here. And so this

22:29.880 --> 22:35.640
is like a really, really essential choice when you go to produce any solution with search.

22:35.640 --> 22:39.960
So generative encodings, you know, my colleagues and I and many others have been focusing for a

22:39.960 --> 22:44.840
long time on why these types of encodings are really interesting. And some of the desirable

22:44.840 --> 22:49.160
properties that we want is that you can get regularity, which means you can get patterns in

22:49.160 --> 22:54.760
the final artifact. It might be the architecture of a neural net, or here is the hands on your,

22:54.760 --> 22:59.640
you know, in your body. And what you see is there's a repeating theme in your hands. That's the

22:59.640 --> 23:05.000
regular pattern. But it also has variation. Each of your fingers is a variation on a concept or a

23:05.000 --> 23:09.400
theme. And that's kind of one thing that you might want while you search. There are some others

23:09.400 --> 23:15.080
benefits here, but I'm not going to get into those. So this is something that I just think is really

23:15.080 --> 23:19.480
fascinating to think about, especially if you're interested in aesthetics. And it also ends up

23:19.480 --> 23:23.000
being helpful algorithmically. And it's going to factor into a lot of Joel's work, I assume,

23:23.000 --> 23:28.360
depending on what he talks about. And this is this question of how does nature build the

23:28.360 --> 23:34.600
astronomically elegant, complex creatures that you see in the natural world? Like a question

23:34.600 --> 23:37.640
that I'm not sure if you've ever stopped and thought about, but it's a fascinating one to think

23:37.640 --> 23:44.360
about is how does every cell in your body know what kind of cell to become? You have, you know,

23:44.360 --> 23:51.080
the same software is being run in every one of your cells, the same DNA, yet some of your cells

23:51.080 --> 23:56.280
turn into hair cells or spleen cells or liver cells or eye cells. How does it do that? How does

23:56.280 --> 24:01.640
every cell know what kind of cell to become? Well, it turns out that nature is using a generative

24:01.640 --> 24:07.080
encoding where it reuses information, where the cell fate, which is the type of cell, is a function

24:07.080 --> 24:12.520
of its geometric location in the body. It's almost as if the body wanted to know the XYZ

24:12.520 --> 24:17.720
GPS coordinates of each cell so that it could tell you, oh, if you're like up here, left of the

24:17.720 --> 24:22.200
midline, three quarters of the way up the y-axis, then become a heart cell, for example.

24:23.320 --> 24:28.200
So if you look through developmental biology textbooks, what you find is that these kinds

24:28.200 --> 24:33.640
of geometric patterns are the lingua franca of developmental biology. So here's this beautiful

24:33.640 --> 24:38.920
cartoon by Sean Carroll. So here's your DNA which has these genes on it. And in this developing

24:38.920 --> 24:44.040
embryo are currently three different chemical patterns. They're called morphogens. They're

24:44.040 --> 24:50.200
literally some protein that's sitting diffused inside this embryo. And if this gene here says

24:50.200 --> 24:56.840
that protein A is present and B and C are not present, then this gene expresses and produces

24:56.840 --> 25:02.280
a new protein, only where that's true. And so now you've combined these three pre-existing

25:02.280 --> 25:07.560
patterns to produce this fourth new pattern. And this might therefore tell the vertebra and a spine

25:07.560 --> 25:13.080
that they should turn into vertebra cells. You get this repeating theme down the middle, but only

25:13.480 --> 25:17.640
the left half of the embryo. And if you look through that, go ahead.

25:17.640 --> 25:22.040
Would I be able to interject real quick? Sure. My research is actually focusing on exactly this

25:22.040 --> 25:26.680
same kind of problem, but in mammals. And so in mammals, the morphogen model explains some stuff,

25:26.680 --> 25:32.200
but it's actually even more complex. It is much more complex. Everything in nature is much more

25:32.200 --> 25:39.240
complex than we know. So I am simplifying here because I'm flying through this material. And

25:39.320 --> 25:44.200
not all of the, not, it's not to say that the only thing that's happening is geometric patterning,

25:44.200 --> 25:51.960
but it is, basically, I think it's the backbone of the way this stuff gets built. And so by capturing

25:51.960 --> 25:57.560
that power and putting it into our search processes, we've gone a long way towards the power of

25:57.560 --> 26:03.320
developmental biology. And you could argue that you've skipped out on a lot of the extra complexity

26:03.320 --> 26:07.560
that would be very computationally difficult to simulate by doing these things efficiently.

26:09.320 --> 26:10.520
Yeah. All right. That's a good point.

26:13.240 --> 26:20.200
Cool. Thank you for the question. So getting to the issue I was just talking about, which is how

26:20.200 --> 26:26.840
can we efficiently make this sort of a process happen? So what we don't want to do computationally

26:26.840 --> 26:31.800
is have, like, diffusing chemicals in some chemical simulator, because that would be

26:31.800 --> 26:37.080
really, really expensive. And so Ken Stanley, my longtime friend and colleague figured out,

26:37.080 --> 26:43.080
is that you can actually abstract a lot of the power of this system without any of the underlying

26:43.960 --> 26:49.800
chemistry and in physics in these things that are called CPPNs or compositional pattern producing

26:49.800 --> 26:55.240
networks. And the idea is, is just like in nature, we're going to encode phenotypic elements as a

26:55.240 --> 27:01.720
function of their geometric location. So here's how it works. You take a thing that you want to

27:02.840 --> 27:06.920
optimize. This could be a neural network, it could be a robot morphology, it could be a

27:06.920 --> 27:13.640
picture. And you provide coordinates for everything in the artifact. So imagine it's easiest to think

27:13.640 --> 27:18.440
about pictures. So imagine you give every pixel an x, y coordinate, then you literally pass the

27:18.440 --> 27:24.440
number, then those numbers into this function. So first you put in one, one for this pixel,

27:24.440 --> 27:30.520
and then one, two, and then one, three. And you ask the genome as a function of those two numbers

27:30.520 --> 27:35.640
to spit out the value at that location. And if this is a random function,

27:35.640 --> 27:41.720
then you're going to get a random picture. But if this function here has mathematical functions

27:41.720 --> 27:46.840
that, you know, have regularities in them, then you're going to get a regular artifact.

27:46.840 --> 27:53.560
So for example, if you want left-right symmetry, you can pass the x-axis through a Gaussian here,

27:53.560 --> 27:57.400
and then everything downstream of that Gaussian node will have left-right symmetry.

27:58.120 --> 28:03.640
Similarly, you could have in the y-axis, if you wanted a repeating theme like segmentation,

28:03.640 --> 28:08.680
you could pass the y through a sine function, and then everything downstream of that node will be

28:09.400 --> 28:14.520
regular in that way. You can also add in linear things. You could say, I want to follow the sine,

28:14.520 --> 28:19.800
but only add in a linear component, so like shift it or warp it or bend it in certain ways. So you

28:19.800 --> 28:25.560
can mix and match asymmetric and symmetric and repeating themes to produce arbitrary complexity

28:25.560 --> 28:32.040
using these geometric functions. And kind of what was really amazing at the time,

28:32.040 --> 28:36.600
because image generation wasn't working very well, was the kind of images that would pop out of

28:36.600 --> 28:41.160
these systems. So all of these images here were produced on a website called Pickbrier, where

28:41.160 --> 28:46.680
humans manually choose which ones they find interesting, but the underlying encoding is a CPPN.

28:47.800 --> 28:51.080
And Jill's going to tell you a lot more about like a modern version of this website.

28:51.640 --> 28:57.720
So these images here are all encoded with CPPNs, and what you can see is very, very natural like

28:57.800 --> 29:03.560
shapes, like things like left-right symmetry, repeating motifs, and the lineages as you kind of

29:03.560 --> 29:08.200
permute and mutate these things. You go from a butterfly to a bat with these kind of beautiful

29:08.200 --> 29:15.240
gradations and interpolations that are nice to see. Myself and my postdoc advisor, I took the

29:15.240 --> 29:18.920
same exact idea and we just put it in three dimensions, and what you get are these nice

29:18.920 --> 29:24.360
three-dimensional shapes, which also show a lot of these regularities. And then we went off and we

29:24.360 --> 29:29.560
built this website called endlessforms.com, where you can go on, it's basically Pickbrier but in 3D.

29:29.560 --> 29:35.160
You can take an individual shape and you can say, I want to further evolve or optimize that shape.

29:35.720 --> 29:40.680
Let's see if this plays. Here, for example, you might take this lamp and you are presented with

29:40.680 --> 29:45.160
a bunch of variants on the lamp, and then you pick the one that you like and you see the next

29:45.160 --> 29:50.760
generation and you can kind of crawl through three-dimensional lamp space. And importantly,

29:50.760 --> 29:54.600
if you find one that you like, then you can publish it to the website and other people can

29:54.600 --> 29:59.720
pick it up and branch off of that. This is how you get that growing archive of stepping stones

30:00.520 --> 30:03.800
that allows us to produce kind of an interesting exploration of the space.

30:05.480 --> 30:10.200
Here are some of the other designs that popped out of this system, and here's kind of repeating

30:10.200 --> 30:16.680
segmentation, left-right symmetry, radial symmetry, and mostly a lot of the things just look really

30:16.680 --> 30:22.440
natural and interesting. So this is kind of a fun aesthetic space to be playing in using these CPPNs.

30:25.320 --> 30:30.200
Because we could, we 3D printed the objects and allowed users on the website to 3D print them,

30:30.200 --> 30:34.600
so it's kind of fun to hold these things in your hand, and you can therefore help people who have

30:34.600 --> 30:40.360
no knowledge of CAD and design to produce arbitrarily complex images and then 3D print them

30:40.360 --> 30:43.960
for whatever they want, like a chessboard or something. So when we put this out there,

30:43.960 --> 30:49.240
people really found this interesting, which I think just goes to the to the fact that if you can

30:49.240 --> 30:54.760
automate the design, if you can help people produce really interesting things that they're curious

30:54.760 --> 30:59.480
about and they find exciting, but eliminate all the technical barriers to doing so, then people

30:59.480 --> 31:05.480
get really excited about those tools, and Joel's website as a, you know, GAN breeder is a testament

31:05.480 --> 31:10.280
to that as well. So going back to the overall scientific question here, which is can we use

31:10.280 --> 31:15.400
this to create an open-ended algorithm? Now you know all the pieces of the puzzles. So we're

31:15.400 --> 31:20.120
going to have AlexNet, which is an early image net network that was quite good at the time,

31:20.120 --> 31:23.240
be able to recognize a thousand different classes, and then we're going to have an optimization

31:23.240 --> 31:27.400
algorithm that's going to generate these little tiny CPPN networks that are trying to produce

31:27.400 --> 31:33.000
images that light, that the DNN, the deep neural net, thinks represent, you know, are classified

31:33.000 --> 31:38.920
as each one of the thousand bins in image net. So the idea hopefully is that you'll get goal

31:38.920 --> 31:44.040
switching. So if one of the networks is the best dog we've ever seen, or particular dog,

31:44.040 --> 31:48.760
and then a permutation on that produces the best fish we've ever seen, then now that network can

31:48.760 --> 31:53.880
go to hop over to that bin and start optimizing to become a better fish. And maybe that produces a

31:53.880 --> 31:59.400
better stepping stone for a cat and then a bird, etc. And the hypothesis that we wanted to test

31:59.400 --> 32:06.600
is, is that better than separately optimizing for each one of the bins in image net? So here is

32:06.600 --> 32:12.360
the performance over time. Time here, training goes from bottom to top, and the category of

32:12.360 --> 32:17.320
thousand image net classes are along the x-axis. What you can see is that over time performance

32:17.320 --> 32:22.280
rises with training all the way up to one, you know, red in most places, which means that the

32:22.280 --> 32:27.240
deep neural net is certain that this thing is a lion, and this is a starfish, and this is a guitar.

32:27.880 --> 32:33.240
So my question to you is, knowing that the deep neural net thinks that each one of these things

32:33.320 --> 32:38.520
is in that category, you know, what do you think they look like? And if you had asked this question

32:38.520 --> 32:44.680
in 2015, 2016, people would have said they look like electric, you know, starfish and guitars,

32:44.680 --> 32:50.360
but you probably now, because you guys are, we've had the benefit of a few years, you probably are

32:50.360 --> 32:55.160
used to the idea that what you do, what you get is not that, but you get these things that are called

32:55.160 --> 33:00.840
fooling images or adversarial images, which is to say that the deep neural net is absolutely

33:00.840 --> 33:06.280
certain that this is a starfish, and this is a peacock, and this is a king penguin, and this is

33:06.280 --> 33:11.560
an electric guitar, even though they obviously are not those things. So at the time, this was a,

33:11.560 --> 33:16.680
this, we published this paper, deep neural nets are easily fooled, and it was a really big wake-up

33:16.680 --> 33:21.960
call to the community that AI sees the world differently. There are huge security concerns

33:21.960 --> 33:28.040
here, and this generated a tremendous amount of discussion and awareness amongst the scientific

33:28.040 --> 33:31.720
community, the machinery community, and also the broader public about the fact that these new

33:31.720 --> 33:36.040
tools that we're building have a lot of deep flaws within them that we need to worry about.

33:36.680 --> 33:42.120
Nowadays, everyone's very familiar with adversarial images. At the time, this was not very well known,

33:43.480 --> 33:49.080
and so I thought that was interesting. However, I also think from an aesthetic perspective,

33:49.080 --> 33:52.680
it's interesting that we were trying to generate innovation engines and generate images. We weren't

33:52.680 --> 33:56.600
trying to study neural nets and whether they had flaws, and then this just kind of popped out,

33:56.600 --> 34:01.960
so I thought that was an interesting story. But while some of the images didn't look anything

34:01.960 --> 34:06.280
like the categories of interest, another thing that we found interesting is that many of them

34:06.280 --> 34:10.280
did, and from an aesthetic perspective, this is pretty cool because now you're getting an automated

34:10.280 --> 34:16.440
art generator. So for example, matchstick, television, and bagel, they pretty much do look

34:16.440 --> 34:21.640
like those things. However, I also think from an aesthetic perspective that some of these really

34:22.200 --> 34:28.120
evokes an artistic interpretation of what that abstract platonic concept represented by that

34:28.120 --> 34:37.640
class is. For me, this image of a prison cell evokes more than just a picture of a prison cell.

34:37.640 --> 34:42.600
It seems to me like an artist decided to represent the bleakness but also the hope or

34:42.600 --> 34:47.160
something about this prison cell. And so even though there is no artist that was trying to

34:47.160 --> 34:51.400
capture that behind here, there's a neural network that's kind of captured the platonic

34:51.400 --> 34:57.720
concept of a prison cell, and that somehow leads to its own dialing in of what is central and

34:57.720 --> 35:03.000
essential about that concept, or at least evokes those kind of reactions in us and allows us to

35:03.000 --> 35:09.720
explore potentially new types of artistic and aesthetic connections to concepts. So if you

35:09.720 --> 35:14.520
look through the diversity of the images that were generated, I do think this kind of really hit

35:14.520 --> 35:19.880
the mark in terms of a quality diversity algorithm. You've got this huge set of images as all comes

35:19.880 --> 35:25.800
from, you know, one run. And at least I'm not, I think that they are, they might have been pulled

35:25.800 --> 35:30.840
from a couple of different runs in this case. But each one produces this giant, this diverse set

35:30.840 --> 35:34.680
of images, and many of them I think are really aesthetically interesting, like I think this

35:34.680 --> 35:40.040
volcano or this beacon, or this cup, I could actually imagine a coffee shop where this is this

35:40.040 --> 35:45.720
logo, your comments on a mask and a banana, etc. So we really, really thought it was cool to see

35:45.720 --> 35:51.640
kind of this pop out of an automated system back in 2015. Scientifically, we're also really

35:51.640 --> 35:55.640
interested in like whether or not goal switching was playing a huge role in these networks. And so

35:55.640 --> 36:01.080
we have, if you optimize for a single class only, like the water tower class, what we see is that

36:01.080 --> 36:06.280
you do indeed get stuck on a local optima. It lands on this particular pattern really early in the

36:06.280 --> 36:11.160
run. And then it just does minor tweets on that idea and gets stuck on it until eventually it kind

36:11.160 --> 36:16.760
of maxes out what you can do in that corner of the search space. In contrast with map elites,

36:16.760 --> 36:22.120
what you see is that early on it locks on this half dome moon image, and it does okay, but then

36:22.120 --> 36:26.440
it kind of gets stuck. And then from a totally different class, something that happened to have

36:26.440 --> 36:32.280
been produced to for the beacon class, actually ends up looking like a better water tower and

36:32.440 --> 36:36.920
goal switches in, it invades this class. And then with further optimization to look like a water

36:36.920 --> 36:42.520
tower ends up making the DNN think with 98% confidence that this is a water tower. And you

36:42.520 --> 36:48.680
can kind of see why. And we see this lesson over and over and over again. There's many goal switches

36:48.680 --> 36:54.760
happening within this population of networks. And we think that's a big reason why performance is

36:54.760 --> 37:01.560
much higher than when you optimize for a single class. So what's really interesting about goal

37:01.560 --> 37:06.440
switching is that it allows what what are what biologists call adaptive radiations. So you come

37:06.440 --> 37:11.640
up with a good idea like maybe a more efficient way to metabolize oxygen in one lake in Africa.

37:11.640 --> 37:17.000
And then that idea will spread to all of the surrounding lakes in Africa. And then on top of

37:17.000 --> 37:23.080
that technological foundation, those fish will respecialize to their particular niche and adapt

37:23.080 --> 37:27.080
that innovative incorporate that innovation. The same thing happened with Darwin's finches,

37:27.080 --> 37:33.160
which radiated out from one from one couple of finches to all of these diverse finches.

37:33.160 --> 37:37.400
And we see the same thing in technology where computers, for example, were invented for one

37:37.400 --> 37:42.040
purpose and then kind of spread throughout an ecosystem and are now embedded in all sorts of

37:42.040 --> 37:47.560
technological devices in our lives. So what's really nice is you can see these adaptive radiations

37:47.560 --> 37:51.880
happen in these quality diversity algorithms. So this is one of my favorite plots from all of

37:51.960 --> 37:57.400
the science I've done in my entire career. Inside one of these innovation engine runs,

37:57.400 --> 38:01.960
you've got this early innovation, which is this dome against a background, a colored background.

38:01.960 --> 38:08.520
And that thing, which looked up the abaya class, then radiates out and it's children because this

38:08.520 --> 38:13.800
is a population. So these literally are descendants of each other. It's descendants kind of produce

38:13.800 --> 38:19.320
a phylogenetic tree, just like we see in nature. And ultimately, this innovation turned into a

38:19.320 --> 38:26.600
volcano, a mosque, a water tower, a beacon, a yurt, a church, a planetarium, an obelisk, and a dome.

38:26.600 --> 38:30.920
And it's just awesome to see an innovation then get rid of that concept, get rift upon and kind

38:30.920 --> 38:36.600
of radiate out into a huge explosion of diversity. So if you study the history of biology, you'll see

38:36.600 --> 38:39.880
that there were many moments in the history of biology where something similar happened. We got

38:39.880 --> 38:45.400
like, you know, single multicellular organisms or rate or bilateral symmetry or the four-legged

38:45.400 --> 38:50.200
body plan. And then you see this explosion of diversity that descends from that central innovation.

38:50.200 --> 38:53.400
So I think it's beautiful to see that happening inside of our algorithms.

38:54.760 --> 39:00.120
We ended up submitting the art that was produced by this algorithm to a competition at the University

39:00.120 --> 39:04.360
of Wyoming where I was a professor. And every year, art students work for a year and they submit

39:04.360 --> 39:08.360
their best project to this competition. And then there's a judges who decide which of them get

39:08.360 --> 39:13.800
hung on the wall and accepted into the competition. So we did not tell them this is AI-generated art,

39:13.800 --> 39:18.600
we just submitted it. And not only was the art accepted, it was also given an award.

39:18.600 --> 39:23.000
So here you see people having wine and cheese. And I was like eavesdropping as they're discussing

39:23.000 --> 39:27.640
the intent of the artist behind producing all of these different images, not knowing that it was

39:27.640 --> 39:33.000
an AI algorithm behind it, which I thought was pretty cool. So in some sense, this passed the

39:33.000 --> 39:40.360
artistic turning test. Sample size one. FYI, in case you're interested, there is much more work on

39:40.360 --> 39:45.320
CPPNs that are more modern. So nowadays, a lot of people are playing with differentiable CPPNs

39:45.320 --> 39:49.880
instead of using evolution. I have to because it's so beautiful. Quickly look at the work of Alex

39:49.880 --> 39:55.080
here, which I highly recommend you check out. All of these things here are different CPPN

39:56.120 --> 40:01.000
represented networks that are doing deep visualization, which is the technique I'm

40:01.000 --> 40:05.240
going to tell you about later. So I encourage you to check that out. There's also, you can

40:05.240 --> 40:09.560
use CPPNs to encode neural networks. I did that a lot in my dissertation and now you can do that

40:09.560 --> 40:15.400
with Backprop. David Ha has been pushing that and there's much more work in this vein. Okay,

40:15.400 --> 40:20.760
so getting back to QD, I think that I hopefully have convinced you that it has all of these nice

40:20.760 --> 40:26.360
properties, like a diverse set of high performing solutions that it produces, it has goal switching,

40:26.360 --> 40:30.920
and it allows you to kind of illuminate the entire search space and learn a lot about what's possible.

40:32.040 --> 40:36.200
Just quickly, I want to say that these ideas really have given us a lot of leverage on hard

40:36.280 --> 40:41.640
technical problems. So in this paper that we had in Nature, we use these ideas to have robots that

40:41.640 --> 40:46.040
could adapt to damage within one to two minutes to get up and continue on with their mission,

40:46.040 --> 40:50.920
even if they're extremely damaged. And then we also use these ideas behind the algorithm GoExplore,

40:50.920 --> 40:55.720
which you may have heard of, which completely solved the Atari benchmark suite, including

40:55.720 --> 41:00.760
solving really hard exploration challenges like mono zoom as revenge and pitfall. You can see all

41:00.760 --> 41:04.920
the previous attempts to solve this heartless game, which became kind of its own grand challenge

41:04.920 --> 41:09.240
of the field, do not perform very well. And then this is the difference once you start adding in

41:09.240 --> 41:14.200
these ideas from quality diversity algorithms. Ultimately, we ended up beating the human world

41:14.200 --> 41:20.920
record on this game. Oh, and as a quick little teaser, this paper was also recently accepted

41:20.920 --> 41:24.680
to a really nice journal. I can't quite tell you which one, but if I'll share that information

41:24.680 --> 41:28.280
on Twitter in the next couple of weeks, if you are interested to get the final version

41:28.280 --> 41:33.720
and the updated version of this paper. So I think QD algorithms are really interesting.

41:33.720 --> 41:37.480
I think the question that we should always ask though is what's missing where, you know,

41:37.480 --> 41:41.880
they're not yet open-ended algorithms. So the thing that I think is missing is that while these

41:41.880 --> 41:46.360
things can produce a large diverse set of interesting solutions within one domain,

41:46.920 --> 41:50.600
ultimately, their ability to innovate is constrained because they're stuck in this one

41:50.600 --> 41:55.160
particular setting that we put them in. But what we really want is these open-ended algorithms that

41:55.160 --> 42:00.680
just keep going and kind of generating wildly different solutions as they run. So traditionally

42:00.680 --> 42:05.080
in ML, we pick a particular challenge like Chester, Gro or Dota or Starcraft and we bang

42:05.080 --> 42:09.720
away on it for a while. But the intriguing possibility that I want all of you to consider

42:09.720 --> 42:14.760
today is could we create an algorithm that generates its own challenges and solves them?

42:15.640 --> 42:21.960
Just as nature arguably created the challenge or the opportunity of leaves on the top of trees,

42:21.960 --> 42:26.520
and then the solution to that challenge, which is giraffes or caterpillars that can eat them.

42:27.400 --> 42:31.000
So, you know, this kind of a thing might produce something that's interesting

42:31.000 --> 42:35.720
after a billion years. So our most recent work on this is in this algorithm called Poet,

42:35.720 --> 42:41.160
which is the paired open-ended trailblazer. And the idea here is that we're going to try to endlessly

42:41.160 --> 42:45.480
generate interesting, complex and diverse learning environments and their solutions.

42:46.360 --> 42:52.280
So the idea is again quite simple and you'll recognize it. It's basically we want to

42:52.280 --> 42:57.400
generate new learning environments and we're going to add them to this set of our population of

42:57.400 --> 43:02.680
environments if they're not too easy and not too hard for the current population of agents.

43:02.680 --> 43:05.880
And if they're novel, there's something about them that's unique and different.

43:05.880 --> 43:09.720
And then we'll optimize agents to better solve each of these challenges and we'll allow goal

43:09.720 --> 43:15.880
switching between them. So the example task that we used here is obstacle courses. So this little

43:15.880 --> 43:21.160
creature here has to run as fast as possible without falling over. And here's the general idea.

43:21.160 --> 43:24.920
You start with an easy environment. So first you have to make that encoding choice. How are you

43:24.920 --> 43:30.760
going to encode an environment on a parameter vector? Here we have things like the number of

43:31.320 --> 43:35.240
whether or not there are gaps, whether or not there are stumps, the ruggedness of the terrain,

43:35.240 --> 43:39.800
et cetera. So you can start with an easy one of those, which is maybe just flat terrain.

43:39.800 --> 43:44.600
And then you start having an agent, which has its own parameter vector. This is a neural network

43:44.600 --> 43:49.640
and is learning via RL to solve this task. And once it gets good enough on that task,

43:49.720 --> 43:55.160
then we copy phi 1, the parameter vector of the environment, to make phi 2. And then we'll try

43:55.160 --> 44:00.680
this agent via transfer and goal switching. It goes and it starts optimizing here. Now,

44:00.680 --> 44:05.400
we are simultaneously continuing to optimize this parameter vector on this environment and this

44:05.400 --> 44:11.240
parameter vector on this environment. We keep going. Maybe eventually this environment gets

44:11.240 --> 44:16.920
solved well enough by this parameter vector. So we copy it and we now make phi 3 a new environment.

44:17.000 --> 44:23.000
Turns out that's too hard for either theta 1 or theta 2. So we throw that out. We generate,

44:23.000 --> 44:28.200
we try again, we get a new environment and we test this one and this one. We take the better of those

44:28.200 --> 44:33.640
to you on this new environment to seed training. And in this case, it was theta 2. So it goes in

44:33.640 --> 44:38.040
there. This does not have to be a linear chain. At any point, any one of the environments in the

44:38.040 --> 44:43.800
set can produce a new environment. And then we'll try all of the current agents on that environment

44:43.800 --> 44:49.160
to see if they're the best and if they are, they get to start. And the process can keep going like

44:49.160 --> 44:54.040
this. Now, imagine eventually we generate a really, really hard challenge like phi 6 here.

44:54.600 --> 45:00.680
And initially the best parameter vector, we try all of them on this environment was theta 5. It

45:00.680 --> 45:05.640
was the best stepping stone. So we start optimizing a copy of theta 5 in this environment and it gets

45:05.640 --> 45:09.960
better and better and better. But it maybe hits a local optimal and it can't break through and

45:09.960 --> 45:14.440
really, really do well on this environment. But in the meantime, we're still optimizing theta 4 on

45:14.440 --> 45:19.080
this environment. Maybe it has an innovation that makes it better on this environment. So it invades

45:19.080 --> 45:24.040
this environment, just like a species in nature could invade a new niche, kicks out that parameter

45:24.040 --> 45:29.480
vector. And now we start building on the back of this innovation here. And then that maybe with a

45:29.480 --> 45:34.040
little bit more optimization comes up with an innovation that then transfers in and becomes

45:34.040 --> 45:38.760
the best thing we've ever seen on phi 6. And maybe that gets us off the local optimal and solves that

45:38.760 --> 45:45.000
problem. So that is kind of the nature of goal switching. So here we use evolution strategies,

45:45.000 --> 45:52.440
but any RL algorithm would work. And you can see this little agent here. And it is traversing this

45:52.440 --> 45:57.960
course. And what you can see is at the beginning, all of the challenges are quite simple. They're

45:57.960 --> 46:04.440
a little tiny stumps, little gaps, just a little ruggedness in the terrain. But over time, the

46:04.440 --> 46:10.040
agent gets better and better. And the environments automatically start getting harder and harder.

46:10.040 --> 46:18.120
So it's kind of like a natural curriculum generation. And you can still, the algorithm

46:18.120 --> 46:23.400
is here is kind of still pushing in separate dimensions, like taller gaps or more ruggedness

46:23.400 --> 46:29.960
or wider gaps. Sorry, I didn't tell her stumps. Later in time, with more training, the algorithm

46:29.960 --> 46:34.680
starts to put together these challenges. Sorry, my dog is barking. So you get things like bigger

46:34.680 --> 46:40.120
gaps and stumps and ruggedness all put together. And ultimately, these environments get really,

46:40.120 --> 46:46.840
really, really difficult for this little robot to traverse. Here's another challenge that was

46:46.840 --> 46:53.400
invented and solved by this algorithm. So I think from an aesthetic point of view, it's kind of cool

46:53.400 --> 46:57.800
because you can think about each one of these robots as its own little creation. It's kind of a

46:57.800 --> 47:03.240
curiosity. Just like animals in the world, we love to watch nature shows and see different animals

47:03.240 --> 47:07.560
and how they're different and what they can accomplish and how their bodies are different,

47:07.560 --> 47:12.040
et cetera. So you can kind of think of the agents produced by these things as really interesting

47:12.040 --> 47:16.920
aesthetic artifacts. Scientifically, we wanted to see whether or not goal switching in this

47:16.920 --> 47:21.000
domain was paying off. And so we did direct optimization in each one of these environments

47:21.000 --> 47:25.880
and found that it failed miserably. That's down here. And with Poet and the goal switching,

47:25.880 --> 47:30.600
what you see is much, much better performance in each one of these environments. This is the only

47:30.600 --> 47:36.360
way that we know of to go solve these hard problems. And in the paper, there's more of a

47:36.360 --> 47:41.400
detailed study about that claim if you're interested. So I want to show you one anecdote of what popped

47:41.400 --> 47:45.480
out in the system. So I think it's so interesting. So here in the simplest possible environment,

47:45.480 --> 47:49.880
a flat ground, you get this agent here that is optimized for a really long time and it's got

47:49.880 --> 47:56.600
this knee-dragging behavior. And eventually, the system generates a permutation of this

47:56.600 --> 48:00.600
environment, which is a harder challenge that has little tiny stumps. And this knee-dragging

48:00.600 --> 48:05.720
behavior is not very good because it keeps tripping up on these little stumps. So with

48:05.720 --> 48:11.400
some more optimization in that environment, the agent learns to stand up and it gets faster at

48:11.400 --> 48:15.880
that. Now, because the algorithm is always checking any solution to see whether or not it's better

48:15.880 --> 48:21.560
at invading some other niche, this descendant actually goes back automatically and invades that

48:21.560 --> 48:27.160
flat ground, replacing this knee-drager. Now that it knows how to stand up, as you can see here,

48:27.160 --> 48:32.760
it gets much better performance in that new environment. And then with further optimization,

48:32.760 --> 48:37.160
it ends up with much better performance. Now, because this is a computational system,

48:37.160 --> 48:41.960
we could do the counterfactual. We went back to this original agent in the top left and we optimized

48:41.960 --> 48:47.400
it for an equal amount of computation in that flat ground environment. And it just never learns to

48:47.400 --> 48:53.160
stand up. It's just on a local optimal and it's stuck in its ways. It was only by going into a

48:53.160 --> 48:59.000
harder environment and coming back that it learned a better behavior and a better strategy. And this

48:59.000 --> 49:03.560
is why I think that it's so hard to design curricula. You would never, as a human, say that you're

49:03.560 --> 49:08.040
going to take something to a harder environment just to have it solve a simpler environment.

49:08.120 --> 49:11.240
But in this case, that's exactly what was needed to solve this problem.

49:12.520 --> 49:18.440
So we go through a quantifying algorithm that goal switching is essential to solve the hardest

49:18.440 --> 49:24.840
challenges generated by this system. So future work in this domain, I think there's all sorts of

49:24.840 --> 49:31.480
stuff you could do. Obviously, you could just take it into more complex rich simulators. So,

49:31.480 --> 49:36.360
you know, you could have more complex encodings as well. But here is like the world's from deep

49:36.360 --> 49:42.040
mind. But I think it's really kind of pumps my intuition is to watch, you know, what's possible,

49:42.040 --> 49:46.680
what will be possible in the future with more computation. Like imagine what Poet could do

49:46.680 --> 49:51.480
in a world this complicated, where it has to do with flying creatures and climbing and talking

49:51.480 --> 49:56.840
to other agents, maybe negotiating trades in a market, you know, and if you were doing all of

49:56.840 --> 50:01.400
this, you know, what might pop out of the system, I think it's fascinating to consider, both from

50:01.480 --> 50:07.320
a static perspective and from a machine learning perspective. You also could optimize the bodies

50:07.320 --> 50:11.400
of the creatures themselves. So in the bottom in the right, you see, you know, I showed you some

50:11.400 --> 50:16.680
work that we did in that vein a while back, but not with Poet. And David Ha has done that in

50:16.680 --> 50:21.480
particular environments that are handcrafted. But imagine if you paired body optimization with

50:21.480 --> 50:25.160
environment generation, then you could really get weird things like you see in nature, where you

50:25.160 --> 50:29.320
have a particular kind of like cave dwelling spider that's optimized to that environment,

50:29.320 --> 50:33.640
which is very different from birds that are flying up in the Pacific Northwest.

50:34.600 --> 50:37.800
So another thing that I think would be interesting would be to combine innovation

50:37.800 --> 50:43.400
engines with modern tools. So imagine if you took something like Dolly, which is this amazing

50:43.400 --> 50:49.560
new thing produced by my colleagues here at OpenAI. And not only did you have humans asking for

50:49.560 --> 50:54.520
particular innovations or particular images from Dolly, but you have the algorithm invent the

50:54.520 --> 50:58.920
challenge and the solution. So the challenge could be, you know, can you create this? Can you create

50:59.640 --> 51:03.640
this? Dolly would then create them. And if they're interesting, you add it to a set. And then you

51:03.640 --> 51:07.720
have something that looks at the set of things that are already produced and produces completely new

51:07.720 --> 51:12.760
types of images. That would be awesome to see. And that doesn't have to be limited to images. You

51:12.760 --> 51:18.040
could use then the same technology to do it in different modalities, such as videos and music

51:18.040 --> 51:23.240
and poetry or algorithmic space. Again, the challenge that remains is how do you detect

51:23.240 --> 51:27.560
what's interestingly new? I'll throw it out there that I think you probably with a lot of data could

51:27.560 --> 51:32.520
learn a function of what humans consider interesting. In fact, if Joel remembers, I sent him a giant

51:32.520 --> 51:36.200
email saying that I think we should do this with his website, GanReader. We haven't done it yet,

51:36.200 --> 51:41.560
but it'd be a great project for a student to take on. So I want to quickly check the time here.

51:42.600 --> 51:46.760
Yeah. So we started a little bit late. So I'm going to race through this because I think you'll

51:46.760 --> 51:51.640
find it interesting, but I won't be able to go into any detail here. But part two of the talk,

51:52.520 --> 51:56.280
which I'll do very quickly, is I wanted to tell you about this entire other arc of research that

51:56.280 --> 52:01.560
we did called AI neuroscience, which is how much we want to study. Just like neuroscientists try to

52:01.560 --> 52:05.480
study the human brain, we want to study how much the deep neural nets understand about the images

52:05.480 --> 52:12.040
that they classify. So we're all familiar with deep neural nets, but they tend to be a black box.

52:12.040 --> 52:17.880
We don't really know what each neuron in the deep neural net does. But one way neuroscientists probe

52:17.880 --> 52:23.400
this question is they literally put probes into your neurons and they look for which neurons light

52:23.400 --> 52:28.120
up in response to which images. For example, they found neurons that light up in response to

52:28.120 --> 52:33.240
Kobe Bryant or Bill Clinton, for example. And people have called these things like a Kobe Bryant

52:33.240 --> 52:37.480
neuron, for example, and they respond to very different modalities, such as the name Kobe Bryant,

52:37.480 --> 52:42.200
a line drawing him in the Lakers uniform. The question is, you don't really know just because

52:42.200 --> 52:46.920
the response to those images, if it's a Kobe Bryant neuron, it could be an LA Laker neuron

52:46.920 --> 52:52.680
instead of a Kobe Bryant image neuron, for example. So we thought the ideal task would be to synthesize

52:52.680 --> 52:57.560
the images that maximally activate that neuron. And if you did that and you got these images,

52:57.560 --> 53:02.200
then you'd know, oh, that's a Laker neuron, not a Kobe Bryant neuron. But if you got these images,

53:02.200 --> 53:07.400
you'd know it's a Kobe Bryant neuron. So this is actually possible with artificial neural networks,

53:07.400 --> 53:12.120
but you can do is you can take a neural net and then you could have like an artist, an AI artist

53:12.120 --> 53:18.280
that's trying to generate an image to activate this particular neuron here. And what you can do is

53:18.280 --> 53:22.280
you can use backprop. So the artist generates an image and then you just follow the gradient to

53:22.280 --> 53:26.520
increase this neuron until you get an image that lights up that neuron, and it might look like this.

53:26.520 --> 53:31.000
And you can do the same technique for all the intermediate neurons in the neural net.

53:31.720 --> 53:37.000
We call this deep visualization. Our first attempt at this actually was that same paper,

53:37.000 --> 53:42.760
deep neural nets are easily fooled when we did it with CPPNs here or a direct encoding on the left

53:42.760 --> 53:48.440
here, or with backprop on the right, we got images that did not look at all like things that they're

53:48.440 --> 53:54.440
supposed to, but the neural net was perfectly sure is a peacock or chimpanzee. And you know what

53:54.440 --> 53:59.240
happened with that paper. We then went on and started asking questions like why are these neural

53:59.240 --> 54:03.800
nets easily fooled? And I don't have time to get into a lot of the details here, but what we basically

54:03.800 --> 54:09.960
thought is that maybe deep neural nets do recognize the images they're supposed to like a lion or a

54:09.960 --> 54:16.040
dolphin, but maybe they recognize a whole lot of other things also as in that class unnatural images.

54:16.040 --> 54:21.800
So if we could stop the artist from generating unnatural images and only stay to the space of

54:21.800 --> 54:27.480
natural images, then we might find out what that neuron really is for and what it's been trained

54:27.480 --> 54:32.520
to see within the space of natural images. So skipping over some of the details here,

54:33.480 --> 54:37.880
the fooling work started out saying maybe these deep neural nets don't really understand at all

54:37.880 --> 54:41.880
what they're classifying. They're just locking on to spurious correlations like that there's a

54:41.960 --> 54:45.960
orange texture. If you see orange, you know, this kind of orange texture next to blue color

54:45.960 --> 54:50.680
of starfish, but they never learned like what a five-legged starfish is because they didn't

54:50.680 --> 54:54.840
need to to solve the problem. We wanted to see whether or not there is that notion of like a

54:54.840 --> 55:00.120
five-legged starfish in the network. So in take two, what we tried to do is we added more manual

55:00.120 --> 55:05.720
priors to try to constrain the image generator, the artist, to generate only natural images. And

55:05.720 --> 55:11.000
when we add that extra constraint, then we get images, you know, previously people had done that

55:11.000 --> 55:17.640
and they kind of looked like this. You start to see dumbbells and dolomations. These are the

55:17.640 --> 55:22.120
ones that we got with slightly better priors. And you can start to see that the network does

55:22.120 --> 55:27.080
actually kind of know what a flamingo is or a beetle. It's an interesting historical side note.

55:27.080 --> 55:32.120
These images here in this work inspire deep dream, which is also done by Alex over at Google.

55:32.120 --> 55:37.560
And that stuff is super cool if you haven't seen it. And then third take, we tried to add even

55:37.560 --> 55:43.880
better priors, manually designed priors, and what you get are these images here. And I want to stop

55:43.880 --> 55:48.120
for a moment and kind of reflect on this from an aesthetic perspective. We're trying to do better

55:48.120 --> 55:54.360
and better science. We're creating different algorithms or different hand-coded priors to

55:54.360 --> 55:59.400
kind of accomplish the scientific quest. But if you look at the different images, each one of them

55:59.400 --> 56:04.200
has a different style. And I think it's kind of interesting that like slight tweaks to algorithms

56:04.200 --> 56:08.680
produce wildly different artistic styles. It's like all these different artists are out there

56:08.680 --> 56:11.960
and you just kind of are searching through the space of artists kind of accidentally

56:11.960 --> 56:16.040
while you're doing your science. So this style is very different from this style. And I actually

56:16.040 --> 56:20.360
think this is just really beautiful. Like if I saw this in an art museum, I would think that this

56:20.360 --> 56:24.120
is beautiful art, even though it was produced purely for scientific reasons and we had no

56:24.120 --> 56:29.720
intention of producing images in this style. We then went on for one more take at this. We tried

56:29.720 --> 56:35.800
to say, okay, we're machine learning researchers instead of manually encoding what characterizes

56:35.800 --> 56:40.440
a natural image. Let's learn it. And so we start learning the natural image priors and our papers

56:40.440 --> 56:45.080
are full of lots of details on this. And the way that we do this, we have a generator kind of like

56:45.080 --> 56:50.520
the generator in a GAN. We hook it up to the target network we're interrogating. And then we try to

56:50.520 --> 56:54.760
search in a latent code to produce an image that activates a certain neuron in question.

56:55.400 --> 57:00.280
And when we did that, we got these images, which at the time were some of the most realistic images

57:00.280 --> 57:05.880
deep neural nets had ever produced. You were seeing realistic lawnmowers and lemons and barns

57:05.880 --> 57:12.360
and candles. These images are not great by modern standards, but this is 2016. Here are other images

57:12.360 --> 57:18.120
in this class. And for the first time ever, the images were starting to look photorealistic.

57:18.120 --> 57:22.200
Like these are the synthetic images for this class. And these are the real images.

57:22.200 --> 57:25.960
And, you know, I don't think that you would really be able to tell the difference if I had swapped

57:25.960 --> 57:31.640
them unless you look very carefully. So compared to the best work at the time, which is on the left,

57:31.640 --> 57:38.040
these images were a big step up. And they helped us confirm this hypothesis, which is basically,

57:38.040 --> 57:41.800
if this is the space of natural images, these networks do understand what it means to be a

57:41.800 --> 57:48.520
lawnmower. Like if this blue line here is the class of lawnmowers, then they do stay to, if you

57:48.520 --> 57:53.480
keep them in the natural, if you only generate images in the natural image space, then you do

57:53.480 --> 57:58.360
get a lawnmower. But if you let it generate images anywhere in the space, like all the way out here,

57:58.360 --> 58:03.080
then it also, the network will similarly say this garbage here is in the class of what it

58:03.080 --> 58:07.400
means to be a lawnmower. And so if we want for aesthetic purposes to have neural nets generate

58:07.400 --> 58:13.000
realistic stuff, we got to get it focused on something that both is natural and activates

58:13.000 --> 58:17.720
the network's classification as opposed to way out here. And GANs do this also, but they do it

58:17.720 --> 58:22.680
via a very different mechanism. So I told you, you could look at each individual neuron within

58:22.680 --> 58:27.320
the network. I don't have time to go through this now, but if you're interested, then I encourage

58:27.320 --> 58:31.080
you to kind of go into the paper and look, you could kind of fly around the neural net and see

58:31.080 --> 58:36.200
that you get things like cargill grill detectors and buckets and bird heads. And as you go up in

58:36.200 --> 58:40.680
the network, you get these really weird concepts like one-eyed turtles and like arches over water

58:40.680 --> 58:45.080
until you eventually get the class neurons where we know what they are because we've grounded them

58:45.080 --> 58:50.120
via our labels. The one final thing I'll mention here is that the one problem with our technique

58:50.120 --> 58:55.800
is that it generates very, very little diversity. So these are synthetic images produced by our

58:55.800 --> 59:01.560
network for this class. And they look a lot like the images that most highly activate that neuron

59:01.560 --> 59:06.920
from the real world from the real data set, but they don't represent the diversity of images in

59:06.920 --> 59:12.520
that class. And so we did a lot of work, including adding with Yashua Benji on these things called

59:12.520 --> 59:17.160
plug-and-play generative networks, where we wanted to add a lot more diversity. And so you could

59:17.160 --> 59:21.000
take the same network and you can light up a bunch of different classes that it's never even seen

59:21.000 --> 59:25.480
before. That's a bit of an aside like ballrooms and art galleries, but mostly we were interested in

59:25.480 --> 59:31.800
getting more diversity. And the takeaway message is we were able to accomplish that. So here is PPGNs,

59:31.800 --> 59:36.200
which is the one that has more diversity. And you can see a much more diversity in this set of

59:36.200 --> 59:42.440
images versus DGNAMV1, which are the images over here. And this diversity better represents

59:42.520 --> 59:47.720
kind of the diversity of the natural class. So with the original attempt, DGN, you got volcanoes

59:47.720 --> 59:52.360
that look like this. It kind of goes and finds one type of volcano, like a local optima, and it

59:52.360 --> 59:57.400
sits on it. But the plug-and-play generative networks are much more kind of like an open-ended

59:57.400 --> 01:00:02.200
algorithm, at least within this class, where it samples new versions of volcanoes over and over

01:00:02.200 --> 01:00:08.600
again. And so you get all this big diversity of volcanoes out of this new sampling technique.

01:00:09.320 --> 01:00:14.600
So to conclude this, the AI neuroscience part, I won't actually get into these details, but it

01:00:14.600 --> 01:00:19.160
taught us a lot about what neural nets, you know, what's going on inside neural nets, it taught us

01:00:19.160 --> 01:00:24.120
whether or not they really recognize and learn about the concepts in our world. Like we did find

01:00:24.120 --> 01:00:28.120
in the end that they do know what a volcano is, and you know the five-legged nature of a starshow,

01:00:28.120 --> 01:00:32.760
and what a lawnmower is, even though they also are susceptible to producing and recognizing

01:00:32.760 --> 01:00:37.800
these adversarial fooling images as being part of the class. And it was cool to see the rapid

01:00:37.800 --> 01:00:44.520
progress just within my own team of collaborators from 2015 to 2017. And since then, I highly

01:00:44.520 --> 01:00:50.200
recommend the work of Chris Ola, who's continued to push in this direction. And very, very soon,

01:00:50.200 --> 01:00:55.240
Gabriel Go and Chris and others have new work coming out of OpenAI that will blow your mind.

01:00:55.240 --> 01:01:00.200
So I encourage you to watch the OpenAI blog in the coming weeks for this new result that you

01:01:00.200 --> 01:01:05.560
really like. You could do all of this stuff in different modes, like speech and video, etc.

01:01:05.560 --> 01:01:08.760
I won't dive into this. I want to just highlight one thing. This is my future work slide all the

01:01:08.760 --> 01:01:13.640
way back in 2016, and I thought it would be awesome to do this with real animal brains.

01:01:16.680 --> 01:01:20.280
Since then, actually, somebody has done that. They took our algorithm for DGN,

01:01:20.280 --> 01:01:24.120
they applied it to a real monkey brain, and they synthetically are generating images that activate

01:01:24.120 --> 01:01:28.600
neurons within the monkey brain, specifically within the face recognition part of the monkey

01:01:28.600 --> 01:01:33.720
brain. And you do in fact get a synthetic monkey-looking face, which is pretty amazing.

01:01:33.720 --> 01:01:38.760
So to conclude my overall talk, I think innovation engines are really interesting because they kind

01:01:38.760 --> 01:01:44.200
of push on this question of can we automatically produce an open-ended creative process that in

01:01:44.200 --> 01:01:50.120
any sort of modality like art or music or invention will just endlessly generate interesting new

01:01:50.120 --> 01:01:54.280
things. We've got a long way to go to accomplish that goal, but my colleagues and I, like Ken Stanley

01:01:54.280 --> 01:01:58.360
and Joe Layman and myself are really, really focused on this goal and trying to pull that off,

01:01:58.360 --> 01:02:04.280
including now at OpenAI, where all those people are. And I also showed you very, very quickly some

01:02:04.280 --> 01:02:07.720
of our work in AI neuroscience, which we were doing for scientific reasons, but produce these

01:02:07.720 --> 01:02:11.800
interesting aesthetic artifacts. And I'll just leave you with one final thought, which is that I find

01:02:11.800 --> 01:02:16.440
it surprising how often science produces aesthetic artifacts. Almost none of the work that I was

01:02:16.440 --> 01:02:21.720
doing was trying to do it just for aesthetic purposes, but along the way, it produced these

01:02:21.720 --> 01:02:26.440
things that I think are beautiful and interesting, and could be kind of aesthetic artifacts in their

01:02:26.440 --> 01:02:29.960
own right. And so I think it's nice because you don't have to choose between being an artist and

01:02:29.960 --> 01:02:34.840
a scientist. You kind of kind of can do both nowadays, especially with the modern tools and

01:02:34.840 --> 01:02:39.160
machine learning. And I'm sure that's kind of a realization that is being reinforced over and

01:02:39.160 --> 01:02:43.480
over again with all the different lectures in this wonderful class that you are participating in.

01:02:43.480 --> 01:02:47.800
So with that, I want to say thank you, and I'll turn it over to either questions or Joel, depending

01:02:47.800 --> 01:02:55.080
on what you want to do, Ali. Thank you so much. I appreciate it. It was really interesting and

01:02:55.080 --> 01:03:02.840
inspiring to me, and I'm sure for many of us in this class, this comment that you also made about

01:03:02.840 --> 01:03:11.720
science and creating and art, I think that it also is very well aligned with some of the other

01:03:12.280 --> 01:03:17.560
insight that we learned from other speakers. For instance, Alyosha, of course, was mentioning that

01:03:17.560 --> 01:03:23.560
when I asked this question, he was mentioning that he also thinks that, you know, creativity is

01:03:23.560 --> 01:03:30.360
a different tier of our evolution. So that really resonated with me what you were talking today.

01:03:31.880 --> 01:03:42.520
And I think that this is very exciting for us. One question that I have is if students want to,

01:03:43.560 --> 01:03:50.280
because this is a very interesting topic, and especially that type of poet or open-endedness

01:03:50.840 --> 01:03:59.720
area, if a student wants to join you in this sort of mission, what do you recommend to them to work on?

01:04:01.320 --> 01:04:06.840
Yeah. So one thing I would recommend is we had an ICML tutorial, I think about a year ago, that

01:04:06.840 --> 01:04:13.160
really covered a lot of this work in more depth. It's an ICML tutorial on population-based methods.

01:04:13.160 --> 01:04:19.560
So then you can see, can Joel and myself kind of going through, this is Joel Lehmann, not Joel Simon,

01:04:19.720 --> 01:04:25.480
going through a lot of the work that we've done in this field. And I recommend reading a lot of the

01:04:25.480 --> 01:04:30.920
work of both Ken and Joel, as well as you can look into some of the work that we've done in this area.

01:04:30.920 --> 01:04:35.480
And then in terms of what I recommend you work on, there's so many things, it's like,

01:04:35.480 --> 01:04:40.760
there's so many options that it's fun. You could apply a lot of these algorithms in a new domain,

01:04:40.760 --> 01:04:47.080
for example, that you find interesting, you know, a new kind of art. You could take more modern tools

01:04:47.080 --> 01:04:52.120
that work really well and weave them into these ideas, or you could invent new ideas, you know,

01:04:52.120 --> 01:04:57.560
like I still think if people, if anyone out here can crack the question of how can you automatically

01:04:57.560 --> 01:05:04.520
recognize newly interesting things, that I think is like a Turing award-winning innovation that will

01:05:04.520 --> 01:05:11.160
catalyze and propel so much algorithmic advance, including potentially advancing our push to

01:05:11.160 --> 01:05:16.200
artificial general intelligence. Like that might be one of the key stepping stones that gets us there.

01:05:16.200 --> 01:05:19.880
So I have this paper called AI Generating Algorithms, which I recommend people check out if

01:05:19.880 --> 01:05:25.080
they're interested. And it basically talks about how these sorts of ideas may do the fastest path

01:05:25.080 --> 01:05:32.120
to produce general AI. So that's not an aesthetic quest, it's more of a scientific quest. And but

01:05:32.120 --> 01:05:35.800
if you're interested in that, I think that's fascinating. But I also just think, just literally

01:05:35.800 --> 01:05:40.840
take all these ideas and go like do Poet, but do it in some totally wild and crazy different domain,

01:05:40.840 --> 01:05:46.440
or do an innovation engine in, you know, like architecture or poetry and see what happens,

01:05:46.440 --> 01:05:52.120
you know, you can use new tools like GPT-3 or Dolly, etc. So I think there's just a lot of

01:05:52.120 --> 01:05:58.120
low-hanging fruit here to be explored. Certainly. And that also reminds me of what you mentioned,

01:05:58.120 --> 01:06:05.320
we didn't optimize to create a microwave. We explored different things and I think that

01:06:05.320 --> 01:06:12.440
your advice is quite in that direction. Also, Joseph has a question. Joseph, would you like to

01:06:13.880 --> 01:06:21.080
ask it yourself or? I wasn't able to get my mic working earlier. Let me just

01:06:22.280 --> 01:06:30.360
fix that. Hi, Jeff. I was just wondering if you've explored anything on Poet in multi-agent settings

01:06:30.360 --> 01:06:35.240
to this point. Yeah, the short answer there is that we have a lot of really exciting ideas.

01:06:36.120 --> 01:06:39.720
For how we want to take advantage of that. I can't share those specific ideas

01:06:40.760 --> 01:06:45.800
because we may or may not be working on them. But I also think in the spirit of the talk that

01:06:45.800 --> 01:06:51.320
the best way to make advances is to have a community of people with different ideas pushing

01:06:51.320 --> 01:06:55.560
different directions because you never know what's going to unlock. So I almost don't want to give you

01:06:55.560 --> 01:06:58.760
too many ideas either because I don't want to cause conversion thinking. I think it's almost

01:06:58.760 --> 01:07:02.760
better if there's so many different ways you could apply the concepts of Poet to multi-agent

01:07:02.760 --> 01:07:08.280
settings that I don't think you can go wrong. I think if many different people and groups push

01:07:08.280 --> 01:07:13.880
on that, really good things will happen. Fair. We also may or may not be working on that, right?

01:07:16.760 --> 01:07:21.800
The one thing I wanted to ask you specifically about that is whether you figured out one,

01:07:21.800 --> 01:07:27.880
maybe you can't tell me, but any way to get around the problem where in multi-agent settings,

01:07:27.880 --> 01:07:33.800
sometimes you don't have a single evaluation metric that correlates the environment difficulty

01:07:33.800 --> 01:07:38.840
with agent performance because you add more agents in, well, then the performance goes down

01:07:38.840 --> 01:07:42.920
because there are more of them and they're all doing smarter things. So that sort of thing has

01:07:42.920 --> 01:07:48.920
thrown a wrench in the whole annex measure. Yeah, that's right. So one of the things you could switch

01:07:48.920 --> 01:07:57.240
to is a notion of agent versus agent. Like if an agent is as opposed to doing better on that

01:07:57.240 --> 01:08:03.480
environment, it's that agent versus other agents or agents that have come before. Another thing

01:08:03.480 --> 01:08:07.960
you could do is you could switch to more of a learning progress metric, which is if they're

01:08:07.960 --> 01:08:16.200
getting better, are they learning? According to some measure, like does their value function,

01:08:17.480 --> 01:08:22.120
their prediction of how well they're going to do, is that wrong? It's because they were either

01:08:22.120 --> 01:08:25.880
better or worse in that situation and versus those opponents than they thought they were,

01:08:25.880 --> 01:08:30.440
and measures like that could really catalyze, recognizing this is still an interesting environment

01:08:30.440 --> 01:08:33.800
because they're learning. This is still an interesting matchup between this opponent and

01:08:33.800 --> 01:08:38.040
this opponent because they're learning. I mean, we've been actually trying to do something very

01:08:38.040 --> 01:08:44.440
similar there. It still seems to run into the same sort of issue though, right? If you can't

01:08:44.440 --> 01:08:48.840
measure absolute performance, it can still be difficult to then measure relative performance

01:08:48.840 --> 01:08:54.440
because your reward peak can be going down even if you are learning because so are all the other

01:08:54.440 --> 01:08:59.240
agents. Sometimes you have to run as fast as you can just to remain in the same place.

01:08:59.800 --> 01:09:08.920
Yeah, pretty much. That's the red queen quote from Alison Wonderland. Yeah, these are all challenges

01:09:08.920 --> 01:09:12.200
and it's the kind of challenge that happens once you get into the multi-agent setting.

01:09:12.200 --> 01:09:16.600
So I think this is just for a lot of experimentation and hard thinking has to happen. I don't think

01:09:16.600 --> 01:09:22.120
there's a really super, short, easy, obvious answer. It's just going to require research.

01:09:22.120 --> 01:09:26.280
Well, I mean, I look forward to seeing what setting it is that you're trying that out in

01:09:26.280 --> 01:09:29.480
whenever that gets published. Likewise, yeah, with your work.

01:09:31.960 --> 01:09:37.480
Thanks. Excellent. Are there questions? Any more questions?

01:09:45.400 --> 01:09:51.480
Guys, don't be shy. If you have questions, just go ahead. Of course, if Jeff has time.

01:09:52.360 --> 01:09:56.360
I have time. I just also want to be cognizant of Joel and giving him his proper time.

01:09:57.960 --> 01:10:07.640
Excellent. Okay, cool. Thank you. All right, then let's thank you again, Jeff. It was really,

01:10:07.640 --> 01:10:09.320
really interesting and inspiring.

