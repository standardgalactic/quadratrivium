start	end	text
0	7840	Hello everyone, welcome to your course, AI for Art, Aesthetics and Creativity.
7840	18880	Today we have a very special speaker, Prof. from OpenAI, and he's going to talk about
18880	29760	creating art and artistic work and images in general, these diffusion models and probably
29760	37240	you have already worked with the glide collab, so he's going to walk us through that as well.
37240	45880	So let's get us started, Prof. I always ask if please you can share with us what motivates
45880	51880	you working in this space and also giving us a little background about yourself.
51880	57880	For sure, thanks for having me here today, by the way this is really exciting.
57880	67880	Yeah, so a background about me, I was an undergrad at MIT in computer science and math and then after that,
67880	73880	I came to OpenAI to do AI research and I've been here for five years doing research on unsupervised
73880	81880	learning, generative models, all kinds of things and what motivates me to do this research.
81880	91880	When I was in college, I was excited by the idea of trying to understand what makes humans intelligent
91880	99880	and I think I attended a few talks, which were really amazing and I felt like there's a lot of
99880	103880	amazing progress happening in this field and I just wanted to part of it, see what's happening, see what
103880	109880	I could contribute and then one thing led to another and here I am.
109880	119880	I think so far, wouldn't say we are very close to unraveling what makes humans intelligent,
119880	127880	but we've made a lot of progress I think in these years, so it's been pretty fun.
127880	133880	Cool then, so I'll just get started.
133880	139880	And anyone, feel free to just ask any question at any point, pause me if anything feels confusing,
139880	147880	if any notation is understood. I don't see the chat window on my screen directly, so if you could just
147880	153880	directly tell your question, that would be easier or if Ali, if you see something in the chat, just let me know.
153880	157880	Cool, I'll get started.
157880	165880	So I'll begin by just showing a few examples of very powerful creative ML models from the past few years.
165880	173880	The first one you all might have already seen in news GP3, the language model from OpenAI.
173880	179880	And one example I'm showcasing here is like these language models.
179880	190880	They show like a very few examples of something pretty simple like here, like on the left you see examples of like poems by specific black writers.
190880	196880	And on the right, then you can see once the model has seen examples of this kind, what it can generate.
196880	202880	And it's getting poetry from just a few examples. This is pretty crazy.
202880	205880	There's a second model I'll show you next.
205880	208880	This is the audio playing.
211880	214880	Yeah, we can hear your audio.
236880	240880	You may bring it, and that's it.
240880	265880	Anyhow, so that was a sample from a model for generating music called jukebox.
265880	273880	And everything here was generated from the model, the music, the singing, how to sing it, how to pronounce the lyrics and everything.
273880	278880	All the model was given was the lyrics and an artist and it produced all of this by itself.
278880	285880	Does the generative model like produce the music and like the sentence separately or together?
285880	294880	Everything together. Yeah, so because kind of how you sing something kind of has to go with the music that's provided by Swasa, right?
294880	299880	It's kind of hard to like generate them separately from each other.
299880	301880	What was that your question?
301880	307880	So I can read from the chat that people are getting excited.
307880	313880	Someone has a loud and other is saying this is freaking awesome.
313880	316880	Thank you.
316880	321880	Share or talk if you like.
321880	323880	Oh yeah.
323880	328880	Sorry, I can't see the chat window so feel free to just talk.
328880	333880	Yeah, when we heard samples from like that from these models we were also amazed.
333880	347880	The model I have here is the slide model you guys might have seen in papers. And here you have a model that given a text prompt is generating a visual representation of it or whatever it imagines what that the text kind of signifies.
347880	362880	So you could see, and these are things that are go back to your point Ali you made earlier about composition. These things involve a model really having to compose a lot of different concepts together like robots meditating in a way past the retreat, but it is able to imagine this.
362880	377880	In the last few years I think like ML models for such very hard creative tasks have become really good. And today we'll see like what are some of the kind of concepts driving this progress.
377880	393880	And so before I even start down that route, like why are we trying to, you know, from a research perspective like trying to train models that you know create things. Well, one concept here is that, you know, this as this code by Feynman says what I cannot create I cannot.
393880	412880	I don't understand training models that can, you know, create things be images or your video and so on. It's kind of one of the hardest tasks in those domains. And if you really care about whether models can understand images audio video so on, then one of the best ways to know
412880	421880	if you're making progress out of these models are really learning something advanced is to see if they can create really complex things and really hard to understand things.
421880	430880	And for people who care about representation learning or something this is one, one way you can know you're making progress on such stuff.
430880	445880	And there has been a lot of progress in this field of, you know, trying to create things from models or what we call generative modeling. So here you see just in this very small domain of phase generation, things that GANs could create in 2014, versus things that they can create in
445880	452880	2018, like, it's absolutely astounding how much progress has happened in the past few years.
452880	474880	So, what is a generative model. So, you can think of what our inputs here in our data set to look like just a collection of examples, x1, y1, x2, y2, xn, yn, where x here represents, let's say an image and why some label or some other information describing this image.
474880	482880	So you just have the sample from some natural distribution of images, p of x comma y.
482880	496880	So you could have like images of corgis, ostriches, goldfishes and so on. You want to train a model that can learn this distribution you want to train a model that then ask for a corgi produces a corgi and ask for an ostrich produces an ostrich, or so on.
496880	508880	You want to learn p of x given y, given some label y, corgi, ostrich, goldfish and so on. Can I generate a real image or an image that looks real from this distribution.
508880	514880	And one such a model is trained, you can use it to generate novel samples.
514880	524880	So you can generate corgis, ostrich, goldfishes that are actually real haven't been seen before but look like real images.
524880	534880	One of the things I guess that matters is, is how you evaluate such models because if you if you don't have evaluation metric you can't tell you're making progress.
534880	547880	And we won't go into too much detail here about these metrics but one of the metrics use was FID for measuring image generation and what these metrics are trying to capture is like fidelity and diversity.
548880	559880	Fidelity would mean like how realistic or how correct an image looks versus diversity would be like how many different kinds of images such a model can generate.
559880	574880	And so GANs were kind of like the state of the art for difficult image generation benchmarks before diffusion models came along which we will not talk about in our talk today.
574880	584880	The progress in diffusion models has been pretty recent, it's been just like the last couple of years there's been a lot of papers and even in these people that you could see like things have been improving since 2020.
584880	592880	And you could now generate realistic faces, you know, lots of different categories of images from ImageNet and so on from these models.
592880	608880	So it's a pretty exciting field and these models in one of our recent papers we showed them to be actually better than GANs at generating images and so I'm pretty excited by these models and that's what I'm going to cover today.
608880	616880	There's quick graphic here for like how things look like when diffusion models generate an image.
616880	619880	Let me just play it again.
619880	624880	So let's go to what these models are.
624880	636880	As you saw in that graphic, you could see that that image was started out looking like noise and you finally got a real image out by like the slow process of noise converting to an image.
636880	651880	And what is actually happening behind the scenes here is you have a fixed process that adds noise to a training image. So let's say you start with X0 on the left here as an image.
651880	654880	So that's just a dog ball on the left.
654880	670880	So a fixed process that slowly adds Gaussian noise to this image. So at each step you add a little amount of Gaussian noise. And as you go from left to right by the end, at the last time step B, you have just pure noise left.
670880	682880	And what the model is trying to learn is to undo this process. It's trying to reverse it. It's trying to take some noise damage and be noisy a little bit, make it a little less noisy and so on.
682880	695880	How do you obtain a generative model out of this? Well, if you train a model to reverse noise like this, then at test time when you actually want to use the model, you could start with pure noise at the end.
695880	704880	You could start with XT. Then you could run it step by step backwards to remove noise from it and try to produce an image from it.
704880	711880	Any questions on this diagram?
712880	720880	Okay, I'll just check the chat to throw the question there.
720880	724880	Okay, no questions.
724880	741880	Okay, so let's remember the notation from your X0 is an example from the dataset, XT, capital T, XT is noise and there's intermediate steps, X little t's, we call them, where you have like some slightly
742880	758880	noise image. And we can, to introduce more notation here, you could represent one step of the forward noising process with a distribution Q of X little t, given X little t minus 1.
758880	770880	And right now, I'm going to use Gaussian noise as a noising process. So we're going to add a little bit of Gaussian noise to this.
770880	785880	And the thing about here is this in this notation, there's some mean, which is centered around the original noise damage XT minus one, and there's some variance one minus alpha T here of how much noise that is being added to this image.
785880	796880	So this is the forward process. This is the process that adds noise to images Q of XT given XT minus one. What we are learning is the reverse thing. We want to denoise this image.
796880	804880	So we were learning P of XT minus one given XT. And what you can show is for very small
806880	815880	noising steps where the amount of noise added is very tiny. The reverse process kind of looks like the forward process.
815880	824880	This is kind of a set of points. Maybe I'll go in a little bit of an example here. Let's say, looking at a single pixel here, it had some real value on the real line, let's say
826880	836880	0.8. And then you added a tiny amount of Gaussian noise to that thing. So it became 0.81 or 0.79 or so, depending on what noise you sampled.
836880	845880	Now you're given this new value 0.79. This is the noise value. And you want to predict the distribution of what could have been the value it came from.
845880	856880	If the amount of noise added, that you added in your step was very tiny amount of Gaussian noise, then the reverse prediction also looks kind of like a Gaussian.
857880	867880	So it looks like, oh, it's somewhere around 0.79, some distribution that where you came from. I mean, 0.8 is pretty close to 0.79 in this situation.
868880	881880	And so you could write that down as a model that is predicting the mean of this reverse process and the variance of this reverse process, mu theta being the mean and sigma theta here being the variance that you're trying to predict.
882880	888880	So far, so good. Any questions at this point?
895880	910880	Okay, so to summarize the notation again, XT minus one to XT is a process that's adding noise and the process we are trying to learn is XT to XT minus one to reverse this noise.
910880	918880	And this looks like a Gaussian in the forward direction and predicting a new Gaussian in the reverse direction.
920880	935880	A paper showed you could do some forms of training tricks to make this process simpler. You don't have to add noise little by little at every step. You could just directly sample an intermediate XT given your data example by just adding a lot of Gaussian noise to it.
936880	944880	And it also showed instead of trying to predict the mean of the reverse process, you could just directly try to predict what noise was added to the image.
946880	950880	This is possible because you could write the mean in terms of the noise that was added.
951880	971880	Trying to predict the variance can be just simplified to just using a fixed variance or a learnt variance. We won't go into that today. All you should get from this is that to predict the reverse process where you are trying to predict the mean and the variance of the Gaussian to reverse that
971880	976880	noising process, it's enough to try to predict what noise was added to the image.
978880	993880	So how does this look like when you are actually training these borders? You take an image X0, you sample some random noise, you sample some Gaussian noise and you just combine these two to produce a noised XT.
994880	997880	There's a formula here of how we've combined them.
998880	1014880	You can think of this combination as something that is kind of like interpolating between the image and the noise. So at t close to zero, you should just get the image X0 and t close to capital T, you should get complete noise.
1015880	1025880	And this kind of interpolation factor, alpha t bar, kind of plotted it here, it goes from like one near t equals zero to zero near t equals capital T.
1026880	1031880	This kind of controls how you interpolate between a fully denoised image versus a fully noised thing.
1032880	1039880	And at training time, you're just sampling all possible combinations of mixing of noise and image and you're trying to denoise all these combinations.
1040880	1051880	So what is the model trying to do now? It's trying to predict, as we said in the earlier slide, it's trying to predict what noise was added into the image.
1052880	1067880	So you take in the noised XT, you take in what time step or kind of like an indication of where in the process you are, you tell the network, hey, I am at this step in the process, this is my noised image.
1067880	1071880	What noise was possibly added to this image? So it's trying to predict epsilon.
1072880	1089880	And what it's being used to train with is just like simple L2 loss, like just take the mean squared error of the difference between the network's prediction and the actual noise that you trained with and you try to minimise this loss so that you can train the network to predict what noise was added into the image.
1090880	1100880	So intuitively, you can think of this as like, well, if I'm given a noised image, and if I can predict what noise was added to it, I can kind of like subtract that noise out, right, try to get a real image out.
1101880	1106880	And this is kind of what is happening when you're training a diffusion model. It's learning to denoise images.
1108880	1109880	Any questions so far?
1109880	1117880	No questions.
1118880	1119880	Okay.
1121880	1125880	So what does the model that kind of does this denoising usually look like?
1126880	1145880	Kind of models that we have in our papers usually look like these convolutional unit style models where the U kind of signifies kind of like how the shape of the model here in this picture is looking like, but to think of it as just like a model that runs a bunch of
1146880	1163880	convolutional images, it kind of like down samples the image down into smaller and smaller spatial fields so that it can like learn features at different levels of granularity and then kind of samples it back into something that looks like a prediction of a noise.
1164880	1173880	I don't have to go into the details of architectures, but just to give you an example of what kind of neural nets are trained to perform this task, this is how they look like.
1175880	1185880	So, okay, we have a model that is trying to now denoise images, it's trying to predict the noise that was added to an image. How do we go back to actually getting a generative model out of this?
1186880	1200880	As we talked about in an earlier slide, it's equivalent to predicting the mean of the reverse process, like you can write down the mean of the reverse process in terms of the noise prediction.
1200880	1209880	So now that you have a network that can predict the noise that was added, you can also write down a network that can predict the mean of the reverse process.
1209880	1215880	And once you have something that can tell you the mean of the reverse process, you can run the reverse process backwards.
1215880	1229880	So you can start with noise x t, you could run, you could sample from this reverse process p of x t minus one given x t, you know the mean, and we have fixed the variance to something to do one step of sampling from this process.
1230880	1239880	You do one more step, one more step and so on. And as we talked about what we're doing was denoising, right, we're trying to like learn a process that removes noise from images.
1239880	1246880	So if you start from pure noise and you're denoising it one step at a time, by the end of the process, you would have something that looks like a real image.
1248880	1256880	So, so what we've covered so far is how you train these models and how you sample from these models. Any questions so far?
1260880	1264880	Okay.
1264880	1268880	Um, it's okay.
1268880	1277880	A bunch of theory there, but what you should remember is you train for denoising, and you can derive a sampler from it, once you've trained for denoising.
1277880	1283880	What do you do next? Well, you could now make the model class conditional, you could provide labels at training time.
1283880	1293880	So you could provide, you know, let's say you're training on ImageNet or something, you could have labels that say this image is a goldfincher, this image is a Corgi or so on.
1293880	1312880	And you could make the model, the denoising model class conditional, you could provide these labels, the model so that, given this label, it tries to produce an image from p of x given y, like the distribution of images that are kind of represented by this label.
1312880	1323880	And it's pretty simple, you just throw in a label into the model at some point, so that it now has this extra information when it's trying to denoise images.
1323880	1334880	You could also do something like up sampling, you could ask the model, given this low resolution image, what would be kind of the high resolution image that could be generated from this.
1334880	1347880	So again, just like throwing in a label y, you can throw in a low resolution image as extra conditioning information into the model as it tries to denoise.
1347880	1363880	So, we've now talked about models that are class conditional. The thing is, if you just train models like this, where you give them a label for an image and you train them for producing the image given the label, they're not very good at doing this out of the box.
1363880	1378880	They kind of produce very incoherent samples. And one of the tricks that we developed to kind of fix this was the trick of guidance, where what you do is you train a model to look at the images that are being generated.
1378880	1391880	Use a classifier to classify what is the label of this image. So you kind of look at a noisy image and you're like, you know, whether you ask the model, hey, does this look like a dog or not.
1391880	1404880	So you train a classifier on these noisy images, then you take a gradient of the classifier, you ask the classifier, hey, how can I increase the likelihood to make this image look like a dog.
1404880	1417880	Because you can run the classifier forward, you can get a, get a probability from the classifier of it being a dog, you can also differentiate this function to get the gradient of how to change the image so that this probability increases.
1417880	1429880	And then you augment your diffusion model with such a classifier to kind of guide it towards generating images that are more likely to be classified as a dog by the classifier.
1429880	1445880	So how do we end up doing this in practice. Okay, so you can train a classifier on noisy images, you can just take your data set of images, noise them and train a classifier to predict the label of the noisy images.
1445880	1463880	And then how do you guide now your generative diffusion model to use this classifier. Well, you run the classifier on the noisy images, you predict the probability of, you know, the class label under the classifier so whether something is a dog or not.
1463880	1481880	You take the gradient of this prediction to obtain kind of direction for which the model should change its input to increase the probability of this image, you can add this direction into the mean of the reverse process that you are already going towards.
1481880	1499880	So in terms of the actual formula, it just looks like adding an extra term to your mean prediction, which is the gradient of the log probability of the prediction of the label, given the noisy image.
1499880	1506880	Questions on this, this is, this is important and this could be a little complicated.
1506880	1513880	It seems there are two questions before this. Can you read them.
1513880	1516880	Do you still need a classifier.
1516880	1521880	Once the model is trained.
1521880	1528880	So here by the model you mean the diffusion model, right.
1528880	1545880	Yes, you still need it, because it is part of the sampling process, you're using gradients directly from the classifier in the sampling process, so you still have to keep the classifier around when you sample from the model.
1545880	1561880	So if you look at the next question is the underlying representation of the classes for condition.
1561880	1579880	I followed the question, Ben, could you explain.
1579880	1581880	Okay.
1581880	1583880	I have another question.
1583880	1588880	The s in the term. Is that just a hyper parameter or
1588880	1595880	we'll get to that term in the next slide but yes that is just a hyper parameter.
1595880	1612880	The main thing from this slide is like we previously had a reverse process that looked like a Gaussian with some mean mu and some variance sigma. We now have a modified reverse process where we've just modified the mean mu with an extra term, which is scaled by this
1612880	1624880	parameter s has the variance in it kind of for appropriate scaling as well, and it has this gradient term, which is the gradient of a classifier on noise damages.
1624880	1641880	And we're kind of basically using this gradient to kind of guide the model towards directions where the classifier would predict a higher likelihood of the label being correct for the noise damage, so that the conditional model produces an image that is more correct.
1642880	1649880	Another question. Why is the variance in the additional term also included.
1649880	1653880	That's just how it popped out from the derivation.
1653880	1655880	Oh, okay.
1655880	1672880	I guess you can think of it as kind of like the step size of these things is controlled by the variance if you have a Gaussian with a very small mean in the reverse process and you don't want to take a really large step with your gradient, because you'll really, you'll pop out very far from
1672880	1686880	the reverse process should have taken you to the reverse process is taking really small steps, which kind of can be thought about by its variance, and you also want to change that process only by that much amount.
1686880	1687880	Does that make sense.
1688880	1693880	So, I guess the variance terms like a cap in step size.
1693880	1702880	Right, like to the maximum and the class very gradient is maybe somewhere between zero and one or something like that or
1702880	1710880	I don't know if it has any explicit range here, but I mean it's kind of mostly just direction.
1710880	1714880	Yeah, and you're kind of scaling this direction by a step size.
1714880	1725880	And the extra hyper parameter is if you want to kind of like make these steps bigger or smaller than what is naturally there so that's the extra parameter s that we'll talk about in the next slide.
1725880	1727880	Okay, thank you.
1727880	1735880	Yeah. Okay, so the parameter s here. So what we found was if you just actually use the step size that pops out from the derivation.
1735880	1744880	So as being one, no, no hyper parameter, it kind of doesn't do that much. So on the left you see the samples with as being one.
1744880	1751880	They don't look like any image from any particular class, but it turned out when we added this extra hyper parameter and just bumped it up.
1751880	1759880	So you have scale 10 here on the right, they actually start looking like samples from the distribution of a particular class.
1759880	1774880	So you can think of this extra hyper parameter s as kind of helping the model focus on the modes of the distribution because you're kind of narrowing down the possible things that it produces, at least that's what we saw empirically.
1774880	1784880	However, the trade off here is because you're narrowing it down well, they also kind of start looking similar to each other, the images that are produced.
1784880	1793880	But anyhow, the way to think about the scale factor here is just that it's controlling how much guidance we're using how much is the classifier influencing the final outcome.
1793880	1805880	And when you use a small value for us, it's not influencing that much when you use a large value it's influencing a lot, and the effect of their influences, you're kind of collapsing your distribution towards the modes of whatever the
1805880	1820880	table that thinks is kind of the best representation of that label, they were very high scale will just collapse to the thing that the classifier is most likely to classifiers that they just not always what you want you want some kind of diversity, what you produce.
1820880	1827880	There's some, there's some like intermediate value of scale that is kind of the best that you want to use.
1827880	1836880	And this is kind of how the process looks like in practice here on the bottom you here you have a usual like diffusion process with scale.
1836880	1851880	Let me see I can't see the image. So scale zero you're just using no guidance, and then when you turn on guidance, and now using the gradients of the classifier can nudge the process in the direction where it's more likely to produce that butterfly.
1851880	1862880	So the scale up even higher you're nudging it even further out from its original reverse trajectory into this new trajectory, where it's now producing a very clear butterfly.
1862880	1876880	So the scale parameter is kind of controlling how much guidance is happening and how much the model is being nudged out from its original distribution towards this new better distribution.
1876880	1893880	So similar things, instead of labels you could now have text descriptions of images. So, same model class you're still conditioning on something, but this conditioning thing why instead of being a label is now a piece of text that's a robot's
1893880	1896880	kind of a pass now retreat.
1896880	1908880	And you could train basically the same kind of models, all you have to now change as well you don't have a classified now right, there's no classifier that is predicting a label you're that you have to predict the whole sentence, if you try to do that.
1908880	1913880	So how can we do guidance in this situation.
1913880	1916880	Well, first, let me go in.
1917880	1934880	Oh, okay. Well, first let me go into how you can even pass in conditioning information to diffusion models, which look like text, you just, you can just simply run a transformer on the text and just attend to the representations of the text in the model.
1934880	1955880	What's important is just a pictorial representation of how to deal with text being passed into these models, you can just run a transformer model on this and just have your original convolutional unit architecture attend to this model when it's trying to do the denoising.
1955880	1964880	Back to guidance, how do you actually guide when you have text as the kind of label information. And one of the things you could do is use clip.
1964880	1971880	I think you guys cover clip in a previous lecture Ali you said that so can.
1971880	1974880	Yes, sounds sounds good.
1974880	1977880	Yeah, so I'll skip clip. Okay.
1977880	1989880	So I'm assuming you guys on the clip, but basically clip is a model where you have an image encoder and a text encoder, and it's trying to predict how close the representations of the image and the text.
1989880	2002880	And so you can use clip for guidance, you can ask, hey, I have this noise damage, I have this text description, run the image encoder run the text encoder from clip, how close are these representations.
2002880	2013880	If they're close, then you're going to get a high dot product here, you can take a gradient of this dot product and get a direction to increase this dot product.
2013880	2029880	And that's the gradient you're going to use for guidance, gonna ask the model hey can you increase this dot product so the image, the not the image that you're trying to produce from the reverse process is close in representations to the representation of the text that you're provided.
2029880	2034880	So this is how clip guidance works.
2034880	2041880	What you can do, which we sure enough, which was short in a paper on classifier free guidance is you could skip the classifier completely.
2041880	2054880	And just train a usual diffusion model for for reversing the process but train it sometimes without labels. So sometimes don't, don't tell it what was the text that described an image.
2054880	2062880	And then at test time you ask the model, which direction should it go, given the label and which direction should it go without the label.
2062880	2083880	And then you move your predictions in the direction of the model predictions when it was given the label so in the formula here if epsilon was the epsilon theta xt given why was the prediction of the model with the label and epsilon theta xt given
2083880	2093880	the empty set five was its prediction without the labels, you're kind of taking the difference of these two and using that as your direction to kind of nudge the model in.
2093880	2100880	And again, you have the scale factor s outside of this direction, which telling the model to move in the direction of the predictions with the label.
2100880	2106880	And when you use as greater than one, you'll be moving a lot more in the direction of the predictions with the label.
2106880	2117880	And the cool thing about this way of guiding is that you don't need a separate classifier or a clip model or anything, you're just using the diffusion model itself for guidance.
2117880	2129880	You're directly just asking the model, it's own kind of prediction of which way it should go to increase the probability of the generated image being from the correct class.
2129880	2135880	Any questions about classifier free guidance.
2135880	2154880	What I have is, have you thought about implementing something like, okay, at this, at each stage, for instance, let's talk about the butterfly example at this stage I want to add something to this image.
2154880	2182880	And so the text, you know, can gradually form the shape like for the image like, okay, I want the butterfly and then on top of it I want this flower and then this, you know, gradually giving more idea of how your butterfly want to be depicted.
2182880	2201880	So you're doing this in steps for image, and then you are injecting the tokens from the clip to your, you know, your network for for image generation.
2201880	2210880	And so what if gradually adding things that you want to be in that image.
2211880	2227880	That's a great question, I haven't done this, like we haven't done this directly, but you can kind of do this right, you could like, you could run your reverse process to some point with with your text conditioning being just the simple thing hey it's a butterfly.
2227880	2238880	Then you could continue with a new text prompt for guidance, hey, the butterfly looks like this or so on, and keep going. Maybe that works. Not sure.
2238880	2243880	You could do something else where you just run the whole process, first generate a butterfly.
2243880	2254880	You take the butterfly, you noise it to go back in the process, and then rerun it, but now with a different prompt, so you kind of modifying this generated butterfly in a new direction.
2254880	2268880	Then, you know, noise it again and rerun it again with a slightly different prompt, you kind of be like slowly changing this generation iteratively in these like kind of like iterative modification.
2268880	2277880	So in another slide later we'll show how to do this with something like in painting, but if you just wanted to do it for your direct image. This is maybe how you would do it.
2277880	2280880	Does that kind of answer.
2280880	2291880	Yeah, yeah, I think that's a very interesting, you know, thought and yeah I appreciate your answer.
2291880	2299880	I think that in painting could be one way of thinking about it. Yeah.
2299880	2309880	Yeah, but what I was trying to say there was like yeah, you could also do it without impending by like kind of modifying the full image by like renoising it and reproducing.
2309880	2327880	Yeah, yeah, that also makes sense. I think that I was also referring to more like just the way that by removing the noise you are, you know, trying to somehow refine the image.
2327880	2333880	This also in steps could, you know, add more context to the image.
2333880	2336880	And there might be different ways of implementing it.
2336880	2338880	Yeah.
2338880	2340880	I think that's good.
2340880	2343880	Okay, thanks.
2343880	2345880	Okay.
2345880	2355880	So, in our guide paper we kind of compare these two forms of like guidance for text conditional models clip guidance was classified for guidance.
2355880	2372880	And here are a few samples like representative samples from the model. So on the left here is just samples without any guidance. This is just a pure conditional diffusion model there is no form of classifier clip guidance or classifier free guidance.
2372880	2383880	And kind of see, you know, it's kind of getting the prompts of the pram pure steam glass window of a panda panda eating bamboo. It's kind of alright, but it's not very coherent.
2383880	2393880	Then you do clip guidance with scale to start getting better with the classifier free guidance ones look the best in in all the tests we did.
2393880	2409880	And I think part of this might be just that it's, it's not exactly the correct thing to use clip part of it just might be that it's kind of better inductive bias to use classifier free guidance.
2409880	2424880	There could be a lot of reasons but at least empirically, this was working better in practice to generate more realistic samples from these models, and you can see guidance does make a big difference in, you know, generating more realistic things, but it also does kind of make, you know, it's
2424880	2434880	kind of like more collapse effect happen all of these samples kind of start looking a little similar to each other when when you do a lot of guidance.
2434880	2446880	So, what what what have we done here we've trained a model that you know given a text prompt can generate images and we've done it for this diffusion technique.
2446880	2459880	And this was what the strain in the glide paper, and we then showed that this model actually was beating the older open a model, Dali, which was actually a bigger model, which was trained in a very different fashion.
2459880	2465880	The strain is using an order aggressive model on these like discrete VA tokens.
2465880	2481880	And it, the new diffusion model not only generated things that looked a lot more realistic it actually generated them faster and use fewer parameters. So, this new model class is actually a lot nicer to use for these tasks than the older class of models.
2481880	2492880	One cool advantage of these models is also because they're not doing this thing or to aggressively they're you know just generating and hold image you can do these things that are much harder to do with these older autoregressive models can do things like in painting.
2492880	2498880	So you could mask out a portion of the image, and then ask the model to kind of fill in that portion.
2498880	2509880	And how would you do that well just like we passed our conditioning labels in the past you could just pass in kind of this like half filled image as extra conditioning information to the model.
2509880	2528880	So you take this image and a mask on top of it, you provide this extra information to the model when it's trying to run its generative process and it's going to try to now think of this as a label hey like this is image what are the possible images that correspond to this label for this kind of
2528880	2548880	a masked image, what are the things that could complete this image. And what you're providing is this kind of like image X zero with a little bit of region must and a mask and that tells what is the part of the image that has been masked.
2548880	2560880	Now, to text condition and painting, you could provide an, you know, an image with a mask and you could also provide a text label to tell the model how it shouldn't paint the region.
2560880	2572880	So these are examples from the paper. So on the left here, you have the text label being zebras roaming in the field and you have this image with a green mask on it. So the masked region was removed.
2572880	2585880	And the model was asked to fill in this image conditioned on this product. So now it's going to try to fill in not only something that kind of completes the image correctly, like isn't there the conditional distribution but also kind of matches the product.
2585880	2595880	On the right here you see something with a girl hugging a corgi on a pedestal. And it's kind of matching the style of the image very well here if you can see it kind of looks like it's like painting.
2595880	2606880	Kind of nicely like blended in. So this is really cool thing which you can do very easily out of the box with diffusion models but it's kind of much harder to do with other classes of models.
2606880	2621880	And you could take this idea iteratively, like you could now erase a region of image. So let's say we erased the region on the left here, and you first filled it in with, you know, a cozy living room, and you raised a different region.
2621880	2631880	And you know, asked for a painting of a corgi on the wall above the couch. When you get a painting there, you raise another region, put a coffee table, put a flower vase and so on.
2631880	2646880	So this is one way of kind of doing the thing you talked about Ali, but you kind of like generate things iteratively, but this is doing it from painting erasing regions, raising very specific regions, then asking the model to fill that region in with the thing you want.
2646880	2656880	It doesn't cover all kind of modifications that you want to do, but it does cover things that you can represent as like adding things one by one into an image, if that makes sense.
2656880	2671880	So like stuff that you maybe cannot do with this is like, you know, change the style of an image completely the full thing, because well, if you just erase the whole thing you couldn't, it wouldn't have anything to condition it can't use the style but things like this where you add things, you
2671880	2675880	can do it pretty easily through iterative painting.
2675880	2681880	Any questions so far on the painting side of things.
2681880	2688880	So Linda is asking if the collab is available for painting I think I saw it on the website.
2689880	2699880	Yes, the collab that we released in the guide repo the thing the third one is the second one that one doesn't painting.
2699880	2710880	Basically, all you like to do that is you'll have to provide this extra image, and you'll have to provide a mask or like mask out a portion of the image and then provide a mask that tells what has been masked.
2710880	2720880	And then you just run the guided diffusion process as usual, but now with this extra information to try to impaint this region.
2720880	2725880	I'll go into kind of notebook later but yes, the notebooks there.
2725880	2729880	Diego also has a question.
2729880	2736880	Can you remove objects using printing. Yeah, I mean, so let me go back to the slide.
2737880	2751880	I mean, I guess, technically, in the very first one we removed the thing right we just must out whatever was on the wall in the left. And here we ended up adding a painting of a colleague but you could just ask for nothing.
2751880	2754880	And then it would just fill it with the wall.
2754880	2759880	I don't know if there's an example here.
2759880	2768880	Yeah, in all of these things we kind of change something modified something but if you just don't give any prompt is just going to try to fill it.
2768880	2777880	Without any extra information is just trying to make the best possible completion, and that could be kind of like removing an object.
2777880	2784880	Does that answer your question.
2784880	2790880	Assuming yes, never move on.
2790880	2792880	Okay.
2792880	2806880	Well, you can take this idea further and you can do out painting kind of so like previously we drew a mask that was inside the image, but you could also kind of move the rectangle that the model is focusing on outside the image.
2806880	2817880	So now the mask looks like a strip of things around the image that is masked, and you can ask the model to fill that thing, and you could keep moving this rectangle around to kind of expand out from an image.
2817880	2834880	This is something that Holly heard, and then she like to this central image here and then she kept moving the square out kind of expand out the canvas of the model and ask you to keep filling in extra information outside of the region.
2834880	2843880	At the end of the day for the model is there is just like some conditioning information some mask, and it's going to just try to fill in in that region whatever it thinks is the best possible completion.
2843880	2849880	It doesn't have to be inside and be outside as well.
2849880	2859880	So, one other, I guess, important thing is like, we talked about the release notebooks the breeze notebooks is kind of the released model which is the filtered glide model.
2859880	2876880	So in our paper we talk about this where we, if we looked at, you know, kind of the things you could generate with the big original glide model, and there were a lot of, like, problematic things that it could generate that made it unsafe to release the full big model.
2876880	2892880	So release a small smaller model on a filter data set. And it cannot generate things that look as impressive as the big model, but it's still kind of can generate realistic looking images for like some of these easier prompts.
2892880	2901880	But yes, there was going to be a little bit of a performance gap between using the filtered small model that has been released versus for the best images you can see.
2901880	2910880	You can still generate a lot of cool things with the small filtered model. These are some of the things I found on Twitter that people have generated with the notebooks that we released.
2910880	2912880	So on the left here.
2912880	2923880	I think what they did was, they kind of did the painting thing, but they just went kind of like in a panorama fashion left to right, and kind of kept asking the model to fill these landscapes.
2924880	2930880	The guidance scale a lot to make it very artsy think in the right.
2930880	2937880	I've kind of problem like they've done this out painting thing but
2937880	2951880	I don't know how they got those structures, but I think a part of this part of the fun stuff here is kind of these prompt search or prompt tuning things where you kind of find these prompts and generate very specific and artistic styles.
2951880	2961880	And if you find very cool prompts and you can now use these tricks of our painting and so on, kind of like keep expanding it out to generate these cool pieces of art.
2961880	2973880	This is another thing I found on Twitter where they trained a classifier for guidance model on conceptual captions and I think this is like a flower a space flower with some space.
2973880	2975880	Our team.
2975880	2976880	Super cool.
2976880	2979880	There is a question.
2979880	2981880	You want to read it.
2981880	2983880	Let's see.
2983880	2987880	What did it create that was dangerous.
2987880	2991880	So, or maybe comment.
2991880	2993880	Oh, sorry.
2993880	3007880	I think I, yeah, what did it create that was dangerous. Yeah, I guess, well, for all the days I would recommend just reading a paper. I mean, there were, and I wasn't the one who did the safety analysis here was the opinion.
3007880	3011880	The people who work on safety at opening and Alex.
3011880	3029880	But I think it was stuff like violence it was stuff that could be used for like, if it makes it for like misinformation and so on. But I mean these models are pretty powerful so you could generate lots of things that you don't want to be floating on the internet.
3029880	3044880	I mean, the trade offs are hard here right because like, on the one hand you do want to, you know, put these powerful models out there in the hands of people to like, generate all these nice cool art and like, like lots of positive use cases right.
3044880	3054880	But I think you want to also be conservative to not create a lot of like stuff that you don't want floating around on the internet that's associated with your models.
3054880	3057880	You know, this is a tough trade off.
3057880	3071880	I think it's, it's nice that we can still release some safe model that people can use, but making these models like fully safe when they never generate something that is like, kind of like not a, not a good thing.
3071880	3075880	It's very hard problem in general.
3075880	3088880	So you need to find more like detailed examples in our paper, if you're looking for like specific examples, but that was kind of our line of thinking on like releasing like the small filter budget.
3088880	3101880	Okay, maybe a slight tangent but what what does the process look like of let's say calling, you know, the unsafe parts away from from the model, like how do you go about that.
3101880	3121880	So calls usually I guess training these training kind of like these classifiers to filter out portions of the data set that could be like not safe, if you could, you know, train an NSFW classifier you could train a classifier for like hate symbols you could train a classifier for
3121880	3132880	other things, then you, once you have labeled data on which you can train these classifiers labeled data for like I don't know real images that you consider things that you don't want to model to generate.
3132880	3144880	You could run these classifiers on your training data set filter it out, then train a model on the filter data set. So hopefully the model will never go into regions where
3144880	3149880	there's nothing like that because it was never part of the training data.
3149880	3152880	Yeah, awesome. Thank you.
3152880	3163880	Okay, so just a quick like some like look into the notebooks that we've released this. This is just like some useful.
3163880	3175880	Some parameters that you will have to like, kind of like deal with when you're trying to generate stuff from the notebooks that you released. Well, there's the two scales we've talked about in a talk today the classifier free guidance scale and the clip guidance
3175880	3189880	scale, the small values for these scales will generate, you know, more diverse, but not very coherent samples larger values will generate coherent things very large values will generate like very artsy looking things.
3189880	3198880	The classifier free guidance scale, like, I think three might be the default but you could try five 1020 or so on to generate more artistic things.
3198880	3201880	Similarly for the clip guidance scale.
3201880	3216880	Time steps kind of controls like how many little steps you take in the diffusion process. I think by default we use 100. There's 100 steps of like iterative denoising that will happen so if you use a higher value to look more sharp, but you'll also spend more
3216880	3219880	time creating a sample.
3219880	3222880	So it was a good like trade off that we used in the thing.
3222880	3236880	Finally, the further in painting notebook, you would have to provide an extra thing which is like, what is the region of a given image that you want to paint so you would have to provide, let's say a 64 by 64 image that you want to impaint and some
3237880	3249880	that you've like removed that you kind of specify with a mask, which is like, I think one in places where the image is not masked and zero in the places where the image is masked.
3249880	3260880	I could be wrong on the zero versus one, so you should check the notebook for which direction, basically it's a binary mask that tells this is the portion of the image that is masked, this is the portion of the image that is unmasked.
3260880	3266880	And the rest is like, just just a usual image with three channels that you provide as extra information to the model.
3266880	3270880	And do you just upload that as an image file.
3270880	3284880	I think the way in the notebook that works is, so if this is on a co lab you'll have to have the file on drive and then you open it using pillow image dot open or something. I don't know if there's like a direct upload button.
3284880	3286880	But I guess like,
3286880	3296880	Oh, sorry, I guess my question was, like when you add the mask, like the mask is just like removing part of like a regular image file or like there's something more to it.
3296880	3307880	Oh, yeah, that's just removing parts of the regular file. So like, I think if you want to do it programmatically just just zero out that region.
3307880	3309880	Does that answer the question or.
3309880	3312880	That makes sense. Yeah, thank you. Yeah.
3312880	3326880	There's an example in the notebook and there's a cell in the notebook that kind of masks an image that might be more clear where you can see like, you are loading an image from the disk then you are kind of like removing a region then you are kind of writing down a
3326880	3333880	mask that specifies what you removed and then you pass in all this information into the model.
3333880	3343880	So I think that's it for the stuff you will need to kind of like apply this thing to the notebook.
3343880	3356880	And if you want more further reading or like what we talked about today, I mean I try to focus on mostly like things you will need to understand for like kind of generating art from these things but you want to go into more detail about the
3356880	3366880	design of these models. I think the best paper would probably be the denoising diffusion probabilistic models paper by Jonathan Ho, the DDPM paper.
3366880	3379880	That has kind of like the basic theory of the models that we talked about today, and there was our paper on diffusion models began to imagine this is that kind of talks about the guidance trick for classifier guidance, and then the glide paper
3379880	3394880	to this for text conditional models where we talk about clip guidance and classifier free guidance. There was also the paper by young song generative modeling best made ingredients of the data distribution which kind of like was before the Jonathan
3394880	3406880	Ho approach this problem from a very different perspective of score matching, and in the DDPM paper Jonathan Ho and others showed how it's kind of equivalent to score matching.
3406880	3420880	So if you want to understand diffusion models from a different lens, I think I would strongly recommend that paper, and these two blogs as well by Lillian and Yang on diffusion models and score matching models, basically like two sides of the same kind of understanding from both
3420880	3426880	the super useful to see you know why these generated models work.
3426880	3431880	And that's it.
3431880	3436880	Thank you so much it was very, very interesting and fascinating.
3436880	3438880	I'm very inspiring.
3438880	3440880	Are there questions.
3440880	3441880	Go ahead.
3441880	3443880	Super cool.
3443880	3444880	Thank you.
3444880	3460880	Question. Did you notice if there was any relationship between say, like, if you fed it to dimensional noise, and if you were to step through the X or Y coordinates, did you notice if there's any relationship between the coordinates used for two dimensional noise and the output you can
3460880	3462880	Say that again.
3462880	3464880	What did you say at the end.
3464880	3475880	If you use two dimensional noise is there a relationship between the coordinates that you use for the two dimensional noise map and the outputs of the model.
3475880	3483880	Like is there a relationship that that that you observe between the noise that you use and the model and the outputs of the model.
3484880	3491880	There's a little bit so like one way you can do this is you can like fix the noise, the sample and change the label.
3491880	3500880	And you can see that the generated images for the same noise but different labels kind of have similar like perspective and spatial structure.
3500880	3505880	So like, but but they look kind of like images from different classes.
3505880	3514880	So this is definitely control some aspect of you know how the final output looks like and there's some kind of spatial like connection, but it's not an exact direct connection.
3514880	3517880	Does that kind of answer your question.
3517880	3519880	Yeah, got it.
3519880	3528880	I love this in our I think diffusion models beat guns paper. I think that in the appendix we have an example where we like do this specific thing.
3528880	3532880	It's actually more directly connected when you use a different sampling method.
3532880	3540880	So, I showed you there is reverse process right where at each step you're doing this reverse step with the Gaussian.
3540880	3552880	At each step you're adding a little bit of noise when you sample from the Gaussian, but there's a different way of reverse sampling from these models which is called ddim is another paper on that, where you just sample noise once at the start.
3552880	3569880	And then you just run a deterministic reverse process to sample from the model in that case that there's kind of like this one to one correspondence between the noise and the generated image, and then it's more clear to see this.
3569880	3584880	Thank you.
3584880	3589880	I can ask my earlier question again, I guess if nobody else is not a question.
3590880	3607880	So I guess, if you're using a diffusion model without clip. Right. So I guess what's being trained is the classifiers for the labels that am I understanding that correctly.
3608880	3610880	For the denoising process.
3610880	3623880	Yeah, I guess I'm trying to understand if without clip. How does it know what to denoise to without like some representation of the text that you're feeding it.
3623880	3626880	Yeah, yeah, so.
3626880	3642880	Well, yeah, if you train a model or denoising model without text labels, then it doesn't know where to go and the only way you can generate a sample for a given text distribution it would would be through like clip guidance or something, but we do have.
3642880	3656880	We train these models to be text conditional diffusion model. And in the classifier free guidance case, you train it with or without the labels. So maybe I can go back to one of our slides here.
3656880	3668880	The way the model, the reverse process model sees the text is through this kind of conditioning on the, the representations output by a transformer on the text.
3668880	3670880	Okay, got it.
3670880	3674880	So this text conditioning here is without clip.
3674880	3678880	Yes, so.
3678880	3694880	Can I point a glossed over in guidance was you could use guidance on top of unconditional models or conditional models. So you could have a reverse diffusion model that isn't conditioned on any labels, then it wouldn't have any way of actually like producing an image given a class.
3694880	3702880	But then you could use guidance on top to get it to produce an image giving a class, but you could also use guidance on top of conditional models themselves.
3702880	3713880	So you could have your original model be able to produce an image text, like we did here, but also use guidance on top to make it even better at doing this.
3713880	3715880	Got it. Okay, yeah.
3715880	3719880	This one.
3719880	3729880	Okay, thank you.
3729880	3739880	Okay, excellent. If are there more questions.
3739880	3744880	Well, I think that we can wrap up the session.
3744880	3747880	Again want to thank you a lot.
3747880	3752880	Profile and it was, it was great. Thank you so much.
3752880	3761880	Thank you. And thank you for having me and feel free to just like email me any questions later or DM me on Twitter with questions.
3761880	3776880	I think there's a lot of cool stuff out happening in this so like, I would strongly recommend doing some of the like reading some of the blogs are reading just like things that you can find in other collab notebooks as well.
