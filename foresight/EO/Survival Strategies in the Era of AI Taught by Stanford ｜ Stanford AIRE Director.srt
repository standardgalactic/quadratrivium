1
00:00:00,000 --> 00:00:04,920
If a job can be done by a human and it costs $1,000,

2
00:00:04,920 --> 00:00:08,040
because you can't really calculate faster than the machines,

3
00:00:08,040 --> 00:00:09,400
then you let the robot do it,

4
00:00:09,400 --> 00:00:12,160
it will just cost roughly around $200.

5
00:00:12,160 --> 00:00:16,000
AI will make a lot of jobs disappear in the future.

6
00:00:16,000 --> 00:00:19,480
How much more information kids gets nowadays?

7
00:00:19,480 --> 00:00:21,280
It's just completely different now.

8
00:00:21,280 --> 00:00:24,200
We still use the same way to teach them.

9
00:00:24,200 --> 00:00:26,200
And then the more I think about it,

10
00:00:26,200 --> 00:00:29,440
the more I feel like we need to push to change that.

11
00:00:31,560 --> 00:00:32,400
I'm Li Zhang.

12
00:00:32,400 --> 00:00:34,800
I'm the director of the Stanford Air Program.

13
00:00:34,800 --> 00:00:37,840
You know, the era of AI is in the near future,

14
00:00:37,840 --> 00:00:40,920
and I would say it's actually now, it started already.

15
00:00:40,920 --> 00:00:42,880
I'm passionate trying to figure out

16
00:00:42,880 --> 00:00:45,320
what is the right way of teaching the next generation

17
00:00:45,320 --> 00:00:47,800
in the era of AI and robotics.

18
00:00:51,200 --> 00:00:55,080
We have a lot of people are afraid of AI,

19
00:00:55,080 --> 00:00:56,560
so they try to avoid this.

20
00:00:56,560 --> 00:00:58,920
They're like, oh, I wanna stay away from that.

21
00:00:58,920 --> 00:01:00,720
But the thing is that that's probably one

22
00:01:00,720 --> 00:01:03,960
of the most powerful tool that we have ever invented.

23
00:01:03,960 --> 00:01:05,200
If you don't use these tools,

24
00:01:05,200 --> 00:01:08,440
then you cannot really compete with anyone like other people.

25
00:01:08,440 --> 00:01:11,680
I think there's a few things we need to change.

26
00:01:11,680 --> 00:01:16,160
One is that we need to start to teach AI thinking

27
00:01:16,160 --> 00:01:17,400
as early as possible.

28
00:01:17,400 --> 00:01:20,880
AI thinking will allow them to know the difference

29
00:01:20,880 --> 00:01:22,760
between human and AI.

30
00:01:22,760 --> 00:01:26,280
And then the human part is really the innovation part

31
00:01:26,280 --> 00:01:27,800
from zero to one.

32
00:01:27,800 --> 00:01:30,600
That's where AI cannot do a good job.

33
00:01:30,600 --> 00:01:31,760
We need to focus on that.

34
00:01:31,760 --> 00:01:35,200
There's three important things about AI thinking.

35
00:01:35,200 --> 00:01:36,400
With the first thing,

36
00:01:36,400 --> 00:01:39,640
you need to have general understanding of how AI works.

37
00:01:39,640 --> 00:01:44,640
In the past, AI is basically mostly based on the rules

38
00:01:44,760 --> 00:01:49,200
or the specific algorithms that we write in the computer.

39
00:01:49,200 --> 00:01:50,720
The human set the rules.

40
00:01:50,720 --> 00:01:55,720
And then now we developed a different algorithms

41
00:01:56,080 --> 00:01:59,640
like deep learning, reinforcement learning based on data

42
00:01:59,640 --> 00:02:03,080
because we have much more powerful computers

43
00:02:03,080 --> 00:02:05,440
that can handle way more data.

44
00:02:05,440 --> 00:02:07,200
And then they will develop

45
00:02:07,200 --> 00:02:10,200
and trying to find the most optimized solution

46
00:02:10,200 --> 00:02:11,280
based on the current data.

47
00:02:11,280 --> 00:02:12,720
And then the more data you have,

48
00:02:12,720 --> 00:02:15,480
the better solution you usually will get.

49
00:02:15,480 --> 00:02:17,320
If you do the first one,

50
00:02:17,320 --> 00:02:20,400
the second one is that you will gain the ability

51
00:02:20,400 --> 00:02:22,680
to differentiate the human ability

52
00:02:22,680 --> 00:02:25,920
versus the machine's ability or AI's ability.

53
00:02:25,920 --> 00:02:27,600
I think probably most of the audience

54
00:02:27,600 --> 00:02:30,760
don't know there's a scientific research area

55
00:02:30,760 --> 00:02:32,880
called a structural biology.

56
00:02:32,880 --> 00:02:36,560
Scientists in this field study the structure of a protein.

57
00:02:36,560 --> 00:02:39,440
Proteins are so important for all the living creatures.

58
00:02:39,440 --> 00:02:43,440
The whole world have like 100 to 200 million proteins.

59
00:02:43,440 --> 00:02:45,400
This research area like scientists,

60
00:02:45,400 --> 00:02:46,800
a lot of them are focusing on

61
00:02:46,800 --> 00:02:49,120
determining the structure of these proteins.

62
00:02:49,120 --> 00:02:53,600
We human only find just a very little number

63
00:02:53,600 --> 00:02:55,480
of these proteins like the structures of it,

64
00:02:55,480 --> 00:02:56,640
less than 1%.

65
00:02:56,640 --> 00:02:59,080
However, this AI is called alpha fold.

66
00:02:59,080 --> 00:03:00,560
That's from deep mind.

67
00:03:00,560 --> 00:03:02,040
In the past two years,

68
00:03:02,040 --> 00:03:04,960
alpha fold predict like the structure

69
00:03:04,960 --> 00:03:07,760
of almost all the proteins in the world.

70
00:03:07,760 --> 00:03:10,880
And they put it in the open database online.

71
00:03:10,880 --> 00:03:13,640
So a job, once the machines can do it,

72
00:03:13,640 --> 00:03:15,040
then let the machines do it.

73
00:03:15,040 --> 00:03:17,040
And then we focus on the human part.

74
00:03:17,080 --> 00:03:18,640
After you get the first two,

75
00:03:18,640 --> 00:03:22,240
the third one is you will have the ability to work with AI,

76
00:03:22,240 --> 00:03:24,760
use AI to help you to accomplish other jobs.

77
00:03:24,760 --> 00:03:27,560
There's critical part is from zero to one,

78
00:03:27,560 --> 00:03:29,720
which basically that we invent something

79
00:03:29,720 --> 00:03:31,360
that doesn't exist before.

80
00:03:31,360 --> 00:03:34,000
And we probably can do zero to one better

81
00:03:34,000 --> 00:03:37,320
with AI providing a lot of information and things like that.

82
00:03:37,320 --> 00:03:41,800
So we should prepare our kids to learn how to innovate,

83
00:03:41,800 --> 00:03:44,880
to generate new ideas, to use AI to help us,

84
00:03:44,880 --> 00:03:45,880
that kind of stuff.

85
00:03:48,040 --> 00:03:53,040
Creativity, it's something that is really hard to teach.

86
00:03:54,840 --> 00:03:58,080
Or some people think creativity cannot be taught.

87
00:03:58,080 --> 00:04:00,680
How to teach people creativity.

88
00:04:00,680 --> 00:04:03,560
This thing get changed by the Stanford design thinking.

89
00:04:03,560 --> 00:04:06,120
We can use this method to teach you

90
00:04:06,120 --> 00:04:08,720
how to systematically to make innovations.

91
00:04:08,720 --> 00:04:12,320
Design thinking is a methodology that we use here

92
00:04:12,320 --> 00:04:15,760
at Stanford to teach people how to make innovations.

93
00:04:15,760 --> 00:04:20,720
And we do not make you as innovative or creative

94
00:04:20,720 --> 00:04:23,000
as Steve Jobs or Elon Musk.

95
00:04:23,000 --> 00:04:25,760
However, we can use this methodology

96
00:04:25,760 --> 00:04:30,280
to make you more creative or innovative than yourself.

97
00:04:30,280 --> 00:04:33,880
So design thinking has steps that you can follow.

98
00:04:33,880 --> 00:04:35,920
The first step is empathize.

99
00:04:35,920 --> 00:04:38,880
First, you have to understand who you're invent for.

100
00:04:38,880 --> 00:04:40,680
Are you inventing for your parents

101
00:04:40,680 --> 00:04:44,280
or you're inventing for children who are studying in the school?

102
00:04:44,280 --> 00:04:46,320
You have to understand who are the users.

103
00:04:46,320 --> 00:04:49,480
Then you empathize with them, especially their emotion.

104
00:04:49,480 --> 00:04:52,800
And then you go to the second step, which is called define.

105
00:04:52,800 --> 00:04:56,080
A lot of people, they didn't have the right problem

106
00:04:56,080 --> 00:04:56,920
to start with.

107
00:04:56,920 --> 00:04:59,240
Then you have to define that problem clearly.

108
00:04:59,240 --> 00:05:02,800
And then you go to the third step, which is ideation,

109
00:05:02,800 --> 00:05:06,680
which is using brainstorming to generate a lot of ideas.

110
00:05:06,680 --> 00:05:10,000
And then you kind of get feedbacks from the users.

111
00:05:10,000 --> 00:05:12,400
You pick the good ones to prototype.

112
00:05:12,400 --> 00:05:15,040
After you do the prototype, which is the fourth step,

113
00:05:15,040 --> 00:05:18,200
you do test with the user and then you get feedback.

114
00:05:18,200 --> 00:05:20,960
Maybe the feedback is good or maybe the feedback is bad,

115
00:05:20,960 --> 00:05:23,960
but you have to do redesign or reinvent.

116
00:05:23,960 --> 00:05:28,160
We have a phrase called all design is redesign.

117
00:05:28,160 --> 00:05:31,280
If you realize, well, I actually didn't define

118
00:05:31,280 --> 00:05:33,920
this problem right, then you go back to the step two.

119
00:05:33,920 --> 00:05:36,360
So you have to go in this iterations.

120
00:05:36,360 --> 00:05:40,520
Eventually you will have some very nice inventions.

121
00:05:40,560 --> 00:05:44,520
But when you read books and or you listen to some lectures,

122
00:05:44,520 --> 00:05:47,840
whatever, after you finish in that,

123
00:05:47,840 --> 00:05:49,440
you didn't understand it yet.

124
00:05:49,440 --> 00:05:52,440
You have to use it several times to really feel it.

125
00:05:52,440 --> 00:05:56,360
Let me give you an example in one of the class at Stanford.

126
00:05:56,360 --> 00:06:00,880
So basically this project is about how to get good incubators,

127
00:06:00,880 --> 00:06:03,400
get more incubators for the Nepal.

128
00:06:03,400 --> 00:06:06,400
At first that, actually a lot of people are just trying

129
00:06:06,400 --> 00:06:08,600
to say, well, just design it in California.

130
00:06:08,600 --> 00:06:12,040
But then we say, well, you have to gain empathy.

131
00:06:12,040 --> 00:06:15,000
You need to go to the real place.

132
00:06:15,000 --> 00:06:16,400
If you have never been to Nepal,

133
00:06:16,400 --> 00:06:18,000
how can you design for that?

134
00:06:18,000 --> 00:06:20,920
They actually fly to Nepal and they went to the mountains

135
00:06:20,920 --> 00:06:24,240
and to their surprise, they actually see a lot of these

136
00:06:24,240 --> 00:06:27,240
expensive incubators in these medical centers.

137
00:06:27,240 --> 00:06:29,840
They actually are not lack of those machines,

138
00:06:29,840 --> 00:06:31,360
but they don't know how to operate them.

139
00:06:31,360 --> 00:06:33,640
Problem is they find wrong.

140
00:06:33,640 --> 00:06:35,160
They have to redefine the problem.

141
00:06:35,160 --> 00:06:37,280
And then they went back to these villages

142
00:06:37,280 --> 00:06:39,040
and talk with those farmers.

143
00:06:39,040 --> 00:06:42,240
We do need those things, but not in these medical centers.

144
00:06:42,240 --> 00:06:43,560
We need in our home.

145
00:06:43,560 --> 00:06:44,720
We need the cheap ones.

146
00:06:44,720 --> 00:06:47,680
So then they actually design a very cheap,

147
00:06:47,680 --> 00:06:51,280
like kind of functioning as a baby incubator

148
00:06:51,280 --> 00:06:53,080
and have very good success.

149
00:06:53,080 --> 00:06:54,720
When that's a good example,

150
00:06:54,720 --> 00:06:57,560
the problem was defined wrong at first.

151
00:06:57,560 --> 00:07:00,920
And then they go into this design thinking process

152
00:07:00,920 --> 00:07:03,040
and they find a way to redesign the problem.

153
00:07:03,040 --> 00:07:05,560
And then they solve their right problem.

154
00:07:08,280 --> 00:07:11,760
The most interesting thing about AI robotics,

155
00:07:11,760 --> 00:07:12,720
there's a few of them.

156
00:07:12,720 --> 00:07:14,640
I think the first one is chat GPT

157
00:07:14,640 --> 00:07:18,520
because it's probably a surprise for a lot of people

158
00:07:18,520 --> 00:07:22,560
that AI can talk with people in that a very natural way.

159
00:07:22,560 --> 00:07:25,080
And also it can not only chat with you,

160
00:07:25,080 --> 00:07:26,800
it can also write code for you.

161
00:07:26,800 --> 00:07:28,800
It seems like he knows a whole lot

162
00:07:28,800 --> 00:07:30,880
and it's smarter than a lot of people

163
00:07:30,880 --> 00:07:32,720
and which surprise people.

164
00:07:32,720 --> 00:07:36,240
So, and also it's gonna change education for sure

165
00:07:36,240 --> 00:07:40,240
because now kids can use chat GPT to write essays

166
00:07:40,240 --> 00:07:41,080
and do homeworks.

167
00:07:41,080 --> 00:07:43,600
So then teachers need to think about

168
00:07:43,600 --> 00:07:44,840
how to deal with that.

169
00:07:44,840 --> 00:07:49,840
Actually, I just gave my student an assignment yesterday.

170
00:07:50,320 --> 00:07:52,480
I asked a student to write an essay.

171
00:07:52,480 --> 00:07:54,040
I said, well, you know what?

172
00:07:54,040 --> 00:07:57,080
We just talked about chat GPT in a class.

173
00:07:57,080 --> 00:07:59,880
Now I'm gonna give you an assignment to write an essay

174
00:07:59,880 --> 00:08:01,640
with the help of chat GPT.

175
00:08:01,640 --> 00:08:03,440
I'm not really asking you to not use it.

176
00:08:03,440 --> 00:08:04,440
I ask you to use it.

177
00:08:04,440 --> 00:08:05,960
And then after that class,

178
00:08:05,960 --> 00:08:09,040
I will have short discussions with each of you

179
00:08:09,040 --> 00:08:10,560
and tell me how you use it.

180
00:08:10,560 --> 00:08:11,440
How do you feel it?

181
00:08:11,440 --> 00:08:14,600
I think that technology advancement,

182
00:08:14,600 --> 00:08:19,320
you cannot try to ignore it or trying to avoid it.

183
00:08:19,320 --> 00:08:21,920
It's happening and it's just like water.

184
00:08:21,920 --> 00:08:23,240
You cannot block it.

185
00:08:23,240 --> 00:08:25,160
You have to go with it.

186
00:08:25,160 --> 00:08:29,040
For me, I want to understand how chat GPT

187
00:08:29,040 --> 00:08:31,240
is gonna impact education system.

188
00:08:31,240 --> 00:08:33,480
And I wanna work with our students

189
00:08:33,480 --> 00:08:35,240
to understand that better.

190
00:08:35,240 --> 00:08:38,080
So that's why I gave this homework for my students.

191
00:08:39,680 --> 00:08:42,400
I'm a big fan of Autobots, Transformers.

192
00:08:42,400 --> 00:08:45,440
I grew up with those cartoons and I'm a big fan of it.

193
00:08:45,440 --> 00:08:49,360
Even now, I'm still a big fan of Optimus Prime.

194
00:08:49,360 --> 00:08:50,960
And that really inspired me

195
00:08:50,960 --> 00:08:53,320
that I always wanna make cool robots

196
00:08:53,320 --> 00:08:54,680
like when I was a little kid.

197
00:08:54,680 --> 00:08:58,400
And I think most kids, they have a dream when they're young.

198
00:08:58,400 --> 00:09:00,760
It's easier to inspire a dream

199
00:09:00,760 --> 00:09:02,840
when someone's in early ages.

200
00:09:02,840 --> 00:09:06,240
After people grow up, they kinda lose their interest.

201
00:09:06,240 --> 00:09:07,200
They lose their dream.

202
00:09:07,200 --> 00:09:08,240
They don't know what to do.

203
00:09:08,240 --> 00:09:12,400
It's actually critical important for these little minds

204
00:09:12,400 --> 00:09:13,760
to have dreams.

205
00:09:13,760 --> 00:09:17,120
My ultimate goal is to find out

206
00:09:17,120 --> 00:09:21,080
what is the ideal education system for the future.

207
00:09:21,080 --> 00:09:23,800
The education part is really important.

208
00:09:23,800 --> 00:09:27,880
It has profound impact on the next generation's future.

209
00:09:27,880 --> 00:09:29,800
And that's my ultimate goal.

