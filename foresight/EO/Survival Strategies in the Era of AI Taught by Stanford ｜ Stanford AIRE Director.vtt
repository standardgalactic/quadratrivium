WEBVTT

00:00.000 --> 00:04.920
If a job can be done by a human and it costs $1,000,

00:04.920 --> 00:08.040
because you can't really calculate faster than the machines,

00:08.040 --> 00:09.400
then you let the robot do it,

00:09.400 --> 00:12.160
it will just cost roughly around $200.

00:12.160 --> 00:16.000
AI will make a lot of jobs disappear in the future.

00:16.000 --> 00:19.480
How much more information kids gets nowadays?

00:19.480 --> 00:21.280
It's just completely different now.

00:21.280 --> 00:24.200
We still use the same way to teach them.

00:24.200 --> 00:26.200
And then the more I think about it,

00:26.200 --> 00:29.440
the more I feel like we need to push to change that.

00:31.560 --> 00:32.400
I'm Li Zhang.

00:32.400 --> 00:34.800
I'm the director of the Stanford Air Program.

00:34.800 --> 00:37.840
You know, the era of AI is in the near future,

00:37.840 --> 00:40.920
and I would say it's actually now, it started already.

00:40.920 --> 00:42.880
I'm passionate trying to figure out

00:42.880 --> 00:45.320
what is the right way of teaching the next generation

00:45.320 --> 00:47.800
in the era of AI and robotics.

00:51.200 --> 00:55.080
We have a lot of people are afraid of AI,

00:55.080 --> 00:56.560
so they try to avoid this.

00:56.560 --> 00:58.920
They're like, oh, I wanna stay away from that.

00:58.920 --> 01:00.720
But the thing is that that's probably one

01:00.720 --> 01:03.960
of the most powerful tool that we have ever invented.

01:03.960 --> 01:05.200
If you don't use these tools,

01:05.200 --> 01:08.440
then you cannot really compete with anyone like other people.

01:08.440 --> 01:11.680
I think there's a few things we need to change.

01:11.680 --> 01:16.160
One is that we need to start to teach AI thinking

01:16.160 --> 01:17.400
as early as possible.

01:17.400 --> 01:20.880
AI thinking will allow them to know the difference

01:20.880 --> 01:22.760
between human and AI.

01:22.760 --> 01:26.280
And then the human part is really the innovation part

01:26.280 --> 01:27.800
from zero to one.

01:27.800 --> 01:30.600
That's where AI cannot do a good job.

01:30.600 --> 01:31.760
We need to focus on that.

01:31.760 --> 01:35.200
There's three important things about AI thinking.

01:35.200 --> 01:36.400
With the first thing,

01:36.400 --> 01:39.640
you need to have general understanding of how AI works.

01:39.640 --> 01:44.640
In the past, AI is basically mostly based on the rules

01:44.760 --> 01:49.200
or the specific algorithms that we write in the computer.

01:49.200 --> 01:50.720
The human set the rules.

01:50.720 --> 01:55.720
And then now we developed a different algorithms

01:56.080 --> 01:59.640
like deep learning, reinforcement learning based on data

01:59.640 --> 02:03.080
because we have much more powerful computers

02:03.080 --> 02:05.440
that can handle way more data.

02:05.440 --> 02:07.200
And then they will develop

02:07.200 --> 02:10.200
and trying to find the most optimized solution

02:10.200 --> 02:11.280
based on the current data.

02:11.280 --> 02:12.720
And then the more data you have,

02:12.720 --> 02:15.480
the better solution you usually will get.

02:15.480 --> 02:17.320
If you do the first one,

02:17.320 --> 02:20.400
the second one is that you will gain the ability

02:20.400 --> 02:22.680
to differentiate the human ability

02:22.680 --> 02:25.920
versus the machine's ability or AI's ability.

02:25.920 --> 02:27.600
I think probably most of the audience

02:27.600 --> 02:30.760
don't know there's a scientific research area

02:30.760 --> 02:32.880
called a structural biology.

02:32.880 --> 02:36.560
Scientists in this field study the structure of a protein.

02:36.560 --> 02:39.440
Proteins are so important for all the living creatures.

02:39.440 --> 02:43.440
The whole world have like 100 to 200 million proteins.

02:43.440 --> 02:45.400
This research area like scientists,

02:45.400 --> 02:46.800
a lot of them are focusing on

02:46.800 --> 02:49.120
determining the structure of these proteins.

02:49.120 --> 02:53.600
We human only find just a very little number

02:53.600 --> 02:55.480
of these proteins like the structures of it,

02:55.480 --> 02:56.640
less than 1%.

02:56.640 --> 02:59.080
However, this AI is called alpha fold.

02:59.080 --> 03:00.560
That's from deep mind.

03:00.560 --> 03:02.040
In the past two years,

03:02.040 --> 03:04.960
alpha fold predict like the structure

03:04.960 --> 03:07.760
of almost all the proteins in the world.

03:07.760 --> 03:10.880
And they put it in the open database online.

03:10.880 --> 03:13.640
So a job, once the machines can do it,

03:13.640 --> 03:15.040
then let the machines do it.

03:15.040 --> 03:17.040
And then we focus on the human part.

03:17.080 --> 03:18.640
After you get the first two,

03:18.640 --> 03:22.240
the third one is you will have the ability to work with AI,

03:22.240 --> 03:24.760
use AI to help you to accomplish other jobs.

03:24.760 --> 03:27.560
There's critical part is from zero to one,

03:27.560 --> 03:29.720
which basically that we invent something

03:29.720 --> 03:31.360
that doesn't exist before.

03:31.360 --> 03:34.000
And we probably can do zero to one better

03:34.000 --> 03:37.320
with AI providing a lot of information and things like that.

03:37.320 --> 03:41.800
So we should prepare our kids to learn how to innovate,

03:41.800 --> 03:44.880
to generate new ideas, to use AI to help us,

03:44.880 --> 03:45.880
that kind of stuff.

03:48.040 --> 03:53.040
Creativity, it's something that is really hard to teach.

03:54.840 --> 03:58.080
Or some people think creativity cannot be taught.

03:58.080 --> 04:00.680
How to teach people creativity.

04:00.680 --> 04:03.560
This thing get changed by the Stanford design thinking.

04:03.560 --> 04:06.120
We can use this method to teach you

04:06.120 --> 04:08.720
how to systematically to make innovations.

04:08.720 --> 04:12.320
Design thinking is a methodology that we use here

04:12.320 --> 04:15.760
at Stanford to teach people how to make innovations.

04:15.760 --> 04:20.720
And we do not make you as innovative or creative

04:20.720 --> 04:23.000
as Steve Jobs or Elon Musk.

04:23.000 --> 04:25.760
However, we can use this methodology

04:25.760 --> 04:30.280
to make you more creative or innovative than yourself.

04:30.280 --> 04:33.880
So design thinking has steps that you can follow.

04:33.880 --> 04:35.920
The first step is empathize.

04:35.920 --> 04:38.880
First, you have to understand who you're invent for.

04:38.880 --> 04:40.680
Are you inventing for your parents

04:40.680 --> 04:44.280
or you're inventing for children who are studying in the school?

04:44.280 --> 04:46.320
You have to understand who are the users.

04:46.320 --> 04:49.480
Then you empathize with them, especially their emotion.

04:49.480 --> 04:52.800
And then you go to the second step, which is called define.

04:52.800 --> 04:56.080
A lot of people, they didn't have the right problem

04:56.080 --> 04:56.920
to start with.

04:56.920 --> 04:59.240
Then you have to define that problem clearly.

04:59.240 --> 05:02.800
And then you go to the third step, which is ideation,

05:02.800 --> 05:06.680
which is using brainstorming to generate a lot of ideas.

05:06.680 --> 05:10.000
And then you kind of get feedbacks from the users.

05:10.000 --> 05:12.400
You pick the good ones to prototype.

05:12.400 --> 05:15.040
After you do the prototype, which is the fourth step,

05:15.040 --> 05:18.200
you do test with the user and then you get feedback.

05:18.200 --> 05:20.960
Maybe the feedback is good or maybe the feedback is bad,

05:20.960 --> 05:23.960
but you have to do redesign or reinvent.

05:23.960 --> 05:28.160
We have a phrase called all design is redesign.

05:28.160 --> 05:31.280
If you realize, well, I actually didn't define

05:31.280 --> 05:33.920
this problem right, then you go back to the step two.

05:33.920 --> 05:36.360
So you have to go in this iterations.

05:36.360 --> 05:40.520
Eventually you will have some very nice inventions.

05:40.560 --> 05:44.520
But when you read books and or you listen to some lectures,

05:44.520 --> 05:47.840
whatever, after you finish in that,

05:47.840 --> 05:49.440
you didn't understand it yet.

05:49.440 --> 05:52.440
You have to use it several times to really feel it.

05:52.440 --> 05:56.360
Let me give you an example in one of the class at Stanford.

05:56.360 --> 06:00.880
So basically this project is about how to get good incubators,

06:00.880 --> 06:03.400
get more incubators for the Nepal.

06:03.400 --> 06:06.400
At first that, actually a lot of people are just trying

06:06.400 --> 06:08.600
to say, well, just design it in California.

06:08.600 --> 06:12.040
But then we say, well, you have to gain empathy.

06:12.040 --> 06:15.000
You need to go to the real place.

06:15.000 --> 06:16.400
If you have never been to Nepal,

06:16.400 --> 06:18.000
how can you design for that?

06:18.000 --> 06:20.920
They actually fly to Nepal and they went to the mountains

06:20.920 --> 06:24.240
and to their surprise, they actually see a lot of these

06:24.240 --> 06:27.240
expensive incubators in these medical centers.

06:27.240 --> 06:29.840
They actually are not lack of those machines,

06:29.840 --> 06:31.360
but they don't know how to operate them.

06:31.360 --> 06:33.640
Problem is they find wrong.

06:33.640 --> 06:35.160
They have to redefine the problem.

06:35.160 --> 06:37.280
And then they went back to these villages

06:37.280 --> 06:39.040
and talk with those farmers.

06:39.040 --> 06:42.240
We do need those things, but not in these medical centers.

06:42.240 --> 06:43.560
We need in our home.

06:43.560 --> 06:44.720
We need the cheap ones.

06:44.720 --> 06:47.680
So then they actually design a very cheap,

06:47.680 --> 06:51.280
like kind of functioning as a baby incubator

06:51.280 --> 06:53.080
and have very good success.

06:53.080 --> 06:54.720
When that's a good example,

06:54.720 --> 06:57.560
the problem was defined wrong at first.

06:57.560 --> 07:00.920
And then they go into this design thinking process

07:00.920 --> 07:03.040
and they find a way to redesign the problem.

07:03.040 --> 07:05.560
And then they solve their right problem.

07:08.280 --> 07:11.760
The most interesting thing about AI robotics,

07:11.760 --> 07:12.720
there's a few of them.

07:12.720 --> 07:14.640
I think the first one is chat GPT

07:14.640 --> 07:18.520
because it's probably a surprise for a lot of people

07:18.520 --> 07:22.560
that AI can talk with people in that a very natural way.

07:22.560 --> 07:25.080
And also it can not only chat with you,

07:25.080 --> 07:26.800
it can also write code for you.

07:26.800 --> 07:28.800
It seems like he knows a whole lot

07:28.800 --> 07:30.880
and it's smarter than a lot of people

07:30.880 --> 07:32.720
and which surprise people.

07:32.720 --> 07:36.240
So, and also it's gonna change education for sure

07:36.240 --> 07:40.240
because now kids can use chat GPT to write essays

07:40.240 --> 07:41.080
and do homeworks.

07:41.080 --> 07:43.600
So then teachers need to think about

07:43.600 --> 07:44.840
how to deal with that.

07:44.840 --> 07:49.840
Actually, I just gave my student an assignment yesterday.

07:50.320 --> 07:52.480
I asked a student to write an essay.

07:52.480 --> 07:54.040
I said, well, you know what?

07:54.040 --> 07:57.080
We just talked about chat GPT in a class.

07:57.080 --> 07:59.880
Now I'm gonna give you an assignment to write an essay

07:59.880 --> 08:01.640
with the help of chat GPT.

08:01.640 --> 08:03.440
I'm not really asking you to not use it.

08:03.440 --> 08:04.440
I ask you to use it.

08:04.440 --> 08:05.960
And then after that class,

08:05.960 --> 08:09.040
I will have short discussions with each of you

08:09.040 --> 08:10.560
and tell me how you use it.

08:10.560 --> 08:11.440
How do you feel it?

08:11.440 --> 08:14.600
I think that technology advancement,

08:14.600 --> 08:19.320
you cannot try to ignore it or trying to avoid it.

08:19.320 --> 08:21.920
It's happening and it's just like water.

08:21.920 --> 08:23.240
You cannot block it.

08:23.240 --> 08:25.160
You have to go with it.

08:25.160 --> 08:29.040
For me, I want to understand how chat GPT

08:29.040 --> 08:31.240
is gonna impact education system.

08:31.240 --> 08:33.480
And I wanna work with our students

08:33.480 --> 08:35.240
to understand that better.

08:35.240 --> 08:38.080
So that's why I gave this homework for my students.

08:39.680 --> 08:42.400
I'm a big fan of Autobots, Transformers.

08:42.400 --> 08:45.440
I grew up with those cartoons and I'm a big fan of it.

08:45.440 --> 08:49.360
Even now, I'm still a big fan of Optimus Prime.

08:49.360 --> 08:50.960
And that really inspired me

08:50.960 --> 08:53.320
that I always wanna make cool robots

08:53.320 --> 08:54.680
like when I was a little kid.

08:54.680 --> 08:58.400
And I think most kids, they have a dream when they're young.

08:58.400 --> 09:00.760
It's easier to inspire a dream

09:00.760 --> 09:02.840
when someone's in early ages.

09:02.840 --> 09:06.240
After people grow up, they kinda lose their interest.

09:06.240 --> 09:07.200
They lose their dream.

09:07.200 --> 09:08.240
They don't know what to do.

09:08.240 --> 09:12.400
It's actually critical important for these little minds

09:12.400 --> 09:13.760
to have dreams.

09:13.760 --> 09:17.120
My ultimate goal is to find out

09:17.120 --> 09:21.080
what is the ideal education system for the future.

09:21.080 --> 09:23.800
The education part is really important.

09:23.800 --> 09:27.880
It has profound impact on the next generation's future.

09:27.880 --> 09:29.800
And that's my ultimate goal.

