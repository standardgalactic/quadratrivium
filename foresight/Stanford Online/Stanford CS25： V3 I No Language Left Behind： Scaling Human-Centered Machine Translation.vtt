WEBVTT

00:00.000 --> 00:10.000
We're glad to have Angela Fan today with us here.

00:10.000 --> 00:15.960
And she's a research scientist at Meta AI Research in New York, focusing on research

00:15.960 --> 00:18.280
in text generation mainly.

00:18.280 --> 00:24.880
And currently she's working on language modeling and developing the line AI agents, metaproducts,

00:24.880 --> 00:29.200
and recent research products include no language left behind, which she'll be talking briefly

00:29.200 --> 00:35.760
about today, universal speech translation for unwritten languages, as well as Lama2.

00:35.760 --> 00:38.280
So give it up for Angela, I guess.

00:38.280 --> 00:41.480
All right, thank you all so much.

00:41.480 --> 00:44.880
So yeah, when I got this email, I was like, oh, I should probably talk about Lama2.

00:44.880 --> 00:48.920
But then I noticed you have Sharon, who will like, you know, is like a 10x better speaker

00:48.920 --> 00:49.920
than me.

00:49.920 --> 00:52.000
So I was like, okay, like maybe not Lama2.

00:52.000 --> 00:55.600
But then I thought I maybe would cover this project that we did called No Language Left

00:55.600 --> 00:59.880
Behind, which could be very, also very relevant to this class.

00:59.880 --> 01:07.880
And so when you think about a lot of text generation technology, most of it, until fairly recently,

01:07.880 --> 01:10.360
has been really focused on English.

01:10.360 --> 01:14.440
But there are actually more than 3000 written languages worldwide.

01:14.440 --> 01:20.040
And for me, this is extremely personally meaningful because actually English is my third language.

01:20.040 --> 01:22.040
So it's really important.

01:23.040 --> 01:26.880
Yeah, so it's really also very personally meaningful.

01:26.880 --> 01:31.600
And when you think about some of the multilingual technology that permeates, it's not like we've

01:31.600 --> 01:33.800
never worked on multilingual, right?

01:33.800 --> 01:37.880
Actually, when speaking about generative AI, I actually think translation is one of the

01:37.880 --> 01:42.000
most commercially successful and widespread applications of generative AI.

01:42.000 --> 01:47.240
I mean, ultimately, translation models, they are, you know, like conditional language models.

01:47.240 --> 01:52.120
And so when you think about like traveling or something like that, or my sister is taking

01:52.120 --> 01:56.040
Spanish, so like just like doing her Spanish homework, we have a lot of tools that exist

01:56.040 --> 01:57.040
today.

01:57.040 --> 02:01.840
So things like Google Translate cover around 130 languages, Microsoft Translate about 110.

02:01.840 --> 02:07.680
This might be a little bit outdated since I pulled the statistics a little bit ago.

02:07.680 --> 02:11.480
But the project for No Language Left Behind, it started from like a very simple ask, like,

02:11.480 --> 02:14.320
okay, there's 3000 languages worldwide.

02:14.400 --> 02:20.160
Maybe it'll be like pretty hard to get to all 3000, since some of them are pretty rare

02:20.160 --> 02:21.880
and not spoken by many.

02:21.880 --> 02:27.000
But there are still like hundreds of languages spoken by millions and millions of people.

02:27.000 --> 02:28.920
And so we were like, okay, no big deal.

02:28.920 --> 02:34.160
Like, let's just start from the 100-ish that we have today and just go for like a doubling.

02:34.160 --> 02:38.320
Like, what would it take to actually be able to double this kind of coverage?

02:38.320 --> 02:41.680
And of course, you know, just saying that you support a bunch of languages is not the

02:41.680 --> 02:42.680
goal.

02:42.680 --> 02:47.320
You actually want to create high quality safe translations that would be usable by people

02:47.320 --> 02:51.000
just like if you're going on vacation today, you're kind of instinctive to whip out your

02:51.000 --> 02:54.560
phone and get on the Google Translate app.

02:54.560 --> 02:58.920
And so kind of the backdrop to this project was that there's actually a lot of progress

02:58.920 --> 03:00.240
in translation.

03:00.240 --> 03:04.640
So historically, there's been a lot of focus on what we call higher resource languages.

03:04.640 --> 03:08.600
And these are not necessarily languages that are spoken by the most people in the world.

03:08.600 --> 03:12.200
But when we say higher resource, it means the most amount of data.

03:12.200 --> 03:16.880
And so you can think about things like Europarl or, you know, translations from the European

03:16.880 --> 03:17.880
Parliament.

03:17.880 --> 03:22.200
And those served as the foundation for a lot, a lot of translation development.

03:22.200 --> 03:26.360
And more recently, there's been a great focus on low resource languages, and it's been driven

03:26.360 --> 03:32.320
across the research community with groups like Ghana NLP, Masekane, America's NLP.

03:32.320 --> 03:34.760
And these are all really exciting developments.

03:34.760 --> 03:39.920
And so these have led to a lot of development of new data sets, as well as criticisms of

03:39.920 --> 03:44.880
existing data sets, and also work on new languages, and usually languages that people

03:44.880 --> 03:47.120
kind of speak and they care a lot about.

03:47.120 --> 03:49.800
And we found this like really, really exciting.

03:49.800 --> 03:54.320
And so looking at a lot of this, a bunch of us got together at fair and started thinking

03:54.320 --> 03:59.080
like, okay, we actually speak some pretty low resource languages from like Catalan to

03:59.080 --> 04:01.040
Ossamese and so on.

04:01.040 --> 04:04.640
And so we started this as kind of like a big, passionate research project.

04:04.640 --> 04:09.520
And so today, I want to cover a little bit about our high level approach to this problem,

04:09.520 --> 04:11.640
which is a little bit interdisciplinary.

04:11.640 --> 04:16.040
I want to talk about how we actually created the data sets to be able to support this kind

04:16.040 --> 04:17.040
of work.

04:17.040 --> 04:21.760
Of course, I want to talk about the models, since this is a class about transformers.

04:21.760 --> 04:25.040
One note here, I think that's actually very interesting in terms of translation as like

04:25.040 --> 04:30.680
a research direction, is that actually a lot of innovations have been done in translation.

04:30.680 --> 04:35.120
The original transformer paper, I think is one of them, and which makes always translation

04:35.120 --> 04:37.560
a quite interesting area to work on.

04:37.600 --> 04:40.880
Because I feel like it's a very mature research area as well.

04:40.880 --> 04:44.760
So it kind of is like, okay, if your architecture works in translation, it probably works very

04:44.760 --> 04:45.760
generally.

04:45.760 --> 04:49.760
So that's also one of the things that excites me about translation research.

04:49.760 --> 04:53.200
Then I want to talk about evaluation, like how are we actually measuring and ensuring

04:53.200 --> 04:57.200
the quality of these translations are good and safe for people.

04:57.200 --> 05:00.840
And then I want to end with a little bit of like, you know, high level thoughts about

05:00.840 --> 05:05.560
future directions and things that I hope that we can work on in the future.

05:05.560 --> 05:08.120
So I want to start with our approach.

05:08.120 --> 05:12.360
I think the most important thing in research is to know that we're working on a real problem,

05:12.360 --> 05:16.600
especially when it's really close to people like translation.

05:16.600 --> 05:20.760
And I think in many areas, like when I was working on on-device AI, for example, I feel

05:20.760 --> 05:25.280
like I had like a research problem in mind, but it was like very, very disconnected from

05:25.280 --> 05:28.320
the practical problem of actually putting models on phones.

05:28.320 --> 05:30.800
And so this was something that was really important to us.

05:30.800 --> 05:35.480
And so we actually started the project by kind of like focusing on a social sciences

05:35.480 --> 05:39.200
type approach or, you know, sociology type approach.

05:39.200 --> 05:42.840
And we actually did a lot of interviews with low resource speakers.

05:42.840 --> 05:48.280
And so we met with about 44 different native speakers that spoke 36 different languages

05:48.280 --> 05:50.360
across North America.

05:50.360 --> 05:54.320
I will say that a lot of them are like immigrants to the US, since that was kind of like the

05:54.320 --> 05:57.360
easiest kind of cohort to recruit.

05:57.360 --> 06:01.960
And we learned a lot of different things about how they approach low resource languages,

06:01.960 --> 06:04.240
but also the kind of technological need that they have.

06:04.240 --> 06:08.360
Because I think it's easy to be like, hey, I have this cool background, like I have this

06:08.360 --> 06:11.680
cool problem, and I want to solve it, but I think it's very important to actually like

06:11.680 --> 06:15.280
talk to the people if this is a problem that needs to be solved.

06:15.280 --> 06:19.480
And so we learned that there's great fear in general that low resource languages might

06:19.480 --> 06:25.960
be undergoing a state of decline, partially because a lot of education is shifting to

06:25.960 --> 06:30.240
languages like Hindi or like English or Mandarin Chinese, for example.

06:30.240 --> 06:34.640
And there's a lot of excitement to be included in existing translation systems.

06:34.640 --> 06:39.560
And people said they have always tried to use Google translator, Microsoft translate

06:39.560 --> 06:41.240
in their existing languages.

06:41.240 --> 06:45.400
But ultimately they found that the quality is really insufficient for reliable usage.

06:45.400 --> 06:49.080
So if you think about like, well, I was going to say when I was in high school, but you're

06:49.080 --> 06:51.080
all probably like substantially younger than me.

06:51.080 --> 06:54.680
So maybe like, you know, 10, so years ago, you know, and you tried to use Google translate

06:54.680 --> 06:58.640
for your Spanish homework, like your Spanish teacher could always identify that like, you

06:58.640 --> 07:01.960
know, it was not a human written translation until you would get marks off.

07:01.960 --> 07:06.040
But that's not really the case for some of the high resource languages today.

07:06.040 --> 07:10.520
And so I think as with all things in machine learning, it really starts from a data perspective.

07:10.520 --> 07:14.560
Like why can't we just train models in hundreds of languages or large language models in hundreds

07:14.560 --> 07:15.560
of languages?

07:15.560 --> 07:17.840
It's because we don't have the data to support it.

07:17.840 --> 07:22.480
And so I want to talk first about evaluation data sets because I think it's extremely important

07:22.480 --> 07:24.840
to nail evaluation.

07:24.840 --> 07:27.160
And then I'll talk about training.

07:27.160 --> 07:32.800
So for an evaluation data set for this work, we started this Flora's effort, it stands

07:32.800 --> 07:36.880
for Facebook low resource, I guess we're called meta now, but I didn't think more as was like

07:36.880 --> 07:41.040
a very good, a renaming so we're still calling it Flora's.

07:41.040 --> 07:45.480
So this was something we originally started for just two languages in this first paper

07:45.480 --> 07:48.320
at EMLP, many years ago.

07:48.320 --> 07:50.560
So it was just for Napoleon Sinhalo.

07:50.560 --> 07:55.280
And we later extended it to incorporate two more languages in a release afterwards.

07:55.280 --> 08:00.440
You know, we thought a lot about, okay, like Flora's was really useful for the community.

08:00.440 --> 08:02.280
How can we extend it to 100 languages?

08:02.280 --> 08:08.160
And so that was this follow up work that we did, I think we had at ACL or WMT.

08:08.160 --> 08:13.480
And then in this project, we were like, okay, how can we go from Flora's 101 to Flora's

08:13.480 --> 08:16.640
200 to really go for the doubling effect?

08:16.640 --> 08:17.640
And so what is Flora's?

08:17.640 --> 08:19.080
Well, it's in the name.

08:19.080 --> 08:21.480
It's a focus on low resource languages.

08:21.480 --> 08:26.720
So we do include some higher resource languages like German or Hindi or so on, almost for

08:26.720 --> 08:29.040
calibration effect as well.

08:29.040 --> 08:33.480
But the majority of the focus is on these lower and mid resource languages.

08:33.480 --> 08:39.200
It's the first large scale, many to many machine translation evaluation data set, which means

08:39.200 --> 08:43.880
that we take all of the sentences in English and then we translate them to all of the languages,

08:43.880 --> 08:48.440
which means that you would be able to evaluate any cross pair of languages.

08:48.440 --> 08:52.160
So for example, like Chinese to French, I lived in France for many years.

08:52.160 --> 08:54.080
So it's like very personally relevant to me.

08:54.080 --> 08:58.760
Of course, 200 languages also in the name, there's a broad diversity of different domains

08:58.760 --> 08:59.760
and topics.

08:59.760 --> 09:04.200
I think this is important when designing an evaluation data set, which is like very top

09:04.200 --> 09:10.120
of mind for anybody interested in language modeling research, because like the way people

09:10.120 --> 09:15.320
train machine translation models and the way people use them are often like very different.

09:15.320 --> 09:19.240
And so if you only benchmark your data set, for example, on news, which is very common

09:19.240 --> 09:23.720
in translation research, then you don't really pick up the fact that people talk about such

09:23.720 --> 09:28.320
a wide variety of things and have like different casual conversations that they need translated

09:28.320 --> 09:31.040
official documents and so on.

09:31.040 --> 09:33.200
It's also document level data set.

09:33.200 --> 09:36.840
This is not something that I think the community is like broadly leveraging right now.

09:36.840 --> 09:40.800
But the way it's translated is that you can have document level context.

09:40.800 --> 09:44.440
And so translators are provided the entire document to translate from.

09:44.440 --> 09:49.480
We also provide the entire document for evaluation and we translate like multiple sentences from

09:49.480 --> 09:50.760
the same paragraph.

09:50.760 --> 09:54.880
And so this was like a potential to research direction that we wanted to make sure we covered

09:54.880 --> 09:58.880
models that needed like potentially more context because a lot of translation work is done

09:58.880 --> 10:00.960
at the sentence level.

10:00.960 --> 10:04.000
So how do we actually ensure that this data set was high quality?

10:04.000 --> 10:06.720
So the first step is that we take a document.

10:06.720 --> 10:10.320
Well, actually, first step is like alignment on language standards.

10:10.320 --> 10:15.280
So this is very important because when you're translating French or Chinese, I think most

10:15.280 --> 10:19.360
people have a strong understanding of like what it means to produce like a good French

10:19.360 --> 10:20.840
or good Chinese.

10:20.840 --> 10:24.200
And there are a lot of professional translators hired in these languages.

10:24.200 --> 10:28.320
But when you go to lower resource languages, it's not necessarily the case that there's

10:28.320 --> 10:35.440
like a glowing translation industry around translating a lower resource language.

10:35.440 --> 10:40.160
And so one of the first things is actually to align on like what is a high quality translation?

10:40.160 --> 10:42.600
And so there's actually a lot of challenges here.

10:42.600 --> 10:45.640
So there are certain low resource languages where there's different competing language

10:45.640 --> 10:50.480
standards or there's like very high variance in different regions on how languages are

10:50.480 --> 10:51.600
spoken.

10:51.600 --> 10:54.320
And so this step is a pretty critical one.

10:54.320 --> 10:58.600
So then what we do is we take the document, we send it to one group of translators and

10:58.600 --> 11:00.920
they do the first translation step.

11:00.920 --> 11:05.000
Then we do some automatic checking, you know, like if the input sentence was like 10 words

11:05.000 --> 11:09.400
and the output sentence is like 300 words, it's like most likely something went wrong,

11:09.880 --> 11:11.440
and so we send it back.

11:11.440 --> 11:17.920
Otherwise, we'll send it onwards to a separate, completely independent set of translators

11:17.920 --> 11:19.160
that do review.

11:19.160 --> 11:21.360
And so they try to rate the quality of this.

11:21.360 --> 11:25.480
And if the quality doesn't pass the sufficient bar, it gets sent back to the original set

11:25.480 --> 11:30.680
of translators to edit and they kind of go through and like address all of the feedback.

11:30.680 --> 11:34.560
And then if it's good enough, then it enters our data set.

11:34.560 --> 11:36.400
And so there's many challenges here.

11:36.440 --> 11:41.280
The first one, of course, is just like finding translators and also finding more translators.

11:41.280 --> 11:45.880
There was a certain issue that we ran into, for example, that in a certain country that

11:45.880 --> 11:47.880
the internet was not available.

11:47.880 --> 11:51.400
And so, you know, it's a lot of recruitment.

11:51.400 --> 11:54.040
The other one, of course, is language standardization.

11:54.040 --> 11:59.880
I think I briefly mentioned this before, but there's a lot of different challenges in just

11:59.880 --> 12:02.480
understanding like what is a high quality translation.

12:02.480 --> 12:05.000
For example, the low resource language, Breton.

12:05.000 --> 12:08.440
There's like two competing groups on like, how do you write Breton?

12:08.440 --> 12:11.200
So it's like very difficult to resolve some of those things.

12:11.200 --> 12:16.520
And the final thing is that there's actually a lot of variation, even in languages like Arabic,

12:16.520 --> 12:22.600
like the Arabic, like Moroccan Arabic is very different from, you know, Jordanian Arabic and so on.

12:22.600 --> 12:27.400
And there are also certain regions that they speak the same language, but due to historical reasons,

12:27.400 --> 12:29.240
they write in different scripts.

12:29.240 --> 12:33.600
And so one of the things we actually did was like, if there are languages written in multiple scripts,

12:33.600 --> 12:37.560
we actually supported the collection of a multiple script evaluation.

12:37.560 --> 12:41.880
And I think this is really important because if you're building an underlying technology

12:41.880 --> 12:46.600
and you only choose one, then I think you risk like just kind of like naturally supporting

12:46.600 --> 12:51.720
one over the other when we really should be like kind of a more neutral technology provider.

12:51.720 --> 12:57.440
And so this is something that we we explored a lot as well as exploring different variants of Arabic.

12:57.440 --> 12:58.480
This is also open source.

12:58.480 --> 13:03.560
If you just go to this link, you can just like download all of the all of the text files for this.

13:03.760 --> 13:09.040
With evaluation done, I want to talk a little bit about how we collected some of these training data sets.

13:09.040 --> 13:13.880
The first thing I want to talk about is this data set we created called NLBCD.

13:13.880 --> 13:18.960
And the idea of this is like it's a really seed data set of high quality translations

13:18.960 --> 13:21.160
and languages that really don't have anything.

13:21.160 --> 13:26.160
Why? Because, well, you can't start from nothing, you know, you got a bootstrap from somewhere.

13:26.160 --> 13:32.320
A lot of people have been using the Bible as a way to bootstrap, but it's very limited domain,

13:32.320 --> 13:34.280
obviously very religious text.

13:34.280 --> 13:41.400
And so we created this data set NLBCD for languages that really don't have anything to get started from.

13:41.400 --> 13:46.520
It's only about 5,000 sentences, so it's nothing crazy, but it supports a lot of different use cases

13:46.520 --> 13:51.720
like training language identification models or sentence encoders, engram language models,

13:51.720 --> 13:54.800
like all of these things that I'm about to talk about in our data set pipeline.

13:56.040 --> 13:59.680
So it covers 43 languages, about 6,000 sentences.

13:59.800 --> 14:03.840
And the way we decided to sample it is focused on really general content.

14:03.840 --> 14:08.400
So Wikipedia has this article of like, hey, if you're going to start like a new Wikipedia

14:08.400 --> 14:13.840
in your new language, I think Wikipedia has like 309-ish Wikipedia's last I checked.

14:13.840 --> 14:17.600
Here's like a list of articles that every Wikipedia in a new language should have.

14:17.600 --> 14:20.640
And so that's where we sampled this original content from.

14:20.640 --> 14:24.840
And of course, it's also open source if you want to download it.

14:24.880 --> 14:30.600
So what we ended up doing to get large-scale training data is using mining.

14:30.600 --> 14:33.200
So this is not something we pioneered in this project.

14:33.200 --> 14:35.600
We have like a bunch of different previous work.

14:35.600 --> 14:37.800
So we started from Wikimatrix.

14:37.800 --> 14:41.600
We were like, hey, there's a lot of different sentences in Wikipedia

14:41.600 --> 14:44.280
and different languages that we should be able to match up.

14:44.280 --> 14:49.520
And so we tried to do that with Wikipedia to get machine translation training data.

14:49.520 --> 14:52.480
We extended that to the web in the CCMatrix project,

14:52.520 --> 14:56.680
and then we extended it to very, very large-scale mining on all cross-pairs

14:56.680 --> 15:00.680
in this project on beyond English-centric multilingual machine translation.

15:00.680 --> 15:04.320
We really tried to ditch like English as a central pivot language.

15:04.320 --> 15:07.200
And so the way this whole data mining thing works

15:07.200 --> 15:09.680
is that it focuses on sentence alignment.

15:09.680 --> 15:11.560
So everyone is probably super familiar with this

15:11.560 --> 15:13.320
because this is how language models are built now.

15:13.320 --> 15:17.520
But it's like you take Common Crawl or any other open source dump of the web.

15:17.520 --> 15:20.560
I don't know, like Red Pajama or like whatever you want to CCNet,

15:20.560 --> 15:22.320
whatever you want to use these days.

15:22.320 --> 15:25.960
And you take all of the data, you extract all of the text,

15:25.960 --> 15:28.720
you know, a lot of HTML parsing and so on goes into it.

15:28.720 --> 15:31.640
And the idea is that we want to try to find matching text

15:31.640 --> 15:33.080
that could be a translation.

15:33.080 --> 15:35.240
So we shatter it all into sentences,

15:35.240 --> 15:38.360
we embed them with different sentence encoder models,

15:38.360 --> 15:42.040
and then we do a match to try to understand in a multilingual space

15:42.040 --> 15:44.680
if the sentences match.

15:44.680 --> 15:47.000
And so one of the biggest challenges to this

15:47.000 --> 15:50.600
is that the quality of the sentence encoding is very important.

15:50.600 --> 15:52.720
So if your sentence encoding is not very accurate,

15:52.720 --> 15:55.760
then it's impossible to match in this multidimensional space

15:55.760 --> 15:58.480
the idea of like the meaning being the same.

15:58.480 --> 16:00.880
And so one of the big things we tried to do here

16:00.880 --> 16:05.360
in this project was try to improve the quality of the sentence encoders.

16:05.360 --> 16:08.760
And so one of the big things that we did was train sentence encoders

16:08.760 --> 16:10.240
with mask language modeling.

16:10.240 --> 16:11.520
You see that on the left.

16:11.520 --> 16:16.400
But we also use multilingual distillation, which you see on the right.

16:16.400 --> 16:19.840
And so previous approaches to sentence encoders

16:19.840 --> 16:22.240
and the trend in the research community for a while

16:22.240 --> 16:25.360
was to really try to embed all languages

16:25.360 --> 16:27.200
in the same sentence encoder model.

16:27.200 --> 16:30.880
So projects like XLMR, for example, are in that direction.

16:30.880 --> 16:33.160
I think it's pretty widely used.

16:33.160 --> 16:36.240
The challenge with this when you're training a low resource model

16:36.240 --> 16:38.640
is that a lot of your high resource data

16:38.640 --> 16:41.960
just overwhelms your low resource data.

16:41.960 --> 16:45.040
And so you don't end up with a very high quality sentence encoder

16:45.040 --> 16:46.320
for those languages.

16:46.320 --> 16:49.640
So what we ended up doing is we had a multilingual teacher model

16:49.680 --> 16:52.520
and we distilled a bunch of student models

16:52.520 --> 16:56.440
that are specialized to different language families

16:56.440 --> 16:57.680
that are low resource.

16:57.680 --> 17:00.200
And so this enables the quality to be pretty high.

17:00.200 --> 17:02.000
And so the way that distillation works

17:02.000 --> 17:05.400
is that the teacher and the student model both see the same data

17:05.400 --> 17:08.360
and then we try to minimize the cosine loss

17:08.360 --> 17:12.480
between the sentence embeddings that they produce.

17:12.480 --> 17:14.360
I think an important question that you can ask here

17:14.360 --> 17:17.520
is why do you need to do multilingual distillation?

17:17.520 --> 17:21.280
Why can't you just train a bunch of different student models,

17:21.280 --> 17:22.720
like one per language family,

17:22.720 --> 17:25.040
like why even care about distillation?

17:25.040 --> 17:27.880
And the reason is because if you're going to use a bunch

17:27.880 --> 17:29.960
of sentence encoders for mining,

17:29.960 --> 17:31.880
the important thing is that they all exist

17:31.880 --> 17:34.160
in the same embedding space.

17:34.160 --> 17:35.680
Like if you train one separate model

17:35.680 --> 17:36.800
and another separate model,

17:36.800 --> 17:39.160
there's nothing constraining them

17:39.160 --> 17:41.960
so that you can mine all of the data against each other.

17:41.960 --> 17:43.760
And so one of the things we found

17:43.760 --> 17:46.640
is that by starting everything from the same teacher model

17:46.640 --> 17:48.280
and trying to use this cosine loss

17:48.280 --> 17:50.520
to minimize the distance between embeddings,

17:50.520 --> 17:52.960
you are able to have this constrained space

17:52.960 --> 17:56.080
where you can mine every language against every other,

17:56.080 --> 17:58.840
even if you have different student models.

17:58.840 --> 18:01.760
And so this graph on the Y axis,

18:01.760 --> 18:05.040
it shows the error rate of mining.

18:05.040 --> 18:06.600
And so lower is better.

18:06.600 --> 18:07.840
And on the X axis,

18:07.840 --> 18:10.040
it shows a bunch of different low resource languages.

18:10.040 --> 18:11.760
So for example, the first one is Urdu,

18:11.760 --> 18:14.120
the second one is Telugu,

18:14.120 --> 18:16.080
third one is Tagalog, and so on.

18:16.120 --> 18:19.760
And so the gray bar here is the original laser paper.

18:19.760 --> 18:22.680
So this is a paper we put out maybe in 2018-ish

18:22.680 --> 18:24.280
and we had all of these languages

18:24.280 --> 18:25.720
with count of them as included.

18:25.720 --> 18:26.560
But as you can see,

18:26.560 --> 18:29.200
the error rate is extremely, extremely high

18:29.200 --> 18:30.200
for these languages.

18:30.200 --> 18:32.320
So even though they were included,

18:32.320 --> 18:34.520
couldn't really be used for high quality.

18:34.520 --> 18:37.880
And the blue bar is the laser model that we trained

18:37.880 --> 18:40.760
based on the technique I just described in the previous slide.

18:40.760 --> 18:42.400
And you can see that I think the most important point

18:42.400 --> 18:44.160
is that you can barely see the blue bars.

18:44.160 --> 18:45.680
So it was very effective

18:45.680 --> 18:47.480
even for these previous languages

18:47.480 --> 18:50.800
that people had thought we had previously embedded.

18:51.680 --> 18:53.560
And then so now how does this kind of thing

18:53.560 --> 18:56.680
fit into a whole data pipeline around this approach?

18:56.680 --> 18:58.960
So one of the most important things

18:58.960 --> 19:01.480
is when you download the data from the web,

19:01.480 --> 19:04.280
you don't really know what language it's in.

19:04.280 --> 19:07.320
And so this is part of all of the large scale data cleaning

19:07.320 --> 19:10.480
that goes into training large language models today.

19:10.480 --> 19:13.640
And so the way we identify different languages

19:13.760 --> 19:15.560
is through like simple classification models

19:15.560 --> 19:18.280
called language identification models.

19:18.280 --> 19:20.760
And I think it's a classification model.

19:20.760 --> 19:24.480
And so people think it's easier than it actually is.

19:24.480 --> 19:26.480
But I think some of the major challenges

19:26.480 --> 19:29.120
are that there's so many different languages.

19:29.120 --> 19:30.880
They're written in many different ways

19:30.880 --> 19:33.840
and web text is very casual.

19:33.840 --> 19:35.120
And so it can be very difficult

19:35.120 --> 19:37.440
to actually train a good classification model

19:37.440 --> 19:38.960
that can generalize to them.

19:38.960 --> 19:40.440
And so what we did is,

19:40.440 --> 19:43.520
we had our LID training data

19:43.520 --> 19:47.400
and we produced a language identification model LID.

19:47.400 --> 19:49.720
And then we actually did human evaluation

19:49.720 --> 19:52.560
to label errors coming from the LID system

19:52.560 --> 19:55.760
to iteratively improve this on web text itself

19:55.760 --> 19:58.720
to improve the quality of this specific model.

19:58.720 --> 20:00.560
Then after we produce this LID model,

20:00.560 --> 20:02.520
then we insert like all of our common crawl

20:02.520 --> 20:04.440
where the web arrow is coming in

20:04.440 --> 20:06.760
and we do a ton of filtering and cleaning.

20:06.760 --> 20:09.280
And this produces a huge corpus of different

20:09.320 --> 20:11.440
monolingual data that you can then use

20:11.440 --> 20:13.880
for training anything.

20:13.880 --> 20:16.520
Afterwards, we train our encoder,

20:16.520 --> 20:18.200
what I described on the previous text,

20:18.200 --> 20:20.280
and then we convert this monolingual data

20:20.280 --> 20:22.440
into what we call mined by texts.

20:22.440 --> 20:24.520
So these are a huge data set of things

20:24.520 --> 20:27.440
that we think are translations of each other.

20:27.440 --> 20:30.680
And then finally, what we do is we actually try to validate

20:30.680 --> 20:32.920
that these are real mined by texts

20:32.920 --> 20:36.360
by training very small bilingual multilingual,

20:36.360 --> 20:38.320
sorry bilingual translation models

20:38.360 --> 20:40.880
in order to see what the quality is like.

20:40.880 --> 20:41.880
And I think this is important

20:41.880 --> 20:44.840
because the data development cycle

20:44.840 --> 20:47.680
and the end task that it's being used for,

20:47.680 --> 20:51.120
you don't want to completely separate it.

20:51.120 --> 20:53.720
An analogy to large language model training today

20:53.720 --> 20:56.160
is that when you're doing your pre-training,

20:56.160 --> 20:58.760
you don't want someone to just deliver you a data,

20:58.760 --> 21:00.960
like the data mix of your different data sets

21:00.960 --> 21:01.800
is very important.

21:01.800 --> 21:03.240
And it's pretty similar here.

21:04.480 --> 21:07.520
And I think one of the highlights that we did here

21:07.520 --> 21:10.120
is really focused on the human evaluation

21:10.120 --> 21:12.240
of the language identification model

21:12.240 --> 21:13.880
because that actually improves the quality

21:13.880 --> 21:15.640
of all of the underlying data

21:15.640 --> 21:18.320
if you just more accurately know what language it's in.

21:19.600 --> 21:21.240
And this entire data pipeline

21:21.240 --> 21:23.040
is actually open source in this library

21:23.040 --> 21:25.480
and we had an MNLP paper describing it.

21:25.480 --> 21:27.200
The reason why I thought this was important

21:27.200 --> 21:29.240
is that because I think data cleaning

21:29.240 --> 21:31.560
is actually such a fundamental underlying thing

21:31.560 --> 21:34.880
that drives model quality and people's data pipelines.

21:34.880 --> 21:36.640
It's like, I had this script and this other thing

21:37.640 --> 21:39.520
and so it's actually, I think very important

21:39.520 --> 21:42.240
to be able to recreate it and rerun it

21:42.240 --> 21:45.120
as part of almost like your research

21:45.120 --> 21:47.520
that you would do as follow-up work.

21:47.520 --> 21:49.520
And so that's why we open sourced it.

21:50.560 --> 21:52.400
A few reflection things.

21:53.560 --> 21:54.920
For low resource languages,

21:54.920 --> 21:57.120
even though we did a large scale mining,

21:57.120 --> 21:59.400
I think monolingual data is the limiting factor.

21:59.400 --> 22:01.840
Like there are many languages that do not have

22:01.840 --> 22:04.720
like a huge amount of text written online.

22:04.800 --> 22:08.240
And so it can be very challenging to get a large amount.

22:08.240 --> 22:10.640
Further, I think languages and unique scripts

22:10.640 --> 22:14.240
can be extremely hard to get good representations of

22:14.240 --> 22:16.440
if you don't have very much data.

22:16.440 --> 22:17.800
There are certain languages as well

22:17.800 --> 22:20.440
where they were historically written in a new script

22:20.440 --> 22:22.640
but now the government would like to write it

22:23.840 --> 22:26.720
in a totally new one like the old cheeky script, for example.

22:26.720 --> 22:30.200
And so there's not a lot of content to represent these scripts.

22:30.200 --> 22:32.520
So it's hard to learn representations.

22:32.520 --> 22:35.760
And then further, a lot of the content we create,

22:35.760 --> 22:38.760
it's even after mining, it's a fairly limited domain,

22:38.760 --> 22:40.320
often religious content.

22:41.520 --> 22:44.440
Okay, so with data discussed,

22:44.440 --> 22:48.480
I wanna segue a little bit into some of the modeling work

22:48.480 --> 22:51.880
just to kind of start with like a high level picture.

22:51.880 --> 22:54.040
I think there's like three major challenges

22:54.040 --> 22:57.000
when you talk about like large scale multi-lingual modeling.

22:57.000 --> 23:00.760
And these pretty much apply to language models as well.

23:01.760 --> 23:04.200
The first one is effective data augmentation

23:04.200 --> 23:05.440
for low resource languages.

23:05.440 --> 23:09.120
Like how can you prevent the low resource language data

23:09.120 --> 23:11.120
from just being completely drowned out

23:11.120 --> 23:13.080
by the time you've seen like all of your words

23:13.080 --> 23:14.880
of German or Russian?

23:14.880 --> 23:17.520
I think there's also a question of like scalability

23:17.520 --> 23:18.360
of the model.

23:18.360 --> 23:21.120
So even if you train very large scale models,

23:21.120 --> 23:22.680
how do you prevent the representations

23:22.680 --> 23:25.640
of different languages from interfering with each other?

23:25.640 --> 23:27.600
And that leads to the last point as well

23:27.600 --> 23:30.720
of like if you give the model very limited capacity,

23:30.720 --> 23:32.520
then of course it may not have the capacity

23:32.520 --> 23:35.000
to model all of these different languages.

23:35.000 --> 23:38.320
And so you also need to accelerate the scale of the model.

23:39.280 --> 23:42.000
And so preliminary for those

23:43.360 --> 23:45.680
who may not have seen a translation system before,

23:45.680 --> 23:48.040
I don't know how many of you that practically is.

23:48.040 --> 23:50.640
So we use standard sequence-to-sequence models.

23:50.640 --> 23:52.640
So the input text, the like coral thing

23:52.640 --> 23:54.200
is like what you wanna translate

23:54.200 --> 23:56.760
and there's a transformer decoder model

23:56.760 --> 23:58.520
that then with a tension mechanism

23:58.520 --> 24:00.560
goes to a transformer decoder model.

24:00.560 --> 24:03.080
And then it decodes autoregressively

24:03.080 --> 24:05.920
the actual translation, which you can see here in yellow.

24:06.960 --> 24:10.000
And so I wanna talk a little bit about like how

24:10.000 --> 24:12.680
the data looks as we feed it into the models.

24:12.680 --> 24:13.880
So there's a few different ways

24:13.880 --> 24:15.480
that you might wanna think about data.

24:15.480 --> 24:18.440
So you wanna be like, okay, did a human look at it

24:18.440 --> 24:21.200
and decide that like these two sentences are translations

24:21.200 --> 24:22.560
or are they noisy?

24:22.560 --> 24:25.280
Also, is it limited in size?

24:25.280 --> 24:26.680
Another thing you can think about is like

24:26.680 --> 24:29.640
is the data quality dependent on some other factor?

24:29.640 --> 24:31.280
And so that's like the model dependent thing

24:31.280 --> 24:33.680
in which case like the data quality may be capped

24:33.680 --> 24:35.360
by the quality of that dependency.

24:36.840 --> 24:38.920
And so I think you can think a little bit

24:38.920 --> 24:40.120
like the ideal data set.

24:40.120 --> 24:43.560
It would be like humans have reviewed every bit of it.

24:43.560 --> 24:44.880
It's not noisy at all.

24:44.880 --> 24:46.800
We have an infinite amount

24:46.800 --> 24:49.480
and it doesn't have any dependencies on any other models.

24:49.480 --> 24:51.240
It's just like pure quality.

24:51.240 --> 24:54.480
But in reality, like closer to what we have are these.

24:54.480 --> 24:56.560
So we have a bunch of different data sources.

24:56.560 --> 24:58.440
We have the seed data that I discussed

24:58.440 --> 25:00.160
like way back in the talk

25:00.160 --> 25:03.200
where it's a small amount of like really high quality

25:03.200 --> 25:04.480
human aligned data.

25:04.480 --> 25:06.880
But the only problem is that it's limited in size.

25:06.880 --> 25:09.720
It's like 6,000 sentences per language.

25:09.720 --> 25:11.480
We have the public by text.

25:11.480 --> 25:13.680
So this is data that people have created

25:13.680 --> 25:15.560
over many years of working in translation.

25:15.560 --> 25:18.240
You know, you can download it from like the opus corpus

25:18.240 --> 25:22.360
for example, mostly has not been reviewed by humans.

25:22.360 --> 25:24.360
So pretty extremely noisy.

25:24.360 --> 25:26.880
In many languages, it's just coming from the Bible.

25:26.880 --> 25:28.760
So the size is quite limited.

25:28.760 --> 25:30.280
You have our mind data.

25:31.520 --> 25:33.640
So this is not human aligned either.

25:34.640 --> 25:37.080
And but it does have a model dependency, you know,

25:37.080 --> 25:39.720
it's dependent on the quality of the sentence encoders.

25:39.720 --> 25:43.720
And we have two other sources of data from back translation.

25:43.720 --> 25:45.520
So the idea of back translation,

25:45.520 --> 25:47.240
it's a model augmentation technique

25:47.240 --> 25:49.160
heavily used in machine translation

25:49.160 --> 25:52.480
where you use a model to produce like pseudo translations

25:52.480 --> 25:53.560
like silver data.

25:54.400 --> 25:55.960
And we use two different techniques

25:55.960 --> 25:57.720
to produce these back translations

25:57.720 --> 26:00.360
that also are dependent on the underlying model

26:00.360 --> 26:02.400
used to make the translations.

26:02.400 --> 26:04.200
And so this is a picture of like our high level

26:04.200 --> 26:05.120
of different data sources

26:05.120 --> 26:07.240
and like how you wanna think about the quality

26:07.240 --> 26:09.000
and the different axes.

26:09.000 --> 26:11.040
And so if we put them all together, what do we get?

26:11.040 --> 26:14.800
So the Y axis here is the number of training pairs

26:14.800 --> 26:18.280
and the X axis here is the language is sorted by resource.

26:18.280 --> 26:20.520
So you can see like on the left hand side,

26:20.520 --> 26:22.920
you have your low resource languages like Wolof

26:22.920 --> 26:24.680
and on your right hand side,

26:24.680 --> 26:27.240
you've got your high resource languages like French.

26:27.240 --> 26:29.640
The peak is English, of course.

26:29.640 --> 26:32.280
And so if you just look at what's available publicly,

26:32.280 --> 26:34.160
this is a distribution you get.

26:34.160 --> 26:38.120
And you'll see like a huge, huge fall off pretty quickly.

26:38.120 --> 26:41.480
And then if you add in the data that we have created

26:41.480 --> 26:43.120
for mining and back translation,

26:43.120 --> 26:45.800
our goal is basically to like make the distribution

26:45.800 --> 26:47.600
a little bit more uniform.

26:47.600 --> 26:51.440
It's very hard on the extremely low resource side, of course,

26:51.440 --> 26:53.320
but to make it a little bit more uniform

26:53.320 --> 26:55.360
so that you don't just immediately, you know,

26:55.360 --> 26:57.360
overfit on your low resource languages

26:57.360 --> 26:59.600
before you've even seen like three shards

26:59.600 --> 27:00.600
of your German data.

27:02.320 --> 27:04.960
With that kind of data strategy in mind,

27:04.960 --> 27:08.440
I wanna talk a little bit about mixture of experts.

27:08.440 --> 27:11.200
So this is something that we explored quite aggressively

27:11.200 --> 27:14.440
in the translation space for a number of years.

27:14.440 --> 27:16.400
You know, we could have this equal conversation

27:16.400 --> 27:17.760
about some of the debates going on

27:17.760 --> 27:20.360
on like, do you want sparse or dense architectures

27:20.360 --> 27:22.200
for large language models?

27:22.200 --> 27:26.000
But essentially mixture of experts, it enables massive scale

27:26.000 --> 27:28.040
because you don't have to just scale

27:28.040 --> 27:30.560
like you're kind of your dense trunk model,

27:30.560 --> 27:33.000
but you can have like a bunch of different separate experts

27:33.000 --> 27:34.520
that you activate per token.

27:36.040 --> 27:38.880
It also allows you to avoid language interference

27:38.880 --> 27:41.000
because the idea is that the different experts,

27:41.000 --> 27:44.160
they could specialize to specific languages.

27:44.160 --> 27:46.320
Unfortunately, it adds a ton of capacity

27:46.320 --> 27:49.120
so it becomes pretty easy to overfit.

27:49.120 --> 27:52.160
So I wanna talk a little bit about this overfitting

27:52.160 --> 27:53.000
phenomenon.

27:53.000 --> 27:56.360
So the top set of graphs that we're gonna talk about

27:56.360 --> 27:58.960
is for the language Congo

27:58.960 --> 28:01.880
and then the bottom set of languages is French.

28:01.880 --> 28:04.240
So you really wanna compare like a low resource language

28:04.240 --> 28:07.120
on top with a high resource language on bottom.

28:07.120 --> 28:08.920
So if you just take your dense model,

28:08.920 --> 28:11.640
traditional transformer sequence to sequence architecture,

28:11.640 --> 28:13.720
that's the graph that you're showing, right?

28:13.720 --> 28:15.560
So there's a little bit of overfitting

28:15.560 --> 28:17.040
on the low resource language,

28:17.040 --> 28:18.840
but you can pretty much regularize this

28:18.840 --> 28:20.720
with standard dropout techniques, right?

28:20.720 --> 28:23.040
So there's not a big problem and on French,

28:23.040 --> 28:25.080
you basically have no real problem.

28:26.160 --> 28:28.920
However, the minute you switch from like a dense architecture

28:28.920 --> 28:31.600
to a token level MOE architecture,

28:31.600 --> 28:34.120
you just have experienced a massive overfitting

28:34.120 --> 28:35.440
on the low resource language.

28:35.440 --> 28:38.440
So the green line here is like just demonstrating

28:38.440 --> 28:40.160
without dropout the overfitting.

28:40.160 --> 28:42.000
And then if you add dropout,

28:42.000 --> 28:43.800
you get a little bit better performance,

28:43.800 --> 28:45.880
but it's still overfitting quite a bit.

28:45.880 --> 28:49.640
Like essentially by like 12K updates,

28:49.640 --> 28:51.560
there's no real point in continuing training,

28:51.560 --> 28:53.600
like you're burning GPU basically.

28:54.520 --> 28:56.760
And so one of the things we actually worked on quite a bit

28:56.760 --> 28:58.000
was like trying to figure out

28:58.000 --> 29:01.920
how to properly regularize these MOE architectures

29:01.920 --> 29:04.160
with this specific masking technique

29:04.160 --> 29:07.520
on the gating function that decides like which MOE to route,

29:07.520 --> 29:10.240
sorry, which expert to route to and your MOE architecture

29:10.240 --> 29:13.400
to just try to pull back some of this overfitting effect.

29:13.400 --> 29:17.240
So if you look in the top right graph, the purple line,

29:17.440 --> 29:21.640
you still see some successful regularization.

29:22.960 --> 29:26.800
Another thing that we did to control the overfitting effect

29:26.800 --> 29:29.560
that's actually quite being used in language models today

29:29.560 --> 29:31.880
as well is curriculum learning.

29:31.880 --> 29:33.720
And the idea of this is like,

29:33.720 --> 29:37.320
how are we going to stage when languages are introduced?

29:37.320 --> 29:40.680
And so what we did was we tried to train a vanilla model

29:40.680 --> 29:41.960
and then we started to measure

29:41.960 --> 29:44.120
when the languages begin to overfit.

29:44.120 --> 29:47.680
And then we basically bucket them into different sections.

29:47.680 --> 29:50.200
And so for high resource languages like French,

29:50.200 --> 29:51.440
you want to start it early

29:51.440 --> 29:53.560
and it needs to be trained the entire way.

29:53.560 --> 29:56.400
But for a lower resource language like Wolof,

29:56.400 --> 29:59.480
after maybe like a hundred K updates, it's done.

29:59.480 --> 30:01.920
So the rest of the time is just overfitting.

30:01.920 --> 30:03.840
And so it actually gets worse the more you train it.

30:03.840 --> 30:06.000
So what we did is we moved some of those lower resource

30:06.000 --> 30:08.480
languages and we inserted them much later

30:08.480 --> 30:09.920
into the training schedule.

30:09.920 --> 30:11.600
So you start training your high resource,

30:11.600 --> 30:13.640
then you start training your low, your mid resource,

30:13.640 --> 30:16.080
and then your low resource, and then your very low resource.

30:16.080 --> 30:19.440
And so by the end, everything in theory has trained

30:19.440 --> 30:21.560
and is not as overfit as it would be

30:21.560 --> 30:23.040
without this kind of technique.

30:24.120 --> 30:25.600
So I want to show some results.

30:25.600 --> 30:28.880
So first I want to show results on existing datasets.

30:28.880 --> 30:30.800
So before we get to 200 languages,

30:30.800 --> 30:33.080
like let's just talk about 100 languages.

30:33.080 --> 30:35.800
And so this is the Flores 101 DevTest.

30:35.800 --> 30:37.360
It's important to compare to this

30:37.360 --> 30:39.720
because this is where like existing benchmarks

30:39.720 --> 30:41.320
in the community lie.

30:41.320 --> 30:43.600
Whereas on 200, of course, we can put up anything.

30:44.480 --> 30:46.240
Because it's the first work on that.

30:46.240 --> 30:51.120
So the first column is translating out of English.

30:51.120 --> 30:54.840
So English to Chinese, English to Icelandic, anything like that.

30:54.840 --> 30:57.320
The second column is translating into English.

30:57.320 --> 30:58.880
So Chinese to English.

30:58.880 --> 31:03.160
The third column, XXYY, it's translating any cross pair

31:03.160 --> 31:04.640
are not involving English.

31:04.640 --> 31:06.720
And the last column is the average.

31:06.720 --> 31:08.720
So if you look at the first set of rows,

31:08.720 --> 31:12.440
this is a comparison on models that cover 87 different languages.

31:12.440 --> 31:14.720
So there was this paper MTAM 100.

31:14.720 --> 31:16.680
There was also this deep net paper.

31:16.680 --> 31:18.840
So you can see the average blue score.

31:18.840 --> 31:20.880
Blue is a standard translation metric,

31:20.880 --> 31:23.600
essentially a metric of word overlap.

31:23.600 --> 31:26.040
So we're looking at blue score here.

31:26.040 --> 31:29.520
And so you can see the last row NLB 200.

31:29.520 --> 31:31.680
Even though we cover 200 languages,

31:31.680 --> 31:33.920
the blue score is substantially above

31:33.920 --> 31:35.360
some of the existing work.

31:35.360 --> 31:37.480
Now, if we look at 101 languages,

31:37.480 --> 31:40.320
only the Delta LM paper from Microsoft at the time

31:40.320 --> 31:42.280
covered that number of languages.

31:42.280 --> 31:45.720
And so if you compare on all of the different cross sets,

31:45.720 --> 31:49.240
similarly, you see that there's no language left behind model

31:49.240 --> 31:51.840
is much stronger in terms of blue.

31:51.840 --> 31:54.600
One thing really quick on the variance of these blue numbers,

31:54.600 --> 31:56.400
I think it's important to understand

31:56.400 --> 31:58.400
is something statistically significant or not.

31:58.400 --> 32:03.400
I think about 0.5 blue is kind of like the general plus

32:03.400 --> 32:04.520
minus that you'll see.

32:04.520 --> 32:07.840
And so if it's above that, it's usually

32:07.840 --> 32:11.480
a statistically significant metric improvement.

32:11.680 --> 32:14.840
So now I want to talk a little bit about Flora's 200 results.

32:14.840 --> 32:17.400
So here's similar, like the first chunk of columns

32:17.400 --> 32:19.320
translating out of English, then

32:19.320 --> 32:21.440
next chunk is translating into English,

32:21.440 --> 32:25.560
then you have your cross pairs, and then you have your average.

32:25.560 --> 32:27.880
So we have this blue metric as well.

32:27.880 --> 32:33.200
We also have a character level metric based on CHRF++

32:33.200 --> 32:35.640
that's commonly used in the translation community.

32:35.640 --> 32:37.440
So I think looking at these numbers, of course,

32:37.440 --> 32:40.880
there's no baseline work to compare to on the previous slide.

32:40.920 --> 32:43.920
And so when we get to human evaluation in a little bit,

32:43.920 --> 32:45.560
it'll be more concrete.

32:45.560 --> 32:48.960
But I think generally one of the rules of thumb

32:48.960 --> 32:51.920
I have for these types of numbers is around 30

32:51.920 --> 32:57.000
is pretty reasonably becomes usable.

32:57.000 --> 33:00.960
And I think another thing, if you compare these supervised pairs

33:00.960 --> 33:04.600
to zero shot pairs, I think we don't see a huge drop-off

33:04.600 --> 33:06.760
on zero shot, which indicates the model has

33:06.760 --> 33:09.280
some sort of generalization, even if it didn't see

33:09.280 --> 33:12.840
that translation pair directly during training.

33:12.840 --> 33:14.760
Another way to calibrate some of this

33:14.760 --> 33:17.000
is to compare to Google Translate.

33:17.000 --> 33:19.320
And so if you compare to Google Translate,

33:19.320 --> 33:21.360
no language to left behind is quite a bit better

33:21.360 --> 33:25.080
at translating into English and not as good as translating

33:25.080 --> 33:28.240
out of English, although if you like average across everything,

33:28.240 --> 33:31.600
it's a little bit better.

33:31.600 --> 33:34.240
I want to talk a little bit about human evaluation as well

33:34.240 --> 33:36.760
to complement some of our discussion

33:36.760 --> 33:38.800
on automatic evaluation.

33:38.800 --> 33:42.280
And so I think automatic metrics fast, really good

33:42.280 --> 33:44.720
for research and duration, impossible to move forward

33:44.720 --> 33:49.400
without, but human evaluation is really the real deal here.

33:49.400 --> 33:52.000
And so we had this paper at Amptox

33:52.000 --> 33:54.800
on how to make this human evaluation very consistent

33:54.800 --> 33:57.600
and scalable across different language pairs.

33:57.600 --> 34:00.680
I think this goes back to the kind of evaluation data set

34:00.680 --> 34:03.480
point that I was making at the beginning of the talk, where

34:03.480 --> 34:06.000
if you're a professional German translator,

34:06.000 --> 34:08.400
you're really good at evaluating the quality of your German

34:08.440 --> 34:09.960
translation.

34:09.960 --> 34:13.960
But beyond that, there's not a lot of consistency.

34:13.960 --> 34:18.280
And if you evaluate translation on a five point scale,

34:18.280 --> 34:20.880
a five translating between two languages

34:20.880 --> 34:23.440
and a three translating between other two languages,

34:23.440 --> 34:24.960
are those really comparable?

34:24.960 --> 34:27.720
And so we had this entire experiment methodology

34:27.720 --> 34:30.600
on how we might want to make this a little bit more

34:30.600 --> 34:32.320
comparable.

34:32.320 --> 34:35.360
So I want to show some results now on this.

34:35.360 --> 34:37.680
So the y-axis here, so the metric

34:37.720 --> 34:40.360
is called XSTS, some metric for how

34:40.360 --> 34:42.280
we're doing this human evaluation.

34:42.280 --> 34:45.680
The y-axis here is actually the delta.

34:45.680 --> 34:48.600
So anything is a five point scale.

34:48.600 --> 34:52.080
So it's a delta, not the raw score.

34:52.080 --> 34:55.240
The x-axis here is a bunch of different translation directions

34:55.240 --> 34:56.680
that we evaluated.

34:56.680 --> 34:59.880
So the gray set is translating into English.

34:59.880 --> 35:03.320
The green set is translating non-English directions,

35:03.320 --> 35:07.120
so like French to Oluf.

35:07.120 --> 35:10.040
And then the blue set is translating out of English.

35:10.040 --> 35:13.400
And so what you're looking for is like a positive delta

35:13.400 --> 35:17.120
indicates that our modeling architecture is much better.

35:17.120 --> 35:21.640
So what the delta is between is like a baseline transformer

35:21.640 --> 35:24.080
model just trained on all of our data

35:24.080 --> 35:26.440
versus like the final no language left behind model

35:26.440 --> 35:27.440
that we created.

35:27.440 --> 35:29.680
So the data is actually the same for both of them.

35:29.680 --> 35:32.160
That's how we get all 200 languages.

35:32.160 --> 35:34.320
So we're just measuring here the human eval

35:34.320 --> 35:36.320
of the modeling improvements.

35:36.320 --> 35:41.400
As you can see, most of the delta is pretty noticeable.

35:41.400 --> 35:47.000
Some of them not so much like, I don't know, Zulu to English.

35:47.000 --> 35:48.480
We didn't seem to improve very much,

35:48.480 --> 35:51.040
but in general, it's an improvement detectable

35:51.040 --> 35:52.520
by human evaluation.

35:52.520 --> 35:54.680
You might also ask, OK, what is the statistically

35:54.680 --> 35:59.200
significant difference here between about 0.2 to 0.3

35:59.200 --> 36:02.640
plus or minus is something that's pretty noticeable.

36:02.640 --> 36:05.240
And above 0.5, it's very noticeable.

36:07.040 --> 36:10.480
One of the things that I also want to get at in evaluation

36:10.480 --> 36:15.680
is that there's many different facets of model evaluation.

36:15.680 --> 36:18.360
And I think if you look at all of the different LLM leader

36:18.360 --> 36:20.800
boards or the transparency reports or whatever,

36:20.800 --> 36:23.520
you'll begin to internalize this pretty quickly.

36:23.520 --> 36:26.080
But what we just looked at are just very high level

36:26.080 --> 36:27.360
summary numbers.

36:27.360 --> 36:30.360
And they don't really tell you what exactly are the errors

36:30.360 --> 36:32.520
and is it ultimately usable by people?

36:32.520 --> 36:35.400
Is it a safe thing that people can rely on?

36:35.440 --> 36:37.720
And so one of the things we really focused on

36:37.720 --> 36:39.520
is user safety.

36:39.520 --> 36:43.040
And some of that manifests in some of the toxicity work

36:43.040 --> 36:44.040
that we did.

36:44.040 --> 36:47.520
And the driving thing here is that not all errors in translation

36:47.520 --> 36:48.520
are made equal.

36:48.520 --> 36:50.800
So during COVID, there was this one that was really

36:50.800 --> 36:52.920
went viral circulating around.

36:52.920 --> 36:55.680
But the message during COVID is you've got to wash your hands.

36:55.680 --> 36:58.360
But the translation producer is like, you've got to hold hands,

36:58.360 --> 37:02.160
which I think is exactly the opposite of what you want to do.

37:02.160 --> 37:03.800
And other types of measurement errors

37:03.840 --> 37:05.560
are really important as well.

37:05.560 --> 37:08.240
So if you're telling someone how far they want to go,

37:08.240 --> 37:10.760
and you're like, hey, you want to travel five kilometers,

37:10.760 --> 37:13.800
and then your translation is like travel 500 kilometers,

37:13.800 --> 37:16.800
it's a completely different type of issue.

37:16.800 --> 37:18.960
And so what we did for toxicity, which

37:18.960 --> 37:22.200
is a big focus for this work, is that we collected different

37:22.200 --> 37:25.720
toxicity lists for all 200 languages.

37:25.720 --> 37:27.880
And so why do I care so much about toxicity?

37:27.880 --> 37:29.720
I think it's a user safety thing.

37:29.720 --> 37:32.560
So if you input some perfectly benign text,

37:32.600 --> 37:34.440
and then the output is profanity,

37:34.440 --> 37:36.720
I think it's just really unexpected.

37:36.720 --> 37:39.120
And it breaks a lot of trust in the system.

37:39.120 --> 37:42.440
And it's an extremely poor experience for people.

37:42.440 --> 37:45.240
That being said, it's also a very, very challenging thing,

37:45.240 --> 37:47.760
because it's extremely culturally specific.

37:47.760 --> 37:52.360
So things that are slurs or insults in certain languages,

37:52.360 --> 37:55.800
they don't really generalize across cultures,

37:55.800 --> 37:57.680
which means that things like this

37:57.680 --> 38:00.280
are very challenging to create.

38:00.280 --> 38:02.240
And I also was very interested in this direction,

38:02.240 --> 38:04.880
because I think it's broadly useful for all sorts

38:04.880 --> 38:07.320
of different type of detection things

38:07.320 --> 38:09.440
that you need to do, and also mitigation.

38:09.440 --> 38:11.000
And so even though we develop this

38:11.000 --> 38:12.680
in the context of translation,

38:12.680 --> 38:16.720
it can be used very broadly in other types of NLP applications.

38:17.880 --> 38:20.000
This is also open source, you can download it.

38:20.000 --> 38:21.800
You have to type in a little password

38:21.800 --> 38:23.520
that's in the GitHub repo,

38:23.520 --> 38:25.400
just so that you don't accidentally download

38:25.400 --> 38:27.600
and realize you have files of curse words

38:27.600 --> 38:29.120
all over your computer.

38:30.120 --> 38:31.800
Okay, so I wanna end a little bit

38:31.800 --> 38:34.320
with some thoughts about future directions.

38:34.320 --> 38:36.080
And before I get there,

38:36.080 --> 38:39.800
there's like a 190 page paper that writes up

38:39.800 --> 38:42.240
all of this in far greater detail,

38:42.240 --> 38:43.720
in case you're curious.

38:45.000 --> 38:46.920
So a few future directions

38:46.920 --> 38:49.000
that I think I'm really interested in,

38:49.000 --> 38:51.320
and some of these are also very applicable

38:51.320 --> 38:52.760
to things like speech,

38:52.760 --> 38:57.440
is that I think one of them is more explicit multilingual.

38:57.720 --> 39:00.360
So I think a lot of approaches to multilingual

39:00.360 --> 39:01.920
have been like, hey,

39:01.920 --> 39:04.320
we have this thing that's working well for one language,

39:04.320 --> 39:06.480
like let's try to scale it

39:06.480 --> 39:07.880
to a bunch of different languages,

39:07.880 --> 39:08.960
and then we're gonna put them all

39:08.960 --> 39:10.200
in the same modeling bucket,

39:10.200 --> 39:12.760
and just kind of like hope that the model learns

39:12.760 --> 39:14.760
all of these different representations.

39:14.760 --> 39:17.040
But I think there's a lot of potential room

39:17.040 --> 39:20.280
for explicitly bringing in,

39:20.280 --> 39:22.160
like the fact that you know it's multilingual

39:22.160 --> 39:25.320
into the architecture more.

39:25.320 --> 39:27.760
And so, you know,

39:27.760 --> 39:32.120
it's possible to capture more nuances between languages

39:32.120 --> 39:34.440
or different relationships between languages.

39:35.600 --> 39:38.080
And the other one is continued support for everyone.

39:38.080 --> 39:40.960
I think it's like something reflecting on this project

39:40.960 --> 39:43.520
is that, you know, going from 100 to 200

39:43.520 --> 39:45.400
was already pretty challenging,

39:45.400 --> 39:47.320
but going beyond a lot of the techniques

39:47.320 --> 39:48.560
that we developed here

39:48.560 --> 39:51.240
are not necessarily that scalable.

39:51.240 --> 39:53.320
This is actually what inspired some of our work

39:53.320 --> 39:55.280
on speech translation as well.

39:55.280 --> 39:58.360
So if you recently saw like the seamless M4T release

39:58.360 --> 39:59.920
or like the unwritten languages,

39:59.920 --> 40:01.840
like we did a lot of modeling of Hokeum,

40:01.840 --> 40:04.720
and I think that goes into this direction really well,

40:04.720 --> 40:07.680
because many of the languages that people want to use

40:07.680 --> 40:09.800
are like spoken first languages

40:09.800 --> 40:12.000
and not necessarily like primarily written.

40:13.080 --> 40:14.240
And then I think the last thing

40:14.240 --> 40:15.960
that I'm still really passionate about

40:15.960 --> 40:18.800
is like continued increase ease of use

40:18.800 --> 40:20.280
and training of these models

40:20.280 --> 40:23.000
and like democratization for the community.

40:23.000 --> 40:25.440
So one of the things that we tried to do in this work

40:25.440 --> 40:28.080
is just like really, really clearly write down

40:28.080 --> 40:30.200
everything that we did and like open source,

40:30.200 --> 40:32.840
like even the data pipeline and things like that.

40:32.840 --> 40:34.520
And so that's where you get like all of the repos

40:34.520 --> 40:38.040
that I linked and, you know, like a huge write up.

40:38.040 --> 40:40.120
But I think if someone were to try to reproduce this

40:40.120 --> 40:42.080
for their own language, and many people have,

40:42.080 --> 40:44.200
like I'm not saying that that hasn't been,

40:44.200 --> 40:46.520
but it's like, if you wanted to like do this,

40:46.520 --> 40:49.480
it would be extremely, extremely hard

40:49.480 --> 40:52.400
because there's just like so much different things going on.

40:52.400 --> 40:54.440
So I think most of the, what we've seen is like,

40:54.440 --> 40:55.960
people have downloaded the base model

40:55.960 --> 40:58.040
and fine-tuned it for their own language,

40:58.040 --> 41:00.960
but it's pretty hard to just like add on

41:00.960 --> 41:03.200
many, many more languages to this system

41:03.200 --> 41:06.000
because of how complicated all of the moving parts are.

41:06.000 --> 41:08.920
And so I feel like something for the translation community

41:08.920 --> 41:13.320
overall is like, how do we simplify a lot of these things?

41:13.320 --> 41:16.000
And I think that's where like a lot of fundamental modeling

41:16.000 --> 41:19.040
innovation could help us get to.

41:19.040 --> 41:21.440
And so yeah, I got a chance to give this talk,

41:21.440 --> 41:23.560
but of course the work is like being done

41:23.560 --> 41:27.320
by a huge team of people that I've cited here.

41:27.320 --> 41:30.480
And yeah, if you want to use any of this

41:30.480 --> 41:32.200
or read more about it, like everything is linked

41:32.200 --> 41:35.920
from this main GitHub repo here in Fairseek,

41:35.920 --> 41:38.560
and you can like click on everything else afterwards.

41:39.640 --> 41:42.680
But yeah, maybe I'll go back to Stephen

41:42.680 --> 41:45.400
if we have any questions or anything else like that.

41:45.400 --> 41:46.840
All right, now thanks for the great talk.

41:46.840 --> 41:48.480
Yeah, if anybody has any questions,

41:48.480 --> 41:50.360
feel free to unmute and ask.

41:51.440 --> 41:52.280
Thank you.

41:57.280 --> 41:59.800
Did you consult with a lot of like native speakers

42:00.720 --> 42:03.800
for like, you know, profanities and this type of stuff?

42:03.800 --> 42:07.600
Like how are you able to get access to the, you know,

42:07.600 --> 42:10.920
low quality languages or low resource languages

42:10.920 --> 42:13.680
and make sure that translations are correct?

42:13.680 --> 42:15.360
Yeah, yeah, that's a really good question.

42:15.360 --> 42:17.120
I mean, I think it's the most important to consult

42:17.120 --> 42:18.640
like a bunch of native speakers

42:19.640 --> 42:21.720
across the entire development process.

42:21.720 --> 42:24.000
So part of our original thing was just like interviewing

42:24.000 --> 42:26.840
a bunch of people to understand like what they're looking for

42:26.840 --> 42:28.640
in a high quality translation.

42:28.640 --> 42:32.160
And then we have like an entire professional translation team

42:32.160 --> 42:36.160
hired, which took quite a long time to find

42:36.160 --> 42:40.120
to consult with along the process.

42:40.120 --> 42:43.000
And then right now, like we also have some of the things

42:43.000 --> 42:45.240
like toxicity lists are open to the community.

42:45.240 --> 42:46.800
So if you make like a pull request,

42:46.800 --> 42:48.760
we try to like, you know, validate that

42:48.760 --> 42:50.160
that's like a useful addition

42:50.160 --> 42:53.400
and then like try to merge it in as well.

42:56.840 --> 42:58.160
We have a question in the room.

42:58.160 --> 43:00.560
Let's see if that comes over soon.

43:00.560 --> 43:01.400
Oh, go ahead.

43:01.400 --> 43:03.080
So I'll speed, see if we should get it.

43:03.080 --> 43:04.560
Yeah.

43:04.560 --> 43:06.520
So like, did you spend most of your time

43:06.520 --> 43:07.960
in the data pipeline state?

43:09.280 --> 43:10.120
Yeah.

43:11.120 --> 43:13.840
Yeah, good question.

43:13.840 --> 43:14.680
I think the question is,

43:14.680 --> 43:15.640
did you spend most of your time

43:15.640 --> 43:16.840
in the data pipeline state?

43:16.840 --> 43:19.920
It ended up being about like kind of like 50-50

43:19.920 --> 43:23.280
like data or more like driving work.

43:23.280 --> 43:25.440
And then like 50-50 on the other side

43:25.440 --> 43:27.320
like modeling and evaluation work.

43:27.320 --> 43:29.280
Because once like the data is set,

43:29.280 --> 43:31.480
then there is a lot and a lot of iteration

43:31.480 --> 43:33.880
on the modeling side to figure out like, okay,

43:33.880 --> 43:35.840
which, how much of the data should we use?

43:35.840 --> 43:37.000
Like how should we portion the data?

43:37.000 --> 43:38.080
How do we prevent overfitting?

43:38.080 --> 43:40.200
What is the right architecture?

43:40.200 --> 43:42.520
But a lot of work goes into the data

43:42.520 --> 43:44.680
because I think if you don't have high quality data,

43:45.280 --> 43:47.320
you just can't get a good model.

43:49.080 --> 43:52.480
And for data mining, how do you mine the data?

43:52.480 --> 43:55.880
Do you use like Selenium or how do you mine the web?

43:57.160 --> 44:00.520
Yeah, so for the web, we start with Common Crawl.

44:00.520 --> 44:03.240
So we downloaded all of the different dumps of Common Crawl

44:03.240 --> 44:05.240
and then we use HTML parser.

44:05.240 --> 44:08.000
I think now like, if you download, for example,

44:08.000 --> 44:09.200
the red pajama dataset,

44:09.200 --> 44:12.120
like they've done a lot of this like parsing and stuff.

44:12.120 --> 44:15.240
And then we have like large scale pipelines

44:15.240 --> 44:18.240
that are set up like you can use Spark, for example,

44:18.240 --> 44:19.400
to process these things,

44:19.400 --> 44:21.720
to like split all of the different sentences out,

44:21.720 --> 44:23.600
run your language identification.

44:23.600 --> 44:26.480
You know, you can do different heuristic cleaning.

44:26.480 --> 44:28.520
There are certain languages where it's like very actually,

44:28.520 --> 44:30.880
very challenging to identify what is a sentence.

44:30.880 --> 44:34.320
Like I think in Thai, there is no like period.

44:34.320 --> 44:36.720
So you have to like use different models

44:36.720 --> 44:38.120
to identify what is a sentence

44:38.120 --> 44:40.280
and like parse some of those things out.

44:40.480 --> 44:44.080
And then we end up with, you know, our monolingual data dump.

44:46.280 --> 44:47.920
What is Common Crawl?

44:47.920 --> 44:51.600
Is it software that you use for datasets?

44:51.600 --> 44:52.440
Oh, yeah, yeah.

44:52.440 --> 44:54.760
Common Crawl is kind of like an open source version

44:54.760 --> 44:57.840
of the web that runs, I think maybe quarterly.

44:57.840 --> 44:58.880
I would have to check.

44:58.880 --> 45:00.920
But yeah, if you go to like Common Crawl.org,

45:00.920 --> 45:03.840
you can download it, but warning, it's like very large.

45:11.280 --> 45:12.600
I have a question.

45:12.600 --> 45:14.200
I mean, you might have mentioned this briefly,

45:14.200 --> 45:17.800
but I'm wondering how chatGBT and GPT-4 does on this.

45:17.800 --> 45:21.600
Like does just more scale and pre-training data help

45:21.600 --> 45:25.400
as well for low resource machine translation?

45:25.400 --> 45:26.800
Yeah, yeah, good question.

45:26.800 --> 45:28.200
Actually, there have been some studies done

45:28.200 --> 45:30.360
on like how, you know, these systems work.

45:30.360 --> 45:32.160
I think for high resource languages,

45:32.160 --> 45:35.000
it's actually quite beneficial to scale up.

45:35.000 --> 45:37.360
I think part of that is because the models

45:37.560 --> 45:39.240
have some innate generalization.

45:39.240 --> 45:40.960
And so one of the challenges that people talk

45:40.960 --> 45:42.840
about different things in different languages.

45:42.840 --> 45:45.600
So like seeing that knowledge in another language

45:45.600 --> 45:47.480
can actually help the generalization.

45:47.480 --> 45:51.080
But on low resource languages, it's, yeah,

45:51.080 --> 45:53.680
the performance is pretty difficult,

45:53.680 --> 45:56.600
especially on some of these translation benchmarks.

45:56.600 --> 45:59.040
I also think that language models,

45:59.040 --> 46:02.000
in terms of being trained for like a translation objective,

46:02.000 --> 46:04.320
tend to score worse on translation benchmarks

46:04.320 --> 46:06.480
because language models are like approximately

46:07.480 --> 46:09.680
capturing the same thing or as translation models.

46:09.680 --> 46:12.640
So you really try to align the meaning a little bit more.

46:13.800 --> 46:15.240
But yeah, so I think for low resource,

46:15.240 --> 46:17.480
it's still pretty challenging.

46:17.480 --> 46:19.320
But yeah, one thing that's interesting

46:19.320 --> 46:21.320
is for most English language models,

46:21.320 --> 46:23.400
they can actually do a reasonable job

46:23.400 --> 46:24.840
at producing other languages

46:24.840 --> 46:27.000
because it's impossible to get rid of other languages

46:27.000 --> 46:28.720
in your English specific data.

46:28.720 --> 46:32.200
So things like French or German will work reasonably.

46:36.480 --> 46:39.400
So just to clarify, you said language models trained

46:39.400 --> 46:43.600
with a translation objective do better, right?

46:43.600 --> 46:46.040
Because, right?

46:46.040 --> 46:46.880
They tend to do better.

46:46.880 --> 46:49.200
Like if you fine tune for the translation task,

46:49.200 --> 46:50.760
it will tend to do better.

46:50.760 --> 46:52.240
Well, that makes sense compared to like,

46:52.240 --> 46:56.800
for example, some few shot in context examples.

46:56.800 --> 46:59.080
Right, right, exactly, exactly.

46:59.080 --> 47:00.640
And one other question is,

47:03.760 --> 47:05.640
do you see this being similar to, for example,

47:05.640 --> 47:08.200
fine tuning on particular expert domains,

47:08.200 --> 47:13.200
which might also have less data and low resource,

47:13.920 --> 47:16.720
and as well as domain specific jargon and so forth?

47:18.800 --> 47:21.880
Yeah, I mean, I think if we were to restart this project now,

47:21.880 --> 47:23.480
I think that would be one of the first things

47:23.480 --> 47:26.120
we also explored, or at least like an extremely strong

47:26.120 --> 47:28.440
baseline where if you like take some of the data

47:28.440 --> 47:33.120
and you try to fine tune or try to do domain adaptation,

47:33.120 --> 47:35.520
I think that's also where like some of the like retrieval

47:35.520 --> 47:38.720
type approaches go in for translation,

47:38.720 --> 47:40.600
but also large language modeling work

47:40.600 --> 47:42.520
where you try to have like a separate domain

47:42.520 --> 47:45.920
that you can like retrieve some text in for adaptation.

47:45.920 --> 47:48.520
I think all of those approaches are pretty promising.

47:54.520 --> 47:56.280
Arcade, any other questions?

47:59.440 --> 48:01.560
One quick one on the point of the video question.

48:01.560 --> 48:02.760
You're looking at one of the slides,

48:02.760 --> 48:05.960
I think you showed some peak results with zero shot

48:05.960 --> 48:10.280
that were higher than just the base model.

48:10.280 --> 48:12.880
Do you think that's because there might still be

48:12.880 --> 48:16.040
some overfitting on those low resource languages?

48:16.040 --> 48:17.000
Yeah, good question.

48:17.000 --> 48:19.720
So for our large scale mining,

48:19.720 --> 48:23.000
we don't mind like every single possible cross pair.

48:23.000 --> 48:26.400
So like Icelandic will love,

48:26.400 --> 48:28.360
it's probably like not like the most

48:28.360 --> 48:30.080
in demand translation direction.

48:30.080 --> 48:32.920
And so we did not mind like all 200 times 200

48:32.920 --> 48:34.040
because it's like really producing

48:34.040 --> 48:35.960
like a combinatorial explosion.

48:35.960 --> 48:38.400
And so that's where the zero shot results come from

48:38.400 --> 48:40.560
where you don't need,

48:40.560 --> 48:43.560
we don't have training data directionally in that pair,

48:43.560 --> 48:46.520
but the model has seen both the input and the output.

48:46.520 --> 48:50.200
And so I think those results are pretty good.

48:50.200 --> 48:52.720
Well, they're good for certain languages,

48:52.720 --> 48:56.760
which I think goes to show like the generalization capability

48:56.760 --> 48:58.800
and it's not like as critical

48:58.800 --> 49:00.760
to have like every single pair covered,

49:00.760 --> 49:02.440
but many of them are not as good.

49:02.440 --> 49:04.840
And so you see overall the performance is lower,

49:04.840 --> 49:06.080
even though on certain languages,

49:06.080 --> 49:08.000
it can perform better than you expect.

49:08.000 --> 49:10.160
But that's because it has seen the input and the output.

49:10.160 --> 49:12.960
It's not zero shot on like completely unseen language.

49:22.000 --> 49:23.160
I have a question.

49:24.120 --> 49:28.120
But I wanted you to also, you know,

49:28.120 --> 49:31.000
do something related to transcription

49:31.000 --> 49:32.640
or audio information?

49:34.400 --> 49:35.640
Yeah, good question.

49:35.640 --> 49:38.960
So in this project, no, not so much transcription,

49:38.960 --> 49:40.760
but we had a follow up work that we released

49:40.760 --> 49:44.800
actually just like a month or so ago called seamless M4T,

49:44.800 --> 49:46.120
which is like a joint model

49:46.120 --> 49:48.400
for both speech and text translation.

49:48.400 --> 49:51.440
And that's where we do leverage a lot of audio transcription

49:51.440 --> 49:54.320
because that also has like, it helps us bridge,

49:54.320 --> 49:56.440
you know, like the spoken data and the text data

49:56.440 --> 49:58.120
to leverage both of them together.

50:08.240 --> 50:10.960
Wait, just to clarify, the supervised fine tuning

50:10.960 --> 50:15.560
it worked better, right, compared to other methods.

50:16.600 --> 50:19.120
So actually in this work, it was as a couple of years ago now.

50:19.120 --> 50:23.520
So supervised fine tuning wasn't as common as it was now.

50:23.520 --> 50:25.240
But I think in the literature,

50:25.240 --> 50:26.960
if you want to use like a large language model

50:26.960 --> 50:29.160
to do translation, it's currently best yet

50:29.160 --> 50:31.600
if you do some supervised fine tuning.

50:31.600 --> 50:33.120
I'm just wondering about that

50:33.120 --> 50:34.800
because the way as humans, right,

50:34.800 --> 50:39.360
we don't just learn by looking at pairs of the same thing

50:39.360 --> 50:40.200
in different languages

50:40.200 --> 50:44.360
and kind of memorizing how to map from one to the other.

50:44.360 --> 50:46.240
We kind of learn in a more unsupervised way

50:46.240 --> 50:48.400
where if we know both languages,

50:48.400 --> 50:51.840
then we can kind of naturally translate between them.

50:54.480 --> 50:57.120
But I guess it makes sense for an LLMY

50:57.120 --> 51:01.280
having supervised examples would help, yeah.

51:01.280 --> 51:05.000
Yeah, I mean, I think as like the base foundation model

51:05.000 --> 51:06.800
continues to improve in quality,

51:06.800 --> 51:09.240
I think that's where the quality will probably improve

51:09.240 --> 51:11.160
when you don't need less and less fine tuning.

51:11.160 --> 51:13.560
I mean, do you think that's like the open AI approach?

51:13.560 --> 51:15.360
Like if you have the best foundation model,

51:15.360 --> 51:18.040
then you don't need as much like domain specific fine tuning.

51:18.080 --> 51:19.840
I think like, you know, like at the start

51:19.840 --> 51:21.400
when I started working on text generation,

51:21.400 --> 51:22.840
there was like translation researchers

51:22.840 --> 51:24.040
and like summarization researchers

51:24.040 --> 51:25.480
and like question answering researchers

51:25.480 --> 51:27.240
and they like work very differently.

51:27.240 --> 51:28.680
But now it's like, it's all driven

51:28.680 --> 51:30.000
by the same underlying thing

51:30.000 --> 51:31.680
and you're not like a specialized

51:31.680 --> 51:33.760
summarization researcher anymore.

51:35.480 --> 51:38.600
Right, I think that makes a lot of sense.

51:41.280 --> 51:43.000
Do we have any other questions?

51:44.000 --> 51:45.000
Any questions?

51:52.000 --> 51:54.000
Ron, any more in-person questions?

51:56.000 --> 51:57.000
Oh, don't think so.

51:58.000 --> 51:59.000
Okay, great.

51:59.000 --> 52:00.000
All right.

52:00.000 --> 52:03.000
Well, thank you, Angela, for the very interesting

52:03.000 --> 52:06.000
and a great talk again and for taking the time.

52:06.000 --> 52:11.000
And we hope, yeah, we hope that you can keep in touch

52:11.000 --> 52:14.000
and if anybody has any other questions,

52:14.000 --> 52:17.000
feel free to get in touch with Angela.

52:17.000 --> 52:19.000
All right, thanks so much for having me today.

52:19.000 --> 52:20.000
Bye, everyone.

