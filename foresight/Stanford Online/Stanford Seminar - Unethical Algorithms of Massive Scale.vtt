WEBVTT

00:00.000 --> 00:14.880
Who was here last time I was here?

00:14.880 --> 00:17.000
I know Hal was.

00:17.000 --> 00:20.040
Oh, I know that guy, Rick.

00:20.040 --> 00:21.040
And oh, I remember you two.

00:21.040 --> 00:22.040
What's your first name?

00:22.040 --> 00:23.040
Eugene.

00:23.040 --> 00:24.040
Eugene, of course.

00:24.040 --> 00:25.040
How are you?

00:25.040 --> 00:26.040
Okay.

00:26.040 --> 00:27.040
Good.

00:27.080 --> 00:31.400
When I recall, when I was here last time, I came with a lot of slides and I decided

00:31.400 --> 00:33.480
not to use them.

00:33.480 --> 00:38.680
And I'm going to do the same thing again, except I think I'm going to show you one slide

00:38.680 --> 00:40.680
because it just blows my mind.

00:40.680 --> 00:43.520
So when we get to that one point, I'm going to turn this on and I'm going to show you

00:43.520 --> 00:45.440
one slide.

00:45.440 --> 00:47.320
And by then, I hope you'll be prepared.

00:47.320 --> 00:51.040
Oh, dear.

00:51.040 --> 00:53.720
Well, that shouldn't be.

00:53.720 --> 00:54.720
How do we get rid of that?

00:54.720 --> 00:56.960
We're just going to go like that.

00:56.960 --> 00:59.320
So well, that's only half of it anyway.

00:59.320 --> 01:01.560
That's not the important half of the slide.

01:01.560 --> 01:06.680
So I want to take us on a journey.

01:06.680 --> 01:14.080
And the journey is going to take us from the hypothetical to the somewhat real, to the

01:14.080 --> 01:19.280
real, to the surreal.

01:19.280 --> 01:21.920
So we're going to move in that direction.

01:21.920 --> 01:24.680
So let's start with the hypothetical.

01:24.680 --> 01:28.560
And in fact, I liked Andy's introduction, short, sweet.

01:28.560 --> 01:36.960
He mentioned something about influence, perhaps on the internet, perhaps using new technologies.

01:36.960 --> 01:41.400
Let's consider a few hypothetical situations.

01:41.400 --> 01:42.400
Here we go.

01:42.400 --> 01:44.760
We'll start with Facebook.

01:44.760 --> 01:57.440
Let's say that last spring or summer, Facebook sent out, this is hypothetical now, sent out

01:57.440 --> 02:01.280
reminders to go register to vote.

02:01.280 --> 02:08.320
Now at the moment, they have nearly two billion members.

02:08.400 --> 02:15.640
Among those members, there are 72% of the adult population of the US.

02:15.640 --> 02:23.760
So if Facebook chose to send out, go out and register to vote reminders to their people,

02:23.760 --> 02:25.280
they could reach a lot of people.

02:25.280 --> 02:31.000
They could reach a lot of people because in fact, a lot of Americans who are eligible

02:31.000 --> 02:33.760
to vote are not registered.

02:33.760 --> 02:40.800
In fact, I think it's roughly 70 million Americans who are eligible to vote out of the 220 or

02:40.800 --> 02:44.760
so who could vote are not even registered.

02:44.760 --> 02:51.120
So if you take roughly 0.7 times 0.7, if you see where I got those numbers from, then

02:51.120 --> 02:59.680
that means Facebook could reach 50 million Americans who are not registered to vote and

02:59.680 --> 03:04.480
could send out reminders to them.

03:04.480 --> 03:07.560
Now here's the hypothetical part.

03:07.560 --> 03:13.200
What if they sent out those reminders only to people in certain demographics?

03:13.200 --> 03:19.000
What if they chose to send out reminders just to Democrats, let's say, or just to Republicans,

03:19.000 --> 03:23.920
or just to supporters of Donald Trump, or just to supporters of Hillary Clinton?

03:23.920 --> 03:26.840
Would anyone know that?

03:26.840 --> 03:33.600
I don't think anyone would know that because what Facebook sends out is always targeted.

03:33.600 --> 03:41.920
No one keeps track of which groups are receiving those messages or those items on the newsfeed.

03:41.920 --> 03:44.000
No one keeps track.

03:44.000 --> 03:50.000
So in fact, hypothetically, Facebook could have sent out those reminders to register

03:50.000 --> 03:58.000
to vote, reaching 50 million unregistered adults who are eligible to vote, and no one

03:58.000 --> 04:04.080
would have known they could have done so selectively just to supporters of one candidate.

04:04.080 --> 04:08.640
Now how many additional people would then have registered to vote?

04:08.640 --> 04:10.920
We'll get to that.

04:10.920 --> 04:18.600
Okay, now we're still on the hypothetical, but let me just mention on this one issue

04:18.600 --> 04:26.160
that in fact, Facebook did send out reminders to go register to vote.

04:26.160 --> 04:34.780
They sent them out en masse, and the New York Times concluded that because, very clever

04:34.780 --> 04:39.280
and simple what they came up with, the New York Times concluded that because Facebook,

04:39.280 --> 04:45.160
generally speaking, reaches a younger audience, and because younger people tend to be more

04:45.160 --> 04:51.480
Democrat than Republican, then in fact, Facebook, even if it did broadcast these messages to

04:51.480 --> 04:57.520
everyone, that what they did was advantageous to Democrats.

04:57.520 --> 05:00.840
That was the New York Times conclusion, and they came up with some numbers, they came

05:00.840 --> 05:08.400
up with some estimates, but in fact, we don't really know to whom those reminders were sent.

05:08.400 --> 05:09.400
Okay, there's example one.

05:09.400 --> 05:12.360
Now let's go to example two.

05:12.480 --> 05:19.760
Election day, if on election day, Facebook chose to send out go out and vote reminders

05:19.760 --> 05:26.240
just to people of one political party or just to supporters of one candidate, how many additional

05:26.240 --> 05:36.400
people might they stimulate to get off of their sofas and go vote?

05:37.400 --> 05:44.200
Well, as it happens, there's actually an answer to this question, because in 2012, Facebook,

05:44.200 --> 05:50.320
with some people I know from the University of California, San Diego, published an article

05:50.320 --> 05:55.600
about a manipulation that they did in 2010 during the 2010 election.

05:55.600 --> 06:00.920
They in fact sent out go out and vote reminders to 60 million of their members on election

06:00.920 --> 06:08.240
day in 2010, and they had a control group, and they did some surveying to try to figure

06:08.240 --> 06:16.560
out who went out and voted in the experimental group, when the group that was getting the

06:16.560 --> 06:21.560
reminders and in the control group, and they concluded that their reminders on election

06:21.560 --> 06:30.520
day in 2010 caused an additional 340,000 people to go out and vote.

06:30.520 --> 06:37.400
So if you extrapolate from that published experiment, if you extrapolate from that to

06:37.400 --> 06:49.920
election day in 2016, that would tell you conservatively that if on election day Facebook

06:49.920 --> 06:58.280
had sent out go out and vote reminders selectively to supporters of one party or another, conservatively

06:58.280 --> 07:05.240
speaking, they could easily have caused an additional six or 700,000 people to go out

07:05.240 --> 07:11.680
and vote who otherwise would have stayed home, and no one would have known.

07:11.680 --> 07:16.560
So did they actually do that on election day?

07:16.560 --> 07:23.080
I don't know, but as you'll see, we're going to move from the hypothetical to the real

07:23.080 --> 07:27.240
and a little bit in the direction of the surreal, so we'll get back to this.

07:27.240 --> 07:32.640
Now there are other things hypothetically that Facebook could have done to manipulate

07:32.640 --> 07:34.000
people last year.

07:34.000 --> 07:39.880
You may recall that a whistleblower turned up, a former Facebook employee who had been

07:39.880 --> 07:47.040
one of the news curators, and in fact I met another of the news curators for Facebook

07:47.040 --> 07:52.280
sometime later in New York, and who told me that no, they weren't sitting in a basement

07:52.280 --> 07:58.640
as the press had reported, no, that was false, but yes, they really were a bunch of recent

07:58.640 --> 08:06.560
college graduates with very liberal leanings, and yes, they were selectively removing conservative

08:06.560 --> 08:13.040
news stories from the news feed that Facebook shows to people, and Facebook now seems to

08:13.040 --> 08:17.800
be, according to some reports, the main place people are getting their news, or at least

08:17.800 --> 08:21.560
getting links to their news stories.

08:21.560 --> 08:31.920
So the curators, human curators, were indeed messing with the news feed in a way that favored

08:31.920 --> 08:33.520
the Democrats.

08:33.520 --> 08:35.720
So this is an actual whistleblower who came forth.

08:35.720 --> 08:41.260
So this is, but let's keep it hypothetical, because first of all, we don't know that the

08:41.260 --> 08:45.840
management of Facebook had anything to do that, it could have just been that they happened

08:45.840 --> 08:50.280
to hire these particular people with these particular political leanings, right?

08:50.280 --> 08:56.720
So just an error, really a kind of, you know, an oversight, you could consider, however,

08:56.720 --> 09:02.160
let's look at this hypothetically, what if they deliberately wanted to do that?

09:02.160 --> 09:06.680
What if it wasn't just an accident of hiring, what if they deliberately wanted to alter

09:06.680 --> 09:11.200
our opinions on things by altering news feeds?

09:11.200 --> 09:12.200
Could they do that?

09:12.200 --> 09:14.560
Yes, are they doing that?

09:14.560 --> 09:18.960
Well, there was that whistleblower, but you know, all those people got fired, and they

09:18.960 --> 09:24.280
said they were moving to an algorithm, and so are they doing this now?

09:24.280 --> 09:26.400
I don't know.

09:26.400 --> 09:27.960
So it's still hypothetical.

09:27.960 --> 09:31.600
So you've got the news feeds, you've got the trending stories, same thing could be

09:31.600 --> 09:33.120
done there, right?

09:33.120 --> 09:41.580
So Facebook has a bunch of different ways to alter opinions without people knowing.

09:41.580 --> 09:43.840
That's what's important.

09:43.840 --> 09:46.180
That's what's important.

09:46.180 --> 09:52.260
They even have a fifth way, because are any of you here Facebook users and willing to

09:52.260 --> 09:53.260
admit it?

09:53.260 --> 09:56.860
Okay, well, that's most of you, wow.

09:56.860 --> 10:06.820
You know they have a search bar, but what you may or may not know is that although the

10:06.820 --> 10:12.620
search bar is usually used to find your friends and family, it can be used for other purposes

10:12.620 --> 10:21.660
too, and before the election, Facebook posted a video urging people to search for election

10:21.660 --> 10:30.820
2016 in the search bar, and then that would give you a list, again, a feed of information

10:30.820 --> 10:33.500
which of course they had complete control over.

10:33.500 --> 10:36.580
So they've got the search bar, they've got the trending stories, they've got the news

10:36.580 --> 10:44.940
feed, they've got the possibility of sending out selective reminders, lots of things, none

10:44.940 --> 10:46.940
of which would be visible to people.

10:46.940 --> 10:53.460
Let's shift over to the big guy, Google.

10:53.460 --> 11:02.900
So Google controls lists also, news feeds are lists, and Google controls lists.

11:02.900 --> 11:08.980
Two very, very important lists, among others, but two extremely important lists, both of

11:08.980 --> 11:15.820
which are generated on the fly when you get onto Google search and start to conduct a

11:15.820 --> 11:17.060
search.

11:17.060 --> 11:21.020
The first list is the little list up at the top.

11:21.020 --> 11:25.420
Those are the search suggestions in what is sometimes called autocomplete.

11:25.420 --> 11:32.140
Google invented autocomplete, 2004 I believe, and when they invented it, it had I believe

11:32.260 --> 11:38.860
10 search suggestions, and it was an opt-in feature.

11:38.860 --> 11:46.580
But a couple of years later, it was no longer an opt-in, in fact, you couldn't opt out.

11:46.580 --> 11:52.580
And then sometime later, the list began to change, initially it appeared that the list

11:52.580 --> 11:56.700
was just showing you what other people were searching for.

11:56.700 --> 12:01.700
And if you, right now, for example, if you go and conduct a search on Yahoo, don't waste

12:01.740 --> 12:07.380
your time because their search results are terrible, by the way, and they're pulling

12:07.380 --> 12:13.660
almost all of their search results from Google under an arrangement that was signed between

12:13.660 --> 12:18.260
the two companies in late 2015, however, let's put that aside.

12:18.260 --> 12:24.860
The point is, when you try to do a search on Yahoo, you get 10 search results, and they

12:24.860 --> 12:28.140
appear to be what people are searching for.

12:28.140 --> 12:33.340
If you use Bing, which I also wouldn't bother with, but you get eight search results, which

12:33.340 --> 12:35.700
also appear to be what people are searching for.

12:35.700 --> 12:41.700
You can confirm that, in fact, the suggestions you're getting on Bing and Yahoo are really,

12:41.700 --> 12:44.060
generally speaking, just what people are searching for.

12:44.060 --> 12:45.660
How do you confirm that?

12:45.660 --> 12:47.020
It's very simple.

12:47.020 --> 12:52.220
You go over to Google, Trends, and you can see what people are searching for.

12:52.300 --> 12:59.540
So, meanwhile, Google's list of suggestions over the years, for some reason, got smaller

12:59.540 --> 13:06.460
and smaller and smaller, so that, at least on most devices, they only show you four items.

13:06.460 --> 13:11.540
Occasionally, you'll get three, two, or one.

13:11.540 --> 13:16.500
There are some circumstances under which you can get five, six, seven, but in fact, we actually

13:16.500 --> 13:21.140
did an extensive survey to figure out how likely those possibilities are.

13:21.220 --> 13:22.620
Very unlikely.

13:22.620 --> 13:25.980
You generally speaking, on most devices, get four.

13:25.980 --> 13:29.820
On some mobile devices, you get five, but the point is, it's a short list.

13:29.820 --> 13:36.900
And the items on that list no longer have any obvious correspondence to what people

13:36.900 --> 13:40.260
are searching for, so what are they showing you?

13:40.260 --> 13:47.620
Well, the point is, here's a list that Google controls that we all see, perhaps, every day

13:47.620 --> 13:52.300
or perhaps many times a day, and it's the search suggestions list.

13:52.300 --> 13:54.700
And generally speaking, it has four items.

13:54.700 --> 13:59.100
And generally speaking, those four items don't have any obvious correspondence anymore to

13:59.100 --> 14:00.940
what people are searching for.

14:00.940 --> 14:02.140
Very easy to show that.

14:02.140 --> 14:04.900
You just look on Google Trends.

14:04.900 --> 14:11.660
More and more, the items that appear on that list also are customized for the individual.

14:11.660 --> 14:16.020
So that's one reason why, of course, they're not going to have much correspondence to what

14:16.020 --> 14:19.820
people in general are searching for, because they're going to have to do with you and your

14:19.820 --> 14:24.020
history and what Google's algorithm perceives as your needs.

14:24.020 --> 14:25.420
So there's a list.

14:25.420 --> 14:28.660
And then they've got this other list, because once you click on something, sometimes even

14:28.660 --> 14:36.460
if you don't click on something, in the suggestions, the search results populate.

14:36.460 --> 14:39.300
Sometimes you don't even have to click, and the results populate below.

14:39.300 --> 14:41.300
So now you've got a second list.

14:41.300 --> 14:44.620
So I've got a short list, and I've got a long list.

14:44.620 --> 14:49.380
Now the long list, as you know, goes on forever.

14:49.380 --> 14:54.740
But most people don't go beyond the first page of results, which shows you 10 results.

14:54.740 --> 14:59.900
In fact, 50% of all clicks go to the top two results.

14:59.900 --> 15:05.780
And more than 90% of all clicks are on the first page.

15:05.780 --> 15:14.820
So what's on that first page is very, very important, extremely important, two lists.

15:14.820 --> 15:18.660
Now let's get hypothetical here.

15:18.660 --> 15:28.780
What if Google were using search suggestions not to help you do your search, although that's

15:28.780 --> 15:31.540
what they would claim, of course, but they're actually a business.

15:31.540 --> 15:36.060
They're not really the public library, like they pretend to be, they're actually a business.

15:36.060 --> 15:42.100
And so what if Google were actually using search suggestions in a way that makes them

15:42.100 --> 15:44.380
more money?

15:44.380 --> 15:46.140
How could they use search suggestions?

15:46.140 --> 15:51.460
It's hypothetical, I'm not claiming anything.

15:51.460 --> 15:54.540
But how would they do that?

15:54.540 --> 16:00.340
Well, as a matter of fact, we know a lot about this, that's when I get to the real part of

16:00.340 --> 16:03.040
my talk, I'll explain to you how we know.

16:03.040 --> 16:07.180
We know a lot about this, but just staying hypothetical for the moment, how could they

16:07.180 --> 16:08.180
do this?

16:08.180 --> 16:12.220
Well, first of all, if they know about you and your search history and your interests

16:12.220 --> 16:17.420
and so on, in fact, they know a lot about all of us, well, they could put items there

16:17.420 --> 16:21.420
that they think you're likely to click on.

16:21.420 --> 16:26.700
And that they think you want to see, maybe, but more importantly, they could put items

16:26.700 --> 16:34.500
there on that list that you're very likely to click on rather than doing what.

16:34.500 --> 16:36.580
What do they not want you to do?

16:36.580 --> 16:44.980
Yes, they don't want you to type your search term, your full search term.

16:44.980 --> 16:48.940
This is hypothetical, of course.

16:48.940 --> 16:55.220
So hypothetically, if I were running Google and I wanted to make a lot of money, I would

16:55.220 --> 16:59.860
figure out how to show people search terms that made it very likely that people are going

16:59.860 --> 17:03.980
to click on one of the search terms.

17:03.980 --> 17:08.860
And I would also, since I'm now controlling what people are clicking on, I would make sure

17:08.860 --> 17:14.260
that the results that populate as a result of a click or even without a click, I would

17:14.260 --> 17:19.300
make darn sure that those results are results I want to show people.

17:19.300 --> 17:20.300
See?

17:20.300 --> 17:21.700
Yes, what is your name?

17:21.700 --> 17:22.700
Hi, John.

17:22.700 --> 17:30.300
Why don't you think they want you to type out what it is you really want?

17:30.300 --> 17:34.620
You know, I don't really want to speculate about the motives, particular motives.

17:34.620 --> 17:42.560
I guess what I'm saying is if I were in charge, then I would lose control over what people

17:42.560 --> 17:45.140
were searching for.

17:45.140 --> 17:46.140
Think about this.

17:46.140 --> 17:53.620
If I let you go ahead and type your whole search term, and then I let you hit Enter,

17:53.620 --> 17:59.260
I'm in a tough position now because my credibility always depends on giving you exactly what

17:59.260 --> 18:00.260
you want.

18:00.260 --> 18:04.260
So you always have to have that feeling that they answered your question, right?

18:04.260 --> 18:08.480
So I'm really kind of stuck because depending on what you typed, I've actually got to give

18:08.480 --> 18:14.260
you more or less what it is you wanted or what it is you thought you wanted.

18:14.260 --> 18:15.260
See what I'm saying?

18:15.260 --> 18:19.500
If I lose some control, whereas if I can get you to click on one of the suggestions that

18:19.500 --> 18:22.740
I make, I'm in complete control.

18:22.740 --> 18:26.460
That's just better from a business perspective.

18:26.460 --> 18:33.660
So we've got this list of here, and again, hypothetically, Google could show people lists

18:33.660 --> 18:37.540
that give them more control over what people search for, and another way to put that is

18:37.540 --> 18:43.620
Google could show people search terms that would nudge people's searches.

18:43.620 --> 18:48.340
You know that great book from 2008 by Thaler and the other guy called Nudge?

18:48.340 --> 18:50.500
It's a great, great book.

18:50.500 --> 18:56.620
And search suggestions hypothetically could be used to nudge people's searches in directions

18:56.620 --> 18:58.580
that are advantageous for the company.

18:58.580 --> 19:01.260
It's hypothetical, right?

19:01.260 --> 19:03.940
Now let's get to the search results.

19:03.940 --> 19:08.820
Search results, 10, those are the key ones.

19:08.820 --> 19:14.260
Google has total control over the order in which these items are presented.

19:14.260 --> 19:22.940
Hypothetically, they could put items near the top that they want you to click on, and

19:22.940 --> 19:27.940
again, where doing so would be advantageous to the company.

19:27.940 --> 19:33.180
And that could have to do with making money, that could be one goal, possibly, but could

19:33.180 --> 19:35.260
have to do with other things too.

19:35.260 --> 19:40.540
People agendas have to do with anything, really.

19:40.540 --> 19:46.300
I mean, again, I don't know people's specific motives, I'm just saying one could hypothetically

19:46.300 --> 19:55.900
use search results in a way to manipulate people's thinking, beliefs, purchases, certainly,

19:55.900 --> 19:57.900
and possibly even their votes.

19:57.900 --> 20:02.380
Okay, so we've got a few different hypotheticals here for Facebook.

20:02.380 --> 20:07.780
We've got a couple for Google, and I could go on all day about other options Google has.

20:07.780 --> 20:12.100
If you want to look at a cool article, it's a piece I wrote for US News and World Report

20:12.100 --> 20:17.580
called The News Censorship, and that goes through lots of different crazy lists that

20:17.580 --> 20:23.740
Google controls, and if you can control lists, wow, you can control what people think.

20:23.740 --> 20:37.220
No, the Great Firewall is trivial by comparison.

20:37.220 --> 20:43.300
The Great Firewall cuts off access to a lot of information, although all of the Chinese

20:43.300 --> 20:51.500
students who work with me say that in China it's very common for people to use proxies

20:51.500 --> 20:54.500
to get around the firewall.

20:54.500 --> 21:00.540
But all it does is restrict access, where I'm talking about a much finer degree of control.

21:00.540 --> 21:03.340
Also, the Great Firewall is visible.

21:03.340 --> 21:05.780
Do you see what I'm saying?

21:05.780 --> 21:09.420
It's completely different than the kinds of hypothetical situations I'm discussing so

21:09.420 --> 21:15.860
far because I'm talking about methods of influence that are completely invisible.

21:15.860 --> 21:21.580
If someone is showing you a list of search suggestions that have been carefully prepared

21:21.580 --> 21:25.780
to make sure, make it likely anyway, that you're going to click on one of them and when you

21:25.780 --> 21:30.300
do, that serves my corporate needs, you can't see that.

21:30.300 --> 21:31.300
It's impossible.

21:31.300 --> 21:33.300
And the same is true, of course, with the search results.

21:33.300 --> 21:39.180
If I'm putting the results in an order that suits my corporate needs, serves my corporate

21:39.180 --> 21:40.340
needs, you can't see that.

21:40.340 --> 21:42.100
It's impossible.

21:43.100 --> 21:46.060
Okay, so we got a few possibilities for Facebook.

21:46.060 --> 21:47.980
We got a couple for Google.

21:47.980 --> 21:52.820
Now let's go into crazy land here because remember, we're moving gradually toward the

21:52.820 --> 22:10.660
surreal, but still, speaking hypothetically, Tinder, Tinder, Tinder, Tinder is a kind of

22:11.660 --> 22:16.540
it's a matching service mainly for people who want to have sex with each other.

22:16.540 --> 22:20.900
Very popular sex, I mean, and Tinder too.

22:20.900 --> 22:28.860
So Tinder normally just shows you pictures of people and then you swipe left or swipe

22:28.860 --> 22:32.780
right indicating whether you're hot or not, right?

22:32.780 --> 22:37.620
This brings us right back to Bill Gates and his original app at Harvard that got him into

22:37.620 --> 22:38.700
trouble.

22:38.700 --> 22:40.580
So that's really what Tinder is.

22:40.580 --> 22:45.500
It's just a hot or not, you swipe and so on, and if someone else who you said was hot

22:45.500 --> 22:50.340
swipes you as hot, then you get connected with that person and that's basically what

22:50.340 --> 22:51.340
Tinder is.

22:51.340 --> 22:57.540
Oh, I'm sorry, Zuckerberg, absolutely, sorry.

22:57.540 --> 22:58.540
Thank you.

22:58.540 --> 22:59.540
I appreciate that.

22:59.540 --> 23:04.900
Okay, so, but before the election, a couple months before the election, Tinder announced

23:04.900 --> 23:07.180
a very odd application.

23:07.180 --> 23:13.220
It was called Swipe the Vote and Tinder offered to help you figure out which candidate you're

23:13.220 --> 23:18.220
better suited for, which candidate in other words better serves your values and your needs

23:18.220 --> 23:21.460
as a voter, Tinder.

23:21.460 --> 23:27.140
So sure enough, when people got onto Tinder, one of the options they had was to swipe the

23:27.140 --> 23:31.580
vote, you know, let us help you figure out who to vote for.

23:31.580 --> 23:36.540
So of course the people who are most likely to do this are going to be undecided voters.

23:37.140 --> 23:41.580
That's gorgeous, that's beautiful because we know a lot about undecided voters and those

23:41.580 --> 23:44.740
are the people who are easiest to influence.

23:44.740 --> 23:51.740
So over time, I don't know how many people use Swipe the Vote because how would I know,

23:51.740 --> 23:52.940
right?

23:52.940 --> 23:54.580
But here's the way it worked.

23:54.580 --> 23:59.020
It asks a question about immigration and it says, you know, you agree or disagree and

23:59.020 --> 24:03.020
you swipe one way or the other and then it asks another question, you know, about taxes

24:03.020 --> 24:05.260
and you swipe one way or the other and so on.

24:05.260 --> 24:10.660
And it's just pretty much five questions and then it says, you're a perfect match for Donald

24:10.660 --> 24:11.660
Trump.

24:11.660 --> 24:17.460
So we're still in hypothetical land.

24:17.460 --> 24:27.740
What if hypothetically the company had some bias in favor of one candidate or the other?

24:27.740 --> 24:32.900
Couldn't they make it, couldn't they tell every single person who swipes the vote?

24:33.380 --> 24:36.940
That they should vote for Donald Trump or Hillary Clinton?

24:36.940 --> 24:37.940
Couldn't they do that?

24:37.940 --> 24:38.940
Would anyone know?

24:38.940 --> 24:39.940
Would anyone even notice?

24:39.940 --> 24:46.180
You know, if they wanted to mask the effect, as we've done a lot of experiments on masking,

24:46.180 --> 24:49.780
you know, and they didn't want it to be that obvious, believe me, that's trivially easy

24:49.780 --> 24:51.580
to do.

24:51.580 --> 24:59.980
But the point is, here's a matching service at a website used by tens of millions of Americans

25:00.060 --> 25:03.660
which is advising people on how to vote.

25:03.660 --> 25:07.300
But we don't know what that algorithm is doing.

25:07.300 --> 25:09.660
We don't know whether they favor one candidate or the other.

25:09.660 --> 25:16.660
Well, it turns out that Tinder is not the only matching service, vote matching service on

25:16.660 --> 25:17.660
the internet.

25:17.660 --> 25:20.620
They're popping up more and more.

25:20.620 --> 25:25.380
Some look really, really credible, you know, they're nonprofits and this and that.

25:25.380 --> 25:27.300
But you don't really know who's running them.

25:27.300 --> 25:31.060
You don't know what their motives are and you don't know what the algorithm is doing.

25:31.060 --> 25:36.900
So hypothetically, you could put matching services on the internet, including on big

25:36.900 --> 25:45.500
websites like Tinder, to help people make up their minds about voters or about abortion

25:45.500 --> 25:49.140
or about taxes or about homosexuality or about anything.

25:49.140 --> 25:54.580
You could put matching services up on the internet and algorithms could be shifting

25:54.580 --> 25:58.380
opinions literally by the millions because we know the numbers.

25:58.380 --> 25:59.380
This is what we do.

25:59.380 --> 26:00.380
This is all we do.

26:00.380 --> 26:02.500
We just quantify these effects.

26:02.500 --> 26:09.180
And no one would know because it's invisible.

26:09.180 --> 26:14.060
Okay, I could go on with hypotheticals but you get the idea.

26:14.060 --> 26:21.020
Oh, no, no, was Tinder's algorithm biased toward one candidate or the other?

26:21.020 --> 26:23.540
I don't know.

26:23.540 --> 26:28.820
Remember all those, I don't know, that's very important.

26:28.820 --> 26:32.740
Okay.

26:32.740 --> 26:41.020
To put this in perspective, what kinds of manipulations are making the news every day?

26:41.020 --> 26:44.140
They're not what I just told you.

26:44.140 --> 26:52.220
What are the manipulations that are in the news constantly, especially lately?

26:52.220 --> 26:58.380
Fake news, that's number one, absolutely, positively number one, fake news.

26:58.380 --> 27:02.460
And number two is Cambridge Analytica.

27:02.460 --> 27:08.460
And Cambridge Analytica using massive amounts of data, some of which they kind of, you could

27:08.460 --> 27:13.860
say stole or obtained unethically anyway, and a lot of which they bought.

27:13.860 --> 27:22.940
Cambridge Analytica funded by that Mercer billionaire fellow who is a staunch Trump supporter.

27:22.940 --> 27:32.980
And Cambridge Analytica supposedly helped shift the vote toward Brexit in the Brexit referendum.

27:32.980 --> 27:37.260
And Cambridge Analytica supposedly also helped to put Trump in office.

27:37.260 --> 27:39.660
That makes the news not as much as fake news does though.

27:39.660 --> 27:45.820
Fake news in the news all the time.

27:45.820 --> 27:49.420
We don't study, we could easily study the impact.

27:49.420 --> 27:53.460
We could quantify the impact of fake news stories on people.

27:53.460 --> 27:55.820
We don't, we don't bother.

27:55.820 --> 28:00.220
We could quantify the impact of the kinds of manipulations Cambridge Analytica was using,

28:00.220 --> 28:07.500
which by the way is just plain old marketing stuff, because all they were doing was customizing

28:07.740 --> 28:12.700
basically images and language and ads to get people to click.

28:12.700 --> 28:15.820
That's exactly what marketers do, right?

28:15.820 --> 28:19.100
You use multivariate analysis, you keep changing things.

28:19.100 --> 28:24.940
Now they, they had access to lots of data about people, about supposedly all the voting,

28:24.940 --> 28:26.860
all the voters in America.

28:26.860 --> 28:31.500
They claim to have more than 5,000 data points for every single voter in the United States.

28:32.220 --> 28:40.220
So what I'm saying is that I'm not, we're not studying that.

28:40.220 --> 28:45.100
Why are we not studying these incredibly, because they're trivial.

28:45.100 --> 28:51.020
By comparison to the hypotheticals that I just described, they're completely trivial.

28:51.020 --> 28:53.740
Why is fake news trivial by comparison?

28:53.740 --> 28:56.300
First of all, you can see fake news.

28:57.180 --> 29:01.500
You know there's fake news in front of your eyeballs, or you know there's news anyway.

29:01.500 --> 29:05.340
You're not sure whether it's fake enough, but you sure as heck know that there's a human element

29:05.340 --> 29:09.420
there, because it looks like a newspaper, and so a human must have written it.

29:09.420 --> 29:13.020
And some, and usually there's an aim of a human who wrote the article.

29:13.020 --> 29:15.020
You can see it.

29:16.220 --> 29:20.220
That's very different than kinds of influence, which are invisible to people.

29:20.220 --> 29:23.180
There's extensive research on this and social psychology.

29:23.260 --> 29:28.140
If you influence people using methods, subtle methods that they can't see,

29:30.380 --> 29:34.060
people end up believing that they made up their own minds.

29:34.060 --> 29:38.300
You can still shift people's opinions and actions and so on,

29:38.300 --> 29:42.620
but if they can't see the source of influence, they end up believing that they made up their own minds.

29:42.620 --> 29:45.260
They have no idea that they've even been influenced.

29:46.540 --> 29:52.060
So what's the earliest, obvious example of fake news?

29:52.060 --> 30:00.940
What's the earliest example of that kind of influence in the United States that made big news back in the late 50s, I think, a long time ago?

30:06.140 --> 30:09.100
Exactly, subliminal stimulation, that's right.

30:09.100 --> 30:16.140
And this made big news in the U.S. a long time ago, because supposedly a movie theater in New Jersey was,

30:16.460 --> 30:21.900
you know, had cut in these little frames into their film saying,

30:23.260 --> 30:27.020
go buy a soda, you know, you're thirsty, go buy a soda, go buy our popcorn.

30:27.580 --> 30:30.860
And that got into the news and there was a big uproar.

30:30.860 --> 30:39.100
And as a matter of fact, the association that controlled television standards at the time, they made it supposedly,

30:39.100 --> 30:48.060
they prohibited the use of subliminal stimuli, at least on television.

30:48.060 --> 30:54.700
Some countries ended up passing very strict laws prohibiting it in all kinds of public situations.

30:54.700 --> 30:57.980
The UK subliminal stimulation is unlawful, period.

30:58.540 --> 31:00.140
We never made it unlawful here.

31:00.140 --> 31:05.500
It's still probably used, but, you know, it doesn't really have that much of an impact.

31:06.140 --> 31:07.500
It's just scary, though.

31:07.500 --> 31:12.620
The idea that there's some stimulus that's affecting you and you can't really see it and

31:12.620 --> 31:18.060
it's caused you to buy a drink, but it turns out subliminal stimuli do have an impact on people,

31:18.060 --> 31:20.060
but it's very, very, very, very small.

31:21.500 --> 31:26.860
So, you know, if you're building a business, that's probably not where you want to put your marketing money.

31:28.140 --> 31:34.460
But the point is, invisible stimuli that affect people, you know, they've been around for a while.

31:34.860 --> 31:36.300
There are lots of examples.

31:36.300 --> 31:38.060
There's a body of research on this.

31:39.020 --> 31:43.820
But what I'm trying to tell you is that looking at those hypotheticals,

31:43.820 --> 31:46.140
we have now moved into a very different world,

31:48.300 --> 31:55.980
where there are, hypothetically, means of influencing people by the billions online,

31:57.180 --> 32:01.340
invisibly, without any awareness on people's part that they're being manipulated.

32:01.340 --> 32:07.820
And, you know, the word ethics is in the title of my talk today.

32:09.580 --> 32:13.820
Although the use of these methods is currently perfectly legal,

32:15.980 --> 32:18.380
not because I think anyone would say they should be legal,

32:18.380 --> 32:21.660
but simply because the law hasn't caught up with the technologies.

32:22.780 --> 32:26.620
But I think most of us would agree that these are unethical, at least,

32:27.500 --> 32:28.860
even if they're legal at the moment.

32:29.420 --> 32:32.780
I think most of us would agree that they are unethical.

32:33.820 --> 32:41.260
So, more and more, I think we need to be thinking about the ethics of what new technology is bringing to people.

32:44.140 --> 32:47.100
All right, let's move now, more in the realm of real.

32:49.420 --> 32:52.460
I don't want to spend too much time on this because I could go on forever.

32:52.460 --> 32:54.300
And by the way, what time do I need to stop?

32:55.260 --> 33:00.940
I know it's five something, but okay, good, we're running schedule.

33:00.940 --> 33:05.100
So, let's move a little bit toward the real.

33:07.500 --> 33:15.580
In early 2012, in fact, it happened to be New Year's Day, come to think of it, January for 2012,

33:16.220 --> 33:21.420
I got a bunch of emails all from Google saying that my website had been hacked

33:21.740 --> 33:27.260
and that they were blocking access through their search engine.

33:28.140 --> 33:33.740
So, until that day, I had never given any thought to Google at all.

33:33.740 --> 33:35.180
I just thought it was a great search engine.

33:35.980 --> 33:41.340
And I started to learn some things about Google that made me more concerned about the company.

33:41.340 --> 33:44.380
For one thing, I learned that they had no customer service department,

33:44.380 --> 33:45.900
which I thought was odd, and they still don't.

33:46.780 --> 33:57.980
No, actually, they don't, but we can talk about it more later if you like.

33:58.540 --> 34:04.460
But it's not like lots of other companies where you just call an 800 number and someone answers

34:04.460 --> 34:06.220
the phone and they help you solve your problem.

34:06.220 --> 34:07.580
They don't have anything like that.

34:07.580 --> 34:11.580
In fact, at one point when I did get someone on the phone from Google,

34:11.580 --> 34:14.060
she basically said, I'm really sorry I can't answer that question.

34:14.060 --> 34:15.580
I'm really sorry I can't answer that question.

34:15.580 --> 34:17.020
I said, can you help me at all?

34:17.020 --> 34:18.780
She goes, no, I'm really not allowed to help you.

34:19.500 --> 34:25.660
So, that's the closest I got to a human being who was not a bot and it was an actual person.

34:25.660 --> 34:26.940
I don't think she was a bot anyway.

34:27.580 --> 34:32.620
And the point is I started to learn some things about the company, which bothered me.

34:32.620 --> 34:37.180
It only took me five or six days to get my website taken care of, cleaned up, and so on.

34:37.180 --> 34:40.460
And it took much longer to get it through Google sensors,

34:41.420 --> 34:47.340
in other words, to get their algorithm to okay my website again.

34:47.340 --> 34:49.820
But all right, it was just a hack, no big deal.

34:51.500 --> 34:56.060
However, there were a couple things about this because I've been coding since I was 13 years

34:56.060 --> 35:00.220
old and there were a couple things about what happened that bothered me and made me want to

35:00.220 --> 35:01.820
look more closely at this company.

35:02.620 --> 35:10.220
One was that not only did the search engine block people, warn people away from going to my website.

35:10.220 --> 35:11.820
I understand that, right?

35:11.820 --> 35:16.460
Google's crawlers found malware, I get that, right?

35:16.460 --> 35:19.980
So, their search engine should warn people away, makes perfect sense.

35:21.500 --> 35:28.860
But also, if you tried to get to my website or any of the 20 psychological tests that are

35:28.860 --> 35:32.540
actually based there, so through other URLs you tried to get into those tests,

35:33.340 --> 35:37.340
using Firefox, you couldn't get there.

35:37.340 --> 35:38.940
And that doesn't make sense.

35:38.940 --> 35:44.940
Firefox is a product of Mozilla, which is a non-profit corporation, and I don't get that.

35:44.940 --> 35:48.940
I don't see how Google's crawler would have anything to do with Firefox.

35:49.900 --> 35:53.740
And then I found the same was true with Safari, which is owned by Apple.

35:54.780 --> 35:57.740
So, there were things like this that were bugging me.

35:57.740 --> 35:59.020
I don't want to go into details.

35:59.020 --> 36:03.740
I just want to point out that I started to think a little bit more critically about Google as a

36:03.740 --> 36:12.300
company. Later that year, chatting with some people about search results and search rankings,

36:13.660 --> 36:18.380
I got interested in that, not just on Google, but on search engines in general.

36:19.820 --> 36:25.500
We're all constantly wondering about the search algorithm that they use and how they do this

36:25.500 --> 36:29.420
ordering and how every once in a while they change the ordering, which puts another

36:30.220 --> 36:34.780
thousand businesses out of business, and everyone's always wondering about those things.

36:36.060 --> 36:43.500
It turns out that by late 2012, there was a growing scientific literature looking at

36:44.140 --> 36:50.380
the impact of search rankings, search position, in other words, on people's behavior.

36:51.340 --> 37:00.700
This was being done primarily in the field of marketing because where you are in the search

37:00.700 --> 37:06.620
results depends a lot on whether your business is going to succeed or fail.

37:06.620 --> 37:10.780
If you can get up one more notch, depending on your industry, that might be worth another

37:10.780 --> 37:15.980
million dollars in revenue. So, in fact, there was a growing literature looking at

37:16.060 --> 37:19.660
those little notches and how they impacted people. Among other things,

37:20.620 --> 37:26.140
eye tracking studies showed that people's eyes would go up to the top of the list,

37:26.140 --> 37:31.580
even when you deliberately constructed lists in which superior results were down at the bottom.

37:32.380 --> 37:37.900
In other words, people were just hung up on the top stuff. It's as if people generally believed

37:38.700 --> 37:41.900
that what's at the top is better and what's at the top is truer.

37:42.380 --> 37:50.140
Well, Eugene, I was there. The two books I've seen about the history of Google,

37:51.660 --> 37:54.300
all of them and all the other articles I've seen,

37:55.820 --> 38:00.300
missed the fact that Larry and Sergey had a classmate named Luis Gravano, who is now

38:00.860 --> 38:05.660
a computer science professor at Columbia University. And upstairs in Route 104,

38:06.460 --> 38:13.820
Luis assembled the most amazing quarter or two seminars. Everybody who wrote a search engine

38:13.820 --> 38:19.500
up through the 1990s was invited to come, the guys who wrote Alta Vista, Steve Kersh, who wrote

38:19.500 --> 38:26.700
InfoSeq, and so forth. You go down the list and Larry and Sergey sat on the side of the room

38:26.700 --> 38:32.940
and they started giggling because Larry had developed page rank with Terry and Hector and

38:33.260 --> 38:40.140
other people. And I mean, relevance ranking, and this information retrieval is not my area,

38:40.140 --> 38:45.820
but I certainly used dialogue back in 1976-76. I don't want us to get too much off track because

38:45.820 --> 38:52.460
my time is limited. The thing is this, relevance ranking has been around for decades. And you

38:52.460 --> 38:57.900
should talk to contact Luis Gravano and find out. I can go beyond that, Eugene, because as a matter

38:57.900 --> 39:03.980
of fact, list effects have been around for centuries. And they have been studied in detail

39:03.980 --> 39:11.340
for at least 100 years. So it has long been known that items at the top of a list have more impact

39:11.340 --> 39:16.540
than items in the middle. Under some conditions, items at the bottom of a list also have more impact,

39:16.540 --> 39:21.420
their names for all these things. And all this stuff has been well studied. But when I look at

39:21.420 --> 39:30.380
this literature, when I looked at this literature, I was finding numbers that were just off the scale.

39:31.580 --> 39:37.580
And it wasn't until quite some, I mean, sometime much, much later that we actually figured out

39:38.460 --> 39:46.220
why items near the top of these search results are so impactful. They're incredibly impactful.

39:46.220 --> 39:55.580
In other words, search results produced list effects that are orders of magnitude greater

39:55.580 --> 40:03.900
than any other list effects ever studied. Okay? Well, with luck, I'll be able to tell you why

40:03.900 --> 40:08.940
shortly. But let me just explain what happened. I got interested in this because I saw these big

40:08.940 --> 40:15.260
numbers and I thought, well, if people have this trust for what's at the top, could you use search

40:15.260 --> 40:21.260
results deliberately? I asked to alter people's opinions about things, not just alter their

40:21.260 --> 40:27.980
purchases. In other words, obviously, purchasing was the main issue in these studies. Clicks,

40:28.780 --> 40:34.940
click throughs, conversion rates, that kind of thing. But I was asking a different question. I

40:34.940 --> 40:41.260
was saying, if people have enormous trust for these items near the top, could we use search

40:41.260 --> 40:46.620
results to alter people's opinions? And I thought, what kinds of opinions could we alter? Could we

40:46.620 --> 40:54.060
alter people's voting preferences, for example? That was a question that I raised. So early 2013,

40:54.060 --> 40:59.980
working with a former student of mine, he was working for me at the time, Ronald Robertson,

40:59.980 --> 41:05.660
who's now getting his PhD in a network science program at Northeastern University.

41:06.300 --> 41:15.020
We decided to test this idea by randomly assigning eligible voters to one of three groups. In one

41:15.020 --> 41:21.500
group, they saw search results which were ordered in such a way that favored one political candidate.

41:21.500 --> 41:26.300
In other words, if you clicked on an item near the top of that list, you'd get to a web page,

41:26.300 --> 41:30.300
which said awesome things about that candidate or terrible things about the opposing candidate.

41:30.620 --> 41:38.140
Some people are randomly assigned to a second group in which the opposite is the case. They're

41:38.140 --> 41:42.220
seeing search results that favor the opposing candidate. And the third group is the control

41:42.220 --> 41:49.740
group. They're seeing the search results mixed up. Now, I thought that using this kind of research

41:49.740 --> 41:56.220
design that we could shift, I predicted, two to three percent of the people in these, we call them

41:56.220 --> 42:03.340
bias groups. I figured we could shift two to three percent of them using this technique. And I thought,

42:03.340 --> 42:08.140
okay, that's not a big number, but still a lot of elections are very close. So if you could shift

42:08.140 --> 42:14.300
two to three percent of your undecided voters reliably using, you know, search rankings, I thought,

42:14.300 --> 42:20.700
well, that could have an impact on very close elections. First experiment we ran, the shift was

42:21.420 --> 42:28.380
over forty-eight percent. Second one we ran, the shift was sixty-three percent. Third one we ran,

42:28.380 --> 42:32.860
I think it was thirty-nine percent. These were all pretty small studies. Then we did a national

42:32.860 --> 42:37.340
study in the U.S. with more than two thousand people. Shift we got was, again, about thirty-nine

42:37.340 --> 42:43.900
percent. We also discovered very quickly that we could mask what we were doing. We could hide it.

42:44.860 --> 42:49.340
Even in the first experiment we ran, where people were seeing highly, highly, highly

42:49.340 --> 42:56.620
biased search results, a quarter of the people in the study seemed to have no awareness. I'm sorry,

42:56.620 --> 43:00.780
a quarter of the people in the study, only a quarter of the people in the study, seemed to be

43:00.780 --> 43:06.220
aware of the bias. Three quarters seemed to have no awareness. We found that just by mixing things

43:06.220 --> 43:12.620
up a little bit, okay, so you, so I've got, you know, Trump, Trump, Trump, Clinton, Trump,

43:12.620 --> 43:17.820
Trump, Trump, Trump, just by mixing things up a little bit, adding in a mask, we could easily

43:17.820 --> 43:23.420
boost the number of people who were unaware that they were seeing bias search rankings to one hundred

43:23.420 --> 43:30.380
percent. There was very, very simple manipulation to do and a very simple manipulation to hide.

43:31.740 --> 43:38.060
Producing outrageous shifts in voting preferences as high as eighty percent

43:39.340 --> 43:44.940
in one of the demographic groups that we looked at. We were, we're running experience that were

43:44.940 --> 43:49.420
all speaking of hypothetical and we're moving toward the real, though we're not there yet,

43:49.420 --> 43:55.980
because this is still all kind of science-y stuff, right? But then we did a big experiment in India

43:55.980 --> 44:01.580
during their 2014 election there with more than 2,000 voters from throughout India,

44:01.580 --> 44:06.460
right smack in the middle of the campaign. In fact, even after the voting process started,

44:06.460 --> 44:10.540
we were still bringing in people who hadn't voted yet, because in India they have so many voters

44:10.540 --> 44:14.140
that in fact they, they stretch out the voting process over a period of several weeks and we

44:14.140 --> 44:20.940
were still conducting our study. And there in India where we got real voters and they're being

44:20.940 --> 44:25.260
bombarded with information and they have high familiarity with the candidates, I was saying,

44:25.260 --> 44:30.860
I think we'll still get an effect, but I think it'll be really small, one to two percent or zero.

44:31.500 --> 44:36.060
I thought, I thought maybe the, the reality of the campaigning and the pressure and all that

44:36.060 --> 44:44.140
would just overwhelm what search results could do. What we learned was that search,

44:44.140 --> 44:49.740
bias search results could easily shift voting preferences by more than 20 percent with real

44:49.740 --> 44:56.620
voters and over 60 percent in some demographic groups. In other words, here was a kind of

44:56.620 --> 45:03.820
manipulation, oh by the way, 99.5 percent of the people in that study showed no awareness whatsoever

45:03.820 --> 45:11.340
that they were seeing bias search rankings, 99.5 percent. So this is very different than fake news

45:11.340 --> 45:15.020
and it's very different than even what Cambridge Analytica was doing, you know, where they're,

45:15.020 --> 45:20.300
they're just coming up with good clickbait for people, because no one can see this occurring,

45:20.300 --> 45:25.340
no one's aware that they're being manipulated at all, and yet we're manipulating them. We're

45:25.340 --> 45:33.100
manipulating them sufficiently to, we figured out looking at, in fact, election statistics from

45:33.100 --> 45:41.020
around the world, we were manipulating people sufficiently so that biased search rankings,

45:41.020 --> 45:48.220
could, we calculated, be currently determining the outcomes of upwards of 25 percent of the

45:48.220 --> 45:52.700
national elections in the world. That's mainly because a lot of elections are very close.

45:55.820 --> 46:00.380
And depending on the country and depending on how, what the internet penetration is in that

46:00.380 --> 46:05.020
country, what the percentages of undecided voters and some other things, you know, you can

46:05.020 --> 46:12.300
actually calculate fairly precisely whether or not search rankings can be used to flip an election.

46:14.140 --> 46:17.820
In some of our experiments, we were using web pages and search results from the

46:18.460 --> 46:24.860
2010 election for Prime Minister of Australia. I mentioned this because the winner of that

46:24.860 --> 46:31.500
election won by a margin of 0.24 percent. There are a lot of very close elections.

46:32.460 --> 46:38.780
And even in our last election, Hillary won the popular vote by approximately 2.9 million votes,

46:39.580 --> 46:46.460
but what percentage is that of the total vote of close to 140 million people?

46:48.940 --> 46:53.900
Can you do that in your head? The point is, that's a pretty close election. A lot of elections are

46:53.900 --> 47:00.700
close. Search rankings are very powerful. And so that's what we began to learn. So we since have

47:00.700 --> 47:08.620
done many, many experiments on search results and their power to influence people. We've done

47:08.620 --> 47:15.340
experiments showing that you can influence people's attitudes about things like abortion, fracking,

47:16.300 --> 47:26.620
homosexuality. We've learned that if you let people do multiple searches and which they're seeing

47:27.500 --> 47:32.620
mainly different sets of web pages, but in each case they're seeing a biased set of web pages,

47:33.420 --> 47:40.780
that with each additional search, there's an increase in that shift that we call manipulation

47:40.780 --> 47:47.340
power. So people who conduct multiple searches on the same topic, if they're seeing search results

47:47.340 --> 47:52.380
that are biased in a particular way, that has more and more of an impact on them over time.

47:54.460 --> 48:01.500
We've also done some cool work on the role that operant conditioning seems to play

48:02.060 --> 48:05.740
in this effect, which we eventually called SEEM, the search engine manipulation effect.

48:06.220 --> 48:10.700
I won't go into the details of the experiment, but basically what we figured out, what we confirmed,

48:11.820 --> 48:20.060
is that the reason why search rankings have such an enormous effect, again much larger than most

48:20.060 --> 48:26.460
list effects, is because there's something very peculiar about the way we use search engines.

48:28.460 --> 48:34.860
The vast majority of searches that we conduct are of a routine sort. We're looking for facts.

48:36.700 --> 48:44.140
Right? I go, tell me about where Rick Lozanski went to school.

48:46.540 --> 48:53.180
Or I say, what is the capital of Massachusetts? And sure enough, over and over and over again,

48:53.180 --> 48:59.580
the correct answer appears where? Right at the top. And of course, these days, it even gets up into

48:59.580 --> 49:04.380
the so-called featured snippet or the Google box. So you don't even have to look at the search results.

49:04.380 --> 49:08.620
We're actually doing experiments on the impact of the featured snippet. Right now,

49:08.620 --> 49:13.580
they're running literally right now. The point is, in the experiment we did in operant conditioning,

49:13.580 --> 49:20.780
what we figured out was that the reason why people believe that what's at the top is truer and better

49:20.780 --> 49:26.940
is because there's this daily regimen of operant conditioning. We're like rats in a skinner box

49:26.940 --> 49:30.540
in which we're learning over and over and over again what's at the top is better,

49:30.540 --> 49:35.340
what's at the top is truer. So when the day comes, when we want to put in something a little

49:35.340 --> 49:40.220
different, like something we're really unsure about, like what's the best vacation spot in the

49:40.220 --> 49:46.140
United States? So there's no clear answer, right? It doesn't matter. We're going to trust because

49:46.140 --> 49:50.940
of all that conditioning that never stops. We're going to trust what's at the top more than we

49:50.940 --> 49:55.980
trust things that are down lower. It's really that simple. In the experiment we did, we actually

49:56.060 --> 50:02.300
manipulated people's trust level to show that if you interfere with that operant conditioning,

50:02.300 --> 50:06.860
in fact, people don't trust what's at the top so much and they start looking lower and they

50:06.860 --> 50:14.700
start going to subsequent pages of search results. So we also have done a series of experiments that

50:14.700 --> 50:21.980
will be published soon and looking at the way SIEM can be suppressed with various kinds of alerts

50:22.620 --> 50:27.020
and there are people interested in this because, for example, you may be familiar with the project

50:27.020 --> 50:35.180
called FindX. Anyone know FindX? It's a new project based in Europe. In fact, the man who

50:35.180 --> 50:39.980
started this is now working with me and some other people and something I'll mention at the end of

50:39.980 --> 50:51.660
the talk. FindX is meant to be a search engine which is transparent and fair in which the

50:51.660 --> 51:02.620
rules for ordering are made public and in which even users have a say actually in determining

51:02.620 --> 51:07.660
what the algorithm is doing and how it's computing search results. Another thing they are thinking

51:07.660 --> 51:17.660
about is adding alerts. If you add alerts saying this set of results appears to favor Hillary

51:17.660 --> 51:24.700
Clinton, that has an impact on the way people treat what's in the search results. You can also

51:24.700 --> 51:30.540
add alerts to particular items in the list. So we have work coming out on that.

51:32.060 --> 51:38.540
So we're moving gradually toward the real here. We also started last year studying

51:38.540 --> 51:42.700
search suggestions. Now, again, we're studying things that are invisible. We're not interested in

51:42.700 --> 51:52.860
fake news. Yeah. Yes, I have a question. Yes. Is there a group of people who are somewhat immune

51:52.860 --> 52:00.140
to these effects you describe? In other words, everybody is affected by those?

52:00.940 --> 52:05.980
Well, in the studies we've done in the United States, we've never found any, well, I mean,

52:05.980 --> 52:10.060
there's going to be individuals who are immune, of course, but we have never found a demographic

52:10.060 --> 52:15.340
group that's immune. I'm talking individualism. Is there an individual biologically possible

52:15.340 --> 52:19.980
who would not be affected by it? Well, of course, anyone who is very, by nature, very skeptical

52:19.980 --> 52:25.740
or anyone who's had a bad experience with Google or something, of course, individuals.

52:25.740 --> 52:31.340
So there is a group of people who are immune. Because I don't think so. We are all the same.

52:31.340 --> 52:38.940
Well, as I say, in the United States, we have never found a demographic group that was immune.

52:39.660 --> 52:45.660
Never. Right. So it's just a question of how much people are swayed. Is it this much or is it this

52:45.660 --> 52:50.380
much? But I mean, it's crazy. Everybody's a little bit. And if everybody's swayed a little bit,

52:50.380 --> 52:57.500
how can we talk about facts and fake news? If the content producers and content consumers

52:57.500 --> 53:04.060
also are influenced by other people's opinion, then everything is relative. Well, that's Abraham Lincoln.

53:04.140 --> 53:07.740
You can fool all the people some of the time. Some of the people all the time.

53:07.740 --> 53:13.260
No, no, I'm not talking about this. Let me just point out that we know how to suppress

53:14.060 --> 53:18.780
these effects. So in the paper that we have coming out, we actually show how you can suppress the

53:18.780 --> 53:23.420
in our control groups, we suppress the effect completely, 100%. So we know how to suppress

53:24.860 --> 53:32.060
this kind of effect. If you mix things up, then people don't shift one way or the other.

53:32.380 --> 53:35.980
And there are other ways to suppress the effect in varying degrees. So we're learning about that.

53:35.980 --> 53:40.540
Let me just shift over to search suggestions quickly, because we now have learned a lot.

53:40.540 --> 53:46.540
Okay, room, nice to meet you. We've now learned a lot about search suggestions and why we're

53:46.540 --> 53:50.460
seeing the search suggestions we're seeing, why generally speaking, we're only seeing four.

53:51.340 --> 53:58.540
We actually, I mean, really have learned so much about this that again, it's a whole scary area.

53:58.540 --> 54:05.100
So we've named a new effect called the search suggestion effect, because search suggestions

54:05.100 --> 54:11.100
can in fact be used easily to manipulate people's opinions, attitudes, beliefs, behavior, voting

54:11.100 --> 54:17.740
preferences. We've even figured out where the number four comes from. And the key there to put

54:17.740 --> 54:24.300
it just briefly, the key to that number four has to do with what happens with negative search

54:24.300 --> 54:29.020
suggestions. You've heard of negativity bias, I'm sure, because people study it in a half a

54:29.020 --> 54:34.220
dozen different fields. Sometimes it's called the cockroach and the salad phenomenon. When

54:34.220 --> 54:37.500
there's something negative, and then when a stimulus is negative, like a cockroach in your

54:37.500 --> 54:42.700
salad, your attention is drawn to it and it ruins the whole salad, and you send the salad back.

54:44.620 --> 54:50.300
Now, if I put a piece of chocolate into a plate of sewage, that does not upgrade the plate of

54:50.300 --> 54:56.380
sewage at all. So something particular about negatives, well, it turns out our new experiments

54:56.380 --> 55:01.340
show that there's something very special about those negatives in this list of search suggestions too.

55:01.340 --> 55:09.180
And guess who knows that? Google. So in June, July and August of last year, we documented the fact,

55:09.180 --> 55:15.260
this was partly based on a video that had gone viral in June, then in fact, Google was systematically

55:15.260 --> 55:21.100
suppressing negative search suggestions for Hillary Clinton. Now, when we went public with that,

55:21.100 --> 55:25.420
and others went public with that, so it wasn't just us, but when we went public with our findings,

55:25.420 --> 55:30.540
Google flipped the switch. They literally just turned off the manipulation, just like that.

55:31.420 --> 55:35.980
And from that day on, you could start to see negatives when you did searches for anything

55:35.980 --> 55:40.460
related to Hillary Clinton. But June, July and August, it was virtually impossible to get any

55:40.540 --> 55:45.660
negative search suggestions. We've learned that when there's a negative in that list of four,

55:46.300 --> 55:54.540
it can draw 10 to 15 times as many clicks. And the more undecided someone is on an issue,

55:54.540 --> 56:01.100
the more clicks the negative draws. So one of the simplest ways to manipulate people's opinions

56:01.100 --> 56:06.140
invisibly is through the differential suppression of negative search suggestions. That is to say,

56:06.540 --> 56:10.700
suppress the negative search suggestions for the position I'm supporting,

56:10.700 --> 56:14.940
and I allow negative search suggestions to appear for the other position, the one I'm not supporting.

56:16.300 --> 56:22.380
And what we're now doing is quantifying what that does to people's searches and what that does

56:22.380 --> 56:26.620
to people's opinions and voting preferences. We're doing that right now. But we even figured

56:26.620 --> 56:33.980
out that number four, because it turns out that if there is a negative in the list,

56:34.940 --> 56:39.340
and I, as I add more and more alternatives to that negative, because I want people clicking

56:39.340 --> 56:42.700
on that negative, believe me, I'm allowing that negative to be there because I want people to

56:42.700 --> 56:47.900
click on it and I know it attracts attention and I know it attracts clicks. But the more alternatives

56:47.900 --> 56:55.420
I add, the fewer people will click on the negative. It dilutes the impact of the negativity bias.

56:56.060 --> 57:02.860
Right? Now, by the same token, I want to keep adding more items to my list. Why?

57:04.780 --> 57:10.700
Because I don't want people finishing their own search term. I don't want them doing that.

57:10.700 --> 57:16.380
So on the one hand, I want my list to be long. On the other hand, I want it to be short. Well,

57:16.380 --> 57:22.780
it turns out those two distributions overlap perfectly with one optimal value.

57:25.420 --> 57:33.100
Guess what it is? Four. Four is the magic number. We didn't know if this was going to come out of

57:33.100 --> 57:40.700
our data, but it popped right out. Okay. So we're learning more and more about how these things

57:40.700 --> 57:51.180
work. Now we get to the cereal. You know, all this stuff, even the experiments, even the experiment

57:51.260 --> 57:57.580
in India, in some sense, it's all hypothetical, isn't it? Because you don't know what people

57:57.580 --> 58:02.460
are really seeing. I mean, to see what people are really seeing, I'd have to creep up behind

58:02.460 --> 58:07.900
Eugene like this and I'd have to look over his shoulder and go, are there any European nations

58:07.900 --> 58:14.780
that we're practically unaffected by the two world wars? Now I know because I crept up on him

58:14.780 --> 58:20.060
and I looked over his shoulder and wouldn't we have to do that to really see what people are seeing?

58:21.900 --> 58:29.260
Okay. So I tell the story, the full story. It's coming out in a couple months in a piece called

58:29.260 --> 58:34.780
Haming Big Tech and I recommend it to you highly because I'm told by friends who read it that it

58:34.780 --> 58:41.100
reads like a spy novel. And I tell the story of what this crazy thing we did. So now we're in the

58:41.100 --> 58:51.980
surreal realm here. Starting in late 2015, early 2016, we set up a Nielsen-type network of field

58:51.980 --> 59:02.220
agents around the country. All these people were recruited in a clandestine manner. We took incredible

59:02.220 --> 59:08.460
steps to make sure that they could not be identified, which Nielsen does too. Nielsen does the same

59:08.460 --> 59:13.020
with the families they used to rate television shows. They've been doing that since the 1950s.

59:14.380 --> 59:21.660
So we recruited these people. We developed a custom add-on for both Firefox and Chrome

59:22.620 --> 59:27.980
that all of these are field agents installed on their computers. That gave us control over

59:28.700 --> 59:33.020
information that we would be collecting automatically when they conducted searches.

59:33.580 --> 59:39.580
In particular, searches using any one of 500 different election-related search terms

59:39.580 --> 59:43.580
that we control. We control that list. Sometimes we could collect whatever we wanted.

59:44.140 --> 59:47.900
But as it happens, we were only collecting information about election-related searches.

59:48.860 --> 59:55.500
And we got our first data starting to come in on May 19, 2016, and we kept going up to the

59:55.500 --> 01:00:03.100
election. And as we worked out the kinks in our system, the rate of data flow increased. And

01:00:03.100 --> 01:00:15.260
ultimately, we preserved 13,207 searches on Google Bing and Yahoo and the 98,044 web pages to which

01:00:15.260 --> 01:00:24.140
the search results linked. And of course, we knew what search positions the links were appearing in.

01:00:25.500 --> 01:00:31.180
So in other words, we had the ability to determine. We were not looking over the shoulders of our field

01:00:31.180 --> 01:00:36.300
agents as they were conducting searches and preserving their actual search results and

01:00:36.300 --> 01:00:40.700
preserving the web pages to which all 10 search results on the first page linked.

01:00:41.980 --> 01:00:47.500
So this had never been done before, apparently. And it was tremendously exciting. And it was very

01:00:47.500 --> 01:00:53.580
nerve-wracking. We then used crowdsourcing to determine whether the web pages were

01:00:54.380 --> 01:01:00.940
favored Hillary Clinton or Donald Trump. And we concluded that, in fact, for roughly,

01:01:00.940 --> 01:01:10.140
for merely six months before the election, Google's search rankings were biased in favor of Hillary

01:01:10.140 --> 01:01:18.140
Clinton. We also determined that the bias in Google's search results was larger than the bias in

01:01:18.140 --> 01:01:23.740
Yahoo's search results, which was much, much smaller. And of course, the fact that they

01:01:23.740 --> 01:01:27.500
have a bias shouldn't be too surprising since they're pulling almost all of their

01:01:27.500 --> 01:01:34.460
search results from Google. And then what about Bing? Well, it turns out we couldn't use our Bing

01:01:34.460 --> 01:01:40.380
data. There were a bunch of data we couldn't use. Why? Because some of our field agents were commuting,

01:01:41.100 --> 01:01:47.900
we're communicating with us using Gmail. We deliberately recruited a few field agents

01:01:47.900 --> 01:01:53.500
deliberately who used Gmail because we knew that if Google took an interest in what we were doing,

01:01:54.300 --> 01:01:58.780
it would be very easy for them to identify those people. So that was kind of our control group.

01:01:59.740 --> 01:02:02.300
So that brings me finally to the one slide I'm going to show you.

01:02:02.300 --> 01:02:07.340
Now, is this real or surreal?

01:02:18.620 --> 01:02:25.900
This is showing you over a 25-day period before November 8 and including November 8.

01:02:25.900 --> 01:02:31.820
This is showing you the bias, if any of those points above the line is showing bias

01:02:32.620 --> 01:02:37.180
or favoritism for Hillary Clinton, this pro-Clinton, below the line that would be

01:02:38.380 --> 01:02:44.540
web pages favored Donald Trump. So this is showing you 25 days before the election

01:02:45.340 --> 01:02:52.220
and you see there are pretty clear favoritism for Hillary Clinton in search results. And by the

01:02:52.220 --> 01:02:56.140
way, it said nothing to do with the search terms because if you look at the search terms people

01:02:56.140 --> 01:03:03.180
were using, the search terms actually slightly favored Donald Trump. So this was not an effective

01:03:03.180 --> 01:03:13.260
search terms. This is an algorithmic effect. And now this is what's cool. These are all

01:03:14.140 --> 01:03:21.500
non-Gmail Google users. What about that control group we had? What about the Google users who

01:03:21.500 --> 01:03:25.020
were also communicating with us during all these months using Gmail?

01:03:34.860 --> 01:03:44.700
Now, to my eye, those graphs look different. Statistically, those numbers are dramatically

01:03:44.780 --> 01:03:52.060
different. At the point 001 level, they're dramatically different. You can draw whatever

01:03:52.060 --> 01:03:58.220
conclusions you like regarding why we got this difference, but what this tells me is when you're

01:03:58.220 --> 01:04:03.340
going to conduct a study like this, you should be very cautious about how you conduct the study.

01:04:04.620 --> 01:04:10.540
What we realized at the end of all this was not so much that our numbers really were very

01:04:10.540 --> 01:04:18.620
important. What we realized is that we have the ability now to look over people's shoulders as

01:04:18.620 --> 01:04:26.460
they're looking at Tinder and they're swiping as they're using Facebook, as they're looking at

01:04:26.460 --> 01:04:31.660
Facebook feeds, as they're looking at not just search rankings, as they're looking at search

01:04:31.660 --> 01:04:38.860
suggestions, you can use the same add-on technology that we successfully developed here in this project

01:04:39.580 --> 01:04:44.700
to look over people's shoulders around the world. You can scale up what we did

01:04:45.660 --> 01:04:52.620
and set it up in country after country after country. When we realized that this was possible,

01:04:52.620 --> 01:04:58.380
what we really had here, a way of keeping tabs on these big tech companies and what they're

01:04:58.380 --> 01:05:04.620
showing people, then I called up some people I knew, including one of these guys over here

01:05:05.420 --> 01:05:10.860
and a guy some of you know named Dennis Allison and some other nice folks, Jake Shapiro from

01:05:10.860 --> 01:05:17.900
Princeton University and Martin Moore from King's College London and on and on and on. The list now

01:05:17.900 --> 01:05:23.260
is growing and growing and growing of people at major institutions who've become part of a group

01:05:24.220 --> 01:05:28.860
that is working to set up a new organization. It's called the Sunlight Society.

01:05:29.820 --> 01:05:40.780
And the Sunlight Society will serve as a kind of monitor of technologies that are being developed

01:05:41.340 --> 01:05:47.740
which could in fact influence people's behaviors, people's opinions, people's votes,

01:05:47.740 --> 01:05:54.860
people's purchases, perhaps without them even knowing. This kind of system, whether we do it

01:05:54.860 --> 01:06:01.180
successfully or not, it needs to exist. There's definitely a need for this at this point because

01:06:01.740 --> 01:06:06.700
everything that I've been saying up until just a few minutes ago was all hypothetical, wasn't it?

01:06:07.820 --> 01:06:13.900
This is not so hypothetical anymore. This is much closer to real or even surreal. This is weird.

01:06:17.100 --> 01:06:24.300
You can use this technology to look at demographic effects, to look at what these

01:06:24.300 --> 01:06:34.380
companies are showing people, how individualized these stimuli are that people are being subjected

01:06:34.380 --> 01:06:41.820
to. You could look at anything that people are seeing on their screens, have it instantly transmitted

01:06:42.940 --> 01:06:49.340
to servers which is what we did, have your servers do an analysis and we're now working on

01:06:49.340 --> 01:06:54.860
automating the analysis of bias ratings, for example. And all of that stuff can be automated.

01:06:54.860 --> 01:07:02.380
You can train algorithms to evaluate text in much the same way that humans evaluate text

01:07:02.380 --> 01:07:06.780
and those algorithms are getting better and better and better. And in fact, both Google and Facebook

01:07:06.780 --> 01:07:12.140
right now are using algorithms like that to try to identify fake news stories. The point is you

01:07:12.140 --> 01:07:21.980
could be collecting data in real time on many different platforms, analyzing the data in real

01:07:21.980 --> 01:07:30.460
time and finding the problems maybe before they get out of hand. You could share these findings

01:07:30.460 --> 01:07:36.060
as appropriate with the media. You could share them as appropriate with law enforcement agencies.

01:07:37.020 --> 01:07:45.260
Courts, I had a conference call a couple of weeks ago with the two top investigators in the three

01:07:45.260 --> 01:07:52.940
antitrust actions that the EU has brought against Google. They're very interested in this kind of

01:07:52.940 --> 01:07:59.500
technology because the evidence they have to support some of the claims that they have made

01:07:59.500 --> 01:08:08.620
against Google is actually pretty weak compared to what we have. So I think we're there. We've

01:08:08.620 --> 01:08:15.900
gone from hypothetical to a little bit more real, but still somewhat hypothetical, to a lot more real

01:08:15.900 --> 01:08:24.220
and then the possibility of really finally being able to make companies like this accountable to

01:08:24.220 --> 01:08:31.100
the public. If this interests you and you'd like to help, you know, join this effort,

01:08:31.900 --> 01:08:36.700
again, whether we do it successfully or not, we know it's going to happen and we know it needs

01:08:36.700 --> 01:08:51.740
to happen. And that's my story. Thank you. So, given the two examples that gave of Facebook and

01:08:51.740 --> 01:09:00.940
Google and given the powerful effect, I'm sorry, and Tinder and given that this effect is so powerful

01:09:02.060 --> 01:09:10.620
as you state, why did you do it from when? Well, he won because of the peculiarities of the electoral

01:09:10.620 --> 01:09:18.300
college and the American people didn't choose him. I mean, Hillary Clinton won by almost 2.9

01:09:18.300 --> 01:09:24.620
million votes. She won the popular vote. Maybe in California with nothing about it. That's irrelevant.

01:09:24.620 --> 01:09:31.020
I mean, if we had a direct vote kind of system, which they have in many countries, then she would

01:09:31.020 --> 01:09:40.300
have won. You know, the analysis of that election, and people are going to be analyzing that election

01:09:40.300 --> 01:09:46.860
for a hundred years, and we all know there's a long list of reasons why Donald Trump won.

01:09:48.300 --> 01:09:52.620
But I will tell you, and I guess it's on the record because I'm being recorded, I will tell you

01:09:52.620 --> 01:09:57.660
that then I'm a friend of some people in the Trump family, and then I was in touch with them on

01:09:57.660 --> 01:10:04.540
election eve, and that there came a certain moment in time, I won't tell you the exact time,

01:10:05.580 --> 01:10:13.660
where I got a text, and the text said, we are all shocked here. And when this person said we,

01:10:14.460 --> 01:10:26.700
this person meant we. See what I'm saying? Not only did they not believe they were going to win,

01:10:27.580 --> 01:10:34.940
I personally don't think based on, again, my personal knowledge of some of the people involved,

01:10:34.940 --> 01:10:40.540
I personally do not believe he had any intention of becoming president, which is why he is still

01:10:40.540 --> 01:10:50.700
looking very much like a deer in the headlights. He was trying to increase his celebrity status,

01:10:50.700 --> 01:10:56.940
he was trying to lay the foundations for setting up a huge media network, and he was putting all

01:10:56.940 --> 01:11:03.260
those pieces in place. And this is not what these people had in mind, which is why they're kind of

01:11:03.260 --> 01:11:10.940
all scarring around, and there's just complete chaos, and you know. So he won because of what

01:11:10.940 --> 01:11:15.580
historians will tell us 50 years from now, that's why he won. See what I'm saying?

01:11:18.220 --> 01:11:23.740
Well, you know, the question is, again, hypotheticals, right? The question is,

01:11:23.740 --> 01:11:29.180
was Google using, and was Facebook using these manipulations to the full extent that they had,

01:11:29.180 --> 01:11:34.060
that was possible? And we have reason to believe that they were not. I mean, we know, for example,

01:11:34.060 --> 01:11:39.340
that Google turned off that negative search suggestion manipulation in early September.

01:11:39.340 --> 01:11:45.340
We know they just turned it right off, like that. So I think that these companies that,

01:11:45.340 --> 01:11:52.300
you know, behind the scenes, or in some cases very openly were, you know, wanted Hillary Clinton

01:11:52.300 --> 01:11:58.380
to win and were supporting her in all kinds of ways. I mean, Dustin Moskowitz, am I pronouncing

01:11:58.940 --> 01:12:04.540
that correct? One of the co-founders of Facebook, he donated just a couple of months before the

01:12:04.540 --> 01:12:11.100
election. He donated $25 million to the Democrats. So, you know, these companies, and the people who

01:12:11.100 --> 01:12:14.780
worked for these companies, they were very strong supporters of the Democrats. But I think, number

01:12:14.780 --> 01:12:22.700
one, I think that they held back a little bit on the manipulations. And number two, I think that

01:12:22.780 --> 01:12:30.140
they were just overconfident. I think they were overconfident. The polls said consistently that

01:12:30.140 --> 01:12:34.300
she had it in the bag. And I think they just got overconfident. And maybe we're being a little

01:12:34.300 --> 01:12:38.220
cautious. And I don't think that they used all the tools that they had available to them.

01:12:40.380 --> 01:12:47.740
But that's why you have to have a monitoring system in place. Because the historians are

01:12:47.740 --> 01:12:53.580
just going to be speculating. We don't need to speculate. We can monitor. We can track. They

01:12:53.580 --> 01:13:03.260
track us. We can track them. It's that simple. And then this won't be speculation. Why is this

01:13:03.260 --> 01:13:07.820
all speculation? There was an article that came out in The Guardian, which has done a very, very

01:13:07.820 --> 01:13:12.860
good series on high tech and very skeptical about, you know, what high tech is serving up to the

01:13:12.860 --> 01:13:19.740
world. It was a very good piece in early December talking about the Brexit issue. And this was by

01:13:19.740 --> 01:13:26.540
Carol Cadwalader. I've spoken with a number of times. Very, very, very, very smart journalists

01:13:26.540 --> 01:13:33.020
and good investigative journalists. And in this article, she laments the fact that what

01:13:34.380 --> 01:13:39.740
people in the UK were seeing on their computer screens, you know, back in June when the Brexit

01:13:40.060 --> 01:13:46.860
book occurred, that it was all lost, that we can't know what Cambridge Analytica was showing people.

01:13:46.860 --> 01:13:51.180
Because it's all lost. It's all ephemeral, right? Most of what we see on screens is ephemeral,

01:13:51.820 --> 01:13:56.460
especially when we're generating search results. That's ephemeral. It exists for a couple seconds,

01:13:56.460 --> 01:14:01.660
and it has an impact on us, and it goes away, and it's gone. So what she was saying was,

01:14:01.660 --> 01:14:05.980
if only, if only we could go back in time and see what people were seeing on their screens.

01:14:06.780 --> 01:14:14.940
Okay? We could do that. I have an appointment on Friday with folks from the Internet Archive,

01:14:14.940 --> 01:14:21.660
which is not far from here, which is, you know, Brewster Kale's project. And, you know, they've

01:14:21.660 --> 01:14:25.340
been following what we've been doing since almost the beginning, because at some point the Internet

01:14:25.340 --> 01:14:31.660
Archive is going to post our database for everyone to, you know, pour through. But I mean, that's

01:14:31.740 --> 01:14:36.620
what we need. We need organizations like the Internet Archive working with people who develop

01:14:36.620 --> 01:14:42.620
monitoring systems, an organization like the Sunlight Society that not only develops and scales

01:14:42.620 --> 01:14:47.500
up these systems, but that looks around the world for other people developing similar systems,

01:14:47.500 --> 01:14:52.940
and kind of coordinates, coordinates the efforts. And this, that we don't have to speculate. We'll

01:14:52.940 --> 01:14:59.420
know what's happening. And this could result in something wonderful. It could actually get

01:15:00.060 --> 01:15:05.900
some of these manipulations to disappear. It's possible if a good monitoring system were in

01:15:05.900 --> 01:15:10.460
place that some of these companies who are doing some of these crazy things, think about swipe the

01:15:10.460 --> 01:15:17.740
boat, will stop because they'll realize this is being recorded. This is being recorded.

01:15:21.900 --> 01:15:27.020
Yes, what is your name? Brad. Now, are you one of the famous or infamous actual students?

01:15:27.740 --> 01:15:32.300
I guess I am. Wow. Well, I will say I have not been here for that many times.

01:15:33.420 --> 01:15:38.300
Well, thank you for coming, person. Thank you. Yeah, this is definitely quite interesting. I'm

01:15:38.300 --> 01:15:41.900
like curious to see more of this data and the need for it is like, it's definitely very clear.

01:15:42.540 --> 01:15:46.540
It's less clear to me like how we can actually be interpreting these results

01:15:47.660 --> 01:15:52.300
right now anyway, without having more of it. Just because like for one difference right off the

01:15:52.300 --> 01:15:57.020
bat with like gmail users, you're always logged into your Google search results. Like that's

01:15:57.020 --> 01:16:01.180
a completely different set of personalization and development going on at Google, right to be

01:16:01.180 --> 01:16:05.820
showing you that you know which results those are. Right. So that's just like already a difference

01:16:05.820 --> 01:16:09.500
there. And then just thinking about how do you measure I think the hardest part there more

01:16:09.500 --> 01:16:12.940
fundamentally is like how do you measure what is a bias set of search results. Let's see, Brad,

01:16:12.940 --> 01:16:17.020
I can see this in your head. I can see the gears because you're not just asking these questions,

01:16:17.020 --> 01:16:19.900
you're answering them in your head at the same time that you're asking the questions.

01:16:20.620 --> 01:16:28.220
Deny that. The first. Deny it. Yes or no. I think I have two different questions. One I have like

01:16:28.220 --> 01:16:33.260
one imagine to answer for which is the personalization components. Yeah. Which is,

01:16:33.260 --> 01:16:37.900
but I think I could be dissuaded at that one. Right. But the second one. It's easy, right?

01:16:39.500 --> 01:16:44.780
You know how to do that, right? Oh, how to change the data. Oh, I'm saying though that you know how

01:16:44.860 --> 01:16:50.140
to track the personalization. It's very easy. Yeah. I'm just saying it's harder to get. I can

01:16:50.140 --> 01:16:53.980
also imagine coming up with algorithms that seem very neutral and are tempted to be very

01:16:53.980 --> 01:17:00.460
neutral that would give identical effects. And that's why I think it's very interesting to study

01:17:00.460 --> 01:17:05.340
more and see if you can like tease out and but B, I'm not ready to like leave to the conclusion

01:17:05.340 --> 01:17:10.460
that Google is manipulating its results to influencer. I don't know what they're doing,

01:17:10.460 --> 01:17:17.100
but I know how to track what they're doing. And I'm learning more and more about how to

01:17:17.100 --> 01:17:22.060
automate the analysis of the data that we're collecting. And I know how to set up systems

01:17:22.060 --> 01:17:27.900
like this. So I think one thing I am curious about is how do you figure out what's a bias

01:17:27.900 --> 01:17:34.380
set of search results? Well, we just thought we that's a very good question. This question

01:17:34.380 --> 01:17:40.300
comes up all the time. And I sometimes I regret using the term bias because it's a loaded term.

01:17:40.300 --> 01:17:45.820
And I'm not using it in a loaded way, believe it or not. I realized bias sounds like prejudice

01:17:45.820 --> 01:17:51.820
and things like that. And I don't I'm using it in the way psychology researchers use the term,

01:17:51.820 --> 01:17:59.100
which is that that favors one perspective over another. And so when we have when we do use

01:17:59.100 --> 01:18:05.740
crowdsourcing to rate, you know, whether a page is pro one candidate or another, we just we give

01:18:05.740 --> 01:18:11.180
them an 11 point scale goes from five to zero to five, right? And here's candidate a and here's

01:18:11.180 --> 01:18:16.460
candidate b. And we say, read the webpage and just tell us whether it favored and on this 11

01:18:16.460 --> 01:18:21.260
point scale, whether it favors candidate a or candidate b. So bias is an unfortunate term.

01:18:22.460 --> 01:18:27.020
The point is you can you can take terms like that operationalize them until you're satisfied.

01:18:28.060 --> 01:18:32.940
So I don't think that's what the problem is. I don't even think that bias per se is the problem.

01:18:32.940 --> 01:18:39.340
I think we're talking about a whole new world that is emerging. And this is I'm actually working

01:18:39.340 --> 01:18:44.700
on a book on this subject trying to think ahead 10 or 20 years. Wow, is that impossible these days?

01:18:45.340 --> 01:18:51.420
But I think a whole new world is emerging in which effects of the sort that I've been telling you

01:18:51.420 --> 01:18:56.700
about are simply going to multiply. And so, you know, it's going to be a game of catch up. And

01:18:56.700 --> 01:19:01.180
that's one of the reasons why you have to have monitoring systems in place, because even if you

01:19:01.180 --> 01:19:07.420
don't understand how those apparently neutral kinds of stimuli, right, but that you mentioned,

01:19:07.420 --> 01:19:10.620
even if you don't understand how that's being used to manipulate people,

01:19:10.620 --> 01:19:14.380
well, if you at least if you capture the information, you can go back and analyze the

01:19:14.380 --> 01:19:19.180
crap out of it. And maybe you can figure it out. And I think that's the world that we're headed

01:19:19.180 --> 01:19:25.420
toward one in which new technologies, I mean, imagine how Google Home could be used to manipulate

01:19:25.900 --> 01:19:31.820
or the new product that Apple just announced. But Apple has never had this motive, by the way,

01:19:32.460 --> 01:19:38.780
because Apple has a different business model. Apple actually sells products. Microsoft actually

01:19:38.780 --> 01:19:42.700
sells products. I realize more and more companies are moving in the direction of Google's business

01:19:42.700 --> 01:19:48.540
model. But Google doesn't sell any products. Not really. More than 90% of their revenue is

01:19:48.540 --> 01:19:56.780
still advertising revenue. They're they use cool looking data collection platforms to collect data,

01:19:57.340 --> 01:20:01.820
and then they leverage that data to make this this year, they're going to make over they'll

01:20:01.820 --> 01:20:09.740
have revenues of over $100 billion. So Google is still the place you have to watch. And

01:20:10.620 --> 01:20:18.620
secondarily, Facebook, Google currently controls five out of the six billion platform

01:20:20.300 --> 01:20:24.220
applications in the world. And there's only one left. And that's Facebook controls the other one,

01:20:24.220 --> 01:20:29.180
which is social media. But what I'm saying is Google, you have to keep an eye on Google,

01:20:29.180 --> 01:20:32.460
but they're going to be other companies. It's not just Google. They're going to be other companies

01:20:32.460 --> 01:20:37.900
doing other things that have never been done before. You know, these these effects, we're

01:20:37.900 --> 01:20:43.660
now studying four effects that have never existed before in human history, completely

01:20:43.660 --> 01:20:51.580
unprecedented, almost entirely invisible, with which produce enormous shifts in people's thinking.

01:20:53.020 --> 01:20:56.220
Our if we're if we have identified and are studying four,

01:20:59.020 --> 01:21:00.460
what do you think, could there be five?

01:21:00.780 --> 01:21:09.340
How many are there? I don't know. You know, we've we've found and are studying four.

01:21:10.060 --> 01:21:13.900
So that does that mean they're actually 10? Does that mean they're actually 100?

01:21:13.900 --> 01:21:19.180
I don't know. But I do know this. Next year, there'll be more of those kinds of effects than

01:21:19.180 --> 01:21:29.180
there are this year. Hal? So let me let me shift to the advertising world. A product is to try and

01:21:29.260 --> 01:21:34.060
give us some of the emotions associated with politics. There's an incredible battle between

01:21:36.940 --> 01:21:41.980
search engines trying to give people what they want, and advertisers trying to

01:21:43.100 --> 01:21:48.060
bump their stuff up there, whether they deserve it or not. Yes, that's right. So how do you decide

01:21:48.060 --> 01:21:55.740
what's fair in this war? And in terms of if I translate this back into politics, how am I going

01:21:55.740 --> 01:22:03.100
to decide what's fair in that world? You know, is your crowdsource evaluation? I can tell you

01:22:03.100 --> 01:22:09.340
what I am, and I can tell you what I'm not. Okay, I'll start with the knots. I am not a lawyer.

01:22:09.340 --> 01:22:17.180
I'm not a public policymaker. I am not a thought leader. I am not. You know what I am? I'm a

01:22:17.180 --> 01:22:21.980
researcher. I'm a really, really good researcher. The more I've done research over the years,

01:22:21.980 --> 01:22:28.300
the more I realized I'm good. I know how to figure these things out, and I love doing it. And that's

01:22:29.340 --> 01:22:33.980
about as far as I could go. No, I think that's cool though. I think that's pretty far. I think

01:22:33.980 --> 01:22:42.540
you're on a wonderful project. Okay. The one thing you haven't mentioned yet is keeping track of the

01:22:42.540 --> 01:22:49.980
stuff that wasn't displayed so you know when you try and go back a year and evaluate something

01:22:49.980 --> 01:22:56.940
as to whether, you know, the stuff that you got was the right sample. Well, that's why we want to

01:22:56.940 --> 01:23:03.420
scale up the kind of thing that we did. If you scale it up large enough, you can keep track of

01:23:03.420 --> 01:23:08.220
all kinds of stuff. Look what Brewster Cale's organization does. You've heard of the Wayback

01:23:08.220 --> 01:23:16.620
Machine? I mean, the Internet Archive takes snapshots of the entire Internet pretty much.

01:23:17.340 --> 01:23:20.860
I don't know if they do the dark net, but I mean, at least, you know, the Internet we most of us

01:23:20.860 --> 01:23:26.860
can see. So, I mean, if you have the resources, you could capture lots of different, and what is it

01:23:26.860 --> 01:23:32.540
we want to capture ephemeral information? That's what we want to capture. That's what is normally

01:23:32.540 --> 01:23:38.780
completely lost. Fantastic. Yeah. And what I'm saying is we can capture ephemeral information.

01:23:38.780 --> 01:23:44.940
Hold on to it. Analyze it now or analyze it later.

