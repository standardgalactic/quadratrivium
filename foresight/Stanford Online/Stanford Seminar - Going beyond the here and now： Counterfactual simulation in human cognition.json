{"text": " Well, thank you. Thank you so much for having me. It's a pleasure to be here. And I hope maybe some of the things that I talk about may give some inspiration for you, HCI guys. So I lead the causality and cognition lab in the psychology department. I'm interested in how people understand causality and basically how the world works and how they understand each other. And we're interested in how people learn about the causal structure of the world, how they, once they have it in their mind, how they can use it to reason about the world, make predictions, make inferences about the past, or think about maybe also how things could have played out differently from how they actually did. And how those capacities also allow us to make the kind of judgments we do in our everyday lives, like for example, assigning responsibility to one another. And that's in fact one of the bigger sort of overarching goals that my lab is working toward, namely developing a computational framework for understanding responsibility. And I think to get there, we have to be able to answer at least two questions, namely one being what causal role somebody's action played in bringing about the outcome. And the other one being what the action that the person took tells us about the kind of person that they are. For this first one, we need some intuitive theory of how the world works. So we can relate the actions that somebody took to the kind of outcomes that resulted from those actions. And for the second question, we need some intuitive theory of how people work. So we can go backwards from the actions that we've observed to the mental states that may have given rise to those actions. So what were the person's intentions, what did they believe, what were the kinds of things maybe that they were able to do as well. And so I studied psychology, like in my undergrad, and I was most excited about social psychology, because I felt sort of most applicable, I guess, to my everyday life, and somehow also got into responsibility, like back then already. Maybe it was because I was in some group project where I felt I was doing all the heavy lifting and maybe I wasn't getting all the credit for it. So that was sort of what interested me initially. And when I read around in that work in social psychology, a lot of the theories that I saw took a form sort of like this. So I'll just give you a few examples. So basically sort of like boxes and arrows theories, where they identified important concepts that were related to how we assign responsibility, and maybe also roughly how they were related to one another, but still left a lot in a certain way unspecified. So this is a quote from Bertrand Molle from a while ago. He says, like, an important limitation of many of these models of moral judgment or assigning responsibility is they don't really generate any quantitative predictions. And you might say, like, oh, what do you need quantitative predictions for? Well, one thing that they're useful for is sort of, you know, laying your cards out and making it concrete, what your model does also allows it then to be falsified more easily. And I remember this one instance, it was like me, I think maybe first day of my PhD, I went to this conference and had dinner, you know, with one of the, one of the people who had made one of these sort of boxes and arrows and diagrams. And I told them about some experiment that I thought, that I thought of and thought, like, oh, this would happen. And I think that would be the result of that experiment. And, and I was very, very smart. I thought, like, oh, this would totally kind of disprove your theory, right? And he said, no, no, that would be totally consistent with my theory. And I thought, oh, that's weird. I maybe I really tried to understand the theory very well. And, and so, so that also was a sort of little bit of a moment for me that I felt like, okay, maybe it's important to try to make these theories even more precise. So we know what it is that they're predicting, so we can go about and, you know, falsify them and sort of improve them. And so that's been very much kind of an inspiration for me, what I've been trying to do it a little bit. And so one of the starting points in almost all of these theories of responsibility is there's causality, always causality comes first. So I thought, okay, let me try, let me try that one. So can we get more specific about what it means, you know, what people, what it takes for people to say that one thing caused another thing to happen. And so I think that three key ingredients that we need, like in order to get a theory for how people think that one thing caused another thing to happen. And those are starting with a mental model that people have of a particular domain, a mental model that allows us to conceive of counterfactual interventions. So, and I'll flush it out a little bit more in a moment. So imagining how things could have been different from how they actually were. And that allows us then to mentally simulate what the consequences of this counterfactual intervention would have been. And so the idea of mental models has been around, you know, for quite some time and has recently gotten a little bit more attention again, also in AI. And, but, but yeah, some of the credit at least in modern times that go to the philosopher Kenneth Craig and his book, The Nature of Explanation, who said something along the lines, well, he said exactly that, but I'm going to say along the lines, so that we have something like a small scale model. Oh, wouldn't it be very helpful if we had something like a small scale model of the world in our minds that we can then use for all sorts of things, like predicting what was going to happen if I did this, rather than actually having to carry out the action and then, you know, dying maybe if it was a bad one. And, and yeah, that that would be really helpful for decision making. And as I will say in a moment also really helpful for explaining kind of why something happened. So this idea of mental models has been around for a very long time. And then in somewhat more recent years, at least in cognitive science, has been made a little bit more concrete, particularly as it pertains to our mental model of the physical world. And so the idea is was here to say like, well, maybe our mental model of the physical world is in certain respects, similar to the kinds of physics engines that we use to make realistic computer games. That's a common move, right? You have some, some tool and then you think like, okay, maybe the mind is a little bit like that tool. So this was just, you know, psychologists playing Angry Birds and then thinking like, okay, maybe the mind is a little bit like Angry Birds. So here, the basic idea, right, is that we take in the world, you know, through our perceptual senses, and that we then build this internal representation of the world. That's now the physics engine kind of representation. So that we pass the world, for example, into objects and the properties of those objects and then the interactions between those objects. So here, this child maybe passes the world into the ball and then the eagle on top of the tower and then the tower or the blocks that make up the tower. And now that you have this internal representation of the world, you can use it, for example, for planning. So if this child, for example, wants to topple over that tower, they can think about what's going to happen if they roll the ball like in different kinds of ways. So I can run simulations using this internal engine in my mind. So having this would be very useful because I could make predictions about the future. I could pay sort of Sherlock and infer from the current state of the world what must have happened in the past. And as I'll show in a moment, this would also be useful for explaining something that happened in the present. Okay, so what I'll do is in this in the remaining time, right? I'll basically want to cover these two different aspects of working towards this computational framework. So in part one, I'm going to focus on the physical domain. And then in part two, I'm going to expand it to just start to think about people. I should say, obviously, feel free to ask questions like anytime throughout. Otherwise, I'll try and end around 12.20 so that we have a little bit of time also for Q&A at the end. Feel free to ask and throughout if anything's unclear. Okay, so let's start with this part one. And I should also warn you, there is a little bit of audience participation required. So get ready for that. So the first, we started really simple, right? I was saying, okay, I want to understand causality a little bit better. What's the simplest possible setting maybe in which you could think about causality? Well, it's two billion balls colliding with one another. And here's the first audience participation part. So there's going to be these two balls coming in on the right side of the screen. And I'm going to ask you whether you think that ball A caused ball B to go through the gate. And if you think so, maybe just raise your arm like at the end of the video clip. So here's what's happening. Okay, so who thinks that A caused B to go through the gate in this case? Okay, a lot of people do anyone think that it didn't? No one dares? Okay, cool. So you're in line with what most people say in this case. And here's what I think was going on in your minds. Not the motor part of raising your hand, but the kind of judgment, the part of, yeah, was there causation happening in this case? And the first part is very kind of uncontroversial. So you looked at what actually happened. You saw that they collided with one another and then ball B ended up going through the gate. And now the somewhat more controversial part is to say that, well, that's in itself is not sufficient. That does not contain all the information you need in order to say that A caused ball B to go through the gate in this case. But you also need something like this. You need the capacity to simulate in your mind, in this case, that removing basically ball A from the scene, kind of in your mind. And then simulating where ball B would have gone if ball A hadn't been present in the scene. Maybe you all sort of naturally and spontaneously did that. And of course, I already talked a little bit about counterfactuals and stuff like that in the experiment. Of course, I don't do that. I just ask people to make causal judgments. So the simple idea here is then to say, when do you say that A caused me to go through the gate? It's really sort of like an epistemic notion. So your subjective degree of belief, well, to the extent that you think that what would have happened in the actual, so that what would have happened in the counterfactual situation would have been different from the thing that actually happened, that determines your extent to which you say that A caused B to go through the gate. And here you're probably pretty sure in this instance that B would have missed if A hadn't been there. So you say, yes, A caused it to go through. And just a little bit in terms of sort of background, a lot of the inspiration for this kind of work comes from Judea Pearl's work on causality. Some of you may have heard of his work. And there they use different kinds of generative models to capture people's causal knowledge of the world. So this could be something like causal base nets or structural equations that you may also remember from your stats class if you had one. And then you define some kind of operations on these models to support things like counterfactual reasoning. So imagining that some variable had been replaced with another one, for example. And so I'm doing something quite similar here, only in that I'm assuming that the generative model that people have of the world in this case is somewhat richer than what can be represented with these causal basis or structural equations. So in my case, the generative model that I assume people have in their mind is something like the physics engine that I actually use to generate them in the stimuli. And I'll make that noisy. I'll show you in a second how I'm making it noisy. And then I also have to think about, okay, what are now the counterfactual intervention operators that you might have over a representation like this one? And in this case, it could be something like imagining that an object wouldn't have been, would not have been there, for example. Okay, so you might think now, okay, well, maybe that's the only game in town. Like what else could you possibly be doing in a setting like this? And at least luckily for me, there has been a lot of philosophers and psychologists that have argued for what I called these actualist theories of causation. And they basically just say you don't need that part, right? All you need, all the information you need to give causal judgments or causal explanations for what happened is there in the actual situation in some sense. And so one of the best kind of worked out accounts of that in psychology comes from a psychologist called Philip Wolff and he calls it the force dynamics model of causation. And the idea is that all you need to pay attention to is the forces that are associated with the agent and the patient. That's the sort of lingo they use. And you then you just look, need to look at how these forces are configured. And that helps you to say what in this case here, there's different causal expressions is appropriate to use in a particular situation. And I'll just apply it to this example here. So we have the patient which is ball B that has a force that is associated with it. Then we have an agent that applies a force to the patient in this case. As a function of these two forces, we have some resulting force here. And then in this case, the patient also ended up reaching the end state. And because this configuration looks like that and that maps onto this force configuration, Philip Wolff's account would also here say, yes, a cause B to go through the gate. So this clip would not help us actually tease apart this other model that I've been kind of promoting. So just to make this distinction sort of clear or clearer. So in the force dynamics model, you start with some intuitive theory of how the world works, which in this case are these little force vectors that apply to agents and patients. And you can then directly go from there to making causal judgments. So there's this direct route from this kind of intuitive theory to causal judgment. He also says that you can do counterfactuals too by imagining, for example, if one of the forces hadn't been there, what would have happened in the situation, but that it's not necessary to figure out whether something caused something to happen. And sort of what I'm arguing for is sort of a slightly different picture. Where I'm saying, well, first of all, I start with a slightly different theory of the domain. In this case, again, using the physics engine rather than using these force vectors. But then saying that you have to go through this process of counterfactual simulation to say that something caused something to happen. And what I'm going to try and do in the next two slides is sort of motivate that account. One way to motivate at first is that I started off saying like I want to have this model of responsibility. And that means that I want to have a model of causation that not only narrowly applies to the physical world, but that can also be applied to, for example, the kind of causation that happens between people. And here's just some examples of causal statements that you could hear at the fall of Lehman Brothers, caused the financial crisis. My housemates failed to water my plants, caused them to die. Realizing that he forgot his wallet at home, caused him to go back. You probably wouldn't say that exactly in English, but they all seem to find sort of causal things, like to say. And it's probably a little bit tricky, or at least I would find it tricky, to think of how would I explain these sorts of causations with force vectors. And the hope is that the account that I'm developing is a little bit more flexible so that it can apply to these sorts of situations as well. But now, and another kind of key advantage, I think, of the model that we've been developing is that it actually allows us to derive quantitative predictions. And it's hence more easily falsifiable that some of the prior work. And so you can falsify it if you like, write a paper until we was wrong. And then I have to go back to the office and improve the account. So here's a way in which we're getting quantitative predictions out of this model. But I was saying that how you make causal judgments is by comparing what actually happened with what would have happened in the relevant counterfactual situation. But now you don't know that. The thing that I'm showing here on the right-hand side, I guess, that's in some sense the ground to truth. But you don't get to see that. You only see what actually happens. You don't get to see what would have happened if ball A hadn't been there. So you have to use your intuitive understanding, again, of this domain to simulate what would have happened in this counterfactual. And so one way for us to capture this uncertainty that you may have about exactly what would have happened if ball A hadn't been there is by generating simulations from our physics engine, but now injecting a little bit of noise into that engine. So now it becomes sort of like a probabilistic program because it's now not a deterministic outcome anymore if ball A hadn't been there. But rather what I'm doing is I'm generating a simulated sample from my model. And now in this case there's many different ways in which you could make your model kind of random or uncertain. Here what we did is we just took the actual ground truth, that ball B, velocity that ball B would have had, and applied a small perturbation to the velocity vector at each point in time. So now it's sort of like in your simulation, when you're imagining where ball B would have gone, it sort of jiggles a little bit along the way. And so this might be now one outcome, like off such a sample. So if you think like, oh, oh, I think it would have missed. But let me try again. Like, oh, yeah, I think it would have missed. Yeah, I'm pretty sure it would have missed. So this is just multiple times sampling in your mind of what would have happened if ball A hadn't been there. And here, since all of them, you're pretty sure that it would have missed, you said, yeah, A caused it to go through. But you can probably already anticipate, we can now do a slightly different case, right, where in the actual situation, again, still A collides with B and B goes in. But this time it's sort of less clear what would have happened if ball A hadn't been present in the scene. Because that ball B is headed like right to the goal post, essentially. And now if you apply the same idea of simulating with noise what would have happened, you know, in some cases, maybe ball B would have missed. But it's also possible that ball B would have gone in anyhow, even if A hadn't been there. And that accordingly, you might say like, yeah, I'm less sure, you know, that A caused ball B to go through the gate in this case. So that's what we did now in our experiment where we showed people a bunch of clips like this one. So here's just three different ones, one clip in which, you know, it's pretty clear here at the top that ball B would have missed if ball A hadn't been there. The one in the middle is like one, this kind of close call. And then the one on the right hand side is one in which it was pretty clear that ball B would have gone in anyhow, even if A hadn't been there. And then between experiments, we either asked them some counterfactual question. So that's the one here at the bottom, the blue one. Do you think that ball B would have missed if ball A hadn't been there? And then we see that in this case, they're pretty sure, yeah, I think it would have missed. Here, they're right at the midpoint of the scale, not sure, right, whether it would have missed or not. So we give them some slider where they can just evaluate their degree of belief. And then in this case, they're pretty sure that it would not have missed, even if ball A hadn't been there. And then we take a separate group of participants and we ask them a causal question. So those participants don't hear anything about counterfactuals. We just asked them in a clip like that, what do you think that ball A caused ball B to go through the gate? And we see that judgments align very closely with those of the ones in the counterfactual question condition. And we can also use that model that I described that draws these samples and tries to simulate what would have happened. And it also yields very similar judgments in this, or makes predictions in this case. These were just three of the video clips. We had like 18 different clips in that experiment. And if we just line up here on the x-axis, the average counterfactual judgments that participants made, and on the y-axis, the average causal ratings that participants gave, you see that they're very closely aligned with one another, at least suggesting a strong relationship between these kinds of judgments. But when we published this work as a coxide paper, so for the cognitive science proceedings, one of the reviewers, they were mostly happy with it, but one of the reviewers was saying, yeah, but all of the clips that you showed participants, something slightly different was going on. So maybe you just didn't try hard enough to come up with an actualistic count, like one that only looks at what actually happened. And if you tried a little bit harder, then you could have explained it away. So we did try, and we didn't succeed, but it's also sort of a weird position that you're in when you kind of don't want to succeed, right? So we thought, okay, maybe the better thing, rather than being crappy at modeling, you know, just let's come up with an experiment where it feels like if it comes up in the way that we think it will, there's no way you could possibly explain it with an actualistic count. And so that's the route we took. So just to really think like, oh, are these counterfactors really necessary for understanding causal judgments? So second round of audience participation, get ready. I'm just going to show you a slightly different clip, and this time I'm going to ask you whether you think that ball A prevented Bobby from going through the gate. Okay, what do you think? If you think that ball A prevented Bobby from going through the gate, you can raise your hand. Okay, a few people think so in this case. Okay, I'll show you another one. Okay, this was not some kind of, you know, glitch. I was having fun, you know, doing the physics engine and sort of playing portal, right, by turning these things into a Taylor port, right? And I didn't tell you anything about them, of course, when I showed you the first clip, but maybe just seeing that one clip, you already have like one shot learning, yeah, okay, maybe that's a Taylor port. And the Taylor port, it works only for ball B, you know, it doesn't work for ball A, and the yellow thing is the entry of the Taylor port, and the blue thing is the exit of the Taylor port. And now that I've shown you that, if I now show you exactly the same clip again, you're going to say, at least if you're like my participants, yes, it prevented it from going through, right? Because now what changed is basically your belief about how the world works, such that your counterfactual looks a little bit more like that now, right? What would have happened is that it would have gone through the Taylor port and into the goal, right? So the fact that I can show you exactly the same clip twice, right? And, and all I've changed was your belief about how the world works. And that makes a big difference to your causal judgment, sort of shows that it's, it cannot be sufficient to explain causal judgments just in terms of what actually happened, because actually what actually happened was exactly the same in both of the times that I showed you the clip. I don't need to do the Taylor port thing. The Taylor port thing is cute because I can show you exactly the same clip, but I can also move some obstacle in and out of the way, right here on the left hand side, you're not going to say that A prevented B from going through the gate. On the right hand side, you are because the block is out of the way, right? And a similar way for causation. And on the left hand side, you're going to say, yeah, A caused it because the block would have blocked it. And on the right hand side, you're not really going to say that it caused it because it would have gone in anyhow, right? Same idea. I'm doing exactly the same interactions between the balls. I'm just changing something kind of in the background that affects the counterfactual and, and thereby also affects people's causal judgments. Okay. So another thing that's sort of neat about this model is that it doesn't only kind of predict basically the judgment that people should give at the end of it, but also says something about the cognitive process by which they arrive at the judgment, right? In this case is maybe this process of mental simulation, that you kind of generating these samples and thinking about what would have happened, and that those drive the causal judgment. And one way we can do that, or can sort of get more direct evidence on that is to use eye tracking, right? To see, okay, where is it that you're looking at when you're asked to make causal judgments in these kinds of video clips. So we went back to the really simple ones again. And now also between experiments, just ask participants a different question about the video that, that, that they would see. And they knew at the beginning what question they would be asked. So we had one condition here that we call the outcome condition where they'd watch the video and we would just ask them at the end, in this case, if it ended up missing, did be completely miss the gate. And so I'll show you the eye movements of one of the participants in this condition. And I'm going to play the video at half speed and I'll do some sort of life narration as it unfolds. So the blue dot is the eye movement, right? So the participant here is looking back and forth between ball A and ball B. So looking, looking at ball B, sort of now trying to extrapolate where ball B will end up hitting the wall. And then mostly looking at ball B. Not very exciting, but also that's all they need to know in order to answer this question in this case. So now if you take a different participant who was asked to make a causal question, or asked to answer a causal question in the video, but otherwise saw exactly the same video clips as other participants did, you're going to see that the eye movements look quite different. And they look different in a way that made me very happy at the time. So you see they're not just looking at ball B, they're trying to anticipate where ball B would have gone, you know, if ball A wasn't present in the scene. And it's quite likely that when you guys, when I showed you this first video clip that you did that, right? And may not even been super, you know, aware to you that you did do that, like I haven't really checked, you know, yeah, how, well, at some point at the beginning when I ran this on the laptop, I would sometimes see that people would use their finger, or they would use their, you know, kind of pen or something. And that's of course pretty aware, I guess, right? But it's possible that with the eye movements, this sort of comes so natural to us that we don't even realize that we're engaging kind of in this kind of process. But yeah, I was very happy, you know, when I saw this happening. And so this is anecdotal in a sense, it's just one video clip, right? But we can also look at more generally, sort of analyzing the differences in the eye movements that people are producing between these different experiments. And what I'm showing here is just looking at the saccades that participants are producing. So those are fast eye movements jumping from one point to another. And then I look at the endpoints of those saccades. And I look at where those fall, right? And I took into account only the time between ball A and ball B coming into the scene. And before basically, when they collide with one another, that time window. And then we see that on this, for the causal question, a lot of those saccades basically end up along the path right that ball B would have taken if ball A hadn't been there. Whereas in the other condition, we see very few of these kinds of eye movements. So nice, I guess, even more direct evidence that people are engaging in this kind of process and that they're doing it specifically when asked to answer a causal question about the clip and sort of spontaneously. There is this other part to it. But I think I will skip, so I have a little bit more time to, let me see. Well, actually, I'll share it. Sorry about that. So there was another, after we published this paper, there was another reviewer number two, as there often is. And they were basically still saying, okay, well, this was for the eye tracking data. And they said, that's nice. You're showing us these sort of eye movements. But they basically said that, okay, these eye movements, they're happening before the balls are colliding with one another. And you're calling it sort of counterfactual simulation. Counterfactual should mean it should be back in the past. Going back in the past, evaluating that something would have been different, and then seeing what difference that would have made. And they were saying, oh, what, you should just call it the hypothetical simulation model instead, and not that. So we were able to push back. But the reviewer also was right to some extent, I think. So this is a paper that I've published quite recently, where I was trying to say that, no, you really need the counterfactuals. So a lot of this has been like, yeah, you really need the counterfactuals. And then you just keep getting some pushback, and you try to convince people even more so. So this was this reviewer number two here. You haven't really shown us counterfactual simulation. Those looks are happening before the balls are colliding. So his idea was, well, maybe what people are doing is they're kind of simulating some hypothetical future. In this case, the hypothetical future is like, what would happen if ball A wasn't there? And then they're storing that in their mind, and comparing that to what actually happened at the end. And that's a slightly different computation from the one that I think they're carrying out. And this relates to something, again, here's Judea Pearl, this climbing on this kind of virtual letter here. Because he has argued that there are these three different ways of thinking about the extent to which people have causal knowledge of how the world works. On the lowest rung of the letter, and he often accuses a lot of deep learning and so on to be on that rung, although it's a little unclear, he calls that rung the level of association. So that's what you learn in the stats classes correlation. When two things are associated with one another, and you can infer one variable from the presence of another, so the normal conditional probability, PY given, I would say PY given X. So what does some symptom tell me about the disease, for example? On the next level, it's the level of interventional reasoning. That's the kind of when I do a randomized control trial, for example, or if I'm, again, hypothetically reasoning, oh, what would happen if I were to do this? What would happen if I were to do that? And that's sort of when your stats teacher tells you causation and correlation aren't the same thing, that's often the thing that they then think about, right? That like, oh, on the level of an experiment, now I'm performing an intervention, randomly assigning people to different groups, and I can draw different kinds of causal inferences from that information than when I just have observations. But then process ultimately, the kind of the highest rung on the letter is reserved for counterfactual reasoning, and that allows you to give specific answers essentially to why questions. So why did this happen in this particular case? Like, you know, was it the aspirin that stopped my headache, or would it have stopped anyhow, even if it hadn't taken the aspirin? Or, you know, was Kennedy shot? Would Kennedy still have been alive if it hadn't been shot by very heavy-ass world? And so essentially, now the question boils down to, do we need that third level, like to explain people's causal judgments, or is the second one enough, right? So just to kind of try and make it a little bit more clear, right? So the hypothetical, luckily in English, also we have sort of a way of marking the difference between them. So here's an English hypothetical. Would B go into the goal if A was removed? So what you'd be doing is taking the time into account until they collide, simulating like a possible future, and then computing the probability of that. Versus the counterfactual, what I'm doing, slightly different in English, right, would B have gone into the goal if A had been removed? I sometimes, you know, regret having gotten into counterfactual so much, so obviously not a native speaker, and the counterfactuals are sometimes a little complicated, right, that you get the tenses right and so on, but I think I've mostly gotten it down by now after like 20 years. So would B have gone into the goal if ball A had been removed? So you're doing slightly different here now, right? You're taking into account everything until the end, and you're now going back in time to do this intervention and then think about how the world could have unfolded differently from how it actually did. So now it turns out in this very simple setting here, that makes no difference. The hypothetical probability and the counterfactual probability is the same because there's nothing, there's only this one causal event happening, so it doesn't really come apart. So in a very simple setting where you have one cause and one effect, essentially, you cannot tease the two apart, but you don't need to make it much more complicated. It's sufficient if you just have one other alternative event that you are initially uncertain about, and that will make it such that now the hypothetical probability and the counterfactual probability will be different from one another. So here was the genius invention, just putting like a little block again that you've seen earlier, but this time the block is on rails into the scene, and that will now make it such that we can tease these two different things apart. So here's an example. I'm not going to ask for audience petition this time, but let's say that this was happening in the clip, and now if you were asked to say, oh, did it prevent it from going into the goal? My participants say in this case, yes, it did. And the idea is, why is it? Well, because the block moved out of the way in time, such that Balbi would have gone through the goal if Ball A hadn't been there. But you may have also noticed that the movement of the block is happening after the balls collided with one another. So not something that you could have sort of anticipated at this earlier moment in time, or at least had some uncertainty about. So the basic idea here is to say like, oh, my hypothetical probability at the time would Ball B go into the goal if Ball A wasn't there? Well, that's unsure. That depends on whether or not the block's going to move. So I should give it like a 0.5 or something. I told participants it's just as likely to move as it's not. Whereas for the counterfactual probability, well, I know that it moved in this case. So I should be pretty certain that it would have gone in if Ball A had been removed. So now I have a way basically of teasing the two apart and can see which one better explains the causal judgments. Is it the hypothetical judgments that I ask participants to do, or is it the counterfactual judgments that I ask another group to do? And then I ask one group to give causal judgments and then just try to relate them to one another. And what I find is when I look at the hypothetical, so maybe I should say a little bit more about that plot here, at the bottom, it basically shows you the initial configuration of the block. Was it in the way or not? And then did it move yes or no? So in this example here, it's one where it was initially in the way, but it moved. But in the hypothetical condition, you don't know that because you only see it until they pause. And then if you look at the hypothetical judgments, they think when it's initially in the way, they think it's a little less likely that it's going to go in. And when it's initially out of the way, they think it's a little bit more likely. So they're sort of a little bit sticky in terms of what actually happened. For the counterfactual probabilities, pretty much only the final state is what matters. If it was out of the way at the end, you think, yeah, it would have gone in. If it was in the way at the end, you think it would have missed. And now if you ask people to make causal judgments in this case, we see that they align very closely with the counterfactual ones and not with the hypothetical ones. And this was for the kind of missed cases, but the same story again holds essentially for the causal cases too. So they think that it caused it when the block would have been in the way at the end, and they don't think that it caused it when the block was would have been out of the way at the end. So enough to make this review too happy, but maybe not Michael. I'm a happy guy. I'm curious. Can you go back one slide? Just to make sure I understand. There were two things that changed in that intervention. There was the question you asked, the hypothetical versus the counterfactual. And it also sounds like the changes in how far they saw into the video. That's right. That's right. And I'm picturing the counterfactual situation where if you ask me the hypothetical question, but showed me the full video, so I see a whole video and then you say, would be going into the goal if A was removed? I don't know. Yeah. Yeah. It's a tricky one. I mean, I guess, you know, you'd have to ask them, like, what did you think? I guess sort of at the time, right? Like before it happened, did you think, and people are often bad at that, right? We know that from all the hindsight research and so on, that they have difficulty putting themselves back into the epistemic state, I guess that they had at an earlier point in time, right? So I'm not exactly, I haven't tried that one. I haven't tried showing it until the end, but then asking them the hypothetical question, it's possible, of course, that they will confuse it like as a counterfactual question, right? And, but for me, it was still sufficient, I guess, at least to address this reviewer's concern, because his idea was really, yeah, that computation is happening earlier, right? It's happening before the causal event of interest, and then you're storing the output of that computation, in this case, the hypothetical probability, and then just comparing that to what actually happens at the end, right? So it still felt that it's addressing that, but yeah. Okay, so having these two things helps teasing them apart. Okay, I'll sum up the first part, and then the second part will be short, but that's okay. So for this counterfactual simulation model, what I've showed you that there's this sort of nice correspondence between people's beliefs about the relevant counterfactual and the causal judgments that they make, that it looks like that these things are necessary, which you can show with the teleport or with the, with the brick in and out of the way, that people spontaneously engage in this kind of counterfactual simulation as evidence to the eye movements, and that it's counterfactuals really and not hypotheticals that seem to be important for expanding causal judgments. We've played around with this model like a little bit more. Once you have a hammer, right, you find all the nails. So this one is just like looking at slightly more complex cases. This one here, philosophers love, because it's a case of, let me show it again, maybe a case of double prevention, where B prevents ball A from preventing ball E from going through the gate, right, because knocks it out. It happens in, maybe in football, probably happens often when one tackles like another person that would have tackled the person running with the ball, right. And so you might say, oh, to what extent did that cause it? You can also look at omissions when nothing is happening. So ball A is just chilling here in the corner, and you might still ask, oh, did it go in because ball A didn't hit it, right? And now you could imagine, well, if it had hit it, what would have happened in this case? And we can also look at cases where really nothing is happening at all. So here's just a tower of blocks, right, and you might still wonder, oh, to what extent is this black one here responsible for the other one staying on the table? And even though, yeah, there's nothing happening, right, you might still say, well, how do you answer this question? Maybe by doing something like playing Jenga in your mind, right, imagining it being removed, and then what would have happened to the scene? So that even just physical support in some sense is very closely related to ideas of causation, right. What it means to support is essentially to prevent something from falling. Okay, so that was part one. Now a sort of short version of part two. And so responsibility attribution was something that I've been into for quite a while and was also my motivating thing. And then I drifted off into causality world mostly just because physics engines were around at the time. So it was like, oh, now I can use those. And with around at the time, I mean, I was a postdoc with Josh Tenenbaum back then and physics engines were all the rage at the time. And I said, okay, now I'll also use them. And there aren't really yet, although I guess Michael is working on it, psychology engines, right, that is easy where you could just have agents and think about what they would have done. So this work that I had done on responsibility attribution wasn't particularly social, also didn't really involve simulation, I think. And there was one experiment that got a little bit closer that I'll briefly share with you here on a paper called Moral Dynamics. And it will look very billiard ball world like I haven't moved too far away from the billiard balls, but this kind of that's somewhat agentive, right? So and so we could show people like a video clip like this and then ask them, what about extent do you think that blue was responsible that the green one got harmed in this case here? And our inspiration here came from a paper called Moral Kinematics where they basically argued, again, it's somewhat more actualist view and saying, okay, there's certain features that people are picking up on in these scenes, like the duration of contact, how far things moved and things like that. And then they directly mapped from these features of the scene to the moral judgment in this case. And we liked the general setup, but didn't really like that model like as much. So we proposed another model that has a slightly different title, Moral Dynamics instead. And we thought, okay, these features are important, but the features are important in that they give us evidence for the latent variables and that those are ultimately the ones that I care about. And in this case, what are the latent ones that we thought one, not very surprisingly here on the right hand side causality, but did you think that it actually caused it, you know, to for this negative outcome to happen. And then the left side, the intuitive psychology part, very kind of minimal in this case here. But it's basically saying like, well, maybe these features give you some evidence about like how much the agent actually wanted to bring about this negative outcome. So if you think, for example, if somebody really wants something to happen, then they're willing to incur a larger cost to make it happen. Putting a lot of effort, for example. So if somebody puts in a lot of effort into something, you know that they must have really valued it. And if somebody really valued some negative outcome, well, that's a bad thing. That was roughly the idea here. And we could then show that if we have a model that just basically infers the amount of effort that some agent exerted and tried to map that onto the responsibility that worked kind of, you know, okay-ish. If we only took into account the causal role that some agent played and tried to use that to explain the extent to which they're held responsible, that worked okay-ish. But if we now took a model that takes both of these components into account, that worked pretty well, which was roughly in line with this kind of unsurprisingly, now this framework that I laid out at the beginning, right, that when we assign responsibility to others, we don't just care about the causal role that they played, but also what the action tells me about the kind of person that they are. In this case, the action tells me something about the desire that they had to bring about this negative outcome. Okay. But still, we didn't really have a real model of agents in this case. We still sort of basically just use the physics engine. Also, we weren't able to talk about intentions, and it's clearly important often when people talk about responsibility. And also still our kind of factual simulation here was basically purely physical, just seeing how this thing would have moved without the other one. So I don't have the skills to make it happen with sort of more agentive agents, but luckily now that I'm here, I get to work out with all these smart people, and here's my PhD student, Sarah Wu, and our research assistant, Shruti Sreeta, and they've looked into cases now that are a little bit more agentive. They're still kind of in in grid world, but at least now planning and intentions and things like that are involved. And here's the basic setup. So this is inspired by some previous work that has looked into helping and hindering as a case study. And what they did is essentially they said, well, what it means for somebody to intend to help someone is that their utility function includes the other person's utility with a positive sign. Intending to help just means wanting to bring positive utility, at least in this framework, to the other person. And intending to hinder puts a negative sign, like now I want it that the other person is a low utility. So it turns out though that intending to help or hinder versus actually helping or hindering is not necessarily the same thing. So here's an example. I don't have a child yet, but at some point maybe we'll have a child, and then if I go grocery shopping with the child, there probably will be a period of time where they're not actually helping. They're sort of like trying to help, but kind of making it worse, at least in terms of efficiency and so on. It's going to take longer. Of course, it's useful because eventually they will be helpful. I have to go through that process just like a PhD student. So yeah, so you go through that process, and then you might intend to be helpful, but it might take a little bit of time to actually be helpful. And the claim is to evaluate that, you need counterfactuals again to tell, oh, is the person actually helpful? Well, how would it have happened without them, essentially? Or there's different counterfactuals to consider, but that's one of them. So here's our grid world that we played with, with the helping and hindering setup. So we have this red guy here who wants to get to the star, has a pure physical goal in this case, just to get to that location. Then we have this blue one who has a pure social goal. They either want to help or hinder the red one from getting there. And then there are these walls here that you can't do anything about, but there's also these blocks, and only the blue one can interact with these blocks. They can push, pull them out of the way. So here's our Hollywood clip of what's happening in this situation. Okay, so in this case, happy end, like a Hollywood movie, red made it, and then we can show people these clips and we can ask them, oh, how responsible was the blue player for the red player's success, for example, in this trial? We can also ask them a counterfactual question, right, would the red player still have succeeded even if the blue player hadn't been there? And we can ask them to make an inference about the intention of the blue one in this case. What was the blue player intending to do? Were they trying to help or were they trying to hinder? Definitely help, definitely hinder. So the idea is now basically the same as earlier, by just saying, okay, again, we need some kind of generative model of the domain. In this domain, now it's a model of agents basically planning and recursively reasoning about one another, right? And that's now our probabilistic program. And we can again compute counterfactuals over that, maybe in this case thinking, well, what would have happened if the blue one hadn't been there? And then thinking how the red one would have planned their path differently, but without the presence of blue, that's a rough idea. So again, we take some actual situation and we can then simulate what would have happened in the relevant counterfactual situation in this case where blue hadn't been there. We can talk later if you like about other counterfactuals you might consider, but we just went with this one here, but what if they hadn't been there? In this case, yeah, they wouldn't have made it because the block was in the way, right? We also have a model of intention inference, but I'll sort of skip that. It's basically just saying, okay, if you have a generative model about what an helping or hindering agent would do, you can then condition on the observations that you see them acting and see what's more likely that they were helping or hindering given the actions that they carried out. So I'll just give you a few more examples of the sort of video clips that we showed to participants. That's a diagram of the one that you've just seen. Here's another one where kind of, you know, blue is sort of extra mean, you might say. There was already a block in the way, but they put another block in the way. What the heck? Yeah, really trying to be helpful through adversarial actions. So here's another one here where blue is sort of laudably helpful, but like, you know, was not really necessary, but maybe looks nice. Here's a case in which sort of things go wrong. Where blue was maybe trying to be helpful, but actually sort of made it worse, you know, the reactions that they took. And then here's another one. We had a large number, so I'm just showing like a subset of them. So this is one where blue could have easily hindered if they had wanted to, but didn't, because they could have just pushed it into the way. And so then we now have to again, yeah, try to capture whether we can, with our model, capture the counterfactual judgments that people are making. And we sort of can, there's not as much kind of variance here, at least in the predictions of the model. So this model is sort of okay-ish. It captures the trends overall, but there's more variance in people's judgments that is not quite captured by the model yet. So we're still, this is sort of more ongoing work. In terms of intention inference, it's fine. So it can also kind of infer whether the person was helping or hindering, but also here, what you see is stuff are bunched up that the model all gives a hundred to, where there's still some differentiation that people make, but sort of mostly captures what's going on. And if we now look at the responsibility judgments, and we try to do the same thing initially that we did with the billiard balls earlier, that we just take the counterfactuals, like on the x-axis, and try to predict the responsibility here on the y-axis, it's okay-ish, but not, you always want, when you do computational modeling, you always want them nicely line up on the diagonal. And that's not really what was happening in this case, whereas for the billiard balls, we have this very simple counterfactuals nicely predict the causal ratings. But if again, if you have a model that incorporates also the intention inferences, like into the predictions, now they do sort of more nicely line up on the diagonal. Again, suggesting that when it comes to assigning responsibility for agents, it's not just the causal role that matters. It also matters what the actions that they took tell me about the kind of person that they are. In this case, it tells me something about their intentions, like they try to be helpful, or that they try to be hindering. So the both of these components. And just to give you a sense of an example where we need this kind of intention part, like that's back to that mean one where the blue one pushes another one into the way, right? And so just to help you kind of interpret the bars here, the counterfactual, that's the condition where we asked them, would red have succeeded if blue hadn't been there? That's basically our causal model. And they don't think so, right? The pink, pink, purplish one is like very low, right? But also when we asked them what the intention of the blue one is, they think, yeah, was really hindering. So here zero means hindering and 100 means helping. So they think, yeah, they were hindering. So even though they say that, yeah, the blue one didn't really play a causal role, they still give them quite a bit of responsibility, like in the blue one on the right hand side. So that's one case, at least, where currently we need this other part. So they think, yeah, blue blue's actually make no difference, but they were definitely trying to hinder. And so, yeah, I still give them some responsibility for this outcome. Okay, so sort of almost last slide. Because we have these agents like recursively thinking about one another, an interesting setting that also can happen here is that you can actually hinder or help one another, again, maybe also like in the, in the advisor, advisor setting, not by actually making any change to the physical world, but changing somebody else's belief. So I just want to show you that example. And maybe you'll get that intuition from the setting here. So very, very mean, very, very sad. Because it looked really like blue was going to help, right? And then they didn't, right? And here's just one participant, what they're saying, oh, blue tricked red into thinking she was going to move the box to help. But then once red was stuck on the side of the wall, blue left the box where it was, very sad, you know. And a lot of people say something along those lines. We also had one condition where we just have them give explanations of what happened, right? And here the interesting part, right, is that the hindering is not happening because blue changed anything about the world. They didn't move a block in the way or something, but they hindered because they made red believe that they were going to be helpful and then they weren't, right? Here, if blue hadn't been there, red would have just walked along on the outside and they might have made it, you know, anyhow, even without blue. And this happens because they're recursively thinking about one another, right? And red things like, oh, blue is taking actions that are going to help me so I can take the shortcut. And then it turns out I couldn't in this case. Okay, wrapping up. So this was the second part where we, I guess, applied this model now to at least a simple setting where agents are interacting with one another, helping and hindering one another, that in order to judge whether somebody helped or hindered, I again think that you need this process of counterfactual simulation and that responsibility judgments are sensitive both to the cause of the world that somebody played and what the actions tell us about the kind of mental state that they had. Just to conclude, so together, hopefully, this sort of set of studies gets some evidence that people seem to be constructing these rich mental models of the world that we can get evidence for in different kinds of ways, like through eye tracking and other tools. By imagining interventions like on these mental models, those allow us to compute the counterfactuals, which I think are important for assigning responsibility, giving explanations and so on. And that this counterfactual simulation model that I've been kind of developing can then be relatively flexibly applied to physical and social events, where you think that the main thing that's happening is that your model of the world changes and maybe the exact counterfactual cooperation that you're carrying out changes, but otherwise the framework sort of holds. So with that, I want to thank the main people who helped me do this kind of work, and then maybe you for your attention. And there's a little bit of time for questions. So one thing I'm curious is, I assume notions of causality are probably somewhat universal, but especially issues of moral judgment, intention are likely dependent to some extent on environmental factors, cultural factors, those kinds of things. And so I'm curious if you've either observed those in your experiments or if you have some way of controlling for those factors when you recruit participants. Yeah, so that's an interesting question. And I think even notions of causality actually, there are cultural effects like who you see there. So when making causal judgments, there's often, there's basically like in many cases, what's called the problem of causal selection, how do I even decide what thing to pick out of as the cause in the first place. In my setting, very often I've kind of made it pretty easy, and I've sort of constrained it because I already told you like these are the possible causes, but in the real world it's not like that. And it's sometimes, we may see something, we may see a person as a cause, or we may see a system as a cause, or we may also see the kind of counterfactuals that may come to mind to us may also depend on what our background is. And it often tells us something about, oh, when somebody then gives a certain counterfactual, it tells us quite a bit about them. So this comes up in the context, for example, also of victim blaming. Like if that's the counterfactual that came to mind to you, oh, that tells me something like about you. So I would say that even in that context, there are strong kind of interpersonal and cultural effects that affect how we attribute causality. Now when it comes to intention inferences, I'm not sure that that process in and of itself, that at least to me feels relatively whatever universal, that we kind of, we have to engage in that all the time by trying to predict what other people are intending in the way that we interact with them. But then again, how maybe then judgments in this case of responsibility or morality like draw on these different components, for example, that I've laid out here, no claim that that is in any sense sort of universal. But it might very well be that in certain cultures like this kind of what I take here to be more the person component, right, may have a stronger influence on responsibility judgments and in others, it might mostly be about causality. I certainly in my experiments for individual participants see a lot of variance along the lines. But there's some people that don't care about even the intention part at all. They just say like, oh, when it's about responsible, I just look at what would have happened if they hadn't been there. And then other participants, judgments are suggesting that they care about the intention part much more. But I have not yet engaged in the kind of work that then tries to explain why is it, why is it that this person casts so much about causality and why is it that this person casts so much about the intention part, for example. Thank you. I'm going to hug the mic actually. I'm interested, like, do you think this model applies to other settings? Because all of the examples were sort of like physical or agents taking physical actions. So if you had just like a verbal description of some social scenario where there's like speech acts that are causing things, do you think it would work the same? Yeah. Yeah, that's a great question. So would it work the same? So my sense is like, yeah, in a similar way, so there's a number of things here, I think. So we have applied the model a little bit, like this kind of counterfactual simulation model in the physical world, also two speech acts. And there it's in the context of like, we were basically jealous of, you know, for those of you who remember full wolf, you had these different words, right? And we were like, oh, our model can only do like cause and prevent. That's kind of sad. But there's other causal expressions, of course, right? Enabling, affecting, letting, allowing, and so on. And it's going to be a little bit of a of doing, but I'll get there. So we were trying to see to what extent this framework that we have could also allow us to explain differences between these different expressions, right? And, and this also comes up, you know, in philosophy, like even questions, so the question versus killing versus causing to die, even people like in cases of abortion, you know, the way that you talk about it, right? Again, reveals something, you know, how you think about it. And in general, right, like this distinction also, when you have that as an alternative that you could have said killing, but you chose causing to die, it suggests maybe a more roundabout way in which something happened, right? Like the person killed it, caused them to die. You think, yeah, it would be weird to say that someone caused them to die when they like, you know, directly walked up to them and, you know, shot them. This also came up recently or still coming up these days, actually, with the case of Alec Baldwin, Rust, like in the movie, right? The way that people talk about it was it will hold the gun that discharged or something rather than, you know, shot the person, right? So it matters a lot, basically, like in this case, the choice of word, right? And the, and the, in some sense, the counterfactual alternatives you could have had, right, for them, the image that it's creating in the listener in this case, right? So the fact that, oh, you chose this expression suggests to me that the scenario must have been such, like rather than such. So that's at least the minimal way, I think, in which it applies also to, to thinking about speech acts, right? And thinking like, yeah. And of course, you could think like, oh, you know, again, take the advice example, would the students still have done that if I had not said that, right? So we are obviously causing each other a lot in the way that we talk to each other. And sometimes, you know, yeah. Also, of course, after talking, I might think like, oh, I wish I had, I had answered this question from differently than what I actually did. And I regret it, right? And things like that. Yeah. So on a similar note, I'm wondering if you have thoughts on how possible it would be to use this model on society, large scale societal events, their divisive, such as what cost a person to be elected, what cost code outbreaks, or what causes climate change, like how possible would it be to apply this to those events and also what challenges you foresee? Yeah. Yeah, that's a great question. And, and so, so I had the example of example at the beginning with like, oh, did the fall of Lehman Brothers caused the financial crisis, right? That's sort of like, large scale. And I don't know, right? And, and, and partly it might, so, and there's a few options, right? One is like, okay, just like totally punting, right? And saying like, okay, well, if the system gets sufficiently complex, such that I cannot carry out the relevant counterfactual computation anymore, well, I just don't know, right? I cannot give that causal answer. That's, that's one version, right? And there's another version where you say like, okay, well, to the extent that I can maybe, you know, abstract away from a lot of the lower level details that say of some, so if I'm, if I'm, if I have the capacity to build maybe a more abstract model, which, which I can now simulate, right, then I might be giving you an answer sort of on that level, right? And so, but then it's also half punting, right? Because now you have to kind of come up with a good model of how people generate the right kind of causal abstractions for some situation that then allow them to compute the counterfactual, because now it's not messy anymore, right? And another thing that I should mention, and that quite a lot of the work on responsibility that I've, that I've looked at particularly in groups, the sort of situations that you pointed out, like elections and, you know, global warming, they're, they're characterized by, by large degrees of over determination, right? Like in election, you hardly ever cast a pivotal vote, right? And, and so those also traditionally were problems for counterfactual accounts, right? Because everyone can say like, I made no difference, like if I fly every day, you know, that's not really going to make a difference. And so, and there you can, and similar with election, why should I go vote, right? Because if my vote's not going to make any difference, right? And there at least models have been built that then say like, okay, well, it's not, you're not off the hook, right? It's basically saying, even if you would not have made a difference in this particular situation, maybe the degree of responsibility that you have for some election, for example, maybe related to how close you were to making a difference to the outcome, right? If it's like, if the outcome is 6-5, you feel very responsible. If it's like 7-4, a little less. If it's like 8-3, a little less, right? But not, but it shouldn't go to zero, right? And then, and then as it, maybe now relates to kind of, you know, global warming and so on, part of the challenge then from the more like, you know, what do we do about it? Side might be like, okay, how do we make it such that people don't perceive a sort of, you know, going to zero sense of responsibility, right? Such that you feel like actually the actions that you do make a difference to the outcome. And so, yeah, so that's, so I think a mix of thoughts, I guess, in response to your question. So we're about it, time. Is there a reminder if you are here? If you're logging attendance, make sure to grab one of these code words up at the front and give Toby a compliment on his talk on your way out, maybe make you come up next door. Let's thank our speaker.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 15.72, "text": " Well, thank you. Thank you so much for having me. It's a pleasure to be here. And I hope", "tokens": [50364, 1042, 11, 1309, 291, 13, 1044, 291, 370, 709, 337, 1419, 385, 13, 467, 311, 257, 6834, 281, 312, 510, 13, 400, 286, 1454, 51150], "temperature": 0.0, "avg_logprob": -0.20554216357244962, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.04403899237513542}, {"id": 1, "seek": 0, "start": 15.72, "end": 21.84, "text": " maybe some of the things that I talk about may give some inspiration for you, HCI guys.", "tokens": [51150, 1310, 512, 295, 264, 721, 300, 286, 751, 466, 815, 976, 512, 10249, 337, 291, 11, 389, 25240, 1074, 13, 51456], "temperature": 0.0, "avg_logprob": -0.20554216357244962, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.04403899237513542}, {"id": 2, "seek": 0, "start": 21.84, "end": 26.04, "text": " So I lead the causality and cognition lab in the psychology department. I'm interested", "tokens": [51456, 407, 286, 1477, 264, 3302, 1860, 293, 46905, 2715, 294, 264, 15105, 5882, 13, 286, 478, 3102, 51666], "temperature": 0.0, "avg_logprob": -0.20554216357244962, "compression_ratio": 1.4216216216216215, "no_speech_prob": 0.04403899237513542}, {"id": 3, "seek": 2604, "start": 26.04, "end": 30.24, "text": " in how people understand causality and basically how the world works and how they understand", "tokens": [50364, 294, 577, 561, 1223, 3302, 1860, 293, 1936, 577, 264, 1002, 1985, 293, 577, 436, 1223, 50574], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 4, "seek": 2604, "start": 30.24, "end": 34.92, "text": " each other. And we're interested in how people learn about the causal structure of the world,", "tokens": [50574, 1184, 661, 13, 400, 321, 434, 3102, 294, 577, 561, 1466, 466, 264, 38755, 3877, 295, 264, 1002, 11, 50808], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 5, "seek": 2604, "start": 34.92, "end": 38.68, "text": " how they, once they have it in their mind, how they can use it to reason about the world,", "tokens": [50808, 577, 436, 11, 1564, 436, 362, 309, 294, 641, 1575, 11, 577, 436, 393, 764, 309, 281, 1778, 466, 264, 1002, 11, 50996], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 6, "seek": 2604, "start": 38.68, "end": 42.32, "text": " make predictions, make inferences about the past, or think about maybe also how things", "tokens": [50996, 652, 21264, 11, 652, 13596, 2667, 466, 264, 1791, 11, 420, 519, 466, 1310, 611, 577, 721, 51178], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 7, "seek": 2604, "start": 42.32, "end": 46.120000000000005, "text": " could have played out differently from how they actually did. And how those capacities", "tokens": [51178, 727, 362, 3737, 484, 7614, 490, 577, 436, 767, 630, 13, 400, 577, 729, 39396, 51368], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 8, "seek": 2604, "start": 46.120000000000005, "end": 50.519999999999996, "text": " also allow us to make the kind of judgments we do in our everyday lives, like for example,", "tokens": [51368, 611, 2089, 505, 281, 652, 264, 733, 295, 40337, 321, 360, 294, 527, 7429, 2909, 11, 411, 337, 1365, 11, 51588], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 9, "seek": 2604, "start": 50.519999999999996, "end": 55.6, "text": " assigning responsibility to one another. And that's in fact one of the bigger sort of overarching", "tokens": [51588, 49602, 6357, 281, 472, 1071, 13, 400, 300, 311, 294, 1186, 472, 295, 264, 3801, 1333, 295, 45501, 51842], "temperature": 0.0, "avg_logprob": -0.15588178834715088, "compression_ratio": 1.9305135951661632, "no_speech_prob": 0.0626361072063446}, {"id": 10, "seek": 5560, "start": 55.68, "end": 59.56, "text": " goals that my lab is working toward, namely developing a computational framework for", "tokens": [50368, 5493, 300, 452, 2715, 307, 1364, 7361, 11, 20926, 6416, 257, 28270, 8388, 337, 50562], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 11, "seek": 5560, "start": 59.56, "end": 64.0, "text": " understanding responsibility. And I think to get there, we have to be able to answer at", "tokens": [50562, 3701, 6357, 13, 400, 286, 519, 281, 483, 456, 11, 321, 362, 281, 312, 1075, 281, 1867, 412, 50784], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 12, "seek": 5560, "start": 64.0, "end": 68.04, "text": " least two questions, namely one being what causal role somebody's action played in bringing", "tokens": [50784, 1935, 732, 1651, 11, 20926, 472, 885, 437, 38755, 3090, 2618, 311, 3069, 3737, 294, 5062, 50986], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 13, "seek": 5560, "start": 68.04, "end": 72.36, "text": " about the outcome. And the other one being what the action that the person took tells", "tokens": [50986, 466, 264, 9700, 13, 400, 264, 661, 472, 885, 437, 264, 3069, 300, 264, 954, 1890, 5112, 51202], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 14, "seek": 5560, "start": 72.36, "end": 76.64, "text": " us about the kind of person that they are. For this first one, we need some intuitive", "tokens": [51202, 505, 466, 264, 733, 295, 954, 300, 436, 366, 13, 1171, 341, 700, 472, 11, 321, 643, 512, 21769, 51416], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 15, "seek": 5560, "start": 76.64, "end": 80.6, "text": " theory of how the world works. So we can relate the actions that somebody took to the kind", "tokens": [51416, 5261, 295, 577, 264, 1002, 1985, 13, 407, 321, 393, 10961, 264, 5909, 300, 2618, 1890, 281, 264, 733, 51614], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 16, "seek": 5560, "start": 80.6, "end": 84.68, "text": " of outcomes that resulted from those actions. And for the second question, we need some", "tokens": [51614, 295, 10070, 300, 18753, 490, 729, 5909, 13, 400, 337, 264, 1150, 1168, 11, 321, 643, 512, 51818], "temperature": 0.0, "avg_logprob": -0.11504875211154714, "compression_ratio": 1.9099378881987579, "no_speech_prob": 0.0009100900497287512}, {"id": 17, "seek": 8468, "start": 84.76, "end": 88.48, "text": " intuitive theory of how people work. So we can go backwards from the actions that we've", "tokens": [50368, 21769, 5261, 295, 577, 561, 589, 13, 407, 321, 393, 352, 12204, 490, 264, 5909, 300, 321, 600, 50554], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 18, "seek": 8468, "start": 88.48, "end": 92.08000000000001, "text": " observed to the mental states that may have given rise to those actions. So what were", "tokens": [50554, 13095, 281, 264, 4973, 4368, 300, 815, 362, 2212, 6272, 281, 729, 5909, 13, 407, 437, 645, 50734], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 19, "seek": 8468, "start": 92.08000000000001, "end": 95.36000000000001, "text": " the person's intentions, what did they believe, what were the kinds of things maybe that they", "tokens": [50734, 264, 954, 311, 19354, 11, 437, 630, 436, 1697, 11, 437, 645, 264, 3685, 295, 721, 1310, 300, 436, 50898], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 20, "seek": 8468, "start": 95.36000000000001, "end": 101.2, "text": " were able to do as well. And so I studied psychology, like in my undergrad, and I was", "tokens": [50898, 645, 1075, 281, 360, 382, 731, 13, 400, 370, 286, 9454, 15105, 11, 411, 294, 452, 14295, 11, 293, 286, 390, 51190], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 21, "seek": 8468, "start": 101.2, "end": 104.68, "text": " most excited about social psychology, because I felt sort of most applicable, I guess, to", "tokens": [51190, 881, 2919, 466, 2093, 15105, 11, 570, 286, 2762, 1333, 295, 881, 21142, 11, 286, 2041, 11, 281, 51364], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 22, "seek": 8468, "start": 104.68, "end": 109.24000000000001, "text": " my everyday life, and somehow also got into responsibility, like back then already. Maybe", "tokens": [51364, 452, 7429, 993, 11, 293, 6063, 611, 658, 666, 6357, 11, 411, 646, 550, 1217, 13, 2704, 51592], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 23, "seek": 8468, "start": 109.24000000000001, "end": 112.92000000000002, "text": " it was because I was in some group project where I felt I was doing all the heavy lifting", "tokens": [51592, 309, 390, 570, 286, 390, 294, 512, 1594, 1716, 689, 286, 2762, 286, 390, 884, 439, 264, 4676, 15798, 51776], "temperature": 0.0, "avg_logprob": -0.12309833395070043, "compression_ratio": 1.774928774928775, "no_speech_prob": 0.00036673512659035623}, {"id": 24, "seek": 11292, "start": 113.0, "end": 116.72, "text": " and maybe I wasn't getting all the credit for it. So that was sort of what interested", "tokens": [50368, 293, 1310, 286, 2067, 380, 1242, 439, 264, 5397, 337, 309, 13, 407, 300, 390, 1333, 295, 437, 3102, 50554], "temperature": 0.0, "avg_logprob": -0.1082894178537222, "compression_ratio": 1.7532467532467533, "no_speech_prob": 0.0005741140921600163}, {"id": 25, "seek": 11292, "start": 116.72, "end": 122.16, "text": " me initially. And when I read around in that work in social psychology, a lot of the theories", "tokens": [50554, 385, 9105, 13, 400, 562, 286, 1401, 926, 294, 300, 589, 294, 2093, 15105, 11, 257, 688, 295, 264, 13667, 50826], "temperature": 0.0, "avg_logprob": -0.1082894178537222, "compression_ratio": 1.7532467532467533, "no_speech_prob": 0.0005741140921600163}, {"id": 26, "seek": 11292, "start": 122.16, "end": 127.16, "text": " that I saw took a form sort of like this. So I'll just give you a few examples. So basically", "tokens": [50826, 300, 286, 1866, 1890, 257, 1254, 1333, 295, 411, 341, 13, 407, 286, 603, 445, 976, 291, 257, 1326, 5110, 13, 407, 1936, 51076], "temperature": 0.0, "avg_logprob": -0.1082894178537222, "compression_ratio": 1.7532467532467533, "no_speech_prob": 0.0005741140921600163}, {"id": 27, "seek": 11292, "start": 127.16, "end": 131.68, "text": " sort of like boxes and arrows theories, where they identified important concepts that were", "tokens": [51076, 1333, 295, 411, 9002, 293, 19669, 13667, 11, 689, 436, 9234, 1021, 10392, 300, 645, 51302], "temperature": 0.0, "avg_logprob": -0.1082894178537222, "compression_ratio": 1.7532467532467533, "no_speech_prob": 0.0005741140921600163}, {"id": 28, "seek": 11292, "start": 131.68, "end": 136.04, "text": " related to how we assign responsibility, and maybe also roughly how they were related to", "tokens": [51302, 4077, 281, 577, 321, 6269, 6357, 11, 293, 1310, 611, 9810, 577, 436, 645, 4077, 281, 51520], "temperature": 0.0, "avg_logprob": -0.1082894178537222, "compression_ratio": 1.7532467532467533, "no_speech_prob": 0.0005741140921600163}, {"id": 29, "seek": 11292, "start": 136.04, "end": 142.6, "text": " one another, but still left a lot in a certain way unspecified. So this is a quote from", "tokens": [51520, 472, 1071, 11, 457, 920, 1411, 257, 688, 294, 257, 1629, 636, 2693, 494, 66, 2587, 13, 407, 341, 307, 257, 6513, 490, 51848], "temperature": 0.0, "avg_logprob": -0.1082894178537222, "compression_ratio": 1.7532467532467533, "no_speech_prob": 0.0005741140921600163}, {"id": 30, "seek": 14260, "start": 142.96, "end": 146.68, "text": " Bertrand Molle from a while ago. He says, like, an important limitation of many of these", "tokens": [50382, 29594, 3699, 376, 1833, 68, 490, 257, 1339, 2057, 13, 634, 1619, 11, 411, 11, 364, 1021, 27432, 295, 867, 295, 613, 50568], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 31, "seek": 14260, "start": 146.68, "end": 151.2, "text": " models of moral judgment or assigning responsibility is they don't really generate any quantitative", "tokens": [50568, 5245, 295, 9723, 12216, 420, 49602, 6357, 307, 436, 500, 380, 534, 8460, 604, 27778, 50794], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 32, "seek": 14260, "start": 151.2, "end": 155.35999999999999, "text": " predictions. And you might say, like, oh, what do you need quantitative predictions for? Well,", "tokens": [50794, 21264, 13, 400, 291, 1062, 584, 11, 411, 11, 1954, 11, 437, 360, 291, 643, 27778, 21264, 337, 30, 1042, 11, 51002], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 33, "seek": 14260, "start": 155.35999999999999, "end": 159.48, "text": " one thing that they're useful for is sort of, you know, laying your cards out and making", "tokens": [51002, 472, 551, 300, 436, 434, 4420, 337, 307, 1333, 295, 11, 291, 458, 11, 14903, 428, 5632, 484, 293, 1455, 51208], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 34, "seek": 14260, "start": 159.48, "end": 164.28, "text": " it concrete, what your model does also allows it then to be falsified more easily. And I", "tokens": [51208, 309, 9859, 11, 437, 428, 2316, 775, 611, 4045, 309, 550, 281, 312, 16720, 2587, 544, 3612, 13, 400, 286, 51448], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 35, "seek": 14260, "start": 164.28, "end": 168.44, "text": " remember this one instance, it was like me, I think maybe first day of my PhD, I went to", "tokens": [51448, 1604, 341, 472, 5197, 11, 309, 390, 411, 385, 11, 286, 519, 1310, 700, 786, 295, 452, 14476, 11, 286, 1437, 281, 51656], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 36, "seek": 14260, "start": 168.44, "end": 172.2, "text": " this conference and had dinner, you know, with one of the, one of the people who had made", "tokens": [51656, 341, 7586, 293, 632, 6148, 11, 291, 458, 11, 365, 472, 295, 264, 11, 472, 295, 264, 561, 567, 632, 1027, 51844], "temperature": 0.0, "avg_logprob": -0.18277931213378906, "compression_ratio": 1.7534246575342465, "no_speech_prob": 0.0003396680986043066}, {"id": 37, "seek": 17220, "start": 172.2, "end": 176.72, "text": " one of these sort of boxes and arrows and diagrams. And I told them about some experiment", "tokens": [50364, 472, 295, 613, 1333, 295, 9002, 293, 19669, 293, 36709, 13, 400, 286, 1907, 552, 466, 512, 5120, 50590], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 38, "seek": 17220, "start": 176.72, "end": 181.32, "text": " that I thought, that I thought of and thought, like, oh, this would happen. And I think that", "tokens": [50590, 300, 286, 1194, 11, 300, 286, 1194, 295, 293, 1194, 11, 411, 11, 1954, 11, 341, 576, 1051, 13, 400, 286, 519, 300, 50820], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 39, "seek": 17220, "start": 181.32, "end": 185.83999999999997, "text": " would be the result of that experiment. And, and I was very, very smart. I thought, like,", "tokens": [50820, 576, 312, 264, 1874, 295, 300, 5120, 13, 400, 11, 293, 286, 390, 588, 11, 588, 4069, 13, 286, 1194, 11, 411, 11, 51046], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 40, "seek": 17220, "start": 185.83999999999997, "end": 189.2, "text": " oh, this would totally kind of disprove your theory, right? And he said, no, no, that would", "tokens": [51046, 1954, 11, 341, 576, 3879, 733, 295, 717, 46955, 428, 5261, 11, 558, 30, 400, 415, 848, 11, 572, 11, 572, 11, 300, 576, 51214], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 41, "seek": 17220, "start": 189.2, "end": 193.6, "text": " be totally consistent with my theory. And I thought, oh, that's weird. I maybe I really", "tokens": [51214, 312, 3879, 8398, 365, 452, 5261, 13, 400, 286, 1194, 11, 1954, 11, 300, 311, 3657, 13, 286, 1310, 286, 534, 51434], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 42, "seek": 17220, "start": 193.6, "end": 198.23999999999998, "text": " tried to understand the theory very well. And, and so, so that also was a sort of little", "tokens": [51434, 3031, 281, 1223, 264, 5261, 588, 731, 13, 400, 11, 293, 370, 11, 370, 300, 611, 390, 257, 1333, 295, 707, 51666], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 43, "seek": 17220, "start": 198.23999999999998, "end": 202.07999999999998, "text": " bit of a moment for me that I felt like, okay, maybe it's important to try to make these", "tokens": [51666, 857, 295, 257, 1623, 337, 385, 300, 286, 2762, 411, 11, 1392, 11, 1310, 309, 311, 1021, 281, 853, 281, 652, 613, 51858], "temperature": 0.0, "avg_logprob": -0.1510587079184396, "compression_ratio": 2.019230769230769, "no_speech_prob": 0.00025666074361652136}, {"id": 44, "seek": 20208, "start": 202.12, "end": 205.4, "text": " theories even more precise. So we know what it is that they're predicting, so we can go", "tokens": [50366, 13667, 754, 544, 13600, 13, 407, 321, 458, 437, 309, 307, 300, 436, 434, 32884, 11, 370, 321, 393, 352, 50530], "temperature": 0.0, "avg_logprob": -0.11617115565708705, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0017455066554248333}, {"id": 45, "seek": 20208, "start": 205.4, "end": 209.64000000000001, "text": " about and, you know, falsify them and sort of improve them. And so that's been very much", "tokens": [50530, 466, 293, 11, 291, 458, 11, 16720, 2505, 552, 293, 1333, 295, 3470, 552, 13, 400, 370, 300, 311, 668, 588, 709, 50742], "temperature": 0.0, "avg_logprob": -0.11617115565708705, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0017455066554248333}, {"id": 46, "seek": 20208, "start": 209.64000000000001, "end": 214.56, "text": " kind of an inspiration for me, what I've been trying to do it a little bit. And so one of", "tokens": [50742, 733, 295, 364, 10249, 337, 385, 11, 437, 286, 600, 668, 1382, 281, 360, 309, 257, 707, 857, 13, 400, 370, 472, 295, 50988], "temperature": 0.0, "avg_logprob": -0.11617115565708705, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0017455066554248333}, {"id": 47, "seek": 20208, "start": 214.56, "end": 219.84, "text": " the starting points in almost all of these theories of responsibility is there's causality,", "tokens": [50988, 264, 2891, 2793, 294, 1920, 439, 295, 613, 13667, 295, 6357, 307, 456, 311, 3302, 1860, 11, 51252], "temperature": 0.0, "avg_logprob": -0.11617115565708705, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0017455066554248333}, {"id": 48, "seek": 20208, "start": 219.84, "end": 223.60000000000002, "text": " always causality comes first. So I thought, okay, let me try, let me try that one. So", "tokens": [51252, 1009, 3302, 1860, 1487, 700, 13, 407, 286, 1194, 11, 1392, 11, 718, 385, 853, 11, 718, 385, 853, 300, 472, 13, 407, 51440], "temperature": 0.0, "avg_logprob": -0.11617115565708705, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0017455066554248333}, {"id": 49, "seek": 20208, "start": 223.60000000000002, "end": 229.20000000000002, "text": " can we get more specific about what it means, you know, what people, what it takes for people", "tokens": [51440, 393, 321, 483, 544, 2685, 466, 437, 309, 1355, 11, 291, 458, 11, 437, 561, 11, 437, 309, 2516, 337, 561, 51720], "temperature": 0.0, "avg_logprob": -0.11617115565708705, "compression_ratio": 1.8114478114478114, "no_speech_prob": 0.0017455066554248333}, {"id": 50, "seek": 22920, "start": 229.23999999999998, "end": 235.32, "text": " to say that one thing caused another thing to happen. And so I think that three key ingredients", "tokens": [50366, 281, 584, 300, 472, 551, 7008, 1071, 551, 281, 1051, 13, 400, 370, 286, 519, 300, 1045, 2141, 6952, 50670], "temperature": 0.0, "avg_logprob": -0.12448568497934649, "compression_ratio": 1.935251798561151, "no_speech_prob": 0.0002648101362865418}, {"id": 51, "seek": 22920, "start": 235.32, "end": 239.48, "text": " that we need, like in order to get a theory for how people think that one thing caused", "tokens": [50670, 300, 321, 643, 11, 411, 294, 1668, 281, 483, 257, 5261, 337, 577, 561, 519, 300, 472, 551, 7008, 50878], "temperature": 0.0, "avg_logprob": -0.12448568497934649, "compression_ratio": 1.935251798561151, "no_speech_prob": 0.0002648101362865418}, {"id": 52, "seek": 22920, "start": 239.48, "end": 244.72, "text": " another thing to happen. And those are starting with a mental model that people have of a", "tokens": [50878, 1071, 551, 281, 1051, 13, 400, 729, 366, 2891, 365, 257, 4973, 2316, 300, 561, 362, 295, 257, 51140], "temperature": 0.0, "avg_logprob": -0.12448568497934649, "compression_ratio": 1.935251798561151, "no_speech_prob": 0.0002648101362865418}, {"id": 53, "seek": 22920, "start": 244.72, "end": 249.79999999999998, "text": " particular domain, a mental model that allows us to conceive of counterfactual interventions.", "tokens": [51140, 1729, 9274, 11, 257, 4973, 2316, 300, 4045, 505, 281, 48605, 295, 5682, 44919, 901, 20924, 13, 51394], "temperature": 0.0, "avg_logprob": -0.12448568497934649, "compression_ratio": 1.935251798561151, "no_speech_prob": 0.0002648101362865418}, {"id": 54, "seek": 22920, "start": 249.83999999999997, "end": 253.48, "text": " So, and I'll flush it out a little bit more in a moment. So imagining how things could", "tokens": [51396, 407, 11, 293, 286, 603, 19568, 309, 484, 257, 707, 857, 544, 294, 257, 1623, 13, 407, 27798, 577, 721, 727, 51578], "temperature": 0.0, "avg_logprob": -0.12448568497934649, "compression_ratio": 1.935251798561151, "no_speech_prob": 0.0002648101362865418}, {"id": 55, "seek": 22920, "start": 253.48, "end": 257.56, "text": " have been different from how they actually were. And that allows us then to mentally", "tokens": [51578, 362, 668, 819, 490, 577, 436, 767, 645, 13, 400, 300, 4045, 505, 550, 281, 17072, 51782], "temperature": 0.0, "avg_logprob": -0.12448568497934649, "compression_ratio": 1.935251798561151, "no_speech_prob": 0.0002648101362865418}, {"id": 56, "seek": 25756, "start": 257.56, "end": 263.56, "text": " simulate what the consequences of this counterfactual intervention would have been. And so the idea", "tokens": [50364, 27817, 437, 264, 10098, 295, 341, 5682, 44919, 901, 13176, 576, 362, 668, 13, 400, 370, 264, 1558, 50664], "temperature": 0.0, "avg_logprob": -0.16896435751843808, "compression_ratio": 1.6987577639751552, "no_speech_prob": 0.000508830591570586}, {"id": 57, "seek": 25756, "start": 263.56, "end": 267.52, "text": " of mental models has been around, you know, for quite some time and has recently gotten", "tokens": [50664, 295, 4973, 5245, 575, 668, 926, 11, 291, 458, 11, 337, 1596, 512, 565, 293, 575, 3938, 5768, 50862], "temperature": 0.0, "avg_logprob": -0.16896435751843808, "compression_ratio": 1.6987577639751552, "no_speech_prob": 0.000508830591570586}, {"id": 58, "seek": 25756, "start": 267.52, "end": 272.56, "text": " a little bit more attention again, also in AI. And, but, but yeah, some of the credit", "tokens": [50862, 257, 707, 857, 544, 3202, 797, 11, 611, 294, 7318, 13, 400, 11, 457, 11, 457, 1338, 11, 512, 295, 264, 5397, 51114], "temperature": 0.0, "avg_logprob": -0.16896435751843808, "compression_ratio": 1.6987577639751552, "no_speech_prob": 0.000508830591570586}, {"id": 59, "seek": 25756, "start": 272.56, "end": 277.04, "text": " at least in modern times that go to the philosopher Kenneth Craig and his book, The Nature of", "tokens": [51114, 412, 1935, 294, 4363, 1413, 300, 352, 281, 264, 29805, 33735, 19732, 293, 702, 1446, 11, 440, 20159, 295, 51338], "temperature": 0.0, "avg_logprob": -0.16896435751843808, "compression_ratio": 1.6987577639751552, "no_speech_prob": 0.000508830591570586}, {"id": 60, "seek": 25756, "start": 277.04, "end": 280.6, "text": " Explanation, who said something along the lines, well, he said exactly that, but I'm", "tokens": [51338, 12514, 282, 399, 11, 567, 848, 746, 2051, 264, 3876, 11, 731, 11, 415, 848, 2293, 300, 11, 457, 286, 478, 51516], "temperature": 0.0, "avg_logprob": -0.16896435751843808, "compression_ratio": 1.6987577639751552, "no_speech_prob": 0.000508830591570586}, {"id": 61, "seek": 25756, "start": 280.6, "end": 284.76, "text": " going to say along the lines, so that we have something like a small scale model. Oh, wouldn't", "tokens": [51516, 516, 281, 584, 2051, 264, 3876, 11, 370, 300, 321, 362, 746, 411, 257, 1359, 4373, 2316, 13, 876, 11, 2759, 380, 51724], "temperature": 0.0, "avg_logprob": -0.16896435751843808, "compression_ratio": 1.6987577639751552, "no_speech_prob": 0.000508830591570586}, {"id": 62, "seek": 28476, "start": 284.76, "end": 289.52, "text": " it be very helpful if we had something like a small scale model of the world in our minds", "tokens": [50364, 309, 312, 588, 4961, 498, 321, 632, 746, 411, 257, 1359, 4373, 2316, 295, 264, 1002, 294, 527, 9634, 50602], "temperature": 0.0, "avg_logprob": -0.12718104576879694, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0010430398397147655}, {"id": 63, "seek": 28476, "start": 289.52, "end": 292.92, "text": " that we can then use for all sorts of things, like predicting what was going to happen if", "tokens": [50602, 300, 321, 393, 550, 764, 337, 439, 7527, 295, 721, 11, 411, 32884, 437, 390, 516, 281, 1051, 498, 50772], "temperature": 0.0, "avg_logprob": -0.12718104576879694, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0010430398397147655}, {"id": 64, "seek": 28476, "start": 292.92, "end": 297.15999999999997, "text": " I did this, rather than actually having to carry out the action and then, you know, dying", "tokens": [50772, 286, 630, 341, 11, 2831, 813, 767, 1419, 281, 3985, 484, 264, 3069, 293, 550, 11, 291, 458, 11, 8639, 50984], "temperature": 0.0, "avg_logprob": -0.12718104576879694, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0010430398397147655}, {"id": 65, "seek": 28476, "start": 297.15999999999997, "end": 302.4, "text": " maybe if it was a bad one. And, and yeah, that that would be really helpful for decision", "tokens": [50984, 1310, 498, 309, 390, 257, 1578, 472, 13, 400, 11, 293, 1338, 11, 300, 300, 576, 312, 534, 4961, 337, 3537, 51246], "temperature": 0.0, "avg_logprob": -0.12718104576879694, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0010430398397147655}, {"id": 66, "seek": 28476, "start": 302.4, "end": 306.2, "text": " making. And as I will say in a moment also really helpful for explaining kind of why", "tokens": [51246, 1455, 13, 400, 382, 286, 486, 584, 294, 257, 1623, 611, 534, 4961, 337, 13468, 733, 295, 983, 51436], "temperature": 0.0, "avg_logprob": -0.12718104576879694, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0010430398397147655}, {"id": 67, "seek": 28476, "start": 306.2, "end": 311.4, "text": " something happened. So this idea of mental models has been around for a very long time.", "tokens": [51436, 746, 2011, 13, 407, 341, 1558, 295, 4973, 5245, 575, 668, 926, 337, 257, 588, 938, 565, 13, 51696], "temperature": 0.0, "avg_logprob": -0.12718104576879694, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0010430398397147655}, {"id": 68, "seek": 31140, "start": 311.4, "end": 315.15999999999997, "text": " And then in somewhat more recent years, at least in cognitive science, has been made", "tokens": [50364, 400, 550, 294, 8344, 544, 5162, 924, 11, 412, 1935, 294, 15605, 3497, 11, 575, 668, 1027, 50552], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 69, "seek": 31140, "start": 315.15999999999997, "end": 318.64, "text": " a little bit more concrete, particularly as it pertains to our mental model of the physical", "tokens": [50552, 257, 707, 857, 544, 9859, 11, 4098, 382, 309, 13269, 2315, 281, 527, 4973, 2316, 295, 264, 4001, 50726], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 70, "seek": 31140, "start": 318.64, "end": 323.4, "text": " world. And so the idea is was here to say like, well, maybe our mental model of the", "tokens": [50726, 1002, 13, 400, 370, 264, 1558, 307, 390, 510, 281, 584, 411, 11, 731, 11, 1310, 527, 4973, 2316, 295, 264, 50964], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 71, "seek": 31140, "start": 323.4, "end": 328.35999999999996, "text": " physical world is in certain respects, similar to the kinds of physics engines that we use", "tokens": [50964, 4001, 1002, 307, 294, 1629, 24126, 11, 2531, 281, 264, 3685, 295, 10649, 12982, 300, 321, 764, 51212], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 72, "seek": 31140, "start": 328.35999999999996, "end": 332.64, "text": " to make realistic computer games. That's a common move, right? You have some, some tool", "tokens": [51212, 281, 652, 12465, 3820, 2813, 13, 663, 311, 257, 2689, 1286, 11, 558, 30, 509, 362, 512, 11, 512, 2290, 51426], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 73, "seek": 31140, "start": 332.64, "end": 336.03999999999996, "text": " and then you think like, okay, maybe the mind is a little bit like that tool. So this was", "tokens": [51426, 293, 550, 291, 519, 411, 11, 1392, 11, 1310, 264, 1575, 307, 257, 707, 857, 411, 300, 2290, 13, 407, 341, 390, 51596], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 74, "seek": 31140, "start": 336.03999999999996, "end": 339.76, "text": " just, you know, psychologists playing Angry Birds and then thinking like, okay, maybe", "tokens": [51596, 445, 11, 291, 458, 11, 41562, 2433, 49860, 41456, 293, 550, 1953, 411, 11, 1392, 11, 1310, 51782], "temperature": 0.0, "avg_logprob": -0.14048687187401024, "compression_ratio": 1.824925816023739, "no_speech_prob": 0.002661254024133086}, {"id": 75, "seek": 33976, "start": 339.8, "end": 346.56, "text": " the mind is a little bit like Angry Birds. So here, the basic idea, right, is that we", "tokens": [50366, 264, 1575, 307, 257, 707, 857, 411, 49860, 41456, 13, 407, 510, 11, 264, 3875, 1558, 11, 558, 11, 307, 300, 321, 50704], "temperature": 0.0, "avg_logprob": -0.15172042543925937, "compression_ratio": 1.96309963099631, "no_speech_prob": 0.0007283989107236266}, {"id": 76, "seek": 33976, "start": 346.56, "end": 350.36, "text": " take in the world, you know, through our perceptual senses, and that we then build this internal", "tokens": [50704, 747, 294, 264, 1002, 11, 291, 458, 11, 807, 527, 43276, 901, 17057, 11, 293, 300, 321, 550, 1322, 341, 6920, 50894], "temperature": 0.0, "avg_logprob": -0.15172042543925937, "compression_ratio": 1.96309963099631, "no_speech_prob": 0.0007283989107236266}, {"id": 77, "seek": 33976, "start": 350.36, "end": 354.32, "text": " representation of the world. That's now the physics engine kind of representation. So", "tokens": [50894, 10290, 295, 264, 1002, 13, 663, 311, 586, 264, 10649, 2848, 733, 295, 10290, 13, 407, 51092], "temperature": 0.0, "avg_logprob": -0.15172042543925937, "compression_ratio": 1.96309963099631, "no_speech_prob": 0.0007283989107236266}, {"id": 78, "seek": 33976, "start": 354.32, "end": 358.28, "text": " that we pass the world, for example, into objects and the properties of those objects", "tokens": [51092, 300, 321, 1320, 264, 1002, 11, 337, 1365, 11, 666, 6565, 293, 264, 7221, 295, 729, 6565, 51290], "temperature": 0.0, "avg_logprob": -0.15172042543925937, "compression_ratio": 1.96309963099631, "no_speech_prob": 0.0007283989107236266}, {"id": 79, "seek": 33976, "start": 358.28, "end": 362.88, "text": " and then the interactions between those objects. So here, this child maybe passes the world", "tokens": [51290, 293, 550, 264, 13280, 1296, 729, 6565, 13, 407, 510, 11, 341, 1440, 1310, 11335, 264, 1002, 51520], "temperature": 0.0, "avg_logprob": -0.15172042543925937, "compression_ratio": 1.96309963099631, "no_speech_prob": 0.0007283989107236266}, {"id": 80, "seek": 33976, "start": 362.88, "end": 366.71999999999997, "text": " into the ball and then the eagle on top of the tower and then the tower or the blocks", "tokens": [51520, 666, 264, 2594, 293, 550, 264, 30745, 322, 1192, 295, 264, 10567, 293, 550, 264, 10567, 420, 264, 8474, 51712], "temperature": 0.0, "avg_logprob": -0.15172042543925937, "compression_ratio": 1.96309963099631, "no_speech_prob": 0.0007283989107236266}, {"id": 81, "seek": 36672, "start": 366.76000000000005, "end": 371.84000000000003, "text": " that make up the tower. And now that you have this internal representation of the world,", "tokens": [50366, 300, 652, 493, 264, 10567, 13, 400, 586, 300, 291, 362, 341, 6920, 10290, 295, 264, 1002, 11, 50620], "temperature": 0.0, "avg_logprob": -0.10458568512924074, "compression_ratio": 1.8013468013468013, "no_speech_prob": 0.00035114376805722713}, {"id": 82, "seek": 36672, "start": 371.84000000000003, "end": 375.64000000000004, "text": " you can use it, for example, for planning. So if this child, for example, wants to topple", "tokens": [50620, 291, 393, 764, 309, 11, 337, 1365, 11, 337, 5038, 13, 407, 498, 341, 1440, 11, 337, 1365, 11, 2738, 281, 48433, 306, 50810], "temperature": 0.0, "avg_logprob": -0.10458568512924074, "compression_ratio": 1.8013468013468013, "no_speech_prob": 0.00035114376805722713}, {"id": 83, "seek": 36672, "start": 375.64000000000004, "end": 380.04, "text": " over that tower, they can think about what's going to happen if they roll the ball like", "tokens": [50810, 670, 300, 10567, 11, 436, 393, 519, 466, 437, 311, 516, 281, 1051, 498, 436, 3373, 264, 2594, 411, 51030], "temperature": 0.0, "avg_logprob": -0.10458568512924074, "compression_ratio": 1.8013468013468013, "no_speech_prob": 0.00035114376805722713}, {"id": 84, "seek": 36672, "start": 380.04, "end": 386.0, "text": " in different kinds of ways. So I can run simulations using this internal engine in my mind. So", "tokens": [51030, 294, 819, 3685, 295, 2098, 13, 407, 286, 393, 1190, 35138, 1228, 341, 6920, 2848, 294, 452, 1575, 13, 407, 51328], "temperature": 0.0, "avg_logprob": -0.10458568512924074, "compression_ratio": 1.8013468013468013, "no_speech_prob": 0.00035114376805722713}, {"id": 85, "seek": 36672, "start": 386.0, "end": 389.24, "text": " having this would be very useful because I could make predictions about the future. I", "tokens": [51328, 1419, 341, 576, 312, 588, 4420, 570, 286, 727, 652, 21264, 466, 264, 2027, 13, 286, 51490], "temperature": 0.0, "avg_logprob": -0.10458568512924074, "compression_ratio": 1.8013468013468013, "no_speech_prob": 0.00035114376805722713}, {"id": 86, "seek": 36672, "start": 389.24, "end": 392.96000000000004, "text": " could pay sort of Sherlock and infer from the current state of the world what must have", "tokens": [51490, 727, 1689, 1333, 295, 37769, 293, 13596, 490, 264, 2190, 1785, 295, 264, 1002, 437, 1633, 362, 51676], "temperature": 0.0, "avg_logprob": -0.10458568512924074, "compression_ratio": 1.8013468013468013, "no_speech_prob": 0.00035114376805722713}, {"id": 87, "seek": 39296, "start": 392.96, "end": 398.12, "text": " happened in the past. And as I'll show in a moment, this would also be useful for explaining", "tokens": [50364, 2011, 294, 264, 1791, 13, 400, 382, 286, 603, 855, 294, 257, 1623, 11, 341, 576, 611, 312, 4420, 337, 13468, 50622], "temperature": 0.0, "avg_logprob": -0.14996859135518548, "compression_ratio": 1.7331189710610932, "no_speech_prob": 0.000635405769571662}, {"id": 88, "seek": 39296, "start": 398.12, "end": 403.96, "text": " something that happened in the present. Okay, so what I'll do is in this in the remaining", "tokens": [50622, 746, 300, 2011, 294, 264, 1974, 13, 1033, 11, 370, 437, 286, 603, 360, 307, 294, 341, 294, 264, 8877, 50914], "temperature": 0.0, "avg_logprob": -0.14996859135518548, "compression_ratio": 1.7331189710610932, "no_speech_prob": 0.000635405769571662}, {"id": 89, "seek": 39296, "start": 403.96, "end": 409.2, "text": " time, right? I'll basically want to cover these two different aspects of working towards", "tokens": [50914, 565, 11, 558, 30, 286, 603, 1936, 528, 281, 2060, 613, 732, 819, 7270, 295, 1364, 3030, 51176], "temperature": 0.0, "avg_logprob": -0.14996859135518548, "compression_ratio": 1.7331189710610932, "no_speech_prob": 0.000635405769571662}, {"id": 90, "seek": 39296, "start": 409.2, "end": 413.32, "text": " this computational framework. So in part one, I'm going to focus on the physical domain.", "tokens": [51176, 341, 28270, 8388, 13, 407, 294, 644, 472, 11, 286, 478, 516, 281, 1879, 322, 264, 4001, 9274, 13, 51382], "temperature": 0.0, "avg_logprob": -0.14996859135518548, "compression_ratio": 1.7331189710610932, "no_speech_prob": 0.000635405769571662}, {"id": 91, "seek": 39296, "start": 413.32, "end": 418.12, "text": " And then in part two, I'm going to expand it to just start to think about people. I should", "tokens": [51382, 400, 550, 294, 644, 732, 11, 286, 478, 516, 281, 5268, 309, 281, 445, 722, 281, 519, 466, 561, 13, 286, 820, 51622], "temperature": 0.0, "avg_logprob": -0.14996859135518548, "compression_ratio": 1.7331189710610932, "no_speech_prob": 0.000635405769571662}, {"id": 92, "seek": 39296, "start": 418.12, "end": 422.35999999999996, "text": " say, obviously, feel free to ask questions like anytime throughout. Otherwise, I'll try", "tokens": [51622, 584, 11, 2745, 11, 841, 1737, 281, 1029, 1651, 411, 13038, 3710, 13, 10328, 11, 286, 603, 853, 51834], "temperature": 0.0, "avg_logprob": -0.14996859135518548, "compression_ratio": 1.7331189710610932, "no_speech_prob": 0.000635405769571662}, {"id": 93, "seek": 42236, "start": 422.56, "end": 428.76, "text": " and end around 12.20 so that we have a little bit of time also for Q&A at the end. Feel", "tokens": [50374, 293, 917, 926, 2272, 13, 2009, 370, 300, 321, 362, 257, 707, 857, 295, 565, 611, 337, 1249, 5, 32, 412, 264, 917, 13, 14113, 50684], "temperature": 0.0, "avg_logprob": -0.15669063930093807, "compression_ratio": 1.6512345679012346, "no_speech_prob": 0.004182389471679926}, {"id": 94, "seek": 42236, "start": 428.76, "end": 433.08000000000004, "text": " free to ask and throughout if anything's unclear. Okay, so let's start with this part", "tokens": [50684, 1737, 281, 1029, 293, 3710, 498, 1340, 311, 25636, 13, 1033, 11, 370, 718, 311, 722, 365, 341, 644, 50900], "temperature": 0.0, "avg_logprob": -0.15669063930093807, "compression_ratio": 1.6512345679012346, "no_speech_prob": 0.004182389471679926}, {"id": 95, "seek": 42236, "start": 433.08000000000004, "end": 437.16, "text": " one. And I should also warn you, there is a little bit of audience participation required.", "tokens": [50900, 472, 13, 400, 286, 820, 611, 12286, 291, 11, 456, 307, 257, 707, 857, 295, 4034, 13487, 4739, 13, 51104], "temperature": 0.0, "avg_logprob": -0.15669063930093807, "compression_ratio": 1.6512345679012346, "no_speech_prob": 0.004182389471679926}, {"id": 96, "seek": 42236, "start": 437.16, "end": 441.96000000000004, "text": " So get ready for that. So the first, we started really simple, right? I was saying, okay,", "tokens": [51104, 407, 483, 1919, 337, 300, 13, 407, 264, 700, 11, 321, 1409, 534, 2199, 11, 558, 30, 286, 390, 1566, 11, 1392, 11, 51344], "temperature": 0.0, "avg_logprob": -0.15669063930093807, "compression_ratio": 1.6512345679012346, "no_speech_prob": 0.004182389471679926}, {"id": 97, "seek": 42236, "start": 441.96000000000004, "end": 445.44, "text": " I want to understand causality a little bit better. What's the simplest possible setting", "tokens": [51344, 286, 528, 281, 1223, 3302, 1860, 257, 707, 857, 1101, 13, 708, 311, 264, 22811, 1944, 3287, 51518], "temperature": 0.0, "avg_logprob": -0.15669063930093807, "compression_ratio": 1.6512345679012346, "no_speech_prob": 0.004182389471679926}, {"id": 98, "seek": 42236, "start": 445.44, "end": 449.56, "text": " maybe in which you could think about causality? Well, it's two billion balls colliding with", "tokens": [51518, 1310, 294, 597, 291, 727, 519, 466, 3302, 1860, 30, 1042, 11, 309, 311, 732, 5218, 9803, 1263, 2819, 365, 51724], "temperature": 0.0, "avg_logprob": -0.15669063930093807, "compression_ratio": 1.6512345679012346, "no_speech_prob": 0.004182389471679926}, {"id": 99, "seek": 44956, "start": 449.56, "end": 454.16, "text": " one another. And here's the first audience participation part. So there's going to be", "tokens": [50364, 472, 1071, 13, 400, 510, 311, 264, 700, 4034, 13487, 644, 13, 407, 456, 311, 516, 281, 312, 50594], "temperature": 0.0, "avg_logprob": -0.12172257489171522, "compression_ratio": 1.768, "no_speech_prob": 0.0008290082914754748}, {"id": 100, "seek": 44956, "start": 454.16, "end": 457.72, "text": " these two balls coming in on the right side of the screen. And I'm going to ask you whether", "tokens": [50594, 613, 732, 9803, 1348, 294, 322, 264, 558, 1252, 295, 264, 2568, 13, 400, 286, 478, 516, 281, 1029, 291, 1968, 50772], "temperature": 0.0, "avg_logprob": -0.12172257489171522, "compression_ratio": 1.768, "no_speech_prob": 0.0008290082914754748}, {"id": 101, "seek": 44956, "start": 457.72, "end": 461.64, "text": " you think that ball A caused ball B to go through the gate. And if you think so, maybe", "tokens": [50772, 291, 519, 300, 2594, 316, 7008, 2594, 363, 281, 352, 807, 264, 8539, 13, 400, 498, 291, 519, 370, 11, 1310, 50968], "temperature": 0.0, "avg_logprob": -0.12172257489171522, "compression_ratio": 1.768, "no_speech_prob": 0.0008290082914754748}, {"id": 102, "seek": 44956, "start": 461.64, "end": 466.64, "text": " just raise your arm like at the end of the video clip. So here's what's happening. Okay,", "tokens": [50968, 445, 5300, 428, 3726, 411, 412, 264, 917, 295, 264, 960, 7353, 13, 407, 510, 311, 437, 311, 2737, 13, 1033, 11, 51218], "temperature": 0.0, "avg_logprob": -0.12172257489171522, "compression_ratio": 1.768, "no_speech_prob": 0.0008290082914754748}, {"id": 103, "seek": 44956, "start": 466.64, "end": 473.64, "text": " so who thinks that A caused B to go through the gate in this case? Okay, a lot of people", "tokens": [51218, 370, 567, 7309, 300, 316, 7008, 363, 281, 352, 807, 264, 8539, 294, 341, 1389, 30, 1033, 11, 257, 688, 295, 561, 51568], "temperature": 0.0, "avg_logprob": -0.12172257489171522, "compression_ratio": 1.768, "no_speech_prob": 0.0008290082914754748}, {"id": 104, "seek": 47364, "start": 474.32, "end": 480.32, "text": " do anyone think that it didn't? No one dares? Okay, cool. So you're in line with what most", "tokens": [50398, 360, 2878, 519, 300, 309, 994, 380, 30, 883, 472, 50213, 30, 1033, 11, 1627, 13, 407, 291, 434, 294, 1622, 365, 437, 881, 50698], "temperature": 0.0, "avg_logprob": -0.2632515033086141, "compression_ratio": 1.5863636363636364, "no_speech_prob": 0.0004644588625524193}, {"id": 105, "seek": 47364, "start": 480.32, "end": 486.32, "text": " people say in this case. And here's what I think was going on in your minds. Not the", "tokens": [50698, 561, 584, 294, 341, 1389, 13, 400, 510, 311, 437, 286, 519, 390, 516, 322, 294, 428, 9634, 13, 1726, 264, 50998], "temperature": 0.0, "avg_logprob": -0.2632515033086141, "compression_ratio": 1.5863636363636364, "no_speech_prob": 0.0004644588625524193}, {"id": 106, "seek": 47364, "start": 493.76, "end": 498.76, "text": " motor part of raising your hand, but the kind of judgment, the part of, yeah, was there", "tokens": [51370, 5932, 644, 295, 11225, 428, 1011, 11, 457, 264, 733, 295, 12216, 11, 264, 644, 295, 11, 1338, 11, 390, 456, 51620], "temperature": 0.0, "avg_logprob": -0.2632515033086141, "compression_ratio": 1.5863636363636364, "no_speech_prob": 0.0004644588625524193}, {"id": 107, "seek": 47364, "start": 498.76, "end": 502.47999999999996, "text": " causation happening in this case? And the first part is very kind of uncontroversial.", "tokens": [51620, 3302, 399, 2737, 294, 341, 1389, 30, 400, 264, 700, 644, 307, 588, 733, 295, 36019, 340, 840, 831, 13, 51806], "temperature": 0.0, "avg_logprob": -0.2632515033086141, "compression_ratio": 1.5863636363636364, "no_speech_prob": 0.0004644588625524193}, {"id": 108, "seek": 50248, "start": 502.48, "end": 505.72, "text": " So you looked at what actually happened. You saw that they collided with one another", "tokens": [50364, 407, 291, 2956, 412, 437, 767, 2011, 13, 509, 1866, 300, 436, 1263, 2112, 365, 472, 1071, 50526], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 109, "seek": 50248, "start": 505.72, "end": 509.44, "text": " and then ball B ended up going through the gate. And now the somewhat more controversial", "tokens": [50526, 293, 550, 2594, 363, 4590, 493, 516, 807, 264, 8539, 13, 400, 586, 264, 8344, 544, 17323, 50712], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 110, "seek": 50248, "start": 509.44, "end": 514.32, "text": " part is to say that, well, that's in itself is not sufficient. That does not contain all", "tokens": [50712, 644, 307, 281, 584, 300, 11, 731, 11, 300, 311, 294, 2564, 307, 406, 11563, 13, 663, 775, 406, 5304, 439, 50956], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 111, "seek": 50248, "start": 514.32, "end": 517.5600000000001, "text": " the information you need in order to say that A caused ball B to go through the gate in", "tokens": [50956, 264, 1589, 291, 643, 294, 1668, 281, 584, 300, 316, 7008, 2594, 363, 281, 352, 807, 264, 8539, 294, 51118], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 112, "seek": 50248, "start": 517.5600000000001, "end": 522.36, "text": " this case. But you also need something like this. You need the capacity to simulate in", "tokens": [51118, 341, 1389, 13, 583, 291, 611, 643, 746, 411, 341, 13, 509, 643, 264, 6042, 281, 27817, 294, 51358], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 113, "seek": 50248, "start": 522.36, "end": 527.64, "text": " your mind, in this case, that removing basically ball A from the scene, kind of in your mind.", "tokens": [51358, 428, 1575, 11, 294, 341, 1389, 11, 300, 12720, 1936, 2594, 316, 490, 264, 4145, 11, 733, 295, 294, 428, 1575, 13, 51622], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 114, "seek": 50248, "start": 527.64, "end": 530.88, "text": " And then simulating where ball B would have gone if ball A hadn't been present in the", "tokens": [51622, 400, 550, 1034, 12162, 689, 2594, 363, 576, 362, 2780, 498, 2594, 316, 8782, 380, 668, 1974, 294, 264, 51784], "temperature": 0.0, "avg_logprob": -0.14298546554258207, "compression_ratio": 1.8308605341246291, "no_speech_prob": 0.0005108024924993515}, {"id": 115, "seek": 53088, "start": 530.92, "end": 535.4399999999999, "text": " scene. Maybe you all sort of naturally and spontaneously did that. And of course, I already", "tokens": [50366, 4145, 13, 2704, 291, 439, 1333, 295, 8195, 293, 47632, 630, 300, 13, 400, 295, 1164, 11, 286, 1217, 50592], "temperature": 0.0, "avg_logprob": -0.1608734130859375, "compression_ratio": 1.749185667752443, "no_speech_prob": 0.001780003309249878}, {"id": 116, "seek": 53088, "start": 535.4399999999999, "end": 539.52, "text": " talked a little bit about counterfactuals and stuff like that in the experiment. Of course,", "tokens": [50592, 2825, 257, 707, 857, 466, 5682, 44919, 901, 82, 293, 1507, 411, 300, 294, 264, 5120, 13, 2720, 1164, 11, 50796], "temperature": 0.0, "avg_logprob": -0.1608734130859375, "compression_ratio": 1.749185667752443, "no_speech_prob": 0.001780003309249878}, {"id": 117, "seek": 53088, "start": 539.52, "end": 544.72, "text": " I don't do that. I just ask people to make causal judgments. So the simple idea here", "tokens": [50796, 286, 500, 380, 360, 300, 13, 286, 445, 1029, 561, 281, 652, 38755, 40337, 13, 407, 264, 2199, 1558, 510, 51056], "temperature": 0.0, "avg_logprob": -0.1608734130859375, "compression_ratio": 1.749185667752443, "no_speech_prob": 0.001780003309249878}, {"id": 118, "seek": 53088, "start": 544.72, "end": 548.92, "text": " is then to say, when do you say that A caused me to go through the gate? It's really sort", "tokens": [51056, 307, 550, 281, 584, 11, 562, 360, 291, 584, 300, 316, 7008, 385, 281, 352, 807, 264, 8539, 30, 467, 311, 534, 1333, 51266], "temperature": 0.0, "avg_logprob": -0.1608734130859375, "compression_ratio": 1.749185667752443, "no_speech_prob": 0.001780003309249878}, {"id": 119, "seek": 53088, "start": 548.92, "end": 552.92, "text": " of like an epistemic notion. So your subjective degree of belief, well, to the extent that", "tokens": [51266, 295, 411, 364, 2388, 468, 3438, 10710, 13, 407, 428, 25972, 4314, 295, 7107, 11, 731, 11, 281, 264, 8396, 300, 51466], "temperature": 0.0, "avg_logprob": -0.1608734130859375, "compression_ratio": 1.749185667752443, "no_speech_prob": 0.001780003309249878}, {"id": 120, "seek": 53088, "start": 552.92, "end": 558.12, "text": " you think that what would have happened in the actual, so that what would have happened", "tokens": [51466, 291, 519, 300, 437, 576, 362, 2011, 294, 264, 3539, 11, 370, 300, 437, 576, 362, 2011, 51726], "temperature": 0.0, "avg_logprob": -0.1608734130859375, "compression_ratio": 1.749185667752443, "no_speech_prob": 0.001780003309249878}, {"id": 121, "seek": 55812, "start": 558.16, "end": 561.28, "text": " in the counterfactual situation would have been different from the thing that actually", "tokens": [50366, 294, 264, 5682, 44919, 901, 2590, 576, 362, 668, 819, 490, 264, 551, 300, 767, 50522], "temperature": 0.0, "avg_logprob": -0.1578245532605075, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.00019403555779717863}, {"id": 122, "seek": 55812, "start": 561.28, "end": 566.08, "text": " happened, that determines your extent to which you say that A caused B to go through the", "tokens": [50522, 2011, 11, 300, 24799, 428, 8396, 281, 597, 291, 584, 300, 316, 7008, 363, 281, 352, 807, 264, 50762], "temperature": 0.0, "avg_logprob": -0.1578245532605075, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.00019403555779717863}, {"id": 123, "seek": 55812, "start": 566.08, "end": 570.44, "text": " gate. And here you're probably pretty sure in this instance that B would have missed", "tokens": [50762, 8539, 13, 400, 510, 291, 434, 1391, 1238, 988, 294, 341, 5197, 300, 363, 576, 362, 6721, 50980], "temperature": 0.0, "avg_logprob": -0.1578245532605075, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.00019403555779717863}, {"id": 124, "seek": 55812, "start": 570.44, "end": 575.52, "text": " if A hadn't been there. So you say, yes, A caused it to go through. And just a little", "tokens": [50980, 498, 316, 8782, 380, 668, 456, 13, 407, 291, 584, 11, 2086, 11, 316, 7008, 309, 281, 352, 807, 13, 400, 445, 257, 707, 51234], "temperature": 0.0, "avg_logprob": -0.1578245532605075, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.00019403555779717863}, {"id": 125, "seek": 55812, "start": 575.52, "end": 579.96, "text": " bit in terms of sort of background, a lot of the inspiration for this kind of work comes", "tokens": [51234, 857, 294, 2115, 295, 1333, 295, 3678, 11, 257, 688, 295, 264, 10249, 337, 341, 733, 295, 589, 1487, 51456], "temperature": 0.0, "avg_logprob": -0.1578245532605075, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.00019403555779717863}, {"id": 126, "seek": 55812, "start": 579.96, "end": 586.84, "text": " from Judea Pearl's work on causality. Some of you may have heard of his work. And there", "tokens": [51456, 490, 36521, 64, 24639, 311, 589, 322, 3302, 1860, 13, 2188, 295, 291, 815, 362, 2198, 295, 702, 589, 13, 400, 456, 51800], "temperature": 0.0, "avg_logprob": -0.1578245532605075, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.00019403555779717863}, {"id": 127, "seek": 58684, "start": 586.88, "end": 590.6800000000001, "text": " they use different kinds of generative models to capture people's causal knowledge of the", "tokens": [50366, 436, 764, 819, 3685, 295, 1337, 1166, 5245, 281, 7983, 561, 311, 38755, 3601, 295, 264, 50556], "temperature": 0.0, "avg_logprob": -0.1368903284487517, "compression_ratio": 1.76, "no_speech_prob": 0.000277959305094555}, {"id": 128, "seek": 58684, "start": 590.6800000000001, "end": 595.0400000000001, "text": " world. So this could be something like causal base nets or structural equations that you", "tokens": [50556, 1002, 13, 407, 341, 727, 312, 746, 411, 38755, 3096, 36170, 420, 15067, 11787, 300, 291, 50774], "temperature": 0.0, "avg_logprob": -0.1368903284487517, "compression_ratio": 1.76, "no_speech_prob": 0.000277959305094555}, {"id": 129, "seek": 58684, "start": 595.0400000000001, "end": 599.96, "text": " may also remember from your stats class if you had one. And then you define some kind", "tokens": [50774, 815, 611, 1604, 490, 428, 18152, 1508, 498, 291, 632, 472, 13, 400, 550, 291, 6964, 512, 733, 51020], "temperature": 0.0, "avg_logprob": -0.1368903284487517, "compression_ratio": 1.76, "no_speech_prob": 0.000277959305094555}, {"id": 130, "seek": 58684, "start": 599.96, "end": 605.4, "text": " of operations on these models to support things like counterfactual reasoning. So imagining", "tokens": [51020, 295, 7705, 322, 613, 5245, 281, 1406, 721, 411, 5682, 44919, 901, 21577, 13, 407, 27798, 51292], "temperature": 0.0, "avg_logprob": -0.1368903284487517, "compression_ratio": 1.76, "no_speech_prob": 0.000277959305094555}, {"id": 131, "seek": 58684, "start": 605.4, "end": 610.2800000000001, "text": " that some variable had been replaced with another one, for example. And so I'm doing", "tokens": [51292, 300, 512, 7006, 632, 668, 10772, 365, 1071, 472, 11, 337, 1365, 13, 400, 370, 286, 478, 884, 51536], "temperature": 0.0, "avg_logprob": -0.1368903284487517, "compression_ratio": 1.76, "no_speech_prob": 0.000277959305094555}, {"id": 132, "seek": 58684, "start": 610.2800000000001, "end": 614.12, "text": " something quite similar here, only in that I'm assuming that the generative model that", "tokens": [51536, 746, 1596, 2531, 510, 11, 787, 294, 300, 286, 478, 11926, 300, 264, 1337, 1166, 2316, 300, 51728], "temperature": 0.0, "avg_logprob": -0.1368903284487517, "compression_ratio": 1.76, "no_speech_prob": 0.000277959305094555}, {"id": 133, "seek": 61412, "start": 614.12, "end": 618.16, "text": " people have of the world in this case is somewhat richer than what can be represented", "tokens": [50364, 561, 362, 295, 264, 1002, 294, 341, 1389, 307, 8344, 29021, 813, 437, 393, 312, 10379, 50566], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 134, "seek": 61412, "start": 618.16, "end": 622.32, "text": " with these causal basis or structural equations. So in my case, the generative model that I", "tokens": [50566, 365, 613, 38755, 5143, 420, 15067, 11787, 13, 407, 294, 452, 1389, 11, 264, 1337, 1166, 2316, 300, 286, 50774], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 135, "seek": 61412, "start": 622.32, "end": 625.96, "text": " assume people have in their mind is something like the physics engine that I actually use", "tokens": [50774, 6552, 561, 362, 294, 641, 1575, 307, 746, 411, 264, 10649, 2848, 300, 286, 767, 764, 50956], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 136, "seek": 61412, "start": 625.96, "end": 630.44, "text": " to generate them in the stimuli. And I'll make that noisy. I'll show you in a second", "tokens": [50956, 281, 8460, 552, 294, 264, 47752, 13, 400, 286, 603, 652, 300, 24518, 13, 286, 603, 855, 291, 294, 257, 1150, 51180], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 137, "seek": 61412, "start": 630.44, "end": 635.52, "text": " how I'm making it noisy. And then I also have to think about, okay, what are now the counterfactual", "tokens": [51180, 577, 286, 478, 1455, 309, 24518, 13, 400, 550, 286, 611, 362, 281, 519, 466, 11, 1392, 11, 437, 366, 586, 264, 5682, 44919, 901, 51434], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 138, "seek": 61412, "start": 635.52, "end": 639.76, "text": " intervention operators that you might have over a representation like this one? And in", "tokens": [51434, 13176, 19077, 300, 291, 1062, 362, 670, 257, 10290, 411, 341, 472, 30, 400, 294, 51646], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 139, "seek": 61412, "start": 639.76, "end": 643.6800000000001, "text": " this case, it could be something like imagining that an object wouldn't have been, would not", "tokens": [51646, 341, 1389, 11, 309, 727, 312, 746, 411, 27798, 300, 364, 2657, 2759, 380, 362, 668, 11, 576, 406, 51842], "temperature": 0.0, "avg_logprob": -0.14271538922575866, "compression_ratio": 1.8425655976676385, "no_speech_prob": 0.00033516183611936867}, {"id": 140, "seek": 64368, "start": 643.68, "end": 648.52, "text": " have been there, for example. Okay, so you might think now, okay, well, maybe that's", "tokens": [50364, 362, 668, 456, 11, 337, 1365, 13, 1033, 11, 370, 291, 1062, 519, 586, 11, 1392, 11, 731, 11, 1310, 300, 311, 50606], "temperature": 0.0, "avg_logprob": -0.14090432061089408, "compression_ratio": 1.70926517571885, "no_speech_prob": 0.0006765631260350347}, {"id": 141, "seek": 64368, "start": 648.52, "end": 652.7199999999999, "text": " the only game in town. Like what else could you possibly be doing in a setting like this?", "tokens": [50606, 264, 787, 1216, 294, 3954, 13, 1743, 437, 1646, 727, 291, 6264, 312, 884, 294, 257, 3287, 411, 341, 30, 50816], "temperature": 0.0, "avg_logprob": -0.14090432061089408, "compression_ratio": 1.70926517571885, "no_speech_prob": 0.0006765631260350347}, {"id": 142, "seek": 64368, "start": 652.7199999999999, "end": 656.2399999999999, "text": " And at least luckily for me, there has been a lot of philosophers and psychologists that", "tokens": [50816, 400, 412, 1935, 22880, 337, 385, 11, 456, 575, 668, 257, 688, 295, 36839, 293, 41562, 300, 50992], "temperature": 0.0, "avg_logprob": -0.14090432061089408, "compression_ratio": 1.70926517571885, "no_speech_prob": 0.0006765631260350347}, {"id": 143, "seek": 64368, "start": 656.2399999999999, "end": 660.52, "text": " have argued for what I called these actualist theories of causation. And they basically", "tokens": [50992, 362, 20219, 337, 437, 286, 1219, 613, 3539, 468, 13667, 295, 3302, 399, 13, 400, 436, 1936, 51206], "temperature": 0.0, "avg_logprob": -0.14090432061089408, "compression_ratio": 1.70926517571885, "no_speech_prob": 0.0006765631260350347}, {"id": 144, "seek": 64368, "start": 660.52, "end": 664.52, "text": " just say you don't need that part, right? All you need, all the information you need", "tokens": [51206, 445, 584, 291, 500, 380, 643, 300, 644, 11, 558, 30, 1057, 291, 643, 11, 439, 264, 1589, 291, 643, 51406], "temperature": 0.0, "avg_logprob": -0.14090432061089408, "compression_ratio": 1.70926517571885, "no_speech_prob": 0.0006765631260350347}, {"id": 145, "seek": 64368, "start": 664.52, "end": 669.8399999999999, "text": " to give causal judgments or causal explanations for what happened is there in the actual situation", "tokens": [51406, 281, 976, 38755, 40337, 420, 38755, 28708, 337, 437, 2011, 307, 456, 294, 264, 3539, 2590, 51672], "temperature": 0.0, "avg_logprob": -0.14090432061089408, "compression_ratio": 1.70926517571885, "no_speech_prob": 0.0006765631260350347}, {"id": 146, "seek": 66984, "start": 669.88, "end": 674.8000000000001, "text": " in some sense. And so one of the best kind of worked out accounts of that in psychology", "tokens": [50366, 294, 512, 2020, 13, 400, 370, 472, 295, 264, 1151, 733, 295, 2732, 484, 9402, 295, 300, 294, 15105, 50612], "temperature": 0.0, "avg_logprob": -0.14142079991618478, "compression_ratio": 1.7852348993288591, "no_speech_prob": 0.0011151728685945272}, {"id": 147, "seek": 66984, "start": 674.8000000000001, "end": 679.4, "text": " comes from a psychologist called Philip Wolff and he calls it the force dynamics model", "tokens": [50612, 1487, 490, 257, 29514, 1219, 21144, 19925, 602, 293, 415, 5498, 309, 264, 3464, 15679, 2316, 50842], "temperature": 0.0, "avg_logprob": -0.14142079991618478, "compression_ratio": 1.7852348993288591, "no_speech_prob": 0.0011151728685945272}, {"id": 148, "seek": 66984, "start": 679.4, "end": 684.08, "text": " of causation. And the idea is that all you need to pay attention to is the forces that", "tokens": [50842, 295, 3302, 399, 13, 400, 264, 1558, 307, 300, 439, 291, 643, 281, 1689, 3202, 281, 307, 264, 5874, 300, 51076], "temperature": 0.0, "avg_logprob": -0.14142079991618478, "compression_ratio": 1.7852348993288591, "no_speech_prob": 0.0011151728685945272}, {"id": 149, "seek": 66984, "start": 684.08, "end": 689.6, "text": " are associated with the agent and the patient. That's the sort of lingo they use. And you", "tokens": [51076, 366, 6615, 365, 264, 9461, 293, 264, 4537, 13, 663, 311, 264, 1333, 295, 287, 18459, 436, 764, 13, 400, 291, 51352], "temperature": 0.0, "avg_logprob": -0.14142079991618478, "compression_ratio": 1.7852348993288591, "no_speech_prob": 0.0011151728685945272}, {"id": 150, "seek": 66984, "start": 689.6, "end": 693.08, "text": " then you just look, need to look at how these forces are configured. And that helps you", "tokens": [51352, 550, 291, 445, 574, 11, 643, 281, 574, 412, 577, 613, 5874, 366, 30538, 13, 400, 300, 3665, 291, 51526], "temperature": 0.0, "avg_logprob": -0.14142079991618478, "compression_ratio": 1.7852348993288591, "no_speech_prob": 0.0011151728685945272}, {"id": 151, "seek": 66984, "start": 693.08, "end": 697.6800000000001, "text": " to say what in this case here, there's different causal expressions is appropriate to use in", "tokens": [51526, 281, 584, 437, 294, 341, 1389, 510, 11, 456, 311, 819, 38755, 15277, 307, 6854, 281, 764, 294, 51756], "temperature": 0.0, "avg_logprob": -0.14142079991618478, "compression_ratio": 1.7852348993288591, "no_speech_prob": 0.0011151728685945272}, {"id": 152, "seek": 69768, "start": 697.68, "end": 702.4799999999999, "text": " a particular situation. And I'll just apply it to this example here. So we have the patient", "tokens": [50364, 257, 1729, 2590, 13, 400, 286, 603, 445, 3079, 309, 281, 341, 1365, 510, 13, 407, 321, 362, 264, 4537, 50604], "temperature": 0.0, "avg_logprob": -0.13589975237846375, "compression_ratio": 1.8281786941580755, "no_speech_prob": 0.0004877230094280094}, {"id": 153, "seek": 69768, "start": 702.4799999999999, "end": 706.52, "text": " which is ball B that has a force that is associated with it. Then we have an agent", "tokens": [50604, 597, 307, 2594, 363, 300, 575, 257, 3464, 300, 307, 6615, 365, 309, 13, 1396, 321, 362, 364, 9461, 50806], "temperature": 0.0, "avg_logprob": -0.13589975237846375, "compression_ratio": 1.8281786941580755, "no_speech_prob": 0.0004877230094280094}, {"id": 154, "seek": 69768, "start": 706.52, "end": 710.52, "text": " that applies a force to the patient in this case. As a function of these two forces, we", "tokens": [50806, 300, 13165, 257, 3464, 281, 264, 4537, 294, 341, 1389, 13, 1018, 257, 2445, 295, 613, 732, 5874, 11, 321, 51006], "temperature": 0.0, "avg_logprob": -0.13589975237846375, "compression_ratio": 1.8281786941580755, "no_speech_prob": 0.0004877230094280094}, {"id": 155, "seek": 69768, "start": 710.52, "end": 714.3599999999999, "text": " have some resulting force here. And then in this case, the patient also ended up reaching", "tokens": [51006, 362, 512, 16505, 3464, 510, 13, 400, 550, 294, 341, 1389, 11, 264, 4537, 611, 4590, 493, 9906, 51198], "temperature": 0.0, "avg_logprob": -0.13589975237846375, "compression_ratio": 1.8281786941580755, "no_speech_prob": 0.0004877230094280094}, {"id": 156, "seek": 69768, "start": 714.3599999999999, "end": 720.0, "text": " the end state. And because this configuration looks like that and that maps onto this force", "tokens": [51198, 264, 917, 1785, 13, 400, 570, 341, 11694, 1542, 411, 300, 293, 300, 11317, 3911, 341, 3464, 51480], "temperature": 0.0, "avg_logprob": -0.13589975237846375, "compression_ratio": 1.8281786941580755, "no_speech_prob": 0.0004877230094280094}, {"id": 157, "seek": 69768, "start": 720.0, "end": 724.4399999999999, "text": " configuration, Philip Wolff's account would also here say, yes, a cause B to go through", "tokens": [51480, 11694, 11, 21144, 19925, 602, 311, 2696, 576, 611, 510, 584, 11, 2086, 11, 257, 3082, 363, 281, 352, 807, 51702], "temperature": 0.0, "avg_logprob": -0.13589975237846375, "compression_ratio": 1.8281786941580755, "no_speech_prob": 0.0004877230094280094}, {"id": 158, "seek": 72444, "start": 724.44, "end": 728.24, "text": " the gate. So this clip would not help us actually tease apart this other model that", "tokens": [50364, 264, 8539, 13, 407, 341, 7353, 576, 406, 854, 505, 767, 30444, 4936, 341, 661, 2316, 300, 50554], "temperature": 0.0, "avg_logprob": -0.11503519217173258, "compression_ratio": 1.8047945205479452, "no_speech_prob": 0.0016479998594149947}, {"id": 159, "seek": 72444, "start": 728.24, "end": 734.1600000000001, "text": " I've been kind of promoting. So just to make this distinction sort of clear or clearer.", "tokens": [50554, 286, 600, 668, 733, 295, 16383, 13, 407, 445, 281, 652, 341, 16844, 1333, 295, 1850, 420, 26131, 13, 50850], "temperature": 0.0, "avg_logprob": -0.11503519217173258, "compression_ratio": 1.8047945205479452, "no_speech_prob": 0.0016479998594149947}, {"id": 160, "seek": 72444, "start": 734.1600000000001, "end": 737.48, "text": " So in the force dynamics model, you start with some intuitive theory of how the world", "tokens": [50850, 407, 294, 264, 3464, 15679, 2316, 11, 291, 722, 365, 512, 21769, 5261, 295, 577, 264, 1002, 51016], "temperature": 0.0, "avg_logprob": -0.11503519217173258, "compression_ratio": 1.8047945205479452, "no_speech_prob": 0.0016479998594149947}, {"id": 161, "seek": 72444, "start": 737.48, "end": 742.08, "text": " works, which in this case are these little force vectors that apply to agents and patients.", "tokens": [51016, 1985, 11, 597, 294, 341, 1389, 366, 613, 707, 3464, 18875, 300, 3079, 281, 12554, 293, 4209, 13, 51246], "temperature": 0.0, "avg_logprob": -0.11503519217173258, "compression_ratio": 1.8047945205479452, "no_speech_prob": 0.0016479998594149947}, {"id": 162, "seek": 72444, "start": 742.08, "end": 745.96, "text": " And you can then directly go from there to making causal judgments. So there's this direct", "tokens": [51246, 400, 291, 393, 550, 3838, 352, 490, 456, 281, 1455, 38755, 40337, 13, 407, 456, 311, 341, 2047, 51440], "temperature": 0.0, "avg_logprob": -0.11503519217173258, "compression_ratio": 1.8047945205479452, "no_speech_prob": 0.0016479998594149947}, {"id": 163, "seek": 72444, "start": 745.96, "end": 751.12, "text": " route from this kind of intuitive theory to causal judgment. He also says that you can", "tokens": [51440, 7955, 490, 341, 733, 295, 21769, 5261, 281, 38755, 12216, 13, 634, 611, 1619, 300, 291, 393, 51698], "temperature": 0.0, "avg_logprob": -0.11503519217173258, "compression_ratio": 1.8047945205479452, "no_speech_prob": 0.0016479998594149947}, {"id": 164, "seek": 75112, "start": 751.12, "end": 755.72, "text": " do counterfactuals too by imagining, for example, if one of the forces hadn't been there, what", "tokens": [50364, 360, 5682, 44919, 901, 82, 886, 538, 27798, 11, 337, 1365, 11, 498, 472, 295, 264, 5874, 8782, 380, 668, 456, 11, 437, 50594], "temperature": 0.0, "avg_logprob": -0.1415052267221304, "compression_ratio": 1.773462783171521, "no_speech_prob": 0.0009104373748414218}, {"id": 165, "seek": 75112, "start": 755.72, "end": 760.2, "text": " would have happened in the situation, but that it's not necessary to figure out whether", "tokens": [50594, 576, 362, 2011, 294, 264, 2590, 11, 457, 300, 309, 311, 406, 4818, 281, 2573, 484, 1968, 50818], "temperature": 0.0, "avg_logprob": -0.1415052267221304, "compression_ratio": 1.773462783171521, "no_speech_prob": 0.0009104373748414218}, {"id": 166, "seek": 75112, "start": 760.2, "end": 764.92, "text": " something caused something to happen. And sort of what I'm arguing for is sort of a slightly", "tokens": [50818, 746, 7008, 746, 281, 1051, 13, 400, 1333, 295, 437, 286, 478, 19697, 337, 307, 1333, 295, 257, 4748, 51054], "temperature": 0.0, "avg_logprob": -0.1415052267221304, "compression_ratio": 1.773462783171521, "no_speech_prob": 0.0009104373748414218}, {"id": 167, "seek": 75112, "start": 764.92, "end": 768.36, "text": " different picture. Where I'm saying, well, first of all, I start with a slightly different", "tokens": [51054, 819, 3036, 13, 2305, 286, 478, 1566, 11, 731, 11, 700, 295, 439, 11, 286, 722, 365, 257, 4748, 819, 51226], "temperature": 0.0, "avg_logprob": -0.1415052267221304, "compression_ratio": 1.773462783171521, "no_speech_prob": 0.0009104373748414218}, {"id": 168, "seek": 75112, "start": 768.36, "end": 772.52, "text": " theory of the domain. In this case, again, using the physics engine rather than using", "tokens": [51226, 5261, 295, 264, 9274, 13, 682, 341, 1389, 11, 797, 11, 1228, 264, 10649, 2848, 2831, 813, 1228, 51434], "temperature": 0.0, "avg_logprob": -0.1415052267221304, "compression_ratio": 1.773462783171521, "no_speech_prob": 0.0009104373748414218}, {"id": 169, "seek": 75112, "start": 772.52, "end": 776.88, "text": " these force vectors. But then saying that you have to go through this process of counterfactual", "tokens": [51434, 613, 3464, 18875, 13, 583, 550, 1566, 300, 291, 362, 281, 352, 807, 341, 1399, 295, 5682, 44919, 901, 51652], "temperature": 0.0, "avg_logprob": -0.1415052267221304, "compression_ratio": 1.773462783171521, "no_speech_prob": 0.0009104373748414218}, {"id": 170, "seek": 77688, "start": 776.88, "end": 781.88, "text": " simulation to say that something caused something to happen. And what I'm going to try and do", "tokens": [50364, 16575, 281, 584, 300, 746, 7008, 746, 281, 1051, 13, 400, 437, 286, 478, 516, 281, 853, 293, 360, 50614], "temperature": 0.0, "avg_logprob": -0.13228298218782283, "compression_ratio": 1.8362989323843417, "no_speech_prob": 0.0025492426939308643}, {"id": 171, "seek": 77688, "start": 781.88, "end": 787.08, "text": " in the next two slides is sort of motivate that account.", "tokens": [50614, 294, 264, 958, 732, 9788, 307, 1333, 295, 28497, 300, 2696, 13, 50874], "temperature": 0.0, "avg_logprob": -0.13228298218782283, "compression_ratio": 1.8362989323843417, "no_speech_prob": 0.0025492426939308643}, {"id": 172, "seek": 77688, "start": 787.08, "end": 790.76, "text": " One way to motivate at first is that I started off saying like I want to have this model", "tokens": [50874, 1485, 636, 281, 28497, 412, 700, 307, 300, 286, 1409, 766, 1566, 411, 286, 528, 281, 362, 341, 2316, 51058], "temperature": 0.0, "avg_logprob": -0.13228298218782283, "compression_ratio": 1.8362989323843417, "no_speech_prob": 0.0025492426939308643}, {"id": 173, "seek": 77688, "start": 790.76, "end": 795.16, "text": " of responsibility. And that means that I want to have a model of causation that not only", "tokens": [51058, 295, 6357, 13, 400, 300, 1355, 300, 286, 528, 281, 362, 257, 2316, 295, 3302, 399, 300, 406, 787, 51278], "temperature": 0.0, "avg_logprob": -0.13228298218782283, "compression_ratio": 1.8362989323843417, "no_speech_prob": 0.0025492426939308643}, {"id": 174, "seek": 77688, "start": 795.16, "end": 799.32, "text": " narrowly applies to the physical world, but that can also be applied to, for example, the", "tokens": [51278, 9432, 356, 13165, 281, 264, 4001, 1002, 11, 457, 300, 393, 611, 312, 6456, 281, 11, 337, 1365, 11, 264, 51486], "temperature": 0.0, "avg_logprob": -0.13228298218782283, "compression_ratio": 1.8362989323843417, "no_speech_prob": 0.0025492426939308643}, {"id": 175, "seek": 77688, "start": 799.32, "end": 803.76, "text": " kind of causation that happens between people. And here's just some examples of causal statements", "tokens": [51486, 733, 295, 3302, 399, 300, 2314, 1296, 561, 13, 400, 510, 311, 445, 512, 5110, 295, 38755, 12363, 51708], "temperature": 0.0, "avg_logprob": -0.13228298218782283, "compression_ratio": 1.8362989323843417, "no_speech_prob": 0.0025492426939308643}, {"id": 176, "seek": 80376, "start": 803.76, "end": 807.96, "text": " that you could hear at the fall of Lehman Brothers, caused the financial crisis. My", "tokens": [50364, 300, 291, 727, 1568, 412, 264, 2100, 295, 42631, 1601, 19886, 11, 7008, 264, 4669, 5869, 13, 1222, 50574], "temperature": 0.0, "avg_logprob": -0.18127891307568733, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0017530897166579962}, {"id": 177, "seek": 80376, "start": 807.96, "end": 812.4399999999999, "text": " housemates failed to water my plants, caused them to die. Realizing that he forgot his", "tokens": [50574, 1782, 10977, 7612, 281, 1281, 452, 5972, 11, 7008, 552, 281, 978, 13, 8467, 3319, 300, 415, 5298, 702, 50798], "temperature": 0.0, "avg_logprob": -0.18127891307568733, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0017530897166579962}, {"id": 178, "seek": 80376, "start": 812.4399999999999, "end": 816.28, "text": " wallet at home, caused him to go back. You probably wouldn't say that exactly in English,", "tokens": [50798, 16599, 412, 1280, 11, 7008, 796, 281, 352, 646, 13, 509, 1391, 2759, 380, 584, 300, 2293, 294, 3669, 11, 50990], "temperature": 0.0, "avg_logprob": -0.18127891307568733, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0017530897166579962}, {"id": 179, "seek": 80376, "start": 816.28, "end": 820.56, "text": " but they all seem to find sort of causal things, like to say. And it's probably a little bit", "tokens": [50990, 457, 436, 439, 1643, 281, 915, 1333, 295, 38755, 721, 11, 411, 281, 584, 13, 400, 309, 311, 1391, 257, 707, 857, 51204], "temperature": 0.0, "avg_logprob": -0.18127891307568733, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0017530897166579962}, {"id": 180, "seek": 80376, "start": 820.56, "end": 824.96, "text": " tricky, or at least I would find it tricky, to think of how would I explain these sorts", "tokens": [51204, 12414, 11, 420, 412, 1935, 286, 576, 915, 309, 12414, 11, 281, 519, 295, 577, 576, 286, 2903, 613, 7527, 51424], "temperature": 0.0, "avg_logprob": -0.18127891307568733, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0017530897166579962}, {"id": 181, "seek": 80376, "start": 824.96, "end": 828.96, "text": " of causations with force vectors. And the hope is that the account that I'm developing", "tokens": [51424, 295, 3302, 763, 365, 3464, 18875, 13, 400, 264, 1454, 307, 300, 264, 2696, 300, 286, 478, 6416, 51624], "temperature": 0.0, "avg_logprob": -0.18127891307568733, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0017530897166579962}, {"id": 182, "seek": 82896, "start": 828.96, "end": 833.88, "text": " is a little bit more flexible so that it can apply to these sorts of situations as well.", "tokens": [50364, 307, 257, 707, 857, 544, 11358, 370, 300, 309, 393, 3079, 281, 613, 7527, 295, 6851, 382, 731, 13, 50610], "temperature": 0.0, "avg_logprob": -0.1301424441130265, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.0004034209414385259}, {"id": 183, "seek": 82896, "start": 833.88, "end": 839.6800000000001, "text": " But now, and another kind of key advantage, I think, of the model that we've been developing", "tokens": [50610, 583, 586, 11, 293, 1071, 733, 295, 2141, 5002, 11, 286, 519, 11, 295, 264, 2316, 300, 321, 600, 668, 6416, 50900], "temperature": 0.0, "avg_logprob": -0.1301424441130265, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.0004034209414385259}, {"id": 184, "seek": 82896, "start": 839.6800000000001, "end": 844.64, "text": " is that it actually allows us to derive quantitative predictions. And it's hence more easily falsifiable", "tokens": [50900, 307, 300, 309, 767, 4045, 505, 281, 28446, 27778, 21264, 13, 400, 309, 311, 16678, 544, 3612, 16720, 30876, 51148], "temperature": 0.0, "avg_logprob": -0.1301424441130265, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.0004034209414385259}, {"id": 185, "seek": 82896, "start": 844.64, "end": 849.12, "text": " that some of the prior work. And so you can falsify it if you like, write a paper until", "tokens": [51148, 300, 512, 295, 264, 4059, 589, 13, 400, 370, 291, 393, 16720, 2505, 309, 498, 291, 411, 11, 2464, 257, 3035, 1826, 51372], "temperature": 0.0, "avg_logprob": -0.1301424441130265, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.0004034209414385259}, {"id": 186, "seek": 82896, "start": 849.12, "end": 855.5600000000001, "text": " we was wrong. And then I have to go back to the office and improve the account. So here's", "tokens": [51372, 321, 390, 2085, 13, 400, 550, 286, 362, 281, 352, 646, 281, 264, 3398, 293, 3470, 264, 2696, 13, 407, 510, 311, 51694], "temperature": 0.0, "avg_logprob": -0.1301424441130265, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.0004034209414385259}, {"id": 187, "seek": 85556, "start": 855.5999999999999, "end": 859.3599999999999, "text": " a way in which we're getting quantitative predictions out of this model. But I was saying", "tokens": [50366, 257, 636, 294, 597, 321, 434, 1242, 27778, 21264, 484, 295, 341, 2316, 13, 583, 286, 390, 1566, 50554], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 188, "seek": 85556, "start": 859.3599999999999, "end": 864.4, "text": " that how you make causal judgments is by comparing what actually happened with what", "tokens": [50554, 300, 577, 291, 652, 38755, 40337, 307, 538, 15763, 437, 767, 2011, 365, 437, 50806], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 189, "seek": 85556, "start": 864.4, "end": 869.4399999999999, "text": " would have happened in the relevant counterfactual situation. But now you don't know that. The", "tokens": [50806, 576, 362, 2011, 294, 264, 7340, 5682, 44919, 901, 2590, 13, 583, 586, 291, 500, 380, 458, 300, 13, 440, 51058], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 190, "seek": 85556, "start": 869.4399999999999, "end": 873.2399999999999, "text": " thing that I'm showing here on the right-hand side, I guess, that's in some sense the ground", "tokens": [51058, 551, 300, 286, 478, 4099, 510, 322, 264, 558, 12, 5543, 1252, 11, 286, 2041, 11, 300, 311, 294, 512, 2020, 264, 2727, 51248], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 191, "seek": 85556, "start": 873.2399999999999, "end": 877.4799999999999, "text": " to truth. But you don't get to see that. You only see what actually happens. You don't", "tokens": [51248, 281, 3494, 13, 583, 291, 500, 380, 483, 281, 536, 300, 13, 509, 787, 536, 437, 767, 2314, 13, 509, 500, 380, 51460], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 192, "seek": 85556, "start": 877.4799999999999, "end": 881.5999999999999, "text": " get to see what would have happened if ball A hadn't been there. So you have to use your", "tokens": [51460, 483, 281, 536, 437, 576, 362, 2011, 498, 2594, 316, 8782, 380, 668, 456, 13, 407, 291, 362, 281, 764, 428, 51666], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 193, "seek": 85556, "start": 881.5999999999999, "end": 884.88, "text": " intuitive understanding, again, of this domain to simulate what would have happened in this", "tokens": [51666, 21769, 3701, 11, 797, 11, 295, 341, 9274, 281, 27817, 437, 576, 362, 2011, 294, 341, 51830], "temperature": 0.0, "avg_logprob": -0.13462647755940754, "compression_ratio": 1.9294478527607362, "no_speech_prob": 0.008055901154875755}, {"id": 194, "seek": 88488, "start": 884.88, "end": 890.16, "text": " counterfactual. And so one way for us to capture this uncertainty that you may have", "tokens": [50364, 5682, 44919, 901, 13, 400, 370, 472, 636, 337, 505, 281, 7983, 341, 15697, 300, 291, 815, 362, 50628], "temperature": 0.0, "avg_logprob": -0.11730769047370324, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.00014646182535216212}, {"id": 195, "seek": 88488, "start": 890.16, "end": 895.48, "text": " about exactly what would have happened if ball A hadn't been there is by generating simulations", "tokens": [50628, 466, 2293, 437, 576, 362, 2011, 498, 2594, 316, 8782, 380, 668, 456, 307, 538, 17746, 35138, 50894], "temperature": 0.0, "avg_logprob": -0.11730769047370324, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.00014646182535216212}, {"id": 196, "seek": 88488, "start": 895.48, "end": 899.64, "text": " from our physics engine, but now injecting a little bit of noise into that engine. So", "tokens": [50894, 490, 527, 10649, 2848, 11, 457, 586, 10711, 278, 257, 707, 857, 295, 5658, 666, 300, 2848, 13, 407, 51102], "temperature": 0.0, "avg_logprob": -0.11730769047370324, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.00014646182535216212}, {"id": 197, "seek": 88488, "start": 899.64, "end": 904.12, "text": " now it becomes sort of like a probabilistic program because it's now not a deterministic", "tokens": [51102, 586, 309, 3643, 1333, 295, 411, 257, 31959, 3142, 1461, 570, 309, 311, 586, 406, 257, 15957, 3142, 51326], "temperature": 0.0, "avg_logprob": -0.11730769047370324, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.00014646182535216212}, {"id": 198, "seek": 88488, "start": 904.12, "end": 909.24, "text": " outcome anymore if ball A hadn't been there. But rather what I'm doing is I'm generating", "tokens": [51326, 9700, 3602, 498, 2594, 316, 8782, 380, 668, 456, 13, 583, 2831, 437, 286, 478, 884, 307, 286, 478, 17746, 51582], "temperature": 0.0, "avg_logprob": -0.11730769047370324, "compression_ratio": 1.6973180076628354, "no_speech_prob": 0.00014646182535216212}, {"id": 199, "seek": 90924, "start": 909.24, "end": 914.8, "text": " a simulated sample from my model. And now in this case there's many different ways in", "tokens": [50364, 257, 41713, 6889, 490, 452, 2316, 13, 400, 586, 294, 341, 1389, 456, 311, 867, 819, 2098, 294, 50642], "temperature": 0.0, "avg_logprob": -0.14284569469850456, "compression_ratio": 1.71656050955414, "no_speech_prob": 0.0008166400366462767}, {"id": 200, "seek": 90924, "start": 914.8, "end": 918.96, "text": " which you could make your model kind of random or uncertain. Here what we did is we just", "tokens": [50642, 597, 291, 727, 652, 428, 2316, 733, 295, 4974, 420, 11308, 13, 1692, 437, 321, 630, 307, 321, 445, 50850], "temperature": 0.0, "avg_logprob": -0.14284569469850456, "compression_ratio": 1.71656050955414, "no_speech_prob": 0.0008166400366462767}, {"id": 201, "seek": 90924, "start": 918.96, "end": 924.6, "text": " took the actual ground truth, that ball B, velocity that ball B would have had, and applied", "tokens": [50850, 1890, 264, 3539, 2727, 3494, 11, 300, 2594, 363, 11, 9269, 300, 2594, 363, 576, 362, 632, 11, 293, 6456, 51132], "temperature": 0.0, "avg_logprob": -0.14284569469850456, "compression_ratio": 1.71656050955414, "no_speech_prob": 0.0008166400366462767}, {"id": 202, "seek": 90924, "start": 924.6, "end": 928.88, "text": " a small perturbation to the velocity vector at each point in time. So now it's sort of", "tokens": [51132, 257, 1359, 40468, 399, 281, 264, 9269, 8062, 412, 1184, 935, 294, 565, 13, 407, 586, 309, 311, 1333, 295, 51346], "temperature": 0.0, "avg_logprob": -0.14284569469850456, "compression_ratio": 1.71656050955414, "no_speech_prob": 0.0008166400366462767}, {"id": 203, "seek": 90924, "start": 928.88, "end": 933.12, "text": " like in your simulation, when you're imagining where ball B would have gone, it sort of jiggles", "tokens": [51346, 411, 294, 428, 16575, 11, 562, 291, 434, 27798, 689, 2594, 363, 576, 362, 2780, 11, 309, 1333, 295, 361, 19469, 51558], "temperature": 0.0, "avg_logprob": -0.14284569469850456, "compression_ratio": 1.71656050955414, "no_speech_prob": 0.0008166400366462767}, {"id": 204, "seek": 90924, "start": 933.12, "end": 938.64, "text": " a little bit along the way. And so this might be now one outcome, like off such a sample.", "tokens": [51558, 257, 707, 857, 2051, 264, 636, 13, 400, 370, 341, 1062, 312, 586, 472, 9700, 11, 411, 766, 1270, 257, 6889, 13, 51834], "temperature": 0.0, "avg_logprob": -0.14284569469850456, "compression_ratio": 1.71656050955414, "no_speech_prob": 0.0008166400366462767}, {"id": 205, "seek": 93864, "start": 938.64, "end": 941.52, "text": " So if you think like, oh, oh, I think it would have missed. But let me try again. Like,", "tokens": [50364, 407, 498, 291, 519, 411, 11, 1954, 11, 1954, 11, 286, 519, 309, 576, 362, 6721, 13, 583, 718, 385, 853, 797, 13, 1743, 11, 50508], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 206, "seek": 93864, "start": 941.52, "end": 944.4399999999999, "text": " oh, yeah, I think it would have missed. Yeah, I'm pretty sure it would have missed. So this", "tokens": [50508, 1954, 11, 1338, 11, 286, 519, 309, 576, 362, 6721, 13, 865, 11, 286, 478, 1238, 988, 309, 576, 362, 6721, 13, 407, 341, 50654], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 207, "seek": 93864, "start": 944.4399999999999, "end": 947.4, "text": " is just multiple times sampling in your mind of what would have happened if ball A hadn't", "tokens": [50654, 307, 445, 3866, 1413, 21179, 294, 428, 1575, 295, 437, 576, 362, 2011, 498, 2594, 316, 8782, 380, 50802], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 208, "seek": 93864, "start": 947.4, "end": 950.84, "text": " been there. And here, since all of them, you're pretty sure that it would have missed, you", "tokens": [50802, 668, 456, 13, 400, 510, 11, 1670, 439, 295, 552, 11, 291, 434, 1238, 988, 300, 309, 576, 362, 6721, 11, 291, 50974], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 209, "seek": 93864, "start": 950.84, "end": 955.16, "text": " said, yeah, A caused it to go through. But you can probably already anticipate, we can", "tokens": [50974, 848, 11, 1338, 11, 316, 7008, 309, 281, 352, 807, 13, 583, 291, 393, 1391, 1217, 21685, 11, 321, 393, 51190], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 210, "seek": 93864, "start": 955.16, "end": 960.3199999999999, "text": " now do a slightly different case, right, where in the actual situation, again, still A collides", "tokens": [51190, 586, 360, 257, 4748, 819, 1389, 11, 558, 11, 689, 294, 264, 3539, 2590, 11, 797, 11, 920, 316, 1263, 1875, 51448], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 211, "seek": 93864, "start": 960.3199999999999, "end": 963.8, "text": " with B and B goes in. But this time it's sort of less clear what would have happened", "tokens": [51448, 365, 363, 293, 363, 1709, 294, 13, 583, 341, 565, 309, 311, 1333, 295, 1570, 1850, 437, 576, 362, 2011, 51622], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 212, "seek": 93864, "start": 963.8, "end": 967.6, "text": " if ball A hadn't been present in the scene. Because that ball B is headed like right to", "tokens": [51622, 498, 2594, 316, 8782, 380, 668, 1974, 294, 264, 4145, 13, 1436, 300, 2594, 363, 307, 12798, 411, 558, 281, 51812], "temperature": 0.0, "avg_logprob": -0.17673046030896775, "compression_ratio": 1.9944289693593316, "no_speech_prob": 0.0008674131240695715}, {"id": 213, "seek": 96760, "start": 967.64, "end": 972.12, "text": " the goal post, essentially. And now if you apply the same idea of simulating with noise", "tokens": [50366, 264, 3387, 2183, 11, 4476, 13, 400, 586, 498, 291, 3079, 264, 912, 1558, 295, 1034, 12162, 365, 5658, 50590], "temperature": 0.0, "avg_logprob": -0.15644502291714188, "compression_ratio": 1.7311475409836066, "no_speech_prob": 0.001263821148313582}, {"id": 214, "seek": 96760, "start": 972.12, "end": 976.0400000000001, "text": " what would have happened, you know, in some cases, maybe ball B would have missed. But", "tokens": [50590, 437, 576, 362, 2011, 11, 291, 458, 11, 294, 512, 3331, 11, 1310, 2594, 363, 576, 362, 6721, 13, 583, 50786], "temperature": 0.0, "avg_logprob": -0.15644502291714188, "compression_ratio": 1.7311475409836066, "no_speech_prob": 0.001263821148313582}, {"id": 215, "seek": 96760, "start": 976.0400000000001, "end": 980.0, "text": " it's also possible that ball B would have gone in anyhow, even if A hadn't been there.", "tokens": [50786, 309, 311, 611, 1944, 300, 2594, 363, 576, 362, 2780, 294, 44995, 11, 754, 498, 316, 8782, 380, 668, 456, 13, 50984], "temperature": 0.0, "avg_logprob": -0.15644502291714188, "compression_ratio": 1.7311475409836066, "no_speech_prob": 0.001263821148313582}, {"id": 216, "seek": 96760, "start": 980.0, "end": 983.5600000000001, "text": " And that accordingly, you might say like, yeah, I'm less sure, you know, that A caused", "tokens": [50984, 400, 300, 19717, 11, 291, 1062, 584, 411, 11, 1338, 11, 286, 478, 1570, 988, 11, 291, 458, 11, 300, 316, 7008, 51162], "temperature": 0.0, "avg_logprob": -0.15644502291714188, "compression_ratio": 1.7311475409836066, "no_speech_prob": 0.001263821148313582}, {"id": 217, "seek": 96760, "start": 983.5600000000001, "end": 988.4, "text": " ball B to go through the gate in this case. So that's what we did now in our experiment", "tokens": [51162, 2594, 363, 281, 352, 807, 264, 8539, 294, 341, 1389, 13, 407, 300, 311, 437, 321, 630, 586, 294, 527, 5120, 51404], "temperature": 0.0, "avg_logprob": -0.15644502291714188, "compression_ratio": 1.7311475409836066, "no_speech_prob": 0.001263821148313582}, {"id": 218, "seek": 96760, "start": 988.4, "end": 992.72, "text": " where we showed people a bunch of clips like this one. So here's just three different ones,", "tokens": [51404, 689, 321, 4712, 561, 257, 3840, 295, 13117, 411, 341, 472, 13, 407, 510, 311, 445, 1045, 819, 2306, 11, 51620], "temperature": 0.0, "avg_logprob": -0.15644502291714188, "compression_ratio": 1.7311475409836066, "no_speech_prob": 0.001263821148313582}, {"id": 219, "seek": 99272, "start": 992.96, "end": 999.12, "text": " one clip in which, you know, it's pretty clear here at the top that ball B would have missed", "tokens": [50376, 472, 7353, 294, 597, 11, 291, 458, 11, 309, 311, 1238, 1850, 510, 412, 264, 1192, 300, 2594, 363, 576, 362, 6721, 50684], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 220, "seek": 99272, "start": 999.12, "end": 1003.12, "text": " if ball A hadn't been there. The one in the middle is like one, this kind of close call.", "tokens": [50684, 498, 2594, 316, 8782, 380, 668, 456, 13, 440, 472, 294, 264, 2808, 307, 411, 472, 11, 341, 733, 295, 1998, 818, 13, 50884], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 221, "seek": 99272, "start": 1003.12, "end": 1006.4, "text": " And then the one on the right hand side is one in which it was pretty clear that ball", "tokens": [50884, 400, 550, 264, 472, 322, 264, 558, 1011, 1252, 307, 472, 294, 597, 309, 390, 1238, 1850, 300, 2594, 51048], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 222, "seek": 99272, "start": 1006.4, "end": 1010.88, "text": " B would have gone in anyhow, even if A hadn't been there. And then between experiments,", "tokens": [51048, 363, 576, 362, 2780, 294, 44995, 11, 754, 498, 316, 8782, 380, 668, 456, 13, 400, 550, 1296, 12050, 11, 51272], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 223, "seek": 99272, "start": 1010.88, "end": 1014.1600000000001, "text": " we either asked them some counterfactual question. So that's the one here at the bottom,", "tokens": [51272, 321, 2139, 2351, 552, 512, 5682, 44919, 901, 1168, 13, 407, 300, 311, 264, 472, 510, 412, 264, 2767, 11, 51436], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 224, "seek": 99272, "start": 1014.1600000000001, "end": 1017.76, "text": " the blue one. Do you think that ball B would have missed if ball A hadn't been there?", "tokens": [51436, 264, 3344, 472, 13, 1144, 291, 519, 300, 2594, 363, 576, 362, 6721, 498, 2594, 316, 8782, 380, 668, 456, 30, 51616], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 225, "seek": 99272, "start": 1018.4, "end": 1022.1600000000001, "text": " And then we see that in this case, they're pretty sure, yeah, I think it would have missed.", "tokens": [51648, 400, 550, 321, 536, 300, 294, 341, 1389, 11, 436, 434, 1238, 988, 11, 1338, 11, 286, 519, 309, 576, 362, 6721, 13, 51836], "temperature": 0.0, "avg_logprob": -0.09725139780742366, "compression_ratio": 2.0664451827242525, "no_speech_prob": 0.001150463125668466}, {"id": 226, "seek": 102216, "start": 1022.16, "end": 1026.1599999999999, "text": " Here, they're right at the midpoint of the scale, not sure, right, whether it would have", "tokens": [50364, 1692, 11, 436, 434, 558, 412, 264, 2062, 6053, 295, 264, 4373, 11, 406, 988, 11, 558, 11, 1968, 309, 576, 362, 50564], "temperature": 0.0, "avg_logprob": -0.08859359714346872, "compression_ratio": 1.7911392405063291, "no_speech_prob": 8.877825166564435e-05}, {"id": 227, "seek": 102216, "start": 1026.1599999999999, "end": 1031.6, "text": " missed or not. So we give them some slider where they can just evaluate their degree of belief.", "tokens": [50564, 6721, 420, 406, 13, 407, 321, 976, 552, 512, 26046, 689, 436, 393, 445, 13059, 641, 4314, 295, 7107, 13, 50836], "temperature": 0.0, "avg_logprob": -0.08859359714346872, "compression_ratio": 1.7911392405063291, "no_speech_prob": 8.877825166564435e-05}, {"id": 228, "seek": 102216, "start": 1031.6, "end": 1037.36, "text": " And then in this case, they're pretty sure that it would not have missed, even if ball A hadn't", "tokens": [50836, 400, 550, 294, 341, 1389, 11, 436, 434, 1238, 988, 300, 309, 576, 406, 362, 6721, 11, 754, 498, 2594, 316, 8782, 380, 51124], "temperature": 0.0, "avg_logprob": -0.08859359714346872, "compression_ratio": 1.7911392405063291, "no_speech_prob": 8.877825166564435e-05}, {"id": 229, "seek": 102216, "start": 1037.36, "end": 1042.48, "text": " been there. And then we take a separate group of participants and we ask them a causal question.", "tokens": [51124, 668, 456, 13, 400, 550, 321, 747, 257, 4994, 1594, 295, 10503, 293, 321, 1029, 552, 257, 38755, 1168, 13, 51380], "temperature": 0.0, "avg_logprob": -0.08859359714346872, "compression_ratio": 1.7911392405063291, "no_speech_prob": 8.877825166564435e-05}, {"id": 230, "seek": 102216, "start": 1042.48, "end": 1046.24, "text": " So those participants don't hear anything about counterfactuals. We just asked them in a clip", "tokens": [51380, 407, 729, 10503, 500, 380, 1568, 1340, 466, 5682, 44919, 901, 82, 13, 492, 445, 2351, 552, 294, 257, 7353, 51568], "temperature": 0.0, "avg_logprob": -0.08859359714346872, "compression_ratio": 1.7911392405063291, "no_speech_prob": 8.877825166564435e-05}, {"id": 231, "seek": 102216, "start": 1046.24, "end": 1050.72, "text": " like that, what do you think that ball A caused ball B to go through the gate? And we see that", "tokens": [51568, 411, 300, 11, 437, 360, 291, 519, 300, 2594, 316, 7008, 2594, 363, 281, 352, 807, 264, 8539, 30, 400, 321, 536, 300, 51792], "temperature": 0.0, "avg_logprob": -0.08859359714346872, "compression_ratio": 1.7911392405063291, "no_speech_prob": 8.877825166564435e-05}, {"id": 232, "seek": 105072, "start": 1051.1200000000001, "end": 1056.48, "text": " judgments align very closely with those of the ones in the counterfactual question condition.", "tokens": [50384, 40337, 7975, 588, 8185, 365, 729, 295, 264, 2306, 294, 264, 5682, 44919, 901, 1168, 4188, 13, 50652], "temperature": 0.0, "avg_logprob": -0.11472246580034773, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.222287654760294e-05}, {"id": 233, "seek": 105072, "start": 1057.6000000000001, "end": 1061.52, "text": " And we can also use that model that I described that draws these samples and tries to simulate", "tokens": [50708, 400, 321, 393, 611, 764, 300, 2316, 300, 286, 7619, 300, 20045, 613, 10938, 293, 9898, 281, 27817, 50904], "temperature": 0.0, "avg_logprob": -0.11472246580034773, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.222287654760294e-05}, {"id": 234, "seek": 105072, "start": 1061.52, "end": 1066.4, "text": " what would have happened. And it also yields very similar judgments in this, or makes predictions", "tokens": [50904, 437, 576, 362, 2011, 13, 400, 309, 611, 32168, 588, 2531, 40337, 294, 341, 11, 420, 1669, 21264, 51148], "temperature": 0.0, "avg_logprob": -0.11472246580034773, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.222287654760294e-05}, {"id": 235, "seek": 105072, "start": 1066.4, "end": 1071.3600000000001, "text": " in this case. These were just three of the video clips. We had like 18 different clips in that", "tokens": [51148, 294, 341, 1389, 13, 1981, 645, 445, 1045, 295, 264, 960, 13117, 13, 492, 632, 411, 2443, 819, 13117, 294, 300, 51396], "temperature": 0.0, "avg_logprob": -0.11472246580034773, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.222287654760294e-05}, {"id": 236, "seek": 105072, "start": 1071.3600000000001, "end": 1076.08, "text": " experiment. And if we just line up here on the x-axis, the average counterfactual judgments", "tokens": [51396, 5120, 13, 400, 498, 321, 445, 1622, 493, 510, 322, 264, 2031, 12, 24633, 11, 264, 4274, 5682, 44919, 901, 40337, 51632], "temperature": 0.0, "avg_logprob": -0.11472246580034773, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.222287654760294e-05}, {"id": 237, "seek": 107608, "start": 1076.1599999999999, "end": 1080.8799999999999, "text": " that participants made, and on the y-axis, the average causal ratings that participants gave,", "tokens": [50368, 300, 10503, 1027, 11, 293, 322, 264, 288, 12, 24633, 11, 264, 4274, 38755, 24603, 300, 10503, 2729, 11, 50604], "temperature": 0.0, "avg_logprob": -0.09969552858607976, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0014545208541676402}, {"id": 238, "seek": 107608, "start": 1080.8799999999999, "end": 1084.8, "text": " you see that they're very closely aligned with one another, at least suggesting a strong", "tokens": [50604, 291, 536, 300, 436, 434, 588, 8185, 17962, 365, 472, 1071, 11, 412, 1935, 18094, 257, 2068, 50800], "temperature": 0.0, "avg_logprob": -0.09969552858607976, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0014545208541676402}, {"id": 239, "seek": 107608, "start": 1084.8, "end": 1090.72, "text": " relationship between these kinds of judgments. But when we published this work as a coxide paper,", "tokens": [50800, 2480, 1296, 613, 3685, 295, 40337, 13, 583, 562, 321, 6572, 341, 589, 382, 257, 598, 87, 482, 3035, 11, 51096], "temperature": 0.0, "avg_logprob": -0.09969552858607976, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0014545208541676402}, {"id": 240, "seek": 107608, "start": 1090.72, "end": 1095.28, "text": " so for the cognitive science proceedings, one of the reviewers, they were mostly happy with it,", "tokens": [51096, 370, 337, 264, 15605, 3497, 37254, 11, 472, 295, 264, 45837, 11, 436, 645, 5240, 2055, 365, 309, 11, 51324], "temperature": 0.0, "avg_logprob": -0.09969552858607976, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0014545208541676402}, {"id": 241, "seek": 107608, "start": 1095.28, "end": 1098.8799999999999, "text": " but one of the reviewers was saying, yeah, but all of the clips that you showed participants,", "tokens": [51324, 457, 472, 295, 264, 45837, 390, 1566, 11, 1338, 11, 457, 439, 295, 264, 13117, 300, 291, 4712, 10503, 11, 51504], "temperature": 0.0, "avg_logprob": -0.09969552858607976, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0014545208541676402}, {"id": 242, "seek": 107608, "start": 1098.8799999999999, "end": 1102.8799999999999, "text": " something slightly different was going on. So maybe you just didn't try hard enough to come", "tokens": [51504, 746, 4748, 819, 390, 516, 322, 13, 407, 1310, 291, 445, 994, 380, 853, 1152, 1547, 281, 808, 51704], "temperature": 0.0, "avg_logprob": -0.09969552858607976, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.0014545208541676402}, {"id": 243, "seek": 110288, "start": 1102.88, "end": 1106.8000000000002, "text": " up with an actualistic count, like one that only looks at what actually happened. And if you", "tokens": [50364, 493, 365, 364, 3539, 3142, 1207, 11, 411, 472, 300, 787, 1542, 412, 437, 767, 2011, 13, 400, 498, 291, 50560], "temperature": 0.0, "avg_logprob": -0.09888079883606453, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0003004693135153502}, {"id": 244, "seek": 110288, "start": 1106.8000000000002, "end": 1114.24, "text": " tried a little bit harder, then you could have explained it away. So we did try, and we didn't", "tokens": [50560, 3031, 257, 707, 857, 6081, 11, 550, 291, 727, 362, 8825, 309, 1314, 13, 407, 321, 630, 853, 11, 293, 321, 994, 380, 50932], "temperature": 0.0, "avg_logprob": -0.09888079883606453, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0003004693135153502}, {"id": 245, "seek": 110288, "start": 1114.24, "end": 1118.16, "text": " succeed, but it's also sort of a weird position that you're in when you kind of don't want to", "tokens": [50932, 7754, 11, 457, 309, 311, 611, 1333, 295, 257, 3657, 2535, 300, 291, 434, 294, 562, 291, 733, 295, 500, 380, 528, 281, 51128], "temperature": 0.0, "avg_logprob": -0.09888079883606453, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0003004693135153502}, {"id": 246, "seek": 110288, "start": 1118.16, "end": 1123.8400000000001, "text": " succeed, right? So we thought, okay, maybe the better thing, rather than being crappy at modeling,", "tokens": [51128, 7754, 11, 558, 30, 407, 321, 1194, 11, 1392, 11, 1310, 264, 1101, 551, 11, 2831, 813, 885, 36531, 412, 15983, 11, 51412], "temperature": 0.0, "avg_logprob": -0.09888079883606453, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0003004693135153502}, {"id": 247, "seek": 110288, "start": 1124.48, "end": 1128.0800000000002, "text": " you know, just let's come up with an experiment where it feels like if it comes up in the way that", "tokens": [51444, 291, 458, 11, 445, 718, 311, 808, 493, 365, 364, 5120, 689, 309, 3417, 411, 498, 309, 1487, 493, 294, 264, 636, 300, 51624], "temperature": 0.0, "avg_logprob": -0.09888079883606453, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0003004693135153502}, {"id": 248, "seek": 112808, "start": 1128.08, "end": 1133.04, "text": " we think it will, there's no way you could possibly explain it with an actualistic count.", "tokens": [50364, 321, 519, 309, 486, 11, 456, 311, 572, 636, 291, 727, 6264, 2903, 309, 365, 364, 3539, 3142, 1207, 13, 50612], "temperature": 0.0, "avg_logprob": -0.11257989829945787, "compression_ratio": 1.6200716845878136, "no_speech_prob": 0.00019958792836405337}, {"id": 249, "seek": 112808, "start": 1133.04, "end": 1136.96, "text": " And so that's the route we took. So just to really think like, oh, are these counterfactors", "tokens": [50612, 400, 370, 300, 311, 264, 7955, 321, 1890, 13, 407, 445, 281, 534, 519, 411, 11, 1954, 11, 366, 613, 5682, 44919, 830, 50808], "temperature": 0.0, "avg_logprob": -0.11257989829945787, "compression_ratio": 1.6200716845878136, "no_speech_prob": 0.00019958792836405337}, {"id": 250, "seek": 112808, "start": 1136.96, "end": 1141.6, "text": " really necessary for understanding causal judgments? So second round of audience participation,", "tokens": [50808, 534, 4818, 337, 3701, 38755, 40337, 30, 407, 1150, 3098, 295, 4034, 13487, 11, 51040], "temperature": 0.0, "avg_logprob": -0.11257989829945787, "compression_ratio": 1.6200716845878136, "no_speech_prob": 0.00019958792836405337}, {"id": 251, "seek": 112808, "start": 1141.6, "end": 1145.36, "text": " get ready. I'm just going to show you a slightly different clip, and this time I'm going to ask", "tokens": [51040, 483, 1919, 13, 286, 478, 445, 516, 281, 855, 291, 257, 4748, 819, 7353, 11, 293, 341, 565, 286, 478, 516, 281, 1029, 51228], "temperature": 0.0, "avg_logprob": -0.11257989829945787, "compression_ratio": 1.6200716845878136, "no_speech_prob": 0.00019958792836405337}, {"id": 252, "seek": 112808, "start": 1145.36, "end": 1148.24, "text": " you whether you think that ball A prevented Bobby from going through the gate.", "tokens": [51228, 291, 1968, 291, 519, 300, 2594, 316, 27314, 19573, 490, 516, 807, 264, 8539, 13, 51372], "temperature": 0.0, "avg_logprob": -0.11257989829945787, "compression_ratio": 1.6200716845878136, "no_speech_prob": 0.00019958792836405337}, {"id": 253, "seek": 114824, "start": 1148.24, "end": 1160.88, "text": " Okay, what do you think? If you think that ball A prevented Bobby from going through", "tokens": [50364, 1033, 11, 437, 360, 291, 519, 30, 759, 291, 519, 300, 2594, 316, 27314, 19573, 490, 516, 807, 50996], "temperature": 0.0, "avg_logprob": -0.18165090560913086, "compression_ratio": 1.3507462686567164, "no_speech_prob": 0.0005439852247945964}, {"id": 254, "seek": 114824, "start": 1160.88, "end": 1168.96, "text": " the gate, you can raise your hand. Okay, a few people think so in this case. Okay, I'll show you", "tokens": [50996, 264, 8539, 11, 291, 393, 5300, 428, 1011, 13, 1033, 11, 257, 1326, 561, 519, 370, 294, 341, 1389, 13, 1033, 11, 286, 603, 855, 291, 51400], "temperature": 0.0, "avg_logprob": -0.18165090560913086, "compression_ratio": 1.3507462686567164, "no_speech_prob": 0.0005439852247945964}, {"id": 255, "seek": 116896, "start": 1168.96, "end": 1178.64, "text": " another one. Okay, this was not some kind of, you know, glitch. I was having fun, you know,", "tokens": [50364, 1071, 472, 13, 1033, 11, 341, 390, 406, 512, 733, 295, 11, 291, 458, 11, 23552, 13, 286, 390, 1419, 1019, 11, 291, 458, 11, 50848], "temperature": 0.0, "avg_logprob": -0.1119313778415803, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.004826609045267105}, {"id": 256, "seek": 116896, "start": 1178.64, "end": 1183.6000000000001, "text": " doing the physics engine and sort of playing portal, right, by turning these things into a", "tokens": [50848, 884, 264, 10649, 2848, 293, 1333, 295, 2433, 14982, 11, 558, 11, 538, 6246, 613, 721, 666, 257, 51096], "temperature": 0.0, "avg_logprob": -0.1119313778415803, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.004826609045267105}, {"id": 257, "seek": 116896, "start": 1183.6000000000001, "end": 1186.64, "text": " Taylor port, right? And I didn't tell you anything about them, of course, when I showed you the", "tokens": [51096, 12060, 2436, 11, 558, 30, 400, 286, 994, 380, 980, 291, 1340, 466, 552, 11, 295, 1164, 11, 562, 286, 4712, 291, 264, 51248], "temperature": 0.0, "avg_logprob": -0.1119313778415803, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.004826609045267105}, {"id": 258, "seek": 116896, "start": 1186.64, "end": 1190.8, "text": " first clip, but maybe just seeing that one clip, you already have like one shot learning, yeah,", "tokens": [51248, 700, 7353, 11, 457, 1310, 445, 2577, 300, 472, 7353, 11, 291, 1217, 362, 411, 472, 3347, 2539, 11, 1338, 11, 51456], "temperature": 0.0, "avg_logprob": -0.1119313778415803, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.004826609045267105}, {"id": 259, "seek": 116896, "start": 1190.8, "end": 1195.2, "text": " okay, maybe that's a Taylor port. And the Taylor port, it works only for ball B, you know, it", "tokens": [51456, 1392, 11, 1310, 300, 311, 257, 12060, 2436, 13, 400, 264, 12060, 2436, 11, 309, 1985, 787, 337, 2594, 363, 11, 291, 458, 11, 309, 51676], "temperature": 0.0, "avg_logprob": -0.1119313778415803, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.004826609045267105}, {"id": 260, "seek": 119520, "start": 1195.28, "end": 1199.28, "text": " doesn't work for ball A, and the yellow thing is the entry of the Taylor port, and the blue", "tokens": [50368, 1177, 380, 589, 337, 2594, 316, 11, 293, 264, 5566, 551, 307, 264, 8729, 295, 264, 12060, 2436, 11, 293, 264, 3344, 50568], "temperature": 0.0, "avg_logprob": -0.0819863878447434, "compression_ratio": 1.8594249201277955, "no_speech_prob": 0.001754070515744388}, {"id": 261, "seek": 119520, "start": 1199.28, "end": 1204.64, "text": " thing is the exit of the Taylor port. And now that I've shown you that, if I now show you exactly", "tokens": [50568, 551, 307, 264, 11043, 295, 264, 12060, 2436, 13, 400, 586, 300, 286, 600, 4898, 291, 300, 11, 498, 286, 586, 855, 291, 2293, 50836], "temperature": 0.0, "avg_logprob": -0.0819863878447434, "compression_ratio": 1.8594249201277955, "no_speech_prob": 0.001754070515744388}, {"id": 262, "seek": 119520, "start": 1204.64, "end": 1209.68, "text": " the same clip again, you're going to say, at least if you're like my participants, yes, it prevented", "tokens": [50836, 264, 912, 7353, 797, 11, 291, 434, 516, 281, 584, 11, 412, 1935, 498, 291, 434, 411, 452, 10503, 11, 2086, 11, 309, 27314, 51088], "temperature": 0.0, "avg_logprob": -0.0819863878447434, "compression_ratio": 1.8594249201277955, "no_speech_prob": 0.001754070515744388}, {"id": 263, "seek": 119520, "start": 1209.68, "end": 1213.76, "text": " it from going through, right? Because now what changed is basically your belief about how the", "tokens": [51088, 309, 490, 516, 807, 11, 558, 30, 1436, 586, 437, 3105, 307, 1936, 428, 7107, 466, 577, 264, 51292], "temperature": 0.0, "avg_logprob": -0.0819863878447434, "compression_ratio": 1.8594249201277955, "no_speech_prob": 0.001754070515744388}, {"id": 264, "seek": 119520, "start": 1213.76, "end": 1217.76, "text": " world works, such that your counterfactual looks a little bit more like that now, right? What would", "tokens": [51292, 1002, 1985, 11, 1270, 300, 428, 5682, 44919, 901, 1542, 257, 707, 857, 544, 411, 300, 586, 11, 558, 30, 708, 576, 51492], "temperature": 0.0, "avg_logprob": -0.0819863878447434, "compression_ratio": 1.8594249201277955, "no_speech_prob": 0.001754070515744388}, {"id": 265, "seek": 119520, "start": 1217.76, "end": 1221.68, "text": " have happened is that it would have gone through the Taylor port and into the goal, right? So the", "tokens": [51492, 362, 2011, 307, 300, 309, 576, 362, 2780, 807, 264, 12060, 2436, 293, 666, 264, 3387, 11, 558, 30, 407, 264, 51688], "temperature": 0.0, "avg_logprob": -0.0819863878447434, "compression_ratio": 1.8594249201277955, "no_speech_prob": 0.001754070515744388}, {"id": 266, "seek": 122168, "start": 1221.68, "end": 1226.88, "text": " fact that I can show you exactly the same clip twice, right? And, and all I've changed was your", "tokens": [50364, 1186, 300, 286, 393, 855, 291, 2293, 264, 912, 7353, 6091, 11, 558, 30, 400, 11, 293, 439, 286, 600, 3105, 390, 428, 50624], "temperature": 0.0, "avg_logprob": -0.08492102446379485, "compression_ratio": 1.9292929292929293, "no_speech_prob": 0.0004105937550775707}, {"id": 267, "seek": 122168, "start": 1226.88, "end": 1231.04, "text": " belief about how the world works. And that makes a big difference to your causal judgment, sort of", "tokens": [50624, 7107, 466, 577, 264, 1002, 1985, 13, 400, 300, 1669, 257, 955, 2649, 281, 428, 38755, 12216, 11, 1333, 295, 50832], "temperature": 0.0, "avg_logprob": -0.08492102446379485, "compression_ratio": 1.9292929292929293, "no_speech_prob": 0.0004105937550775707}, {"id": 268, "seek": 122168, "start": 1231.04, "end": 1236.48, "text": " shows that it's, it cannot be sufficient to explain causal judgments just in terms of what", "tokens": [50832, 3110, 300, 309, 311, 11, 309, 2644, 312, 11563, 281, 2903, 38755, 40337, 445, 294, 2115, 295, 437, 51104], "temperature": 0.0, "avg_logprob": -0.08492102446379485, "compression_ratio": 1.9292929292929293, "no_speech_prob": 0.0004105937550775707}, {"id": 269, "seek": 122168, "start": 1236.48, "end": 1240.48, "text": " actually happened, because actually what actually happened was exactly the same in both of the", "tokens": [51104, 767, 2011, 11, 570, 767, 437, 767, 2011, 390, 2293, 264, 912, 294, 1293, 295, 264, 51304], "temperature": 0.0, "avg_logprob": -0.08492102446379485, "compression_ratio": 1.9292929292929293, "no_speech_prob": 0.0004105937550775707}, {"id": 270, "seek": 122168, "start": 1240.48, "end": 1245.04, "text": " times that I showed you the clip. I don't need to do the Taylor port thing. The Taylor port thing", "tokens": [51304, 1413, 300, 286, 4712, 291, 264, 7353, 13, 286, 500, 380, 643, 281, 360, 264, 12060, 2436, 551, 13, 440, 12060, 2436, 551, 51532], "temperature": 0.0, "avg_logprob": -0.08492102446379485, "compression_ratio": 1.9292929292929293, "no_speech_prob": 0.0004105937550775707}, {"id": 271, "seek": 122168, "start": 1245.04, "end": 1249.04, "text": " is cute because I can show you exactly the same clip, but I can also move some obstacle in and", "tokens": [51532, 307, 4052, 570, 286, 393, 855, 291, 2293, 264, 912, 7353, 11, 457, 286, 393, 611, 1286, 512, 23112, 294, 293, 51732], "temperature": 0.0, "avg_logprob": -0.08492102446379485, "compression_ratio": 1.9292929292929293, "no_speech_prob": 0.0004105937550775707}, {"id": 272, "seek": 124904, "start": 1249.04, "end": 1253.6, "text": " out of the way, right here on the left hand side, you're not going to say that A prevented B from", "tokens": [50364, 484, 295, 264, 636, 11, 558, 510, 322, 264, 1411, 1011, 1252, 11, 291, 434, 406, 516, 281, 584, 300, 316, 27314, 363, 490, 50592], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 273, "seek": 124904, "start": 1253.6, "end": 1258.0, "text": " going through the gate. On the right hand side, you are because the block is out of the way, right?", "tokens": [50592, 516, 807, 264, 8539, 13, 1282, 264, 558, 1011, 1252, 11, 291, 366, 570, 264, 3461, 307, 484, 295, 264, 636, 11, 558, 30, 50812], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 274, "seek": 124904, "start": 1258.0, "end": 1262.24, "text": " And a similar way for causation. And on the left hand side, you're going to say, yeah, A caused it", "tokens": [50812, 400, 257, 2531, 636, 337, 3302, 399, 13, 400, 322, 264, 1411, 1011, 1252, 11, 291, 434, 516, 281, 584, 11, 1338, 11, 316, 7008, 309, 51024], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 275, "seek": 124904, "start": 1262.24, "end": 1266.24, "text": " because the block would have blocked it. And on the right hand side, you're not really going to say", "tokens": [51024, 570, 264, 3461, 576, 362, 15470, 309, 13, 400, 322, 264, 558, 1011, 1252, 11, 291, 434, 406, 534, 516, 281, 584, 51224], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 276, "seek": 124904, "start": 1266.24, "end": 1270.8, "text": " that it caused it because it would have gone in anyhow, right? Same idea. I'm doing exactly the", "tokens": [51224, 300, 309, 7008, 309, 570, 309, 576, 362, 2780, 294, 44995, 11, 558, 30, 10635, 1558, 13, 286, 478, 884, 2293, 264, 51452], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 277, "seek": 124904, "start": 1270.8, "end": 1274.32, "text": " same interactions between the balls. I'm just changing something kind of in the background", "tokens": [51452, 912, 13280, 1296, 264, 9803, 13, 286, 478, 445, 4473, 746, 733, 295, 294, 264, 3678, 51628], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 278, "seek": 124904, "start": 1274.32, "end": 1278.3999999999999, "text": " that affects the counterfactual and, and thereby also affects people's causal judgments.", "tokens": [51628, 300, 11807, 264, 5682, 44919, 901, 293, 11, 293, 28281, 611, 11807, 561, 311, 38755, 40337, 13, 51832], "temperature": 0.0, "avg_logprob": -0.10554518182593656, "compression_ratio": 2.1065830721003134, "no_speech_prob": 0.0035907833371311426}, {"id": 279, "seek": 127904, "start": 1280.0, "end": 1286.08, "text": " Okay. So another thing that's sort of neat about this model is that it doesn't only kind of predict", "tokens": [50412, 1033, 13, 407, 1071, 551, 300, 311, 1333, 295, 10654, 466, 341, 2316, 307, 300, 309, 1177, 380, 787, 733, 295, 6069, 50716], "temperature": 0.0, "avg_logprob": -0.09989561990042713, "compression_ratio": 1.7463235294117647, "no_speech_prob": 4.908057599095628e-05}, {"id": 280, "seek": 127904, "start": 1286.08, "end": 1290.8799999999999, "text": " basically the judgment that people should give at the end of it, but also says something about", "tokens": [50716, 1936, 264, 12216, 300, 561, 820, 976, 412, 264, 917, 295, 309, 11, 457, 611, 1619, 746, 466, 50956], "temperature": 0.0, "avg_logprob": -0.09989561990042713, "compression_ratio": 1.7463235294117647, "no_speech_prob": 4.908057599095628e-05}, {"id": 281, "seek": 127904, "start": 1290.8799999999999, "end": 1295.68, "text": " the cognitive process by which they arrive at the judgment, right? In this case is maybe this", "tokens": [50956, 264, 15605, 1399, 538, 597, 436, 8881, 412, 264, 12216, 11, 558, 30, 682, 341, 1389, 307, 1310, 341, 51196], "temperature": 0.0, "avg_logprob": -0.09989561990042713, "compression_ratio": 1.7463235294117647, "no_speech_prob": 4.908057599095628e-05}, {"id": 282, "seek": 127904, "start": 1295.68, "end": 1299.68, "text": " process of mental simulation, that you kind of generating these samples and thinking about what", "tokens": [51196, 1399, 295, 4973, 16575, 11, 300, 291, 733, 295, 17746, 613, 10938, 293, 1953, 466, 437, 51396], "temperature": 0.0, "avg_logprob": -0.09989561990042713, "compression_ratio": 1.7463235294117647, "no_speech_prob": 4.908057599095628e-05}, {"id": 283, "seek": 127904, "start": 1299.68, "end": 1305.52, "text": " would have happened, and that those drive the causal judgment. And one way we can do that,", "tokens": [51396, 576, 362, 2011, 11, 293, 300, 729, 3332, 264, 38755, 12216, 13, 400, 472, 636, 321, 393, 360, 300, 11, 51688], "temperature": 0.0, "avg_logprob": -0.09989561990042713, "compression_ratio": 1.7463235294117647, "no_speech_prob": 4.908057599095628e-05}, {"id": 284, "seek": 130552, "start": 1305.6, "end": 1309.36, "text": " or can sort of get more direct evidence on that is to use eye tracking, right? To see, okay,", "tokens": [50368, 420, 393, 1333, 295, 483, 544, 2047, 4467, 322, 300, 307, 281, 764, 3313, 11603, 11, 558, 30, 1407, 536, 11, 1392, 11, 50556], "temperature": 0.0, "avg_logprob": -0.10736452831941493, "compression_ratio": 1.8280254777070064, "no_speech_prob": 0.0013227061135694385}, {"id": 285, "seek": 130552, "start": 1309.36, "end": 1312.8799999999999, "text": " where is it that you're looking at when you're asked to make causal judgments in these kinds", "tokens": [50556, 689, 307, 309, 300, 291, 434, 1237, 412, 562, 291, 434, 2351, 281, 652, 38755, 40337, 294, 613, 3685, 50732], "temperature": 0.0, "avg_logprob": -0.10736452831941493, "compression_ratio": 1.8280254777070064, "no_speech_prob": 0.0013227061135694385}, {"id": 286, "seek": 130552, "start": 1312.8799999999999, "end": 1318.8799999999999, "text": " of video clips. So we went back to the really simple ones again. And now also between experiments,", "tokens": [50732, 295, 960, 13117, 13, 407, 321, 1437, 646, 281, 264, 534, 2199, 2306, 797, 13, 400, 586, 611, 1296, 12050, 11, 51032], "temperature": 0.0, "avg_logprob": -0.10736452831941493, "compression_ratio": 1.8280254777070064, "no_speech_prob": 0.0013227061135694385}, {"id": 287, "seek": 130552, "start": 1318.8799999999999, "end": 1323.44, "text": " just ask participants a different question about the video that, that, that they would see. And", "tokens": [51032, 445, 1029, 10503, 257, 819, 1168, 466, 264, 960, 300, 11, 300, 11, 300, 436, 576, 536, 13, 400, 51260], "temperature": 0.0, "avg_logprob": -0.10736452831941493, "compression_ratio": 1.8280254777070064, "no_speech_prob": 0.0013227061135694385}, {"id": 288, "seek": 130552, "start": 1323.44, "end": 1327.12, "text": " they knew at the beginning what question they would be asked. So we had one condition here that", "tokens": [51260, 436, 2586, 412, 264, 2863, 437, 1168, 436, 576, 312, 2351, 13, 407, 321, 632, 472, 4188, 510, 300, 51444], "temperature": 0.0, "avg_logprob": -0.10736452831941493, "compression_ratio": 1.8280254777070064, "no_speech_prob": 0.0013227061135694385}, {"id": 289, "seek": 130552, "start": 1327.12, "end": 1330.8799999999999, "text": " we call the outcome condition where they'd watch the video and we would just ask them at the end,", "tokens": [51444, 321, 818, 264, 9700, 4188, 689, 436, 1116, 1159, 264, 960, 293, 321, 576, 445, 1029, 552, 412, 264, 917, 11, 51632], "temperature": 0.0, "avg_logprob": -0.10736452831941493, "compression_ratio": 1.8280254777070064, "no_speech_prob": 0.0013227061135694385}, {"id": 290, "seek": 133088, "start": 1330.96, "end": 1335.7600000000002, "text": " in this case, if it ended up missing, did be completely miss the gate. And so I'll show you", "tokens": [50368, 294, 341, 1389, 11, 498, 309, 4590, 493, 5361, 11, 630, 312, 2584, 1713, 264, 8539, 13, 400, 370, 286, 603, 855, 291, 50608], "temperature": 0.0, "avg_logprob": -0.12990235888268337, "compression_ratio": 1.7527675276752768, "no_speech_prob": 0.000188081365195103}, {"id": 291, "seek": 133088, "start": 1335.7600000000002, "end": 1339.2, "text": " the eye movements of one of the participants in this condition. And I'm going to play the", "tokens": [50608, 264, 3313, 9981, 295, 472, 295, 264, 10503, 294, 341, 4188, 13, 400, 286, 478, 516, 281, 862, 264, 50780], "temperature": 0.0, "avg_logprob": -0.12990235888268337, "compression_ratio": 1.7527675276752768, "no_speech_prob": 0.000188081365195103}, {"id": 292, "seek": 133088, "start": 1339.2, "end": 1344.96, "text": " video at half speed and I'll do some sort of life narration as it unfolds. So the blue dot is the", "tokens": [50780, 960, 412, 1922, 3073, 293, 286, 603, 360, 512, 1333, 295, 993, 43299, 382, 309, 17980, 82, 13, 407, 264, 3344, 5893, 307, 264, 51068], "temperature": 0.0, "avg_logprob": -0.12990235888268337, "compression_ratio": 1.7527675276752768, "no_speech_prob": 0.000188081365195103}, {"id": 293, "seek": 133088, "start": 1344.96, "end": 1348.8000000000002, "text": " eye movement, right? So the participant here is looking back and forth between ball A and ball B.", "tokens": [51068, 3313, 3963, 11, 558, 30, 407, 264, 24950, 510, 307, 1237, 646, 293, 5220, 1296, 2594, 316, 293, 2594, 363, 13, 51260], "temperature": 0.0, "avg_logprob": -0.12990235888268337, "compression_ratio": 1.7527675276752768, "no_speech_prob": 0.000188081365195103}, {"id": 294, "seek": 133088, "start": 1349.7600000000002, "end": 1354.88, "text": " So looking, looking at ball B, sort of now trying to extrapolate where ball B will end up hitting", "tokens": [51308, 407, 1237, 11, 1237, 412, 2594, 363, 11, 1333, 295, 586, 1382, 281, 48224, 473, 689, 2594, 363, 486, 917, 493, 8850, 51564], "temperature": 0.0, "avg_logprob": -0.12990235888268337, "compression_ratio": 1.7527675276752768, "no_speech_prob": 0.000188081365195103}, {"id": 295, "seek": 135488, "start": 1354.88, "end": 1363.6000000000001, "text": " the wall. And then mostly looking at ball B. Not very exciting, but also that's all they need to", "tokens": [50364, 264, 2929, 13, 400, 550, 5240, 1237, 412, 2594, 363, 13, 1726, 588, 4670, 11, 457, 611, 300, 311, 439, 436, 643, 281, 50800], "temperature": 0.0, "avg_logprob": -0.09942815984998431, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.000268833915470168}, {"id": 296, "seek": 135488, "start": 1363.6000000000001, "end": 1368.5600000000002, "text": " know in order to answer this question in this case. So now if you take a different participant", "tokens": [50800, 458, 294, 1668, 281, 1867, 341, 1168, 294, 341, 1389, 13, 407, 586, 498, 291, 747, 257, 819, 24950, 51048], "temperature": 0.0, "avg_logprob": -0.09942815984998431, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.000268833915470168}, {"id": 297, "seek": 135488, "start": 1369.1200000000001, "end": 1374.3200000000002, "text": " who was asked to make a causal question, or asked to answer a causal question in the video,", "tokens": [51076, 567, 390, 2351, 281, 652, 257, 38755, 1168, 11, 420, 2351, 281, 1867, 257, 38755, 1168, 294, 264, 960, 11, 51336], "temperature": 0.0, "avg_logprob": -0.09942815984998431, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.000268833915470168}, {"id": 298, "seek": 135488, "start": 1374.3200000000002, "end": 1378.48, "text": " but otherwise saw exactly the same video clips as other participants did, you're going to see that", "tokens": [51336, 457, 5911, 1866, 2293, 264, 912, 960, 13117, 382, 661, 10503, 630, 11, 291, 434, 516, 281, 536, 300, 51544], "temperature": 0.0, "avg_logprob": -0.09942815984998431, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.000268833915470168}, {"id": 299, "seek": 135488, "start": 1378.48, "end": 1381.92, "text": " the eye movements look quite different. And they look different in a way that made me very happy", "tokens": [51544, 264, 3313, 9981, 574, 1596, 819, 13, 400, 436, 574, 819, 294, 257, 636, 300, 1027, 385, 588, 2055, 51716], "temperature": 0.0, "avg_logprob": -0.09942815984998431, "compression_ratio": 1.8143939393939394, "no_speech_prob": 0.000268833915470168}, {"id": 300, "seek": 138192, "start": 1381.92, "end": 1387.76, "text": " at the time. So you see they're not just looking at ball B, they're trying to anticipate where", "tokens": [50364, 412, 264, 565, 13, 407, 291, 536, 436, 434, 406, 445, 1237, 412, 2594, 363, 11, 436, 434, 1382, 281, 21685, 689, 50656], "temperature": 0.0, "avg_logprob": -0.0989107864581986, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.0017513252096250653}, {"id": 301, "seek": 138192, "start": 1387.76, "end": 1392.8000000000002, "text": " ball B would have gone, you know, if ball A wasn't present in the scene. And it's quite likely that", "tokens": [50656, 2594, 363, 576, 362, 2780, 11, 291, 458, 11, 498, 2594, 316, 2067, 380, 1974, 294, 264, 4145, 13, 400, 309, 311, 1596, 3700, 300, 50908], "temperature": 0.0, "avg_logprob": -0.0989107864581986, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.0017513252096250653}, {"id": 302, "seek": 138192, "start": 1392.8000000000002, "end": 1397.68, "text": " when you guys, when I showed you this first video clip that you did that, right? And may not even", "tokens": [50908, 562, 291, 1074, 11, 562, 286, 4712, 291, 341, 700, 960, 7353, 300, 291, 630, 300, 11, 558, 30, 400, 815, 406, 754, 51152], "temperature": 0.0, "avg_logprob": -0.0989107864581986, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.0017513252096250653}, {"id": 303, "seek": 138192, "start": 1397.68, "end": 1402.4, "text": " been super, you know, aware to you that you did do that, like I haven't really checked, you know,", "tokens": [51152, 668, 1687, 11, 291, 458, 11, 3650, 281, 291, 300, 291, 630, 360, 300, 11, 411, 286, 2378, 380, 534, 10033, 11, 291, 458, 11, 51388], "temperature": 0.0, "avg_logprob": -0.0989107864581986, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.0017513252096250653}, {"id": 304, "seek": 138192, "start": 1403.1200000000001, "end": 1406.8000000000002, "text": " yeah, how, well, at some point at the beginning when I ran this on the laptop, I would sometimes", "tokens": [51424, 1338, 11, 577, 11, 731, 11, 412, 512, 935, 412, 264, 2863, 562, 286, 5872, 341, 322, 264, 10732, 11, 286, 576, 2171, 51608], "temperature": 0.0, "avg_logprob": -0.0989107864581986, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.0017513252096250653}, {"id": 305, "seek": 138192, "start": 1406.8000000000002, "end": 1409.68, "text": " see that people would use their finger, or they would use their, you know, kind of", "tokens": [51608, 536, 300, 561, 576, 764, 641, 5984, 11, 420, 436, 576, 764, 641, 11, 291, 458, 11, 733, 295, 51752], "temperature": 0.0, "avg_logprob": -0.0989107864581986, "compression_ratio": 1.8446601941747574, "no_speech_prob": 0.0017513252096250653}, {"id": 306, "seek": 140968, "start": 1410.3200000000002, "end": 1415.52, "text": " pen or something. And that's of course pretty aware, I guess, right? But it's possible that with", "tokens": [50396, 3435, 420, 746, 13, 400, 300, 311, 295, 1164, 1238, 3650, 11, 286, 2041, 11, 558, 30, 583, 309, 311, 1944, 300, 365, 50656], "temperature": 0.0, "avg_logprob": -0.10634669637292381, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0009672517189756036}, {"id": 307, "seek": 140968, "start": 1415.52, "end": 1419.52, "text": " the eye movements, this sort of comes so natural to us that we don't even realize that we're engaging", "tokens": [50656, 264, 3313, 9981, 11, 341, 1333, 295, 1487, 370, 3303, 281, 505, 300, 321, 500, 380, 754, 4325, 300, 321, 434, 11268, 50856], "temperature": 0.0, "avg_logprob": -0.10634669637292381, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0009672517189756036}, {"id": 308, "seek": 140968, "start": 1419.52, "end": 1425.2, "text": " kind of in this kind of process. But yeah, I was very happy, you know, when I saw this happening.", "tokens": [50856, 733, 295, 294, 341, 733, 295, 1399, 13, 583, 1338, 11, 286, 390, 588, 2055, 11, 291, 458, 11, 562, 286, 1866, 341, 2737, 13, 51140], "temperature": 0.0, "avg_logprob": -0.10634669637292381, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0009672517189756036}, {"id": 309, "seek": 140968, "start": 1426.3200000000002, "end": 1430.88, "text": " And so this is anecdotal in a sense, it's just one video clip, right? But we can also look at", "tokens": [51196, 400, 370, 341, 307, 26652, 38180, 294, 257, 2020, 11, 309, 311, 445, 472, 960, 7353, 11, 558, 30, 583, 321, 393, 611, 574, 412, 51424], "temperature": 0.0, "avg_logprob": -0.10634669637292381, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0009672517189756036}, {"id": 310, "seek": 140968, "start": 1430.88, "end": 1435.2, "text": " more generally, sort of analyzing the differences in the eye movements that people are producing", "tokens": [51424, 544, 5101, 11, 1333, 295, 23663, 264, 7300, 294, 264, 3313, 9981, 300, 561, 366, 10501, 51640], "temperature": 0.0, "avg_logprob": -0.10634669637292381, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.0009672517189756036}, {"id": 311, "seek": 143520, "start": 1435.28, "end": 1438.8, "text": " between these different experiments. And what I'm showing here is just looking at", "tokens": [50368, 1296, 613, 819, 12050, 13, 400, 437, 286, 478, 4099, 510, 307, 445, 1237, 412, 50544], "temperature": 0.0, "avg_logprob": -0.09186025966297497, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0032670910004526377}, {"id": 312, "seek": 143520, "start": 1438.8, "end": 1442.56, "text": " the saccades that participants are producing. So those are fast eye movements jumping from", "tokens": [50544, 264, 4899, 66, 2977, 300, 10503, 366, 10501, 13, 407, 729, 366, 2370, 3313, 9981, 11233, 490, 50732], "temperature": 0.0, "avg_logprob": -0.09186025966297497, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0032670910004526377}, {"id": 313, "seek": 143520, "start": 1442.56, "end": 1448.24, "text": " one point to another. And then I look at the endpoints of those saccades. And I look at where", "tokens": [50732, 472, 935, 281, 1071, 13, 400, 550, 286, 574, 412, 264, 917, 20552, 295, 729, 4899, 66, 2977, 13, 400, 286, 574, 412, 689, 51016], "temperature": 0.0, "avg_logprob": -0.09186025966297497, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0032670910004526377}, {"id": 314, "seek": 143520, "start": 1448.24, "end": 1453.6000000000001, "text": " those fall, right? And I took into account only the time between ball A and ball B coming into the", "tokens": [51016, 729, 2100, 11, 558, 30, 400, 286, 1890, 666, 2696, 787, 264, 565, 1296, 2594, 316, 293, 2594, 363, 1348, 666, 264, 51284], "temperature": 0.0, "avg_logprob": -0.09186025966297497, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0032670910004526377}, {"id": 315, "seek": 143520, "start": 1453.6000000000001, "end": 1461.28, "text": " scene. And before basically, when they collide with one another, that time window. And then we", "tokens": [51284, 4145, 13, 400, 949, 1936, 11, 562, 436, 49093, 365, 472, 1071, 11, 300, 565, 4910, 13, 400, 550, 321, 51668], "temperature": 0.0, "avg_logprob": -0.09186025966297497, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0032670910004526377}, {"id": 316, "seek": 146128, "start": 1461.28, "end": 1467.36, "text": " see that on this, for the causal question, a lot of those saccades basically end up along the path", "tokens": [50364, 536, 300, 322, 341, 11, 337, 264, 38755, 1168, 11, 257, 688, 295, 729, 4899, 66, 2977, 1936, 917, 493, 2051, 264, 3100, 50668], "temperature": 0.0, "avg_logprob": -0.08173273227832935, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.00031425044289790094}, {"id": 317, "seek": 146128, "start": 1467.36, "end": 1471.36, "text": " right that ball B would have taken if ball A hadn't been there. Whereas in the other condition,", "tokens": [50668, 558, 300, 2594, 363, 576, 362, 2726, 498, 2594, 316, 8782, 380, 668, 456, 13, 13813, 294, 264, 661, 4188, 11, 50868], "temperature": 0.0, "avg_logprob": -0.08173273227832935, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.00031425044289790094}, {"id": 318, "seek": 146128, "start": 1471.36, "end": 1480.16, "text": " we see very few of these kinds of eye movements. So nice, I guess, even more direct evidence", "tokens": [50868, 321, 536, 588, 1326, 295, 613, 3685, 295, 3313, 9981, 13, 407, 1481, 11, 286, 2041, 11, 754, 544, 2047, 4467, 51308], "temperature": 0.0, "avg_logprob": -0.08173273227832935, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.00031425044289790094}, {"id": 319, "seek": 146128, "start": 1480.16, "end": 1483.84, "text": " that people are engaging in this kind of process and that they're doing it specifically", "tokens": [51308, 300, 561, 366, 11268, 294, 341, 733, 295, 1399, 293, 300, 436, 434, 884, 309, 4682, 51492], "temperature": 0.0, "avg_logprob": -0.08173273227832935, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.00031425044289790094}, {"id": 320, "seek": 146128, "start": 1483.84, "end": 1488.16, "text": " when asked to answer a causal question about the clip and sort of spontaneously.", "tokens": [51492, 562, 2351, 281, 1867, 257, 38755, 1168, 466, 264, 7353, 293, 1333, 295, 47632, 13, 51708], "temperature": 0.0, "avg_logprob": -0.08173273227832935, "compression_ratio": 1.6764705882352942, "no_speech_prob": 0.00031425044289790094}, {"id": 321, "seek": 148816, "start": 1488.4, "end": 1496.4, "text": " There is this other part to it. But I think I will skip, so I have a little bit more time to,", "tokens": [50376, 821, 307, 341, 661, 644, 281, 309, 13, 583, 286, 519, 286, 486, 10023, 11, 370, 286, 362, 257, 707, 857, 544, 565, 281, 11, 50776], "temperature": 0.0, "avg_logprob": -0.2205238149623678, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.0001329912047367543}, {"id": 322, "seek": 148816, "start": 1497.52, "end": 1502.4, "text": " let me see. Well, actually, I'll share it. Sorry about that. So there was another,", "tokens": [50832, 718, 385, 536, 13, 1042, 11, 767, 11, 286, 603, 2073, 309, 13, 4919, 466, 300, 13, 407, 456, 390, 1071, 11, 51076], "temperature": 0.0, "avg_logprob": -0.2205238149623678, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.0001329912047367543}, {"id": 323, "seek": 148816, "start": 1502.4, "end": 1507.28, "text": " after we published this paper, there was another reviewer number two, as there often is.", "tokens": [51076, 934, 321, 6572, 341, 3035, 11, 456, 390, 1071, 3131, 260, 1230, 732, 11, 382, 456, 2049, 307, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2205238149623678, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.0001329912047367543}, {"id": 324, "seek": 148816, "start": 1509.28, "end": 1514.48, "text": " And they were basically still saying, okay, well, this was for the eye tracking data. And they said,", "tokens": [51420, 400, 436, 645, 1936, 920, 1566, 11, 1392, 11, 731, 11, 341, 390, 337, 264, 3313, 11603, 1412, 13, 400, 436, 848, 11, 51680], "temperature": 0.0, "avg_logprob": -0.2205238149623678, "compression_ratio": 1.6339285714285714, "no_speech_prob": 0.0001329912047367543}, {"id": 325, "seek": 151448, "start": 1514.88, "end": 1519.92, "text": " that's nice. You're showing us these sort of eye movements. But they basically said that, okay,", "tokens": [50384, 300, 311, 1481, 13, 509, 434, 4099, 505, 613, 1333, 295, 3313, 9981, 13, 583, 436, 1936, 848, 300, 11, 1392, 11, 50636], "temperature": 0.0, "avg_logprob": -0.13127782690616055, "compression_ratio": 1.8514851485148516, "no_speech_prob": 0.0010157313663512468}, {"id": 326, "seek": 151448, "start": 1519.92, "end": 1524.32, "text": " these eye movements, they're happening before the balls are colliding with one another. And you're", "tokens": [50636, 613, 3313, 9981, 11, 436, 434, 2737, 949, 264, 9803, 366, 1263, 2819, 365, 472, 1071, 13, 400, 291, 434, 50856], "temperature": 0.0, "avg_logprob": -0.13127782690616055, "compression_ratio": 1.8514851485148516, "no_speech_prob": 0.0010157313663512468}, {"id": 327, "seek": 151448, "start": 1524.32, "end": 1528.24, "text": " calling it sort of counterfactual simulation. Counterfactual should mean it should be back", "tokens": [50856, 5141, 309, 1333, 295, 5682, 44919, 901, 16575, 13, 35607, 44919, 901, 820, 914, 309, 820, 312, 646, 51052], "temperature": 0.0, "avg_logprob": -0.13127782690616055, "compression_ratio": 1.8514851485148516, "no_speech_prob": 0.0010157313663512468}, {"id": 328, "seek": 151448, "start": 1528.24, "end": 1532.24, "text": " in the past. Going back in the past, evaluating that something would have been different,", "tokens": [51052, 294, 264, 1791, 13, 10963, 646, 294, 264, 1791, 11, 27479, 300, 746, 576, 362, 668, 819, 11, 51252], "temperature": 0.0, "avg_logprob": -0.13127782690616055, "compression_ratio": 1.8514851485148516, "no_speech_prob": 0.0010157313663512468}, {"id": 329, "seek": 151448, "start": 1532.24, "end": 1538.0, "text": " and then seeing what difference that would have made. And they were saying, oh, what,", "tokens": [51252, 293, 550, 2577, 437, 2649, 300, 576, 362, 1027, 13, 400, 436, 645, 1566, 11, 1954, 11, 437, 11, 51540], "temperature": 0.0, "avg_logprob": -0.13127782690616055, "compression_ratio": 1.8514851485148516, "no_speech_prob": 0.0010157313663512468}, {"id": 330, "seek": 151448, "start": 1538.0, "end": 1543.28, "text": " you should just call it the hypothetical simulation model instead, and not that. So we were able to", "tokens": [51540, 291, 820, 445, 818, 309, 264, 33053, 16575, 2316, 2602, 11, 293, 406, 300, 13, 407, 321, 645, 1075, 281, 51804], "temperature": 0.0, "avg_logprob": -0.13127782690616055, "compression_ratio": 1.8514851485148516, "no_speech_prob": 0.0010157313663512468}, {"id": 331, "seek": 154328, "start": 1543.44, "end": 1551.6, "text": " push back. But the reviewer also was right to some extent, I think. So this is a paper that I've", "tokens": [50372, 2944, 646, 13, 583, 264, 3131, 260, 611, 390, 558, 281, 512, 8396, 11, 286, 519, 13, 407, 341, 307, 257, 3035, 300, 286, 600, 50780], "temperature": 0.0, "avg_logprob": -0.07593883514404297, "compression_ratio": 1.7859327217125383, "no_speech_prob": 0.0003978577151428908}, {"id": 332, "seek": 154328, "start": 1551.6, "end": 1556.72, "text": " published quite recently, where I was trying to say that, no, you really need the counterfactuals.", "tokens": [50780, 6572, 1596, 3938, 11, 689, 286, 390, 1382, 281, 584, 300, 11, 572, 11, 291, 534, 643, 264, 5682, 44919, 901, 82, 13, 51036], "temperature": 0.0, "avg_logprob": -0.07593883514404297, "compression_ratio": 1.7859327217125383, "no_speech_prob": 0.0003978577151428908}, {"id": 333, "seek": 154328, "start": 1556.72, "end": 1560.16, "text": " So a lot of this has been like, yeah, you really need the counterfactuals. And then you just keep", "tokens": [51036, 407, 257, 688, 295, 341, 575, 668, 411, 11, 1338, 11, 291, 534, 643, 264, 5682, 44919, 901, 82, 13, 400, 550, 291, 445, 1066, 51208], "temperature": 0.0, "avg_logprob": -0.07593883514404297, "compression_ratio": 1.7859327217125383, "no_speech_prob": 0.0003978577151428908}, {"id": 334, "seek": 154328, "start": 1560.16, "end": 1564.72, "text": " getting some pushback, and you try to convince people even more so. So this was this reviewer", "tokens": [51208, 1242, 512, 2944, 3207, 11, 293, 291, 853, 281, 13447, 561, 754, 544, 370, 13, 407, 341, 390, 341, 3131, 260, 51436], "temperature": 0.0, "avg_logprob": -0.07593883514404297, "compression_ratio": 1.7859327217125383, "no_speech_prob": 0.0003978577151428908}, {"id": 335, "seek": 154328, "start": 1564.72, "end": 1568.8, "text": " number two here. You haven't really shown us counterfactual simulation. Those looks are happening", "tokens": [51436, 1230, 732, 510, 13, 509, 2378, 380, 534, 4898, 505, 5682, 44919, 901, 16575, 13, 3950, 1542, 366, 2737, 51640], "temperature": 0.0, "avg_logprob": -0.07593883514404297, "compression_ratio": 1.7859327217125383, "no_speech_prob": 0.0003978577151428908}, {"id": 336, "seek": 154328, "start": 1568.8, "end": 1572.8, "text": " before the balls are colliding. So his idea was, well, maybe what people are doing is they're kind", "tokens": [51640, 949, 264, 9803, 366, 1263, 2819, 13, 407, 702, 1558, 390, 11, 731, 11, 1310, 437, 561, 366, 884, 307, 436, 434, 733, 51840], "temperature": 0.0, "avg_logprob": -0.07593883514404297, "compression_ratio": 1.7859327217125383, "no_speech_prob": 0.0003978577151428908}, {"id": 337, "seek": 157280, "start": 1572.8, "end": 1577.2, "text": " of simulating some hypothetical future. In this case, the hypothetical future is like,", "tokens": [50364, 295, 1034, 12162, 512, 33053, 2027, 13, 682, 341, 1389, 11, 264, 33053, 2027, 307, 411, 11, 50584], "temperature": 0.0, "avg_logprob": -0.11261179762066535, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.00016079879424069077}, {"id": 338, "seek": 157280, "start": 1577.2, "end": 1581.76, "text": " what would happen if ball A wasn't there? And then they're storing that in their mind,", "tokens": [50584, 437, 576, 1051, 498, 2594, 316, 2067, 380, 456, 30, 400, 550, 436, 434, 26085, 300, 294, 641, 1575, 11, 50812], "temperature": 0.0, "avg_logprob": -0.11261179762066535, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.00016079879424069077}, {"id": 339, "seek": 157280, "start": 1581.76, "end": 1585.84, "text": " and comparing that to what actually happened at the end. And that's a slightly different", "tokens": [50812, 293, 15763, 300, 281, 437, 767, 2011, 412, 264, 917, 13, 400, 300, 311, 257, 4748, 819, 51016], "temperature": 0.0, "avg_logprob": -0.11261179762066535, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.00016079879424069077}, {"id": 340, "seek": 157280, "start": 1585.84, "end": 1591.12, "text": " computation from the one that I think they're carrying out. And this relates to something,", "tokens": [51016, 24903, 490, 264, 472, 300, 286, 519, 436, 434, 9792, 484, 13, 400, 341, 16155, 281, 746, 11, 51280], "temperature": 0.0, "avg_logprob": -0.11261179762066535, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.00016079879424069077}, {"id": 341, "seek": 157280, "start": 1591.12, "end": 1598.8, "text": " again, here's Judea Pearl, this climbing on this kind of virtual letter here. Because he has argued", "tokens": [51280, 797, 11, 510, 311, 36521, 64, 24639, 11, 341, 14780, 322, 341, 733, 295, 6374, 5063, 510, 13, 1436, 415, 575, 20219, 51664], "temperature": 0.0, "avg_logprob": -0.11261179762066535, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.00016079879424069077}, {"id": 342, "seek": 159880, "start": 1598.8, "end": 1603.84, "text": " that there are these three different ways of thinking about the extent to which people have", "tokens": [50364, 300, 456, 366, 613, 1045, 819, 2098, 295, 1953, 466, 264, 8396, 281, 597, 561, 362, 50616], "temperature": 0.0, "avg_logprob": -0.08621801896528765, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.00035668641794472933}, {"id": 343, "seek": 159880, "start": 1603.84, "end": 1609.44, "text": " causal knowledge of how the world works. On the lowest rung of the letter, and he often accuses", "tokens": [50616, 38755, 3601, 295, 577, 264, 1002, 1985, 13, 1282, 264, 12437, 367, 1063, 295, 264, 5063, 11, 293, 415, 2049, 11168, 279, 50896], "temperature": 0.0, "avg_logprob": -0.08621801896528765, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.00035668641794472933}, {"id": 344, "seek": 159880, "start": 1609.44, "end": 1613.04, "text": " a lot of deep learning and so on to be on that rung, although it's a little unclear,", "tokens": [50896, 257, 688, 295, 2452, 2539, 293, 370, 322, 281, 312, 322, 300, 367, 1063, 11, 4878, 309, 311, 257, 707, 25636, 11, 51076], "temperature": 0.0, "avg_logprob": -0.08621801896528765, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.00035668641794472933}, {"id": 345, "seek": 159880, "start": 1614.1599999999999, "end": 1617.76, "text": " he calls that rung the level of association. So that's what you learn in the stats classes", "tokens": [51132, 415, 5498, 300, 367, 1063, 264, 1496, 295, 14598, 13, 407, 300, 311, 437, 291, 1466, 294, 264, 18152, 5359, 51312], "temperature": 0.0, "avg_logprob": -0.08621801896528765, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.00035668641794472933}, {"id": 346, "seek": 159880, "start": 1617.76, "end": 1623.04, "text": " correlation. When two things are associated with one another, and you can infer one variable from", "tokens": [51312, 20009, 13, 1133, 732, 721, 366, 6615, 365, 472, 1071, 11, 293, 291, 393, 13596, 472, 7006, 490, 51576], "temperature": 0.0, "avg_logprob": -0.08621801896528765, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.00035668641794472933}, {"id": 347, "seek": 162304, "start": 1623.12, "end": 1629.28, "text": " the presence of another, so the normal conditional probability, PY given, I would say PY given X.", "tokens": [50368, 264, 6814, 295, 1071, 11, 370, 264, 2710, 27708, 8482, 11, 430, 56, 2212, 11, 286, 576, 584, 430, 56, 2212, 1783, 13, 50676], "temperature": 0.0, "avg_logprob": -0.15837010329331808, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00048720798804424703}, {"id": 348, "seek": 162304, "start": 1629.28, "end": 1634.1599999999999, "text": " So what does some symptom tell me about the disease, for example? On the next level,", "tokens": [50676, 407, 437, 775, 512, 29370, 980, 385, 466, 264, 4752, 11, 337, 1365, 30, 1282, 264, 958, 1496, 11, 50920], "temperature": 0.0, "avg_logprob": -0.15837010329331808, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00048720798804424703}, {"id": 349, "seek": 162304, "start": 1634.1599999999999, "end": 1637.84, "text": " it's the level of interventional reasoning. That's the kind of when I do a randomized control", "tokens": [50920, 309, 311, 264, 1496, 295, 13176, 304, 21577, 13, 663, 311, 264, 733, 295, 562, 286, 360, 257, 38513, 1969, 51104], "temperature": 0.0, "avg_logprob": -0.15837010329331808, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00048720798804424703}, {"id": 350, "seek": 162304, "start": 1637.84, "end": 1642.72, "text": " trial, for example, or if I'm, again, hypothetically reasoning, oh, what would happen if I were to do", "tokens": [51104, 7308, 11, 337, 1365, 11, 420, 498, 286, 478, 11, 797, 11, 24371, 22652, 21577, 11, 1954, 11, 437, 576, 1051, 498, 286, 645, 281, 360, 51348], "temperature": 0.0, "avg_logprob": -0.15837010329331808, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00048720798804424703}, {"id": 351, "seek": 162304, "start": 1642.72, "end": 1648.56, "text": " this? What would happen if I were to do that? And that's sort of when your stats teacher tells you", "tokens": [51348, 341, 30, 708, 576, 1051, 498, 286, 645, 281, 360, 300, 30, 400, 300, 311, 1333, 295, 562, 428, 18152, 5027, 5112, 291, 51640], "temperature": 0.0, "avg_logprob": -0.15837010329331808, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00048720798804424703}, {"id": 352, "seek": 164856, "start": 1649.12, "end": 1653.04, "text": " causation and correlation aren't the same thing, that's often the thing that they then think about,", "tokens": [50392, 3302, 399, 293, 20009, 3212, 380, 264, 912, 551, 11, 300, 311, 2049, 264, 551, 300, 436, 550, 519, 466, 11, 50588], "temperature": 0.0, "avg_logprob": -0.10843116481129716, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.0003097920271102339}, {"id": 353, "seek": 164856, "start": 1653.04, "end": 1656.08, "text": " right? That like, oh, on the level of an experiment, now I'm performing an intervention,", "tokens": [50588, 558, 30, 663, 411, 11, 1954, 11, 322, 264, 1496, 295, 364, 5120, 11, 586, 286, 478, 10205, 364, 13176, 11, 50740], "temperature": 0.0, "avg_logprob": -0.10843116481129716, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.0003097920271102339}, {"id": 354, "seek": 164856, "start": 1656.08, "end": 1660.72, "text": " randomly assigning people to different groups, and I can draw different kinds of causal inferences", "tokens": [50740, 16979, 49602, 561, 281, 819, 3935, 11, 293, 286, 393, 2642, 819, 3685, 295, 38755, 13596, 2667, 50972], "temperature": 0.0, "avg_logprob": -0.10843116481129716, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.0003097920271102339}, {"id": 355, "seek": 164856, "start": 1660.72, "end": 1666.96, "text": " from that information than when I just have observations. But then process ultimately,", "tokens": [50972, 490, 300, 1589, 813, 562, 286, 445, 362, 18163, 13, 583, 550, 1399, 6284, 11, 51284], "temperature": 0.0, "avg_logprob": -0.10843116481129716, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.0003097920271102339}, {"id": 356, "seek": 164856, "start": 1666.96, "end": 1672.8, "text": " the kind of the highest rung on the letter is reserved for counterfactual reasoning,", "tokens": [51284, 264, 733, 295, 264, 6343, 367, 1063, 322, 264, 5063, 307, 24819, 337, 5682, 44919, 901, 21577, 11, 51576], "temperature": 0.0, "avg_logprob": -0.10843116481129716, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.0003097920271102339}, {"id": 357, "seek": 164856, "start": 1672.8, "end": 1677.36, "text": " and that allows you to give specific answers essentially to why questions. So why did this", "tokens": [51576, 293, 300, 4045, 291, 281, 976, 2685, 6338, 4476, 281, 983, 1651, 13, 407, 983, 630, 341, 51804], "temperature": 0.0, "avg_logprob": -0.10843116481129716, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.0003097920271102339}, {"id": 358, "seek": 167736, "start": 1677.36, "end": 1682.0, "text": " happen in this particular case? Like, you know, was it the aspirin that stopped my headache,", "tokens": [50364, 1051, 294, 341, 1729, 1389, 30, 1743, 11, 291, 458, 11, 390, 309, 264, 20003, 259, 300, 5936, 452, 23520, 11, 50596], "temperature": 0.0, "avg_logprob": -0.17080117634364536, "compression_ratio": 1.70625, "no_speech_prob": 0.000853351375553757}, {"id": 359, "seek": 167736, "start": 1682.0, "end": 1686.24, "text": " or would it have stopped anyhow, even if it hadn't taken the aspirin? Or, you know,", "tokens": [50596, 420, 576, 309, 362, 5936, 44995, 11, 754, 498, 309, 8782, 380, 2726, 264, 20003, 259, 30, 1610, 11, 291, 458, 11, 50808], "temperature": 0.0, "avg_logprob": -0.17080117634364536, "compression_ratio": 1.70625, "no_speech_prob": 0.000853351375553757}, {"id": 360, "seek": 167736, "start": 1686.9599999999998, "end": 1690.56, "text": " was Kennedy shot? Would Kennedy still have been alive if it hadn't been shot by", "tokens": [50844, 390, 16517, 3347, 30, 6068, 16517, 920, 362, 668, 5465, 498, 309, 8782, 380, 668, 3347, 538, 51024], "temperature": 0.0, "avg_logprob": -0.17080117634364536, "compression_ratio": 1.70625, "no_speech_prob": 0.000853351375553757}, {"id": 361, "seek": 167736, "start": 1690.56, "end": 1696.08, "text": " very heavy-ass world? And so essentially, now the question boils down to, do we need that third", "tokens": [51024, 588, 4676, 12, 640, 1002, 30, 400, 370, 4476, 11, 586, 264, 1168, 35049, 760, 281, 11, 360, 321, 643, 300, 2636, 51300], "temperature": 0.0, "avg_logprob": -0.17080117634364536, "compression_ratio": 1.70625, "no_speech_prob": 0.000853351375553757}, {"id": 362, "seek": 167736, "start": 1696.08, "end": 1703.1999999999998, "text": " level, like to explain people's causal judgments, or is the second one enough, right? So just to kind", "tokens": [51300, 1496, 11, 411, 281, 2903, 561, 311, 38755, 40337, 11, 420, 307, 264, 1150, 472, 1547, 11, 558, 30, 407, 445, 281, 733, 51656], "temperature": 0.0, "avg_logprob": -0.17080117634364536, "compression_ratio": 1.70625, "no_speech_prob": 0.000853351375553757}, {"id": 363, "seek": 167736, "start": 1703.1999999999998, "end": 1706.56, "text": " of try and make it a little bit more clear, right? So the hypothetical, luckily in English,", "tokens": [51656, 295, 853, 293, 652, 309, 257, 707, 857, 544, 1850, 11, 558, 30, 407, 264, 33053, 11, 22880, 294, 3669, 11, 51824], "temperature": 0.0, "avg_logprob": -0.17080117634364536, "compression_ratio": 1.70625, "no_speech_prob": 0.000853351375553757}, {"id": 364, "seek": 170656, "start": 1706.6399999999999, "end": 1710.56, "text": " also we have sort of a way of marking the difference between them. So here's an English", "tokens": [50368, 611, 321, 362, 1333, 295, 257, 636, 295, 25482, 264, 2649, 1296, 552, 13, 407, 510, 311, 364, 3669, 50564], "temperature": 0.0, "avg_logprob": -0.09645088931970429, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0006984639330767095}, {"id": 365, "seek": 170656, "start": 1710.56, "end": 1715.6799999999998, "text": " hypothetical. Would B go into the goal if A was removed? So what you'd be doing is taking the", "tokens": [50564, 33053, 13, 6068, 363, 352, 666, 264, 3387, 498, 316, 390, 7261, 30, 407, 437, 291, 1116, 312, 884, 307, 1940, 264, 50820], "temperature": 0.0, "avg_logprob": -0.09645088931970429, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0006984639330767095}, {"id": 366, "seek": 170656, "start": 1715.6799999999998, "end": 1721.9199999999998, "text": " time into account until they collide, simulating like a possible future, and then computing the", "tokens": [50820, 565, 666, 2696, 1826, 436, 49093, 11, 1034, 12162, 411, 257, 1944, 2027, 11, 293, 550, 15866, 264, 51132], "temperature": 0.0, "avg_logprob": -0.09645088931970429, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0006984639330767095}, {"id": 367, "seek": 170656, "start": 1721.9199999999998, "end": 1727.84, "text": " probability of that. Versus the counterfactual, what I'm doing, slightly different in English,", "tokens": [51132, 8482, 295, 300, 13, 12226, 301, 264, 5682, 44919, 901, 11, 437, 286, 478, 884, 11, 4748, 819, 294, 3669, 11, 51428], "temperature": 0.0, "avg_logprob": -0.09645088931970429, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0006984639330767095}, {"id": 368, "seek": 170656, "start": 1727.84, "end": 1734.3999999999999, "text": " right, would B have gone into the goal if A had been removed? I sometimes, you know, regret", "tokens": [51428, 558, 11, 576, 363, 362, 2780, 666, 264, 3387, 498, 316, 632, 668, 7261, 30, 286, 2171, 11, 291, 458, 11, 10879, 51756], "temperature": 0.0, "avg_logprob": -0.09645088931970429, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0006984639330767095}, {"id": 369, "seek": 173440, "start": 1734.4, "end": 1738.0800000000002, "text": " having gotten into counterfactual so much, so obviously not a native speaker, and the", "tokens": [50364, 1419, 5768, 666, 5682, 44919, 901, 370, 709, 11, 370, 2745, 406, 257, 8470, 8145, 11, 293, 264, 50548], "temperature": 0.0, "avg_logprob": -0.09681700247305411, "compression_ratio": 1.7203647416413375, "no_speech_prob": 0.0005684909992851317}, {"id": 370, "seek": 173440, "start": 1738.0800000000002, "end": 1741.76, "text": " counterfactuals are sometimes a little complicated, right, that you get the tenses right and so on,", "tokens": [50548, 5682, 44919, 901, 82, 366, 2171, 257, 707, 6179, 11, 558, 11, 300, 291, 483, 264, 256, 9085, 558, 293, 370, 322, 11, 50732], "temperature": 0.0, "avg_logprob": -0.09681700247305411, "compression_ratio": 1.7203647416413375, "no_speech_prob": 0.0005684909992851317}, {"id": 371, "seek": 173440, "start": 1741.76, "end": 1746.72, "text": " but I think I've mostly gotten it down by now after like 20 years. So would B have gone into", "tokens": [50732, 457, 286, 519, 286, 600, 5240, 5768, 309, 760, 538, 586, 934, 411, 945, 924, 13, 407, 576, 363, 362, 2780, 666, 50980], "temperature": 0.0, "avg_logprob": -0.09681700247305411, "compression_ratio": 1.7203647416413375, "no_speech_prob": 0.0005684909992851317}, {"id": 372, "seek": 173440, "start": 1746.72, "end": 1750.4, "text": " the goal if ball A had been removed? So you're doing slightly different here now, right? You're", "tokens": [50980, 264, 3387, 498, 2594, 316, 632, 668, 7261, 30, 407, 291, 434, 884, 4748, 819, 510, 586, 11, 558, 30, 509, 434, 51164], "temperature": 0.0, "avg_logprob": -0.09681700247305411, "compression_ratio": 1.7203647416413375, "no_speech_prob": 0.0005684909992851317}, {"id": 373, "seek": 173440, "start": 1750.4, "end": 1755.44, "text": " taking into account everything until the end, and you're now going back in time to do this", "tokens": [51164, 1940, 666, 2696, 1203, 1826, 264, 917, 11, 293, 291, 434, 586, 516, 646, 294, 565, 281, 360, 341, 51416], "temperature": 0.0, "avg_logprob": -0.09681700247305411, "compression_ratio": 1.7203647416413375, "no_speech_prob": 0.0005684909992851317}, {"id": 374, "seek": 173440, "start": 1755.44, "end": 1759.3600000000001, "text": " intervention and then think about how the world could have unfolded differently from how it actually", "tokens": [51416, 13176, 293, 550, 519, 466, 577, 264, 1002, 727, 362, 17980, 292, 7614, 490, 577, 309, 767, 51612], "temperature": 0.0, "avg_logprob": -0.09681700247305411, "compression_ratio": 1.7203647416413375, "no_speech_prob": 0.0005684909992851317}, {"id": 375, "seek": 175936, "start": 1759.36, "end": 1765.52, "text": " did. So now it turns out in this very simple setting here, that makes no difference. The", "tokens": [50364, 630, 13, 407, 586, 309, 4523, 484, 294, 341, 588, 2199, 3287, 510, 11, 300, 1669, 572, 2649, 13, 440, 50672], "temperature": 0.0, "avg_logprob": -0.09212099760770798, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.00036802361137233675}, {"id": 376, "seek": 175936, "start": 1765.52, "end": 1769.36, "text": " hypothetical probability and the counterfactual probability is the same because there's nothing,", "tokens": [50672, 33053, 8482, 293, 264, 5682, 44919, 901, 8482, 307, 264, 912, 570, 456, 311, 1825, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09212099760770798, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.00036802361137233675}, {"id": 377, "seek": 175936, "start": 1769.36, "end": 1774.4799999999998, "text": " there's only this one causal event happening, so it doesn't really come apart. So in a very simple", "tokens": [50864, 456, 311, 787, 341, 472, 38755, 2280, 2737, 11, 370, 309, 1177, 380, 534, 808, 4936, 13, 407, 294, 257, 588, 2199, 51120], "temperature": 0.0, "avg_logprob": -0.09212099760770798, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.00036802361137233675}, {"id": 378, "seek": 175936, "start": 1774.4799999999998, "end": 1780.6399999999999, "text": " setting where you have one cause and one effect, essentially, you cannot tease the two apart,", "tokens": [51120, 3287, 689, 291, 362, 472, 3082, 293, 472, 1802, 11, 4476, 11, 291, 2644, 30444, 264, 732, 4936, 11, 51428], "temperature": 0.0, "avg_logprob": -0.09212099760770798, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.00036802361137233675}, {"id": 379, "seek": 175936, "start": 1780.6399999999999, "end": 1784.6399999999999, "text": " but you don't need to make it much more complicated. It's sufficient if you just have one other", "tokens": [51428, 457, 291, 500, 380, 643, 281, 652, 309, 709, 544, 6179, 13, 467, 311, 11563, 498, 291, 445, 362, 472, 661, 51628], "temperature": 0.0, "avg_logprob": -0.09212099760770798, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.00036802361137233675}, {"id": 380, "seek": 175936, "start": 1784.6399999999999, "end": 1789.1999999999998, "text": " alternative event that you are initially uncertain about, and that will make it such that", "tokens": [51628, 8535, 2280, 300, 291, 366, 9105, 11308, 466, 11, 293, 300, 486, 652, 309, 1270, 300, 51856], "temperature": 0.0, "avg_logprob": -0.09212099760770798, "compression_ratio": 1.825242718446602, "no_speech_prob": 0.00036802361137233675}, {"id": 381, "seek": 178920, "start": 1789.28, "end": 1793.28, "text": " now the hypothetical probability and the counterfactual probability will be different from one another.", "tokens": [50368, 586, 264, 33053, 8482, 293, 264, 5682, 44919, 901, 8482, 486, 312, 819, 490, 472, 1071, 13, 50568], "temperature": 0.0, "avg_logprob": -0.08577958318113371, "compression_ratio": 1.7727272727272727, "no_speech_prob": 8.47242190502584e-05}, {"id": 382, "seek": 178920, "start": 1794.48, "end": 1799.2, "text": " So here was the genius invention, just putting like a little block again that you've seen earlier,", "tokens": [50628, 407, 510, 390, 264, 14017, 22265, 11, 445, 3372, 411, 257, 707, 3461, 797, 300, 291, 600, 1612, 3071, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08577958318113371, "compression_ratio": 1.7727272727272727, "no_speech_prob": 8.47242190502584e-05}, {"id": 383, "seek": 178920, "start": 1799.2, "end": 1804.96, "text": " but this time the block is on rails into the scene, and that will now make it such that we", "tokens": [50864, 457, 341, 565, 264, 3461, 307, 322, 27649, 666, 264, 4145, 11, 293, 300, 486, 586, 652, 309, 1270, 300, 321, 51152], "temperature": 0.0, "avg_logprob": -0.08577958318113371, "compression_ratio": 1.7727272727272727, "no_speech_prob": 8.47242190502584e-05}, {"id": 384, "seek": 178920, "start": 1804.96, "end": 1808.72, "text": " can tease these two different things apart. So here's an example. I'm not going to ask for", "tokens": [51152, 393, 30444, 613, 732, 819, 721, 4936, 13, 407, 510, 311, 364, 1365, 13, 286, 478, 406, 516, 281, 1029, 337, 51340], "temperature": 0.0, "avg_logprob": -0.08577958318113371, "compression_ratio": 1.7727272727272727, "no_speech_prob": 8.47242190502584e-05}, {"id": 385, "seek": 178920, "start": 1808.72, "end": 1812.24, "text": " audience petition this time, but let's say that this was happening in the clip,", "tokens": [51340, 4034, 22661, 341, 565, 11, 457, 718, 311, 584, 300, 341, 390, 2737, 294, 264, 7353, 11, 51516], "temperature": 0.0, "avg_logprob": -0.08577958318113371, "compression_ratio": 1.7727272727272727, "no_speech_prob": 8.47242190502584e-05}, {"id": 386, "seek": 178920, "start": 1813.76, "end": 1817.1200000000001, "text": " and now if you were asked to say, oh, did it prevent it from going into the goal?", "tokens": [51592, 293, 586, 498, 291, 645, 2351, 281, 584, 11, 1954, 11, 630, 309, 4871, 309, 490, 516, 666, 264, 3387, 30, 51760], "temperature": 0.0, "avg_logprob": -0.08577958318113371, "compression_ratio": 1.7727272727272727, "no_speech_prob": 8.47242190502584e-05}, {"id": 387, "seek": 181712, "start": 1817.6799999999998, "end": 1822.2399999999998, "text": " My participants say in this case, yes, it did. And the idea is, why is it? Well,", "tokens": [50392, 1222, 10503, 584, 294, 341, 1389, 11, 2086, 11, 309, 630, 13, 400, 264, 1558, 307, 11, 983, 307, 309, 30, 1042, 11, 50620], "temperature": 0.0, "avg_logprob": -0.12042789748220732, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.0010153334587812424}, {"id": 388, "seek": 181712, "start": 1822.2399999999998, "end": 1827.12, "text": " because the block moved out of the way in time, such that Balbi would have gone through the goal", "tokens": [50620, 570, 264, 3461, 4259, 484, 295, 264, 636, 294, 565, 11, 1270, 300, 13140, 5614, 576, 362, 2780, 807, 264, 3387, 50864], "temperature": 0.0, "avg_logprob": -0.12042789748220732, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.0010153334587812424}, {"id": 389, "seek": 181712, "start": 1827.12, "end": 1831.52, "text": " if Ball A hadn't been there. But you may have also noticed that the movement of the block", "tokens": [50864, 498, 10744, 316, 8782, 380, 668, 456, 13, 583, 291, 815, 362, 611, 5694, 300, 264, 3963, 295, 264, 3461, 51084], "temperature": 0.0, "avg_logprob": -0.12042789748220732, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.0010153334587812424}, {"id": 390, "seek": 181712, "start": 1831.52, "end": 1836.1599999999999, "text": " is happening after the balls collided with one another. So not something that you could have", "tokens": [51084, 307, 2737, 934, 264, 9803, 1263, 2112, 365, 472, 1071, 13, 407, 406, 746, 300, 291, 727, 362, 51316], "temperature": 0.0, "avg_logprob": -0.12042789748220732, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.0010153334587812424}, {"id": 391, "seek": 181712, "start": 1836.1599999999999, "end": 1840.1599999999999, "text": " sort of anticipated at this earlier moment in time, or at least had some uncertainty about.", "tokens": [51316, 1333, 295, 23267, 412, 341, 3071, 1623, 294, 565, 11, 420, 412, 1935, 632, 512, 15697, 466, 13, 51516], "temperature": 0.0, "avg_logprob": -0.12042789748220732, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.0010153334587812424}, {"id": 392, "seek": 181712, "start": 1840.9599999999998, "end": 1846.0, "text": " So the basic idea here is to say like, oh, my hypothetical probability at the time", "tokens": [51556, 407, 264, 3875, 1558, 510, 307, 281, 584, 411, 11, 1954, 11, 452, 33053, 8482, 412, 264, 565, 51808], "temperature": 0.0, "avg_logprob": -0.12042789748220732, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.0010153334587812424}, {"id": 393, "seek": 184600, "start": 1846.0, "end": 1849.92, "text": " would Ball B go into the goal if Ball A wasn't there? Well, that's unsure. That depends on", "tokens": [50364, 576, 10744, 363, 352, 666, 264, 3387, 498, 10744, 316, 2067, 380, 456, 30, 1042, 11, 300, 311, 32486, 13, 663, 5946, 322, 50560], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 394, "seek": 184600, "start": 1849.92, "end": 1853.92, "text": " whether or not the block's going to move. So I should give it like a 0.5 or something. I told", "tokens": [50560, 1968, 420, 406, 264, 3461, 311, 516, 281, 1286, 13, 407, 286, 820, 976, 309, 411, 257, 1958, 13, 20, 420, 746, 13, 286, 1907, 50760], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 395, "seek": 184600, "start": 1853.92, "end": 1858.4, "text": " participants it's just as likely to move as it's not. Whereas for the counterfactual probability,", "tokens": [50760, 10503, 309, 311, 445, 382, 3700, 281, 1286, 382, 309, 311, 406, 13, 13813, 337, 264, 5682, 44919, 901, 8482, 11, 50984], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 396, "seek": 184600, "start": 1859.12, "end": 1862.88, "text": " well, I know that it moved in this case. So I should be pretty certain that it would have", "tokens": [51020, 731, 11, 286, 458, 300, 309, 4259, 294, 341, 1389, 13, 407, 286, 820, 312, 1238, 1629, 300, 309, 576, 362, 51208], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 397, "seek": 184600, "start": 1862.88, "end": 1867.28, "text": " gone in if Ball A had been removed. So now I have a way basically of teasing the two apart", "tokens": [51208, 2780, 294, 498, 10744, 316, 632, 668, 7261, 13, 407, 586, 286, 362, 257, 636, 1936, 295, 37720, 264, 732, 4936, 51428], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 398, "seek": 184600, "start": 1867.28, "end": 1871.92, "text": " and can see which one better explains the causal judgments. Is it the hypothetical judgments", "tokens": [51428, 293, 393, 536, 597, 472, 1101, 13948, 264, 38755, 40337, 13, 1119, 309, 264, 33053, 40337, 51660], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 399, "seek": 184600, "start": 1871.92, "end": 1875.68, "text": " that I ask participants to do, or is it the counterfactual judgments that I ask another group", "tokens": [51660, 300, 286, 1029, 10503, 281, 360, 11, 420, 307, 309, 264, 5682, 44919, 901, 40337, 300, 286, 1029, 1071, 1594, 51848], "temperature": 0.0, "avg_logprob": -0.08064686593833877, "compression_ratio": 1.8207282913165266, "no_speech_prob": 0.0001251693320227787}, {"id": 400, "seek": 187568, "start": 1875.68, "end": 1880.8, "text": " to do? And then I ask one group to give causal judgments and then just try to relate them to", "tokens": [50364, 281, 360, 30, 400, 550, 286, 1029, 472, 1594, 281, 976, 38755, 40337, 293, 550, 445, 853, 281, 10961, 552, 281, 50620], "temperature": 0.0, "avg_logprob": -0.08000427435252293, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.00013740701251663268}, {"id": 401, "seek": 187568, "start": 1880.8, "end": 1888.0, "text": " one another. And what I find is when I look at the hypothetical, so maybe I should say a little", "tokens": [50620, 472, 1071, 13, 400, 437, 286, 915, 307, 562, 286, 574, 412, 264, 33053, 11, 370, 1310, 286, 820, 584, 257, 707, 50980], "temperature": 0.0, "avg_logprob": -0.08000427435252293, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.00013740701251663268}, {"id": 402, "seek": 187568, "start": 1888.0, "end": 1892.4, "text": " bit more about that plot here, at the bottom, it basically shows you the initial configuration", "tokens": [50980, 857, 544, 466, 300, 7542, 510, 11, 412, 264, 2767, 11, 309, 1936, 3110, 291, 264, 5883, 11694, 51200], "temperature": 0.0, "avg_logprob": -0.08000427435252293, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.00013740701251663268}, {"id": 403, "seek": 187568, "start": 1892.4, "end": 1898.3200000000002, "text": " of the block. Was it in the way or not? And then did it move yes or no? So in this example here,", "tokens": [51200, 295, 264, 3461, 13, 3027, 309, 294, 264, 636, 420, 406, 30, 400, 550, 630, 309, 1286, 2086, 420, 572, 30, 407, 294, 341, 1365, 510, 11, 51496], "temperature": 0.0, "avg_logprob": -0.08000427435252293, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.00013740701251663268}, {"id": 404, "seek": 187568, "start": 1898.3200000000002, "end": 1902.4, "text": " it's one where it was initially in the way, but it moved. But in the hypothetical condition,", "tokens": [51496, 309, 311, 472, 689, 309, 390, 9105, 294, 264, 636, 11, 457, 309, 4259, 13, 583, 294, 264, 33053, 4188, 11, 51700], "temperature": 0.0, "avg_logprob": -0.08000427435252293, "compression_ratio": 1.758364312267658, "no_speech_prob": 0.00013740701251663268}, {"id": 405, "seek": 190240, "start": 1902.88, "end": 1906.8000000000002, "text": " you don't know that because you only see it until they pause. And then if you look at the", "tokens": [50388, 291, 500, 380, 458, 300, 570, 291, 787, 536, 309, 1826, 436, 10465, 13, 400, 550, 498, 291, 574, 412, 264, 50584], "temperature": 0.0, "avg_logprob": -0.07510558161242255, "compression_ratio": 1.965034965034965, "no_speech_prob": 0.0005524493753910065}, {"id": 406, "seek": 190240, "start": 1906.8000000000002, "end": 1910.16, "text": " hypothetical judgments, they think when it's initially in the way, they think it's a little", "tokens": [50584, 33053, 40337, 11, 436, 519, 562, 309, 311, 9105, 294, 264, 636, 11, 436, 519, 309, 311, 257, 707, 50752], "temperature": 0.0, "avg_logprob": -0.07510558161242255, "compression_ratio": 1.965034965034965, "no_speech_prob": 0.0005524493753910065}, {"id": 407, "seek": 190240, "start": 1910.16, "end": 1913.44, "text": " less likely that it's going to go in. And when it's initially out of the way, they think it's a", "tokens": [50752, 1570, 3700, 300, 309, 311, 516, 281, 352, 294, 13, 400, 562, 309, 311, 9105, 484, 295, 264, 636, 11, 436, 519, 309, 311, 257, 50916], "temperature": 0.0, "avg_logprob": -0.07510558161242255, "compression_ratio": 1.965034965034965, "no_speech_prob": 0.0005524493753910065}, {"id": 408, "seek": 190240, "start": 1913.44, "end": 1917.8400000000001, "text": " little bit more likely. So they're sort of a little bit sticky in terms of what actually happened.", "tokens": [50916, 707, 857, 544, 3700, 13, 407, 436, 434, 1333, 295, 257, 707, 857, 14470, 294, 2115, 295, 437, 767, 2011, 13, 51136], "temperature": 0.0, "avg_logprob": -0.07510558161242255, "compression_ratio": 1.965034965034965, "no_speech_prob": 0.0005524493753910065}, {"id": 409, "seek": 190240, "start": 1919.0400000000002, "end": 1923.52, "text": " For the counterfactual probabilities, pretty much only the final state is what matters.", "tokens": [51196, 1171, 264, 5682, 44919, 901, 33783, 11, 1238, 709, 787, 264, 2572, 1785, 307, 437, 7001, 13, 51420], "temperature": 0.0, "avg_logprob": -0.07510558161242255, "compression_ratio": 1.965034965034965, "no_speech_prob": 0.0005524493753910065}, {"id": 410, "seek": 190240, "start": 1923.52, "end": 1927.92, "text": " If it was out of the way at the end, you think, yeah, it would have gone in. If it was in the way", "tokens": [51420, 759, 309, 390, 484, 295, 264, 636, 412, 264, 917, 11, 291, 519, 11, 1338, 11, 309, 576, 362, 2780, 294, 13, 759, 309, 390, 294, 264, 636, 51640], "temperature": 0.0, "avg_logprob": -0.07510558161242255, "compression_ratio": 1.965034965034965, "no_speech_prob": 0.0005524493753910065}, {"id": 411, "seek": 192792, "start": 1927.92, "end": 1932.64, "text": " at the end, you think it would have missed. And now if you ask people to make causal judgments", "tokens": [50364, 412, 264, 917, 11, 291, 519, 309, 576, 362, 6721, 13, 400, 586, 498, 291, 1029, 561, 281, 652, 38755, 40337, 50600], "temperature": 0.0, "avg_logprob": -0.08415462301789428, "compression_ratio": 1.9792387543252594, "no_speech_prob": 0.00104804546572268}, {"id": 412, "seek": 192792, "start": 1932.64, "end": 1936.96, "text": " in this case, we see that they align very closely with the counterfactual ones and not with the", "tokens": [50600, 294, 341, 1389, 11, 321, 536, 300, 436, 7975, 588, 8185, 365, 264, 5682, 44919, 901, 2306, 293, 406, 365, 264, 50816], "temperature": 0.0, "avg_logprob": -0.08415462301789428, "compression_ratio": 1.9792387543252594, "no_speech_prob": 0.00104804546572268}, {"id": 413, "seek": 192792, "start": 1936.96, "end": 1942.0800000000002, "text": " hypothetical ones. And this was for the kind of missed cases, but the same story again holds", "tokens": [50816, 33053, 2306, 13, 400, 341, 390, 337, 264, 733, 295, 6721, 3331, 11, 457, 264, 912, 1657, 797, 9190, 51072], "temperature": 0.0, "avg_logprob": -0.08415462301789428, "compression_ratio": 1.9792387543252594, "no_speech_prob": 0.00104804546572268}, {"id": 414, "seek": 192792, "start": 1942.0800000000002, "end": 1947.3600000000001, "text": " essentially for the causal cases too. So they think that it caused it when the block would have been", "tokens": [51072, 4476, 337, 264, 38755, 3331, 886, 13, 407, 436, 519, 300, 309, 7008, 309, 562, 264, 3461, 576, 362, 668, 51336], "temperature": 0.0, "avg_logprob": -0.08415462301789428, "compression_ratio": 1.9792387543252594, "no_speech_prob": 0.00104804546572268}, {"id": 415, "seek": 192792, "start": 1947.3600000000001, "end": 1951.2, "text": " in the way at the end, and they don't think that it caused it when the block was would have been", "tokens": [51336, 294, 264, 636, 412, 264, 917, 11, 293, 436, 500, 380, 519, 300, 309, 7008, 309, 562, 264, 3461, 390, 576, 362, 668, 51528], "temperature": 0.0, "avg_logprob": -0.08415462301789428, "compression_ratio": 1.9792387543252594, "no_speech_prob": 0.00104804546572268}, {"id": 416, "seek": 192792, "start": 1951.2, "end": 1956.0, "text": " out of the way at the end. So enough to make this review too happy, but maybe not Michael.", "tokens": [51528, 484, 295, 264, 636, 412, 264, 917, 13, 407, 1547, 281, 652, 341, 3131, 886, 2055, 11, 457, 1310, 406, 5116, 13, 51768], "temperature": 0.0, "avg_logprob": -0.08415462301789428, "compression_ratio": 1.9792387543252594, "no_speech_prob": 0.00104804546572268}, {"id": 417, "seek": 195792, "start": 1958.16, "end": 1963.68, "text": " I'm a happy guy. I'm curious. Can you go back one slide? Just to make sure I understand.", "tokens": [50376, 286, 478, 257, 2055, 2146, 13, 286, 478, 6369, 13, 1664, 291, 352, 646, 472, 4137, 30, 1449, 281, 652, 988, 286, 1223, 13, 50652], "temperature": 0.0, "avg_logprob": -0.14842659387833032, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.004903486929833889}, {"id": 418, "seek": 195792, "start": 1965.3600000000001, "end": 1970.24, "text": " There were two things that changed in that intervention. There was the question you asked,", "tokens": [50736, 821, 645, 732, 721, 300, 3105, 294, 300, 13176, 13, 821, 390, 264, 1168, 291, 2351, 11, 50980], "temperature": 0.0, "avg_logprob": -0.14842659387833032, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.004903486929833889}, {"id": 419, "seek": 195792, "start": 1970.24, "end": 1975.6000000000001, "text": " the hypothetical versus the counterfactual. And it also sounds like the changes in how far they", "tokens": [50980, 264, 33053, 5717, 264, 5682, 44919, 901, 13, 400, 309, 611, 3263, 411, 264, 2962, 294, 577, 1400, 436, 51248], "temperature": 0.0, "avg_logprob": -0.14842659387833032, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.004903486929833889}, {"id": 420, "seek": 195792, "start": 1975.6000000000001, "end": 1981.68, "text": " saw into the video. That's right. That's right. And I'm picturing the counterfactual situation", "tokens": [51248, 1866, 666, 264, 960, 13, 663, 311, 558, 13, 663, 311, 558, 13, 400, 286, 478, 2317, 1345, 264, 5682, 44919, 901, 2590, 51552], "temperature": 0.0, "avg_logprob": -0.14842659387833032, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.004903486929833889}, {"id": 421, "seek": 195792, "start": 1981.68, "end": 1986.64, "text": " where if you ask me the hypothetical question, but showed me the full video, so I see a whole video", "tokens": [51552, 689, 498, 291, 1029, 385, 264, 33053, 1168, 11, 457, 4712, 385, 264, 1577, 960, 11, 370, 286, 536, 257, 1379, 960, 51800], "temperature": 0.0, "avg_logprob": -0.14842659387833032, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.004903486929833889}, {"id": 422, "seek": 198664, "start": 1986.72, "end": 1992.0800000000002, "text": " and then you say, would be going into the goal if A was removed? I don't know.", "tokens": [50368, 293, 550, 291, 584, 11, 576, 312, 516, 666, 264, 3387, 498, 316, 390, 7261, 30, 286, 500, 380, 458, 13, 50636], "temperature": 0.0, "avg_logprob": -0.18155426517609627, "compression_ratio": 1.7873015873015874, "no_speech_prob": 0.0029597256798297167}, {"id": 423, "seek": 198664, "start": 1992.96, "end": 1996.72, "text": " Yeah. Yeah. It's a tricky one. I mean, I guess, you know, you'd have to ask them, like, what did", "tokens": [50680, 865, 13, 865, 13, 467, 311, 257, 12414, 472, 13, 286, 914, 11, 286, 2041, 11, 291, 458, 11, 291, 1116, 362, 281, 1029, 552, 11, 411, 11, 437, 630, 50868], "temperature": 0.0, "avg_logprob": -0.18155426517609627, "compression_ratio": 1.7873015873015874, "no_speech_prob": 0.0029597256798297167}, {"id": 424, "seek": 198664, "start": 1996.72, "end": 2001.2800000000002, "text": " you think? I guess sort of at the time, right? Like before it happened, did you think, and people", "tokens": [50868, 291, 519, 30, 286, 2041, 1333, 295, 412, 264, 565, 11, 558, 30, 1743, 949, 309, 2011, 11, 630, 291, 519, 11, 293, 561, 51096], "temperature": 0.0, "avg_logprob": -0.18155426517609627, "compression_ratio": 1.7873015873015874, "no_speech_prob": 0.0029597256798297167}, {"id": 425, "seek": 198664, "start": 2001.2800000000002, "end": 2004.8000000000002, "text": " are often bad at that, right? We know that from all the hindsight research and so on, that they", "tokens": [51096, 366, 2049, 1578, 412, 300, 11, 558, 30, 492, 458, 300, 490, 439, 264, 44357, 2132, 293, 370, 322, 11, 300, 436, 51272], "temperature": 0.0, "avg_logprob": -0.18155426517609627, "compression_ratio": 1.7873015873015874, "no_speech_prob": 0.0029597256798297167}, {"id": 426, "seek": 198664, "start": 2004.8000000000002, "end": 2009.0400000000002, "text": " have difficulty putting themselves back into the epistemic state, I guess that they had at an", "tokens": [51272, 362, 10360, 3372, 2969, 646, 666, 264, 2388, 468, 3438, 1785, 11, 286, 2041, 300, 436, 632, 412, 364, 51484], "temperature": 0.0, "avg_logprob": -0.18155426517609627, "compression_ratio": 1.7873015873015874, "no_speech_prob": 0.0029597256798297167}, {"id": 427, "seek": 198664, "start": 2009.0400000000002, "end": 2013.68, "text": " earlier point in time, right? So I'm not exactly, I haven't tried that one. I haven't tried showing", "tokens": [51484, 3071, 935, 294, 565, 11, 558, 30, 407, 286, 478, 406, 2293, 11, 286, 2378, 380, 3031, 300, 472, 13, 286, 2378, 380, 3031, 4099, 51716], "temperature": 0.0, "avg_logprob": -0.18155426517609627, "compression_ratio": 1.7873015873015874, "no_speech_prob": 0.0029597256798297167}, {"id": 428, "seek": 201368, "start": 2013.92, "end": 2018.0, "text": " it until the end, but then asking them the hypothetical question, it's possible, of course,", "tokens": [50376, 309, 1826, 264, 917, 11, 457, 550, 3365, 552, 264, 33053, 1168, 11, 309, 311, 1944, 11, 295, 1164, 11, 50580], "temperature": 0.0, "avg_logprob": -0.1059569330776439, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.0006063692853786051}, {"id": 429, "seek": 201368, "start": 2018.0, "end": 2024.88, "text": " that they will confuse it like as a counterfactual question, right? And, but for me, it was still", "tokens": [50580, 300, 436, 486, 28584, 309, 411, 382, 257, 5682, 44919, 901, 1168, 11, 558, 30, 400, 11, 457, 337, 385, 11, 309, 390, 920, 50924], "temperature": 0.0, "avg_logprob": -0.1059569330776439, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.0006063692853786051}, {"id": 430, "seek": 201368, "start": 2024.88, "end": 2028.96, "text": " sufficient, I guess, at least to address this reviewer's concern, because his idea was really,", "tokens": [50924, 11563, 11, 286, 2041, 11, 412, 1935, 281, 2985, 341, 3131, 260, 311, 3136, 11, 570, 702, 1558, 390, 534, 11, 51128], "temperature": 0.0, "avg_logprob": -0.1059569330776439, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.0006063692853786051}, {"id": 431, "seek": 201368, "start": 2028.96, "end": 2033.2, "text": " yeah, that computation is happening earlier, right? It's happening before the causal event of", "tokens": [51128, 1338, 11, 300, 24903, 307, 2737, 3071, 11, 558, 30, 467, 311, 2737, 949, 264, 38755, 2280, 295, 51340], "temperature": 0.0, "avg_logprob": -0.1059569330776439, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.0006063692853786051}, {"id": 432, "seek": 201368, "start": 2033.2, "end": 2037.04, "text": " interest, and then you're storing the output of that computation, in this case, the hypothetical", "tokens": [51340, 1179, 11, 293, 550, 291, 434, 26085, 264, 5598, 295, 300, 24903, 11, 294, 341, 1389, 11, 264, 33053, 51532], "temperature": 0.0, "avg_logprob": -0.1059569330776439, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.0006063692853786051}, {"id": 433, "seek": 201368, "start": 2037.04, "end": 2042.0, "text": " probability, and then just comparing that to what actually happens at the end, right? So it still", "tokens": [51532, 8482, 11, 293, 550, 445, 15763, 300, 281, 437, 767, 2314, 412, 264, 917, 11, 558, 30, 407, 309, 920, 51780], "temperature": 0.0, "avg_logprob": -0.1059569330776439, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.0006063692853786051}, {"id": 434, "seek": 204200, "start": 2042.0, "end": 2051.92, "text": " felt that it's addressing that, but yeah. Okay, so having these two things helps teasing them apart.", "tokens": [50364, 2762, 300, 309, 311, 14329, 300, 11, 457, 1338, 13, 1033, 11, 370, 1419, 613, 732, 721, 3665, 37720, 552, 4936, 13, 50860], "temperature": 0.0, "avg_logprob": -0.0951466393052486, "compression_ratio": 1.7374100719424461, "no_speech_prob": 8.745930972509086e-05}, {"id": 435, "seek": 204200, "start": 2052.72, "end": 2056.16, "text": " Okay, I'll sum up the first part, and then the second part will be short, but that's okay.", "tokens": [50900, 1033, 11, 286, 603, 2408, 493, 264, 700, 644, 11, 293, 550, 264, 1150, 644, 486, 312, 2099, 11, 457, 300, 311, 1392, 13, 51072], "temperature": 0.0, "avg_logprob": -0.0951466393052486, "compression_ratio": 1.7374100719424461, "no_speech_prob": 8.745930972509086e-05}, {"id": 436, "seek": 204200, "start": 2057.2, "end": 2060.8, "text": " So for this counterfactual simulation model, what I've showed you that there's this sort of nice", "tokens": [51124, 407, 337, 341, 5682, 44919, 901, 16575, 2316, 11, 437, 286, 600, 4712, 291, 300, 456, 311, 341, 1333, 295, 1481, 51304], "temperature": 0.0, "avg_logprob": -0.0951466393052486, "compression_ratio": 1.7374100719424461, "no_speech_prob": 8.745930972509086e-05}, {"id": 437, "seek": 204200, "start": 2060.8, "end": 2065.92, "text": " correspondence between people's beliefs about the relevant counterfactual and the causal judgments", "tokens": [51304, 38135, 1296, 561, 311, 13585, 466, 264, 7340, 5682, 44919, 901, 293, 264, 38755, 40337, 51560], "temperature": 0.0, "avg_logprob": -0.0951466393052486, "compression_ratio": 1.7374100719424461, "no_speech_prob": 8.745930972509086e-05}, {"id": 438, "seek": 204200, "start": 2065.92, "end": 2069.92, "text": " that they make, that it looks like that these things are necessary, which you can show with the", "tokens": [51560, 300, 436, 652, 11, 300, 309, 1542, 411, 300, 613, 721, 366, 4818, 11, 597, 291, 393, 855, 365, 264, 51760], "temperature": 0.0, "avg_logprob": -0.0951466393052486, "compression_ratio": 1.7374100719424461, "no_speech_prob": 8.745930972509086e-05}, {"id": 439, "seek": 206992, "start": 2069.92, "end": 2075.04, "text": " teleport or with the, with the brick in and out of the way, that people spontaneously engage in", "tokens": [50364, 28050, 420, 365, 264, 11, 365, 264, 16725, 294, 293, 484, 295, 264, 636, 11, 300, 561, 47632, 4683, 294, 50620], "temperature": 0.0, "avg_logprob": -0.10441152784559461, "compression_ratio": 1.7208588957055215, "no_speech_prob": 0.0001909420097945258}, {"id": 440, "seek": 206992, "start": 2075.04, "end": 2079.6800000000003, "text": " this kind of counterfactual simulation as evidence to the eye movements, and that it's", "tokens": [50620, 341, 733, 295, 5682, 44919, 901, 16575, 382, 4467, 281, 264, 3313, 9981, 11, 293, 300, 309, 311, 50852], "temperature": 0.0, "avg_logprob": -0.10441152784559461, "compression_ratio": 1.7208588957055215, "no_speech_prob": 0.0001909420097945258}, {"id": 441, "seek": 206992, "start": 2079.6800000000003, "end": 2084.2400000000002, "text": " counterfactuals really and not hypotheticals that seem to be important for expanding causal judgments.", "tokens": [50852, 5682, 44919, 901, 82, 534, 293, 406, 33053, 82, 300, 1643, 281, 312, 1021, 337, 14702, 38755, 40337, 13, 51080], "temperature": 0.0, "avg_logprob": -0.10441152784559461, "compression_ratio": 1.7208588957055215, "no_speech_prob": 0.0001909420097945258}, {"id": 442, "seek": 206992, "start": 2085.44, "end": 2089.12, "text": " We've played around with this model like a little bit more. Once you have a hammer, right,", "tokens": [51140, 492, 600, 3737, 926, 365, 341, 2316, 411, 257, 707, 857, 544, 13, 3443, 291, 362, 257, 13017, 11, 558, 11, 51324], "temperature": 0.0, "avg_logprob": -0.10441152784559461, "compression_ratio": 1.7208588957055215, "no_speech_prob": 0.0001909420097945258}, {"id": 443, "seek": 206992, "start": 2089.12, "end": 2093.36, "text": " you find all the nails. So this one is just like looking at slightly more complex cases.", "tokens": [51324, 291, 915, 439, 264, 15394, 13, 407, 341, 472, 307, 445, 411, 1237, 412, 4748, 544, 3997, 3331, 13, 51536], "temperature": 0.0, "avg_logprob": -0.10441152784559461, "compression_ratio": 1.7208588957055215, "no_speech_prob": 0.0001909420097945258}, {"id": 444, "seek": 206992, "start": 2093.36, "end": 2097.12, "text": " This one here, philosophers love, because it's a case of, let me show it again, maybe a case of", "tokens": [51536, 639, 472, 510, 11, 36839, 959, 11, 570, 309, 311, 257, 1389, 295, 11, 718, 385, 855, 309, 797, 11, 1310, 257, 1389, 295, 51724], "temperature": 0.0, "avg_logprob": -0.10441152784559461, "compression_ratio": 1.7208588957055215, "no_speech_prob": 0.0001909420097945258}, {"id": 445, "seek": 209712, "start": 2097.12, "end": 2103.04, "text": " double prevention, where B prevents ball A from preventing ball E from going through the gate,", "tokens": [50364, 3834, 14630, 11, 689, 363, 22367, 2594, 316, 490, 19965, 2594, 462, 490, 516, 807, 264, 8539, 11, 50660], "temperature": 0.0, "avg_logprob": -0.1419262488683065, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.00023770293046254665}, {"id": 446, "seek": 209712, "start": 2103.04, "end": 2107.92, "text": " right, because knocks it out. It happens in, maybe in football, probably happens often when", "tokens": [50660, 558, 11, 570, 40815, 309, 484, 13, 467, 2314, 294, 11, 1310, 294, 7346, 11, 1391, 2314, 2049, 562, 50904], "temperature": 0.0, "avg_logprob": -0.1419262488683065, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.00023770293046254665}, {"id": 447, "seek": 209712, "start": 2107.92, "end": 2111.68, "text": " one tackles like another person that would have tackled the person running with the ball, right.", "tokens": [50904, 472, 9426, 904, 411, 1071, 954, 300, 576, 362, 9426, 1493, 264, 954, 2614, 365, 264, 2594, 11, 558, 13, 51092], "temperature": 0.0, "avg_logprob": -0.1419262488683065, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.00023770293046254665}, {"id": 448, "seek": 209712, "start": 2111.68, "end": 2115.2799999999997, "text": " And so you might say, oh, to what extent did that cause it? You can also look at omissions when", "tokens": [51092, 400, 370, 291, 1062, 584, 11, 1954, 11, 281, 437, 8396, 630, 300, 3082, 309, 30, 509, 393, 611, 574, 412, 3406, 7922, 562, 51272], "temperature": 0.0, "avg_logprob": -0.1419262488683065, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.00023770293046254665}, {"id": 449, "seek": 209712, "start": 2115.2799999999997, "end": 2120.24, "text": " nothing is happening. So ball A is just chilling here in the corner, and you might still ask,", "tokens": [51272, 1825, 307, 2737, 13, 407, 2594, 316, 307, 445, 31047, 510, 294, 264, 4538, 11, 293, 291, 1062, 920, 1029, 11, 51520], "temperature": 0.0, "avg_logprob": -0.1419262488683065, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.00023770293046254665}, {"id": 450, "seek": 209712, "start": 2120.24, "end": 2123.8399999999997, "text": " oh, did it go in because ball A didn't hit it, right? And now you could imagine, well, if it had hit", "tokens": [51520, 1954, 11, 630, 309, 352, 294, 570, 2594, 316, 994, 380, 2045, 309, 11, 558, 30, 400, 586, 291, 727, 3811, 11, 731, 11, 498, 309, 632, 2045, 51700], "temperature": 0.0, "avg_logprob": -0.1419262488683065, "compression_ratio": 1.7770897832817338, "no_speech_prob": 0.00023770293046254665}, {"id": 451, "seek": 212384, "start": 2123.92, "end": 2127.6000000000004, "text": " it, what would have happened in this case? And we can also look at cases where really", "tokens": [50368, 309, 11, 437, 576, 362, 2011, 294, 341, 1389, 30, 400, 321, 393, 611, 574, 412, 3331, 689, 534, 50552], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 452, "seek": 212384, "start": 2127.6000000000004, "end": 2132.08, "text": " nothing is happening at all. So here's just a tower of blocks, right, and you might still wonder,", "tokens": [50552, 1825, 307, 2737, 412, 439, 13, 407, 510, 311, 445, 257, 10567, 295, 8474, 11, 558, 11, 293, 291, 1062, 920, 2441, 11, 50776], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 453, "seek": 212384, "start": 2132.08, "end": 2135.6000000000004, "text": " oh, to what extent is this black one here responsible for the other one staying on the table?", "tokens": [50776, 1954, 11, 281, 437, 8396, 307, 341, 2211, 472, 510, 6250, 337, 264, 661, 472, 7939, 322, 264, 3199, 30, 50952], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 454, "seek": 212384, "start": 2136.1600000000003, "end": 2139.28, "text": " And even though, yeah, there's nothing happening, right, you might still say, well,", "tokens": [50980, 400, 754, 1673, 11, 1338, 11, 456, 311, 1825, 2737, 11, 558, 11, 291, 1062, 920, 584, 11, 731, 11, 51136], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 455, "seek": 212384, "start": 2139.28, "end": 2143.28, "text": " how do you answer this question? Maybe by doing something like playing Jenga in your mind, right,", "tokens": [51136, 577, 360, 291, 1867, 341, 1168, 30, 2704, 538, 884, 746, 411, 2433, 508, 31494, 294, 428, 1575, 11, 558, 11, 51336], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 456, "seek": 212384, "start": 2143.28, "end": 2147.44, "text": " imagining it being removed, and then what would have happened to the scene? So that even just", "tokens": [51336, 27798, 309, 885, 7261, 11, 293, 550, 437, 576, 362, 2011, 281, 264, 4145, 30, 407, 300, 754, 445, 51544], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 457, "seek": 212384, "start": 2147.44, "end": 2152.8, "text": " physical support in some sense is very closely related to ideas of causation, right. What it means", "tokens": [51544, 4001, 1406, 294, 512, 2020, 307, 588, 8185, 4077, 281, 3487, 295, 3302, 399, 11, 558, 13, 708, 309, 1355, 51812], "temperature": 0.0, "avg_logprob": -0.10622065580343898, "compression_ratio": 1.826330532212885, "no_speech_prob": 0.0021457658149302006}, {"id": 458, "seek": 215280, "start": 2152.8, "end": 2159.44, "text": " to support is essentially to prevent something from falling. Okay, so that was part one. Now a", "tokens": [50364, 281, 1406, 307, 4476, 281, 4871, 746, 490, 7440, 13, 1033, 11, 370, 300, 390, 644, 472, 13, 823, 257, 50696], "temperature": 0.0, "avg_logprob": -0.10958256963956153, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.00030049524502828717}, {"id": 459, "seek": 215280, "start": 2159.44, "end": 2165.1200000000003, "text": " sort of short version of part two. And so responsibility attribution was something that I've", "tokens": [50696, 1333, 295, 2099, 3037, 295, 644, 732, 13, 400, 370, 6357, 9080, 1448, 390, 746, 300, 286, 600, 50980], "temperature": 0.0, "avg_logprob": -0.10958256963956153, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.00030049524502828717}, {"id": 460, "seek": 215280, "start": 2165.1200000000003, "end": 2170.32, "text": " been into for quite a while and was also my motivating thing. And then I drifted off into", "tokens": [50980, 668, 666, 337, 1596, 257, 1339, 293, 390, 611, 452, 41066, 551, 13, 400, 550, 286, 19699, 292, 766, 666, 51240], "temperature": 0.0, "avg_logprob": -0.10958256963956153, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.00030049524502828717}, {"id": 461, "seek": 215280, "start": 2170.32, "end": 2175.04, "text": " causality world mostly just because physics engines were around at the time. So it was like, oh,", "tokens": [51240, 3302, 1860, 1002, 5240, 445, 570, 10649, 12982, 645, 926, 412, 264, 565, 13, 407, 309, 390, 411, 11, 1954, 11, 51476], "temperature": 0.0, "avg_logprob": -0.10958256963956153, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.00030049524502828717}, {"id": 462, "seek": 215280, "start": 2175.04, "end": 2179.6800000000003, "text": " now I can use those. And with around at the time, I mean, I was a postdoc with Josh Tenenbaum back", "tokens": [51476, 586, 286, 393, 764, 729, 13, 400, 365, 926, 412, 264, 565, 11, 286, 914, 11, 286, 390, 257, 2183, 39966, 365, 9785, 9380, 268, 46641, 646, 51708], "temperature": 0.0, "avg_logprob": -0.10958256963956153, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.00030049524502828717}, {"id": 463, "seek": 217968, "start": 2179.68, "end": 2184.24, "text": " then and physics engines were all the rage at the time. And I said, okay, now I'll also use them.", "tokens": [50364, 550, 293, 10649, 12982, 645, 439, 264, 20133, 412, 264, 565, 13, 400, 286, 848, 11, 1392, 11, 586, 286, 603, 611, 764, 552, 13, 50592], "temperature": 0.0, "avg_logprob": -0.12720057543586283, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0002906728768721223}, {"id": 464, "seek": 217968, "start": 2184.24, "end": 2189.3599999999997, "text": " And there aren't really yet, although I guess Michael is working on it, psychology engines,", "tokens": [50592, 400, 456, 3212, 380, 534, 1939, 11, 4878, 286, 2041, 5116, 307, 1364, 322, 309, 11, 15105, 12982, 11, 50848], "temperature": 0.0, "avg_logprob": -0.12720057543586283, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0002906728768721223}, {"id": 465, "seek": 217968, "start": 2189.3599999999997, "end": 2192.48, "text": " right, that is easy where you could just have agents and think about what they would have done.", "tokens": [50848, 558, 11, 300, 307, 1858, 689, 291, 727, 445, 362, 12554, 293, 519, 466, 437, 436, 576, 362, 1096, 13, 51004], "temperature": 0.0, "avg_logprob": -0.12720057543586283, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0002906728768721223}, {"id": 466, "seek": 217968, "start": 2193.7599999999998, "end": 2198.3199999999997, "text": " So this work that I had done on responsibility attribution wasn't particularly social, also", "tokens": [51068, 407, 341, 589, 300, 286, 632, 1096, 322, 6357, 9080, 1448, 2067, 380, 4098, 2093, 11, 611, 51296], "temperature": 0.0, "avg_logprob": -0.12720057543586283, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0002906728768721223}, {"id": 467, "seek": 217968, "start": 2198.3199999999997, "end": 2201.8399999999997, "text": " didn't really involve simulation, I think. And there was one experiment that got a little bit", "tokens": [51296, 994, 380, 534, 9494, 16575, 11, 286, 519, 13, 400, 456, 390, 472, 5120, 300, 658, 257, 707, 857, 51472], "temperature": 0.0, "avg_logprob": -0.12720057543586283, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0002906728768721223}, {"id": 468, "seek": 217968, "start": 2201.8399999999997, "end": 2207.2, "text": " closer that I'll briefly share with you here on a paper called Moral Dynamics. And it will look", "tokens": [51472, 4966, 300, 286, 603, 10515, 2073, 365, 291, 510, 322, 257, 3035, 1219, 5146, 304, 22947, 1167, 13, 400, 309, 486, 574, 51740], "temperature": 0.0, "avg_logprob": -0.12720057543586283, "compression_ratio": 1.7027027027027026, "no_speech_prob": 0.0002906728768721223}, {"id": 469, "seek": 220720, "start": 2207.2, "end": 2211.7599999999998, "text": " very billiard ball world like I haven't moved too far away from the billiard balls, but this kind", "tokens": [50364, 588, 2961, 72, 515, 2594, 1002, 411, 286, 2378, 380, 4259, 886, 1400, 1314, 490, 264, 2961, 72, 515, 9803, 11, 457, 341, 733, 50592], "temperature": 0.0, "avg_logprob": -0.15775569971056952, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0006261596572585404}, {"id": 470, "seek": 220720, "start": 2211.7599999999998, "end": 2215.3599999999997, "text": " of that's somewhat agentive, right? So and so we could show people like a video clip like this", "tokens": [50592, 295, 300, 311, 8344, 9461, 488, 11, 558, 30, 407, 293, 370, 321, 727, 855, 561, 411, 257, 960, 7353, 411, 341, 50772], "temperature": 0.0, "avg_logprob": -0.15775569971056952, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0006261596572585404}, {"id": 471, "seek": 220720, "start": 2215.3599999999997, "end": 2219.8399999999997, "text": " and then ask them, what about extent do you think that blue was responsible that the green one got", "tokens": [50772, 293, 550, 1029, 552, 11, 437, 466, 8396, 360, 291, 519, 300, 3344, 390, 6250, 300, 264, 3092, 472, 658, 50996], "temperature": 0.0, "avg_logprob": -0.15775569971056952, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0006261596572585404}, {"id": 472, "seek": 220720, "start": 2219.8399999999997, "end": 2225.3599999999997, "text": " harmed in this case here? And our inspiration here came from a paper called Moral Kinematics where", "tokens": [50996, 41478, 294, 341, 1389, 510, 30, 400, 527, 10249, 510, 1361, 490, 257, 3035, 1219, 5146, 304, 27950, 37541, 689, 51272], "temperature": 0.0, "avg_logprob": -0.15775569971056952, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0006261596572585404}, {"id": 473, "seek": 220720, "start": 2225.3599999999997, "end": 2229.9199999999996, "text": " they basically argued, again, it's somewhat more actualist view and saying, okay, there's certain", "tokens": [51272, 436, 1936, 20219, 11, 797, 11, 309, 311, 8344, 544, 3539, 468, 1910, 293, 1566, 11, 1392, 11, 456, 311, 1629, 51500], "temperature": 0.0, "avg_logprob": -0.15775569971056952, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0006261596572585404}, {"id": 474, "seek": 220720, "start": 2229.9199999999996, "end": 2233.8399999999997, "text": " features that people are picking up on in these scenes, like the duration of contact,", "tokens": [51500, 4122, 300, 561, 366, 8867, 493, 322, 294, 613, 8026, 11, 411, 264, 16365, 295, 3385, 11, 51696], "temperature": 0.0, "avg_logprob": -0.15775569971056952, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0006261596572585404}, {"id": 475, "seek": 223384, "start": 2233.84, "end": 2238.1600000000003, "text": " how far things moved and things like that. And then they directly mapped from these features", "tokens": [50364, 577, 1400, 721, 4259, 293, 721, 411, 300, 13, 400, 550, 436, 3838, 33318, 490, 613, 4122, 50580], "temperature": 0.0, "avg_logprob": -0.10612998498934452, "compression_ratio": 1.800751879699248, "no_speech_prob": 0.00045803768443875015}, {"id": 476, "seek": 223384, "start": 2238.1600000000003, "end": 2244.6400000000003, "text": " of the scene to the moral judgment in this case. And we liked the general setup, but didn't really", "tokens": [50580, 295, 264, 4145, 281, 264, 9723, 12216, 294, 341, 1389, 13, 400, 321, 4501, 264, 2674, 8657, 11, 457, 994, 380, 534, 50904], "temperature": 0.0, "avg_logprob": -0.10612998498934452, "compression_ratio": 1.800751879699248, "no_speech_prob": 0.00045803768443875015}, {"id": 477, "seek": 223384, "start": 2244.6400000000003, "end": 2250.48, "text": " like that model like as much. So we proposed another model that has a slightly different title,", "tokens": [50904, 411, 300, 2316, 411, 382, 709, 13, 407, 321, 10348, 1071, 2316, 300, 575, 257, 4748, 819, 4876, 11, 51196], "temperature": 0.0, "avg_logprob": -0.10612998498934452, "compression_ratio": 1.800751879699248, "no_speech_prob": 0.00045803768443875015}, {"id": 478, "seek": 223384, "start": 2250.48, "end": 2254.96, "text": " Moral Dynamics instead. And we thought, okay, these features are important, but the features are", "tokens": [51196, 5146, 304, 22947, 1167, 2602, 13, 400, 321, 1194, 11, 1392, 11, 613, 4122, 366, 1021, 11, 457, 264, 4122, 366, 51420], "temperature": 0.0, "avg_logprob": -0.10612998498934452, "compression_ratio": 1.800751879699248, "no_speech_prob": 0.00045803768443875015}, {"id": 479, "seek": 223384, "start": 2254.96, "end": 2260.6400000000003, "text": " important in that they give us evidence for the latent variables and that those are ultimately", "tokens": [51420, 1021, 294, 300, 436, 976, 505, 4467, 337, 264, 48994, 9102, 293, 300, 729, 366, 6284, 51704], "temperature": 0.0, "avg_logprob": -0.10612998498934452, "compression_ratio": 1.800751879699248, "no_speech_prob": 0.00045803768443875015}, {"id": 480, "seek": 226064, "start": 2260.64, "end": 2264.8799999999997, "text": " the ones that I care about. And in this case, what are the latent ones that we thought one,", "tokens": [50364, 264, 2306, 300, 286, 1127, 466, 13, 400, 294, 341, 1389, 11, 437, 366, 264, 48994, 2306, 300, 321, 1194, 472, 11, 50576], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 481, "seek": 226064, "start": 2264.8799999999997, "end": 2268.8799999999997, "text": " not very surprisingly here on the right hand side causality, but did you think that it actually", "tokens": [50576, 406, 588, 17600, 510, 322, 264, 558, 1011, 1252, 3302, 1860, 11, 457, 630, 291, 519, 300, 309, 767, 50776], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 482, "seek": 226064, "start": 2268.8799999999997, "end": 2273.8399999999997, "text": " caused it, you know, to for this negative outcome to happen. And then the left side,", "tokens": [50776, 7008, 309, 11, 291, 458, 11, 281, 337, 341, 3671, 9700, 281, 1051, 13, 400, 550, 264, 1411, 1252, 11, 51024], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 483, "seek": 226064, "start": 2273.8399999999997, "end": 2277.6, "text": " the intuitive psychology part, very kind of minimal in this case here. But it's basically", "tokens": [51024, 264, 21769, 15105, 644, 11, 588, 733, 295, 13206, 294, 341, 1389, 510, 13, 583, 309, 311, 1936, 51212], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 484, "seek": 226064, "start": 2277.6, "end": 2282.16, "text": " saying like, well, maybe these features give you some evidence about like how much the agent", "tokens": [51212, 1566, 411, 11, 731, 11, 1310, 613, 4122, 976, 291, 512, 4467, 466, 411, 577, 709, 264, 9461, 51440], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 485, "seek": 226064, "start": 2282.16, "end": 2286.7999999999997, "text": " actually wanted to bring about this negative outcome. So if you think, for example, if somebody", "tokens": [51440, 767, 1415, 281, 1565, 466, 341, 3671, 9700, 13, 407, 498, 291, 519, 11, 337, 1365, 11, 498, 2618, 51672], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 486, "seek": 226064, "start": 2286.7999999999997, "end": 2290.48, "text": " really wants something to happen, then they're willing to incur a larger cost to make it happen.", "tokens": [51672, 534, 2738, 746, 281, 1051, 11, 550, 436, 434, 4950, 281, 35774, 257, 4833, 2063, 281, 652, 309, 1051, 13, 51856], "temperature": 0.0, "avg_logprob": -0.09453644657766583, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.0038812803104519844}, {"id": 487, "seek": 229064, "start": 2291.6, "end": 2295.44, "text": " Putting a lot of effort, for example. So if somebody puts in a lot of effort into something,", "tokens": [50412, 31367, 257, 688, 295, 4630, 11, 337, 1365, 13, 407, 498, 2618, 8137, 294, 257, 688, 295, 4630, 666, 746, 11, 50604], "temperature": 0.0, "avg_logprob": -0.08454617901124815, "compression_ratio": 1.855305466237942, "no_speech_prob": 7.965836994117126e-05}, {"id": 488, "seek": 229064, "start": 2295.44, "end": 2299.92, "text": " you know that they must have really valued it. And if somebody really valued some negative outcome,", "tokens": [50604, 291, 458, 300, 436, 1633, 362, 534, 22608, 309, 13, 400, 498, 2618, 534, 22608, 512, 3671, 9700, 11, 50828], "temperature": 0.0, "avg_logprob": -0.08454617901124815, "compression_ratio": 1.855305466237942, "no_speech_prob": 7.965836994117126e-05}, {"id": 489, "seek": 229064, "start": 2299.92, "end": 2304.8799999999997, "text": " well, that's a bad thing. That was roughly the idea here. And we could then show that if we have", "tokens": [50828, 731, 11, 300, 311, 257, 1578, 551, 13, 663, 390, 9810, 264, 1558, 510, 13, 400, 321, 727, 550, 855, 300, 498, 321, 362, 51076], "temperature": 0.0, "avg_logprob": -0.08454617901124815, "compression_ratio": 1.855305466237942, "no_speech_prob": 7.965836994117126e-05}, {"id": 490, "seek": 229064, "start": 2304.8799999999997, "end": 2310.4, "text": " a model that just basically infers the amount of effort that some agent exerted and tried to map", "tokens": [51076, 257, 2316, 300, 445, 1936, 1536, 433, 264, 2372, 295, 4630, 300, 512, 9461, 31941, 292, 293, 3031, 281, 4471, 51352], "temperature": 0.0, "avg_logprob": -0.08454617901124815, "compression_ratio": 1.855305466237942, "no_speech_prob": 7.965836994117126e-05}, {"id": 491, "seek": 229064, "start": 2310.4, "end": 2315.8399999999997, "text": " that onto the responsibility that worked kind of, you know, okay-ish. If we only took into account", "tokens": [51352, 300, 3911, 264, 6357, 300, 2732, 733, 295, 11, 291, 458, 11, 1392, 12, 742, 13, 759, 321, 787, 1890, 666, 2696, 51624], "temperature": 0.0, "avg_logprob": -0.08454617901124815, "compression_ratio": 1.855305466237942, "no_speech_prob": 7.965836994117126e-05}, {"id": 492, "seek": 229064, "start": 2315.8399999999997, "end": 2320.16, "text": " the causal role that some agent played and tried to use that to explain the extent to which", "tokens": [51624, 264, 38755, 3090, 300, 512, 9461, 3737, 293, 3031, 281, 764, 300, 281, 2903, 264, 8396, 281, 597, 51840], "temperature": 0.0, "avg_logprob": -0.08454617901124815, "compression_ratio": 1.855305466237942, "no_speech_prob": 7.965836994117126e-05}, {"id": 493, "seek": 232016, "start": 2320.16, "end": 2324.96, "text": " they're held responsible, that worked okay-ish. But if we now took a model that takes both of", "tokens": [50364, 436, 434, 5167, 6250, 11, 300, 2732, 1392, 12, 742, 13, 583, 498, 321, 586, 1890, 257, 2316, 300, 2516, 1293, 295, 50604], "temperature": 0.0, "avg_logprob": -0.07355690730437067, "compression_ratio": 1.8453947368421053, "no_speech_prob": 0.0001558906224090606}, {"id": 494, "seek": 232016, "start": 2324.96, "end": 2329.2, "text": " these components into account, that worked pretty well, which was roughly in line with this kind", "tokens": [50604, 613, 6677, 666, 2696, 11, 300, 2732, 1238, 731, 11, 597, 390, 9810, 294, 1622, 365, 341, 733, 50816], "temperature": 0.0, "avg_logprob": -0.07355690730437067, "compression_ratio": 1.8453947368421053, "no_speech_prob": 0.0001558906224090606}, {"id": 495, "seek": 232016, "start": 2329.2, "end": 2334.3999999999996, "text": " of unsurprisingly, now this framework that I laid out at the beginning, right, that when we assign", "tokens": [50816, 295, 2693, 374, 34408, 11, 586, 341, 8388, 300, 286, 9897, 484, 412, 264, 2863, 11, 558, 11, 300, 562, 321, 6269, 51076], "temperature": 0.0, "avg_logprob": -0.07355690730437067, "compression_ratio": 1.8453947368421053, "no_speech_prob": 0.0001558906224090606}, {"id": 496, "seek": 232016, "start": 2334.3999999999996, "end": 2338.64, "text": " responsibility to others, we don't just care about the causal role that they played, but also what", "tokens": [51076, 6357, 281, 2357, 11, 321, 500, 380, 445, 1127, 466, 264, 38755, 3090, 300, 436, 3737, 11, 457, 611, 437, 51288], "temperature": 0.0, "avg_logprob": -0.07355690730437067, "compression_ratio": 1.8453947368421053, "no_speech_prob": 0.0001558906224090606}, {"id": 497, "seek": 232016, "start": 2338.64, "end": 2342.72, "text": " the action tells me about the kind of person that they are. In this case, the action tells me", "tokens": [51288, 264, 3069, 5112, 385, 466, 264, 733, 295, 954, 300, 436, 366, 13, 682, 341, 1389, 11, 264, 3069, 5112, 385, 51492], "temperature": 0.0, "avg_logprob": -0.07355690730437067, "compression_ratio": 1.8453947368421053, "no_speech_prob": 0.0001558906224090606}, {"id": 498, "seek": 232016, "start": 2342.72, "end": 2345.8399999999997, "text": " something about the desire that they had to bring about this negative outcome.", "tokens": [51492, 746, 466, 264, 7516, 300, 436, 632, 281, 1565, 466, 341, 3671, 9700, 13, 51648], "temperature": 0.0, "avg_logprob": -0.07355690730437067, "compression_ratio": 1.8453947368421053, "no_speech_prob": 0.0001558906224090606}, {"id": 499, "seek": 234584, "start": 2346.48, "end": 2353.04, "text": " Okay. But still, we didn't really have a real model of agents in this case. We still sort of", "tokens": [50396, 1033, 13, 583, 920, 11, 321, 994, 380, 534, 362, 257, 957, 2316, 295, 12554, 294, 341, 1389, 13, 492, 920, 1333, 295, 50724], "temperature": 0.0, "avg_logprob": -0.1545428873222565, "compression_ratio": 1.6714801444043321, "no_speech_prob": 8.47260671434924e-05}, {"id": 500, "seek": 234584, "start": 2353.04, "end": 2358.2400000000002, "text": " basically just use the physics engine. Also, we weren't able to talk about intentions, and it's", "tokens": [50724, 1936, 445, 764, 264, 10649, 2848, 13, 2743, 11, 321, 4999, 380, 1075, 281, 751, 466, 19354, 11, 293, 309, 311, 50984], "temperature": 0.0, "avg_logprob": -0.1545428873222565, "compression_ratio": 1.6714801444043321, "no_speech_prob": 8.47260671434924e-05}, {"id": 501, "seek": 234584, "start": 2358.2400000000002, "end": 2363.1200000000003, "text": " clearly important often when people talk about responsibility. And also still our kind of factual", "tokens": [50984, 4448, 1021, 2049, 562, 561, 751, 466, 6357, 13, 400, 611, 920, 527, 733, 295, 48029, 51228], "temperature": 0.0, "avg_logprob": -0.1545428873222565, "compression_ratio": 1.6714801444043321, "no_speech_prob": 8.47260671434924e-05}, {"id": 502, "seek": 234584, "start": 2363.1200000000003, "end": 2366.88, "text": " simulation here was basically purely physical, just seeing how this thing would have moved", "tokens": [51228, 16575, 510, 390, 1936, 17491, 4001, 11, 445, 2577, 577, 341, 551, 576, 362, 4259, 51416], "temperature": 0.0, "avg_logprob": -0.1545428873222565, "compression_ratio": 1.6714801444043321, "no_speech_prob": 8.47260671434924e-05}, {"id": 503, "seek": 234584, "start": 2366.88, "end": 2374.88, "text": " without the other one. So I don't have the skills to make it happen with sort of more", "tokens": [51416, 1553, 264, 661, 472, 13, 407, 286, 500, 380, 362, 264, 3942, 281, 652, 309, 1051, 365, 1333, 295, 544, 51816], "temperature": 0.0, "avg_logprob": -0.1545428873222565, "compression_ratio": 1.6714801444043321, "no_speech_prob": 8.47260671434924e-05}, {"id": 504, "seek": 237488, "start": 2374.88, "end": 2379.12, "text": " agentive agents, but luckily now that I'm here, I get to work out with all these smart people,", "tokens": [50364, 9461, 488, 12554, 11, 457, 22880, 586, 300, 286, 478, 510, 11, 286, 483, 281, 589, 484, 365, 439, 613, 4069, 561, 11, 50576], "temperature": 0.0, "avg_logprob": -0.14640032124315572, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006655149627476931}, {"id": 505, "seek": 237488, "start": 2379.84, "end": 2383.76, "text": " and here's my PhD student, Sarah Wu, and our research assistant, Shruti Sreeta,", "tokens": [50612, 293, 510, 311, 452, 14476, 3107, 11, 9519, 17287, 11, 293, 527, 2132, 10994, 11, 1160, 24316, 72, 318, 265, 7664, 11, 50808], "temperature": 0.0, "avg_logprob": -0.14640032124315572, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006655149627476931}, {"id": 506, "seek": 237488, "start": 2383.76, "end": 2388.0, "text": " and they've looked into cases now that are a little bit more agentive. They're still kind of in", "tokens": [50808, 293, 436, 600, 2956, 666, 3331, 586, 300, 366, 257, 707, 857, 544, 9461, 488, 13, 814, 434, 920, 733, 295, 294, 51020], "temperature": 0.0, "avg_logprob": -0.14640032124315572, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006655149627476931}, {"id": 507, "seek": 237488, "start": 2388.0, "end": 2393.76, "text": " in grid world, but at least now planning and intentions and things like that are involved.", "tokens": [51020, 294, 10748, 1002, 11, 457, 412, 1935, 586, 5038, 293, 19354, 293, 721, 411, 300, 366, 3288, 13, 51308], "temperature": 0.0, "avg_logprob": -0.14640032124315572, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006655149627476931}, {"id": 508, "seek": 237488, "start": 2394.48, "end": 2399.04, "text": " And here's the basic setup. So this is inspired by some previous work that has looked into helping", "tokens": [51344, 400, 510, 311, 264, 3875, 8657, 13, 407, 341, 307, 7547, 538, 512, 3894, 589, 300, 575, 2956, 666, 4315, 51572], "temperature": 0.0, "avg_logprob": -0.14640032124315572, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006655149627476931}, {"id": 509, "seek": 239904, "start": 2399.04, "end": 2405.84, "text": " and hindering as a case study. And what they did is essentially they said, well, what it means", "tokens": [50364, 293, 20138, 1794, 382, 257, 1389, 2979, 13, 400, 437, 436, 630, 307, 4476, 436, 848, 11, 731, 11, 437, 309, 1355, 50704], "temperature": 0.0, "avg_logprob": -0.12207899866877375, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.005379965528845787}, {"id": 510, "seek": 239904, "start": 2405.84, "end": 2411.52, "text": " for somebody to intend to help someone is that their utility function includes the other person's", "tokens": [50704, 337, 2618, 281, 19759, 281, 854, 1580, 307, 300, 641, 14877, 2445, 5974, 264, 661, 954, 311, 50988], "temperature": 0.0, "avg_logprob": -0.12207899866877375, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.005379965528845787}, {"id": 511, "seek": 239904, "start": 2411.52, "end": 2417.44, "text": " utility with a positive sign. Intending to help just means wanting to bring positive utility,", "tokens": [50988, 14877, 365, 257, 3353, 1465, 13, 5681, 2029, 281, 854, 445, 1355, 7935, 281, 1565, 3353, 14877, 11, 51284], "temperature": 0.0, "avg_logprob": -0.12207899866877375, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.005379965528845787}, {"id": 512, "seek": 239904, "start": 2417.44, "end": 2421.84, "text": " at least in this framework, to the other person. And intending to hinder puts a negative sign,", "tokens": [51284, 412, 1935, 294, 341, 8388, 11, 281, 264, 661, 954, 13, 400, 560, 2029, 281, 276, 5669, 8137, 257, 3671, 1465, 11, 51504], "temperature": 0.0, "avg_logprob": -0.12207899866877375, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.005379965528845787}, {"id": 513, "seek": 239904, "start": 2421.84, "end": 2427.7599999999998, "text": " like now I want it that the other person is a low utility. So it turns out though that", "tokens": [51504, 411, 586, 286, 528, 309, 300, 264, 661, 954, 307, 257, 2295, 14877, 13, 407, 309, 4523, 484, 1673, 300, 51800], "temperature": 0.0, "avg_logprob": -0.12207899866877375, "compression_ratio": 1.8645418326693226, "no_speech_prob": 0.005379965528845787}, {"id": 514, "seek": 242776, "start": 2427.76, "end": 2432.6400000000003, "text": " intending to help or hinder versus actually helping or hindering is not necessarily the same", "tokens": [50364, 560, 2029, 281, 854, 420, 276, 5669, 5717, 767, 4315, 420, 20138, 1794, 307, 406, 4725, 264, 912, 50608], "temperature": 0.0, "avg_logprob": -0.08711115296904023, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00038574219797737896}, {"id": 515, "seek": 242776, "start": 2432.6400000000003, "end": 2438.4, "text": " thing. So here's an example. I don't have a child yet, but at some point maybe we'll have a child,", "tokens": [50608, 551, 13, 407, 510, 311, 364, 1365, 13, 286, 500, 380, 362, 257, 1440, 1939, 11, 457, 412, 512, 935, 1310, 321, 603, 362, 257, 1440, 11, 50896], "temperature": 0.0, "avg_logprob": -0.08711115296904023, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00038574219797737896}, {"id": 516, "seek": 242776, "start": 2438.4, "end": 2442.0, "text": " and then if I go grocery shopping with the child, there probably will be a period of time where", "tokens": [50896, 293, 550, 498, 286, 352, 14410, 8688, 365, 264, 1440, 11, 456, 1391, 486, 312, 257, 2896, 295, 565, 689, 51076], "temperature": 0.0, "avg_logprob": -0.08711115296904023, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00038574219797737896}, {"id": 517, "seek": 242776, "start": 2442.0, "end": 2449.28, "text": " they're not actually helping. They're sort of like trying to help, but kind of making it worse,", "tokens": [51076, 436, 434, 406, 767, 4315, 13, 814, 434, 1333, 295, 411, 1382, 281, 854, 11, 457, 733, 295, 1455, 309, 5324, 11, 51440], "temperature": 0.0, "avg_logprob": -0.08711115296904023, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00038574219797737896}, {"id": 518, "seek": 242776, "start": 2449.28, "end": 2452.88, "text": " at least in terms of efficiency and so on. It's going to take longer. Of course, it's useful", "tokens": [51440, 412, 1935, 294, 2115, 295, 10493, 293, 370, 322, 13, 467, 311, 516, 281, 747, 2854, 13, 2720, 1164, 11, 309, 311, 4420, 51620], "temperature": 0.0, "avg_logprob": -0.08711115296904023, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00038574219797737896}, {"id": 519, "seek": 242776, "start": 2452.88, "end": 2457.2000000000003, "text": " because eventually they will be helpful. I have to go through that process just like a PhD student.", "tokens": [51620, 570, 4728, 436, 486, 312, 4961, 13, 286, 362, 281, 352, 807, 300, 1399, 445, 411, 257, 14476, 3107, 13, 51836], "temperature": 0.0, "avg_logprob": -0.08711115296904023, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.00038574219797737896}, {"id": 520, "seek": 245776, "start": 2458.32, "end": 2472.32, "text": " So yeah, so you go through that process, and then you might intend to be helpful,", "tokens": [50392, 407, 1338, 11, 370, 291, 352, 807, 300, 1399, 11, 293, 550, 291, 1062, 19759, 281, 312, 4961, 11, 51092], "temperature": 0.0, "avg_logprob": -0.18104111746455845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.0002990535576827824}, {"id": 521, "seek": 245776, "start": 2472.32, "end": 2478.32, "text": " but it might take a little bit of time to actually be helpful. And the claim is to evaluate that,", "tokens": [51092, 457, 309, 1062, 747, 257, 707, 857, 295, 565, 281, 767, 312, 4961, 13, 400, 264, 3932, 307, 281, 13059, 300, 11, 51392], "temperature": 0.0, "avg_logprob": -0.18104111746455845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.0002990535576827824}, {"id": 522, "seek": 245776, "start": 2478.32, "end": 2482.0, "text": " you need counterfactuals again to tell, oh, is the person actually helpful? Well,", "tokens": [51392, 291, 643, 5682, 44919, 901, 82, 797, 281, 980, 11, 1954, 11, 307, 264, 954, 767, 4961, 30, 1042, 11, 51576], "temperature": 0.0, "avg_logprob": -0.18104111746455845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.0002990535576827824}, {"id": 523, "seek": 245776, "start": 2482.0, "end": 2486.0800000000004, "text": " how would it have happened without them, essentially? Or there's different counterfactuals", "tokens": [51576, 577, 576, 309, 362, 2011, 1553, 552, 11, 4476, 30, 1610, 456, 311, 819, 5682, 44919, 901, 82, 51780], "temperature": 0.0, "avg_logprob": -0.18104111746455845, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.0002990535576827824}, {"id": 524, "seek": 248608, "start": 2486.16, "end": 2490.08, "text": " to consider, but that's one of them. So here's our grid world that we played with,", "tokens": [50368, 281, 1949, 11, 457, 300, 311, 472, 295, 552, 13, 407, 510, 311, 527, 10748, 1002, 300, 321, 3737, 365, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09089138083261987, "compression_ratio": 1.8803986710963456, "no_speech_prob": 0.002428856212645769}, {"id": 525, "seek": 248608, "start": 2490.08, "end": 2495.04, "text": " with the helping and hindering setup. So we have this red guy here who wants to get to the star,", "tokens": [50564, 365, 264, 4315, 293, 20138, 1794, 8657, 13, 407, 321, 362, 341, 2182, 2146, 510, 567, 2738, 281, 483, 281, 264, 3543, 11, 50812], "temperature": 0.0, "avg_logprob": -0.09089138083261987, "compression_ratio": 1.8803986710963456, "no_speech_prob": 0.002428856212645769}, {"id": 526, "seek": 248608, "start": 2495.04, "end": 2499.84, "text": " has a pure physical goal in this case, just to get to that location. Then we have this blue one", "tokens": [50812, 575, 257, 6075, 4001, 3387, 294, 341, 1389, 11, 445, 281, 483, 281, 300, 4914, 13, 1396, 321, 362, 341, 3344, 472, 51052], "temperature": 0.0, "avg_logprob": -0.09089138083261987, "compression_ratio": 1.8803986710963456, "no_speech_prob": 0.002428856212645769}, {"id": 527, "seek": 248608, "start": 2499.84, "end": 2504.4, "text": " who has a pure social goal. They either want to help or hinder the red one from getting there.", "tokens": [51052, 567, 575, 257, 6075, 2093, 3387, 13, 814, 2139, 528, 281, 854, 420, 276, 5669, 264, 2182, 472, 490, 1242, 456, 13, 51280], "temperature": 0.0, "avg_logprob": -0.09089138083261987, "compression_ratio": 1.8803986710963456, "no_speech_prob": 0.002428856212645769}, {"id": 528, "seek": 248608, "start": 2504.4, "end": 2508.56, "text": " And then there are these walls here that you can't do anything about, but there's also these blocks,", "tokens": [51280, 400, 550, 456, 366, 613, 7920, 510, 300, 291, 393, 380, 360, 1340, 466, 11, 457, 456, 311, 611, 613, 8474, 11, 51488], "temperature": 0.0, "avg_logprob": -0.09089138083261987, "compression_ratio": 1.8803986710963456, "no_speech_prob": 0.002428856212645769}, {"id": 529, "seek": 248608, "start": 2508.56, "end": 2513.92, "text": " and only the blue one can interact with these blocks. They can push, pull them out of the way.", "tokens": [51488, 293, 787, 264, 3344, 472, 393, 4648, 365, 613, 8474, 13, 814, 393, 2944, 11, 2235, 552, 484, 295, 264, 636, 13, 51756], "temperature": 0.0, "avg_logprob": -0.09089138083261987, "compression_ratio": 1.8803986710963456, "no_speech_prob": 0.002428856212645769}, {"id": 530, "seek": 251392, "start": 2513.92, "end": 2517.6800000000003, "text": " So here's our Hollywood clip of what's happening in this situation.", "tokens": [50364, 407, 510, 311, 527, 11628, 7353, 295, 437, 311, 2737, 294, 341, 2590, 13, 50552], "temperature": 0.0, "avg_logprob": -0.13212930031542508, "compression_ratio": 1.7131147540983607, "no_speech_prob": 0.00011956008529523388}, {"id": 531, "seek": 251392, "start": 2522.16, "end": 2528.16, "text": " Okay, so in this case, happy end, like a Hollywood movie, red made it,", "tokens": [50776, 1033, 11, 370, 294, 341, 1389, 11, 2055, 917, 11, 411, 257, 11628, 3169, 11, 2182, 1027, 309, 11, 51076], "temperature": 0.0, "avg_logprob": -0.13212930031542508, "compression_ratio": 1.7131147540983607, "no_speech_prob": 0.00011956008529523388}, {"id": 532, "seek": 251392, "start": 2528.16, "end": 2531.2000000000003, "text": " and then we can show people these clips and we can ask them, oh, how responsible was the", "tokens": [51076, 293, 550, 321, 393, 855, 561, 613, 13117, 293, 321, 393, 1029, 552, 11, 1954, 11, 577, 6250, 390, 264, 51228], "temperature": 0.0, "avg_logprob": -0.13212930031542508, "compression_ratio": 1.7131147540983607, "no_speech_prob": 0.00011956008529523388}, {"id": 533, "seek": 251392, "start": 2531.2000000000003, "end": 2535.52, "text": " blue player for the red player's success, for example, in this trial? We can also ask them", "tokens": [51228, 3344, 4256, 337, 264, 2182, 4256, 311, 2245, 11, 337, 1365, 11, 294, 341, 7308, 30, 492, 393, 611, 1029, 552, 51444], "temperature": 0.0, "avg_logprob": -0.13212930031542508, "compression_ratio": 1.7131147540983607, "no_speech_prob": 0.00011956008529523388}, {"id": 534, "seek": 251392, "start": 2535.52, "end": 2539.6, "text": " a counterfactual question, right, would the red player still have succeeded even if the blue player", "tokens": [51444, 257, 5682, 44919, 901, 1168, 11, 558, 11, 576, 264, 2182, 4256, 920, 362, 20263, 754, 498, 264, 3344, 4256, 51648], "temperature": 0.0, "avg_logprob": -0.13212930031542508, "compression_ratio": 1.7131147540983607, "no_speech_prob": 0.00011956008529523388}, {"id": 535, "seek": 253960, "start": 2539.6, "end": 2545.04, "text": " hadn't been there? And we can ask them to make an inference about the intention of the blue one", "tokens": [50364, 8782, 380, 668, 456, 30, 400, 321, 393, 1029, 552, 281, 652, 364, 38253, 466, 264, 7789, 295, 264, 3344, 472, 50636], "temperature": 0.0, "avg_logprob": -0.11322838730282253, "compression_ratio": 1.7938461538461539, "no_speech_prob": 0.000286670692730695}, {"id": 536, "seek": 253960, "start": 2545.04, "end": 2548.7999999999997, "text": " in this case. What was the blue player intending to do? Were they trying to help or were they", "tokens": [50636, 294, 341, 1389, 13, 708, 390, 264, 3344, 4256, 560, 2029, 281, 360, 30, 12448, 436, 1382, 281, 854, 420, 645, 436, 50824], "temperature": 0.0, "avg_logprob": -0.11322838730282253, "compression_ratio": 1.7938461538461539, "no_speech_prob": 0.000286670692730695}, {"id": 537, "seek": 253960, "start": 2548.7999999999997, "end": 2554.48, "text": " trying to hinder? Definitely help, definitely hinder. So the idea is now basically the same as earlier,", "tokens": [50824, 1382, 281, 276, 5669, 30, 12151, 854, 11, 2138, 276, 5669, 13, 407, 264, 1558, 307, 586, 1936, 264, 912, 382, 3071, 11, 51108], "temperature": 0.0, "avg_logprob": -0.11322838730282253, "compression_ratio": 1.7938461538461539, "no_speech_prob": 0.000286670692730695}, {"id": 538, "seek": 253960, "start": 2554.48, "end": 2558.48, "text": " by just saying, okay, again, we need some kind of generative model of the domain. In this domain,", "tokens": [51108, 538, 445, 1566, 11, 1392, 11, 797, 11, 321, 643, 512, 733, 295, 1337, 1166, 2316, 295, 264, 9274, 13, 682, 341, 9274, 11, 51308], "temperature": 0.0, "avg_logprob": -0.11322838730282253, "compression_ratio": 1.7938461538461539, "no_speech_prob": 0.000286670692730695}, {"id": 539, "seek": 253960, "start": 2558.48, "end": 2563.8399999999997, "text": " now it's a model of agents basically planning and recursively reasoning about one another, right?", "tokens": [51308, 586, 309, 311, 257, 2316, 295, 12554, 1936, 5038, 293, 20560, 3413, 21577, 466, 472, 1071, 11, 558, 30, 51576], "temperature": 0.0, "avg_logprob": -0.11322838730282253, "compression_ratio": 1.7938461538461539, "no_speech_prob": 0.000286670692730695}, {"id": 540, "seek": 253960, "start": 2564.88, "end": 2569.12, "text": " And that's now our probabilistic program. And we can again compute counterfactuals over that,", "tokens": [51628, 400, 300, 311, 586, 527, 31959, 3142, 1461, 13, 400, 321, 393, 797, 14722, 5682, 44919, 901, 82, 670, 300, 11, 51840], "temperature": 0.0, "avg_logprob": -0.11322838730282253, "compression_ratio": 1.7938461538461539, "no_speech_prob": 0.000286670692730695}, {"id": 541, "seek": 256912, "start": 2569.12, "end": 2572.96, "text": " maybe in this case thinking, well, what would have happened if the blue one hadn't been there?", "tokens": [50364, 1310, 294, 341, 1389, 1953, 11, 731, 11, 437, 576, 362, 2011, 498, 264, 3344, 472, 8782, 380, 668, 456, 30, 50556], "temperature": 0.0, "avg_logprob": -0.09669018487860687, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.0005610429798252881}, {"id": 542, "seek": 256912, "start": 2572.96, "end": 2577.3599999999997, "text": " And then thinking how the red one would have planned their path differently, but without the", "tokens": [50556, 400, 550, 1953, 577, 264, 2182, 472, 576, 362, 8589, 641, 3100, 7614, 11, 457, 1553, 264, 50776], "temperature": 0.0, "avg_logprob": -0.09669018487860687, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.0005610429798252881}, {"id": 543, "seek": 256912, "start": 2577.3599999999997, "end": 2582.88, "text": " presence of blue, that's a rough idea. So again, we take some actual situation and we can then", "tokens": [50776, 6814, 295, 3344, 11, 300, 311, 257, 5903, 1558, 13, 407, 797, 11, 321, 747, 512, 3539, 2590, 293, 321, 393, 550, 51052], "temperature": 0.0, "avg_logprob": -0.09669018487860687, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.0005610429798252881}, {"id": 544, "seek": 256912, "start": 2582.88, "end": 2586.7999999999997, "text": " simulate what would have happened in the relevant counterfactual situation in this case where blue", "tokens": [51052, 27817, 437, 576, 362, 2011, 294, 264, 7340, 5682, 44919, 901, 2590, 294, 341, 1389, 689, 3344, 51248], "temperature": 0.0, "avg_logprob": -0.09669018487860687, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.0005610429798252881}, {"id": 545, "seek": 256912, "start": 2586.7999999999997, "end": 2590.96, "text": " hadn't been there. We can talk later if you like about other counterfactuals you might consider,", "tokens": [51248, 8782, 380, 668, 456, 13, 492, 393, 751, 1780, 498, 291, 411, 466, 661, 5682, 44919, 901, 82, 291, 1062, 1949, 11, 51456], "temperature": 0.0, "avg_logprob": -0.09669018487860687, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.0005610429798252881}, {"id": 546, "seek": 256912, "start": 2590.96, "end": 2594.96, "text": " but we just went with this one here, but what if they hadn't been there? In this case, yeah,", "tokens": [51456, 457, 321, 445, 1437, 365, 341, 472, 510, 11, 457, 437, 498, 436, 8782, 380, 668, 456, 30, 682, 341, 1389, 11, 1338, 11, 51656], "temperature": 0.0, "avg_logprob": -0.09669018487860687, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.0005610429798252881}, {"id": 547, "seek": 259496, "start": 2594.96, "end": 2599.36, "text": " they wouldn't have made it because the block was in the way, right? We also have a model of", "tokens": [50364, 436, 2759, 380, 362, 1027, 309, 570, 264, 3461, 390, 294, 264, 636, 11, 558, 30, 492, 611, 362, 257, 2316, 295, 50584], "temperature": 0.0, "avg_logprob": -0.06028010997366398, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0003459241706877947}, {"id": 548, "seek": 259496, "start": 2599.36, "end": 2603.12, "text": " intention inference, but I'll sort of skip that. It's basically just saying, okay, if you have a", "tokens": [50584, 7789, 38253, 11, 457, 286, 603, 1333, 295, 10023, 300, 13, 467, 311, 1936, 445, 1566, 11, 1392, 11, 498, 291, 362, 257, 50772], "temperature": 0.0, "avg_logprob": -0.06028010997366398, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0003459241706877947}, {"id": 549, "seek": 259496, "start": 2603.12, "end": 2607.76, "text": " generative model about what an helping or hindering agent would do, you can then condition on the", "tokens": [50772, 1337, 1166, 2316, 466, 437, 364, 4315, 420, 20138, 1794, 9461, 576, 360, 11, 291, 393, 550, 4188, 322, 264, 51004], "temperature": 0.0, "avg_logprob": -0.06028010997366398, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0003459241706877947}, {"id": 550, "seek": 259496, "start": 2607.76, "end": 2612.88, "text": " observations that you see them acting and see what's more likely that they were helping or", "tokens": [51004, 18163, 300, 291, 536, 552, 6577, 293, 536, 437, 311, 544, 3700, 300, 436, 645, 4315, 420, 51260], "temperature": 0.0, "avg_logprob": -0.06028010997366398, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0003459241706877947}, {"id": 551, "seek": 259496, "start": 2612.88, "end": 2617.36, "text": " hindering given the actions that they carried out. So I'll just give you a few more examples of the", "tokens": [51260, 20138, 1794, 2212, 264, 5909, 300, 436, 9094, 484, 13, 407, 286, 603, 445, 976, 291, 257, 1326, 544, 5110, 295, 264, 51484], "temperature": 0.0, "avg_logprob": -0.06028010997366398, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0003459241706877947}, {"id": 552, "seek": 259496, "start": 2617.36, "end": 2622.16, "text": " sort of video clips that we showed to participants. That's a diagram of the one that you've just seen.", "tokens": [51484, 1333, 295, 960, 13117, 300, 321, 4712, 281, 10503, 13, 663, 311, 257, 10686, 295, 264, 472, 300, 291, 600, 445, 1612, 13, 51724], "temperature": 0.0, "avg_logprob": -0.06028010997366398, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0003459241706877947}, {"id": 553, "seek": 262216, "start": 2622.16, "end": 2629.52, "text": " Here's another one where kind of, you know, blue is sort of extra mean, you might say. There was", "tokens": [50364, 1692, 311, 1071, 472, 689, 733, 295, 11, 291, 458, 11, 3344, 307, 1333, 295, 2857, 914, 11, 291, 1062, 584, 13, 821, 390, 50732], "temperature": 0.0, "avg_logprob": -0.13114824100416533, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0002451486943755299}, {"id": 554, "seek": 262216, "start": 2629.52, "end": 2634.8799999999997, "text": " already a block in the way, but they put another block in the way. What the heck? Yeah, really trying", "tokens": [50732, 1217, 257, 3461, 294, 264, 636, 11, 457, 436, 829, 1071, 3461, 294, 264, 636, 13, 708, 264, 12872, 30, 865, 11, 534, 1382, 51000], "temperature": 0.0, "avg_logprob": -0.13114824100416533, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0002451486943755299}, {"id": 555, "seek": 262216, "start": 2634.8799999999997, "end": 2643.8399999999997, "text": " to be helpful through adversarial actions. So here's another one here where blue is sort of", "tokens": [51000, 281, 312, 4961, 807, 17641, 44745, 5909, 13, 407, 510, 311, 1071, 472, 510, 689, 3344, 307, 1333, 295, 51448], "temperature": 0.0, "avg_logprob": -0.13114824100416533, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0002451486943755299}, {"id": 556, "seek": 262216, "start": 2643.8399999999997, "end": 2648.7999999999997, "text": " laudably helpful, but like, you know, was not really necessary, but maybe looks nice.", "tokens": [51448, 635, 532, 1188, 4961, 11, 457, 411, 11, 291, 458, 11, 390, 406, 534, 4818, 11, 457, 1310, 1542, 1481, 13, 51696], "temperature": 0.0, "avg_logprob": -0.13114824100416533, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0002451486943755299}, {"id": 557, "seek": 264880, "start": 2649.76, "end": 2652.48, "text": " Here's a case in which sort of things go wrong.", "tokens": [50412, 1692, 311, 257, 1389, 294, 597, 1333, 295, 721, 352, 2085, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1283297925382047, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00014875398483127356}, {"id": 558, "seek": 264880, "start": 2655.84, "end": 2659.52, "text": " Where blue was maybe trying to be helpful, but actually sort of made it worse, you know,", "tokens": [50716, 2305, 3344, 390, 1310, 1382, 281, 312, 4961, 11, 457, 767, 1333, 295, 1027, 309, 5324, 11, 291, 458, 11, 50900], "temperature": 0.0, "avg_logprob": -0.1283297925382047, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00014875398483127356}, {"id": 559, "seek": 264880, "start": 2659.52, "end": 2664.32, "text": " the reactions that they took. And then here's another one. We had a large number, so I'm just", "tokens": [50900, 264, 12215, 300, 436, 1890, 13, 400, 550, 510, 311, 1071, 472, 13, 492, 632, 257, 2416, 1230, 11, 370, 286, 478, 445, 51140], "temperature": 0.0, "avg_logprob": -0.1283297925382047, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00014875398483127356}, {"id": 560, "seek": 264880, "start": 2664.32, "end": 2669.76, "text": " showing like a subset of them. So this is one where blue could have easily hindered if they had", "tokens": [51140, 4099, 411, 257, 25993, 295, 552, 13, 407, 341, 307, 472, 689, 3344, 727, 362, 3612, 20138, 4073, 498, 436, 632, 51412], "temperature": 0.0, "avg_logprob": -0.1283297925382047, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00014875398483127356}, {"id": 561, "seek": 264880, "start": 2669.76, "end": 2676.4, "text": " wanted to, but didn't, because they could have just pushed it into the way. And so then we now", "tokens": [51412, 1415, 281, 11, 457, 994, 380, 11, 570, 436, 727, 362, 445, 9152, 309, 666, 264, 636, 13, 400, 370, 550, 321, 586, 51744], "temperature": 0.0, "avg_logprob": -0.1283297925382047, "compression_ratio": 1.6254826254826256, "no_speech_prob": 0.00014875398483127356}, {"id": 562, "seek": 267640, "start": 2676.48, "end": 2681.52, "text": " have to again, yeah, try to capture whether we can, with our model, capture the counterfactual", "tokens": [50368, 362, 281, 797, 11, 1338, 11, 853, 281, 7983, 1968, 321, 393, 11, 365, 527, 2316, 11, 7983, 264, 5682, 44919, 901, 50620], "temperature": 0.0, "avg_logprob": -0.10086846182532344, "compression_ratio": 1.8547854785478548, "no_speech_prob": 0.0020803187508136034}, {"id": 563, "seek": 267640, "start": 2681.52, "end": 2685.44, "text": " judgments that people are making. And we sort of can, there's not as much kind of variance here,", "tokens": [50620, 40337, 300, 561, 366, 1455, 13, 400, 321, 1333, 295, 393, 11, 456, 311, 406, 382, 709, 733, 295, 21977, 510, 11, 50816], "temperature": 0.0, "avg_logprob": -0.10086846182532344, "compression_ratio": 1.8547854785478548, "no_speech_prob": 0.0020803187508136034}, {"id": 564, "seek": 267640, "start": 2686.0, "end": 2690.08, "text": " at least in the predictions of the model. So this model is sort of okay-ish. It captures the trends", "tokens": [50844, 412, 1935, 294, 264, 21264, 295, 264, 2316, 13, 407, 341, 2316, 307, 1333, 295, 1392, 12, 742, 13, 467, 27986, 264, 13892, 51048], "temperature": 0.0, "avg_logprob": -0.10086846182532344, "compression_ratio": 1.8547854785478548, "no_speech_prob": 0.0020803187508136034}, {"id": 565, "seek": 267640, "start": 2690.08, "end": 2693.6, "text": " overall, but there's more variance in people's judgments that is not quite captured by the", "tokens": [51048, 4787, 11, 457, 456, 311, 544, 21977, 294, 561, 311, 40337, 300, 307, 406, 1596, 11828, 538, 264, 51224], "temperature": 0.0, "avg_logprob": -0.10086846182532344, "compression_ratio": 1.8547854785478548, "no_speech_prob": 0.0020803187508136034}, {"id": 566, "seek": 267640, "start": 2693.6, "end": 2699.52, "text": " model yet. So we're still, this is sort of more ongoing work. In terms of intention inference,", "tokens": [51224, 2316, 1939, 13, 407, 321, 434, 920, 11, 341, 307, 1333, 295, 544, 10452, 589, 13, 682, 2115, 295, 7789, 38253, 11, 51520], "temperature": 0.0, "avg_logprob": -0.10086846182532344, "compression_ratio": 1.8547854785478548, "no_speech_prob": 0.0020803187508136034}, {"id": 567, "seek": 267640, "start": 2699.52, "end": 2703.76, "text": " it's fine. So it can also kind of infer whether the person was helping or hindering,", "tokens": [51520, 309, 311, 2489, 13, 407, 309, 393, 611, 733, 295, 13596, 1968, 264, 954, 390, 4315, 420, 20138, 1794, 11, 51732], "temperature": 0.0, "avg_logprob": -0.10086846182532344, "compression_ratio": 1.8547854785478548, "no_speech_prob": 0.0020803187508136034}, {"id": 568, "seek": 270376, "start": 2703.76, "end": 2707.44, "text": " but also here, what you see is stuff are bunched up that the model all gives a hundred to,", "tokens": [50364, 457, 611, 510, 11, 437, 291, 536, 307, 1507, 366, 3840, 292, 493, 300, 264, 2316, 439, 2709, 257, 3262, 281, 11, 50548], "temperature": 0.0, "avg_logprob": -0.11218593789519166, "compression_ratio": 1.8085808580858085, "no_speech_prob": 9.310882160207257e-05}, {"id": 569, "seek": 270376, "start": 2708.48, "end": 2713.28, "text": " where there's still some differentiation that people make, but sort of mostly captures what's", "tokens": [50600, 689, 456, 311, 920, 512, 38902, 300, 561, 652, 11, 457, 1333, 295, 5240, 27986, 437, 311, 50840], "temperature": 0.0, "avg_logprob": -0.11218593789519166, "compression_ratio": 1.8085808580858085, "no_speech_prob": 9.310882160207257e-05}, {"id": 570, "seek": 270376, "start": 2713.28, "end": 2718.4, "text": " going on. And if we now look at the responsibility judgments, and we try to do the same thing", "tokens": [50840, 516, 322, 13, 400, 498, 321, 586, 574, 412, 264, 6357, 40337, 11, 293, 321, 853, 281, 360, 264, 912, 551, 51096], "temperature": 0.0, "avg_logprob": -0.11218593789519166, "compression_ratio": 1.8085808580858085, "no_speech_prob": 9.310882160207257e-05}, {"id": 571, "seek": 270376, "start": 2718.4, "end": 2722.2400000000002, "text": " initially that we did with the billiard balls earlier, that we just take the counterfactuals,", "tokens": [51096, 9105, 300, 321, 630, 365, 264, 2961, 72, 515, 9803, 3071, 11, 300, 321, 445, 747, 264, 5682, 44919, 901, 82, 11, 51288], "temperature": 0.0, "avg_logprob": -0.11218593789519166, "compression_ratio": 1.8085808580858085, "no_speech_prob": 9.310882160207257e-05}, {"id": 572, "seek": 270376, "start": 2722.2400000000002, "end": 2729.0400000000004, "text": " like on the x-axis, and try to predict the responsibility here on the y-axis, it's okay-ish,", "tokens": [51288, 411, 322, 264, 2031, 12, 24633, 11, 293, 853, 281, 6069, 264, 6357, 510, 322, 264, 288, 12, 24633, 11, 309, 311, 1392, 12, 742, 11, 51628], "temperature": 0.0, "avg_logprob": -0.11218593789519166, "compression_ratio": 1.8085808580858085, "no_speech_prob": 9.310882160207257e-05}, {"id": 573, "seek": 270376, "start": 2729.0400000000004, "end": 2732.5600000000004, "text": " but not, you always want, when you do computational modeling, you always want them", "tokens": [51628, 457, 406, 11, 291, 1009, 528, 11, 562, 291, 360, 28270, 15983, 11, 291, 1009, 528, 552, 51804], "temperature": 0.0, "avg_logprob": -0.11218593789519166, "compression_ratio": 1.8085808580858085, "no_speech_prob": 9.310882160207257e-05}, {"id": 574, "seek": 273256, "start": 2732.56, "end": 2737.2, "text": " nicely line up on the diagonal. And that's not really what was happening in this case,", "tokens": [50364, 9594, 1622, 493, 322, 264, 21539, 13, 400, 300, 311, 406, 534, 437, 390, 2737, 294, 341, 1389, 11, 50596], "temperature": 0.0, "avg_logprob": -0.09353232965236757, "compression_ratio": 1.8531468531468531, "no_speech_prob": 6.81272940710187e-05}, {"id": 575, "seek": 273256, "start": 2737.2, "end": 2740.7999999999997, "text": " whereas for the billiard balls, we have this very simple counterfactuals nicely predict", "tokens": [50596, 9735, 337, 264, 2961, 72, 515, 9803, 11, 321, 362, 341, 588, 2199, 5682, 44919, 901, 82, 9594, 6069, 50776], "temperature": 0.0, "avg_logprob": -0.09353232965236757, "compression_ratio": 1.8531468531468531, "no_speech_prob": 6.81272940710187e-05}, {"id": 576, "seek": 273256, "start": 2741.44, "end": 2747.04, "text": " the causal ratings. But if again, if you have a model that incorporates also the intention", "tokens": [50808, 264, 38755, 24603, 13, 583, 498, 797, 11, 498, 291, 362, 257, 2316, 300, 50193, 611, 264, 7789, 51088], "temperature": 0.0, "avg_logprob": -0.09353232965236757, "compression_ratio": 1.8531468531468531, "no_speech_prob": 6.81272940710187e-05}, {"id": 577, "seek": 273256, "start": 2747.04, "end": 2753.04, "text": " inferences, like into the predictions, now they do sort of more nicely line up on the diagonal.", "tokens": [51088, 13596, 2667, 11, 411, 666, 264, 21264, 11, 586, 436, 360, 1333, 295, 544, 9594, 1622, 493, 322, 264, 21539, 13, 51388], "temperature": 0.0, "avg_logprob": -0.09353232965236757, "compression_ratio": 1.8531468531468531, "no_speech_prob": 6.81272940710187e-05}, {"id": 578, "seek": 273256, "start": 2753.68, "end": 2757.44, "text": " Again, suggesting that when it comes to assigning responsibility for agents,", "tokens": [51420, 3764, 11, 18094, 300, 562, 309, 1487, 281, 49602, 6357, 337, 12554, 11, 51608], "temperature": 0.0, "avg_logprob": -0.09353232965236757, "compression_ratio": 1.8531468531468531, "no_speech_prob": 6.81272940710187e-05}, {"id": 579, "seek": 273256, "start": 2757.44, "end": 2761.84, "text": " it's not just the causal role that matters. It also matters what the actions that they took", "tokens": [51608, 309, 311, 406, 445, 264, 38755, 3090, 300, 7001, 13, 467, 611, 7001, 437, 264, 5909, 300, 436, 1890, 51828], "temperature": 0.0, "avg_logprob": -0.09353232965236757, "compression_ratio": 1.8531468531468531, "no_speech_prob": 6.81272940710187e-05}, {"id": 580, "seek": 276184, "start": 2761.84, "end": 2765.44, "text": " tell me about the kind of person that they are. In this case, it tells me something about", "tokens": [50364, 980, 385, 466, 264, 733, 295, 954, 300, 436, 366, 13, 682, 341, 1389, 11, 309, 5112, 385, 746, 466, 50544], "temperature": 0.0, "avg_logprob": -0.10117544926388163, "compression_ratio": 1.8516129032258064, "no_speech_prob": 0.0001441974745830521}, {"id": 581, "seek": 276184, "start": 2765.44, "end": 2769.76, "text": " their intentions, like they try to be helpful, or that they try to be hindering. So the both of", "tokens": [50544, 641, 19354, 11, 411, 436, 853, 281, 312, 4961, 11, 420, 300, 436, 853, 281, 312, 20138, 1794, 13, 407, 264, 1293, 295, 50760], "temperature": 0.0, "avg_logprob": -0.10117544926388163, "compression_ratio": 1.8516129032258064, "no_speech_prob": 0.0001441974745830521}, {"id": 582, "seek": 276184, "start": 2769.76, "end": 2775.04, "text": " these components. And just to give you a sense of an example where we need this kind of intention", "tokens": [50760, 613, 6677, 13, 400, 445, 281, 976, 291, 257, 2020, 295, 364, 1365, 689, 321, 643, 341, 733, 295, 7789, 51024], "temperature": 0.0, "avg_logprob": -0.10117544926388163, "compression_ratio": 1.8516129032258064, "no_speech_prob": 0.0001441974745830521}, {"id": 583, "seek": 276184, "start": 2775.04, "end": 2779.36, "text": " part, like that's back to that mean one where the blue one pushes another one into the way, right?", "tokens": [51024, 644, 11, 411, 300, 311, 646, 281, 300, 914, 472, 689, 264, 3344, 472, 21020, 1071, 472, 666, 264, 636, 11, 558, 30, 51240], "temperature": 0.0, "avg_logprob": -0.10117544926388163, "compression_ratio": 1.8516129032258064, "no_speech_prob": 0.0001441974745830521}, {"id": 584, "seek": 276184, "start": 2779.92, "end": 2784.2400000000002, "text": " And so just to help you kind of interpret the bars here, the counterfactual, that's the condition", "tokens": [51268, 400, 370, 445, 281, 854, 291, 733, 295, 7302, 264, 10228, 510, 11, 264, 5682, 44919, 901, 11, 300, 311, 264, 4188, 51484], "temperature": 0.0, "avg_logprob": -0.10117544926388163, "compression_ratio": 1.8516129032258064, "no_speech_prob": 0.0001441974745830521}, {"id": 585, "seek": 276184, "start": 2784.2400000000002, "end": 2788.4, "text": " where we asked them, would red have succeeded if blue hadn't been there? That's basically our", "tokens": [51484, 689, 321, 2351, 552, 11, 576, 2182, 362, 20263, 498, 3344, 8782, 380, 668, 456, 30, 663, 311, 1936, 527, 51692], "temperature": 0.0, "avg_logprob": -0.10117544926388163, "compression_ratio": 1.8516129032258064, "no_speech_prob": 0.0001441974745830521}, {"id": 586, "seek": 278840, "start": 2788.4, "end": 2795.44, "text": " causal model. And they don't think so, right? The pink, pink, purplish one is like very low,", "tokens": [50364, 38755, 2316, 13, 400, 436, 500, 380, 519, 370, 11, 558, 30, 440, 7022, 11, 7022, 11, 1864, 564, 742, 472, 307, 411, 588, 2295, 11, 50716], "temperature": 0.0, "avg_logprob": -0.11374524775767486, "compression_ratio": 1.8758389261744965, "no_speech_prob": 0.0003848131455015391}, {"id": 587, "seek": 278840, "start": 2795.44, "end": 2799.6, "text": " right? But also when we asked them what the intention of the blue one is, they think, yeah,", "tokens": [50716, 558, 30, 583, 611, 562, 321, 2351, 552, 437, 264, 7789, 295, 264, 3344, 472, 307, 11, 436, 519, 11, 1338, 11, 50924], "temperature": 0.0, "avg_logprob": -0.11374524775767486, "compression_ratio": 1.8758389261744965, "no_speech_prob": 0.0003848131455015391}, {"id": 588, "seek": 278840, "start": 2799.6, "end": 2803.44, "text": " was really hindering. So here zero means hindering and 100 means helping. So they think, yeah,", "tokens": [50924, 390, 534, 20138, 1794, 13, 407, 510, 4018, 1355, 20138, 1794, 293, 2319, 1355, 4315, 13, 407, 436, 519, 11, 1338, 11, 51116], "temperature": 0.0, "avg_logprob": -0.11374524775767486, "compression_ratio": 1.8758389261744965, "no_speech_prob": 0.0003848131455015391}, {"id": 589, "seek": 278840, "start": 2803.44, "end": 2808.4, "text": " they were hindering. So even though they say that, yeah, the blue one didn't really play a causal", "tokens": [51116, 436, 645, 20138, 1794, 13, 407, 754, 1673, 436, 584, 300, 11, 1338, 11, 264, 3344, 472, 994, 380, 534, 862, 257, 38755, 51364], "temperature": 0.0, "avg_logprob": -0.11374524775767486, "compression_ratio": 1.8758389261744965, "no_speech_prob": 0.0003848131455015391}, {"id": 590, "seek": 278840, "start": 2808.4, "end": 2811.6800000000003, "text": " role, they still give them quite a bit of responsibility, like in the blue one on the", "tokens": [51364, 3090, 11, 436, 920, 976, 552, 1596, 257, 857, 295, 6357, 11, 411, 294, 264, 3344, 472, 322, 264, 51528], "temperature": 0.0, "avg_logprob": -0.11374524775767486, "compression_ratio": 1.8758389261744965, "no_speech_prob": 0.0003848131455015391}, {"id": 591, "seek": 278840, "start": 2811.6800000000003, "end": 2816.7200000000003, "text": " right hand side. So that's one case, at least, where currently we need this other part. So they", "tokens": [51528, 558, 1011, 1252, 13, 407, 300, 311, 472, 1389, 11, 412, 1935, 11, 689, 4362, 321, 643, 341, 661, 644, 13, 407, 436, 51780], "temperature": 0.0, "avg_logprob": -0.11374524775767486, "compression_ratio": 1.8758389261744965, "no_speech_prob": 0.0003848131455015391}, {"id": 592, "seek": 281672, "start": 2816.72, "end": 2819.52, "text": " think, yeah, blue blue's actually make no difference, but they were definitely trying to", "tokens": [50364, 519, 11, 1338, 11, 3344, 3344, 311, 767, 652, 572, 2649, 11, 457, 436, 645, 2138, 1382, 281, 50504], "temperature": 0.0, "avg_logprob": -0.12156785818246695, "compression_ratio": 1.73125, "no_speech_prob": 0.00013333169044926763}, {"id": 593, "seek": 281672, "start": 2819.52, "end": 2823.12, "text": " hinder. And so, yeah, I still give them some responsibility for this outcome.", "tokens": [50504, 276, 5669, 13, 400, 370, 11, 1338, 11, 286, 920, 976, 552, 512, 6357, 337, 341, 9700, 13, 50684], "temperature": 0.0, "avg_logprob": -0.12156785818246695, "compression_ratio": 1.73125, "no_speech_prob": 0.00013333169044926763}, {"id": 594, "seek": 281672, "start": 2824.48, "end": 2830.64, "text": " Okay, so sort of almost last slide. Because we have these agents like recursively thinking about", "tokens": [50752, 1033, 11, 370, 1333, 295, 1920, 1036, 4137, 13, 1436, 321, 362, 613, 12554, 411, 20560, 3413, 1953, 466, 51060], "temperature": 0.0, "avg_logprob": -0.12156785818246695, "compression_ratio": 1.73125, "no_speech_prob": 0.00013333169044926763}, {"id": 595, "seek": 281672, "start": 2830.64, "end": 2835.12, "text": " one another, an interesting setting that also can happen here is that you can actually hinder or", "tokens": [51060, 472, 1071, 11, 364, 1880, 3287, 300, 611, 393, 1051, 510, 307, 300, 291, 393, 767, 276, 5669, 420, 51284], "temperature": 0.0, "avg_logprob": -0.12156785818246695, "compression_ratio": 1.73125, "no_speech_prob": 0.00013333169044926763}, {"id": 596, "seek": 281672, "start": 2835.12, "end": 2840.3999999999996, "text": " help one another, again, maybe also like in the, in the advisor, advisor setting, not by actually", "tokens": [51284, 854, 472, 1071, 11, 797, 11, 1310, 611, 411, 294, 264, 11, 294, 264, 19161, 11, 19161, 3287, 11, 406, 538, 767, 51548], "temperature": 0.0, "avg_logprob": -0.12156785818246695, "compression_ratio": 1.73125, "no_speech_prob": 0.00013333169044926763}, {"id": 597, "seek": 281672, "start": 2840.3999999999996, "end": 2844.8799999999997, "text": " making any change to the physical world, but changing somebody else's belief. So I just want to", "tokens": [51548, 1455, 604, 1319, 281, 264, 4001, 1002, 11, 457, 4473, 2618, 1646, 311, 7107, 13, 407, 286, 445, 528, 281, 51772], "temperature": 0.0, "avg_logprob": -0.12156785818246695, "compression_ratio": 1.73125, "no_speech_prob": 0.00013333169044926763}, {"id": 598, "seek": 284488, "start": 2845.36, "end": 2848.88, "text": " show you that example. And maybe you'll get that intuition from the setting here.", "tokens": [50388, 855, 291, 300, 1365, 13, 400, 1310, 291, 603, 483, 300, 24002, 490, 264, 3287, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14205440945095485, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.00019999250071123242}, {"id": 599, "seek": 284488, "start": 2854.96, "end": 2860.1600000000003, "text": " So very, very mean, very, very sad. Because it looked really like blue was going to help,", "tokens": [50868, 407, 588, 11, 588, 914, 11, 588, 11, 588, 4227, 13, 1436, 309, 2956, 534, 411, 3344, 390, 516, 281, 854, 11, 51128], "temperature": 0.0, "avg_logprob": -0.14205440945095485, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.00019999250071123242}, {"id": 600, "seek": 284488, "start": 2860.1600000000003, "end": 2867.52, "text": " right? And then they didn't, right? And here's just one participant, what they're saying,", "tokens": [51128, 558, 30, 400, 550, 436, 994, 380, 11, 558, 30, 400, 510, 311, 445, 472, 24950, 11, 437, 436, 434, 1566, 11, 51496], "temperature": 0.0, "avg_logprob": -0.14205440945095485, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.00019999250071123242}, {"id": 601, "seek": 284488, "start": 2867.52, "end": 2870.96, "text": " oh, blue tricked red into thinking she was going to move the box to help. But then", "tokens": [51496, 1954, 11, 3344, 39345, 2182, 666, 1953, 750, 390, 516, 281, 1286, 264, 2424, 281, 854, 13, 583, 550, 51668], "temperature": 0.0, "avg_logprob": -0.14205440945095485, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.00019999250071123242}, {"id": 602, "seek": 287096, "start": 2870.96, "end": 2876.08, "text": " once red was stuck on the side of the wall, blue left the box where it was, very sad, you know.", "tokens": [50364, 1564, 2182, 390, 5541, 322, 264, 1252, 295, 264, 2929, 11, 3344, 1411, 264, 2424, 689, 309, 390, 11, 588, 4227, 11, 291, 458, 13, 50620], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 603, "seek": 287096, "start": 2876.08, "end": 2879.84, "text": " And a lot of people say something along those lines. We also had one condition where we just", "tokens": [50620, 400, 257, 688, 295, 561, 584, 746, 2051, 729, 3876, 13, 492, 611, 632, 472, 4188, 689, 321, 445, 50808], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 604, "seek": 287096, "start": 2879.84, "end": 2883.6, "text": " have them give explanations of what happened, right? And here the interesting part, right,", "tokens": [50808, 362, 552, 976, 28708, 295, 437, 2011, 11, 558, 30, 400, 510, 264, 1880, 644, 11, 558, 11, 50996], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 605, "seek": 287096, "start": 2883.6, "end": 2887.52, "text": " is that the hindering is not happening because blue changed anything about the world. They didn't", "tokens": [50996, 307, 300, 264, 20138, 1794, 307, 406, 2737, 570, 3344, 3105, 1340, 466, 264, 1002, 13, 814, 994, 380, 51192], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 606, "seek": 287096, "start": 2887.52, "end": 2891.28, "text": " move a block in the way or something, but they hindered because they made red believe that", "tokens": [51192, 1286, 257, 3461, 294, 264, 636, 420, 746, 11, 457, 436, 20138, 4073, 570, 436, 1027, 2182, 1697, 300, 51380], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 607, "seek": 287096, "start": 2891.28, "end": 2895.12, "text": " they were going to be helpful and then they weren't, right? Here, if blue hadn't been there,", "tokens": [51380, 436, 645, 516, 281, 312, 4961, 293, 550, 436, 4999, 380, 11, 558, 30, 1692, 11, 498, 3344, 8782, 380, 668, 456, 11, 51572], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 608, "seek": 287096, "start": 2895.12, "end": 2898.96, "text": " red would have just walked along on the outside and they might have made it, you know, anyhow,", "tokens": [51572, 2182, 576, 362, 445, 7628, 2051, 322, 264, 2380, 293, 436, 1062, 362, 1027, 309, 11, 291, 458, 11, 44995, 11, 51764], "temperature": 0.0, "avg_logprob": -0.09296323657035828, "compression_ratio": 1.8531073446327684, "no_speech_prob": 0.0009106161305680871}, {"id": 609, "seek": 289896, "start": 2899.04, "end": 2903.36, "text": " even without blue. And this happens because they're recursively thinking about one another,", "tokens": [50368, 754, 1553, 3344, 13, 400, 341, 2314, 570, 436, 434, 20560, 3413, 1953, 466, 472, 1071, 11, 50584], "temperature": 0.0, "avg_logprob": -0.0982879271874061, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0002231619437225163}, {"id": 610, "seek": 289896, "start": 2903.36, "end": 2906.32, "text": " right? And red things like, oh, blue is taking actions that are going to help me", "tokens": [50584, 558, 30, 400, 2182, 721, 411, 11, 1954, 11, 3344, 307, 1940, 5909, 300, 366, 516, 281, 854, 385, 50732], "temperature": 0.0, "avg_logprob": -0.0982879271874061, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0002231619437225163}, {"id": 611, "seek": 289896, "start": 2906.32, "end": 2912.4, "text": " so I can take the shortcut. And then it turns out I couldn't in this case. Okay, wrapping up.", "tokens": [50732, 370, 286, 393, 747, 264, 24822, 13, 400, 550, 309, 4523, 484, 286, 2809, 380, 294, 341, 1389, 13, 1033, 11, 21993, 493, 13, 51036], "temperature": 0.0, "avg_logprob": -0.0982879271874061, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0002231619437225163}, {"id": 612, "seek": 289896, "start": 2913.2, "end": 2917.12, "text": " So this was the second part where we, I guess, applied this model now to at least a simple", "tokens": [51076, 407, 341, 390, 264, 1150, 644, 689, 321, 11, 286, 2041, 11, 6456, 341, 2316, 586, 281, 412, 1935, 257, 2199, 51272], "temperature": 0.0, "avg_logprob": -0.0982879271874061, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0002231619437225163}, {"id": 613, "seek": 289896, "start": 2917.12, "end": 2921.36, "text": " setting where agents are interacting with one another, helping and hindering one another,", "tokens": [51272, 3287, 689, 12554, 366, 18017, 365, 472, 1071, 11, 4315, 293, 20138, 1794, 472, 1071, 11, 51484], "temperature": 0.0, "avg_logprob": -0.0982879271874061, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0002231619437225163}, {"id": 614, "seek": 289896, "start": 2922.32, "end": 2926.32, "text": " that in order to judge whether somebody helped or hindered, I again think that you need this", "tokens": [51532, 300, 294, 1668, 281, 6995, 1968, 2618, 4254, 420, 20138, 4073, 11, 286, 797, 519, 300, 291, 643, 341, 51732], "temperature": 0.0, "avg_logprob": -0.0982879271874061, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0002231619437225163}, {"id": 615, "seek": 292632, "start": 2926.32, "end": 2932.48, "text": " process of counterfactual simulation and that responsibility judgments are sensitive both", "tokens": [50364, 1399, 295, 5682, 44919, 901, 16575, 293, 300, 6357, 40337, 366, 9477, 1293, 50672], "temperature": 0.0, "avg_logprob": -0.12167092525597775, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0002689679677132517}, {"id": 616, "seek": 292632, "start": 2932.48, "end": 2936.6400000000003, "text": " to the cause of the world that somebody played and what the actions tell us about the kind of", "tokens": [50672, 281, 264, 3082, 295, 264, 1002, 300, 2618, 3737, 293, 437, 264, 5909, 980, 505, 466, 264, 733, 295, 50880], "temperature": 0.0, "avg_logprob": -0.12167092525597775, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0002689679677132517}, {"id": 617, "seek": 292632, "start": 2936.6400000000003, "end": 2942.1600000000003, "text": " mental state that they had. Just to conclude, so together, hopefully, this sort of set of studies", "tokens": [50880, 4973, 1785, 300, 436, 632, 13, 1449, 281, 16886, 11, 370, 1214, 11, 4696, 11, 341, 1333, 295, 992, 295, 5313, 51156], "temperature": 0.0, "avg_logprob": -0.12167092525597775, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0002689679677132517}, {"id": 618, "seek": 292632, "start": 2942.1600000000003, "end": 2946.4, "text": " gets some evidence that people seem to be constructing these rich mental models of the", "tokens": [51156, 2170, 512, 4467, 300, 561, 1643, 281, 312, 39969, 613, 4593, 4973, 5245, 295, 264, 51368], "temperature": 0.0, "avg_logprob": -0.12167092525597775, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0002689679677132517}, {"id": 619, "seek": 292632, "start": 2946.4, "end": 2950.0800000000004, "text": " world that we can get evidence for in different kinds of ways, like through eye tracking and other", "tokens": [51368, 1002, 300, 321, 393, 483, 4467, 337, 294, 819, 3685, 295, 2098, 11, 411, 807, 3313, 11603, 293, 661, 51552], "temperature": 0.0, "avg_logprob": -0.12167092525597775, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.0002689679677132517}, {"id": 620, "seek": 295008, "start": 2950.08, "end": 2956.4, "text": " tools. By imagining interventions like on these mental models, those allow us to compute the", "tokens": [50364, 3873, 13, 3146, 27798, 20924, 411, 322, 613, 4973, 5245, 11, 729, 2089, 505, 281, 14722, 264, 50680], "temperature": 0.0, "avg_logprob": -0.06875094720872782, "compression_ratio": 1.8149350649350648, "no_speech_prob": 0.0005971093196421862}, {"id": 621, "seek": 295008, "start": 2956.4, "end": 2960.96, "text": " counterfactuals, which I think are important for assigning responsibility, giving explanations", "tokens": [50680, 5682, 44919, 901, 82, 11, 597, 286, 519, 366, 1021, 337, 49602, 6357, 11, 2902, 28708, 50908], "temperature": 0.0, "avg_logprob": -0.06875094720872782, "compression_ratio": 1.8149350649350648, "no_speech_prob": 0.0005971093196421862}, {"id": 622, "seek": 295008, "start": 2960.96, "end": 2966.4, "text": " and so on. And that this counterfactual simulation model that I've been kind of developing can then", "tokens": [50908, 293, 370, 322, 13, 400, 300, 341, 5682, 44919, 901, 16575, 2316, 300, 286, 600, 668, 733, 295, 6416, 393, 550, 51180], "temperature": 0.0, "avg_logprob": -0.06875094720872782, "compression_ratio": 1.8149350649350648, "no_speech_prob": 0.0005971093196421862}, {"id": 623, "seek": 295008, "start": 2966.4, "end": 2970.64, "text": " be relatively flexibly applied to physical and social events, where you think that the main", "tokens": [51180, 312, 7226, 5896, 3545, 6456, 281, 4001, 293, 2093, 3931, 11, 689, 291, 519, 300, 264, 2135, 51392], "temperature": 0.0, "avg_logprob": -0.06875094720872782, "compression_ratio": 1.8149350649350648, "no_speech_prob": 0.0005971093196421862}, {"id": 624, "seek": 295008, "start": 2970.64, "end": 2974.4, "text": " thing that's happening is that your model of the world changes and maybe the exact", "tokens": [51392, 551, 300, 311, 2737, 307, 300, 428, 2316, 295, 264, 1002, 2962, 293, 1310, 264, 1900, 51580], "temperature": 0.0, "avg_logprob": -0.06875094720872782, "compression_ratio": 1.8149350649350648, "no_speech_prob": 0.0005971093196421862}, {"id": 625, "seek": 295008, "start": 2974.4, "end": 2978.4, "text": " counterfactual cooperation that you're carrying out changes, but otherwise the framework sort of", "tokens": [51580, 5682, 44919, 901, 14968, 300, 291, 434, 9792, 484, 2962, 11, 457, 5911, 264, 8388, 1333, 295, 51780], "temperature": 0.0, "avg_logprob": -0.06875094720872782, "compression_ratio": 1.8149350649350648, "no_speech_prob": 0.0005971093196421862}, {"id": 626, "seek": 297840, "start": 2978.4, "end": 2983.52, "text": " holds. So with that, I want to thank the main people who helped me do this kind of work,", "tokens": [50364, 9190, 13, 407, 365, 300, 11, 286, 528, 281, 1309, 264, 2135, 561, 567, 4254, 385, 360, 341, 733, 295, 589, 11, 50620], "temperature": 0.0, "avg_logprob": -0.13533676371854894, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.0005859069642610848}, {"id": 627, "seek": 297840, "start": 2983.52, "end": 2987.6800000000003, "text": " and then maybe you for your attention. And there's a little bit of time for questions.", "tokens": [50620, 293, 550, 1310, 291, 337, 428, 3202, 13, 400, 456, 311, 257, 707, 857, 295, 565, 337, 1651, 13, 50828], "temperature": 0.0, "avg_logprob": -0.13533676371854894, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.0005859069642610848}, {"id": 628, "seek": 297840, "start": 2999.52, "end": 3004.96, "text": " So one thing I'm curious is, I assume notions of causality are probably somewhat universal,", "tokens": [51420, 407, 472, 551, 286, 478, 6369, 307, 11, 286, 6552, 35799, 295, 3302, 1860, 366, 1391, 8344, 11455, 11, 51692], "temperature": 0.0, "avg_logprob": -0.13533676371854894, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.0005859069642610848}, {"id": 629, "seek": 300496, "start": 3005.04, "end": 3009.76, "text": " but especially issues of moral judgment, intention are likely dependent to some extent on", "tokens": [50368, 457, 2318, 2663, 295, 9723, 12216, 11, 7789, 366, 3700, 12334, 281, 512, 8396, 322, 50604], "temperature": 0.0, "avg_logprob": -0.15219750696299028, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002042583655565977}, {"id": 630, "seek": 300496, "start": 3009.76, "end": 3013.68, "text": " environmental factors, cultural factors, those kinds of things. And so I'm curious if you've", "tokens": [50604, 8303, 6771, 11, 6988, 6771, 11, 729, 3685, 295, 721, 13, 400, 370, 286, 478, 6369, 498, 291, 600, 50800], "temperature": 0.0, "avg_logprob": -0.15219750696299028, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002042583655565977}, {"id": 631, "seek": 300496, "start": 3013.68, "end": 3017.04, "text": " either observed those in your experiments or if you have some way of controlling for those", "tokens": [50800, 2139, 13095, 729, 294, 428, 12050, 420, 498, 291, 362, 512, 636, 295, 14905, 337, 729, 50968], "temperature": 0.0, "avg_logprob": -0.15219750696299028, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002042583655565977}, {"id": 632, "seek": 300496, "start": 3017.04, "end": 3023.44, "text": " factors when you recruit participants. Yeah, so that's an interesting question. And I think", "tokens": [50968, 6771, 562, 291, 15119, 10503, 13, 865, 11, 370, 300, 311, 364, 1880, 1168, 13, 400, 286, 519, 51288], "temperature": 0.0, "avg_logprob": -0.15219750696299028, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002042583655565977}, {"id": 633, "seek": 300496, "start": 3023.44, "end": 3030.4, "text": " even notions of causality actually, there are cultural effects like who you see there. So", "tokens": [51288, 754, 35799, 295, 3302, 1860, 767, 11, 456, 366, 6988, 5065, 411, 567, 291, 536, 456, 13, 407, 51636], "temperature": 0.0, "avg_logprob": -0.15219750696299028, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.002042583655565977}, {"id": 634, "seek": 303040, "start": 3031.28, "end": 3036.2400000000002, "text": " when making causal judgments, there's often, there's basically like in many cases,", "tokens": [50408, 562, 1455, 38755, 40337, 11, 456, 311, 2049, 11, 456, 311, 1936, 411, 294, 867, 3331, 11, 50656], "temperature": 0.0, "avg_logprob": -0.14182163154991873, "compression_ratio": 1.8531468531468531, "no_speech_prob": 0.00042855029460042715}, {"id": 635, "seek": 303040, "start": 3037.04, "end": 3040.88, "text": " what's called the problem of causal selection, how do I even decide what thing to pick out of", "tokens": [50696, 437, 311, 1219, 264, 1154, 295, 38755, 9450, 11, 577, 360, 286, 754, 4536, 437, 551, 281, 1888, 484, 295, 50888], "temperature": 0.0, "avg_logprob": -0.14182163154991873, "compression_ratio": 1.8531468531468531, "no_speech_prob": 0.00042855029460042715}, {"id": 636, "seek": 303040, "start": 3040.88, "end": 3045.6800000000003, "text": " as the cause in the first place. In my setting, very often I've kind of made it pretty easy,", "tokens": [50888, 382, 264, 3082, 294, 264, 700, 1081, 13, 682, 452, 3287, 11, 588, 2049, 286, 600, 733, 295, 1027, 309, 1238, 1858, 11, 51128], "temperature": 0.0, "avg_logprob": -0.14182163154991873, "compression_ratio": 1.8531468531468531, "no_speech_prob": 0.00042855029460042715}, {"id": 637, "seek": 303040, "start": 3045.6800000000003, "end": 3050.48, "text": " and I've sort of constrained it because I already told you like these are the possible causes,", "tokens": [51128, 293, 286, 600, 1333, 295, 38901, 309, 570, 286, 1217, 1907, 291, 411, 613, 366, 264, 1944, 7700, 11, 51368], "temperature": 0.0, "avg_logprob": -0.14182163154991873, "compression_ratio": 1.8531468531468531, "no_speech_prob": 0.00042855029460042715}, {"id": 638, "seek": 303040, "start": 3051.52, "end": 3055.44, "text": " but in the real world it's not like that. And it's sometimes, we may see something,", "tokens": [51420, 457, 294, 264, 957, 1002, 309, 311, 406, 411, 300, 13, 400, 309, 311, 2171, 11, 321, 815, 536, 746, 11, 51616], "temperature": 0.0, "avg_logprob": -0.14182163154991873, "compression_ratio": 1.8531468531468531, "no_speech_prob": 0.00042855029460042715}, {"id": 639, "seek": 303040, "start": 3055.44, "end": 3059.6800000000003, "text": " we may see a person as a cause, or we may see a system as a cause, or we may also", "tokens": [51616, 321, 815, 536, 257, 954, 382, 257, 3082, 11, 420, 321, 815, 536, 257, 1185, 382, 257, 3082, 11, 420, 321, 815, 611, 51828], "temperature": 0.0, "avg_logprob": -0.14182163154991873, "compression_ratio": 1.8531468531468531, "no_speech_prob": 0.00042855029460042715}, {"id": 640, "seek": 305968, "start": 3059.68, "end": 3064.3999999999996, "text": " see the kind of counterfactuals that may come to mind to us may also depend on what our background", "tokens": [50364, 536, 264, 733, 295, 5682, 44919, 901, 82, 300, 815, 808, 281, 1575, 281, 505, 815, 611, 5672, 322, 437, 527, 3678, 50600], "temperature": 0.0, "avg_logprob": -0.11899588537997886, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.0003976831503678113}, {"id": 641, "seek": 305968, "start": 3064.3999999999996, "end": 3069.68, "text": " is. And it often tells us something about, oh, when somebody then gives a certain counterfactual,", "tokens": [50600, 307, 13, 400, 309, 2049, 5112, 505, 746, 466, 11, 1954, 11, 562, 2618, 550, 2709, 257, 1629, 5682, 44919, 901, 11, 50864], "temperature": 0.0, "avg_logprob": -0.11899588537997886, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.0003976831503678113}, {"id": 642, "seek": 305968, "start": 3069.68, "end": 3075.04, "text": " it tells us quite a bit about them. So this comes up in the context, for example, also of victim", "tokens": [50864, 309, 5112, 505, 1596, 257, 857, 466, 552, 13, 407, 341, 1487, 493, 294, 264, 4319, 11, 337, 1365, 11, 611, 295, 6760, 51132], "temperature": 0.0, "avg_logprob": -0.11899588537997886, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.0003976831503678113}, {"id": 643, "seek": 305968, "start": 3075.04, "end": 3079.8399999999997, "text": " blaming. Like if that's the counterfactual that came to mind to you, oh, that tells me something", "tokens": [51132, 32364, 13, 1743, 498, 300, 311, 264, 5682, 44919, 901, 300, 1361, 281, 1575, 281, 291, 11, 1954, 11, 300, 5112, 385, 746, 51372], "temperature": 0.0, "avg_logprob": -0.11899588537997886, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.0003976831503678113}, {"id": 644, "seek": 305968, "start": 3079.8399999999997, "end": 3086.24, "text": " like about you. So I would say that even in that context, there are strong kind of interpersonal", "tokens": [51372, 411, 466, 291, 13, 407, 286, 576, 584, 300, 754, 294, 300, 4319, 11, 456, 366, 2068, 733, 295, 47102, 51692], "temperature": 0.0, "avg_logprob": -0.11899588537997886, "compression_ratio": 1.8037037037037038, "no_speech_prob": 0.0003976831503678113}, {"id": 645, "seek": 308624, "start": 3086.3199999999997, "end": 3092.4799999999996, "text": " and cultural effects that affect how we attribute causality. Now when it comes to intention inferences,", "tokens": [50368, 293, 6988, 5065, 300, 3345, 577, 321, 19667, 3302, 1860, 13, 823, 562, 309, 1487, 281, 7789, 13596, 2667, 11, 50676], "temperature": 0.0, "avg_logprob": -0.114480252535838, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.0006250187288969755}, {"id": 646, "seek": 308624, "start": 3092.4799999999996, "end": 3096.7999999999997, "text": " I'm not sure that that process in and of itself, that at least to me feels relatively", "tokens": [50676, 286, 478, 406, 988, 300, 300, 1399, 294, 293, 295, 2564, 11, 300, 412, 1935, 281, 385, 3417, 7226, 50892], "temperature": 0.0, "avg_logprob": -0.114480252535838, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.0006250187288969755}, {"id": 647, "seek": 308624, "start": 3098.7999999999997, "end": 3103.2799999999997, "text": " whatever universal, that we kind of, we have to engage in that all the time by trying to", "tokens": [50992, 2035, 11455, 11, 300, 321, 733, 295, 11, 321, 362, 281, 4683, 294, 300, 439, 264, 565, 538, 1382, 281, 51216], "temperature": 0.0, "avg_logprob": -0.114480252535838, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.0006250187288969755}, {"id": 648, "seek": 308624, "start": 3103.2799999999997, "end": 3108.8799999999997, "text": " predict what other people are intending in the way that we interact with them. But then again,", "tokens": [51216, 6069, 437, 661, 561, 366, 560, 2029, 294, 264, 636, 300, 321, 4648, 365, 552, 13, 583, 550, 797, 11, 51496], "temperature": 0.0, "avg_logprob": -0.114480252535838, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.0006250187288969755}, {"id": 649, "seek": 308624, "start": 3108.8799999999997, "end": 3115.04, "text": " how maybe then judgments in this case of responsibility or morality like draw on these", "tokens": [51496, 577, 1310, 550, 40337, 294, 341, 1389, 295, 6357, 420, 29106, 411, 2642, 322, 613, 51804], "temperature": 0.0, "avg_logprob": -0.114480252535838, "compression_ratio": 1.6788321167883211, "no_speech_prob": 0.0006250187288969755}, {"id": 650, "seek": 311504, "start": 3115.04, "end": 3120.08, "text": " different components, for example, that I've laid out here, no claim that that is in any sense", "tokens": [50364, 819, 6677, 11, 337, 1365, 11, 300, 286, 600, 9897, 484, 510, 11, 572, 3932, 300, 300, 307, 294, 604, 2020, 50616], "temperature": 0.0, "avg_logprob": -0.1475226411195559, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009458937565796077}, {"id": 651, "seek": 311504, "start": 3120.08, "end": 3126.64, "text": " sort of universal. But it might very well be that in certain cultures like this kind of what I take", "tokens": [50616, 1333, 295, 11455, 13, 583, 309, 1062, 588, 731, 312, 300, 294, 1629, 12951, 411, 341, 733, 295, 437, 286, 747, 50944], "temperature": 0.0, "avg_logprob": -0.1475226411195559, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009458937565796077}, {"id": 652, "seek": 311504, "start": 3126.64, "end": 3131.2799999999997, "text": " here to be more the person component, right, may have a stronger influence on responsibility", "tokens": [50944, 510, 281, 312, 544, 264, 954, 6542, 11, 558, 11, 815, 362, 257, 7249, 6503, 322, 6357, 51176], "temperature": 0.0, "avg_logprob": -0.1475226411195559, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009458937565796077}, {"id": 653, "seek": 311504, "start": 3131.2799999999997, "end": 3136.56, "text": " judgments and in others, it might mostly be about causality. I certainly in my experiments", "tokens": [51176, 40337, 293, 294, 2357, 11, 309, 1062, 5240, 312, 466, 3302, 1860, 13, 286, 3297, 294, 452, 12050, 51440], "temperature": 0.0, "avg_logprob": -0.1475226411195559, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009458937565796077}, {"id": 654, "seek": 311504, "start": 3137.84, "end": 3141.52, "text": " for individual participants see a lot of variance along the lines. But there's some people that", "tokens": [51504, 337, 2609, 10503, 536, 257, 688, 295, 21977, 2051, 264, 3876, 13, 583, 456, 311, 512, 561, 300, 51688], "temperature": 0.0, "avg_logprob": -0.1475226411195559, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.0009458937565796077}, {"id": 655, "seek": 314152, "start": 3141.52, "end": 3145.6, "text": " don't care about even the intention part at all. They just say like, oh, when it's about responsible,", "tokens": [50364, 500, 380, 1127, 466, 754, 264, 7789, 644, 412, 439, 13, 814, 445, 584, 411, 11, 1954, 11, 562, 309, 311, 466, 6250, 11, 50568], "temperature": 0.0, "avg_logprob": -0.09959136394032261, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0020376001484692097}, {"id": 656, "seek": 314152, "start": 3145.6, "end": 3150.4, "text": " I just look at what would have happened if they hadn't been there. And then other participants,", "tokens": [50568, 286, 445, 574, 412, 437, 576, 362, 2011, 498, 436, 8782, 380, 668, 456, 13, 400, 550, 661, 10503, 11, 50808], "temperature": 0.0, "avg_logprob": -0.09959136394032261, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0020376001484692097}, {"id": 657, "seek": 314152, "start": 3150.4, "end": 3157.12, "text": " judgments are suggesting that they care about the intention part much more. But I have not yet", "tokens": [50808, 40337, 366, 18094, 300, 436, 1127, 466, 264, 7789, 644, 709, 544, 13, 583, 286, 362, 406, 1939, 51144], "temperature": 0.0, "avg_logprob": -0.09959136394032261, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0020376001484692097}, {"id": 658, "seek": 314152, "start": 3157.7599999999998, "end": 3161.84, "text": " engaged in the kind of work that then tries to explain why is it, why is it that this person", "tokens": [51176, 8237, 294, 264, 733, 295, 589, 300, 550, 9898, 281, 2903, 983, 307, 309, 11, 983, 307, 309, 300, 341, 954, 51380], "temperature": 0.0, "avg_logprob": -0.09959136394032261, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0020376001484692097}, {"id": 659, "seek": 314152, "start": 3161.84, "end": 3166.48, "text": " casts so much about causality and why is it that this person casts so much about the intention", "tokens": [51380, 41921, 370, 709, 466, 3302, 1860, 293, 983, 307, 309, 300, 341, 954, 41921, 370, 709, 466, 264, 7789, 51612], "temperature": 0.0, "avg_logprob": -0.09959136394032261, "compression_ratio": 1.889763779527559, "no_speech_prob": 0.0020376001484692097}, {"id": 660, "seek": 316648, "start": 3166.48, "end": 3175.84, "text": " part, for example. Thank you. I'm going to hug the mic actually. I'm interested, like, do you think", "tokens": [50364, 644, 11, 337, 1365, 13, 1044, 291, 13, 286, 478, 516, 281, 8777, 264, 3123, 767, 13, 286, 478, 3102, 11, 411, 11, 360, 291, 519, 50832], "temperature": 0.0, "avg_logprob": -0.13614022213479746, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.005706273950636387}, {"id": 661, "seek": 316648, "start": 3175.84, "end": 3181.92, "text": " this model applies to other settings? Because all of the examples were sort of like physical or", "tokens": [50832, 341, 2316, 13165, 281, 661, 6257, 30, 1436, 439, 295, 264, 5110, 645, 1333, 295, 411, 4001, 420, 51136], "temperature": 0.0, "avg_logprob": -0.13614022213479746, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.005706273950636387}, {"id": 662, "seek": 316648, "start": 3181.92, "end": 3187.36, "text": " agents taking physical actions. So if you had just like a verbal description of some social", "tokens": [51136, 12554, 1940, 4001, 5909, 13, 407, 498, 291, 632, 445, 411, 257, 24781, 3855, 295, 512, 2093, 51408], "temperature": 0.0, "avg_logprob": -0.13614022213479746, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.005706273950636387}, {"id": 663, "seek": 316648, "start": 3187.36, "end": 3191.84, "text": " scenario where there's like speech acts that are causing things, do you think it would work the same?", "tokens": [51408, 9005, 689, 456, 311, 411, 6218, 10672, 300, 366, 9853, 721, 11, 360, 291, 519, 309, 576, 589, 264, 912, 30, 51632], "temperature": 0.0, "avg_logprob": -0.13614022213479746, "compression_ratio": 1.6208333333333333, "no_speech_prob": 0.005706273950636387}, {"id": 664, "seek": 319184, "start": 3192.32, "end": 3198.08, "text": " Yeah. Yeah, that's a great question. So would it work the same? So my sense is like, yeah, in a", "tokens": [50388, 865, 13, 865, 11, 300, 311, 257, 869, 1168, 13, 407, 576, 309, 589, 264, 912, 30, 407, 452, 2020, 307, 411, 11, 1338, 11, 294, 257, 50676], "temperature": 0.0, "avg_logprob": -0.14706013679504396, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.0008120921556837857}, {"id": 665, "seek": 319184, "start": 3198.08, "end": 3208.08, "text": " similar way, so there's a number of things here, I think. So we have applied the model a little bit,", "tokens": [50676, 2531, 636, 11, 370, 456, 311, 257, 1230, 295, 721, 510, 11, 286, 519, 13, 407, 321, 362, 6456, 264, 2316, 257, 707, 857, 11, 51176], "temperature": 0.0, "avg_logprob": -0.14706013679504396, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.0008120921556837857}, {"id": 666, "seek": 319184, "start": 3208.08, "end": 3212.88, "text": " like this kind of counterfactual simulation model in the physical world, also two speech acts.", "tokens": [51176, 411, 341, 733, 295, 5682, 44919, 901, 16575, 2316, 294, 264, 4001, 1002, 11, 611, 732, 6218, 10672, 13, 51416], "temperature": 0.0, "avg_logprob": -0.14706013679504396, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.0008120921556837857}, {"id": 667, "seek": 319184, "start": 3212.88, "end": 3217.28, "text": " And there it's in the context of like, we were basically jealous of, you know,", "tokens": [51416, 400, 456, 309, 311, 294, 264, 4319, 295, 411, 11, 321, 645, 1936, 13805, 295, 11, 291, 458, 11, 51636], "temperature": 0.0, "avg_logprob": -0.14706013679504396, "compression_ratio": 1.5879828326180256, "no_speech_prob": 0.0008120921556837857}, {"id": 668, "seek": 321728, "start": 3218.2400000000002, "end": 3221.84, "text": " for those of you who remember full wolf, you had these different words, right? And we were like,", "tokens": [50412, 337, 729, 295, 291, 567, 1604, 1577, 19216, 11, 291, 632, 613, 819, 2283, 11, 558, 30, 400, 321, 645, 411, 11, 50592], "temperature": 0.0, "avg_logprob": -0.178480116789006, "compression_ratio": 1.685512367491166, "no_speech_prob": 0.000952081405557692}, {"id": 669, "seek": 321728, "start": 3221.84, "end": 3226.0800000000004, "text": " oh, our model can only do like cause and prevent. That's kind of sad. But there's other causal", "tokens": [50592, 1954, 11, 527, 2316, 393, 787, 360, 411, 3082, 293, 4871, 13, 663, 311, 733, 295, 4227, 13, 583, 456, 311, 661, 38755, 50804], "temperature": 0.0, "avg_logprob": -0.178480116789006, "compression_ratio": 1.685512367491166, "no_speech_prob": 0.000952081405557692}, {"id": 670, "seek": 321728, "start": 3226.0800000000004, "end": 3232.7200000000003, "text": " expressions, of course, right? Enabling, affecting, letting, allowing, and so on. And it's going to be", "tokens": [50804, 15277, 11, 295, 1164, 11, 558, 30, 2193, 20112, 11, 17476, 11, 8295, 11, 8293, 11, 293, 370, 322, 13, 400, 309, 311, 516, 281, 312, 51136], "temperature": 0.0, "avg_logprob": -0.178480116789006, "compression_ratio": 1.685512367491166, "no_speech_prob": 0.000952081405557692}, {"id": 671, "seek": 321728, "start": 3232.7200000000003, "end": 3237.1200000000003, "text": " a little bit of a of doing, but I'll get there. So we were trying to see to what extent this", "tokens": [51136, 257, 707, 857, 295, 257, 295, 884, 11, 457, 286, 603, 483, 456, 13, 407, 321, 645, 1382, 281, 536, 281, 437, 8396, 341, 51356], "temperature": 0.0, "avg_logprob": -0.178480116789006, "compression_ratio": 1.685512367491166, "no_speech_prob": 0.000952081405557692}, {"id": 672, "seek": 321728, "start": 3237.1200000000003, "end": 3241.2000000000003, "text": " framework that we have could also allow us to explain differences between these different", "tokens": [51356, 8388, 300, 321, 362, 727, 611, 2089, 505, 281, 2903, 7300, 1296, 613, 819, 51560], "temperature": 0.0, "avg_logprob": -0.178480116789006, "compression_ratio": 1.685512367491166, "no_speech_prob": 0.000952081405557692}, {"id": 673, "seek": 324120, "start": 3242.0, "end": 3247.68, "text": " expressions, right? And, and this also comes up, you know, in philosophy, like even questions,", "tokens": [50404, 15277, 11, 558, 30, 400, 11, 293, 341, 611, 1487, 493, 11, 291, 458, 11, 294, 10675, 11, 411, 754, 1651, 11, 50688], "temperature": 0.0, "avg_logprob": -0.13911691352502623, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.03612189739942551}, {"id": 674, "seek": 324120, "start": 3247.68, "end": 3252.08, "text": " so the question versus killing versus causing to die, even people like in cases of abortion,", "tokens": [50688, 370, 264, 1168, 5717, 8011, 5717, 9853, 281, 978, 11, 754, 561, 411, 294, 3331, 295, 22902, 11, 50908], "temperature": 0.0, "avg_logprob": -0.13911691352502623, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.03612189739942551}, {"id": 675, "seek": 324120, "start": 3252.08, "end": 3255.9199999999996, "text": " you know, the way that you talk about it, right? Again, reveals something, you know,", "tokens": [50908, 291, 458, 11, 264, 636, 300, 291, 751, 466, 309, 11, 558, 30, 3764, 11, 20893, 746, 11, 291, 458, 11, 51100], "temperature": 0.0, "avg_logprob": -0.13911691352502623, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.03612189739942551}, {"id": 676, "seek": 324120, "start": 3255.9199999999996, "end": 3260.72, "text": " how you think about it. And in general, right, like this distinction also, when you have that as", "tokens": [51100, 577, 291, 519, 466, 309, 13, 400, 294, 2674, 11, 558, 11, 411, 341, 16844, 611, 11, 562, 291, 362, 300, 382, 51340], "temperature": 0.0, "avg_logprob": -0.13911691352502623, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.03612189739942551}, {"id": 677, "seek": 324120, "start": 3260.72, "end": 3265.2799999999997, "text": " an alternative that you could have said killing, but you chose causing to die, it suggests maybe", "tokens": [51340, 364, 8535, 300, 291, 727, 362, 848, 8011, 11, 457, 291, 5111, 9853, 281, 978, 11, 309, 13409, 1310, 51568], "temperature": 0.0, "avg_logprob": -0.13911691352502623, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.03612189739942551}, {"id": 678, "seek": 324120, "start": 3265.2799999999997, "end": 3268.24, "text": " a more roundabout way in which something happened, right? Like the person killed it,", "tokens": [51568, 257, 544, 3098, 21970, 636, 294, 597, 746, 2011, 11, 558, 30, 1743, 264, 954, 4652, 309, 11, 51716], "temperature": 0.0, "avg_logprob": -0.13911691352502623, "compression_ratio": 1.9131944444444444, "no_speech_prob": 0.03612189739942551}, {"id": 679, "seek": 326824, "start": 3268.24, "end": 3272.8799999999997, "text": " caused them to die. You think, yeah, it would be weird to say that someone caused them to die", "tokens": [50364, 7008, 552, 281, 978, 13, 509, 519, 11, 1338, 11, 309, 576, 312, 3657, 281, 584, 300, 1580, 7008, 552, 281, 978, 50596], "temperature": 0.0, "avg_logprob": -0.12255859375, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.0027978469152003527}, {"id": 680, "seek": 326824, "start": 3272.8799999999997, "end": 3276.72, "text": " when they like, you know, directly walked up to them and, you know, shot them. This also came", "tokens": [50596, 562, 436, 411, 11, 291, 458, 11, 3838, 7628, 493, 281, 552, 293, 11, 291, 458, 11, 3347, 552, 13, 639, 611, 1361, 50788], "temperature": 0.0, "avg_logprob": -0.12255859375, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.0027978469152003527}, {"id": 681, "seek": 326824, "start": 3276.72, "end": 3282.0, "text": " up recently or still coming up these days, actually, with the case of Alec Baldwin, Rust,", "tokens": [50788, 493, 3938, 420, 920, 1348, 493, 613, 1708, 11, 767, 11, 365, 264, 1389, 295, 9366, 66, 46050, 11, 34952, 11, 51052], "temperature": 0.0, "avg_logprob": -0.12255859375, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.0027978469152003527}, {"id": 682, "seek": 326824, "start": 3282.0, "end": 3286.08, "text": " like in the movie, right? The way that people talk about it was it will hold the gun that", "tokens": [51052, 411, 294, 264, 3169, 11, 558, 30, 440, 636, 300, 561, 751, 466, 309, 390, 309, 486, 1797, 264, 3874, 300, 51256], "temperature": 0.0, "avg_logprob": -0.12255859375, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.0027978469152003527}, {"id": 683, "seek": 326824, "start": 3286.08, "end": 3290.56, "text": " discharged or something rather than, you know, shot the person, right? So it matters a lot,", "tokens": [51256, 37081, 420, 746, 2831, 813, 11, 291, 458, 11, 3347, 264, 954, 11, 558, 30, 407, 309, 7001, 257, 688, 11, 51480], "temperature": 0.0, "avg_logprob": -0.12255859375, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.0027978469152003527}, {"id": 684, "seek": 326824, "start": 3290.56, "end": 3295.2, "text": " basically, like in this case, the choice of word, right? And the, and the, in some sense,", "tokens": [51480, 1936, 11, 411, 294, 341, 1389, 11, 264, 3922, 295, 1349, 11, 558, 30, 400, 264, 11, 293, 264, 11, 294, 512, 2020, 11, 51712], "temperature": 0.0, "avg_logprob": -0.12255859375, "compression_ratio": 1.823920265780731, "no_speech_prob": 0.0027978469152003527}, {"id": 685, "seek": 329520, "start": 3295.2, "end": 3299.52, "text": " the counterfactual alternatives you could have had, right, for them, the image that it's creating", "tokens": [50364, 264, 5682, 44919, 901, 20478, 291, 727, 362, 632, 11, 558, 11, 337, 552, 11, 264, 3256, 300, 309, 311, 4084, 50580], "temperature": 0.0, "avg_logprob": -0.10689818536913073, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.003941166680306196}, {"id": 686, "seek": 329520, "start": 3299.52, "end": 3304.16, "text": " in the listener in this case, right? So the fact that, oh, you chose this expression suggests to me", "tokens": [50580, 294, 264, 31569, 294, 341, 1389, 11, 558, 30, 407, 264, 1186, 300, 11, 1954, 11, 291, 5111, 341, 6114, 13409, 281, 385, 50812], "temperature": 0.0, "avg_logprob": -0.10689818536913073, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.003941166680306196}, {"id": 687, "seek": 329520, "start": 3304.16, "end": 3308.8799999999997, "text": " that the scenario must have been such, like rather than such. So that's at least the minimal way,", "tokens": [50812, 300, 264, 9005, 1633, 362, 668, 1270, 11, 411, 2831, 813, 1270, 13, 407, 300, 311, 412, 1935, 264, 13206, 636, 11, 51048], "temperature": 0.0, "avg_logprob": -0.10689818536913073, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.003941166680306196}, {"id": 688, "seek": 329520, "start": 3308.8799999999997, "end": 3313.04, "text": " I think, in which it applies also to, to thinking about speech acts, right? And thinking like,", "tokens": [51048, 286, 519, 11, 294, 597, 309, 13165, 611, 281, 11, 281, 1953, 466, 6218, 10672, 11, 558, 30, 400, 1953, 411, 11, 51256], "temperature": 0.0, "avg_logprob": -0.10689818536913073, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.003941166680306196}, {"id": 689, "seek": 329520, "start": 3313.04, "end": 3317.2, "text": " yeah. And of course, you could think like, oh, you know, again, take the advice example, would the", "tokens": [51256, 1338, 13, 400, 295, 1164, 11, 291, 727, 519, 411, 11, 1954, 11, 291, 458, 11, 797, 11, 747, 264, 5192, 1365, 11, 576, 264, 51464], "temperature": 0.0, "avg_logprob": -0.10689818536913073, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.003941166680306196}, {"id": 690, "seek": 329520, "start": 3317.2, "end": 3322.16, "text": " students still have done that if I had not said that, right? So we are obviously causing each other", "tokens": [51464, 1731, 920, 362, 1096, 300, 498, 286, 632, 406, 848, 300, 11, 558, 30, 407, 321, 366, 2745, 9853, 1184, 661, 51712], "temperature": 0.0, "avg_logprob": -0.10689818536913073, "compression_ratio": 1.8235294117647058, "no_speech_prob": 0.003941166680306196}, {"id": 691, "seek": 332216, "start": 3322.24, "end": 3326.96, "text": " a lot in the way that we talk to each other. And sometimes, you know, yeah. Also, of course,", "tokens": [50368, 257, 688, 294, 264, 636, 300, 321, 751, 281, 1184, 661, 13, 400, 2171, 11, 291, 458, 11, 1338, 13, 2743, 11, 295, 1164, 11, 50604], "temperature": 0.0, "avg_logprob": -0.13886135966837906, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0008669566013850272}, {"id": 692, "seek": 332216, "start": 3326.96, "end": 3331.92, "text": " after talking, I might think like, oh, I wish I had, I had answered this question from differently", "tokens": [50604, 934, 1417, 11, 286, 1062, 519, 411, 11, 1954, 11, 286, 3172, 286, 632, 11, 286, 632, 10103, 341, 1168, 490, 7614, 50852], "temperature": 0.0, "avg_logprob": -0.13886135966837906, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0008669566013850272}, {"id": 693, "seek": 332216, "start": 3332.48, "end": 3335.68, "text": " than what I actually did. And I regret it, right? And things like that.", "tokens": [50880, 813, 437, 286, 767, 630, 13, 400, 286, 10879, 309, 11, 558, 30, 400, 721, 411, 300, 13, 51040], "temperature": 0.0, "avg_logprob": -0.13886135966837906, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0008669566013850272}, {"id": 694, "seek": 332216, "start": 3338.48, "end": 3343.3599999999997, "text": " Yeah. So on a similar note, I'm wondering if you have thoughts on how possible it would be to", "tokens": [51180, 865, 13, 407, 322, 257, 2531, 3637, 11, 286, 478, 6359, 498, 291, 362, 4598, 322, 577, 1944, 309, 576, 312, 281, 51424], "temperature": 0.0, "avg_logprob": -0.13886135966837906, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0008669566013850272}, {"id": 695, "seek": 332216, "start": 3344.24, "end": 3349.68, "text": " use this model on society, large scale societal events, their divisive, such as what cost a", "tokens": [51468, 764, 341, 2316, 322, 4086, 11, 2416, 4373, 33472, 3931, 11, 641, 25974, 488, 11, 1270, 382, 437, 2063, 257, 51740], "temperature": 0.0, "avg_logprob": -0.13886135966837906, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0008669566013850272}, {"id": 696, "seek": 334968, "start": 3349.68, "end": 3356.64, "text": " person to be elected, what cost code outbreaks, or what causes climate change, like how possible", "tokens": [50364, 954, 281, 312, 11776, 11, 437, 2063, 3089, 39097, 11, 420, 437, 7700, 5659, 1319, 11, 411, 577, 1944, 50712], "temperature": 0.0, "avg_logprob": -0.1535153542795489, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.001601917902007699}, {"id": 697, "seek": 334968, "start": 3356.64, "end": 3361.3599999999997, "text": " would it be to apply this to those events and also what challenges you foresee? Yeah. Yeah,", "tokens": [50712, 576, 309, 312, 281, 3079, 341, 281, 729, 3931, 293, 611, 437, 4759, 291, 38736, 30, 865, 13, 865, 11, 50948], "temperature": 0.0, "avg_logprob": -0.1535153542795489, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.001601917902007699}, {"id": 698, "seek": 334968, "start": 3361.3599999999997, "end": 3366.7999999999997, "text": " that's a great question. And, and so, so I had the example of example at the beginning with like,", "tokens": [50948, 300, 311, 257, 869, 1168, 13, 400, 11, 293, 370, 11, 370, 286, 632, 264, 1365, 295, 1365, 412, 264, 2863, 365, 411, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1535153542795489, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.001601917902007699}, {"id": 699, "seek": 334968, "start": 3366.7999999999997, "end": 3370.08, "text": " oh, did the fall of Lehman Brothers caused the financial crisis, right? That's sort of like,", "tokens": [51220, 1954, 11, 630, 264, 2100, 295, 42631, 1601, 19886, 7008, 264, 4669, 5869, 11, 558, 30, 663, 311, 1333, 295, 411, 11, 51384], "temperature": 0.0, "avg_logprob": -0.1535153542795489, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.001601917902007699}, {"id": 700, "seek": 334968, "start": 3370.08, "end": 3374.56, "text": " large scale. And I don't know, right? And, and, and partly it might, so, and there's a few options,", "tokens": [51384, 2416, 4373, 13, 400, 286, 500, 380, 458, 11, 558, 30, 400, 11, 293, 11, 293, 17031, 309, 1062, 11, 370, 11, 293, 456, 311, 257, 1326, 3956, 11, 51608], "temperature": 0.0, "avg_logprob": -0.1535153542795489, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.001601917902007699}, {"id": 701, "seek": 334968, "start": 3374.56, "end": 3379.04, "text": " right? One is like, okay, just like totally punting, right? And saying like, okay, well, if the system", "tokens": [51608, 558, 30, 1485, 307, 411, 11, 1392, 11, 445, 411, 3879, 4468, 783, 11, 558, 30, 400, 1566, 411, 11, 1392, 11, 731, 11, 498, 264, 1185, 51832], "temperature": 0.0, "avg_logprob": -0.1535153542795489, "compression_ratio": 1.7477477477477477, "no_speech_prob": 0.001601917902007699}, {"id": 702, "seek": 337904, "start": 3379.04, "end": 3383.6, "text": " gets sufficiently complex, such that I cannot carry out the relevant counterfactual computation", "tokens": [50364, 2170, 31868, 3997, 11, 1270, 300, 286, 2644, 3985, 484, 264, 7340, 5682, 44919, 901, 24903, 50592], "temperature": 0.0, "avg_logprob": -0.08090115212774895, "compression_ratio": 1.8198757763975155, "no_speech_prob": 0.00046451520756818354}, {"id": 703, "seek": 337904, "start": 3383.6, "end": 3388.8, "text": " anymore, well, I just don't know, right? I cannot give that causal answer. That's, that's one version,", "tokens": [50592, 3602, 11, 731, 11, 286, 445, 500, 380, 458, 11, 558, 30, 286, 2644, 976, 300, 38755, 1867, 13, 663, 311, 11, 300, 311, 472, 3037, 11, 50852], "temperature": 0.0, "avg_logprob": -0.08090115212774895, "compression_ratio": 1.8198757763975155, "no_speech_prob": 0.00046451520756818354}, {"id": 704, "seek": 337904, "start": 3388.8, "end": 3393.36, "text": " right? And there's another version where you say like, okay, well, to the extent that I can maybe,", "tokens": [50852, 558, 30, 400, 456, 311, 1071, 3037, 689, 291, 584, 411, 11, 1392, 11, 731, 11, 281, 264, 8396, 300, 286, 393, 1310, 11, 51080], "temperature": 0.0, "avg_logprob": -0.08090115212774895, "compression_ratio": 1.8198757763975155, "no_speech_prob": 0.00046451520756818354}, {"id": 705, "seek": 337904, "start": 3393.36, "end": 3398.88, "text": " you know, abstract away from a lot of the lower level details that say of some, so if I'm, if I'm,", "tokens": [51080, 291, 458, 11, 12649, 1314, 490, 257, 688, 295, 264, 3126, 1496, 4365, 300, 584, 295, 512, 11, 370, 498, 286, 478, 11, 498, 286, 478, 11, 51356], "temperature": 0.0, "avg_logprob": -0.08090115212774895, "compression_ratio": 1.8198757763975155, "no_speech_prob": 0.00046451520756818354}, {"id": 706, "seek": 337904, "start": 3398.88, "end": 3404.0, "text": " if I have the capacity to build maybe a more abstract model, which, which I can now simulate,", "tokens": [51356, 498, 286, 362, 264, 6042, 281, 1322, 1310, 257, 544, 12649, 2316, 11, 597, 11, 597, 286, 393, 586, 27817, 11, 51612], "temperature": 0.0, "avg_logprob": -0.08090115212774895, "compression_ratio": 1.8198757763975155, "no_speech_prob": 0.00046451520756818354}, {"id": 707, "seek": 337904, "start": 3404.0, "end": 3408.56, "text": " right, then I might be giving you an answer sort of on that level, right? And so, but then it's", "tokens": [51612, 558, 11, 550, 286, 1062, 312, 2902, 291, 364, 1867, 1333, 295, 322, 300, 1496, 11, 558, 30, 400, 370, 11, 457, 550, 309, 311, 51840], "temperature": 0.0, "avg_logprob": -0.08090115212774895, "compression_ratio": 1.8198757763975155, "no_speech_prob": 0.00046451520756818354}, {"id": 708, "seek": 340856, "start": 3408.56, "end": 3412.96, "text": " also half punting, right? Because now you have to kind of come up with a good model of how people", "tokens": [50364, 611, 1922, 4468, 783, 11, 558, 30, 1436, 586, 291, 362, 281, 733, 295, 808, 493, 365, 257, 665, 2316, 295, 577, 561, 50584], "temperature": 0.0, "avg_logprob": -0.0839137817496684, "compression_ratio": 1.746177370030581, "no_speech_prob": 0.0001868969266070053}, {"id": 709, "seek": 340856, "start": 3412.96, "end": 3418.08, "text": " generate the right kind of causal abstractions for some situation that then allow them to compute", "tokens": [50584, 8460, 264, 558, 733, 295, 38755, 12649, 626, 337, 512, 2590, 300, 550, 2089, 552, 281, 14722, 50840], "temperature": 0.0, "avg_logprob": -0.0839137817496684, "compression_ratio": 1.746177370030581, "no_speech_prob": 0.0001868969266070053}, {"id": 710, "seek": 340856, "start": 3418.08, "end": 3423.2, "text": " the counterfactual, because now it's not messy anymore, right? And another thing that I should", "tokens": [50840, 264, 5682, 44919, 901, 11, 570, 586, 309, 311, 406, 16191, 3602, 11, 558, 30, 400, 1071, 551, 300, 286, 820, 51096], "temperature": 0.0, "avg_logprob": -0.0839137817496684, "compression_ratio": 1.746177370030581, "no_speech_prob": 0.0001868969266070053}, {"id": 711, "seek": 340856, "start": 3423.2, "end": 3427.2799999999997, "text": " mention, and that quite a lot of the work on responsibility that I've, that I've looked at", "tokens": [51096, 2152, 11, 293, 300, 1596, 257, 688, 295, 264, 589, 322, 6357, 300, 286, 600, 11, 300, 286, 600, 2956, 412, 51300], "temperature": 0.0, "avg_logprob": -0.0839137817496684, "compression_ratio": 1.746177370030581, "no_speech_prob": 0.0001868969266070053}, {"id": 712, "seek": 340856, "start": 3427.2799999999997, "end": 3432.32, "text": " particularly in groups, the sort of situations that you pointed out, like elections and, you know,", "tokens": [51300, 4098, 294, 3935, 11, 264, 1333, 295, 6851, 300, 291, 10932, 484, 11, 411, 12870, 293, 11, 291, 458, 11, 51552], "temperature": 0.0, "avg_logprob": -0.0839137817496684, "compression_ratio": 1.746177370030581, "no_speech_prob": 0.0001868969266070053}, {"id": 713, "seek": 340856, "start": 3432.32, "end": 3436.96, "text": " global warming, they're, they're characterized by, by large degrees of over determination,", "tokens": [51552, 4338, 17983, 11, 436, 434, 11, 436, 434, 29361, 538, 11, 538, 2416, 5310, 295, 670, 18432, 11, 51784], "temperature": 0.0, "avg_logprob": -0.0839137817496684, "compression_ratio": 1.746177370030581, "no_speech_prob": 0.0001868969266070053}, {"id": 714, "seek": 343696, "start": 3436.96, "end": 3443.52, "text": " right? Like in election, you hardly ever cast a pivotal vote, right? And, and so those also", "tokens": [50364, 558, 30, 1743, 294, 6618, 11, 291, 13572, 1562, 4193, 257, 39078, 4740, 11, 558, 30, 400, 11, 293, 370, 729, 611, 50692], "temperature": 0.0, "avg_logprob": -0.1247389638746107, "compression_ratio": 1.8848684210526316, "no_speech_prob": 0.00032638528500683606}, {"id": 715, "seek": 343696, "start": 3443.52, "end": 3447.68, "text": " traditionally were problems for counterfactual accounts, right? Because everyone can say like,", "tokens": [50692, 19067, 645, 2740, 337, 5682, 44919, 901, 9402, 11, 558, 30, 1436, 1518, 393, 584, 411, 11, 50900], "temperature": 0.0, "avg_logprob": -0.1247389638746107, "compression_ratio": 1.8848684210526316, "no_speech_prob": 0.00032638528500683606}, {"id": 716, "seek": 343696, "start": 3447.68, "end": 3452.32, "text": " I made no difference, like if I fly every day, you know, that's not really going to make a difference.", "tokens": [50900, 286, 1027, 572, 2649, 11, 411, 498, 286, 3603, 633, 786, 11, 291, 458, 11, 300, 311, 406, 534, 516, 281, 652, 257, 2649, 13, 51132], "temperature": 0.0, "avg_logprob": -0.1247389638746107, "compression_ratio": 1.8848684210526316, "no_speech_prob": 0.00032638528500683606}, {"id": 717, "seek": 343696, "start": 3452.32, "end": 3457.28, "text": " And so, and there you can, and similar with election, why should I go vote, right? Because", "tokens": [51132, 400, 370, 11, 293, 456, 291, 393, 11, 293, 2531, 365, 6618, 11, 983, 820, 286, 352, 4740, 11, 558, 30, 1436, 51380], "temperature": 0.0, "avg_logprob": -0.1247389638746107, "compression_ratio": 1.8848684210526316, "no_speech_prob": 0.00032638528500683606}, {"id": 718, "seek": 343696, "start": 3457.28, "end": 3460.7200000000003, "text": " if my vote's not going to make any difference, right? And there at least models have been built", "tokens": [51380, 498, 452, 4740, 311, 406, 516, 281, 652, 604, 2649, 11, 558, 30, 400, 456, 412, 1935, 5245, 362, 668, 3094, 51552], "temperature": 0.0, "avg_logprob": -0.1247389638746107, "compression_ratio": 1.8848684210526316, "no_speech_prob": 0.00032638528500683606}, {"id": 719, "seek": 343696, "start": 3460.7200000000003, "end": 3465.6, "text": " that then say like, okay, well, it's not, you're not off the hook, right? It's basically saying,", "tokens": [51552, 300, 550, 584, 411, 11, 1392, 11, 731, 11, 309, 311, 406, 11, 291, 434, 406, 766, 264, 6328, 11, 558, 30, 467, 311, 1936, 1566, 11, 51796], "temperature": 0.0, "avg_logprob": -0.1247389638746107, "compression_ratio": 1.8848684210526316, "no_speech_prob": 0.00032638528500683606}, {"id": 720, "seek": 346560, "start": 3465.6, "end": 3469.2799999999997, "text": " even if you would not have made a difference in this particular situation,", "tokens": [50364, 754, 498, 291, 576, 406, 362, 1027, 257, 2649, 294, 341, 1729, 2590, 11, 50548], "temperature": 0.0, "avg_logprob": -0.0858036263348305, "compression_ratio": 1.8053691275167785, "no_speech_prob": 0.0007074543391354382}, {"id": 721, "seek": 346560, "start": 3469.2799999999997, "end": 3472.7999999999997, "text": " maybe the degree of responsibility that you have for some election, for example,", "tokens": [50548, 1310, 264, 4314, 295, 6357, 300, 291, 362, 337, 512, 6618, 11, 337, 1365, 11, 50724], "temperature": 0.0, "avg_logprob": -0.0858036263348305, "compression_ratio": 1.8053691275167785, "no_speech_prob": 0.0007074543391354382}, {"id": 722, "seek": 346560, "start": 3472.7999999999997, "end": 3477.12, "text": " maybe related to how close you were to making a difference to the outcome, right? If it's like,", "tokens": [50724, 1310, 4077, 281, 577, 1998, 291, 645, 281, 1455, 257, 2649, 281, 264, 9700, 11, 558, 30, 759, 309, 311, 411, 11, 50940], "temperature": 0.0, "avg_logprob": -0.0858036263348305, "compression_ratio": 1.8053691275167785, "no_speech_prob": 0.0007074543391354382}, {"id": 723, "seek": 346560, "start": 3477.12, "end": 3482.16, "text": " if the outcome is 6-5, you feel very responsible. If it's like 7-4, a little less. If it's like", "tokens": [50940, 498, 264, 9700, 307, 1386, 12, 20, 11, 291, 841, 588, 6250, 13, 759, 309, 311, 411, 1614, 12, 19, 11, 257, 707, 1570, 13, 759, 309, 311, 411, 51192], "temperature": 0.0, "avg_logprob": -0.0858036263348305, "compression_ratio": 1.8053691275167785, "no_speech_prob": 0.0007074543391354382}, {"id": 724, "seek": 346560, "start": 3482.16, "end": 3487.8399999999997, "text": " 8-3, a little less, right? But not, but it shouldn't go to zero, right? And then, and then as it,", "tokens": [51192, 1649, 12, 18, 11, 257, 707, 1570, 11, 558, 30, 583, 406, 11, 457, 309, 4659, 380, 352, 281, 4018, 11, 558, 30, 400, 550, 11, 293, 550, 382, 309, 11, 51476], "temperature": 0.0, "avg_logprob": -0.0858036263348305, "compression_ratio": 1.8053691275167785, "no_speech_prob": 0.0007074543391354382}, {"id": 725, "seek": 346560, "start": 3487.8399999999997, "end": 3491.52, "text": " maybe now relates to kind of, you know, global warming and so on, part of the challenge then", "tokens": [51476, 1310, 586, 16155, 281, 733, 295, 11, 291, 458, 11, 4338, 17983, 293, 370, 322, 11, 644, 295, 264, 3430, 550, 51660], "temperature": 0.0, "avg_logprob": -0.0858036263348305, "compression_ratio": 1.8053691275167785, "no_speech_prob": 0.0007074543391354382}, {"id": 726, "seek": 349152, "start": 3491.52, "end": 3496.96, "text": " from the more like, you know, what do we do about it? Side might be like, okay, how do we make it", "tokens": [50364, 490, 264, 544, 411, 11, 291, 458, 11, 437, 360, 321, 360, 466, 309, 30, 19026, 1062, 312, 411, 11, 1392, 11, 577, 360, 321, 652, 309, 50636], "temperature": 0.0, "avg_logprob": -0.12575883772766705, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0010419944301247597}, {"id": 727, "seek": 349152, "start": 3496.96, "end": 3503.36, "text": " such that people don't perceive a sort of, you know, going to zero sense of responsibility,", "tokens": [50636, 1270, 300, 561, 500, 380, 20281, 257, 1333, 295, 11, 291, 458, 11, 516, 281, 4018, 2020, 295, 6357, 11, 50956], "temperature": 0.0, "avg_logprob": -0.12575883772766705, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0010419944301247597}, {"id": 728, "seek": 349152, "start": 3503.36, "end": 3508.8, "text": " right? Such that you feel like actually the actions that you do make a difference to the outcome.", "tokens": [50956, 558, 30, 9653, 300, 291, 841, 411, 767, 264, 5909, 300, 291, 360, 652, 257, 2649, 281, 264, 9700, 13, 51228], "temperature": 0.0, "avg_logprob": -0.12575883772766705, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0010419944301247597}, {"id": 729, "seek": 349152, "start": 3508.8, "end": 3516.16, "text": " And so, yeah, so that's, so I think a mix of thoughts, I guess, in response to your question.", "tokens": [51228, 400, 370, 11, 1338, 11, 370, 300, 311, 11, 370, 286, 519, 257, 2890, 295, 4598, 11, 286, 2041, 11, 294, 4134, 281, 428, 1168, 13, 51596], "temperature": 0.0, "avg_logprob": -0.12575883772766705, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0010419944301247597}, {"id": 730, "seek": 351616, "start": 3517.12, "end": 3522.16, "text": " So we're about it, time. Is there a reminder if you are here? If you're logging attendance,", "tokens": [50412, 407, 321, 434, 466, 309, 11, 565, 13, 1119, 456, 257, 13548, 498, 291, 366, 510, 30, 759, 291, 434, 27991, 24337, 11, 50664], "temperature": 0.0, "avg_logprob": -0.26982318333217076, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.08609481155872345}, {"id": 731, "seek": 351616, "start": 3522.16, "end": 3526.3999999999996, "text": " make sure to grab one of these code words up at the front and give Toby a compliment on his", "tokens": [50664, 652, 988, 281, 4444, 472, 295, 613, 3089, 2283, 493, 412, 264, 1868, 293, 976, 40223, 257, 16250, 322, 702, 50876], "temperature": 0.0, "avg_logprob": -0.26982318333217076, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.08609481155872345}, {"id": 732, "seek": 351616, "start": 3526.3999999999996, "end": 3530.7999999999997, "text": " talk on your way out, maybe make you come up next door. Let's thank our speaker.", "tokens": [50876, 751, 322, 428, 636, 484, 11, 1310, 652, 291, 808, 493, 958, 2853, 13, 961, 311, 1309, 527, 8145, 13, 51096], "temperature": 0.0, "avg_logprob": -0.26982318333217076, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.08609481155872345}], "language": "en"}