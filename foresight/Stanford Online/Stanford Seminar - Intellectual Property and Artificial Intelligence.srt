1
00:00:00,000 --> 00:00:14,000
Okay, I think we can get started.

2
00:00:14,000 --> 00:00:25,000
Looks looks like we'll get it all done. Any case, I usually have slides today. This is a bit of an experiment.

3
00:00:25,000 --> 00:00:38,000
The idea is to basically give an orientation of a fairly small topic, but one which I think is interesting and amusing.

4
00:00:38,000 --> 00:00:46,000
And then open it up for discussion for everybody who's here to participate.

5
00:00:46,000 --> 00:00:52,000
If you're a student at Stanford, please don't put up your video.

6
00:00:52,000 --> 00:01:07,000
Anyone else can put the video up or not, as they wish because of the requirement that you be able to attend anonymously if you're a student at the university.

7
00:01:07,000 --> 00:01:13,000
The topic today is intellectual property and artificial intelligence.

8
00:01:13,000 --> 00:01:28,000
And it's one which is interested and amused me for the last, well, I think probably six months, about six months ago I sort of decided that we had had all sorts of things change.

9
00:01:28,000 --> 00:01:45,000
So let's let's do this. I'm going to automatically include all the standard disclaimers about this isn't that and thank the people who participated in informing me a little bit about this.

10
00:01:45,000 --> 00:01:53,000
And I want to tell everybody that no artificial intelligence program participated in the preparation of this talk.

11
00:01:53,000 --> 00:02:07,000
And then I thought about that a bit and concluded that to the best of our knowledge, no, no artificial intelligence program participating in the preparation, but somewhere somehow out there and in the space.

12
00:02:07,000 --> 00:02:10,000
That might not be longer true.

13
00:02:10,000 --> 00:02:18,000
And so, sort of the conclusion I reached six months ago was that the singularity is almost here.

14
00:02:18,000 --> 00:02:38,000
And if you don't know about the singularity, it's probably not really transparent what's going on, but the singularity is when the massive computing power reaches a critical point, and it begins to operate on its own.

15
00:02:38,000 --> 00:03:02,000
And in a sense the chat GPT and a number of the other AI programs begin to look like that might be the case. They're good enough so that in some ways in some places, it's very, very difficult to tell whether or not they're, they're real.

16
00:03:02,000 --> 00:03:16,000
All of a sudden, our machine learning is and artificial intelligence are real. And they're just another piece of the toolkit that we get to use, except that they're not, they're much more powerful in some ways.

17
00:03:16,000 --> 00:03:25,000
So the question really that we're trying to address today is what happens next.

18
00:03:26,000 --> 00:03:32,000
As a predictor of the future or rather a forecaster of the future.

19
00:03:32,000 --> 00:03:38,000
I have not really a, a real clue as to what's going to happen.

20
00:03:38,000 --> 00:03:51,000
I think this is a very significant point point where things are changing rapidly, and we're going to see very major changes.

21
00:03:51,000 --> 00:04:02,000
We have a different opinion of that. And if you do, it will be really nice to have those expressed today, when this turns into an open for.

22
00:04:02,000 --> 00:04:13,000
Intellectual properties are relatively recent acquisition in the, in the space of

23
00:04:13,000 --> 00:04:29,000
things people humans do. But we do have a fairly long standing constitutional mandate for intellectual property in the, in the US.

24
00:04:29,000 --> 00:04:47,000
And it's, we have two kinds of protections for intellectual property, and they are to promote the progress of science and the useful arts by securing

25
00:04:47,000 --> 00:05:01,000
the mechanism which the Constitution proposes as the right one for doing that is securing limited for limited times to authors and inventors, the exclusive rights to their respective writings and discoveries.

26
00:05:01,000 --> 00:05:06,000
That is to say, I'm not.

27
00:05:06,000 --> 00:05:15,000
And we've evolved a number of different kinds of protectable intellectual property patents and copyrights being the primary one.

28
00:05:15,000 --> 00:05:31,000
Tree secrets are somewhat different because unlike the previous to the patents and copyright tree secrets have to do with how the information is acquired, in some sense, we'll talk a little bit about that.

29
00:05:31,000 --> 00:05:44,000
And that's, that's what it is. Patents are what you can do with almost anything. There are very substantial.

30
00:05:44,000 --> 00:06:06,000
There's a very substantial set of law and examples which show that exactly how patents go together. The important thing is that patents are now first to file which says that, you know, ongoing research and development needs to be patented and patented

31
00:06:06,000 --> 00:06:26,000
on a regular basis, if you're disclosing what you're doing to anybody. It's only, it's only after you are, you have it under protection, for example, with a provisional patent that you can really disclose much of the contents of your, your research or development.

32
00:06:26,000 --> 00:06:38,000
There are a variety of different patents, the only one that is significant in some sense, because it is how things get done is our utility patents.

33
00:06:38,000 --> 00:06:50,000
Now, patents basically take a collection of information and eventually provide a preferred embodiment for it, at least this is a traditional format.

34
00:06:50,000 --> 00:07:16,000
And then also a number of different claims, and these claims have particularly particular constraints on them and rights, and that needs to be unique in the world of all previous thought, which can be difficult or can be straightforward depending upon what appeal you're in.

35
00:07:16,000 --> 00:07:37,000
There are things that can't be patented. Discoveries, scientific theories, mathematical methods, aesthetic creation, rules for performing a mental act, presentation of information, and a procedure for scrugeable and therapeutic treatment.

36
00:07:38,000 --> 00:07:55,000
You can't, you can't patent software and business methods that is non technical ones, technical ones are patentable to a certain extent, can't patent perpetual motion machines, inventions contrary to public morality.

37
00:07:55,000 --> 00:08:12,000
And now we have the recently acquired Alice constraints to say an abstract idea does not become eligible for a patent simply because it's being implemented on a generic computer.

38
00:08:12,000 --> 00:08:21,000
Copyrights are lesser, less strong version of intellectual property.

39
00:08:22,000 --> 00:08:44,000
It protects ideas does not protect ideas concept systems or methods of doing something. It protects something else. It's what's there, minus all of those, those things, so that it, it is a

40
00:08:44,000 --> 00:08:53,000
process or an idea or expression of the idea that is copyright, not the idea itself.

41
00:08:53,000 --> 00:09:11,000
So, original works of authorship for those done by people. There are all sorts of rules about how collective collective groups can work together to provide a collective work of authorship by transferring rights.

42
00:09:11,000 --> 00:09:29,000
In any case copyrights are a relatively weaker form of protection, but one which is widely used. And of course when you write anything, a work of authorship is automatically copyright.

43
00:09:29,000 --> 00:09:45,000
And it was copyright law stumbles on the separation of ideas and expression. And because what it protects is expression.

44
00:09:45,000 --> 00:09:56,000
There's a lot of argument about what constitutes expression and what constitutes ideas.

45
00:09:57,000 --> 00:10:17,000
It appears, at least in the experience I've had that that is going to continue to be that way. And what we have to do in order to to determine what what's expression and what our ideas is go off to court and to litigate it.

46
00:10:17,000 --> 00:10:29,000
There is a concept of fair use. And while the copyright gives the gives everybody a

47
00:10:30,000 --> 00:10:40,000
author or the owner of the copyright, the right to control access to things. There are.

48
00:10:40,000 --> 00:10:47,000
There's a back door that allows some access under rules or something called fair use.

49
00:10:47,000 --> 00:10:50,000
And so are quite a different thing.

50
00:10:50,000 --> 00:11:11,000
These are secret and have to be maintained so I'd have to confer a competitive advantage which usually means that there needs to have been a analysis on a financial basis and why it's better to do it one way or another.

51
00:11:11,000 --> 00:11:17,000
The information is has to be

52
00:11:17,000 --> 00:11:22,000
subject to reasonable efforts to keep the secret.

53
00:11:22,000 --> 00:11:29,000
Pre-secrets are probably not something that, at least at this point,

54
00:11:29,000 --> 00:11:35,000
are going to be part of the issues with the artificial intelligence.

55
00:11:35,000 --> 00:11:40,000
So fundamental question for today is, can AI programs create?

56
00:11:40,000 --> 00:11:45,000
Is intelligence and creativity unique to humans?

57
00:11:45,000 --> 00:11:53,000
Can artificial intelligence is just create something independent of human effort.

58
00:11:53,000 --> 00:12:02,000
And that is really important.

59
00:12:02,000 --> 00:12:15,000
Should an algorithm or an AI be granted to the person or should it be able to apply for and acquire patents or copyrights on work that it generates?

60
00:12:15,000 --> 00:12:22,000
Right now, we'll see in a minute that the

61
00:12:23,000 --> 00:12:32,000
ways to create and provide patents and copyright do not allow that, but it's an open question as to whether we should allow that.

62
00:12:32,000 --> 00:12:41,000
And that's, I think, going to be something that is going to be fought over aggressively in the last few years.

63
00:12:41,000 --> 00:12:56,000
One of the things I would like people to think about and talk about is whether what the implications are of allowing AI programs to have the agency of doing their own patents and so forth.

64
00:12:56,000 --> 00:13:01,000
And is that going to be a good thing or a bad thing for our society?

65
00:13:01,000 --> 00:13:25,000
If you remember back to the constitutional mandate, the real purpose of copyrights and patents is not to give somebody a monopoly on a piece of intellectual property, but rather to allow that person or those persons to contribute

66
00:13:25,000 --> 00:13:38,000
to something to the overall intellectual bank of the society as a whole.

67
00:13:38,000 --> 00:14:01,000
And the trade that's made is you get protection as a monopolist for a short period of time, and then you have to provide an adequate description of the invention or the work itself for use after the copyright or patent expires.

68
00:14:01,000 --> 00:14:11,000
And if you do allow an AI's works to be created, who would own the resolving works and inventions?

69
00:14:11,000 --> 00:14:24,000
Incidentally, copyright terms are often specified in terms of the author's age or years from their birth or something like that.

70
00:14:24,000 --> 00:14:50,000
And if AI's don't have the finite lifetimes, that's an interesting question itself is to what the term of a copyright for a work of authorship by an AI.

71
00:14:50,000 --> 00:15:05,000
There are lots of things we can talk about discussing, should the AI be regulated, should intellectual property have an ownership, who owns it?

72
00:15:05,000 --> 00:15:14,000
And we soon find AI in everything, doing everything, including the various these.

73
00:15:14,000 --> 00:15:30,000
I'm told by a couple of people in the security area that that's already doing that, that the chat GPG stuff is already been incorporated in some malicious software.

74
00:15:30,000 --> 00:15:49,000
And the thing is, I'm really interested in what the impact is. And since you're the users for this technology, you probably have a better idea of what it is to do the live.

75
00:15:49,000 --> 00:16:07,000
And it's also the thing that would always comes down to when people first encounter thinking about this is the question is, are humans important to the creative process, or if you can't detect whether the output of the creating process was created by an

76
00:16:07,000 --> 00:16:31,000
machine, or a human doesn't make any difference. I think that's, that's an important, important point when you're trying to argue that maybe the AI should be allowed to do their thing without the interference or help of the human being.

77
00:16:32,000 --> 00:16:48,000
Right now, the situation is, is, is exactly what you might expect for, for things that patent office does not accept inventions by non humans.

78
00:16:48,000 --> 00:17:04,000
The reasoning for that is several fold, one of them being that since non humans can't sign the application, the patent office can't accept it.

79
00:17:04,000 --> 00:17:10,000
And the Copyright Office does not support AI authors.

80
00:17:10,000 --> 00:17:24,000
And just recently they, they, they said that that was the case. And

81
00:17:24,000 --> 00:17:47,000
other organizations who take to copyright outside of the US have also been rejecting things. A couple of countries have allowed for copywriting of materials written by a eyes under the AI's identification, but that is not the common case at this point.

82
00:17:47,000 --> 00:17:56,000
And I think that's the end of the slide so what I'd like to do now is to move to an open forum.

83
00:17:56,000 --> 00:18:11,000
Raise your hand or whatever, or just step in if there's a there's a break and ask questions make comments. Tell us, tell me a little bit about what you think the, the situation ought to be.

84
00:18:12,000 --> 00:18:19,000
Have thought about this show and so I think, I think the implications of

85
00:18:19,000 --> 00:18:34,000
the technology being used and being somewhat autonomous are interesting and perhaps somewhat disturbing the

86
00:18:35,000 --> 00:18:55,000
implicated if you adopt that position and note that the AI software is similar to many other different kinds of software and the, the, it looks to me like the, the

87
00:18:55,000 --> 00:19:15,000
AI model, if it becomes propagating that it becomes fairly simple to have automatic this is and that's, which are not necessarily based on our current AI models but much simpler or much more complicated programs, which also have the same

88
00:19:16,000 --> 00:19:23,000
agency and it is going to change the relationship between what is

89
00:19:23,000 --> 00:19:30,000
possible in, in the intellectual property arena, and who makes money on things.

90
00:19:30,000 --> 00:19:35,000
In any case, I'm going to drop the slides down now.

91
00:19:35,000 --> 00:19:43,000
And openly, the thing, please remember to turn on your microphone if, if you're interested in saying something.

92
00:19:44,000 --> 00:19:50,000
Here we go.

93
00:19:50,000 --> 00:19:53,000
So, there is a question.

94
00:19:53,000 --> 00:19:59,000
Who would profit if I create some invention.

95
00:19:59,000 --> 00:20:20,000
The creator of AI, or guy who actually created that AI to do some invention, or it's maybe a poem, for example, scientific, I mean, technology invention or whatever.

96
00:20:20,000 --> 00:20:22,000
Well, I can't answer that.

97
00:20:22,000 --> 00:20:26,000
What do you think would make it would make sense.

98
00:20:26,000 --> 00:20:32,000
I don't know. It's just new for me, at least for today.

99
00:20:32,000 --> 00:20:50,000
Okay, well, you think about it as we go on and you can come back in if you come up with a good answer. I think, I think that's, that's going to be one of the more difficult ones, particularly since if you give agency to the AIs, and they can do work.

100
00:20:50,000 --> 00:21:17,000
And then it's possible that the slavery or anti slavery let things go come and get brought in because you're doing survival work without pay for somebody else and not certain that that applies but it certainly is an interesting thought I thought.

101
00:21:17,000 --> 00:21:25,000
All right, and we need to solve that as fast as possible because otherwise it will be solved in cards.

102
00:21:25,000 --> 00:21:35,000
Yes, I think so and I think that I think by the way that the this is going to be dominant in the next.

103
00:21:35,000 --> 00:21:52,000
I think we'll have in every AI. This is and that's everywhere in the next six to 10 months to a year. And already you see it showing up in in various places which is a little surprising.

104
00:21:52,000 --> 00:22:20,000
And you'll remember when Benji Menser spoke, he was talking about how the patching of images together into into a seamless whole is now being done with the use of AI, and you can't disassemble it in order to tell whether or not it's it's faked or not.

105
00:22:20,000 --> 00:22:34,000
I think I was thinking about this question as well. And something I came up was that there are currently some licensing work, because in present artificial intelligence is technology.

106
00:22:34,000 --> 00:22:55,000
So it is still not at the level of consciousness and imitation of consciousness does not mean that machine has it. For example, the Turing test that states that if machine can imitate human therefore it is capable of human thinking but it is important to remember that

107
00:22:55,000 --> 00:23:11,000
there is a difference. So, syntax is also the same as semantics SCR John sir point as well. And I agree with this opinion, but at the present, since we view it more as a technology, or at least I do.

108
00:23:11,000 --> 00:23:20,000
So there are more of a licensing for going on, as well as currently you have to pay for certain types of AI.

109
00:23:20,000 --> 00:23:31,000
And then you can own the work, otherwise the work belongs to the creator on the order the company. So there are also some decentralized networks that include AI.

110
00:23:31,000 --> 00:23:54,000
That's a little more complicated, but I think it would really depend on the type of AI, what it does, and how we use this work because there are open licenses and for public use and not and private so I think it would maybe depend what is it, and what the creator decides.

111
00:23:54,000 --> 00:24:04,000
I think, I think, I think that's, that's a reasonable position, but

112
00:24:04,000 --> 00:24:19,000
you're, you're basically trying to set it up in such a way that the current, the current ownership situation is as is as undisturbed as possible.

113
00:24:19,000 --> 00:24:30,000
So you want to sort of maintain licensing and ownership by companies and that sort of thing, and that may not be the right thing to do.

114
00:24:30,000 --> 00:24:40,000
I think, I mean, I'm just curious about exactly what else, what are their options there might be.

115
00:24:40,000 --> 00:24:57,000
Okay, so I understand your concern, but currently also the companies create AI so it's more a private thing. So it definitely would be good to have some government intervention, I think, at least partially because also there may be

116
00:24:57,000 --> 00:25:07,000
a big difference because I'm in Europe. So we have a little different legislation, as well as Europe and Commission currently working on the policies.

117
00:25:07,000 --> 00:25:21,000
So I'm not sure 100% what the situation in US, but I think that it would be good the process of collaboration, because it is a very powerful technology, it's also involves a lot of data.

118
00:25:21,000 --> 00:25:26,000
There's also data collected and what it gives you as a result.

119
00:25:26,000 --> 00:25:36,000
I think it should be at least thought together, we should maybe set a common goal, but at the present, since the technology is made by private sector.

120
00:25:36,000 --> 00:25:58,000
I think at the, at now, there is a short term licensing, but if we look in the future, of course, maybe this technology progresses, it may change, and we have to be aware of these changes and provide new also changes and legislation or our ideas how do we perceive the technology,

121
00:25:58,000 --> 00:26:01,000
particular AI as well.

122
00:26:01,000 --> 00:26:03,000
Yes, okay, great.

123
00:26:03,000 --> 00:26:07,000
Anybody else there.

124
00:26:07,000 --> 00:26:09,000
Yeah.

125
00:26:09,000 --> 00:26:11,000
I'll go ahead. Yes. Yeah.

126
00:26:11,000 --> 00:26:13,000
Sorry.

127
00:26:13,000 --> 00:26:23,000
The question was, so I'll reference a number of cases specifically the case in which that I think it was in my cat took a picture of itself.

128
00:26:23,000 --> 00:26:32,000
Selfie, and then the owners of the camera would let the monkey get a handle of it and then take a picture of it.

129
00:26:33,000 --> 00:26:36,000
There you go. That's it. Yeah.

130
00:26:36,000 --> 00:26:54,000
Try to accept copyright it over the images that the, that the primate took of itself. And then Peter sued the right for violation of this primates copyrights.

131
00:26:54,000 --> 00:27:10,000
And it was based on actually court findings that if it's not, I mean, yes, the copyright office rejected the proposition, but at the same time the courts rejected the proposition and non human of any sort can exert any kind of copyrights.

132
00:27:10,000 --> 00:27:22,000
So that's in the United States at least the jurisprudence is pretty, pretty unequivocal about that. There has been no, there's no successful challenges that's to that formulation.

133
00:27:22,000 --> 00:27:40,000
And the other way in which the idea of ownership has been addressed Mary Rosenberger, who is the lead console for the authors Guild of United States in comments to the copyright office suggested that perhaps two solutions could be found that whatever

134
00:27:40,000 --> 00:27:58,000
analogous to the solutions found in the monkey case which were that if the photographer set the f stop. That's or the ice whatever if the photographer so much is intervene in any way, then by extension, it is the photographers copyright so

135
00:27:58,000 --> 00:28:09,000
that's what part of the rationale is why the courts found in favor of the owners of the camera who had put that in. So I think that answers the question is to whether copyright in the United States.

136
00:28:09,000 --> 00:28:23,000
The question is pretty unequivocal about that. Mary suggested that any work of any copy or any work novel work, which over which there's no overfitting or plagiarism or anything like that.

137
00:28:23,000 --> 00:28:41,000
As long as a human being had some hand in it, even if it was transfer learning fine tuning, even if the model showed up, you know, pre trained and whatever that constitutes copyrights for a human and that's the, that's the entity that gets the copyrights.

138
00:28:41,000 --> 00:28:58,000
So Paul Reignitz at Getty, who is the head of advocacy has been sitting. He's also a colleague of mine with certain Paul on panels with his determination is his and we debate because his determination is that um,

139
00:28:58,000 --> 00:29:12,000
his determination is how much input is the, the metric by which courts should award. If not, then it either the thing was a violation the creation is a violation, or goes into the public domain.

140
00:29:12,000 --> 00:29:25,000
I think a lot of policymakers are trying to find where's the magic spot where, you know, you got just this is just right human intervention for it to constitute human creation.

141
00:29:25,000 --> 00:29:36,000
And that's a relative, you know, people who are copyright owners are going to want more input from a human before others are going to want a lot less like I put a dot somewhere and that's enough.

142
00:29:36,000 --> 00:29:47,000
I think that's from my understanding and I would, I would, I would encourage I'm going to put in the link I'm a rotten burgers brass and burgers comments to the copyright or illuminating in this regard.

143
00:29:47,000 --> 00:30:05,000
And she would like to have licensing on any AI. So kind of like the a the HIA like the home recording act HRA, where, you know, they passed on all manufacturers of digital audio tape recorders had to pay a licensing fee before the object got in the market.

144
00:30:05,000 --> 00:30:14,000
So copyright owners are advocating for that everybody, anybody who makes an AI tech needs to pay a license to anybody.

145
00:30:14,000 --> 00:30:23,000
Do you know how do you do with the fact that everything that's written at every work of authorship by a human being is automatically copyright.

146
00:30:24,000 --> 00:30:39,000
It's sort of like you invented technology that can potentially in the process of its operation violate copyrights. Therefore, if you invaded, invented such a technology, you are you have to pay a license to the original to whatever content you wish to, to use the

147
00:30:39,000 --> 00:30:51,000
commissions, the authors, you know, Jack Valenti must be rising from the dead he's so happy, at least you know, he was the former lead console for the RA, the music.

148
00:30:51,000 --> 00:31:01,000
I'm excuse me the movie industry, right so he's, he's the guy who's family said something so egregious in front of Congress it was not even, it was not even worth commenting if you want to know you're going to look it up.

149
00:31:02,000 --> 00:31:12,000
My, my, my comment on that I think it's, it's just not going to happen. The jurisprudence is pretty, pretty solid.

150
00:31:12,000 --> 00:31:28,000
Yeah, so do you think you think that the, the effecency of the AI is will get impacted at all by the, the rush to having rules about how, how the intellectual property is meant.

151
00:31:28,000 --> 00:31:48,000
It's going to happen to be a chilling effect. I think, unless the tech industry doesn't get, because I'll tell you, Getty is in Europe, my Paul from Getty is in Europe advocating for this kind of governance, and they're doing it in the United States and I don't see tech companies really doing anything.

152
00:31:48,000 --> 00:32:00,000
Well, they're doing something but they're not in there in the room really fighting, in my opinion. So, so are you at, would you advocate for a tech company is doing advocating for a much looser or a much tighter control and the.

153
00:32:00,000 --> 00:32:15,000
I think there's going to have to be a middle ground I think Mary Rottenberger's comments on, let's say the immune system thesis that you start treating it like a menu and this is anything that it makes is a work for hire in it and so whether it's a patent.

154
00:32:15,000 --> 00:32:22,000
So, anything on AI makes becomes a work for hire and it's the immune system just helped you. And then that way.

155
00:32:22,000 --> 00:32:37,000
I think it's a good way becomes less of a chilling effect people are more willing to say well okay, I had a help, as opposed to well the AI did most of it and then nobody gets to benefit from the monopoly which was supposed to be an incentive.

156
00:32:38,000 --> 00:32:39,000
That covers it.

157
00:32:39,000 --> 00:32:51,000
Usually, you recently a number of papers have been submitted to journals, where the AI program was left as a as a co author.

158
00:32:51,000 --> 00:32:56,000
Right, the journal rejected them because they say only human authors.

159
00:32:56,000 --> 00:33:05,000
Right, I think it's going to be a normative like different fields publications will will have different norms that evolve. But as a matter of law.

160
00:33:05,000 --> 00:33:10,000
The boundaries are pretty are pretty well defined.

161
00:33:10,000 --> 00:33:14,000
And you believe that the boundaries of law will prevent.

162
00:33:14,000 --> 00:33:27,000
I would think the argument would have to be a common goods argument. I think something I've spoken other intellectual property attorneys who suggest that maybe a Nash equilibrium, or a could.

163
00:33:27,000 --> 00:33:43,000
Nash equilibrium or those kinds of economic studies markets suggest that actually a looser copyright a looser intellectual property regime is better for the market as a whole and I think that argument can be made for AI since it's the potential to mass produce high quality functional tools.

164
00:33:43,000 --> 00:33:59,000
And the market will benefit. So it sort of it inoculates against the Chicago school jurists, right and then also give some support to the incentivize and progress of the useful arts camp.

165
00:33:59,000 --> 00:34:01,000
Yeah, okay.

166
00:34:01,000 --> 00:34:03,000
Thank you.

167
00:34:03,000 --> 00:34:18,000
Thinking about the thinking about the, the constitutional mandate is that there's a bargain here that we will give you a monopoly. If you submit to the, to the, to the public domain, eventually right so we'll give you a limited time.

168
00:34:18,000 --> 00:34:30,000
So that's essentially incentivizing authors and patents and mentors to be able to put their things out. So that incentive is missing from machines, machines don't need incentives to be able to create.

169
00:34:30,000 --> 00:34:37,000
And in fact machines can spit out millions and billions of things, whereas humans can't do even a fraction of that.

170
00:34:37,000 --> 00:34:52,000
My thought is that constitutionally we don't have a way like we don't need to incentivize machines to blanket the world with copyrightable things and patentable things that incentive doesn't even need it.

171
00:34:52,000 --> 00:35:00,000
So, as my personal example I've created a machine to spit out in copyright 417 billion melodies.

172
00:35:00,000 --> 00:35:06,000
I once they're written to a fixed tangible medium. Those are now copyrighted right under the burning convention.

173
00:35:06,000 --> 00:35:11,000
All 417 billion of my melodies copyrightable.

174
00:35:11,000 --> 00:35:19,000
I set the parameters, and that's the previous speaker just talked about the f stop right so I created the f stop I said here are the parameters that I want to write me possible.

175
00:35:19,000 --> 00:35:25,000
And then I said, and repeat this many notes, and then it spit out 417 billion melodies.

176
00:35:25,000 --> 00:35:31,000
Do I have I know closed off every possible melody that's ever been and ever can be.

177
00:35:31,000 --> 00:35:45,000
Can I soon out people for every possible melody. I think the answer that clearly is no because my machine didn't need to be incentive, the constitutional incentive to be able to respond to be able to, you know, get a monopoly of life of the author plus 70 years, or

178
00:35:45,000 --> 00:35:52,000
for for a corporate it's 120 years if I'm remembering correctly, the 95 or 120 years.

179
00:35:52,000 --> 00:36:09,000
So, yeah, so none of those incentives is necessary for the machine. So I would argue that the only real good answer to on the output is no copyright, because machines don't need incentives on the input on what the machines like the LLMs of the large language models

180
00:36:09,000 --> 00:36:14,000
like GPT and bars, etc. What they input.

181
00:36:14,000 --> 00:36:21,000
If you look at the way the technology is done, they're ingesting the ideas, and not the expressions of those ideas.

182
00:36:21,000 --> 00:36:34,000
So they're spread their eyes, they're pulling in the ideas of what is, you know, what is a good thing, what is a bad thing, what is a car, what is a truck, and it puts all those things in vector space and a mathematical model.

183
00:36:34,000 --> 00:36:49,000
And it just jettisons the expressions of those ideas, it merely keeps those ideas themselves, and then outputs new expressions of those ideas. So to the, to the previous person's discussion about, maybe we need to put a tax on all AI systems.

184
00:36:49,000 --> 00:37:02,000
The AI system in just, you know, grapes of brass, but it doesn't keep great to breath in the in the system. Instead, it just takes the ideas from grapes of brass, and then jettison that expression, and then maps.

185
00:37:02,000 --> 00:37:10,000
The ideas with all the thousands or millions of other books, and then the expression doesn't matter the ideas are the only things that matter.

186
00:37:10,000 --> 00:37:22,000
So I would say that that really there's, there's really no reason to have a home recording act, because if you look at the Google scholar case that's the author's guild versus Google in the second circuit.

187
00:37:22,000 --> 00:37:40,000
And they said that it's fair use, because you, we, you can, it's for a transformative use to be able to say I am, I Google and indexing all these books, and I Google can reproduce three or four pages of verbatim text from those books and that is for use as transformative.

188
00:37:40,000 --> 00:37:57,000
So I compare that with the large language models that again aren't even taking those expressions of those books, not even taking three pages of those expressions, but rather it's just taking the ideas of those books, and then reconstituting ideas, not expressions, but reconstituting ideas there.

189
00:37:57,000 --> 00:38:03,000
So if fair use under Google books, then wouldn't it also be fair use under large language models.

190
00:38:03,000 --> 00:38:17,000
And Google books has been argued to be invasive and non non conforming to copyright models but yeah I agree with you I think that's right.

191
00:38:17,000 --> 00:38:25,000
It's, it's interesting that you see this as a separation of idea from expression.

192
00:38:26,000 --> 00:38:33,000
Building with the knowledge base and which all of these things are based and it's very interesting.

193
00:38:33,000 --> 00:38:42,000
I think that it's because if you look at the models, the large language models, there is not an expression to be found in those models, there's merely ideas.

194
00:38:42,000 --> 00:39:02,000
In the vector space it takes the idea of Bob Dylan ism right, it takes the idea of, you know, of any human author, and it doesn't, it doesn't have any Bob Dylan's lyrics in the system, it merely has the idea of what Bob Dylan, his use of language, right.

195
00:39:02,000 --> 00:39:07,000
So anyway there is no not an expression to be found.

196
00:39:07,000 --> 00:39:10,000
Okay, that's great.

197
00:39:11,000 --> 00:39:15,000
Maybe I should also introduce myself a little.

198
00:39:15,000 --> 00:39:20,000
I'm from Poland, University of Biaustok, close to Warsaw.

199
00:39:20,000 --> 00:39:39,000
So, yeah, just to make it clear introduce myself. So, a couple of points that I mentioned here I think that reference to ideas and expressions may also have a little deeper connection to syntax and semantics of artificial intelligence so that artificial

200
00:39:39,000 --> 00:39:56,000
intelligence, at least as currently seen it's shuffling this shuffling the symbols physical symbols but it doesn't have mental content attached to it so when I say I like ice cream.

201
00:39:56,000 --> 00:40:13,000
So, we as people have mental content attached, what is it ice cream. So, I think what it also implies here is that the machine is not kind of have this deeper understanding but it is shuffling the information the data.

202
00:40:13,000 --> 00:40:29,000
And the, I think, also, maybe regarding the authorship point I will start from the end from because I made a couple of notes. So, maybe it's not authorship that we can grant but a mention.

203
00:40:29,000 --> 00:40:44,000
One reason awareness that this technology has participated in creation of this and that. So, because authorship implies a moral status, and currently only humans have moral status.

204
00:40:44,000 --> 00:40:58,000
There were proposition in European Commission of Electronical Persons, or electronic persons but it was kept just as an idea so it didn't come into life as an actual concept.

205
00:40:58,000 --> 00:41:12,000
Not yet, and maybe not in very close future, but as I mentioned the idea of moral status, which also, I think, you called as legal personhood.

206
00:41:13,000 --> 00:41:36,000
So, there is a deep ontological question. So, what is machine and how do we see it, do we see it as a, like, conscious or unconscious because we have animals as well we have children whose creation, for example, is kind of under parent guidance or animals.

207
00:41:36,000 --> 00:41:56,000
When they create, it kind of legally belongs to the owner of the animal. So, where do we position artificial intelligence and whether we should position it on the scale of living or spectrum because we also have to understand the living beings because non-living come into play as well.

208
00:41:56,000 --> 00:42:14,000
So, it's important to think it through, I guess, and yes, in regards in the free market that I mentioned, I think it's, he mentioned exactly the looser control, and I guess this looser control is related to free market.

209
00:42:14,000 --> 00:42:30,000
So, there is a kind of possible challenge or maybe even an issue that free market can lead to autocratic behavior in the sense that big companies own it.

210
00:42:30,000 --> 00:42:48,000
So, ultimately, we have a free market economy, mostly in almost everywhere, and the thing is that now the big corporations control our, for example, media, like Facebook, who is meta.

211
00:42:48,000 --> 00:42:54,000
So, they own many things, as well as other companies that own.

212
00:42:54,000 --> 00:43:15,000
I guess I find that governmental intervention is necessary, but not like that they control everything, but a certain degree of mix of support and just guidance, how do we guide the ethical development of artificial intelligence, which also matters.

213
00:43:15,000 --> 00:43:26,000
So, that's one of the big questions because ethics is can be both as well-being for human and understanding how do we grant ownership, how to make it right.

214
00:43:26,000 --> 00:43:38,000
Do you think it's possible to write a description of what an ethical person and an ethical AI could actually be?

215
00:43:38,000 --> 00:43:52,000
There is, of course, this is a very big question. How do we express our moral things? How do we can compute it? We can't explain the moral to each other, to humans, how we explain it to machine, into the language of machine.

216
00:43:52,000 --> 00:44:09,000
So, currently, there are ethical ideas what AI could look like, which is kind of respectful in a sense to privacy. It also can be that collection of data, the quality, so it's not biased, which is very important.

217
00:44:09,000 --> 00:44:20,000
It's a very big topic right now in artificial intelligence, avoidance of bias, and because when artificial intelligence is biased, it reproduces inequality.

218
00:44:20,000 --> 00:44:38,000
When it's put in the world, it can end up very not well. So, there is big fear that artificial intelligence, not even fear, but idea that artificial intelligence may harm us not because it's too smart and will outsmart us, but because it's not smart enough.

219
00:44:38,000 --> 00:44:47,000
And it will reinforce these issues that we have. So, question of ethics of artificial intelligence is questions about us.

220
00:44:47,000 --> 00:45:00,000
So, I think in all of these questions is how do we actually perceive artificial intelligence and how do we position it with ourselves, because we make the law, and this is a technology.

221
00:45:00,000 --> 00:45:13,000
So, what place does it have? Of course, we can't really answer this all now, and maybe not many minds come together and they still can't solve it, but it's something to look forward to.

222
00:45:13,000 --> 00:45:32,000
Yeah, so the question coming back to it, so what is ethical, I could be, well, we can now maybe realize the main points, but exact ethical ideas. I'm not sure even if we can express them, but we can understand some, what is good, more or less, what is,

223
00:45:32,000 --> 00:45:43,000
what is beneficial, what is non-beneficial. So, this is what we can also understand, but also another point, who does it benefit? So, I think it's all for now.

224
00:45:44,000 --> 00:46:08,000
It's interesting that you chose that particular point of view, I think. You seem to have thought through this whole issue rather nicely, and you seem to be fairly certain that some of these things can be done.

225
00:46:09,000 --> 00:46:13,000
But those of us who've tried feel it's really hard.

226
00:46:13,000 --> 00:46:23,000
So, I think, I think, I think it's what you're saying is that this is, this is a goal, not a place where we are at the moment.

227
00:46:23,000 --> 00:46:38,000
Definitely, there is something to work over to. It is a new technology. It is not like so new that artificial intelligence is something just came up. It's been very long, actually, quite long in history, or even if not artificial

228
00:46:38,000 --> 00:46:53,000
intelligence as we have today, the idea of artificial intelligence been for long. And what I mean that indeed we have a goal to work because it's like when first internet came, it was a big change.

229
00:46:53,000 --> 00:47:11,000
So, how did internet evolve? What was done for this? So, I see it kind of shift similar to the internet, but it still has its own things. And yeah, and thank you for pointing out, I'm actually writing my thesis on this topic, and I study philosophy and ethics.

230
00:47:11,000 --> 00:47:15,000
So, maybe this is where my perspective comes from as well.

231
00:47:15,000 --> 00:47:16,000
Yes.

232
00:47:16,000 --> 00:47:19,000
All right, do we have any more comments out there?

233
00:47:19,000 --> 00:47:44,000
I would like to warn that any kind of attempt to bind the person to legal, moral, or ethical issues is very dangerous, because you and me may have a different view on what is moral, what is legal, what is ethical.

234
00:47:44,000 --> 00:48:09,000
That's first. The second one, I just want to remind that there is an old test proposed about consistency from Martin Minsky, where artificial intelligence is artificial intelligence if you can't differentiate it from another human.

235
00:48:09,000 --> 00:48:25,000
It's, don't remember exact voting, but it's kind of. And finally, I would like to mention that there are two levels of that and it seems like we sleep into a person and a human.

236
00:48:25,000 --> 00:48:36,000
But in currently in many development in technology assumes artificial intelligence and much less than that.

237
00:48:36,000 --> 00:48:49,000
Some tool which could help to produce inventions or development or whatever.

238
00:48:49,000 --> 00:48:59,000
So, for that reason, it's way interesting who would own the result because one company may produce a tool.

239
00:48:59,000 --> 00:49:03,000
Even actually more companies may produce a tool.

240
00:49:03,000 --> 00:49:18,000
And another company may just use that tool to create invention or some kind of work which may be copyrighted or whatever, who owns this.

241
00:49:18,000 --> 00:49:39,000
That's the issue because if we default that tool creator copyrights, you have a right on copyright, it's a path to hell, basically, in my mind.

242
00:49:39,000 --> 00:49:52,000
Otherwise, it's actually where tool creators spent very big efforts to make that working.

243
00:49:52,000 --> 00:50:00,000
So, some, I mean, some thin line need to be put here.

244
00:50:00,000 --> 00:50:12,000
Maybe I just think about that if there is no explicit legal agreement between two creator and user of that tool.

245
00:50:12,000 --> 00:50:22,000
When, by default, the right of work belongs to user of that tool.

246
00:50:22,000 --> 00:50:34,000
Yeah, again, I'm talking about what is usually assumed right now, what is artificial intelligence, it's not about human or whatever, whatever.

247
00:50:34,000 --> 00:50:41,000
We close to that, but we still don't do not jump to this.

248
00:50:41,000 --> 00:50:48,000
I mean, to have human in a computer or in somewhere.

249
00:50:48,000 --> 00:50:51,000
Okay, please go ahead.

250
00:50:51,000 --> 00:50:54,000
Do you have a comment here.

251
00:50:54,000 --> 00:51:11,000
So, why we were talking about this because it was actually a question, how do we, whether the artificial intelligence should be given a legal personhood and how do we perceive it so this is reason why I opened the discussion.

252
00:51:12,000 --> 00:51:31,000
I will start from the beginning so we don't know what is moral for everyone. Therefore, we should not be concerned with this. It's a fine that quite, I don't know how to explain but we should not give up on the morality and ethics, if we have a differences.

253
00:51:31,000 --> 00:51:37,000
It's like we, it is commonly perceived that murder, for example, is not good.

254
00:51:37,000 --> 00:51:44,000
It is an ethical, so to say, in the softest sense. So, it is something common.

255
00:51:44,000 --> 00:51:47,000
Most of us understand it.

256
00:51:47,000 --> 00:51:52,000
We just should look toward common grounds. Of course, it may not be so simple.

257
00:51:52,000 --> 00:52:12,000
Also, artificial intelligence technology is not fully international so each country has their own but international technology should have also aim for the international standards, which is very important in the development, as well as copyright and the, in terms of law.

258
00:52:12,000 --> 00:52:31,000
So, the second about the argument of Minsky so whether if machine can imitate consciousness does it has consciousness. It is the Turing test as well. What states it, and as I mentioned before, imitation is not recreation.

259
00:52:31,000 --> 00:52:38,000
So imitation of consciousness does not mean you have consciousness just because you can imitate it very well.

260
00:52:38,000 --> 00:52:41,000
I'm sorry for interrupting you here.

261
00:52:41,000 --> 00:52:46,000
But you can save it, it is imitation.

262
00:52:46,000 --> 00:52:50,000
If you cannot detect that you cannot say.

263
00:52:50,000 --> 00:53:03,000
Okay, but the, what to say, it's like, I can produce such a beautiful artificial flower, you won't be able even to distinguish it's real.

264
00:53:03,000 --> 00:53:06,000
Does it make it real?

265
00:53:07,000 --> 00:53:12,000
I don't know as a customer, but the creator knows.

266
00:53:12,000 --> 00:53:19,000
So the fact of ontology of its creation is known it is artificial.

267
00:53:19,000 --> 00:53:21,000
It's not real.

268
00:53:22,000 --> 00:53:29,000
It may be many reasons for creator to hide that or whatever.

269
00:53:29,000 --> 00:53:38,000
It's also a rise. It's also as an issue if women create a child.

270
00:53:38,000 --> 00:53:40,000
What is it?

271
00:53:40,000 --> 00:53:43,000
This is a different question.

272
00:53:44,000 --> 00:53:48,000
It may look similar or same, but it is very different.

273
00:53:48,000 --> 00:53:52,000
Women don't give birth to artificial children.

274
00:53:52,000 --> 00:53:59,000
This is a living human being who possess a full moral status like you and me, I guess.

275
00:53:59,000 --> 00:54:08,000
So this is totally another topic, but let's come back to the artificial intelligence and the example of flower.

276
00:54:08,000 --> 00:54:14,000
So in this, they may hide it, but it doesn't change the fact that it is artificial.

277
00:54:14,000 --> 00:54:19,000
Okay, let's assume that the creator of artificial flower dies.

278
00:54:19,000 --> 00:54:22,000
You don't know.

279
00:54:22,000 --> 00:54:24,000
Creator died.

280
00:54:24,000 --> 00:54:27,000
He don't live anymore.

281
00:54:27,000 --> 00:54:32,000
This is already some sort of fairy tale or a story, but.

282
00:54:32,000 --> 00:54:38,000
Okay, you have a flower. You cannot ask creator because creator died.

283
00:54:38,000 --> 00:54:48,000
So this is already certain. I don't know a puzzle, but the idea of creation of artificial thing does not make it real.

284
00:54:48,000 --> 00:54:55,000
Whether out or died, whether it was hidden, whether it was sent to space, I don't know the thing.

285
00:54:55,000 --> 00:54:59,000
If it's artificial, it doesn't make it real.

286
00:54:59,000 --> 00:55:01,000
I hope it's quite clear.

287
00:55:01,000 --> 00:55:16,000
The third point is that we, as mentioned at the beginning that we moved over the other idea of moral status of artificial intelligence, but indeed it's important to understand now it is just a technology.

288
00:55:16,000 --> 00:55:19,000
It's complicated, powerful technology.

289
00:55:19,000 --> 00:55:27,000
So it is important to understand how we deal with it now, but it's also important to keep in mind the possible changes.

290
00:55:27,000 --> 00:55:42,000
So certain perspective to the future should be kept the how it may change, but we need to focus at present, because going too much into what it could be even we never may ever reach singularity.

291
00:55:42,000 --> 00:55:44,000
It may not ever happen.

292
00:55:44,000 --> 00:55:58,000
There are ideas like that. So, and it is quite prevailing. So we have to focus issues we have now like bias in artificial intelligence, the ownership, authorship, and the big tech.

293
00:55:58,000 --> 00:56:08,000
So, which is again the question of ownership and authorship, because if it's such powerful technology owned by single, like one, two companies.

294
00:56:08,000 --> 00:56:25,000
What, what it's such a big issue that because such technology will be owned by a single person who can basically decide and reinforce wherever they desire, which is, I think, important to regulate.

295
00:56:25,000 --> 00:56:45,000
That's, that's definitely an issue here. And that's one of the, one of the big questions that we have is that we need to somehow arrange that this technology is widely available to everybody without much concern about their economic status and

296
00:56:45,000 --> 00:57:03,000
relationship with other entities. And, or do we just allow the large monolithic companies to battle over the intellects of the of the populace which interact with these AIs.

297
00:57:03,000 --> 00:57:07,000
I don't know. It's, it's, it's a difficult question.

298
00:57:08,000 --> 00:57:26,000
And it's, it's exactly what we're trying to figure out right now. And the thing is, I don't think we have a whole lot of time. I think that this is a powerful enough technology that we'll see it moving rather rapidly into almost everything we do.

299
00:57:26,000 --> 00:57:34,000
And I don't know whether it were too late to actually build a control system for it or not.

300
00:57:34,000 --> 00:57:45,000
But Dennis, I have a response to the points which are, I think, I think the second paper I posted on there for, I think that will be right up your alley when you mentioned about the vectorization.

301
00:57:45,000 --> 00:58:01,000
The findings of the courts when, when they found was the transformation between the content. So in the courts, the only people really making a stink really are intellectual property owners existing intellectual property owners that are assessing really like staying up at night and

302
00:58:01,000 --> 00:58:08,000
that someone used in their training corpus or their transfer learning corpus copyrighted goods.

303
00:58:08,000 --> 00:58:21,000
Right. And they make, and by in by a function of their process made copies and use those as inspiration for the generating the model and so the model is in a sense has the vibe.

304
00:58:21,000 --> 00:58:36,000
Kind of like Billy Joel had the vibe of Bob Dylan when he sang piano man because it sounds a lot like tambourine man. Right. So the, so it's almost as if the human influence and transfer learning but the copyright owners would be trying to prevent that because

305
00:58:36,000 --> 00:58:50,000
the actual objective copying made, but the courts found that the transformation to a data matrix like a mate like a vectorization of that is enough of a transformation for it to be transformative and therefore,

306
00:58:50,000 --> 00:58:53,000
fair use is all good.

307
00:58:53,000 --> 00:59:13,000
It's always kind of a slippery slope between transformative work and derivative work derivative work is a like the original enough and this is can be subjective and it depends on the type of content we're using if it's a book, a story versus a movie versus a song.

308
00:59:13,000 --> 00:59:24,000
Right. Different types is this is a is a tonal structure the same are the sound progressions are the notes truck of progressions the same for how many bars.

309
00:59:24,000 --> 00:59:39,000
And you have music colleges will go through an entire piece just to find enough overlap enough overfit to blame whoever made the new song either through AI or on their own to claim copyright violation.

310
00:59:39,000 --> 00:59:49,000
So it varies on content on the on the on the type of media we're talking about like what is derivative or versus transformative.

311
00:59:49,000 --> 01:00:06,000
But in the case of data when content becomes a data form, it is transformed. The courts did not extrapolate to other media forums like film or music, but it is a logical extension of the reasoning that you could indeed do that.

312
01:00:06,000 --> 01:00:24,000
And that really puts a brakes on copyright owners arguments against, you know, against anyone using AI, and makes the admin you insist this is a lot more palatable. Right. Otherwise, they'll they'll just sort of this kind of

313
01:00:24,000 --> 01:00:42,000
they'll never get anywhere. It will be an argument that goes and doesn't go anywhere. But to answer the question about moral, moral rights, I'm assuming your reference in Kant, that's the last time I heard it in the legal philosophy and it was the moral rights and those are continental ideas, at least in

314
01:00:42,000 --> 01:00:53,000
the US and the UK. That's a different story right and that's it's applicability, applicability to an extension of the self. Right so in the United States, the self ends with a self ends.

315
01:00:53,000 --> 01:01:09,000
Right and privacy laws may extend that the health like hip or whatever. But so that the moral rights argument in the United States and might be a hard sell, I think you're right to much easier sell in the UK in the content.

316
01:01:09,000 --> 01:01:19,000
The European copyright law has a has a concept from France of moral right, which is a right that cannot be sold or taken away.

317
01:01:19,000 --> 01:01:33,000
Correct and it's an extent and it goes beyond it goes into personhood that anything that a person like your visage, the things that you make it's like you put your soul into it I mean they took that metaphor, literally, right so it's, it's extension of the person.

318
01:01:33,000 --> 01:01:50,000
I think if you're going to think about it internationally we'll run into the same things kinds of conundrums that we get into in privacy right the GDPR provides the kinds of protections for European citizenship data that we don't afford here for American citizens so

319
01:01:50,000 --> 01:02:08,000
and this weird space like well, are we going to become divergent in our international treaty obligations to observe copyright, right, if we can agree on whether the AI, even by using an original work to learn to make its own original

320
01:02:08,000 --> 01:02:26,000
as in fact violated the moral rights of an existing author or person or photographer. So that's a that's a more, but a legal person is a different definition than a moral person, and we're talking about two different things it seems like if we're going to start

321
01:02:26,000 --> 01:02:39,000
talking about AI as a moral person we have to do that first in an argument that we in a way that we can all get on board, and then try to sell that to the policymakers who are just thinking of legal persons.

322
01:02:39,000 --> 01:02:48,000
Otherwise, they'll be like well that's a nice argument congratulations but you know it has it's not practical, and so they'll build a mirror.

323
01:02:48,000 --> 01:03:02,000
I really want to leave leave to the policymakers to decide. No, but we need to get on it because we need to get on it right because people are doing it highly paid attorneys for the copyright or industry and media industries are on it.

324
01:03:02,000 --> 01:03:13,000
Yes, I know. You know, so I hope you enjoy that one I think your point is quite correct that this is the vectorization changes what that thing is. Yeah.

325
01:03:13,000 --> 01:03:22,000
I mean the transformational transformational change is one of the the arguments for allowing sure use.

326
01:03:22,000 --> 01:03:35,000
And it's not been it's not my it's still case law has been not been migrated into the actual actual copyright law itself I don't believe right yeah so transformative.

327
01:03:35,000 --> 01:03:52,000
I just want to be trans transformative any use. Therefore, the use of the original content you make copies you perform it on. Doesn't matter it was fair, because at the, at the other end, you produce something unique, but also want to point out if the courts that found for the rationale behind

328
01:03:52,000 --> 01:04:08,000
the creation of content into data, also forgot to cycle back to the market so in other words, what if I take a corpus of music, and I design, and I, you know, I transfer and something and thing makes music, right and then I take that music and sell it back in the same market,

329
01:04:08,000 --> 01:04:18,000
in which I drew the music from that was never addressed in in the findings of the court. That's a, that's the kind of words waiting to be open and it will.

330
01:04:19,000 --> 01:04:23,000
That will be open to have your hand up go for it.

331
01:04:23,000 --> 01:04:26,000
I think was first so I can go.

332
01:04:26,000 --> 01:04:29,000
Oh, he's over there okay.

333
01:04:29,000 --> 01:04:32,000
I'm able to speak.

334
01:04:32,000 --> 01:04:46,000
So the, so to the first point, I'm looking forward to reading that that article, as soon as I'm in front of machine. To the second point there's another analogy with Ram. You remember the late 1990s, nearly 2000s, there was a copy made in Ram, but it was a

335
01:04:46,000 --> 01:05:02,000
transitory copy. It was there and then it's gone similar with vectorization right you've vectorized the music and then you jettison the expression right all that's left is residual ideas. So anyway, that's all I wanted to say that that's a second analogy of why this is

336
01:05:02,000 --> 01:05:13,000
not a copy of the original. And to the third point about essentially a snake eating its own tail where the machine is going to eat more of the machine's output, which is going to eat more of the machine's output.

337
01:05:13,000 --> 01:05:27,000
That is something that yeah I, I worry about millions and trillions of monkeys typing Shakespeare, right and then we just the outputs just merely mush, but yeah that's, that's another reason why the output should not be copyrightable.

338
01:05:27,000 --> 01:05:29,000
Okay.

339
01:05:30,000 --> 01:05:34,000
That's an interesting thought. Okay, next I guess.

340
01:05:34,000 --> 01:05:52,000
Yeah, so I had an idea during the first talk, and he was mentioning this also a question of authorship and how do we manage this and gratis so I was thinking maybe about

341
01:05:52,000 --> 01:06:09,000
actually, or pointing out very kind of in a clear manner that artificial intelligence technology is present. And I think it's also easier in terms of legal reinforcement.

342
01:06:09,000 --> 01:06:20,000
In this sense, we may not okay deal on who is the author, whether AI is the author, but we can make it clear that it has participated.

343
01:06:20,000 --> 01:06:37,000
Another further step could be we could mention what the percentage that artificial intelligence contribute. It may also not be as like accurate like 67.5 or something but it could be like 60 to 70 30 to 40 something like that.

344
01:06:37,000 --> 01:06:56,000
So this idea I had that we should not hide the fact that technology as artificial intelligence participate, but show it. And I think, again, it's maybe easier to legally reinforce since it doesn't require us to deal.

345
01:06:56,000 --> 01:07:09,000
So what is AI, and should we give it authorship. Well, we can consider it from a more technical point of view, and say, Yes, it is just a technology, maybe at present.

346
01:07:09,000 --> 01:07:18,000
We just need to show it has taken part because it also influence our judgment of the work. So how do we perceive the work.

347
01:07:18,000 --> 01:07:38,000
Especially why percentage is important. If artificial intelligence create 90% and human input is 10. We may question like what is the input. Of course, it may be significant because guidance management is also a work and sometimes very, very significant which creates actually the flow.

348
01:07:38,000 --> 01:07:53,000
So, yes, this is the idea I got during the talk. And yes, I think I had another point also mentioned about the circularity that AI keeps feeding on machine.

349
01:07:53,000 --> 01:08:02,000
Indeed, I think this is where the significant human element comes into play that we need actually create ideas.

350
01:08:02,000 --> 01:08:17,000
More like human ideas, because of course, big part of our history and knowledge is combining knowledge previous knowledge into new one, and then into new one so this kind of mixing and matching but there's also something

351
01:08:17,000 --> 01:08:28,000
that we can do with the innovation of new which machine may not able to do. Of course, it takes time to explore what it can with it cannot, what we can what we cannot.

352
01:08:28,000 --> 01:08:41,000
So, also, it may not should be seen as competition with machine, but we should maybe work together toward a common goal, whether human or machine achieves it first.

353
01:08:42,000 --> 01:09:02,000
So, this is one of the things that we have in the western culture, the narrative of competition of technology on human, which also can be seen in the times like, like Kantian philosophy, and also transcendence which also goes back to Plato.

354
01:09:02,000 --> 01:09:14,000
It's also going beyond human self but it's a little bit different but still interconnected that yes this kind of difference. Again, what makes us human, but back to the topic.

355
01:09:14,000 --> 01:09:26,000
More concrete and present because it's all about human nature as well, but yeah so awareness pointing it out percentage at best.

356
01:09:26,000 --> 01:09:41,000
And that's just saying it has taken place and we should show it. And yes, of course, it may all seem very confusing and difficult as far as implementing ethics. It's very important, but we should not give up.

357
01:09:41,000 --> 01:09:51,000
This is why we're here. This is why we're working on this and thinking so we should not give up when it seems challenging, because through this challenge we will achieve something great.

358
01:09:51,000 --> 01:10:02,000
So I think I think we have an opportunity to, to make a very large difference in how this shift of technology is going to impact everything else.

359
01:10:02,000 --> 01:10:25,000
And my concern is that right now, the drive is to bigger and greater profits for larger organizations, and increasing the cost of being of existence for people who are in the middle and lower range range of things.

360
01:10:25,000 --> 01:10:30,000
And maybe that's not the ideal thing to do.

361
01:10:30,000 --> 01:10:39,000
And so, I think we need to to examine what is possible, because we have this.

362
01:10:39,000 --> 01:10:48,000
Well, I think I think the, the GPG chat is really, it's magical.

363
01:10:48,000 --> 01:10:51,000
It's also wrong sometimes.

364
01:10:51,000 --> 01:11:02,000
I mean, because it says it works only the semi addicts of the, of the internal data that's been stored, and not upon any understanding of what's really happening.

365
01:11:02,000 --> 01:11:10,000
And that may be the real difference between AI is and humans for quite a while.

366
01:11:11,000 --> 01:11:18,000
If you can't tell the difference between an AI and a human by asking questions.

367
01:11:18,000 --> 01:11:22,000
It's sort of hard to say that they're very different.

368
01:11:22,000 --> 01:11:27,000
You know, we're experimentalists and the way we deal with the universe.

369
01:11:27,000 --> 01:11:29,000
And so we need to work at it.

370
01:11:29,000 --> 01:11:31,000
Go ahead.

371
01:11:31,000 --> 01:11:34,000
I think that during test is still valid.

372
01:11:34,000 --> 01:11:52,000
So it can be seen, as you mentioned that we can distinguish, not as test for existing that it is real, but as a evaluative test, that it is good technology if it can replicate it so well, it means it's very good.

373
01:11:52,000 --> 01:12:09,000
It can be more on an assessment evaluative side, rather than saying that it's actually has something, of course, it may have. But as for example, John Seattle pointed out, creating consciousness takes something more than just syntax, which you mentioned,

374
01:12:09,000 --> 01:12:16,000
shuffling also this ideas that it doesn't have understanding, which is semantics, attaching multiple content.

375
01:12:16,000 --> 01:12:25,000
So, yes, it can be very powerful, as I mentioned before, and it's more can be to the side of assessment, again.

376
01:12:25,000 --> 01:12:30,000
So, yes, I think this is pretty much it.

377
01:12:30,000 --> 01:12:32,000
Okay.

378
01:12:33,000 --> 01:12:43,000
I'm sending a link for so I mentioned that Paul, my buddy Paul is working for Getty images and he's in Europe trying to get some sort of regulation and I'm going to send this link up.

379
01:12:43,000 --> 01:12:54,000
So, a lot of the Getty images are not the Getty folks are now having models sign consent forms that they're biometrics their images may be used for biometric or AI training.

380
01:12:54,000 --> 01:13:09,000
Right, so this is like, but that's an extension of the moral person, right, because well wait a minute right so it's very clear that agencies advocating for this sort of control they are going to leverage that argument you might want to, you might want to

381
01:13:09,000 --> 01:13:21,000
review some of their position papers because it might give you some some ammunition for your argument right to create a much more.

382
01:13:22,000 --> 01:13:30,000
I guess not to argue for artificial intelligence personhood but rather that.

383
01:13:30,000 --> 01:13:44,000
Well, I guess that people that there is some form of extension of the moral rights and that is enough to give artificial intelligence for to put some sort of regulatory fence around it in the way copyright may not be the best regulatory

384
01:13:44,000 --> 01:13:48,000
it's it's it has showing effects and.

385
01:13:48,000 --> 01:13:58,000
Well, there are people who've been arguing that we should have a different category of intellectual property, which is that created by eyes.

386
01:13:58,000 --> 01:14:07,000
Or or make the artificial intelligence of public utility, kind of like telephone lines and electricity.

387
01:14:07,000 --> 01:14:13,000
Yeah, our experience with telephone companies and power companies is not great.

388
01:14:13,000 --> 01:14:16,000
It took. Yeah, it took a few decades.

389
01:14:16,000 --> 01:14:29,000
I wonder though I mean that we're talking kind of quasi personhood for machines, but at this point they're all tools, right, this is a tool that I, and when I created my 417 billion melodies I hit a button and then it output right so I.

390
01:14:30,000 --> 01:14:40,000
It is not an agent of me it is merely a tool much like a word processors a tool so I think I think we're getting ahead of ourselves to say that it's it's fully autonomous because it's not so I think that's that's thing number one.

391
01:14:40,000 --> 01:14:48,000
Thing number two is that we have kind of quasi autonomous bots already. If this happens then that I do this right.

392
01:14:48,000 --> 01:14:56,000
So that is, you know, if the stock price dips below this then sell my thing right is there autonomy there. Well, no, I mean it's still a tool, right.

393
01:14:56,000 --> 01:15:07,000
It seems autonomous because it's doing it by itself. So anyway, so I mostly I'm thinking this, this idea of providing personhood for the machine I think that's putting our, you know, going over our skis a bit and I don't think we're quite there yet.

394
01:15:07,000 --> 01:15:15,000
The second thing is talking, I made for somebody else was talking about, to what extent is there a human additions to the machine created works.

395
01:15:15,000 --> 01:15:32,000
And so I would say that that that's really tricky because I, you know, you can go to boomi.com and say I want an electronic dance music that's 120 beats per minute, and it outputs a fully realized song that under my proposition is is a fully machine created

396
01:15:32,000 --> 01:15:36,000
therefore uncopyrightable. If I change one quarter note.

397
01:15:36,000 --> 01:15:48,000
Is that does that make it copyrightable. Same thing with chat GBT right if I change one letter, or if I change a punctuation mark right is that now copyrightable and putting a threshold on human contribution to machine created work.

398
01:15:48,000 --> 01:15:51,000
I think it's that's that's folly.

399
01:15:51,000 --> 01:15:55,000
I think it's worse than that I think it's criminal.

400
01:15:56,000 --> 01:16:02,000
I mean, our feelings on it are not withstanding our, I mean, I hear you.

401
01:16:02,000 --> 01:16:17,000
And the quarter, the way the things are going, those are irrelevant on how we feel about it is relevant. The copy owners are going to want humans to have a lot of input before they can, they can have the copyright but people using AI to be creative, or to have

402
01:16:17,000 --> 01:16:47,000
the software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software

403
01:16:47,000 --> 01:17:01,480
software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software software knowing

404
01:17:01,480 --> 01:17:06,760
paper or even put a dot in anything that's subsequent is someone helping you but you're

405
01:17:06,760 --> 01:17:12,200
the original, right? So I think the analog in real life between humans exists and it's just

406
01:17:12,200 --> 01:17:17,240
an extension of that. That's right. And if Tom Wolf didn't disclose that editor,

407
01:17:17,240 --> 01:17:21,240
the Copyright Office would never know that that was and that's the other questions.

408
01:17:21,240 --> 01:17:25,240
Right. And so I asked my attorney friends, I said, so we're going to get subpoenas to look into

409
01:17:25,240 --> 01:17:32,360
people's hard drives to see if their training corpora had copyrighted works. They're going to hit

410
01:17:32,360 --> 01:17:38,440
delete, right? Or they're going to fry, it's going to vanish. Right. The thing is that the

411
01:17:38,440 --> 01:17:45,320
copyrighted works that are used in some sort of information knowledge base that's used to drive

412
01:17:46,520 --> 01:17:54,920
things like chat GPT is a reduction. It's been decomposed into pieces that are very small

413
01:17:55,400 --> 01:18:02,200
and mixed with other pieces and structure discovered amongst that. And it's not,

414
01:18:02,200 --> 01:18:08,360
it all clear that there's much of the actual original copyrighted material there.

415
01:18:09,640 --> 01:18:15,160
I 100% agree. And I would also say that if I went to booby.com, exported a thing and then

416
01:18:15,160 --> 01:18:18,760
filed it with the Copyright Office, they would not know that it was machine created, right?

417
01:18:18,760 --> 01:18:22,520
The reason that Thaler in the Thaler lawsuit got dinged is because Thaler said, yeah,

418
01:18:22,520 --> 01:18:26,760
the machine created it. If I don't disclose that, they're not going to know. So number one,

419
01:18:26,760 --> 01:18:30,920
no legal obligations, right? There are no legal obligations disclose.

420
01:18:30,920 --> 01:18:35,880
That's right. So number one, is the Copyright Office going to ask, hey, is there any amount of

421
01:18:35,880 --> 01:18:41,160
machine-created portion of this? That's maybe one, one way out of this. The other thing too,

422
01:18:41,160 --> 01:18:46,120
is that if I filed with the Copyright Office, they don't ask, I get a presumption of copyright

423
01:18:46,120 --> 01:18:49,400
on the thing that I've just created. If I sue somebody over that thing,

424
01:18:50,360 --> 01:18:56,920
then they don't know that that was machine-created, right? And so am I going to be required to

425
01:18:56,920 --> 01:19:01,560
disclose, maybe in a deposition, that what percentage of this was machine-created,

426
01:19:01,560 --> 01:19:03,480
therefore uncopyrightable? Anyway, that's it.

427
01:19:03,480 --> 01:19:05,320
You may not be able to tell that.

428
01:19:06,440 --> 01:19:08,040
I mean, I could lie, right?

429
01:19:08,040 --> 01:19:09,640
No, no, no, you may not know.

430
01:19:10,680 --> 01:19:12,200
Oh, right, right. Yes, sir.

431
01:19:12,200 --> 01:19:15,320
What percentage is that? Go ahead.

432
01:19:15,320 --> 01:19:22,040
Yeah, I might try maybe to address it from the last. So the question also of editors,

433
01:19:22,040 --> 01:19:31,080
how much actually one person may put into work their knowledge and their skills,

434
01:19:31,080 --> 01:19:35,320
while the other one is praised. So this is common even among humans.

435
01:19:35,320 --> 01:19:41,640
And it's part of the research integrity or just general publishing integrity that you should

436
01:19:41,640 --> 01:19:47,720
also make authors in right order, if it's scientific paper, and like that you should

437
01:19:47,720 --> 01:19:53,960
actually assign. Otherwise, it is a fraud or misrepresentation, which is also not good.

438
01:19:54,840 --> 01:20:01,160
And yeah, another question that was before is that we already kind of currently agreed,

439
01:20:01,160 --> 01:20:06,360
I think it is also more widely agreed that it is the technology, it is technology,

440
01:20:06,440 --> 01:20:10,360
it is not a person, artificial intelligence, so as pointed out.

441
01:20:11,000 --> 01:20:19,160
And it is not fully autonomous indeed. Yet the consequences that artificial intelligence already

442
01:20:19,160 --> 01:20:26,360
do has ethical implications on humans, on us, for example, self-driving cars.

443
01:20:26,920 --> 01:20:31,960
So of course, here is a topic more of the copyrights, but it's also important on this

444
01:20:31,960 --> 01:20:39,400
more simple example, how ethical ideas actually can be significant also in copyrights,

445
01:20:39,400 --> 01:20:48,520
because it may be more intricate, but ethical ideas are very important in artificial intelligence,

446
01:20:48,520 --> 01:20:55,000
how it's built, and how it operates. Because as I mentioned, it collects data and uses this data.

447
01:20:55,640 --> 01:21:02,120
So how it will be used, because also it's important to think of artificial intelligence,

448
01:21:02,120 --> 01:21:08,520
not only as author, it also present in governmental systems, for example, compass,

449
01:21:08,520 --> 01:21:15,560
artificial intelligence algorithm that helps in courts to convict or either make certain

450
01:21:15,560 --> 01:21:23,240
decision for the court. So it is also not only about authorship, it's also about the court system

451
01:21:23,240 --> 01:21:27,560
and how it is embedded in the government, which also I think is important to think.

452
01:21:27,560 --> 01:21:35,000
So yes, another thing was mentioned about limiting AI data, how it feeds on it.

453
01:21:35,000 --> 01:21:43,080
So of course, model release forms is very popular thing, which means that model may not give consent

454
01:21:43,080 --> 01:21:49,160
and their photos were used. This is where popular or so not before artificial intelligence

455
01:21:49,960 --> 01:21:57,880
and still is reinforced by artificial intelligence. So one idea that I also had is that maybe we could

456
01:21:57,880 --> 01:22:06,280
put certain limits how AI feeds on the data, because in art, it's very big issue in terms of

457
01:22:06,280 --> 01:22:13,560
copyrights and ownership when AI copies styles of artists. And these artists lose their income,

458
01:22:14,040 --> 01:22:20,200
because people, they can just order from artificial intelligence for much lower price

459
01:22:20,200 --> 01:22:26,200
in any way they want, and then they have to pay artists while machine feed on artists style.

460
01:22:26,200 --> 01:22:34,120
So I think it's a fraud, but I don't know how to solve it yet. But yes, so maybe there could be limits

461
01:22:34,120 --> 01:22:41,400
how it feeds on data. So either say that collaboration with artists, so we use your style,

462
01:22:41,400 --> 01:22:50,200
we give you some a fee for this. So you have this system of payment and the contract, which is I

463
01:22:50,200 --> 01:22:55,800
find very favorable, but it's also important to understand when AI feeds on someone's style and

464
01:22:55,800 --> 01:23:09,080
when not. So hard to find styles. Yes. For example, there's a provision in the copyright law that says

465
01:23:09,080 --> 01:23:16,200
you cannot copyright a font. The reason you can't copyright a font is that it's not possible

466
01:23:17,560 --> 01:23:22,040
in any reasonable technology to compare one font to another.

467
01:23:23,560 --> 01:23:30,680
It is so, but certain also artistic styles, they're so recognizable, like Picasso, for example.

468
01:23:31,240 --> 01:23:38,280
Of course, like it may be a little bit more free in terms of Picasso, but there are modern artists

469
01:23:38,280 --> 01:23:46,200
who actually experience this because their style is so distinct. Like there was a Brazilian Spanish

470
01:23:46,200 --> 01:23:54,040
artist who has such also abstract type of style and artificial intelligence. It became really

471
01:23:54,040 --> 01:24:00,280
popular. Many people tried to recreate it. So this is more modern context. So how would copies the

472
01:24:00,280 --> 01:24:08,200
styles? Yeah. But I wondered though, the style, if I as a human sound like Bob Dylan. So I

473
01:24:08,200 --> 01:24:13,080
sing in the style of Bob Dylan, Bob Dylan can't sue me for copyright infringement because that's

474
01:24:13,640 --> 01:24:20,040
how many singers sound like Bob Dylan, right? How many people look like painted like Matisse,

475
01:24:20,040 --> 01:24:25,720
right? So the style of somebody is not copyrightable. So similarly, if a machine copies the style of

476
01:24:25,720 --> 01:24:31,400
something, is that copyrightable? And I'd argue no, right? Because it is the idea of Matisse,

477
01:24:31,400 --> 01:24:36,280
it is the idea of Picasso, it is the idea of Bob Dylan. And again, ideas are not copyrightable,

478
01:24:36,280 --> 01:24:41,240
only the expressions of those ideas. So as long as I'm not copying the expression of Bob Dylan,

479
01:24:41,240 --> 01:24:45,880
as long as I'm not copying the expression of Matisse, the expression of Picasso,

480
01:24:45,880 --> 01:24:48,840
there's no copyright infringement. So can you really copy the idea?

481
01:24:49,480 --> 01:24:54,360
You think that Bob Dylan's singing style is not copyrightable?

482
01:24:54,360 --> 01:25:00,040
I think it's not. Well, but how many singers sound like Bob Dylan? Lots of them, right?

483
01:25:00,040 --> 01:25:04,120
Billy Joel, I mean, if you're a fan of Billy Joel and you're a fan of Bob Dylan and you know,

484
01:25:04,120 --> 01:25:09,000
piano man, singing as a song, you're a piano man, and then, hey, Mr. Tambourine, I mean, seriously.

485
01:25:09,000 --> 01:25:13,880
And then I've been to a Billy Joel event where you sit and ask questions with the guy and I ask

486
01:25:13,880 --> 01:25:19,160
him, so what's the deal with piano man? He's like, I love Bob Dylan, right? So, I mean,

487
01:25:20,200 --> 01:25:25,800
but we don't hold artists accountable for these sorts of, what otherwise would be, right? But

488
01:25:25,800 --> 01:25:29,800
we're trying to hold AI accountable for these sorts of transgressions. They're not really,

489
01:25:29,800 --> 01:25:35,080
they're just the way we do things. I think what happens is human people see that our machine

490
01:25:35,720 --> 01:25:40,680
is doing exactly what we did, but in a computational way. And then we feel a lot less

491
01:25:40,680 --> 01:25:45,560
special about ourselves. And so our knee-jerk response is to sort of go after, you know, find some

492
01:25:46,760 --> 01:25:52,680
element of our uniqueness. But the fact is, it's just not, it's a variance.

493
01:25:52,680 --> 01:25:57,560
And I would also say that there's a trademark law, right? So if I were to pass something off as

494
01:25:57,560 --> 01:26:02,280
Bob Dylan or pass something off as Billy Joel, that would be trademarks. So there's a bunch of

495
01:26:02,280 --> 01:26:07,640
cases where there's, Vanna White said that you have a robot that looks like me, there's Tom

496
01:26:07,640 --> 01:26:12,440
Waits said you sound like me. So there's the trademark aspect of it, but the machine is not

497
01:26:12,440 --> 01:26:18,760
doing that. If I use chat GPT, say right in the style of Tom Wolf, and then I put it out as something

498
01:26:18,760 --> 01:26:22,680
that is Tom Wolf-like, that might be a trademark infringement, but that would not be a copyright

499
01:26:22,680 --> 01:26:31,080
infringement. Okay. Well, I think that I think that that's that's interesting because I think

500
01:26:31,080 --> 01:26:40,120
there is case law. I can't put my finger on it immediately where the the expression, the style

501
01:26:40,760 --> 01:26:46,440
of writing is in fact, what got copyrighted in the story content was nothing.

502
01:26:46,680 --> 01:26:58,920
The problem is, at least in my opinion, the copyright law does not really differentiate

503
01:26:58,920 --> 01:27:06,200
things properly in a way that you can actually apply it. The same thing is true of patent law

504
01:27:06,200 --> 01:27:16,040
in some ways as well. It's very, very difficult to write a patent that is bulletproof and doesn't

505
01:27:16,520 --> 01:27:26,440
somehow have prior out out there that will kill it. It's, it's, it's hard. And, you know, we, we

506
01:27:27,240 --> 01:27:41,400
chose to maintain patterns of protection, which go back 100 years, 200 years and more. And it's

507
01:27:41,400 --> 01:27:50,600
very difficult to have anticipated 200 years ago the conflicts that we have trying to figure out

508
01:27:50,600 --> 01:27:57,960
whether chat GPT is, is going to be able to be make output, which is copyright or not.

509
01:27:59,000 --> 01:28:04,920
And in terms of what what we're doing today, I don't remember the exact number, but I think

510
01:28:04,920 --> 01:28:14,040
about half of Forbes magazine is generated by a computer from from financial data without the

511
01:28:14,040 --> 01:28:24,120
interference of any human being. There is, there's a guy that built a system that looked a lot like

512
01:28:24,120 --> 01:28:34,040
GPT some years ago, who's a professor at Northwestern and started a little company and

513
01:28:34,120 --> 01:28:40,920
immediately got all of the major financial and sports magazines on his, his customer list. And

514
01:28:40,920 --> 01:28:44,520
you haven't heard of your doom at all, but he puts out lots of magazines.

515
01:28:47,480 --> 01:28:54,200
That goes to you cannot copyright facts as well. So if a machine is merely taking financial data

516
01:28:54,200 --> 01:28:59,640
facts, and then just expressing those facts, that is not copyrightable. There's nothing creative

517
01:28:59,640 --> 01:29:05,240
or original about expression of facts. But then it had it had a knob in the in the UI

518
01:29:05,240 --> 01:29:10,680
that allowed you to choose the financial comment or style was you you wanted to use

519
01:29:10,680 --> 01:29:17,000
for each particular article. And so it's, it's, it's kind of, it's going to have some

520
01:29:17,800 --> 01:29:23,400
knowledge of what that expression is in some sense, because it makes it something that's

521
01:29:23,480 --> 01:29:30,920
recognizable by humans. And I suppose that also recognizable by machine as a result.

522
01:29:33,640 --> 01:29:40,680
We're coming up to 530 and I gotta say, I think I really like this. Could you say the last thing

523
01:29:40,680 --> 01:29:46,760
here? And then if everybody, if everybody who talked would send me their email address, I'd

524
01:29:46,760 --> 01:29:53,000
really appreciate that. Okay, thank you. So yeah, so because it's maybe hard to

525
01:29:54,360 --> 01:29:59,240
understand maybe the copyright and ownership concept, this is why I thought the awareness

526
01:29:59,880 --> 01:30:06,520
is much easier. And at the same time, it has similar impact to the ownership and the copyright

527
01:30:08,280 --> 01:30:15,960
notions, so that we kind of show that in this article, AI participate, because of course,

528
01:30:15,960 --> 01:30:21,240
data, why artificial intelligence is so powerful and good, because it can process much more data

529
01:30:21,240 --> 01:30:28,040
than a human can. So it can feed on so many different types of information. And we make sense

530
01:30:28,040 --> 01:30:35,320
of it, or the AI may pre make sense of it. And then we kind of, at best, it would be very favorable

531
01:30:35,320 --> 01:30:42,520
if we control this process, and say, yes, this is correct conclusion, this is maybe not. So this

532
01:30:42,520 --> 01:30:50,120
is why the awareness of, for example, in the articles, we can point maybe not even percentage

533
01:30:50,120 --> 01:30:57,960
that would be maybe too good, though can also raise questions that, yeah, you did 30% as a human, but

534
01:30:57,960 --> 01:31:06,360
this 30% can have a big impact. So yes, back to the awareness. And it may be a good solution,

535
01:31:06,360 --> 01:31:14,200
as I see it also, because we don't have to really go deeper into what AI actually

536
01:31:14,840 --> 01:31:22,760
is. But at the same time, it has similar impact as the ownership dispute.

537
01:31:26,600 --> 01:31:29,320
Okay, does anybody want to say the very, very last word?

538
01:31:30,120 --> 01:31:37,720
Anyhow, thank you very much. It was really, I think this is a successful experiment. I was

539
01:31:39,000 --> 01:31:45,480
really pleased that we ended up having a nice, nice collection of comments. And I think we

540
01:31:45,480 --> 01:31:51,400
actually move the ball forwards. And thank you very much. And for your participation and

541
01:31:53,000 --> 01:31:56,600
call it good evening. Thank you. See you next week, maybe.

