start	end	text
0	15360	So Chris Potts is a professor and actually also the chair of the Department of Linguistics
15360	20400	and by courtesy also at the Department of Computer Science and he's a great expert in
20400	24400	the area of natural language understanding so he's you know there would not be a better
24400	29160	person to hear about a topic than him and we are so grateful that he could make the
29160	34760	time and he's actually also teaching the graduate course CS22 for you natural language
34760	39880	understanding that we actually transform into a professional course that is starting next week
39880	44920	on the same topic so you know if you're interested in learning more we have some links included
45560	50760	you know down below on your platform you can check it out and you know there's so many other
50760	55320	things that can be said about Chris like he has a super interesting podcast he's running like so
55320	61160	many interesting research papers like projects he worked on so you know go ahead and learn more
61160	67240	about him like you should also have a little link I think without further ado I think we can kick it
67240	73800	off Chris thank you so much once again oh thank you so much Petra for the kind words and welcome
73800	80200	to everyone it's wonderful to be here with you all I do think that we live in a golden age for
80280	86360	natural language understanding maybe also a disconcerting age a weird age but certainly
86360	91480	a time of a lot of innovation and a lot of change it's sort of an interesting moment for
91480	99640	reflection for me because I started teaching my NLU course at Stanford in 2012 about a decade ago
100280	106920	that feels very recent in my lived experience but it feels like a completely different age
106920	113320	when it comes to NLU and indeed all of artificial intelligence I I never would have guessed in 2012
113320	119720	that we would have such an amazing array of technologies and scientific innovations and
119720	126840	that we would have these models that were just so performant and also so widely deployed in the
126840	134360	world this is also a story of again for better or worse increasing societal impact and so that
134360	139160	does come together for me into a golden age and just to reflect on this a little bit it's really
139160	145160	just amazing to think about how many of these models you can get hands on with if you want to
145160	151800	right away right you can download or use via apis models like dolly 2 that do incredible text to
151800	157720	image generation stable diffusion mid-journey they're all in that class we also have github
157720	163640	co-pilot based in the codex model for doing code generation tons of people derive a lot of value
163640	170520	from that system u.com is at the leading edge I would say of search technologies that are changing
170520	175000	the search experience and also leading us to new and better results when we search on the web
176040	183000	whisper ai is an incredible model from open ai this does speech to text and this model is a
183000	190280	generic model that is better than the best user customized models that we had 10 years ago just
190280	194840	astounding not something I would have predicted I think and then of course the star of our show
194840	202200	for today is going to be these big language models gpt 3 is the famous one you can use it via an api
202200	208840	we have all these open source ones as well that have come out opt bloom gpt neo x these are models
208840	213800	that you can download and work with to your heart's content provided that you have all the computing
213800	219560	resources necessary so just incredible and I'm sure you're familiar with this but let's just you
219560	224600	know get this into our common ground here it's incredible what these models can do here's a quick
224600	233960	demo of gpt 3 I asked the da Vinci 2 engine in which year was stanford university founded
233960	239000	when did it enroll its first students who is its current president and what is its mascot
239000	246200	and da Vinci 2 gave a fluent and complete answer that is correct on all counts just incredible
246920	252680	that was with da Vinci 2 we got a big update to that model in late 2022 that's da Vinci 3
252680	258360	and here I'm showing you that it reproduces that results exactly and I do think that da Vinci 3 is
258360	264360	a big step forward over the previous engine here's actually an example of that you know I have like
264360	270120	to play adversarial games with this model and so I asked da Vinci 2 would it be possible to hire a
270120	275320	team of tamarins to help me paint my house assuming I'm willing to pay them in sufficient quantities
275320	280440	of fruit to meet minimum wage requirements in california this is adversarial because I know
280440	285960	that these models don't have a really rich understanding of the world we live in they're
285960	291480	often distracted by details like this and sure enough da Vinci 2 got confused yes it would be
291480	295320	possible to hire a team of tamarins to paint your house you would need to make sure that you're
295320	301560	providing them with enough fruit to meet minimum wage requirements and so forth so easily distracted
301560	307480	but I tried this again with da Vinci 3 and with the same question it gave a very sensible answer no
307480	312280	it would not be possible to hire a team of tamarins to help you paint your house da Vinci 2 was not
312280	318280	distracted by my adversarial game this is not to say that you can't trick da Vinci 2 just go on to
318280	324120	twitter and you'll find examples of that but again I do think we're seeing a pretty remarkable rate
324120	331480	of progress toward these models being robust and relatively trustworthy this is also a story
331560	336760	of scientific innovation that was a brief anecdote but we're seeing this same level of progress
336760	341640	in the tools that we use to measure system performance in the field I've put this under
341640	347000	the heading of benchmark saturate faster than ever this is from a paper from 2021 that I was
347000	352680	involved with Kila et al here's the framework along the x-axis I have time going back to the
352680	359480	1990s and along the y-axis I have a normalized measure of our estimate of human performance
359480	366520	that's the red line set at zero so MNIST digit recognition a grand old data set in the field
366520	371720	that was launched in the 1990s and it took about 20 years for us to surpass this estimate of human
371720	377640	performance switchboard is a similar story launched in the 90s this is the speech to text problem it
377640	384200	took about 20 years for us to get up past this red line here image net is newer this was launched
384200	390680	in 2009 it took about 10 years for us to reach this saturation point and from here the pace is
390680	396040	really going to pick up so squad 1.1 is question answering that was solved in about three years
396840	403240	the response was squad 2.0 that was solved in less than two years and then the glue benchmark
403240	407720	if you were in the field you might recall back the glue benchmark is this big set of tasks that
407720	413800	was meant to stress test our best models when it was announced a lot of us worried that it was just
413800	419480	too hard for present day models but glue was saturated in less than a year the response was
419480	425560	super glue meant to be much harder it was also saturated in less than a year a remarkable
425560	430440	story of progress undoubtedly even if you're cynical about this measure of human performance
430440	437640	we are still seeing a rapid increase in the rate of change here and you know 2021 was ages ago in
437640	443640	the story of AI now I think this same thing carries over into the current era with our largest
443640	449480	language models this is from a really nice post from Jason Wei he is assessing emergent abilities
449480	455160	in large language models you see eight of them given here along the x-axis for these plots you
455160	461640	have model size and on the y-axis you have accuracy and what Jason is showing is that at a certain
461640	467160	point these really big models just attain these abilities to do these really hard tasks
467960	474520	Jason estimates that for 137 tasks models are showing this kind of emergent ability and that
474520	480760	includes tasks that were explicitly set up to help us stress test our largest language model
480760	488520	they're just falling away one by one really incredible now we're going to talk a little
488520	493640	bit later about the factors that are driving this enormous progress for large language models but I
493640	498920	want to be upfront that one of the major factors here is just the raw size of these models you
498920	503960	can see that in Jason's plots that's where the emergent ability kicks in and let me put that
503960	509080	in context for you so this is from a famous plot from a paper that's actually about making models
509080	515560	smaller and what they did is track the rise of you know increases in model size along the x-axis
515560	522040	we have time depth it only goes back to 2018 it's not very long ago and in 2018 the largest of our
522040	530920	models had around 100 million parameters seems small by current comparisons in late 2019 early 2020
530920	536440	we start to see a rapid increase in the size of these models so that by the end of 2020 we have
536440	543800	this megatron model at 8.3 billion parameters I remember when that came out it seemed like it
543800	549640	must be some kind of typo I could not fathom that we had a model that was that large but now of
549640	554760	course this is kind of on the small side soon after that we got an 11 billion parameter variant of
554760	562840	that model and then gpd3 came out that says 175 billion parameters and that one too now looks
562840	568440	small in comparison to these truly gargantuan megatron models and the palm model from google
568440	576040	which surpassed 500 billion parameters I want to emphasize that this has made a complete mockery
576040	582600	of the y-axis of this plot to capture the scale correctly we would need 5 000 of these slides
582600	588040	stacked on top of each other again it still feels weird to say that but that is the truth
588040	594440	the scale of this is absolutely enormous and not something I think that I would have anticipated
594440	599960	way back when we were dealing with those 100 million parameter babies by comparison they seem
599960	607560	large to me at that point so this brings us to our central question it's a golden age this is all
607560	612760	undoubtedly exciting and the things that I've just described to you are going to have an impact on
612760	619320	your lives positive and negative but certainly an impact but I take it that we are here today
619320	625000	because we are researchers and we would like to participate in this research and that could leave
625000	631720	you with a kind of worried feeling how can you contribute to nlu in this era of these gargantuan
631720	638280	models I've set this up as a kind of flow chart first question do you have 50 million dollars
638280	644760	and a love of deep learning infrastructure if the answer is yes to this question then I would
644760	649240	encourage you to go off and build your own large language model you could change the world in this
649240	654600	way I would also request that you get in touch with me maybe you could join my research group and
654680	660840	maybe fund my research group that would be wonderful but I'm assuming that most of you
660840	666920	cannot truthfully answer yes to this question I'm in the no camp right and on both counts I am both
666920	672760	dramatically short of the funds and I also don't have a love of deep learning infrastructure so for
672760	678520	those of us who have to answer no to this question how can you contribute even if the answer is no
678520	683960	there are tons of things that you can be doing all right so just topics that are front of mind
683960	689160	to me include retrieval augmented in-context learning this could be small models that are
689160	694920	performant you could always contribute to creating better benchmarks this is a perennial challenge
694920	700360	for the field and maybe the most significant thing that you can do is just create devices that allow
700360	705960	us to accurately measure the performance of our systems you could also help us solve what I've
705960	711320	called the last mile problem for productive applications these central developments in AI
711320	718040	take us 95 percent of the way toward utility but that last five percent actually having a
718040	724680	positive impact on people's lives often requires twice as much development twice as much innovation
724680	731080	across domain experts people who are good at human computer interaction and AI experts right and
731080	735800	there's so there's just a huge amount that has to be done to realize the potential of these technologies
736520	742600	and then finally you could think about achieving faithful human interpretable explanations of how
742600	748120	these models behave if we're going to trust them we need to understand how they work at a human level
748120	752600	that is supremely challenging and therefore this is incredibly important work you could be doing
753800	758360	now I would love to talk with you about all four of those things and really elaborate on them but
758360	764680	our time is short and so what I've done is select one topic retrieval augmented in-context learning
764680	770120	to focus on because it's it's intimately connected to this notion of in-context learning
770120	775960	and it's a place where all of us can participate in lots of innovative ways so that's kind of the
775960	782920	central plan for the day before I do that though I just want to help us get more common ground around
782920	788760	what I take to be the really central change that's happening as a result of these large language
788760	795800	models and I've put that under the heading of the rise of in-context learning again this is
795800	801000	something we're all getting used to it really remarks a genuine paradigm shift I would say
802440	808440	in-context learning really traces to the GPT-3 paper there are precedents earlier in the literature
808440	814360	but it was the GPT-3 paper that really gave it a thorough initial investigation and showed that it
814440	820840	had promised with the earliest GPT models here's how this works we have our big language model
820840	827000	and we prompt it with a bunch of text so for example this is from that GPT-3 paper we might
827000	833240	prompt the model with a context passage and a title we might follow that with one or more
833240	838360	demonstrations here the demonstration is a question and an answer and the goal of the
838360	843080	demonstration is to help the model learn in context that is from the prompt we've given it
843080	848200	what behavior we're trying to elicit from it so here you might say we're trying to coax the model
848200	854440	to do extractive question answering to find the answer as a substring of the passage we gave it
854440	859480	you might have a few of those and then finally we have the actual question we want the model to
859480	865240	answer we prompt the model with this prompt here that puts it in some state and then its
865240	870120	generation is taken to be the prediction or response and that's how we assess its success
870920	875080	and the whole idea is that the model can learn in context that is from this prompt
875080	879880	what we want it to do so that gives you a sense for how this works you've probably all prompted
879880	884760	language models like you like this yourself already i want to dwell on this for a second though
884760	890200	this is a really different thing from what we used to do throughout artificial intelligence
890200	895800	let me contrast in context learning with the standard paradigm of standard supervision
896760	903000	back in the old days of 2017 or whatever we would typically set things up like this we would have
903000	907720	say we wanted to solve a problem like classifying texts according to whether they express nervous
907720	912680	anticipation a complex human emotion the first step would be that we would need to create a data
912680	918520	set of positive and negative examples of that phenomenon and then we would train a custom
918520	924760	built model to make the binary distinction reflected in the labels here it can be surprisingly
924840	929720	powerful but you can start to see already how this isn't going to scale to the complexity of
929720	935480	the human experience we're going to need separate data sets and maybe separate models for optimism
935480	941080	and sadness and every other emotion you can think of and that's just a subset of all the
941080	945880	problems we might want our models to solve for each one we're going to need data and maybe a
945880	954200	custom built model the promise of in-context learning is that a single big frozen language model
954200	959080	can serve all those goals and in this mode we do that prompting thing that I just described
959080	964600	we're going to give the model examples just expressed in flat text of positive and negative
964600	969240	instances and hope that that's enough for it to learn in context about the distinction we're
969240	974760	trying to establish this is really really different consider that over here the phrase nervous
974760	980200	anticipation has no special status the model doesn't really process it it's entirely structured to
980200	986600	make a binary distinction and the label nervous anticipation is kind of for us on the right the
986600	992680	model needs to learn essentially the meanings of all of these terms and our intentions and figure
992680	998920	out how to make these distinctions on new examples all from a prompt it's just weird and wild that
998920	1004040	this works at all I think I used to be discouraging about this as an avenue and now we're seeing it
1004040	1012120	bear so much fruit what are the mechanisms behind this I'm going to identify a few of them for you
1012120	1017720	the first one is certainly the transformer architecture this is the basic building block
1017720	1023000	of essentially all the language models that I've mentioned so far we have great coverage of the
1023000	1027240	transformer in our course natural language understanding so I'm going to do this quickly
1027240	1032920	the transformer starts with word embeddings and positional encodings on top of those we have a
1032920	1038600	bunch of attention mechanisms these give the name to the famous paper attention is all you need
1038600	1043880	which announced the transformer evidently attention is not all you need because we have these
1043880	1047880	positional encodings at the bottom and then we have a bunch of feed forward layers and
1047880	1055000	regularization steps at the top but attention really is the beating heart of this model and it
1055000	1061240	really was a dramatic departure from the fancy mechanisms LSTMs and so forth that were characteristic
1061240	1066840	of the pre-transformer era so that's essentially though on the diagram here the full model in the
1066840	1072520	course we have a bunch of materials that help you get hands on with transformer representations
1072520	1078280	and also dive deep into math into the mathematics so I'm just going to skip past this I will say
1078280	1082360	that if you dive deep you're likely to go through the same journey we all go through
1083000	1088440	where your first question is how on earth does this work this diagram looks very complicated
1088440	1094120	but then you come to terms with it and you realize oh this is actually a bunch of very
1094120	1100120	simple mechanisms but then you arrive at a question that is a burning question for all of us why does
1100120	1105720	this work so well this remains an open question a lot of people are working on explaining why this
1105720	1111400	is so effective and that is certainly an area in which all of us could participate analytic work
1111400	1119640	understanding why this is so successful the second big innovation here is a realization
1119640	1124920	that what I've called self supervision is an incredibly powerful mechanism for acquiring
1124920	1131800	rich representations of form and meaning this is also very strange in self supervision the model's
1131800	1137400	only objective is to learn from co-occurrence patterns in the sequences it's trained on this is
1137400	1143400	purely distributional learning another way to put this is the model is just learning to assign
1143400	1150040	high probability to attested sequences that is the fundamental mechanism we think about these
1150040	1155400	models as generators but generation is just sampling from the model that's a kind of secondary
1155400	1161240	or derivative process the main thing is learning from these co-occurrence patterns an enlightening
1161240	1165640	thing about the current era is that it's fruitful for these sequences content to contain lots of
1165640	1171560	symbols not just language but computer code sensor readings even images and so forth those
1171560	1177640	are all just symbol streams and the model learns associations among them the core thing about
1177640	1182360	self supervision though that really contrasts it with the standard supervised paradigm I mentioned
1182360	1188520	before is that the objective doesn't mention any specific specific symbols or relations between
1188520	1195400	them is entirely about learning these co-occurrence patterns and from this simple mechanism we get such
1195480	1202280	rich results and that is incredibly empowering because you need hardly any human effort to train
1202280	1208200	a model with self supervision you just need vast quantities of these symbol streams and so that has
1208200	1215080	facilitated the rise of another important mechanism here large-scale pre-training and there are actually
1215080	1220440	two innovations that are happening here right so we see the rise of large-scale pre-training in the
1220440	1227800	earliest work on static word representations like word to vex and glove and what those teams realize
1227800	1233400	is not only that it's powerful to train on vast quantities of data using just self supervision
1233400	1240040	but also that it's empowering to the community to release those parameters not just data not just
1240040	1245480	code but the actual learned representations for other people to build on that has been incredible
1245480	1251640	in terms of building effective systems after those we get ELMO which was the first model to do this
1251640	1258120	for contextual word representations truly large language models then we get BERT of course and
1258120	1265240	GPT and then finally of course GPT-3 at a scale that was really previously unimagined and maybe
1265240	1273800	kind of unimaginable for me a final piece that we should not overlook is the role of human feedback
1273800	1280360	in all of this and I'm thinking in particular of the open AI models I've given a lot of coverage
1280360	1286120	so far of this mechanism of self supervision but we have to acknowledge that our best models
1286120	1291480	are what open AI calls the instruct models and those are trained with way more than just self
1291480	1298280	supervision this is a diagram from the chat GPT blog post it has a lot of details I'm confident
1298280	1303880	that there are really two pieces that are important first the language model is fine tuned
1304440	1310520	on human level supervision just making binary distinctions about good generations and bad ones
1310520	1316600	that's already beyond self supervision and then in a second phase the model generates outputs and
1316600	1322600	humans rank all of the outputs the model has produced and that feedback goes into a lightweight
1322600	1329000	reinforcement learning mechanism in both of those phases we have important human contributions
1329000	1334600	that take us beyond that self supervision step and kind of reduce the magical feeling of how
1334600	1340680	these models are achieving so much I'm emphasizing this because I think what we're seeing is a return
1340680	1346280	to a familiar and kind of cynical sounding story about AI which is that many of the transformative
1346280	1353080	step forwards are actually on the back of a lot of human effort behind the scenes expressed at the
1353080	1359560	level of training data but on the positive side here it is incredible that this human feedback
1359560	1365240	is having such an important impact instruct models are best in class in the field and we have a lot
1365240	1371240	of evidence that that must be because of these human feedback steps happening at a scale that I
1371320	1376840	assume is astounding they must have at open AI large teams of people providing very fine
1376840	1381800	green feedback across lots of different domains with lots of different tasks in mind
1384280	1390600	final piece by way of background prompting itself this has been a real journey for all of us I've
1390600	1396200	described this as step by step and chain of thought reasoning to give you a feel for how
1396200	1400920	this is happening let's just imagine that we've posed a question like can our models reason about
1401000	1408600	negation that is if we didn't eat any food does the model know that we didn't eat any pizza in the
1408600	1416280	old days of 2021 we were so naive we would prompt models with just that direct question like is it
1416280	1420440	true that if we didn't eat any food then we didn't eat any pizza and we would see what the model
1420440	1429240	said in return now in 2023 we know so much and we have learned that it can really help to design
1429240	1433960	a prompt that helps the model reason in the intended ways this is often called step by step
1433960	1438840	reasoning here's an example of a prompt that was given to me by Omar Khattab you start by telling
1438840	1444040	it it's a logic and common sense reasoning exam for some reason that's helpful then you give it
1444040	1450040	some specific instructions and then you use some special markup to give it an example of the kind
1450040	1456120	of reasoning that you would like it to follow after that example comes the actual prompt and in
1456120	1462040	this context what we essentially ask the model to do is express its own reasoning and then conditional
1462040	1468520	on what it has produced create an answer and the eye-opening thing about the current era is that
1468520	1473000	this can be transformative better I think if you wanted to put this poetically you'd say that these
1473000	1478040	large language models are kind of like alien creatures and it's taking us some time to figure
1478040	1483160	out how to communicate with them and together with all that instruct fine tuning with human
1483160	1488760	supervision we're converging on prompts like this as the powerful device and this is exciting to me
1488760	1495080	because what's really emerging is that this is a kind of very light way of programming an AI system
1495080	1499720	using only prompts as opposed to all the deep learning code that we used to have to write
1499720	1504360	and that's going to be incredibly empowering in terms of system development and experimentation
1506680	1511240	all right so we have our background in place I'd like to move to my main topic here
1511240	1515800	which is retrieval augmented in-context learning what you're going to see here is a
1515800	1521640	combination of language models with retriever models which are themselves under the hood
1521640	1527160	large language models as well but let me start with a bit of the backstory here I think we're
1527160	1533000	all probably vaguely aware at this point that large language models have been revolutionizing
1533000	1539400	search again the star of this is the transformer or maybe more specifically its famous spokesmodel
1539400	1545400	Burt right after Burt was announced around 2018 Google announced that it was incorporating
1545400	1551240	aspects of Burt into its core search technology and Microsoft made a similar announcement at
1551240	1557800	about the same time and I think those are just two public facing stories of you know many instances
1557800	1564120	of large search technologies having Burt elements incorporated into them in that era and then of
1564120	1569800	course in the current era we have startups like you.com which have made large language models
1569800	1575560	pretty central to the entire search experience in the form of you know delivering results but also
1575560	1583000	interactive search with conversational agents so that's all exciting but I am an NLP at heart
1583000	1587720	and so for me in a way the more exciting direction here is the fact that finally
1588360	1595240	search is revolutionizing NLP by helping us bridge the gap into much more relevant
1595240	1600760	knowledge intensive tasks to give you a feel for how that's happening let's just use question
1600760	1608120	answering as an example so prior to this work in NLP we would pose question answering or QA in the
1608120	1615640	following way you saw this already with the GPT-3 example we would have as given at test time a title
1615640	1621880	and a context passage and then a question and the task of the model is to find the answer to that
1621880	1627800	question as a literal substring of the context passage which was guaranteed by the nature of
1627800	1634760	the data set as you can imagine models are really good at this task superhuman certainly at this
1634760	1640440	task but it's also a very rarefied task this is not a natural form of question answering in the
1640440	1646440	world and it's certainly unlike the scenario of for example doing web search so the promise of the
1646440	1651560	open formulations of this task are that we're going to connect more directly with the real world
1651560	1659400	in this formulation at test time we're just given a question and the standard strategy is to rely on
1659400	1665880	some kind of retrieval mechanism to find relevant evidence in a large corpus or maybe even the web
1666440	1671800	and then we proceed as before this is a much harder problem because we're not going to get
1671800	1676280	the substring guarantee anymore because we're dependent on the retriever to find relevant
1676280	1682200	evidence but of course it's a much more important task because this is much more like our experience
1682200	1688600	of searching on the web now I've kind of biased already in describing things this way where I
1688600	1694600	assume we're retrieving a passage but there is another narrative out there let me skip to this
1694600	1698920	then you could call this like the llms for everything approach and this would be where
1698920	1704600	there's no explicit retriever you just have a question come in you have a big opaque model
1704600	1710200	process that question and out comes an answer voila you hope that the user's information
1710200	1716520	need is met directly no separate retrieval mechanism just the language model doing everything I think
1716520	1721800	this is an incredibly inspiring vision but we should be aware that there are lots of kind of
1721800	1728680	danger zones here so the first is just efficiency one of the major factors driving that explosion
1728680	1733960	in model size that I tracked before is that in this llms for everything approach we are asking
1733960	1740200	this model to play the role of both knowledge store and language capability if we could separate
1740200	1747720	those out we might get away with smaller models we have a related problem of update ability suppose
1747720	1753080	a fact in the world changes that document on the web changes for example well you're going to have
1753080	1758600	to update the parameters of this big opaque model somehow to conform to the change in reality
1759400	1763800	there are people hard at work on that problem that's a very exciting problem but I think we're a
1763800	1769480	long way from being able to offer guarantees that a change in the world is reflected in the model
1769480	1775800	behavior and that plays into all sorts of issues of trustworthiness and explainability of behavior
1775800	1783080	and so forth also we have an issue of provenance look at the answer at the bottom there is that the
1783080	1788680	correct answer should you trust this model right in the standard web search experience we typically
1788680	1793880	are given some web pages that we can click on to verify at least at the next level of detail
1793880	1799560	whether the information is correct but here we're just given this response and if the model also
1799560	1803640	generated a provenance string if it told us where it found the information we'd be left with the
1803640	1809320	concern that that provenance string was also untrustworthy right and this is like a really
1809320	1814440	breaking a fundamental contract that users expect to have with search technologies I believe
1815320	1819880	so those are some things to worry about there are positives though of course these models are
1819880	1825960	incredibly effective at meeting your information need directly and they're also outstanding at
1825960	1831080	synthesizing information if your question can only be answered by 10 different web pages
1831080	1835160	it's very likely that the language model will still be able to do it without you having to hunt
1835160	1842360	through all those pages so exciting but lots of concerns here here is the alternative of retrieval
1842360	1849320	augmented approaches right oh I can't resist this actually just to give you an example of how
1849320	1856920	important this trustworthy thing can be so I used to be impressed by DaVinci 3 because it would give
1857000	1862120	a correct answer to the question are professional baseball players allowed to glue small wings
1862120	1866920	onto their caps this is a question that I got from a wonderful article by Hector Levec where he
1866920	1872760	encourages us to stress test our models by asking them questions that would seem to run up against
1872760	1878280	any simple distributional or statistical learning model and really get at whether they have a model
1878280	1883720	of the world and for DaVinci 2 it gave what it looked like a really good Levec style answer
1883720	1891000	there is no rule against it but it is not common that seems true so I was disappointed I guess
1891000	1895160	or I'm actually not sure how to feel about this when I asked DaVinci 3 the same question and it
1895160	1900440	said no professional baseball players are not allowed to glue small wings onto their caps major
1900440	1904440	league baseball has strict rules about the appearance of players uniforms and caps in any
1904440	1911560	modification to the caps are not allowed that also sounds reasonable to me is it true it would help
1911640	1917400	enormously if the model could offer me at least a web page with with evidence that's relevant to
1917400	1923480	these claims otherwise I'm simply left wondering and I think that shows you that we've kind of broken
1923480	1928920	this implicit contract with the user that we expect from search so that'll bring me to my
1928920	1934280	alternative here retrieval based or retrieval augmented NLP to give you a sense for this at
1934280	1938680	the top here I have a standard search box and I've put in a very complicated question indeed
1939400	1944440	the first step in this approach is familiar from the LLMs for everything one we're going to encode
1944440	1949800	that query into a dense numerical representation capturing aspects of its form and meaning we
1949800	1955880	use a language model for that the next step is new though we are also going to use a language model
1955880	1961240	maybe the same one we use for the query to process all of the documents in our document collection
1961880	1968040	so each one has some kind of numerical deep learning representation now on the basis of
1968040	1973080	these represent representations we can now score documents with respect to queries just like we
1973080	1979640	would in the standard good old days of information retrieval so we can reproduce every aspect of
1979640	1985160	that familiar experience if we want to we're just doing it now in this very rich semantic space
1985960	1990200	so we get some results back and we could offer those to the user as ranked results but we can
1990200	1996840	also go further we can have another language model call it a reader or a generator slurp up
1996840	2002680	those retrieved passages and synthesize them into a single answer maybe meeting the user's
2002680	2007960	information need directly right so let's check in on how we're doing with respect to our goals
2007960	2012760	here first efficiency I won't have time to substantiate this today but these systems in
2012760	2018040	terms of parameter counts can be much smaller than the integrated approach I mentioned before
2019240	2025160	we also have an easy path to update ability we have this index here so as pages change in our
2025160	2031160	document store we simply use our frozen language model to reprocess and re-represent them and we
2031160	2036280	can have a pretty good guarantee at this point that information changes will be reflected in
2036280	2041560	the retrieved results down here we're also naturally tracking provenance because we have
2041560	2046120	all these documents and they're used to deliver the results and we can have that carry through
2046120	2052360	into the generation so we've kept that contract with the user these models are incredibly effective
2052360	2058040	across lots of literature we're seeing that retrieval augmented approaches are just superior
2058040	2064200	to the fully integrated llms for everything one and we've retained the benefit of llms for everything
2064200	2069800	because we have this model down here the reader generator that can synthesize information into
2069800	2077880	answers that meet the information need directly so that's my fundamental pitch now again things are
2077880	2084280	changing fast and even the approach to designing these systems is also changing really fast so in
2084280	2091720	the in the previous era of 2020 we would have these pre-trained components like we have our index and
2091720	2097000	our retriever maybe we have a language model like reader generator and you might have other
2097000	2102840	pre-trained components image processing and so forth so you have all these assets and the question is
2102840	2108600	how are you going to bring them together into an integrated solution the standard deep learning
2108600	2114840	answer to that question is to define a bunch of task specific parameters that are meant to tie
2114840	2119560	together all those components and then you learn those parameters with respect to some task
2119560	2125720	and you hope that that has kind of created an effective integrated system that's the modular
2125720	2131960	vision of deep learning the truth in practice is that even for very experienced researchers
2131960	2138680	and system designers this can often go really wrong and debugging these systems and figuring out
2138680	2144440	how to improve them can be very difficult because they are so opaque and the scale is so large
2146520	2152680	but maybe we're moving out of an era in which we have to do this at all so this will bring us back
2152680	2159240	to in-context learning the fundamental insight here is that many of these models can in principle
2159240	2167480	communicate in natural language right so a retriever is abstractly just a device for pulling in text
2167480	2174200	and producing text with scores and a language model is also a device for pulling in text and
2174200	2180600	producing text with scores and we have already seen in my basic picture of retrieval augmented
2180600	2185320	approaches that we could have the retriever communicate with the language model via retrieve
2185320	2191000	results well what if we just allow that to go in both directions now we've got a system
2191000	2196840	that is essentially constructed by prompts that help these models do message passing between them
2196840	2202680	in potentially very complicated ways an entirely new approach to system design that I think is going
2202680	2208200	to have an incredible democratizing effect on who designs these systems and what they're for
2209000	2215160	let me give you a deep sense for just how wide open the design space is here again to give you
2215240	2221800	a sense for how much of this research is still left to be done even in this golden era let's
2221800	2227320	imagine a search context the question is what course to take what we're going to do in this new
2227320	2234520	mode is begin a prompt that contains that question just as before and now what we can do next is
2234520	2239720	retrieve a context passage that'll be like the retrieval augmented approach that I showed you
2239720	2244760	at the start of this section right you could just use our retriever for that but there's more
2244760	2249000	that could be done what about demonstrations let's imagine that we have a little train set
2249000	2254440	of qa pairs that kind of demonstrate for our system what the intended behavior is well we can add
2254440	2259320	those into the prompt and now we're giving the system a lot of few shot guidance about how to
2259320	2266280	learn in context right but that's also just the beginning I might have sampled these training
2266280	2272840	examples randomly for my train set but I have a retriever remember and so what I could do instead
2272840	2278680	is find the demonstrations that are the most similar to the user's question and put those
2278680	2284040	in my prompt with the expectation that that will help it understand kind of topical coherence and
2284040	2290280	lead to better results but I could go further right I could use my retriever again to find
2290280	2295800	relevant context passages for each one of those demonstrations to further help it figure out
2295800	2301720	how to reason in terms of evidence and that also opens up a huge design space we could do what we
2301720	2306600	call hindsight retrieval where for each one of these we're using both the question and the answer
2306600	2313000	to find relevant context passages to really give you integrated informational packets that the model
2313000	2318200	can benefit from and there's lots more that we could do with these demonstrations you're probably
2318200	2324120	starting to see it right we could do some rewriting and so forth really makes sophisticated use of
2324120	2330040	the retriever and the language model interwoven we could also think about how we selected this
2330040	2336440	background passage I was assuming that we would just retrieve the most relevant passage according
2336440	2342680	to our question but we could also think about rewriting the user's query in terms of the
2342680	2347480	demonstrations that we could construct it to get a new query that will help the model that's
2347480	2352680	especially powerful if you have a kind of interactional mode where the demonstrations are actually
2352680	2358520	part of like a dialogue history or something like that and then finally we could turn our
2358520	2363160	attention to how we're actually generating the answer I was assuming we would take the top
2363160	2367960	generation from the language model but we could do much more we could filter its generations
2367960	2373800	to just those that match a substring of the passage reproducing some of the old mode of
2373800	2378920	question answering but now in this completely open formulation that can be incredibly powerful
2378920	2384600	if you know your model can retrieve good background passages here those are two simple steps you could
2384600	2391640	also go all the way to the other extreme and use the full retrieval augmented generation or rag model
2391640	2396840	which is essentially creates a full probability model that allows us to marginalize out the
2396840	2403400	contribution of passages that can be incredibly powerful in terms of making maximal use of the
2403400	2411080	capacity of this model to generate text conditional on all the work that we did up here I hope that's
2411080	2416360	giving you a sense for just how much can happen here what we're starting to see I think is that
2416360	2422040	there is a new programming mode emerging it's a programming mode that involves using these large
2422040	2429720	pre-trained components to design in code prompts that are essentially full AI systems that are
2429720	2435720	entirely about message passing between these frozen components we have a new paper out that's called
2435800	2440840	demonstrate search predictor dsp this is a lightweight programming framework for doing
2440840	2446600	exactly what I was just describing for you and one thing I want to call out is that our results
2446600	2453960	are fantastic now you know we can pat ourselves on the back we have a very talented team and so it's
2453960	2459080	no surprise the results are so good but I actually want to be upfront with you I think the real insight
2459080	2465320	here is that it is such early days in terms of us figuring out how to construct these prompts how to
2465320	2471400	program these systems that we've only just begun to understand what's optimal we have explored only
2471400	2476840	a tiny part of the space and everything we're doing is suboptimal and that's just the kind of conditions
2476840	2482600	where you get these huge leap forwards leaps forward in performance on these tasks so I suspect
2482600	2488280	that the bold row that we have here will not be long-lived given how much innovation is happening
2488280	2493960	in this space and I want to make a pitch for our course here right so we have in this course
2494600	2499560	a bunch of assignment slash bake-offs and the way that works essentially is that you have an
2499560	2505640	assignment that helps you build some baselines and then work toward an original system which you
2505640	2511640	enter into a bake-off which is a kind of informal competition around data and modeling our newest
2511640	2517160	of these is called few shot open qa with cobear retrieval it's a version of the problems that I've
2517160	2522360	just been describing for you this is a problem that could not even have been meaningfully posed
2522440	2529000	five years ago and now we are seeing students doing incredible cutting-edge things in this mode
2529000	2534280	it's exactly what I was just describing for you and we're in the sort of moment where a student
2534280	2539160	project could lead to a paper that you know really leaves leads to state-of-the-art performance in
2539160	2544120	surprising ways again because there is just so much research that has to be done here
2544520	2554440	I'm running out of time what I think I'll do is just briefly call out again those important other
2554440	2559800	areas that I've given short drift to today but I think are just so important starting with data
2559800	2567000	sets I've been talking about system design and task performance but it is now and will always be the
2567000	2573320	case that contributing you new benchmark data sets is basically the most important thing you can do
2573400	2579080	Jacques Cousteau said water and air the two essential fluids on which all life depends I would
2579080	2588280	extend that NLP our data sets are the resource on which all progress depends now Cousteau extended
2588280	2593320	this with have become global garbage cans I am not that cynical about our data sets I think we've
2593320	2598520	learned a lot about how to create effective data sets we're getting better at this but we need to
2598520	2604280	watch out for this metaphorical pollution and we need always to be pushing our systems with
2604280	2610360	harder tasks that come closer to the human capabilities that we're actually actually trying to get them
2610360	2616120	to achieve and without contributions of data sets we could be tricking ourselves when we think we're
2616120	2623320	making a lot of progress the second thing that I wanted to call out relates to model explainability
2623320	2629000	you know we're in an era of incredible impact and that has rightly turned researchers to questions
2629000	2637560	of system reliability safety trust approved use and pernicious social biases we have to get serious
2637560	2643640	about all these issues if we're gonna responsibly have all of the impact that we're achieving at this
2643640	2649720	point all of these things are incredibly difficult because the systems we're talking about are these
2649720	2655400	enormous opaque impossible to understand analytically devices like this that are just
2655400	2661000	clouding our understanding of them and so to me that shines a light on the importance of
2661000	2666920	achieving analytic guarantees about our model behaviors that seems to me to be a prerequisite
2666920	2672520	for getting serious about any one of these topics and the goal there in our terms is to achieve
2673240	2679400	faithful human interpretable explanations of model behavior we have great coverage of these
2679400	2685080	methods in the course hands-on materials screencasts and other things that will help you
2685640	2691240	participate in this research and also as a side effect write absolutely outstanding
2691240	2698360	discussion and analysis sections for your papers and the final thing I wanted to call out is just
2698440	2705800	that last mile problem fundamental advances in AI take us 95 percent of the way there but that last
2705800	2712280	five percent is every bit as difficult as the first 95 in my group we've been looking a lot at
2712280	2719960	image accessibility this is an incredibly important societal problem because images are so central
2719960	2726440	to modern life across being on the web and in social media also in the news and in our scientific
2726440	2732520	discourse and it's a sad fact about the current state of the world that almost none of these images
2732520	2738840	are made non-visually accessible so blind and low vision users are basically unable to understand
2738840	2743640	all this context and receive all of this information something has to change that
2744760	2750920	image-based text generation has become incredibly good over the last 10 years that's another story
2750920	2757480	of astounding progress but it has yet to take us to the point where we can actually write useful
2757480	2763320	descriptions of these images that would help a BLB user and that last bit is going to require
2763320	2771000	HCI research linguistic research and fundamental advances in AI and by the way lots of astounding
2771000	2777880	new data sets and this is just one example of in the innumerable number of applied problems
2777880	2783560	that fall into this mode and that can be very exciting for people who have domain expertise
2783560	2792600	that can help us close that final mile so let me wrap up here I don't want to have a standard
2792600	2798600	conclusion I think it's fun to close with some predictions about the future and I have put this
2798600	2803800	under the heading of predictions for the text next 10 years or so although I'm about to retract
2803800	2810280	that for reasons I will get to but here are the predictions first laggard industries that are rich
2810280	2816040	in text data will be transformed in part by NLP technology and that's likely to happen from
2816040	2822360	some disruptive newcomers coming out of left field second prediction artificial assistants
2822360	2827240	will get dramatically better and become more ubiquitous with the side effect that you'll
2827240	2833640	often be unsure in life whether this customer service representative is a person or an AI
2833640	2841480	or some team combining the two many kinds of writing including student papers at universities
2841480	2846440	will be done with AI writing assistants and this might be transparently true given how
2846440	2852360	sophisticated autocomplete and other tools have gotten at this point and then finally
2852360	2857560	the negative effects of NLP and of AI will be amplified along with the positives I'm thinking
2857560	2864600	of things like disinformation spread market disruption systemic bias it's almost sure to
2864600	2869160	be the case if it hasn't already happened already that there will be some calamitous world event
2869720	2876040	that traces to the intentional or unintentional misuse of some AI technology that's in our future
2876920	2880920	so I think these are reasonable predictions and I'm curious for yours but I have to tell you
2881720	2889720	that I made these predictions in 2020 two years ago with the expectation that they would be good
2889720	2896520	for 10 years but more than half of them probably have already come true two and three are definitely
2896520	2901640	true about the world we live in and on the flip side I just failed to predict so many important
2901640	2906360	things like the most prominent example is that I just failed to predict the progress we would see
2906440	2913400	in text image models like dolly two and and stable diffusion in fact I'll be honest with you I might
2913400	2918360	have bet against them I thought that was an area that was going to languish for a long time and yet
2918360	2923320	nonetheless seemingly out of nowhere we had this incredible set of advances and there are probably
2923320	2930600	lots of other areas where I would make similarly bad predictions so I said 10 years but I think
2930680	2937320	my new rule is going to be that I'm going to predict only through 2024 at the very outside
2937320	2943960	because in 10 years the only thing I can say with confidence is that we will be in a radically
2943960	2949480	different place from where we are now but what that place will be like is anyone's guess I'm
2949480	2954200	interested in your predictions about it but I think I will stop here thank you very much
2954760	2961720	thank you so much Chris for the engaging and extremely interesting topic and presentation
2961720	2967160	you have given I'm always amazed by all the new things you're mentioning every single time we
2967160	2973080	talk I feel it is something new something exciting you know not you not me especially not me like
2973080	2979000	expected if you'll be talking about it so soon many questions came in I must already see people
2979000	2983720	unfortunately not be able to get to all of them because the time is limited and the audience is
2983800	2991080	so active and so many people showed up so let me pick a few um Chris so the cost of the training
2991080	2995960	model so it seems it really scales with the size and we are paying a lot of attention and like
2995960	3001320	putting a lot of effort into the training uh so what does it mean for the energy requirements
3001320	3005320	and I guess we are talking about predictions but like how does it look like now and like
3005320	3012360	what do you recommend people to to pay attention to oh it's a wonderful set of questions to be
3012360	3020280	answering and critically important I mean I ask myself you know you know if you think about
3020280	3025000	industries in the world some of them are improving in terms of their environmental impacts some are
3025000	3031320	getting much worse where is artificial intelligence in that is it getting better or is it getting worse
3031320	3037720	I don't know the answer because on the one hand the expenditure for training and now serving for
3037720	3044040	example GPT-3 to everyone who wants to use it is absolutely enormous and it has real costs
3044840	3051720	like measured in emissions and things like that on the other hand this is a centralization of all
3051720	3057960	of that and that can often bring real benefits and I want to not forget of the previous era
3057960	3065080	where every single person trained every single model from scratch and so now a lot of our research
3065160	3071960	is actually just using these frozen components they were expensive but the expenditure of our lab
3071960	3079240	is probably going way down because we are not training these big models it kind of reminds
3079240	3084040	me of that last mile problem again in the previous era it was like we were all driving to pick up our
3084040	3090040	groceries everywhere huge expenditure with all those individual trips now it's much more like
3090120	3093320	they're all brought to the end of the street and we walk to get them
3094200	3098440	but of course that's done in big trucks and those have real consequences as well
3098440	3104920	I don't know but I hope that a lot of smart people work continue to work on this problem
3104920	3108840	and that'll lead to benefits in terms of us doing all these things more efficiently as well
3110840	3117000	thank you so much the next question and you touched on that a few times but it might be
3117000	3122200	good to summarize that a little bit because we got a lot of the questions about kind of the
3122200	3129080	trustworthiness and if the model actually knows that it's wrong or correct and like how do how
3129080	3133480	do we trust the model or like how do we achieve the trustworthiness of the model because right now
3133480	3139240	it's a lot of the generation happening generative models happening so like how do we pass that
3139800	3149160	it's an incredibly good question and it is the thing I have in mind when we're doing all our work
3149160	3155720	on explaining models because I feel like offering faithful human interpretable explanations is the
3155720	3162200	step we can take toward trustworthiness it's a very difficult problem I just want to add that it
3162200	3167640	might be even harder than we've anticipated because people are also pretty untrustworthy
3168600	3176120	it's just that individual people often don't have like a systemic effect right so if you're
3176120	3181480	really doing a poor job at something you probably impact just a handful of people
3181480	3187640	and other people say at your company do a much better job but these ai's are now it's like they're
3187640	3195000	everyone and so any kind of small problem that they have is amplified across the entire population
3195080	3199960	they interact with and that's going to probably mean that our standards for trustworthiness for
3199960	3205400	them need to be higher than they are for humans and that's another sense in which they're going
3205400	3211480	to have to be superhuman to achieve the jobs we're asking of them and the field cannot offer
3211480	3219960	guarantees right now so come help us fascinating thank you so much and like I saw also some
3219960	3224600	questions or comments about the bias in data and like you mentioned it also right like you
3224600	3232120	like we are improving like there is a big improvement happening um last question for you um like a
3232120	3236680	little bit of a thought experiment but like do you think that the large language models might be
3236680	3242520	able to come up with answers to as yet unanswered important scientific questions like something
3242520	3248920	we are not even sure that it even exists like in our minds right now oh it's a wonderful question
3248920	3253720	yeah and people are asking this across multiple domains like they're producing incredible artwork
3253720	3259320	but are we now trapped inside a feedback loop that's going to lead to less truly innovative art
3259320	3265240	and and if we ask them to generate text are they going to do either weird irrelevant stuff or just
3265240	3272840	more of the boring average case stuff um I don't know the answer I will say though that these models
3272840	3278840	have an incredible capacity to synthesize information across sources and I feel like
3279480	3285880	that is a source of innovation for humans as well simply making those connections and it might be
3285880	3290920	true that there is nothing new under the sun but there are lots of new connections perspectives
3290920	3296520	and so forth to be had and I actually do have faith that models are going to be able to at least
3296520	3304280	simulate some of that and it might look to us like innovation but this is not to say that this
3304280	3309960	is uh not a concern for us it should be something we think about especially because we might be
3309960	3314360	heading into an era when whether we want them to or not mostly these models are trained on their own
3314360	3319720	output which is being put on the web and then consumed when people create train sets and so
3319720	3328840	forth and so on yeah great thank you so much and we are nearing the end so like last point um
3329400	3335160	do you have any like last remarks any anything anything interesting you would suggest others to
3335160	3342680	look at follow read um learn about to kind of get more acquainted with the subject well learn
3342680	3347560	more about the NLU GPT-3 other large language models and their recommendations
3350680	3355720	the thing that comes to mind based on all the interactions I have with the professional
3355720	3361720	development students who have taken our course before is that a lot of you I'm guessing have
3361720	3368760	incredibly valuable valuable domain expertise you work in an industry in a position that has taught
3368760	3375560	you tons of things and given you lots of skills and my last mile problem shows you that that is
3375560	3381320	relevant to AI and therefore you could bring it to bear on AI and we might all benefit where you
3381320	3385800	would be taking all these innovations you can learn about in our course and other courses
3385800	3392600	combining that with your domain expertise and maybe actually making progress in a meaningful way on a
3392600	3399720	problem as opposed to merely having demos and things that our scientific community often produces
3399720	3405160	real impact so often requires real domain expertise of the sort you all have
3407000	3413160	great thank you so much um and yeah at the end thank you so much Chris for taking the time to do
3413160	3419560	this I know beginning of the quarter hectic Stanford live and I appreciate you taking the time to do
3419560	3425320	this to run this webinar thank you also everybody who had a chance to join us live or like who's
3425320	3431240	watching this recording if you could please let us know what kind of other topics you might be
3431240	3438440	interested in in this sort of a free webinar structure we have a little survey down on the console
3439640	3446280	and yeah I hope you all have a great day a wonderful start of the of or like end of the
3446280	3451000	winter start of the spring and yeah thank you everybody for joining us yeah Petra this is
3451000	3455400	wonderful we got an astounding number of really great questions it's too bad we're out of time
3455400	3459480	there's a lot to think about here and so that's just another thank you to the audience for all
3459480	3472680	this food for thought thank you
