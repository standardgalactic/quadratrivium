start	end	text
0	15440	Okay, I've been given a knob, so let's get started and it sounds like I've cut out already
15440	17240	so let's just abandon this.
17240	18920	Can you hear me okay at the back?
18920	19920	Yeah.
19920	20920	Is that okay?
20920	21920	Great.
21920	27160	So, today, hopefully, you're here to learn about D-Player and to give you a little bit
27160	32360	of context, I'm interested in data manipulation in the context of data analysis, so you've
32360	39160	got raw data coming in one side, understanding knowledge and insight coming out the other.
39160	44800	And today we're going to be focusing on data manipulation, but I see this really as being
44800	49880	part of the cycle of other data analysis or data science tools.
49880	54080	So to me, there's really four main tools for data science.
54080	58880	So the first is data tidying, getting your data into a form that's actually suitable
58880	59880	for analysis.
59880	65040	Now, in this diagram, I've drawn this little short arrow, but as many of you have actually
65040	69520	worked with real data, you know, often the arrow is all the way around on the other
69520	70520	side of the room.
70520	75600	So often, one of the most challenging parts of doing a data analysis is just getting the
75600	80720	data in the right form that you can work with it.
80720	85400	Now once you've done that, you'll often do some basic manipulation, data transformation.
85400	88880	You'll create new variables that are functions of existing variables.
88880	92800	You might do a little bit of aggregation and so on, and that's mostly what we're going
92800	94160	to be talking about today.
94160	99920	But it's also important to bear in mind that you're doing this to fit into a cycle.
99920	103400	You want your tools to easily plug into the other.
103400	109000	You want your manipulation tools to easily plug into your data visualization and modeling
109000	110160	tools.
110160	114280	The visualizations are great because they uncover the unexpected.
114280	119040	They help you make precise your questions about the data, but the problem with visualizations
119040	121320	is that they fundamentally don't scale.
121320	126280	On the other hand, the kind of complementary tools, statistical models, machine learning,
126280	130600	data mining, basically whenever you've made a question sufficiently precise that you
130600	135760	can answer it with a handful of summary statistics or an algorithm, you've got a model.
135760	141040	Tools are great because they scale, but they don't fundamentally surprise your linear models
141040	143880	and they're going to tell you your data is nonlinear.
143880	149480	So any real data analysis, you're going to be circling between these tools multiple times.
149480	151840	You might start by looking at a plot.
151840	154040	Based on that plot, you develop a model.
154040	156560	You then take some predictions from that model.
156560	159600	You transform your data to look at the residuals.
159600	162040	You visualize those and so on and so on.
162040	166240	So while today we're going to be focusing on data manipulation, data transformation,
166240	173480	the goal is to have tools that embed seamlessly into your data analysis process.
173480	180560	And so the family of tools that I've been working on and others at RStudio are working
180560	186880	on have recently sort of undergone somewhat of a change and if you're interested in hearing
186880	190800	more about that, I'm going to be talking about that in my talk on Tuesday.
190800	197000	So basically, for data tidying, now the tidier package, which is kind of another update of
197000	203120	reshape and then reshape2 and now tidier, pliers become de-plier and ggplot is in the
203120	206040	process of turning into ggplot2.
206040	212600	And as you'll see today, there are some kind of very important commonalities that underlie
212600	217720	all of these tools that make it easy for you to use them.
217720	219800	So today we're going to talk about data manipulation.
219800	224560	We'll start with a little intro to the data we're going to be using, then talk about single
224560	231520	table verbs, a little bit about data pipelines, some more complicated types of filtering and
231520	239320	grouping, joins, a very general do operator and then I'm just going to talk very briefly
239320	244240	at the end about how all the tools you've learned today working with data frames also
244240	247480	apply to databases as well.
247480	254360	But before we begin, I kind of want to start with the caveat and then the bad news is whenever
254360	258040	you're learning a new tool for a long time, you're going to suck.
258040	264640	It's going to be very frustrating, but the good news is that that is typical, it's something
264640	268200	that happens to everyone and it's only temporary.
268200	274360	Unfortunately, there is no way to going from knowing nothing about a subject to knowing
274360	280000	something about a subject and being an expert in it without going through a period of great
280000	282880	frustration and much suckiness.
282880	286000	But remember, when you're getting frustrated, that's a good thing.
286000	292080	That's typical, it's temporary, keep pushing through and in time will become second nature.
292080	295280	Okay, with that said, let's get started.
295280	300000	We're going to be looking at four interrelated datasets today.
300000	304840	I have given you them in a RStudio project.
304840	311000	So if you have downloaded the code and data, you can double click on this R approach file.
311000	319000	If you're not using RStudio, my apologies, but you can just change your working directory
319000	321680	and I'll assume you'll be okay with that.
321680	327080	So in this directory, we've got the scripts, which mostly correspond to what we're going
327080	331120	to be working through today, and then we have got four datasets.
331120	342640	I wanted to start briefly with a couple of hints about using ... I'm not going to do
342640	343640	that.
343640	344840	Okay, I'm going to tell you about the data.
344840	346680	So we've got these four datasets.
346680	348840	The first one is the main one we're going to be looking at.
348840	354320	This is not a huge dataset, but it's recently sized, about 200,000 observations.
354320	361240	This is every flight that departed from Houston in 2011, and then we have got three datasets
361240	365800	that we can join with this dataset that provide useful additional metadata.
365800	369760	So we have some data about the weather for each hour.
369760	374920	As you can imagine, if we're looking at flight data, you might be interested in what causes
374920	375920	flight delays.
375920	379320	The weather is obviously a cause of that.
379320	383720	You might also be interested in, are there planes that are consistently delayed?
383720	387120	So we have some information about the planes that are flying these routes, when they're
387120	391360	built, what type of plane they are, how many people they see, and so on.
391360	395400	And then we have some information about the airports that the flights are flying to, which
395400	400240	is mainly their location, so you can plot them on a map.
400240	405520	Now to load this data in, I'm not going to talk to you about this code.
405520	411000	It's there in the first file.
411680	415960	To get started, you're going to want to source that file in that it's going to create these
415960	417680	four datasets.
417680	424320	The only thing that you might not have seen before is this tableDF function.
424320	431080	What that is going to do, it's going to turn these data frames into dpliers tableDF objects,
431080	438360	which are almost identical in every single way to data frames, except when you print out
438360	445280	a tableDF, it does not print out 10,000 rows, it will only print out the first 10 rows.
445280	449200	So it gives you some summary information about what's going on in that dataset.
449200	451800	It prints all the variables that fit in one screen.
451800	457960	It might make us a little wider.
457960	462280	And if they don't fit on the screen, it just gives you a little summary, the names of the
462280	465080	variables and what type of variable they have.
466080	475400	It's identical in every way to a data frame, except when you look at the class, it is one,
475400	477120	well, two additional things.
477120	482120	If a package doesn't know about dpliers, it would just treat it exactly like a data frame.
482120	486280	In fact, it is a data frame, it's just a special type of data frame.
486280	493320	So we've got flights data, about 200,000 observations, weather, which is about 8,000.
493320	499080	These planes, about 3,000, and then about 3,000 airports.
499080	505240	Okay, now that you've introduced yourselves and hopefully have some questions to ask about
505240	511200	the data, we're going to dive in and learn the first five important verbs associated
511200	512480	with dpliers.
512480	517360	So my kind of contention is if you know these five verbs and combine them with another tool,
517400	523720	we'll learn about shortly, this will solve 90% say of your data manipulation problems.
523720	528480	And that's really important because now when you have a data manipulation problem, instead
528480	533080	of thinking, well, there's like 1,000 functions and base R, which one of those is the one
533080	534080	I need.
534080	537000	Now you just need to look through these five verbs.
537000	542600	So the first verb is filter, where you're going to select rows based on the values of
542600	544960	their variables.
544960	551360	You might also want to just focus on a certain number of columns or variables that select.
551360	555880	You might want to reorder the rows or arrange the data frame.
555880	560320	You might want to add new variables that are functions of existing variables.
560320	566160	Or finally, you might want to reduce multiple values down to a single value.
566160	569760	So all of these functions work exactly the same way.
569760	572760	The first argument is always a data frame.
572760	578360	The subsequent arguments tell you what to do with that data frame.
578360	581280	And then they always return a data frame.
581280	585600	So none of these functions modify in place, so whenever you use them, if you do want to
585600	590040	modify your data frame, you're going to have to assign the results.
590040	593800	A lot of the times I'm just going to show you, I'm just going to run the code and kind
593800	597200	of show you the results on screen and then throw it away.
597200	600760	That's great for teaching, but obviously when you're doing a real data analysis, you actually
600760	603480	want to save what you've done.
603480	610240	To illustrate these, I'm going to start with a very simple five-row data frame, which I'm
610240	614480	also going to show in slides.
614480	619400	So filter allows you to select rows that match some criteria.
619400	626160	So here we're going to say filterDF, we want all the rows with color equals blue.
626160	628760	So this is the input and this is the output.
628760	636200	So if you've used subset before and baseR, this is very, very similar.
636200	642720	If you're looking to see if a value matches one of multiple values, you can use in.
642720	649080	And then there's a whole set of other operators, the regular logic, the numerical comparison
649080	653040	operator is greater than, greater than, equal to, so on and so on.
653040	657400	Not equal, equal and member of the set.
657400	668040	You might also want to use the Boolean algebra, so or and and not an exclusive or.
668040	672120	So I'm just showing this here as a reference, hopefully if you've used R a little bit, you're
672120	674720	familiar with these already.
674720	677720	There are kind of two main things to be cautious of.
677720	683760	When you're working with vectors, you want to use the single bar and the single ampersand.
683760	687800	If you're working with scalars, if you're working with single numbers, like you're using
687800	692520	an if statement, that's when you use the double bar or the double ampersand.
692520	697880	But here we're going to be working with vectors and values, so we want to always use the single
697880	701000	vertical bar or the single ampersand.
701000	704480	And we'll talk about this in a little, very shortly.
704480	710840	So what I want you guys to do is practice using filter by extracting the flights that
710840	711840	match these criteria.
711840	716880	So first of all, all of the flights that went to San Francisco, all of the flights that were
716880	721840	in January, or all flights that were delayed by more than an hour, or they departed between
721840	728040	midnight and 5 AM, or when the arrival delay was twice as much as the departure delay or
728040	729040	corrective.
729040	730040	So I'll give you a few minutes.
730040	733480	I'll circulate around and help you again, there's only one of me and there's a lot of
733480	734480	you.
734480	740240	So if you get stuck on my behalf, please feel free to ask your neighbor for help.
740240	744280	Okay, so let's have a go at how you might tackle this.
744280	756800	So we wanted to find all the flights that went to SFO Oakland.
756800	759040	So you might start like this.
759040	762360	So there's 2,800 that went to SFO.
762360	765720	Now a common mistake when you're first using R, you would say, I want the destination to
765720	773600	equal San Francisco or Oakland, you do that, that's not going to work.
773600	779240	So you either have to be very explicit and say destination equals SFO, or destination
779240	791000	equals Oakland, or use the in operator.
791000	798520	So that's all of the flights that his destination was San Francisco or Oakland.
798520	805560	In January, that's actually a tricky one.
805560	812360	The easiest way to do that is, in this case I know the first flight was January 1st, so
812360	818520	I can just say give me all the flights before the 1st of February.
818520	827120	That didn't work surprisingly, so we might need to just, oh, 2011, yeah, okay.
827120	833200	So let's just see how that thing went down.
833200	840120	So that gets us 18,000 flights in January.
840120	846320	Again between midnight and 5am, there are two ways you can write this, so probably you
846320	852240	might have written this, all of the flights where hour is greater than or equal to 0,
852240	854720	and hour is less than or equal to 5.
854720	860160	With filter, you can also supply multiple arguments to it, and those arguments are all
860160	863520	ended together.
863520	869480	There's no real benefit to doing it this way, rather than this way, except maybe one day
869480	873680	we might be able to figure out how to do these in parallel, and it might be twice as fast
873680	875920	if you do it this way.
875920	880800	And then finally, all the flights delayed by more than an hour.
880800	885520	There's two delay variables here, the departure delay and the arrival delay.
885520	891080	I should have mentioned if it's a negative delay, that means it arrived early or departed
891080	892080	early.
892080	898600	We can find all the flights that were delayed by more than an hour, right, 10,000 flights,
898920	905680	if any of you have, I assume you've all flown in the US, so you're not surprised by this.
905680	909080	And we can also use more complicated expressions in there.
909080	915480	We can find all of the flights where the arrival delay is twice as much as the departure delay.
915480	921480	So these are cases where we have lost time during the flight.
922480	929480	Well, on these ones we might also want to say, and the departure delay was greater than zero.
932480	938480	Right, so this minute, this flight, wait a little longer, right?
938480	945480	Yeah, this flight was two minutes delayed departing, and it was six minutes late on arrival.
947480	950480	Any questions about Felter?
950480	951480	Yep.
951480	954480	Why would you use Felter instead of Felter?
954480	961480	Because it's faster, because it is better defined, it just does one thing, and it does
961480	966480	it one thing well, or a subset does multiple things, and then finally you can use Felter
966480	971480	on database tables and it will generate SQL for you.
971480	974480	Will it work on regular data frames?
974480	975480	Yes.
976480	981480	Okay, the next verb is select, which allows you to pick variables you're interested in.
981480	986480	So this is most useful if you have a data set that has hundreds of variables, and you
986480	988480	just want to look at a few of them.
988480	995480	The syntax is the name of the data frame, and then the list of the variables you want to keep.
995480	1000480	So select works like the select argument to subset if you've ever used that.
1000480	1004480	But basically you can treat the names of variables like their positions.
1004480	1010480	So you can say use negative to say give me all the variables that are not color.
1012480	1015480	What I want you guys to do now is read the help for select.
1015480	1021480	What are the other ways you can select sets of variables, and then see if you can come
1021480	1027480	up with three ways of selecting out the two delay variables from this data set.
1027480	1038480	So if you look at the help for select, you'll see that all of these main verbs are documented
1038480	1044480	together, and you'll see that I've been courteous to Americans.
1044480	1053480	But if we scroll down, we can see that there are five ways of, well, at least five ways,
1053480	1056480	extra ways of selecting variables.
1056480	1061480	So you can select variables that start with a common prefix, then end with a common suffix
1061480	1067480	that contain some character string or the match a regular expression, or you can do
1067480	1071480	like a numeric range, say all of x1 to x10.
1071480	1077480	So this is my attempt to come up with every way that you might reasonably want to select a variable.
1077480	1082480	So a couple of ways you can select these two.
1082480	1086480	You can select them just as individual variables.
1086480	1092480	You could say pick all of the variables between from a rival delay to departure delay.
1092480	1098480	You could find all of the variables that end with delay or all of the variables that contain delay.
1098480	1100480	There's lots of other ways too.
1100480	1102480	You could also write this.
1102480	1104480	You could say make a vector of columns.
1104480	1106480	We're using C.
1106480	1114480	Basically, inside select variable names, you can treat them like the numeric positions.
1114480	1120480	So anything you can do to a numeric position, you can do with a variable name.
1120480	1125480	So the goal of select is to make it easy to refer to your variables by name.
1125480	1129480	It's always a better idea to refer to your variables by name than by position,
1129480	1136480	because you don't want your data input format changes and you're referring to variables by position.
1136480	1145480	It's very easy to have code that works but gives you meaningless results because it's using the wrong variables.
1145480	1151480	The next verb is a range which just changes the order of the rows.
1151480	1155480	So if you just use a variable and orders it by that,
1155480	1160480	you can order in descending order by using the desk wrapper.
1160480	1168480	And I don't show you here but you can add additional variables to break ties if there are ties in this first variable.
1168480	1173480	So again, order the flights by departure date and time.
1173480	1177480	Figure out using a range which flights were most delayed
1177480	1182480	and then which flights caught up the most time during the flight.
1183480	1186480	So again, a few minutes to work on this and I'll show you the answers.
1186480	1191480	Okay, if we want to order the flights by their departure date,
1191480	1195480	we could say order it by date and then hour and then minute.
1195480	1199480	Just want to see multiple, ordering by multiple variables.
1199480	1206480	So you can see the first flight left on January 1st, one minute after midnight.
1206480	1215480	So I should mention this depth variable is the departure time as like a 24-hour time
1215480	1218480	but all the zeros got dropped off.
1218480	1223480	And then the hour and minute are just that, this time split up into those pieces.
1223480	1230480	So for example in this column, there's not going to be a 661,
1230480	1235480	no flights left, it's 61 minutes past 6am.
1235480	1239480	This is just a weird decimal time.
1239480	1243480	We want to sort, find the most delayed, that's just a matter of sorting
1243480	1246480	so that our delays are descending.
1246480	1251480	We can see the most delayed flight was 981 minutes.
1251480	1256480	So an impressive 16-hour delay.
1256480	1259480	Now normally flights aren't delayed that long,
1259480	1262480	not because flights aren't delayed that long
1262480	1270480	but generally airlines cancel the flights to make their departure delay statistics look better.
1270480	1273480	So similarly we could do the same thing for arrival delay,
1273480	1281480	which is going to give us a pretty similar message.
1281480	1288480	And the other thing I wanted to show here is that you can arrange on kind of compound expressions.
1288480	1293480	I wanted to find the planes in a mode made up the most time
1293480	1297480	and there's the biggest difference between the departure and arrival delay.
1297480	1303480	So there's a flight, so for example this flight left one minute early
1303480	1307480	and it arrived an hour and 10 minutes early.
1307480	1311480	So you can arrange on compound expressions
1311480	1315480	although generally it's going to be easier to add that as a new variable
1315480	1318480	depending on what's going on and then arranged by that.
1318480	1320480	Why are you reporting this descending?
1320480	1326480	Because I wanted to find the one, I wanted to find the biggest difference.
1326480	1329480	I may have...
1329480	1332480	Actually I got the same result.
1332480	1336480	I may have hit this round the wrong way.
1336480	1339480	Oh yeah.
1339480	1343480	So depending on which way round we need to track the arrival from departure
1343480	1346480	to ascending or ascending.
1346480	1349480	Any other questions about arrange?
1349480	1353480	I had a problem with the NAs, the first time I did something
1353480	1355480	I got all the NAs on top.
1355480	1359480	I did it in a different way than you did once I...
1359480	1364480	So NAs should always sort to the end and if they don't that's a bug.
1364480	1369480	They do but what if I want the smallest without the NAs?
1369480	1373480	So you have to use felt as a removal of the NAs currently.
1373480	1378480	Is there an opposite of descending?
1378480	1381480	Yes, just don't do descending.
1381480	1385480	I think also the way that...
1385480	1391480	I believe that if you do descending or descending that is ascending.
1391480	1395480	It's the one still.
1395480	1399480	If you really want an ascending function you can just do that.
1405480	1409480	Okay, the starting to get more complicated.
1409480	1413480	The next verb is mutate which allows you to add new variables
1413480	1416480	that are functions of existing variables.
1416480	1419480	So here we're adding a new variable called double
1419480	1422480	which is two times our existing value variable.
1422480	1425480	So again in all of the dplyr functions
1425480	1430480	you never need to explicitly refer to the data frame that you're working with.
1430480	1432480	That's always implicit.
1432480	1435480	It's going to look for this value inside the data frame
1435480	1439480	rather than in your global environment.
1439480	1444480	Mutate is very similar to transform and base r if you've used that.
1444480	1448480	One big difference with mutate is you can do multiple...
1448480	1453480	In additional mutations or additional transformations
1453480	1456480	you can refer to variables that you just created
1456480	1460480	which you cannot do in transform and is a little bit annoying.
1460480	1464480	So here we first double value and then we make a new column called quadruple
1464480	1468480	which is just two times double a variable we just created.
1468480	1472480	How does it compare to within?
1472480	1477480	Basically I think within is a hideous monstrosity that no one should ever use.
1477480	1481480	And if you want to know more I can tell you.
1481480	1485480	Okay so your turn to create some variables.
1485480	1489480	See if you can figure out the speed and miles per hour
1489480	1492480	which flight flew the fastest.
1492480	1496480	See if you can create a new variable that shows how much time was made up
1496480	1498480	during the course of the flight or lost.
1498480	1502480	And then how did I compute the hour and minute variables
1502480	1506480	from that departure variable?
1506480	1510480	Okay so if I wanted to compute the speed
1510480	1514480	that is just the distance divided by the time divided by 60
1514480	1517480	because time is in minutes.
1517480	1521480	So if we print that out
1521480	1525480	you know unless you make your screen really wide you can't see everything.
1525480	1529480	So one thing you can do is use the view function
1529480	1533480	which works in RStudio and other R ideas
1533480	1537480	which will just show all of your variables
1537480	1540480	on a nice kind of scrollable table
1540480	1545480	or you can always just select the variables you want to see
1545480	1549480	so from like departure to speed.
1549480	1554480	So if you use a very handy way
1554480	1558480	of just viewing a data frame in a nice table.
1558480	1562480	Did you change flights?
1562480	1566480	Yes so in this case I modified flights because I wanted to create
1566480	1570480	a new variable and modify that original data set to add that new variable
1570480	1574480	and then I can sort it to find the fastest ones
1574480	1579480	and see 760 miles an hour.
1579480	1583480	When you mutate does there
1583480	1587480	an easy way to specify a position?
1587480	1591480	No so when you add new variables they always go on to the end of the data frame.
1591480	1595480	If you wanted to reposition them there's currently no particularly easy
1595480	1599480	way to do that. You could create a big select statement but it's
1599480	1603480	kind of a pain.
1603480	1607480	We could create this delta variable
1607480	1611480	which is just the difference between the departure and arrival delay.
1611480	1615480	If you didn't care about the direction
1615480	1619480	you could do whatever you want in this
1619480	1623480	whatever R expression you want.
1623480	1627480	The last thing I wanted to mention
1627480	1631480	is just a useful trick. If I have this departure
1631480	1635480	we have the first two digits of the hour and the second two digits of the minute
1635480	1639480	you can use the integer division operator
1639480	1643480	and the modular operator to extract those pieces out.
1643480	1647480	This is just a useful little trick if you want to pull out certain digits
1647480	1651480	from a long number.
1651480	1655480	Any other questions about
1655480	1659480	mutate?
1659480	1663480	Okay next I want to talk about a new function group phi
1663480	1667480	which is summarized together. You can use summarized and regular data frames
1667480	1671480	but you always get a data frame that is only one row
1671480	1675480	which is typically not very useful.
1675480	1679480	That's exactly what I said. So summarized is going to give you a one row
1679480	1683480	data frame. What you're going to want to do is actually group your data first
1683480	1687480	and then summarized will operate by group.
1687480	1691480	Here we're saying create a new data frame
1691480	1695480	and use this old data frame grouped by color
1695480	1699480	and then we're going to summarize this and for each group
1699480	1703480	compute the total by summing up the value of your vehicle.
1703480	1707480	So I'm going to create four useful ways
1707480	1711480	of grouping the flights data. We might want to group it by date
1711480	1715480	we might want to group it by hour, we might want to group it by plane
1715480	1719480	or we might want to group it by destination.
1719480	1723480	Just to bear in mind when you do create all these groupings
1723480	1727480	dplyr is sort of smart enough that doesn't create a complete copy
1727480	1731480	of your data every single time. It works the same way as the rest
1731480	1735480	of R, it doesn't sort of a lazy way. If you modify one of these data sets
1735480	1739480	you'll have to create a copy but until you do so they all point to the same
1739480	1743480	place. So grouping data doesn't
1743480	1747480	use up, it doesn't create a copy of the data, it does use up a little bit more
1747480	1751480	memory because grouping builds up an index so
1751480	1755480	you know what observations are in each group.
1755480	1759480	Now there are lots of summary functions you can use, most of these
1759480	1763480	are pretty standard, minimum, medium, maximum
1763480	1767480	you can extract contiles, there are two functions
1767480	1771480	that are special in dplyr in which just
1771480	1775480	tells you how many observations are in a group, indistinct
1775480	1779480	and I should have a
1779480	1783480	x there, tells you how many different observations
1783480	1787480	are in a variable, that's the same as doing
1787480	1791480	length unique x but it's a little bit more efficient.
1791480	1795480	You can sum, you can compute means. It's also often
1795480	1799480	useful to do summaries of logical vectors because
1799480	1803480	when you take a logical vector and treat it like it's a numeric
1803480	1807480	all the falses turn into zeros and the trues turn into ones
1807480	1811480	so what that means is when you sum a logical vector it tells
1811480	1815480	you how many trues there were so this would tell you how many values
1815480	1819480	of x are greater than 10. The mean is just the sum
1819480	1823480	divided by the length so the mean of a logical vector is the
1823480	1827480	proportion of values of the true. There's a really useful little
1827480	1831480	trick. And then lots of other ways of measuring
1831480	1835480	the variation, standard deviation, variance, interquadal range,
1835480	1839480	median absolute deviation. So these are all just standard
1839480	1843480	functions.
1849480	1853480	Okay what I want you guys, what I've shown here is the distribution
1853480	1857480	of departure delays. So I've got two views of this
1857480	1861480	one which shows all of the delays and one which just shows the delays less than
1861480	1865480	like two hours. So what I want you to do with your neighbor for two minutes
1865480	1869480	is just quickly brainstorm given this distribution
1869480	1873480	given what you know about flight delays
1873480	1877480	how might you want to summarize this distribution. What function might
1877480	1881480	what you want to use or do you want to use a mean or a median or something else.
1881480	1885480	So take two minutes starting now, talk it over with your neighbor.
1885480	1889480	So we're going to summarize by date
1889480	1893480	what's one way we could use to summarize the distribution of
1893480	1897480	delays. The median? We could use the median
1897480	1901480	I mean probably want to use the departure delay
1901480	1905480	so if we just run that
1909480	1913480	we are going to get a new data frame and it is
1913480	1917480	265 rows which you should have anticipated. You know how many
1917480	1921480	days there are in a year. I've got one little problem here
1921480	1925480	probably want to use Na.Ramq was true
1925480	1929480	let's do that.
1929480	1933480	How else could we summarize it?
1933480	1937480	The mean is another obvious one
1937480	1941480	let's just assume we've got that
1941480	1945480	What else might you want to see? 90% quanta.
1945480	1949480	Okay we've got max
1949480	1953480	and actually typing all of this Na.Ramq.true
1953480	1957480	is going to get tedious real fast so I'm just going to filter
1957480	1961480	it and I say I want all of the ones that are not missing
1961480	1965480	okay so that way I can just drop this off
1965480	1969480	and I'll bother typing it
1969480	1973480	so that's the median, the mean, the maximum and then something
1973480	1977480	in between we could get the 90th
1977480	1981480	quanta. Remember how to use that function
1985480	1989480	Any other ideas?
1989480	1993480	Is there a way to for example
1993480	1997480	compute more than just the 90% quanta?
1997480	2001480	Currently you have to type them in like this
2001480	2005480	but there will be some way in the future that you do that
2009480	2013480	Yeah we could also do some thresholds
2013480	2017480	well first of all we could say
2017480	2021480	what's the proportion that is delayed
2021480	2025480	so that is the average of all of the ones where the delay
2025480	2029480	is greater than zero
2029480	2031480	so that is the
2031480	2033480	presently high
2033480	2037480	but you might say well who really cares if it's only
2037480	2041480	a 5 minute delay or a 10 minute delay
2041480	2045480	I might just say arbitrarily like a 15 minute delay that's not bad
2045480	2049480	Why are we looking at departure not arrival?
2049480	2053480	Yeah so equally you might say well it's
2053480	2057480	the impact on our arrival that's what really matters because that's
2057480	2061480	someone picking us up at the airport and our flight
2061480	2065480	is now delayed by an hour and they're getting angry so we could switch all this to arrival
2065480	2069480	delay too and the results are pretty similar
2069480	2073480	So 15 minutes is kind of arbitrary you know you could look at a few
2073480	2077480	other ones if you wanted to do that
2077480	2081480	Yes? Is there a way to use this summer function?
2081480	2085480	You could but I'm not sure
2085480	2089480	that you would want to
2093480	2097480	So current well so there's two problems
2097480	2101480	so first of all I mean this is a reasonable thing to do
2101480	2105480	currently though summarise
2105480	2109480	when you summarise you have to reduce to a single number not multiple numbers
2109480	2113480	because again a future version of dplyr will let you summarise multiple numbers
2113480	2117480	at some point in the future
2117480	2121480	What did I do? So this is what I did
2121480	2125480	and you have to have urm everywhere
2125480	2129480	or you can filter out all of the flights
2129480	2133480	that are not missing
2133480	2137480	but don't have a missing departure
2137480	2141480	So this kind of
2141480	2145480	brings me to my next point at any like in any real data manipulation
2145480	2149480	task you're probably not just going to use one verb
2149480	2153480	but you're going to string multiple verbs together first of all we group it
2153480	2157480	then we filter it then we summarise it and we want some way
2157480	2161480	to kind of express that more naturally or more simply which is that
2161480	2165480	the idea of having a data pipeline
2165480	2169480	you need to do quickly just take a minute
2169480	2173480	talk this over with your neighbour what does this snippet of code do
2173480	2177480	so you've got one minute starting now
2177480	2181480	okay so this looks pretty complicated
2181480	2185480	but if you kind of really carefully pass it you have to start from the innermost thing
2185480	2189480	we're going to start with the flights data then we're going to filter it
2189480	2193480	to remove any missing delays then we're going to group it by date
2193480	2197480	in an hour then we're going to summarise it to compute the average delay
2197480	2201480	and the number of observations in that hour
2201480	2205480	then we're going to filter it to only look at the hours that have more than 10 flights
2205480	2209480	so it's not too complicated
2209480	2213480	but we have to read it in quite an unnatural way to read insight out
2213480	2217480	and then also like the arguments to filter are quite far away
2217480	2221480	so instead
2221480	2225480	what we're going to talk about after the coffee break is this pipe operator
2225480	2229480	and you'll see that that makes the code quite
2229480	2233480	a lot easier to read so the coffee is outside now
2233480	2237480	so let's have a coffee break and come back at
2237480	2241480	3.40
2241480	2245480	music
2245480	2249480	music
2249480	2253480	about this operator
2253480	2257480	called the pipe operator so what this basically does
2257480	2261480	is take the thing on the left hand side of the pipe
2261480	2265480	and put it as the first argument as a thing on the right hand side
2265480	2269480	and the advantage of this is it allows us to take something like this
2269480	2273480	which is pretty hard to read and transform it into something like this
2273480	2277480	and this is pretty easy to read particularly if you pronounce this operator as then
2277480	2281480	so we can read this take flights then filter it
2281480	2285480	to remove any values with a missing value for depth delay
2285480	2289480	then group it by date and hour then summarise it
2289480	2293480	computing the average delay and the number of observations in the group
2293480	2297480	then filter it to look at all of the
2297480	2301480	observations we're going to have in 10 so
2301480	2305480	this pipe operator allows us to
2305480	2309480	form chains of complicated
2309480	2313480	data transformation operations that are made up of very simple pieces so the goal
2313480	2317480	is you make something complex by joining together many simple
2317480	2321480	things that are easy to understand in isolation
2321480	2325480	so I want to give you some practice using that with
2325480	2329480	three challenges so which destinations have the highest
2329480	2333480	average delays which flights
2333480	2337480	happen every day and where do they fly to and then on average
2337480	2341480	how do delays vary over the course of a day
2341480	2345480	and if you're going to do that probably look at the non cancelled flights
2345480	2349480	so those three challenges are relatively
2349480	2353480	simple but you're going to need to string together multiple of these verbs
2353480	2357480	you've seen before you might have to use a range and group by and summarise
2357480	2361480	and filter in some order so have a go at joining those together
2361480	2365480	and again if you get stuck I'll come around and help you out or better
2365480	2369480	ask your neighbour
2369480	2373480	do well we start with the flights
2373480	2377480	what are we going to do to that filter to remove anase yep we can
2377480	2381480	remove the anase let's do rival delays
2381480	2385480	what next
2385480	2389480	group by so group by is kind of a fundamentally
2389480	2393480	like statistical operator you're saying what is the unit of interest in this analysis
2393480	2397480	and in this case it's the destination of the flight
2397480	2401480	then for each destination what we want to do is summarise it
2401480	2405480	I'm just going to say let's use the mean delay
2405480	2409480	the other thing I think you always want to do whenever you do
2409480	2413480	a group by summary is you always want to recall the number of observations
2413480	2417480	in each group because when you start looking at these averages
2417480	2421480	you know if there's a destination that has the highest
2421480	2425480	average delay but only one flight flew there
2425480	2429480	and that's probably not as interesting and then if we want to focus on the most
2429480	2433480	delayed flights we're going to arrange it in
2433480	2437480	descending mean so let's run this
2437480	2441480	they've worked so you can see this is a good example
2441480	2445480	so there's this airport BBT which
2445480	2449480	see
2449480	2453480	I think I've already looked at this before so that is Jack Brooks
2453480	2457480	Brooks regional airport on the airport
2457480	2461480	of Texas so there are only three flights flew there the entire
2461480	2465480	year you're not going to trust this average that much so
2465480	2469480	what we might want to do is filter out all of the
2469480	2473480	flights where there's less than 10 observations
2473480	2477480	we'll run that pipeline again
2477480	2481480	now again I've constructed this pipeline
2481480	2485480	just by typing every step and it worked
2485480	2489480	which I have to say I'm slightly amazed at but generally when you're creating pipelines
2489480	2493480	you want to do it a step at a time and this is one reason
2493480	2497480	that I think the default printing is really important
2497480	2501480	because you can just print out the result at every stage and you can see does that look right or not
2501480	2505480	if you have a normal data frame it will print all of it right
2505480	2509480	yes so if you have a normal data frame
2509480	2513480	it will print the whole thing and if you want to turn
2513480	2517480	you can always take a normal data frame
2517480	2521480	and the first thing you can do is pipe it into tables here and turn it
2521480	2525480	into a data frame the other thing
2525480	2529480	the other thing that's useful is you might often pipe
2529480	2533480	this into something rather than just printing it you could pipe it into view
2533480	2537480	if you wanted to see more of the data
2537480	2541480	that's kind of interesting
2541480	2545480	if you wanted to just
2545480	2549480	kind of step through it
2549480	2553480	you could do
2553480	2557480	talk about you could do something like
2557480	2561480	this
2561480	2565480	maybe
2565480	2569480	so we're just taking the row number and taking a modulo 5
2569480	2573480	equals zero so that's going to give us every fifth that would be one way to do it
2573480	2577480	so if you
2577480	2581480	shows you everything well it shows you the first so many rows
2581480	2585480	in the future I think we'll make it so it shows you every row
2585480	2589480	in a way that's reasonably efficient
2589480	2593480	the other thing that's useful is to pipe it to str so you can see exactly what variables
2593480	2597480	you've created and if they're the right type and so on
2597480	2601480	or if you're so inclined
2601480	2605480	could you put in two functions like head and tail after each other
2605480	2609480	you can't basically so you want a pipeline that has a split
2609480	2613480	in it right you want to have a pipeline that one pipe goes to head
2613480	2617480	and the other pipe goes to tail
2617480	2621480	at the same time yeah I don't
2621480	2625480	like a data table does that by default on that I think that's a nice idea
2625480	2629480	the reason dply doesn't do it is because you can do that for data
2629480	2633480	frames but you can't in general do that efficiently for database queries
2633480	2637480	you can always use tail off
2637480	2641480	so there's another handy keyboard
2641480	2645480	shortcut in our studio which I
2645480	2649480	suspect no one knows about because the only reason I know about it is the
2649480	2653480	Joe who added it told me about it there's this command called rerun
2653480	2657480	previous has anyone used rerun previous before
2657480	2661480	so what that does is if you have selected a
2661480	2665480	block of code and press command enter
2665480	2669480	now if I modify it it's kind of annoying I have to select that
2669480	2673480	block of code again or you can press command shift P
2673480	2677480	and it just sends those same lines of code into the R console
2677480	2681480	so this is really useful if you want to iterate rapidly on your pipeline
2681480	2685480	you can easily change things and maybe I wanted an ascending order
2685480	2689480	and just command shift P and rerun the whole pipeline
2691480	2695480	okay
2695480	2699480	okay so
2699480	2703480	any questions about that pipeline that we created to solve that problem
2703480	2707480	so the next one is which flights
2707480	2711480	happen every day and where do they fly to
2711480	2715480	no
2715480	2719480	so what are we going to start with that
2719480	2723480	and which flights fly every day of the year what's probably the first
2723480	2727480	thing we want to do we want to group by
2727480	2731480	and we want to do that by carrier and the flight number
2731480	2735480	now we want to find all
2735480	2739480	flights that flew every day of the year
2739480	2743480	any ideas so we're going to summarize what might we summarize
2743480	2747480	we might use the dates
2747480	2751480	what how well we're going to use the date how what are we going to do with that
2751480	2755480	oh so we could do we could do count
2755480	2759480	flights
2759480	2763480	we could do count and then we could filter by
2763480	2767480	let's give us a name
2767480	2771480	365
2771480	2775480	I forgot to put two equals
2775480	2779480	now the problem with this is that it's possible
2779480	2783480	this flight flew
2783480	2787480	twice on one day and didn't fly it all on another day
2787480	2791480	I feel like that's yeah so actually
2791480	2795480	this is my solution too but now I think a better way would be to say
2795480	2799480	count the number of distinct
2799480	2803480	dates so if there's 365 distinct
2803480	2807480	dates then we know it's flown every day
2807480	2811480	I think this would give us a slightly different answer
2811480	2815480	well in this case it gives us the same answer because there aren't flights that fly
2815480	2819480	every day and then
2819480	2823480	fly twice on one day but not on another
2823480	2827480	now what if we wanted to add see what destinations these flights flew to
2827480	2831480	any thoughts on that
2831480	2835480	we could just add to the group by
2835480	2839480	there are other ways we could do this which we'll see later but in this case it's easy enough
2839480	2843480	to just add that into the group by
2843480	2847480	and see Honolulu and a lot of flights to New York
2847480	2851480	and Chicago and Seattle and Miami I think
2855480	2859480	the last one on average
2859480	2863480	the non cancelled flights vary over the course of the day
2863480	2867480	so again so first of all we always want to say
2867480	2871480	they're not cancelled which I think
2871480	2875480	because cancelled equals zero cancelled is
2875480	2879480	a reason code associated with it and then normally
2879480	2883480	once you've kind of filtered out clearly wrong things the first step is going to be
2883480	2887480	grouping it here we want to group by hour say
2887480	2891480	or maybe hour and minute
2891480	2895480	and then summarize again we want to
2895480	2899480	count how many observations on each group so we can disregard the delayed flights
2899480	2903480	and we could do the mean
2907480	2911480	departure delay
2911480	2915480	and
2915480	2919480	summarize not summary
2919480	2923480	so now when you get to this point
2923480	2927480	it starts to get easier to see
2927480	2931480	what's going on with the visualizations so
2931480	2935480	this is basically that pipeline I just showed you
2935480	2939480	I think I've done a slightly differently I created a new variable called time
2939480	2943480	which is just hour plus minute divided by 60 that gives me like a floating point
2943480	2947480	number that smoothly varies over the course of the day
2947480	2951480	group it, summarize it and then I'm going to do a little ggplot to
2955480	2959480	plot it
2959480	2963480	so you can see very early in the day
2963480	2967480	we have this kind of scattered cloud of some plots that are very
2967480	2971480	delayed what might these be
2971480	2975480	the ones from the end of the previous night
2975480	2979480	the ones from the end of the previous night and why are the averages so high
2979480	2983480	so variable
2983480	2987480	these are the ones that have hardly any data
2987480	2991480	there are hardly any flights leave after midnight so these averages
2991480	2995480	are kind of suspicious we're not really seeing much of a pattern we're just seeing
2995480	2999480	individual flights that were delayed a really long time from the previous day
2999480	3003480	so we might want to, so one we could show then the visualization
3003480	3007480	is to make the points proportional to the
3007480	3011480	number of observations or we could filter it and add some other stuff
3011480	3015480	there's no schedule flights
3015480	3019480	exactly there's no schedule flights yeah
3019480	3023480	so there's some kind of interesting pattern going on here
3023480	3027480	I don't really understand if it's possible it's an artifact
3027480	3031480	but it looks like it added these white lines on every hour
3031480	3035480	but it looks like there's some kind of pattern where they start off
3035480	3039480	delays kind of accumulate over the course of the day
3039480	3043480	but there's also some weird pattern within the hour where they accumulate and then they drop
3043480	3047480	back a little which I don't know what's going on
3047480	3051480	but certainly the suggestion is if you want to leave on time fly early in the day
3051480	3055480	or late in the hour
3055480	3059480	or late in the hour
3063480	3067480	any questions about those pipelines in general or how you can combine
3067480	3071480	these pieces with a pipe operator?
3071480	3075480	range is generally what the advantage is to chaining versus having
3075480	3079480	a ton of parentheses inside
3079480	3083480	but the sole example is that it makes it easier for you to read and understand what's going on
3083480	3087480	does any advantage just having it line by line
3087480	3091480	no basically no
3091480	3095480	save a little bit of memory but it's not
3095480	3099480	yep
3099480	3103480	so yeah in all the versions of D player used
3103480	3107480	percent dot percent
3107480	3111480	now I prefer percent greater than percent for two reasons
3111480	3115480	first of all it's easy to type because you can hold your finger on the shift button the whole time
3115480	3119480	and secondly I think it's not a
3119480	3123480	symmetric operation so having an asymmetric operator
3123480	3127480	helps you understand what's going on, the data is flowing from left to right
3127480	3131480	any other questions?
3131480	3135480	is there a particular preferred order?
3135480	3139480	no obviously the less
3139480	3143480	data you have to work with the faster things are going to be so that generally suggests you should
3143480	3147480	filter early on and you know so
3147480	3151480	if you use a database, a database looks at the sequence of all the
3151480	3155480	operations and says oh you did this filter at the end but it would actually
3155480	3159480	be way more efficient to do that at the beginning, D player doesn't do anything like that
3159480	3163480	D player executes it exactly as you give it so if you
3163480	3167480	can think of a faster way to order the operations it might be worthwhile
3167480	3171480	to do so generally and I'm not really going to talk about
3171480	3175480	performance today but generally if you've got million like
3175480	3179480	less than 10 million observations you won't even have to worry
3179480	3183480	about the performance it's going to be a few seconds and it's not
3183480	3187480	like it's a waste of time worrying about it because it's not going to take you that long
3187480	3191480	ok, the next thing I'm going to talk about
3191480	3195480	is a great thing
3195480	3199480	music
3199480	3203480	music
3203480	3205480	music
