I found out like yesterday afternoon that I had to do this talk, so I was preparing so I didn't get a chance to see the keynote
I look forward to watching the video of it. Hi, my name is Richard Campbell. I am an old geek. I've been doing this stuff for a long time
I'm for British Columbia
This is a picture of my house on the left and my neighbor's house on the right. We call this the animal highway
I didn't realize until I put this camera in that we get bears every week
It's this is about six in the morning in the summertime
On a Wednesday because Wednesday in my neighborhood is garbage day
So he's just coming to see if I put out my garbage early or not
And there are consequences if I do so and actually we get fine if we put out the garbage early
It's quite against the rules, but it that's what it's like living British Columbia
It's just forest behind me
It's like a big old buffet for bears and they come through and check on it
He sees actually at the at the top of the driveway right now surveying his domain
Anybody got the garbage out before he moves on I
Make a lot of podcasts any done at rocks listeners
Awesome Carl's not here. I won't be recording it out in a rocks this week
I'm gonna be doing some run as Carl started down at rocks back in 2002 which predates the word podcast by a couple of years
I came on board with show 100 in 2005 where it 18 will do 18 30 this week
It's already in the can and this
And yeah, a lot of the stuff that I do is based on down to rocks this talk definitely is
Coming from all these interviews we get to do we get to talk to really smart people
And so you get to decide to synthesize the sort of vision of what's going on. I do an IT show as well
Call run as radio and I think a episode 863 went up today
And for a brief period between 2011 and 2014 we made a show called the tablet show
Back when we didn't know what to do about tablets and now we know tablet development. It's just development. It's not a big deal
All right, so we're gonna do a little future prediction
So let's refer to Niels Bohr's prediction is very difficult, especially about the future although. I don't know what else you would predict
So let's go through the obvious things that are happening today that are gonna shape the way we build software for the next few years
I wrote the first version is talking 2019 thinking one of the 2020 is gonna be like and now it's 2023
And it's not exactly what I thought but
Did anybody plan up for a pandemic in 2019? I don't think so
But obviously the cloud has come to dominate in the past few years. It was true
It was less true in 2018 2019
But today if you don't have a cloud plan you kind of don't have a plan your your employer is probably gonna ask you
well, how does the cloud fit into this equation and
Same for mobile devices mobile devices are now the most common computing device in the world
They are the majority of compute the reason iPhone and Android dominates just because there's so many of them
We figure this four billion smartphones operating in the world which pretty much is one for every adult human and
We've transformed society for that
Fundamentally we are all cyborgs right we have digital extensions to ourselves now
We tend to because of science fiction think about cyborgs as the digital stuff is inside you, but a yuck
And B impairs upgrades
But if we don't think of our phone as an extension of ourselves try losing it for a day
Like we're pretty agitated when we don't have that device around it's our communication device
We would just take it for granted that we could talk to anybody anywhere if they'll answer which they won't
Or we at least message them and whatever messaging constraint you currently have the Venn diagram of messaging systems is continued to be messy
But that's because it's so all-encompassing and so we can't talk about
Future of compute and and the kind of work we're going to be doing if we don't include these devices and how they're going to evolve as well
We know how to make an awful lot of data
That's just a byproduct of having a lot of devices feeding into common reservoirs, right?
The you know ultimately a lot of what's made the modern machine land
Machine learning models exist is because of this is tremendous feed of data that we're generating on the behalf of others
And all of these are obvious trends more compute more cloud more devices
More data nothing surprising here. It's all expected. What are the unexpected things?
We're we're we're going to hit limits in the next ten years
For me the big one is we are finally going to run Moore's law to the ground
So Gordon Moore is a person. He was one of the founders of Intel
They were one of the first companies to make micro processors
Well, actually they first made Ram that was their original product when when Intel started up
Ram was still largely core Ram little ferrous coils wound with copper to store bits sounds as reliable as you think it would be
And so the idea of building
Silicon substrate Ram was a big deal and that was an Intel's original product and it was while they're making Ram
That Gordon Moore observed that for roughly the same amount of cost
Every 18 to 24 months. We could double the number of circuits on the piece of silicon
Now they only were able to do that by working very hard at it
Later that would be called Moore's law. It's not a law
Right a law is something that happens whether you work hard at it or not
Like gravity you don't have to do much gravity is going to apply
But for Moore's law to be a law companies work extremely diligently to increase the density of electronics and it's worked if you'd
So pull this data from Wikipedia. This is a sort of chart of the processor
The density of transistors in processors from the original
4004 in 1970 up till around now and you see how clean that line is and that's because we have an
Exponential number on the left of the number of transistors if I didn't use an exponent on the left and go up orders of magnitude
We get the hockey stick the dumb graph where nothing is meaningful and then it shoots up at the end
It's a bad way to explain this honestly, I mean and we're technical people
Getting our heads around an exponential function is hard when I'm explaining it simpler. I talk about things like this
What is that warp drive for the enterprise? No, that's this
This is a cray
XMP supercomputer circa 1985
They've only they only made a couple of hundred of these that at in 1985. This was the most powerful computer
You could buy they were millions of dollars
They ran on on 200 kilowatts of power. So you kind of need to bring your own generator
They're cooled with mineral oil because they're running so hot without mineral oil pumping through it all the time that it will melt
You notice it's kind of curved
They're trying their best to keep the wires as short as possible
So the speed of light doesn't impair the performance of the computer
This is leading edge technology in 1985 and it's knocking out about 1.9
Gigaflops
per second so just about two billion floating point operations per second in 1985 they modeled
Nuclear explosions on this the Voyager missions were computed on computers like this doing the orbital calculations
fast forward a few years say
2011 the iPad 2
About 800 bucks
Don't put it in any liquids. That's a mistake
It runs, you know on its built-in battery for about 20 hours and it's got about
1.9 gigaflops of processing power
So 26 years later the most powerful computer in the world is now a device you give to children and
They play candy crush on it
That's the advancement of society and
This face it that's not fast
That's a 20 at 2011 device and a consumer device at that
Today if you're a consumer you want a high-performance compute device you buy a very expensive video card, right?
An RTX 4090 these days if you can find one, they're a couple of grand
You know, they're not cheap
but
16,000 cores in it
currently pulls down about 82 teraflops at full bore so
40,000 times faster than the iPad 2
So 11 years later, you know, and that's this is also
450 watts
So, you know, you can heat the room with it if you like like I hope you bought a big power supply because you're gonna need it
And if you want you can run too. I don't know why you would
Nobody's mining Bitcoin anymore. That's done
And it's still a consumer device today
There's a today the fastest computer in the world the supercomputers of the world
There's a race going on between the Chinese the Americans and the Japanese and the current leader like literally this past fall
Was the frontier supercomputer in Oak Ridge labs? So that's in Tennessee in the US. That's based on the HP architecture
so this is a massive multi-processor machine and
1100 petaflops or 1.1 exa flops
For about six hundred million dollars
Needs about 20 megawatts of power. So bring your own nuclear reactor
and takes up about
700 square meters. So clear out the basement
13,000 times faster than the 4090 or
600 million times faster than the iPad 2 or the cray XMP
Moore's law
That's what we're talking about is our ability to continue to extend compute and I like that comparison where the cray
Compute power became our consumer device like are we going to have an exa flop device in our hands?
It's possible. I don't know what you'd do with it
But then we didn't know we needed to play candy crush in the first place right it just emerged that way
And Moore's law is ending this graph cannot continue. Why why are we running into the limit?
Well, we're getting better and better at packing transistors into smaller and smaller space
And you'll hear these terms like the 10 nanometer process and the seven nanometer process and the five nanometer process
Scientists have built a one nanometer transistor, but only one of them
Those are all rough measurements, they're not realistic in the actual circuits are more complicated that we have good
Sensors now this is an electron tunneling image of the
IBM five nanometer process. So this is doped silicon layered together
It's hard to measure what we talk about nano things all the time is compute people the billionth of something a billionth of meter
Is really really small people can't understand a billion right same problem is that exponential function?
And I always describe this as if I want to wait get you to wait for a million seconds a million seconds about 11 days
But a billion seconds is 33 years
So the idea that a nanometer is to a meter as a second is the 33 years
And we're making stuff at that scale today. That's how dense we're getting this is kind of this is stanling
scanning tunneling microscopy of a
Silicon substrate the yellow dots are
Silicon atoms the blue holes are phosphorus atoms
We talk about doping silicon when we make
Integrated circuits so that they change their voltage behavior so that you can apply voltage and pass it through a semiconductor
This is literally the structure of it. It is a crystal
And when you get down into those
nanometer scales, we're running out of atoms
A silicon atom is 111 picometers across like point one nanometers
so when you start talking about a
Transistor layered together. That's only a couple of dozen nanomies across. It's only hundreds not even hundreds of atoms
Strictly right quantum effects start to apply like we're just getting as dense as we physically
Can get and that's going to be the limit and not only that we can make these things at all that that we can make
Billions of transistors on a given die
for about a thousand dollars
Right keep the prices stayed consistent the manufacturing process has to keep improving
Without really raising the price so that we'll continue to buy them
And again, we get debate like how fast did you need to go and how density need to be?
But we've built our entire industry of on the fact that we're going to have more compute in about two years
for the same amount of money and
That ends in the next decade
Now there's a bunch of things that we're doing or
Haven't been doing because of Moore's law one is we have not really improved
Architectures for the most part especially if you're talking about Intel
They've more or less sold the same core chip design
For 40 years because every time they try to change it we got very angry
Because it wasn't compatible with what we've done before and we like compatibility more and so at this point that perpetually
Evolving x64 and x86 architecture has gotten fairly convoluted the amount of steps involved in a given work cycle
even if it's going at multiple gigahertz is
Complex now we do have simpler architectures the arm architecture came along quite a few years ago and
It was built for more power efficiency more compute efficiency
It just didn't have the legacy that the other systems have but arms pretty mature today
It's one of the reasons you're seeing more and more interest in arm in general for compute because the amount of energy necessary for a given unit of work is
lower in those architectures
You can expect as we lose the ability to get more compute
For free by buying the next generation processor that optimizations in architecture become much more important
Now for us as programmers for the large part. We're insulated from that our modern programming environment
Almost completely abstracts us from the actual underlying hardware if you're living in a dot in dot net land
It's Microsoft's responsibility to make sure that the common language runtime
Compiles and optimizes to the processor you have they do that all of the time. We don't even think that it happens
It's kind of magic. It just works in that brief period where they thought arm was a really good idea now
They're coming back to that idea again. You could compile dot net to arm
It went away, it'll be back because it's nothing that we have to do
It's their responsibility to do implementations against the hardware. That's the power of abstraction for us
I would argue that today the M1 and the M2 made by Apple are the most advanced
processors out there architecturally
They're arm-based, but they've also added they've condensed a lot of things. Most of the memory is here
They have a tensor compute units or basically units optimized to do neural neural net calculations
They have the GPU integrated in putting all those things in a single die
Putting 40 billion transistors together all working and playing happily has some benefits
And so, you know, those are some of the nicest computers we can buy today
And it sort of speaks to what the future looks like and I'm I'm an advocate of William Gibson
The guy who coined the term cyberspace while typing it on a Wedgewood typewriter
But his quote is the future is here. It's just not evenly distributed
So if you want to understand the future one of the easy ways to go is go look at where the concentrations of real rare
Innovation are and what's happening in Cupertino with processors like this is pretty profound
It speaks to what phones should look like in the future and what our other compute devices can be deeply integrated circuits the modern
manufacturing foundry
Allows us to build very customized
Circuits that are as close together as possible to run as fast as possible with the least amount of heat and the least amount of battery waste
All right
Let's stop talking about the underlying hardware the net real constraint these days is the network
5g was wonderful. It was heavily advertised a few years ago. Now it's here and nobody can tell works perfect
I mean the
It's a good question
In theory these standards for wireless are about
increasing
Frequency to intensify more data so more people can communicate simultaneously the downside is as you move up in spectrum
You decrease the penetration
So our old 2g phones which were living down in the 900 megahertz range worked beautifully in basements
When we got up to 3g and 4g phones and we moved up to the 2 gigahertz band range
We had trouble communicating into in closed areas, right? Some buildings work some not so much
It was easy to get into a Faraday cage rear phone wouldn't work
5g bumps this up into the 20 gigahertz range big increase in data density, but the penetration goes down a fair bit
It's blocked by things like
trees
Bodies, you know, I've stood in front of a 5g tower doing a speed test with my phone and going wow
That's smoking fast and then I turned around
And then 20 gigahertz apparently doesn't go through me
So there's challenges for these higher frequencies. There was the 6g specification underway
But there's no simple solutions here network is going to be our constraining resource as
Developers we have to think hard about how we move data between points of compute
That's always going to be a limitation. There are no workarounds largely for
For the laws of physics the speed of light. That's a law
This the modern is a the the the satellite networks that are going up now are very interesting
For certain applications what we've really reached is a point where much of the parts of the globe that don't have good cellular coverage
Can have sufficient satellite coverage?
So more and more we're reinforcing ester Dyson's belief that it was easy
It was easier to put networking everywhere than it was to build a good disconnected client
So if you just keep presuming we're gonna have them with everywhere
I got I got on the early Starlink beta because I have a place sort of up in the wilderness in BC where the bears are even more common and
It's an insuppressive like that's just a pizza box size antenna
You need a clear shot of the sky. That's the hard part
And if you've got a clear shot of the sky
You've got about 400 megabits down and 100 up at 29 at 20 milliseconds you can game from there
It's not as fast as your your your synchronous fiber, but it's faster than you would get in most isolated areas
So that ubiquitous connectivity and huge amounts of compute available in very small devices
You know the other side of Moore's law is the old hardware gets very cheap
And so we're seeing things like automobiles where they won't spend money on compute. They still have it
They're still they're now starting to put 3g
Cell services into all cars so that all cars have telemetry back to the factory whether you want it or not
Because it's more important for the factory to know about what how you're using the car
So this model of the ubiquitous computing is emerging more and more where every device has an IP address and
Can connect to the network and and is communicating perhaps not for your benefit before the vendors benefit
But it's always communicating and we have options there. We're gonna be responsible for a lot of it
I'd be remiss in just setting the stage for all this to not talk a little bit about the pandemic
Well again when I wrote the original version it wasn't the thing, but we've continued to deal with this
That's obviously in the later stages
Our friend Sachin Adele said was famously quoted by May of 2020 saying two years of cloud migration happened in two months as
We've as everyone discovered yes
You can work at home and we tore apart our perimeter networks and shoved and expanded our VPNs and
Quickly shuffled whatever we could into the cloud. We changed the landscape of work. We changed the landscape of compute
I mean for most of us in our industry working from was just not a big deal. We've been doing it anyway
I do hope one day to make either a video series or a talk just on how video
Conferencing evolved over those two years
Remember that period where everybody thought all of those
Inlaid graphics with the hats and in the horns and things was a good idea
It lasted like three months for three months everybody had fun with that
They're like, okay, that's really dumb and they turn that off, but that's the evil evolution of etiquette perception
And today it's really interesting to see how everybody comes on with a face initially says hi
Then when somebody actually starts to talk most cameras go off
To not distract like that. We're developing an etiquette for that model. We were rushed to do it
But we're also seeing the other side of the pandemic
We're starting to see the economic impacts we the side effect of mass layoffs was a loss of expertise that in general all
Workchains are less efficient today as we tried to gear them back up and you have a 20 or 30 or 40 percent
Inexperienced worker role in across those chains of work
You have a lot more mistakes and they cascade on top of each other
We had the supply chain deeply disruptive ports that were had had too many empty containers and not and not enough full ones
Not enough space to move things around and literally going to take years to straighten it out
And then the byproduct of all of that friction and supply was an increase in demand for certain goods
Which then got interpreted as inflation and here we are it's 2023. I hope you're having fun
Now what does this mean for us in our industry specifically because for the most part
We've had 20 years as developers
Just in a growth mindset
2008 2009 not withstanding the sort of great recession because I think for the most part technical industry was insulated from that
We were not as impacted as much as many others
So I've talked to folks that have been working since after the dot-com bus
2002 and it's just been build what you want go faster build more
You know explore great ideas now. I'm older than that
I started writing code in the 80s when economics are a lot tougher and we focused really hard on this contact of return on investment
The problem is that when we're software developers we rarely are directly responsible making money for the company
Typically the things that we make are tools that allow those that make money for the company to work more efficiently
If the things we're making don't do that, they're really not that important
You know this capitalist model has always functioned on the idea of rapid relatively inefficient growth
Followed by a period of sort of cleanup shaking out the weak stuff a bit of a recessionary period for a year or so
We cut the sort of fat off and then we'll grow again
Except that we've gotten good enough with our economic models to avoid that whole cleanup phase for 20 years
and now that we're looking at one in a very serious way and
Folks are seeing that you know what it's like to have a five or six percent interest rate and
They you know new costs of things the pressure on energy and so forth
Companies are being more reflective. They're sort of looking back and going are we doing the right things?
Are we focused on the important stuff?
And it's in our best interests with our skills and the main nose and the companies that we're working in
Make sure you know how your company makes money
Make sure the things you're building
Help that because we are productivity amplifiers
We're incredibly good at building tools that allow the rest to work faster to do more
We can help companies survive in difficult times if we work on the right things
All right, we wanted to talk about technology. We've kind of set the stage. Here is the landscape we live in today
So now that we know we're living in a cloud and living in a cloud world mostly smartphones
We're not going to count on you compute going much faster and in general our employers and our customers are really tighter with their cash
What should we do?
Start with the browser market because the browser market is
Kind of stable now
If you really want to use up a lot of memory in your computer
There's chrome if you want to be frustrated with how well your websites work you've safari if you want to use a browser
Nobody else cares about there's edge and if you want to be an angry anarchist. There's Firefox like you have choices, right?
There's no perfect solution any of these there nobody's utterly dominating the market
I mean chrome is still a big player especially for your typical employer
That's likely the browser using you tend to build to that and we're clearly seeing the rough edges
We're not all the same same things work together, but we have the tooling sets and
You know in on Donna rocks we made fun of the rapid rates like hey
We've got an hour-long show here. There'll be at least two more framers before this is done
That I feel like that pace is eased off a little. I think people want a certain level of stability
you know angular is not the new sexy anymore, but it's
It's utilization level inside of larger companies is massive and those top three across the board seem to be
that you know majority of web development and we're still doing mostly browser development especially for companies because it's also deployment issue and
They're always running latest version and that's things we want from that
Even if we have to constrain the feature set someone and getting and all of these libraries have some degree advantages for
working in the
heterogeneous client world that we have that people are expected to be able to use those pages on a phone and on a tablet not a
PC and have a reasonable experience on all of them. It's still not easy
Development for us has all the easiest time of development was when the device you were writing the code on was the device
It would normally run on that just hasn't been true for 20 years
Whether we acknowledged it or not now we typically are writing on a desktop PC or a robust laptop
But we're running it on smaller form factor devices and that's a way more difficult thing to develop for it
More complicated model. It's a longer cycle, but if you're not respecting that cycle you struggle with what you're making
The progressive web app movement has helped us at the minimum to give us an icon
For regular users to be able to get to that web page because goodness knows they couldn't figure bookmarks out
All right, so now we have an icon. It starts up a frameless browser
We're that's good enough. There's a bunch of other great stuff in PWA and the three guys to use it think it's great
And then there's our friend Steve Sanderson who brought us web assembly in the form of what would eventually be known as blazer
now
He didn't invent it. You know, he wasn't first, but he
Definitely brought it for us in the dot-net community back in 2016 at the NDC conference in Oslo
He showed it off for the first time with a very bizarro version of C sharp
That allowed us to run C sharp on the browser and really what web assembly is evolved into is a kind of container strategy
Where the inside service of the container is this browser environment a sandbox
That's relatively safe to operate within and you can introduce almost any kind of code
Microsoft took their time
Committing to blazer Microsoft doesn't like being first. It seems these days
They kind of sat on that project as an experimental project until go lang for web
W a shipped as soon as that happened well then blazer came out
But it was like when nobody wants to attack Javascript, but we do want to program in the languages
We want to program the devices we want to program in and w a gives us this ability to program in the languages of choice
Down on the client device still in the browser. So I still have my deployment issue solved
I still have continuous update models or every time you click on it
You get the latest version like all of the benefits of working in web development, but now I get the language that I want to use
And if you've listened to the show, you know, we've been talking about other places that this container could run
I mean blazer made it absolutely obvious to us that we can run it on the server
We can run it on the client, but now it's interesting to start thinking about different points of compute. I
Don't want this code to necessarily run on the client device, but I wanted to run close to the client
So could I define a
Set of parameters for where this X block of code could execute that it could run in a CDN an edge point of some kind
No, and this is all
Experimental, but I'm hearing it more and more often that the web assembly is a another kind of container
And what the potential of that offers to us long term
So if you haven't explored this world and sort of poking around what's possible there just understand this is an area of growth
Extremely smart people are looking at where they can take web assembly to
Now if you want dumber areas we could talk about web 3
It's easy to make fun of mostly because it's pretty silly I
See it coming down to three central ideas
Decentralized web is I think the most reasonable aspect of web 3
We
If you think about web 1 late 90s early aughts the whole dot-com boom
Dot-com from Microsoft perspective for the idea of the internet becoming a popular thing
That was very decentralized people ran web servers on machines under their desks
Connected to the internet. It wasn't a good idea, but it's something we did and
It was powerful and flexible except it wasn't reliable right sometimes that machine sometimes you trip over the power cord
Sometimes the cat barfs into the CD drive right like stuff happens and that machine was actually on the internet
Web 2 was far more centralized right we gave up our ownership of those
Devices in on the internet for a service provider. It's just that we chose folks like Facebook
But you can still put geocities in that can as well if you want
But we now we're getting into more interesting compute models with distributed execution
And the problem of course is that those products turned into other kinds of exploitation of us
And
That's not controlling the value we're actually making and now everyone's a little bit sick of it
And so decentralized web is becoming hip again. Just trying to do it in a better way
Me running on the cloud you could still be largely decentralized because it's all about ownership of data
So can you run your own services through a provider?
Who's not really running competing services directly, but rather having other people compete in that space
I look more to stuff like the Shopify model
Where there's no reason for you to employ your own e-commerce engine anymore when you can go to a Shopify and run their engine
For a set fee with many thousands of other people running their the same engine for their products
The one person not running an e-commerce engine is Shopify themselves, right? They're not a competitor in your own space
That's fairly decentralized. I can live with that
This only parts when we get into web 3. I mean blockchain is not inherently stupid. It's just wildly
Misapplied right the idea of a distributed data engine is pretty compelling
It's just that people don't think about it. Well, you know when I have a customer asking me about well
We got to use blockchain. It's like why because he saw it in a magazine
Like what do you want from it?
What what's the difference and often with most companies they still want to be central point of control
It's like so you don't want blockchain the idea that other entities can introduce transactions on into this data
independent of you is
The basic stepping point like if you're not going to do that then what are you talking about?
Why do you need this? But blockchain's got the problem that BitTorrent has
BitTorrent's problem was that it came out of Napster about a stealing music
It was a good protocol used for where its initial use was a nefarious use that was ultimately illegal and
Blockchain has the same problem. It's bound to crypto and as we're seeing pretty clearly these days
Crypto is pretty much a Ponzi scheme and so
Are we gonna get something from it eventually? Maybe our most people just gonna lose their money here seems like it
It's easier to see that now than it then we saw it before but that's the part that's really
contaminating web3 is
These fairly good ideas bound up with an idea that was very easy to exploit to fairly destructive purposes
And so I think most of us these days who are a little more serious about stuff are going
You know, I think I'm just gonna stay back from that
Rodeo and let it wind down and then we'll see what pieces are left in the end
Web2 didn't happen overnight either this exploration of new ways to use the internet. It's is an exploration
It takes time
There's no other way to do it
And so it's a question of are you gonna jump in and be part of that exploration or are you gonna witness it and then make your
move later on?
If you think like an engineer you're pretty conservative and you're not the first you're big on the IT mantra of change is good
You go first
Not a bad way to look at crypto these days
Dotnet's in a good place
It just knows I'm glad about that I make a podcast called dotnet rocks and back in 2011
We thought maybe dotnet doesn't rock and things were pretty hard by 11 years on 12 years on dotnet's rocking pretty hard
They've done a remarkable thing. They've rewritten the entire thing to be a cloud-centric
heterogeneous client platform with some limitations without having to replace all the tooling in the process. I
Mean if you learned how to develop against dotnet in
2010 with studio 2010 I can drop you on to studio
2022 and dotnet core and you won't be confused
You'll more or less get it. There's a bunch of new stuff and there's some edges to things and we focus on some other elements
but
Really we've had a complete
overhaul of this 20 year old stack over the past six seven years and
Yet we don't have to relearn we don't have to start over
We get to move most of our code on on to it and the new things you write we use familiar skills
If anything the biggest problem Microsoft has right now with this is that it's so calm
It's so similar. We still have our old practices. We're not using the new language features
We're not taking advantage of the new stuff that's been brought to it and the only way they're gonna fix that is tooling
Because compatibility is so important
They're not going to take stuff away if you're using C sharp to constructs. They're going to keep working
But you probably want to use a new one
So I think you're gonna start having more clippy events where pops it goes. Wow, you're coding like it's
2007 can I help you?
Because you clean help and
The big new tool in this space is Maui
So this is the culmination of a tremendous effort inside of Microsoft to consolidate a client development solution
That's deals with the heterogeneous client and multiple platforms. It's still pretty raw
Again the conservative engineering type of look at that you go, you know
I'll let you guys iterate on that a couple of times you guys you kind of get it right at the third version
You're kind of like an aversion a half right now
So we'll give you a little more time, but the goal is challenging the idea of this
Magical unified client development model works for all the devices something we want our customers couldn't care less about
The customer only cares that it runs on their device. They don't care if it runs on anybody else's device
We're the ones who want to write one code base that runs on all of those devices because otherwise
We can't keep them in sync or we're leaving somebody out and they're angry with us and that's never fun
So this is Microsoft's client side attempt on this and I mean, I'm I'm excited for them
This said the seven version is substantially better. I think this will be almost sexy by November of this year with dotnet eight
It just takes time for them to get this many features and this many teams
Co-operating across the stacks and if you're sticking with web development
I don't blame you because it does it solves this problem with its own set of limitations
I've yet to see a Maui implementation of a cross prop platform client solution where I said wow you couldn't do that with web
We're not there yet
We might be I don't know the answer to that
We've talked about this a few times on the show and it doesn't seem to be going away the power platform
So here's the other reality is that we kind of know what the client space landscape looks like
We know there's phones and tablets and PCs an
awful lot of our data over forms problem space and in work is all dependent on
The cloud tenant that our employer has anyway
And so the fact that we can essentially run this set of tools that builds a bulk of that for us
It's pretty compelling
But even more importantly
These tools are simple are straightforward enough that a domain expert can take a pretty good shot at an 80% solution
For a workflow for a company and then it needs to be cleaned up by some of the bit more experience
But a lot of you x development can be done by the person who's going to use it
Now this has happened before this is access and visual basic in the middle 90s
Where most people who grab those tools were domain experts not developers
They became developers later, and I think we're seeing another wave of this
But the parts that we find the least pleasant as professional developers that you I multi-platform you I problem
this thing kind of knocks out and
Then it has a set of hooks back to back-end services with some limitations. They're all customizable
We as professional developers can build additional endpoints for the power platform
And if you're good at the UX side you can build custom components on the UX side for these domain experts to use too
But I'm looking at our to-do list, and we're not getting to the bottom of it
So there's a group of people out there that want to move things along by taking on some of that work
Do it
The way Microsoft's licensed the thing it's for internal apps only you pretty much cannot put a power app into public
It has to be authenticated members of the tenant
So it's for internal apps
They weren't fun to build in the first place
So anything we can do to get more of those off the table and modernize them, right?
You're looking at that web forms app that the CIO wants to run on their iPad
And suddenly the fact that power platform could get you a prototype of that in pretty short order. It's pretty compelling
I've mentioned web WA in the context of containerization containerization is an ongoing evolving thing
It's only getting bigger. I got a recent show up where we're talking about Azure application
identities and
That ties into giving a security context to an application
It's going to run in the cloud in a lot of ways containers do that too, right?
We're demanding a manifest saying this is what the app. This is the resources the app needs
This is the operating contents that needs to operate in here
The rights that it needs the access points that it needs and more importantly if it tries to do anything isn't in that kill it
Containers are just the evolution of that
In the next few years, I think we're see containerization of software in general on desktop machines because of the security problems
That when a given piece of software gets exploited and it tries to do anything outside of its normal set of behaviors
The operating system recognizes that it's exceeding its container limits and stops it
Now that was always a good idea and Microsoft's tried to implement this in a few different ways for a long time
But I think the security context is going to win. I
Look at what's happened in cyber insurance in the past couple of years
Today if you want to get cyber insurance not least it more expensive, but even multi they and they require
multi-factor authentication
But more and more I'm seeing things like you're required to do a privileged access audit. I
Wouldn't surprise me at all if the insurers at some point say if the apps if your apps aren't running containers, you're not insured
Because they see them as ways to avoid the exploits that the black hats are using
So that might be what pushes this technology over the top as it becomes a
consistent industry-wide way to resist the ransomware and other security attacks
And if you're feeling a little overwhelmed with all the stuff
I'm rattling through because I get to just tell stories for a living. I don't have to implement any of it
Which is why it's all easy for me
That's okay
There are a bunch of ways to have a great development career
Staying on the leading edge is really fun. If it's fun for you
You know the upside the downside to the leading edge is also the bleeding edge and sometimes you bleed
You can also have a great career and many people do by becoming an expert in a stack that your company values and staying
That expert it may not be the newest technology anymore
but it's the one the company relies on and
They need those experts and they need you to continue to grow and to be good at that technology
And to keep it functional for the organization to keep you into things it needs to don't jump because the thing is new
You jump because it can no longer solve the business problems that it needs to solve
I've talked to folks that started doing web forms develop in 2005 and their company still uses a ton of it there
And it works. It's reliable. It's known set of problem spaces
They have a you know, they're 15 years into this or plus and they do I really need to to jump to a new stack
It's like no those apps aren't going away
And in fact even when they are they're going to technologies that are orthogonal to web forms anyway
That's why blazer got so hip if you're a web forms developer and you look at blazer
You're just not that surprised this looks like something you've done. It's not that hard to jump on to the new stack
So
The question is what did you want to do?
Do you want to be part of the group of folks that are always learning and pushing on a new thing?
Or are you going to be the expert in a given set?
You find a space that you like and you stay in that space and you get really good at space and now you're an expert in a
diminishing pool
Like you're pace still going to be good
But you need to maintain your expertise
You need to keep figuring out where the limits are and what's possible like it doesn't mean you ever stop learning
We don't get to do that in this industry
But it's a question of what you focus on
Do you really want to learn the new bits where we're all just trying to figure it out or you continue to expand on the space that you're
There's not one way to do a great career
Let's talk about artificial intelligence
And I use this image for the simple reason that it's it is the reason that we think about AI the way we think about it
It's terrible term
It was coined in the 1950s by a guy named Marvin Minsky when he's trying to sell stuff to the US military
The first time regular humans heard the phrase artificial intelligence. It was in the movie
2001 a space Odyssey and Hal and then he tried to kill everybody and
Set up our relationship with artificial intelligence going forward
It's an umbrella term the one thing I know for sure about artificial intelligence is as long as somebody's calling something artificial intelligence
It's because it doesn't work as soon as it does work. It gets a new name
right it becomes deep learning a predictive analytics or
You know to speech tech systems as long as it doesn't work. It's AI and
And so when folks talk to me about hey, you know, I'm working on this AI problem
It's like, what are you really working on? Like is it a machine learning model? That's the new thing, right?
Like really what really came out of
Jeff Hinton's papers in 2011 that led to stuff like Siri and all the voice recognition and ultimately these vision
Interpretation models is all deep learning models based on machine learning, right?
Then this particular graphic I like because the short lines are
The oldest technologies that those planning schedule optimization. Those are back in the 50s
experts and robotics from the 1970s original speech recognition systems go back to the 80s and then in the 2010s
We get this current crop of image recognition vision systems language interpretation
And we can incorporate that is our software today. There are good libraries. You don't have to invent stuff
It isn't research anymore. You want an image recognition module? It's a module. You load it into your software
You have an image to be recognized and it can recognize it
This is a real thing the software was doing what you told it to do said, oh, no, no three dogs
And you've run into the chatbots, right? They're out there
You they're first-line tech support for almost everything today. You're gonna get a chat bot for us and sometimes they're speech bots
And they're they are getting better. There's mean. They're good. We all learned to say agent very early on if we want to get out of that loop
These are again tooling sets that we can work with the area that I I'm really fascinated by right now that Microsoft's working on are these form
recognizers
So the idea that I can I can use an image recognition system look at a form and it recognizes
What is form and what is data and then associates the two together into?
Value pairs
That's pretty cool, right that we had a different strategy to digitizing a form rather than building it by hand in
In code that now the tool would actually recognize before you generate for you
I
This was really about using initially paper because they call it a form recognizer
Like can I parse a page and have it pull the data out of it?
But I immediately thought hey aim that in a at a web forms page and re reimparse it for me
And make it into power platform stuff
Like can you could I just have a tool thumb through all of the different views and an application and regenerate it in the new language?
Why not we have machine learning models that are capable of parsing the data
The final area in the machine learning spaces that has gotten powerful actually has been powerful a while and when people are asking about
Hey, my kids getting into technology like where's the big career opportunity? It's analyzing data
We have more data than ever before we're analyzing it
Less and less effectively because we're just outnumbered. There's so much data and only so much time
The good news is the cloud is making things simpler for us in the 90s
We had most of these predictive analytic models
It's just that each one of them represented a huge amount of compute
And so you'd do a bunch of pre-work to figure out what the most likely
Analytic model will be effective on this given data, and then you'd build out a system and run it once and it would take weeks
Today, this is a couple of hours in Azure load the date
You'll spend more time loading the data up then you'll run all of the predicted analytic models
And then you'll run model analysis against the models to figure out the one that fits the data set best
For $20 for the computer
So we have better tools than ever for doing advanced analytics and as we go and when we talk about as advanced analytics, you know the predictive model
Is really what's the next number that's going to come from this?
What's the trend on these is just going up as it's going down, right?
We have plenty of tools and those sorts of forms as we start adding in machine learning we do it in bulk
We're able to do more of them faster and compare them so that we can select models more efficiently
It's less time or your space and more just hammer it with compute, but you can go to a more advanced stage
Given you take a predictive model, and it says this is the most likely outcome
Now you can actually run a scenario beyond that you're getting into prescriptive analytics
So you're cycling the predictive model with actions
You've been experienced. This is where you know it or not. Have you lately?
thrown a bunch of stuff in a shopping cart and abandoned it and then you get an email from someone saying hey
You put this stuff in your cart
Like can I give you a 10% off so you'll go buy it?
You're seeing a prescriptive model saying how often do I tickle this person now that they've shown some interest to increase the
Likelihood of completing a sale. There's no humans involved. It's all software
But they're now running these prescriptive explorers to say how often should I hit them?
But given a thousand people did that and I emailed them this way. What was the response rate?
Whatever you mail in this way. What's the response rate? That's automated now that is prescriptive analytic models
Now obviously in the e-commerce sale is one side, but you're also seeing the same models used for things like when should you?
Evacuate a town for a forest fire
If I wait till it's obvious that the fire is going to hit the town now
I risk people's health in the crisis of trying to get them out
Or is it better at a low stress level to say let's move them early?
It'll cost us less the chance of them being injured killed is lower and
Then if the fire goes the other way, it's not that big of a deal, right?
We're still building prescriptive models to explore the psychological effects of emergencies and
Being able to act more effectively to protect people
We can also make video games
So this is one of the open AI models
In the early days where you would describe a game
This is someone making a bad version of asteroids and it would spit out code for you
This is not that exciting anymore. Most people have played hopefully with co-pilot now a whole other way to pull up code
You don't understand you so have to use stackover flow for this
But now you can do a machine learning model. So there's fewer people saying that's a dumb question
I'm concerned with the training set
We've done a couple of great shows around this with folks like Michelle Manning where we you know
It's maybe generating code that works, but isn't secure or isn't you know reliable
They've trained it against all of the open libraries on GitHub and that doesn't mean that means it's only as good as the code
That we put into GitHub some of the code I put in the GitHub. I'm not proud of
So it is interesting to say how can they improve this to say hey, I only want highly secure code
That's thoughtful of all of those kinds of things. They're now starting to stick language onto this
So now you're gonna talk about what code you want to write and
The VP of the power platform Charles Lamanna announced they've not made a version of co-pilot for power platform
So, oh you had a no-code solution where you're draggy dropping the form too much work. Just say make me a form
All right now use the image recognizer show them a copy of the paper version before and it comes up
So those are machine learning models for programming. There are tools for us to use the whole we will all be replaced by this is
Silly it always was silly. It's only getting sillier the longer we use these things
But if you don't use them in your routine work, you kind of miss it out. It's an accelerant
There's no excuse for not understanding the code. You're putting your system
So the idea that this is an you're already you were using Google sometimes you're using stack overflow
Why wouldn't you use co-pilot to pull up code and then evaluate that code? It's easier than a blank screen
It's at all anything we can do to get ourselves moving on a given problem space, but it's still our discrimination
The tool does not know that this code is right all it knows it is it fit the criteria you described to it at the time
That's as much as know with some percentage of probability
hopefully in the high 90s, but not always and
Chat GPT about the same thing right there. I call it a Dunning Kruger accelerator
If you know nothing about a topic chat GPT is awesome
As soon as you know something about a topic and ask chat GDP it's not that awesome
Not actually concerned with facts
What replaces the smartphone?
I mean the smartphone is dominated. It's not the primary computer device, but it's kind of mature
you know
The phones get bigger they get smaller they have one camera two cameras three cameras way too many cameras
But they're kind of the same. They're a slab of black glass
We're kind of ripe for disintermediation the obvious devices some kind of AR headset
Right is some pair of glasses that we can put on that puts the data directly to our eyes
It does everything the phone does without having to pull it out
All right, and actually gives us a bunch of other capabilities because now we have instrumentation on our heads
so that it can observe the world around us because we're not paying attention and
That offers a bunch of possibilities that being said 2023 not a good year for AR
Apple's just announced. This is a mock-up of what we thought Apple was going to make
It's all a lie and it currently Apple says they're not making anything they've backed off
So whatever prototypes they were working on internally, they're not happy with them right now
There are commercial products that are glasses with devices on it
This is a Qualcomm device called the XR1 you can buy this today. It's about thousand bucks tethered to an Android phone
And it's just a USB headset that has microphones and speakers and cameras and and
And screens integrated into it and you're seeing these used in certain commercial applications
If you want to look more like Google Glass, you can do this with the Toshiba devices. This is the Dyna edge
So I want one eye a little more industrial looking
Okay, this hardware exists. There is HoloLens, but HoloLens is not in a good place
If I was this is the tremble version of HoloLens 2
This is the one they wanted to put on all construction workers because construction workers are good with equipment
at
3000 bucks a piece plus about a thousand dollars a month in operating costs
When I when we started doing some case studies on implied HoloLens products
I was stunned at how much Azure eats to operate it properly like
Now for certain markets that makes perfect sense construction site not so much
But if you've been paying attention to the recent round of layoffs, you know, they've pretty much laid off the entire HoloLens team
The leader of the HoloLens team a guy named Alex Kipman left Microsoft back in July
So they've been a little bit leaderless for the past few years and the army announced they shut down there
They were gonna shut down a project. They want to do more research on it and then these round of layoffs came
So it looks like the HoloLens is an orphan for the moment
I mean the the opportunity in certain verticals is really interesting the you know industrial applications where
Basically equipment becomes transparent checklists are live
You're making continuous video record of the maintenance that you're doing. These are all interesting applied cases
I looked at this very much as the
That the AR glasses were in the same place that the BlackBerry phone was in like the 1990s
In the 90s if you want an email on your phone, I know crazy
You had to buy these a thousand dollar phones in the 90s
From from rim called the BlackBerry and had a little keyboard on it and you had to run a custom version of exchange server
inside of your organization to make it work
So you need a couple of guys in lab coats and
A whole ton of licenses and you too could have email on your phone and it was so popular in the 90s
They called them crackberries
But it needed to be the right vertical it needed that cost had to be worthwhile that continuous access that person was important enough
Right, you saw it on like the West Wing right the politicians and bureaucrats needed this sort of thing
And of course today emails been completely
Commercialized it's in every device. It's not a big deal
But I look at HoloLens and the AR devices that way for the right vertical where you can afford that
Expend is trivial to its value totally makes sense consumer device. No, not there yet
And we don't know when we will be it's an insanely complex device now the HoloLens 2 is six years old
We never saw the HoloLens 3 so the tick tock of Moore's law still applying
We should be able to get dramatically better headset. We're just struggling for the applications for it
I'll make fun of meta very briefly. It's not hard to do anymore. It was funnier a couple of years ago. I
We would have said hey Zuckerberg created the largest loss of value in all time
He burned through ten billion dollars in a year, but then I
Mean Facebook was a trillion dollar company now. It's a 300 billion dollar company well done
But then you know, let's look at Twitter or Tesla
My billionaires messing up their companies seems to be a style. I presume it will pass
These headsets are compelling
This was really John Carmack the guy behind Oculus that got acquired by Facebook who has now put down his his laptop
I go, okay, I've had enough you people and he's left now to so any sense
That Facebook's along between Cheryl Samberg leaving and Asia and and and Carmack leaving
Zucks by himself and I think fairly far off the rails
Microsoft seemed to be playing ball
They they wanted a team's version of this with the new the quest pro the $1,500 headset in the horizon workspace
They've now backed away from this. So this is kind of a dark time in general
We're kind of it for AR and VR if you are interested in developing in the space
The obvious tool is unity like the bulk of development being done in the space is done in unity. It's C sharp centric
It's its own custom build essentially if you've never played with this is it's an experience
And I recommend the tool often to kids who think they want to make games
Because you can do a few watch a few videos use the free version of unity and you can do a lot
You can make a pretty basic straightforward side scroll and have an experience and then start to think more profoundly about the challenges of writing games
But a lot they but unity has going forward is a really good set of 3d libraries
For making it easy to do all of that three-dimensional work
Okay, one last topic and then we'll wrap up
Quantum computing because people love it. So quantum computing is a kind of super computing
It's not likely to be a regular general-purpose compute. It's for super compute problems
So the same way that we build these titanic supercomputers for modeling weather and things these are the kinds of problems basis
The quantum computers good for that
There are a number of companies that are building a variety of different styles of quantum computers
This to me likens very much to the late 40s early 50s in
General computing before the development of the of silicon
So every computer is kind of bespoke. This the sycamore computer built by Google. It has 54 qubits
It was the first to achieve quantum supremacy where it worked on a particular problem
That was considered thousands of years of compute in traditional computing
That's questionable. My favorite part of that story was it's a 54 bit computer quantum computer
Except one of the bits was broken on performance day. So it was a 53 cubit cubit run
this particular design of quantum computers is what they call
Transmon quantum processing. So this is kind of this is a way of doing quantum entanglement with ultra-cooled
Material they cool in the liquid helium
Which is dangerous
The Chinese have a photonic quantum computer. They had up and running in about 2020 with a hundred and 13 entangled qubits
They did a Bose's sampling compute in 200 seconds. That would have been multi-billion years of traditional compute
It was a known problem. It's kind of a proof point. But again, these are
Getting there and then IBM's Eagle and Osprey and Condor architectures
in the hundred to
120 or so qubits that one was in benchmarking in 20 late 2021 2022
We haven't seen the results from it yet. They were promising by last year to have a 400 qubit
Processor that hasn't materialized yet and this was supposed to be the year they produced a thousand qubits that hasn't happened either
The real question is what the hell are you going to do with this thing?
Like the only thing ever here on the news
This is the end of security that we're going to be able to break our say encryption
Which is true?
Kinda in the end encryption strategies that use prime number very these very large prime numbers are
susceptible to the compute strengths of quantum computer if you have four or five thousand entangled qubits
You should be able to crush through 128 digit primes in a matter of seconds
We don't have to use
Prime based encryption there are other kinds of encryption in fact and the NSA is currently recommending that we switch to a lattice based
Encryption, it's just not as efficient to encrypt with other kinds of encryption strategies
It turns out the computers are good at prime numbers as a cost effective ways to do encryption as well as decryption
So forget the encryption problem solvable not interesting
The most interesting problems in the quantum computing space are actually chemistry problems and the classic one for me is in agriculture
So in the pre technological era if you wanted to grow crops routinely if you were planting wheat
If you kept growing wheat in the same chunk of land year over year
You got less and less wheat because you depleted the soil you had to rejuvenate the soil now today in an industrial world
We have the Hayrabash process where we make industrial fertilizers and after you have a season of growing wheat
You then fertilize the stod out of that land and repopulate that replenish the soil to grow wheat again
But before we had that we rotated crops and there are bean plants typically that has a rhizome on it
That lives on the roots and inside of that is an enzyme called nitrogenase and nitrogenase
Naturally affixes nitrogen it takes water and night from and what and nitrogen from the air and in a catalytic reaction
Turns it into ammonia so in the normal crop rotation you would grow a crop of beans
You would harvest the beans you plow the plants under and then you let the land go fallow for a year
You let those roots rot and they were to release fertilizers back into the soil and then the third year you can plant wheat again
That's the traditional non-technical way to do it chemical fertilizers avoided that but chemical fertilizers have their own cost
They're about 1% of the energy consumption of this planet is based on making and distributing fertilizers
So if we could utilize this thing that a bean plant could do
We could have a significant impact on agriculture
The problem is that the catalytic reaction that goes on inside of that enzyme
involves atoms of molybdenum and iron and it's a 2 to the
170th complex problem to understand the electron interaction, which is like more atoms that are on the than they're on the earth a
Midsize quantum computer something in the 400 qubit range should be able to solve this should give us an example
Of the correct catalytic reaction that doesn't mean we'll immediately be able to implement it
But once you know what the reaction looks like you have a chance of now engineering and implementation of it
So that we could be making fertilizer directly from air at low power plant power
And be able to grow food more routinely. It's an interesting quantum problem
There are other quantum chemistry problems like that battery design is largely based on experimentation
Not on our actual understanding of the interactions of the compounds what we have done in battery
Development today has gotten really good at iterating on trying different combinations not actually understanding the optimal combination
It's a quantum computing problem
Modern superconductors the Rebco superconductors, which are made from rare earth materials and barium cupric oxide are
ceramics that are superconductive at liquid nitrogen temperatures as opposed to niobium Tim, which is superconducting at helium temperatures
Which is way harder to deal with we've had these superconductors for about 40 years
We just don't really understand how they work and
So it's hard to make better ones and again quantum computer quantum chemistry problem
These are all deterministic problems so the real question is how many quantum computers do we need?
Because once you've solved it you kind of need to solve it again, right?
It's not a non deterministic problem where you need to do it every time like a weather problem
It's just a deterministic problem and it reminds me of of
of
Thomas Watson's statement when they were first building mechanical mainframes for the original version of IBM where he told his board
I think there's only a market for like five of these and then they went out selling and they sold like 25
And it was a revelation, but that was because back then the computer looked like this
Right, this is before
Intel this is before
The silicon transistor you've your computer looks like this
You can't envision a smartphone like you can't see it from there. It's it's too hard
The first transistor ever made may in Bell Labs the geranium transistor looked like this
It's pretty hard to look at that and mink M1 chip
All right, it's a big jump
So going back to that mainframe
What made
Traditional computing useful was the integrated circuit. We suddenly had a stable reliable way to make bits
We made RAM and then we made processes for them. They were consistent and we could scale them and Moore's law took over
We got more and more potential compute. I described to you three different kinds of quantum computers today
They were all radically different because there's not a good qubit yet
Everybody's trying to make the right qubit. They're exploring their quantum computers are very
Much like these bespoke general computers from the 40s and 50s
And maybe that's what it's gonna take the my favorite story of this whole thing is the guy one of the guys who made this transistor
Guy named William Shockley
He was also the guy who who then created a company called Fairchild summer conductor
And he tried to make and he made the first integrated circuits
And when he was trying to figure out the chemo the chemistry was gonna need to dope it properly and what the ratio should be and so
forth he used an old-style mechanical mainframe to do the computation and
That gave him the models to be able to build the first integrated circuits that made far more reliable general-purpose computers
I wonder if these flaky goofy
Unreliable quantum computers are building today or the compute devices will need to find the reliable qubit. I
Don't know the answer to that, but I like how the history rhymes. I do know this
We're trying to predict the future the best way to do it is to make it and that's us we do this
We're going to go out and do some work
We're these next couple of days
We're gonna do a bunch of learning and we're gonna create the future and I can't wait to see what we make. Thank you for your time
