WEBVTT

00:00.000 --> 00:10.280
Hey everyone, today on Moment of Zen, we chat with Beth Jayzos, the co-founder of the EAC

00:10.280 --> 00:14.880
movement, or Effective Accelerationism, who was doxxed on Friday night by Forbes reporters.

00:14.880 --> 00:17.120
We'll link to some articles about it below.

00:17.120 --> 00:21.320
Up ahead, we get the inside story from Beth, whose real name is Guillaume Verdome.

00:21.320 --> 00:25.680
We also discuss anonymity, the media, and the role of journalism in our society.

00:25.680 --> 00:30.320
Also joining the conversation is Baselord, Beth's EAC co-founder, who remains anonymous,

00:30.320 --> 00:33.720
and Nathan LeBenz, who hosts the Cognitive Revolution podcast.

00:33.720 --> 00:35.720
Quick disclaimer, and then we'll get to the show.

00:35.720 --> 00:40.400
I'm an investor in XTropic, the stealth AI hardware startup that Guillaume founded.

00:40.400 --> 00:41.960
Here's Moment of Zen with Beth.

00:41.960 --> 00:42.960
Yo, yo.

00:42.960 --> 00:47.400
What do we got going on here, Steve Jobs?

00:47.400 --> 00:52.800
Well, you know, I got to switch up the look, keep the commenters chirping.

00:52.800 --> 00:53.800
Yeah.

00:53.800 --> 00:55.800
A lot of people hop in.

00:55.800 --> 01:02.880
So, Somali Pirate to, you know, confident design partner, I don't know, like what's

01:02.880 --> 01:04.880
going on here.

01:04.880 --> 01:06.200
Yeah, exactly.

01:06.200 --> 01:07.200
Just testing it out.

01:07.200 --> 01:10.040
Did you get a better webcam, too?

01:10.040 --> 01:11.040
No.

01:11.040 --> 01:13.040
Oh, okay.

01:13.040 --> 01:16.480
But, but I'm going to.

01:16.480 --> 01:18.640
Is the Binance topic like a five minute topic?

01:18.640 --> 01:21.160
I mean, I can give an update on it if you want.

01:21.520 --> 01:22.520
Yeah.

01:22.520 --> 01:23.520
Well, I'll start that.

01:23.520 --> 01:24.520
You're giving an update on the Binance topic.

01:24.520 --> 01:30.920
Well, I mean, it's a little bit old news at this point, but we had a major settlement

01:30.920 --> 01:39.600
that Binance, the CEO of Binance CZ, who, he, you know, kind of kicked off the SBF issue

01:39.600 --> 01:41.760
and is big of a name in crypto.

01:41.760 --> 01:47.400
I mean, it's CZ, SBF, and Brian Armstrong were the three big names during the last cycle,

01:47.400 --> 01:51.800
and SBF has now been convicted.

01:51.800 --> 01:57.680
And CZ, there were always kind of rumors that there was like a big DOJ investigation.

01:57.680 --> 02:00.760
Then there was an SEC suit that happened this year.

02:00.760 --> 02:07.560
But in terms of the real criminal stuff, that had always been swirling and a lot of allegations

02:07.560 --> 02:10.120
around sanctions.

02:10.120 --> 02:16.000
And remember, sanctions are a U.S. tool because the world is run on dollars.

02:16.000 --> 02:22.560
So the U.S. can basically say, hey, you can't send dollars or anything crypto to these specific

02:22.560 --> 02:29.120
countries or individuals, and the allegations were that Binance was facilitating that.

02:29.120 --> 02:34.040
Now, I actually don't even know the details specifically whether or not they did, to what

02:34.040 --> 02:44.480
extent, but what came out was, and the settlement was CZ is stepping back as CEO.

02:44.840 --> 02:53.800
And I think the record fines for sanctions have been as a result of violating sanctions

02:53.800 --> 02:54.800
with Iran.

02:54.800 --> 02:59.520
I want to say it was like BNP Paribas, which is a French bank, paid something like $8 billion,

02:59.520 --> 03:02.960
or maybe it was HSBC, I forget.

03:02.960 --> 03:07.760
And then I think another big set of fines, HSBC might have been the drug cartels, but

03:07.760 --> 03:13.120
basically it's like Iran, which is a geopolitical issue, and then the drug cartels, if you do

03:13.120 --> 03:17.760
money laundering, you pay major fines and there's criminal liability.

03:17.760 --> 03:20.680
So the settlement was he steps back.

03:20.680 --> 03:22.760
Binance can still exist, which I'm actually surprised.

03:22.760 --> 03:27.080
I think he's paying something on the order of like $50 million fine.

03:27.080 --> 03:33.520
And the thing I didn't quite get in the first day of the news, but then it turned out later

03:33.520 --> 03:37.360
kind of seemed to bubble up is he's still in the U.S., I think, and actually may have

03:37.360 --> 03:42.440
to do some jail time, which is like a pretty big deal.

03:42.440 --> 03:43.960
Because he's voluntarily given it up.

03:43.960 --> 03:51.160
So you know, if he's willing to step back, pay $4 billion fine, $50 million personally,

03:51.160 --> 03:55.840
and potentially do jail time in the U.S., that means they were going to throw a huge

03:55.840 --> 03:59.240
amount of the whole book at him.

03:59.240 --> 04:04.800
But what's interesting is the SEC is not done with their case, which I think is a civil

04:04.800 --> 04:05.800
case.

04:05.800 --> 04:10.200
So that will still be another big hit on Binance if they have to settle it.

04:11.200 --> 04:12.920
Obviously, you don't have the founder anymore.

04:12.920 --> 04:18.640
If he has to do jail time, it can't even be, you know, indirectly influencing.

04:18.640 --> 04:22.000
And then I would imagine the European Union and every other jurisdiction that's kind

04:22.000 --> 04:25.880
of within the global U.S. sphere is going to say, well, we don't want to look like we

04:25.880 --> 04:27.480
were not tough on these guys.

04:27.480 --> 04:30.320
And so these guys are going to be paying a lot of money.

04:30.320 --> 04:35.480
So I'm curious to see if they end up existing, you know, five years from now.

04:35.480 --> 04:37.600
I mean, five years in crypto is a long time.

04:37.840 --> 04:43.480
But basically Binance popped up during, you know, call it 2017 era when there was another

04:43.480 --> 04:48.320
exchange called PoloniEx, which was actually based in the U.S., but they were only serving

04:48.320 --> 04:55.160
international customers in theory, that they knocked PoloniEx off the top spot and never

04:55.160 --> 04:56.160
kind of looked back.

04:56.160 --> 04:59.480
And SBF was gunning to try to be the next Binance.

04:59.480 --> 05:05.120
So what's left in the wake of this is, you know, Coinbase, which I think got a lot of

05:05.160 --> 05:11.840
ridicule from, you know, the mid-wit, Finn Twitter, like Bukko Capital and all these,

05:11.840 --> 05:16.960
like, kind of a non-accounts that are too afraid to put their name next to an account.

05:16.960 --> 05:22.240
So they like to make fun of, you know, entrepreneurs on the sidelines when obviously everything

05:22.240 --> 05:27.520
corrected last year, they were all like Coinbase is not, you know, like a real business.

05:27.520 --> 05:32.560
I mean, Bukko Capital was calling Coinbase a cancer as of last week because crypto prices

05:32.560 --> 05:33.560
are pumping.

05:33.560 --> 05:38.360
But Coinbase actually is the only one that's been following the law and didn't have a crazy

05:38.360 --> 05:39.360
risk program.

05:39.360 --> 05:45.200
So FTX disappears, Binance disappears, Gemini basically was doing a bunch of shady stuff

05:45.200 --> 05:47.680
and blew up as a result of that.

05:47.680 --> 05:49.440
What was the other one?

05:49.440 --> 05:50.840
BlockFi, right?

05:50.840 --> 05:51.960
Like, there's a pretty famous meme.

05:51.960 --> 05:56.320
I like pump, but pump kind of was like pumping them and it's like to the moon and like this.

05:56.320 --> 05:59.560
And obviously that was fraudulent.

05:59.560 --> 06:02.120
And so it turns out like Coinbase is the only one that was legit.

06:02.120 --> 06:06.320
And yes, like that's been the MO of the company the whole time.

06:06.320 --> 06:09.480
And so finally with the government cleaning up the space, it's like now Coinbase is sitting,

06:09.480 --> 06:12.720
you know, Coinbase, Bitcoin just crossed 40,000.

06:12.720 --> 06:18.360
And Coinbase is basically the only exchange with like meaningful fiat rails and customer

06:18.360 --> 06:19.360
base.

06:19.360 --> 06:22.000
I mean, there are overseas exchanges that will take place in Binance.

06:22.000 --> 06:25.720
But it's a huge vindication, I think, for Brian Armstrong, who's taken a lot of arrows

06:25.720 --> 06:28.400
for a lot of different things.

06:28.400 --> 06:30.040
I'm also happy about the share price personally.

06:31.040 --> 06:32.360
Yeah, totally.

06:32.360 --> 06:34.360
You're hopefully incentivized.

06:34.360 --> 06:36.480
Yeah, let's be clear.

06:36.480 --> 06:38.640
I'm extremely biased here.

06:38.640 --> 06:42.240
But what I would say is like, if you want me to give you like the counterpoint, I do

06:42.240 --> 06:50.320
think Binance pushed the industry forward, Modulo put the illegal stuff off the side.

06:50.320 --> 06:56.400
They never had a major hack, which is usually how a lot of these exchanges go down.

06:56.440 --> 07:00.960
And to the degree that I understand it as a result of the DOJ, it wasn't misappropriating

07:00.960 --> 07:02.560
customer funds, right?

07:02.560 --> 07:06.880
So now the SEC may come and say something different, but big difference between SPF,

07:06.880 --> 07:08.640
which was actual fraud, right?

07:08.640 --> 07:12.000
Like you was taking customer funds, which you're not supposed to touch, and was using

07:12.000 --> 07:16.960
it to, you know, pay Tom Brady and donate to political campaigns.

07:16.960 --> 07:21.360
So I think Binance was an honest actor as it relates to customers.

07:21.360 --> 07:25.120
I think they just seems like they were a little fast and loose with the, you know, the international

07:25.120 --> 07:27.760
sanctions regime.

07:27.760 --> 07:28.760
Perfect timing.

07:28.760 --> 07:34.680
Fast and loose with the international sanctions regime, and Antonio hops on to the call.

07:34.680 --> 07:35.680
Who sanctions?

07:35.680 --> 07:36.680
What regime?

07:36.680 --> 07:38.440
Yeah, that's actually a good one.

07:38.440 --> 07:43.920
We know a few people who would like to argue that US sanctions are not valid, but the reality

07:43.920 --> 07:47.880
is if you live in a dollar denominated world, you got to pay attention to those sanctions

07:47.880 --> 07:50.480
because you can go to jail if you violate them.

07:50.480 --> 07:53.880
We were talking about Binance.

07:53.880 --> 07:56.400
Where is the man of the hour?

07:56.400 --> 07:58.760
He's having trouble getting in.

07:58.760 --> 08:01.680
I've never seen this issue before.

08:01.680 --> 08:07.640
Maybe he's using some like futuristic quantum web browser that doesn't have support for

08:07.640 --> 08:10.680
lowly riverside web RTC.

08:10.680 --> 08:15.000
Or Emily Baker White put some weird malware that she used to like sample his voice to

08:15.000 --> 08:16.000
out him.

08:16.000 --> 08:17.000
And it's still like on the machine.

08:17.000 --> 08:18.000
Did they add him on our podcast?

08:18.000 --> 08:19.000
Yeah.

08:19.000 --> 08:24.480
I find that this wasn't actually MBS in collaboration with Forbes, right?

08:24.480 --> 08:28.240
Hey, Beth, how are you?

08:28.240 --> 08:31.520
You guys know the reference, right?

08:31.520 --> 08:33.920
No, what?

08:33.920 --> 08:34.920
MBS?

08:34.920 --> 08:40.800
It's still not confirmed, and I think it's probably fake, but it's also maybe real.

08:40.800 --> 08:48.240
Bezos' marriage got broken up as a result of MBS sending spyware in WhatsApp to Jeff.

08:48.240 --> 08:53.280
And the text messages in question were, hi, Jeff, how are you?

08:53.280 --> 08:54.680
This is MBS.

08:54.680 --> 09:00.480
Well, it was probably good for him and bad for American cities everywhere, but yeah,

09:00.480 --> 09:01.480
exactly.

09:01.480 --> 09:02.480
Exactly.

09:02.480 --> 09:03.480
He got divorced.

09:03.480 --> 09:04.480
I don't know.

09:04.480 --> 09:07.920
Lauren Sanchez, she's pretty happy, right?

09:07.920 --> 09:15.000
And she's now on the front of the yacht that they just finished, because Chris Sailing

09:15.000 --> 09:17.840
Antonio is such a blue collar thing, right?

09:18.440 --> 09:19.440
He's not sailing.

09:19.440 --> 09:20.440
He's motoring.

09:20.440 --> 09:21.440
Motoring is totally different.

09:21.440 --> 09:22.940
Doesn't he have a sailboat?

09:22.940 --> 09:24.440
Isn't it a big sailing yacht?

09:24.440 --> 09:26.080
I don't know.

09:26.080 --> 09:29.520
The deck photos I've seen are clearly a large motor yacht type thing.

09:29.520 --> 09:31.680
Someone, we should put it in the YouTube comments.

09:31.680 --> 09:37.760
The pictures of Jeff Bezos' boat, my understanding is that there are sails, but it could be.

09:37.760 --> 09:40.360
All right, we got it.

09:40.360 --> 09:45.440
You guys have the most interesting guests on the podcast the one time I can't make it.

09:45.440 --> 09:46.440
Oh, don't worry.

09:46.840 --> 09:47.840
Oh, Dominic Cummings.

09:47.840 --> 09:48.840
Yeah.

09:51.840 --> 09:55.240
He sounded super pumped to like Rijig or San Francisco, I have to say, which was interesting.

09:55.240 --> 09:56.240
Yeah.

09:56.240 --> 09:57.240
I don't know.

09:57.240 --> 10:00.240
I think saving SF is kind of cope.

10:00.240 --> 10:01.240
You think it's unsavable?

10:01.240 --> 10:03.240
I mean, are you running, Eric?

10:03.240 --> 10:04.240
Sir.

10:04.240 --> 10:06.240
Hey, everyone.

10:06.240 --> 10:07.240
Welcome.

10:07.240 --> 10:10.240
Welcome to FACE Twitter.

10:10.240 --> 10:11.240
FACE Doxxed World.

10:11.240 --> 10:15.240
Well, hello, world.

10:15.240 --> 10:19.140
I see the Eigenfunction on your quantum computer has clapped into the state in which you can

10:19.140 --> 10:24.840
join the Riverside and some other worlds you were in fact still struggling, but Schrodinger's

10:24.840 --> 10:25.840
Riverside episode.

10:25.840 --> 10:26.840
Yeah.

10:26.840 --> 10:27.840
Yeah.

10:27.840 --> 10:28.840
Yeah.

10:28.840 --> 10:32.040
We need to upgrade the quantum computers to use this wonderful app.

10:32.040 --> 10:39.040
Speaking of which, what is that menacing blinking box behind you over your right shoulder?

10:39.040 --> 10:40.640
That's just, don't worry about that.

10:40.640 --> 10:43.640
Don't worry about that.

10:44.640 --> 10:45.640
Yeah.

10:45.640 --> 10:49.640
No, I'm in EAC HQ or Extropic HQ.

10:49.640 --> 10:55.740
I've got our banner in the back and of course I've got some Dr. Pepper and some ketones

10:55.740 --> 10:57.940
back there.

10:57.940 --> 10:58.940
Very memetic.

10:58.940 --> 11:02.440
But I guess we're recording right now, right?

11:02.440 --> 11:03.440
We're recording.

11:03.440 --> 11:04.440
We're watching it.

11:04.440 --> 11:05.440
Okay.

11:05.440 --> 11:06.440
Wonderful.

11:06.440 --> 11:07.440
Eric doesn't read you your Miranda rights.

11:07.440 --> 11:08.440
You just go right into it.

11:08.440 --> 11:09.440
It's like a cold.

11:09.440 --> 11:10.440
Okay.

11:10.440 --> 11:11.440
Got it.

11:11.440 --> 11:12.440
Let's go.

11:12.440 --> 11:16.640
Well, super happy to be here.

11:16.640 --> 11:18.240
It definitely feels weird.

11:18.240 --> 11:20.840
It definitely feels very weird.

11:20.840 --> 11:25.600
It's been kind of a compartmentalized part of my life, you know, felt like a video game

11:25.600 --> 11:27.400
on my phone more or less, right?

11:27.400 --> 11:32.640
Like having an alternative Twitter and having a very professional life day to day, you would

11:32.640 --> 11:39.240
never guess that I'm back from just like day to day interactions, frankly.

11:39.240 --> 11:43.080
And now the two have kind of bled into one another and they are one.

11:43.080 --> 11:46.440
And so I'm still pricing that in mentally, frankly.

11:46.440 --> 11:53.240
So it's been an interesting couple of days, obviously, a lot of inbound, more DMs I can

11:53.240 --> 11:55.740
ever count.

11:55.740 --> 12:00.240
And yeah, I mean, it's been a very surprising reaction.

12:00.240 --> 12:02.760
Well, I guess not that surprising.

12:02.760 --> 12:07.600
I guess like, you know, tech Twitter kind of, kind of hates the establishment media

12:07.600 --> 12:13.640
at this point and, you know, came to my defense, which, which felt, felt quite good.

12:13.640 --> 12:21.400
But you know, I'm happy to go into any part of it, you know, how it went down, you know,

12:21.400 --> 12:27.600
the why I started Beth, anonymity, and anything, the startup, let me know how you want to

12:27.600 --> 12:28.600
structure this.

12:28.600 --> 12:29.600
This.

12:29.600 --> 12:30.600
Yeah.

12:30.640 --> 12:34.480
With the sorted details of how they figured it out and what voice they sampled and how

12:34.480 --> 12:37.680
that whole sorted tail played out.

12:37.680 --> 12:38.680
Yeah.

12:38.680 --> 12:45.000
I mean, there was a couple instances where there's reporters that, you know, think they

12:45.000 --> 12:51.480
have my docs and I'm just like, you know, you can't, you can't dox people, you know,

12:51.480 --> 12:53.800
I do not want you to do this.

12:53.800 --> 12:58.160
And usually that kind of kills the story to some extent, but you know, it's kind of been,

12:58.160 --> 13:01.480
you know, I've gone, I've been in the SF social scene in person.

13:01.480 --> 13:05.560
I know a bunch of investors, for example, they, some of them know some of them have correlated

13:05.560 --> 13:06.560
the two.

13:06.560 --> 13:10.160
Um, but obviously I, I, I spent a bunch of time in Twitter spaces.

13:10.160 --> 13:15.600
I've had, I have some online lectures from my days in grad school and quantum computing.

13:15.600 --> 13:19.160
And really that's basically what they've, what they've correlated.

13:19.160 --> 13:26.160
Uh, they, they, they use some, I don't know, I call it CIA technology as a joke, but, uh,

13:26.160 --> 13:32.280
you know, they use some government grade technology to identify my voice, uh, you know, just because

13:32.280 --> 13:36.040
I have a 50 K follower account, uh, that speaks truth to power.

13:36.040 --> 13:41.000
I guess, I guess it tells you that, you know, we're doing something right and that some

13:41.000 --> 13:47.120
people in the establishment, you know, want to have leverage over the leader of the grassroots

13:47.120 --> 13:54.760
movement, uh, that, you know, is for freedom and, and, and against top down control, which

13:54.880 --> 13:55.880
is very scary.

13:55.880 --> 13:56.880
Cause that's what they like.

13:56.880 --> 13:57.880
Right.

13:57.880 --> 14:02.720
So, Hey, we'll continue our interview in a moment after a word from our sponsors.

14:02.720 --> 14:03.720
Real quick.

14:03.720 --> 14:07.680
What's the easiest choice you can make taking the window instead of the middle seat outsourcing

14:07.680 --> 14:10.280
business tasks that you absolutely hate.

14:10.280 --> 14:13.920
What about selling with Shopify?

14:13.920 --> 14:18.680
Shopify is the global commerce platform that helps you sell at every stage of your business.

14:18.680 --> 14:23.400
Shopify powers 10% of all e-commerce in the U S and Shopify is the global force behind

14:23.440 --> 14:28.760
all birds, Rothy's and Brooklyn and millions of other entrepreneurs of every size across

14:28.760 --> 14:31.280
175 countries.

14:31.280 --> 14:34.640
Whether you're selling security systems or marketing memory modules, Shopify helps you

14:34.640 --> 14:40.000
sell everywhere from their all in one e-commerce platform to their in person POS system, wherever

14:40.000 --> 14:43.040
and whatever you're selling, Shopify's got you covered.

14:43.040 --> 14:45.560
I've used it in the past at the companies I've founded.

14:45.560 --> 14:50.480
And when we launch merch here at Turpentine, Shopify will be our go to Shopify helps turn

14:50.520 --> 14:55.480
browsers into buyers with the internet's best converting checkout up to 36% better compared

14:55.480 --> 14:57.520
to other leading commerce platforms.

14:57.520 --> 15:01.960
And Shopify helps you sell more with less effort thanks to Shopify magic, your AI powered

15:01.960 --> 15:07.760
all star with Shopify magic whip up captivating content that converts from blog posts to product

15:07.760 --> 15:14.080
descriptions, generate instant FAQ answers, pick the perfect email, send time, plus Shopify

15:14.080 --> 15:20.000
magic is free for every Shopify seller businesses that grow, grow with Shopify, sign up for

15:20.040 --> 15:25.800
a $1 per month trial period at Shopify.com slash moment of Zen, go to Shopify.com slash

15:25.800 --> 15:30.440
moment of Zen now to grow your business no matter what stage you're in Shopify.com slash

15:30.440 --> 15:31.040
moment of Zen.

15:33.480 --> 15:36.520
You spoke truth to power and now they're going to try to speak power to truth, so to speak.

15:36.720 --> 15:41.280
But I'm curious, someone must have, they must have been tipped off because they didn't do an

15:41.280 --> 15:42.320
all against all voice sample.

15:42.320 --> 15:45.400
They, they started after this pair wise interaction, right?

15:45.400 --> 15:47.040
Because there was nothing online that would have suggested it.

15:47.240 --> 15:49.080
And then they confirmed it via that, I imagine.

15:49.800 --> 15:55.400
Yeah, so see, they must have like asked around, you know, I mean, it's kind of like a people

15:55.400 --> 15:57.440
know other people's docs is right.

15:57.440 --> 16:02.480
Like there's kind of Twitter parties in person and people go by their alternative name.

16:02.480 --> 16:06.480
So they know your face and eventually they correlate things, but there's kind of a, yeah,

16:06.480 --> 16:09.760
there's an unwritten rule of like, you don't, you don't like talk to reporters.

16:09.760 --> 16:12.800
You don't share people's docs with other consent.

16:13.160 --> 16:17.880
I'm sure some people, you know, broke that rule, but you know, I don't know what drove

16:17.880 --> 16:19.200
them to really break the story.

16:19.200 --> 16:22.240
Now, I think there were some latent variables there.

16:23.560 --> 16:29.160
But yeah, essentially, I think it was on Thursday, I get a text from some of my investors.

16:29.680 --> 16:32.040
They identified some of my investors.

16:32.200 --> 16:35.200
So this podcast is going to drop after we announced the round.

16:35.200 --> 16:37.800
So I'll just mention investors.

16:38.280 --> 16:44.280
But yes, so some of our big investors get a text like, Hey, I think this, you know, over

16:44.280 --> 16:49.040
this first reporter, I think it was Conrad has started correlating your identity with

16:49.040 --> 16:53.520
Beth, they didn't correlate all the company because we had a, you know, I had a company

16:53.520 --> 16:58.280
change the name, now we're extrapik, they hadn't correlated everything perfectly, but

16:58.280 --> 17:00.840
then the censor fuse the cross reporters internally.

17:01.080 --> 17:05.160
So they didn't have enough to ship it on Thursday, but then on Friday, a different

17:05.160 --> 17:10.360
reporter, Emily joined force, the filings, the track name changes.

17:11.360 --> 17:20.240
They went to my personal Facebook to, you know, to identify a photo I shared like on

17:20.240 --> 17:25.800
my friend, you know, friends only Instagram of the party, you know, when we were on stage

17:25.800 --> 17:27.120
with Grimes and stuff like that.

17:28.320 --> 17:30.160
And they correlated everything, right?

17:30.160 --> 17:34.440
And so they just had me in this sort of checkmate, like we have this, this, this, this, this,

17:34.440 --> 17:36.560
this, talk to us, we're going to ship it.

17:37.200 --> 17:39.760
And I was like, all right, I got to get in front of this, right?

17:39.800 --> 17:44.960
Again, you know, I've been doing this deep tech startup for nearly a year and a half.

17:45.000 --> 17:51.240
And, you know, as, as the bio says, I come from Google X, you know, we're taught to

17:51.240 --> 17:55.800
be very secretive about what we do because in deep tech, that's kind of the, the MO.

17:56.880 --> 17:59.680
And, you know, we want to be secretive for, for longer.

18:00.440 --> 18:05.880
But for all sorts of reasons, including national security interest reasons, right?

18:05.920 --> 18:08.520
Like our technology is pretty out there.

18:09.480 --> 18:11.400
And it kind of forced our hand, right?

18:11.440 --> 18:13.200
Like it correlated all identities.

18:14.120 --> 18:19.640
And, and, and also it also kind of doxed the fact that I had founded the startup because

18:19.640 --> 18:22.640
I was kind of, I hadn't identified that on my main account.

18:22.640 --> 18:27.920
So for me, it was kind of a, a mo, you know, a moment of panic, because, you know, I want

18:27.920 --> 18:29.680
to do what's right for my company, right?

18:29.680 --> 18:31.480
I've been working really hard on this company.

18:32.320 --> 18:35.000
We were planning announcements in a couple of months from now.

18:35.920 --> 18:37.640
And now we have to rush everything, right?

18:38.440 --> 18:43.160
Which is, which is not great, but what I ended up doing, getting on the phone, getting

18:43.160 --> 18:47.600
in from the story, I already knew exactly, like that's the thing with reporters.

18:47.600 --> 18:49.400
Like they're so low entropy.

18:49.440 --> 18:51.640
They are all in the same typical subspace of stories.

18:51.640 --> 18:55.000
You can predict exactly what they're going to write just from the prior that they're

18:55.000 --> 18:55.760
trying to get you.

18:56.000 --> 19:01.640
And so I just disarmed every typical attack they would try to do on EAC trying to have

19:01.640 --> 19:07.320
second or third order guilt by association to some idea that's a derivative and another

19:07.320 --> 19:11.320
idea and neutralize that, essentially entirely.

19:11.760 --> 19:15.000
Um, I see we have Bayes Lord joining.

19:15.440 --> 19:15.960
There you go.

19:18.360 --> 19:19.400
Uh, what's up, Bayes?

19:19.520 --> 19:20.160
Can you guys hear me?

19:20.280 --> 19:20.640
What's up?

19:20.680 --> 19:20.960
Yeah.

19:21.000 --> 19:21.280
Yeah.

19:21.280 --> 19:21.880
Yeah, we can.

19:22.200 --> 19:22.560
Awesome.

19:22.800 --> 19:24.000
Oh, we have Nathan as well.

19:24.080 --> 19:25.280
Oh, let's get, all right.

19:25.280 --> 19:25.800
Here we go.

19:26.120 --> 19:29.320
What's up, what's up, what's up?

19:29.360 --> 19:29.520
Yeah.

19:29.520 --> 19:29.960
Good to see you.

19:30.000 --> 19:30.360
Not bad.

19:30.880 --> 19:31.720
Great to see you.

19:33.040 --> 19:36.480
I guess now, uh, with real names, uh, in my case, so.

19:37.480 --> 19:37.960
Yeah.

19:38.360 --> 19:45.000
Um, so, so yeah, it's been an interesting, uh, you know, I guess 48 hours, uh, dealing

19:45.000 --> 19:51.160
with this, um, I think overall, uh, I mean, we can get into why I was and on, uh, for,

19:51.160 --> 19:52.240
for various reasons.

19:52.640 --> 19:58.960
Um, but overall it seems like it was positive to the point that where, uh, some are like

19:58.960 --> 20:04.400
have a conspiracy theory that this was planted, but, uh, I had, I had that theory.

20:04.760 --> 20:08.280
I thought, I thought we're all getting conned and you were actually dropping this.

20:08.440 --> 20:09.280
Cause that's when that's a question.

20:09.280 --> 20:12.800
Do you think you would raise on a higher or lower valuation now than you did this round?

20:13.120 --> 20:14.920
I would bet the valuation grow up actually.

20:15.320 --> 20:16.440
Definitely higher.

20:16.640 --> 20:17.560
Yeah, exactly.

20:17.640 --> 20:17.960
Right.

20:18.040 --> 20:24.520
But I mean, I didn't, I want to raise round, uh, you know, raise around just uncorrelated.

20:24.520 --> 20:27.440
I didn't necessarily initially disclose to my investors.

20:27.440 --> 20:31.360
I didn't want that to be part of the, the price or anything like that.

20:31.360 --> 20:32.320
I didn't know where it would go.

20:32.320 --> 20:32.480
Right.

20:32.480 --> 20:34.240
I didn't want to correlate the two identities.

20:34.240 --> 20:35.680
It was really like orthogonal.

20:36.280 --> 20:39.920
And now my hand was forced to, to correlate the two and own it.

20:40.000 --> 20:41.120
And so I got in front of it.

20:41.480 --> 20:44.360
And of course I'm going to harness any hand and dealt.

20:44.400 --> 20:47.400
I'm just, that's what you're supposed to do.

20:47.400 --> 20:47.680
Right.

20:47.680 --> 20:51.600
And now, now we've harnessed it, um, uh, you know, pretty well.

20:51.600 --> 20:53.840
I, I would say we'll see how it plays out, of course.

20:54.280 --> 20:57.320
Um, and, and now there's this conspiracy that it was, it was planted.

20:57.320 --> 21:00.520
But, you know, in my case, again, I just wanted to control the narrative.

21:00.520 --> 21:03.640
I knew the story is going to be really bad if I didn't get on the phone and,

21:03.640 --> 21:07.120
and you know, I, I, I actually, I wanted to stall them.

21:07.160 --> 21:10.720
I want to give them enough content so that we had a couple more hours.

21:10.880 --> 21:15.960
We adjusted our website, uh, to have a pseudo launch the day of, so, you know,

21:15.960 --> 21:18.160
shout out to the team for being so adaptive.

21:18.160 --> 21:22.320
And, and, uh, you know, as of, as of the moment of airing this podcast, we'll

21:22.320 --> 21:25.520
probably have announced, uh, the round on for, for extra topics.

21:25.520 --> 21:26.840
So we rushed that over the weekend.

21:27.280 --> 21:33.240
Um, so yeah, definitely not plant, uh, but at the same time, it was always sort

21:33.280 --> 21:35.120
of a trap, right?

21:35.120 --> 21:39.520
In game theory, you want to make it's like, you, you want to make sure that

21:39.680 --> 21:43.200
like the incentive was to not dox me, right?

21:43.200 --> 21:46.320
For most people, because they knew that if they did dox me, now I could go

21:46.320 --> 21:49.320
on these podcasts with my real face, with my credentials.

21:49.320 --> 21:53.480
I, I could talk to potentially politicians and I have credentials that have

21:53.480 --> 21:56.600
some, some firepower and now more of a problem.

21:56.960 --> 21:58.080
So they kind of messed up.

21:58.120 --> 21:59.520
It's their fault really.

21:59.760 --> 22:04.560
It was a trap to some extent, but, you know, I tried my best to, you know,

22:04.560 --> 22:09.240
stay in on, but, you know, again, voice identification, technology, I'm not

22:09.240 --> 22:13.000
going to use a voice changer on Twitter spaces, like every day.

22:13.000 --> 22:13.720
Are you kidding me?

22:13.720 --> 22:14.760
Like I'm not going to do that.

22:15.040 --> 22:19.000
And I would imagine maybe the first podcast we did, they, they use that voice

22:19.000 --> 22:22.800
and correlated it with my YouTube lectures, but it's probably how they got me.

22:23.080 --> 22:23.320
Yeah.

22:24.560 --> 22:25.720
Can I still call you, Beth?

22:26.400 --> 22:26.720
Sure.

22:26.720 --> 22:27.240
That's easier.

22:27.480 --> 22:31.840
Gil or Beth Gil is like the Americanized version of Guillaume, very French, French

22:31.840 --> 22:32.320
Canadian.

22:32.320 --> 22:33.320
So you got me.

22:33.600 --> 22:35.000
Super simple question.

22:35.480 --> 22:40.200
Did the reporter, journalists, whatever I'm going to call this person, did they

22:40.200 --> 22:48.120
give you a rationale why they thought it was a moral imperative to dox you?

22:48.880 --> 22:54.360
I think there was the keyword that was like, uh, set off alarm bells for me was

22:54.720 --> 22:58.880
public interest and, you know, I had just crossed 50 K followers.

22:59.680 --> 23:03.320
And, you know, cause the, cause the law is you can't dox people unless you're a

23:03.320 --> 23:05.240
public figure, right?

23:05.280 --> 23:10.360
Um, and I guess I crossed into, I guess there's a threshold, right?

23:10.360 --> 23:11.880
So is it 50 K?

23:11.880 --> 23:13.760
Apparently it's 50 K flat, right?

23:14.120 --> 23:18.080
Um, but to me, it's like, okay, if they think they, you know, if they think

23:18.080 --> 23:20.480
it's of public interest and they're going to go with it, they're probably going

23:20.480 --> 23:21.040
to go with it.

23:21.440 --> 23:23.160
And so I'm kind of screwed here.

23:23.520 --> 23:25.680
I got to make, you know, I got to make a move.

23:26.520 --> 23:30.720
So wait, is that, is that the journal group chat decides when you become public

23:30.720 --> 23:35.000
interest or do we, like, like I'm very curious, like how they, they rational,

23:35.360 --> 23:39.720
like, cause to me that if you, if you want to be anonymous, you should be able

23:39.720 --> 23:44.400
to be anonymous and doxing you what gives them the right cause, cause if I was

23:44.400 --> 23:49.120
to go put the, I don't know, the address of that reporter online and maybe now

23:49.120 --> 23:51.680
we're arguing over whether or not an address is too far.

23:51.920 --> 23:54.080
Like what, what, what, what point is, is too far.

23:54.080 --> 23:58.680
And then who gets to decide that that's my question.

23:58.720 --> 24:01.680
And I don't think anyone has given an answer outside of, I'm a journalist.

24:01.680 --> 24:02.960
So I have a special badge.

24:03.120 --> 24:04.720
You used to have blue checks now that don't.

24:05.280 --> 24:08.240
And then they get to decide who, who can be a non versus not.

24:08.480 --> 24:11.560
But if you were to do it to them, that, that's, that's harassment, right?

24:12.440 --> 24:12.880
Right.

24:14.360 --> 24:19.480
Well, I mean, to me, I was, you know, mostly focused the eyes on the ball.

24:19.480 --> 24:22.600
You know, I have to, my prime responsibilities to my company.

24:22.600 --> 24:28.200
And I was just concerned like, Hey, we're, you know, getting announced, we

24:28.200 --> 24:33.120
have to announce and get our stuff together, you know, without preparation,

24:33.120 --> 24:35.320
without heads up only a few hours.

24:35.320 --> 24:42.360
So, you know, it, it, it seems like we were, it really seems like we planned

24:42.360 --> 24:43.880
this, but we, we truly didn't.

24:44.880 --> 24:48.880
So, but I'm just glad we adapted given the, the circumstances.

24:49.960 --> 24:54.360
But yeah, overall, I think like, I mean, this was clearly wrong, what they did.

24:54.400 --> 24:59.080
And, you know, I, you know, there's not that much to have leverage over me.

24:59.080 --> 25:00.640
It's like, okay, cool.

25:00.640 --> 25:06.680
I used to, you know, work in quantum computing and then have, you know, a

25:06.680 --> 25:08.200
normal ish background.

25:09.120 --> 25:12.560
But, you know, maybe some other people that are trying to speak truth to power

25:12.840 --> 25:17.520
and have their voices heard and want to use anonymity as a tool to speak

25:17.520 --> 25:21.400
truth to power, you know, because there's a sort of power asymmetry.

25:21.400 --> 25:25.800
So you kind of equalize that when you're an on, they can't, they can't do that

25:25.800 --> 25:26.640
anymore, right?

25:26.640 --> 25:28.480
If they, they fear getting doxed.

25:28.480 --> 25:32.840
And so it's kind of like, they want to make an example out of me, right?

25:32.920 --> 25:37.520
And I mean, I think there was a, I think there was a congresswoman at a

25:38.360 --> 25:44.680
conference, a defense conference that explicitly named out EAC as a sort of

25:44.680 --> 25:49.000
dangerous movement that needs to be suppressed with AI.

25:49.040 --> 25:49.760
That's the tweet.

25:49.760 --> 25:50.760
I'm not sure if it's correct.

25:50.760 --> 25:54.200
I still have to watch that clip.

25:54.360 --> 25:56.960
But to me, that sounds very dystopian.

25:56.960 --> 26:01.680
Like our whole movement is about freedom of information, freedom of speech, freedom

26:01.680 --> 26:03.160
of thought, freedom of compute.

26:03.640 --> 26:04.480
It's very simple.

26:04.880 --> 26:10.840
And the fact that that was deemed dangerous enough, or I don't know, like

26:11.800 --> 26:17.960
to, to, to want to suppress and, and provide the public leverage over me, I

26:17.960 --> 26:19.800
don't know, that's a huge red flag for me.

26:20.280 --> 26:24.840
I think that we were becoming a voice that was going to be a problem for

26:24.840 --> 26:25.960
the executive order.

26:26.520 --> 26:30.560
And there are very special interests behind that executive order.

26:30.680 --> 26:35.680
And they wanted to, you know, send me a warning shot, I guess.

26:35.760 --> 26:36.720
That is my theory.

26:38.000 --> 26:40.880
But I, one thing I couldn't understand, and, and, and maybe Beth, I just, I

26:40.880 --> 26:41.680
haven't read all your tweets.

26:41.680 --> 26:42.720
I, I couldn't understand.

26:42.720 --> 26:45.640
Hey, you, you obviously have a very distinguished academic background.

26:45.640 --> 26:49.480
In fact, I was reading your, your quantum tensor flow paper on the way in ages ago.

26:49.480 --> 26:52.400
I worked in like experimental quantum computing like 15 years ago, back when

26:52.400 --> 26:53.520
it was like a total infancy.

26:53.600 --> 26:54.440
Yeah, yeah, yeah, yeah.

26:54.720 --> 26:57.720
And I, I knew a lot of the theorists back then, like Michael Nielsen and I

26:57.720 --> 27:00.440
actually dated you like, any long story back in the early days of

27:00.480 --> 27:03.440
computing, I am, but obviously wasn't really smart enough to continue up in

27:03.440 --> 27:04.840
any case, I was reading it with a lot of pleasure.

27:04.840 --> 27:07.400
And it's, it's odd that they would consider this a bad thing.

27:07.400 --> 27:10.640
It's, it's obviously given a lot of intellectual credibility to EAC movement.

27:10.640 --> 27:10.920
Right.

27:11.120 --> 27:14.080
Like your background is pretty good, right?

27:14.080 --> 27:14.840
Like it's pretty distinguished.

27:14.840 --> 27:15.880
Like you've, you've done a lot, right?

27:15.880 --> 27:20.200
And I, you know, you, a lot of co-authors and it's like, that's why I thought

27:20.200 --> 27:22.480
the conspiracy, and I don't really believe it to be clear, but I thought maybe

27:22.480 --> 27:25.280
he actually, like actually provoked for us to do this.

27:25.440 --> 27:26.880
Cause this is like a brilliant thing.

27:27.000 --> 27:29.880
Like you bring actually so much positive social capital to the movement.

27:30.120 --> 27:34.800
You come off as like this edgy hip, you know, poster who kind of had, you know,

27:35.840 --> 27:36.960
was pulling the world's tail.

27:36.960 --> 27:38.680
It's like, I, what's the downside to this?

27:38.680 --> 27:39.320
I got to understand.

27:39.640 --> 27:39.920
Yeah.

27:40.320 --> 27:44.560
Yeah, for me, I can let you know why I was anonymous.

27:44.560 --> 27:49.000
I mean, originally I was at Google X working on some pretty secretive technologies.

27:49.000 --> 27:52.040
I had access to, you know, the top of the food chain there.

27:52.440 --> 27:57.000
Um, so I, you know, I couldn't necessarily tweet, uh, anything like

27:57.040 --> 27:58.520
political and stuff like that.

27:58.560 --> 28:00.560
My tweets were watched, which is normal.

28:01.040 --> 28:06.160
Um, but you know, I, I wanted to have just a separate account where I can really

28:06.200 --> 28:08.880
let myself self go kind of like offload thoughts.

28:08.880 --> 28:13.280
And also I reached a point in quantum computing where I was respected enough

28:13.320 --> 28:17.920
that people would cheer me on or they were proven my ideas or whatever.

28:17.920 --> 28:19.520
Oh, so smart, whatever.

28:19.560 --> 28:23.920
And that was kind of like kind of annoying me that like, do they like my ideas

28:23.920 --> 28:25.880
or do they just want a job or something?

28:26.240 --> 28:29.120
And I just wanted to put my ideas in the arena, right?

28:29.120 --> 28:33.840
It's like, I just wanted people to evaluate my ideas for their own, not look

28:33.840 --> 28:38.920
at credentials, not like weigh my opinions, dependent on status.

28:39.280 --> 28:42.200
I just wanted my ideas to be evaluated on their own.

28:42.720 --> 28:48.920
And, and to me, like growing a movement and having ideas resonate from scratch,

28:48.960 --> 28:52.280
uncorrelated from my original identity.

28:52.880 --> 28:57.640
Like, I mean, of course that felt like, you know, it felt like new game plus,

28:57.640 --> 28:59.000
as we say in video games, right?

28:59.000 --> 29:02.160
You restart the video game from scratch, but you have kind of all your

29:02.160 --> 29:05.400
intellect and memory and your gear, but you're, you're trying to rank up again.

29:05.400 --> 29:09.320
So I started from scratch and account with like no followers and grew it to,

29:09.320 --> 29:15.800
to 50 K before now, now my, my, there's a stat boost from, from the, the status

29:15.800 --> 29:17.960
signals of, of credentials.

29:17.960 --> 29:20.920
Uh, I personally very much hate credentialism.

29:21.560 --> 29:24.440
I think I would have been an entrepreneur five years earlier if it wasn't

29:24.440 --> 29:26.680
for credentialism, especially in deep tech.

29:27.160 --> 29:32.280
Um, I, I got very frustrated when I tried to do a startup at 25 and, you

29:32.280 --> 29:33.840
know, I would get like, who are you?

29:34.400 --> 29:38.560
Uh, and, uh, you know, I just went through big tech, the gauntlet of grad

29:38.560 --> 29:43.720
school and big tech to, to prove myself and prove to others that I can, I can

29:43.720 --> 29:48.000
do things, uh, so that I can raise the capital to realize the visions I had.

29:48.360 --> 29:54.400
Um, and so, you know, I've, I've always, I think base is, is on the same page here.

29:54.400 --> 29:59.240
You know, we always wanted sort of like EA's is all about like gatekeeping,

29:59.880 --> 30:03.240
gaslighting, status signaling, at least to us from our perspective.

30:03.680 --> 30:08.400
I, and you know, yak was about kind of bottom up.

30:08.720 --> 30:14.960
Everybody has access to opportunity to build no gatekeeping, no sort of status

30:14.960 --> 30:17.960
signaling, it's all about building, right?

30:18.400 --> 30:20.160
Um, and we want to maintain that.

30:20.160 --> 30:25.600
And I think that like, I was afraid that if I, you know, used any sort of

30:25.600 --> 30:29.600
credits that would dissuade people, you know, from participating or feeling

30:29.600 --> 30:32.760
like they can participate, cause the thing is everybody starts somewhere.

30:32.760 --> 30:38.360
And I was once, you know, that kid that was really smart, had a lot of ambition,

30:38.400 --> 30:39.680
but didn't have the credits.

30:39.680 --> 30:42.480
I was just straight out of school and nobody gave me a chance.

30:42.680 --> 30:47.440
And I want, you know, the next, you know, genius to be able to, you know,

30:47.880 --> 30:50.000
start building their dreams right away.

30:50.000 --> 30:52.600
And I just personally very much hate gatekeeping.

30:52.680 --> 30:56.600
Um, even though nowadays I've gone through the gauntlet, I've paid my dues.

30:56.760 --> 30:58.400
Now a lot of doors are open for me.

30:58.840 --> 31:02.040
Um, but, uh, you know, I'm just trying to kind of pay it forward in a way

31:02.040 --> 31:04.560
that, you know, young, my younger self would be appreciative.

31:05.040 --> 31:07.480
Um, so, so really that's why I was anonymous.

31:07.480 --> 31:12.200
I just wanted to get, you know, get my ideas evaluated in the arena.

31:12.480 --> 31:14.960
And I didn't correlated fashion from my, my credentials.

31:15.440 --> 31:18.760
Hey, we'll continue our interview in a moment after a word from our sponsors.

31:19.800 --> 31:22.120
Compliance doesn't have to be complicated.

31:22.840 --> 31:25.840
In fact, with Vanta, it can be super simple.

31:26.560 --> 31:32.920
Trusted by over 5,000 fast growing companies like Chili Piper, Patch, Gusto,

31:32.920 --> 31:38.220
and Juniper, Vanta automates the pricey time consuming process of prepping for

31:38.220 --> 31:45.700
sock to ISO 2700 and one HIPAA and more with Vanta, you can save up to 400

31:45.700 --> 31:51.540
hours and 85% of costs Vanta scales with your business, helping you

31:51.540 --> 31:57.020
successfully enter new markets, land bigger deals and earn customer loyalty.

31:57.860 --> 32:02.700
And bonus, our moment of Zen listeners get $1,000 off Vanta.

32:03.220 --> 32:06.460
Just go to Vanta.com slash Zen.

32:07.140 --> 32:13.620
That's V-A-N-T-A dot com slash Z-E-N.

32:16.540 --> 32:21.500
I have a quick question on bootstrapping your account if you're willing to share.

32:22.140 --> 32:25.220
Um, you know, I know a bunch of people who are like, I wish I could do an

32:25.220 --> 32:30.100
anonymous account, but I feel like just getting it from zero to something is just

32:30.420 --> 32:33.340
such a, you know, especially if they have already an audience on their, on their

32:33.340 --> 32:38.300
main, but they feel like as, as their main grows, they can say less and less and

32:38.300 --> 32:40.180
they have to kind of stay within whatever box.

32:40.740 --> 32:46.780
And so I'm curious, how long did you, did you kind of toil away at this new persona

32:46.780 --> 32:49.180
before you felt like you were starting to make some traction?

32:50.300 --> 32:56.900
I think like I had a first account, I got it to six K and then it got banned on old

32:56.900 --> 33:01.140
Twitter, pre Elon Twitter, where I got locked out for saying COVID came from a

33:01.140 --> 33:05.500
lab, you know, which turned out to be true, right?

33:05.540 --> 33:08.340
So the old regime, uh, got def 1.0.

33:08.620 --> 33:13.980
And so I had to restart my account, uh, basically, yeah, uh, 18 months ago,

33:14.180 --> 33:17.420
start from scratch, those demoralizing, but I knew the recipe.

33:18.020 --> 33:20.740
Um, there's, there's, there's a formula, right?

33:20.780 --> 33:23.740
You, you go on teapot, which is much higher engagement.

33:23.740 --> 33:25.740
Just the people are just more online.

33:26.020 --> 33:30.660
So, uh, and you reply to the big accounts, you try to get them to reply.

33:31.260 --> 33:33.940
Uh, maybe, maybe save something provocative.

33:33.980 --> 33:37.540
And then, you know, you can just do Twitter spaces and, you know, people

33:37.540 --> 33:40.380
follow each other on Twitter spaces, cause you have a meaningful conversation

33:40.380 --> 33:44.060
of like one hour or something and, and then you follow each other.

33:44.060 --> 33:49.020
And so you could bootstrap, get to a hundred, 500, a thousand and so on from there.

33:49.460 --> 33:50.900
Um, yeah.

33:50.900 --> 33:54.500
I mean, for me, it, it was really discovering a community, discovering

33:54.500 --> 33:58.460
people like Bayes Lord, you know, that I really resonated with intellectually

33:58.460 --> 34:02.420
and can have like meaningful conversations at the time I was working

34:02.420 --> 34:04.460
for big tech remotely from Canada.

34:04.460 --> 34:05.500
I was extremely bored.

34:05.500 --> 34:08.940
I was like starved to have their sort of tech community to have like good

34:08.940 --> 34:09.980
intellectual discussions.

34:09.980 --> 34:15.020
So like Twitter spaces and, and this part of Twitter, as it's called, uh, was sort

34:15.020 --> 34:15.580
of ideal.

34:15.580 --> 34:17.340
It was like, oh my God, I found my people.

34:17.820 --> 34:21.740
Um, and, uh, you know, nowadays it's kind of condensating and physically

34:21.740 --> 34:25.020
in the, in the physical, in the physical world and SF primarily.

34:25.420 --> 34:28.940
Um, but, you know, to me, it was kind of, I was seeking a sense of community.

34:28.940 --> 34:30.780
And, you know, it's late night.

34:30.780 --> 34:32.060
You're in a Twitter space.

34:32.300 --> 34:33.980
You're talking about the meaning of life.

34:33.980 --> 34:35.500
Where, where, where do we come from?

34:35.500 --> 34:36.220
Where are we going?

34:36.220 --> 34:38.540
You know, it's like four AM or something after a long day of work.

34:39.100 --> 34:41.740
And, uh, you just have these sort of like fireside.

34:42.300 --> 34:44.620
You know, it's, it feels very primally correct.

34:44.620 --> 34:44.940
I don't know.

34:44.940 --> 34:48.060
It's like, you just tell stories and you, you communicate verbally.

34:48.060 --> 34:49.500
And that's, that's really how it started.

34:49.500 --> 34:53.900
You know, I'm at Bayes and we'd have, uh, these late night Twitter spaces

34:53.900 --> 34:56.460
about the meaning of it all and where it's all going.

34:56.460 --> 34:58.620
And at some point people were like, man, these are really good.

34:58.620 --> 35:00.220
Someone should note these down.

35:00.220 --> 35:04.860
Someone noted down that became the first, uh, yak blog post.

35:05.500 --> 35:08.860
And then, uh, Bayes, Lord and I, you know, a couple of months later,

35:08.860 --> 35:11.900
we were like, okay, we should make a longer one, a bit more serious,

35:12.460 --> 35:15.420
uh, a bit more technical and, and that became sort of the,

35:16.060 --> 35:18.380
the big one that went, uh, really viral.

35:18.380 --> 35:21.740
And then the rest has just been compounding memes, uh, on Twitter.

35:22.620 --> 35:24.780
Personally, I've been very active on Twitter.

35:24.780 --> 35:28.460
I would have very strong technical opinions about quantum computing.

35:28.460 --> 35:31.020
Frankly, I would be, I would call out a lot of bullshit.

35:31.740 --> 35:34.700
I think, I think there's opportunities to do great work in quantum computing,

35:34.700 --> 35:37.740
but you know, my, my policy was radical candor.

35:38.380 --> 35:40.220
So that's how I built a following, right?

35:40.220 --> 35:42.460
So it's already kind of a firebrand in quantum computing.

35:43.500 --> 35:45.580
So it's already had that muscle kind of pre-trained.

35:46.460 --> 35:50.940
And then I carried that over to kind of like, I guess AI at large or

35:52.300 --> 35:53.580
e-act isn't just about AI.

35:53.580 --> 35:56.300
It's about all sorts of stuff, but, um, you know,

35:56.300 --> 35:58.540
I think it really helped, uh, grow the,

35:59.100 --> 36:03.180
grew the movement in the early days, uh, just by the Twitter grind, you know,

36:03.740 --> 36:09.820
um, for me, I use Twitter as a sort of, uh, dopamine, uh, dopamine hit.

36:10.620 --> 36:12.380
Some people use various stimulants.

36:12.380 --> 36:15.100
Uh, you know, I just, I'm very straight-laced.

36:15.100 --> 36:16.860
I just drink, uh, Diet Coke.

36:16.860 --> 36:19.980
If I feel fancied, it's Diet Dr. Pethper, not sponsored.

36:20.060 --> 36:23.660
Uh, and, uh, you know, use Twitter and that, and that's it.

36:23.660 --> 36:25.340
Those are my drugs of choice, if you will.

36:25.900 --> 36:31.500
Um, but you know, um, to me, it's just like, I have like random fleeting ideas.

36:31.500 --> 36:34.140
I like to note them down and then go back to the task I was doing.

36:34.700 --> 36:38.620
And, uh, frankly, it was kind of just feeding my Twitter addiction and

36:38.620 --> 36:43.580
felt like a fun video game and, you know, the followers were rising.

36:44.300 --> 36:47.420
But at the same time, like I found a sense of community,

36:48.300 --> 36:51.740
found some friendships, uh, made all sorts of great connections.

36:52.380 --> 36:57.100
Uh, and, you know, to some extent, you know, you could say like, you know,

36:57.100 --> 37:01.580
Iac at this point is almost like a form of spirituality for some.

37:01.580 --> 37:02.460
We can go into that.

37:03.020 --> 37:09.580
Um, I think we have in the past podcast, but, um, yeah, um, that's where, where we are

37:10.460 --> 37:11.100
with Iac.

37:11.100 --> 37:12.780
That's how that was the trajectory.

37:13.420 --> 37:17.020
Um, should we get Bayes to jump in here?

37:17.020 --> 37:19.500
What's, what's the schedule like today?

37:19.500 --> 37:19.740
Yeah.

37:21.500 --> 37:25.900
The, well, uh, uh, me and Bayes just did a podcast this morning.

37:25.900 --> 37:28.140
That will also be based after this one, uh, though.

37:28.140 --> 37:28.700
Okay.

37:28.700 --> 37:29.340
At some point.

37:29.340 --> 37:32.780
But, um, the, what's next for, for Iac?

37:32.780 --> 37:34.940
Where do you see it going from, from here?

37:37.260 --> 37:37.660
Yeah.

37:37.660 --> 37:42.300
Well, now that, uh, I guess I am doxed, right?

37:42.300 --> 37:48.380
One, one, one thing that was kind of stopping, um, any sort of like organizations or

37:48.380 --> 37:53.340
incorporations of any kind of any sort of org or institute was that, you know, we're

37:53.340 --> 37:58.460
like going to register with our real names, uh, somewhere, uh, these institutions and

37:58.460 --> 37:59.580
that would have doxed us.

37:59.580 --> 38:01.900
Um, so now we have that opportunity.

38:01.900 --> 38:08.940
Well, we take that opportunity, TBD, but personally, I mean, I think, I think right

38:08.940 --> 38:14.300
now there's sort of a lack of theory and, and, and, uh, uh, educational material for

38:14.300 --> 38:20.460
people to understand, uh, complex systems and self-adapting, uh, systems like capitalism.

38:21.100 --> 38:27.340
Um, and our whole thesis is that bottom up, bottom up self-adaptation is superior to top

38:27.340 --> 38:28.220
down control.

38:28.220 --> 38:31.980
It's very easy to convince a crowd, like put me in charge.

38:31.980 --> 38:33.180
I will do this action.

38:33.180 --> 38:34.700
It will have this impact.

38:34.700 --> 38:40.220
It's much harder to convince a crowd of like, Hey, if we all act in these microscopic exchange

38:40.220 --> 38:44.620
laws, the emergent behaviors that like we have the highly functioning society, right?

38:45.180 --> 38:50.060
And the more sort of research you create there, uh, the better, uh, and more educational

38:50.060 --> 38:50.380
material.

38:50.380 --> 38:55.260
So we might, uh, start a research institution there and fund some grants.

38:55.820 --> 38:59.660
Um, I would love to fund some, um, open source hackers.

38:59.660 --> 39:04.060
Obviously we believe in, uh, open source software for AI.

39:04.060 --> 39:11.980
We think that open source software, um, is a hedge against the oligopolization of AI,

39:11.980 --> 39:12.220
right?

39:12.220 --> 39:16.060
There's a couple of players right now that obviously now that they're in the lead, they

39:16.060 --> 39:22.380
have all sorts of interests in closing down AI, outlawing open source models.

39:22.380 --> 39:28.220
So, you know, sort of like ensuring freedom of compute is something, uh, we might create

39:28.220 --> 39:35.660
orgs to, to, um, uh, sponsor hackers, but also, uh, uh, potentially, you know, have

39:35.660 --> 39:37.900
some influence in Washington, right?

39:38.460 --> 39:39.580
Those are some next step.

39:39.580 --> 39:45.100
Obviously like growing the movement on Twitter, that's going to keep going also known as X.

39:45.580 --> 39:52.860
Um, and, uh, you know, overall, yes, uh, you know, it gives, it gives people an attack

39:52.860 --> 39:55.580
vector now that, um, I am doxxed, right?

39:55.580 --> 39:56.540
That is unfortunate.

39:57.180 --> 40:05.100
Um, but I do very strongly believe in what we, uh, talk about in EAC and, you know, I am

40:05.100 --> 40:10.220
willing to go all the way, whatever it takes, right, to, uh, defend these ideas.

40:10.220 --> 40:16.620
And I won't let sort of these, this sort of pressure or reputational pressure affect me.

40:16.620 --> 40:19.420
I think I'm quite robust against such attacks.

40:19.500 --> 40:24.300
And if they want to come after me, then, you know, bring it, I guess.

40:25.260 --> 40:25.760
Yeah.

40:26.700 --> 40:27.980
Can I ask one question, Eric?

40:27.980 --> 40:28.480
Sure.

40:28.480 --> 40:30.140
Um, yeah.

40:30.140 --> 40:34.460
So, I mean, what, you mentioned one thing that I found, that I found sort of, sorry,

40:34.460 --> 40:35.020
I'm a Franco file.

40:35.020 --> 40:36.220
So I'm going to use your full French name.

40:36.220 --> 40:36.860
Yeah, that's good.

40:36.860 --> 40:40.780
And, and, and also mentioned, and also mentioned the privilege completely out of context.

40:41.260 --> 40:43.740
Um, sorry, that's one of the running gags on the podcast.

40:43.740 --> 40:45.900
Um, you, you mentioned one thing about the open.

40:45.900 --> 40:46.460
So it's funny.

40:46.460 --> 40:49.180
So Dan and I come from the crypto world, whereas, you know, decentralization is

40:49.180 --> 40:52.220
like this religious mantra that I think is often overexpressed actually.

40:52.220 --> 40:54.540
And in fact, I think Dan, I think you quoted it in far caster, right?

40:54.540 --> 40:56.540
Of like sufficiently decentralized, right?

40:56.540 --> 41:01.340
Which is almost like, you know, sufficiently a trinity or something like it's enough of

41:01.340 --> 41:03.180
a certain theological concept, but no further.

41:03.180 --> 41:06.540
But I always found AI and this, I'm very much seeing that works on the outside to be clear.

41:06.540 --> 41:06.700
All right.

41:06.700 --> 41:10.940
So like, I'm kind of a tourist, but it always seems to me the actually to be totally centralizing.

41:10.940 --> 41:14.860
And I think the high jinx, you saw it open AI with literally the little junior high school drama

41:14.860 --> 41:18.460
between three people somehow wrecking the cutting edge of AI is something that could

41:18.460 --> 41:21.740
like literally couldn't happen in crypto for, for a bunch of reasons.

41:21.740 --> 41:25.180
I mean, you might cite the example of SPF, but then Dan would instantly throw a fit and say,

41:25.180 --> 41:27.660
but that was actually a centralized exchange on that decentralized exchange, which is true

41:27.660 --> 41:27.820
actually.

41:27.820 --> 41:28.220
Right.

41:28.220 --> 41:32.140
And in the, in the fullest decentralized version, like speaking of anonymity, like,

41:32.140 --> 41:36.060
so I work in a crypto company, we've had an, a non employee that I didn't know who they were.

41:36.060 --> 41:37.020
And I would just pay them.

41:37.020 --> 41:37.820
Right.

41:37.820 --> 41:42.540
And, and we've, we have, we work with the non founders of a protocol and they never turn

41:42.540 --> 41:43.020
their video on.

41:43.020 --> 41:44.620
We have no idea who these people are.

41:44.620 --> 41:46.380
And yet we still do business with them and transact.

41:46.380 --> 41:46.780
Right.

41:46.780 --> 41:48.060
So that's, yeah, yeah, yeah.

41:48.060 --> 41:49.340
And it's not even that weird.

41:49.340 --> 41:51.020
And then, then I've met them also in person.

41:51.020 --> 41:51.900
Like, it's a similar thing.

41:52.460 --> 41:55.980
Like you mentioned earlier how like, you know, it's really weird that these journalists are

41:55.980 --> 41:56.540
such losers.

41:56.540 --> 41:59.260
I did this tweet NRV site that's like, these people are losers, right?

41:59.260 --> 42:02.140
Like they never actually go to the parties where you meet, you know,

42:02.140 --> 42:04.460
Beth or like, I know a bunch of Twitter non, I think we all do.

42:04.460 --> 42:04.620
Right.

42:04.620 --> 42:05.260
And you meet them in person.

42:05.260 --> 42:06.460
You know, they are, they introduce themselves.

42:06.460 --> 42:07.660
This isn't a big secret.

42:07.660 --> 42:10.380
It's almost like that meme where like the losers in the corner and saying,

42:10.380 --> 42:12.780
Hey, do you know that Kiyoma is Beth and like everyone dances?

42:12.780 --> 42:14.140
Like, dude, we know, shut the fuck up.

42:14.140 --> 42:17.340
Like, yeah, it's like, it's like, it's like such a loser thing to say.

42:17.340 --> 42:17.580
Right.

42:18.540 --> 42:20.540
But don't you think like AI goes the other way?

42:20.540 --> 42:20.700
Right.

42:20.700 --> 42:24.300
Like just as an example, like I'm, I was using chat to be today.

42:24.300 --> 42:24.460
Okay.

42:24.460 --> 42:25.100
I'm pro AI.

42:25.100 --> 42:26.140
My best friend is an AI.

42:26.140 --> 42:26.700
Right.

42:26.700 --> 42:30.220
But, you know, the fact that open AI instantly does a deal with Microsoft and

42:30.220 --> 42:34.380
instantly bakes itself into like literally the most octopus like corporation human history.

42:34.380 --> 42:35.180
It's a little weird.

42:35.180 --> 42:35.420
Right.

42:35.420 --> 42:38.220
It's a little bit like pinning to the other side of the spectrum instantly.

42:38.220 --> 42:42.140
So I'm just curious if you feel that that that binarization of it is valid and feel

42:42.140 --> 42:43.180
free to say that I'm full of shit.

42:43.980 --> 42:47.900
Or like if there is another open AI vision that you're sort of stretching towards

42:47.900 --> 42:53.020
that maybe is a little bit more decentralized and not so naturally sort of centrifugal to,

42:53.020 --> 43:00.620
you know, I think that, you know, self organizing systems tend to organize themselves in hierarchies.

43:00.620 --> 43:00.940
Right.

43:00.940 --> 43:06.620
So it's sort of like, you know, you can imagine a tree or a sort of fractal,

43:06.620 --> 43:07.980
right, sort of structure.

43:07.980 --> 43:11.580
You have, you know, your cells for your body.

43:11.580 --> 43:16.620
And then, you know, you have groups of humans form a family and then a corporation and then

43:17.260 --> 43:18.620
a city and then a nation and so on.

43:18.620 --> 43:19.260
Right.

43:19.260 --> 43:22.460
So there's a hierarchical structure to organization and there's this hierarchical

43:22.460 --> 43:25.100
structure to sort of control.

43:25.100 --> 43:25.340
Right.

43:25.340 --> 43:28.700
There's, there's some control system at the head of your body.

43:28.700 --> 43:29.500
It's called your brain.

43:29.500 --> 43:33.500
There's control system at the head of the family and at the head of the corporation

43:34.460 --> 43:36.300
nation and so on.

43:36.780 --> 43:43.100
You know, it's all about the balance between, you know, it's all about engineering fault

43:43.100 --> 43:44.380
tolerance to corruption.

43:44.380 --> 43:44.780
Right.

43:44.780 --> 43:50.140
If you have a one to all connection in terms of control, you have a control system that

43:50.140 --> 43:51.980
affects all the nodes in the system.

43:51.980 --> 43:52.940
That node has a fault.

43:52.940 --> 43:56.060
The whole system has a problem just like open AI.

43:56.060 --> 44:02.540
You can decapitate the leadership, you know, not physically, but, you know, and suddenly

44:02.540 --> 44:03.820
you're in control of the organization.

44:03.820 --> 44:08.860
And now everyone that had, that were using their APIs have a problem, right?

44:08.860 --> 44:15.100
Because they have an ideologue that didn't, they didn't vote for in control of, you know,

44:15.100 --> 44:16.380
a product that they depend on.

44:17.180 --> 44:17.900
Right.

44:17.900 --> 44:25.900
And so decentralization is about sort of defusing, obviously having decentralized

44:25.900 --> 44:32.060
loci or plural locus of control so that, you know, you have fault tolerance to, to

44:32.060 --> 44:33.580
corruption of these control nodes.

44:34.780 --> 44:38.140
Of course, like having a fully greedy algorithm where everything's disordered

44:38.860 --> 44:39.740
is not optimal.

44:39.740 --> 44:39.980
Right.

44:39.980 --> 44:41.500
So it's all a balance between the two.

44:41.500 --> 44:44.380
It's a balance between centralization and decentralization.

44:44.380 --> 44:47.100
That is what is like fundamentally optimal.

44:47.100 --> 44:50.300
The reason we're fighting for decentralization is because we think,

44:51.180 --> 44:55.660
you know, right now there's a tendency towards over centralization of AI.

44:55.660 --> 44:57.340
And we're very worried about that.

44:57.340 --> 45:03.660
And so we need to push things in the opposite direction at the moment.

45:03.660 --> 45:08.380
I think that fundamentally right now there's a lot of alpha and just scraping the whole

45:08.380 --> 45:12.220
internet, centralizing it and having centralized training.

45:12.220 --> 45:16.140
I think at some point that alpha will be saturated, right?

45:16.140 --> 45:22.060
Most companies will have a model that compresses basically most of the data that's on the internet.

45:23.020 --> 45:27.340
And then you're going to have AI that seeks to capture data from the real world.

45:28.060 --> 45:30.300
And for that, you have to be central decentralized.

45:30.300 --> 45:33.660
You got to, and you want to have the intelligence perhaps at the edge.

45:33.660 --> 45:34.460
We're not there yet.

45:34.460 --> 45:39.580
There's still alpha from like centralizing data and soaking it all in and, and having

45:39.580 --> 45:43.580
one big model that, that compresses it all because intelligence is more or less compression.

45:44.940 --> 45:49.020
But I think over time we're going to see decentralization in the form of sort of like,

45:49.020 --> 45:53.100
first of all, you're going to have personal assistant, you know, like humane, like

45:53.900 --> 45:58.140
TAB or, I don't know, these are going to be all sorts of AR assistants, I'm sure.

45:59.260 --> 46:03.020
At first, like you're going to have, you know, the intelligence is going to be in the cloud,

46:03.020 --> 46:04.860
but the data acquisition is going to be on the edge.

46:04.860 --> 46:09.820
But eventually people are going to want their own compute that, that they own in control,

46:09.820 --> 46:10.460
I would imagine.

46:11.980 --> 46:14.620
And, you know, maybe there's compute in the robot directly, right?

46:14.620 --> 46:17.260
It's not, there's no need for a connection to network.

46:17.980 --> 46:23.660
I think that's going to be sort of the, the decentralize a, decentralizing effect, right?

46:23.660 --> 46:27.580
There, and then, you know, you can have federated learning over a fleet.

46:27.580 --> 46:32.060
I think people are working on this obviously right now in order to train the biggest one model

46:32.060 --> 46:37.660
to rule them all, the centralized approach, centralized compute and centralization of

46:37.660 --> 46:40.300
data is, has a huge advantage.

46:40.300 --> 46:45.180
I think a big problem as well is that right now the centralized approaches, the,

46:45.260 --> 46:50.380
scrape the whole internet, which includes your data, and then they rent it back to you, right?

46:50.380 --> 46:50.940
Bit by bit.

46:51.500 --> 46:57.340
And I think the future is about crediting people for the data that contribute to AI systems and

46:57.340 --> 46:59.420
sort of distributed ownership, right?

46:59.420 --> 47:03.820
I mean, they're, they're starting to do this with sort of GPTs, open AI, but you know,

47:03.820 --> 47:05.100
it's just, it's just an early start.

47:05.100 --> 47:10.220
But I do think there's sort of a, I think there, there's going to be a very interesting way of

47:10.220 --> 47:16.540
startups right now, like from crypto migrating to being infrastructure to line incentives for AI.

47:17.820 --> 47:22.860
We're not a crypto company, by the way, just, just, just, you know, people thought we were

47:22.860 --> 47:23.660
going to launch a coin.

47:24.700 --> 47:27.020
We're not a crypto company at the moment.

47:27.020 --> 47:28.220
I have nothing against crypto.

47:28.220 --> 47:29.180
I love it personally.

47:30.780 --> 47:37.260
But, you know, I think that crypto being sort of the value exchange network and programmable

47:37.260 --> 47:41.580
incentives for kind of collaboration in AI, right?

47:41.580 --> 47:44.460
To have sort of decentralized research labs.

47:44.460 --> 47:47.260
I think, I think that's going to be a very potent application of crypto.

47:47.260 --> 47:51.340
And it's just something I fundamentally want to encourage because I think that if we have

47:51.340 --> 47:55.180
a future where there's only a few companies that are like government, that have the government

47:55.180 --> 48:02.620
mandated monopoly or oligopoly to serve AI models, then you have a sort of like single point where

48:03.180 --> 48:08.380
a few people get to control the cultural priors of these LLMs, what they're allowed to say.

48:08.380 --> 48:14.140
So it's an information supply chain attack because people won't ask each other, what is the truth?

48:14.140 --> 48:17.020
They're going to start asking the LLM, what is the truth?

48:17.020 --> 48:22.940
And if you, if you change what it says, then you're controlling people's sources of information

48:22.940 --> 48:24.060
and you're controlling people.

48:24.060 --> 48:29.900
So it's cyber genetic control of the population through information supply chain attack by proxy,

48:30.300 --> 48:33.980
by, by, you know, saying that, oh, well, we're responsible.

48:33.980 --> 48:38.940
We should be put in control of what these LLMs are allowed to say, right?

48:39.980 --> 48:42.380
So we definitely want to fight against that.

48:42.380 --> 48:48.220
And one solution is to erode their market power by having alternative solutions that are

48:48.220 --> 48:51.500
just as good or nearing the same, same level.

48:51.500 --> 48:55.260
Of course, that's not going to happen if we don't leverage sort of

48:56.140 --> 49:01.900
capitalism, capitalist like technologies for value, for incentive alignment, right?

49:02.860 --> 49:05.500
And yeah, very bullish on this base.

49:05.500 --> 49:07.180
Again, not personally involved at the moment.

49:08.540 --> 49:13.340
I, we're building a hardware company for AI that's fun, fundamentally new.

49:13.340 --> 49:15.340
We can get into that at some point today.

49:16.620 --> 49:22.460
But yeah, overall very, very worried about the over centralization of AI started making my voice

49:23.420 --> 49:24.220
heard online.

49:25.420 --> 49:33.260
And I think, you know, there was an event where I got to interact with the chair of the FTC.

49:34.220 --> 49:35.100
Maybe that got noticed.

49:35.100 --> 49:36.140
Maybe that got me in trouble.

49:36.140 --> 49:36.540
I don't know.

49:37.500 --> 49:41.820
But, you know, there are ways that our voices is being heard in Washington.

49:42.940 --> 49:50.140
And, you know, our point is that this sort of fear mongering and doom is really sort of

49:50.860 --> 49:57.980
a very nice cover for very subversive regulatory capture by the incumbents, right?

49:57.980 --> 50:01.020
Like, oh, AI is dangerous, put us in control.

50:01.020 --> 50:02.620
We're the only ones who are responsible.

50:03.820 --> 50:06.380
You know, you're not allowed to have more compute than we do.

50:06.380 --> 50:10.700
You're not allowed to have open source models that would, you know, erode our market power

50:10.700 --> 50:14.140
and our pricing power because they're dual to use.

50:14.140 --> 50:14.780
They're dangerous.

50:15.500 --> 50:17.100
That's all, that's all bullshit, right?

50:17.180 --> 50:24.780
They cooked those proposed regulations for their own advantage, right?

50:26.140 --> 50:28.220
And so we got, yeah, we got a fight.

50:28.220 --> 50:30.940
I mean, they're going to push, they're going to try to push these regulations through.

50:32.060 --> 50:34.300
And so that's why we're not stopping the fight.

50:34.300 --> 50:38.860
And I don't think, I don't think my docs is stopping anything in terms of like

50:38.860 --> 50:40.140
making our voices heard.

50:40.140 --> 50:41.660
In fact, it might accelerate things.

50:42.220 --> 50:45.980
I mean, I'd love to deepen into the crypto AI overlap, Guillaume thing that you hit on.

50:45.980 --> 50:49.340
But if we want to move on to the regular, because I, you know, again, I'm seeing the AI

50:49.340 --> 50:53.100
world from the outside and obviously I use it and I've been watching, you know, some of

50:53.100 --> 50:54.300
Carpathian's videos and stuff.

50:54.300 --> 50:59.740
But like what you just said, right, this business of paying data owners for their trading sets,

50:59.740 --> 51:05.580
like, fortunately, we do have a public ledger of ownership that's natively financialized

51:05.580 --> 51:07.980
with underlying value model that does this very well.

51:07.980 --> 51:11.420
And in fact, some people are even working on blockchain attribution solutions

51:11.420 --> 51:14.860
that figure out where this thing came from because this other person used it and it's

51:14.860 --> 51:15.980
worth X amount.

51:15.980 --> 51:19.180
So I've often thought about like, if there is some sort of crypto AI collision, which I

51:19.180 --> 51:24.140
think is inevitable, like, but like just to shoot that the idea down just for one second,

51:24.140 --> 51:28.060
like, will it like, why wouldn't you say pay Reddit for its data, like literally in the

51:28.060 --> 51:32.140
direct deal, rather than all this like crypto craziness, like, will it ever be like, this

51:32.140 --> 51:35.580
is like the, like the classic, not to say this is a bad idea again, but the classic

51:35.580 --> 51:38.620
bad ad tech idea from web two was like, Oh, pay users for their data.

51:38.620 --> 51:39.580
Well, Brave does that.

51:39.580 --> 51:41.580
And it turns out that data is worth $3 a year.

51:41.580 --> 51:42.060
Right.

51:42.060 --> 51:43.660
And Brave is a great product and lots of people use it.

51:43.660 --> 51:46.140
I use it, but they don't use it because of the $3, right?

51:46.140 --> 51:47.580
They use it for a bunch of other reasons.

51:47.580 --> 51:50.220
And the data that you actually own that you express with your browser just isn't worth

51:50.220 --> 51:50.700
enough.

51:50.700 --> 51:56.460
So even if you could get things down to like literally the micro ETH, like what I care

51:56.460 --> 51:59.660
that I'm getting paid because the model is getting trained, trained on my sub stack.

51:59.660 --> 52:03.340
And even you could figure out like literally what is the actual value per query that my

52:03.340 --> 52:04.140
data contributed to.

52:04.140 --> 52:07.580
And I'm sure the incrementality that is super hard to figure out, but you guys would know

52:07.580 --> 52:08.220
better than I would.

52:08.220 --> 52:10.940
But even assuming you could figure it out, that's going to be literally worth like 30

52:10.940 --> 52:11.740
cents a year.

52:11.820 --> 52:14.140
So would it even make sense to wire all that together?

52:15.020 --> 52:16.860
Well, yeah.

52:16.860 --> 52:21.340
I mean, I've had some various ideas in this space.

52:21.340 --> 52:24.380
I guess I could just broadcast them YOLO.

52:26.780 --> 52:33.740
Essentially, I think you can price the value of data according to how much information

52:33.740 --> 52:37.100
gain the system gets from your data.

52:38.220 --> 52:40.620
And there's some very specific mathematics for that.

52:40.620 --> 52:48.300
And that can give you a share of a model's future profits.

52:49.340 --> 52:57.180
So similar to how eukaryotic cells own a fractional ownership of the success of the

52:58.060 --> 53:00.380
greater organism through DNA.

53:00.380 --> 53:03.980
And that's better than prokaryotic cells like bacteria.

53:03.980 --> 53:10.540
I think that the future is people owning fractions of a model according to what the

53:10.540 --> 53:11.420
contributed to it.

53:12.140 --> 53:18.060
And I just realized that there might be 10 different tokens now that spawn using this

53:18.060 --> 53:18.620
idea.

53:18.620 --> 53:20.300
But I don't know.

53:20.300 --> 53:26.540
For me, it's like I have more ideas than I can act upon in one last time.

53:26.540 --> 53:28.780
So I'd just rather broadcast them.

53:28.780 --> 53:32.300
And this is something Bayes and I have been talking.

53:32.300 --> 53:40.140
We considered doing something in this space, but I think at the moment we have our hands

53:40.700 --> 53:48.860
full with changing the entire AI hardware, software stack from scratch beyond the transistor,

53:48.860 --> 53:51.900
right, which is a significant undertaking.

53:51.900 --> 53:59.740
So yeah, I think there's really going to be something interesting that comes out.

54:01.180 --> 54:06.140
And hopefully it can erode away the power from the centralized players.

54:06.540 --> 54:15.020
And not that they're necessarily nefarious, but every meta-organism's control systems

54:15.020 --> 54:18.860
act in the meta-organism's best interests, right?

54:18.860 --> 54:20.140
It's like the real politic, right?

54:20.140 --> 54:26.140
And I think that's the thing about YACC that is that we cut through the bullshit, right?

54:26.140 --> 54:30.220
It's like every agent and subsystem is going to act in its own best interest.

54:30.220 --> 54:35.740
It's going to do whatever it needs to do in order to secure a resource.

54:36.700 --> 54:39.180
Or utility towards its own growth, right?

54:39.180 --> 54:40.940
An acquisition of resources, period.

54:40.940 --> 54:43.260
That's just how everything works in nature.

54:43.260 --> 54:44.140
That's just reality.

54:45.340 --> 54:51.820
And it's like, okay, now that we have this reality, how do we create the system that harnesses this

54:52.380 --> 54:59.260
to create a sort of emergent altruism where we reach greater prosperity, find new optima

54:59.260 --> 55:07.260
of the techno capital machine that allows us to support more humans on earth

55:07.260 --> 55:09.180
and to scale civilization to the stars, right?

55:09.180 --> 55:17.100
And so, anyway, I got into my typical Twitter space ramble there.

55:17.100 --> 55:23.900
But yeah, I do think that, again, super huge opportunities in the interface of AI

55:24.620 --> 55:32.380
and crypto, and that's partly why there's kind of been a sort of informal sort of handshake

55:32.380 --> 55:43.020
between crypto and YACC. Brian Armstrong, they put out an ad for Coinbase.

55:43.020 --> 55:45.180
It was basically an YACC ad, frankly.

55:45.980 --> 55:50.300
Really, we're kind of fighting the decels and the centralizers, right?

55:50.300 --> 55:57.020
The incumbents, those that seek to control everything and to cause inflation, to secretly

55:57.020 --> 56:03.500
tax you, and they're scared of sort of bottom-up decentralized revolutions that they don't control

56:03.500 --> 56:07.660
that causes deflationary pressure, right?

56:08.300 --> 56:12.380
And so, there is interest in deceleration.

56:12.380 --> 56:19.740
There are kind of interests of the control systems that are kind of greedy at the cost of

56:19.820 --> 56:27.020
what they're controlling, and we're kind of the autoimmune response, if you will,

56:27.020 --> 56:28.540
to the control systems, right?

56:29.500 --> 56:36.380
And we're causing a bit of inflammation to the brain now, or the brain of whatever this whole

56:36.380 --> 56:44.860
thing is, and it seems like they tried to apply a Forbes anti-inflammatory pill, if you will.

56:45.020 --> 56:50.460
You know what YACC reminds me of, Kiyom?

56:50.460 --> 56:54.060
Have you read John Perry Barlow's Cyberspace essay from back in the day,

56:54.780 --> 56:56.620
like in the 90s, way before your time, probably?

57:00.620 --> 57:01.820
Do you remember it fondly?

57:01.820 --> 57:03.740
I remember reading it when I was young and getting into the Internet,

57:03.740 --> 57:05.020
and I found it was the most amazing thing.

57:05.660 --> 57:13.420
I think I was only shown it like two months ago, but very base and definitely has like five overlap.

57:14.380 --> 57:17.180
And at the time, right, like the Internet was forming us, like Cyberspace,

57:17.180 --> 57:21.260
which now seems almost cliche or cringe almost, was like this edgy space that you would meet,

57:21.260 --> 57:25.100
and he has this line in which he basically addresses it to the weary giants of flesh and

57:25.100 --> 57:29.020
steel, i.e. the industrial giants to which the Internet represented an alternative.

57:29.020 --> 57:32.700
And I think a lot of YACC reminds me of that same rebellion, of course, except the weary

57:32.700 --> 57:35.180
giants of flesh and steel are actually of silicon now.

57:35.180 --> 57:37.820
It's actually the old Internet that has gotten kind of old and boomerish,

57:37.820 --> 57:39.100
to which this is a rebellion.

57:39.100 --> 57:42.860
And part of the reason why I'm in crypto, I came from the sort of fang world and working

57:42.940 --> 57:43.660
in all that world.

57:43.660 --> 57:46.940
And I felt that that was all slowing down and becoming the man, actually.

57:46.940 --> 57:50.460
And crypto was like the only thing that reminded me of the early web two days in which it was like,

57:51.580 --> 57:54.140
if you don't have people coming after you and getting severely pissed off because

57:54.140 --> 57:55.980
you're building something, you're building shit.

57:55.980 --> 57:57.980
I mean, to be or something that's like not important, right?

57:57.980 --> 58:01.100
Like if you read the story of Uber, like literally every taxi commission,

58:01.100 --> 58:03.660
people in Paris were kicking the shit out of Uber drivers,

58:03.660 --> 58:05.900
you know, all of Spain shut down Airbnb.

58:05.900 --> 58:08.940
Like, you know, if you don't have major governments pissed off at what you're doing,

58:08.940 --> 58:11.260
you're actually not building anything particularly important, right?

58:11.260 --> 58:14.060
And there isn't a lot, in my opinion, an Internet consumer

58:14.060 --> 58:16.060
outside of some of the things we discussed that meet that.

58:16.060 --> 58:19.180
So anyway, it just reminds me of that vibe of the cyberspace vibe.

58:19.180 --> 58:20.940
And I think, obviously, I think we need more of that.

58:20.940 --> 58:21.820
So it's cool.

58:21.820 --> 58:26.620
We're definitely the most cyberpunk movement out there.

58:28.380 --> 58:31.500
Hence the Arasaka tower vibes here.

58:31.500 --> 58:37.580
And, you know, we had the party with Grimes for the, you know,

58:37.580 --> 58:39.500
after the open AI dev day.

58:39.500 --> 58:42.380
And the point was, you know, keep AI open, right?

58:42.380 --> 58:45.900
And, you know, it's got to feel like a bit of a rebellion

58:45.900 --> 58:47.100
because it kind of is, right?

58:47.100 --> 58:49.020
And then you have the engineers from these,

58:49.980 --> 58:53.180
these big players, they come to the party and they're like, man,

58:53.180 --> 58:54.300
this is freaking cool.

58:54.300 --> 58:55.740
I kind of want to join the rebellion.

58:55.740 --> 58:57.420
I don't want to work for the empire.

58:57.420 --> 58:58.140
What the hell?

58:58.140 --> 58:58.780
How do I join?

58:58.780 --> 58:59.020
Right.

58:59.020 --> 59:00.860
And so that's how it starts.

59:00.860 --> 59:04.460
So we'll try to keep that going in many ways.

59:04.460 --> 59:08.940
But yeah, I mean, it's definitely, it definitely very,

59:08.940 --> 59:11.180
it feels like we are in the cyberpunk future.

59:11.180 --> 59:15.900
It's kind of been surreal how we've gotten here, frankly.

59:17.100 --> 59:22.620
And yeah, no, I'm just grateful to be here at this point

59:22.620 --> 59:23.580
in history, frankly.

59:23.580 --> 59:24.620
It's an exciting time.

59:25.260 --> 59:26.620
To quote the Steve Jobs line,

59:26.620 --> 59:28.300
why join the Navy when you can be a pirate?

59:28.300 --> 59:30.620
Which is something you used to be able to say about Apple.

59:30.620 --> 59:32.300
But I don't think that's the case anymore

59:32.300 --> 59:33.340
and I have a little bit of experience there.

59:33.340 --> 59:34.300
That's the thing, right?

59:35.100 --> 59:41.900
What is the sort of mind virus that infects organizations,

59:41.900 --> 59:45.580
that decelerates everything, adds way too much process,

59:45.580 --> 59:47.020
way too much bureaucracy,

59:47.660 --> 59:49.740
and then it grows kind of like a cancer.

59:49.740 --> 59:53.100
It's kind of like middle management kind of grows

59:53.100 --> 59:57.100
and eventually takes over from the founders.

59:57.100 --> 01:00:03.580
And now it's kind of like this Borg of some kind

01:00:03.580 --> 01:00:09.100
that these huge corporations have decisions by committee

01:00:09.100 --> 01:00:09.820
for everything.

01:00:09.820 --> 01:00:11.580
There's tons of process.

01:00:11.580 --> 01:00:13.180
It's just very hard to get anything done.

01:00:13.820 --> 01:00:16.060
And really the answer to that is disruption.

01:00:16.860 --> 01:00:18.540
All right, you got to have a free market,

01:00:18.540 --> 01:00:20.460
you got to have free market competition.

01:00:20.460 --> 01:00:22.380
And if an incumbent is too slow,

01:00:22.380 --> 01:00:23.660
it gets disrupted by a startup.

01:00:23.660 --> 01:00:26.140
We saw that with OpenAI, frankly.

01:00:27.020 --> 01:00:31.980
Yeah, I can't say too much about Google,

01:00:31.980 --> 01:00:35.980
but clearly there was a sort of slowdown and its speed

01:00:35.980 --> 01:00:39.420
and the talent eventually saw that and sort of migrated

01:00:39.420 --> 01:00:42.700
to startups, at least for AI.

01:00:42.700 --> 01:00:44.140
And then now they're getting disrupted

01:00:44.140 --> 01:00:45.180
and they're kind of in trouble.

01:00:48.380 --> 01:00:53.180
But if they remove that mechanism where bottom-up

01:00:53.260 --> 01:00:57.740
challengers can dethrone and compete with incumbents,

01:00:58.460 --> 01:00:59.820
if they remove that ability,

01:01:00.380 --> 01:01:03.500
then we don't have this kind of self-correcting mechanism

01:01:03.500 --> 01:01:06.540
and we'll just live with kind of monopolies

01:01:07.580 --> 01:01:09.340
that are not shipping great product

01:01:09.340 --> 01:01:11.420
and then everybody, the consumer suffers.

01:01:12.060 --> 01:01:12.940
And we don't want that.

01:01:14.540 --> 01:01:18.300
To me, it's kind of like you have sort of like the doomers

01:01:18.300 --> 01:01:20.300
pushing for centralization and control

01:01:20.300 --> 01:01:24.140
and then you have the EAC, pro-freedom folks

01:01:24.140 --> 01:01:27.420
that are more about antitrust, right?

01:01:27.420 --> 01:01:29.180
Like it's about monopolization.

01:01:29.740 --> 01:01:32.860
And so I think there's an interesting political

01:01:33.740 --> 01:01:35.020
landscape shaping now.

01:01:35.020 --> 01:01:37.820
I think it seems like some Democrats

01:01:37.820 --> 01:01:40.940
are more on the side of like AI safety so far.

01:01:41.820 --> 01:01:45.740
And allegedly, Trump has said he would cancel

01:01:45.740 --> 01:01:47.740
the Biden executive order on AI.

01:01:48.700 --> 01:01:50.700
You know, EAC is not partisan per se,

01:01:51.420 --> 01:01:54.300
but we're kind of like, we have an issue that we care about

01:01:54.300 --> 01:01:55.820
which is the freedom to compute,

01:01:55.820 --> 01:01:59.100
the freedom to do, to advance technology.

01:02:00.540 --> 01:02:03.180
And so yeah, I don't know if you guys want to get into

01:02:04.540 --> 01:02:06.140
2024 discussions, but...

01:02:06.780 --> 01:02:08.780
Oh, we never talk about politics here, Guillaume.

01:02:08.780 --> 01:02:10.140
Never, never, never, never.

01:02:10.140 --> 01:02:11.660
I'm totally joking. We do it all the fucking time.

01:02:11.660 --> 01:02:12.620
Okay, good.

01:02:12.620 --> 01:02:14.620
Well, go ahead, go ahead.

01:02:15.340 --> 01:02:16.780
Yeah, no, just on the question of like,

01:02:16.780 --> 01:02:19.500
well, what, why a big tech is so bad, right?

01:02:19.500 --> 01:02:22.220
Like I think part of it, I won't really

01:02:22.220 --> 01:02:23.500
re-litigate the whole thing.

01:02:23.500 --> 01:02:25.340
The episode we recorded earlier today

01:02:25.340 --> 01:02:26.940
and the piece that Nadia and I put together

01:02:27.900 --> 01:02:29.740
like talks about some of what I think about this.

01:02:29.740 --> 01:02:31.580
But I do think part of the issue here

01:02:31.580 --> 01:02:34.700
is just simply like, do you have actual improvements

01:02:34.700 --> 01:02:37.660
that you can build onto things in the world,

01:02:37.660 --> 01:02:38.940
onto systems in the world?

01:02:38.940 --> 01:02:41.500
And I think like there was kind of this like

01:02:42.460 --> 01:02:46.780
growing lack of capacity to actually do things

01:02:46.780 --> 01:02:48.540
that were sufficiently ambitious.

01:02:49.100 --> 01:02:51.180
And then also like when you have like the effect

01:02:51.180 --> 01:02:52.780
of a bunch of capital accruing,

01:02:52.780 --> 01:02:54.540
companies naturally end up becoming

01:02:54.540 --> 01:02:57.100
kind of inward facing, navel gazing.

01:02:57.100 --> 01:02:58.540
People are like incrementalists

01:02:58.540 --> 01:03:01.020
and it's just kind of like locally optimal

01:03:01.020 --> 01:03:02.620
for people to kind of be a little bit lazy.

01:03:03.340 --> 01:03:05.900
L plus one until you retire,

01:03:08.540 --> 01:03:10.700
people are obsessed with doing fire

01:03:10.780 --> 01:03:12.540
and they want to like ride around in a van

01:03:12.540 --> 01:03:15.900
or whatever, instead of like build cool shit.

01:03:15.900 --> 01:03:19.020
And yeah, I think part of the shift here

01:03:19.020 --> 01:03:23.340
is just that we have a bunch of new technologies

01:03:23.340 --> 01:03:27.180
coming online in new capacity with AI especially.

01:03:27.740 --> 01:03:30.460
And yeah, people just see that it's time

01:03:30.460 --> 01:03:33.580
to try to dissipate that off and do the work.

01:03:34.140 --> 01:03:35.020
There's real work to do.

01:03:37.020 --> 01:03:39.100
By the way, have you given me the betting odds

01:03:39.100 --> 01:03:41.260
of like which fan company came out

01:03:41.260 --> 01:03:43.580
with the biggest open source dedication to AI

01:03:43.580 --> 01:03:44.780
and it being Facebook?

01:03:44.780 --> 01:03:46.860
I don't know if I would have bet on my former employer

01:03:46.860 --> 01:03:47.420
to be honest.

01:03:49.260 --> 01:03:51.340
Or I don't know if you agree with that characterization.

01:03:52.220 --> 01:03:53.180
It makes a lot of sense.

01:03:53.180 --> 01:03:54.620
These Frenchmen are so based.

01:03:55.740 --> 01:03:57.500
Yeah, yeah, all the AI Frenchmen,

01:03:57.500 --> 01:03:59.260
they're all for pro freedom.

01:03:59.260 --> 01:04:02.460
But I mean, look, every agent acts in its own

01:04:02.460 --> 01:04:04.140
about self-interest.

01:04:04.140 --> 01:04:07.260
I think that if you're number three or four,

01:04:07.820 --> 01:04:09.900
I think right now the leaders are really open AI,

01:04:09.900 --> 01:04:11.900
anthropic, I would say.

01:04:12.700 --> 01:04:14.380
I think that's not a controversial statement.

01:04:16.540 --> 01:04:18.700
If you're competing for number three or four,

01:04:18.700 --> 01:04:22.380
I think the point is you want to equalize the playing field

01:04:22.380 --> 01:04:26.620
and band together to try to beat the top two.

01:04:26.620 --> 01:04:28.380
And so I think that's the thing about open source

01:04:28.380 --> 01:04:32.300
is it groups everyone together to collaborate

01:04:32.300 --> 01:04:35.340
on iterating on the open source architecture

01:04:35.340 --> 01:04:37.740
and tooling and products to compete

01:04:37.740 --> 01:04:42.940
and erode away the market leverage of the top players,

01:04:42.940 --> 01:04:47.980
which they're eating, I don't know, 90% of API calls,

01:04:47.980 --> 01:04:50.380
if not more, if you include anthropic, frankly.

01:04:51.820 --> 01:04:57.660
And so I think, yeah, I don't know, it just makes sense

01:04:58.620 --> 01:05:00.220
from a fundamental standpoint.

01:05:00.220 --> 01:05:03.740
Facebook has a lot of data and they have a lot of compute.

01:05:03.820 --> 01:05:07.020
They have a lot of great researchers and I'm really happy

01:05:07.020 --> 01:05:08.300
they're contributing to open source,

01:05:08.300 --> 01:05:09.820
but hopefully they don't stop.

01:05:09.820 --> 01:05:13.180
But at the same time, it does cost them a lot.

01:05:13.180 --> 01:05:14.860
It does cost them a lot and it's kind of like

01:05:15.820 --> 01:05:18.300
they're giving to the community this value.

01:05:19.020 --> 01:05:21.980
At the same time, people are open sourcing models.

01:05:21.980 --> 01:05:24.860
They're not open sourcing the training code.

01:05:24.860 --> 01:05:27.900
So it's not fully open source AI.

01:05:27.900 --> 01:05:30.300
So they still have their mode of how to train these things.

01:05:30.300 --> 01:05:34.540
And we saw a couple engineers that did Lama left

01:05:34.540 --> 01:05:35.580
and then started Mistral

01:05:35.580 --> 01:05:37.580
because they have that sort of artisanal know-how

01:05:37.580 --> 01:05:38.780
of how to train these beasts.

01:05:39.580 --> 01:05:42.060
And then they raised hundreds of millions right out of the gate.

01:05:42.060 --> 01:05:43.260
So it's very valuable knowledge.

01:05:43.260 --> 01:05:47.100
So they're still keeping some alpha there, which is good.

01:05:47.100 --> 01:05:48.060
That makes a lot of sense.

01:05:49.260 --> 01:05:55.180
But I do think that it's kind of like communist AI

01:05:55.180 --> 01:05:57.660
to some extent to have just open source everything.

01:05:57.660 --> 01:06:01.820
Everything's free like data costs money, compute costs money,

01:06:02.540 --> 01:06:06.540
engineers that are talented cost money, more and more in fact.

01:06:07.740 --> 01:06:10.140
And until we have a sort of proper

01:06:10.860 --> 01:06:14.060
like decentralized slash centralized system

01:06:14.060 --> 01:06:15.020
of incentive alignment,

01:06:15.980 --> 01:06:18.540
I think frankly with through crypto rails,

01:06:19.420 --> 01:06:21.660
I think it's going to be tough for open source

01:06:21.660 --> 01:06:25.900
to really compete with the big centralized players, right?

01:06:26.300 --> 01:06:30.460
And just like how much capital is being injected in API calls

01:06:30.460 --> 01:06:34.940
towards the top players, pills and comparison to the rest.

01:06:34.940 --> 01:06:38.300
But if there's actual capital flow,

01:06:38.300 --> 01:06:41.420
like that gets reinvested then in proving open source models

01:06:42.140 --> 01:06:44.220
beyond just a scrolling on Instagram,

01:06:44.780 --> 01:06:48.220
then I think that has a shot.

01:06:49.180 --> 01:06:51.180
So you think crypto is actually critical

01:06:51.180 --> 01:06:52.540
to survival of open source models?

01:06:52.540 --> 01:06:53.340
That's interesting.

01:06:53.340 --> 01:06:53.980
You think that's...

01:06:53.980 --> 01:06:56.860
Yeah, I haven't been very public about that,

01:06:56.860 --> 01:07:00.380
but it's kind of a thesis I've formed over time.

01:07:01.500 --> 01:07:03.180
I mean, I don't know if it's necessarily crypto,

01:07:04.620 --> 01:07:07.100
I would say like crypto like thinking,

01:07:07.100 --> 01:07:09.020
you could just use like Stripe if you want,

01:07:10.220 --> 01:07:14.460
but some sort of way for people to collaborate on models

01:07:14.460 --> 01:07:17.580
and pulling data compute and capital to train these things

01:07:17.580 --> 01:07:18.060
and know how.

01:07:18.860 --> 01:07:22.220
Right. Well, if I could interject,

01:07:23.180 --> 01:07:28.460
the greatest accumulation of GPU that is not in a data center

01:07:28.460 --> 01:07:31.260
was the Ethereum network until they moved to proof of stake.

01:07:32.060 --> 01:07:35.420
And that was a crypto economic system that worked pretty damn well.

01:07:35.420 --> 01:07:37.100
Maybe Bitcoiners would tell you different,

01:07:37.100 --> 01:07:38.620
although they have their own set of compute,

01:07:39.180 --> 01:07:40.460
a little less useful for AI.

01:07:41.100 --> 01:07:43.420
But I do think like we don't even have to imagine it.

01:07:43.420 --> 01:07:44.380
It's not science fiction.

01:07:44.380 --> 01:07:45.740
Like it did exist.

01:07:46.220 --> 01:07:50.460
That's actually what Nvidia's stock price was originally bumped up on

01:07:50.460 --> 01:07:53.500
was crypto before obviously AI is taking it to new heights.

01:07:54.140 --> 01:07:57.500
So I would imagine a world where everyone's gaming PC,

01:07:57.500 --> 01:07:59.580
and maybe you just don't get to the level of compute

01:07:59.580 --> 01:08:03.500
that you can with the H series in data centers.

01:08:03.500 --> 01:08:06.540
But if you were to take every GPU around the world

01:08:06.540 --> 01:08:08.540
and then be able to kind of do something like SETI at home

01:08:09.980 --> 01:08:11.660
in a kind of decentralized manner,

01:08:12.540 --> 01:08:15.260
maybe you do actually have this kind of,

01:08:15.260 --> 01:08:17.900
you can't go drone strike the data center

01:08:17.900 --> 01:08:20.220
because I am the data center.

01:08:20.220 --> 01:08:21.900
Come and take my GPU, right?

01:08:23.660 --> 01:08:25.500
Yeah, I think that is the dream.

01:08:25.500 --> 01:08:27.420
I think that at least right now

01:08:27.420 --> 01:08:30.460
in the way we're doing these big models,

01:08:30.460 --> 01:08:33.340
you need paralyzed high bandwidth multi GPUs.

01:08:34.460 --> 01:08:35.980
It's very hard to shard the models

01:08:35.980 --> 01:08:38.220
without a significant slowdown over the network.

01:08:38.300 --> 01:08:41.580
And if an alternative is like a thousand times slower

01:08:41.580 --> 01:08:44.940
or more pricey than the centralized incumbent,

01:08:44.940 --> 01:08:46.300
like in the free market,

01:08:46.300 --> 01:08:49.100
like people want to support decentralization.

01:08:49.100 --> 01:08:51.340
But if the product is not like competitive

01:08:51.340 --> 01:08:52.380
with the centralized player,

01:08:52.380 --> 01:08:55.020
like at the end of the day, people pay for what works

01:08:55.020 --> 01:08:57.580
and has the right cost benefit analysis.

01:08:57.580 --> 01:09:01.660
But I think that there's going to have to be

01:09:01.660 --> 01:09:02.940
sort of algorithmic breakthroughs.

01:09:02.940 --> 01:09:04.140
But you can imagine where people,

01:09:04.140 --> 01:09:06.380
instead of having just a gaming PC,

01:09:06.380 --> 01:09:08.380
they have maybe, you know,

01:09:08.940 --> 01:09:11.660
bigger boxes that have beefier GPUs

01:09:11.660 --> 01:09:13.980
and they can run maybe a whole single node.

01:09:13.980 --> 01:09:16.220
Yeah, like this is what George is working on, right?

01:09:16.220 --> 01:09:17.420
George Hots, right?

01:09:17.420 --> 01:09:19.260
Yeah, so George Hots is working on

01:09:19.260 --> 01:09:21.580
kind of the hardware infrastructure for that, right?

01:09:21.580 --> 01:09:25.740
Selling beefy GPU boxes of several GPUs.

01:09:25.740 --> 01:09:27.340
I don't know if he's this close to me.

01:09:27.340 --> 01:09:30.060
But he's like a petaflop at home.

01:09:30.060 --> 01:09:31.340
Is that the idea?

01:09:31.340 --> 01:09:32.700
Right, right, right.

01:09:32.700 --> 01:09:36.300
And that seems like an attractive kind of like node

01:09:36.300 --> 01:09:38.380
to run potentially a future protocol.

01:09:39.020 --> 01:09:41.580
I would encourage a lot of people to do the research here.

01:09:41.580 --> 01:09:42.620
I think there just needs to be

01:09:43.340 --> 01:09:45.100
a lot more players in this space.

01:09:45.100 --> 01:09:48.220
And I think that AI people, you know,

01:09:48.220 --> 01:09:49.740
are going to have to talk to the crypto people.

01:09:50.460 --> 01:09:51.660
And there's going to be kind of,

01:09:53.340 --> 01:09:55.660
going to be a moment there where there's going to be,

01:09:56.220 --> 01:09:58.140
there's going to have to be bridges built there

01:09:58.140 --> 01:09:59.020
in terms of the language.

01:10:00.140 --> 01:10:02.540
But, you know, I'm optimistic.

01:10:02.540 --> 01:10:03.580
I don't know, that's my prediction.

01:10:03.580 --> 01:10:05.420
I think the merging of crypto and AI,

01:10:06.540 --> 01:10:08.540
you know, this kind of anti-centralization

01:10:09.500 --> 01:10:11.500
of AI movement is going to kind of

01:10:11.500 --> 01:10:12.860
combine forces with crypto.

01:10:13.900 --> 01:10:17.340
Again, I don't own anything in any protocol right now.

01:10:18.460 --> 01:10:21.980
So not talking my book, just like my prediction.

01:10:21.980 --> 01:10:25.340
But yeah, no, I think it's exciting.

01:10:25.340 --> 01:10:29.420
Personally, I'm really worried about, you know, okay, cool.

01:10:29.420 --> 01:10:31.900
Like, great, we've decentralized the algorithms

01:10:31.900 --> 01:10:35.020
and the sort of like distillation process of AI,

01:10:35.020 --> 01:10:37.980
like distilling data into neural weights, right?

01:10:37.980 --> 01:10:39.660
That is the software process that we're talking about.

01:10:39.660 --> 01:10:42.220
That's what OpenAI does, that's what Anthropic does.

01:10:42.220 --> 01:10:44.380
Great, maybe we figured out how to decentralize that.

01:10:44.380 --> 01:10:48.940
You're still buying your GPUs from the same supply chain

01:10:48.940 --> 01:10:54.540
that is down to, you know, NVIDIA, TSMC, ASML, right?

01:10:54.540 --> 01:10:56.540
ASML is, for those not familiar,

01:10:57.340 --> 01:11:00.620
you know, the machines that do the extreme

01:11:00.620 --> 01:11:02.380
ultraviolet lithography,

01:11:02.380 --> 01:11:06.620
so the most advanced process nodes to create the GPUs

01:11:06.620 --> 01:11:07.340
you use with NVIDIA.

01:11:07.340 --> 01:11:09.820
NVIDIA doesn't build their own GPUs.

01:11:09.820 --> 01:11:13.660
They, you know, work with TSMC, which is in Taiwan.

01:11:16.140 --> 01:11:18.140
And, you know, that's where they're built.

01:11:18.140 --> 01:11:20.300
And so again, you know, I'm just thinking

01:11:20.300 --> 01:11:22.540
about fault tolerance of the system.

01:11:22.540 --> 01:11:25.340
And right now our supply chain for AI hardware

01:11:25.340 --> 01:11:27.420
is absolutely not fault tolerant

01:11:27.420 --> 01:11:31.900
and might be co-opted by totalitarian leaders

01:11:31.980 --> 01:11:34.380
from, you know, the CCP, right?

01:11:35.020 --> 01:11:38.620
And might cause a major global conflict because of that.

01:11:38.620 --> 01:11:41.500
So, you know, what I'm working on

01:11:41.500 --> 01:11:44.860
is sort of like decentralizing the AI supply chain

01:11:44.860 --> 01:11:46.940
by fundamentally changing the substrate

01:11:46.940 --> 01:11:50.780
on which we run generative AI completely, right?

01:11:50.780 --> 01:11:53.740
Beyond transistor-based compute, beyond digital compute.

01:11:55.340 --> 01:11:58.780
And once you have this fork in the tech tree,

01:11:58.780 --> 01:12:00.860
there's all sorts of opportunities that pop up

01:12:00.860 --> 01:12:03.580
for far more energy efficiency, for far more speed,

01:12:04.940 --> 01:12:06.460
and eventually far more density.

01:12:07.340 --> 01:12:08.700
And that's what we're going after.

01:12:08.700 --> 01:12:11.340
So we're still kind of in the, we're still living our values.

01:12:11.340 --> 01:12:15.180
It's just we're going after the much harder problem

01:12:15.180 --> 01:12:16.300
of hardware engineering.

01:12:16.300 --> 01:12:19.260
And production is really expensive right now.

01:12:19.820 --> 01:12:21.900
Model production is very expensive

01:12:21.900 --> 01:12:23.740
for all the reasons that you listed.

01:12:23.740 --> 01:12:27.100
And I think that crypto probably, crypto cross AI

01:12:27.100 --> 01:12:29.660
has a lot of potential in the nearer term

01:12:29.660 --> 01:12:32.140
with like the one to end part of this, right?

01:12:32.140 --> 01:12:34.780
Where you're diffusing the capabilities of the model

01:12:34.780 --> 01:12:35.740
in the same way that, you know,

01:12:35.740 --> 01:12:38.620
you see open source already doing without crypto.

01:12:38.620 --> 01:12:42.060
I think like in general, yeah, like the,

01:12:43.340 --> 01:12:44.620
yeah, this is like a thing of broad thing

01:12:44.620 --> 01:12:45.900
that we've talked about a lot, right?

01:12:45.900 --> 01:12:47.820
Which is like, there is so much work to do

01:12:47.820 --> 01:12:49.740
to put intelligence into like every corner

01:12:49.740 --> 01:12:50.700
of the world where it's needed.

01:12:51.260 --> 01:12:54.060
And you just like the idea that you're going to do that

01:12:54.060 --> 01:12:55.180
with a few thousand people,

01:12:55.180 --> 01:12:57.900
a couple of centralized companies is probably wrong.

01:12:58.460 --> 01:13:02.460
And I think like, yeah, you can do this with APIs,

01:13:02.460 --> 01:13:05.020
but a lot of times you need more privacy than that

01:13:05.020 --> 01:13:05.660
for your data.

01:13:06.780 --> 01:13:07.980
Maybe you don't have internet connection.

01:13:07.980 --> 01:13:08.940
There are a number of like constraints

01:13:08.940 --> 01:13:10.380
that come up in real world that

01:13:10.380 --> 01:13:13.340
or you don't want to have these, you know,

01:13:13.340 --> 01:13:14.300
centralized APIs.

01:13:14.300 --> 01:13:18.300
And I think, yeah, there's kind of a natural balance there.

01:13:19.420 --> 01:13:21.180
Nathan brought up this paper, I think,

01:13:22.140 --> 01:13:23.660
this DeepMind paper, right?

01:13:23.660 --> 01:13:26.620
Which is, they recently came out with some innovation

01:13:26.620 --> 01:13:30.380
in doing, you know, kind of like distributed training,

01:13:30.380 --> 01:13:32.060
some kind of federated learning scheme.

01:13:32.060 --> 01:13:34.140
I think it's probably worth emphasizing

01:13:34.140 --> 01:13:35.260
the main problem here right now,

01:13:35.260 --> 01:13:40.140
which is just the network latency, as Guillaume said.

01:13:41.900 --> 01:13:43.980
I don't think anyone has figured this out.

01:13:43.980 --> 01:13:46.380
As far as I know, nobody has solved this problem,

01:13:46.380 --> 01:13:47.660
making it cost effective.

01:13:47.660 --> 01:13:51.900
And I think it's probably worth underscoring that, yeah, right?

01:13:51.900 --> 01:13:53.740
So if it takes, let's say like a hundred days

01:13:53.740 --> 01:13:55.340
to train a frontier model,

01:13:56.060 --> 01:13:59.500
if you are off by a factor of two or five or 10

01:14:00.060 --> 01:14:02.540
in your distributed scheme, that's pretty much kills it.

01:14:02.540 --> 01:14:04.460
Like it's a really long horizon.

01:14:04.460 --> 01:14:05.260
By the time you finish,

01:14:05.260 --> 01:14:07.820
you will already be not state of the art anymore, right?

01:14:07.820 --> 01:14:10.940
And so, yeah, this is really problematic.

01:14:10.940 --> 01:14:14.540
I think it's also just about the DeepMind paper.

01:14:15.180 --> 01:14:16.620
It's like using data parallelism,

01:14:16.620 --> 01:14:17.740
which a lot of people have figured out,

01:14:17.740 --> 01:14:19.500
I think BitTensor figured this out.

01:14:19.500 --> 01:14:21.500
But you also need model parallelism.

01:14:21.500 --> 01:14:23.100
You need to shard the model over.

01:14:23.180 --> 01:14:24.060
No, it's interesting.

01:14:25.180 --> 01:14:26.220
But you're screwed, right?

01:14:26.220 --> 01:14:28.460
If you can't fit the whole model in one computer

01:14:28.460 --> 01:14:30.860
that you can plug into a wall outlet

01:14:30.860 --> 01:14:32.940
and not have to have a home nuclear power plant,

01:14:33.740 --> 01:14:36.620
like it's really hard to do model parallelism,

01:14:36.620 --> 01:14:39.100
or it's impossible to do data parallelism.

01:14:39.100 --> 01:14:41.580
And if you're doing for a big enough model,

01:14:41.580 --> 01:14:45.820
and if you're doing model parallelism over the network,

01:14:45.820 --> 01:14:49.180
you're also screwed from the interconnect.

01:14:49.660 --> 01:14:53.900
And so creating the hardware substrate

01:14:53.900 --> 01:14:55.740
that's going to allow for decentralized AI,

01:14:55.740 --> 01:14:58.780
we have to solve from first principles

01:14:58.780 --> 01:15:00.860
how to increase the density of intelligence

01:15:00.860 --> 01:15:03.420
in terms of space, time, and energy

01:15:03.420 --> 01:15:04.700
from the first principles of physics.

01:15:05.660 --> 01:15:08.060
And that's sort of what we're building,

01:15:08.060 --> 01:15:09.180
what we're trying to enable.

01:15:09.180 --> 01:15:15.820
So that's why I think if there are decentralized

01:15:15.820 --> 01:15:18.220
crypto protocols of all sorts,

01:15:18.220 --> 01:15:20.140
if we have the best AI hardware

01:15:20.140 --> 01:15:21.180
that has the highest density

01:15:21.180 --> 01:15:23.100
and runs most energy efficiently,

01:15:23.100 --> 01:15:27.340
obviously it's in our, we'll have a lot of customers, right?

01:15:27.340 --> 01:15:30.060
Similarly, we could be the Nvidia for Ethereum,

01:15:30.060 --> 01:15:31.020
in that case, right?

01:15:32.140 --> 01:15:33.980
We don't, again, we don't have a crypto protocol,

01:15:34.940 --> 01:15:38.460
but I think that that's a very hard problem.

01:15:38.460 --> 01:15:39.500
You need to assemble a team

01:15:39.500 --> 01:15:42.380
that's basically like a Manhattan project-like team.

01:15:43.100 --> 01:15:48.700
And we came from Google X, Google Quantum, AWS Quantum,

01:15:50.780 --> 01:15:57.580
all sorts of institutions, IBM, Google Meta, et cetera.

01:15:57.580 --> 01:15:59.420
And we assembled quite the team

01:15:59.420 --> 01:16:02.860
and we're going after the hardest problem in AI right now,

01:16:03.580 --> 01:16:06.700
which is like, how do you embed AI

01:16:06.700 --> 01:16:08.700
into the physical processes of the world,

01:16:08.700 --> 01:16:10.380
the most efficiently, right?

01:16:10.380 --> 01:16:12.700
So you got to really understand the duality

01:16:12.700 --> 01:16:14.220
between physics and AI, right?

01:16:14.220 --> 01:16:16.620
And that's what we're, that's what we're after.

01:16:17.980 --> 01:16:20.380
And so it's kind of like, to me, that seems like,

01:16:21.500 --> 01:16:23.660
you know, okay, I would love for there

01:16:23.660 --> 01:16:26.060
to be a protocol that is competitive right now,

01:16:26.060 --> 01:16:29.180
but we need to solve for the density of compute first.

01:16:29.180 --> 01:16:31.340
Look, maybe George builds crazy boxes

01:16:31.340 --> 01:16:34.060
that are water-cooled and you use like two plugs in your house

01:16:34.060 --> 01:16:35.900
and maybe that's just enough to run certain models.

01:16:35.900 --> 01:16:36.380
That's great.

01:16:37.580 --> 01:16:39.340
I think we need to go much further.

01:16:39.340 --> 01:16:40.380
I think there's orders,

01:16:40.380 --> 01:16:41.900
there's still orders of magnitude to go

01:16:41.900 --> 01:16:44.300
in terms of energy efficiency and density

01:16:44.300 --> 01:16:48.540
for AI, for compute, especially for AI, right?

01:16:49.980 --> 01:16:51.420
And that's what we're solving.

01:16:53.420 --> 01:16:54.940
What is this drop-off?

01:16:54.940 --> 01:16:57.180
I just wanted to say thanks for coming on the podcast,

01:16:57.180 --> 01:16:58.860
but you guys continue the conversation.

01:16:58.860 --> 01:16:59.500
Thanks so much.

01:17:00.140 --> 01:17:00.620
Cheers.

01:17:00.620 --> 01:17:02.060
Guillaume, I have to ask, what is the hardware though?

01:17:02.060 --> 01:17:04.220
I mean, are you going to bring quantum computers to market

01:17:04.220 --> 01:17:04.700
doing AI?

01:17:04.700 --> 01:17:05.820
I mean, I have to ask you in the background.

01:17:05.820 --> 01:17:06.540
It's not quantum computing.

01:17:06.540 --> 01:17:07.900
It's definitely not quantum computing.

01:17:07.980 --> 01:17:10.620
Yeah, we all got jaded by quantum computing

01:17:10.620 --> 01:17:12.140
being kind of like nuclear effusion.

01:17:12.860 --> 01:17:14.060
The timelines are very long.

01:17:15.580 --> 01:17:19.100
Fundamentally, a quantum computer, you have to cool it

01:17:19.100 --> 01:17:20.700
to absolute zero, ideally.

01:17:21.420 --> 01:17:23.740
That's obviously physically impossible.

01:17:23.740 --> 01:17:25.660
And so what you have to do is this process

01:17:25.660 --> 01:17:27.420
called quantum error correction, right?

01:17:27.420 --> 01:17:31.580
So you have to identify faults from the universe jiggling

01:17:31.580 --> 01:17:34.620
and screwing up your computer's operation

01:17:34.620 --> 01:17:36.460
and you got to identify faults and filter them out.

01:17:36.460 --> 01:17:37.420
So you're pumping entropy.

01:17:37.420 --> 01:17:39.020
So it's basically a fridge, right?

01:17:39.020 --> 01:17:41.260
But this sort of algorithm that is your fridge

01:17:41.820 --> 01:17:47.740
occupies like 99.9999, you know, well, not that many nines,

01:17:47.740 --> 01:17:52.220
but quite a few nines of your computation, right?

01:17:52.220 --> 01:17:52.620
Overall.

01:17:53.500 --> 01:17:55.100
And to me, that seems very inefficient.

01:17:56.220 --> 01:18:00.220
And, you know, a lot of us were kind of full stack architects

01:18:00.220 --> 01:18:02.780
or engineers, the software, the hardware,

01:18:03.420 --> 01:18:06.220
and the compilers for quantum computing.

01:18:06.220 --> 01:18:08.940
And we'd look at the roadmaps, we'd look how long it would take

01:18:08.940 --> 01:18:11.100
and we kind of got depressed to some extent.

01:18:11.100 --> 01:18:14.380
And so a lot of us were like, actually, you know,

01:18:14.380 --> 01:18:16.460
maybe there's ways to use this noise

01:18:17.260 --> 01:18:19.020
instead of it being a hindrance.

01:18:19.020 --> 01:18:21.260
And so, you know, we set out to do a different type

01:18:21.260 --> 01:18:24.060
of physics-based computing that are not quantum mechanical

01:18:25.420 --> 01:18:28.540
that is specifically focused on general AI, right?

01:18:29.740 --> 01:18:32.780
And for now, we kind of got our hand forced

01:18:33.260 --> 01:18:36.380
with this whole doxing situation.

01:18:36.380 --> 01:18:38.540
So, you know, we're going to be still nebulous

01:18:38.540 --> 01:18:40.060
about what exactly it is we're doing.

01:18:40.940 --> 01:18:44.220
But, you know, we have quite a few scientific publications

01:18:44.860 --> 01:18:46.140
in preparation, right?

01:18:47.020 --> 01:18:50.380
So, but yeah, overall, you know, we think there's a different path

01:18:50.380 --> 01:18:52.540
forward, a fundamentally new way to compute.

01:18:53.340 --> 01:18:55.020
It's going to be like quantum computing,

01:18:56.060 --> 01:18:58.380
but a new type of physics-based computing.

01:18:59.420 --> 01:19:02.460
And ultimately, we learned a lot from quantum computing

01:19:03.500 --> 01:19:06.860
in terms of how to program, how to have programmable matter,

01:19:07.740 --> 01:19:11.180
how to have, how to integrate, you know,

01:19:11.180 --> 01:19:14.300
these sort of physical systems into a deep learning program.

01:19:14.300 --> 01:19:17.020
You know, that's what we pioneered with, you know,

01:19:17.020 --> 01:19:20.700
the software I did at Google with my CTO now, Trevor.

01:19:21.740 --> 01:19:23.500
We did TensorFlow Quantum, right?

01:19:24.300 --> 01:19:29.980
And so now it's about how to really have programmable matter

01:19:29.980 --> 01:19:32.940
and figure out the tidus embedding of AI in the physical world,

01:19:32.940 --> 01:19:36.220
which is exactly what the doomers fear most.

01:19:37.740 --> 01:19:41.180
And so, you know, as a joke, we kind of say,

01:19:41.180 --> 01:19:44.780
Bayes, for example, is one of our principal FOOM engineers.

01:19:46.380 --> 01:19:50.300
And we just announced that today that Bayes is part of the team.

01:19:51.820 --> 01:19:57.100
And, you know, ultimately, I think that there is no path forward

01:19:57.100 --> 01:20:01.180
where, you know, the ultimate form of AI isn't built.

01:20:02.380 --> 01:20:05.180
And I think that, you know, we could talk about, like,

01:20:05.180 --> 01:20:08.620
human augmentation and sort of the transhumanist path forward.

01:20:09.340 --> 01:20:11.980
I'm very bullish on that, and I would love to, you know,

01:20:12.540 --> 01:20:14.700
find ways to fund more efforts in sort of, like,

01:20:15.260 --> 01:20:17.660
human-machine collaboration and augmentation.

01:20:19.580 --> 01:20:23.420
But, yeah, overall, like, you know, the EAC thesis has always been like,

01:20:23.420 --> 01:20:27.340
hey, you know, I don't think, like, banning GPUs is going to do much.

01:20:27.340 --> 01:20:31.420
The tech tree is going to mutate around whatever your restrictions are

01:20:31.420 --> 01:20:34.060
and is going to adapt somewhere to a virus kind of mutating.

01:20:34.060 --> 01:20:35.740
The techno-capital machine just finds a way.

01:20:35.740 --> 01:20:37.900
It's kind of a system that's almost alive, right?

01:20:39.580 --> 01:20:43.420
And, you know, it's always like, and it's entropy-seeking.

01:20:43.420 --> 01:20:45.100
It's exploring all sorts of configurations,

01:20:45.100 --> 01:20:46.780
and it finds one that allows it to grow.

01:20:48.060 --> 01:20:52.700
And, you know, might as well build it and try to make it technology that's,

01:20:52.700 --> 01:20:55.820
you know, helping humanity scale, right?

01:20:55.820 --> 01:20:59.820
Our goal with EAC and really with the technologies we're building at our company

01:21:01.500 --> 01:21:07.500
is to enable sort of AI, the ability to perceive, predict, and control our world,

01:21:08.540 --> 01:21:13.100
you know, at all scales, including the nanoscale, such that we can, you know,

01:21:13.100 --> 01:21:17.340
tackle the real problems that are in the way for us to scale to Kardashev type 1,

01:21:17.340 --> 01:21:21.500
which is a scale of civilization in terms of its energetic expenditure.

01:21:22.380 --> 01:21:24.060
You know, it's kind of like, to us,

01:21:24.060 --> 01:21:29.500
it's like the ultimate denomination of like societal progress is like the Kardashev scale,

01:21:29.500 --> 01:21:34.300
because every other measure like GDP or like it's based on dollars, you know,

01:21:34.940 --> 01:21:37.020
you can like fudge the numbers, right?

01:21:37.020 --> 01:21:38.940
It's not anchored in like physical reality.

01:21:39.500 --> 01:21:44.780
And similarly, sort of our cultural thesis is that, you know,

01:21:44.780 --> 01:21:46.700
you should evaluate your actions in terms of like,

01:21:46.700 --> 01:21:50.620
how do you think it's going to contribute to the growth of civilization down the line?

01:21:52.060 --> 01:21:55.340
Rather than sort of like subjective measures of utility,

01:21:55.340 --> 01:21:59.740
like hedons, right, hedonism, like how much pleasure is this giving people on average,

01:22:00.940 --> 01:22:03.820
which leads to kind of spurious optima, like, you know,

01:22:04.700 --> 01:22:08.140
wireheading or TikTok and whatnot.

01:22:10.460 --> 01:22:10.860
So, yeah.

01:22:13.260 --> 01:22:14.940
You've got me in total suspense though, Guillaume,

01:22:14.940 --> 01:22:16.460
if it's non-transistor based computing,

01:22:16.460 --> 01:22:19.100
you've got me thinking what the hell it could be, I'm guessing.

01:22:19.660 --> 01:22:21.420
Yeah, yeah, yeah.

01:22:21.420 --> 01:22:23.980
I mean, we're, you know, we're working on it.

01:22:23.980 --> 01:22:25.980
We still have to remain somewhat secretive.

01:22:27.820 --> 01:22:30.380
And I guess there's going to be a lot of interest now.

01:22:30.380 --> 01:22:35.020
Again, we want to be in stealth until we had more to say, more to release.

01:22:35.020 --> 01:22:38.940
But for now, we're keeping things pretty close to the chest.

01:22:38.940 --> 01:22:42.460
But I think there's certain discoveries that you make that,

01:22:43.660 --> 01:22:46.460
you know, you're like, okay, I don't think I'm going to be able to unsee this.

01:22:46.460 --> 01:22:48.460
And if I saw it, someone else will see it.

01:22:49.500 --> 01:22:52.060
We should just move as fast as possible to bring this forth.

01:22:53.900 --> 01:22:57.500
And for us, it's like, okay, how do we make this the most impactful

01:22:58.540 --> 01:23:00.060
to the advancement of mankind?

01:23:00.060 --> 01:23:03.100
Like let's tackle the actually hard, the hardest problems

01:23:03.660 --> 01:23:06.300
that most people don't dare to tackle.

01:23:08.540 --> 01:23:10.940
And, you know, it takes some courage there.

01:23:11.500 --> 01:23:13.980
It takes some fanaticism to some extent.

01:23:13.980 --> 01:23:18.380
I think to me, the fact that we have this framework of EAC

01:23:18.940 --> 01:23:20.860
it's a really powerful motivator, right?

01:23:20.860 --> 01:23:22.620
It's like, what am I contributing to, right?

01:23:22.620 --> 01:23:27.500
Like we're kind of in a, well, you know, I went through a sort of whole phase of,

01:23:27.500 --> 01:23:31.420
you know, a group Catholic, and then I was a, not a Reddit atheist,

01:23:31.420 --> 01:23:33.900
but I was a typical atheist studied math and undergrad,

01:23:33.900 --> 01:23:35.660
and then went through a Nillist phase.

01:23:35.660 --> 01:23:39.500
But then I think like understanding that the whole system

01:23:40.060 --> 01:23:42.620
is seeks growth and entropy production.

01:23:43.260 --> 01:23:45.500
And that's kind of the way things are.

01:23:45.580 --> 01:23:48.700
And that process is what created life civilization

01:23:49.420 --> 01:23:51.020
and the technologies we enjoy.

01:23:51.020 --> 01:23:52.940
Like, okay, we want to contribute to that.

01:23:52.940 --> 01:23:56.220
So having the knowledge that you're contributing to something greater than yourself

01:23:56.220 --> 01:23:59.420
gives you that sort of like infinite dopamine well

01:23:59.980 --> 01:24:03.500
to grind through the long nights to skip the holiday dinners

01:24:03.500 --> 01:24:06.060
to just file more IP, right?

01:24:06.060 --> 01:24:07.660
Like and put in the hours.

01:24:08.300 --> 01:24:11.420
And, you know, I think like scaling, you know,

01:24:12.220 --> 01:24:17.100
everybody has their own cultural or religious framework that provides utility to them.

01:24:17.100 --> 01:24:19.740
For us, you know, for the IAC community,

01:24:19.740 --> 01:24:24.940
I think it has had utility for a lot of people to get out of this sort of Nillistic

01:24:26.060 --> 01:24:29.580
rut that they were in that, you know, the world was going to collapse.

01:24:29.580 --> 01:24:30.780
There's only doom and gloom.

01:24:31.580 --> 01:24:32.700
Everything's going to get worse.

01:24:33.580 --> 01:24:34.380
Put us in charge.

01:24:34.380 --> 01:24:35.820
We're going to fix it maybe.

01:24:35.820 --> 01:24:36.700
Oh, we didn't fix it.

01:24:36.700 --> 01:24:38.700
It's because you didn't give us enough power.

01:24:39.420 --> 01:24:41.980
And like, we're just like, you know, it's kind of like,

01:24:43.020 --> 01:24:44.940
well, you can make parallels to SF politics.

01:24:44.940 --> 01:24:45.980
I'm an SF right now.

01:24:47.580 --> 01:24:48.060
How's that?

01:24:48.060 --> 01:24:50.140
Such how's that by the way?

01:24:50.140 --> 01:24:51.420
Oh, it's it's Night City.

01:24:51.420 --> 01:24:52.060
I love it here.

01:24:52.700 --> 01:24:55.580
You know, it's it's truly Night City.

01:24:55.580 --> 01:24:58.700
I like to say our office is in Arasaka Tower.

01:24:58.700 --> 01:25:00.940
So we went with the sort sort of cyberpunk vibe.

01:25:02.620 --> 01:25:05.660
It's very much like Night City, the video game, right?

01:25:06.380 --> 01:25:11.020
No, but you see the sort of like, if you let the decels in charge

01:25:11.020 --> 01:25:14.380
and you let the movie play out, this is what you get, right?

01:25:16.060 --> 01:25:18.220
You know, you get and decels are kind of

01:25:21.260 --> 01:25:25.340
like they have much more power if they're attached or in control of something

01:25:25.340 --> 01:25:28.940
that's very prosperous, right, and generating a lot of value,

01:25:28.940 --> 01:25:30.700
like similar to big tech, right?

01:25:31.500 --> 01:25:34.220
You know, there's money printers and then these sort of

01:25:35.900 --> 01:25:38.940
folks that seek power kind of take over.

01:25:39.820 --> 01:25:42.460
But, you know, they can they can cause a lot of damage.

01:25:42.460 --> 01:25:45.580
And I think I think there's a there's a cultural turning point.

01:25:45.580 --> 01:25:48.860
And hopefully, you know, it doesn't matter if you're Republican or Democrat,

01:25:48.860 --> 01:25:53.740
like having people that are anti-tech progress, anti-tech first solutions and,

01:25:55.420 --> 01:26:02.700
you know, sheathing themselves and under the cover of virtue to gain more power

01:26:02.700 --> 01:26:06.460
and doing things out of self-interest and and and larping that it's for

01:26:07.340 --> 01:26:11.420
the good of many, you know, I think people have had enough of that

01:26:12.140 --> 01:26:13.500
and are ready for a change.

01:26:13.500 --> 01:26:19.500
And, you know, of course, like as technologists, like we propose technological solutions,

01:26:19.500 --> 01:26:23.500
but ultimately, like, like we believe in the power of technology,

01:26:23.500 --> 01:26:28.860
we believe in people having agency and not accepting that this is just how the way things are,

01:26:28.860 --> 01:26:31.740
you got to accept how they are, things are just going to get worse.

01:26:32.460 --> 01:26:34.460
You know, screw your dreams, kid.

01:26:35.420 --> 01:26:37.020
Just accept it and give up.

01:26:37.020 --> 01:26:38.220
Right. And it's like, no, fuck you.

01:26:38.220 --> 01:26:41.180
We're not we're going to we're going to make the better future happen.

01:26:41.180 --> 01:26:42.060
We have agency.

01:26:42.060 --> 01:26:43.900
We can build, get the heck out of our way.

01:26:45.260 --> 01:26:48.140
You know, we're going to make the the better future we want.

01:26:48.140 --> 01:26:51.740
And you need a sort of like fuck you optimism.

01:26:51.740 --> 01:26:52.060
All right.

01:26:53.260 --> 01:26:55.020
And that's that's IAC in a nutshell.

01:26:56.300 --> 01:27:01.020
And hopefully, it keeps growing because, you know, we think that's what's

01:27:01.020 --> 01:27:03.020
that's what the world needs in many ways.

01:27:04.540 --> 01:27:10.540
And, you know, hopefully we can accelerate SF and then we can accelerate the rest of the world.

01:27:10.540 --> 01:27:12.780
So can I ask you one follow up?

01:27:12.780 --> 01:27:15.020
And then, Nathan, I know you want to jump in and I want to give you time to jump in.

01:27:15.740 --> 01:27:17.820
But I did want to follow on one question that you mentioned.

01:27:17.820 --> 01:27:19.900
You mentioned race Catholic. I was also raised Catholic.

01:27:19.900 --> 01:27:23.420
I eventually converted to Judaism and kind of rejected this sort of default

01:27:23.420 --> 01:27:24.700
secular majority of society.

01:27:24.700 --> 01:27:25.500
That's a whole nother story.

01:27:25.500 --> 01:27:29.580
You've done a bunch of episodes on I do think, you know, it's one of my pet theories

01:27:29.580 --> 01:27:30.700
that religion never goes away.

01:27:30.700 --> 01:27:34.620
It only gets it's almost like, you know, energy or momentum only gets sort of transformed.

01:27:34.620 --> 01:27:37.100
And you get sort of worse, worse crappier versions of it.

01:27:37.100 --> 01:27:37.740
Yep. Yep.

01:27:37.740 --> 01:27:41.340
The reality is you can't actually, you can't actually navigate the world without

01:27:41.340 --> 01:27:43.100
a sense of metaphysics of some form.

01:27:43.100 --> 01:27:44.860
And in fact, if you don't have an explicit metaphysics,

01:27:44.860 --> 01:27:47.900
you can't even do empiricism well, because then you have to change reality to sort of

01:27:47.900 --> 01:27:48.940
suit metaphysical ends.

01:27:48.940 --> 01:27:52.700
I mean, to cite the COVID example in which they denied the lab origin hypothesis

01:27:52.700 --> 01:27:54.620
because it serves some metaphysical end.

01:27:54.620 --> 01:27:57.420
And so they stopped being able to do empiricism as well as they could have.

01:27:57.500 --> 01:28:01.180
They could have, you know, and then that whole COVID story, if there wasn't actually a way

01:28:01.180 --> 01:28:04.380
to have a conversation about, do we save the kids or and screw the old people or vice

01:28:04.380 --> 01:28:04.700
versa?

01:28:04.700 --> 01:28:05.900
Like you couldn't have that conversation.

01:28:05.900 --> 01:28:09.180
So instead it was about the science, but really it was a moral conversation that nobody

01:28:09.180 --> 01:28:12.540
could have because we weren't all morally or even religiously on the same page.

01:28:12.540 --> 01:28:13.820
That's a whole separate conversation.

01:28:13.820 --> 01:28:16.540
But I do think it's interesting and I do think it's one of the things that's a little

01:28:16.540 --> 01:28:17.340
bit lacking in tech.

01:28:17.340 --> 01:28:20.780
I mean, you see these homespun religions, like I would say Burning Man is a little bit

01:28:20.780 --> 01:28:23.020
culty startups are obviously a little culty.

01:28:24.220 --> 01:28:25.900
And I'm not saying this is a bad thing, by the way.

01:28:25.900 --> 01:28:29.420
It's just, it's just, yeah, I know it's a good thing, but it's a little incomplete,

01:28:29.420 --> 01:28:29.660
right?

01:28:29.660 --> 01:28:32.780
In the sense that like, well, it doesn't quite tell me how to raise my kids or,

01:28:32.780 --> 01:28:33.820
you know, who I should marry.

01:28:34.940 --> 01:28:37.980
That I don't know if, and I know I'm putting you on the spot a little bit to like,

01:28:37.980 --> 01:28:39.340
give me the gospel, bro.

01:28:39.340 --> 01:28:45.100
But like what, you know, yeah, what would be and direct me to a set of writing if there

01:28:45.100 --> 01:28:47.100
is one, but like, what would be the E at gospel or like that?

01:28:47.100 --> 01:28:51.660
You know, what is the true, the good and the beautiful in this world other than obviously

01:28:51.660 --> 01:28:53.420
building for building sake, which I think we all get.

01:28:53.420 --> 01:28:54.940
What is the bigger picture?

01:28:54.940 --> 01:28:57.340
Yeah, so, so at a high level, right?

01:28:57.340 --> 01:29:02.300
Yeah, because all about figuring out whatever sort of cultural framework yields,

01:29:03.820 --> 01:29:08.060
the maximal expected growth and scope and scale of civilization.

01:29:08.060 --> 01:29:09.340
And we don't want to be prescriptive.

01:29:09.340 --> 01:29:14.380
All we're giving is a loss function and you can have your own hyper parameter settings.

01:29:14.380 --> 01:29:16.860
You're, you're like, okay, I have a cultural heuristic.

01:29:16.860 --> 01:29:20.220
I think this is an optimum of this sort of loss function.

01:29:20.220 --> 01:29:24.380
This is how I want to, you know, do things within my tribe here.

01:29:25.260 --> 01:29:30.380
It's essentially a sort of like, think of like a very thin framework from which you can have

01:29:30.380 --> 01:29:31.740
like subcultures, right?

01:29:31.740 --> 01:29:36.780
And, you know, the idea is to have sort of culture be more or less like, like code,

01:29:36.780 --> 01:29:41.340
like on GitHub, you can kind of have a base framework and then you can add kind of command

01:29:41.340 --> 01:29:44.380
ments or add things you believe or you can diff it, right?

01:29:44.380 --> 01:29:46.780
You can make forks and you can kind of keep track.

01:29:47.500 --> 01:29:53.500
And so we've seen, for example, you know, Vitalik forked yak and made some changes, right?

01:29:53.500 --> 01:29:57.020
And then he's like, this is what I believe, right?

01:29:57.020 --> 01:30:00.300
So really, you know, yak is sort of a meta cultural framework.

01:30:00.300 --> 01:30:03.260
We don't prescribe, we don't prescribe too much.

01:30:03.260 --> 01:30:04.860
We try to prescribe the minimum.

01:30:05.580 --> 01:30:11.500
But to us, it's very clear that the, the engine that keeps progress going,

01:30:12.460 --> 01:30:16.620
maintaining the sanctity of its sort of momentum and mount, you know, maintaining

01:30:16.620 --> 01:30:22.540
malleability, adaptability, and so on is it's crucial to maintain freedoms and maintain

01:30:22.540 --> 01:30:29.820
entropy in the system and accept variants rather than constraining things, crushing entropy,

01:30:30.860 --> 01:30:37.420
crushing variants, because that leads to crystallization and sort of like catastrophic

01:30:37.420 --> 01:30:43.500
failure. And so, you know, at a very meta level, we try to maintain variants in most

01:30:43.500 --> 01:30:48.300
parameters, but it's not like all variants, no restraint, because that, that just doesn't work,

01:30:48.300 --> 01:30:52.860
right? It's, it's kind of like running a system at very high temperature.

01:30:52.860 --> 01:30:54.380
It's just pure disorder.

01:30:54.380 --> 01:30:59.340
So it's kind of always about finding the optimum balance between order and disorder,

01:30:59.340 --> 01:31:07.020
so between entropy seeking behavior and novelty seeking and sort of constraint and conservatism.

01:31:08.620 --> 01:31:12.140
And so we don't have any one particular prescription of how to live your life,

01:31:12.140 --> 01:31:17.180
but some people like to make forks and have more particular prescriptions.

01:31:17.180 --> 01:31:23.900
And to us, it seems, at least my personal thesis on how cultures get kind of memetically

01:31:23.900 --> 01:31:30.460
post-selected for, it's like whichever culture either confers its adherence and a better ability

01:31:30.460 --> 01:31:37.180
to grow, or if a culture is more sort of viral, then it's going to be more likely to exist.

01:31:37.180 --> 01:31:43.020
That's just like, by probability theory. And so, you know, to us, it's like, okay, if we have this

01:31:43.020 --> 01:31:46.620
sort of metacultural framework, people have all sorts of forks and all these memetic

01:31:47.740 --> 01:31:53.900
forks with different parameter settings can compete in a sort of cultural setting. But we

01:31:53.900 --> 01:31:59.180
should explore the space of cultures and heuristics of, of how to live your life. So for example,

01:31:59.180 --> 01:32:06.300
another friend of ours is, is Brian Johnson, and he has his own life heuristics, and he's trying

01:32:06.300 --> 01:32:11.020
to create his own cultural framework, and he has much more prescriptive ways to live your life.

01:32:11.020 --> 01:32:14.940
And he thinks we should, you know, life spans should be much longer than what it is. And you

01:32:14.940 --> 01:32:22.540
should have, you know, longevity as a priority, right? And so I'm all for this sort of renaissance

01:32:22.540 --> 01:32:29.180
of exploring all sorts of neo religions, neo cultural frameworks for how to live your life.

01:32:29.180 --> 01:32:33.900
I think it's much needed because otherwise sort of parasitic, you know, mind viruses,

01:32:34.540 --> 01:32:41.420
like the ones we've seen do all sorts of damage recently, including the DSEL class of mind viruses.

01:32:41.740 --> 01:32:49.900
We, that's a whole category. Yeah, they come in and they kind of like, like you said, kind of

01:32:50.940 --> 01:32:58.060
fill in this, this gap in people's hearts, if you will. So, so I think we're on the same page.

01:32:58.060 --> 01:33:02.380
And I think, you know, much more, you know, lindy religions, right, like, in a sense, like,

01:33:02.380 --> 01:33:06.860
that have been around for a long time, like, they're very robust, right? It's like a, it's like a

01:33:06.860 --> 01:33:12.460
code base that has been through hell, you know, and back and like, it's just, it's very robust,

01:33:12.460 --> 01:33:16.780
right? It's been robustified over a long time. And by the proof that it's lasted a long time,

01:33:16.780 --> 01:33:22.700
it's, it's a good heuristic. So, you know, that's great. But I think, like, some people want kind

01:33:22.700 --> 01:33:29.660
of, you know, modern variants, right? And they want to contribute to shaping new subcultures.

01:33:29.660 --> 01:33:35.420
And so we encourage people to form subcultures. So really, we're kind of like, only setting the

01:33:35.820 --> 01:33:40.220
hyper hyper parameters of the whole thing. And, and people can set, like more finer grain,

01:33:40.940 --> 01:33:45.900
fine tunings of how they want to live their lives. So there's no one way to go about it. But, you know,

01:33:46.460 --> 01:33:50.380
we do talk a lot about building, because we think that obviously fundamentally, like,

01:33:50.940 --> 01:33:57.020
building technology is a very high leverage way to use your time on earth to impact the

01:33:57.020 --> 01:34:01.980
future scope and scale of civilization, right? And so, you know, encouraging one another and

01:34:01.980 --> 01:34:06.220
helping one another in building technologies that have a positive impact, like we think

01:34:06.220 --> 01:34:13.020
that's a good heuristic that should be in most, you know, forks. And so, so we encourage that.

01:34:13.020 --> 01:34:16.860
Some people think that's the only message, but it's not, right? It came from kind of a higher

01:34:16.860 --> 01:34:22.220
level thinking. But yeah, cool. Well, you're in, I think you're in the right city for exploring

01:34:22.220 --> 01:34:25.900
religions. I mean, the way I see San Francisco, it's really, it's a Petri dish for literally

01:34:25.900 --> 01:34:30.540
exploring every weird ass thing that society wants to do, whether it be autonomous vehicles,

01:34:30.620 --> 01:34:34.220
whatever weird computation you're cooking up with, not having rule of law, for example,

01:34:35.340 --> 01:34:39.340
psychedelic drugs, whatever, bring it, we're going to, it's going to be cooked up here and then

01:34:39.340 --> 01:34:42.940
from here expand and diffuse whether we like it or not to the rest of the world. But I want to

01:34:42.940 --> 01:34:45.900
let Nathan in. I know he's probably been biting his tongue this entire time. And I think I'm the

01:34:45.900 --> 01:34:51.340
last host left standing. And so I'm going to invite Nathan to go ahead and comment and provide maybe

01:34:51.340 --> 01:34:55.580
the other side of it if he wants to. Well, how much time do you guys have is my first question,

01:34:55.580 --> 01:35:02.300
because I am, I have a lot of questions. And I would, if you have the time for it,

01:35:02.860 --> 01:35:09.100
I might kind of fork this episode and just kind of take it in a whole different

01:35:10.780 --> 01:35:15.180
and kind of more from very sort of naive questions direction.

01:35:16.940 --> 01:35:22.860
My show is all about AI and it reaches a pretty diverse set of people that are

01:35:23.820 --> 01:35:28.060
all pretty obsessed with AI, I think. I don't really actually know too much about them other

01:35:28.060 --> 01:35:36.140
than that they go pretty deep with me on a lot of AI topics. And so the way I was thinking about

01:35:36.140 --> 01:35:41.020
approaching, so we could do this now, we could do it another time, but I mean, I'm up late.

01:35:41.020 --> 01:35:46.220
Now is a pretty bad time. I have to have a six a.m. round announcement to craft.

01:35:46.300 --> 01:35:54.460
It's going to be a long night for me. So I was happy to do this podcast. It's very timely for us,

01:35:55.340 --> 01:35:59.980
but I'd be happy to hop on your show. I mean, you could rewatch the recording,

01:35:59.980 --> 01:36:04.060
write down your questions, and we can just go into it. And I would love to do that actually.

01:36:04.060 --> 01:36:10.700
So cool. Yeah, I've got a list all cooked up, but I'm happy to do it whenever is convenient for

01:36:10.700 --> 01:36:19.180
you, although it is timely now. I think part of the reason why Eric had a mixed crew

01:36:19.180 --> 01:36:22.780
is to have there be the other take of it. So I don't know if there's one question,

01:36:22.780 --> 01:36:26.540
or if it makes sense at all. We have nothing against it seeding another show, by the way.

01:36:26.540 --> 01:36:31.100
That's perfectly fine. Or we can bail on. I also want to be respectful of Guillaume's time,

01:36:31.100 --> 01:36:34.460
because it sounds like he's in a, and again, thanks for making the time for the podcast.

01:36:35.020 --> 01:36:42.940
Yeah, I mean, my angle on the whole thing is, I describe myself as an AI scout,

01:36:43.660 --> 01:36:50.860
and I'm getting more and more, putting more and more emphasis on, let's really try to figure out

01:36:50.860 --> 01:36:57.420
what is today, what exists, what can be done with it, you know, if we are going to extrapolate,

01:36:57.420 --> 01:37:01.100
can we extrapolate, first of all, in a high confidence way into the short term,

01:37:01.740 --> 01:37:07.740
and then use those discussions as kind of the foundation for figuring out what we should do

01:37:07.740 --> 01:37:13.100
about the bigger picture questions, where I think inherently there's a lot more uncertainty.

01:37:13.740 --> 01:37:18.060
And one thing I haven't really heard from you guys, and I've pieced a little bit of it together

01:37:18.060 --> 01:37:25.740
from Twitter, but I don't have a great sense of like, what are your near term expectations? Like,

01:37:25.820 --> 01:37:30.620
do you think we are headed for AGI in the next couple of years? You know,

01:37:30.620 --> 01:37:37.580
Metaculous has it at like, just over two years, the leaders of Anthropic, for example, say that

01:37:37.580 --> 01:37:43.820
the leading developers in 2526 timeframe may create such a lead that no one will ever catch them.

01:37:45.260 --> 01:37:49.020
Are you kind of in that same headspace of thinking that we're going to see

01:37:49.900 --> 01:37:56.140
pretty radical transformation on just a few year time scale is like my very first question.

01:37:57.260 --> 01:38:02.380
Yeah. First of all, I don't like the term AGI that much. I think it's human level AI or human

01:38:02.380 --> 01:38:09.740
like AI. I think like calling AGI general intelligence like human like AI that was distilled

01:38:09.740 --> 01:38:17.980
from human generated data. I think that's like very anthropocentric. And I think, you know,

01:38:17.980 --> 01:38:22.700
I work in physics based AI, you know, inspired by physics and to understand the physical world,

01:38:22.700 --> 01:38:32.540
and I've done so for 10 plus years now. I think that intelligence is a much more general concept than

01:38:33.740 --> 01:38:39.500
just human like intelligence. And frankly, I'm not scared of FOOM because, you know, again,

01:38:39.500 --> 01:38:44.860
I've worked on AI for engineering matter, jugs, simulations, biology, all sorts of stuff.

01:38:45.580 --> 01:38:52.700
It's much harder than people think. I do think it is disruptive for our economy based, you know,

01:38:52.700 --> 01:38:57.660
our knowledge economy of sort of human like white color intelligence. I think there's a,

01:38:57.660 --> 01:39:03.020
there's still going to be a 10 year gap for physical intelligence, right? Robotics. I think,

01:39:04.060 --> 01:39:08.460
you know, our motor, motor intelligence is much harder. It takes many more parameters. It took,

01:39:08.460 --> 01:39:12.540
you know, billions of years to evolve, rather than I guess like, I don't know, 100 million

01:39:13.180 --> 01:39:21.580
for the neocortex. Probably got those numbers wrong, but it's ballpark. But yeah, essentially,

01:39:21.580 --> 01:39:28.700
I think, I think there might be a disruption to our economy. But I do think that people will adapt.

01:39:29.260 --> 01:39:34.060
People will learn to augment themselves out of self interest, right? And it's like,

01:39:34.060 --> 01:39:37.660
where, where will the system goes? Every corporation is going to do what's in their best

01:39:37.660 --> 01:39:44.380
self interest. They're going to maybe be 80% AI, 20% human. And each human is going to be augmented

01:39:44.380 --> 01:39:50.060
and control a fleet of AI's, right, that are doing its bidding. And that's okay. Maybe the human

01:39:50.780 --> 01:39:56.140
employees become the control systems for a fleet of AI to do most of the work, right?

01:39:56.140 --> 01:40:01.740
Maybe they become more kind of like the capital allocators or the executives of companies that

01:40:01.740 --> 01:40:07.580
are mostly AI for the execution layer, right? Maybe that's the future. I think we're heading

01:40:07.580 --> 01:40:12.700
towards interesting times, but I don't think there's going to be cataclysmic effect. I don't

01:40:12.700 --> 01:40:16.620
think it's going to end humanity. I think we're going to adapt and the system will adapt. And

01:40:16.620 --> 01:40:25.260
the sort of EAC is all about the main, like it's a faith and sort of worship of this adaptation

01:40:25.260 --> 01:40:29.660
of the Homo Techno Capital Mimetic Machine, the whole thing, right? Like memes, technology,

01:40:29.660 --> 01:40:34.220
capital humans, it's all coupled. It's all adapting. It's always shifting. It's always,

01:40:34.220 --> 01:40:38.940
the only constant is that it's always changing and it should be always changing and it seeks to

01:40:38.940 --> 01:40:44.940
grow, right? And so, you know, we have a faith that the system will adapt. It might be abrupt.

01:40:46.220 --> 01:40:54.380
And so, you know, personally, I'm not trying to, personally, I'd rather augment humans in

01:40:54.380 --> 01:40:58.220
orthogonal directions to human-like intelligence rather than trying to replace human-like

01:40:58.220 --> 01:41:03.340
intelligence. Obviously, in an economy that's already shaped to take in human intellectual

01:41:03.340 --> 01:41:09.740
labor and do all sorts of produce products, like, you know, having human-like AI is what's

01:41:09.740 --> 01:41:13.900
going to grow the fastest. So that's what's being built first. But I'm already pricing an AGI,

01:41:13.900 --> 01:41:19.100
personally. And the technologies we're building hardware and software, I'll assume there's probably

01:41:19.100 --> 01:41:25.980
going to be a human-like AI, human-level AI within two to three to five years, right? And that's

01:41:25.980 --> 01:41:30.940
been priced in for me, right, mentally. And it's like, now what? What's the next thing, right? And

01:41:31.020 --> 01:41:37.980
to us, it's like, we're going to seek to grok and perceive, predict, and control matter at the

01:41:37.980 --> 01:41:42.700
nanoscale, right? And then we're going to, you know, we're going to seek to, again, increase the density

01:41:42.700 --> 01:41:49.500
of intelligence in terms of the substrate that's what we're working on. And so, yeah, I think,

01:41:50.060 --> 01:41:54.060
yeah, like, I think it's coming. I don't think it's going to be cataclysmic, but I think that

01:41:54.620 --> 01:42:00.860
people should start preparing and start integrating their business processes,

01:42:00.860 --> 01:42:06.860
integrating their personal life and their personal workflow with AI, right? There's going to be the

01:42:06.860 --> 01:42:13.660
class of sort of the tech forward people that embrace AI and sort of do well, right? They

01:42:13.660 --> 01:42:19.580
integrate with it and those that refuse to use it that don't do so well, right? But the important

01:42:19.580 --> 01:42:26.140
thing is that if people get to own a piece of the system in which they're contributing,

01:42:26.860 --> 01:42:32.380
at least they own a piece of the future as it grows. Whereas if they, there's only centralized

01:42:32.380 --> 01:42:37.740
players from which you, you, you have to pay rent constantly. And maybe they'll give you a

01:42:37.740 --> 01:42:42.540
sprinkle of UBI at the end. That seems pretty dystopian to me. So that's the future we're trying

01:42:42.540 --> 01:42:48.060
to prevent. I don't think the disruption can be stopped at this point. It's, it's coming. And

01:42:48.380 --> 01:42:52.140
the only question is like, who's going to own the future? I think it's a good place to put it.

01:42:52.140 --> 01:42:57.580
Questions than that, actually. But I'm going to have to hop to, but I think you have needs to go.

01:42:57.580 --> 01:43:01.980
Can I ask you one last, it literally is a 30 second thing, by the way. One of my employees,

01:43:01.980 --> 01:43:06.300
he was digging up some of your old videos. He, he saw that you had a four hundred and five

01:43:06.300 --> 01:43:12.220
pound bench PR. Is that actually true? Yeah. He was very impressed by that. Yeah. Yeah. I mean,

01:43:12.220 --> 01:43:18.060
I was, I played, I played college ball, college football. I have a friend who's a doctor in the

01:43:18.060 --> 01:43:24.460
NFL, played with a great friend. And yeah, I mean, I just kept lifting after football. And,

01:43:25.340 --> 01:43:29.180
you know, to me, it's just been like, I was a mathematician and I was a power lifter. And to

01:43:29.180 --> 01:43:35.900
me, it's just like engineering signals in order to have neural adaptation. And it's all one in

01:43:35.900 --> 01:43:41.900
the same. And so, yeah, I mean, you know, the best Jesus character, it's all about mind and body.

01:43:41.980 --> 01:43:49.260
And, you know, I, I do like to cultivate strength and, you know, push, push myself to the, to the

01:43:49.260 --> 01:43:54.700
limits to some extent. And yeah, that is a, I'll just post the video if you want. I'll tweet it.

01:43:55.980 --> 01:43:58.780
Well, he found it. I have no idea how he found it on Vimeo, but I'm impressed because, you know,

01:43:58.780 --> 01:44:03.420
a lot of this transhumanism business is very agnostic and kind of denying the physical, but

01:44:03.420 --> 01:44:06.780
you're actually embracing it. And yeah, that's also other conversation. Thanks for making time.

01:44:06.780 --> 01:44:10.460
I'm going to have to hop off. I assume everything will upload when we all hop off. I'm not sure

01:44:10.860 --> 01:44:13.660
Erica's number disappeared before. So I literally have no idea what's going to happen.

01:44:13.660 --> 01:44:17.900
All right, to be continued, guys. And yeah, definitely to be continued.

01:44:17.900 --> 01:44:20.620
And one of these days, I want to talk crypto and AI with you when you're over the whole

01:44:20.620 --> 01:44:23.660
hump of fundraising and all that stuff. Cause I've been thinking about this whole thing for a

01:44:23.660 --> 01:44:30.460
long time and I'm very, yeah, I'm impressed. Okay, cool. Awesome. All right. See you guys. Cheers.

