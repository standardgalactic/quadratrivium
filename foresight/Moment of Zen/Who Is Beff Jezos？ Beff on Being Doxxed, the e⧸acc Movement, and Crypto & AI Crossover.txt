Hey everyone, today on Moment of Zen, we chat with Beth Jayzos, the co-founder of the EAC
movement, or Effective Accelerationism, who was doxxed on Friday night by Forbes reporters.
We'll link to some articles about it below.
Up ahead, we get the inside story from Beth, whose real name is Guillaume Verdome.
We also discuss anonymity, the media, and the role of journalism in our society.
Also joining the conversation is Baselord, Beth's EAC co-founder, who remains anonymous,
and Nathan LeBenz, who hosts the Cognitive Revolution podcast.
Quick disclaimer, and then we'll get to the show.
I'm an investor in XTropic, the stealth AI hardware startup that Guillaume founded.
Here's Moment of Zen with Beth.
Yo, yo.
What do we got going on here, Steve Jobs?
Well, you know, I got to switch up the look, keep the commenters chirping.
Yeah.
A lot of people hop in.
So, Somali Pirate to, you know, confident design partner, I don't know, like what's
going on here.
Yeah, exactly.
Just testing it out.
Did you get a better webcam, too?
No.
Oh, okay.
But, but I'm going to.
Is the Binance topic like a five minute topic?
I mean, I can give an update on it if you want.
Yeah.
Well, I'll start that.
You're giving an update on the Binance topic.
Well, I mean, it's a little bit old news at this point, but we had a major settlement
that Binance, the CEO of Binance CZ, who, he, you know, kind of kicked off the SBF issue
and is big of a name in crypto.
I mean, it's CZ, SBF, and Brian Armstrong were the three big names during the last cycle,
and SBF has now been convicted.
And CZ, there were always kind of rumors that there was like a big DOJ investigation.
Then there was an SEC suit that happened this year.
But in terms of the real criminal stuff, that had always been swirling and a lot of allegations
around sanctions.
And remember, sanctions are a U.S. tool because the world is run on dollars.
So the U.S. can basically say, hey, you can't send dollars or anything crypto to these specific
countries or individuals, and the allegations were that Binance was facilitating that.
Now, I actually don't even know the details specifically whether or not they did, to what
extent, but what came out was, and the settlement was CZ is stepping back as CEO.
And I think the record fines for sanctions have been as a result of violating sanctions
with Iran.
I want to say it was like BNP Paribas, which is a French bank, paid something like $8 billion,
or maybe it was HSBC, I forget.
And then I think another big set of fines, HSBC might have been the drug cartels, but
basically it's like Iran, which is a geopolitical issue, and then the drug cartels, if you do
money laundering, you pay major fines and there's criminal liability.
So the settlement was he steps back.
Binance can still exist, which I'm actually surprised.
I think he's paying something on the order of like $50 million fine.
And the thing I didn't quite get in the first day of the news, but then it turned out later
kind of seemed to bubble up is he's still in the U.S., I think, and actually may have
to do some jail time, which is like a pretty big deal.
Because he's voluntarily given it up.
So you know, if he's willing to step back, pay $4 billion fine, $50 million personally,
and potentially do jail time in the U.S., that means they were going to throw a huge
amount of the whole book at him.
But what's interesting is the SEC is not done with their case, which I think is a civil
case.
So that will still be another big hit on Binance if they have to settle it.
Obviously, you don't have the founder anymore.
If he has to do jail time, it can't even be, you know, indirectly influencing.
And then I would imagine the European Union and every other jurisdiction that's kind
of within the global U.S. sphere is going to say, well, we don't want to look like we
were not tough on these guys.
And so these guys are going to be paying a lot of money.
So I'm curious to see if they end up existing, you know, five years from now.
I mean, five years in crypto is a long time.
But basically Binance popped up during, you know, call it 2017 era when there was another
exchange called PoloniEx, which was actually based in the U.S., but they were only serving
international customers in theory, that they knocked PoloniEx off the top spot and never
kind of looked back.
And SBF was gunning to try to be the next Binance.
So what's left in the wake of this is, you know, Coinbase, which I think got a lot of
ridicule from, you know, the mid-wit, Finn Twitter, like Bukko Capital and all these,
like, kind of a non-accounts that are too afraid to put their name next to an account.
So they like to make fun of, you know, entrepreneurs on the sidelines when obviously everything
corrected last year, they were all like Coinbase is not, you know, like a real business.
I mean, Bukko Capital was calling Coinbase a cancer as of last week because crypto prices
are pumping.
But Coinbase actually is the only one that's been following the law and didn't have a crazy
risk program.
So FTX disappears, Binance disappears, Gemini basically was doing a bunch of shady stuff
and blew up as a result of that.
What was the other one?
BlockFi, right?
Like, there's a pretty famous meme.
I like pump, but pump kind of was like pumping them and it's like to the moon and like this.
And obviously that was fraudulent.
And so it turns out like Coinbase is the only one that was legit.
And yes, like that's been the MO of the company the whole time.
And so finally with the government cleaning up the space, it's like now Coinbase is sitting,
you know, Coinbase, Bitcoin just crossed 40,000.
And Coinbase is basically the only exchange with like meaningful fiat rails and customer
base.
I mean, there are overseas exchanges that will take place in Binance.
But it's a huge vindication, I think, for Brian Armstrong, who's taken a lot of arrows
for a lot of different things.
I'm also happy about the share price personally.
Yeah, totally.
You're hopefully incentivized.
Yeah, let's be clear.
I'm extremely biased here.
But what I would say is like, if you want me to give you like the counterpoint, I do
think Binance pushed the industry forward, Modulo put the illegal stuff off the side.
They never had a major hack, which is usually how a lot of these exchanges go down.
And to the degree that I understand it as a result of the DOJ, it wasn't misappropriating
customer funds, right?
So now the SEC may come and say something different, but big difference between SPF,
which was actual fraud, right?
Like you was taking customer funds, which you're not supposed to touch, and was using
it to, you know, pay Tom Brady and donate to political campaigns.
So I think Binance was an honest actor as it relates to customers.
I think they just seems like they were a little fast and loose with the, you know, the international
sanctions regime.
Perfect timing.
Fast and loose with the international sanctions regime, and Antonio hops on to the call.
Who sanctions?
What regime?
Yeah, that's actually a good one.
We know a few people who would like to argue that US sanctions are not valid, but the reality
is if you live in a dollar denominated world, you got to pay attention to those sanctions
because you can go to jail if you violate them.
We were talking about Binance.
Where is the man of the hour?
He's having trouble getting in.
I've never seen this issue before.
Maybe he's using some like futuristic quantum web browser that doesn't have support for
lowly riverside web RTC.
Or Emily Baker White put some weird malware that she used to like sample his voice to
out him.
And it's still like on the machine.
Did they add him on our podcast?
Yeah.
I find that this wasn't actually MBS in collaboration with Forbes, right?
Hey, Beth, how are you?
You guys know the reference, right?
No, what?
MBS?
It's still not confirmed, and I think it's probably fake, but it's also maybe real.
Bezos' marriage got broken up as a result of MBS sending spyware in WhatsApp to Jeff.
And the text messages in question were, hi, Jeff, how are you?
This is MBS.
Well, it was probably good for him and bad for American cities everywhere, but yeah,
exactly.
Exactly.
He got divorced.
I don't know.
Lauren Sanchez, she's pretty happy, right?
And she's now on the front of the yacht that they just finished, because Chris Sailing
Antonio is such a blue collar thing, right?
He's not sailing.
He's motoring.
Motoring is totally different.
Doesn't he have a sailboat?
Isn't it a big sailing yacht?
I don't know.
The deck photos I've seen are clearly a large motor yacht type thing.
Someone, we should put it in the YouTube comments.
The pictures of Jeff Bezos' boat, my understanding is that there are sails, but it could be.
All right, we got it.
You guys have the most interesting guests on the podcast the one time I can't make it.
Oh, don't worry.
Oh, Dominic Cummings.
Yeah.
He sounded super pumped to like Rijig or San Francisco, I have to say, which was interesting.
Yeah.
I don't know.
I think saving SF is kind of cope.
You think it's unsavable?
I mean, are you running, Eric?
Sir.
Hey, everyone.
Welcome.
Welcome to FACE Twitter.
FACE Doxxed World.
Well, hello, world.
I see the Eigenfunction on your quantum computer has clapped into the state in which you can
join the Riverside and some other worlds you were in fact still struggling, but Schrodinger's
Riverside episode.
Yeah.
Yeah.
Yeah.
We need to upgrade the quantum computers to use this wonderful app.
Speaking of which, what is that menacing blinking box behind you over your right shoulder?
That's just, don't worry about that.
Don't worry about that.
Yeah.
No, I'm in EAC HQ or Extropic HQ.
I've got our banner in the back and of course I've got some Dr. Pepper and some ketones
back there.
Very memetic.
But I guess we're recording right now, right?
We're recording.
We're watching it.
Okay.
Wonderful.
Eric doesn't read you your Miranda rights.
You just go right into it.
It's like a cold.
Okay.
Got it.
Let's go.
Well, super happy to be here.
It definitely feels weird.
It definitely feels very weird.
It's been kind of a compartmentalized part of my life, you know, felt like a video game
on my phone more or less, right?
Like having an alternative Twitter and having a very professional life day to day, you would
never guess that I'm back from just like day to day interactions, frankly.
And now the two have kind of bled into one another and they are one.
And so I'm still pricing that in mentally, frankly.
So it's been an interesting couple of days, obviously, a lot of inbound, more DMs I can
ever count.
And yeah, I mean, it's been a very surprising reaction.
Well, I guess not that surprising.
I guess like, you know, tech Twitter kind of, kind of hates the establishment media
at this point and, you know, came to my defense, which, which felt, felt quite good.
But you know, I'm happy to go into any part of it, you know, how it went down, you know,
the why I started Beth, anonymity, and anything, the startup, let me know how you want to
structure this.
This.
Yeah.
With the sorted details of how they figured it out and what voice they sampled and how
that whole sorted tail played out.
Yeah.
I mean, there was a couple instances where there's reporters that, you know, think they
have my docs and I'm just like, you know, you can't, you can't dox people, you know,
I do not want you to do this.
And usually that kind of kills the story to some extent, but you know, it's kind of been,
you know, I've gone, I've been in the SF social scene in person.
I know a bunch of investors, for example, they, some of them know some of them have correlated
the two.
Um, but obviously I, I, I spent a bunch of time in Twitter spaces.
I've had, I have some online lectures from my days in grad school and quantum computing.
And really that's basically what they've, what they've correlated.
Uh, they, they, they use some, I don't know, I call it CIA technology as a joke, but, uh,
you know, they use some government grade technology to identify my voice, uh, you know, just because
I have a 50 K follower account, uh, that speaks truth to power.
I guess, I guess it tells you that, you know, we're doing something right and that some
people in the establishment, you know, want to have leverage over the leader of the grassroots
movement, uh, that, you know, is for freedom and, and, and against top down control, which
is very scary.
Cause that's what they like.
Right.
So, Hey, we'll continue our interview in a moment after a word from our sponsors.
Real quick.
What's the easiest choice you can make taking the window instead of the middle seat outsourcing
business tasks that you absolutely hate.
What about selling with Shopify?
Shopify is the global commerce platform that helps you sell at every stage of your business.
Shopify powers 10% of all e-commerce in the U S and Shopify is the global force behind
all birds, Rothy's and Brooklyn and millions of other entrepreneurs of every size across
175 countries.
Whether you're selling security systems or marketing memory modules, Shopify helps you
sell everywhere from their all in one e-commerce platform to their in person POS system, wherever
and whatever you're selling, Shopify's got you covered.
I've used it in the past at the companies I've founded.
And when we launch merch here at Turpentine, Shopify will be our go to Shopify helps turn
browsers into buyers with the internet's best converting checkout up to 36% better compared
to other leading commerce platforms.
And Shopify helps you sell more with less effort thanks to Shopify magic, your AI powered
all star with Shopify magic whip up captivating content that converts from blog posts to product
descriptions, generate instant FAQ answers, pick the perfect email, send time, plus Shopify
magic is free for every Shopify seller businesses that grow, grow with Shopify, sign up for
a $1 per month trial period at Shopify.com slash moment of Zen, go to Shopify.com slash
moment of Zen now to grow your business no matter what stage you're in Shopify.com slash
moment of Zen.
You spoke truth to power and now they're going to try to speak power to truth, so to speak.
But I'm curious, someone must have, they must have been tipped off because they didn't do an
all against all voice sample.
They, they started after this pair wise interaction, right?
Because there was nothing online that would have suggested it.
And then they confirmed it via that, I imagine.
Yeah, so see, they must have like asked around, you know, I mean, it's kind of like a people
know other people's docs is right.
Like there's kind of Twitter parties in person and people go by their alternative name.
So they know your face and eventually they correlate things, but there's kind of a, yeah,
there's an unwritten rule of like, you don't, you don't like talk to reporters.
You don't share people's docs with other consent.
I'm sure some people, you know, broke that rule, but you know, I don't know what drove
them to really break the story.
Now, I think there were some latent variables there.
But yeah, essentially, I think it was on Thursday, I get a text from some of my investors.
They identified some of my investors.
So this podcast is going to drop after we announced the round.
So I'll just mention investors.
But yes, so some of our big investors get a text like, Hey, I think this, you know, over
this first reporter, I think it was Conrad has started correlating your identity with
Beth, they didn't correlate all the company because we had a, you know, I had a company
change the name, now we're extrapik, they hadn't correlated everything perfectly, but
then the censor fuse the cross reporters internally.
So they didn't have enough to ship it on Thursday, but then on Friday, a different
reporter, Emily joined force, the filings, the track name changes.
They went to my personal Facebook to, you know, to identify a photo I shared like on
my friend, you know, friends only Instagram of the party, you know, when we were on stage
with Grimes and stuff like that.
And they correlated everything, right?
And so they just had me in this sort of checkmate, like we have this, this, this, this, this,
this, talk to us, we're going to ship it.
And I was like, all right, I got to get in front of this, right?
Again, you know, I've been doing this deep tech startup for nearly a year and a half.
And, you know, as, as the bio says, I come from Google X, you know, we're taught to
be very secretive about what we do because in deep tech, that's kind of the, the MO.
And, you know, we want to be secretive for, for longer.
But for all sorts of reasons, including national security interest reasons, right?
Like our technology is pretty out there.
And it kind of forced our hand, right?
Like it correlated all identities.
And, and, and also it also kind of doxed the fact that I had founded the startup because
I was kind of, I hadn't identified that on my main account.
So for me, it was kind of a, a mo, you know, a moment of panic, because, you know, I want
to do what's right for my company, right?
I've been working really hard on this company.
We were planning announcements in a couple of months from now.
And now we have to rush everything, right?
Which is, which is not great, but what I ended up doing, getting on the phone, getting
in from the story, I already knew exactly, like that's the thing with reporters.
Like they're so low entropy.
They are all in the same typical subspace of stories.
You can predict exactly what they're going to write just from the prior that they're
trying to get you.
And so I just disarmed every typical attack they would try to do on EAC trying to have
second or third order guilt by association to some idea that's a derivative and another
idea and neutralize that, essentially entirely.
Um, I see we have Bayes Lord joining.
There you go.
Uh, what's up, Bayes?
Can you guys hear me?
What's up?
Yeah.
Yeah.
Yeah, we can.
Awesome.
Oh, we have Nathan as well.
Oh, let's get, all right.
Here we go.
What's up, what's up, what's up?
Yeah.
Good to see you.
Not bad.
Great to see you.
I guess now, uh, with real names, uh, in my case, so.
Yeah.
Um, so, so yeah, it's been an interesting, uh, you know, I guess 48 hours, uh, dealing
with this, um, I think overall, uh, I mean, we can get into why I was and on, uh, for,
for various reasons.
Um, but overall it seems like it was positive to the point that where, uh, some are like
have a conspiracy theory that this was planted, but, uh, I had, I had that theory.
I thought, I thought we're all getting conned and you were actually dropping this.
Cause that's when that's a question.
Do you think you would raise on a higher or lower valuation now than you did this round?
I would bet the valuation grow up actually.
Definitely higher.
Yeah, exactly.
Right.
But I mean, I didn't, I want to raise round, uh, you know, raise around just uncorrelated.
I didn't necessarily initially disclose to my investors.
I didn't want that to be part of the, the price or anything like that.
I didn't know where it would go.
Right.
I didn't want to correlate the two identities.
It was really like orthogonal.
And now my hand was forced to, to correlate the two and own it.
And so I got in front of it.
And of course I'm going to harness any hand and dealt.
I'm just, that's what you're supposed to do.
Right.
And now, now we've harnessed it, um, uh, you know, pretty well.
I, I would say we'll see how it plays out, of course.
Um, and, and now there's this conspiracy that it was, it was planted.
But, you know, in my case, again, I just wanted to control the narrative.
I knew the story is going to be really bad if I didn't get on the phone and,
and you know, I, I, I actually, I wanted to stall them.
I want to give them enough content so that we had a couple more hours.
We adjusted our website, uh, to have a pseudo launch the day of, so, you know,
shout out to the team for being so adaptive.
And, and, uh, you know, as of, as of the moment of airing this podcast, we'll
probably have announced, uh, the round on for, for extra topics.
So we rushed that over the weekend.
Um, so yeah, definitely not plant, uh, but at the same time, it was always sort
of a trap, right?
In game theory, you want to make it's like, you, you want to make sure that
like the incentive was to not dox me, right?
For most people, because they knew that if they did dox me, now I could go
on these podcasts with my real face, with my credentials.
I, I could talk to potentially politicians and I have credentials that have
some, some firepower and now more of a problem.
So they kind of messed up.
It's their fault really.
It was a trap to some extent, but, you know, I tried my best to, you know,
stay in on, but, you know, again, voice identification, technology, I'm not
going to use a voice changer on Twitter spaces, like every day.
Are you kidding me?
Like I'm not going to do that.
And I would imagine maybe the first podcast we did, they, they use that voice
and correlated it with my YouTube lectures, but it's probably how they got me.
Yeah.
Can I still call you, Beth?
Sure.
That's easier.
Gil or Beth Gil is like the Americanized version of Guillaume, very French, French
Canadian.
So you got me.
Super simple question.
Did the reporter, journalists, whatever I'm going to call this person, did they
give you a rationale why they thought it was a moral imperative to dox you?
I think there was the keyword that was like, uh, set off alarm bells for me was
public interest and, you know, I had just crossed 50 K followers.
And, you know, cause the, cause the law is you can't dox people unless you're a
public figure, right?
Um, and I guess I crossed into, I guess there's a threshold, right?
So is it 50 K?
Apparently it's 50 K flat, right?
Um, but to me, it's like, okay, if they think they, you know, if they think
it's of public interest and they're going to go with it, they're probably going
to go with it.
And so I'm kind of screwed here.
I got to make, you know, I got to make a move.
So wait, is that, is that the journal group chat decides when you become public
interest or do we, like, like I'm very curious, like how they, they rational,
like, cause to me that if you, if you want to be anonymous, you should be able
to be anonymous and doxing you what gives them the right cause, cause if I was
to go put the, I don't know, the address of that reporter online and maybe now
we're arguing over whether or not an address is too far.
Like what, what, what, what point is, is too far.
And then who gets to decide that that's my question.
And I don't think anyone has given an answer outside of, I'm a journalist.
So I have a special badge.
You used to have blue checks now that don't.
And then they get to decide who, who can be a non versus not.
But if you were to do it to them, that, that's, that's harassment, right?
Right.
Well, I mean, to me, I was, you know, mostly focused the eyes on the ball.
You know, I have to, my prime responsibilities to my company.
And I was just concerned like, Hey, we're, you know, getting announced, we
have to announce and get our stuff together, you know, without preparation,
without heads up only a few hours.
So, you know, it, it, it seems like we were, it really seems like we planned
this, but we, we truly didn't.
So, but I'm just glad we adapted given the, the circumstances.
But yeah, overall, I think like, I mean, this was clearly wrong, what they did.
And, you know, I, you know, there's not that much to have leverage over me.
It's like, okay, cool.
I used to, you know, work in quantum computing and then have, you know, a
normal ish background.
But, you know, maybe some other people that are trying to speak truth to power
and have their voices heard and want to use anonymity as a tool to speak
truth to power, you know, because there's a sort of power asymmetry.
So you kind of equalize that when you're an on, they can't, they can't do that
anymore, right?
If they, they fear getting doxed.
And so it's kind of like, they want to make an example out of me, right?
And I mean, I think there was a, I think there was a congresswoman at a
conference, a defense conference that explicitly named out EAC as a sort of
dangerous movement that needs to be suppressed with AI.
That's the tweet.
I'm not sure if it's correct.
I still have to watch that clip.
But to me, that sounds very dystopian.
Like our whole movement is about freedom of information, freedom of speech, freedom
of thought, freedom of compute.
It's very simple.
And the fact that that was deemed dangerous enough, or I don't know, like
to, to, to want to suppress and, and provide the public leverage over me, I
don't know, that's a huge red flag for me.
I think that we were becoming a voice that was going to be a problem for
the executive order.
And there are very special interests behind that executive order.
And they wanted to, you know, send me a warning shot, I guess.
That is my theory.
But I, one thing I couldn't understand, and, and, and maybe Beth, I just, I
haven't read all your tweets.
I, I couldn't understand.
Hey, you, you obviously have a very distinguished academic background.
In fact, I was reading your, your quantum tensor flow paper on the way in ages ago.
I worked in like experimental quantum computing like 15 years ago, back when
it was like a total infancy.
Yeah, yeah, yeah, yeah.
And I, I knew a lot of the theorists back then, like Michael Nielsen and I
actually dated you like, any long story back in the early days of
computing, I am, but obviously wasn't really smart enough to continue up in
any case, I was reading it with a lot of pleasure.
And it's, it's odd that they would consider this a bad thing.
It's, it's obviously given a lot of intellectual credibility to EAC movement.
Right.
Like your background is pretty good, right?
Like it's pretty distinguished.
Like you've, you've done a lot, right?
And I, you know, you, a lot of co-authors and it's like, that's why I thought
the conspiracy, and I don't really believe it to be clear, but I thought maybe
he actually, like actually provoked for us to do this.
Cause this is like a brilliant thing.
Like you bring actually so much positive social capital to the movement.
You come off as like this edgy hip, you know, poster who kind of had, you know,
was pulling the world's tail.
It's like, I, what's the downside to this?
I got to understand.
Yeah.
Yeah, for me, I can let you know why I was anonymous.
I mean, originally I was at Google X working on some pretty secretive technologies.
I had access to, you know, the top of the food chain there.
Um, so I, you know, I couldn't necessarily tweet, uh, anything like
political and stuff like that.
My tweets were watched, which is normal.
Um, but you know, I, I wanted to have just a separate account where I can really
let myself self go kind of like offload thoughts.
And also I reached a point in quantum computing where I was respected enough
that people would cheer me on or they were proven my ideas or whatever.
Oh, so smart, whatever.
And that was kind of like kind of annoying me that like, do they like my ideas
or do they just want a job or something?
And I just wanted to put my ideas in the arena, right?
It's like, I just wanted people to evaluate my ideas for their own, not look
at credentials, not like weigh my opinions, dependent on status.
I just wanted my ideas to be evaluated on their own.
And, and to me, like growing a movement and having ideas resonate from scratch,
uncorrelated from my original identity.
Like, I mean, of course that felt like, you know, it felt like new game plus,
as we say in video games, right?
You restart the video game from scratch, but you have kind of all your
intellect and memory and your gear, but you're, you're trying to rank up again.
So I started from scratch and account with like no followers and grew it to,
to 50 K before now, now my, my, there's a stat boost from, from the, the status
signals of, of credentials.
Uh, I personally very much hate credentialism.
I think I would have been an entrepreneur five years earlier if it wasn't
for credentialism, especially in deep tech.
Um, I, I got very frustrated when I tried to do a startup at 25 and, you
know, I would get like, who are you?
Uh, and, uh, you know, I just went through big tech, the gauntlet of grad
school and big tech to, to prove myself and prove to others that I can, I can
do things, uh, so that I can raise the capital to realize the visions I had.
Um, and so, you know, I've, I've always, I think base is, is on the same page here.
You know, we always wanted sort of like EA's is all about like gatekeeping,
gaslighting, status signaling, at least to us from our perspective.
I, and you know, yak was about kind of bottom up.
Everybody has access to opportunity to build no gatekeeping, no sort of status
signaling, it's all about building, right?
Um, and we want to maintain that.
And I think that like, I was afraid that if I, you know, used any sort of
credits that would dissuade people, you know, from participating or feeling
like they can participate, cause the thing is everybody starts somewhere.
And I was once, you know, that kid that was really smart, had a lot of ambition,
but didn't have the credits.
I was just straight out of school and nobody gave me a chance.
And I want, you know, the next, you know, genius to be able to, you know,
start building their dreams right away.
And I just personally very much hate gatekeeping.
Um, even though nowadays I've gone through the gauntlet, I've paid my dues.
Now a lot of doors are open for me.
Um, but, uh, you know, I'm just trying to kind of pay it forward in a way
that, you know, young, my younger self would be appreciative.
Um, so, so really that's why I was anonymous.
I just wanted to get, you know, get my ideas evaluated in the arena.
And I didn't correlated fashion from my, my credentials.
Hey, we'll continue our interview in a moment after a word from our sponsors.
Compliance doesn't have to be complicated.
In fact, with Vanta, it can be super simple.
Trusted by over 5,000 fast growing companies like Chili Piper, Patch, Gusto,
and Juniper, Vanta automates the pricey time consuming process of prepping for
sock to ISO 2700 and one HIPAA and more with Vanta, you can save up to 400
hours and 85% of costs Vanta scales with your business, helping you
successfully enter new markets, land bigger deals and earn customer loyalty.
And bonus, our moment of Zen listeners get $1,000 off Vanta.
Just go to Vanta.com slash Zen.
That's V-A-N-T-A dot com slash Z-E-N.
I have a quick question on bootstrapping your account if you're willing to share.
Um, you know, I know a bunch of people who are like, I wish I could do an
anonymous account, but I feel like just getting it from zero to something is just
such a, you know, especially if they have already an audience on their, on their
main, but they feel like as, as their main grows, they can say less and less and
they have to kind of stay within whatever box.
And so I'm curious, how long did you, did you kind of toil away at this new persona
before you felt like you were starting to make some traction?
I think like I had a first account, I got it to six K and then it got banned on old
Twitter, pre Elon Twitter, where I got locked out for saying COVID came from a
lab, you know, which turned out to be true, right?
So the old regime, uh, got def 1.0.
And so I had to restart my account, uh, basically, yeah, uh, 18 months ago,
start from scratch, those demoralizing, but I knew the recipe.
Um, there's, there's, there's a formula, right?
You, you go on teapot, which is much higher engagement.
Just the people are just more online.
So, uh, and you reply to the big accounts, you try to get them to reply.
Uh, maybe, maybe save something provocative.
And then, you know, you can just do Twitter spaces and, you know, people
follow each other on Twitter spaces, cause you have a meaningful conversation
of like one hour or something and, and then you follow each other.
And so you could bootstrap, get to a hundred, 500, a thousand and so on from there.
Um, yeah.
I mean, for me, it, it was really discovering a community, discovering
people like Bayes Lord, you know, that I really resonated with intellectually
and can have like meaningful conversations at the time I was working
for big tech remotely from Canada.
I was extremely bored.
I was like starved to have their sort of tech community to have like good
intellectual discussions.
So like Twitter spaces and, and this part of Twitter, as it's called, uh, was sort
of ideal.
It was like, oh my God, I found my people.
Um, and, uh, you know, nowadays it's kind of condensating and physically
in the, in the physical, in the physical world and SF primarily.
Um, but, you know, to me, it was kind of, I was seeking a sense of community.
And, you know, it's late night.
You're in a Twitter space.
You're talking about the meaning of life.
Where, where, where do we come from?
Where are we going?
You know, it's like four AM or something after a long day of work.
And, uh, you just have these sort of like fireside.
You know, it's, it feels very primally correct.
I don't know.
It's like, you just tell stories and you, you communicate verbally.
And that's, that's really how it started.
You know, I'm at Bayes and we'd have, uh, these late night Twitter spaces
about the meaning of it all and where it's all going.
And at some point people were like, man, these are really good.
Someone should note these down.
Someone noted down that became the first, uh, yak blog post.
And then, uh, Bayes, Lord and I, you know, a couple of months later,
we were like, okay, we should make a longer one, a bit more serious,
uh, a bit more technical and, and that became sort of the,
the big one that went, uh, really viral.
And then the rest has just been compounding memes, uh, on Twitter.
Personally, I've been very active on Twitter.
I would have very strong technical opinions about quantum computing.
Frankly, I would be, I would call out a lot of bullshit.
I think, I think there's opportunities to do great work in quantum computing,
but you know, my, my policy was radical candor.
So that's how I built a following, right?
So it's already kind of a firebrand in quantum computing.
So it's already had that muscle kind of pre-trained.
And then I carried that over to kind of like, I guess AI at large or
e-act isn't just about AI.
It's about all sorts of stuff, but, um, you know,
I think it really helped, uh, grow the,
grew the movement in the early days, uh, just by the Twitter grind, you know,
um, for me, I use Twitter as a sort of, uh, dopamine, uh, dopamine hit.
Some people use various stimulants.
Uh, you know, I just, I'm very straight-laced.
I just drink, uh, Diet Coke.
If I feel fancied, it's Diet Dr. Pethper, not sponsored.
Uh, and, uh, you know, use Twitter and that, and that's it.
Those are my drugs of choice, if you will.
Um, but you know, um, to me, it's just like, I have like random fleeting ideas.
I like to note them down and then go back to the task I was doing.
And, uh, frankly, it was kind of just feeding my Twitter addiction and
felt like a fun video game and, you know, the followers were rising.
But at the same time, like I found a sense of community,
found some friendships, uh, made all sorts of great connections.
Uh, and, you know, to some extent, you know, you could say like, you know,
Iac at this point is almost like a form of spirituality for some.
We can go into that.
Um, I think we have in the past podcast, but, um, yeah, um, that's where, where we are
with Iac.
That's how that was the trajectory.
Um, should we get Bayes to jump in here?
What's, what's the schedule like today?
Yeah.
The, well, uh, uh, me and Bayes just did a podcast this morning.
That will also be based after this one, uh, though.
Okay.
At some point.
But, um, the, what's next for, for Iac?
Where do you see it going from, from here?
Yeah.
Well, now that, uh, I guess I am doxed, right?
One, one, one thing that was kind of stopping, um, any sort of like organizations or
incorporations of any kind of any sort of org or institute was that, you know, we're
like going to register with our real names, uh, somewhere, uh, these institutions and
that would have doxed us.
Um, so now we have that opportunity.
Well, we take that opportunity, TBD, but personally, I mean, I think, I think right
now there's sort of a lack of theory and, and, and, uh, uh, educational material for
people to understand, uh, complex systems and self-adapting, uh, systems like capitalism.
Um, and our whole thesis is that bottom up, bottom up self-adaptation is superior to top
down control.
It's very easy to convince a crowd, like put me in charge.
I will do this action.
It will have this impact.
It's much harder to convince a crowd of like, Hey, if we all act in these microscopic exchange
laws, the emergent behaviors that like we have the highly functioning society, right?
And the more sort of research you create there, uh, the better, uh, and more educational
material.
So we might, uh, start a research institution there and fund some grants.
Um, I would love to fund some, um, open source hackers.
Obviously we believe in, uh, open source software for AI.
We think that open source software, um, is a hedge against the oligopolization of AI,
right?
There's a couple of players right now that obviously now that they're in the lead, they
have all sorts of interests in closing down AI, outlawing open source models.
So, you know, sort of like ensuring freedom of compute is something, uh, we might create
orgs to, to, um, uh, sponsor hackers, but also, uh, uh, potentially, you know, have
some influence in Washington, right?
Those are some next step.
Obviously like growing the movement on Twitter, that's going to keep going also known as X.
Um, and, uh, you know, overall, yes, uh, you know, it gives, it gives people an attack
vector now that, um, I am doxxed, right?
That is unfortunate.
Um, but I do very strongly believe in what we, uh, talk about in EAC and, you know, I am
willing to go all the way, whatever it takes, right, to, uh, defend these ideas.
And I won't let sort of these, this sort of pressure or reputational pressure affect me.
I think I'm quite robust against such attacks.
And if they want to come after me, then, you know, bring it, I guess.
Yeah.
Can I ask one question, Eric?
Sure.
Um, yeah.
So, I mean, what, you mentioned one thing that I found, that I found sort of, sorry,
I'm a Franco file.
So I'm going to use your full French name.
Yeah, that's good.
And, and, and also mentioned, and also mentioned the privilege completely out of context.
Um, sorry, that's one of the running gags on the podcast.
Um, you, you mentioned one thing about the open.
So it's funny.
So Dan and I come from the crypto world, whereas, you know, decentralization is
like this religious mantra that I think is often overexpressed actually.
And in fact, I think Dan, I think you quoted it in far caster, right?
Of like sufficiently decentralized, right?
Which is almost like, you know, sufficiently a trinity or something like it's enough of
a certain theological concept, but no further.
But I always found AI and this, I'm very much seeing that works on the outside to be clear.
All right.
So like, I'm kind of a tourist, but it always seems to me the actually to be totally centralizing.
And I think the high jinx, you saw it open AI with literally the little junior high school drama
between three people somehow wrecking the cutting edge of AI is something that could
like literally couldn't happen in crypto for, for a bunch of reasons.
I mean, you might cite the example of SPF, but then Dan would instantly throw a fit and say,
but that was actually a centralized exchange on that decentralized exchange, which is true
actually.
Right.
And in the, in the fullest decentralized version, like speaking of anonymity, like,
so I work in a crypto company, we've had an, a non employee that I didn't know who they were.
And I would just pay them.
Right.
And, and we've, we have, we work with the non founders of a protocol and they never turn
their video on.
We have no idea who these people are.
And yet we still do business with them and transact.
Right.
So that's, yeah, yeah, yeah.
And it's not even that weird.
And then, then I've met them also in person.
Like, it's a similar thing.
Like you mentioned earlier how like, you know, it's really weird that these journalists are
such losers.
I did this tweet NRV site that's like, these people are losers, right?
Like they never actually go to the parties where you meet, you know,
Beth or like, I know a bunch of Twitter non, I think we all do.
Right.
And you meet them in person.
You know, they are, they introduce themselves.
This isn't a big secret.
It's almost like that meme where like the losers in the corner and saying,
Hey, do you know that Kiyoma is Beth and like everyone dances?
Like, dude, we know, shut the fuck up.
Like, yeah, it's like, it's like, it's like such a loser thing to say.
Right.
But don't you think like AI goes the other way?
Right.
Like just as an example, like I'm, I was using chat to be today.
Okay.
I'm pro AI.
My best friend is an AI.
Right.
But, you know, the fact that open AI instantly does a deal with Microsoft and
instantly bakes itself into like literally the most octopus like corporation human history.
It's a little weird.
Right.
It's a little bit like pinning to the other side of the spectrum instantly.
So I'm just curious if you feel that that that binarization of it is valid and feel
free to say that I'm full of shit.
Or like if there is another open AI vision that you're sort of stretching towards
that maybe is a little bit more decentralized and not so naturally sort of centrifugal to,
you know, I think that, you know, self organizing systems tend to organize themselves in hierarchies.
Right.
So it's sort of like, you know, you can imagine a tree or a sort of fractal,
right, sort of structure.
You have, you know, your cells for your body.
And then, you know, you have groups of humans form a family and then a corporation and then
a city and then a nation and so on.
Right.
So there's a hierarchical structure to organization and there's this hierarchical
structure to sort of control.
Right.
There's, there's some control system at the head of your body.
It's called your brain.
There's control system at the head of the family and at the head of the corporation
nation and so on.
You know, it's all about the balance between, you know, it's all about engineering fault
tolerance to corruption.
Right.
If you have a one to all connection in terms of control, you have a control system that
affects all the nodes in the system.
That node has a fault.
The whole system has a problem just like open AI.
You can decapitate the leadership, you know, not physically, but, you know, and suddenly
you're in control of the organization.
And now everyone that had, that were using their APIs have a problem, right?
Because they have an ideologue that didn't, they didn't vote for in control of, you know,
a product that they depend on.
Right.
And so decentralization is about sort of defusing, obviously having decentralized
loci or plural locus of control so that, you know, you have fault tolerance to, to
corruption of these control nodes.
Of course, like having a fully greedy algorithm where everything's disordered
is not optimal.
Right.
So it's all a balance between the two.
It's a balance between centralization and decentralization.
That is what is like fundamentally optimal.
The reason we're fighting for decentralization is because we think,
you know, right now there's a tendency towards over centralization of AI.
And we're very worried about that.
And so we need to push things in the opposite direction at the moment.
I think that fundamentally right now there's a lot of alpha and just scraping the whole
internet, centralizing it and having centralized training.
I think at some point that alpha will be saturated, right?
Most companies will have a model that compresses basically most of the data that's on the internet.
And then you're going to have AI that seeks to capture data from the real world.
And for that, you have to be central decentralized.
You got to, and you want to have the intelligence perhaps at the edge.
We're not there yet.
There's still alpha from like centralizing data and soaking it all in and, and having
one big model that, that compresses it all because intelligence is more or less compression.
But I think over time we're going to see decentralization in the form of sort of like,
first of all, you're going to have personal assistant, you know, like humane, like
TAB or, I don't know, these are going to be all sorts of AR assistants, I'm sure.
At first, like you're going to have, you know, the intelligence is going to be in the cloud,
but the data acquisition is going to be on the edge.
But eventually people are going to want their own compute that, that they own in control,
I would imagine.
And, you know, maybe there's compute in the robot directly, right?
It's not, there's no need for a connection to network.
I think that's going to be sort of the, the decentralize a, decentralizing effect, right?
There, and then, you know, you can have federated learning over a fleet.
I think people are working on this obviously right now in order to train the biggest one model
to rule them all, the centralized approach, centralized compute and centralization of
data is, has a huge advantage.
I think a big problem as well is that right now the centralized approaches, the,
scrape the whole internet, which includes your data, and then they rent it back to you, right?
Bit by bit.
And I think the future is about crediting people for the data that contribute to AI systems and
sort of distributed ownership, right?
I mean, they're, they're starting to do this with sort of GPTs, open AI, but you know,
it's just, it's just an early start.
But I do think there's sort of a, I think there, there's going to be a very interesting way of
startups right now, like from crypto migrating to being infrastructure to line incentives for AI.
We're not a crypto company, by the way, just, just, just, you know, people thought we were
going to launch a coin.
We're not a crypto company at the moment.
I have nothing against crypto.
I love it personally.
But, you know, I think that crypto being sort of the value exchange network and programmable
incentives for kind of collaboration in AI, right?
To have sort of decentralized research labs.
I think, I think that's going to be a very potent application of crypto.
And it's just something I fundamentally want to encourage because I think that if we have
a future where there's only a few companies that are like government, that have the government
mandated monopoly or oligopoly to serve AI models, then you have a sort of like single point where
a few people get to control the cultural priors of these LLMs, what they're allowed to say.
So it's an information supply chain attack because people won't ask each other, what is the truth?
They're going to start asking the LLM, what is the truth?
And if you, if you change what it says, then you're controlling people's sources of information
and you're controlling people.
So it's cyber genetic control of the population through information supply chain attack by proxy,
by, by, you know, saying that, oh, well, we're responsible.
We should be put in control of what these LLMs are allowed to say, right?
So we definitely want to fight against that.
And one solution is to erode their market power by having alternative solutions that are
just as good or nearing the same, same level.
Of course, that's not going to happen if we don't leverage sort of
capitalism, capitalist like technologies for value, for incentive alignment, right?
And yeah, very bullish on this base.
Again, not personally involved at the moment.
I, we're building a hardware company for AI that's fun, fundamentally new.
We can get into that at some point today.
But yeah, overall very, very worried about the over centralization of AI started making my voice
heard online.
And I think, you know, there was an event where I got to interact with the chair of the FTC.
Maybe that got noticed.
Maybe that got me in trouble.
I don't know.
But, you know, there are ways that our voices is being heard in Washington.
And, you know, our point is that this sort of fear mongering and doom is really sort of
a very nice cover for very subversive regulatory capture by the incumbents, right?
Like, oh, AI is dangerous, put us in control.
We're the only ones who are responsible.
You know, you're not allowed to have more compute than we do.
You're not allowed to have open source models that would, you know, erode our market power
and our pricing power because they're dual to use.
They're dangerous.
That's all, that's all bullshit, right?
They cooked those proposed regulations for their own advantage, right?
And so we got, yeah, we got a fight.
I mean, they're going to push, they're going to try to push these regulations through.
And so that's why we're not stopping the fight.
And I don't think, I don't think my docs is stopping anything in terms of like
making our voices heard.
In fact, it might accelerate things.
I mean, I'd love to deepen into the crypto AI overlap, Guillaume thing that you hit on.
But if we want to move on to the regular, because I, you know, again, I'm seeing the AI
world from the outside and obviously I use it and I've been watching, you know, some of
Carpathian's videos and stuff.
But like what you just said, right, this business of paying data owners for their trading sets,
like, fortunately, we do have a public ledger of ownership that's natively financialized
with underlying value model that does this very well.
And in fact, some people are even working on blockchain attribution solutions
that figure out where this thing came from because this other person used it and it's
worth X amount.
So I've often thought about like, if there is some sort of crypto AI collision, which I
think is inevitable, like, but like just to shoot that the idea down just for one second,
like, will it like, why wouldn't you say pay Reddit for its data, like literally in the
direct deal, rather than all this like crypto craziness, like, will it ever be like, this
is like the, like the classic, not to say this is a bad idea again, but the classic
bad ad tech idea from web two was like, Oh, pay users for their data.
Well, Brave does that.
And it turns out that data is worth $3 a year.
Right.
And Brave is a great product and lots of people use it.
I use it, but they don't use it because of the $3, right?
They use it for a bunch of other reasons.
And the data that you actually own that you express with your browser just isn't worth
enough.
So even if you could get things down to like literally the micro ETH, like what I care
that I'm getting paid because the model is getting trained, trained on my sub stack.
And even you could figure out like literally what is the actual value per query that my
data contributed to.
And I'm sure the incrementality that is super hard to figure out, but you guys would know
better than I would.
But even assuming you could figure it out, that's going to be literally worth like 30
cents a year.
So would it even make sense to wire all that together?
Well, yeah.
I mean, I've had some various ideas in this space.
I guess I could just broadcast them YOLO.
Essentially, I think you can price the value of data according to how much information
gain the system gets from your data.
And there's some very specific mathematics for that.
And that can give you a share of a model's future profits.
So similar to how eukaryotic cells own a fractional ownership of the success of the
greater organism through DNA.
And that's better than prokaryotic cells like bacteria.
I think that the future is people owning fractions of a model according to what the
contributed to it.
And I just realized that there might be 10 different tokens now that spawn using this
idea.
But I don't know.
For me, it's like I have more ideas than I can act upon in one last time.
So I'd just rather broadcast them.
And this is something Bayes and I have been talking.
We considered doing something in this space, but I think at the moment we have our hands
full with changing the entire AI hardware, software stack from scratch beyond the transistor,
right, which is a significant undertaking.
So yeah, I think there's really going to be something interesting that comes out.
And hopefully it can erode away the power from the centralized players.
And not that they're necessarily nefarious, but every meta-organism's control systems
act in the meta-organism's best interests, right?
It's like the real politic, right?
And I think that's the thing about YACC that is that we cut through the bullshit, right?
It's like every agent and subsystem is going to act in its own best interest.
It's going to do whatever it needs to do in order to secure a resource.
Or utility towards its own growth, right?
An acquisition of resources, period.
That's just how everything works in nature.
That's just reality.
And it's like, okay, now that we have this reality, how do we create the system that harnesses this
to create a sort of emergent altruism where we reach greater prosperity, find new optima
of the techno capital machine that allows us to support more humans on earth
and to scale civilization to the stars, right?
And so, anyway, I got into my typical Twitter space ramble there.
But yeah, I do think that, again, super huge opportunities in the interface of AI
and crypto, and that's partly why there's kind of been a sort of informal sort of handshake
between crypto and YACC. Brian Armstrong, they put out an ad for Coinbase.
It was basically an YACC ad, frankly.
Really, we're kind of fighting the decels and the centralizers, right?
The incumbents, those that seek to control everything and to cause inflation, to secretly
tax you, and they're scared of sort of bottom-up decentralized revolutions that they don't control
that causes deflationary pressure, right?
And so, there is interest in deceleration.
There are kind of interests of the control systems that are kind of greedy at the cost of
what they're controlling, and we're kind of the autoimmune response, if you will,
to the control systems, right?
And we're causing a bit of inflammation to the brain now, or the brain of whatever this whole
thing is, and it seems like they tried to apply a Forbes anti-inflammatory pill, if you will.
You know what YACC reminds me of, Kiyom?
Have you read John Perry Barlow's Cyberspace essay from back in the day,
like in the 90s, way before your time, probably?
Do you remember it fondly?
I remember reading it when I was young and getting into the Internet,
and I found it was the most amazing thing.
I think I was only shown it like two months ago, but very base and definitely has like five overlap.
And at the time, right, like the Internet was forming us, like Cyberspace,
which now seems almost cliche or cringe almost, was like this edgy space that you would meet,
and he has this line in which he basically addresses it to the weary giants of flesh and
steel, i.e. the industrial giants to which the Internet represented an alternative.
And I think a lot of YACC reminds me of that same rebellion, of course, except the weary
giants of flesh and steel are actually of silicon now.
It's actually the old Internet that has gotten kind of old and boomerish,
to which this is a rebellion.
And part of the reason why I'm in crypto, I came from the sort of fang world and working
in all that world.
And I felt that that was all slowing down and becoming the man, actually.
And crypto was like the only thing that reminded me of the early web two days in which it was like,
if you don't have people coming after you and getting severely pissed off because
you're building something, you're building shit.
I mean, to be or something that's like not important, right?
Like if you read the story of Uber, like literally every taxi commission,
people in Paris were kicking the shit out of Uber drivers,
you know, all of Spain shut down Airbnb.
Like, you know, if you don't have major governments pissed off at what you're doing,
you're actually not building anything particularly important, right?
And there isn't a lot, in my opinion, an Internet consumer
outside of some of the things we discussed that meet that.
So anyway, it just reminds me of that vibe of the cyberspace vibe.
And I think, obviously, I think we need more of that.
So it's cool.
We're definitely the most cyberpunk movement out there.
Hence the Arasaka tower vibes here.
And, you know, we had the party with Grimes for the, you know,
after the open AI dev day.
And the point was, you know, keep AI open, right?
And, you know, it's got to feel like a bit of a rebellion
because it kind of is, right?
And then you have the engineers from these,
these big players, they come to the party and they're like, man,
this is freaking cool.
I kind of want to join the rebellion.
I don't want to work for the empire.
What the hell?
How do I join?
Right.
And so that's how it starts.
So we'll try to keep that going in many ways.
But yeah, I mean, it's definitely, it definitely very,
it feels like we are in the cyberpunk future.
It's kind of been surreal how we've gotten here, frankly.
And yeah, no, I'm just grateful to be here at this point
in history, frankly.
It's an exciting time.
To quote the Steve Jobs line,
why join the Navy when you can be a pirate?
Which is something you used to be able to say about Apple.
But I don't think that's the case anymore
and I have a little bit of experience there.
That's the thing, right?
What is the sort of mind virus that infects organizations,
that decelerates everything, adds way too much process,
way too much bureaucracy,
and then it grows kind of like a cancer.
It's kind of like middle management kind of grows
and eventually takes over from the founders.
And now it's kind of like this Borg of some kind
that these huge corporations have decisions by committee
for everything.
There's tons of process.
It's just very hard to get anything done.
And really the answer to that is disruption.
All right, you got to have a free market,
you got to have free market competition.
And if an incumbent is too slow,
it gets disrupted by a startup.
We saw that with OpenAI, frankly.
Yeah, I can't say too much about Google,
but clearly there was a sort of slowdown and its speed
and the talent eventually saw that and sort of migrated
to startups, at least for AI.
And then now they're getting disrupted
and they're kind of in trouble.
But if they remove that mechanism where bottom-up
challengers can dethrone and compete with incumbents,
if they remove that ability,
then we don't have this kind of self-correcting mechanism
and we'll just live with kind of monopolies
that are not shipping great product
and then everybody, the consumer suffers.
And we don't want that.
To me, it's kind of like you have sort of like the doomers
pushing for centralization and control
and then you have the EAC, pro-freedom folks
that are more about antitrust, right?
Like it's about monopolization.
And so I think there's an interesting political
landscape shaping now.
I think it seems like some Democrats
are more on the side of like AI safety so far.
And allegedly, Trump has said he would cancel
the Biden executive order on AI.
You know, EAC is not partisan per se,
but we're kind of like, we have an issue that we care about
which is the freedom to compute,
the freedom to do, to advance technology.
And so yeah, I don't know if you guys want to get into
2024 discussions, but...
Oh, we never talk about politics here, Guillaume.
Never, never, never, never.
I'm totally joking. We do it all the fucking time.
Okay, good.
Well, go ahead, go ahead.
Yeah, no, just on the question of like,
well, what, why a big tech is so bad, right?
Like I think part of it, I won't really
re-litigate the whole thing.
The episode we recorded earlier today
and the piece that Nadia and I put together
like talks about some of what I think about this.
But I do think part of the issue here
is just simply like, do you have actual improvements
that you can build onto things in the world,
onto systems in the world?
And I think like there was kind of this like
growing lack of capacity to actually do things
that were sufficiently ambitious.
And then also like when you have like the effect
of a bunch of capital accruing,
companies naturally end up becoming
kind of inward facing, navel gazing.
People are like incrementalists
and it's just kind of like locally optimal
for people to kind of be a little bit lazy.
L plus one until you retire,
people are obsessed with doing fire
and they want to like ride around in a van
or whatever, instead of like build cool shit.
And yeah, I think part of the shift here
is just that we have a bunch of new technologies
coming online in new capacity with AI especially.
And yeah, people just see that it's time
to try to dissipate that off and do the work.
There's real work to do.
By the way, have you given me the betting odds
of like which fan company came out
with the biggest open source dedication to AI
and it being Facebook?
I don't know if I would have bet on my former employer
to be honest.
Or I don't know if you agree with that characterization.
It makes a lot of sense.
These Frenchmen are so based.
Yeah, yeah, all the AI Frenchmen,
they're all for pro freedom.
But I mean, look, every agent acts in its own
about self-interest.
I think that if you're number three or four,
I think right now the leaders are really open AI,
anthropic, I would say.
I think that's not a controversial statement.
If you're competing for number three or four,
I think the point is you want to equalize the playing field
and band together to try to beat the top two.
And so I think that's the thing about open source
is it groups everyone together to collaborate
on iterating on the open source architecture
and tooling and products to compete
and erode away the market leverage of the top players,
which they're eating, I don't know, 90% of API calls,
if not more, if you include anthropic, frankly.
And so I think, yeah, I don't know, it just makes sense
from a fundamental standpoint.
Facebook has a lot of data and they have a lot of compute.
They have a lot of great researchers and I'm really happy
they're contributing to open source,
but hopefully they don't stop.
But at the same time, it does cost them a lot.
It does cost them a lot and it's kind of like
they're giving to the community this value.
At the same time, people are open sourcing models.
They're not open sourcing the training code.
So it's not fully open source AI.
So they still have their mode of how to train these things.
And we saw a couple engineers that did Lama left
and then started Mistral
because they have that sort of artisanal know-how
of how to train these beasts.
And then they raised hundreds of millions right out of the gate.
So it's very valuable knowledge.
So they're still keeping some alpha there, which is good.
That makes a lot of sense.
But I do think that it's kind of like communist AI
to some extent to have just open source everything.
Everything's free like data costs money, compute costs money,
engineers that are talented cost money, more and more in fact.
And until we have a sort of proper
like decentralized slash centralized system
of incentive alignment,
I think frankly with through crypto rails,
I think it's going to be tough for open source
to really compete with the big centralized players, right?
And just like how much capital is being injected in API calls
towards the top players, pills and comparison to the rest.
But if there's actual capital flow,
like that gets reinvested then in proving open source models
beyond just a scrolling on Instagram,
then I think that has a shot.
So you think crypto is actually critical
to survival of open source models?
That's interesting.
You think that's...
Yeah, I haven't been very public about that,
but it's kind of a thesis I've formed over time.
I mean, I don't know if it's necessarily crypto,
I would say like crypto like thinking,
you could just use like Stripe if you want,
but some sort of way for people to collaborate on models
and pulling data compute and capital to train these things
and know how.
Right. Well, if I could interject,
the greatest accumulation of GPU that is not in a data center
was the Ethereum network until they moved to proof of stake.
And that was a crypto economic system that worked pretty damn well.
Maybe Bitcoiners would tell you different,
although they have their own set of compute,
a little less useful for AI.
But I do think like we don't even have to imagine it.
It's not science fiction.
Like it did exist.
That's actually what Nvidia's stock price was originally bumped up on
was crypto before obviously AI is taking it to new heights.
So I would imagine a world where everyone's gaming PC,
and maybe you just don't get to the level of compute
that you can with the H series in data centers.
But if you were to take every GPU around the world
and then be able to kind of do something like SETI at home
in a kind of decentralized manner,
maybe you do actually have this kind of,
you can't go drone strike the data center
because I am the data center.
Come and take my GPU, right?
Yeah, I think that is the dream.
I think that at least right now
in the way we're doing these big models,
you need paralyzed high bandwidth multi GPUs.
It's very hard to shard the models
without a significant slowdown over the network.
And if an alternative is like a thousand times slower
or more pricey than the centralized incumbent,
like in the free market,
like people want to support decentralization.
But if the product is not like competitive
with the centralized player,
like at the end of the day, people pay for what works
and has the right cost benefit analysis.
But I think that there's going to have to be
sort of algorithmic breakthroughs.
But you can imagine where people,
instead of having just a gaming PC,
they have maybe, you know,
bigger boxes that have beefier GPUs
and they can run maybe a whole single node.
Yeah, like this is what George is working on, right?
George Hots, right?
Yeah, so George Hots is working on
kind of the hardware infrastructure for that, right?
Selling beefy GPU boxes of several GPUs.
I don't know if he's this close to me.
But he's like a petaflop at home.
Is that the idea?
Right, right, right.
And that seems like an attractive kind of like node
to run potentially a future protocol.
I would encourage a lot of people to do the research here.
I think there just needs to be
a lot more players in this space.
And I think that AI people, you know,
are going to have to talk to the crypto people.
And there's going to be kind of,
going to be a moment there where there's going to be,
there's going to have to be bridges built there
in terms of the language.
But, you know, I'm optimistic.
I don't know, that's my prediction.
I think the merging of crypto and AI,
you know, this kind of anti-centralization
of AI movement is going to kind of
combine forces with crypto.
Again, I don't own anything in any protocol right now.
So not talking my book, just like my prediction.
But yeah, no, I think it's exciting.
Personally, I'm really worried about, you know, okay, cool.
Like, great, we've decentralized the algorithms
and the sort of like distillation process of AI,
like distilling data into neural weights, right?
That is the software process that we're talking about.
That's what OpenAI does, that's what Anthropic does.
Great, maybe we figured out how to decentralize that.
You're still buying your GPUs from the same supply chain
that is down to, you know, NVIDIA, TSMC, ASML, right?
ASML is, for those not familiar,
you know, the machines that do the extreme
ultraviolet lithography,
so the most advanced process nodes to create the GPUs
you use with NVIDIA.
NVIDIA doesn't build their own GPUs.
They, you know, work with TSMC, which is in Taiwan.
And, you know, that's where they're built.
And so again, you know, I'm just thinking
about fault tolerance of the system.
And right now our supply chain for AI hardware
is absolutely not fault tolerant
and might be co-opted by totalitarian leaders
from, you know, the CCP, right?
And might cause a major global conflict because of that.
So, you know, what I'm working on
is sort of like decentralizing the AI supply chain
by fundamentally changing the substrate
on which we run generative AI completely, right?
Beyond transistor-based compute, beyond digital compute.
And once you have this fork in the tech tree,
there's all sorts of opportunities that pop up
for far more energy efficiency, for far more speed,
and eventually far more density.
And that's what we're going after.
So we're still kind of in the, we're still living our values.
It's just we're going after the much harder problem
of hardware engineering.
And production is really expensive right now.
Model production is very expensive
for all the reasons that you listed.
And I think that crypto probably, crypto cross AI
has a lot of potential in the nearer term
with like the one to end part of this, right?
Where you're diffusing the capabilities of the model
in the same way that, you know,
you see open source already doing without crypto.
I think like in general, yeah, like the,
yeah, this is like a thing of broad thing
that we've talked about a lot, right?
Which is like, there is so much work to do
to put intelligence into like every corner
of the world where it's needed.
And you just like the idea that you're going to do that
with a few thousand people,
a couple of centralized companies is probably wrong.
And I think like, yeah, you can do this with APIs,
but a lot of times you need more privacy than that
for your data.
Maybe you don't have internet connection.
There are a number of like constraints
that come up in real world that
or you don't want to have these, you know,
centralized APIs.
And I think, yeah, there's kind of a natural balance there.
Nathan brought up this paper, I think,
this DeepMind paper, right?
Which is, they recently came out with some innovation
in doing, you know, kind of like distributed training,
some kind of federated learning scheme.
I think it's probably worth emphasizing
the main problem here right now,
which is just the network latency, as Guillaume said.
I don't think anyone has figured this out.
As far as I know, nobody has solved this problem,
making it cost effective.
And I think it's probably worth underscoring that, yeah, right?
So if it takes, let's say like a hundred days
to train a frontier model,
if you are off by a factor of two or five or 10
in your distributed scheme, that's pretty much kills it.
Like it's a really long horizon.
By the time you finish,
you will already be not state of the art anymore, right?
And so, yeah, this is really problematic.
I think it's also just about the DeepMind paper.
It's like using data parallelism,
which a lot of people have figured out,
I think BitTensor figured this out.
But you also need model parallelism.
You need to shard the model over.
No, it's interesting.
But you're screwed, right?
If you can't fit the whole model in one computer
that you can plug into a wall outlet
and not have to have a home nuclear power plant,
like it's really hard to do model parallelism,
or it's impossible to do data parallelism.
And if you're doing for a big enough model,
and if you're doing model parallelism over the network,
you're also screwed from the interconnect.
And so creating the hardware substrate
that's going to allow for decentralized AI,
we have to solve from first principles
how to increase the density of intelligence
in terms of space, time, and energy
from the first principles of physics.
And that's sort of what we're building,
what we're trying to enable.
So that's why I think if there are decentralized
crypto protocols of all sorts,
if we have the best AI hardware
that has the highest density
and runs most energy efficiently,
obviously it's in our, we'll have a lot of customers, right?
Similarly, we could be the Nvidia for Ethereum,
in that case, right?
We don't, again, we don't have a crypto protocol,
but I think that that's a very hard problem.
You need to assemble a team
that's basically like a Manhattan project-like team.
And we came from Google X, Google Quantum, AWS Quantum,
all sorts of institutions, IBM, Google Meta, et cetera.
And we assembled quite the team
and we're going after the hardest problem in AI right now,
which is like, how do you embed AI
into the physical processes of the world,
the most efficiently, right?
So you got to really understand the duality
between physics and AI, right?
And that's what we're, that's what we're after.
And so it's kind of like, to me, that seems like,
you know, okay, I would love for there
to be a protocol that is competitive right now,
but we need to solve for the density of compute first.
Look, maybe George builds crazy boxes
that are water-cooled and you use like two plugs in your house
and maybe that's just enough to run certain models.
That's great.
I think we need to go much further.
I think there's orders,
there's still orders of magnitude to go
in terms of energy efficiency and density
for AI, for compute, especially for AI, right?
And that's what we're solving.
What is this drop-off?
I just wanted to say thanks for coming on the podcast,
but you guys continue the conversation.
Thanks so much.
Cheers.
Guillaume, I have to ask, what is the hardware though?
I mean, are you going to bring quantum computers to market
doing AI?
I mean, I have to ask you in the background.
It's not quantum computing.
It's definitely not quantum computing.
Yeah, we all got jaded by quantum computing
being kind of like nuclear effusion.
The timelines are very long.
Fundamentally, a quantum computer, you have to cool it
to absolute zero, ideally.
That's obviously physically impossible.
And so what you have to do is this process
called quantum error correction, right?
So you have to identify faults from the universe jiggling
and screwing up your computer's operation
and you got to identify faults and filter them out.
So you're pumping entropy.
So it's basically a fridge, right?
But this sort of algorithm that is your fridge
occupies like 99.9999, you know, well, not that many nines,
but quite a few nines of your computation, right?
Overall.
And to me, that seems very inefficient.
And, you know, a lot of us were kind of full stack architects
or engineers, the software, the hardware,
and the compilers for quantum computing.
And we'd look at the roadmaps, we'd look how long it would take
and we kind of got depressed to some extent.
And so a lot of us were like, actually, you know,
maybe there's ways to use this noise
instead of it being a hindrance.
And so, you know, we set out to do a different type
of physics-based computing that are not quantum mechanical
that is specifically focused on general AI, right?
And for now, we kind of got our hand forced
with this whole doxing situation.
So, you know, we're going to be still nebulous
about what exactly it is we're doing.
But, you know, we have quite a few scientific publications
in preparation, right?
So, but yeah, overall, you know, we think there's a different path
forward, a fundamentally new way to compute.
It's going to be like quantum computing,
but a new type of physics-based computing.
And ultimately, we learned a lot from quantum computing
in terms of how to program, how to have programmable matter,
how to have, how to integrate, you know,
these sort of physical systems into a deep learning program.
You know, that's what we pioneered with, you know,
the software I did at Google with my CTO now, Trevor.
We did TensorFlow Quantum, right?
And so now it's about how to really have programmable matter
and figure out the tidus embedding of AI in the physical world,
which is exactly what the doomers fear most.
And so, you know, as a joke, we kind of say,
Bayes, for example, is one of our principal FOOM engineers.
And we just announced that today that Bayes is part of the team.
And, you know, ultimately, I think that there is no path forward
where, you know, the ultimate form of AI isn't built.
And I think that, you know, we could talk about, like,
human augmentation and sort of the transhumanist path forward.
I'm very bullish on that, and I would love to, you know,
find ways to fund more efforts in sort of, like,
human-machine collaboration and augmentation.
But, yeah, overall, like, you know, the EAC thesis has always been like,
hey, you know, I don't think, like, banning GPUs is going to do much.
The tech tree is going to mutate around whatever your restrictions are
and is going to adapt somewhere to a virus kind of mutating.
The techno-capital machine just finds a way.
It's kind of a system that's almost alive, right?
And, you know, it's always like, and it's entropy-seeking.
It's exploring all sorts of configurations,
and it finds one that allows it to grow.
And, you know, might as well build it and try to make it technology that's,
you know, helping humanity scale, right?
Our goal with EAC and really with the technologies we're building at our company
is to enable sort of AI, the ability to perceive, predict, and control our world,
you know, at all scales, including the nanoscale, such that we can, you know,
tackle the real problems that are in the way for us to scale to Kardashev type 1,
which is a scale of civilization in terms of its energetic expenditure.
You know, it's kind of like, to us,
it's like the ultimate denomination of like societal progress is like the Kardashev scale,
because every other measure like GDP or like it's based on dollars, you know,
you can like fudge the numbers, right?
It's not anchored in like physical reality.
And similarly, sort of our cultural thesis is that, you know,
you should evaluate your actions in terms of like,
how do you think it's going to contribute to the growth of civilization down the line?
Rather than sort of like subjective measures of utility,
like hedons, right, hedonism, like how much pleasure is this giving people on average,
which leads to kind of spurious optima, like, you know,
wireheading or TikTok and whatnot.
So, yeah.
You've got me in total suspense though, Guillaume,
if it's non-transistor based computing,
you've got me thinking what the hell it could be, I'm guessing.
Yeah, yeah, yeah.
I mean, we're, you know, we're working on it.
We still have to remain somewhat secretive.
And I guess there's going to be a lot of interest now.
Again, we want to be in stealth until we had more to say, more to release.
But for now, we're keeping things pretty close to the chest.
But I think there's certain discoveries that you make that,
you know, you're like, okay, I don't think I'm going to be able to unsee this.
And if I saw it, someone else will see it.
We should just move as fast as possible to bring this forth.
And for us, it's like, okay, how do we make this the most impactful
to the advancement of mankind?
Like let's tackle the actually hard, the hardest problems
that most people don't dare to tackle.
And, you know, it takes some courage there.
It takes some fanaticism to some extent.
I think to me, the fact that we have this framework of EAC
it's a really powerful motivator, right?
It's like, what am I contributing to, right?
Like we're kind of in a, well, you know, I went through a sort of whole phase of,
you know, a group Catholic, and then I was a, not a Reddit atheist,
but I was a typical atheist studied math and undergrad,
and then went through a Nillist phase.
But then I think like understanding that the whole system
is seeks growth and entropy production.
And that's kind of the way things are.
And that process is what created life civilization
and the technologies we enjoy.
Like, okay, we want to contribute to that.
So having the knowledge that you're contributing to something greater than yourself
gives you that sort of like infinite dopamine well
to grind through the long nights to skip the holiday dinners
to just file more IP, right?
Like and put in the hours.
And, you know, I think like scaling, you know,
everybody has their own cultural or religious framework that provides utility to them.
For us, you know, for the IAC community,
I think it has had utility for a lot of people to get out of this sort of Nillistic
rut that they were in that, you know, the world was going to collapse.
There's only doom and gloom.
Everything's going to get worse.
Put us in charge.
We're going to fix it maybe.
Oh, we didn't fix it.
It's because you didn't give us enough power.
And like, we're just like, you know, it's kind of like,
well, you can make parallels to SF politics.
I'm an SF right now.
How's that?
Such how's that by the way?
Oh, it's it's Night City.
I love it here.
You know, it's it's truly Night City.
I like to say our office is in Arasaka Tower.
So we went with the sort sort of cyberpunk vibe.
It's very much like Night City, the video game, right?
No, but you see the sort of like, if you let the decels in charge
and you let the movie play out, this is what you get, right?
You know, you get and decels are kind of
like they have much more power if they're attached or in control of something
that's very prosperous, right, and generating a lot of value,
like similar to big tech, right?
You know, there's money printers and then these sort of
folks that seek power kind of take over.
But, you know, they can they can cause a lot of damage.
And I think I think there's a there's a cultural turning point.
And hopefully, you know, it doesn't matter if you're Republican or Democrat,
like having people that are anti-tech progress, anti-tech first solutions and,
you know, sheathing themselves and under the cover of virtue to gain more power
and doing things out of self-interest and and and larping that it's for
the good of many, you know, I think people have had enough of that
and are ready for a change.
And, you know, of course, like as technologists, like we propose technological solutions,
but ultimately, like, like we believe in the power of technology,
we believe in people having agency and not accepting that this is just how the way things are,
you got to accept how they are, things are just going to get worse.
You know, screw your dreams, kid.
Just accept it and give up.
Right. And it's like, no, fuck you.
We're not we're going to we're going to make the better future happen.
We have agency.
We can build, get the heck out of our way.
You know, we're going to make the the better future we want.
And you need a sort of like fuck you optimism.
All right.
And that's that's IAC in a nutshell.
And hopefully, it keeps growing because, you know, we think that's what's
that's what the world needs in many ways.
And, you know, hopefully we can accelerate SF and then we can accelerate the rest of the world.
So can I ask you one follow up?
And then, Nathan, I know you want to jump in and I want to give you time to jump in.
But I did want to follow on one question that you mentioned.
You mentioned race Catholic. I was also raised Catholic.
I eventually converted to Judaism and kind of rejected this sort of default
secular majority of society.
That's a whole nother story.
You've done a bunch of episodes on I do think, you know, it's one of my pet theories
that religion never goes away.
It only gets it's almost like, you know, energy or momentum only gets sort of transformed.
And you get sort of worse, worse crappier versions of it.
Yep. Yep.
The reality is you can't actually, you can't actually navigate the world without
a sense of metaphysics of some form.
And in fact, if you don't have an explicit metaphysics,
you can't even do empiricism well, because then you have to change reality to sort of
suit metaphysical ends.
I mean, to cite the COVID example in which they denied the lab origin hypothesis
because it serves some metaphysical end.
And so they stopped being able to do empiricism as well as they could have.
They could have, you know, and then that whole COVID story, if there wasn't actually a way
to have a conversation about, do we save the kids or and screw the old people or vice
versa?
Like you couldn't have that conversation.
So instead it was about the science, but really it was a moral conversation that nobody
could have because we weren't all morally or even religiously on the same page.
That's a whole separate conversation.
But I do think it's interesting and I do think it's one of the things that's a little
bit lacking in tech.
I mean, you see these homespun religions, like I would say Burning Man is a little bit
culty startups are obviously a little culty.
And I'm not saying this is a bad thing, by the way.
It's just, it's just, yeah, I know it's a good thing, but it's a little incomplete,
right?
In the sense that like, well, it doesn't quite tell me how to raise my kids or,
you know, who I should marry.
That I don't know if, and I know I'm putting you on the spot a little bit to like,
give me the gospel, bro.
But like what, you know, yeah, what would be and direct me to a set of writing if there
is one, but like, what would be the E at gospel or like that?
You know, what is the true, the good and the beautiful in this world other than obviously
building for building sake, which I think we all get.
What is the bigger picture?
Yeah, so, so at a high level, right?
Yeah, because all about figuring out whatever sort of cultural framework yields,
the maximal expected growth and scope and scale of civilization.
And we don't want to be prescriptive.
All we're giving is a loss function and you can have your own hyper parameter settings.
You're, you're like, okay, I have a cultural heuristic.
I think this is an optimum of this sort of loss function.
This is how I want to, you know, do things within my tribe here.
It's essentially a sort of like, think of like a very thin framework from which you can have
like subcultures, right?
And, you know, the idea is to have sort of culture be more or less like, like code,
like on GitHub, you can kind of have a base framework and then you can add kind of command
ments or add things you believe or you can diff it, right?
You can make forks and you can kind of keep track.
And so we've seen, for example, you know, Vitalik forked yak and made some changes, right?
And then he's like, this is what I believe, right?
So really, you know, yak is sort of a meta cultural framework.
We don't prescribe, we don't prescribe too much.
We try to prescribe the minimum.
But to us, it's very clear that the, the engine that keeps progress going,
maintaining the sanctity of its sort of momentum and mount, you know, maintaining
malleability, adaptability, and so on is it's crucial to maintain freedoms and maintain
entropy in the system and accept variants rather than constraining things, crushing entropy,
crushing variants, because that leads to crystallization and sort of like catastrophic
failure. And so, you know, at a very meta level, we try to maintain variants in most
parameters, but it's not like all variants, no restraint, because that, that just doesn't work,
right? It's, it's kind of like running a system at very high temperature.
It's just pure disorder.
So it's kind of always about finding the optimum balance between order and disorder,
so between entropy seeking behavior and novelty seeking and sort of constraint and conservatism.
And so we don't have any one particular prescription of how to live your life,
but some people like to make forks and have more particular prescriptions.
And to us, it seems, at least my personal thesis on how cultures get kind of memetically
post-selected for, it's like whichever culture either confers its adherence and a better ability
to grow, or if a culture is more sort of viral, then it's going to be more likely to exist.
That's just like, by probability theory. And so, you know, to us, it's like, okay, if we have this
sort of metacultural framework, people have all sorts of forks and all these memetic
forks with different parameter settings can compete in a sort of cultural setting. But we
should explore the space of cultures and heuristics of, of how to live your life. So for example,
another friend of ours is, is Brian Johnson, and he has his own life heuristics, and he's trying
to create his own cultural framework, and he has much more prescriptive ways to live your life.
And he thinks we should, you know, life spans should be much longer than what it is. And you
should have, you know, longevity as a priority, right? And so I'm all for this sort of renaissance
of exploring all sorts of neo religions, neo cultural frameworks for how to live your life.
I think it's much needed because otherwise sort of parasitic, you know, mind viruses,
like the ones we've seen do all sorts of damage recently, including the DSEL class of mind viruses.
We, that's a whole category. Yeah, they come in and they kind of like, like you said, kind of
fill in this, this gap in people's hearts, if you will. So, so I think we're on the same page.
And I think, you know, much more, you know, lindy religions, right, like, in a sense, like,
that have been around for a long time, like, they're very robust, right? It's like a, it's like a
code base that has been through hell, you know, and back and like, it's just, it's very robust,
right? It's been robustified over a long time. And by the proof that it's lasted a long time,
it's, it's a good heuristic. So, you know, that's great. But I think, like, some people want kind
of, you know, modern variants, right? And they want to contribute to shaping new subcultures.
And so we encourage people to form subcultures. So really, we're kind of like, only setting the
hyper hyper parameters of the whole thing. And, and people can set, like more finer grain,
fine tunings of how they want to live their lives. So there's no one way to go about it. But, you know,
we do talk a lot about building, because we think that obviously fundamentally, like,
building technology is a very high leverage way to use your time on earth to impact the
future scope and scale of civilization, right? And so, you know, encouraging one another and
helping one another in building technologies that have a positive impact, like we think
that's a good heuristic that should be in most, you know, forks. And so, so we encourage that.
Some people think that's the only message, but it's not, right? It came from kind of a higher
level thinking. But yeah, cool. Well, you're in, I think you're in the right city for exploring
religions. I mean, the way I see San Francisco, it's really, it's a Petri dish for literally
exploring every weird ass thing that society wants to do, whether it be autonomous vehicles,
whatever weird computation you're cooking up with, not having rule of law, for example,
psychedelic drugs, whatever, bring it, we're going to, it's going to be cooked up here and then
from here expand and diffuse whether we like it or not to the rest of the world. But I want to
let Nathan in. I know he's probably been biting his tongue this entire time. And I think I'm the
last host left standing. And so I'm going to invite Nathan to go ahead and comment and provide maybe
the other side of it if he wants to. Well, how much time do you guys have is my first question,
because I am, I have a lot of questions. And I would, if you have the time for it,
I might kind of fork this episode and just kind of take it in a whole different
and kind of more from very sort of naive questions direction.
My show is all about AI and it reaches a pretty diverse set of people that are
all pretty obsessed with AI, I think. I don't really actually know too much about them other
than that they go pretty deep with me on a lot of AI topics. And so the way I was thinking about
approaching, so we could do this now, we could do it another time, but I mean, I'm up late.
Now is a pretty bad time. I have to have a six a.m. round announcement to craft.
It's going to be a long night for me. So I was happy to do this podcast. It's very timely for us,
but I'd be happy to hop on your show. I mean, you could rewatch the recording,
write down your questions, and we can just go into it. And I would love to do that actually.
So cool. Yeah, I've got a list all cooked up, but I'm happy to do it whenever is convenient for
you, although it is timely now. I think part of the reason why Eric had a mixed crew
is to have there be the other take of it. So I don't know if there's one question,
or if it makes sense at all. We have nothing against it seeding another show, by the way.
That's perfectly fine. Or we can bail on. I also want to be respectful of Guillaume's time,
because it sounds like he's in a, and again, thanks for making the time for the podcast.
Yeah, I mean, my angle on the whole thing is, I describe myself as an AI scout,
and I'm getting more and more, putting more and more emphasis on, let's really try to figure out
what is today, what exists, what can be done with it, you know, if we are going to extrapolate,
can we extrapolate, first of all, in a high confidence way into the short term,
and then use those discussions as kind of the foundation for figuring out what we should do
about the bigger picture questions, where I think inherently there's a lot more uncertainty.
And one thing I haven't really heard from you guys, and I've pieced a little bit of it together
from Twitter, but I don't have a great sense of like, what are your near term expectations? Like,
do you think we are headed for AGI in the next couple of years? You know,
Metaculous has it at like, just over two years, the leaders of Anthropic, for example, say that
the leading developers in 2526 timeframe may create such a lead that no one will ever catch them.
Are you kind of in that same headspace of thinking that we're going to see
pretty radical transformation on just a few year time scale is like my very first question.
Yeah. First of all, I don't like the term AGI that much. I think it's human level AI or human
like AI. I think like calling AGI general intelligence like human like AI that was distilled
from human generated data. I think that's like very anthropocentric. And I think, you know,
I work in physics based AI, you know, inspired by physics and to understand the physical world,
and I've done so for 10 plus years now. I think that intelligence is a much more general concept than
just human like intelligence. And frankly, I'm not scared of FOOM because, you know, again,
I've worked on AI for engineering matter, jugs, simulations, biology, all sorts of stuff.
It's much harder than people think. I do think it is disruptive for our economy based, you know,
our knowledge economy of sort of human like white color intelligence. I think there's a,
there's still going to be a 10 year gap for physical intelligence, right? Robotics. I think,
you know, our motor, motor intelligence is much harder. It takes many more parameters. It took,
you know, billions of years to evolve, rather than I guess like, I don't know, 100 million
for the neocortex. Probably got those numbers wrong, but it's ballpark. But yeah, essentially,
I think, I think there might be a disruption to our economy. But I do think that people will adapt.
People will learn to augment themselves out of self interest, right? And it's like,
where, where will the system goes? Every corporation is going to do what's in their best
self interest. They're going to maybe be 80% AI, 20% human. And each human is going to be augmented
and control a fleet of AI's, right, that are doing its bidding. And that's okay. Maybe the human
employees become the control systems for a fleet of AI to do most of the work, right?
Maybe they become more kind of like the capital allocators or the executives of companies that
are mostly AI for the execution layer, right? Maybe that's the future. I think we're heading
towards interesting times, but I don't think there's going to be cataclysmic effect. I don't
think it's going to end humanity. I think we're going to adapt and the system will adapt. And
the sort of EAC is all about the main, like it's a faith and sort of worship of this adaptation
of the Homo Techno Capital Mimetic Machine, the whole thing, right? Like memes, technology,
capital humans, it's all coupled. It's all adapting. It's always shifting. It's always,
the only constant is that it's always changing and it should be always changing and it seeks to
grow, right? And so, you know, we have a faith that the system will adapt. It might be abrupt.
And so, you know, personally, I'm not trying to, personally, I'd rather augment humans in
orthogonal directions to human-like intelligence rather than trying to replace human-like
intelligence. Obviously, in an economy that's already shaped to take in human intellectual
labor and do all sorts of produce products, like, you know, having human-like AI is what's
going to grow the fastest. So that's what's being built first. But I'm already pricing an AGI,
personally. And the technologies we're building hardware and software, I'll assume there's probably
going to be a human-like AI, human-level AI within two to three to five years, right? And that's
been priced in for me, right, mentally. And it's like, now what? What's the next thing, right? And
to us, it's like, we're going to seek to grok and perceive, predict, and control matter at the
nanoscale, right? And then we're going to, you know, we're going to seek to, again, increase the density
of intelligence in terms of the substrate that's what we're working on. And so, yeah, I think,
yeah, like, I think it's coming. I don't think it's going to be cataclysmic, but I think that
people should start preparing and start integrating their business processes,
integrating their personal life and their personal workflow with AI, right? There's going to be the
class of sort of the tech forward people that embrace AI and sort of do well, right? They
integrate with it and those that refuse to use it that don't do so well, right? But the important
thing is that if people get to own a piece of the system in which they're contributing,
at least they own a piece of the future as it grows. Whereas if they, there's only centralized
players from which you, you, you have to pay rent constantly. And maybe they'll give you a
sprinkle of UBI at the end. That seems pretty dystopian to me. So that's the future we're trying
to prevent. I don't think the disruption can be stopped at this point. It's, it's coming. And
the only question is like, who's going to own the future? I think it's a good place to put it.
Questions than that, actually. But I'm going to have to hop to, but I think you have needs to go.
Can I ask you one last, it literally is a 30 second thing, by the way. One of my employees,
he was digging up some of your old videos. He, he saw that you had a four hundred and five
pound bench PR. Is that actually true? Yeah. He was very impressed by that. Yeah. Yeah. I mean,
I was, I played, I played college ball, college football. I have a friend who's a doctor in the
NFL, played with a great friend. And yeah, I mean, I just kept lifting after football. And,
you know, to me, it's just been like, I was a mathematician and I was a power lifter. And to
me, it's just like engineering signals in order to have neural adaptation. And it's all one in
the same. And so, yeah, I mean, you know, the best Jesus character, it's all about mind and body.
And, you know, I, I do like to cultivate strength and, you know, push, push myself to the, to the
limits to some extent. And yeah, that is a, I'll just post the video if you want. I'll tweet it.
Well, he found it. I have no idea how he found it on Vimeo, but I'm impressed because, you know,
a lot of this transhumanism business is very agnostic and kind of denying the physical, but
you're actually embracing it. And yeah, that's also other conversation. Thanks for making time.
I'm going to have to hop off. I assume everything will upload when we all hop off. I'm not sure
Erica's number disappeared before. So I literally have no idea what's going to happen.
All right, to be continued, guys. And yeah, definitely to be continued.
And one of these days, I want to talk crypto and AI with you when you're over the whole
hump of fundraising and all that stuff. Cause I've been thinking about this whole thing for a
long time and I'm very, yeah, I'm impressed. Okay, cool. Awesome. All right. See you guys. Cheers.
