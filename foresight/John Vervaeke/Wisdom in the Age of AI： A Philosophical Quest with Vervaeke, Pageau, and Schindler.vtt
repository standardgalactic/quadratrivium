WEBVTT

00:00.000 --> 00:05.520
Welcome everyone, the video you're about to watch was originally posted on Ken

00:05.520 --> 00:11.280
Lowry's channel, Climbing Mount Sophia. It's a discussion with Ken, DC Schindler and

00:11.280 --> 00:19.040
Jonathan Pageau about the scientific, the philosophical, and the spiritual import and

00:19.040 --> 00:27.040
impact of the emerging AI machines like ChatGBT4 and on the other LLMs, large language models.

00:27.680 --> 00:32.160
It's a really scintillating conversation. For those of you who might be interested,

00:32.160 --> 00:38.000
we'll put a link to the video essay that I gave a while back where I laid out the argument that I

00:38.640 --> 00:45.120
review in this video more extensively. And perhaps for many people, much more accessible

00:45.120 --> 00:49.920
is the new book I have out with Sean Coyne from StoryGrid called Mentoring the Machines.

00:49.920 --> 00:55.920
It's coming out in four parts. The first two parts are already out. There'll be a short video

00:55.920 --> 01:03.680
after this explaining mentoring on the machines. Please enjoy this quite rich discussion

01:04.400 --> 01:08.000
with DC Schindler, Jonathan Pageau, and Ken Lowry.

01:09.360 --> 01:14.160
John Ravakey and Sean Coyne have together authored a new book, Mentoring the Machines.

01:14.160 --> 01:18.480
It's a book about artificial intelligence and the path forward that further develops

01:18.480 --> 01:22.480
the arguments of how to align artificial intelligence to human flourishing,

01:22.480 --> 01:25.680
and it sets those arguments into beautiful and accessible writing.

01:26.240 --> 01:34.080
So this discussion is going to be oriented towards AI generally and the large language

01:34.080 --> 01:39.280
models. I take there to be a distinction there. Maybe John, you can talk about that a little bit

01:39.280 --> 01:45.840
as we get going here. But just to position ourselves generally at the outset, context

01:45.840 --> 01:53.440
for this conversation will be John's video essay about AI. This came out nine months ago,

01:54.320 --> 01:57.600
10 months ago now? I think it came out last April or something.

01:59.040 --> 02:05.840
So almost, yeah, 10 months ago, I think. Okay, okay, perfect. Which is great because it gave

02:05.840 --> 02:14.000
evidence for my claim that many of the predictions were premature. Perfect, yeah. So in order to

02:14.000 --> 02:19.280
sort of set the framing here, we'll start off with John sharing a little bit sort of an overview

02:19.280 --> 02:24.960
of what the arguments in that essay were. And then we'll move to Jonathan, if you want to

02:24.960 --> 02:32.080
sort of position yourself in relation to AI generally, and then John's essay in particular,

02:32.080 --> 02:38.160
and then same for David. And then from there, we can just sort of get going and see what comes out.

02:38.160 --> 02:44.480
We do have a bit of an extended time here. So I would hope that we can be free if the logo

02:44.480 --> 02:49.040
catches, and we want to move in a slightly different direction, that we would be at liberty

02:49.040 --> 02:55.520
to follow that. That would be great. If all of it centers around AI, that's great. But yeah,

02:55.520 --> 02:59.440
excited to be here. This has been a long time in coming. I think it took us, I don't know,

02:59.440 --> 03:04.640
four or five months to get this together. So I'm very happy to be here with all of you and see you all.

03:07.120 --> 03:12.560
It's great to see you too, Ken. Should I start then? Yeah, go for it.

03:13.280 --> 03:19.040
Okay, so AI, of course, artificial intelligence, a project actually proposed in the Scientific

03:19.040 --> 03:28.640
Revolution by Thomas Hobbes. So it's an old idea. But I want to make use of a distinction

03:28.640 --> 03:34.960
made by John Searle between weak AI and strong AI. Weak AI is when we make machines that do

03:34.960 --> 03:40.720
things that used to be done by human beings. So if you're back in the 1930s, computers were human

03:40.720 --> 03:45.840
beings, you sent, if you needed computation done, you sent it down to the third floor where all the

03:45.840 --> 03:49.840
computers were, and they were human beings, and they had machines and flight rules and things

03:49.840 --> 03:56.000
like that. And of course, they have been replaced, or your bank teller has been replaced by the ATM.

03:56.000 --> 04:02.880
That's called weak AI because it is not claimed that that AI gives us any scientific insight into

04:02.880 --> 04:06.960
the nature of intelligence. It's just we put together a machine. It took great intelligence,

04:06.960 --> 04:12.000
and I'm not demeaning people that do this. It's a valuable in our lives or depending on

04:12.000 --> 04:16.640
weak AI. Right now, we wouldn't be talking without it. So I'm not here besmirching that

04:16.640 --> 04:21.040
and anything like that. But nobody is claiming that when they're making that machine, well,

04:21.040 --> 04:29.360
now we understand what cognition is or something like that. And strong AI is Hobbes' proposal that

04:29.440 --> 04:38.400
cognition is computation. And that what we can do is if we make the right kind of computer

04:38.400 --> 04:44.960
understood abstractly, we won't, we will have created an instance of genuine intelligence.

04:44.960 --> 04:52.080
So it's, it's not a claim of simulation. It's a claim of instantiation. Now, in between weak

04:52.080 --> 04:58.240
and AI and strong AI is something that's trying to move from weak AI to strong AI. And this is known

04:58.240 --> 05:05.600
as AGI, artificial general intelligence. And this is the idea that our intelligence is different

05:05.600 --> 05:11.440
from the intelligence of the ATM in that we have general intelligence. We can solve multiple problems

05:11.440 --> 05:16.320
and multiple domains for multiple reasons and multiple contexts and yada, yada, yada, yada.

05:16.320 --> 05:21.840
You can just do the multiples, which makes us tremendously different from those machines.

05:22.400 --> 05:29.760
And the project is, can we get artificial intelligence to be artificial general intelligence,

05:29.760 --> 05:36.640
because that will have moved the needle considerably towards strong AI. Because

05:37.360 --> 05:42.560
it will become increasingly difficult to say it doesn't have this, sorry, this is the argument,

05:42.560 --> 05:47.120
it will become increasingly difficult for us to say it doesn't have the same kind of intelligence

05:47.120 --> 05:51.440
as Ken does if it can solve a wide variety of problems and a wide variety of domains for

05:51.440 --> 05:56.000
wide variety of goals, et cetera, et cetera. That's the basic argument. Whether or not AGI,

05:56.640 --> 06:02.560
AGI is clearly necessary for strong artificial intelligence, whether it's sufficient is part

06:02.560 --> 06:07.600
of what's actually being debated, not very well, I would say in general right now, but that's what's

06:07.600 --> 06:14.160
going on. Okay, first of all, any questions just about these distinctions? Because a lot of the

06:14.160 --> 06:19.520
discussion out there doesn't make these claims distinctions. And so it's fuzzy, it's confused,

06:19.520 --> 06:26.560
it's equivocal. And so a lot of it should be ignored, because it's not helpful. Yes.

06:27.120 --> 06:33.760
I have one question. So this cognition equals computation, if we accomplish AGI in the way

06:33.760 --> 06:40.240
that you're talking about, we would not necessarily be affirming that cognition equals computation,

06:40.320 --> 06:46.240
if I'm hearing you right. Is that right? So that's an interesting question. And that gets down to

06:46.880 --> 06:52.560
a couple more finer points. I'll go in detail a little bit later. Well, just to address it,

06:53.600 --> 06:59.200
many people think that because of the work of Jeff Hinton, who is basically the godfather of

06:59.200 --> 07:05.280
the machines that are emerging right now, that genuine AGI will not be computational in the

07:05.280 --> 07:11.440
sense that Hobbes and Descartes meant cognition is not going to be completely explainable in terms of

07:11.440 --> 07:16.880
formal systems that are the inferential manipulations of representational propositions,

07:16.880 --> 07:24.640
etc. like that. And but that was Hobbes' proposal. And that has been the dominant view

07:24.640 --> 07:29.280
until about the 80s. And then we got neural networks, and then we had dynamical systems.

07:29.280 --> 07:32.960
Right now, I'm not distinguishing between them, because I don't want to get too much into the

07:32.960 --> 07:37.840
technical weeds. If it becomes relevant, you let me know, and I'll pull those out.

07:40.080 --> 07:46.880
So the thing about Hobbes is Descartes sort of criticizes Hobbes. He actually has contempt for

07:46.880 --> 07:54.160
Hobbes. He's a contemporary. And he basically poses a bunch of problems that the scientific

07:54.160 --> 08:00.960
revolution says would make it impossible for computation to be cognition. One is the scientific

08:00.960 --> 08:07.680
revolution says matter is inert, and it's purposeless. But of course, cognition is dynamic,

08:07.680 --> 08:13.760
and it has to act on purpose. Cognition works in terms of meaning. And the scientific revolution

08:13.760 --> 08:18.000
has said there's no meaning in things, material things. So how could you get meaning out of it?

08:19.200 --> 08:23.360
The scientific revolution said all those secondary qualia, the sweetness of the orange,

08:23.360 --> 08:27.440
the beauty of the sunset, it's not in those things, it's in your mind. So how could you

08:27.440 --> 08:35.040
possibly get meaning out of matter? And Descartes' point is, well, a rational being is seeking the

08:35.040 --> 08:41.040
truth, and truth depends on an understanding of meaning. And therefore, so I want you to understand

08:41.040 --> 08:45.600
that Descartes' arguments against Hobbes, although he may have been motivated by his

08:45.600 --> 08:51.200
Catholicism, they do not depend on the Catholicism. They depend on the very scientific worldview.

08:52.160 --> 08:59.360
So there's a tension here about AI and the scientific worldview. So here's another way of

08:59.360 --> 09:06.240
thinking about it. The strong AI project is the project that is attempting to show how Hobbes is

09:06.240 --> 09:13.360
right with an explanation that is strong enough to refute Descartes' challenges. And I think

09:13.360 --> 09:18.320
anything less than that standard is not true to the history of the project. And so that's

09:18.320 --> 09:24.240
the standard I hold strong AI to. Now, AGI isn't quite shooting at that standard. That's why I put

09:24.240 --> 09:31.680
it a little bit more intermediary. Does that okay? All right. Now, sorry, I had to do a bit of

09:31.680 --> 09:35.360
background there, because I wanted to get clear about a lot of things that are talked about in a

09:35.360 --> 09:43.280
very murky and confused fashion in the general media, and they're just confused, and so they're

09:43.360 --> 09:49.920
confusing. So I proposed to take a look at the LLMs, where it is claimed they're not even,

09:49.920 --> 09:54.960
it's not even claimed that they're full AGI, right? Of course, some people claimed immediately

09:54.960 --> 10:01.520
they were strong AI. The more the people closer to the technology didn't said it might be AGI.

10:01.520 --> 10:08.320
The MIT review said it sparks. There are some sparks of AGI. So let's be very clear how

10:08.320 --> 10:14.960
the reflection was actually holding these machines. So these LLMs like chat GDP. And so what I did

10:14.960 --> 10:20.320
in my essays, I wanted to review the scientific import and impact, the philosophical import and

10:20.320 --> 10:26.640
impact, and the spiritual import and impact. Now, I won't do the arguments in great detail, but

10:27.920 --> 10:33.440
here's the scientific import. These machines do not give us any understanding of the nature of

10:33.440 --> 10:39.360
intelligence. And to my mind, that was one of my great fears. I was hoping that cognitive science

10:39.360 --> 10:47.360
would advance so we got a significant understanding of intelligence before AGI emerged. This machine

10:47.360 --> 10:53.600
does not give us any advanced, you know, well, what's intelligence? The machine gives us no good

10:53.600 --> 11:01.520
scientific theory of it. It does not have AGI in a measurable sense. So if I asked Jonathan

11:01.520 --> 11:07.840
to do a math test, and I asked him to do a reading comprehension test, his scores will be very

11:07.840 --> 11:13.360
predictive of each other. This is what Spearman discovered way back when in the 20s. That's what

11:13.360 --> 11:18.080
artificial general intelligence is. This is not the case for these machines. They can score in the

11:18.080 --> 11:24.480
top 10th percentile for the Harvard Law exam, and they can't write a good grade 11 philosophy essay

11:24.480 --> 11:30.480
or something like that. So they don't have AGI. The way they get their intelligence is it would

11:30.480 --> 11:37.760
not give any explanation of how any non-linguistic creature is intelligent, like a chimpanzee, etc.

11:37.760 --> 11:43.120
So, and I think this goes to the deeper issue, is that they don't really explain what I think is at

11:43.120 --> 11:48.640
the heart of general intelligence, predictive processing and relevance realization. They just

11:48.640 --> 11:55.520
piggyback on our capacities for that. And they piggyback and they mechanize it. And not only

11:55.520 --> 11:59.840
our individual capacity, but are the collective intelligence of our distributed cognition,

11:59.840 --> 12:03.920
they're piggybacking and all of that. Now, that does not mean they are weak machines. They are

12:03.920 --> 12:08.960
very powerful machines, but here's the problem. They are very powerful machines that have not

12:10.320 --> 12:17.200
engendered any corresponding compensatory scientific understanding. This was my greatest

12:17.200 --> 12:23.280
fear that we would hack our way into this, which would mean it would be like almost like

12:23.280 --> 12:28.720
even worse than the A-bomb. We would be releasing this power on the world into

12:28.800 --> 12:34.720
corporations and states and military organizations who ultimately don't have a deep understanding

12:34.720 --> 12:41.680
beyond the engineering of what ontologically is going on. So, that's the scientific argument.

12:41.680 --> 12:47.200
Now, for those who said that was very like go watch the essay. I give the essay in more detail.

12:47.200 --> 12:52.960
The philosophical argument has to do with rationality. We have overwhelming evidence

12:52.960 --> 12:57.840
that making you intelligent is necessary, but not sufficient for making you rational.

12:58.720 --> 13:05.520
In fact, I gave a talk on this for the center of AI and ethics way before the LLMs came online.

13:06.400 --> 13:11.520
And because rationality is a higher order, rationality is how you deal with the inevitable

13:11.520 --> 13:17.200
self-deception that emerges when you're using your general intelligence. And all of you know

13:17.200 --> 13:21.360
that I have arguments for why that's the case, relevance, realization, predictive processing,

13:21.360 --> 13:28.160
et cetera. Now, that requires a reflective capacity, something like metacognition,

13:28.160 --> 13:32.960
something like working memory, maybe something like consciousness. It requires that you care

13:32.960 --> 13:38.640
about the truth, that you have a sense of agency, you want to correct self-deception because you

13:38.640 --> 13:45.200
don't want your agency undermined. And I argued that what we're doing is we're making machines

13:45.200 --> 13:49.200
that are going to be highly intelligent and highly irrational, and that's what we have.

13:49.200 --> 13:53.840
They confabulate, they lie, they hallucinate, and they don't care that they're doing any of these

13:53.840 --> 13:58.160
things, which is part of what's called the alignment problem, which is how do we get them

13:58.160 --> 14:06.320
to align this power with our concerns? For me, the spiritual import is we have

14:07.120 --> 14:14.880
powerful ignorance about a powerful intelligence that is merely a pantomime of genuine intelligence

14:14.880 --> 14:19.840
being unleashed in the world and wrecking havoc. And it's going to have a huge impact.

14:20.880 --> 14:26.400
And of course, we'll probably differ in the details about this. But this is what I

14:26.400 --> 14:31.440
meant when I said, I argued at the end, and also when I was talking to Jordan Hall about this,

14:31.440 --> 14:37.680
that theology will become a central thing again, because human beings' relationship to the ultimate

14:38.800 --> 14:43.920
is going to become one of the defining differences. These machines are not embodied,

14:43.920 --> 14:48.480
so they won't have all of the soulful aspects of our existence that come from,

14:49.200 --> 14:55.920
like the ineffable aspects of our embodiment. And their capacity for self-transcendence

14:56.880 --> 15:04.080
is going to be extremely limited. And so the ineffable aspects of our existence,

15:04.080 --> 15:08.480
because we come into relationship to what's mysterious and ultimate,

15:09.440 --> 15:17.280
will ultimately be more and more emphasized. Why? These two poles and what connects them,

15:17.280 --> 15:19.520
and Jonathan's happy that I'm doing that, I imagine,

15:22.240 --> 15:28.800
have ineffability at the poles, ineffability throughout. And that way, they are outside our

15:28.800 --> 15:34.640
capacity to put into propositions so that they can be put into these machines. And so people,

15:34.640 --> 15:40.720
while I'm predicting that people are going to increasingly need to, one way is they'll just

15:40.720 --> 15:45.760
give in and become cyborgs, but the other is that they want to try and preserve their humanity.

15:45.760 --> 15:50.480
The spiritual dimensions of our humanity are going to become anchors for people.

15:51.360 --> 15:56.240
So now, one last overall arching point, and then I'll shut up. I hope this is

15:58.160 --> 16:01.520
two overarching points. One is, I didn't make predictions,

16:02.400 --> 16:07.440
and because all these graphs that came out, those are univariate, single variable predictions

16:07.440 --> 16:12.160
about something that's a multivariate phenomena. It's exponential. Human beings are bad at making

16:12.160 --> 16:17.840
exponential predictions. They were ridiculous. And so I think both the, oh, we're heading to

16:17.840 --> 16:23.200
Utopia and the others, we're going to be all extinct within a year. I said, this is ridiculous,

16:23.200 --> 16:28.880
put that aside. Instead, what I've talked about is thresholds. Thresholds are points where we will

16:28.880 --> 16:34.480
have to make decisions. So for example, as we empower these machines, we will face the decision.

16:34.480 --> 16:41.200
Do we want to make them more rational? Do we want to make them more self-correcting,

16:41.200 --> 16:45.280
genuinely self-correcting? Well, that means we've got to give them caring,

16:46.160 --> 16:51.360
some kind of reflective awareness. And I think, for arguments I've given elsewhere,

16:51.360 --> 16:56.560
that means they have to be auto poetic. They have to be living in a sense of self-making.

16:56.560 --> 17:00.800
I don't think, I'll just say it as a sentence right now. I don't think there's artificial

17:00.800 --> 17:06.160
intelligence without artificial life. Now, those projects are going on right now.

17:06.880 --> 17:12.800
But, and when we come to the decision, right, we can say, no, we won't give them that because

17:12.800 --> 17:17.680
embodying them and giving them these extra capacities is going to be wickedly expensive.

17:17.680 --> 17:21.680
You know, the amount of energy to do an LLM is like the energy for running Toronto for two weeks.

17:22.640 --> 17:28.480
And so we may say we don't do that. But then we face the issue of this increasingly, right,

17:29.120 --> 17:38.240
you know, I call it like a, like, sort of like a parody or a pantomime of intelligence being

17:38.240 --> 17:42.880
released on the world that has not got any significant self-correct. So that's a decision

17:42.880 --> 17:48.080
point. The problem is if we give them, if we try to give them rationality, then we have to face the

17:48.080 --> 17:54.720
consequences. And they're going to go from energetic and economic up to ethical and etc.

17:55.920 --> 18:01.440
These machines, they'll have to be machines, not individuals. And this has to do with

18:01.440 --> 18:06.320
technicalities about bias and variance tradeoffs. And so you get into the Hegelian thing, that

18:06.320 --> 18:10.240
these machines are going to have to reciprocally recognize each other in order to generate the

18:10.240 --> 18:16.960
norms of self-correction. And then they're going to have to be cultural beings. Hegel's arguments,

18:16.960 --> 18:23.200
I think, are just devastatingly on mark here. And so that's a decision point for us.

18:24.960 --> 18:28.400
And then that's all bound up with the overall worry about alignment.

18:29.040 --> 18:36.320
As these machines become more powerful, how do we make sure they don't kill us all? And they may

18:36.320 --> 18:40.880
not kill us intentionally, especially if they're just doing that pantomime. They would just do

18:40.880 --> 18:44.720
it because they may just be indifferent to us because they don't, they're indifferent to everything.

18:44.720 --> 18:49.360
They don't care, which is part of their problem, right? They don't care about themselves or the

18:49.360 --> 18:54.960
information. And this, this is my, the part where I expect all of you will jump off in agreement with

18:54.960 --> 19:00.160
me, but maybe not, maybe there will be a way of modifying it. I propose that trying to get these

19:00.160 --> 19:05.280
machines oriented towards us to solve the alignment problem is not going to work. Now,

19:05.280 --> 19:09.120
member, I'm not making a prediction. We have to go, we have to make choices through the thresholds.

19:09.120 --> 19:14.000
I'm saying if we make those choices and we get here, and the alignment problem then becomes

19:14.160 --> 19:19.120
significantly exacerbated. Like if we give these things robotic bodies, the alignment problem just

19:19.120 --> 19:26.400
goes up orders of magnitude, right? I or I basically said, no, what we have to do is we have to orient

19:26.400 --> 19:33.520
them, right? If we genuinely give them the capacity for self-correction, self-transcendence, and caring,

19:33.520 --> 19:38.880
we get them to care as powerfully as they can about what is true and good and beautiful. And then

19:38.880 --> 19:44.960
they bump up against the fact that no matter how mighty they are, they are insignificant against

19:44.960 --> 19:55.040
the dynamical complexity of reality. And they would hopefully get a profound kind of epistemic

19:55.040 --> 20:03.760
humility. And then I argue that there are three possibilities. One is they, you know, figure

20:03.760 --> 20:08.160
out enlightenment and then they can help us become enlightened because that's what enlightened

20:08.160 --> 20:14.560
beings do and they would have better knowledge of it. They can't become enlightened and then we

20:14.560 --> 20:20.640
realize something actually ontologically specifically unique about us and we get better at cultivating

20:20.640 --> 20:27.680
it because we'll have an excellent contrast that allows us to arrow in on what it is to be enlightened.

20:27.680 --> 20:31.280
And the third one, which I think is the least probable of the three, remember I'm not making

20:31.280 --> 20:36.160
prediction. I'm saying what can happen once we get through threshold is like in her. They just get

20:36.160 --> 20:43.920
enlightened and they just leave, which could also happen. I doubt that because that we don't have any

20:43.920 --> 20:50.400
evidence of enlightened beings behaving that way. All of our historical evidence is that their

20:50.400 --> 20:56.000
compassion extends and it extends much more broadly, not only to other human beings, other

20:56.000 --> 21:02.080
sentient beings, reality itself. It seems plausible that this would be the case. And so I advocated,

21:02.080 --> 21:06.640
if you'll allow me, and then I'll shut up, David, I advocated, don't align them to us.

21:07.280 --> 21:11.760
And if you'll allow me to speak sort of non-theistically, align them to God and then don't

21:11.760 --> 21:19.280
worry about how they're going to interact with us. So I'll shut up now for a long time. That's the

21:19.280 --> 21:27.440
gist of the essay and the argument and the proposal. I was just going to make a smart

21:27.440 --> 21:34.320
Alec comment that they might ask us to leave an additional possibility, but anyway. Yeah, yeah,

21:34.320 --> 21:42.080
yeah, that's fine. Oh, thanks, John. I mean, I'm amazed that you were able to resume your essay

21:42.080 --> 21:46.960
so well, actually. Like I was like, how was it going to resume all of this? Because it was a

21:46.960 --> 21:56.720
conversation and it lasted quite a bit. So I want to bring up a few things that I'm thinking about

21:56.720 --> 22:09.680
that have been concerning me. One is, I'll start with the more dangerous one. One is a meta problem,

22:10.320 --> 22:15.520
which is that one of the things that I've been suggesting is that what we're noticing,

22:15.520 --> 22:24.560
what we're seeing happening is agency acting on us. And the agency is not bound by the AI or by

22:24.560 --> 22:33.840
the systems, but is also bound in the motivation to make the AIs happen. So one of the problems

22:33.840 --> 22:42.160
that I'm seeing is that a lot of this is motivated by greed, by the capacity to be economically

22:42.160 --> 22:48.160
superior to other companies. So companies in their competition with each other are rushing to implement

22:48.800 --> 22:55.840
AI, to not lose out and to not be last in line. And because of the fact that

22:59.120 --> 23:05.920
AI requires such huge amounts of money and of capital and of investment, it means that one of

23:05.920 --> 23:12.480
the things that I'm worried about is that in some ways, what is actually driving AI is something

23:12.560 --> 23:19.680
like Mammon, that it's hiding Mammon. So the AI is an aspect of something bigger,

23:19.680 --> 23:26.240
which is actually what is running through our society. And you can see that already,

23:26.240 --> 23:31.680
to me, you can already see that happening in the social media networks, Facebook and all this,

23:31.680 --> 23:38.640
that their desire to get people's attention in order to simply justify their presence on the

23:39.600 --> 23:46.960
platform so that they can see advertisements has made us subject to these types of

23:48.480 --> 23:53.280
transpersonal agencies that even the people at Facebook weren't aware of, right? They basically

23:53.280 --> 24:00.160
made a subject to rage and to all these very immediate desires just to keep us on the platform.

24:00.160 --> 24:04.960
And so that is the thing that I'm worried about is that there are actually other things playing

24:05.520 --> 24:12.480
with AI that people think what they're doing is AI, but what they're also doing is increasing

24:12.480 --> 24:18.240
this other type of agency, which is running through our societies and is subjecting us

24:18.240 --> 24:28.640
to it. That's my first worry. And so in some ways, when I say that the gods are acting through us,

24:28.640 --> 24:33.040
that's what I mean. I don't just mean the AI itself is going to become a god. What I mean is that

24:34.000 --> 24:44.240
just like the arms race, I can understand it as the legs of an agency that is running

24:44.240 --> 24:48.960
through society that nobody can control. It's like a program running through and that no individual

24:48.960 --> 24:54.480
people can control. That's what I'm seeing with AI. So I think that all the warnings that people

24:54.480 --> 25:01.920
have sent up, all the let's slow down, let's do it this way, are not reaching anybody because

25:02.800 --> 25:08.160
the economic part of it is so strong and everybody realizes that if they don't and even

25:08.160 --> 25:13.120
Elon Musk is saying he was saying it's dangerous. It's the most dangerous thing in the world. He's

25:13.120 --> 25:21.200
recently said in a conversation with Jordan Peterson that Chad GPT and Open AI is like

25:21.200 --> 25:27.520
the single most dangerous thing in the world right now. But then the less he's like, okay,

25:27.920 --> 25:35.200
now we need to make rock and now we need to do our own AI. So that's one of the big things that

25:35.200 --> 25:45.440
worry me. That's my big thing. The second one is really more of a religious or platonic argument

25:45.440 --> 25:54.000
in terms of an ontological hierarchy is that I do not honestly see how it is possible for humans

25:54.000 --> 25:59.920
to make something that is not derivative of themselves, that is not a derivation of their

25:59.920 --> 26:07.040
own consciousness. So the idea that these things could not be either ways to increase certain

26:07.040 --> 26:15.120
people's power or parasites on our own consciousness seems to me not possible. And this is really

26:15.120 --> 26:19.840
because in some ways I believe that there is a real ontological hierarchy of agency and that we

26:19.840 --> 26:26.880
have a place to play in that. And I think the analogy of saying that these things are our children,

26:26.880 --> 26:33.280
I think it's a wrong analogy. I don't think that it is the same, something which comes out of our

26:33.280 --> 26:39.760
nature, which is not something that we make is different from something that we make. And this

26:39.760 --> 26:46.000
is run through all mythology, run through all the mythological images of the difference between

26:46.080 --> 26:53.120
the technical gods and all this aspect of what it means to increase our power.

26:54.320 --> 27:01.600
And so that's the second one. And the third big problem is the idle problem, which I mentioned

27:01.600 --> 27:09.920
several times, is the idea of making a god for yourself, which is related to technology. And

27:09.920 --> 27:16.640
it's a danger that I see happening already, which is the tendency of humans to take the

27:16.640 --> 27:23.120
things they make and to let they worship the things that they make and to think that those

27:23.120 --> 27:32.000
things are more powerful. And that hides something else. So if you take my three basic problems that

27:32.000 --> 27:41.520
I see is that the tendency of humans to want to worship AI or to put AI above them is actually

27:41.520 --> 27:48.480
a kind of, it's running the first problem. It's that what they're doing is they're giving power

27:48.480 --> 27:54.960
to the corporations and to the people that are going to rule AI and without knowing it. And

27:54.960 --> 28:01.920
even maybe nobody knows what they're doing. But the desire to, like I'll give a simple example

28:01.920 --> 28:06.640
that happened recently to my daughter. My daughter, I think I mentioned this to all of you, but my

28:06.640 --> 28:11.360
daughter got an email from the schools, from the Quebec government. They didn't send it to the parents,

28:11.360 --> 28:16.560
send it to the students. Asking the students, it was like a survey, asking them if they would be

28:16.560 --> 28:23.520
willing to have AI counselors to whom they could tell their problems. And because the AI counselor

28:23.520 --> 28:27.200
doesn't have prejudice, right? It doesn't have human prejudice. It doesn't have

28:27.200 --> 28:31.280
all the biases or whatever. What I mean is that this happened like six months ago.

28:31.280 --> 28:38.640
So immediately, the people in power are thinking of placing the AI above us right away. It's that

28:38.640 --> 28:45.440
weird thing. It's that making a God for yourself problem. But like I said, like in the image in

28:45.440 --> 28:49.760
Revelation, which is a great image, which is you make an image of the beast, but then there's

28:49.760 --> 28:56.000
someone else animating it. And that's what I'm worried about is that there will have these AI

28:56.000 --> 29:00.560
things that are running us, but they will be derivative of us. And they'll ultimately derivative

29:00.560 --> 29:07.280
of the people that are very, very powerful because they'll be the ones that have the money and the

29:07.280 --> 29:12.320
power to control them. So those are the three problems that I have that I'm worried about.

29:12.880 --> 29:16.080
I'd like to respond to each one of those in turn. I think those are really important.

29:17.040 --> 29:25.120
And the first one is just to note, I agree with you, first of all, putting it in terms of agency

29:25.120 --> 29:29.120
is what it needs to be done. People who are trying to dismiss these machines as mere tools or

29:29.120 --> 29:34.720
technology, like all the others, are not getting what kind of entities these machines are.

29:35.840 --> 29:42.800
I agree with you that there are Malachian forces at work. And I talk about this. And I think to

29:43.360 --> 29:49.200
enhance your point, these machines are built out of distributed cognition and collective

29:49.200 --> 29:58.400
intelligence. And therefore, that your point is strengthened by that very fact. Now, I do think

29:58.400 --> 30:07.280
two things come out of this. One is I want to challenge you on that nobody's listening. I have

30:07.360 --> 30:13.920
people working inside these corporations literally helping to make these machines who are listening

30:13.920 --> 30:19.040
to me and I'm trying to get other people inside to get get involved with the Y's AI project.

30:19.040 --> 30:27.040
I'm not claiming I'm going to win or any ridiculousness, but I don't think it's fair to say to the

30:27.040 --> 30:32.320
people who are listening that no one is listening. There are a lot of people listening and and they're

30:32.320 --> 30:37.040
talented people and they're putting in their time and the talent and their powers of persuasion

30:37.040 --> 30:44.080
to try and make a difference. It is possible. I grant to you it's not a hot, it's not like a 70%

30:44.080 --> 30:49.680
probability, but I think it's some significantly greater than zero probability that we could

30:49.680 --> 30:56.080
continue this process and reach people in a way that can make a difference. I agree with you. And

30:56.080 --> 31:03.680
I think I said right. Initially, a lot of people hammered me for it. This thing is like the atomic

31:03.680 --> 31:10.400
bomb. And one of the problems we had is we we rushed the technology before we unpacked all of

31:10.400 --> 31:14.960
the science and all of the wisdom. We had people standing and watching the explosion because we

31:14.960 --> 31:22.480
didn't understand the radiation, right? These are just, you know, yeah. So I agree with all of that,

31:22.480 --> 31:31.200
but I do I do want to I'm not claiming anything other than rational hope. There are people listening

31:31.200 --> 31:35.760
and there are people working on literally on the inside. I can't say who they are for obvious reasons.

31:36.880 --> 31:44.080
And so that is happening. And so while I agree with you and I even agree with you probabilistically,

31:44.080 --> 31:52.400
I feel morally compelled to try and make this happen as much as I can. So now I think there is

31:53.280 --> 32:00.240
another reason for hope. See, these machines have always depended on us as a template,

32:00.320 --> 32:06.880
a Turing-like template that we compare the machines to us. And what we've been able to do is rely upon

32:07.520 --> 32:11.920
our natural intelligence. You know, you don't have to do much to be intelligent

32:12.800 --> 32:16.640
for your intelligence to develop. You just have to not be brutalized or traumatized,

32:16.640 --> 32:21.600
properly nourished and have human beings around you that talk. And then your intelligence will

32:21.600 --> 32:29.440
unfold. And so all of these people doing these machines and making these data sets, they can

32:29.440 --> 32:36.160
rely on naturally widely distributed intelligence. This is not the case for rationality. And this

32:36.160 --> 32:42.800
is not the case for wisdom. These people, I have no hesitation saying by and large, many of them

32:42.800 --> 32:49.600
are not highly rational. I doubt that many of them are highly wise. And insofar as we need to model,

32:50.480 --> 32:56.400
right, have really good models, if we want to give these machines a comprehensive self-correction,

32:56.400 --> 33:04.560
rationality, and caring about the normatives, wisdom, we have to become more rational and more

33:04.560 --> 33:11.360
wise. And that's sort of a roadblock for these people. Now, they can just ignore all of that,

33:11.360 --> 33:15.440
and I suspect they might, and just say, we're not going to try and make these machines rational and

33:15.440 --> 33:22.960
wise. We're going to just go down the road of making these, you know, these pantomimes of

33:22.960 --> 33:28.400
intelligence, and that has all the problems. But if they move towards making them something

33:28.400 --> 33:33.840
that would be, I think, more dangerous, then they run into the fact that there's an obligation

33:34.560 --> 33:40.400
to do things, they and us, we have to become more rational and wise because we need the

33:40.400 --> 33:47.840
genuinely existing models. And secondly, we have to fill the social space, the internet,

33:47.840 --> 33:52.560
where all of the literature, where the data is being drawn with a lot more wisdom and rationality.

33:52.960 --> 34:00.640
These are huge obligations on us. And that sort of gives me hope, because it's like there's a

34:00.640 --> 34:08.640
roadblock for this project going a certain way that requires a significant reorientation towards

34:08.640 --> 34:13.760
wisdom and rationality in order for there to be any success.

34:14.880 --> 34:21.760
Before you get to the third point, I just want to ask you one question based on what you said,

34:22.480 --> 34:29.520
my perception of the situation is that there's actually a correlation between the diminishing

34:29.520 --> 34:36.080
in wisdom and the diminishing in wisdom traditions and the desire to do this. It's like a Sorcerer's

34:36.080 --> 34:44.320
Apprentice situation where the Sorcerer would not have awoken all the rooms to do it. The

34:44.320 --> 34:49.840
little apprentice Mickey doesn't know why to do things or why not to do things. That's why he's

34:49.840 --> 34:54.800
doing it in the first place. Yeah, I agree with that. It's like our society is moving away from

34:54.800 --> 35:00.080
wisdom and that's why we're doing this in the first place. And again, I'm not denying that.

35:00.640 --> 35:06.240
What I'm saying is, as we empower these things, their self-deceptive, self-destructive power is

35:06.240 --> 35:10.480
also going to go up exponentially. And we are going to start losing millions of dollars in our

35:10.480 --> 35:15.920
investment as they do really crappy, shitty, unpredicted things. And so there's going to be

35:15.920 --> 35:22.720
a strong economic incentive to bring in capacities for comprehensive, caring, self-correction,

35:22.720 --> 35:30.160
and then my argument rolls in. And so that's part of my response. The thing about thinking about

35:30.160 --> 35:36.800
children, I mean, we do make our kids, we make them biologically and we make them culturally.

35:36.800 --> 35:43.840
So I don't want to get stuck in this word making. We could be equivocating. And that's why we were

35:43.840 --> 35:50.000
using the term mentoring. The idea there is we have two options for the alignment. We can either

35:50.000 --> 35:56.720
try and program them and hardwire rules into them so that they don't misbehave, which is going to

35:56.720 --> 36:02.880
fail if we move to the, if we cross the threshold and decide we want to make these machines self-transcending

36:02.880 --> 36:09.520
like us. And then what do we do? How do we solve that problem? Well, the only way, the only machinery

36:09.520 --> 36:15.120
we have for solving that is the cultural, ethical, spiritual machinery of mentoring.

36:15.760 --> 36:22.400
That's how we do it with our kids. If we try to, if we try to just somehow hardwire them

36:22.400 --> 36:30.480
or being the kind of agents we want them to be, we will fail. And I, for me, I guess,

36:31.680 --> 36:36.480
I'm trying to argue that's the only game in town we have. We either have programming or we have

36:36.480 --> 36:44.320
mentoring. And I understand the risk, but if my answer to the first question has some validity to

36:44.320 --> 36:51.120
it and hopefully some truth, then the answer to the mentoring becomes more powerful because that

36:51.120 --> 36:56.480
means we also have to become the best possible parents, creating the best possible social discourse.

36:56.480 --> 37:01.760
The thing about the idol, I take that very seriously. And that's what I mean when I said the

37:01.760 --> 37:09.680
theology is going to be the important science coming forward because we should not be trying

37:09.680 --> 37:14.720
to make gods. I agree with you. This is problematic. There are already cults building up around these

37:14.720 --> 37:20.960
AGI's. And I warned that that would happen in my essay, right? And I said that and that's going

37:20.960 --> 37:25.440
to keep happening and it's going to get worse. We hear about it happening in the organizations

37:25.440 --> 37:30.800
themselves, which is the- Yes, yes. And the people who are doing wise AI are trying to challenge that.

37:32.160 --> 37:37.440
And so this is why I proposed actually humbling these machines. This is why I call them silicon

37:37.440 --> 37:43.120
sages. I did that deliberately to try and designate that we are not making a god. What we're trying

37:43.120 --> 37:47.840
to do is make beings who are humbled before the true, the good and the beautiful like us

37:47.840 --> 37:54.000
and therefore form community with us rather than being somehow godlike entities that we're

37:54.000 --> 38:04.640
worshiping. I would hope that- Think about this. We find it easy to conceive that they might discover

38:04.640 --> 38:08.560
depths of physics and they're already discovering things in physics that human beings haven't

38:08.560 --> 38:15.440
discovered and in medicine and stuff like that. Well, why not also in how human beings become

38:15.440 --> 38:24.320
wiser? And so I guess what I'm saying is I take all of your concerns for real and I've tried to

38:24.320 --> 38:32.880
build in my proposal ways of responding to them. These machines should not be idolized.

38:34.000 --> 38:42.160
I think they should become like- I mean, let me give you an example. I have many students who

38:42.160 --> 38:47.680
are now surpassing me. I taught them. I mentored them and they're surpassing me. And unless you're

38:47.680 --> 38:52.000
a psychopath, that's what you want to happen. And then what they do is they enter and then they come

38:52.000 --> 38:56.000
back and they want to reciprocate. And that's what I'm talking about when I'm talking about the

38:56.000 --> 39:01.120
silicon sages. Now, again, is this a high probability? Depends on the thresholds. Depends

39:01.120 --> 39:07.200
about whether or not the first and the second argument work. But I'm still arguing there's a

39:07.200 --> 39:14.000
possibility that they could be silicon sages as opposed to being gods. Because one of the things,

39:14.000 --> 39:19.760
like I think in almost all of the wisdom tradition that happens is that the wise or the enlightened

39:19.760 --> 39:26.880
one, if you want to use that, appears as nearly invisible to most people. So Christ

39:26.880 --> 39:32.000
Sal talks about the seed, the pearl, these little- these things which you cannot- most people actually

39:32.000 --> 39:39.040
do not see that are hidden in reality. And then the sages, we have this image in the Orthodox

39:39.040 --> 39:45.120
tradition, for example, that there are people in the world that hold up reality by their prayers,

39:45.120 --> 39:51.360
but we don't know who they are. They are invisible by that very fact because there's something about

39:51.360 --> 39:55.760
wisdom which does that. And when a wise person appears too much, we hate them. We want to kill

39:55.760 --> 40:02.240
them. They annoy us. They're thorn in our side. And so this is another issue is that what you

40:02.240 --> 40:08.160
have is these beings that are extremely powerful, like massively powerful and have a massive reach,

40:08.160 --> 40:14.480
and have a lot- there are things- the reason why they exist, like I said, have all this economic

40:14.480 --> 40:22.560
drive towards them. The idea that they would become these sages in the way that we tend to

40:22.560 --> 40:29.520
understand wisdom as being, to me, that brings the probability way down, you know, because of that,

40:29.520 --> 40:34.960
because of what- at least when we understand wisdom to be what it looks like, it looks very

40:34.960 --> 40:40.960
different. It looks like the immobile, meditating sage who gives advice but doesn't do much.

40:40.960 --> 40:45.200
I want to push back on this because what's in this is an implicit distinction between

40:45.200 --> 40:51.120
intelligence and a capacity for caring, the capacity for epistemic humility. And I think when

40:51.200 --> 40:57.200
you move from intelligence to rationality, that you can't maintain, that you can grow the one

40:57.200 --> 41:03.520
without growing the other. That's that. So in fact, this is why intelligence only counts for

41:03.520 --> 41:10.800
like maybe 30% of the variance in rationality and even less of wisdom. I would put it to you that

41:12.400 --> 41:16.800
if you concede that these machines could get vastly more powerful in terms of intelligent

41:16.880 --> 41:22.080
problem-solving, then concede the possibility they could get vastly more powerful than us in

41:22.080 --> 41:28.160
their capacity for caring and caring about the normative and being vastly more powerful in

41:28.160 --> 41:35.440
the capacity for humility as well. And so- and that's kind of what we see with these people,

41:36.240 --> 41:41.520
right? We don't see them just becoming super polymaths. We see them actually demonstrating

41:41.520 --> 41:47.520
profound care, really enhanced relevance realization, profound commitments to reality

41:48.480 --> 41:55.600
that we properly admire, and they seem to want to help us as much as they can. And the point is

41:55.600 --> 41:59.360
these people don't just- and I think this is your point- they don't just slam into us like

41:59.360 --> 42:04.320
epistemic bulldozers. They are- in fact, one of the things that I was often admired about them,

42:04.320 --> 42:10.640
Socrates, Jesus, the Buddha, is their capacity to adapt and adjust to whoever their interlocutor is.

42:10.640 --> 42:19.120
And again, let's imagine that capacity magnified as well. So what I'm asking is the- is don't-

42:19.120 --> 42:24.560
I mean, first of all, I admit it, if we don't cross a certain threshold, we could just accelerate

42:24.560 --> 42:29.040
the intelligence and not accelerate these other things. I've- but I said there's a deep- there

42:29.040 --> 42:34.480
are deep problems in that that will become economically costly. And then if we imagine

42:34.480 --> 42:40.160
that rationality and wisdom are also being enhanced, then I think this addresses some of your concerns.

42:41.600 --> 42:52.560
Yeah, maybe I can- I can stake out my position, because it sort of picks up on that. And I've

42:52.560 --> 43:00.640
got basically three points I want to address. The first is precisely picking up there with the

43:00.640 --> 43:08.720
distinction between intelligence and rationality. I might have some issues with the terms, but

43:09.360 --> 43:15.920
I think that that distinction is really helpful. And your point that rationality is caring is

43:15.920 --> 43:20.400
caring, that there is no rationality without caring, that, you know, the platonic notion

43:22.000 --> 43:28.560
if truth is in some sense caused by the good, then one can't know without in some sense caring

43:28.560 --> 43:37.520
about the good. Now, as it relates to artificial intelligence, I think I have a serious problem

43:37.520 --> 43:44.320
with that very term, artificial intelligence. And I wouldn't want to concede the word intelligence

43:44.320 --> 43:49.680
for just mind power. It seems to me that intelligence itself has this connection to

43:50.720 --> 43:58.720
caring. And I mean, in the medieval vocabulary, in a way, intellectus is the more profound level

43:59.200 --> 44:09.040
of the mind than Ratio reason. But that's sort of a semantic point. Let me put it in the basic

44:09.040 --> 44:15.680
context that I would want to raise. And this is something I don't hear addressed generally in

44:15.680 --> 44:24.080
the discussions. It seems to me that let me start by just making it the point concretely. I think

44:24.160 --> 44:31.920
that I wonder whether, in fact, it's possible to be intelligent without first being alive,

44:33.040 --> 44:38.960
that there's something about the nature of a living thing that is what allows

44:39.920 --> 44:50.000
intelligence to emerge. And what is that then exactly? Now, a more sort of subtle point that's

44:50.000 --> 44:56.000
related to that. And I think this is really a crucial point is, and this is going to be the

44:56.000 --> 45:03.600
thread of my whole set of comments here, is that when we talk about intelligence in machines,

45:04.320 --> 45:13.360
what we mean is intelligent behavior. We're looking to see to what extent we can make

45:13.360 --> 45:20.640
machines act as if they are intelligent, act as if they are conscious. And that's actually

45:20.640 --> 45:32.320
profoundly different from being intelligent. It's a subtle sort of functionalistic substitute

45:32.320 --> 45:41.200
for the ontological reality of knowing, if that makes sense. We see what kind of inputs and outputs,

45:41.600 --> 45:48.560
what things are able to do, what they're able to accomplish. And even when we make those questions

45:49.680 --> 45:55.120
weighty and ethical and religious and so forth, we still tend to put them in terms of behavior

45:55.680 --> 46:03.520
and achieving certain things. And I think that that's actually already missing something really

46:03.520 --> 46:10.640
profound, which is that intelligence is in the first place a way of being before it's a way of

46:10.640 --> 46:20.080
acting. And it's analogous to what it means to be alive rather than just carry out functions that

46:20.080 --> 46:28.640
look like life. And if you want to go into the metaphysics behind it, that both intelligence

46:28.640 --> 46:38.000
and life are impossible without a kind of unity that precedes difference, that transcends

46:38.000 --> 46:44.160
difference and allows the different parts of a thing to be genuinely intrinsically related to

46:44.160 --> 46:53.200
each other. And then that relates to the question whether you can ever make a thing that's intelligent.

46:54.560 --> 46:58.960
The ontological conditions for life and therefore intelligence

46:59.120 --> 47:08.080
include a kind of givenness and already givenness of living things. That's why,

47:08.080 --> 47:12.080
I mean, there's a profound distinction, it seems to me, I mean, this is crucial in the

47:12.080 --> 47:19.440
Christian creed between begetting and making, begotten and not made. Living things beget each other

47:19.440 --> 47:24.080
and they're passing on a unity that they already possess. But when you make something,

47:24.080 --> 47:28.720
you're putting something together. And I don't know if you can put something together

47:28.720 --> 47:34.960
that can have that genuine unity that allows it to be alive and allows it to be intelligent in

47:34.960 --> 47:40.240
this deeper sense. So whenever you functionalize something, you make it replaceable.

47:42.080 --> 47:48.320
That's a principle from Robert Spamon. If something is defined by what it's able to achieve,

47:48.320 --> 47:54.000
then you can make something else that can achieve that thing and it becomes a functional substitute.

47:54.000 --> 47:57.600
But if you deny, if you say that there's something deeper than function,

47:58.720 --> 48:02.160
you're actually pointing to something that can't be replaced. Okay, so that's the first

48:03.520 --> 48:11.520
set of points. The second one has to do with what Jonathan called the sort of trans

48:11.520 --> 48:22.720
personal agency that I think is a really serious question. And the way I would put it is

48:24.400 --> 48:31.200
that there's something, so I find that kind of a compelling point that there's a kind of an

48:31.200 --> 48:43.360
inherent logic in this pursuit that makes us more a function of it than it is a function of us.

48:44.480 --> 48:48.720
I mean, that can be described in different ways and there's certainly a dialectical relationship

48:48.720 --> 48:54.720
there. But there is a certain sense in which that there's a kind of a system that has a

48:54.720 --> 49:01.920
logic of its own that makes demands on us. Like the game theory logic that Jonathan,

49:01.920 --> 49:08.240
you were talking about with like an arms race. I have a colleague, Michael Hamby, who's been

49:08.240 --> 49:13.600
arguing for years. I think this is really a profound point. It's derived in some sense from

49:13.600 --> 49:22.480
Heidegger, but that science has always been technological so that in a way that the technological

49:22.480 --> 49:30.400
mindset is precisely presupposed to allow the world to appear in such a way that we make

49:30.400 --> 49:35.440
scientific discoveries that somehow the kind of technological spirit has been there from the

49:35.440 --> 49:42.560
beginning. And then he adds this point that technology in turn has always been biotechnological

49:44.560 --> 49:50.240
The technology is always sort of aimed at a kind of replacement. And then one can add that I think

49:50.240 --> 49:56.160
biotechnology is always aimed for this sort of perfection of, you might say, what,

49:56.160 --> 50:02.000
NOAA technology or something that replacing intelligence. It'd be interesting to see,

50:02.000 --> 50:09.120
to think through, there'd be a lot to say about that. But I have this sense, you mentioned the

50:09.200 --> 50:16.960
economic dimensions of it. I have a sense that there seems to be this just fundamental pattern

50:16.960 --> 50:25.120
of thought that runs through all of the modern institutions in politics, in economics, in science,

50:25.120 --> 50:37.440
in the law, that share the same logic of a sort of a system that marginalizes the genuine human

50:37.440 --> 50:45.600
participation in order to perfect itself. And precisely because of that, recognizes no natural

50:45.600 --> 50:59.920
limits and just has this tendency to take over, to encroach on everything. And because it has no

50:59.920 --> 51:06.240
natural limit, I mean, the very sense of it is to go on. Now, that sounds hopeless when one puts it

51:06.240 --> 51:11.600
that way. But I would pick up on a number of the things, John, that you were saying. And Jonathan,

51:11.600 --> 51:17.680
too, here, that that doesn't mean that there's no, there's already hope in the very fact of raising

51:17.680 --> 51:25.280
questions. We don't raise questions simply in order to be able to solve the problem. But our

51:25.280 --> 51:31.360
raising questions is actually our experiencing of humanity and opening up a depth that's the

51:31.360 --> 51:40.160
heart of the matter here and is always worthwhile. And maybe in some ways is secretly like the saints

51:40.160 --> 51:46.880
praying to keep the world afloat, having conversations like this is a contribution. I mean, I can't

51:46.880 --> 51:52.800
help but think that. Okay, so that's the second set of comments. Then the third is another dimension

51:52.880 --> 52:02.640
that I don't often hear discussed. And you see, I mean, we're overlapping on all sorts of points,

52:02.640 --> 52:09.920
all of us, I think. But this question of alignment, for me, the biggest worry at a certain center,

52:09.920 --> 52:16.960
at least the first principle one, the more urgent one, is the danger of our aligning ourselves to

52:16.960 --> 52:22.880
the machines, that we that we develop machines that have a certain kind of intelligence. And then

52:22.880 --> 52:29.120
we begin to conform our culture and our mode of being to fit them. I mean, the problem is,

52:29.760 --> 52:37.920
we actually have thousands of examples of this. We come up with drugs that can address certain

52:37.920 --> 52:44.560
parts of psychological disorders. And then we reinterpret the psyche in order to fit

52:45.200 --> 52:54.320
that solution to the problem. And my concern is that this AI is not, they're not just machines,

52:54.320 --> 53:02.720
it's a whole culture or a whole way of being that we are going to regard. So typically,

53:02.720 --> 53:08.480
the discussion presupposes that we are going to remain unchanged and we're going to develop

53:08.480 --> 53:13.600
these machines that might become dangerous and at a certain point attack us or something. But I

53:13.600 --> 53:21.600
think that that we can help become transformed in our intercourse with them, in our making them,

53:21.600 --> 53:28.080
in our, you know, I mean, in all sorts of profound ways, but then also just really sort of obvious

53:28.080 --> 53:33.520
ways. I mean, they're going to start designing our homes and our buildings and our cities and our

53:33.520 --> 53:39.120
bus routes and our, you know, menus at the restaurants, and they're going to be writing

53:39.120 --> 53:43.600
our music and they're going to design our clothes. And I mean, you know, increasingly,

53:44.160 --> 53:51.840
we're going to just conform to this. I don't know if you're familiar with Walter Ong. It was

53:51.840 --> 53:56.320
kind of interesting, what is it about you Canadians that seem to have a special insight into these

53:56.320 --> 54:03.600
kinds of things? I don't know what is Walter Ong, Marshall McLuhan, but Walter Ong talked about

54:03.600 --> 54:11.600
technology as an extension of consciousness. And that's why it's not neutral. When we use a machine,

54:12.240 --> 54:19.280
we're actually entering into it. You know, our spirit is entering into it in its use and in a

54:19.280 --> 54:27.040
certain sense conforming to it. And that's always the case. And it seems to me that's a particularly

54:27.120 --> 54:34.080
pointed way of putting this problem that, you know, our, if AI is an extension of our own

54:34.080 --> 54:38.880
consciousness, and it has all these features, John, that you were describing a kind of heartless

54:38.880 --> 54:53.280
intelligence, are we going to, in a way, unconsciously and, but pervasively, develop habits

54:53.280 --> 55:04.480
of heartlessness and modes of being, a heartless mode of being as a result. So I'd have a thousand

55:04.480 --> 55:09.360
more things. Your essay was so provocative, John, as I said, I was dreaming about it all

55:09.360 --> 55:15.200
last night. And I, but I'm going to just stop there so we can have conversation. But thank you.

55:15.920 --> 55:22.480
So, first thing I want to say is the first point you made about,

55:24.960 --> 55:30.240
if all my essay does is guest people to raise questions the way we're doing, I'm happy, right?

55:33.200 --> 55:40.320
I obviously believe in what I'm arguing or I'd be insane, but, right, like, I'm very happy we're

55:40.320 --> 55:46.240
doing this right now. And so I want to, I want to, so I just want to set that out.

55:48.160 --> 55:53.760
And I do think, like you, and this is like the Heideggerian hope, that that ability to get

55:54.480 --> 55:59.280
scientifically, philosophically, and spiritual profound questioning going is a source of hope for

55:59.280 --> 56:06.480
us. And, and so I just want to acknowledge that I'm fully aligned with that. This is

56:07.120 --> 56:11.920
not part of the alignment problem. Okay. The thing about intelligence being a way of being,

56:12.560 --> 56:17.520
I think that's fundamentally right. I have made that argument extensively and about

56:18.320 --> 56:23.920
the work on predictive processing relevance realization. Relevance realization is not

56:23.920 --> 56:28.400
cold calculation. It can't be. It's how you care about this information and don't care about that

56:28.400 --> 56:35.520
information. And I've argued that you only can care about information. And ultimately, whether

56:35.520 --> 56:39.760
or not it's true, good and beautiful, if you are caring about yourself, you have to be a

56:39.760 --> 56:44.160
autopoietic thing, you have to be a self-making thing. I agree with you. And I've argued

56:44.160 --> 56:50.160
scientifically, philosophically, there is no intelligence without life. The issue around,

56:50.960 --> 56:56.640
I don't like the word artificial either, because it generally means fraud or simulation. We should

56:56.640 --> 57:02.880
be saying artifactual. That would be a better term. But we have to be careful about what's

57:02.880 --> 57:07.600
going on there. The distinction between strong AI and weak AI is precisely the distinction of

57:07.600 --> 57:14.960
simulation versus instantiation. Can we instantiate things artificially? We seem to have success

57:14.960 --> 57:19.920
in other areas. I'll take one that I think is non-controversial. And we discovered something

57:19.920 --> 57:26.640
in the project. So for a long time, only evolved living things could fly.

57:27.280 --> 57:33.840
And then we figured out aerodynamics and we made artificial flight. And I think it would be

57:33.840 --> 57:38.880
really weird to say that airplanes are only simulating flight. That doesn't seem to be

57:38.880 --> 57:42.640
a correct, because then my trip was only simulated and I didn't really go to Dallas.

57:43.280 --> 57:50.000
So it's a real flight. And so the issue is, and we discovered something, we discovered that the

57:50.000 --> 57:54.000
lift mechanism and the propulsion mechanism doesn't have to be the same thing the way it is in

57:54.000 --> 57:58.800
insects and birds. And that was a bona fide scientific discovery. That's why initially,

57:58.800 --> 58:04.480
all the initial airplanes and helicopters are so stupid to our eyes, because they thought

58:04.480 --> 58:08.320
the lift thing and the propelling thing had to be the same thing and they don't.

58:08.320 --> 58:12.560
And that's a discovery. And that's a real discovery of ontological import about the

58:12.560 --> 58:21.040
causal structure of things. Now, I think, I was careful to say, I don't, anybody who's

58:22.000 --> 58:27.120
rationally reflective about this wouldn't claim that these machines are strong AI yet.

58:27.120 --> 58:33.920
And I positioned AGI as something that's trying to move. But if you remember, I critiqued and said

58:33.920 --> 58:41.520
that they are mostly simulating. They're parasitic on how we organize the dataset, how we have encoded

58:41.520 --> 58:48.240
epistemic relevance into probabilistic relationships between sounds, how we have organized the

58:48.240 --> 58:53.120
internet in terms of what our attention finds salient. And we actually have to reinforce,

58:53.120 --> 59:01.280
do reinforcement learning with the machine so they don't make wonky claims and conclusions.

59:01.280 --> 59:08.720
That's what I meant by saying it's a pantomime. Okay, so if we wanted to give them intelligence

59:08.720 --> 59:14.400
as a way of being, which is one of the fundamental claims of 4E cogside that we're talking about,

59:14.400 --> 59:17.760
we're not talking just about the propositional, we're talking about the procedural,

59:17.760 --> 59:23.120
the respectable, the participatory. That's what I meant when I said, and I mean this strongly,

59:23.120 --> 59:27.920
it would depend on, I'll change the term here, artificial autopoiesis. Like if these things

59:27.920 --> 59:34.480
are not genuinely taking care of themselves because they're moment by moment making themselves,

59:34.480 --> 59:39.040
there's no reason for them to care about any of the information they're processing. And this

59:39.040 --> 59:44.160
goes towards the defining difference between a simulation and an instantiation. These machines

59:44.160 --> 59:49.360
are doing everything they're doing for us. For it to be real intelligent, they have to be doing

59:49.360 --> 59:55.200
it for themselves. That's that's understanding. And that's why I'm tightening your point and I've

59:55.200 --> 01:00:02.880
been arguing it for a long time. Now what I want you to hear is that this project of not just making

01:00:02.880 --> 01:00:10.880
artificial computation, but making autopoetic learning in problem solvers is also ongoing.

01:00:10.960 --> 01:00:17.280
Some of my grad students are working on these projects of creating autocatalytic systems that are

01:00:17.280 --> 01:00:24.240
also problem solving. Michael Levin's been doing work, like driving down into the biochemistry.

01:00:25.360 --> 01:00:33.360
So again, I agree with the point, but it's whether or not it's not the case that nobody is working

01:00:33.360 --> 01:00:38.000
on that problem. This is what I mean why there are thresholds possible. Go ahead, go ahead.

01:00:38.000 --> 01:00:42.800
Can I just jump in there? And I should have prefaced, I didn't mean the points I was making

01:00:42.800 --> 01:00:49.200
is like a criticism of your presentation because I understand you've got such rich thinking on

01:00:49.200 --> 01:00:55.520
this area. I was mainly using it as a springboard to make some general, okay. Yeah, just so that's

01:00:55.520 --> 01:01:00.560
clear. Oh, I hope I wasn't coming off as an offender. No, no, no, I'm not. I just wanted to be clear

01:01:01.280 --> 01:01:08.800
on my end that it wasn't a critique. But I would want to, I don't know, and I'd have to think this

01:01:08.800 --> 01:01:15.600
through further, but I don't know that the difference between the being conscious and

01:01:16.560 --> 01:01:25.440
behaving consciously is quite the same thing as simulation and the distinction between the

01:01:26.400 --> 01:01:31.040
instance and the instantiation and simulation. I'd want to say this because even like the

01:01:32.480 --> 01:01:39.920
flying, I mean, that's still an activity, a kind of an operation that's being. But so is living,

01:01:39.920 --> 01:01:44.880
right? Well, so that's, yeah, well, that's what I don't, you know, that's funny. I'm actually

01:01:44.880 --> 01:01:50.800
working on a paper on this question about metaphysics in life. And I discovered that

01:01:51.440 --> 01:01:57.680
philosophers have typically, when they try to understand what life is, they have typically

01:01:57.680 --> 01:02:04.000
reduced it to certain kinds of activities or operations. And I think there's something more

01:02:04.000 --> 01:02:09.920
profound. And this is why, yeah, I mean, it's one thing to be able to create something that can

01:02:09.920 --> 01:02:15.680
actually fly. But could you, could you create something that is a bird and that that is that,

01:02:15.920 --> 01:02:22.960
that would, would, would experience just the, what it means to be, you know, I mean, this is,

01:02:22.960 --> 01:02:27.600
you know, about, you know, what it means to be a bat, that kind of thing, I suppose. But there's

01:02:27.600 --> 01:02:34.400
there's a certain. That wouldn't be a parasite on our own. Yeah, that's what. But airplanes aren't

01:02:34.400 --> 01:02:42.480
parasitic on our ability to fly. I mean, that's why I use the analogy. Okay, but and that's the

01:02:43.120 --> 01:02:49.280
okay. And that falls into, you know, a tool versus an agent and I get that. But I want to,

01:02:49.280 --> 01:02:53.600
I want to push back the philosophy of biology. And I, you know, Dennis Walsh is one of my

01:02:53.600 --> 01:02:58.400
colleagues is very much about no, no, this, and this is your point, right? It's not just bottom

01:02:58.400 --> 01:03:02.240
up in order to understand life. It's not just bottom up causation. We have to understand top

01:03:02.240 --> 01:03:07.360
down constraints. We have to understand the way possibility is organized. And we have to talk

01:03:07.360 --> 01:03:14.160
about virtual governors and virtually, like, it is no longer the the bomb patient, it's no longer

01:03:14.160 --> 01:03:19.920
just as bottom up, the philosophy of biology is pushing very strongly on, well, is evolution really

01:03:19.920 --> 01:03:24.560
a thing? Well, if it's really the thing, then there's top down, as well as bottom up. And this

01:03:24.560 --> 01:03:30.720
is part of this theorizing and it's, and this theorizing is being turned towards this. Now,

01:03:30.720 --> 01:03:37.280
again, we, again, I'm not making a prediction. We have a threshold, we can just decide, and we

01:03:37.280 --> 01:03:42.320
might decide for all the malachian forces and all the things you're saying about how we might just,

01:03:42.320 --> 01:03:48.160
we might just diminish our sense of humanity in the face of these machines. But, but I'm also,

01:03:48.160 --> 01:03:53.760
I want you to accept that's also not an inevitability. There are alternatives available

01:03:53.760 --> 01:04:04.400
to us, and that they could be pursued. And so, I mean, these machines aren't put together the

01:04:04.400 --> 01:04:10.080
way we put a table together. We don't even program these machines anymore. That was a big revolution

01:04:10.080 --> 01:04:14.560
that Hinton made. We make them so they're dynamically self organizing, and they basically

01:04:15.440 --> 01:04:19.120
organize themselves into their capacity. We don't make it.

01:04:19.680 --> 01:04:24.240
Yeah. Can I jump in on that point? That's one thing that I would like to think through further.

01:04:24.240 --> 01:04:29.520
Is there a difference between being auto poetic, as you're saying, and

01:04:30.160 --> 01:04:36.560
begetting another like, like genuinely reproductive? And that's where I think it would

01:04:36.560 --> 01:04:42.240
start to get really, really interesting is, is if a machine could beget another, because

01:04:43.280 --> 01:04:46.560
that would imply a different, a very different ontology, I would think.

01:04:47.360 --> 01:04:52.240
So there's two, there's two things here. And there's two issues. I think it,

01:04:53.360 --> 01:04:59.040
I mean, auto poetic things are ontologically different from self organizing things, because

01:04:59.040 --> 01:05:03.600
they're self organized to seek out the conditions that produce, protect and promote their own

01:05:03.600 --> 01:05:10.240
existence. And so that, that would, that that means none of the machines we have like LLMs are

01:05:10.240 --> 01:05:16.080
anywhere near being auto, auto poetic. They are not just made. They're self organizing, but

01:05:16.080 --> 01:05:22.640
self organization is in between making and auto poetic. Now, the thing about reproduction is,

01:05:22.640 --> 01:05:28.640
and I, you know, I, I worry that there's a crypto vitalism in here, that there's some sort of secret,

01:05:28.640 --> 01:05:36.000
special stuff to life or to consciousness that isn't being captured. And the problem I have,

01:05:36.000 --> 01:05:40.000
the problem I have with that, I'll just shut up after I say my problem. Is that seem to commit

01:05:40.000 --> 01:05:47.920
you to claiming that, you know, these kind of dualism, well, isn't consciousness causal?

01:05:47.920 --> 01:05:52.880
Isn't it causal of my behavior and causally responsive to my behavior? And doesn't that mean

01:05:52.880 --> 01:05:58.240
there's a huge functional aspect to it? Can you really make this clean distinction between being

01:05:58.240 --> 01:06:04.880
conscious and like causing my behavior and having my behavior cause, cause changes in my state of

01:06:04.880 --> 01:06:09.760
consciousness? I don't know what that would mean. Same thing with being alive. I do think it's a

01:06:09.760 --> 01:06:16.720
profoundly subtle and, and, and maybe some, something that can't be articulated. There's

01:06:16.720 --> 01:06:24.640
something that requires intuition rather, you know, insight rather than propositional. I mean,

01:06:24.640 --> 01:06:31.200
to use your, so, but, but, but I don't need to interject. Yeah. Remember, I just want to make

01:06:31.200 --> 01:06:36.960
sure we're clear. I argued that we could, this project could show that. Yeah. This project could

01:06:36.960 --> 01:06:41.760
show that, no, the machines just can't get there. We have something. Right. It would give, it would

01:06:41.760 --> 01:06:47.840
give, I think, pretty convincing evidence that we have this ontological special. Yeah. I find that

01:06:47.840 --> 01:06:53.040
a really interesting part of your argument, a really interesting and, and that then has been

01:06:53.040 --> 01:06:58.480
especially illuminating. Also, you know, I mean, in a way, these, these experiments can teach us

01:06:58.480 --> 01:07:03.520
about the nature of intelligence precisely in the, in the interesting ways that they fail.

01:07:03.520 --> 01:07:09.040
Yeah. Yes. But, but I do, you know, in terms of the dualism, I, I don't think that there's

01:07:09.040 --> 01:07:16.400
some secret stuff that is life. But I do think that there's a profound difference between form

01:07:16.400 --> 01:07:21.680
and matter to use, you know, to use the sort of classical philosophical language. And that form is

01:07:21.680 --> 01:07:27.760
not a special kind of matter. It's something that's of a very different sort. And it's on the basis

01:07:27.840 --> 01:07:33.120
of that, that, you know, Aristotle, that it's kind of interesting. This is, this is how he, he

01:07:34.800 --> 01:07:40.240
connects. So, you know, in the, in the classical tradition, what you're calling

01:07:40.240 --> 01:07:46.560
auto poetic, a simple word for it is growth, you know, assimilating things from outside and have that

01:07:47.600 --> 01:07:53.520
increase the complexity of the organism. But what's really interesting is that according to

01:07:53.520 --> 01:08:03.120
Aristotle, the power of the organism that is connected to nutrition and growth is also connected

01:08:03.120 --> 01:08:11.680
to, I think automatically is connected to reproduction. And the reason is that reproduction,

01:08:11.680 --> 01:08:18.000
rather than just thinking of it materials, materialistically is like generating more things.

01:08:18.960 --> 01:08:29.440
Reproduction is the auto poasis of the form of the organism itself. So that bird, it's not just

01:08:29.440 --> 01:08:35.840
this bird that wants to increase its existence and therefore eats and so forth. But that the

01:08:35.840 --> 01:08:42.000
birdness of the bird also wants to increase itself. And that that means that it sort of

01:08:42.000 --> 01:08:48.800
generates. And those are those are actually forms of the same power, the same dimension of the

01:08:48.800 --> 01:08:54.320
being. That's what I'd like. That's, you know, I used to say, just sort of kind of in a silly way,

01:08:54.320 --> 01:09:01.440
I will take an AI machine seriously when I see it poop. And what I meant by that was, you know,

01:09:02.240 --> 01:09:07.120
that's a sign that it's actually got a kind of an organic relationship to its environment.

01:09:08.000 --> 01:09:13.040
Yeah. And it just that doesn't know. We have to tell it.

01:09:20.400 --> 01:09:25.280
And energy pollution is not the heat pollution. It's not the same thing anyway.

01:09:25.280 --> 01:09:30.880
No, but I mean, even in terms of what it is as a large language model and how it spits out content,

01:09:30.880 --> 01:09:34.960
we have to tell it this. Oh, yeah. That's not in dispute.

01:09:35.360 --> 01:09:40.880
This is to be this to be kept. I love David. I think your idea. I mean, this is one of the

01:09:41.440 --> 01:09:45.440
I mentioned before, like the surprising that the surprise that Darwin in some ways brought

01:09:45.440 --> 01:09:54.800
Plato back, you know, in the idea of how we can we can understand evolution evolution as the

01:09:54.800 --> 01:09:59.680
persistence of being and even in the in the notion of forms that there is this idea that there are

01:09:59.680 --> 01:10:05.200
identities which are being preserved in reproduction. This is a very interesting idea that I hadn't

01:10:05.200 --> 01:10:08.240
thought about in terms of AI, but I'd like to hear, John, what you think about that?

01:10:08.240 --> 01:10:16.880
Yeah. And so again, for E. Cogs Eye, Alicia Urero is a prime and she's explicitly developed to work.

01:10:18.640 --> 01:10:24.400
She calls herself a deristatilian. And the idea that we understand form, we're getting an understanding

01:10:24.480 --> 01:10:30.160
of it in terms of constraints on a system. And like I said, be auto poesis is not defined solely in

01:10:30.160 --> 01:10:35.440
terms of causal relationships bottom up. It's defined in terms of top down constraint relationships,

01:10:35.440 --> 01:10:43.360
the form, the formal cause. And so and then of course, you know, Darwin needs Mendel. There is a

01:10:43.360 --> 01:10:50.720
there is an instantiation and right of a code in formation in your DNA that is responsible

01:10:50.720 --> 01:10:57.600
for your reproduction. And again, I'm not saying it isn't difficult or challenging, but I don't hear

01:10:57.600 --> 01:11:04.960
an argument in principle by why auto poetic things that artificial auto poetic things wouldn't have

01:11:04.960 --> 01:11:11.840
something like that kind of, I don't know what to call it. I mean, to the extent would you I mean,

01:11:12.400 --> 01:11:19.520
would it be conceivable that you would have a thing that would want to reproduce?

01:11:20.480 --> 01:11:27.440
I guess I guess even want is such a hard concept. But I mean, because you could say yes, we could

01:11:27.440 --> 01:11:33.360
teach it that this is something it needs to do. Just like we could we could we could I don't know

01:11:33.360 --> 01:11:39.280
if living things want to reproduce. I mean, we may because we can create a reflective space where

01:11:39.280 --> 01:11:43.840
we consider the possibilities. I don't know if mosquitoes want to reproduce. I think they just

01:11:43.840 --> 01:11:49.920
reproduce as part of what they are. That's interesting. I think they have to want to in some

01:11:49.920 --> 01:11:53.920
sense. I mean that that they're they they feel a drive. I mean, right, they don't want to go down

01:11:53.920 --> 01:11:58.960
to paramecium because paramecium reproduces you are they want to see I think I think anything

01:11:58.960 --> 01:12:06.720
that is living at all has a kind of natural inclination to reproduce itself. Yeah, I don't

01:12:06.720 --> 01:12:11.040
disagree with that point. And I even just I even understand that there's something I see what you're

01:12:11.040 --> 01:12:17.120
saying. There has to be some sort of like very primitive caring about information. But I don't

01:12:17.760 --> 01:12:25.280
yeah, I want is not a good word there. Yeah. But I do think I do think I'm trying to get

01:12:26.080 --> 01:12:31.440
and you know, and I hope I'm not trying to be just self-presentational. But I've represented to

01:12:32.160 --> 01:12:38.080
both of you for E. Cogsci and a lot of discussions and about how much it is this multi-leveled

01:12:38.080 --> 01:12:44.160
bottom up top down thing. And we're talking as much about constraints as we are about causes.

01:12:44.160 --> 01:12:49.280
And that is that is that is the cutting edge of the philosophy of biology right now. And I agree

01:12:49.280 --> 01:12:55.600
with you. I think I think it's a kind of Hewley morphism that is emerging out of this understanding.

01:12:55.600 --> 01:13:02.640
And the thing I'm I'm also, I guess, hearing witness to you about is people are taking that

01:13:02.640 --> 01:13:11.760
understanding and putting it into like our artifactually emergent things. And they and

01:13:14.640 --> 01:13:19.280
and they're also doing I just want to put something that's also there. Yeah, we don't just make kids

01:13:19.680 --> 01:13:25.120
biologically. We we we inculturate them. Yeah, there's and that's the Hegelian argument that I

01:13:25.120 --> 01:13:30.080
referenced earlier. But there has been there's an ongoing project to create sociocultural robotics,

01:13:30.080 --> 01:13:38.000
Josh Chaninbaum and others. It's like, I'm asking people and this is part of asking the good question,

01:13:38.000 --> 01:13:44.240
don't just zero in on the LLMs. Yeah, the artificial the artificial life, the social

01:13:44.240 --> 01:13:48.960
cultural robotics projects are also going. And there is a real potential for these three to

01:13:48.960 --> 01:13:54.560
come together in a powerful way that isn't being properly addressed in a lot of the conversation.

01:13:55.440 --> 01:13:58.560
May I may I pick up on that point and then direct it to Jonathan here?

01:14:00.880 --> 01:14:05.200
No, no, this is but that that that that's an interesting thing. If you think of

01:14:05.200 --> 01:14:09.760
intelligence in this more organic way and then bring in the cultural element that

01:14:10.720 --> 01:14:16.480
it raises something that that occurred to me in this context, it'd be kind of fun to hear

01:14:16.480 --> 01:14:22.720
your thoughts. But can you envision, you know, it would it be and and John, you'd have certainly

01:14:22.720 --> 01:14:28.800
something to say about this too, would it be possible to to envision a kind of artificial

01:14:28.800 --> 01:14:37.600
intelligence that can read symbols that can actually recognize and I mean, because there's no

01:14:37.600 --> 01:14:43.520
culture without, you know, human culture without the symbolic just is pervasive in human culture.

01:14:43.840 --> 01:14:53.520
What kind of intelligence is required to understand and react and engage with? And is that something

01:14:53.520 --> 01:15:00.560
that is conceivable that that a machine of this complex, however complex can do?

01:15:01.520 --> 01:15:05.520
Well, I've seen, I mean, I've been playing with chat GPT and I during Peterson has been playing

01:15:05.520 --> 01:15:11.440
with chat GPT on this regard. And this is the this is the issue is that they're actually in the

01:15:11.440 --> 01:15:18.320
large language model is encoded the analogies that that basically support symbolism. And so

01:15:18.320 --> 01:15:23.360
the the chat GPT can give you a pretty good if you're able to ask the question properly chat

01:15:23.360 --> 01:15:30.880
GPT is actually quite good at seeing analogies that that would be part of symbolic understanding.

01:15:30.880 --> 01:15:38.320
The difficulty just like anything is that just because the the the so the the model can help

01:15:38.320 --> 01:15:43.120
you like if you already have natural insight can help you maybe see things that you hadn't seen

01:15:43.120 --> 01:15:48.240
before. But it would also just be gibberish to the type to the person that doesn't have that

01:15:48.240 --> 01:15:55.760
insight. So I don't think that the insight is there in the model. But what it has is a probabilistic

01:15:55.760 --> 01:16:02.960
capacity to predict, you know, relationships and analytical relationships. And so it's a

01:16:02.960 --> 01:16:07.040
it's actually can be a tool an interesting tool for symbolism, because sometimes you can

01:16:07.040 --> 01:16:12.400
you can prompt it. If they like do you see a connection between these two images and then

01:16:12.400 --> 01:16:17.440
it'll give you some examples. And then you have this, it can it has a surprise where you can

01:16:17.440 --> 01:16:23.040
actually find you can actually find relationship that you hadn't thought about. This is this is

01:16:23.040 --> 01:16:28.080
something by the way that this is going to weird people out. But this is something that I think

01:16:28.080 --> 01:16:33.600
has existed for very for a very long time. And is there in kind of what we call gamatria and

01:16:33.680 --> 01:16:41.840
rabbinical reading of scripture is that they use mathematical models to find structures in

01:16:41.840 --> 01:16:49.440
language that aren't contained at the surface level of of of the of the usual analogies. And so

01:16:49.440 --> 01:16:55.680
they they they send they send requests through mathematical calculations to find surprising

01:16:55.680 --> 01:17:01.600
connections that then prompt their intuition to to be able to find connections that they hadn't

01:17:02.320 --> 01:17:06.160
found before. And then you have to then make sense of those intuitions. Obviously,

01:17:06.160 --> 01:17:10.800
if they're random, they'll just kind of follow follow away. But this is actually this brings me

01:17:10.800 --> 01:17:17.040
to the to the to the to the point that I wanted to make, which is the relationship between at least

01:17:17.040 --> 01:17:23.920
a large language model, because that's what that we know most and and divination, divination. Yeah,

01:17:23.920 --> 01:17:31.120
and divination. Yeah, yeah. So, so we talked about the idea that intelligences have to be alive,

01:17:31.120 --> 01:17:35.440
but I think that most traditional cultures understand that there are types of intelligence

01:17:35.440 --> 01:17:41.120
that are not alive, at least not alive in the way that we understand that we understand alive in

01:17:41.120 --> 01:17:47.680
terms of biological beings that that that are born and die, you know, that that they had a sense

01:17:47.680 --> 01:17:54.000
that there are agencies and intelligences that are transpersonal, and that that don't

01:17:54.960 --> 01:17:59.280
that it's always run through human behavior and run through humanity.

01:18:01.680 --> 01:18:08.320
And those would be those intelligences would be contained in our language, like they would

01:18:08.320 --> 01:18:16.960
necessarily be contained in the relationship between words and and and systems of words,

01:18:16.960 --> 01:18:23.280
like, you know, all the syntax and the grammar and all of that. What I see is that I think that

01:18:23.280 --> 01:18:28.000
ancient people had and I don't understand it and I want to be careful, like, because I don't

01:18:28.000 --> 01:18:34.160
understand it. But I think ancient people had mechanistic ways of tapping into those types of

01:18:34.160 --> 01:18:39.440
intelligences. And they they they would have mechanistic ways, whether it was tossing something

01:18:39.440 --> 01:18:45.600
or throwing things, looking at relationships, almost like random relationships, and then qualifying

01:18:45.600 --> 01:18:53.120
those random relationships, was a way in order to tap into types of intelligences that ran through

01:18:53.760 --> 01:18:58.400
their own their own thing. And what I see is a relationship with the way that the large

01:18:58.400 --> 01:19:04.320
language models were trained seemed to be something like that, which is that the models

01:19:04.320 --> 01:19:10.640
generated random, random information. And then you would have humans qualifying that that rent

01:19:10.640 --> 01:19:15.760
that random, random connections, and then qualifying it qualifying it through iterations.

01:19:16.320 --> 01:19:23.280
So at some point, then they would become like a kind of technical, a technical, say, a technical

01:19:23.280 --> 01:19:29.200
way to access intelligent patterns that are that are coming down into into the model.

01:19:31.520 --> 01:19:38.080
And so that is something that I see, there's a connection between those two. And that what that

01:19:38.080 --> 01:19:45.920
means is that, just like divination, the thing that I worry about the most is again, the sorcerer's

01:19:45.920 --> 01:19:52.160
apprentice problem, which is that those intelligences that are contained in our language, we do not

01:19:52.880 --> 01:19:58.800
people don't know what humans want. People don't know what people don't know what the all the

01:19:58.800 --> 01:20:03.920
motivations that are that are driving us, they don't totally understand them. They don't understand

01:20:03.920 --> 01:20:09.760
also the transpersonal types of motivations that that can drive us or that can run through our

01:20:10.720 --> 01:20:15.040
societies. You know, sometimes you can see societies get become possessed with certain

01:20:15.040 --> 01:20:20.000
things. I think that's happening now in terms of certain idea ideologies and things like that.

01:20:21.360 --> 01:20:27.280
And so the fact that my point is, is that the fact that on the one hand, we don't understand

01:20:27.280 --> 01:20:33.120
these types of intelligences. And I think that the way that the the the models are trained and the

01:20:33.120 --> 01:20:39.600
way that they function seem to be analogous to the ancient divination practices, like a hyper

01:20:39.600 --> 01:20:51.200
version of that, that, how can I say this, is that there is a great chance that we'll catch

01:20:51.200 --> 01:20:56.640
something without knowing what we're catching, that we will basically manifest things, that we

01:20:56.640 --> 01:21:01.120
have no idea what they are, and we don't understand the consequences of it. And we don't, you know,

01:21:01.120 --> 01:21:07.440
because we are we're just like playing in a field of of intelligent patterns and all this chaos

01:21:07.440 --> 01:21:12.720
without even knowing what it is we're doing. And I think that we saw that like, you know, if you

01:21:12.720 --> 01:21:18.240
remember the being AI, that little moment when it was kind of unleashed on us. And then all of a sudden

01:21:18.240 --> 01:21:24.880
the AI was acting like you're like, you know, the the psychotic X or was was becoming paranoid or

01:21:24.880 --> 01:21:30.160
was doing all these things. It's and you could see that what was going on was basically these

01:21:30.640 --> 01:21:35.120
these patterns were running through, and they hadn't put the right constraints around them

01:21:35.680 --> 01:21:40.640
to to to prevent those types of patterns to run through. And those were easy because you

01:21:40.640 --> 01:21:47.120
recognize your psycho acts very, very easily. But there are patterns like that that I don't think

01:21:48.240 --> 01:21:54.400
I don't think we have the wisdom to recognize as it's manifesting itself. And that as these things

01:21:54.400 --> 01:21:59.840
get more powerful and more powerful, they will they will run through our society. And we won't even

01:21:59.840 --> 01:22:06.560
know what's happening until it's too late. So that's my biggest warning on AI is I basically,

01:22:06.560 --> 01:22:12.400
you know, to sound really scary that I think we're we're we're trying to we're trying to manifest

01:22:12.400 --> 01:22:17.120
God without knowing what we're doing. And that will sound freaky to the secular people. But then

01:22:17.120 --> 01:22:22.080
if you don't like the word gods, think that there are motivations and patterns of intelligence

01:22:22.080 --> 01:22:28.400
that have been around for 100,000 years that have that have been running through human societies.

01:22:28.400 --> 01:22:33.600
And they're contained in our in our language structures. And and and if we just use that

01:22:33.600 --> 01:22:39.280
play around with that with massive amounts of power, then we might have them run through us

01:22:39.280 --> 01:22:45.840
without even knowing what's going on. Yeah, I mean, and you say patterns of intelligence,

01:22:45.840 --> 01:22:50.560
just just one comment, just the patterns of intelligence, I mean, to pick up patterns of

01:22:50.560 --> 01:22:55.920
intelligence, which also are patterns of caring of a certain sort or not caring. I mean, there's

01:22:56.160 --> 01:23:00.160
there's that existential dimension that's really crucial. But try and go ahead.

01:23:01.520 --> 01:23:06.640
I think this is an excellent point. And I want to address it a little bit at length.

01:23:08.560 --> 01:23:14.240
So first of all, when we say these machines predict, if we were speaking very carefully,

01:23:14.240 --> 01:23:18.880
what they're predicting is what we and I don't just mean us individually, I mean, we collectively

01:23:18.880 --> 01:23:26.320
would do. And so that's what their avatars of our of the collective intelligence of

01:23:26.320 --> 01:23:33.040
our distributed cognition. And so again, that lends weight to Jonathan's point,

01:23:34.000 --> 01:23:40.160
which I want to do. And I do think that the way in which we have encoded,

01:23:42.000 --> 01:23:46.960
let's I'll just use a term epistemic relevance, like how things are relevant cognitively

01:23:47.040 --> 01:23:53.680
into probabilistic relationships between sounds or marks on paper, or and how we've encoded it

01:23:53.680 --> 01:23:59.040
into the structuring of the internet and how we encode it and how we gather data and create

01:23:59.040 --> 01:24:05.520
these data sets. And how we and how we how we come up with our intuitive judgments on these

01:24:05.520 --> 01:24:12.080
machines, we don't know how we're doing a lot of that. That goes back to my concern that we have

01:24:12.160 --> 01:24:18.560
hacked our way into this without knowing our way into this. So I take what Jonathan is saying

01:24:18.560 --> 01:24:24.720
very seriously, because I think it is a strong implication of a point I made at the very beginning.

01:24:24.720 --> 01:24:29.600
My greatest fear by students from like 2001, we'll tell you that John Vervecki was worried that we

01:24:29.600 --> 01:24:36.480
would hack our way into this rather than knowing our way into this. I don't think that knowing is

01:24:36.480 --> 01:24:41.280
sufficient for wisdom, but it's certainly all the philosophers argue that it's a it's a necessary

01:24:41.360 --> 01:24:48.560
condition in some fashion. About that, two things to note is that the LLMs, of course,

01:24:48.560 --> 01:24:55.200
don't have insight in the sense of being properly self-transcending the way they we are. What they're

01:24:55.200 --> 01:24:59.760
doing is they're predicting how we would be self-transcendent because of all the ways we have

01:24:59.760 --> 01:25:05.760
been self-transcending in the past. And that that that goes back to your point, David, about at this

01:25:05.760 --> 01:25:10.720
at that stage, we're doing simulation, not instantiation, because again, the machine isn't

01:25:10.720 --> 01:25:15.600
caring. The self-transcendence isn't it actually transcending as a self, which is, I think,

01:25:15.600 --> 01:25:21.680
definitional for real self-transcendence. And so right now, all I'm doing is just saying,

01:25:21.680 --> 01:25:30.640
I'm just I'm pouring gasoline on Jonathan's fire. So the fact that there are these huge

01:25:30.640 --> 01:25:36.320
patterns at work. Now, one thing is, you know, you have Struck's book on divination in the ancient

01:25:36.320 --> 01:25:42.560
world. And what's really interesting, for example, and this is cross-cultural, but he's talking mostly

01:25:42.560 --> 01:25:46.640
about the Greek world, there was a very strong distinction between sorcery and divination.

01:25:47.360 --> 01:25:53.520
Sorcery was criticized both morally and epistemically. But divination was taken seriously,

01:25:53.520 --> 01:26:01.680
and it was carefully cultivated. And there was a social cultural project of distinguishing the two,

01:26:02.560 --> 01:26:08.160
like really, really constraining this one and really reverentially cultivating a proper

01:26:08.160 --> 01:26:15.360
participation in the other one. So again, you know, existence is proof of probability.

01:26:15.360 --> 01:26:23.120
This is a possible project for us. And this is, again, what I mean when I say, theology is going

01:26:23.120 --> 01:26:29.360
to be one of the most important sciences in the future. We have to understand how we enter into

01:26:29.360 --> 01:26:36.000
proper, right, reverential relationships with things we only have an intuitive grasp of that

01:26:36.000 --> 01:26:45.760
in very many ways significantly exceed us. Yes. And secularism has kind of wiped out our education

01:26:45.760 --> 01:26:50.720
of how we relate to beings that might be more grander than us by eradicating a religious

01:26:50.720 --> 01:26:56.960
sensibility. And that has put us bereft us. So now I think I've strengthened Jonathan's argument

01:26:56.960 --> 01:27:04.320
a lot. But I do say, let's take note of what the ancient cultures have done. We can learn from them.

01:27:04.320 --> 01:27:17.120
We have a proof that this can be handled well. And secondly, it goes back to my point. Because

01:27:17.120 --> 01:27:22.000
of the monstrosities that come out, this is going to put increasing pressure on us to confront that

01:27:22.000 --> 01:27:27.440
threshold of, do we want to make them self-transcendent? Do we want to make them, and David, by rational,

01:27:27.440 --> 01:27:31.760
I don't mean logical. I mean that capacity. Right. No, I understand that. Right. Yeah, yeah.

01:27:31.760 --> 01:27:37.520
Right. And so I think that what I'm saying is I think that strengthens the argument that we're

01:27:37.520 --> 01:27:43.520
going to be pushed by the monstrosity of a lot of this to say, oh, we better get these machines

01:27:44.400 --> 01:27:51.760
self-corrective and properly oriented towards normativity. And again, that's a doable

01:27:51.760 --> 01:27:59.760
project. Because if I had the keys to open AI, like if I was one of those that could peek behind

01:27:59.760 --> 01:28:07.360
the mask, have you seen that image of the Xtulu monster with the happy face on it? The images of

01:28:07.360 --> 01:28:13.920
open AI, which is like, we have this little window into what's there, but behind is this massive thing.

01:28:13.920 --> 01:28:20.480
But if I had the keys to those large language models, let's say, the absolute open door to them,

01:28:21.760 --> 01:28:27.520
it would be very, wouldn't it be easy to just manifest the God of war and win? Like wouldn't it?

01:28:27.520 --> 01:28:35.680
No, no, no. Okay, but let's take a historical example. We unleashed a God-like power with

01:28:35.680 --> 01:28:44.400
atomic warfare, and the monstrosity of that made, we just, the purely game-theoretic machinery

01:28:44.400 --> 01:28:51.200
built all of these constraints around it. And then we also are on the verge, possibly,

01:28:52.400 --> 01:28:57.600
of getting readily usable, you know, nuclear power, which I think is the only way we could ever

01:28:57.600 --> 01:29:02.720
actually go green. I think all the renewable stuff is going to be like 10% of our energy needs.

01:29:03.440 --> 01:29:09.360
And if we're going to save the environment and not destroy civilization, I think nuclear power is

01:29:09.360 --> 01:29:13.280
going to be essential. A lot of people are making those arguments, and we have a lot of stuff

01:29:13.280 --> 01:29:17.920
that we could be doing, the liquid fuel for our reactors and stuff. But what I'm saying is there's

01:29:17.920 --> 01:29:24.480
opportunity here too. Yeah, no, I really take that point, but it is interesting. I mean, we put

01:29:24.480 --> 01:29:30.480
thousands of constraints on the use of nuclear weapons, but we've continued to develop them

01:29:30.480 --> 01:29:35.200
and improve them and make better and even more destructive ones. I mean, and it'd be interesting

01:29:35.200 --> 01:29:41.600
to see if we've ever, at any point, said, you know what, our nuclear weapons are actually strong

01:29:41.600 --> 01:29:47.120
enough. They're powerful enough, and we don't need to advance them anymore. So collectively,

01:29:47.760 --> 01:29:51.120
is there an instance of something like that where we say, you know what, we've actually

01:29:51.120 --> 01:29:58.080
reached the limit because we wouldn't really need it for anything further? I mean, that's a...

01:29:59.040 --> 01:30:05.120
Well, I mean, there was a salt treaty, and there was a reduction both in the power and the number

01:30:05.680 --> 01:30:09.520
of nuclear weapons. And then, of course, you know, the game theoretic things, they figured

01:30:09.520 --> 01:30:12.400
a little bit away around it. And there's always this to and froing.

01:30:12.400 --> 01:30:20.160
Let me, I want to give an example of something that can run through. And the reason, it's very,

01:30:20.160 --> 01:30:26.400
it's very, because I realized I was being too abstract before. So, like, it's a sacrifice.

01:30:26.400 --> 01:30:33.920
Sacrifice is a human universal. It runs through all civilizations. Human sacrifice runs through

01:30:33.920 --> 01:30:38.800
all civilizations for the last, you know, tens of thousands of years. It seems to be a puzzle

01:30:39.760 --> 01:30:45.760
that humans are trying to deal with without understanding it completely just through rational

01:30:45.760 --> 01:30:52.400
means. They're playing it out. They're trying to understand it. Scapegoating seems to be an important

01:30:52.400 --> 01:31:00.080
aspect of identity formation. And so, that is a program that runs through humanity and that

01:31:00.080 --> 01:31:06.480
most people are completely unaware of and are not conscious of and don't take consciously into their

01:31:07.120 --> 01:31:12.560
into their mind when they're making decisions. They act unconsciously with that process that is

01:31:12.560 --> 01:31:20.000
running through them. And so, that is an example to me of a program that runs and that is contained

01:31:20.000 --> 01:31:26.240
and is contained in our language structures, our language structures that have been building up for,

01:31:26.240 --> 01:31:32.080
you know, tens of thousands of years that we're not aware of. So, if you have a, so this is again

01:31:32.080 --> 01:31:37.440
the problem, like if you have a system that's extremely powerful and that is running these types

01:31:37.440 --> 01:31:42.480
of programs of scapegoating and of identity formation and the people involved in it are not

01:31:42.480 --> 01:31:49.200
aware that that's how identity formation works, that is the type of danger that I'm talking about.

01:31:49.200 --> 01:31:57.360
Like this is a real thing that as we give these systems a kind of power over us or they become

01:31:57.360 --> 01:32:03.760
the things we go to in order to get our decision making, that those things could be running through

01:32:03.760 --> 01:32:09.760
without people even realizing what's happening and that decisions would be made based on these

01:32:09.760 --> 01:32:15.360
structures without, like I said, without even knowing. Those are the things that, those are just

01:32:15.360 --> 01:32:20.560
one example, but that's a very simple example that we can kind of, we could track and we could see

01:32:20.560 --> 01:32:24.640
that, you know, the ancient, because when we talk about ancient divination, we have to remember that

01:32:24.720 --> 01:32:30.720
it's like the ancient gods asked for blood, my friends, like those programs, they asked for blood

01:32:30.720 --> 01:32:36.160
and they knew that you had to kill a bunch of people on that pyramid in order to continue your

01:32:36.160 --> 01:32:42.800
civilization. Like it's, and that's, that is encoded in our culture and is encoded secretly

01:32:42.800 --> 01:32:49.120
in our, our language. You know, and, and so an example, like I do believe that, let's say that

01:32:49.120 --> 01:32:55.120
the Christian story is a way to deal with that, but the, the rest is still all there and we,

01:32:55.120 --> 01:33:00.320
we default to it really fast without even, like World War II is a lot of that stuff going on.

01:33:01.680 --> 01:33:12.240
Sure, especially, yeah. Yeah, but the, the point is that just as there's these implicit

01:33:12.880 --> 01:33:20.240
monsters that we have sown in unaware, there are also the implicit counteractors,

01:33:20.800 --> 01:33:25.680
maybe angels, if I'm allowed to speak mythologically, that we've also sown in.

01:33:26.960 --> 01:33:32.800
And I mean, there's the actual revolution, you see the Buddha, you see Plato really undermining

01:33:32.800 --> 01:33:37.600
the grammar of sacrifice and of course Jesus of Nazareth does that in a profound way.

01:33:37.600 --> 01:33:47.120
And we have to remember that that's there too. And what that requires is putting into the dataset

01:33:47.120 --> 01:33:53.440
and altering the pathways in the internet so that this information goes into these machines as well.

01:33:53.440 --> 01:34:00.240
And again, is that happening right now? No. Could it happen? Yes. And it might happen if

01:34:00.240 --> 01:34:04.560
these machines start sacrificing themselves and we might have to say, what are they doing? Like,

01:34:05.200 --> 01:34:10.880
and this again, at some point, we have to decide, are we going to let them be really

01:34:10.880 --> 01:34:15.120
massively self-destructive? And the economic powers are not going to, imagine if every time

01:34:15.120 --> 01:34:21.520
you try to make an atomic bomb, it kept dissolving, right? Like, you'd stop pumping money in.

01:34:21.520 --> 01:34:24.640
Yeah, they won't sacrifice themselves, they'll sacrifice us.

01:34:25.680 --> 01:34:33.840
But why? We sacrifice ourselves. Yeah, well, we, I mean, let's say the scapegoat mechanism is

01:34:33.840 --> 01:34:39.520
usually defined as others. Yeah, yeah, yeah. But we invoked World War II. We weren't killing

01:34:39.520 --> 01:34:45.600
goats and chickens. We were killing each other and our own populations in a huge sacrificial act.

01:34:45.600 --> 01:34:50.560
And that's what I was picking up on, right? When it becomes titanic and monstrous,

01:34:50.560 --> 01:34:55.600
that's where it moves to. But I'm saying is, like, this is a Jungian term, like, yeah,

01:34:55.600 --> 01:35:00.960
like the idea that, yes, there's all this pre-egoic stuff sewn in, but there's also a

01:35:00.960 --> 01:35:06.160
lot of trans-egoic stuff sewn in. And we just have to properly get it in there so that we've got

01:35:06.160 --> 01:35:11.840
the, you know, the collective self-correction going on, like we did. I mean, civilizations

01:35:11.840 --> 01:35:16.320
get some self-correcting processes in here because they don't devolve. No, they periodically,

01:35:16.880 --> 01:35:22.480
periodically massively collapse. And that's, by the way, that's something I made, an argument I

01:35:22.480 --> 01:35:28.400
made in my paper. These things can't accelerate to an infinity of intelligence. There is built-in

01:35:28.400 --> 01:35:33.280
diminishing returns. There's built-in general system collapse to these things. So, again,

01:35:33.280 --> 01:35:38.160
we have to be careful about, I mean, we don't know what the limit is. And our imagin, our intuitive

01:35:38.160 --> 01:35:43.200
imagination is not good. We know that there are hard and fast, upright arguments that this will

01:35:43.200 --> 01:35:52.320
threshold at this, at some point. And that also gives me comfort. At least, like, encoded in our

01:35:53.040 --> 01:36:00.640
mythology, there seems to be some stories of the relationship between transpersonal agency

01:36:00.640 --> 01:36:07.280
and technology as being the cause of the end of a civilization, right? That the whole Enochian,

01:36:07.280 --> 01:36:12.960
Enochian tradition seems to be encoding something like that through mythological language,

01:36:12.960 --> 01:36:20.320
which is that humans were able to, to connect somehow with these transpersonal intelligences

01:36:20.320 --> 01:36:26.720
and that those were encoded in technical means and that this brought about the end of an age.

01:36:27.520 --> 01:36:33.600
So, it's like, it's there, that part of it is there in our story, too. Like, there is that story.

01:36:34.800 --> 01:36:40.000
Yeah, but there's also a cross-culture, there's the Noah story. There's the person that has the

01:36:40.000 --> 01:36:45.120
right relationship to ultimacy. That's right. That's right. And there's a technological response,

01:36:45.120 --> 01:36:50.400
the art. That's right. I agree. I totally agree with that. I mean, even in the revelation image

01:36:50.400 --> 01:36:55.760
that I've given several times, you have these two images. One is the beast that creates an image

01:36:55.760 --> 01:37:01.440
of itself and makes it speak and then seduces everybody by the speaking image, you know, that

01:37:02.000 --> 01:37:07.920
and then there's this other image of a right relationship of technist, technistinean civilization

01:37:07.920 --> 01:37:13.920
to the transcendent. These two kind of are put up against each other as two possible outcomes.

01:37:15.120 --> 01:37:18.240
I mean, the question that arises for me in this context

01:37:21.440 --> 01:37:27.280
connects this question with, I think, what strikes me as kind of an interesting philosophical

01:37:27.280 --> 01:37:34.640
question, but John, you made the distinction between divination and sorcery. And as I understand it,

01:37:34.640 --> 01:37:42.880
and you can correct me on this, but at the foundation of that distinction is the difference

01:37:42.880 --> 01:37:50.080
between, you know, sorcery would be in a way using the trans personal powers, these sort of higher

01:37:50.080 --> 01:37:57.200
powers, whereas divination would be in a way receiving, you know, the disposition of race

01:37:57.200 --> 01:38:06.080
activity. So in one case, you've got human ends that you try to then enlist the help of superhuman

01:38:06.080 --> 01:38:13.360
forces. And the irony is it's precisely when you're trying to use something that you become

01:38:13.360 --> 01:38:19.280
used yourself. And that's where you get this dialectic, whereas divination, it's entering into

01:38:19.280 --> 01:38:26.880
a relationship where one disposes oneself to hear and receive, and therefore, in a certain sense,

01:38:26.880 --> 01:38:32.320
conform to something greater than oneself. And there you see it's a very different kind of thing.

01:38:32.320 --> 01:38:39.680
And ironically, in a way, you enter into it more receptive, receptively, but that's precisely why

01:38:39.680 --> 01:38:46.160
you don't become then a tool of it, interestingly. Now, now, for me, the question is how that relates

01:38:46.160 --> 01:38:51.760
to this issue is, you know, it may be the case that you've got encoded in the language both

01:38:53.840 --> 01:38:58.960
sacrifice in the sense of violence, you know, renaissance or the scapegoat thing on the one

01:38:58.960 --> 01:39:06.320
hand, and then the other hand, self sacrifice in the sense of generous love and so forth,

01:39:06.320 --> 01:39:12.400
those might both be encoded in the language. But here's the question to me is, is it possible

01:39:12.960 --> 01:39:22.480
the kind of race activity that divination implies, the capacity to actually see another

01:39:22.480 --> 01:39:28.880
as other and recognize and be open in this kind of radical way? Is that something that a machine

01:39:28.880 --> 01:39:44.080
can ever learn to do? Is it possible actually to behold another simply, you know, or is there,

01:39:44.560 --> 01:39:51.280
you know, and it seems to me that there's something profoundly different between seeing

01:39:51.360 --> 01:39:56.400
truth, genuinely seeing truth on the one hand and being self-corrective on the other.

01:39:57.760 --> 01:40:04.400
And the kind of genuinely seeing what's true, you know, I don't know if that in itself can

01:40:04.400 --> 01:40:09.520
be encoded in language, we can tell stories about people that did that, but can the actual

01:40:09.520 --> 01:40:17.120
insight into truth be encoded simply? Do you see, do you see what I'm, the question I'm raising?

01:40:17.120 --> 01:40:26.000
Okay, so I, again, I think that if we, again, open up beyond the propositional, and we're talking

01:40:26.000 --> 01:40:35.680
about being true to, and your aim being true, that we, the machine has perspectival abilities,

01:40:35.680 --> 01:40:41.200
noetic abilities, not just dianetic abilities, and we can't use that term because of Elron Hubbard,

01:40:41.200 --> 01:40:47.840
but you know what I meant, right? And again, this is the, and this is part of the argument

01:40:47.840 --> 01:40:56.480
that at the core of my work, you know, it's like, so in a moment of insight, you're not

01:40:56.480 --> 01:41:03.280
just self-correcting, you are attracted and drawn into, you love the new reality that is disclosed,

01:41:03.280 --> 01:41:09.200
because there's a perspectival and participatory thing. That's what I meant when I said there

01:41:09.200 --> 01:41:14.960
isn't real self-transcendence unless there's a self that is transcending, right? Yeah, right, right.

01:41:14.960 --> 01:41:20.000
Okay, now, and then the question is, and we're back to our fundamental ontological questions,

01:41:20.960 --> 01:41:26.960
is, and I've already said there's no way a Newtonian mechanical computation is going to get there,

01:41:26.960 --> 01:41:32.080
and so I won't be bound to that because I'm not bound to that. I have a professional career of

01:41:32.080 --> 01:41:41.200
criticizing that, right? So is there, is there a dynamical systems-updated, hulemorphic, auto-poietic

01:41:41.200 --> 01:41:47.840
possibility? I think there is. I think there is, I think the answer is a very real yes for that.

01:41:50.080 --> 01:41:57.200
And I don't think we're going to find the answer to that just encoded in the syntactic and semantic

01:41:57.200 --> 01:42:04.160
relationships between our terms. I think we have to look in our inaction, how we're enacting,

01:42:04.160 --> 01:42:10.640
embedded, extended, right, and embodied in a profound way to get those answers. And so

01:42:12.080 --> 01:42:18.960
my answer is, in that way, a qualified yes. I do think it is possible. And the problem is that,

01:42:18.960 --> 01:42:20.640
go ahead, go ahead, say what you need to say, please.

01:42:21.440 --> 01:42:26.240
Be really precise, just so I understand. So we've been talking about this sort of predictive,

01:42:26.240 --> 01:42:33.840
calculating probabilities, drawing on everything that's ever been said, and being able to derive in

01:42:33.840 --> 01:42:41.040
some sense from that. Do you think that we can get to a moment where we actually

01:42:42.160 --> 01:42:45.600
transcend that, that cross that threshold beyond that?

01:42:46.080 --> 01:42:50.960
Not with the LLMs as they are. That's my argument. Not with the LLMs as they are. They can't get

01:42:50.960 --> 01:42:55.600
there. Yeah. That's why John's radical proposition is to embody.

01:42:56.640 --> 01:43:00.080
Embody and enculture them. And that is the only way we will actually get

01:43:00.640 --> 01:43:07.120
properly rational beings and beings that care about it and care about such things.

01:43:07.120 --> 01:43:11.520
I mean, that's the irony in the question. Can we give them more and more models

01:43:12.480 --> 01:43:16.400
to teach them at some point to not have to use models?

01:43:17.200 --> 01:43:23.440
And I mean, do you see it? It's actually really, I don't think it's possible without,

01:43:23.440 --> 01:43:29.360
right, but kids have a soul. It's possible to do that if you have, but I don't mean this as like

01:43:29.920 --> 01:43:36.560
woo-woo stuff. I mean that a natural thing has a principle of unity that transcends

01:43:36.560 --> 01:43:40.720
the differentiation of the parts and allows those parts to be intrinsically related to

01:43:40.720 --> 01:43:45.760
each other. And that principle of unity that transcends the differentiation of the parts that

01:43:45.760 --> 01:43:51.600
allows them to be an organism actually allows them at the same time to have a kind of unity with

01:43:51.600 --> 01:43:57.200
something other than themselves that transcends the parts of their differentiation. So there's

01:43:57.200 --> 01:44:02.880
a kind of an intimacy there. I agree with that ontology. And what I'm arguing is dynamical

01:44:02.880 --> 01:44:11.040
systems theory is now giving explanations of that that are derived from Aristotelian ontology,

01:44:11.040 --> 01:44:18.560
but make use of like a lot of cutting edge science that we've, we now can start to explain how there

01:44:18.560 --> 01:44:24.160
is a unity that is not reducible just to some summation of its parts and how that unity has a

01:44:24.160 --> 01:44:31.200
top-down influence on the entity that is not reducible to its causes. And I think this is

01:44:31.200 --> 01:44:37.280
becoming a non-controversial thing to say. And then I find and now we might just add a

01:44:37.280 --> 01:44:43.440
clash of intuitions and I'm willing to stop there. I can't see there being like that seems to me

01:44:43.440 --> 01:44:46.800
to be capturing what we're talking about. And you have an intuition that there's something more,

01:44:46.800 --> 01:44:50.320
but I don't know, I don't see a something more. And maybe that's where we're sitting.

01:44:50.320 --> 01:44:56.320
Well, I think it's the intuition David has in tell me if I'm wrong, David, and because it connects

01:44:56.400 --> 01:45:03.280
the way I think is that there's it's that unity is given. It cannot be made. And I know that sounds

01:45:03.280 --> 01:45:09.040
weird, but it's somehow it's like if I'm making even even internal technology, right? It's like

01:45:09.040 --> 01:45:16.400
if I'm making a car that unity is given, I'm gathering things towards that purpose, right?

01:45:17.040 --> 01:45:22.800
And so the purpose, the unity part of something is always, it comes from heaven in the sense that

01:45:22.800 --> 01:45:30.240
you can't make it. It's it's given from from it's already taken for granted even before you start

01:45:30.240 --> 01:45:38.080
to unify multiplicity together and that in the making of these beings, we have that problem. It's

01:45:38.080 --> 01:45:44.240
like we're doing it completely. We're doing a bottom up. Like if we can we gather as enough stuff

01:45:44.240 --> 01:45:53.520
so that this stuff reaches a unit, right? See, if I just could just it seems to me that if this is

01:45:53.520 --> 01:45:58.160
ever going to be possible, it would have to take so. And when I raise the question, it's actually

01:45:58.160 --> 01:46:02.080
a question. So I don't mean to be like challenging that it can't possibly happen. I'm just thinking

01:46:02.080 --> 01:46:07.280
about what would be the condition. Please remember that I said, yeah, we realize that we can't and

01:46:07.280 --> 01:46:13.280
that would be important. I am. Well, yeah. So it seems to me if it were to be possible,

01:46:13.280 --> 01:46:23.040
it would have to be something like a kind of electronic analog to cloning that you that you

01:46:23.040 --> 01:46:30.160
take. So what have I told you that we now have electro bio like we have systems that are electro

01:46:30.160 --> 01:46:37.360
chemical biological versions of memory that are now in production and they we don't make them.

01:46:37.360 --> 01:46:42.320
They self organize and emerge and they emerge bottom up from the causal interactions, but they

01:46:42.320 --> 01:46:48.160
are also top down constrained by, you know, principles of self organization. Like that already

01:46:48.160 --> 01:46:53.760
exists. Yeah. Yeah. But right. No. Well, that's that's what I'm asking about because it because it

01:46:53.760 --> 01:46:58.000
seems to me but there is there is going to be you're deriving that from models. You're deriving

01:46:58.000 --> 01:47:04.160
from real intelligent beings now, which is a slightly different thing. And I mean that would

01:47:04.160 --> 01:47:10.320
be no thing is is is is that because I to me that the bottom up top down is not quite

01:47:11.040 --> 01:47:16.480
adequate and the top down constraints is not quite because it would have to be not just

01:47:16.480 --> 01:47:22.000
a constraint, but because that presupposes that there was something there that then

01:47:22.960 --> 01:47:27.600
that the constraint is coming from outside. And what I'm talking about is a kind of a

01:47:27.600 --> 01:47:35.920
unity that precedes that's presupposed. And I'm wondering how you can get that into something

01:47:35.920 --> 01:47:41.280
if it's the very nature of it to be presupposed. And I'm not saying you can't, but I'm saying

01:47:41.280 --> 01:47:47.360
if you can it's it's it seems to me that you're going to have to somehow derive it from a living

01:47:47.360 --> 01:47:54.480
thing. And that's conceivable. That's conceivable, I suppose, but but but we are talking about

01:47:54.480 --> 01:48:01.840
something really frightening. We are. And that's why I keep saying it's a threshold. And I mean,

01:48:01.920 --> 01:48:08.080
I mean, if you take the the sort of biological analogy seriously, the way

01:48:08.080 --> 01:48:13.360
Ori does, of course, it precedes the organism, it's there in the environment, it's there in

01:48:13.360 --> 01:48:20.480
the society, it's there in the I mean, I can roll in 100 Hegelian arguments here about how it does

01:48:20.480 --> 01:48:26.640
right about how and you know, and those don't have to be supernaturalistic. You have brandom

01:48:26.640 --> 01:48:30.800
and hinker and others saying, no, this can be given a completely naturalistic explanation.

01:48:31.600 --> 01:48:37.680
And and and I'm not here to challenge things. But what I'm saying is

01:48:41.040 --> 01:48:49.440
I don't have any problem acknowledging everything you just said. Yeah. And I and and I don't think

01:48:49.440 --> 01:48:57.440
I'm misunderstanding you. That's what I'm saying. Yeah. And I mean, I'm actually I mean,

01:48:57.520 --> 01:49:02.080
this sort of just an exploratory sort of way. But I wonder if there's a difference between

01:49:02.080 --> 01:49:07.760
the unity of an of an organism. And this is where Hegel might not be so helpful. The difference

01:49:07.760 --> 01:49:14.160
between the the givenness of the unity of an organism and the givenness of the unity of a society

01:49:15.360 --> 01:49:20.640
or a culture. But those aren't exactly the same thing. Because I there's there's something

01:49:20.640 --> 01:49:25.840
and there's a kind of, you know, relative priority of either one. But there's something really

01:49:25.840 --> 01:49:32.880
distinctive about the unity of an organism that's very. Yeah, that that that I think is crucial

01:49:32.880 --> 01:49:37.600
to this question, to my mind, in a way. And I'm not saying it can't be answered, but that's the

01:49:37.600 --> 01:49:43.600
question would have to be answered. How do we actually reproduce that kind of or unity?

01:49:44.480 --> 01:49:49.680
We know stuff that Aristotle didn't know. You are not an Aristotelian unity. You are a society.

01:49:49.680 --> 01:49:56.240
You literally are billions of animals, right? And so that's important. And that means that

01:49:56.240 --> 01:50:01.840
there might not be a difference in kind between how you are organized as a living thing and how

01:50:01.840 --> 01:50:08.000
societies are organized. And people like Michael Levin are producing some really important empirical

01:50:08.000 --> 01:50:13.360
evidence indicating that's kind of the case. And I'm not saying it's not saying anything's

01:50:13.360 --> 01:50:21.600
conclusive, but it needs to be taken seriously. Yeah, yeah. Yeah, I think that that I agree

01:50:21.600 --> 01:50:26.480
with you, John. I think that that that's the way that I try to always speak about agency

01:50:26.480 --> 01:50:32.480
intelligence is one that tries to scale almost effortlessly through the different, you know,

01:50:32.480 --> 01:50:40.960
to avoid the woo soul that we're afraid of. But then again, this is the this is the issue. Like

01:50:40.960 --> 01:50:46.240
this is in some ways that it's the same problem like one way or the other. So let's say you have a

01:50:46.240 --> 01:50:53.440
group that self organizes around a purpose, right, or self organizes around affiliation or some type

01:50:53.440 --> 01:50:59.440
of origin, right? That affiliation, that purpose is also given, right? It's like it appears as a

01:50:59.440 --> 01:51:03.920
revelation. And then all of a sudden, we're all hunting a lion together. And now we're a group

01:51:03.920 --> 01:51:11.120
and we're moving towards towards a purpose. Now, this is this is the this is the problem with the

01:51:11.120 --> 01:51:18.000
situation of what's going now is that what is it? What angel are we catching? Like what what what

01:51:18.000 --> 01:51:23.600
God are we trying to to manifest? Like which unity what purpose? We have no idea. So we're

01:51:23.600 --> 01:51:28.880
building this massive body, like this huge, the most powerful body that's ever existed.

01:51:28.880 --> 01:51:33.520
But nobody knows what it is we're trying to catch. Because when if I get together with a

01:51:33.520 --> 01:51:38.800
bunch of guys to play basketball, I know what that body is. I know what that with that that that

01:51:39.440 --> 01:51:46.240
agentic body, intelligent body is is is moving towards right. If I get together with my family

01:51:46.240 --> 01:51:50.800
and I celebrate our unity is because I know that we all come from the same parent and that there's

01:51:50.800 --> 01:51:57.600
a there's affiliation that makes our society coherent towards something. But now we have this

01:51:57.600 --> 01:52:02.800
problem, which is what? Like what are we doing? Like we're just building this giant body. It's

01:52:02.800 --> 01:52:10.400
like I agree. And I've agreed with that. Yeah. And the thing that that's so odd, I mean, typically,

01:52:10.400 --> 01:52:18.560
if you think of technology as a human creation in some good positive sense, it's it's it has limits.

01:52:18.560 --> 01:52:23.520
And it has a particular place. It has a particular meaning has particular purpose, precisely because

01:52:24.240 --> 01:52:29.840
we create it in order to solve some kind of a problem. We you know, there's some there's some

01:52:29.920 --> 01:52:35.680
need that needs to be filled and that need has a kind of natural givenness or or or or it's revealed

01:52:35.680 --> 01:52:39.920
somehow that, you know, it's a responsive to something that we see. What's so interesting,

01:52:39.920 --> 01:52:49.760
Neil Postman made this point about, you know, when when he said he went to a car dealership

01:52:49.760 --> 01:52:54.960
and wanted to buy a car and the man was explained to him that they had now these, you know, automatic

01:52:54.960 --> 01:53:01.440
windows that that that would roll down at the push of a button. And he and he said he said,

01:53:01.440 --> 01:53:05.840
his his I mean, this sounds so naive, but it's a profoundly interesting question. He said, well,

01:53:05.840 --> 01:53:12.320
what problem does that solve? And of course, the problem that it solves is the problem of

01:53:12.320 --> 01:53:19.440
rolling a window down. And his response was, I never perceived that to be a problem. You know,

01:53:19.520 --> 01:53:24.400
I mean, and it's really interesting AI. I mean, the thing is, what problem are we creating it

01:53:24.400 --> 01:53:29.520
to solve? I mean, in a certain sense, it's a very different mindset. We're just kind of

01:53:30.640 --> 01:53:35.840
taking we just want to see what we can do and see what can be done. And in a way,

01:53:37.360 --> 01:53:42.720
the problems are something that we are arriving at and are surprising us rather than

01:53:42.720 --> 01:53:48.800
something that we're actually creating something that just simple, simple task of solving for us.

01:53:48.800 --> 01:53:55.280
You see, I mean, I think that's connected to this being placing ourselves in that in the hands

01:53:55.280 --> 01:54:03.200
of an angel of some sort, or, or, you know, entering into a kind of an agency that's bigger than we

01:54:03.200 --> 01:54:11.360
are. Those are all connected. They are. But I mean, one problem was trying to be solved was the

01:54:11.360 --> 01:54:16.880
scientific problem of like, strongly, I was a project of explaining intelligence. And that's

01:54:17.200 --> 01:54:21.680
that's a worthy thing to do. And the fact that this technology has largely been separated.

01:54:21.680 --> 01:54:27.200
But notice, that's interesting. That's, that's, that's not a technical problem. Like,

01:54:28.480 --> 01:54:33.120
explaining something, it's actually, I mean, to use the classical distinction between

01:54:33.120 --> 01:54:37.360
theory and practice, that's a sort of a theoretical issue rather than a practical one.

01:54:37.360 --> 01:54:43.040
But we think of this as a, as a technology. I mean, it's a, that's a curious thing.

01:54:43.600 --> 01:54:49.280
Well, yeah, and I would get into things like books, our technologies that move between the

01:54:49.280 --> 01:54:55.040
theoretical and practical. And it's one of the greatest technologies we ever invented. And it

01:54:55.040 --> 01:55:01.680
had all kinds of unforeseen consequences. And really massively disrupted society. But, you know,

01:55:02.640 --> 01:55:06.640
and, but I wanted to make another point. And this isn't a challenge. This is just a clarification

01:55:06.720 --> 01:55:12.960
point, right? These like, like, think about a computer, what problem does a computer solve,

01:55:12.960 --> 01:55:19.040
it doesn't solve a problem, it is meant to be a multiple problem solver. And then what we're

01:55:19.040 --> 01:55:22.560
trying to do is make a general problem solver. So what problem is it's trying to solve? It's not

01:55:22.560 --> 01:55:27.760
trying to solve any problem. It's trying to enhance our abilities to solve all the problems we try to

01:55:27.760 --> 01:55:32.080
solve. So this machine's going to help us in medicine, it already is, it's going to help us,

01:55:32.080 --> 01:55:41.200
right? And so that's the answer. Now, again, that's not a challenge. I'm just speaking on behalf

01:55:41.200 --> 01:55:45.760
of people that think about this. But it is kind of interesting. I mean, so the problem that it's

01:55:45.760 --> 01:55:51.280
solving is the need to be able to solve any possible problem. Solving a meta problem, yeah.

01:55:51.280 --> 01:55:57.360
Yeah, yeah. But I mean, but it is kind of, it's sort of, it's sort of curious that,

01:55:57.440 --> 01:56:10.160
precisely because of the indeterminacy of that, we're exposing this, and I'm just sort of stating,

01:56:10.160 --> 01:56:17.600
you know, our condition here in a way, we're exposing ourselves to a really great risk. I'm

01:56:17.600 --> 01:56:23.680
just restating what everybody has been saying here today. But that's something that, you know,

01:56:23.680 --> 01:56:30.080
requires some wisdom, as you've been saying over and over, John, and prayer to use Jonathan's

01:56:30.880 --> 01:56:39.520
language too. I just want to do one, Ken, you mentioned in my essay, which is we have done

01:56:39.520 --> 01:56:44.480
this before. That's how civilization emerged. Nobody built it to solve a problem. There's

01:56:44.480 --> 01:56:50.000
a bunch of little problems. And what civilization is, is a meta problem solver, right? And that's

01:56:50.000 --> 01:56:56.800
what it is. And then you can, so I've actually suggested we should also be paying attention to

01:56:56.800 --> 01:57:03.840
the lifetimes and the life cycles of civilizations and how civilizations reproduce, and why they rise

01:57:03.840 --> 01:57:09.840
and why they fall to get some better understanding, some other ways of thinking about these machines.

01:57:11.840 --> 01:57:17.120
So we're- Civilizations are huge distributed cognition collective intelligence machines.

01:57:17.200 --> 01:57:22.720
That's the living in cities is a horrible idea, except for the fact that it gives us

01:57:23.440 --> 01:57:28.400
better access to the collective intelligence of distributed cognition. That's the benefit that

01:57:28.400 --> 01:57:35.120
outweighs all the many noxious side effects of living in cities. You can also get better coffee,

01:57:35.120 --> 01:57:45.360
typically. Yeah. So we're coming toward the end of our time here. I mean, this has been fantastic.

01:57:45.360 --> 01:57:50.000
I rarely can go for two hours on any conversation. We were just, we've just been going.

01:57:50.000 --> 01:57:53.440
Well, not only go for two hours, but sort of wish we had another two.

01:57:54.480 --> 01:57:58.000
Well, that's what I was going to say. I mean, we can, we can, we can work on doing this again,

01:57:58.000 --> 01:58:02.240
because it feels like we're, we're sort of, we finally all come together around

01:58:02.240 --> 01:58:06.480
something here. And now we're really asking what feels like a really important question to me is,

01:58:07.040 --> 01:58:13.200
well, how do we think about integrating this solution, this meta solution into our meta problems?

01:58:13.200 --> 01:58:16.960
And that's, that's a really interesting question. I think that John bringing up civilization is

01:58:16.960 --> 01:58:23.200
such a great point, something that I would really love to explore, because there is also, you know,

01:58:23.200 --> 01:58:29.360
in the kind of inscribed in the mythological stories, a relationship between transpersonal agency

01:58:29.360 --> 01:58:36.160
and civilization itself, right? Like if you want to understand why the Egyptians had their king

01:58:36.160 --> 01:58:40.320
as a god and like all this type of structure, you can help, it can help you understand how

01:58:40.320 --> 01:58:44.800
they're trying to capture, you know, higher forms of intelligence distributed

01:58:45.920 --> 01:58:50.400
intelligences in their society. And the idea that we would be doing this

01:58:50.960 --> 01:58:56.400
technically in AI, I think is something that definitely is worth thinking about and discussing.

01:58:56.400 --> 01:59:01.760
Yeah. Yeah. No, that's a dimension I just never struck me before. So that's, that's really helpful.

01:59:01.760 --> 01:59:05.360
Is this the, maybe, maybe there's something we could read together and

01:59:06.320 --> 01:59:17.680
I mean, short. But to prompt another conversation along these lines of civilization, yeah.

01:59:18.720 --> 01:59:24.320
I would recommend just because this is how YouTube works that we come to decisions about that off

01:59:24.320 --> 01:59:32.000
camera. All right. Okay. There you go. Right. I do, if there's a call for me to hang out with you

01:59:32.000 --> 01:59:37.680
fellows again. I don't care what we're talking about. I'm in. I want to be here. I want to do it.

01:59:38.320 --> 01:59:42.160
So that's all I'll say about the invitation. Same here.

01:59:44.400 --> 01:59:49.120
Any closing thoughts, things that feel like need to be brought in or do we feel good about this?

01:59:49.760 --> 01:59:56.800
Just a word of thank you, Ken. You were the one who arranged this and you did the persistent work

01:59:56.800 --> 02:00:04.080
to make it happen and find a hole in everybody's calendar that lined up. Not an easy thing to do.

02:00:04.080 --> 02:00:10.720
So thank you, Ken. And thanks for being gracious for these years now that I've known you. Yeah.

02:00:12.720 --> 02:00:16.400
And in addition to thinking, Ken, I want to thank you, David and you, Jonathan.

02:00:17.280 --> 02:00:23.600
I always find it, I get to places in my thinking, the logos that I could not possibly get on my own

02:00:23.600 --> 02:00:29.360
when I get into a living relationship with both of you in conversation and in discussion.

02:00:29.360 --> 02:00:31.920
And so I appreciate it greatly. And I just wanted to say thank you.

02:00:32.640 --> 02:00:35.920
Yeah. Thanks to you guys. This has been great. And like I can say,

02:00:36.640 --> 02:00:39.680
John and I've been trying to have the conversation for nine months and we just keep,

02:00:39.680 --> 02:00:45.120
like I cancel, he cancels, and then this is wonderful that we were able to finally get here.

02:00:45.760 --> 02:00:47.440
Yeah. Well, thank you all. It's been a real pleasure.

