1
00:00:00,000 --> 00:00:04,840
I was invited by François Chavre to keynote one of the days of the Knowledge Graph

2
00:00:04,840 --> 00:00:11,440
Conference in May 2023 in New York, New York. This is a post-conference recording

3
00:00:11,440 --> 00:00:18,120
of the talk. François asked me what topic I want to talk about. I said wiki data

4
00:00:18,120 --> 00:00:23,040
and wiki functions and he said, do you have something else to talk about? You

5
00:00:23,040 --> 00:00:27,800
talked about it the last time you were here at the conference in 2019 and I

6
00:00:27,800 --> 00:00:35,960
said there's one topic everyone talks to me about and this is what about

7
00:00:35,960 --> 00:00:42,800
knowledge graphs and large language models and he said perfect do that and

8
00:00:42,800 --> 00:00:46,800
I thought great given how much I have been talking and thinking about it I

9
00:00:46,800 --> 00:00:53,240
probably should have a good idea what I want to say by May. Well it's May now and

10
00:00:53,400 --> 00:00:59,840
I'm still full of doubts about what to say. I recently stumbled upon this quote

11
00:00:59,840 --> 00:01:04,640
looking at books for my daughter and it gives me some hope for the talk today.

12
00:01:04,640 --> 00:01:12,680
When in doubt you can't be wrong. So let this be my first disclaimer for today. I

13
00:01:12,680 --> 00:01:18,080
am most certainly in doubt. I don't know what the future of knowledge graphs is

14
00:01:18,080 --> 00:01:23,120
but I have been talking about this for a decade now for a lot of very smart

15
00:01:23,120 --> 00:01:28,720
people so I hope that what I say will prove your time. There is one thing I

16
00:01:28,720 --> 00:01:35,040
have no doubts about. Something big is happening. See this is from the book

17
00:01:35,040 --> 00:01:40,320
Diffusion of Innovation. It shows how technology is adopted. Well my brother

18
00:01:40,320 --> 00:01:44,840
who lives in a small village of 180 people on a Croatian island he is

19
00:01:44,840 --> 00:01:51,480
roughly here on this chart but he called me last fall to talk about stable

20
00:01:51,480 --> 00:01:56,480
diffusion the image generation model. Chatchity P a large language model

21
00:01:56,480 --> 00:02:04,520
reached 100 million users two months after launch. This is a record in how

22
00:02:04,520 --> 00:02:08,760
fast the technology is spreading. If there's one thing we don't need to be

23
00:02:08,760 --> 00:02:14,600
in doubt about is that these technology are having a large impact on the world.

24
00:02:14,600 --> 00:02:19,680
Last year in September that's two months before the release of Chatchity P a

25
00:02:19,800 --> 00:02:23,880
number of researchers and practitioners in the knowledge graph field met in

26
00:02:23,880 --> 00:02:28,480
Dachstuhl in Germany. Our goal was to discuss the role of knowledge

27
00:02:28,480 --> 00:02:32,840
engineering in the 21st century like we were almost under a kind of shock

28
00:02:32,840 --> 00:02:36,920
talking about it processing and trying to figure out what it really means for

29
00:02:36,920 --> 00:02:42,360
us. I'm trying to distill some of the results from that seminar and also from

30
00:02:42,360 --> 00:02:47,040
any other conversations I had in this talk but you can also just go and read

31
00:02:47,040 --> 00:02:55,080
the report directly. My second disclaimer nothing in this talk is generated by an AI.

32
00:02:55,080 --> 00:03:00,680
And this explicitly marked so or you see a screenshot from an AI. This is not one

33
00:03:00,680 --> 00:03:04,680
of those talks where we have a reveal at the end that all of this was generated.

34
00:03:04,680 --> 00:03:12,800
And finally the last disclaimer this is a focused talk it is only about knowledge

35
00:03:12,800 --> 00:03:18,080
graphs and large language models. It is not about the ethical questions of

36
00:03:18,080 --> 00:03:22,960
large language models. It's not about blunders of current LLMs. It's not of the

37
00:03:22,960 --> 00:03:29,320
that those systems will have about the impact on jobs and the economy. It's not

38
00:03:29,320 --> 00:03:33,360
about questions of copyright or whether LLMs are a path to destruction of the

39
00:03:33,360 --> 00:03:37,760
human race. All of these questions are interesting and deserve their own talks

40
00:03:37,760 --> 00:03:44,840
and I will not talk about them today. So what makes me believe that there is a

41
00:03:44,840 --> 00:03:49,840
future for knowledge graphs in the world of large language models? About six or

42
00:03:49,840 --> 00:03:54,640
seven years ago I was working at Google on the knowledge graph. Back then the

43
00:03:54,640 --> 00:03:59,600
knowledge graph wasn't necessarily a generic term yet. It was a big question

44
00:03:59,600 --> 00:04:04,640
Google had to ask itself. The knowledge graph costs a lot of resources, a lot of

45
00:04:04,640 --> 00:04:09,200
money, a lot of manpower to run and maintain. A lot of people were working on

46
00:04:09,200 --> 00:04:13,640
the knowledge graph. Is all of this work going to be obsolete? Should we stop

47
00:04:13,640 --> 00:04:19,040
investing in that? I give you the answer that I came up with back then. Let's

48
00:04:19,040 --> 00:04:25,640
think first principles. So what is a knowledge graph? A knowledge graph represents

49
00:04:25,640 --> 00:04:30,400
things and the relations usually stored in a graph database. WikiData is an

50
00:04:30,400 --> 00:04:34,400
example. WikiData is the largest publicly available free knowledge graph that

51
00:04:34,400 --> 00:04:39,920
anyone can edit. What is a large language model? Model here means that we have a

52
00:04:39,920 --> 00:04:44,920
neural network, nodes connected with each other with weights. The weights in

53
00:04:44,920 --> 00:04:49,000
this neural networks are trained on some input and desired outputs in order to

54
00:04:49,000 --> 00:04:54,160
create good outputs on novel inputs. They are language models because they are

55
00:04:54,160 --> 00:04:59,560
trained on natural language texts and it is a large language model because it is

56
00:04:59,560 --> 00:05:04,960
trained on lots and lots of natural language texts. GPT is a family of large

57
00:05:04,960 --> 00:05:10,080
language models which have been created by OpenAI. GPT-4 is the current version

58
00:05:10,080 --> 00:05:13,880
but OpenAI has not published much data about it. So the following data is for

59
00:05:13,880 --> 00:05:22,400
GPT-3. GPT-3 has 96 such layers in the picture and it had 175 billion

60
00:05:22,400 --> 00:05:29,120
parameters. That is weights. As a large language model, GPT-3 has been trained to

61
00:05:29,120 --> 00:05:34,920
provide appropriate answers to a given prompt to our input. So for example, given

62
00:05:34,920 --> 00:05:38,640
the following input or prompt, who created the School of Athens.

63
00:05:38,640 --> 00:05:44,680
JGDP answers, the School of Athens is a famous fresco painted by the Italian

64
00:05:44,680 --> 00:05:50,520
Renaissance artist Raphael. It was painted between 1509 and 1511 as part of a

65
00:05:50,520 --> 00:05:54,920
commission for the Vatican's Apostolic Palace in Rome. The fresco is widely

66
00:05:54,920 --> 00:06:01,320
regarded as one of the greatest works of art of the high Renaissance. This answer

67
00:06:01,320 --> 00:06:05,640
is not only correct, it is brilliant. There's absolutely nothing to complain

68
00:06:05,640 --> 00:06:12,560
about. It gives context, it answers the question. It's great. If you go to Google

69
00:06:12,560 --> 00:06:17,200
and ask the same question, the answer is the same, Raphael. But the context is even

70
00:06:17,200 --> 00:06:24,240
more amazing. A picture from Raphael, his biography, data about him, who influenced

71
00:06:24,240 --> 00:06:29,040
him, other artists that are being searched for. The answer is just beautiful and

72
00:06:29,040 --> 00:06:35,320
amazing. You can also go to Wikidata and write a sparkle query, asking for the

73
00:06:35,320 --> 00:06:41,760
creator of the School of Athens. Again, you will get the result, Raphael. Not as

74
00:06:41,760 --> 00:06:51,480
pretty as Google, not as much context as with JGDP. But here's one thing, JGDP took

75
00:06:51,560 --> 00:06:56,720
about five seconds to answer my question. Admittedly, it gave a lot of context I

76
00:06:56,720 --> 00:07:02,720
didn't ask for, but even just passing the question took close to a second. Google

77
00:07:02,720 --> 00:07:07,200
took half a second, including passing, but it also got a lot of great context and

78
00:07:07,200 --> 00:07:09,960
gave me results from the search index, even though they didn't make it to a

79
00:07:09,960 --> 00:07:16,360
screenshot. Wikidata took about a quarter of a second to produce the answer, and

80
00:07:16,360 --> 00:07:21,800
that's not all. JGDP is running on the fastest and most expensive hardware you

81
00:07:21,800 --> 00:07:26,760
can buy. Google is running on the fastest and most expensive hardware you

82
00:07:26,760 --> 00:07:32,040
cannot buy. And the Wikidata query service is running abandonware on a

83
00:07:32,040 --> 00:07:39,000
server somewhere. And if you think about this, it is not surprising. The query I

84
00:07:39,000 --> 00:07:43,560
asked had six tokens of input. A token is roughly a word for a natural language

85
00:07:43,560 --> 00:07:48,600
model. And the answer produced 60 tokens. Now, if the answer would just have been

86
00:07:48,600 --> 00:07:53,400
Raphael, it would still have been at least two tokens. Every single token runs for

87
00:07:53,400 --> 00:08:00,120
the 96 layers of JGDP, branching out to 175 billion weights and multiplying

88
00:08:00,120 --> 00:08:06,840
matrices and soft maximum results. Whereas in Wikidata, we look up an item out

89
00:08:06,840 --> 00:08:11,720
of 100 million and find a key out of 10,000 to get the results values. Those

90
00:08:11,720 --> 00:08:18,040
are both logarithmic operations. It's just much cheaper. Given this paper,

91
00:08:18,040 --> 00:08:22,920
getting and hosting your own copy of Wikidata, 1,000 Wikidata queries, like

92
00:08:22,920 --> 00:08:29,240
the ones I just asked, would cost me about 14 cents in the cloud. The authors thought

93
00:08:29,240 --> 00:08:32,680
this was too expensive and bought their own hardware to make it even cheaper.

94
00:08:32,680 --> 00:08:38,760
Whereas if I look at Azure pricing for GPT-4, a thousand queries, as asked before,

95
00:08:38,760 --> 00:08:48,440
would cost $7.56. So that's 14 cents compared to more than $7, so a factor of 50.

96
00:08:48,440 --> 00:08:54,600
50 times more expense can make a difference. Now, to make it very clear, I don't know

97
00:08:54,600 --> 00:08:58,680
how robust these numbers are. I would love to see more robust numbers and I expect

98
00:08:58,680 --> 00:09:04,200
the cost for inference to go down. But even Sam Altman, the CEO of OpenAI,

99
00:09:04,200 --> 00:09:09,720
the company making JetGDP, describes the compute cost of JetGDP as eye-watering.

100
00:09:10,760 --> 00:09:14,600
And don't forget, he made a really good deal with Microsoft about running it on Azure.

101
00:09:15,880 --> 00:09:20,040
John Hennessey, chairman of Google and former computer science professor at Stanford,

102
00:09:20,040 --> 00:09:25,080
so he really knows what he's talking about, said that running at JetGDP, like Google,

103
00:09:25,080 --> 00:09:31,800
would be 10 times more expensive. And that's just talking about the inference costs. Each

104
00:09:31,800 --> 00:09:37,320
of these models also need to be trained. And current state-of-the-art language models cost

105
00:09:37,320 --> 00:09:44,600
millions of dollars to train. For GPT-4, the cost was given as more than $100 million.

106
00:09:46,600 --> 00:09:53,240
The cost for GPT-3 was around $4 million. Good news is, you probably don't have to do this

107
00:09:53,240 --> 00:09:58,680
training. But you can just hopefully reuse an existing open source model that you can find

108
00:09:58,680 --> 00:10:04,200
due to your task. This will be considerably cheaper to train a model from the foundation on.

109
00:10:04,920 --> 00:10:08,680
But not for inference. The same cost that we saw earlier remains.

110
00:10:10,920 --> 00:10:15,800
Here's some interesting new thoughts. Some folks, like Sam Altman, think that the age of

111
00:10:15,800 --> 00:10:21,720
large language models is already over. OpenAI says it's because of diminishing returns of further

112
00:10:21,720 --> 00:10:26,680
reading. Guess what? After reading a million books worth of text, you don't seem to learn too much

113
00:10:26,680 --> 00:10:34,840
new stuff. He said that OpenAI is not working on GPT-5, but that they want to explore new ideas.

114
00:10:34,840 --> 00:10:39,880
And that's great. Because with models that are more readily available out there, such as Metas

115
00:10:39,880 --> 00:10:47,000
Llama, we can see new ideas happening very fast. For example, when Llama was leaked within days,

116
00:10:47,000 --> 00:10:52,840
someone managed to run it on consumer hardware. A few days later, we got it running on a phone,

117
00:10:52,840 --> 00:11:00,120
and then a Raspberry Pi. It was very slow, but it ran. And by the way, as ridiculous as that sounds,

118
00:11:00,120 --> 00:11:04,040
this still means that these giant models are more expensive to run than a knowledge graph.

119
00:11:04,840 --> 00:11:09,160
And really, it's not just cost, right? There are a few challenges that large

120
00:11:09,160 --> 00:11:13,800
language models need to overcome. We need new ideas for those. Let's take a look.

121
00:11:15,720 --> 00:11:21,720
Here's one thing that surprised me a lot. A few weeks ago, I stumbled into one of those Wikipedia

122
00:11:21,720 --> 00:11:28,120
rabbit holes where I got temporarily obsessed with figuring out one specific fact. The correct

123
00:11:28,120 --> 00:11:35,160
place of birth of a not-too-well-known Croatian actress, Anna Begovic. I was surprised that

124
00:11:35,160 --> 00:11:40,120
Google and Wikipedia Wikidata were giving different answers, so I tried to figure out

125
00:11:40,120 --> 00:11:46,920
the truth and fix it. Here's a screenshot of Google answering the question. Begovic was born in

126
00:11:46,920 --> 00:11:53,960
Terpan. Wikipedia used to say split. After a bit of hunting through sources, I figured out that it

127
00:11:53,960 --> 00:12:01,720
mostly likely is Terpan, though. And that a lot of the sources were copying from Wikipedia and Wikidata

128
00:12:01,720 --> 00:12:08,360
and became contaminated by Wikipedia and Wikidata. This is an example of our knowledge ecosystem being

129
00:12:08,440 --> 00:12:13,800
substantial danger, by the way, and that long before we have LLM syndemics.

130
00:12:15,880 --> 00:12:22,360
Now, if you go to Bing Chat, which is powered by OpenAI's GPT, but has access to web search

131
00:12:23,080 --> 00:12:28,760
and ask for the place of birth of Anna Begovic, it also answers me Terpan, which is great,

132
00:12:28,760 --> 00:12:34,440
and it gives me free sources for that answer. It's just very disappointing that if you follow

133
00:12:34,440 --> 00:12:39,080
one of the references to Wikipedia, you will actually find it says split.

134
00:12:40,200 --> 00:12:45,480
When I asked ChatGDP instead of Bing Chat, I get a different answer. It answers split.

135
00:12:46,200 --> 00:12:51,560
This is not too surprising. After all, Wikipedia was claiming split until just a few weeks ago,

136
00:12:51,560 --> 00:12:57,720
and ChatGDP was trained on a 2021 copy of the web. Corrections to Wikipedia done in 2023

137
00:12:57,720 --> 00:13:01,560
would not show up. Split is totally expected as an answer here.

138
00:13:02,360 --> 00:13:07,160
What is interesting, though, is if I ask the same question in Croatian,

139
00:13:08,280 --> 00:13:16,280
I get a different wrong answer. Zagreb. Now, that's an interesting answer,

140
00:13:16,280 --> 00:13:24,040
because it demonstrates us two things. First, knowledge in ChatGDP seems to be not stored in

141
00:13:24,040 --> 00:13:30,200
a language independent way, but is stored within each individual language. Depending on the language

142
00:13:30,200 --> 00:13:36,920
I ask the question in, I receive a different answer. Also, the English answer at least has

143
00:13:36,920 --> 00:13:43,640
support in the training data. Wikipedia did say split. The Croatian answer, where does Zagreb come

144
00:13:43,640 --> 00:13:49,400
from? I can find a single source that says that Anna Begovic was born in Zagreb.

145
00:13:49,640 --> 00:13:57,560
But here's the thing. What if ChatGDP is actually just guessing, it's just making it up?

146
00:13:58,600 --> 00:14:03,400
What is the probability of Zagreb given the prior of Croatian actress?

147
00:14:05,000 --> 00:14:11,720
In order to figure that out, I want to check Wikipedia. I ask ChatGDP to give me a sparkle

148
00:14:11,720 --> 00:14:18,520
query for Croatian actors in the places of birth. The query it returns to me is good enough for our

149
00:14:18,520 --> 00:14:25,640
purpose. I can just copy and paste it. It is subtly wrong if you read it in detail. It does not ask

150
00:14:25,640 --> 00:14:31,720
for Croatian actors, but for actors born in the place in Croatia. But again, good enough for our

151
00:14:31,720 --> 00:14:41,800
purposes. But still, this is fascinating. ChatGDP got out of the box all of the QIDs right in this

152
00:14:41,800 --> 00:14:49,000
query. For Croatia, for actor, it got a property ID right. It can make sparkle queries that are

153
00:14:49,000 --> 00:14:57,000
syntactically right. And all of that with zero shot extra training. There was no look up on the web.

154
00:14:57,000 --> 00:15:05,240
ChatGDP just knows these QIDs by heart. In fact, you can totally ask ChatGDP to make you a table

155
00:15:05,240 --> 00:15:11,240
of all the countries of the European Union and their QIDs. It has a lot of QIDs memorized.

156
00:15:11,800 --> 00:15:19,400
Just you never know if maybe one of them is wrong or not. The query can be copied and pasted right

157
00:15:19,400 --> 00:15:26,520
into the Wikipedia query service. And it runs giving 445 answers. And you can already see in the

158
00:15:26,520 --> 00:15:34,120
screenshot that the first few are all in Zagreb. So now we can see that of the 445 Croatian actors

159
00:15:34,120 --> 00:15:41,080
for place of birth, 154 are born in Zagreb, about a third. This gives a pretty good conditional

160
00:15:41,080 --> 00:15:48,120
probability for the birthplace of Croatian actors. ChatGDP is guessing the place of birth

161
00:15:48,120 --> 00:15:54,840
for Anna Begovic in Croatian, even though it knows it in English. This leads me to something my

162
00:15:54,840 --> 00:16:01,720
manager at Google used to say. You can machine learn Obama's birthplace every time you need it,

163
00:16:01,720 --> 00:16:05,160
but it costs a lot and you're never sure it is correct.

164
00:16:05,400 --> 00:16:12,360
Another interesting observation is that GPT isn't particularly good with knowing what it knows.

165
00:16:13,720 --> 00:16:20,920
For example, here we are asking for cities with mayors born after 1998. I wanted to ask something

166
00:16:20,920 --> 00:16:26,440
that I expected to be not trivially Google-able, where there wouldn't be a listicle or table on

167
00:16:26,440 --> 00:16:34,920
the map. So ChatGDP correctly points out that that would make them younger than 23 at its cutoff

168
00:16:34,920 --> 00:16:44,040
80 date of 2021. So it is unlikely that anyone would be mayor at that age. Asking Bing Chat,

169
00:16:44,040 --> 00:16:47,880
it also says that it doesn't know anything about mayors born after 1998.

170
00:16:50,360 --> 00:16:55,400
Let's check Wikidata. I again used ChatGDP to help me write a query, although this time I

171
00:16:55,400 --> 00:17:02,600
had to make a few fixes. And indeed, Wikidata has an answer. It tells me about Christian von

172
00:17:02,600 --> 00:17:08,360
Waldenfelds, who was born in April 2000, mayor of Lichtenberg in Bavaria, Germany.

173
00:17:09,720 --> 00:17:14,920
He became mayor in 2020, well before the cutoff date of Chaterity, by the way.

174
00:17:17,000 --> 00:17:21,400
This is no endorsement of his politics or his platform he is running, by the way.

175
00:17:23,960 --> 00:17:29,800
Now that we know the answers, we can guide Bing Chat and get the mayor of Lichtenberg and his age.

176
00:17:29,800 --> 00:17:33,720
And obviously this answer is inconsistent with its previous answer,

177
00:17:33,720 --> 00:17:38,840
but ChatGDP or BingJDP are both completely unaware of this inconsistency and don't care.

178
00:17:40,520 --> 00:17:45,480
Large language models are not yet graded being consistent, whether about individual facts

179
00:17:45,480 --> 00:17:53,000
or across different languages. They are also not always very good at math. But even if they were

180
00:17:53,000 --> 00:17:59,800
good at math, we have to answer the same question that we do for looking up facts in a knowledge

181
00:17:59,800 --> 00:18:10,440
graph. Why would you ever use 96 layers, 175 billion parameters model, to do multiplication?

182
00:18:11,080 --> 00:18:14,280
When that's something you can do in a single operation on your CPU.

183
00:18:15,640 --> 00:18:22,200
Why internalized knowledge in an LLM if you can externalize it in a graph store and look it up

184
00:18:22,280 --> 00:18:29,240
when needed. Don't get bedazzled by the capabilities of large language models.

185
00:18:30,920 --> 00:18:37,640
Autoregressive transformer models such as ChatGDP are touring complete and they are just a very

186
00:18:37,640 --> 00:18:44,360
expensive reiteration of touring's carpet. You can do everything with them, but it doesn't mean you

187
00:18:44,360 --> 00:18:51,400
should. Use LLMs where they are efficient and use other things where they are better.

188
00:18:53,160 --> 00:18:59,240
One possible solution to this capability gap are so-called augmented language models.

189
00:19:00,280 --> 00:19:06,040
Toolform are being a particularly well-known example. Or for ChatGDP, that's what ChatGDP

190
00:19:06,040 --> 00:19:12,360
plugins are there for. The idea is that we can enrich large language models with additional

191
00:19:12,360 --> 00:19:18,280
systems which are good and efficient at specific tasks, such as math or other functions,

192
00:19:18,440 --> 00:19:24,120
from wiki functions, or looking up facts or query results in a knowledge graph such as wiki data.

193
00:19:25,240 --> 00:19:31,800
I mean, given that ChatGDP already can, zero shot, create queries against wiki data,

194
00:19:31,800 --> 00:19:34,600
there isn't that much to do to make them work together.

195
00:19:37,080 --> 00:19:43,240
Some folks think that some mapping of strategic nodes into a knowledge graph with embeddings,

196
00:19:43,880 --> 00:19:47,320
we can easily connect a knowledge graph directly to a large language model.

197
00:19:48,520 --> 00:19:52,920
But we don't even need to do that, we can just use the Sparkle query generation ability

198
00:19:52,920 --> 00:20:00,280
directly and ask queries against wiki data. And not only can we connect LLMs to a knowledge

199
00:20:00,280 --> 00:20:06,360
graph, but also to a repository of functions, such as wiki functions. Both knowledge graphs and

200
00:20:06,360 --> 00:20:14,120
functions would be tools the LLM can learn to use. There is work in trying to understand

201
00:20:14,120 --> 00:20:18,680
how knowledge is stored in the parameters of a large language model. And when we look at this

202
00:20:18,680 --> 00:20:28,280
work, we start to understand why large language models are large. Do they really have to be this

203
00:20:28,280 --> 00:20:37,880
large? Let's compare with stable diffusion one. Stable diffusion one is a text to image generator.

204
00:20:37,880 --> 00:20:44,040
It has to understand natural language prompts, just as GPT does. It can make an image out of

205
00:20:44,040 --> 00:20:48,760
basically any prompt. It can also generate the image of a good number of celebrities.

206
00:20:48,760 --> 00:20:55,400
Here, for example, I'm asking for the Pope, Geleta Thunberg, Idris Elba, Michelle Yeo,

207
00:20:55,400 --> 00:21:00,600
Helen Mirren, and Yanle Kuhn to explain knowledge graphs with the help of a whiteboard.

208
00:21:02,360 --> 00:21:11,000
So GPT-3 had 175 billion parameters. How many parameters do you think are in stable diffusion

209
00:21:11,000 --> 00:21:19,880
one, knowing all these people being able to generate them? 890 million parameters.

210
00:21:20,760 --> 00:21:29,960
Now, I think 890 million is a lot. But GPT-3 is about 200 times larger than stable diffusion one.

211
00:21:31,240 --> 00:21:36,600
And it's no surprise. Think of it. All the knowledge that we were using for questions

212
00:21:36,600 --> 00:21:42,360
answering so far. The embedded QIDs, what are the member countries of the EU,

213
00:21:42,360 --> 00:21:49,640
the place of birth of individual people. I mean, if it has NABegovitch, I'm sure GPT-3 knows the

214
00:21:49,640 --> 00:21:55,640
place of birth of millions of individuals. All this taught in many different languages.

215
00:21:57,080 --> 00:22:01,320
All of this is taught in those hundreds of billions of parameters.

216
00:22:01,800 --> 00:22:06,600
You don't need that for text generation. But you need it if you want to answer all

217
00:22:06,600 --> 00:22:13,160
these questions we have been asking. And indeed, Metas Lama, which came out a few weeks ago,

218
00:22:13,160 --> 00:22:20,680
is considerably smaller than GPT-3, about 25 times smaller. But it seems to be

219
00:22:20,680 --> 00:22:27,400
rather competitive in terms of language understanding and fluency. So yes, we could

220
00:22:27,880 --> 00:22:34,920
internalize all the 1.4 billion statements in Wikidata into a large language model.

221
00:22:35,880 --> 00:22:41,560
But what if we go the other way around and try to externalize the knowledge model instead?

222
00:22:42,600 --> 00:22:47,480
If we leave the language model to deal with language, but push the knowledge

223
00:22:48,120 --> 00:22:53,960
to a knowledge graph or a different knowledge model, in a world where language models can

224
00:22:53,960 --> 00:23:01,960
generate infinite content, knowledge becomes valuable. And that takes us back to Jamie Taylor's

225
00:23:01,960 --> 00:23:08,520
rule. We don't want to machine learn Obama's place of birth every time we need it. We want to

226
00:23:08,520 --> 00:23:15,480
store it once and for all. And that's what knowledge graphs are good for. To keep you

227
00:23:15,480 --> 00:23:21,800
valuable knowledge safe. I am of the strict belief there is no reason to ever again

228
00:23:22,440 --> 00:23:29,720
manually enter the place of birth for Anna Begovic. This makes knowledge for Wikidata

229
00:23:29,720 --> 00:23:37,320
both valuable and a public good. The knowledge graph provides you with the ground truth for your

230
00:23:37,320 --> 00:23:44,360
language models. By the way, the other way around is also true. Large language models can be an

231
00:23:44,360 --> 00:23:50,360
amazing tool to speed up the creation of a knowledge graph. They are probably the best tool for

232
00:23:50,360 --> 00:23:58,200
knowledge extraction we have seen developed in a decade or two. We want to extract knowledge into

233
00:23:58,200 --> 00:24:08,040
a symbolic form. We want the system to overfit for truth. And this is why it makes so much sense

234
00:24:08,040 --> 00:24:16,040
to store the knowledge in a symbolic system. One that can be edited, audited, curated, understood.

235
00:24:16,680 --> 00:24:23,080
We can cover the long tail by simply adding new notes to the knowledge graph. One we don't train

236
00:24:23,080 --> 00:24:29,480
to return knowledge with a certain probability to make stuff up on the fly. But one where we can

237
00:24:29,480 --> 00:24:35,720
simply look it up. And maybe not all of the pieces are in place to make this happen just yet.

238
00:24:36,360 --> 00:24:41,480
There are questions around identity and embeddings. How exactly do they talk with each other?

239
00:24:41,800 --> 00:24:49,480
But there are good ideas to help with those problems. And knowledge graphs themselves should

240
00:24:49,480 --> 00:24:56,200
probably also evolve. I want to make one particular suggestion here. Freebase, the Google Knowledge

241
00:24:56,200 --> 00:25:02,760
Graph, Wikidata, they all have two kinds of special values or special statements. The third one is

242
00:25:02,760 --> 00:25:09,160
the possibility to say that a specific statement has no value. Here, for example, we are saying that

243
00:25:09,240 --> 00:25:17,080
Elizabeth I has no children. The second special value is the unknown value. That is, we know

244
00:25:17,080 --> 00:25:22,520
that there is a value for it, but we don't know what the value is. It's like a question mark in

245
00:25:22,520 --> 00:25:28,840
the graph. For example, we don't know who Adam Smith's father is, but we know he has one. It could

246
00:25:28,840 --> 00:25:33,240
be one of the existing notes. It could be one that we didn't represent yet. We have no idea.

247
00:25:34,200 --> 00:25:41,640
My suggestion is to introduce a third special value. It's complicated. I usually get people

248
00:25:41,640 --> 00:25:47,480
laughing when I make this suggestion, but I'm really serious. It's complicated is what you would use

249
00:25:47,480 --> 00:25:51,320
if the answer cannot be stated with the expressivity of your knowledge graph.

250
00:25:52,360 --> 00:25:58,840
This helps with maintaining the graph to mark difficult spots explicitly. This helps with

251
00:25:58,920 --> 00:26:06,840
avoiding embarrassing wrong or flat out dangerous answers. Given the interaction with LLMs,

252
00:26:07,400 --> 00:26:15,160
this can in particular mark areas of knowledge where we say, don't trust the graph. Can we instead

253
00:26:15,160 --> 00:26:20,120
train the LLM harder on this particular question and assign a few extra parameters for that?

254
00:26:20,280 --> 00:26:28,840
But really, what we want to be able to say are more expressive statements. In order to build

255
00:26:29,480 --> 00:26:35,800
a much more expressive ground truth, to be able to say sentences like these,

256
00:26:35,800 --> 00:26:41,960
Jupiter is the largest planet in the solar system. That's what we are working on right now.

257
00:26:42,520 --> 00:26:47,880
With abstract Wikipedia and leaky functions, we aim to vastly extend the limited expressivity

258
00:26:47,880 --> 00:26:56,600
of Viki data so that complicated things become stateable. This way, we hope to provide a ground

259
00:26:56,600 --> 00:27:05,720
truth for large language models. In summary, large language models are truly awesome. They are

260
00:27:05,720 --> 00:27:11,960
particularly awesome as an incredibly enabling UX tool. It's just breathtaking, honestly,

261
00:27:12,360 --> 00:27:19,080
things are happening which I didn't think possible in my lifetime. But they hallucinate.

262
00:27:19,720 --> 00:27:27,240
They need ground truth. They just make up stuff. They are expensive to train and to run.

263
00:27:28,200 --> 00:27:32,520
They're difficult to fix and repair, which is great if you have to explain someone,

264
00:27:32,520 --> 00:27:36,680
sorry, I cannot fix your problem. The thing is making a mistake, but I don't have a clue how to

265
00:27:36,680 --> 00:27:44,040
make it better. They are hard to audit and explain, which in areas like finance and medicine is crucial.

266
00:27:44,760 --> 00:27:50,200
They give inconsistent answers. They struggle with low resource languages.

267
00:27:51,560 --> 00:27:57,400
And they have a coverage gap on long tail entities, which is not easily overcome. All of these

268
00:27:57,400 --> 00:28:04,280
problems can be solved with knowledge graphs, which is why I think that the future of knowledge

269
00:28:04,280 --> 00:28:11,640
graphs is brighter than ever, especially thanks to a world that has large language models in it.

270
00:28:13,400 --> 00:28:17,640
Thank you for your attention. Thanks to all the people who helped me clarify my thinking

271
00:28:17,640 --> 00:28:26,440
around this topic. And if you have any questions, feel free to put them in the comments.

