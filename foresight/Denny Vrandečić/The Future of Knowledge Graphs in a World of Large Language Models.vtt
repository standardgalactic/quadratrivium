WEBVTT

00:00.000 --> 00:04.840
I was invited by François Chavre to keynote one of the days of the Knowledge Graph

00:04.840 --> 00:11.440
Conference in May 2023 in New York, New York. This is a post-conference recording

00:11.440 --> 00:18.120
of the talk. François asked me what topic I want to talk about. I said wiki data

00:18.120 --> 00:23.040
and wiki functions and he said, do you have something else to talk about? You

00:23.040 --> 00:27.800
talked about it the last time you were here at the conference in 2019 and I

00:27.800 --> 00:35.960
said there's one topic everyone talks to me about and this is what about

00:35.960 --> 00:42.800
knowledge graphs and large language models and he said perfect do that and

00:42.800 --> 00:46.800
I thought great given how much I have been talking and thinking about it I

00:46.800 --> 00:53.240
probably should have a good idea what I want to say by May. Well it's May now and

00:53.400 --> 00:59.840
I'm still full of doubts about what to say. I recently stumbled upon this quote

00:59.840 --> 01:04.640
looking at books for my daughter and it gives me some hope for the talk today.

01:04.640 --> 01:12.680
When in doubt you can't be wrong. So let this be my first disclaimer for today. I

01:12.680 --> 01:18.080
am most certainly in doubt. I don't know what the future of knowledge graphs is

01:18.080 --> 01:23.120
but I have been talking about this for a decade now for a lot of very smart

01:23.120 --> 01:28.720
people so I hope that what I say will prove your time. There is one thing I

01:28.720 --> 01:35.040
have no doubts about. Something big is happening. See this is from the book

01:35.040 --> 01:40.320
Diffusion of Innovation. It shows how technology is adopted. Well my brother

01:40.320 --> 01:44.840
who lives in a small village of 180 people on a Croatian island he is

01:44.840 --> 01:51.480
roughly here on this chart but he called me last fall to talk about stable

01:51.480 --> 01:56.480
diffusion the image generation model. Chatchity P a large language model

01:56.480 --> 02:04.520
reached 100 million users two months after launch. This is a record in how

02:04.520 --> 02:08.760
fast the technology is spreading. If there's one thing we don't need to be

02:08.760 --> 02:14.600
in doubt about is that these technology are having a large impact on the world.

02:14.600 --> 02:19.680
Last year in September that's two months before the release of Chatchity P a

02:19.800 --> 02:23.880
number of researchers and practitioners in the knowledge graph field met in

02:23.880 --> 02:28.480
Dachstuhl in Germany. Our goal was to discuss the role of knowledge

02:28.480 --> 02:32.840
engineering in the 21st century like we were almost under a kind of shock

02:32.840 --> 02:36.920
talking about it processing and trying to figure out what it really means for

02:36.920 --> 02:42.360
us. I'm trying to distill some of the results from that seminar and also from

02:42.360 --> 02:47.040
any other conversations I had in this talk but you can also just go and read

02:47.040 --> 02:55.080
the report directly. My second disclaimer nothing in this talk is generated by an AI.

02:55.080 --> 03:00.680
And this explicitly marked so or you see a screenshot from an AI. This is not one

03:00.680 --> 03:04.680
of those talks where we have a reveal at the end that all of this was generated.

03:04.680 --> 03:12.800
And finally the last disclaimer this is a focused talk it is only about knowledge

03:12.800 --> 03:18.080
graphs and large language models. It is not about the ethical questions of

03:18.080 --> 03:22.960
large language models. It's not about blunders of current LLMs. It's not of the

03:22.960 --> 03:29.320
that those systems will have about the impact on jobs and the economy. It's not

03:29.320 --> 03:33.360
about questions of copyright or whether LLMs are a path to destruction of the

03:33.360 --> 03:37.760
human race. All of these questions are interesting and deserve their own talks

03:37.760 --> 03:44.840
and I will not talk about them today. So what makes me believe that there is a

03:44.840 --> 03:49.840
future for knowledge graphs in the world of large language models? About six or

03:49.840 --> 03:54.640
seven years ago I was working at Google on the knowledge graph. Back then the

03:54.640 --> 03:59.600
knowledge graph wasn't necessarily a generic term yet. It was a big question

03:59.600 --> 04:04.640
Google had to ask itself. The knowledge graph costs a lot of resources, a lot of

04:04.640 --> 04:09.200
money, a lot of manpower to run and maintain. A lot of people were working on

04:09.200 --> 04:13.640
the knowledge graph. Is all of this work going to be obsolete? Should we stop

04:13.640 --> 04:19.040
investing in that? I give you the answer that I came up with back then. Let's

04:19.040 --> 04:25.640
think first principles. So what is a knowledge graph? A knowledge graph represents

04:25.640 --> 04:30.400
things and the relations usually stored in a graph database. WikiData is an

04:30.400 --> 04:34.400
example. WikiData is the largest publicly available free knowledge graph that

04:34.400 --> 04:39.920
anyone can edit. What is a large language model? Model here means that we have a

04:39.920 --> 04:44.920
neural network, nodes connected with each other with weights. The weights in

04:44.920 --> 04:49.000
this neural networks are trained on some input and desired outputs in order to

04:49.000 --> 04:54.160
create good outputs on novel inputs. They are language models because they are

04:54.160 --> 04:59.560
trained on natural language texts and it is a large language model because it is

04:59.560 --> 05:04.960
trained on lots and lots of natural language texts. GPT is a family of large

05:04.960 --> 05:10.080
language models which have been created by OpenAI. GPT-4 is the current version

05:10.080 --> 05:13.880
but OpenAI has not published much data about it. So the following data is for

05:13.880 --> 05:22.400
GPT-3. GPT-3 has 96 such layers in the picture and it had 175 billion

05:22.400 --> 05:29.120
parameters. That is weights. As a large language model, GPT-3 has been trained to

05:29.120 --> 05:34.920
provide appropriate answers to a given prompt to our input. So for example, given

05:34.920 --> 05:38.640
the following input or prompt, who created the School of Athens.

05:38.640 --> 05:44.680
JGDP answers, the School of Athens is a famous fresco painted by the Italian

05:44.680 --> 05:50.520
Renaissance artist Raphael. It was painted between 1509 and 1511 as part of a

05:50.520 --> 05:54.920
commission for the Vatican's Apostolic Palace in Rome. The fresco is widely

05:54.920 --> 06:01.320
regarded as one of the greatest works of art of the high Renaissance. This answer

06:01.320 --> 06:05.640
is not only correct, it is brilliant. There's absolutely nothing to complain

06:05.640 --> 06:12.560
about. It gives context, it answers the question. It's great. If you go to Google

06:12.560 --> 06:17.200
and ask the same question, the answer is the same, Raphael. But the context is even

06:17.200 --> 06:24.240
more amazing. A picture from Raphael, his biography, data about him, who influenced

06:24.240 --> 06:29.040
him, other artists that are being searched for. The answer is just beautiful and

06:29.040 --> 06:35.320
amazing. You can also go to Wikidata and write a sparkle query, asking for the

06:35.320 --> 06:41.760
creator of the School of Athens. Again, you will get the result, Raphael. Not as

06:41.760 --> 06:51.480
pretty as Google, not as much context as with JGDP. But here's one thing, JGDP took

06:51.560 --> 06:56.720
about five seconds to answer my question. Admittedly, it gave a lot of context I

06:56.720 --> 07:02.720
didn't ask for, but even just passing the question took close to a second. Google

07:02.720 --> 07:07.200
took half a second, including passing, but it also got a lot of great context and

07:07.200 --> 07:09.960
gave me results from the search index, even though they didn't make it to a

07:09.960 --> 07:16.360
screenshot. Wikidata took about a quarter of a second to produce the answer, and

07:16.360 --> 07:21.800
that's not all. JGDP is running on the fastest and most expensive hardware you

07:21.800 --> 07:26.760
can buy. Google is running on the fastest and most expensive hardware you

07:26.760 --> 07:32.040
cannot buy. And the Wikidata query service is running abandonware on a

07:32.040 --> 07:39.000
server somewhere. And if you think about this, it is not surprising. The query I

07:39.000 --> 07:43.560
asked had six tokens of input. A token is roughly a word for a natural language

07:43.560 --> 07:48.600
model. And the answer produced 60 tokens. Now, if the answer would just have been

07:48.600 --> 07:53.400
Raphael, it would still have been at least two tokens. Every single token runs for

07:53.400 --> 08:00.120
the 96 layers of JGDP, branching out to 175 billion weights and multiplying

08:00.120 --> 08:06.840
matrices and soft maximum results. Whereas in Wikidata, we look up an item out

08:06.840 --> 08:11.720
of 100 million and find a key out of 10,000 to get the results values. Those

08:11.720 --> 08:18.040
are both logarithmic operations. It's just much cheaper. Given this paper,

08:18.040 --> 08:22.920
getting and hosting your own copy of Wikidata, 1,000 Wikidata queries, like

08:22.920 --> 08:29.240
the ones I just asked, would cost me about 14 cents in the cloud. The authors thought

08:29.240 --> 08:32.680
this was too expensive and bought their own hardware to make it even cheaper.

08:32.680 --> 08:38.760
Whereas if I look at Azure pricing for GPT-4, a thousand queries, as asked before,

08:38.760 --> 08:48.440
would cost $7.56. So that's 14 cents compared to more than $7, so a factor of 50.

08:48.440 --> 08:54.600
50 times more expense can make a difference. Now, to make it very clear, I don't know

08:54.600 --> 08:58.680
how robust these numbers are. I would love to see more robust numbers and I expect

08:58.680 --> 09:04.200
the cost for inference to go down. But even Sam Altman, the CEO of OpenAI,

09:04.200 --> 09:09.720
the company making JetGDP, describes the compute cost of JetGDP as eye-watering.

09:10.760 --> 09:14.600
And don't forget, he made a really good deal with Microsoft about running it on Azure.

09:15.880 --> 09:20.040
John Hennessey, chairman of Google and former computer science professor at Stanford,

09:20.040 --> 09:25.080
so he really knows what he's talking about, said that running at JetGDP, like Google,

09:25.080 --> 09:31.800
would be 10 times more expensive. And that's just talking about the inference costs. Each

09:31.800 --> 09:37.320
of these models also need to be trained. And current state-of-the-art language models cost

09:37.320 --> 09:44.600
millions of dollars to train. For GPT-4, the cost was given as more than $100 million.

09:46.600 --> 09:53.240
The cost for GPT-3 was around $4 million. Good news is, you probably don't have to do this

09:53.240 --> 09:58.680
training. But you can just hopefully reuse an existing open source model that you can find

09:58.680 --> 10:04.200
due to your task. This will be considerably cheaper to train a model from the foundation on.

10:04.920 --> 10:08.680
But not for inference. The same cost that we saw earlier remains.

10:10.920 --> 10:15.800
Here's some interesting new thoughts. Some folks, like Sam Altman, think that the age of

10:15.800 --> 10:21.720
large language models is already over. OpenAI says it's because of diminishing returns of further

10:21.720 --> 10:26.680
reading. Guess what? After reading a million books worth of text, you don't seem to learn too much

10:26.680 --> 10:34.840
new stuff. He said that OpenAI is not working on GPT-5, but that they want to explore new ideas.

10:34.840 --> 10:39.880
And that's great. Because with models that are more readily available out there, such as Metas

10:39.880 --> 10:47.000
Llama, we can see new ideas happening very fast. For example, when Llama was leaked within days,

10:47.000 --> 10:52.840
someone managed to run it on consumer hardware. A few days later, we got it running on a phone,

10:52.840 --> 11:00.120
and then a Raspberry Pi. It was very slow, but it ran. And by the way, as ridiculous as that sounds,

11:00.120 --> 11:04.040
this still means that these giant models are more expensive to run than a knowledge graph.

11:04.840 --> 11:09.160
And really, it's not just cost, right? There are a few challenges that large

11:09.160 --> 11:13.800
language models need to overcome. We need new ideas for those. Let's take a look.

11:15.720 --> 11:21.720
Here's one thing that surprised me a lot. A few weeks ago, I stumbled into one of those Wikipedia

11:21.720 --> 11:28.120
rabbit holes where I got temporarily obsessed with figuring out one specific fact. The correct

11:28.120 --> 11:35.160
place of birth of a not-too-well-known Croatian actress, Anna Begovic. I was surprised that

11:35.160 --> 11:40.120
Google and Wikipedia Wikidata were giving different answers, so I tried to figure out

11:40.120 --> 11:46.920
the truth and fix it. Here's a screenshot of Google answering the question. Begovic was born in

11:46.920 --> 11:53.960
Terpan. Wikipedia used to say split. After a bit of hunting through sources, I figured out that it

11:53.960 --> 12:01.720
mostly likely is Terpan, though. And that a lot of the sources were copying from Wikipedia and Wikidata

12:01.720 --> 12:08.360
and became contaminated by Wikipedia and Wikidata. This is an example of our knowledge ecosystem being

12:08.440 --> 12:13.800
substantial danger, by the way, and that long before we have LLM syndemics.

12:15.880 --> 12:22.360
Now, if you go to Bing Chat, which is powered by OpenAI's GPT, but has access to web search

12:23.080 --> 12:28.760
and ask for the place of birth of Anna Begovic, it also answers me Terpan, which is great,

12:28.760 --> 12:34.440
and it gives me free sources for that answer. It's just very disappointing that if you follow

12:34.440 --> 12:39.080
one of the references to Wikipedia, you will actually find it says split.

12:40.200 --> 12:45.480
When I asked ChatGDP instead of Bing Chat, I get a different answer. It answers split.

12:46.200 --> 12:51.560
This is not too surprising. After all, Wikipedia was claiming split until just a few weeks ago,

12:51.560 --> 12:57.720
and ChatGDP was trained on a 2021 copy of the web. Corrections to Wikipedia done in 2023

12:57.720 --> 13:01.560
would not show up. Split is totally expected as an answer here.

13:02.360 --> 13:07.160
What is interesting, though, is if I ask the same question in Croatian,

13:08.280 --> 13:16.280
I get a different wrong answer. Zagreb. Now, that's an interesting answer,

13:16.280 --> 13:24.040
because it demonstrates us two things. First, knowledge in ChatGDP seems to be not stored in

13:24.040 --> 13:30.200
a language independent way, but is stored within each individual language. Depending on the language

13:30.200 --> 13:36.920
I ask the question in, I receive a different answer. Also, the English answer at least has

13:36.920 --> 13:43.640
support in the training data. Wikipedia did say split. The Croatian answer, where does Zagreb come

13:43.640 --> 13:49.400
from? I can find a single source that says that Anna Begovic was born in Zagreb.

13:49.640 --> 13:57.560
But here's the thing. What if ChatGDP is actually just guessing, it's just making it up?

13:58.600 --> 14:03.400
What is the probability of Zagreb given the prior of Croatian actress?

14:05.000 --> 14:11.720
In order to figure that out, I want to check Wikipedia. I ask ChatGDP to give me a sparkle

14:11.720 --> 14:18.520
query for Croatian actors in the places of birth. The query it returns to me is good enough for our

14:18.520 --> 14:25.640
purpose. I can just copy and paste it. It is subtly wrong if you read it in detail. It does not ask

14:25.640 --> 14:31.720
for Croatian actors, but for actors born in the place in Croatia. But again, good enough for our

14:31.720 --> 14:41.800
purposes. But still, this is fascinating. ChatGDP got out of the box all of the QIDs right in this

14:41.800 --> 14:49.000
query. For Croatia, for actor, it got a property ID right. It can make sparkle queries that are

14:49.000 --> 14:57.000
syntactically right. And all of that with zero shot extra training. There was no look up on the web.

14:57.000 --> 15:05.240
ChatGDP just knows these QIDs by heart. In fact, you can totally ask ChatGDP to make you a table

15:05.240 --> 15:11.240
of all the countries of the European Union and their QIDs. It has a lot of QIDs memorized.

15:11.800 --> 15:19.400
Just you never know if maybe one of them is wrong or not. The query can be copied and pasted right

15:19.400 --> 15:26.520
into the Wikipedia query service. And it runs giving 445 answers. And you can already see in the

15:26.520 --> 15:34.120
screenshot that the first few are all in Zagreb. So now we can see that of the 445 Croatian actors

15:34.120 --> 15:41.080
for place of birth, 154 are born in Zagreb, about a third. This gives a pretty good conditional

15:41.080 --> 15:48.120
probability for the birthplace of Croatian actors. ChatGDP is guessing the place of birth

15:48.120 --> 15:54.840
for Anna Begovic in Croatian, even though it knows it in English. This leads me to something my

15:54.840 --> 16:01.720
manager at Google used to say. You can machine learn Obama's birthplace every time you need it,

16:01.720 --> 16:05.160
but it costs a lot and you're never sure it is correct.

16:05.400 --> 16:12.360
Another interesting observation is that GPT isn't particularly good with knowing what it knows.

16:13.720 --> 16:20.920
For example, here we are asking for cities with mayors born after 1998. I wanted to ask something

16:20.920 --> 16:26.440
that I expected to be not trivially Google-able, where there wouldn't be a listicle or table on

16:26.440 --> 16:34.920
the map. So ChatGDP correctly points out that that would make them younger than 23 at its cutoff

16:34.920 --> 16:44.040
80 date of 2021. So it is unlikely that anyone would be mayor at that age. Asking Bing Chat,

16:44.040 --> 16:47.880
it also says that it doesn't know anything about mayors born after 1998.

16:50.360 --> 16:55.400
Let's check Wikidata. I again used ChatGDP to help me write a query, although this time I

16:55.400 --> 17:02.600
had to make a few fixes. And indeed, Wikidata has an answer. It tells me about Christian von

17:02.600 --> 17:08.360
Waldenfelds, who was born in April 2000, mayor of Lichtenberg in Bavaria, Germany.

17:09.720 --> 17:14.920
He became mayor in 2020, well before the cutoff date of Chaterity, by the way.

17:17.000 --> 17:21.400
This is no endorsement of his politics or his platform he is running, by the way.

17:23.960 --> 17:29.800
Now that we know the answers, we can guide Bing Chat and get the mayor of Lichtenberg and his age.

17:29.800 --> 17:33.720
And obviously this answer is inconsistent with its previous answer,

17:33.720 --> 17:38.840
but ChatGDP or BingJDP are both completely unaware of this inconsistency and don't care.

17:40.520 --> 17:45.480
Large language models are not yet graded being consistent, whether about individual facts

17:45.480 --> 17:53.000
or across different languages. They are also not always very good at math. But even if they were

17:53.000 --> 17:59.800
good at math, we have to answer the same question that we do for looking up facts in a knowledge

17:59.800 --> 18:10.440
graph. Why would you ever use 96 layers, 175 billion parameters model, to do multiplication?

18:11.080 --> 18:14.280
When that's something you can do in a single operation on your CPU.

18:15.640 --> 18:22.200
Why internalized knowledge in an LLM if you can externalize it in a graph store and look it up

18:22.280 --> 18:29.240
when needed. Don't get bedazzled by the capabilities of large language models.

18:30.920 --> 18:37.640
Autoregressive transformer models such as ChatGDP are touring complete and they are just a very

18:37.640 --> 18:44.360
expensive reiteration of touring's carpet. You can do everything with them, but it doesn't mean you

18:44.360 --> 18:51.400
should. Use LLMs where they are efficient and use other things where they are better.

18:53.160 --> 18:59.240
One possible solution to this capability gap are so-called augmented language models.

19:00.280 --> 19:06.040
Toolform are being a particularly well-known example. Or for ChatGDP, that's what ChatGDP

19:06.040 --> 19:12.360
plugins are there for. The idea is that we can enrich large language models with additional

19:12.360 --> 19:18.280
systems which are good and efficient at specific tasks, such as math or other functions,

19:18.440 --> 19:24.120
from wiki functions, or looking up facts or query results in a knowledge graph such as wiki data.

19:25.240 --> 19:31.800
I mean, given that ChatGDP already can, zero shot, create queries against wiki data,

19:31.800 --> 19:34.600
there isn't that much to do to make them work together.

19:37.080 --> 19:43.240
Some folks think that some mapping of strategic nodes into a knowledge graph with embeddings,

19:43.880 --> 19:47.320
we can easily connect a knowledge graph directly to a large language model.

19:48.520 --> 19:52.920
But we don't even need to do that, we can just use the Sparkle query generation ability

19:52.920 --> 20:00.280
directly and ask queries against wiki data. And not only can we connect LLMs to a knowledge

20:00.280 --> 20:06.360
graph, but also to a repository of functions, such as wiki functions. Both knowledge graphs and

20:06.360 --> 20:14.120
functions would be tools the LLM can learn to use. There is work in trying to understand

20:14.120 --> 20:18.680
how knowledge is stored in the parameters of a large language model. And when we look at this

20:18.680 --> 20:28.280
work, we start to understand why large language models are large. Do they really have to be this

20:28.280 --> 20:37.880
large? Let's compare with stable diffusion one. Stable diffusion one is a text to image generator.

20:37.880 --> 20:44.040
It has to understand natural language prompts, just as GPT does. It can make an image out of

20:44.040 --> 20:48.760
basically any prompt. It can also generate the image of a good number of celebrities.

20:48.760 --> 20:55.400
Here, for example, I'm asking for the Pope, Geleta Thunberg, Idris Elba, Michelle Yeo,

20:55.400 --> 21:00.600
Helen Mirren, and Yanle Kuhn to explain knowledge graphs with the help of a whiteboard.

21:02.360 --> 21:11.000
So GPT-3 had 175 billion parameters. How many parameters do you think are in stable diffusion

21:11.000 --> 21:19.880
one, knowing all these people being able to generate them? 890 million parameters.

21:20.760 --> 21:29.960
Now, I think 890 million is a lot. But GPT-3 is about 200 times larger than stable diffusion one.

21:31.240 --> 21:36.600
And it's no surprise. Think of it. All the knowledge that we were using for questions

21:36.600 --> 21:42.360
answering so far. The embedded QIDs, what are the member countries of the EU,

21:42.360 --> 21:49.640
the place of birth of individual people. I mean, if it has NABegovitch, I'm sure GPT-3 knows the

21:49.640 --> 21:55.640
place of birth of millions of individuals. All this taught in many different languages.

21:57.080 --> 22:01.320
All of this is taught in those hundreds of billions of parameters.

22:01.800 --> 22:06.600
You don't need that for text generation. But you need it if you want to answer all

22:06.600 --> 22:13.160
these questions we have been asking. And indeed, Metas Lama, which came out a few weeks ago,

22:13.160 --> 22:20.680
is considerably smaller than GPT-3, about 25 times smaller. But it seems to be

22:20.680 --> 22:27.400
rather competitive in terms of language understanding and fluency. So yes, we could

22:27.880 --> 22:34.920
internalize all the 1.4 billion statements in Wikidata into a large language model.

22:35.880 --> 22:41.560
But what if we go the other way around and try to externalize the knowledge model instead?

22:42.600 --> 22:47.480
If we leave the language model to deal with language, but push the knowledge

22:48.120 --> 22:53.960
to a knowledge graph or a different knowledge model, in a world where language models can

22:53.960 --> 23:01.960
generate infinite content, knowledge becomes valuable. And that takes us back to Jamie Taylor's

23:01.960 --> 23:08.520
rule. We don't want to machine learn Obama's place of birth every time we need it. We want to

23:08.520 --> 23:15.480
store it once and for all. And that's what knowledge graphs are good for. To keep you

23:15.480 --> 23:21.800
valuable knowledge safe. I am of the strict belief there is no reason to ever again

23:22.440 --> 23:29.720
manually enter the place of birth for Anna Begovic. This makes knowledge for Wikidata

23:29.720 --> 23:37.320
both valuable and a public good. The knowledge graph provides you with the ground truth for your

23:37.320 --> 23:44.360
language models. By the way, the other way around is also true. Large language models can be an

23:44.360 --> 23:50.360
amazing tool to speed up the creation of a knowledge graph. They are probably the best tool for

23:50.360 --> 23:58.200
knowledge extraction we have seen developed in a decade or two. We want to extract knowledge into

23:58.200 --> 24:08.040
a symbolic form. We want the system to overfit for truth. And this is why it makes so much sense

24:08.040 --> 24:16.040
to store the knowledge in a symbolic system. One that can be edited, audited, curated, understood.

24:16.680 --> 24:23.080
We can cover the long tail by simply adding new notes to the knowledge graph. One we don't train

24:23.080 --> 24:29.480
to return knowledge with a certain probability to make stuff up on the fly. But one where we can

24:29.480 --> 24:35.720
simply look it up. And maybe not all of the pieces are in place to make this happen just yet.

24:36.360 --> 24:41.480
There are questions around identity and embeddings. How exactly do they talk with each other?

24:41.800 --> 24:49.480
But there are good ideas to help with those problems. And knowledge graphs themselves should

24:49.480 --> 24:56.200
probably also evolve. I want to make one particular suggestion here. Freebase, the Google Knowledge

24:56.200 --> 25:02.760
Graph, Wikidata, they all have two kinds of special values or special statements. The third one is

25:02.760 --> 25:09.160
the possibility to say that a specific statement has no value. Here, for example, we are saying that

25:09.240 --> 25:17.080
Elizabeth I has no children. The second special value is the unknown value. That is, we know

25:17.080 --> 25:22.520
that there is a value for it, but we don't know what the value is. It's like a question mark in

25:22.520 --> 25:28.840
the graph. For example, we don't know who Adam Smith's father is, but we know he has one. It could

25:28.840 --> 25:33.240
be one of the existing notes. It could be one that we didn't represent yet. We have no idea.

25:34.200 --> 25:41.640
My suggestion is to introduce a third special value. It's complicated. I usually get people

25:41.640 --> 25:47.480
laughing when I make this suggestion, but I'm really serious. It's complicated is what you would use

25:47.480 --> 25:51.320
if the answer cannot be stated with the expressivity of your knowledge graph.

25:52.360 --> 25:58.840
This helps with maintaining the graph to mark difficult spots explicitly. This helps with

25:58.920 --> 26:06.840
avoiding embarrassing wrong or flat out dangerous answers. Given the interaction with LLMs,

26:07.400 --> 26:15.160
this can in particular mark areas of knowledge where we say, don't trust the graph. Can we instead

26:15.160 --> 26:20.120
train the LLM harder on this particular question and assign a few extra parameters for that?

26:20.280 --> 26:28.840
But really, what we want to be able to say are more expressive statements. In order to build

26:29.480 --> 26:35.800
a much more expressive ground truth, to be able to say sentences like these,

26:35.800 --> 26:41.960
Jupiter is the largest planet in the solar system. That's what we are working on right now.

26:42.520 --> 26:47.880
With abstract Wikipedia and leaky functions, we aim to vastly extend the limited expressivity

26:47.880 --> 26:56.600
of Viki data so that complicated things become stateable. This way, we hope to provide a ground

26:56.600 --> 27:05.720
truth for large language models. In summary, large language models are truly awesome. They are

27:05.720 --> 27:11.960
particularly awesome as an incredibly enabling UX tool. It's just breathtaking, honestly,

27:12.360 --> 27:19.080
things are happening which I didn't think possible in my lifetime. But they hallucinate.

27:19.720 --> 27:27.240
They need ground truth. They just make up stuff. They are expensive to train and to run.

27:28.200 --> 27:32.520
They're difficult to fix and repair, which is great if you have to explain someone,

27:32.520 --> 27:36.680
sorry, I cannot fix your problem. The thing is making a mistake, but I don't have a clue how to

27:36.680 --> 27:44.040
make it better. They are hard to audit and explain, which in areas like finance and medicine is crucial.

27:44.760 --> 27:50.200
They give inconsistent answers. They struggle with low resource languages.

27:51.560 --> 27:57.400
And they have a coverage gap on long tail entities, which is not easily overcome. All of these

27:57.400 --> 28:04.280
problems can be solved with knowledge graphs, which is why I think that the future of knowledge

28:04.280 --> 28:11.640
graphs is brighter than ever, especially thanks to a world that has large language models in it.

28:13.400 --> 28:17.640
Thank you for your attention. Thanks to all the people who helped me clarify my thinking

28:17.640 --> 28:26.440
around this topic. And if you have any questions, feel free to put them in the comments.

