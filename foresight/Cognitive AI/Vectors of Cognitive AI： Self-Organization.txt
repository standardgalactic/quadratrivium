Hello, everyone. Can everyone see my screen?
You can see your screen, yes.
Excellent.
Great. So, my name is Tanya Greenberg. Today we're going to be talking about self-organization.
Biological and social agents are very different from our present approaches to design artificial agents.
Technological systems are constructed from outside in.
They extend the part of the world with known functionality by forging its deterministic substrate into required functions.
This is, however, this is true whether we are building a bicycle in a workshop or learning algorithm in a software development environment.
However, biological systems are growing from inside out.
They organize an indeterministic substrate with unreliable properties into a structure that converges to serving the required function and which will even self heal and regrow when they are being damaged or disturbed.
Today, we will be exploring this dichotomy and how it applies to technological systems, especially artificial intelligence.
So, our first presenter today will be Professor Christoph von der Malzburg.
Today, Professor von der Malzburg is a senior fellow at the Frankfurt Institute for Advanced Studies and a visiting professor at the Institute of Neuroinformatics at ETH Zurich.
Previously, he served as a research scientist at Max Planck Institute in GÃ¶ttingen and professor of computer science, neuroscience, physics and psychology at University of Southern California, and as director of the Institute of Neuroinformatics at Bochum University.
He has founded two successful companies and has received many awards, including Pioneer Award of the Neural Network Council IEEE and the HAB Award of the International Neural Network Society.
Christoph, the floor is now yours.
Okay, thank you.
Can I share my screen?
Yes, you should be able to.
I will stop my show.
Yeah, continue.
Okay.
Here we go.
So, first, I would like to discuss the how to determine the information content of the brain and of the environment with which the brain is dealing.
And the right way of going about that is Kolmogorov complexity.
The information content according to the information content of the structure is measured in terms of the bit length of the shortest algorithm that creates that structure that can create that structure.
Let me give you a simple example. The Julia set is a very complicated thing. In order to describe it as is, you need a literally an infinite amount of information.
You can blow it up as long as you want and it still continues to create more to contain more structure, but in order to create it, it needs a few line algorithms, the guts of which are shown on the lower left.
The flip side of low Kolmogorov complexity is that the structure it is describing is highly structured. It has high structural regularity, which is again displayed here you can see, there is a lot of structural regularity, which never repeats, but you
can see the inner coherence of the whole thing.
Now, what about our natural environment.
I claim it has very low Kolmogorov complexity. Otherwise we couldn't perceive it and science wouldn't work. And I think virtual reality is a very good tool to show that
the working environment in including their dynamical interaction with a viewer can be created with very little information. So the basis of that is computer graphics in computer graphics.
That's an amazing field that has developed over 20 or 30 years the ability to create very realistically looking scenes and also dynamic scenes.
And that created something like an ontology of our visual environment. And I guess you all know how it is done it is a is a compositional game you start with a representation of the shape in terms of shapes in terms of wire frame models.
When you give them surface markings and reflectivity, you transform them by known laws into a scene in position them in the scene, you, you project the scene with projective geometry into a virtual camera yet you illuminated.
So that is something that can be done with a few gigabytes of program code.
We all learn in a very deliberately designed simple environment in nursery.
And although this nursery is very limited in terms of numbers of samples and complexity, we later walk out into the world and can reflect it represented in our brain.
Now, as I said, to generate this kind of to simulate if one care to do that, that kind of environment including the social interactions, it would take a few gigabytes of a program like a computer games program virtual reality program.
So the color of complexity of our environment as far as is needed for learning is gigabytes only.
So let me remind you that, at least to psychologists, the speed with the rate at which we pick up information into our long term memory is a bit or so per second, so that over your whole lifetime you pick up a gigabit.
I've heard that I found that offenses to the rich to the richness of my inner life, but turned it the other way around and say it takes a gigabyte to create the world as I know it to, to represent it.
The line is a very complicated thing, a simple estimate of the amount of information you need to describe the wiring is a petabyte 10 to 15 bytes. Here's a little computation on the screen, how I arrived at that.
The color of complexity of it must be very low. It takes one gigabyte of genetic information to create an organism like mine, including the brain.
And as we saw it takes a few gigabytes to train it to at least some level of competence. So the color of complexity of the brain is very low.
The brain is highly structured. And I think this is the query theory has to shoot for to describe the particular kind of structure that is dominating the brain.
The question arises, what is the Kolmogorov algorithm by which the brain is actually created.
The, as I said, the brain is dominated.
No, here's my slide. The brain is the result of self organization, of course, where the genes play the role of parametric control.
And likewise the sensory signals they just influence this process of self organization, which however is totally dominated by the structure that we just concluded must be structuring it.
So the brain is dominated by attractor patterns and see that in, in analogy to crystals or to touring patterns if you heard of, heard of them to soap bubbles, or the Golgi apparatus that is in all the eukaryotic cells, all the cells of your button.
Those structures arise by the more or less chaotic interaction, dynamic interaction of the building elements of those systems. These patterns emerge as one, as one called seven speaks of emergence they just arise because they can self stabilize they can prevail in a dynamic game.
So that poses the very important question what are the emerging patterns in the brain.
There is, thank goodness, a very good paradigm for that that has been studied 40 years ago, very intensively I must say I was in the middle of this with dozens of different types of experiments done on frog and fish.
The question is, how come that the fibers that grow out in some stage in the embryo from the, from the retina on the left on the left, and grow out to target structures in the brain the optic tecton for instance here on the right.
And I found that these fibers, which at least in some species start out in a rather random pattern, order themselves in over some time.
Well, at the end, you have a beautiful picture, appearing here in the tecton, when a picture is shown into the retina and a connectivity pattern when neighboring ganglion cells in the retina connect to neighboring cells in the tecton.
And I found these fibers nowhere to go. There was a handful of theories, all of them died, given the enormous flexibility of the system, its resistance to experimental interventions and quirks of natural development.
And the one that survived, and I was one of the people who proposed it with my friend David Wiltshire and Alexander Heusler is network self organization.
The claim is that is the Kolmogorov algorithm of the brain, and it works like so a network and initially more or less random network create signals.
The signals act back on the network by synaptic plasticity, and this loop this initially unstable loop continues until a network structure is reached that stabilizes itself via the signals that create signals that stabilize that same network and retinotopy is just one example of that.
In some leap of faith, one has to see, or if you don't take it as a logical conclusion, one has to see the structure of the brain as an overlay of lots of self organized network patterns.
These attractor networks are characterized by two properties one is the consistency of different pathways, a single pathway can only grow if it gets cooperative help from other pathways coming from the same source.
This is going to the same target cooperativity. And this is bridled in by a sparsity constraints varsity meaning a limited number of inputs to the same neuron or outputs from the same neuron.
That's a simple characterization of attractor networks.
The reason for this is that the brain is an overlay of lots of attractor nets, each having its own support as a set of of neurons, and each time that set of neurons active, it works a little bit on on its connectivity until it has reached attractor structure.
And you can be part of a number of attractor nets.
The central thesis towards I have been driving is the emergent nets self organized nets are the brain spires.
And this is a very bold, it took me a while to sort of put my belief behind this. This is a very bold statement of course, saying that the mechanics or network self organization is at the base of the structure of our mind.
The structure of our brain. That is one half of that of the hypothesis and the other one is the structures that arise by this mechanics are a powerful Bay bias to understand the environment.
The statistical learning mechanism needs to have a very strong bias, it tunes it to the phenomenon that is to be learned from. And so the idea here is the conclusion here is that the buyers in our brain is network suck.
The attractor nets are the data structure of the mind they they form a construction kit for mine states. They are the Lego blocks of the mind of the chunks of cognitive theory and the syntax the grammar, under which they combine into each other is any
structure of co active networks has to form a stabilized a self organized a attractor net that would be given enough time to be stable under self organization is in principle a very simple system.
I just give a simple illustration to make it more concrete face recognition that was the base at the base of two companies I've co funded in the past in California in Germany.
So the idea is the image of an object or a face enters primary visual context as we all know, as a 2D array of local feature detectors, which are, as we also know, connected literally connected by short range connections.
So it is a tiny step from there to assuming that what the input image activates is local connectivity fragments fragments of connectivity, which seamlessly blend into each other to represent the whole face.
One order to record in in order to recognize it, you need a model of that phase in another part of the brain if you see form complex, and in order to establish the relationship the similarity relationship you need fiber projections between a primary visual
and the, and the info temporal context, which links corresponding parts to each other. These projection path networks have to switch as quickly as the images change in the primary context.
They are called shifter circuits by Charles Anderson and by David van Essen.
Now let me just point out that the whole structure here that arises in a fraction of the second when you look at the face is an attractor network is composed of lots of little net fragments that have been previously prepared, and that fuse into each other to form this representation.
So let me, let me go one step further and submit the idea that we comprehend objects by linking them sensory objects by linking them to schematic description there are schematic description that are put together by
artwork fragments that have been trained before. So let me come to my end and repeat my central thesis emergent nets are the brain spires.
Thank you.
Thank you very much Christoph that was an excellent presentation.
So.
You want me to stop sharing I suppose.
Yes, you could do that.
I think the share will be interrupted when Yuri starts. So, um, our next presenter is Professor Yuri was a Bojaki, Yuri Bojaki is the biggest professor of neuroscience, NYU School of Medicine, and is among the top 0.2% of most cited neuroscientists.
He has contributed to the emerging under emerging understanding of the dynamics of hippocampal system, and the recognition of the importance of temporal firing properties in the formation of neural codes is overarching hypothesis is that the numerous rhythms that the brain perpetually
are responsible for segmentation of neural information and communication across brain regions. He proposed how these rhythms support a brain syntax, a physiological basis of cognitive operations.
His most influential work is known as the two stage model of memory trace consolidation, and has been adopted as a framework at several leading laboratories around the world.
Yuri the floor is now yours.
Thank you Tatiana. Let me use this opportunity to ask a few questions and then, then I go to my presentation.
The first thing I like to ask is that, you know, what makes us so successful as a species. And the answer is that we are the, perhaps only or very exceptional species that was capable of externalizing brain function.
We expand the body and expand the brain we make machines clocks rulers computers to help us and obey us, not to substitute or compete with us.
Now, if you take this position and you can ask, you know, how is AI.
And why do we call it artificial intelligence in the first place I did always bug me know what if we are talking about artificial smartness artificial creativity thinking artificial consciousness.
What just happened that AI survived and because that was a community agreement, you know, and what if, for nine months, named a computer and artificial brain then we would be having a branch sponsored by governments and we will be all researching artificial
brains. Now, what is so special about intelligence.
Intelligence in biology is typically defined as the ability of the species to survive and prosper in its own niche.
And the emphasis to me is on niche, because it would be unfair to put a human underwater for 10 minutes and then conclude that the fish are more intelligent.
All all species survive and perform in their own niche.
And the question is then what is the niche for AI. If every intelligent agent requires a, a, a, a environment to leave what is AI is defined environment.
Now,
we need to do a artificial version of something or anything. We need to give it have a good definition of the real thing first.
And let's see how it works with intelligence, like space and time. Intelligent is an abstract the used idea.
Ideas become scientific only then we begin to measure them. Measuring needs scales. Time and space became scientific terms that began to measure duration and distance by clocks and rulers.
Intelligence also became a scientific term that we made up a scale for measuring IQ. Historically, this was introduced as a tool for selecting soldiers.
During the first fall, first world war, for particular goals, you know, goals is a very important thing is was classification can happen only on the in the presence of a goal.
But today, the goals of AI are very different, you know, different groups of people come up with their, their own creative definitions and relate them to their own rulers.
Unfortunately, there is no agreed common ruler against which we can measure intelligence of humans, other animals, machines and computer algorithms.
So, when it comes to defining AI, one may wonder this is a fantastic system or a field that can leave alone.
Or, indeed, as some people say, you know, AI should be inspired by the brain, or whether brain scientists like myself should be looking out for AI people like you guys to see how much we can steal from you to understand the brain.
So, in order to do that, you know, we'd like to see is what kind of, of aspects of hypothesis or statements AI is using currently from brain models.
Now, I have to share the screen here.
And
there we go.
Share
and just view.
And
let's go. So,
we can distinguish basically three extreme versions of how we think about brains in general. One is, I would say is still dominant.
And it's based on the key words like random organization, egalitarian, have rules, the eye balance, noise, and sleep plays no importance whatsoever.
You know, we create robots so they can work 24 hours a day, and we create algorithms to work 24 hours a day but be humans and other animals sleep also.
And the whole idea here is that you start with a simple brain and make it more and more complex and complexity scales with experience.
You can call this model Tableau-Raza and writing in.
And Christoph very eloquently already pointed out that you know this is not the kind of brains we almost brain scientists look at or imagine.
The brains have internal dynamics, and it's a common word, but we don't really explain what it is so I give it a try and explain it but it is.
So the alternative of the AI-like or the Tableau-Raza or the Blake-Slang model would be an alternative which is an autonomous system, a self-organized system, which has very different rules instead of egalitarian.
It has strong skewed rules and sleep is an essential feature that is necessary to maintain its own dynamics.
Instead of the clean paper, the brains come with a pre-configured dynamic, and that pre-configured dynamic gives you an enormous realm of possibilities, typically sequences, and learning under this model is not a synthesis,
it's not putting something into the brain, but I'm masking and matching an existing pattern with the experience.
The way how we can summarize these two models in just very simple sentences, you know this is the famous short summary of have is that neurons that fight together, why together.
In the other end, you can say that neurons that are born together will why together, therefore they will fight together with a much higher probability that neurons that are not born together.
Now, this is a very simplified view, of course, of the brain and I have a checkbox here saying which side I prefer.
And of course, you would like to know whether there are supports for any of these things.
You know, I have never met anybody in my neuroscience community would say, oh, the brain is a Tableau-Raza, but there are famous people such as this guy here who said exactly that.
You know, it's not so long ago that there's a notebook and then you have to fill it up with experience.
Here's another giant, you know, John Hopfield, who not so long ago said, you know, large number of simple equivalent components.
So, this is exactly where a lot majority of AI people live on and I'm happy to hear the, you know, you contradicting me.
And of course, there are new areas of AI that are different and they are more brain inspired but I think large and by a large even your sciences is following these principles.
In contrast, you know, if we are looking for fundamental laws or fundamental rules in the brain, then not too many. This is not like physics, but at least we have one overwhelming rule in the brain.
This is called the wave effectal law, which describes our subjective perception as a log rule.
And there are many, many attempts to show, you know, why this is the case and it's also not only for our perceptions, but it applies to almost everything, such as short-term memory, long-term memory, space, duration perception and so on.
The reason, the fundamental reason, I think, why this log rule occurs is because the brain has a dynamic range, extraordinary wide dynamic range in almost everything from synaptic ways to firing race, population, synchrony and so on.
And a lot of log-lobal, they show log-normal distribution, or log-normal like distributions. And this dynamic is based by a skewed system, which is as, as Christoph already pointed out, this is not from random, not random organization at all, but the connectivity can be described by a log rule,
which means that one area of the brain is connected to a handful of other areas in the brain very strongly.
50% of these connections are to a handful of areas, but the other 50% is to a very large number of other areas with weak connections. And this is what is expressed by the log rule.
Of course, these are interesting observations, these are only statistics, but the question is whether these are statistical curiosities only, or they serve something interesting.
And I think what they serve is exactly what the brain have to solve, which is a fight, it's a continuous struggle of war between wide dynamic range, stability, resilience, homostasis, redundancy, degeneracy,
and, you know, this is one end, the other end, if you want, will be plasticity and robustness.
So, if these are fundamental rules of the brains, then we know that there are small brains and large brains, and how will they react in their niche where they live.
And this is that, not the answer, but my hypothesis is that the main goal of the brain is to maintain its own dynamic.
Second, is to generate an output, and to see the consequences of its output, and predict the consequences of this output.
This whole creature is generating an output. It interacts with the body and with his own niche in the environment, and then it events sensors to make the prediction better.
And the goal, of course, is to predict this is the consequences of its own actions.
They get larger. There are many, many loops added to this. But the entire goal of this is exactly the same. But now, this organism, such as your brain and my brain, can predict the future at a much longer time scale, and in the much,
much more noisy complex environment.
Now, this is not yet cognition. There is one more trick here.
Namely, we have to disengage the brain from the world.
What I see is not because there are photons on my retina. I can see, you know, I close my eyes, and the screen doesn't appear. I can still see Tatiana and, and, and everybody on the screen in my mind is because what we see is actually the brain
computation. And if that is true, then we can temporarily, or for a longer time, disengage or remove from the environment and keep going on with the computation and do, and compute what if scenarios, what if I didn't wake up this morning early enough to come to this talk,
and what would be the consequences of this. Therefore, I put my alarm clock and so on.
And so these are the kind of things that these complex brain can do.
Now, there is one more bug that is, is complicated because all you see is here is loops loops loops loops and complicated loops and interactive loops and this looks like a, a Tullamo cortical system.
So here is our cortex and the Tullamo's.
There are two tricks here, one is that we, the brains invented side loops. There are two side loops here, the cerebellum and the base of ganglia. They are first cousins.
They like each other, they compute similar things and they complement each other. And the third loop is the hippocampus.
You may wonder if you would like to make a AI system, you know, why are these side loops, what they are good for, and how they work.
So in the rest of my time, I'd like to show you some examples how they actually work.
So my first claim was that the number one goal for the brain is to maintain its own dynamics. Is it expensive or is it, does it come for free.
So recently, then living standard grad students in my lab devoted his five years here and calculated what we did is that what you see on the left is the distribution of inter spike intervals, that is how regular spikes spike or work.
And that they are pretty irregular most of the time. And in the x axis you can do this it is like interval and every single line there are a few thousand neurons here in the hippocampus.
Every line is the inter spike interval distribution of a neuron.
And you can see is that that there is this nice shift that is different from neuron to neuron.
So there are fingerprints that are neuron individual neuron characteristic firing patterns, which is on the low end of the firing. This can be zero to zero point zero one zero point zero zero one very low frequency firing.
I've ordered many people for a long time you know why do neurons fire it is such a low rate that doesn't make sense you know they cannot do anything, except that was discharging their partner inter neurons, but they don't have any information value.
Now, it turns out that there are other regimes, such as here you can see a band here that all neurons are in the same band. This is in the hippocampus this is the theta band.
There's another band here but but gamma there's another one here is a bursting pattern and so on. So, by analogy to physics, we call this state here, the individual specific state, the ground state.
And then the other states that are common to all neurons or most of the neurons is the activated states. So this is shown here in the cartoon manner that every neuron can have its own ground state.
And is activated state activated states means they are working together with many other neurons for a purpose.
What fraction of the neurons pan in their ground state to do nothing or to maintain your dynamics nothing meaning no communication no perception no thinking and so on.
And the answer is astonishingly high. This is a figure that shows the hippocampus the preform cortex, basal anatomical blood, frontal cortex, visual cortex, the thalamus doesn't matter where you go and what state but it sleep was waking.
Most of the spikes everywhere in the brains are devoted to maintain the brain dynamic.
So I made my first point. My second point is that there are many euros that are silent, or they are firing these scattered spikes, such as the ones I just showed you that they are they are in the ground state.
So, for example, if you are a place neuron, you can see my cursor here probably if the animal is running in an environment and you are recording from the hippocampus then, then there are play cells and this is place cell number one place and number two place and number three four and so on.
But there are half of more of the neurons that died like this yellow cells that they don't do anything.
So how do we know that are they part of this attractor that Christopher was talking about, talking about, or they are distinct from it from each other.
So how do we know that the way how to do it is do a trick what Manuel Valero did is is optogenetically activated cell for a short period of time and again short period of time periodically 20 milliseconds for thousands of times that doesn't perturb the system.
So how are you, and then you're on fires a spike, and then it fires a spike and not a spike. So now this neuron the same neuron that you have seen before that doesn't have any place field all of a sudden does have a place for.
So we can be we show that and this place field is married to a particular position just like normal places and this is another one.
And then there are many of these. In fact, most of them.
If you have the probing done right. So the middle one would be the noisy one that you wouldn't see otherwise because the firing rates are too low compared to outside a field and we don't know where the field is.
But if you probe the neuron, then we can unmask place fields from every single C1 pyramidal neuron in the hippocampus.
I mean, it is part of the same exact attractor, except it doesn't spike it doesn't have an output.
Unmasking is as effective as making. So remember that, you know, on the one hand you have to synthesize you have to make neurons and you make them.
The fire the way how the world makes them fire or the other one is that it just happens when you are searching into something. There's a high probability that a particular pattern occurs and that pattern can be associated no link to something meaningful.
So where do these preconfigured lists of sequences come from.
And the answer is perhaps by from either evolution or evolution or embryonic states.
So now we are doing a little bit of a neuro-ocular and we are asking is that if you are recording from an adult brain, how would we be smarter to know how this neuron should behave if we know that this neuron and another neuron born in the same day or in a different day.
And to do that, Roman who started my lab, he labels neurons at different stages of development, such as embryonic states 131415 and 16 days, mark them permanently.
So when the animals grow up, then we can compare the adult animals as and and and know which neurons were born on the same day, and which neurons were not.
And the answer is, even if we go to those neurons that that we're born together, they will fight together the same data cycle, the same shop with cycles, the population level they like to be together, they form cell assemblies, and even at the very extreme
level, this black neuron was born on on 14 days, if 14 days and it has one field and it has another field.
The blue neuron was born on the same day and it has a similar field, and the red neuron was born at a different day at this similar field.
And if you do the statistics on a large number of neurons, we find that neurons that are born together, they do many things similarly, and they fire together and fire together.
Well, this brings us to the, the new brain picture, which is my spaghetti brain, which shows what suggests that we are not making complex brain from simple brains.
The brains are devoted, devoting their enormous resources to maintain the dynamic that brain dynamic does not change or scales with learning or experience.
My brain, your brain or that of a, a totally unexperienced brain or the brain of Albert Einstein are not necessarily different in complexity, because learning is not a, not adding, but it's a matching process.
In this spaghetti, the thicker ones that have already be associated or linked to experience. And so, you know, without without analogy, it would be like a Chinese dictionary where there are many symbols all the symbols are there for communication, which is don't understand them but we have to ground them by knowledge such as knowledge of English words or in our
cases is experience.
So, the interesting challenge to day I if you are interested in brain inspired system, maybe we should be looking at the right end of my first slide, which is this slide here that we can create a system that already has a realm of possibilities for matching, but another requirement that that system should be
supporting a goal it has to live in a niche. It has to be embodied, it has to have a
thing that is deciding or constraining the features that it can support with itself organized complexity.
And, you know, I have a few more things to say but if you're interested then just read this book. Thanks a lot.
Thank you very much. That was an excellent presentation. So, um, next up, we have Professor Dave, actually, let me quickly create a spotlight.
Okay.
So, David Ackley is emeritus professor of computer science at University of New Mexico. David received his PhD from Carnegie Mellon University.
Before starting his academic position at the University of New Mexico. He was a member of the cognitive science research group at Bell Core is ongoing research interests center on artificial life models and real artificial
life models. Current research emphasis include genetic algorithms and programming distributed and social computing robust self aware systems and computer security. Dave the floors know yours.
Yeah, I wasn't exactly sure how I fit in here. Christoph is an incredible legend I mean I started doing computer neural networks in the 80s and graduate school and I was already reading his papers.
And then Georgie's talk was just an incredibly perfect setup for what I want to say.
You know, I, my interest is making computers do new things by themselves, because that's cool. And so I've been doing that my entire career and I, the big problem is of course is that once I've gotten to do it it's not cool anymore so I have to kind of keep moving on and keep feeding the
with new cool stuff so I went from neural networks to genetic algorithms to artificial life started doing in the 90s started doing biological approaches to computer security trying to do automated diversity generation to try to make it so that you know if
they're going to be bugs in software and there were going to be bugs in software. Well then maybe the attacker would have to solve a different problem for each copy of Excel rather than just being able to kill all of them at once.
And, you know, by the late oos. I was depressed about computer security I was depressed about the impossibility of fixing computer security, you know, and the problem wasn't that we couldn't get the you know users to change their passwords or apply patches
or that programmers were incompetent or that managers ship crap, although all those things are true. The problem is, even if those were all fixed.
We still would have incredible computer security problems that are just getting worse and are going to continue to get worse, as people figure out how to exploit the incredible fact that the way we've designed computers is one bug is all it takes to take over the entire machine.
And, you know, physical systems, living systems, brain systems are not like that. I mean, except in very, very rare circumstances. And so I said, Well, you know, what is the actual problem here.
And the problem is, I've concluded the underlying architecture of computation, the CPU and random access model is broken. I mean, it's fine for small systems. But as the system gets bigger and bigger and bigger, it's terrible.
My, my goal is to say, Well, how can we come up with a new architecture, which will be more inherently robust, much more like the attractor networks, the overlapping attractor networks that Chris was talking about, much more like the brain spaghetti that you're
just showing, and yet still be able to engineer with it somehow. And my answer is, Well, number one, we have to stop eating the glass sandwich, and this is the glass sandwich. The idea is, the purpose of a computation is to connect physics to value to connect
the matter to money to put it not to find a point on it. And the way we do that is we build hardware, we build these digital electronic circuits that in fact have tremendous redundancy in them.
A wire that we use to carry one bit could easily carry dozens or hundreds or thousands of different values, what some degree of error, but we don't do that we send one bit down and we stick amplifiers everywhere to squish that one bit back over and over and over again.
And that heroic act of redundancy in digital circuitry is what makes the hardware so reliable that the software level can just assume that it's perfect. Just assume a trick to present a synchronous unit.
I need to find the best way to learn math and science.
Okay.
I'm not sure who I heard.
The circuitry of the electronic circuitry is incredibly redundant and therefore software can be incredibly non redundant. And that's baked into the DNA of computer science.
The idea is, you should never, you know, don't repeat yourself that's a mantra and software engineering. You should use caches if you've computed something you should remember it don't compute it again.
And all of that is built on top of the idea of, we have to trust the hardware is perfect, but that guarantee that hardware provides always has an asterisk, because of course there is still some probability of failure some probability of an undetected error coming
from the hardware level and reaching the software level, we just engineer it so that it's low enough that we can finish playing solitaire, or doing whatever program we want to do with having vanishing low chance of anything going wrong.
Similarly, once the computations get really really big like data several data center level 10s of thousands of these machines all owned by a single organization.
And that's bringing them failing because that remaining level of failure is there. And they start applying robustness features, but for everybody else there's basically, you know, electronic circuit robustness, and then this fragile and incredibly efficient, which equals
incredibly non redundant, incredibly fragile non robust software built on top. And the claim is the suggestion is, we have to stop eating the glass sandwich. And here's my conclusions.
This is a 12 step program for inventing a new architecture that in fact, almost completely inverts the design assumptions that underlie deterministic execution with CPU and ramp.
And I won't any have anywhere near enough time to go through all of these, but several of them have already been mentioned.
Number seven, look at life for lessons that's what I take from both Yuri and Kristoff using their studying the brain and studying the, the nervous systems of animals and people and everything for understanding about how these things work and the fact that for
brains aren't just sitting there they're doing stuff all the time if you want to do something with a brain, you have to work with the dynamics that it's got that's very different than a computer with memory just sitting there empty you load it up with a program and then it does whatever you wish.
So, it begins with step one, admit we have a problem and for me, that is driven by computer security, I think, you know, 50 years from now, hopefully less are great grandkids will not believe the world that we've lived in as far as computer security
today of the computers we have today are so unbelievably gullible. I mean, one mistake, I mean, they're, they're like complete, you know, you just talk to them, and they become zombies, it's like a horror movie where all you have to do is say the thing, and then they start
sending spam to Russia for you or whatever it is that they do. And that is not the way it has to be. That is the way it is because the way we've designed the glass sandwich, but we could do something else and so you know, the idea is instead of thinking
about correctness and efficiency only at software, we have to think in terms of robustness first think robust first, and admit we have a problem, we can sing the whole song, pick new metrics, and so on.
But I won't do that I just want to get a little bit more unpack the idea, show a few demos, and then stop there and let's go with discussion for it. Okay.
So here's the answer. The answer to how to stop eating the glass sandwich is go for structure at all scales and rather than saying we've got physics, we've got hardware that produces universality as close to the physics as possible.
And then it's all just software, we're going to say no, actually we want to delay universality and have that happen much closer to the value.
And we want instead, just like you were talking about just like talking about have attractor nets, things that self stabilize things that have their own internal goals, other than get the credit card number.
Yes, we have to get the credit card number at the end otherwise we can't pay for the whole operation, but we want to do it with things inside that are worrying about their own goals.
You know, am I still is everything all cleaned up do I have enough room to work drive enough copies or enough cousins and brothers and so forth that are available to do it in case something happens to me, and so forth, and they themselves are made of even smaller systems like
that. So rather than saying you know it's turtles all the way down, we want to build bottom up and say you know it's thermostats all the way up, made out of more and more and more complicated ones layered on, and I want to engineer that I want to actually build
that learn by implementing them, you know we can learn by studying the brain we can learn by studying animals, that's great, but that's not what I do, I want to do it by building it and seeing cool new things happen.
All right, so I've already said this, don't blame the users the programmers the managers blame the architecture in particular blame random access memory, you know, which is this wonderful thing, and it's far far too wonderful, because the instant
we manage to knock a program off its kilter. Once you have this huge field of opportunities you can find anything you need a little bit here and there 17 of these carry loop make a thing by one.
You're doing whatever you wish. How do you stop that what we had now all the stuff that we're doing now the people doing computer security work you know it's there.
We're going to do it because here's the engineering field that we're currently living and we got to play it as it lays, but it's patch patch patch, I mean, not just for the users but for the whole idea.
It's a glass dam that is going to spring leaks, we have to keep patching it up.
The whole thing is going to go to hell, but we could if we wanted actually start to build another dam a little further away out of stern or stuff out of stuff that's built out of rip stop nylon instead of out of brittle glass.
And in order to do that we have to ditch random access memory. And what are we going to replace it with if we get rid of random access memory.
Well, the suggestion I make is, it's going to be some kind of cellular automata. Now, if you're not familiar with cellular automata. It's the idea of instead of having one big central processing unit, and one massive Ram, you have a whole bunch of teeny little processors with little teeny bits of Ram, and
you can talk to nearest neighbors or nearest two or three neighbors or whatever it is some limited neighborhood that is all that they can get to, and there's no general purpose pointer, they cannot go well, I need that little bit in this little bit.
So does that mean everything's guaranteed to be fine. No, does that mean everything is safe. No, but it does mean that if an attack is going to be mustered in the most critical moments when you first knocked the system off kilter.
So, very little bit of stuff to work with, and it's all very delicate and you have to do a land war. You have to take over the next stop and the next bit and the next bit and spread it, rather than going boom, I won.
Now, most people that are familiar with cellular automata.
There are things like Conway's Game of Life, and that has a two characteristics that I don't like, and in particular number one, it's deterministic. So it inherits that exact same flaw that believing in perfect hardware that CPU and Ram inherits from.
So if we get around the problems that CPU and Ram and deterministic execution are causing, we have to give up on deterministic execution, we have to admit that there will be flaws, and they have to be handled software can't just say reliability is a hardware problem.
It can't be synchronous, the whole thing can't go kuchunk kuchunk kuchunk at once, because the whole point of cellular automata is that it can get bigger, we can add more we can grow the thing out, and the bigger the thing gets the worst synchronization becomes.
One of the tricks you can do that people keep discovering every decade or two about ways to kind of lay a synchronous thing on top of an asynchronous thing, but they all rely on deterministic execution.
If there's a possibility of errors, that means the synchronous overlay, it actually locks up the entire universe grinds to a halt, not a good outcome for having one bit flip.
We have to embrace asynchronous valuable hardware and say how could we program on that. And wow that's harder than programming on CPU and Ram. But hey, we know a little bit more about software now than we did when we first invented the von Neumann machine and all the subsequent CPU and Ram stuff.
That's the idea, how do we make a cellular automata got it. That's can be indefinitely scalable. We make it by making an individual tile, a chunk of cellular automata that can connect with others of its own kind and we just keep plugging it out.
So here, this is a T two tile this is the specific tile that I've been working on for the last decade or so. It's a small project so it's going slowly.
But in fact we had an earlier version called the Illuminato X Machina back in 2008 that similarly it's a 2D thing that you plug them together and so forth those were actually briefly marketed.
And recently we have the T two tiles the one that I just showed you. And these things are, you know, ridiculous, huge, heavy, hot $100 expensive each, because they're a research prototype. And, you know, the key is to figure out what we want to figure out a new deal between hardware and
software. And then yes, the hardware guys can come in and figure out how to do this beautiful.
We have to know what we want first. So, that's it. There's a the T two tile project has bi weekly videos on YouTube. There's also a T two demos, which just shows examples of the stuff running.
And you know we've got a new programming language called alarm which is a procedural language for coding up transition rules for these things. We also have a spatial programming language called splat, where you actually can make these
little, these little diagrams you know little ASCII pictures, saying this 2D pattern goes to that 2D pattern and so forth. And that you know it's very simple but it made stuff possible it made stuff work, like that I've been trying to get to work forever.
Now, I'm just going to show you this one and then I'm going to I guess I'll stop because my 15 minutes are up.
One of the problems with asynchronous cellular automata is how do you move a big thing. How do you move something that's bigger than you can move all at once. If it's synchronous you kind of imagine going chunk in one step, but when it's asynchronous you can't you have to somehow
do it. And that's what this example was doing. It's the little blue guys that go through they create swap lines that come up and pass through the rectangle and each time they pass through the matrix the matrix moves one step in the opposite direction that's what a swap
line does. So a swap line is designed so that it never gets more than 45 degrees down the line. So it's a limited amount of synchronization, the passing of the line is a certain degree of synchronization.
And that's just one example of learn by doing this is another example I'll just let this run I guess and well, and this is taking a plate, a grid of sites that communally say let's create a common spatial origin let's create a 00 and a
whatever it is. There's no overall grid coordinates in the underlying architecture there's no 00 because it's indefinitely scalable there's no beginning.
Everything just thinks it's the center of the universe and it goes from there, but that doesn't mean we can set up our own private little one. And once we do that we can do all kinds of things with it.
So this is more stuff with plates. Oh, and I'll just jump to this last one, if I can. There it is.
This is an incredibly lame neural network, kind of encoded in an movable feast machine written in ULAM. And here it is actually running.
The two blocks that you see on the upper side are crossbar matrices that connect inbound inbound wires and outbound wires and they each have a weight at the connection.
And then down so it's actually doing a simple function optimization where the one on the upper left represents the function the one on the upper right represents the knowledge that the algorithm is gaining and then it actually had a little
speed out on the screen to produce human output. So that's it.
Well, I will stop there. And
it's going incredibly slow, but hopefully some folks will be inspired, you know, step step 11 is, you know, it, we have to make it happen we have to get organized and so forth.
This is not going to be running Excel in a year this is a long term fundamental research project to kind of go for a mulligan to kind of do a do over instead of having determinism at the bottom we have determinism at the top instead of having data center software reliability at
the top we have it at the bottom, and so on.
Thanks for listening.
Thank you David.
I from the chat they see this was an extremely inspiring presentations.
Okay, I'll switch to us.
So, our final presenter today is Dr. Yosha Bach.
Yosha Bach is a cognitive scientist and AI researcher with a focus on computational models of cognition and neuro symbolic AI.
He has taught and worked in AI research at Humboldt University of Berlin, the Institute for cognitive science in Osnabrook, the MIT media lab, the Harvard program for evolutionary dynamics, and is currently a principal AI
researcher at Intel Labs California.
Yosha, the floor is now yours.
Thank you.
The machine that builds the machine is a very interesting topic when we think about the brain because our mind is something that is not just designed as a technological system from the outside in, but as biological and social systems are from the inside out.
When you look at this difference, when we design a system in our lab we start from a deterministic environment and we take a substrate to this environment that is not structured yet in the way in which we want it to be structured but we can fully control it, and we extend our
determinism into this new part of the universe to basically extend our deterministic world into this particular thing so we are coming from the outside in a technological design.
In the biological system, you do not have this deterministic environment to start this. Instead, you have an indeterministic environment and you start out with some seed that needs to colonize the environment to branch out to subdue it to turn it into something that the seed knows how to deal with.
And then gradually turn its own structure and then you go beyond simple organic roles, you look at organismic roles where you already know the structure around you because you have created this or you are part of something that had shared destiny at some point.
And so now you have known units around you this which you can collaborate and organize and so you are colonizing the outside internally you are organizing from the ground up from local units inside out and
we can ask ourselves what an organism is does an organism actually exist right we sometimes think of organisms as things, but the organism is the virtual thing it's a function that describes the coherent pattern and the activity of many cells.
Right so the individual cells are all serving that function and by making them coherent due to evolutionary pressure and the design constraints that are built into the cells as a result of that you see a coherent pattern emerging and this coherent pattern that we see emerging.
That is the causal structure that we call the organism and the organism, like every other thing that exists to exist is to be implemented is implemented to some extent.
But it's not implemented in the way in which computer chip is implemented, but the degree of approximation is much more vague.
And it's the organism exists to the degree that the patterns in the interaction of the cells in the organism are coherent.
So in some sense we see a pattern of this organization, a software that emerges over this information processing that looks as if there is a coherent agent that is inhabiting this thing.
And traditionally the word for this emerging operating system for an autonomous robot in nature is called spirit.
In this sense, the emergent agency that we see in organisms is this actually what was called spirits by the previous civilization.
And the spirits also happen to be in our own minds and they also happen to emerge in groups of people in nation states and ecosystems and so on and these spirits are virtual machines that possess agency that is they play a controlling wall by being able to model the future,
in a certain place in the universe to some degree and they are approximately implemented.
And so, in this sense, the spirit is a very high level of an organization that is required to see the emergence of such a spirit.
And then we look at the hierarchy of course the systems at the lowest level.
They have something like our automata like the game of life, and the automata, they can already be curing complete it's not that they are limited in any way, if you give them some memory and so on.
They can implement arbitrarily complex structure to set them up in the right way, but you need to do this from the outside where some kind of design process.
The automaton that might be able to do this without it was a random starting state is our universe itself.
That might be a big automaton at its bottom level and it just happened to inhabit a region that has interesting enough complexity to contain us.
So if you look at the mechanism that is slightly more complicated than causal that an automaton that's usually a stateful thing and it is entwined with a substrate.
Here I use as an example the famous machines by.
Sorry, my brain is blanking out.
Tonya, you know his name.
Theo Janssen, Theo Janssen strand piece, and he has been building these amazing machines that are driven usually by wind power, and they're completely mechanical things that are fully coupled with the environment that don't have an existence that is in the sense independent of the environment.
So if you look at feedback systems you can have open loop systems that are coupled for instance in oscillators you and synthesizers you produce interesting patterns that are the result of some static coupling.
If you take this coupling dynamic, for instance, in the regulator for a steam engine, you can have cybernetics control system, and the controller and the cybernetics system is built by having a system that cares about the target value and wants to minimize the distance to the target value.
And if you extend this controller with computation, you can get an agent.
But to have this decoupling of this ability to model the future, you need to have a system that is a computer a Turing machine in some sense is a mechanism that is disentangling itself decoupling a causal structure from the underlying dynamic of the universe.
And the only thing about our computers is that they do the same thing, regardless of what the environment is doing they work the same way, whether you are carrying them to America and New York, or whether the temperature is a few degrees higher or lower or whether your climate
is down, or whether the wind is blowing or not. And the same kind of computer also exists inside of our skulls. It's a slightly different one, but this principle of the computer is that enables an arbitrary causal structure.
And you need to have this arbitrary causal structure to be able to make models of the future, right, because you want to look at different futures, regardless of what the universe is doing right now.
And the simple system that we know in nature that is in the sense Turing complete and has the powers of functional approximation and self organization to achieve that is the cell.
So the cell basically is able to perform computations that are decoupled from its immediate substrate, and then enable the cell to make models that predict the future to so the cell can regulate against future disturbances and keep itself stable against these disturbances.
So that's why the cell is such a complex system is able to exist.
So the cell is an agent, and an agent is basically a controller, combined with an internal set point generator, and the ability to model the future so the agent is not just acting like a thermostat on the next frame and tries to optimize the state of the next
frame but it's integrating the expected set point deviations over the future and tries to minimize them.
And if the modeling capacity is sufficient, then this agent is able to model different branches of the universe and the effect that its decisions will have on these branches.
And as a result, you basically get beliefs desires and intentions all emerging from a simple controller that is able to model the future. So this is basically a minimal concept of agency and agents can start to collaborate with each other and
as a groups for agents and groups agents, the typically have individual motivation and a reputation system among the agents that makes sure that their actions are harmonious and beneficial to the members of the group.
And slightly different extension of the group agent is a state building agent.
A state building agent is one that scales beyond reputation system.
It means that the individuals do not have to know each other individually to have to maintain a model of their reputation and that transaction and synchronize this reputation system somehow like a tribe does.
A state is fundamentally different from the tribe, because the members of the state become interchangeable they have functional roles now.
And these state building agents can grow very large, but the size of the state building agents depends on the size of the effective colonial structure that we can maintain so basically logistics chain to build such a colony of units such as synchronize the state needs to
have a way to impose administration on its substrate and extract more like entropy from the substrate, then the administration costs, and this limits the size of the design of state building system, especially once you have such a state building system and evolution it's
going to repeat the similar systems for the same leg entropy.
And so you are basically the set of principles that has outcompeted all other systems from extracting like entropy from your volume of space.
And to do this, you need to impose a coordinated patterns of organization onto your volume of space.
And because you're competing with others limits the size that you can have and there are very few organisms that have cracked the code and have become infinitely scaling state building agents right most state building systems have a limited size that design is limited by the stable logistics chain that they can use to impose their
environment. And this here for instance is Pando forest it's ash trees in Utah. It's one of the largest organisms that we have on earth all these trees are the same tree.
They're not just genetic clones for each other, but their wounds are connected.
This is basically one big tree that can grow as large as it wants. It's very old, and it didn't mutate very much since it's gross right so it needs to be evolutionary stable so it doesn't drift.
Another example for an infinitely scaling state building agent is linear PC by you mean it's a Brazilian and that has spread around the world.
And all members of this and of these end colonies will not attack each other they will all treat each other as part of the same cohesive colony.
This is the exception of a few drifted colonies for instance in the US.
When they get in touch with the other colonies they will attack each other. So they had some kind of genetic drift after the colony was established that makes them appear to be strangers to each other but the species has cracked the problem of becoming infinitely scaling
There's no limit to the size of this colony apparently.
And if you look at the design constraints for such systems, the mechanical component needs to have an outside in design by some external agent so it is not going to exist by itself and it's not able to adapt by itself.
And then you build a controller controller gets resilient that can be larger than the mechanical component because it's able to adapt its states to a slightly changing environmental circumstances and maintain an attractor state by itself via dynamic control.
And if your controller is able to model the future via decoupled computation then it's able to integrate future reward and is able to not just adapt itself to the environment but it's also able to adapt the environment to itself.
And in group agent you can do this on the next level.
You can basically build an agent that is composed of multiple sub agents and each of these sub agents has its individual motivation and the reputation system to coordinate the group.
And in a state building agent, you change this reputation system or extended via hierarchy of the governments and this thing needs an immune system.
The sub agents are submitting to this governance and are not building their own government that is competing with the main government.
And you will have limited autonomy of the sub agent so there will be set up in such a way that they per default, most of them will want to submit to the state building group, rather than doing their own thing.
You can see this in humans via basically a domesticated species of the hominids and as a result you're not just tribal homo sapiens is state building because the most of the individuals in our species are beginning to submit to the group before they do their own thing.
And if you go to an infinitely scalable state building agent you can do at some level less than you can do and these other groups because the need to be static you cannot have an evolutionary drift.
You cannot adapt to the environment beyond the mechanisms that are built into the system because if you were to drift, then this this infinite scale would break and you would no longer be consistent.
So, if you think of hierarchical governments as a principle, we have a trade of their between adaptivity and coherence in the system.
The more adaptive it is the harder it is to maintain coherence and the individual agents here are incentivized to defect from the system very often and you might have to limit this by having an agent that imposes an offset to the payoff matrix to the individuals and this is what you call a government.
The need for a government comes not from political constraints or from the desire to exploit people or something else just game theoretic thing that you can derive from first principles.
And the purpose of this government is to integrate the total reward which can happen from bottom up and to top down to credit assignment to make sure that the individual behavior is adjusted in such a way that the national equilibrium of the individual agents become compatible with the common good.
And this is something that also needs to happen in some sense in our own brain the neurons are autonomous reinforcement learners and the interaction between the neurons needs to be coordinated into a coherent structure.
And Jerry Aylman has suggested that the organization that happens in our own mind is something that evolves in every individual in some kind of what he calls evolution because you will Darwinism.
And so maybe the top down process that is harmonizing about bottom up perception is something like a governance a colonizing agent so our brain is not just playing free jazz, which it does to some extent, but it also plays a coordinated symphony.
It is serving coherent goals, it is has an emerging coherent agent that is forming inside the organization of the cells, it makes our organism more efficient by giving it coordinated spirit.
And because this relevant to AI current measure learning representations all have an outside in design and organisms the representations are different your organisms are coupled to the environments with the features are not static.
They are functions that basically operators on your government representation to give you the next state, and they're tuned in such a way that they track the sensory patterns.
These features are kept stable and coordinated by an individual controller so every feature is probably some control structure that maintains its stability and its coordination with the environment.
And the entire thing goes beyond jazz by having some kind of emergent governance that harmonizes it and instantiates individual features and resolve some and they're no longer necessary destroys the attractor states.
And governance when it's at the level of the scene that you currently use to interpret the world.
And you have multiple systems of interacting agency in there, visit the scene agent that is trying to predict how the world continues. You also have a self agent that is driven by the motivation of our organism.
And you have an attention agent that is figuring out which features to select and harmonize and to instantiate and to dissolve at any given moment.
In this way, organisms can have an essentialized causes tractor, but the central is cross instructor is not like a CPU and a computer rather it's an.
It's more like the centralized process structure in a society of people that emerges as a result of an evolution that makes the society more efficient and better at competing with other societies.
So, this is very for today.
Right, so now we are to the discussion part of the session. Let me see what's what we have in the chat for questions.
So, first of all, please feel free if any of the panelists has comments about each other's presentations. Please feel free to voice them.
In terms of questions so first question is from Thomas McGee.
And it is not.
It was posted, I believe during Yuri's present presentation but it may have been to anyone.
Here are some examples of multistable and metastable neural attractor dynamics with the slow fluctuation of externally oriented delta theta and dominated oscillations and internally oriented alpha beta oscillations be an example of an endogenous multi stable attractor dynamic in the brain.
Also curious about some examples of neural heteroclinic cycles.
There are many questions and there are many components to this.
One of the most beautiful things in in in brain evolution about scales is brain rhythms.
Now, what you would like to know in general about scaling is that what do you want to preserve. And what do you, what are you allowed to sacrifice.
The brain rhythms are extremely useful on this because they are pretty much the same in every single brain in, at least in the mammals from the mouse, the human.
And the mechanisms are the same the pharmacological sensitivity is the same.
One interesting thing is that they form a just just to finish this line, which means that the most important thing for the brain is to keep timing preserved.
And the reason why timing is so important is because we control muscles, and the muscles are the same in all species and the speed of the muscle hasn't changed the evolution at all.
So other creatures have pretty much the same speed so that's probably one of the evolutionary pressures that allowed or force to keep timing the same and then you sacrifice a lot.
You sacrifice a structure, you put a lot of lines that is axons in a larger brain that are much more much faster conducting because you have to deliver the information in the same time to a more distant target.
Then the calibers of the axons grow and so on and that these are beautifully demonstrated by comparisons of the fibers in the copper scolosum and in the, in the retina, the optic tract and so on.
Now, these oscillations or returns that this questioner asked about form a beautiful hierarchical system.
The hierarchical organization is simple, which is called phase amplitude coupling, which means that the lower oscillations phase modulate the amplitude or the magnitude of the faster one and the phase of the fast one modulates the amplitude of the even faster one and so on and so on and so on.
The consequence of all this is that when you have a short period of time and you've got a short period of an oscillator or short waveform, then only events can occur locally.
When you have more time and then you have a slow oscillator that it engages all the other ones in a larger neuronal space.
Very different from me, I probably had this is if I, if I understood it right from, from, from Dave, he alluded to this that that we try to believe a stuff to distant architectures rather than just the neighbors.
This is what the brain does in both ways, namely that most of the organizational pattern is local.
But the large oscillation is allowing that local computation is broadcasted locally globally a little bit, and the global computations that is the global oscillations constraints, what goes on in any local situation.
This allows this hierarchical system allows you to have a brain syntax to package information in short chunks and longer chunks.
So, you asked about various various names but for the audience it doesn't matter, let's just call the faster ones, gamma oscillations which are about 2030 millisecond.
This could be the content of this is a bunch of neurons firing together with the one and only purpose is to discharge a post synaptic target neuron.
It can be called a neuronal ladder. Now a theta and an alpha oscillation can concatenate several of these slots, the gamma oscillations to a neuronal word, and the neuronal word can be combined into a longer segment.
So, this is the way I think it was, was Christoph who already mentioned that, you know, without a generative rule, a syntactical rule you cannot really grow the information content infinitely but if you have such a syntactical rule such as the brain oscillatory hierarchy,
then it allows the brain to generate infinite number of sequences from limited number of elements. So this is a complicated answer to the brain rhythms.
If you I just didn't throw the ball I had a previous book, but that's a short answer.
I want to follow up on that. Is it the case so you're saying these brain rhythms are extremely conserved across mammalian species at least.
And does that mean that the size of the brain doesn't affect the rate of a given class of oscillation.
The elephants are going no faster, no slower.
Even though they have much more distance in just raw centimeters to cover. I mean, and why the hell would that be. I mean, why, because they just stretch the axons out that makes hardly any difference in the propagation time.
I think the idea of physical systems was was discussed a couple of times here. No physical this physical systems are different from from theoretical creations with unlimited speed and so on.
I wanted to to keep the.
If you if you look at my mark here, it has color and all sorts of features, as you know, it has been studied, and for Mars, we'll study it about the mining issue.
All these things have to come together, but they have to come together somewhere in a small brain and the large brain, in the same time, in order to perceive it and they do understand why same time.
Why couldn't it be a little longer in the big brain because we are. Well, not because but this is the speculation. I'm interacting with another species and another species and another species and another species and all of this.
If that would be a tremendous, you know, order of magnitude advantage, then in speed, for example, I would be that.
I think the short cycles I could expect to be preserved or forced chemically or something like that, but it's the long ones that I would expect could have more variation.
This is the interesting kick brains do this for a goal and we can talk about the goal a little bit later, because this if you are interested in what is preserved in the brain throughout evolution then my answer is timing and the brain oscillation.
It's not because the brains cannot do something else. Breathing, which is also an oscillation a very regular thing is organized by by about a few thousand neurons that can have several orders of magnitude different in written, you know, the ways and the heart rate.
So they are very, very different. So if you want, you can do it. But all the other oscillation that I use for cognition and controlling the body seems to be preserved.
Thank you. And as I mentioned briefly, that there is there are beautiful full anatomical data showing that the connection between this part of my brain that this part of the brain is about 100 times smaller in a smaller brain.
And the conduction velocity is 10 times more in my brain, because it's needed that you get there at the same time.
The cost is the size the cost is enormous because you have to put my lane and energetically, it's so costly to maintain to deliver electricity one from one place or another.
But this is what brains do.
Oh, that's the same in digital manufacturing computers the more metal you have to run the more energy you pay the more later you pay the more area you pay. It costs a ton.
And if you want to crank this clock the same speed on a big physical system, the brain is just like your chips, you know, in that sense, thank you.
I have a question to dirty.
If you look at the organization of the new cortex, how much of that do you think is the result of deliberate circuitry building and how much of it is just a stochastic substrate.
You point out that the complexity doesn't very much change to be learning, but it's not that the brain starts out with no structure or the new cortex starts out with no structure.
After the initial setup, of course, and then it forms all this intricate structure after interacting with the environment, it seeks the structure, but the complexity at which a child perceives the world is probably not that much different from the complexity at which
a child perceives the world, even though the functions are being learned are slightly different, but how much of that is basically reflected via the circuitry and how much is the circuitry just a result of of the learning of
for instance, RNA based memory that is stored in the activation pattern or propensity of the individual cells.
The propensity of the individual cells seems to be preserved throughout much of lifetime. So the firing rate of a neurons is almost like a fingerprint that you can perturb it you can do lots of things that it do the same.
Now you take a cortical unit a cortical module it's called the column.
And then many people are very much interested in how the different columns compute something differently in the visual system versus a thinking system such as the prefrontal cortex.
But the if you look at the connectivity of these two systems they are not very different. So the commonality is much stronger so much so that experiments have been done 20 years ago.
When either a newborn or a prenatal animal is taken out and you take a piece of tissue from here and you put it here and you change it, there will be a relatively normal brain because the system can tolerate that kind of discrepancy.
Now when you look at a small brain a large brain and you say how many different types of neurons that are there.
Then today, on these days, you know, people celebrate if they find one neuron that in the human brain, or in a primate brain that looks a little bit different, or genetically looks different than in the brain of a mouse, because the component diversity is relatively limited
throughout the mammalian evolution. Now, having said that the neocortex is a modular system, it can just grow because you can add element, and then you need the agent that you talked about the controller that brings this together that maybe the Talibus that allows all these things to be modulated together work together.
But there is this different type of organization called the hippocampus, which is a single giant cortical module.
It's the same structure, there's no modularity in it, it just grows from the tree shrew to the whale, and it gets larger and larger, because it is quote unquote design as a random graph that you would like to go from anywhere to anywhere else in just two steps.
That may be an interesting thing, you know, why, and I don't have a good answer, nobody does, why do we have this, this external loops, why does the neocortex cannot solve the problem of the, of the, but the hippocampus can do but what I learned today is that even in computer science and
architecture is the primary thing that determines form defines function and brain is not an exception from this. In fact, it's I think the prime example.
Yuri. So, so we have a question from we scroll to, to Christoph and Yuri, looking at your insights is the current architectural paradigm for artificial neural networks still stuck in an architecture, ignoring the endless loop with environment paradigm of real
networks. So, despite, despite the deep learning advances, will we continue getting more stuck.
This question has a plus script saying some alternatives like cellular automata still totally missed the feature of being massively looped, or massively parallel, in my opinion, also a dead end street.
But I take it as asking is deep learning, the end of the story, so to speak, and, and can that be continued indefinitely by just enlarging the system or is enlarging the, the training sets.
What I mean here is that deep learning is stuck. The main problem being that it's a priori assumptions, it's, it's fundamental data model is not tuned to our environment.
To some particular application fields but as far as we are, and after animal type human type intelligence deep learning doesn't have the right data architecture.
That is the reason for it being very poor in generalizing, you know, if you show a new kind of object to a three year old child, the child gets it after the inspection of a single sample of that object, and recognize it in under massive changes
that are in exact shape and so on.
And so what deep learning is poor in is its feet forward architecture, which is forced on it by the necessity to back propagate the error.
This is a very poor data format. And as I have tried to point out, self organized networks which differ from what we have today in deep learning structures, fundamentally, by having cycles of, of connectivity, you know lateral connections
between within a layer, speaking about the layer system.
So I think the enormous efficiency with it, with which animals learn or or humans learn is something which is beyond reach of the deep learning paradigm.
So first off, I have a question about comical complexity. If you think of physics the comical complexity of the universe might be very low in the sense that it could be a fractal which has a simple generator function.
But the complexity of the particle universe is extremely high.
Right, so if we tried to describe the detailed fine grain structure of the universe around us, we would need an enormous amount of code because you cannot compress it very well, because we don't have access to the underlying function and our position in the
But the description that we are making of the world with Newtonian physics and basically the game engine that our mind inhabits again has a much, much lower complexity.
So there's basically an emergent causal structure that we use to predict the world that fascinatingly works quite well.
And that can be described efficiently in what you describe as a gigabyte of code, probably a lot less if you write the code down more efficiently than we do.
And now an interesting question is what is the actual comical complexity of our mind where the complexity of building a brain by setting up self organization process between the cells is probably relatively low.
It's not the entire gigabyte of genetic information, but probably more in the order of kilobytes or megabytes that are required to basically form out the brain as in the self organization process.
But what is the comical complexity of the emergent system if you were to design the brain as an engineering project from the outside in.
Is this going to be similar to the Newtonian world where you have a relatively efficient structure could we come up with classical AI architecture describe the brain efficiently.
Or do you have to deal with the fact that the effective structure of the brain is going to be very complicated so you will need to have a self organization to understand it.
My argument was of course that the brain is of low Conmogorov complexity, because it can be built with so little genetic information.
Some people claim or have computed that the 3.3 billion
basis can be compressed to something like 50 mega mega bit. So the complexity is very low and the in order to build the brain you need a process of self organization that's as we know starts with a single fertilized cell and goes through divisions and goes through a sequence of
a tractor states. That's the way the brain is built. Now, our way of building outside in completely ignore such constraints as are implicit implicit in the organic growth from one state to the next.
We can sort of when putting together blueprint, we can, we have the full, the full universe of potential patterns we can can throw on to our blueprint, and the only constraint that we are observing is the design ideas we have in mind.
So I think, of course, you can buy by knowing the exact, the procedures of self organization, the mechanism of self organization, you can let them play in your computer that you use for the design and get the final result and then that impose that final result outside in on on a piece of hardware.
But I find it pretty against the nature of things to do that. So, I think complex, complex brains, artificial brains will be built inside out, and if only they are constructed on digital computers.
As a present time, I'm simulating all my systems of course on the digital computer. What can I do, even on the digital computer, you would rely on an organic growth process, generating the final structure as a sequence of intermediate states.
So I think you are stuck with self organization.
By the way, the reason why I wanted to have Dave on this panel is I thought that it would be interesting to see if there is an interaction between the ways in which he is designing computers by self organizing principles and the way in which we think in neuroscience and cognitive science about self organization for information processing.
So, comment on that.
He made it very clear that reliability in our digital computers is is solely on the on the hardware level.
And by by forcing the signals to decide either for one of a zero with, you know, these, these self interacting loops, driving the signals to saturation, and, and building on that very personal as he puts it software.
There are two flaws number one, the software needs to be signed outside in there is no way the computer prefers more functional strategies software prefers more functional structures less functions factor by itself.
All the functional structures must be brought from the outside in. And number two, the unreliability talks about. So if on the software level, you have something that is built on redundancy multiple pathways,
built on a tractor dynamics, you can work with you can live with underlying hardware neuromorphic hardware for instance, which is analog, which is prone to a noise noise that is bridled in by these.
If you, if you want to refer to that as such by the software level bridled in by the by what we now have as software. So I'm completely in tune with David at least I love his way of looking at them.
Thank you Christoph I mean, you know, this was such a big aha for me, because I was raised as a computer scientist I was raised to be all about efficiency, all about correctness, and then to realize that that was all just purchased on this phenomenal act of redundancy at the amplifier digital
and that you know we were just sort of cruising on that ever since. And yeah so the question is, is how can you build bottom up in terms of software and the idea all that I come up with is that we build simple agents and then we build more complex agents at bigger slower and more complex agents by combining
the collaborations of smaller, simple ones, and you know, exactly how to do that depends on what the actual hardware you're trying to deal with if you're trying to deal with analog neuromorphic stuff that has one set of affordances that you now have to figure out how to work with.
I work with, you know, stuff that's a little bit more traditional like cellular automata except, you know, best effort only and asynchronous only and so forth.
But there's clear set of problems, like control of space and how to reduce variation around space so that you can now do something more specific.
And if I could take one, one minute I could show a little demo that I wanted to show.
Because it kind of shows the idea maybe.
So, you know, one approach is to just make everything big and rigid. Right, so, so here is a block of wall, so to speak.
And the idea is well but you know instead we want to do something more adaptive more reactive so this is a
simple cell membrane that's kind of knocking around. And, oops, and I think I may have just killed it. Let's start a new one.
So much for robustness there you know if God is going to mess it up you know it's not really his fault.
But the point is, is that you know the existing stuff that we have tries to be rigid, and it counts on the, the underlying hardware remaining rigid and so forth.
Okay, there's our rigid thing.
And, but one of the things that we do, because there's this terrible problem you know if you try to be robust.
But there actually is nothing challenging the robustness, the robustness looks like waste. So there's this inherent tendency to start chipping away at the redundancy, because if there's no actual
problems, then it doesn't matter, you can get away with it. So, for me can happen in natural evolutionary processes as well. So one of the things that we do in what we build is we build stuff into deliberately challenge the system.
And one of the things we've got is an element called drag it stands for dynamic regulator. And what it does is, it just wanders around and randomly erases stuff that it's next to every so often, not all the time.
And every so often it just creates a new sort of food particle that can be used for anything. So I'm going to flood the world with drag right now.
So, you know what we see happen is the, the rigid structure gets eaten up, right.
But the, the cell cell, I want to call it a cell membrane it's not a real cell membrane obviously this is so abstracted away.
It actually does active transport to bring the little food particles inside and it grows.
So this is my suggestion, an example, you know, a thought experiment well it's implemented not exactly a thought experiment of how you can actually start building up that you build first you build small fast structures, then you build bigger slower structures out of multiple units of
things. And we just try to keep going up and at each stage of the operation, we're going to have data sheets, saying you know this thing is good for this it'll work at this it'll do badly at that.
If you go outside these parameters behaviors it's your fault, and so on, just like real systems always have data sheets, but computer science never did.
And it was again because of that same dam determinism that the hardware guarantee was supposedly providing us.
What I really like about your work is that you don't try to imitate brains.
And it's beautiful work about spike neural networks but why you spikes if you can set arbitrary messages and so you come under this organization from a completely different angle.
And I wonder, have you thought about learning systems in this way, could you build structure that is learning new functions, how would a meta learning system look like because you have to design eventually the meta learning right.
The last example that I showed the function optimizer as a simple example that was actually implementing the sigh algorithm that I did my dissertation on in 1987.
And here it is coming back. And one thing that was interesting to me when I was implementing it in the movable feast machine in this architecture is that it was really hard to do a bipartite graph.
It was to connect everything by equally length units, and I ended up not doing it I ended up doing a crossbar switch and putting, you know, mate weight matrix weight weights at each intersection.
But then, since it's all asynchronous. That means that the stuff that's close to the crotch where they meet is much faster, and it's a lot like a georgies picture where he showed the simple brain, and then the bigger brains wrapped around it with the bigger loops the slower
structures fell out in the sigh algorithm in the sigh implementation that I did on the movable feast, because once again, we still had space. There's no random access memory you can't just pretend everything is next to everything.
Yeah, I think so I think it's going to impact the structure of learning systems in a fundamental way, and it's going to be a pain, because right now you can just throw around matrices.
You can tensor them up and just do the deep learning things the way people are doing and they're having great fun if I was younger, I would totally be doing that but you know I did my version of it in the 80s and I moved on like that.
All of that all put together is still under the same as Christoph was saying outside in where you pick the architecture I've got 10 layers and a concentrator and a convolutional layer and then the transform attentional thing.
That's all done by the human and then it's fixed.
And I want to have something that's underneath all of that that says you know we can we can do these things, but then we can reprogram them by sending down new software rather than saying we have to throw out the machine and build a new one.
Maybe that's the brain goal is to put a lot of effort into making the system resistant to catastrophic interference and that's the primary goal probably your brain and my brain never experiences catastrophic interference showed up, you know, a car accident or something
like that.
I like a lot of statements you had Dave, my favorite one was this, we have to know what we want.
First, which is an interesting statement, because this is exactly what AI is about it has to have a goal.
On the other hand, you, your mind is very fascinated about self organization.
And there are two interesting things here, you know, one is that it just grows and we don't know what the end product will be. The other one is the goal.
I think, and this is I think what most of the people don't understand out there, the difference between evolution and and intelligent design is that evolution can be explained best with a goal.
But that's just a convenience. And of course, evolution doesn't tremendously tremendously misleading sometimes convenience but virtually irresistible.
And we think that says something to Christos point about low order structure in the environment, so that there is some specific thing to want.
It's not just like every possible environmental input is equally likely. There is structure there that our brain is trying to latch on to. And once it finds it that feels like a goal, I want to get better at doing that.
And then we go off to the races, then we can do deep learning. Once we've got something that says, you know, I want this this is a good mapping, then boom, go hill climb and be merry.
I like that. And you know, there's a whole big field is called decision making, but it is the natural intelligent design kind of.
It sounds like it.
It's a great Augustin's definition, but in the real brain decisions are made post hoc.
Most of the decisions that I made in my life, I justified and it looks like decision.
After the fact, rather than. Yeah, the dig I make is that intelligence intelligence likes to think it's the captain but really it's the historian.
There is an excellent question from Kevin to all of the panelists.
So, what are the panel panels thoughts and artificially creating the phenomenal aspects of our existence. For example, consciousness.
For example, there is a what it is like to recall an episodic memory while basil ganglier learning and memory can operate outside of awareness, connecting to the ideas of chunking and attractors slash complexity, rhythms of the brain and
hardware software considerations.
Would we need anything different to go from artificial intelligence to artificial consciousness and qualia, potentially metabolic or biochemical universities or perhaps artificial conscious computing can already be accomplished without the bits of info at the molecular
level, like for an artificial hippocampus medial temporal lobe system to create what it is like to encode and recall an episodic memory.
Wow.
And can I give a shot.
Go ahead.
You know, I to me at least the state of consciousness in my brain is one where a large number of modalities like seeing and hearing and wanting and feeling and emotion.
And the aims I am after at the present time, where all these modalities are in sync with each other, they speak of the same thing they understand each other they one responds to the other in a useful way, like when you drive your car.
The signal coming in into your peripheral vision immediately lets your arms turn the steering wheel or your foot hit the break.
So the phenomenon of consciousness is one of of integration of all subsystems into one coherent state. And I see that as a an example of
the different fragments, connectivity fragments in the different modalities being activated, activated by activating the participating neurons.
Activated such that they all fit together into one brain spanning coherent network and network that if it was given time would just recreate a stabilize itself by the exchange of signals that's how I see the, the generation of
conscious states.
Just to add to that, you know, the organizer is the brain rhythms, the system of brain rhythms, they are the ones that bring all this together. So probably that's why it is so important.
And of course you can see the evolution of brain rhythms, and you can study it. Your questions, the question is more complex, I don't think anybody can give a one centers explanation about quality.
But I can give you an explanation about the role of the hippocampus, for example. So I take out my hippocampus, and I will probably still know I'm Yuri Bojaki.
I can do a lot of things, except that I will be missing my past.
I will be missing what is called the no static consciousness that is, I don't know whether I was an agent of a episode or not. I don't remember anything about my life as being a participant of this and this is done entirely by one system this side loop of the hippocampus
and what kind of consciousness is this. It's a good question because you always say you are awake. Fine, you know your name, and you know that you are distinct from others, but I don't know who I am in terms of my history.
It's a story that lives in the environment and responds according to the socially agreed norms. This is the kind of thing that I think AI can do not so long from now, but the feeling of it or being you and putting you as the first person
This is the big question is that when a AI system can be saying that I am the viewer, I'm the first person experienced rather than the third person describer of the events out there.
A bit more optimistic than your, basically our model of reality is a model of what the world is like right and our model of the self is a model of what our interaction with the world is like.
And the model is written for us and then informs our future behavior so basically it's the historian that is helping the emergent captain that makes a decision based on the model contents.
And as a result, this story is continued with the consideration that the emergent captain is making right the entire system is virtual the captain is virtual.
The, the agent that lives inside of the world that we observe as being us is a virtual construct that is getting causal power, because it would be very useful to know what it would be like for the brain, if such a person existed and coordinated the behavior of the organism right
So it's a spirit that is being conjured by the interaction of the cell and the phenomenal experience that we have this feeling of what it's like and the content of what it's like is a model of what it is like to attend to our model of reality.
The purpose of modeling is control so the purpose of our modeling phenomenon experience in our own mind and being able to access it and reflect on it is to control the attention that we are paying and the way in which you are coordinating our inner reality.
And the issue is that we have to grasp that the consciousness is not physical it's not something that exists at the level of neurons or physics. It is entirely virtual it's a story, and we live inside of that story.
It is being accessed by this loom that leaves the story to continue the weaving and the contents of the weaving when we reflect on it that is the reflection that we have that the experience as our phenomenology.
This is not in one brain. No, the word consciousness means joint knowledge, knowledge of yours and mine. And in Russian it's called Susnanya. This is for Tatiana, which also means knowledge mirroring from you.
I have no idea who I am. If I'm the only person in my own niche, and I'm surrounded only by alligators, I would have a very interesting opinion about myself, certainly very different than living in New York.
Interesting. You know, you could interpret consciousness also by saying that the different parts of your brain know together.
That's exactly the first view, because now you are you looking at yourself, but you're looking at yourself as your past experience, which is.
Mr. Yuri, why you think that this particular function of knowing your own history of being conscious of your own self in as you just said in a social setting couldn't be modeled in artificial intelligence.
Why would that be a barrier.
I don't think there are limits, because there are no limits in our world, right. I just say this is the most difficult thing to do.
The kind of consciousness which is just mirroring that are I know that I'm separate. It's a relatively easy one because the way how I would approach it as a biologist to say what, how can I study these things in an animal and when I say first person second or third person view, then I can study an animal of low organization such as a mouse,
because in every animal, the most important distinction is the self from everything else.
There are boundaries and so on this is this is a biological thing that has to be internalized very early on in evolution, because that's the important thing.
So this is the egocentric world, and then then the allocentric kind of thing that comes much later.
Because that requires that you generate something that is transferable to the other organism, which is one of your species, you know, this is the social this way it comes up.
So all these complicated things such as social is, and individual is can come down to the ego versus.
I mean, as a, as an engineer, I approach consciousness with how can I build it or what would it take to make a crappy little substitute for it and say, maybe it's something like this.
And I think there, I can get a little bit mostly I don't talk about this because I think the appropriate level of implementation is so much lower than it.
So consciousness is something that is kind of architectural and structural that is going to see much less mysterious once we earn our way up to that level of architecture.
But I do have a thought about it and you know one of the things is is okay so we're willing to buy Dave's pitch that we have to have more redundancy in software software is going to have to start taking over some of the reliability work which we had said,
I saw hardware problem for the first 70 years. And so what that redundancy look like and I think the best example of or the most obvious wonderful example is in software is unit tests that having tests for code is a redundant representation, the format of the
test and the procedural code that it's testing are getting at similar dynamics, but they get it in a completely different way one does it the other one checks to see if it was done.
And so that, you know, it used to be in computer science when I was young tests were like, because you're too stupid to prove it's correct, you know, but now we live in a different world where if you don't have tests, then you're essentially negligent.
And that is a kind of software redundancy right there, that is, you know, you can bite it, you can eat it people love it, because it's good. And so to cover go dot dot dot way past anything that I can actually cover with an implementation right now.
The sense of qualia the sense of consciousness that the guts of it is going to be that we have these redundant representations, one sort of procedural thing that is we're doing that's actually running our sequencing control what we do move the hand do this.
And the other one the historian that folks have been referring to that is describing what we've done, and we're going to get a kind of matching between those two representations that's going to be like the test going green thing.
And that ultimately is going to turn out to be the contents of conscious experience that that green book when the test is passed. We now have told the story. That's my engineer story.
Thank you Dave so one last question from the audience I'm sorry we couldn't get through everyone's questions so this one is from Paul Cassidy to everyone, which thinkers theories and concepts are you currently finding most fascinating and stimulating.
These can be either directly related to the discussion topics or not highly creative and interesting people are the best to get recommendations off in my experience.
So thinkers theories concepts, most fascinating and stimulating cheese.
You know the funny thing is for all the engineering and science I try to do I really don't have that much time for non friction.
So you know, I see I feel like I learned a lot much more about the world from fiction.
So all I can say is, at the moment I'm reading walk away by Corey doctor and I'm finding it fun.
You know, two authors who are often cited these days in circles that discuss consciousness are Julia to know me and Bernard bars, and both of them actually talk in different ways about coherence of the state.
And I'm finding coherence of the state into knowing the, the basic idea is the space of all possible states of neurons in the brain is reduced by connection so if, if you cut the brain in half, then the two halves are free to think to create states.
We're able to to to to create in the presence of the influence from the other half. So that is the kind of, you know, he talks about, of course, entropy and such things, whereas Bernard bars things consciousness comes to comes into existence by there being a central blackboard,
kind of exchange medium in the middle in the virtual middle of the brain, to which all the different agent or different sub modalities can put stuff and from which they can read stuff.
So, again, a kind of means of creating order of creating coherence in the whole thing.
So many of the discussions I've seen. These are referred to as the main theories.
Whether you like it or not.
So Christoph, what do you think of integrated information to know any stuff to buy it.
Yeah, I agree with his basic idea. But I mean you cannot make a whole career out of out of this idea with a five function you cannot measure it you cannot compute it.
You cannot deduce anything from it. It's a nice thought.
But so what I find to to narrow the the different modalities where my brain cannot speak the same language, they cannot communicate in the same language on the blackboard.
So they speak different pairs of languages.
And so that I find that to narrow.
Yeah, to me it seems it's metaphorical at best and even if it's a metaphor, I don't know if it's a good one but it's well it seems popular I mean just like the markup blanket stuff seems popular but it seems.
I don't know.
I have trouble buying it.
Thank you.
I'm an active leader.
I'm an active leader. I read a lot.
I would make a short list of whom I would recommend because every single time I find some great idea.
What fascinates me most is that how far I have to go back in history to find the same idea.
You always do so I my, my favorite books are always old.
You mentioned in the during the prep session you mentioned the prepared unprepared counter counter prepared concepts who was that by selling month I can send you the reference right away.
So, for example, you know that one is a extraordinary person when we talk about, you know, in my book inside out.
I go back in time and I realize that you know I maybe I have to go all the way to plateau.
Because that was the odd to be decided out but then Seligman and many others that Breland and Breland that that we discussed at the before the meeting they are great thinkers.
You know, ideas come by every 50 years.
Small additions come by every day.
Rain cycles do continue to lower herds.
Very low.
Indeed.
Of the most interesting current authors.
I think, and Greg Egan, I think Greg Egan is probably the most interesting philosopher for mind was currently alive.
greg and this last name is Egan E G a n.
I certainly will pitch permutation city to anybody.
Yes, sir.
Yes, as books to read.
Yes, it's also very beautiful, mathematically inspired short stories. He's, he's a very mathematically inclined and physically, physicists like person who plays a lot with this ideas in his mind and it's not
a story driven the things that he writes the stories are vehicles to explore ideas and mental fractals. It's quite beautiful and intricate.
But I do agree with viewers statement that most of the good stuff is actually quite old learned a lot by reading can and
I also besides that I never found them that exciting I grew up with him. And now I realize he's very good. He just was not exciting because he was just the intellectual ground zero where I grew up. It was just so normal.
But it's still very good stuff.
Excellent. Thank you, Yosha. So, with this, we wrap up.
We would like to thank Intel Labs for allowing us to host this event.
And we would like to thank all of the presenters for participating and for delivering these amazing presentations and the lively discussion afterwards.
The meeting has been recorded and will be posted on our YouTube channel. The link can be found in the chat and the chat log with all the references will also be posted on our website so don't worry, you don't need to copy paste anything in a rush it will be there.
So with this, thank you everyone. It was great meeting you all thank you the audience for participating and enjoy the rest of your day.
Thanks to all our guests. It was amazing and thank you Tanya for having with the organization and doing the moderation today.
Thank you, thank you.
Nice meeting you guys.
Absolutely, it was great.
