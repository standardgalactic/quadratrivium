1
00:00:00,000 --> 00:00:17,960
Good afternoon. We're here with Dr. Raymond Kurzweil. It's July 13, 2009, and Dr. Kurzweil,

2
00:00:17,960 --> 00:00:19,480
thanks so much for being with us today.

3
00:00:19,480 --> 00:00:20,480
Yeah, it's my pleasure.

4
00:00:20,480 --> 00:00:25,960
I'd like to start by asking you how you would explain your vision of the future to an intelligent

5
00:00:25,960 --> 00:00:26,960
12-year-old.

6
00:00:26,960 --> 00:00:31,560
In the same way I would explain it to anyone else, in fact, a 12-year-old will probably

7
00:00:31,560 --> 00:00:37,480
get it very quickly. Even a 12-year-old has been around long enough to see the exponential

8
00:00:37,480 --> 00:00:43,960
growth of information technology, the accelerating pace of change. I mean, only a few years ago,

9
00:00:43,960 --> 00:00:48,760
maybe when this 12-year-old started using computers, we really didn't use wikis or blogs

10
00:00:48,760 --> 00:00:56,400
or social networks. We didn't use tweets a few hours ago. That's a small exaggeration.

11
00:00:56,400 --> 00:01:00,520
Right back a decade, maybe it's before the 12-year-old's time, most people didn't use

12
00:01:00,520 --> 00:01:07,040
search engines. That sounds like ancient history. That's less than a decade ago. The pace of

13
00:01:07,040 --> 00:01:13,480
change is getting faster and faster. The first changes, paradigm shifts, stone tools, fire,

14
00:01:13,480 --> 00:01:18,280
the wheel, took tens of thousands of years. The printing press took two centuries. The

15
00:01:18,280 --> 00:01:22,840
telephone only took half a century to reach a quarter of the population, and now we have

16
00:01:22,840 --> 00:01:28,720
major paradigm shifts in just a few years' time. That's the nature of an evolutionary

17
00:01:28,720 --> 00:01:34,560
process. Technology is an evolutionary process. It's survival of the fittest, just like biological

18
00:01:34,560 --> 00:01:40,640
evolution. Biological evolution or technological evolution will evolve a capability and then

19
00:01:40,640 --> 00:01:46,280
adopt that capability and use it to evolve the next stage. That's why the next stage

20
00:01:46,280 --> 00:01:53,520
goes more quickly. It builds on the shoulders of the previous generation and this exponential

21
00:01:53,520 --> 00:02:00,520
growth and the capability of these technologies. If you measure the power of these technologies,

22
00:02:00,520 --> 00:02:05,680
let's say per dollar, the amount of computation you get, the number of MIPS per dollar, or

23
00:02:05,680 --> 00:02:09,960
the number of bits that you can buy per dollar, or the number of bits you move around on the

24
00:02:09,960 --> 00:02:14,480
internet, or the number of bits of brain data we're getting, or the number of base pairs

25
00:02:14,520 --> 00:02:19,360
of DNA that we're sequencing in a year, the cost of sequencing a base pair of DNA, these

26
00:02:19,360 --> 00:02:26,680
fundamental measures of information technology grow in an exponential manner. Now, maybe

27
00:02:26,680 --> 00:02:33,680
a 12-year-old hasn't become familiar with exponential numbers, but if I count 30, if

28
00:02:33,680 --> 00:02:43,680
I take 30 steps linearly, I go 1, 2, 3, 4, 5, 30 steps later I'm at 30. If I count exponentially,

29
00:02:43,680 --> 00:02:50,680
I double each time, 2, 4, 8, 16, 30 steps later I'm at a billion. It ultimately explodes.

30
00:02:51,040 --> 00:02:55,400
We start out doubling little numbers, but finally we're doubling big numbers and there's a huge

31
00:02:55,400 --> 00:03:01,200
difference between the linear perspective and the exponential perspective. It's the nature

32
00:03:01,200 --> 00:03:07,240
of human intelligence. Basically, if you ask what is intelligence, intelligence makes predictions

33
00:03:07,240 --> 00:03:13,320
about the future, so we are constantly anticipating what will happen next. But our intuition,

34
00:03:13,360 --> 00:03:19,560
what's hardwired in our brains is a linear prediction about the future. When we walked

35
00:03:19,560 --> 00:03:23,480
through the fields a thousand years ago, we saw something coming at us through the corner

36
00:03:23,480 --> 00:03:27,840
of our eye. We made a linear prediction where that animal would be and what to do about it,

37
00:03:27,840 --> 00:03:33,360
and that's hardwired, and that works quite well. But it doesn't work well in anticipating

38
00:03:33,360 --> 00:03:39,360
the nature of information technology. So even sophisticated scientists will use their intuition,

39
00:03:39,400 --> 00:03:45,760
which is linear, to think about where technology will be in 5, 10, 20 years. But the true nature

40
00:03:45,760 --> 00:03:50,800
of it is exponential, and that's why people's imagination fails them when they think about

41
00:03:50,800 --> 00:03:56,440
the future. When I was a student at MIT, we all shared a computer, took up half a building,

42
00:03:56,440 --> 00:04:00,880
it's an IBM 7094, maybe it's here, it costs tens of millions of dollars. The computer in

43
00:04:00,880 --> 00:04:06,520
your cell phone today is a million times cheaper and a thousand times more powerful. That's

44
00:04:06,600 --> 00:04:12,600
a billion fold increase in the amount of computation you get per dollar since I was a student, and

45
00:04:12,600 --> 00:04:19,600
we'll do it again in the next 25 years. So this is a very revolutionary characteristic

46
00:04:19,600 --> 00:04:25,960
of information technology, and it's not just Moore's Law. Moore's Law talks about shrinking

47
00:04:25,960 --> 00:04:31,040
the size of components on an integrated circuit. Moore's Law is just one of these paradigms.

48
00:04:31,040 --> 00:04:36,440
It was not the first paradigm to bring exponential growth to computing. We had four paradigm

49
00:04:36,920 --> 00:04:42,240
Moore's Law. The exponential growth of computing goes back decades before Gordon Moore was

50
00:04:42,240 --> 00:04:47,840
even born. I put lots of computers going back to the 1890 American census, the first census

51
00:04:47,840 --> 00:04:53,480
to be automated with electromechanical equipment, on a logarithmic graph, and there's a smooth

52
00:04:53,480 --> 00:05:00,480
progression for 110 years. We've made trillions fold increase in the amount of computation

53
00:05:01,480 --> 00:05:06,400
you can buy per dollar over the last century, and it was not affected by any of the things

54
00:05:06,440 --> 00:05:11,360
that happened. You don't see any evidence of impact of the Great Depression, World War

55
00:05:11,360 --> 00:05:17,360
I or II or the Cold War. There's just this inexorable progression in the power of computers.

56
00:05:17,360 --> 00:05:22,120
At the same time, we've shrunk them to be smaller at a rate of 100 and 3D volume per

57
00:05:22,120 --> 00:05:27,920
decade, and it's true not just of computers, but anything where you can measure the information

58
00:05:27,920 --> 00:05:33,120
content of a technology, and we can talk about some of the other aspects of information technology

59
00:05:33,160 --> 00:05:40,160
like our biology. This exponential growth is quite revolutionary. It's powerful as these

60
00:05:40,760 --> 00:05:46,240
computers are today and other forms of information technology. 25 years from now, there'll be

61
00:05:46,240 --> 00:05:53,080
a billion times more powerful again, and 100,000 times smaller, so you get some idea of what

62
00:05:53,080 --> 00:05:54,960
will be feasible.

63
00:05:54,960 --> 00:06:00,000
How has science fiction influenced your thinking, if at all?

64
00:06:01,000 --> 00:06:07,680
Well, I read the Tom Swift Junior series when I was eight, nine, and ten. That impressed

65
00:06:07,680 --> 00:06:14,680
upon me the idea that you can find ideas and inventions to overcome any problem. That was

66
00:06:14,680 --> 00:06:21,360
kind of the philosophy of my family. So the plot of every one of those novels was the

67
00:06:21,360 --> 00:06:28,360
same. Tom Swift Junior would get into some problem, and the fate of the human race hung

68
00:06:29,080 --> 00:06:36,080
in the balance. He would disappear into his basement, and the sort of tension of each

69
00:06:39,120 --> 00:06:44,480
novel was what idea would he come up with to save the day. And invariably, he'd come

70
00:06:44,480 --> 00:06:51,080
up with some very clever idea that you wouldn't have thought of that overcame the problem.

71
00:06:51,080 --> 00:06:56,480
And it did represent my own philosophy, which I got from my family, that no matter what kind

72
00:06:56,480 --> 00:07:01,960
of problem you encounter, there's a solution out there, and you can find it. And it was

73
00:07:01,960 --> 00:07:07,480
personalized. You, Ray, can find this solution, and you should look for it, and when you find

74
00:07:07,480 --> 00:07:12,480
it, you should implement it. And that's been kind of an imperative in my life.

75
00:07:12,480 --> 00:07:19,480
Great answer. Now, a lot of your life's activities have combined, excuse me, combined humans

76
00:07:20,680 --> 00:07:26,440
and technology. We can start with the EOCR, optical character recognition stuff, the synthesizers,

77
00:07:26,440 --> 00:07:33,400
now the singularity. Is that a life motif in your life that's combining and or enhancing

78
00:07:33,400 --> 00:07:40,400
the human condition? It actually goes back to a feeling I had when I was five. My parents

79
00:07:40,400 --> 00:07:45,160
gave me all these record sets and construction toys, and I had this idea, if you put things

80
00:07:45,160 --> 00:07:49,720
together in just the right way, you could create transcendent effects. I did not have

81
00:07:49,720 --> 00:07:54,080
that vocabulary, but I do remember the feeling as a five-year-old, that, wow, I can put these

82
00:07:54,120 --> 00:08:01,280
things together and do something magical that would overcome human problems. And I decided

83
00:08:01,280 --> 00:08:07,940
I would be an inventor, and I remember having that idea, and I did have that much vocabulary.

84
00:08:07,940 --> 00:08:11,080
And other kids were wondering what they would be, and I always had this conceit, I know

85
00:08:11,080 --> 00:08:17,040
what I'm going to be. And my invention started to get some traction when I was seven or eight.

86
00:08:17,040 --> 00:08:21,560
I created a puppet theater. There was kind of a virtual reality world, and I had a command

87
00:08:21,560 --> 00:08:26,440
station, and I could move the sun and the stars and characters on and off the stage

88
00:08:26,440 --> 00:08:32,360
with these mechanical linkages, and I could control the small universe from my command

89
00:08:32,360 --> 00:08:38,400
station. I discovered the computer when I was twelve, and I had the feeling then that you

90
00:08:38,400 --> 00:08:43,280
could recreate reality in the computer. You could create virtual realities, you could

91
00:08:43,280 --> 00:08:50,280
recreate aspects of our thinking, and that sort of animated me starting when I was twelve,

92
00:08:51,000 --> 00:08:58,000
I had access to some early 1401s and IBM 1620s back starting in 1960, and I also built

93
00:08:58,480 --> 00:09:03,840
some of my own computerized devices. And I had this idea that really the heart of human

94
00:09:03,840 --> 00:09:09,120
intelligence was our ability to recognize patterns, and very much the history now of

95
00:09:09,120 --> 00:09:15,160
neuroscience confirms that. That is what human beings do very well. We're very good at looking

96
00:09:15,160 --> 00:09:20,040
at a chessboard and seeing a pattern. We're not very good at doing the logical mini-max

97
00:09:20,040 --> 00:09:26,240
algorithm in our head. Kasparov was asked, how many moves ahead do you look per second

98
00:09:26,240 --> 00:09:32,080
when Deep Blue could analyze 300 million board positions in this recursive expanding tree

99
00:09:32,080 --> 00:09:39,080
of move, counter move possibilities? Deep Blue could do 300 million. How many do you

100
00:09:39,160 --> 00:09:45,200
do, Mr. Kasparov? And he said less than one. So how is it that he can hold a candle to

101
00:09:45,200 --> 00:09:49,400
a computer? Well, he's got a deep power as a pattern recognition. That is the heart of

102
00:09:49,400 --> 00:09:53,440
human intelligence. By the way, computers are much better now at the pattern recognition

103
00:09:53,440 --> 00:09:59,680
aspect. So even with one percent of the computation of Deep Blue, they can do even better than

104
00:09:59,680 --> 00:10:06,520
Deep Blue did, because we've mastered pattern recognition more than we have in the past.

105
00:10:06,520 --> 00:10:11,280
Pattern recognition is still not as good as humans, but it's getting better and better,

106
00:10:11,280 --> 00:10:16,720
and that is the heart of what human beings do. And I had this sense really starting when

107
00:10:16,720 --> 00:10:22,920
I was 12. When I was 14, I did a project to analyze melodies, to look for the patterns

108
00:10:22,920 --> 00:10:28,080
that a composer would use, and I would feed in Chopin or Mozart, and I had ways of finding

109
00:10:28,080 --> 00:10:34,040
the patterns, and then composing original music using the same patterns. And indeed,

110
00:10:34,080 --> 00:10:38,960
it would sound like a student, maybe a third grade student of Chopin or Mozart, depending

111
00:10:38,960 --> 00:10:45,080
on who I had analyzed. And that was my first pattern recognition project. It won some prizes

112
00:10:45,080 --> 00:10:48,960
like the Westinghouse Science Talent Search. I was one of the finalists that got to meet

113
00:10:48,960 --> 00:10:56,200
President Johnson, and that was my first pattern recognition project. My first major commercial

114
00:10:56,200 --> 00:11:02,640
project in pattern recognition was OmniFont Optical Character Recognition. And that really

115
00:11:02,680 --> 00:11:07,440
dealt with the key issue of finding invariant features and patterns, because that's what

116
00:11:07,440 --> 00:11:13,960
pattern recognition does, particularly at the human level. We're able to look at a face and

117
00:11:13,960 --> 00:11:20,720
we're able to recognize the invariant features. No matter how the face is pointed, even if it's

118
00:11:20,720 --> 00:11:29,360
occluded, even if it's represented through a distorted lens, we can find the invariant features.

119
00:11:29,400 --> 00:11:33,480
We can find the invariant features of speech, no matter who's speaking, even if the accent is

120
00:11:33,480 --> 00:11:40,160
different, and even if it's a different shaped vocal tract and so on. So we're very good at

121
00:11:40,160 --> 00:11:49,080
recognizing patterns, even if there are changes in the information. And so that's what we did

122
00:11:49,080 --> 00:11:55,760
with character recognition. We were able to recognize that a shape, let's say, that we would

123
00:11:55,760 --> 00:12:01,160
recognize as a capital A, had a concave region facing south, and it had a triangular looped

124
00:12:01,160 --> 00:12:07,240
portion in the northern region, and it had a north central to southeast and southwest connection

125
00:12:07,240 --> 00:12:12,160
and a crossbar between them. These are the invariant features of a capital A, no matter what

126
00:12:12,160 --> 00:12:19,000
type style you use. And we were able to successfully do that. That became kind of a solution in

127
00:12:19,000 --> 00:12:24,480
search of a problem. I sat next to a blind guy in a plane, and he was telling me how he had

128
00:12:24,480 --> 00:12:30,600
difficulty accessing ordinary printed material. But otherwise, Linus was not a handicap, he said,

129
00:12:30,600 --> 00:12:37,920
but he did have this one issue. And so we devoted the omnifine character recognition to the reading

130
00:12:37,920 --> 00:12:43,400
problem of the blind. And we had to develop a couple other technologies, Texas speech synthesis

131
00:12:43,400 --> 00:12:49,400
and a CCD telepath scanner. We developed those and created the first printed speech reading

132
00:12:49,440 --> 00:12:55,280
machine for the blind. Later on, I got involved with speech recognition, which is an even

133
00:12:55,280 --> 00:13:02,200
more complex panel recognition problem. Because if you look at a spectrogram, a picture of

134
00:13:02,200 --> 00:13:05,720
speech of two different people saying the same word, it can look completely different,

135
00:13:05,720 --> 00:13:10,480
yet there must be some invariant features there that allows human intelligence to recognize

136
00:13:10,480 --> 00:13:14,840
it as the same word. Even the same person saying the same word at different times will

137
00:13:14,880 --> 00:13:21,240
look very different. So we developed technology that could handle that, and that got involved

138
00:13:21,240 --> 00:13:26,000
with looking for patterns in human language, which is really the heart of human intelligence.

139
00:13:26,000 --> 00:13:31,880
Alan Turing based the Turing test on language recognizing that language and its hierarchical

140
00:13:31,880 --> 00:13:38,080
nature reflects the hierarchical nature of our intelligence. That's what's really unique

141
00:13:38,080 --> 00:13:44,360
about humans is that we have this neocortex that can understand and deal with hierarchies

142
00:13:44,360 --> 00:13:49,200
of patterns to reflect the hierarchies of patterns that exist in the natural world.

143
00:13:49,200 --> 00:13:56,200
That's great. Could you tell us a bit about your synthesizers and how you came across?

144
00:13:59,560 --> 00:14:05,400
That seems like quite a bit of an outlier, and yet you were very successful at that.

145
00:14:05,400 --> 00:14:11,000
Well, the music synthesizer is an output rather than an input technology, but it's also based

146
00:14:11,040 --> 00:14:15,760
on pattern recognition to really examine the question, what makes a piano sound like a

147
00:14:15,760 --> 00:14:22,200
piano? What patterns of sound enable a piano to do that? So we actually had a model of

148
00:14:22,200 --> 00:14:26,920
how a piano produces sound. We combined that with sampling technology, but sampling by

149
00:14:26,920 --> 00:14:33,720
itself was not adequate to solve the problem because you don't have enough memory to accurately

150
00:14:33,720 --> 00:14:39,880
record every possible sound and how they interact with each other in a piano. So we would model

151
00:14:40,000 --> 00:14:47,000
the signal processing and pattern generation capabilities of a piano to be able to recreate

152
00:14:47,000 --> 00:14:53,400
that realistically and also understand what the human auditory perceptual system does

153
00:14:53,400 --> 00:14:58,440
because it can be fooled by certain things, whereas in other ways it's extremely sensitive

154
00:14:58,440 --> 00:15:04,720
to the slightest variations, but some things it's not able to recognize very well. So understanding

155
00:15:04,760 --> 00:15:10,600
what its strength and weaknesses are, we could recreate the piano with enough accuracy in

156
00:15:10,600 --> 00:15:17,600
the ways in which the human auditory perceptual system was accurate. I got into that really

157
00:15:18,200 --> 00:15:22,640
through the Reading Machine project, and Stevie Wonder was our first customer. He heard me

158
00:15:22,640 --> 00:15:29,240
present the Reading Machine in 1976 on the Today Show. He called us up out of the blue.

159
00:15:29,280 --> 00:15:35,800
Our receptionist didn't really think it was him, but he did come over, and we happened

160
00:15:35,800 --> 00:15:43,080
to just finish our first Reading Machine that we could actually part with, and he left with

161
00:15:43,080 --> 00:15:50,080
it after we showed him how to use it. That was 1976, and that started what is now a 33-year

162
00:15:52,080 --> 00:15:58,280
friendship. A few years later, in 1982, he was giving me a tour of his studio, which he

163
00:15:58,280 --> 00:16:03,640
called Wonderland, and he was lamenting the state of the art in musical instruments. On

164
00:16:03,640 --> 00:16:07,520
the one hand, there were these 19th century acoustic instruments, which were still the

165
00:16:07,520 --> 00:16:13,480
instruments of choice in terms of creating very beautiful, rich sounds. From a panel

166
00:16:13,480 --> 00:16:17,880
recognition signal processing point of view, we would say they're very complex sounds.

167
00:16:17,880 --> 00:16:22,640
On the other hand, there were these electronic sounds that a computer could generate. They

168
00:16:22,680 --> 00:16:29,200
were very thin, relatively simple, but you could control them much better. Acoustic instruments,

169
00:16:29,200 --> 00:16:32,960
even if you're a virtuoso, you can't play every instrument, and even if you could play

170
00:16:32,960 --> 00:16:36,720
every instrument, you can't play them at the same time. Most of them, you can only play

171
00:16:36,720 --> 00:16:42,360
one note at a time. You can't sit down and play an orchestra. With these electronic instruments

172
00:16:42,360 --> 00:16:47,640
at that time, in the early 80s, you could play a line of music. The computer would remember

173
00:16:47,640 --> 00:16:52,080
it. You could play it back, and then you could play another line over it. You could actually

174
00:16:52,120 --> 00:16:57,120
erase notes and replay them, just like you would edit a letter on a word processor. You

175
00:16:57,120 --> 00:17:02,400
had much better control methods. You could play a whole orchestra or rock band on your

176
00:17:02,400 --> 00:17:07,680
computer, but the sounds that you had to use that were available at that time were very

177
00:17:07,680 --> 00:17:12,280
thin. When you selected piano, it sounded like an organ. When you selected violin, it

178
00:17:12,280 --> 00:17:17,120
sounded like an organ. You said, wouldn't it be great if we could really command these

179
00:17:17,160 --> 00:17:22,680
very rich, beautiful, complex sounds of acoustic instruments with these very powerful control

180
00:17:22,680 --> 00:17:28,960
methods of the computer world? I felt that would be feasible using some principles of

181
00:17:28,960 --> 00:17:35,720
signal processing and pattern recognition combined with the sampling world. We started

182
00:17:35,720 --> 00:17:42,000
Kurzweil Music together. He was part of our company, as a musical advisor, to guide the

183
00:17:42,040 --> 00:17:47,600
development. We worked together. Two years later, we introduced the Kurzweil 250, which

184
00:17:47,600 --> 00:17:52,600
has been recognized as the first electronic instrument that accurately could recreate

185
00:17:52,600 --> 00:17:59,600
the grand piano and other orchestral instruments. Shifting a little bit towards the future

186
00:17:59,760 --> 00:18:06,760
and your vision of a couple of things. One is, I think, in the year 2039, we achieved

187
00:18:07,440 --> 00:18:13,880
parity with our computers that achieved parity in 2029. Computers become as intelligent for

188
00:18:13,880 --> 00:18:20,880
some definition of intelligence as humans. Then later in 2050, I believe, they actually

189
00:18:21,720 --> 00:18:28,080
can be merged through nanotechnology or other technologies with humans ourselves and augment

190
00:18:28,080 --> 00:18:35,080
us. There's a lot in that question, but could you maybe lay it out for us a bit?

191
00:18:35,680 --> 00:18:41,240
The first thing that's important to recognize is that computers are growing exponentially

192
00:18:41,240 --> 00:18:48,240
in power. They're doubling in less than a year for the same cost. That's actually a

193
00:18:48,840 --> 00:18:53,840
trajectory that's been going on for 110 years. We'll continue it and we'll continue

194
00:18:53,840 --> 00:18:58,840
past Moore's Law. Moore's Law was not the first paradigm to bring exponential growth

195
00:18:58,840 --> 00:19:03,520
through computing. It was the fifth paradigm. The exponential growth of computing started

196
00:19:03,520 --> 00:19:08,440
decades before Gordon Moore was born. We had electromechanical calculators, really

197
00:19:08,440 --> 00:19:13,360
based computers such as Alan Turing's machine, which cracked the German enigma code. We

198
00:19:13,360 --> 00:19:18,680
had vacuum tube-based computers in the 1950s. CBS predicted the election of Eisenhower

199
00:19:18,680 --> 00:19:24,080
in 1952 with a vacuum tube-based computer. Then there were shrinking vacuum tubes every

200
00:19:24,080 --> 00:19:29,240
year making them smaller and smaller to keep this exponential growth going. That finally

201
00:19:29,240 --> 00:19:33,480
hit a wall. They got to a point where they couldn't shrink the vacuum tubes anymore and

202
00:19:33,480 --> 00:19:38,760
keep the vacuum. That was the end of the shrinking of vacuum tubes. It was not the end of the

203
00:19:38,760 --> 00:19:45,160
exponential growth of computing. We went to the fourth paradigm, transistors, and finally

204
00:19:45,160 --> 00:19:49,640
integrated circuits and Moore's Law and the shrinking of component sizes on an integrated

205
00:19:49,640 --> 00:19:55,080
circuit. As paradigms go, that's been a great paradigm, but it is not the sum total of this

206
00:19:55,080 --> 00:20:02,000
exponential growth of computing. It will come to an end by around 2020. The key feature

207
00:20:02,040 --> 00:20:06,560
sizes then will be on the order of 4 nanometers, which is about 20 carbon atoms, and we won't

208
00:20:06,560 --> 00:20:11,680
be able to shrink them anymore. But we'll then go to the sixth paradigm, which is three-dimensional

209
00:20:11,680 --> 00:20:17,760
molecular computing, self-organizing circuits. I talked about this in my 1999 book, The Age

210
00:20:17,760 --> 00:20:22,760
of Spiritual Machines. At that time, it was considered a very controversial notion. It's

211
00:20:22,760 --> 00:20:28,040
now a very mainstream notion. If you speak to the scientists at Intel, such as Justin

212
00:20:28,080 --> 00:20:34,040
Rottener, their CTO, he will tell you they have these kinds of circuits working in experimental

213
00:20:34,040 --> 00:20:39,560
form. They feel the crossover will be in the teen years, well before we run out of steam

214
00:20:39,560 --> 00:20:45,040
with flat integrated circuits. That will keep this exponential growth going for a long time.

215
00:20:45,040 --> 00:20:52,040
By 2019, $1,000 of computation will be equal to the most conservative estimates of the amount

216
00:20:52,880 --> 00:20:58,360
of computation we need to simulate the entire human brain, which I estimated about 10 to

217
00:20:58,360 --> 00:21:05,360
the 16th 10 million billion calculations per second. We'll achieve that for $1,000 by 2019,

218
00:21:08,240 --> 00:21:15,000
even using conventional silicon without even going to the next paradigm. That's the hardware

219
00:21:15,000 --> 00:21:19,200
side of the equation. I think that's pretty non-controversial. The more interesting issue

220
00:21:19,240 --> 00:21:26,000
is, will we have the software? We've made a lot of progress in artificial intelligence

221
00:21:26,000 --> 00:21:30,160
without looking inside the human brain. In fact, up until recently, we really could not

222
00:21:30,160 --> 00:21:35,560
look inside the human brain with enough precision to figure out what was going on. These colorful

223
00:21:35,560 --> 00:21:41,400
fMRI images would tell you where things are going on if you're solving a logic puzzle

224
00:21:41,400 --> 00:21:46,360
or looking at visual information. There's something going on here or there, but that

225
00:21:46,680 --> 00:21:53,600
doesn't give you enough precision to see what's going on. The spatial resolution of

226
00:21:53,600 --> 00:21:58,040
brain scanning has been doubling every year. The amount of data we're getting is doubling

227
00:21:58,040 --> 00:22:02,600
every year. We can model individual neurons. We're getting more and more information. We're

228
00:22:02,600 --> 00:22:07,280
showing that we can turn this information into working models in simulations of brain

229
00:22:07,280 --> 00:22:12,240
regions. There's already about 20 regions of the brain that have been modeled and simulated

230
00:22:12,600 --> 00:22:17,040
regions of the auditory cortex, the visual cortex, the cerebellum where we do our skill

231
00:22:17,040 --> 00:22:24,040
formation like catching a fly ball. We have figured out how that works. Even slices now

232
00:22:24,200 --> 00:22:30,800
of the cerebral cortex, which is the most important region. We've recently simulated

233
00:22:30,800 --> 00:22:36,640
substantial slices of the cerebral cortex where we do our logical thinking, our hierarchical

234
00:22:36,680 --> 00:22:42,200
thinking, our invariant feature detection for pattern recognition. That's really the

235
00:22:42,200 --> 00:22:47,520
heart of human intelligence. We're beginning to understand how that works. I make the case

236
00:22:47,520 --> 00:22:52,200
in my book Singularity is Near that we will have all the models and simulations of the

237
00:22:52,200 --> 00:22:59,200
human brain within 20 years. By 2029, we will understand enough about the human brain to

238
00:22:59,200 --> 00:23:04,880
recreate its fundamental methods, its algorithms. The computers at that time will be far more

239
00:23:04,880 --> 00:23:10,200
powerful than is necessary to simulate the human brain. I've been very consistent about

240
00:23:10,200 --> 00:23:16,960
the date 2029 when we will have both the hardware and the software to simulate human intelligence.

241
00:23:16,960 --> 00:23:23,960
We already have hundreds of examples of software, AI software, in use in our economic infrastructure

242
00:23:24,160 --> 00:23:29,160
that does things that used to require human intelligence. Every time you send an email

243
00:23:29,160 --> 00:23:33,960
or connect a cell phone call intelligent algorithm through the information, pick up any product

244
00:23:34,000 --> 00:23:38,400
that was designed in part with intelligent computer-assisted design, manufacturing and

245
00:23:38,400 --> 00:23:43,640
robotic factories, inventory levels controlled by just-in-time inventory, systems that are

246
00:23:43,640 --> 00:23:49,800
intelligent, automatic detection of credit card fraud, lots of financial decisions made

247
00:23:49,800 --> 00:23:55,280
by computers. Again, an electrocardiogram that comes back with an intelligent analysis

248
00:23:55,280 --> 00:24:00,520
by computers that rivals that of doctors, same for blood cell images, intelligent algorithms

249
00:24:00,560 --> 00:24:06,000
flying land airplanes, guide intelligent weapons systems. These systems are doing what

250
00:24:06,000 --> 00:24:11,600
used to require human intelligence and very often doing them better than humans consistently,

251
00:24:11,600 --> 00:24:18,600
very inexpensively. These were actually research projects not so long ago, 10, 15 years ago.

252
00:24:18,600 --> 00:24:22,920
If all the AI in the world stopped tomorrow, our whole civilization would have grown to

253
00:24:22,920 --> 00:24:29,720
a halt. That was not the case 15 years ago. These are narrow examples of AI. We call them

254
00:24:29,720 --> 00:24:36,520
narrow AI because they're doing some particular task, playing chess or analyzing an electrocardiogram

255
00:24:36,520 --> 00:24:42,640
and otherwise they don't have the suppleness and subtlety and flexibility of human intelligence.

256
00:24:42,640 --> 00:24:47,400
But the narrowness is gradually getting less narrow as we're learning more about how the

257
00:24:47,400 --> 00:24:52,680
best example of human intelligence works, which is the human brain itself. It's not hidden

258
00:24:52,680 --> 00:24:57,880
from us. That's another exponential progression. I've been very consistent about the state

259
00:24:57,960 --> 00:25:05,800
2029. It goes back through several of my books that by that date we will have machines that

260
00:25:05,800 --> 00:25:12,440
operated at the human level in terms of the entire flexibility of human intelligence. One way to

261
00:25:12,440 --> 00:25:19,080
measure that is with the Turing test, which I think has held up very well. Turing described this

262
00:25:19,080 --> 00:25:36,520
50 years ago, Alan Turing described a test whereby a human judge would interview a computer,

263
00:25:36,520 --> 00:25:43,800
an AI, and a human, a human foil over what he called teletype lines, basically instant messaging. So

264
00:25:43,800 --> 00:25:49,480
the human judge would not see who he or she is interviewing. And if after a few hours he didn't

265
00:25:49,480 --> 00:25:54,920
actually specify the rules very well, but if after some period of time the human judge can't tell

266
00:25:54,920 --> 00:26:00,120
who's the machine and who's the human, we say that the machine has passed the Turing test.

267
00:26:00,920 --> 00:26:06,760
And no machine has yet passed the Turing test. There are Turing tests run every year.

268
00:26:07,480 --> 00:26:14,200
Loebner runs one series of tests. And the machines are getting better every year.

269
00:26:14,920 --> 00:26:20,680
According to Loebner, if a computer can fool the human judges 30% of the time,

270
00:26:21,640 --> 00:26:26,600
we will say that they have passed the test. And the last test they fooled the judges 25% of the

271
00:26:26,600 --> 00:26:32,120
time. Now I actually think that those rules are too easy, but I do feel within 20 years that

272
00:26:32,120 --> 00:26:39,560
that's probably conservative. Computers will pass valid forms of the Turing test. And then

273
00:26:39,560 --> 00:26:45,080
they will then combine what are now strengths of human intelligence, which is our tremendous

274
00:26:45,080 --> 00:26:51,560
ability to recognize patterns with ways in which machines are already superior. I mean, your cell

275
00:26:51,560 --> 00:26:59,080
phone can remember millions or billions of things accurately. Machines can find knowledge instantly

276
00:26:59,080 --> 00:27:04,520
out of billions of possibilities. They can do logical thinking much better than we can.

277
00:27:04,520 --> 00:27:11,400
Few mathematicians or no mathematicians can really hold up to Mathematica in terms of manipulating

278
00:27:11,400 --> 00:27:17,240
equations and solving theorems and this kind of thing. Machines are better than we are at logical

279
00:27:17,240 --> 00:27:22,440
thinking, remembering things, transferring knowledge. If a machine has a skill, it can transfer that

280
00:27:22,440 --> 00:27:27,080
skill and that knowledge and that information and that database at electronic speeds,

281
00:27:27,080 --> 00:27:31,960
which is a million times faster than the transmission, electrochemical transmission that

282
00:27:31,960 --> 00:27:37,160
goes on in our brains or the transmission from one person to another using language.

283
00:27:37,880 --> 00:27:44,200
So these are superiority today of machines. When we combine that with a machine that can actually

284
00:27:45,160 --> 00:27:51,400
match human intelligence in terms of our ability to recognize patterns, use language and understand it,

285
00:27:51,400 --> 00:27:56,920
that will be a very powerful combination. But it's not going to be a matter of us competing with

286
00:27:57,320 --> 00:28:03,960
these machines because this is not some alien invasion of intelligent machines from Mars. It's

287
00:28:03,960 --> 00:28:09,880
part of our human machine civilization. We've always built our machines to extend our own reach.

288
00:28:10,520 --> 00:28:15,000
I mean, ever since we picked up a stick to reach a higher branch, we've extended our physical

289
00:28:15,000 --> 00:28:21,000
reach with our machines, our tools. Now we already extend our mental reach. You know, I can take a

290
00:28:21,000 --> 00:28:25,000
device out of my pocket and access all of human knowledge with a few keystrokes. That makes me

291
00:28:25,000 --> 00:28:31,480
smarter. That extends my mental reach. Very few people can do their jobs today without these mental

292
00:28:31,480 --> 00:28:36,680
extenders represented by our computers and all the knowledge bases they command.

293
00:28:37,400 --> 00:28:41,640
And we are going to literally make ourselves smarter. We ultimately will put these machines

294
00:28:41,640 --> 00:28:46,840
inside our bodies and brains. They're already very close to us. When I was a student, I had to go

295
00:28:46,840 --> 00:28:51,960
across campus to get to the computer. Now it's in my pocket. It will make its way into our bodies

296
00:28:51,960 --> 00:28:57,000
and brains. And that started. You can put a computer in your brain today if you happen to be a

297
00:28:57,000 --> 00:29:03,160
Parkinson's patient or a deaf person. You can put computers in your brain that will replace

298
00:29:03,160 --> 00:29:11,160
the functionality that's been lost by disease or disability. And the latest generation of this

299
00:29:11,160 --> 00:29:15,240
FDA-approved Neural Implant for Parkinson's allows you to actually download

300
00:29:15,240 --> 00:29:18,280
new software to the computer inside your brain from outside the patient.

301
00:29:19,000 --> 00:29:24,680
Now today, that Neural Implant is not blood cell size. It's pea size. It's pretty small.

302
00:29:25,320 --> 00:29:30,600
But another exponential trend is we're shrinking technology. It's actually, according to my models,

303
00:29:30,600 --> 00:29:38,840
a rate of 100 per decade. So these technologies will be 100,000 times smaller in 25 years.

304
00:29:38,840 --> 00:29:45,400
In 25 years from now, they will be the size of a blood cell. So my vision is a few decades from

305
00:29:45,400 --> 00:29:51,080
now, we will have millions of these nanobots, nano-engineered blood cell size devices which

306
00:29:51,080 --> 00:29:56,120
have computers in them. They'll be going inside our bloodstream to keep us healthy from inside.

307
00:29:56,120 --> 00:30:01,240
They'll augment our immune system. They'll destroy disease when it's the level of a cell,

308
00:30:01,240 --> 00:30:05,640
rather than the level of an organ and it's life-threatening. They'll go into our brains

309
00:30:05,640 --> 00:30:10,920
through our capillaries. We'll have Neural Implants without surgery introduced non-invasively

310
00:30:10,920 --> 00:30:16,040
through the bloodstream. They'll interact not just with a few neurons, but with all of our

311
00:30:16,040 --> 00:30:21,240
neurons. We can have millions or billions of them. They'll put our brains on the internet.

312
00:30:21,240 --> 00:30:27,320
They'll provide a highly realistic full immersion virtual reality, incorporating all the senses

313
00:30:27,880 --> 00:30:33,720
from within the nervous system. And most importantly, they will extend our intelligence,

314
00:30:33,720 --> 00:30:40,280
which they do today, even if they're just in our pockets and in our hands, we can access

315
00:30:40,360 --> 00:30:45,560
all of knowledge easily. That makes us smarter, but a convenient place to put them, particularly

316
00:30:45,560 --> 00:30:50,360
when the size of blood cells will be in our brains. We won't lose them that way.

317
00:30:51,080 --> 00:30:55,720
They'll have an opportunity to more intimately integrate with our intelligence and they will

318
00:30:55,720 --> 00:31:00,920
make us smarter. That is what our technology has always done, and it's getting closer and closer

319
00:31:01,000 --> 00:31:06,680
to us and more and more intimate. Is thinking then a form of calculation?

320
00:31:10,360 --> 00:31:16,200
In some ways, the brain has a very different architecture from conventional computers. A

321
00:31:16,200 --> 00:31:20,920
conventional von Neumann machine is very, very fast, but it does one thing at a time.

322
00:31:21,560 --> 00:31:25,560
We've taken some baby steps in parallel processing, and you might have a chip now that has four

323
00:31:26,120 --> 00:31:32,280
cores or 16 cores, and so there's 16 things at a time very quickly. The brain is massively

324
00:31:32,280 --> 00:31:37,960
parallel, really 100 trillion fold, because the calculations take place in the interneuronal

325
00:31:37,960 --> 00:31:48,280
connections in the dendrites and the synaptic clefs between neurons, and we have 100 trillion of them.

326
00:31:48,280 --> 00:31:54,920
But they're very slow. They calculate about 200 calculations per second. That's maybe 10 million

327
00:31:54,920 --> 00:32:00,840
times slower than computers today, and we can build machines that have this massively parallel

328
00:32:00,840 --> 00:32:06,840
architecture, or we can simulate it. We really just need to achieve the computational level.

329
00:32:07,720 --> 00:32:13,000
It's an engineering detail as to how parallel we make the computers, because they can simulate

330
00:32:13,720 --> 00:32:18,760
what goes on inside the human brain. But if you talk about what goes on in a neuron,

331
00:32:18,760 --> 00:32:26,920
it is computable, and particularly when we understand the salient information features,

332
00:32:26,920 --> 00:32:33,800
we don't have to simulate all of the life support functions of a neuron because we're really building

333
00:32:33,800 --> 00:32:41,000
it through a different infrastructure, a different substrate, and we've already figured out what

334
00:32:41,000 --> 00:32:47,880
the salient algorithms are for certain regions of the brain. The auditory cortex does certain types

335
00:32:47,880 --> 00:32:55,240
of transformations to auditory information, and we really don't have to simulate exactly how a neuron

336
00:32:55,240 --> 00:32:59,960
does that if we understand what the neurons are doing from an information processing point of

337
00:32:59,960 --> 00:33:06,280
view. So we've already done that for some parts of the brain, and the most important part of the

338
00:33:06,280 --> 00:33:11,960
brain is the neocortex. That's where we do this hierarchical thinking that results in language

339
00:33:11,960 --> 00:33:17,640
and results in ability to create tools and to understand the world, which is naturally hierarchical

340
00:33:18,440 --> 00:33:24,600
as well. And that's what's unique about human beings is that we can do that. Only mammals have

341
00:33:24,600 --> 00:33:31,240
a neocortex, and our neocortex, which is about the size of a table napkin, is the biggest.

342
00:33:32,120 --> 00:33:38,600
But it's still limited. Why not have a neocortex that's much bigger than a table napkin? Well,

343
00:33:38,600 --> 00:33:45,560
we'll be able to extend those limitations by being able to add computation, and that computation in

344
00:33:45,560 --> 00:33:50,120
our brains can then be on the internet and can access the vast amount of computing that will

345
00:33:50,120 --> 00:33:56,200
exist in the cloud, which is already formulating. So we will be doing some of our thinking out on the

346
00:33:56,200 --> 00:34:02,200
cloud. You know, once we have computation inside our brains, that'll be on the internet, and then

347
00:34:02,200 --> 00:34:07,160
just like any computer, it will be extending, multiplying its ability by thinking out on the

348
00:34:07,160 --> 00:34:14,840
cloud. That's where our future lies. But yes, what the brain does is it processes information.

349
00:34:14,840 --> 00:34:19,400
There's some architectural differences with computers. But it's the nature of software that

350
00:34:19,400 --> 00:34:24,520
you can write software that will simulate a different architecture. As long as we have enough

351
00:34:25,640 --> 00:34:31,080
brute force, we'll have the ability to simulate what goes on in the human brain provider. We know

352
00:34:31,080 --> 00:34:36,680
what goes on there. So we also need the software. We need the algorithmic insights. But we're making

353
00:34:36,680 --> 00:34:42,040
exponential gains in that as well. And then we'll need a third component, which is education,

354
00:34:42,680 --> 00:34:47,560
because you can take a human brain, which has hardware and software, you know, which is

355
00:34:48,200 --> 00:34:54,120
integrated together in the human brain. But it doesn't do much unless you educate it.

356
00:34:55,000 --> 00:35:00,840
And that's in fact a complex process. A lot of knowledge goes into the education of human beings.

357
00:35:00,840 --> 00:35:07,960
In fact, we've had thousands of years of culture to develop the means of educating the brain and

358
00:35:08,040 --> 00:35:15,480
accessing all of the learning that goes on at all of our history and literature. And the human

359
00:35:15,480 --> 00:35:22,280
brain can access that. But all of that is out there. It's all on the Internet. These AIs will

360
00:35:22,280 --> 00:35:29,400
be able to be educated with all of human knowledge readily accessible. But we'll actually have to

361
00:35:29,400 --> 00:35:34,200
design that learning program, just as we do for human intelligence.

362
00:35:34,440 --> 00:35:39,880
Should we be hopeful or a little concerned about these developments?

363
00:35:41,320 --> 00:35:41,800
Or both?

364
00:35:46,760 --> 00:35:53,560
I'm not blasé about the dangers of technology. Technology has been a double-edged sword ever

365
00:35:53,560 --> 00:35:59,880
since we had tools. Our very first tools, fire, stone tools, the wheel, were used for

366
00:35:59,880 --> 00:36:05,400
both creativity and destructiveness. They've always amplified our ability to be destructive

367
00:36:05,400 --> 00:36:11,320
in war and conflict. And certainly we've seen a lot of destructiveness come from our tools. I

368
00:36:11,320 --> 00:36:16,840
would argue that we've been helped more than we've been hurt. People forget what life was like. If

369
00:36:16,840 --> 00:36:22,600
you read Thomas Hobbes, he's described life a few hundred years ago quite well. It's short.

370
00:36:23,240 --> 00:36:30,120
Human life expectancy was 37 in 1800. Brutish, disaster-prone, labor-filled. It took six hours

371
00:36:30,120 --> 00:36:36,760
to create the evening meal. There were no social safety nets. Most people lived on the brink of

372
00:36:36,760 --> 00:36:42,840
disaster and disease-filled. We had no sanitation, no antibiotics. And life was very, very hard

373
00:36:42,840 --> 00:36:50,920
just 200 years ago. Human life expectancy was 48 in 1900. We've come a long way in overcoming

374
00:36:51,000 --> 00:36:56,600
human suffering. We still have a lot of suffering to go. But technology is a double-edged sword.

375
00:36:57,240 --> 00:37:03,720
We've created enough nuclear weapons to destroy all human life, all mammalian life. So that's

376
00:37:05,480 --> 00:37:13,080
certainly a downside to technology. AI, strong AI, AI at the human levels and beyond,

377
00:37:13,080 --> 00:37:19,000
will be the most powerful technology that we'll ever create. It will have the power to

378
00:37:19,880 --> 00:37:26,760
destroy us if we don't build our own moral and ethical values into it. So there's a lot of

379
00:37:26,760 --> 00:37:36,760
discussion in the AI field on how to build what Yatkowski calls friendly AI versus unfriendly AI.

380
00:37:38,520 --> 00:37:43,000
Certainly, if you're in a situation where there's some AI and it's much more intelligent than you

381
00:37:43,000 --> 00:37:47,320
are and it's bent on your destruction, that's not a good situation to be in. We have to

382
00:37:47,320 --> 00:37:51,640
basically avoid getting in that situation in the first place. The only thing that could protect

383
00:37:51,640 --> 00:38:01,080
you from that would be an AI that's even smarter, that's on your side. And we really need to integrate

384
00:38:01,080 --> 00:38:09,320
with this technology. It's not my view of it that it's a civilization apart that we have to combat.

385
00:38:10,200 --> 00:38:17,960
The sort of scenario deployed in many science features and movies of man versus machine I think

386
00:38:17,960 --> 00:38:23,320
is unrealistic because we're going to be very integrated with our technology. We can see conflict

387
00:38:23,320 --> 00:38:32,120
today between different groups of humans and their machines. And the technology amplifies

388
00:38:33,080 --> 00:38:39,480
the destructive capability of both sides. But that could be a frightening scenario as well

389
00:38:40,280 --> 00:38:46,920
because we do amplify our destructiveness with our machines. So it's a complex issue. I do take

390
00:38:46,920 --> 00:38:51,800
some hope from the fact that I think the decentralized nature of these new technologies,

391
00:38:51,800 --> 00:38:57,400
like the internet, is inherently democratizing. I wrote in my first book, The Age of Intelligent

392
00:38:57,400 --> 00:39:03,960
Machines, which I wrote in the 80s when the Soviet Union was going strong, that the Soviet Union

393
00:39:03,960 --> 00:39:09,240
would be swept away by the then emerging decentralized electronic communication. We

394
00:39:09,240 --> 00:39:14,520
didn't have the internet yet, but we had early forms of email over teletype machines and early

395
00:39:14,520 --> 00:39:20,600
fax machines. And that kept everybody in the know. And I felt this would sweep away the Soviet Union.

396
00:39:20,600 --> 00:39:26,440
These were far more powerful tools than the copiers that they were controlling. And indeed,

397
00:39:26,440 --> 00:39:32,840
that's what we saw in this 1991 coup against Gorbachev. The authorities grabbed the central

398
00:39:32,840 --> 00:39:38,120
TV and radio station, which they had always done before, but it did not keep people in the dark.

399
00:39:38,120 --> 00:39:44,600
And the totalitarian control was swept away. And then we saw a tremendous movement towards

400
00:39:44,600 --> 00:39:50,120
democracies during the 1990s with the rise of the World Wide Web. And people forget, but the

401
00:39:50,120 --> 00:39:54,200
world was a very different place some decades ago. There were very few democracies. And today,

402
00:39:55,000 --> 00:40:01,400
there are relatively few holdouts. You can argue about how perfect various democracies are,

403
00:40:01,400 --> 00:40:06,120
but there's much more democratization in the world than there was some decades ago.

404
00:40:06,920 --> 00:40:13,400
And we also have a democratization of access to the tools of creativity. It used to be,

405
00:40:13,400 --> 00:40:17,080
if you wanted to create a movie, you had to be a big Hollywood studio. If you wanted to do some

406
00:40:18,440 --> 00:40:23,400
technology development, you had to be a big corporation, a government lab, or an academic

407
00:40:23,400 --> 00:40:28,920
lab. Today, a kid in her dorm room can create a full-length motion picture in high definition

408
00:40:28,920 --> 00:40:34,920
with a $500 camera on her PC. A couple of kids at Stanford, as a dorm project, wrote a little bit

409
00:40:34,920 --> 00:40:40,440
of software and revolutionized web search and created a company worth $100 billion today.

410
00:40:40,440 --> 00:40:45,240
And there's lots of other examples of that. And these tools are literally in everybody's hands.

411
00:40:45,240 --> 00:40:50,440
It's not just the haves and the richer, getting richer. I mean, take these so-called cell phones,

412
00:40:50,440 --> 00:40:56,520
they're really very powerful devices that access all of human knowledge and are really tools of

413
00:40:56,520 --> 00:41:01,400
creativity there in half the hands of the world. I just got back from China, half the farmers in

414
00:41:01,400 --> 00:41:08,680
China have them. And nearly everyone will have them within a few years. So the tools of creativity

415
00:41:09,320 --> 00:41:15,800
and access to them have been democratized. These are positive indications. But technology,

416
00:41:15,800 --> 00:41:21,640
nonetheless, can be creative and overcome suffering on the one hand or destructive on the

417
00:41:21,640 --> 00:41:28,200
other. We've had that intertwined promise and peril ever since we've had stone tools and fire.

418
00:41:28,200 --> 00:41:36,360
And so it's an old story. And we need to keep these technologies safe. And it's a complex

419
00:41:36,360 --> 00:41:41,320
issue as to how to do that. On the one hand, we need ethical standards to prevent accidental

420
00:41:41,320 --> 00:41:47,720
problems. So for example, biotechnology, which is the ability to reprogram biology as a set of

421
00:41:47,720 --> 00:41:54,120
information processes, that's a whole new concept. And we're using that to reprogram biology away

422
00:41:54,120 --> 00:42:00,600
from disease, presumably good things. But it could also be misapplied by a bioterrorist to

423
00:42:00,600 --> 00:42:06,360
create a new biological virus that could be more deadly or more communicable or more stealthy.

424
00:42:06,360 --> 00:42:11,320
Now to prevent that from happening accidentally, we have ethical standards. They're called the

425
00:42:11,320 --> 00:42:20,200
Asilomar Guidelines. And they have actually kept biotechnology safe for 30 years. But if you have

426
00:42:20,200 --> 00:42:25,720
a bioterrorist, he's not going to follow those ethical standards. So we also need a rapid response

427
00:42:25,720 --> 00:42:31,880
system that would act as a kind of technological immune system. And a good model of that is how

428
00:42:31,880 --> 00:42:37,640
we deal with software viruses. We actually have an immune system. We automatically detect new

429
00:42:37,640 --> 00:42:43,160
software viruses, which emerge every day. There are destructive people who write these software

430
00:42:43,160 --> 00:42:50,840
viruses and put them out and we detect them. And we reverse engineer them. An antiviral program

431
00:42:50,840 --> 00:42:56,040
is coded, in some cases, automatically spread virally on the internet. And within hours,

432
00:42:56,680 --> 00:43:01,960
we have protection from a new software virus. And you can argue about how perfect it is. But

433
00:43:01,960 --> 00:43:07,000
nobody has taken down even a portion of the internet for even a second over the last 10 years.

434
00:43:07,000 --> 00:43:13,880
It's been a very robust system because we do have a technological immune system that protects us

435
00:43:13,880 --> 00:43:19,880
from software viruses. We need a similar system for biological viruses. And I've actually been

436
00:43:19,880 --> 00:43:25,960
working with the Army. I'm on the Army Science Advisor Group. And the primary issue that I've

437
00:43:25,960 --> 00:43:33,960
been dealing with is a rapid response system for biological viruses. We do have the technological

438
00:43:33,960 --> 00:43:44,280
ideas to do that. Do you think a computer can become self-aware? And if so, when might this

439
00:43:44,600 --> 00:43:53,560
happen? Well, part of human intelligence is the ability to reflect on ourselves, reflect on our

440
00:43:53,560 --> 00:44:00,120
thinking, have a model in my brain of how my brain creates models of the world so I can think about

441
00:44:00,120 --> 00:44:06,840
my thinking. And we can take that level of recursion several more steps and think about ourselves

442
00:44:06,840 --> 00:44:12,360
thinking about ourselves thinking. And human beings are capable of doing that because of the

443
00:44:12,360 --> 00:44:19,480
hierarchical thinking of the neocortex. Is that being self-reflective? From an objective point

444
00:44:19,480 --> 00:44:24,840
of view, it is. You have an entity that's thinking about itself thinking and can create models of

445
00:44:24,840 --> 00:44:31,400
itself thinking. But philosophically, that's not really the same thing as consciousness,

446
00:44:32,200 --> 00:44:38,840
the sort of feeling that one has. You can talk about how the brain processes the color red,

447
00:44:39,560 --> 00:44:47,080
but the feeling of redness, let alone more subtle feelings like happiness and joy and humor.

448
00:44:49,160 --> 00:44:55,400
The feeling of that, which is what we associate with consciousness, is very hard to describe.

449
00:44:56,680 --> 00:45:02,440
And ultimately, if you talk about what some people refer to as the hard problem of consciousness,

450
00:45:03,240 --> 00:45:09,960
it's fundamentally not a scientific issue because a synonym for consciousness is subjective

451
00:45:09,960 --> 00:45:15,560
experience. And if you ask, well, what is science, science is objective observation

452
00:45:16,360 --> 00:45:22,040
and deductions from that. There's a conceptual gap between subjective experience and objective

453
00:45:22,840 --> 00:45:29,240
observation. Another way of saying this is there's really no machine you could imagine building

454
00:45:29,960 --> 00:45:34,360
where you slide an entity in and a green light goes on. Okay, this one's conscious.

455
00:45:34,360 --> 00:45:39,880
No, this entity is not conscious. That doesn't have some philosophical assumptions built into it.

456
00:45:39,880 --> 00:45:44,200
I mean, you could build a machine like that, but different philosophers would build

457
00:45:44,200 --> 00:45:50,200
different assumptions into the machine. So John Searle would want it to be squirting biological

458
00:45:50,200 --> 00:45:55,160
neurotransmitters. And if it wasn't biological, he would say it's not conscious. And Dan Dennett

459
00:45:55,160 --> 00:46:00,840
would want it, wouldn't require it to be biological, but he would require it to be able to think about

460
00:46:00,840 --> 00:46:05,640
itself, thinking and build a model of itself. And if it did that, then maybe it's conscious.

461
00:46:05,640 --> 00:46:10,040
And different philosophers would have different assumptions. But there's really no way to prove

462
00:46:10,040 --> 00:46:17,960
whether another entity is conscious. My prediction is that these future machines will convince us

463
00:46:17,960 --> 00:46:23,080
that they're conscious. They will seem like they're conscious. They'll be convincing. We have machines

464
00:46:23,080 --> 00:46:29,960
today that talk about being happy or sad, avatars on the web or characters in a computer game.

465
00:46:30,600 --> 00:46:35,800
Their behavior is not yet convincing. It's not yet complex enough to really convince us that

466
00:46:35,800 --> 00:46:41,400
they're really having these emotions. So they seem like a simulation. In the future, that simulation

467
00:46:41,400 --> 00:46:46,760
will be so good that will be indistinguishable from the real thing. And it will actually introduce a

468
00:46:46,760 --> 00:46:52,680
philosophical issue. Is there a difference between a totally convincing simulation and the real thing?

469
00:46:54,040 --> 00:46:57,640
I believe we will be convinced by these machines. They will

470
00:46:58,680 --> 00:47:07,240
succeed in us believing that they are conscious. We will want to believe them because they'll

471
00:47:07,240 --> 00:47:14,040
be very influential. They'll be very clever. They'll get mad at us if we don't believe them.

472
00:47:16,200 --> 00:47:20,120
And moreover, it's going to get mixed up. It's not going to be a clear distinction. You know,

473
00:47:20,200 --> 00:47:24,840
I could be able to walk in a room and say, okay, humans on the left and machines on the right,

474
00:47:24,840 --> 00:47:29,480
because it's going to be all mixed up. You can have a biological human that's got computers in

475
00:47:29,480 --> 00:47:35,800
their brain, maybe billions of them. There may be more going on in the non-biological portion

476
00:47:35,800 --> 00:47:39,560
of their intelligence than the biological portion. So are they machine? Are they human?

477
00:47:40,440 --> 00:47:46,040
The action may be with the non-biological part. It's not going to be a clear distinction between

478
00:47:46,040 --> 00:47:52,600
human and machine the way it is today, because my prediction is we're going to merge with these

479
00:47:52,600 --> 00:47:59,160
technologies. So where does our consciousness lie? Do you have to be biological to be conscious?

480
00:48:00,680 --> 00:48:06,680
It's a philosophical question, and it just means that there's still a role for philosophy that

481
00:48:06,680 --> 00:48:11,800
science can't answer every question. Now, some scientists will go on and say, well, since it's

482
00:48:11,800 --> 00:48:17,880
not scientific, it's not real, and consciousness is just an illusion, and we shouldn't worry about it.

483
00:48:17,880 --> 00:48:22,840
It's a distraction. And you can build a completely consistent philosophy that does not have consciousness

484
00:48:22,840 --> 00:48:29,400
in it. But my own view is that it's a mistake, because our whole moral system is based on

485
00:48:29,400 --> 00:48:35,720
consciousness, and our whole legal system is based on our moral system. So if I hurt someone,

486
00:48:35,720 --> 00:48:43,640
cause them pain and suffering, which is a conscious experience, that's a moral and probably a crime.

487
00:48:44,280 --> 00:48:51,000
If you extinguish someone's consciousness, that's a high crime. If I destroy some property,

488
00:48:51,000 --> 00:48:55,160
that's probably okay if it's my property. If it's your property, it's a crime, not because I've

489
00:48:55,160 --> 00:49:00,600
caused suffering to the property, but I've caused suffering to the owner of the property. So it all

490
00:49:00,920 --> 00:49:07,640
comes down to consciousness, our whole moral and ethical and legal system. So I don't think we

491
00:49:07,640 --> 00:49:13,960
can just dismiss it as an illusion quite so easily. But it's another way of saying there's still a

492
00:49:13,960 --> 00:49:22,520
role for the idea of values and philosophical thoughts about the implications of these issues.

493
00:49:23,400 --> 00:49:29,640
But we are going to become increasingly non-biological. I don't think it makes sense to

494
00:49:30,600 --> 00:49:37,800
insist that these processes have to be running on a biological substrate, because what our brains

495
00:49:37,800 --> 00:49:44,920
are doing is shuffling around information. John Swarles says, well computers just shuffle around

496
00:49:44,920 --> 00:49:51,640
symbols and human beings really think thoughts and are really feeling these thoughts. But if you

497
00:49:51,640 --> 00:49:57,240
look at what in fact is going on, our brains are just shuffling around neurotransmitter levels and

498
00:49:57,240 --> 00:50:03,560
ion channels and ions and those are just representing information. And if you can shuffle

499
00:50:03,560 --> 00:50:09,560
around the information using a different substrate, the same thing is going on. You could do a thought

500
00:50:09,560 --> 00:50:14,120
experiment where you take just a little piece of your brain and replace it with a machine.

501
00:50:15,160 --> 00:50:19,800
The machine is operating on a completely different substrate, but it's still the same person.

502
00:50:20,920 --> 00:50:25,480
We've actually done this experiment, for example with Parkinson's patients. They had a piece of

503
00:50:25,480 --> 00:50:31,000
their brain, it stopped functioning and we replaced it with a computer. And if you ask them,

504
00:50:31,000 --> 00:50:35,320
do you think that computer is part of you? Because yes, different people, the same question, you

505
00:50:35,320 --> 00:50:38,680
might get different answers. But I've actually asked this question and most of them will say,

506
00:50:38,680 --> 00:50:45,000
yes, it's definitely part of me. And well if you carry this thought experiment further and keep

507
00:50:45,000 --> 00:50:51,240
replacing more and more portions of the brain with computers, the person's personality never

508
00:50:51,240 --> 00:50:59,480
changes. There's a continuity of identity. You would come to the conclusion that it's always the

509
00:50:59,480 --> 00:51:04,760
same person, the same consciousness. It certainly would seem that way. At the end of this process,

510
00:51:04,760 --> 00:51:11,880
you would have a person that has no biology. So we've discussed these issues actually for

511
00:51:11,880 --> 00:51:17,560
thousands of years, going back to the platonic dialogues. These will become actual pressing

512
00:51:17,560 --> 00:51:24,680
real issues as we go forward. But the reality is it's not going to be deciding,

513
00:51:24,680 --> 00:51:29,720
is that avatar conscious? Because we're going to become the machines. We'll start by becoming

514
00:51:29,720 --> 00:51:35,000
partly machine, because we will be putting these machines in our bodies and brains and

515
00:51:35,000 --> 00:51:41,000
we'll be partly biological, partly non-biological. But it is the nature of the machine portion of

516
00:51:41,000 --> 00:51:44,920
our intelligence that it grows exponentially. That's the nature of what I call the law of

517
00:51:44,920 --> 00:51:52,840
accelerating returns. The biological portion is fixed. It's not going anywhere. And I mean,

518
00:51:52,840 --> 00:51:57,400
biological evolution is a million times slower than technological evolution. So ultimately,

519
00:51:58,120 --> 00:52:04,440
we're going to be much more machine than we are biological. And people, when they think about

520
00:52:04,440 --> 00:52:09,080
that, they say, well, I don't want to become machine-like, because they're thinking about

521
00:52:09,080 --> 00:52:14,600
the machines that they know today. And if you look at your cell phone or your PC, it's impressive,

522
00:52:14,600 --> 00:52:18,200
but you don't want to become that kind of machine, because that is lesser than humans.

523
00:52:19,080 --> 00:52:22,840
We probably need some new terminology, because I'm talking about a machine

524
00:52:22,840 --> 00:52:28,280
that does have the subtlety and suppleness and intelligence and richness and complexity

525
00:52:28,280 --> 00:52:32,520
of human beings. And we will want to become those kinds of machines, because ultimately,

526
00:52:33,240 --> 00:52:37,800
those machines are going to be greater than we are. And we're going to want to emerge with them to

527
00:52:38,760 --> 00:52:45,800
enhance our own capabilities. And then people say, well, will we still be human if we do that?

528
00:52:46,680 --> 00:52:53,320
In my mind, that is what's being, in my mind, that is what being human is all about, going

529
00:52:53,320 --> 00:53:01,160
beyond our limitations, extending ourselves. If it wasn't for our tools, our life expectancy

530
00:53:01,160 --> 00:53:05,640
would be 23, which is what it was 1,000 years ago. We didn't stay on the ground. We didn't stay in

531
00:53:05,640 --> 00:53:12,120
the planet. We have not stayed with the limitations of biology. We're the only species that does that.

532
00:53:12,120 --> 00:53:16,760
We make ourselves greater through our tools. And we're going to literally transform

533
00:53:17,480 --> 00:53:24,760
our biological substrate. We're going to transcend biology. But in my mind, that's not

534
00:53:24,760 --> 00:53:31,800
transcending our humanity, because it is the nature of being human to extend beyond our boundaries.

535
00:53:31,800 --> 00:53:40,600
Very nice. What would you be doing if you were born in 1750 at the start of the industrial revolution?

536
00:53:48,600 --> 00:53:54,760
Well, I was born in 1750 in a way, because I started with mechanical

537
00:53:55,400 --> 00:54:01,160
technology. That's what I had when I was five, six, seven, eight. I had the kinds of tools that

538
00:54:01,160 --> 00:54:08,360
people had in 1750. And indeed, in 1750, people built mechanical devices that could calculate

539
00:54:09,160 --> 00:54:18,680
using mechanical devices. And they built elaborate automata. And I built devices that could

540
00:54:18,840 --> 00:54:25,800
manipulate reality using mechanical devices, at least as much as a five, six, and seven-year-old

541
00:54:25,800 --> 00:54:35,320
could do. So I was very much like those inventors in 1750, using mechanical technology. I then

542
00:54:35,320 --> 00:54:43,880
discovered information in the computer around the age of 11 or 12. I began to build little

543
00:54:44,600 --> 00:54:51,000
computerized devices and also got access to professional computers, like the IBM

544
00:54:51,720 --> 00:55:00,360
1401 and 1620. And so I jumped ahead a few hundred years at that time and entered the

545
00:55:00,360 --> 00:55:08,280
information age, where we had much more powerful tools to manipulate information. But even in 1750,

546
00:55:09,160 --> 00:55:18,040
the idea that you could embody information was around. Leibniz talked about the human brain as

547
00:55:18,760 --> 00:55:23,800
a set of logical pulleys. And he described it in mechanical terms, but he described it as a

548
00:55:25,000 --> 00:55:30,840
system that manipulated information using the kinds of metaphors that existed at that time.

549
00:55:31,400 --> 00:55:41,880
So one of the possible consequences of the vision that you have for the future is a radical

550
00:55:41,880 --> 00:55:49,240
extension in the human lifespan. I wonder if you could chat about that and the related thought that

551
00:55:49,240 --> 00:55:56,280
we need a finite lifespan in order to sort of, that's how we understand our lives currently,

552
00:55:56,280 --> 00:56:04,120
is that we live about 70 years and we plan our lives accordingly. How might that change if we live

553
00:56:04,120 --> 00:56:14,920
for, say, 500 years? A health and medicine biology has just made a grand transformation

554
00:56:15,800 --> 00:56:21,240
from being not an information technology, just kind of a hit or miss affair where we would just

555
00:56:21,240 --> 00:56:27,800
find things accidentally, to where it is now an information technology. We have now the software

556
00:56:27,800 --> 00:56:33,800
that life runs on, which is the Genome, and we're also making exponential gains in understanding it.

557
00:56:33,800 --> 00:56:38,760
By the way, the collection of the Genome followed exactly my exponential progression,

558
00:56:39,800 --> 00:56:44,200
which I call the Law of Accelerating Returns. Halfway through the project, the skeptics said,

559
00:56:44,200 --> 00:56:48,120
I told you this wasn't going to work. Here, halfway through the project, and you've only

560
00:56:48,200 --> 00:56:53,320
finished one percent of the project. It's pretty pathetic, but actually that was right on schedule,

561
00:56:53,320 --> 00:56:58,040
because if you're on an exponential progression where you're doubling your progress every year,

562
00:56:58,040 --> 00:57:02,360
once you get to one percent, you're only seven doublings away from 100 percent,

563
00:57:02,360 --> 00:57:06,280
and that's exactly what happened. It continued to double every year and seven years later,

564
00:57:06,280 --> 00:57:12,520
it was finished, and we've continued that past the end of the Genome project. So 2003, we had this

565
00:57:12,520 --> 00:57:17,400
software that runs in our bodies. It's outdated software. How long do you go without updating

566
00:57:17,400 --> 00:57:22,360
the software on your cell phone or your computer? Your cell phone updates itself every few days.

567
00:57:23,000 --> 00:57:27,640
This software hasn't been updated in thousands of years. Some of these programs are millions of

568
00:57:27,640 --> 00:57:32,440
years old. Like the fat insulin receptor gene is millions of years old. It says, hold on to every

569
00:57:32,440 --> 00:57:37,240
calorie, because the next hunting season may not work out so well. That was a great idea when

570
00:57:37,240 --> 00:57:43,000
our genes evolved. Today, it underlies an epidemic of obesity. We turn that gene off in animal

571
00:57:43,000 --> 00:57:47,960
experiments, and these animals ate a lot and remain slim and live 20 percent longer. That's

572
00:57:47,960 --> 00:57:53,000
just one of the 23,000 genes we'd like to tinker with. We also have the means now of changing

573
00:57:53,000 --> 00:57:59,000
our genes, not just in a baby, but in a mature individual. RNA interference can turn genes off,

574
00:57:59,000 --> 00:58:04,520
new forms of gene therapy can add new genes. We'll have not just designer babies, but designer baby

575
00:58:04,520 --> 00:58:10,680
boomers. We can design these interventions on computers. We can test them out on biological

576
00:58:10,680 --> 00:58:16,840
simulators that are getting more sophisticated every year. Health and medicine has just become

577
00:58:16,840 --> 00:58:23,000
an information technology. As such, it's going to double in power every year. That's the nature

578
00:58:23,000 --> 00:58:28,840
of information technology in any field. These technologies, even though they're in an early

579
00:58:28,840 --> 00:58:34,520
stage today, will be a million times more powerful in 20 years, and it will be a very different

580
00:58:35,240 --> 00:58:41,080
era. I've written a series of health books, the last two I've co-authored with Dr. Terry Grossman,

581
00:58:41,640 --> 00:58:47,640
and we talk about three bridges to radical life extinction. Bridge one is applying today's knowledge

582
00:58:47,640 --> 00:58:54,680
to slow down the aging process, and there's a lot you can do already to slow down aging processes.

583
00:58:54,680 --> 00:58:59,720
For example, the cell membrane in every cell is made up of a certain substance called phosphatidyl

584
00:58:59,720 --> 00:59:05,480
choline that depletes. Graduates, we get older. That's why the skin sags in an elderly person and

585
00:59:05,480 --> 00:59:11,400
their organs don't work as well. That's one of the 12 aging processes. You can actually stop and

586
00:59:11,400 --> 00:59:17,080
reverse that by supplementing with that substance. Another aging process is the buildup of plaque

587
00:59:17,080 --> 00:59:25,080
in our arteries. It not only causes heart attacks and strokes, but also leads to an elderly person's

588
00:59:25,160 --> 00:59:30,920
organs not working very well, claudication of limbs, impotence, and so on. You can reverse that

589
00:59:31,880 --> 00:59:36,920
not so easily by just taking one supplement, but you can attack it from any different

590
00:59:37,640 --> 00:59:43,480
perspectives and actually slow down. If you're diligent enough, actually reverse

591
00:59:44,120 --> 00:59:50,680
that process. Dr. Dean Ornish has shown that. We've described in detail how you can slow down,

592
00:59:50,760 --> 00:59:55,400
stop, and in some cases reverse all these different aging processes with today's knowledge.

593
00:59:56,840 --> 01:00:02,040
Today, it's somewhat complicated. You have to learn about your own body, what your issues are, and

594
01:00:02,040 --> 01:00:08,280
develop a program that's multifaceted to slow down the aging process. In my own case,

595
01:00:09,800 --> 01:00:16,760
on biological aging tests, when I was 40, I came out at about 38. I'm now 61, and on these

596
01:00:16,760 --> 01:00:21,720
biological aging tests, I come out in my early 40s. I've only aged a few years in the last 20

597
01:00:21,720 --> 01:00:29,080
years, according to these biological aging tests of how old I am internally. The goal of this,

598
01:00:29,080 --> 01:00:35,800
what we call bridge one, is not to live hundreds of years. It's just to get to bridge two in good

599
01:00:35,800 --> 01:00:43,400
shape. Bridge two is only maybe 15 years away when we have really the golden age of biotechnology,

600
01:00:43,400 --> 01:00:49,480
this ability to reprogram the information processes that underlie our biology. We'll have

601
01:00:49,480 --> 01:00:57,160
very powerful tools to really stop and reverse aging processes with biotechnology methods in 10,

602
01:00:57,160 --> 01:01:03,640
15, 20 years. According to my models, 15 years from now, we'll be adding more than a year every

603
01:01:03,640 --> 01:01:09,320
year, not just infant life expectancy, but to your remaining life expectancy. So as you go forward

604
01:01:09,320 --> 01:01:14,840
a year, your life expectancy will move on away from you. It's not a guarantee, but it will change

605
01:01:14,840 --> 01:01:20,840
the metaphor of the sense of time running out. They'll start running in. That's a bridge to the

606
01:01:20,840 --> 01:01:26,600
third bridge, which is the nanotechnology revolution. The quintessential app, I used to call it the

607
01:01:26,600 --> 01:01:35,240
killer app, but that's not so good a name for a health technology, are nanobots. And we'll have

608
01:01:35,320 --> 01:01:41,160
billions of nanobots, blood cell-sized devices augmenting our immune system, going through our

609
01:01:41,160 --> 01:01:47,160
body, keeping us healthy, destroying disease when it's at the level of a cell rather than an organ,

610
01:01:47,960 --> 01:01:54,440
and that really will keep us going for a very long time. And if you go beyond that, we ultimately

611
01:01:55,400 --> 01:02:01,320
will become mostly non-biological by merging with machine intelligence. The nanobus will go inside

612
01:02:01,320 --> 01:02:06,280
our brain. They'll interact with our biological neurons. They ultimately will be where the action

613
01:02:06,280 --> 01:02:12,040
is. Now being computerized, we will back them up just the way we back up our computers today.

614
01:02:12,760 --> 01:02:18,440
Ultimately, most of our brain will be non-biological. Ultimately, it will be so powerful that even the

615
01:02:19,320 --> 01:02:25,320
part that's biological will be understood, modeled, and simulated by the non-biological part,

616
01:02:25,320 --> 01:02:31,080
and so we can back up the biological part also. And so we'll have a means of restoring our

617
01:02:31,080 --> 01:02:36,200
mind file. People a hundred years from now will look back at this era where we went through the

618
01:02:36,200 --> 01:02:41,560
day without backing up our mind file. It's pretty remarkable, just as we would think it

619
01:02:41,560 --> 01:02:48,120
remarkable today if people didn't back up their personal computer files. We take for granted

620
01:02:48,120 --> 01:02:54,280
that you can smash your computer and then recreate its personality, its skills, its knowledge,

621
01:02:54,280 --> 01:03:01,640
just by loading it from a backup. So its mind file of your computer is not dependent on the

622
01:03:01,640 --> 01:03:09,080
hardware. There's a separation of hardware and software. In our brains, the software is embedded

623
01:03:09,080 --> 01:03:14,600
in the hardware. And if the hardware crashes, the software disappears with it. We take that for

624
01:03:14,600 --> 01:03:21,800
granted. But ultimately, we will achieve the same thing that we do now in our computers for our

625
01:03:22,440 --> 01:03:28,760
brains, which are really information processes. We have information in our brains that represents

626
01:03:28,760 --> 01:03:34,200
our memories, our skills, our personality. That's our mind file. It's information. It's the most

627
01:03:34,200 --> 01:03:39,800
valuable information we have. We'd like to be able to preserve that. And as we become more

628
01:03:39,800 --> 01:03:47,640
non-biological, we'll be able to do that. Now, people sometimes talk about, well, if we have

629
01:03:47,640 --> 01:03:52,520
radical life extension, then people live a lot longer. A, we'll run out of resources and we'll

630
01:03:52,520 --> 01:03:57,480
run out of things to do and life will get boring. And there won't be new opportunities because the

631
01:03:57,480 --> 01:04:04,600
old people won't get out of the way. If we just had radical life extension and no other changes,

632
01:04:05,160 --> 01:04:08,920
these would be problems. But it's important to look at all the different things that are

633
01:04:08,920 --> 01:04:13,880
happening. The same technologies that will bring radical life extension will also bring

634
01:04:13,960 --> 01:04:19,480
radical expansion of our resources. For example, we have plenty of energy. We have 10,000 times

635
01:04:19,480 --> 01:04:24,360
more sunlight than we need to meet all of our energy needs. But right now we can't capture it

636
01:04:24,360 --> 01:04:29,720
efficiently. I just did a study with Larry Page of Google for the National Academy of Engineering

637
01:04:30,360 --> 01:04:38,120
and we described a plan to convert our entire energy system to solar energy within 20 years.

638
01:04:39,080 --> 01:04:43,320
That is, in fact, on an exponential. We've been doubling the amount of solar energy we're producing

639
01:04:43,320 --> 01:04:48,600
in the world every two years. We've been doing that for 20 years. There's already been 10 doublings

640
01:04:49,240 --> 01:04:52,840
and there were only eight doublings away from it meeting 100% of our energy needs.

641
01:04:53,400 --> 01:04:58,040
And then you might say, well, but is there really enough sunlight? Well, there's 10,000 times more

642
01:04:58,040 --> 01:05:03,240
than we need. We only have to capture one part in 10,000 and we'll be able to do that with nano

643
01:05:03,240 --> 01:05:08,680
technology applied to solar panels. There are similar new technologies for water, for food,

644
01:05:09,240 --> 01:05:15,240
for housing that can meet the material needs of a growing biological population.

645
01:05:16,120 --> 01:05:19,960
And life won't be boring because we're going to be making ourselves smarter. We're going to merge

646
01:05:19,960 --> 01:05:25,080
with this technology. We're going to expand our minds quite literally. We're going to expand our

647
01:05:25,080 --> 01:05:30,760
experiences. We'll have virtual reality from within the nervous system, incorporating all of

648
01:05:30,760 --> 01:05:36,440
the senses. We'll be able to choose a virtual reality environment just as we choose a website

649
01:05:36,440 --> 01:05:45,240
today. And unlike, say, Second Life Today, which is small and flat and on your screen and sort of

650
01:05:45,240 --> 01:05:50,280
cartoon-like, these will be full immersion virtual reality environments that compete with real reality

651
01:05:50,280 --> 01:05:55,560
and ours realistic as real reality. And you can have a different body, different virtual body

652
01:05:55,560 --> 01:06:00,600
in these virtual environments for different circumstances. And so life is not going to be

653
01:06:00,600 --> 01:06:08,600
boring. And as for opportunities, we're constantly creating new institutions. Larry Page and

654
01:06:08,600 --> 01:06:15,480
Sergey Brin didn't wait for some old person to open up a position for them to create a whole new

655
01:06:15,480 --> 01:06:22,120
institution and a new opportunity. And we are expanding human knowledge. It doubles about every

656
01:06:22,120 --> 01:06:28,840
14 months. So we create constantly new opportunities to contribute. It's really life that gives meaning

657
01:06:28,840 --> 01:06:34,280
to life and the things we can do with it and all the creativity that we can deploy. We don't need

658
01:06:34,280 --> 01:06:40,440
death to give meaning to life. In fact, in my view, death is a great tragedy. It's a great robber

659
01:06:40,440 --> 01:06:47,960
of all the things that gives life meaning. It destroys meaning and knowledge and skill and

660
01:06:47,960 --> 01:06:55,160
relationships. And so we will have the means of transcending that limitation. That is what human

661
01:06:55,160 --> 01:07:00,920
beings do as we transcend our limitations. And we're going to transcend this particular biological

662
01:07:00,920 --> 01:07:08,760
limitation. Thank you. Previous visions of the past did not pan out, especially in the field of AI.

663
01:07:08,760 --> 01:07:11,960
What is different this time? Well,

664
01:07:12,200 --> 01:07:20,840
there's certainly no shortage of bad

665
01:07:21,880 --> 01:07:27,640
futurism. But my own thesis is based on what I call the law of accelerating returns,

666
01:07:28,200 --> 01:07:35,320
which is specifically the exponential growth of information technology. And I got into this

667
01:07:35,320 --> 01:07:39,160
because of my interest in being an inventor and I realized that timing was important. So I began

668
01:07:39,160 --> 01:07:44,200
to study technology trends and I gathered a lot of data. And about 30 years ago, I made a pretty

669
01:07:45,000 --> 01:07:51,240
unexpected discovery, which is the trajectory of information technology based on measuring

670
01:07:51,800 --> 01:07:56,520
the attributes of it, like the price performance of computing or the price performance of biological

671
01:07:56,520 --> 01:08:03,480
technologies, follows amazingly predictable trajectories. In the case of computation,

672
01:08:03,480 --> 01:08:08,440
going back to the 1890 census, if you put all the computers on a logarithmic graph,

673
01:08:08,440 --> 01:08:15,160
they form a very smooth doubly exponential graph. The price performance of computing was

674
01:08:15,160 --> 01:08:21,800
doubling every three years in 1900, every two years in 1950, every one year in the year 2000.

675
01:08:21,800 --> 01:08:27,640
It's now down to 11 months. It's a very smooth progression, very predictable and was not affected

676
01:08:27,640 --> 01:08:31,880
by any of the little things that happened in the 20th century, like two world wars,

677
01:08:31,880 --> 01:08:36,040
the Cold War, the Great Depression. It went through thick and thin and worn piece

678
01:08:36,760 --> 01:08:42,040
and continues now through the current economic downturn, completely unperturbed.

679
01:08:42,760 --> 01:08:46,840
And it's not just the price performance of computing. It's anything you can measure in

680
01:08:46,840 --> 01:08:52,600
terms of information, bits being moved around on the internet or bits of data about the brain.

681
01:08:53,480 --> 01:08:59,240
All these different measurements follow these exquisitely predictable trajectories, number

682
01:08:59,240 --> 01:09:05,000
of bits you can put on a magnetic disk. That's not Moore's law. Moore's law is actually just one

683
01:09:05,000 --> 01:09:09,320
example of this. People talk about Moore's law as being the sum total of exponential growth and

684
01:09:09,320 --> 01:09:15,320
they ask, well, how long can Moore's law last? Now Moore's law as paradigms go has been a very

685
01:09:15,320 --> 01:09:21,080
important one, but it's just one of the paradigms that has brought this exponential growth. It was

686
01:09:21,080 --> 01:09:25,960
the fifth paradigm in computers and we see similar trajectories in things that have nothing to do

687
01:09:25,960 --> 01:09:32,440
with integrated circuits. So this turns out to be very predictable. I have a whole theory on

688
01:09:32,520 --> 01:09:38,600
evolution, both biological and technological as to why this happens. Basically an evolutionary

689
01:09:38,600 --> 01:09:45,960
process evolves a capability, adopts that capability and then uses it to evolve the next stage.

690
01:09:45,960 --> 01:09:50,840
So even in biological evolution, it took a billion years for DNA to evolve, but then it

691
01:09:50,840 --> 01:09:56,520
biological evolution adopted it. So the next stage, the Cambrian explosion went 100 times faster

692
01:09:56,520 --> 01:10:01,320
and biological evolution kept getting faster and faster. Homo sapiens involved in just a few

693
01:10:01,320 --> 01:10:08,280
hundred thousand years and the fruits of these evolutionary processes grow in power and I have

694
01:10:08,280 --> 01:10:14,440
a whole mathematical treatment of that, but we can see it empirically and I have a team of ten

695
01:10:14,440 --> 01:10:19,160
people that gather this data in these different fields and we see very predictable progression

696
01:10:19,160 --> 01:10:25,320
of these information technologies. So I believe what we can predict very accurately is the overall

697
01:10:25,320 --> 01:10:31,240
power of these technologies. Now when we talk about the implications of it and what this will

698
01:10:31,240 --> 01:10:39,720
enable us to do and whether a promise or peril will be more important or predominant, we can have

699
01:10:39,720 --> 01:10:46,760
arguments about, but I think the overall power of these technologies is inexorable. Thank you.

