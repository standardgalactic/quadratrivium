1
00:00:00,000 --> 00:00:07,120
In this session we are going to cover two notebooks, one this is the first one dedicated to the

2
00:00:07,120 --> 00:00:13,520
creation of the dataset and a second one dedicated to the fine-tuning of the model.

3
00:00:15,120 --> 00:00:22,080
Here we're going to have a very big and friendly approach to this topic and then at the end of

4
00:00:22,080 --> 00:00:29,840
this session I will present some resources to go beyond that and to be able to also like use

5
00:00:30,080 --> 00:00:37,280
better tools and perform other things but in this session we're going to stick to like the basics

6
00:00:37,280 --> 00:00:43,600
and try to really learn the theory behind it so we're also like more aware of what's going on when

7
00:00:43,600 --> 00:00:53,760
we use automated tools. In this first notebook we're going to talk about datasets and how to

8
00:00:53,760 --> 00:00:59,760
create a high quality dataset so I want to mention the fact that there are basically two datasets

9
00:01:00,720 --> 00:01:06,160
several datasets we're interested in. The first one is instruction datasets where

10
00:01:06,160 --> 00:01:11,360
inputs are instructions this is basically how you use chart gpt like write me something and

11
00:01:11,360 --> 00:01:17,920
the model is supposed to write you something and not complete what you just said because this is

12
00:01:17,920 --> 00:01:24,080
real completion and this is part of the pre-training of these models they pre-train on a lot of data

13
00:01:24,160 --> 00:01:30,960
and the task is next token prediction so they're just here to predict what the next word is going

14
00:01:30,960 --> 00:01:38,320
to be and this is nice but not really what we want to create assistance so instead we're going to

15
00:01:38,320 --> 00:01:44,640
use supervised fine-tuning to be able to turn a base model into a useful chat model here.

16
00:01:45,760 --> 00:01:51,520
There are also preference datasets I want to mention it briefly this is reinforcement

17
00:01:51,520 --> 00:01:58,560
learning from human feedback this is often used after the supervised fine-tuning process and in

18
00:01:58,560 --> 00:02:05,280
these datasets you will find different answers and some kind of ranking of these answers to say

19
00:02:05,280 --> 00:02:10,240
hey this one is more useful than the other one we're going to mention it during the fine-tuning

20
00:02:10,240 --> 00:02:15,920
process in the second notebook and finally there are other types of dataset it can be sentence

21
00:02:15,920 --> 00:02:21,680
classification it can be code dataset where you have a fill in the middle objective where you

22
00:02:21,680 --> 00:02:28,880
want to fill in code that has some context so before your cursor and after your cursor and

23
00:02:28,880 --> 00:02:34,160
this is where you want the code to be but we're not going to talk about this it was just a general

24
00:02:34,160 --> 00:02:40,080
overview of the kind of dataset you can expect in this space so as mentioned here we're just going

25
00:02:40,160 --> 00:02:44,800
to use supervised fine-tuning so with an instruction dataset and we're going to be a lot

26
00:02:44,800 --> 00:02:52,400
owned by filtering an existing dataset so the one that we're going to use today is the open

27
00:02:52,400 --> 00:02:58,160
platypus dataset it's a collection of different datasets actually this is already a dataset that

28
00:02:58,160 --> 00:03:04,160
has been filtered using all the dataset but we're going to do it even more we can check what it looks

29
00:03:04,160 --> 00:03:12,160
like on the hugging face page here so here you have the instructions for example the board game

30
00:03:12,160 --> 00:03:17,760
speeder and divider into three parts blah blah blah and the output that is expected by the model

31
00:03:17,760 --> 00:03:22,720
so this is basically what your model is going to learn during the supervised fine-tuning process

32
00:03:22,720 --> 00:03:29,920
it's going to learn to output this answer when it has this instruction and we repeat it a lot of

33
00:03:29,920 --> 00:03:35,120
times and at some point the model is pretty good at understanding what it needs to do so it needs

34
00:03:35,120 --> 00:03:43,280
to provide a useful answer for this instruction you have more information about the platypus dataset

35
00:03:43,280 --> 00:03:50,160
and there's also a really nice paper you can find here about how they did it and how they trained

36
00:03:50,160 --> 00:03:55,760
their models called platypus so an interesting read if you want to know more about it

37
00:03:56,560 --> 00:04:03,120
so first of all let's start with the code we're going to need to install some libraries

38
00:04:03,760 --> 00:04:11,600
so here we're going to keep install a bunch of libraries we're going to install datasets the

39
00:04:11,600 --> 00:04:18,480
library from hugging face you handle this also transformers very useful sentence transformers

40
00:04:18,480 --> 00:04:26,800
too because we are going to use sentence transformers to create embeddings of our data we're going to

41
00:04:26,800 --> 00:04:35,680
see why in a few minutes and finally a vector database from facebook face gpu here you can see

42
00:04:35,680 --> 00:04:43,600
the runtime so make sure you have a t4 gpu or more if you can afford it but the entire code should

43
00:04:43,600 --> 00:04:51,520
run using a free tier google collab so with a t4 gpu for the sake of this exercise i'm using a v100

44
00:04:51,520 --> 00:04:56,240
with higher ram because it's just going to be a bit faster and we won't have to stay at the screen

45
00:04:56,240 --> 00:05:03,120
for 30 minutes the second step that is really useful so this is the first time i tried to use it

46
00:05:03,120 --> 00:05:08,320
please bear with me this is quite a new feature in google collab but now we have a secret tab here

47
00:05:08,320 --> 00:05:14,720
on the left and as you can see here you can add a new secret and you can give it a name

48
00:05:15,280 --> 00:05:21,680
hugging face and a value so you can retrieve the value using this link if you have a hugging face

49
00:05:21,680 --> 00:05:29,280
account so here i collab i can copy it here i can write the hugging face here and copy paste the

50
00:05:29,280 --> 00:05:38,000
value here so and give access to the notebook um so this should be a really clean way of

51
00:05:38,000 --> 00:05:42,480
managing your secrets because now they share across all your notebooks and they won't going to be

52
00:05:43,200 --> 00:05:52,960
shared with people um other than in your account um to use it to jump in um we just got a question

53
00:05:52,960 --> 00:05:57,440
from the audience that i'm not sure what the answer is i don't know how widespread this problem is

54
00:05:58,400 --> 00:06:07,040
but do you know what an insure file accessible error message might be oh uh sorry i thought

55
00:06:07,040 --> 00:06:16,160
that we tested that uh let me let me just uh try out the links that are used okay

56
00:06:17,120 --> 00:06:28,000
uh anyone with the link should be able to access them actually uh some can some people

57
00:06:28,000 --> 00:06:32,160
confirm that you can access it which you can you access these notebooks uh i can access

58
00:06:32,160 --> 00:06:36,720
the notebooks one thing might be the case like you do need to be logged into google i think

59
00:06:36,720 --> 00:06:41,920
in order to access colab so if you're not logged into google then you probably need to do that

60
00:06:42,880 --> 00:06:46,720
all right we'll continue for now um if anyone else has any problems please do let us know in

61
00:06:46,720 --> 00:06:53,520
the chat of the comments uh yes please uh oh uh james just might be a company blocking it for

62
00:06:53,520 --> 00:06:59,840
security reasons yeah if you can't access any google products from uh your corporate uh laptop

63
00:06:59,840 --> 00:07:05,120
then yeah you probably have to find a different network unfortunately or just watch for now

64
00:07:05,120 --> 00:07:11,440
follow along uh when you get the recording yeah exactly uh sorry about that google colab can be

65
00:07:11,920 --> 00:07:20,000
a bit difficult to use in some in some context um here we're going to uh import our secret

66
00:07:20,000 --> 00:07:27,920
using uh google colab use the data use the data get so now the hf token um has the correct value

67
00:07:27,920 --> 00:07:32,400
and this is what we're going to use if we need it in the when we need it in the rest of this

68
00:07:32,400 --> 00:07:40,160
collab this is optional uh we are only going to need it when we want to upload uh the data set

69
00:07:40,160 --> 00:07:45,920
so if you don't have a hugging face account you don't need to create one i recommend it because

70
00:07:45,920 --> 00:07:51,360
it's nicer and you'll be able to upload your own data set in your own account but if not it's okay

71
00:07:52,080 --> 00:07:55,760
i will upload it in my account and you'll be able to reuse it from this account

72
00:07:56,880 --> 00:08:02,160
so now we have the hugging face token and the first thing that we want to do is to

73
00:08:02,880 --> 00:08:12,240
load the data set that we want to use so in this case it's the data set that was mentioned here so

74
00:08:12,240 --> 00:08:21,760
open open platypus we can copy paste it from here and it should load the data set download it

75
00:08:21,760 --> 00:08:27,680
and load it and we're going to see all the different columns inside of the data set so

76
00:08:28,640 --> 00:08:36,560
input output instruction and data source uh that should be correct here and we have the

77
00:08:36,560 --> 00:08:47,520
number of rows so almost to 25k rows um so we can see a bit more about it we're going to

78
00:08:48,480 --> 00:08:55,120
read it as a bandit's data set and we can even with google collab convert it into an interactive

79
00:08:55,120 --> 00:09:00,960
table it's a better way of looking at it unfortunately it can take some time for google

80
00:09:00,960 --> 00:09:07,760
collab to convert it so we're going to see but yeah it's nice to see that we have the instruction

81
00:09:07,760 --> 00:09:12,720
and we have the output and this is all that matters here we're going to explore a bit more

82
00:09:12,720 --> 00:09:19,840
about instruction the output if it was a real data set real raw data set what we want to do at this

83
00:09:19,840 --> 00:09:27,120
point is really read not every line because it's too too too much but a lot of these lines

84
00:09:27,120 --> 00:09:33,280
and be able to get a good understanding of what's in this data set and what we expect and also like

85
00:09:33,280 --> 00:09:40,400
just clean it like if there are samples that are not high quality that have like bad english that are

86
00:09:40,400 --> 00:09:46,720
just plain wrong we want to remove them this is very important we want to create the best

87
00:09:47,280 --> 00:09:54,320
data set possible so it means filtering out a lot of samples okay so now we have this data set we

88
00:09:54,320 --> 00:10:03,440
can read everything here this is a lot of data so we won't do it in this case it could take too

89
00:10:03,440 --> 00:10:13,760
much time but now something that we can do let me show you once again the the code here so load

90
00:10:13,760 --> 00:10:20,560
data set and then the name of the data and what we are going to do here is that we're going to

91
00:10:20,560 --> 00:10:30,640
use the transformers library to import the tokenizer this will convert the row text into tokens

92
00:10:31,200 --> 00:10:40,000
then we will import the matplotlib library to plot the results and also the cborn library

93
00:10:40,000 --> 00:10:50,080
for the same reasons first we want to import the tokenizer so in our case we want the tokenizer not

94
00:10:50,080 --> 00:10:55,280
from but as suggested here but from lamatu because this is the model that we want to use

95
00:10:56,400 --> 00:11:05,840
so we're going to use a new research version of lamatu and not the official one from meta

96
00:11:05,840 --> 00:11:11,440
why that it's because if you don't have a hugging face account you will not be able to access the

97
00:11:12,080 --> 00:11:18,240
official version of it so news research just re-uploaded the entire thing so now we have

98
00:11:18,240 --> 00:11:25,680
the tokenizer we can test it here it's going to download it once again from hugging face and

99
00:11:25,680 --> 00:11:34,320
and then we're going to print it once it's done here you can sit with all the special tokens

100
00:11:34,320 --> 00:11:43,200
unknown etc when it's done we want to use it to tokenize our instructions here and also outputs

101
00:11:43,200 --> 00:11:53,040
here so the way that we're going to do it we're going to create a table an area called instruction

102
00:11:53,120 --> 00:12:03,920
token counts it's a bit of a ghost but and we're going to use the tokenizer to tokenize

103
00:12:04,560 --> 00:12:14,880
every sample in our data set this is not correct actually this is why you should not always trust

104
00:12:15,440 --> 00:12:31,600
coder lambs for example in our data set train and close it so here in this table we should get

105
00:12:31,600 --> 00:12:37,440
like the token counts for every instruction and we're going to repeat this process with the

106
00:12:38,240 --> 00:12:46,320
output so pretty much the same thing here and we want the output and finally we want to

107
00:12:46,320 --> 00:12:55,600
combine the instruction in the output because this is like the entire data set and so instruction

108
00:12:55,680 --> 00:13:08,080
plus output and in this case we want to call it combine token counts and here we're going to merge

109
00:13:08,080 --> 00:13:23,520
these two tables for instruction outputs in zip etc and we should get like the the sum of all the

110
00:13:24,160 --> 00:13:32,960
tokens here in both instruction outputs now that is done we are going to do a little function to

111
00:13:32,960 --> 00:13:40,640
plot the distribution of our token so we can have an easy visualization of it so here I'm going to

112
00:13:40,720 --> 00:13:52,800
use sns set style white grid and slowly but surely get everything here

113
00:13:58,000 --> 00:14:04,640
actually I'm sorry but I'm going to copy paste it so it's a bit faster to do it

114
00:14:05,280 --> 00:14:12,640
and now we can plot the distribution for every instruction output and combine token count

115
00:14:13,520 --> 00:14:22,480
so this is a very simple plot and we can call it using plot distribution and here we're going to

116
00:14:22,480 --> 00:14:28,640
first use instruction token counts and we're going to see the distribution of token counts

117
00:14:29,280 --> 00:14:32,000
for instruction on A

118
00:14:40,880 --> 00:14:47,040
this part takes a bit of time unfortunately because yeah it needs to tokenize the entire data set

119
00:14:50,320 --> 00:14:57,200
but once you've done it you can basically comment it it's okay and we're going to repeat this process

120
00:14:58,720 --> 00:15:05,600
with the output token counts so this time it's for output only and finally the

121
00:15:07,040 --> 00:15:16,400
combine token counts so here it's for instruction plus output here I'm going to

122
00:15:16,400 --> 00:15:26,240
comment it so we get faster results and now we have a distribution for all of our data

123
00:15:26,880 --> 00:15:34,400
so here you can see that we have approximately like the the minis is around here so around

124
00:15:34,960 --> 00:15:42,080
500 tokens there's a long tail distribution goes up to like 5000 tokens why is it important

125
00:15:42,080 --> 00:15:48,880
why does it matter it's because these models they have a certain context window and if it's

126
00:15:48,880 --> 00:15:55,440
because beyond this context window it's not going to be very helpful so it's important to know like

127
00:15:55,440 --> 00:16:01,680
the the number of tokens in our data set we also maybe want to sample more from

128
00:16:03,360 --> 00:16:07,440
samples that have more tokens because they're going to be more informative than others

129
00:16:08,160 --> 00:16:15,840
but we'll see about that basically here we can see okay I'm going to put a certain threshold

130
00:16:15,840 --> 00:16:23,600
for this data set at 2k tokens the max context size for lambda 2 is actually 4k but

131
00:16:23,600 --> 00:16:30,800
this is just an example to show how we can just set a threshold so here we want to filter out

132
00:16:30,800 --> 00:16:44,720
rows with more than 2000 samples so one way of doing it is to say if I count in numeric combined

133
00:16:45,680 --> 00:17:00,400
token counts if count okay so here we're going to retrieve the index of every sample where the

134
00:17:00,400 --> 00:17:10,880
count in combined token counts is lower than 2k and now we can print how many of this we have

135
00:17:14,960 --> 00:17:17,520
okay and if we print

136
00:17:20,880 --> 00:17:28,960
length of the data set in train and we are going to remove the length of the valid indices

137
00:17:28,960 --> 00:17:35,360
so we see how many we remove okay we only remove 31 of them but that's fine you can have a more

138
00:17:35,360 --> 00:17:41,120
aggressive threshold if you want in this case yeah we're going to remove just a few of them as you

139
00:17:41,120 --> 00:17:48,320
can see here then we're going to extract the valid rows based on the indices so here we need to

140
00:17:49,040 --> 00:17:56,880
take the data set train and we're going to use the select method to only get the valid indices

141
00:17:58,480 --> 00:18:08,800
and then we're going to get the token counts so for the valid rows so we can also plot this

142
00:18:08,800 --> 00:18:16,560
distribution here and we plot the distribution of the token counts after filtering exactly like that

143
00:18:21,440 --> 00:18:28,320
okay there's an issue here because I executed the code twice I shouldn't have

144
00:18:29,040 --> 00:18:34,160
but that's fine if you execute it once it should be okay now it's already filtered which is why

145
00:18:34,160 --> 00:18:40,560
it's grid in there and here you see that we have a very different plot because all this

146
00:18:40,560 --> 00:18:49,120
right part has been filtered out another thing that we can do is near the duplication using

147
00:18:49,120 --> 00:18:56,560
embeddings which is why we install the sentient transformers library and what we want to do here

148
00:18:56,560 --> 00:19:07,120
is we want to embed every row every sample from our data set so here we want to translate that into

149
00:19:07,120 --> 00:19:14,080
a vector we call an embedding and using an embedding model how to choose the best embedding model

150
00:19:14,080 --> 00:19:21,680
it's often it's a popular question one way of answering it is looking at the MTEB the board

151
00:19:21,760 --> 00:19:28,320
on a hugging face this is where you can see like a competition with all the embedding models on

152
00:19:29,440 --> 00:19:36,080
various tasks it's funny because since I've made this screenshot there are new ones on top of it

153
00:19:36,960 --> 00:19:44,720
the one that we're going to use here is the GTE base embedding model it's a it's a really good

154
00:19:44,720 --> 00:19:50,000
model it's not the best model but it's going to be faster than other options which is why we're going

155
00:19:50,000 --> 00:19:57,600
to use it here and we're going to use these embeddings to then calculate the similarity between

156
00:19:57,600 --> 00:20:03,360
them and when they're too similar we're just going to filter them out so how are we going to do it

157
00:20:03,360 --> 00:20:10,320
we're going to use the sentient transformer library and we import the sentient transformer

158
00:20:11,040 --> 00:20:18,080
class we're also going to import face the vector database from facebook it's not the best vector

159
00:20:18,080 --> 00:20:23,760
database but it's very simple it's very minimalistic which is why I used it in this example from

160
00:20:23,760 --> 00:20:32,960
data set we are going to use data set and data set dict to be a bit fancy we're also going to use

161
00:20:32,960 --> 00:20:42,560
tqdm to have a nice loading bar and finally number for some operations so here we're going to

162
00:20:42,560 --> 00:20:49,680
really create the code in one function to do everything so we are going to pass it a data set

163
00:20:50,320 --> 00:20:55,840
we are going to pass it the name of the embedding model we want to use and we're going to pass it

164
00:20:55,840 --> 00:21:03,920
threshold for example 95 percent it means that when it's 95 percent as similar as another

165
00:21:03,920 --> 00:21:10,960
embedding it's fishy and we probably do not want to to use it we probably want to filter out this

166
00:21:10,960 --> 00:21:19,120
model so as a sentence transformer we're going to use the model that we we pass this argument

167
00:21:20,400 --> 00:21:30,560
for the output we are going to use all the example in the data set so what we want to filter

168
00:21:31,360 --> 00:21:36,400
filter out here are just the outputs are not the instructions we're fine if we have similar

169
00:21:36,400 --> 00:21:40,880
instructions we just do not want similar outputs because this is what the model is going to be

170
00:21:41,040 --> 00:21:51,360
trained on then we are going to say that we are converting text to embeddings we are going to

171
00:21:52,720 --> 00:22:01,360
use the sentence model and encode the outputs that we have and we can even show a progress bar

172
00:22:02,320 --> 00:22:05,040
to be fancy bar

173
00:22:07,760 --> 00:22:14,720
then we're going to get the dimension of our embeddings so you can see in the

174
00:22:15,680 --> 00:22:23,440
little boards some of them they have like 1024 some of them they have like 768 basically yeah

175
00:22:23,440 --> 00:22:29,520
they have different dimensions take that into account we are going to create our index using

176
00:22:30,080 --> 00:22:38,080
the vector database so it's going to be a flat ip index in this case

177
00:22:39,680 --> 00:22:49,840
and we need to normalize our embeddings the face already has a function to do it but i do not trust

178
00:22:49,840 --> 00:22:54,720
it that much so we're going to do it on our own because i had a bad experience with it

179
00:22:55,680 --> 00:23:02,160
and i think it's going to be better that way so here we're using numpy to normalize it

180
00:23:03,200 --> 00:23:10,080
using the norm to just take the norm to normalize the entire embedding space

181
00:23:10,640 --> 00:23:15,280
and then we're going to add it to our index as normalized embeddings

182
00:23:16,640 --> 00:23:22,320
then we're going to say we are filtering out let's say near duplicates

183
00:23:22,640 --> 00:23:31,440
and in this part of the code we want to use the index search so we have

184
00:23:33,360 --> 00:23:39,520
the normalized embedding we just put and here we are going to say k equal

185
00:23:40,400 --> 00:23:46,320
2 so we are going to return at most two vectors we don't need more in this case

186
00:23:47,280 --> 00:23:54,640
and we're going to create a list of the samples we want to keep call it to keep

187
00:23:55,360 --> 00:24:02,720
and this is the main loop finally range length yeah it's fine

188
00:24:05,120 --> 00:24:10,320
and we're going to do something nice for the QDM so we have a nice loading bar

189
00:24:11,200 --> 00:24:25,120
and what we want here is if the dimension is so this if this is we're going to return here the

190
00:24:25,120 --> 00:24:32,480
similarity between these embeddings and if this is this if the cosine similarity is

191
00:24:32,480 --> 00:24:38,400
below the threshold we are going to keep it so we are going to add it to the to keep

192
00:24:39,360 --> 00:24:52,320
happened and then we have i yes an index index and then we can create data set trains and we

193
00:24:52,320 --> 00:24:58,960
are going to use the select method from the data set object to only keep these indexes

194
00:25:00,640 --> 00:25:07,520
then we are going to return it as a data set dict this is not the most elegant way of doing it but

195
00:25:08,240 --> 00:25:14,720
it's going to be fine for the purpose of this exercise and then we can call our function so

196
00:25:15,680 --> 00:25:22,640
the duplicate data set and we are going to pass the data set and we're going to pass

197
00:25:23,840 --> 00:25:30,400
the embedding model we want to use so in this case as I mentioned it's going to be the gte large

198
00:25:31,200 --> 00:25:40,000
and we can just copy paste it here and as a threshold I'm going to use 0.95 be careful if

199
00:25:40,000 --> 00:25:47,120
you switch the embedding model you won't have the same distribution of cosine similarity so some

200
00:25:47,120 --> 00:25:53,840
models to get the same results you're going to need like 85 others you can might need 99.9

201
00:25:54,640 --> 00:26:02,560
it really depends on the embedding model that you use it should be fine so now we can convert

202
00:26:02,560 --> 00:26:10,560
the entire data set into embeddings here we are downloading the embedding model it's not a big

203
00:26:10,560 --> 00:26:17,840
model which is why it's it's pretty fast the long part is actually comparing the embeddings

204
00:26:18,720 --> 00:26:25,520
I should mention why we're doing it using a vector database instead of a for loop I've tried to do a

205
00:26:25,520 --> 00:26:31,120
very minimalistic version using two for loop so we would compare every embedding to all the other

206
00:26:31,120 --> 00:26:38,320
embeddings but it took a very long time so this is why we're using a vector database here to be

207
00:26:38,320 --> 00:26:45,120
more efficient to be used by the computations and and get the results basically just faster because

208
00:26:45,120 --> 00:26:51,280
otherwise it would take like two hours it was really really too long unfortunately so here we

209
00:26:51,280 --> 00:26:58,880
still downloading the models and then with a v100 with high ram it should take about three to four

210
00:26:58,880 --> 00:27:06,720
minutes to get all the embeddings and to filter out the data set in the meantime we can continue

211
00:27:06,720 --> 00:27:14,640
I'm just going to show the code here because I don't know if you can really see it if you had time

212
00:27:15,280 --> 00:27:21,360
to see the code this part might be a bit confusing but I don't want to delve too deep

213
00:27:21,360 --> 00:27:29,920
to the details of the face vector database okay so now you see that it's converting the text to

214
00:27:29,920 --> 00:27:36,000
embeddings oh it's going to take much longer than last time I've tried unfortunately but it's okay

215
00:27:36,000 --> 00:27:46,160
like we we can stop it or come back later to finish it what we want to see when we have this

216
00:27:46,160 --> 00:27:55,680
dedupe data set is the number of samples that were filtered out so we can print the length of the

217
00:27:56,640 --> 00:28:09,040
original data set we can print the length of the dedupe data set and we can even print the number

218
00:28:09,040 --> 00:28:15,440
of samples that were removed so in this case the length of the original data set minus the

219
00:28:15,440 --> 00:28:23,920
length of the dedupe data set and this will tell us that how many rows we we removed and last time

220
00:28:23,920 --> 00:28:35,440
you can see it later on the solution notebook it's about 8 000 samples one thing that we can do

221
00:28:36,000 --> 00:28:43,200
when that part is over is topk sampling so in this case we still have too many samples because if

222
00:28:43,200 --> 00:28:51,120
we remove 8 000 samples we're still going to have 20 no we're still going to have 16 k samples

223
00:28:51,200 --> 00:28:56,160
maybe this is too much for what we want to do so we can randomly sample

224
00:28:59,200 --> 00:29:06,400
some some rows in order to do that we're going to create a new function called topk

225
00:29:07,360 --> 00:29:15,840
rows we are going to use a data set token counts and k to know how many we want to have

226
00:29:16,480 --> 00:29:24,000
we're going to sort the indices because we can sort it by descending token count

227
00:29:24,000 --> 00:29:30,000
and get the topk indices in this case so it's going to be sorted range

228
00:29:32,720 --> 00:29:44,480
length token counts and here we are going to use going to use lambda i token counts

229
00:29:44,480 --> 00:29:48,160
reverse is equal to true so here we should get

230
00:29:51,440 --> 00:29:59,120
everything that we need so the token counts and get all the data sets with most samples first

231
00:29:59,920 --> 00:30:07,440
and then topk indices we are going to just keep those those topk

232
00:30:08,400 --> 00:30:14,000
yeah and i just talked about randomly doing it but it's not true we're just getting

233
00:30:14,000 --> 00:30:21,760
like the the samples with the most tokens sorry about that and then we can create topk data

234
00:30:21,760 --> 00:30:30,800
and here we have instruction where we want data sets that are in the topk indices

235
00:30:33,520 --> 00:30:36,080
and we're going to do the same thing with the output

236
00:30:37,760 --> 00:30:44,080
you could do something similar with the select method but yeah this time this time i want to

237
00:30:44,640 --> 00:30:51,120
to be clear about what's going on so we have a full loop to select all the samples that were

238
00:30:51,120 --> 00:30:58,160
in the sorted indices here and we are not going to keep like 1000 of them and we are going to do

239
00:30:58,960 --> 00:31:08,560
the same thing with output and finally we can return our data sets from the dictionary that we

240
00:31:08,560 --> 00:31:20,720
did topk data so this is our function but in order to call it we are going to need to have

241
00:31:20,720 --> 00:31:27,280
the new token counts because here we filtered out a lot of samples so we can just copy paste

242
00:31:27,280 --> 00:31:33,440
what we did at the beginning here get the instruction token counts the output token

243
00:31:33,440 --> 00:31:40,640
counts the combined token counts and this is what we will use when we want to call this function

244
00:31:41,200 --> 00:31:51,600
so let's have a k of 1000 and the topk data set will be get topk rows data set we're going to

245
00:31:51,600 --> 00:31:57,280
use it with the combined counts and the k of 1000 so this is how we're going to call the function

246
00:31:58,320 --> 00:32:09,520
and finally we are going to save it as a dictionary like yeah data set dict as they call it

247
00:32:11,040 --> 00:32:15,840
to make sure that we still have like a train split but not not very important

248
00:32:16,240 --> 00:32:24,160
after we've done that we can once again re-compute all of the token counts

249
00:32:26,240 --> 00:32:29,600
and the plot actually like also plot the distribution

250
00:32:32,000 --> 00:32:38,480
so this is just to see what's the new distribution after after filtering after topk sampling

251
00:32:39,440 --> 00:32:46,800
now how it looks like and yeah we'll see we'll see in a few minutes

252
00:32:48,640 --> 00:32:51,520
when this is done and we can see the

253
00:32:56,160 --> 00:33:05,920
the distribution we can just also see the samples themselves to see like with pandas

254
00:33:06,640 --> 00:33:13,520
how it looks like like we've done at the very beginning of this notebook here and we'll see

255
00:33:13,520 --> 00:33:20,640
like how many samples remain and finally I want to mention chat templates so there's a need to

256
00:33:20,640 --> 00:33:25,680
define a chat template if you want to use your large language model as a chat bot there are

257
00:33:25,680 --> 00:33:32,000
different ways of doing it here's a way of doing it we have a raw user content either

258
00:33:32,960 --> 00:33:35,840
raw assistant so this is more like the raw data

259
00:33:37,920 --> 00:33:44,000
this is a format that you can use just user two points and then the message then assistant

260
00:33:44,000 --> 00:33:50,400
two point nice nice to meet you in the case of flamato you have this particular template so

261
00:33:50,400 --> 00:33:53,920
you have this token s then you have the instruction you have space

262
00:33:56,240 --> 00:34:00,160
not not not the instruction it's it's another token for instruction then you have

263
00:34:01,120 --> 00:34:06,000
a sys you have the system prompt you have here the user prompt and finally the model answer

264
00:34:06,000 --> 00:34:11,600
it's quite a difficult template you we don't need to use it to function our lamato model

265
00:34:11,600 --> 00:34:16,800
because we're functioning the base model and this chat template is only used in the chat version

266
00:34:16,800 --> 00:34:24,160
of lamato this is not the one that we use here I wanted to mention the chat ml template from open

267
00:34:24,240 --> 00:34:30,480
ai it looks like this it's the most popular and standardized one you can see it in a lot of

268
00:34:30,480 --> 00:34:35,200
state-of-the-art open source models we're not going to use this one because it requires adding

269
00:34:35,200 --> 00:34:41,360
tokens it's more difficult so the one that we're going to use is going to be quite simple we're

270
00:34:41,360 --> 00:34:51,040
going to create a function called chat template about it with an example and in this example we're

271
00:34:51,040 --> 00:35:02,640
going to format we format the instruction and here we're going to use this instruction then

272
00:35:02,640 --> 00:35:14,080
break line then we can finally put the original instruction and break line break line and here

273
00:35:14,080 --> 00:35:21,440
we can put like output or response and go for response and another break line why this one

274
00:35:21,440 --> 00:35:26,720
honestly there's no good reason you could imagine a lot of different prompt templates but it's going

275
00:35:26,720 --> 00:35:33,920
to be nice to see that the function model will follow this prompt template finally we can return

276
00:35:34,000 --> 00:35:41,280
example and we map that using the map method from the data set object and this will

277
00:35:43,840 --> 00:35:48,640
yeah this will change all of our instructions so they can follow this template we're going to

278
00:35:48,640 --> 00:35:58,880
visualize it when okay it's done let's go back a bit earlier so we managed to remove

279
00:35:58,880 --> 00:36:07,840
sorry a bit earlier so yeah we filtered everything that we wanted to filter we filtered out like

280
00:36:08,400 --> 00:36:15,840
8k samples like I mentioned previously then there's a top case sampling where we said we only want to

281
00:36:16,480 --> 00:36:26,240
keep the top 1000 samples in terms of token counts so the one with the most tokens and you can see

282
00:36:26,240 --> 00:36:33,360
here the distribution of token counts for instruction only for token counts and finally

283
00:36:34,160 --> 00:36:40,000
the distribution of token counts for instruction for output you can see we don't have samples with

284
00:36:40,000 --> 00:36:46,880
less than 1000 samples thanks to the top case sampling yeah it should make sense hopefully

285
00:36:46,880 --> 00:36:52,320
so here we have 1000 samples with a lot of tokens and they should be high quality because

286
00:36:52,320 --> 00:36:57,520
they're not close to each other we need to duplicate them so it means that

287
00:36:57,520 --> 00:37:03,680
they should be pretty far away from each other here you can see all the 1000 rows once again

288
00:37:03,680 --> 00:37:09,040
you can click it here if you want to have a good overview of the samples that we that were selected

289
00:37:09,760 --> 00:37:16,400
and now they should follow our chat template so just let's check if if this is correct

290
00:37:17,040 --> 00:37:24,880
and here you can see the instruction let's click it here we really have like the instruction

291
00:37:24,880 --> 00:37:33,120
and the response as mentioned here so this is working as intended instruction response and

292
00:37:33,120 --> 00:37:42,960
here is the response that we want the model to follow all right so this is done and the final

293
00:37:42,960 --> 00:37:48,960
thing that we can do here this is optional this is if you have a hugging phase hub count if you

294
00:37:50,560 --> 00:37:57,040
put the value here of your secrets then you can just push the data set to the hugging phase hub

295
00:37:57,920 --> 00:37:58,400
like this

296
00:38:02,240 --> 00:38:10,480
and we specify the token here i'm calling it mini platpus you can call it however you want

297
00:38:11,040 --> 00:38:20,320
um and this is going to upload it and you can even check if it's correctly uploaded if I go

298
00:38:20,320 --> 00:38:26,240
to my hugging phase account and I check my data set this one was uploaded dated less than one

299
00:38:26,240 --> 00:38:33,840
minute ago and here you can see our entire data set uh cool so we have everything

300
00:38:34,160 --> 00:38:42,800
now uh and we're ready to go to fine tuning uh I hope it was it was clear uh and if not I hope

301
00:38:42,800 --> 00:38:49,840
that the solution notebook will help you uh to to to create your own data sets to go further beyond

302
00:38:49,840 --> 00:38:56,160
that you can create synthetic data using um 24 it's something that is used quite a lot and it

303
00:38:56,160 --> 00:39:01,760
creates uh really good uh data sets so it is something that you can play with and otherwise

304
00:39:01,760 --> 00:39:08,080
it's really like a manual reviewing you can import this data set in google sheets and really

305
00:39:08,080 --> 00:39:15,440
manually review every row possible maybe create some regex to automate the process a little bit

306
00:39:15,440 --> 00:39:22,240
but this is a very time consuming process but it's also like very nice because then people

307
00:39:22,240 --> 00:39:29,760
can reuse your data sets if you share them but now let's go to the fine tuning uh notebook

308
00:39:30,640 --> 00:39:37,680
you should also have it uh let me uh check the the chat uh okay you have the solution notebook

309
00:39:38,560 --> 00:39:46,800
cool um so here you have um lama 2 and we're going to delve deep into the fine tuning process so

310
00:39:46,800 --> 00:39:50,880
as mentioned previously there are two ways of fine tuning these models this supervised fine

311
00:39:50,880 --> 00:39:57,200
tuning this is what we're gonna do uh so we're gonna tune it on a set of instructions and responses

312
00:39:57,200 --> 00:40:04,800
it's going to help the model focus where we want um so to be helpful to follow the chat template too

313
00:40:05,360 --> 00:40:11,040
and there's also the reinforcement learning from human feedback where we want the model to

314
00:40:11,040 --> 00:40:15,920
maximize your word signal i'm not going to delve into that uh there are a lot of good articles

315
00:40:15,920 --> 00:40:22,560
about it uh it's able to capture more complex uh preferences but it's also like more difficult to

316
00:40:22,560 --> 00:40:32,720
implement and in practice uh most um if not all this this year but except this year nearly all

317
00:40:32,720 --> 00:40:38,160
the state-of-the-art open source LLMs just use supervised fine tuning so yeah something to keep

318
00:40:38,160 --> 00:40:45,440
in mind um and once again there's an example uh from a few months ago now the NEMA paper that

319
00:40:45,440 --> 00:40:51,120
shows that only 1000 high quality samples can really make the difference and and get very far

320
00:40:51,120 --> 00:40:57,840
um in this case when you have a 65 billion models um and i want to mention the open LM

321
00:40:57,840 --> 00:41:04,320
leaderboard you might be familiar with it um but this is quite useful to see uh what are the best

322
00:41:04,320 --> 00:41:11,520
models so currently you have like this non-Lama model um i wanted to uh yeah show this Godzilla

323
00:41:11,600 --> 00:41:21,120
2 7b model because um it's using a Lama 2 70b and um uh i saw that it was using my data set so

324
00:41:21,120 --> 00:41:26,320
when i was telling you like yeah it's nice to also share your data set you see like sometimes it can

325
00:41:26,320 --> 00:41:32,400
be reused by other people without uh you knowing anything about it but i'm glad this one was useful

326
00:41:32,960 --> 00:41:40,800
um so what we're going to do here is um as previously we are going to start by installing

327
00:41:40,800 --> 00:41:48,000
all the libraries that we want so in this case we're going to go pip install queue and we're

328
00:41:48,000 --> 00:41:53,920
going to update because uh Google collab already has some of these libraries but we want to use

329
00:41:53,920 --> 00:42:01,760
really like the latest version available in this case bits and bytes and 1db transformers

330
00:42:01,760 --> 00:42:11,120
and the hugging face oops i'm going to disconnect this session okay uh once again you can use a

331
00:42:11,120 --> 00:42:16,880
t4 gpu for the entire uh notebook here i'm just going to use the v100 because it's going to be

332
00:42:16,880 --> 00:42:23,280
faster transformers for the transformers data set for the data set accelerating it's it's to make

333
00:42:23,280 --> 00:42:29,280
things uh faster pft it's going to be for the fine tuning process that we're going to use i will

334
00:42:29,280 --> 00:42:36,960
mention it later tl is a wrapper it can be used for supervised fine tuning or for reinforcement

335
00:42:36,960 --> 00:42:41,840
learning from human feedbacks we have bits and bytes for quantization because we are not going

336
00:42:41,840 --> 00:42:47,600
to use the model in full precision and 1db for reporting so we can have a nice dashboard where

337
00:42:47,600 --> 00:42:55,120
we can track the progress of our model um once again we're going to use google collab i'm just

338
00:42:55,120 --> 00:43:03,840
going to copy paste it uh from the previous um notebook so we have our secret token

339
00:43:06,240 --> 00:43:13,040
current access okay um it's optional if you don't have a hugging face account once again

340
00:43:13,040 --> 00:43:18,560
and here we're going to import a lot of libraries we can import os we're going to import torch we're

341
00:43:18,560 --> 00:43:26,000
going to import the data set from data sets and from the transformers library we need to import

342
00:43:26,000 --> 00:43:41,280
a lot of classes uh so auto model for causal lm auto tokenizer uh bits and bytes config auto

343
00:43:41,920 --> 00:43:53,280
auto tokenizer uh training arguments and pipeline when we want to run it um when the model is

344
00:43:53,280 --> 00:44:04,480
trained and then from pft we also need to import a few of them so lower config pft model and something

345
00:44:04,480 --> 00:44:17,280
called prepare model for kbit training and the last one is the wrapper for supervised training

346
00:44:18,160 --> 00:44:27,600
from the tira library called sft trainer um i'm going to let it here for for a second

347
00:44:28,240 --> 00:44:33,280
and um we're going to talk about uh the different ways we can find during this model so we have

348
00:44:33,280 --> 00:44:39,440
three ways there's the full fine tuning there's laura and there is uh q laura with full fine

349
00:44:39,440 --> 00:44:49,680
tuning uh we're going to use um the the entire model so we're going to uh train all the weights

350
00:44:49,680 --> 00:44:56,080
in the model which is very costly then we have laura which instead of training all the weights

351
00:44:56,080 --> 00:45:02,400
we're just going to add some adapters in in some layers and we're going to only train these uh added

352
00:45:02,400 --> 00:45:09,200
weights uh so this really reduces the cost of training the model because we are just going to

353
00:45:09,200 --> 00:45:16,240
train like one percent two percent of the entire weights and finally we have q laura which is using

354
00:45:16,240 --> 00:45:24,480
laura but with a model that has been quantized so uh in this case we're not going to use the model in

355
00:45:24,480 --> 00:45:34,480
six-bit precision so with every weight in the model uh occupying 16 bits on the disc but instead

356
00:45:34,480 --> 00:45:41,680
they're just going to be quantized into four bits so we can lose a bit of precision here but in the

357
00:45:41,680 --> 00:45:48,560
end there are mechanisms to make it less impactful and we'll be able to get a really strong model using

358
00:45:48,560 --> 00:45:58,400
q laura a bit of calculation here we have 16 gigabytes of VRAM with our GPU here you can see

359
00:45:58,400 --> 00:46:09,840
it's 16 gigabytes and um lama 2 7B weights so we have seven billion parameters if they take up

360
00:46:10,480 --> 00:46:18,400
two bytes it means that we're going to use 14 gigabytes so we are almost like using the entire

361
00:46:19,120 --> 00:46:24,400
VRAM and in addition there are like other things there's an overhead due to optimizer stays gradients

362
00:46:24,400 --> 00:46:32,560
for all activations so it's going to be challenging but we we can manage to fit it into only 16 gigabytes

363
00:46:32,560 --> 00:46:43,520
of memory okay so now we're going to really delve into the code to function it um we are going to

364
00:46:43,520 --> 00:46:53,920
reuse the news research model here like previously and we are going to give a name to our new model

365
00:46:55,040 --> 00:47:01,680
so in this case i'm going to call it lama 2 7B and mini platypus

366
00:47:04,160 --> 00:47:12,080
and we're going to reuse the dataset that we just created so it should be called mini platypus

367
00:47:13,040 --> 00:47:18,720
and we're just going to use the train splits finally we have the tokenizer

368
00:47:19,520 --> 00:47:26,320
so here we are going to use the tokenizer from the lama 2 model

369
00:47:27,840 --> 00:47:34,880
and we're going to use the fast version of it we are going to do something that is

370
00:47:35,280 --> 00:47:45,040
um some people hate it we don't have a padding token for lama and this is a really big problem

371
00:47:45,040 --> 00:47:54,880
because we we have a dataset with different number of tokens for each row so we need to

372
00:47:54,880 --> 00:48:01,600
pad it so they all have the same length right and there are different ways of doing it here i'm using

373
00:48:01,600 --> 00:48:07,200
a token called the end of sentence token and this will have an impact on the generation of our model

374
00:48:09,040 --> 00:48:13,840
this is what we're going to use here there are different ways of doing it this is definitely

375
00:48:13,840 --> 00:48:20,880
not the best version of it if you want to learn more about it i linked an article from benjamin

376
00:48:20,880 --> 00:48:27,520
mary about two other ways of doing it and this is what we should do but for the sake of simplicity

377
00:48:27,520 --> 00:48:33,280
here i'm telling you about this problem but i'm still using the end of sentence token for this

378
00:48:34,080 --> 00:48:45,360
fine-tuning then we are going to talk about the configuration of the culor so here bnb config

379
00:48:45,920 --> 00:48:52,400
it's the bits and byte configuration the first thing that we want to do here is to load the model

380
00:48:52,400 --> 00:49:01,520
using four bits otherwise it will not fit into the VRAM in order to do that we can specify the

381
00:49:01,520 --> 00:49:07,760
quant type that we want to use in our case we want to use the nf4 format this is the format that was

382
00:49:09,120 --> 00:49:21,360
introduced in the culor paper and we are going to use a compute type so this is how the weights

383
00:49:21,360 --> 00:49:27,200
are stored using four bits and when we want to compute it's only it's going to use 16 bits so we

384
00:49:27,200 --> 00:49:37,920
have more accuracy and we are also going to use something called double quantization so even the

385
00:49:37,920 --> 00:49:46,800
quantization parameters are quantized it's it's to like really take even less space than without

386
00:49:46,880 --> 00:49:53,200
using it then we have the lower configuration so on top of culor we also have the lower

387
00:49:53,200 --> 00:50:00,480
configuration and in this case we have a bunch of diameters one of them is the alpha the alpha is

388
00:50:00,480 --> 00:50:08,800
basically the strength of the adapter the impact it has on the the model because you can merge these

389
00:50:08,800 --> 00:50:16,080
adapters in a very weak way so using very little weight or using a big weight 32 is a pretty big

390
00:50:16,080 --> 00:50:22,640
weight but this is a quite standard value for this parameter we also have like the dropout because

391
00:50:22,640 --> 00:50:28,640
when we add these adapters they have a little dropout so we have a 5 probability of skipping

392
00:50:28,640 --> 00:50:36,560
these connections and finally we have a rank which is like the dimension of the the matrix that I use

393
00:50:36,560 --> 00:50:45,120
here if you want to know more about law and like a minimalistic implementation of it I made this

394
00:50:45,120 --> 00:50:53,120
notebook called nano law and this goes into in depth into like the theory behind it and we

395
00:50:53,120 --> 00:50:59,440
will help you understand these parameters a bit better we do not want to take care of the bias so

396
00:50:59,440 --> 00:51:04,880
we have the weights and the biases here we do not care about the biases and the task type in this

397
00:51:04,880 --> 00:51:13,520
case is causal lm because we are auto aggressive and the target modules here we have a very long

398
00:51:13,520 --> 00:51:20,720
list of target modules the target modules it's something that you can see here actually

399
00:51:20,720 --> 00:51:30,560
and the attention lma attention thing it's basically like okay what which which modules do you want

400
00:51:32,080 --> 00:51:43,040
to not train but add a law adapter to it and we are going to use a lot of them because

401
00:51:43,040 --> 00:51:49,600
it's been shown to really improve performance so the more modules we have the more

402
00:51:51,040 --> 00:51:58,240
parameters we are going to train but this is fine like we we can afford it with our limited

403
00:51:58,240 --> 00:52:08,880
budget it's going to help us in the long run then we're going to load the model from pre-trained

404
00:52:09,760 --> 00:52:20,480
and we're going to use the base model that we typed earlier the quantization config so we have

405
00:52:20,480 --> 00:52:26,720
the bnb config here this is what we're going to use and finally the device map so here it's

406
00:52:27,680 --> 00:52:36,000
we could also use auto but I'm going to use that it's going to automatically detect the device the

407
00:52:36,000 --> 00:52:40,960
hardware that you have so in our case we'll detect the gpu and make sure that we're using the gpu for

408
00:52:40,960 --> 00:52:47,440
training otherwise it's not going to work and finally we are going to call a function called

409
00:52:48,080 --> 00:52:57,120
model for kb training this will cast the layer norm in fp32 so in more precision it will make

410
00:52:57,120 --> 00:53:05,520
the output embedding layer require grads and add the upcasting to the mlhead to fp32 so what it

411
00:53:05,520 --> 00:53:11,760
means is that it's going to take some layers some modules and make sure that we are using them with

412
00:53:11,760 --> 00:53:17,600
the highest precision possible because it's been showed to really improve the performance too so

413
00:53:17,600 --> 00:53:23,840
yeah there are some modules that we will not that do not really matter some of them matter

414
00:53:23,840 --> 00:53:31,520
quite a lot and we want to be quite proactive on that and in the end this will help us build

415
00:53:31,520 --> 00:53:42,080
the best model possible so if I oops I forgot to execute that um and then if I forgot to execute

416
00:53:42,080 --> 00:53:48,560
that too oh just while you're running those in the bits um the data set sorry I just wanted to

417
00:53:48,560 --> 00:53:53,120
refer to just like just because we're coming up to time um just we are going to over in a bit

418
00:53:53,920 --> 00:53:57,360
before we get to before you all jump off for those of you who have to dash

419
00:53:57,360 --> 00:54:03,040
as I was going to say we've got three webinars coming up next week so on Tuesday we've got

420
00:54:03,040 --> 00:54:09,520
an introduction to snowflake code along coming along uh on Wednesday we've got a session on

421
00:54:09,520 --> 00:54:14,560
using ai in robotics so if you're interested in agreeing on ai then that's uh something uh

422
00:54:14,560 --> 00:54:19,040
definitely worth attending and then on Thursday we've got a session for best practices on putting

423
00:54:19,040 --> 00:54:26,160
lmms into production so three great sessions please do go to datacamp.com slash webinars

424
00:54:26,160 --> 00:54:30,800
sign up for those um we have got some great questions from the audience as well so I'm

425
00:54:30,800 --> 00:54:35,360
hoping to get to those afterwards if you do have to jump that fine uh please do catch up on the

426
00:54:35,360 --> 00:54:40,320
recording for everyone else um I hope you're okay hanging around for a minute and with that I will

427
00:54:40,320 --> 00:54:45,360
dash off and let you uh get back to it Maxine yes sorry about that we should be over in like 10

428
00:54:45,360 --> 00:54:53,680
minutes I underestimated the time uh it takes you to write the code um but um yeah here we have

429
00:54:54,240 --> 00:54:58,960
lower configuration loading the model preparing the model for training uh we are currently

430
00:55:00,240 --> 00:55:04,880
downloading the model here you can see the different modules in the lma attention

431
00:55:06,080 --> 00:55:12,400
class and this those are the one that we target also in the lma mlp you can see the

432
00:55:12,400 --> 00:55:18,080
hugging face implementation of it to to have more details about how it's actually implemented

433
00:55:18,880 --> 00:55:26,240
um once it's done we have more uh boilerplate code uh to to type uh this one it's training

434
00:55:26,240 --> 00:55:33,600
arguments uh so we have the training arguments here and what we want to do is to give like a bunch of

435
00:55:36,320 --> 00:55:43,120
parameters to it so like where do I output the results we're going to specify uh directory for

436
00:55:43,120 --> 00:55:50,640
that uh how many epochs we want to run the model on um here I'm going to put one but let's put four

437
00:55:50,640 --> 00:55:57,040
or five uh basically between three and five it is pretty good for an amateur model at this size

438
00:55:58,000 --> 00:56:04,240
there is the per device uh train batch size uh this will tell us like how many

439
00:56:04,640 --> 00:56:05,840
um

440
00:56:08,160 --> 00:56:13,680
yeah the number of batches that we're going to take for every every every step um

441
00:56:14,400 --> 00:56:19,600
we have the gradient accumulation uh steps we're not going to use it here it's basically a

442
00:56:19,600 --> 00:56:28,240
for loop inside of the um training uh so we don't have to add more um use more VRAM but in this case

443
00:56:28,320 --> 00:56:34,320
it's going to be fine we won't need it we have the evaluation strategy it's not going to be very

444
00:56:34,320 --> 00:56:40,960
useful here because we are not going to um evaluate this model um we just want to train it

445
00:56:41,600 --> 00:56:46,960
and we're going to mention what evaluation looks like with uh uh these models a bit later

446
00:56:47,840 --> 00:56:53,600
logging steps we want to log every step uh the optimizer that we're going to use is the

447
00:56:54,320 --> 00:57:00,720
adam optimizer uh but a version that is paged in eight bits so it's going to lose

448
00:57:00,720 --> 00:57:08,240
test memory uh the learning rate uh we are going to use uh this one there are different

449
00:57:08,240 --> 00:57:15,200
learning rates that that what we can use um refer to the qloa because qloa really impacts

450
00:57:15,200 --> 00:57:19,760
the learning rate the the model also really impact the learning rate that you want to use

451
00:57:20,480 --> 00:57:27,280
we have the scheduler uh in this case we're going to use linear and warm up steps

452
00:57:29,440 --> 00:57:36,960
like it won't be really useful here but we can say uh 10 uh to warm up the the optimizer

453
00:57:36,960 --> 00:57:43,840
we want to report it to weights and biases and finally uh something that i'm going to put here but

454
00:57:44,320 --> 00:57:54,720
uh remove this line uh for like for real training we're just going to stop after two steps otherwise

455
00:57:54,720 --> 00:57:59,520
it will take like an hour to train the model but yeah you can just feel free to remove this step

456
00:57:59,520 --> 00:58:05,520
if you want a real training so those are the training arguments uh then we need also to use

457
00:58:05,520 --> 00:58:11,840
the fft trainer so the wrap i mentioned earlier and in this case we just specify the model the

458
00:58:11,840 --> 00:58:17,680
training data set uh we don't have an eval data set so i'm just going to reuse the same one

459
00:58:18,240 --> 00:58:28,640
pft config um we specified it um it wants to know the text field here so the instruction field

460
00:58:28,640 --> 00:58:36,640
in our data set in our data set was called instruction um the max sequence length um

461
00:58:37,440 --> 00:58:45,520
so we're gonna go for uh 512 uh you could say like yeah but we we put a threshold at 2k but

462
00:58:45,520 --> 00:58:52,080
we don't have enough VRAM unfortunately uh it it will take like a lot of VRAM to to

463
00:58:52,080 --> 00:58:59,600
to put everything into memory so we we're just gonna stop at uh 500 in this example and finally

464
00:58:59,600 --> 00:59:07,120
we're going to give it the training arguments so this is what we have and when it's done we can

465
00:59:07,120 --> 00:59:15,200
start the training and when the training is done uh we can even save the model uh using that

466
00:59:17,120 --> 00:59:23,760
so we should have yeah the model has been downloaded here and now we are training the model

467
00:59:24,560 --> 00:59:31,120
so this is a loss a training loss and evaluation loss from weights and biases and as you can see

468
00:59:31,120 --> 00:59:36,400
it's a very nice way to tracking the the progress of the model we can see here the warm-up steps

469
00:59:36,400 --> 00:59:43,360
where it's it's pretty bad and then it goes better and better uh you can see the training uh loss is

470
00:59:43,360 --> 00:59:50,000
in blue so it's quite spiky it's a bit noisy the eval loss is in orange it's a lot less noisy

471
00:59:50,000 --> 00:59:56,800
because it's less frequent and something that you can observe uh if you train it for like five epochs

472
00:59:56,800 --> 01:00:04,080
is that the eval loss will go up instead of down uh normally uh traditionally in machine learning

473
01:00:04,080 --> 01:00:09,360
this is a bad thing but with large average model it's been proven uh time and time again that it's

474
01:00:09,360 --> 01:00:16,320
actually desirable and the best models um actually like overfit really a lot on the training data

475
01:00:16,320 --> 01:00:22,720
and this is not a problem actually this makes them better um here as you can see your model

476
01:00:22,720 --> 01:00:28,160
has already been trained for two steps so if you want you can add more steps you can remove it if

477
01:00:28,160 --> 01:00:33,520
you want to train it on the entire data set it will take a while however uh we can check um

478
01:00:33,520 --> 01:00:39,600
weights and biases here we won't see any the lot because we only have two steps uh but just to show

479
01:00:39,600 --> 01:00:47,760
you uh here's our run and you can see here the global step uh train run time train loss of 1.2

480
01:00:48,960 --> 01:00:52,880
so yeah this is what you would use if you run it on the entire data set

481
01:00:54,640 --> 01:01:03,280
finally we can um use our model now that it's been it's been trained uh we can prompt it and say

482
01:01:04,000 --> 01:01:14,560
what is a large language model uh we have to wrap it using the right uh chat template so with

483
01:01:14,560 --> 01:01:24,240
instruction prompt and and then response

484
01:01:28,480 --> 01:01:38,480
and we can use a a pipeline here uh from hugging face it's going to be pretty nice so model

485
01:01:39,120 --> 01:01:49,120
tokenizer equal to tokenizer and we're going to restrict the generation in 128 and finally

486
01:01:49,120 --> 01:01:59,280
we can get the result here and print it so i'm going to print the generated text it's an object

487
01:01:59,280 --> 01:02:07,440
that returns um and we can do something fancy and remove the instruction part this is a question

488
01:02:07,440 --> 01:02:13,440
that a lot of people ask me like why do i see the instruction uh in the generation in the generated

489
01:02:13,440 --> 01:02:20,880
text you can just trim it basically this is how the hugging face object works but you can remove

490
01:02:20,880 --> 01:02:27,200
it manually like this so now the train model is going to answer the question what is a large

491
01:02:27,200 --> 01:02:36,960
language model and it will print um the answer here then we want to delete it okay we have the

492
01:02:37,040 --> 01:02:43,280
answer so what is a neural network no the answer is a large language model is a type of artificial

493
01:02:43,280 --> 01:02:48,160
intelligence model that is trained large amount of text data to generate human like text which is

494
01:02:48,160 --> 01:02:53,040
pretty good actually um not thanks to our fine tuning because it was not intense enough but

495
01:02:53,040 --> 01:02:57,840
it's a pretty good answer and then you can see that it keeps repeating like instruction response

496
01:02:57,840 --> 01:03:02,640
instruction and this is because of our padding actually it's because we're using the end of

497
01:03:02,640 --> 01:03:12,080
sentence token as a padding token so now it just doesn't stop and keeps talking so if you

498
01:03:12,080 --> 01:03:17,120
don't want to have this behavior please use a different padding technique as mentioned previously

499
01:03:18,960 --> 01:03:27,040
finally we want to remove a lot of things so this is specific to google collab we want to

500
01:03:27,840 --> 01:03:34,960
collect all the model and the objects in the in the memory in the VRAM so we can merge it with the

501
01:03:35,920 --> 01:03:43,360
so we can merge the base model with the adapter that we trained this is a piece of code that is

502
01:03:43,360 --> 01:03:49,120
difficult to understand why do we need to call it twice honestly I do not know I just know that it

503
01:03:49,120 --> 01:03:58,480
works when I do it and actually and sometimes it doesn't work so well worst case scenario you can

504
01:03:58,480 --> 01:04:06,800
just like restart the the collab and and just execute this part of the code but here for the

505
01:04:06,800 --> 01:04:18,720
sake of time I am going to copy paste the code so we are going to re reload the base model here

506
01:04:19,200 --> 01:04:25,520
and we are going to also load the adapter so the cooler adapter that we

507
01:04:27,040 --> 01:04:34,880
we created you can see it here this is our cooler adapter with adapter config adapter model

508
01:04:34,880 --> 01:04:46,240
and this is what we want to to load hopefully it will work and and then we can push our model

509
01:04:46,240 --> 01:04:53,280
to the hugging face hub when we do that we are going to push the model and the tokenizer and

510
01:04:53,920 --> 01:05:01,200
we're using the hf token here this is optional of course and this will upload it to our

511
01:05:03,680 --> 01:05:11,360
our hugging face account so here we are merging and unloading the model we are going to reload

512
01:05:11,360 --> 01:05:19,360
the tokenizer not just in order to save it too and it's going to be uploaded okay so this is the

513
01:05:19,360 --> 01:05:28,400
end of this session sorry it's a bit late but if you want to go further just know that you should

514
01:05:28,400 --> 01:05:36,160
be able to reuse use this entire collab notebook with mistral 7b instead of flama 7b mistral 7b

515
01:05:36,160 --> 01:05:42,480
is a better model but the name of this talk was fine-tuning llama 2 so I stuck to llama 2

516
01:05:43,120 --> 01:05:50,960
but I would yeah I encourage you to try it out if you want a better fine-tuning tool I recommend

517
01:05:50,960 --> 01:05:55,760
actual tool because these Google collab they're really nice to understand the theory behind everything

518
01:05:55,760 --> 01:06:04,560
and be able to implement this fine-tuning process on your own but if you want to really

519
01:06:05,360 --> 01:06:12,000
fine-tune state-of-the-art open source LLMs I recommend actual tool it's really a great tool

520
01:06:12,000 --> 01:06:18,320
I've been using it a lot of people have been using it and this is quite easy to use so yeah

521
01:06:18,320 --> 01:06:25,200
this is a good recommendation and then what you can do with this model is you can evaluate it

522
01:06:25,200 --> 01:06:30,560
using a evaluation harness you can even get on the open LM leaderboard if you have a good model

523
01:06:31,520 --> 01:06:38,240
or you can quantize it so you would make it easier to execute on consumer grade hardware

524
01:06:38,240 --> 01:06:46,880
and you could use your fine-tune model on your own GPU so that's it for me it will take a while

525
01:06:46,880 --> 01:06:51,360
for the model to be pushed to the hub because it's quite it's quite big but as you can see it's

526
01:06:51,360 --> 01:06:59,360
been merged and everything is working correctly so I hope that you found it useful and if you

527
01:06:59,360 --> 01:07:04,880
have any questions maybe now it's the time to ask the question to answer the questions

528
01:07:06,080 --> 01:07:11,920
all right thank you Maxim that was fantastic a lot to unpack there I actually have like

529
01:07:11,920 --> 01:07:16,400
a lot of questions for you but I think if I start asking questions we're going to go on

530
01:07:16,400 --> 01:07:21,040
longer than an Ed Sheeran concert so I'm going to stick to audience questions instead

531
01:07:21,520 --> 01:07:30,480
let's go with this one first from Prudine so Prudine is saying like maybe don't need to show

532
01:07:30,480 --> 01:07:35,680
this but how do you go about querying tabular data so I mean this is very much focused on we've just

533
01:07:35,680 --> 01:07:43,120
got a lot of text if it's tabular data what's the difference for tabular data I would not

534
01:07:43,120 --> 01:07:49,680
recommend using LLMs because they've really made for for text there are some yeah actually I'm

535
01:07:49,680 --> 01:07:54,960
wondering like I don't know maybe maybe we can't get into too much detail but is the standard like

536
01:07:56,240 --> 01:08:00,960
if you've got just a text file or once if you've got like a pandas data frame of text

537
01:08:02,320 --> 01:08:08,800
yeah this is a good question actually you could see it when we uploaded our data set to the

538
01:08:08,800 --> 01:08:15,760
hiking phase hub this is kind of a data frame but it only has a text so if we go back to the

539
01:08:15,760 --> 01:08:20,080
data set that we've dealt here you can see like it's basically data frame with instruction

540
01:08:20,080 --> 01:08:28,400
output columns but it's not it's not tabular right it's it's really text yeah okay interesting

541
01:08:29,040 --> 01:08:36,000
all right next question comes from Kiran saying okay so we've been doing this fine tuning on a GPU

542
01:08:36,000 --> 01:08:40,240
do we also need a GPU at the point where we're hosting these things is it just the training bit

543
01:08:40,320 --> 01:08:46,400
that's computationally intensive or is it also inference no the inference is also like very

544
01:08:46,400 --> 01:08:53,360
intensive unfortunately and you definitely need well you need a GPU in general but in particular

545
01:08:53,360 --> 01:09:06,720
if you use lama.cpp I can show it on my screen if you use lama.cpp you can use it on a CPU

546
01:09:06,720 --> 01:09:16,800
you can see it sorry I'm gonna you can see it here it's me like running it and it runs on on a CPU

547
01:09:17,840 --> 01:09:23,680
you'll have to compromise a little bit because like you need to lower the precision of the model so

548
01:09:23,680 --> 01:09:32,320
it's smaller and faster to execute but this is something that you can do on the CPU

549
01:09:33,200 --> 01:09:37,680
all right very good so um for anyone who's interested in lama.cpp I know I've got a

550
01:09:37,680 --> 01:09:44,000
tutorial on that perhaps Reece can post a link to that in the moment next question

551
01:09:44,800 --> 01:09:53,280
comes from Minfem so it looks like you you got some fancy co-pilot action or some sort of

552
01:09:53,280 --> 01:09:59,280
autocomplete thing going on there in co-lab where does it what's that tool yeah it's a tool called

553
01:09:59,280 --> 01:10:04,320
codium and yeah it works really well with Google collab as you could see I don't know if it learned

554
01:10:04,320 --> 01:10:11,360
from my own code but it was like really accurate this time I spoke well when you're practicing

555
01:10:11,360 --> 01:10:17,040
rehearsing the the tutorial you probably have the same thing a few times so yeah yeah good way to

556
01:10:17,040 --> 01:10:25,600
train it yeah I mean they're training dataset now nice okay so codium's the thing uh next thing

557
01:10:25,680 --> 01:10:31,920
comes from from Wei saying uh how important is parameter tuning during function I guess that's

558
01:10:31,920 --> 01:10:37,280
like hyper parameter tuning yeah it's a really good question for some of the hyper parameters

559
01:10:37,280 --> 01:10:43,680
going to be very important um and for some of them it's it's more like one percent two percent

560
01:10:43,680 --> 01:10:50,560
gains for example everything here honestly if you stick to like traditional values uh it's it's

561
01:10:50,560 --> 01:10:55,680
gonna make like not super meaningful improvements of course they're important because one percent

562
01:10:55,680 --> 01:11:02,160
two percent it's good to have but they're not yeah that that important uh and there are other

563
01:11:02,160 --> 01:11:08,560
yeah parameters that are a bit more important the learning rate is a really important one

564
01:11:09,680 --> 01:11:14,640
and for this one yeah recommend checking the model that you want to use if you use mistral instead of

565
01:11:15,600 --> 01:11:20,960
lambda two it's going to impact it if you use q lower lower or full fine tuning it's also going to

566
01:11:20,960 --> 01:11:30,880
impact it all right um excellent next one is from bed can you show again how you show how you

567
01:11:30,880 --> 01:11:35,760
load save models maybe we'll skip the using for text generation but if you just cover

568
01:11:35,760 --> 01:11:41,520
loading save models I think that's useful okay so the you save the model by calling the the trainer

569
01:11:42,480 --> 01:11:50,080
object and with the model and save pre-trained new model uh so this is uh yeah just just some

570
01:11:50,080 --> 01:11:57,360
code you need to you know and and then it was the text generation right uh yes uh and in this case

571
01:11:57,360 --> 01:12:04,000
I use the pipeline there are a lot of ways of like using them um it's not super pretty but uh it

572
01:12:04,000 --> 01:12:09,040
doesn't take a lot of lines of code and yeah this is an object from hugging face from their library

573
01:12:09,600 --> 01:12:18,000
which allows you to nicely um use the the text generation for instance okay oh I think the

574
01:12:18,000 --> 01:12:24,160
question is about like once you've saved it how do you load that back okay uh basically just reusing

575
01:12:24,160 --> 01:12:34,080
that and if you check actually um I've uh the model is uploaded on hugging face already and here

576
01:12:34,160 --> 01:12:44,640
you have a usage um section where I describe how you all the code you need to use it so okay

577
01:12:44,640 --> 01:12:50,160
see you're getting the whatever model type is from pre-trained uh pulling back off the hugging

578
01:12:50,160 --> 01:12:58,880
face page all right nice yeah okay so uh next question from Arun saying can you see what percentage

579
01:12:58,880 --> 01:13:06,400
of trainable parameters um we are reduced we're going to have to queue Laura so this is like how

580
01:13:06,400 --> 01:13:10,960
many different I remember you saying queue Laura just changes some of the weights in the model so I

581
01:13:10,960 --> 01:13:18,240
guess you want to know what percentage that is um it's an excellent question I uh I cannot show you

582
01:13:18,240 --> 01:13:27,200
because I deleted the model type in trainer um before but yeah there's a command to do that

583
01:13:27,200 --> 01:13:31,840
I recommend checking on google but yeah definitely you can see exactly like the percentage of

584
01:13:31,840 --> 01:13:38,720
parameters the number of parameters that you're training using either lower or queue lower all

585
01:13:38,720 --> 01:13:46,000
right excellent um and we've got so many more questions uh all right let's just do a couple more

586
01:13:46,560 --> 01:13:47,920
um so

587
01:13:54,080 --> 01:14:03,600
this next one all right okay it's always fine okay so Alexander asks how do you find

588
01:14:03,600 --> 01:14:10,000
tune an LLM so it can extract JSON from differently format that's actually maybe a little bit

589
01:14:10,160 --> 01:14:17,040
um specific but can you talk about how you apply it to like um a sort of you've got a CSV file or

590
01:14:17,040 --> 01:14:26,800
an excel file of text how do you how I guess how do you standardize that data um yeah I I don't know

591
01:14:26,800 --> 01:14:34,320
if it's really a task for an LLM um because there um um if it's just extracting I would say like why

592
01:14:34,320 --> 01:14:41,680
do you want to use an LLM and not something else um other than that um there are different

593
01:14:41,680 --> 01:14:50,480
frameworks like uh JSON former or LMQM even better LMQM let me show you if it's really about the

594
01:14:50,480 --> 01:14:57,760
generation generating a popularly formatted JSON this is a really good uh framework to do it um

595
01:14:57,760 --> 01:15:03,280
there are a lot of them but this one is currently the most popular one uh it's quite easy to use

596
01:15:03,920 --> 01:15:09,200
I'm not sure if we'd answer the questions but I wouldn't use an LLM to extract this information

597
01:15:09,200 --> 01:15:14,400
I would use it to generate a JSON uh and to generate this JSON this is the library I would use

598
01:15:15,760 --> 01:15:23,840
okay uh so LMQL was that all right LMQL yeah LMQL all right that's worth looking into then

599
01:15:23,840 --> 01:15:28,320
all right one very one very last question then since we're well over time anyway we're

600
01:15:28,320 --> 01:15:35,200
we're past limits all right so um how can you improve the forms of LLMs you think basically

601
01:15:35,200 --> 01:15:41,280
what's the what a llama index and lang chain and what's the difference between them um yeah so this

602
01:15:41,280 --> 01:15:48,080
is um you have fine tuning and um lang chain and llama index they are more about like creating this

603
01:15:48,080 --> 01:15:56,880
retrieval augmented generations so um fine tuning is is one way of customizing an LLM for your use

604
01:15:56,880 --> 01:16:03,840
case and the RAG pipeline is another way of doing it so with lang chain and llama index you're going

605
01:16:03,840 --> 01:16:10,480
to retrieve more context using some vector database or regular databases that you have

606
01:16:12,240 --> 01:16:17,120
the difference between them I'm not going to delve into the details LLM index is is

607
01:16:18,560 --> 01:16:24,240
there's less stuff but maybe more in depth than lang chain and I would recommend

608
01:16:25,200 --> 01:16:29,840
actually implementing both approaches so fine tuning your LLM and using this fine

609
01:16:29,840 --> 01:16:34,880
tune LLM with the RAG pipeline and this is where you'll get the best performance possible

610
01:16:36,480 --> 01:16:41,760
all right fantastic we're gonna have to call it a day there I think I know there's more questions

611
01:16:41,760 --> 01:16:45,600
so sorry to everyone in the audience if you didn't get to your question I just want to say thank you

612
01:16:45,600 --> 01:16:50,480
again Maxim that was like incredibly informative and lots of new things that I think we need to

613
01:16:50,480 --> 01:16:57,360
explore so brilliant thank you again thank you to recent moderating oh sorry gone Maxim

614
01:16:58,080 --> 01:17:03,280
thank you Richie and thanks everyone for your patience I know it's been a lot but I hope that

615
01:17:03,280 --> 01:17:08,640
you found it informative so yeah all right brilliant and yeah so thank you to everyone in

616
01:17:08,640 --> 01:17:12,320
the audience who asked the question thank you to everyone who showed up today hope to see you all

617
01:17:12,320 --> 01:17:16,880
again soon lots of exciting webinars coming up so goodbye have a great weekend

