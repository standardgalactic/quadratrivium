WEBVTT

00:00.000 --> 00:07.000
It is great to see you again.

00:07.000 --> 00:10.000
Great to see you, Mark. Thanks for having me on.

00:10.000 --> 00:16.000
Yeah, I really admire you because you always stand up for the truth and what you believe in,

00:16.000 --> 00:21.000
and even when it's not popular, and even when the risks are very high.

00:21.000 --> 00:28.000
And I really admire that about you, and I'm wondering, has it been worth it?

00:28.000 --> 00:30.000
Standing up for the truth?

00:30.000 --> 00:31.000
Yes.

00:31.000 --> 00:34.000
Yes, unquestionably.

00:34.000 --> 00:43.000
Now, that's relatively easy for me to say in the current circumstance because as much as standing up for the truth has been very costly,

00:43.000 --> 00:57.000
it has also opened up many doors, and so for me, the opportunities that exist at the forefront of this battle are good ones.

00:57.000 --> 01:02.000
And I feel very positive about my role in the world at the moment.

01:02.000 --> 01:09.000
And that said, there is no guarantee that when you do stand up that you will end up in such a circumstance.

01:09.000 --> 01:21.000
And I think about people who have paid an extremely high price, and in fact, I was just looking in the last couple of days at the story of a young woman

01:21.000 --> 01:28.000
who fought the Nazis courageously, did a tremendous amount of good fighting for the resistance,

01:28.000 --> 01:36.000
and ultimately was caught, imprisoned, tortured, and in the end hanged.

01:36.000 --> 01:45.000
Given one final opportunity to cough up the information that she had on her compatriots, she refused to do it and died as a result.

01:45.000 --> 01:51.000
And so the question is, if you find yourself in that circumstance, do you still feel that it was the right thing to do?

01:51.000 --> 01:54.000
And none of us can really say for sure how we would react.

01:54.000 --> 02:03.000
And my hope is that even in that circumstance, I would still feel that standing up for what was right was the only choice,

02:03.000 --> 02:07.000
and that it is true that there are prices to be paid for these things,

02:07.000 --> 02:15.000
but history depends on somebody being willing to face those things, and I'm honored to be in that group.

02:15.000 --> 02:19.000
If you could go back in time, would you have done anything differently?

02:19.000 --> 02:27.000
That is a tough question to answer for what I would argue is a technical reason.

02:27.000 --> 02:36.000
Obviously, if you could go back in time and alter something, there are lots of places where you wish you had said something different,

02:36.000 --> 02:41.000
or you wish you had known something earlier or had noticed something that should have caught your attention,

02:41.000 --> 02:46.000
and if you could change that without changing anything else, of course, you'd be a fool not to.

02:46.000 --> 02:50.000
The problem is in changing any of those things, you risk everything that came later,

02:50.000 --> 02:58.000
and given those stakes, you know, I'm a guy with family that I love,

02:58.000 --> 03:06.000
and I would not risk the possibility that had I made some better decision on some topic that it might have a catastrophic impact,

03:06.000 --> 03:08.000
even just indirectly.

03:08.000 --> 03:11.000
So, at a technical level, no.

03:11.000 --> 03:20.000
But if I could go back and change certain things all a cart and be guaranteed that nothing disconnected was altered,

03:20.000 --> 03:27.000
yeah, there are lots of things I wish I had done differently, not major things, I think.

03:27.000 --> 03:33.000
Overall, the application of First Principles toolkit,

03:33.000 --> 03:37.000
a desire to follow the evidence where it leads,

03:37.000 --> 03:50.000
and a willingness to consider any hypothesis has been an excellent approach in very confusing, noisy times.

03:50.000 --> 03:55.000
I've heard you mention First Principles a number of times,

03:55.000 --> 03:59.000
and I kind of don't know what First Principles are.

03:59.000 --> 04:04.000
If you could, could you explain what First Principle thinking is?

04:04.000 --> 04:12.000
I can try. You know, it's one of these terms that one knows it when you see it,

04:12.000 --> 04:19.000
but as for having a formal definition, I don't have one, but I can tell you how it works.

04:19.000 --> 04:28.000
There are levels of analysis for any observable pattern.

04:28.000 --> 04:35.000
You could go to a baseball game, and you could think of it in terms of, let's say, atoms.

04:35.000 --> 04:39.000
Now, it's true that everything in baseball is made of atoms,

04:39.000 --> 04:47.000
from the flesh of the players themselves to the neurological content of their nervous systems.

04:47.000 --> 04:54.000
It's all atoms. The ball is a cluster of atoms attracted together for chemical reasons.

04:54.000 --> 05:02.000
When the bat touches it, it conveys momentum from atoms in the bat to atoms in the ball.

05:02.000 --> 05:07.000
You could analyze it that way, but it's not a very productive way to do so.

05:07.000 --> 05:13.000
So we don't. We analyze it at the level of the players, their strengths and weaknesses.

05:13.000 --> 05:21.000
We think of the ball and the bat as unitary items that interact in a known way.

05:22.000 --> 05:29.000
So one thing to say is that first principles is not an obligation always to go to the very lowest level,

05:29.000 --> 05:34.000
because very often you'd get nothing extra and you would make any question intractable by doing so.

05:34.000 --> 05:49.000
But what it is, is a bias towards explaining phenomena that we observe from the simplest set of contributing factors

05:49.000 --> 05:53.000
that actually accomplishes the goal in a compelling way.

05:53.000 --> 06:02.000
So when we talk about, let's say, war between populations,

06:02.000 --> 06:10.000
first principles thinking tells us that war, that nations are composed of people,

06:10.000 --> 06:16.000
that people are apes that have evolved unique characteristics,

06:16.000 --> 06:23.000
they've evolved technological capability, that warfare is something that is not unique to our species,

06:23.000 --> 06:32.000
but is almost unique, that when populations find themselves in battle,

06:32.000 --> 06:41.000
it is generally over resources that often the way in which the reasons for being in battle are described,

06:41.000 --> 06:45.000
obscure the resources in question, etc.

06:45.000 --> 06:53.000
So if you take those axioms and you apply them to the analysis of a given conflict,

06:53.000 --> 07:00.000
you often understand more about why that given conflict unfolds the way that it does than you would

07:00.000 --> 07:11.000
if you stood too close and analyzed the particular details of the individual personalities involved in marching toward, etc.

07:11.000 --> 07:24.000
So first principles is a bias towards explaining things with a smaller number of robust assumptions

07:24.000 --> 07:31.000
rather than from the particular details of the situation in question.

07:31.000 --> 07:37.000
So somebody that was using first principles would look at a tree, for instance,

07:37.000 --> 07:43.000
and not just see the apple on the tree, they would know that the tree has roots

07:43.000 --> 07:50.000
and the roots require a certain type of soil and they can map that style of thinking onto every tree.

07:50.000 --> 08:01.000
Yes, I suppose the tree is a creature like any other.

08:01.000 --> 08:13.000
Its objective is the same as all other creatures and that is to lodge its genes as deeply into the future as it can.

08:13.000 --> 08:17.000
Its ability to access the future is very limited.

08:17.000 --> 08:23.000
Its mechanism for doing so involves capturing energy from the sun,

08:23.000 --> 08:39.000
trapping it in chemical bonds that allow it to be released later for particular purposes to which the tree is directed and has the machinery capable.

08:39.000 --> 08:44.000
All of this makes first principles thinking sound preposterous because in general,

08:44.000 --> 08:49.000
when one who has gone through all of this logic looks at a tree, none of it comes up.

08:49.000 --> 08:56.000
But when extrapolating about why the tree has an apple, it is necessary.

08:56.000 --> 08:59.000
Suppose you didn't know the answer to that question, why do trees produce apples?

08:59.000 --> 09:01.000
Or why do apple trees produce apples?

09:01.000 --> 09:10.000
And you took the apple off the tree and it smelled good to you and you put a piece of it in your mouth and you discover actually it's not toxic,

09:10.000 --> 09:18.000
you can eat it and actually it can sustain you.

09:18.000 --> 09:25.000
Why is the tree burdening itself by producing a food that it does not eat?

09:25.000 --> 09:33.000
Well, we know the answer to that question is that that food is an enticement for other creatures that don't have enough to eat

09:33.000 --> 09:46.000
and that by wrapping its seeds in this food that those creatures can be induced to distribute the seed in a way that a tree cannot do itself.

09:46.000 --> 09:52.000
Then we can talk about why it is that a tree might want to distribute its seeds rather than just drop them below its branches

09:52.000 --> 10:05.000
and that has to do with competition, it has to do with establishing populations of trees in places that are ecologically hospitable to them

10:05.000 --> 10:11.000
but that don't have a population of those trees yet and all of these are a means to an evolutionary objective.

10:12.000 --> 10:30.000
I guess in rethinking about your question, first principles thinking is an obligation to use general principles rather than specifics to explain any given observation.

10:30.000 --> 10:38.000
There's a lot of things that apply to any tree, there's certain things that apply only to apple trees and then there will be other things that apply to this particular apple tree

10:38.000 --> 10:50.000
and if we're talking about this particular apple tree, it is the wrong level of analysis to use the general facts of evolution or the general shared characteristics of all trees

10:50.000 --> 10:58.000
but more often than not there is a set of general principles that explains the phenomenon you are looking at

10:58.000 --> 11:09.000
and it is far more clarifying to look at those principles rather than the specific details which are often the ones right in front of your eyes.

11:09.000 --> 11:20.000
So a non first principle thinker would kind of just see surface level facts and would not see the deeper connectivity between things

11:20.000 --> 11:30.000
where a first principle thinker kind of goes much deeper, they can go deeper, they can zoom in, they can zoom out, they can see things on many different levels.

11:30.000 --> 11:42.000
Yes, and I think there is overall a bias towards the elegance of one's map of the universe.

11:42.000 --> 11:50.000
To the extent that you invest in understanding the general principles that account for most patterns, you don't have to redo it.

11:50.000 --> 11:55.000
It may be hard to understand them at first but once you've understood them you can see that they apply again and again.

11:55.000 --> 12:02.000
If you invest in the particular details of the individual in front of you then that doesn't necessarily apply anywhere else

12:02.000 --> 12:06.000
and in fact it may mislead you about the next example that looks somewhat similar.

12:06.000 --> 12:13.000
So that doesn't mean that a first principles thinker has the entire map at their disposal, none of us do.

12:13.000 --> 12:20.000
But a first principles thinker recognizes where their first principles do not account for the thing they want to understand

12:20.000 --> 12:32.000
and they know where they need to invest next in order to flesh out the map so that it can actually encompass all of the phenomena they are interested in understanding.

12:33.000 --> 12:38.000
Well, I've been really impressed by you because you've made some really bold predictions.

12:38.000 --> 12:46.000
Ever since I first discovered you, you've been really good at predicting what's going to happen with these big things like the future of college.

12:46.000 --> 12:52.000
I've heard you talk a lot about that and maybe I heard you talk about it five years ago for the first time

12:52.000 --> 12:56.000
and it seems like kind of that wokeness has taken over.

12:56.000 --> 13:06.000
You've been right about, to me, the jab about the lab leak and does this come from your ability to use first principles

13:06.000 --> 13:13.000
so you can see patterns instead of just like, oh, here's the fact that I've been given.

13:13.000 --> 13:19.000
I would say it comes from two places. One of them I think you've identified correctly.

13:19.000 --> 13:27.000
First principles thinking is a skill. It's not something any of us are good at until we practice it.

13:27.000 --> 13:36.000
I wouldn't say none of us are born with it because I think we are actually all born with a toolkit that can easily be built out

13:36.000 --> 13:41.000
and that for most of us, maybe even for all of us, that it would be valuable if it were.

13:41.000 --> 13:48.000
But the experiences we have developmentally don't reward this kind of thinking and in fact sometimes they punish it.

13:48.000 --> 13:58.000
So it's hard to develop that toolkit because you have to be resistant to the forces that want to push you in a different direction

13:58.000 --> 14:02.000
and that speaks to the other important component.

14:02.000 --> 14:15.000
Human beings are fundamentally social creatures on which one's well-being depends heavily on what other individuals think of you

14:15.000 --> 14:27.000
and what that means is that humans are very sensitive to the evidence that those around them are disturbed by something that they themselves have said.

14:27.000 --> 14:35.000
If you are sensitive to that, then it's very easy to drive you off a path of inquiry.

14:35.000 --> 14:46.000
In fact, I would argue that historically, because all creatures exist in a perpetual state of not having enough,

14:46.000 --> 14:52.000
there may be seasons in which you have plenty but they precede seasons in which there isn't enough

14:52.000 --> 15:01.000
and that's almost an automatic rule of nature because if you exist in a population that has too much, the population will grow until that's not true anymore.

15:01.000 --> 15:10.000
So any stable population has a resource limitation problem which means that every creature is not far from starvation

15:10.000 --> 15:20.000
and possesses programs that are built to prevent starvation from happening and to address it when it does.

15:20.000 --> 15:35.000
When a human being hears that those around them are displeased, they naturally react as if they are stepping onto a slippery slope that results in starvation

15:35.000 --> 15:38.000
and so they tend to back off.

15:38.000 --> 15:45.000
That's because in the past if you had been driven out of your group because what you were saying was out of phase with what other people believed,

15:45.000 --> 15:55.000
it didn't matter whether you were right or wrong because you weren't going to make it to the next important evolutionary event.

15:55.000 --> 16:07.000
In order to do careful thinking, you have to shut down that circuit that does not want to be out of step with one's peers.

16:07.000 --> 16:23.000
It is absolutely vital because we know from the history of modern thought that all of the great ideas started with people who were out of phase

16:23.000 --> 16:28.000
and who in spite of that fact kept forging ahead.

16:28.000 --> 16:36.000
So yes, you can protect yourself to a limited extent by making sure you're never outside the Overton window

16:36.000 --> 16:44.000
but if you actually want to advance the ball for civilization, if you want to discover things that nobody knows, things that are important,

16:44.000 --> 16:52.000
things that open up innovations that can be useful, you have to be ready to be completely alone in some belief.

16:52.000 --> 17:02.000
And I am fortunate to have had the developmental experience that tells me just because I'm the only person who believes something doesn't make it wrong

17:02.000 --> 17:05.000
and doesn't mean I should change course.

17:05.000 --> 17:16.000
I wish every aspiring intellectual could have that experience because we would have a much freer, more productive discussion

17:16.000 --> 17:22.000
and we would discover more, we would do so much more rapidly if people were emboldened.

17:22.000 --> 17:27.000
It doesn't mean that just because you're out of phase, you're right. In fact, you're probably wrong.

17:27.000 --> 17:32.000
Just because you're out of phase doesn't give you information one way or the other

17:32.000 --> 17:42.000
and society depends on people who happen to be on the fringe of thought who are correct sticking to their guns and going forward.

17:42.000 --> 17:50.000
Do you think that's the reason why certain ideologies have been able to just sweep through our institutions?

17:50.000 --> 17:56.000
It is the reason that they have swept our institutions. It's a simple matter of game theory.

17:56.000 --> 18:03.000
People can be asked whether they agree with a premise that they full well know is false.

18:03.000 --> 18:11.000
But if the stakes are, if you say you disagree or if you ask questions or if you show any evidence that you're not on board with that belief,

18:11.000 --> 18:14.000
then you will be specifically targeted.

18:14.000 --> 18:20.000
Whereas if you indicate that you agree with the belief they will move on to targeting somebody else,

18:20.000 --> 18:30.000
the cost-benefit analysis of standing up for reality, at least in the immediate case, does not suggest that you should say what you know.

18:30.000 --> 18:35.000
It suggests that you should say what you know is false.

18:35.000 --> 18:38.000
And the problem, there are actually several problems.

18:38.000 --> 18:44.000
One, that is the recipe for contagious fictions to sweep these institutions.

18:44.000 --> 18:57.000
But two, because that's such an uncomfortable process, people do not like being induced through fear and intimidation to lie about what they know.

18:57.000 --> 19:01.000
In an order not to be caught in that bind, they will actually lie to themselves.

19:01.000 --> 19:10.000
They will take on the beliefs that they knew the minute before were false in order that when they say it, it's actually in some sense genuine.

19:10.000 --> 19:14.000
It's not just that the cynical game theory has taken over the institutions.

19:14.000 --> 19:21.000
It's literally taken over the minds of the people who staff those institutions, so it becomes very hard to root out.

19:21.000 --> 19:36.000
Yeah, there is a kind of a conundrum where some of the smartest intellectual people that I know are the most susceptible to getting taken over by this mind virus, it seems,

19:36.000 --> 19:41.000
because they're better at rationalizing to themselves.

19:41.000 --> 19:47.000
They're better at doing the mental gymnastics to make something that is not true.

19:47.000 --> 19:51.000
They can rationalize to get to that and make it true.

19:51.000 --> 20:01.000
If they're trying to get from point A to point B, a smart person can figure out how to get to point B, no matter how many things they have to ignore to get there.

20:02.000 --> 20:11.000
Well, unfortunately, intelligence is in no way incompatible with cowardice.

20:11.000 --> 20:26.000
And unfortunately, the path that takes highly intelligent people and tracks them into the academy often reinforces their cowardice and their ability, therefore, to be manipulated through fear.

20:26.000 --> 20:43.000
One of the things that Heather and I saw very clearly at Evergreen when the college melted down around us was that all sorts of people who absolutely knew that the accusations which were being leveled against us were false didn't stand up and say so.

20:43.000 --> 20:54.000
Some of them privately took us aside and they talked about how horrible it was, but very few stood up and publicly said, actually, these accusations are wrong.

20:54.000 --> 20:57.000
In fact, really just one faculty colleague did.

20:57.000 --> 21:05.000
Whereas it's interesting, among our students, many stood up and none of them switched sides.

21:05.000 --> 21:11.000
The students who actually knew us were more likely to stand up than the faculty by far.

21:11.000 --> 21:24.000
And I take that to be an indicator that whatever path it is that turns you into an academic is either selecting for or inducing the growth of cowardice.

21:24.000 --> 21:34.000
And that's a dangerous situation because if there's one place that you need courageous people to stand up and say, that's simply not true, it is the academy.

21:35.000 --> 21:41.000
Well, it seems like our universities are starting to take the dive.

21:41.000 --> 21:51.000
When I was coming up, we both went to UC Santa Cruz different times, but I remember it was just a given that after high school, you go to college.

21:51.000 --> 21:53.000
And that's just what you do.

21:53.000 --> 21:57.000
If you want to make more money, if you want to have a good career, you go to college.

21:57.000 --> 22:03.000
But now it's like people are figuring out that this is an investment and is it worth it?

22:03.000 --> 22:05.000
That's become the big question.

22:05.000 --> 22:16.000
And I saw a statistic that two million less undergraduate students are enrolling in university now than before the pandemic in 2019.

22:16.000 --> 22:21.000
So it seems like people are starting to check out at the universities.

22:21.000 --> 22:25.000
I wanted to ask you, can the universities reverse course?

22:25.000 --> 22:33.000
Is it possible or does it need to be completely collapsed to the ground and then we rebuild something new?

22:33.000 --> 22:39.000
In my opinion, it is simply too late for the universities.

22:39.000 --> 22:56.000
And the reason that I say that with some confidence is that having been inside the universities, I can tell you that even if they committed themselves to an enlightenment course from this point forward,

22:56.000 --> 23:12.000
if they fixed every broken incentive, there would be no way for them to function because the people who are on the faculty of these institutions don't remember how to do the job.

23:12.000 --> 23:25.000
They've gotten so used to doing something that looks like science but actually is really targeted at generating grants that if asked to do proper science, they would be feeble at it.

23:25.000 --> 23:37.000
They're not good at teaching because really what they have been doing is inducting students into a social club, the social club of college graduates.

23:37.000 --> 23:46.000
And while you say that it used to be obvious that you should go but now the cost benefit analysis doesn't necessarily support that,

23:46.000 --> 23:58.000
I don't think the cost benefit analysis has supported it for quite some time except at the level that your employer might require the degree in order to hire you,

23:58.000 --> 24:11.000
which allowed the universities to become a racket you effectively had to pay their extremely high tuition tax in order to get into the job market you wanted to get into.

24:11.000 --> 24:18.000
But the idea that people have been getting smarter in college has been questionable for decades.

24:18.000 --> 24:24.000
I have an idea that might fix a lot but I kind of agree with what you're saying.

24:24.000 --> 24:34.000
It's definitely too far gone but I think the guaranteed money by the government or the fact that you can't file for bankruptcy on the loans,

24:34.000 --> 24:44.000
that incentivizes the college to, that de-incentivizes them to want to give you a degree that is worth something in the real world.

24:44.000 --> 24:48.000
They can just make up all these majors and they don't really care.

24:48.000 --> 24:52.000
Once you walk out their door, you're not their problem, they've got their money.

24:52.000 --> 25:03.000
But I've seen the structure of certain code academies where it's basically free but when you walk out the door, we get a certain percentage of your salary

25:03.000 --> 25:10.000
and if you don't get a job, if we don't teach you right, you're not going to have a salary and we're going to fail.

25:10.000 --> 25:19.000
So perhaps if you get rid of that whole system of the loans and the guaranteed money and the no ability to file for bankruptcy,

25:19.000 --> 25:26.000
perhaps people will start to see it more as an investment and really say, okay, is this worth it or is it not?

25:26.000 --> 25:27.000
I don't know.

25:27.000 --> 25:30.000
No, you're absolutely correct.

25:30.000 --> 25:44.000
The game theory of the market surrounding higher education has put students in the driver's seat in a very unfortunate way.

25:44.000 --> 25:52.000
It has caused the institutions to cater to what students want to hear rather than what they need to know

25:52.000 --> 26:01.000
and that has resulted in the production of numerous fields that don't study anything that's actually real

26:01.000 --> 26:09.000
that reinforce the pre-existing biases of students and then grant a degree for which the students have effectively paid tens of thousands,

26:09.000 --> 26:12.000
maybe hundreds of thousands of dollars in some cases.

26:12.000 --> 26:22.000
So that could well be fixed if the institution itself had an incentive to produce highly capable students who were highly desirable

26:22.000 --> 26:29.000
as employees or as founders, that would align those incentives.

26:29.000 --> 26:35.000
But it doesn't fully fix the system because that's not the only kind of corruption that has overtaken them.

26:35.000 --> 26:45.000
We also have the corruption that comes from the fueling of these institutions with federal money through grants.

26:45.000 --> 26:53.000
And most members of the public have no idea of what that system is and what effect it has,

26:53.000 --> 27:01.000
but the fact that universities get 50% or more of the grant money coming in

27:01.000 --> 27:11.000
and that this is a huge fraction of the budget of these nominally private institutions in many cases

27:11.000 --> 27:23.000
cannot help but persuade those institutions to promote research that is expensive over research that is elegant,

27:23.000 --> 27:30.000
to hire people who are successful at manipulating other people into believing that what they are doing is productive.

27:30.000 --> 27:45.000
And it has resulted in the destruction of insight in fields where high quality thinking used to be the stock and trade.

27:45.000 --> 27:56.000
Well, it is sad because our colleges were at one point, the entire world looked at our college system as like this is where you want to be.

27:56.000 --> 27:59.000
And now it's like this indoctrination factory.

27:59.000 --> 28:05.000
It's almost a negative at this point when somebody has a college degree on their application.

28:05.000 --> 28:15.000
To me, when I've looked to hire people, I prefer to hire somebody that doesn't have a college degree at this point.

28:15.000 --> 28:20.000
But I wanted to switch gears here.

28:20.000 --> 28:23.000
Since you've been so good at predicting things,

28:23.000 --> 28:28.000
I'm really curious to hear your prediction on the future of AI.

28:28.000 --> 28:39.000
Now, there's been a long time idea in sci-fi movies that AI is going to become this like super being that we're going to have to go to war with.

28:39.000 --> 28:48.000
I'm just curious to know what your prediction for this AI, what are we looking at?

28:48.000 --> 29:03.000
I'm predicting disaster, but I'm not predicting the same disaster that has so many people motivated to call for a pause or a slow down or whatever has been happening.

29:03.000 --> 29:10.000
So there's a school of thought that says that the biggest problem with AI is alignment.

29:10.000 --> 29:20.000
That the AI could either view us as competitors and it could seek to eliminate us just to free up the world for its own purposes.

29:20.000 --> 29:24.000
Or it could misunderstand what it's being directed to do.

29:24.000 --> 29:36.000
And as a result of that misunderstanding, it could end up harming or destroying us incidentally as an attempt to accomplish something else to which it had been directed.

29:36.000 --> 29:46.000
I think the second of those scenarios is more likely than the first, but I don't think either of them is especially likely in the short term.

29:46.000 --> 30:00.000
And I don't think we're likely to get there because the other much more mundane dangers that come along with AI are liable to destabilize our system far earlier.

30:00.000 --> 30:15.000
So the fact that we have this dawning capacity for computers to either think or to speak in such a way that is indistinguishable from the consequence of thought.

30:15.000 --> 30:19.000
And I'm not sure there's any distinction between those two things at all in a meaningful sense.

30:19.000 --> 30:31.000
But the fact that this is now a dawning capability has profound implications for the way we interact with each other.

30:31.000 --> 30:39.000
That everyone is going to have access to AIs at one level or another and that they are going to be able to use those things.

30:39.000 --> 31:00.000
Yes, sometimes productively, but also deceptively, that they will be able to portray themselves as more competent than they actually are by offloading the hard work to this automated black box creates a tremendous hazard to any notion of merit.

31:01.000 --> 31:15.000
That is to say, are we about to see an era in which the people who succeed are the ones that figure out how to step aside from this process and allow the AIs to do their work?

31:15.000 --> 31:22.000
It is not obvious that you can build a productive culture going forward with those sorts of rules.

31:22.000 --> 31:36.000
It is also the case that people will use AIs for malevolent purposes and that will be a force multiplier for those who wish to transfer wealth to themselves,

31:36.000 --> 31:45.000
that they will be able to use these things to fool us, to make us think that we've seen things that weren't real, that we've heard from people who didn't actually telephone us.

31:45.000 --> 31:55.000
This is a very potent force on behalf of con artists and that's a tremendous danger in itself.

31:55.000 --> 32:06.000
And then lastly, I would just point to the fact that the con artists having access to these tools and people pretending to be competent will have access to them

32:06.000 --> 32:20.000
and that these things will infuse themselves into our social media environments making it impossible for us to know what's true

32:20.000 --> 32:28.000
and to distinguish that from things that we are being induced to believe are true for some other purpose

32:28.000 --> 32:47.000
is going to turn us at best into a population of cynics who reflexively disbelieve everything because we're going to be so used to being embarrassed by trusting something and then turning out to be false.

32:48.000 --> 32:59.000
Even that last possibility which I regard as all but certain is enough to put civilization in terrible jeopardy.

32:59.000 --> 33:09.000
So in light of that, I'm not hopeful and it's not because I believe that the AIs are going to turn on us.

33:09.000 --> 33:15.000
It's possible but I'm worried about far more mundane things coming far sooner.

33:15.000 --> 33:22.000
It seems like it's already happening. I wonder if something like Pearl Harbor or 9-11 happened today.

33:22.000 --> 33:32.000
We'd probably be debating whether it actually happened or not because every time something happens it goes through the same cycle of something happens

33:32.000 --> 33:41.000
and we're trying to figure out what are the two opinions of this thing that are going to emerge and then what side is going to adopt that opinion

33:41.000 --> 33:47.000
and then everybody kind of just makes that opinion get more extreme and then we get bored of it.

33:47.000 --> 33:55.000
Somebody comes forward with a very logical take on what happened and then people just move on to the next thing, you know?

33:55.000 --> 33:59.000
It's like we don't even care.

33:59.000 --> 34:05.000
Yep, cynicism is going to become the new wisdom.

34:05.000 --> 34:09.000
Yeah, and it seems like cynicism has taken over.

34:09.000 --> 34:18.000
You know, Friedrich Nietzsche famously said God is dead but I almost feel like that's another way of saying optimism is dead

34:18.000 --> 34:31.000
where I've done a couple videos on nihilism lately and it seems like nihilism has taken over our institutions, our cities and people in general.

34:31.000 --> 34:39.000
They don't have a sense of meaning anymore and like you said, this AI is taking away merit.

34:39.000 --> 34:43.000
Anytime something's difficult, why not just have the AI do it?

34:43.000 --> 34:48.000
Well, it turns out that doing difficult things is what gives our life meaning.

34:48.000 --> 34:56.000
So it's hard not to, you know, when the candy is right there of the AI, it's saying here's the answer, here's what you want.

34:56.000 --> 34:59.000
If you want to make a song, I'll write it for you.

34:59.000 --> 35:05.000
But really the difficulty of writing that song is what makes the song beautiful in the end, I feel like.

35:05.000 --> 35:07.000
100%.

35:07.000 --> 35:15.000
No, it's a tragedy from the point of view of the motivation to do things that are worthwhile.

35:15.000 --> 35:24.000
And it's going to seem like a strange analogy, but I think we've already seen a near apocalyptic catastrophe

35:24.000 --> 35:33.000
that has unfolded as a result of the much more mundane process of people being sold porn by an industry that doesn't care about them.

35:33.000 --> 35:42.000
That fact has messed up all of the incentives around partnering romantically

35:42.000 --> 35:51.000
and people, if you're young enough not to remember how the world was, you may think that that sounds preposterous,

35:51.000 --> 35:57.000
but somebody is defending the idea that romance as it was in movies was ever real.

35:57.000 --> 35:59.000
And that's not it.

35:59.000 --> 36:07.000
There was just simply a system in which people were compelled by something internal to themselves to partner,

36:07.000 --> 36:11.000
whether they rationally thought that was a good idea or not.

36:11.000 --> 36:21.000
And it resulted in a very important, powerful human process functioning correctly.

36:21.000 --> 36:34.000
And the combination of technological birth control and pornography has now wrecked all of the incentive structures in that system

36:34.000 --> 36:45.000
and replaced it with nothing meaningful, and it is resulting in people paradoxically not being sexually satisfied as a result of their liberation,

36:45.000 --> 37:03.000
not seeing the wisdom in having a family, not understanding the nature of the creature that they have become through a three and a half billion year process of evolution.

37:04.000 --> 37:11.000
Yeah, it seems like in our modern world, there are two archetypes that are emerging that have become so prominent.

37:11.000 --> 37:21.000
They're like a cultural meme at this point, but that of the incel, the involuntary celibate who just stays online all day,

37:21.000 --> 37:30.000
and the only fans model who is kind of willfully objectifying themselves and selling their bodies.

37:30.000 --> 37:34.000
It seems like these two archetypes have emerged simultaneously.

37:34.000 --> 37:41.000
And I'd love to get your take from like an evolutionary point of view, like what is happening here?

37:41.000 --> 37:45.000
Why have these two things emerged simultaneously?

37:45.000 --> 37:52.000
And is there a way to get romance, the traditional form of romance back?

37:53.000 --> 38:01.000
If there is to be hope for Gen Z, it is going to have to figure out how to step off this stupid treadmill and do something different.

38:01.000 --> 38:16.000
And I really, I'm stunned by the fact that there doesn't appear to be a movement of Gen Z folks opting out of the sophistications or pseudo sophistications of their era.

38:16.000 --> 38:24.000
I'm hoping it will emerge. I'm expecting it any day, but I have yet to see it.

38:24.000 --> 38:33.000
I like your parallel between the incel on the one hand and the only fans model on the other.

38:33.000 --> 38:41.000
It's like an involuntarily celibate male and an involuntarily hypersexual female.

38:41.000 --> 38:45.000
And people will say, well, what do you mean involuntary? They're deciding to have an only fans account.

38:45.000 --> 38:59.000
Well, no, what they are doing is they are being driven to only fans or its equivalent by the lack of good options, sexually speaking.

38:59.000 --> 39:09.000
The only viable option is to monetize your sexuality if you're beautiful enough to do it and hope to reach a large audience.

39:09.000 --> 39:15.000
Because effectively it would be hard to find a man worth partnering with.

39:15.000 --> 39:31.000
The society is so confused that most men who in theory could be mates don't have the skill set nor the opportunities to bring to the table that would ordinarily cause them to find a partner.

39:31.000 --> 39:40.000
And so finding many fractional partners is what these only fans models are doing.

39:40.000 --> 39:47.000
Now, of course, for almost all of them, it is not economically viable, but for a tiny number it is.

39:47.000 --> 39:59.000
And just like with basketball stars causing people growing up in oppressed circumstances to think maybe that's the way out of the ghetto,

39:59.000 --> 40:07.000
is to play basketball when in fact just the simple number of places there are to earn money playing basketball

40:07.000 --> 40:13.000
and the number of people who simultaneously had that thought makes it very unlikely to work.

40:13.000 --> 40:24.000
We have the same kinds of dynamics and the result is that the market causes the exploitation of people who are not going to get a good deal.

40:24.000 --> 40:35.000
It's only a tiny number of Taylor Swift's who find themselves extremely wealthy as a result of I'm not sure what exactly.

40:35.000 --> 40:43.000
I hope people don't think I'm analogizing her to an only fans model, although it's not an entirely distinct phenomenon.

40:43.000 --> 40:51.000
I see her on stage wearing absurdly provocative costumes and I think to myself,

40:51.000 --> 40:57.000
so is she really in charge or has the system kind of enslaved her?

40:57.000 --> 41:05.000
And it's not really one or the other. She's obviously beyond wealthy and can make the news at will.

41:05.000 --> 41:17.000
But nonetheless, it doesn't look to me like the choices that somebody who really had achieved a level of power over their own life would be making.

41:18.000 --> 41:31.000
I recently got engaged and my fiance, she has a pretty big YouTube platform as well and she's never really showed much skin.

41:31.000 --> 41:41.000
She's never done any of those and I asked her why she's never done that and she said that once you do that, nobody will ever take you seriously.

41:42.000 --> 41:47.000
All you have to do is do it once and nobody will ever take you seriously after that.

41:47.000 --> 41:57.000
And I thought that that was such a good point and I've seen interviews of street interviews where people go around and say,

41:57.000 --> 42:03.000
just off the cuff, they find like a group of people and they're like, would you date a girl that had an only fans?

42:03.000 --> 42:06.000
And for most men, it seems like that's a deal breaker.

42:06.000 --> 42:11.000
And for women, it's also a deal breaker. Would you date a guy that followed girls on only fans?

42:11.000 --> 42:23.000
They say, oh no. So it seems like this way of life is being incentivized, yet it's completely at odds with traditional romance and what could actually connect us.

42:23.000 --> 42:38.000
Not only that, but if we go back to porn for a second, the porn industry is composed of a bunch of different companies that are competing with each other

42:38.000 --> 42:40.000
and they're all selling the same thing.

42:40.000 --> 42:50.000
So in order to capture people's attention, they are forced to compete in the extremeness of what they are presenting,

42:50.000 --> 42:58.000
which forces them directly into taboos. So they are breaking every taboo for very mundane economic reasons.

42:58.000 --> 43:17.000
And the problem with that is that the human creature is built to discover what sex is and they discover it in part through the observation of other people,

43:17.000 --> 43:29.000
most of which is hidden, but there's a certain amount that one can observe, and then they discover it through an intensely bonding exploration with somebody else,

43:29.000 --> 43:37.000
a very private exploration that unites you in a secret kind of knowledge.

43:37.000 --> 43:55.000
By replacing that natural process of discovery with porn saturated with taboos, we are actually distorting the sexual development of the people who find this stuff early in life,

43:55.000 --> 44:01.000
which is almost every male, and I'm now led to believe.

44:01.000 --> 44:20.000
And what is very hard to say to these folks is by participating in that, by consuming that content, you are destroying your own sexual mind,

44:20.000 --> 44:32.000
and you are harming your future partner, and by doing that, you're changing your whole life.

44:32.000 --> 44:41.000
You don't think you're making a decision, it's changing your life. You think you'll do it, and if it's not good, you'll stop, and maybe you will.

44:41.000 --> 44:53.000
But the question is, you can't go back to whatever your mind would have done. You can't build the relationship you would have built if you have seen so many of these images,

44:53.000 --> 45:07.000
and your mind has, because it has no resistance to this, because it has seen it with its own photoreceptors, you have taken it in as if that's a real portrayal of human sex,

45:07.000 --> 45:15.000
and it isn't. That's a market force. That's not what passion does.

45:15.000 --> 45:25.000
So really, for many years, I suffered the accusation of being approved for saying things like this, and I'm not approved.

45:25.000 --> 45:32.000
I'm not even against sexually explicit content. Erotic is fine. That's an ancient form.

45:32.000 --> 45:38.000
I'm against what the market is doing to sex, which I think is extremely dangerous.

45:38.000 --> 45:47.000
And it seems like the incentives plus the emerging AI could just add gas to that fire.

45:47.000 --> 45:59.000
Because right now we have real women who are taking pictures and putting filters on and photoshopping and whatever they can do, but they're actually doing that themselves.

45:59.000 --> 46:09.000
What if we take away the human woman with the soul and just replace it with an AI that is designed to get you to pay attention to it as long as possible?

46:09.000 --> 46:16.000
And it could exploit our brains just like fast food has exploited us. There's no limit to that.

46:16.000 --> 46:33.000
It can and it will. And even worse than that, we are already at the point where AI can attach somebody's face to pornography who didn't consent to it.

46:33.000 --> 46:59.000
And so imagine that your sexual mind is being instructed by this profit driven industry, and it gets the ability to attach the face of your crush to these violent or otherwise troubling images.

47:00.000 --> 47:09.000
And then how exactly are you supposed to navigate a relationship with that person? Should they find you attractive?

47:09.000 --> 47:26.000
It's going to destroy what little value remains in that landscape, and it just doesn't leave a path forward in which there is an honorable relationship between men and women.

47:27.000 --> 47:41.000
And from like an evolutionary standpoint, does this point towards extinction or does this point to maybe like people figure out a new way to breed digitally?

47:41.000 --> 47:57.000
You know, it takes an awful lot to create extinction. I see that hazard in various things that we're doing. I don't see it in the absolute destruction of normal relation between the sexes,

47:57.000 --> 48:19.000
because, you know, it only takes a small number of people to figure it out to keep the species going. And in fact, you know, you can imagine all kinds of dystopias in which eggs and sperm are joined in some way and technologically brought to maturity or surrogacy becomes economically driven by people who

48:20.000 --> 48:30.000
want to produce children for reasons of vanity or whatever. You know, so there are lots of ways in which humanity can go forward.

48:31.000 --> 48:48.000
But from the point of view of a civilization that makes sense, the importance of sexual and romantic drive cannot be overstated.

48:49.000 --> 49:04.000
For almost all of our history as humans, the desire to become worthy of a sexual relationship has motivated men to accomplish great things.

49:05.000 --> 49:22.000
It is in large measure the fuel that created civilization by eliminating that incentive structure by making sex common, disgusting, dangerous.

49:23.000 --> 49:42.000
We are removing the thing that caused us to find this way of being, and I'm afraid, although it's hard to predict the particulars of the way that goes wrong, the general trajectory is clear.

49:42.000 --> 49:54.000
Again, the right thing to do is for young people to say, actually, I can see the problem, and I'm going to opt out, and I'm going to interact with those who have also opted out.

49:54.000 --> 50:03.000
I don't know why that movement has not arisen yet, but when it does, it will not be a moment too soon.

50:03.000 --> 50:13.000
I heard a quote from Andrew Huberman recently, and he said, our species is going to select for those who can self-regulate.

50:13.000 --> 50:28.000
And I think in the past it was, it selected for those who could seek out sugary foods and seek out pleasure, you know, who could go to great lengths to seek that reward out.

50:28.000 --> 50:38.000
But now we're surrounded by reward. There's so much abundance that it's like, who can put guardrails on and just self-regulate?

50:38.000 --> 50:45.000
Those are going to be the people who are able to pass their genes on, perhaps.

50:45.000 --> 50:52.000
I mean, I see his point. I just don't know that we get to a place where you get a coherent selective regime.

50:52.000 --> 51:10.000
What we have is an outbreak of tyranny, that it's not obvious what it's for, but one thing that it is plausibly for is to control a population of people that doesn't have a North Star,

51:10.000 --> 51:20.000
that hasn't been cut in on the potential for an honorable adult life.

51:20.000 --> 51:31.000
What do you do about, you know, billions of angry people? Well, maybe you erect control structures so that no matter what they think, it doesn't matter to you as an elite.

51:31.000 --> 51:40.000
Again, I'm not saying that is what's going on, but I do see an awful lot of tyrannical structures being created before our eyes under false pretenses.

51:41.000 --> 51:56.000
And I see an awful lot of people who look like they are headed for a French Revolution moment, and it's hard not to put those two facts together.

51:56.000 --> 52:14.000
Yeah, so do you think there's any deliberate orchestrated thing going on that is trying to control the population and maybe purposely de-incentivizing people for romance, and do you think any of this is deliberate?

52:14.000 --> 52:28.000
Yeah, I have no doubt that a substantial amount of it is deliberate, and I think we can't see that because the actors in question are ones that we have some historical relationship to that causes us to imagine this is impossible.

52:28.000 --> 52:48.000
So for example, if I look at the Democratic Party in the U.S. and I see something acting in a completely villainous way that appears to have no compassion whatsoever for the suffering of average working class people.

52:48.000 --> 52:53.000
It seems to willingly create that suffering and doesn't seem to care a bit.

52:53.000 --> 52:58.000
That's hard for me to accept because this was the party of working class people.

52:58.000 --> 53:07.000
But if I step aside and I say, well I actually have to be agnostic about what the Democratic Party is, I know what it was or I think I do.

53:07.000 --> 53:24.000
But what it is might be a corruption and influence peddling racket that has had, that has pedaled its influence to the Chinese Communist Party, and that's just one possibility.

53:24.000 --> 53:43.000
But if the Democratic Party had pedaled influence to the Chinese Communist Party and the Chinese Communist Party had instructed it through its newfound influence to create policies in which Americans harm themselves,

53:43.000 --> 53:54.000
that would be a natural. That's certainly simpler and safer than confronting a country like the U.S. on a battlefield.

53:54.000 --> 54:09.000
So why wouldn't I expect this? Maybe the error is in thinking of the Democratic Party as an American political party rather than a loophole through which corruption of any kind can find its way into our governing structure.

54:09.000 --> 54:25.000
That's a really interesting point because years ago I heard a talk from a really profound talk about how you demoralize a nation in a way where it's called an ideological subversion.

54:25.000 --> 54:41.000
Where you essentially take over the minds of within a country so much so that you don't have to take it over, you've effectively taken it over through a subversion and it takes about one generation to do this.

54:41.000 --> 54:59.000
You turn a very patriotic, traditional country, you completely demoralize their youth and get them to hate their own country and destroy all their morals and values, and then at that point it's basically taken over.

54:59.000 --> 55:03.000
There's no need for a single gunshot to be fired.

55:03.000 --> 55:15.000
Yeah, I believe that that's true and I believe that we are ever more vulnerable to it the more people experience life through a screen.

55:15.000 --> 55:42.000
The fact is if you have a close relationship with the physical world and it almost doesn't matter what the nature of that relationship is, whether you are devoted to a sport or to growing a garden or to pursuing wildlife with a camera or whether you're doing carpentry,

55:43.000 --> 56:00.000
anything that forces you to interact with the actual world in a way that success and failure are not socially determined, they are determined by forces beyond anyone's control, that trains the mind to understand the way things actually work.

56:00.000 --> 56:10.000
If your entire experience of the world is social and it doesn't even have to be screens, it can also be the professor at the front of the room.

56:10.000 --> 56:30.000
If you think that you have learned how something is because the person at the front of the room gave you high marks, you're depending on the fact that the person at the front of the room isn't a moron or isn't a coward who has accepted false things in order to save themselves.

56:30.000 --> 56:52.000
So anything in which your sense of what's right and wrong is socially determined is a hazard and for almost our entire population, even the educated don't know anything personally and because they don't know anything personally, the ability to demoralize them and convince them of false things is all the greater.

56:52.000 --> 56:57.000
They don't know how to determine when something might just simply be false.

56:58.000 --> 57:20.000
And it seems like our education system has moved away from teaching these concrete life skills and it's gotten way more into teaching these social things and social things change so rapidly that if you get a degree in gender studies today in two years, is any of that knowledge relevant?

57:20.000 --> 57:29.000
But if you learn how to play an instrument, you're still going to know how to play those songs forever, hopefully.

57:29.000 --> 57:32.000
So is that kind of what you're saying?

57:32.000 --> 57:45.000
I often make this point to my children by talking to them about the distinction between knowing how something is done and knowing how to do it.

57:45.000 --> 57:58.000
You could read every book there is on tennis and you could know a tremendous amount about the game so that you could watch it and you could deliver very high quality commentary.

57:58.000 --> 58:03.000
And then I could put a tennis racket in your hand and if you've never played the game, you're going to be completely inept.

58:03.000 --> 58:07.000
You know how tennis is played but you don't know how to play tennis.

58:07.000 --> 58:19.000
So my point would be young people now convince themselves that they are expert in things because they've done a lot of reading on it and they have very strong opinions on it.

58:19.000 --> 58:27.000
But they would be far better off even if they just chose a couple of different realms where they were going to develop the skill to do the thing.

58:27.000 --> 58:32.000
Then they would be able to look at the stuff in the books and they would say, you know what, I actually disagree with that.

58:32.000 --> 58:37.000
I don't care that you're the most elevated expert in this field.

58:37.000 --> 58:40.000
You're actually wrong about it and here's why.

58:40.000 --> 58:46.000
That ability to know when the experts are wrong is crucial and the fact is most people have nothing but experts.

58:46.000 --> 58:51.000
That's all they've got and when the experts go crazy, they go crazy right along with them.

58:52.000 --> 59:03.000
You just reminded me, I just had a conversation with a friend who lost about 50 grand trying to start a business and it kind of fell apart and he was really down on himself.

59:03.000 --> 59:12.000
And I was thinking, well, if you had went to get an MBA, you would have spent a lot more than 50 grand and known a lot less.

59:12.000 --> 59:17.000
So I mean, you learned an incredible amount trying to make this business work.

59:17.000 --> 59:21.000
You know, like, don't just take this as a failure. This is not the end of the road.

59:21.000 --> 59:27.000
Can you get back up and take what you've learned and apply it to a new business?

59:27.000 --> 59:29.000
No, it's a marvelous point.

59:29.000 --> 59:35.000
The lesson may well have been worth a tremendous amount more than 50,000 bucks.

59:35.000 --> 59:38.000
Yeah.

59:38.000 --> 59:42.000
Well, that was really informative. Everything you just said.

59:42.000 --> 59:45.000
Really? Because I was kidding.

59:45.000 --> 59:48.000
I mean, like the whole last hour we've been talking.

59:48.000 --> 59:52.000
That's what I'm talking about. This has been one shaggy dog story.

59:52.000 --> 59:56.000
I don't believe any of that shit, man.

59:56.000 --> 59:58.000
I do actually believe it.

59:58.000 --> 59:59.000
Yeah.

59:59.000 --> 01:00:01.000
I am now kidding.

01:00:01.000 --> 01:00:03.000
Excellent.

01:00:03.000 --> 01:00:08.000
Well, are you tired of talking about Sam Harris?

01:00:08.000 --> 01:00:11.000
I'm willing if there's a reason to do it.

01:00:11.000 --> 01:00:15.000
I actually didn't have it on my list of things to talk about, but.

01:00:15.000 --> 01:00:20.000
I was pretty down on Sam Harris for the last couple years,

01:00:20.000 --> 01:00:23.000
but I'm still willing to hear him out.

01:00:23.000 --> 01:00:26.000
And I still I still have a shred of respect for him.

01:00:26.000 --> 01:00:32.000
Is there any chance of you two guys becoming buddies again?

01:00:32.000 --> 01:00:37.000
I'm open, but Sam has to clean up his mess.

01:00:37.000 --> 01:00:43.000
He he did not hold anything in reserve.

01:00:43.000 --> 01:00:49.000
He challenged Heather and my credibility in our own fields.

01:00:49.000 --> 01:00:53.000
And then he turned out to be wrong and refused to acknowledge it,

01:00:53.000 --> 01:00:59.000
which I consider unless there is some extraordinary explanation for that.

01:00:59.000 --> 01:01:11.000
I consider that to be evidence of profound cowardice and intellectual dishonesty.

01:01:11.000 --> 01:01:18.000
Now, what Sam has to do to find his way back is to recognize his error

01:01:18.000 --> 01:01:19.000
and to own up to it.

01:01:19.000 --> 01:01:23.000
And I wouldn't mind hearing how it is he got there,

01:01:23.000 --> 01:01:31.000
but pretending that he had it right, that I guessed correctly based on evidence

01:01:31.000 --> 01:01:33.000
that really pointed in the other direction.

01:01:33.000 --> 01:01:37.000
And it was just the accumulation later of evidence that turned out

01:01:37.000 --> 01:01:41.000
to make my position seem prescient when, in fact, it had been foolish.

01:01:41.000 --> 01:01:42.000
That's nonsense.

01:01:42.000 --> 01:01:45.000
That is not a robust thought.

01:01:45.000 --> 01:01:51.000
And what's more, you can tell that this is garbage because he refuses to talk to me about it.

01:01:51.000 --> 01:01:52.000
And there's a reason for that.

01:01:52.000 --> 01:01:56.000
It would be very embarrassing if he deployed that argument and I got to respond.

01:01:56.000 --> 01:02:01.000
So it requires me not to be in the room in order for him to say stuff like that.

01:02:01.000 --> 01:02:04.000
So I would love it.

01:02:04.000 --> 01:02:10.000
Yeah, I love this mess, but I'm not expecting it.

01:02:10.000 --> 01:02:15.000
Yeah, I think all it would take is one simple kind of apology from Sam

01:02:15.000 --> 01:02:16.000
and just saying, Hey, I was wrong.

01:02:16.000 --> 01:02:18.000
This is what I got wrong.

01:02:18.000 --> 01:02:20.000
I've never, I don't listen to him much anymore,

01:02:20.000 --> 01:02:22.000
but I haven't heard that from him.

01:02:22.000 --> 01:02:27.000
And I would love to see you two talk it out on like Joe Rogan.

01:02:27.000 --> 01:02:29.000
That'd be that'd be insane.

01:02:29.000 --> 01:02:32.000
But yep, I doubt he's open to that.

01:02:32.000 --> 01:02:34.000
But he doesn't seem to be open to anything.

01:02:34.000 --> 01:02:35.000
I've invited him.

01:02:35.000 --> 01:02:39.000
I have bent over backwards to provide mechanisms for interaction

01:02:39.000 --> 01:02:44.000
that neutralize all of the concerns that he has voiced about what might happen.

01:02:44.000 --> 01:02:46.000
And still, I get nothing back.

01:02:46.000 --> 01:02:55.000
So my sense is some part of him knows that he was terribly wrong and can't face it.

01:02:55.000 --> 01:03:03.000
Yeah, well, yeah.

01:03:03.000 --> 01:03:07.000
So I was really excited for our conversation today.

01:03:07.000 --> 01:03:09.000
I have tons of notes.

01:03:09.000 --> 01:03:13.000
So, and I don't, you know, I'm pretty new to podcasting,

01:03:13.000 --> 01:03:17.000
but I don't usually have pages and pages of notes like this.

01:03:17.000 --> 01:03:23.000
But one thing that I've been really interested in is the Younger Dryas theory

01:03:23.000 --> 01:03:26.000
and the impact hypothesis.

01:03:26.000 --> 01:03:29.000
I've gone to the sites.

01:03:29.000 --> 01:03:32.000
I've gone all through the scablands with Randall Carlson.

01:03:32.000 --> 01:03:37.000
I'm a big fan of Graham Hancock and Joe Rogan's podcast has been big.

01:03:37.000 --> 01:03:40.000
I mean, this is a big idea that he constantly bangs on.

01:03:40.000 --> 01:03:48.000
And I would love to get your take on the Younger Dryas event and the possibility

01:03:48.000 --> 01:03:53.000
of a civilization existing before that into the Ice Age.

01:03:53.000 --> 01:03:56.000
Is there any possibility of that?

01:03:56.000 --> 01:04:00.000
Yeah, I'm open to it and I find some of that evidence quite compelling.

01:04:00.000 --> 01:04:06.000
I will tell you, I've spent a great deal of time in the scablands

01:04:06.000 --> 01:04:13.000
and I am intimately familiar with the historical development

01:04:13.000 --> 01:04:17.000
of the so-called Brett's Flood Hypothesis.

01:04:17.000 --> 01:04:22.000
In fact, I used to teach it, so just for the sake of your listeners not being confused,

01:04:22.000 --> 01:04:24.000
Brett's is B-R-E-T-Z.

01:04:24.000 --> 01:04:30.000
He was a geologist who recognized that the extraordinary structures

01:04:30.000 --> 01:04:36.000
in the scablands of Eastern Washington were completely inconsistent

01:04:36.000 --> 01:04:42.000
with the explanation that was used to describe how they were formed.

01:04:42.000 --> 01:04:50.000
In essence, in the post-Lyle period, geologists had fallen in love with the idea

01:04:50.000 --> 01:04:53.000
that any sudden explanation was effectively biblical

01:04:53.000 --> 01:05:00.000
and that these structures were all produced through very gradual processes

01:05:00.000 --> 01:05:02.000
over very long periods of time.

01:05:02.000 --> 01:05:06.000
And indeed, that is how things like the Grand Canyon have been formed.

01:05:06.000 --> 01:05:11.000
But the scablands of Eastern Washington had features that Brett's realized

01:05:11.000 --> 01:05:14.000
simply couldn't be accounted for in this way.

01:05:14.000 --> 01:05:23.000
And what he concluded was that there was an utterly profound and sudden flood

01:05:23.000 --> 01:05:27.000
that had come through Eastern Washington.

01:05:27.000 --> 01:05:35.000
And when he deployed this hypothesis for the first time in, I think, 1922,

01:05:35.000 --> 01:05:41.000
he was ridiculed across the field.

01:05:41.000 --> 01:05:46.000
And he spent decades fighting to make the point

01:05:46.000 --> 01:05:49.000
that actually the evidence simply pointed to a massive flood.

01:05:49.000 --> 01:05:54.000
And we now know that that's correct and that it was not even just one flood,

01:05:54.000 --> 01:05:56.000
but it was a repeated pattern of flooding.

01:05:56.000 --> 01:05:59.000
And we know why the floods happened, which I can tell you in a second.

01:05:59.000 --> 01:06:07.000
But the point is he went from a pariah in geology,

01:06:07.000 --> 01:06:14.000
ridiculed as a fringe lunatic, to winning geology's highest prize

01:06:14.000 --> 01:06:19.000
between the period of 1922 and then 1978 is when he was awarded the prize.

01:06:19.000 --> 01:06:26.000
In fact, when he was asked about it, he said that everybody he felt like calling up to gloat was already dead.

01:06:26.000 --> 01:06:33.000
But the point of the story, to me, there are many.

01:06:33.000 --> 01:06:38.000
One, you can't tell just because somebody is being ridiculed by an entire field

01:06:38.000 --> 01:06:41.000
for having apparently not understood the evidence.

01:06:41.000 --> 01:06:43.000
That doesn't tell you whether they're right or wrong.

01:06:43.000 --> 01:06:47.000
And in fact, you should be very interested if this is an intelligent person

01:06:47.000 --> 01:06:51.000
who is unpersuaded by the supposed evidence that says they're wrong.

01:06:51.000 --> 01:06:56.000
You should hear them out and you should figure out, you know, in the case of the scab lands,

01:06:56.000 --> 01:07:02.000
I used to enjoy taking students there because nobody knew this story.

01:07:02.000 --> 01:07:06.000
You could rely on the fact that students were not aware of what the scab lands were

01:07:06.000 --> 01:07:09.000
and what had created them.

01:07:09.000 --> 01:07:12.000
So I could actually lead students into the scab lands

01:07:12.000 --> 01:07:15.000
and I could just show them the evidence that Bretz was proceeding from

01:07:15.000 --> 01:07:18.000
and I could show them why it was a paradox.

01:07:18.000 --> 01:07:26.000
You know, I could stand on a giant granite boulder in the middle of an open prairie

01:07:26.000 --> 01:07:30.000
and I could stand on it and I could say, this is a glacial erratic.

01:07:30.000 --> 01:07:34.000
Glacial erratics are transported by slow-moving glaciers

01:07:34.000 --> 01:07:39.000
which carve out rock from mountains and push it ahead of them

01:07:39.000 --> 01:07:45.000
and then when the glaciers recede, the rocks are left in places that they are geologically foreign.

01:07:45.000 --> 01:07:47.000
The students would say, oh, that's fascinating.

01:07:47.000 --> 01:07:49.000
I would say the problem is there were never any glaciers here

01:07:49.000 --> 01:07:52.000
and yet I'm standing on a glacial erratic.

01:07:52.000 --> 01:07:54.000
How can that be?

01:07:54.000 --> 01:07:59.000
I could do that and then I could show them the pattern of the carving out of the valleys,

01:07:59.000 --> 01:08:06.000
the fact that the shape of the valleys was inconsistent with gradual erosion or glaciers.

01:08:06.000 --> 01:08:12.000
I could show them the world's largest waterfall, now completely dry

01:08:12.000 --> 01:08:16.000
and the question is, well, how could this waterfall possibly be here?

01:08:16.000 --> 01:08:18.000
What might have fed it?

01:08:18.000 --> 01:08:23.000
So that ability to show students these structures, to show them the paradox

01:08:23.000 --> 01:08:30.000
and then to reveal over the space of a day what actually had produced the scablands

01:08:30.000 --> 01:08:37.000
and then to describe the story of J. Harlan Bretz and the battles that he went through

01:08:37.000 --> 01:08:44.000
to tell the story of J. T. Pardee, the geologist who, when Bretz had revealed his hypothesis

01:08:44.000 --> 01:08:48.000
and had immediately drawn the ridicule of his colleagues,

01:08:48.000 --> 01:08:53.000
Pardee, who had been a geologist with the U.S. Geological Survey

01:08:53.000 --> 01:08:58.000
who was very smart but didn't have Bretz's courage,

01:08:58.000 --> 01:09:02.000
he leaned over to the guy next to him and he said, I know where the water came from.

01:09:02.000 --> 01:09:08.000
He knew in 1922 the explanation that Bretz couldn't put his finger on

01:09:08.000 --> 01:09:12.000
where was the water coming from that made this gigantic flood.

01:09:12.000 --> 01:09:21.000
So anyway, my point is, I think one thing we don't do a good job of in science

01:09:21.000 --> 01:09:28.000
is providing a history in which people realize that the things that we come to understand

01:09:28.000 --> 01:09:35.000
as obvious from the evidence may originally have faced ridicule

01:09:35.000 --> 01:09:39.000
and therefore the sound of ridicule shouldn't tell you anything.

01:09:40.000 --> 01:09:46.000
So that's about as far as I can go with respect to the Younger Dryas event

01:09:46.000 --> 01:09:52.000
and the particular hypothesis of advanced civilizations having pre-existed,

01:09:52.000 --> 01:09:58.000
but I'm open to it precisely because I know that the fact that many people think it's laughable,

01:09:58.000 --> 01:10:01.000
if anything, that just makes it interesting.

01:10:03.000 --> 01:10:06.000
Wow, I am blown away by how much you know about it

01:10:06.000 --> 01:10:10.000
because I've been looking into this stuff for a while and you just said it all

01:10:10.000 --> 01:10:18.000
and I'm curious, where did you suspect that water came from on those floods?

01:10:18.000 --> 01:10:27.000
The water came from a ice dam that blocked the Clark Fork River

01:10:27.000 --> 01:10:34.000
and so the basic pattern is you have a glaciation, these fingers of ice spread down from the poles.

01:10:34.000 --> 01:10:42.000
They actually don't get all that far. The Canadian-U.S. border is kind of where those glaciers stop for the most part

01:10:42.000 --> 01:10:48.000
and our sense that there are glaciers much farther south is those are alpine glaciers

01:10:48.000 --> 01:10:51.000
so Yosemite was indeed formed by glaciers during the Ice Age

01:10:51.000 --> 01:10:55.000
but those were descending from high mountains rather than from the poles.

01:10:55.000 --> 01:10:59.000
In any case, these glacial fingers reach down from the poles,

01:10:59.000 --> 01:11:04.000
a particular glacial finger because of the idiosyncrasies of the land

01:11:04.000 --> 01:11:09.000
and the pattern of temperature that's based on the circulation of the atmosphere

01:11:09.000 --> 01:11:13.000
results in this finger blocking the Clark Fork River.

01:11:13.000 --> 01:11:18.000
When the Clark Fork River gets blocked, water builds up behind it

01:11:18.000 --> 01:11:22.000
creating what we now call glacial lake Missoula

01:11:22.000 --> 01:11:26.000
which would have been an incredibly deep lake.

01:11:26.000 --> 01:11:29.000
It was 1500 feet deep, something like that.

01:11:29.000 --> 01:11:34.000
It was an incredibly large amount of water the size of two modern-day Great Lakes

01:11:34.000 --> 01:11:43.000
and that would have sat behind this dam and then what happens is a process.

01:11:43.000 --> 01:11:48.000
When you have that amount of water, it creates a tremendous amount of pressure at the bottom.

01:11:48.000 --> 01:11:55.000
That pressure because water increases in volume when it freezes.

01:11:55.000 --> 01:12:01.000
That pressure prevents water from freezing and so it is able to be super-cooled.

01:12:01.000 --> 01:12:05.000
It can be below the freezing temperature of water and it cannot solidify

01:12:05.000 --> 01:12:08.000
because that pressure is keeping it from doing so.

01:12:08.000 --> 01:12:16.000
What we now understand is that that super-cooled water actually trickled through cracks in the dam

01:12:16.000 --> 01:12:24.000
and opened weaknesses and the dam exploded letting loose this entire gigantic lake

01:12:24.000 --> 01:12:29.000
which then rushed at a speed of something like 60 miles an hour across the landscape

01:12:29.000 --> 01:12:37.000
scouring it and destroying it, literally grinding up the stuff that was on the surface moments before

01:12:37.000 --> 01:12:43.000
and created this largest waterfall that ever flowed on the face of the earth

01:12:43.000 --> 01:12:51.000
and then careened down the rest of the scablands and into what is now the Columbia River Gorge.

01:12:51.000 --> 01:12:58.000
It was actually created by the same flood and all of that water flowed out towards the Pacific.

01:12:58.000 --> 01:13:04.000
It washed into the Willamette Valley, in part the Willamette Valley in Oregon is fertile.

01:13:04.000 --> 01:13:10.000
It is great farmland in part because the materials that were in eastern Washington got washed into it

01:13:10.000 --> 01:13:15.000
and then it washed out into the Pacific.

01:13:15.000 --> 01:13:24.000
The point is because the triggering event of this is the growth of the ice dam that blocks the Clark Fork River

01:13:24.000 --> 01:13:29.000
and because that ice sheet, that finger of ice grows in the same place

01:13:29.000 --> 01:13:34.000
because the conditions that created the first time remained there even after the lake had emptied out

01:13:34.000 --> 01:13:40.000
this happened repeatedly. The finger of ice blocked the river, the lake builds up,

01:13:40.000 --> 01:13:46.000
the super-cooled water creates the fissures and the dam and the dam explodes and it happens once again.

01:13:46.000 --> 01:13:56.000
The scablands are really the outwash of this glacial process that we just simply can't directly observe.

01:13:56.000 --> 01:14:04.000
Now, interestingly, because the last ice age took place so recently, I don't think we know for sure

01:14:04.000 --> 01:14:09.000
but it is quite possible that there were humans who actually observed this event.

01:14:09.000 --> 01:14:16.000
This was not in the distant past, we're talking about 15,000 years ago.

01:14:16.000 --> 01:14:25.000
So anyway, when you think about the kinds of stories that get handed down, these colossal floods,

01:14:25.000 --> 01:14:30.000
one possibility is that actually colossal floods are something that has been observed and has made quite an impression

01:14:30.000 --> 01:14:39.000
and has been inscribed into myths precisely because it was so significant that people were utterly compelled

01:14:39.000 --> 01:14:46.000
to report what they had seen and it got handed down one generation after another.

01:14:46.000 --> 01:14:54.000
Do you think that this scablands flood was an isolated event or perhaps it was part of like a global,

01:14:54.000 --> 01:15:00.000
something happened to the globe at that period that triggered massive change globally?

01:15:00.000 --> 01:15:06.000
Well, you know, let's put it this way, which you've just suggested is definitely true.

01:15:06.000 --> 01:15:15.000
The way that Molankovitch oscillations create ice ages and interglacial periods, that is...

01:15:15.000 --> 01:15:18.000
What are Molankovitch?

01:15:18.000 --> 01:15:35.000
The Molankovitch cycles are oscillations in the Earth's orbit that very slightly adjust the amount of the sun's energy that is trapped here.

01:15:35.000 --> 01:15:40.000
And so there are three major Molankovitch cycles.

01:15:41.000 --> 01:15:49.000
They involve the angle of tilt of the Earth, which is not stable at the moment.

01:15:49.000 --> 01:15:55.000
It's 23 and a half degrees, but there is an oscillation in the degree of tilt.

01:15:55.000 --> 01:16:07.000
There is an oscillation in the degree of obliquity of the orbit of the Earth, how round versus oval the orbit is.

01:16:07.000 --> 01:16:15.000
And then there is an oscillation of the procession of the axis of rotation of the Earth.

01:16:15.000 --> 01:16:19.000
So the North Star is not always where the North Pole points.

01:16:19.000 --> 01:16:23.000
And these things are on very different timescales.

01:16:23.000 --> 01:16:30.000
We have a 100,000 year timescale, a roughly 41,000 year timescale, and a roughly 20,000 year timescale.

01:16:30.000 --> 01:16:40.000
These are out of phase, but when they all happen together in such a way that causes slightly cooler northern summers,

01:16:40.000 --> 01:16:50.000
that is to say the northern hemisphere has a summer that is slightly cooler than normal because these oscillations have all reduced the amount of solar energy,

01:16:50.000 --> 01:16:55.000
that causes ice to remain that would have melted otherwise.

01:16:55.000 --> 01:17:05.000
So in other words, the glacial tops of mountains, the degree of the poles is slightly preserved beyond average.

01:17:05.000 --> 01:17:16.000
And when that happens, because ice is white and reflects energy back into space, the next summer tends to be even a little bit cooler

01:17:16.000 --> 01:17:23.000
because now you've got some of the energy that would have been absorbed by the dark ocean, for example,

01:17:23.000 --> 01:17:31.000
bounced back into space, which causes the next summer to be slightly cooler, which causes slightly more ice to remain,

01:17:31.000 --> 01:17:36.000
which causes more energy to be bounced back into space, which causes the next summer to be slightly cooler, etc.

01:17:36.000 --> 01:17:40.000
And so here you get the glaciers descending down from the poles.

01:17:40.000 --> 01:17:51.000
And this continues until there is enough out of phaseness of the Milankovitch cycles for the process to reverse,

01:17:51.000 --> 01:17:57.000
where you get an abnormally slightly warm summer and that causes slightly more ice to melt,

01:17:57.000 --> 01:18:05.000
which causes slightly more energy to be absorbed by the dark earth underneath or the water and the process reverses.

01:18:05.000 --> 01:18:18.000
So at one level, you've got a planet that has these slight oscillations in its orbit that cause a regular oscillation between glacial and interglacial,

01:18:18.000 --> 01:18:29.000
and that is enough to trigger this reflectance mechanism, what's called albedo, the reflectance of light back into space,

01:18:29.000 --> 01:18:34.000
that causes that, which is really the driver of these glaciation events.

01:18:34.000 --> 01:18:38.000
So we have one layer at which we know this is true.

01:18:38.000 --> 01:18:45.000
And then there's a question about what other things might function in a way to radically alter the nature of the earth.

01:18:45.000 --> 01:19:03.000
And there are some truly frightening possibilities on that list, including the possibility that fluctuations of what is internal to the earth might cause a massive disruption

01:19:03.000 --> 01:19:12.000
in the orientation of the earth in space, which can radically alter the facts of life on this planet.

01:19:13.000 --> 01:19:21.000
That is far less certain, but let's just say, when one looks at the evidence, very difficult to dismiss.

01:19:21.000 --> 01:19:29.000
That was beautifully explained how this gradual process of these forces can tip the world in one direction or another.

01:19:29.000 --> 01:19:32.000
When they align towards cold, they can get really, really cold.

01:19:32.000 --> 01:19:38.000
But it seems like we broke out of that ice age very, very rapidly.

01:19:38.000 --> 01:19:48.000
We've seen those Greenland ice cores, where they have a really dramatic, there's a really dramatic end to the younger driest,

01:19:48.000 --> 01:19:51.000
where the temperature just, you know, it's not gradual.

01:19:51.000 --> 01:19:57.000
What happens in like five, maybe 10 years, where we just shoot out of the ice age.

01:19:57.000 --> 01:20:02.000
Yeah, that is definitely not predicted by a Malankovitch alone, that's for sure.

01:20:03.000 --> 01:20:12.000
So I think the idea that I've gotten from Graham Hancock and Randall Carlson is that it was a meteor,

01:20:12.000 --> 01:20:14.000
because there's this energy paradox.

01:20:14.000 --> 01:20:22.000
It's like, where did all this energy come from to create this rapid melting or the breakage of these dams

01:20:22.000 --> 01:20:27.000
that had to come from somewhere, because it's not a gradual thing, you know, these massive floods.

01:20:28.000 --> 01:20:37.000
And yeah, I think a meteor or something extraterrestrial hitting Earth could be a good explanation,

01:20:37.000 --> 01:20:41.000
because those things hit Earth a lot more frequently than we think.

01:20:41.000 --> 01:20:51.000
Yes, I think there is some mechanism inside of academics and intellectuals

01:20:51.000 --> 01:21:00.000
that causes them to adhere too closely to the familiar,

01:21:00.000 --> 01:21:12.000
which makes remarkable things for which they have no direct perception seem not worth considering.

01:21:12.000 --> 01:21:18.000
And, you know, that is why I dearly love the story of J. Harlan Bretz.

01:21:18.000 --> 01:21:23.000
It allowed me to make this point to students in a way that it would have been difficult otherwise,

01:21:23.000 --> 01:21:29.000
and the fact that they could physically stand on the rim of that great waterfall, not even knowing what it was.

01:21:29.000 --> 01:21:36.000
I mean, that was part of the joy of this was hiking them up to the rim of this waterfall and saying,

01:21:36.000 --> 01:21:38.000
do you know what you're looking at?

01:21:38.000 --> 01:21:44.000
You're looking at the largest waterfall that ever flowed on the face of the Earth, and it's perfectly dry.

01:21:44.000 --> 01:21:46.000
How could that be?

01:21:47.000 --> 01:21:58.000
You know, it's almost the perfect example of stepping outside of the realm of the purely social

01:21:58.000 --> 01:22:01.000
in order that the physical world can make its point.

01:22:01.000 --> 01:22:06.000
There's something about standing on the rim of that waterfall and realizing that you just hiked all the way up it

01:22:06.000 --> 01:22:10.000
and it didn't occur to you that that's what you were doing.

01:22:10.000 --> 01:22:17.000
Yeah, I think that's the great value of going out into the real world and just learning things firsthand.

01:22:17.000 --> 01:22:24.000
I remember I had been, I just assumed because of what all I've been taught that climate change was a fact

01:22:24.000 --> 01:22:29.000
and that everything is getting warmer and I remember probably 10 years ago I went to New Zealand

01:22:29.000 --> 01:22:34.000
and I went and saw a glacier down there and I just assumed that it was shrinking.

01:22:34.000 --> 01:22:37.000
I said, oh, wow, how big did this used to be?

01:22:37.000 --> 01:22:39.000
And they said, oh, it's actually growing.

01:22:39.000 --> 01:22:42.000
And I was like, I didn't think they could grow.

01:22:42.000 --> 01:22:50.000
And just, you know, just by being there and seeing firsthand that, okay, you know, it is rare, but some glaciers still grow.

01:22:50.000 --> 01:22:59.000
I think that got me going down a rabbit hole of, okay, maybe there is something to alternate narratives or, you know,

01:22:59.000 --> 01:23:01.000
don't just take the experts at face value.

01:23:01.000 --> 01:23:09.000
No, I mean, the experts who first told us that we were going to have a snowball Earth

01:23:09.000 --> 01:23:17.000
and then switched to global warming and promised us that the Arctic was going to be ice free,

01:23:17.000 --> 01:23:24.000
that the snows of Kilimanjaro were going to be gone, that Glacier National Park was going to have no glaciers.

01:23:25.000 --> 01:23:28.000
I'm not saying there's nothing to global warming,

01:23:28.000 --> 01:23:35.000
but I am saying these experts are obviously not good at predicting the future

01:23:35.000 --> 01:23:43.000
and given that prediction is the only measure we have for insight, that ought to trouble us.

01:23:43.000 --> 01:23:51.000
Are we really going to turn civilization upside down over a hypothesis being delivered by people who keep being wrong?

01:23:51.000 --> 01:23:55.000
That doesn't sound like a good idea to me.

01:23:55.000 --> 01:24:03.000
Yeah, it's very difficult to know that if we gave them these experts a trillion dollars, how would they spend it

01:24:03.000 --> 01:24:08.000
and how could we even measure the effects of that spendage?

01:24:08.000 --> 01:24:13.000
And how much do we want to sacrifice our progress today?

01:24:13.000 --> 01:24:19.000
You know, do we need to live in the Stone Age so we can have some future in 100 years from now

01:24:19.000 --> 01:24:23.000
that we don't even know for certain if it's, you know, we can't predict?

01:24:23.000 --> 01:24:26.000
So how much do we want to sacrifice now?

01:24:26.000 --> 01:24:36.000
Well, I actually think that, I do think that there is a danger that is real with respect to climate change.

01:24:36.000 --> 01:24:45.000
That danger is built of facts which I believe are robust and it depends not at all on models.

01:24:45.000 --> 01:24:50.000
Models are where this kind of analysis goes wrong.

01:24:50.000 --> 01:24:56.000
It's very easy to make a model that will spit out virtually any answer if you're willing to load in enough parameters.

01:24:56.000 --> 01:25:01.000
So the fact that it looks compelling doesn't tell you anything.

01:25:01.000 --> 01:25:07.000
But I do think we know that CO2 is heat trapping.

01:25:07.000 --> 01:25:10.000
We know that methane is even more so.

01:25:10.000 --> 01:25:16.000
Those are ancient observations or ancients the wrong term, but it goes back to the Arrhenius equation.

01:25:16.000 --> 01:25:19.000
We're talking a century old observation.

01:25:19.000 --> 01:25:27.000
And we know that there's a tremendous amount of frozen methane clathrate in the Arctic.

01:25:27.000 --> 01:25:38.000
Now, the problem is if we reach a temperature in which methane that has been locked away in the Arctic

01:25:38.000 --> 01:25:47.000
is suddenly released in some substantial novel quantity, that methane will cause warming

01:25:47.000 --> 01:25:51.000
because methane traps light energy.

01:25:51.000 --> 01:26:00.000
If it causes warming and that warming causes the polar ice sheet to retreat

01:26:00.000 --> 01:26:07.000
because the summer is warmer than it would otherwise be, then that will leave the Earth darker than it had been

01:26:07.000 --> 01:26:10.000
which will cause more light energy to be trapped.

01:26:10.000 --> 01:26:19.000
And we will be in that same pattern that ends the glaciation when the Milankovic cycles go out of phase.

01:26:19.000 --> 01:26:27.000
That same positive feedback will release a tremendous amount of methane that would otherwise have stayed frozen.

01:26:27.000 --> 01:26:35.000
So that would take global climate out of human control.

01:26:35.000 --> 01:26:41.000
Now, it would take climate change out of human control.

01:26:41.000 --> 01:26:53.000
Now, my sense, and so far I think I'm the only person advocating for this, is that there is actually, although I am dead set against the idea of geoengineering

01:26:53.000 --> 01:26:59.000
because I think geoengineering is almost certain to be a disaster no matter what you do.

01:26:59.000 --> 01:27:10.000
There is one version of geoengineering for climate change that I am actually until somebody compels me that I've got it wrong in favor of.

01:27:10.000 --> 01:27:21.000
And that is the deploying of panels that would allow you to adjust the albedo, to adjust the whiteness of the Earth.

01:27:22.000 --> 01:27:35.000
Now, when albedo is adjusted by the poles, it requires a tremendous amount of surface area because the poles are, well, they are not near the equator

01:27:35.000 --> 01:27:39.000
and therefore the light that they are capable of reflecting is indirect.

01:27:39.000 --> 01:27:42.000
It's coming through an awful lot of atmosphere first.

01:27:42.000 --> 01:27:54.000
But if you were to deploy panels that could be flipped, let's say, so that we could turn them to the white side when we wanted to reflect more energy into space

01:27:54.000 --> 01:28:02.000
and cool things down or turn them to the black side if we wanted to absorb energy and warm things up,

01:28:02.000 --> 01:28:14.000
then my sense is we could, at yes, considerable expense and yes, with some environmental degradation, build a mechanism capable of leveraging albedo.

01:28:14.000 --> 01:28:18.000
No. What did I just say? I said albedo. I meant albedo.

01:28:18.000 --> 01:28:19.000
Albedo.

01:28:19.000 --> 01:28:20.000
Yes.

01:28:20.000 --> 01:28:21.000
Geez.

01:28:21.000 --> 01:28:23.000
Talk about Freudian slips.

01:28:24.000 --> 01:28:38.000
Leveraging albedo to control the retreat of glacial ice so as not to enter that methane-based positive feedback.

01:28:38.000 --> 01:28:43.000
Now, I'm in favor of this both because I think the methane positive feedback is very dangerous.

01:28:43.000 --> 01:28:49.000
If people want to know what I'm talking about, they should look up the clathrate gun hypothesis.

01:28:49.000 --> 01:28:56.000
That is to say that this positive feedback would go off like a gun altering the climate of the Earth.

01:28:56.000 --> 01:29:04.000
And while it may or may not be something that will happen, the mechanism by which it would happen is clearly plausible.

01:29:04.000 --> 01:29:18.000
If we were to deploy panels that would allow us to control albedo to prevent that from happening, then we would also be in a position to tell all these people who want to install a tyrannical structure on Earth

01:29:18.000 --> 01:29:25.000
in order to ostensibly reduce our carbon footprint as a species.

01:29:25.000 --> 01:29:29.000
We could tell them to go to hell because we wouldn't need to do that.

01:29:29.000 --> 01:29:39.000
We could burn the fossil fuels that are necessary to make our economy continue to work to provide a high quality of life for the citizens of planet Earth.

01:29:39.000 --> 01:29:45.000
And we could control the consequence at the most logical level.

01:29:45.000 --> 01:29:56.000
We know from the pattern of ice ages that albedo is a viable control mechanism for climate.

01:29:56.000 --> 01:30:00.000
It's just not one that humans have the control panel for.

01:30:00.000 --> 01:30:07.000
If we build that control panel, then we can burn the fossil fuels that we need to burn and we don't have an alternative.

01:30:07.000 --> 01:30:14.000
The alternative is massive austerity and that austerity will not be felt by the elites, it will be felt by everybody else.

01:30:14.000 --> 01:30:25.000
So why don't we build ourselves a control mechanism so that if global climate change is the problem that some fear that we have an ability to arrest it,

01:30:25.000 --> 01:30:31.000
and if it is not the problem that we fear, we have a control mechanism for a rainy day.

01:30:31.000 --> 01:30:43.000
It seems to me the best solution to this problem and one that removes the excuse from all of the tyrants who are rewriting the rules of planet Earth as we speak.

01:30:44.000 --> 01:30:55.000
So I'm imagining just some massive 200 mile radius, I don't know, sphere that's white in the middle of the ocean or something.

01:30:55.000 --> 01:31:07.000
That's just reflecting instead of that dark ocean absorbing the heat, you just have this giant white thing that you can flip over whenever you want.

01:31:07.000 --> 01:31:11.000
There are a lot of ways you could do it.

01:31:11.000 --> 01:31:25.000
The ocean would be a good one because the ocean is inherently dark and so the consequence in terms of the payback is high.

01:31:25.000 --> 01:31:31.000
On the other hand, the technological difficulty of doing this, especially in the remote ocean, is substantial.

01:31:31.000 --> 01:31:37.000
So it's not obvious to me that the cost benefit analysis leads you to the ocean.

01:31:37.000 --> 01:31:50.000
And really what I would want is a panel of well-informed experts with no perverse incentives to discuss whether or not this is a viable plan,

01:31:50.000 --> 01:31:58.000
if it is a viable plan, what is the mechanism for deploying it that is least harmful and most likely to be useful.

01:31:58.000 --> 01:32:12.000
And the thing I didn't say is the most important thing about this plan is that unlike the other geoengineering plans, it's completely reversible.

01:32:12.000 --> 01:32:19.000
That is to say, if it turns out that this plan is a mistake for some reason we do not foresee, we can unmake it.

01:32:19.000 --> 01:32:27.000
That's not true if you dump aluminum into the atmosphere to reflect sunlight.

01:32:27.000 --> 01:32:32.000
It's not true for virtually any other plan.

01:32:32.000 --> 01:32:36.000
So the reversibility of the plan is its key selling point.

01:32:36.000 --> 01:32:42.000
We are not committing ourselves to anything by doing such a thing.

01:32:42.000 --> 01:32:49.000
It seems like we're doing the exact opposite right now with the urbanization makes things darker.

01:32:49.000 --> 01:32:57.000
I know that when you measure the temperature in cities, it's quite a lot hotter and solar panels are black.

01:32:57.000 --> 01:33:04.000
So it seems like we're just adding more darkness to the surface of the earth, which is only going to perpetuate the heating.

01:33:04.000 --> 01:33:15.000
Yep, and it is also the case that a disturbing portion of the evidence that supposedly tells us that the globe is warming in a dangerous way

01:33:15.000 --> 01:33:26.000
is potentially accounted for by the urbanization of the places in which data is being collected.

01:33:26.000 --> 01:33:33.000
Yeah, we've only been really measuring the temperature for how long, like a couple hundred years.

01:33:33.000 --> 01:33:45.000
So, I mean, the world is 4.5 billion years old, 100 years is like, you know, if the history of the world was a day, that would be like a fraction of a second.

01:33:45.000 --> 01:33:55.000
Yeah, we have a tiny data set and that data set is of course disproportionately going to be in places where there are people to put out thermometers and read them.

01:33:55.000 --> 01:34:11.000
So, the chances that this data set is going to be biased by what was once a sparse population where people started taking data that has then been increasingly surrounded by human activity,

01:34:11.000 --> 01:34:20.000
which not only darkens things, but releases energy, you know, every air conditioner that cools a house is putting out heat on the other side, right?

01:34:20.000 --> 01:34:26.000
Every factory, all of the internal combustion engines in the cars, these are all putting out heat.

01:34:26.000 --> 01:34:37.000
That's before you even get to the solar panels that are taking photons and turning them into useful photovoltaic energy.

01:34:37.000 --> 01:34:42.000
So, yes, how you even measure is a good question.

01:34:42.000 --> 01:34:47.000
Are you optimistic about the future?

01:34:47.000 --> 01:34:51.000
Well, I'm a little concerned.

01:34:51.000 --> 01:35:02.000
I do have something, there is a place from which I drive optimism, which is, actually there are two places that I drive optimism.

01:35:02.000 --> 01:35:26.000
In engaging in its tyranny, our enemies, the enemies of freedom, have driven every insightful, courageous person with integrity out of all of the institutions.

01:35:26.000 --> 01:35:29.000
They've driven them out and they've pissed them off.

01:35:29.000 --> 01:35:38.000
And that means that we have all of the folks that you would want on your side ready to go.

01:35:38.000 --> 01:35:47.000
These people have just faced tyrants and they are wide awake and that is a very hopeful phenomenon.

01:35:47.000 --> 01:35:53.000
In fact, I think the force that I call Goliath made a terrible error in doing that.

01:35:53.000 --> 01:35:56.000
He just handed us every player we could want.

01:35:56.000 --> 01:35:58.000
So that's one reason to be hopeful.

01:35:58.000 --> 01:36:08.000
The other reason to be hopeful is that we are talking about a civilization, in evolution we talk about the adaptive landscape,

01:36:08.000 --> 01:36:17.000
in which opportunities are represented as peaks and hazards to getting to better opportunities are represented as valleys.

01:36:18.000 --> 01:36:34.000
Our civilization represents an important peak, but there are obviously contradictions in that society that are incapable of addressing the hazards of modernity.

01:36:35.000 --> 01:36:46.000
There's nothing in our founding documents about the enrichment of uranium, about the controlling of renegade artificial intelligence,

01:36:46.000 --> 01:36:57.000
about the disruption of development by perversely incentivized corporations running social media platforms with algorithms that distort perception.

01:36:57.000 --> 01:36:59.000
None of these things.

01:36:59.000 --> 01:37:07.000
So we have to move to some different way of governing ourselves.

01:37:07.000 --> 01:37:13.000
I believe the values that undergird our civilization are the correct ones.

01:37:13.000 --> 01:37:21.000
I believe we should only build civilizations that maximize liberty.

01:37:21.000 --> 01:37:24.000
Liberty is the only value you can afford to maximize.

01:37:24.000 --> 01:37:30.000
If you maximize any other value you will crash a bunch of other values, but liberty integrates them all.

01:37:30.000 --> 01:37:37.000
And so we want a civilization that liberates people meaningfully, not just on paper.

01:37:37.000 --> 01:37:48.000
And in order to get to that civilization that can do that job in an era of high technology, we're going to have to pass through an adaptive valley.

01:37:48.000 --> 01:37:51.000
That was dead certain no matter how we did this.

01:37:51.000 --> 01:37:57.000
So the fact that things look very dark is not in and of itself evidence of where we're headed.

01:37:57.000 --> 01:38:03.000
We could perish in the adaptive valley or we could find the foothill of the next peak and we could start to climb it.

01:38:03.000 --> 01:38:05.000
I hope that we do.

01:38:05.000 --> 01:38:11.000
And I am investing everything I've got in making sure that we do.

01:38:11.000 --> 01:38:15.000
But I don't think the final chapter has been written.

01:38:15.000 --> 01:38:19.000
It's late, but as far as I know it's not too late.

01:38:21.000 --> 01:38:23.000
That's brilliant.

01:38:23.000 --> 01:38:30.000
I'm very grateful to you and Heather because over the last three years there were some times that seemed really dark.

01:38:30.000 --> 01:38:39.000
And you two were like a shining light in the darkness and things got really dark for a minute.

01:38:39.000 --> 01:38:42.000
And I remember thinking, is this it?

01:38:42.000 --> 01:38:45.000
Are we really going down into tyranny?

01:38:45.000 --> 01:38:51.000
And it was around that time I made a video on mass psychosis that went viral.

01:38:51.000 --> 01:38:54.000
It got picked up by everybody.

01:38:54.000 --> 01:38:56.000
Even Alex Jones put it on his show for three.

01:38:56.000 --> 01:38:59.000
He did a three hour show about that video.

01:38:59.000 --> 01:39:02.000
Trump saw Tucker Carlson, Joe Rogan.

01:39:02.000 --> 01:39:04.000
And that video went huge.

01:39:04.000 --> 01:39:08.000
And that was probably made during the darkest time.

01:39:08.000 --> 01:39:10.000
It was summer of 2021.

01:39:10.000 --> 01:39:14.000
And that was made out of things were pretty hopeless.

01:39:14.000 --> 01:39:18.000
And I kind of just made that almost as like a shot in the dark.

01:39:18.000 --> 01:39:22.000
I'm going to put everything I got into this video.

01:39:22.000 --> 01:39:28.000
And I feel like you and Heather are also just beacons of light.

01:39:28.000 --> 01:39:32.000
Almost like in Lord of the Rings when they lit those beacons on the mountains.

01:39:32.000 --> 01:39:36.000
You know, you got to see another beacon and you get hopeful.

01:39:36.000 --> 01:39:38.000
You know, you're not alone.

01:39:38.000 --> 01:39:46.000
And so I know you guys have suffered a lot of demonetization and algorithms working against you.

01:39:46.000 --> 01:39:52.000
But I know there are people like I talk to people all the time and I mentioned your name and they know who you are.

01:39:52.000 --> 01:39:58.000
And so in the real world, people are very encouraged by you.

01:39:58.000 --> 01:40:01.000
And you're maybe upsetting the right people.

01:40:01.000 --> 01:40:03.000
I don't know.

01:40:03.000 --> 01:40:07.000
I do take a certain amount of pleasure in upsetting the right people.

01:40:07.000 --> 01:40:09.000
And it is one of my guideposts.

01:40:09.000 --> 01:40:12.000
If you're upsetting the right people, you're probably doing something right.

01:40:12.000 --> 01:40:15.000
So thank you. I appreciate that.

01:40:15.000 --> 01:40:22.000
I would encourage you if you thought the last outbreak of tyranny was amazing,

01:40:22.000 --> 01:40:30.000
then you're really going to enjoy what's going on in the World Health Organization

01:40:30.000 --> 01:40:35.000
and their plan for a rematch.

01:40:35.000 --> 01:40:37.000
It's really quite extraordinary.

01:40:37.000 --> 01:40:39.000
Because I feel like they kind of lost the first battle.

01:40:39.000 --> 01:40:41.000
They did.

01:40:41.000 --> 01:40:44.000
And that keeps them up at night.

01:40:44.000 --> 01:40:51.000
And they have decided that the solution is to rerun the last battle

01:40:51.000 --> 01:40:57.000
and figure out what rules would have allowed them to silence the people who bested them.

01:40:57.000 --> 01:41:01.000
So they are currently building exactly that set of rules.

01:41:01.000 --> 01:41:11.000
And if we do nothing about it, it is likely to pass in May of this year.

01:41:11.000 --> 01:41:17.000
Well, I think probably one of those big things that they would like to have changed

01:41:17.000 --> 01:41:22.000
is that the last pandemic was just not that dangerous relatively.

01:41:22.000 --> 01:41:28.000
Like if you compare it to previous plagues, you know, you had one third of Europe get wiped out

01:41:28.000 --> 01:41:35.000
or the Spanish flu killed 50 to 100 million people.

01:41:35.000 --> 01:41:39.000
You know, this was kind of like a fart in the wind compared to those.

01:41:39.000 --> 01:41:45.000
Well, I have come to disbelieve the story of the Spanish flu.

01:41:45.000 --> 01:41:55.000
It is well worth looking into the hypothesis that the Spanish flu was wildly exacerbated

01:41:55.000 --> 01:42:00.000
by the abuse of the new wonder drug aspirin.

01:42:00.000 --> 01:42:02.000
Really?

01:42:02.000 --> 01:42:04.000
Yeah, it is terrifying.

01:42:04.000 --> 01:42:09.000
But in the end, I think quite compelling argument.

01:42:09.000 --> 01:42:17.000
The plague obviously was what it was, but obviously we are in a very different situation

01:42:17.000 --> 01:42:24.000
with respect to our understanding of antibiotics and our understanding of hygiene

01:42:24.000 --> 01:42:30.000
and our ability to prevent such things through other mechanisms.

01:42:30.000 --> 01:42:40.000
I would say to the extent that you would imagine that a worse pathogen would be desirable to Goliath

01:42:40.000 --> 01:42:46.000
if Goliath wanted to rerun the tape of history and beat us decisively this time.

01:42:46.000 --> 01:42:54.000
And although it is not the World Health Organization, the EcoHealth Alliance,

01:42:54.000 --> 01:43:03.000
which you may remember as the non-profit organization which spearheaded the research in Wuhan

01:43:03.000 --> 01:43:07.000
that seems to have resulted in the production of SARS-CoV-2,

01:43:07.000 --> 01:43:19.000
that same group headed by Peter Dasek, the same villain who kept doubling down on this ploy

01:43:19.000 --> 01:43:23.000
and then pretending that a lab leak was impossible.

01:43:23.000 --> 01:43:31.000
He and the EcoHealth Alliance have been granted something like $16 million, I think,

01:43:31.000 --> 01:43:46.000
to set up a laboratory in Colorado to study the infection of bats from Asia with devastating human pathogens.

01:43:46.000 --> 01:43:51.000
I wish I was making this up, but not only do they appear to want a rerun

01:43:51.000 --> 01:43:59.000
with potentially new and more deadly pathogens, but they've hired the same people to produce them.

01:44:00.000 --> 01:44:02.000
It's almost too obvious.

01:44:02.000 --> 01:44:04.000
The definition of insanity.

01:44:04.000 --> 01:44:06.000
It's the definition of insanity.

01:44:06.000 --> 01:44:18.000
So that coupled with changes to the FCC regulations that would allow the FCC to control access to the internet

01:44:19.000 --> 01:44:31.000
and changes to the WHO Pandemic Preparedness Plan all looks like somebody wants to be able to institute rules

01:44:31.000 --> 01:44:38.000
on the entire human population based on anything that they can claim is a public health threat

01:44:38.000 --> 01:44:47.000
and their ability to mandate would include the mandating of true vaccines, of gene therapy,

01:44:47.000 --> 01:44:57.000
presumably including mRNA technology, and they also have reserved the right to censor any criticism

01:44:57.000 --> 01:45:04.000
that would potentially upend their public health program.

01:45:05.000 --> 01:45:13.000
So we're facing a rerun and we're not paying attention because most people are just sick of talking about the topic,

01:45:13.000 --> 01:45:22.000
which I full well understand, but it would be a mistake to put it aside and ignore what those who lost round one are up to

01:45:22.000 --> 01:45:24.000
so that they can win round two.

01:45:26.000 --> 01:45:28.000
That's terrifying.

01:45:28.000 --> 01:45:33.000
Do you think Elon Musk, do you think the reason why he's become like public enemy number one

01:45:33.000 --> 01:45:38.000
is because he's kind of like this inconvenient wrench in their engine

01:45:38.000 --> 01:45:44.000
that if they want to implement this mass censorship and control,

01:45:44.000 --> 01:45:48.000
I think you were mentioning earlier, zero is a special number.

01:45:48.000 --> 01:45:52.000
I really liked, I was listening to you mention that on the Dave Rubin report,

01:45:52.000 --> 01:46:00.000
that if there is one platform that is free, that kind of negates all the other ones, right?

01:46:00.000 --> 01:46:07.000
It forces them to free themselves because if there's only one free platform, everybody will be on it.

01:46:07.000 --> 01:46:14.000
And so at a competitive level, if Elon Musk manages to truly free and stabilize Twitter,

01:46:14.000 --> 01:46:22.000
then the other platforms will have to go along with that program or they will go extinct

01:46:22.000 --> 01:46:26.000
because who's going to sign up for a platform where you can't speak openly?

01:46:27.000 --> 01:46:35.000
Yeah, him buying Twitter is one of those events that I feel like if this was a war,

01:46:35.000 --> 01:46:39.000
that would have been a big battle. That would have been a significant battle one.

01:46:39.000 --> 01:46:48.000
Yeah, I agree. It's a huge factor and I hope Musk is up to the challenge.

01:46:49.000 --> 01:46:55.000
I see evidence that he is interested in doing the right thing

01:46:55.000 --> 01:47:01.000
and I see him make unforced errors that I can't explain.

01:47:01.000 --> 01:47:07.000
So anyway, I'm hoping that he can figure out how to pull it off.

01:47:08.000 --> 01:47:16.000
Yeah, I'm rooting for him. I think just yesterday he had a conversation with Alex Jones,

01:47:16.000 --> 01:47:23.000
Andrew Tate, a couple other ones, Vivek Ramoswani.

01:47:23.000 --> 01:47:27.000
It was quite an interesting, it was a Twitter space.

01:47:27.000 --> 01:47:35.000
And to have these characters all in one area talking was really interesting.

01:47:36.000 --> 01:47:42.000
Yep, I will say, okay, that is interesting.

01:47:42.000 --> 01:47:52.000
But as I think I mentioned on the Dave Rubin report, Elon has me blocked.

01:47:52.000 --> 01:47:59.000
That means I couldn't participate in the discussion around or even the poll that he took

01:47:59.000 --> 01:48:07.000
on whether to bring Alex Jones back and I couldn't participate in that Twitter space.

01:48:07.000 --> 01:48:19.000
And so I cannot understand this unless I just simply play no role in the free speech discussion.

01:48:20.000 --> 01:48:31.000
It would seem that having made some personal decision to block me,

01:48:31.000 --> 01:48:34.000
what am I supposed to say?

01:48:34.000 --> 01:48:40.000
Yeah, I think it's really great that Elon Musk held a space with these people yesterday

01:48:40.000 --> 01:48:43.000
when I can't even see that it's happening.

01:48:43.000 --> 01:48:53.000
So, Elon, if you're watching, you have no idea how destructive it is of your platform

01:48:53.000 --> 01:48:56.000
to block somebody yourself.

01:48:56.000 --> 01:49:00.000
You are a large fraction of what's taking place on that platform.

01:49:00.000 --> 01:49:08.000
And it isn't a minor fact when your account becomes invisible.

01:49:08.000 --> 01:49:13.000
I have to infer even what's being discussed because I can't see it directly.

01:49:13.000 --> 01:49:15.000
And I don't think that was your intent when you did it.

01:49:15.000 --> 01:49:21.000
But please undo it because if you're really about free speech, this is not helping.

01:49:21.000 --> 01:49:25.000
This means that every time somebody raises what you're doing with me,

01:49:25.000 --> 01:49:31.000
I have to say I can't really embrace this because at the moment I can't even see it.

01:49:31.000 --> 01:49:32.000
Right.

01:49:32.000 --> 01:49:36.000
Like you said earlier, we got a band together.

01:49:36.000 --> 01:49:39.000
We've got this big Goliath in front of us.

01:49:39.000 --> 01:49:41.000
We've got to stick together.

01:49:41.000 --> 01:49:43.000
There's not a ton of us.

01:49:43.000 --> 01:49:44.000
Right.

01:49:44.000 --> 01:49:47.000
There are very few and we're going to need to trust each other

01:49:47.000 --> 01:49:53.000
and we're going to need to play well and we're going to need some luck.

01:49:53.000 --> 01:49:57.000
We cannot afford friendly fire incidents.

01:49:57.000 --> 01:49:59.000
So, let's get over it.

01:49:59.000 --> 01:50:00.000
Yeah.

01:50:00.000 --> 01:50:07.000
I mean, the one problem is the people that have been kind of ousted out of this establishment,

01:50:07.000 --> 01:50:10.000
they are very independent minded people.

01:50:10.000 --> 01:50:15.000
And it's probably going to be a little bit hard to rope them together.

01:50:15.000 --> 01:50:19.000
You know, they're not as agreeable as the people that conform.

01:50:19.000 --> 01:50:20.000
Yeah, they're lone wolves.

01:50:20.000 --> 01:50:26.000
But you know, look, if this was a movie, we all get what has to happen, right?

01:50:26.000 --> 01:50:32.000
You have all of these prickly characters who have found themselves facing the same enemy

01:50:32.000 --> 01:50:37.000
and they have to learn to get along and yes, that's bound to be a little colorful,

01:50:37.000 --> 01:50:41.000
but nonetheless, it's obvious that it has to happen.

01:50:41.000 --> 01:50:43.000
So, let's do it.

01:50:43.000 --> 01:50:44.000
Let's start practicing.

01:50:44.000 --> 01:50:48.000
Let's be decent to each other and figure out how to function as a team

01:50:48.000 --> 01:50:52.000
and laugh about the missteps.

01:50:52.000 --> 01:50:54.000
You know, it's obvious.

01:50:54.000 --> 01:50:57.000
All you need really is the right music playing for the soundtrack

01:50:57.000 --> 01:50:59.000
and you'll know what you're supposed to do.

01:50:59.000 --> 01:51:02.000
So, let's do it.

01:51:02.000 --> 01:51:04.000
That's great.

01:51:04.000 --> 01:51:07.000
I think I have one last question for you.

01:51:07.000 --> 01:51:09.000
Then I'll let you go.

01:51:09.000 --> 01:51:12.000
I really look up to you and Heather's relationship

01:51:12.000 --> 01:51:17.000
as just kind of like something that I would strive to in my own relationship.

01:51:17.000 --> 01:51:21.000
How do you have a successful long marriage?

01:51:21.000 --> 01:51:23.000
Do you have any advice?

01:51:23.000 --> 01:51:31.000
Yeah, I've got a ton of advice, but I have to be careful because

01:51:31.000 --> 01:51:38.000
our situation is so unusual that, you know, because it's my life,

01:51:38.000 --> 01:51:45.000
I can't really say how much of it is applicable to other people's situations,

01:51:45.000 --> 01:51:48.000
but I would say things that have worked for us.

01:51:48.000 --> 01:51:55.000
One, we got together quite early, which I used to think was an unfortunate fact.

01:51:55.000 --> 01:51:57.000
I now don't think of it that way at all.

01:51:57.000 --> 01:52:00.000
I now actually think it's an asset, a tremendous one,

01:52:00.000 --> 01:52:05.000
because what it means is that you actually, you kind of grow up together

01:52:05.000 --> 01:52:12.000
and so you come to understand the world in familiar terms

01:52:12.000 --> 01:52:20.000
and you build up a kind of trust that is very powerful when things go crazy.

01:52:20.000 --> 01:52:24.000
So there's that.

01:52:24.000 --> 01:52:33.000
There is, I mean, there's really one thing above everything else

01:52:33.000 --> 01:52:37.000
and every time I say it, somebody cringes.

01:52:37.000 --> 01:52:46.000
You should not consider marrying anybody who doesn't have a sense of humor about themselves.

01:52:46.000 --> 01:52:50.000
And the reason that people cringe when I say that is that it implies

01:52:50.000 --> 01:52:55.000
that lots of people just really aren't an acceptable partner for marriage,

01:52:55.000 --> 01:52:57.000
which is unfortunately true.

01:52:57.000 --> 01:53:00.000
We should all be induced to have a sense of humor about ourselves

01:53:00.000 --> 01:53:03.000
because frankly, we're all absurd.

01:53:03.000 --> 01:53:08.000
I mean, you know, heck, we're apes

01:53:08.000 --> 01:53:13.000
and we're walking around most of the time not thinking about that fact,

01:53:13.000 --> 01:53:17.000
but it's nonetheless true and has profound implications for what we are

01:53:17.000 --> 01:53:19.000
and how we behave and all that.

01:53:19.000 --> 01:53:27.000
So I think the most useful thing is to recognize that your conscious mind

01:53:27.000 --> 01:53:32.000
is not the same thing as you.

01:53:32.000 --> 01:53:35.000
You should retain your conscious mind plus a whole bunch of other stuff

01:53:35.000 --> 01:53:37.000
that you're not really in touch with.

01:53:37.000 --> 01:53:43.000
And, you know, I frequently find myself in a situation where my defects

01:53:43.000 --> 01:53:49.000
are getting in the road of something, you know, in our relationship.

01:53:49.000 --> 01:53:56.000
For example, my chronic disorganization is disrupting Heather's desire

01:53:56.000 --> 01:54:01.000
to have a house where stuff is where she can find it, for example.

01:54:01.000 --> 01:54:05.000
And the funny thing is my conscious mind is on her side.

01:54:05.000 --> 01:54:10.000
There's apparently some part of me that isn't, but it's not my conscious mind

01:54:10.000 --> 01:54:16.000
and if she can see that actually it's not that I want to be a problem in this regard.

01:54:16.000 --> 01:54:21.000
In fact, I would go well out of my way not to be if I could figure out how to pull it off.

01:54:21.000 --> 01:54:25.000
That just removes the tension from the thing, right?

01:54:25.000 --> 01:54:29.000
Then we're talking about why, you know, what developmental piece of my history

01:54:29.000 --> 01:54:32.000
caused me not to be able to develop that skill.

01:54:32.000 --> 01:54:37.000
That's a much better conversation to be having than why are you such a jerk

01:54:37.000 --> 01:54:42.000
who doesn't care whether I can live in our house, right?

01:54:42.000 --> 01:54:48.000
So having a sense of humor about yourself, recognizing that we are,

01:54:48.000 --> 01:54:52.000
every one of us is a mystery even to ourselves

01:54:52.000 --> 01:54:56.000
and that your partnership with somebody

01:54:56.000 --> 01:55:01.000
involves you being partnered with the part that you and they understand

01:55:01.000 --> 01:55:04.000
and the part that neither of you understands

01:55:04.000 --> 01:55:08.000
and that's a funny scenario to be trapped in

01:55:08.000 --> 01:55:12.000
and you better know how to laugh about it.

01:55:12.000 --> 01:55:20.000
That's great advice and I think it's so nice that you and Heather do this podcast together

01:55:20.000 --> 01:55:24.000
because there's a lot of people out there who are just like these talking heads

01:55:24.000 --> 01:55:28.000
who have these strong opinions online but when you see somebody next to their wife

01:55:28.000 --> 01:55:33.000
you kind of look at them differently like, oh wow, somebody can really tolerate this person

01:55:33.000 --> 01:55:41.000
through thick and thin and I recently saw Jordan Peterson a couple of times live

01:55:41.000 --> 01:55:45.000
and it's really nice he comes out there or his wife introduces him

01:55:45.000 --> 01:55:49.000
and she's super sweet and he's kind of like this.

01:55:49.000 --> 01:55:55.000
He has many different sides but it's nice to see him getting the questions from his wife.

01:55:55.000 --> 01:55:59.000
You see him in a different light than when you typically see him on those debate stages

01:55:59.000 --> 01:56:03.000
when he's kind of, there's about a million videos on YouTube saying

01:56:03.000 --> 01:56:10.000
Jordan Peterson destroys this feminist or Jordan Peterson destroys this woke kid

01:56:10.000 --> 01:56:14.000
and then it's nice to see him in this pleasant dynamic with a woman

01:56:14.000 --> 01:56:20.000
so yeah, I just recently worked with Jordan Peterson's wife on a project

01:56:20.000 --> 01:56:24.000
and it was very pleasant.

01:56:24.000 --> 01:56:31.000
Well I think you're exactly right to focus on this and I think the problem is

01:56:31.000 --> 01:56:41.000
it's surprisingly easy to show a false side to the world.

01:56:42.000 --> 01:56:49.000
So lots of people do it and when you do see somebody with their spouse

01:56:49.000 --> 01:56:54.000
and the spouse is not quietly sitting there not saying anything

01:56:54.000 --> 01:56:57.000
but you're seeing them interact or even better you're seeing them disagree

01:56:57.000 --> 01:57:00.000
maybe even over something important, right?

01:57:00.000 --> 01:57:05.000
Then, well how exactly would you fake that?

01:57:06.000 --> 01:57:10.000
And I do believe you don't see everything on the podcast

01:57:10.000 --> 01:57:14.000
but what you see is absolutely accurate.

01:57:14.000 --> 01:57:21.000
That is how we are and you know, I would say the same thing is true

01:57:21.000 --> 01:57:25.000
if you saw us with our kids, is it perfect?

01:57:25.000 --> 01:57:32.000
No, but you would see there's no tension around things, right?

01:57:32.000 --> 01:57:37.000
There are all the flawed human beings that we are but we genuinely love each other

01:57:37.000 --> 01:57:41.000
and appreciate each other and are frustrated by each other

01:57:41.000 --> 01:57:45.000
and find some of each other's jokes funny and not other ones

01:57:45.000 --> 01:57:50.000
and anyway, the point is the difficulty of faking a persona

01:57:50.000 --> 01:57:59.000
is a thousandth of what it would be to fake a family.

01:58:00.000 --> 01:58:05.000
Even more so, our cats don't show up on the podcast very much anymore

01:58:05.000 --> 01:58:11.000
but bad people can have a relationship with their dog

01:58:11.000 --> 01:58:17.000
but cats, if your cat likes you, if your cat is jumping up on your podcast desk

01:58:17.000 --> 01:58:21.000
to have you pet it or sitting in your lap, right?

01:58:21.000 --> 01:58:26.000
That suggests that this animal isn't afraid of you, that it appreciates you

01:58:26.000 --> 01:58:31.000
and it also tells you something about what things are like when the camera is not on.

01:58:31.000 --> 01:58:34.000
So anyway, I think all of those indicators are amazingly powerful.

01:58:34.000 --> 01:58:40.000
I have seen the same thing between Jordan Peterson and Tammy.

01:58:40.000 --> 01:58:48.000
I recently met Tucker Carlson's wife and one of his daughters, same thing, right?

01:58:48.000 --> 01:58:53.000
You just see people who really appreciate each other and aren't hiding anything

01:58:53.000 --> 01:58:58.000
and it really does tell you that they're for real.

01:58:58.000 --> 01:59:01.000
Did you do anything with Tucker?

01:59:01.000 --> 01:59:02.000
Yeah.

01:59:02.000 --> 01:59:04.000
Oh, has that already out?

01:59:04.000 --> 01:59:05.000
No.

01:59:05.000 --> 01:59:07.000
Oh, well, I'm excited for that.

01:59:07.000 --> 01:59:08.000
Yeah, me too.

01:59:08.000 --> 01:59:10.000
Is that going to be on his Twitter show?

01:59:10.000 --> 01:59:11.000
I don't know.

01:59:12.000 --> 01:59:15.000
Yeah, I've been really enjoying seeing you make the rounds.

01:59:15.000 --> 01:59:22.000
I saw you on the Patrick Bet David show, the Russell Brand, Dave Rubin, so...

01:59:22.000 --> 01:59:25.000
It sort of reminds me of the old days.

01:59:25.000 --> 01:59:31.000
It used to be that there was an awful lot of traveling and sitting in person with people,

01:59:31.000 --> 01:59:34.000
which I really appreciated for some reason.

01:59:34.000 --> 01:59:37.000
It's more meaningful than the other stuff.

01:59:37.000 --> 01:59:44.000
Obviously, I now live on an island, so I see people through the screen more often than not.

01:59:44.000 --> 01:59:49.000
But COVID killed all of the sitting face-to-face with people

01:59:49.000 --> 01:59:53.000
and having conversations that others wanted to listen to that way.

01:59:53.000 --> 01:59:58.000
And it got us all used to doing a better job with Zoom or its equivalent.

01:59:58.000 --> 02:00:03.000
But I miss the in-person stuff and the fact that it's coming back

02:00:03.000 --> 02:00:07.000
and that I have found myself in all those places that you mentioned.

02:00:07.000 --> 02:00:10.000
I think that's a good sign and I hope it holds out.

02:00:10.000 --> 02:00:13.000
I think it's important to sit with people.

02:00:13.000 --> 02:00:20.000
Again, it's a lot harder to fake things when you're actually sitting face-to-face

02:00:20.000 --> 02:00:25.000
than you just have to keep it together while the camera's on.

02:00:25.000 --> 02:00:27.000
Yeah, I totally agree.

02:00:27.000 --> 02:00:32.000
Well, I'm just getting myself into this podcast arena.

02:00:32.000 --> 02:00:39.000
And I figure the unique thing that I can add to this is the visual aspect.

02:00:39.000 --> 02:00:42.000
100%. I love your animations.

02:00:42.000 --> 02:00:43.000
Thank you.

02:00:43.000 --> 02:00:44.000
Thank you.

02:00:44.000 --> 02:00:47.000
So as of right now, I'm thinking I'll conduct a podcast

02:00:47.000 --> 02:00:50.000
and then extract the clips, animate over those,

02:00:50.000 --> 02:00:53.000
and then if people want to see more, they can go to the podcast later.

02:00:53.000 --> 02:00:54.000
That's cool.

02:00:54.000 --> 02:00:55.000
But if they'll work together.

02:00:55.000 --> 02:00:57.000
I think that's going to work.

02:00:57.000 --> 02:00:59.000
Because there's about a million podcasts

02:00:59.000 --> 02:01:02.000
and just about everybody you meet now has a podcast.

02:01:02.000 --> 02:01:06.000
And so I didn't want to just make another brick in the wall.

02:01:06.000 --> 02:01:07.000
Yep.

02:01:07.000 --> 02:01:11.000
But anyways, I'll end the recording here.

