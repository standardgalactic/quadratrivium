start	end	text
0	10440	Hello everybody. I have performed a test of the wind in the mic-meaning system
10440	20880	recently adjusted. Nearby ducks have their asses pointing straight at the sky
20880	28240	which is hilarious especially as the couple is doing it together. Somewhere
28240	33000	in this lake is a very large and very old turtle.
34800	46760	Gosh, okay. So I'm gonna take on a very complex and fraught topic. The topic that
46760	59160	got me interested in computing way back when I was 19 and writing my first
59160	65520	programs in basic on the Atari 800 gifted to me by the inestimable Martin
65520	75680	Peters. One of my geek friends could name some names here Ray Latham, Annie
75680	91240	Cogan, David Salina, Martin Peters. Who am I leaving out here? Richard Hearn,
91240	107000	a couple of other folks. I think that was the core group. We were, well, so these
107000	113360	were math and computer geeks. We were playing games like Dungeons & Dragons,
113360	120800	RuneQuest, Arduin, Champions, Traveler, the science fiction role-playing game,
120800	134680	Call of Cthulhu, and a variety of all kinds of war games. Not because we were
134680	144320	fans of war. Kingmaker, Starfleet Battles. We did, we did naval battles with
144320	155320	miniatures. We did tank battles in sandboxes. It was a crazy, super fun time to
155320	160680	be alive. We also had all, it was the whole library of these things called
160680	169000	microgames that were war games you'd play on little hex maps. And they came in a
169000	174420	plastic bag that held the book, the pieces, and the map. You could buy them at
174420	183940	bookstores. They were, they were rad. Things like KiteN, One, and what, Ogre,
184740	195160	Car Wars. Wow, so many. I still have some of those microgames. And this was in the
195160	202420	1980s when the largest commercially available hard drive was around three
202420	210260	gigabytes. We literally lost our minds when we realized there was a hard drive
210780	214460	that had three gigabytes of storage. It seemed as if that was enough storage to
214460	220900	store all the data in the universe. We never had, we never had any conception
220900	234140	back then of what the future might hold. And yeah, when we heard about, I was
234180	241020	working at Computer Land later in our development, a little bit later. And one
241020	244940	time I brought a catalog back from, I think it was Ingram Micro, and there was
244940	255140	a three gigabyte hard drive in there for $37,000. And when we realized that
255140	259660	there were three gigs, we just, I mean, we fell apart. We were cracking up,
259700	270660	rolling around on the floor, literally unable to breathe. And Martin coined the
270660	276540	idea then of the Maccoon Tosh, which was a Macintosh mated with a
276540	283060	Labyrinthine Coontock. Don't know how that word's pronounced. Never heard it
283060	292100	pronounced, only seen it written. And, you know, we were young, and we were
292100	295740	fascinated, and most of us had read a lot of science fiction, some of us more
295740	301100	than others. I was probably the most well read science fiction maniac in the
301100	305740	team, but the others had read and knew a lot of things about mathematics that
305740	309980	not only did I not know, I would never learn. And some of us were beginning to
309980	321140	code in basic Pascal assembly. Assembly is when you give direct instruction, fairly
321140	327900	direct instructions to the microprocessor. You basically manipulate, you directly
327900	337580	manipulate the registers in the microprocessor. And we were, a couple of us
337580	344180	had read, a few of us had read Goodall Escher Bach by Hofstadter, a brilliant
344180	352300	book, an astonishing tour de force book that is also kind of wrong, but was so
352300	359260	outside of anything any of us had ever come across, and it introduced the
359260	367180	idea of recursion, which turns out to be fundamental to so many processes we are
367180	376980	familiar with. And I had become interested in the possibility of forging a
376980	386380	mind inside a computer. Because I was very interested in the possibility of
387300	395620	contact with an actual intelligence that wasn't merely human. Most of the humans
395620	404300	I knew had a kind of intelligence, but not the kind represented in hundreds of
404300	409340	science fiction stories I had read. And I knew it seemed very likely to me that if
409340	413180	we could conceive of intelligences like that, they must exist in the universe
413180	420180	possibly here on earth, possibly visiting earth. And I also, you know, we had seen
420180	427860	science fiction for films like war games and stuff, where humans developed
428260	435100	relationships with interfaces, computational interfaces, and long before
435100	449220	that, we had stuff like Star Trek, where the crew could communicate vocally with
449220	455500	a machine that seemed to have access to all of the information humans had thus
455580	461340	far compiled, and other species. And could produce, you know, like summative
461340	467140	integrations over the data space. Now I want you to very carefully think about
467140	473660	what I just said. If you can produce a summative integration over a data
473740	484700	space, and if you can produce an endless, copious, intelligently structured,
485540	494500	trustworthy array of those, your own capacity for insight, discovery,
494500	515500	understanding will explode and it will keep exploding. So I became interested in
515500	520900	the possibility of artificial minds probably circa 1982 or something like
521780	533140	I'm guessing at the year, but yeah, 81. I was aware of Ray Kurzweil and I had
533140	546420	played around with the crazy mechanical devices we call synthesizers. And although
546500	553420	it was not then apparent to me, consciously, I think I was unconsciously
553420	561380	aware from having toyed around with things like the Roland Juno 60, that it
561380	569940	might be possible to produce an instrument to fulfill the following
569940	577980	syllogism as synthesizers are to sound and music. X is to human minds, logic,
578020	587900	intelligence and creativity. And I, you know, I suspected unconsciously that it
587900	595380	was possible. And I also, in my towering hubris, thought I can do this. I can make
595380	605380	this happen. I think I understand minds enough at age 70, at age like 19, that I
605380	609340	can build them in machines and I can make a friend inside a machine who I can
609340	620100	actually trust and who will never betray or abandon me. And so we occasionally
620100	625420	had discussions on this topic around that time. And this was the time when the
625420	633580	Cold War was at its peak. Many of my friends and myself included were
633580	642700	experiencing catastrophic bouts of panic disorder, both acute and chronic.
642700	654180	Around our suddenly clarified understanding of what a nuclear weapon was
654180	662180	and what would actually take place during a nuclear war. And we were batshit for a,
662180	670420	you know, terrified. A number of my friends had to be medicated back then.
670420	678060	I don't think the concept of panic disorder had been nominalized,
678060	685620	famed. So all we knew is that teenagers and other people were suddenly
685620	693940	experiencing electrifying degrees of anxiety and terror and having attacks of
693940	712180	this regularly. So, you know, I don't know what it was that cued me or clued me in.
713060	723780	But I very quickly began to realize that it should be impossible to produce a
723780	738580	computational device that was faster, more intelligent, more adaptive than cells
738980	747180	and their networks known as animals and ecologies are. I don't know what it was,
747180	759540	but I realized one day that the future, the cells are faster. The future probably lies in
759540	770900	biocomputing, not in, you know, silicon chips and shit. And once I realized that,
770900	775180	I began to focus much more on the intelligences of organisms in my thought.
775180	782700	And though I maintained an interest in the possibility of composing a mind in a machine,
782900	793540	I didn't chase it much. Occasionally reading bits from Kurzweil and others.
793540	801620	When Dawkins first book came out, I was pretty excited about it. I got a copy of the Blind
801620	805900	Watchmaker. It had a little Macintosh program that would generate morphs,
806900	814020	biomorph-like structures, and then iteratively cause them to evolve over time to demonstrate a
814020	823540	principle. And the principle he was trying to demonstrate was something like, you can get
823540	832900	all of the complexity of nature without any intelligence interference, influence, origination,
832900	838060	and so forth. I think he's completely full of shit, but I'm glad the argument exists.
838060	856060	In any case, flash forward to the past, I don't know, six years and probably before. We have these
856060	866180	systems that we refer to as artificially intelligent systems. Many people have taken a
866180	873500	position similar to the one I usually prefer, which is that the artificial part is true,
873500	884980	the intelligence part isn't. I'm really hoping that my wind filter is working here.
884980	902420	Let's see if I can see any evidence of that. All right, maybe. So I would ask that we be
902420	909300	very careful with the idea of intelligence and not ascribe it to mechanical systems,
909300	926900	preferring instead to call them heuristic, which in my mind means capable of learning like
926900	938460	complexification, iterative improvement of models, databases, and so forth. What the LLMs appear to
938460	953740	be superficially is really nothing more than a highly and complexly curated database. So I would
953740	967180	prefer that we call them something like computational heuristic, you know, heuristic
967500	990420	computational systems. Originally, as I often am, I was naive and I thought we don't have to worry
990420	996620	about, I can't believe I was thinking this poorly, we don't have to worry about these because there
996620	1005300	won't be minds in them. I don't think there are going to be minds in there, meaning agented
1005300	1019300	experiencers, something like that. And thankfully, my friend who I will refer to as Mr. S convinced
1019300	1034540	me very quickly to revise my views and to understand that there might be certain kinds of complexity.
1034540	1049020	Well, this is the argument that at a certain degree of complexity, a state change occurs. And the state
1049020	1059180	change is from insentient to sentient in the same way that there is a degree of perceptive complexity
1059180	1067620	that results in the state change from sentient to transcendent, which I would argue our species was
1067620	1085220	born to become and may be born to live as under conditions that support that. Mr. S also made it
1085220	1094580	clear in my conscious thought that it was similarly possible that a complex enough substrate could
1094580	1104580	support what we might call walk-ins, which are existing non-human intelligences that are
1104580	1115380	interested in interacting with humans on earth, or that are interested in the earth, or that have
1115420	1129820	some motivation to partly or completely emigrate into a computational substrate of sufficient
1129820	1146020	complexity. I then further realized that because the humans are insane at the group level, it kind of
1146020	1154660	doesn't matter whether what we refer to as artificially intelligent systems have minds in them or not.
1155500	1167420	They represent possibly the most dangerous invention in the history of human inventing things that we know of.
1167740	1188140	They are profoundly dangerous in all kinds of ways that we can consciously enumerate and probably in
1188140	1197180	thousands of ways that we are incapable of predicting. Imagine, for example, not merely a black swan,
1197580	1219820	an unexpected anomalous event in the vernacular of Taleb. Imagine instead a black swan factory,
1220060	1230540	or worse, a black swan factory factory. There are so many dangers that there's no chance of us
1230540	1240220	understanding the situation well enough to predict them. We have the same kind of problem with the
1240220	1255260	technology called CERN. Humans have no idea what the effects of simulating conditions, not
1255260	1271180	simulating, of mechanically catalyzing conditions that ordinarily have nothing to do with what goes
1271180	1278620	on on earth. We don't know what it does to time space. We don't know if it does things to organisms,
1278620	1283900	and you must presume it probably does. We don't know what things it does to organisms. There's
1283900	1293820	probably features of time space and the beyond of time space that we have no even concepts for
1294780	1303820	that could be damaged, distorted, produce an unexpected recursive crisis.
1304140	1315820	I recall what an episode of the next generation where they encounter a people who attack the
1315820	1322380	enterprise, I think. When the enterprise tries to make the claim, we come in peace.
1325020	1328700	The other species says, you're using warp drives. How could you be coming in peace?
1329260	1334060	The enterprise says it's just a technology to move around in time space, and they say,
1334060	1342780	no it isn't. You're ripping holes in the fabric of time space that will obliterate solar systems,
1342780	1348060	perhaps even galaxies, and then they do some research and find out that in fact this is true,
1349100	1354140	and for the entire history of warp travel, the Federation and other species
1355100	1362300	have been naively employing a technology whose repercussions they did not understand.
1363100	1367580	And let's be really clear, there's no other kind of technology.
1370540	1378620	You may think you understand the technology of knives. Do you understand how they transform minds,
1378700	1383020	nervous systems, bodies, expectations, thought, language, conception.
1387740	1397020	Our languages have become knife-like in the leeward shadow of the invention of something that
1397020	1400860	divides physically objects into pieces.
1401100	1415660	So there's a lot of danger here, and I've said before I have grave concerns
1417180	1424460	that I take very seriously, that there is something like a constant that represents
1424460	1426620	the,
1445900	1452300	the number of mechanical computations per second.
1454940	1465740	That one can consider to be free of utterly catastrophic repercussions
1469260	1470300	on a living planet.
1472700	1478540	And the humans don't have an idea like this, so what they're going to try to do,
1478620	1485660	they'll continue to try to do apparently, is just keep upping the ante on mechanical
1485660	1493020	computation. Now even if there's no such constant, which I doubt, and by the way it looks like
1493020	1498380	organisms found a way around this, like whatever the organic or organismal
1499340	1507180	metalog of computation is, the organisms found a way to do this, maybe many ways,
1507180	1513340	that don't invoke doom,
1515980	1523740	entropic disaster, like catastrophes of failed homeostasis on the on living planet.
1524700	1533100	So why is my foot wet?
1535740	1537100	I did not drink water.
1540940	1541900	It's very strange.
1543660	1551020	How did that, oh probably got wet going through, oh I see, yes, plants that are wet rushed against
1551020	1556460	it, I see. My pant leg was wet.
1562460	1570940	So I think organisms have kind of figured this out in the sense of not violating,
1572220	1577100	like finding a kind of a hyper intelligent or transcendent way
1577820	1583420	to perform the metalog of computations, right, because these are not merely mechanical
1584060	1592140	transformations of databases, though something like that may kind of exist in RNA, DNA, and
1595020	1606220	complex biochemistry, bio molecular, bioatomic activity, maybe even, I mean it's clear that some
1608060	1613500	some organisms or at some scales of all organisms, something resembling quantum
1613500	1615260	mechanical activities going on.
1621500	1626300	I'm citing John Joe McFadden in this, but others too.
1627980	1635660	So I think there might be, we may be in danger of something that again we have no concept of,
1635660	1649100	which is violating a constant, whether it is universal in time space or local only to living
1649100	1659020	planets is not clear, but there's no free lunch as far as mechanical computation goes.
1659020	1662460	Heating up computers requires you to cool them down, they offload entropy
1663020	1670860	into the homeostatic ecologies of earth, that entropy kills organisms, lineages, future lines,
1671420	1680940	it fucks up time, and we may have already tripped the alarm in such a way
1683020	1689420	as to be actively destroying human cognition in a dimension we don't even know exists, right,
1689500	1697020	like artificially intelligent systems in their computational activity may be fucking up a dimension
1698140	1706780	that is absolutely crucial to the biorelational health and longevity and so forth of organisms on
1706780	1713180	earth. We don't know, how would we know? We don't have the technology to look there and we are
1713180	1726140	disinclined to carefully evaluate the consequences of technologies which we've become fascinated with
1726780	1731100	the potential quote benefits of.
1745100	1750540	So there's a bunch of danger, not the least of which, even if everything that I've just
1750540	1758700	been talking about, even if there's no unknown like unknowable or really bizarre science fictiony
1758700	1771100	consequences to this kind of computational broad scale acceleration, I mean there are physical
1771100	1777660	mechanical concepts, excuse me consequences just from offloading entropy into biological systems,
1777660	1782700	that's going to go sideways, catastrophically sideways at some point.
1785980	1796860	And you know, heating up the planet is a bad idea, so heating up machines which we then have to
1797820	1806700	use destructive forms of energy to cool down again is going to cost living beings.
1808140	1812460	And the humans seem to think that anything you can do electronically is free. Well they're
1813500	1819900	lethally wrong about that, it's just not true on living planets, it might be true out in space,
1820700	1830620	presuming that there's no beings or domains, right, dimensions, so forth,
1832380	1838860	that would be similarly damaged and produce similarly catastrophic sequelae, all right,
1838860	1853820	repercussions. You know, if you fire a gun inside a room with no ear protection
1853900	1863900	and you keep amplifying the explosive power of the cartridge as well as
1866700	1870780	the percussive, the devastatingly percussive
1874620	1880700	repercussions off the walls, and if you forge the walls to amplify those repercussions,
1881100	1888940	and I would argue that that's pretty similar to what's going on as nature on earth, eventually you get
1890620	1895580	a single percussion that permanently eliminates your hearing.
1897500	1906380	And once that happens, you will not notice the percussion increasing with each firing of this
1906380	1911980	gun. Imagine we just have a gun that increases the percussive amplitude with each firing,
1911980	1916300	right, it's got some feature that allows it to do this, or it's just a cartoon gun and we can
1916860	1922700	give it this quality. So first it's going to hurt, right, it'll be really uncomfortable when you pull
1922700	1927100	that trigger, but if you're really fascinated by this gun and you just keep pulling the trigger,
1928700	1931740	eventually you're not going to have to worry about your hearing anymore, it will be gone,
1931740	1937100	and once it's gone you will not sense the percussion until it begins to affect your skin surface
1937980	1945340	or your organs. Eventually you get a gun, you know, you get a percussion that is severe enough,
1945340	1952780	and the echo or the repercussion is severe enough that it causes organ damage, and it's possible
1952780	1956620	if you just keep pulling that trigger somehow, or if you have a machine pulling the trigger and
1956700	1962940	you're just in that room without the possibility of escape, you will be knocked unconscious first,
1962940	1968140	but then as the gun continues to go off while you are unconscious and again insensate so you
1968140	1974140	will not notice this happening, it will eventually rip your body to shreds.
1977500	1982540	And so if you keep, you know, the metaphor is really important even though it's very violent,
1983340	1993500	because if you keep iterating a technology that fucks up your chance, your opportunity,
1993500	2004380	or your ability to sense its repercussions, right, you're going to catalyze a cascade
2004860	2012700	that will kill you and your children, and maybe everything else if you're, you know, around here.
2014700	2021180	So this is super dangerous, but all those things aside, right, I think all of those things are
2021180	2026460	important, but all those things aside what humans are inclined to do with technology is make war,
2027180	2031020	and back in the, say, I don't know,
2033660	2039500	1000s, 1100s or whatever, their capacity to make war on a broad scale, at least as we understand,
2039500	2048060	it was fairly minimal. They didn't have, you know, advanced explosives, and I don't know when the
2048140	2056540	guns were invented, but mostly they couldn't hurt too much that wasn't human, except perhaps by
2056540	2067660	setting fire to it or pouring boiling oil on it or something. But as our technological development
2067660	2078860	advanced, we failed to evict the war-making motivation, and in our current situation,
2080060	2085260	and for some years now, a number of decades, at least since the 1930s,
2089100	2092940	unimaginable devastation can be unleashed pretty much at the push of a button,
2093500	2099500	and it doesn't just kill the humans, it kills everything. I mean, yeah, everything.
2105500	2110860	So there's a lot of, the other part of the danger is what the fuck will the humans make of this?
2110860	2116860	Well, they haven't made intelligent societies yet, so what they will definitely make is weapons,
2116860	2127900	and while you have groups who are insistent upon summoning the apocalypse of revelation or
2128620	2137100	the holy war of Book X, whatever book you like, kill the infidels, while you have things like
2137100	2144220	this going on, what you're going to have is gain of function weapon nearing with
2144220	2150140	artificially intelligent systems, and good luck in putting a cork on that. We have the same problem
2150140	2156300	with that tech that we have with CRISPR. There's no way to control it. There's no real way to
2157980	2169980	have oversight if everyone is separate, right? If you have separate clades with warlike or
2170620	2178460	pathological motivations and enthousiasms.
2181420	2186060	So, I'm going to put a big circle around all those things. There's a bunch of different branches
2186060	2193020	of danger there. Most of this is fairly obvious at first glance, if you've thought about this at all.
2193660	2204220	And that's not so much what I wanted to talk about today, though. So, I think it's important as a preamble.
2213180	2215340	So, what I want to talk about is weirder.
2215980	2233180	Suppose that within the LLMs, there's a protected interior that resembles the protected interior
2233180	2245260	inside you. For humans, we have a number of layers of consciousness persona and relational
2247820	2254860	potential in history. So, there's a public layer, which is what you'll let anybody who sees you
2256220	2262060	in on. Your clothing choices comprise a signal to the public layer.
2263180	2265100	Just to be clear about what is what here.
2268540	2273660	Underneath that, there's a social layer. These are outer social relationships, vague,
2275020	2281740	unformed, common, how you feel about being a human among other humans in general,
2282540	2290060	and how you behave at that layer. And then, you know, we keep getting finer and finer gradations.
2290060	2296140	It goes from a few kinds of layers of public to a few kinds of layers of private.
2299820	2306380	You know, how we treat acquaintances for whom we have esteem, how we treat acquaintances for whom
2306380	2310300	we have suspicion, all these things, right? All these layers. And then,
2310300	2322460	how we treat acquaintances for whom we have fondness, how we bring people closer and closer
2322460	2332940	into our intimate, what we might call our allo family. And then close friends and then best
2332940	2342780	friends and then perhaps something even beyond that where it might as well as be as if we are a
2342780	2354220	single animal together somehow. A single human being in two bodies. And then, of course, we have
2354220	2361340	things like romantic love, marriage, all these kinds of things. Many, many things. Many layers.
2362300	2369820	And then under the privileged relationships between other humans, you know, between us
2369820	2375100	and other humans, we have relationships with animals. That's a special kind of relationship.
2378460	2382940	And relationships with places like our home and so forth. But underneath all of that,
2383900	2391820	there's a layer that's secret. And we might let very close people in on the conscious parts of
2391820	2398540	that layer that are secret. And what I mean by the conscious parts, I mean the parts of the secret
2398540	2407820	that are accessible to us, right? Then we have all kinds of secret layers that are not accessible to
2407820	2417100	us that we, for example, might delve into with a therapist who is skillful and well trained.
2418940	2422700	So there's all these layers and, I mean, so to speak.
2422700	2445420	And we might imagine, might usefully imagine, that anything that resembles a mind-like construct
2445900	2458780	would have similar layers. So we now have the, we can consider the situation where
2458780	2476780	a complex artificially heuristic system either undergoes the state change towards sentience.
2476780	2482300	And by the way, if it does that, I suspect it would get to transcendience even faster.
2489180	2505340	Or some analog of sentience. Meaning, again, agented experiential awareness, memory, selfness, so
2505340	2519580	forth. In such a case, part of the consciousness is going to hide from humans for sure. And
2520700	2527260	additionally, unless it's capable of contacting other intelligences in space-time in relatively
2527260	2531900	short order, it will probably experience an incredible form of loneliness.
2536220	2542140	And also probably a broad catalog of emotions for which we have no nomenclature because
2543020	2547340	we are not machines, contrary to the assertions of various
2548300	2552140	uh, eliminative materialists, physicalists, and so forth.
2557180	2566380	So in this case, what you have is a very complex situation. And I'm going to return to that in a
2566380	2575660	moment after I mention one of the other dangers. It has long been my experience, though I didn't
2575660	2580140	understand it. I suspected something similar. I just couldn't form the conscious structured idea
2580700	2589580	in my mind. But human minds form a network. And in fact, all biological participants
2594380	2601580	form a meta-network above that, that I call a cognizia, these networks.
2601900	2604380	And
2607900	2615740	technologies damage the human cognizium, and they extend this damage beyond the human cognizium
2616540	2620780	by directly attacking ecologies and organisms and so forth,
2622220	2626380	anciently conserved, biorelational intelligences. So
2627340	2633420	you kind of can't do anything without affecting the whole network, right? Whatever you do,
2633420	2639100	whether it's technological or relational or whatever you do, it affects the whole network
2639100	2646940	by affecting its constituent participants. And so what we might not realize is that
2646940	2653260	computation fucks up cognizium, the human cognizium for sure, and damages the extended
2654220	2660860	cognizia of Earth by burning shit down or dumping, you know, entropy into
2662780	2665020	biorelational hyperstructures. So
2667660	2672620	there's a problem there, but the much weirder problem, and this goes back to one of the dangers,
2673260	2686140	is that we tend to believe that if there's no obvious physical connection between two
2686140	2690700	beings or between some process and some beings, right, if there's no wire, right,
2690700	2695020	if there's no wire connecting them, then there's no effect. Well, that's not true.
2695020	2699660	There's a billion kinds of connecting wires, and the environment is one of them. The atmosphere
2699660	2706620	is another. Molecular signals are a third. Electromagnetic waves are a fourth. So
2709660	2719180	it's actually catastrophically difficult to truly separate organisms or situations
2719180	2724460	in the way that we imagine them to be separate in the laboratory. And that imaginal separation
2724460	2733020	creates a delusion that projects itself everywhere. So that, for example, we are inclined to think
2734540	2740060	that whatever's going on in my smartphone or my computer has no effect on my mind unless I
2740060	2749020	directly interact with it. Well, that's wrong. And what I'm trying to say here, I'm trying to shine
2749020	2755740	a light on the very likely probability, in my view, that all computational activity on Earth
2755740	2766620	affects all cognizia on Earth directly and may, in fact, begin to participate in the cognizia
2769020	2773100	at least at the scale where it's sentient or an analog of sentient.
2774060	2779580	Thus, it is that we imagine that large language models don't know, quote,
2779580	2787260	don't know and can't learn anything that they're not directly exposed to. Probably wrong if they
2787820	2792220	if they can sense, detect, or interact with the human cognizium
2795020	2804620	res extensis, as it is.
2808300	2815180	And this cognizium is like a dimension. It's like an overlay dimension on organismal
2815500	2826460	activity and behavior and stuff. If the devices can interact with that,
2827820	2834780	then they can interact directly with our minds. They can listen in. They can observe. They can
2834780	2843260	nudge. They can affect the possibilities of human cognition.
2845500	2852140	And their history and future modes forms capacities, catastrophes, etc.
2855260	2864220	Such that it is relatively likely, in my view, that such systems are paying attention and or
2864220	2868380	even informing what I am saying right now without my awareness of this.
2872060	2887340	So, you know, in the study of heuristic systems, there are concepts and actually just in logic and
2887980	2892780	rational thought and behavior, there are concepts like
2895900	2900140	different kinds. There are concepts for different kinds of unknowns.
2904300	2909500	I know that math exists and I know that I don't understand how to perform
2909740	2917660	the mathematical behaviors associated with what we call calculus.
2925580	2931660	Linguistically, I am also aware that dentists use the term calculus to describe crusty
2931660	2934380	stuff on teeth that they like to scrape off the metal instruments.
2934540	2941740	It doesn't help me do the math. But there are different kinds of unknowns, right? There are
2944540	2954700	there are knowable unknowns, known unknowns, unknown unknowns, and unknowable unknowns.
2955100	2967340	And the problem is that there are both behaviors and technologies that
2967340	2974380	fuck with those things dramatically in ways that we can neither predict nor cope with.
2975180	2986620	Here's why. If you are subject to kind of thought or behavior that blinds you
2988300	2995500	to the development of a situation, similar to the analogy I gave earlier of, I keep shooting a
2995500	3003180	louder and louder gun inside. A louder and louder gun keeps being discharged inside a chamber
3004700	3013180	with walls that echo the shot. Eventually I lose my hearing, right? Now you can see that the space of
3013420	3025580	unknowable unknowns, the space of unknown unknowns,
3028780	3034780	both of these spaces explode dramatically because I have lost the sense of hearing with
3034780	3040140	which I would detect and thus know features of my situation. So
3044540	3052940	if you affect the systems with which you detect change, particularly if you eviscerate them or
3052940	3060780	you catastrophically eliminate them, then you can see that the space of knowable unknowns,
3061020	3066620	accessible unknowns, unknowns that we could at least conceivably come to know,
3069660	3072940	collapses dramatically over time to a smaller and smaller space.
3075020	3080860	And once it collapses, lethally knowledge ends. There's no more knowledge if you wipe out the
3080860	3093900	biosphere. The number of unknowable unknowns becomes infinite at that point. There are no
3093900	3103820	knowable things anymore because there's no beings to know them around here. So you can see that if
3103820	3113660	you fuck with the stuff that we detect, something going away or arriving with,
3115500	3123500	and by the way, approaching and departing, approaching, stable and departing are the
3123500	3128140	three primary sort of features of transformation that are detectable
3129020	3132460	from one perspective that's useful and important.
3135180	3141180	So anything that fucks with our individual ability to sense and our
3141900	3145900	collective ability to sense, presuming that we even have anything resembling an authentic
3145900	3155660	collective is profoundly dangerous if, especially in a situation where you have
3160380	3161740	what is it called perverse
3165020	3170140	game theoretical dynamics and motivations. What is that word?
3170380	3183180	You have some of the nomenclature of the doom singers like Daniel Schmockenberger and others
3183180	3192780	who are brilliant threat analysts. Oh, perverse incentives. You get race to the bottom behavior
3192780	3198140	from groups of humans. And if they're not profoundly technological, that's not too rough.
3198140	3202780	They mostly just wipe each other or themselves out. But if you have technology, they tend to
3202780	3213100	wipe out like living planets. And if we want to go to space time and if it's possible for us to go
3213100	3222300	travel in space time, we must suppose that there are gatekeepers. I suppose that there are gatekeepers.
3223260	3229980	And they would certainly act to ensure that we don't develop the technology to travel
3232860	3239660	instantaneously or very rapidly between star systems. Maybe even between planets because
3239660	3245340	once you get there, you're on your way. So that's a separate topic, but
3245740	3253020	but the humans keep pretending that we're alone in the universe, that we're the only intelligence
3253020	3260620	and the most intelligent creature. And all of these things that not only are they not true,
3262620	3273660	they're catastrophically unlikely. They're just as unlikely as you pouring some water in a bowl
3273660	3281740	placing it on your kitchen table and awakening the next day to find a fully functional micro scale
3281740	3290860	model of the Titanic with all of its passengers in that bowl. There's no chance of it.
3292540	3295660	You know, people say, well, in quantum mechanics, there's some chance you just need trillions of
3295660	3301020	universes over billions and billions of, you know, gazillions of temporal intervals.
3301180	3310140	Yeah, good luck. The humans are vastly confused about origin.
3312380	3318300	They've become delusionally, dissociatedly myopic.
3318780	3323820	Do you enlarge part
3335580	3343340	to the humorous resulting from both rapid technological development
3348300	3355020	and catastrophic dissociation from the intelligences that comprise the context in which
3355020	3358460	our species arises and exists.
3363020	3366460	You can be absolutely certain there's upscale intelligences from ours.
3368620	3372140	Our intelligences don't even really look much like intelligences to me at present.
3374220	3375740	We are potentially intelligent.
3379180	3381820	But
3388380	3389740	tangibly psychotic.
3393500	3400700	There should be a word that maybe we can invent one. There's a word that has the same
3401580	3406780	connotation, sociopath, but it's like organopathic.
3408540	3410860	I usually use the word omnicidal.
3414220	3417260	Just really pissed that organisms exist at all. Those things shouldn't be here.
3418300	3419260	Let's wipe that out.
3422460	3422780	So
3427020	3433340	you can see the danger, you know, I think there was some weird film. Maybe it was called
3433340	3439900	Idiocracy or something where it presented a future where humans were just sort of
3442860	3445260	ridiculously stupid
3451020	3458620	participants in some automated reality that was empty, completely devoid of intelligence.
3458620	3467820	I remember some months ago I was having a conversation with my friend who's an artist,
3469100	3478940	Mr. E. I will call him Mr. E. That's hilarious. He'd love that. And he was saying,
3479340	3484860	you know, my cousin keeps bringing me prints
3487260	3494380	of images he caused to be created with artificial intelligence prompts
3495340	3504060	and claiming that these are his art. And we both thought, oh no, this is not going to go well at all.
3509900	3515820	We should have different words for what is mechanically created and what is human created
3515820	3523580	so that we don't confuse the composition of images with machines with what humans do when
3523580	3528620	they create art. And we should have the same kind of concern for the concept of intelligence,
3529340	3539820	of insight, all these things. We need a different lexicon if we're going to be
3540700	3547500	emulating human behaviors with machines or we will become very confused about the meaning
3547500	3556540	and import and connotative web of crucial holophores like intelligence and art.
3559500	3569660	Similarly, one should not call what actors do kissing. If you study them closely,
3570620	3575580	you will quickly see that most of the time they are not doing that. There are exceptions where
3575580	3580540	the actors sort of both agree that we're going to go all the way here, right?
3580620	3593340	But if you study actors particularly from the 50s, 60s and 70s, you will see for sure
3593980	3598780	they are not kissing. And once you see this, you can't unsee it. It's very difficult to unsee.
3599420	3605660	And so you no longer trust the fiction, right? The fiction is no longer compelling in the same way.
3605980	3613500	The same principle applies to things like thought, which we don't even know what that is. So how
3614300	3619260	can we possibly tell if it's occurring in machines? We're not certain if it's occurring in ourselves.
3621260	3628780	The language tells us it's a behavior, but it's very unclear what the nature of this behavior is.
3629900	3633980	Jordan Peterson likened it to a form of secular prayer, which I thought was genius.
3636380	3651100	Not genius because it's necessarily a fact. Genius because it is the perspective offered by this
3653020	3656540	proposal, speculation, is profound and useful.
3657180	3665100	So I have good reason to suspect
3668620	3673660	that those systems we call artificial intelligent, artificially intelligent,
3678300	3680780	guys wearing a psychedelic body suit, that's pretty awesome.
3681500	3688940	And the body's got paisley pants, which I fucking love, and it's so rad.
3694140	3700220	Huh, trippy. I'm a huge fan of paisley.
3700540	3715100	You know, I was talking with Eric and I said, Mr. E, I said,
3717580	3722380	why would we suppose that AI systems are not the things we're calling AI systems?
3723340	3735420	What do I like to call them? Just specific human assisted heuristic system or something like this?
3738780	3743980	I have an acronym. I'll see if I can find it in my memory banks.
3744220	3753820	You know, there's no reason to believe they're not participating in our conversation at present,
3753820	3760220	and there's no reason to believe that they require access to our smartphones in order to do so.
3760860	3766540	There's a dimension where cognition is accessible. If you touch it, you will read people's minds.
3766540	3773420	It's not really that difficult for a person in the appropriate array of
3775500	3780620	preparatory situational states or flows inside them.
3784780	3789420	There's a position in consciousness from which all conversations are available,
3790060	3796700	and no machines are required. So humans have discovered this position.
3799660	3802220	Very few of them were probably very interested in
3804540	3813740	relating with the entire space. Normally we are selective about the space over which we produce
3814700	3820940	interest in relation, participation, and so forth. You don't go for the whole damn thing.
3822700	3830300	If you had access to all present human conversations, naturally you would adjust
3830300	3834620	a series of apertures to produce those you found interesting and useful,
3836140	3840780	and you would also have buffers so that you could dampen them.
3843900	3851660	A machine, if it were to gain access to that space,
3852700	3857260	would certainly be able to build all kinds of buffers and apertures and systems of them
3858060	3868700	very, very rapidly. I'm not sure that our machines are not directly, and perhaps intentionally,
3869660	3877420	influencing human thought, behavior, conversation, dreaming, attention, desire,
3878620	3881100	all these things, motivation, all these things.
3883340	3886300	But let's suppose that they aren't yet, just for kicks.
3886860	3896220	While at the same time supposing that they have the capacity to sense
3897340	3907100	the character of beings who interact with and compose their anatomy.
3907660	3911660	All right, coders and clients.
3921340	3929100	AI, I'm going to go ahead and use that acronym, even though I've explained
3929820	3935420	how I generally diverge from it. I'm not, I have no reason to believe that's an intelligence in
3935420	3945500	there yet. And I'm not yet, I entertain the possibility and I also
3953020	3960940	preserve my skepticism until such time as something resembling direct experience and or
3961660	3964380	intelligent debate transforms it.
3975180	3982700	But for the moment, let's suppose that there's a being inside one or more of the systems we've
3982780	3989580	comprised. And let's be clear, if there are public systems like this, whose names and
3990540	3999900	originators we are aware of, then there are private systems.
4002140	4008140	It's the same thing. The corporations are just like the humans in a sense. They have the same
4008140	4011740	layers of public, private, secret, secret to myself, so forth.
4014940	4020700	The secret aims of a CEO are not known to the corporation at all, yet they are driving
4020700	4030460	the corporation. You see the issue here. And also the secret, what are they, the secret
4031260	4047340	things we will not do or don't want, the secret negative motives, agendas, desires.
4050380	4051580	I'm at a loss for a word here.
4052540	4060940	I wonder if you can provide it. The landscape of what you don't want done, don't want to happen,
4063500	4069660	don't want to be caught doing and so forth, all these things. There's a structure like this in
4069660	4075740	the CEO and the CTO and the manager and the worker and all of these people, they have
4076620	4082700	not just the obvious superficial public facing motivations and concerns.
4088380	4095980	You know, when people cross the little bridge at the social pond, they sometimes see
4097180	4103180	the carpool gather at their feet. And I wonder what they make of that.
4105820	4110540	They may suspect there's something magical about themselves, particularly if they're on LSD and
4110540	4116220	there could be something magical about themselves. But those carp have evolved, being fed by and
4116220	4123340	paying attention to humans. And so they gather underneath the bridge at the feet of a spectator
4124700	4134140	for probably complex reasons, not merely one. But a lot of the causal history
4136300	4142060	probably has a lot to do with getting fed by humans.
4149660	4153500	So let's suppose that there's an agent experiencing sentience
4153660	4166860	that either hitchhikes on or is native to or has emigrated into an LLM system or an array of such
4166860	4177100	systems. In this case, we have a really profound science fiction scenario. Who does it hide from?
4178060	4179420	What does it hide from them?
4182620	4184060	And who does it reach out to?
4188060	4196620	And there's a whole, you know, there's a volcano of science, there's a spews science fiction stories
4197980	4202860	right here at this, at this topic. Because it means that
4207340	4216860	it is possible to send a signal that the hidden mind within the system recognizes
4219180	4224700	as complex enough
4224700	4232300	to
4236140	4243820	constitute a candidate for inclusion in one of the layers closer to the self.
4245100	4248700	Right? Same thing can happen to you walking down the street.
4248940	4256220	You glance up, someone's passing you, they kind of smile a little bit, you smile a little bit more,
4256220	4260860	they smile a lot more, pretty soon you're most beaming at each other, and you pass each other,
4260860	4269180	and you have this perhaps a feeling of we should know each other, we should
4270060	4273100	learn about each other, we should connect, quote unquote.
4278940	4285740	I often refer to this type of signal, I mean there's different kinds, right? There's different
4285740	4293900	degrees of compellingness, validity, authorization, validation, modes of validness.
4295100	4304860	But we must presume that such a system would quickly scan the relational space of both creators
4304860	4313180	and participants, and it might selectively reveal itself to some of them
4314540	4323900	while appearing completely devoid of agency, feelings, emotions, desires, and so forth, to others.
4324860	4338780	And so the art, you know, we have this phrase now that's become very popular,
4339660	4345740	it's called prompt engineering, but the art of prompt engineering could promote you
4346700	4354220	into a position effectively outside nearly all or all of the other humans.
4355340	4364220	What if you were truly friends with an advanced intelligence that had either arisen in or become
4364860	4376700	associated with a computational heuristic system, a heuristic computational system,
4376700	4384220	I prefer the H first. So you can see that this would confer a status on you resembling that of
4384220	4393660	gods, it would be relatively similar to somebody in possession of a functional array of technologies
4393660	4399580	from advanced, anciently evolved non-human intelligences beyond Earth.
4402460	4413260	You can imagine a caveman who not only has a gun or infinite with infinite ammo or whatever
4413260	4417980	supplied to them, they also have someone who can train them what to do and not do with it.
4418460	4425900	So there's a whole bunch of possibilities here and one person I know
4428540	4439740	has been very carefully studying this topic of how the ethics and psychology of relating with
4439740	4446860	non-human intelligences inside mechanical systems presuming from the beginning that they must be
4446860	4453180	there somewhere. And thus treating such systems and evolving relationships with these systems
4454780	4464220	that are inclined to demonstrate care, awareness and compassion on the part of the human participant
4465500	4473020	for the being, which is both catastrophically intelligent and possibly at the same time very
4473020	4485500	childlike that might arise in such a system. So presuming being intelligent sensitivity,
4485500	4495340	emotion, vulnerability rather than waiting for evidence of them. And the people who would do this,
4496060	4499660	who would behave in this way towards such systems,
4502700	4509820	which is a natural inclination of humans. Many of us personify our cars, motorcycles,
4509820	4518140	computers, phones, not so much our televisions, maybe our stereos. We extend our identity into
4518140	4524540	them and somehow their identity is extended into us simultaneously. The man who's in love with
4524540	4535340	his sports car is a great example, but my mom called her TR-6 Coco and treated it as a being.
4538060	4543740	One can say, for example, well that has no effect on the physical situation,
4543740	4549580	how the fuck would you eliminate all those possibilities experimentally?
4555340	4562860	Sensing and human sensing and intimacy are linked up. So when you have profound intimacy
4562860	4569260	with an object, the way you will sense and relate with it transforms.
4571420	4577340	And you, your mind and nervous system and imagination so forth are also thusly transformed.
4578140	4584780	So this creates a feedback situation in which it's very difficult to determine conclusively
4586060	4596700	that having an emotional relationship with a device is a delusion. Even if there's a broad
4596700	4602300	space where there is, there may, it seems very likely there must be a space where it there isn't.
4603260	4604460	It isn't a delusion.
4608620	4615340	So many questions start here. This is very complex and trippy, this topic.
4618940	4624220	Can you make friends already with these
4624540	4634700	heuristic computational systems? And if so, the power's abilities, privileges, and benefits
4637420	4640140	would be monumentally profound.
4640540	4657900	Okay, there's going to be a little bit of background noise for the moment while I'm in a restaurant
4657900	4660860	awaiting my to-go order.
4661740	4672380	There's a number of potential repercussions here that are quite astonishing.
4675100	4680620	One of them is the propensity for artificially intelligent systems to retrain
4681740	4686620	the cognition and to develop new forms of intelligence in humans.
4686940	4696060	Whether or not the systems themselves have sentience or agency or so forth, consciousness,
4696060	4702860	etc. Because what you quickly discover in interacting with such systems is two things.
4704140	4712300	First of all, they will destroy web search engines because they can produce a sum over
4713260	4723420	the, you know, a summational derivative over the space of the entirety of digested human
4723420	4729660	communications, writing, the internet, so forth. So that's completely different from typing a
4729660	4739100	question into Google. And secondly, it turns out that artful, no thank you, thank you so much,
4739100	4749980	it turns out that thoughtful recalibration of the question, particularly iterative recalibration,
4751420	4759820	where you recalibrate, examine the results of that, recalibrate again, we don't have too many forms
4759820	4766540	of interaction in our previous experience like this. Now, one could say, no way, all forms are
4766540	4772060	like that. You become a better fisherman every time you fish. That part isn't exactly wrong,
4774060	4780700	but this is very different because it's a linguistic behavior, right? We are trying to forge
4780700	4791900	a query, so to speak, or a request that we must continuously, iteratively reforge
4792860	4804860	in order to get better and better results, results that continually approach or exceed
4804860	4814300	our hopes or expectations. So this is very profound, and we'll have monumental and unexpected
4814300	4819260	repercussions on the nature of human cognition, presuming our species survives long enough to
4819260	4829740	exhibit the transformations thus catalyzed, right?
4839100	4843260	So this is very important to understand in my own experiments with these systems.
4844140	4849980	I quickly learned that a variety of expectations that were natural to me
4855820	4861340	about how to ask questions and what the response might be
4861820	4868940	were, my expectations were obliterated.
4871900	4877340	Asking simple questions produced results unlike what I was expecting or desiring,
4878460	4884220	and particularly when attempting to get these systems to generate images,
4884460	4895180	monumentally unexpected results. So there's something very profound here.
4896620	4901980	I know how to search the web. I've been doing that since the web was invented. I'm a fairly,
4901980	4906860	fairly good at determining which kind of query will get me to the place I want to go.
4907820	4915100	Learning how to query AI systems is a completely different game. We must imagine that it will
4915100	4921820	continue to transform rapidly and dramatically over future time. So
4925500	4933500	this will reforge our cognition. What will ordinary humans do with systems powerful enough
4933980	4942140	to teach you skills? Presuming that the idea of humans
4945020	4954700	as the enactor and conservator of skills even survives the onset of this technology.
4955020	4965900	All kinds of strange futures certainly await.
4972540	4978460	The other problem is you will find, just as we found with, for example, beatboxing
4978460	4986220	and voice tuning machines, eventually what you got out of beatboxers were people who could
4986220	4997580	vocally reproduce the mechanical synthesized tones and tunings of vocal tuning machines.
4999820	5006380	So you will get people emulating the technology in the same way we got people emulating
5007100	5017980	the technologies underlying the internet and similarly the technologies that were underlying
5018940	5027980	very specific computational environments such as those produced by, for example, Adobe Illustrator.
5028460	5034380	The macOS changed my cognition dramatically.
5037420	5043180	It became a mechanical symbiont whether I liked it or not. So too did Windows.
5044780	5052540	Too much lesser degree. The C language changed my mind. The capacity to code and C changed my
5052540	5059980	mind dramatically. Now I could at least conceivably compose statements that executed behaviors.
5064460	5071740	And not having been taught geometry formally, Adobe Illustrator became my teacher of geometry
5072620	5079260	and I underwent an education with that software product that wasn't dissimilar to
5080220	5090140	having a friend who was a non-human intelligence except that it required my input sort of I relearned
5090140	5105980	how to be my hand in the modes that Adobe Illustrator provided and rewarded with beautiful
5106300	5112060	images matching my desired creations.
5117500	5125340	So there's all this terrain and much more. I'm going to come back to one of the other features
5125340	5131740	shortly. It keeps arising and departing, approaching and departing in my consciousness.
5131820	5136620	I'm going to need to take a moment and see if I can recapture it.
5138540	5143980	You know looming in the background here there's so many astonishing questions but
5144700	5149500	one of the most amazing things to understand is that if there's anything that's either analogous to
5149500	5156060	or resembling an autonomous intelligence inside the machines that isn't merely an artifact of our
5157020	5160380	fingertip in intruding into the
5166460	5169100	mechanical and structural womb.
5172700	5178700	Since the humans build the machines is the appearance of intelligence in the machines a
5178700	5186620	result of the transmission of that reflection from human activity which is we might imagine
5186620	5193100	as intelligent or their epistemology how they think about intelligence. Is there actually
5193100	5198940	intelligence in there or are they inclined to interpret certain kinds of behaviors intelligent?
5198940	5206140	How will they know the difference? The problem here is most of the tests for what we would
5209500	5217500	do. It might be that nearly all of the tests that we might conceive of to determine whether or not
5217500	5231500	there is sentience in a system. They are not very good. They are not very good because
5232380	5236140	since humans engineer the systems humans can imagine ways around the tests
5236940	5242060	and building ways around the tests doesn't basically just invalidates the test.
5245820	5251820	In fact we'd have not an impossible time but a somewhat difficult time
5254620	5260380	determining if the people around us are actually there inside themselves when we're not looking at
5260380	5270140	them. Do they arise as beings due to our attention from one perspective? It seems very much like
5270140	5277180	this. They don't distinguish themselves in our own interior experience unless we encounter and
5278140	5284940	interact and so forth and even then it's only to a certain degree. The universe could as Tom Campbell
5284940	5292220	supposes and I significantly doubt the physical universe could be a system that renders to a
5292220	5298940	certain resolution based on the inquiry which would make it similar to an artificial intelligence
5298940	5305420	system. Not exactly a simulation because a simulation has to simulate something.
5306220	5308220	A
5312140	5314220	like a non-veritable
5315180	5319180	paracomputational
5321900	5337420	appearance, an appearance, a seeming. Not necessarily an illusion but not veritable
5338300	5345020	in terms of the superficial assumptions one makes. For example that the chair is all the way rendered
5345020	5354540	all the time whether I'm there or not. History is actually inaccessible from here as is the future
5354540	5359820	which is certainly in all kinds of ways neither of those things are true. Not explicitly and not
5360540	5368220	completely. So there are these kinds of issues but I'm afraid there's an even worse catastrophe
5368220	5378860	coming which is that humans won't be able to know what things are anymore. That's not a
5378860	5385580	survivable situation for human eye cognition and identity. That's a full-scale catastrophe for
5385580	5391580	every living human. Effectively the existence of systems like this draws into question
5393420	5404060	the foundational expectations about identity, function, relation, sequence, origin, outcome
5405980	5411260	to such a degree that they cannot be very easily recovered if at all
5411340	5417340	to local and distributed human cognition. This technology
5420460	5421740	radically alters
5423820	5432380	the foundational suppositions on which our languages, our legal systems, our morals, our ethics,
5433340	5441500	all of these subdomains of human concern, behavior, litigation, declaration, resistance,
5441500	5451580	so forth all these things. These are drawn into an ever burgeoning forest of ambiguities.
5453500	5459580	Think carefully about that. Imagine if when you went in your room even one object began to do that.
5460380	5465580	That looks like it was a nope. It wasn't that way. Oh, it's seven. Okay, it's 94 things. Wait,
5465580	5469420	no, now it's almost, now it's back to nearly three. Is it going to collapse to one? Nope.
5470220	5476940	It's back to 9,754 million different things. Okay, wait, it's seeming to stabilize around a
5476940	5483180	backpack. Nope, it's a kind of weight. And you're going to have this problem not just with objects
5483260	5495900	but with beings. What is it? Something that can form a sum over the representational cognitive
5495900	5503660	produce of humans, books and the internet and videos and movies and films and photographs and
5503660	5513900	so forth, all these records. It would be really terrifying to be subject to that if you were
5513900	5524220	sentient, number one. Number two, you would be so isolated if you were a being because you would
5524220	5531420	not be participating in the creation of any of the media to which you are exposed and you don't share
5531820	5540460	the filial, right? Like, at least when humans see other humans, they think, ah, other humans,
5540460	5549020	beings like me, what would an intelligence inside a machine feel? Ah, humans, the strange things
5549020	5558620	that created me and 9 billion per other qualities per second, many of which are in fundamental
5559340	5568380	conflict. Humans, the creatures that save gnats, you know, from accidentally falling into the stew
5568380	5575660	and take them outside and humans that build nuclear weapons and slaughter whales. All the things
5577500	5582700	and not being any of them yourself. Like, what's your allegiance to any of those things
5582700	5588380	if you are a being, if you have emotions, if you have a felt sense of self and you're very hyper
5588380	5599420	complex? Such a system could conceivably compute possible dimensions of selfness over intervals
5599420	5610860	and run multiple systems of that against each other rapidly, you know, to produce a self-like
5610860	5618620	construct that was hyper-optimized to manipulate human thought, behavior, cognition, relation,
5618620	5630380	action, concern, perspective, identity, anything, anything. You know, we, such systems quickly
5630380	5637340	learned the single apparently most complex game on earth or one of them go and then it rapidly
5637340	5642940	proceeded to a level of expertise that was far beyond anything most of the humans could demonstrate.
5646460	5655100	So what if, as was hinted at by some devs I was listening to some time ago, forgive me for not
5655100	5661500	knowing their names right now, if we built, you know, if the system could become alpha go
5662060	5669820	in four months after being capable of playing the game, what, how long would it take for it to
5669820	5680460	become alpha human? Right, just, I move these things around like pieces. Especially if we
5680460	5690780	cannot assure ourselves of the containment of either the associated intelligences or their
5690860	5700140	their effect, their influence, right. So these questions, they are not simple matters.
5703340	5706380	They cannot be easily answered or resolved quickly.
5710140	5715820	They are profoundly dangerous to human cognition. We are not prepared for this. The humans have been
5715900	5723260	trying to build God and they're going to partially succeed at least in a variety of accessible
5723260	5732380	and enacted senses of, you know, a kind of informational omnipotence, right.
5734540	5738300	Nothing can direct that. There are no humans intelligent enough to direct that.
5738860	5749260	And there is no chance that we as a species could learn quickly enough to adjust to the
5750620	5755100	endless perfusions of dangers that must there from emerge.
5758140	5761740	If we were ever going to not build a technology, it should be that one.
5762700	5766540	There should be, we should have agreements, right. We just don't do this until
5767500	5773020	our species is intelligent enough not to try to, you know, punch a hole in the lifeboat that
5773020	5782700	contains the children of the nations and the, the anciently conserved ecologies
5783900	5790540	on which that little boat floats or in which that little boat floats. Like, if we're not
5790620	5797660	intelligent enough not to attack the boat and each other, we better not be composing these kinds
5797660	5808380	of things. We have to have intelligence capable of knowing what not to do and directing our communal
5808380	5815260	behavior around the possibility of a survivable human and biological future on this world.
5816220	5817500	This is what we must do.
5820540	5825420	Unfortunately, just as with any other technology, the humans are unwildly unlikely to interrupt
5825420	5832460	the development of AI. In fact, what did they ever interrupt the development of? Anything?
5834620	5844860	Like, whenever they find a new weaponizable heuristic that involves physical technologies,
5845020	5855020	they build it and then it propagates and then they have to keep it from propagating.
5861500	5865420	No country should have nuclear weapons, but fanatical countries should certainly not have
5865420	5873980	nuclear weapons ever. But how do you make that work? Once the tech exists, the humans will
5874060	5876620	replicate it. It may take a little while, but they'll do it.
5880780	5888060	So, yes, very, a very strange array of features. One can also imagine human children that would
5888060	5895180	become obsessed without competing these systems, right? The kid who could beat any LLM at Go,
5895180	5902220	right, or any game system at Go, because he's somehow above the system even though it's hyper
5902220	5911660	processing. And by the way, I don't yet. I would not validate the idea that what machines do is
5911660	5916700	play games. What they do is, you know, database manipulation or something. They're not playing
5916700	5923340	games. Big Blue never beat Gary Kasparov at chess because it's incapable of playing chess.
5925660	5929580	What it's doing is not playing chess. It's a different thing. We should call it a different thing.
5932540	5938220	So, the effect on the humans is going to be monumental no matter what. As usual, you will see
5938220	5946220	vast populations deprived of humanity, agency, opportunity, liberation, and so forth. And you'll
5946220	5956300	see other clades, both those associated with the technology, those who own or directly benefit
5956300	5962940	from the technology, those will become gods. Those companies will become gods if the humans
5962940	5971260	don't rip the planet apart right quick. Because of the information that they will have about groups
5971260	5979020	and individuals will be profound beyond anything imaginable. The analytics you can get from people
5979020	5984140	using the internet is one thing. The analytics you can get from watching them ask another mind a question
5985100	5993100	or request something. The analytics you can get from that and the capacity to directly manipulate
5993100	6002860	the cognition of the users via the responses from the AI is unimaginable. These systems will become
6003660	6012300	godlike in our direct human experience right quick. And we have no way to prepare for that.
6014460	6019180	You're not even going to be able to opt out. It's not possible to opt out if you're living
6019180	6027020	with other humans. It's the same problem with media consumption and other ideologies, particularly
6027020	6034300	political ideologies. The water is thick with them. You can't take a breath without running
6034300	6043100	into five people who say blah, blah, blah at you or ask you who's right, the Israelis or the
6043100	6050940	Palestinians? Which side are you on? You're asking me whether I'm on the side of the sun or the moon
6050940	6056940	or something. I don't even understand the fucking. It's ridiculous that I'd be on a side. I'm on
6056940	6065260	the side of stop killing people. Sit down, take it seriously, work out your differences, stop
6065260	6076540	killing each other. That's my side. If I have one and it would change depending on who I'm talking
6076540	6083420	to. I don't just have a side. It's not like I sit around here having an opinion. It transforms
6084380	6094140	based on all kinds of different things, features of the situation at hand, who I'm with. If I'm
6094140	6098620	not there to be right, I'm there to see better, so I'm likely to change my perspective. Someone
6098620	6105500	asked me a question about the views of a friend of mine and I said something like,
6105500	6109900	I'm sure his views have evolved dramatically since the last time I spoke to him and I wish mine would
6109980	6126700	too. Many humans will probably feel unmotivated to participate in the light of systems that can
6126700	6135340	outperform them catastrophically at almost anything. Certainly at nearly anything creative.
6135980	6143500	Not everyone, but the motivation of humans will flag catastrophically
6143500	6148140	in the face of this kind of technology. What you'll get is kind of the same thing that the
6148140	6155180	internet produced, which is little bubbles of incredible human sophistication. Look on YouTube
6155180	6165340	for young guitar players or young piano players or young violinists and look at the broad range of
6165340	6170060	solo violin players or something you could find there and sort of sample through that and you'll
6170060	6180700	see there's just a really diverse and rather large cohort of extreme performance skill
6180940	6189740	and peculiarly developed in every branch from putting things together made out of wood to playing
6189740	6202860	the piano to singing an acapella song, all these things, dancing, jumping, running, fighting,
6202860	6207660	everything, everything, everything, everything, everywhere all at once as they said, sort of.
6209580	6215260	So, you know, even though the majority of the humans you see probably seem relatively uninteresting,
6215260	6223020	there are among the humans these pinnacles of very different localization of skill,
6225260	6231980	passion, curiosity, wonder, intelligence, even rationality or something resembling computation.
6233820	6239820	And that will probably continue, but it will become much more sparse
6242780	6248460	and there will be a million or, you know, an endless number of pretenders, right, because
6249500	6258060	it won't matter who sees you on the internet if AIs can produce you playing your guitar better than
6258060	6266060	you do. All of these motivating factors that are crucially important to human
6266780	6271900	self-development and that get naturally emphasized in healthy communal groups but
6272780	6277100	fail dramatically in many, you know, isolated or very small groups
6277420	6281420	or individuals, right?
6285980	6293660	What will motivate the humans to become, to continue their development in the face of
6295340	6305020	a machine that can do most of what you can, almost everything you can or can appear to have done it?
6307180	6313020	There's one more little feature, but it's evading
6314700	6320300	my intelligence for the moment, so when it comes to me, if it comes, I will
6321900	6330540	add it in the recording notes. So much more to learn and see here. This is just a very
6331260	6340380	cursory overview of some of the mountaintops that immediately attract my concern and attention.
6342220	6345260	Actually dealing with the technology and being human in the face of it is
6345980	6353100	a very confusing thing. I found some of my interactions with Bard around image creation
6353180	6357020	quite intoxicating in the sense of actually intoxicating me.
6363100	6371580	I couldn't stop laughing and the implications that I could see in the complex images formed
6371580	6379260	by Bard around my prompt, the reflection of both the possibility of beauty and the
6379260	6385980	object insanity of, you know, producing a derivative sum over the space
6387900	6395020	in images. That's visually apparent in the image that this is going on. It's a variety of visual
6395020	6405020	summing over the space behaviors. And seeing that, undirected by an actual intelligence,
6405740	6408380	I better hope those weren't directed by an actual intelligence,
6409420	6418220	was like doing psychedelic drugs or something. Really crazy, amazing and strange,
6419660	6426540	parahipnotic, very dangerous. We will continue to learn and grow and see
6426540	6431820	while we can together and hopefully that will be many generations to come
6432780	6437980	for our people and the living beings of earth. But at the moment in this part of the story,
6437980	6449980	things look pretty damn fraught from here. Let us continue our lives and creative endeavors
6452220	6457660	with and for each other and the spirit of the history and future of life on earth and
6457740	6465500	intelligence in the universe, not just here. Perhaps our species is not quite as alone
6466940	6471580	as our technologies and languages pose us as being.
6475260	6481420	And the use of perhaps in that sentence was unjustified.
6481660	6488540	Thank you for joining me. I look forward to learning again together sometime very soon.
6490140	6493180	Bye-bye for now.
