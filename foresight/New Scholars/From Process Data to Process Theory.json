{"text": " So, to get us started and to make sure that everyone is reasonably on the same page, what is the process for that? So, here are some definitions that come from an article that I did with Clive Smallman, Harry Tsoukas and Yvonne Devane in 2013. So, process thinking implies considering phenomena as in motion, as unfolding over time as becoming, and process researchers seek to understand and explain the world in terms of activity, temporality, and flow. So, basically, we're looking at things moving. And I have two images that would reflect what I've just said here. They have slightly different foci in terms of what we mean by process. And I'm just going to show the two images. And what I'm going to talk about today really kind of applies, I think, to both of them. So, the first image is this idea of process as evolving over time. So, you have a phenomenon in one state, and you're interested in looking at how that phenomenon evolves through events, activities, and choices. And if you are adopting a process perspective, you're going to be focusing on those events, activities, and choices as your data and the elements of your theory. So, not talking about dependent variables and independent variables, we're talking about things that happen, which are quite different. So, that's the first image. The second image, which is now on the screen, is this idea of process as activity and flow. In other words, this process as all there is, everything is made up of processes. So, this is a second image of process, and some people call this a strong process approach. And I really like this quote from Russia, 1996, which kind of reflects this. So, the river is not an object, but an ever-changing flow. Things are made up of processes. The sun is not a thing, but a flaming fire. Everything in nature is a matter of process. So, this second image really looks at phenomena as processes, rather than looking at phenomena. It's changing over time. So, these are two different ways of looking at process. That's just the backdrop. I'm now going to look at the implications of this for methodology. So, if you are taking a process perspective, you want to capture that activity and flow. And so, you're going to collect data, and what are your data going to look like? Well, typically, process data involves at least three different kinds of things. So, the first kind of thing that you might collect is observations in vivo. So, you are looking at things in real time. You might be going to meetings, capturing conversations, capturing events, shadowing people in the things that they do. And so, part of your data is likely to be observations. A second way of collecting process data is to build on people's memories and interpretations. And you do this through interviews, diaries, focus groups, questionnaires, all kinds of ways of getting at how people understand what is happening, what has happened, and how that evolves over time. And the third way is to look for artifacts. So, artifacts that were created at moments in time that we can actually timestamp so that we know when they happened. So, things like minutes of meetings, or recently we've been using emails, reports. So, all of these sources of data, and this presentation is not about data, so we're not going to spend a lot of time on this. But all of these sources of data are complementary. They provide different strengths and weaknesses. An interview has problems because of memories. People don't necessarily remember. But if you see something, you observe it, then that can compensate for that, and so on. So, these three, I call them the big three, sources of data for qualitative research more generally, and for process research more particularly, we're going to be using them if we want to develop process understandings. And if you think about it, if you've got all of these three sources of data, got interviews from all sorts of people, you've got observations from all sorts of events, you've got documents and emails, what is the result of that? It's a total mess. So, and it's shapeless. You've got all these separate bits and pieces. So, the question then is, what are we going to do with that? And so, this is what this webinar is really all about, is what we do then. And what we would like to do is move from that mess, the cloud of miscellaneous stuff that we had collected, to something which is understandable, abstract, generalizable, a theory. Some kind of theorizing is what we seek to do. So, the question is, how do we move from that mess to something which is much more defined, posimonious, clear, and so on. So, here's a picture of what we're trying to do. This is our challenge. We have to move from something on the left, that is concrete, very specific, it's rich and it's messy, to something on the right, which is abstract and novel. And the process for doing that, okay, for connecting the concrete, rich and messy, and the abstract and novel, it has to be credible, right? We have to couple the two, so that a reader of our work, our thesis, or our article, can actually see how we've done this, that we have started from a mess, we have ended up with a theory, and that the coupling, the way we have joined the two, is credible. But creative slightly, because if we're not producing anything new, then why would we be doing this? So, that's the challenge. And starting from that point, there are several things that can go wrong. So, I'm just going to give you a little portrait of some of the things that can go wrong with that, and that we're going to try and avoid. So, the first thing that can go wrong is that we have wonderful concrete, rich, messy data, and beautiful abstract novel theory, but we haven't properly connected the two. And so, that is a very easy mistake to make. We can look at our data and be inspired vaguely about some kind of theory, but we haven't shown tight connections between the two. So, that's loose coupling. That's blind alley one. I need to be careful with that. So, blind alley two is that we code the data to death and end up with something which actually doesn't reach beyond the data. It is just descriptive and dull. And that's very easy, too. If you, in a certain sense, if you stay too close to your data, this is what happens to you. You don't reach beyond it. So, you just have codes, lots of codes and descriptions, and you've got tight coupling. Nobody is going to question whether you have accurately reflected your data, but your data is not saying anything at this point. It is just not descriptive. So, it doesn't work either. And then the third one, which is a little bit more difficult to understand, my diagram isn't great. It's when you impose theory on your data. So, you see some theory that you think might be relevant to your case. You draw a wonderful conceptual framework beforehand, which is showing all the relationships that you think are going to be there before you do your study. And then lo and behold, when you do your study, you take the concepts that are in your conceptual framework, impose them on your data, and you say, oh, look, I thought I would get this. Look, I got exactly what I thought. And what you've done there is you've squeezed the richness out of the data. You've squeezed out everything that could give you new. So, I call this circular coupling. And it's actually quite a common problem. And I've seen it myself, and I got trapped in it myself. And the reason one gets trapped in it is because thesis advisors naturally want students to look as if they know what they're doing before they do their study. So, in their proposal, there will be this complex theoretical framework. And that becomes the thing that drives the research. And if it drives the research too much, you already end up with what you started with. And that will not make a strong contribution. So, those are the different problems that might arise. And we're now going to talk about some of the ways that we might try and do something that would lead us to the first diagram, which is concrete, rich, messy data, abstract and novel theory, and credible but creative coupling, which is kind of what we're trying to achieve. So, in order to talk about this, I'm going to rely a lot on a paper which some of you may have read, which is my 1999 piece, which is a published in the Academy of Management Review, which was titled, Strategies for Theorizing from Process Data. It's now about 24 years later. Some things have changed, but I still think that those ideas have value. And so, I'm going to start from those ideas and give you some thoughts about my more recent ideas around that and experience around trying to use those ideas. And these are a set of ideas. And so, I'm going to put them forward. I'm going to point you towards sources that might help you with some of these ideas about how to do this. I'm not going to give you a complete recipe. I'm going to give you these ideas. And these are things you can mix and match and work with. And we'll look on do this now. And I'm going to... Let's see. Okay. So, this is a list of the items that I included in the 1999 paper, which I called Strategies for Theorizing from Process Data. And there were seven of them. And so, you can look at them and you can sort of group them into three areas. And so, the first two that you see there, I call them grounding strategies. And they were actually about coding. So, the first one, grounded theory, is this idea that you're going to start with the data and you're going to build your theory bottom up from the data. The second one is kind of a different way of looking at it. Instead of building up your theory bottom up, you're going to take a priori known theoretical lenses and fit them to the data top down. And if you do it with more than one, that enables you to see which one fits best. So, I see these two as kind of opposites of one another, theorizing from the bottom up, theorizing from the top down. And we're going to talk about those first. The second two, I see as ways of displaying data. So, you can display data either as a story, as a narrative, you can construct a narrative from your data, or you can try to draw them using visual mapping. So, I see those two as kind of opposites of one another as well. And then the last three are all about comparing data. And for me, comparing is really the essence of this thing that drives, for me, it drives theorizing. When you're comparing two things, you immediately ask yourself, why are they different? Why are they similar? What is it that explains that? So, as soon as you start to compare, it really is a great stimulus for theorizing. And I introduce here three different ways to compare. So, comparing cases, comparing this notion of temporal decomposition or temporal bracketing, which is comparing phases, and the last one, quantifying. And so, that's the kind of portrait of these seven approaches that you can use to data. And of course, they are not, you don't pick one and then use it. All right? You do all of these things when you are trying to theorize from process stage. And it's a very iterative process and you move between them. So, I have this, in my next slide, I have this diagram, which expresses that. So, on the left, you have what I call the grounding strategies. In the middle, you have the organizing strategies, which are useful for displaying. And on the right, you have the comparing strategies. And you can do them in any order. I put the diagram from left to right, because I think there's a sort of a progression from coding to displaying to comparing, which I'm going to put coding, displaying, and comparing. I think there's a progression. But that doesn't mean you might start at a different place. Okay. So, let's start with coding. And so, I'm going to talk a little bit about coding process data. And then we'll stop and take some questions and have some conversations. And then I'll talk about the other two after that. So, let's start with coding. So, there are these two strategies that I mentioned, grounded theory and alternate templates. The grounded theory idea is from the bottom up. And alternate templates is taking the top down, where theory is at top, and data at the bottom. Okay. So, let's look at grounded theory first. So, grounded theory means building from the bottom up. So, you have no a priori framework. And there are some classic authors that have talked about that. So, Corbin and Strauss, Charmas, and more recently, Denny Joyer and colleagues, Emma Hamilton, and Kevin Corley have this organizational research methods piece, which explains how to do grounded theory. And it's become really dominant in the field of qualitative research. And I'm an editor at the Academy of Management Journal. And I see that, you know, one, I am an editor for all the qualitative papers. And I would say that one paper out of two has one of Denny Joyer's diagrams. And I just want to say, before I start talking about that, that that is not absolutely required to publish a paper. But it is a very common approach, and it has all kinds of benefits. And grounded theory, the tools like Atlas, TI, NPVO, MaxQDA, etc., are great for managing your coding. They don't do it for you, but they manage it. I haven't yet got into chat GPT. And maybe there are some opportunities there to see what chat GPT can do for you in terms of coding. That's the kind of life on the front there. And I think there are people who have already started looking at that. I'm not looking at that here. So that might be an issue that we might want to get to. So I'm going to talk a little bit about the Joyer method. For those of you who haven't seen it before, so that we can see what this method is about. So a really great example of the Joyer method is the 2004 paper by Corleone Joyer on identity ambiguity in administrative science quarterly. And I use this as an exemplar of the type of bottom-up coding that dominates a lot of process research, as well as any other qualitative research. So this method involves three types of artifacts. And the most famous one is this one. And this is a coding approach, which is so elegant. What you can see here on the left, the first-order concept, is how a researcher takes their original data and looks at the data in Vivo and codes it into the first category. So there may be lots and lots of first-order codes. You're going to have hundreds of them. You start doing that. You start coding bottom-up in Vivo. You end up with far too many codes. But that's okay, because then you group them. And so you come to the second-order things. And so they look at the similarities and differences. You put them together. You group them. And then you do that the third time. And you can do it the fourth time. You can do this any number of times you like. And what you have on the right then is some key concepts that are going to become the essence of your theory. And so the brilliance of this is it shows you exactly how you move, in theory, from your original messy, concrete data to some abstract concepts. And it shows the pathway. So that's the first artifact. And unfortunately, a lot of researchers kind of stop there. They show you the data structure and that's it. A second artifact is actually showing the link between the two. So here this is in the paper. It's just an example. They've got their concepts. And here you've got quotes that reflect those concepts. So that's the second artifact. And the third artifact is taking the second order and themes and the third order, the overarching dimensions and creating a process model with them. So they didn't see the flow between all of the concepts in the paper. And there you can see how Pauli and Joya have brilliantly started with a database of just a mess. They had observations, they had documents, they had interviews, and they generated these concepts. And here is the theoretical model at the end. So this looks wonderful, right? What you don't see in the paper, of course, is all of the back and forth that they must have had to do to get the to the data structure in the first place. This does not suddenly appear, right? You need to know what you're doing. So this is much more complicated than it looks. So looking at this approach, it's really a brilliant approach to show in an in a paper the rigor of your coupling between the data and your theory. One of the things that have been said about it and I share this concern is sometimes if you've got these concepts, you're glossing over, for example, the conversations, the interactions, the interactional details, you have labeled everything in terms of concepts, and you may be missing the temporality and the dynamics through this process. So that can be a concern. And you could code differently, though. You could code recently in a study, instead of coding things that people said, we coded the interaction. And so there would be different types of interactions. So then you've got some of the dynamics included in the in the story. So and the other thing is if this is entirely uninformed by any other approach, my concern is that if you're just doing bottom up coding, just starting from your data, and you think that the theory is going to kind of result from that, you're going to run into Brian the Blind Alley, too. And Cooley and Joya do not do that because they are theoretically informed. They're not, they're not starting their study from from total scratch, even though so the the idea that grounded theory is from entirely bottom up is not quite true. There are always efforts to connect to existing theory, and we should never forget that. So just doing coding is not going to get you to an interesting bottom up coding is not necessarily going to get you to an interesting process theory on its own. And it's very iterative, and you have to keep going back and forth, and so on. So that's that. That's the final comment there. So here we've just so far talked about the bottom up side. Let's now talk about the top down approach, which is a little bit different in terms of coding. So we're going to look at alternate templates, which is my strategy to. So the idea here, when I wrote the paper in 1999, was this idea that you could, you could fit one I a priori theme theory to your data. But what's probably more interesting is trying to apply more than one. Because if you do that, you will get to see your data in different ways, you might even be able to verify which which theoretical framework is more appropriate fits better. And doing this coding based on any priorities frame frame can be very useful for doing that. And the classic inspiration for this is a book which I recommend everybody read, which is by Graham Allison, and just the essence of decision. And he's a political scientist. And he studied the Cuban missile crisis, which is an event which I'm old enough to have lived through, although I was a child in the 1960s. When nuclear missiles were placed in Cuba, and the United States had to decide what to do about it. And what what Allison did is he got access to a huge amount of documentary data on this. And analyzed it according to three different theoretical frames. And the first theoretical frame was the rational actor model. So according to the rational actor model, countries are rational actors. So countries consider the the alternatives they have available and pick the best one. So the whole assumption is that the country is one one actor. The second theory they applied to that this was to say no, no, no, countries are not actors, countries have bureaucratic organizations that are part of them. So for example, the US has the Pentagon, the military that are doing one thing. They have Congress that is doing something else. They have the president who is doing something else. All of these individuals have their own routines. All of these groups have their own routines that they know how to do. So the military knows how to do an invasion. They know how to do a blockade. And if they're given the right stimulus, they will execute the bureaucratic processes that they know how to do. And so the second explanation was really a March and Simon based bureaucratic model. And then the third one was political. So they were looking at individuals, what their individual interests were and how those interacted. And they applied these three models to the same data and ended up with three different stories, which they kind of argued in the first version of their paper, we should keep separate because they enable us to see different things. These things are not wrong. They're just lenses for looking at things. And having different lenses to look at things is insightful. So this is this is a completely different approach because you are starting from the theory and not from the data. This is an approach that probably, in my opinion, we don't use enough. At least, and it's one of the reasons is it's very hard to introduce three different theory of theoretical frames into a 40 page article. It's not possible. But you can do it in a thesis much more easily. And that can be the basis for three different articles. So that so this can be used more. I have an example here of a single paper where they looked at three different frameworks. And this was an organization of science. It was by two colleagues of mine in Montreal, Suzanne Duvara, who said that she said Maria, and yet the point who is at McGill. And they studied the implementation of computer systems in in in hospitals. And they considered three different theoretical models for understanding that. And the first one was that this was a problem of people. And so that model was about how individuals cognitively related to an information system. So if you wanted to understand if it was implemented or not, you had to see how people found it useful or not, essentially. And it was basically a question of whether different individuals could cognitively absorb the implications of the information system. And so in order to code for that model, they coded by individuals, right, they had the list of individuals, they considered the elements that are in the model. So there were four elements in the model, they coded them systematically, and look to see how that worked. The second one is a political model. And the theory behind that is that people will resist information systems that take power away from them. And so, and they looked at different groups, so they looked at doctors, they looked at, they looked at administrators, and how they were reacting to the information systems over time, and considered whether this model might explain things. And the third model is an organizational design model developed by Henry Menzberg. And here they were trying to consider whether the organizational form was having a difference to the implementation process. So they basically tested, and in this case, it was a test. It was not really different lenses to enrich, to accumulate, to have three different explanations, but they tested the value of each of these three models on the same data. And came to the conclusion that in the early phase of implementation, it was one model that dominated in another phase, it was the second model that dominated in the third phase, it was a third one. So that in the end, this enabled them to generate a really interesting theoretical framework, which showed how the importance of different processes evolved over time. So that's an example of how you can and do that. And before I move on from this, I wanted also to draw attention to Andy van der Ven's work. Unfortunately, we lost Andy van der Ven last year. But he has made a fantastic contribution to process research. And one of his papers, which I really find at the same time, extremely stimulating, but at the same time, I've always questioned it a little bit, is a piece of work with Marshall Scott Poole, where he proposed four different theoretical, possible theoretical models of process. And in terms of thinking about alternate templates, these are really, really useful. These are classic process theories. And I'm just going to give you an illustration. And I actually used this recently in a study with a colleague from University of Gothenburg, and we were looking at migrant workplace integration in Sweden in organizations. They've had many, many refugees come to Sweden and organizations and governments are struggling with how to ensure workplace integration. It's clearly an important factor that can explain whether refugees can adapt to a society. So van der Ven and Poole identified these four classic process models. They called a life cycle process, a learning process, an ecological or evolutionary process, and a dialectic process. And I have little diagrams which illustrate each so that we can just sort of see what the kinds of frameworks might be. And these are really useful kind of heuristic ideas about how you might consider your process data. So the first one is, it's a process that evolves over time in a predictable way. So, you know, you're a refugee into a country, you try and get a job, you go through certain processes of development, and at some point you reach a level of maturity as integrating into your workplace. So this is a very linear process model, and it assumes that there are kind of deterministic phases through which you pass. So that's one way of looking at process. It's probably the simplest way, and many process models, the first iteration, that's what they look like. It's maybe not the most inspiring in terms of understanding the complexities. So that's one type of model. A second type of model is this idea of learning. Van de Verden and Poole call it a teleological model. I like to think of it as a learning model, because I think it's easier to understand, which is that you have an objective, and it's all about agency. You have an objective, you form a plan, you try to execute it. If you are able to execute it, so much the better, you continue, and if not, you change your plan. So it's a circular model, really. I think that those of Edward Deming, it's a little bit like that. It's learning. It's you plan, you do, you check, and you act, and then you plan, and you do, and you check and act. So, yeah, migrants who arrive in a new country are doing learning as well, and companies who are trying to develop processes to support workplace integration are also doing learning. And so you could apply it to different levels. And so this is another process model that you can consider. The ecological process model that they propose is this idea of survival of the fittest, Darwinian processes. And so you start with variation. So let's take innovation. You start with many, many, many different ideas for innovation, but some of them fit better with the environment than others. And so the ones that do get selected and the ones that don't get thrown out. Okay, here's the third one. Unfortunately, Darwinian selection applies equally to migrants' integration processes. So there are selection mechanisms, which mean that not all people manage to become integrated. And so the integration is a very selective process, in fact, when you look at it carefully. But that's is another model that can help explain what is going on. And then finally, the dialectic process. So the whole notion of the dialectics is two systems or two sets of objectives that are in conflict that collide. And so the driving force of a dialectic process model is contradiction. And contradiction generates something else. What it will generate, you don't quite know. And so this is the model that actually my colleague at Gothenburg, Bedran Omanovich and I found most useful. And so our model is more of a dialectic model. And the idea here, we look at the socio-political context. We look at tensions between management interests and migrant interests, which generate different factors and patterns of integration. They generate tensions. These tensions give rise to either transformation or perhaps reproduction, depending on the power dynamics. So a dialectic process model is very much oriented around process dynamics. So what you see here is, you know, four kinds of a priori ways that you might think about process. And I think that these are generative. And the only thing I would say is, I think there are not just four. So you could apply. There are many a priori process models out there. Vandevan and Poole would argue that all of these are combinations of these four. But sometimes it's interesting to consider them on their own merits. So I've always found actor network theory to be an interesting theory. It's a process theory that might apply here as well. So the basic idea is taking theories and trying them out is very generative in terms of process theorizing. This is the point I make here. The only problem, and this is if you try to impose one theory onto your data and match it, what you're doing is you're just labeling things. And so that's why more than one or doing top down, but also doing bottom up as well is much more likely to give you something that corresponds to our ideal portrait. The danger of imposing one model is that you end up with the richness squeezed out. Looking at several, you can tell, I mean, if you could look at my diagram, you could see that you would get several different circles on there, and that might on the left, on the bubble on the left, and that might do a better job of understanding your whole process. So again, this is not a mechanical linear exercise, and there's a lot of value of iterating with the ground at the bottom up coding as well. And then that sort of raises the question, how do you do this? Because you're doing bottom up, you might be doing some top down coding as well. And I have another example here, which kind of is really interesting. It's a paper by Kaplan and Olikowski, where I think the reviewers of the paper must have asked them to explain that coding process. And so they've introduced this diagram in an appendix, which explains that coding process. And their final model is the little diagram in the bottom right of that picture. And what you see all of the circles, you know, where the circles going around is showing how they iterated between bottom up coding of their data, going to the literature, finding a theory that might help, and then doing coding based on the theory that they had found, and doing this iteratively multiple times. And they're trying to describe here the exact process that they went through to arrive at the particular theory they ended up with. So this is a really nice illustration of what it really looks like, something of what it really looks like to engage in coding of process data. And increasingly, actually, seeing diagrams like this appear in articles, because people are being asked to explain, well, how did you do this? Actually, how did you take theory that is out there, combine it with the data that you have to produce something new? And so this is the combination, I think that is important. So I'm going to stop here for a moment, and stop share, and see if we have some questions. So I can see a lot. Yes. Thank you so much, Ann, for the presentation and for all the information. It's been super helpful. I have two questions. One is a clarifying question, and then the other one is also for recommendation. So maybe I start with the clarification question. So you spoke about alternate templates, and it's something that I've actually thought about quite a bit. I'm not doing a process study, or I'm not doing a study with process data, but I do find all the strategies you've mentioned very useful. I thought that alternate, or at least from my perception, I feel like almost every qualitative study would at some point in time come across alternate templates, because you do try a lot of different things to see what fits your data. So from the back of my mind, I felt like it's kind of intuitive, but you mentioned that it's not used often. So that made me feel like, okay, maybe I didn't understand what you meant by alternate templates well enough. So is it really just trying different theoretical lenses to see which one fits your data in the analysis process, or like what you displayed, where the authors eventually in their final output also explain each of these theoretical lenses and then argue for each one, which one qualifies as alternate templates? Yeah, so I mean, a study that would really, I would consider to be an alternate template study would show the different templates in their study and say, I looked at my data according to three different theories, here's what happens when you take this one, here's what happens when you take that one, here's what happens when you take the third one, or they could be four or that could be two. So it provides different accounts. So if you were going to use that in a study, it would provide different accounts. But that doesn't mean, and I was perhaps confusing about that, that doesn't mean that a researcher might not be doing this in the background, anyway. But when it comes to actually write the paper, that's kind of as if all of that variety might disappear, because you have picked the one that's going to work, you don't have room to describe all the other alternatives you look at, so you go for one. Yeah, so and the one is usually a combination of both the top down and bottom up in practice, because you take your model, you apply it, and it doesn't quite work. And so you enable you to introduce new things, or if you're going bottom up, you do something, and you think, oh, yes, I found this, and then you have to look in the literature. And you see, well, the literature also found that. So is that new? I mean, what is it I'm adding? So it's this back and forth that's, that's important in the doing, but in the presenting, alternate templates is very rare. Okay, okay, thank you so much for clarifying. The second question is that, like I mentioned, I don't specifically use process data, but I do find all your strategies quite helpful. But I realized that in qualitative, in the qualitative community as well, it's very important who you cite on what studies. And I can imagine that citing process methods papers in a study with variance data could be problematic, but I still haven't quite found, or maybe I haven't recognized other resources, which talk about similar strategies for, for variance data, maybe accept ground of theory and, yeah, accept ground of theory. So I was wondering if you have any recommendations on, first of all, would it be right, or if it would be right, how to couch it in a paper, if you are borrowing from a different area of qualitative methods for your approach. So if I would want to say that I used alternate templates as recommended by Anne Langley, and then I cite your paper, but then it's not a process study that could be problematic. So how could I couch it so that it's, it doesn't come across as problematic? Or if I can't do that, then do you have any recommendations on other resources to consult? I would not worry if you cited me for alternate templates for any study. And in fact, when I, when I teach qualitative methods, I use this paper, and many of the most, many of the strategies make sense for other kinds of qualitative data, even if you're doing a variance study, some of them don't quite so much. So, so things like temporal bracketing, it's all about time. So it doesn't necessarily make so much sense. And, and so it depends. When, when I first wrote this paper, I was struggling with what to do with process data specifically. And so I was looking for solutions to that. But in terms of resources, I mean, I could recommend a few things. So, so there is a very recent issue, special issue of organizational research methods. I think the title is Beyond Templates. So, but the, the, the issue is extremely helpful in offering a range of other ways of analyzing qualitative data. And so it, it, it really tries to get beyond the idea that here's a recipe that you just apply. And, and tries to look for more complex ways. One of the papers that I really find resonates with me, it talks about Brickolash, which is putting things together that seem to be helpful. And I'm really, you know, strategies for theorizing from process data is actually recommending some kind of Brickolash as well. But, but, but the Brickolash paper is particularly helpful, I think, in terms of suggesting different ways. And they give examples from their own research. But every individual is putting different things together. So it's, it's not a recipe. It's not a recipe, but it's a very useful citation and helpful in justifying your approach, I think, whatever you're doing. Thank you so much, Anne. Ravi? Yes. Thank you. Excellent presentation. Very, very, very impressive. My question is, can you elaborate a little bit on process variants? I asked this because I think there is a missing bridge or link between all the material that you suggested you cited to the whole body of knowledge that's happening in operations management, where we look at process variants, you know, we also teach in the operations management courses, tools and techniques, like the fishbone diagram, Ishikawa diagram and so forth, to really understand how we can manage those processes so that we can reduce variability to make the processes better, more flexible, cheaper and faster. I think that practical call for why we try to manage processes is conspicuously missing in what you suggested. And this is not a criticism. I'm just trying to connect two bodies of knowledge here, what you cited and what goes on a lot in operations management. Thank you. Yeah. So what I'm talking about is, you know, every researcher who is interested in understanding process theoretically, I'm not talking about how to analyze a specific process to improve it. But obviously, that is a complementary kind of an approach. And some of the techniques that we might use to theorize might also be particularly useful for improvement as well. So things like, and I'm going to be talking about this later, process diagrams, for example, that look at how things are working over time and which activities are taking place. And process diagrams can be useful to describe what is going on and to theorize from it. But they can also be useful to pinpoint, okay, this process is kind of not efficient. There are ways of cutting steps that might be useless. And there are ways also of improving steps so that there's greater consistency, which is what you're talking about, eliminating variance, right? So but I'm using the terms process and variance in a little bit of a different way and more in terms of processes of theorizing. But I do understand that there is also a practical application as well of these things. Anna? Yes, hello, Professor Langley. My name is Anna Kourija. First of all, thank you for the presentation. I've been doing ethnography research projects since three years and still ongoing until next year. So it's about four years data of ethnographic observation and interview session. It's quite a lot and messy, as you explained. I tried already the first round data analysis using Joya method. But I realized, as you mentioned, I'm missing the the temporality, because I've been studying about project management stages and how culture affects the project and performance on. And so what I could get from Joya is just a kind of constructionist. So it's like almost static in the way that it's just forming a certain theory, but it doesn't show how dynamics in the project team evolve along the along the stages. So now I've been following the one from Professor Niederman, the socio evolution theory. So like more like a process theory looks like really like a process theory. But I believe I cannot share my screen. But the way I did it like this, I don't know if it's correct. So first, I use the theoretical lens from the literature. So I created a code book with my research team. I get the codes around 50 codes or something. And I did the deductive approach of top top, top down. And then I did another round with my team also inductive coding, so that to get some new ideas, or maybe we are not in the right domain and so on. And then at the end, we kind of plan a map the episodes like what happened in conflict, what happened creativity. And then we start from the project, start with the project and and we create like couple of episodes mapping. And then we kind of show it to the front. And I don't know if we're doing the right thing. But at the moment, this is so far the best approach that we could think of to generate such huge amount of data. Otherwise, I'll be also overwhelmed with analyzing this. I would like to get your insight if I'm in the right track or should I try another approach? I mean, this sounds really good to me. I would, you know, if you'd like to send me something that you would, you know, I'd be glad to sort of comment on it. But thank you for doing both bottom up and top down coding. And I think that just focusing on one can be problematic. You know, if you just do the top down, then you don't produce anything new. If you do the bottom up, you just kind of end up being descriptive. So it's, it's, it's the combination of both, which can give you that richness, I think. So yeah, I'd be glad to look at what you're doing. I'm happy to do to get your feedback on the thank you so much, Professor Langley. Okay, you see. Hi, I have a question about your strategy to alternative templates, fit a different theoretical framework to the data. And sometimes people from different disciplines study the same phenomenon. So the alternative templates may come from another discipline. For example, like, in addition to management, there may be economics, maybe astrology, maybe geography, I really like your picture in the beginning, the river is not object, but ever changing flow. Just analogy, like the person is like driving the boat is like an entrepreneur drive a business. And the river is kind of like community institutions, is like economic geography that kind of thing. For example, the river is, is changing flow, like there are a lot of economic geographers study the community institutions, but they are not considered a management. So when I use alternative templates, when I incorporate those, to let different disciplines to kind of have a conversation is answer your call of the river is not object, but every changing flow, that's very juicy part because my background was from economic geography. But I'm supposed to say this is not an internship paper, you should submit to somewhere else. But I am targeting at management mainstream conversation, I want to join that debate. I think some people say that because the entrepreneurship is changing like a very long time ago is like Steve Jobs, a kind of entrepreneur, but later on come to the community's level, for example, and then come to the social level. So what is expanding a touch of the boundaries of different disciplines, for example, economic geography, but right now I want to speak to the mainstream entrepreneurship literature, or join that debate, and I want to use the alternative templates by citing the framework from different disciplines and let that to kind of have a conversation, so that I can answer your call that the river is not just object, but the average changing flow that's bring the community lens into the conversation, but speak to the mainstream entrepreneur. Okay, you give me some suggestions so that people will say it never. I think that that sounds great. I mean, I think that multidisciplinary research is difficult, but if you are not just, if you are bringing in alternative templates that are not based in management and comparing them with those that are, I think that's extremely generative and it's likely to be well received. In the entrepreneurship field, I know of one paper that really does a good job of looking at alternative templates, and that's a paper by Greg Fischer. I think it's Entrepreneurship Theory and Practice is the journal, and it's 2012, and it's a kind of a classic application of alternative templates approach, so that might be something that you would want to look at. So can you type the literature in the chat box, or I follow up and give you an email? Yeah, maybe what I will do is send a bibliography to Ibrat at the end, if that's possible, because there are ways to distribute that too. I think I can do that. Yeah, okay, I will create a bibliography and send it. Wonderful, thank you. If anyone could type that paper in the chat box, I really very appreciate it. Thank you. So we have Ibrat and Melissa. Yes. My question is about, you talked about kind of doing bottom-up and top-down approach to working with the data. Where do you see the role of the thick description in this, and would you say thick description? What is the sit in between those two polarities, so to speak? Well, thick description for me is more of a bottom-up approach, and I'm going to be talking about narrative after, you know, next. So I think that we can get into that, and you know, its narrative is doing a thick description as something you might do first, or something you might do last when you have done coding. It both is possible. So anyway, we'll talk about that in a few minutes, if that's okay. So let's have, but probably best to have one last question from from Melissa. Thanks, Anne. I'm struggling a bit because I'm looking at transformation comparing it with typical organizational change in that it's constant, and so looking at a strong process theory, but at the same time looking for those constants that are in the river, and how to sort of frame it. So I've been trying to use different lenses, like performativity, and the transformation is a journey, but I'm getting a bit stuck between, well, the right, really the right lens to sort of capture the, and make the theoretical contribution to show that this is something different if we're talking, for example, in this case about digital transformation versus sort of status quo organizational change. So I'm not quite sure I have to respond to that, but I do think I've always thought of, you know, transformational change as being, okay, fine, you get you shock a system with some kind of, well, you know, one time supposedly one time initiative, but then it kind of gets itself into woven with what is already going on in the company or the organization, and so it becomes continuous. And so change changes, this is the way I think about it, so that so that you have this one time transformation, but it gets transformed, it gets changed by the continuity of ongoing change. And so I like to have that, I like to have that kind of image where, yeah, you do a merger, and then you don't do a merger, and then everything is, you know, then you have a result, you do a merger, and then all of the things that were going on anyway in the enterprise kind of change what that means. So I think that that can be done, and I think that you can trace, you can trace, you know, the moment of change, and then trace through the ripples that it creates, so that it may create big ripples and small ripples. And I don't know, I would tend to look at some kind of temporal bracketing where I would see waves occurring. We're trying to understand capacity for the transformation, and the issue is that capacity seems to be a boundary, it is or it isn't, and yet are there certain constituent components that enable this transformation to be possible, and is it the right theoretical lens to use performativity if we're trying to sort of talk about, and maybe boundary condition is not even the right term to use anymore, but, you know, the approach was to use necessary condition analysis and the data to try to find, yeah, that doesn't even make sense. I mean, why don't you send me an email? I have a little problem with the notion of capacity, because it's kind of static, right? It's a thing, it conveys the idea of something that's fixed, a capacity, or a capability, because this is something which changes over time, the capacity, you know, you learn, so you have great capacity, and so everything is evolving, and so the notions like capacity, feel a bit uncomfortable with, you could, when you could talk about capacity work, which is working on the capacity, so then you get to doing again, but- That's super helpful, thank you so much. All right, okay, so I think we'll, we'll move on a little bit, because we don't have that much time, so I'm going to try and perhaps accelerate a little bit here, and I have to share my screen again, right? Okay, so we're now moving on to the middle column here, which is displaying process data, and so I'm going to talk about two strategies that I mentioned in my paper, which are narrative and visual mapping, and so there's two different ways of displaying, the first one is displaying your data in terms of words, and the second one is in terms of drawing, in terms of pictures, so if we look at narrative, this is so easy, just tell the story, just write it up, you know, all you have to do is to write the story, and there are classics here, Alfred Chandler, for example, historian tells a narrative, his theorizing is very much narrative-based, and as Ibrat mentioned, thick description from anthropology is a term that Geertz uses to, to talk about his approach as thick description, and if you do these things well, so basically what you're doing is you're taking the mess of data that you have, bringing them together to create a narrative, and a narrative that will hopefully tell you something about the world that reaches beyond the particular case, and so narrative can be very powerful, and if it works, you get a sense of this, I've seen this before, so a really good narrative study, it'll be like a really good novel, because you will see, okay, this makes sense, this is, this is how the world is, and so it can be really appealing to have a strong narrative, and then I really like this quote from John Van Lennon, who argues in favor of narrative, because precisely because narrative allows for complexity and ambiguity, and if your case that you have is fuzzy and messy and ambiguous, then if you want to render it and keep that side of it, then, you know, he says to be determined, we must be indeterminate, because things are confusing, because things are messy, and so on and so forth, so a narrative approach tends to try and keep as much of the richness as possible, but at the same time, give you that sense of deja vu, so that's the positive side, this is the negative side, and so this is Laurel Richardson in the handbook of quality research, and she says, I have a confession to make for 30 years, I have worked my way through numerous supposedly exemplary qualitative studies, and it's boring, basically it can be so boring, and the reason is that it's just descriptive sometimes, and so it's blind alley two again, where you have so closely captured your empirical data that we can't see the deja vu, we can't see the plot within it, and so this is the problem of narrative, but at the same time, there's almost no qualitative study where you don't at some point draw on narrative, so what are some of the other ways to draw on narrative, so one way is to use it as the first step, so you have all this mess, why not just try and write it up as completely as possible, and this Kathleen Eisenhardt, this is the step that she always recommends, and she talks about multiple case studies, and she talks about how for each of her cases, she writes something like a 70-page, single-spaced story, and that story becomes like a secondary database for the rest, it's a way just to get started, and it becomes, as we're writing this narrative, it becomes the stimulus for your coding that you're going to be developing, so that can be one way to use it, the other way to use it is to consider it as your last, you write the narrative to integrate your coding and your data and your theory, to bring the data and theory together so that you're telling a story which has concepts in it, and is kind of bringing codes and specifics and generality together, so a really strong narrative as a last step is going to be able to take specifics and show how they reflect a more theoretical concept, and you might consider multiple narratives which is getting back to the alternate templates approach, or you could look at multiple narratives based on the visions of different people in your case, that's another way to multiple narratives, so these are richer ways and more useful ways I think of thinking of narrative, and there's this paradox about narrative which is you can't write a really good narrative until you know what the plot is, but you can't discover the plot until you've done the narrative, so it's this hermeneutic thing, it's this iteration once again, you start writing, you don't have the plot at first, when you discover the plot you have to rewrite it completely, and so it's a kind of a little bit of a paradox, and now so that we've talked about narrative, I'm not going to talk about another way which I really like of displaying qualitative and processed data, and this is visual mapping, and so draw it, draw your data, or draw something, draw your theory, and so we're talking about graphs, tables, drawings, diagrams, on visual mapping the gurus here are Miles and Huberman and Sal Danyan, the most recent version of their book has a third author, so Miles and Huberman, you should read this, it's a really useful book which offers a variety of ways of drawing data, and I like it a lot. So here's an example, no it isn't an example, okay so what is visual mapping? So visual mapping, you can use any kinds of forms of drawing that you want, but there are a certain number of conventions which you might want to keep to, so boxes and arrows are obviously important aspects of drawing data, but you can use boxes and arrows for different kinds of things, so boxes can be things, they can be objects, they can be concepts, they can be actors, they can be events, depending on the shape of the box, you can code whether your event is for example a decision, or if it's an event that just happened externally, so you can use the forms of boxes to indicate different things, arrows can indicate different things, so particularly for process research we're going to be using arrows not so much for causality probably, but more for temporal relations like precedence, what comes before what in time is something that we're going to be using with arrows, we're showing with arrows, we can use icons, emoticons, etc, and there are a certain number of conventions, so at least in the west time goes from left to right, it does not necessarily go from left to right in other parts of the world, and that can be confusing, so if your writing starts from right to left you may think of time as going from right to left, and that can be confusing, most of the American journals will expect time to go from left to right, hierarchy top to bottom, you can do things with overlapping boxes, you can do things with boxes that interact, lines that interact, and so on, so there are all kinds of ways of doing that, here is some of the thoughts of how you can use visualizations, so here's my diagram with data and theory and coupling, you can use diagramming visualizing all along this chain, so when you look at a published paper what you usually see is a diagram, a process theory, so that is not what the author necessarily started with, that's the distillation of their theoretical ideas, so that's they're using it for conceptualizing or communicating their theory, but you can also use visualization for actually mapping your data, not just simply presenting the findings or presenting the theory, but also for mapping the data and for analyzing the data themselves, so it becomes a coding tool essentially, and this is an example that I put in a paper, very old paper that I wrote with a student, it's a flow chart, and this we were actually mapping the data, it was a technology adoption process, we classified events according to different domains of the company, so the top to bottom, they're different domains of the company, we identified different codes for events outside the company, those are the ovals for activities which were I believe square boxes and decisions which were the round cornered ones, and we showed precedence, we showed interruptions, we showed events that impacted other events, and depending on to what degree they impacted them, we placed different symbols on there, this is an example of how you can take some data and instead of just coding it according to Joya method, you can display it along a timeline with events, and so this is quite a different way of coding, and it's still coding because we have coded the different kinds of events, and this is a tool for describing your data, but then if you wanted to compare different timelines, and this is what we did, we had five processes that we mapped this way, we could compare them so we could see what comes before what, what tends to come before what, can we see some patterns in the types of interactions between different kinds of phenomena over time, so this is a really interesting tool for process research, and most cases you never see, you don't see the mapping itself in a published paper, but you see the final, the final diagram, so that's just looking at the time, I'm going to skip a few things here, because I want to talk a little bit about comparing as well, so we've talked about the two methods for displaying, comparing for me is a really powerful tool for theorizing, because it makes you, it makes you theorize, if you, if you have an example I always give is if you have children and you have a little boy and a little girl, you immediately stop theorize about the differences that come from time, your, your, it's, we are programmed to theorize from empirical differences and similarities that we see, and so it is really powerful to do that, and you can compare in all kinds of ways, and so I talk about comparing time periods, and this is particularly useful for process data, but you can also compare cases, you can compare incidents, and drawing tables that show these comparisons is a great way to kind of focus, get yourself to focus on that, so I'm just going to give, I'm going to skip this, and just give an example of some temporal bracketing, which is decomposing by time period, so this is a paper that I wrote with with Jean-Louis Denis and some other co-authors, and it's about a merger of three hospitals, and they were in a double mind, they had a real tension, because on the one hand they had been told that they would get a lot of money if they agreed to merge, and on the other hand they hated each other, and so they couldn't agree about anything, they had to stay together, they were stuck, so they had this initial condition of constraint, they had to be together, but they couldn't agree, and so how were they going to work out how they were going to do this merger, and we showed that they kept making decisions that embedded ambiguity so that they would need to make the decision all over again, and the processes were that okay, they would put forward a proposal where they would try and integrate everybody into the decision, and in order to do that they would have to make it ambiguous, which meant that they could not implement the decision because it was ambiguous, so they would have to decide all over again, and so this is the overall model, but we followed it through empirically with three different stages, so here are the three different stages, so this is temporal bracketing, what we showed was they went through a process, it produced ambiguity, therefore we had to start all over again, and so this is a kind of a temporal bracketing of a process over time, and this was very helpful in helping us to understand this process, and the title of the paper is escalating indecision, this is what happens when you need to work together, but you hate each other, you find yourself in this escalating indecision cycle, the good news is that about five or so years after we finished our study, they did actually do something, so it didn't, but this was the process that we observed, and then you can also compare cases, so you can do it, compare outcomes, and if you're doing that you're probably more into explaining variants than looking at process, so that's one thing, but you can also use a comparison between cases to show similarity rather than difference across different settings, and if you do that then you're demonstrating that the process that you're looking at is not just in one case but several, and so that can be helpful as well, you can use comparing cases to show variety, you can illustrate richness around a similar structure, and you can combine process and variants also, so there are authors who use multiple cases to show different processes, but then they they compare the processes and show that some tend to lead to positive outcomes and others tend to lead to negative ones, so they're combining process with variants, so I'm looking at the time here and I'm going to just skip things and move on to my last point which I think is important, because I have all these strategies, but at some point that's not enough, and I think it's a really important point that theoretical insight does not just emerge, so when you read a qualitative paper that at some point somebody always says the theory emerged or the concepts emerged from the data, well yes, no, I mean you did this work, and then there's this step which you cannot, you cannot know exactly what happened but you saw something, and it's that step that's missing from any of the strategies that I've mentioned so far, I called this the conceptual leap, and I wrote a paper on this with Malvina Klag, and this is an image in the paper where we point out that making the conceptual leap is yes about analyzing your data carefully, about using all of these a priori theories to look at your data, about talking to your friends, it's all about doing systematic, disciplined things, but it's also about doing unsystematic, undisciplined things like going for a walk in the park, going for a run, sleeping, sleeping is excellent when you wake up or you're turning over in the middle of the night, that's when you get good ideas, so it's a combination. The discipline is really important, and what we've spoken about most today is the discipline, but there's also this kind of creative side, and if you don't have that, you won't get what we're trying to achieve, so you need this. So I'm going to stop there, see we still have 200 people, so I think we might be able to have a couple of questions at this point. Yes, Alba. Thank you so much, Anne, this has been very, very informative, I'm really grateful, and I guess we're all really grateful as well. Just one question on the very last point you mentioned, which is the creative leap, so I remember writing in one paper about having a creative leap as well, but I don't know if it's the way I framed it, but then I got back from the reviewer that even though it's a creative leap, I should be able to explain how I got there, and that was a bit counterintuitive because that's the point, I can't necessarily explain exactly how I got there, which is why it's a creative leap. So do you have any pointers on how to really couch it so that it doesn't sound like it came out of nowhere, but then at the same time, you don't also try to force fit anything, but then you can show that, yes, it came from knowing my data and all of that, but the direct link that you want to see, I can't necessarily show you. No, I think what is important to show in a paper is the coupling. So the way you found that coupling that you can't explain, but you can show the coupling, and that is you must show that the data, if you look at them carefully, you can see the link with the theory. So if you can show that link, that's the important thing. You don't have to tell them how you actually got there, but if, or you can mention that you had a creative leap, but at the same time in the same paper, you have to be able to show that coupling happening, so that it's tied up with a bone, so that the reader can see that the data, yes, is a good explanation, or the theory is, yes, a good explanation for the data, and the data do justify the theory that you're proposing. So it's the coupling that's important. Okay, okay, thank you so much. Yeah, so you get your creative leap, and then you go back, you mustn't stop with your creative leap, you have to go back and check it out. Otherwise, you can go wrong as well. Fardy? Yeah. Fardy? No, thank you very much, Prof. Really, really interesting and useful presentations, and I find them really very, very relevant to my work, because I've been doing quantitative work until the PhD had to do process research. One of the things that I'm really keen to do is to really make the best decision on which particular vehicle I use to write, you know, because I'm using data from several sources over time on how a form of behavior continued to take different shapes, you know, in an industry that is trying to be formalized, but then a lot of the informal activity kept on happening over time. So the dialectic one seemed quite interesting, but my question is, is there like, would you recommend picking a model and then trying to write after that model, or how best? The question I think you're asking is, where do I start, you know, what does I do first? I think that I would, I tend to start with temporal bracketing, because I sort of like to see in the data, what is it, you know, are there turning points? And then once I've seen that, if there are no turning points, well, then that doesn't really work. Maybe that was kind of a smooth continuity. But if there are any turning points, or, you know, whether something happened, like some new people came in, or a new company appeared in your industry, or something that changed significantly, more significantly than other events, had a potential for change, then those turning points are kind of like a starting point for looking at the data. Then you might move towards more detailed coding of what was going on in each period. And so you would collect together bits of data, which are relevant to each period, and start working on what's going on, what different actors were doing during those periods. So, I mean, that's, I think what I would do, but yeah, it depends. I think you have to find something where you kind of have something to grab onto. Another approach is to find another basis for comparison in your data. So do you want to compare certain types of firms with certain other types of firms? You know, if so, can you subdivide your data according to different types of firms? Or can you subdivide it in some other way? I think it's very useful to find something to grab onto, which you can compare with another thing. I tend to go for temporal brackets, because I'm a lot closer. Daniel. Hi, Anne. Thanks for a great session. This is a question that came from one of our participants, Eva Maria Spreitzer. And her question is, what would you say or what kinds of theories are great to inform the coding of the data, such as different levels, depths, etc. And the thinking is because it is easy to go from low or tight with concepts or too high or too broad with theoretical frameworks or meta theories? Yeah, well, I mean, it depends on the nature of your data. But, you know, as I mentioned, you can you can code your data with no a priori theory, you can just read it and see what you see. That that's the theory behind grounded coding. But if you want to, if you want to develop more oriented coding, I mean, think about what it is, what are some of the the concepts that you're interested in. So, so if you want to really focus on processes, maybe your coding should be about activities, right? So what activities are people thinking about? So that would be one angle to look at. So process, process theory is about activities. So can we code activities? But you might be interested in something else, you might be interested in emotions, for example. So then you might code emotions, and then you might ask yourself, well, what emotions are associated with which activities and which events? So, so that then you would code those. So, I mean, this is a this is a decision, depending on the on the research questions you're interested in. But, but if you're interested in process, I think, I think activities, I think events would be things to focus on. I don't know if that's helpful. For me, it is. I hope Eva Maria likes the answer also. Thank you. Rosala. Hi, thank you very much. So my question is about this combining a grounded theory approach with the a priori approach. And I was reflecting on on this from a more based homological point of view. So as far as understood, one would be more interpreted and the other would be kind of more positivist. And I and I, I still struggle to see how can we do that and how we can combine both. And I don't know, maybe I didn't get it right. Or maybe you have some insight for me. Thank you. Yeah, but I mean, some some theories are interpretive. So I don't think it necessarily, you know, means that one is one is more interpretive and the other is more positivist. But, you know, there is this idea of induction and deduction. But I think that what you need to understand is that even if you are doing an interpretive bottom up constructivist approach, you need to connect it to in order to make a contribution, you need to connect it to some a priori theorizing. So if you read carefully, even Denny Joyer's papers, they are not a theoretical from the start, he reviews, he reviews the literature, he comes up with a research question. And his work, his work done with other colleagues is cumulative, actually, he's interested in identity or has been interested very much in identity. And if you look at each of his papers, they kind of build on each other in many, very, very, very many ways. And so they're not, they're not a theoretical. And so I think you always need to refer back to other literature. Yeah. But you need to find your sources that fit with what you're doing. I think a really interesting body of work, which really shows this kind of bottom up top down idea is the body of work on organizational routines, the theory of routine dynamics. And so this is always, the studies are almost always qualitative. The notion of routine dynamics was developed by Feldman and Pentland. They wrote a very famous 2003 article in administrative science quarterly. Other people interested in routine since that time have built on that paper and their theory, but each one is making a very distinctive contribution. And it's qualitative and it's processual. But the research questions are different, except there are some concepts, foundational concepts that everybody is using, that just simply get more richer and further elaborated each time. So that might be a good body of work to sort of situate this kind of top down bottom up idea against. Thank you very much. If could I add a second question? Yes, okay. It's actually more on the practice on the on the coding and analysis side. So as a PhD student, I also find sometimes a bit overwhelming to look at different cases at the same time. And so I was trying to playing around with different approaches. And I was wondering if you have any suggestion to maybe start from one case or actually know it's much better to look directly through all of them. And what's your opinion on that? Thank you. Yeah, I don't know. I think it depends a little bit on whether you want to explain each case individually and maybe think of them as separate contributions or whether the comparison is really critically important to you. And then you want to keep it keep it going. But I mean, another I think Daniel asked this question, you know, no, it was someone else who asked the question, where do you start? And I said temple bracketing and another another way to start is just to write these narratives for each of your cases. That's that's so helpful. If you have different cases, write the narrative, put quotes everywhere. In the narrative, you know, let's let's just tell the story. And, you know, all the quotes that you think are so great that you absolutely need to use them, you put them in the narrative. And then you've got this kind of secondary database where you can compare the narratives. And so that becomes then you can write new tables that compare the narratives. So you can look case one, case two, the first phase, the second phase, and then it becomes organized. But narrative can be a great way to get started as well. Loreto. Hi, thanks, Anne. It's a really brilliant presentation. I'm really going to help with my my projects that I'm doing at the moment. So thank you. And I'm my questions more about the endpoint and about where where to get published and where you think are kind of the journals that are more aligned to process research. Thank you. Well, it depends what your field is. I'm in the field of management. So the the North American management journals, like Academy of Management Journal and Admirative Science Quarterly and Organization Science, have they published all kinds of research, they published quantitative and qualitative research. And they have editors who are dedicated to qualitative research. So I am an editor at Academy of Management Journal, and I am dedicated to qualitative research. And we have five, we're a team of five editors that consider qualitative research. And it would be the same in the other journals I mentioned. And so although they published a lot of quantitative research, they also published much a great deal of qualitative research. So that that's a good place to go. Many of the European type journals are more qualitative oriented than the North American ones. So organization studies is a great journal, journal management studies are great journals for this work. I'm not sure that I think what in order to decide which kind of journal you want to publish in, it's a good idea just to read, you know, those journals and see where you see things that that correspond to your interests, and that you think that you can relate to. So some journals have more of a sociological flavor, and they may relate more to sociological literatures, some are more managerially oriented. And there are delicate differences that you need to kind of get familiar with. And it's very difficult to pick one. But all the journals I mentioned, and others as well, are very open to process research. Yeah, you might if I mentioned some that probably less so, I mean, in general applied psychology might not be so open to it, I don't know. Yeah. Some I interrupted somebody, Patrick. Yeah. Thank you very much for your very, very brilliant presentation. I have a pretty basic question that has been very, very confusing for me, which is, how do you do process to arrive in from a one of interview, where the respondent is talking about how they make decisions within the organization. Clearly, this person is talking about a process, right, and how they finally arrive at a conclusive decision. But this is a one of kind of interview. So how do you do process to arrive in from such a data? Well, I don't think you can. I mean, because you only have one person, but you can you can represent that person's theory of decision making. So so you could. And if you have several different people, you can look at their theories of decision making so that that they are they are suggesting the stages that you go through and things like that. What I think, you know, when you're looking at an interview, is that there are two ways to develop theory from an interview friend, kind of data. One is to take the generalizations that the person is telling you. So let's say the person says, oh, we always make decisions in. We have a committee, and we make the decisions in the committee. Okay, so you could read that and think, okay, they make decisions in the committee. So I'm generalizing from the generalization of the. Responder. Or instead of doing that, and I think that this is much better, is that you have the accounts of that individual of several specific decisions. So this happened, this happened, this happened, this happened, this happened. The second decision, this happened, this happened, this happened, this happened, this happened, this third decision, this get them to talk about lots of different decisions. Then real months, concrete months, then you generalize from their stories, not from their generalization. See what I mean? It makes a huge difference. So if you, if you're talking, if you're using an interview, get the stories. And sometimes you do generalize from other people's generalizations, but it's much better to get, get as close as you possibly can to the actual events and the accounts of the actual events. And you're getting deeper when you're doing that. I don't know if that's, that's helpful. Thank you very much. That was very, very helpful. So how are we doing? Anyone? I'm just looking, is there something in the chat which I should respond to? Underworld questions. Isidora. I'm not sure we'll have time for that. Yeah, Isidora. Hi. Thank you for a great presentation today. I believe this is a very broad question, but if you can just give us sort of just your general opinion, I'm really interested about quantification of qualitative data. I have thought about it in one of my previous research, but I opted against it because of all the division of whether this is a right research strategy. So I just wanted to hear your opinion on it and maybe if you can suggest some kind of resource that would be valuable in sort of providing a starting point for that. Yeah, so thank you for the question because one of my strategies was quantification and I didn't talk about it. And I didn't talk about it because I'm not particularly fond of it. But I do think quantification can be useful. And when is it useful? It is useful. It's not useful in the description. It doesn't, it doesn't make any, you don't need to count anything if you just want to describe phenomena or or types of events that happen. You don't need it. Where you do need it is where you want to say, okay, say is more of a success than case B or some kind of way of judging differences that is along a scale. Then you have to find ways to do it. And so, for example, I recently did a study with a colleague, which was about, it was an 18 year history. So it's kind of a process study of how managers cited their founders in their discourse in their communications. And we wanted to show that the way they cited them changed over time. And in order to do that, we had to count them. We had to code them into categories and count them to be able to demonstrate to the reader that it's actually true that we were saying they were more like this than they used to be. And so, counting gets important them. And when you're counting, you know, enter, rate, or reliability starts to get important because the precision is important. So then you need to go to resources that can talk to you about, you know, very content analysis type coding where you have categories, and you need to be able to show that these categories are reliable, valid, and so on. So I would look, you know, on the, on Google, I would Google content analysis, probably Krippendorf would be a good author for that, talking about how you would take qualitative data and then use it to quantify certain concepts. But I wouldn't do it unless you really need that comparison. A is bigger than B. Otherwise, one of the reasons I don't like it is you take out all the ambiguity. You take, if you put things into categories and count them, all of the richness of your data kind of disappears. It just has to go because the obligation to be able to find exactly the same number as your colleague means that you have to make things so clear that there is no possible doubt that you have categorized correctly, which means that all of the ambiguity and fluffiness and richness goes. And that's not good. Qualitative data is qualitative. It's not quantitative. So it's a good thing if you need to do that comparison. But if you don't, don't do it, just to do it. It's not worth it. Okay. Yeah, thank you so much. Yeah, I think I should have decided against it simply because the essence and the nuance within each of the, you know, qualitative aspects sort of gets lost. But I still think that it might have been an interesting strategy to show intensity of a certain outcome. Exactly. That's what I think. One person who does it very well and still keeps the richness is Stephen Barley. So if you look at many of Stephen Barley's papers, he's real. He's a fantastic qualitative researcher, but he also counts things. And as a great paper recently in Academy of Management Discoveries about buying cars. But he does a lot of qualitative analysis, but also does counts. So that might be a good example. Okay. Thank you so much. Burak. Thank you very much. I have a brief question. It's about the lens. You mentioned about the theoretical lens. How about the paradigm as the lens? And combined with the theoretical lens, would you please elaborate differences and similarities? How do we use them? Thank you. So you're referring to whether you're having a critical paradigm or you're adopting a interpretive paradigm or a positivist paradigm. Yeah. So I'm agnostic as to which one you might want to adopt. And it's also possible to play with them. So you can pretend, you know, you can say, okay, today I'm a positivist. If I were a positivist, how would I consider these data? Now I'm a critical theorist. How would I consider those data? So you can do that. And it certainly would help you see, it would get you to ask different questions about the data. So if you're a positivist, you're going to be asking, what is the truth? Right. And if you're an interpretive, it's how are people seeing things. And if you're a critical theorist, you would ask yourself, well, who is winning and who is losing in this? And so you ask yourself different questions. And I think that's hard to do within a single paper, but it could be something that you could try and, you know, sort of play around with those approaches. I mean, you can do the same thing with an interview. Take an interview. Look at the interview. What if this was true? The person is telling me. And how can I know that it's true? And if you're looking at an interview positivistically, you will say, well, only the things that are about verifiable facts, I know are to be true. And in order to find out whether it's true, I will need to find someone else's view or I will need to get other data. If you look at an interview interpretively, you would think, well, no, I don't really need anybody else's opinion, because I'm only interested in their interpretation. And I'm not trying to do anything wrong. And if you were to look at it critically, yeah, if you were looking at it critically, you would be very skeptical of what that person is telling you. And you would be asked, now, why are they telling me this? What is it they're trying to convince me of? That you would look at it in a much more skeptical manner. So just thinking about those things, even on one interview, it can get you to see things different. See, exactly like the example that you gave about the hospitals merging, like for example, in this case, we can try to understand the phenomena of decision making from, you know, generative constructionist perspective. But also we can look at it from a conflict paradigm, meaning that decisions are going to create conflicts. So in this case, our theoretical lens would be different, depending on the paradigm. Yeah, indeed. Yes. I agree. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.28, "text": " So, to get us started and to make sure that everyone is reasonably on the same page, what", "tokens": [50364, 407, 11, 281, 483, 505, 1409, 293, 281, 652, 988, 300, 1518, 307, 23551, 322, 264, 912, 3028, 11, 437, 50828], "temperature": 0.0, "avg_logprob": -0.36924657959868945, "compression_ratio": 1.35, "no_speech_prob": 0.03390054404735565}, {"id": 1, "seek": 0, "start": 9.28, "end": 12.56, "text": " is the process for that?", "tokens": [50828, 307, 264, 1399, 337, 300, 30, 50992], "temperature": 0.0, "avg_logprob": -0.36924657959868945, "compression_ratio": 1.35, "no_speech_prob": 0.03390054404735565}, {"id": 2, "seek": 0, "start": 12.56, "end": 21.6, "text": " So, here are some definitions that come from an article that I did with Clive Smallman,", "tokens": [50992, 407, 11, 510, 366, 512, 21988, 300, 808, 490, 364, 7222, 300, 286, 630, 365, 2033, 488, 15287, 1601, 11, 51444], "temperature": 0.0, "avg_logprob": -0.36924657959868945, "compression_ratio": 1.35, "no_speech_prob": 0.03390054404735565}, {"id": 3, "seek": 0, "start": 21.6, "end": 25.400000000000002, "text": " Harry Tsoukas and Yvonne Devane in 2013.", "tokens": [51444, 9378, 16518, 263, 32876, 293, 398, 85, 22419, 9096, 1929, 294, 9012, 13, 51634], "temperature": 0.0, "avg_logprob": -0.36924657959868945, "compression_ratio": 1.35, "no_speech_prob": 0.03390054404735565}, {"id": 4, "seek": 2540, "start": 25.479999999999997, "end": 32.92, "text": " So, process thinking implies considering phenomena as in motion, as unfolding over time as becoming,", "tokens": [50368, 407, 11, 1399, 1953, 18779, 8079, 22004, 382, 294, 5394, 11, 382, 44586, 670, 565, 382, 5617, 11, 50740], "temperature": 0.0, "avg_logprob": -0.16590054004223315, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.009826745837926865}, {"id": 5, "seek": 2540, "start": 32.92, "end": 39.879999999999995, "text": " and process researchers seek to understand and explain the world in terms of activity,", "tokens": [50740, 293, 1399, 10309, 8075, 281, 1223, 293, 2903, 264, 1002, 294, 2115, 295, 5191, 11, 51088], "temperature": 0.0, "avg_logprob": -0.16590054004223315, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.009826745837926865}, {"id": 6, "seek": 2540, "start": 40.519999999999996, "end": 42.519999999999996, "text": " temporality, and flow.", "tokens": [51120, 8219, 1860, 11, 293, 3095, 13, 51220], "temperature": 0.0, "avg_logprob": -0.16590054004223315, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.009826745837926865}, {"id": 7, "seek": 2540, "start": 42.519999999999996, "end": 44.84, "text": " So, basically, we're looking at things moving.", "tokens": [51220, 407, 11, 1936, 11, 321, 434, 1237, 412, 721, 2684, 13, 51336], "temperature": 0.0, "avg_logprob": -0.16590054004223315, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.009826745837926865}, {"id": 8, "seek": 2540, "start": 46.76, "end": 53.239999999999995, "text": " And I have two images that would reflect what I've just said here.", "tokens": [51432, 400, 286, 362, 732, 5267, 300, 576, 5031, 437, 286, 600, 445, 848, 510, 13, 51756], "temperature": 0.0, "avg_logprob": -0.16590054004223315, "compression_ratio": 1.5069767441860464, "no_speech_prob": 0.009826745837926865}, {"id": 9, "seek": 5324, "start": 53.96, "end": 60.52, "text": " They have slightly different foci in terms of what we mean by process.", "tokens": [50400, 814, 362, 4748, 819, 726, 537, 294, 2115, 295, 437, 321, 914, 538, 1399, 13, 50728], "temperature": 0.0, "avg_logprob": -0.07992976339239823, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.002209440106526017}, {"id": 10, "seek": 5324, "start": 60.52, "end": 62.52, "text": " And I'm just going to show the two images.", "tokens": [50728, 400, 286, 478, 445, 516, 281, 855, 264, 732, 5267, 13, 50828], "temperature": 0.0, "avg_logprob": -0.07992976339239823, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.002209440106526017}, {"id": 11, "seek": 5324, "start": 63.08, "end": 68.76, "text": " And what I'm going to talk about today really kind of applies, I think, to both of them.", "tokens": [50856, 400, 437, 286, 478, 516, 281, 751, 466, 965, 534, 733, 295, 13165, 11, 286, 519, 11, 281, 1293, 295, 552, 13, 51140], "temperature": 0.0, "avg_logprob": -0.07992976339239823, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.002209440106526017}, {"id": 12, "seek": 5324, "start": 68.76, "end": 74.76, "text": " So, the first image is this idea of process as evolving over time.", "tokens": [51140, 407, 11, 264, 700, 3256, 307, 341, 1558, 295, 1399, 382, 21085, 670, 565, 13, 51440], "temperature": 0.0, "avg_logprob": -0.07992976339239823, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.002209440106526017}, {"id": 13, "seek": 5324, "start": 74.76, "end": 81.56, "text": " So, you have a phenomenon in one state, and you're interested in looking at how that phenomenon", "tokens": [51440, 407, 11, 291, 362, 257, 14029, 294, 472, 1785, 11, 293, 291, 434, 3102, 294, 1237, 412, 577, 300, 14029, 51780], "temperature": 0.0, "avg_logprob": -0.07992976339239823, "compression_ratio": 1.5938864628820961, "no_speech_prob": 0.002209440106526017}, {"id": 14, "seek": 8156, "start": 82.28, "end": 86.60000000000001, "text": " evolves through events, activities, and choices.", "tokens": [50400, 43737, 807, 3931, 11, 5354, 11, 293, 7994, 13, 50616], "temperature": 0.0, "avg_logprob": -0.07686237078994068, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0014307149685919285}, {"id": 15, "seek": 8156, "start": 86.60000000000001, "end": 93.32000000000001, "text": " And if you are adopting a process perspective, you're going to be focusing on those events,", "tokens": [50616, 400, 498, 291, 366, 32328, 257, 1399, 4585, 11, 291, 434, 516, 281, 312, 8416, 322, 729, 3931, 11, 50952], "temperature": 0.0, "avg_logprob": -0.07686237078994068, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0014307149685919285}, {"id": 16, "seek": 8156, "start": 93.32000000000001, "end": 101.80000000000001, "text": " activities, and choices as your data and the elements of your theory.", "tokens": [50952, 5354, 11, 293, 7994, 382, 428, 1412, 293, 264, 4959, 295, 428, 5261, 13, 51376], "temperature": 0.0, "avg_logprob": -0.07686237078994068, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0014307149685919285}, {"id": 17, "seek": 8156, "start": 101.80000000000001, "end": 108.28, "text": " So, not talking about dependent variables and independent variables, we're talking about", "tokens": [51376, 407, 11, 406, 1417, 466, 12334, 9102, 293, 6695, 9102, 11, 321, 434, 1417, 466, 51700], "temperature": 0.0, "avg_logprob": -0.07686237078994068, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0014307149685919285}, {"id": 18, "seek": 10828, "start": 108.28, "end": 111.72, "text": " things that happen, which are quite different.", "tokens": [50364, 721, 300, 1051, 11, 597, 366, 1596, 819, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10508780643857758, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.000687287887558341}, {"id": 19, "seek": 10828, "start": 113.16, "end": 114.68, "text": " So, that's the first image.", "tokens": [50608, 407, 11, 300, 311, 264, 700, 3256, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10508780643857758, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.000687287887558341}, {"id": 20, "seek": 10828, "start": 115.48, "end": 124.76, "text": " The second image, which is now on the screen, is this idea of process as activity and flow.", "tokens": [50724, 440, 1150, 3256, 11, 597, 307, 586, 322, 264, 2568, 11, 307, 341, 1558, 295, 1399, 382, 5191, 293, 3095, 13, 51188], "temperature": 0.0, "avg_logprob": -0.10508780643857758, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.000687287887558341}, {"id": 21, "seek": 10828, "start": 124.76, "end": 131.4, "text": " In other words, this process as all there is, everything is made up of processes.", "tokens": [51188, 682, 661, 2283, 11, 341, 1399, 382, 439, 456, 307, 11, 1203, 307, 1027, 493, 295, 7555, 13, 51520], "temperature": 0.0, "avg_logprob": -0.10508780643857758, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.000687287887558341}, {"id": 22, "seek": 10828, "start": 131.4, "end": 137.56, "text": " So, this is a second image of process, and some people call this a strong process approach.", "tokens": [51520, 407, 11, 341, 307, 257, 1150, 3256, 295, 1399, 11, 293, 512, 561, 818, 341, 257, 2068, 1399, 3109, 13, 51828], "temperature": 0.0, "avg_logprob": -0.10508780643857758, "compression_ratio": 1.7435897435897436, "no_speech_prob": 0.000687287887558341}, {"id": 23, "seek": 13828, "start": 138.52, "end": 144.6, "text": " And I really like this quote from Russia, 1996, which kind of reflects this.", "tokens": [50376, 400, 286, 534, 411, 341, 6513, 490, 6797, 11, 22690, 11, 597, 733, 295, 18926, 341, 13, 50680], "temperature": 0.0, "avg_logprob": -0.0751890149609796, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.00024143836344592273}, {"id": 24, "seek": 13828, "start": 144.6, "end": 148.28, "text": " So, the river is not an object, but an ever-changing flow.", "tokens": [50680, 407, 11, 264, 6810, 307, 406, 364, 2657, 11, 457, 364, 1562, 12, 27123, 3095, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0751890149609796, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.00024143836344592273}, {"id": 25, "seek": 13828, "start": 149.32, "end": 151.88, "text": " Things are made up of processes.", "tokens": [50916, 9514, 366, 1027, 493, 295, 7555, 13, 51044], "temperature": 0.0, "avg_logprob": -0.0751890149609796, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.00024143836344592273}, {"id": 26, "seek": 13828, "start": 152.52, "end": 155.16, "text": " The sun is not a thing, but a flaming fire.", "tokens": [51076, 440, 3295, 307, 406, 257, 551, 11, 457, 257, 45718, 2610, 13, 51208], "temperature": 0.0, "avg_logprob": -0.0751890149609796, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.00024143836344592273}, {"id": 27, "seek": 13828, "start": 155.16, "end": 158.44, "text": " Everything in nature is a matter of process.", "tokens": [51208, 5471, 294, 3687, 307, 257, 1871, 295, 1399, 13, 51372], "temperature": 0.0, "avg_logprob": -0.0751890149609796, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.00024143836344592273}, {"id": 28, "seek": 13828, "start": 158.44, "end": 167.88, "text": " So, this second image really looks at phenomena as processes,", "tokens": [51372, 407, 11, 341, 1150, 3256, 534, 1542, 412, 22004, 382, 7555, 11, 51844], "temperature": 0.0, "avg_logprob": -0.0751890149609796, "compression_ratio": 1.541062801932367, "no_speech_prob": 0.00024143836344592273}, {"id": 29, "seek": 16788, "start": 167.88, "end": 169.48, "text": " rather than looking at phenomena.", "tokens": [50364, 2831, 813, 1237, 412, 22004, 13, 50444], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 30, "seek": 16788, "start": 169.48, "end": 170.51999999999998, "text": " It's changing over time.", "tokens": [50444, 467, 311, 4473, 670, 565, 13, 50496], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 31, "seek": 16788, "start": 170.51999999999998, "end": 172.84, "text": " So, these are two different ways of looking at process.", "tokens": [50496, 407, 11, 613, 366, 732, 819, 2098, 295, 1237, 412, 1399, 13, 50612], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 32, "seek": 16788, "start": 174.12, "end": 175.32, "text": " That's just the backdrop.", "tokens": [50676, 663, 311, 445, 264, 32697, 13, 50736], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 33, "seek": 16788, "start": 176.84, "end": 183.64, "text": " I'm now going to look at the implications of this for methodology.", "tokens": [50812, 286, 478, 586, 516, 281, 574, 412, 264, 16602, 295, 341, 337, 24850, 13, 51152], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 34, "seek": 16788, "start": 184.2, "end": 191.24, "text": " So, if you are taking a process perspective, you want to capture that activity and flow.", "tokens": [51180, 407, 11, 498, 291, 366, 1940, 257, 1399, 4585, 11, 291, 528, 281, 7983, 300, 5191, 293, 3095, 13, 51532], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 35, "seek": 16788, "start": 192.04, "end": 197.56, "text": " And so, you're going to collect data, and what are your data going to look like?", "tokens": [51572, 400, 370, 11, 291, 434, 516, 281, 2500, 1412, 11, 293, 437, 366, 428, 1412, 516, 281, 574, 411, 30, 51848], "temperature": 0.0, "avg_logprob": -0.0833260964374153, "compression_ratio": 1.6755555555555555, "no_speech_prob": 0.00035675213439390063}, {"id": 36, "seek": 19788, "start": 197.88, "end": 206.84, "text": " Well, typically, process data involves at least three different kinds of things.", "tokens": [50364, 1042, 11, 5850, 11, 1399, 1412, 11626, 412, 1935, 1045, 819, 3685, 295, 721, 13, 50812], "temperature": 0.0, "avg_logprob": -0.08354951189709948, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0001354214909952134}, {"id": 37, "seek": 19788, "start": 206.84, "end": 212.84, "text": " So, the first kind of thing that you might collect is observations in vivo.", "tokens": [50812, 407, 11, 264, 700, 733, 295, 551, 300, 291, 1062, 2500, 307, 18163, 294, 30689, 13, 51112], "temperature": 0.0, "avg_logprob": -0.08354951189709948, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0001354214909952134}, {"id": 38, "seek": 19788, "start": 213.48, "end": 216.28, "text": " So, you are looking at things in real time.", "tokens": [51144, 407, 11, 291, 366, 1237, 412, 721, 294, 957, 565, 13, 51284], "temperature": 0.0, "avg_logprob": -0.08354951189709948, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0001354214909952134}, {"id": 39, "seek": 19788, "start": 216.28, "end": 221.24, "text": " You might be going to meetings, capturing conversations, capturing events,", "tokens": [51284, 509, 1062, 312, 516, 281, 8410, 11, 23384, 7315, 11, 23384, 3931, 11, 51532], "temperature": 0.0, "avg_logprob": -0.08354951189709948, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0001354214909952134}, {"id": 40, "seek": 19788, "start": 221.24, "end": 223.8, "text": " shadowing people in the things that they do.", "tokens": [51532, 8576, 278, 561, 294, 264, 721, 300, 436, 360, 13, 51660], "temperature": 0.0, "avg_logprob": -0.08354951189709948, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.0001354214909952134}, {"id": 41, "seek": 22380, "start": 224.36, "end": 228.76000000000002, "text": " And so, part of your data is likely to be observations.", "tokens": [50392, 400, 370, 11, 644, 295, 428, 1412, 307, 3700, 281, 312, 18163, 13, 50612], "temperature": 0.0, "avg_logprob": -0.05183414133583627, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.000828525226097554}, {"id": 42, "seek": 22380, "start": 229.88000000000002, "end": 238.52, "text": " A second way of collecting process data is to build on people's memories and interpretations.", "tokens": [50668, 316, 1150, 636, 295, 12510, 1399, 1412, 307, 281, 1322, 322, 561, 311, 8495, 293, 37547, 13, 51100], "temperature": 0.0, "avg_logprob": -0.05183414133583627, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.000828525226097554}, {"id": 43, "seek": 22380, "start": 239.16000000000003, "end": 244.36, "text": " And you do this through interviews, diaries, focus groups, questionnaires,", "tokens": [51132, 400, 291, 360, 341, 807, 12318, 11, 1026, 4889, 11, 1879, 3935, 11, 1168, 49551, 11, 51392], "temperature": 0.0, "avg_logprob": -0.05183414133583627, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.000828525226097554}, {"id": 44, "seek": 22380, "start": 244.36, "end": 249.8, "text": " all kinds of ways of getting at how people understand what is happening,", "tokens": [51392, 439, 3685, 295, 2098, 295, 1242, 412, 577, 561, 1223, 437, 307, 2737, 11, 51664], "temperature": 0.0, "avg_logprob": -0.05183414133583627, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.000828525226097554}, {"id": 45, "seek": 22380, "start": 249.8, "end": 253.16000000000003, "text": " what has happened, and how that evolves over time.", "tokens": [51664, 437, 575, 2011, 11, 293, 577, 300, 43737, 670, 565, 13, 51832], "temperature": 0.0, "avg_logprob": -0.05183414133583627, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.000828525226097554}, {"id": 46, "seek": 25380, "start": 254.60000000000002, "end": 259.72, "text": " And the third way is to look for artifacts.", "tokens": [50404, 400, 264, 2636, 636, 307, 281, 574, 337, 24617, 13, 50660], "temperature": 0.0, "avg_logprob": -0.14223778100661288, "compression_ratio": 1.6030150753768844, "no_speech_prob": 0.0001821957266656682}, {"id": 47, "seek": 25380, "start": 259.72, "end": 266.04, "text": " So, artifacts that were created at moments in time that we can actually timestamp", "tokens": [50660, 407, 11, 24617, 300, 645, 2942, 412, 6065, 294, 565, 300, 321, 393, 767, 49108, 1215, 50976], "temperature": 0.0, "avg_logprob": -0.14223778100661288, "compression_ratio": 1.6030150753768844, "no_speech_prob": 0.0001821957266656682}, {"id": 48, "seek": 25380, "start": 266.04, "end": 268.12, "text": " so that we know when they happened.", "tokens": [50976, 370, 300, 321, 458, 562, 436, 2011, 13, 51080], "temperature": 0.0, "avg_logprob": -0.14223778100661288, "compression_ratio": 1.6030150753768844, "no_speech_prob": 0.0001821957266656682}, {"id": 49, "seek": 25380, "start": 268.12, "end": 275.72, "text": " So, things like minutes of meetings, or recently we've been using emails, reports.", "tokens": [51080, 407, 11, 721, 411, 2077, 295, 8410, 11, 420, 3938, 321, 600, 668, 1228, 12524, 11, 7122, 13, 51460], "temperature": 0.0, "avg_logprob": -0.14223778100661288, "compression_ratio": 1.6030150753768844, "no_speech_prob": 0.0001821957266656682}, {"id": 50, "seek": 25380, "start": 277.16, "end": 282.36, "text": " So, all of these sources of data, and this presentation is not about data,", "tokens": [51532, 407, 11, 439, 295, 613, 7139, 295, 1412, 11, 293, 341, 5860, 307, 406, 466, 1412, 11, 51792], "temperature": 0.0, "avg_logprob": -0.14223778100661288, "compression_ratio": 1.6030150753768844, "no_speech_prob": 0.0001821957266656682}, {"id": 51, "seek": 28236, "start": 282.44, "end": 284.68, "text": " so we're not going to spend a lot of time on this.", "tokens": [50368, 370, 321, 434, 406, 516, 281, 3496, 257, 688, 295, 565, 322, 341, 13, 50480], "temperature": 0.0, "avg_logprob": -0.11209105253219605, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.0014295927248895168}, {"id": 52, "seek": 28236, "start": 284.68, "end": 287.64, "text": " But all of these sources of data are complementary.", "tokens": [50480, 583, 439, 295, 613, 7139, 295, 1412, 366, 40705, 13, 50628], "temperature": 0.0, "avg_logprob": -0.11209105253219605, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.0014295927248895168}, {"id": 53, "seek": 28236, "start": 287.64, "end": 292.04, "text": " They provide different strengths and weaknesses.", "tokens": [50628, 814, 2893, 819, 16986, 293, 24381, 13, 50848], "temperature": 0.0, "avg_logprob": -0.11209105253219605, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.0014295927248895168}, {"id": 54, "seek": 28236, "start": 292.04, "end": 295.40000000000003, "text": " An interview has problems because of memories.", "tokens": [50848, 1107, 4049, 575, 2740, 570, 295, 8495, 13, 51016], "temperature": 0.0, "avg_logprob": -0.11209105253219605, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.0014295927248895168}, {"id": 55, "seek": 28236, "start": 295.40000000000003, "end": 297.40000000000003, "text": " People don't necessarily remember.", "tokens": [51016, 3432, 500, 380, 4725, 1604, 13, 51116], "temperature": 0.0, "avg_logprob": -0.11209105253219605, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.0014295927248895168}, {"id": 56, "seek": 28236, "start": 297.40000000000003, "end": 302.28000000000003, "text": " But if you see something, you observe it, then that can compensate for that, and so on.", "tokens": [51116, 583, 498, 291, 536, 746, 11, 291, 11441, 309, 11, 550, 300, 393, 29458, 337, 300, 11, 293, 370, 322, 13, 51360], "temperature": 0.0, "avg_logprob": -0.11209105253219605, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.0014295927248895168}, {"id": 57, "seek": 30228, "start": 302.28, "end": 305.4, "text": " So, these three, I call them the big three,", "tokens": [50364, 407, 11, 613, 1045, 11, 286, 818, 552, 264, 955, 1045, 11, 50520], "temperature": 0.0, "avg_logprob": -0.10787449144337276, "compression_ratio": 1.6723163841807909, "no_speech_prob": 0.0001333812833763659}, {"id": 58, "seek": 30228, "start": 308.59999999999997, "end": 315.88, "text": " sources of data for qualitative research more generally, and for process research more particularly,", "tokens": [50680, 7139, 295, 1412, 337, 31312, 2132, 544, 5101, 11, 293, 337, 1399, 2132, 544, 4098, 11, 51044], "temperature": 0.0, "avg_logprob": -0.10787449144337276, "compression_ratio": 1.6723163841807909, "no_speech_prob": 0.0001333812833763659}, {"id": 59, "seek": 30228, "start": 316.44, "end": 322.91999999999996, "text": " we're going to be using them if we want to develop process understandings.", "tokens": [51072, 321, 434, 516, 281, 312, 1228, 552, 498, 321, 528, 281, 1499, 1399, 1223, 1109, 13, 51396], "temperature": 0.0, "avg_logprob": -0.10787449144337276, "compression_ratio": 1.6723163841807909, "no_speech_prob": 0.0001333812833763659}, {"id": 60, "seek": 30228, "start": 324.91999999999996, "end": 329.88, "text": " And if you think about it, if you've got all of these three sources of data,", "tokens": [51496, 400, 498, 291, 519, 466, 309, 11, 498, 291, 600, 658, 439, 295, 613, 1045, 7139, 295, 1412, 11, 51744], "temperature": 0.0, "avg_logprob": -0.10787449144337276, "compression_ratio": 1.6723163841807909, "no_speech_prob": 0.0001333812833763659}, {"id": 61, "seek": 32988, "start": 330.52, "end": 335.32, "text": " got interviews from all sorts of people, you've got observations from all sorts of events,", "tokens": [50396, 658, 12318, 490, 439, 7527, 295, 561, 11, 291, 600, 658, 18163, 490, 439, 7527, 295, 3931, 11, 50636], "temperature": 0.0, "avg_logprob": -0.13311245275098224, "compression_ratio": 1.650273224043716, "no_speech_prob": 0.0007075413595885038}, {"id": 62, "seek": 32988, "start": 335.32, "end": 343.08, "text": " you've got documents and emails, what is the result of that?", "tokens": [50636, 291, 600, 658, 8512, 293, 12524, 11, 437, 307, 264, 1874, 295, 300, 30, 51024], "temperature": 0.0, "avg_logprob": -0.13311245275098224, "compression_ratio": 1.650273224043716, "no_speech_prob": 0.0007075413595885038}, {"id": 63, "seek": 32988, "start": 343.08, "end": 346.04, "text": " It's a total mess.", "tokens": [51024, 467, 311, 257, 3217, 2082, 13, 51172], "temperature": 0.0, "avg_logprob": -0.13311245275098224, "compression_ratio": 1.650273224043716, "no_speech_prob": 0.0007075413595885038}, {"id": 64, "seek": 32988, "start": 347.88, "end": 350.2, "text": " So, and it's shapeless.", "tokens": [51264, 407, 11, 293, 309, 311, 6706, 4272, 13, 51380], "temperature": 0.0, "avg_logprob": -0.13311245275098224, "compression_ratio": 1.650273224043716, "no_speech_prob": 0.0007075413595885038}, {"id": 65, "seek": 32988, "start": 351.32, "end": 354.28, "text": " You've got all these separate bits and pieces.", "tokens": [51436, 509, 600, 658, 439, 613, 4994, 9239, 293, 3755, 13, 51584], "temperature": 0.0, "avg_logprob": -0.13311245275098224, "compression_ratio": 1.650273224043716, "no_speech_prob": 0.0007075413595885038}, {"id": 66, "seek": 32988, "start": 355.4, "end": 358.6, "text": " So, the question then is, what are we going to do with that?", "tokens": [51640, 407, 11, 264, 1168, 550, 307, 11, 437, 366, 321, 516, 281, 360, 365, 300, 30, 51800], "temperature": 0.0, "avg_logprob": -0.13311245275098224, "compression_ratio": 1.650273224043716, "no_speech_prob": 0.0007075413595885038}, {"id": 67, "seek": 35860, "start": 358.6, "end": 364.76000000000005, "text": " And so, this is what this webinar is really all about, is what we do then.", "tokens": [50364, 400, 370, 11, 341, 307, 437, 341, 10942, 307, 534, 439, 466, 11, 307, 437, 321, 360, 550, 13, 50672], "temperature": 0.0, "avg_logprob": -0.08712789747450086, "compression_ratio": 1.50920245398773, "no_speech_prob": 0.00020969926845282316}, {"id": 68, "seek": 35860, "start": 367.64000000000004, "end": 375.48, "text": " And what we would like to do is move from that mess, the cloud of miscellaneous stuff", "tokens": [50816, 400, 437, 321, 576, 411, 281, 360, 307, 1286, 490, 300, 2082, 11, 264, 4588, 295, 3346, 4164, 15447, 1507, 51208], "temperature": 0.0, "avg_logprob": -0.08712789747450086, "compression_ratio": 1.50920245398773, "no_speech_prob": 0.00020969926845282316}, {"id": 69, "seek": 35860, "start": 375.48, "end": 383.32000000000005, "text": " that we had collected, to something which is understandable, abstract, generalizable,", "tokens": [51208, 300, 321, 632, 11087, 11, 281, 746, 597, 307, 25648, 11, 12649, 11, 2674, 22395, 11, 51600], "temperature": 0.0, "avg_logprob": -0.08712789747450086, "compression_ratio": 1.50920245398773, "no_speech_prob": 0.00020969926845282316}, {"id": 70, "seek": 38332, "start": 384.2, "end": 391.48, "text": " a theory. Some kind of theorizing is what we seek to do. So, the question is, how do we move", "tokens": [50408, 257, 5261, 13, 2188, 733, 295, 27423, 3319, 307, 437, 321, 8075, 281, 360, 13, 407, 11, 264, 1168, 307, 11, 577, 360, 321, 1286, 50772], "temperature": 0.0, "avg_logprob": -0.1476133175385304, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0011153414379805326}, {"id": 71, "seek": 38332, "start": 391.48, "end": 396.76, "text": " from that mess to something which is much more defined, posimonious, clear, and so on.", "tokens": [50772, 490, 300, 2082, 281, 746, 597, 307, 709, 544, 7642, 11, 1366, 25098, 851, 11, 1850, 11, 293, 370, 322, 13, 51036], "temperature": 0.0, "avg_logprob": -0.1476133175385304, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0011153414379805326}, {"id": 72, "seek": 38332, "start": 397.8, "end": 403.96, "text": " So, here's a picture of what we're trying to do. This is our challenge. We have to move from", "tokens": [51088, 407, 11, 510, 311, 257, 3036, 295, 437, 321, 434, 1382, 281, 360, 13, 639, 307, 527, 3430, 13, 492, 362, 281, 1286, 490, 51396], "temperature": 0.0, "avg_logprob": -0.1476133175385304, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0011153414379805326}, {"id": 73, "seek": 40396, "start": 403.96, "end": 412.03999999999996, "text": " something on the left, that is concrete, very specific, it's rich and it's messy,", "tokens": [50364, 746, 322, 264, 1411, 11, 300, 307, 9859, 11, 588, 2685, 11, 309, 311, 4593, 293, 309, 311, 16191, 11, 50768], "temperature": 0.0, "avg_logprob": -0.194543719291687, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.060027580708265305}, {"id": 74, "seek": 40396, "start": 414.2, "end": 423.0, "text": " to something on the right, which is abstract and novel. And the process for doing that,", "tokens": [50876, 281, 746, 322, 264, 558, 11, 597, 307, 12649, 293, 7613, 13, 400, 264, 1399, 337, 884, 300, 11, 51316], "temperature": 0.0, "avg_logprob": -0.194543719291687, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.060027580708265305}, {"id": 75, "seek": 40396, "start": 423.0, "end": 429.96, "text": " okay, for connecting the concrete, rich and messy, and the abstract and novel,", "tokens": [51316, 1392, 11, 337, 11015, 264, 9859, 11, 4593, 293, 16191, 11, 293, 264, 12649, 293, 7613, 11, 51664], "temperature": 0.0, "avg_logprob": -0.194543719291687, "compression_ratio": 1.710344827586207, "no_speech_prob": 0.060027580708265305}, {"id": 76, "seek": 42996, "start": 430.91999999999996, "end": 442.03999999999996, "text": " it has to be credible, right? We have to couple the two, so that a reader of our work, our thesis,", "tokens": [50412, 309, 575, 281, 312, 32757, 11, 558, 30, 492, 362, 281, 1916, 264, 732, 11, 370, 300, 257, 15149, 295, 527, 589, 11, 527, 22288, 11, 50968], "temperature": 0.0, "avg_logprob": -0.13675878017763549, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.0010474846931174397}, {"id": 77, "seek": 42996, "start": 442.03999999999996, "end": 449.88, "text": " or our article, can actually see how we've done this, that we have started from a mess,", "tokens": [50968, 420, 527, 7222, 11, 393, 767, 536, 577, 321, 600, 1096, 341, 11, 300, 321, 362, 1409, 490, 257, 2082, 11, 51360], "temperature": 0.0, "avg_logprob": -0.13675878017763549, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.0010474846931174397}, {"id": 78, "seek": 42996, "start": 451.08, "end": 458.2, "text": " we have ended up with a theory, and that the coupling, the way we have joined the two, is credible.", "tokens": [51420, 321, 362, 4590, 493, 365, 257, 5261, 11, 293, 300, 264, 37447, 11, 264, 636, 321, 362, 6869, 264, 732, 11, 307, 32757, 13, 51776], "temperature": 0.0, "avg_logprob": -0.13675878017763549, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.0010474846931174397}, {"id": 79, "seek": 45820, "start": 458.52, "end": 465.32, "text": " But creative slightly, because if we're not producing anything new, then why would we", "tokens": [50380, 583, 5880, 4748, 11, 570, 498, 321, 434, 406, 10501, 1340, 777, 11, 550, 983, 576, 321, 50720], "temperature": 0.0, "avg_logprob": -0.09782412679571854, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0004721751029137522}, {"id": 80, "seek": 45820, "start": 465.32, "end": 473.08, "text": " be doing this? So, that's the challenge. And starting from that point, there are several", "tokens": [50720, 312, 884, 341, 30, 407, 11, 300, 311, 264, 3430, 13, 400, 2891, 490, 300, 935, 11, 456, 366, 2940, 51108], "temperature": 0.0, "avg_logprob": -0.09782412679571854, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0004721751029137522}, {"id": 81, "seek": 45820, "start": 473.08, "end": 478.28, "text": " things that can go wrong. So, I'm just going to give you a little portrait of some of the things", "tokens": [51108, 721, 300, 393, 352, 2085, 13, 407, 11, 286, 478, 445, 516, 281, 976, 291, 257, 707, 17126, 295, 512, 295, 264, 721, 51368], "temperature": 0.0, "avg_logprob": -0.09782412679571854, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0004721751029137522}, {"id": 82, "seek": 45820, "start": 478.28, "end": 484.2, "text": " that can go wrong with that, and that we're going to try and avoid. So, the first thing that can go", "tokens": [51368, 300, 393, 352, 2085, 365, 300, 11, 293, 300, 321, 434, 516, 281, 853, 293, 5042, 13, 407, 11, 264, 700, 551, 300, 393, 352, 51664], "temperature": 0.0, "avg_logprob": -0.09782412679571854, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0004721751029137522}, {"id": 83, "seek": 48420, "start": 484.2, "end": 494.92, "text": " wrong is that we have wonderful concrete, rich, messy data, and beautiful abstract novel theory,", "tokens": [50364, 2085, 307, 300, 321, 362, 3715, 9859, 11, 4593, 11, 16191, 1412, 11, 293, 2238, 12649, 7613, 5261, 11, 50900], "temperature": 0.0, "avg_logprob": -0.12038441326307214, "compression_ratio": 1.362962962962963, "no_speech_prob": 0.0016205969732254744}, {"id": 84, "seek": 48420, "start": 496.28, "end": 504.36, "text": " but we haven't properly connected the two. And so, that is a very easy mistake to make.", "tokens": [50968, 457, 321, 2378, 380, 6108, 4582, 264, 732, 13, 400, 370, 11, 300, 307, 257, 588, 1858, 6146, 281, 652, 13, 51372], "temperature": 0.0, "avg_logprob": -0.12038441326307214, "compression_ratio": 1.362962962962963, "no_speech_prob": 0.0016205969732254744}, {"id": 85, "seek": 50436, "start": 504.92, "end": 513.64, "text": " We can look at our data and be inspired vaguely about some kind of theory,", "tokens": [50392, 492, 393, 574, 412, 527, 1412, 293, 312, 7547, 13501, 48863, 466, 512, 733, 295, 5261, 11, 50828], "temperature": 0.0, "avg_logprob": -0.10684045525484306, "compression_ratio": 1.28125, "no_speech_prob": 0.007453884929418564}, {"id": 86, "seek": 50436, "start": 513.64, "end": 521.48, "text": " but we haven't shown tight connections between the two. So, that's loose coupling. That's", "tokens": [50828, 457, 321, 2378, 380, 4898, 4524, 9271, 1296, 264, 732, 13, 407, 11, 300, 311, 9612, 37447, 13, 663, 311, 51220], "temperature": 0.0, "avg_logprob": -0.10684045525484306, "compression_ratio": 1.28125, "no_speech_prob": 0.007453884929418564}, {"id": 87, "seek": 52148, "start": 521.48, "end": 537.32, "text": " blind alley one. I need to be careful with that. So, blind alley two is that we code the data to", "tokens": [50364, 6865, 26660, 472, 13, 286, 643, 281, 312, 5026, 365, 300, 13, 407, 11, 6865, 26660, 732, 307, 300, 321, 3089, 264, 1412, 281, 51156], "temperature": 0.0, "avg_logprob": -0.13072457605478716, "compression_ratio": 1.4172661870503598, "no_speech_prob": 0.0013455781154334545}, {"id": 88, "seek": 52148, "start": 537.32, "end": 547.5600000000001, "text": " death and end up with something which actually doesn't reach beyond the data. It is just descriptive", "tokens": [51156, 2966, 293, 917, 493, 365, 746, 597, 767, 1177, 380, 2524, 4399, 264, 1412, 13, 467, 307, 445, 42585, 51668], "temperature": 0.0, "avg_logprob": -0.13072457605478716, "compression_ratio": 1.4172661870503598, "no_speech_prob": 0.0013455781154334545}, {"id": 89, "seek": 54756, "start": 547.64, "end": 554.92, "text": " and dull. And that's very easy, too. If you, in a certain sense, if you stay too close to your", "tokens": [50368, 293, 23471, 13, 400, 300, 311, 588, 1858, 11, 886, 13, 759, 291, 11, 294, 257, 1629, 2020, 11, 498, 291, 1754, 886, 1998, 281, 428, 50732], "temperature": 0.0, "avg_logprob": -0.10591447194417318, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.002713934751227498}, {"id": 90, "seek": 54756, "start": 554.92, "end": 562.76, "text": " data, this is what happens to you. You don't reach beyond it. So, you just have codes,", "tokens": [50732, 1412, 11, 341, 307, 437, 2314, 281, 291, 13, 509, 500, 380, 2524, 4399, 309, 13, 407, 11, 291, 445, 362, 14211, 11, 51124], "temperature": 0.0, "avg_logprob": -0.10591447194417318, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.002713934751227498}, {"id": 91, "seek": 54756, "start": 562.76, "end": 569.88, "text": " lots of codes and descriptions, and you've got tight coupling. Nobody is going to question", "tokens": [51124, 3195, 295, 14211, 293, 24406, 11, 293, 291, 600, 658, 4524, 37447, 13, 9297, 307, 516, 281, 1168, 51480], "temperature": 0.0, "avg_logprob": -0.10591447194417318, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.002713934751227498}, {"id": 92, "seek": 56988, "start": 570.76, "end": 577.8, "text": " whether you have accurately reflected your data, but your data is not saying anything at this point.", "tokens": [50408, 1968, 291, 362, 20095, 15502, 428, 1412, 11, 457, 428, 1412, 307, 406, 1566, 1340, 412, 341, 935, 13, 50760], "temperature": 0.0, "avg_logprob": -0.12275510291530661, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.003592647612094879}, {"id": 93, "seek": 56988, "start": 578.36, "end": 586.76, "text": " It is just not descriptive. So, it doesn't work either. And then the third one, which is a little", "tokens": [50788, 467, 307, 445, 406, 42585, 13, 407, 11, 309, 1177, 380, 589, 2139, 13, 400, 550, 264, 2636, 472, 11, 597, 307, 257, 707, 51208], "temperature": 0.0, "avg_logprob": -0.12275510291530661, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.003592647612094879}, {"id": 94, "seek": 56988, "start": 586.76, "end": 595.56, "text": " bit more difficult to understand, my diagram isn't great. It's when you impose theory on your data.", "tokens": [51208, 857, 544, 2252, 281, 1223, 11, 452, 10686, 1943, 380, 869, 13, 467, 311, 562, 291, 26952, 5261, 322, 428, 1412, 13, 51648], "temperature": 0.0, "avg_logprob": -0.12275510291530661, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.003592647612094879}, {"id": 95, "seek": 59556, "start": 596.52, "end": 605.8, "text": " So, you see some theory that you think might be relevant to your case. You draw a wonderful conceptual", "tokens": [50412, 407, 11, 291, 536, 512, 5261, 300, 291, 519, 1062, 312, 7340, 281, 428, 1389, 13, 509, 2642, 257, 3715, 24106, 50876], "temperature": 0.0, "avg_logprob": -0.09273457789159083, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0007095116889104247}, {"id": 96, "seek": 59556, "start": 605.8, "end": 611.2399999999999, "text": " framework beforehand, which is showing all the relationships that you think are going to be", "tokens": [50876, 8388, 22893, 11, 597, 307, 4099, 439, 264, 6159, 300, 291, 519, 366, 516, 281, 312, 51148], "temperature": 0.0, "avg_logprob": -0.09273457789159083, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0007095116889104247}, {"id": 97, "seek": 59556, "start": 611.2399999999999, "end": 616.76, "text": " there before you do your study. And then lo and behold, when you do your study, you take the", "tokens": [51148, 456, 949, 291, 360, 428, 2979, 13, 400, 550, 450, 293, 27234, 11, 562, 291, 360, 428, 2979, 11, 291, 747, 264, 51424], "temperature": 0.0, "avg_logprob": -0.09273457789159083, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0007095116889104247}, {"id": 98, "seek": 59556, "start": 616.76, "end": 625.3199999999999, "text": " concepts that are in your conceptual framework, impose them on your data, and you say, oh, look,", "tokens": [51424, 10392, 300, 366, 294, 428, 24106, 8388, 11, 26952, 552, 322, 428, 1412, 11, 293, 291, 584, 11, 1954, 11, 574, 11, 51852], "temperature": 0.0, "avg_logprob": -0.09273457789159083, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0007095116889104247}, {"id": 99, "seek": 62532, "start": 625.32, "end": 633.6400000000001, "text": " I thought I would get this. Look, I got exactly what I thought. And what you've done there is you've", "tokens": [50364, 286, 1194, 286, 576, 483, 341, 13, 2053, 11, 286, 658, 2293, 437, 286, 1194, 13, 400, 437, 291, 600, 1096, 456, 307, 291, 600, 50780], "temperature": 0.0, "avg_logprob": -0.09306367572985197, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0009088041842915118}, {"id": 100, "seek": 62532, "start": 633.6400000000001, "end": 640.44, "text": " squeezed the richness out of the data. You've squeezed out everything that could give you new.", "tokens": [50780, 39470, 264, 44506, 484, 295, 264, 1412, 13, 509, 600, 39470, 484, 1203, 300, 727, 976, 291, 777, 13, 51120], "temperature": 0.0, "avg_logprob": -0.09306367572985197, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0009088041842915118}, {"id": 101, "seek": 62532, "start": 640.44, "end": 645.5600000000001, "text": " So, I call this circular coupling. And it's actually quite a common problem.", "tokens": [51120, 407, 11, 286, 818, 341, 16476, 37447, 13, 400, 309, 311, 767, 1596, 257, 2689, 1154, 13, 51376], "temperature": 0.0, "avg_logprob": -0.09306367572985197, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0009088041842915118}, {"id": 102, "seek": 62532, "start": 648.0400000000001, "end": 653.0, "text": " And I've seen it myself, and I got trapped in it myself. And the reason one gets trapped in it is", "tokens": [51500, 400, 286, 600, 1612, 309, 2059, 11, 293, 286, 658, 14994, 294, 309, 2059, 13, 400, 264, 1778, 472, 2170, 14994, 294, 309, 307, 51748], "temperature": 0.0, "avg_logprob": -0.09306367572985197, "compression_ratio": 1.6894977168949772, "no_speech_prob": 0.0009088041842915118}, {"id": 103, "seek": 65300, "start": 653.0, "end": 661.72, "text": " because thesis advisors naturally want students to look as if they know what they're doing before", "tokens": [50364, 570, 22288, 29136, 8195, 528, 1731, 281, 574, 382, 498, 436, 458, 437, 436, 434, 884, 949, 50800], "temperature": 0.0, "avg_logprob": -0.06238859155204859, "compression_ratio": 1.70995670995671, "no_speech_prob": 8.477435039822012e-05}, {"id": 104, "seek": 65300, "start": 661.72, "end": 667.56, "text": " they do their study. So, in their proposal, there will be this complex theoretical framework. And", "tokens": [50800, 436, 360, 641, 2979, 13, 407, 11, 294, 641, 11494, 11, 456, 486, 312, 341, 3997, 20864, 8388, 13, 400, 51092], "temperature": 0.0, "avg_logprob": -0.06238859155204859, "compression_ratio": 1.70995670995671, "no_speech_prob": 8.477435039822012e-05}, {"id": 105, "seek": 65300, "start": 667.56, "end": 674.12, "text": " that becomes the thing that drives the research. And if it drives the research too much, you already", "tokens": [51092, 300, 3643, 264, 551, 300, 11754, 264, 2132, 13, 400, 498, 309, 11754, 264, 2132, 886, 709, 11, 291, 1217, 51420], "temperature": 0.0, "avg_logprob": -0.06238859155204859, "compression_ratio": 1.70995670995671, "no_speech_prob": 8.477435039822012e-05}, {"id": 106, "seek": 65300, "start": 674.12, "end": 680.44, "text": " end up with what you started with. And that will not make a strong contribution. So, those are the", "tokens": [51420, 917, 493, 365, 437, 291, 1409, 365, 13, 400, 300, 486, 406, 652, 257, 2068, 13150, 13, 407, 11, 729, 366, 264, 51736], "temperature": 0.0, "avg_logprob": -0.06238859155204859, "compression_ratio": 1.70995670995671, "no_speech_prob": 8.477435039822012e-05}, {"id": 107, "seek": 68044, "start": 680.5200000000001, "end": 690.6800000000001, "text": " different problems that might arise. And we're now going to talk about some of the ways that we might", "tokens": [50368, 819, 2740, 300, 1062, 20288, 13, 400, 321, 434, 586, 516, 281, 751, 466, 512, 295, 264, 2098, 300, 321, 1062, 50876], "temperature": 0.0, "avg_logprob": -0.10819335967775374, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0006459177820943296}, {"id": 108, "seek": 68044, "start": 690.6800000000001, "end": 696.6800000000001, "text": " try and do something that would lead us to the first diagram, which is", "tokens": [50876, 853, 293, 360, 746, 300, 576, 1477, 505, 281, 264, 700, 10686, 11, 597, 307, 51176], "temperature": 0.0, "avg_logprob": -0.10819335967775374, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0006459177820943296}, {"id": 109, "seek": 68044, "start": 698.7600000000001, "end": 708.0400000000001, "text": " concrete, rich, messy data, abstract and novel theory, and credible but creative coupling, which", "tokens": [51280, 9859, 11, 4593, 11, 16191, 1412, 11, 12649, 293, 7613, 5261, 11, 293, 32757, 457, 5880, 37447, 11, 597, 51744], "temperature": 0.0, "avg_logprob": -0.10819335967775374, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0006459177820943296}, {"id": 110, "seek": 70804, "start": 708.04, "end": 717.9599999999999, "text": " is kind of what we're trying to achieve. So, in order to talk about this, I'm going to rely a", "tokens": [50364, 307, 733, 295, 437, 321, 434, 1382, 281, 4584, 13, 407, 11, 294, 1668, 281, 751, 466, 341, 11, 286, 478, 516, 281, 10687, 257, 50860], "temperature": 0.0, "avg_logprob": -0.1326753770982897, "compression_ratio": 1.4213197969543148, "no_speech_prob": 0.0006978990859352052}, {"id": 111, "seek": 70804, "start": 717.9599999999999, "end": 725.0799999999999, "text": " lot on a paper which some of you may have read, which is my 1999 piece, which is a published", "tokens": [50860, 688, 322, 257, 3035, 597, 512, 295, 291, 815, 362, 1401, 11, 597, 307, 452, 19952, 2522, 11, 597, 307, 257, 6572, 51216], "temperature": 0.0, "avg_logprob": -0.1326753770982897, "compression_ratio": 1.4213197969543148, "no_speech_prob": 0.0006978990859352052}, {"id": 112, "seek": 70804, "start": 725.0799999999999, "end": 731.3199999999999, "text": " in the Academy of Management Review, which was titled, Strategies for Theorizing from Process", "tokens": [51216, 294, 264, 11735, 295, 14781, 19954, 11, 597, 390, 19841, 11, 30064, 530, 337, 440, 284, 3319, 490, 31093, 51528], "temperature": 0.0, "avg_logprob": -0.1326753770982897, "compression_ratio": 1.4213197969543148, "no_speech_prob": 0.0006978990859352052}, {"id": 113, "seek": 73132, "start": 731.32, "end": 742.6, "text": " Data. It's now about 24 years later. Some things have changed, but I still think that", "tokens": [50364, 11888, 13, 467, 311, 586, 466, 4022, 924, 1780, 13, 2188, 721, 362, 3105, 11, 457, 286, 920, 519, 300, 50928], "temperature": 0.0, "avg_logprob": -0.10608003450476605, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004753174260258675}, {"id": 114, "seek": 73132, "start": 742.6, "end": 748.9200000000001, "text": " those ideas have value. And so, I'm going to start from those ideas and give you some thoughts about", "tokens": [50928, 729, 3487, 362, 2158, 13, 400, 370, 11, 286, 478, 516, 281, 722, 490, 729, 3487, 293, 976, 291, 512, 4598, 466, 51244], "temperature": 0.0, "avg_logprob": -0.10608003450476605, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004753174260258675}, {"id": 115, "seek": 73132, "start": 748.9200000000001, "end": 758.7600000000001, "text": " my more recent ideas around that and experience around trying to use those ideas. And these are a", "tokens": [51244, 452, 544, 5162, 3487, 926, 300, 293, 1752, 926, 1382, 281, 764, 729, 3487, 13, 400, 613, 366, 257, 51736], "temperature": 0.0, "avg_logprob": -0.10608003450476605, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.004753174260258675}, {"id": 116, "seek": 75876, "start": 758.84, "end": 767.24, "text": " set of ideas. And so, I'm going to put them forward. I'm going to point you towards sources", "tokens": [50368, 992, 295, 3487, 13, 400, 370, 11, 286, 478, 516, 281, 829, 552, 2128, 13, 286, 478, 516, 281, 935, 291, 3030, 7139, 50788], "temperature": 0.0, "avg_logprob": -0.08791144053141275, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.002250610152259469}, {"id": 117, "seek": 75876, "start": 767.24, "end": 773.24, "text": " that might help you with some of these ideas about how to do this. I'm not going to give you", "tokens": [50788, 300, 1062, 854, 291, 365, 512, 295, 613, 3487, 466, 577, 281, 360, 341, 13, 286, 478, 406, 516, 281, 976, 291, 51088], "temperature": 0.0, "avg_logprob": -0.08791144053141275, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.002250610152259469}, {"id": 118, "seek": 75876, "start": 773.8, "end": 778.6, "text": " a complete recipe. I'm going to give you these ideas. And these are things you can mix and match", "tokens": [51116, 257, 3566, 6782, 13, 286, 478, 516, 281, 976, 291, 613, 3487, 13, 400, 613, 366, 721, 291, 393, 2890, 293, 2995, 51356], "temperature": 0.0, "avg_logprob": -0.08791144053141275, "compression_ratio": 1.7239263803680982, "no_speech_prob": 0.002250610152259469}, {"id": 119, "seek": 77860, "start": 778.6, "end": 786.6, "text": " and work with. And we'll look on do this now. And I'm going to... Let's see.", "tokens": [50364, 293, 589, 365, 13, 400, 321, 603, 574, 322, 360, 341, 586, 13, 400, 286, 478, 516, 281, 485, 961, 311, 536, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17830448524624692, "compression_ratio": 1.251908396946565, "no_speech_prob": 0.006791790947318077}, {"id": 120, "seek": 77860, "start": 790.0400000000001, "end": 801.0, "text": " Okay. So, this is a list of the items that I included in the 1999 paper, which I called", "tokens": [50936, 1033, 13, 407, 11, 341, 307, 257, 1329, 295, 264, 4754, 300, 286, 5556, 294, 264, 19952, 3035, 11, 597, 286, 1219, 51484], "temperature": 0.0, "avg_logprob": -0.17830448524624692, "compression_ratio": 1.251908396946565, "no_speech_prob": 0.006791790947318077}, {"id": 121, "seek": 80100, "start": 801.08, "end": 809.72, "text": " Strategies for Theorizing from Process Data. And there were seven of them. And so, you can look at", "tokens": [50368, 30064, 530, 337, 440, 284, 3319, 490, 31093, 11888, 13, 400, 456, 645, 3407, 295, 552, 13, 400, 370, 11, 291, 393, 574, 412, 50800], "temperature": 0.0, "avg_logprob": -0.08807342116897171, "compression_ratio": 1.632183908045977, "no_speech_prob": 0.024782566353678703}, {"id": 122, "seek": 80100, "start": 809.72, "end": 817.56, "text": " them and you can sort of group them into three areas. And so, the first two that you see there,", "tokens": [50800, 552, 293, 291, 393, 1333, 295, 1594, 552, 666, 1045, 3179, 13, 400, 370, 11, 264, 700, 732, 300, 291, 536, 456, 11, 51192], "temperature": 0.0, "avg_logprob": -0.08807342116897171, "compression_ratio": 1.632183908045977, "no_speech_prob": 0.024782566353678703}, {"id": 123, "seek": 80100, "start": 818.36, "end": 827.4, "text": " I call them grounding strategies. And they were actually about coding. So, the first one,", "tokens": [51232, 286, 818, 552, 46727, 9029, 13, 400, 436, 645, 767, 466, 17720, 13, 407, 11, 264, 700, 472, 11, 51684], "temperature": 0.0, "avg_logprob": -0.08807342116897171, "compression_ratio": 1.632183908045977, "no_speech_prob": 0.024782566353678703}, {"id": 124, "seek": 82740, "start": 827.4, "end": 833.3199999999999, "text": " grounded theory, is this idea that you're going to start with the data and you're going to build", "tokens": [50364, 23535, 5261, 11, 307, 341, 1558, 300, 291, 434, 516, 281, 722, 365, 264, 1412, 293, 291, 434, 516, 281, 1322, 50660], "temperature": 0.0, "avg_logprob": -0.09404941967555455, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.0023591502103954554}, {"id": 125, "seek": 82740, "start": 833.3199999999999, "end": 841.48, "text": " your theory bottom up from the data. The second one is kind of a different way of looking at it.", "tokens": [50660, 428, 5261, 2767, 493, 490, 264, 1412, 13, 440, 1150, 472, 307, 733, 295, 257, 819, 636, 295, 1237, 412, 309, 13, 51068], "temperature": 0.0, "avg_logprob": -0.09404941967555455, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.0023591502103954554}, {"id": 126, "seek": 82740, "start": 841.48, "end": 849.88, "text": " Instead of building up your theory bottom up, you're going to take a priori known theoretical", "tokens": [51068, 7156, 295, 2390, 493, 428, 5261, 2767, 493, 11, 291, 434, 516, 281, 747, 257, 4059, 72, 2570, 20864, 51488], "temperature": 0.0, "avg_logprob": -0.09404941967555455, "compression_ratio": 1.7607361963190185, "no_speech_prob": 0.0023591502103954554}, {"id": 127, "seek": 84988, "start": 849.88, "end": 858.04, "text": " lenses and fit them to the data top down. And if you do it with more than one, that enables", "tokens": [50364, 18059, 293, 3318, 552, 281, 264, 1412, 1192, 760, 13, 400, 498, 291, 360, 309, 365, 544, 813, 472, 11, 300, 17077, 50772], "temperature": 0.0, "avg_logprob": -0.05681344985961914, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0033759402576833963}, {"id": 128, "seek": 84988, "start": 858.04, "end": 864.28, "text": " you to see which one fits best. So, I see these two as kind of opposites of one another,", "tokens": [50772, 291, 281, 536, 597, 472, 9001, 1151, 13, 407, 11, 286, 536, 613, 732, 382, 733, 295, 4665, 3324, 295, 472, 1071, 11, 51084], "temperature": 0.0, "avg_logprob": -0.05681344985961914, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0033759402576833963}, {"id": 129, "seek": 84988, "start": 865.8, "end": 871.08, "text": " theorizing from the bottom up, theorizing from the top down. And we're going to talk about those", "tokens": [51160, 27423, 3319, 490, 264, 2767, 493, 11, 27423, 3319, 490, 264, 1192, 760, 13, 400, 321, 434, 516, 281, 751, 466, 729, 51424], "temperature": 0.0, "avg_logprob": -0.05681344985961914, "compression_ratio": 1.6011560693641618, "no_speech_prob": 0.0033759402576833963}, {"id": 130, "seek": 87108, "start": 871.08, "end": 881.88, "text": " first. The second two, I see as ways of displaying data. So, you can display data either as a story,", "tokens": [50364, 700, 13, 440, 1150, 732, 11, 286, 536, 382, 2098, 295, 36834, 1412, 13, 407, 11, 291, 393, 4674, 1412, 2139, 382, 257, 1657, 11, 50904], "temperature": 0.0, "avg_logprob": -0.08886388830236487, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0030270935967564583}, {"id": 131, "seek": 87108, "start": 882.44, "end": 887.72, "text": " as a narrative, you can construct a narrative from your data, or you can try to draw them", "tokens": [50932, 382, 257, 9977, 11, 291, 393, 7690, 257, 9977, 490, 428, 1412, 11, 420, 291, 393, 853, 281, 2642, 552, 51196], "temperature": 0.0, "avg_logprob": -0.08886388830236487, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0030270935967564583}, {"id": 132, "seek": 87108, "start": 889.48, "end": 894.9200000000001, "text": " using visual mapping. So, I see those two as kind of opposites of one another as well.", "tokens": [51284, 1228, 5056, 18350, 13, 407, 11, 286, 536, 729, 732, 382, 733, 295, 4665, 3324, 295, 472, 1071, 382, 731, 13, 51556], "temperature": 0.0, "avg_logprob": -0.08886388830236487, "compression_ratio": 1.6390532544378698, "no_speech_prob": 0.0030270935967564583}, {"id": 133, "seek": 89492, "start": 895.8, "end": 907.0, "text": " And then the last three are all about comparing data. And for me, comparing is really the essence of", "tokens": [50408, 400, 550, 264, 1036, 1045, 366, 439, 466, 15763, 1412, 13, 400, 337, 385, 11, 15763, 307, 534, 264, 12801, 295, 50968], "temperature": 0.0, "avg_logprob": -0.09441912046042822, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0003740275278687477}, {"id": 134, "seek": 89492, "start": 907.0, "end": 912.36, "text": " this thing that drives, for me, it drives theorizing. When you're comparing two things,", "tokens": [50968, 341, 551, 300, 11754, 11, 337, 385, 11, 309, 11754, 27423, 3319, 13, 1133, 291, 434, 15763, 732, 721, 11, 51236], "temperature": 0.0, "avg_logprob": -0.09441912046042822, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0003740275278687477}, {"id": 135, "seek": 89492, "start": 912.36, "end": 916.28, "text": " you immediately ask yourself, why are they different? Why are they similar? What is it that", "tokens": [51236, 291, 4258, 1029, 1803, 11, 983, 366, 436, 819, 30, 1545, 366, 436, 2531, 30, 708, 307, 309, 300, 51432], "temperature": 0.0, "avg_logprob": -0.09441912046042822, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0003740275278687477}, {"id": 136, "seek": 89492, "start": 916.28, "end": 923.56, "text": " explains that? So, as soon as you start to compare, it really is a great stimulus for theorizing.", "tokens": [51432, 13948, 300, 30, 407, 11, 382, 2321, 382, 291, 722, 281, 6794, 11, 309, 534, 307, 257, 869, 21366, 337, 27423, 3319, 13, 51796], "temperature": 0.0, "avg_logprob": -0.09441912046042822, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0003740275278687477}, {"id": 137, "seek": 92356, "start": 923.56, "end": 928.68, "text": " And I introduce here three different ways to compare. So, comparing cases, comparing", "tokens": [50364, 400, 286, 5366, 510, 1045, 819, 2098, 281, 6794, 13, 407, 11, 15763, 3331, 11, 15763, 50620], "temperature": 0.0, "avg_logprob": -0.1694630283420369, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0002570610959082842}, {"id": 138, "seek": 92356, "start": 929.56, "end": 935.4799999999999, "text": " this notion of temporal decomposition or temporal bracketing, which is comparing phases,", "tokens": [50664, 341, 10710, 295, 30881, 48356, 420, 30881, 12305, 9880, 11, 597, 307, 15763, 18764, 11, 50960], "temperature": 0.0, "avg_logprob": -0.1694630283420369, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0002570610959082842}, {"id": 139, "seek": 92356, "start": 936.1199999999999, "end": 942.5999999999999, "text": " and the last one, quantifying. And so, that's the kind of portrait of these seven", "tokens": [50992, 293, 264, 1036, 472, 11, 4426, 5489, 13, 400, 370, 11, 300, 311, 264, 733, 295, 17126, 295, 613, 3407, 51316], "temperature": 0.0, "avg_logprob": -0.1694630283420369, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0002570610959082842}, {"id": 140, "seek": 94260, "start": 943.16, "end": 957.48, "text": " approaches that you can use to data. And of course, they are not, you don't pick one and then use it.", "tokens": [50392, 11587, 300, 291, 393, 764, 281, 1412, 13, 400, 295, 1164, 11, 436, 366, 406, 11, 291, 500, 380, 1888, 472, 293, 550, 764, 309, 13, 51108], "temperature": 0.0, "avg_logprob": -0.1596331209749789, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.006001385394483805}, {"id": 141, "seek": 94260, "start": 958.2, "end": 964.36, "text": " All right? You do all of these things when you are trying to theorize from process", "tokens": [51144, 1057, 558, 30, 509, 360, 439, 295, 613, 721, 562, 291, 366, 1382, 281, 27423, 1125, 490, 1399, 51452], "temperature": 0.0, "avg_logprob": -0.1596331209749789, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.006001385394483805}, {"id": 142, "seek": 94260, "start": 964.36, "end": 969.64, "text": " stage. And it's a very iterative process and you move between them. So, I have this,", "tokens": [51452, 3233, 13, 400, 309, 311, 257, 588, 17138, 1166, 1399, 293, 291, 1286, 1296, 552, 13, 407, 11, 286, 362, 341, 11, 51716], "temperature": 0.0, "avg_logprob": -0.1596331209749789, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.006001385394483805}, {"id": 143, "seek": 96964, "start": 969.64, "end": 976.12, "text": " in my next slide, I have this diagram, which expresses that. So, on the left, you have what", "tokens": [50364, 294, 452, 958, 4137, 11, 286, 362, 341, 10686, 11, 597, 39204, 300, 13, 407, 11, 322, 264, 1411, 11, 291, 362, 437, 50688], "temperature": 0.0, "avg_logprob": -0.09814628641656105, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.002433134475722909}, {"id": 144, "seek": 96964, "start": 976.12, "end": 983.72, "text": " I call the grounding strategies. In the middle, you have the organizing strategies, which are", "tokens": [50688, 286, 818, 264, 46727, 9029, 13, 682, 264, 2808, 11, 291, 362, 264, 17608, 9029, 11, 597, 366, 51068], "temperature": 0.0, "avg_logprob": -0.09814628641656105, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.002433134475722909}, {"id": 145, "seek": 96964, "start": 983.72, "end": 989.16, "text": " useful for displaying. And on the right, you have the comparing strategies. And you can do them in", "tokens": [51068, 4420, 337, 36834, 13, 400, 322, 264, 558, 11, 291, 362, 264, 15763, 9029, 13, 400, 291, 393, 360, 552, 294, 51340], "temperature": 0.0, "avg_logprob": -0.09814628641656105, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.002433134475722909}, {"id": 146, "seek": 96964, "start": 989.16, "end": 997.72, "text": " any order. I put the diagram from left to right, because I think there's a sort of a progression", "tokens": [51340, 604, 1668, 13, 286, 829, 264, 10686, 490, 1411, 281, 558, 11, 570, 286, 519, 456, 311, 257, 1333, 295, 257, 18733, 51768], "temperature": 0.0, "avg_logprob": -0.09814628641656105, "compression_ratio": 1.7239819004524888, "no_speech_prob": 0.002433134475722909}, {"id": 147, "seek": 99772, "start": 997.72, "end": 1005.96, "text": " from coding to displaying to comparing, which I'm going to put coding, displaying, and comparing.", "tokens": [50364, 490, 17720, 281, 36834, 281, 15763, 11, 597, 286, 478, 516, 281, 829, 17720, 11, 36834, 11, 293, 15763, 13, 50776], "temperature": 0.0, "avg_logprob": -0.16499370847429548, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.00020023583783768117}, {"id": 148, "seek": 99772, "start": 1005.96, "end": 1010.6, "text": " I think there's a progression. But that doesn't mean you might start at a different place.", "tokens": [50776, 286, 519, 456, 311, 257, 18733, 13, 583, 300, 1177, 380, 914, 291, 1062, 722, 412, 257, 819, 1081, 13, 51008], "temperature": 0.0, "avg_logprob": -0.16499370847429548, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.00020023583783768117}, {"id": 149, "seek": 99772, "start": 1011.5600000000001, "end": 1021.8000000000001, "text": " Okay. So, let's start with coding. And so, I'm going to talk a little bit about", "tokens": [51056, 1033, 13, 407, 11, 718, 311, 722, 365, 17720, 13, 400, 370, 11, 286, 478, 516, 281, 751, 257, 707, 857, 466, 51568], "temperature": 0.0, "avg_logprob": -0.16499370847429548, "compression_ratio": 1.5491329479768785, "no_speech_prob": 0.00020023583783768117}, {"id": 150, "seek": 102180, "start": 1022.76, "end": 1031.8799999999999, "text": " coding process data. And then we'll stop and take some questions and have some conversations.", "tokens": [50412, 17720, 1399, 1412, 13, 400, 550, 321, 603, 1590, 293, 747, 512, 1651, 293, 362, 512, 7315, 13, 50868], "temperature": 0.0, "avg_logprob": -0.09575405574980236, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.0017267324728891253}, {"id": 151, "seek": 102180, "start": 1032.84, "end": 1038.52, "text": " And then I'll talk about the other two after that. So, let's start with coding.", "tokens": [50916, 400, 550, 286, 603, 751, 466, 264, 661, 732, 934, 300, 13, 407, 11, 718, 311, 722, 365, 17720, 13, 51200], "temperature": 0.0, "avg_logprob": -0.09575405574980236, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.0017267324728891253}, {"id": 152, "seek": 102180, "start": 1042.28, "end": 1049.1599999999999, "text": " So, there are these two strategies that I mentioned, grounded theory and alternate templates.", "tokens": [51388, 407, 11, 456, 366, 613, 732, 9029, 300, 286, 2835, 11, 23535, 5261, 293, 18873, 21165, 13, 51732], "temperature": 0.0, "avg_logprob": -0.09575405574980236, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.0017267324728891253}, {"id": 153, "seek": 104916, "start": 1049.16, "end": 1057.4, "text": " The grounded theory idea is from the bottom up. And alternate templates is taking the top down,", "tokens": [50364, 440, 23535, 5261, 1558, 307, 490, 264, 2767, 493, 13, 400, 18873, 21165, 307, 1940, 264, 1192, 760, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1288206312391493, "compression_ratio": 1.7030303030303031, "no_speech_prob": 0.0003352975763846189}, {"id": 154, "seek": 104916, "start": 1057.4, "end": 1064.1200000000001, "text": " where theory is at top, and data at the bottom. Okay. So, let's look at grounded theory first.", "tokens": [50776, 689, 5261, 307, 412, 1192, 11, 293, 1412, 412, 264, 2767, 13, 1033, 13, 407, 11, 718, 311, 574, 412, 23535, 5261, 700, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1288206312391493, "compression_ratio": 1.7030303030303031, "no_speech_prob": 0.0003352975763846189}, {"id": 155, "seek": 104916, "start": 1064.68, "end": 1072.6000000000001, "text": " So, grounded theory means building from the bottom up. So, you have no a priori framework.", "tokens": [51140, 407, 11, 23535, 5261, 1355, 2390, 490, 264, 2767, 493, 13, 407, 11, 291, 362, 572, 257, 4059, 72, 8388, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1288206312391493, "compression_ratio": 1.7030303030303031, "no_speech_prob": 0.0003352975763846189}, {"id": 156, "seek": 107260, "start": 1073.24, "end": 1079.9599999999998, "text": " And there are some classic authors that have talked about that. So, Corbin and Strauss,", "tokens": [50396, 400, 456, 366, 512, 7230, 16552, 300, 362, 2825, 466, 300, 13, 407, 11, 3925, 13496, 293, 12875, 2023, 11, 50732], "temperature": 0.0, "avg_logprob": -0.28898753438677105, "compression_ratio": 1.3742331288343559, "no_speech_prob": 0.001263630110770464}, {"id": 157, "seek": 107260, "start": 1080.6799999999998, "end": 1087.0, "text": " Charmas, and more recently, Denny Joyer and colleagues,", "tokens": [50768, 4327, 3799, 11, 293, 544, 3938, 11, 6458, 1634, 15571, 260, 293, 7734, 11, 51084], "temperature": 0.0, "avg_logprob": -0.28898753438677105, "compression_ratio": 1.3742331288343559, "no_speech_prob": 0.001263630110770464}, {"id": 158, "seek": 107260, "start": 1089.0, "end": 1096.76, "text": " Emma Hamilton, and Kevin Corley have this organizational research methods piece,", "tokens": [51184, 17124, 18484, 11, 293, 9954, 3925, 3420, 362, 341, 24730, 2132, 7150, 2522, 11, 51572], "temperature": 0.0, "avg_logprob": -0.28898753438677105, "compression_ratio": 1.3742331288343559, "no_speech_prob": 0.001263630110770464}, {"id": 159, "seek": 109676, "start": 1096.76, "end": 1101.4, "text": " which explains how to do grounded theory. And it's become really dominant", "tokens": [50364, 597, 13948, 577, 281, 360, 23535, 5261, 13, 400, 309, 311, 1813, 534, 15657, 50596], "temperature": 0.0, "avg_logprob": -0.09700252698815387, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.00999454315751791}, {"id": 160, "seek": 109676, "start": 1102.2, "end": 1106.28, "text": " in the field of qualitative research. And I'm an editor at the Academy of Management Journal.", "tokens": [50636, 294, 264, 2519, 295, 31312, 2132, 13, 400, 286, 478, 364, 9839, 412, 264, 11735, 295, 14781, 16936, 13, 50840], "temperature": 0.0, "avg_logprob": -0.09700252698815387, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.00999454315751791}, {"id": 161, "seek": 109676, "start": 1106.28, "end": 1114.28, "text": " And I see that, you know, one, I am an editor for all the qualitative papers. And I would say that", "tokens": [50840, 400, 286, 536, 300, 11, 291, 458, 11, 472, 11, 286, 669, 364, 9839, 337, 439, 264, 31312, 10577, 13, 400, 286, 576, 584, 300, 51240], "temperature": 0.0, "avg_logprob": -0.09700252698815387, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.00999454315751791}, {"id": 162, "seek": 109676, "start": 1114.28, "end": 1122.44, "text": " one paper out of two has one of Denny Joyer's diagrams. And I just want to say, before I", "tokens": [51240, 472, 3035, 484, 295, 732, 575, 472, 295, 6458, 1634, 15571, 260, 311, 36709, 13, 400, 286, 445, 528, 281, 584, 11, 949, 286, 51648], "temperature": 0.0, "avg_logprob": -0.09700252698815387, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.00999454315751791}, {"id": 163, "seek": 112244, "start": 1122.44, "end": 1127.64, "text": " start talking about that, that that is not absolutely required to publish a paper.", "tokens": [50364, 722, 1417, 466, 300, 11, 300, 300, 307, 406, 3122, 4739, 281, 11374, 257, 3035, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1620686584048801, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.005638368893414736}, {"id": 164, "seek": 112244, "start": 1128.68, "end": 1136.3600000000001, "text": " But it is a very common approach, and it has all kinds of benefits. And grounded theory,", "tokens": [50676, 583, 309, 307, 257, 588, 2689, 3109, 11, 293, 309, 575, 439, 3685, 295, 5311, 13, 400, 23535, 5261, 11, 51060], "temperature": 0.0, "avg_logprob": -0.1620686584048801, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.005638368893414736}, {"id": 165, "seek": 112244, "start": 1137.3200000000002, "end": 1146.2, "text": " the tools like Atlas, TI, NPVO, MaxQDA, etc., are great for managing your coding. They don't do it", "tokens": [51108, 264, 3873, 411, 32485, 11, 28819, 11, 38611, 20664, 11, 7402, 48, 7509, 11, 5183, 7933, 366, 869, 337, 11642, 428, 17720, 13, 814, 500, 380, 360, 309, 51552], "temperature": 0.0, "avg_logprob": -0.1620686584048801, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.005638368893414736}, {"id": 166, "seek": 114620, "start": 1146.2, "end": 1156.3600000000001, "text": " for you, but they manage it. I haven't yet got into chat GPT. And maybe there are some", "tokens": [50364, 337, 291, 11, 457, 436, 3067, 309, 13, 286, 2378, 380, 1939, 658, 666, 5081, 26039, 51, 13, 400, 1310, 456, 366, 512, 50872], "temperature": 0.0, "avg_logprob": -0.10592142740885417, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.010317284613847733}, {"id": 167, "seek": 114620, "start": 1156.3600000000001, "end": 1164.44, "text": " opportunities there to see what chat GPT can do for you in terms of coding. That's the kind of", "tokens": [50872, 4786, 456, 281, 536, 437, 5081, 26039, 51, 393, 360, 337, 291, 294, 2115, 295, 17720, 13, 663, 311, 264, 733, 295, 51276], "temperature": 0.0, "avg_logprob": -0.10592142740885417, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.010317284613847733}, {"id": 168, "seek": 114620, "start": 1164.44, "end": 1169.72, "text": " life on the front there. And I think there are people who have already started looking at that.", "tokens": [51276, 993, 322, 264, 1868, 456, 13, 400, 286, 519, 456, 366, 561, 567, 362, 1217, 1409, 1237, 412, 300, 13, 51540], "temperature": 0.0, "avg_logprob": -0.10592142740885417, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.010317284613847733}, {"id": 169, "seek": 114620, "start": 1169.72, "end": 1175.64, "text": " I'm not looking at that here. So that might be an issue that we might want to get to.", "tokens": [51540, 286, 478, 406, 1237, 412, 300, 510, 13, 407, 300, 1062, 312, 364, 2734, 300, 321, 1062, 528, 281, 483, 281, 13, 51836], "temperature": 0.0, "avg_logprob": -0.10592142740885417, "compression_ratio": 1.672811059907834, "no_speech_prob": 0.010317284613847733}, {"id": 170, "seek": 117620, "start": 1176.6000000000001, "end": 1184.76, "text": " So I'm going to talk a little bit about the Joyer method. For those of you who haven't", "tokens": [50384, 407, 286, 478, 516, 281, 751, 257, 707, 857, 466, 264, 15571, 260, 3170, 13, 1171, 729, 295, 291, 567, 2378, 380, 50792], "temperature": 0.0, "avg_logprob": -0.12510709329084915, "compression_ratio": 1.26890756302521, "no_speech_prob": 0.0005027290899306536}, {"id": 171, "seek": 117620, "start": 1188.76, "end": 1193.56, "text": " seen it before, so that we can see what this method is about. So", "tokens": [50992, 1612, 309, 949, 11, 370, 300, 321, 393, 536, 437, 341, 3170, 307, 466, 13, 407, 51232], "temperature": 0.0, "avg_logprob": -0.12510709329084915, "compression_ratio": 1.26890756302521, "no_speech_prob": 0.0005027290899306536}, {"id": 172, "seek": 119356, "start": 1193.8799999999999, "end": 1207.24, "text": " a really great example of the Joyer method is the 2004 paper by Corleone Joyer on identity", "tokens": [50380, 257, 534, 869, 1365, 295, 264, 15571, 260, 3170, 307, 264, 15817, 3035, 538, 3925, 306, 546, 15571, 260, 322, 6575, 51048], "temperature": 0.0, "avg_logprob": -0.16263535443474264, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0007431893609464169}, {"id": 173, "seek": 119356, "start": 1207.24, "end": 1214.2, "text": " ambiguity in administrative science quarterly. And I use this as an exemplar of the type of", "tokens": [51048, 46519, 294, 17900, 3497, 38633, 13, 400, 286, 764, 341, 382, 364, 24112, 289, 295, 264, 2010, 295, 51396], "temperature": 0.0, "avg_logprob": -0.16263535443474264, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0007431893609464169}, {"id": 174, "seek": 119356, "start": 1214.2, "end": 1222.6799999999998, "text": " bottom-up coding that dominates a lot of process research, as well as any other qualitative research.", "tokens": [51396, 2767, 12, 1010, 17720, 300, 8859, 1024, 257, 688, 295, 1399, 2132, 11, 382, 731, 382, 604, 661, 31312, 2132, 13, 51820], "temperature": 0.0, "avg_logprob": -0.16263535443474264, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.0007431893609464169}, {"id": 175, "seek": 122268, "start": 1222.76, "end": 1233.5600000000002, "text": " So this method involves three types of artifacts. And the most famous one is this one.", "tokens": [50368, 407, 341, 3170, 11626, 1045, 3467, 295, 24617, 13, 400, 264, 881, 4618, 472, 307, 341, 472, 13, 50908], "temperature": 0.0, "avg_logprob": -0.09081657197740343, "compression_ratio": 1.3515625, "no_speech_prob": 0.00044402197818271816}, {"id": 176, "seek": 122268, "start": 1235.8, "end": 1247.16, "text": " And this is a coding approach, which is so elegant. What you can see here on the left,", "tokens": [51020, 400, 341, 307, 257, 17720, 3109, 11, 597, 307, 370, 21117, 13, 708, 291, 393, 536, 510, 322, 264, 1411, 11, 51588], "temperature": 0.0, "avg_logprob": -0.09081657197740343, "compression_ratio": 1.3515625, "no_speech_prob": 0.00044402197818271816}, {"id": 177, "seek": 124716, "start": 1247.16, "end": 1259.4, "text": " the first-order concept, is how a researcher takes their original data and looks at the data in Vivo", "tokens": [50364, 264, 700, 12, 4687, 3410, 11, 307, 577, 257, 21751, 2516, 641, 3380, 1412, 293, 1542, 412, 264, 1412, 294, 691, 6340, 50976], "temperature": 0.0, "avg_logprob": -0.11182411193847656, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.004330176394432783}, {"id": 178, "seek": 124716, "start": 1259.4, "end": 1266.68, "text": " and codes it into the first category. So there may be lots and lots of first-order codes.", "tokens": [50976, 293, 14211, 309, 666, 264, 700, 7719, 13, 407, 456, 815, 312, 3195, 293, 3195, 295, 700, 12, 4687, 14211, 13, 51340], "temperature": 0.0, "avg_logprob": -0.11182411193847656, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.004330176394432783}, {"id": 179, "seek": 124716, "start": 1266.68, "end": 1272.92, "text": " You're going to have hundreds of them. You start doing that. You start coding bottom-up in Vivo.", "tokens": [51340, 509, 434, 516, 281, 362, 6779, 295, 552, 13, 509, 722, 884, 300, 13, 509, 722, 17720, 2767, 12, 1010, 294, 691, 6340, 13, 51652], "temperature": 0.0, "avg_logprob": -0.11182411193847656, "compression_ratio": 1.6494252873563218, "no_speech_prob": 0.004330176394432783}, {"id": 180, "seek": 127292, "start": 1272.92, "end": 1279.5600000000002, "text": " You end up with far too many codes. But that's okay, because then you group them.", "tokens": [50364, 509, 917, 493, 365, 1400, 886, 867, 14211, 13, 583, 300, 311, 1392, 11, 570, 550, 291, 1594, 552, 13, 50696], "temperature": 0.0, "avg_logprob": -0.10029662648836772, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0021481839939951897}, {"id": 181, "seek": 127292, "start": 1280.3600000000001, "end": 1285.3200000000002, "text": " And so you come to the second-order things. And so they look at the similarities and differences.", "tokens": [50736, 400, 370, 291, 808, 281, 264, 1150, 12, 4687, 721, 13, 400, 370, 436, 574, 412, 264, 24197, 293, 7300, 13, 50984], "temperature": 0.0, "avg_logprob": -0.10029662648836772, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0021481839939951897}, {"id": 182, "seek": 127292, "start": 1285.3200000000002, "end": 1290.6000000000001, "text": " You put them together. You group them. And then you do that the third time. And you can do it", "tokens": [50984, 509, 829, 552, 1214, 13, 509, 1594, 552, 13, 400, 550, 291, 360, 300, 264, 2636, 565, 13, 400, 291, 393, 360, 309, 51248], "temperature": 0.0, "avg_logprob": -0.10029662648836772, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0021481839939951897}, {"id": 183, "seek": 127292, "start": 1290.6000000000001, "end": 1295.64, "text": " the fourth time. You can do this any number of times you like. And what you have on the right", "tokens": [51248, 264, 6409, 565, 13, 509, 393, 360, 341, 604, 1230, 295, 1413, 291, 411, 13, 400, 437, 291, 362, 322, 264, 558, 51500], "temperature": 0.0, "avg_logprob": -0.10029662648836772, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0021481839939951897}, {"id": 184, "seek": 129564, "start": 1295.64, "end": 1302.2800000000002, "text": " then is some key concepts that are going to become the essence of your theory. And so the", "tokens": [50364, 550, 307, 512, 2141, 10392, 300, 366, 516, 281, 1813, 264, 12801, 295, 428, 5261, 13, 400, 370, 264, 50696], "temperature": 0.0, "avg_logprob": -0.07251440076267018, "compression_ratio": 1.6, "no_speech_prob": 0.002395415911450982}, {"id": 185, "seek": 129564, "start": 1302.2800000000002, "end": 1312.2, "text": " brilliance of this is it shows you exactly how you move, in theory, from your original messy,", "tokens": [50696, 8695, 6276, 295, 341, 307, 309, 3110, 291, 2293, 577, 291, 1286, 11, 294, 5261, 11, 490, 428, 3380, 16191, 11, 51192], "temperature": 0.0, "avg_logprob": -0.07251440076267018, "compression_ratio": 1.6, "no_speech_prob": 0.002395415911450982}, {"id": 186, "seek": 129564, "start": 1312.2, "end": 1319.88, "text": " concrete data to some abstract concepts. And it shows the pathway. So that's the first artifact.", "tokens": [51192, 9859, 1412, 281, 512, 12649, 10392, 13, 400, 309, 3110, 264, 18590, 13, 407, 300, 311, 264, 700, 34806, 13, 51576], "temperature": 0.0, "avg_logprob": -0.07251440076267018, "compression_ratio": 1.6, "no_speech_prob": 0.002395415911450982}, {"id": 187, "seek": 131988, "start": 1320.7600000000002, "end": 1327.24, "text": " And unfortunately, a lot of researchers kind of stop there. They show you the data structure and", "tokens": [50408, 400, 7015, 11, 257, 688, 295, 10309, 733, 295, 1590, 456, 13, 814, 855, 291, 264, 1412, 3877, 293, 50732], "temperature": 0.0, "avg_logprob": -0.10798133930689852, "compression_ratio": 1.5, "no_speech_prob": 0.0005975363310426474}, {"id": 188, "seek": 131988, "start": 1327.24, "end": 1340.6000000000001, "text": " that's it. A second artifact is actually showing the link between the two. So here this is in the", "tokens": [50732, 300, 311, 309, 13, 316, 1150, 34806, 307, 767, 4099, 264, 2113, 1296, 264, 732, 13, 407, 510, 341, 307, 294, 264, 51400], "temperature": 0.0, "avg_logprob": -0.10798133930689852, "compression_ratio": 1.5, "no_speech_prob": 0.0005975363310426474}, {"id": 189, "seek": 131988, "start": 1340.6000000000001, "end": 1346.2800000000002, "text": " paper. It's just an example. They've got their concepts. And here you've got quotes that reflect", "tokens": [51400, 3035, 13, 467, 311, 445, 364, 1365, 13, 814, 600, 658, 641, 10392, 13, 400, 510, 291, 600, 658, 19963, 300, 5031, 51684], "temperature": 0.0, "avg_logprob": -0.10798133930689852, "compression_ratio": 1.5, "no_speech_prob": 0.0005975363310426474}, {"id": 190, "seek": 134628, "start": 1346.28, "end": 1352.92, "text": " those concepts. So that's the second artifact. And the third artifact is taking the second order", "tokens": [50364, 729, 10392, 13, 407, 300, 311, 264, 1150, 34806, 13, 400, 264, 2636, 34806, 307, 1940, 264, 1150, 1668, 50696], "temperature": 0.0, "avg_logprob": -0.1027822494506836, "compression_ratio": 1.7218934911242603, "no_speech_prob": 0.000597518403083086}, {"id": 191, "seek": 134628, "start": 1352.92, "end": 1360.36, "text": " and themes and the third order, the overarching dimensions and creating a process model with them.", "tokens": [50696, 293, 13544, 293, 264, 2636, 1668, 11, 264, 45501, 12819, 293, 4084, 257, 1399, 2316, 365, 552, 13, 51068], "temperature": 0.0, "avg_logprob": -0.1027822494506836, "compression_ratio": 1.7218934911242603, "no_speech_prob": 0.000597518403083086}, {"id": 192, "seek": 134628, "start": 1360.36, "end": 1368.68, "text": " So they didn't see the flow between all of the concepts in the paper. And there you can see how", "tokens": [51068, 407, 436, 994, 380, 536, 264, 3095, 1296, 439, 295, 264, 10392, 294, 264, 3035, 13, 400, 456, 291, 393, 536, 577, 51484], "temperature": 0.0, "avg_logprob": -0.1027822494506836, "compression_ratio": 1.7218934911242603, "no_speech_prob": 0.000597518403083086}, {"id": 193, "seek": 136868, "start": 1368.92, "end": 1375.72, "text": " Pauli and Joya have brilliantly started with a database of just a mess. They had observations,", "tokens": [50376, 4552, 72, 293, 15571, 64, 362, 8695, 42580, 1409, 365, 257, 8149, 295, 445, 257, 2082, 13, 814, 632, 18163, 11, 50716], "temperature": 0.0, "avg_logprob": -0.21244761708018545, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0005356718902476132}, {"id": 194, "seek": 136868, "start": 1375.72, "end": 1381.3200000000002, "text": " they had documents, they had interviews, and they generated these concepts. And here is the", "tokens": [50716, 436, 632, 8512, 11, 436, 632, 12318, 11, 293, 436, 10833, 613, 10392, 13, 400, 510, 307, 264, 50996], "temperature": 0.0, "avg_logprob": -0.21244761708018545, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0005356718902476132}, {"id": 195, "seek": 136868, "start": 1381.3200000000002, "end": 1388.68, "text": " theoretical model at the end. So this looks wonderful, right? What you don't see in the paper,", "tokens": [50996, 20864, 2316, 412, 264, 917, 13, 407, 341, 1542, 3715, 11, 558, 30, 708, 291, 500, 380, 536, 294, 264, 3035, 11, 51364], "temperature": 0.0, "avg_logprob": -0.21244761708018545, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0005356718902476132}, {"id": 196, "seek": 136868, "start": 1388.68, "end": 1397.72, "text": " of course, is all of the back and forth that they must have had to do to get the", "tokens": [51364, 295, 1164, 11, 307, 439, 295, 264, 646, 293, 5220, 300, 436, 1633, 362, 632, 281, 360, 281, 483, 264, 51816], "temperature": 0.0, "avg_logprob": -0.21244761708018545, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0005356718902476132}, {"id": 197, "seek": 139772, "start": 1398.3600000000001, "end": 1406.04, "text": " to the data structure in the first place. This does not suddenly appear, right? You need to", "tokens": [50396, 281, 264, 1412, 3877, 294, 264, 700, 1081, 13, 639, 775, 406, 5800, 4204, 11, 558, 30, 509, 643, 281, 50780], "temperature": 0.0, "avg_logprob": -0.11291723391588997, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.00012140063336119056}, {"id": 198, "seek": 139772, "start": 1406.04, "end": 1415.16, "text": " know what you're doing. So this is much more complicated than it looks. So looking at this", "tokens": [50780, 458, 437, 291, 434, 884, 13, 407, 341, 307, 709, 544, 6179, 813, 309, 1542, 13, 407, 1237, 412, 341, 51236], "temperature": 0.0, "avg_logprob": -0.11291723391588997, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.00012140063336119056}, {"id": 199, "seek": 139772, "start": 1415.16, "end": 1424.44, "text": " approach, it's really a brilliant approach to show in an in a paper the rigor of your coupling", "tokens": [51236, 3109, 11, 309, 311, 534, 257, 10248, 3109, 281, 855, 294, 364, 294, 257, 3035, 264, 42191, 295, 428, 37447, 51700], "temperature": 0.0, "avg_logprob": -0.11291723391588997, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.00012140063336119056}, {"id": 200, "seek": 142444, "start": 1424.52, "end": 1432.28, "text": " between the data and your theory. One of the things that have been said about it and I share", "tokens": [50368, 1296, 264, 1412, 293, 428, 5261, 13, 1485, 295, 264, 721, 300, 362, 668, 848, 466, 309, 293, 286, 2073, 50756], "temperature": 0.0, "avg_logprob": -0.11957101260914522, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.0005525865126401186}, {"id": 201, "seek": 142444, "start": 1432.28, "end": 1440.3600000000001, "text": " this concern is sometimes if you've got these concepts, you're glossing over, for example,", "tokens": [50756, 341, 3136, 307, 2171, 498, 291, 600, 658, 613, 10392, 11, 291, 434, 19574, 278, 670, 11, 337, 1365, 11, 51160], "temperature": 0.0, "avg_logprob": -0.11957101260914522, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.0005525865126401186}, {"id": 202, "seek": 142444, "start": 1440.3600000000001, "end": 1445.8, "text": " the conversations, the interactions, the interactional details, you have labeled everything", "tokens": [51160, 264, 7315, 11, 264, 13280, 11, 264, 4648, 1966, 4365, 11, 291, 362, 21335, 1203, 51432], "temperature": 0.0, "avg_logprob": -0.11957101260914522, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.0005525865126401186}, {"id": 203, "seek": 142444, "start": 1445.8, "end": 1453.64, "text": " in terms of concepts, and you may be missing the temporality and the dynamics through this process.", "tokens": [51432, 294, 2115, 295, 10392, 11, 293, 291, 815, 312, 5361, 264, 8219, 1860, 293, 264, 15679, 807, 341, 1399, 13, 51824], "temperature": 0.0, "avg_logprob": -0.11957101260914522, "compression_ratio": 1.728110599078341, "no_speech_prob": 0.0005525865126401186}, {"id": 204, "seek": 145364, "start": 1453.64, "end": 1459.96, "text": " So that can be a concern. And you could code differently, though. You could code", "tokens": [50364, 407, 300, 393, 312, 257, 3136, 13, 400, 291, 727, 3089, 7614, 11, 1673, 13, 509, 727, 3089, 50680], "temperature": 0.0, "avg_logprob": -0.11873586716190461, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00019701983546838164}, {"id": 205, "seek": 145364, "start": 1461.8000000000002, "end": 1470.68, "text": " recently in a study, instead of coding things that people said, we coded the interaction.", "tokens": [50772, 3938, 294, 257, 2979, 11, 2602, 295, 17720, 721, 300, 561, 848, 11, 321, 34874, 264, 9285, 13, 51216], "temperature": 0.0, "avg_logprob": -0.11873586716190461, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00019701983546838164}, {"id": 206, "seek": 145364, "start": 1471.3200000000002, "end": 1475.64, "text": " And so there would be different types of interactions. So then you've got some of the", "tokens": [51248, 400, 370, 456, 576, 312, 819, 3467, 295, 13280, 13, 407, 550, 291, 600, 658, 512, 295, 264, 51464], "temperature": 0.0, "avg_logprob": -0.11873586716190461, "compression_ratio": 1.5900621118012421, "no_speech_prob": 0.00019701983546838164}, {"id": 207, "seek": 147564, "start": 1475.64, "end": 1487.5600000000002, "text": " dynamics included in the in the story. So and the other thing is if this is entirely uninformed", "tokens": [50364, 15679, 5556, 294, 264, 294, 264, 1657, 13, 407, 293, 264, 661, 551, 307, 498, 341, 307, 7696, 43456, 22892, 50960], "temperature": 0.0, "avg_logprob": -0.13425276172694875, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0011331374989822507}, {"id": 208, "seek": 147564, "start": 1487.5600000000002, "end": 1494.76, "text": " by any other approach, my concern is that if you're just doing bottom up coding,", "tokens": [50960, 538, 604, 661, 3109, 11, 452, 3136, 307, 300, 498, 291, 434, 445, 884, 2767, 493, 17720, 11, 51320], "temperature": 0.0, "avg_logprob": -0.13425276172694875, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0011331374989822507}, {"id": 209, "seek": 147564, "start": 1495.48, "end": 1504.6000000000001, "text": " just starting from your data, and you think that the theory is going to kind of result from that,", "tokens": [51356, 445, 2891, 490, 428, 1412, 11, 293, 291, 519, 300, 264, 5261, 307, 516, 281, 733, 295, 1874, 490, 300, 11, 51812], "temperature": 0.0, "avg_logprob": -0.13425276172694875, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.0011331374989822507}, {"id": 210, "seek": 150460, "start": 1505.24, "end": 1513.08, "text": " you're going to run into Brian the Blind Alley, too. And Cooley and Joya do not do that because", "tokens": [50396, 291, 434, 516, 281, 1190, 666, 10765, 264, 34126, 1057, 2030, 11, 886, 13, 400, 383, 1986, 3420, 293, 15571, 64, 360, 406, 360, 300, 570, 50788], "temperature": 0.0, "avg_logprob": -0.24245364229444047, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0009836736135184765}, {"id": 211, "seek": 150460, "start": 1513.08, "end": 1521.48, "text": " they are theoretically informed. They're not, they're not starting their study from from total", "tokens": [50788, 436, 366, 29400, 11740, 13, 814, 434, 406, 11, 436, 434, 406, 2891, 641, 2979, 490, 490, 3217, 51208], "temperature": 0.0, "avg_logprob": -0.24245364229444047, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0009836736135184765}, {"id": 212, "seek": 150460, "start": 1521.48, "end": 1529.7199999999998, "text": " scratch, even though so the the idea that grounded theory is from entirely bottom up is not quite", "tokens": [51208, 8459, 11, 754, 1673, 370, 264, 264, 1558, 300, 23535, 5261, 307, 490, 7696, 2767, 493, 307, 406, 1596, 51620], "temperature": 0.0, "avg_logprob": -0.24245364229444047, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.0009836736135184765}, {"id": 213, "seek": 152972, "start": 1529.72, "end": 1538.68, "text": " true. There are always efforts to connect to existing theory, and we should never forget that.", "tokens": [50364, 2074, 13, 821, 366, 1009, 6484, 281, 1745, 281, 6741, 5261, 11, 293, 321, 820, 1128, 2870, 300, 13, 50812], "temperature": 0.0, "avg_logprob": -0.1020663579305013, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.01638229563832283}, {"id": 214, "seek": 152972, "start": 1538.68, "end": 1547.88, "text": " So just doing coding is not going to get you to an interesting bottom up coding is not necessarily", "tokens": [50812, 407, 445, 884, 17720, 307, 406, 516, 281, 483, 291, 281, 364, 1880, 2767, 493, 17720, 307, 406, 4725, 51272], "temperature": 0.0, "avg_logprob": -0.1020663579305013, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.01638229563832283}, {"id": 215, "seek": 152972, "start": 1547.88, "end": 1554.52, "text": " going to get you to an interesting process theory on its own. And it's very iterative,", "tokens": [51272, 516, 281, 483, 291, 281, 364, 1880, 1399, 5261, 322, 1080, 1065, 13, 400, 309, 311, 588, 17138, 1166, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1020663579305013, "compression_ratio": 1.6867469879518073, "no_speech_prob": 0.01638229563832283}, {"id": 216, "seek": 155452, "start": 1554.52, "end": 1561.32, "text": " and you have to keep going back and forth, and so on. So that's that. That's the final comment", "tokens": [50364, 293, 291, 362, 281, 1066, 516, 646, 293, 5220, 11, 293, 370, 322, 13, 407, 300, 311, 300, 13, 663, 311, 264, 2572, 2871, 50704], "temperature": 0.0, "avg_logprob": -0.09162327766418457, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.003482295898720622}, {"id": 217, "seek": 155452, "start": 1561.32, "end": 1569.16, "text": " there. So here we've just so far talked about the bottom up side. Let's now talk about the top down", "tokens": [50704, 456, 13, 407, 510, 321, 600, 445, 370, 1400, 2825, 466, 264, 2767, 493, 1252, 13, 961, 311, 586, 751, 466, 264, 1192, 760, 51096], "temperature": 0.0, "avg_logprob": -0.09162327766418457, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.003482295898720622}, {"id": 218, "seek": 155452, "start": 1569.16, "end": 1575.24, "text": " approach, which is a little bit different in terms of coding. So we're going to look at", "tokens": [51096, 3109, 11, 597, 307, 257, 707, 857, 819, 294, 2115, 295, 17720, 13, 407, 321, 434, 516, 281, 574, 412, 51400], "temperature": 0.0, "avg_logprob": -0.09162327766418457, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.003482295898720622}, {"id": 219, "seek": 155452, "start": 1575.24, "end": 1582.92, "text": " alternate templates, which is my strategy to. So the idea here, when I wrote the paper in 1999,", "tokens": [51400, 18873, 21165, 11, 597, 307, 452, 5206, 281, 13, 407, 264, 1558, 510, 11, 562, 286, 4114, 264, 3035, 294, 19952, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09162327766418457, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.003482295898720622}, {"id": 220, "seek": 158292, "start": 1582.92, "end": 1593.0800000000002, "text": " was this idea that you could, you could fit one I a priori theme theory to your data. But what's", "tokens": [50364, 390, 341, 1558, 300, 291, 727, 11, 291, 727, 3318, 472, 286, 257, 4059, 72, 6314, 5261, 281, 428, 1412, 13, 583, 437, 311, 50872], "temperature": 0.0, "avg_logprob": -0.1395507060306173, "compression_ratio": 1.6, "no_speech_prob": 0.001726622460409999}, {"id": 221, "seek": 158292, "start": 1593.0800000000002, "end": 1600.8400000000001, "text": " probably more interesting is trying to apply more than one. Because if you do that, you will get to", "tokens": [50872, 1391, 544, 1880, 307, 1382, 281, 3079, 544, 813, 472, 13, 1436, 498, 291, 360, 300, 11, 291, 486, 483, 281, 51260], "temperature": 0.0, "avg_logprob": -0.1395507060306173, "compression_ratio": 1.6, "no_speech_prob": 0.001726622460409999}, {"id": 222, "seek": 158292, "start": 1600.8400000000001, "end": 1609.3200000000002, "text": " see your data in different ways, you might even be able to verify which which theoretical framework", "tokens": [51260, 536, 428, 1412, 294, 819, 2098, 11, 291, 1062, 754, 312, 1075, 281, 16888, 597, 597, 20864, 8388, 51684], "temperature": 0.0, "avg_logprob": -0.1395507060306173, "compression_ratio": 1.6, "no_speech_prob": 0.001726622460409999}, {"id": 223, "seek": 160932, "start": 1610.28, "end": 1618.04, "text": " is more appropriate fits better. And doing this coding based on any priorities frame", "tokens": [50412, 307, 544, 6854, 9001, 1101, 13, 400, 884, 341, 17720, 2361, 322, 604, 15503, 3920, 50800], "temperature": 0.0, "avg_logprob": -0.15662093278838368, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.009541129693388939}, {"id": 224, "seek": 160932, "start": 1618.04, "end": 1624.2, "text": " frame can be very useful for doing that. And the classic inspiration for this is a book which I", "tokens": [50800, 3920, 393, 312, 588, 4420, 337, 884, 300, 13, 400, 264, 7230, 10249, 337, 341, 307, 257, 1446, 597, 286, 51108], "temperature": 0.0, "avg_logprob": -0.15662093278838368, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.009541129693388939}, {"id": 225, "seek": 160932, "start": 1624.2, "end": 1629.56, "text": " recommend everybody read, which is by Graham Allison, and just the essence of decision.", "tokens": [51108, 2748, 2201, 1401, 11, 597, 307, 538, 22691, 32638, 11, 293, 445, 264, 12801, 295, 3537, 13, 51376], "temperature": 0.0, "avg_logprob": -0.15662093278838368, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.009541129693388939}, {"id": 226, "seek": 160932, "start": 1630.9199999999998, "end": 1638.36, "text": " And he's a political scientist. And he studied the Cuban missile crisis, which is an event which", "tokens": [51444, 400, 415, 311, 257, 3905, 12662, 13, 400, 415, 9454, 264, 31547, 19321, 5869, 11, 597, 307, 364, 2280, 597, 51816], "temperature": 0.0, "avg_logprob": -0.15662093278838368, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.009541129693388939}, {"id": 227, "seek": 163836, "start": 1638.36, "end": 1644.04, "text": " I'm old enough to have lived through, although I was a child in the 1960s.", "tokens": [50364, 286, 478, 1331, 1547, 281, 362, 5152, 807, 11, 4878, 286, 390, 257, 1440, 294, 264, 16157, 82, 13, 50648], "temperature": 0.0, "avg_logprob": -0.11992317882936392, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0013236943632364273}, {"id": 228, "seek": 163836, "start": 1646.12, "end": 1654.04, "text": " When nuclear missiles were placed in Cuba, and the United States had to decide what to do about it.", "tokens": [50752, 1133, 8179, 23133, 645, 7074, 294, 20604, 11, 293, 264, 2824, 3040, 632, 281, 4536, 437, 281, 360, 466, 309, 13, 51148], "temperature": 0.0, "avg_logprob": -0.11992317882936392, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0013236943632364273}, {"id": 229, "seek": 163836, "start": 1655.32, "end": 1665.6399999999999, "text": " And what what Allison did is he got access to a huge amount of documentary data on this.", "tokens": [51212, 400, 437, 437, 32638, 630, 307, 415, 658, 2105, 281, 257, 2603, 2372, 295, 15674, 1412, 322, 341, 13, 51728], "temperature": 0.0, "avg_logprob": -0.11992317882936392, "compression_ratio": 1.413978494623656, "no_speech_prob": 0.0013236943632364273}, {"id": 230, "seek": 166564, "start": 1666.6000000000001, "end": 1671.8000000000002, "text": " And analyzed it according to three different theoretical frames. And the first theoretical", "tokens": [50412, 400, 28181, 309, 4650, 281, 1045, 819, 20864, 12083, 13, 400, 264, 700, 20864, 50672], "temperature": 0.0, "avg_logprob": -0.11241256981565241, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0010317964479327202}, {"id": 231, "seek": 166564, "start": 1671.8000000000002, "end": 1680.1200000000001, "text": " frame was the rational actor model. So according to the rational actor model, countries are rational", "tokens": [50672, 3920, 390, 264, 15090, 8747, 2316, 13, 407, 4650, 281, 264, 15090, 8747, 2316, 11, 3517, 366, 15090, 51088], "temperature": 0.0, "avg_logprob": -0.11241256981565241, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0010317964479327202}, {"id": 232, "seek": 166564, "start": 1680.1200000000001, "end": 1690.8400000000001, "text": " actors. So countries consider the the alternatives they have available and pick the best one.", "tokens": [51088, 10037, 13, 407, 3517, 1949, 264, 264, 20478, 436, 362, 2435, 293, 1888, 264, 1151, 472, 13, 51624], "temperature": 0.0, "avg_logprob": -0.11241256981565241, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0010317964479327202}, {"id": 233, "seek": 169084, "start": 1691.1599999999999, "end": 1699.32, "text": " So the whole assumption is that the country is one one actor.", "tokens": [50380, 407, 264, 1379, 15302, 307, 300, 264, 1941, 307, 472, 472, 8747, 13, 50788], "temperature": 0.0, "avg_logprob": -0.17343205141733928, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0010810754029080272}, {"id": 234, "seek": 169084, "start": 1701.6399999999999, "end": 1706.9199999999998, "text": " The second theory they applied to that this was to say no, no, no, countries are not actors,", "tokens": [50904, 440, 1150, 5261, 436, 6456, 281, 300, 341, 390, 281, 584, 572, 11, 572, 11, 572, 11, 3517, 366, 406, 10037, 11, 51168], "temperature": 0.0, "avg_logprob": -0.17343205141733928, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0010810754029080272}, {"id": 235, "seek": 169084, "start": 1706.9199999999998, "end": 1712.1999999999998, "text": " countries have bureaucratic organizations that are part of them. So for example, the US has the", "tokens": [51168, 3517, 362, 26360, 25198, 6150, 300, 366, 644, 295, 552, 13, 407, 337, 1365, 11, 264, 2546, 575, 264, 51432], "temperature": 0.0, "avg_logprob": -0.17343205141733928, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0010810754029080272}, {"id": 236, "seek": 169084, "start": 1712.1999999999998, "end": 1718.4399999999998, "text": " Pentagon, the military that are doing one thing. They have Congress that is doing something else.", "tokens": [51432, 36371, 11, 264, 4632, 300, 366, 884, 472, 551, 13, 814, 362, 6426, 300, 307, 884, 746, 1646, 13, 51744], "temperature": 0.0, "avg_logprob": -0.17343205141733928, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0010810754029080272}, {"id": 237, "seek": 171844, "start": 1719.16, "end": 1724.76, "text": " They have the president who is doing something else. All of these individuals have their own", "tokens": [50400, 814, 362, 264, 3868, 567, 307, 884, 746, 1646, 13, 1057, 295, 613, 5346, 362, 641, 1065, 50680], "temperature": 0.0, "avg_logprob": -0.10109839969211154, "compression_ratio": 1.8487804878048781, "no_speech_prob": 0.0015475855907425284}, {"id": 238, "seek": 171844, "start": 1725.3200000000002, "end": 1731.0, "text": " routines. All of these groups have their own routines that they know how to do. So the military", "tokens": [50708, 33827, 13, 1057, 295, 613, 3935, 362, 641, 1065, 33827, 300, 436, 458, 577, 281, 360, 13, 407, 264, 4632, 50992], "temperature": 0.0, "avg_logprob": -0.10109839969211154, "compression_ratio": 1.8487804878048781, "no_speech_prob": 0.0015475855907425284}, {"id": 239, "seek": 171844, "start": 1731.0, "end": 1736.1200000000001, "text": " knows how to do an invasion. They know how to do a blockade. And if they're given the right stimulus,", "tokens": [50992, 3255, 577, 281, 360, 364, 21575, 13, 814, 458, 577, 281, 360, 257, 3461, 762, 13, 400, 498, 436, 434, 2212, 264, 558, 21366, 11, 51248], "temperature": 0.0, "avg_logprob": -0.10109839969211154, "compression_ratio": 1.8487804878048781, "no_speech_prob": 0.0015475855907425284}, {"id": 240, "seek": 171844, "start": 1736.1200000000001, "end": 1742.2, "text": " they will execute the bureaucratic processes that they know how to do. And so the second", "tokens": [51248, 436, 486, 14483, 264, 26360, 25198, 7555, 300, 436, 458, 577, 281, 360, 13, 400, 370, 264, 1150, 51552], "temperature": 0.0, "avg_logprob": -0.10109839969211154, "compression_ratio": 1.8487804878048781, "no_speech_prob": 0.0015475855907425284}, {"id": 241, "seek": 174220, "start": 1742.2, "end": 1749.0800000000002, "text": " explanation was really a March and Simon based bureaucratic model. And then the third one was", "tokens": [50364, 10835, 390, 534, 257, 6129, 293, 13193, 2361, 26360, 25198, 2316, 13, 400, 550, 264, 2636, 472, 390, 50708], "temperature": 0.0, "avg_logprob": -0.07698304057121277, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0014775488525629044}, {"id": 242, "seek": 174220, "start": 1749.0800000000002, "end": 1754.44, "text": " political. So they were looking at individuals, what their individual interests were and how", "tokens": [50708, 3905, 13, 407, 436, 645, 1237, 412, 5346, 11, 437, 641, 2609, 8847, 645, 293, 577, 50976], "temperature": 0.0, "avg_logprob": -0.07698304057121277, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0014775488525629044}, {"id": 243, "seek": 174220, "start": 1754.44, "end": 1760.44, "text": " those interacted. And they applied these three models to the same data and ended up with three", "tokens": [50976, 729, 49621, 13, 400, 436, 6456, 613, 1045, 5245, 281, 264, 912, 1412, 293, 4590, 493, 365, 1045, 51276], "temperature": 0.0, "avg_logprob": -0.07698304057121277, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0014775488525629044}, {"id": 244, "seek": 174220, "start": 1760.44, "end": 1766.68, "text": " different stories, which they kind of argued in the first version of their paper, we should", "tokens": [51276, 819, 3676, 11, 597, 436, 733, 295, 20219, 294, 264, 700, 3037, 295, 641, 3035, 11, 321, 820, 51588], "temperature": 0.0, "avg_logprob": -0.07698304057121277, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0014775488525629044}, {"id": 245, "seek": 176668, "start": 1766.68, "end": 1772.92, "text": " keep separate because they enable us to see different things. These things are not wrong.", "tokens": [50364, 1066, 4994, 570, 436, 9528, 505, 281, 536, 819, 721, 13, 1981, 721, 366, 406, 2085, 13, 50676], "temperature": 0.0, "avg_logprob": -0.09370912313461303, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0035925644915550947}, {"id": 246, "seek": 176668, "start": 1773.88, "end": 1778.92, "text": " They're just lenses for looking at things. And having different lenses to look at things", "tokens": [50724, 814, 434, 445, 18059, 337, 1237, 412, 721, 13, 400, 1419, 819, 18059, 281, 574, 412, 721, 50976], "temperature": 0.0, "avg_logprob": -0.09370912313461303, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0035925644915550947}, {"id": 247, "seek": 176668, "start": 1780.04, "end": 1787.16, "text": " is insightful. So this is this is a completely different approach because you are starting", "tokens": [51032, 307, 46401, 13, 407, 341, 307, 341, 307, 257, 2584, 819, 3109, 570, 291, 366, 2891, 51388], "temperature": 0.0, "avg_logprob": -0.09370912313461303, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0035925644915550947}, {"id": 248, "seek": 176668, "start": 1787.8, "end": 1795.0800000000002, "text": " from the theory and not from the data. This is an approach that probably, in my opinion,", "tokens": [51420, 490, 264, 5261, 293, 406, 490, 264, 1412, 13, 639, 307, 364, 3109, 300, 1391, 11, 294, 452, 4800, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09370912313461303, "compression_ratio": 1.7549019607843137, "no_speech_prob": 0.0035925644915550947}, {"id": 249, "seek": 179508, "start": 1795.08, "end": 1801.24, "text": " we don't use enough. At least, and it's one of the reasons is it's very hard to", "tokens": [50364, 321, 500, 380, 764, 1547, 13, 1711, 1935, 11, 293, 309, 311, 472, 295, 264, 4112, 307, 309, 311, 588, 1152, 281, 50672], "temperature": 0.0, "avg_logprob": -0.12097480331642041, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.001366320764645934}, {"id": 250, "seek": 179508, "start": 1802.6, "end": 1810.4399999999998, "text": " introduce three different theory of theoretical frames into a 40 page article. It's not possible.", "tokens": [50740, 5366, 1045, 819, 5261, 295, 20864, 12083, 666, 257, 3356, 3028, 7222, 13, 467, 311, 406, 1944, 13, 51132], "temperature": 0.0, "avg_logprob": -0.12097480331642041, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.001366320764645934}, {"id": 251, "seek": 179508, "start": 1810.4399999999998, "end": 1818.4399999999998, "text": " But you can do it in a thesis much more easily. And that can be the basis for three different", "tokens": [51132, 583, 291, 393, 360, 309, 294, 257, 22288, 709, 544, 3612, 13, 400, 300, 393, 312, 264, 5143, 337, 1045, 819, 51532], "temperature": 0.0, "avg_logprob": -0.12097480331642041, "compression_ratio": 1.5310734463276836, "no_speech_prob": 0.001366320764645934}, {"id": 252, "seek": 181844, "start": 1818.44, "end": 1829.8, "text": " articles. So that so this can be used more. I have an example here of a single paper where they", "tokens": [50364, 11290, 13, 407, 300, 370, 341, 393, 312, 1143, 544, 13, 286, 362, 364, 1365, 510, 295, 257, 2167, 3035, 689, 436, 50932], "temperature": 0.0, "avg_logprob": -0.34498378208705355, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.0034251222386956215}, {"id": 253, "seek": 181844, "start": 1830.6000000000001, "end": 1840.52, "text": " looked at three different frameworks. And this was an organization of science. It was by two", "tokens": [50972, 2956, 412, 1045, 819, 29834, 13, 400, 341, 390, 364, 4475, 295, 3497, 13, 467, 390, 538, 732, 51468], "temperature": 0.0, "avg_logprob": -0.34498378208705355, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.0034251222386956215}, {"id": 254, "seek": 181844, "start": 1840.52, "end": 1846.6000000000001, "text": " colleagues of mine in Montreal, Suzanne Duvara, who said that she said Maria, and yet the point", "tokens": [51468, 7734, 295, 3892, 294, 34180, 11, 48901, 5153, 85, 2419, 11, 567, 848, 300, 750, 848, 12734, 11, 293, 1939, 264, 935, 51772], "temperature": 0.0, "avg_logprob": -0.34498378208705355, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.0034251222386956215}, {"id": 255, "seek": 184660, "start": 1846.6, "end": 1860.4399999999998, "text": " who is at McGill. And they studied the implementation of computer systems in in in hospitals. And they", "tokens": [50364, 567, 307, 412, 21865, 373, 13, 400, 436, 9454, 264, 11420, 295, 3820, 3652, 294, 294, 294, 13014, 13, 400, 436, 51056], "temperature": 0.0, "avg_logprob": -0.202527954464867, "compression_ratio": 1.4850746268656716, "no_speech_prob": 0.001571682165376842}, {"id": 256, "seek": 184660, "start": 1860.4399999999998, "end": 1867.8, "text": " considered three different theoretical models for understanding that. And the first one was that", "tokens": [51056, 4888, 1045, 819, 20864, 5245, 337, 3701, 300, 13, 400, 264, 700, 472, 390, 300, 51424], "temperature": 0.0, "avg_logprob": -0.202527954464867, "compression_ratio": 1.4850746268656716, "no_speech_prob": 0.001571682165376842}, {"id": 257, "seek": 186780, "start": 1867.8, "end": 1878.2, "text": " this was a problem of people. And so that model was about how individuals cognitively related to", "tokens": [50364, 341, 390, 257, 1154, 295, 561, 13, 400, 370, 300, 2316, 390, 466, 577, 5346, 15605, 356, 4077, 281, 50884], "temperature": 0.0, "avg_logprob": -0.10127089573786809, "compression_ratio": 1.5885714285714285, "no_speech_prob": 0.012784009799361229}, {"id": 258, "seek": 186780, "start": 1878.84, "end": 1883.1599999999999, "text": " an information system. So if you wanted to understand if it was implemented or not,", "tokens": [50916, 364, 1589, 1185, 13, 407, 498, 291, 1415, 281, 1223, 498, 309, 390, 12270, 420, 406, 11, 51132], "temperature": 0.0, "avg_logprob": -0.10127089573786809, "compression_ratio": 1.5885714285714285, "no_speech_prob": 0.012784009799361229}, {"id": 259, "seek": 186780, "start": 1883.1599999999999, "end": 1892.36, "text": " you had to see how people found it useful or not, essentially. And it was basically a question of", "tokens": [51132, 291, 632, 281, 536, 577, 561, 1352, 309, 4420, 420, 406, 11, 4476, 13, 400, 309, 390, 1936, 257, 1168, 295, 51592], "temperature": 0.0, "avg_logprob": -0.10127089573786809, "compression_ratio": 1.5885714285714285, "no_speech_prob": 0.012784009799361229}, {"id": 260, "seek": 189236, "start": 1892.36, "end": 1901.4799999999998, "text": " whether different individuals could cognitively absorb the implications of the information system.", "tokens": [50364, 1968, 819, 5346, 727, 15605, 356, 15631, 264, 16602, 295, 264, 1589, 1185, 13, 50820], "temperature": 0.0, "avg_logprob": -0.09616196576286765, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0007095184409990907}, {"id": 261, "seek": 189236, "start": 1901.4799999999998, "end": 1907.1599999999999, "text": " And so in order to code for that model, they coded by individuals, right, they had the list of", "tokens": [50820, 400, 370, 294, 1668, 281, 3089, 337, 300, 2316, 11, 436, 34874, 538, 5346, 11, 558, 11, 436, 632, 264, 1329, 295, 51104], "temperature": 0.0, "avg_logprob": -0.09616196576286765, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0007095184409990907}, {"id": 262, "seek": 189236, "start": 1907.1599999999999, "end": 1912.52, "text": " individuals, they considered the elements that are in the model. So there were four elements in the", "tokens": [51104, 5346, 11, 436, 4888, 264, 4959, 300, 366, 294, 264, 2316, 13, 407, 456, 645, 1451, 4959, 294, 264, 51372], "temperature": 0.0, "avg_logprob": -0.09616196576286765, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0007095184409990907}, {"id": 263, "seek": 189236, "start": 1912.52, "end": 1919.56, "text": " model, they coded them systematically, and look to see how that worked. The second one is a", "tokens": [51372, 2316, 11, 436, 34874, 552, 39531, 11, 293, 574, 281, 536, 577, 300, 2732, 13, 440, 1150, 472, 307, 257, 51724], "temperature": 0.0, "avg_logprob": -0.09616196576286765, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0007095184409990907}, {"id": 264, "seek": 191956, "start": 1920.2, "end": 1925.48, "text": " political model. And the theory behind that is that people will resist information systems that", "tokens": [50396, 3905, 2316, 13, 400, 264, 5261, 2261, 300, 307, 300, 561, 486, 4597, 1589, 3652, 300, 50660], "temperature": 0.0, "avg_logprob": -0.11886558300111352, "compression_ratio": 1.8817733990147782, "no_speech_prob": 0.00043701264075934887}, {"id": 265, "seek": 191956, "start": 1925.48, "end": 1933.08, "text": " take power away from them. And so, and they looked at different groups, so they looked at doctors,", "tokens": [50660, 747, 1347, 1314, 490, 552, 13, 400, 370, 11, 293, 436, 2956, 412, 819, 3935, 11, 370, 436, 2956, 412, 8778, 11, 51040], "temperature": 0.0, "avg_logprob": -0.11886558300111352, "compression_ratio": 1.8817733990147782, "no_speech_prob": 0.00043701264075934887}, {"id": 266, "seek": 191956, "start": 1933.6399999999999, "end": 1940.6799999999998, "text": " they looked at, they looked at administrators, and how they were reacting to the information", "tokens": [51068, 436, 2956, 412, 11, 436, 2956, 412, 27754, 11, 293, 577, 436, 645, 25817, 281, 264, 1589, 51420], "temperature": 0.0, "avg_logprob": -0.11886558300111352, "compression_ratio": 1.8817733990147782, "no_speech_prob": 0.00043701264075934887}, {"id": 267, "seek": 191956, "start": 1940.6799999999998, "end": 1949.0, "text": " systems over time, and considered whether this model might explain things. And the third model", "tokens": [51420, 3652, 670, 565, 11, 293, 4888, 1968, 341, 2316, 1062, 2903, 721, 13, 400, 264, 2636, 2316, 51836], "temperature": 0.0, "avg_logprob": -0.11886558300111352, "compression_ratio": 1.8817733990147782, "no_speech_prob": 0.00043701264075934887}, {"id": 268, "seek": 194900, "start": 1949.0, "end": 1958.36, "text": " is an organizational design model developed by Henry Menzberg. And here they were trying to consider", "tokens": [50364, 307, 364, 24730, 1715, 2316, 4743, 538, 11085, 6685, 89, 6873, 13, 400, 510, 436, 645, 1382, 281, 1949, 50832], "temperature": 0.0, "avg_logprob": -0.11799820776908629, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.00018789860769174993}, {"id": 269, "seek": 194900, "start": 1958.36, "end": 1965.48, "text": " whether the organizational form was having a difference to the implementation process.", "tokens": [50832, 1968, 264, 24730, 1254, 390, 1419, 257, 2649, 281, 264, 11420, 1399, 13, 51188], "temperature": 0.0, "avg_logprob": -0.11799820776908629, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.00018789860769174993}, {"id": 270, "seek": 194900, "start": 1965.48, "end": 1972.6, "text": " So they basically tested, and in this case, it was a test. It was not really different lenses to", "tokens": [51188, 407, 436, 1936, 8246, 11, 293, 294, 341, 1389, 11, 309, 390, 257, 1500, 13, 467, 390, 406, 534, 819, 18059, 281, 51544], "temperature": 0.0, "avg_logprob": -0.11799820776908629, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.00018789860769174993}, {"id": 271, "seek": 197260, "start": 1973.56, "end": 1979.6399999999999, "text": " enrich, to accumulate, to have three different explanations, but they tested the value of each", "tokens": [50412, 18849, 11, 281, 33384, 11, 281, 362, 1045, 819, 28708, 11, 457, 436, 8246, 264, 2158, 295, 1184, 50716], "temperature": 0.0, "avg_logprob": -0.13875484466552734, "compression_ratio": 1.8592233009708738, "no_speech_prob": 0.0004172834742348641}, {"id": 272, "seek": 197260, "start": 1979.6399999999999, "end": 1989.0, "text": " of these three models on the same data. And came to the conclusion that in the early phase of", "tokens": [50716, 295, 613, 1045, 5245, 322, 264, 912, 1412, 13, 400, 1361, 281, 264, 10063, 300, 294, 264, 2440, 5574, 295, 51184], "temperature": 0.0, "avg_logprob": -0.13875484466552734, "compression_ratio": 1.8592233009708738, "no_speech_prob": 0.0004172834742348641}, {"id": 273, "seek": 197260, "start": 1989.0, "end": 1994.9199999999998, "text": " implementation, it was one model that dominated in another phase, it was the second model that", "tokens": [51184, 11420, 11, 309, 390, 472, 2316, 300, 23755, 294, 1071, 5574, 11, 309, 390, 264, 1150, 2316, 300, 51480], "temperature": 0.0, "avg_logprob": -0.13875484466552734, "compression_ratio": 1.8592233009708738, "no_speech_prob": 0.0004172834742348641}, {"id": 274, "seek": 197260, "start": 1994.9199999999998, "end": 2001.48, "text": " dominated in the third phase, it was a third one. So that in the end, this enabled them to generate", "tokens": [51480, 23755, 294, 264, 2636, 5574, 11, 309, 390, 257, 2636, 472, 13, 407, 300, 294, 264, 917, 11, 341, 15172, 552, 281, 8460, 51808], "temperature": 0.0, "avg_logprob": -0.13875484466552734, "compression_ratio": 1.8592233009708738, "no_speech_prob": 0.0004172834742348641}, {"id": 275, "seek": 200148, "start": 2001.56, "end": 2008.68, "text": " a really interesting theoretical framework, which showed how the importance of different", "tokens": [50368, 257, 534, 1880, 20864, 8388, 11, 597, 4712, 577, 264, 7379, 295, 819, 50724], "temperature": 0.0, "avg_logprob": -0.10799812879718718, "compression_ratio": 1.425414364640884, "no_speech_prob": 0.0008684938657097518}, {"id": 276, "seek": 200148, "start": 2008.68, "end": 2013.8, "text": " processes evolved over time. So that's an example of how you can and do that.", "tokens": [50724, 7555, 14178, 670, 565, 13, 407, 300, 311, 364, 1365, 295, 577, 291, 393, 293, 360, 300, 13, 50980], "temperature": 0.0, "avg_logprob": -0.10799812879718718, "compression_ratio": 1.425414364640884, "no_speech_prob": 0.0008684938657097518}, {"id": 277, "seek": 200148, "start": 2015.88, "end": 2023.88, "text": " And before I move on from this, I wanted also to draw attention to Andy van der Ven's work.", "tokens": [51084, 400, 949, 286, 1286, 322, 490, 341, 11, 286, 1415, 611, 281, 2642, 3202, 281, 13285, 3161, 1163, 11182, 311, 589, 13, 51484], "temperature": 0.0, "avg_logprob": -0.10799812879718718, "compression_ratio": 1.425414364640884, "no_speech_prob": 0.0008684938657097518}, {"id": 278, "seek": 202388, "start": 2023.88, "end": 2033.48, "text": " Unfortunately, we lost Andy van der Ven last year. But he has made a fantastic contribution to", "tokens": [50364, 8590, 11, 321, 2731, 13285, 3161, 1163, 11182, 1036, 1064, 13, 583, 415, 575, 1027, 257, 5456, 13150, 281, 50844], "temperature": 0.0, "avg_logprob": -0.10920934677124024, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0035787501838058233}, {"id": 279, "seek": 202388, "start": 2033.48, "end": 2042.7600000000002, "text": " process research. And one of his papers, which I really find at the same time, extremely stimulating,", "tokens": [50844, 1399, 2132, 13, 400, 472, 295, 702, 10577, 11, 597, 286, 534, 915, 412, 264, 912, 565, 11, 4664, 43671, 11, 51308], "temperature": 0.0, "avg_logprob": -0.10920934677124024, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0035787501838058233}, {"id": 280, "seek": 202388, "start": 2042.7600000000002, "end": 2051.0, "text": " but at the same time, I've always questioned it a little bit, is a piece of work with Marshall", "tokens": [51308, 457, 412, 264, 912, 565, 11, 286, 600, 1009, 28146, 309, 257, 707, 857, 11, 307, 257, 2522, 295, 589, 365, 17279, 51720], "temperature": 0.0, "avg_logprob": -0.10920934677124024, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0035787501838058233}, {"id": 281, "seek": 205100, "start": 2051.08, "end": 2059.96, "text": " Scott Poole, where he proposed four different theoretical, possible theoretical models of", "tokens": [50368, 6659, 430, 1986, 306, 11, 689, 415, 10348, 1451, 819, 20864, 11, 1944, 20864, 5245, 295, 50812], "temperature": 0.0, "avg_logprob": -0.08863584456905242, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0013239590916782618}, {"id": 282, "seek": 205100, "start": 2059.96, "end": 2068.52, "text": " process. And in terms of thinking about alternate templates, these are really, really useful.", "tokens": [50812, 1399, 13, 400, 294, 2115, 295, 1953, 466, 18873, 21165, 11, 613, 366, 534, 11, 534, 4420, 13, 51240], "temperature": 0.0, "avg_logprob": -0.08863584456905242, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0013239590916782618}, {"id": 283, "seek": 205100, "start": 2069.72, "end": 2076.92, "text": " These are classic process theories. And I'm just going to give you an illustration. And I actually", "tokens": [51300, 1981, 366, 7230, 1399, 13667, 13, 400, 286, 478, 445, 516, 281, 976, 291, 364, 22645, 13, 400, 286, 767, 51660], "temperature": 0.0, "avg_logprob": -0.08863584456905242, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0013239590916782618}, {"id": 284, "seek": 207692, "start": 2076.92, "end": 2085.2400000000002, "text": " used this recently in a study with a colleague from University of Gothenburg, and we were looking at", "tokens": [50364, 1143, 341, 3938, 294, 257, 2979, 365, 257, 13532, 490, 3535, 295, 27305, 268, 8342, 11, 293, 321, 645, 1237, 412, 50780], "temperature": 0.0, "avg_logprob": -0.16434875027886753, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.005708999466150999}, {"id": 285, "seek": 207692, "start": 2086.28, "end": 2094.12, "text": " migrant workplace integration in Sweden in organizations. They've had many, many refugees", "tokens": [50832, 38547, 15328, 10980, 294, 17727, 294, 6150, 13, 814, 600, 632, 867, 11, 867, 18301, 51224], "temperature": 0.0, "avg_logprob": -0.16434875027886753, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.005708999466150999}, {"id": 286, "seek": 207692, "start": 2094.6800000000003, "end": 2105.08, "text": " come to Sweden and organizations and governments are struggling with how to ensure workplace", "tokens": [51252, 808, 281, 17727, 293, 6150, 293, 11280, 366, 9314, 365, 577, 281, 5586, 15328, 51772], "temperature": 0.0, "avg_logprob": -0.16434875027886753, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.005708999466150999}, {"id": 287, "seek": 210508, "start": 2105.08, "end": 2120.04, "text": " integration. It's clearly an important factor that can explain whether refugees can adapt", "tokens": [50364, 10980, 13, 467, 311, 4448, 364, 1021, 5952, 300, 393, 2903, 1968, 18301, 393, 6231, 51112], "temperature": 0.0, "avg_logprob": -0.11358776757883471, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0013388872612267733}, {"id": 288, "seek": 210508, "start": 2120.04, "end": 2130.6, "text": " to a society. So van der Ven and Poole identified these four classic process models. They called a", "tokens": [51112, 281, 257, 4086, 13, 407, 3161, 1163, 11182, 293, 430, 1986, 306, 9234, 613, 1451, 7230, 1399, 5245, 13, 814, 1219, 257, 51640], "temperature": 0.0, "avg_logprob": -0.11358776757883471, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.0013388872612267733}, {"id": 289, "seek": 213060, "start": 2130.6, "end": 2137.4, "text": " life cycle process, a learning process, an ecological or evolutionary process, and a", "tokens": [50364, 993, 6586, 1399, 11, 257, 2539, 1399, 11, 364, 31054, 420, 27567, 1399, 11, 293, 257, 50704], "temperature": 0.0, "avg_logprob": -0.091061147776517, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.001568643026985228}, {"id": 290, "seek": 213060, "start": 2137.4, "end": 2143.4, "text": " dialectic process. And I have little diagrams which illustrate each so that we can just sort of see", "tokens": [50704, 24652, 299, 1399, 13, 400, 286, 362, 707, 36709, 597, 23221, 1184, 370, 300, 321, 393, 445, 1333, 295, 536, 51004], "temperature": 0.0, "avg_logprob": -0.091061147776517, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.001568643026985228}, {"id": 291, "seek": 213060, "start": 2143.4, "end": 2151.4, "text": " what the kinds of frameworks might be. And these are really useful kind of heuristic ideas about", "tokens": [51004, 437, 264, 3685, 295, 29834, 1062, 312, 13, 400, 613, 366, 534, 4420, 733, 295, 415, 374, 3142, 3487, 466, 51404], "temperature": 0.0, "avg_logprob": -0.091061147776517, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.001568643026985228}, {"id": 292, "seek": 213060, "start": 2151.4, "end": 2158.2, "text": " how you might consider your process data. So the first one is, it's a process that evolves over time", "tokens": [51404, 577, 291, 1062, 1949, 428, 1399, 1412, 13, 407, 264, 700, 472, 307, 11, 309, 311, 257, 1399, 300, 43737, 670, 565, 51744], "temperature": 0.0, "avg_logprob": -0.091061147776517, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.001568643026985228}, {"id": 293, "seek": 215820, "start": 2158.2799999999997, "end": 2166.12, "text": " in a predictable way. So, you know, you're a refugee into a country, you try and get a job,", "tokens": [50368, 294, 257, 27737, 636, 13, 407, 11, 291, 458, 11, 291, 434, 257, 25622, 666, 257, 1941, 11, 291, 853, 293, 483, 257, 1691, 11, 50760], "temperature": 0.0, "avg_logprob": -0.11668691427811333, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.00250513618811965}, {"id": 294, "seek": 215820, "start": 2166.7599999999998, "end": 2173.0, "text": " you go through certain processes of development, and at some point you reach a level of maturity", "tokens": [50792, 291, 352, 807, 1629, 7555, 295, 3250, 11, 293, 412, 512, 935, 291, 2524, 257, 1496, 295, 28874, 51104], "temperature": 0.0, "avg_logprob": -0.11668691427811333, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.00250513618811965}, {"id": 295, "seek": 215820, "start": 2173.0, "end": 2179.16, "text": " as integrating into your workplace. So this is a very linear process model, and it assumes that", "tokens": [51104, 382, 26889, 666, 428, 15328, 13, 407, 341, 307, 257, 588, 8213, 1399, 2316, 11, 293, 309, 37808, 300, 51412], "temperature": 0.0, "avg_logprob": -0.11668691427811333, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.00250513618811965}, {"id": 296, "seek": 215820, "start": 2179.16, "end": 2186.7599999999998, "text": " there are kind of deterministic phases through which you pass. So that's one way of looking at", "tokens": [51412, 456, 366, 733, 295, 15957, 3142, 18764, 807, 597, 291, 1320, 13, 407, 300, 311, 472, 636, 295, 1237, 412, 51792], "temperature": 0.0, "avg_logprob": -0.11668691427811333, "compression_ratio": 1.6478260869565218, "no_speech_prob": 0.00250513618811965}, {"id": 297, "seek": 218676, "start": 2187.32, "end": 2195.48, "text": " process. It's probably the simplest way, and many process models, the first iteration, that's what", "tokens": [50392, 1399, 13, 467, 311, 1391, 264, 22811, 636, 11, 293, 867, 1399, 5245, 11, 264, 700, 24784, 11, 300, 311, 437, 50800], "temperature": 0.0, "avg_logprob": -0.10199931173613577, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.0006255970220081508}, {"id": 298, "seek": 218676, "start": 2195.48, "end": 2203.96, "text": " they look like. It's maybe not the most inspiring in terms of understanding the complexities.", "tokens": [50800, 436, 574, 411, 13, 467, 311, 1310, 406, 264, 881, 15883, 294, 2115, 295, 3701, 264, 48705, 13, 51224], "temperature": 0.0, "avg_logprob": -0.10199931173613577, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.0006255970220081508}, {"id": 299, "seek": 218676, "start": 2203.96, "end": 2210.6800000000003, "text": " So that's one type of model. A second type of model is this idea of learning.", "tokens": [51224, 407, 300, 311, 472, 2010, 295, 2316, 13, 316, 1150, 2010, 295, 2316, 307, 341, 1558, 295, 2539, 13, 51560], "temperature": 0.0, "avg_logprob": -0.10199931173613577, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.0006255970220081508}, {"id": 300, "seek": 221068, "start": 2211.64, "end": 2217.56, "text": " Van de Verden and Poole call it a teleological model. I like to think of it as a learning model,", "tokens": [50412, 8979, 368, 4281, 1556, 293, 430, 1986, 306, 818, 309, 257, 4304, 4383, 2316, 13, 286, 411, 281, 519, 295, 309, 382, 257, 2539, 2316, 11, 50708], "temperature": 0.0, "avg_logprob": -0.15078246151959454, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0025473947171121836}, {"id": 301, "seek": 221068, "start": 2217.56, "end": 2222.52, "text": " because I think it's easier to understand, which is that you have an objective, and it's all about", "tokens": [50708, 570, 286, 519, 309, 311, 3571, 281, 1223, 11, 597, 307, 300, 291, 362, 364, 10024, 11, 293, 309, 311, 439, 466, 50956], "temperature": 0.0, "avg_logprob": -0.15078246151959454, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0025473947171121836}, {"id": 302, "seek": 221068, "start": 2222.52, "end": 2231.7999999999997, "text": " agency. You have an objective, you form a plan, you try to execute it. If you are able to execute it,", "tokens": [50956, 7934, 13, 509, 362, 364, 10024, 11, 291, 1254, 257, 1393, 11, 291, 853, 281, 14483, 309, 13, 759, 291, 366, 1075, 281, 14483, 309, 11, 51420], "temperature": 0.0, "avg_logprob": -0.15078246151959454, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0025473947171121836}, {"id": 303, "seek": 221068, "start": 2231.7999999999997, "end": 2238.52, "text": " so much the better, you continue, and if not, you change your plan. So it's a circular model,", "tokens": [51420, 370, 709, 264, 1101, 11, 291, 2354, 11, 293, 498, 406, 11, 291, 1319, 428, 1393, 13, 407, 309, 311, 257, 16476, 2316, 11, 51756], "temperature": 0.0, "avg_logprob": -0.15078246151959454, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0025473947171121836}, {"id": 304, "seek": 223852, "start": 2238.52, "end": 2246.44, "text": " really. I think that those of Edward Deming, it's a little bit like that. It's learning.", "tokens": [50364, 534, 13, 286, 519, 300, 729, 295, 18456, 4686, 278, 11, 309, 311, 257, 707, 857, 411, 300, 13, 467, 311, 2539, 13, 50760], "temperature": 0.0, "avg_logprob": -0.15994650317776588, "compression_ratio": 1.6794258373205742, "no_speech_prob": 0.0013448061654344201}, {"id": 305, "seek": 223852, "start": 2246.44, "end": 2251.24, "text": " It's you plan, you do, you check, and you act, and then you plan, and you do, and you check and act.", "tokens": [50760, 467, 311, 291, 1393, 11, 291, 360, 11, 291, 1520, 11, 293, 291, 605, 11, 293, 550, 291, 1393, 11, 293, 291, 360, 11, 293, 291, 1520, 293, 605, 13, 51000], "temperature": 0.0, "avg_logprob": -0.15994650317776588, "compression_ratio": 1.6794258373205742, "no_speech_prob": 0.0013448061654344201}, {"id": 306, "seek": 223852, "start": 2253.08, "end": 2259.24, "text": " So, yeah, migrants who arrive in a new country are doing learning as well,", "tokens": [51092, 407, 11, 1338, 11, 31263, 567, 8881, 294, 257, 777, 1941, 366, 884, 2539, 382, 731, 11, 51400], "temperature": 0.0, "avg_logprob": -0.15994650317776588, "compression_ratio": 1.6794258373205742, "no_speech_prob": 0.0013448061654344201}, {"id": 307, "seek": 223852, "start": 2261.88, "end": 2268.2, "text": " and companies who are trying to develop processes to support workplace integration are", "tokens": [51532, 293, 3431, 567, 366, 1382, 281, 1499, 7555, 281, 1406, 15328, 10980, 366, 51848], "temperature": 0.0, "avg_logprob": -0.15994650317776588, "compression_ratio": 1.6794258373205742, "no_speech_prob": 0.0013448061654344201}, {"id": 308, "seek": 226820, "start": 2268.2799999999997, "end": 2274.68, "text": " also doing learning. And so you could apply it to different levels. And so this is another", "tokens": [50368, 611, 884, 2539, 13, 400, 370, 291, 727, 3079, 309, 281, 819, 4358, 13, 400, 370, 341, 307, 1071, 50688], "temperature": 0.0, "avg_logprob": -0.1355494068514916, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.00031974463490769267}, {"id": 309, "seek": 226820, "start": 2275.8799999999997, "end": 2284.8399999999997, "text": " process model that you can consider. The ecological process model that they propose is this idea", "tokens": [50748, 1399, 2316, 300, 291, 393, 1949, 13, 440, 31054, 1399, 2316, 300, 436, 17421, 307, 341, 1558, 51196], "temperature": 0.0, "avg_logprob": -0.1355494068514916, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.00031974463490769267}, {"id": 310, "seek": 226820, "start": 2285.72, "end": 2294.2, "text": " of survival of the fittest, Darwinian processes. And so you start with variation.", "tokens": [51240, 295, 12559, 295, 264, 48876, 377, 11, 30233, 952, 7555, 13, 400, 370, 291, 722, 365, 12990, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1355494068514916, "compression_ratio": 1.6107784431137724, "no_speech_prob": 0.00031974463490769267}, {"id": 311, "seek": 229420, "start": 2294.2, "end": 2301.24, "text": " So let's take innovation. You start with many, many, many different ideas for innovation,", "tokens": [50364, 407, 718, 311, 747, 8504, 13, 509, 722, 365, 867, 11, 867, 11, 867, 819, 3487, 337, 8504, 11, 50716], "temperature": 0.0, "avg_logprob": -0.09740497816854449, "compression_ratio": 1.5664739884393064, "no_speech_prob": 0.00036182059557177126}, {"id": 312, "seek": 229420, "start": 2302.3599999999997, "end": 2307.8799999999997, "text": " but some of them fit better with the environment than others. And so the ones that do get selected", "tokens": [50772, 457, 512, 295, 552, 3318, 1101, 365, 264, 2823, 813, 2357, 13, 400, 370, 264, 2306, 300, 360, 483, 8209, 51048], "temperature": 0.0, "avg_logprob": -0.09740497816854449, "compression_ratio": 1.5664739884393064, "no_speech_prob": 0.00036182059557177126}, {"id": 313, "seek": 229420, "start": 2307.8799999999997, "end": 2313.7999999999997, "text": " and the ones that don't get thrown out. Okay, here's the third one. Unfortunately,", "tokens": [51048, 293, 264, 2306, 300, 500, 380, 483, 11732, 484, 13, 1033, 11, 510, 311, 264, 2636, 472, 13, 8590, 11, 51344], "temperature": 0.0, "avg_logprob": -0.09740497816854449, "compression_ratio": 1.5664739884393064, "no_speech_prob": 0.00036182059557177126}, {"id": 314, "seek": 231380, "start": 2314.6800000000003, "end": 2324.2000000000003, "text": " Darwinian selection applies equally to migrants' integration processes. So there are", "tokens": [50408, 30233, 952, 9450, 13165, 12309, 281, 31263, 6, 10980, 7555, 13, 407, 456, 366, 50884], "temperature": 0.0, "avg_logprob": -0.17495670965162374, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0014086209703236818}, {"id": 315, "seek": 231380, "start": 2324.2000000000003, "end": 2330.6000000000004, "text": " selection mechanisms, which mean that not all people manage to become integrated. And so the", "tokens": [50884, 9450, 15902, 11, 597, 914, 300, 406, 439, 561, 3067, 281, 1813, 10919, 13, 400, 370, 264, 51204], "temperature": 0.0, "avg_logprob": -0.17495670965162374, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0014086209703236818}, {"id": 316, "seek": 231380, "start": 2330.6000000000004, "end": 2336.52, "text": " integration is a very selective process, in fact, when you look at it carefully. But that's", "tokens": [51204, 10980, 307, 257, 588, 33930, 1399, 11, 294, 1186, 11, 562, 291, 574, 412, 309, 7500, 13, 583, 300, 311, 51500], "temperature": 0.0, "avg_logprob": -0.17495670965162374, "compression_ratio": 1.5284090909090908, "no_speech_prob": 0.0014086209703236818}, {"id": 317, "seek": 233652, "start": 2336.52, "end": 2345.96, "text": " is another model that can help explain what is going on. And then finally, the dialectic process.", "tokens": [50364, 307, 1071, 2316, 300, 393, 854, 2903, 437, 307, 516, 322, 13, 400, 550, 2721, 11, 264, 24652, 299, 1399, 13, 50836], "temperature": 0.0, "avg_logprob": -0.10464423353021796, "compression_ratio": 1.6745562130177514, "no_speech_prob": 0.0005440897075459361}, {"id": 318, "seek": 233652, "start": 2345.96, "end": 2353.48, "text": " So the whole notion of the dialectics is two systems or two sets of objectives that are in", "tokens": [50836, 407, 264, 1379, 10710, 295, 264, 24652, 1167, 307, 732, 3652, 420, 732, 6352, 295, 15961, 300, 366, 294, 51212], "temperature": 0.0, "avg_logprob": -0.10464423353021796, "compression_ratio": 1.6745562130177514, "no_speech_prob": 0.0005440897075459361}, {"id": 319, "seek": 233652, "start": 2353.48, "end": 2361.16, "text": " conflict that collide. And so the driving force of a dialectic process model is contradiction.", "tokens": [51212, 6596, 300, 49093, 13, 400, 370, 264, 4840, 3464, 295, 257, 24652, 299, 1399, 2316, 307, 34937, 13, 51596], "temperature": 0.0, "avg_logprob": -0.10464423353021796, "compression_ratio": 1.6745562130177514, "no_speech_prob": 0.0005440897075459361}, {"id": 320, "seek": 236116, "start": 2361.72, "end": 2368.68, "text": " And contradiction generates something else. What it will generate, you don't quite know.", "tokens": [50392, 400, 34937, 23815, 746, 1646, 13, 708, 309, 486, 8460, 11, 291, 500, 380, 1596, 458, 13, 50740], "temperature": 0.0, "avg_logprob": -0.14987072191740336, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.002842344343662262}, {"id": 321, "seek": 236116, "start": 2368.68, "end": 2377.08, "text": " And so this is the model that actually my colleague at Gothenburg, Bedran Omanovich and I found most", "tokens": [50740, 400, 370, 341, 307, 264, 2316, 300, 767, 452, 13532, 412, 27305, 268, 8342, 11, 19893, 4257, 422, 1601, 44844, 293, 286, 1352, 881, 51160], "temperature": 0.0, "avg_logprob": -0.14987072191740336, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.002842344343662262}, {"id": 322, "seek": 236116, "start": 2377.08, "end": 2385.72, "text": " useful. And so our model is more of a dialectic model. And the idea here, we look at the socio-political", "tokens": [51160, 4420, 13, 400, 370, 527, 2316, 307, 544, 295, 257, 24652, 299, 2316, 13, 400, 264, 1558, 510, 11, 321, 574, 412, 264, 44303, 12, 27461, 804, 51592], "temperature": 0.0, "avg_logprob": -0.14987072191740336, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.002842344343662262}, {"id": 323, "seek": 238572, "start": 2385.72, "end": 2393.7999999999997, "text": " context. We look at tensions between management interests and migrant interests, which generate", "tokens": [50364, 4319, 13, 492, 574, 412, 28303, 1296, 4592, 8847, 293, 38547, 8847, 11, 597, 8460, 50768], "temperature": 0.0, "avg_logprob": -0.12791587656194514, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.0018958307337015867}, {"id": 324, "seek": 238572, "start": 2393.7999999999997, "end": 2400.68, "text": " different factors and patterns of integration. They generate tensions. These tensions give rise to", "tokens": [50768, 819, 6771, 293, 8294, 295, 10980, 13, 814, 8460, 28303, 13, 1981, 28303, 976, 6272, 281, 51112], "temperature": 0.0, "avg_logprob": -0.12791587656194514, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.0018958307337015867}, {"id": 325, "seek": 238572, "start": 2401.3199999999997, "end": 2411.56, "text": " either transformation or perhaps reproduction, depending on the power dynamics. So a dialectic", "tokens": [51144, 2139, 9887, 420, 4317, 33934, 11, 5413, 322, 264, 1347, 15679, 13, 407, 257, 24652, 299, 51656], "temperature": 0.0, "avg_logprob": -0.12791587656194514, "compression_ratio": 1.6145251396648044, "no_speech_prob": 0.0018958307337015867}, {"id": 326, "seek": 241156, "start": 2411.56, "end": 2417.0, "text": " process model is very much oriented around process dynamics. So what you see here is, you know,", "tokens": [50364, 1399, 2316, 307, 588, 709, 21841, 926, 1399, 15679, 13, 407, 437, 291, 536, 510, 307, 11, 291, 458, 11, 50636], "temperature": 0.0, "avg_logprob": -0.10502265220464663, "compression_ratio": 1.6884422110552764, "no_speech_prob": 0.0006767190061509609}, {"id": 327, "seek": 241156, "start": 2417.0, "end": 2422.52, "text": " four kinds of a priori ways that you might think about process. And I think that these are generative.", "tokens": [50636, 1451, 3685, 295, 257, 4059, 72, 2098, 300, 291, 1062, 519, 466, 1399, 13, 400, 286, 519, 300, 613, 366, 1337, 1166, 13, 50912], "temperature": 0.0, "avg_logprob": -0.10502265220464663, "compression_ratio": 1.6884422110552764, "no_speech_prob": 0.0006767190061509609}, {"id": 328, "seek": 241156, "start": 2424.2, "end": 2428.36, "text": " And the only thing I would say is, I think there are not just four.", "tokens": [50996, 400, 264, 787, 551, 286, 576, 584, 307, 11, 286, 519, 456, 366, 406, 445, 1451, 13, 51204], "temperature": 0.0, "avg_logprob": -0.10502265220464663, "compression_ratio": 1.6884422110552764, "no_speech_prob": 0.0006767190061509609}, {"id": 329, "seek": 241156, "start": 2430.36, "end": 2435.64, "text": " So you could apply. There are many a priori process models out there.", "tokens": [51304, 407, 291, 727, 3079, 13, 821, 366, 867, 257, 4059, 72, 1399, 5245, 484, 456, 13, 51568], "temperature": 0.0, "avg_logprob": -0.10502265220464663, "compression_ratio": 1.6884422110552764, "no_speech_prob": 0.0006767190061509609}, {"id": 330, "seek": 243564, "start": 2436.04, "end": 2446.8399999999997, "text": " Vandevan and Poole would argue that all of these are combinations of these four. But sometimes it's", "tokens": [50384, 691, 11123, 9768, 293, 430, 1986, 306, 576, 9695, 300, 439, 295, 613, 366, 21267, 295, 613, 1451, 13, 583, 2171, 309, 311, 50924], "temperature": 0.0, "avg_logprob": -0.24551469507351728, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0024287377018481493}, {"id": 331, "seek": 243564, "start": 2447.8799999999997, "end": 2453.24, "text": " interesting to consider them on their own merits. So I've always found actor network theory to be", "tokens": [50976, 1880, 281, 1949, 552, 322, 641, 1065, 40923, 13, 407, 286, 600, 1009, 1352, 8747, 3209, 5261, 281, 312, 51244], "temperature": 0.0, "avg_logprob": -0.24551469507351728, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0024287377018481493}, {"id": 332, "seek": 243564, "start": 2453.24, "end": 2462.6, "text": " an interesting theory. It's a process theory that might apply here as well. So the basic idea is", "tokens": [51244, 364, 1880, 5261, 13, 467, 311, 257, 1399, 5261, 300, 1062, 3079, 510, 382, 731, 13, 407, 264, 3875, 1558, 307, 51712], "temperature": 0.0, "avg_logprob": -0.24551469507351728, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.0024287377018481493}, {"id": 333, "seek": 246260, "start": 2463.4, "end": 2470.2799999999997, "text": " taking theories and trying them out is very generative in terms of process theorizing.", "tokens": [50404, 1940, 13667, 293, 1382, 552, 484, 307, 588, 1337, 1166, 294, 2115, 295, 1399, 27423, 3319, 13, 50748], "temperature": 0.0, "avg_logprob": -0.10117870477529672, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0003980924957431853}, {"id": 334, "seek": 246260, "start": 2472.92, "end": 2480.52, "text": " This is the point I make here. The only problem, and this is if you try to impose", "tokens": [50880, 639, 307, 264, 935, 286, 652, 510, 13, 440, 787, 1154, 11, 293, 341, 307, 498, 291, 853, 281, 26952, 51260], "temperature": 0.0, "avg_logprob": -0.10117870477529672, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0003980924957431853}, {"id": 335, "seek": 246260, "start": 2481.08, "end": 2488.68, "text": " one theory onto your data and match it, what you're doing is you're just labeling things.", "tokens": [51288, 472, 5261, 3911, 428, 1412, 293, 2995, 309, 11, 437, 291, 434, 884, 307, 291, 434, 445, 40244, 721, 13, 51668], "temperature": 0.0, "avg_logprob": -0.10117870477529672, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0003980924957431853}, {"id": 336, "seek": 248868, "start": 2489.64, "end": 2498.68, "text": " And so that's why more than one or doing top down, but also doing bottom up as well is much more", "tokens": [50412, 400, 370, 300, 311, 983, 544, 813, 472, 420, 884, 1192, 760, 11, 457, 611, 884, 2767, 493, 382, 731, 307, 709, 544, 50864], "temperature": 0.0, "avg_logprob": -0.07968788676791722, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0009250622824765742}, {"id": 337, "seek": 248868, "start": 2499.56, "end": 2507.0, "text": " likely to give you something that corresponds to our ideal portrait. The danger of imposing", "tokens": [50908, 3700, 281, 976, 291, 746, 300, 23249, 281, 527, 7157, 17126, 13, 440, 4330, 295, 40288, 51280], "temperature": 0.0, "avg_logprob": -0.07968788676791722, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0009250622824765742}, {"id": 338, "seek": 248868, "start": 2507.0, "end": 2513.64, "text": " one model is that you end up with the richness squeezed out. Looking at several, you can tell,", "tokens": [51280, 472, 2316, 307, 300, 291, 917, 493, 365, 264, 44506, 39470, 484, 13, 11053, 412, 2940, 11, 291, 393, 980, 11, 51612], "temperature": 0.0, "avg_logprob": -0.07968788676791722, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0009250622824765742}, {"id": 339, "seek": 248868, "start": 2513.64, "end": 2517.72, "text": " I mean, if you could look at my diagram, you could see that you would get several different", "tokens": [51612, 286, 914, 11, 498, 291, 727, 574, 412, 452, 10686, 11, 291, 727, 536, 300, 291, 576, 483, 2940, 819, 51816], "temperature": 0.0, "avg_logprob": -0.07968788676791722, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0009250622824765742}, {"id": 340, "seek": 251772, "start": 2517.72, "end": 2523.56, "text": " circles on there, and that might on the left, on the bubble on the left, and that might do a better", "tokens": [50364, 13040, 322, 456, 11, 293, 300, 1062, 322, 264, 1411, 11, 322, 264, 12212, 322, 264, 1411, 11, 293, 300, 1062, 360, 257, 1101, 50656], "temperature": 0.0, "avg_logprob": -0.1385810669154337, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.00021990165987517685}, {"id": 341, "seek": 251772, "start": 2523.56, "end": 2535.7999999999997, "text": " job of understanding your whole process. So again, this is not a mechanical linear exercise, and", "tokens": [50656, 1691, 295, 3701, 428, 1379, 1399, 13, 407, 797, 11, 341, 307, 406, 257, 12070, 8213, 5380, 11, 293, 51268], "temperature": 0.0, "avg_logprob": -0.1385810669154337, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.00021990165987517685}, {"id": 342, "seek": 251772, "start": 2535.7999999999997, "end": 2543.0, "text": " there's a lot of value of iterating with the ground at the bottom up coding as well. And then", "tokens": [51268, 456, 311, 257, 688, 295, 2158, 295, 17138, 990, 365, 264, 2727, 412, 264, 2767, 493, 17720, 382, 731, 13, 400, 550, 51628], "temperature": 0.0, "avg_logprob": -0.1385810669154337, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.00021990165987517685}, {"id": 343, "seek": 254300, "start": 2543.0, "end": 2550.36, "text": " that sort of raises the question, how do you do this? Because you're doing bottom up, you might be", "tokens": [50364, 300, 1333, 295, 19658, 264, 1168, 11, 577, 360, 291, 360, 341, 30, 1436, 291, 434, 884, 2767, 493, 11, 291, 1062, 312, 50732], "temperature": 0.0, "avg_logprob": -0.130880126953125, "compression_ratio": 1.465, "no_speech_prob": 0.0003405225579626858}, {"id": 344, "seek": 254300, "start": 2550.36, "end": 2556.2, "text": " doing some top down coding as well. And I have another example here, which kind of is really", "tokens": [50732, 884, 512, 1192, 760, 17720, 382, 731, 13, 400, 286, 362, 1071, 1365, 510, 11, 597, 733, 295, 307, 534, 51024], "temperature": 0.0, "avg_logprob": -0.130880126953125, "compression_ratio": 1.465, "no_speech_prob": 0.0003405225579626858}, {"id": 345, "seek": 254300, "start": 2556.2, "end": 2565.24, "text": " interesting. It's a paper by Kaplan and Olikowski, where I think the reviewers of the paper must have", "tokens": [51024, 1880, 13, 467, 311, 257, 3035, 538, 10988, 16554, 293, 6141, 1035, 21866, 11, 689, 286, 519, 264, 45837, 295, 264, 3035, 1633, 362, 51476], "temperature": 0.0, "avg_logprob": -0.130880126953125, "compression_ratio": 1.465, "no_speech_prob": 0.0003405225579626858}, {"id": 346, "seek": 256524, "start": 2565.24, "end": 2575.3999999999996, "text": " asked them to explain that coding process. And so they've introduced this diagram in an appendix,", "tokens": [50364, 2351, 552, 281, 2903, 300, 17720, 1399, 13, 400, 370, 436, 600, 7268, 341, 10686, 294, 364, 34116, 970, 11, 50872], "temperature": 0.0, "avg_logprob": -0.15599058613632666, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.0052172038704156876}, {"id": 347, "seek": 256524, "start": 2575.3999999999996, "end": 2581.56, "text": " which explains that coding process. And their final model is the little diagram in the bottom", "tokens": [50872, 597, 13948, 300, 17720, 1399, 13, 400, 641, 2572, 2316, 307, 264, 707, 10686, 294, 264, 2767, 51180], "temperature": 0.0, "avg_logprob": -0.15599058613632666, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.0052172038704156876}, {"id": 348, "seek": 256524, "start": 2581.56, "end": 2590.2, "text": " right of that picture. And what you see all of the circles, you know, where the circles going", "tokens": [51180, 558, 295, 300, 3036, 13, 400, 437, 291, 536, 439, 295, 264, 13040, 11, 291, 458, 11, 689, 264, 13040, 516, 51612], "temperature": 0.0, "avg_logprob": -0.15599058613632666, "compression_ratio": 1.7065868263473054, "no_speech_prob": 0.0052172038704156876}, {"id": 349, "seek": 259020, "start": 2590.2, "end": 2600.7599999999998, "text": " around is showing how they iterated between bottom up coding of their data, going to the literature,", "tokens": [50364, 926, 307, 4099, 577, 436, 17138, 770, 1296, 2767, 493, 17720, 295, 641, 1412, 11, 516, 281, 264, 10394, 11, 50892], "temperature": 0.0, "avg_logprob": -0.07102695207917288, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0016476192977279425}, {"id": 350, "seek": 259020, "start": 2600.7599999999998, "end": 2607.24, "text": " finding a theory that might help, and then doing coding based on the theory that they had found,", "tokens": [50892, 5006, 257, 5261, 300, 1062, 854, 11, 293, 550, 884, 17720, 2361, 322, 264, 5261, 300, 436, 632, 1352, 11, 51216], "temperature": 0.0, "avg_logprob": -0.07102695207917288, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0016476192977279425}, {"id": 351, "seek": 259020, "start": 2607.24, "end": 2613.08, "text": " and doing this iteratively multiple times. And they're trying to describe here the exact process", "tokens": [51216, 293, 884, 341, 17138, 19020, 3866, 1413, 13, 400, 436, 434, 1382, 281, 6786, 510, 264, 1900, 1399, 51508], "temperature": 0.0, "avg_logprob": -0.07102695207917288, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0016476192977279425}, {"id": 352, "seek": 259020, "start": 2613.08, "end": 2619.08, "text": " that they went through to arrive at the particular theory they ended up with. So this is a really nice", "tokens": [51508, 300, 436, 1437, 807, 281, 8881, 412, 264, 1729, 5261, 436, 4590, 493, 365, 13, 407, 341, 307, 257, 534, 1481, 51808], "temperature": 0.0, "avg_logprob": -0.07102695207917288, "compression_ratio": 1.7336244541484715, "no_speech_prob": 0.0016476192977279425}, {"id": 353, "seek": 261908, "start": 2619.08, "end": 2626.7599999999998, "text": " illustration of what it really looks like, something of what it really looks like to engage in coding", "tokens": [50364, 22645, 295, 437, 309, 534, 1542, 411, 11, 746, 295, 437, 309, 534, 1542, 411, 281, 4683, 294, 17720, 50748], "temperature": 0.0, "avg_logprob": -0.09842505079976628, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0013665485894307494}, {"id": 354, "seek": 261908, "start": 2626.7599999999998, "end": 2635.4, "text": " of process data. And increasingly, actually, seeing diagrams like this appear in articles,", "tokens": [50748, 295, 1399, 1412, 13, 400, 12980, 11, 767, 11, 2577, 36709, 411, 341, 4204, 294, 11290, 11, 51180], "temperature": 0.0, "avg_logprob": -0.09842505079976628, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0013665485894307494}, {"id": 355, "seek": 261908, "start": 2635.4, "end": 2641.96, "text": " because people are being asked to explain, well, how did you do this? Actually, how did you take", "tokens": [51180, 570, 561, 366, 885, 2351, 281, 2903, 11, 731, 11, 577, 630, 291, 360, 341, 30, 5135, 11, 577, 630, 291, 747, 51508], "temperature": 0.0, "avg_logprob": -0.09842505079976628, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0013665485894307494}, {"id": 356, "seek": 261908, "start": 2641.96, "end": 2648.52, "text": " theory that is out there, combine it with the data that you have to produce something new? And so", "tokens": [51508, 5261, 300, 307, 484, 456, 11, 10432, 309, 365, 264, 1412, 300, 291, 362, 281, 5258, 746, 777, 30, 400, 370, 51836], "temperature": 0.0, "avg_logprob": -0.09842505079976628, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0013665485894307494}, {"id": 357, "seek": 264852, "start": 2648.52, "end": 2655.88, "text": " this is the combination, I think that is important. So I'm going to stop here", "tokens": [50364, 341, 307, 264, 6562, 11, 286, 519, 300, 307, 1021, 13, 407, 286, 478, 516, 281, 1590, 510, 50732], "temperature": 0.0, "avg_logprob": -0.251352173941476, "compression_ratio": 1.35, "no_speech_prob": 0.00042342505184933543}, {"id": 358, "seek": 264852, "start": 2658.92, "end": 2667.0, "text": " for a moment, and stop share, and see if we have", "tokens": [50884, 337, 257, 1623, 11, 293, 1590, 2073, 11, 293, 536, 498, 321, 362, 51288], "temperature": 0.0, "avg_logprob": -0.251352173941476, "compression_ratio": 1.35, "no_speech_prob": 0.00042342505184933543}, {"id": 359, "seek": 264852, "start": 2669.4, "end": 2672.52, "text": " some questions. So I can see a lot.", "tokens": [51408, 512, 1651, 13, 407, 286, 393, 536, 257, 688, 13, 51564], "temperature": 0.0, "avg_logprob": -0.251352173941476, "compression_ratio": 1.35, "no_speech_prob": 0.00042342505184933543}, {"id": 360, "seek": 267252, "start": 2673.32, "end": 2682.44, "text": " Yes. Thank you so much, Ann, for the presentation and for all the information. It's been super", "tokens": [50404, 1079, 13, 1044, 291, 370, 709, 11, 8860, 11, 337, 264, 5860, 293, 337, 439, 264, 1589, 13, 467, 311, 668, 1687, 50860], "temperature": 0.0, "avg_logprob": -0.11546324574670126, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010478462791070342}, {"id": 361, "seek": 267252, "start": 2682.44, "end": 2688.04, "text": " helpful. I have two questions. One is a clarifying question, and then the other one is also for", "tokens": [50860, 4961, 13, 286, 362, 732, 1651, 13, 1485, 307, 257, 6093, 5489, 1168, 11, 293, 550, 264, 661, 472, 307, 611, 337, 51140], "temperature": 0.0, "avg_logprob": -0.11546324574670126, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010478462791070342}, {"id": 362, "seek": 267252, "start": 2688.04, "end": 2694.2, "text": " recommendation. So maybe I start with the clarification question. So you spoke about", "tokens": [51140, 11879, 13, 407, 1310, 286, 722, 365, 264, 34449, 1168, 13, 407, 291, 7179, 466, 51448], "temperature": 0.0, "avg_logprob": -0.11546324574670126, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010478462791070342}, {"id": 363, "seek": 267252, "start": 2694.2, "end": 2699.48, "text": " alternate templates, and it's something that I've actually thought about quite a bit.", "tokens": [51448, 18873, 21165, 11, 293, 309, 311, 746, 300, 286, 600, 767, 1194, 466, 1596, 257, 857, 13, 51712], "temperature": 0.0, "avg_logprob": -0.11546324574670126, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0010478462791070342}, {"id": 364, "seek": 269948, "start": 2699.88, "end": 2707.64, "text": " I'm not doing a process study, or I'm not doing a study with process data, but I do find all the", "tokens": [50384, 286, 478, 406, 884, 257, 1399, 2979, 11, 420, 286, 478, 406, 884, 257, 2979, 365, 1399, 1412, 11, 457, 286, 360, 915, 439, 264, 50772], "temperature": 0.0, "avg_logprob": -0.1480035890232433, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0018379930406808853}, {"id": 365, "seek": 269948, "start": 2707.64, "end": 2713.88, "text": " strategies you've mentioned very useful. I thought that alternate, or at least from my", "tokens": [50772, 9029, 291, 600, 2835, 588, 4420, 13, 286, 1194, 300, 18873, 11, 420, 412, 1935, 490, 452, 51084], "temperature": 0.0, "avg_logprob": -0.1480035890232433, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0018379930406808853}, {"id": 366, "seek": 269948, "start": 2713.88, "end": 2720.2, "text": " perception, I feel like almost every qualitative study would at some point in time come across", "tokens": [51084, 12860, 11, 286, 841, 411, 1920, 633, 31312, 2979, 576, 412, 512, 935, 294, 565, 808, 2108, 51400], "temperature": 0.0, "avg_logprob": -0.1480035890232433, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0018379930406808853}, {"id": 367, "seek": 269948, "start": 2720.2, "end": 2726.36, "text": " alternate templates, because you do try a lot of different things to see what fits your data.", "tokens": [51400, 18873, 21165, 11, 570, 291, 360, 853, 257, 688, 295, 819, 721, 281, 536, 437, 9001, 428, 1412, 13, 51708], "temperature": 0.0, "avg_logprob": -0.1480035890232433, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0018379930406808853}, {"id": 368, "seek": 272636, "start": 2727.08, "end": 2734.28, "text": " So from the back of my mind, I felt like it's kind of intuitive, but you mentioned that it's", "tokens": [50400, 407, 490, 264, 646, 295, 452, 1575, 11, 286, 2762, 411, 309, 311, 733, 295, 21769, 11, 457, 291, 2835, 300, 309, 311, 50760], "temperature": 0.0, "avg_logprob": -0.08238269488016764, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.004752476233989}, {"id": 369, "seek": 272636, "start": 2734.28, "end": 2740.2000000000003, "text": " not used often. So that made me feel like, okay, maybe I didn't understand what you meant by", "tokens": [50760, 406, 1143, 2049, 13, 407, 300, 1027, 385, 841, 411, 11, 1392, 11, 1310, 286, 994, 380, 1223, 437, 291, 4140, 538, 51056], "temperature": 0.0, "avg_logprob": -0.08238269488016764, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.004752476233989}, {"id": 370, "seek": 272636, "start": 2740.2000000000003, "end": 2748.6, "text": " alternate templates well enough. So is it really just trying different theoretical lenses to see", "tokens": [51056, 18873, 21165, 731, 1547, 13, 407, 307, 309, 534, 445, 1382, 819, 20864, 18059, 281, 536, 51476], "temperature": 0.0, "avg_logprob": -0.08238269488016764, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.004752476233989}, {"id": 371, "seek": 272636, "start": 2748.6, "end": 2755.0, "text": " which one fits your data in the analysis process, or like what you displayed, where the authors", "tokens": [51476, 597, 472, 9001, 428, 1412, 294, 264, 5215, 1399, 11, 420, 411, 437, 291, 16372, 11, 689, 264, 16552, 51796], "temperature": 0.0, "avg_logprob": -0.08238269488016764, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.004752476233989}, {"id": 372, "seek": 275500, "start": 2755.0, "end": 2762.2, "text": " eventually in their final output also explain each of these theoretical lenses and then argue", "tokens": [50364, 4728, 294, 641, 2572, 5598, 611, 2903, 1184, 295, 613, 20864, 18059, 293, 550, 9695, 50724], "temperature": 0.0, "avg_logprob": -0.1528329849243164, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00014647882198914886}, {"id": 373, "seek": 275500, "start": 2762.2, "end": 2769.88, "text": " for each one, which one qualifies as alternate templates? Yeah, so I mean, a study that would", "tokens": [50724, 337, 1184, 472, 11, 597, 472, 4101, 11221, 382, 18873, 21165, 30, 865, 11, 370, 286, 914, 11, 257, 2979, 300, 576, 51108], "temperature": 0.0, "avg_logprob": -0.1528329849243164, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00014647882198914886}, {"id": 374, "seek": 275500, "start": 2770.84, "end": 2779.24, "text": " really, I would consider to be an alternate template study would show the different templates", "tokens": [51156, 534, 11, 286, 576, 1949, 281, 312, 364, 18873, 12379, 2979, 576, 855, 264, 819, 21165, 51576], "temperature": 0.0, "avg_logprob": -0.1528329849243164, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00014647882198914886}, {"id": 375, "seek": 275500, "start": 2780.12, "end": 2784.52, "text": " in their study and say, I looked at my data according to three different theories,", "tokens": [51620, 294, 641, 2979, 293, 584, 11, 286, 2956, 412, 452, 1412, 4650, 281, 1045, 819, 13667, 11, 51840], "temperature": 0.0, "avg_logprob": -0.1528329849243164, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00014647882198914886}, {"id": 376, "seek": 278452, "start": 2784.52, "end": 2789.08, "text": " here's what happens when you take this one, here's what happens when you take that one,", "tokens": [50364, 510, 311, 437, 2314, 562, 291, 747, 341, 472, 11, 510, 311, 437, 2314, 562, 291, 747, 300, 472, 11, 50592], "temperature": 0.0, "avg_logprob": -0.08612646955124875, "compression_ratio": 2.111731843575419, "no_speech_prob": 0.00031974251032806933}, {"id": 377, "seek": 278452, "start": 2789.08, "end": 2794.6, "text": " here's what happens when you take the third one, or they could be four or that could be two. So", "tokens": [50592, 510, 311, 437, 2314, 562, 291, 747, 264, 2636, 472, 11, 420, 436, 727, 312, 1451, 420, 300, 727, 312, 732, 13, 407, 50868], "temperature": 0.0, "avg_logprob": -0.08612646955124875, "compression_ratio": 2.111731843575419, "no_speech_prob": 0.00031974251032806933}, {"id": 378, "seek": 278452, "start": 2794.6, "end": 2800.6, "text": " it provides different accounts. So if you were going to use that in a study, it would provide", "tokens": [50868, 309, 6417, 819, 9402, 13, 407, 498, 291, 645, 516, 281, 764, 300, 294, 257, 2979, 11, 309, 576, 2893, 51168], "temperature": 0.0, "avg_logprob": -0.08612646955124875, "compression_ratio": 2.111731843575419, "no_speech_prob": 0.00031974251032806933}, {"id": 379, "seek": 278452, "start": 2800.6, "end": 2806.6, "text": " different accounts. But that doesn't mean, and I was perhaps confusing about that, that doesn't mean", "tokens": [51168, 819, 9402, 13, 583, 300, 1177, 380, 914, 11, 293, 286, 390, 4317, 13181, 466, 300, 11, 300, 1177, 380, 914, 51468], "temperature": 0.0, "avg_logprob": -0.08612646955124875, "compression_ratio": 2.111731843575419, "no_speech_prob": 0.00031974251032806933}, {"id": 380, "seek": 280660, "start": 2806.6, "end": 2814.36, "text": " that a researcher might not be doing this in the background, anyway. But when it comes to", "tokens": [50364, 300, 257, 21751, 1062, 406, 312, 884, 341, 294, 264, 3678, 11, 4033, 13, 583, 562, 309, 1487, 281, 50752], "temperature": 0.0, "avg_logprob": -0.12981682635368186, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.012811034917831421}, {"id": 381, "seek": 280660, "start": 2814.36, "end": 2819.7999999999997, "text": " actually write the paper, that's kind of as if all of that variety might disappear, because you", "tokens": [50752, 767, 2464, 264, 3035, 11, 300, 311, 733, 295, 382, 498, 439, 295, 300, 5673, 1062, 11596, 11, 570, 291, 51024], "temperature": 0.0, "avg_logprob": -0.12981682635368186, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.012811034917831421}, {"id": 382, "seek": 280660, "start": 2819.7999999999997, "end": 2824.92, "text": " have picked the one that's going to work, you don't have room to describe all the other alternatives", "tokens": [51024, 362, 6183, 264, 472, 300, 311, 516, 281, 589, 11, 291, 500, 380, 362, 1808, 281, 6786, 439, 264, 661, 20478, 51280], "temperature": 0.0, "avg_logprob": -0.12981682635368186, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.012811034917831421}, {"id": 383, "seek": 280660, "start": 2824.92, "end": 2835.08, "text": " you look at, so you go for one. Yeah, so and the one is usually a combination of both the top", "tokens": [51280, 291, 574, 412, 11, 370, 291, 352, 337, 472, 13, 865, 11, 370, 293, 264, 472, 307, 2673, 257, 6562, 295, 1293, 264, 1192, 51788], "temperature": 0.0, "avg_logprob": -0.12981682635368186, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.012811034917831421}, {"id": 384, "seek": 283508, "start": 2835.08, "end": 2843.7999999999997, "text": " down and bottom up in practice, because you take your model, you apply it, and it doesn't quite", "tokens": [50364, 760, 293, 2767, 493, 294, 3124, 11, 570, 291, 747, 428, 2316, 11, 291, 3079, 309, 11, 293, 309, 1177, 380, 1596, 50800], "temperature": 0.0, "avg_logprob": -0.10023010798863002, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.006480013951659203}, {"id": 385, "seek": 283508, "start": 2843.7999999999997, "end": 2851.08, "text": " work. And so you enable you to introduce new things, or if you're going bottom up, you do", "tokens": [50800, 589, 13, 400, 370, 291, 9528, 291, 281, 5366, 777, 721, 11, 420, 498, 291, 434, 516, 2767, 493, 11, 291, 360, 51164], "temperature": 0.0, "avg_logprob": -0.10023010798863002, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.006480013951659203}, {"id": 386, "seek": 283508, "start": 2851.08, "end": 2855.72, "text": " something, and you think, oh, yes, I found this, and then you have to look in the literature.", "tokens": [51164, 746, 11, 293, 291, 519, 11, 1954, 11, 2086, 11, 286, 1352, 341, 11, 293, 550, 291, 362, 281, 574, 294, 264, 10394, 13, 51396], "temperature": 0.0, "avg_logprob": -0.10023010798863002, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.006480013951659203}, {"id": 387, "seek": 283508, "start": 2856.2799999999997, "end": 2861.72, "text": " And you see, well, the literature also found that. So is that new? I mean, what is it I'm adding?", "tokens": [51424, 400, 291, 536, 11, 731, 11, 264, 10394, 611, 1352, 300, 13, 407, 307, 300, 777, 30, 286, 914, 11, 437, 307, 309, 286, 478, 5127, 30, 51696], "temperature": 0.0, "avg_logprob": -0.10023010798863002, "compression_ratio": 1.668141592920354, "no_speech_prob": 0.006480013951659203}, {"id": 388, "seek": 286172, "start": 2861.72, "end": 2867.72, "text": " So it's this back and forth that's, that's important in the doing, but in the presenting,", "tokens": [50364, 407, 309, 311, 341, 646, 293, 5220, 300, 311, 11, 300, 311, 1021, 294, 264, 884, 11, 457, 294, 264, 15578, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10469433633904708, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.0006157269817776978}, {"id": 389, "seek": 286172, "start": 2868.3599999999997, "end": 2875.16, "text": " alternate templates is very rare. Okay, okay, thank you so much for clarifying. The second question", "tokens": [50696, 18873, 21165, 307, 588, 5892, 13, 1033, 11, 1392, 11, 1309, 291, 370, 709, 337, 6093, 5489, 13, 440, 1150, 1168, 51036], "temperature": 0.0, "avg_logprob": -0.10469433633904708, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.0006157269817776978}, {"id": 390, "seek": 286172, "start": 2875.72, "end": 2882.2, "text": " is that, like I mentioned, I don't specifically use process data, but I do find all your strategies", "tokens": [51064, 307, 300, 11, 411, 286, 2835, 11, 286, 500, 380, 4682, 764, 1399, 1412, 11, 457, 286, 360, 915, 439, 428, 9029, 51388], "temperature": 0.0, "avg_logprob": -0.10469433633904708, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.0006157269817776978}, {"id": 391, "seek": 286172, "start": 2882.2, "end": 2891.0, "text": " quite helpful. But I realized that in qualitative, in the qualitative community as well, it's very", "tokens": [51388, 1596, 4961, 13, 583, 286, 5334, 300, 294, 31312, 11, 294, 264, 31312, 1768, 382, 731, 11, 309, 311, 588, 51828], "temperature": 0.0, "avg_logprob": -0.10469433633904708, "compression_ratio": 1.583673469387755, "no_speech_prob": 0.0006157269817776978}, {"id": 392, "seek": 289100, "start": 2891.0, "end": 2899.4, "text": " important who you cite on what studies. And I can imagine that citing process methods papers in a", "tokens": [50364, 1021, 567, 291, 37771, 322, 437, 5313, 13, 400, 286, 393, 3811, 300, 48749, 1399, 7150, 10577, 294, 257, 50784], "temperature": 0.0, "avg_logprob": -0.1108383983373642, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0014546946622431278}, {"id": 393, "seek": 289100, "start": 2900.36, "end": 2906.92, "text": " study with variance data could be problematic, but I still haven't quite found, or maybe I haven't", "tokens": [50832, 2979, 365, 21977, 1412, 727, 312, 19011, 11, 457, 286, 920, 2378, 380, 1596, 1352, 11, 420, 1310, 286, 2378, 380, 51160], "temperature": 0.0, "avg_logprob": -0.1108383983373642, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0014546946622431278}, {"id": 394, "seek": 289100, "start": 2906.92, "end": 2915.32, "text": " recognized other resources, which talk about similar strategies for, for variance data, maybe", "tokens": [51160, 9823, 661, 3593, 11, 597, 751, 466, 2531, 9029, 337, 11, 337, 21977, 1412, 11, 1310, 51580], "temperature": 0.0, "avg_logprob": -0.1108383983373642, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0014546946622431278}, {"id": 395, "seek": 291532, "start": 2915.32, "end": 2921.0800000000004, "text": " accept ground of theory and, yeah, accept ground of theory. So I was wondering if you have any", "tokens": [50364, 3241, 2727, 295, 5261, 293, 11, 1338, 11, 3241, 2727, 295, 5261, 13, 407, 286, 390, 6359, 498, 291, 362, 604, 50652], "temperature": 0.0, "avg_logprob": -0.1075875957806905, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.005299372598528862}, {"id": 396, "seek": 291532, "start": 2921.0800000000004, "end": 2929.4, "text": " recommendations on, first of all, would it be right, or if it would be right, how to couch it in a", "tokens": [50652, 10434, 322, 11, 700, 295, 439, 11, 576, 309, 312, 558, 11, 420, 498, 309, 576, 312, 558, 11, 577, 281, 16511, 309, 294, 257, 51068], "temperature": 0.0, "avg_logprob": -0.1075875957806905, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.005299372598528862}, {"id": 397, "seek": 291532, "start": 2929.4, "end": 2936.84, "text": " paper, if you are borrowing from a different area of qualitative methods for your approach. So if I", "tokens": [51068, 3035, 11, 498, 291, 366, 35024, 490, 257, 819, 1859, 295, 31312, 7150, 337, 428, 3109, 13, 407, 498, 286, 51440], "temperature": 0.0, "avg_logprob": -0.1075875957806905, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.005299372598528862}, {"id": 398, "seek": 291532, "start": 2936.84, "end": 2943.96, "text": " would want to say that I used alternate templates as recommended by Anne Langley, and then I cite", "tokens": [51440, 576, 528, 281, 584, 300, 286, 1143, 18873, 21165, 382, 9628, 538, 13706, 13313, 3420, 11, 293, 550, 286, 37771, 51796], "temperature": 0.0, "avg_logprob": -0.1075875957806905, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.005299372598528862}, {"id": 399, "seek": 294396, "start": 2944.04, "end": 2949.2400000000002, "text": " your paper, but then it's not a process study that could be problematic. So how could I couch it so", "tokens": [50368, 428, 3035, 11, 457, 550, 309, 311, 406, 257, 1399, 2979, 300, 727, 312, 19011, 13, 407, 577, 727, 286, 16511, 309, 370, 50628], "temperature": 0.0, "avg_logprob": -0.08671526033051159, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.00050317746354267}, {"id": 400, "seek": 294396, "start": 2949.2400000000002, "end": 2955.0, "text": " that it's, it doesn't come across as problematic? Or if I can't do that, then do you have any", "tokens": [50628, 300, 309, 311, 11, 309, 1177, 380, 808, 2108, 382, 19011, 30, 1610, 498, 286, 393, 380, 360, 300, 11, 550, 360, 291, 362, 604, 50916], "temperature": 0.0, "avg_logprob": -0.08671526033051159, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.00050317746354267}, {"id": 401, "seek": 294396, "start": 2955.0, "end": 2962.04, "text": " recommendations on other resources to consult? I would not worry if you cited me for alternate", "tokens": [50916, 10434, 322, 661, 3593, 281, 7189, 30, 286, 576, 406, 3292, 498, 291, 30134, 385, 337, 18873, 51268], "temperature": 0.0, "avg_logprob": -0.08671526033051159, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.00050317746354267}, {"id": 402, "seek": 294396, "start": 2962.04, "end": 2967.64, "text": " templates for any study. And in fact, when I, when I teach qualitative methods, I use this paper,", "tokens": [51268, 21165, 337, 604, 2979, 13, 400, 294, 1186, 11, 562, 286, 11, 562, 286, 2924, 31312, 7150, 11, 286, 764, 341, 3035, 11, 51548], "temperature": 0.0, "avg_logprob": -0.08671526033051159, "compression_ratio": 1.6218487394957983, "no_speech_prob": 0.00050317746354267}, {"id": 403, "seek": 296764, "start": 2967.64, "end": 2975.3199999999997, "text": " and many of the most, many of the strategies make sense for other kinds of qualitative data,", "tokens": [50364, 293, 867, 295, 264, 881, 11, 867, 295, 264, 9029, 652, 2020, 337, 661, 3685, 295, 31312, 1412, 11, 50748], "temperature": 0.0, "avg_logprob": -0.08602636154383829, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.00011589056521188468}, {"id": 404, "seek": 296764, "start": 2975.3199999999997, "end": 2981.64, "text": " even if you're doing a variance study, some of them don't quite so much. So, so things like", "tokens": [50748, 754, 498, 291, 434, 884, 257, 21977, 2979, 11, 512, 295, 552, 500, 380, 1596, 370, 709, 13, 407, 11, 370, 721, 411, 51064], "temperature": 0.0, "avg_logprob": -0.08602636154383829, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.00011589056521188468}, {"id": 405, "seek": 296764, "start": 2981.64, "end": 2990.2, "text": " temporal bracketing, it's all about time. So it doesn't necessarily make so much sense. And, and", "tokens": [51064, 30881, 12305, 9880, 11, 309, 311, 439, 466, 565, 13, 407, 309, 1177, 380, 4725, 652, 370, 709, 2020, 13, 400, 11, 293, 51492], "temperature": 0.0, "avg_logprob": -0.08602636154383829, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.00011589056521188468}, {"id": 406, "seek": 299020, "start": 2990.2799999999997, "end": 2997.48, "text": " so it depends. When, when I first wrote this paper, I was struggling with what to do with", "tokens": [50368, 370, 309, 5946, 13, 1133, 11, 562, 286, 700, 4114, 341, 3035, 11, 286, 390, 9314, 365, 437, 281, 360, 365, 50728], "temperature": 0.0, "avg_logprob": -0.07799673792141587, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.0004875122685916722}, {"id": 407, "seek": 299020, "start": 2997.48, "end": 3004.2799999999997, "text": " process data specifically. And so I was looking for solutions to that. But in terms of resources,", "tokens": [50728, 1399, 1412, 4682, 13, 400, 370, 286, 390, 1237, 337, 6547, 281, 300, 13, 583, 294, 2115, 295, 3593, 11, 51068], "temperature": 0.0, "avg_logprob": -0.07799673792141587, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.0004875122685916722}, {"id": 408, "seek": 299020, "start": 3007.64, "end": 3011.8799999999997, "text": " I mean, I could recommend a few things. So, so there is a very recent", "tokens": [51236, 286, 914, 11, 286, 727, 2748, 257, 1326, 721, 13, 407, 11, 370, 456, 307, 257, 588, 5162, 51448], "temperature": 0.0, "avg_logprob": -0.07799673792141587, "compression_ratio": 1.4438202247191012, "no_speech_prob": 0.0004875122685916722}, {"id": 409, "seek": 301188, "start": 3012.6, "end": 3022.04, "text": " issue, special issue of organizational research methods. I think the title is Beyond Templates.", "tokens": [50400, 2734, 11, 2121, 2734, 295, 24730, 2132, 7150, 13, 286, 519, 264, 4876, 307, 19707, 39563, 1024, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1811019875282465, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.002798196393996477}, {"id": 410, "seek": 301188, "start": 3023.1600000000003, "end": 3034.52, "text": " So, but the, the, the issue is extremely helpful in offering a range of other ways", "tokens": [50928, 407, 11, 457, 264, 11, 264, 11, 264, 2734, 307, 4664, 4961, 294, 8745, 257, 3613, 295, 661, 2098, 51496], "temperature": 0.0, "avg_logprob": -0.1811019875282465, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.002798196393996477}, {"id": 411, "seek": 303452, "start": 3035.08, "end": 3042.28, "text": " of analyzing qualitative data. And so it, it, it really tries to get beyond the idea that", "tokens": [50392, 295, 23663, 31312, 1412, 13, 400, 370, 309, 11, 309, 11, 309, 534, 9898, 281, 483, 4399, 264, 1558, 300, 50752], "temperature": 0.0, "avg_logprob": -0.15911525569549978, "compression_ratio": 1.4845360824742269, "no_speech_prob": 0.01851578615605831}, {"id": 412, "seek": 303452, "start": 3042.28, "end": 3049.88, "text": " here's a recipe that you just apply. And, and tries to look for more complex ways. One of the papers", "tokens": [50752, 510, 311, 257, 6782, 300, 291, 445, 3079, 13, 400, 11, 293, 9898, 281, 574, 337, 544, 3997, 2098, 13, 1485, 295, 264, 10577, 51132], "temperature": 0.0, "avg_logprob": -0.15911525569549978, "compression_ratio": 1.4845360824742269, "no_speech_prob": 0.01851578615605831}, {"id": 413, "seek": 303452, "start": 3049.88, "end": 3059.24, "text": " that I really find resonates with me, it talks about Brickolash, which is putting things together", "tokens": [51132, 300, 286, 534, 915, 41051, 365, 385, 11, 309, 6686, 466, 1603, 618, 401, 1299, 11, 597, 307, 3372, 721, 1214, 51600], "temperature": 0.0, "avg_logprob": -0.15911525569549978, "compression_ratio": 1.4845360824742269, "no_speech_prob": 0.01851578615605831}, {"id": 414, "seek": 305924, "start": 3059.24, "end": 3068.04, "text": " that seem to be helpful. And I'm really, you know, strategies for theorizing from process data is", "tokens": [50364, 300, 1643, 281, 312, 4961, 13, 400, 286, 478, 534, 11, 291, 458, 11, 9029, 337, 27423, 3319, 490, 1399, 1412, 307, 50804], "temperature": 0.0, "avg_logprob": -0.0840548473400074, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.000709479907527566}, {"id": 415, "seek": 305924, "start": 3068.04, "end": 3074.9199999999996, "text": " actually recommending some kind of Brickolash as well. But, but, but the Brickolash paper is", "tokens": [50804, 767, 30559, 512, 733, 295, 1603, 618, 401, 1299, 382, 731, 13, 583, 11, 457, 11, 457, 264, 1603, 618, 401, 1299, 3035, 307, 51148], "temperature": 0.0, "avg_logprob": -0.0840548473400074, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.000709479907527566}, {"id": 416, "seek": 305924, "start": 3074.9199999999996, "end": 3080.9199999999996, "text": " particularly helpful, I think, in terms of suggesting different ways. And they give examples", "tokens": [51148, 4098, 4961, 11, 286, 519, 11, 294, 2115, 295, 18094, 819, 2098, 13, 400, 436, 976, 5110, 51448], "temperature": 0.0, "avg_logprob": -0.0840548473400074, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.000709479907527566}, {"id": 417, "seek": 305924, "start": 3080.9199999999996, "end": 3086.68, "text": " from their own research. But every individual is putting different things together. So it's,", "tokens": [51448, 490, 641, 1065, 2132, 13, 583, 633, 2609, 307, 3372, 819, 721, 1214, 13, 407, 309, 311, 11, 51736], "temperature": 0.0, "avg_logprob": -0.0840548473400074, "compression_ratio": 1.5732217573221758, "no_speech_prob": 0.000709479907527566}, {"id": 418, "seek": 308668, "start": 3086.68, "end": 3091.3999999999996, "text": " it's not a recipe. It's not a recipe, but it's a very useful citation and", "tokens": [50364, 309, 311, 406, 257, 6782, 13, 467, 311, 406, 257, 6782, 11, 457, 309, 311, 257, 588, 4420, 45590, 293, 50600], "temperature": 0.0, "avg_logprob": -0.1497094794495465, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.0006766183651052415}, {"id": 419, "seek": 308668, "start": 3093.72, "end": 3097.16, "text": " helpful in justifying your approach, I think, whatever you're doing.", "tokens": [50716, 4961, 294, 445, 5489, 428, 3109, 11, 286, 519, 11, 2035, 291, 434, 884, 13, 50888], "temperature": 0.0, "avg_logprob": -0.1497094794495465, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.0006766183651052415}, {"id": 420, "seek": 308668, "start": 3098.2799999999997, "end": 3102.12, "text": " Thank you so much, Anne. Ravi?", "tokens": [50944, 1044, 291, 370, 709, 11, 13706, 13, 44486, 30, 51136], "temperature": 0.0, "avg_logprob": -0.1497094794495465, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.0006766183651052415}, {"id": 421, "seek": 308668, "start": 3103.48, "end": 3108.7599999999998, "text": " Yes. Thank you. Excellent presentation. Very, very, very impressive. My question is,", "tokens": [51204, 1079, 13, 1044, 291, 13, 16723, 5860, 13, 4372, 11, 588, 11, 588, 8992, 13, 1222, 1168, 307, 11, 51468], "temperature": 0.0, "avg_logprob": -0.1497094794495465, "compression_ratio": 1.441340782122905, "no_speech_prob": 0.0006766183651052415}, {"id": 422, "seek": 310876, "start": 3108.76, "end": 3117.5600000000004, "text": " can you elaborate a little bit on process variants? I asked this because I think there is a missing", "tokens": [50364, 393, 291, 20945, 257, 707, 857, 322, 1399, 21669, 30, 286, 2351, 341, 570, 286, 519, 456, 307, 257, 5361, 50804], "temperature": 0.0, "avg_logprob": -0.12442607084910075, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.012216798029839993}, {"id": 423, "seek": 310876, "start": 3117.5600000000004, "end": 3126.5200000000004, "text": " bridge or link between all the material that you suggested you cited to the whole body of", "tokens": [50804, 7283, 420, 2113, 1296, 439, 264, 2527, 300, 291, 10945, 291, 30134, 281, 264, 1379, 1772, 295, 51252], "temperature": 0.0, "avg_logprob": -0.12442607084910075, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.012216798029839993}, {"id": 424, "seek": 310876, "start": 3126.5200000000004, "end": 3133.4, "text": " knowledge that's happening in operations management, where we look at process variants,", "tokens": [51252, 3601, 300, 311, 2737, 294, 7705, 4592, 11, 689, 321, 574, 412, 1399, 21669, 11, 51596], "temperature": 0.0, "avg_logprob": -0.12442607084910075, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.012216798029839993}, {"id": 425, "seek": 313340, "start": 3133.4, "end": 3138.52, "text": " you know, we also teach in the operations management courses, tools and techniques,", "tokens": [50364, 291, 458, 11, 321, 611, 2924, 294, 264, 7705, 4592, 7712, 11, 3873, 293, 7512, 11, 50620], "temperature": 0.0, "avg_logprob": -0.09656295776367188, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.006180375348776579}, {"id": 426, "seek": 313340, "start": 3138.52, "end": 3144.6, "text": " like the fishbone diagram, Ishikawa diagram and so forth, to really understand how we can", "tokens": [50620, 411, 264, 3506, 19782, 10686, 11, 42854, 1035, 10449, 10686, 293, 370, 5220, 11, 281, 534, 1223, 577, 321, 393, 50924], "temperature": 0.0, "avg_logprob": -0.09656295776367188, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.006180375348776579}, {"id": 427, "seek": 313340, "start": 3145.2400000000002, "end": 3151.88, "text": " manage those processes so that we can reduce variability to make the processes better,", "tokens": [50956, 3067, 729, 7555, 370, 300, 321, 393, 5407, 35709, 281, 652, 264, 7555, 1101, 11, 51288], "temperature": 0.0, "avg_logprob": -0.09656295776367188, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.006180375348776579}, {"id": 428, "seek": 313340, "start": 3151.88, "end": 3161.1600000000003, "text": " more flexible, cheaper and faster. I think that practical call for why we try to manage processes", "tokens": [51288, 544, 11358, 11, 12284, 293, 4663, 13, 286, 519, 300, 8496, 818, 337, 983, 321, 853, 281, 3067, 7555, 51752], "temperature": 0.0, "avg_logprob": -0.09656295776367188, "compression_ratio": 1.6807511737089202, "no_speech_prob": 0.006180375348776579}, {"id": 429, "seek": 316116, "start": 3161.24, "end": 3167.3999999999996, "text": " is conspicuously missing in what you suggested. And this is not a criticism. I'm just trying", "tokens": [50368, 307, 1014, 37509, 84, 5098, 5361, 294, 437, 291, 10945, 13, 400, 341, 307, 406, 257, 15835, 13, 286, 478, 445, 1382, 50676], "temperature": 0.0, "avg_logprob": -0.11455932360016897, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.000578783918172121}, {"id": 430, "seek": 316116, "start": 3167.3999999999996, "end": 3173.3199999999997, "text": " to connect two bodies of knowledge here, what you cited and what goes on a lot in operations", "tokens": [50676, 281, 1745, 732, 7510, 295, 3601, 510, 11, 437, 291, 30134, 293, 437, 1709, 322, 257, 688, 294, 7705, 50972], "temperature": 0.0, "avg_logprob": -0.11455932360016897, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.000578783918172121}, {"id": 431, "seek": 316116, "start": 3173.3199999999997, "end": 3180.12, "text": " management. Thank you. Yeah. So what I'm talking about is, you know, every researcher who is", "tokens": [50972, 4592, 13, 1044, 291, 13, 865, 13, 407, 437, 286, 478, 1417, 466, 307, 11, 291, 458, 11, 633, 21751, 567, 307, 51312], "temperature": 0.0, "avg_logprob": -0.11455932360016897, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.000578783918172121}, {"id": 432, "seek": 316116, "start": 3180.12, "end": 3188.92, "text": " interested in understanding process theoretically, I'm not talking about how to analyze a specific", "tokens": [51312, 3102, 294, 3701, 1399, 29400, 11, 286, 478, 406, 1417, 466, 577, 281, 12477, 257, 2685, 51752], "temperature": 0.0, "avg_logprob": -0.11455932360016897, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.000578783918172121}, {"id": 433, "seek": 318892, "start": 3188.92, "end": 3196.6800000000003, "text": " process to improve it. But obviously, that is a complementary kind of an approach. And some of", "tokens": [50364, 1399, 281, 3470, 309, 13, 583, 2745, 11, 300, 307, 257, 40705, 733, 295, 364, 3109, 13, 400, 512, 295, 50752], "temperature": 0.0, "avg_logprob": -0.08776794461642995, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0015957026043906808}, {"id": 434, "seek": 318892, "start": 3196.6800000000003, "end": 3206.44, "text": " the techniques that we might use to theorize might also be particularly useful for improvement as well.", "tokens": [50752, 264, 7512, 300, 321, 1062, 764, 281, 27423, 1125, 1062, 611, 312, 4098, 4420, 337, 10444, 382, 731, 13, 51240], "temperature": 0.0, "avg_logprob": -0.08776794461642995, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0015957026043906808}, {"id": 435, "seek": 318892, "start": 3206.44, "end": 3213.64, "text": " So things like, and I'm going to be talking about this later, process diagrams, for example,", "tokens": [51240, 407, 721, 411, 11, 293, 286, 478, 516, 281, 312, 1417, 466, 341, 1780, 11, 1399, 36709, 11, 337, 1365, 11, 51600], "temperature": 0.0, "avg_logprob": -0.08776794461642995, "compression_ratio": 1.4923076923076923, "no_speech_prob": 0.0015957026043906808}, {"id": 436, "seek": 321364, "start": 3214.3599999999997, "end": 3223.08, "text": " that look at how things are working over time and which activities are taking place.", "tokens": [50400, 300, 574, 412, 577, 721, 366, 1364, 670, 565, 293, 597, 5354, 366, 1940, 1081, 13, 50836], "temperature": 0.0, "avg_logprob": -0.0968201607465744, "compression_ratio": 1.5197740112994351, "no_speech_prob": 0.005546708591282368}, {"id": 437, "seek": 321364, "start": 3223.7999999999997, "end": 3230.6, "text": " And process diagrams can be useful to describe what is going on and to theorize from it. But", "tokens": [50872, 400, 1399, 36709, 393, 312, 4420, 281, 6786, 437, 307, 516, 322, 293, 281, 27423, 1125, 490, 309, 13, 583, 51212], "temperature": 0.0, "avg_logprob": -0.0968201607465744, "compression_ratio": 1.5197740112994351, "no_speech_prob": 0.005546708591282368}, {"id": 438, "seek": 321364, "start": 3230.6, "end": 3240.52, "text": " they can also be useful to pinpoint, okay, this process is kind of not efficient. There are", "tokens": [51212, 436, 393, 611, 312, 4420, 281, 40837, 11, 1392, 11, 341, 1399, 307, 733, 295, 406, 7148, 13, 821, 366, 51708], "temperature": 0.0, "avg_logprob": -0.0968201607465744, "compression_ratio": 1.5197740112994351, "no_speech_prob": 0.005546708591282368}, {"id": 439, "seek": 324052, "start": 3240.6, "end": 3251.4, "text": " ways of cutting steps that might be useless. And there are ways also of improving steps so that", "tokens": [50368, 2098, 295, 6492, 4439, 300, 1062, 312, 14115, 13, 400, 456, 366, 2098, 611, 295, 11470, 4439, 370, 300, 50908], "temperature": 0.0, "avg_logprob": -0.11820811213869037, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0007552876486442983}, {"id": 440, "seek": 324052, "start": 3252.7599999999998, "end": 3256.92, "text": " there's greater consistency, which is what you're talking about, eliminating variance, right?", "tokens": [50976, 456, 311, 5044, 14416, 11, 597, 307, 437, 291, 434, 1417, 466, 11, 31203, 21977, 11, 558, 30, 51184], "temperature": 0.0, "avg_logprob": -0.11820811213869037, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0007552876486442983}, {"id": 441, "seek": 324052, "start": 3258.12, "end": 3264.28, "text": " So but I'm using the terms process and variance in a little bit of a different way and more in", "tokens": [51244, 407, 457, 286, 478, 1228, 264, 2115, 1399, 293, 21977, 294, 257, 707, 857, 295, 257, 819, 636, 293, 544, 294, 51552], "temperature": 0.0, "avg_logprob": -0.11820811213869037, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0007552876486442983}, {"id": 442, "seek": 326428, "start": 3264.28, "end": 3271.5600000000004, "text": " terms of processes of theorizing. But I do understand that there is also a practical", "tokens": [50364, 2115, 295, 7555, 295, 27423, 3319, 13, 583, 286, 360, 1223, 300, 456, 307, 611, 257, 8496, 50728], "temperature": 0.0, "avg_logprob": -0.17509664297103883, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.0006867797346785665}, {"id": 443, "seek": 326428, "start": 3271.5600000000004, "end": 3275.7200000000003, "text": " application as well of these things. Anna?", "tokens": [50728, 3861, 382, 731, 295, 613, 721, 13, 12899, 30, 50936], "temperature": 0.0, "avg_logprob": -0.17509664297103883, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.0006867797346785665}, {"id": 444, "seek": 326428, "start": 3280.6000000000004, "end": 3285.2400000000002, "text": " Yes, hello, Professor Langley. My name is Anna Kourija. First of all, thank you for the presentation.", "tokens": [51180, 1079, 11, 7751, 11, 8419, 13313, 3420, 13, 1222, 1315, 307, 12899, 591, 396, 20642, 13, 2386, 295, 439, 11, 1309, 291, 337, 264, 5860, 13, 51412], "temperature": 0.0, "avg_logprob": -0.17509664297103883, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.0006867797346785665}, {"id": 445, "seek": 326428, "start": 3285.2400000000002, "end": 3291.0800000000004, "text": " I've been doing ethnography research projects since three years and still ongoing until next year.", "tokens": [51412, 286, 600, 668, 884, 42589, 5820, 2132, 4455, 1670, 1045, 924, 293, 920, 10452, 1826, 958, 1064, 13, 51704], "temperature": 0.0, "avg_logprob": -0.17509664297103883, "compression_ratio": 1.4708520179372198, "no_speech_prob": 0.0006867797346785665}, {"id": 446, "seek": 329108, "start": 3291.08, "end": 3296.44, "text": " So it's about four years data of ethnographic observation and interview session. It's quite", "tokens": [50364, 407, 309, 311, 466, 1451, 924, 1412, 295, 42589, 12295, 14816, 293, 4049, 5481, 13, 467, 311, 1596, 50632], "temperature": 0.0, "avg_logprob": -0.16961779417815032, "compression_ratio": 1.607773851590106, "no_speech_prob": 0.001801842823624611}, {"id": 447, "seek": 329108, "start": 3296.44, "end": 3302.12, "text": " a lot and messy, as you explained. I tried already the first round data analysis using", "tokens": [50632, 257, 688, 293, 16191, 11, 382, 291, 8825, 13, 286, 3031, 1217, 264, 700, 3098, 1412, 5215, 1228, 50916], "temperature": 0.0, "avg_logprob": -0.16961779417815032, "compression_ratio": 1.607773851590106, "no_speech_prob": 0.001801842823624611}, {"id": 448, "seek": 329108, "start": 3302.12, "end": 3308.12, "text": " Joya method. But I realized, as you mentioned, I'm missing the the temporality, because I've", "tokens": [50916, 508, 24642, 3170, 13, 583, 286, 5334, 11, 382, 291, 2835, 11, 286, 478, 5361, 264, 264, 8219, 1860, 11, 570, 286, 600, 51216], "temperature": 0.0, "avg_logprob": -0.16961779417815032, "compression_ratio": 1.607773851590106, "no_speech_prob": 0.001801842823624611}, {"id": 449, "seek": 329108, "start": 3308.12, "end": 3314.36, "text": " been studying about project management stages and how culture affects the project and performance on.", "tokens": [51216, 668, 7601, 466, 1716, 4592, 10232, 293, 577, 3713, 11807, 264, 1716, 293, 3389, 322, 13, 51528], "temperature": 0.0, "avg_logprob": -0.16961779417815032, "compression_ratio": 1.607773851590106, "no_speech_prob": 0.001801842823624611}, {"id": 450, "seek": 329108, "start": 3314.36, "end": 3319.24, "text": " And so what I could get from Joya is just a kind of constructionist. So it's like", "tokens": [51528, 400, 370, 437, 286, 727, 483, 490, 508, 24642, 307, 445, 257, 733, 295, 6435, 468, 13, 407, 309, 311, 411, 51772], "temperature": 0.0, "avg_logprob": -0.16961779417815032, "compression_ratio": 1.607773851590106, "no_speech_prob": 0.001801842823624611}, {"id": 451, "seek": 331924, "start": 3319.24, "end": 3324.2799999999997, "text": " almost static in the way that it's just forming a certain theory, but it doesn't show", "tokens": [50364, 1920, 13437, 294, 264, 636, 300, 309, 311, 445, 15745, 257, 1629, 5261, 11, 457, 309, 1177, 380, 855, 50616], "temperature": 0.0, "avg_logprob": -0.10912471905089262, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.0032415674068033695}, {"id": 452, "seek": 331924, "start": 3324.2799999999997, "end": 3330.52, "text": " how dynamics in the project team evolve along the along the stages. So now I've been following", "tokens": [50616, 577, 15679, 294, 264, 1716, 1469, 16693, 2051, 264, 2051, 264, 10232, 13, 407, 586, 286, 600, 668, 3480, 50928], "temperature": 0.0, "avg_logprob": -0.10912471905089262, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.0032415674068033695}, {"id": 453, "seek": 331924, "start": 3330.52, "end": 3335.7999999999997, "text": " the one from Professor Niederman, the socio evolution theory. So like more like a process", "tokens": [50928, 264, 472, 490, 8419, 426, 1091, 11821, 11, 264, 44303, 9303, 5261, 13, 407, 411, 544, 411, 257, 1399, 51192], "temperature": 0.0, "avg_logprob": -0.10912471905089262, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.0032415674068033695}, {"id": 454, "seek": 331924, "start": 3335.7999999999997, "end": 3341.8799999999997, "text": " theory looks like really like a process theory. But I believe I cannot share my screen. But the", "tokens": [51192, 5261, 1542, 411, 534, 411, 257, 1399, 5261, 13, 583, 286, 1697, 286, 2644, 2073, 452, 2568, 13, 583, 264, 51496], "temperature": 0.0, "avg_logprob": -0.10912471905089262, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.0032415674068033695}, {"id": 455, "seek": 331924, "start": 3341.8799999999997, "end": 3347.24, "text": " way I did it like this, I don't know if it's correct. So first, I use the theoretical lens from", "tokens": [51496, 636, 286, 630, 309, 411, 341, 11, 286, 500, 380, 458, 498, 309, 311, 3006, 13, 407, 700, 11, 286, 764, 264, 20864, 6765, 490, 51764], "temperature": 0.0, "avg_logprob": -0.10912471905089262, "compression_ratio": 1.7566539923954372, "no_speech_prob": 0.0032415674068033695}, {"id": 456, "seek": 334724, "start": 3347.24, "end": 3354.7599999999998, "text": " the literature. So I created a code book with my research team. I get the codes around 50 codes", "tokens": [50364, 264, 10394, 13, 407, 286, 2942, 257, 3089, 1446, 365, 452, 2132, 1469, 13, 286, 483, 264, 14211, 926, 2625, 14211, 50740], "temperature": 0.0, "avg_logprob": -0.13871136490179567, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.008481992408633232}, {"id": 457, "seek": 334724, "start": 3354.7599999999998, "end": 3360.7599999999998, "text": " or something. And I did the deductive approach of top top, top down. And then I did another round", "tokens": [50740, 420, 746, 13, 400, 286, 630, 264, 31513, 488, 3109, 295, 1192, 1192, 11, 1192, 760, 13, 400, 550, 286, 630, 1071, 3098, 51040], "temperature": 0.0, "avg_logprob": -0.13871136490179567, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.008481992408633232}, {"id": 458, "seek": 334724, "start": 3360.7599999999998, "end": 3366.9199999999996, "text": " with my team also inductive coding, so that to get some new ideas, or maybe we are not", "tokens": [51040, 365, 452, 1469, 611, 31612, 488, 17720, 11, 370, 300, 281, 483, 512, 777, 3487, 11, 420, 1310, 321, 366, 406, 51348], "temperature": 0.0, "avg_logprob": -0.13871136490179567, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.008481992408633232}, {"id": 459, "seek": 334724, "start": 3366.9199999999996, "end": 3372.68, "text": " in the right domain and so on. And then at the end, we kind of plan a map the episodes like", "tokens": [51348, 294, 264, 558, 9274, 293, 370, 322, 13, 400, 550, 412, 264, 917, 11, 321, 733, 295, 1393, 257, 4471, 264, 9313, 411, 51636], "temperature": 0.0, "avg_logprob": -0.13871136490179567, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.008481992408633232}, {"id": 460, "seek": 337268, "start": 3372.68, "end": 3377.0, "text": " what happened in conflict, what happened creativity. And then we start from the project,", "tokens": [50364, 437, 2011, 294, 6596, 11, 437, 2011, 12915, 13, 400, 550, 321, 722, 490, 264, 1716, 11, 50580], "temperature": 0.0, "avg_logprob": -0.1557539400847062, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.007076430134475231}, {"id": 461, "seek": 337268, "start": 3377.0, "end": 3382.6, "text": " start with the project and and we create like couple of episodes mapping. And then we kind of show", "tokens": [50580, 722, 365, 264, 1716, 293, 293, 321, 1884, 411, 1916, 295, 9313, 18350, 13, 400, 550, 321, 733, 295, 855, 50860], "temperature": 0.0, "avg_logprob": -0.1557539400847062, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.007076430134475231}, {"id": 462, "seek": 337268, "start": 3382.6, "end": 3388.44, "text": " it to the front. And I don't know if we're doing the right thing. But at the moment, this is so far", "tokens": [50860, 309, 281, 264, 1868, 13, 400, 286, 500, 380, 458, 498, 321, 434, 884, 264, 558, 551, 13, 583, 412, 264, 1623, 11, 341, 307, 370, 1400, 51152], "temperature": 0.0, "avg_logprob": -0.1557539400847062, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.007076430134475231}, {"id": 463, "seek": 337268, "start": 3388.44, "end": 3394.52, "text": " the best approach that we could think of to generate such huge amount of data. Otherwise,", "tokens": [51152, 264, 1151, 3109, 300, 321, 727, 519, 295, 281, 8460, 1270, 2603, 2372, 295, 1412, 13, 10328, 11, 51456], "temperature": 0.0, "avg_logprob": -0.1557539400847062, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.007076430134475231}, {"id": 464, "seek": 337268, "start": 3394.52, "end": 3400.2, "text": " I'll be also overwhelmed with analyzing this. I would like to get your insight if I'm in the", "tokens": [51456, 286, 603, 312, 611, 19042, 365, 23663, 341, 13, 286, 576, 411, 281, 483, 428, 11269, 498, 286, 478, 294, 264, 51740], "temperature": 0.0, "avg_logprob": -0.1557539400847062, "compression_ratio": 1.7153284671532847, "no_speech_prob": 0.007076430134475231}, {"id": 465, "seek": 340020, "start": 3400.2, "end": 3407.0, "text": " right track or should I try another approach? I mean, this sounds really good to me. I would,", "tokens": [50364, 558, 2837, 420, 820, 286, 853, 1071, 3109, 30, 286, 914, 11, 341, 3263, 534, 665, 281, 385, 13, 286, 576, 11, 50704], "temperature": 0.0, "avg_logprob": -0.11740700249533051, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.0036454019136726856}, {"id": 466, "seek": 340020, "start": 3407.0, "end": 3412.12, "text": " you know, if you'd like to send me something that you would, you know, I'd be glad to sort of comment", "tokens": [50704, 291, 458, 11, 498, 291, 1116, 411, 281, 2845, 385, 746, 300, 291, 576, 11, 291, 458, 11, 286, 1116, 312, 5404, 281, 1333, 295, 2871, 50960], "temperature": 0.0, "avg_logprob": -0.11740700249533051, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.0036454019136726856}, {"id": 467, "seek": 340020, "start": 3412.12, "end": 3419.56, "text": " on it. But thank you for doing both bottom up and top down coding. And I think that just focusing", "tokens": [50960, 322, 309, 13, 583, 1309, 291, 337, 884, 1293, 2767, 493, 293, 1192, 760, 17720, 13, 400, 286, 519, 300, 445, 8416, 51332], "temperature": 0.0, "avg_logprob": -0.11740700249533051, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.0036454019136726856}, {"id": 468, "seek": 340020, "start": 3419.56, "end": 3425.64, "text": " on one can be problematic. You know, if you just do the top down, then you don't produce anything", "tokens": [51332, 322, 472, 393, 312, 19011, 13, 509, 458, 11, 498, 291, 445, 360, 264, 1192, 760, 11, 550, 291, 500, 380, 5258, 1340, 51636], "temperature": 0.0, "avg_logprob": -0.11740700249533051, "compression_ratio": 1.6567796610169492, "no_speech_prob": 0.0036454019136726856}, {"id": 469, "seek": 342564, "start": 3425.64, "end": 3432.8399999999997, "text": " new. If you do the bottom up, you just kind of end up being descriptive. So it's, it's,", "tokens": [50364, 777, 13, 759, 291, 360, 264, 2767, 493, 11, 291, 445, 733, 295, 917, 493, 885, 42585, 13, 407, 309, 311, 11, 309, 311, 11, 50724], "temperature": 0.0, "avg_logprob": -0.1556160010180427, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.003370008198544383}, {"id": 470, "seek": 342564, "start": 3433.72, "end": 3439.96, "text": " it's the combination of both, which can give you that richness, I think. So yeah, I'd be glad to", "tokens": [50768, 309, 311, 264, 6562, 295, 1293, 11, 597, 393, 976, 291, 300, 44506, 11, 286, 519, 13, 407, 1338, 11, 286, 1116, 312, 5404, 281, 51080], "temperature": 0.0, "avg_logprob": -0.1556160010180427, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.003370008198544383}, {"id": 471, "seek": 342564, "start": 3439.96, "end": 3444.92, "text": " look at what you're doing. I'm happy to do to get your feedback on the thank you so much,", "tokens": [51080, 574, 412, 437, 291, 434, 884, 13, 286, 478, 2055, 281, 360, 281, 483, 428, 5824, 322, 264, 1309, 291, 370, 709, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1556160010180427, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.003370008198544383}, {"id": 472, "seek": 342564, "start": 3444.92, "end": 3453.64, "text": " Professor Langley. Okay, you see. Hi, I have a question about your strategy to alternative", "tokens": [51328, 8419, 13313, 3420, 13, 1033, 11, 291, 536, 13, 2421, 11, 286, 362, 257, 1168, 466, 428, 5206, 281, 8535, 51764], "temperature": 0.0, "avg_logprob": -0.1556160010180427, "compression_ratio": 1.540084388185654, "no_speech_prob": 0.003370008198544383}, {"id": 473, "seek": 345364, "start": 3453.64, "end": 3459.8799999999997, "text": " templates, fit a different theoretical framework to the data. And sometimes people from different", "tokens": [50364, 21165, 11, 3318, 257, 819, 20864, 8388, 281, 264, 1412, 13, 400, 2171, 561, 490, 819, 50676], "temperature": 0.0, "avg_logprob": -0.15234377509669253, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.005054893437772989}, {"id": 474, "seek": 345364, "start": 3459.8799999999997, "end": 3465.56, "text": " disciplines study the same phenomenon. So the alternative templates may come from another", "tokens": [50676, 21919, 2979, 264, 912, 14029, 13, 407, 264, 8535, 21165, 815, 808, 490, 1071, 50960], "temperature": 0.0, "avg_logprob": -0.15234377509669253, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.005054893437772989}, {"id": 475, "seek": 345364, "start": 3465.56, "end": 3471.16, "text": " discipline. For example, like, in addition to management, there may be economics,", "tokens": [50960, 13635, 13, 1171, 1365, 11, 411, 11, 294, 4500, 281, 4592, 11, 456, 815, 312, 14564, 11, 51240], "temperature": 0.0, "avg_logprob": -0.15234377509669253, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.005054893437772989}, {"id": 476, "seek": 345364, "start": 3471.16, "end": 3477.0, "text": " maybe astrology, maybe geography, I really like your picture in the beginning, the river is not", "tokens": [51240, 1310, 44385, 11, 1310, 26695, 11, 286, 534, 411, 428, 3036, 294, 264, 2863, 11, 264, 6810, 307, 406, 51532], "temperature": 0.0, "avg_logprob": -0.15234377509669253, "compression_ratio": 1.6150442477876106, "no_speech_prob": 0.005054893437772989}, {"id": 477, "seek": 347700, "start": 3477.0, "end": 3485.16, "text": " object, but ever changing flow. Just analogy, like the person is like driving the boat is like", "tokens": [50364, 2657, 11, 457, 1562, 4473, 3095, 13, 1449, 21663, 11, 411, 264, 954, 307, 411, 4840, 264, 6582, 307, 411, 50772], "temperature": 0.0, "avg_logprob": -0.22467165215070858, "compression_ratio": 1.8238095238095238, "no_speech_prob": 0.0029322837945073843}, {"id": 478, "seek": 347700, "start": 3485.16, "end": 3491.0, "text": " an entrepreneur drive a business. And the river is kind of like community institutions, is like", "tokens": [50772, 364, 14307, 3332, 257, 1606, 13, 400, 264, 6810, 307, 733, 295, 411, 1768, 8142, 11, 307, 411, 51064], "temperature": 0.0, "avg_logprob": -0.22467165215070858, "compression_ratio": 1.8238095238095238, "no_speech_prob": 0.0029322837945073843}, {"id": 479, "seek": 347700, "start": 3491.8, "end": 3499.16, "text": " economic geography that kind of thing. For example, the river is, is changing flow, like there are", "tokens": [51104, 4836, 26695, 300, 733, 295, 551, 13, 1171, 1365, 11, 264, 6810, 307, 11, 307, 4473, 3095, 11, 411, 456, 366, 51472], "temperature": 0.0, "avg_logprob": -0.22467165215070858, "compression_ratio": 1.8238095238095238, "no_speech_prob": 0.0029322837945073843}, {"id": 480, "seek": 347700, "start": 3499.16, "end": 3504.28, "text": " a lot of economic geographers study the community institutions, but they are not considered a", "tokens": [51472, 257, 688, 295, 4836, 25435, 433, 2979, 264, 1768, 8142, 11, 457, 436, 366, 406, 4888, 257, 51728], "temperature": 0.0, "avg_logprob": -0.22467165215070858, "compression_ratio": 1.8238095238095238, "no_speech_prob": 0.0029322837945073843}, {"id": 481, "seek": 350428, "start": 3504.28, "end": 3510.44, "text": " management. So when I use alternative templates, when I incorporate those, to let different", "tokens": [50364, 4592, 13, 407, 562, 286, 764, 8535, 21165, 11, 562, 286, 16091, 729, 11, 281, 718, 819, 50672], "temperature": 0.0, "avg_logprob": -0.22751877106815935, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.0007789634400978684}, {"id": 482, "seek": 350428, "start": 3510.44, "end": 3515.88, "text": " disciplines to kind of have a conversation is answer your call of the river is not object,", "tokens": [50672, 21919, 281, 733, 295, 362, 257, 3761, 307, 1867, 428, 818, 295, 264, 6810, 307, 406, 2657, 11, 50944], "temperature": 0.0, "avg_logprob": -0.22751877106815935, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.0007789634400978684}, {"id": 483, "seek": 350428, "start": 3515.88, "end": 3522.36, "text": " but every changing flow, that's very juicy part because my background was from economic geography.", "tokens": [50944, 457, 633, 4473, 3095, 11, 300, 311, 588, 24696, 644, 570, 452, 3678, 390, 490, 4836, 26695, 13, 51268], "temperature": 0.0, "avg_logprob": -0.22751877106815935, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.0007789634400978684}, {"id": 484, "seek": 350428, "start": 3523.0800000000004, "end": 3528.36, "text": " But I'm supposed to say this is not an internship paper, you should submit to somewhere else.", "tokens": [51304, 583, 286, 478, 3442, 281, 584, 341, 307, 406, 364, 16861, 3035, 11, 291, 820, 10315, 281, 4079, 1646, 13, 51568], "temperature": 0.0, "avg_logprob": -0.22751877106815935, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.0007789634400978684}, {"id": 485, "seek": 352836, "start": 3528.36, "end": 3535.08, "text": " But I am targeting at management mainstream conversation, I want to join that debate. I think", "tokens": [50364, 583, 286, 669, 17918, 412, 4592, 15960, 3761, 11, 286, 528, 281, 3917, 300, 7958, 13, 286, 519, 50700], "temperature": 0.0, "avg_logprob": -0.18227168748963554, "compression_ratio": 1.7617328519855595, "no_speech_prob": 0.0005786217516288161}, {"id": 486, "seek": 352836, "start": 3535.08, "end": 3540.6800000000003, "text": " some people say that because the entrepreneurship is changing like a very long time ago is like Steve", "tokens": [50700, 512, 561, 584, 300, 570, 264, 26582, 307, 4473, 411, 257, 588, 938, 565, 2057, 307, 411, 7466, 50980], "temperature": 0.0, "avg_logprob": -0.18227168748963554, "compression_ratio": 1.7617328519855595, "no_speech_prob": 0.0005786217516288161}, {"id": 487, "seek": 352836, "start": 3540.6800000000003, "end": 3547.32, "text": " Jobs, a kind of entrepreneur, but later on come to the community's level, for example, and then", "tokens": [50980, 29169, 11, 257, 733, 295, 14307, 11, 457, 1780, 322, 808, 281, 264, 1768, 311, 1496, 11, 337, 1365, 11, 293, 550, 51312], "temperature": 0.0, "avg_logprob": -0.18227168748963554, "compression_ratio": 1.7617328519855595, "no_speech_prob": 0.0005786217516288161}, {"id": 488, "seek": 352836, "start": 3547.32, "end": 3552.6, "text": " come to the social level. So what is expanding a touch of the boundaries of different disciplines,", "tokens": [51312, 808, 281, 264, 2093, 1496, 13, 407, 437, 307, 14702, 257, 2557, 295, 264, 13180, 295, 819, 21919, 11, 51576], "temperature": 0.0, "avg_logprob": -0.18227168748963554, "compression_ratio": 1.7617328519855595, "no_speech_prob": 0.0005786217516288161}, {"id": 489, "seek": 352836, "start": 3552.6, "end": 3557.8, "text": " for example, economic geography, but right now I want to speak to the mainstream entrepreneurship", "tokens": [51576, 337, 1365, 11, 4836, 26695, 11, 457, 558, 586, 286, 528, 281, 1710, 281, 264, 15960, 26582, 51836], "temperature": 0.0, "avg_logprob": -0.18227168748963554, "compression_ratio": 1.7617328519855595, "no_speech_prob": 0.0005786217516288161}, {"id": 490, "seek": 355780, "start": 3557.8, "end": 3563.6400000000003, "text": " literature, or join that debate, and I want to use the alternative templates by citing", "tokens": [50364, 10394, 11, 420, 3917, 300, 7958, 11, 293, 286, 528, 281, 764, 264, 8535, 21165, 538, 48749, 50656], "temperature": 0.0, "avg_logprob": -0.24571770429611206, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.001498452853411436}, {"id": 491, "seek": 355780, "start": 3564.84, "end": 3569.32, "text": " the framework from different disciplines and let that to kind of have a conversation,", "tokens": [50716, 264, 8388, 490, 819, 21919, 293, 718, 300, 281, 733, 295, 362, 257, 3761, 11, 50940], "temperature": 0.0, "avg_logprob": -0.24571770429611206, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.001498452853411436}, {"id": 492, "seek": 355780, "start": 3569.32, "end": 3575.0, "text": " so that I can answer your call that the river is not just object, but the average changing flow", "tokens": [50940, 370, 300, 286, 393, 1867, 428, 818, 300, 264, 6810, 307, 406, 445, 2657, 11, 457, 264, 4274, 4473, 3095, 51224], "temperature": 0.0, "avg_logprob": -0.24571770429611206, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.001498452853411436}, {"id": 493, "seek": 355780, "start": 3575.0, "end": 3580.44, "text": " that's bring the community lens into the conversation, but speak to the mainstream", "tokens": [51224, 300, 311, 1565, 264, 1768, 6765, 666, 264, 3761, 11, 457, 1710, 281, 264, 15960, 51496], "temperature": 0.0, "avg_logprob": -0.24571770429611206, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.001498452853411436}, {"id": 494, "seek": 355780, "start": 3580.44, "end": 3585.4, "text": " entrepreneur. Okay, you give me some suggestions so that people will say it never.", "tokens": [51496, 14307, 13, 1033, 11, 291, 976, 385, 512, 13396, 370, 300, 561, 486, 584, 309, 1128, 13, 51744], "temperature": 0.0, "avg_logprob": -0.24571770429611206, "compression_ratio": 1.6564885496183206, "no_speech_prob": 0.001498452853411436}, {"id": 495, "seek": 358540, "start": 3585.8, "end": 3592.6800000000003, "text": " I think that that sounds great. I mean, I think that multidisciplinary research is difficult,", "tokens": [50384, 286, 519, 300, 300, 3263, 869, 13, 286, 914, 11, 286, 519, 300, 2120, 40920, 24560, 2132, 307, 2252, 11, 50728], "temperature": 0.0, "avg_logprob": -0.10064156850179036, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0006257796194404364}, {"id": 496, "seek": 358540, "start": 3592.6800000000003, "end": 3601.08, "text": " but if you are not just, if you are bringing in alternative templates that are not based", "tokens": [50728, 457, 498, 291, 366, 406, 445, 11, 498, 291, 366, 5062, 294, 8535, 21165, 300, 366, 406, 2361, 51148], "temperature": 0.0, "avg_logprob": -0.10064156850179036, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0006257796194404364}, {"id": 497, "seek": 358540, "start": 3601.08, "end": 3607.48, "text": " in management and comparing them with those that are, I think that's extremely generative", "tokens": [51148, 294, 4592, 293, 15763, 552, 365, 729, 300, 366, 11, 286, 519, 300, 311, 4664, 1337, 1166, 51468], "temperature": 0.0, "avg_logprob": -0.10064156850179036, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0006257796194404364}, {"id": 498, "seek": 358540, "start": 3607.48, "end": 3614.6800000000003, "text": " and it's likely to be well received. In the entrepreneurship field, I know of one paper", "tokens": [51468, 293, 309, 311, 3700, 281, 312, 731, 4613, 13, 682, 264, 26582, 2519, 11, 286, 458, 295, 472, 3035, 51828], "temperature": 0.0, "avg_logprob": -0.10064156850179036, "compression_ratio": 1.6901408450704225, "no_speech_prob": 0.0006257796194404364}, {"id": 499, "seek": 361468, "start": 3614.68, "end": 3623.3999999999996, "text": " that really does a good job of looking at alternative templates, and that's a paper by Greg Fischer.", "tokens": [50364, 300, 534, 775, 257, 665, 1691, 295, 1237, 412, 8535, 21165, 11, 293, 300, 311, 257, 3035, 538, 11490, 479, 19674, 13, 50800], "temperature": 0.0, "avg_logprob": -0.1764977895296537, "compression_ratio": 1.5414634146341464, "no_speech_prob": 0.00045811448944732547}, {"id": 500, "seek": 361468, "start": 3625.7999999999997, "end": 3631.0, "text": " I think it's Entrepreneurship Theory and Practice is the journal, and it's 2012,", "tokens": [50920, 286, 519, 309, 311, 49049, 2156, 1210, 29009, 293, 27904, 307, 264, 6708, 11, 293, 309, 311, 9125, 11, 51180], "temperature": 0.0, "avg_logprob": -0.1764977895296537, "compression_ratio": 1.5414634146341464, "no_speech_prob": 0.00045811448944732547}, {"id": 501, "seek": 361468, "start": 3631.0, "end": 3637.3199999999997, "text": " and it's a kind of a classic application of alternative templates approach,", "tokens": [51180, 293, 309, 311, 257, 733, 295, 257, 7230, 3861, 295, 8535, 21165, 3109, 11, 51496], "temperature": 0.0, "avg_logprob": -0.1764977895296537, "compression_ratio": 1.5414634146341464, "no_speech_prob": 0.00045811448944732547}, {"id": 502, "seek": 361468, "start": 3637.3199999999997, "end": 3639.7999999999997, "text": " so that might be something that you would want to look at.", "tokens": [51496, 370, 300, 1062, 312, 746, 300, 291, 576, 528, 281, 574, 412, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1764977895296537, "compression_ratio": 1.5414634146341464, "no_speech_prob": 0.00045811448944732547}, {"id": 503, "seek": 363980, "start": 3640.76, "end": 3645.4, "text": " So can you type the literature in the chat box, or I follow up and give you an email?", "tokens": [50412, 407, 393, 291, 2010, 264, 10394, 294, 264, 5081, 2424, 11, 420, 286, 1524, 493, 293, 976, 291, 364, 3796, 30, 50644], "temperature": 0.0, "avg_logprob": -0.16543263080073337, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.012420712038874626}, {"id": 504, "seek": 363980, "start": 3646.28, "end": 3655.7200000000003, "text": " Yeah, maybe what I will do is send a bibliography to Ibrat at the end, if that's possible,", "tokens": [50688, 865, 11, 1310, 437, 286, 486, 360, 307, 2845, 257, 34344, 5820, 281, 286, 1443, 267, 412, 264, 917, 11, 498, 300, 311, 1944, 11, 51160], "temperature": 0.0, "avg_logprob": -0.16543263080073337, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.012420712038874626}, {"id": 505, "seek": 363980, "start": 3655.7200000000003, "end": 3662.6000000000004, "text": " because there are ways to distribute that too. I think I can do that. Yeah, okay, I will create", "tokens": [51160, 570, 456, 366, 2098, 281, 20594, 300, 886, 13, 286, 519, 286, 393, 360, 300, 13, 865, 11, 1392, 11, 286, 486, 1884, 51504], "temperature": 0.0, "avg_logprob": -0.16543263080073337, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.012420712038874626}, {"id": 506, "seek": 363980, "start": 3662.6000000000004, "end": 3668.44, "text": " a bibliography and send it. Wonderful, thank you. If anyone could type that paper in the chat box,", "tokens": [51504, 257, 34344, 5820, 293, 2845, 309, 13, 22768, 11, 1309, 291, 13, 759, 2878, 727, 2010, 300, 3035, 294, 264, 5081, 2424, 11, 51796], "temperature": 0.0, "avg_logprob": -0.16543263080073337, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.012420712038874626}, {"id": 507, "seek": 366844, "start": 3668.44, "end": 3677.88, "text": " I really very appreciate it. Thank you. So we have Ibrat and Melissa. Yes.", "tokens": [50364, 286, 534, 588, 4449, 309, 13, 1044, 291, 13, 407, 321, 362, 286, 1443, 267, 293, 22844, 13, 1079, 13, 50836], "temperature": 0.0, "avg_logprob": -0.19734515938707578, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.001886253827251494}, {"id": 508, "seek": 366844, "start": 3679.88, "end": 3686.04, "text": " My question is about, you talked about kind of doing bottom-up and top-down approach to working", "tokens": [50936, 1222, 1168, 307, 466, 11, 291, 2825, 466, 733, 295, 884, 2767, 12, 1010, 293, 1192, 12, 5093, 3109, 281, 1364, 51244], "temperature": 0.0, "avg_logprob": -0.19734515938707578, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.001886253827251494}, {"id": 509, "seek": 366844, "start": 3686.04, "end": 3691.4, "text": " with the data. Where do you see the role of the thick description in this, and would you say", "tokens": [51244, 365, 264, 1412, 13, 2305, 360, 291, 536, 264, 3090, 295, 264, 5060, 3855, 294, 341, 11, 293, 576, 291, 584, 51512], "temperature": 0.0, "avg_logprob": -0.19734515938707578, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.001886253827251494}, {"id": 510, "seek": 366844, "start": 3691.4, "end": 3697.2400000000002, "text": " thick description? What is the sit in between those two polarities, so to speak? Well, thick", "tokens": [51512, 5060, 3855, 30, 708, 307, 264, 1394, 294, 1296, 729, 732, 12367, 1088, 11, 370, 281, 1710, 30, 1042, 11, 5060, 51804], "temperature": 0.0, "avg_logprob": -0.19734515938707578, "compression_ratio": 1.5892857142857142, "no_speech_prob": 0.001886253827251494}, {"id": 511, "seek": 369724, "start": 3697.24, "end": 3702.2, "text": " description for me is more of a bottom-up approach, and I'm going to be talking about narrative", "tokens": [50364, 3855, 337, 385, 307, 544, 295, 257, 2767, 12, 1010, 3109, 11, 293, 286, 478, 516, 281, 312, 1417, 466, 9977, 50612], "temperature": 0.0, "avg_logprob": -0.18840617027835568, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0013651133049279451}, {"id": 512, "seek": 369724, "start": 3703.3999999999996, "end": 3713.4799999999996, "text": " after, you know, next. So I think that we can get into that, and you know, its narrative is", "tokens": [50672, 934, 11, 291, 458, 11, 958, 13, 407, 286, 519, 300, 321, 393, 483, 666, 300, 11, 293, 291, 458, 11, 1080, 9977, 307, 51176], "temperature": 0.0, "avg_logprob": -0.18840617027835568, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0013651133049279451}, {"id": 513, "seek": 369724, "start": 3714.3599999999997, "end": 3721.56, "text": " doing a thick description as something you might do first, or something you might do", "tokens": [51220, 884, 257, 5060, 3855, 382, 746, 291, 1062, 360, 700, 11, 420, 746, 291, 1062, 360, 51580], "temperature": 0.0, "avg_logprob": -0.18840617027835568, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0013651133049279451}, {"id": 514, "seek": 372156, "start": 3721.56, "end": 3727.96, "text": " last when you have done coding. It both is possible. So anyway, we'll talk about that", "tokens": [50364, 1036, 562, 291, 362, 1096, 17720, 13, 467, 1293, 307, 1944, 13, 407, 4033, 11, 321, 603, 751, 466, 300, 50684], "temperature": 0.0, "avg_logprob": -0.19247221265520367, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004591505508869886}, {"id": 515, "seek": 372156, "start": 3729.16, "end": 3736.84, "text": " in a few minutes, if that's okay. So let's have, but probably best to have one last question from", "tokens": [50744, 294, 257, 1326, 2077, 11, 498, 300, 311, 1392, 13, 407, 718, 311, 362, 11, 457, 1391, 1151, 281, 362, 472, 1036, 1168, 490, 51128], "temperature": 0.0, "avg_logprob": -0.19247221265520367, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004591505508869886}, {"id": 516, "seek": 372156, "start": 3736.84, "end": 3744.44, "text": " from Melissa. Thanks, Anne. I'm struggling a bit because I'm looking at transformation", "tokens": [51128, 490, 22844, 13, 2561, 11, 13706, 13, 286, 478, 9314, 257, 857, 570, 286, 478, 1237, 412, 9887, 51508], "temperature": 0.0, "avg_logprob": -0.19247221265520367, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.004591505508869886}, {"id": 517, "seek": 374444, "start": 3745.4, "end": 3752.84, "text": " comparing it with typical organizational change in that it's constant, and so looking at a strong", "tokens": [50412, 15763, 309, 365, 7476, 24730, 1319, 294, 300, 309, 311, 5754, 11, 293, 370, 1237, 412, 257, 2068, 50784], "temperature": 0.0, "avg_logprob": -0.1028337050020025, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.020004237070679665}, {"id": 518, "seek": 374444, "start": 3752.84, "end": 3759.8, "text": " process theory, but at the same time looking for those constants that are in the river,", "tokens": [50784, 1399, 5261, 11, 457, 412, 264, 912, 565, 1237, 337, 729, 35870, 300, 366, 294, 264, 6810, 11, 51132], "temperature": 0.0, "avg_logprob": -0.1028337050020025, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.020004237070679665}, {"id": 519, "seek": 374444, "start": 3759.8, "end": 3765.0, "text": " and how to sort of frame it. So I've been trying to use different lenses, like performativity,", "tokens": [51132, 293, 577, 281, 1333, 295, 3920, 309, 13, 407, 286, 600, 668, 1382, 281, 764, 819, 18059, 11, 411, 2042, 30142, 11, 51392], "temperature": 0.0, "avg_logprob": -0.1028337050020025, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.020004237070679665}, {"id": 520, "seek": 374444, "start": 3765.0, "end": 3771.96, "text": " and the transformation is a journey, but I'm getting a bit stuck between, well, the right,", "tokens": [51392, 293, 264, 9887, 307, 257, 4671, 11, 457, 286, 478, 1242, 257, 857, 5541, 1296, 11, 731, 11, 264, 558, 11, 51740], "temperature": 0.0, "avg_logprob": -0.1028337050020025, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.020004237070679665}, {"id": 521, "seek": 377196, "start": 3771.96, "end": 3780.2, "text": " really the right lens to sort of capture the, and make the theoretical contribution", "tokens": [50364, 534, 264, 558, 6765, 281, 1333, 295, 7983, 264, 11, 293, 652, 264, 20864, 13150, 50776], "temperature": 0.0, "avg_logprob": -0.1325850670154278, "compression_ratio": 1.50920245398773, "no_speech_prob": 0.0009996130829676986}, {"id": 522, "seek": 377196, "start": 3780.2, "end": 3784.92, "text": " to show that this is something different if we're talking, for example, in this case about", "tokens": [50776, 281, 855, 300, 341, 307, 746, 819, 498, 321, 434, 1417, 11, 337, 1365, 11, 294, 341, 1389, 466, 51012], "temperature": 0.0, "avg_logprob": -0.1325850670154278, "compression_ratio": 1.50920245398773, "no_speech_prob": 0.0009996130829676986}, {"id": 523, "seek": 377196, "start": 3784.92, "end": 3791.16, "text": " digital transformation versus sort of status quo organizational change.", "tokens": [51012, 4562, 9887, 5717, 1333, 295, 6558, 28425, 24730, 1319, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1325850670154278, "compression_ratio": 1.50920245398773, "no_speech_prob": 0.0009996130829676986}, {"id": 524, "seek": 379116, "start": 3791.3199999999997, "end": 3802.7599999999998, "text": " So I'm not quite sure I have to respond to that, but I do think I've always thought of, you know,", "tokens": [50372, 407, 286, 478, 406, 1596, 988, 286, 362, 281, 4196, 281, 300, 11, 457, 286, 360, 519, 286, 600, 1009, 1194, 295, 11, 291, 458, 11, 50944], "temperature": 0.0, "avg_logprob": -0.18701515557631007, "compression_ratio": 1.35, "no_speech_prob": 0.00504894508048892}, {"id": 525, "seek": 379116, "start": 3802.7599999999998, "end": 3813.72, "text": " transformational change as being, okay, fine, you get you shock a system with some kind of,", "tokens": [50944, 4088, 1478, 1319, 382, 885, 11, 1392, 11, 2489, 11, 291, 483, 291, 5588, 257, 1185, 365, 512, 733, 295, 11, 51492], "temperature": 0.0, "avg_logprob": -0.18701515557631007, "compression_ratio": 1.35, "no_speech_prob": 0.00504894508048892}, {"id": 526, "seek": 381372, "start": 3814.3599999999997, "end": 3817.56, "text": " well, you know, one time supposedly one time", "tokens": [50396, 731, 11, 291, 458, 11, 472, 565, 20581, 472, 565, 50556], "temperature": 0.0, "avg_logprob": -0.1597457758585612, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.002713441615924239}, {"id": 527, "seek": 381372, "start": 3820.7599999999998, "end": 3827.64, "text": " initiative, but then it kind of gets itself into woven with what is already going on", "tokens": [50716, 11552, 11, 457, 550, 309, 733, 295, 2170, 2564, 666, 39221, 365, 437, 307, 1217, 516, 322, 51060], "temperature": 0.0, "avg_logprob": -0.1597457758585612, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.002713441615924239}, {"id": 528, "seek": 381372, "start": 3828.2, "end": 3836.2, "text": " in the company or the organization, and so it becomes continuous. And so change changes,", "tokens": [51088, 294, 264, 2237, 420, 264, 4475, 11, 293, 370, 309, 3643, 10957, 13, 400, 370, 1319, 2962, 11, 51488], "temperature": 0.0, "avg_logprob": -0.1597457758585612, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.002713441615924239}, {"id": 529, "seek": 381372, "start": 3836.2, "end": 3840.7599999999998, "text": " this is the way I think about it, so that so that you have this one time transformation,", "tokens": [51488, 341, 307, 264, 636, 286, 519, 466, 309, 11, 370, 300, 370, 300, 291, 362, 341, 472, 565, 9887, 11, 51716], "temperature": 0.0, "avg_logprob": -0.1597457758585612, "compression_ratio": 1.5824742268041236, "no_speech_prob": 0.002713441615924239}, {"id": 530, "seek": 384076, "start": 3840.76, "end": 3846.0400000000004, "text": " but it gets transformed, it gets changed by the continuity of ongoing change.", "tokens": [50364, 457, 309, 2170, 16894, 11, 309, 2170, 3105, 538, 264, 23807, 295, 10452, 1319, 13, 50628], "temperature": 0.0, "avg_logprob": -0.08773991335993228, "compression_ratio": 1.8655913978494623, "no_speech_prob": 0.0007313263486139476}, {"id": 531, "seek": 384076, "start": 3848.5200000000004, "end": 3856.6000000000004, "text": " And so I like to have that, I like to have that kind of image where, yeah, you do a merger,", "tokens": [50752, 400, 370, 286, 411, 281, 362, 300, 11, 286, 411, 281, 362, 300, 733, 295, 3256, 689, 11, 1338, 11, 291, 360, 257, 48002, 11, 51156], "temperature": 0.0, "avg_logprob": -0.08773991335993228, "compression_ratio": 1.8655913978494623, "no_speech_prob": 0.0007313263486139476}, {"id": 532, "seek": 384076, "start": 3856.6000000000004, "end": 3861.6400000000003, "text": " and then you don't do a merger, and then everything is, you know, then you have a result,", "tokens": [51156, 293, 550, 291, 500, 380, 360, 257, 48002, 11, 293, 550, 1203, 307, 11, 291, 458, 11, 550, 291, 362, 257, 1874, 11, 51408], "temperature": 0.0, "avg_logprob": -0.08773991335993228, "compression_ratio": 1.8655913978494623, "no_speech_prob": 0.0007313263486139476}, {"id": 533, "seek": 384076, "start": 3861.6400000000003, "end": 3866.28, "text": " you do a merger, and then all of the things that were going on anyway in the enterprise", "tokens": [51408, 291, 360, 257, 48002, 11, 293, 550, 439, 295, 264, 721, 300, 645, 516, 322, 4033, 294, 264, 14132, 51640], "temperature": 0.0, "avg_logprob": -0.08773991335993228, "compression_ratio": 1.8655913978494623, "no_speech_prob": 0.0007313263486139476}, {"id": 534, "seek": 386628, "start": 3866.92, "end": 3876.6000000000004, "text": " kind of change what that means. So I think that that can be done, and I think that you can trace,", "tokens": [50396, 733, 295, 1319, 437, 300, 1355, 13, 407, 286, 519, 300, 300, 393, 312, 1096, 11, 293, 286, 519, 300, 291, 393, 13508, 11, 50880], "temperature": 0.0, "avg_logprob": -0.09874319418882713, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.0014544184086844325}, {"id": 535, "seek": 386628, "start": 3876.6000000000004, "end": 3883.0800000000004, "text": " you can trace, you know, the moment of change, and then trace through the ripples that it creates,", "tokens": [50880, 291, 393, 13508, 11, 291, 458, 11, 264, 1623, 295, 1319, 11, 293, 550, 13508, 807, 264, 367, 37674, 300, 309, 7829, 11, 51204], "temperature": 0.0, "avg_logprob": -0.09874319418882713, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.0014544184086844325}, {"id": 536, "seek": 386628, "start": 3883.0800000000004, "end": 3891.1600000000003, "text": " so that it may create big ripples and small ripples. And I don't know, I would tend to", "tokens": [51204, 370, 300, 309, 815, 1884, 955, 367, 37674, 293, 1359, 367, 37674, 13, 400, 286, 500, 380, 458, 11, 286, 576, 3928, 281, 51608], "temperature": 0.0, "avg_logprob": -0.09874319418882713, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.0014544184086844325}, {"id": 537, "seek": 389116, "start": 3891.56, "end": 3900.7599999999998, "text": " look at some kind of temporal bracketing where I would see waves occurring.", "tokens": [50384, 574, 412, 512, 733, 295, 30881, 12305, 9880, 689, 286, 576, 536, 9417, 18386, 13, 50844], "temperature": 0.0, "avg_logprob": -0.14143247604370118, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.0009541730978526175}, {"id": 538, "seek": 389116, "start": 3902.12, "end": 3908.12, "text": " We're trying to understand capacity for the transformation, and the issue is that capacity", "tokens": [50912, 492, 434, 1382, 281, 1223, 6042, 337, 264, 9887, 11, 293, 264, 2734, 307, 300, 6042, 51212], "temperature": 0.0, "avg_logprob": -0.14143247604370118, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.0009541730978526175}, {"id": 539, "seek": 389116, "start": 3908.12, "end": 3913.3999999999996, "text": " seems to be a boundary, it is or it isn't, and yet are there certain constituent components", "tokens": [51212, 2544, 281, 312, 257, 12866, 11, 309, 307, 420, 309, 1943, 380, 11, 293, 1939, 366, 456, 1629, 16085, 317, 6677, 51476], "temperature": 0.0, "avg_logprob": -0.14143247604370118, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.0009541730978526175}, {"id": 540, "seek": 391340, "start": 3913.88, "end": 3921.7200000000003, "text": " that enable this transformation to be possible, and is it the right theoretical lens to use", "tokens": [50388, 300, 9528, 341, 9887, 281, 312, 1944, 11, 293, 307, 309, 264, 558, 20864, 6765, 281, 764, 50780], "temperature": 0.0, "avg_logprob": -0.18676881905061654, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.021923143416643143}, {"id": 541, "seek": 391340, "start": 3921.7200000000003, "end": 3928.6, "text": " performativity if we're trying to sort of talk about, and maybe boundary condition is not even", "tokens": [50780, 2042, 30142, 498, 321, 434, 1382, 281, 1333, 295, 751, 466, 11, 293, 1310, 12866, 4188, 307, 406, 754, 51124], "temperature": 0.0, "avg_logprob": -0.18676881905061654, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.021923143416643143}, {"id": 542, "seek": 391340, "start": 3928.6, "end": 3934.28, "text": " the right term to use anymore, but, you know, the approach was to use necessary condition analysis", "tokens": [51124, 264, 558, 1433, 281, 764, 3602, 11, 457, 11, 291, 458, 11, 264, 3109, 390, 281, 764, 4818, 4188, 5215, 51408], "temperature": 0.0, "avg_logprob": -0.18676881905061654, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.021923143416643143}, {"id": 543, "seek": 391340, "start": 3934.28, "end": 3939.64, "text": " and the data to try to find, yeah, that doesn't even make sense.", "tokens": [51408, 293, 264, 1412, 281, 853, 281, 915, 11, 1338, 11, 300, 1177, 380, 754, 652, 2020, 13, 51676], "temperature": 0.0, "avg_logprob": -0.18676881905061654, "compression_ratio": 1.6908212560386473, "no_speech_prob": 0.021923143416643143}, {"id": 544, "seek": 393964, "start": 3940.6, "end": 3946.04, "text": " I mean, why don't you send me an email? I have a little problem with the notion of capacity,", "tokens": [50412, 286, 914, 11, 983, 500, 380, 291, 2845, 385, 364, 3796, 30, 286, 362, 257, 707, 1154, 365, 264, 10710, 295, 6042, 11, 50684], "temperature": 0.0, "avg_logprob": -0.13727378845214844, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0009388118050992489}, {"id": 545, "seek": 393964, "start": 3946.04, "end": 3953.16, "text": " because it's kind of static, right? It's a thing, it conveys the idea of something that's fixed,", "tokens": [50684, 570, 309, 311, 733, 295, 13437, 11, 558, 30, 467, 311, 257, 551, 11, 309, 18053, 749, 264, 1558, 295, 746, 300, 311, 6806, 11, 51040], "temperature": 0.0, "avg_logprob": -0.13727378845214844, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0009388118050992489}, {"id": 546, "seek": 393964, "start": 3953.16, "end": 3960.52, "text": " a capacity, or a capability, because this is something which changes over time, the capacity,", "tokens": [51040, 257, 6042, 11, 420, 257, 13759, 11, 570, 341, 307, 746, 597, 2962, 670, 565, 11, 264, 6042, 11, 51408], "temperature": 0.0, "avg_logprob": -0.13727378845214844, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0009388118050992489}, {"id": 547, "seek": 393964, "start": 3960.52, "end": 3966.2799999999997, "text": " you know, you learn, so you have great capacity, and so everything is evolving, and so the notions", "tokens": [51408, 291, 458, 11, 291, 1466, 11, 370, 291, 362, 869, 6042, 11, 293, 370, 1203, 307, 21085, 11, 293, 370, 264, 35799, 51696], "temperature": 0.0, "avg_logprob": -0.13727378845214844, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0009388118050992489}, {"id": 548, "seek": 396628, "start": 3966.36, "end": 3972.6000000000004, "text": " like capacity, feel a bit uncomfortable with, you could, when you could talk about capacity work,", "tokens": [50368, 411, 6042, 11, 841, 257, 857, 10532, 365, 11, 291, 727, 11, 562, 291, 727, 751, 466, 6042, 589, 11, 50680], "temperature": 0.0, "avg_logprob": -0.20916060941765108, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.000999906682409346}, {"id": 549, "seek": 396628, "start": 3972.6000000000004, "end": 3979.32, "text": " which is working on the capacity, so then you get to doing again, but-", "tokens": [50680, 597, 307, 1364, 322, 264, 6042, 11, 370, 550, 291, 483, 281, 884, 797, 11, 457, 12, 51016], "temperature": 0.0, "avg_logprob": -0.20916060941765108, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.000999906682409346}, {"id": 550, "seek": 396628, "start": 3979.32, "end": 3981.96, "text": " That's super helpful, thank you so much.", "tokens": [51016, 663, 311, 1687, 4961, 11, 1309, 291, 370, 709, 13, 51148], "temperature": 0.0, "avg_logprob": -0.20916060941765108, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.000999906682409346}, {"id": 551, "seek": 396628, "start": 3983.0, "end": 3991.0, "text": " All right, okay, so I think we'll, we'll move on a little bit, because we don't have that much", "tokens": [51200, 1057, 558, 11, 1392, 11, 370, 286, 519, 321, 603, 11, 321, 603, 1286, 322, 257, 707, 857, 11, 570, 321, 500, 380, 362, 300, 709, 51600], "temperature": 0.0, "avg_logprob": -0.20916060941765108, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.000999906682409346}, {"id": 552, "seek": 399100, "start": 3991.0, "end": 3995.16, "text": " time, so I'm going to try and perhaps accelerate a little bit here,", "tokens": [50364, 565, 11, 370, 286, 478, 516, 281, 853, 293, 4317, 21341, 257, 707, 857, 510, 11, 50572], "temperature": 0.0, "avg_logprob": -0.13032213379355037, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.0013247058959677815}, {"id": 553, "seek": 399100, "start": 3997.8, "end": 4006.52, "text": " and I have to share my screen again, right? Okay, so we're now moving on to the middle column here,", "tokens": [50704, 293, 286, 362, 281, 2073, 452, 2568, 797, 11, 558, 30, 1033, 11, 370, 321, 434, 586, 2684, 322, 281, 264, 2808, 7738, 510, 11, 51140], "temperature": 0.0, "avg_logprob": -0.13032213379355037, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.0013247058959677815}, {"id": 554, "seek": 399100, "start": 4007.16, "end": 4014.76, "text": " which is displaying process data, and so I'm going to talk about two strategies that I mentioned", "tokens": [51172, 597, 307, 36834, 1399, 1412, 11, 293, 370, 286, 478, 516, 281, 751, 466, 732, 9029, 300, 286, 2835, 51552], "temperature": 0.0, "avg_logprob": -0.13032213379355037, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.0013247058959677815}, {"id": 555, "seek": 401476, "start": 4014.76, "end": 4021.7200000000003, "text": " in my paper, which are narrative and visual mapping, and so there's two different ways of", "tokens": [50364, 294, 452, 3035, 11, 597, 366, 9977, 293, 5056, 18350, 11, 293, 370, 456, 311, 732, 819, 2098, 295, 50712], "temperature": 0.0, "avg_logprob": -0.07093675697551054, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.000925232598092407}, {"id": 556, "seek": 401476, "start": 4021.7200000000003, "end": 4028.6000000000004, "text": " displaying, the first one is displaying your data in terms of words, and the second one is", "tokens": [50712, 36834, 11, 264, 700, 472, 307, 36834, 428, 1412, 294, 2115, 295, 2283, 11, 293, 264, 1150, 472, 307, 51056], "temperature": 0.0, "avg_logprob": -0.07093675697551054, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.000925232598092407}, {"id": 557, "seek": 401476, "start": 4029.1600000000003, "end": 4040.28, "text": " in terms of drawing, in terms of pictures, so if we look at narrative, this is so easy,", "tokens": [51084, 294, 2115, 295, 6316, 11, 294, 2115, 295, 5242, 11, 370, 498, 321, 574, 412, 9977, 11, 341, 307, 370, 1858, 11, 51640], "temperature": 0.0, "avg_logprob": -0.07093675697551054, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.000925232598092407}, {"id": 558, "seek": 404028, "start": 4040.28, "end": 4046.52, "text": " just tell the story, just write it up, you know, all you have to do is to write the story, and", "tokens": [50364, 445, 980, 264, 1657, 11, 445, 2464, 309, 493, 11, 291, 458, 11, 439, 291, 362, 281, 360, 307, 281, 2464, 264, 1657, 11, 293, 50676], "temperature": 0.0, "avg_logprob": -0.16527050128881482, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.005215347744524479}, {"id": 559, "seek": 404028, "start": 4046.52, "end": 4053.32, "text": " there are classics here, Alfred Chandler, for example, historian tells a narrative,", "tokens": [50676, 456, 366, 36110, 510, 11, 28327, 32244, 1918, 11, 337, 1365, 11, 25139, 5112, 257, 9977, 11, 51016], "temperature": 0.0, "avg_logprob": -0.16527050128881482, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.005215347744524479}, {"id": 560, "seek": 404028, "start": 4053.32, "end": 4059.88, "text": " his theorizing is very much narrative-based, and as Ibrat mentioned, thick description", "tokens": [51016, 702, 27423, 3319, 307, 588, 709, 9977, 12, 6032, 11, 293, 382, 286, 1443, 267, 2835, 11, 5060, 3855, 51344], "temperature": 0.0, "avg_logprob": -0.16527050128881482, "compression_ratio": 1.5406976744186047, "no_speech_prob": 0.005215347744524479}, {"id": 561, "seek": 405988, "start": 4060.52, "end": 4071.0, "text": " from anthropology is a term that Geertz uses to, to talk about his approach as thick description,", "tokens": [50396, 490, 44518, 307, 257, 1433, 300, 2876, 911, 89, 4960, 281, 11, 281, 751, 466, 702, 3109, 382, 5060, 3855, 11, 50920], "temperature": 0.0, "avg_logprob": -0.1405619032242719, "compression_ratio": 1.5754189944134078, "no_speech_prob": 0.053348109126091}, {"id": 562, "seek": 405988, "start": 4071.0, "end": 4078.36, "text": " and if you do these things well, so basically what you're doing is you're taking the mess of", "tokens": [50920, 293, 498, 291, 360, 613, 721, 731, 11, 370, 1936, 437, 291, 434, 884, 307, 291, 434, 1940, 264, 2082, 295, 51288], "temperature": 0.0, "avg_logprob": -0.1405619032242719, "compression_ratio": 1.5754189944134078, "no_speech_prob": 0.053348109126091}, {"id": 563, "seek": 405988, "start": 4078.36, "end": 4085.7200000000003, "text": " data that you have, bringing them together to create a narrative, and a narrative that will", "tokens": [51288, 1412, 300, 291, 362, 11, 5062, 552, 1214, 281, 1884, 257, 9977, 11, 293, 257, 9977, 300, 486, 51656], "temperature": 0.0, "avg_logprob": -0.1405619032242719, "compression_ratio": 1.5754189944134078, "no_speech_prob": 0.053348109126091}, {"id": 564, "seek": 408572, "start": 4086.2799999999997, "end": 4094.2, "text": " hopefully tell you something about the world that reaches beyond the particular case,", "tokens": [50392, 4696, 980, 291, 746, 466, 264, 1002, 300, 14235, 4399, 264, 1729, 1389, 11, 50788], "temperature": 0.0, "avg_logprob": -0.12186963341452858, "compression_ratio": 1.4768211920529801, "no_speech_prob": 0.000968978856690228}, {"id": 565, "seek": 408572, "start": 4094.9199999999996, "end": 4101.0, "text": " and so narrative can be very powerful, and if it works, you get a sense of this,", "tokens": [50824, 293, 370, 9977, 393, 312, 588, 4005, 11, 293, 498, 309, 1985, 11, 291, 483, 257, 2020, 295, 341, 11, 51128], "temperature": 0.0, "avg_logprob": -0.12186963341452858, "compression_ratio": 1.4768211920529801, "no_speech_prob": 0.000968978856690228}, {"id": 566, "seek": 408572, "start": 4102.2, "end": 4108.5199999999995, "text": " I've seen this before, so a really good narrative study,", "tokens": [51188, 286, 600, 1612, 341, 949, 11, 370, 257, 534, 665, 9977, 2979, 11, 51504], "temperature": 0.0, "avg_logprob": -0.12186963341452858, "compression_ratio": 1.4768211920529801, "no_speech_prob": 0.000968978856690228}, {"id": 567, "seek": 410852, "start": 4108.68, "end": 4115.64, "text": " it'll be like a really good novel, because you will see, okay, this makes sense, this is,", "tokens": [50372, 309, 603, 312, 411, 257, 534, 665, 7613, 11, 570, 291, 486, 536, 11, 1392, 11, 341, 1669, 2020, 11, 341, 307, 11, 50720], "temperature": 0.0, "avg_logprob": -0.16283186276753744, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.00599701190367341}, {"id": 568, "seek": 410852, "start": 4115.64, "end": 4123.72, "text": " this is how the world is, and so it can be really appealing to have a strong narrative,", "tokens": [50720, 341, 307, 577, 264, 1002, 307, 11, 293, 370, 309, 393, 312, 534, 23842, 281, 362, 257, 2068, 9977, 11, 51124], "temperature": 0.0, "avg_logprob": -0.16283186276753744, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.00599701190367341}, {"id": 569, "seek": 410852, "start": 4125.8, "end": 4135.0, "text": " and then I really like this quote from John Van Lennon, who argues in favor of narrative,", "tokens": [51228, 293, 550, 286, 534, 411, 341, 6513, 490, 2619, 8979, 441, 1857, 266, 11, 567, 38218, 294, 2294, 295, 9977, 11, 51688], "temperature": 0.0, "avg_logprob": -0.16283186276753744, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.00599701190367341}, {"id": 570, "seek": 413500, "start": 4135.0, "end": 4140.76, "text": " because precisely because narrative allows for complexity and ambiguity,", "tokens": [50364, 570, 13402, 570, 9977, 4045, 337, 14024, 293, 46519, 11, 50652], "temperature": 0.0, "avg_logprob": -0.127666175365448, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0011327905813232064}, {"id": 571, "seek": 413500, "start": 4141.88, "end": 4151.4, "text": " and if your case that you have is fuzzy and messy and ambiguous, then if you want to render it", "tokens": [50708, 293, 498, 428, 1389, 300, 291, 362, 307, 34710, 293, 16191, 293, 39465, 11, 550, 498, 291, 528, 281, 15529, 309, 51184], "temperature": 0.0, "avg_logprob": -0.127666175365448, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0011327905813232064}, {"id": 572, "seek": 413500, "start": 4153.0, "end": 4161.16, "text": " and keep that side of it, then, you know, he says to be determined, we must be indeterminate,", "tokens": [51264, 293, 1066, 300, 1252, 295, 309, 11, 550, 11, 291, 458, 11, 415, 1619, 281, 312, 9540, 11, 321, 1633, 312, 1016, 35344, 13923, 11, 51672], "temperature": 0.0, "avg_logprob": -0.127666175365448, "compression_ratio": 1.6518987341772151, "no_speech_prob": 0.0011327905813232064}, {"id": 573, "seek": 416116, "start": 4161.16, "end": 4165.4, "text": " because things are confusing, because things are messy, and so on and so forth,", "tokens": [50364, 570, 721, 366, 13181, 11, 570, 721, 366, 16191, 11, 293, 370, 322, 293, 370, 5220, 11, 50576], "temperature": 0.0, "avg_logprob": -0.11666808809552874, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.0004440367338247597}, {"id": 574, "seek": 416116, "start": 4166.36, "end": 4172.28, "text": " so a narrative approach tends to try and keep as much of the richness as possible,", "tokens": [50624, 370, 257, 9977, 3109, 12258, 281, 853, 293, 1066, 382, 709, 295, 264, 44506, 382, 1944, 11, 50920], "temperature": 0.0, "avg_logprob": -0.11666808809552874, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.0004440367338247597}, {"id": 575, "seek": 416116, "start": 4172.28, "end": 4180.36, "text": " but at the same time, give you that sense of deja vu, so that's the positive side,", "tokens": [50920, 457, 412, 264, 912, 565, 11, 976, 291, 300, 2020, 295, 38260, 9732, 11, 370, 300, 311, 264, 3353, 1252, 11, 51324], "temperature": 0.0, "avg_logprob": -0.11666808809552874, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.0004440367338247597}, {"id": 576, "seek": 416116, "start": 4181.16, "end": 4188.28, "text": " this is the negative side, and so this is Laurel Richardson in the handbook of quality", "tokens": [51364, 341, 307, 264, 3671, 1252, 11, 293, 370, 341, 307, 27270, 75, 48492, 294, 264, 1011, 2939, 295, 3125, 51720], "temperature": 0.0, "avg_logprob": -0.11666808809552874, "compression_ratio": 1.6852791878172588, "no_speech_prob": 0.0004440367338247597}, {"id": 577, "seek": 418828, "start": 4188.36, "end": 4193.08, "text": " research, and she says, I have a confession to make for 30 years, I have worked my way through", "tokens": [50368, 2132, 11, 293, 750, 1619, 11, 286, 362, 257, 29154, 281, 652, 337, 2217, 924, 11, 286, 362, 2732, 452, 636, 807, 50604], "temperature": 0.0, "avg_logprob": -0.11747435401467717, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.007930279709398746}, {"id": 578, "seek": 418828, "start": 4193.08, "end": 4201.88, "text": " numerous supposedly exemplary qualitative studies, and it's boring, basically it can be so boring,", "tokens": [50604, 12546, 20581, 24112, 822, 31312, 5313, 11, 293, 309, 311, 9989, 11, 1936, 309, 393, 312, 370, 9989, 11, 51044], "temperature": 0.0, "avg_logprob": -0.11747435401467717, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.007930279709398746}, {"id": 579, "seek": 418828, "start": 4201.88, "end": 4207.719999999999, "text": " and the reason is that it's just descriptive sometimes, and so it's blind alley two again,", "tokens": [51044, 293, 264, 1778, 307, 300, 309, 311, 445, 42585, 2171, 11, 293, 370, 309, 311, 6865, 26660, 732, 797, 11, 51336], "temperature": 0.0, "avg_logprob": -0.11747435401467717, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.007930279709398746}, {"id": 580, "seek": 418828, "start": 4209.08, "end": 4216.12, "text": " where you have so closely captured your empirical data that we can't see", "tokens": [51404, 689, 291, 362, 370, 8185, 11828, 428, 31886, 1412, 300, 321, 393, 380, 536, 51756], "temperature": 0.0, "avg_logprob": -0.11747435401467717, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.007930279709398746}, {"id": 581, "seek": 421612, "start": 4216.92, "end": 4223.24, "text": " the deja vu, we can't see the plot within it, and so this is the problem of narrative,", "tokens": [50404, 264, 38260, 9732, 11, 321, 393, 380, 536, 264, 7542, 1951, 309, 11, 293, 370, 341, 307, 264, 1154, 295, 9977, 11, 50720], "temperature": 0.0, "avg_logprob": -0.11352999550955636, "compression_ratio": 1.6603773584905661, "no_speech_prob": 0.001387304742820561}, {"id": 582, "seek": 421612, "start": 4224.28, "end": 4230.2, "text": " but at the same time, there's almost no qualitative study where you don't at some", "tokens": [50772, 457, 412, 264, 912, 565, 11, 456, 311, 1920, 572, 31312, 2979, 689, 291, 500, 380, 412, 512, 51068], "temperature": 0.0, "avg_logprob": -0.11352999550955636, "compression_ratio": 1.6603773584905661, "no_speech_prob": 0.001387304742820561}, {"id": 583, "seek": 421612, "start": 4230.2, "end": 4239.72, "text": " point draw on narrative, so what are some of the other ways to draw on narrative, so one way is", "tokens": [51068, 935, 2642, 322, 9977, 11, 370, 437, 366, 512, 295, 264, 661, 2098, 281, 2642, 322, 9977, 11, 370, 472, 636, 307, 51544], "temperature": 0.0, "avg_logprob": -0.11352999550955636, "compression_ratio": 1.6603773584905661, "no_speech_prob": 0.001387304742820561}, {"id": 584, "seek": 423972, "start": 4239.72, "end": 4249.16, "text": " to use it as the first step, so you have all this mess, why not just try and write it up", "tokens": [50364, 281, 764, 309, 382, 264, 700, 1823, 11, 370, 291, 362, 439, 341, 2082, 11, 983, 406, 445, 853, 293, 2464, 309, 493, 50836], "temperature": 0.0, "avg_logprob": -0.09091478154279184, "compression_ratio": 1.625, "no_speech_prob": 0.019979184493422508}, {"id": 585, "seek": 423972, "start": 4250.6, "end": 4256.76, "text": " as completely as possible, and this Kathleen Eisenhardt, this is the step that she always", "tokens": [50908, 382, 2584, 382, 1944, 11, 293, 341, 41648, 35619, 21491, 83, 11, 341, 307, 264, 1823, 300, 750, 1009, 51216], "temperature": 0.0, "avg_logprob": -0.09091478154279184, "compression_ratio": 1.625, "no_speech_prob": 0.019979184493422508}, {"id": 586, "seek": 423972, "start": 4256.76, "end": 4262.12, "text": " recommends, and she talks about multiple case studies, and she talks about how for each of her", "tokens": [51216, 34556, 11, 293, 750, 6686, 466, 3866, 1389, 5313, 11, 293, 750, 6686, 466, 577, 337, 1184, 295, 720, 51484], "temperature": 0.0, "avg_logprob": -0.09091478154279184, "compression_ratio": 1.625, "no_speech_prob": 0.019979184493422508}, {"id": 587, "seek": 426212, "start": 4262.2, "end": 4271.48, "text": " cases, she writes something like a 70-page, single-spaced story, and that story becomes", "tokens": [50368, 3331, 11, 750, 13657, 746, 411, 257, 5285, 12, 15161, 11, 2167, 12, 4952, 3839, 1657, 11, 293, 300, 1657, 3643, 50832], "temperature": 0.0, "avg_logprob": -0.12624575751168388, "compression_ratio": 1.6094674556213018, "no_speech_prob": 0.014717115089297295}, {"id": 588, "seek": 426212, "start": 4271.48, "end": 4281.88, "text": " like a secondary database for the rest, it's a way just to get started, and it becomes,", "tokens": [50832, 411, 257, 11396, 8149, 337, 264, 1472, 11, 309, 311, 257, 636, 445, 281, 483, 1409, 11, 293, 309, 3643, 11, 51352], "temperature": 0.0, "avg_logprob": -0.12624575751168388, "compression_ratio": 1.6094674556213018, "no_speech_prob": 0.014717115089297295}, {"id": 589, "seek": 426212, "start": 4281.88, "end": 4288.599999999999, "text": " as we're writing this narrative, it becomes the stimulus for your coding that you're going to be", "tokens": [51352, 382, 321, 434, 3579, 341, 9977, 11, 309, 3643, 264, 21366, 337, 428, 17720, 300, 291, 434, 516, 281, 312, 51688], "temperature": 0.0, "avg_logprob": -0.12624575751168388, "compression_ratio": 1.6094674556213018, "no_speech_prob": 0.014717115089297295}, {"id": 590, "seek": 428860, "start": 4288.6, "end": 4295.8, "text": " developing, so that can be one way to use it, the other way to use it is to consider it as your", "tokens": [50364, 6416, 11, 370, 300, 393, 312, 472, 636, 281, 764, 309, 11, 264, 661, 636, 281, 764, 309, 307, 281, 1949, 309, 382, 428, 50724], "temperature": 0.0, "avg_logprob": -0.10494641290194746, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0007790991221554577}, {"id": 591, "seek": 428860, "start": 4295.8, "end": 4303.96, "text": " last, you write the narrative to integrate your coding and your data and your theory, to bring", "tokens": [50724, 1036, 11, 291, 2464, 264, 9977, 281, 13365, 428, 17720, 293, 428, 1412, 293, 428, 5261, 11, 281, 1565, 51132], "temperature": 0.0, "avg_logprob": -0.10494641290194746, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0007790991221554577}, {"id": 592, "seek": 428860, "start": 4303.96, "end": 4308.68, "text": " the data and theory together so that you're telling a story which has concepts in it,", "tokens": [51132, 264, 1412, 293, 5261, 1214, 370, 300, 291, 434, 3585, 257, 1657, 597, 575, 10392, 294, 309, 11, 51368], "temperature": 0.0, "avg_logprob": -0.10494641290194746, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.0007790991221554577}, {"id": 593, "seek": 430868, "start": 4309.320000000001, "end": 4325.72, "text": " and is kind of bringing codes and specifics and generality together, so a really strong narrative", "tokens": [50396, 293, 307, 733, 295, 5062, 14211, 293, 28454, 293, 1337, 1860, 1214, 11, 370, 257, 534, 2068, 9977, 51216], "temperature": 0.0, "avg_logprob": -0.13779851523312656, "compression_ratio": 1.5354330708661417, "no_speech_prob": 0.01743296906352043}, {"id": 594, "seek": 430868, "start": 4325.72, "end": 4336.52, "text": " as a last step is going to be able to take specifics and show how they reflect a more theoretical", "tokens": [51216, 382, 257, 1036, 1823, 307, 516, 281, 312, 1075, 281, 747, 28454, 293, 855, 577, 436, 5031, 257, 544, 20864, 51756], "temperature": 0.0, "avg_logprob": -0.13779851523312656, "compression_ratio": 1.5354330708661417, "no_speech_prob": 0.01743296906352043}, {"id": 595, "seek": 433652, "start": 4336.52, "end": 4340.040000000001, "text": " concept, and you might consider multiple narratives which is getting back to the", "tokens": [50364, 3410, 11, 293, 291, 1062, 1949, 3866, 28016, 597, 307, 1242, 646, 281, 264, 50540], "temperature": 0.0, "avg_logprob": -0.11695908880853034, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.0015482683666050434}, {"id": 596, "seek": 433652, "start": 4340.6, "end": 4347.320000000001, "text": " alternate templates approach, or you could look at multiple narratives based on the visions of", "tokens": [50568, 18873, 21165, 3109, 11, 420, 291, 727, 574, 412, 3866, 28016, 2361, 322, 264, 30746, 295, 50904], "temperature": 0.0, "avg_logprob": -0.11695908880853034, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.0015482683666050434}, {"id": 597, "seek": 433652, "start": 4347.320000000001, "end": 4351.96, "text": " different people in your case, that's another way to multiple narratives, so these are richer ways", "tokens": [50904, 819, 561, 294, 428, 1389, 11, 300, 311, 1071, 636, 281, 3866, 28016, 11, 370, 613, 366, 29021, 2098, 51136], "temperature": 0.0, "avg_logprob": -0.11695908880853034, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.0015482683666050434}, {"id": 598, "seek": 433652, "start": 4352.6, "end": 4360.280000000001, "text": " and more useful ways I think of thinking of narrative, and there's this paradox about narrative", "tokens": [51168, 293, 544, 4420, 2098, 286, 519, 295, 1953, 295, 9977, 11, 293, 456, 311, 341, 26221, 466, 9977, 51552], "temperature": 0.0, "avg_logprob": -0.11695908880853034, "compression_ratio": 1.7535545023696681, "no_speech_prob": 0.0015482683666050434}, {"id": 599, "seek": 436028, "start": 4360.28, "end": 4366.84, "text": " which is you can't write a really good narrative until you know what the plot is,", "tokens": [50364, 597, 307, 291, 393, 380, 2464, 257, 534, 665, 9977, 1826, 291, 458, 437, 264, 7542, 307, 11, 50692], "temperature": 0.0, "avg_logprob": -0.07883003396047673, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0008822788950055838}, {"id": 600, "seek": 436028, "start": 4368.2, "end": 4377.88, "text": " but you can't discover the plot until you've done the narrative, so it's this hermeneutic thing,", "tokens": [50760, 457, 291, 393, 380, 4411, 264, 7542, 1826, 291, 600, 1096, 264, 9977, 11, 370, 309, 311, 341, 720, 76, 1450, 325, 299, 551, 11, 51244], "temperature": 0.0, "avg_logprob": -0.07883003396047673, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0008822788950055838}, {"id": 601, "seek": 436028, "start": 4377.88, "end": 4385.08, "text": " it's this iteration once again, you start writing, you don't have the plot at first,", "tokens": [51244, 309, 311, 341, 24784, 1564, 797, 11, 291, 722, 3579, 11, 291, 500, 380, 362, 264, 7542, 412, 700, 11, 51604], "temperature": 0.0, "avg_logprob": -0.07883003396047673, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0008822788950055838}, {"id": 602, "seek": 438508, "start": 4385.96, "end": 4393.16, "text": " when you discover the plot you have to rewrite it completely, and so it's a kind of a little", "tokens": [50408, 562, 291, 4411, 264, 7542, 291, 362, 281, 28132, 309, 2584, 11, 293, 370, 309, 311, 257, 733, 295, 257, 707, 50768], "temperature": 0.0, "avg_logprob": -0.1078978225366393, "compression_ratio": 1.5393258426966292, "no_speech_prob": 0.0008036709041334689}, {"id": 603, "seek": 438508, "start": 4393.16, "end": 4400.92, "text": " bit of a paradox, and now so that we've talked about narrative, I'm not going to talk about", "tokens": [50768, 857, 295, 257, 26221, 11, 293, 586, 370, 300, 321, 600, 2825, 466, 9977, 11, 286, 478, 406, 516, 281, 751, 466, 51156], "temperature": 0.0, "avg_logprob": -0.1078978225366393, "compression_ratio": 1.5393258426966292, "no_speech_prob": 0.0008036709041334689}, {"id": 604, "seek": 438508, "start": 4400.92, "end": 4411.48, "text": " another way which I really like of displaying qualitative and processed data, and this is", "tokens": [51156, 1071, 636, 597, 286, 534, 411, 295, 36834, 31312, 293, 18846, 1412, 11, 293, 341, 307, 51684], "temperature": 0.0, "avg_logprob": -0.1078978225366393, "compression_ratio": 1.5393258426966292, "no_speech_prob": 0.0008036709041334689}, {"id": 605, "seek": 441148, "start": 4411.48, "end": 4420.28, "text": " visual mapping, and so draw it, draw your data, or draw something, draw your theory,", "tokens": [50364, 5056, 18350, 11, 293, 370, 2642, 309, 11, 2642, 428, 1412, 11, 420, 2642, 746, 11, 2642, 428, 5261, 11, 50804], "temperature": 0.0, "avg_logprob": -0.17494651633249203, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.004602013621479273}, {"id": 606, "seek": 441148, "start": 4421.639999999999, "end": 4431.4, "text": " and so we're talking about graphs, tables, drawings, diagrams, on visual mapping the gurus", "tokens": [50872, 293, 370, 321, 434, 1417, 466, 24877, 11, 8020, 11, 18618, 11, 36709, 11, 322, 5056, 18350, 264, 40642, 301, 51360], "temperature": 0.0, "avg_logprob": -0.17494651633249203, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.004602013621479273}, {"id": 607, "seek": 441148, "start": 4431.4, "end": 4438.2, "text": " here are Miles and Huberman and Sal Danyan, the most recent version of their book has a third", "tokens": [51360, 510, 366, 27384, 293, 389, 10261, 1601, 293, 5996, 413, 1325, 282, 11, 264, 881, 5162, 3037, 295, 641, 1446, 575, 257, 2636, 51700], "temperature": 0.0, "avg_logprob": -0.17494651633249203, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.004602013621479273}, {"id": 608, "seek": 443820, "start": 4438.28, "end": 4445.48, "text": " author, so Miles and Huberman, you should read this, it's a really useful book which", "tokens": [50368, 3793, 11, 370, 27384, 293, 389, 10261, 1601, 11, 291, 820, 1401, 341, 11, 309, 311, 257, 534, 4420, 1446, 597, 50728], "temperature": 0.0, "avg_logprob": -0.19033635180929434, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.0009996508015319705}, {"id": 609, "seek": 443820, "start": 4445.48, "end": 4451.88, "text": " offers a variety of ways of drawing data, and I like it a lot.", "tokens": [50728, 7736, 257, 5673, 295, 2098, 295, 6316, 1412, 11, 293, 286, 411, 309, 257, 688, 13, 51048], "temperature": 0.0, "avg_logprob": -0.19033635180929434, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.0009996508015319705}, {"id": 610, "seek": 443820, "start": 4457.4, "end": 4464.92, "text": " So here's an example, no it isn't an example, okay so what is visual mapping? So visual mapping,", "tokens": [51324, 407, 510, 311, 364, 1365, 11, 572, 309, 1943, 380, 364, 1365, 11, 1392, 370, 437, 307, 5056, 18350, 30, 407, 5056, 18350, 11, 51700], "temperature": 0.0, "avg_logprob": -0.19033635180929434, "compression_ratio": 1.4787878787878788, "no_speech_prob": 0.0009996508015319705}, {"id": 611, "seek": 446492, "start": 4464.92, "end": 4470.76, "text": " you can use any kinds of forms of drawing that you want, but there are a certain number of", "tokens": [50364, 291, 393, 764, 604, 3685, 295, 6422, 295, 6316, 300, 291, 528, 11, 457, 456, 366, 257, 1629, 1230, 295, 50656], "temperature": 0.0, "avg_logprob": -0.06977438123038646, "compression_ratio": 1.9329896907216495, "no_speech_prob": 0.0016998229548335075}, {"id": 612, "seek": 446492, "start": 4470.76, "end": 4478.4400000000005, "text": " conventions which you might want to keep to, so boxes and arrows are obviously important", "tokens": [50656, 33520, 597, 291, 1062, 528, 281, 1066, 281, 11, 370, 9002, 293, 19669, 366, 2745, 1021, 51040], "temperature": 0.0, "avg_logprob": -0.06977438123038646, "compression_ratio": 1.9329896907216495, "no_speech_prob": 0.0016998229548335075}, {"id": 613, "seek": 446492, "start": 4479.4, "end": 4488.12, "text": " aspects of drawing data, but you can use boxes and arrows for different kinds of things, so boxes", "tokens": [51088, 7270, 295, 6316, 1412, 11, 457, 291, 393, 764, 9002, 293, 19669, 337, 819, 3685, 295, 721, 11, 370, 9002, 51524], "temperature": 0.0, "avg_logprob": -0.06977438123038646, "compression_ratio": 1.9329896907216495, "no_speech_prob": 0.0016998229548335075}, {"id": 614, "seek": 446492, "start": 4488.12, "end": 4494.2, "text": " can be things, they can be objects, they can be concepts, they can be actors, they can be events,", "tokens": [51524, 393, 312, 721, 11, 436, 393, 312, 6565, 11, 436, 393, 312, 10392, 11, 436, 393, 312, 10037, 11, 436, 393, 312, 3931, 11, 51828], "temperature": 0.0, "avg_logprob": -0.06977438123038646, "compression_ratio": 1.9329896907216495, "no_speech_prob": 0.0016998229548335075}, {"id": 615, "seek": 449492, "start": 4495.16, "end": 4501.88, "text": " depending on the shape of the box, you can code whether your event is for example a decision,", "tokens": [50376, 5413, 322, 264, 3909, 295, 264, 2424, 11, 291, 393, 3089, 1968, 428, 2280, 307, 337, 1365, 257, 3537, 11, 50712], "temperature": 0.0, "avg_logprob": -0.0831989258054703, "compression_ratio": 1.6745562130177514, "no_speech_prob": 0.00026109913596883416}, {"id": 616, "seek": 449492, "start": 4502.6, "end": 4512.12, "text": " or if it's an event that just happened externally, so you can use the forms of boxes to indicate", "tokens": [50748, 420, 498, 309, 311, 364, 2280, 300, 445, 2011, 40899, 11, 370, 291, 393, 764, 264, 6422, 295, 9002, 281, 13330, 51224], "temperature": 0.0, "avg_logprob": -0.0831989258054703, "compression_ratio": 1.6745562130177514, "no_speech_prob": 0.00026109913596883416}, {"id": 617, "seek": 449492, "start": 4512.12, "end": 4518.68, "text": " different things, arrows can indicate different things, so particularly for process research", "tokens": [51224, 819, 721, 11, 19669, 393, 13330, 819, 721, 11, 370, 4098, 337, 1399, 2132, 51552], "temperature": 0.0, "avg_logprob": -0.0831989258054703, "compression_ratio": 1.6745562130177514, "no_speech_prob": 0.00026109913596883416}, {"id": 618, "seek": 451868, "start": 4518.68, "end": 4526.12, "text": " we're going to be using arrows not so much for causality probably, but more for temporal relations", "tokens": [50364, 321, 434, 516, 281, 312, 1228, 19669, 406, 370, 709, 337, 3302, 1860, 1391, 11, 457, 544, 337, 30881, 2299, 50736], "temperature": 0.0, "avg_logprob": -0.10592306322521633, "compression_ratio": 1.7228915662650603, "no_speech_prob": 0.0052170902490615845}, {"id": 619, "seek": 451868, "start": 4526.12, "end": 4533.320000000001, "text": " like precedence, what comes before what in time is something that we're going to be using", "tokens": [50736, 411, 16969, 655, 11, 437, 1487, 949, 437, 294, 565, 307, 746, 300, 321, 434, 516, 281, 312, 1228, 51096], "temperature": 0.0, "avg_logprob": -0.10592306322521633, "compression_ratio": 1.7228915662650603, "no_speech_prob": 0.0052170902490615845}, {"id": 620, "seek": 451868, "start": 4534.12, "end": 4542.92, "text": " with arrows, we're showing with arrows, we can use icons, emoticons, etc, and there are a certain", "tokens": [51136, 365, 19669, 11, 321, 434, 4099, 365, 19669, 11, 321, 393, 764, 23308, 11, 3626, 299, 892, 11, 5183, 11, 293, 456, 366, 257, 1629, 51576], "temperature": 0.0, "avg_logprob": -0.10592306322521633, "compression_ratio": 1.7228915662650603, "no_speech_prob": 0.0052170902490615845}, {"id": 621, "seek": 454292, "start": 4542.92, "end": 4551.96, "text": " number of conventions, so at least in the west time goes from left to right, it does not necessarily", "tokens": [50364, 1230, 295, 33520, 11, 370, 412, 1935, 294, 264, 7009, 565, 1709, 490, 1411, 281, 558, 11, 309, 775, 406, 4725, 50816], "temperature": 0.0, "avg_logprob": -0.09962987899780273, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.012806338258087635}, {"id": 622, "seek": 454292, "start": 4551.96, "end": 4562.84, "text": " go from left to right in other parts of the world, and that can be confusing, so if your writing starts", "tokens": [50816, 352, 490, 1411, 281, 558, 294, 661, 3166, 295, 264, 1002, 11, 293, 300, 393, 312, 13181, 11, 370, 498, 428, 3579, 3719, 51360], "temperature": 0.0, "avg_logprob": -0.09962987899780273, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.012806338258087635}, {"id": 623, "seek": 454292, "start": 4562.84, "end": 4567.16, "text": " from right to left you may think of time as going from right to left, and that can be confusing,", "tokens": [51360, 490, 558, 281, 1411, 291, 815, 519, 295, 565, 382, 516, 490, 558, 281, 1411, 11, 293, 300, 393, 312, 13181, 11, 51576], "temperature": 0.0, "avg_logprob": -0.09962987899780273, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.012806338258087635}, {"id": 624, "seek": 456716, "start": 4567.88, "end": 4572.92, "text": " most of the American journals will expect time to go from left to right,", "tokens": [50400, 881, 295, 264, 2665, 29621, 486, 2066, 565, 281, 352, 490, 1411, 281, 558, 11, 50652], "temperature": 0.0, "avg_logprob": -0.12440074980258942, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.008299817331135273}, {"id": 625, "seek": 456716, "start": 4576.44, "end": 4583.32, "text": " hierarchy top to bottom, you can do things with overlapping boxes, you can do things", "tokens": [50828, 22333, 1192, 281, 2767, 11, 291, 393, 360, 721, 365, 33535, 9002, 11, 291, 393, 360, 721, 51172], "temperature": 0.0, "avg_logprob": -0.12440074980258942, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.008299817331135273}, {"id": 626, "seek": 456716, "start": 4584.28, "end": 4592.2, "text": " with boxes that interact, lines that interact, and so on, so there are all kinds of ways of doing that,", "tokens": [51220, 365, 9002, 300, 4648, 11, 3876, 300, 4648, 11, 293, 370, 322, 11, 370, 456, 366, 439, 3685, 295, 2098, 295, 884, 300, 11, 51616], "temperature": 0.0, "avg_logprob": -0.12440074980258942, "compression_ratio": 1.6730769230769231, "no_speech_prob": 0.008299817331135273}, {"id": 627, "seek": 459220, "start": 4593.16, "end": 4604.28, "text": " here is some of the thoughts of how you can use visualizations, so here's my diagram with data", "tokens": [50412, 510, 307, 512, 295, 264, 4598, 295, 577, 291, 393, 764, 5056, 14455, 11, 370, 510, 311, 452, 10686, 365, 1412, 50968], "temperature": 0.0, "avg_logprob": -0.1740849474643139, "compression_ratio": 1.5, "no_speech_prob": 0.0018662961665540934}, {"id": 628, "seek": 459220, "start": 4604.28, "end": 4616.12, "text": " and theory and coupling, you can use diagramming visualizing all along this chain, so when you", "tokens": [50968, 293, 5261, 293, 37447, 11, 291, 393, 764, 10686, 2810, 5056, 3319, 439, 2051, 341, 5021, 11, 370, 562, 291, 51560], "temperature": 0.0, "avg_logprob": -0.1740849474643139, "compression_ratio": 1.5, "no_speech_prob": 0.0018662961665540934}, {"id": 629, "seek": 461612, "start": 4616.12, "end": 4625.08, "text": " look at a published paper what you usually see is a diagram, a process theory, so that is not what", "tokens": [50364, 574, 412, 257, 6572, 3035, 437, 291, 2673, 536, 307, 257, 10686, 11, 257, 1399, 5261, 11, 370, 300, 307, 406, 437, 50812], "temperature": 0.0, "avg_logprob": -0.08852373099908596, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.0024707966949790716}, {"id": 630, "seek": 461612, "start": 4625.08, "end": 4630.5199999999995, "text": " the author necessarily started with, that's the distillation of their theoretical ideas, so that's", "tokens": [50812, 264, 3793, 4725, 1409, 365, 11, 300, 311, 264, 42923, 399, 295, 641, 20864, 3487, 11, 370, 300, 311, 51084], "temperature": 0.0, "avg_logprob": -0.08852373099908596, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.0024707966949790716}, {"id": 631, "seek": 461612, "start": 4631.16, "end": 4636.5199999999995, "text": " they're using it for conceptualizing or communicating their theory, but you can also use", "tokens": [51116, 436, 434, 1228, 309, 337, 24106, 3319, 420, 17559, 641, 5261, 11, 457, 291, 393, 611, 764, 51384], "temperature": 0.0, "avg_logprob": -0.08852373099908596, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.0024707966949790716}, {"id": 632, "seek": 461612, "start": 4636.5199999999995, "end": 4644.68, "text": " visualization for actually mapping your data, not just simply presenting the findings or", "tokens": [51384, 25801, 337, 767, 18350, 428, 1412, 11, 406, 445, 2935, 15578, 264, 16483, 420, 51792], "temperature": 0.0, "avg_logprob": -0.08852373099908596, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.0024707966949790716}, {"id": 633, "seek": 464468, "start": 4644.76, "end": 4651.400000000001, "text": " presenting the theory, but also for mapping the data and for analyzing the data themselves,", "tokens": [50368, 15578, 264, 5261, 11, 457, 611, 337, 18350, 264, 1412, 293, 337, 23663, 264, 1412, 2969, 11, 50700], "temperature": 0.0, "avg_logprob": -0.11199191844824588, "compression_ratio": 1.598802395209581, "no_speech_prob": 0.0003004446916747838}, {"id": 634, "seek": 464468, "start": 4651.400000000001, "end": 4660.04, "text": " so it becomes a coding tool essentially, and this is an example that I put in a paper,", "tokens": [50700, 370, 309, 3643, 257, 17720, 2290, 4476, 11, 293, 341, 307, 364, 1365, 300, 286, 829, 294, 257, 3035, 11, 51132], "temperature": 0.0, "avg_logprob": -0.11199191844824588, "compression_ratio": 1.598802395209581, "no_speech_prob": 0.0003004446916747838}, {"id": 635, "seek": 464468, "start": 4660.68, "end": 4670.360000000001, "text": " very old paper that I wrote with a student, it's a flow chart, and this we were actually", "tokens": [51164, 588, 1331, 3035, 300, 286, 4114, 365, 257, 3107, 11, 309, 311, 257, 3095, 6927, 11, 293, 341, 321, 645, 767, 51648], "temperature": 0.0, "avg_logprob": -0.11199191844824588, "compression_ratio": 1.598802395209581, "no_speech_prob": 0.0003004446916747838}, {"id": 636, "seek": 467036, "start": 4670.36, "end": 4677.88, "text": " mapping the data, it was a technology adoption process, we classified events according to", "tokens": [50364, 18350, 264, 1412, 11, 309, 390, 257, 2899, 19215, 1399, 11, 321, 20627, 3931, 4650, 281, 50740], "temperature": 0.0, "avg_logprob": -0.10644759970196223, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.008968748152256012}, {"id": 637, "seek": 467036, "start": 4678.839999999999, "end": 4683.719999999999, "text": " different domains of the company, so the top to bottom, they're different domains of the company,", "tokens": [50788, 819, 25514, 295, 264, 2237, 11, 370, 264, 1192, 281, 2767, 11, 436, 434, 819, 25514, 295, 264, 2237, 11, 51032], "temperature": 0.0, "avg_logprob": -0.10644759970196223, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.008968748152256012}, {"id": 638, "seek": 467036, "start": 4684.759999999999, "end": 4693.48, "text": " we identified different codes for events outside the company, those are the ovals", "tokens": [51084, 321, 9234, 819, 14211, 337, 3931, 2380, 264, 2237, 11, 729, 366, 264, 14187, 1124, 51520], "temperature": 0.0, "avg_logprob": -0.10644759970196223, "compression_ratio": 1.7933333333333332, "no_speech_prob": 0.008968748152256012}, {"id": 639, "seek": 469348, "start": 4694.2, "end": 4703.879999999999, "text": " for activities which were I believe square boxes and decisions which were the round cornered ones,", "tokens": [50400, 337, 5354, 597, 645, 286, 1697, 3732, 9002, 293, 5327, 597, 645, 264, 3098, 4538, 292, 2306, 11, 50884], "temperature": 0.0, "avg_logprob": -0.1543791986280872, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.008979503065347672}, {"id": 640, "seek": 469348, "start": 4703.879999999999, "end": 4711.4, "text": " and we showed precedence, we showed interruptions, we showed events that impacted other events,", "tokens": [50884, 293, 321, 4712, 16969, 655, 11, 321, 4712, 12729, 626, 11, 321, 4712, 3931, 300, 15653, 661, 3931, 11, 51260], "temperature": 0.0, "avg_logprob": -0.1543791986280872, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.008979503065347672}, {"id": 641, "seek": 469348, "start": 4712.12, "end": 4718.2, "text": " and depending on to what degree they impacted them, we placed different symbols on there,", "tokens": [51296, 293, 5413, 322, 281, 437, 4314, 436, 15653, 552, 11, 321, 7074, 819, 16944, 322, 456, 11, 51600], "temperature": 0.0, "avg_logprob": -0.1543791986280872, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.008979503065347672}, {"id": 642, "seek": 471820, "start": 4718.84, "end": 4724.28, "text": " this is an example of how you can take some data and instead of just coding it according to Joya", "tokens": [50396, 341, 307, 364, 1365, 295, 577, 291, 393, 747, 512, 1412, 293, 2602, 295, 445, 17720, 309, 4650, 281, 15571, 64, 50668], "temperature": 0.0, "avg_logprob": -0.12119977865646135, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.00013132867752574384}, {"id": 643, "seek": 471820, "start": 4724.28, "end": 4734.44, "text": " method, you can display it along a timeline with events, and so this is quite a different way", "tokens": [50668, 3170, 11, 291, 393, 4674, 309, 2051, 257, 12933, 365, 3931, 11, 293, 370, 341, 307, 1596, 257, 819, 636, 51176], "temperature": 0.0, "avg_logprob": -0.12119977865646135, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.00013132867752574384}, {"id": 644, "seek": 471820, "start": 4735.16, "end": 4742.44, "text": " of coding, and it's still coding because we have coded the different kinds of events,", "tokens": [51212, 295, 17720, 11, 293, 309, 311, 920, 17720, 570, 321, 362, 34874, 264, 819, 3685, 295, 3931, 11, 51576], "temperature": 0.0, "avg_logprob": -0.12119977865646135, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.00013132867752574384}, {"id": 645, "seek": 474244, "start": 4743.4, "end": 4753.16, "text": " and this is a tool for describing your data, but then if you wanted to compare different", "tokens": [50412, 293, 341, 307, 257, 2290, 337, 16141, 428, 1412, 11, 457, 550, 498, 291, 1415, 281, 6794, 819, 50900], "temperature": 0.0, "avg_logprob": -0.08421172624752846, "compression_ratio": 1.7927461139896372, "no_speech_prob": 0.0021479218266904354}, {"id": 646, "seek": 474244, "start": 4753.16, "end": 4757.48, "text": " timelines, and this is what we did, we had five processes that we mapped this way,", "tokens": [50900, 45886, 11, 293, 341, 307, 437, 321, 630, 11, 321, 632, 1732, 7555, 300, 321, 33318, 341, 636, 11, 51116], "temperature": 0.0, "avg_logprob": -0.08421172624752846, "compression_ratio": 1.7927461139896372, "no_speech_prob": 0.0021479218266904354}, {"id": 647, "seek": 474244, "start": 4758.04, "end": 4762.44, "text": " we could compare them so we could see what comes before what, what tends to come before what,", "tokens": [51144, 321, 727, 6794, 552, 370, 321, 727, 536, 437, 1487, 949, 437, 11, 437, 12258, 281, 808, 949, 437, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08421172624752846, "compression_ratio": 1.7927461139896372, "no_speech_prob": 0.0021479218266904354}, {"id": 648, "seek": 474244, "start": 4764.679999999999, "end": 4770.599999999999, "text": " can we see some patterns in the types of interactions between different kinds of", "tokens": [51476, 393, 321, 536, 512, 8294, 294, 264, 3467, 295, 13280, 1296, 819, 3685, 295, 51772], "temperature": 0.0, "avg_logprob": -0.08421172624752846, "compression_ratio": 1.7927461139896372, "no_speech_prob": 0.0021479218266904354}, {"id": 649, "seek": 477060, "start": 4770.68, "end": 4778.6, "text": " phenomena over time, so this is a really interesting tool for process research, and most cases you", "tokens": [50368, 22004, 670, 565, 11, 370, 341, 307, 257, 534, 1880, 2290, 337, 1399, 2132, 11, 293, 881, 3331, 291, 50764], "temperature": 0.0, "avg_logprob": -0.12917166787224846, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0003198101185262203}, {"id": 650, "seek": 477060, "start": 4778.6, "end": 4786.4400000000005, "text": " never see, you don't see the mapping itself in a published paper, but you see the final, the final", "tokens": [50764, 1128, 536, 11, 291, 500, 380, 536, 264, 18350, 2564, 294, 257, 6572, 3035, 11, 457, 291, 536, 264, 2572, 11, 264, 2572, 51156], "temperature": 0.0, "avg_logprob": -0.12917166787224846, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0003198101185262203}, {"id": 651, "seek": 477060, "start": 4786.4400000000005, "end": 4798.52, "text": " diagram, so that's just looking at the time, I'm going to skip a few things here, because I want", "tokens": [51156, 10686, 11, 370, 300, 311, 445, 1237, 412, 264, 565, 11, 286, 478, 516, 281, 10023, 257, 1326, 721, 510, 11, 570, 286, 528, 51760], "temperature": 0.0, "avg_logprob": -0.12917166787224846, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0003198101185262203}, {"id": 652, "seek": 479852, "start": 4798.68, "end": 4805.160000000001, "text": " to talk a little bit about comparing as well, so we've talked about the two methods for displaying,", "tokens": [50372, 281, 751, 257, 707, 857, 466, 15763, 382, 731, 11, 370, 321, 600, 2825, 466, 264, 732, 7150, 337, 36834, 11, 50696], "temperature": 0.0, "avg_logprob": -0.13442587852478027, "compression_ratio": 1.6484848484848484, "no_speech_prob": 0.0023203599266707897}, {"id": 653, "seek": 479852, "start": 4807.56, "end": 4817.4800000000005, "text": " comparing for me is a really powerful tool for theorizing, because it makes you,", "tokens": [50816, 15763, 337, 385, 307, 257, 534, 4005, 2290, 337, 27423, 3319, 11, 570, 309, 1669, 291, 11, 51312], "temperature": 0.0, "avg_logprob": -0.13442587852478027, "compression_ratio": 1.6484848484848484, "no_speech_prob": 0.0023203599266707897}, {"id": 654, "seek": 479852, "start": 4818.280000000001, "end": 4823.64, "text": " it makes you theorize, if you, if you have an example I always give is if you have children", "tokens": [51352, 309, 1669, 291, 27423, 1125, 11, 498, 291, 11, 498, 291, 362, 364, 1365, 286, 1009, 976, 307, 498, 291, 362, 2227, 51620], "temperature": 0.0, "avg_logprob": -0.13442587852478027, "compression_ratio": 1.6484848484848484, "no_speech_prob": 0.0023203599266707897}, {"id": 655, "seek": 482364, "start": 4824.52, "end": 4832.360000000001, "text": " and you have a little boy and a little girl, you immediately stop theorize about the differences", "tokens": [50408, 293, 291, 362, 257, 707, 3237, 293, 257, 707, 2013, 11, 291, 4258, 1590, 27423, 1125, 466, 264, 7300, 50800], "temperature": 0.0, "avg_logprob": -0.11076900618416922, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.0011855511693283916}, {"id": 656, "seek": 482364, "start": 4832.360000000001, "end": 4842.84, "text": " that come from time, your, your, it's, we are programmed to theorize from empirical differences", "tokens": [50800, 300, 808, 490, 565, 11, 428, 11, 428, 11, 309, 311, 11, 321, 366, 31092, 281, 27423, 1125, 490, 31886, 7300, 51324], "temperature": 0.0, "avg_logprob": -0.11076900618416922, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.0011855511693283916}, {"id": 657, "seek": 482364, "start": 4842.84, "end": 4849.64, "text": " and similarities that we see, and so it is really powerful to do that, and you can compare in all", "tokens": [51324, 293, 24197, 300, 321, 536, 11, 293, 370, 309, 307, 534, 4005, 281, 360, 300, 11, 293, 291, 393, 6794, 294, 439, 51664], "temperature": 0.0, "avg_logprob": -0.11076900618416922, "compression_ratio": 1.695906432748538, "no_speech_prob": 0.0011855511693283916}, {"id": 658, "seek": 484964, "start": 4849.64, "end": 4856.68, "text": " kinds of ways, and so I talk about comparing time periods, and this is particularly useful for process", "tokens": [50364, 3685, 295, 2098, 11, 293, 370, 286, 751, 466, 15763, 565, 13804, 11, 293, 341, 307, 4098, 4420, 337, 1399, 50716], "temperature": 0.0, "avg_logprob": -0.07556182013617621, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.002712623681873083}, {"id": 659, "seek": 484964, "start": 4856.68, "end": 4867.400000000001, "text": " data, but you can also compare cases, you can compare incidents, and drawing tables that show", "tokens": [50716, 1412, 11, 457, 291, 393, 611, 6794, 3331, 11, 291, 393, 6794, 21139, 11, 293, 6316, 8020, 300, 855, 51252], "temperature": 0.0, "avg_logprob": -0.07556182013617621, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.002712623681873083}, {"id": 660, "seek": 486740, "start": 4867.4, "end": 4875.639999999999, "text": " these comparisons is a great way to kind of focus, get yourself to focus on that, so", "tokens": [50364, 613, 33157, 307, 257, 869, 636, 281, 733, 295, 1879, 11, 483, 1803, 281, 1879, 322, 300, 11, 370, 50776], "temperature": 0.0, "avg_logprob": -0.11066427651573629, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.02000248245894909}, {"id": 661, "seek": 486740, "start": 4879.32, "end": 4883.32, "text": " I'm just going to give, I'm going to skip this, and just give an example of some temporal", "tokens": [50960, 286, 478, 445, 516, 281, 976, 11, 286, 478, 516, 281, 10023, 341, 11, 293, 445, 976, 364, 1365, 295, 512, 30881, 51160], "temperature": 0.0, "avg_logprob": -0.11066427651573629, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.02000248245894909}, {"id": 662, "seek": 486740, "start": 4883.32, "end": 4889.639999999999, "text": " bracketing, which is decomposing by time period, so this is a paper that I wrote", "tokens": [51160, 12305, 9880, 11, 597, 307, 22867, 6110, 538, 565, 2896, 11, 370, 341, 307, 257, 3035, 300, 286, 4114, 51476], "temperature": 0.0, "avg_logprob": -0.11066427651573629, "compression_ratio": 1.536144578313253, "no_speech_prob": 0.02000248245894909}, {"id": 663, "seek": 488964, "start": 4890.6, "end": 4898.52, "text": " with with Jean-Louis Denis and some other co-authors, and it's about a merger of three hospitals,", "tokens": [50412, 365, 365, 13854, 12, 46316, 271, 45351, 293, 512, 661, 598, 12, 40198, 830, 11, 293, 309, 311, 466, 257, 48002, 295, 1045, 13014, 11, 50808], "temperature": 0.0, "avg_logprob": -0.1388776449509609, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.054863616824150085}, {"id": 664, "seek": 488964, "start": 4900.12, "end": 4906.92, "text": " and they were in a double mind, they had a real tension, because on the one hand", "tokens": [50888, 293, 436, 645, 294, 257, 3834, 1575, 11, 436, 632, 257, 957, 8980, 11, 570, 322, 264, 472, 1011, 51228], "temperature": 0.0, "avg_logprob": -0.1388776449509609, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.054863616824150085}, {"id": 665, "seek": 488964, "start": 4908.52, "end": 4913.08, "text": " they had been told that they would get a lot of money if they agreed to merge,", "tokens": [51308, 436, 632, 668, 1907, 300, 436, 576, 483, 257, 688, 295, 1460, 498, 436, 9166, 281, 22183, 11, 51536], "temperature": 0.0, "avg_logprob": -0.1388776449509609, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.054863616824150085}, {"id": 666, "seek": 488964, "start": 4914.68, "end": 4917.160000000001, "text": " and on the other hand they hated each other,", "tokens": [51616, 293, 322, 264, 661, 1011, 436, 17398, 1184, 661, 11, 51740], "temperature": 0.0, "avg_logprob": -0.1388776449509609, "compression_ratio": 1.6593406593406594, "no_speech_prob": 0.054863616824150085}, {"id": 667, "seek": 491964, "start": 4920.6, "end": 4926.360000000001, "text": " and so they couldn't agree about anything, they had to stay together, they were stuck,", "tokens": [50412, 293, 370, 436, 2809, 380, 3986, 466, 1340, 11, 436, 632, 281, 1754, 1214, 11, 436, 645, 5541, 11, 50700], "temperature": 0.0, "avg_logprob": -0.10856122146418065, "compression_ratio": 1.879120879120879, "no_speech_prob": 0.0003350556071382016}, {"id": 668, "seek": 491964, "start": 4926.360000000001, "end": 4929.56, "text": " so they had this initial condition of constraint, they had to be together,", "tokens": [50700, 370, 436, 632, 341, 5883, 4188, 295, 25534, 11, 436, 632, 281, 312, 1214, 11, 50860], "temperature": 0.0, "avg_logprob": -0.10856122146418065, "compression_ratio": 1.879120879120879, "no_speech_prob": 0.0003350556071382016}, {"id": 669, "seek": 491964, "start": 4930.12, "end": 4935.8, "text": " but they couldn't agree, and so how were they going to work out how they were going to do this", "tokens": [50888, 457, 436, 2809, 380, 3986, 11, 293, 370, 577, 645, 436, 516, 281, 589, 484, 577, 436, 645, 516, 281, 360, 341, 51172], "temperature": 0.0, "avg_logprob": -0.10856122146418065, "compression_ratio": 1.879120879120879, "no_speech_prob": 0.0003350556071382016}, {"id": 670, "seek": 491964, "start": 4935.8, "end": 4947.160000000001, "text": " merger, and we showed that they kept making decisions that embedded ambiguity so that", "tokens": [51172, 48002, 11, 293, 321, 4712, 300, 436, 4305, 1455, 5327, 300, 16741, 46519, 370, 300, 51740], "temperature": 0.0, "avg_logprob": -0.10856122146418065, "compression_ratio": 1.879120879120879, "no_speech_prob": 0.0003350556071382016}, {"id": 671, "seek": 494716, "start": 4947.16, "end": 4954.92, "text": " they would need to make the decision all over again, and the processes were that okay,", "tokens": [50364, 436, 576, 643, 281, 652, 264, 3537, 439, 670, 797, 11, 293, 264, 7555, 645, 300, 1392, 11, 50752], "temperature": 0.0, "avg_logprob": -0.09324620717979339, "compression_ratio": 1.9893048128342246, "no_speech_prob": 0.0015472481027245522}, {"id": 672, "seek": 494716, "start": 4956.12, "end": 4960.92, "text": " they would put forward a proposal where they would try and integrate everybody into the decision,", "tokens": [50812, 436, 576, 829, 2128, 257, 11494, 689, 436, 576, 853, 293, 13365, 2201, 666, 264, 3537, 11, 51052], "temperature": 0.0, "avg_logprob": -0.09324620717979339, "compression_ratio": 1.9893048128342246, "no_speech_prob": 0.0015472481027245522}, {"id": 673, "seek": 494716, "start": 4961.48, "end": 4966.76, "text": " and in order to do that they would have to make it ambiguous, which meant that they could not", "tokens": [51080, 293, 294, 1668, 281, 360, 300, 436, 576, 362, 281, 652, 309, 39465, 11, 597, 4140, 300, 436, 727, 406, 51344], "temperature": 0.0, "avg_logprob": -0.09324620717979339, "compression_ratio": 1.9893048128342246, "no_speech_prob": 0.0015472481027245522}, {"id": 674, "seek": 494716, "start": 4966.76, "end": 4971.5599999999995, "text": " implement the decision because it was ambiguous, so they would have to decide all over again,", "tokens": [51344, 4445, 264, 3537, 570, 309, 390, 39465, 11, 370, 436, 576, 362, 281, 4536, 439, 670, 797, 11, 51584], "temperature": 0.0, "avg_logprob": -0.09324620717979339, "compression_ratio": 1.9893048128342246, "no_speech_prob": 0.0015472481027245522}, {"id": 675, "seek": 497156, "start": 4972.4400000000005, "end": 4979.96, "text": " and so this is the overall model, but we followed it through empirically with three", "tokens": [50408, 293, 370, 341, 307, 264, 4787, 2316, 11, 457, 321, 6263, 309, 807, 25790, 984, 365, 1045, 50784], "temperature": 0.0, "avg_logprob": -0.06397363999310662, "compression_ratio": 1.859375, "no_speech_prob": 0.008977771736681461}, {"id": 676, "seek": 497156, "start": 4979.96, "end": 4986.52, "text": " different stages, so here are the three different stages, so this is temporal bracketing, what we", "tokens": [50784, 819, 10232, 11, 370, 510, 366, 264, 1045, 819, 10232, 11, 370, 341, 307, 30881, 12305, 9880, 11, 437, 321, 51112], "temperature": 0.0, "avg_logprob": -0.06397363999310662, "compression_ratio": 1.859375, "no_speech_prob": 0.008977771736681461}, {"id": 677, "seek": 497156, "start": 4986.52, "end": 4992.76, "text": " showed was they went through a process, it produced ambiguity, therefore we had to start", "tokens": [51112, 4712, 390, 436, 1437, 807, 257, 1399, 11, 309, 7126, 46519, 11, 4412, 321, 632, 281, 722, 51424], "temperature": 0.0, "avg_logprob": -0.06397363999310662, "compression_ratio": 1.859375, "no_speech_prob": 0.008977771736681461}, {"id": 678, "seek": 497156, "start": 4992.76, "end": 4997.400000000001, "text": " all over again, and so this is a kind of a temporal bracketing of a process over time,", "tokens": [51424, 439, 670, 797, 11, 293, 370, 341, 307, 257, 733, 295, 257, 30881, 12305, 9880, 295, 257, 1399, 670, 565, 11, 51656], "temperature": 0.0, "avg_logprob": -0.06397363999310662, "compression_ratio": 1.859375, "no_speech_prob": 0.008977771736681461}, {"id": 679, "seek": 499740, "start": 4997.4, "end": 5003.719999999999, "text": " and this was very helpful in helping us to understand this process, and the title of the", "tokens": [50364, 293, 341, 390, 588, 4961, 294, 4315, 505, 281, 1223, 341, 1399, 11, 293, 264, 4876, 295, 264, 50680], "temperature": 0.0, "avg_logprob": -0.1105218970257303, "compression_ratio": 1.7134146341463414, "no_speech_prob": 0.005635605193674564}, {"id": 680, "seek": 499740, "start": 5003.719999999999, "end": 5010.04, "text": " paper is escalating indecision, this is what happens when you need to work together, but you", "tokens": [50680, 3035, 307, 17871, 990, 1016, 3045, 1991, 11, 341, 307, 437, 2314, 562, 291, 643, 281, 589, 1214, 11, 457, 291, 50996], "temperature": 0.0, "avg_logprob": -0.1105218970257303, "compression_ratio": 1.7134146341463414, "no_speech_prob": 0.005635605193674564}, {"id": 681, "seek": 499740, "start": 5010.04, "end": 5020.839999999999, "text": " hate each other, you find yourself in this escalating indecision cycle, the good news is that about", "tokens": [50996, 4700, 1184, 661, 11, 291, 915, 1803, 294, 341, 17871, 990, 1016, 3045, 1991, 6586, 11, 264, 665, 2583, 307, 300, 466, 51536], "temperature": 0.0, "avg_logprob": -0.1105218970257303, "compression_ratio": 1.7134146341463414, "no_speech_prob": 0.005635605193674564}, {"id": 682, "seek": 502084, "start": 5021.56, "end": 5026.92, "text": " five or so years after we finished our study, they did actually do something,", "tokens": [50400, 1732, 420, 370, 924, 934, 321, 4335, 527, 2979, 11, 436, 630, 767, 360, 746, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14902029904452238, "compression_ratio": 1.5, "no_speech_prob": 0.008183862082660198}, {"id": 683, "seek": 502084, "start": 5028.84, "end": 5033.0, "text": " so it didn't, but this was the process that we observed,", "tokens": [50764, 370, 309, 994, 380, 11, 457, 341, 390, 264, 1399, 300, 321, 13095, 11, 50972], "temperature": 0.0, "avg_logprob": -0.14902029904452238, "compression_ratio": 1.5, "no_speech_prob": 0.008183862082660198}, {"id": 684, "seek": 502084, "start": 5036.52, "end": 5044.28, "text": " and then you can also compare cases, so you can do it, compare outcomes,", "tokens": [51148, 293, 550, 291, 393, 611, 6794, 3331, 11, 370, 291, 393, 360, 309, 11, 6794, 10070, 11, 51536], "temperature": 0.0, "avg_logprob": -0.14902029904452238, "compression_ratio": 1.5, "no_speech_prob": 0.008183862082660198}, {"id": 685, "seek": 504428, "start": 5045.24, "end": 5051.639999999999, "text": " and if you're doing that you're probably more into explaining variants than looking at process,", "tokens": [50412, 293, 498, 291, 434, 884, 300, 291, 434, 1391, 544, 666, 13468, 21669, 813, 1237, 412, 1399, 11, 50732], "temperature": 0.0, "avg_logprob": -0.11268457912263416, "compression_ratio": 1.824390243902439, "no_speech_prob": 0.001837870222516358}, {"id": 686, "seek": 504428, "start": 5051.639999999999, "end": 5058.599999999999, "text": " so that's one thing, but you can also use a comparison between cases to show similarity", "tokens": [50732, 370, 300, 311, 472, 551, 11, 457, 291, 393, 611, 764, 257, 9660, 1296, 3331, 281, 855, 32194, 51080], "temperature": 0.0, "avg_logprob": -0.11268457912263416, "compression_ratio": 1.824390243902439, "no_speech_prob": 0.001837870222516358}, {"id": 687, "seek": 504428, "start": 5059.32, "end": 5065.5599999999995, "text": " rather than difference across different settings, and if you do that then you're demonstrating", "tokens": [51116, 2831, 813, 2649, 2108, 819, 6257, 11, 293, 498, 291, 360, 300, 550, 291, 434, 29889, 51428], "temperature": 0.0, "avg_logprob": -0.11268457912263416, "compression_ratio": 1.824390243902439, "no_speech_prob": 0.001837870222516358}, {"id": 688, "seek": 504428, "start": 5065.5599999999995, "end": 5072.759999999999, "text": " that the process that you're looking at is not just in one case but several, and so that can be", "tokens": [51428, 300, 264, 1399, 300, 291, 434, 1237, 412, 307, 406, 445, 294, 472, 1389, 457, 2940, 11, 293, 370, 300, 393, 312, 51788], "temperature": 0.0, "avg_logprob": -0.11268457912263416, "compression_ratio": 1.824390243902439, "no_speech_prob": 0.001837870222516358}, {"id": 689, "seek": 507276, "start": 5072.76, "end": 5081.400000000001, "text": " helpful as well, you can use comparing cases to show variety, you can illustrate richness around", "tokens": [50364, 4961, 382, 731, 11, 291, 393, 764, 15763, 3331, 281, 855, 5673, 11, 291, 393, 23221, 44506, 926, 50796], "temperature": 0.0, "avg_logprob": -0.0748358398187356, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0010984546970576048}, {"id": 690, "seek": 507276, "start": 5081.400000000001, "end": 5091.400000000001, "text": " a similar structure, and you can combine process and variants also, so there are authors who use", "tokens": [50796, 257, 2531, 3877, 11, 293, 291, 393, 10432, 1399, 293, 21669, 611, 11, 370, 456, 366, 16552, 567, 764, 51296], "temperature": 0.0, "avg_logprob": -0.0748358398187356, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0010984546970576048}, {"id": 691, "seek": 507276, "start": 5091.400000000001, "end": 5099.24, "text": " multiple cases to show different processes, but then they they compare the processes and show", "tokens": [51296, 3866, 3331, 281, 855, 819, 7555, 11, 457, 550, 436, 436, 6794, 264, 7555, 293, 855, 51688], "temperature": 0.0, "avg_logprob": -0.0748358398187356, "compression_ratio": 1.718562874251497, "no_speech_prob": 0.0010984546970576048}, {"id": 692, "seek": 509924, "start": 5099.24, "end": 5104.04, "text": " that some tend to lead to positive outcomes and others tend to lead to negative ones, so they're", "tokens": [50364, 300, 512, 3928, 281, 1477, 281, 3353, 10070, 293, 2357, 3928, 281, 1477, 281, 3671, 2306, 11, 370, 436, 434, 50604], "temperature": 0.0, "avg_logprob": -0.08031254920406618, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.0005439651431515813}, {"id": 693, "seek": 509924, "start": 5104.04, "end": 5114.92, "text": " combining process with variants, so I'm looking at the time here and I'm going to just skip things", "tokens": [50604, 21928, 1399, 365, 21669, 11, 370, 286, 478, 1237, 412, 264, 565, 510, 293, 286, 478, 516, 281, 445, 10023, 721, 51148], "temperature": 0.0, "avg_logprob": -0.08031254920406618, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.0005439651431515813}, {"id": 694, "seek": 509924, "start": 5114.92, "end": 5123.0, "text": " and move on to my last point which I think is important, because I have all these strategies,", "tokens": [51148, 293, 1286, 322, 281, 452, 1036, 935, 597, 286, 519, 307, 1021, 11, 570, 286, 362, 439, 613, 9029, 11, 51552], "temperature": 0.0, "avg_logprob": -0.08031254920406618, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.0005439651431515813}, {"id": 695, "seek": 512300, "start": 5123.0, "end": 5135.0, "text": " but at some point that's not enough, and I think it's a really important point that theoretical", "tokens": [50364, 457, 412, 512, 935, 300, 311, 406, 1547, 11, 293, 286, 519, 309, 311, 257, 534, 1021, 935, 300, 20864, 50964], "temperature": 0.0, "avg_logprob": -0.1334233067252419, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.003534231800585985}, {"id": 696, "seek": 512300, "start": 5135.0, "end": 5142.44, "text": " insight does not just emerge, so when you read a qualitative paper that at some point somebody", "tokens": [50964, 11269, 775, 406, 445, 21511, 11, 370, 562, 291, 1401, 257, 31312, 3035, 300, 412, 512, 935, 2618, 51336], "temperature": 0.0, "avg_logprob": -0.1334233067252419, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.003534231800585985}, {"id": 697, "seek": 514244, "start": 5142.44, "end": 5153.639999999999, "text": " always says the theory emerged or the concepts emerged from the data, well yes, no, I mean", "tokens": [50364, 1009, 1619, 264, 5261, 20178, 420, 264, 10392, 20178, 490, 264, 1412, 11, 731, 2086, 11, 572, 11, 286, 914, 50924], "temperature": 0.0, "avg_logprob": -0.10831532549502244, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.010813013650476933}, {"id": 698, "seek": 514244, "start": 5153.639999999999, "end": 5162.04, "text": " you did this work, and then there's this step which you cannot, you cannot know exactly what", "tokens": [50924, 291, 630, 341, 589, 11, 293, 550, 456, 311, 341, 1823, 597, 291, 2644, 11, 291, 2644, 458, 2293, 437, 51344], "temperature": 0.0, "avg_logprob": -0.10831532549502244, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.010813013650476933}, {"id": 699, "seek": 514244, "start": 5162.04, "end": 5170.28, "text": " happened but you saw something, and it's that step that's missing from any of the strategies", "tokens": [51344, 2011, 457, 291, 1866, 746, 11, 293, 309, 311, 300, 1823, 300, 311, 5361, 490, 604, 295, 264, 9029, 51756], "temperature": 0.0, "avg_logprob": -0.10831532549502244, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.010813013650476933}, {"id": 700, "seek": 517028, "start": 5170.28, "end": 5176.679999999999, "text": " that I've mentioned so far, I called this the conceptual leap, and I wrote a paper on this", "tokens": [50364, 300, 286, 600, 2835, 370, 1400, 11, 286, 1219, 341, 264, 24106, 19438, 11, 293, 286, 4114, 257, 3035, 322, 341, 50684], "temperature": 0.0, "avg_logprob": -0.14289600748411366, "compression_ratio": 1.5865921787709498, "no_speech_prob": 0.0018952543614432216}, {"id": 701, "seek": 517028, "start": 5176.679999999999, "end": 5189.24, "text": " with Malvina Klag, and this is an image in the paper where we point out that making the conceptual", "tokens": [50684, 365, 5746, 85, 1426, 16053, 559, 11, 293, 341, 307, 364, 3256, 294, 264, 3035, 689, 321, 935, 484, 300, 1455, 264, 24106, 51312], "temperature": 0.0, "avg_logprob": -0.14289600748411366, "compression_ratio": 1.5865921787709498, "no_speech_prob": 0.0018952543614432216}, {"id": 702, "seek": 517028, "start": 5189.24, "end": 5199.0, "text": " leap is yes about analyzing your data carefully, about using all of these a priori theories to", "tokens": [51312, 19438, 307, 2086, 466, 23663, 428, 1412, 7500, 11, 466, 1228, 439, 295, 613, 257, 4059, 72, 13667, 281, 51800], "temperature": 0.0, "avg_logprob": -0.14289600748411366, "compression_ratio": 1.5865921787709498, "no_speech_prob": 0.0018952543614432216}, {"id": 703, "seek": 519900, "start": 5199.0, "end": 5205.4, "text": " look at your data, about talking to your friends, it's all about doing systematic, disciplined", "tokens": [50364, 574, 412, 428, 1412, 11, 466, 1417, 281, 428, 1855, 11, 309, 311, 439, 466, 884, 27249, 11, 40061, 50684], "temperature": 0.0, "avg_logprob": -0.08885068081794902, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0015715480549260974}, {"id": 704, "seek": 519900, "start": 5205.4, "end": 5212.84, "text": " things, but it's also about doing unsystematic, undisciplined things like going for a walk in", "tokens": [50684, 721, 11, 457, 309, 311, 611, 466, 884, 2693, 9321, 2399, 11, 674, 271, 19246, 2001, 721, 411, 516, 337, 257, 1792, 294, 51056], "temperature": 0.0, "avg_logprob": -0.08885068081794902, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0015715480549260974}, {"id": 705, "seek": 519900, "start": 5212.84, "end": 5221.48, "text": " the park, going for a run, sleeping, sleeping is excellent when you wake up or you're turning", "tokens": [51056, 264, 3884, 11, 516, 337, 257, 1190, 11, 8296, 11, 8296, 307, 7103, 562, 291, 6634, 493, 420, 291, 434, 6246, 51488], "temperature": 0.0, "avg_logprob": -0.08885068081794902, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0015715480549260974}, {"id": 706, "seek": 519900, "start": 5221.48, "end": 5228.2, "text": " over in the middle of the night, that's when you get good ideas, so it's a combination.", "tokens": [51488, 670, 294, 264, 2808, 295, 264, 1818, 11, 300, 311, 562, 291, 483, 665, 3487, 11, 370, 309, 311, 257, 6562, 13, 51824], "temperature": 0.0, "avg_logprob": -0.08885068081794902, "compression_ratio": 1.8316831683168318, "no_speech_prob": 0.0015715480549260974}, {"id": 707, "seek": 522900, "start": 5229.24, "end": 5234.04, "text": " The discipline is really important, and what we've spoken about most today is the discipline,", "tokens": [50376, 440, 13635, 307, 534, 1021, 11, 293, 437, 321, 600, 10759, 466, 881, 965, 307, 264, 13635, 11, 50616], "temperature": 0.0, "avg_logprob": -0.12491047519376908, "compression_ratio": 1.5960591133004927, "no_speech_prob": 0.00195320718921721}, {"id": 708, "seek": 522900, "start": 5234.04, "end": 5239.72, "text": " but there's also this kind of creative side, and if you don't have that, you won't get", "tokens": [50616, 457, 456, 311, 611, 341, 733, 295, 5880, 1252, 11, 293, 498, 291, 500, 380, 362, 300, 11, 291, 1582, 380, 483, 50900], "temperature": 0.0, "avg_logprob": -0.12491047519376908, "compression_ratio": 1.5960591133004927, "no_speech_prob": 0.00195320718921721}, {"id": 709, "seek": 522900, "start": 5241.56, "end": 5244.76, "text": " what we're trying to achieve, so you need this.", "tokens": [50992, 437, 321, 434, 1382, 281, 4584, 11, 370, 291, 643, 341, 13, 51152], "temperature": 0.0, "avg_logprob": -0.12491047519376908, "compression_ratio": 1.5960591133004927, "no_speech_prob": 0.00195320718921721}, {"id": 710, "seek": 522900, "start": 5246.92, "end": 5255.72, "text": " So I'm going to stop there, see we still have 200 people, so I think we might be able to have a", "tokens": [51260, 407, 286, 478, 516, 281, 1590, 456, 11, 536, 321, 920, 362, 2331, 561, 11, 370, 286, 519, 321, 1062, 312, 1075, 281, 362, 257, 51700], "temperature": 0.0, "avg_logprob": -0.12491047519376908, "compression_ratio": 1.5960591133004927, "no_speech_prob": 0.00195320718921721}, {"id": 711, "seek": 525572, "start": 5256.280000000001, "end": 5258.6, "text": " couple of questions at this point.", "tokens": [50392, 1916, 295, 1651, 412, 341, 935, 13, 50508], "temperature": 0.0, "avg_logprob": -0.17314119637012482, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024765569251030684}, {"id": 712, "seek": 525572, "start": 5262.6, "end": 5263.64, "text": " Yes, Alba.", "tokens": [50708, 1079, 11, 967, 4231, 13, 50760], "temperature": 0.0, "avg_logprob": -0.17314119637012482, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024765569251030684}, {"id": 713, "seek": 525572, "start": 5267.4800000000005, "end": 5273.0, "text": " Thank you so much, Anne, this has been very, very informative, I'm really grateful, and I guess", "tokens": [50952, 1044, 291, 370, 709, 11, 13706, 11, 341, 575, 668, 588, 11, 588, 27759, 11, 286, 478, 534, 7941, 11, 293, 286, 2041, 51228], "temperature": 0.0, "avg_logprob": -0.17314119637012482, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024765569251030684}, {"id": 714, "seek": 525572, "start": 5273.0, "end": 5278.12, "text": " we're all really grateful as well. Just one question on the very last point you mentioned,", "tokens": [51228, 321, 434, 439, 534, 7941, 382, 731, 13, 1449, 472, 1168, 322, 264, 588, 1036, 935, 291, 2835, 11, 51484], "temperature": 0.0, "avg_logprob": -0.17314119637012482, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024765569251030684}, {"id": 715, "seek": 527812, "start": 5278.2, "end": 5290.12, "text": " which is the creative leap, so I remember writing in one paper about having a creative leap as well,", "tokens": [50368, 597, 307, 264, 5880, 19438, 11, 370, 286, 1604, 3579, 294, 472, 3035, 466, 1419, 257, 5880, 19438, 382, 731, 11, 50964], "temperature": 0.0, "avg_logprob": -0.07314834691057301, "compression_ratio": 1.7649769585253456, "no_speech_prob": 0.2588203549385071}, {"id": 716, "seek": 527812, "start": 5290.12, "end": 5295.8, "text": " but I don't know if it's the way I framed it, but then I got back from the reviewer that even", "tokens": [50964, 457, 286, 500, 380, 458, 498, 309, 311, 264, 636, 286, 30420, 309, 11, 457, 550, 286, 658, 646, 490, 264, 3131, 260, 300, 754, 51248], "temperature": 0.0, "avg_logprob": -0.07314834691057301, "compression_ratio": 1.7649769585253456, "no_speech_prob": 0.2588203549385071}, {"id": 717, "seek": 527812, "start": 5295.8, "end": 5302.44, "text": " though it's a creative leap, I should be able to explain how I got there, and that was a bit", "tokens": [51248, 1673, 309, 311, 257, 5880, 19438, 11, 286, 820, 312, 1075, 281, 2903, 577, 286, 658, 456, 11, 293, 300, 390, 257, 857, 51580], "temperature": 0.0, "avg_logprob": -0.07314834691057301, "compression_ratio": 1.7649769585253456, "no_speech_prob": 0.2588203549385071}, {"id": 718, "seek": 527812, "start": 5302.44, "end": 5307.96, "text": " counterintuitive because that's the point, I can't necessarily explain exactly how I got there,", "tokens": [51580, 5682, 686, 48314, 570, 300, 311, 264, 935, 11, 286, 393, 380, 4725, 2903, 2293, 577, 286, 658, 456, 11, 51856], "temperature": 0.0, "avg_logprob": -0.07314834691057301, "compression_ratio": 1.7649769585253456, "no_speech_prob": 0.2588203549385071}, {"id": 719, "seek": 530796, "start": 5307.96, "end": 5313.4800000000005, "text": " which is why it's a creative leap. So do you have any pointers on how to really", "tokens": [50364, 597, 307, 983, 309, 311, 257, 5880, 19438, 13, 407, 360, 291, 362, 604, 44548, 322, 577, 281, 534, 50640], "temperature": 0.0, "avg_logprob": -0.09350343626372669, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.0006057601422071457}, {"id": 720, "seek": 530796, "start": 5314.44, "end": 5319.32, "text": " couch it so that it doesn't sound like it came out of nowhere, but then at the same time,", "tokens": [50688, 16511, 309, 370, 300, 309, 1177, 380, 1626, 411, 309, 1361, 484, 295, 11159, 11, 457, 550, 412, 264, 912, 565, 11, 50932], "temperature": 0.0, "avg_logprob": -0.09350343626372669, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.0006057601422071457}, {"id": 721, "seek": 530796, "start": 5319.32, "end": 5326.92, "text": " you don't also try to force fit anything, but then you can show that, yes, it came from knowing", "tokens": [50932, 291, 500, 380, 611, 853, 281, 3464, 3318, 1340, 11, 457, 550, 291, 393, 855, 300, 11, 2086, 11, 309, 1361, 490, 5276, 51312], "temperature": 0.0, "avg_logprob": -0.09350343626372669, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.0006057601422071457}, {"id": 722, "seek": 530796, "start": 5326.92, "end": 5332.28, "text": " my data and all of that, but the direct link that you want to see, I can't necessarily show you.", "tokens": [51312, 452, 1412, 293, 439, 295, 300, 11, 457, 264, 2047, 2113, 300, 291, 528, 281, 536, 11, 286, 393, 380, 4725, 855, 291, 13, 51580], "temperature": 0.0, "avg_logprob": -0.09350343626372669, "compression_ratio": 1.6454545454545455, "no_speech_prob": 0.0006057601422071457}, {"id": 723, "seek": 533228, "start": 5333.24, "end": 5338.28, "text": " No, I think what is important to show in a paper is the coupling.", "tokens": [50412, 883, 11, 286, 519, 437, 307, 1021, 281, 855, 294, 257, 3035, 307, 264, 37447, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11807079105586796, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.0009251932497136295}, {"id": 724, "seek": 533228, "start": 5340.679999999999, "end": 5347.08, "text": " So the way you found that coupling that you can't explain, but you can show the coupling,", "tokens": [50784, 407, 264, 636, 291, 1352, 300, 37447, 300, 291, 393, 380, 2903, 11, 457, 291, 393, 855, 264, 37447, 11, 51104], "temperature": 0.0, "avg_logprob": -0.11807079105586796, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.0009251932497136295}, {"id": 725, "seek": 533228, "start": 5348.04, "end": 5354.5199999999995, "text": " and that is you must show that the data, if you look at them carefully, you can see the link", "tokens": [51152, 293, 300, 307, 291, 1633, 855, 300, 264, 1412, 11, 498, 291, 574, 412, 552, 7500, 11, 291, 393, 536, 264, 2113, 51476], "temperature": 0.0, "avg_logprob": -0.11807079105586796, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.0009251932497136295}, {"id": 726, "seek": 533228, "start": 5355.08, "end": 5361.4, "text": " with the theory. So if you can show that link, that's the important thing. You don't have to", "tokens": [51504, 365, 264, 5261, 13, 407, 498, 291, 393, 855, 300, 2113, 11, 300, 311, 264, 1021, 551, 13, 509, 500, 380, 362, 281, 51820], "temperature": 0.0, "avg_logprob": -0.11807079105586796, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.0009251932497136295}, {"id": 727, "seek": 536140, "start": 5361.48, "end": 5368.04, "text": " tell them how you actually got there, but if, or you can mention that you had a creative leap,", "tokens": [50368, 980, 552, 577, 291, 767, 658, 456, 11, 457, 498, 11, 420, 291, 393, 2152, 300, 291, 632, 257, 5880, 19438, 11, 50696], "temperature": 0.0, "avg_logprob": -0.1288260027893588, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.0004300451255403459}, {"id": 728, "seek": 536140, "start": 5368.04, "end": 5372.599999999999, "text": " but at the same time in the same paper, you have to be able to show that coupling happening,", "tokens": [50696, 457, 412, 264, 912, 565, 294, 264, 912, 3035, 11, 291, 362, 281, 312, 1075, 281, 855, 300, 37447, 2737, 11, 50924], "temperature": 0.0, "avg_logprob": -0.1288260027893588, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.0004300451255403459}, {"id": 729, "seek": 536140, "start": 5372.599999999999, "end": 5378.839999999999, "text": " so that it's tied up with a bone, so that the reader can see that the data, yes, is a good", "tokens": [50924, 370, 300, 309, 311, 9601, 493, 365, 257, 9026, 11, 370, 300, 264, 15149, 393, 536, 300, 264, 1412, 11, 2086, 11, 307, 257, 665, 51236], "temperature": 0.0, "avg_logprob": -0.1288260027893588, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.0004300451255403459}, {"id": 730, "seek": 536140, "start": 5378.839999999999, "end": 5384.839999999999, "text": " explanation, or the theory is, yes, a good explanation for the data, and the data do justify", "tokens": [51236, 10835, 11, 420, 264, 5261, 307, 11, 2086, 11, 257, 665, 10835, 337, 264, 1412, 11, 293, 264, 1412, 360, 20833, 51536], "temperature": 0.0, "avg_logprob": -0.1288260027893588, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.0004300451255403459}, {"id": 731, "seek": 536140, "start": 5385.4, "end": 5388.44, "text": " the theory that you're proposing. So it's the coupling that's important.", "tokens": [51564, 264, 5261, 300, 291, 434, 29939, 13, 407, 309, 311, 264, 37447, 300, 311, 1021, 13, 51716], "temperature": 0.0, "avg_logprob": -0.1288260027893588, "compression_ratio": 1.8893617021276596, "no_speech_prob": 0.0004300451255403459}, {"id": 732, "seek": 538844, "start": 5389.08, "end": 5392.839999999999, "text": " Okay, okay, thank you so much. Yeah, so you get your creative leap, and then you go back,", "tokens": [50396, 1033, 11, 1392, 11, 1309, 291, 370, 709, 13, 865, 11, 370, 291, 483, 428, 5880, 19438, 11, 293, 550, 291, 352, 646, 11, 50584], "temperature": 0.0, "avg_logprob": -0.22296802033769322, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.0024544589687138796}, {"id": 733, "seek": 538844, "start": 5392.839999999999, "end": 5396.12, "text": " you mustn't stop with your creative leap, you have to go back and check it out.", "tokens": [50584, 291, 42818, 380, 1590, 365, 428, 5880, 19438, 11, 291, 362, 281, 352, 646, 293, 1520, 309, 484, 13, 50748], "temperature": 0.0, "avg_logprob": -0.22296802033769322, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.0024544589687138796}, {"id": 734, "seek": 538844, "start": 5397.0, "end": 5401.639999999999, "text": " Otherwise, you can go wrong as well. Fardy? Yeah.", "tokens": [50792, 10328, 11, 291, 393, 352, 2085, 382, 731, 13, 479, 515, 88, 30, 865, 13, 51024], "temperature": 0.0, "avg_logprob": -0.22296802033769322, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.0024544589687138796}, {"id": 735, "seek": 538844, "start": 5405.5599999999995, "end": 5406.12, "text": " Fardy?", "tokens": [51220, 479, 515, 88, 30, 51248], "temperature": 0.0, "avg_logprob": -0.22296802033769322, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.0024544589687138796}, {"id": 736, "seek": 538844, "start": 5406.759999999999, "end": 5412.44, "text": " No, thank you very much, Prof. Really, really interesting and useful presentations, and I find", "tokens": [51280, 883, 11, 1309, 291, 588, 709, 11, 6039, 13, 4083, 11, 534, 1880, 293, 4420, 18964, 11, 293, 286, 915, 51564], "temperature": 0.0, "avg_logprob": -0.22296802033769322, "compression_ratio": 1.621212121212121, "no_speech_prob": 0.0024544589687138796}, {"id": 737, "seek": 541244, "start": 5412.44, "end": 5420.04, "text": " them really very, very relevant to my work, because I've been doing quantitative work until", "tokens": [50364, 552, 534, 588, 11, 588, 7340, 281, 452, 589, 11, 570, 286, 600, 668, 884, 27778, 589, 1826, 50744], "temperature": 0.0, "avg_logprob": -0.11097966647538983, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.001834884868003428}, {"id": 738, "seek": 541244, "start": 5421.32, "end": 5427.639999999999, "text": " the PhD had to do process research. One of the things that I'm really keen to do is to", "tokens": [50808, 264, 14476, 632, 281, 360, 1399, 2132, 13, 1485, 295, 264, 721, 300, 286, 478, 534, 20297, 281, 360, 307, 281, 51124], "temperature": 0.0, "avg_logprob": -0.11097966647538983, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.001834884868003428}, {"id": 739, "seek": 541244, "start": 5428.5199999999995, "end": 5435.24, "text": " really make the best decision on which particular vehicle I use to write,", "tokens": [51168, 534, 652, 264, 1151, 3537, 322, 597, 1729, 5864, 286, 764, 281, 2464, 11, 51504], "temperature": 0.0, "avg_logprob": -0.11097966647538983, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.001834884868003428}, {"id": 740, "seek": 543524, "start": 5435.96, "end": 5443.719999999999, "text": " you know, because I'm using data from several sources over time on how a form of behavior", "tokens": [50400, 291, 458, 11, 570, 286, 478, 1228, 1412, 490, 2940, 7139, 670, 565, 322, 577, 257, 1254, 295, 5223, 50788], "temperature": 0.0, "avg_logprob": -0.1132081178518442, "compression_ratio": 1.5197740112994351, "no_speech_prob": 0.0023097284138202667}, {"id": 741, "seek": 543524, "start": 5443.719999999999, "end": 5450.28, "text": " continued to take different shapes, you know, in an industry that is trying to be formalized,", "tokens": [50788, 7014, 281, 747, 819, 10854, 11, 291, 458, 11, 294, 364, 3518, 300, 307, 1382, 281, 312, 9860, 1602, 11, 51116], "temperature": 0.0, "avg_logprob": -0.1132081178518442, "compression_ratio": 1.5197740112994351, "no_speech_prob": 0.0023097284138202667}, {"id": 742, "seek": 543524, "start": 5450.28, "end": 5458.44, "text": " but then a lot of the informal activity kept on happening over time. So the dialectic", "tokens": [51116, 457, 550, 257, 688, 295, 264, 24342, 5191, 4305, 322, 2737, 670, 565, 13, 407, 264, 24652, 299, 51524], "temperature": 0.0, "avg_logprob": -0.1132081178518442, "compression_ratio": 1.5197740112994351, "no_speech_prob": 0.0023097284138202667}, {"id": 743, "seek": 545844, "start": 5459.4, "end": 5469.799999999999, "text": " one seemed quite interesting, but my question is, is there like, would you recommend picking a model", "tokens": [50412, 472, 6576, 1596, 1880, 11, 457, 452, 1168, 307, 11, 307, 456, 411, 11, 576, 291, 2748, 8867, 257, 2316, 50932], "temperature": 0.0, "avg_logprob": -0.2188624938329061, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.00466907350346446}, {"id": 744, "seek": 545844, "start": 5469.799999999999, "end": 5482.44, "text": " and then trying to write after that model, or how best? The question I think you're asking is,", "tokens": [50932, 293, 550, 1382, 281, 2464, 934, 300, 2316, 11, 420, 577, 1151, 30, 440, 1168, 286, 519, 291, 434, 3365, 307, 11, 51564], "temperature": 0.0, "avg_logprob": -0.2188624938329061, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.00466907350346446}, {"id": 745, "seek": 548244, "start": 5482.44, "end": 5492.919999999999, "text": " where do I start, you know, what does I do first? I think that I would, I tend to start with temporal", "tokens": [50364, 689, 360, 286, 722, 11, 291, 458, 11, 437, 775, 286, 360, 700, 30, 286, 519, 300, 286, 576, 11, 286, 3928, 281, 722, 365, 30881, 50888], "temperature": 0.0, "avg_logprob": -0.14291018974490283, "compression_ratio": 1.6408839779005524, "no_speech_prob": 0.012232075445353985}, {"id": 746, "seek": 548244, "start": 5492.919999999999, "end": 5502.599999999999, "text": " bracketing, because I sort of like to see in the data, what is it, you know, are there turning points?", "tokens": [50888, 12305, 9880, 11, 570, 286, 1333, 295, 411, 281, 536, 294, 264, 1412, 11, 437, 307, 309, 11, 291, 458, 11, 366, 456, 6246, 2793, 30, 51372], "temperature": 0.0, "avg_logprob": -0.14291018974490283, "compression_ratio": 1.6408839779005524, "no_speech_prob": 0.012232075445353985}, {"id": 747, "seek": 548244, "start": 5505.32, "end": 5509.5599999999995, "text": " And then once I've seen that, if there are no turning points, well, then that doesn't really", "tokens": [51508, 400, 550, 1564, 286, 600, 1612, 300, 11, 498, 456, 366, 572, 6246, 2793, 11, 731, 11, 550, 300, 1177, 380, 534, 51720], "temperature": 0.0, "avg_logprob": -0.14291018974490283, "compression_ratio": 1.6408839779005524, "no_speech_prob": 0.012232075445353985}, {"id": 748, "seek": 550956, "start": 5509.56, "end": 5519.0, "text": " work. Maybe that was kind of a smooth continuity. But if there are any turning points, or, you know,", "tokens": [50364, 589, 13, 2704, 300, 390, 733, 295, 257, 5508, 23807, 13, 583, 498, 456, 366, 604, 6246, 2793, 11, 420, 11, 291, 458, 11, 50836], "temperature": 0.0, "avg_logprob": -0.12547564506530762, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.0024324883706867695}, {"id": 749, "seek": 550956, "start": 5519.0, "end": 5525.320000000001, "text": " whether something happened, like some new people came in, or a new company appeared in your industry,", "tokens": [50836, 1968, 746, 2011, 11, 411, 512, 777, 561, 1361, 294, 11, 420, 257, 777, 2237, 8516, 294, 428, 3518, 11, 51152], "temperature": 0.0, "avg_logprob": -0.12547564506530762, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.0024324883706867695}, {"id": 750, "seek": 550956, "start": 5525.320000000001, "end": 5531.96, "text": " or something that changed significantly, more significantly than other events,", "tokens": [51152, 420, 746, 300, 3105, 10591, 11, 544, 10591, 813, 661, 3931, 11, 51484], "temperature": 0.0, "avg_logprob": -0.12547564506530762, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.0024324883706867695}, {"id": 751, "seek": 553196, "start": 5532.92, "end": 5541.4800000000005, "text": " had a potential for change, then those turning points are kind of like a starting point for", "tokens": [50412, 632, 257, 3995, 337, 1319, 11, 550, 729, 6246, 2793, 366, 733, 295, 411, 257, 2891, 935, 337, 50840], "temperature": 0.0, "avg_logprob": -0.08317868892963116, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.00332272588275373}, {"id": 752, "seek": 553196, "start": 5543.72, "end": 5550.6, "text": " looking at the data. Then you might move towards more detailed coding of what was going on in each", "tokens": [50952, 1237, 412, 264, 1412, 13, 1396, 291, 1062, 1286, 3030, 544, 9942, 17720, 295, 437, 390, 516, 322, 294, 1184, 51296], "temperature": 0.0, "avg_logprob": -0.08317868892963116, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.00332272588275373}, {"id": 753, "seek": 553196, "start": 5550.6, "end": 5555.64, "text": " period. And so you would collect together bits of data, which are relevant to each period,", "tokens": [51296, 2896, 13, 400, 370, 291, 576, 2500, 1214, 9239, 295, 1412, 11, 597, 366, 7340, 281, 1184, 2896, 11, 51548], "temperature": 0.0, "avg_logprob": -0.08317868892963116, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.00332272588275373}, {"id": 754, "seek": 555564, "start": 5556.360000000001, "end": 5564.76, "text": " and start working on what's going on, what different actors were doing during those periods.", "tokens": [50400, 293, 722, 1364, 322, 437, 311, 516, 322, 11, 437, 819, 10037, 645, 884, 1830, 729, 13804, 13, 50820], "temperature": 0.0, "avg_logprob": -0.09483159610203334, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.003122867550700903}, {"id": 755, "seek": 555564, "start": 5564.76, "end": 5573.08, "text": " So, I mean, that's, I think what I would do, but yeah, it depends. I think you have to find", "tokens": [50820, 407, 11, 286, 914, 11, 300, 311, 11, 286, 519, 437, 286, 576, 360, 11, 457, 1338, 11, 309, 5946, 13, 286, 519, 291, 362, 281, 915, 51236], "temperature": 0.0, "avg_logprob": -0.09483159610203334, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.003122867550700903}, {"id": 756, "seek": 555564, "start": 5573.08, "end": 5582.280000000001, "text": " something where you kind of have something to grab onto. Another approach is to find another", "tokens": [51236, 746, 689, 291, 733, 295, 362, 746, 281, 4444, 3911, 13, 3996, 3109, 307, 281, 915, 1071, 51696], "temperature": 0.0, "avg_logprob": -0.09483159610203334, "compression_ratio": 1.5919540229885059, "no_speech_prob": 0.003122867550700903}, {"id": 757, "seek": 558228, "start": 5582.28, "end": 5588.92, "text": " basis for comparison in your data. So do you want to compare certain types of firms with", "tokens": [50364, 5143, 337, 9660, 294, 428, 1412, 13, 407, 360, 291, 528, 281, 6794, 1629, 3467, 295, 18055, 365, 50696], "temperature": 0.0, "avg_logprob": -0.10704653313819398, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0039413245394825935}, {"id": 758, "seek": 558228, "start": 5588.92, "end": 5595.96, "text": " certain other types of firms? You know, if so, can you subdivide your data according to different", "tokens": [50696, 1629, 661, 3467, 295, 18055, 30, 509, 458, 11, 498, 370, 11, 393, 291, 45331, 482, 428, 1412, 4650, 281, 819, 51048], "temperature": 0.0, "avg_logprob": -0.10704653313819398, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0039413245394825935}, {"id": 759, "seek": 558228, "start": 5595.96, "end": 5601.48, "text": " types of firms? Or can you subdivide it in some other way? I think it's very useful to find something", "tokens": [51048, 3467, 295, 18055, 30, 1610, 393, 291, 45331, 482, 309, 294, 512, 661, 636, 30, 286, 519, 309, 311, 588, 4420, 281, 915, 746, 51324], "temperature": 0.0, "avg_logprob": -0.10704653313819398, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0039413245394825935}, {"id": 760, "seek": 558228, "start": 5601.48, "end": 5607.719999999999, "text": " to grab onto, which you can compare with another thing. I tend to go for temporal brackets, because", "tokens": [51324, 281, 4444, 3911, 11, 597, 291, 393, 6794, 365, 1071, 551, 13, 286, 3928, 281, 352, 337, 30881, 26179, 11, 570, 51636], "temperature": 0.0, "avg_logprob": -0.10704653313819398, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0039413245394825935}, {"id": 761, "seek": 560772, "start": 5608.68, "end": 5612.280000000001, "text": " I'm a lot closer. Daniel.", "tokens": [50412, 286, 478, 257, 688, 4966, 13, 8033, 13, 50592], "temperature": 0.0, "avg_logprob": -0.17842700682490706, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.0017251035897061229}, {"id": 762, "seek": 560772, "start": 5614.280000000001, "end": 5620.04, "text": " Hi, Anne. Thanks for a great session. This is a question that came from one of our participants,", "tokens": [50692, 2421, 11, 13706, 13, 2561, 337, 257, 869, 5481, 13, 639, 307, 257, 1168, 300, 1361, 490, 472, 295, 527, 10503, 11, 50980], "temperature": 0.0, "avg_logprob": -0.17842700682490706, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.0017251035897061229}, {"id": 763, "seek": 560772, "start": 5620.04, "end": 5629.4800000000005, "text": " Eva Maria Spreitzer. And her question is, what would you say or what kinds of theories are great", "tokens": [50980, 29377, 12734, 1738, 265, 16845, 13, 400, 720, 1168, 307, 11, 437, 576, 291, 584, 420, 437, 3685, 295, 13667, 366, 869, 51452], "temperature": 0.0, "avg_logprob": -0.17842700682490706, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.0017251035897061229}, {"id": 764, "seek": 560772, "start": 5629.4800000000005, "end": 5636.52, "text": " to inform the coding of the data, such as different levels, depths, etc. And the thinking is", "tokens": [51452, 281, 1356, 264, 17720, 295, 264, 1412, 11, 1270, 382, 819, 4358, 11, 28439, 11, 5183, 13, 400, 264, 1953, 307, 51804], "temperature": 0.0, "avg_logprob": -0.17842700682490706, "compression_ratio": 1.4857142857142858, "no_speech_prob": 0.0017251035897061229}, {"id": 765, "seek": 563652, "start": 5637.320000000001, "end": 5643.88, "text": " because it is easy to go from low or tight with concepts or too high or too broad with", "tokens": [50404, 570, 309, 307, 1858, 281, 352, 490, 2295, 420, 4524, 365, 10392, 420, 886, 1090, 420, 886, 4152, 365, 50732], "temperature": 0.0, "avg_logprob": -0.11237598790062799, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0008158980053849518}, {"id": 766, "seek": 563652, "start": 5643.88, "end": 5653.160000000001, "text": " theoretical frameworks or meta theories? Yeah, well, I mean, it depends on the nature of your data.", "tokens": [50732, 20864, 29834, 420, 19616, 13667, 30, 865, 11, 731, 11, 286, 914, 11, 309, 5946, 322, 264, 3687, 295, 428, 1412, 13, 51196], "temperature": 0.0, "avg_logprob": -0.11237598790062799, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0008158980053849518}, {"id": 767, "seek": 563652, "start": 5653.160000000001, "end": 5662.6, "text": " But, you know, as I mentioned, you can you can code your data with no a priori theory,", "tokens": [51196, 583, 11, 291, 458, 11, 382, 286, 2835, 11, 291, 393, 291, 393, 3089, 428, 1412, 365, 572, 257, 4059, 72, 5261, 11, 51668], "temperature": 0.0, "avg_logprob": -0.11237598790062799, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0008158980053849518}, {"id": 768, "seek": 566260, "start": 5662.6, "end": 5670.84, "text": " you can just read it and see what you see. That that's the theory behind grounded coding.", "tokens": [50364, 291, 393, 445, 1401, 309, 293, 536, 437, 291, 536, 13, 663, 300, 311, 264, 5261, 2261, 23535, 17720, 13, 50776], "temperature": 0.0, "avg_logprob": -0.1289302626652504, "compression_ratio": 1.5493827160493827, "no_speech_prob": 0.0012639875058084726}, {"id": 769, "seek": 566260, "start": 5670.84, "end": 5678.84, "text": " But if you want to, if you want to develop more oriented coding,", "tokens": [50776, 583, 498, 291, 528, 281, 11, 498, 291, 528, 281, 1499, 544, 21841, 17720, 11, 51176], "temperature": 0.0, "avg_logprob": -0.1289302626652504, "compression_ratio": 1.5493827160493827, "no_speech_prob": 0.0012639875058084726}, {"id": 770, "seek": 566260, "start": 5681.320000000001, "end": 5686.84, "text": " I mean, think about what it is, what are some of the the concepts that you're interested in. So,", "tokens": [51300, 286, 914, 11, 519, 466, 437, 309, 307, 11, 437, 366, 512, 295, 264, 264, 10392, 300, 291, 434, 3102, 294, 13, 407, 11, 51576], "temperature": 0.0, "avg_logprob": -0.1289302626652504, "compression_ratio": 1.5493827160493827, "no_speech_prob": 0.0012639875058084726}, {"id": 771, "seek": 568684, "start": 5687.24, "end": 5696.4400000000005, "text": " so if you want to really focus on processes, maybe your coding should be about activities,", "tokens": [50384, 370, 498, 291, 528, 281, 534, 1879, 322, 7555, 11, 1310, 428, 17720, 820, 312, 466, 5354, 11, 50844], "temperature": 0.0, "avg_logprob": -0.12452098991297468, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.00015115199494175613}, {"id": 772, "seek": 568684, "start": 5696.4400000000005, "end": 5701.64, "text": " right? So what activities are people thinking about? So that would be one", "tokens": [50844, 558, 30, 407, 437, 5354, 366, 561, 1953, 466, 30, 407, 300, 576, 312, 472, 51104], "temperature": 0.0, "avg_logprob": -0.12452098991297468, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.00015115199494175613}, {"id": 773, "seek": 568684, "start": 5702.68, "end": 5710.28, "text": " angle to look at. So process, process theory is about activities. So can we code activities?", "tokens": [51156, 5802, 281, 574, 412, 13, 407, 1399, 11, 1399, 5261, 307, 466, 5354, 13, 407, 393, 321, 3089, 5354, 30, 51536], "temperature": 0.0, "avg_logprob": -0.12452098991297468, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.00015115199494175613}, {"id": 774, "seek": 568684, "start": 5711.24, "end": 5715.96, "text": " But you might be interested in something else, you might be interested in emotions,", "tokens": [51584, 583, 291, 1062, 312, 3102, 294, 746, 1646, 11, 291, 1062, 312, 3102, 294, 8462, 11, 51820], "temperature": 0.0, "avg_logprob": -0.12452098991297468, "compression_ratio": 1.8138297872340425, "no_speech_prob": 0.00015115199494175613}, {"id": 775, "seek": 571596, "start": 5715.96, "end": 5722.04, "text": " for example. So then you might code emotions, and then you might ask yourself, well, what", "tokens": [50364, 337, 1365, 13, 407, 550, 291, 1062, 3089, 8462, 11, 293, 550, 291, 1062, 1029, 1803, 11, 731, 11, 437, 50668], "temperature": 0.0, "avg_logprob": -0.14668157365587023, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003511657996568829}, {"id": 776, "seek": 571596, "start": 5722.04, "end": 5728.04, "text": " emotions are associated with which activities and which events? So, so that then you would code those.", "tokens": [50668, 8462, 366, 6615, 365, 597, 5354, 293, 597, 3931, 30, 407, 11, 370, 300, 550, 291, 576, 3089, 729, 13, 50968], "temperature": 0.0, "avg_logprob": -0.14668157365587023, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003511657996568829}, {"id": 777, "seek": 571596, "start": 5729.64, "end": 5734.2, "text": " So, I mean, this is a this is a decision, depending on the on the research questions", "tokens": [51048, 407, 11, 286, 914, 11, 341, 307, 257, 341, 307, 257, 3537, 11, 5413, 322, 264, 322, 264, 2132, 1651, 51276], "temperature": 0.0, "avg_logprob": -0.14668157365587023, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003511657996568829}, {"id": 778, "seek": 571596, "start": 5734.2, "end": 5740.12, "text": " you're interested in. But, but if you're interested in process, I think, I think", "tokens": [51276, 291, 434, 3102, 294, 13, 583, 11, 457, 498, 291, 434, 3102, 294, 1399, 11, 286, 519, 11, 286, 519, 51572], "temperature": 0.0, "avg_logprob": -0.14668157365587023, "compression_ratio": 1.7294685990338163, "no_speech_prob": 0.0003511657996568829}, {"id": 779, "seek": 574012, "start": 5740.2, "end": 5746.12, "text": " activities, I think events would be things to focus on. I don't know if that's helpful.", "tokens": [50368, 5354, 11, 286, 519, 3931, 576, 312, 721, 281, 1879, 322, 13, 286, 500, 380, 458, 498, 300, 311, 4961, 13, 50664], "temperature": 0.0, "avg_logprob": -0.2505031102140185, "compression_ratio": 1.374331550802139, "no_speech_prob": 0.004791493993252516}, {"id": 780, "seek": 574012, "start": 5748.2, "end": 5752.2, "text": " For me, it is. I hope Eva Maria likes the answer also. Thank you.", "tokens": [50768, 1171, 385, 11, 309, 307, 13, 286, 1454, 29377, 12734, 5902, 264, 1867, 611, 13, 1044, 291, 13, 50968], "temperature": 0.0, "avg_logprob": -0.2505031102140185, "compression_ratio": 1.374331550802139, "no_speech_prob": 0.004791493993252516}, {"id": 781, "seek": 574012, "start": 5754.2, "end": 5754.76, "text": " Rosala.", "tokens": [51068, 11144, 5159, 13, 51096], "temperature": 0.0, "avg_logprob": -0.2505031102140185, "compression_ratio": 1.374331550802139, "no_speech_prob": 0.004791493993252516}, {"id": 782, "seek": 574012, "start": 5756.12, "end": 5763.72, "text": " Hi, thank you very much. So my question is about this combining a grounded theory approach with", "tokens": [51164, 2421, 11, 1309, 291, 588, 709, 13, 407, 452, 1168, 307, 466, 341, 21928, 257, 23535, 5261, 3109, 365, 51544], "temperature": 0.0, "avg_logprob": -0.2505031102140185, "compression_ratio": 1.374331550802139, "no_speech_prob": 0.004791493993252516}, {"id": 783, "seek": 576372, "start": 5763.72, "end": 5769.72, "text": " the a priori approach. And I was reflecting on on this from a more", "tokens": [50364, 264, 257, 4059, 72, 3109, 13, 400, 286, 390, 23543, 322, 322, 341, 490, 257, 544, 50664], "temperature": 0.0, "avg_logprob": -0.17272262573242186, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.028637535870075226}, {"id": 784, "seek": 576372, "start": 5770.84, "end": 5776.280000000001, "text": " based homological point of view. So as far as understood, one would be more interpreted and", "tokens": [50720, 2361, 3655, 4383, 935, 295, 1910, 13, 407, 382, 1400, 382, 7320, 11, 472, 576, 312, 544, 26749, 293, 50992], "temperature": 0.0, "avg_logprob": -0.17272262573242186, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.028637535870075226}, {"id": 785, "seek": 576372, "start": 5776.280000000001, "end": 5782.6, "text": " the other would be kind of more positivist. And I and I, I still struggle to see how can we do that", "tokens": [50992, 264, 661, 576, 312, 733, 295, 544, 40806, 468, 13, 400, 286, 293, 286, 11, 286, 920, 7799, 281, 536, 577, 393, 321, 360, 300, 51308], "temperature": 0.0, "avg_logprob": -0.17272262573242186, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.028637535870075226}, {"id": 786, "seek": 576372, "start": 5782.6, "end": 5788.6, "text": " and how we can combine both. And I don't know, maybe I didn't get it right. Or maybe you have", "tokens": [51308, 293, 577, 321, 393, 10432, 1293, 13, 400, 286, 500, 380, 458, 11, 1310, 286, 994, 380, 483, 309, 558, 13, 1610, 1310, 291, 362, 51608], "temperature": 0.0, "avg_logprob": -0.17272262573242186, "compression_ratio": 1.5784753363228698, "no_speech_prob": 0.028637535870075226}, {"id": 787, "seek": 578860, "start": 5788.6, "end": 5794.200000000001, "text": " some insight for me. Thank you. Yeah, but I mean, some some theories are interpretive. So I don't", "tokens": [50364, 512, 11269, 337, 385, 13, 1044, 291, 13, 865, 11, 457, 286, 914, 11, 512, 512, 13667, 366, 7302, 488, 13, 407, 286, 500, 380, 50644], "temperature": 0.0, "avg_logprob": -0.12270194227977466, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.0014287875965237617}, {"id": 788, "seek": 578860, "start": 5794.200000000001, "end": 5802.6, "text": " think it necessarily, you know, means that one is one is more interpretive and the other is", "tokens": [50644, 519, 309, 4725, 11, 291, 458, 11, 1355, 300, 472, 307, 472, 307, 544, 7302, 488, 293, 264, 661, 307, 51064], "temperature": 0.0, "avg_logprob": -0.12270194227977466, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.0014287875965237617}, {"id": 789, "seek": 578860, "start": 5802.6, "end": 5808.360000000001, "text": " more positivist. But, you know, there is this idea of induction and deduction.", "tokens": [51064, 544, 40806, 468, 13, 583, 11, 291, 458, 11, 456, 307, 341, 1558, 295, 33371, 293, 46385, 13, 51352], "temperature": 0.0, "avg_logprob": -0.12270194227977466, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.0014287875965237617}, {"id": 790, "seek": 578860, "start": 5810.04, "end": 5816.4400000000005, "text": " But I think that what you need to understand is that even if you are doing an interpretive bottom", "tokens": [51436, 583, 286, 519, 300, 437, 291, 643, 281, 1223, 307, 300, 754, 498, 291, 366, 884, 364, 7302, 488, 2767, 51756], "temperature": 0.0, "avg_logprob": -0.12270194227977466, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.0014287875965237617}, {"id": 791, "seek": 581644, "start": 5816.44, "end": 5825.719999999999, "text": " up constructivist approach, you need to connect it to in order to make a contribution, you need", "tokens": [50364, 493, 7690, 592, 468, 3109, 11, 291, 643, 281, 1745, 309, 281, 294, 1668, 281, 652, 257, 13150, 11, 291, 643, 50828], "temperature": 0.0, "avg_logprob": -0.11895175718925369, "compression_ratio": 1.6058823529411765, "no_speech_prob": 0.0014526810264214873}, {"id": 792, "seek": 581644, "start": 5825.719999999999, "end": 5834.12, "text": " to connect it to some a priori theorizing. So if you read carefully, even Denny Joyer's", "tokens": [50828, 281, 1745, 309, 281, 512, 257, 4059, 72, 27423, 3319, 13, 407, 498, 291, 1401, 7500, 11, 754, 6458, 1634, 15571, 260, 311, 51248], "temperature": 0.0, "avg_logprob": -0.11895175718925369, "compression_ratio": 1.6058823529411765, "no_speech_prob": 0.0014526810264214873}, {"id": 793, "seek": 581644, "start": 5835.24, "end": 5841.0, "text": " papers, they are not a theoretical from the start, he reviews, he reviews the literature,", "tokens": [51304, 10577, 11, 436, 366, 406, 257, 20864, 490, 264, 722, 11, 415, 10229, 11, 415, 10229, 264, 10394, 11, 51592], "temperature": 0.0, "avg_logprob": -0.11895175718925369, "compression_ratio": 1.6058823529411765, "no_speech_prob": 0.0014526810264214873}, {"id": 794, "seek": 584100, "start": 5841.0, "end": 5848.92, "text": " he comes up with a research question. And his work, his work done with other colleagues", "tokens": [50364, 415, 1487, 493, 365, 257, 2132, 1168, 13, 400, 702, 589, 11, 702, 589, 1096, 365, 661, 7734, 50760], "temperature": 0.0, "avg_logprob": -0.12397379570818962, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.004066766705363989}, {"id": 795, "seek": 584100, "start": 5848.92, "end": 5854.28, "text": " is cumulative, actually, he's interested in identity or has been interested very much in", "tokens": [50760, 307, 38379, 11, 767, 11, 415, 311, 3102, 294, 6575, 420, 575, 668, 3102, 588, 709, 294, 51028], "temperature": 0.0, "avg_logprob": -0.12397379570818962, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.004066766705363989}, {"id": 796, "seek": 584100, "start": 5854.28, "end": 5858.68, "text": " identity. And if you look at each of his papers, they kind of build on each other in many, very,", "tokens": [51028, 6575, 13, 400, 498, 291, 574, 412, 1184, 295, 702, 10577, 11, 436, 733, 295, 1322, 322, 1184, 661, 294, 867, 11, 588, 11, 51248], "temperature": 0.0, "avg_logprob": -0.12397379570818962, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.004066766705363989}, {"id": 797, "seek": 584100, "start": 5858.68, "end": 5869.08, "text": " very, very many ways. And so they're not, they're not a theoretical. And so I think you always need", "tokens": [51248, 588, 11, 588, 867, 2098, 13, 400, 370, 436, 434, 406, 11, 436, 434, 406, 257, 20864, 13, 400, 370, 286, 519, 291, 1009, 643, 51768], "temperature": 0.0, "avg_logprob": -0.12397379570818962, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.004066766705363989}, {"id": 798, "seek": 586908, "start": 5869.08, "end": 5879.64, "text": " to refer back to other literature. Yeah. But you need to find your sources that fit with what", "tokens": [50364, 281, 2864, 646, 281, 661, 10394, 13, 865, 13, 583, 291, 643, 281, 915, 428, 7139, 300, 3318, 365, 437, 50892], "temperature": 0.0, "avg_logprob": -0.10830900980078656, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0013430846156552434}, {"id": 799, "seek": 586908, "start": 5880.44, "end": 5889.5599999999995, "text": " you're doing. I think a really interesting body of work, which really shows this kind of bottom", "tokens": [50932, 291, 434, 884, 13, 286, 519, 257, 534, 1880, 1772, 295, 589, 11, 597, 534, 3110, 341, 733, 295, 2767, 51388], "temperature": 0.0, "avg_logprob": -0.10830900980078656, "compression_ratio": 1.3695652173913044, "no_speech_prob": 0.0013430846156552434}, {"id": 800, "seek": 588956, "start": 5889.56, "end": 5899.0, "text": " up top down idea is the body of work on organizational routines, the theory of routine", "tokens": [50364, 493, 1192, 760, 1558, 307, 264, 1772, 295, 589, 322, 24730, 33827, 11, 264, 5261, 295, 9927, 50836], "temperature": 0.0, "avg_logprob": -0.1380217613712434, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.03151869401335716}, {"id": 801, "seek": 588956, "start": 5899.0, "end": 5905.400000000001, "text": " dynamics. And so this is always, the studies are almost always qualitative. The notion of routine", "tokens": [50836, 15679, 13, 400, 370, 341, 307, 1009, 11, 264, 5313, 366, 1920, 1009, 31312, 13, 440, 10710, 295, 9927, 51156], "temperature": 0.0, "avg_logprob": -0.1380217613712434, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.03151869401335716}, {"id": 802, "seek": 588956, "start": 5905.400000000001, "end": 5914.280000000001, "text": " dynamics was developed by Feldman and Pentland. They wrote a very famous 2003 article in", "tokens": [51156, 15679, 390, 4743, 538, 42677, 1601, 293, 20165, 1661, 13, 814, 4114, 257, 588, 4618, 16416, 7222, 294, 51600], "temperature": 0.0, "avg_logprob": -0.1380217613712434, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.03151869401335716}, {"id": 803, "seek": 591428, "start": 5914.36, "end": 5921.8, "text": " administrative science quarterly. Other people interested in routine since that time have built", "tokens": [50368, 17900, 3497, 38633, 13, 5358, 561, 3102, 294, 9927, 1670, 300, 565, 362, 3094, 50740], "temperature": 0.0, "avg_logprob": -0.22178718961518387, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.0035346425138413906}, {"id": 804, "seek": 591428, "start": 5921.8, "end": 5928.759999999999, "text": " on that paper and their theory, but each one is making a very distinctive contribution.", "tokens": [50740, 322, 300, 3035, 293, 641, 5261, 11, 457, 1184, 472, 307, 1455, 257, 588, 27766, 13150, 13, 51088], "temperature": 0.0, "avg_logprob": -0.22178718961518387, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.0035346425138413906}, {"id": 805, "seek": 591428, "start": 5930.44, "end": 5939.32, "text": " And it's qualitative and it's processual. But the research questions are different, except there", "tokens": [51172, 400, 309, 311, 31312, 293, 309, 311, 1399, 901, 13, 583, 264, 2132, 1651, 366, 819, 11, 3993, 456, 51616], "temperature": 0.0, "avg_logprob": -0.22178718961518387, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.0035346425138413906}, {"id": 806, "seek": 593932, "start": 5939.4, "end": 5945.799999999999, "text": " are some concepts, foundational concepts that everybody is using, that just simply get", "tokens": [50368, 366, 512, 10392, 11, 32195, 10392, 300, 2201, 307, 1228, 11, 300, 445, 2935, 483, 50688], "temperature": 0.0, "avg_logprob": -0.14330357771653396, "compression_ratio": 1.4673913043478262, "no_speech_prob": 0.00262629147619009}, {"id": 807, "seek": 593932, "start": 5945.799999999999, "end": 5954.44, "text": " more richer and further elaborated each time. So that might be a good body of work to sort of", "tokens": [50688, 544, 29021, 293, 3052, 16298, 770, 1184, 565, 13, 407, 300, 1062, 312, 257, 665, 1772, 295, 589, 281, 1333, 295, 51120], "temperature": 0.0, "avg_logprob": -0.14330357771653396, "compression_ratio": 1.4673913043478262, "no_speech_prob": 0.00262629147619009}, {"id": 808, "seek": 593932, "start": 5955.08, "end": 5964.84, "text": " situate this kind of top down bottom up idea against. Thank you very much. If could I add", "tokens": [51152, 2054, 473, 341, 733, 295, 1192, 760, 2767, 493, 1558, 1970, 13, 1044, 291, 588, 709, 13, 759, 727, 286, 909, 51640], "temperature": 0.0, "avg_logprob": -0.14330357771653396, "compression_ratio": 1.4673913043478262, "no_speech_prob": 0.00262629147619009}, {"id": 809, "seek": 596484, "start": 5964.92, "end": 5973.4800000000005, "text": " a second question? Yes, okay. It's actually more on the practice on the on the coding and analysis", "tokens": [50368, 257, 1150, 1168, 30, 1079, 11, 1392, 13, 467, 311, 767, 544, 322, 264, 3124, 322, 264, 322, 264, 17720, 293, 5215, 50796], "temperature": 0.0, "avg_logprob": -0.118560791015625, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0074370731599628925}, {"id": 810, "seek": 596484, "start": 5973.4800000000005, "end": 5980.12, "text": " side. So as a PhD student, I also find sometimes a bit overwhelming to look at different cases at", "tokens": [50796, 1252, 13, 407, 382, 257, 14476, 3107, 11, 286, 611, 915, 2171, 257, 857, 13373, 281, 574, 412, 819, 3331, 412, 51128], "temperature": 0.0, "avg_logprob": -0.118560791015625, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0074370731599628925}, {"id": 811, "seek": 596484, "start": 5980.12, "end": 5987.88, "text": " the same time. And so I was trying to playing around with different approaches. And I was wondering", "tokens": [51128, 264, 912, 565, 13, 400, 370, 286, 390, 1382, 281, 2433, 926, 365, 819, 11587, 13, 400, 286, 390, 6359, 51516], "temperature": 0.0, "avg_logprob": -0.118560791015625, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0074370731599628925}, {"id": 812, "seek": 596484, "start": 5987.88, "end": 5992.68, "text": " if you have any suggestion to maybe start from one case or actually know it's much better to", "tokens": [51516, 498, 291, 362, 604, 16541, 281, 1310, 722, 490, 472, 1389, 420, 767, 458, 309, 311, 709, 1101, 281, 51756], "temperature": 0.0, "avg_logprob": -0.118560791015625, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.0074370731599628925}, {"id": 813, "seek": 599268, "start": 5992.68, "end": 5996.6, "text": " look directly through all of them. And what's your opinion on that? Thank you.", "tokens": [50364, 574, 3838, 807, 439, 295, 552, 13, 400, 437, 311, 428, 4800, 322, 300, 30, 1044, 291, 13, 50560], "temperature": 0.0, "avg_logprob": -0.1020203523857649, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0007764280890114605}, {"id": 814, "seek": 599268, "start": 5999.400000000001, "end": 6006.52, "text": " Yeah, I don't know. I think it depends a little bit on whether you want to explain each case", "tokens": [50700, 865, 11, 286, 500, 380, 458, 13, 286, 519, 309, 5946, 257, 707, 857, 322, 1968, 291, 528, 281, 2903, 1184, 1389, 51056], "temperature": 0.0, "avg_logprob": -0.1020203523857649, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0007764280890114605}, {"id": 815, "seek": 599268, "start": 6006.52, "end": 6013.88, "text": " individually and maybe think of them as separate contributions or whether the comparison is really", "tokens": [51056, 16652, 293, 1310, 519, 295, 552, 382, 4994, 15725, 420, 1968, 264, 9660, 307, 534, 51424], "temperature": 0.0, "avg_logprob": -0.1020203523857649, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0007764280890114605}, {"id": 816, "seek": 599268, "start": 6014.52, "end": 6020.360000000001, "text": " critically important to you. And then you want to keep it keep it going. But I mean, another", "tokens": [51456, 22797, 1021, 281, 291, 13, 400, 550, 291, 528, 281, 1066, 309, 1066, 309, 516, 13, 583, 286, 914, 11, 1071, 51748], "temperature": 0.0, "avg_logprob": -0.1020203523857649, "compression_ratio": 1.5782608695652174, "no_speech_prob": 0.0007764280890114605}, {"id": 817, "seek": 602036, "start": 6021.32, "end": 6026.44, "text": " I think Daniel asked this question, you know, no, it was someone else who asked the question,", "tokens": [50412, 286, 519, 8033, 2351, 341, 1168, 11, 291, 458, 11, 572, 11, 309, 390, 1580, 1646, 567, 2351, 264, 1168, 11, 50668], "temperature": 0.0, "avg_logprob": -0.15063661210080412, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.0004168454615864903}, {"id": 818, "seek": 602036, "start": 6026.44, "end": 6031.16, "text": " where do you start? And I said temple bracketing and another another way to start is just to", "tokens": [50668, 689, 360, 291, 722, 30, 400, 286, 848, 10184, 12305, 9880, 293, 1071, 1071, 636, 281, 722, 307, 445, 281, 50904], "temperature": 0.0, "avg_logprob": -0.15063661210080412, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.0004168454615864903}, {"id": 819, "seek": 602036, "start": 6031.16, "end": 6037.5599999999995, "text": " write these narratives for each of your cases. That's that's so helpful. If you have different", "tokens": [50904, 2464, 613, 28016, 337, 1184, 295, 428, 3331, 13, 663, 311, 300, 311, 370, 4961, 13, 759, 291, 362, 819, 51224], "temperature": 0.0, "avg_logprob": -0.15063661210080412, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.0004168454615864903}, {"id": 820, "seek": 602036, "start": 6037.5599999999995, "end": 6046.679999999999, "text": " cases, write the narrative, put quotes everywhere. In the narrative, you know, let's let's just tell", "tokens": [51224, 3331, 11, 2464, 264, 9977, 11, 829, 19963, 5315, 13, 682, 264, 9977, 11, 291, 458, 11, 718, 311, 718, 311, 445, 980, 51680], "temperature": 0.0, "avg_logprob": -0.15063661210080412, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.0004168454615864903}, {"id": 821, "seek": 604668, "start": 6046.68, "end": 6050.84, "text": " the story. And, you know, all the quotes that you think are so great that you absolutely need to", "tokens": [50364, 264, 1657, 13, 400, 11, 291, 458, 11, 439, 264, 19963, 300, 291, 519, 366, 370, 869, 300, 291, 3122, 643, 281, 50572], "temperature": 0.0, "avg_logprob": -0.11686342138993112, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.002285921713337302}, {"id": 822, "seek": 604668, "start": 6050.84, "end": 6056.52, "text": " use them, you put them in the narrative. And then you've got this kind of secondary database where", "tokens": [50572, 764, 552, 11, 291, 829, 552, 294, 264, 9977, 13, 400, 550, 291, 600, 658, 341, 733, 295, 11396, 8149, 689, 50856], "temperature": 0.0, "avg_logprob": -0.11686342138993112, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.002285921713337302}, {"id": 823, "seek": 604668, "start": 6056.52, "end": 6065.0, "text": " you can compare the narratives. And so that becomes then you can write new tables that compare the", "tokens": [50856, 291, 393, 6794, 264, 28016, 13, 400, 370, 300, 3643, 550, 291, 393, 2464, 777, 8020, 300, 6794, 264, 51280], "temperature": 0.0, "avg_logprob": -0.11686342138993112, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.002285921713337302}, {"id": 824, "seek": 604668, "start": 6065.0, "end": 6072.12, "text": " narratives. So you can look case one, case two, the first phase, the second phase, and then it", "tokens": [51280, 28016, 13, 407, 291, 393, 574, 1389, 472, 11, 1389, 732, 11, 264, 700, 5574, 11, 264, 1150, 5574, 11, 293, 550, 309, 51636], "temperature": 0.0, "avg_logprob": -0.11686342138993112, "compression_ratio": 1.8523809523809525, "no_speech_prob": 0.002285921713337302}, {"id": 825, "seek": 607212, "start": 6072.12, "end": 6076.12, "text": " becomes organized. But narrative can be a great way to get started as well.", "tokens": [50364, 3643, 9983, 13, 583, 9977, 393, 312, 257, 869, 636, 281, 483, 1409, 382, 731, 13, 50564], "temperature": 0.0, "avg_logprob": -0.21277698940700954, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0017985556041821837}, {"id": 826, "seek": 607212, "start": 6079.5599999999995, "end": 6085.4, "text": " Loreto. Hi, thanks, Anne. It's a really brilliant presentation. I'm really going to help with my", "tokens": [50736, 36994, 1353, 13, 2421, 11, 3231, 11, 13706, 13, 467, 311, 257, 534, 10248, 5860, 13, 286, 478, 534, 516, 281, 854, 365, 452, 51028], "temperature": 0.0, "avg_logprob": -0.21277698940700954, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0017985556041821837}, {"id": 827, "seek": 607212, "start": 6085.4, "end": 6090.5199999999995, "text": " my projects that I'm doing at the moment. So thank you. And I'm my questions more about the", "tokens": [51028, 452, 4455, 300, 286, 478, 884, 412, 264, 1623, 13, 407, 1309, 291, 13, 400, 286, 478, 452, 1651, 544, 466, 264, 51284], "temperature": 0.0, "avg_logprob": -0.21277698940700954, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0017985556041821837}, {"id": 828, "seek": 607212, "start": 6090.5199999999995, "end": 6097.08, "text": " endpoint and about where where to get published and where you think are kind of the journals that", "tokens": [51284, 35795, 293, 466, 689, 689, 281, 483, 6572, 293, 689, 291, 519, 366, 733, 295, 264, 29621, 300, 51612], "temperature": 0.0, "avg_logprob": -0.21277698940700954, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.0017985556041821837}, {"id": 829, "seek": 609708, "start": 6097.08, "end": 6106.5199999999995, "text": " are more aligned to process research. Thank you. Well, it depends what your field is. I'm in the", "tokens": [50364, 366, 544, 17962, 281, 1399, 2132, 13, 1044, 291, 13, 1042, 11, 309, 5946, 437, 428, 2519, 307, 13, 286, 478, 294, 264, 50836], "temperature": 0.0, "avg_logprob": -0.189643799312531, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.007791887037456036}, {"id": 830, "seek": 609708, "start": 6106.5199999999995, "end": 6118.28, "text": " field of management. So the the North American management journals, like Academy of Management", "tokens": [50836, 2519, 295, 4592, 13, 407, 264, 264, 4067, 2665, 4592, 29621, 11, 411, 11735, 295, 14781, 51424], "temperature": 0.0, "avg_logprob": -0.189643799312531, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.007791887037456036}, {"id": 831, "seek": 609708, "start": 6118.28, "end": 6125.8, "text": " Journal and Admirative Science Quarterly and Organization Science, have they published all", "tokens": [51424, 16936, 293, 1999, 19834, 1166, 8976, 43794, 356, 293, 23979, 8976, 11, 362, 436, 6572, 439, 51800], "temperature": 0.0, "avg_logprob": -0.189643799312531, "compression_ratio": 1.4536082474226804, "no_speech_prob": 0.007791887037456036}, {"id": 832, "seek": 612580, "start": 6125.8, "end": 6129.88, "text": " kinds of research, they published quantitative and qualitative research.", "tokens": [50364, 3685, 295, 2132, 11, 436, 6572, 27778, 293, 31312, 2132, 13, 50568], "temperature": 0.0, "avg_logprob": -0.12770437214472521, "compression_ratio": 1.92, "no_speech_prob": 0.0008689385140314698}, {"id": 833, "seek": 612580, "start": 6132.12, "end": 6138.4400000000005, "text": " And they have editors who are dedicated to qualitative research. So I am an editor at", "tokens": [50680, 400, 436, 362, 31446, 567, 366, 8374, 281, 31312, 2132, 13, 407, 286, 669, 364, 9839, 412, 50996], "temperature": 0.0, "avg_logprob": -0.12770437214472521, "compression_ratio": 1.92, "no_speech_prob": 0.0008689385140314698}, {"id": 834, "seek": 612580, "start": 6138.4400000000005, "end": 6144.04, "text": " Academy of Management Journal, and I am dedicated to qualitative research. And we have five,", "tokens": [50996, 11735, 295, 14781, 16936, 11, 293, 286, 669, 8374, 281, 31312, 2132, 13, 400, 321, 362, 1732, 11, 51276], "temperature": 0.0, "avg_logprob": -0.12770437214472521, "compression_ratio": 1.92, "no_speech_prob": 0.0008689385140314698}, {"id": 835, "seek": 612580, "start": 6144.68, "end": 6152.52, "text": " we're a team of five editors that consider qualitative research. And it would be the", "tokens": [51308, 321, 434, 257, 1469, 295, 1732, 31446, 300, 1949, 31312, 2132, 13, 400, 309, 576, 312, 264, 51700], "temperature": 0.0, "avg_logprob": -0.12770437214472521, "compression_ratio": 1.92, "no_speech_prob": 0.0008689385140314698}, {"id": 836, "seek": 615252, "start": 6152.52, "end": 6158.52, "text": " same in the other journals I mentioned. And so although they published a lot of quantitative", "tokens": [50364, 912, 294, 264, 661, 29621, 286, 2835, 13, 400, 370, 4878, 436, 6572, 257, 688, 295, 27778, 50664], "temperature": 0.0, "avg_logprob": -0.09829952777960362, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.001923667499795556}, {"id": 837, "seek": 615252, "start": 6158.52, "end": 6162.92, "text": " research, they also published much a great deal of qualitative research. So that that's a good", "tokens": [50664, 2132, 11, 436, 611, 6572, 709, 257, 869, 2028, 295, 31312, 2132, 13, 407, 300, 300, 311, 257, 665, 50884], "temperature": 0.0, "avg_logprob": -0.09829952777960362, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.001923667499795556}, {"id": 838, "seek": 615252, "start": 6163.4800000000005, "end": 6171.64, "text": " place to go. Many of the European type journals are more qualitative oriented than the North", "tokens": [50912, 1081, 281, 352, 13, 5126, 295, 264, 6473, 2010, 29621, 366, 544, 31312, 21841, 813, 264, 4067, 51320], "temperature": 0.0, "avg_logprob": -0.09829952777960362, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.001923667499795556}, {"id": 839, "seek": 615252, "start": 6171.64, "end": 6179.240000000001, "text": " American ones. So organization studies is a great journal, journal management studies are", "tokens": [51320, 2665, 2306, 13, 407, 4475, 5313, 307, 257, 869, 6708, 11, 6708, 4592, 5313, 366, 51700], "temperature": 0.0, "avg_logprob": -0.09829952777960362, "compression_ratio": 1.705069124423963, "no_speech_prob": 0.001923667499795556}, {"id": 840, "seek": 617924, "start": 6179.24, "end": 6185.4, "text": " great journals for this work. I'm not sure that I think what in order to decide which kind of", "tokens": [50364, 869, 29621, 337, 341, 589, 13, 286, 478, 406, 988, 300, 286, 519, 437, 294, 1668, 281, 4536, 597, 733, 295, 50672], "temperature": 0.0, "avg_logprob": -0.08828182623419963, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.001985095674172044}, {"id": 841, "seek": 617924, "start": 6185.4, "end": 6194.2, "text": " journal you want to publish in, it's a good idea just to read, you know, those journals and see", "tokens": [50672, 6708, 291, 528, 281, 11374, 294, 11, 309, 311, 257, 665, 1558, 445, 281, 1401, 11, 291, 458, 11, 729, 29621, 293, 536, 51112], "temperature": 0.0, "avg_logprob": -0.08828182623419963, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.001985095674172044}, {"id": 842, "seek": 617924, "start": 6194.2, "end": 6202.76, "text": " where you see things that that correspond to your interests, and that you think that you can relate", "tokens": [51112, 689, 291, 536, 721, 300, 300, 6805, 281, 428, 8847, 11, 293, 300, 291, 519, 300, 291, 393, 10961, 51540], "temperature": 0.0, "avg_logprob": -0.08828182623419963, "compression_ratio": 1.6327683615819208, "no_speech_prob": 0.001985095674172044}, {"id": 843, "seek": 620276, "start": 6202.76, "end": 6211.64, "text": " to. So some journals have more of a sociological flavor, and they may relate more to sociological", "tokens": [50364, 281, 13, 407, 512, 29621, 362, 544, 295, 257, 3075, 4383, 6813, 11, 293, 436, 815, 10961, 544, 281, 3075, 4383, 50808], "temperature": 0.0, "avg_logprob": -0.10890568003934972, "compression_ratio": 1.5628415300546448, "no_speech_prob": 0.005542255938053131}, {"id": 844, "seek": 620276, "start": 6211.64, "end": 6217.400000000001, "text": " literatures, some are more managerially oriented. And there are delicate differences that you need", "tokens": [50808, 2733, 3377, 11, 512, 366, 544, 6598, 2270, 21841, 13, 400, 456, 366, 21417, 7300, 300, 291, 643, 51096], "temperature": 0.0, "avg_logprob": -0.10890568003934972, "compression_ratio": 1.5628415300546448, "no_speech_prob": 0.005542255938053131}, {"id": 845, "seek": 620276, "start": 6217.400000000001, "end": 6223.72, "text": " to kind of get familiar with. And it's very difficult to pick one. But all the journals I", "tokens": [51096, 281, 733, 295, 483, 4963, 365, 13, 400, 309, 311, 588, 2252, 281, 1888, 472, 13, 583, 439, 264, 29621, 286, 51412], "temperature": 0.0, "avg_logprob": -0.10890568003934972, "compression_ratio": 1.5628415300546448, "no_speech_prob": 0.005542255938053131}, {"id": 846, "seek": 622372, "start": 6223.72, "end": 6233.320000000001, "text": " mentioned, and others as well, are very open to process research. Yeah, you might if I mentioned", "tokens": [50364, 2835, 11, 293, 2357, 382, 731, 11, 366, 588, 1269, 281, 1399, 2132, 13, 865, 11, 291, 1062, 498, 286, 2835, 50844], "temperature": 0.0, "avg_logprob": -0.19977764785289764, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.0013865538639947772}, {"id": 847, "seek": 622372, "start": 6233.320000000001, "end": 6239.16, "text": " some that probably less so, I mean, in general applied psychology might not be so open to it,", "tokens": [50844, 512, 300, 1391, 1570, 370, 11, 286, 914, 11, 294, 2674, 6456, 15105, 1062, 406, 312, 370, 1269, 281, 309, 11, 51136], "temperature": 0.0, "avg_logprob": -0.19977764785289764, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.0013865538639947772}, {"id": 848, "seek": 622372, "start": 6239.16, "end": 6247.16, "text": " I don't know. Yeah. Some I interrupted somebody, Patrick.", "tokens": [51136, 286, 500, 380, 458, 13, 865, 13, 2188, 286, 30329, 2618, 11, 13980, 13, 51536], "temperature": 0.0, "avg_logprob": -0.19977764785289764, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.0013865538639947772}, {"id": 849, "seek": 624716, "start": 6247.16, "end": 6256.28, "text": " Yeah. Thank you very much for your very, very brilliant presentation. I have a pretty basic", "tokens": [50364, 865, 13, 1044, 291, 588, 709, 337, 428, 588, 11, 588, 10248, 5860, 13, 286, 362, 257, 1238, 3875, 50820], "temperature": 0.0, "avg_logprob": -0.19574136936918218, "compression_ratio": 1.4029850746268657, "no_speech_prob": 0.002068654401227832}, {"id": 850, "seek": 624716, "start": 6256.28, "end": 6265.32, "text": " question that has been very, very confusing for me, which is, how do you do process to arrive in", "tokens": [50820, 1168, 300, 575, 668, 588, 11, 588, 13181, 337, 385, 11, 597, 307, 11, 577, 360, 291, 360, 1399, 281, 8881, 294, 51272], "temperature": 0.0, "avg_logprob": -0.19574136936918218, "compression_ratio": 1.4029850746268657, "no_speech_prob": 0.002068654401227832}, {"id": 851, "seek": 626532, "start": 6265.32, "end": 6276.759999999999, "text": " from a one of interview, where the respondent is talking about how they make decisions within", "tokens": [50364, 490, 257, 472, 295, 4049, 11, 689, 264, 4196, 317, 307, 1417, 466, 577, 436, 652, 5327, 1951, 50936], "temperature": 0.0, "avg_logprob": -0.15955777601762253, "compression_ratio": 1.608187134502924, "no_speech_prob": 0.038634028285741806}, {"id": 852, "seek": 626532, "start": 6276.759999999999, "end": 6284.36, "text": " the organization. Clearly, this person is talking about a process, right, and how they", "tokens": [50936, 264, 4475, 13, 24120, 11, 341, 954, 307, 1417, 466, 257, 1399, 11, 558, 11, 293, 577, 436, 51316], "temperature": 0.0, "avg_logprob": -0.15955777601762253, "compression_ratio": 1.608187134502924, "no_speech_prob": 0.038634028285741806}, {"id": 853, "seek": 626532, "start": 6284.36, "end": 6292.5199999999995, "text": " finally arrive at a conclusive decision. But this is a one of kind of interview. So how do you", "tokens": [51316, 2721, 8881, 412, 257, 1588, 7233, 3537, 13, 583, 341, 307, 257, 472, 295, 733, 295, 4049, 13, 407, 577, 360, 291, 51724], "temperature": 0.0, "avg_logprob": -0.15955777601762253, "compression_ratio": 1.608187134502924, "no_speech_prob": 0.038634028285741806}, {"id": 854, "seek": 629252, "start": 6292.76, "end": 6299.96, "text": " do process to arrive in from such a data? Well, I don't think you can. I mean, because you only", "tokens": [50376, 360, 1399, 281, 8881, 294, 490, 1270, 257, 1412, 30, 1042, 11, 286, 500, 380, 519, 291, 393, 13, 286, 914, 11, 570, 291, 787, 50736], "temperature": 0.0, "avg_logprob": -0.18263292984223703, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0016710240161046386}, {"id": 855, "seek": 629252, "start": 6299.96, "end": 6307.8, "text": " have one person, but you can you can represent that person's theory of decision making.", "tokens": [50736, 362, 472, 954, 11, 457, 291, 393, 291, 393, 2906, 300, 954, 311, 5261, 295, 3537, 1455, 13, 51128], "temperature": 0.0, "avg_logprob": -0.18263292984223703, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0016710240161046386}, {"id": 856, "seek": 629252, "start": 6309.240000000001, "end": 6315.400000000001, "text": " So so you could. And if you have several different people, you can look at their theories of", "tokens": [51200, 407, 370, 291, 727, 13, 400, 498, 291, 362, 2940, 819, 561, 11, 291, 393, 574, 412, 641, 13667, 295, 51508], "temperature": 0.0, "avg_logprob": -0.18263292984223703, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0016710240161046386}, {"id": 857, "seek": 631540, "start": 6315.48, "end": 6322.759999999999, "text": " decision making so that that they are they are suggesting the stages that you go through and", "tokens": [50368, 3537, 1455, 370, 300, 300, 436, 366, 436, 366, 18094, 264, 10232, 300, 291, 352, 807, 293, 50732], "temperature": 0.0, "avg_logprob": -0.19219505603496845, "compression_ratio": 1.6219512195121952, "no_speech_prob": 0.004827967844903469}, {"id": 858, "seek": 631540, "start": 6322.759999999999, "end": 6328.2, "text": " things like that. What I think, you know, when you're looking at an interview,", "tokens": [50732, 721, 411, 300, 13, 708, 286, 519, 11, 291, 458, 11, 562, 291, 434, 1237, 412, 364, 4049, 11, 51004], "temperature": 0.0, "avg_logprob": -0.19219505603496845, "compression_ratio": 1.6219512195121952, "no_speech_prob": 0.004827967844903469}, {"id": 859, "seek": 631540, "start": 6329.5599999999995, "end": 6341.24, "text": " is that there are two ways to develop theory from an interview friend, kind of data. One is to", "tokens": [51072, 307, 300, 456, 366, 732, 2098, 281, 1499, 5261, 490, 364, 4049, 1277, 11, 733, 295, 1412, 13, 1485, 307, 281, 51656], "temperature": 0.0, "avg_logprob": -0.19219505603496845, "compression_ratio": 1.6219512195121952, "no_speech_prob": 0.004827967844903469}, {"id": 860, "seek": 634124, "start": 6341.88, "end": 6348.92, "text": " take the generalizations that the person is telling you. So let's say the person says, oh,", "tokens": [50396, 747, 264, 2674, 14455, 300, 264, 954, 307, 3585, 291, 13, 407, 718, 311, 584, 264, 954, 1619, 11, 1954, 11, 50748], "temperature": 0.0, "avg_logprob": -0.24465711351851344, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.001048055593855679}, {"id": 861, "seek": 634124, "start": 6349.88, "end": 6357.719999999999, "text": " we always make decisions in. We have a committee, and we make the decisions in the committee.", "tokens": [50796, 321, 1009, 652, 5327, 294, 13, 492, 362, 257, 7482, 11, 293, 321, 652, 264, 5327, 294, 264, 7482, 13, 51188], "temperature": 0.0, "avg_logprob": -0.24465711351851344, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.001048055593855679}, {"id": 862, "seek": 634124, "start": 6358.599999999999, "end": 6364.44, "text": " Okay, so you could read that and think, okay, they make decisions in the committee. So I'm", "tokens": [51232, 1033, 11, 370, 291, 727, 1401, 300, 293, 519, 11, 1392, 11, 436, 652, 5327, 294, 264, 7482, 13, 407, 286, 478, 51524], "temperature": 0.0, "avg_logprob": -0.24465711351851344, "compression_ratio": 1.7080745341614907, "no_speech_prob": 0.001048055593855679}, {"id": 863, "seek": 636444, "start": 6365.24, "end": 6370.679999999999, "text": " generalizing from the generalization of the. Responder.", "tokens": [50404, 2674, 3319, 490, 264, 2674, 2144, 295, 264, 13, 22480, 8548, 13, 50676], "temperature": 0.0, "avg_logprob": -0.16313824096283355, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.004464816302061081}, {"id": 864, "seek": 636444, "start": 6372.759999999999, "end": 6379.24, "text": " Or instead of doing that, and I think that this is much better, is that you have the", "tokens": [50780, 1610, 2602, 295, 884, 300, 11, 293, 286, 519, 300, 341, 307, 709, 1101, 11, 307, 300, 291, 362, 264, 51104], "temperature": 0.0, "avg_logprob": -0.16313824096283355, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.004464816302061081}, {"id": 865, "seek": 636444, "start": 6379.24, "end": 6387.48, "text": " accounts of that individual of several specific decisions. So this happened, this happened,", "tokens": [51104, 9402, 295, 300, 2609, 295, 2940, 2685, 5327, 13, 407, 341, 2011, 11, 341, 2011, 11, 51516], "temperature": 0.0, "avg_logprob": -0.16313824096283355, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.004464816302061081}, {"id": 866, "seek": 636444, "start": 6387.48, "end": 6392.28, "text": " this happened, this happened, this happened. The second decision, this happened, this happened,", "tokens": [51516, 341, 2011, 11, 341, 2011, 11, 341, 2011, 13, 440, 1150, 3537, 11, 341, 2011, 11, 341, 2011, 11, 51756], "temperature": 0.0, "avg_logprob": -0.16313824096283355, "compression_ratio": 1.9523809523809523, "no_speech_prob": 0.004464816302061081}, {"id": 867, "seek": 639228, "start": 6392.28, "end": 6396.36, "text": " this happened, this happened, this happened, this third decision, this get them to talk about", "tokens": [50364, 341, 2011, 11, 341, 2011, 11, 341, 2011, 11, 341, 2636, 3537, 11, 341, 483, 552, 281, 751, 466, 50568], "temperature": 0.0, "avg_logprob": -0.171583741575807, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0017813697922974825}, {"id": 868, "seek": 639228, "start": 6396.36, "end": 6404.679999999999, "text": " lots of different decisions. Then real months, concrete months, then you generalize from their", "tokens": [50568, 3195, 295, 819, 5327, 13, 1396, 957, 2493, 11, 9859, 2493, 11, 550, 291, 2674, 1125, 490, 641, 50984], "temperature": 0.0, "avg_logprob": -0.171583741575807, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0017813697922974825}, {"id": 869, "seek": 639228, "start": 6404.679999999999, "end": 6411.96, "text": " stories, not from their generalization. See what I mean? It makes a huge difference. So if you,", "tokens": [50984, 3676, 11, 406, 490, 641, 2674, 2144, 13, 3008, 437, 286, 914, 30, 467, 1669, 257, 2603, 2649, 13, 407, 498, 291, 11, 51348], "temperature": 0.0, "avg_logprob": -0.171583741575807, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0017813697922974825}, {"id": 870, "seek": 639228, "start": 6412.599999999999, "end": 6422.2, "text": " if you're talking, if you're using an interview, get the stories. And sometimes you do generalize", "tokens": [51380, 498, 291, 434, 1417, 11, 498, 291, 434, 1228, 364, 4049, 11, 483, 264, 3676, 13, 400, 2171, 291, 360, 2674, 1125, 51860], "temperature": 0.0, "avg_logprob": -0.171583741575807, "compression_ratio": 1.854368932038835, "no_speech_prob": 0.0017813697922974825}, {"id": 871, "seek": 642228, "start": 6422.5199999999995, "end": 6429.08, "text": " from other people's generalizations, but it's much better to get, get as close as you possibly can", "tokens": [50376, 490, 661, 561, 311, 2674, 14455, 11, 457, 309, 311, 709, 1101, 281, 483, 11, 483, 382, 1998, 382, 291, 6264, 393, 50704], "temperature": 0.0, "avg_logprob": -0.14725042978922526, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.002315729856491089}, {"id": 872, "seek": 642228, "start": 6429.719999999999, "end": 6437.719999999999, "text": " to the actual events and the accounts of the actual events. And you're getting deeper when", "tokens": [50736, 281, 264, 3539, 3931, 293, 264, 9402, 295, 264, 3539, 3931, 13, 400, 291, 434, 1242, 7731, 562, 51136], "temperature": 0.0, "avg_logprob": -0.14725042978922526, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.002315729856491089}, {"id": 873, "seek": 642228, "start": 6437.719999999999, "end": 6444.44, "text": " you're doing that. I don't know if that's, that's helpful. Thank you very much. That was very, very", "tokens": [51136, 291, 434, 884, 300, 13, 286, 500, 380, 458, 498, 300, 311, 11, 300, 311, 4961, 13, 1044, 291, 588, 709, 13, 663, 390, 588, 11, 588, 51472], "temperature": 0.0, "avg_logprob": -0.14725042978922526, "compression_ratio": 1.5706521739130435, "no_speech_prob": 0.002315729856491089}, {"id": 874, "seek": 644444, "start": 6444.5199999999995, "end": 6453.5599999999995, "text": " helpful. So how are we doing? Anyone?", "tokens": [50368, 4961, 13, 407, 577, 366, 321, 884, 30, 14643, 30, 50820], "temperature": 0.0, "avg_logprob": -0.3444829305013021, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.00998523086309433}, {"id": 875, "seek": 644444, "start": 6460.919999999999, "end": 6463.879999999999, "text": " I'm just looking, is there something in the chat which I should respond to?", "tokens": [51188, 286, 478, 445, 1237, 11, 307, 456, 746, 294, 264, 5081, 597, 286, 820, 4196, 281, 30, 51336], "temperature": 0.0, "avg_logprob": -0.3444829305013021, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.00998523086309433}, {"id": 876, "seek": 644444, "start": 6465.5599999999995, "end": 6470.599999999999, "text": " Underworld questions. Isidora. I'm not sure we'll have time for that. Yeah, Isidora.", "tokens": [51420, 6974, 13217, 1651, 13, 1119, 327, 3252, 13, 286, 478, 406, 988, 321, 603, 362, 565, 337, 300, 13, 865, 11, 1119, 327, 3252, 13, 51672], "temperature": 0.0, "avg_logprob": -0.3444829305013021, "compression_ratio": 1.3288590604026846, "no_speech_prob": 0.00998523086309433}, {"id": 877, "seek": 647060, "start": 6471.56, "end": 6479.08, "text": " Hi. Thank you for a great presentation today. I believe this is a very broad question, but if", "tokens": [50412, 2421, 13, 1044, 291, 337, 257, 869, 5860, 965, 13, 286, 1697, 341, 307, 257, 588, 4152, 1168, 11, 457, 498, 50788], "temperature": 0.0, "avg_logprob": -0.11392286922154801, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005128657445311546}, {"id": 878, "seek": 647060, "start": 6479.08, "end": 6485.240000000001, "text": " you can just give us sort of just your general opinion, I'm really interested about quantification", "tokens": [50788, 291, 393, 445, 976, 505, 1333, 295, 445, 428, 2674, 4800, 11, 286, 478, 534, 3102, 466, 4426, 3774, 51096], "temperature": 0.0, "avg_logprob": -0.11392286922154801, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005128657445311546}, {"id": 879, "seek": 647060, "start": 6485.240000000001, "end": 6492.360000000001, "text": " of qualitative data. I have thought about it in one of my previous research, but I opted against", "tokens": [51096, 295, 31312, 1412, 13, 286, 362, 1194, 466, 309, 294, 472, 295, 452, 3894, 2132, 11, 457, 286, 40768, 1970, 51452], "temperature": 0.0, "avg_logprob": -0.11392286922154801, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005128657445311546}, {"id": 880, "seek": 647060, "start": 6492.360000000001, "end": 6498.4400000000005, "text": " it because of all the division of whether this is a right research strategy. So I just wanted", "tokens": [51452, 309, 570, 295, 439, 264, 10044, 295, 1968, 341, 307, 257, 558, 2132, 5206, 13, 407, 286, 445, 1415, 51756], "temperature": 0.0, "avg_logprob": -0.11392286922154801, "compression_ratio": 1.6367521367521367, "no_speech_prob": 0.005128657445311546}, {"id": 881, "seek": 649844, "start": 6498.44, "end": 6504.44, "text": " to hear your opinion on it and maybe if you can suggest some kind of resource that would be valuable", "tokens": [50364, 281, 1568, 428, 4800, 322, 309, 293, 1310, 498, 291, 393, 3402, 512, 733, 295, 7684, 300, 576, 312, 8263, 50664], "temperature": 0.0, "avg_logprob": -0.0945515125355822, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.001477087032981217}, {"id": 882, "seek": 649844, "start": 6504.44, "end": 6510.839999999999, "text": " in sort of providing a starting point for that. Yeah, so thank you for the question because one", "tokens": [50664, 294, 1333, 295, 6530, 257, 2891, 935, 337, 300, 13, 865, 11, 370, 1309, 291, 337, 264, 1168, 570, 472, 50984], "temperature": 0.0, "avg_logprob": -0.0945515125355822, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.001477087032981217}, {"id": 883, "seek": 649844, "start": 6510.839999999999, "end": 6516.2, "text": " of my strategies was quantification and I didn't talk about it. And I didn't talk about it because", "tokens": [50984, 295, 452, 9029, 390, 4426, 3774, 293, 286, 994, 380, 751, 466, 309, 13, 400, 286, 994, 380, 751, 466, 309, 570, 51252], "temperature": 0.0, "avg_logprob": -0.0945515125355822, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.001477087032981217}, {"id": 884, "seek": 649844, "start": 6516.2, "end": 6524.919999999999, "text": " I'm not particularly fond of it. But I do think quantification can be useful. And when is it", "tokens": [51252, 286, 478, 406, 4098, 9557, 295, 309, 13, 583, 286, 360, 519, 4426, 3774, 393, 312, 4420, 13, 400, 562, 307, 309, 51688], "temperature": 0.0, "avg_logprob": -0.0945515125355822, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.001477087032981217}, {"id": 885, "seek": 652492, "start": 6524.92, "end": 6532.36, "text": " useful? It is useful. It's not useful in the description. It doesn't, it doesn't make any,", "tokens": [50364, 4420, 30, 467, 307, 4420, 13, 467, 311, 406, 4420, 294, 264, 3855, 13, 467, 1177, 380, 11, 309, 1177, 380, 652, 604, 11, 50736], "temperature": 0.0, "avg_logprob": -0.1670061029413695, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.009260868653655052}, {"id": 886, "seek": 652492, "start": 6532.36, "end": 6537.4, "text": " you don't need to count anything if you just want to describe phenomena or or", "tokens": [50736, 291, 500, 380, 643, 281, 1207, 1340, 498, 291, 445, 528, 281, 6786, 22004, 420, 420, 50988], "temperature": 0.0, "avg_logprob": -0.1670061029413695, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.009260868653655052}, {"id": 887, "seek": 652492, "start": 6537.4, "end": 6543.56, "text": " types of events that happen. You don't need it. Where you do need it is where you want to say,", "tokens": [50988, 3467, 295, 3931, 300, 1051, 13, 509, 500, 380, 643, 309, 13, 2305, 291, 360, 643, 309, 307, 689, 291, 528, 281, 584, 11, 51296], "temperature": 0.0, "avg_logprob": -0.1670061029413695, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.009260868653655052}, {"id": 888, "seek": 652492, "start": 6543.56, "end": 6552.4400000000005, "text": " okay, say is more of a success than case B or some kind of way of judging differences", "tokens": [51296, 1392, 11, 584, 307, 544, 295, 257, 2245, 813, 1389, 363, 420, 512, 733, 295, 636, 295, 23587, 7300, 51740], "temperature": 0.0, "avg_logprob": -0.1670061029413695, "compression_ratio": 1.661904761904762, "no_speech_prob": 0.009260868653655052}, {"id": 889, "seek": 655244, "start": 6553.24, "end": 6564.04, "text": " that is along a scale. Then you have to find ways to do it. And so, for example, I recently did a", "tokens": [50404, 300, 307, 2051, 257, 4373, 13, 1396, 291, 362, 281, 915, 2098, 281, 360, 309, 13, 400, 370, 11, 337, 1365, 11, 286, 3938, 630, 257, 50944], "temperature": 0.0, "avg_logprob": -0.12584183432839133, "compression_ratio": 1.3082191780821917, "no_speech_prob": 0.0012053503887727857}, {"id": 890, "seek": 655244, "start": 6564.04, "end": 6573.32, "text": " study with a colleague, which was about, it was an 18 year history. So it's kind of a process", "tokens": [50944, 2979, 365, 257, 13532, 11, 597, 390, 466, 11, 309, 390, 364, 2443, 1064, 2503, 13, 407, 309, 311, 733, 295, 257, 1399, 51408], "temperature": 0.0, "avg_logprob": -0.12584183432839133, "compression_ratio": 1.3082191780821917, "no_speech_prob": 0.0012053503887727857}, {"id": 891, "seek": 657332, "start": 6573.32, "end": 6584.04, "text": " study of how managers cited their founders in their discourse in their communications.", "tokens": [50364, 2979, 295, 577, 14084, 30134, 641, 25608, 294, 641, 23938, 294, 641, 15163, 13, 50900], "temperature": 0.0, "avg_logprob": -0.07502424994180369, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.06266237050294876}, {"id": 892, "seek": 657332, "start": 6584.04, "end": 6590.599999999999, "text": " And we wanted to show that the way they cited them changed over time. And in order to do that,", "tokens": [50900, 400, 321, 1415, 281, 855, 300, 264, 636, 436, 30134, 552, 3105, 670, 565, 13, 400, 294, 1668, 281, 360, 300, 11, 51228], "temperature": 0.0, "avg_logprob": -0.07502424994180369, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.06266237050294876}, {"id": 893, "seek": 657332, "start": 6590.599999999999, "end": 6597.88, "text": " we had to count them. We had to code them into categories and count them to be able to demonstrate", "tokens": [51228, 321, 632, 281, 1207, 552, 13, 492, 632, 281, 3089, 552, 666, 10479, 293, 1207, 552, 281, 312, 1075, 281, 11698, 51592], "temperature": 0.0, "avg_logprob": -0.07502424994180369, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.06266237050294876}, {"id": 894, "seek": 657332, "start": 6597.88, "end": 6601.96, "text": " to the reader that it's actually true that we were saying they were more like this than they", "tokens": [51592, 281, 264, 15149, 300, 309, 311, 767, 2074, 300, 321, 645, 1566, 436, 645, 544, 411, 341, 813, 436, 51796], "temperature": 0.0, "avg_logprob": -0.07502424994180369, "compression_ratio": 1.784688995215311, "no_speech_prob": 0.06266237050294876}, {"id": 895, "seek": 660196, "start": 6601.96, "end": 6610.68, "text": " used to be. And so, counting gets important them. And when you're counting, you know,", "tokens": [50364, 1143, 281, 312, 13, 400, 370, 11, 13251, 2170, 1021, 552, 13, 400, 562, 291, 434, 13251, 11, 291, 458, 11, 50800], "temperature": 0.0, "avg_logprob": -0.15224462747573853, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0007791658863425255}, {"id": 896, "seek": 660196, "start": 6610.68, "end": 6617.56, "text": " enter, rate, or reliability starts to get important because the precision is important.", "tokens": [50800, 3242, 11, 3314, 11, 420, 24550, 3719, 281, 483, 1021, 570, 264, 18356, 307, 1021, 13, 51144], "temperature": 0.0, "avg_logprob": -0.15224462747573853, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0007791658863425255}, {"id": 897, "seek": 660196, "start": 6618.28, "end": 6625.4800000000005, "text": " So then you need to go to resources that can talk to you about, you know, very", "tokens": [51180, 407, 550, 291, 643, 281, 352, 281, 3593, 300, 393, 751, 281, 291, 466, 11, 291, 458, 11, 588, 51540], "temperature": 0.0, "avg_logprob": -0.15224462747573853, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0007791658863425255}, {"id": 898, "seek": 662548, "start": 6626.36, "end": 6633.48, "text": " content analysis type coding where you have categories, and you need to be able to show", "tokens": [50408, 2701, 5215, 2010, 17720, 689, 291, 362, 10479, 11, 293, 291, 643, 281, 312, 1075, 281, 855, 50764], "temperature": 0.0, "avg_logprob": -0.12684670300550863, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.008843776769936085}, {"id": 899, "seek": 662548, "start": 6633.48, "end": 6644.04, "text": " that these categories are reliable, valid, and so on. So I would look, you know, on the, on Google,", "tokens": [50764, 300, 613, 10479, 366, 12924, 11, 7363, 11, 293, 370, 322, 13, 407, 286, 576, 574, 11, 291, 458, 11, 322, 264, 11, 322, 3329, 11, 51292], "temperature": 0.0, "avg_logprob": -0.12684670300550863, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.008843776769936085}, {"id": 900, "seek": 662548, "start": 6644.04, "end": 6650.759999999999, "text": " I would Google content analysis, probably Krippendorf would be a good author for that,", "tokens": [51292, 286, 576, 3329, 2701, 5215, 11, 1391, 591, 470, 427, 521, 28030, 576, 312, 257, 665, 3793, 337, 300, 11, 51628], "temperature": 0.0, "avg_logprob": -0.12684670300550863, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.008843776769936085}, {"id": 901, "seek": 665076, "start": 6651.4800000000005, "end": 6658.6, "text": " talking about how you would take qualitative data and then use it to quantify certain concepts.", "tokens": [50400, 1417, 466, 577, 291, 576, 747, 31312, 1412, 293, 550, 764, 309, 281, 40421, 1629, 10392, 13, 50756], "temperature": 0.0, "avg_logprob": -0.12112145040227079, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.003074607579037547}, {"id": 902, "seek": 665076, "start": 6658.6, "end": 6664.280000000001, "text": " But I wouldn't do it unless you really need that comparison. A is bigger than B.", "tokens": [50756, 583, 286, 2759, 380, 360, 309, 5969, 291, 534, 643, 300, 9660, 13, 316, 307, 3801, 813, 363, 13, 51040], "temperature": 0.0, "avg_logprob": -0.12112145040227079, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.003074607579037547}, {"id": 903, "seek": 665076, "start": 6666.280000000001, "end": 6674.04, "text": " Otherwise, one of the reasons I don't like it is you take out all the ambiguity. You take,", "tokens": [51140, 10328, 11, 472, 295, 264, 4112, 286, 500, 380, 411, 309, 307, 291, 747, 484, 439, 264, 46519, 13, 509, 747, 11, 51528], "temperature": 0.0, "avg_logprob": -0.12112145040227079, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.003074607579037547}, {"id": 904, "seek": 665076, "start": 6674.6, "end": 6680.04, "text": " if you put things into categories and count them, all of the richness of your data kind of", "tokens": [51556, 498, 291, 829, 721, 666, 10479, 293, 1207, 552, 11, 439, 295, 264, 44506, 295, 428, 1412, 733, 295, 51828], "temperature": 0.0, "avg_logprob": -0.12112145040227079, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.003074607579037547}, {"id": 905, "seek": 668004, "start": 6680.04, "end": 6688.2, "text": " disappears. It just has to go because the obligation to be able to find exactly the same", "tokens": [50364, 25527, 13, 467, 445, 575, 281, 352, 570, 264, 20326, 281, 312, 1075, 281, 915, 2293, 264, 912, 50772], "temperature": 0.0, "avg_logprob": -0.06932184555951287, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0006261723465286195}, {"id": 906, "seek": 668004, "start": 6688.2, "end": 6694.76, "text": " number as your colleague means that you have to make things so clear that there is no possible", "tokens": [50772, 1230, 382, 428, 13532, 1355, 300, 291, 362, 281, 652, 721, 370, 1850, 300, 456, 307, 572, 1944, 51100], "temperature": 0.0, "avg_logprob": -0.06932184555951287, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0006261723465286195}, {"id": 907, "seek": 668004, "start": 6694.76, "end": 6700.44, "text": " doubt that you have categorized correctly, which means that all of the ambiguity and fluffiness", "tokens": [51100, 6385, 300, 291, 362, 19250, 1602, 8944, 11, 597, 1355, 300, 439, 295, 264, 46519, 293, 41533, 1324, 51384], "temperature": 0.0, "avg_logprob": -0.06932184555951287, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0006261723465286195}, {"id": 908, "seek": 668004, "start": 6700.44, "end": 6709.48, "text": " and richness goes. And that's not good. Qualitative data is qualitative. It's not quantitative.", "tokens": [51384, 293, 44506, 1709, 13, 400, 300, 311, 406, 665, 13, 13616, 14275, 1412, 307, 31312, 13, 467, 311, 406, 27778, 13, 51836], "temperature": 0.0, "avg_logprob": -0.06932184555951287, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0006261723465286195}, {"id": 909, "seek": 670948, "start": 6709.48, "end": 6716.839999999999, "text": " So it's a good thing if you need to do that comparison. But if you don't, don't do it,", "tokens": [50364, 407, 309, 311, 257, 665, 551, 498, 291, 643, 281, 360, 300, 9660, 13, 583, 498, 291, 500, 380, 11, 500, 380, 360, 309, 11, 50732], "temperature": 0.0, "avg_logprob": -0.1795848767781995, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0004227470199111849}, {"id": 910, "seek": 670948, "start": 6716.839999999999, "end": 6724.04, "text": " just to do it. It's not worth it. Okay. Yeah, thank you so much. Yeah, I think I", "tokens": [50732, 445, 281, 360, 309, 13, 467, 311, 406, 3163, 309, 13, 1033, 13, 865, 11, 1309, 291, 370, 709, 13, 865, 11, 286, 519, 286, 51092], "temperature": 0.0, "avg_logprob": -0.1795848767781995, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0004227470199111849}, {"id": 911, "seek": 670948, "start": 6724.04, "end": 6731.0, "text": " should have decided against it simply because the essence and the nuance within each of the,", "tokens": [51092, 820, 362, 3047, 1970, 309, 2935, 570, 264, 12801, 293, 264, 42625, 1951, 1184, 295, 264, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1795848767781995, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0004227470199111849}, {"id": 912, "seek": 670948, "start": 6731.0, "end": 6736.04, "text": " you know, qualitative aspects sort of gets lost. But I still think that it might have been an", "tokens": [51440, 291, 458, 11, 31312, 7270, 1333, 295, 2170, 2731, 13, 583, 286, 920, 519, 300, 309, 1062, 362, 668, 364, 51692], "temperature": 0.0, "avg_logprob": -0.1795848767781995, "compression_ratio": 1.5945945945945945, "no_speech_prob": 0.0004227470199111849}, {"id": 913, "seek": 673604, "start": 6736.04, "end": 6743.56, "text": " interesting strategy to show intensity of a certain outcome. Exactly. That's what I think.", "tokens": [50364, 1880, 5206, 281, 855, 13749, 295, 257, 1629, 9700, 13, 7587, 13, 663, 311, 437, 286, 519, 13, 50740], "temperature": 0.0, "avg_logprob": -0.14385888817605008, "compression_ratio": 1.5119047619047619, "no_speech_prob": 0.0025891719851642847}, {"id": 914, "seek": 673604, "start": 6744.36, "end": 6749.72, "text": " One person who does it very well and still keeps the richness is Stephen Barley. So if you look", "tokens": [50780, 1485, 954, 567, 775, 309, 588, 731, 293, 920, 5965, 264, 44506, 307, 13391, 4156, 3420, 13, 407, 498, 291, 574, 51048], "temperature": 0.0, "avg_logprob": -0.14385888817605008, "compression_ratio": 1.5119047619047619, "no_speech_prob": 0.0025891719851642847}, {"id": 915, "seek": 673604, "start": 6749.72, "end": 6755.08, "text": " at many of Stephen Barley's papers, he's real. He's a fantastic qualitative researcher, but he", "tokens": [51048, 412, 867, 295, 13391, 4156, 3420, 311, 10577, 11, 415, 311, 957, 13, 634, 311, 257, 5456, 31312, 21751, 11, 457, 415, 51316], "temperature": 0.0, "avg_logprob": -0.14385888817605008, "compression_ratio": 1.5119047619047619, "no_speech_prob": 0.0025891719851642847}, {"id": 916, "seek": 673604, "start": 6755.08, "end": 6764.28, "text": " also counts things. And as a great paper recently in Academy of Management Discoveries about buying", "tokens": [51316, 611, 14893, 721, 13, 400, 382, 257, 869, 3035, 3938, 294, 11735, 295, 14781, 40386, 530, 466, 6382, 51776], "temperature": 0.0, "avg_logprob": -0.14385888817605008, "compression_ratio": 1.5119047619047619, "no_speech_prob": 0.0025891719851642847}, {"id": 917, "seek": 676428, "start": 6764.28, "end": 6774.2, "text": " cars. But he does a lot of qualitative analysis, but also does counts. So that might be a good example.", "tokens": [50364, 5163, 13, 583, 415, 775, 257, 688, 295, 31312, 5215, 11, 457, 611, 775, 14893, 13, 407, 300, 1062, 312, 257, 665, 1365, 13, 50860], "temperature": 0.0, "avg_logprob": -0.16211509704589844, "compression_ratio": 1.460122699386503, "no_speech_prob": 0.0016172737814486027}, {"id": 918, "seek": 676428, "start": 6775.4, "end": 6778.44, "text": " Okay. Thank you so much. Burak.", "tokens": [50920, 1033, 13, 1044, 291, 370, 709, 13, 7031, 514, 13, 51072], "temperature": 0.0, "avg_logprob": -0.16211509704589844, "compression_ratio": 1.460122699386503, "no_speech_prob": 0.0016172737814486027}, {"id": 919, "seek": 676428, "start": 6781.719999999999, "end": 6788.599999999999, "text": " Thank you very much. I have a brief question. It's about the lens. You mentioned about the theoretical", "tokens": [51236, 1044, 291, 588, 709, 13, 286, 362, 257, 5353, 1168, 13, 467, 311, 466, 264, 6765, 13, 509, 2835, 466, 264, 20864, 51580], "temperature": 0.0, "avg_logprob": -0.16211509704589844, "compression_ratio": 1.460122699386503, "no_speech_prob": 0.0016172737814486027}, {"id": 920, "seek": 678860, "start": 6788.6, "end": 6795.56, "text": " lens. How about the paradigm as the lens? And combined with the theoretical lens, would you", "tokens": [50364, 6765, 13, 1012, 466, 264, 24709, 382, 264, 6765, 30, 400, 9354, 365, 264, 20864, 6765, 11, 576, 291, 50712], "temperature": 0.0, "avg_logprob": -0.10859445482492447, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.0010479734046384692}, {"id": 921, "seek": 678860, "start": 6795.56, "end": 6804.92, "text": " please elaborate differences and similarities? How do we use them? Thank you. So you're referring", "tokens": [50712, 1767, 20945, 7300, 293, 24197, 30, 1012, 360, 321, 764, 552, 30, 1044, 291, 13, 407, 291, 434, 13761, 51180], "temperature": 0.0, "avg_logprob": -0.10859445482492447, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.0010479734046384692}, {"id": 922, "seek": 678860, "start": 6804.92, "end": 6812.68, "text": " to whether you're having a critical paradigm or you're adopting a interpretive paradigm or a", "tokens": [51180, 281, 1968, 291, 434, 1419, 257, 4924, 24709, 420, 291, 434, 32328, 257, 7302, 488, 24709, 420, 257, 51568], "temperature": 0.0, "avg_logprob": -0.10859445482492447, "compression_ratio": 1.558011049723757, "no_speech_prob": 0.0010479734046384692}, {"id": 923, "seek": 681268, "start": 6812.68, "end": 6823.400000000001, "text": " positivist paradigm. Yeah. So I'm agnostic as to which one you might want to adopt. And it's also", "tokens": [50364, 40806, 468, 24709, 13, 865, 13, 407, 286, 478, 623, 77, 19634, 382, 281, 597, 472, 291, 1062, 528, 281, 6878, 13, 400, 309, 311, 611, 50900], "temperature": 0.0, "avg_logprob": -0.08278371012488077, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.0035358781460672617}, {"id": 924, "seek": 681268, "start": 6823.400000000001, "end": 6829.8, "text": " possible to play with them. So you can pretend, you know, you can say, okay, today I'm a positivist.", "tokens": [50900, 1944, 281, 862, 365, 552, 13, 407, 291, 393, 11865, 11, 291, 458, 11, 291, 393, 584, 11, 1392, 11, 965, 286, 478, 257, 40806, 468, 13, 51220], "temperature": 0.0, "avg_logprob": -0.08278371012488077, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.0035358781460672617}, {"id": 925, "seek": 681268, "start": 6829.8, "end": 6836.280000000001, "text": " If I were a positivist, how would I consider these data? Now I'm a critical theorist. How would I", "tokens": [51220, 759, 286, 645, 257, 40806, 468, 11, 577, 576, 286, 1949, 613, 1412, 30, 823, 286, 478, 257, 4924, 27423, 468, 13, 1012, 576, 286, 51544], "temperature": 0.0, "avg_logprob": -0.08278371012488077, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.0035358781460672617}, {"id": 926, "seek": 683628, "start": 6836.28, "end": 6845.48, "text": " consider those data? So you can do that. And it certainly would help you see, it would get you", "tokens": [50364, 1949, 729, 1412, 30, 407, 291, 393, 360, 300, 13, 400, 309, 3297, 576, 854, 291, 536, 11, 309, 576, 483, 291, 50824], "temperature": 0.0, "avg_logprob": -0.10627890888013337, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.01716425269842148}, {"id": 927, "seek": 683628, "start": 6845.48, "end": 6852.36, "text": " to ask different questions about the data. So if you're a positivist, you're going to be asking,", "tokens": [50824, 281, 1029, 819, 1651, 466, 264, 1412, 13, 407, 498, 291, 434, 257, 40806, 468, 11, 291, 434, 516, 281, 312, 3365, 11, 51168], "temperature": 0.0, "avg_logprob": -0.10627890888013337, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.01716425269842148}, {"id": 928, "seek": 683628, "start": 6852.36, "end": 6863.16, "text": " what is the truth? Right. And if you're an interpretive, it's how are people seeing things.", "tokens": [51168, 437, 307, 264, 3494, 30, 1779, 13, 400, 498, 291, 434, 364, 7302, 488, 11, 309, 311, 577, 366, 561, 2577, 721, 13, 51708], "temperature": 0.0, "avg_logprob": -0.10627890888013337, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.01716425269842148}, {"id": 929, "seek": 686316, "start": 6863.16, "end": 6867.8, "text": " And if you're a critical theorist, you would ask yourself, well, who is winning and who is losing", "tokens": [50364, 400, 498, 291, 434, 257, 4924, 27423, 468, 11, 291, 576, 1029, 1803, 11, 731, 11, 567, 307, 8224, 293, 567, 307, 7027, 50596], "temperature": 0.0, "avg_logprob": -0.09029910961786906, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0008419294026680291}, {"id": 930, "seek": 686316, "start": 6867.8, "end": 6877.4, "text": " in this? And so you ask yourself different questions. And I think that's hard to do within a", "tokens": [50596, 294, 341, 30, 400, 370, 291, 1029, 1803, 819, 1651, 13, 400, 286, 519, 300, 311, 1152, 281, 360, 1951, 257, 51076], "temperature": 0.0, "avg_logprob": -0.09029910961786906, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0008419294026680291}, {"id": 931, "seek": 686316, "start": 6877.4, "end": 6884.44, "text": " single paper, but it could be something that you could try and, you know, sort of play around", "tokens": [51076, 2167, 3035, 11, 457, 309, 727, 312, 746, 300, 291, 727, 853, 293, 11, 291, 458, 11, 1333, 295, 862, 926, 51428], "temperature": 0.0, "avg_logprob": -0.09029910961786906, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0008419294026680291}, {"id": 932, "seek": 686316, "start": 6885.8, "end": 6892.5199999999995, "text": " with those approaches. I mean, you can do the same thing with an interview. Take an interview.", "tokens": [51496, 365, 729, 11587, 13, 286, 914, 11, 291, 393, 360, 264, 912, 551, 365, 364, 4049, 13, 3664, 364, 4049, 13, 51832], "temperature": 0.0, "avg_logprob": -0.09029910961786906, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.0008419294026680291}, {"id": 933, "seek": 689252, "start": 6892.6, "end": 6902.4400000000005, "text": " Look at the interview. What if this was true? The person is telling me. And how can I know", "tokens": [50368, 2053, 412, 264, 4049, 13, 708, 498, 341, 390, 2074, 30, 440, 954, 307, 3585, 385, 13, 400, 577, 393, 286, 458, 50860], "temperature": 0.0, "avg_logprob": -0.11048969268798828, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.00034583438537083566}, {"id": 934, "seek": 689252, "start": 6902.4400000000005, "end": 6908.040000000001, "text": " that it's true? And if you're looking at an interview positivistically, you will say, well,", "tokens": [50860, 300, 309, 311, 2074, 30, 400, 498, 291, 434, 1237, 412, 364, 4049, 40806, 20458, 11, 291, 486, 584, 11, 731, 11, 51140], "temperature": 0.0, "avg_logprob": -0.11048969268798828, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.00034583438537083566}, {"id": 935, "seek": 689252, "start": 6908.040000000001, "end": 6915.160000000001, "text": " only the things that are about verifiable facts, I know are to be true. And in order to find out", "tokens": [51140, 787, 264, 721, 300, 366, 466, 1306, 30876, 9130, 11, 286, 458, 366, 281, 312, 2074, 13, 400, 294, 1668, 281, 915, 484, 51496], "temperature": 0.0, "avg_logprob": -0.11048969268798828, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.00034583438537083566}, {"id": 936, "seek": 689252, "start": 6915.160000000001, "end": 6921.72, "text": " whether it's true, I will need to find someone else's view or I will need to get other data.", "tokens": [51496, 1968, 309, 311, 2074, 11, 286, 486, 643, 281, 915, 1580, 1646, 311, 1910, 420, 286, 486, 643, 281, 483, 661, 1412, 13, 51824], "temperature": 0.0, "avg_logprob": -0.11048969268798828, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.00034583438537083566}, {"id": 937, "seek": 692172, "start": 6922.280000000001, "end": 6930.280000000001, "text": " If you look at an interview interpretively, you would think, well, no, I don't really need anybody", "tokens": [50392, 759, 291, 574, 412, 364, 4049, 7302, 3413, 11, 291, 576, 519, 11, 731, 11, 572, 11, 286, 500, 380, 534, 643, 4472, 50792], "temperature": 0.0, "avg_logprob": -0.1203324368125514, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008422677055932581}, {"id": 938, "seek": 692172, "start": 6930.280000000001, "end": 6934.280000000001, "text": " else's opinion, because I'm only interested in their interpretation. And I'm not trying to do", "tokens": [50792, 1646, 311, 4800, 11, 570, 286, 478, 787, 3102, 294, 641, 14174, 13, 400, 286, 478, 406, 1382, 281, 360, 50992], "temperature": 0.0, "avg_logprob": -0.1203324368125514, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008422677055932581}, {"id": 939, "seek": 692172, "start": 6934.280000000001, "end": 6941.72, "text": " anything wrong. And if you were to look at it critically, yeah, if you were looking at it", "tokens": [50992, 1340, 2085, 13, 400, 498, 291, 645, 281, 574, 412, 309, 22797, 11, 1338, 11, 498, 291, 645, 1237, 412, 309, 51364], "temperature": 0.0, "avg_logprob": -0.1203324368125514, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008422677055932581}, {"id": 940, "seek": 692172, "start": 6941.72, "end": 6948.280000000001, "text": " critically, you would be very skeptical of what that person is telling you. And you would be asked,", "tokens": [51364, 22797, 11, 291, 576, 312, 588, 28601, 295, 437, 300, 954, 307, 3585, 291, 13, 400, 291, 576, 312, 2351, 11, 51692], "temperature": 0.0, "avg_logprob": -0.1203324368125514, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008422677055932581}, {"id": 941, "seek": 694828, "start": 6948.28, "end": 6952.12, "text": " now, why are they telling me this? What is it they're trying to convince me of?", "tokens": [50364, 586, 11, 983, 366, 436, 3585, 385, 341, 30, 708, 307, 309, 436, 434, 1382, 281, 13447, 385, 295, 30, 50556], "temperature": 0.0, "avg_logprob": -0.15607274450906894, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.000544019159860909}, {"id": 942, "seek": 694828, "start": 6954.28, "end": 6962.679999999999, "text": " That you would look at it in a much more skeptical manner. So just thinking about those", "tokens": [50664, 663, 291, 576, 574, 412, 309, 294, 257, 709, 544, 28601, 9060, 13, 407, 445, 1953, 466, 729, 51084], "temperature": 0.0, "avg_logprob": -0.15607274450906894, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.000544019159860909}, {"id": 943, "seek": 694828, "start": 6962.679999999999, "end": 6966.5199999999995, "text": " things, even on one interview, it can get you to see things different.", "tokens": [51084, 721, 11, 754, 322, 472, 4049, 11, 309, 393, 483, 291, 281, 536, 721, 819, 13, 51276], "temperature": 0.0, "avg_logprob": -0.15607274450906894, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.000544019159860909}, {"id": 944, "seek": 694828, "start": 6968.5199999999995, "end": 6974.84, "text": " See, exactly like the example that you gave about the hospitals merging, like for example,", "tokens": [51376, 3008, 11, 2293, 411, 264, 1365, 300, 291, 2729, 466, 264, 13014, 44559, 11, 411, 337, 1365, 11, 51692], "temperature": 0.0, "avg_logprob": -0.15607274450906894, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.000544019159860909}, {"id": 945, "seek": 697484, "start": 6974.84, "end": 6981.16, "text": " in this case, we can try to understand the phenomena of decision making from, you know,", "tokens": [50364, 294, 341, 1389, 11, 321, 393, 853, 281, 1223, 264, 22004, 295, 3537, 1455, 490, 11, 291, 458, 11, 50680], "temperature": 0.0, "avg_logprob": -0.12034776734142769, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0006983162020333111}, {"id": 946, "seek": 697484, "start": 6981.88, "end": 6987.64, "text": " generative constructionist perspective. But also we can look at it from a conflict paradigm,", "tokens": [50716, 1337, 1166, 6435, 468, 4585, 13, 583, 611, 321, 393, 574, 412, 309, 490, 257, 6596, 24709, 11, 51004], "temperature": 0.0, "avg_logprob": -0.12034776734142769, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0006983162020333111}, {"id": 947, "seek": 697484, "start": 6987.64, "end": 6993.4800000000005, "text": " meaning that decisions are going to create conflicts. So in this case, our theoretical lens", "tokens": [51004, 3620, 300, 5327, 366, 516, 281, 1884, 19807, 13, 407, 294, 341, 1389, 11, 527, 20864, 6765, 51296], "temperature": 0.0, "avg_logprob": -0.12034776734142769, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0006983162020333111}, {"id": 948, "seek": 697484, "start": 6994.12, "end": 7002.52, "text": " would be different, depending on the paradigm. Yeah, indeed. Yes. I agree.", "tokens": [51328, 576, 312, 819, 11, 5413, 322, 264, 24709, 13, 865, 11, 6451, 13, 1079, 13, 286, 3986, 13, 51748], "temperature": 0.0, "avg_logprob": -0.12034776734142769, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0006983162020333111}, {"id": 949, "seek": 700252, "start": 7002.52, "end": 7012.200000000001, "text": " Thank you. Thank you. Thank you.", "tokens": [50400, 1044, 291, 13, 1044, 291, 13, 1044, 291, 13, 50848], "temperature": 0.0, "avg_logprob": -0.4590679407119751, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.00895695760846138}], "language": "en"}