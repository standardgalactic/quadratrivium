WEBVTT

00:00.000 --> 00:09.280
So, to get us started and to make sure that everyone is reasonably on the same page, what

00:09.280 --> 00:12.560
is the process for that?

00:12.560 --> 00:21.600
So, here are some definitions that come from an article that I did with Clive Smallman,

00:21.600 --> 00:25.400
Harry Tsoukas and Yvonne Devane in 2013.

00:25.480 --> 00:32.920
So, process thinking implies considering phenomena as in motion, as unfolding over time as becoming,

00:32.920 --> 00:39.880
and process researchers seek to understand and explain the world in terms of activity,

00:40.520 --> 00:42.520
temporality, and flow.

00:42.520 --> 00:44.840
So, basically, we're looking at things moving.

00:46.760 --> 00:53.240
And I have two images that would reflect what I've just said here.

00:53.960 --> 01:00.520
They have slightly different foci in terms of what we mean by process.

01:00.520 --> 01:02.520
And I'm just going to show the two images.

01:03.080 --> 01:08.760
And what I'm going to talk about today really kind of applies, I think, to both of them.

01:08.760 --> 01:14.760
So, the first image is this idea of process as evolving over time.

01:14.760 --> 01:21.560
So, you have a phenomenon in one state, and you're interested in looking at how that phenomenon

01:22.280 --> 01:26.600
evolves through events, activities, and choices.

01:26.600 --> 01:33.320
And if you are adopting a process perspective, you're going to be focusing on those events,

01:33.320 --> 01:41.800
activities, and choices as your data and the elements of your theory.

01:41.800 --> 01:48.280
So, not talking about dependent variables and independent variables, we're talking about

01:48.280 --> 01:51.720
things that happen, which are quite different.

01:53.160 --> 01:54.680
So, that's the first image.

01:55.480 --> 02:04.760
The second image, which is now on the screen, is this idea of process as activity and flow.

02:04.760 --> 02:11.400
In other words, this process as all there is, everything is made up of processes.

02:11.400 --> 02:17.560
So, this is a second image of process, and some people call this a strong process approach.

02:18.520 --> 02:24.600
And I really like this quote from Russia, 1996, which kind of reflects this.

02:24.600 --> 02:28.280
So, the river is not an object, but an ever-changing flow.

02:29.320 --> 02:31.880
Things are made up of processes.

02:32.520 --> 02:35.160
The sun is not a thing, but a flaming fire.

02:35.160 --> 02:38.440
Everything in nature is a matter of process.

02:38.440 --> 02:47.880
So, this second image really looks at phenomena as processes,

02:47.880 --> 02:49.480
rather than looking at phenomena.

02:49.480 --> 02:50.520
It's changing over time.

02:50.520 --> 02:52.840
So, these are two different ways of looking at process.

02:54.120 --> 02:55.320
That's just the backdrop.

02:56.840 --> 03:03.640
I'm now going to look at the implications of this for methodology.

03:04.200 --> 03:11.240
So, if you are taking a process perspective, you want to capture that activity and flow.

03:12.040 --> 03:17.560
And so, you're going to collect data, and what are your data going to look like?

03:17.880 --> 03:26.840
Well, typically, process data involves at least three different kinds of things.

03:26.840 --> 03:32.840
So, the first kind of thing that you might collect is observations in vivo.

03:33.480 --> 03:36.280
So, you are looking at things in real time.

03:36.280 --> 03:41.240
You might be going to meetings, capturing conversations, capturing events,

03:41.240 --> 03:43.800
shadowing people in the things that they do.

03:44.360 --> 03:48.760
And so, part of your data is likely to be observations.

03:49.880 --> 03:58.520
A second way of collecting process data is to build on people's memories and interpretations.

03:59.160 --> 04:04.360
And you do this through interviews, diaries, focus groups, questionnaires,

04:04.360 --> 04:09.800
all kinds of ways of getting at how people understand what is happening,

04:09.800 --> 04:13.160
what has happened, and how that evolves over time.

04:14.600 --> 04:19.720
And the third way is to look for artifacts.

04:19.720 --> 04:26.040
So, artifacts that were created at moments in time that we can actually timestamp

04:26.040 --> 04:28.120
so that we know when they happened.

04:28.120 --> 04:35.720
So, things like minutes of meetings, or recently we've been using emails, reports.

04:37.160 --> 04:42.360
So, all of these sources of data, and this presentation is not about data,

04:42.440 --> 04:44.680
so we're not going to spend a lot of time on this.

04:44.680 --> 04:47.640
But all of these sources of data are complementary.

04:47.640 --> 04:52.040
They provide different strengths and weaknesses.

04:52.040 --> 04:55.400
An interview has problems because of memories.

04:55.400 --> 04:57.400
People don't necessarily remember.

04:57.400 --> 05:02.280
But if you see something, you observe it, then that can compensate for that, and so on.

05:02.280 --> 05:05.400
So, these three, I call them the big three,

05:08.600 --> 05:15.880
sources of data for qualitative research more generally, and for process research more particularly,

05:16.440 --> 05:22.920
we're going to be using them if we want to develop process understandings.

05:24.920 --> 05:29.880
And if you think about it, if you've got all of these three sources of data,

05:30.520 --> 05:35.320
got interviews from all sorts of people, you've got observations from all sorts of events,

05:35.320 --> 05:43.080
you've got documents and emails, what is the result of that?

05:43.080 --> 05:46.040
It's a total mess.

05:47.880 --> 05:50.200
So, and it's shapeless.

05:51.320 --> 05:54.280
You've got all these separate bits and pieces.

05:55.400 --> 05:58.600
So, the question then is, what are we going to do with that?

05:58.600 --> 06:04.760
And so, this is what this webinar is really all about, is what we do then.

06:07.640 --> 06:15.480
And what we would like to do is move from that mess, the cloud of miscellaneous stuff

06:15.480 --> 06:23.320
that we had collected, to something which is understandable, abstract, generalizable,

06:24.200 --> 06:31.480
a theory. Some kind of theorizing is what we seek to do. So, the question is, how do we move

06:31.480 --> 06:36.760
from that mess to something which is much more defined, posimonious, clear, and so on.

06:37.800 --> 06:43.960
So, here's a picture of what we're trying to do. This is our challenge. We have to move from

06:43.960 --> 06:52.040
something on the left, that is concrete, very specific, it's rich and it's messy,

06:54.200 --> 07:03.000
to something on the right, which is abstract and novel. And the process for doing that,

07:03.000 --> 07:09.960
okay, for connecting the concrete, rich and messy, and the abstract and novel,

07:10.920 --> 07:22.040
it has to be credible, right? We have to couple the two, so that a reader of our work, our thesis,

07:22.040 --> 07:29.880
or our article, can actually see how we've done this, that we have started from a mess,

07:31.080 --> 07:38.200
we have ended up with a theory, and that the coupling, the way we have joined the two, is credible.

07:38.520 --> 07:45.320
But creative slightly, because if we're not producing anything new, then why would we

07:45.320 --> 07:53.080
be doing this? So, that's the challenge. And starting from that point, there are several

07:53.080 --> 07:58.280
things that can go wrong. So, I'm just going to give you a little portrait of some of the things

07:58.280 --> 08:04.200
that can go wrong with that, and that we're going to try and avoid. So, the first thing that can go

08:04.200 --> 08:14.920
wrong is that we have wonderful concrete, rich, messy data, and beautiful abstract novel theory,

08:16.280 --> 08:24.360
but we haven't properly connected the two. And so, that is a very easy mistake to make.

08:24.920 --> 08:33.640
We can look at our data and be inspired vaguely about some kind of theory,

08:33.640 --> 08:41.480
but we haven't shown tight connections between the two. So, that's loose coupling. That's

08:41.480 --> 08:57.320
blind alley one. I need to be careful with that. So, blind alley two is that we code the data to

08:57.320 --> 09:07.560
death and end up with something which actually doesn't reach beyond the data. It is just descriptive

09:07.640 --> 09:14.920
and dull. And that's very easy, too. If you, in a certain sense, if you stay too close to your

09:14.920 --> 09:22.760
data, this is what happens to you. You don't reach beyond it. So, you just have codes,

09:22.760 --> 09:29.880
lots of codes and descriptions, and you've got tight coupling. Nobody is going to question

09:30.760 --> 09:37.800
whether you have accurately reflected your data, but your data is not saying anything at this point.

09:38.360 --> 09:46.760
It is just not descriptive. So, it doesn't work either. And then the third one, which is a little

09:46.760 --> 09:55.560
bit more difficult to understand, my diagram isn't great. It's when you impose theory on your data.

09:56.520 --> 10:05.800
So, you see some theory that you think might be relevant to your case. You draw a wonderful conceptual

10:05.800 --> 10:11.240
framework beforehand, which is showing all the relationships that you think are going to be

10:11.240 --> 10:16.760
there before you do your study. And then lo and behold, when you do your study, you take the

10:16.760 --> 10:25.320
concepts that are in your conceptual framework, impose them on your data, and you say, oh, look,

10:25.320 --> 10:33.640
I thought I would get this. Look, I got exactly what I thought. And what you've done there is you've

10:33.640 --> 10:40.440
squeezed the richness out of the data. You've squeezed out everything that could give you new.

10:40.440 --> 10:45.560
So, I call this circular coupling. And it's actually quite a common problem.

10:48.040 --> 10:53.000
And I've seen it myself, and I got trapped in it myself. And the reason one gets trapped in it is

10:53.000 --> 11:01.720
because thesis advisors naturally want students to look as if they know what they're doing before

11:01.720 --> 11:07.560
they do their study. So, in their proposal, there will be this complex theoretical framework. And

11:07.560 --> 11:14.120
that becomes the thing that drives the research. And if it drives the research too much, you already

11:14.120 --> 11:20.440
end up with what you started with. And that will not make a strong contribution. So, those are the

11:20.520 --> 11:30.680
different problems that might arise. And we're now going to talk about some of the ways that we might

11:30.680 --> 11:36.680
try and do something that would lead us to the first diagram, which is

11:38.760 --> 11:48.040
concrete, rich, messy data, abstract and novel theory, and credible but creative coupling, which

11:48.040 --> 11:57.960
is kind of what we're trying to achieve. So, in order to talk about this, I'm going to rely a

11:57.960 --> 12:05.080
lot on a paper which some of you may have read, which is my 1999 piece, which is a published

12:05.080 --> 12:11.320
in the Academy of Management Review, which was titled, Strategies for Theorizing from Process

12:11.320 --> 12:22.600
Data. It's now about 24 years later. Some things have changed, but I still think that

12:22.600 --> 12:28.920
those ideas have value. And so, I'm going to start from those ideas and give you some thoughts about

12:28.920 --> 12:38.760
my more recent ideas around that and experience around trying to use those ideas. And these are a

12:38.840 --> 12:47.240
set of ideas. And so, I'm going to put them forward. I'm going to point you towards sources

12:47.240 --> 12:53.240
that might help you with some of these ideas about how to do this. I'm not going to give you

12:53.800 --> 12:58.600
a complete recipe. I'm going to give you these ideas. And these are things you can mix and match

12:58.600 --> 13:06.600
and work with. And we'll look on do this now. And I'm going to... Let's see.

13:10.040 --> 13:21.000
Okay. So, this is a list of the items that I included in the 1999 paper, which I called

13:21.080 --> 13:29.720
Strategies for Theorizing from Process Data. And there were seven of them. And so, you can look at

13:29.720 --> 13:37.560
them and you can sort of group them into three areas. And so, the first two that you see there,

13:38.360 --> 13:47.400
I call them grounding strategies. And they were actually about coding. So, the first one,

13:47.400 --> 13:53.320
grounded theory, is this idea that you're going to start with the data and you're going to build

13:53.320 --> 14:01.480
your theory bottom up from the data. The second one is kind of a different way of looking at it.

14:01.480 --> 14:09.880
Instead of building up your theory bottom up, you're going to take a priori known theoretical

14:09.880 --> 14:18.040
lenses and fit them to the data top down. And if you do it with more than one, that enables

14:18.040 --> 14:24.280
you to see which one fits best. So, I see these two as kind of opposites of one another,

14:25.800 --> 14:31.080
theorizing from the bottom up, theorizing from the top down. And we're going to talk about those

14:31.080 --> 14:41.880
first. The second two, I see as ways of displaying data. So, you can display data either as a story,

14:42.440 --> 14:47.720
as a narrative, you can construct a narrative from your data, or you can try to draw them

14:49.480 --> 14:54.920
using visual mapping. So, I see those two as kind of opposites of one another as well.

14:55.800 --> 15:07.000
And then the last three are all about comparing data. And for me, comparing is really the essence of

15:07.000 --> 15:12.360
this thing that drives, for me, it drives theorizing. When you're comparing two things,

15:12.360 --> 15:16.280
you immediately ask yourself, why are they different? Why are they similar? What is it that

15:16.280 --> 15:23.560
explains that? So, as soon as you start to compare, it really is a great stimulus for theorizing.

15:23.560 --> 15:28.680
And I introduce here three different ways to compare. So, comparing cases, comparing

15:29.560 --> 15:35.480
this notion of temporal decomposition or temporal bracketing, which is comparing phases,

15:36.120 --> 15:42.600
and the last one, quantifying. And so, that's the kind of portrait of these seven

15:43.160 --> 15:57.480
approaches that you can use to data. And of course, they are not, you don't pick one and then use it.

15:58.200 --> 16:04.360
All right? You do all of these things when you are trying to theorize from process

16:04.360 --> 16:09.640
stage. And it's a very iterative process and you move between them. So, I have this,

16:09.640 --> 16:16.120
in my next slide, I have this diagram, which expresses that. So, on the left, you have what

16:16.120 --> 16:23.720
I call the grounding strategies. In the middle, you have the organizing strategies, which are

16:23.720 --> 16:29.160
useful for displaying. And on the right, you have the comparing strategies. And you can do them in

16:29.160 --> 16:37.720
any order. I put the diagram from left to right, because I think there's a sort of a progression

16:37.720 --> 16:45.960
from coding to displaying to comparing, which I'm going to put coding, displaying, and comparing.

16:45.960 --> 16:50.600
I think there's a progression. But that doesn't mean you might start at a different place.

16:51.560 --> 17:01.800
Okay. So, let's start with coding. And so, I'm going to talk a little bit about

17:02.760 --> 17:11.880
coding process data. And then we'll stop and take some questions and have some conversations.

17:12.840 --> 17:18.520
And then I'll talk about the other two after that. So, let's start with coding.

17:22.280 --> 17:29.160
So, there are these two strategies that I mentioned, grounded theory and alternate templates.

17:29.160 --> 17:37.400
The grounded theory idea is from the bottom up. And alternate templates is taking the top down,

17:37.400 --> 17:44.120
where theory is at top, and data at the bottom. Okay. So, let's look at grounded theory first.

17:44.680 --> 17:52.600
So, grounded theory means building from the bottom up. So, you have no a priori framework.

17:53.240 --> 17:59.960
And there are some classic authors that have talked about that. So, Corbin and Strauss,

18:00.680 --> 18:07.000
Charmas, and more recently, Denny Joyer and colleagues,

18:09.000 --> 18:16.760
Emma Hamilton, and Kevin Corley have this organizational research methods piece,

18:16.760 --> 18:21.400
which explains how to do grounded theory. And it's become really dominant

18:22.200 --> 18:26.280
in the field of qualitative research. And I'm an editor at the Academy of Management Journal.

18:26.280 --> 18:34.280
And I see that, you know, one, I am an editor for all the qualitative papers. And I would say that

18:34.280 --> 18:42.440
one paper out of two has one of Denny Joyer's diagrams. And I just want to say, before I

18:42.440 --> 18:47.640
start talking about that, that that is not absolutely required to publish a paper.

18:48.680 --> 18:56.360
But it is a very common approach, and it has all kinds of benefits. And grounded theory,

18:57.320 --> 19:06.200
the tools like Atlas, TI, NPVO, MaxQDA, etc., are great for managing your coding. They don't do it

19:06.200 --> 19:16.360
for you, but they manage it. I haven't yet got into chat GPT. And maybe there are some

19:16.360 --> 19:24.440
opportunities there to see what chat GPT can do for you in terms of coding. That's the kind of

19:24.440 --> 19:29.720
life on the front there. And I think there are people who have already started looking at that.

19:29.720 --> 19:35.640
I'm not looking at that here. So that might be an issue that we might want to get to.

19:36.600 --> 19:44.760
So I'm going to talk a little bit about the Joyer method. For those of you who haven't

19:48.760 --> 19:53.560
seen it before, so that we can see what this method is about. So

19:53.880 --> 20:07.240
a really great example of the Joyer method is the 2004 paper by Corleone Joyer on identity

20:07.240 --> 20:14.200
ambiguity in administrative science quarterly. And I use this as an exemplar of the type of

20:14.200 --> 20:22.680
bottom-up coding that dominates a lot of process research, as well as any other qualitative research.

20:22.760 --> 20:33.560
So this method involves three types of artifacts. And the most famous one is this one.

20:35.800 --> 20:47.160
And this is a coding approach, which is so elegant. What you can see here on the left,

20:47.160 --> 20:59.400
the first-order concept, is how a researcher takes their original data and looks at the data in Vivo

20:59.400 --> 21:06.680
and codes it into the first category. So there may be lots and lots of first-order codes.

21:06.680 --> 21:12.920
You're going to have hundreds of them. You start doing that. You start coding bottom-up in Vivo.

21:12.920 --> 21:19.560
You end up with far too many codes. But that's okay, because then you group them.

21:20.360 --> 21:25.320
And so you come to the second-order things. And so they look at the similarities and differences.

21:25.320 --> 21:30.600
You put them together. You group them. And then you do that the third time. And you can do it

21:30.600 --> 21:35.640
the fourth time. You can do this any number of times you like. And what you have on the right

21:35.640 --> 21:42.280
then is some key concepts that are going to become the essence of your theory. And so the

21:42.280 --> 21:52.200
brilliance of this is it shows you exactly how you move, in theory, from your original messy,

21:52.200 --> 21:59.880
concrete data to some abstract concepts. And it shows the pathway. So that's the first artifact.

22:00.760 --> 22:07.240
And unfortunately, a lot of researchers kind of stop there. They show you the data structure and

22:07.240 --> 22:20.600
that's it. A second artifact is actually showing the link between the two. So here this is in the

22:20.600 --> 22:26.280
paper. It's just an example. They've got their concepts. And here you've got quotes that reflect

22:26.280 --> 22:32.920
those concepts. So that's the second artifact. And the third artifact is taking the second order

22:32.920 --> 22:40.360
and themes and the third order, the overarching dimensions and creating a process model with them.

22:40.360 --> 22:48.680
So they didn't see the flow between all of the concepts in the paper. And there you can see how

22:48.920 --> 22:55.720
Pauli and Joya have brilliantly started with a database of just a mess. They had observations,

22:55.720 --> 23:01.320
they had documents, they had interviews, and they generated these concepts. And here is the

23:01.320 --> 23:08.680
theoretical model at the end. So this looks wonderful, right? What you don't see in the paper,

23:08.680 --> 23:17.720
of course, is all of the back and forth that they must have had to do to get the

23:18.360 --> 23:26.040
to the data structure in the first place. This does not suddenly appear, right? You need to

23:26.040 --> 23:35.160
know what you're doing. So this is much more complicated than it looks. So looking at this

23:35.160 --> 23:44.440
approach, it's really a brilliant approach to show in an in a paper the rigor of your coupling

23:44.520 --> 23:52.280
between the data and your theory. One of the things that have been said about it and I share

23:52.280 --> 24:00.360
this concern is sometimes if you've got these concepts, you're glossing over, for example,

24:00.360 --> 24:05.800
the conversations, the interactions, the interactional details, you have labeled everything

24:05.800 --> 24:13.640
in terms of concepts, and you may be missing the temporality and the dynamics through this process.

24:13.640 --> 24:19.960
So that can be a concern. And you could code differently, though. You could code

24:21.800 --> 24:30.680
recently in a study, instead of coding things that people said, we coded the interaction.

24:31.320 --> 24:35.640
And so there would be different types of interactions. So then you've got some of the

24:35.640 --> 24:47.560
dynamics included in the in the story. So and the other thing is if this is entirely uninformed

24:47.560 --> 24:54.760
by any other approach, my concern is that if you're just doing bottom up coding,

24:55.480 --> 25:04.600
just starting from your data, and you think that the theory is going to kind of result from that,

25:05.240 --> 25:13.080
you're going to run into Brian the Blind Alley, too. And Cooley and Joya do not do that because

25:13.080 --> 25:21.480
they are theoretically informed. They're not, they're not starting their study from from total

25:21.480 --> 25:29.720
scratch, even though so the the idea that grounded theory is from entirely bottom up is not quite

25:29.720 --> 25:38.680
true. There are always efforts to connect to existing theory, and we should never forget that.

25:38.680 --> 25:47.880
So just doing coding is not going to get you to an interesting bottom up coding is not necessarily

25:47.880 --> 25:54.520
going to get you to an interesting process theory on its own. And it's very iterative,

25:54.520 --> 26:01.320
and you have to keep going back and forth, and so on. So that's that. That's the final comment

26:01.320 --> 26:09.160
there. So here we've just so far talked about the bottom up side. Let's now talk about the top down

26:09.160 --> 26:15.240
approach, which is a little bit different in terms of coding. So we're going to look at

26:15.240 --> 26:22.920
alternate templates, which is my strategy to. So the idea here, when I wrote the paper in 1999,

26:22.920 --> 26:33.080
was this idea that you could, you could fit one I a priori theme theory to your data. But what's

26:33.080 --> 26:40.840
probably more interesting is trying to apply more than one. Because if you do that, you will get to

26:40.840 --> 26:49.320
see your data in different ways, you might even be able to verify which which theoretical framework

26:50.280 --> 26:58.040
is more appropriate fits better. And doing this coding based on any priorities frame

26:58.040 --> 27:04.200
frame can be very useful for doing that. And the classic inspiration for this is a book which I

27:04.200 --> 27:09.560
recommend everybody read, which is by Graham Allison, and just the essence of decision.

27:10.920 --> 27:18.360
And he's a political scientist. And he studied the Cuban missile crisis, which is an event which

27:18.360 --> 27:24.040
I'm old enough to have lived through, although I was a child in the 1960s.

27:26.120 --> 27:34.040
When nuclear missiles were placed in Cuba, and the United States had to decide what to do about it.

27:35.320 --> 27:45.640
And what what Allison did is he got access to a huge amount of documentary data on this.

27:46.600 --> 27:51.800
And analyzed it according to three different theoretical frames. And the first theoretical

27:51.800 --> 28:00.120
frame was the rational actor model. So according to the rational actor model, countries are rational

28:00.120 --> 28:10.840
actors. So countries consider the the alternatives they have available and pick the best one.

28:11.160 --> 28:19.320
So the whole assumption is that the country is one one actor.

28:21.640 --> 28:26.920
The second theory they applied to that this was to say no, no, no, countries are not actors,

28:26.920 --> 28:32.200
countries have bureaucratic organizations that are part of them. So for example, the US has the

28:32.200 --> 28:38.440
Pentagon, the military that are doing one thing. They have Congress that is doing something else.

28:39.160 --> 28:44.760
They have the president who is doing something else. All of these individuals have their own

28:45.320 --> 28:51.000
routines. All of these groups have their own routines that they know how to do. So the military

28:51.000 --> 28:56.120
knows how to do an invasion. They know how to do a blockade. And if they're given the right stimulus,

28:56.120 --> 29:02.200
they will execute the bureaucratic processes that they know how to do. And so the second

29:02.200 --> 29:09.080
explanation was really a March and Simon based bureaucratic model. And then the third one was

29:09.080 --> 29:14.440
political. So they were looking at individuals, what their individual interests were and how

29:14.440 --> 29:20.440
those interacted. And they applied these three models to the same data and ended up with three

29:20.440 --> 29:26.680
different stories, which they kind of argued in the first version of their paper, we should

29:26.680 --> 29:32.920
keep separate because they enable us to see different things. These things are not wrong.

29:33.880 --> 29:38.920
They're just lenses for looking at things. And having different lenses to look at things

29:40.040 --> 29:47.160
is insightful. So this is this is a completely different approach because you are starting

29:47.800 --> 29:55.080
from the theory and not from the data. This is an approach that probably, in my opinion,

29:55.080 --> 30:01.240
we don't use enough. At least, and it's one of the reasons is it's very hard to

30:02.600 --> 30:10.440
introduce three different theory of theoretical frames into a 40 page article. It's not possible.

30:10.440 --> 30:18.440
But you can do it in a thesis much more easily. And that can be the basis for three different

30:18.440 --> 30:29.800
articles. So that so this can be used more. I have an example here of a single paper where they

30:30.600 --> 30:40.520
looked at three different frameworks. And this was an organization of science. It was by two

30:40.520 --> 30:46.600
colleagues of mine in Montreal, Suzanne Duvara, who said that she said Maria, and yet the point

30:46.600 --> 31:00.440
who is at McGill. And they studied the implementation of computer systems in in in hospitals. And they

31:00.440 --> 31:07.800
considered three different theoretical models for understanding that. And the first one was that

31:07.800 --> 31:18.200
this was a problem of people. And so that model was about how individuals cognitively related to

31:18.840 --> 31:23.160
an information system. So if you wanted to understand if it was implemented or not,

31:23.160 --> 31:32.360
you had to see how people found it useful or not, essentially. And it was basically a question of

31:32.360 --> 31:41.480
whether different individuals could cognitively absorb the implications of the information system.

31:41.480 --> 31:47.160
And so in order to code for that model, they coded by individuals, right, they had the list of

31:47.160 --> 31:52.520
individuals, they considered the elements that are in the model. So there were four elements in the

31:52.520 --> 31:59.560
model, they coded them systematically, and look to see how that worked. The second one is a

32:00.200 --> 32:05.480
political model. And the theory behind that is that people will resist information systems that

32:05.480 --> 32:13.080
take power away from them. And so, and they looked at different groups, so they looked at doctors,

32:13.640 --> 32:20.680
they looked at, they looked at administrators, and how they were reacting to the information

32:20.680 --> 32:29.000
systems over time, and considered whether this model might explain things. And the third model

32:29.000 --> 32:38.360
is an organizational design model developed by Henry Menzberg. And here they were trying to consider

32:38.360 --> 32:45.480
whether the organizational form was having a difference to the implementation process.

32:45.480 --> 32:52.600
So they basically tested, and in this case, it was a test. It was not really different lenses to

32:53.560 --> 32:59.640
enrich, to accumulate, to have three different explanations, but they tested the value of each

32:59.640 --> 33:09.000
of these three models on the same data. And came to the conclusion that in the early phase of

33:09.000 --> 33:14.920
implementation, it was one model that dominated in another phase, it was the second model that

33:14.920 --> 33:21.480
dominated in the third phase, it was a third one. So that in the end, this enabled them to generate

33:21.560 --> 33:28.680
a really interesting theoretical framework, which showed how the importance of different

33:28.680 --> 33:33.800
processes evolved over time. So that's an example of how you can and do that.

33:35.880 --> 33:43.880
And before I move on from this, I wanted also to draw attention to Andy van der Ven's work.

33:43.880 --> 33:53.480
Unfortunately, we lost Andy van der Ven last year. But he has made a fantastic contribution to

33:53.480 --> 34:02.760
process research. And one of his papers, which I really find at the same time, extremely stimulating,

34:02.760 --> 34:11.000
but at the same time, I've always questioned it a little bit, is a piece of work with Marshall

34:11.080 --> 34:19.960
Scott Poole, where he proposed four different theoretical, possible theoretical models of

34:19.960 --> 34:28.520
process. And in terms of thinking about alternate templates, these are really, really useful.

34:29.720 --> 34:36.920
These are classic process theories. And I'm just going to give you an illustration. And I actually

34:36.920 --> 34:45.240
used this recently in a study with a colleague from University of Gothenburg, and we were looking at

34:46.280 --> 34:54.120
migrant workplace integration in Sweden in organizations. They've had many, many refugees

34:54.680 --> 35:05.080
come to Sweden and organizations and governments are struggling with how to ensure workplace

35:05.080 --> 35:20.040
integration. It's clearly an important factor that can explain whether refugees can adapt

35:20.040 --> 35:30.600
to a society. So van der Ven and Poole identified these four classic process models. They called a

35:30.600 --> 35:37.400
life cycle process, a learning process, an ecological or evolutionary process, and a

35:37.400 --> 35:43.400
dialectic process. And I have little diagrams which illustrate each so that we can just sort of see

35:43.400 --> 35:51.400
what the kinds of frameworks might be. And these are really useful kind of heuristic ideas about

35:51.400 --> 35:58.200
how you might consider your process data. So the first one is, it's a process that evolves over time

35:58.280 --> 36:06.120
in a predictable way. So, you know, you're a refugee into a country, you try and get a job,

36:06.760 --> 36:13.000
you go through certain processes of development, and at some point you reach a level of maturity

36:13.000 --> 36:19.160
as integrating into your workplace. So this is a very linear process model, and it assumes that

36:19.160 --> 36:26.760
there are kind of deterministic phases through which you pass. So that's one way of looking at

36:27.320 --> 36:35.480
process. It's probably the simplest way, and many process models, the first iteration, that's what

36:35.480 --> 36:43.960
they look like. It's maybe not the most inspiring in terms of understanding the complexities.

36:43.960 --> 36:50.680
So that's one type of model. A second type of model is this idea of learning.

36:51.640 --> 36:57.560
Van de Verden and Poole call it a teleological model. I like to think of it as a learning model,

36:57.560 --> 37:02.520
because I think it's easier to understand, which is that you have an objective, and it's all about

37:02.520 --> 37:11.800
agency. You have an objective, you form a plan, you try to execute it. If you are able to execute it,

37:11.800 --> 37:18.520
so much the better, you continue, and if not, you change your plan. So it's a circular model,

37:18.520 --> 37:26.440
really. I think that those of Edward Deming, it's a little bit like that. It's learning.

37:26.440 --> 37:31.240
It's you plan, you do, you check, and you act, and then you plan, and you do, and you check and act.

37:33.080 --> 37:39.240
So, yeah, migrants who arrive in a new country are doing learning as well,

37:41.880 --> 37:48.200
and companies who are trying to develop processes to support workplace integration are

37:48.280 --> 37:54.680
also doing learning. And so you could apply it to different levels. And so this is another

37:55.880 --> 38:04.840
process model that you can consider. The ecological process model that they propose is this idea

38:05.720 --> 38:14.200
of survival of the fittest, Darwinian processes. And so you start with variation.

38:14.200 --> 38:21.240
So let's take innovation. You start with many, many, many different ideas for innovation,

38:22.360 --> 38:27.880
but some of them fit better with the environment than others. And so the ones that do get selected

38:27.880 --> 38:33.800
and the ones that don't get thrown out. Okay, here's the third one. Unfortunately,

38:34.680 --> 38:44.200
Darwinian selection applies equally to migrants' integration processes. So there are

38:44.200 --> 38:50.600
selection mechanisms, which mean that not all people manage to become integrated. And so the

38:50.600 --> 38:56.520
integration is a very selective process, in fact, when you look at it carefully. But that's

38:56.520 --> 39:05.960
is another model that can help explain what is going on. And then finally, the dialectic process.

39:05.960 --> 39:13.480
So the whole notion of the dialectics is two systems or two sets of objectives that are in

39:13.480 --> 39:21.160
conflict that collide. And so the driving force of a dialectic process model is contradiction.

39:21.720 --> 39:28.680
And contradiction generates something else. What it will generate, you don't quite know.

39:28.680 --> 39:37.080
And so this is the model that actually my colleague at Gothenburg, Bedran Omanovich and I found most

39:37.080 --> 39:45.720
useful. And so our model is more of a dialectic model. And the idea here, we look at the socio-political

39:45.720 --> 39:53.800
context. We look at tensions between management interests and migrant interests, which generate

39:53.800 --> 40:00.680
different factors and patterns of integration. They generate tensions. These tensions give rise to

40:01.320 --> 40:11.560
either transformation or perhaps reproduction, depending on the power dynamics. So a dialectic

40:11.560 --> 40:17.000
process model is very much oriented around process dynamics. So what you see here is, you know,

40:17.000 --> 40:22.520
four kinds of a priori ways that you might think about process. And I think that these are generative.

40:24.200 --> 40:28.360
And the only thing I would say is, I think there are not just four.

40:30.360 --> 40:35.640
So you could apply. There are many a priori process models out there.

40:36.040 --> 40:46.840
Vandevan and Poole would argue that all of these are combinations of these four. But sometimes it's

40:47.880 --> 40:53.240
interesting to consider them on their own merits. So I've always found actor network theory to be

40:53.240 --> 41:02.600
an interesting theory. It's a process theory that might apply here as well. So the basic idea is

41:03.400 --> 41:10.280
taking theories and trying them out is very generative in terms of process theorizing.

41:12.920 --> 41:20.520
This is the point I make here. The only problem, and this is if you try to impose

41:21.080 --> 41:28.680
one theory onto your data and match it, what you're doing is you're just labeling things.

41:29.640 --> 41:38.680
And so that's why more than one or doing top down, but also doing bottom up as well is much more

41:39.560 --> 41:47.000
likely to give you something that corresponds to our ideal portrait. The danger of imposing

41:47.000 --> 41:53.640
one model is that you end up with the richness squeezed out. Looking at several, you can tell,

41:53.640 --> 41:57.720
I mean, if you could look at my diagram, you could see that you would get several different

41:57.720 --> 42:03.560
circles on there, and that might on the left, on the bubble on the left, and that might do a better

42:03.560 --> 42:15.800
job of understanding your whole process. So again, this is not a mechanical linear exercise, and

42:15.800 --> 42:23.000
there's a lot of value of iterating with the ground at the bottom up coding as well. And then

42:23.000 --> 42:30.360
that sort of raises the question, how do you do this? Because you're doing bottom up, you might be

42:30.360 --> 42:36.200
doing some top down coding as well. And I have another example here, which kind of is really

42:36.200 --> 42:45.240
interesting. It's a paper by Kaplan and Olikowski, where I think the reviewers of the paper must have

42:45.240 --> 42:55.400
asked them to explain that coding process. And so they've introduced this diagram in an appendix,

42:55.400 --> 43:01.560
which explains that coding process. And their final model is the little diagram in the bottom

43:01.560 --> 43:10.200
right of that picture. And what you see all of the circles, you know, where the circles going

43:10.200 --> 43:20.760
around is showing how they iterated between bottom up coding of their data, going to the literature,

43:20.760 --> 43:27.240
finding a theory that might help, and then doing coding based on the theory that they had found,

43:27.240 --> 43:33.080
and doing this iteratively multiple times. And they're trying to describe here the exact process

43:33.080 --> 43:39.080
that they went through to arrive at the particular theory they ended up with. So this is a really nice

43:39.080 --> 43:46.760
illustration of what it really looks like, something of what it really looks like to engage in coding

43:46.760 --> 43:55.400
of process data. And increasingly, actually, seeing diagrams like this appear in articles,

43:55.400 --> 44:01.960
because people are being asked to explain, well, how did you do this? Actually, how did you take

44:01.960 --> 44:08.520
theory that is out there, combine it with the data that you have to produce something new? And so

44:08.520 --> 44:15.880
this is the combination, I think that is important. So I'm going to stop here

44:18.920 --> 44:27.000
for a moment, and stop share, and see if we have

44:29.400 --> 44:32.520
some questions. So I can see a lot.

44:33.320 --> 44:42.440
Yes. Thank you so much, Ann, for the presentation and for all the information. It's been super

44:42.440 --> 44:48.040
helpful. I have two questions. One is a clarifying question, and then the other one is also for

44:48.040 --> 44:54.200
recommendation. So maybe I start with the clarification question. So you spoke about

44:54.200 --> 44:59.480
alternate templates, and it's something that I've actually thought about quite a bit.

44:59.880 --> 45:07.640
I'm not doing a process study, or I'm not doing a study with process data, but I do find all the

45:07.640 --> 45:13.880
strategies you've mentioned very useful. I thought that alternate, or at least from my

45:13.880 --> 45:20.200
perception, I feel like almost every qualitative study would at some point in time come across

45:20.200 --> 45:26.360
alternate templates, because you do try a lot of different things to see what fits your data.

45:27.080 --> 45:34.280
So from the back of my mind, I felt like it's kind of intuitive, but you mentioned that it's

45:34.280 --> 45:40.200
not used often. So that made me feel like, okay, maybe I didn't understand what you meant by

45:40.200 --> 45:48.600
alternate templates well enough. So is it really just trying different theoretical lenses to see

45:48.600 --> 45:55.000
which one fits your data in the analysis process, or like what you displayed, where the authors

45:55.000 --> 46:02.200
eventually in their final output also explain each of these theoretical lenses and then argue

46:02.200 --> 46:09.880
for each one, which one qualifies as alternate templates? Yeah, so I mean, a study that would

46:10.840 --> 46:19.240
really, I would consider to be an alternate template study would show the different templates

46:20.120 --> 46:24.520
in their study and say, I looked at my data according to three different theories,

46:24.520 --> 46:29.080
here's what happens when you take this one, here's what happens when you take that one,

46:29.080 --> 46:34.600
here's what happens when you take the third one, or they could be four or that could be two. So

46:34.600 --> 46:40.600
it provides different accounts. So if you were going to use that in a study, it would provide

46:40.600 --> 46:46.600
different accounts. But that doesn't mean, and I was perhaps confusing about that, that doesn't mean

46:46.600 --> 46:54.360
that a researcher might not be doing this in the background, anyway. But when it comes to

46:54.360 --> 46:59.800
actually write the paper, that's kind of as if all of that variety might disappear, because you

46:59.800 --> 47:04.920
have picked the one that's going to work, you don't have room to describe all the other alternatives

47:04.920 --> 47:15.080
you look at, so you go for one. Yeah, so and the one is usually a combination of both the top

47:15.080 --> 47:23.800
down and bottom up in practice, because you take your model, you apply it, and it doesn't quite

47:23.800 --> 47:31.080
work. And so you enable you to introduce new things, or if you're going bottom up, you do

47:31.080 --> 47:35.720
something, and you think, oh, yes, I found this, and then you have to look in the literature.

47:36.280 --> 47:41.720
And you see, well, the literature also found that. So is that new? I mean, what is it I'm adding?

47:41.720 --> 47:47.720
So it's this back and forth that's, that's important in the doing, but in the presenting,

47:48.360 --> 47:55.160
alternate templates is very rare. Okay, okay, thank you so much for clarifying. The second question

47:55.720 --> 48:02.200
is that, like I mentioned, I don't specifically use process data, but I do find all your strategies

48:02.200 --> 48:11.000
quite helpful. But I realized that in qualitative, in the qualitative community as well, it's very

48:11.000 --> 48:19.400
important who you cite on what studies. And I can imagine that citing process methods papers in a

48:20.360 --> 48:26.920
study with variance data could be problematic, but I still haven't quite found, or maybe I haven't

48:26.920 --> 48:35.320
recognized other resources, which talk about similar strategies for, for variance data, maybe

48:35.320 --> 48:41.080
accept ground of theory and, yeah, accept ground of theory. So I was wondering if you have any

48:41.080 --> 48:49.400
recommendations on, first of all, would it be right, or if it would be right, how to couch it in a

48:49.400 --> 48:56.840
paper, if you are borrowing from a different area of qualitative methods for your approach. So if I

48:56.840 --> 49:03.960
would want to say that I used alternate templates as recommended by Anne Langley, and then I cite

49:04.040 --> 49:09.240
your paper, but then it's not a process study that could be problematic. So how could I couch it so

49:09.240 --> 49:15.000
that it's, it doesn't come across as problematic? Or if I can't do that, then do you have any

49:15.000 --> 49:22.040
recommendations on other resources to consult? I would not worry if you cited me for alternate

49:22.040 --> 49:27.640
templates for any study. And in fact, when I, when I teach qualitative methods, I use this paper,

49:27.640 --> 49:35.320
and many of the most, many of the strategies make sense for other kinds of qualitative data,

49:35.320 --> 49:41.640
even if you're doing a variance study, some of them don't quite so much. So, so things like

49:41.640 --> 49:50.200
temporal bracketing, it's all about time. So it doesn't necessarily make so much sense. And, and

49:50.280 --> 49:57.480
so it depends. When, when I first wrote this paper, I was struggling with what to do with

49:57.480 --> 50:04.280
process data specifically. And so I was looking for solutions to that. But in terms of resources,

50:07.640 --> 50:11.880
I mean, I could recommend a few things. So, so there is a very recent

50:12.600 --> 50:22.040
issue, special issue of organizational research methods. I think the title is Beyond Templates.

50:23.160 --> 50:34.520
So, but the, the, the issue is extremely helpful in offering a range of other ways

50:35.080 --> 50:42.280
of analyzing qualitative data. And so it, it, it really tries to get beyond the idea that

50:42.280 --> 50:49.880
here's a recipe that you just apply. And, and tries to look for more complex ways. One of the papers

50:49.880 --> 50:59.240
that I really find resonates with me, it talks about Brickolash, which is putting things together

50:59.240 --> 51:08.040
that seem to be helpful. And I'm really, you know, strategies for theorizing from process data is

51:08.040 --> 51:14.920
actually recommending some kind of Brickolash as well. But, but, but the Brickolash paper is

51:14.920 --> 51:20.920
particularly helpful, I think, in terms of suggesting different ways. And they give examples

51:20.920 --> 51:26.680
from their own research. But every individual is putting different things together. So it's,

51:26.680 --> 51:31.400
it's not a recipe. It's not a recipe, but it's a very useful citation and

51:33.720 --> 51:37.160
helpful in justifying your approach, I think, whatever you're doing.

51:38.280 --> 51:42.120
Thank you so much, Anne. Ravi?

51:43.480 --> 51:48.760
Yes. Thank you. Excellent presentation. Very, very, very impressive. My question is,

51:48.760 --> 51:57.560
can you elaborate a little bit on process variants? I asked this because I think there is a missing

51:57.560 --> 52:06.520
bridge or link between all the material that you suggested you cited to the whole body of

52:06.520 --> 52:13.400
knowledge that's happening in operations management, where we look at process variants,

52:13.400 --> 52:18.520
you know, we also teach in the operations management courses, tools and techniques,

52:18.520 --> 52:24.600
like the fishbone diagram, Ishikawa diagram and so forth, to really understand how we can

52:25.240 --> 52:31.880
manage those processes so that we can reduce variability to make the processes better,

52:31.880 --> 52:41.160
more flexible, cheaper and faster. I think that practical call for why we try to manage processes

52:41.240 --> 52:47.400
is conspicuously missing in what you suggested. And this is not a criticism. I'm just trying

52:47.400 --> 52:53.320
to connect two bodies of knowledge here, what you cited and what goes on a lot in operations

52:53.320 --> 53:00.120
management. Thank you. Yeah. So what I'm talking about is, you know, every researcher who is

53:00.120 --> 53:08.920
interested in understanding process theoretically, I'm not talking about how to analyze a specific

53:08.920 --> 53:16.680
process to improve it. But obviously, that is a complementary kind of an approach. And some of

53:16.680 --> 53:26.440
the techniques that we might use to theorize might also be particularly useful for improvement as well.

53:26.440 --> 53:33.640
So things like, and I'm going to be talking about this later, process diagrams, for example,

53:34.360 --> 53:43.080
that look at how things are working over time and which activities are taking place.

53:43.800 --> 53:50.600
And process diagrams can be useful to describe what is going on and to theorize from it. But

53:50.600 --> 54:00.520
they can also be useful to pinpoint, okay, this process is kind of not efficient. There are

54:00.600 --> 54:11.400
ways of cutting steps that might be useless. And there are ways also of improving steps so that

54:12.760 --> 54:16.920
there's greater consistency, which is what you're talking about, eliminating variance, right?

54:18.120 --> 54:24.280
So but I'm using the terms process and variance in a little bit of a different way and more in

54:24.280 --> 54:31.560
terms of processes of theorizing. But I do understand that there is also a practical

54:31.560 --> 54:35.720
application as well of these things. Anna?

54:40.600 --> 54:45.240
Yes, hello, Professor Langley. My name is Anna Kourija. First of all, thank you for the presentation.

54:45.240 --> 54:51.080
I've been doing ethnography research projects since three years and still ongoing until next year.

54:51.080 --> 54:56.440
So it's about four years data of ethnographic observation and interview session. It's quite

54:56.440 --> 55:02.120
a lot and messy, as you explained. I tried already the first round data analysis using

55:02.120 --> 55:08.120
Joya method. But I realized, as you mentioned, I'm missing the the temporality, because I've

55:08.120 --> 55:14.360
been studying about project management stages and how culture affects the project and performance on.

55:14.360 --> 55:19.240
And so what I could get from Joya is just a kind of constructionist. So it's like

55:19.240 --> 55:24.280
almost static in the way that it's just forming a certain theory, but it doesn't show

55:24.280 --> 55:30.520
how dynamics in the project team evolve along the along the stages. So now I've been following

55:30.520 --> 55:35.800
the one from Professor Niederman, the socio evolution theory. So like more like a process

55:35.800 --> 55:41.880
theory looks like really like a process theory. But I believe I cannot share my screen. But the

55:41.880 --> 55:47.240
way I did it like this, I don't know if it's correct. So first, I use the theoretical lens from

55:47.240 --> 55:54.760
the literature. So I created a code book with my research team. I get the codes around 50 codes

55:54.760 --> 56:00.760
or something. And I did the deductive approach of top top, top down. And then I did another round

56:00.760 --> 56:06.920
with my team also inductive coding, so that to get some new ideas, or maybe we are not

56:06.920 --> 56:12.680
in the right domain and so on. And then at the end, we kind of plan a map the episodes like

56:12.680 --> 56:17.000
what happened in conflict, what happened creativity. And then we start from the project,

56:17.000 --> 56:22.600
start with the project and and we create like couple of episodes mapping. And then we kind of show

56:22.600 --> 56:28.440
it to the front. And I don't know if we're doing the right thing. But at the moment, this is so far

56:28.440 --> 56:34.520
the best approach that we could think of to generate such huge amount of data. Otherwise,

56:34.520 --> 56:40.200
I'll be also overwhelmed with analyzing this. I would like to get your insight if I'm in the

56:40.200 --> 56:47.000
right track or should I try another approach? I mean, this sounds really good to me. I would,

56:47.000 --> 56:52.120
you know, if you'd like to send me something that you would, you know, I'd be glad to sort of comment

56:52.120 --> 56:59.560
on it. But thank you for doing both bottom up and top down coding. And I think that just focusing

56:59.560 --> 57:05.640
on one can be problematic. You know, if you just do the top down, then you don't produce anything

57:05.640 --> 57:12.840
new. If you do the bottom up, you just kind of end up being descriptive. So it's, it's,

57:13.720 --> 57:19.960
it's the combination of both, which can give you that richness, I think. So yeah, I'd be glad to

57:19.960 --> 57:24.920
look at what you're doing. I'm happy to do to get your feedback on the thank you so much,

57:24.920 --> 57:33.640
Professor Langley. Okay, you see. Hi, I have a question about your strategy to alternative

57:33.640 --> 57:39.880
templates, fit a different theoretical framework to the data. And sometimes people from different

57:39.880 --> 57:45.560
disciplines study the same phenomenon. So the alternative templates may come from another

57:45.560 --> 57:51.160
discipline. For example, like, in addition to management, there may be economics,

57:51.160 --> 57:57.000
maybe astrology, maybe geography, I really like your picture in the beginning, the river is not

57:57.000 --> 58:05.160
object, but ever changing flow. Just analogy, like the person is like driving the boat is like

58:05.160 --> 58:11.000
an entrepreneur drive a business. And the river is kind of like community institutions, is like

58:11.800 --> 58:19.160
economic geography that kind of thing. For example, the river is, is changing flow, like there are

58:19.160 --> 58:24.280
a lot of economic geographers study the community institutions, but they are not considered a

58:24.280 --> 58:30.440
management. So when I use alternative templates, when I incorporate those, to let different

58:30.440 --> 58:35.880
disciplines to kind of have a conversation is answer your call of the river is not object,

58:35.880 --> 58:42.360
but every changing flow, that's very juicy part because my background was from economic geography.

58:43.080 --> 58:48.360
But I'm supposed to say this is not an internship paper, you should submit to somewhere else.

58:48.360 --> 58:55.080
But I am targeting at management mainstream conversation, I want to join that debate. I think

58:55.080 --> 59:00.680
some people say that because the entrepreneurship is changing like a very long time ago is like Steve

59:00.680 --> 59:07.320
Jobs, a kind of entrepreneur, but later on come to the community's level, for example, and then

59:07.320 --> 59:12.600
come to the social level. So what is expanding a touch of the boundaries of different disciplines,

59:12.600 --> 59:17.800
for example, economic geography, but right now I want to speak to the mainstream entrepreneurship

59:17.800 --> 59:23.640
literature, or join that debate, and I want to use the alternative templates by citing

59:24.840 --> 59:29.320
the framework from different disciplines and let that to kind of have a conversation,

59:29.320 --> 59:35.000
so that I can answer your call that the river is not just object, but the average changing flow

59:35.000 --> 59:40.440
that's bring the community lens into the conversation, but speak to the mainstream

59:40.440 --> 59:45.400
entrepreneur. Okay, you give me some suggestions so that people will say it never.

59:45.800 --> 59:52.680
I think that that sounds great. I mean, I think that multidisciplinary research is difficult,

59:52.680 --> 01:00:01.080
but if you are not just, if you are bringing in alternative templates that are not based

01:00:01.080 --> 01:00:07.480
in management and comparing them with those that are, I think that's extremely generative

01:00:07.480 --> 01:00:14.680
and it's likely to be well received. In the entrepreneurship field, I know of one paper

01:00:14.680 --> 01:00:23.400
that really does a good job of looking at alternative templates, and that's a paper by Greg Fischer.

01:00:25.800 --> 01:00:31.000
I think it's Entrepreneurship Theory and Practice is the journal, and it's 2012,

01:00:31.000 --> 01:00:37.320
and it's a kind of a classic application of alternative templates approach,

01:00:37.320 --> 01:00:39.800
so that might be something that you would want to look at.

01:00:40.760 --> 01:00:45.400
So can you type the literature in the chat box, or I follow up and give you an email?

01:00:46.280 --> 01:00:55.720
Yeah, maybe what I will do is send a bibliography to Ibrat at the end, if that's possible,

01:00:55.720 --> 01:01:02.600
because there are ways to distribute that too. I think I can do that. Yeah, okay, I will create

01:01:02.600 --> 01:01:08.440
a bibliography and send it. Wonderful, thank you. If anyone could type that paper in the chat box,

01:01:08.440 --> 01:01:17.880
I really very appreciate it. Thank you. So we have Ibrat and Melissa. Yes.

01:01:19.880 --> 01:01:26.040
My question is about, you talked about kind of doing bottom-up and top-down approach to working

01:01:26.040 --> 01:01:31.400
with the data. Where do you see the role of the thick description in this, and would you say

01:01:31.400 --> 01:01:37.240
thick description? What is the sit in between those two polarities, so to speak? Well, thick

01:01:37.240 --> 01:01:42.200
description for me is more of a bottom-up approach, and I'm going to be talking about narrative

01:01:43.400 --> 01:01:53.480
after, you know, next. So I think that we can get into that, and you know, its narrative is

01:01:54.360 --> 01:02:01.560
doing a thick description as something you might do first, or something you might do

01:02:01.560 --> 01:02:07.960
last when you have done coding. It both is possible. So anyway, we'll talk about that

01:02:09.160 --> 01:02:16.840
in a few minutes, if that's okay. So let's have, but probably best to have one last question from

01:02:16.840 --> 01:02:24.440
from Melissa. Thanks, Anne. I'm struggling a bit because I'm looking at transformation

01:02:25.400 --> 01:02:32.840
comparing it with typical organizational change in that it's constant, and so looking at a strong

01:02:32.840 --> 01:02:39.800
process theory, but at the same time looking for those constants that are in the river,

01:02:39.800 --> 01:02:45.000
and how to sort of frame it. So I've been trying to use different lenses, like performativity,

01:02:45.000 --> 01:02:51.960
and the transformation is a journey, but I'm getting a bit stuck between, well, the right,

01:02:51.960 --> 01:03:00.200
really the right lens to sort of capture the, and make the theoretical contribution

01:03:00.200 --> 01:03:04.920
to show that this is something different if we're talking, for example, in this case about

01:03:04.920 --> 01:03:11.160
digital transformation versus sort of status quo organizational change.

01:03:11.320 --> 01:03:22.760
So I'm not quite sure I have to respond to that, but I do think I've always thought of, you know,

01:03:22.760 --> 01:03:33.720
transformational change as being, okay, fine, you get you shock a system with some kind of,

01:03:34.360 --> 01:03:37.560
well, you know, one time supposedly one time

01:03:40.760 --> 01:03:47.640
initiative, but then it kind of gets itself into woven with what is already going on

01:03:48.200 --> 01:03:56.200
in the company or the organization, and so it becomes continuous. And so change changes,

01:03:56.200 --> 01:04:00.760
this is the way I think about it, so that so that you have this one time transformation,

01:04:00.760 --> 01:04:06.040
but it gets transformed, it gets changed by the continuity of ongoing change.

01:04:08.520 --> 01:04:16.600
And so I like to have that, I like to have that kind of image where, yeah, you do a merger,

01:04:16.600 --> 01:04:21.640
and then you don't do a merger, and then everything is, you know, then you have a result,

01:04:21.640 --> 01:04:26.280
you do a merger, and then all of the things that were going on anyway in the enterprise

01:04:26.920 --> 01:04:36.600
kind of change what that means. So I think that that can be done, and I think that you can trace,

01:04:36.600 --> 01:04:43.080
you can trace, you know, the moment of change, and then trace through the ripples that it creates,

01:04:43.080 --> 01:04:51.160
so that it may create big ripples and small ripples. And I don't know, I would tend to

01:04:51.560 --> 01:05:00.760
look at some kind of temporal bracketing where I would see waves occurring.

01:05:02.120 --> 01:05:08.120
We're trying to understand capacity for the transformation, and the issue is that capacity

01:05:08.120 --> 01:05:13.400
seems to be a boundary, it is or it isn't, and yet are there certain constituent components

01:05:13.880 --> 01:05:21.720
that enable this transformation to be possible, and is it the right theoretical lens to use

01:05:21.720 --> 01:05:28.600
performativity if we're trying to sort of talk about, and maybe boundary condition is not even

01:05:28.600 --> 01:05:34.280
the right term to use anymore, but, you know, the approach was to use necessary condition analysis

01:05:34.280 --> 01:05:39.640
and the data to try to find, yeah, that doesn't even make sense.

01:05:40.600 --> 01:05:46.040
I mean, why don't you send me an email? I have a little problem with the notion of capacity,

01:05:46.040 --> 01:05:53.160
because it's kind of static, right? It's a thing, it conveys the idea of something that's fixed,

01:05:53.160 --> 01:06:00.520
a capacity, or a capability, because this is something which changes over time, the capacity,

01:06:00.520 --> 01:06:06.280
you know, you learn, so you have great capacity, and so everything is evolving, and so the notions

01:06:06.360 --> 01:06:12.600
like capacity, feel a bit uncomfortable with, you could, when you could talk about capacity work,

01:06:12.600 --> 01:06:19.320
which is working on the capacity, so then you get to doing again, but-

01:06:19.320 --> 01:06:21.960
That's super helpful, thank you so much.

01:06:23.000 --> 01:06:31.000
All right, okay, so I think we'll, we'll move on a little bit, because we don't have that much

01:06:31.000 --> 01:06:35.160
time, so I'm going to try and perhaps accelerate a little bit here,

01:06:37.800 --> 01:06:46.520
and I have to share my screen again, right? Okay, so we're now moving on to the middle column here,

01:06:47.160 --> 01:06:54.760
which is displaying process data, and so I'm going to talk about two strategies that I mentioned

01:06:54.760 --> 01:07:01.720
in my paper, which are narrative and visual mapping, and so there's two different ways of

01:07:01.720 --> 01:07:08.600
displaying, the first one is displaying your data in terms of words, and the second one is

01:07:09.160 --> 01:07:20.280
in terms of drawing, in terms of pictures, so if we look at narrative, this is so easy,

01:07:20.280 --> 01:07:26.520
just tell the story, just write it up, you know, all you have to do is to write the story, and

01:07:26.520 --> 01:07:33.320
there are classics here, Alfred Chandler, for example, historian tells a narrative,

01:07:33.320 --> 01:07:39.880
his theorizing is very much narrative-based, and as Ibrat mentioned, thick description

01:07:40.520 --> 01:07:51.000
from anthropology is a term that Geertz uses to, to talk about his approach as thick description,

01:07:51.000 --> 01:07:58.360
and if you do these things well, so basically what you're doing is you're taking the mess of

01:07:58.360 --> 01:08:05.720
data that you have, bringing them together to create a narrative, and a narrative that will

01:08:06.280 --> 01:08:14.200
hopefully tell you something about the world that reaches beyond the particular case,

01:08:14.920 --> 01:08:21.000
and so narrative can be very powerful, and if it works, you get a sense of this,

01:08:22.200 --> 01:08:28.520
I've seen this before, so a really good narrative study,

01:08:28.680 --> 01:08:35.640
it'll be like a really good novel, because you will see, okay, this makes sense, this is,

01:08:35.640 --> 01:08:43.720
this is how the world is, and so it can be really appealing to have a strong narrative,

01:08:45.800 --> 01:08:55.000
and then I really like this quote from John Van Lennon, who argues in favor of narrative,

01:08:55.000 --> 01:09:00.760
because precisely because narrative allows for complexity and ambiguity,

01:09:01.880 --> 01:09:11.400
and if your case that you have is fuzzy and messy and ambiguous, then if you want to render it

01:09:13.000 --> 01:09:21.160
and keep that side of it, then, you know, he says to be determined, we must be indeterminate,

01:09:21.160 --> 01:09:25.400
because things are confusing, because things are messy, and so on and so forth,

01:09:26.360 --> 01:09:32.280
so a narrative approach tends to try and keep as much of the richness as possible,

01:09:32.280 --> 01:09:40.360
but at the same time, give you that sense of deja vu, so that's the positive side,

01:09:41.160 --> 01:09:48.280
this is the negative side, and so this is Laurel Richardson in the handbook of quality

01:09:48.360 --> 01:09:53.080
research, and she says, I have a confession to make for 30 years, I have worked my way through

01:09:53.080 --> 01:10:01.880
numerous supposedly exemplary qualitative studies, and it's boring, basically it can be so boring,

01:10:01.880 --> 01:10:07.720
and the reason is that it's just descriptive sometimes, and so it's blind alley two again,

01:10:09.080 --> 01:10:16.120
where you have so closely captured your empirical data that we can't see

01:10:16.920 --> 01:10:23.240
the deja vu, we can't see the plot within it, and so this is the problem of narrative,

01:10:24.280 --> 01:10:30.200
but at the same time, there's almost no qualitative study where you don't at some

01:10:30.200 --> 01:10:39.720
point draw on narrative, so what are some of the other ways to draw on narrative, so one way is

01:10:39.720 --> 01:10:49.160
to use it as the first step, so you have all this mess, why not just try and write it up

01:10:50.600 --> 01:10:56.760
as completely as possible, and this Kathleen Eisenhardt, this is the step that she always

01:10:56.760 --> 01:11:02.120
recommends, and she talks about multiple case studies, and she talks about how for each of her

01:11:02.200 --> 01:11:11.480
cases, she writes something like a 70-page, single-spaced story, and that story becomes

01:11:11.480 --> 01:11:21.880
like a secondary database for the rest, it's a way just to get started, and it becomes,

01:11:21.880 --> 01:11:28.600
as we're writing this narrative, it becomes the stimulus for your coding that you're going to be

01:11:28.600 --> 01:11:35.800
developing, so that can be one way to use it, the other way to use it is to consider it as your

01:11:35.800 --> 01:11:43.960
last, you write the narrative to integrate your coding and your data and your theory, to bring

01:11:43.960 --> 01:11:48.680
the data and theory together so that you're telling a story which has concepts in it,

01:11:49.320 --> 01:12:05.720
and is kind of bringing codes and specifics and generality together, so a really strong narrative

01:12:05.720 --> 01:12:16.520
as a last step is going to be able to take specifics and show how they reflect a more theoretical

01:12:16.520 --> 01:12:20.040
concept, and you might consider multiple narratives which is getting back to the

01:12:20.600 --> 01:12:27.320
alternate templates approach, or you could look at multiple narratives based on the visions of

01:12:27.320 --> 01:12:31.960
different people in your case, that's another way to multiple narratives, so these are richer ways

01:12:32.600 --> 01:12:40.280
and more useful ways I think of thinking of narrative, and there's this paradox about narrative

01:12:40.280 --> 01:12:46.840
which is you can't write a really good narrative until you know what the plot is,

01:12:48.200 --> 01:12:57.880
but you can't discover the plot until you've done the narrative, so it's this hermeneutic thing,

01:12:57.880 --> 01:13:05.080
it's this iteration once again, you start writing, you don't have the plot at first,

01:13:05.960 --> 01:13:13.160
when you discover the plot you have to rewrite it completely, and so it's a kind of a little

01:13:13.160 --> 01:13:20.920
bit of a paradox, and now so that we've talked about narrative, I'm not going to talk about

01:13:20.920 --> 01:13:31.480
another way which I really like of displaying qualitative and processed data, and this is

01:13:31.480 --> 01:13:40.280
visual mapping, and so draw it, draw your data, or draw something, draw your theory,

01:13:41.640 --> 01:13:51.400
and so we're talking about graphs, tables, drawings, diagrams, on visual mapping the gurus

01:13:51.400 --> 01:13:58.200
here are Miles and Huberman and Sal Danyan, the most recent version of their book has a third

01:13:58.280 --> 01:14:05.480
author, so Miles and Huberman, you should read this, it's a really useful book which

01:14:05.480 --> 01:14:11.880
offers a variety of ways of drawing data, and I like it a lot.

01:14:17.400 --> 01:14:24.920
So here's an example, no it isn't an example, okay so what is visual mapping? So visual mapping,

01:14:24.920 --> 01:14:30.760
you can use any kinds of forms of drawing that you want, but there are a certain number of

01:14:30.760 --> 01:14:38.440
conventions which you might want to keep to, so boxes and arrows are obviously important

01:14:39.400 --> 01:14:48.120
aspects of drawing data, but you can use boxes and arrows for different kinds of things, so boxes

01:14:48.120 --> 01:14:54.200
can be things, they can be objects, they can be concepts, they can be actors, they can be events,

01:14:55.160 --> 01:15:01.880
depending on the shape of the box, you can code whether your event is for example a decision,

01:15:02.600 --> 01:15:12.120
or if it's an event that just happened externally, so you can use the forms of boxes to indicate

01:15:12.120 --> 01:15:18.680
different things, arrows can indicate different things, so particularly for process research

01:15:18.680 --> 01:15:26.120
we're going to be using arrows not so much for causality probably, but more for temporal relations

01:15:26.120 --> 01:15:33.320
like precedence, what comes before what in time is something that we're going to be using

01:15:34.120 --> 01:15:42.920
with arrows, we're showing with arrows, we can use icons, emoticons, etc, and there are a certain

01:15:42.920 --> 01:15:51.960
number of conventions, so at least in the west time goes from left to right, it does not necessarily

01:15:51.960 --> 01:16:02.840
go from left to right in other parts of the world, and that can be confusing, so if your writing starts

01:16:02.840 --> 01:16:07.160
from right to left you may think of time as going from right to left, and that can be confusing,

01:16:07.880 --> 01:16:12.920
most of the American journals will expect time to go from left to right,

01:16:16.440 --> 01:16:23.320
hierarchy top to bottom, you can do things with overlapping boxes, you can do things

01:16:24.280 --> 01:16:32.200
with boxes that interact, lines that interact, and so on, so there are all kinds of ways of doing that,

01:16:33.160 --> 01:16:44.280
here is some of the thoughts of how you can use visualizations, so here's my diagram with data

01:16:44.280 --> 01:16:56.120
and theory and coupling, you can use diagramming visualizing all along this chain, so when you

01:16:56.120 --> 01:17:05.080
look at a published paper what you usually see is a diagram, a process theory, so that is not what

01:17:05.080 --> 01:17:10.520
the author necessarily started with, that's the distillation of their theoretical ideas, so that's

01:17:11.160 --> 01:17:16.520
they're using it for conceptualizing or communicating their theory, but you can also use

01:17:16.520 --> 01:17:24.680
visualization for actually mapping your data, not just simply presenting the findings or

01:17:24.760 --> 01:17:31.400
presenting the theory, but also for mapping the data and for analyzing the data themselves,

01:17:31.400 --> 01:17:40.040
so it becomes a coding tool essentially, and this is an example that I put in a paper,

01:17:40.680 --> 01:17:50.360
very old paper that I wrote with a student, it's a flow chart, and this we were actually

01:17:50.360 --> 01:17:57.880
mapping the data, it was a technology adoption process, we classified events according to

01:17:58.840 --> 01:18:03.720
different domains of the company, so the top to bottom, they're different domains of the company,

01:18:04.760 --> 01:18:13.480
we identified different codes for events outside the company, those are the ovals

01:18:14.200 --> 01:18:23.880
for activities which were I believe square boxes and decisions which were the round cornered ones,

01:18:23.880 --> 01:18:31.400
and we showed precedence, we showed interruptions, we showed events that impacted other events,

01:18:32.120 --> 01:18:38.200
and depending on to what degree they impacted them, we placed different symbols on there,

01:18:38.840 --> 01:18:44.280
this is an example of how you can take some data and instead of just coding it according to Joya

01:18:44.280 --> 01:18:54.440
method, you can display it along a timeline with events, and so this is quite a different way

01:18:55.160 --> 01:19:02.440
of coding, and it's still coding because we have coded the different kinds of events,

01:19:03.400 --> 01:19:13.160
and this is a tool for describing your data, but then if you wanted to compare different

01:19:13.160 --> 01:19:17.480
timelines, and this is what we did, we had five processes that we mapped this way,

01:19:18.040 --> 01:19:22.440
we could compare them so we could see what comes before what, what tends to come before what,

01:19:24.680 --> 01:19:30.600
can we see some patterns in the types of interactions between different kinds of

01:19:30.680 --> 01:19:38.600
phenomena over time, so this is a really interesting tool for process research, and most cases you

01:19:38.600 --> 01:19:46.440
never see, you don't see the mapping itself in a published paper, but you see the final, the final

01:19:46.440 --> 01:19:58.520
diagram, so that's just looking at the time, I'm going to skip a few things here, because I want

01:19:58.680 --> 01:20:05.160
to talk a little bit about comparing as well, so we've talked about the two methods for displaying,

01:20:07.560 --> 01:20:17.480
comparing for me is a really powerful tool for theorizing, because it makes you,

01:20:18.280 --> 01:20:23.640
it makes you theorize, if you, if you have an example I always give is if you have children

01:20:24.520 --> 01:20:32.360
and you have a little boy and a little girl, you immediately stop theorize about the differences

01:20:32.360 --> 01:20:42.840
that come from time, your, your, it's, we are programmed to theorize from empirical differences

01:20:42.840 --> 01:20:49.640
and similarities that we see, and so it is really powerful to do that, and you can compare in all

01:20:49.640 --> 01:20:56.680
kinds of ways, and so I talk about comparing time periods, and this is particularly useful for process

01:20:56.680 --> 01:21:07.400
data, but you can also compare cases, you can compare incidents, and drawing tables that show

01:21:07.400 --> 01:21:15.640
these comparisons is a great way to kind of focus, get yourself to focus on that, so

01:21:19.320 --> 01:21:23.320
I'm just going to give, I'm going to skip this, and just give an example of some temporal

01:21:23.320 --> 01:21:29.640
bracketing, which is decomposing by time period, so this is a paper that I wrote

01:21:30.600 --> 01:21:38.520
with with Jean-Louis Denis and some other co-authors, and it's about a merger of three hospitals,

01:21:40.120 --> 01:21:46.920
and they were in a double mind, they had a real tension, because on the one hand

01:21:48.520 --> 01:21:53.080
they had been told that they would get a lot of money if they agreed to merge,

01:21:54.680 --> 01:21:57.160
and on the other hand they hated each other,

01:22:00.600 --> 01:22:06.360
and so they couldn't agree about anything, they had to stay together, they were stuck,

01:22:06.360 --> 01:22:09.560
so they had this initial condition of constraint, they had to be together,

01:22:10.120 --> 01:22:15.800
but they couldn't agree, and so how were they going to work out how they were going to do this

01:22:15.800 --> 01:22:27.160
merger, and we showed that they kept making decisions that embedded ambiguity so that

01:22:27.160 --> 01:22:34.920
they would need to make the decision all over again, and the processes were that okay,

01:22:36.120 --> 01:22:40.920
they would put forward a proposal where they would try and integrate everybody into the decision,

01:22:41.480 --> 01:22:46.760
and in order to do that they would have to make it ambiguous, which meant that they could not

01:22:46.760 --> 01:22:51.560
implement the decision because it was ambiguous, so they would have to decide all over again,

01:22:52.440 --> 01:22:59.960
and so this is the overall model, but we followed it through empirically with three

01:22:59.960 --> 01:23:06.520
different stages, so here are the three different stages, so this is temporal bracketing, what we

01:23:06.520 --> 01:23:12.760
showed was they went through a process, it produced ambiguity, therefore we had to start

01:23:12.760 --> 01:23:17.400
all over again, and so this is a kind of a temporal bracketing of a process over time,

01:23:17.400 --> 01:23:23.720
and this was very helpful in helping us to understand this process, and the title of the

01:23:23.720 --> 01:23:30.040
paper is escalating indecision, this is what happens when you need to work together, but you

01:23:30.040 --> 01:23:40.840
hate each other, you find yourself in this escalating indecision cycle, the good news is that about

01:23:41.560 --> 01:23:46.920
five or so years after we finished our study, they did actually do something,

01:23:48.840 --> 01:23:53.000
so it didn't, but this was the process that we observed,

01:23:56.520 --> 01:24:04.280
and then you can also compare cases, so you can do it, compare outcomes,

01:24:05.240 --> 01:24:11.640
and if you're doing that you're probably more into explaining variants than looking at process,

01:24:11.640 --> 01:24:18.600
so that's one thing, but you can also use a comparison between cases to show similarity

01:24:19.320 --> 01:24:25.560
rather than difference across different settings, and if you do that then you're demonstrating

01:24:25.560 --> 01:24:32.760
that the process that you're looking at is not just in one case but several, and so that can be

01:24:32.760 --> 01:24:41.400
helpful as well, you can use comparing cases to show variety, you can illustrate richness around

01:24:41.400 --> 01:24:51.400
a similar structure, and you can combine process and variants also, so there are authors who use

01:24:51.400 --> 01:24:59.240
multiple cases to show different processes, but then they they compare the processes and show

01:24:59.240 --> 01:25:04.040
that some tend to lead to positive outcomes and others tend to lead to negative ones, so they're

01:25:04.040 --> 01:25:14.920
combining process with variants, so I'm looking at the time here and I'm going to just skip things

01:25:14.920 --> 01:25:23.000
and move on to my last point which I think is important, because I have all these strategies,

01:25:23.000 --> 01:25:35.000
but at some point that's not enough, and I think it's a really important point that theoretical

01:25:35.000 --> 01:25:42.440
insight does not just emerge, so when you read a qualitative paper that at some point somebody

01:25:42.440 --> 01:25:53.640
always says the theory emerged or the concepts emerged from the data, well yes, no, I mean

01:25:53.640 --> 01:26:02.040
you did this work, and then there's this step which you cannot, you cannot know exactly what

01:26:02.040 --> 01:26:10.280
happened but you saw something, and it's that step that's missing from any of the strategies

01:26:10.280 --> 01:26:16.680
that I've mentioned so far, I called this the conceptual leap, and I wrote a paper on this

01:26:16.680 --> 01:26:29.240
with Malvina Klag, and this is an image in the paper where we point out that making the conceptual

01:26:29.240 --> 01:26:39.000
leap is yes about analyzing your data carefully, about using all of these a priori theories to

01:26:39.000 --> 01:26:45.400
look at your data, about talking to your friends, it's all about doing systematic, disciplined

01:26:45.400 --> 01:26:52.840
things, but it's also about doing unsystematic, undisciplined things like going for a walk in

01:26:52.840 --> 01:27:01.480
the park, going for a run, sleeping, sleeping is excellent when you wake up or you're turning

01:27:01.480 --> 01:27:08.200
over in the middle of the night, that's when you get good ideas, so it's a combination.

01:27:09.240 --> 01:27:14.040
The discipline is really important, and what we've spoken about most today is the discipline,

01:27:14.040 --> 01:27:19.720
but there's also this kind of creative side, and if you don't have that, you won't get

01:27:21.560 --> 01:27:24.760
what we're trying to achieve, so you need this.

01:27:26.920 --> 01:27:35.720
So I'm going to stop there, see we still have 200 people, so I think we might be able to have a

01:27:36.280 --> 01:27:38.600
couple of questions at this point.

01:27:42.600 --> 01:27:43.640
Yes, Alba.

01:27:47.480 --> 01:27:53.000
Thank you so much, Anne, this has been very, very informative, I'm really grateful, and I guess

01:27:53.000 --> 01:27:58.120
we're all really grateful as well. Just one question on the very last point you mentioned,

01:27:58.200 --> 01:28:10.120
which is the creative leap, so I remember writing in one paper about having a creative leap as well,

01:28:10.120 --> 01:28:15.800
but I don't know if it's the way I framed it, but then I got back from the reviewer that even

01:28:15.800 --> 01:28:22.440
though it's a creative leap, I should be able to explain how I got there, and that was a bit

01:28:22.440 --> 01:28:27.960
counterintuitive because that's the point, I can't necessarily explain exactly how I got there,

01:28:27.960 --> 01:28:33.480
which is why it's a creative leap. So do you have any pointers on how to really

01:28:34.440 --> 01:28:39.320
couch it so that it doesn't sound like it came out of nowhere, but then at the same time,

01:28:39.320 --> 01:28:46.920
you don't also try to force fit anything, but then you can show that, yes, it came from knowing

01:28:46.920 --> 01:28:52.280
my data and all of that, but the direct link that you want to see, I can't necessarily show you.

01:28:53.240 --> 01:28:58.280
No, I think what is important to show in a paper is the coupling.

01:29:00.680 --> 01:29:07.080
So the way you found that coupling that you can't explain, but you can show the coupling,

01:29:08.040 --> 01:29:14.520
and that is you must show that the data, if you look at them carefully, you can see the link

01:29:15.080 --> 01:29:21.400
with the theory. So if you can show that link, that's the important thing. You don't have to

01:29:21.480 --> 01:29:28.040
tell them how you actually got there, but if, or you can mention that you had a creative leap,

01:29:28.040 --> 01:29:32.600
but at the same time in the same paper, you have to be able to show that coupling happening,

01:29:32.600 --> 01:29:38.840
so that it's tied up with a bone, so that the reader can see that the data, yes, is a good

01:29:38.840 --> 01:29:44.840
explanation, or the theory is, yes, a good explanation for the data, and the data do justify

01:29:45.400 --> 01:29:48.440
the theory that you're proposing. So it's the coupling that's important.

01:29:49.080 --> 01:29:52.840
Okay, okay, thank you so much. Yeah, so you get your creative leap, and then you go back,

01:29:52.840 --> 01:29:56.120
you mustn't stop with your creative leap, you have to go back and check it out.

01:29:57.000 --> 01:30:01.640
Otherwise, you can go wrong as well. Fardy? Yeah.

01:30:05.560 --> 01:30:06.120
Fardy?

01:30:06.760 --> 01:30:12.440
No, thank you very much, Prof. Really, really interesting and useful presentations, and I find

01:30:12.440 --> 01:30:20.040
them really very, very relevant to my work, because I've been doing quantitative work until

01:30:21.320 --> 01:30:27.640
the PhD had to do process research. One of the things that I'm really keen to do is to

01:30:28.520 --> 01:30:35.240
really make the best decision on which particular vehicle I use to write,

01:30:35.960 --> 01:30:43.720
you know, because I'm using data from several sources over time on how a form of behavior

01:30:43.720 --> 01:30:50.280
continued to take different shapes, you know, in an industry that is trying to be formalized,

01:30:50.280 --> 01:30:58.440
but then a lot of the informal activity kept on happening over time. So the dialectic

01:30:59.400 --> 01:31:09.800
one seemed quite interesting, but my question is, is there like, would you recommend picking a model

01:31:09.800 --> 01:31:22.440
and then trying to write after that model, or how best? The question I think you're asking is,

01:31:22.440 --> 01:31:32.920
where do I start, you know, what does I do first? I think that I would, I tend to start with temporal

01:31:32.920 --> 01:31:42.600
bracketing, because I sort of like to see in the data, what is it, you know, are there turning points?

01:31:45.320 --> 01:31:49.560
And then once I've seen that, if there are no turning points, well, then that doesn't really

01:31:49.560 --> 01:31:59.000
work. Maybe that was kind of a smooth continuity. But if there are any turning points, or, you know,

01:31:59.000 --> 01:32:05.320
whether something happened, like some new people came in, or a new company appeared in your industry,

01:32:05.320 --> 01:32:11.960
or something that changed significantly, more significantly than other events,

01:32:12.920 --> 01:32:21.480
had a potential for change, then those turning points are kind of like a starting point for

01:32:23.720 --> 01:32:30.600
looking at the data. Then you might move towards more detailed coding of what was going on in each

01:32:30.600 --> 01:32:35.640
period. And so you would collect together bits of data, which are relevant to each period,

01:32:36.360 --> 01:32:44.760
and start working on what's going on, what different actors were doing during those periods.

01:32:44.760 --> 01:32:53.080
So, I mean, that's, I think what I would do, but yeah, it depends. I think you have to find

01:32:53.080 --> 01:33:02.280
something where you kind of have something to grab onto. Another approach is to find another

01:33:02.280 --> 01:33:08.920
basis for comparison in your data. So do you want to compare certain types of firms with

01:33:08.920 --> 01:33:15.960
certain other types of firms? You know, if so, can you subdivide your data according to different

01:33:15.960 --> 01:33:21.480
types of firms? Or can you subdivide it in some other way? I think it's very useful to find something

01:33:21.480 --> 01:33:27.720
to grab onto, which you can compare with another thing. I tend to go for temporal brackets, because

01:33:28.680 --> 01:33:32.280
I'm a lot closer. Daniel.

01:33:34.280 --> 01:33:40.040
Hi, Anne. Thanks for a great session. This is a question that came from one of our participants,

01:33:40.040 --> 01:33:49.480
Eva Maria Spreitzer. And her question is, what would you say or what kinds of theories are great

01:33:49.480 --> 01:33:56.520
to inform the coding of the data, such as different levels, depths, etc. And the thinking is

01:33:57.320 --> 01:34:03.880
because it is easy to go from low or tight with concepts or too high or too broad with

01:34:03.880 --> 01:34:13.160
theoretical frameworks or meta theories? Yeah, well, I mean, it depends on the nature of your data.

01:34:13.160 --> 01:34:22.600
But, you know, as I mentioned, you can you can code your data with no a priori theory,

01:34:22.600 --> 01:34:30.840
you can just read it and see what you see. That that's the theory behind grounded coding.

01:34:30.840 --> 01:34:38.840
But if you want to, if you want to develop more oriented coding,

01:34:41.320 --> 01:34:46.840
I mean, think about what it is, what are some of the the concepts that you're interested in. So,

01:34:47.240 --> 01:34:56.440
so if you want to really focus on processes, maybe your coding should be about activities,

01:34:56.440 --> 01:35:01.640
right? So what activities are people thinking about? So that would be one

01:35:02.680 --> 01:35:10.280
angle to look at. So process, process theory is about activities. So can we code activities?

01:35:11.240 --> 01:35:15.960
But you might be interested in something else, you might be interested in emotions,

01:35:15.960 --> 01:35:22.040
for example. So then you might code emotions, and then you might ask yourself, well, what

01:35:22.040 --> 01:35:28.040
emotions are associated with which activities and which events? So, so that then you would code those.

01:35:29.640 --> 01:35:34.200
So, I mean, this is a this is a decision, depending on the on the research questions

01:35:34.200 --> 01:35:40.120
you're interested in. But, but if you're interested in process, I think, I think

01:35:40.200 --> 01:35:46.120
activities, I think events would be things to focus on. I don't know if that's helpful.

01:35:48.200 --> 01:35:52.200
For me, it is. I hope Eva Maria likes the answer also. Thank you.

01:35:54.200 --> 01:35:54.760
Rosala.

01:35:56.120 --> 01:36:03.720
Hi, thank you very much. So my question is about this combining a grounded theory approach with

01:36:03.720 --> 01:36:09.720
the a priori approach. And I was reflecting on on this from a more

01:36:10.840 --> 01:36:16.280
based homological point of view. So as far as understood, one would be more interpreted and

01:36:16.280 --> 01:36:22.600
the other would be kind of more positivist. And I and I, I still struggle to see how can we do that

01:36:22.600 --> 01:36:28.600
and how we can combine both. And I don't know, maybe I didn't get it right. Or maybe you have

01:36:28.600 --> 01:36:34.200
some insight for me. Thank you. Yeah, but I mean, some some theories are interpretive. So I don't

01:36:34.200 --> 01:36:42.600
think it necessarily, you know, means that one is one is more interpretive and the other is

01:36:42.600 --> 01:36:48.360
more positivist. But, you know, there is this idea of induction and deduction.

01:36:50.040 --> 01:36:56.440
But I think that what you need to understand is that even if you are doing an interpretive bottom

01:36:56.440 --> 01:37:05.720
up constructivist approach, you need to connect it to in order to make a contribution, you need

01:37:05.720 --> 01:37:14.120
to connect it to some a priori theorizing. So if you read carefully, even Denny Joyer's

01:37:15.240 --> 01:37:21.000
papers, they are not a theoretical from the start, he reviews, he reviews the literature,

01:37:21.000 --> 01:37:28.920
he comes up with a research question. And his work, his work done with other colleagues

01:37:28.920 --> 01:37:34.280
is cumulative, actually, he's interested in identity or has been interested very much in

01:37:34.280 --> 01:37:38.680
identity. And if you look at each of his papers, they kind of build on each other in many, very,

01:37:38.680 --> 01:37:49.080
very, very many ways. And so they're not, they're not a theoretical. And so I think you always need

01:37:49.080 --> 01:37:59.640
to refer back to other literature. Yeah. But you need to find your sources that fit with what

01:38:00.440 --> 01:38:09.560
you're doing. I think a really interesting body of work, which really shows this kind of bottom

01:38:09.560 --> 01:38:19.000
up top down idea is the body of work on organizational routines, the theory of routine

01:38:19.000 --> 01:38:25.400
dynamics. And so this is always, the studies are almost always qualitative. The notion of routine

01:38:25.400 --> 01:38:34.280
dynamics was developed by Feldman and Pentland. They wrote a very famous 2003 article in

01:38:34.360 --> 01:38:41.800
administrative science quarterly. Other people interested in routine since that time have built

01:38:41.800 --> 01:38:48.760
on that paper and their theory, but each one is making a very distinctive contribution.

01:38:50.440 --> 01:38:59.320
And it's qualitative and it's processual. But the research questions are different, except there

01:38:59.400 --> 01:39:05.800
are some concepts, foundational concepts that everybody is using, that just simply get

01:39:05.800 --> 01:39:14.440
more richer and further elaborated each time. So that might be a good body of work to sort of

01:39:15.080 --> 01:39:24.840
situate this kind of top down bottom up idea against. Thank you very much. If could I add

01:39:24.920 --> 01:39:33.480
a second question? Yes, okay. It's actually more on the practice on the on the coding and analysis

01:39:33.480 --> 01:39:40.120
side. So as a PhD student, I also find sometimes a bit overwhelming to look at different cases at

01:39:40.120 --> 01:39:47.880
the same time. And so I was trying to playing around with different approaches. And I was wondering

01:39:47.880 --> 01:39:52.680
if you have any suggestion to maybe start from one case or actually know it's much better to

01:39:52.680 --> 01:39:56.600
look directly through all of them. And what's your opinion on that? Thank you.

01:39:59.400 --> 01:40:06.520
Yeah, I don't know. I think it depends a little bit on whether you want to explain each case

01:40:06.520 --> 01:40:13.880
individually and maybe think of them as separate contributions or whether the comparison is really

01:40:14.520 --> 01:40:20.360
critically important to you. And then you want to keep it keep it going. But I mean, another

01:40:21.320 --> 01:40:26.440
I think Daniel asked this question, you know, no, it was someone else who asked the question,

01:40:26.440 --> 01:40:31.160
where do you start? And I said temple bracketing and another another way to start is just to

01:40:31.160 --> 01:40:37.560
write these narratives for each of your cases. That's that's so helpful. If you have different

01:40:37.560 --> 01:40:46.680
cases, write the narrative, put quotes everywhere. In the narrative, you know, let's let's just tell

01:40:46.680 --> 01:40:50.840
the story. And, you know, all the quotes that you think are so great that you absolutely need to

01:40:50.840 --> 01:40:56.520
use them, you put them in the narrative. And then you've got this kind of secondary database where

01:40:56.520 --> 01:41:05.000
you can compare the narratives. And so that becomes then you can write new tables that compare the

01:41:05.000 --> 01:41:12.120
narratives. So you can look case one, case two, the first phase, the second phase, and then it

01:41:12.120 --> 01:41:16.120
becomes organized. But narrative can be a great way to get started as well.

01:41:19.560 --> 01:41:25.400
Loreto. Hi, thanks, Anne. It's a really brilliant presentation. I'm really going to help with my

01:41:25.400 --> 01:41:30.520
my projects that I'm doing at the moment. So thank you. And I'm my questions more about the

01:41:30.520 --> 01:41:37.080
endpoint and about where where to get published and where you think are kind of the journals that

01:41:37.080 --> 01:41:46.520
are more aligned to process research. Thank you. Well, it depends what your field is. I'm in the

01:41:46.520 --> 01:41:58.280
field of management. So the the North American management journals, like Academy of Management

01:41:58.280 --> 01:42:05.800
Journal and Admirative Science Quarterly and Organization Science, have they published all

01:42:05.800 --> 01:42:09.880
kinds of research, they published quantitative and qualitative research.

01:42:12.120 --> 01:42:18.440
And they have editors who are dedicated to qualitative research. So I am an editor at

01:42:18.440 --> 01:42:24.040
Academy of Management Journal, and I am dedicated to qualitative research. And we have five,

01:42:24.680 --> 01:42:32.520
we're a team of five editors that consider qualitative research. And it would be the

01:42:32.520 --> 01:42:38.520
same in the other journals I mentioned. And so although they published a lot of quantitative

01:42:38.520 --> 01:42:42.920
research, they also published much a great deal of qualitative research. So that that's a good

01:42:43.480 --> 01:42:51.640
place to go. Many of the European type journals are more qualitative oriented than the North

01:42:51.640 --> 01:42:59.240
American ones. So organization studies is a great journal, journal management studies are

01:42:59.240 --> 01:43:05.400
great journals for this work. I'm not sure that I think what in order to decide which kind of

01:43:05.400 --> 01:43:14.200
journal you want to publish in, it's a good idea just to read, you know, those journals and see

01:43:14.200 --> 01:43:22.760
where you see things that that correspond to your interests, and that you think that you can relate

01:43:22.760 --> 01:43:31.640
to. So some journals have more of a sociological flavor, and they may relate more to sociological

01:43:31.640 --> 01:43:37.400
literatures, some are more managerially oriented. And there are delicate differences that you need

01:43:37.400 --> 01:43:43.720
to kind of get familiar with. And it's very difficult to pick one. But all the journals I

01:43:43.720 --> 01:43:53.320
mentioned, and others as well, are very open to process research. Yeah, you might if I mentioned

01:43:53.320 --> 01:43:59.160
some that probably less so, I mean, in general applied psychology might not be so open to it,

01:43:59.160 --> 01:44:07.160
I don't know. Yeah. Some I interrupted somebody, Patrick.

01:44:07.160 --> 01:44:16.280
Yeah. Thank you very much for your very, very brilliant presentation. I have a pretty basic

01:44:16.280 --> 01:44:25.320
question that has been very, very confusing for me, which is, how do you do process to arrive in

01:44:25.320 --> 01:44:36.760
from a one of interview, where the respondent is talking about how they make decisions within

01:44:36.760 --> 01:44:44.360
the organization. Clearly, this person is talking about a process, right, and how they

01:44:44.360 --> 01:44:52.520
finally arrive at a conclusive decision. But this is a one of kind of interview. So how do you

01:44:52.760 --> 01:44:59.960
do process to arrive in from such a data? Well, I don't think you can. I mean, because you only

01:44:59.960 --> 01:45:07.800
have one person, but you can you can represent that person's theory of decision making.

01:45:09.240 --> 01:45:15.400
So so you could. And if you have several different people, you can look at their theories of

01:45:15.480 --> 01:45:22.760
decision making so that that they are they are suggesting the stages that you go through and

01:45:22.760 --> 01:45:28.200
things like that. What I think, you know, when you're looking at an interview,

01:45:29.560 --> 01:45:41.240
is that there are two ways to develop theory from an interview friend, kind of data. One is to

01:45:41.880 --> 01:45:48.920
take the generalizations that the person is telling you. So let's say the person says, oh,

01:45:49.880 --> 01:45:57.720
we always make decisions in. We have a committee, and we make the decisions in the committee.

01:45:58.600 --> 01:46:04.440
Okay, so you could read that and think, okay, they make decisions in the committee. So I'm

01:46:05.240 --> 01:46:10.680
generalizing from the generalization of the. Responder.

01:46:12.760 --> 01:46:19.240
Or instead of doing that, and I think that this is much better, is that you have the

01:46:19.240 --> 01:46:27.480
accounts of that individual of several specific decisions. So this happened, this happened,

01:46:27.480 --> 01:46:32.280
this happened, this happened, this happened. The second decision, this happened, this happened,

01:46:32.280 --> 01:46:36.360
this happened, this happened, this happened, this third decision, this get them to talk about

01:46:36.360 --> 01:46:44.680
lots of different decisions. Then real months, concrete months, then you generalize from their

01:46:44.680 --> 01:46:51.960
stories, not from their generalization. See what I mean? It makes a huge difference. So if you,

01:46:52.600 --> 01:47:02.200
if you're talking, if you're using an interview, get the stories. And sometimes you do generalize

01:47:02.520 --> 01:47:09.080
from other people's generalizations, but it's much better to get, get as close as you possibly can

01:47:09.720 --> 01:47:17.720
to the actual events and the accounts of the actual events. And you're getting deeper when

01:47:17.720 --> 01:47:24.440
you're doing that. I don't know if that's, that's helpful. Thank you very much. That was very, very

01:47:24.520 --> 01:47:33.560
helpful. So how are we doing? Anyone?

01:47:40.920 --> 01:47:43.880
I'm just looking, is there something in the chat which I should respond to?

01:47:45.560 --> 01:47:50.600
Underworld questions. Isidora. I'm not sure we'll have time for that. Yeah, Isidora.

01:47:51.560 --> 01:47:59.080
Hi. Thank you for a great presentation today. I believe this is a very broad question, but if

01:47:59.080 --> 01:48:05.240
you can just give us sort of just your general opinion, I'm really interested about quantification

01:48:05.240 --> 01:48:12.360
of qualitative data. I have thought about it in one of my previous research, but I opted against

01:48:12.360 --> 01:48:18.440
it because of all the division of whether this is a right research strategy. So I just wanted

01:48:18.440 --> 01:48:24.440
to hear your opinion on it and maybe if you can suggest some kind of resource that would be valuable

01:48:24.440 --> 01:48:30.840
in sort of providing a starting point for that. Yeah, so thank you for the question because one

01:48:30.840 --> 01:48:36.200
of my strategies was quantification and I didn't talk about it. And I didn't talk about it because

01:48:36.200 --> 01:48:44.920
I'm not particularly fond of it. But I do think quantification can be useful. And when is it

01:48:44.920 --> 01:48:52.360
useful? It is useful. It's not useful in the description. It doesn't, it doesn't make any,

01:48:52.360 --> 01:48:57.400
you don't need to count anything if you just want to describe phenomena or or

01:48:57.400 --> 01:49:03.560
types of events that happen. You don't need it. Where you do need it is where you want to say,

01:49:03.560 --> 01:49:12.440
okay, say is more of a success than case B or some kind of way of judging differences

01:49:13.240 --> 01:49:24.040
that is along a scale. Then you have to find ways to do it. And so, for example, I recently did a

01:49:24.040 --> 01:49:33.320
study with a colleague, which was about, it was an 18 year history. So it's kind of a process

01:49:33.320 --> 01:49:44.040
study of how managers cited their founders in their discourse in their communications.

01:49:44.040 --> 01:49:50.600
And we wanted to show that the way they cited them changed over time. And in order to do that,

01:49:50.600 --> 01:49:57.880
we had to count them. We had to code them into categories and count them to be able to demonstrate

01:49:57.880 --> 01:50:01.960
to the reader that it's actually true that we were saying they were more like this than they

01:50:01.960 --> 01:50:10.680
used to be. And so, counting gets important them. And when you're counting, you know,

01:50:10.680 --> 01:50:17.560
enter, rate, or reliability starts to get important because the precision is important.

01:50:18.280 --> 01:50:25.480
So then you need to go to resources that can talk to you about, you know, very

01:50:26.360 --> 01:50:33.480
content analysis type coding where you have categories, and you need to be able to show

01:50:33.480 --> 01:50:44.040
that these categories are reliable, valid, and so on. So I would look, you know, on the, on Google,

01:50:44.040 --> 01:50:50.760
I would Google content analysis, probably Krippendorf would be a good author for that,

01:50:51.480 --> 01:50:58.600
talking about how you would take qualitative data and then use it to quantify certain concepts.

01:50:58.600 --> 01:51:04.280
But I wouldn't do it unless you really need that comparison. A is bigger than B.

01:51:06.280 --> 01:51:14.040
Otherwise, one of the reasons I don't like it is you take out all the ambiguity. You take,

01:51:14.600 --> 01:51:20.040
if you put things into categories and count them, all of the richness of your data kind of

01:51:20.040 --> 01:51:28.200
disappears. It just has to go because the obligation to be able to find exactly the same

01:51:28.200 --> 01:51:34.760
number as your colleague means that you have to make things so clear that there is no possible

01:51:34.760 --> 01:51:40.440
doubt that you have categorized correctly, which means that all of the ambiguity and fluffiness

01:51:40.440 --> 01:51:49.480
and richness goes. And that's not good. Qualitative data is qualitative. It's not quantitative.

01:51:49.480 --> 01:51:56.840
So it's a good thing if you need to do that comparison. But if you don't, don't do it,

01:51:56.840 --> 01:52:04.040
just to do it. It's not worth it. Okay. Yeah, thank you so much. Yeah, I think I

01:52:04.040 --> 01:52:11.000
should have decided against it simply because the essence and the nuance within each of the,

01:52:11.000 --> 01:52:16.040
you know, qualitative aspects sort of gets lost. But I still think that it might have been an

01:52:16.040 --> 01:52:23.560
interesting strategy to show intensity of a certain outcome. Exactly. That's what I think.

01:52:24.360 --> 01:52:29.720
One person who does it very well and still keeps the richness is Stephen Barley. So if you look

01:52:29.720 --> 01:52:35.080
at many of Stephen Barley's papers, he's real. He's a fantastic qualitative researcher, but he

01:52:35.080 --> 01:52:44.280
also counts things. And as a great paper recently in Academy of Management Discoveries about buying

01:52:44.280 --> 01:52:54.200
cars. But he does a lot of qualitative analysis, but also does counts. So that might be a good example.

01:52:55.400 --> 01:52:58.440
Okay. Thank you so much. Burak.

01:53:01.720 --> 01:53:08.600
Thank you very much. I have a brief question. It's about the lens. You mentioned about the theoretical

01:53:08.600 --> 01:53:15.560
lens. How about the paradigm as the lens? And combined with the theoretical lens, would you

01:53:15.560 --> 01:53:24.920
please elaborate differences and similarities? How do we use them? Thank you. So you're referring

01:53:24.920 --> 01:53:32.680
to whether you're having a critical paradigm or you're adopting a interpretive paradigm or a

01:53:32.680 --> 01:53:43.400
positivist paradigm. Yeah. So I'm agnostic as to which one you might want to adopt. And it's also

01:53:43.400 --> 01:53:49.800
possible to play with them. So you can pretend, you know, you can say, okay, today I'm a positivist.

01:53:49.800 --> 01:53:56.280
If I were a positivist, how would I consider these data? Now I'm a critical theorist. How would I

01:53:56.280 --> 01:54:05.480
consider those data? So you can do that. And it certainly would help you see, it would get you

01:54:05.480 --> 01:54:12.360
to ask different questions about the data. So if you're a positivist, you're going to be asking,

01:54:12.360 --> 01:54:23.160
what is the truth? Right. And if you're an interpretive, it's how are people seeing things.

01:54:23.160 --> 01:54:27.800
And if you're a critical theorist, you would ask yourself, well, who is winning and who is losing

01:54:27.800 --> 01:54:37.400
in this? And so you ask yourself different questions. And I think that's hard to do within a

01:54:37.400 --> 01:54:44.440
single paper, but it could be something that you could try and, you know, sort of play around

01:54:45.800 --> 01:54:52.520
with those approaches. I mean, you can do the same thing with an interview. Take an interview.

01:54:52.600 --> 01:55:02.440
Look at the interview. What if this was true? The person is telling me. And how can I know

01:55:02.440 --> 01:55:08.040
that it's true? And if you're looking at an interview positivistically, you will say, well,

01:55:08.040 --> 01:55:15.160
only the things that are about verifiable facts, I know are to be true. And in order to find out

01:55:15.160 --> 01:55:21.720
whether it's true, I will need to find someone else's view or I will need to get other data.

01:55:22.280 --> 01:55:30.280
If you look at an interview interpretively, you would think, well, no, I don't really need anybody

01:55:30.280 --> 01:55:34.280
else's opinion, because I'm only interested in their interpretation. And I'm not trying to do

01:55:34.280 --> 01:55:41.720
anything wrong. And if you were to look at it critically, yeah, if you were looking at it

01:55:41.720 --> 01:55:48.280
critically, you would be very skeptical of what that person is telling you. And you would be asked,

01:55:48.280 --> 01:55:52.120
now, why are they telling me this? What is it they're trying to convince me of?

01:55:54.280 --> 01:56:02.680
That you would look at it in a much more skeptical manner. So just thinking about those

01:56:02.680 --> 01:56:06.520
things, even on one interview, it can get you to see things different.

01:56:08.520 --> 01:56:14.840
See, exactly like the example that you gave about the hospitals merging, like for example,

01:56:14.840 --> 01:56:21.160
in this case, we can try to understand the phenomena of decision making from, you know,

01:56:21.880 --> 01:56:27.640
generative constructionist perspective. But also we can look at it from a conflict paradigm,

01:56:27.640 --> 01:56:33.480
meaning that decisions are going to create conflicts. So in this case, our theoretical lens

01:56:34.120 --> 01:56:42.520
would be different, depending on the paradigm. Yeah, indeed. Yes. I agree.

01:56:42.520 --> 01:56:52.200
Thank you. Thank you. Thank you.

