So, to get us started and to make sure that everyone is reasonably on the same page, what
is the process for that?
So, here are some definitions that come from an article that I did with Clive Smallman,
Harry Tsoukas and Yvonne Devane in 2013.
So, process thinking implies considering phenomena as in motion, as unfolding over time as becoming,
and process researchers seek to understand and explain the world in terms of activity,
temporality, and flow.
So, basically, we're looking at things moving.
And I have two images that would reflect what I've just said here.
They have slightly different foci in terms of what we mean by process.
And I'm just going to show the two images.
And what I'm going to talk about today really kind of applies, I think, to both of them.
So, the first image is this idea of process as evolving over time.
So, you have a phenomenon in one state, and you're interested in looking at how that phenomenon
evolves through events, activities, and choices.
And if you are adopting a process perspective, you're going to be focusing on those events,
activities, and choices as your data and the elements of your theory.
So, not talking about dependent variables and independent variables, we're talking about
things that happen, which are quite different.
So, that's the first image.
The second image, which is now on the screen, is this idea of process as activity and flow.
In other words, this process as all there is, everything is made up of processes.
So, this is a second image of process, and some people call this a strong process approach.
And I really like this quote from Russia, 1996, which kind of reflects this.
So, the river is not an object, but an ever-changing flow.
Things are made up of processes.
The sun is not a thing, but a flaming fire.
Everything in nature is a matter of process.
So, this second image really looks at phenomena as processes,
rather than looking at phenomena.
It's changing over time.
So, these are two different ways of looking at process.
That's just the backdrop.
I'm now going to look at the implications of this for methodology.
So, if you are taking a process perspective, you want to capture that activity and flow.
And so, you're going to collect data, and what are your data going to look like?
Well, typically, process data involves at least three different kinds of things.
So, the first kind of thing that you might collect is observations in vivo.
So, you are looking at things in real time.
You might be going to meetings, capturing conversations, capturing events,
shadowing people in the things that they do.
And so, part of your data is likely to be observations.
A second way of collecting process data is to build on people's memories and interpretations.
And you do this through interviews, diaries, focus groups, questionnaires,
all kinds of ways of getting at how people understand what is happening,
what has happened, and how that evolves over time.
And the third way is to look for artifacts.
So, artifacts that were created at moments in time that we can actually timestamp
so that we know when they happened.
So, things like minutes of meetings, or recently we've been using emails, reports.
So, all of these sources of data, and this presentation is not about data,
so we're not going to spend a lot of time on this.
But all of these sources of data are complementary.
They provide different strengths and weaknesses.
An interview has problems because of memories.
People don't necessarily remember.
But if you see something, you observe it, then that can compensate for that, and so on.
So, these three, I call them the big three,
sources of data for qualitative research more generally, and for process research more particularly,
we're going to be using them if we want to develop process understandings.
And if you think about it, if you've got all of these three sources of data,
got interviews from all sorts of people, you've got observations from all sorts of events,
you've got documents and emails, what is the result of that?
It's a total mess.
So, and it's shapeless.
You've got all these separate bits and pieces.
So, the question then is, what are we going to do with that?
And so, this is what this webinar is really all about, is what we do then.
And what we would like to do is move from that mess, the cloud of miscellaneous stuff
that we had collected, to something which is understandable, abstract, generalizable,
a theory. Some kind of theorizing is what we seek to do. So, the question is, how do we move
from that mess to something which is much more defined, posimonious, clear, and so on.
So, here's a picture of what we're trying to do. This is our challenge. We have to move from
something on the left, that is concrete, very specific, it's rich and it's messy,
to something on the right, which is abstract and novel. And the process for doing that,
okay, for connecting the concrete, rich and messy, and the abstract and novel,
it has to be credible, right? We have to couple the two, so that a reader of our work, our thesis,
or our article, can actually see how we've done this, that we have started from a mess,
we have ended up with a theory, and that the coupling, the way we have joined the two, is credible.
But creative slightly, because if we're not producing anything new, then why would we
be doing this? So, that's the challenge. And starting from that point, there are several
things that can go wrong. So, I'm just going to give you a little portrait of some of the things
that can go wrong with that, and that we're going to try and avoid. So, the first thing that can go
wrong is that we have wonderful concrete, rich, messy data, and beautiful abstract novel theory,
but we haven't properly connected the two. And so, that is a very easy mistake to make.
We can look at our data and be inspired vaguely about some kind of theory,
but we haven't shown tight connections between the two. So, that's loose coupling. That's
blind alley one. I need to be careful with that. So, blind alley two is that we code the data to
death and end up with something which actually doesn't reach beyond the data. It is just descriptive
and dull. And that's very easy, too. If you, in a certain sense, if you stay too close to your
data, this is what happens to you. You don't reach beyond it. So, you just have codes,
lots of codes and descriptions, and you've got tight coupling. Nobody is going to question
whether you have accurately reflected your data, but your data is not saying anything at this point.
It is just not descriptive. So, it doesn't work either. And then the third one, which is a little
bit more difficult to understand, my diagram isn't great. It's when you impose theory on your data.
So, you see some theory that you think might be relevant to your case. You draw a wonderful conceptual
framework beforehand, which is showing all the relationships that you think are going to be
there before you do your study. And then lo and behold, when you do your study, you take the
concepts that are in your conceptual framework, impose them on your data, and you say, oh, look,
I thought I would get this. Look, I got exactly what I thought. And what you've done there is you've
squeezed the richness out of the data. You've squeezed out everything that could give you new.
So, I call this circular coupling. And it's actually quite a common problem.
And I've seen it myself, and I got trapped in it myself. And the reason one gets trapped in it is
because thesis advisors naturally want students to look as if they know what they're doing before
they do their study. So, in their proposal, there will be this complex theoretical framework. And
that becomes the thing that drives the research. And if it drives the research too much, you already
end up with what you started with. And that will not make a strong contribution. So, those are the
different problems that might arise. And we're now going to talk about some of the ways that we might
try and do something that would lead us to the first diagram, which is
concrete, rich, messy data, abstract and novel theory, and credible but creative coupling, which
is kind of what we're trying to achieve. So, in order to talk about this, I'm going to rely a
lot on a paper which some of you may have read, which is my 1999 piece, which is a published
in the Academy of Management Review, which was titled, Strategies for Theorizing from Process
Data. It's now about 24 years later. Some things have changed, but I still think that
those ideas have value. And so, I'm going to start from those ideas and give you some thoughts about
my more recent ideas around that and experience around trying to use those ideas. And these are a
set of ideas. And so, I'm going to put them forward. I'm going to point you towards sources
that might help you with some of these ideas about how to do this. I'm not going to give you
a complete recipe. I'm going to give you these ideas. And these are things you can mix and match
and work with. And we'll look on do this now. And I'm going to... Let's see.
Okay. So, this is a list of the items that I included in the 1999 paper, which I called
Strategies for Theorizing from Process Data. And there were seven of them. And so, you can look at
them and you can sort of group them into three areas. And so, the first two that you see there,
I call them grounding strategies. And they were actually about coding. So, the first one,
grounded theory, is this idea that you're going to start with the data and you're going to build
your theory bottom up from the data. The second one is kind of a different way of looking at it.
Instead of building up your theory bottom up, you're going to take a priori known theoretical
lenses and fit them to the data top down. And if you do it with more than one, that enables
you to see which one fits best. So, I see these two as kind of opposites of one another,
theorizing from the bottom up, theorizing from the top down. And we're going to talk about those
first. The second two, I see as ways of displaying data. So, you can display data either as a story,
as a narrative, you can construct a narrative from your data, or you can try to draw them
using visual mapping. So, I see those two as kind of opposites of one another as well.
And then the last three are all about comparing data. And for me, comparing is really the essence of
this thing that drives, for me, it drives theorizing. When you're comparing two things,
you immediately ask yourself, why are they different? Why are they similar? What is it that
explains that? So, as soon as you start to compare, it really is a great stimulus for theorizing.
And I introduce here three different ways to compare. So, comparing cases, comparing
this notion of temporal decomposition or temporal bracketing, which is comparing phases,
and the last one, quantifying. And so, that's the kind of portrait of these seven
approaches that you can use to data. And of course, they are not, you don't pick one and then use it.
All right? You do all of these things when you are trying to theorize from process
stage. And it's a very iterative process and you move between them. So, I have this,
in my next slide, I have this diagram, which expresses that. So, on the left, you have what
I call the grounding strategies. In the middle, you have the organizing strategies, which are
useful for displaying. And on the right, you have the comparing strategies. And you can do them in
any order. I put the diagram from left to right, because I think there's a sort of a progression
from coding to displaying to comparing, which I'm going to put coding, displaying, and comparing.
I think there's a progression. But that doesn't mean you might start at a different place.
Okay. So, let's start with coding. And so, I'm going to talk a little bit about
coding process data. And then we'll stop and take some questions and have some conversations.
And then I'll talk about the other two after that. So, let's start with coding.
So, there are these two strategies that I mentioned, grounded theory and alternate templates.
The grounded theory idea is from the bottom up. And alternate templates is taking the top down,
where theory is at top, and data at the bottom. Okay. So, let's look at grounded theory first.
So, grounded theory means building from the bottom up. So, you have no a priori framework.
And there are some classic authors that have talked about that. So, Corbin and Strauss,
Charmas, and more recently, Denny Joyer and colleagues,
Emma Hamilton, and Kevin Corley have this organizational research methods piece,
which explains how to do grounded theory. And it's become really dominant
in the field of qualitative research. And I'm an editor at the Academy of Management Journal.
And I see that, you know, one, I am an editor for all the qualitative papers. And I would say that
one paper out of two has one of Denny Joyer's diagrams. And I just want to say, before I
start talking about that, that that is not absolutely required to publish a paper.
But it is a very common approach, and it has all kinds of benefits. And grounded theory,
the tools like Atlas, TI, NPVO, MaxQDA, etc., are great for managing your coding. They don't do it
for you, but they manage it. I haven't yet got into chat GPT. And maybe there are some
opportunities there to see what chat GPT can do for you in terms of coding. That's the kind of
life on the front there. And I think there are people who have already started looking at that.
I'm not looking at that here. So that might be an issue that we might want to get to.
So I'm going to talk a little bit about the Joyer method. For those of you who haven't
seen it before, so that we can see what this method is about. So
a really great example of the Joyer method is the 2004 paper by Corleone Joyer on identity
ambiguity in administrative science quarterly. And I use this as an exemplar of the type of
bottom-up coding that dominates a lot of process research, as well as any other qualitative research.
So this method involves three types of artifacts. And the most famous one is this one.
And this is a coding approach, which is so elegant. What you can see here on the left,
the first-order concept, is how a researcher takes their original data and looks at the data in Vivo
and codes it into the first category. So there may be lots and lots of first-order codes.
You're going to have hundreds of them. You start doing that. You start coding bottom-up in Vivo.
You end up with far too many codes. But that's okay, because then you group them.
And so you come to the second-order things. And so they look at the similarities and differences.
You put them together. You group them. And then you do that the third time. And you can do it
the fourth time. You can do this any number of times you like. And what you have on the right
then is some key concepts that are going to become the essence of your theory. And so the
brilliance of this is it shows you exactly how you move, in theory, from your original messy,
concrete data to some abstract concepts. And it shows the pathway. So that's the first artifact.
And unfortunately, a lot of researchers kind of stop there. They show you the data structure and
that's it. A second artifact is actually showing the link between the two. So here this is in the
paper. It's just an example. They've got their concepts. And here you've got quotes that reflect
those concepts. So that's the second artifact. And the third artifact is taking the second order
and themes and the third order, the overarching dimensions and creating a process model with them.
So they didn't see the flow between all of the concepts in the paper. And there you can see how
Pauli and Joya have brilliantly started with a database of just a mess. They had observations,
they had documents, they had interviews, and they generated these concepts. And here is the
theoretical model at the end. So this looks wonderful, right? What you don't see in the paper,
of course, is all of the back and forth that they must have had to do to get the
to the data structure in the first place. This does not suddenly appear, right? You need to
know what you're doing. So this is much more complicated than it looks. So looking at this
approach, it's really a brilliant approach to show in an in a paper the rigor of your coupling
between the data and your theory. One of the things that have been said about it and I share
this concern is sometimes if you've got these concepts, you're glossing over, for example,
the conversations, the interactions, the interactional details, you have labeled everything
in terms of concepts, and you may be missing the temporality and the dynamics through this process.
So that can be a concern. And you could code differently, though. You could code
recently in a study, instead of coding things that people said, we coded the interaction.
And so there would be different types of interactions. So then you've got some of the
dynamics included in the in the story. So and the other thing is if this is entirely uninformed
by any other approach, my concern is that if you're just doing bottom up coding,
just starting from your data, and you think that the theory is going to kind of result from that,
you're going to run into Brian the Blind Alley, too. And Cooley and Joya do not do that because
they are theoretically informed. They're not, they're not starting their study from from total
scratch, even though so the the idea that grounded theory is from entirely bottom up is not quite
true. There are always efforts to connect to existing theory, and we should never forget that.
So just doing coding is not going to get you to an interesting bottom up coding is not necessarily
going to get you to an interesting process theory on its own. And it's very iterative,
and you have to keep going back and forth, and so on. So that's that. That's the final comment
there. So here we've just so far talked about the bottom up side. Let's now talk about the top down
approach, which is a little bit different in terms of coding. So we're going to look at
alternate templates, which is my strategy to. So the idea here, when I wrote the paper in 1999,
was this idea that you could, you could fit one I a priori theme theory to your data. But what's
probably more interesting is trying to apply more than one. Because if you do that, you will get to
see your data in different ways, you might even be able to verify which which theoretical framework
is more appropriate fits better. And doing this coding based on any priorities frame
frame can be very useful for doing that. And the classic inspiration for this is a book which I
recommend everybody read, which is by Graham Allison, and just the essence of decision.
And he's a political scientist. And he studied the Cuban missile crisis, which is an event which
I'm old enough to have lived through, although I was a child in the 1960s.
When nuclear missiles were placed in Cuba, and the United States had to decide what to do about it.
And what what Allison did is he got access to a huge amount of documentary data on this.
And analyzed it according to three different theoretical frames. And the first theoretical
frame was the rational actor model. So according to the rational actor model, countries are rational
actors. So countries consider the the alternatives they have available and pick the best one.
So the whole assumption is that the country is one one actor.
The second theory they applied to that this was to say no, no, no, countries are not actors,
countries have bureaucratic organizations that are part of them. So for example, the US has the
Pentagon, the military that are doing one thing. They have Congress that is doing something else.
They have the president who is doing something else. All of these individuals have their own
routines. All of these groups have their own routines that they know how to do. So the military
knows how to do an invasion. They know how to do a blockade. And if they're given the right stimulus,
they will execute the bureaucratic processes that they know how to do. And so the second
explanation was really a March and Simon based bureaucratic model. And then the third one was
political. So they were looking at individuals, what their individual interests were and how
those interacted. And they applied these three models to the same data and ended up with three
different stories, which they kind of argued in the first version of their paper, we should
keep separate because they enable us to see different things. These things are not wrong.
They're just lenses for looking at things. And having different lenses to look at things
is insightful. So this is this is a completely different approach because you are starting
from the theory and not from the data. This is an approach that probably, in my opinion,
we don't use enough. At least, and it's one of the reasons is it's very hard to
introduce three different theory of theoretical frames into a 40 page article. It's not possible.
But you can do it in a thesis much more easily. And that can be the basis for three different
articles. So that so this can be used more. I have an example here of a single paper where they
looked at three different frameworks. And this was an organization of science. It was by two
colleagues of mine in Montreal, Suzanne Duvara, who said that she said Maria, and yet the point
who is at McGill. And they studied the implementation of computer systems in in in hospitals. And they
considered three different theoretical models for understanding that. And the first one was that
this was a problem of people. And so that model was about how individuals cognitively related to
an information system. So if you wanted to understand if it was implemented or not,
you had to see how people found it useful or not, essentially. And it was basically a question of
whether different individuals could cognitively absorb the implications of the information system.
And so in order to code for that model, they coded by individuals, right, they had the list of
individuals, they considered the elements that are in the model. So there were four elements in the
model, they coded them systematically, and look to see how that worked. The second one is a
political model. And the theory behind that is that people will resist information systems that
take power away from them. And so, and they looked at different groups, so they looked at doctors,
they looked at, they looked at administrators, and how they were reacting to the information
systems over time, and considered whether this model might explain things. And the third model
is an organizational design model developed by Henry Menzberg. And here they were trying to consider
whether the organizational form was having a difference to the implementation process.
So they basically tested, and in this case, it was a test. It was not really different lenses to
enrich, to accumulate, to have three different explanations, but they tested the value of each
of these three models on the same data. And came to the conclusion that in the early phase of
implementation, it was one model that dominated in another phase, it was the second model that
dominated in the third phase, it was a third one. So that in the end, this enabled them to generate
a really interesting theoretical framework, which showed how the importance of different
processes evolved over time. So that's an example of how you can and do that.
And before I move on from this, I wanted also to draw attention to Andy van der Ven's work.
Unfortunately, we lost Andy van der Ven last year. But he has made a fantastic contribution to
process research. And one of his papers, which I really find at the same time, extremely stimulating,
but at the same time, I've always questioned it a little bit, is a piece of work with Marshall
Scott Poole, where he proposed four different theoretical, possible theoretical models of
process. And in terms of thinking about alternate templates, these are really, really useful.
These are classic process theories. And I'm just going to give you an illustration. And I actually
used this recently in a study with a colleague from University of Gothenburg, and we were looking at
migrant workplace integration in Sweden in organizations. They've had many, many refugees
come to Sweden and organizations and governments are struggling with how to ensure workplace
integration. It's clearly an important factor that can explain whether refugees can adapt
to a society. So van der Ven and Poole identified these four classic process models. They called a
life cycle process, a learning process, an ecological or evolutionary process, and a
dialectic process. And I have little diagrams which illustrate each so that we can just sort of see
what the kinds of frameworks might be. And these are really useful kind of heuristic ideas about
how you might consider your process data. So the first one is, it's a process that evolves over time
in a predictable way. So, you know, you're a refugee into a country, you try and get a job,
you go through certain processes of development, and at some point you reach a level of maturity
as integrating into your workplace. So this is a very linear process model, and it assumes that
there are kind of deterministic phases through which you pass. So that's one way of looking at
process. It's probably the simplest way, and many process models, the first iteration, that's what
they look like. It's maybe not the most inspiring in terms of understanding the complexities.
So that's one type of model. A second type of model is this idea of learning.
Van de Verden and Poole call it a teleological model. I like to think of it as a learning model,
because I think it's easier to understand, which is that you have an objective, and it's all about
agency. You have an objective, you form a plan, you try to execute it. If you are able to execute it,
so much the better, you continue, and if not, you change your plan. So it's a circular model,
really. I think that those of Edward Deming, it's a little bit like that. It's learning.
It's you plan, you do, you check, and you act, and then you plan, and you do, and you check and act.
So, yeah, migrants who arrive in a new country are doing learning as well,
and companies who are trying to develop processes to support workplace integration are
also doing learning. And so you could apply it to different levels. And so this is another
process model that you can consider. The ecological process model that they propose is this idea
of survival of the fittest, Darwinian processes. And so you start with variation.
So let's take innovation. You start with many, many, many different ideas for innovation,
but some of them fit better with the environment than others. And so the ones that do get selected
and the ones that don't get thrown out. Okay, here's the third one. Unfortunately,
Darwinian selection applies equally to migrants' integration processes. So there are
selection mechanisms, which mean that not all people manage to become integrated. And so the
integration is a very selective process, in fact, when you look at it carefully. But that's
is another model that can help explain what is going on. And then finally, the dialectic process.
So the whole notion of the dialectics is two systems or two sets of objectives that are in
conflict that collide. And so the driving force of a dialectic process model is contradiction.
And contradiction generates something else. What it will generate, you don't quite know.
And so this is the model that actually my colleague at Gothenburg, Bedran Omanovich and I found most
useful. And so our model is more of a dialectic model. And the idea here, we look at the socio-political
context. We look at tensions between management interests and migrant interests, which generate
different factors and patterns of integration. They generate tensions. These tensions give rise to
either transformation or perhaps reproduction, depending on the power dynamics. So a dialectic
process model is very much oriented around process dynamics. So what you see here is, you know,
four kinds of a priori ways that you might think about process. And I think that these are generative.
And the only thing I would say is, I think there are not just four.
So you could apply. There are many a priori process models out there.
Vandevan and Poole would argue that all of these are combinations of these four. But sometimes it's
interesting to consider them on their own merits. So I've always found actor network theory to be
an interesting theory. It's a process theory that might apply here as well. So the basic idea is
taking theories and trying them out is very generative in terms of process theorizing.
This is the point I make here. The only problem, and this is if you try to impose
one theory onto your data and match it, what you're doing is you're just labeling things.
And so that's why more than one or doing top down, but also doing bottom up as well is much more
likely to give you something that corresponds to our ideal portrait. The danger of imposing
one model is that you end up with the richness squeezed out. Looking at several, you can tell,
I mean, if you could look at my diagram, you could see that you would get several different
circles on there, and that might on the left, on the bubble on the left, and that might do a better
job of understanding your whole process. So again, this is not a mechanical linear exercise, and
there's a lot of value of iterating with the ground at the bottom up coding as well. And then
that sort of raises the question, how do you do this? Because you're doing bottom up, you might be
doing some top down coding as well. And I have another example here, which kind of is really
interesting. It's a paper by Kaplan and Olikowski, where I think the reviewers of the paper must have
asked them to explain that coding process. And so they've introduced this diagram in an appendix,
which explains that coding process. And their final model is the little diagram in the bottom
right of that picture. And what you see all of the circles, you know, where the circles going
around is showing how they iterated between bottom up coding of their data, going to the literature,
finding a theory that might help, and then doing coding based on the theory that they had found,
and doing this iteratively multiple times. And they're trying to describe here the exact process
that they went through to arrive at the particular theory they ended up with. So this is a really nice
illustration of what it really looks like, something of what it really looks like to engage in coding
of process data. And increasingly, actually, seeing diagrams like this appear in articles,
because people are being asked to explain, well, how did you do this? Actually, how did you take
theory that is out there, combine it with the data that you have to produce something new? And so
this is the combination, I think that is important. So I'm going to stop here
for a moment, and stop share, and see if we have
some questions. So I can see a lot.
Yes. Thank you so much, Ann, for the presentation and for all the information. It's been super
helpful. I have two questions. One is a clarifying question, and then the other one is also for
recommendation. So maybe I start with the clarification question. So you spoke about
alternate templates, and it's something that I've actually thought about quite a bit.
I'm not doing a process study, or I'm not doing a study with process data, but I do find all the
strategies you've mentioned very useful. I thought that alternate, or at least from my
perception, I feel like almost every qualitative study would at some point in time come across
alternate templates, because you do try a lot of different things to see what fits your data.
So from the back of my mind, I felt like it's kind of intuitive, but you mentioned that it's
not used often. So that made me feel like, okay, maybe I didn't understand what you meant by
alternate templates well enough. So is it really just trying different theoretical lenses to see
which one fits your data in the analysis process, or like what you displayed, where the authors
eventually in their final output also explain each of these theoretical lenses and then argue
for each one, which one qualifies as alternate templates? Yeah, so I mean, a study that would
really, I would consider to be an alternate template study would show the different templates
in their study and say, I looked at my data according to three different theories,
here's what happens when you take this one, here's what happens when you take that one,
here's what happens when you take the third one, or they could be four or that could be two. So
it provides different accounts. So if you were going to use that in a study, it would provide
different accounts. But that doesn't mean, and I was perhaps confusing about that, that doesn't mean
that a researcher might not be doing this in the background, anyway. But when it comes to
actually write the paper, that's kind of as if all of that variety might disappear, because you
have picked the one that's going to work, you don't have room to describe all the other alternatives
you look at, so you go for one. Yeah, so and the one is usually a combination of both the top
down and bottom up in practice, because you take your model, you apply it, and it doesn't quite
work. And so you enable you to introduce new things, or if you're going bottom up, you do
something, and you think, oh, yes, I found this, and then you have to look in the literature.
And you see, well, the literature also found that. So is that new? I mean, what is it I'm adding?
So it's this back and forth that's, that's important in the doing, but in the presenting,
alternate templates is very rare. Okay, okay, thank you so much for clarifying. The second question
is that, like I mentioned, I don't specifically use process data, but I do find all your strategies
quite helpful. But I realized that in qualitative, in the qualitative community as well, it's very
important who you cite on what studies. And I can imagine that citing process methods papers in a
study with variance data could be problematic, but I still haven't quite found, or maybe I haven't
recognized other resources, which talk about similar strategies for, for variance data, maybe
accept ground of theory and, yeah, accept ground of theory. So I was wondering if you have any
recommendations on, first of all, would it be right, or if it would be right, how to couch it in a
paper, if you are borrowing from a different area of qualitative methods for your approach. So if I
would want to say that I used alternate templates as recommended by Anne Langley, and then I cite
your paper, but then it's not a process study that could be problematic. So how could I couch it so
that it's, it doesn't come across as problematic? Or if I can't do that, then do you have any
recommendations on other resources to consult? I would not worry if you cited me for alternate
templates for any study. And in fact, when I, when I teach qualitative methods, I use this paper,
and many of the most, many of the strategies make sense for other kinds of qualitative data,
even if you're doing a variance study, some of them don't quite so much. So, so things like
temporal bracketing, it's all about time. So it doesn't necessarily make so much sense. And, and
so it depends. When, when I first wrote this paper, I was struggling with what to do with
process data specifically. And so I was looking for solutions to that. But in terms of resources,
I mean, I could recommend a few things. So, so there is a very recent
issue, special issue of organizational research methods. I think the title is Beyond Templates.
So, but the, the, the issue is extremely helpful in offering a range of other ways
of analyzing qualitative data. And so it, it, it really tries to get beyond the idea that
here's a recipe that you just apply. And, and tries to look for more complex ways. One of the papers
that I really find resonates with me, it talks about Brickolash, which is putting things together
that seem to be helpful. And I'm really, you know, strategies for theorizing from process data is
actually recommending some kind of Brickolash as well. But, but, but the Brickolash paper is
particularly helpful, I think, in terms of suggesting different ways. And they give examples
from their own research. But every individual is putting different things together. So it's,
it's not a recipe. It's not a recipe, but it's a very useful citation and
helpful in justifying your approach, I think, whatever you're doing.
Thank you so much, Anne. Ravi?
Yes. Thank you. Excellent presentation. Very, very, very impressive. My question is,
can you elaborate a little bit on process variants? I asked this because I think there is a missing
bridge or link between all the material that you suggested you cited to the whole body of
knowledge that's happening in operations management, where we look at process variants,
you know, we also teach in the operations management courses, tools and techniques,
like the fishbone diagram, Ishikawa diagram and so forth, to really understand how we can
manage those processes so that we can reduce variability to make the processes better,
more flexible, cheaper and faster. I think that practical call for why we try to manage processes
is conspicuously missing in what you suggested. And this is not a criticism. I'm just trying
to connect two bodies of knowledge here, what you cited and what goes on a lot in operations
management. Thank you. Yeah. So what I'm talking about is, you know, every researcher who is
interested in understanding process theoretically, I'm not talking about how to analyze a specific
process to improve it. But obviously, that is a complementary kind of an approach. And some of
the techniques that we might use to theorize might also be particularly useful for improvement as well.
So things like, and I'm going to be talking about this later, process diagrams, for example,
that look at how things are working over time and which activities are taking place.
And process diagrams can be useful to describe what is going on and to theorize from it. But
they can also be useful to pinpoint, okay, this process is kind of not efficient. There are
ways of cutting steps that might be useless. And there are ways also of improving steps so that
there's greater consistency, which is what you're talking about, eliminating variance, right?
So but I'm using the terms process and variance in a little bit of a different way and more in
terms of processes of theorizing. But I do understand that there is also a practical
application as well of these things. Anna?
Yes, hello, Professor Langley. My name is Anna Kourija. First of all, thank you for the presentation.
I've been doing ethnography research projects since three years and still ongoing until next year.
So it's about four years data of ethnographic observation and interview session. It's quite
a lot and messy, as you explained. I tried already the first round data analysis using
Joya method. But I realized, as you mentioned, I'm missing the the temporality, because I've
been studying about project management stages and how culture affects the project and performance on.
And so what I could get from Joya is just a kind of constructionist. So it's like
almost static in the way that it's just forming a certain theory, but it doesn't show
how dynamics in the project team evolve along the along the stages. So now I've been following
the one from Professor Niederman, the socio evolution theory. So like more like a process
theory looks like really like a process theory. But I believe I cannot share my screen. But the
way I did it like this, I don't know if it's correct. So first, I use the theoretical lens from
the literature. So I created a code book with my research team. I get the codes around 50 codes
or something. And I did the deductive approach of top top, top down. And then I did another round
with my team also inductive coding, so that to get some new ideas, or maybe we are not
in the right domain and so on. And then at the end, we kind of plan a map the episodes like
what happened in conflict, what happened creativity. And then we start from the project,
start with the project and and we create like couple of episodes mapping. And then we kind of show
it to the front. And I don't know if we're doing the right thing. But at the moment, this is so far
the best approach that we could think of to generate such huge amount of data. Otherwise,
I'll be also overwhelmed with analyzing this. I would like to get your insight if I'm in the
right track or should I try another approach? I mean, this sounds really good to me. I would,
you know, if you'd like to send me something that you would, you know, I'd be glad to sort of comment
on it. But thank you for doing both bottom up and top down coding. And I think that just focusing
on one can be problematic. You know, if you just do the top down, then you don't produce anything
new. If you do the bottom up, you just kind of end up being descriptive. So it's, it's,
it's the combination of both, which can give you that richness, I think. So yeah, I'd be glad to
look at what you're doing. I'm happy to do to get your feedback on the thank you so much,
Professor Langley. Okay, you see. Hi, I have a question about your strategy to alternative
templates, fit a different theoretical framework to the data. And sometimes people from different
disciplines study the same phenomenon. So the alternative templates may come from another
discipline. For example, like, in addition to management, there may be economics,
maybe astrology, maybe geography, I really like your picture in the beginning, the river is not
object, but ever changing flow. Just analogy, like the person is like driving the boat is like
an entrepreneur drive a business. And the river is kind of like community institutions, is like
economic geography that kind of thing. For example, the river is, is changing flow, like there are
a lot of economic geographers study the community institutions, but they are not considered a
management. So when I use alternative templates, when I incorporate those, to let different
disciplines to kind of have a conversation is answer your call of the river is not object,
but every changing flow, that's very juicy part because my background was from economic geography.
But I'm supposed to say this is not an internship paper, you should submit to somewhere else.
But I am targeting at management mainstream conversation, I want to join that debate. I think
some people say that because the entrepreneurship is changing like a very long time ago is like Steve
Jobs, a kind of entrepreneur, but later on come to the community's level, for example, and then
come to the social level. So what is expanding a touch of the boundaries of different disciplines,
for example, economic geography, but right now I want to speak to the mainstream entrepreneurship
literature, or join that debate, and I want to use the alternative templates by citing
the framework from different disciplines and let that to kind of have a conversation,
so that I can answer your call that the river is not just object, but the average changing flow
that's bring the community lens into the conversation, but speak to the mainstream
entrepreneur. Okay, you give me some suggestions so that people will say it never.
I think that that sounds great. I mean, I think that multidisciplinary research is difficult,
but if you are not just, if you are bringing in alternative templates that are not based
in management and comparing them with those that are, I think that's extremely generative
and it's likely to be well received. In the entrepreneurship field, I know of one paper
that really does a good job of looking at alternative templates, and that's a paper by Greg Fischer.
I think it's Entrepreneurship Theory and Practice is the journal, and it's 2012,
and it's a kind of a classic application of alternative templates approach,
so that might be something that you would want to look at.
So can you type the literature in the chat box, or I follow up and give you an email?
Yeah, maybe what I will do is send a bibliography to Ibrat at the end, if that's possible,
because there are ways to distribute that too. I think I can do that. Yeah, okay, I will create
a bibliography and send it. Wonderful, thank you. If anyone could type that paper in the chat box,
I really very appreciate it. Thank you. So we have Ibrat and Melissa. Yes.
My question is about, you talked about kind of doing bottom-up and top-down approach to working
with the data. Where do you see the role of the thick description in this, and would you say
thick description? What is the sit in between those two polarities, so to speak? Well, thick
description for me is more of a bottom-up approach, and I'm going to be talking about narrative
after, you know, next. So I think that we can get into that, and you know, its narrative is
doing a thick description as something you might do first, or something you might do
last when you have done coding. It both is possible. So anyway, we'll talk about that
in a few minutes, if that's okay. So let's have, but probably best to have one last question from
from Melissa. Thanks, Anne. I'm struggling a bit because I'm looking at transformation
comparing it with typical organizational change in that it's constant, and so looking at a strong
process theory, but at the same time looking for those constants that are in the river,
and how to sort of frame it. So I've been trying to use different lenses, like performativity,
and the transformation is a journey, but I'm getting a bit stuck between, well, the right,
really the right lens to sort of capture the, and make the theoretical contribution
to show that this is something different if we're talking, for example, in this case about
digital transformation versus sort of status quo organizational change.
So I'm not quite sure I have to respond to that, but I do think I've always thought of, you know,
transformational change as being, okay, fine, you get you shock a system with some kind of,
well, you know, one time supposedly one time
initiative, but then it kind of gets itself into woven with what is already going on
in the company or the organization, and so it becomes continuous. And so change changes,
this is the way I think about it, so that so that you have this one time transformation,
but it gets transformed, it gets changed by the continuity of ongoing change.
And so I like to have that, I like to have that kind of image where, yeah, you do a merger,
and then you don't do a merger, and then everything is, you know, then you have a result,
you do a merger, and then all of the things that were going on anyway in the enterprise
kind of change what that means. So I think that that can be done, and I think that you can trace,
you can trace, you know, the moment of change, and then trace through the ripples that it creates,
so that it may create big ripples and small ripples. And I don't know, I would tend to
look at some kind of temporal bracketing where I would see waves occurring.
We're trying to understand capacity for the transformation, and the issue is that capacity
seems to be a boundary, it is or it isn't, and yet are there certain constituent components
that enable this transformation to be possible, and is it the right theoretical lens to use
performativity if we're trying to sort of talk about, and maybe boundary condition is not even
the right term to use anymore, but, you know, the approach was to use necessary condition analysis
and the data to try to find, yeah, that doesn't even make sense.
I mean, why don't you send me an email? I have a little problem with the notion of capacity,
because it's kind of static, right? It's a thing, it conveys the idea of something that's fixed,
a capacity, or a capability, because this is something which changes over time, the capacity,
you know, you learn, so you have great capacity, and so everything is evolving, and so the notions
like capacity, feel a bit uncomfortable with, you could, when you could talk about capacity work,
which is working on the capacity, so then you get to doing again, but-
That's super helpful, thank you so much.
All right, okay, so I think we'll, we'll move on a little bit, because we don't have that much
time, so I'm going to try and perhaps accelerate a little bit here,
and I have to share my screen again, right? Okay, so we're now moving on to the middle column here,
which is displaying process data, and so I'm going to talk about two strategies that I mentioned
in my paper, which are narrative and visual mapping, and so there's two different ways of
displaying, the first one is displaying your data in terms of words, and the second one is
in terms of drawing, in terms of pictures, so if we look at narrative, this is so easy,
just tell the story, just write it up, you know, all you have to do is to write the story, and
there are classics here, Alfred Chandler, for example, historian tells a narrative,
his theorizing is very much narrative-based, and as Ibrat mentioned, thick description
from anthropology is a term that Geertz uses to, to talk about his approach as thick description,
and if you do these things well, so basically what you're doing is you're taking the mess of
data that you have, bringing them together to create a narrative, and a narrative that will
hopefully tell you something about the world that reaches beyond the particular case,
and so narrative can be very powerful, and if it works, you get a sense of this,
I've seen this before, so a really good narrative study,
it'll be like a really good novel, because you will see, okay, this makes sense, this is,
this is how the world is, and so it can be really appealing to have a strong narrative,
and then I really like this quote from John Van Lennon, who argues in favor of narrative,
because precisely because narrative allows for complexity and ambiguity,
and if your case that you have is fuzzy and messy and ambiguous, then if you want to render it
and keep that side of it, then, you know, he says to be determined, we must be indeterminate,
because things are confusing, because things are messy, and so on and so forth,
so a narrative approach tends to try and keep as much of the richness as possible,
but at the same time, give you that sense of deja vu, so that's the positive side,
this is the negative side, and so this is Laurel Richardson in the handbook of quality
research, and she says, I have a confession to make for 30 years, I have worked my way through
numerous supposedly exemplary qualitative studies, and it's boring, basically it can be so boring,
and the reason is that it's just descriptive sometimes, and so it's blind alley two again,
where you have so closely captured your empirical data that we can't see
the deja vu, we can't see the plot within it, and so this is the problem of narrative,
but at the same time, there's almost no qualitative study where you don't at some
point draw on narrative, so what are some of the other ways to draw on narrative, so one way is
to use it as the first step, so you have all this mess, why not just try and write it up
as completely as possible, and this Kathleen Eisenhardt, this is the step that she always
recommends, and she talks about multiple case studies, and she talks about how for each of her
cases, she writes something like a 70-page, single-spaced story, and that story becomes
like a secondary database for the rest, it's a way just to get started, and it becomes,
as we're writing this narrative, it becomes the stimulus for your coding that you're going to be
developing, so that can be one way to use it, the other way to use it is to consider it as your
last, you write the narrative to integrate your coding and your data and your theory, to bring
the data and theory together so that you're telling a story which has concepts in it,
and is kind of bringing codes and specifics and generality together, so a really strong narrative
as a last step is going to be able to take specifics and show how they reflect a more theoretical
concept, and you might consider multiple narratives which is getting back to the
alternate templates approach, or you could look at multiple narratives based on the visions of
different people in your case, that's another way to multiple narratives, so these are richer ways
and more useful ways I think of thinking of narrative, and there's this paradox about narrative
which is you can't write a really good narrative until you know what the plot is,
but you can't discover the plot until you've done the narrative, so it's this hermeneutic thing,
it's this iteration once again, you start writing, you don't have the plot at first,
when you discover the plot you have to rewrite it completely, and so it's a kind of a little
bit of a paradox, and now so that we've talked about narrative, I'm not going to talk about
another way which I really like of displaying qualitative and processed data, and this is
visual mapping, and so draw it, draw your data, or draw something, draw your theory,
and so we're talking about graphs, tables, drawings, diagrams, on visual mapping the gurus
here are Miles and Huberman and Sal Danyan, the most recent version of their book has a third
author, so Miles and Huberman, you should read this, it's a really useful book which
offers a variety of ways of drawing data, and I like it a lot.
So here's an example, no it isn't an example, okay so what is visual mapping? So visual mapping,
you can use any kinds of forms of drawing that you want, but there are a certain number of
conventions which you might want to keep to, so boxes and arrows are obviously important
aspects of drawing data, but you can use boxes and arrows for different kinds of things, so boxes
can be things, they can be objects, they can be concepts, they can be actors, they can be events,
depending on the shape of the box, you can code whether your event is for example a decision,
or if it's an event that just happened externally, so you can use the forms of boxes to indicate
different things, arrows can indicate different things, so particularly for process research
we're going to be using arrows not so much for causality probably, but more for temporal relations
like precedence, what comes before what in time is something that we're going to be using
with arrows, we're showing with arrows, we can use icons, emoticons, etc, and there are a certain
number of conventions, so at least in the west time goes from left to right, it does not necessarily
go from left to right in other parts of the world, and that can be confusing, so if your writing starts
from right to left you may think of time as going from right to left, and that can be confusing,
most of the American journals will expect time to go from left to right,
hierarchy top to bottom, you can do things with overlapping boxes, you can do things
with boxes that interact, lines that interact, and so on, so there are all kinds of ways of doing that,
here is some of the thoughts of how you can use visualizations, so here's my diagram with data
and theory and coupling, you can use diagramming visualizing all along this chain, so when you
look at a published paper what you usually see is a diagram, a process theory, so that is not what
the author necessarily started with, that's the distillation of their theoretical ideas, so that's
they're using it for conceptualizing or communicating their theory, but you can also use
visualization for actually mapping your data, not just simply presenting the findings or
presenting the theory, but also for mapping the data and for analyzing the data themselves,
so it becomes a coding tool essentially, and this is an example that I put in a paper,
very old paper that I wrote with a student, it's a flow chart, and this we were actually
mapping the data, it was a technology adoption process, we classified events according to
different domains of the company, so the top to bottom, they're different domains of the company,
we identified different codes for events outside the company, those are the ovals
for activities which were I believe square boxes and decisions which were the round cornered ones,
and we showed precedence, we showed interruptions, we showed events that impacted other events,
and depending on to what degree they impacted them, we placed different symbols on there,
this is an example of how you can take some data and instead of just coding it according to Joya
method, you can display it along a timeline with events, and so this is quite a different way
of coding, and it's still coding because we have coded the different kinds of events,
and this is a tool for describing your data, but then if you wanted to compare different
timelines, and this is what we did, we had five processes that we mapped this way,
we could compare them so we could see what comes before what, what tends to come before what,
can we see some patterns in the types of interactions between different kinds of
phenomena over time, so this is a really interesting tool for process research, and most cases you
never see, you don't see the mapping itself in a published paper, but you see the final, the final
diagram, so that's just looking at the time, I'm going to skip a few things here, because I want
to talk a little bit about comparing as well, so we've talked about the two methods for displaying,
comparing for me is a really powerful tool for theorizing, because it makes you,
it makes you theorize, if you, if you have an example I always give is if you have children
and you have a little boy and a little girl, you immediately stop theorize about the differences
that come from time, your, your, it's, we are programmed to theorize from empirical differences
and similarities that we see, and so it is really powerful to do that, and you can compare in all
kinds of ways, and so I talk about comparing time periods, and this is particularly useful for process
data, but you can also compare cases, you can compare incidents, and drawing tables that show
these comparisons is a great way to kind of focus, get yourself to focus on that, so
I'm just going to give, I'm going to skip this, and just give an example of some temporal
bracketing, which is decomposing by time period, so this is a paper that I wrote
with with Jean-Louis Denis and some other co-authors, and it's about a merger of three hospitals,
and they were in a double mind, they had a real tension, because on the one hand
they had been told that they would get a lot of money if they agreed to merge,
and on the other hand they hated each other,
and so they couldn't agree about anything, they had to stay together, they were stuck,
so they had this initial condition of constraint, they had to be together,
but they couldn't agree, and so how were they going to work out how they were going to do this
merger, and we showed that they kept making decisions that embedded ambiguity so that
they would need to make the decision all over again, and the processes were that okay,
they would put forward a proposal where they would try and integrate everybody into the decision,
and in order to do that they would have to make it ambiguous, which meant that they could not
implement the decision because it was ambiguous, so they would have to decide all over again,
and so this is the overall model, but we followed it through empirically with three
different stages, so here are the three different stages, so this is temporal bracketing, what we
showed was they went through a process, it produced ambiguity, therefore we had to start
all over again, and so this is a kind of a temporal bracketing of a process over time,
and this was very helpful in helping us to understand this process, and the title of the
paper is escalating indecision, this is what happens when you need to work together, but you
hate each other, you find yourself in this escalating indecision cycle, the good news is that about
five or so years after we finished our study, they did actually do something,
so it didn't, but this was the process that we observed,
and then you can also compare cases, so you can do it, compare outcomes,
and if you're doing that you're probably more into explaining variants than looking at process,
so that's one thing, but you can also use a comparison between cases to show similarity
rather than difference across different settings, and if you do that then you're demonstrating
that the process that you're looking at is not just in one case but several, and so that can be
helpful as well, you can use comparing cases to show variety, you can illustrate richness around
a similar structure, and you can combine process and variants also, so there are authors who use
multiple cases to show different processes, but then they they compare the processes and show
that some tend to lead to positive outcomes and others tend to lead to negative ones, so they're
combining process with variants, so I'm looking at the time here and I'm going to just skip things
and move on to my last point which I think is important, because I have all these strategies,
but at some point that's not enough, and I think it's a really important point that theoretical
insight does not just emerge, so when you read a qualitative paper that at some point somebody
always says the theory emerged or the concepts emerged from the data, well yes, no, I mean
you did this work, and then there's this step which you cannot, you cannot know exactly what
happened but you saw something, and it's that step that's missing from any of the strategies
that I've mentioned so far, I called this the conceptual leap, and I wrote a paper on this
with Malvina Klag, and this is an image in the paper where we point out that making the conceptual
leap is yes about analyzing your data carefully, about using all of these a priori theories to
look at your data, about talking to your friends, it's all about doing systematic, disciplined
things, but it's also about doing unsystematic, undisciplined things like going for a walk in
the park, going for a run, sleeping, sleeping is excellent when you wake up or you're turning
over in the middle of the night, that's when you get good ideas, so it's a combination.
The discipline is really important, and what we've spoken about most today is the discipline,
but there's also this kind of creative side, and if you don't have that, you won't get
what we're trying to achieve, so you need this.
So I'm going to stop there, see we still have 200 people, so I think we might be able to have a
couple of questions at this point.
Yes, Alba.
Thank you so much, Anne, this has been very, very informative, I'm really grateful, and I guess
we're all really grateful as well. Just one question on the very last point you mentioned,
which is the creative leap, so I remember writing in one paper about having a creative leap as well,
but I don't know if it's the way I framed it, but then I got back from the reviewer that even
though it's a creative leap, I should be able to explain how I got there, and that was a bit
counterintuitive because that's the point, I can't necessarily explain exactly how I got there,
which is why it's a creative leap. So do you have any pointers on how to really
couch it so that it doesn't sound like it came out of nowhere, but then at the same time,
you don't also try to force fit anything, but then you can show that, yes, it came from knowing
my data and all of that, but the direct link that you want to see, I can't necessarily show you.
No, I think what is important to show in a paper is the coupling.
So the way you found that coupling that you can't explain, but you can show the coupling,
and that is you must show that the data, if you look at them carefully, you can see the link
with the theory. So if you can show that link, that's the important thing. You don't have to
tell them how you actually got there, but if, or you can mention that you had a creative leap,
but at the same time in the same paper, you have to be able to show that coupling happening,
so that it's tied up with a bone, so that the reader can see that the data, yes, is a good
explanation, or the theory is, yes, a good explanation for the data, and the data do justify
the theory that you're proposing. So it's the coupling that's important.
Okay, okay, thank you so much. Yeah, so you get your creative leap, and then you go back,
you mustn't stop with your creative leap, you have to go back and check it out.
Otherwise, you can go wrong as well. Fardy? Yeah.
Fardy?
No, thank you very much, Prof. Really, really interesting and useful presentations, and I find
them really very, very relevant to my work, because I've been doing quantitative work until
the PhD had to do process research. One of the things that I'm really keen to do is to
really make the best decision on which particular vehicle I use to write,
you know, because I'm using data from several sources over time on how a form of behavior
continued to take different shapes, you know, in an industry that is trying to be formalized,
but then a lot of the informal activity kept on happening over time. So the dialectic
one seemed quite interesting, but my question is, is there like, would you recommend picking a model
and then trying to write after that model, or how best? The question I think you're asking is,
where do I start, you know, what does I do first? I think that I would, I tend to start with temporal
bracketing, because I sort of like to see in the data, what is it, you know, are there turning points?
And then once I've seen that, if there are no turning points, well, then that doesn't really
work. Maybe that was kind of a smooth continuity. But if there are any turning points, or, you know,
whether something happened, like some new people came in, or a new company appeared in your industry,
or something that changed significantly, more significantly than other events,
had a potential for change, then those turning points are kind of like a starting point for
looking at the data. Then you might move towards more detailed coding of what was going on in each
period. And so you would collect together bits of data, which are relevant to each period,
and start working on what's going on, what different actors were doing during those periods.
So, I mean, that's, I think what I would do, but yeah, it depends. I think you have to find
something where you kind of have something to grab onto. Another approach is to find another
basis for comparison in your data. So do you want to compare certain types of firms with
certain other types of firms? You know, if so, can you subdivide your data according to different
types of firms? Or can you subdivide it in some other way? I think it's very useful to find something
to grab onto, which you can compare with another thing. I tend to go for temporal brackets, because
I'm a lot closer. Daniel.
Hi, Anne. Thanks for a great session. This is a question that came from one of our participants,
Eva Maria Spreitzer. And her question is, what would you say or what kinds of theories are great
to inform the coding of the data, such as different levels, depths, etc. And the thinking is
because it is easy to go from low or tight with concepts or too high or too broad with
theoretical frameworks or meta theories? Yeah, well, I mean, it depends on the nature of your data.
But, you know, as I mentioned, you can you can code your data with no a priori theory,
you can just read it and see what you see. That that's the theory behind grounded coding.
But if you want to, if you want to develop more oriented coding,
I mean, think about what it is, what are some of the the concepts that you're interested in. So,
so if you want to really focus on processes, maybe your coding should be about activities,
right? So what activities are people thinking about? So that would be one
angle to look at. So process, process theory is about activities. So can we code activities?
But you might be interested in something else, you might be interested in emotions,
for example. So then you might code emotions, and then you might ask yourself, well, what
emotions are associated with which activities and which events? So, so that then you would code those.
So, I mean, this is a this is a decision, depending on the on the research questions
you're interested in. But, but if you're interested in process, I think, I think
activities, I think events would be things to focus on. I don't know if that's helpful.
For me, it is. I hope Eva Maria likes the answer also. Thank you.
Rosala.
Hi, thank you very much. So my question is about this combining a grounded theory approach with
the a priori approach. And I was reflecting on on this from a more
based homological point of view. So as far as understood, one would be more interpreted and
the other would be kind of more positivist. And I and I, I still struggle to see how can we do that
and how we can combine both. And I don't know, maybe I didn't get it right. Or maybe you have
some insight for me. Thank you. Yeah, but I mean, some some theories are interpretive. So I don't
think it necessarily, you know, means that one is one is more interpretive and the other is
more positivist. But, you know, there is this idea of induction and deduction.
But I think that what you need to understand is that even if you are doing an interpretive bottom
up constructivist approach, you need to connect it to in order to make a contribution, you need
to connect it to some a priori theorizing. So if you read carefully, even Denny Joyer's
papers, they are not a theoretical from the start, he reviews, he reviews the literature,
he comes up with a research question. And his work, his work done with other colleagues
is cumulative, actually, he's interested in identity or has been interested very much in
identity. And if you look at each of his papers, they kind of build on each other in many, very,
very, very many ways. And so they're not, they're not a theoretical. And so I think you always need
to refer back to other literature. Yeah. But you need to find your sources that fit with what
you're doing. I think a really interesting body of work, which really shows this kind of bottom
up top down idea is the body of work on organizational routines, the theory of routine
dynamics. And so this is always, the studies are almost always qualitative. The notion of routine
dynamics was developed by Feldman and Pentland. They wrote a very famous 2003 article in
administrative science quarterly. Other people interested in routine since that time have built
on that paper and their theory, but each one is making a very distinctive contribution.
And it's qualitative and it's processual. But the research questions are different, except there
are some concepts, foundational concepts that everybody is using, that just simply get
more richer and further elaborated each time. So that might be a good body of work to sort of
situate this kind of top down bottom up idea against. Thank you very much. If could I add
a second question? Yes, okay. It's actually more on the practice on the on the coding and analysis
side. So as a PhD student, I also find sometimes a bit overwhelming to look at different cases at
the same time. And so I was trying to playing around with different approaches. And I was wondering
if you have any suggestion to maybe start from one case or actually know it's much better to
look directly through all of them. And what's your opinion on that? Thank you.
Yeah, I don't know. I think it depends a little bit on whether you want to explain each case
individually and maybe think of them as separate contributions or whether the comparison is really
critically important to you. And then you want to keep it keep it going. But I mean, another
I think Daniel asked this question, you know, no, it was someone else who asked the question,
where do you start? And I said temple bracketing and another another way to start is just to
write these narratives for each of your cases. That's that's so helpful. If you have different
cases, write the narrative, put quotes everywhere. In the narrative, you know, let's let's just tell
the story. And, you know, all the quotes that you think are so great that you absolutely need to
use them, you put them in the narrative. And then you've got this kind of secondary database where
you can compare the narratives. And so that becomes then you can write new tables that compare the
narratives. So you can look case one, case two, the first phase, the second phase, and then it
becomes organized. But narrative can be a great way to get started as well.
Loreto. Hi, thanks, Anne. It's a really brilliant presentation. I'm really going to help with my
my projects that I'm doing at the moment. So thank you. And I'm my questions more about the
endpoint and about where where to get published and where you think are kind of the journals that
are more aligned to process research. Thank you. Well, it depends what your field is. I'm in the
field of management. So the the North American management journals, like Academy of Management
Journal and Admirative Science Quarterly and Organization Science, have they published all
kinds of research, they published quantitative and qualitative research.
And they have editors who are dedicated to qualitative research. So I am an editor at
Academy of Management Journal, and I am dedicated to qualitative research. And we have five,
we're a team of five editors that consider qualitative research. And it would be the
same in the other journals I mentioned. And so although they published a lot of quantitative
research, they also published much a great deal of qualitative research. So that that's a good
place to go. Many of the European type journals are more qualitative oriented than the North
American ones. So organization studies is a great journal, journal management studies are
great journals for this work. I'm not sure that I think what in order to decide which kind of
journal you want to publish in, it's a good idea just to read, you know, those journals and see
where you see things that that correspond to your interests, and that you think that you can relate
to. So some journals have more of a sociological flavor, and they may relate more to sociological
literatures, some are more managerially oriented. And there are delicate differences that you need
to kind of get familiar with. And it's very difficult to pick one. But all the journals I
mentioned, and others as well, are very open to process research. Yeah, you might if I mentioned
some that probably less so, I mean, in general applied psychology might not be so open to it,
I don't know. Yeah. Some I interrupted somebody, Patrick.
Yeah. Thank you very much for your very, very brilliant presentation. I have a pretty basic
question that has been very, very confusing for me, which is, how do you do process to arrive in
from a one of interview, where the respondent is talking about how they make decisions within
the organization. Clearly, this person is talking about a process, right, and how they
finally arrive at a conclusive decision. But this is a one of kind of interview. So how do you
do process to arrive in from such a data? Well, I don't think you can. I mean, because you only
have one person, but you can you can represent that person's theory of decision making.
So so you could. And if you have several different people, you can look at their theories of
decision making so that that they are they are suggesting the stages that you go through and
things like that. What I think, you know, when you're looking at an interview,
is that there are two ways to develop theory from an interview friend, kind of data. One is to
take the generalizations that the person is telling you. So let's say the person says, oh,
we always make decisions in. We have a committee, and we make the decisions in the committee.
Okay, so you could read that and think, okay, they make decisions in the committee. So I'm
generalizing from the generalization of the. Responder.
Or instead of doing that, and I think that this is much better, is that you have the
accounts of that individual of several specific decisions. So this happened, this happened,
this happened, this happened, this happened. The second decision, this happened, this happened,
this happened, this happened, this happened, this third decision, this get them to talk about
lots of different decisions. Then real months, concrete months, then you generalize from their
stories, not from their generalization. See what I mean? It makes a huge difference. So if you,
if you're talking, if you're using an interview, get the stories. And sometimes you do generalize
from other people's generalizations, but it's much better to get, get as close as you possibly can
to the actual events and the accounts of the actual events. And you're getting deeper when
you're doing that. I don't know if that's, that's helpful. Thank you very much. That was very, very
helpful. So how are we doing? Anyone?
I'm just looking, is there something in the chat which I should respond to?
Underworld questions. Isidora. I'm not sure we'll have time for that. Yeah, Isidora.
Hi. Thank you for a great presentation today. I believe this is a very broad question, but if
you can just give us sort of just your general opinion, I'm really interested about quantification
of qualitative data. I have thought about it in one of my previous research, but I opted against
it because of all the division of whether this is a right research strategy. So I just wanted
to hear your opinion on it and maybe if you can suggest some kind of resource that would be valuable
in sort of providing a starting point for that. Yeah, so thank you for the question because one
of my strategies was quantification and I didn't talk about it. And I didn't talk about it because
I'm not particularly fond of it. But I do think quantification can be useful. And when is it
useful? It is useful. It's not useful in the description. It doesn't, it doesn't make any,
you don't need to count anything if you just want to describe phenomena or or
types of events that happen. You don't need it. Where you do need it is where you want to say,
okay, say is more of a success than case B or some kind of way of judging differences
that is along a scale. Then you have to find ways to do it. And so, for example, I recently did a
study with a colleague, which was about, it was an 18 year history. So it's kind of a process
study of how managers cited their founders in their discourse in their communications.
And we wanted to show that the way they cited them changed over time. And in order to do that,
we had to count them. We had to code them into categories and count them to be able to demonstrate
to the reader that it's actually true that we were saying they were more like this than they
used to be. And so, counting gets important them. And when you're counting, you know,
enter, rate, or reliability starts to get important because the precision is important.
So then you need to go to resources that can talk to you about, you know, very
content analysis type coding where you have categories, and you need to be able to show
that these categories are reliable, valid, and so on. So I would look, you know, on the, on Google,
I would Google content analysis, probably Krippendorf would be a good author for that,
talking about how you would take qualitative data and then use it to quantify certain concepts.
But I wouldn't do it unless you really need that comparison. A is bigger than B.
Otherwise, one of the reasons I don't like it is you take out all the ambiguity. You take,
if you put things into categories and count them, all of the richness of your data kind of
disappears. It just has to go because the obligation to be able to find exactly the same
number as your colleague means that you have to make things so clear that there is no possible
doubt that you have categorized correctly, which means that all of the ambiguity and fluffiness
and richness goes. And that's not good. Qualitative data is qualitative. It's not quantitative.
So it's a good thing if you need to do that comparison. But if you don't, don't do it,
just to do it. It's not worth it. Okay. Yeah, thank you so much. Yeah, I think I
should have decided against it simply because the essence and the nuance within each of the,
you know, qualitative aspects sort of gets lost. But I still think that it might have been an
interesting strategy to show intensity of a certain outcome. Exactly. That's what I think.
One person who does it very well and still keeps the richness is Stephen Barley. So if you look
at many of Stephen Barley's papers, he's real. He's a fantastic qualitative researcher, but he
also counts things. And as a great paper recently in Academy of Management Discoveries about buying
cars. But he does a lot of qualitative analysis, but also does counts. So that might be a good example.
Okay. Thank you so much. Burak.
Thank you very much. I have a brief question. It's about the lens. You mentioned about the theoretical
lens. How about the paradigm as the lens? And combined with the theoretical lens, would you
please elaborate differences and similarities? How do we use them? Thank you. So you're referring
to whether you're having a critical paradigm or you're adopting a interpretive paradigm or a
positivist paradigm. Yeah. So I'm agnostic as to which one you might want to adopt. And it's also
possible to play with them. So you can pretend, you know, you can say, okay, today I'm a positivist.
If I were a positivist, how would I consider these data? Now I'm a critical theorist. How would I
consider those data? So you can do that. And it certainly would help you see, it would get you
to ask different questions about the data. So if you're a positivist, you're going to be asking,
what is the truth? Right. And if you're an interpretive, it's how are people seeing things.
And if you're a critical theorist, you would ask yourself, well, who is winning and who is losing
in this? And so you ask yourself different questions. And I think that's hard to do within a
single paper, but it could be something that you could try and, you know, sort of play around
with those approaches. I mean, you can do the same thing with an interview. Take an interview.
Look at the interview. What if this was true? The person is telling me. And how can I know
that it's true? And if you're looking at an interview positivistically, you will say, well,
only the things that are about verifiable facts, I know are to be true. And in order to find out
whether it's true, I will need to find someone else's view or I will need to get other data.
If you look at an interview interpretively, you would think, well, no, I don't really need anybody
else's opinion, because I'm only interested in their interpretation. And I'm not trying to do
anything wrong. And if you were to look at it critically, yeah, if you were looking at it
critically, you would be very skeptical of what that person is telling you. And you would be asked,
now, why are they telling me this? What is it they're trying to convince me of?
That you would look at it in a much more skeptical manner. So just thinking about those
things, even on one interview, it can get you to see things different.
See, exactly like the example that you gave about the hospitals merging, like for example,
in this case, we can try to understand the phenomena of decision making from, you know,
generative constructionist perspective. But also we can look at it from a conflict paradigm,
meaning that decisions are going to create conflicts. So in this case, our theoretical lens
would be different, depending on the paradigm. Yeah, indeed. Yes. I agree.
Thank you. Thank you. Thank you.
