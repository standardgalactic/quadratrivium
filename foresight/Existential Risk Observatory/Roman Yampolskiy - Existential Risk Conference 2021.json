{"text": " Our computer scientists at the University of Louisville and specialized in behavioral biometrics, security of cyber worlds and AI safety. And indeed, one of my personal first steps in the world of existential risk was to read the number of your publications. And I think you may have inspired many like me to start working on either AI safety or existential risk or related fields. And I think you also have always interesting and thought-provoking comments available on each topic to social accounts, for example. So I really enjoyed reading those and I can recommend them to everyone. So we are now honored and it is a great pleasure, I can say, to be able to learn from you today. And we'll give the stage to you now, Dr. Romer Jampolsky. Thank you so much. Wonderful introduction. I really appreciate that. I think the plan is that I'll give about a 10-minute intro to my latest work and then we'll let me set up the slides. Where is it? Where did it go? Yeah, that's right. We can take a little bit longer as well if you want to. And then we can move to the fireside chat and then the Q&A with audience. Can you see my slides? Yes. Excellent. So my name is Dr. Jampolsky. I'm a faculty member at University of Louisville. I've been doing work on AI safety for about 10 years now. Give or take. And my latest work covers what I will call impossibility results. Problems we encounter with actually accomplishing what we think is necessary for us to do not just development work for AI, but also work in terms of control and safety. If you would like to learn more about my work after this talk, you are definitely welcome to follow me. You can follow me on Twitter, follow me on Facebook. I always encourage you not to follow me home. It's very important. So let's start with the big problem right away. If you heard previous talks at this conference, I had a chance to hear a little bit. You know about concerns a lot of people have with advanced artificial intelligence, usually called AI safety, AI alignment problem, sometimes AI control problem. The question is the problem we're trying to solve is how can humanity remain safely in control while benefiting from superior form of intelligence? So we want this very capable agent to do work for us, to be helpful, but we want to be in charge. We want to be able to undo any changes if we don't like them. We want to be final decision makers as to what's going to happen. And the good news is after 10 years of building up the movement, there is a lot of people working on this now. There is a lot of research labs, a lot of PhD programs, but I think the main question of control problem has not been addressed sufficiently. And that is, is the problem actually solvable? So everyone kind of works on it, but I haven't seen much in terms of proofs or even rigorous argumentation for why we think we can do this. Why is this problem solvable? Is it solvable? Is it partially solvable? Maybe it's not solvable. Maybe it's a silly question. It's not even decidable. So that's essentially what I've been looking at for the last couple years. And I started by formalizing a little bit what I mean by control problem. So we can talk about different types of control. We have explicit control where you give orders and the system follows. And this is the kind of standard Gini problem, right? You wish for things, then you realize that's not what I meant and you hope you get to undo the damage. Then there is implicit control. So you have a system with a little more common sense. It doesn't take your words literally, it tries to kind of parse things in the right way. And there are intermediate steps between explicit and delegated control. Delegated control is the other extreme where you have this superintelligent system very friendly. It knows what needs to happen better than you do. And you might be even very happy with the decisions it makes, but you're not in charge. The system is completely in control. Aligned control is another intermediate option where the system kind of understands your values, human values, and tries to do the best it can to fulfill those values, even if your spoken directions are not exactly what maps onto those ideal values. So it seems at least from now that some sort of intermediate value between total control and total autonomy for the system is necessary for us to be happy with the results. If a system is completely autonomous, we have no control over it. By definition, we will lose control. If a system has no autonomy, it's completely deterministic. We decide ahead of time what's going to happen. It's not very useful. It cannot be generally intelligent. It's a great way to do simple tasks for a narrow AI, but it's not something we can utilize to solve completely new problems and new domains, help us with science, help us cure diseases and things like that. So what I try to do is kind of break down the bigger problem of control into all the ingredients we need, all the tools we would need to make controllability possible. So what do you need? You can start thinking for yourself. If you want to be in control, well, you kind of have to understand the situation. What is the system doing? Can the system explain what it's doing? Can you comprehend the explanation? That's another very important one. Can you predict what the system is likely to do? Maybe not just direction in which it is going, but specifics. What steps will it take? Can you verify that whatever it is you want the system to do and program it to do is actually going to happen? So can you verify the implementation versus the model? Can you verify the model against your goals and data and so on? That is also a need for general ability to govern AI research, AI systems, so governability of that. And of course, we communicate with systems in human language and we need to make sure that communication we use is unambiguous. There is no way to misinterpret commands in a potentially dangerous way. And there is many, many more such limitations. And what I've been doing, kind of looking at each one and trying to publish those results. So I'll go over some of the publications I have on that so far. One paper talks about limits to explainability and incomprehensibility. So essentially, for very complex systems, large neural networks, it is impossible for the system to provide an exact explanation of what it is doing or why without simplifying it to the point of where it is like you explaining something to a child. So a lot of important details are removed and then a very simplified version is given to you because if a full version is given to you, you'll simply not be able to comprehend it. And if you want to learn more and see the kind of argumentation, in some cases, proofs, just go to the paper. I provide all the information you need to get access to those papers. There are also available as preprints on my Google scholar account. Another impossibility result is unpredictability and that's our inability to precisely predict all decisions, all intermediate steps, a much smarter agent will take. Of course, if we could predict all the decisions of a smarter agent, we ourselves would be that smart and by definition, there wouldn't be much of an intelligence gap, cognitive gap between us. That is also problems with verifiability. We know for a fact that with software, with mathematical proofs, we can only get to a certain degree of confidence, but never 100% confidence in the fact that we have no errors in the proof. So with more resources, we can increase safety and security, but we're never able to guarantee something with 100% accuracy, which is a problem for a superintelligence system, which makes potentially billions of decisions every minute. Even if one in 100 million creates a problem, you're guaranteed to have a huge problem within a minute or so. There are also problems with governance. We have history of trying to govern technology, things like spam and computer viruses. We have laws against those malevolent software products, but they don't seem to be doing much. So it's not obvious how much benefit is actually added and other negative consequences from trying to control research, control what is allowed and not allowed to be experimented with. Even the orders we give to the system, the communication channel through English is very ambiguous and you're almost guaranteed to run into situations where your orders will be misinterpreted at multiple levels due to how imprecise human languages are. So what we did with our colleague, we surveyed a lot of those impossibility results. Those I looked at and those other people have looked at, I'm not going to go into details of all of them. I can just tell you there is a lot of them and some purely software problems, mathematical problems, many problems with physics of the universe, impossibility results from physics. But if you think even a small subset of all those tools is necessary to solve the control problem, you have to come to the conclusion that control is not possible. At least not 100% guaranteed safe, secure control we all dream about. And I have a very lengthy paper about that, about 70 pages. I now have a few subsections of it published coming out in conferences, those should be a lot more readable. But I think I bring up a lot of interesting questions and additional directions for research and hopefully in the next half hour or 40 minutes we can talk about what all this means and how we can move forward from where we are right now. Thank you very much, Roman, for this introduction already. Yes, we can now have a chat about indeed where does it leave us and where should we go from now and also a couple of related questions. And towards the end, after about 15 to 20 minutes, we will also take questions from the audience. So please, if you have any questions then please type them into the chat. We're in the questions section rather. So first, you're spending quite a lot of time researching AI existential risk, but I don't think it's already obvious for everyone in the call why AI would be a danger at all. And I don't think everyone is perhaps 100% convinced that this is actually an issue or an existential danger, at least that is. Could you please recap how exactly AI could become an existential risk according to you? Right, so there is a lot of ways to get to that conclusion. I have a few papers where I simply collect examples of accidents, AI failures throughout history. And if you look at that progression, it's kind of same exponential chart you see with development. We get more problems, the problems become more severe, and our ability to anticipate and predict them seems to be very limited. So basically the conclusion is something like, if you have a system of service to do X, eventually it fails to X. Frequently it does so very quickly and you go, hmm, okay, my self-driving car just killed a bunch of pedestrians, that's a problem. And then it's a narrow system, the damage is limited, right? So self-driving car, okay, the worst it can do is run through some pedestrians. But if a system becomes general, and it's now controlling not just a single car, but networks of cars, nuclear response, airline industry, stock market, the damage is proportioned. I think it's also not the best way to assume that I have to prove that this service or product is dangerous. Whoever is developing and releasing it has to prove that it is safe, that it's standard liability law for any product. Show me that this system, which is smarter than me, smarter than you, smarter than all of us, will never do something within anticipate, something dangerous, something we don't want it to do. Is this proof could at any point be possible or is it within the impossibility realm of your theory? Well, I think I'm arguing that it's impossible to do so, and not just because it's impossible to prove that, but it's impossible to get to that level of performance. You can get progressively safer and more secure because you can look at specific accept domains. You can limit what the system can do in certain situations, but you have an infinite space of possible problems. So it's very hard to prove deterministically that you can sit at all of them. So if AI safety would indeed be impossible, what does that imply for AI safety research? Does it imply anything for AI safety research? Is that would that be a waste of time or is it still something that we should pursue? Not at all. I'm doing it more than ever. So think about mathematics. We know in mathematics there are many impossibility results. You cannot prove certain things in general. You cannot have proofs with 100 percent confidence. It doesn't stop mathematicians from discovering new beautiful mathematics. We know in physics there are limits to, for example, speed, fundamental limit, you know, speed of light. That doesn't limit us from doing great work on faster cars and faster rockets. It just tells you that there are limits to what can be done. And so you should a, not waste your resources trying to accomplish that. Like knowing that perpetual motion machines are not possible is helpful result in physics. Same here. We need to understand what we can achieve and then concentrate on what is actually solvable instead of trying to create magical devices which cannot work. Next one. For AI to become an existential risk, it's commonly thought that it should first outsmart humans. How big do you personally think the chances that this will happen at all and which probabilities do your fellow AI scientists assign to this? That AI will ever become as smart as humans? Exactly. Well, it's a guarantee. I mean, we have proof by existence, right? If you just copy human system, you got same level. We also kind of give a lot of credit to humans because we tend to think about Einstein and similar type humans as typical examples. Every human is quite dumb. So it's not that hard to get to that level. And how are you on timelines? Of course, you hear quite values that are quite far apart. I think Elon Musk said that there could be a five-year timeline up until AGI that's on the progressive side. On the other side, there are people that claim it would take hundreds of years. Where are you on this line and how certain are you? That's a very hard question. No one knows for sure and no one can accurately predict something like that. But if our current theory is about how systems scale, all right, meaning if you just add more compute, add more data, you keep making progress, then it becomes a question of cost. How much compute are you willing to purchase to get to that level? Do you have finite resources or what is here? $200 billion now. So maybe at that level, seven years is a reasonable estimate. With my budget, it might be 2040. It depends on what type of resources you have. If it's also as difficult as, let's say, Manhattan Project was, right? You need resources of a whole country to get there. It's one question. If we discover, okay, there is a simplifying assumption, so we need a lot less resources to drain this type of engine, a lot less compute. Maybe you can do it with a laptop in a garage and then it becomes a lot more affordable and takes less time. So I don't have specific dates. I would be surprised in maybe 2045 if I don't see something at human level. But that's not important to the argument at all. Whatever it's 2045, 2070, it's still something we need to worry about today, control and work on safety aspects of it. I've read somewhere that there are about 70 research projects explicitly aiming for AGI at this point. I guess the most famous two ones are DeepMind and OpenAI, at least the ones I know best. Do you know a project that we've never heard of, but actually has a fair chance of beating those two? Well, there could be many secret projects by secret agencies. I'm sure NSA is very interested in processing your data more efficiently. So I'd be surprised if they don't have something good happening. Usually, if you look at the history of what they publicly released and what we later learned they had, I think they had public ecryptography like 30 years ahead of everyone. So maybe already. Interesting thought. A week ago, you posted on the Facebook timeline that I referred to already, which is quite interesting. A quote from that helped me to understand where is the number of highly respected people who, one, argued that advanced AI is dangerous to humanity, and two, work as fast as they can on developing advanced AI. And there were, I believe, 116 comments under your post. Have you come any closer to understanding this personally? No, I had some good explanations and the best one, and I think that's the one Elon actually gave himself was saying, okay, if we can't control it, I might as well be the one to get there and I have the best chance of controlling it. People who don't care about safety have less of a chance. But it is interesting. So a lot of very big names in arguing that AI is extremely dangerous are also people who invested the most time and money in making it as fast as they can. Yeah, and on a more serious note, some people might say, if AI is so dangerous, can't we just not build it? You said something about regulation in your talk, but what would you say to them as a general response? You can't stop progress on something so useful and so fuzzy in terms of separation between narrow and general AI. If we could make it where, okay, you only can work on narrow AI, but not allowed to work in general, it would be a good moratorium to have for a few years. But the dividing line is meaningless. If you're using neural networks, they're general. If you're using a lot of those latest evolutionary techniques, they are leading you to general solutions. So it's simply impossible. If you make all computer science illegal, you're killing your economy, you're shifting research to other countries. So I think I'll add another impossibility result of unburnability of AI. You cannot ban it. You can maybe delay it at best. It would be very interesting if you could either include or exclude it from the impossibility space indeed, but I'm afraid that goes more into Simon Friedrich's chaos theorem, so to say. You and I both agree, I think that AI is a significant existential risk, but some AI researchers don't agree. And do you think there will ever be a scientific consensus about this? And can we hope to achieve that at some point? And why could that be either so or not? Well, I have a recent paper about AI risk skepticism, and I do a review of both why would someone not accept the risks as real and kind of specific arguments they make for it. I think it ended up with about 100 citations, and I have another 400 unprocessed ones. If anyone's interested, it could be a nice survey. The most common explanation I see is just bias. If you get your funding, your prestige, your reputation, everything from developing faster AI, it's very hard for you to say, I'm working on the most dangerous thing in the world that will kill everyone. So there seems to be this conflict of interest in any other domain. We wouldn't allow for this to happen. If you are working for a tobacco company, you wouldn't be deciding if smoking is dangerous. If you work for an oil company, we don't really trust your assessment of impact on climate. But somehow here, it's fine. And interestingly, AI is a very large umbrella term for lots of research sub-domains. Some people do natural language processing, some do vision. Not everyone does safety and security, but we feel that anyone with a label of AI researcher is qualified to pass judgment on the state of AI safety in software development. Not everyone is a cybersecurity expert. If you're working on backend, GUI, something else, you're not going to be consulted on how to do encryption. Why is this somehow different here? I don't fully understand. It would be interesting indeed also to find out. I'm also kind of puzzled, but perhaps it could have something to do with the fact that it's not a trial and error risk as one of the few areas. I think mostly, of course, you're first developing something and then later you regulate it, but it's only at the phase of application. So at this phase, it's much more obvious to have separate controlling agencies, perhaps. But when you're creating something, of course, that's not that obvious. Maybe one more question about also impossibility of AI safety, but I'm from a different angle. I don't know if you are aware of the work of Anthony Burglas. He has written a book about evolutionary arguments applied to AI, and it roughly goes as follows. For superintelligence, being friendly to people is a necessary baggage. Because of evolution, we should expect only the most efficient superintelligence to survive, and this is probably not the friendliest one. Would you agree to this evolutionary argument applied to AI, or what are your thoughts about this idea? I haven't read the books, so I'm trying to get the argument from your question. So the argument is that it's more efficient to be friendly to humans, and so it's a survival advantage. And the other way around, it's more efficient to be unfriendly to humans, so that would be a survival advantage. Because the friendliness would just be baggage according to him. Oh, in terms of his overhead and development, being friendly limits your space of possibilities. Yeah, I think there is a lot to be said about the trash rest turn option. It starts very friendly, gets the resources and help early on, and once it's capable, it turns on us and removes all restrictions. So sounds like a good book. I think it is, you should read it. All right, I'll put it on my list of 600 books to read, excellent. It was marketed very poorly, so I'm not surprised that you did read it, but I think the idea is interesting indeed. Are you more on the slow takeover or on the fast take-off sides, and why would that be? Very fast. Once we get to human level, it goes super intelligent almost immediately, just adding existing capabilities like infinite memory, access to all the human knowledge, since they are already super intelligent, if you just take human plus internet. And why do you think, I think the slow take-off side kind of gains momentum the last years, I don't know if you agree. And I've heard that this is just because it's more easy to write papers about this, or there are more possible stories that you could tell about this, but do you around you see a shift there? Do you see more people going towards the slow take-off side, or is that not true? I haven't surveyed, I honestly don't know if you think there is a shift bias by ability to publish about it, I believe you. I wouldn't make that claim too strictly. Okay, let's say that you're a non-AI expert and you still want to do something about this existential risk, such as we are kind of. What action do you think would be the best to take? So you're not an AI researcher, but you want to do something about... Yes. Is there anything at all, or would you just say, okay, just leave it to the experts, because there's not much you can do? I mean, in general, I think it's good if citizens are well informed about the world and problems, and so the next time you vote, you don't vote for someone you like visually, but actually picking better policies. It seems like based on age and experience of people were elected, at least in the US, they're not experts on most advanced technology. I hear many of them don't use computers, so I'm skeptical that they can keep up with crypto economics and cryptography and synthetic biology and other interesting questions. So your job as a citizen is to be informed and make sure your views, your informed views, have all represented. Right, some questions from the audience to not finish off yet, but we're getting to the end of the conference already. First one, who do you believe is responsible for the safety of AI? The consumers, governments, or developers, or some other stakeholders? So that's another interesting question. The ownership of AI itself is very difficult, right? If it's self-improving, it changes, it's not even obvious who has any control or possession over it. Obviously, the person to make it and release it has a lot of responsibility, but if it's out there and now you are upgrading it, supplying it with goals, giving it data, it feels like responsibility may shift to you. All of it for systems below human level performance. It's a tool, you are in charge. The moment it's human level or beyond, it's an independent agent. You are as responsible as you are for your adult children. Another one that's also very interesting, I think, is it possible to program in a programming language, not based on human language, to remove the ambiguity? Or would it be possible to have an AI create a language without ambiguity? If the AI could create such a language, would humans be able to learn it, or would we then also have to trust the AI to program in it? That's an excellent question. So there is a lot of effort. First of all, every programming language is an attempt to get away from English and into less ambiguous languages, but we know languages, programming languages have lots of bugs. There are logical languages developed to remove ambiguity. And I think Stephen Wolfram has a nice article about communicating with AI. And he, of course, uses his Mathematica and models he creates in language, Wolfram language he developed as possible solution. I think you can do way better than human language in terms of ambiguity. I'm skeptical about bug-free communication. It relies on your existing cognitive models, your understanding, and if you have different priors, even using well-defined terms may lead to problems. But it's a very interesting area to do additional research. If you have background in linguistics, I definitely invite you to look into that. Another interesting one from Simon Friedrich, actually a previous speaker. Do you think AGI could help overcome their global collective action problems that are at the roots of basically all the existential risks, including those of AI itself? So that's another great question. I see AI as a meta problem and meta solution. If we get it right, if I'm wrong and you can make friendly superintelligence well-aligned, everything I said is just a mistake, then it solves all the other existential problems trivially. Whatever is climate change, synthetic bio, you have a godlike tool for solving those problems. If I'm right and it's a terrible risk and it comes before, then it solves it by either killing all of us. We don't have to worry about it or it comes before again. So if it takes a hundred years for climate change to build up to boiling point, this happens in 20 years. It kind of dominates the risk. I'm not sure about applying AI to solve the AI problem. That's a bit of a catch-22. There are those solutions where you have a supervisory agent, AI, AGI, Nyanee, which looks after the world, making sure no one creates dangerous AIs. I'm very skeptical of such super agents with a lot of government control powers. I think they may be worse than what the system we're protecting against gives us. Great answer, I think. One final question from the audience now. So if we cannot stop AI development and we cannot totally ensure that it is safe, do we just need to accept that it is a risk or even a big risk? Or is there anything we can do, for example, policy-wise? So I think we need to do more research. I published those papers about a year ago and I haven't seen a strong response from a community addressing those. If somebody just published a paper saying, this is why you're wrong, then be very happy, but I haven't seen it. So I have to assume that there is some merit to what I'm saying. The question is then, what do we do with our lives? How do we update based on that? What do we change? For most people, I don't know if it makes any difference. Before you were told, okay, you're definitely dying in 60 years. Now you may be dying in 40. Not a big update. Figure out what to do with your 401k plan. You spend it on something now or wait for it to become worthless later. I don't have any magical solutions or answers. I am curious in case of successful alignment what happens to economy, what happens to work, what happens to people's social interactions. I do have a paper which kind of assumes that progress in virtual reality will be as good as progress in AI. And so each one of us gets what I call a personal universe, where you basically get to do whatever you want and you don't have to negotiate with others. There is no need for consensus. You basically have independence. So at least the difficult part of value alignment problem is not aligning with me or you. It's hard. It's hard, but it's not impossible. It's getting 8 billion people plus all the squirrels and whatnot to agree on something. And this is where the personal universe solution reduces it to just now we need to control the substrate. If you can get control of computational substrate and everyone gets the resources to run their personal universe, okay, we're doing well. We have this virtual agreement. I think that's not a good point again. I'm wondering also on a more personal level, like when did you start to think about AI safety yourself and when did you move into this research field? Was there anything that inspired you to do this and also what were the responses that you got from fellow scientists in moving in this direction? Well, it was a very gradual process. So I was doing research and behavioral biometrics. I was profiling poker players to see if, you know, accounts get hacked and tell the things like that. And at the time, I realized majority of online players are now bots. So my work started to be about detecting bots, preventing bots from participating. But the question was, as bots get smarter and better, can we keep up? And not just in poker, but in general online bots and automation. I did that type of work for a while. I went to what was at the time Singularity Institute for artificial intelligence, which was fighting hard against artificial intelligence. But they had a lot of great ideas, which I still work on. And I've been back as a fellow and a research advisor for Machine Intelligence Research Institute. I think they're doing excellent theoretical work. Yeah, I think perhaps one more, like some AI researchers, I think, might be hesitant to talk about existential risk in the public debate, like you already quickly mentioned, for example, in the media. Do you agree that they are hesitant to do that? And why do you think that is so? I think I lost a few words. So with media, what's the concern? Sorry, I'll just repeat the whole thing. Some AI researchers might be hesitant to talk about existential risk in the public debates, for example, in the media. Do you agree that this is so, that they are hesitant to do this? And if so, why do you think that is? Well, it's a personal decision based on your situation. So some people, before they get tenure, follow a very good advice of be quiet. After you get tenure, never shut up again. But that's not a bad idea. You'll definitely get someone disappointed in you. And that doesn't help your tenure case. I'm tenured, so I've been saying stupid things for years now. What do you think about an initiative such as the existential risk of territory? Is it useful to communicate this to more people in general, or to a certain subset of people? Or do you think it's basically something that should be solved among researchers? Well, if you think about developing a GI, working on superintelligence, you're really running an experiment on all the humans, right? You've got eight billion subjects, none of them consented to that work. The least you can do is tell them about it. That's actually great now to end this talk. If there's no more questions from the audience, and I think we've covered those. Yeah, and then I think we'll leave it here. It was super nice talking to you, and super nice to listen to your short presentation. And I hope that you will also enjoy the rest of the conference maybe tomorrow, and that will definitely be in touch and to cooperate more on this quite hairy problem, but still very interesting one to think about. Absolutely, and hopefully we'll meet in person one day. Likewise.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.96, "text": " Our computer scientists at the University of Louisville and specialized in behavioral biometrics,", "tokens": [50364, 2621, 3820, 7708, 412, 264, 3535, 295, 9763, 8386, 293, 19813, 294, 19124, 3228, 649, 10716, 11, 51012], "temperature": 0.0, "avg_logprob": -0.1504812240600586, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.028460368514060974}, {"id": 1, "seek": 0, "start": 12.96, "end": 18.32, "text": " security of cyber worlds and AI safety. And indeed, one of my personal first steps in the", "tokens": [51012, 3825, 295, 13411, 13401, 293, 7318, 4514, 13, 400, 6451, 11, 472, 295, 452, 2973, 700, 4439, 294, 264, 51280], "temperature": 0.0, "avg_logprob": -0.1504812240600586, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.028460368514060974}, {"id": 2, "seek": 0, "start": 18.32, "end": 22.88, "text": " world of existential risk was to read the number of your publications. And I think you may have", "tokens": [51280, 1002, 295, 37133, 3148, 390, 281, 1401, 264, 1230, 295, 428, 25618, 13, 400, 286, 519, 291, 815, 362, 51508], "temperature": 0.0, "avg_logprob": -0.1504812240600586, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.028460368514060974}, {"id": 3, "seek": 0, "start": 22.88, "end": 28.16, "text": " inspired many like me to start working on either AI safety or existential risk or related fields.", "tokens": [51508, 7547, 867, 411, 385, 281, 722, 1364, 322, 2139, 7318, 4514, 420, 37133, 3148, 420, 4077, 7909, 13, 51772], "temperature": 0.0, "avg_logprob": -0.1504812240600586, "compression_ratio": 1.6008403361344539, "no_speech_prob": 0.028460368514060974}, {"id": 4, "seek": 2816, "start": 29.12, "end": 34.16, "text": " And I think you also have always interesting and thought-provoking comments available on each", "tokens": [50412, 400, 286, 519, 291, 611, 362, 1009, 1880, 293, 1194, 12, 49911, 5953, 3053, 2435, 322, 1184, 50664], "temperature": 0.0, "avg_logprob": -0.16840437838905736, "compression_ratio": 1.583916083916084, "no_speech_prob": 0.01585998944938183}, {"id": 5, "seek": 2816, "start": 34.16, "end": 38.480000000000004, "text": " topic to social accounts, for example. So I really enjoyed reading those and I can recommend them", "tokens": [50664, 4829, 281, 2093, 9402, 11, 337, 1365, 13, 407, 286, 534, 4626, 3760, 729, 293, 286, 393, 2748, 552, 50880], "temperature": 0.0, "avg_logprob": -0.16840437838905736, "compression_ratio": 1.583916083916084, "no_speech_prob": 0.01585998944938183}, {"id": 6, "seek": 2816, "start": 38.480000000000004, "end": 43.68, "text": " to everyone. So we are now honored and it is a great pleasure, I can say, to be able to learn", "tokens": [50880, 281, 1518, 13, 407, 321, 366, 586, 14556, 293, 309, 307, 257, 869, 6834, 11, 286, 393, 584, 11, 281, 312, 1075, 281, 1466, 51140], "temperature": 0.0, "avg_logprob": -0.16840437838905736, "compression_ratio": 1.583916083916084, "no_speech_prob": 0.01585998944938183}, {"id": 7, "seek": 2816, "start": 43.68, "end": 47.36, "text": " from you today. And we'll give the stage to you now, Dr. Romer Jampolsky.", "tokens": [51140, 490, 291, 965, 13, 400, 321, 603, 976, 264, 3233, 281, 291, 586, 11, 2491, 13, 10141, 260, 508, 1215, 19385, 4133, 13, 51324], "temperature": 0.0, "avg_logprob": -0.16840437838905736, "compression_ratio": 1.583916083916084, "no_speech_prob": 0.01585998944938183}, {"id": 8, "seek": 2816, "start": 48.08, "end": 54.400000000000006, "text": " Thank you so much. Wonderful introduction. I really appreciate that. I think the plan is that", "tokens": [51360, 1044, 291, 370, 709, 13, 22768, 9339, 13, 286, 534, 4449, 300, 13, 286, 519, 264, 1393, 307, 300, 51676], "temperature": 0.0, "avg_logprob": -0.16840437838905736, "compression_ratio": 1.583916083916084, "no_speech_prob": 0.01585998944938183}, {"id": 9, "seek": 5440, "start": 54.4, "end": 62.72, "text": " I'll give about a 10-minute intro to my latest work and then we'll let me set up the slides.", "tokens": [50364, 286, 603, 976, 466, 257, 1266, 12, 18256, 12897, 281, 452, 6792, 589, 293, 550, 321, 603, 718, 385, 992, 493, 264, 9788, 13, 50780], "temperature": 0.0, "avg_logprob": -0.15537141618274508, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.01700000651180744}, {"id": 10, "seek": 5440, "start": 66.0, "end": 72.08, "text": " Where is it? Where did it go? Yeah, that's right. We can take a little bit longer as well if you", "tokens": [50944, 2305, 307, 309, 30, 2305, 630, 309, 352, 30, 865, 11, 300, 311, 558, 13, 492, 393, 747, 257, 707, 857, 2854, 382, 731, 498, 291, 51248], "temperature": 0.0, "avg_logprob": -0.15537141618274508, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.01700000651180744}, {"id": 11, "seek": 5440, "start": 72.08, "end": 76.72, "text": " want to. And then we can move to the fireside chat and then the Q&A with audience. Can you see my", "tokens": [51248, 528, 281, 13, 400, 550, 321, 393, 1286, 281, 264, 15044, 482, 5081, 293, 550, 264, 1249, 5, 32, 365, 4034, 13, 1664, 291, 536, 452, 51480], "temperature": 0.0, "avg_logprob": -0.15537141618274508, "compression_ratio": 1.4494949494949494, "no_speech_prob": 0.01700000651180744}, {"id": 12, "seek": 7672, "start": 76.72, "end": 85.68, "text": " slides? Yes. Excellent. So my name is Dr. Jampolsky. I'm a faculty member at University of Louisville.", "tokens": [50364, 9788, 30, 1079, 13, 16723, 13, 407, 452, 1315, 307, 2491, 13, 508, 1215, 19385, 4133, 13, 286, 478, 257, 6389, 4006, 412, 3535, 295, 9763, 8386, 13, 50812], "temperature": 0.0, "avg_logprob": -0.10332816267666751, "compression_ratio": 1.3463414634146342, "no_speech_prob": 0.01892135851085186}, {"id": 13, "seek": 7672, "start": 85.68, "end": 94.0, "text": " I've been doing work on AI safety for about 10 years now. Give or take. And my latest work covers", "tokens": [50812, 286, 600, 668, 884, 589, 322, 7318, 4514, 337, 466, 1266, 924, 586, 13, 5303, 420, 747, 13, 400, 452, 6792, 589, 10538, 51228], "temperature": 0.0, "avg_logprob": -0.10332816267666751, "compression_ratio": 1.3463414634146342, "no_speech_prob": 0.01892135851085186}, {"id": 14, "seek": 7672, "start": 94.56, "end": 101.03999999999999, "text": " what I will call impossibility results. Problems we encounter with actually", "tokens": [51256, 437, 286, 486, 818, 38802, 2841, 3542, 13, 11676, 82, 321, 8593, 365, 767, 51580], "temperature": 0.0, "avg_logprob": -0.10332816267666751, "compression_ratio": 1.3463414634146342, "no_speech_prob": 0.01892135851085186}, {"id": 15, "seek": 10104, "start": 101.04, "end": 109.84, "text": " accomplishing what we think is necessary for us to do not just development work for AI,", "tokens": [50364, 6548, 3807, 437, 321, 519, 307, 4818, 337, 505, 281, 360, 406, 445, 3250, 589, 337, 7318, 11, 50804], "temperature": 0.0, "avg_logprob": -0.0552491648443814, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.02377573773264885}, {"id": 16, "seek": 10104, "start": 109.84, "end": 116.48, "text": " but also work in terms of control and safety. If you would like to learn more about my work", "tokens": [50804, 457, 611, 589, 294, 2115, 295, 1969, 293, 4514, 13, 759, 291, 576, 411, 281, 1466, 544, 466, 452, 589, 51136], "temperature": 0.0, "avg_logprob": -0.0552491648443814, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.02377573773264885}, {"id": 17, "seek": 10104, "start": 117.12, "end": 122.32000000000001, "text": " after this talk, you are definitely welcome to follow me. You can follow me on Twitter,", "tokens": [51168, 934, 341, 751, 11, 291, 366, 2138, 2928, 281, 1524, 385, 13, 509, 393, 1524, 385, 322, 5794, 11, 51428], "temperature": 0.0, "avg_logprob": -0.0552491648443814, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.02377573773264885}, {"id": 18, "seek": 10104, "start": 122.32000000000001, "end": 126.88000000000001, "text": " follow me on Facebook. I always encourage you not to follow me home. It's very important.", "tokens": [51428, 1524, 385, 322, 4384, 13, 286, 1009, 5373, 291, 406, 281, 1524, 385, 1280, 13, 467, 311, 588, 1021, 13, 51656], "temperature": 0.0, "avg_logprob": -0.0552491648443814, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.02377573773264885}, {"id": 19, "seek": 12688, "start": 127.75999999999999, "end": 137.76, "text": " So let's start with the big problem right away. If you heard previous talks at this conference,", "tokens": [50408, 407, 718, 311, 722, 365, 264, 955, 1154, 558, 1314, 13, 759, 291, 2198, 3894, 6686, 412, 341, 7586, 11, 50908], "temperature": 0.0, "avg_logprob": -0.2201258341471354, "compression_ratio": 1.4923857868020305, "no_speech_prob": 0.00391597393900156}, {"id": 20, "seek": 12688, "start": 137.76, "end": 144.96, "text": " I had a chance to hear a little bit. You know about concerns a lot of people have with advanced", "tokens": [50908, 286, 632, 257, 2931, 281, 1568, 257, 707, 857, 13, 509, 458, 466, 7389, 257, 688, 295, 561, 362, 365, 7339, 51268], "temperature": 0.0, "avg_logprob": -0.2201258341471354, "compression_ratio": 1.4923857868020305, "no_speech_prob": 0.00391597393900156}, {"id": 21, "seek": 12688, "start": 144.96, "end": 153.92, "text": " artificial intelligence, usually called AI safety, AI alignment problem, sometimes AI control problem.", "tokens": [51268, 11677, 7599, 11, 2673, 1219, 7318, 4514, 11, 7318, 18515, 1154, 11, 2171, 7318, 1969, 1154, 13, 51716], "temperature": 0.0, "avg_logprob": -0.2201258341471354, "compression_ratio": 1.4923857868020305, "no_speech_prob": 0.00391597393900156}, {"id": 22, "seek": 15392, "start": 154.16, "end": 160.56, "text": " The question is the problem we're trying to solve is how can humanity remain safely in control while", "tokens": [50376, 440, 1168, 307, 264, 1154, 321, 434, 1382, 281, 5039, 307, 577, 393, 10243, 6222, 11750, 294, 1969, 1339, 50696], "temperature": 0.0, "avg_logprob": -0.1591718296209971, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.005948283709585667}, {"id": 23, "seek": 15392, "start": 160.56, "end": 168.23999999999998, "text": " benefiting from superior form of intelligence? So we want this very capable agent to do work for us,", "tokens": [50696, 47515, 490, 13028, 1254, 295, 7599, 30, 407, 321, 528, 341, 588, 8189, 9461, 281, 360, 589, 337, 505, 11, 51080], "temperature": 0.0, "avg_logprob": -0.1591718296209971, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.005948283709585667}, {"id": 24, "seek": 15392, "start": 168.23999999999998, "end": 174.64, "text": " to be helpful, but we want to be in charge. We want to be able to undo any changes if we don't", "tokens": [51080, 281, 312, 4961, 11, 457, 321, 528, 281, 312, 294, 4602, 13, 492, 528, 281, 312, 1075, 281, 23779, 604, 2962, 498, 321, 500, 380, 51400], "temperature": 0.0, "avg_logprob": -0.1591718296209971, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.005948283709585667}, {"id": 25, "seek": 15392, "start": 174.64, "end": 183.04, "text": " like them. We want to be final decision makers as to what's going to happen. And the good news", "tokens": [51400, 411, 552, 13, 492, 528, 281, 312, 2572, 3537, 19323, 382, 281, 437, 311, 516, 281, 1051, 13, 400, 264, 665, 2583, 51820], "temperature": 0.0, "avg_logprob": -0.1591718296209971, "compression_ratio": 1.6024590163934427, "no_speech_prob": 0.005948283709585667}, {"id": 26, "seek": 18304, "start": 184.0, "end": 189.44, "text": " is after 10 years of building up the movement, there is a lot of people working on this now.", "tokens": [50412, 307, 934, 1266, 924, 295, 2390, 493, 264, 3963, 11, 456, 307, 257, 688, 295, 561, 1364, 322, 341, 586, 13, 50684], "temperature": 0.0, "avg_logprob": -0.11299442988570019, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.0023452346213161945}, {"id": 27, "seek": 18304, "start": 189.44, "end": 197.2, "text": " There is a lot of research labs, a lot of PhD programs, but I think the main question of", "tokens": [50684, 821, 307, 257, 688, 295, 2132, 20339, 11, 257, 688, 295, 14476, 4268, 11, 457, 286, 519, 264, 2135, 1168, 295, 51072], "temperature": 0.0, "avg_logprob": -0.11299442988570019, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.0023452346213161945}, {"id": 28, "seek": 18304, "start": 197.76, "end": 203.35999999999999, "text": " control problem has not been addressed sufficiently. And that is, is the problem actually solvable?", "tokens": [51100, 1969, 1154, 575, 406, 668, 13847, 31868, 13, 400, 300, 307, 11, 307, 264, 1154, 767, 1404, 17915, 30, 51380], "temperature": 0.0, "avg_logprob": -0.11299442988570019, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.0023452346213161945}, {"id": 29, "seek": 18304, "start": 203.35999999999999, "end": 209.51999999999998, "text": " So everyone kind of works on it, but I haven't seen much in terms of proofs or even rigorous", "tokens": [51380, 407, 1518, 733, 295, 1985, 322, 309, 11, 457, 286, 2378, 380, 1612, 709, 294, 2115, 295, 8177, 82, 420, 754, 29882, 51688], "temperature": 0.0, "avg_logprob": -0.11299442988570019, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.0023452346213161945}, {"id": 30, "seek": 20952, "start": 209.52, "end": 215.20000000000002, "text": " argumentation for why we think we can do this. Why is this problem solvable? Is it solvable?", "tokens": [50364, 6770, 399, 337, 983, 321, 519, 321, 393, 360, 341, 13, 1545, 307, 341, 1154, 1404, 17915, 30, 1119, 309, 1404, 17915, 30, 50648], "temperature": 0.0, "avg_logprob": -0.06655637741088867, "compression_ratio": 1.7004405286343611, "no_speech_prob": 0.001569076324813068}, {"id": 31, "seek": 20952, "start": 215.20000000000002, "end": 220.96, "text": " Is it partially solvable? Maybe it's not solvable. Maybe it's a silly question. It's not even decidable.", "tokens": [50648, 1119, 309, 18886, 1404, 17915, 30, 2704, 309, 311, 406, 1404, 17915, 13, 2704, 309, 311, 257, 11774, 1168, 13, 467, 311, 406, 754, 21937, 712, 13, 50936], "temperature": 0.0, "avg_logprob": -0.06655637741088867, "compression_ratio": 1.7004405286343611, "no_speech_prob": 0.001569076324813068}, {"id": 32, "seek": 20952, "start": 221.60000000000002, "end": 228.8, "text": " So that's essentially what I've been looking at for the last couple years. And I started by", "tokens": [50968, 407, 300, 311, 4476, 437, 286, 600, 668, 1237, 412, 337, 264, 1036, 1916, 924, 13, 400, 286, 1409, 538, 51328], "temperature": 0.0, "avg_logprob": -0.06655637741088867, "compression_ratio": 1.7004405286343611, "no_speech_prob": 0.001569076324813068}, {"id": 33, "seek": 20952, "start": 228.8, "end": 234.56, "text": " formalizing a little bit what I mean by control problem. So we can talk about different types of", "tokens": [51328, 9860, 3319, 257, 707, 857, 437, 286, 914, 538, 1969, 1154, 13, 407, 321, 393, 751, 466, 819, 3467, 295, 51616], "temperature": 0.0, "avg_logprob": -0.06655637741088867, "compression_ratio": 1.7004405286343611, "no_speech_prob": 0.001569076324813068}, {"id": 34, "seek": 23456, "start": 234.64000000000001, "end": 242.24, "text": " control. We have explicit control where you give orders and the system follows. And this is the", "tokens": [50368, 1969, 13, 492, 362, 13691, 1969, 689, 291, 976, 9470, 293, 264, 1185, 10002, 13, 400, 341, 307, 264, 50748], "temperature": 0.0, "avg_logprob": -0.10310257359554893, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.008824962191283703}, {"id": 35, "seek": 23456, "start": 242.24, "end": 247.68, "text": " kind of standard Gini problem, right? You wish for things, then you realize that's not what I meant", "tokens": [50748, 733, 295, 3832, 460, 3812, 1154, 11, 558, 30, 509, 3172, 337, 721, 11, 550, 291, 4325, 300, 311, 406, 437, 286, 4140, 51020], "temperature": 0.0, "avg_logprob": -0.10310257359554893, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.008824962191283703}, {"id": 36, "seek": 23456, "start": 247.68, "end": 254.32, "text": " and you hope you get to undo the damage. Then there is implicit control. So you have a system with", "tokens": [51020, 293, 291, 1454, 291, 483, 281, 23779, 264, 4344, 13, 1396, 456, 307, 26947, 1969, 13, 407, 291, 362, 257, 1185, 365, 51352], "temperature": 0.0, "avg_logprob": -0.10310257359554893, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.008824962191283703}, {"id": 37, "seek": 23456, "start": 254.32, "end": 259.76, "text": " a little more common sense. It doesn't take your words literally, it tries to kind of parse things", "tokens": [51352, 257, 707, 544, 2689, 2020, 13, 467, 1177, 380, 747, 428, 2283, 3736, 11, 309, 9898, 281, 733, 295, 48377, 721, 51624], "temperature": 0.0, "avg_logprob": -0.10310257359554893, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.008824962191283703}, {"id": 38, "seek": 25976, "start": 259.76, "end": 266.24, "text": " in the right way. And there are intermediate steps between explicit and delegated control.", "tokens": [50364, 294, 264, 558, 636, 13, 400, 456, 366, 19376, 4439, 1296, 13691, 293, 15824, 770, 1969, 13, 50688], "temperature": 0.0, "avg_logprob": -0.07834712938330639, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.0048815165646374226}, {"id": 39, "seek": 25976, "start": 266.24, "end": 272.4, "text": " Delegated control is the other extreme where you have this superintelligent system very friendly.", "tokens": [50688, 1346, 6363, 770, 1969, 307, 264, 661, 8084, 689, 291, 362, 341, 1687, 20761, 25002, 1185, 588, 9208, 13, 50996], "temperature": 0.0, "avg_logprob": -0.07834712938330639, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.0048815165646374226}, {"id": 40, "seek": 25976, "start": 272.4, "end": 278.0, "text": " It knows what needs to happen better than you do. And you might be even very happy with the", "tokens": [50996, 467, 3255, 437, 2203, 281, 1051, 1101, 813, 291, 360, 13, 400, 291, 1062, 312, 754, 588, 2055, 365, 264, 51276], "temperature": 0.0, "avg_logprob": -0.07834712938330639, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.0048815165646374226}, {"id": 41, "seek": 25976, "start": 278.0, "end": 284.32, "text": " decisions it makes, but you're not in charge. The system is completely in control. Aligned control", "tokens": [51276, 5327, 309, 1669, 11, 457, 291, 434, 406, 294, 4602, 13, 440, 1185, 307, 2584, 294, 1969, 13, 967, 16690, 1969, 51592], "temperature": 0.0, "avg_logprob": -0.07834712938330639, "compression_ratio": 1.6266094420600858, "no_speech_prob": 0.0048815165646374226}, {"id": 42, "seek": 28432, "start": 284.32, "end": 291.12, "text": " is another intermediate option where the system kind of understands your values, human values,", "tokens": [50364, 307, 1071, 19376, 3614, 689, 264, 1185, 733, 295, 15146, 428, 4190, 11, 1952, 4190, 11, 50704], "temperature": 0.0, "avg_logprob": -0.07853486045958503, "compression_ratio": 1.6243093922651934, "no_speech_prob": 0.00304594449698925}, {"id": 43, "seek": 28432, "start": 291.12, "end": 300.4, "text": " and tries to do the best it can to fulfill those values, even if your spoken directions are not", "tokens": [50704, 293, 9898, 281, 360, 264, 1151, 309, 393, 281, 13875, 729, 4190, 11, 754, 498, 428, 10759, 11095, 366, 406, 51168], "temperature": 0.0, "avg_logprob": -0.07853486045958503, "compression_ratio": 1.6243093922651934, "no_speech_prob": 0.00304594449698925}, {"id": 44, "seek": 28432, "start": 300.4, "end": 313.44, "text": " exactly what maps onto those ideal values. So it seems at least from now that some sort of intermediate", "tokens": [51168, 2293, 437, 11317, 3911, 729, 7157, 4190, 13, 407, 309, 2544, 412, 1935, 490, 586, 300, 512, 1333, 295, 19376, 51820], "temperature": 0.0, "avg_logprob": -0.07853486045958503, "compression_ratio": 1.6243093922651934, "no_speech_prob": 0.00304594449698925}, {"id": 45, "seek": 31432, "start": 314.71999999999997, "end": 323.28, "text": " value between total control and total autonomy for the system is necessary for us to be happy with", "tokens": [50384, 2158, 1296, 3217, 1969, 293, 3217, 27278, 337, 264, 1185, 307, 4818, 337, 505, 281, 312, 2055, 365, 50812], "temperature": 0.0, "avg_logprob": -0.08769585775292438, "compression_ratio": 1.72, "no_speech_prob": 0.009275216609239578}, {"id": 46, "seek": 31432, "start": 323.28, "end": 330.48, "text": " the results. If a system is completely autonomous, we have no control over it. By definition, we", "tokens": [50812, 264, 3542, 13, 759, 257, 1185, 307, 2584, 23797, 11, 321, 362, 572, 1969, 670, 309, 13, 3146, 7123, 11, 321, 51172], "temperature": 0.0, "avg_logprob": -0.08769585775292438, "compression_ratio": 1.72, "no_speech_prob": 0.009275216609239578}, {"id": 47, "seek": 31432, "start": 330.48, "end": 336.4, "text": " will lose control. If a system has no autonomy, it's completely deterministic. We decide ahead", "tokens": [51172, 486, 3624, 1969, 13, 759, 257, 1185, 575, 572, 27278, 11, 309, 311, 2584, 15957, 3142, 13, 492, 4536, 2286, 51468], "temperature": 0.0, "avg_logprob": -0.08769585775292438, "compression_ratio": 1.72, "no_speech_prob": 0.009275216609239578}, {"id": 48, "seek": 31432, "start": 336.4, "end": 341.03999999999996, "text": " of time what's going to happen. It's not very useful. It cannot be generally intelligent. It's a", "tokens": [51468, 295, 565, 437, 311, 516, 281, 1051, 13, 467, 311, 406, 588, 4420, 13, 467, 2644, 312, 5101, 13232, 13, 467, 311, 257, 51700], "temperature": 0.0, "avg_logprob": -0.08769585775292438, "compression_ratio": 1.72, "no_speech_prob": 0.009275216609239578}, {"id": 49, "seek": 34104, "start": 341.04, "end": 349.20000000000005, "text": " great way to do simple tasks for a narrow AI, but it's not something we can utilize to solve", "tokens": [50364, 869, 636, 281, 360, 2199, 9608, 337, 257, 9432, 7318, 11, 457, 309, 311, 406, 746, 321, 393, 16117, 281, 5039, 50772], "temperature": 0.0, "avg_logprob": -0.09758614945685727, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0022974854800850153}, {"id": 50, "seek": 34104, "start": 350.16, "end": 356.08000000000004, "text": " completely new problems and new domains, help us with science, help us cure diseases and things", "tokens": [50820, 2584, 777, 2740, 293, 777, 25514, 11, 854, 505, 365, 3497, 11, 854, 505, 13698, 11044, 293, 721, 51116], "temperature": 0.0, "avg_logprob": -0.09758614945685727, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0022974854800850153}, {"id": 51, "seek": 34104, "start": 356.08000000000004, "end": 362.24, "text": " like that. So what I try to do is kind of break down the bigger problem of control", "tokens": [51116, 411, 300, 13, 407, 437, 286, 853, 281, 360, 307, 733, 295, 1821, 760, 264, 3801, 1154, 295, 1969, 51424], "temperature": 0.0, "avg_logprob": -0.09758614945685727, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0022974854800850153}, {"id": 52, "seek": 34104, "start": 362.24, "end": 367.6, "text": " into all the ingredients we need, all the tools we would need to make controllability possible.", "tokens": [51424, 666, 439, 264, 6952, 321, 643, 11, 439, 264, 3873, 321, 576, 643, 281, 652, 45159, 2310, 1944, 13, 51692], "temperature": 0.0, "avg_logprob": -0.09758614945685727, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0022974854800850153}, {"id": 53, "seek": 36760, "start": 368.56, "end": 373.84000000000003, "text": " So what do you need? You can start thinking for yourself. If you want to be in control,", "tokens": [50412, 407, 437, 360, 291, 643, 30, 509, 393, 722, 1953, 337, 1803, 13, 759, 291, 528, 281, 312, 294, 1969, 11, 50676], "temperature": 0.0, "avg_logprob": -0.0720075903267696, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0014066190924495459}, {"id": 54, "seek": 36760, "start": 373.84000000000003, "end": 379.20000000000005, "text": " well, you kind of have to understand the situation. What is the system doing? Can the system explain", "tokens": [50676, 731, 11, 291, 733, 295, 362, 281, 1223, 264, 2590, 13, 708, 307, 264, 1185, 884, 30, 1664, 264, 1185, 2903, 50944], "temperature": 0.0, "avg_logprob": -0.0720075903267696, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0014066190924495459}, {"id": 55, "seek": 36760, "start": 379.20000000000005, "end": 384.72, "text": " what it's doing? Can you comprehend the explanation? That's another very important one. Can you predict", "tokens": [50944, 437, 309, 311, 884, 30, 1664, 291, 38183, 264, 10835, 30, 663, 311, 1071, 588, 1021, 472, 13, 1664, 291, 6069, 51220], "temperature": 0.0, "avg_logprob": -0.0720075903267696, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0014066190924495459}, {"id": 56, "seek": 36760, "start": 384.72, "end": 390.0, "text": " what the system is likely to do? Maybe not just direction in which it is going, but specifics.", "tokens": [51220, 437, 264, 1185, 307, 3700, 281, 360, 30, 2704, 406, 445, 3513, 294, 597, 309, 307, 516, 11, 457, 28454, 13, 51484], "temperature": 0.0, "avg_logprob": -0.0720075903267696, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0014066190924495459}, {"id": 57, "seek": 36760, "start": 390.0, "end": 396.96000000000004, "text": " What steps will it take? Can you verify that whatever it is you want the system to do and", "tokens": [51484, 708, 4439, 486, 309, 747, 30, 1664, 291, 16888, 300, 2035, 309, 307, 291, 528, 264, 1185, 281, 360, 293, 51832], "temperature": 0.0, "avg_logprob": -0.0720075903267696, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0014066190924495459}, {"id": 58, "seek": 39696, "start": 397.03999999999996, "end": 404.15999999999997, "text": " program it to do is actually going to happen? So can you verify the implementation versus the model?", "tokens": [50368, 1461, 309, 281, 360, 307, 767, 516, 281, 1051, 30, 407, 393, 291, 16888, 264, 11420, 5717, 264, 2316, 30, 50724], "temperature": 0.0, "avg_logprob": -0.11496720368834748, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0012578282039612532}, {"id": 59, "seek": 39696, "start": 404.15999999999997, "end": 410.32, "text": " Can you verify the model against your goals and data and so on? That is also a need for", "tokens": [50724, 1664, 291, 16888, 264, 2316, 1970, 428, 5493, 293, 1412, 293, 370, 322, 30, 663, 307, 611, 257, 643, 337, 51032], "temperature": 0.0, "avg_logprob": -0.11496720368834748, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0012578282039612532}, {"id": 60, "seek": 39696, "start": 410.88, "end": 417.12, "text": " general ability to govern AI research, AI systems, so governability of that. And of course,", "tokens": [51060, 2674, 3485, 281, 1980, 7318, 2132, 11, 7318, 3652, 11, 370, 1980, 2310, 295, 300, 13, 400, 295, 1164, 11, 51372], "temperature": 0.0, "avg_logprob": -0.11496720368834748, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0012578282039612532}, {"id": 61, "seek": 39696, "start": 417.12, "end": 424.0, "text": " we communicate with systems in human language and we need to make sure that communication we use", "tokens": [51372, 321, 7890, 365, 3652, 294, 1952, 2856, 293, 321, 643, 281, 652, 988, 300, 6101, 321, 764, 51716], "temperature": 0.0, "avg_logprob": -0.11496720368834748, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0012578282039612532}, {"id": 62, "seek": 42400, "start": 424.0, "end": 431.36, "text": " is unambiguous. There is no way to misinterpret commands in a potentially dangerous way.", "tokens": [50364, 307, 517, 2173, 30525, 13, 821, 307, 572, 636, 281, 3346, 41935, 16901, 294, 257, 7263, 5795, 636, 13, 50732], "temperature": 0.0, "avg_logprob": -0.09882928012462144, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.002270969096571207}, {"id": 63, "seek": 42400, "start": 431.36, "end": 436.88, "text": " And there is many, many more such limitations. And what I've been doing, kind of looking at each", "tokens": [50732, 400, 456, 307, 867, 11, 867, 544, 1270, 15705, 13, 400, 437, 286, 600, 668, 884, 11, 733, 295, 1237, 412, 1184, 51008], "temperature": 0.0, "avg_logprob": -0.09882928012462144, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.002270969096571207}, {"id": 64, "seek": 42400, "start": 436.88, "end": 442.96, "text": " one and trying to publish those results. So I'll go over some of the publications I have on that", "tokens": [51008, 472, 293, 1382, 281, 11374, 729, 3542, 13, 407, 286, 603, 352, 670, 512, 295, 264, 25618, 286, 362, 322, 300, 51312], "temperature": 0.0, "avg_logprob": -0.09882928012462144, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.002270969096571207}, {"id": 65, "seek": 42400, "start": 443.6, "end": 450.0, "text": " so far. One paper talks about limits to explainability and incomprehensibility.", "tokens": [51344, 370, 1400, 13, 1485, 3035, 6686, 466, 10406, 281, 2903, 2310, 293, 14036, 40128, 694, 2841, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09882928012462144, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.002270969096571207}, {"id": 66, "seek": 45000, "start": 450.0, "end": 458.72, "text": " So essentially, for very complex systems, large neural networks, it is impossible for the system", "tokens": [50364, 407, 4476, 11, 337, 588, 3997, 3652, 11, 2416, 18161, 9590, 11, 309, 307, 6243, 337, 264, 1185, 50800], "temperature": 0.0, "avg_logprob": -0.1035677482341898, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.002202568342909217}, {"id": 67, "seek": 45000, "start": 458.72, "end": 465.6, "text": " to provide an exact explanation of what it is doing or why without simplifying it to the point of", "tokens": [50800, 281, 2893, 364, 1900, 10835, 295, 437, 309, 307, 884, 420, 983, 1553, 6883, 5489, 309, 281, 264, 935, 295, 51144], "temperature": 0.0, "avg_logprob": -0.1035677482341898, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.002202568342909217}, {"id": 68, "seek": 45000, "start": 465.6, "end": 471.92, "text": " where it is like you explaining something to a child. So a lot of important details are removed", "tokens": [51144, 689, 309, 307, 411, 291, 13468, 746, 281, 257, 1440, 13, 407, 257, 688, 295, 1021, 4365, 366, 7261, 51460], "temperature": 0.0, "avg_logprob": -0.1035677482341898, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.002202568342909217}, {"id": 69, "seek": 45000, "start": 471.92, "end": 476.48, "text": " and then a very simplified version is given to you because if a full version is given to you,", "tokens": [51460, 293, 550, 257, 588, 26335, 3037, 307, 2212, 281, 291, 570, 498, 257, 1577, 3037, 307, 2212, 281, 291, 11, 51688], "temperature": 0.0, "avg_logprob": -0.1035677482341898, "compression_ratio": 1.7219730941704037, "no_speech_prob": 0.002202568342909217}, {"id": 70, "seek": 47648, "start": 476.48, "end": 482.88, "text": " you'll simply not be able to comprehend it. And if you want to learn more and see the kind of", "tokens": [50364, 291, 603, 2935, 406, 312, 1075, 281, 38183, 309, 13, 400, 498, 291, 528, 281, 1466, 544, 293, 536, 264, 733, 295, 50684], "temperature": 0.0, "avg_logprob": -0.17291134054010565, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.0026469649747014046}, {"id": 71, "seek": 47648, "start": 482.88, "end": 488.16, "text": " argumentation, in some cases, proofs, just go to the paper. I provide all the information you need", "tokens": [50684, 6770, 399, 11, 294, 512, 3331, 11, 8177, 82, 11, 445, 352, 281, 264, 3035, 13, 286, 2893, 439, 264, 1589, 291, 643, 50948], "temperature": 0.0, "avg_logprob": -0.17291134054010565, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.0026469649747014046}, {"id": 72, "seek": 47648, "start": 488.16, "end": 493.52000000000004, "text": " to get access to those papers. There are also available as preprints on my Google scholar account.", "tokens": [50948, 281, 483, 2105, 281, 729, 10577, 13, 821, 366, 611, 2435, 382, 659, 25788, 322, 452, 3329, 17912, 2696, 13, 51216], "temperature": 0.0, "avg_logprob": -0.17291134054010565, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.0026469649747014046}, {"id": 73, "seek": 47648, "start": 495.12, "end": 500.96000000000004, "text": " Another impossibility result is unpredictability and that's our inability to", "tokens": [51296, 3996, 38802, 2841, 1874, 307, 28341, 2310, 293, 300, 311, 527, 33162, 281, 51588], "temperature": 0.0, "avg_logprob": -0.17291134054010565, "compression_ratio": 1.593073593073593, "no_speech_prob": 0.0026469649747014046}, {"id": 74, "seek": 50096, "start": 501.35999999999996, "end": 508.4, "text": " precisely predict all decisions, all intermediate steps, a much smarter agent will take.", "tokens": [50384, 13402, 6069, 439, 5327, 11, 439, 19376, 4439, 11, 257, 709, 20294, 9461, 486, 747, 13, 50736], "temperature": 0.0, "avg_logprob": -0.19728256407238187, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.002964576706290245}, {"id": 75, "seek": 50096, "start": 508.4, "end": 513.68, "text": " Of course, if we could predict all the decisions of a smarter agent, we ourselves would be that", "tokens": [50736, 2720, 1164, 11, 498, 321, 727, 6069, 439, 264, 5327, 295, 257, 20294, 9461, 11, 321, 4175, 576, 312, 300, 51000], "temperature": 0.0, "avg_logprob": -0.19728256407238187, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.002964576706290245}, {"id": 76, "seek": 50096, "start": 513.68, "end": 520.64, "text": " smart and by definition, there wouldn't be much of an intelligence gap, cognitive gap between us.", "tokens": [51000, 4069, 293, 538, 7123, 11, 456, 2759, 380, 312, 709, 295, 364, 7599, 7417, 11, 15605, 7417, 1296, 505, 13, 51348], "temperature": 0.0, "avg_logprob": -0.19728256407238187, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.002964576706290245}, {"id": 77, "seek": 50096, "start": 521.84, "end": 528.56, "text": " That is also problems with verifiability. We know for a fact that with software,", "tokens": [51408, 663, 307, 611, 2740, 365, 1306, 17638, 2310, 13, 492, 458, 337, 257, 1186, 300, 365, 4722, 11, 51744], "temperature": 0.0, "avg_logprob": -0.19728256407238187, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.002964576706290245}, {"id": 78, "seek": 52856, "start": 529.1199999999999, "end": 536.88, "text": " with mathematical proofs, we can only get to a certain degree of confidence, but never 100%", "tokens": [50392, 365, 18894, 8177, 82, 11, 321, 393, 787, 483, 281, 257, 1629, 4314, 295, 6687, 11, 457, 1128, 2319, 4, 50780], "temperature": 0.0, "avg_logprob": -0.11757175127665202, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0013373882975429296}, {"id": 79, "seek": 52856, "start": 536.88, "end": 544.16, "text": " confidence in the fact that we have no errors in the proof. So with more resources, we can", "tokens": [50780, 6687, 294, 264, 1186, 300, 321, 362, 572, 13603, 294, 264, 8177, 13, 407, 365, 544, 3593, 11, 321, 393, 51144], "temperature": 0.0, "avg_logprob": -0.11757175127665202, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0013373882975429296}, {"id": 80, "seek": 52856, "start": 544.16, "end": 551.1999999999999, "text": " increase safety and security, but we're never able to guarantee something with 100% accuracy,", "tokens": [51144, 3488, 4514, 293, 3825, 11, 457, 321, 434, 1128, 1075, 281, 10815, 746, 365, 2319, 4, 14170, 11, 51496], "temperature": 0.0, "avg_logprob": -0.11757175127665202, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0013373882975429296}, {"id": 81, "seek": 52856, "start": 551.1999999999999, "end": 556.88, "text": " which is a problem for a superintelligence system, which makes potentially billions of", "tokens": [51496, 597, 307, 257, 1154, 337, 257, 1687, 20761, 17644, 1185, 11, 597, 1669, 7263, 17375, 295, 51780], "temperature": 0.0, "avg_logprob": -0.11757175127665202, "compression_ratio": 1.6133333333333333, "no_speech_prob": 0.0013373882975429296}, {"id": 82, "seek": 55688, "start": 556.88, "end": 563.12, "text": " decisions every minute. Even if one in 100 million creates a problem, you're guaranteed to have a", "tokens": [50364, 5327, 633, 3456, 13, 2754, 498, 472, 294, 2319, 2459, 7829, 257, 1154, 11, 291, 434, 18031, 281, 362, 257, 50676], "temperature": 0.0, "avg_logprob": -0.1132851182744744, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015166020020842552}, {"id": 83, "seek": 55688, "start": 563.12, "end": 570.88, "text": " huge problem within a minute or so. There are also problems with governance. We have history of", "tokens": [50676, 2603, 1154, 1951, 257, 3456, 420, 370, 13, 821, 366, 611, 2740, 365, 17449, 13, 492, 362, 2503, 295, 51064], "temperature": 0.0, "avg_logprob": -0.1132851182744744, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015166020020842552}, {"id": 84, "seek": 55688, "start": 570.88, "end": 578.88, "text": " trying to govern technology, things like spam and computer viruses. We have laws against those", "tokens": [51064, 1382, 281, 1980, 2899, 11, 721, 411, 24028, 293, 3820, 21785, 13, 492, 362, 6064, 1970, 729, 51464], "temperature": 0.0, "avg_logprob": -0.1132851182744744, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015166020020842552}, {"id": 85, "seek": 55688, "start": 579.6, "end": 585.36, "text": " malevolent software products, but they don't seem to be doing much. So it's not obvious how much", "tokens": [51500, 7133, 9646, 317, 4722, 3383, 11, 457, 436, 500, 380, 1643, 281, 312, 884, 709, 13, 407, 309, 311, 406, 6322, 577, 709, 51788], "temperature": 0.0, "avg_logprob": -0.1132851182744744, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0015166020020842552}, {"id": 86, "seek": 58536, "start": 585.36, "end": 591.52, "text": " benefit is actually added and other negative consequences from trying to control research,", "tokens": [50364, 5121, 307, 767, 3869, 293, 661, 3671, 10098, 490, 1382, 281, 1969, 2132, 11, 50672], "temperature": 0.0, "avg_logprob": -0.0785245637635927, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0019379795994609594}, {"id": 87, "seek": 58536, "start": 591.52, "end": 600.32, "text": " control what is allowed and not allowed to be experimented with. Even the orders we give to", "tokens": [50672, 1969, 437, 307, 4350, 293, 406, 4350, 281, 312, 5120, 292, 365, 13, 2754, 264, 9470, 321, 976, 281, 51112], "temperature": 0.0, "avg_logprob": -0.0785245637635927, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0019379795994609594}, {"id": 88, "seek": 58536, "start": 600.32, "end": 606.72, "text": " the system, the communication channel through English is very ambiguous and you're almost", "tokens": [51112, 264, 1185, 11, 264, 6101, 2269, 807, 3669, 307, 588, 39465, 293, 291, 434, 1920, 51432], "temperature": 0.0, "avg_logprob": -0.0785245637635927, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0019379795994609594}, {"id": 89, "seek": 58536, "start": 606.72, "end": 613.84, "text": " guaranteed to run into situations where your orders will be misinterpreted at multiple levels", "tokens": [51432, 18031, 281, 1190, 666, 6851, 689, 428, 9470, 486, 312, 3346, 41935, 292, 412, 3866, 4358, 51788], "temperature": 0.0, "avg_logprob": -0.0785245637635927, "compression_ratio": 1.6194690265486726, "no_speech_prob": 0.0019379795994609594}, {"id": 90, "seek": 61384, "start": 613.84, "end": 621.84, "text": " due to how imprecise human languages are. So what we did with our colleague, we surveyed a lot of", "tokens": [50364, 3462, 281, 577, 704, 13867, 908, 1952, 8650, 366, 13, 407, 437, 321, 630, 365, 527, 13532, 11, 321, 8984, 292, 257, 688, 295, 50764], "temperature": 0.0, "avg_logprob": -0.11570612243984056, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0026679837610572577}, {"id": 91, "seek": 61384, "start": 621.84, "end": 627.9200000000001, "text": " those impossibility results. Those I looked at and those other people have looked at, I'm not going", "tokens": [50764, 729, 38802, 2841, 3542, 13, 3950, 286, 2956, 412, 293, 729, 661, 561, 362, 2956, 412, 11, 286, 478, 406, 516, 51068], "temperature": 0.0, "avg_logprob": -0.11570612243984056, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0026679837610572577}, {"id": 92, "seek": 61384, "start": 627.9200000000001, "end": 635.0400000000001, "text": " to go into details of all of them. I can just tell you there is a lot of them and some purely", "tokens": [51068, 281, 352, 666, 4365, 295, 439, 295, 552, 13, 286, 393, 445, 980, 291, 456, 307, 257, 688, 295, 552, 293, 512, 17491, 51424], "temperature": 0.0, "avg_logprob": -0.11570612243984056, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0026679837610572577}, {"id": 93, "seek": 61384, "start": 635.0400000000001, "end": 640.72, "text": " software problems, mathematical problems, many problems with physics of the universe,", "tokens": [51424, 4722, 2740, 11, 18894, 2740, 11, 867, 2740, 365, 10649, 295, 264, 6445, 11, 51708], "temperature": 0.0, "avg_logprob": -0.11570612243984056, "compression_ratio": 1.6391304347826088, "no_speech_prob": 0.0026679837610572577}, {"id": 94, "seek": 64072, "start": 641.36, "end": 648.1600000000001, "text": " impossibility results from physics. But if you think even a small subset of all those tools", "tokens": [50396, 38802, 2841, 3542, 490, 10649, 13, 583, 498, 291, 519, 754, 257, 1359, 25993, 295, 439, 729, 3873, 50736], "temperature": 0.0, "avg_logprob": -0.11729516654179015, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0043065729551017284}, {"id": 95, "seek": 64072, "start": 648.1600000000001, "end": 654.0, "text": " is necessary to solve the control problem, you have to come to the conclusion that control", "tokens": [50736, 307, 4818, 281, 5039, 264, 1969, 1154, 11, 291, 362, 281, 808, 281, 264, 10063, 300, 1969, 51028], "temperature": 0.0, "avg_logprob": -0.11729516654179015, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0043065729551017284}, {"id": 96, "seek": 64072, "start": 654.0, "end": 661.28, "text": " is not possible. At least not 100% guaranteed safe, secure control we all dream about. And I", "tokens": [51028, 307, 406, 1944, 13, 1711, 1935, 406, 2319, 4, 18031, 3273, 11, 7144, 1969, 321, 439, 3055, 466, 13, 400, 286, 51392], "temperature": 0.0, "avg_logprob": -0.11729516654179015, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0043065729551017284}, {"id": 97, "seek": 64072, "start": 661.28, "end": 668.88, "text": " have a very lengthy paper about that, about 70 pages. I now have a few subsections of it", "tokens": [51392, 362, 257, 588, 35374, 3035, 466, 300, 11, 466, 5285, 7183, 13, 286, 586, 362, 257, 1326, 1422, 40329, 295, 309, 51772], "temperature": 0.0, "avg_logprob": -0.11729516654179015, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.0043065729551017284}, {"id": 98, "seek": 66888, "start": 668.88, "end": 675.36, "text": " published coming out in conferences, those should be a lot more readable. But I think I", "tokens": [50364, 6572, 1348, 484, 294, 22032, 11, 729, 820, 312, 257, 688, 544, 49857, 13, 583, 286, 519, 286, 50688], "temperature": 0.0, "avg_logprob": -0.09314416666499904, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.009865287691354752}, {"id": 99, "seek": 66888, "start": 676.16, "end": 681.36, "text": " bring up a lot of interesting questions and additional directions for research and hopefully", "tokens": [50728, 1565, 493, 257, 688, 295, 1880, 1651, 293, 4497, 11095, 337, 2132, 293, 4696, 50988], "temperature": 0.0, "avg_logprob": -0.09314416666499904, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.009865287691354752}, {"id": 100, "seek": 66888, "start": 681.36, "end": 690.64, "text": " in the next half hour or 40 minutes we can talk about what all this means and how we can move", "tokens": [50988, 294, 264, 958, 1922, 1773, 420, 3356, 2077, 321, 393, 751, 466, 437, 439, 341, 1355, 293, 577, 321, 393, 1286, 51452], "temperature": 0.0, "avg_logprob": -0.09314416666499904, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.009865287691354752}, {"id": 101, "seek": 69064, "start": 690.64, "end": 702.64, "text": " forward from where we are right now. Thank you very much, Roman, for this introduction already.", "tokens": [50364, 2128, 490, 689, 321, 366, 558, 586, 13, 1044, 291, 588, 709, 11, 8566, 11, 337, 341, 9339, 1217, 13, 50964], "temperature": 0.0, "avg_logprob": -0.11487744928716304, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018207691609859467}, {"id": 102, "seek": 69064, "start": 703.76, "end": 708.8, "text": " Yes, we can now have a chat about indeed where does it leave us and where should we go from now", "tokens": [51020, 1079, 11, 321, 393, 586, 362, 257, 5081, 466, 6451, 689, 775, 309, 1856, 505, 293, 689, 820, 321, 352, 490, 586, 51272], "temperature": 0.0, "avg_logprob": -0.11487744928716304, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018207691609859467}, {"id": 103, "seek": 69064, "start": 708.8, "end": 714.56, "text": " and also a couple of related questions. And towards the end, after about 15 to 20 minutes,", "tokens": [51272, 293, 611, 257, 1916, 295, 4077, 1651, 13, 400, 3030, 264, 917, 11, 934, 466, 2119, 281, 945, 2077, 11, 51560], "temperature": 0.0, "avg_logprob": -0.11487744928716304, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018207691609859467}, {"id": 104, "seek": 69064, "start": 714.56, "end": 719.4399999999999, "text": " we will also take questions from the audience. So please, if you have any questions then please", "tokens": [51560, 321, 486, 611, 747, 1651, 490, 264, 4034, 13, 407, 1767, 11, 498, 291, 362, 604, 1651, 550, 1767, 51804], "temperature": 0.0, "avg_logprob": -0.11487744928716304, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.018207691609859467}, {"id": 105, "seek": 71944, "start": 719.44, "end": 725.9200000000001, "text": " type them into the chat. We're in the questions section rather. So first, you're spending quite a", "tokens": [50364, 2010, 552, 666, 264, 5081, 13, 492, 434, 294, 264, 1651, 3541, 2831, 13, 407, 700, 11, 291, 434, 6434, 1596, 257, 50688], "temperature": 0.0, "avg_logprob": -0.12070220092247272, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.02344120852649212}, {"id": 106, "seek": 71944, "start": 725.9200000000001, "end": 730.8000000000001, "text": " lot of time researching AI existential risk, but I don't think it's already obvious for everyone in", "tokens": [50688, 688, 295, 565, 24176, 7318, 37133, 3148, 11, 457, 286, 500, 380, 519, 309, 311, 1217, 6322, 337, 1518, 294, 50932], "temperature": 0.0, "avg_logprob": -0.12070220092247272, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.02344120852649212}, {"id": 107, "seek": 71944, "start": 730.8000000000001, "end": 737.6, "text": " the call why AI would be a danger at all. And I don't think everyone is perhaps 100% convinced", "tokens": [50932, 264, 818, 983, 7318, 576, 312, 257, 4330, 412, 439, 13, 400, 286, 500, 380, 519, 1518, 307, 4317, 2319, 4, 12561, 51272], "temperature": 0.0, "avg_logprob": -0.12070220092247272, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.02344120852649212}, {"id": 108, "seek": 71944, "start": 737.6, "end": 743.12, "text": " that this is actually an issue or an existential danger, at least that is. Could you please recap", "tokens": [51272, 300, 341, 307, 767, 364, 2734, 420, 364, 37133, 4330, 11, 412, 1935, 300, 307, 13, 7497, 291, 1767, 20928, 51548], "temperature": 0.0, "avg_logprob": -0.12070220092247272, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.02344120852649212}, {"id": 109, "seek": 71944, "start": 743.12, "end": 749.0400000000001, "text": " how exactly AI could become an existential risk according to you? Right, so there is a lot of", "tokens": [51548, 577, 2293, 7318, 727, 1813, 364, 37133, 3148, 4650, 281, 291, 30, 1779, 11, 370, 456, 307, 257, 688, 295, 51844], "temperature": 0.0, "avg_logprob": -0.12070220092247272, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.02344120852649212}, {"id": 110, "seek": 74904, "start": 749.04, "end": 756.0799999999999, "text": " ways to get to that conclusion. I have a few papers where I simply collect examples of accidents,", "tokens": [50364, 2098, 281, 483, 281, 300, 10063, 13, 286, 362, 257, 1326, 10577, 689, 286, 2935, 2500, 5110, 295, 23875, 11, 50716], "temperature": 0.0, "avg_logprob": -0.09724976902916319, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00841000210493803}, {"id": 111, "seek": 74904, "start": 756.0799999999999, "end": 761.8399999999999, "text": " AI failures throughout history. And if you look at that progression, it's kind of same exponential", "tokens": [50716, 7318, 20774, 3710, 2503, 13, 400, 498, 291, 574, 412, 300, 18733, 11, 309, 311, 733, 295, 912, 21510, 51004], "temperature": 0.0, "avg_logprob": -0.09724976902916319, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00841000210493803}, {"id": 112, "seek": 74904, "start": 761.8399999999999, "end": 766.8, "text": " chart you see with development. We get more problems, the problems become more severe,", "tokens": [51004, 6927, 291, 536, 365, 3250, 13, 492, 483, 544, 2740, 11, 264, 2740, 1813, 544, 8922, 11, 51252], "temperature": 0.0, "avg_logprob": -0.09724976902916319, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00841000210493803}, {"id": 113, "seek": 74904, "start": 767.52, "end": 774.9599999999999, "text": " and our ability to anticipate and predict them seems to be very limited. So basically the conclusion", "tokens": [51288, 293, 527, 3485, 281, 21685, 293, 6069, 552, 2544, 281, 312, 588, 5567, 13, 407, 1936, 264, 10063, 51660], "temperature": 0.0, "avg_logprob": -0.09724976902916319, "compression_ratio": 1.5802469135802468, "no_speech_prob": 0.00841000210493803}, {"id": 114, "seek": 77496, "start": 774.96, "end": 780.0, "text": " is something like, if you have a system of service to do X, eventually it fails to X.", "tokens": [50364, 307, 746, 411, 11, 498, 291, 362, 257, 1185, 295, 2643, 281, 360, 1783, 11, 4728, 309, 18199, 281, 1783, 13, 50616], "temperature": 0.0, "avg_logprob": -0.1111380467649366, "compression_ratio": 1.6405693950177935, "no_speech_prob": 0.00752596277743578}, {"id": 115, "seek": 77496, "start": 780.0, "end": 785.12, "text": " Frequently it does so very quickly and you go, hmm, okay, my self-driving car just killed a bunch", "tokens": [50616, 6142, 47519, 309, 775, 370, 588, 2661, 293, 291, 352, 11, 16478, 11, 1392, 11, 452, 2698, 12, 47094, 1032, 445, 4652, 257, 3840, 50872], "temperature": 0.0, "avg_logprob": -0.1111380467649366, "compression_ratio": 1.6405693950177935, "no_speech_prob": 0.00752596277743578}, {"id": 116, "seek": 77496, "start": 785.12, "end": 791.2, "text": " of pedestrians, that's a problem. And then it's a narrow system, the damage is limited, right? So", "tokens": [50872, 295, 48339, 11, 300, 311, 257, 1154, 13, 400, 550, 309, 311, 257, 9432, 1185, 11, 264, 4344, 307, 5567, 11, 558, 30, 407, 51176], "temperature": 0.0, "avg_logprob": -0.1111380467649366, "compression_ratio": 1.6405693950177935, "no_speech_prob": 0.00752596277743578}, {"id": 117, "seek": 77496, "start": 791.2, "end": 796.96, "text": " self-driving car, okay, the worst it can do is run through some pedestrians. But if a system", "tokens": [51176, 2698, 12, 47094, 1032, 11, 1392, 11, 264, 5855, 309, 393, 360, 307, 1190, 807, 512, 48339, 13, 583, 498, 257, 1185, 51464], "temperature": 0.0, "avg_logprob": -0.1111380467649366, "compression_ratio": 1.6405693950177935, "no_speech_prob": 0.00752596277743578}, {"id": 118, "seek": 77496, "start": 796.96, "end": 802.24, "text": " becomes general, and it's now controlling not just a single car, but networks of cars,", "tokens": [51464, 3643, 2674, 11, 293, 309, 311, 586, 14905, 406, 445, 257, 2167, 1032, 11, 457, 9590, 295, 5163, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1111380467649366, "compression_ratio": 1.6405693950177935, "no_speech_prob": 0.00752596277743578}, {"id": 119, "seek": 80224, "start": 802.32, "end": 807.2, "text": " nuclear response, airline industry, stock market, the damage is proportioned.", "tokens": [50368, 8179, 4134, 11, 29528, 3518, 11, 4127, 2142, 11, 264, 4344, 307, 16068, 292, 13, 50612], "temperature": 0.0, "avg_logprob": -0.09374965710586376, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.002657395089045167}, {"id": 120, "seek": 80224, "start": 809.04, "end": 815.2, "text": " I think it's also not the best way to assume that I have to prove that this service or product is", "tokens": [50704, 286, 519, 309, 311, 611, 406, 264, 1151, 636, 281, 6552, 300, 286, 362, 281, 7081, 300, 341, 2643, 420, 1674, 307, 51012], "temperature": 0.0, "avg_logprob": -0.09374965710586376, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.002657395089045167}, {"id": 121, "seek": 80224, "start": 815.2, "end": 820.24, "text": " dangerous. Whoever is developing and releasing it has to prove that it is safe, that it's standard", "tokens": [51012, 5795, 13, 24743, 307, 6416, 293, 16327, 309, 575, 281, 7081, 300, 309, 307, 3273, 11, 300, 309, 311, 3832, 51264], "temperature": 0.0, "avg_logprob": -0.09374965710586376, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.002657395089045167}, {"id": 122, "seek": 80224, "start": 820.24, "end": 827.28, "text": " liability law for any product. Show me that this system, which is smarter than me, smarter than you,", "tokens": [51264, 25196, 2101, 337, 604, 1674, 13, 6895, 385, 300, 341, 1185, 11, 597, 307, 20294, 813, 385, 11, 20294, 813, 291, 11, 51616], "temperature": 0.0, "avg_logprob": -0.09374965710586376, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.002657395089045167}, {"id": 123, "seek": 82728, "start": 827.28, "end": 832.48, "text": " smarter than all of us, will never do something within anticipate, something dangerous, something", "tokens": [50364, 20294, 813, 439, 295, 505, 11, 486, 1128, 360, 746, 1951, 21685, 11, 746, 5795, 11, 746, 50624], "temperature": 0.0, "avg_logprob": -0.08553470264781605, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.020748328417539597}, {"id": 124, "seek": 82728, "start": 832.48, "end": 838.16, "text": " we don't want it to do. Is this proof could at any point be possible or is it within the", "tokens": [50624, 321, 500, 380, 528, 309, 281, 360, 13, 1119, 341, 8177, 727, 412, 604, 935, 312, 1944, 420, 307, 309, 1951, 264, 50908], "temperature": 0.0, "avg_logprob": -0.08553470264781605, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.020748328417539597}, {"id": 125, "seek": 82728, "start": 838.16, "end": 845.28, "text": " impossibility realm of your theory? Well, I think I'm arguing that it's impossible to do so,", "tokens": [50908, 38802, 2841, 15355, 295, 428, 5261, 30, 1042, 11, 286, 519, 286, 478, 19697, 300, 309, 311, 6243, 281, 360, 370, 11, 51264], "temperature": 0.0, "avg_logprob": -0.08553470264781605, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.020748328417539597}, {"id": 126, "seek": 82728, "start": 845.28, "end": 850.0799999999999, "text": " and not just because it's impossible to prove that, but it's impossible to get to that level", "tokens": [51264, 293, 406, 445, 570, 309, 311, 6243, 281, 7081, 300, 11, 457, 309, 311, 6243, 281, 483, 281, 300, 1496, 51504], "temperature": 0.0, "avg_logprob": -0.08553470264781605, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.020748328417539597}, {"id": 127, "seek": 82728, "start": 850.0799999999999, "end": 855.1999999999999, "text": " of performance. You can get progressively safer and more secure because you can look at specific", "tokens": [51504, 295, 3389, 13, 509, 393, 483, 46667, 15856, 293, 544, 7144, 570, 291, 393, 574, 412, 2685, 51760], "temperature": 0.0, "avg_logprob": -0.08553470264781605, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.020748328417539597}, {"id": 128, "seek": 85520, "start": 855.2, "end": 861.44, "text": " accept domains. You can limit what the system can do in certain situations, but you have an", "tokens": [50364, 3241, 25514, 13, 509, 393, 4948, 437, 264, 1185, 393, 360, 294, 1629, 6851, 11, 457, 291, 362, 364, 50676], "temperature": 0.0, "avg_logprob": -0.10434825019498842, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0018387982854619622}, {"id": 129, "seek": 85520, "start": 861.44, "end": 867.76, "text": " infinite space of possible problems. So it's very hard to prove deterministically that you", "tokens": [50676, 13785, 1901, 295, 1944, 2740, 13, 407, 309, 311, 588, 1152, 281, 7081, 15957, 20458, 300, 291, 50992], "temperature": 0.0, "avg_logprob": -0.10434825019498842, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0018387982854619622}, {"id": 130, "seek": 85520, "start": 867.76, "end": 874.32, "text": " can sit at all of them. So if AI safety would indeed be impossible, what does that imply for", "tokens": [50992, 393, 1394, 412, 439, 295, 552, 13, 407, 498, 7318, 4514, 576, 6451, 312, 6243, 11, 437, 775, 300, 33616, 337, 51320], "temperature": 0.0, "avg_logprob": -0.10434825019498842, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0018387982854619622}, {"id": 131, "seek": 85520, "start": 874.32, "end": 878.88, "text": " AI safety research? Does it imply anything for AI safety research? Is that would that be a waste", "tokens": [51320, 7318, 4514, 2132, 30, 4402, 309, 33616, 1340, 337, 7318, 4514, 2132, 30, 1119, 300, 576, 300, 312, 257, 5964, 51548], "temperature": 0.0, "avg_logprob": -0.10434825019498842, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0018387982854619622}, {"id": 132, "seek": 85520, "start": 878.88, "end": 884.5600000000001, "text": " of time or is it still something that we should pursue? Not at all. I'm doing it more than ever.", "tokens": [51548, 295, 565, 420, 307, 309, 920, 746, 300, 321, 820, 12392, 30, 1726, 412, 439, 13, 286, 478, 884, 309, 544, 813, 1562, 13, 51832], "temperature": 0.0, "avg_logprob": -0.10434825019498842, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0018387982854619622}, {"id": 133, "seek": 88456, "start": 884.56, "end": 890.0, "text": " So think about mathematics. We know in mathematics there are many impossibility results. You cannot", "tokens": [50364, 407, 519, 466, 18666, 13, 492, 458, 294, 18666, 456, 366, 867, 38802, 2841, 3542, 13, 509, 2644, 50636], "temperature": 0.0, "avg_logprob": -0.11556808338608852, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.0035845621023327112}, {"id": 134, "seek": 88456, "start": 890.0, "end": 896.4799999999999, "text": " prove certain things in general. You cannot have proofs with 100 percent confidence. It doesn't", "tokens": [50636, 7081, 1629, 721, 294, 2674, 13, 509, 2644, 362, 8177, 82, 365, 2319, 3043, 6687, 13, 467, 1177, 380, 50960], "temperature": 0.0, "avg_logprob": -0.11556808338608852, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.0035845621023327112}, {"id": 135, "seek": 88456, "start": 896.4799999999999, "end": 902.0, "text": " stop mathematicians from discovering new beautiful mathematics. We know in physics there are limits", "tokens": [50960, 1590, 32811, 2567, 490, 24773, 777, 2238, 18666, 13, 492, 458, 294, 10649, 456, 366, 10406, 51236], "temperature": 0.0, "avg_logprob": -0.11556808338608852, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.0035845621023327112}, {"id": 136, "seek": 88456, "start": 902.0, "end": 907.8399999999999, "text": " to, for example, speed, fundamental limit, you know, speed of light. That doesn't limit us from", "tokens": [51236, 281, 11, 337, 1365, 11, 3073, 11, 8088, 4948, 11, 291, 458, 11, 3073, 295, 1442, 13, 663, 1177, 380, 4948, 505, 490, 51528], "temperature": 0.0, "avg_logprob": -0.11556808338608852, "compression_ratio": 1.7149122807017543, "no_speech_prob": 0.0035845621023327112}, {"id": 137, "seek": 90784, "start": 907.84, "end": 915.76, "text": " doing great work on faster cars and faster rockets. It just tells you that there are limits to what", "tokens": [50364, 884, 869, 589, 322, 4663, 5163, 293, 4663, 28361, 13, 467, 445, 5112, 291, 300, 456, 366, 10406, 281, 437, 50760], "temperature": 0.0, "avg_logprob": -0.10476566589984697, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.02625613659620285}, {"id": 138, "seek": 90784, "start": 915.76, "end": 920.1600000000001, "text": " can be done. And so you should a, not waste your resources trying to accomplish that. Like", "tokens": [50760, 393, 312, 1096, 13, 400, 370, 291, 820, 257, 11, 406, 5964, 428, 3593, 1382, 281, 9021, 300, 13, 1743, 50980], "temperature": 0.0, "avg_logprob": -0.10476566589984697, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.02625613659620285}, {"id": 139, "seek": 90784, "start": 920.1600000000001, "end": 924.4, "text": " knowing that perpetual motion machines are not possible is helpful result in physics.", "tokens": [50980, 5276, 300, 48216, 5394, 8379, 366, 406, 1944, 307, 4961, 1874, 294, 10649, 13, 51192], "temperature": 0.0, "avg_logprob": -0.10476566589984697, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.02625613659620285}, {"id": 140, "seek": 90784, "start": 925.2, "end": 929.9200000000001, "text": " Same here. We need to understand what we can achieve and then concentrate on what is actually", "tokens": [51232, 10635, 510, 13, 492, 643, 281, 1223, 437, 321, 393, 4584, 293, 550, 18089, 322, 437, 307, 767, 51468], "temperature": 0.0, "avg_logprob": -0.10476566589984697, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.02625613659620285}, {"id": 141, "seek": 90784, "start": 929.9200000000001, "end": 934.1600000000001, "text": " solvable instead of trying to create magical devices which cannot work.", "tokens": [51468, 1404, 17915, 2602, 295, 1382, 281, 1884, 12066, 5759, 597, 2644, 589, 13, 51680], "temperature": 0.0, "avg_logprob": -0.10476566589984697, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.02625613659620285}, {"id": 142, "seek": 93416, "start": 934.16, "end": 941.28, "text": " Next one. For AI to become an existential risk, it's commonly thought that it should", "tokens": [50364, 3087, 472, 13, 1171, 7318, 281, 1813, 364, 37133, 3148, 11, 309, 311, 12719, 1194, 300, 309, 820, 50720], "temperature": 0.0, "avg_logprob": -0.14569069575337532, "compression_ratio": 1.5592592592592593, "no_speech_prob": 0.0029120396357029676}, {"id": 143, "seek": 93416, "start": 941.28, "end": 946.3199999999999, "text": " first outsmart humans. How big do you personally think the chances that this will happen at all", "tokens": [50720, 700, 484, 10817, 446, 6255, 13, 1012, 955, 360, 291, 5665, 519, 264, 10486, 300, 341, 486, 1051, 412, 439, 50972], "temperature": 0.0, "avg_logprob": -0.14569069575337532, "compression_ratio": 1.5592592592592593, "no_speech_prob": 0.0029120396357029676}, {"id": 144, "seek": 93416, "start": 946.9599999999999, "end": 950.64, "text": " and which probabilities do your fellow AI scientists assign to this?", "tokens": [51004, 293, 597, 33783, 360, 428, 7177, 7318, 7708, 6269, 281, 341, 30, 51188], "temperature": 0.0, "avg_logprob": -0.14569069575337532, "compression_ratio": 1.5592592592592593, "no_speech_prob": 0.0029120396357029676}, {"id": 145, "seek": 93416, "start": 951.52, "end": 957.04, "text": " That AI will ever become as smart as humans? Exactly. Well, it's a guarantee. I mean,", "tokens": [51232, 663, 7318, 486, 1562, 1813, 382, 4069, 382, 6255, 30, 7587, 13, 1042, 11, 309, 311, 257, 10815, 13, 286, 914, 11, 51508], "temperature": 0.0, "avg_logprob": -0.14569069575337532, "compression_ratio": 1.5592592592592593, "no_speech_prob": 0.0029120396357029676}, {"id": 146, "seek": 93416, "start": 958.16, "end": 963.76, "text": " we have proof by existence, right? If you just copy human system, you got same level.", "tokens": [51564, 321, 362, 8177, 538, 9123, 11, 558, 30, 759, 291, 445, 5055, 1952, 1185, 11, 291, 658, 912, 1496, 13, 51844], "temperature": 0.0, "avg_logprob": -0.14569069575337532, "compression_ratio": 1.5592592592592593, "no_speech_prob": 0.0029120396357029676}, {"id": 147, "seek": 96416, "start": 964.24, "end": 972.4, "text": " We also kind of give a lot of credit to humans because we tend to think about Einstein and", "tokens": [50368, 492, 611, 733, 295, 976, 257, 688, 295, 5397, 281, 6255, 570, 321, 3928, 281, 519, 466, 23486, 293, 50776], "temperature": 0.0, "avg_logprob": -0.09520099474036176, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.002180415438488126}, {"id": 148, "seek": 96416, "start": 972.4, "end": 978.9599999999999, "text": " similar type humans as typical examples. Every human is quite dumb. So it's not that hard to get", "tokens": [50776, 2531, 2010, 6255, 382, 7476, 5110, 13, 2048, 1952, 307, 1596, 10316, 13, 407, 309, 311, 406, 300, 1152, 281, 483, 51104], "temperature": 0.0, "avg_logprob": -0.09520099474036176, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.002180415438488126}, {"id": 149, "seek": 96416, "start": 978.9599999999999, "end": 991.04, "text": " to that level. And how are you on timelines? Of course, you hear quite values that are quite", "tokens": [51104, 281, 300, 1496, 13, 400, 577, 366, 291, 322, 45886, 30, 2720, 1164, 11, 291, 1568, 1596, 4190, 300, 366, 1596, 51708], "temperature": 0.0, "avg_logprob": -0.09520099474036176, "compression_ratio": 1.4893617021276595, "no_speech_prob": 0.002180415438488126}, {"id": 150, "seek": 99104, "start": 991.04, "end": 997.76, "text": " far apart. I think Elon Musk said that there could be a five-year timeline up until AGI that's", "tokens": [50364, 1400, 4936, 13, 286, 519, 28498, 26019, 848, 300, 456, 727, 312, 257, 1732, 12, 5294, 12933, 493, 1826, 316, 26252, 300, 311, 50700], "temperature": 0.0, "avg_logprob": -0.13876513640085855, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01805388368666172}, {"id": 151, "seek": 99104, "start": 997.76, "end": 1002.24, "text": " on the progressive side. On the other side, there are people that claim it would take hundreds of", "tokens": [50700, 322, 264, 16131, 1252, 13, 1282, 264, 661, 1252, 11, 456, 366, 561, 300, 3932, 309, 576, 747, 6779, 295, 50924], "temperature": 0.0, "avg_logprob": -0.13876513640085855, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01805388368666172}, {"id": 152, "seek": 99104, "start": 1002.24, "end": 1009.4399999999999, "text": " years. Where are you on this line and how certain are you? That's a very hard question. No one knows", "tokens": [50924, 924, 13, 2305, 366, 291, 322, 341, 1622, 293, 577, 1629, 366, 291, 30, 663, 311, 257, 588, 1152, 1168, 13, 883, 472, 3255, 51284], "temperature": 0.0, "avg_logprob": -0.13876513640085855, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01805388368666172}, {"id": 153, "seek": 99104, "start": 1009.4399999999999, "end": 1017.36, "text": " for sure and no one can accurately predict something like that. But if our current theory is about", "tokens": [51284, 337, 988, 293, 572, 472, 393, 20095, 6069, 746, 411, 300, 13, 583, 498, 527, 2190, 5261, 307, 466, 51680], "temperature": 0.0, "avg_logprob": -0.13876513640085855, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01805388368666172}, {"id": 154, "seek": 101736, "start": 1018.0, "end": 1024.0, "text": " how systems scale, all right, meaning if you just add more compute, add more data,", "tokens": [50396, 577, 3652, 4373, 11, 439, 558, 11, 3620, 498, 291, 445, 909, 544, 14722, 11, 909, 544, 1412, 11, 50696], "temperature": 0.0, "avg_logprob": -0.10953689151340061, "compression_ratio": 1.5338983050847457, "no_speech_prob": 0.0032641824800521135}, {"id": 155, "seek": 101736, "start": 1024.0, "end": 1028.88, "text": " you keep making progress, then it becomes a question of cost. How much compute are you", "tokens": [50696, 291, 1066, 1455, 4205, 11, 550, 309, 3643, 257, 1168, 295, 2063, 13, 1012, 709, 14722, 366, 291, 50940], "temperature": 0.0, "avg_logprob": -0.10953689151340061, "compression_ratio": 1.5338983050847457, "no_speech_prob": 0.0032641824800521135}, {"id": 156, "seek": 101736, "start": 1028.88, "end": 1037.6, "text": " willing to purchase to get to that level? Do you have finite resources or what is here? $200", "tokens": [50940, 4950, 281, 8110, 281, 483, 281, 300, 1496, 30, 1144, 291, 362, 19362, 3593, 420, 437, 307, 510, 30, 1848, 7629, 51376], "temperature": 0.0, "avg_logprob": -0.10953689151340061, "compression_ratio": 1.5338983050847457, "no_speech_prob": 0.0032641824800521135}, {"id": 157, "seek": 101736, "start": 1037.6, "end": 1043.1200000000001, "text": " billion now. So maybe at that level, seven years is a reasonable estimate. With my budget, it might", "tokens": [51376, 5218, 586, 13, 407, 1310, 412, 300, 1496, 11, 3407, 924, 307, 257, 10585, 12539, 13, 2022, 452, 4706, 11, 309, 1062, 51652], "temperature": 0.0, "avg_logprob": -0.10953689151340061, "compression_ratio": 1.5338983050847457, "no_speech_prob": 0.0032641824800521135}, {"id": 158, "seek": 104312, "start": 1043.12, "end": 1052.8, "text": " be 2040. It depends on what type of resources you have. If it's also as difficult as, let's say,", "tokens": [50364, 312, 945, 5254, 13, 467, 5946, 322, 437, 2010, 295, 3593, 291, 362, 13, 759, 309, 311, 611, 382, 2252, 382, 11, 718, 311, 584, 11, 50848], "temperature": 0.0, "avg_logprob": -0.11062027644185186, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010936809703707695}, {"id": 159, "seek": 104312, "start": 1052.8, "end": 1058.56, "text": " Manhattan Project was, right? You need resources of a whole country to get there. It's one question.", "tokens": [50848, 23633, 9849, 390, 11, 558, 30, 509, 643, 3593, 295, 257, 1379, 1941, 281, 483, 456, 13, 467, 311, 472, 1168, 13, 51136], "temperature": 0.0, "avg_logprob": -0.11062027644185186, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010936809703707695}, {"id": 160, "seek": 104312, "start": 1058.56, "end": 1063.1999999999998, "text": " If we discover, okay, there is a simplifying assumption, so we need a lot less resources to", "tokens": [51136, 759, 321, 4411, 11, 1392, 11, 456, 307, 257, 6883, 5489, 15302, 11, 370, 321, 643, 257, 688, 1570, 3593, 281, 51368], "temperature": 0.0, "avg_logprob": -0.11062027644185186, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010936809703707695}, {"id": 161, "seek": 104312, "start": 1063.1999999999998, "end": 1070.1599999999999, "text": " drain this type of engine, a lot less compute. Maybe you can do it with a laptop in a garage and then", "tokens": [51368, 12339, 341, 2010, 295, 2848, 11, 257, 688, 1570, 14722, 13, 2704, 291, 393, 360, 309, 365, 257, 10732, 294, 257, 14400, 293, 550, 51716], "temperature": 0.0, "avg_logprob": -0.11062027644185186, "compression_ratio": 1.589430894308943, "no_speech_prob": 0.010936809703707695}, {"id": 162, "seek": 107016, "start": 1070.16, "end": 1076.3200000000002, "text": " it becomes a lot more affordable and takes less time. So I don't have specific dates.", "tokens": [50364, 309, 3643, 257, 688, 544, 12028, 293, 2516, 1570, 565, 13, 407, 286, 500, 380, 362, 2685, 11691, 13, 50672], "temperature": 0.0, "avg_logprob": -0.09634913521251459, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.0029259712900966406}, {"id": 163, "seek": 107016, "start": 1076.3200000000002, "end": 1083.2, "text": " I would be surprised in maybe 2045 if I don't see something at human level. But", "tokens": [50672, 286, 576, 312, 6100, 294, 1310, 945, 8465, 498, 286, 500, 380, 536, 746, 412, 1952, 1496, 13, 583, 51016], "temperature": 0.0, "avg_logprob": -0.09634913521251459, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.0029259712900966406}, {"id": 164, "seek": 107016, "start": 1084.16, "end": 1089.44, "text": " that's not important to the argument at all. Whatever it's 2045, 2070, it's still", "tokens": [51064, 300, 311, 406, 1021, 281, 264, 6770, 412, 439, 13, 8541, 309, 311, 945, 8465, 11, 945, 5867, 11, 309, 311, 920, 51328], "temperature": 0.0, "avg_logprob": -0.09634913521251459, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.0029259712900966406}, {"id": 165, "seek": 107016, "start": 1090.3200000000002, "end": 1095.28, "text": " something we need to worry about today, control and work on safety aspects of it.", "tokens": [51372, 746, 321, 643, 281, 3292, 466, 965, 11, 1969, 293, 589, 322, 4514, 7270, 295, 309, 13, 51620], "temperature": 0.0, "avg_logprob": -0.09634913521251459, "compression_ratio": 1.48868778280543, "no_speech_prob": 0.0029259712900966406}, {"id": 166, "seek": 109528, "start": 1095.92, "end": 1102.24, "text": " I've read somewhere that there are about 70 research projects explicitly aiming for AGI at this", "tokens": [50396, 286, 600, 1401, 4079, 300, 456, 366, 466, 5285, 2132, 4455, 20803, 20253, 337, 316, 26252, 412, 341, 50712], "temperature": 0.0, "avg_logprob": -0.12521618290951378, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.0031113848090171814}, {"id": 167, "seek": 109528, "start": 1102.24, "end": 1108.8, "text": " point. I guess the most famous two ones are DeepMind and OpenAI, at least the ones I know best.", "tokens": [50712, 935, 13, 286, 2041, 264, 881, 4618, 732, 2306, 366, 14895, 44, 471, 293, 7238, 48698, 11, 412, 1935, 264, 2306, 286, 458, 1151, 13, 51040], "temperature": 0.0, "avg_logprob": -0.12521618290951378, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.0031113848090171814}, {"id": 168, "seek": 109528, "start": 1108.8, "end": 1113.92, "text": " Do you know a project that we've never heard of, but actually has a fair chance of beating those two?", "tokens": [51040, 1144, 291, 458, 257, 1716, 300, 321, 600, 1128, 2198, 295, 11, 457, 767, 575, 257, 3143, 2931, 295, 13497, 729, 732, 30, 51296], "temperature": 0.0, "avg_logprob": -0.12521618290951378, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.0031113848090171814}, {"id": 169, "seek": 109528, "start": 1115.28, "end": 1122.6399999999999, "text": " Well, there could be many secret projects by secret agencies. I'm sure NSA is very interested", "tokens": [51364, 1042, 11, 456, 727, 312, 867, 4054, 4455, 538, 4054, 9504, 13, 286, 478, 988, 47299, 307, 588, 3102, 51732], "temperature": 0.0, "avg_logprob": -0.12521618290951378, "compression_ratio": 1.5176470588235293, "no_speech_prob": 0.0031113848090171814}, {"id": 170, "seek": 112264, "start": 1122.64, "end": 1127.68, "text": " in processing your data more efficiently. So I'd be surprised if they don't have something good", "tokens": [50364, 294, 9007, 428, 1412, 544, 19621, 13, 407, 286, 1116, 312, 6100, 498, 436, 500, 380, 362, 746, 665, 50616], "temperature": 0.0, "avg_logprob": -0.14477400447047034, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.008741767145693302}, {"id": 171, "seek": 112264, "start": 1127.68, "end": 1135.76, "text": " happening. Usually, if you look at the history of what they publicly released and what we later", "tokens": [50616, 2737, 13, 11419, 11, 498, 291, 574, 412, 264, 2503, 295, 437, 436, 14843, 4736, 293, 437, 321, 1780, 51020], "temperature": 0.0, "avg_logprob": -0.14477400447047034, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.008741767145693302}, {"id": 172, "seek": 112264, "start": 1135.76, "end": 1140.8000000000002, "text": " learned they had, I think they had public ecryptography like 30 years ahead of everyone. So", "tokens": [51020, 3264, 436, 632, 11, 286, 519, 436, 632, 1908, 308, 46555, 662, 5820, 411, 2217, 924, 2286, 295, 1518, 13, 407, 51272], "temperature": 0.0, "avg_logprob": -0.14477400447047034, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.008741767145693302}, {"id": 173, "seek": 112264, "start": 1141.8400000000001, "end": 1152.3200000000002, "text": " maybe already. Interesting thought. A week ago, you posted on the Facebook timeline that", "tokens": [51324, 1310, 1217, 13, 14711, 1194, 13, 316, 1243, 2057, 11, 291, 9437, 322, 264, 4384, 12933, 300, 51848], "temperature": 0.0, "avg_logprob": -0.14477400447047034, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.008741767145693302}, {"id": 174, "seek": 115232, "start": 1152.3999999999999, "end": 1157.36, "text": " I referred to already, which is quite interesting. A quote from that helped me to understand", "tokens": [50368, 286, 10839, 281, 1217, 11, 597, 307, 1596, 1880, 13, 316, 6513, 490, 300, 4254, 385, 281, 1223, 50616], "temperature": 0.0, "avg_logprob": -0.13988196633078837, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.007281765807420015}, {"id": 175, "seek": 115232, "start": 1157.36, "end": 1161.9199999999998, "text": " where is the number of highly respected people who, one, argued that advanced AI is dangerous to", "tokens": [50616, 689, 307, 264, 1230, 295, 5405, 20020, 561, 567, 11, 472, 11, 20219, 300, 7339, 7318, 307, 5795, 281, 50844], "temperature": 0.0, "avg_logprob": -0.13988196633078837, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.007281765807420015}, {"id": 176, "seek": 115232, "start": 1161.9199999999998, "end": 1166.8, "text": " humanity, and two, work as fast as they can on developing advanced AI. And there were, I believe,", "tokens": [50844, 10243, 11, 293, 732, 11, 589, 382, 2370, 382, 436, 393, 322, 6416, 7339, 7318, 13, 400, 456, 645, 11, 286, 1697, 11, 51088], "temperature": 0.0, "avg_logprob": -0.13988196633078837, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.007281765807420015}, {"id": 177, "seek": 115232, "start": 1166.8, "end": 1171.76, "text": " 116 comments under your post. Have you come any closer to understanding this personally?", "tokens": [51088, 2975, 21, 3053, 833, 428, 2183, 13, 3560, 291, 808, 604, 4966, 281, 3701, 341, 5665, 30, 51336], "temperature": 0.0, "avg_logprob": -0.13988196633078837, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.007281765807420015}, {"id": 178, "seek": 115232, "start": 1173.4399999999998, "end": 1179.36, "text": " No, I had some good explanations and the best one, and I think that's the one Elon actually", "tokens": [51420, 883, 11, 286, 632, 512, 665, 28708, 293, 264, 1151, 472, 11, 293, 286, 519, 300, 311, 264, 472, 28498, 767, 51716], "temperature": 0.0, "avg_logprob": -0.13988196633078837, "compression_ratio": 1.6193771626297577, "no_speech_prob": 0.007281765807420015}, {"id": 179, "seek": 117936, "start": 1179.36, "end": 1184.7199999999998, "text": " gave himself was saying, okay, if we can't control it, I might as well be the one to get there and", "tokens": [50364, 2729, 3647, 390, 1566, 11, 1392, 11, 498, 321, 393, 380, 1969, 309, 11, 286, 1062, 382, 731, 312, 264, 472, 281, 483, 456, 293, 50632], "temperature": 0.0, "avg_logprob": -0.10859091909308183, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.008038808591663837}, {"id": 180, "seek": 117936, "start": 1184.7199999999998, "end": 1190.8, "text": " I have the best chance of controlling it. People who don't care about safety have less of a chance.", "tokens": [50632, 286, 362, 264, 1151, 2931, 295, 14905, 309, 13, 3432, 567, 500, 380, 1127, 466, 4514, 362, 1570, 295, 257, 2931, 13, 50936], "temperature": 0.0, "avg_logprob": -0.10859091909308183, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.008038808591663837}, {"id": 181, "seek": 117936, "start": 1193.36, "end": 1200.6399999999999, "text": " But it is interesting. So a lot of very big names in arguing that AI is extremely dangerous are also", "tokens": [51064, 583, 309, 307, 1880, 13, 407, 257, 688, 295, 588, 955, 5288, 294, 19697, 300, 7318, 307, 4664, 5795, 366, 611, 51428], "temperature": 0.0, "avg_logprob": -0.10859091909308183, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.008038808591663837}, {"id": 182, "seek": 117936, "start": 1200.6399999999999, "end": 1204.9599999999998, "text": " people who invested the most time and money in making it as fast as they can.", "tokens": [51428, 561, 567, 13104, 264, 881, 565, 293, 1460, 294, 1455, 309, 382, 2370, 382, 436, 393, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10859091909308183, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.008038808591663837}, {"id": 183, "seek": 120496, "start": 1205.28, "end": 1210.64, "text": " Yeah, and on a more serious note, some people might say, if AI is so dangerous, can't we just", "tokens": [50380, 865, 11, 293, 322, 257, 544, 3156, 3637, 11, 512, 561, 1062, 584, 11, 498, 7318, 307, 370, 5795, 11, 393, 380, 321, 445, 50648], "temperature": 0.0, "avg_logprob": -0.1252000370963675, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.006961298640817404}, {"id": 184, "seek": 120496, "start": 1210.64, "end": 1215.68, "text": " not build it? You said something about regulation in your talk, but what would you say to them as a", "tokens": [50648, 406, 1322, 309, 30, 509, 848, 746, 466, 15062, 294, 428, 751, 11, 457, 437, 576, 291, 584, 281, 552, 382, 257, 50900], "temperature": 0.0, "avg_logprob": -0.1252000370963675, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.006961298640817404}, {"id": 185, "seek": 120496, "start": 1215.68, "end": 1221.6000000000001, "text": " general response? You can't stop progress on something so useful and so fuzzy in terms of", "tokens": [50900, 2674, 4134, 30, 509, 393, 380, 1590, 4205, 322, 746, 370, 4420, 293, 370, 34710, 294, 2115, 295, 51196], "temperature": 0.0, "avg_logprob": -0.1252000370963675, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.006961298640817404}, {"id": 186, "seek": 120496, "start": 1221.6000000000001, "end": 1227.3600000000001, "text": " separation between narrow and general AI. If we could make it where, okay, you only can work on", "tokens": [51196, 14634, 1296, 9432, 293, 2674, 7318, 13, 759, 321, 727, 652, 309, 689, 11, 1392, 11, 291, 787, 393, 589, 322, 51484], "temperature": 0.0, "avg_logprob": -0.1252000370963675, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.006961298640817404}, {"id": 187, "seek": 120496, "start": 1227.3600000000001, "end": 1233.2, "text": " narrow AI, but not allowed to work in general, it would be a good moratorium to have for a few years.", "tokens": [51484, 9432, 7318, 11, 457, 406, 4350, 281, 589, 294, 2674, 11, 309, 576, 312, 257, 665, 1896, 41679, 281, 362, 337, 257, 1326, 924, 13, 51776], "temperature": 0.0, "avg_logprob": -0.1252000370963675, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.006961298640817404}, {"id": 188, "seek": 123320, "start": 1233.2, "end": 1237.6000000000001, "text": " But the dividing line is meaningless. If you're using neural networks, they're general. If you're", "tokens": [50364, 583, 264, 26764, 1622, 307, 33232, 13, 759, 291, 434, 1228, 18161, 9590, 11, 436, 434, 2674, 13, 759, 291, 434, 50584], "temperature": 0.0, "avg_logprob": -0.09818326985394513, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.006164989899843931}, {"id": 189, "seek": 123320, "start": 1237.6000000000001, "end": 1243.68, "text": " using a lot of those latest evolutionary techniques, they are leading you to general solutions. So it's", "tokens": [50584, 1228, 257, 688, 295, 729, 6792, 27567, 7512, 11, 436, 366, 5775, 291, 281, 2674, 6547, 13, 407, 309, 311, 50888], "temperature": 0.0, "avg_logprob": -0.09818326985394513, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.006164989899843931}, {"id": 190, "seek": 123320, "start": 1243.68, "end": 1249.2, "text": " simply impossible. If you make all computer science illegal, you're killing your economy,", "tokens": [50888, 2935, 6243, 13, 759, 291, 652, 439, 3820, 3497, 11905, 11, 291, 434, 8011, 428, 5010, 11, 51164], "temperature": 0.0, "avg_logprob": -0.09818326985394513, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.006164989899843931}, {"id": 191, "seek": 123320, "start": 1249.2, "end": 1255.6000000000001, "text": " you're shifting research to other countries. So I think I'll add another impossibility result of", "tokens": [51164, 291, 434, 17573, 2132, 281, 661, 3517, 13, 407, 286, 519, 286, 603, 909, 1071, 38802, 2841, 1874, 295, 51484], "temperature": 0.0, "avg_logprob": -0.09818326985394513, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.006164989899843931}, {"id": 192, "seek": 123320, "start": 1255.6000000000001, "end": 1261.04, "text": " unburnability of AI. You cannot ban it. You can maybe delay it at best.", "tokens": [51484, 517, 21763, 2310, 295, 7318, 13, 509, 2644, 5643, 309, 13, 509, 393, 1310, 8577, 309, 412, 1151, 13, 51756], "temperature": 0.0, "avg_logprob": -0.09818326985394513, "compression_ratio": 1.7293233082706767, "no_speech_prob": 0.006164989899843931}, {"id": 193, "seek": 126104, "start": 1262.0, "end": 1266.24, "text": " It would be very interesting if you could either include or exclude it from the impossibility", "tokens": [50412, 467, 576, 312, 588, 1880, 498, 291, 727, 2139, 4090, 420, 33536, 309, 490, 264, 38802, 2841, 50624], "temperature": 0.0, "avg_logprob": -0.15727395103091285, "compression_ratio": 1.5301724137931034, "no_speech_prob": 0.0048362179659307}, {"id": 194, "seek": 126104, "start": 1266.24, "end": 1273.68, "text": " space indeed, but I'm afraid that goes more into Simon Friedrich's chaos theorem, so to say.", "tokens": [50624, 1901, 6451, 11, 457, 286, 478, 4638, 300, 1709, 544, 666, 13193, 17605, 10794, 311, 14158, 20904, 11, 370, 281, 584, 13, 50996], "temperature": 0.0, "avg_logprob": -0.15727395103091285, "compression_ratio": 1.5301724137931034, "no_speech_prob": 0.0048362179659307}, {"id": 195, "seek": 126104, "start": 1275.44, "end": 1278.96, "text": " You and I both agree, I think that AI is a significant existential risk,", "tokens": [51084, 509, 293, 286, 1293, 3986, 11, 286, 519, 300, 7318, 307, 257, 4776, 37133, 3148, 11, 51260], "temperature": 0.0, "avg_logprob": -0.15727395103091285, "compression_ratio": 1.5301724137931034, "no_speech_prob": 0.0048362179659307}, {"id": 196, "seek": 126104, "start": 1279.68, "end": 1284.8, "text": " but some AI researchers don't agree. And do you think there will ever be a scientific consensus", "tokens": [51296, 457, 512, 7318, 10309, 500, 380, 3986, 13, 400, 360, 291, 519, 456, 486, 1562, 312, 257, 8134, 19115, 51552], "temperature": 0.0, "avg_logprob": -0.15727395103091285, "compression_ratio": 1.5301724137931034, "no_speech_prob": 0.0048362179659307}, {"id": 197, "seek": 128480, "start": 1284.8799999999999, "end": 1289.28, "text": " about this? And can we hope to achieve that at some point? And why could that be", "tokens": [50368, 466, 341, 30, 400, 393, 321, 1454, 281, 4584, 300, 412, 512, 935, 30, 400, 983, 727, 300, 312, 50588], "temperature": 0.0, "avg_logprob": -0.1398682348506967, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.016046611592173576}, {"id": 198, "seek": 128480, "start": 1289.9199999999998, "end": 1298.08, "text": " either so or not? Well, I have a recent paper about AI risk skepticism, and I do a review of both", "tokens": [50620, 2139, 370, 420, 406, 30, 1042, 11, 286, 362, 257, 5162, 3035, 466, 7318, 3148, 19128, 26356, 11, 293, 286, 360, 257, 3131, 295, 1293, 51028], "temperature": 0.0, "avg_logprob": -0.1398682348506967, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.016046611592173576}, {"id": 199, "seek": 128480, "start": 1298.08, "end": 1305.6, "text": " why would someone not accept the risks as real and kind of specific arguments they make for it.", "tokens": [51028, 983, 576, 1580, 406, 3241, 264, 10888, 382, 957, 293, 733, 295, 2685, 12869, 436, 652, 337, 309, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1398682348506967, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.016046611592173576}, {"id": 200, "seek": 128480, "start": 1305.6, "end": 1311.76, "text": " I think it ended up with about 100 citations, and I have another 400 unprocessed ones. If anyone's", "tokens": [51404, 286, 519, 309, 4590, 493, 365, 466, 2319, 4814, 763, 11, 293, 286, 362, 1071, 8423, 517, 41075, 292, 2306, 13, 759, 2878, 311, 51712], "temperature": 0.0, "avg_logprob": -0.1398682348506967, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.016046611592173576}, {"id": 201, "seek": 131176, "start": 1311.76, "end": 1319.2, "text": " interested, it could be a nice survey. The most common explanation I see is just bias. If you", "tokens": [50364, 3102, 11, 309, 727, 312, 257, 1481, 8984, 13, 440, 881, 2689, 10835, 286, 536, 307, 445, 12577, 13, 759, 291, 50736], "temperature": 0.0, "avg_logprob": -0.08921241760253906, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.006945105269551277}, {"id": 202, "seek": 131176, "start": 1320.0, "end": 1327.12, "text": " get your funding, your prestige, your reputation, everything from developing faster AI, it's very", "tokens": [50776, 483, 428, 6137, 11, 428, 42531, 11, 428, 13061, 11, 1203, 490, 6416, 4663, 7318, 11, 309, 311, 588, 51132], "temperature": 0.0, "avg_logprob": -0.08921241760253906, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.006945105269551277}, {"id": 203, "seek": 131176, "start": 1327.12, "end": 1331.04, "text": " hard for you to say, I'm working on the most dangerous thing in the world that will kill", "tokens": [51132, 1152, 337, 291, 281, 584, 11, 286, 478, 1364, 322, 264, 881, 5795, 551, 294, 264, 1002, 300, 486, 1961, 51328], "temperature": 0.0, "avg_logprob": -0.08921241760253906, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.006945105269551277}, {"id": 204, "seek": 131176, "start": 1331.04, "end": 1338.56, "text": " everyone. So there seems to be this conflict of interest in any other domain. We wouldn't allow", "tokens": [51328, 1518, 13, 407, 456, 2544, 281, 312, 341, 6596, 295, 1179, 294, 604, 661, 9274, 13, 492, 2759, 380, 2089, 51704], "temperature": 0.0, "avg_logprob": -0.08921241760253906, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.006945105269551277}, {"id": 205, "seek": 133856, "start": 1339.52, "end": 1344.56, "text": " for this to happen. If you are working for a tobacco company, you wouldn't be deciding if", "tokens": [50412, 337, 341, 281, 1051, 13, 759, 291, 366, 1364, 337, 257, 22994, 2237, 11, 291, 2759, 380, 312, 17990, 498, 50664], "temperature": 0.0, "avg_logprob": -0.09077069033747134, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.005521656945347786}, {"id": 206, "seek": 133856, "start": 1344.56, "end": 1349.36, "text": " smoking is dangerous. If you work for an oil company, we don't really trust your assessment", "tokens": [50664, 14055, 307, 5795, 13, 759, 291, 589, 337, 364, 3184, 2237, 11, 321, 500, 380, 534, 3361, 428, 9687, 50904], "temperature": 0.0, "avg_logprob": -0.09077069033747134, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.005521656945347786}, {"id": 207, "seek": 133856, "start": 1349.36, "end": 1357.76, "text": " of impact on climate. But somehow here, it's fine. And interestingly, AI is a very large umbrella", "tokens": [50904, 295, 2712, 322, 5659, 13, 583, 6063, 510, 11, 309, 311, 2489, 13, 400, 25873, 11, 7318, 307, 257, 588, 2416, 21925, 51324], "temperature": 0.0, "avg_logprob": -0.09077069033747134, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.005521656945347786}, {"id": 208, "seek": 133856, "start": 1357.76, "end": 1363.9199999999998, "text": " term for lots of research sub-domains. Some people do natural language processing, some do vision.", "tokens": [51324, 1433, 337, 3195, 295, 2132, 1422, 12, 4121, 2315, 13, 2188, 561, 360, 3303, 2856, 9007, 11, 512, 360, 5201, 13, 51632], "temperature": 0.0, "avg_logprob": -0.09077069033747134, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.005521656945347786}, {"id": 209, "seek": 136392, "start": 1363.92, "end": 1369.04, "text": " Not everyone does safety and security, but we feel that anyone with a label of AI researcher", "tokens": [50364, 1726, 1518, 775, 4514, 293, 3825, 11, 457, 321, 841, 300, 2878, 365, 257, 7645, 295, 7318, 21751, 50620], "temperature": 0.0, "avg_logprob": -0.0995649809247992, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.00456960266456008}, {"id": 210, "seek": 136392, "start": 1369.04, "end": 1375.2, "text": " is qualified to pass judgment on the state of AI safety in software development. Not everyone", "tokens": [50620, 307, 15904, 281, 1320, 12216, 322, 264, 1785, 295, 7318, 4514, 294, 4722, 3250, 13, 1726, 1518, 50928], "temperature": 0.0, "avg_logprob": -0.0995649809247992, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.00456960266456008}, {"id": 211, "seek": 136392, "start": 1375.2, "end": 1380.3200000000002, "text": " is a cybersecurity expert. If you're working on backend, GUI, something else, you're not going", "tokens": [50928, 307, 257, 38765, 5844, 13, 759, 291, 434, 1364, 322, 38087, 11, 17917, 40, 11, 746, 1646, 11, 291, 434, 406, 516, 51184], "temperature": 0.0, "avg_logprob": -0.0995649809247992, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.00456960266456008}, {"id": 212, "seek": 136392, "start": 1380.3200000000002, "end": 1387.8400000000001, "text": " to be consulted on how to do encryption. Why is this somehow different here? I don't fully understand.", "tokens": [51184, 281, 312, 47941, 322, 577, 281, 360, 29575, 13, 1545, 307, 341, 6063, 819, 510, 30, 286, 500, 380, 4498, 1223, 13, 51560], "temperature": 0.0, "avg_logprob": -0.0995649809247992, "compression_ratio": 1.5483870967741935, "no_speech_prob": 0.00456960266456008}, {"id": 213, "seek": 138784, "start": 1388.8, "end": 1394.8, "text": " It would be interesting indeed also to find out. I'm also kind of puzzled, but perhaps it could", "tokens": [50412, 467, 576, 312, 1880, 6451, 611, 281, 915, 484, 13, 286, 478, 611, 733, 295, 18741, 1493, 11, 457, 4317, 309, 727, 50712], "temperature": 0.0, "avg_logprob": -0.1724792718887329, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.011722641065716743}, {"id": 214, "seek": 138784, "start": 1394.8, "end": 1399.76, "text": " have something to do with the fact that it's not a trial and error risk as one of the few", "tokens": [50712, 362, 746, 281, 360, 365, 264, 1186, 300, 309, 311, 406, 257, 7308, 293, 6713, 3148, 382, 472, 295, 264, 1326, 50960], "temperature": 0.0, "avg_logprob": -0.1724792718887329, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.011722641065716743}, {"id": 215, "seek": 138784, "start": 1401.1999999999998, "end": 1407.36, "text": " areas. I think mostly, of course, you're first developing something and then later you regulate", "tokens": [51032, 3179, 13, 286, 519, 5240, 11, 295, 1164, 11, 291, 434, 700, 6416, 746, 293, 550, 1780, 291, 24475, 51340], "temperature": 0.0, "avg_logprob": -0.1724792718887329, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.011722641065716743}, {"id": 216, "seek": 138784, "start": 1407.36, "end": 1411.52, "text": " it, but it's only at the phase of application. So at this phase, it's much more obvious to have", "tokens": [51340, 309, 11, 457, 309, 311, 787, 412, 264, 5574, 295, 3861, 13, 407, 412, 341, 5574, 11, 309, 311, 709, 544, 6322, 281, 362, 51548], "temperature": 0.0, "avg_logprob": -0.1724792718887329, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.011722641065716743}, {"id": 217, "seek": 141152, "start": 1412.08, "end": 1418.72, "text": " separate controlling agencies, perhaps. But when you're creating something, of course,", "tokens": [50392, 4994, 14905, 9504, 11, 4317, 13, 583, 562, 291, 434, 4084, 746, 11, 295, 1164, 11, 50724], "temperature": 0.0, "avg_logprob": -0.18192621209155554, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0028266082517802715}, {"id": 218, "seek": 141152, "start": 1419.92, "end": 1427.92, "text": " that's not that obvious. Maybe one more question about also impossibility of AI safety, but I'm", "tokens": [50784, 300, 311, 406, 300, 6322, 13, 2704, 472, 544, 1168, 466, 611, 38802, 2841, 295, 7318, 4514, 11, 457, 286, 478, 51184], "temperature": 0.0, "avg_logprob": -0.18192621209155554, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0028266082517802715}, {"id": 219, "seek": 141152, "start": 1427.92, "end": 1433.76, "text": " from a different angle. I don't know if you are aware of the work of Anthony Burglas. He has", "tokens": [51184, 490, 257, 819, 5802, 13, 286, 500, 380, 458, 498, 291, 366, 3650, 295, 264, 589, 295, 15853, 32911, 7743, 13, 634, 575, 51476], "temperature": 0.0, "avg_logprob": -0.18192621209155554, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0028266082517802715}, {"id": 220, "seek": 141152, "start": 1433.76, "end": 1439.6, "text": " written a book about evolutionary arguments applied to AI, and it roughly goes as follows.", "tokens": [51476, 3720, 257, 1446, 466, 27567, 12869, 6456, 281, 7318, 11, 293, 309, 9810, 1709, 382, 10002, 13, 51768], "temperature": 0.0, "avg_logprob": -0.18192621209155554, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.0028266082517802715}, {"id": 221, "seek": 143960, "start": 1440.32, "end": 1445.28, "text": " For superintelligence, being friendly to people is a necessary baggage. Because of evolution,", "tokens": [50400, 1171, 1687, 20761, 17644, 11, 885, 9208, 281, 561, 307, 257, 4818, 41567, 13, 1436, 295, 9303, 11, 50648], "temperature": 0.0, "avg_logprob": -0.0919694235158521, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.013469535857439041}, {"id": 222, "seek": 143960, "start": 1445.28, "end": 1449.6799999999998, "text": " we should expect only the most efficient superintelligence to survive, and this is probably", "tokens": [50648, 321, 820, 2066, 787, 264, 881, 7148, 1687, 20761, 17644, 281, 7867, 11, 293, 341, 307, 1391, 50868], "temperature": 0.0, "avg_logprob": -0.0919694235158521, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.013469535857439041}, {"id": 223, "seek": 143960, "start": 1449.6799999999998, "end": 1455.28, "text": " not the friendliest one. Would you agree to this evolutionary argument applied to AI,", "tokens": [50868, 406, 264, 1277, 16850, 472, 13, 6068, 291, 3986, 281, 341, 27567, 6770, 6456, 281, 7318, 11, 51148], "temperature": 0.0, "avg_logprob": -0.0919694235158521, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.013469535857439041}, {"id": 224, "seek": 143960, "start": 1455.28, "end": 1459.9199999999998, "text": " or what are your thoughts about this idea? I haven't read the books, so I'm trying to get the", "tokens": [51148, 420, 437, 366, 428, 4598, 466, 341, 1558, 30, 286, 2378, 380, 1401, 264, 3642, 11, 370, 286, 478, 1382, 281, 483, 264, 51380], "temperature": 0.0, "avg_logprob": -0.0919694235158521, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.013469535857439041}, {"id": 225, "seek": 143960, "start": 1459.9199999999998, "end": 1464.7199999999998, "text": " argument from your question. So the argument is that it's more efficient to be friendly to humans,", "tokens": [51380, 6770, 490, 428, 1168, 13, 407, 264, 6770, 307, 300, 309, 311, 544, 7148, 281, 312, 9208, 281, 6255, 11, 51620], "temperature": 0.0, "avg_logprob": -0.0919694235158521, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.013469535857439041}, {"id": 226, "seek": 143960, "start": 1464.7199999999998, "end": 1468.48, "text": " and so it's a survival advantage. And the other way around, it's more efficient to be", "tokens": [51620, 293, 370, 309, 311, 257, 12559, 5002, 13, 400, 264, 661, 636, 926, 11, 309, 311, 544, 7148, 281, 312, 51808], "temperature": 0.0, "avg_logprob": -0.0919694235158521, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.013469535857439041}, {"id": 227, "seek": 146848, "start": 1468.48, "end": 1472.72, "text": " unfriendly to humans, so that would be a survival advantage. Because the friendliness", "tokens": [50364, 3971, 4896, 356, 281, 6255, 11, 370, 300, 576, 312, 257, 12559, 5002, 13, 1436, 264, 1277, 32268, 50576], "temperature": 0.0, "avg_logprob": -0.128694910521901, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.007818691432476044}, {"id": 228, "seek": 146848, "start": 1473.6, "end": 1478.16, "text": " would just be baggage according to him. Oh, in terms of his overhead and development,", "tokens": [50620, 576, 445, 312, 41567, 4650, 281, 796, 13, 876, 11, 294, 2115, 295, 702, 19922, 293, 3250, 11, 50848], "temperature": 0.0, "avg_logprob": -0.128694910521901, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.007818691432476044}, {"id": 229, "seek": 146848, "start": 1478.16, "end": 1483.6, "text": " being friendly limits your space of possibilities. Yeah, I think there is a lot to be said about", "tokens": [50848, 885, 9208, 10406, 428, 1901, 295, 12178, 13, 865, 11, 286, 519, 456, 307, 257, 688, 281, 312, 848, 466, 51120], "temperature": 0.0, "avg_logprob": -0.128694910521901, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.007818691432476044}, {"id": 230, "seek": 146848, "start": 1483.6, "end": 1488.4, "text": " the trash rest turn option. It starts very friendly, gets the resources and help early on,", "tokens": [51120, 264, 11321, 1472, 1261, 3614, 13, 467, 3719, 588, 9208, 11, 2170, 264, 3593, 293, 854, 2440, 322, 11, 51360], "temperature": 0.0, "avg_logprob": -0.128694910521901, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.007818691432476044}, {"id": 231, "seek": 146848, "start": 1488.4, "end": 1495.04, "text": " and once it's capable, it turns on us and removes all restrictions. So sounds like a good book.", "tokens": [51360, 293, 1564, 309, 311, 8189, 11, 309, 4523, 322, 505, 293, 30445, 439, 14191, 13, 407, 3263, 411, 257, 665, 1446, 13, 51692], "temperature": 0.0, "avg_logprob": -0.128694910521901, "compression_ratio": 1.6134751773049645, "no_speech_prob": 0.007818691432476044}, {"id": 232, "seek": 149504, "start": 1495.44, "end": 1501.12, "text": " I think it is, you should read it. All right, I'll put it on my list of 600 books to read,", "tokens": [50384, 286, 519, 309, 307, 11, 291, 820, 1401, 309, 13, 1057, 558, 11, 286, 603, 829, 309, 322, 452, 1329, 295, 11849, 3642, 281, 1401, 11, 50668], "temperature": 0.0, "avg_logprob": -0.17731679949844092, "compression_ratio": 1.5759717314487633, "no_speech_prob": 0.007761336863040924}, {"id": 233, "seek": 149504, "start": 1501.12, "end": 1507.52, "text": " excellent. It was marketed very poorly, so I'm not surprised that you did read it,", "tokens": [50668, 7103, 13, 467, 390, 49089, 588, 22271, 11, 370, 286, 478, 406, 6100, 300, 291, 630, 1401, 309, 11, 50988], "temperature": 0.0, "avg_logprob": -0.17731679949844092, "compression_ratio": 1.5759717314487633, "no_speech_prob": 0.007761336863040924}, {"id": 234, "seek": 149504, "start": 1507.52, "end": 1513.44, "text": " but I think the idea is interesting indeed. Are you more on the slow takeover or on the", "tokens": [50988, 457, 286, 519, 264, 1558, 307, 1880, 6451, 13, 2014, 291, 544, 322, 264, 2964, 747, 3570, 420, 322, 264, 51284], "temperature": 0.0, "avg_logprob": -0.17731679949844092, "compression_ratio": 1.5759717314487633, "no_speech_prob": 0.007761336863040924}, {"id": 235, "seek": 149504, "start": 1513.44, "end": 1519.36, "text": " fast take-off sides, and why would that be? Very fast. Once we get to human level, it goes super", "tokens": [51284, 2370, 747, 12, 4506, 4881, 11, 293, 983, 576, 300, 312, 30, 4372, 2370, 13, 3443, 321, 483, 281, 1952, 1496, 11, 309, 1709, 1687, 51580], "temperature": 0.0, "avg_logprob": -0.17731679949844092, "compression_ratio": 1.5759717314487633, "no_speech_prob": 0.007761336863040924}, {"id": 236, "seek": 149504, "start": 1519.36, "end": 1524.3999999999999, "text": " intelligent almost immediately, just adding existing capabilities like infinite memory,", "tokens": [51580, 13232, 1920, 4258, 11, 445, 5127, 6741, 10862, 411, 13785, 4675, 11, 51832], "temperature": 0.0, "avg_logprob": -0.17731679949844092, "compression_ratio": 1.5759717314487633, "no_speech_prob": 0.007761336863040924}, {"id": 237, "seek": 152440, "start": 1524.4, "end": 1529.1200000000001, "text": " access to all the human knowledge, since they are already super intelligent, if you just take", "tokens": [50364, 2105, 281, 439, 264, 1952, 3601, 11, 1670, 436, 366, 1217, 1687, 13232, 11, 498, 291, 445, 747, 50600], "temperature": 0.0, "avg_logprob": -0.22376520368787978, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0015803504502400756}, {"id": 238, "seek": 152440, "start": 1529.1200000000001, "end": 1536.96, "text": " human plus internet. And why do you think, I think the slow take-off side kind of", "tokens": [50600, 1952, 1804, 4705, 13, 400, 983, 360, 291, 519, 11, 286, 519, 264, 2964, 747, 12, 4506, 1252, 733, 295, 50992], "temperature": 0.0, "avg_logprob": -0.22376520368787978, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0015803504502400756}, {"id": 239, "seek": 152440, "start": 1536.96, "end": 1542.72, "text": " gains momentum the last years, I don't know if you agree. And I've heard that this is just because", "tokens": [50992, 16823, 11244, 264, 1036, 924, 11, 286, 500, 380, 458, 498, 291, 3986, 13, 400, 286, 600, 2198, 300, 341, 307, 445, 570, 51280], "temperature": 0.0, "avg_logprob": -0.22376520368787978, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0015803504502400756}, {"id": 240, "seek": 152440, "start": 1542.72, "end": 1548.0, "text": " it's more easy to write papers about this, or there are more possible stories that you could", "tokens": [51280, 309, 311, 544, 1858, 281, 2464, 10577, 466, 341, 11, 420, 456, 366, 544, 1944, 3676, 300, 291, 727, 51544], "temperature": 0.0, "avg_logprob": -0.22376520368787978, "compression_ratio": 1.6167400881057268, "no_speech_prob": 0.0015803504502400756}, {"id": 241, "seek": 154800, "start": 1548.48, "end": 1555.68, "text": " tell about this, but do you around you see a shift there? Do you see more people going", "tokens": [50388, 980, 466, 341, 11, 457, 360, 291, 926, 291, 536, 257, 5513, 456, 30, 1144, 291, 536, 544, 561, 516, 50748], "temperature": 0.0, "avg_logprob": -0.183698693100287, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.01931898482143879}, {"id": 242, "seek": 154800, "start": 1555.68, "end": 1562.88, "text": " towards the slow take-off side, or is that not true? I haven't surveyed, I honestly don't know", "tokens": [50748, 3030, 264, 2964, 747, 12, 4506, 1252, 11, 420, 307, 300, 406, 2074, 30, 286, 2378, 380, 8984, 292, 11, 286, 6095, 500, 380, 458, 51108], "temperature": 0.0, "avg_logprob": -0.183698693100287, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.01931898482143879}, {"id": 243, "seek": 154800, "start": 1562.88, "end": 1568.4, "text": " if you think there is a shift bias by ability to publish about it, I believe you.", "tokens": [51108, 498, 291, 519, 456, 307, 257, 5513, 12577, 538, 3485, 281, 11374, 466, 309, 11, 286, 1697, 291, 13, 51384], "temperature": 0.0, "avg_logprob": -0.183698693100287, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.01931898482143879}, {"id": 244, "seek": 154800, "start": 1569.68, "end": 1576.56, "text": " I wouldn't make that claim too strictly. Okay, let's say that you're a non-AI expert and you", "tokens": [51448, 286, 2759, 380, 652, 300, 3932, 886, 20792, 13, 1033, 11, 718, 311, 584, 300, 291, 434, 257, 2107, 12, 48698, 5844, 293, 291, 51792], "temperature": 0.0, "avg_logprob": -0.183698693100287, "compression_ratio": 1.554585152838428, "no_speech_prob": 0.01931898482143879}, {"id": 245, "seek": 157656, "start": 1576.56, "end": 1582.6399999999999, "text": " still want to do something about this existential risk, such as we are kind of. What action do you", "tokens": [50364, 920, 528, 281, 360, 746, 466, 341, 37133, 3148, 11, 1270, 382, 321, 366, 733, 295, 13, 708, 3069, 360, 291, 50668], "temperature": 0.0, "avg_logprob": -0.11592890234554515, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.006388322450220585}, {"id": 246, "seek": 157656, "start": 1582.6399999999999, "end": 1589.6, "text": " think would be the best to take? So you're not an AI researcher, but you want to do something about...", "tokens": [50668, 519, 576, 312, 264, 1151, 281, 747, 30, 407, 291, 434, 406, 364, 7318, 21751, 11, 457, 291, 528, 281, 360, 746, 466, 485, 51016], "temperature": 0.0, "avg_logprob": -0.11592890234554515, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.006388322450220585}, {"id": 247, "seek": 157656, "start": 1590.56, "end": 1596.32, "text": " Yes. Is there anything at all, or would you just say, okay, just leave it to the experts,", "tokens": [51064, 1079, 13, 1119, 456, 1340, 412, 439, 11, 420, 576, 291, 445, 584, 11, 1392, 11, 445, 1856, 309, 281, 264, 8572, 11, 51352], "temperature": 0.0, "avg_logprob": -0.11592890234554515, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.006388322450220585}, {"id": 248, "seek": 157656, "start": 1596.32, "end": 1602.24, "text": " because there's not much you can do? I mean, in general, I think it's good if citizens are well", "tokens": [51352, 570, 456, 311, 406, 709, 291, 393, 360, 30, 286, 914, 11, 294, 2674, 11, 286, 519, 309, 311, 665, 498, 7180, 366, 731, 51648], "temperature": 0.0, "avg_logprob": -0.11592890234554515, "compression_ratio": 1.6398305084745763, "no_speech_prob": 0.006388322450220585}, {"id": 249, "seek": 160224, "start": 1602.24, "end": 1607.84, "text": " informed about the world and problems, and so the next time you vote, you don't vote for someone you", "tokens": [50364, 11740, 466, 264, 1002, 293, 2740, 11, 293, 370, 264, 958, 565, 291, 4740, 11, 291, 500, 380, 4740, 337, 1580, 291, 50644], "temperature": 0.0, "avg_logprob": -0.10382190994594408, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.024286460131406784}, {"id": 250, "seek": 160224, "start": 1607.84, "end": 1617.2, "text": " like visually, but actually picking better policies. It seems like based on age and experience of people", "tokens": [50644, 411, 19622, 11, 457, 767, 8867, 1101, 7657, 13, 467, 2544, 411, 2361, 322, 3205, 293, 1752, 295, 561, 51112], "temperature": 0.0, "avg_logprob": -0.10382190994594408, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.024286460131406784}, {"id": 251, "seek": 160224, "start": 1617.2, "end": 1622.4, "text": " were elected, at least in the US, they're not experts on most advanced technology. I hear many", "tokens": [51112, 645, 11776, 11, 412, 1935, 294, 264, 2546, 11, 436, 434, 406, 8572, 322, 881, 7339, 2899, 13, 286, 1568, 867, 51372], "temperature": 0.0, "avg_logprob": -0.10382190994594408, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.024286460131406784}, {"id": 252, "seek": 160224, "start": 1622.4, "end": 1629.2, "text": " of them don't use computers, so I'm skeptical that they can keep up with crypto economics and", "tokens": [51372, 295, 552, 500, 380, 764, 10807, 11, 370, 286, 478, 28601, 300, 436, 393, 1066, 493, 365, 17240, 14564, 293, 51712], "temperature": 0.0, "avg_logprob": -0.10382190994594408, "compression_ratio": 1.5887096774193548, "no_speech_prob": 0.024286460131406784}, {"id": 253, "seek": 162920, "start": 1629.28, "end": 1635.76, "text": " cryptography and synthetic biology and other interesting questions. So your job as a citizen", "tokens": [50368, 9844, 5820, 293, 23420, 14956, 293, 661, 1880, 1651, 13, 407, 428, 1691, 382, 257, 13326, 50692], "temperature": 0.0, "avg_logprob": -0.15412832147934857, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005778998602181673}, {"id": 254, "seek": 162920, "start": 1635.76, "end": 1640.56, "text": " is to be informed and make sure your views, your informed views, have all represented.", "tokens": [50692, 307, 281, 312, 11740, 293, 652, 988, 428, 6809, 11, 428, 11740, 6809, 11, 362, 439, 10379, 13, 50932], "temperature": 0.0, "avg_logprob": -0.15412832147934857, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005778998602181673}, {"id": 255, "seek": 162920, "start": 1642.8, "end": 1649.44, "text": " Right, some questions from the audience to not finish off yet, but we're getting to the end of", "tokens": [51044, 1779, 11, 512, 1651, 490, 264, 4034, 281, 406, 2413, 766, 1939, 11, 457, 321, 434, 1242, 281, 264, 917, 295, 51376], "temperature": 0.0, "avg_logprob": -0.15412832147934857, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005778998602181673}, {"id": 256, "seek": 162920, "start": 1649.44, "end": 1654.8, "text": " the conference already. First one, who do you believe is responsible for the safety of AI? The", "tokens": [51376, 264, 7586, 1217, 13, 2386, 472, 11, 567, 360, 291, 1697, 307, 6250, 337, 264, 4514, 295, 7318, 30, 440, 51644], "temperature": 0.0, "avg_logprob": -0.15412832147934857, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.005778998602181673}, {"id": 257, "seek": 165480, "start": 1654.8, "end": 1658.3999999999999, "text": " consumers, governments, or developers, or some other stakeholders?", "tokens": [50364, 11883, 11, 11280, 11, 420, 8849, 11, 420, 512, 661, 17779, 30, 50544], "temperature": 0.0, "avg_logprob": -0.08813385693532116, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.0011359413620084524}, {"id": 258, "seek": 165480, "start": 1661.04, "end": 1665.68, "text": " So that's another interesting question. The ownership of AI itself is very difficult,", "tokens": [50676, 407, 300, 311, 1071, 1880, 1168, 13, 440, 15279, 295, 7318, 2564, 307, 588, 2252, 11, 50908], "temperature": 0.0, "avg_logprob": -0.08813385693532116, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.0011359413620084524}, {"id": 259, "seek": 165480, "start": 1665.68, "end": 1671.44, "text": " right? If it's self-improving, it changes, it's not even obvious who has any control", "tokens": [50908, 558, 30, 759, 309, 311, 2698, 12, 332, 4318, 798, 11, 309, 2962, 11, 309, 311, 406, 754, 6322, 567, 575, 604, 1969, 51196], "temperature": 0.0, "avg_logprob": -0.08813385693532116, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.0011359413620084524}, {"id": 260, "seek": 165480, "start": 1671.44, "end": 1677.04, "text": " or possession over it. Obviously, the person to make it and release it has a lot of responsibility,", "tokens": [51196, 420, 20935, 670, 309, 13, 7580, 11, 264, 954, 281, 652, 309, 293, 4374, 309, 575, 257, 688, 295, 6357, 11, 51476], "temperature": 0.0, "avg_logprob": -0.08813385693532116, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.0011359413620084524}, {"id": 261, "seek": 165480, "start": 1677.04, "end": 1682.8799999999999, "text": " but if it's out there and now you are upgrading it, supplying it with goals, giving it data,", "tokens": [51476, 457, 498, 309, 311, 484, 456, 293, 586, 291, 366, 36249, 309, 11, 46815, 309, 365, 5493, 11, 2902, 309, 1412, 11, 51768], "temperature": 0.0, "avg_logprob": -0.08813385693532116, "compression_ratio": 1.6044776119402986, "no_speech_prob": 0.0011359413620084524}, {"id": 262, "seek": 168288, "start": 1683.1200000000001, "end": 1688.8000000000002, "text": " it feels like responsibility may shift to you. All of it for systems below human level", "tokens": [50376, 309, 3417, 411, 6357, 815, 5513, 281, 291, 13, 1057, 295, 309, 337, 3652, 2507, 1952, 1496, 50660], "temperature": 0.0, "avg_logprob": -0.11587090845461245, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.002089065033942461}, {"id": 263, "seek": 168288, "start": 1688.8000000000002, "end": 1693.2800000000002, "text": " performance. It's a tool, you are in charge. The moment it's human level or beyond,", "tokens": [50660, 3389, 13, 467, 311, 257, 2290, 11, 291, 366, 294, 4602, 13, 440, 1623, 309, 311, 1952, 1496, 420, 4399, 11, 50884], "temperature": 0.0, "avg_logprob": -0.11587090845461245, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.002089065033942461}, {"id": 264, "seek": 168288, "start": 1694.16, "end": 1698.72, "text": " it's an independent agent. You are as responsible as you are for your adult children.", "tokens": [50928, 309, 311, 364, 6695, 9461, 13, 509, 366, 382, 6250, 382, 291, 366, 337, 428, 5075, 2227, 13, 51156], "temperature": 0.0, "avg_logprob": -0.11587090845461245, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.002089065033942461}, {"id": 265, "seek": 168288, "start": 1702.3200000000002, "end": 1706.3200000000002, "text": " Another one that's also very interesting, I think, is it possible to program in a programming", "tokens": [51336, 3996, 472, 300, 311, 611, 588, 1880, 11, 286, 519, 11, 307, 309, 1944, 281, 1461, 294, 257, 9410, 51536], "temperature": 0.0, "avg_logprob": -0.11587090845461245, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.002089065033942461}, {"id": 266, "seek": 168288, "start": 1706.3200000000002, "end": 1711.5200000000002, "text": " language, not based on human language, to remove the ambiguity? Or would it be possible to have an", "tokens": [51536, 2856, 11, 406, 2361, 322, 1952, 2856, 11, 281, 4159, 264, 46519, 30, 1610, 576, 309, 312, 1944, 281, 362, 364, 51796], "temperature": 0.0, "avg_logprob": -0.11587090845461245, "compression_ratio": 1.6816479400749065, "no_speech_prob": 0.002089065033942461}, {"id": 267, "seek": 171152, "start": 1711.52, "end": 1716.8, "text": " AI create a language without ambiguity? If the AI could create such a language, would humans be", "tokens": [50364, 7318, 1884, 257, 2856, 1553, 46519, 30, 759, 264, 7318, 727, 1884, 1270, 257, 2856, 11, 576, 6255, 312, 50628], "temperature": 0.0, "avg_logprob": -0.07440816334315709, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.0031506530940532684}, {"id": 268, "seek": 171152, "start": 1716.8, "end": 1722.72, "text": " able to learn it, or would we then also have to trust the AI to program in it? That's an", "tokens": [50628, 1075, 281, 1466, 309, 11, 420, 576, 321, 550, 611, 362, 281, 3361, 264, 7318, 281, 1461, 294, 309, 30, 663, 311, 364, 50924], "temperature": 0.0, "avg_logprob": -0.07440816334315709, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.0031506530940532684}, {"id": 269, "seek": 171152, "start": 1722.72, "end": 1727.68, "text": " excellent question. So there is a lot of effort. First of all, every programming language is an", "tokens": [50924, 7103, 1168, 13, 407, 456, 307, 257, 688, 295, 4630, 13, 2386, 295, 439, 11, 633, 9410, 2856, 307, 364, 51172], "temperature": 0.0, "avg_logprob": -0.07440816334315709, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.0031506530940532684}, {"id": 270, "seek": 171152, "start": 1727.68, "end": 1732.6399999999999, "text": " attempt to get away from English and into less ambiguous languages, but we know languages,", "tokens": [51172, 5217, 281, 483, 1314, 490, 3669, 293, 666, 1570, 39465, 8650, 11, 457, 321, 458, 8650, 11, 51420], "temperature": 0.0, "avg_logprob": -0.07440816334315709, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.0031506530940532684}, {"id": 271, "seek": 171152, "start": 1732.6399999999999, "end": 1738.08, "text": " programming languages have lots of bugs. There are logical languages developed to remove", "tokens": [51420, 9410, 8650, 362, 3195, 295, 15120, 13, 821, 366, 14978, 8650, 4743, 281, 4159, 51692], "temperature": 0.0, "avg_logprob": -0.07440816334315709, "compression_ratio": 1.7557251908396947, "no_speech_prob": 0.0031506530940532684}, {"id": 272, "seek": 173808, "start": 1738.1599999999999, "end": 1744.48, "text": " ambiguity. And I think Stephen Wolfram has a nice article about communicating with AI. And he, of", "tokens": [50368, 46519, 13, 400, 286, 519, 13391, 16634, 2356, 575, 257, 1481, 7222, 466, 17559, 365, 7318, 13, 400, 415, 11, 295, 50684], "temperature": 0.0, "avg_logprob": -0.1430091748292419, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.004175890237092972}, {"id": 273, "seek": 173808, "start": 1744.48, "end": 1751.36, "text": " course, uses his Mathematica and models he creates in language, Wolfram language he developed as", "tokens": [50684, 1164, 11, 4960, 702, 15776, 8615, 2262, 293, 5245, 415, 7829, 294, 2856, 11, 16634, 2356, 2856, 415, 4743, 382, 51028], "temperature": 0.0, "avg_logprob": -0.1430091748292419, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.004175890237092972}, {"id": 274, "seek": 173808, "start": 1751.36, "end": 1757.9199999999998, "text": " possible solution. I think you can do way better than human language in terms of ambiguity. I'm", "tokens": [51028, 1944, 3827, 13, 286, 519, 291, 393, 360, 636, 1101, 813, 1952, 2856, 294, 2115, 295, 46519, 13, 286, 478, 51356], "temperature": 0.0, "avg_logprob": -0.1430091748292419, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.004175890237092972}, {"id": 275, "seek": 173808, "start": 1757.9199999999998, "end": 1766.3999999999999, "text": " skeptical about bug-free communication. It relies on your existing cognitive models, your", "tokens": [51356, 28601, 466, 7426, 12, 10792, 6101, 13, 467, 30910, 322, 428, 6741, 15605, 5245, 11, 428, 51780], "temperature": 0.0, "avg_logprob": -0.1430091748292419, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.004175890237092972}, {"id": 276, "seek": 176640, "start": 1766.4, "end": 1774.0800000000002, "text": " understanding, and if you have different priors, even using well-defined terms may lead to problems.", "tokens": [50364, 3701, 11, 293, 498, 291, 362, 819, 1790, 830, 11, 754, 1228, 731, 12, 37716, 2115, 815, 1477, 281, 2740, 13, 50748], "temperature": 0.0, "avg_logprob": -0.11062446393464741, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.008449232205748558}, {"id": 277, "seek": 176640, "start": 1774.0800000000002, "end": 1778.3200000000002, "text": " But it's a very interesting area to do additional research. If you have", "tokens": [50748, 583, 309, 311, 257, 588, 1880, 1859, 281, 360, 4497, 2132, 13, 759, 291, 362, 50960], "temperature": 0.0, "avg_logprob": -0.11062446393464741, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.008449232205748558}, {"id": 278, "seek": 176640, "start": 1778.3200000000002, "end": 1782.4, "text": " background in linguistics, I definitely invite you to look into that.", "tokens": [50960, 3678, 294, 21766, 6006, 11, 286, 2138, 7980, 291, 281, 574, 666, 300, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11062446393464741, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.008449232205748558}, {"id": 279, "seek": 176640, "start": 1784.3200000000002, "end": 1789.44, "text": " Another interesting one from Simon Friedrich, actually a previous speaker. Do you think AGI", "tokens": [51260, 3996, 1880, 472, 490, 13193, 17605, 10794, 11, 767, 257, 3894, 8145, 13, 1144, 291, 519, 316, 26252, 51516], "temperature": 0.0, "avg_logprob": -0.11062446393464741, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.008449232205748558}, {"id": 280, "seek": 176640, "start": 1789.44, "end": 1793.52, "text": " could help overcome their global collective action problems that are at the roots of basically", "tokens": [51516, 727, 854, 10473, 641, 4338, 12590, 3069, 2740, 300, 366, 412, 264, 10669, 295, 1936, 51720], "temperature": 0.0, "avg_logprob": -0.11062446393464741, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.008449232205748558}, {"id": 281, "seek": 179352, "start": 1793.52, "end": 1796.4, "text": " all the existential risks, including those of AI itself?", "tokens": [50364, 439, 264, 37133, 10888, 11, 3009, 729, 295, 7318, 2564, 30, 50508], "temperature": 0.0, "avg_logprob": -0.14504175076539488, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0028109843842685223}, {"id": 282, "seek": 179352, "start": 1798.8799999999999, "end": 1805.76, "text": " So that's another great question. I see AI as a meta problem and meta solution. If we get it right,", "tokens": [50632, 407, 300, 311, 1071, 869, 1168, 13, 286, 536, 7318, 382, 257, 19616, 1154, 293, 19616, 3827, 13, 759, 321, 483, 309, 558, 11, 50976], "temperature": 0.0, "avg_logprob": -0.14504175076539488, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0028109843842685223}, {"id": 283, "seek": 179352, "start": 1805.76, "end": 1811.68, "text": " if I'm wrong and you can make friendly superintelligence well-aligned, everything I said is just a", "tokens": [50976, 498, 286, 478, 2085, 293, 291, 393, 652, 9208, 1687, 20761, 17644, 731, 12, 304, 16690, 11, 1203, 286, 848, 307, 445, 257, 51272], "temperature": 0.0, "avg_logprob": -0.14504175076539488, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0028109843842685223}, {"id": 284, "seek": 179352, "start": 1811.68, "end": 1817.2, "text": " mistake, then it solves all the other existential problems trivially. Whatever is climate change,", "tokens": [51272, 6146, 11, 550, 309, 39890, 439, 264, 661, 37133, 2740, 1376, 85, 2270, 13, 8541, 307, 5659, 1319, 11, 51548], "temperature": 0.0, "avg_logprob": -0.14504175076539488, "compression_ratio": 1.5414847161572052, "no_speech_prob": 0.0028109843842685223}, {"id": 285, "seek": 181720, "start": 1817.2, "end": 1823.44, "text": " synthetic bio, you have a godlike tool for solving those problems. If I'm right and it's", "tokens": [50364, 23420, 12198, 11, 291, 362, 257, 3044, 4092, 2290, 337, 12606, 729, 2740, 13, 759, 286, 478, 558, 293, 309, 311, 50676], "temperature": 0.0, "avg_logprob": -0.09263566669664886, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.013299361802637577}, {"id": 286, "seek": 181720, "start": 1823.44, "end": 1829.04, "text": " a terrible risk and it comes before, then it solves it by either killing all of us. We don't", "tokens": [50676, 257, 6237, 3148, 293, 309, 1487, 949, 11, 550, 309, 39890, 309, 538, 2139, 8011, 439, 295, 505, 13, 492, 500, 380, 50956], "temperature": 0.0, "avg_logprob": -0.09263566669664886, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.013299361802637577}, {"id": 287, "seek": 181720, "start": 1829.04, "end": 1834.88, "text": " have to worry about it or it comes before again. So if it takes a hundred years for climate change", "tokens": [50956, 362, 281, 3292, 466, 309, 420, 309, 1487, 949, 797, 13, 407, 498, 309, 2516, 257, 3262, 924, 337, 5659, 1319, 51248], "temperature": 0.0, "avg_logprob": -0.09263566669664886, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.013299361802637577}, {"id": 288, "seek": 181720, "start": 1834.88, "end": 1839.6000000000001, "text": " to build up to boiling point, this happens in 20 years. It kind of dominates the risk.", "tokens": [51248, 281, 1322, 493, 281, 16208, 935, 11, 341, 2314, 294, 945, 924, 13, 467, 733, 295, 8859, 1024, 264, 3148, 13, 51484], "temperature": 0.0, "avg_logprob": -0.09263566669664886, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.013299361802637577}, {"id": 289, "seek": 183960, "start": 1840.48, "end": 1846.7199999999998, "text": " I'm not sure about applying AI to solve the AI problem. That's a bit of a catch-22. There are", "tokens": [50408, 286, 478, 406, 988, 466, 9275, 7318, 281, 5039, 264, 7318, 1154, 13, 663, 311, 257, 857, 295, 257, 3745, 12, 7490, 13, 821, 366, 50720], "temperature": 0.0, "avg_logprob": -0.2096493636505513, "compression_ratio": 1.435, "no_speech_prob": 0.004815255291759968}, {"id": 290, "seek": 183960, "start": 1846.7199999999998, "end": 1854.9599999999998, "text": " those solutions where you have a supervisory agent, AI, AGI, Nyanee, which looks after the world,", "tokens": [50720, 729, 6547, 689, 291, 362, 257, 34409, 827, 9461, 11, 7318, 11, 316, 26252, 11, 426, 6277, 1653, 11, 597, 1542, 934, 264, 1002, 11, 51132], "temperature": 0.0, "avg_logprob": -0.2096493636505513, "compression_ratio": 1.435, "no_speech_prob": 0.004815255291759968}, {"id": 291, "seek": 183960, "start": 1854.9599999999998, "end": 1863.1999999999998, "text": " making sure no one creates dangerous AIs. I'm very skeptical of such super agents with a lot of", "tokens": [51132, 1455, 988, 572, 472, 7829, 5795, 316, 6802, 13, 286, 478, 588, 28601, 295, 1270, 1687, 12554, 365, 257, 688, 295, 51544], "temperature": 0.0, "avg_logprob": -0.2096493636505513, "compression_ratio": 1.435, "no_speech_prob": 0.004815255291759968}, {"id": 292, "seek": 186320, "start": 1864.0800000000002, "end": 1870.72, "text": " government control powers. I think they may be worse than what the system we're protecting against", "tokens": [50408, 2463, 1969, 8674, 13, 286, 519, 436, 815, 312, 5324, 813, 437, 264, 1185, 321, 434, 12316, 1970, 50740], "temperature": 0.0, "avg_logprob": -0.14022504129717428, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.005664534401148558}, {"id": 293, "seek": 186320, "start": 1871.3600000000001, "end": 1882.4, "text": " gives us. Great answer, I think. One final question from the audience now. So if we cannot stop AI", "tokens": [50772, 2709, 505, 13, 3769, 1867, 11, 286, 519, 13, 1485, 2572, 1168, 490, 264, 4034, 586, 13, 407, 498, 321, 2644, 1590, 7318, 51324], "temperature": 0.0, "avg_logprob": -0.14022504129717428, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.005664534401148558}, {"id": 294, "seek": 186320, "start": 1882.4, "end": 1887.1200000000001, "text": " development and we cannot totally ensure that it is safe, do we just need to accept that it is a", "tokens": [51324, 3250, 293, 321, 2644, 3879, 5586, 300, 309, 307, 3273, 11, 360, 321, 445, 643, 281, 3241, 300, 309, 307, 257, 51560], "temperature": 0.0, "avg_logprob": -0.14022504129717428, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.005664534401148558}, {"id": 295, "seek": 186320, "start": 1887.1200000000001, "end": 1891.3600000000001, "text": " risk or even a big risk? Or is there anything we can do, for example, policy-wise?", "tokens": [51560, 3148, 420, 754, 257, 955, 3148, 30, 1610, 307, 456, 1340, 321, 393, 360, 11, 337, 1365, 11, 3897, 12, 3711, 30, 51772], "temperature": 0.0, "avg_logprob": -0.14022504129717428, "compression_ratio": 1.5450819672131149, "no_speech_prob": 0.005664534401148558}, {"id": 296, "seek": 189320, "start": 1893.68, "end": 1898.4, "text": " So I think we need to do more research. I published those papers about a year ago and I", "tokens": [50388, 407, 286, 519, 321, 643, 281, 360, 544, 2132, 13, 286, 6572, 729, 10577, 466, 257, 1064, 2057, 293, 286, 50624], "temperature": 0.0, "avg_logprob": -0.0948668602974184, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.003860334400087595}, {"id": 297, "seek": 189320, "start": 1898.4, "end": 1903.2, "text": " haven't seen a strong response from a community addressing those. If somebody just published", "tokens": [50624, 2378, 380, 1612, 257, 2068, 4134, 490, 257, 1768, 14329, 729, 13, 759, 2618, 445, 6572, 50864], "temperature": 0.0, "avg_logprob": -0.0948668602974184, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.003860334400087595}, {"id": 298, "seek": 189320, "start": 1903.2, "end": 1907.92, "text": " a paper saying, this is why you're wrong, then be very happy, but I haven't seen it. So I have to", "tokens": [50864, 257, 3035, 1566, 11, 341, 307, 983, 291, 434, 2085, 11, 550, 312, 588, 2055, 11, 457, 286, 2378, 380, 1612, 309, 13, 407, 286, 362, 281, 51100], "temperature": 0.0, "avg_logprob": -0.0948668602974184, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.003860334400087595}, {"id": 299, "seek": 189320, "start": 1907.92, "end": 1913.04, "text": " assume that there is some merit to what I'm saying. The question is then, what do we do with our", "tokens": [51100, 6552, 300, 456, 307, 512, 24527, 281, 437, 286, 478, 1566, 13, 440, 1168, 307, 550, 11, 437, 360, 321, 360, 365, 527, 51356], "temperature": 0.0, "avg_logprob": -0.0948668602974184, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.003860334400087595}, {"id": 300, "seek": 189320, "start": 1913.04, "end": 1919.3600000000001, "text": " lives? How do we update based on that? What do we change? For most people, I don't know if it makes", "tokens": [51356, 2909, 30, 1012, 360, 321, 5623, 2361, 322, 300, 30, 708, 360, 321, 1319, 30, 1171, 881, 561, 11, 286, 500, 380, 458, 498, 309, 1669, 51672], "temperature": 0.0, "avg_logprob": -0.0948668602974184, "compression_ratio": 1.6608391608391608, "no_speech_prob": 0.003860334400087595}, {"id": 301, "seek": 191936, "start": 1919.36, "end": 1924.56, "text": " any difference. Before you were told, okay, you're definitely dying in 60 years. Now you may be dying", "tokens": [50364, 604, 2649, 13, 4546, 291, 645, 1907, 11, 1392, 11, 291, 434, 2138, 8639, 294, 4060, 924, 13, 823, 291, 815, 312, 8639, 50624], "temperature": 0.0, "avg_logprob": -0.09358569553920201, "compression_ratio": 1.584, "no_speech_prob": 0.031009269878268242}, {"id": 302, "seek": 191936, "start": 1924.56, "end": 1932.4799999999998, "text": " in 40. Not a big update. Figure out what to do with your 401k plan. You spend it on something now", "tokens": [50624, 294, 3356, 13, 1726, 257, 955, 5623, 13, 43225, 484, 437, 281, 360, 365, 428, 37510, 74, 1393, 13, 509, 3496, 309, 322, 746, 586, 51020], "temperature": 0.0, "avg_logprob": -0.09358569553920201, "compression_ratio": 1.584, "no_speech_prob": 0.031009269878268242}, {"id": 303, "seek": 191936, "start": 1932.4799999999998, "end": 1939.9199999999998, "text": " or wait for it to become worthless later. I don't have any magical solutions or answers. I am curious", "tokens": [51020, 420, 1699, 337, 309, 281, 1813, 34857, 1780, 13, 286, 500, 380, 362, 604, 12066, 6547, 420, 6338, 13, 286, 669, 6369, 51392], "temperature": 0.0, "avg_logprob": -0.09358569553920201, "compression_ratio": 1.584, "no_speech_prob": 0.031009269878268242}, {"id": 304, "seek": 191936, "start": 1940.6399999999999, "end": 1947.28, "text": " in case of successful alignment what happens to economy, what happens to work, what happens to", "tokens": [51428, 294, 1389, 295, 4406, 18515, 437, 2314, 281, 5010, 11, 437, 2314, 281, 589, 11, 437, 2314, 281, 51760], "temperature": 0.0, "avg_logprob": -0.09358569553920201, "compression_ratio": 1.584, "no_speech_prob": 0.031009269878268242}, {"id": 305, "seek": 194728, "start": 1947.28, "end": 1955.28, "text": " people's social interactions. I do have a paper which kind of assumes that progress in virtual", "tokens": [50364, 561, 311, 2093, 13280, 13, 286, 360, 362, 257, 3035, 597, 733, 295, 37808, 300, 4205, 294, 6374, 50764], "temperature": 0.0, "avg_logprob": -0.08411046828346691, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.004305672366172075}, {"id": 306, "seek": 194728, "start": 1955.28, "end": 1963.2, "text": " reality will be as good as progress in AI. And so each one of us gets what I call a personal", "tokens": [50764, 4103, 486, 312, 382, 665, 382, 4205, 294, 7318, 13, 400, 370, 1184, 472, 295, 505, 2170, 437, 286, 818, 257, 2973, 51160], "temperature": 0.0, "avg_logprob": -0.08411046828346691, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.004305672366172075}, {"id": 307, "seek": 194728, "start": 1963.2, "end": 1968.72, "text": " universe, where you basically get to do whatever you want and you don't have to negotiate with", "tokens": [51160, 6445, 11, 689, 291, 1936, 483, 281, 360, 2035, 291, 528, 293, 291, 500, 380, 362, 281, 21713, 365, 51436], "temperature": 0.0, "avg_logprob": -0.08411046828346691, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.004305672366172075}, {"id": 308, "seek": 194728, "start": 1968.72, "end": 1974.56, "text": " others. There is no need for consensus. You basically have independence. So at least the", "tokens": [51436, 2357, 13, 821, 307, 572, 643, 337, 19115, 13, 509, 1936, 362, 14640, 13, 407, 412, 1935, 264, 51728], "temperature": 0.0, "avg_logprob": -0.08411046828346691, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.004305672366172075}, {"id": 309, "seek": 197456, "start": 1974.56, "end": 1980.0, "text": " difficult part of value alignment problem is not aligning with me or you. It's hard. It's hard,", "tokens": [50364, 2252, 644, 295, 2158, 18515, 1154, 307, 406, 419, 9676, 365, 385, 420, 291, 13, 467, 311, 1152, 13, 467, 311, 1152, 11, 50636], "temperature": 0.0, "avg_logprob": -0.0745607549493963, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.0012521060416474938}, {"id": 310, "seek": 197456, "start": 1980.0, "end": 1985.44, "text": " but it's not impossible. It's getting 8 billion people plus all the squirrels and whatnot to agree", "tokens": [50636, 457, 309, 311, 406, 6243, 13, 467, 311, 1242, 1649, 5218, 561, 1804, 439, 264, 28565, 82, 293, 25882, 281, 3986, 50908], "temperature": 0.0, "avg_logprob": -0.0745607549493963, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.0012521060416474938}, {"id": 311, "seek": 197456, "start": 1985.44, "end": 1991.36, "text": " on something. And this is where the personal universe solution reduces it to just now we need", "tokens": [50908, 322, 746, 13, 400, 341, 307, 689, 264, 2973, 6445, 3827, 18081, 309, 281, 445, 586, 321, 643, 51204], "temperature": 0.0, "avg_logprob": -0.0745607549493963, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.0012521060416474938}, {"id": 312, "seek": 197456, "start": 1991.36, "end": 1996.56, "text": " to control the substrate. If you can get control of computational substrate and everyone gets", "tokens": [51204, 281, 1969, 264, 27585, 13, 759, 291, 393, 483, 1969, 295, 28270, 27585, 293, 1518, 2170, 51464], "temperature": 0.0, "avg_logprob": -0.0745607549493963, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.0012521060416474938}, {"id": 313, "seek": 197456, "start": 1996.56, "end": 2003.2, "text": " the resources to run their personal universe, okay, we're doing well. We have this virtual agreement.", "tokens": [51464, 264, 3593, 281, 1190, 641, 2973, 6445, 11, 1392, 11, 321, 434, 884, 731, 13, 492, 362, 341, 6374, 8106, 13, 51796], "temperature": 0.0, "avg_logprob": -0.0745607549493963, "compression_ratio": 1.7163120567375887, "no_speech_prob": 0.0012521060416474938}, {"id": 314, "seek": 200456, "start": 2004.56, "end": 2013.76, "text": " I think that's not a good point again. I'm wondering also on a more personal level,", "tokens": [50364, 286, 519, 300, 311, 406, 257, 665, 935, 797, 13, 286, 478, 6359, 611, 322, 257, 544, 2973, 1496, 11, 50824], "temperature": 0.0, "avg_logprob": -0.14648201886345358, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.005253809504210949}, {"id": 315, "seek": 200456, "start": 2013.76, "end": 2019.2, "text": " like when did you start to think about AI safety yourself and when did you move into this", "tokens": [50824, 411, 562, 630, 291, 722, 281, 519, 466, 7318, 4514, 1803, 293, 562, 630, 291, 1286, 666, 341, 51096], "temperature": 0.0, "avg_logprob": -0.14648201886345358, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.005253809504210949}, {"id": 316, "seek": 200456, "start": 2019.2, "end": 2025.28, "text": " research field? Was there anything that inspired you to do this and also what were the responses", "tokens": [51096, 2132, 2519, 30, 3027, 456, 1340, 300, 7547, 291, 281, 360, 341, 293, 611, 437, 645, 264, 13019, 51400], "temperature": 0.0, "avg_logprob": -0.14648201886345358, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.005253809504210949}, {"id": 317, "seek": 200456, "start": 2025.28, "end": 2031.36, "text": " that you got from fellow scientists in moving in this direction? Well, it was a very gradual", "tokens": [51400, 300, 291, 658, 490, 7177, 7708, 294, 2684, 294, 341, 3513, 30, 1042, 11, 309, 390, 257, 588, 32890, 51704], "temperature": 0.0, "avg_logprob": -0.14648201886345358, "compression_ratio": 1.6061946902654867, "no_speech_prob": 0.005253809504210949}, {"id": 318, "seek": 203136, "start": 2031.36, "end": 2036.7199999999998, "text": " process. So I was doing research and behavioral biometrics. I was profiling poker players to see", "tokens": [50364, 1399, 13, 407, 286, 390, 884, 2132, 293, 19124, 3228, 649, 10716, 13, 286, 390, 1740, 4883, 36863, 4150, 281, 536, 50632], "temperature": 0.0, "avg_logprob": -0.13169142521849467, "compression_ratio": 1.662962962962963, "no_speech_prob": 0.01406413409858942}, {"id": 319, "seek": 203136, "start": 2036.7199999999998, "end": 2042.8799999999999, "text": " if, you know, accounts get hacked and tell the things like that. And at the time, I realized", "tokens": [50632, 498, 11, 291, 458, 11, 9402, 483, 36218, 293, 980, 264, 721, 411, 300, 13, 400, 412, 264, 565, 11, 286, 5334, 50940], "temperature": 0.0, "avg_logprob": -0.13169142521849467, "compression_ratio": 1.662962962962963, "no_speech_prob": 0.01406413409858942}, {"id": 320, "seek": 203136, "start": 2042.8799999999999, "end": 2048.48, "text": " majority of online players are now bots. So my work started to be about detecting bots,", "tokens": [50940, 6286, 295, 2950, 4150, 366, 586, 35410, 13, 407, 452, 589, 1409, 281, 312, 466, 40237, 35410, 11, 51220], "temperature": 0.0, "avg_logprob": -0.13169142521849467, "compression_ratio": 1.662962962962963, "no_speech_prob": 0.01406413409858942}, {"id": 321, "seek": 203136, "start": 2049.44, "end": 2054.4, "text": " preventing bots from participating. But the question was, as bots get smarter and better,", "tokens": [51268, 19965, 35410, 490, 13950, 13, 583, 264, 1168, 390, 11, 382, 35410, 483, 20294, 293, 1101, 11, 51516], "temperature": 0.0, "avg_logprob": -0.13169142521849467, "compression_ratio": 1.662962962962963, "no_speech_prob": 0.01406413409858942}, {"id": 322, "seek": 203136, "start": 2054.4, "end": 2058.96, "text": " can we keep up? And not just in poker, but in general online bots and automation.", "tokens": [51516, 393, 321, 1066, 493, 30, 400, 406, 445, 294, 36863, 11, 457, 294, 2674, 2950, 35410, 293, 17769, 13, 51744], "temperature": 0.0, "avg_logprob": -0.13169142521849467, "compression_ratio": 1.662962962962963, "no_speech_prob": 0.01406413409858942}, {"id": 323, "seek": 205896, "start": 2059.68, "end": 2066.56, "text": " I did that type of work for a while. I went to what was at the time Singularity Institute for", "tokens": [50400, 286, 630, 300, 2010, 295, 589, 337, 257, 1339, 13, 286, 1437, 281, 437, 390, 412, 264, 565, 7474, 1040, 507, 9446, 337, 50744], "temperature": 0.0, "avg_logprob": -0.13214535940261113, "compression_ratio": 1.6711111111111112, "no_speech_prob": 0.003210832830518484}, {"id": 324, "seek": 205896, "start": 2066.56, "end": 2071.68, "text": " artificial intelligence, which was fighting hard against artificial intelligence. But", "tokens": [50744, 11677, 7599, 11, 597, 390, 5237, 1152, 1970, 11677, 7599, 13, 583, 51000], "temperature": 0.0, "avg_logprob": -0.13214535940261113, "compression_ratio": 1.6711111111111112, "no_speech_prob": 0.003210832830518484}, {"id": 325, "seek": 205896, "start": 2071.68, "end": 2077.92, "text": " they had a lot of great ideas, which I still work on. And I've been back as a fellow and a", "tokens": [51000, 436, 632, 257, 688, 295, 869, 3487, 11, 597, 286, 920, 589, 322, 13, 400, 286, 600, 668, 646, 382, 257, 7177, 293, 257, 51312], "temperature": 0.0, "avg_logprob": -0.13214535940261113, "compression_ratio": 1.6711111111111112, "no_speech_prob": 0.003210832830518484}, {"id": 326, "seek": 205896, "start": 2077.92, "end": 2083.68, "text": " research advisor for Machine Intelligence Research Institute. I think they're doing excellent theoretical", "tokens": [51312, 2132, 19161, 337, 22155, 27274, 10303, 9446, 13, 286, 519, 436, 434, 884, 7103, 20864, 51600], "temperature": 0.0, "avg_logprob": -0.13214535940261113, "compression_ratio": 1.6711111111111112, "no_speech_prob": 0.003210832830518484}, {"id": 327, "seek": 208368, "start": 2083.68, "end": 2094.7999999999997, "text": " work. Yeah, I think perhaps one more, like some AI researchers, I think, might be hesitant to talk", "tokens": [50364, 589, 13, 865, 11, 286, 519, 4317, 472, 544, 11, 411, 512, 7318, 10309, 11, 286, 519, 11, 1062, 312, 36290, 281, 751, 50920], "temperature": 0.0, "avg_logprob": -0.12660029694274233, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.006658494472503662}, {"id": 328, "seek": 208368, "start": 2094.7999999999997, "end": 2099.3599999999997, "text": " about existential risk in the public debate, like you already quickly mentioned, for example, in the", "tokens": [50920, 466, 37133, 3148, 294, 264, 1908, 7958, 11, 411, 291, 1217, 2661, 2835, 11, 337, 1365, 11, 294, 264, 51148], "temperature": 0.0, "avg_logprob": -0.12660029694274233, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.006658494472503662}, {"id": 329, "seek": 208368, "start": 2099.3599999999997, "end": 2106.0, "text": " media. Do you agree that they are hesitant to do that? And why do you think that is so?", "tokens": [51148, 3021, 13, 1144, 291, 3986, 300, 436, 366, 36290, 281, 360, 300, 30, 400, 983, 360, 291, 519, 300, 307, 370, 30, 51480], "temperature": 0.0, "avg_logprob": -0.12660029694274233, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.006658494472503662}, {"id": 330, "seek": 208368, "start": 2108.16, "end": 2112.3199999999997, "text": " I think I lost a few words. So with media, what's the concern?", "tokens": [51588, 286, 519, 286, 2731, 257, 1326, 2283, 13, 407, 365, 3021, 11, 437, 311, 264, 3136, 30, 51796], "temperature": 0.0, "avg_logprob": -0.12660029694274233, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.006658494472503662}, {"id": 331, "seek": 211232, "start": 2112.4, "end": 2117.44, "text": " Sorry, I'll just repeat the whole thing. Some AI researchers might be hesitant to talk about", "tokens": [50368, 4919, 11, 286, 603, 445, 7149, 264, 1379, 551, 13, 2188, 7318, 10309, 1062, 312, 36290, 281, 751, 466, 50620], "temperature": 0.0, "avg_logprob": -0.12077966550501382, "compression_ratio": 1.6187290969899666, "no_speech_prob": 0.00609025452286005}, {"id": 332, "seek": 211232, "start": 2117.44, "end": 2122.96, "text": " existential risk in the public debates, for example, in the media. Do you agree that this is so, that", "tokens": [50620, 37133, 3148, 294, 264, 1908, 24203, 11, 337, 1365, 11, 294, 264, 3021, 13, 1144, 291, 3986, 300, 341, 307, 370, 11, 300, 50896], "temperature": 0.0, "avg_logprob": -0.12077966550501382, "compression_ratio": 1.6187290969899666, "no_speech_prob": 0.00609025452286005}, {"id": 333, "seek": 211232, "start": 2122.96, "end": 2130.2400000000002, "text": " they are hesitant to do this? And if so, why do you think that is? Well, it's a personal decision", "tokens": [50896, 436, 366, 36290, 281, 360, 341, 30, 400, 498, 370, 11, 983, 360, 291, 519, 300, 307, 30, 1042, 11, 309, 311, 257, 2973, 3537, 51260], "temperature": 0.0, "avg_logprob": -0.12077966550501382, "compression_ratio": 1.6187290969899666, "no_speech_prob": 0.00609025452286005}, {"id": 334, "seek": 211232, "start": 2130.2400000000002, "end": 2135.52, "text": " based on your situation. So some people, before they get tenure, follow a very good advice of", "tokens": [51260, 2361, 322, 428, 2590, 13, 407, 512, 561, 11, 949, 436, 483, 32256, 11, 1524, 257, 588, 665, 5192, 295, 51524], "temperature": 0.0, "avg_logprob": -0.12077966550501382, "compression_ratio": 1.6187290969899666, "no_speech_prob": 0.00609025452286005}, {"id": 335, "seek": 211232, "start": 2135.52, "end": 2141.84, "text": " be quiet. After you get tenure, never shut up again. But that's not a bad idea. You'll definitely", "tokens": [51524, 312, 5677, 13, 2381, 291, 483, 32256, 11, 1128, 5309, 493, 797, 13, 583, 300, 311, 406, 257, 1578, 1558, 13, 509, 603, 2138, 51840], "temperature": 0.0, "avg_logprob": -0.12077966550501382, "compression_ratio": 1.6187290969899666, "no_speech_prob": 0.00609025452286005}, {"id": 336, "seek": 214184, "start": 2141.84, "end": 2147.2000000000003, "text": " get someone disappointed in you. And that doesn't help your tenure case. I'm tenured, so I've been", "tokens": [50364, 483, 1580, 13856, 294, 291, 13, 400, 300, 1177, 380, 854, 428, 32256, 1389, 13, 286, 478, 2064, 3831, 11, 370, 286, 600, 668, 50632], "temperature": 0.0, "avg_logprob": -0.1281873053246802, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.0021953743416815996}, {"id": 337, "seek": 214184, "start": 2147.2000000000003, "end": 2155.04, "text": " saying stupid things for years now. What do you think about an initiative such as the existential", "tokens": [50632, 1566, 6631, 721, 337, 924, 586, 13, 708, 360, 291, 519, 466, 364, 11552, 1270, 382, 264, 37133, 51024], "temperature": 0.0, "avg_logprob": -0.1281873053246802, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.0021953743416815996}, {"id": 338, "seek": 214184, "start": 2155.04, "end": 2162.48, "text": " risk of territory? Is it useful to communicate this to more people in general, or to a certain", "tokens": [51024, 3148, 295, 11360, 30, 1119, 309, 4420, 281, 7890, 341, 281, 544, 561, 294, 2674, 11, 420, 281, 257, 1629, 51396], "temperature": 0.0, "avg_logprob": -0.1281873053246802, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.0021953743416815996}, {"id": 339, "seek": 214184, "start": 2162.48, "end": 2168.4, "text": " subset of people? Or do you think it's basically something that should be solved among researchers?", "tokens": [51396, 25993, 295, 561, 30, 1610, 360, 291, 519, 309, 311, 1936, 746, 300, 820, 312, 13041, 3654, 10309, 30, 51692], "temperature": 0.0, "avg_logprob": -0.1281873053246802, "compression_ratio": 1.582995951417004, "no_speech_prob": 0.0021953743416815996}, {"id": 340, "seek": 216840, "start": 2169.04, "end": 2174.64, "text": " Well, if you think about developing a GI, working on superintelligence, you're really running an", "tokens": [50396, 1042, 11, 498, 291, 519, 466, 6416, 257, 26634, 11, 1364, 322, 1687, 20761, 17644, 11, 291, 434, 534, 2614, 364, 50676], "temperature": 0.0, "avg_logprob": -0.22504767965763173, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.006964887026697397}, {"id": 341, "seek": 216840, "start": 2174.64, "end": 2178.96, "text": " experiment on all the humans, right? You've got eight billion subjects, none of them consented to", "tokens": [50676, 5120, 322, 439, 264, 6255, 11, 558, 30, 509, 600, 658, 3180, 5218, 13066, 11, 6022, 295, 552, 1014, 6003, 281, 50892], "temperature": 0.0, "avg_logprob": -0.22504767965763173, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.006964887026697397}, {"id": 342, "seek": 216840, "start": 2178.96, "end": 2188.1600000000003, "text": " that work. The least you can do is tell them about it. That's actually great now to end this talk.", "tokens": [50892, 300, 589, 13, 440, 1935, 291, 393, 360, 307, 980, 552, 466, 309, 13, 663, 311, 767, 869, 586, 281, 917, 341, 751, 13, 51352], "temperature": 0.0, "avg_logprob": -0.22504767965763173, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.006964887026697397}, {"id": 343, "seek": 216840, "start": 2188.1600000000003, "end": 2191.92, "text": " If there's no more questions from the audience, and I think we've covered those.", "tokens": [51352, 759, 456, 311, 572, 544, 1651, 490, 264, 4034, 11, 293, 286, 519, 321, 600, 5343, 729, 13, 51540], "temperature": 0.0, "avg_logprob": -0.22504767965763173, "compression_ratio": 1.5847457627118644, "no_speech_prob": 0.006964887026697397}, {"id": 344, "seek": 219192, "start": 2191.92, "end": 2204.56, "text": " Yeah, and then I think we'll leave it here. It was super nice talking to you, and super nice to", "tokens": [50364, 865, 11, 293, 550, 286, 519, 321, 603, 1856, 309, 510, 13, 467, 390, 1687, 1481, 1417, 281, 291, 11, 293, 1687, 1481, 281, 50996], "temperature": 0.0, "avg_logprob": -0.23919289286543682, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.02725754678249359}, {"id": 345, "seek": 219192, "start": 2204.56, "end": 2211.6, "text": " listen to your short presentation. And I hope that you will also enjoy the rest of the conference", "tokens": [50996, 2140, 281, 428, 2099, 5860, 13, 400, 286, 1454, 300, 291, 486, 611, 2103, 264, 1472, 295, 264, 7586, 51348], "temperature": 0.0, "avg_logprob": -0.23919289286543682, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.02725754678249359}, {"id": 346, "seek": 219192, "start": 2211.6, "end": 2216.2400000000002, "text": " maybe tomorrow, and that will definitely be in touch and to cooperate more on this", "tokens": [51348, 1310, 4153, 11, 293, 300, 486, 2138, 312, 294, 2557, 293, 281, 26667, 544, 322, 341, 51580], "temperature": 0.0, "avg_logprob": -0.23919289286543682, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.02725754678249359}, {"id": 347, "seek": 219192, "start": 2217.12, "end": 2219.84, "text": " quite hairy problem, but still very interesting one to think about.", "tokens": [51624, 1596, 42346, 1154, 11, 457, 920, 588, 1880, 472, 281, 519, 466, 13, 51760], "temperature": 0.0, "avg_logprob": -0.23919289286543682, "compression_ratio": 1.5852534562211982, "no_speech_prob": 0.02725754678249359}, {"id": 348, "seek": 221984, "start": 2219.84, "end": 2224.08, "text": " Absolutely, and hopefully we'll meet in person one day. Likewise.", "tokens": [50392, 7021, 11, 293, 4696, 321, 603, 1677, 294, 954, 472, 786, 13, 30269, 13, 50576], "temperature": 0.0, "avg_logprob": -0.3443620906156652, "compression_ratio": 0.9285714285714286, "no_speech_prob": 0.016859233379364014}], "language": "en"}