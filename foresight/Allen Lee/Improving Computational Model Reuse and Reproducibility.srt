1
00:00:00,000 --> 00:00:05,200
Hi there. My name is Alan Lee. I'm a computer scientist and software engineer at the Center

2
00:00:05,200 --> 00:00:10,400
for Behavioral Institutions and the Environment at ASU, and I currently lead cyber infrastructure

3
00:00:10,400 --> 00:00:15,520
development at ComSysNet. I'd like to share some good enough practices that you can use

4
00:00:15,520 --> 00:00:20,960
to improve the reusability and reproducibility of the software you develop to address your

5
00:00:20,960 --> 00:00:25,720
particular research questions. The title of this presentation is a reference to a great

6
00:00:25,720 --> 00:00:30,840
paper by Greg Wilson et al. in the software and data carpentry organizations, first published in

7
00:00:30,840 --> 00:00:37,080
2016 and recently revised here in 2017. I'll include links to relevant articles and web

8
00:00:37,080 --> 00:00:41,800
resources at the end of this presentation. If you have any questions, corrections or comments,

9
00:00:41,800 --> 00:00:46,680
please don't hesitate to reach out to me either via this conference website or email. I'd love to

10
00:00:46,680 --> 00:00:53,240
hear your thoughts. So let's begin. There's been a lot of talk in the hub of recently on

11
00:00:53,240 --> 00:00:58,680
reproducibility and the reproducibility crisis with a particular emphasis on biomedicine,

12
00:00:58,680 --> 00:01:04,360
psychology, and the social sciences. Without really considering the theoretical and methodological

13
00:01:04,360 --> 00:01:09,000
quantities of reproducibility in these disciplines, we can at least make sure that the computational

14
00:01:09,000 --> 00:01:14,680
artifacts that we develop to explore or analyze a given research question are developed, documented,

15
00:01:14,680 --> 00:01:19,880
and archived in ways that help others, including your future self, your colleagues, and graduate

16
00:01:19,880 --> 00:01:25,880
students to more easily evaluate, reuse, and replicate your work. But first we should probably

17
00:01:25,880 --> 00:01:31,400
clarify what we mean exactly when we say reproducibility. Goodman, Finnelli, and Ioanitis did a great

18
00:01:31,400 --> 00:01:37,880
job of this in 2016, discussing aspects of reproducibility and different scientific research

19
00:01:37,880 --> 00:01:43,320
disciplines with a focus on biomedicine, but they distinguished between methods reproducibility,

20
00:01:43,320 --> 00:01:48,280
results reproducibility, and inferential reproducibility. To use a common cooking metaphor,

21
00:01:48,360 --> 00:01:53,400
methods reproducibility is listing all the steps needed to bake a cake, results reproducibility

22
00:01:53,400 --> 00:01:58,600
is like the same cake that you did when I followed those steps, and inferential reproducibility,

23
00:01:59,320 --> 00:02:04,600
they claim as the most important and refers to drawing quantitatively similar conclusions

24
00:02:04,600 --> 00:02:11,160
from an independent replication or reanalysis of the original study. And this presentation will

25
00:02:11,160 --> 00:02:15,880
be primarily focusing on methods reproducibility, but it's important to keep results and inferential

26
00:02:15,880 --> 00:02:21,320
reproducibility in mind as well. Of course, our ultimate goal is reuse, can we build on each other's

27
00:02:21,320 --> 00:02:29,320
work? There have been a number of well-reasoned arguments for making the scientific source code

28
00:02:29,320 --> 00:02:34,360
open and transparent in recent years, so I won't go into these in much detail, but as a computer

29
00:02:34,360 --> 00:02:39,880
scientist and software engineer, I would find it very difficult to properly evaluate any non-trivial

30
00:02:39,880 --> 00:02:45,560
results coming from a set of complex computations without access to the source code. Narrative,

31
00:02:45,640 --> 00:02:51,320
or algorithmic descriptions, UML, data flow diagrams, pseudocode, these all helped greatly

32
00:02:51,320 --> 00:02:57,880
in describing what a piece of code is supposed to do, but the source code, its runtime parameterizations,

33
00:02:57,880 --> 00:03:05,160
initial random seeds, etc., these are all critical for evaluating the software. At CompSysNet,

34
00:03:05,160 --> 00:03:09,960
we're committed to making the source code broadly and usefully accessible and available to others.

35
00:03:09,960 --> 00:03:17,240
We want to move beyond simple static archives or code dumps. We want to release your code base

36
00:03:17,240 --> 00:03:22,040
as open source is a great first step, but we can do a lot better than that. To find out how,

37
00:03:22,040 --> 00:03:27,240
let's begin with a quick overview of the FAIR principles for data management, because after

38
00:03:27,240 --> 00:03:31,640
all code is data that just happened to be interpreted by your computer as executable

39
00:03:31,640 --> 00:03:37,960
instructions. The FAIR principles were developed first in 2014 and eventually were published

40
00:03:38,760 --> 00:03:45,240
in 2016 by a working group out of Force 11, an organization focused on

41
00:03:45,800 --> 00:03:53,400
e-scholarship and dissemination communications. The FAIR guiding principles advocate for digital

42
00:03:53,400 --> 00:04:00,040
artifacts and data to be findable, accessible, interoperable, and reusable. In order to be

43
00:04:00,040 --> 00:04:05,560
findable, your code should have a globally unique and eternally persistent identifier.

44
00:04:06,280 --> 00:04:11,400
In practice, this means a permanent URL where someone can visit and find a landing page

45
00:04:12,040 --> 00:04:17,240
with rich descriptive metadata about your computational model, its uses, and so on.

46
00:04:18,520 --> 00:04:24,040
Furthermore, this URL should identify a specific version or release of your software.

47
00:04:24,920 --> 00:04:29,080
When you cite your own computational model or someone else's computational model in the

48
00:04:29,080 --> 00:04:34,440
publication, you should be citing the exact version of the software used to derive your results,

49
00:04:34,440 --> 00:04:38,760
and that should take you to that snapshot, a snapshot of that code base at that time that

50
00:04:38,760 --> 00:04:45,720
shows exactly the state of the code base at the time that you used it. This snapshot could also

51
00:04:45,720 --> 00:04:51,240
include data analysis scripts used to explore the model outputs or generate visualization or figures,

52
00:04:52,360 --> 00:04:56,280
as well as other plaintext and descriptive metadata.

53
00:04:57,240 --> 00:05:03,400
Accessibility is primarily a cyber infrastructure or platform concern, which is to say, it's our

54
00:05:03,400 --> 00:05:09,080
problem at CompSysNet if you're trying to build a trusted repository for your software. It has more

55
00:05:09,080 --> 00:05:14,520
to do with open protocols to access your metadata and code base that allow for authentication,

56
00:05:14,520 --> 00:05:19,000
authorization, and so on. There is one important point to make, which is that the descriptive

57
00:05:19,000 --> 00:05:23,400
metadata about your computational model should be available even when the underlying data or

58
00:05:24,040 --> 00:05:30,760
code is not available due to licensing restrictions or an embargo. That just means that you should

59
00:05:30,760 --> 00:05:36,680
be aware of what's out there and should be aware that this thing exists and have the options for

60
00:05:36,680 --> 00:05:45,480
contacting authors and getting more information about it. Interoperability in this situation

61
00:05:45,480 --> 00:05:51,560
refers to interoperability of metadata, namely that we use standardized vocabularies for the

62
00:05:51,560 --> 00:05:56,840
descriptive metadata about your computational model. CompSysNet is also collaborating with

63
00:05:56,840 --> 00:06:02,200
CSDMS, the Community Surface Dynamics Modeling System Group at Boulder, as well as other research

64
00:06:02,200 --> 00:06:09,160
groups to establish standardized names for the various inputs, outputs, and process variables

65
00:06:09,160 --> 00:06:14,920
and computational models. CSDMS already has a set of standardized names for their computational

66
00:06:14,920 --> 00:06:20,760
earth systems models and we're actively exploring together ways to connect models as

67
00:06:20,760 --> 00:06:25,560
pluggable components so that an earth systems model can be connected with a behavioral model

68
00:06:26,120 --> 00:06:30,760
and mapping their inputs and outputs onto standardized ontologies of variable types.

69
00:06:30,760 --> 00:06:35,000
This is an active area of research, so if you're interested in this endeavor, please feel free

70
00:06:35,960 --> 00:06:37,400
to contact me directly.

71
00:06:42,200 --> 00:06:49,080
One critical piece of reusability is licensing. A clear usage license is

72
00:06:49,080 --> 00:06:54,360
necessary for anyone to reuse your software. The software carpentry groups recommend permissive

73
00:06:54,360 --> 00:07:01,000
open source licenses like the MIT or Apache license. This facilitates maximum reuse. It imposes

74
00:07:01,000 --> 00:07:06,040
very little restrictions besides attribution. If you have concerns about commercial applications

75
00:07:06,040 --> 00:07:09,320
or contributions back to your code base, you might consider the GPL as well.

76
00:07:10,440 --> 00:07:15,080
Good documentation from multiple vantage points of abstraction is also critical to reuse.

77
00:07:15,640 --> 00:07:19,640
The documentation should include steps on how to run your code,

78
00:07:20,200 --> 00:07:27,400
important inputs, and the internal processes outputs. The ODD protocol is a semi-controversial

79
00:07:27,400 --> 00:07:33,880
standard in the computational modeling community, but it's a great starting point.

80
00:07:34,680 --> 00:07:40,200
You have to also make sure you include your dependencies. What software or system or data

81
00:07:40,200 --> 00:07:47,800
dependencies does your model have? Also, bonus points for test suites that run your and exercise

82
00:07:47,800 --> 00:07:55,080
your computational models and assure and give us confidence that the internal processes within

83
00:07:55,080 --> 00:08:01,160
your model are working correctly. Consistent also offers a peer review process for computational

84
00:08:01,160 --> 00:08:06,680
models. We ask independent reviewers to verify that a computational model submitted to our

85
00:08:06,680 --> 00:08:12,440
model library has well-formatted and commented code is fully documented with the ODD protocol

86
00:08:12,440 --> 00:08:18,040
or an equivalent narrative documentation and working instructions for compiling and executing

87
00:08:18,040 --> 00:08:27,000
the computational model. There's a few more key software engineering practices that can

88
00:08:27,000 --> 00:08:35,160
help us arrive at readable, reusable, and testable code. We can write meaningful variable names and

89
00:08:35,160 --> 00:08:41,800
files as always an important aspect. Keeping your code modular and well-encapsulated by breaking

90
00:08:41,880 --> 00:08:47,240
problems down into smaller pieces and short cogent functions is also extremely useful.

91
00:08:47,880 --> 00:08:52,920
Adding explanatory comments at the start of every module and function in the system that

92
00:08:52,920 --> 00:08:59,240
describe its inputs and expected outputs is also incredibly useful. If you find yourself duplicating

93
00:08:59,240 --> 00:09:05,960
code, try to replace that duplication with a parameterized function. In general, just marking

94
00:09:05,960 --> 00:09:10,760
the entry point into your application and walking through the sample code pass is a very

95
00:09:11,400 --> 00:09:15,880
useful exercise and this is something that the ODD protocol addresses as well.

96
00:09:17,240 --> 00:09:24,280
Version control is another extremely important piece of this puzzle. We'll go into two different

97
00:09:24,280 --> 00:09:32,440
methods for this in the coming slides. And for larger projects, an automated build system

98
00:09:32,440 --> 00:09:39,240
with tests and continuous integration is extremely helpful. A continuous integration

99
00:09:39,240 --> 00:09:45,320
system is one that automatically runs on every change to the code base and tries to compile

100
00:09:45,320 --> 00:09:51,480
and run tests against a clean installation of the code base. It's a great way to keep your

101
00:09:51,480 --> 00:09:57,000
software honest and there's several third-party services that offer this, including TravisCI,

102
00:09:57,000 --> 00:10:02,440
drone.io or Jenkins and we can talk more about this on the conference website if you're interested.

103
00:10:04,600 --> 00:10:09,960
The first approach to version control is manual one. This is one advocated by the

104
00:10:11,480 --> 00:10:16,200
the Good Enough Practices paper by Wilson et al that I referenced earlier. You don't need any

105
00:10:16,200 --> 00:10:23,000
new tools. You just need to be systematic. You can keep your changelodge.txt file dated and organized

106
00:10:23,000 --> 00:10:26,600
and you'll copy your entire project folder on every significant change.

107
00:10:32,680 --> 00:10:39,720
More sophisticated ways to use an actual version control system like Git or Mercurial or SVN.

108
00:10:40,680 --> 00:10:49,000
All of these are great version control systems. If you pick one, you won't go wrong.

109
00:10:49,720 --> 00:10:53,560
This will have a huge payoff down the road as it gives you the confidence to experiment with your

110
00:10:53,560 --> 00:10:57,960
software knowing that you can always revert back to a previous state. It also gives you the ability

111
00:10:57,960 --> 00:11:05,800
to associate meaningful log messages with changes in your code base and to also associate tags and

112
00:11:05,800 --> 00:11:11,400
releases with your code base that help keep track of important milestones. This is critical for

113
00:11:12,360 --> 00:11:20,280
actually citing the specific version of your software. With the model library at CompSysNet,

114
00:11:20,280 --> 00:11:26,120
we also offer the ability to capture snapshots but we want to have tight integration with Git as

115
00:11:26,120 --> 00:11:34,120
well. We'll have more on that later. When you do use a version control system, there are a few

116
00:11:34,120 --> 00:11:39,240
good practices to keep in mind. You should do your best to keep your changes small and isolated.

117
00:11:39,320 --> 00:11:45,240
If you modify every single file in your code base and push that as a commit, it's harder to see

118
00:11:45,240 --> 00:11:50,440
what's going on. Keeping your changes small and isolated, committing early and committing often

119
00:11:50,440 --> 00:11:58,360
helps you be exercised disciplined version control. That way, you can easily see the changes that

120
00:11:58,360 --> 00:12:04,200
were made to the code and tie that in with semantic and descriptive log messages that

121
00:12:04,200 --> 00:12:07,240
describe and document the intent of those changes.

122
00:12:13,640 --> 00:12:19,240
It can also be very helpful to adopt a standardized directory layout. Here's a simple example where

123
00:12:19,240 --> 00:12:24,120
we organize our source code, documents, input data, and output data in different directories

124
00:12:24,120 --> 00:12:29,960
alongside plain text files that describe how our software should be cited. There's also a readme

125
00:12:29,960 --> 00:12:33,000
that describes what the code does and an explicit license file.

126
00:12:39,240 --> 00:12:44,680
Archiving data that your computational models depend on is also critical. You should always

127
00:12:44,680 --> 00:12:49,800
save your data in its raw form, whether it be from a server or instrument, and never overwrite

128
00:12:49,800 --> 00:12:53,880
raw data with its intermediate forms, any sort of processing that you perform on it.

129
00:12:54,440 --> 00:12:58,360
If your data sets are extremely large, you'll have to find some way to generate permanent

130
00:12:58,360 --> 00:13:07,000
URLs for those data sets. You can do this at OSF or FigShare. Otherwise, you can certainly

131
00:13:07,000 --> 00:13:11,320
include them inline in your code base, as we had in that previous file system layout.

132
00:13:14,440 --> 00:13:18,760
Input data that your software depends on should almost certainly be citably archived as well.

133
00:13:20,120 --> 00:13:27,320
When we talk about durable formats, it's okay to have Excel sheets while you're working with your

134
00:13:27,320 --> 00:13:33,480
data, but when you archive your data, it should be archived in a durable format. It should be plain

135
00:13:33,480 --> 00:13:40,840
text, it should be CSV. This allows machines to read them more usefully 20 years from now. Who knows

136
00:13:40,840 --> 00:13:45,160
if the version of Excel that you use to save your file will still be readable, but a plain text file

137
00:13:45,160 --> 00:13:52,520
will still be readable. If you manipulated your data manually, you should document what you did

138
00:13:52,520 --> 00:13:57,080
in the data changelog that records the changes you made, their intent, and also preserves the

139
00:13:57,080 --> 00:14:03,240
before and after. Ideally, though, you should be scripting your data processing instead of hand

140
00:14:03,240 --> 00:14:09,400
munging Excel sheets. This allows others to run your data analysis pipeline from the command line,

141
00:14:09,400 --> 00:14:14,760
it allows continuous integration to work, and it also just enables people to generate the same

142
00:14:14,760 --> 00:14:28,680
outputs you published with minimal effort. Analysis-friendly data is another topic that

143
00:14:28,680 --> 00:14:36,280
Wilson and I all discuss. They describe two fundamental principles that I think are extremely

144
00:14:36,280 --> 00:14:41,400
useful. The first one is to make each column a variable. Putting multiple variables into a

145
00:14:41,400 --> 00:14:47,400
single column makes programmatic analysis a lot messier, just like storing units in a variable.

146
00:14:49,880 --> 00:14:58,760
Instead of storing 3.7kg, you might instead name the units in your metadata instead.

147
00:14:59,720 --> 00:15:05,080
You should also make each row an observation. This is the second principle. You might have one row

148
00:15:05,080 --> 00:15:11,080
representing an observation at a field site with many columns. Each column is a time point measurement,

149
00:15:11,720 --> 00:15:18,600
until the end of data collection. This is usually done to facilitate data entry, but it's much easier

150
00:15:18,600 --> 00:15:24,520
to programmatically analyze when you convert time into a variable itself, so that the year, for

151
00:15:24,520 --> 00:15:32,040
instance, in this case, is a column. You should also make sure that any dependencies that your

152
00:15:32,040 --> 00:15:38,120
code has are clearly documented. Anytime you have to make a change to your local system to run your

153
00:15:38,120 --> 00:15:43,720
code, you should be recording what that change was. An easy way to actually keep yourself honest

154
00:15:43,720 --> 00:15:50,280
here is to occasionally spin up a fresh virtual machine using VirtualBox or VMware or any other

155
00:15:50,280 --> 00:15:56,280
free virtual machine tools, and try and install and run your computational model on that fresh

156
00:15:56,280 --> 00:16:01,320
virtual machine. This almost guarantees that any additional system libraries, third-party

157
00:16:01,320 --> 00:16:06,280
libraries, or data dependencies that need to be set up or installed will come to light as you try

158
00:16:06,280 --> 00:16:11,800
and build and run your computational model. It is time-consuming, however. Docker is another

159
00:16:11,800 --> 00:16:17,880
promising technology that we at CompSetsNet are using internally and experimenting with as a provided

160
00:16:17,880 --> 00:16:23,720
or curated service for model authors. Docker offers the reproducibility of a virtual machine but in

161
00:16:23,720 --> 00:16:28,600
a much more lightweight format. It doesn't carry all the baggage of a virtual machine. A common

162
00:16:28,600 --> 00:16:33,240
metaphor used to distinguish between Docker containers and virtual machines is if you think

163
00:16:33,240 --> 00:16:38,360
of a virtual machine as a house with its own plumbing, Docker is like an apartment that's a

164
00:16:38,920 --> 00:16:44,200
member of a large apartment complex that shares this plumbing and other infrastructure with the

165
00:16:44,200 --> 00:16:51,880
other apartments. Writing a Docker file is kind of like creating a recipe or playbook that declares

166
00:16:51,880 --> 00:16:56,920
all of your application's system and software dependencies and how they should be wired together

167
00:16:56,920 --> 00:17:02,760
for a successfully running application. We don't have time to go into Docker in depth in this

168
00:17:02,760 --> 00:17:14,520
presentation. I'd be happy to discuss further offline. To recap, always make sure you budget the

169
00:17:14,520 --> 00:17:19,880
time needed to properly describe your computational artifacts, ideally in machine-readable ways and

170
00:17:19,880 --> 00:17:26,440
automated. Just like gardening or cleaning, continuous and incremental work with forethought

171
00:17:26,440 --> 00:17:30,680
and planning is much easier to manage than leaving everything to the end and trying to

172
00:17:30,680 --> 00:17:35,800
tie all the loose ends. Automating your computational pipelines as much as you can and

173
00:17:35,800 --> 00:17:41,240
whatever changes you can automate, well those should just be clearly described and documented.

174
00:17:41,240 --> 00:17:47,000
Lorena Barba is very adamant about automation but I think to start with just being explicit

175
00:17:47,000 --> 00:17:53,800
and documenting what you've done is a good enough first step. Good code-based management practices

176
00:17:53,800 --> 00:17:58,520
and archiving your computational models in ways that facilitate reproducibility and reuse is

177
00:17:59,080 --> 00:18:03,960
not really the goal in and of itself but it's a critical step for those of us that use computation

178
00:18:03,960 --> 00:18:08,360
as virtual laboratories. It helps us to better evaluate and build on each other's work

179
00:18:09,640 --> 00:18:14,200
and it's just the right thing to do if we want to be able to move forward as a discipline.

180
00:18:14,200 --> 00:18:21,320
I hope this presentation has been useful and thanks for your time.

