start	end	text
0	5200	Hi there. My name is Alan Lee. I'm a computer scientist and software engineer at the Center
5200	10400	for Behavioral Institutions and the Environment at ASU, and I currently lead cyber infrastructure
10400	15520	development at ComSysNet. I'd like to share some good enough practices that you can use
15520	20960	to improve the reusability and reproducibility of the software you develop to address your
20960	25720	particular research questions. The title of this presentation is a reference to a great
25720	30840	paper by Greg Wilson et al. in the software and data carpentry organizations, first published in
30840	37080	2016 and recently revised here in 2017. I'll include links to relevant articles and web
37080	41800	resources at the end of this presentation. If you have any questions, corrections or comments,
41800	46680	please don't hesitate to reach out to me either via this conference website or email. I'd love to
46680	53240	hear your thoughts. So let's begin. There's been a lot of talk in the hub of recently on
53240	58680	reproducibility and the reproducibility crisis with a particular emphasis on biomedicine,
58680	64360	psychology, and the social sciences. Without really considering the theoretical and methodological
64360	69000	quantities of reproducibility in these disciplines, we can at least make sure that the computational
69000	74680	artifacts that we develop to explore or analyze a given research question are developed, documented,
74680	79880	and archived in ways that help others, including your future self, your colleagues, and graduate
79880	85880	students to more easily evaluate, reuse, and replicate your work. But first we should probably
85880	91400	clarify what we mean exactly when we say reproducibility. Goodman, Finnelli, and Ioanitis did a great
91400	97880	job of this in 2016, discussing aspects of reproducibility and different scientific research
97880	103320	disciplines with a focus on biomedicine, but they distinguished between methods reproducibility,
103320	108280	results reproducibility, and inferential reproducibility. To use a common cooking metaphor,
108360	113400	methods reproducibility is listing all the steps needed to bake a cake, results reproducibility
113400	118600	is like the same cake that you did when I followed those steps, and inferential reproducibility,
119320	124600	they claim as the most important and refers to drawing quantitatively similar conclusions
124600	131160	from an independent replication or reanalysis of the original study. And this presentation will
131160	135880	be primarily focusing on methods reproducibility, but it's important to keep results and inferential
135880	141320	reproducibility in mind as well. Of course, our ultimate goal is reuse, can we build on each other's
141320	149320	work? There have been a number of well-reasoned arguments for making the scientific source code
149320	154360	open and transparent in recent years, so I won't go into these in much detail, but as a computer
154360	159880	scientist and software engineer, I would find it very difficult to properly evaluate any non-trivial
159880	165560	results coming from a set of complex computations without access to the source code. Narrative,
165640	171320	or algorithmic descriptions, UML, data flow diagrams, pseudocode, these all helped greatly
171320	177880	in describing what a piece of code is supposed to do, but the source code, its runtime parameterizations,
177880	185160	initial random seeds, etc., these are all critical for evaluating the software. At CompSysNet,
185160	189960	we're committed to making the source code broadly and usefully accessible and available to others.
189960	197240	We want to move beyond simple static archives or code dumps. We want to release your code base
197240	202040	as open source is a great first step, but we can do a lot better than that. To find out how,
202040	207240	let's begin with a quick overview of the FAIR principles for data management, because after
207240	211640	all code is data that just happened to be interpreted by your computer as executable
211640	217960	instructions. The FAIR principles were developed first in 2014 and eventually were published
218760	225240	in 2016 by a working group out of Force 11, an organization focused on
225800	233400	e-scholarship and dissemination communications. The FAIR guiding principles advocate for digital
233400	240040	artifacts and data to be findable, accessible, interoperable, and reusable. In order to be
240040	245560	findable, your code should have a globally unique and eternally persistent identifier.
246280	251400	In practice, this means a permanent URL where someone can visit and find a landing page
252040	257240	with rich descriptive metadata about your computational model, its uses, and so on.
258520	264040	Furthermore, this URL should identify a specific version or release of your software.
264920	269080	When you cite your own computational model or someone else's computational model in the
269080	274440	publication, you should be citing the exact version of the software used to derive your results,
274440	278760	and that should take you to that snapshot, a snapshot of that code base at that time that
278760	285720	shows exactly the state of the code base at the time that you used it. This snapshot could also
285720	291240	include data analysis scripts used to explore the model outputs or generate visualization or figures,
292360	296280	as well as other plaintext and descriptive metadata.
297240	303400	Accessibility is primarily a cyber infrastructure or platform concern, which is to say, it's our
303400	309080	problem at CompSysNet if you're trying to build a trusted repository for your software. It has more
309080	314520	to do with open protocols to access your metadata and code base that allow for authentication,
314520	319000	authorization, and so on. There is one important point to make, which is that the descriptive
319000	323400	metadata about your computational model should be available even when the underlying data or
324040	330760	code is not available due to licensing restrictions or an embargo. That just means that you should
330760	336680	be aware of what's out there and should be aware that this thing exists and have the options for
336680	345480	contacting authors and getting more information about it. Interoperability in this situation
345480	351560	refers to interoperability of metadata, namely that we use standardized vocabularies for the
351560	356840	descriptive metadata about your computational model. CompSysNet is also collaborating with
356840	362200	CSDMS, the Community Surface Dynamics Modeling System Group at Boulder, as well as other research
362200	369160	groups to establish standardized names for the various inputs, outputs, and process variables
369160	374920	and computational models. CSDMS already has a set of standardized names for their computational
374920	380760	earth systems models and we're actively exploring together ways to connect models as
380760	385560	pluggable components so that an earth systems model can be connected with a behavioral model
386120	390760	and mapping their inputs and outputs onto standardized ontologies of variable types.
390760	395000	This is an active area of research, so if you're interested in this endeavor, please feel free
395960	397400	to contact me directly.
402200	409080	One critical piece of reusability is licensing. A clear usage license is
409080	414360	necessary for anyone to reuse your software. The software carpentry groups recommend permissive
414360	421000	open source licenses like the MIT or Apache license. This facilitates maximum reuse. It imposes
421000	426040	very little restrictions besides attribution. If you have concerns about commercial applications
426040	429320	or contributions back to your code base, you might consider the GPL as well.
430440	435080	Good documentation from multiple vantage points of abstraction is also critical to reuse.
435640	439640	The documentation should include steps on how to run your code,
440200	447400	important inputs, and the internal processes outputs. The ODD protocol is a semi-controversial
447400	453880	standard in the computational modeling community, but it's a great starting point.
454680	460200	You have to also make sure you include your dependencies. What software or system or data
460200	467800	dependencies does your model have? Also, bonus points for test suites that run your and exercise
467800	475080	your computational models and assure and give us confidence that the internal processes within
475080	481160	your model are working correctly. Consistent also offers a peer review process for computational
481160	486680	models. We ask independent reviewers to verify that a computational model submitted to our
486680	492440	model library has well-formatted and commented code is fully documented with the ODD protocol
492440	498040	or an equivalent narrative documentation and working instructions for compiling and executing
498040	507000	the computational model. There's a few more key software engineering practices that can
507000	515160	help us arrive at readable, reusable, and testable code. We can write meaningful variable names and
515160	521800	files as always an important aspect. Keeping your code modular and well-encapsulated by breaking
521880	527240	problems down into smaller pieces and short cogent functions is also extremely useful.
527880	532920	Adding explanatory comments at the start of every module and function in the system that
532920	539240	describe its inputs and expected outputs is also incredibly useful. If you find yourself duplicating
539240	545960	code, try to replace that duplication with a parameterized function. In general, just marking
545960	550760	the entry point into your application and walking through the sample code pass is a very
551400	555880	useful exercise and this is something that the ODD protocol addresses as well.
557240	564280	Version control is another extremely important piece of this puzzle. We'll go into two different
564280	572440	methods for this in the coming slides. And for larger projects, an automated build system
572440	579240	with tests and continuous integration is extremely helpful. A continuous integration
579240	585320	system is one that automatically runs on every change to the code base and tries to compile
585320	591480	and run tests against a clean installation of the code base. It's a great way to keep your
591480	597000	software honest and there's several third-party services that offer this, including TravisCI,
597000	602440	drone.io or Jenkins and we can talk more about this on the conference website if you're interested.
604600	609960	The first approach to version control is manual one. This is one advocated by the
611480	616200	the Good Enough Practices paper by Wilson et al that I referenced earlier. You don't need any
616200	623000	new tools. You just need to be systematic. You can keep your changelodge.txt file dated and organized
623000	626600	and you'll copy your entire project folder on every significant change.
632680	639720	More sophisticated ways to use an actual version control system like Git or Mercurial or SVN.
640680	649000	All of these are great version control systems. If you pick one, you won't go wrong.
649720	653560	This will have a huge payoff down the road as it gives you the confidence to experiment with your
653560	657960	software knowing that you can always revert back to a previous state. It also gives you the ability
657960	665800	to associate meaningful log messages with changes in your code base and to also associate tags and
665800	671400	releases with your code base that help keep track of important milestones. This is critical for
672360	680280	actually citing the specific version of your software. With the model library at CompSysNet,
680280	686120	we also offer the ability to capture snapshots but we want to have tight integration with Git as
686120	694120	well. We'll have more on that later. When you do use a version control system, there are a few
694120	699240	good practices to keep in mind. You should do your best to keep your changes small and isolated.
699320	705240	If you modify every single file in your code base and push that as a commit, it's harder to see
705240	710440	what's going on. Keeping your changes small and isolated, committing early and committing often
710440	718360	helps you be exercised disciplined version control. That way, you can easily see the changes that
718360	724200	were made to the code and tie that in with semantic and descriptive log messages that
724200	727240	describe and document the intent of those changes.
733640	739240	It can also be very helpful to adopt a standardized directory layout. Here's a simple example where
739240	744120	we organize our source code, documents, input data, and output data in different directories
744120	749960	alongside plain text files that describe how our software should be cited. There's also a readme
749960	753000	that describes what the code does and an explicit license file.
759240	764680	Archiving data that your computational models depend on is also critical. You should always
764680	769800	save your data in its raw form, whether it be from a server or instrument, and never overwrite
769800	773880	raw data with its intermediate forms, any sort of processing that you perform on it.
774440	778360	If your data sets are extremely large, you'll have to find some way to generate permanent
778360	787000	URLs for those data sets. You can do this at OSF or FigShare. Otherwise, you can certainly
787000	791320	include them inline in your code base, as we had in that previous file system layout.
794440	798760	Input data that your software depends on should almost certainly be citably archived as well.
800120	807320	When we talk about durable formats, it's okay to have Excel sheets while you're working with your
807320	813480	data, but when you archive your data, it should be archived in a durable format. It should be plain
813480	820840	text, it should be CSV. This allows machines to read them more usefully 20 years from now. Who knows
820840	825160	if the version of Excel that you use to save your file will still be readable, but a plain text file
825160	832520	will still be readable. If you manipulated your data manually, you should document what you did
832520	837080	in the data changelog that records the changes you made, their intent, and also preserves the
837080	843240	before and after. Ideally, though, you should be scripting your data processing instead of hand
843240	849400	munging Excel sheets. This allows others to run your data analysis pipeline from the command line,
849400	854760	it allows continuous integration to work, and it also just enables people to generate the same
854760	868680	outputs you published with minimal effort. Analysis-friendly data is another topic that
868680	876280	Wilson and I all discuss. They describe two fundamental principles that I think are extremely
876280	881400	useful. The first one is to make each column a variable. Putting multiple variables into a
881400	887400	single column makes programmatic analysis a lot messier, just like storing units in a variable.
889880	898760	Instead of storing 3.7kg, you might instead name the units in your metadata instead.
899720	905080	You should also make each row an observation. This is the second principle. You might have one row
905080	911080	representing an observation at a field site with many columns. Each column is a time point measurement,
911720	918600	until the end of data collection. This is usually done to facilitate data entry, but it's much easier
918600	924520	to programmatically analyze when you convert time into a variable itself, so that the year, for
924520	932040	instance, in this case, is a column. You should also make sure that any dependencies that your
932040	938120	code has are clearly documented. Anytime you have to make a change to your local system to run your
938120	943720	code, you should be recording what that change was. An easy way to actually keep yourself honest
943720	950280	here is to occasionally spin up a fresh virtual machine using VirtualBox or VMware or any other
950280	956280	free virtual machine tools, and try and install and run your computational model on that fresh
956280	961320	virtual machine. This almost guarantees that any additional system libraries, third-party
961320	966280	libraries, or data dependencies that need to be set up or installed will come to light as you try
966280	971800	and build and run your computational model. It is time-consuming, however. Docker is another
971800	977880	promising technology that we at CompSetsNet are using internally and experimenting with as a provided
977880	983720	or curated service for model authors. Docker offers the reproducibility of a virtual machine but in
983720	988600	a much more lightweight format. It doesn't carry all the baggage of a virtual machine. A common
988600	993240	metaphor used to distinguish between Docker containers and virtual machines is if you think
993240	998360	of a virtual machine as a house with its own plumbing, Docker is like an apartment that's a
998920	1004200	member of a large apartment complex that shares this plumbing and other infrastructure with the
1004200	1011880	other apartments. Writing a Docker file is kind of like creating a recipe or playbook that declares
1011880	1016920	all of your application's system and software dependencies and how they should be wired together
1016920	1022760	for a successfully running application. We don't have time to go into Docker in depth in this
1022760	1034520	presentation. I'd be happy to discuss further offline. To recap, always make sure you budget the
1034520	1039880	time needed to properly describe your computational artifacts, ideally in machine-readable ways and
1039880	1046440	automated. Just like gardening or cleaning, continuous and incremental work with forethought
1046440	1050680	and planning is much easier to manage than leaving everything to the end and trying to
1050680	1055800	tie all the loose ends. Automating your computational pipelines as much as you can and
1055800	1061240	whatever changes you can automate, well those should just be clearly described and documented.
1061240	1067000	Lorena Barba is very adamant about automation but I think to start with just being explicit
1067000	1073800	and documenting what you've done is a good enough first step. Good code-based management practices
1073800	1078520	and archiving your computational models in ways that facilitate reproducibility and reuse is
1079080	1083960	not really the goal in and of itself but it's a critical step for those of us that use computation
1083960	1088360	as virtual laboratories. It helps us to better evaluate and build on each other's work
1089640	1094200	and it's just the right thing to do if we want to be able to move forward as a discipline.
1094200	1101320	I hope this presentation has been useful and thanks for your time.
