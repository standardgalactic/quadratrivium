{"text": " Hi there. My name is Alan Lee. I'm a computer scientist and software engineer at the Center for Behavioral Institutions and the Environment at ASU, and I currently lead cyber infrastructure development at ComSysNet. I'd like to share some good enough practices that you can use to improve the reusability and reproducibility of the software you develop to address your particular research questions. The title of this presentation is a reference to a great paper by Greg Wilson et al. in the software and data carpentry organizations, first published in 2016 and recently revised here in 2017. I'll include links to relevant articles and web resources at the end of this presentation. If you have any questions, corrections or comments, please don't hesitate to reach out to me either via this conference website or email. I'd love to hear your thoughts. So let's begin. There's been a lot of talk in the hub of recently on reproducibility and the reproducibility crisis with a particular emphasis on biomedicine, psychology, and the social sciences. Without really considering the theoretical and methodological quantities of reproducibility in these disciplines, we can at least make sure that the computational artifacts that we develop to explore or analyze a given research question are developed, documented, and archived in ways that help others, including your future self, your colleagues, and graduate students to more easily evaluate, reuse, and replicate your work. But first we should probably clarify what we mean exactly when we say reproducibility. Goodman, Finnelli, and Ioanitis did a great job of this in 2016, discussing aspects of reproducibility and different scientific research disciplines with a focus on biomedicine, but they distinguished between methods reproducibility, results reproducibility, and inferential reproducibility. To use a common cooking metaphor, methods reproducibility is listing all the steps needed to bake a cake, results reproducibility is like the same cake that you did when I followed those steps, and inferential reproducibility, they claim as the most important and refers to drawing quantitatively similar conclusions from an independent replication or reanalysis of the original study. And this presentation will be primarily focusing on methods reproducibility, but it's important to keep results and inferential reproducibility in mind as well. Of course, our ultimate goal is reuse, can we build on each other's work? There have been a number of well-reasoned arguments for making the scientific source code open and transparent in recent years, so I won't go into these in much detail, but as a computer scientist and software engineer, I would find it very difficult to properly evaluate any non-trivial results coming from a set of complex computations without access to the source code. Narrative, or algorithmic descriptions, UML, data flow diagrams, pseudocode, these all helped greatly in describing what a piece of code is supposed to do, but the source code, its runtime parameterizations, initial random seeds, etc., these are all critical for evaluating the software. At CompSysNet, we're committed to making the source code broadly and usefully accessible and available to others. We want to move beyond simple static archives or code dumps. We want to release your code base as open source is a great first step, but we can do a lot better than that. To find out how, let's begin with a quick overview of the FAIR principles for data management, because after all code is data that just happened to be interpreted by your computer as executable instructions. The FAIR principles were developed first in 2014 and eventually were published in 2016 by a working group out of Force 11, an organization focused on e-scholarship and dissemination communications. The FAIR guiding principles advocate for digital artifacts and data to be findable, accessible, interoperable, and reusable. In order to be findable, your code should have a globally unique and eternally persistent identifier. In practice, this means a permanent URL where someone can visit and find a landing page with rich descriptive metadata about your computational model, its uses, and so on. Furthermore, this URL should identify a specific version or release of your software. When you cite your own computational model or someone else's computational model in the publication, you should be citing the exact version of the software used to derive your results, and that should take you to that snapshot, a snapshot of that code base at that time that shows exactly the state of the code base at the time that you used it. This snapshot could also include data analysis scripts used to explore the model outputs or generate visualization or figures, as well as other plaintext and descriptive metadata. Accessibility is primarily a cyber infrastructure or platform concern, which is to say, it's our problem at CompSysNet if you're trying to build a trusted repository for your software. It has more to do with open protocols to access your metadata and code base that allow for authentication, authorization, and so on. There is one important point to make, which is that the descriptive metadata about your computational model should be available even when the underlying data or code is not available due to licensing restrictions or an embargo. That just means that you should be aware of what's out there and should be aware that this thing exists and have the options for contacting authors and getting more information about it. Interoperability in this situation refers to interoperability of metadata, namely that we use standardized vocabularies for the descriptive metadata about your computational model. CompSysNet is also collaborating with CSDMS, the Community Surface Dynamics Modeling System Group at Boulder, as well as other research groups to establish standardized names for the various inputs, outputs, and process variables and computational models. CSDMS already has a set of standardized names for their computational earth systems models and we're actively exploring together ways to connect models as pluggable components so that an earth systems model can be connected with a behavioral model and mapping their inputs and outputs onto standardized ontologies of variable types. This is an active area of research, so if you're interested in this endeavor, please feel free to contact me directly. One critical piece of reusability is licensing. A clear usage license is necessary for anyone to reuse your software. The software carpentry groups recommend permissive open source licenses like the MIT or Apache license. This facilitates maximum reuse. It imposes very little restrictions besides attribution. If you have concerns about commercial applications or contributions back to your code base, you might consider the GPL as well. Good documentation from multiple vantage points of abstraction is also critical to reuse. The documentation should include steps on how to run your code, important inputs, and the internal processes outputs. The ODD protocol is a semi-controversial standard in the computational modeling community, but it's a great starting point. You have to also make sure you include your dependencies. What software or system or data dependencies does your model have? Also, bonus points for test suites that run your and exercise your computational models and assure and give us confidence that the internal processes within your model are working correctly. Consistent also offers a peer review process for computational models. We ask independent reviewers to verify that a computational model submitted to our model library has well-formatted and commented code is fully documented with the ODD protocol or an equivalent narrative documentation and working instructions for compiling and executing the computational model. There's a few more key software engineering practices that can help us arrive at readable, reusable, and testable code. We can write meaningful variable names and files as always an important aspect. Keeping your code modular and well-encapsulated by breaking problems down into smaller pieces and short cogent functions is also extremely useful. Adding explanatory comments at the start of every module and function in the system that describe its inputs and expected outputs is also incredibly useful. If you find yourself duplicating code, try to replace that duplication with a parameterized function. In general, just marking the entry point into your application and walking through the sample code pass is a very useful exercise and this is something that the ODD protocol addresses as well. Version control is another extremely important piece of this puzzle. We'll go into two different methods for this in the coming slides. And for larger projects, an automated build system with tests and continuous integration is extremely helpful. A continuous integration system is one that automatically runs on every change to the code base and tries to compile and run tests against a clean installation of the code base. It's a great way to keep your software honest and there's several third-party services that offer this, including TravisCI, drone.io or Jenkins and we can talk more about this on the conference website if you're interested. The first approach to version control is manual one. This is one advocated by the the Good Enough Practices paper by Wilson et al that I referenced earlier. You don't need any new tools. You just need to be systematic. You can keep your changelodge.txt file dated and organized and you'll copy your entire project folder on every significant change. More sophisticated ways to use an actual version control system like Git or Mercurial or SVN. All of these are great version control systems. If you pick one, you won't go wrong. This will have a huge payoff down the road as it gives you the confidence to experiment with your software knowing that you can always revert back to a previous state. It also gives you the ability to associate meaningful log messages with changes in your code base and to also associate tags and releases with your code base that help keep track of important milestones. This is critical for actually citing the specific version of your software. With the model library at CompSysNet, we also offer the ability to capture snapshots but we want to have tight integration with Git as well. We'll have more on that later. When you do use a version control system, there are a few good practices to keep in mind. You should do your best to keep your changes small and isolated. If you modify every single file in your code base and push that as a commit, it's harder to see what's going on. Keeping your changes small and isolated, committing early and committing often helps you be exercised disciplined version control. That way, you can easily see the changes that were made to the code and tie that in with semantic and descriptive log messages that describe and document the intent of those changes. It can also be very helpful to adopt a standardized directory layout. Here's a simple example where we organize our source code, documents, input data, and output data in different directories alongside plain text files that describe how our software should be cited. There's also a readme that describes what the code does and an explicit license file. Archiving data that your computational models depend on is also critical. You should always save your data in its raw form, whether it be from a server or instrument, and never overwrite raw data with its intermediate forms, any sort of processing that you perform on it. If your data sets are extremely large, you'll have to find some way to generate permanent URLs for those data sets. You can do this at OSF or FigShare. Otherwise, you can certainly include them inline in your code base, as we had in that previous file system layout. Input data that your software depends on should almost certainly be citably archived as well. When we talk about durable formats, it's okay to have Excel sheets while you're working with your data, but when you archive your data, it should be archived in a durable format. It should be plain text, it should be CSV. This allows machines to read them more usefully 20 years from now. Who knows if the version of Excel that you use to save your file will still be readable, but a plain text file will still be readable. If you manipulated your data manually, you should document what you did in the data changelog that records the changes you made, their intent, and also preserves the before and after. Ideally, though, you should be scripting your data processing instead of hand munging Excel sheets. This allows others to run your data analysis pipeline from the command line, it allows continuous integration to work, and it also just enables people to generate the same outputs you published with minimal effort. Analysis-friendly data is another topic that Wilson and I all discuss. They describe two fundamental principles that I think are extremely useful. The first one is to make each column a variable. Putting multiple variables into a single column makes programmatic analysis a lot messier, just like storing units in a variable. Instead of storing 3.7kg, you might instead name the units in your metadata instead. You should also make each row an observation. This is the second principle. You might have one row representing an observation at a field site with many columns. Each column is a time point measurement, until the end of data collection. This is usually done to facilitate data entry, but it's much easier to programmatically analyze when you convert time into a variable itself, so that the year, for instance, in this case, is a column. You should also make sure that any dependencies that your code has are clearly documented. Anytime you have to make a change to your local system to run your code, you should be recording what that change was. An easy way to actually keep yourself honest here is to occasionally spin up a fresh virtual machine using VirtualBox or VMware or any other free virtual machine tools, and try and install and run your computational model on that fresh virtual machine. This almost guarantees that any additional system libraries, third-party libraries, or data dependencies that need to be set up or installed will come to light as you try and build and run your computational model. It is time-consuming, however. Docker is another promising technology that we at CompSetsNet are using internally and experimenting with as a provided or curated service for model authors. Docker offers the reproducibility of a virtual machine but in a much more lightweight format. It doesn't carry all the baggage of a virtual machine. A common metaphor used to distinguish between Docker containers and virtual machines is if you think of a virtual machine as a house with its own plumbing, Docker is like an apartment that's a member of a large apartment complex that shares this plumbing and other infrastructure with the other apartments. Writing a Docker file is kind of like creating a recipe or playbook that declares all of your application's system and software dependencies and how they should be wired together for a successfully running application. We don't have time to go into Docker in depth in this presentation. I'd be happy to discuss further offline. To recap, always make sure you budget the time needed to properly describe your computational artifacts, ideally in machine-readable ways and automated. Just like gardening or cleaning, continuous and incremental work with forethought and planning is much easier to manage than leaving everything to the end and trying to tie all the loose ends. Automating your computational pipelines as much as you can and whatever changes you can automate, well those should just be clearly described and documented. Lorena Barba is very adamant about automation but I think to start with just being explicit and documenting what you've done is a good enough first step. Good code-based management practices and archiving your computational models in ways that facilitate reproducibility and reuse is not really the goal in and of itself but it's a critical step for those of us that use computation as virtual laboratories. It helps us to better evaluate and build on each other's work and it's just the right thing to do if we want to be able to move forward as a discipline. I hope this presentation has been useful and thanks for your time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.2, "text": " Hi there. My name is Alan Lee. I'm a computer scientist and software engineer at the Center", "tokens": [50364, 2421, 456, 13, 1222, 1315, 307, 16442, 6957, 13, 286, 478, 257, 3820, 12662, 293, 4722, 11403, 412, 264, 5169, 50624], "temperature": 0.0, "avg_logprob": -0.1730478698132085, "compression_ratio": 1.5944055944055944, "no_speech_prob": 0.06718648225069046}, {"id": 1, "seek": 0, "start": 5.2, "end": 10.4, "text": " for Behavioral Institutions and the Environment at ASU, and I currently lead cyber infrastructure", "tokens": [50624, 337, 45807, 304, 33897, 3666, 293, 264, 35354, 412, 7469, 52, 11, 293, 286, 4362, 1477, 13411, 6896, 50884], "temperature": 0.0, "avg_logprob": -0.1730478698132085, "compression_ratio": 1.5944055944055944, "no_speech_prob": 0.06718648225069046}, {"id": 2, "seek": 0, "start": 10.4, "end": 15.52, "text": " development at ComSysNet. I'd like to share some good enough practices that you can use", "tokens": [50884, 3250, 412, 2432, 50, 749, 31890, 13, 286, 1116, 411, 281, 2073, 512, 665, 1547, 7525, 300, 291, 393, 764, 51140], "temperature": 0.0, "avg_logprob": -0.1730478698132085, "compression_ratio": 1.5944055944055944, "no_speech_prob": 0.06718648225069046}, {"id": 3, "seek": 0, "start": 15.52, "end": 20.96, "text": " to improve the reusability and reproducibility of the software you develop to address your", "tokens": [51140, 281, 3470, 264, 38860, 2310, 293, 11408, 537, 39802, 295, 264, 4722, 291, 1499, 281, 2985, 428, 51412], "temperature": 0.0, "avg_logprob": -0.1730478698132085, "compression_ratio": 1.5944055944055944, "no_speech_prob": 0.06718648225069046}, {"id": 4, "seek": 0, "start": 20.96, "end": 25.72, "text": " particular research questions. The title of this presentation is a reference to a great", "tokens": [51412, 1729, 2132, 1651, 13, 440, 4876, 295, 341, 5860, 307, 257, 6408, 281, 257, 869, 51650], "temperature": 0.0, "avg_logprob": -0.1730478698132085, "compression_ratio": 1.5944055944055944, "no_speech_prob": 0.06718648225069046}, {"id": 5, "seek": 2572, "start": 25.72, "end": 30.84, "text": " paper by Greg Wilson et al. in the software and data carpentry organizations, first published in", "tokens": [50364, 3035, 538, 11490, 15388, 1030, 419, 13, 294, 264, 4722, 293, 1412, 1032, 22786, 627, 6150, 11, 700, 6572, 294, 50620], "temperature": 0.0, "avg_logprob": -0.11083400032737038, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.07468048483133316}, {"id": 6, "seek": 2572, "start": 30.84, "end": 37.08, "text": " 2016 and recently revised here in 2017. I'll include links to relevant articles and web", "tokens": [50620, 6549, 293, 3938, 35228, 510, 294, 6591, 13, 286, 603, 4090, 6123, 281, 7340, 11290, 293, 3670, 50932], "temperature": 0.0, "avg_logprob": -0.11083400032737038, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.07468048483133316}, {"id": 7, "seek": 2572, "start": 37.08, "end": 41.8, "text": " resources at the end of this presentation. If you have any questions, corrections or comments,", "tokens": [50932, 3593, 412, 264, 917, 295, 341, 5860, 13, 759, 291, 362, 604, 1651, 11, 36406, 420, 3053, 11, 51168], "temperature": 0.0, "avg_logprob": -0.11083400032737038, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.07468048483133316}, {"id": 8, "seek": 2572, "start": 41.8, "end": 46.68, "text": " please don't hesitate to reach out to me either via this conference website or email. I'd love to", "tokens": [51168, 1767, 500, 380, 20842, 281, 2524, 484, 281, 385, 2139, 5766, 341, 7586, 3144, 420, 3796, 13, 286, 1116, 959, 281, 51412], "temperature": 0.0, "avg_logprob": -0.11083400032737038, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.07468048483133316}, {"id": 9, "seek": 2572, "start": 46.68, "end": 53.239999999999995, "text": " hear your thoughts. So let's begin. There's been a lot of talk in the hub of recently on", "tokens": [51412, 1568, 428, 4598, 13, 407, 718, 311, 1841, 13, 821, 311, 668, 257, 688, 295, 751, 294, 264, 11838, 295, 3938, 322, 51740], "temperature": 0.0, "avg_logprob": -0.11083400032737038, "compression_ratio": 1.6180555555555556, "no_speech_prob": 0.07468048483133316}, {"id": 10, "seek": 5324, "start": 53.24, "end": 58.68, "text": " reproducibility and the reproducibility crisis with a particular emphasis on biomedicine,", "tokens": [50364, 11408, 537, 39802, 293, 264, 11408, 537, 39802, 5869, 365, 257, 1729, 16271, 322, 3228, 17671, 299, 533, 11, 50636], "temperature": 0.0, "avg_logprob": -0.07239221096038818, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.023673424497246742}, {"id": 11, "seek": 5324, "start": 58.68, "end": 64.36, "text": " psychology, and the social sciences. Without really considering the theoretical and methodological", "tokens": [50636, 15105, 11, 293, 264, 2093, 17677, 13, 9129, 534, 8079, 264, 20864, 293, 3170, 4383, 50920], "temperature": 0.0, "avg_logprob": -0.07239221096038818, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.023673424497246742}, {"id": 12, "seek": 5324, "start": 64.36, "end": 69.0, "text": " quantities of reproducibility in these disciplines, we can at least make sure that the computational", "tokens": [50920, 22927, 295, 11408, 537, 39802, 294, 613, 21919, 11, 321, 393, 412, 1935, 652, 988, 300, 264, 28270, 51152], "temperature": 0.0, "avg_logprob": -0.07239221096038818, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.023673424497246742}, {"id": 13, "seek": 5324, "start": 69.0, "end": 74.68, "text": " artifacts that we develop to explore or analyze a given research question are developed, documented,", "tokens": [51152, 24617, 300, 321, 1499, 281, 6839, 420, 12477, 257, 2212, 2132, 1168, 366, 4743, 11, 23007, 11, 51436], "temperature": 0.0, "avg_logprob": -0.07239221096038818, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.023673424497246742}, {"id": 14, "seek": 5324, "start": 74.68, "end": 79.88, "text": " and archived in ways that help others, including your future self, your colleagues, and graduate", "tokens": [51436, 293, 3912, 3194, 294, 2098, 300, 854, 2357, 11, 3009, 428, 2027, 2698, 11, 428, 7734, 11, 293, 8080, 51696], "temperature": 0.0, "avg_logprob": -0.07239221096038818, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.023673424497246742}, {"id": 15, "seek": 7988, "start": 79.88, "end": 85.88, "text": " students to more easily evaluate, reuse, and replicate your work. But first we should probably", "tokens": [50364, 1731, 281, 544, 3612, 13059, 11, 26225, 11, 293, 25356, 428, 589, 13, 583, 700, 321, 820, 1391, 50664], "temperature": 0.0, "avg_logprob": -0.09727338444102894, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.010485487058758736}, {"id": 16, "seek": 7988, "start": 85.88, "end": 91.39999999999999, "text": " clarify what we mean exactly when we say reproducibility. Goodman, Finnelli, and Ioanitis did a great", "tokens": [50664, 17594, 437, 321, 914, 2293, 562, 321, 584, 11408, 537, 39802, 13, 2205, 1601, 11, 3773, 8903, 72, 11, 293, 19239, 282, 16074, 630, 257, 869, 50940], "temperature": 0.0, "avg_logprob": -0.09727338444102894, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.010485487058758736}, {"id": 17, "seek": 7988, "start": 91.39999999999999, "end": 97.88, "text": " job of this in 2016, discussing aspects of reproducibility and different scientific research", "tokens": [50940, 1691, 295, 341, 294, 6549, 11, 10850, 7270, 295, 11408, 537, 39802, 293, 819, 8134, 2132, 51264], "temperature": 0.0, "avg_logprob": -0.09727338444102894, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.010485487058758736}, {"id": 18, "seek": 7988, "start": 97.88, "end": 103.32, "text": " disciplines with a focus on biomedicine, but they distinguished between methods reproducibility,", "tokens": [51264, 21919, 365, 257, 1879, 322, 3228, 17671, 299, 533, 11, 457, 436, 21702, 1296, 7150, 11408, 537, 39802, 11, 51536], "temperature": 0.0, "avg_logprob": -0.09727338444102894, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.010485487058758736}, {"id": 19, "seek": 7988, "start": 103.32, "end": 108.28, "text": " results reproducibility, and inferential reproducibility. To use a common cooking metaphor,", "tokens": [51536, 3542, 11408, 537, 39802, 11, 293, 13596, 2549, 11408, 537, 39802, 13, 1407, 764, 257, 2689, 6361, 19157, 11, 51784], "temperature": 0.0, "avg_logprob": -0.09727338444102894, "compression_ratio": 1.701067615658363, "no_speech_prob": 0.010485487058758736}, {"id": 20, "seek": 10828, "start": 108.36, "end": 113.4, "text": " methods reproducibility is listing all the steps needed to bake a cake, results reproducibility", "tokens": [50368, 7150, 11408, 537, 39802, 307, 22161, 439, 264, 4439, 2978, 281, 16562, 257, 5908, 11, 3542, 11408, 537, 39802, 50620], "temperature": 0.0, "avg_logprob": -0.08465051651000977, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0011690763058140874}, {"id": 21, "seek": 10828, "start": 113.4, "end": 118.6, "text": " is like the same cake that you did when I followed those steps, and inferential reproducibility,", "tokens": [50620, 307, 411, 264, 912, 5908, 300, 291, 630, 562, 286, 6263, 729, 4439, 11, 293, 13596, 2549, 11408, 537, 39802, 11, 50880], "temperature": 0.0, "avg_logprob": -0.08465051651000977, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0011690763058140874}, {"id": 22, "seek": 10828, "start": 119.32000000000001, "end": 124.6, "text": " they claim as the most important and refers to drawing quantitatively similar conclusions", "tokens": [50916, 436, 3932, 382, 264, 881, 1021, 293, 14942, 281, 6316, 27778, 356, 2531, 22865, 51180], "temperature": 0.0, "avg_logprob": -0.08465051651000977, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0011690763058140874}, {"id": 23, "seek": 10828, "start": 124.6, "end": 131.16, "text": " from an independent replication or reanalysis of the original study. And this presentation will", "tokens": [51180, 490, 364, 6695, 39911, 420, 319, 29702, 4642, 295, 264, 3380, 2979, 13, 400, 341, 5860, 486, 51508], "temperature": 0.0, "avg_logprob": -0.08465051651000977, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0011690763058140874}, {"id": 24, "seek": 10828, "start": 131.16, "end": 135.88, "text": " be primarily focusing on methods reproducibility, but it's important to keep results and inferential", "tokens": [51508, 312, 10029, 8416, 322, 7150, 11408, 537, 39802, 11, 457, 309, 311, 1021, 281, 1066, 3542, 293, 13596, 2549, 51744], "temperature": 0.0, "avg_logprob": -0.08465051651000977, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0011690763058140874}, {"id": 25, "seek": 13588, "start": 135.88, "end": 141.32, "text": " reproducibility in mind as well. Of course, our ultimate goal is reuse, can we build on each other's", "tokens": [50364, 11408, 537, 39802, 294, 1575, 382, 731, 13, 2720, 1164, 11, 527, 9705, 3387, 307, 26225, 11, 393, 321, 1322, 322, 1184, 661, 311, 50636], "temperature": 0.0, "avg_logprob": -0.07016677530402811, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.001647438621148467}, {"id": 26, "seek": 13588, "start": 141.32, "end": 149.32, "text": " work? There have been a number of well-reasoned arguments for making the scientific source code", "tokens": [50636, 589, 30, 821, 362, 668, 257, 1230, 295, 731, 12, 265, 1258, 292, 12869, 337, 1455, 264, 8134, 4009, 3089, 51036], "temperature": 0.0, "avg_logprob": -0.07016677530402811, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.001647438621148467}, {"id": 27, "seek": 13588, "start": 149.32, "end": 154.35999999999999, "text": " open and transparent in recent years, so I won't go into these in much detail, but as a computer", "tokens": [51036, 1269, 293, 12737, 294, 5162, 924, 11, 370, 286, 1582, 380, 352, 666, 613, 294, 709, 2607, 11, 457, 382, 257, 3820, 51288], "temperature": 0.0, "avg_logprob": -0.07016677530402811, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.001647438621148467}, {"id": 28, "seek": 13588, "start": 154.35999999999999, "end": 159.88, "text": " scientist and software engineer, I would find it very difficult to properly evaluate any non-trivial", "tokens": [51288, 12662, 293, 4722, 11403, 11, 286, 576, 915, 309, 588, 2252, 281, 6108, 13059, 604, 2107, 12, 83, 470, 22640, 51564], "temperature": 0.0, "avg_logprob": -0.07016677530402811, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.001647438621148467}, {"id": 29, "seek": 13588, "start": 159.88, "end": 165.56, "text": " results coming from a set of complex computations without access to the source code. Narrative,", "tokens": [51564, 3542, 1348, 490, 257, 992, 295, 3997, 2807, 763, 1553, 2105, 281, 264, 4009, 3089, 13, 45658, 1166, 11, 51848], "temperature": 0.0, "avg_logprob": -0.07016677530402811, "compression_ratio": 1.6225165562913908, "no_speech_prob": 0.001647438621148467}, {"id": 30, "seek": 16556, "start": 165.64000000000001, "end": 171.32, "text": " or algorithmic descriptions, UML, data flow diagrams, pseudocode, these all helped greatly", "tokens": [50368, 420, 9284, 299, 24406, 11, 624, 12683, 11, 1412, 3095, 36709, 11, 25505, 532, 905, 1429, 11, 613, 439, 4254, 14147, 50652], "temperature": 0.0, "avg_logprob": -0.11689047191454016, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.0029790126718580723}, {"id": 31, "seek": 16556, "start": 171.32, "end": 177.88, "text": " in describing what a piece of code is supposed to do, but the source code, its runtime parameterizations,", "tokens": [50652, 294, 16141, 437, 257, 2522, 295, 3089, 307, 3442, 281, 360, 11, 457, 264, 4009, 3089, 11, 1080, 34474, 13075, 14455, 11, 50980], "temperature": 0.0, "avg_logprob": -0.11689047191454016, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.0029790126718580723}, {"id": 32, "seek": 16556, "start": 177.88, "end": 185.16, "text": " initial random seeds, etc., these are all critical for evaluating the software. At CompSysNet,", "tokens": [50980, 5883, 4974, 9203, 11, 5183, 7933, 613, 366, 439, 4924, 337, 27479, 264, 4722, 13, 1711, 6620, 50, 749, 31890, 11, 51344], "temperature": 0.0, "avg_logprob": -0.11689047191454016, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.0029790126718580723}, {"id": 33, "seek": 16556, "start": 185.16, "end": 189.96, "text": " we're committed to making the source code broadly and usefully accessible and available to others.", "tokens": [51344, 321, 434, 7784, 281, 1455, 264, 4009, 3089, 19511, 293, 764, 2277, 9515, 293, 2435, 281, 2357, 13, 51584], "temperature": 0.0, "avg_logprob": -0.11689047191454016, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.0029790126718580723}, {"id": 34, "seek": 18996, "start": 189.96, "end": 197.24, "text": " We want to move beyond simple static archives or code dumps. We want to release your code base", "tokens": [50364, 492, 528, 281, 1286, 4399, 2199, 13437, 25607, 420, 3089, 11430, 82, 13, 492, 528, 281, 4374, 428, 3089, 3096, 50728], "temperature": 0.0, "avg_logprob": -0.08756710234142485, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.043994560837745667}, {"id": 35, "seek": 18996, "start": 197.24, "end": 202.04000000000002, "text": " as open source is a great first step, but we can do a lot better than that. To find out how,", "tokens": [50728, 382, 1269, 4009, 307, 257, 869, 700, 1823, 11, 457, 321, 393, 360, 257, 688, 1101, 813, 300, 13, 1407, 915, 484, 577, 11, 50968], "temperature": 0.0, "avg_logprob": -0.08756710234142485, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.043994560837745667}, {"id": 36, "seek": 18996, "start": 202.04000000000002, "end": 207.24, "text": " let's begin with a quick overview of the FAIR principles for data management, because after", "tokens": [50968, 718, 311, 1841, 365, 257, 1702, 12492, 295, 264, 19894, 7740, 9156, 337, 1412, 4592, 11, 570, 934, 51228], "temperature": 0.0, "avg_logprob": -0.08756710234142485, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.043994560837745667}, {"id": 37, "seek": 18996, "start": 207.24, "end": 211.64000000000001, "text": " all code is data that just happened to be interpreted by your computer as executable", "tokens": [51228, 439, 3089, 307, 1412, 300, 445, 2011, 281, 312, 26749, 538, 428, 3820, 382, 7568, 712, 51448], "temperature": 0.0, "avg_logprob": -0.08756710234142485, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.043994560837745667}, {"id": 38, "seek": 18996, "start": 211.64000000000001, "end": 217.96, "text": " instructions. The FAIR principles were developed first in 2014 and eventually were published", "tokens": [51448, 9415, 13, 440, 19894, 7740, 9156, 645, 4743, 700, 294, 8227, 293, 4728, 645, 6572, 51764], "temperature": 0.0, "avg_logprob": -0.08756710234142485, "compression_ratio": 1.597902097902098, "no_speech_prob": 0.043994560837745667}, {"id": 39, "seek": 21796, "start": 218.76000000000002, "end": 225.24, "text": " in 2016 by a working group out of Force 11, an organization focused on", "tokens": [50404, 294, 6549, 538, 257, 1364, 1594, 484, 295, 10580, 2975, 11, 364, 4475, 5178, 322, 50728], "temperature": 0.0, "avg_logprob": -0.08978033065795898, "compression_ratio": 1.5065502183406114, "no_speech_prob": 0.0015478263376280665}, {"id": 40, "seek": 21796, "start": 225.8, "end": 233.4, "text": " e-scholarship and dissemination communications. The FAIR guiding principles advocate for digital", "tokens": [50756, 308, 12, 6145, 401, 685, 1210, 293, 34585, 399, 15163, 13, 440, 19894, 7740, 25061, 9156, 14608, 337, 4562, 51136], "temperature": 0.0, "avg_logprob": -0.08978033065795898, "compression_ratio": 1.5065502183406114, "no_speech_prob": 0.0015478263376280665}, {"id": 41, "seek": 21796, "start": 233.4, "end": 240.04000000000002, "text": " artifacts and data to be findable, accessible, interoperable, and reusable. In order to be", "tokens": [51136, 24617, 293, 1412, 281, 312, 915, 712, 11, 9515, 11, 728, 7192, 712, 11, 293, 41807, 13, 682, 1668, 281, 312, 51468], "temperature": 0.0, "avg_logprob": -0.08978033065795898, "compression_ratio": 1.5065502183406114, "no_speech_prob": 0.0015478263376280665}, {"id": 42, "seek": 21796, "start": 240.04000000000002, "end": 245.56, "text": " findable, your code should have a globally unique and eternally persistent identifier.", "tokens": [51468, 915, 712, 11, 428, 3089, 820, 362, 257, 18958, 3845, 293, 10533, 379, 24315, 45690, 13, 51744], "temperature": 0.0, "avg_logprob": -0.08978033065795898, "compression_ratio": 1.5065502183406114, "no_speech_prob": 0.0015478263376280665}, {"id": 43, "seek": 24556, "start": 246.28, "end": 251.4, "text": " In practice, this means a permanent URL where someone can visit and find a landing page", "tokens": [50400, 682, 3124, 11, 341, 1355, 257, 10996, 12905, 689, 1580, 393, 3441, 293, 915, 257, 11202, 3028, 50656], "temperature": 0.0, "avg_logprob": -0.06969936945105112, "compression_ratio": 1.7401574803149606, "no_speech_prob": 0.0019562358502298594}, {"id": 44, "seek": 24556, "start": 252.04, "end": 257.24, "text": " with rich descriptive metadata about your computational model, its uses, and so on.", "tokens": [50688, 365, 4593, 42585, 26603, 466, 428, 28270, 2316, 11, 1080, 4960, 11, 293, 370, 322, 13, 50948], "temperature": 0.0, "avg_logprob": -0.06969936945105112, "compression_ratio": 1.7401574803149606, "no_speech_prob": 0.0019562358502298594}, {"id": 45, "seek": 24556, "start": 258.52, "end": 264.04, "text": " Furthermore, this URL should identify a specific version or release of your software.", "tokens": [51012, 23999, 11, 341, 12905, 820, 5876, 257, 2685, 3037, 420, 4374, 295, 428, 4722, 13, 51288], "temperature": 0.0, "avg_logprob": -0.06969936945105112, "compression_ratio": 1.7401574803149606, "no_speech_prob": 0.0019562358502298594}, {"id": 46, "seek": 24556, "start": 264.92, "end": 269.08, "text": " When you cite your own computational model or someone else's computational model in the", "tokens": [51332, 1133, 291, 37771, 428, 1065, 28270, 2316, 420, 1580, 1646, 311, 28270, 2316, 294, 264, 51540], "temperature": 0.0, "avg_logprob": -0.06969936945105112, "compression_ratio": 1.7401574803149606, "no_speech_prob": 0.0019562358502298594}, {"id": 47, "seek": 24556, "start": 269.08, "end": 274.44, "text": " publication, you should be citing the exact version of the software used to derive your results,", "tokens": [51540, 19953, 11, 291, 820, 312, 48749, 264, 1900, 3037, 295, 264, 4722, 1143, 281, 28446, 428, 3542, 11, 51808], "temperature": 0.0, "avg_logprob": -0.06969936945105112, "compression_ratio": 1.7401574803149606, "no_speech_prob": 0.0019562358502298594}, {"id": 48, "seek": 27444, "start": 274.44, "end": 278.76, "text": " and that should take you to that snapshot, a snapshot of that code base at that time that", "tokens": [50364, 293, 300, 820, 747, 291, 281, 300, 30163, 11, 257, 30163, 295, 300, 3089, 3096, 412, 300, 565, 300, 50580], "temperature": 0.0, "avg_logprob": -0.10635756174723307, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.002250630408525467}, {"id": 49, "seek": 27444, "start": 278.76, "end": 285.71999999999997, "text": " shows exactly the state of the code base at the time that you used it. This snapshot could also", "tokens": [50580, 3110, 2293, 264, 1785, 295, 264, 3089, 3096, 412, 264, 565, 300, 291, 1143, 309, 13, 639, 30163, 727, 611, 50928], "temperature": 0.0, "avg_logprob": -0.10635756174723307, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.002250630408525467}, {"id": 50, "seek": 27444, "start": 285.71999999999997, "end": 291.24, "text": " include data analysis scripts used to explore the model outputs or generate visualization or figures,", "tokens": [50928, 4090, 1412, 5215, 23294, 1143, 281, 6839, 264, 2316, 23930, 420, 8460, 25801, 420, 9624, 11, 51204], "temperature": 0.0, "avg_logprob": -0.10635756174723307, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.002250630408525467}, {"id": 51, "seek": 27444, "start": 292.36, "end": 296.28, "text": " as well as other plaintext and descriptive metadata.", "tokens": [51260, 382, 731, 382, 661, 11121, 25111, 293, 42585, 26603, 13, 51456], "temperature": 0.0, "avg_logprob": -0.10635756174723307, "compression_ratio": 1.7525773195876289, "no_speech_prob": 0.002250630408525467}, {"id": 52, "seek": 29628, "start": 297.23999999999995, "end": 303.4, "text": " Accessibility is primarily a cyber infrastructure or platform concern, which is to say, it's our", "tokens": [50412, 17166, 2841, 307, 10029, 257, 13411, 6896, 420, 3663, 3136, 11, 597, 307, 281, 584, 11, 309, 311, 527, 50720], "temperature": 0.0, "avg_logprob": -0.22491268046851298, "compression_ratio": 1.6313993174061434, "no_speech_prob": 0.0017544792499393225}, {"id": 53, "seek": 29628, "start": 303.4, "end": 309.08, "text": " problem at CompSysNet if you're trying to build a trusted repository for your software. It has more", "tokens": [50720, 1154, 412, 6620, 50, 749, 31890, 498, 291, 434, 1382, 281, 1322, 257, 16034, 25841, 337, 428, 4722, 13, 467, 575, 544, 51004], "temperature": 0.0, "avg_logprob": -0.22491268046851298, "compression_ratio": 1.6313993174061434, "no_speech_prob": 0.0017544792499393225}, {"id": 54, "seek": 29628, "start": 309.08, "end": 314.52, "text": " to do with open protocols to access your metadata and code base that allow for authentication,", "tokens": [51004, 281, 360, 365, 1269, 20618, 281, 2105, 428, 26603, 293, 3089, 3096, 300, 2089, 337, 26643, 11, 51276], "temperature": 0.0, "avg_logprob": -0.22491268046851298, "compression_ratio": 1.6313993174061434, "no_speech_prob": 0.0017544792499393225}, {"id": 55, "seek": 29628, "start": 314.52, "end": 319.0, "text": " authorization, and so on. There is one important point to make, which is that the descriptive", "tokens": [51276, 33697, 11, 293, 370, 322, 13, 821, 307, 472, 1021, 935, 281, 652, 11, 597, 307, 300, 264, 42585, 51500], "temperature": 0.0, "avg_logprob": -0.22491268046851298, "compression_ratio": 1.6313993174061434, "no_speech_prob": 0.0017544792499393225}, {"id": 56, "seek": 29628, "start": 319.0, "end": 323.4, "text": " metadata about your computational model should be available even when the underlying data or", "tokens": [51500, 26603, 466, 428, 28270, 2316, 820, 312, 2435, 754, 562, 264, 14217, 1412, 420, 51720], "temperature": 0.0, "avg_logprob": -0.22491268046851298, "compression_ratio": 1.6313993174061434, "no_speech_prob": 0.0017544792499393225}, {"id": 57, "seek": 32340, "start": 324.03999999999996, "end": 330.76, "text": " code is not available due to licensing restrictions or an embargo. That just means that you should", "tokens": [50396, 3089, 307, 406, 2435, 3462, 281, 29759, 14191, 420, 364, 23955, 13, 663, 445, 1355, 300, 291, 820, 50732], "temperature": 0.0, "avg_logprob": -0.08454431557073826, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.001674058148637414}, {"id": 58, "seek": 32340, "start": 330.76, "end": 336.67999999999995, "text": " be aware of what's out there and should be aware that this thing exists and have the options for", "tokens": [50732, 312, 3650, 295, 437, 311, 484, 456, 293, 820, 312, 3650, 300, 341, 551, 8198, 293, 362, 264, 3956, 337, 51028], "temperature": 0.0, "avg_logprob": -0.08454431557073826, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.001674058148637414}, {"id": 59, "seek": 32340, "start": 336.67999999999995, "end": 345.47999999999996, "text": " contacting authors and getting more information about it. Interoperability in this situation", "tokens": [51028, 41482, 16552, 293, 1242, 544, 1589, 466, 309, 13, 5751, 7192, 2310, 294, 341, 2590, 51468], "temperature": 0.0, "avg_logprob": -0.08454431557073826, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.001674058148637414}, {"id": 60, "seek": 32340, "start": 345.47999999999996, "end": 351.56, "text": " refers to interoperability of metadata, namely that we use standardized vocabularies for the", "tokens": [51468, 14942, 281, 728, 7192, 2310, 295, 26603, 11, 20926, 300, 321, 764, 31677, 2329, 455, 1040, 530, 337, 264, 51772], "temperature": 0.0, "avg_logprob": -0.08454431557073826, "compression_ratio": 1.7008928571428572, "no_speech_prob": 0.001674058148637414}, {"id": 61, "seek": 35156, "start": 351.56, "end": 356.84, "text": " descriptive metadata about your computational model. CompSysNet is also collaborating with", "tokens": [50364, 42585, 26603, 466, 428, 28270, 2316, 13, 6620, 50, 749, 31890, 307, 611, 30188, 365, 50628], "temperature": 0.0, "avg_logprob": -0.10466730900299855, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.00198721163906157}, {"id": 62, "seek": 35156, "start": 356.84, "end": 362.2, "text": " CSDMS, the Community Surface Dynamics Modeling System Group at Boulder, as well as other research", "tokens": [50628, 9460, 35, 10288, 11, 264, 10421, 36052, 22947, 1167, 6583, 11031, 8910, 10500, 412, 48052, 11, 382, 731, 382, 661, 2132, 50896], "temperature": 0.0, "avg_logprob": -0.10466730900299855, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.00198721163906157}, {"id": 63, "seek": 35156, "start": 362.2, "end": 369.16, "text": " groups to establish standardized names for the various inputs, outputs, and process variables", "tokens": [50896, 3935, 281, 8327, 31677, 5288, 337, 264, 3683, 15743, 11, 23930, 11, 293, 1399, 9102, 51244], "temperature": 0.0, "avg_logprob": -0.10466730900299855, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.00198721163906157}, {"id": 64, "seek": 35156, "start": 369.16, "end": 374.92, "text": " and computational models. CSDMS already has a set of standardized names for their computational", "tokens": [51244, 293, 28270, 5245, 13, 9460, 35, 10288, 1217, 575, 257, 992, 295, 31677, 5288, 337, 641, 28270, 51532], "temperature": 0.0, "avg_logprob": -0.10466730900299855, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.00198721163906157}, {"id": 65, "seek": 37492, "start": 374.92, "end": 380.76, "text": " earth systems models and we're actively exploring together ways to connect models as", "tokens": [50364, 4120, 3652, 5245, 293, 321, 434, 13022, 12736, 1214, 2098, 281, 1745, 5245, 382, 50656], "temperature": 0.0, "avg_logprob": -0.09518320719401041, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.1224464699625969}, {"id": 66, "seek": 37492, "start": 380.76, "end": 385.56, "text": " pluggable components so that an earth systems model can be connected with a behavioral model", "tokens": [50656, 499, 3562, 712, 6677, 370, 300, 364, 4120, 3652, 2316, 393, 312, 4582, 365, 257, 19124, 2316, 50896], "temperature": 0.0, "avg_logprob": -0.09518320719401041, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.1224464699625969}, {"id": 67, "seek": 37492, "start": 386.12, "end": 390.76, "text": " and mapping their inputs and outputs onto standardized ontologies of variable types.", "tokens": [50924, 293, 18350, 641, 15743, 293, 23930, 3911, 31677, 6592, 6204, 295, 7006, 3467, 13, 51156], "temperature": 0.0, "avg_logprob": -0.09518320719401041, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.1224464699625969}, {"id": 68, "seek": 37492, "start": 390.76, "end": 395.0, "text": " This is an active area of research, so if you're interested in this endeavor, please feel free", "tokens": [51156, 639, 307, 364, 4967, 1859, 295, 2132, 11, 370, 498, 291, 434, 3102, 294, 341, 34975, 11, 1767, 841, 1737, 51368], "temperature": 0.0, "avg_logprob": -0.09518320719401041, "compression_ratio": 1.6527777777777777, "no_speech_prob": 0.1224464699625969}, {"id": 69, "seek": 39500, "start": 395.96, "end": 397.4, "text": " to contact me directly.", "tokens": [50412, 281, 3385, 385, 3838, 13, 50484], "temperature": 0.0, "avg_logprob": -0.09778035770763051, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.1499292254447937}, {"id": 70, "seek": 39500, "start": 402.2, "end": 409.08, "text": " One critical piece of reusability is licensing. A clear usage license is", "tokens": [50724, 1485, 4924, 2522, 295, 38860, 2310, 307, 29759, 13, 316, 1850, 14924, 10476, 307, 51068], "temperature": 0.0, "avg_logprob": -0.09778035770763051, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.1499292254447937}, {"id": 71, "seek": 39500, "start": 409.08, "end": 414.36, "text": " necessary for anyone to reuse your software. The software carpentry groups recommend permissive", "tokens": [51068, 4818, 337, 2878, 281, 26225, 428, 4722, 13, 440, 4722, 1032, 22786, 627, 3935, 2748, 4784, 891, 488, 51332], "temperature": 0.0, "avg_logprob": -0.09778035770763051, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.1499292254447937}, {"id": 72, "seek": 39500, "start": 414.36, "end": 421.0, "text": " open source licenses like the MIT or Apache license. This facilitates maximum reuse. It imposes", "tokens": [51332, 1269, 4009, 32821, 411, 264, 13100, 420, 46597, 10476, 13, 639, 10217, 30035, 6674, 26225, 13, 467, 704, 4201, 51664], "temperature": 0.0, "avg_logprob": -0.09778035770763051, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.1499292254447937}, {"id": 73, "seek": 42100, "start": 421.0, "end": 426.04, "text": " very little restrictions besides attribution. If you have concerns about commercial applications", "tokens": [50364, 588, 707, 14191, 11868, 9080, 1448, 13, 759, 291, 362, 7389, 466, 6841, 5821, 50616], "temperature": 0.0, "avg_logprob": -0.08543328179253472, "compression_ratio": 1.6293436293436294, "no_speech_prob": 0.005383579526096582}, {"id": 74, "seek": 42100, "start": 426.04, "end": 429.32, "text": " or contributions back to your code base, you might consider the GPL as well.", "tokens": [50616, 420, 15725, 646, 281, 428, 3089, 3096, 11, 291, 1062, 1949, 264, 460, 21593, 382, 731, 13, 50780], "temperature": 0.0, "avg_logprob": -0.08543328179253472, "compression_ratio": 1.6293436293436294, "no_speech_prob": 0.005383579526096582}, {"id": 75, "seek": 42100, "start": 430.44, "end": 435.08, "text": " Good documentation from multiple vantage points of abstraction is also critical to reuse.", "tokens": [50836, 2205, 14333, 490, 3866, 46206, 2793, 295, 37765, 307, 611, 4924, 281, 26225, 13, 51068], "temperature": 0.0, "avg_logprob": -0.08543328179253472, "compression_ratio": 1.6293436293436294, "no_speech_prob": 0.005383579526096582}, {"id": 76, "seek": 42100, "start": 435.64, "end": 439.64, "text": " The documentation should include steps on how to run your code,", "tokens": [51096, 440, 14333, 820, 4090, 4439, 322, 577, 281, 1190, 428, 3089, 11, 51296], "temperature": 0.0, "avg_logprob": -0.08543328179253472, "compression_ratio": 1.6293436293436294, "no_speech_prob": 0.005383579526096582}, {"id": 77, "seek": 42100, "start": 440.2, "end": 447.4, "text": " important inputs, and the internal processes outputs. The ODD protocol is a semi-controversial", "tokens": [51324, 1021, 15743, 11, 293, 264, 6920, 7555, 23930, 13, 440, 422, 20818, 10336, 307, 257, 12909, 12, 9000, 340, 840, 831, 51684], "temperature": 0.0, "avg_logprob": -0.08543328179253472, "compression_ratio": 1.6293436293436294, "no_speech_prob": 0.005383579526096582}, {"id": 78, "seek": 44740, "start": 447.4, "end": 453.88, "text": " standard in the computational modeling community, but it's a great starting point.", "tokens": [50364, 3832, 294, 264, 28270, 15983, 1768, 11, 457, 309, 311, 257, 869, 2891, 935, 13, 50688], "temperature": 0.0, "avg_logprob": -0.12023466746012369, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0034824104513972998}, {"id": 79, "seek": 44740, "start": 454.67999999999995, "end": 460.2, "text": " You have to also make sure you include your dependencies. What software or system or data", "tokens": [50728, 509, 362, 281, 611, 652, 988, 291, 4090, 428, 36606, 13, 708, 4722, 420, 1185, 420, 1412, 51004], "temperature": 0.0, "avg_logprob": -0.12023466746012369, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0034824104513972998}, {"id": 80, "seek": 44740, "start": 460.2, "end": 467.79999999999995, "text": " dependencies does your model have? Also, bonus points for test suites that run your and exercise", "tokens": [51004, 36606, 775, 428, 2316, 362, 30, 2743, 11, 10882, 2793, 337, 1500, 459, 3324, 300, 1190, 428, 293, 5380, 51384], "temperature": 0.0, "avg_logprob": -0.12023466746012369, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0034824104513972998}, {"id": 81, "seek": 44740, "start": 467.79999999999995, "end": 475.08, "text": " your computational models and assure and give us confidence that the internal processes within", "tokens": [51384, 428, 28270, 5245, 293, 20968, 293, 976, 505, 6687, 300, 264, 6920, 7555, 1951, 51748], "temperature": 0.0, "avg_logprob": -0.12023466746012369, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0034824104513972998}, {"id": 82, "seek": 47508, "start": 475.08, "end": 481.15999999999997, "text": " your model are working correctly. Consistent also offers a peer review process for computational", "tokens": [50364, 428, 2316, 366, 1364, 8944, 13, 6923, 25367, 611, 7736, 257, 15108, 3131, 1399, 337, 28270, 50668], "temperature": 0.0, "avg_logprob": -0.10351154539320204, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.006485423073172569}, {"id": 83, "seek": 47508, "start": 481.15999999999997, "end": 486.68, "text": " models. We ask independent reviewers to verify that a computational model submitted to our", "tokens": [50668, 5245, 13, 492, 1029, 6695, 45837, 281, 16888, 300, 257, 28270, 2316, 14405, 281, 527, 50944], "temperature": 0.0, "avg_logprob": -0.10351154539320204, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.006485423073172569}, {"id": 84, "seek": 47508, "start": 486.68, "end": 492.44, "text": " model library has well-formatted and commented code is fully documented with the ODD protocol", "tokens": [50944, 2316, 6405, 575, 731, 12, 837, 32509, 293, 26940, 3089, 307, 4498, 23007, 365, 264, 422, 20818, 10336, 51232], "temperature": 0.0, "avg_logprob": -0.10351154539320204, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.006485423073172569}, {"id": 85, "seek": 47508, "start": 492.44, "end": 498.03999999999996, "text": " or an equivalent narrative documentation and working instructions for compiling and executing", "tokens": [51232, 420, 364, 10344, 9977, 14333, 293, 1364, 9415, 337, 715, 4883, 293, 32368, 51512], "temperature": 0.0, "avg_logprob": -0.10351154539320204, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.006485423073172569}, {"id": 86, "seek": 49804, "start": 498.04, "end": 507.0, "text": " the computational model. There's a few more key software engineering practices that can", "tokens": [50364, 264, 28270, 2316, 13, 821, 311, 257, 1326, 544, 2141, 4722, 7043, 7525, 300, 393, 50812], "temperature": 0.0, "avg_logprob": -0.09435384992569212, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.006691029295325279}, {"id": 87, "seek": 49804, "start": 507.0, "end": 515.16, "text": " help us arrive at readable, reusable, and testable code. We can write meaningful variable names and", "tokens": [50812, 854, 505, 8881, 412, 49857, 11, 41807, 11, 293, 1500, 712, 3089, 13, 492, 393, 2464, 10995, 7006, 5288, 293, 51220], "temperature": 0.0, "avg_logprob": -0.09435384992569212, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.006691029295325279}, {"id": 88, "seek": 49804, "start": 515.16, "end": 521.8000000000001, "text": " files as always an important aspect. Keeping your code modular and well-encapsulated by breaking", "tokens": [51220, 7098, 382, 1009, 364, 1021, 4171, 13, 30187, 428, 3089, 31111, 293, 731, 12, 268, 496, 1878, 6987, 538, 7697, 51552], "temperature": 0.0, "avg_logprob": -0.09435384992569212, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.006691029295325279}, {"id": 89, "seek": 52180, "start": 521.88, "end": 527.24, "text": " problems down into smaller pieces and short cogent functions is also extremely useful.", "tokens": [50368, 2740, 760, 666, 4356, 3755, 293, 2099, 598, 6930, 6828, 307, 611, 4664, 4420, 13, 50636], "temperature": 0.0, "avg_logprob": -0.08860724932187564, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.34123694896698}, {"id": 90, "seek": 52180, "start": 527.88, "end": 532.92, "text": " Adding explanatory comments at the start of every module and function in the system that", "tokens": [50668, 31204, 9045, 4745, 3053, 412, 264, 722, 295, 633, 10088, 293, 2445, 294, 264, 1185, 300, 50920], "temperature": 0.0, "avg_logprob": -0.08860724932187564, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.34123694896698}, {"id": 91, "seek": 52180, "start": 532.92, "end": 539.24, "text": " describe its inputs and expected outputs is also incredibly useful. If you find yourself duplicating", "tokens": [50920, 6786, 1080, 15743, 293, 5176, 23930, 307, 611, 6252, 4420, 13, 759, 291, 915, 1803, 17154, 990, 51236], "temperature": 0.0, "avg_logprob": -0.08860724932187564, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.34123694896698}, {"id": 92, "seek": 52180, "start": 539.24, "end": 545.9599999999999, "text": " code, try to replace that duplication with a parameterized function. In general, just marking", "tokens": [51236, 3089, 11, 853, 281, 7406, 300, 17154, 399, 365, 257, 13075, 1602, 2445, 13, 682, 2674, 11, 445, 25482, 51572], "temperature": 0.0, "avg_logprob": -0.08860724932187564, "compression_ratio": 1.6371681415929205, "no_speech_prob": 0.34123694896698}, {"id": 93, "seek": 54596, "start": 545.96, "end": 550.76, "text": " the entry point into your application and walking through the sample code pass is a very", "tokens": [50364, 264, 8729, 935, 666, 428, 3861, 293, 4494, 807, 264, 6889, 3089, 1320, 307, 257, 588, 50604], "temperature": 0.0, "avg_logprob": -0.0831483268737793, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.040804989635944366}, {"id": 94, "seek": 54596, "start": 551.4000000000001, "end": 555.88, "text": " useful exercise and this is something that the ODD protocol addresses as well.", "tokens": [50636, 4420, 5380, 293, 341, 307, 746, 300, 264, 422, 20818, 10336, 16862, 382, 731, 13, 50860], "temperature": 0.0, "avg_logprob": -0.0831483268737793, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.040804989635944366}, {"id": 95, "seek": 54596, "start": 557.24, "end": 564.2800000000001, "text": " Version control is another extremely important piece of this puzzle. We'll go into two different", "tokens": [50928, 35965, 1969, 307, 1071, 4664, 1021, 2522, 295, 341, 12805, 13, 492, 603, 352, 666, 732, 819, 51280], "temperature": 0.0, "avg_logprob": -0.0831483268737793, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.040804989635944366}, {"id": 96, "seek": 54596, "start": 564.2800000000001, "end": 572.44, "text": " methods for this in the coming slides. And for larger projects, an automated build system", "tokens": [51280, 7150, 337, 341, 294, 264, 1348, 9788, 13, 400, 337, 4833, 4455, 11, 364, 18473, 1322, 1185, 51688], "temperature": 0.0, "avg_logprob": -0.0831483268737793, "compression_ratio": 1.51931330472103, "no_speech_prob": 0.040804989635944366}, {"id": 97, "seek": 57244, "start": 572.44, "end": 579.24, "text": " with tests and continuous integration is extremely helpful. A continuous integration", "tokens": [50364, 365, 6921, 293, 10957, 10980, 307, 4664, 4961, 13, 316, 10957, 10980, 50704], "temperature": 0.0, "avg_logprob": -0.10565311877758472, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0432998351752758}, {"id": 98, "seek": 57244, "start": 579.24, "end": 585.32, "text": " system is one that automatically runs on every change to the code base and tries to compile", "tokens": [50704, 1185, 307, 472, 300, 6772, 6676, 322, 633, 1319, 281, 264, 3089, 3096, 293, 9898, 281, 31413, 51008], "temperature": 0.0, "avg_logprob": -0.10565311877758472, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0432998351752758}, {"id": 99, "seek": 57244, "start": 585.32, "end": 591.48, "text": " and run tests against a clean installation of the code base. It's a great way to keep your", "tokens": [51008, 293, 1190, 6921, 1970, 257, 2541, 13260, 295, 264, 3089, 3096, 13, 467, 311, 257, 869, 636, 281, 1066, 428, 51316], "temperature": 0.0, "avg_logprob": -0.10565311877758472, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0432998351752758}, {"id": 100, "seek": 57244, "start": 591.48, "end": 597.0, "text": " software honest and there's several third-party services that offer this, including TravisCI,", "tokens": [51316, 4722, 3245, 293, 456, 311, 2940, 2636, 12, 23409, 3328, 300, 2626, 341, 11, 3009, 24430, 25240, 11, 51592], "temperature": 0.0, "avg_logprob": -0.10565311877758472, "compression_ratio": 1.6409090909090909, "no_speech_prob": 0.0432998351752758}, {"id": 101, "seek": 59700, "start": 597.0, "end": 602.44, "text": " drone.io or Jenkins and we can talk more about this on the conference website if you're interested.", "tokens": [50364, 13852, 13, 1004, 420, 41273, 293, 321, 393, 751, 544, 466, 341, 322, 264, 7586, 3144, 498, 291, 434, 3102, 13, 50636], "temperature": 0.0, "avg_logprob": -0.1416728807532269, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.04081256687641144}, {"id": 102, "seek": 59700, "start": 604.6, "end": 609.96, "text": " The first approach to version control is manual one. This is one advocated by the", "tokens": [50744, 440, 700, 3109, 281, 3037, 1969, 307, 9688, 472, 13, 639, 307, 472, 7915, 770, 538, 264, 51012], "temperature": 0.0, "avg_logprob": -0.1416728807532269, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.04081256687641144}, {"id": 103, "seek": 59700, "start": 611.48, "end": 616.2, "text": " the Good Enough Practices paper by Wilson et al that I referenced earlier. You don't need any", "tokens": [51088, 264, 2205, 19401, 19170, 1473, 3035, 538, 15388, 1030, 419, 300, 286, 32734, 3071, 13, 509, 500, 380, 643, 604, 51324], "temperature": 0.0, "avg_logprob": -0.1416728807532269, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.04081256687641144}, {"id": 104, "seek": 59700, "start": 616.2, "end": 623.0, "text": " new tools. You just need to be systematic. You can keep your changelodge.txt file dated and organized", "tokens": [51324, 777, 3873, 13, 509, 445, 643, 281, 312, 27249, 13, 509, 393, 1066, 428, 1534, 338, 19315, 13, 83, 734, 3991, 23804, 293, 9983, 51664], "temperature": 0.0, "avg_logprob": -0.1416728807532269, "compression_ratio": 1.5387755102040817, "no_speech_prob": 0.04081256687641144}, {"id": 105, "seek": 62300, "start": 623.0, "end": 626.6, "text": " and you'll copy your entire project folder on every significant change.", "tokens": [50364, 293, 291, 603, 5055, 428, 2302, 1716, 10820, 322, 633, 4776, 1319, 13, 50544], "temperature": 0.0, "avg_logprob": -0.12071614968972127, "compression_ratio": 1.4367816091954022, "no_speech_prob": 0.0018093331018462777}, {"id": 106, "seek": 62300, "start": 632.68, "end": 639.72, "text": " More sophisticated ways to use an actual version control system like Git or Mercurial or SVN.", "tokens": [50848, 5048, 16950, 2098, 281, 764, 364, 3539, 3037, 1969, 1185, 411, 16939, 420, 18897, 374, 831, 420, 31910, 45, 13, 51200], "temperature": 0.0, "avg_logprob": -0.12071614968972127, "compression_ratio": 1.4367816091954022, "no_speech_prob": 0.0018093331018462777}, {"id": 107, "seek": 62300, "start": 640.68, "end": 649.0, "text": " All of these are great version control systems. If you pick one, you won't go wrong.", "tokens": [51248, 1057, 295, 613, 366, 869, 3037, 1969, 3652, 13, 759, 291, 1888, 472, 11, 291, 1582, 380, 352, 2085, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12071614968972127, "compression_ratio": 1.4367816091954022, "no_speech_prob": 0.0018093331018462777}, {"id": 108, "seek": 64900, "start": 649.72, "end": 653.56, "text": " This will have a huge payoff down the road as it gives you the confidence to experiment with your", "tokens": [50400, 639, 486, 362, 257, 2603, 46547, 760, 264, 3060, 382, 309, 2709, 291, 264, 6687, 281, 5120, 365, 428, 50592], "temperature": 0.0, "avg_logprob": -0.14845634368528804, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.002979830838739872}, {"id": 109, "seek": 64900, "start": 653.56, "end": 657.96, "text": " software knowing that you can always revert back to a previous state. It also gives you the ability", "tokens": [50592, 4722, 5276, 300, 291, 393, 1009, 319, 3281, 646, 281, 257, 3894, 1785, 13, 467, 611, 2709, 291, 264, 3485, 50812], "temperature": 0.0, "avg_logprob": -0.14845634368528804, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.002979830838739872}, {"id": 110, "seek": 64900, "start": 657.96, "end": 665.8, "text": " to associate meaningful log messages with changes in your code base and to also associate tags and", "tokens": [50812, 281, 14644, 10995, 3565, 7897, 365, 2962, 294, 428, 3089, 3096, 293, 281, 611, 14644, 18632, 293, 51204], "temperature": 0.0, "avg_logprob": -0.14845634368528804, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.002979830838739872}, {"id": 111, "seek": 64900, "start": 665.8, "end": 671.4, "text": " releases with your code base that help keep track of important milestones. This is critical for", "tokens": [51204, 16952, 365, 428, 3089, 3096, 300, 854, 1066, 2837, 295, 1021, 42038, 13, 639, 307, 4924, 337, 51484], "temperature": 0.0, "avg_logprob": -0.14845634368528804, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.002979830838739872}, {"id": 112, "seek": 67140, "start": 672.36, "end": 680.28, "text": " actually citing the specific version of your software. With the model library at CompSysNet,", "tokens": [50412, 767, 48749, 264, 2685, 3037, 295, 428, 4722, 13, 2022, 264, 2316, 6405, 412, 6620, 50, 749, 31890, 11, 50808], "temperature": 0.0, "avg_logprob": -0.11461533556927692, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.003323708428069949}, {"id": 113, "seek": 67140, "start": 680.28, "end": 686.12, "text": " we also offer the ability to capture snapshots but we want to have tight integration with Git as", "tokens": [50808, 321, 611, 2626, 264, 3485, 281, 7983, 19206, 27495, 457, 321, 528, 281, 362, 4524, 10980, 365, 16939, 382, 51100], "temperature": 0.0, "avg_logprob": -0.11461533556927692, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.003323708428069949}, {"id": 114, "seek": 67140, "start": 686.12, "end": 694.12, "text": " well. We'll have more on that later. When you do use a version control system, there are a few", "tokens": [51100, 731, 13, 492, 603, 362, 544, 322, 300, 1780, 13, 1133, 291, 360, 764, 257, 3037, 1969, 1185, 11, 456, 366, 257, 1326, 51500], "temperature": 0.0, "avg_logprob": -0.11461533556927692, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.003323708428069949}, {"id": 115, "seek": 67140, "start": 694.12, "end": 699.24, "text": " good practices to keep in mind. You should do your best to keep your changes small and isolated.", "tokens": [51500, 665, 7525, 281, 1066, 294, 1575, 13, 509, 820, 360, 428, 1151, 281, 1066, 428, 2962, 1359, 293, 14621, 13, 51756], "temperature": 0.0, "avg_logprob": -0.11461533556927692, "compression_ratio": 1.5551020408163265, "no_speech_prob": 0.003323708428069949}, {"id": 116, "seek": 69924, "start": 699.32, "end": 705.24, "text": " If you modify every single file in your code base and push that as a commit, it's harder to see", "tokens": [50368, 759, 291, 16927, 633, 2167, 3991, 294, 428, 3089, 3096, 293, 2944, 300, 382, 257, 5599, 11, 309, 311, 6081, 281, 536, 50664], "temperature": 0.0, "avg_logprob": -0.08913398924328032, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.004826724994927645}, {"id": 117, "seek": 69924, "start": 705.24, "end": 710.44, "text": " what's going on. Keeping your changes small and isolated, committing early and committing often", "tokens": [50664, 437, 311, 516, 322, 13, 30187, 428, 2962, 1359, 293, 14621, 11, 26659, 2440, 293, 26659, 2049, 50924], "temperature": 0.0, "avg_logprob": -0.08913398924328032, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.004826724994927645}, {"id": 118, "seek": 69924, "start": 710.44, "end": 718.36, "text": " helps you be exercised disciplined version control. That way, you can easily see the changes that", "tokens": [50924, 3665, 291, 312, 4057, 2640, 40061, 3037, 1969, 13, 663, 636, 11, 291, 393, 3612, 536, 264, 2962, 300, 51320], "temperature": 0.0, "avg_logprob": -0.08913398924328032, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.004826724994927645}, {"id": 119, "seek": 69924, "start": 718.36, "end": 724.2, "text": " were made to the code and tie that in with semantic and descriptive log messages that", "tokens": [51320, 645, 1027, 281, 264, 3089, 293, 7582, 300, 294, 365, 47982, 293, 42585, 3565, 7897, 300, 51612], "temperature": 0.0, "avg_logprob": -0.08913398924328032, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.004826724994927645}, {"id": 120, "seek": 72420, "start": 724.2, "end": 727.24, "text": " describe and document the intent of those changes.", "tokens": [50364, 6786, 293, 4166, 264, 8446, 295, 729, 2962, 13, 50516], "temperature": 0.0, "avg_logprob": -0.10996466318766276, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.0017815117025747895}, {"id": 121, "seek": 72420, "start": 733.6400000000001, "end": 739.24, "text": " It can also be very helpful to adopt a standardized directory layout. Here's a simple example where", "tokens": [50836, 467, 393, 611, 312, 588, 4961, 281, 6878, 257, 31677, 21120, 13333, 13, 1692, 311, 257, 2199, 1365, 689, 51116], "temperature": 0.0, "avg_logprob": -0.10996466318766276, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.0017815117025747895}, {"id": 122, "seek": 72420, "start": 739.24, "end": 744.12, "text": " we organize our source code, documents, input data, and output data in different directories", "tokens": [51116, 321, 13859, 527, 4009, 3089, 11, 8512, 11, 4846, 1412, 11, 293, 5598, 1412, 294, 819, 5391, 530, 51360], "temperature": 0.0, "avg_logprob": -0.10996466318766276, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.0017815117025747895}, {"id": 123, "seek": 72420, "start": 744.12, "end": 749.96, "text": " alongside plain text files that describe how our software should be cited. There's also a readme", "tokens": [51360, 12385, 11121, 2487, 7098, 300, 6786, 577, 527, 4722, 820, 312, 30134, 13, 821, 311, 611, 257, 1401, 1398, 51652], "temperature": 0.0, "avg_logprob": -0.10996466318766276, "compression_ratio": 1.588785046728972, "no_speech_prob": 0.0017815117025747895}, {"id": 124, "seek": 74996, "start": 749.96, "end": 753.0, "text": " that describes what the code does and an explicit license file.", "tokens": [50364, 300, 15626, 437, 264, 3089, 775, 293, 364, 13691, 10476, 3991, 13, 50516], "temperature": 0.0, "avg_logprob": -0.08779838681221008, "compression_ratio": 1.628352490421456, "no_speech_prob": 0.0038232484366744757}, {"id": 125, "seek": 74996, "start": 759.24, "end": 764.6800000000001, "text": " Archiving data that your computational models depend on is also critical. You should always", "tokens": [50828, 10984, 2123, 1412, 300, 428, 28270, 5245, 5672, 322, 307, 611, 4924, 13, 509, 820, 1009, 51100], "temperature": 0.0, "avg_logprob": -0.08779838681221008, "compression_ratio": 1.628352490421456, "no_speech_prob": 0.0038232484366744757}, {"id": 126, "seek": 74996, "start": 764.6800000000001, "end": 769.8000000000001, "text": " save your data in its raw form, whether it be from a server or instrument, and never overwrite", "tokens": [51100, 3155, 428, 1412, 294, 1080, 8936, 1254, 11, 1968, 309, 312, 490, 257, 7154, 420, 7198, 11, 293, 1128, 670, 21561, 51356], "temperature": 0.0, "avg_logprob": -0.08779838681221008, "compression_ratio": 1.628352490421456, "no_speech_prob": 0.0038232484366744757}, {"id": 127, "seek": 74996, "start": 769.8000000000001, "end": 773.88, "text": " raw data with its intermediate forms, any sort of processing that you perform on it.", "tokens": [51356, 8936, 1412, 365, 1080, 19376, 6422, 11, 604, 1333, 295, 9007, 300, 291, 2042, 322, 309, 13, 51560], "temperature": 0.0, "avg_logprob": -0.08779838681221008, "compression_ratio": 1.628352490421456, "no_speech_prob": 0.0038232484366744757}, {"id": 128, "seek": 74996, "start": 774.44, "end": 778.36, "text": " If your data sets are extremely large, you'll have to find some way to generate permanent", "tokens": [51588, 759, 428, 1412, 6352, 366, 4664, 2416, 11, 291, 603, 362, 281, 915, 512, 636, 281, 8460, 10996, 51784], "temperature": 0.0, "avg_logprob": -0.08779838681221008, "compression_ratio": 1.628352490421456, "no_speech_prob": 0.0038232484366744757}, {"id": 129, "seek": 77836, "start": 778.36, "end": 787.0, "text": " URLs for those data sets. You can do this at OSF or FigShare. Otherwise, you can certainly", "tokens": [50364, 43267, 337, 729, 1412, 6352, 13, 509, 393, 360, 341, 412, 12731, 37, 420, 22443, 7774, 543, 13, 10328, 11, 291, 393, 3297, 50796], "temperature": 0.0, "avg_logprob": -0.10512284918145819, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.000677107076626271}, {"id": 130, "seek": 77836, "start": 787.0, "end": 791.32, "text": " include them inline in your code base, as we had in that previous file system layout.", "tokens": [50796, 4090, 552, 294, 1889, 294, 428, 3089, 3096, 11, 382, 321, 632, 294, 300, 3894, 3991, 1185, 13333, 13, 51012], "temperature": 0.0, "avg_logprob": -0.10512284918145819, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.000677107076626271}, {"id": 131, "seek": 77836, "start": 794.44, "end": 798.76, "text": " Input data that your software depends on should almost certainly be citably archived as well.", "tokens": [51168, 682, 2582, 1412, 300, 428, 4722, 5946, 322, 820, 1920, 3297, 312, 4814, 1188, 3912, 3194, 382, 731, 13, 51384], "temperature": 0.0, "avg_logprob": -0.10512284918145819, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.000677107076626271}, {"id": 132, "seek": 77836, "start": 800.12, "end": 807.32, "text": " When we talk about durable formats, it's okay to have Excel sheets while you're working with your", "tokens": [51452, 1133, 321, 751, 466, 22308, 25879, 11, 309, 311, 1392, 281, 362, 19060, 15421, 1339, 291, 434, 1364, 365, 428, 51812], "temperature": 0.0, "avg_logprob": -0.10512284918145819, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.000677107076626271}, {"id": 133, "seek": 80732, "start": 807.32, "end": 813.48, "text": " data, but when you archive your data, it should be archived in a durable format. It should be plain", "tokens": [50364, 1412, 11, 457, 562, 291, 23507, 428, 1412, 11, 309, 820, 312, 3912, 3194, 294, 257, 22308, 7877, 13, 467, 820, 312, 11121, 50672], "temperature": 0.0, "avg_logprob": -0.0921646647092675, "compression_ratio": 1.8185185185185184, "no_speech_prob": 0.00032499810913577676}, {"id": 134, "seek": 80732, "start": 813.48, "end": 820.84, "text": " text, it should be CSV. This allows machines to read them more usefully 20 years from now. Who knows", "tokens": [50672, 2487, 11, 309, 820, 312, 48814, 13, 639, 4045, 8379, 281, 1401, 552, 544, 764, 2277, 945, 924, 490, 586, 13, 2102, 3255, 51040], "temperature": 0.0, "avg_logprob": -0.0921646647092675, "compression_ratio": 1.8185185185185184, "no_speech_prob": 0.00032499810913577676}, {"id": 135, "seek": 80732, "start": 820.84, "end": 825.1600000000001, "text": " if the version of Excel that you use to save your file will still be readable, but a plain text file", "tokens": [51040, 498, 264, 3037, 295, 19060, 300, 291, 764, 281, 3155, 428, 3991, 486, 920, 312, 49857, 11, 457, 257, 11121, 2487, 3991, 51256], "temperature": 0.0, "avg_logprob": -0.0921646647092675, "compression_ratio": 1.8185185185185184, "no_speech_prob": 0.00032499810913577676}, {"id": 136, "seek": 80732, "start": 825.1600000000001, "end": 832.5200000000001, "text": " will still be readable. If you manipulated your data manually, you should document what you did", "tokens": [51256, 486, 920, 312, 49857, 13, 759, 291, 37161, 428, 1412, 16945, 11, 291, 820, 4166, 437, 291, 630, 51624], "temperature": 0.0, "avg_logprob": -0.0921646647092675, "compression_ratio": 1.8185185185185184, "no_speech_prob": 0.00032499810913577676}, {"id": 137, "seek": 80732, "start": 832.5200000000001, "end": 837.08, "text": " in the data changelog that records the changes you made, their intent, and also preserves the", "tokens": [51624, 294, 264, 1412, 1534, 338, 664, 300, 7724, 264, 2962, 291, 1027, 11, 641, 8446, 11, 293, 611, 1183, 9054, 264, 51852], "temperature": 0.0, "avg_logprob": -0.0921646647092675, "compression_ratio": 1.8185185185185184, "no_speech_prob": 0.00032499810913577676}, {"id": 138, "seek": 83708, "start": 837.08, "end": 843.24, "text": " before and after. Ideally, though, you should be scripting your data processing instead of hand", "tokens": [50364, 949, 293, 934, 13, 40817, 11, 1673, 11, 291, 820, 312, 5755, 278, 428, 1412, 9007, 2602, 295, 1011, 50672], "temperature": 0.0, "avg_logprob": -0.08627817034721375, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.0014319799374789}, {"id": 139, "seek": 83708, "start": 843.24, "end": 849.4000000000001, "text": " munging Excel sheets. This allows others to run your data analysis pipeline from the command line,", "tokens": [50672, 275, 1063, 278, 19060, 15421, 13, 639, 4045, 2357, 281, 1190, 428, 1412, 5215, 15517, 490, 264, 5622, 1622, 11, 50980], "temperature": 0.0, "avg_logprob": -0.08627817034721375, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.0014319799374789}, {"id": 140, "seek": 83708, "start": 849.4000000000001, "end": 854.76, "text": " it allows continuous integration to work, and it also just enables people to generate the same", "tokens": [50980, 309, 4045, 10957, 10980, 281, 589, 11, 293, 309, 611, 445, 17077, 561, 281, 8460, 264, 912, 51248], "temperature": 0.0, "avg_logprob": -0.08627817034721375, "compression_ratio": 1.513089005235602, "no_speech_prob": 0.0014319799374789}, {"id": 141, "seek": 85476, "start": 854.76, "end": 868.68, "text": " outputs you published with minimal effort. Analysis-friendly data is another topic that", "tokens": [50364, 23930, 291, 6572, 365, 13206, 4630, 13, 38172, 12, 22864, 1412, 307, 1071, 4829, 300, 51060], "temperature": 0.0, "avg_logprob": -0.08774485504418089, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.01589849404990673}, {"id": 142, "seek": 85476, "start": 868.68, "end": 876.28, "text": " Wilson and I all discuss. They describe two fundamental principles that I think are extremely", "tokens": [51060, 15388, 293, 286, 439, 2248, 13, 814, 6786, 732, 8088, 9156, 300, 286, 519, 366, 4664, 51440], "temperature": 0.0, "avg_logprob": -0.08774485504418089, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.01589849404990673}, {"id": 143, "seek": 85476, "start": 876.28, "end": 881.4, "text": " useful. The first one is to make each column a variable. Putting multiple variables into a", "tokens": [51440, 4420, 13, 440, 700, 472, 307, 281, 652, 1184, 7738, 257, 7006, 13, 31367, 3866, 9102, 666, 257, 51696], "temperature": 0.0, "avg_logprob": -0.08774485504418089, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.01589849404990673}, {"id": 144, "seek": 88140, "start": 881.4, "end": 887.4, "text": " single column makes programmatic analysis a lot messier, just like storing units in a variable.", "tokens": [50364, 2167, 7738, 1669, 1461, 25915, 5215, 257, 688, 2082, 811, 11, 445, 411, 26085, 6815, 294, 257, 7006, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1450681908186092, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.009853621944785118}, {"id": 145, "seek": 88140, "start": 889.88, "end": 898.76, "text": " Instead of storing 3.7kg, you might instead name the units in your metadata instead.", "tokens": [50788, 7156, 295, 26085, 805, 13, 22, 18302, 11, 291, 1062, 2602, 1315, 264, 6815, 294, 428, 26603, 2602, 13, 51232], "temperature": 0.0, "avg_logprob": -0.1450681908186092, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.009853621944785118}, {"id": 146, "seek": 88140, "start": 899.72, "end": 905.0799999999999, "text": " You should also make each row an observation. This is the second principle. You might have one row", "tokens": [51280, 509, 820, 611, 652, 1184, 5386, 364, 14816, 13, 639, 307, 264, 1150, 8665, 13, 509, 1062, 362, 472, 5386, 51548], "temperature": 0.0, "avg_logprob": -0.1450681908186092, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.009853621944785118}, {"id": 147, "seek": 88140, "start": 905.0799999999999, "end": 911.0799999999999, "text": " representing an observation at a field site with many columns. Each column is a time point measurement,", "tokens": [51548, 13460, 364, 14816, 412, 257, 2519, 3621, 365, 867, 13766, 13, 6947, 7738, 307, 257, 565, 935, 13160, 11, 51848], "temperature": 0.0, "avg_logprob": -0.1450681908186092, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.009853621944785118}, {"id": 148, "seek": 91140, "start": 911.72, "end": 918.6, "text": " until the end of data collection. This is usually done to facilitate data entry, but it's much easier", "tokens": [50380, 1826, 264, 917, 295, 1412, 5765, 13, 639, 307, 2673, 1096, 281, 20207, 1412, 8729, 11, 457, 309, 311, 709, 3571, 50724], "temperature": 0.0, "avg_logprob": -0.07866585519578721, "compression_ratio": 1.5934959349593496, "no_speech_prob": 0.0006459866417571902}, {"id": 149, "seek": 91140, "start": 918.6, "end": 924.52, "text": " to programmatically analyze when you convert time into a variable itself, so that the year, for", "tokens": [50724, 281, 37648, 5030, 12477, 562, 291, 7620, 565, 666, 257, 7006, 2564, 11, 370, 300, 264, 1064, 11, 337, 51020], "temperature": 0.0, "avg_logprob": -0.07866585519578721, "compression_ratio": 1.5934959349593496, "no_speech_prob": 0.0006459866417571902}, {"id": 150, "seek": 91140, "start": 924.52, "end": 932.04, "text": " instance, in this case, is a column. You should also make sure that any dependencies that your", "tokens": [51020, 5197, 11, 294, 341, 1389, 11, 307, 257, 7738, 13, 509, 820, 611, 652, 988, 300, 604, 36606, 300, 428, 51396], "temperature": 0.0, "avg_logprob": -0.07866585519578721, "compression_ratio": 1.5934959349593496, "no_speech_prob": 0.0006459866417571902}, {"id": 151, "seek": 91140, "start": 932.04, "end": 938.12, "text": " code has are clearly documented. Anytime you have to make a change to your local system to run your", "tokens": [51396, 3089, 575, 366, 4448, 23007, 13, 39401, 291, 362, 281, 652, 257, 1319, 281, 428, 2654, 1185, 281, 1190, 428, 51700], "temperature": 0.0, "avg_logprob": -0.07866585519578721, "compression_ratio": 1.5934959349593496, "no_speech_prob": 0.0006459866417571902}, {"id": 152, "seek": 93812, "start": 938.12, "end": 943.72, "text": " code, you should be recording what that change was. An easy way to actually keep yourself honest", "tokens": [50364, 3089, 11, 291, 820, 312, 6613, 437, 300, 1319, 390, 13, 1107, 1858, 636, 281, 767, 1066, 1803, 3245, 50644], "temperature": 0.0, "avg_logprob": -0.0741419792175293, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.012617922388017178}, {"id": 153, "seek": 93812, "start": 943.72, "end": 950.28, "text": " here is to occasionally spin up a fresh virtual machine using VirtualBox or VMware or any other", "tokens": [50644, 510, 307, 281, 16895, 6060, 493, 257, 4451, 6374, 3479, 1228, 23887, 34980, 420, 40146, 420, 604, 661, 50972], "temperature": 0.0, "avg_logprob": -0.0741419792175293, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.012617922388017178}, {"id": 154, "seek": 93812, "start": 950.28, "end": 956.28, "text": " free virtual machine tools, and try and install and run your computational model on that fresh", "tokens": [50972, 1737, 6374, 3479, 3873, 11, 293, 853, 293, 3625, 293, 1190, 428, 28270, 2316, 322, 300, 4451, 51272], "temperature": 0.0, "avg_logprob": -0.0741419792175293, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.012617922388017178}, {"id": 155, "seek": 93812, "start": 956.28, "end": 961.32, "text": " virtual machine. This almost guarantees that any additional system libraries, third-party", "tokens": [51272, 6374, 3479, 13, 639, 1920, 32567, 300, 604, 4497, 1185, 15148, 11, 2636, 12, 23409, 51524], "temperature": 0.0, "avg_logprob": -0.0741419792175293, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.012617922388017178}, {"id": 156, "seek": 93812, "start": 961.32, "end": 966.28, "text": " libraries, or data dependencies that need to be set up or installed will come to light as you try", "tokens": [51524, 15148, 11, 420, 1412, 36606, 300, 643, 281, 312, 992, 493, 420, 8899, 486, 808, 281, 1442, 382, 291, 853, 51772], "temperature": 0.0, "avg_logprob": -0.0741419792175293, "compression_ratio": 1.7463235294117647, "no_speech_prob": 0.012617922388017178}, {"id": 157, "seek": 96628, "start": 966.28, "end": 971.8, "text": " and build and run your computational model. It is time-consuming, however. Docker is another", "tokens": [50364, 293, 1322, 293, 1190, 428, 28270, 2316, 13, 467, 307, 565, 12, 21190, 24919, 11, 4461, 13, 33772, 307, 1071, 50640], "temperature": 0.0, "avg_logprob": -0.09618952667828902, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.005727576091885567}, {"id": 158, "seek": 96628, "start": 971.8, "end": 977.88, "text": " promising technology that we at CompSetsNet are using internally and experimenting with as a provided", "tokens": [50640, 20257, 2899, 300, 321, 412, 6620, 50, 1385, 31890, 366, 1228, 19501, 293, 29070, 365, 382, 257, 5649, 50944], "temperature": 0.0, "avg_logprob": -0.09618952667828902, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.005727576091885567}, {"id": 159, "seek": 96628, "start": 977.88, "end": 983.72, "text": " or curated service for model authors. Docker offers the reproducibility of a virtual machine but in", "tokens": [50944, 420, 47851, 2643, 337, 2316, 16552, 13, 33772, 7736, 264, 11408, 537, 39802, 295, 257, 6374, 3479, 457, 294, 51236], "temperature": 0.0, "avg_logprob": -0.09618952667828902, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.005727576091885567}, {"id": 160, "seek": 96628, "start": 983.72, "end": 988.6, "text": " a much more lightweight format. It doesn't carry all the baggage of a virtual machine. A common", "tokens": [51236, 257, 709, 544, 22052, 7877, 13, 467, 1177, 380, 3985, 439, 264, 41567, 295, 257, 6374, 3479, 13, 316, 2689, 51480], "temperature": 0.0, "avg_logprob": -0.09618952667828902, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.005727576091885567}, {"id": 161, "seek": 96628, "start": 988.6, "end": 993.24, "text": " metaphor used to distinguish between Docker containers and virtual machines is if you think", "tokens": [51480, 19157, 1143, 281, 20206, 1296, 33772, 17089, 293, 6374, 8379, 307, 498, 291, 519, 51712], "temperature": 0.0, "avg_logprob": -0.09618952667828902, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.005727576091885567}, {"id": 162, "seek": 99324, "start": 993.24, "end": 998.36, "text": " of a virtual machine as a house with its own plumbing, Docker is like an apartment that's a", "tokens": [50364, 295, 257, 6374, 3479, 382, 257, 1782, 365, 1080, 1065, 39993, 11, 33772, 307, 411, 364, 9587, 300, 311, 257, 50620], "temperature": 0.0, "avg_logprob": -0.08980921203014898, "compression_ratio": 1.750915750915751, "no_speech_prob": 0.0031223029363900423}, {"id": 163, "seek": 99324, "start": 998.92, "end": 1004.2, "text": " member of a large apartment complex that shares this plumbing and other infrastructure with the", "tokens": [50648, 4006, 295, 257, 2416, 9587, 3997, 300, 12182, 341, 39993, 293, 661, 6896, 365, 264, 50912], "temperature": 0.0, "avg_logprob": -0.08980921203014898, "compression_ratio": 1.750915750915751, "no_speech_prob": 0.0031223029363900423}, {"id": 164, "seek": 99324, "start": 1004.2, "end": 1011.88, "text": " other apartments. Writing a Docker file is kind of like creating a recipe or playbook that declares", "tokens": [50912, 661, 29056, 13, 32774, 257, 33772, 3991, 307, 733, 295, 411, 4084, 257, 6782, 420, 862, 2939, 300, 979, 19415, 51296], "temperature": 0.0, "avg_logprob": -0.08980921203014898, "compression_ratio": 1.750915750915751, "no_speech_prob": 0.0031223029363900423}, {"id": 165, "seek": 99324, "start": 1011.88, "end": 1016.92, "text": " all of your application's system and software dependencies and how they should be wired together", "tokens": [51296, 439, 295, 428, 3861, 311, 1185, 293, 4722, 36606, 293, 577, 436, 820, 312, 27415, 1214, 51548], "temperature": 0.0, "avg_logprob": -0.08980921203014898, "compression_ratio": 1.750915750915751, "no_speech_prob": 0.0031223029363900423}, {"id": 166, "seek": 99324, "start": 1016.92, "end": 1022.76, "text": " for a successfully running application. We don't have time to go into Docker in depth in this", "tokens": [51548, 337, 257, 10727, 2614, 3861, 13, 492, 500, 380, 362, 565, 281, 352, 666, 33772, 294, 7161, 294, 341, 51840], "temperature": 0.0, "avg_logprob": -0.08980921203014898, "compression_ratio": 1.750915750915751, "no_speech_prob": 0.0031223029363900423}, {"id": 167, "seek": 102276, "start": 1022.76, "end": 1034.52, "text": " presentation. I'd be happy to discuss further offline. To recap, always make sure you budget the", "tokens": [50364, 5860, 13, 286, 1116, 312, 2055, 281, 2248, 3052, 21857, 13, 1407, 20928, 11, 1009, 652, 988, 291, 4706, 264, 50952], "temperature": 0.0, "avg_logprob": -0.07055848072736691, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.0010480665368959308}, {"id": 168, "seek": 102276, "start": 1034.52, "end": 1039.8799999999999, "text": " time needed to properly describe your computational artifacts, ideally in machine-readable ways and", "tokens": [50952, 565, 2978, 281, 6108, 6786, 428, 28270, 24617, 11, 22915, 294, 3479, 12, 2538, 712, 2098, 293, 51220], "temperature": 0.0, "avg_logprob": -0.07055848072736691, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.0010480665368959308}, {"id": 169, "seek": 102276, "start": 1039.8799999999999, "end": 1046.44, "text": " automated. Just like gardening or cleaning, continuous and incremental work with forethought", "tokens": [51220, 18473, 13, 1449, 411, 31799, 420, 8924, 11, 10957, 293, 35759, 589, 365, 2091, 43135, 51548], "temperature": 0.0, "avg_logprob": -0.07055848072736691, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.0010480665368959308}, {"id": 170, "seek": 102276, "start": 1046.44, "end": 1050.68, "text": " and planning is much easier to manage than leaving everything to the end and trying to", "tokens": [51548, 293, 5038, 307, 709, 3571, 281, 3067, 813, 5012, 1203, 281, 264, 917, 293, 1382, 281, 51760], "temperature": 0.0, "avg_logprob": -0.07055848072736691, "compression_ratio": 1.5537190082644627, "no_speech_prob": 0.0010480665368959308}, {"id": 171, "seek": 105068, "start": 1050.68, "end": 1055.8, "text": " tie all the loose ends. Automating your computational pipelines as much as you can and", "tokens": [50364, 7582, 439, 264, 9612, 5314, 13, 24619, 990, 428, 28270, 40168, 382, 709, 382, 291, 393, 293, 50620], "temperature": 0.0, "avg_logprob": -0.09826482907690183, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.004980748984962702}, {"id": 172, "seek": 105068, "start": 1055.8, "end": 1061.24, "text": " whatever changes you can automate, well those should just be clearly described and documented.", "tokens": [50620, 2035, 2962, 291, 393, 31605, 11, 731, 729, 820, 445, 312, 4448, 7619, 293, 23007, 13, 50892], "temperature": 0.0, "avg_logprob": -0.09826482907690183, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.004980748984962702}, {"id": 173, "seek": 105068, "start": 1061.24, "end": 1067.0, "text": " Lorena Barba is very adamant about automation but I think to start with just being explicit", "tokens": [50892, 36994, 629, 4156, 4231, 307, 588, 16368, 394, 466, 17769, 457, 286, 519, 281, 722, 365, 445, 885, 13691, 51180], "temperature": 0.0, "avg_logprob": -0.09826482907690183, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.004980748984962702}, {"id": 174, "seek": 105068, "start": 1067.0, "end": 1073.8, "text": " and documenting what you've done is a good enough first step. Good code-based management practices", "tokens": [51180, 293, 42360, 437, 291, 600, 1096, 307, 257, 665, 1547, 700, 1823, 13, 2205, 3089, 12, 6032, 4592, 7525, 51520], "temperature": 0.0, "avg_logprob": -0.09826482907690183, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.004980748984962702}, {"id": 175, "seek": 105068, "start": 1073.8, "end": 1078.52, "text": " and archiving your computational models in ways that facilitate reproducibility and reuse is", "tokens": [51520, 293, 3912, 2123, 428, 28270, 5245, 294, 2098, 300, 20207, 11408, 537, 39802, 293, 26225, 307, 51756], "temperature": 0.0, "avg_logprob": -0.09826482907690183, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.004980748984962702}, {"id": 176, "seek": 107852, "start": 1079.08, "end": 1083.96, "text": " not really the goal in and of itself but it's a critical step for those of us that use computation", "tokens": [50392, 406, 534, 264, 3387, 294, 293, 295, 2564, 457, 309, 311, 257, 4924, 1823, 337, 729, 295, 505, 300, 764, 24903, 50636], "temperature": 0.0, "avg_logprob": -0.06077217354493983, "compression_ratio": 1.541899441340782, "no_speech_prob": 0.010005387477576733}, {"id": 177, "seek": 107852, "start": 1083.96, "end": 1088.36, "text": " as virtual laboratories. It helps us to better evaluate and build on each other's work", "tokens": [50636, 382, 6374, 41013, 13, 467, 3665, 505, 281, 1101, 13059, 293, 1322, 322, 1184, 661, 311, 589, 50856], "temperature": 0.0, "avg_logprob": -0.06077217354493983, "compression_ratio": 1.541899441340782, "no_speech_prob": 0.010005387477576733}, {"id": 178, "seek": 107852, "start": 1089.6399999999999, "end": 1094.2, "text": " and it's just the right thing to do if we want to be able to move forward as a discipline.", "tokens": [50920, 293, 309, 311, 445, 264, 558, 551, 281, 360, 498, 321, 528, 281, 312, 1075, 281, 1286, 2128, 382, 257, 13635, 13, 51148], "temperature": 0.0, "avg_logprob": -0.06077217354493983, "compression_ratio": 1.541899441340782, "no_speech_prob": 0.010005387477576733}, {"id": 179, "seek": 109420, "start": 1094.2, "end": 1101.32, "text": " I hope this presentation has been useful and thanks for your time.", "tokens": [50396, 286, 1454, 341, 5860, 575, 668, 4420, 293, 3231, 337, 428, 565, 13, 50720], "temperature": 0.0, "avg_logprob": -0.3200799226760864, "compression_ratio": 0.9850746268656716, "no_speech_prob": 0.1361742615699768}], "language": "en"}