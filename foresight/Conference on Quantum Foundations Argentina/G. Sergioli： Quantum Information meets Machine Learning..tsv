start	end	text
0	9840	Okay, we'll start with the second part of the first session this morning.
9840	17280	The first talk is in charge of Schubert Cercione from the University of Caglione.
18560	24480	Thank you, thank you very much and thank you to all the organizers who invited me. For me it's
24480	31520	very proud and very proud to be invited to this 10th conference of Quantum Foundation.
32080	41280	I'm very happy to be part of this very prominent panel of scientists. I warmly thank all the
41280	49600	organizers and especially Federico Olic and Martin Bosic, who are also a strict friend of
49600	57600	Italian University and of Cagliari and also personal friends. So what I want to introduce
57600	64800	here is Quantum Information Meet Smashing Learning. So basically I like to introduce
64800	73280	generally this topic by starting from a provocative question. I ask you, can you show me a picture
73280	84800	of your Christmas 2018? I am sure that you can and I am sure that if you try to find a picture
84800	90960	of your Christmas, for instance in your mobile, you will find it but probably you need time to
90960	98800	find it just because now we use to make a lot a lot of pics with our mobile because the memory
98800	108720	that our mobile has now is very, very huge and many, many pics can be kept, can be considered,
108720	121760	can be stored in a cell for instance in a mobile. So what we can say is that we can,
121760	130000	can we say that many data corresponds to many information? Basically not because information
130000	139200	means recover from the data what we really need. So the fact that now we have to deal with a very,
139200	146800	very huge amount of information means that potentially we can have a lot of information
146800	154960	but the problem is the process we need to do in order to extrapolate this information
154960	166560	from this big amount of data. So this is the reason why in the last decades big data science
166560	174880	corresponds to face with just this kind of process, this kind of problem and so the problem is how
174880	183680	to manage huge amount of data in order to retrieve in the short time as possible the information
183680	191680	we need, the information we need. Okay so this is why big data born in the in the in the last
191680	197760	decade. So this is just a very brief summary of what I said in these five minutes. So in other
197760	204000	words, enlarging the dimension of the data set is a good thing because it increases the potential
204000	210000	information but it's also bad because it makes the extraction of the required information out.
211040	219600	So from another side you know very well that you know very well how quantum information
220320	226720	born, how quantum information became in the recent past a really new discipline of
230720	236080	quantum theory in general, quantum computing mostly, and we know that the advantage of
236080	243360	quantum computation are most of the the advantages are most of all based on the fact that we have
243440	247600	a speed up of the computation. We can obtain, we can
250000	256800	perform a computer and strong and hard computation in a very very shorter, a shorter time
256800	268240	with respect to a classical, a classical one. Okay so so we know also that quantum computation
268240	276480	is not so futuristic. We can say that till 10 maybe 20 years ago we were speaking about
276480	282720	quantum computation as something that was phantasyntific, that was not really concrete,
282720	290480	but we know that the application in quantum computation has a very very speed up in the
290480	296880	last in the last decade and now we know that the quantum processor already exists and we know
296880	304560	that also by using for instance our our computer in our house we can connect with the IBM quantum
304560	311680	experience and we can just design a quantum algorithm and by a click we can send this
311680	319600	quantum algorithm to a real quantum computer that will perform it, that will give us back the result
319600	328160	as a as a statistical result. So basically the quantum computation is now real, is now real
328160	337360	and also we know that this this topic is is going on and on and for instance just one year ago,
337360	343600	just one year ago in in china that was there was was declared that the
343600	349520	achievement of quantum supremacy because it was possible to perform a calculation in
350560	358000	200 seconds, a kind of calculation that will take more than half a billion years on the
358000	366320	world's faster, no quantum or classical computer. So now we really trust in quantum computation,
366320	373440	we really trust in this. So we were speaking about the data and about quantum computation
373840	379760	but because well summarizing the main problem of big data when machine learning with big data
379760	385360	is the time complexity of the computation but the main advantage of quantum computation is
385360	392640	the possibility to reproduce to use the time complexity. So in a certain sense,
392640	399120	quantum computation and machine learning appears as a very natural and maybe unavoidable,
399120	407840	unavoidable connection but the connection can be deeper and deeper with respect to what we can
407840	415520	think. Indeed the question that they want to ask you in this in this talk is can quantum
415520	424240	information theory help classical machine learning, classical by using classical computer only
424240	431360	and we will provide a positive answer to this question. So this approach that we will speak
431360	439440	is known as a quantum-inspired machine learning and the important thing is that well very often
440720	450320	we know that in many disciplines we speak about the inspiration from quantum mechanics.
450320	457600	Okay now what I want to focus on is the fact that our inspiration is not just an analogy,
457600	466480	it's not a metaphor but it's just a really inspiration regarding a real inspiration to quantum
466480	475920	work in order to have a real benefit in machine learning and in the next minutes I aim to show
475920	484800	you what they mean by real inspiration. Okay in particular we focus on the classification problem.
484800	491120	What is the classification problem? Okay the general idea is that the quantum classification
491120	497440	in the idea that we want to perform is the idea of a quantum classifier where quantum
497440	501760	classification is the idea of quantum classification is to formalize the standard
502480	508000	classification problems in terms of the mathematical quantum object and then
508640	514480	inspired by certain properties of quantum state discrimination we define a quantum
514480	522000	classifier that will provide interesting and real good advantages. The procedure is
522000	528640	based on three fundamental steps that we will describe not now but a few slides later encoding
528640	535600	classification and the coding but we will meet this slide again in a bit. First of all
536960	540000	I want to very very quickly summarize what is the
542080	548400	sorry the general framework of classification problem. So when we have to classify an object
548400	557280	we describe this object as a vector where each component of this vector is a feature of this
557360	565520	object like this object could be a cat and this feature could be the length of the tail,
566080	572640	the weight of the cat and so on and we have different classes of objects for instance
572640	580240	dog and cats and what and so on and this so a pattern is represented by a pair where this is
580240	586720	the vector the object represented by a vector and this is the label that characterized the class
586720	593760	for instance class for instance label one means class of the cat, label two means class of the
593760	601040	dogs for instance okay and the goal of the classification is to have a classifier
603280	615360	I mean a function classifier is a function that allows us to study the vector and gives as an output
615360	623760	the label so looking at the vector looking at the object I can say you if this object is a cat or is
623760	633520	a dog basically okay okay okay so in a general supervised scenario I will be very very very
634320	641920	I will skip many slides but but sometime I can focus on some technical data sometimes not
642000	651600	generally generally in what we say supervised learning we mean that we consider a data set
652160	660640	for instance a data set of dogs and a data set of cats for instance and we divide this data set
660640	667520	at the beginning in two parts the first part is given by the training set this is the set
667520	675520	useful in order to train our algorithm and this is the test set but the set is a set of
675520	683600	object that we use in order to know whether our algorithm is good or not just in order to know
683600	693600	just in order to measure the performance of our algorithm and so obviously then all of these
693680	700240	objects are already labelled so we already know the level of the object so the goal is just to
700240	710320	evaluate how the right if the classifier is good or not so we use a already labelled set of object
710320	716640	we divide it in training and test and obviously also the training is divided with respect to the
716640	724480	classes the classes will get the classes of dogs the classes of foxes and so on and so on okay so
725200	734800	the the first idea of the quantum classification is just to translate formally translate each
734800	743120	object each vector each cat that is represented by a vector in terms of a quantum object that we
743120	749920	represent by a density operator row and there are many many ways to encode this is just encoding to
749920	758720	encode a real vector in terms of the quantum object okay in terms of a density operator obviously
758720	767440	it is only a formal translation we are not transforming a cat in a photon or a dog in
767440	778160	an electron obviously okay so now once we have translated all the data set of real data in terms
778160	787280	of the data set of quantum data or quantum data again we can consider the distinction between
787920	797680	training and test training and test again and the idea is just to obtain a quantum classifier
797680	806800	that is a function that has as input a quantum object of the quantum test set and has the
806800	815360	output level so given this quantum object that is the density operator that represents an unknown
815360	824400	object we can say that we can we can obtain by the classifier that this object is a dog okay so
825040	832560	obviously what we have to show is that this translation from classical to quantum object
833120	838960	has some benefit provides some benefit otherwise it's totally useless okay so okay
839040	849040	now let us talk regarding the general setting in quantum state discrimination okay that probably
849760	858080	most of you already know but I very briefly summarize here let R be a set of density operator
858080	864000	and suppose that Thelis wishes to communicate information to Bobo by using a quantum system
864000	872720	that is one of the system belonging to this state okay to the same Thelis prepares a quantum system
872720	882800	in one of this state in one of this state and hands the system over to Bobo in principle Bobo has
882800	893520	a complete knowledge about R so Bob knows in knows already knows which are row one row two row
893520	903920	M but he does not know the actual state of the system that he have received by Thelis so in order to
903920	915120	so that the Bob's task is to determine which one is among this state in one shot just by making a
915120	926240	single von Neumann measurement over all possible sorry or possible physical observable so there
926240	934400	and so the possibility is that the measure the outcome of the measurement could be just the
934400	941840	row that Thelis sent to Bob or not or can be another one in the first case okay we say that Bob
942400	951520	succeeds in another case we say that Bob fails okay so what is the probability for Bob to
951520	959440	succeed okay given a set R or quantum state and a von Neumann measurement M the average
959440	967520	probability to Bob for Bob to perform a correct discrimination so to correct individuate which
967520	975760	is the state that was sent from Thelis is given by this quantity is given by this quantity and
976720	987200	the aim of course is the maximize maximize this probability so to minimize the probability to
987200	996160	have an error okay so the question is what what is the measure the measure that maximize the
996160	1002880	probability to have the correct discrimination and this measure this measure was obtained by
1003840	1012560	by this strategy okay the strategy is is related only to the binary case so consider to have just
1012560	1021520	row one and row two and if we consider this quantity p1 row one minus p2 row two where p1
1021520	1029760	and p2 are a priori probability okay that can be obtained in some different but empirical way for
1029760	1036880	instance we obtain this quantity we calculate the positive and negative eigenvalues of this
1036880	1045760	quantity we consider the respective eigenvectors and we consider the sum of the projector built
1045760	1053360	over all of each of these eigenvectors in this way we can obtain p plus and p minus
1053920	1061520	and hence from showered that this p plus and p minus is a von Neumann measurement that is optimal
1061520	1068000	that is the optimal measure for the discrimination problem for the binary discrimination problem
1068000	1075200	that we have introduced at the moment so this is the this is the bound this is the bound and
1076160	1082480	intuitively p plus and p minus represent the property for the system to be correctly
1082480	1089760	identified as being the state row one or row two respectively okay and that's from bound can be
1089760	1097840	seen as a measurement of distinguishability between row one and row two so now again with
1097840	1105920	this light because now we have all the ingredients we need in order to put together this discrimination
1105920	1113200	not to put together classification problem and quantum state discrimination the first stage
1113200	1121760	is the encoding we say that we need to have real object and translate the real vector and translate
1121760	1128880	them in terms of quantum object like a density operators like a pure states and for instance
1128880	1135520	it is easy to see because there are several way several way to do this this is one simple way for
1135520	1146160	instance by using the stereographic projection we map each object in this simple case two feature
1146160	1153840	object in a point over a sphere and of a surface one sphere and that's correspond to the point of
1153840	1161680	the block sphere so a pure density matrix a pure state a pure state but there are many other
1161680	1169680	possibilities to encode real object in terms in terms of density matrix pure density matrix okay
1169680	1179600	so once we do that once we have set of quantum states set of density operators
1180240	1188240	for each training set we for each training set for each class of the training set we we represent
1188240	1195280	each class by a quantum centroid that is defined in this way this is just the beginning of our
1195360	1203040	orbit and it is no longer a pure state of course because it is just the sum of all of the state
1203040	1210400	of all the encoded vector belonging to a to a given class to a given class okay obviously the
1210400	1216480	quantum centroid are mixed states are mixed states and they are not the encoding of the
1216480	1222160	respective classical centroid they are a totally new object a totally new object that
1222160	1229920	has not any counterpart in the real world in the world of real object in the world of real vectors
1229920	1240640	okay okay so now we use quantum state discrimination we use the Elstrom measurement
1240640	1248720	that is optimal so we use p plus and p minus that we built we built by considering
1252160	1260000	as the two states to discriminate we will consider the two centroids so let us consider
1260000	1266960	a case where we want to discriminate between cats and dogs we consider the training set of the cats
1267600	1274400	we are encoding this set in terms of quantum object we consider this you can see that the
1274400	1280800	centroid of this class we do the same for the dogs and we have these two centroid these two
1280800	1288160	quantum centroid these two quantum centroid define the finding are two density operator
1288160	1294560	and from this from these two quantum centroids we can apply the Elstrom
1297360	1304400	discrimination and we cannot take the Elstrom measurement the optimal Elstrom measurement
1304400	1315520	p plus and p minus okay so once we pick another quantum object from the test set we have to do
1315520	1322480	we have to say okay this quantum object is a set or is a dog in order to determine if this
1323280	1330000	we consider this classifier that is called the Elstrom quantum classifier we consider
1330960	1342080	these two values if the trace of p plus times rho is greater than p minus times rho we say that
1343040	1352080	in a certain sense rho x is closer to the centroid of the cat otherwise rho x is closer to
1352080	1361520	the centroid of of the dog and so we can make a really a proper classification a proper classification
1361520	1370320	okay why we use quantum state discrimination what is the intuition that that is above this idea
1370880	1376240	the application of quantum state discrimination for classification is inspired by the idea that
1376880	1385040	better is the discrimination between two centroid and better I can distinguish between two classes
1385040	1393120	and so more performance is the classifier in other words greater is the Elstrom bound that
1393120	1398080	remind me I said it is that can be considered as a measurement of distinguishability between two
1398080	1405360	centroid and greater would be for instance the accuracy of the classifier where the accuracy
1405360	1414480	means just the number of times that the classification was correct over the number of total over the
1414480	1424320	total number of experiments okay okay this idea is not only an intuitive idea but that was just
1425280	1436000	exploited that was just proven by an experiment so we have provided an experiment where this
1436000	1447760	classifier has been applied to 40 different data sets and compared with 11 different and
1447840	1454560	general well-performing classifier standard classifier for instance what we can see is that
1454560	1461680	generally generally once the Elstrom bound increase the Elstrom bound increases
1462400	1469760	together with the increasing of the balance of accuracy so this idea seems to be correct
1469760	1476240	that increasing the measurement of distinguishability between two centroid it
1477360	1484320	is together with the increasing of the accuracy of the classifier so this intuition is corroborated
1484320	1491040	by the experience is corroborated by the experience and okay we have many data when we
1492000	1500000	perform it when we compare this classifier is Elstrom classifier with many standard classifier
1500000	1509360	and we show that our classifier is generally better not always not always but okay the average
1512160	1520960	performance of the quantum inspired classifier is very very high with respect to the others
1520960	1527360	standard classical classifier okay now I have many data to show but okay this is
1528240	1535440	just a comparison okay are we okay in these data in these tables you can realize these
1538320	1545200	I don't say supremacy but something like this of our Elstrom classifier with respect to the other
1545280	1551200	but that's not all that's not all indeed a sharp difference between classical and quantum
1551200	1558480	information theory is also based on the fact that sometime made considering a tensor copy
1558480	1565600	of an object can provide a benefit in our computation can provide let's say a kind of
1565600	1572560	additional information with respect to the original information that is given by the
1572560	1581120	initial single state so what we do is just repeat exactly the same algorithm that I have described
1581120	1589440	you above before but by considering but off after the encoding after the encoding instead of the
1589440	1596320	density operator raw the time obtained from the encoding by the encoding from the initial
1596320	1604480	object instead of this row I consider all times itself and times I calculate a new centroid
1604480	1613120	and I define again a new classifier in a new Elstrom of several in the new dimension has been a new
1613120	1621920	k dimensional space in a new larger space and again I define a new Elstrom quantum classifier
1622800	1632160	let's say k tensor product Elstrom quantum classifier what we see what we see is that by increasing
1632160	1639680	the number of the copy also there's strong bound increase and so we see that the accuracy that
1639680	1646960	we obtain after making this copy this copy in a just in a computational way just by making
1647360	1655040	a in bi-mathematica okay or by fighting this copy but what we see is that by making this
1655040	1663600	procedure we have benefit because we increase the accuracy of the of the process we increase
1663600	1672000	again the accuracy of the process okay and again we have data to to show okay we have something but
1672000	1681040	okay I want to use just the last five minutes talk maybe to show you a practical experiment
1681040	1689760	a practical experiment that was provided together with the University of Cambridge and the Institute
1689760	1698320	of Molecular Bioimaging of the University of Catania and the topic is a chronogenic essay
1698320	1705600	the chronogenic essay is a quantification technique of the survival degree of an in vitro cell
1705600	1712720	cultures which is based on the ability of a single cell to grow and form a colony of cell
1712720	1719440	this colony is not a good thing that is a symbol of something with a of something
1719440	1726480	disease something great disease the purpose is to count the number of their colonies so
1726560	1732960	the picture that we are today like picture like this where this is a colony this is a colony
1732960	1742320	this is a colony and so on okay recent results show how bi-classification between pixel x
1743920	1751040	belongs to the colony or pixel x belongs to the belongs to the background by making this
1751040	1757520	classification it is possible to have information about the number of of the colonies there is a
1757520	1766080	correlation between this this is a biological result in a in a in a quantum imagine and biology
1767920	1776160	fields that this result but it is it is an assist for us because it allows us to move
1776160	1783200	the chronogenic essay in a binary classification context so for each pixel if we are able to
1783200	1790800	classify if this pixel is in the colony or it is in the in the background we can have some result
1790800	1799520	regarding the number of the code that is in the chronogenic essay and so you have 10 minutes
1799600	1807040	including the question okay so just I thank you I just spend a few minutes to conclude
1807040	1816240	and I and I leave a few minutes also for four questions okay okay so the experiment
1816240	1823520	involved with the many many many data about 10 millions of data and the result that we had
1823520	1830160	was against that the performance of our elstrom classifier with respect to other in this case
1830720	1838080	18 well-performance classifier is very good because our classifier in most of the cases
1838080	1846080	was one of the best one of the best with respect to to the other and that was very very nice for us
1846080	1853600	so let me conclude with some open problem okay the first open problem is the is this
1854560	1861440	the generalization of this quantum is pirate quantum is pirate and now we know why I say quantum
1861440	1867040	is pirate and now we know why I really say that this this inspiration is useful it's not only
1867040	1875520	a matter of metaphor but this quantum inspiration was based on only a binary quantum state discrimination
1876400	1884400	so the challenge is to have a multiclass classifier a multiclass classifier and the second goal
1884400	1893440	should be just to use this quantum inspired algorithm also in a quantum computer just in order
1893440	1902960	to come from one to be spirited to one so we have some partial result regarding both of these
1903520	1911120	this point and basically regarding the idea of multiclass classifier we are working on this but
1912080	1920640	we are we are taking inspiration from the pretty good measurement that is not an optimal but
1920640	1930080	sub the optimal measurement that allows us to have a multi a quantum multiclassifier
1930960	1937680	and on the other hand well I am not time to show you the detail of the pretty good
1937680	1943280	classifier but the idea is the same but instead of to have an optimal we have a sub optimal
1943280	1951840	measurement but but also we this sub optimal measurement can be used for any classification
1951840	1959760	instead of only binary classification and also the final challenge as I said is just to
1961040	1968720	come from a quantum inspired to really quantum machine learning in order to put together the
1968720	1974880	double benefit of quantum so increase the accuracy but also speed up the computation
1975520	1982080	well by appealing to the neomarks deletion theorem is it possible in principle to reproduce
1982080	1988560	and POVM measurement and for instance also the health strong of the pretty good measurement
1988640	1995600	this is an this is an example but we are working on this and till now we have only only partial
1995600	2004480	result regarding this but the works are still in progress and okay this is the the bibliography
2004480	2012080	that the reference that you can refer to and okay thank you all for listening thank you
2012640	2022480	okay thank you Shusepe for your interest in talk now we have some minutes
2024800	2029840	questions and comments if you want to make a question please
2029840	2039120	and I have a little question
2043040	2050960	for your future but do you know if there is a mathematical relation between the
2050960	2062880	hand strong bound and the accuracy of your classifier okay so yes are you asking if
2063680	2067200	there is a connection between a strong bound and accuracy
2069840	2076000	right okay well basically not basically not because it's very strange because
2076960	2084400	there are really two topics that are that was never merged together between with within
2085680	2093440	before now because in a certain sense health strong was not thinking about the classification
2093440	2099280	problem so in a certain sense health strong well quantum state discrimination
2100000	2108000	and has not the idea of what is the accuracy because the accuracy could be calculated empirically
2108000	2117200	empirically only by making the experiment what the what the theoretically we have is this result
2117200	2124160	is this result that is interesting regarding that strong bound and it is easy to misleading
2124240	2132160	because easy to misleading because we are not saying that if okay we are not saying this
2132160	2138880	that strong bound between two states is less of that strong bound between the states
2138880	2144560	that you obtain by making the tensor copy of itself by itself because in this case it is
2145360	2152400	an already well known result here we are saying this something different because this object
2152400	2165600	our quantum centroid this tensor k row is not row times row times row k times k times it is
2165600	2176000	something different is the centroid that we obtain by making in principle k copies of each
2176000	2184800	object of the data set and after making the centroid so in a certain sense this is a first
2184800	2192480	let me say that theoretical result that put together quantum state discrimination and
2192480	2198000	classification problem because there is the idea of centroid and there is the idea of
2198000	2207360	a strong bound put in together i hope to answer to your question thank you very much welcome
2210000	2211600	another question or comment
2214160	2220000	if not thank you again for your talk thank you all thank you
