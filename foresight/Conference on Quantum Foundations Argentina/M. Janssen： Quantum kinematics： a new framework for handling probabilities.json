{"text": " Okay. Okay, welcome to the second part of the conference of this day. The first talk of this session is in charge of Michael Jensen from the University of Minnesota. The title of the talk is quantum kinematics. A new framework for handling probabilities. Go on, Michael. Okay. Thank you very much for the invitation. Everybody can see my screen. I hope you had a chance to read my abstract. So what I'll be doing for the most part is to talk about the correlations you can get with the proverbial Alice and Bob performing measurements on two spin half particles entangled in the singlet state. And I'll represent the class of correlations that you can get in that kind of, like I should say, in a setup that was suggested by David Merman, where Alice and Bob both choose from the same three observables that they're going to measure. And I'm going to be looking at the kind of correlations that are allowed in that setup, if you just restrict it to like anything that's non-signaling, anything that can be done quantum mechanically, and anything that can be done like with local hidden variable theories. And I'll show you that there is a nice three-dimensional graphical representation of that. So the work is based on a book that I wrote with Michael Janus and Michael Faro. So here is the three of us, like in Minneapolis a few years ago. And since the names of the three of us are sort of variations on Michael, like this has become known in certain circles already as the three mics manifesto. The book will come out in January. It's in the series Boston Studies in the Philosophy and History of Science. And its official title is Understanding Quantum Raffles. Now the book was inspired, and this is the banana that you'll be seeing as my background image throughout the talk, by this book by Jeff Boop, Banana World, Quantum Mechanics for Primates. And here you see a picture of me and Jeff at a conference in 2019, like in Santiago, like following actually right this conference in Cordoba in 2019, where I also gave the talk and had a great time. So I should also like put in a plug for like the sequel to Banana World, which is one of my favorite books. It's a serious comic on entanglement by Jeff and his daughter Tanya, a graphic artist called like Totally, Totally Random. So here's the set up I want to talk about. And so instead of talking about spin half particles, I'm going to be talking about like entangled bananas, like I said, in honor of Jeff's book. And so what we have, we start out with like a pair of entangled bananas, right? So they are described by the usual, you know, singlet state. And then like Alice and Bob, you know, the side like on one of three ways to peel the banana. And so this is basically just window dressing for like, you know, they have, they have like a Dubois magnet with which they measure spin in a certain direction. And now they're going to hold their banana in a particular direction, you know, while peeling it. And then they take a bite out of the banana and determine whether the banana tastes yasta, tastes yummy, or nasty, right? So and the results are we're going to, we're going to put like in a correlation array, which is really the workhorse of Jeff's book, Banana World. And so here you see like, you know, Alice can measure A, B and C, Bob can measure A, B and C, they can only find, you know, plus or minus corresponding to yummy and nasty. And what you see is that if they happen, all the runs in which they happen to peel the same way, they find like a perfect impact correlation, and in all the runs in which they peel different ways, they find like an imperfect, like positive correlation, right? So look at A, B. So there is like, you know, like a three fourth chance of them finding the same 75% chance of finding the same, and only a 25% chance of them finding opposite. And the question is like, you know, like, what's how to, how to account for this? Now, so this is like what you get in this Merman setup, if the angles between like the peeling directions are like 120 degrees. Now, you can consider like a more general correlation array of this sort. And we're going to consider like, you know, any array that would like this, that would be non signaling, right? And in order to guarantee non signaling, if you have these anti correlations, like on the diagonal, it has to be the case that you get uniform marginals. And you do that by making sure that in all the off diagonal cells, the sum of both the two rows and the two columns is equal to a half, right? And so since the probabilities, of course, also have to be like numbers between zero and one, you get that you can parameterize this by these chi's that I have here, and these chi's can run for all the way from minus one to plus one, right? And so I can characterize this correlation array by having three of these parameters for three of these cells, right? This thing is also going to be symmetric. It doesn't matter if you switch like A and B. So that's the story here. And you see that in the special case that is considered by Merman, that these chi values are equal to minus a half, right? So stick that in here. If you put in like minus a half, like this would be, you know, three halves. So this would be three eighths, right? And this would be, you know, like, you know, one eighth, right? So you recover that, you recover that Merman's correlation array. But again, like, you know, you, you, this is a more general form of it. Now, what we're going to try and do is to see like how, like what subclass of those correlations we can simulate, like with a raffle, right? And the raffle is our toy model for a local hidden variable theme. And so we have, we imagine that you have a basket with a bunch of tickets in it, and the tickets like half the outcomes for like all possible measurements that Alice and Bob can do. Now look at the first ticket, like, you know, we know that if they, if they measure the same way that they find opposite results, right? So like, you know, the results on two halves of the tickets have better be up, has better be opposite. The way it works is that you take a ticket, you rip the ticket in half, and then you randomly decide like which one goes to Alice and which one goes to Bob, right? So a ticket where you just switch the left and the right side does not give you a, this does not give you a new ticket. So with that said, there is like four different tickets, right? So it doesn't have to be the case that all the pluses are on one side, you could have a case where two of the pluses are on one side. And like, you know, with one minus, and again, there is three ways of doing this, right? So you have the minus here is for C here, the minus is for B, and here the minus is for A, right? And again, keep in mind that it doesn't matter which side of the ticket you're looking at. Now, we can easily see like if you had like single ticket raffles, just like a basket with one type, what these sky parameters would be, you know, for your correlation array. Because you can see that if you have this ticket, no matter whether you take like AA, AB or AC, you always have like a perfect anti-correlation. And that means that these sky values have to be like plus one. Like maybe I should go just like back here, right? So the moment that chi is plus one, right, then you see you have an anti-correlation, the moment that chi is minus one, you have like a perfect correlation. So okay, so that's easy. Now look at this ticket, there's a little more complicated. So for AB, you see that there's still a perfect anti-correlation. But if you now look at AC or at BC, you see that there's a correlation. So you have minus one. And the same is true for C and D, right? It's just that a different parameter will get like the plus and the other two parameters will be minus. And here then you immediately have like a bell inequality of the type of the Klauser-Hornschirmann Holtz variety. And you can see that, you know, like the sum of these three parameters is three, four ticket A, and it's going to be minus one for all other tickets. So if you take like an arbitrary mix of tickets, right, you would always get like a value somewhere between minus one and three. So and you see that Merman's example where chi, where these three chi's are minus a half. So that would be, if your sum would be minus three halves, violates this inequality. Now, the nice thing about this is that you can come up with a very nice geometrical representation of the situation. And that is essentially due to Jeff's long-time collaborator, now deceased, unfortunately, Idemar Petovsky. And so first of all, we start out with like, you know, like representing these chi values, they can run from minus one to one in like what is called like a non-signaling cube. Remember, like, you know, this was like the general form of a correlation array that is non-signaling. And you see that these tickets, like they're represented now by vertices of that non-signaling cube, right? So it's these four points, right, A, B, C, and D. And a mixed raffle would be represented on like points that are like somewhere in between, right? And once you have, so imagine, like, you know, you have your basket with tickets. So if you take this and this and you put a certain mix, you can end up somewhere over here, but then you take a mix of like, you know, D and C, you get somewhere over here, but you can also like, you know, now mix those, right? So you get all of that, and you can also like mix and match, mix and get like on the inside of this thing. So this is like what is known as the classical tetrahedron. And this is like a very nice way of geometrically representing, you know, what the local hidden variables here we can do. The bell in the quality only corresponds to like one facet of this tetrahedron. It just says that you can't be behind that plane like B, C, D, but you see that there are three other forbidden regions that you would also have to spell out if you want to define fully, you know, what is and what is not allowed. All right. So now in what is allowed by quantum mechanics, right? And so in quantum mechanics, the the result that is predicted by quantum is that these kais are just given by the cosine of the the peeling angle, right? In a way, this is like very satisfying, right? So classically, you see that these kais with these tickets, they're always going to be plus one or minus one, but wouldn't it be nice to have like a theory that just allows like a like a continuity of values between minus one and plus one? Quantum mechanics gives you just that, right? And so it's the cosine of the of the angle and that cosine, of course, is the inner product of like unit vectors in these different peeling directions. All right. So if you think about this correlation array, you see that the entire correlation array can be like characterized by by these parameters, right? These sky parameters. And we can also introduce them for the for the for the diagonal cells, where they're just one. Okay. So and so we'll I'll I'll define this more carefully later on. But these guys are like, you know, what what can be called like anti correlation coefficients. As for now, it's just hinges on three values, right? If chi is one, we saw you have a perfect anti correlation. If it's minus one, you have a perfect correlation, right? So it makes sense that the anti correlation coefficient is then minus one. If chi is zero, you have no correlation at all. Now look at introduce now like a matrix, an anti correlation matrix of just these chi values. And you can write that again, like in in terms of these inner products of these unit vectors. Now, this is a grand matrix, right? And it's a well known property of the of the grand matrix. It doesn't take too much to verify this. But in the interest of time, I'll skip that. We know that the determinant of that of that matrix is going to be it's going to have to be greater or equal than zero. And if you just calculate the determinant of this here, you now get this condition. Okay. So quantum mechanics like imposes the condition that that, you know, that this inequality has to be satisfied. So put differently, right? So quantum mechanics, once you have the idea that these chi values are the cosine of the of the peeling angles, so you can you can specify like the correlation array by just giving me three angles. But basic geometry tells me that once I pick two of these three angles, it puts constraints on the third. And this one, this is the constraint that it that it imposes. And if you now like plot this, you see that what this picks out is an elliptope, or, you know, what has been called sort of a fat tetrahedron, you puff it up a bit, the lines here are contained in it. But like, you know, in the middle, like it's it's blown up a bit. And we call this like the elliptope inequality. And this then is sort of the quantum analog of the of, you know, what the the CHSH inequality in the case of the Merman setup, right? And remember, for the full specification, we don't need just one, but we need four of those inequalities here, we only need one nonlinear inequality. And this inequality is satisfied by Merman's example, right? I mean, if you just look at it, you see that this if you put in a half, you get like exactly that this is going to be equal to zero. So this is actually a neat result, I think, because it gives a concrete example of like a cartoon that you often see about how the convex set for, you know, non signaling quantum and local hidden variable theories are related. Right. So so here is the here's a cross section of our drawing, right, with the non signaling cube, the elliptope and the tetrahedron, right? And now compare that to like the cartoon that is in Banana World, right, where you see like the non signaling cube with like, you know, like the maximal variation, like a Perpeco-Rohlich box, right, was a super quantum correlation that still is non signaling and doesn't violate special relativity. Then you have the quantum convex set. And then in the middle, you have the local polytope. And the beauty is, is that in this particular example of the of the Merman setup, you you reproduce like now exactly, you know, what you just have as a cartoon in in general. And you can play the same game for bananas now entangled bananas of higher spin. And so in our book, we do this right. So here's what the correlation array looks like. Just one cell for a spin one banana. The anti correlation coefficient, it turns out, you know, which is defined like this. I'll get to that in a moment, like stays the same is still the cosine. If you go for two, three halves still the same cosines. So all these correlations are all like constrained by the exact same elliptope inequality. That's not the case if you now try to simulate them with these raffles. So we saw that, you know, like if you do this for spin half, you get like the tetrahedron, right, so you get something with like four facets like this. If you now go up to higher spin, you see that you get a little more structure on these on these on these facets. So this is what it looks like for spin one and notice that this point here is going to touch the the the elliptope for for spin three halves, it's not going to touch the elliptope again. But for all integer spin, it will, right, you see this gets more and more faceted, more and more vertices. And like you can, it's very suggestive that if you go up to higher and higher spin, it gets more and more close to the elliptope, but never quite gets there, right. Now, the so so far it may seem that this elliptope somehow captures like something special about quantum mechanics, in particular, like we used, you know, sort of as hidden like in what I showed you, what we use like, you know, the Bourne rule, the Hilbert space formalism. But in fact, this inequality is not new to quantum mechanics at all. It has been known to statisticians since the 1890s, and it's basically a general constraint on the correlations between any three random variables, right, which also like, you know, makes it understandable that even if you go to higher spin particles in quantum mechanics, you'll never get out of the get out of the elliptope. So this work is due to Carl Pearson, and mostly to Utney Yule. So Pearson, of course, these days is mostly remembers for his dubious role in the eugenics movement, but he's also like, you know, like a very important character in statistics. So let me run to this quickly, right. So now we're talking about some arbitrary random variables with sets of possible outcomes that I'm going to keep discreet. And in fact, I'm only interested in a case where you have you have a random variable with only two outcomes, like, you know, yummy and nasty. And so I'm going to restrict my attention to what we call balanced random variables. And that just means that if X i X of i is a possible value, minus X i is two, and that the probability of X i and the probability of minus X i is the same. And that simplifies matters, because that means that in that case, the expectation value is going to be zero. And that simplifies like some other variables that some other quantities that we're interested in. So we're looking at the variance, right? So the expectation value of X minus the expected value of X squared. If the expected value of X is zero, then the variation of X is just the expectation value of X squared. The standard deviation is the square root of that. And then the covariance, again, like, you know, in general would be like the expectation value of X minus the expectation value of X times Y minus the expectation value of Y, if these two expectation values are zero, then that is just going to be equal to the expectation value of X times Y. And I now introduce like what is called the Pearson correlation coefficient, which is just the covariance of the Pearson correlation coefficients of X and Y is the covariance of X and Y divided by the corresponding standard deviation, sigma X and sigma Y. And so if X and Y are balanced, this is just the expectation value of X and Y divided by these standard deviations. And you can immediately see two properties like, you know, the Pearson correlation coefficient of a variable with itself is just one. And it doesn't matter if you look at a correlation coefficient X, Y or Y, X. And we'll now I'll now prove for you that such such any triplet of such variables is going to have to satisfy this elliptope inequality. And this was shown by Yule in the late 1890s. So here's where here's one way to do it, like, you know, consider, you know, for any triplet v1 v2 v3, like this quantity over here. So I'm looking at the expectation value of some expression squared. So I know this is going to be greater or equal to zero. And now I'm going to work this out. Okay, so I take like, you know, like this term times the rest that gives me this here, right. And so notes that I now get like, you know, v1. And then I have like, x times x, right, expectation value x squared divided by sigma x squared. And then we have the x times the y, the x times z. And then you have similar terms for like, if you now do the v2 y over sigma y and v3 z over sigma c. And you see that in here, like you have like all these Pearson correlation coefficients, it just looks like that. Right. And I can write this like a little more concisely and compactly as justice matrix with these Pearson correlation coefficients sandwiched between like, you know, the column vector v1 v2 v3, and the row vector v1 v2 v3. And remember that this thing has to be greater or equal than zero for any, for any value of v1, v2, v3, which means that that matrix row is positive semi definite, which means that the determinant of row has to be greater or equal than zero. And it follows that, you know, that that's just the elliptope inequality. Right. So there we have it again. Okay. So now, look at the special case that x, y, and z are the taste of Alice's banana, right, in this experiment in the, in the Merman setup, right. So x is the, the taste of Alice's banana when she peels in the A direction, y is the taste of Alice's banana when she peels in the B direction and z is the taste when Alice's banana when she peels in the C direction. All right. So now the obvious problem is, is that as Papescu points out in the, in the preface or the forward of banana world, a banana can only be eaten once, right, once it's peeled, it's peeled, once it's tasted, it's tasted. But there's, we'll see there's ways around this, this, this problem. So first I note that these variables are balanced, right. So we have to now give them some numerical value rather than just yummy or nasty, but you know, inspired by spin, you know, like instead of having like a half h bar, we now have like a half, like a B bar, you know, which I call the banana split, which is just boops constant B divided by two pi. And we're going to pick units such that B bar is equal to one. And so then, you know, these, we see that these, that these variables are perfectly balanced, the expectation value is zero, the variance, right. So it's like, you know, half, half the time, like, you know, it's the product is, it's, it's, it's one half squared, the other half is like, you know, minus a half squared, and that adds up to one fourth, the standard deviation take the square root that is like a half. Now the covariance here, it's a little trickier. And what we're going to do. And like, you know, if you, if you're squeamish about this, like, we did find a way to avoid like this counterfactual reasoning. But I think it's perfectly innocuous. We're going to use my the opposite, if you want to find the covariance of the variables Alice, Alice's taste of banana when peeling a and the taste of Alice's banana when peeling B. So half Alice appeal a and then have her use minus what Bob finds when he peels B as a proxy for what she would have find had she peeled B instead. And so basically, like, you know, that so we use we calculate this thing here, and we can use our correlation array to figure this out. Right. So we have like, if the if the if the tastes are are the are the same, we get we get we get like one fourth. What is the probability of that happening? Well, you need to add these two things. Right. So that's a half one minus guy AB. And then, you know, like, if they're opposite, it's minus one fourth. And the probability of that happening is this, if you work this out, you see that this is one fourth times guy AB. And if you now like calculate the Pearson correlation coefficient, you see that that is exactly equal to guy AB. Right. I already took an advance on that result calling this guy be like an anti correlation coefficient, right. And the anti is because of this minus. All right. So the elliptop inequality, you know, I can just now write for this for these particular variables, right. So in terms of these rows, now, in terms of these guys. And so this is just exactly the same. But there is a few problems, right. So the first problem we already dealt with, like, how do we determine the taste of these two of a Alice feeling a and Alice feeling B and one run? Well, you know, have or use Bob's result as a proxy for one of those. Right. Now, the second problem is like, you know, we can only do this for two tastes for two feelings in one run. Well, that's not a big problem either. Like, you can just have different ones. Right. So if you think about it, that's what we always do, you know, like you like, if you think about the early tests of the CHSH inequality, they weren't switching the settings like, you know, from run to run, you just take measurements for one pair of standing and then fill in another pair. That's all perfectly fine. So that we can do the third problem seems to be a lot nastier. And there the promise is that, you know, that we we derive this elliptop inequality from the condition starting that this the expectation value, this quantity is always greater equal than zero. Right. But the point is that we cannot determine the value of this in one in one run. And it would seem that if if all these three variables like can only take on values like plus or minus a half, that yes, it's going to be greater equal than zero. But that inequality is not tight because like, you know, like we could easily the smallest we could get this is to something like, you know, a half, like, you know, like a state plus and minus, minus here, and then we have a quarter. So this took us a while to to to figure out and the the the answer actually hinges on like, you know, like an interesting property of quantum mechanics, namely that in quantum mechanics, it's perfectly possible for a sum to have a definite value, even if the individual terms in that sum do not. Right. So the simplest example I can think of is like, you know, the Hamiltonian for harmonic oscillator, clearly P and Q cannot have like, you know, definite values at the same time, but you know, the Hamiltonian can. And so to look at this a little more clearly, right, so if you if you were looking essentially at sort of a sum of like her mission operators, linear combination, and that in and of itself should be like a good operator. And so if you introduce like, you know, now like in analogy with a spin vector, like a taste vector, you get, you can write like the taste in the A direction as like the inner products of like T with like the unit vector in the A direction, same for TB, same for TC. And then the inequality becomes this, and you see that we're in a product thing, but the the taste vector with this vector, and this will be zero whenever this combination is zero. Right. And so if you if there are if you pick the right peeling directions for starters that need to be in one plane, you can actually like achieve that. So this this inequality is tight. And this result applies to so the general result of yield does applies to to this to this quantum example. All right. So what do I want to conclude from this? Okay. So the point is, is that this elliptope inequality that we derived first within quantum mechanics from the geometry of Hilbert space can also be derived without quantum mechanics as a general constraint on correlations between three random variables. And is this this distinction like actually we got from within from without from a song by Bob Dylan. So the message then this is the big message of the of the talk is that what this suggests is that the basic Hilbert space formalism of quantum mechanics is just a new framework for handling probabilities. Right. And so this take on quantum mechanics, which has been dubbed boobism is a pun on cubism by Robert Mischewitz belongs, I think, to a class of informational makeovers of the much maligned Copenhagen interpretation. And so in order to to make that clear, like I want to talk, I'll take five more minutes to make the point. And this is far more speculative and tentative than what I've said so far. I think it's best to sort of think in terms of like a genealogy of quantum interpretations. And so we got like two versions of quantum mechanics around 1925 26. First, we have matrix mechanics. And Heisenberg's big discovery was that these problems in spectroscopy that he was running into, just call for a new framework for dealing with with physics, just as like the problems that people had run into in electrodynamics around the turn of the century, called for a new framework of dealing with spatial temporal relations. Now, of course, a little bit later, like Schrodinger comes up with wave mechanics, and his big discovery compatible with Heisenberg was very different, like namely, here the idea is that something wavy is underlying the behavior that we're seeing. And the analogy here is with wave optics in the 19th century. And so they famously didn't care for each other, for each other's views, like, you know, like Heisenberg calling wave mechanics disgusting, and Schrodinger calling matrix mechanics repulsive. And but of course, like mathematical equivalence was rapidly proved in part by Schrodinger himself, but then by the rock, yard down for Neumann. And that kind of papers over like a very different way of thinking about the state, the status of the state vector in the Hilbert space. And I think roughly you can say that the descendants of wave mechanics, those are the ontic interpretations of quantum mechanics, think Everett, the de Broglie-Bohm pilot wave theory, and the Girardi-Romini-Weber spontaneous collapse theory. And the descendants of matrix mechanics are the epistemic interpretations in where I would include Copenhagen, Cubism, and now like, you know, Bubism. And so just a quick way of sort of showing, you know, what I'm, what I'm after, like contrast Boop with Everett, right? So for Boop, like what the Hilbert space is doing you is doing for you, it's giving you the Born Rule, but it doesn't represent stuff, right? In order to represent stuff, you need like some specific quantum applications running on this new quantum operating system to use kind of the metaphor of Nielsen and Chang's book on quantum information. Now, for Everett, it's just the way, it's just the other way around. Hilbert space gives you stuff, you know, Sean Carroll, like says, like, you know, the world is made out of wave functions, right? So, but it doesn't give you the Born Rule now, right? I mean, so for that they appeal to decision theory for agents and a multiverse, okay? Now, so this is Oxford Everettians, there's also another class of Everettians, Berlin Everettians like Christoph Lainer, who really have the courage of their convictions, who use like Hilbert space both to represent stuff and to get the Born Rule and of course, it's a good Everettian, right? You take advantage of the fact that in a multiverse, you really can have your cake and eat it too. So now, for more careful exegesis of all of this, you, you know, I'm going to refer you to our book, where especially like, you know, microfarro, like, lace this out, like much more patiently than I just did, and I'm going to leave you like with one more version of this, of this Dylan song. Now, right, I'm happy to take some questions if there's time. Yes, we have some minutes for comments or questions. If you want to make a comment or question, please indicate it in the chat. I have a short question. Do you think that, or my real question is, if you have some experience in the classroom with this type of topological approximation mechanics, do you think that it can help in education? I'm just making sure. Do you think the question is, like, do you think that this way of thinking about quantum mechanics can help education? No, this form to present some results with the topological forms can help in education of quantum mechanics in the in the courses in the universe. Yeah, no, I mean, like, I'm currently teaching a course on introducing, like, non physics majors to quantum mechanics, where I very much use this, use this approach that I showed you, right? And so, and like, yeah, and so, but it's, I mean, it gives you like a particular way of thinking about quantum mechanics, right? It really pushes this idea that quantum mechanics is like a, you know, the kinematics of quantum mechanics, right? The basic formalism is a new framework for handling probabilities, right? And that, you know, in order to do anything else, right, now you need to do dynamics, you need to like introduce like stuff, right? And what quantum mechanics is telling you that it had to, that it has to behave according to the rules of quantum, right? So, so that's, that's the view I'm pushing. Historically, what I find interesting is that if you now look at modern books on probability theory and statistics, is that Hilbert space methods are being used in these books. And somehow like, so as a historian, I'm very interested, like how it came to be, that there seems to be very little communication between people in physics using Hilbert space methods, and people in general statistics using like Hilbert space methods. Okay, thank you. And there is a question from Federico Hoelig. Yes, thanks, Michelle, for, for this wonderful talk. It's always great to hear you. I always get really excited. And I want to learn more about this approach. And my question is related to what is the stake or the take of your interpretation with regard to non-locality? Because if you interpret quantum mechanics as a new probability formalism, what can you say about the strong claims that the word is local versus the word is non-local? What will you say about that? Yeah, so, so the, that's a difficult question. So, so what I would say is that, you know, in the spirit of what I showed you is that, you know, like you would, you would have thought that special relativity like requires you to, you know, like tell some story where you can like screen off like any correlation by something, you know, that by a common cause. And it turns out that the constraints are not that tight, you can have like, you can have like a very much more liberal constraint and still be non-singling. In fact, you can go beyond quantum mechanics, and you can have like PR boxes. And so to, I would say you just have to get used to the fact that you should resist the temptation that when you have these like correlations that cannot be dealt with sort of the standard way screening them off by conditionalizing on common causes, that you think of these as just constrained produced by natures and not like, oh, Alice does one thing and then like, you know, like it travels like instantaneously to Bob or vice versa. And if you, if you, if you go for this if you go this epistemic route, that is easier, right? I mean, like, I think a lot of students in quantum mechanics who, you know, like, no matter how, how often you tell them that astrodinger, that astrodinger wave function is not a field on ordinary space, still have this picture like, well, then you do a measurement and the whole thing goes poof, instantaneously. And like now you're stretching your head like, you know, what is it that is traveling from like Alice to Bob that then like frustratingly you can never use to send a signal, right? And so I'm hoping that this approach will sort of prevent people like, you know, from going down that particular rabbit hole in the first place. Okay, thanks. Thanks. It's clear. Yeah. I tend to agree. Yes.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.44, "text": " Okay. Okay, welcome to the second part of the conference of this day. The first talk of this", "tokens": [50364, 1033, 13, 1033, 11, 2928, 281, 264, 1150, 644, 295, 264, 7586, 295, 341, 786, 13, 440, 700, 751, 295, 341, 50836], "temperature": 0.0, "avg_logprob": -0.23880653381347655, "compression_ratio": 1.5, "no_speech_prob": 0.02837519533932209}, {"id": 1, "seek": 0, "start": 9.44, "end": 17.2, "text": " session is in charge of Michael Jensen from the University of Minnesota. The title of the talk is", "tokens": [50836, 5481, 307, 294, 4602, 295, 5116, 508, 32934, 490, 264, 3535, 295, 13996, 13, 440, 4876, 295, 264, 751, 307, 51224], "temperature": 0.0, "avg_logprob": -0.23880653381347655, "compression_ratio": 1.5, "no_speech_prob": 0.02837519533932209}, {"id": 2, "seek": 0, "start": 17.76, "end": 24.88, "text": " quantum kinematics. A new framework for handling probabilities. Go on, Michael.", "tokens": [51252, 13018, 15784, 37541, 13, 316, 777, 8388, 337, 13175, 33783, 13, 1037, 322, 11, 5116, 13, 51608], "temperature": 0.0, "avg_logprob": -0.23880653381347655, "compression_ratio": 1.5, "no_speech_prob": 0.02837519533932209}, {"id": 3, "seek": 2488, "start": 25.599999999999998, "end": 33.36, "text": " Okay. Thank you very much for the invitation. Everybody can see my screen. I hope you had", "tokens": [50400, 1033, 13, 1044, 291, 588, 709, 337, 264, 17890, 13, 7646, 393, 536, 452, 2568, 13, 286, 1454, 291, 632, 50788], "temperature": 0.0, "avg_logprob": -0.10776914869035993, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.006989163812249899}, {"id": 4, "seek": 2488, "start": 33.36, "end": 40.0, "text": " a chance to read my abstract. So what I'll be doing for the most part is to talk about the", "tokens": [50788, 257, 2931, 281, 1401, 452, 12649, 13, 407, 437, 286, 603, 312, 884, 337, 264, 881, 644, 307, 281, 751, 466, 264, 51120], "temperature": 0.0, "avg_logprob": -0.10776914869035993, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.006989163812249899}, {"id": 5, "seek": 2488, "start": 40.0, "end": 47.92, "text": " correlations you can get with the proverbial Alice and Bob performing measurements on two spin half", "tokens": [51120, 13983, 763, 291, 393, 483, 365, 264, 49923, 831, 16004, 293, 6085, 10205, 15383, 322, 732, 6060, 1922, 51516], "temperature": 0.0, "avg_logprob": -0.10776914869035993, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.006989163812249899}, {"id": 6, "seek": 2488, "start": 47.92, "end": 53.28, "text": " particles entangled in the singlet state. And I'll represent the class of correlations that you can", "tokens": [51516, 10007, 948, 39101, 294, 264, 1522, 2631, 1785, 13, 400, 286, 603, 2906, 264, 1508, 295, 13983, 763, 300, 291, 393, 51784], "temperature": 0.0, "avg_logprob": -0.10776914869035993, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.006989163812249899}, {"id": 7, "seek": 5328, "start": 53.28, "end": 58.800000000000004, "text": " get in that kind of, like I should say, in a setup that was suggested by David Merman,", "tokens": [50364, 483, 294, 300, 733, 295, 11, 411, 286, 820, 584, 11, 294, 257, 8657, 300, 390, 10945, 538, 4389, 376, 11821, 11, 50640], "temperature": 0.0, "avg_logprob": -0.11543236122475015, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.011307352222502232}, {"id": 8, "seek": 5328, "start": 58.800000000000004, "end": 64.16, "text": " where Alice and Bob both choose from the same three observables that they're going to measure.", "tokens": [50640, 689, 16004, 293, 6085, 1293, 2826, 490, 264, 912, 1045, 9951, 2965, 300, 436, 434, 516, 281, 3481, 13, 50908], "temperature": 0.0, "avg_logprob": -0.11543236122475015, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.011307352222502232}, {"id": 9, "seek": 5328, "start": 64.16, "end": 68.0, "text": " And I'm going to be looking at the kind of correlations that are allowed in that setup,", "tokens": [50908, 400, 286, 478, 516, 281, 312, 1237, 412, 264, 733, 295, 13983, 763, 300, 366, 4350, 294, 300, 8657, 11, 51100], "temperature": 0.0, "avg_logprob": -0.11543236122475015, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.011307352222502232}, {"id": 10, "seek": 5328, "start": 68.0, "end": 72.88, "text": " if you just restrict it to like anything that's non-signaling, anything that can be", "tokens": [51100, 498, 291, 445, 7694, 309, 281, 411, 1340, 300, 311, 2107, 12, 82, 788, 4270, 11, 1340, 300, 393, 312, 51344], "temperature": 0.0, "avg_logprob": -0.11543236122475015, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.011307352222502232}, {"id": 11, "seek": 5328, "start": 72.88, "end": 77.52000000000001, "text": " done quantum mechanically, and anything that can be done like with local hidden variable theories.", "tokens": [51344, 1096, 13018, 4236, 984, 11, 293, 1340, 300, 393, 312, 1096, 411, 365, 2654, 7633, 7006, 13667, 13, 51576], "temperature": 0.0, "avg_logprob": -0.11543236122475015, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.011307352222502232}, {"id": 12, "seek": 7752, "start": 77.52, "end": 83.75999999999999, "text": " And I'll show you that there is a nice three-dimensional graphical representation of that.", "tokens": [50364, 400, 286, 603, 855, 291, 300, 456, 307, 257, 1481, 1045, 12, 18759, 35942, 10290, 295, 300, 13, 50676], "temperature": 0.0, "avg_logprob": -0.1227608150906033, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00392573606222868}, {"id": 13, "seek": 7752, "start": 84.47999999999999, "end": 91.67999999999999, "text": " So the work is based on a book that I wrote with Michael Janus and Michael Faro.", "tokens": [50712, 407, 264, 589, 307, 2361, 322, 257, 1446, 300, 286, 4114, 365, 5116, 4956, 301, 293, 5116, 9067, 78, 13, 51072], "temperature": 0.0, "avg_logprob": -0.1227608150906033, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00392573606222868}, {"id": 14, "seek": 7752, "start": 92.39999999999999, "end": 100.0, "text": " So here is the three of us, like in Minneapolis a few years ago. And since the names of the three of", "tokens": [51108, 407, 510, 307, 264, 1045, 295, 505, 11, 411, 294, 38713, 257, 1326, 924, 2057, 13, 400, 1670, 264, 5288, 295, 264, 1045, 295, 51488], "temperature": 0.0, "avg_logprob": -0.1227608150906033, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00392573606222868}, {"id": 15, "seek": 7752, "start": 100.0, "end": 105.12, "text": " us are sort of variations on Michael, like this has become known in certain circles already as", "tokens": [51488, 505, 366, 1333, 295, 17840, 322, 5116, 11, 411, 341, 575, 1813, 2570, 294, 1629, 13040, 1217, 382, 51744], "temperature": 0.0, "avg_logprob": -0.1227608150906033, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00392573606222868}, {"id": 16, "seek": 10512, "start": 105.12, "end": 113.12, "text": " the three mics manifesto. The book will come out in January. It's in the series Boston Studies in", "tokens": [50364, 264, 1045, 45481, 10067, 78, 13, 440, 1446, 486, 808, 484, 294, 7061, 13, 467, 311, 294, 264, 2638, 12333, 17515, 294, 50764], "temperature": 0.0, "avg_logprob": -0.11642701285226005, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.003808434819802642}, {"id": 17, "seek": 10512, "start": 113.12, "end": 118.48, "text": " the Philosophy and History of Science. And its official title is Understanding Quantum Raffles.", "tokens": [50764, 264, 43655, 293, 12486, 295, 8976, 13, 400, 1080, 4783, 4876, 307, 36858, 44964, 497, 40349, 13, 51032], "temperature": 0.0, "avg_logprob": -0.11642701285226005, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.003808434819802642}, {"id": 18, "seek": 10512, "start": 119.68, "end": 127.2, "text": " Now the book was inspired, and this is the banana that you'll be seeing as my background image", "tokens": [51092, 823, 264, 1446, 390, 7547, 11, 293, 341, 307, 264, 14194, 300, 291, 603, 312, 2577, 382, 452, 3678, 3256, 51468], "temperature": 0.0, "avg_logprob": -0.11642701285226005, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.003808434819802642}, {"id": 19, "seek": 10512, "start": 127.2, "end": 133.28, "text": " throughout the talk, by this book by Jeff Boop, Banana World, Quantum Mechanics for Primates.", "tokens": [51468, 3710, 264, 751, 11, 538, 341, 1446, 538, 7506, 3286, 404, 11, 39588, 3937, 11, 44964, 30175, 1167, 337, 19671, 1024, 13, 51772], "temperature": 0.0, "avg_logprob": -0.11642701285226005, "compression_ratio": 1.5158730158730158, "no_speech_prob": 0.003808434819802642}, {"id": 20, "seek": 13328, "start": 133.84, "end": 140.08, "text": " And here you see a picture of me and Jeff at a conference in 2019, like in Santiago,", "tokens": [50392, 400, 510, 291, 536, 257, 3036, 295, 385, 293, 7506, 412, 257, 7586, 294, 6071, 11, 411, 294, 37621, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10367371959071006, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.003062089439481497}, {"id": 21, "seek": 13328, "start": 140.8, "end": 147.36, "text": " like following actually right this conference in Cordoba in 2019, where I also gave the talk and", "tokens": [50740, 411, 3480, 767, 558, 341, 7586, 294, 40267, 19481, 294, 6071, 11, 689, 286, 611, 2729, 264, 751, 293, 51068], "temperature": 0.0, "avg_logprob": -0.10367371959071006, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.003062089439481497}, {"id": 22, "seek": 13328, "start": 147.36, "end": 152.96, "text": " had a great time. So I should also like put in a plug for like the sequel to Banana World,", "tokens": [51068, 632, 257, 869, 565, 13, 407, 286, 820, 611, 411, 829, 294, 257, 5452, 337, 411, 264, 20622, 281, 39588, 3937, 11, 51348], "temperature": 0.0, "avg_logprob": -0.10367371959071006, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.003062089439481497}, {"id": 23, "seek": 13328, "start": 153.68, "end": 159.6, "text": " which is one of my favorite books. It's a serious comic on entanglement by Jeff and his daughter", "tokens": [51384, 597, 307, 472, 295, 452, 2954, 3642, 13, 467, 311, 257, 3156, 13900, 322, 948, 656, 3054, 538, 7506, 293, 702, 4653, 51680], "temperature": 0.0, "avg_logprob": -0.10367371959071006, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.003062089439481497}, {"id": 24, "seek": 15960, "start": 159.6, "end": 167.76, "text": " Tanya, a graphic artist called like Totally, Totally Random. So here's the set up I want to", "tokens": [50364, 314, 8791, 11, 257, 14089, 5748, 1219, 411, 22837, 11, 22837, 37603, 13, 407, 510, 311, 264, 992, 493, 286, 528, 281, 50772], "temperature": 0.0, "avg_logprob": -0.1617509861185093, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.001387650496326387}, {"id": 25, "seek": 15960, "start": 167.76, "end": 174.32, "text": " talk about. And so instead of talking about spin half particles, I'm going to be talking about", "tokens": [50772, 751, 466, 13, 400, 370, 2602, 295, 1417, 466, 6060, 1922, 10007, 11, 286, 478, 516, 281, 312, 1417, 466, 51100], "temperature": 0.0, "avg_logprob": -0.1617509861185093, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.001387650496326387}, {"id": 26, "seek": 15960, "start": 174.32, "end": 181.2, "text": " like entangled bananas, like I said, in honor of Jeff's book. And so what we have, we start out", "tokens": [51100, 411, 948, 39101, 22742, 11, 411, 286, 848, 11, 294, 5968, 295, 7506, 311, 1446, 13, 400, 370, 437, 321, 362, 11, 321, 722, 484, 51444], "temperature": 0.0, "avg_logprob": -0.1617509861185093, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.001387650496326387}, {"id": 27, "seek": 15960, "start": 181.2, "end": 187.44, "text": " with like a pair of entangled bananas, right? So they are described by the usual, you know,", "tokens": [51444, 365, 411, 257, 6119, 295, 948, 39101, 22742, 11, 558, 30, 407, 436, 366, 7619, 538, 264, 7713, 11, 291, 458, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1617509861185093, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.001387650496326387}, {"id": 28, "seek": 18744, "start": 187.44, "end": 194.48, "text": " singlet state. And then like Alice and Bob, you know, the side like on one of three ways to", "tokens": [50364, 1522, 2631, 1785, 13, 400, 550, 411, 16004, 293, 6085, 11, 291, 458, 11, 264, 1252, 411, 322, 472, 295, 1045, 2098, 281, 50716], "temperature": 0.0, "avg_logprob": -0.14245200979298558, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.005133903119713068}, {"id": 29, "seek": 18744, "start": 194.48, "end": 199.76, "text": " peel the banana. And so this is basically just window dressing for like, you know, they have,", "tokens": [50716, 13889, 264, 14194, 13, 400, 370, 341, 307, 1936, 445, 4910, 17211, 337, 411, 11, 291, 458, 11, 436, 362, 11, 50980], "temperature": 0.0, "avg_logprob": -0.14245200979298558, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.005133903119713068}, {"id": 30, "seek": 18744, "start": 199.76, "end": 205.52, "text": " they have like a Dubois magnet with which they measure spin in a certain direction. And now", "tokens": [50980, 436, 362, 411, 257, 16488, 7376, 15211, 365, 597, 436, 3481, 6060, 294, 257, 1629, 3513, 13, 400, 586, 51268], "temperature": 0.0, "avg_logprob": -0.14245200979298558, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.005133903119713068}, {"id": 31, "seek": 18744, "start": 205.52, "end": 210.24, "text": " they're going to hold their banana in a particular direction, you know, while peeling it. And then", "tokens": [51268, 436, 434, 516, 281, 1797, 641, 14194, 294, 257, 1729, 3513, 11, 291, 458, 11, 1339, 39926, 309, 13, 400, 550, 51504], "temperature": 0.0, "avg_logprob": -0.14245200979298558, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.005133903119713068}, {"id": 32, "seek": 18744, "start": 210.24, "end": 216.16, "text": " they take a bite out of the banana and determine whether the banana tastes yasta, tastes yummy,", "tokens": [51504, 436, 747, 257, 7988, 484, 295, 264, 14194, 293, 6997, 1968, 264, 14194, 8666, 288, 12468, 11, 8666, 18576, 11, 51800], "temperature": 0.0, "avg_logprob": -0.14245200979298558, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.005133903119713068}, {"id": 33, "seek": 21616, "start": 216.24, "end": 223.52, "text": " or nasty, right? So and the results are we're going to, we're going to put like in a correlation", "tokens": [50368, 420, 17923, 11, 558, 30, 407, 293, 264, 3542, 366, 321, 434, 516, 281, 11, 321, 434, 516, 281, 829, 411, 294, 257, 20009, 50732], "temperature": 0.0, "avg_logprob": -0.10889124125242233, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.0016472061397507787}, {"id": 34, "seek": 21616, "start": 223.52, "end": 229.28, "text": " array, which is really the workhorse of Jeff's book, Banana World. And so here you see like,", "tokens": [50732, 10225, 11, 597, 307, 534, 264, 589, 45079, 295, 7506, 311, 1446, 11, 39588, 3937, 13, 400, 370, 510, 291, 536, 411, 11, 51020], "temperature": 0.0, "avg_logprob": -0.10889124125242233, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.0016472061397507787}, {"id": 35, "seek": 21616, "start": 229.28, "end": 234.07999999999998, "text": " you know, Alice can measure A, B and C, Bob can measure A, B and C, they can only find,", "tokens": [51020, 291, 458, 11, 16004, 393, 3481, 316, 11, 363, 293, 383, 11, 6085, 393, 3481, 316, 11, 363, 293, 383, 11, 436, 393, 787, 915, 11, 51260], "temperature": 0.0, "avg_logprob": -0.10889124125242233, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.0016472061397507787}, {"id": 36, "seek": 21616, "start": 234.07999999999998, "end": 240.32, "text": " you know, plus or minus corresponding to yummy and nasty. And what you see is that if they happen,", "tokens": [51260, 291, 458, 11, 1804, 420, 3175, 11760, 281, 18576, 293, 17923, 13, 400, 437, 291, 536, 307, 300, 498, 436, 1051, 11, 51572], "temperature": 0.0, "avg_logprob": -0.10889124125242233, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.0016472061397507787}, {"id": 37, "seek": 21616, "start": 240.32, "end": 246.0, "text": " all the runs in which they happen to peel the same way, they find like a perfect impact correlation,", "tokens": [51572, 439, 264, 6676, 294, 597, 436, 1051, 281, 13889, 264, 912, 636, 11, 436, 915, 411, 257, 2176, 2712, 20009, 11, 51856], "temperature": 0.0, "avg_logprob": -0.10889124125242233, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.0016472061397507787}, {"id": 38, "seek": 24600, "start": 246.0, "end": 254.4, "text": " and in all the runs in which they peel different ways, they find like an imperfect, like positive", "tokens": [50364, 293, 294, 439, 264, 6676, 294, 597, 436, 13889, 819, 2098, 11, 436, 915, 411, 364, 26714, 11, 411, 3353, 50784], "temperature": 0.0, "avg_logprob": -0.11543090457007998, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.00046482268953695893}, {"id": 39, "seek": 24600, "start": 254.4, "end": 260.96, "text": " correlation, right? So look at A, B. So there is like, you know, like a three fourth chance of them", "tokens": [50784, 20009, 11, 558, 30, 407, 574, 412, 316, 11, 363, 13, 407, 456, 307, 411, 11, 291, 458, 11, 411, 257, 1045, 6409, 2931, 295, 552, 51112], "temperature": 0.0, "avg_logprob": -0.11543090457007998, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.00046482268953695893}, {"id": 40, "seek": 24600, "start": 260.96, "end": 267.52, "text": " finding the same 75% chance of finding the same, and only a 25% chance of them finding opposite.", "tokens": [51112, 5006, 264, 912, 9562, 4, 2931, 295, 5006, 264, 912, 11, 293, 787, 257, 3552, 4, 2931, 295, 552, 5006, 6182, 13, 51440], "temperature": 0.0, "avg_logprob": -0.11543090457007998, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.00046482268953695893}, {"id": 41, "seek": 24600, "start": 268.16, "end": 273.36, "text": " And the question is like, you know, like, what's how to, how to account for this? Now, so this is", "tokens": [51472, 400, 264, 1168, 307, 411, 11, 291, 458, 11, 411, 11, 437, 311, 577, 281, 11, 577, 281, 2696, 337, 341, 30, 823, 11, 370, 341, 307, 51732], "temperature": 0.0, "avg_logprob": -0.11543090457007998, "compression_ratio": 1.7422222222222221, "no_speech_prob": 0.00046482268953695893}, {"id": 42, "seek": 27336, "start": 273.44, "end": 279.6, "text": " like what you get in this Merman setup, if the angles between like the peeling directions are", "tokens": [50368, 411, 437, 291, 483, 294, 341, 376, 11821, 8657, 11, 498, 264, 14708, 1296, 411, 264, 39926, 11095, 366, 50676], "temperature": 0.0, "avg_logprob": -0.11295501920912, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.004258089233189821}, {"id": 43, "seek": 27336, "start": 279.6, "end": 286.96000000000004, "text": " like 120 degrees. Now, you can consider like a more general correlation array of this sort.", "tokens": [50676, 411, 10411, 5310, 13, 823, 11, 291, 393, 1949, 411, 257, 544, 2674, 20009, 10225, 295, 341, 1333, 13, 51044], "temperature": 0.0, "avg_logprob": -0.11295501920912, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.004258089233189821}, {"id": 44, "seek": 27336, "start": 288.0, "end": 293.44, "text": " And we're going to consider like, you know, any array that would like this, that would be", "tokens": [51096, 400, 321, 434, 516, 281, 1949, 411, 11, 291, 458, 11, 604, 10225, 300, 576, 411, 341, 11, 300, 576, 312, 51368], "temperature": 0.0, "avg_logprob": -0.11295501920912, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.004258089233189821}, {"id": 45, "seek": 27336, "start": 293.44, "end": 299.52000000000004, "text": " non signaling, right? And in order to guarantee non signaling, if you have these anti correlations,", "tokens": [51368, 2107, 38639, 11, 558, 30, 400, 294, 1668, 281, 10815, 2107, 38639, 11, 498, 291, 362, 613, 6061, 13983, 763, 11, 51672], "temperature": 0.0, "avg_logprob": -0.11295501920912, "compression_ratio": 1.7201834862385321, "no_speech_prob": 0.004258089233189821}, {"id": 46, "seek": 29952, "start": 299.59999999999997, "end": 306.47999999999996, "text": " like on the diagonal, it has to be the case that you get uniform marginals. And you do that by", "tokens": [50368, 411, 322, 264, 21539, 11, 309, 575, 281, 312, 264, 1389, 300, 291, 483, 9452, 10270, 1124, 13, 400, 291, 360, 300, 538, 50712], "temperature": 0.0, "avg_logprob": -0.09679944587476326, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001408898620866239}, {"id": 47, "seek": 29952, "start": 307.68, "end": 314.96, "text": " making sure that in all the off diagonal cells, the sum of both the two rows and the two columns", "tokens": [50772, 1455, 988, 300, 294, 439, 264, 766, 21539, 5438, 11, 264, 2408, 295, 1293, 264, 732, 13241, 293, 264, 732, 13766, 51136], "temperature": 0.0, "avg_logprob": -0.09679944587476326, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001408898620866239}, {"id": 48, "seek": 29952, "start": 314.96, "end": 320.64, "text": " is equal to a half, right? And so since the probabilities, of course, also have to be like", "tokens": [51136, 307, 2681, 281, 257, 1922, 11, 558, 30, 400, 370, 1670, 264, 33783, 11, 295, 1164, 11, 611, 362, 281, 312, 411, 51420], "temperature": 0.0, "avg_logprob": -0.09679944587476326, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001408898620866239}, {"id": 49, "seek": 29952, "start": 320.64, "end": 328.56, "text": " numbers between zero and one, you get that you can parameterize this by these chi's that I have here,", "tokens": [51420, 3547, 1296, 4018, 293, 472, 11, 291, 483, 300, 291, 393, 13075, 1125, 341, 538, 613, 13228, 311, 300, 286, 362, 510, 11, 51816], "temperature": 0.0, "avg_logprob": -0.09679944587476326, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.001408898620866239}, {"id": 50, "seek": 32856, "start": 328.56, "end": 335.28000000000003, "text": " and these chi's can run for all the way from minus one to plus one, right? And so I can characterize", "tokens": [50364, 293, 613, 13228, 311, 393, 1190, 337, 439, 264, 636, 490, 3175, 472, 281, 1804, 472, 11, 558, 30, 400, 370, 286, 393, 38463, 50700], "temperature": 0.0, "avg_logprob": -0.07758596965244838, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.00036231361445970833}, {"id": 51, "seek": 32856, "start": 335.28000000000003, "end": 344.4, "text": " this correlation array by having three of these parameters for three of these cells, right? This", "tokens": [50700, 341, 20009, 10225, 538, 1419, 1045, 295, 613, 9834, 337, 1045, 295, 613, 5438, 11, 558, 30, 639, 51156], "temperature": 0.0, "avg_logprob": -0.07758596965244838, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.00036231361445970833}, {"id": 52, "seek": 32856, "start": 344.4, "end": 350.4, "text": " thing is also going to be symmetric. It doesn't matter if you switch like A and B. So that's the", "tokens": [51156, 551, 307, 611, 516, 281, 312, 32330, 13, 467, 1177, 380, 1871, 498, 291, 3679, 411, 316, 293, 363, 13, 407, 300, 311, 264, 51456], "temperature": 0.0, "avg_logprob": -0.07758596965244838, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.00036231361445970833}, {"id": 53, "seek": 32856, "start": 350.4, "end": 357.2, "text": " story here. And you see that in the special case that is considered by Merman, that these chi values", "tokens": [51456, 1657, 510, 13, 400, 291, 536, 300, 294, 264, 2121, 1389, 300, 307, 4888, 538, 376, 11821, 11, 300, 613, 13228, 4190, 51796], "temperature": 0.0, "avg_logprob": -0.07758596965244838, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.00036231361445970833}, {"id": 54, "seek": 35720, "start": 357.2, "end": 362.71999999999997, "text": " are equal to minus a half, right? So stick that in here. If you put in like minus a half, like this", "tokens": [50364, 366, 2681, 281, 3175, 257, 1922, 11, 558, 30, 407, 2897, 300, 294, 510, 13, 759, 291, 829, 294, 411, 3175, 257, 1922, 11, 411, 341, 50640], "temperature": 0.0, "avg_logprob": -0.10269285070485082, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.0014539817348122597}, {"id": 55, "seek": 35720, "start": 362.71999999999997, "end": 367.36, "text": " would be, you know, three halves. So this would be three eighths, right? And this would be, you know,", "tokens": [50640, 576, 312, 11, 291, 458, 11, 1045, 38490, 13, 407, 341, 576, 312, 1045, 19495, 82, 11, 558, 30, 400, 341, 576, 312, 11, 291, 458, 11, 50872], "temperature": 0.0, "avg_logprob": -0.10269285070485082, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.0014539817348122597}, {"id": 56, "seek": 35720, "start": 367.36, "end": 372.64, "text": " like, you know, one eighth, right? So you recover that, you recover that Merman's correlation array.", "tokens": [50872, 411, 11, 291, 458, 11, 472, 19495, 11, 558, 30, 407, 291, 8114, 300, 11, 291, 8114, 300, 376, 11821, 311, 20009, 10225, 13, 51136], "temperature": 0.0, "avg_logprob": -0.10269285070485082, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.0014539817348122597}, {"id": 57, "seek": 35720, "start": 372.64, "end": 378.8, "text": " But again, like, you know, you, you, this is a more general form of it. Now, what we're going to try", "tokens": [51136, 583, 797, 11, 411, 11, 291, 458, 11, 291, 11, 291, 11, 341, 307, 257, 544, 2674, 1254, 295, 309, 13, 823, 11, 437, 321, 434, 516, 281, 853, 51444], "temperature": 0.0, "avg_logprob": -0.10269285070485082, "compression_ratio": 1.900943396226415, "no_speech_prob": 0.0014539817348122597}, {"id": 58, "seek": 37880, "start": 378.88, "end": 386.72, "text": " and do is to see like how, like what subclass of those correlations we can simulate, like with a", "tokens": [50368, 293, 360, 307, 281, 536, 411, 577, 11, 411, 437, 1422, 11665, 295, 729, 13983, 763, 321, 393, 27817, 11, 411, 365, 257, 50760], "temperature": 0.0, "avg_logprob": -0.1255907289909594, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.022260865196585655}, {"id": 59, "seek": 37880, "start": 386.72, "end": 393.12, "text": " raffle, right? And the raffle is our toy model for a local hidden variable theme. And so we have,", "tokens": [50760, 367, 29264, 11, 558, 30, 400, 264, 367, 29264, 307, 527, 12058, 2316, 337, 257, 2654, 7633, 7006, 6314, 13, 400, 370, 321, 362, 11, 51080], "temperature": 0.0, "avg_logprob": -0.1255907289909594, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.022260865196585655}, {"id": 60, "seek": 37880, "start": 393.12, "end": 397.76, "text": " we imagine that you have a basket with a bunch of tickets in it, and the tickets like half the", "tokens": [51080, 321, 3811, 300, 291, 362, 257, 8390, 365, 257, 3840, 295, 12628, 294, 309, 11, 293, 264, 12628, 411, 1922, 264, 51312], "temperature": 0.0, "avg_logprob": -0.1255907289909594, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.022260865196585655}, {"id": 61, "seek": 37880, "start": 397.76, "end": 403.68, "text": " outcomes for like all possible measurements that Alice and Bob can do. Now look at the first ticket,", "tokens": [51312, 10070, 337, 411, 439, 1944, 15383, 300, 16004, 293, 6085, 393, 360, 13, 823, 574, 412, 264, 700, 10550, 11, 51608], "temperature": 0.0, "avg_logprob": -0.1255907289909594, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.022260865196585655}, {"id": 62, "seek": 40368, "start": 403.68, "end": 409.28000000000003, "text": " like, you know, we know that if they, if they measure the same way that they find opposite", "tokens": [50364, 411, 11, 291, 458, 11, 321, 458, 300, 498, 436, 11, 498, 436, 3481, 264, 912, 636, 300, 436, 915, 6182, 50644], "temperature": 0.0, "avg_logprob": -0.07997812990282403, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.006570346653461456}, {"id": 63, "seek": 40368, "start": 409.28000000000003, "end": 414.8, "text": " results, right? So like, you know, the results on two halves of the tickets have better be up,", "tokens": [50644, 3542, 11, 558, 30, 407, 411, 11, 291, 458, 11, 264, 3542, 322, 732, 38490, 295, 264, 12628, 362, 1101, 312, 493, 11, 50920], "temperature": 0.0, "avg_logprob": -0.07997812990282403, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.006570346653461456}, {"id": 64, "seek": 40368, "start": 414.8, "end": 419.36, "text": " has better be opposite. The way it works is that you take a ticket, you rip the ticket in half,", "tokens": [50920, 575, 1101, 312, 6182, 13, 440, 636, 309, 1985, 307, 300, 291, 747, 257, 10550, 11, 291, 12782, 264, 10550, 294, 1922, 11, 51148], "temperature": 0.0, "avg_logprob": -0.07997812990282403, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.006570346653461456}, {"id": 65, "seek": 40368, "start": 419.36, "end": 425.44, "text": " and then you randomly decide like which one goes to Alice and which one goes to Bob, right? So a", "tokens": [51148, 293, 550, 291, 16979, 4536, 411, 597, 472, 1709, 281, 16004, 293, 597, 472, 1709, 281, 6085, 11, 558, 30, 407, 257, 51452], "temperature": 0.0, "avg_logprob": -0.07997812990282403, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.006570346653461456}, {"id": 66, "seek": 40368, "start": 425.44, "end": 429.6, "text": " ticket where you just switch the left and the right side does not give you a, this does not give", "tokens": [51452, 10550, 689, 291, 445, 3679, 264, 1411, 293, 264, 558, 1252, 775, 406, 976, 291, 257, 11, 341, 775, 406, 976, 51660], "temperature": 0.0, "avg_logprob": -0.07997812990282403, "compression_ratio": 1.954732510288066, "no_speech_prob": 0.006570346653461456}, {"id": 67, "seek": 42960, "start": 429.6, "end": 436.32000000000005, "text": " you a new ticket. So with that said, there is like four different tickets, right? So it doesn't", "tokens": [50364, 291, 257, 777, 10550, 13, 407, 365, 300, 848, 11, 456, 307, 411, 1451, 819, 12628, 11, 558, 30, 407, 309, 1177, 380, 50700], "temperature": 0.0, "avg_logprob": -0.06600867456464625, "compression_ratio": 1.987603305785124, "no_speech_prob": 0.0018079421715810895}, {"id": 68, "seek": 42960, "start": 436.32000000000005, "end": 440.56, "text": " have to be the case that all the pluses are on one side, you could have a case where two of the", "tokens": [50700, 362, 281, 312, 264, 1389, 300, 439, 264, 1804, 279, 366, 322, 472, 1252, 11, 291, 727, 362, 257, 1389, 689, 732, 295, 264, 50912], "temperature": 0.0, "avg_logprob": -0.06600867456464625, "compression_ratio": 1.987603305785124, "no_speech_prob": 0.0018079421715810895}, {"id": 69, "seek": 42960, "start": 440.56, "end": 445.52000000000004, "text": " pluses are on one side. And like, you know, with one minus, and again, there is three ways of doing", "tokens": [50912, 1804, 279, 366, 322, 472, 1252, 13, 400, 411, 11, 291, 458, 11, 365, 472, 3175, 11, 293, 797, 11, 456, 307, 1045, 2098, 295, 884, 51160], "temperature": 0.0, "avg_logprob": -0.06600867456464625, "compression_ratio": 1.987603305785124, "no_speech_prob": 0.0018079421715810895}, {"id": 70, "seek": 42960, "start": 445.52000000000004, "end": 450.8, "text": " this, right? So you have the minus here is for C here, the minus is for B, and here the minus is", "tokens": [51160, 341, 11, 558, 30, 407, 291, 362, 264, 3175, 510, 307, 337, 383, 510, 11, 264, 3175, 307, 337, 363, 11, 293, 510, 264, 3175, 307, 51424], "temperature": 0.0, "avg_logprob": -0.06600867456464625, "compression_ratio": 1.987603305785124, "no_speech_prob": 0.0018079421715810895}, {"id": 71, "seek": 42960, "start": 450.8, "end": 455.12, "text": " for A, right? And again, keep in mind that it doesn't matter which side of the ticket you're", "tokens": [51424, 337, 316, 11, 558, 30, 400, 797, 11, 1066, 294, 1575, 300, 309, 1177, 380, 1871, 597, 1252, 295, 264, 10550, 291, 434, 51640], "temperature": 0.0, "avg_logprob": -0.06600867456464625, "compression_ratio": 1.987603305785124, "no_speech_prob": 0.0018079421715810895}, {"id": 72, "seek": 45512, "start": 455.12, "end": 462.72, "text": " looking at. Now, we can easily see like if you had like single ticket raffles, just like a basket", "tokens": [50364, 1237, 412, 13, 823, 11, 321, 393, 3612, 536, 411, 498, 291, 632, 411, 2167, 10550, 367, 40349, 11, 445, 411, 257, 8390, 50744], "temperature": 0.0, "avg_logprob": -0.1307603373672023, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.004327149596065283}, {"id": 73, "seek": 45512, "start": 462.72, "end": 469.6, "text": " with one type, what these sky parameters would be, you know, for your correlation array. Because you", "tokens": [50744, 365, 472, 2010, 11, 437, 613, 5443, 9834, 576, 312, 11, 291, 458, 11, 337, 428, 20009, 10225, 13, 1436, 291, 51088], "temperature": 0.0, "avg_logprob": -0.1307603373672023, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.004327149596065283}, {"id": 74, "seek": 45512, "start": 469.6, "end": 475.44, "text": " can see that if you have this ticket, no matter whether you take like AA, AB or AC, you always", "tokens": [51088, 393, 536, 300, 498, 291, 362, 341, 10550, 11, 572, 1871, 1968, 291, 747, 411, 30680, 11, 13838, 420, 8157, 11, 291, 1009, 51380], "temperature": 0.0, "avg_logprob": -0.1307603373672023, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.004327149596065283}, {"id": 75, "seek": 45512, "start": 475.44, "end": 481.44, "text": " have like a perfect anti-correlation. And that means that these sky values have to be like plus", "tokens": [51380, 362, 411, 257, 2176, 6061, 12, 19558, 4419, 399, 13, 400, 300, 1355, 300, 613, 5443, 4190, 362, 281, 312, 411, 1804, 51680], "temperature": 0.0, "avg_logprob": -0.1307603373672023, "compression_ratio": 1.7136563876651982, "no_speech_prob": 0.004327149596065283}, {"id": 76, "seek": 48144, "start": 481.52, "end": 488.56, "text": " one. Like maybe I should go just like back here, right? So the moment that chi is plus one, right,", "tokens": [50368, 472, 13, 1743, 1310, 286, 820, 352, 445, 411, 646, 510, 11, 558, 30, 407, 264, 1623, 300, 13228, 307, 1804, 472, 11, 558, 11, 50720], "temperature": 0.0, "avg_logprob": -0.10183380697375145, "compression_ratio": 1.787037037037037, "no_speech_prob": 0.0012436979450285435}, {"id": 77, "seek": 48144, "start": 488.56, "end": 493.6, "text": " then you see you have an anti-correlation, the moment that chi is minus one, you have like a", "tokens": [50720, 550, 291, 536, 291, 362, 364, 6061, 12, 19558, 4419, 399, 11, 264, 1623, 300, 13228, 307, 3175, 472, 11, 291, 362, 411, 257, 50972], "temperature": 0.0, "avg_logprob": -0.10183380697375145, "compression_ratio": 1.787037037037037, "no_speech_prob": 0.0012436979450285435}, {"id": 78, "seek": 48144, "start": 493.6, "end": 499.52, "text": " perfect correlation. So okay, so that's easy. Now look at this ticket, there's a little more", "tokens": [50972, 2176, 20009, 13, 407, 1392, 11, 370, 300, 311, 1858, 13, 823, 574, 412, 341, 10550, 11, 456, 311, 257, 707, 544, 51268], "temperature": 0.0, "avg_logprob": -0.10183380697375145, "compression_ratio": 1.787037037037037, "no_speech_prob": 0.0012436979450285435}, {"id": 79, "seek": 48144, "start": 499.52, "end": 506.32, "text": " complicated. So for AB, you see that there's still a perfect anti-correlation. But if you now look at", "tokens": [51268, 6179, 13, 407, 337, 13838, 11, 291, 536, 300, 456, 311, 920, 257, 2176, 6061, 12, 19558, 4419, 399, 13, 583, 498, 291, 586, 574, 412, 51608], "temperature": 0.0, "avg_logprob": -0.10183380697375145, "compression_ratio": 1.787037037037037, "no_speech_prob": 0.0012436979450285435}, {"id": 80, "seek": 50632, "start": 506.32, "end": 513.2, "text": " AC or at BC, you see that there's a correlation. So you have minus one. And the same is true for", "tokens": [50364, 8157, 420, 412, 14359, 11, 291, 536, 300, 456, 311, 257, 20009, 13, 407, 291, 362, 3175, 472, 13, 400, 264, 912, 307, 2074, 337, 50708], "temperature": 0.0, "avg_logprob": -0.10100492477416992, "compression_ratio": 1.575268817204301, "no_speech_prob": 0.0005701338523067534}, {"id": 81, "seek": 50632, "start": 513.2, "end": 519.92, "text": " C and D, right? It's just that a different parameter will get like the plus and the other two parameters", "tokens": [50708, 383, 293, 413, 11, 558, 30, 467, 311, 445, 300, 257, 819, 13075, 486, 483, 411, 264, 1804, 293, 264, 661, 732, 9834, 51044], "temperature": 0.0, "avg_logprob": -0.10100492477416992, "compression_ratio": 1.575268817204301, "no_speech_prob": 0.0005701338523067534}, {"id": 82, "seek": 50632, "start": 519.92, "end": 527.52, "text": " will be minus. And here then you immediately have like a bell inequality of the type of the", "tokens": [51044, 486, 312, 3175, 13, 400, 510, 550, 291, 4258, 362, 411, 257, 4549, 16970, 295, 264, 2010, 295, 264, 51424], "temperature": 0.0, "avg_logprob": -0.10100492477416992, "compression_ratio": 1.575268817204301, "no_speech_prob": 0.0005701338523067534}, {"id": 83, "seek": 52752, "start": 527.52, "end": 535.12, "text": " Klauser-Hornschirmann Holtz variety. And you can see that, you know, like the sum of these three", "tokens": [50364, 591, 22590, 260, 12, 39, 1865, 6145, 3692, 969, 389, 4837, 89, 5673, 13, 400, 291, 393, 536, 300, 11, 291, 458, 11, 411, 264, 2408, 295, 613, 1045, 50744], "temperature": 0.0, "avg_logprob": -0.18135784694126675, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.0023586105089634657}, {"id": 84, "seek": 52752, "start": 535.12, "end": 542.0, "text": " parameters is three, four ticket A, and it's going to be minus one for all other tickets. So if you", "tokens": [50744, 9834, 307, 1045, 11, 1451, 10550, 316, 11, 293, 309, 311, 516, 281, 312, 3175, 472, 337, 439, 661, 12628, 13, 407, 498, 291, 51088], "temperature": 0.0, "avg_logprob": -0.18135784694126675, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.0023586105089634657}, {"id": 85, "seek": 52752, "start": 542.0, "end": 548.56, "text": " take like an arbitrary mix of tickets, right, you would always get like a value somewhere between", "tokens": [51088, 747, 411, 364, 23211, 2890, 295, 12628, 11, 558, 11, 291, 576, 1009, 483, 411, 257, 2158, 4079, 1296, 51416], "temperature": 0.0, "avg_logprob": -0.18135784694126675, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.0023586105089634657}, {"id": 86, "seek": 52752, "start": 548.56, "end": 556.16, "text": " minus one and three. So and you see that Merman's example where chi, where these three chi's are", "tokens": [51416, 3175, 472, 293, 1045, 13, 407, 293, 291, 536, 300, 376, 11821, 311, 1365, 689, 13228, 11, 689, 613, 1045, 13228, 311, 366, 51796], "temperature": 0.0, "avg_logprob": -0.18135784694126675, "compression_ratio": 1.6638297872340426, "no_speech_prob": 0.0023586105089634657}, {"id": 87, "seek": 55616, "start": 556.16, "end": 562.3199999999999, "text": " minus a half. So that would be, if your sum would be minus three halves, violates this inequality.", "tokens": [50364, 3175, 257, 1922, 13, 407, 300, 576, 312, 11, 498, 428, 2408, 576, 312, 3175, 1045, 38490, 11, 3448, 1024, 341, 16970, 13, 50672], "temperature": 0.0, "avg_logprob": -0.18323341681032765, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0006351451156660914}, {"id": 88, "seek": 55616, "start": 564.0, "end": 569.1999999999999, "text": " Now, the nice thing about this is that you can come up with a very nice geometrical representation", "tokens": [50756, 823, 11, 264, 1481, 551, 466, 341, 307, 300, 291, 393, 808, 493, 365, 257, 588, 1481, 12956, 15888, 10290, 51016], "temperature": 0.0, "avg_logprob": -0.18323341681032765, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0006351451156660914}, {"id": 89, "seek": 55616, "start": 569.76, "end": 577.12, "text": " of the situation. And that is essentially due to Jeff's long-time collaborator,", "tokens": [51044, 295, 264, 2590, 13, 400, 300, 307, 4476, 3462, 281, 7506, 311, 938, 12, 3766, 5091, 1639, 11, 51412], "temperature": 0.0, "avg_logprob": -0.18323341681032765, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0006351451156660914}, {"id": 90, "seek": 55616, "start": 578.0799999999999, "end": 585.76, "text": " now deceased, unfortunately, Idemar Petovsky. And so first of all, we start out with like, you know,", "tokens": [51460, 586, 33156, 11, 7015, 11, 286, 10730, 289, 10472, 5179, 25810, 13, 400, 370, 700, 295, 439, 11, 321, 722, 484, 365, 411, 11, 291, 458, 11, 51844], "temperature": 0.0, "avg_logprob": -0.18323341681032765, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0006351451156660914}, {"id": 91, "seek": 58576, "start": 585.76, "end": 591.6, "text": " like representing these chi values, they can run from minus one to one in like what is called", "tokens": [50364, 411, 13460, 613, 13228, 4190, 11, 436, 393, 1190, 490, 3175, 472, 281, 472, 294, 411, 437, 307, 1219, 50656], "temperature": 0.0, "avg_logprob": -0.11850257189768665, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0016455878503620625}, {"id": 92, "seek": 58576, "start": 591.6, "end": 596.08, "text": " like a non-signaling cube. Remember, like, you know, this was like the general form of a correlation", "tokens": [50656, 411, 257, 2107, 12, 82, 788, 4270, 13728, 13, 5459, 11, 411, 11, 291, 458, 11, 341, 390, 411, 264, 2674, 1254, 295, 257, 20009, 50880], "temperature": 0.0, "avg_logprob": -0.11850257189768665, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0016455878503620625}, {"id": 93, "seek": 58576, "start": 596.08, "end": 602.24, "text": " array that is non-signaling. And you see that these tickets, like they're represented now by", "tokens": [50880, 10225, 300, 307, 2107, 12, 82, 788, 4270, 13, 400, 291, 536, 300, 613, 12628, 11, 411, 436, 434, 10379, 586, 538, 51188], "temperature": 0.0, "avg_logprob": -0.11850257189768665, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0016455878503620625}, {"id": 94, "seek": 58576, "start": 602.24, "end": 609.04, "text": " vertices of that non-signaling cube, right? So it's these four points, right, A, B, C, and D.", "tokens": [51188, 32053, 295, 300, 2107, 12, 82, 788, 4270, 13728, 11, 558, 30, 407, 309, 311, 613, 1451, 2793, 11, 558, 11, 316, 11, 363, 11, 383, 11, 293, 413, 13, 51528], "temperature": 0.0, "avg_logprob": -0.11850257189768665, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0016455878503620625}, {"id": 95, "seek": 60904, "start": 609.92, "end": 618.0, "text": " And a mixed raffle would be represented on like points that are like somewhere in between, right?", "tokens": [50408, 400, 257, 7467, 367, 29264, 576, 312, 10379, 322, 411, 2793, 300, 366, 411, 4079, 294, 1296, 11, 558, 30, 50812], "temperature": 0.0, "avg_logprob": -0.11165424120628227, "compression_ratio": 1.8986784140969164, "no_speech_prob": 0.01587609015405178}, {"id": 96, "seek": 60904, "start": 618.0, "end": 622.64, "text": " And once you have, so imagine, like, you know, you have your basket with tickets.", "tokens": [50812, 400, 1564, 291, 362, 11, 370, 3811, 11, 411, 11, 291, 458, 11, 291, 362, 428, 8390, 365, 12628, 13, 51044], "temperature": 0.0, "avg_logprob": -0.11165424120628227, "compression_ratio": 1.8986784140969164, "no_speech_prob": 0.01587609015405178}, {"id": 97, "seek": 60904, "start": 622.64, "end": 627.92, "text": " So if you take this and this and you put a certain mix, you can end up somewhere over here,", "tokens": [51044, 407, 498, 291, 747, 341, 293, 341, 293, 291, 829, 257, 1629, 2890, 11, 291, 393, 917, 493, 4079, 670, 510, 11, 51308], "temperature": 0.0, "avg_logprob": -0.11165424120628227, "compression_ratio": 1.8986784140969164, "no_speech_prob": 0.01587609015405178}, {"id": 98, "seek": 60904, "start": 627.92, "end": 632.16, "text": " but then you take a mix of like, you know, D and C, you get somewhere over here,", "tokens": [51308, 457, 550, 291, 747, 257, 2890, 295, 411, 11, 291, 458, 11, 413, 293, 383, 11, 291, 483, 4079, 670, 510, 11, 51520], "temperature": 0.0, "avg_logprob": -0.11165424120628227, "compression_ratio": 1.8986784140969164, "no_speech_prob": 0.01587609015405178}, {"id": 99, "seek": 60904, "start": 632.16, "end": 635.5999999999999, "text": " but you can also like, you know, now mix those, right? So you get all of that,", "tokens": [51520, 457, 291, 393, 611, 411, 11, 291, 458, 11, 586, 2890, 729, 11, 558, 30, 407, 291, 483, 439, 295, 300, 11, 51692], "temperature": 0.0, "avg_logprob": -0.11165424120628227, "compression_ratio": 1.8986784140969164, "no_speech_prob": 0.01587609015405178}, {"id": 100, "seek": 63560, "start": 635.6, "end": 642.24, "text": " and you can also like mix and match, mix and get like on the inside of this thing.", "tokens": [50364, 293, 291, 393, 611, 411, 2890, 293, 2995, 11, 2890, 293, 483, 411, 322, 264, 1854, 295, 341, 551, 13, 50696], "temperature": 0.0, "avg_logprob": -0.14396842495425716, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0038593944627791643}, {"id": 101, "seek": 63560, "start": 642.24, "end": 649.36, "text": " So this is like what is known as the classical tetrahedron. And this is like a very nice way of", "tokens": [50696, 407, 341, 307, 411, 437, 307, 2570, 382, 264, 13735, 23319, 15688, 292, 2044, 13, 400, 341, 307, 411, 257, 588, 1481, 636, 295, 51052], "temperature": 0.0, "avg_logprob": -0.14396842495425716, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0038593944627791643}, {"id": 102, "seek": 63560, "start": 650.48, "end": 656.16, "text": " geometrically representing, you know, what the local hidden variables here we can do.", "tokens": [51108, 12956, 81, 984, 13460, 11, 291, 458, 11, 437, 264, 2654, 7633, 9102, 510, 321, 393, 360, 13, 51392], "temperature": 0.0, "avg_logprob": -0.14396842495425716, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0038593944627791643}, {"id": 103, "seek": 63560, "start": 656.72, "end": 662.88, "text": " The bell in the quality only corresponds to like one facet of this tetrahedron.", "tokens": [51420, 440, 4549, 294, 264, 3125, 787, 23249, 281, 411, 472, 1915, 302, 295, 341, 23319, 15688, 292, 2044, 13, 51728], "temperature": 0.0, "avg_logprob": -0.14396842495425716, "compression_ratio": 1.6780487804878048, "no_speech_prob": 0.0038593944627791643}, {"id": 104, "seek": 66288, "start": 662.88, "end": 669.6, "text": " It just says that you can't be behind that plane like B, C, D, but you see that there are three", "tokens": [50364, 467, 445, 1619, 300, 291, 393, 380, 312, 2261, 300, 5720, 411, 363, 11, 383, 11, 413, 11, 457, 291, 536, 300, 456, 366, 1045, 50700], "temperature": 0.0, "avg_logprob": -0.1137571027201991, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.0012242048978805542}, {"id": 105, "seek": 66288, "start": 669.6, "end": 675.84, "text": " other forbidden regions that you would also have to spell out if you want to define fully,", "tokens": [50700, 661, 25990, 10682, 300, 291, 576, 611, 362, 281, 9827, 484, 498, 291, 528, 281, 6964, 4498, 11, 51012], "temperature": 0.0, "avg_logprob": -0.1137571027201991, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.0012242048978805542}, {"id": 106, "seek": 66288, "start": 675.84, "end": 683.68, "text": " you know, what is and what is not allowed. All right. So now in what is allowed by quantum", "tokens": [51012, 291, 458, 11, 437, 307, 293, 437, 307, 406, 4350, 13, 1057, 558, 13, 407, 586, 294, 437, 307, 4350, 538, 13018, 51404], "temperature": 0.0, "avg_logprob": -0.1137571027201991, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.0012242048978805542}, {"id": 107, "seek": 66288, "start": 683.68, "end": 690.8, "text": " mechanics, right? And so in quantum mechanics, the the result that is predicted by quantum", "tokens": [51404, 12939, 11, 558, 30, 400, 370, 294, 13018, 12939, 11, 264, 264, 1874, 300, 307, 19147, 538, 13018, 51760], "temperature": 0.0, "avg_logprob": -0.1137571027201991, "compression_ratio": 1.6803652968036529, "no_speech_prob": 0.0012242048978805542}, {"id": 108, "seek": 69080, "start": 691.52, "end": 698.4, "text": " is that these kais are just given by the cosine of the the peeling angle, right? In a way, this is", "tokens": [50400, 307, 300, 613, 350, 1527, 366, 445, 2212, 538, 264, 23565, 295, 264, 264, 39926, 5802, 11, 558, 30, 682, 257, 636, 11, 341, 307, 50744], "temperature": 0.0, "avg_logprob": -0.12263456454946975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002432191511616111}, {"id": 109, "seek": 69080, "start": 698.4, "end": 702.7199999999999, "text": " like very satisfying, right? So classically, you see that these kais with these tickets,", "tokens": [50744, 411, 588, 18348, 11, 558, 30, 407, 1508, 984, 11, 291, 536, 300, 613, 350, 1527, 365, 613, 12628, 11, 50960], "temperature": 0.0, "avg_logprob": -0.12263456454946975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002432191511616111}, {"id": 110, "seek": 69080, "start": 702.7199999999999, "end": 707.3599999999999, "text": " they're always going to be plus one or minus one, but wouldn't it be nice to have like a theory", "tokens": [50960, 436, 434, 1009, 516, 281, 312, 1804, 472, 420, 3175, 472, 11, 457, 2759, 380, 309, 312, 1481, 281, 362, 411, 257, 5261, 51192], "temperature": 0.0, "avg_logprob": -0.12263456454946975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002432191511616111}, {"id": 111, "seek": 69080, "start": 707.3599999999999, "end": 713.12, "text": " that just allows like a like a continuity of values between minus one and plus one? Quantum", "tokens": [51192, 300, 445, 4045, 411, 257, 411, 257, 23807, 295, 4190, 1296, 3175, 472, 293, 1804, 472, 30, 44964, 51480], "temperature": 0.0, "avg_logprob": -0.12263456454946975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002432191511616111}, {"id": 112, "seek": 69080, "start": 713.12, "end": 719.12, "text": " mechanics gives you just that, right? And so it's the cosine of the of the angle and that cosine,", "tokens": [51480, 12939, 2709, 291, 445, 300, 11, 558, 30, 400, 370, 309, 311, 264, 23565, 295, 264, 295, 264, 5802, 293, 300, 23565, 11, 51780], "temperature": 0.0, "avg_logprob": -0.12263456454946975, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.002432191511616111}, {"id": 113, "seek": 71912, "start": 719.12, "end": 724.5600000000001, "text": " of course, is the inner product of like unit vectors in these different peeling directions.", "tokens": [50364, 295, 1164, 11, 307, 264, 7284, 1674, 295, 411, 4985, 18875, 294, 613, 819, 39926, 11095, 13, 50636], "temperature": 0.0, "avg_logprob": -0.09780490966070265, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00039795628981664777}, {"id": 114, "seek": 71912, "start": 726.16, "end": 733.76, "text": " All right. So if you think about this correlation array, you see that the entire correlation array", "tokens": [50716, 1057, 558, 13, 407, 498, 291, 519, 466, 341, 20009, 10225, 11, 291, 536, 300, 264, 2302, 20009, 10225, 51096], "temperature": 0.0, "avg_logprob": -0.09780490966070265, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00039795628981664777}, {"id": 115, "seek": 71912, "start": 733.76, "end": 739.68, "text": " can be like characterized by by these parameters, right? These sky parameters. And we can also", "tokens": [51096, 393, 312, 411, 29361, 538, 538, 613, 9834, 11, 558, 30, 1981, 5443, 9834, 13, 400, 321, 393, 611, 51392], "temperature": 0.0, "avg_logprob": -0.09780490966070265, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.00039795628981664777}, {"id": 116, "seek": 73968, "start": 739.68, "end": 751.4399999999999, "text": " introduce them for the for the for the diagonal cells, where they're just one. Okay. So and so we'll", "tokens": [50364, 5366, 552, 337, 264, 337, 264, 337, 264, 21539, 5438, 11, 689, 436, 434, 445, 472, 13, 1033, 13, 407, 293, 370, 321, 603, 50952], "temperature": 0.0, "avg_logprob": -0.15073179731182024, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0018964463379234076}, {"id": 117, "seek": 73968, "start": 751.4399999999999, "end": 757.1999999999999, "text": " I'll I'll define this more carefully later on. But these guys are like, you know, what what can be", "tokens": [50952, 286, 603, 286, 603, 6964, 341, 544, 7500, 1780, 322, 13, 583, 613, 1074, 366, 411, 11, 291, 458, 11, 437, 437, 393, 312, 51240], "temperature": 0.0, "avg_logprob": -0.15073179731182024, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0018964463379234076}, {"id": 118, "seek": 73968, "start": 757.1999999999999, "end": 762.56, "text": " called like anti correlation coefficients. As for now, it's just hinges on three values, right? If", "tokens": [51240, 1219, 411, 6061, 20009, 31994, 13, 1018, 337, 586, 11, 309, 311, 445, 46686, 322, 1045, 4190, 11, 558, 30, 759, 51508], "temperature": 0.0, "avg_logprob": -0.15073179731182024, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0018964463379234076}, {"id": 119, "seek": 73968, "start": 762.56, "end": 767.68, "text": " chi is one, we saw you have a perfect anti correlation. If it's minus one, you have a perfect", "tokens": [51508, 13228, 307, 472, 11, 321, 1866, 291, 362, 257, 2176, 6061, 20009, 13, 759, 309, 311, 3175, 472, 11, 291, 362, 257, 2176, 51764], "temperature": 0.0, "avg_logprob": -0.15073179731182024, "compression_ratio": 1.7117903930131004, "no_speech_prob": 0.0018964463379234076}, {"id": 120, "seek": 76768, "start": 767.76, "end": 772.4799999999999, "text": " correlation, right? So it makes sense that the anti correlation coefficient is then minus one.", "tokens": [50368, 20009, 11, 558, 30, 407, 309, 1669, 2020, 300, 264, 6061, 20009, 17619, 307, 550, 3175, 472, 13, 50604], "temperature": 0.0, "avg_logprob": -0.134250901874743, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.00046532799024134874}, {"id": 121, "seek": 76768, "start": 772.4799999999999, "end": 779.5999999999999, "text": " If chi is zero, you have no correlation at all. Now look at introduce now like a matrix, an anti", "tokens": [50604, 759, 13228, 307, 4018, 11, 291, 362, 572, 20009, 412, 439, 13, 823, 574, 412, 5366, 586, 411, 257, 8141, 11, 364, 6061, 50960], "temperature": 0.0, "avg_logprob": -0.134250901874743, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.00046532799024134874}, {"id": 122, "seek": 76768, "start": 779.5999999999999, "end": 788.88, "text": " correlation matrix of just these chi values. And you can write that again, like in in terms of these", "tokens": [50960, 20009, 8141, 295, 445, 613, 13228, 4190, 13, 400, 291, 393, 2464, 300, 797, 11, 411, 294, 294, 2115, 295, 613, 51424], "temperature": 0.0, "avg_logprob": -0.134250901874743, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.00046532799024134874}, {"id": 123, "seek": 76768, "start": 788.88, "end": 796.4, "text": " inner products of these unit vectors. Now, this is a grand matrix, right? And it's a well known", "tokens": [51424, 7284, 3383, 295, 613, 4985, 18875, 13, 823, 11, 341, 307, 257, 2697, 8141, 11, 558, 30, 400, 309, 311, 257, 731, 2570, 51800], "temperature": 0.0, "avg_logprob": -0.134250901874743, "compression_ratio": 1.7092511013215859, "no_speech_prob": 0.00046532799024134874}, {"id": 124, "seek": 79640, "start": 796.4, "end": 801.36, "text": " property of the of the grand matrix. It doesn't take too much to verify this. But in the interest", "tokens": [50364, 4707, 295, 264, 295, 264, 2697, 8141, 13, 467, 1177, 380, 747, 886, 709, 281, 16888, 341, 13, 583, 294, 264, 1179, 50612], "temperature": 0.0, "avg_logprob": -0.09895621624189554, "compression_ratio": 1.7, "no_speech_prob": 0.0008822428644634783}, {"id": 125, "seek": 79640, "start": 801.36, "end": 807.92, "text": " of time, I'll skip that. We know that the determinant of that of that matrix is going to be it's going", "tokens": [50612, 295, 565, 11, 286, 603, 10023, 300, 13, 492, 458, 300, 264, 41296, 295, 300, 295, 300, 8141, 307, 516, 281, 312, 309, 311, 516, 50940], "temperature": 0.0, "avg_logprob": -0.09895621624189554, "compression_ratio": 1.7, "no_speech_prob": 0.0008822428644634783}, {"id": 126, "seek": 79640, "start": 807.92, "end": 813.4399999999999, "text": " to have to be greater or equal than zero. And if you just calculate the determinant of this here,", "tokens": [50940, 281, 362, 281, 312, 5044, 420, 2681, 813, 4018, 13, 400, 498, 291, 445, 8873, 264, 41296, 295, 341, 510, 11, 51216], "temperature": 0.0, "avg_logprob": -0.09895621624189554, "compression_ratio": 1.7, "no_speech_prob": 0.0008822428644634783}, {"id": 127, "seek": 79640, "start": 813.4399999999999, "end": 821.1999999999999, "text": " you now get this condition. Okay. So quantum mechanics like imposes the condition that that,", "tokens": [51216, 291, 586, 483, 341, 4188, 13, 1033, 13, 407, 13018, 12939, 411, 704, 4201, 264, 4188, 300, 300, 11, 51604], "temperature": 0.0, "avg_logprob": -0.09895621624189554, "compression_ratio": 1.7, "no_speech_prob": 0.0008822428644634783}, {"id": 128, "seek": 82120, "start": 821.2800000000001, "end": 827.76, "text": " you know, that this inequality has to be satisfied. So put differently, right? So quantum", "tokens": [50368, 291, 458, 11, 300, 341, 16970, 575, 281, 312, 11239, 13, 407, 829, 7614, 11, 558, 30, 407, 13018, 50692], "temperature": 0.0, "avg_logprob": -0.09450958551985494, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0017258860170841217}, {"id": 129, "seek": 82120, "start": 827.76, "end": 833.76, "text": " mechanics, once you have the idea that these chi values are the cosine of the of the peeling angles,", "tokens": [50692, 12939, 11, 1564, 291, 362, 264, 1558, 300, 613, 13228, 4190, 366, 264, 23565, 295, 264, 295, 264, 39926, 14708, 11, 50992], "temperature": 0.0, "avg_logprob": -0.09450958551985494, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0017258860170841217}, {"id": 130, "seek": 82120, "start": 833.76, "end": 840.48, "text": " so you can you can specify like the correlation array by just giving me three angles. But basic", "tokens": [50992, 370, 291, 393, 291, 393, 16500, 411, 264, 20009, 10225, 538, 445, 2902, 385, 1045, 14708, 13, 583, 3875, 51328], "temperature": 0.0, "avg_logprob": -0.09450958551985494, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0017258860170841217}, {"id": 131, "seek": 82120, "start": 840.48, "end": 845.5200000000001, "text": " geometry tells me that once I pick two of these three angles, it puts constraints on the third.", "tokens": [51328, 18426, 5112, 385, 300, 1564, 286, 1888, 732, 295, 613, 1045, 14708, 11, 309, 8137, 18491, 322, 264, 2636, 13, 51580], "temperature": 0.0, "avg_logprob": -0.09450958551985494, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0017258860170841217}, {"id": 132, "seek": 84552, "start": 845.52, "end": 852.4, "text": " And this one, this is the constraint that it that it imposes. And if you now like plot this,", "tokens": [50364, 400, 341, 472, 11, 341, 307, 264, 25534, 300, 309, 300, 309, 704, 4201, 13, 400, 498, 291, 586, 411, 7542, 341, 11, 50708], "temperature": 0.0, "avg_logprob": -0.12386263067072088, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.002580949105322361}, {"id": 133, "seek": 84552, "start": 852.4, "end": 858.0, "text": " you see that what this picks out is an elliptope, or, you know, what has been called sort of a", "tokens": [50708, 291, 536, 300, 437, 341, 16137, 484, 307, 364, 8284, 22439, 1114, 11, 420, 11, 291, 458, 11, 437, 575, 668, 1219, 1333, 295, 257, 50988], "temperature": 0.0, "avg_logprob": -0.12386263067072088, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.002580949105322361}, {"id": 134, "seek": 84552, "start": 858.0, "end": 863.76, "text": " fat tetrahedron, you puff it up a bit, the lines here are contained in it. But like, you know,", "tokens": [50988, 4046, 23319, 15688, 292, 2044, 11, 291, 19613, 309, 493, 257, 857, 11, 264, 3876, 510, 366, 16212, 294, 309, 13, 583, 411, 11, 291, 458, 11, 51276], "temperature": 0.0, "avg_logprob": -0.12386263067072088, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.002580949105322361}, {"id": 135, "seek": 84552, "start": 863.76, "end": 869.36, "text": " in the middle, like it's it's blown up a bit. And we call this like the elliptope inequality.", "tokens": [51276, 294, 264, 2808, 11, 411, 309, 311, 309, 311, 16479, 493, 257, 857, 13, 400, 321, 818, 341, 411, 264, 8284, 22439, 1114, 16970, 13, 51556], "temperature": 0.0, "avg_logprob": -0.12386263067072088, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.002580949105322361}, {"id": 136, "seek": 86936, "start": 869.36, "end": 873.92, "text": " And this then is sort of the quantum analog of the of, you know, what the", "tokens": [50364, 400, 341, 550, 307, 1333, 295, 264, 13018, 16660, 295, 264, 295, 11, 291, 458, 11, 437, 264, 50592], "temperature": 0.0, "avg_logprob": -0.15828642974028717, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.001242207596078515}, {"id": 137, "seek": 86936, "start": 875.2, "end": 880.0, "text": " the CHSH inequality in the case of the Merman setup, right? And remember, for the full", "tokens": [50656, 264, 5995, 17308, 16970, 294, 264, 1389, 295, 264, 376, 11821, 8657, 11, 558, 30, 400, 1604, 11, 337, 264, 1577, 50896], "temperature": 0.0, "avg_logprob": -0.15828642974028717, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.001242207596078515}, {"id": 138, "seek": 86936, "start": 880.0, "end": 884.88, "text": " specification, we don't need just one, but we need four of those inequalities here,", "tokens": [50896, 31256, 11, 321, 500, 380, 643, 445, 472, 11, 457, 321, 643, 1451, 295, 729, 41874, 510, 11, 51140], "temperature": 0.0, "avg_logprob": -0.15828642974028717, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.001242207596078515}, {"id": 139, "seek": 86936, "start": 884.88, "end": 893.04, "text": " we only need one nonlinear inequality. And this inequality is satisfied by Merman's example,", "tokens": [51140, 321, 787, 643, 472, 2107, 28263, 16970, 13, 400, 341, 16970, 307, 11239, 538, 376, 11821, 311, 1365, 11, 51548], "temperature": 0.0, "avg_logprob": -0.15828642974028717, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.001242207596078515}, {"id": 140, "seek": 86936, "start": 893.04, "end": 897.04, "text": " right? I mean, if you just look at it, you see that this if you put in a half,", "tokens": [51548, 558, 30, 286, 914, 11, 498, 291, 445, 574, 412, 309, 11, 291, 536, 300, 341, 498, 291, 829, 294, 257, 1922, 11, 51748], "temperature": 0.0, "avg_logprob": -0.15828642974028717, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.001242207596078515}, {"id": 141, "seek": 89704, "start": 897.8399999999999, "end": 902.0, "text": " you get like exactly that this is going to be equal to zero.", "tokens": [50404, 291, 483, 411, 2293, 300, 341, 307, 516, 281, 312, 2681, 281, 4018, 13, 50612], "temperature": 0.0, "avg_logprob": -0.13161223109175518, "compression_ratio": 1.5509259259259258, "no_speech_prob": 0.001222388120368123}, {"id": 142, "seek": 89704, "start": 904.88, "end": 912.0, "text": " So this is actually a neat result, I think, because it gives a concrete example of like", "tokens": [50756, 407, 341, 307, 767, 257, 10654, 1874, 11, 286, 519, 11, 570, 309, 2709, 257, 9859, 1365, 295, 411, 51112], "temperature": 0.0, "avg_logprob": -0.13161223109175518, "compression_ratio": 1.5509259259259258, "no_speech_prob": 0.001222388120368123}, {"id": 143, "seek": 89704, "start": 912.0, "end": 919.68, "text": " a cartoon that you often see about how the convex set for, you know, non signaling quantum", "tokens": [51112, 257, 18569, 300, 291, 2049, 536, 466, 577, 264, 42432, 992, 337, 11, 291, 458, 11, 2107, 38639, 13018, 51496], "temperature": 0.0, "avg_logprob": -0.13161223109175518, "compression_ratio": 1.5509259259259258, "no_speech_prob": 0.001222388120368123}, {"id": 144, "seek": 89704, "start": 919.68, "end": 925.8399999999999, "text": " and local hidden variable theories are related. Right. So so here is the here's a cross section", "tokens": [51496, 293, 2654, 7633, 7006, 13667, 366, 4077, 13, 1779, 13, 407, 370, 510, 307, 264, 510, 311, 257, 3278, 3541, 51804], "temperature": 0.0, "avg_logprob": -0.13161223109175518, "compression_ratio": 1.5509259259259258, "no_speech_prob": 0.001222388120368123}, {"id": 145, "seek": 92584, "start": 925.84, "end": 932.0, "text": " of our drawing, right, with the non signaling cube, the elliptope and the tetrahedron, right?", "tokens": [50364, 295, 527, 6316, 11, 558, 11, 365, 264, 2107, 38639, 13728, 11, 264, 8284, 22439, 1114, 293, 264, 23319, 15688, 292, 2044, 11, 558, 30, 50672], "temperature": 0.0, "avg_logprob": -0.20495745600486287, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.000676841358654201}, {"id": 146, "seek": 92584, "start": 932.72, "end": 938.5600000000001, "text": " And now compare that to like the cartoon that is in Banana World, right, where you see like", "tokens": [50708, 400, 586, 6794, 300, 281, 411, 264, 18569, 300, 307, 294, 39588, 3937, 11, 558, 11, 689, 291, 536, 411, 51000], "temperature": 0.0, "avg_logprob": -0.20495745600486287, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.000676841358654201}, {"id": 147, "seek": 92584, "start": 939.2800000000001, "end": 945.76, "text": " the non signaling cube with like, you know, like the maximal variation, like a Perpeco-Rohlich box,", "tokens": [51036, 264, 2107, 38639, 13728, 365, 411, 11, 291, 458, 11, 411, 264, 49336, 12990, 11, 411, 257, 3026, 494, 1291, 12, 49, 1445, 1739, 2424, 11, 51360], "temperature": 0.0, "avg_logprob": -0.20495745600486287, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.000676841358654201}, {"id": 148, "seek": 92584, "start": 945.76, "end": 950.5600000000001, "text": " right, was a super quantum correlation that still is non signaling and doesn't violate special", "tokens": [51360, 558, 11, 390, 257, 1687, 13018, 20009, 300, 920, 307, 2107, 38639, 293, 1177, 380, 37478, 2121, 51600], "temperature": 0.0, "avg_logprob": -0.20495745600486287, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.000676841358654201}, {"id": 149, "seek": 95056, "start": 950.56, "end": 955.76, "text": " relativity. Then you have the quantum convex set. And then in the middle, you have the local", "tokens": [50364, 45675, 13, 1396, 291, 362, 264, 13018, 42432, 992, 13, 400, 550, 294, 264, 2808, 11, 291, 362, 264, 2654, 50624], "temperature": 0.0, "avg_logprob": -0.1536721480520148, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.008419045247137547}, {"id": 150, "seek": 95056, "start": 955.76, "end": 961.92, "text": " polytope. And the beauty is, is that in this particular example of the of the Merman setup,", "tokens": [50624, 6754, 83, 1114, 13, 400, 264, 6643, 307, 11, 307, 300, 294, 341, 1729, 1365, 295, 264, 295, 264, 376, 11821, 8657, 11, 50932], "temperature": 0.0, "avg_logprob": -0.1536721480520148, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.008419045247137547}, {"id": 151, "seek": 95056, "start": 962.8, "end": 969.1999999999999, "text": " you you reproduce like now exactly, you know, what you just have as a cartoon in in general.", "tokens": [50976, 291, 291, 29501, 411, 586, 2293, 11, 291, 458, 11, 437, 291, 445, 362, 382, 257, 18569, 294, 294, 2674, 13, 51296], "temperature": 0.0, "avg_logprob": -0.1536721480520148, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.008419045247137547}, {"id": 152, "seek": 95056, "start": 973.5999999999999, "end": 980.16, "text": " And you can play the same game for bananas now entangled bananas of higher spin. And so in our", "tokens": [51516, 400, 291, 393, 862, 264, 912, 1216, 337, 22742, 586, 948, 39101, 22742, 295, 2946, 6060, 13, 400, 370, 294, 527, 51844], "temperature": 0.0, "avg_logprob": -0.1536721480520148, "compression_ratio": 1.690909090909091, "no_speech_prob": 0.008419045247137547}, {"id": 153, "seek": 98016, "start": 980.16, "end": 985.8399999999999, "text": " book, we do this right. So here's what the correlation array looks like. Just one cell for a spin one", "tokens": [50364, 1446, 11, 321, 360, 341, 558, 13, 407, 510, 311, 437, 264, 20009, 10225, 1542, 411, 13, 1449, 472, 2815, 337, 257, 6060, 472, 50648], "temperature": 0.0, "avg_logprob": -0.15485789824505242, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0018313296604901552}, {"id": 154, "seek": 98016, "start": 985.8399999999999, "end": 991.4399999999999, "text": " banana. The anti correlation coefficient, it turns out, you know, which is defined like this.", "tokens": [50648, 14194, 13, 440, 6061, 20009, 17619, 11, 309, 4523, 484, 11, 291, 458, 11, 597, 307, 7642, 411, 341, 13, 50928], "temperature": 0.0, "avg_logprob": -0.15485789824505242, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0018313296604901552}, {"id": 155, "seek": 98016, "start": 992.16, "end": 998.0, "text": " I'll get to that in a moment, like stays the same is still the cosine. If you go for two,", "tokens": [50964, 286, 603, 483, 281, 300, 294, 257, 1623, 11, 411, 10834, 264, 912, 307, 920, 264, 23565, 13, 759, 291, 352, 337, 732, 11, 51256], "temperature": 0.0, "avg_logprob": -0.15485789824505242, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0018313296604901552}, {"id": 156, "seek": 98016, "start": 998.0, "end": 1005.8399999999999, "text": " three halves still the same cosines. So all these correlations are all like constrained by the exact", "tokens": [51256, 1045, 38490, 920, 264, 912, 3792, 1652, 13, 407, 439, 613, 13983, 763, 366, 439, 411, 38901, 538, 264, 1900, 51648], "temperature": 0.0, "avg_logprob": -0.15485789824505242, "compression_ratio": 1.7155555555555555, "no_speech_prob": 0.0018313296604901552}, {"id": 157, "seek": 100584, "start": 1005.84, "end": 1013.6800000000001, "text": " same elliptope inequality. That's not the case if you now try to simulate them with these raffles.", "tokens": [50364, 912, 8284, 22439, 1114, 16970, 13, 663, 311, 406, 264, 1389, 498, 291, 586, 853, 281, 27817, 552, 365, 613, 367, 40349, 13, 50756], "temperature": 0.0, "avg_logprob": -0.08388640330387996, "compression_ratio": 1.7716894977168949, "no_speech_prob": 0.0016468979883939028}, {"id": 158, "seek": 100584, "start": 1014.24, "end": 1019.76, "text": " So we saw that, you know, like if you do this for spin half, you get like the tetrahedron, right,", "tokens": [50784, 407, 321, 1866, 300, 11, 291, 458, 11, 411, 498, 291, 360, 341, 337, 6060, 1922, 11, 291, 483, 411, 264, 23319, 15688, 292, 2044, 11, 558, 11, 51060], "temperature": 0.0, "avg_logprob": -0.08388640330387996, "compression_ratio": 1.7716894977168949, "no_speech_prob": 0.0016468979883939028}, {"id": 159, "seek": 100584, "start": 1019.76, "end": 1025.92, "text": " so you get something with like four facets like this. If you now go up to higher spin, you see", "tokens": [51060, 370, 291, 483, 746, 365, 411, 1451, 49752, 411, 341, 13, 759, 291, 586, 352, 493, 281, 2946, 6060, 11, 291, 536, 51368], "temperature": 0.0, "avg_logprob": -0.08388640330387996, "compression_ratio": 1.7716894977168949, "no_speech_prob": 0.0016468979883939028}, {"id": 160, "seek": 100584, "start": 1025.92, "end": 1030.72, "text": " that you get a little more structure on these on these on these facets. So this is what it looks", "tokens": [51368, 300, 291, 483, 257, 707, 544, 3877, 322, 613, 322, 613, 322, 613, 49752, 13, 407, 341, 307, 437, 309, 1542, 51608], "temperature": 0.0, "avg_logprob": -0.08388640330387996, "compression_ratio": 1.7716894977168949, "no_speech_prob": 0.0016468979883939028}, {"id": 161, "seek": 103072, "start": 1030.72, "end": 1036.4, "text": " like for spin one and notice that this point here is going to touch the the the elliptope", "tokens": [50364, 411, 337, 6060, 472, 293, 3449, 300, 341, 935, 510, 307, 516, 281, 2557, 264, 264, 264, 8284, 22439, 1114, 50648], "temperature": 0.0, "avg_logprob": -0.17087683426706415, "compression_ratio": 1.8051282051282052, "no_speech_prob": 0.0019845778588205576}, {"id": 162, "seek": 103072, "start": 1038.08, "end": 1043.28, "text": " for for spin three halves, it's not going to touch the elliptope again. But for all integer spin,", "tokens": [50732, 337, 337, 6060, 1045, 38490, 11, 309, 311, 406, 516, 281, 2557, 264, 8284, 22439, 1114, 797, 13, 583, 337, 439, 24922, 6060, 11, 50992], "temperature": 0.0, "avg_logprob": -0.17087683426706415, "compression_ratio": 1.8051282051282052, "no_speech_prob": 0.0019845778588205576}, {"id": 163, "seek": 103072, "start": 1043.28, "end": 1047.1200000000001, "text": " it will, right, you see this gets more and more faceted, more and more", "tokens": [50992, 309, 486, 11, 558, 11, 291, 536, 341, 2170, 544, 293, 544, 1915, 10993, 11, 544, 293, 544, 51184], "temperature": 0.0, "avg_logprob": -0.17087683426706415, "compression_ratio": 1.8051282051282052, "no_speech_prob": 0.0019845778588205576}, {"id": 164, "seek": 103072, "start": 1048.96, "end": 1055.1200000000001, "text": " vertices. And like you can, it's very suggestive that if you go up to higher and higher spin,", "tokens": [51276, 32053, 13, 400, 411, 291, 393, 11, 309, 311, 588, 3402, 488, 300, 498, 291, 352, 493, 281, 2946, 293, 2946, 6060, 11, 51584], "temperature": 0.0, "avg_logprob": -0.17087683426706415, "compression_ratio": 1.8051282051282052, "no_speech_prob": 0.0019845778588205576}, {"id": 165, "seek": 105512, "start": 1055.12, "end": 1060.8, "text": " it gets more and more close to the elliptope, but never quite gets there, right.", "tokens": [50364, 309, 2170, 544, 293, 544, 1998, 281, 264, 8284, 22439, 1114, 11, 457, 1128, 1596, 2170, 456, 11, 558, 13, 50648], "temperature": 0.0, "avg_logprob": -0.154380576779144, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.00030514050740748644}, {"id": 166, "seek": 105512, "start": 1062.32, "end": 1070.4799999999998, "text": " Now, the so so far it may seem that this elliptope somehow captures like something special about", "tokens": [50724, 823, 11, 264, 370, 370, 1400, 309, 815, 1643, 300, 341, 8284, 22439, 1114, 6063, 27986, 411, 746, 2121, 466, 51132], "temperature": 0.0, "avg_logprob": -0.154380576779144, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.00030514050740748644}, {"id": 167, "seek": 105512, "start": 1070.4799999999998, "end": 1075.28, "text": " quantum mechanics, in particular, like we used, you know, sort of as hidden like in what I showed", "tokens": [51132, 13018, 12939, 11, 294, 1729, 11, 411, 321, 1143, 11, 291, 458, 11, 1333, 295, 382, 7633, 411, 294, 437, 286, 4712, 51372], "temperature": 0.0, "avg_logprob": -0.154380576779144, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.00030514050740748644}, {"id": 168, "seek": 105512, "start": 1075.28, "end": 1080.9599999999998, "text": " you, what we use like, you know, the Bourne rule, the Hilbert space formalism. But in fact, this", "tokens": [51372, 291, 11, 437, 321, 764, 411, 11, 291, 458, 11, 264, 35866, 716, 4978, 11, 264, 19914, 4290, 1901, 9860, 1434, 13, 583, 294, 1186, 11, 341, 51656], "temperature": 0.0, "avg_logprob": -0.154380576779144, "compression_ratio": 1.6460176991150441, "no_speech_prob": 0.00030514050740748644}, {"id": 169, "seek": 108096, "start": 1080.96, "end": 1087.04, "text": " inequality is not new to quantum mechanics at all. It has been known to statisticians since the 1890s,", "tokens": [50364, 16970, 307, 406, 777, 281, 13018, 12939, 412, 439, 13, 467, 575, 668, 2570, 281, 29588, 2567, 1670, 264, 47725, 82, 11, 50668], "temperature": 0.0, "avg_logprob": -0.10026928474163187, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.0037580314092338085}, {"id": 170, "seek": 108096, "start": 1087.04, "end": 1092.48, "text": " and it's basically a general constraint on the correlations between any three random variables,", "tokens": [50668, 293, 309, 311, 1936, 257, 2674, 25534, 322, 264, 13983, 763, 1296, 604, 1045, 4974, 9102, 11, 50940], "temperature": 0.0, "avg_logprob": -0.10026928474163187, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.0037580314092338085}, {"id": 171, "seek": 108096, "start": 1092.48, "end": 1096.16, "text": " right, which also like, you know, makes it understandable that even if you go to higher", "tokens": [50940, 558, 11, 597, 611, 411, 11, 291, 458, 11, 1669, 309, 25648, 300, 754, 498, 291, 352, 281, 2946, 51124], "temperature": 0.0, "avg_logprob": -0.10026928474163187, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.0037580314092338085}, {"id": 172, "seek": 108096, "start": 1096.16, "end": 1100.4, "text": " spin particles in quantum mechanics, you'll never get out of the get out of the elliptope.", "tokens": [51124, 6060, 10007, 294, 13018, 12939, 11, 291, 603, 1128, 483, 484, 295, 264, 483, 484, 295, 264, 8284, 22439, 1114, 13, 51336], "temperature": 0.0, "avg_logprob": -0.10026928474163187, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.0037580314092338085}, {"id": 173, "seek": 108096, "start": 1100.96, "end": 1106.72, "text": " So this work is due to Carl Pearson, and mostly to Utney Yule. So Pearson, of course, these days", "tokens": [51364, 407, 341, 589, 307, 3462, 281, 14256, 39041, 11, 293, 5240, 281, 12555, 2397, 398, 2271, 13, 407, 39041, 11, 295, 1164, 11, 613, 1708, 51652], "temperature": 0.0, "avg_logprob": -0.10026928474163187, "compression_ratio": 1.6288659793814433, "no_speech_prob": 0.0037580314092338085}, {"id": 174, "seek": 110672, "start": 1106.72, "end": 1111.52, "text": " is mostly remembers for his dubious role in the eugenics movement, but he's also like, you know,", "tokens": [50364, 307, 5240, 26228, 337, 702, 18540, 851, 3090, 294, 264, 308, 27915, 1167, 3963, 11, 457, 415, 311, 611, 411, 11, 291, 458, 11, 50604], "temperature": 0.0, "avg_logprob": -0.10694489597289031, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.0026610810309648514}, {"id": 175, "seek": 110672, "start": 1111.52, "end": 1117.28, "text": " like a very important character in statistics. So let me run to this quickly, right. So now we're", "tokens": [50604, 411, 257, 588, 1021, 2517, 294, 12523, 13, 407, 718, 385, 1190, 281, 341, 2661, 11, 558, 13, 407, 586, 321, 434, 50892], "temperature": 0.0, "avg_logprob": -0.10694489597289031, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.0026610810309648514}, {"id": 176, "seek": 110672, "start": 1117.28, "end": 1122.32, "text": " talking about some arbitrary random variables with sets of possible outcomes that I'm going to", "tokens": [50892, 1417, 466, 512, 23211, 4974, 9102, 365, 6352, 295, 1944, 10070, 300, 286, 478, 516, 281, 51144], "temperature": 0.0, "avg_logprob": -0.10694489597289031, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.0026610810309648514}, {"id": 177, "seek": 110672, "start": 1122.32, "end": 1127.52, "text": " keep discreet. And in fact, I'm only interested in a case where you have you have a random variable", "tokens": [51144, 1066, 2983, 4751, 13, 400, 294, 1186, 11, 286, 478, 787, 3102, 294, 257, 1389, 689, 291, 362, 291, 362, 257, 4974, 7006, 51404], "temperature": 0.0, "avg_logprob": -0.10694489597289031, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.0026610810309648514}, {"id": 178, "seek": 110672, "start": 1127.52, "end": 1135.44, "text": " with only two outcomes, like, you know, yummy and nasty. And so I'm going to restrict my attention to", "tokens": [51404, 365, 787, 732, 10070, 11, 411, 11, 291, 458, 11, 18576, 293, 17923, 13, 400, 370, 286, 478, 516, 281, 7694, 452, 3202, 281, 51800], "temperature": 0.0, "avg_logprob": -0.10694489597289031, "compression_ratio": 1.7288732394366197, "no_speech_prob": 0.0026610810309648514}, {"id": 179, "seek": 113544, "start": 1136.0, "end": 1142.56, "text": " what we call balanced random variables. And that just means that if X i X of i is a possible value,", "tokens": [50392, 437, 321, 818, 13902, 4974, 9102, 13, 400, 300, 445, 1355, 300, 498, 1783, 741, 1783, 295, 741, 307, 257, 1944, 2158, 11, 50720], "temperature": 0.0, "avg_logprob": -0.10982960148861534, "compression_ratio": 1.897560975609756, "no_speech_prob": 0.0013452108250930905}, {"id": 180, "seek": 113544, "start": 1142.56, "end": 1149.52, "text": " minus X i is two, and that the probability of X i and the probability of minus X i is the same.", "tokens": [50720, 3175, 1783, 741, 307, 732, 11, 293, 300, 264, 8482, 295, 1783, 741, 293, 264, 8482, 295, 3175, 1783, 741, 307, 264, 912, 13, 51068], "temperature": 0.0, "avg_logprob": -0.10982960148861534, "compression_ratio": 1.897560975609756, "no_speech_prob": 0.0013452108250930905}, {"id": 181, "seek": 113544, "start": 1150.4, "end": 1156.24, "text": " And that simplifies matters, because that means that in that case, the expectation value is going", "tokens": [51112, 400, 300, 6883, 11221, 7001, 11, 570, 300, 1355, 300, 294, 300, 1389, 11, 264, 14334, 2158, 307, 516, 51404], "temperature": 0.0, "avg_logprob": -0.10982960148861534, "compression_ratio": 1.897560975609756, "no_speech_prob": 0.0013452108250930905}, {"id": 182, "seek": 113544, "start": 1156.24, "end": 1162.88, "text": " to be zero. And that simplifies like some other variables that some other quantities that we're", "tokens": [51404, 281, 312, 4018, 13, 400, 300, 6883, 11221, 411, 512, 661, 9102, 300, 512, 661, 22927, 300, 321, 434, 51736], "temperature": 0.0, "avg_logprob": -0.10982960148861534, "compression_ratio": 1.897560975609756, "no_speech_prob": 0.0013452108250930905}, {"id": 183, "seek": 116288, "start": 1162.88, "end": 1168.0, "text": " interested in. So we're looking at the variance, right? So the expectation value of X minus the", "tokens": [50364, 3102, 294, 13, 407, 321, 434, 1237, 412, 264, 21977, 11, 558, 30, 407, 264, 14334, 2158, 295, 1783, 3175, 264, 50620], "temperature": 0.0, "avg_logprob": -0.08747003789533649, "compression_ratio": 2.259433962264151, "no_speech_prob": 0.0005975326057523489}, {"id": 184, "seek": 116288, "start": 1168.0, "end": 1174.0, "text": " expected value of X squared. If the expected value of X is zero, then the variation of X is just the", "tokens": [50620, 5176, 2158, 295, 1783, 8889, 13, 759, 264, 5176, 2158, 295, 1783, 307, 4018, 11, 550, 264, 12990, 295, 1783, 307, 445, 264, 50920], "temperature": 0.0, "avg_logprob": -0.08747003789533649, "compression_ratio": 2.259433962264151, "no_speech_prob": 0.0005975326057523489}, {"id": 185, "seek": 116288, "start": 1174.0, "end": 1180.0800000000002, "text": " expectation value of X squared. The standard deviation is the square root of that. And then", "tokens": [50920, 14334, 2158, 295, 1783, 8889, 13, 440, 3832, 25163, 307, 264, 3732, 5593, 295, 300, 13, 400, 550, 51224], "temperature": 0.0, "avg_logprob": -0.08747003789533649, "compression_ratio": 2.259433962264151, "no_speech_prob": 0.0005975326057523489}, {"id": 186, "seek": 116288, "start": 1180.0800000000002, "end": 1185.5200000000002, "text": " the covariance, again, like, you know, in general would be like the expectation value of X minus", "tokens": [51224, 264, 49851, 719, 11, 797, 11, 411, 11, 291, 458, 11, 294, 2674, 576, 312, 411, 264, 14334, 2158, 295, 1783, 3175, 51496], "temperature": 0.0, "avg_logprob": -0.08747003789533649, "compression_ratio": 2.259433962264151, "no_speech_prob": 0.0005975326057523489}, {"id": 187, "seek": 116288, "start": 1185.5200000000002, "end": 1190.88, "text": " the expectation value of X times Y minus the expectation value of Y, if these two expectation", "tokens": [51496, 264, 14334, 2158, 295, 1783, 1413, 398, 3175, 264, 14334, 2158, 295, 398, 11, 498, 613, 732, 14334, 51764], "temperature": 0.0, "avg_logprob": -0.08747003789533649, "compression_ratio": 2.259433962264151, "no_speech_prob": 0.0005975326057523489}, {"id": 188, "seek": 119088, "start": 1190.88, "end": 1198.0800000000002, "text": " values are zero, then that is just going to be equal to the expectation value of X times Y.", "tokens": [50364, 4190, 366, 4018, 11, 550, 300, 307, 445, 516, 281, 312, 2681, 281, 264, 14334, 2158, 295, 1783, 1413, 398, 13, 50724], "temperature": 0.0, "avg_logprob": -0.09834964623611965, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.0012828005710616708}, {"id": 189, "seek": 119088, "start": 1199.68, "end": 1204.5600000000002, "text": " And I now introduce like what is called the Pearson correlation coefficient, which is just the", "tokens": [50804, 400, 286, 586, 5366, 411, 437, 307, 1219, 264, 39041, 20009, 17619, 11, 597, 307, 445, 264, 51048], "temperature": 0.0, "avg_logprob": -0.09834964623611965, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.0012828005710616708}, {"id": 190, "seek": 119088, "start": 1204.5600000000002, "end": 1213.2, "text": " covariance of the Pearson correlation coefficients of X and Y is the covariance of X and Y divided", "tokens": [51048, 49851, 719, 295, 264, 39041, 20009, 31994, 295, 1783, 293, 398, 307, 264, 49851, 719, 295, 1783, 293, 398, 6666, 51480], "temperature": 0.0, "avg_logprob": -0.09834964623611965, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.0012828005710616708}, {"id": 191, "seek": 119088, "start": 1213.2, "end": 1220.0800000000002, "text": " by the corresponding standard deviation, sigma X and sigma Y. And so if X and Y are balanced,", "tokens": [51480, 538, 264, 11760, 3832, 25163, 11, 12771, 1783, 293, 12771, 398, 13, 400, 370, 498, 1783, 293, 398, 366, 13902, 11, 51824], "temperature": 0.0, "avg_logprob": -0.09834964623611965, "compression_ratio": 1.8047619047619048, "no_speech_prob": 0.0012828005710616708}, {"id": 192, "seek": 122008, "start": 1220.1599999999999, "end": 1226.8799999999999, "text": " this is just the expectation value of X and Y divided by these standard deviations.", "tokens": [50368, 341, 307, 445, 264, 14334, 2158, 295, 1783, 293, 398, 6666, 538, 613, 3832, 31219, 763, 13, 50704], "temperature": 0.0, "avg_logprob": -0.09745393260832756, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.00040431699017062783}, {"id": 193, "seek": 122008, "start": 1226.8799999999999, "end": 1233.52, "text": " And you can immediately see two properties like, you know, the Pearson correlation coefficient", "tokens": [50704, 400, 291, 393, 4258, 536, 732, 7221, 411, 11, 291, 458, 11, 264, 39041, 20009, 17619, 51036], "temperature": 0.0, "avg_logprob": -0.09745393260832756, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.00040431699017062783}, {"id": 194, "seek": 122008, "start": 1233.52, "end": 1239.04, "text": " of a variable with itself is just one. And it doesn't matter if you look at a correlation coefficient", "tokens": [51036, 295, 257, 7006, 365, 2564, 307, 445, 472, 13, 400, 309, 1177, 380, 1871, 498, 291, 574, 412, 257, 20009, 17619, 51312], "temperature": 0.0, "avg_logprob": -0.09745393260832756, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.00040431699017062783}, {"id": 195, "seek": 123904, "start": 1239.04, "end": 1250.32, "text": " X, Y or Y, X. And we'll now I'll now prove for you that such such any triplet of such variables", "tokens": [50364, 1783, 11, 398, 420, 398, 11, 1783, 13, 400, 321, 603, 586, 286, 603, 586, 7081, 337, 291, 300, 1270, 1270, 604, 1376, 14657, 295, 1270, 9102, 50928], "temperature": 0.0, "avg_logprob": -0.12309981681205132, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0012642706278711557}, {"id": 196, "seek": 123904, "start": 1250.32, "end": 1254.96, "text": " is going to have to satisfy this elliptope inequality. And this was shown by Yule in the", "tokens": [50928, 307, 516, 281, 362, 281, 19319, 341, 8284, 22439, 1114, 16970, 13, 400, 341, 390, 4898, 538, 398, 2271, 294, 264, 51160], "temperature": 0.0, "avg_logprob": -0.12309981681205132, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0012642706278711557}, {"id": 197, "seek": 123904, "start": 1254.96, "end": 1260.24, "text": " late 1890s. So here's where here's one way to do it, like, you know, consider, you know, for any", "tokens": [51160, 3469, 47725, 82, 13, 407, 510, 311, 689, 510, 311, 472, 636, 281, 360, 309, 11, 411, 11, 291, 458, 11, 1949, 11, 291, 458, 11, 337, 604, 51424], "temperature": 0.0, "avg_logprob": -0.12309981681205132, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0012642706278711557}, {"id": 198, "seek": 123904, "start": 1260.24, "end": 1267.84, "text": " triplet v1 v2 v3, like this quantity over here. So I'm looking at the expectation value of some", "tokens": [51424, 1376, 14657, 371, 16, 371, 17, 371, 18, 11, 411, 341, 11275, 670, 510, 13, 407, 286, 478, 1237, 412, 264, 14334, 2158, 295, 512, 51804], "temperature": 0.0, "avg_logprob": -0.12309981681205132, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0012642706278711557}, {"id": 199, "seek": 126784, "start": 1267.84, "end": 1272.6399999999999, "text": " expression squared. So I know this is going to be greater or equal to zero. And now I'm going to", "tokens": [50364, 6114, 8889, 13, 407, 286, 458, 341, 307, 516, 281, 312, 5044, 420, 2681, 281, 4018, 13, 400, 586, 286, 478, 516, 281, 50604], "temperature": 0.0, "avg_logprob": -0.13006398412916395, "compression_ratio": 1.75, "no_speech_prob": 0.0011865560663864017}, {"id": 200, "seek": 126784, "start": 1272.6399999999999, "end": 1278.9599999999998, "text": " work this out. Okay, so I take like, you know, like this term times the rest that gives me this", "tokens": [50604, 589, 341, 484, 13, 1033, 11, 370, 286, 747, 411, 11, 291, 458, 11, 411, 341, 1433, 1413, 264, 1472, 300, 2709, 385, 341, 50920], "temperature": 0.0, "avg_logprob": -0.13006398412916395, "compression_ratio": 1.75, "no_speech_prob": 0.0011865560663864017}, {"id": 201, "seek": 126784, "start": 1278.9599999999998, "end": 1286.08, "text": " here, right. And so notes that I now get like, you know, v1. And then I have like, x times x,", "tokens": [50920, 510, 11, 558, 13, 400, 370, 5570, 300, 286, 586, 483, 411, 11, 291, 458, 11, 371, 16, 13, 400, 550, 286, 362, 411, 11, 2031, 1413, 2031, 11, 51276], "temperature": 0.0, "avg_logprob": -0.13006398412916395, "compression_ratio": 1.75, "no_speech_prob": 0.0011865560663864017}, {"id": 202, "seek": 126784, "start": 1286.08, "end": 1292.24, "text": " right, expectation value x squared divided by sigma x squared. And then we have the x times the y,", "tokens": [51276, 558, 11, 14334, 2158, 2031, 8889, 6666, 538, 12771, 2031, 8889, 13, 400, 550, 321, 362, 264, 2031, 1413, 264, 288, 11, 51584], "temperature": 0.0, "avg_logprob": -0.13006398412916395, "compression_ratio": 1.75, "no_speech_prob": 0.0011865560663864017}, {"id": 203, "seek": 129224, "start": 1292.24, "end": 1299.76, "text": " the x times z. And then you have similar terms for like, if you now do the v2 y over sigma y and v3", "tokens": [50364, 264, 2031, 1413, 710, 13, 400, 550, 291, 362, 2531, 2115, 337, 411, 11, 498, 291, 586, 360, 264, 371, 17, 288, 670, 12771, 288, 293, 371, 18, 50740], "temperature": 0.0, "avg_logprob": -0.13977373563326323, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0024336560163646936}, {"id": 204, "seek": 129224, "start": 1299.76, "end": 1305.84, "text": " z over sigma c. And you see that in here, like you have like all these Pearson correlation", "tokens": [50740, 710, 670, 12771, 269, 13, 400, 291, 536, 300, 294, 510, 11, 411, 291, 362, 411, 439, 613, 39041, 20009, 51044], "temperature": 0.0, "avg_logprob": -0.13977373563326323, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0024336560163646936}, {"id": 205, "seek": 129224, "start": 1305.84, "end": 1311.1200000000001, "text": " coefficients, it just looks like that. Right. And I can write this like a little more", "tokens": [51044, 31994, 11, 309, 445, 1542, 411, 300, 13, 1779, 13, 400, 286, 393, 2464, 341, 411, 257, 707, 544, 51308], "temperature": 0.0, "avg_logprob": -0.13977373563326323, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0024336560163646936}, {"id": 206, "seek": 129224, "start": 1311.68, "end": 1318.64, "text": " concisely and compactly as justice matrix with these Pearson correlation coefficients", "tokens": [51336, 1588, 271, 736, 293, 14679, 356, 382, 6118, 8141, 365, 613, 39041, 20009, 31994, 51684], "temperature": 0.0, "avg_logprob": -0.13977373563326323, "compression_ratio": 1.7572815533980584, "no_speech_prob": 0.0024336560163646936}, {"id": 207, "seek": 131864, "start": 1318.72, "end": 1327.5200000000002, "text": " sandwiched between like, you know, the column vector v1 v2 v3, and the row vector v1 v2 v3.", "tokens": [50368, 11141, 292, 1296, 411, 11, 291, 458, 11, 264, 7738, 8062, 371, 16, 371, 17, 371, 18, 11, 293, 264, 5386, 8062, 371, 16, 371, 17, 371, 18, 13, 50808], "temperature": 0.0, "avg_logprob": -0.10584013278667743, "compression_ratio": 1.845, "no_speech_prob": 0.0007318372372537851}, {"id": 208, "seek": 131864, "start": 1328.4, "end": 1335.8400000000001, "text": " And remember that this thing has to be greater or equal than zero for any, for any value of v1,", "tokens": [50852, 400, 1604, 300, 341, 551, 575, 281, 312, 5044, 420, 2681, 813, 4018, 337, 604, 11, 337, 604, 2158, 295, 371, 16, 11, 51224], "temperature": 0.0, "avg_logprob": -0.10584013278667743, "compression_ratio": 1.845, "no_speech_prob": 0.0007318372372537851}, {"id": 209, "seek": 131864, "start": 1335.8400000000001, "end": 1341.76, "text": " v2, v3, which means that that matrix row is positive semi definite, which means that the", "tokens": [51224, 371, 17, 11, 371, 18, 11, 597, 1355, 300, 300, 8141, 5386, 307, 3353, 12909, 25131, 11, 597, 1355, 300, 264, 51520], "temperature": 0.0, "avg_logprob": -0.10584013278667743, "compression_ratio": 1.845, "no_speech_prob": 0.0007318372372537851}, {"id": 210, "seek": 131864, "start": 1341.76, "end": 1348.0800000000002, "text": " determinant of row has to be greater or equal than zero. And it follows that, you know, that", "tokens": [51520, 41296, 295, 5386, 575, 281, 312, 5044, 420, 2681, 813, 4018, 13, 400, 309, 10002, 300, 11, 291, 458, 11, 300, 51836], "temperature": 0.0, "avg_logprob": -0.10584013278667743, "compression_ratio": 1.845, "no_speech_prob": 0.0007318372372537851}, {"id": 211, "seek": 134808, "start": 1348.08, "end": 1355.36, "text": " that's just the elliptope inequality. Right. So there we have it again. Okay. So now,", "tokens": [50364, 300, 311, 445, 264, 8284, 22439, 1114, 16970, 13, 1779, 13, 407, 456, 321, 362, 309, 797, 13, 1033, 13, 407, 586, 11, 50728], "temperature": 0.0, "avg_logprob": -0.16419938345935858, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.001262650010176003}, {"id": 212, "seek": 134808, "start": 1357.28, "end": 1364.0, "text": " look at the special case that x, y, and z are the taste of Alice's banana, right, in this", "tokens": [50824, 574, 412, 264, 2121, 1389, 300, 2031, 11, 288, 11, 293, 710, 366, 264, 3939, 295, 16004, 311, 14194, 11, 558, 11, 294, 341, 51160], "temperature": 0.0, "avg_logprob": -0.16419938345935858, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.001262650010176003}, {"id": 213, "seek": 134808, "start": 1364.0, "end": 1370.6399999999999, "text": " experiment in the, in the Merman setup, right. So x is the, the taste of Alice's banana when she", "tokens": [51160, 5120, 294, 264, 11, 294, 264, 376, 11821, 8657, 11, 558, 13, 407, 2031, 307, 264, 11, 264, 3939, 295, 16004, 311, 14194, 562, 750, 51492], "temperature": 0.0, "avg_logprob": -0.16419938345935858, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.001262650010176003}, {"id": 214, "seek": 134808, "start": 1370.6399999999999, "end": 1375.9199999999998, "text": " peels in the A direction, y is the taste of Alice's banana when she peels in the B direction and z", "tokens": [51492, 520, 1625, 294, 264, 316, 3513, 11, 288, 307, 264, 3939, 295, 16004, 311, 14194, 562, 750, 520, 1625, 294, 264, 363, 3513, 293, 710, 51756], "temperature": 0.0, "avg_logprob": -0.16419938345935858, "compression_ratio": 1.8737373737373737, "no_speech_prob": 0.001262650010176003}, {"id": 215, "seek": 137592, "start": 1375.92, "end": 1382.3200000000002, "text": " is the taste when Alice's banana when she peels in the C direction. All right. So now the obvious", "tokens": [50364, 307, 264, 3939, 562, 16004, 311, 14194, 562, 750, 520, 1625, 294, 264, 383, 3513, 13, 1057, 558, 13, 407, 586, 264, 6322, 50684], "temperature": 0.0, "avg_logprob": -0.14796559745018636, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0008940025581978261}, {"id": 216, "seek": 137592, "start": 1382.3200000000002, "end": 1389.04, "text": " problem is, is that as Papescu points out in the, in the preface or the forward of banana world,", "tokens": [50684, 1154, 307, 11, 307, 300, 382, 15919, 279, 12032, 2793, 484, 294, 264, 11, 294, 264, 659, 2868, 420, 264, 2128, 295, 14194, 1002, 11, 51020], "temperature": 0.0, "avg_logprob": -0.14796559745018636, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0008940025581978261}, {"id": 217, "seek": 137592, "start": 1389.76, "end": 1394.8000000000002, "text": " a banana can only be eaten once, right, once it's peeled, it's peeled, once it's tasted, it's", "tokens": [51056, 257, 14194, 393, 787, 312, 12158, 1564, 11, 558, 11, 1564, 309, 311, 39033, 11, 309, 311, 39033, 11, 1564, 309, 311, 25003, 11, 309, 311, 51308], "temperature": 0.0, "avg_logprob": -0.14796559745018636, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0008940025581978261}, {"id": 218, "seek": 137592, "start": 1394.8000000000002, "end": 1402.0800000000002, "text": " tasted. But there's, we'll see there's ways around this, this, this problem. So first I note that", "tokens": [51308, 25003, 13, 583, 456, 311, 11, 321, 603, 536, 456, 311, 2098, 926, 341, 11, 341, 11, 341, 1154, 13, 407, 700, 286, 3637, 300, 51672], "temperature": 0.0, "avg_logprob": -0.14796559745018636, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0008940025581978261}, {"id": 219, "seek": 140208, "start": 1402.08, "end": 1406.8799999999999, "text": " these variables are balanced, right. So we have to now give them some numerical value rather than", "tokens": [50364, 613, 9102, 366, 13902, 11, 558, 13, 407, 321, 362, 281, 586, 976, 552, 512, 29054, 2158, 2831, 813, 50604], "temperature": 0.0, "avg_logprob": -0.12643396286737352, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00679427944123745}, {"id": 220, "seek": 140208, "start": 1406.8799999999999, "end": 1412.6399999999999, "text": " just yummy or nasty, but you know, inspired by spin, you know, like instead of having like a half", "tokens": [50604, 445, 18576, 420, 17923, 11, 457, 291, 458, 11, 7547, 538, 6060, 11, 291, 458, 11, 411, 2602, 295, 1419, 411, 257, 1922, 50892], "temperature": 0.0, "avg_logprob": -0.12643396286737352, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00679427944123745}, {"id": 221, "seek": 140208, "start": 1412.6399999999999, "end": 1419.36, "text": " h bar, we now have like a half, like a B bar, you know, which I call the banana split, which is just", "tokens": [50892, 276, 2159, 11, 321, 586, 362, 411, 257, 1922, 11, 411, 257, 363, 2159, 11, 291, 458, 11, 597, 286, 818, 264, 14194, 7472, 11, 597, 307, 445, 51228], "temperature": 0.0, "avg_logprob": -0.12643396286737352, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00679427944123745}, {"id": 222, "seek": 140208, "start": 1419.36, "end": 1426.08, "text": " boops constant B divided by two pi. And we're going to pick units such that B bar is equal to one.", "tokens": [51228, 748, 3370, 5754, 363, 6666, 538, 732, 3895, 13, 400, 321, 434, 516, 281, 1888, 6815, 1270, 300, 363, 2159, 307, 2681, 281, 472, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12643396286737352, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00679427944123745}, {"id": 223, "seek": 142608, "start": 1427.04, "end": 1432.24, "text": " And so then, you know, these, we see that these, that these variables are perfectly balanced,", "tokens": [50412, 400, 370, 550, 11, 291, 458, 11, 613, 11, 321, 536, 300, 613, 11, 300, 613, 9102, 366, 6239, 13902, 11, 50672], "temperature": 0.0, "avg_logprob": -0.1145529567070727, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.0004372377588879317}, {"id": 224, "seek": 142608, "start": 1432.24, "end": 1439.52, "text": " the expectation value is zero, the variance, right. So it's like, you know, half, half the time,", "tokens": [50672, 264, 14334, 2158, 307, 4018, 11, 264, 21977, 11, 558, 13, 407, 309, 311, 411, 11, 291, 458, 11, 1922, 11, 1922, 264, 565, 11, 51036], "temperature": 0.0, "avg_logprob": -0.1145529567070727, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.0004372377588879317}, {"id": 225, "seek": 142608, "start": 1439.52, "end": 1446.24, "text": " like, you know, it's the product is, it's, it's, it's one half squared, the other half is like,", "tokens": [51036, 411, 11, 291, 458, 11, 309, 311, 264, 1674, 307, 11, 309, 311, 11, 309, 311, 11, 309, 311, 472, 1922, 8889, 11, 264, 661, 1922, 307, 411, 11, 51372], "temperature": 0.0, "avg_logprob": -0.1145529567070727, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.0004372377588879317}, {"id": 226, "seek": 142608, "start": 1446.24, "end": 1451.04, "text": " you know, minus a half squared, and that adds up to one fourth, the standard deviation take the", "tokens": [51372, 291, 458, 11, 3175, 257, 1922, 8889, 11, 293, 300, 10860, 493, 281, 472, 6409, 11, 264, 3832, 25163, 747, 264, 51612], "temperature": 0.0, "avg_logprob": -0.1145529567070727, "compression_ratio": 1.891089108910891, "no_speech_prob": 0.0004372377588879317}, {"id": 227, "seek": 145104, "start": 1451.04, "end": 1457.2, "text": " square root that is like a half. Now the covariance here, it's a little trickier.", "tokens": [50364, 3732, 5593, 300, 307, 411, 257, 1922, 13, 823, 264, 49851, 719, 510, 11, 309, 311, 257, 707, 4282, 811, 13, 50672], "temperature": 0.0, "avg_logprob": -0.13532743087181678, "compression_ratio": 1.65625, "no_speech_prob": 0.00034050288377329707}, {"id": 228, "seek": 145104, "start": 1458.32, "end": 1463.68, "text": " And what we're going to do. And like, you know, if you, if you're squeamish about this, like, we", "tokens": [50728, 400, 437, 321, 434, 516, 281, 360, 13, 400, 411, 11, 291, 458, 11, 498, 291, 11, 498, 291, 434, 8447, 335, 742, 466, 341, 11, 411, 11, 321, 50996], "temperature": 0.0, "avg_logprob": -0.13532743087181678, "compression_ratio": 1.65625, "no_speech_prob": 0.00034050288377329707}, {"id": 229, "seek": 145104, "start": 1463.68, "end": 1470.6399999999999, "text": " did find a way to avoid like this counterfactual reasoning. But I think it's perfectly innocuous.", "tokens": [50996, 630, 915, 257, 636, 281, 5042, 411, 341, 5682, 44919, 901, 21577, 13, 583, 286, 519, 309, 311, 6239, 10843, 12549, 13, 51344], "temperature": 0.0, "avg_logprob": -0.13532743087181678, "compression_ratio": 1.65625, "no_speech_prob": 0.00034050288377329707}, {"id": 230, "seek": 145104, "start": 1470.6399999999999, "end": 1477.52, "text": " We're going to use my the opposite, if you want to find the covariance of the variables Alice,", "tokens": [51344, 492, 434, 516, 281, 764, 452, 264, 6182, 11, 498, 291, 528, 281, 915, 264, 49851, 719, 295, 264, 9102, 16004, 11, 51688], "temperature": 0.0, "avg_logprob": -0.13532743087181678, "compression_ratio": 1.65625, "no_speech_prob": 0.00034050288377329707}, {"id": 231, "seek": 147752, "start": 1478.4, "end": 1483.36, "text": " Alice's taste of banana when peeling a and the taste of Alice's banana when peeling B.", "tokens": [50408, 16004, 311, 3939, 295, 14194, 562, 39926, 257, 293, 264, 3939, 295, 16004, 311, 14194, 562, 39926, 363, 13, 50656], "temperature": 0.0, "avg_logprob": -0.24198922878358423, "compression_ratio": 1.6473684210526316, "no_speech_prob": 0.002470939187332988}, {"id": 232, "seek": 147752, "start": 1484.32, "end": 1494.72, "text": " So half Alice appeal a and then have her use minus what Bob finds when he peels B as a proxy", "tokens": [50704, 407, 1922, 16004, 13668, 257, 293, 550, 362, 720, 764, 3175, 437, 6085, 10704, 562, 415, 520, 1625, 363, 382, 257, 29690, 51224], "temperature": 0.0, "avg_logprob": -0.24198922878358423, "compression_ratio": 1.6473684210526316, "no_speech_prob": 0.002470939187332988}, {"id": 233, "seek": 147752, "start": 1494.72, "end": 1498.6399999999999, "text": " for what she would have find had she peeled B instead.", "tokens": [51224, 337, 437, 750, 576, 362, 915, 632, 750, 39033, 363, 2602, 13, 51420], "temperature": 0.0, "avg_logprob": -0.24198922878358423, "compression_ratio": 1.6473684210526316, "no_speech_prob": 0.002470939187332988}, {"id": 234, "seek": 147752, "start": 1501.12, "end": 1505.92, "text": " And so basically, like, you know, that so we use we calculate this thing here,", "tokens": [51544, 400, 370, 1936, 11, 411, 11, 291, 458, 11, 300, 370, 321, 764, 321, 8873, 341, 551, 510, 11, 51784], "temperature": 0.0, "avg_logprob": -0.24198922878358423, "compression_ratio": 1.6473684210526316, "no_speech_prob": 0.002470939187332988}, {"id": 235, "seek": 150592, "start": 1505.92, "end": 1513.8400000000001, "text": " and we can use our correlation array to figure this out. Right. So we have like, if the if the", "tokens": [50364, 293, 321, 393, 764, 527, 20009, 10225, 281, 2573, 341, 484, 13, 1779, 13, 407, 321, 362, 411, 11, 498, 264, 498, 264, 50760], "temperature": 0.0, "avg_logprob": -0.193793451218378, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0016442411579191685}, {"id": 236, "seek": 150592, "start": 1513.8400000000001, "end": 1523.28, "text": " if the tastes are are the are the same, we get we get we get like one fourth. What is the probability", "tokens": [50760, 498, 264, 8666, 366, 366, 264, 366, 264, 912, 11, 321, 483, 321, 483, 321, 483, 411, 472, 6409, 13, 708, 307, 264, 8482, 51232], "temperature": 0.0, "avg_logprob": -0.193793451218378, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0016442411579191685}, {"id": 237, "seek": 150592, "start": 1523.28, "end": 1527.92, "text": " of that happening? Well, you need to add these two things. Right. So that's a half one minus", "tokens": [51232, 295, 300, 2737, 30, 1042, 11, 291, 643, 281, 909, 613, 732, 721, 13, 1779, 13, 407, 300, 311, 257, 1922, 472, 3175, 51464], "temperature": 0.0, "avg_logprob": -0.193793451218378, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0016442411579191685}, {"id": 238, "seek": 150592, "start": 1528.5600000000002, "end": 1533.1200000000001, "text": " guy AB. And then, you know, like, if they're opposite, it's minus one fourth. And the probability", "tokens": [51496, 2146, 13838, 13, 400, 550, 11, 291, 458, 11, 411, 11, 498, 436, 434, 6182, 11, 309, 311, 3175, 472, 6409, 13, 400, 264, 8482, 51724], "temperature": 0.0, "avg_logprob": -0.193793451218378, "compression_ratio": 1.775229357798165, "no_speech_prob": 0.0016442411579191685}, {"id": 239, "seek": 153312, "start": 1533.12, "end": 1537.9199999999998, "text": " of that happening is this, if you work this out, you see that this is one fourth times guy AB.", "tokens": [50364, 295, 300, 2737, 307, 341, 11, 498, 291, 589, 341, 484, 11, 291, 536, 300, 341, 307, 472, 6409, 1413, 2146, 13838, 13, 50604], "temperature": 0.0, "avg_logprob": -0.17517823571557398, "compression_ratio": 1.8214285714285714, "no_speech_prob": 0.001699640415608883}, {"id": 240, "seek": 153312, "start": 1538.6399999999999, "end": 1542.3999999999999, "text": " And if you now like calculate the Pearson correlation coefficient, you see that that is", "tokens": [50640, 400, 498, 291, 586, 411, 8873, 264, 39041, 20009, 17619, 11, 291, 536, 300, 300, 307, 50828], "temperature": 0.0, "avg_logprob": -0.17517823571557398, "compression_ratio": 1.8214285714285714, "no_speech_prob": 0.001699640415608883}, {"id": 241, "seek": 153312, "start": 1542.3999999999999, "end": 1548.9599999999998, "text": " exactly equal to guy AB. Right. I already took an advance on that result calling this guy be like", "tokens": [50828, 2293, 2681, 281, 2146, 13838, 13, 1779, 13, 286, 1217, 1890, 364, 7295, 322, 300, 1874, 5141, 341, 2146, 312, 411, 51156], "temperature": 0.0, "avg_logprob": -0.17517823571557398, "compression_ratio": 1.8214285714285714, "no_speech_prob": 0.001699640415608883}, {"id": 242, "seek": 153312, "start": 1548.9599999999998, "end": 1552.2399999999998, "text": " an anti correlation coefficient, right. And the anti is because of this minus.", "tokens": [51156, 364, 6061, 20009, 17619, 11, 558, 13, 400, 264, 6061, 307, 570, 295, 341, 3175, 13, 51320], "temperature": 0.0, "avg_logprob": -0.17517823571557398, "compression_ratio": 1.8214285714285714, "no_speech_prob": 0.001699640415608883}, {"id": 243, "seek": 153312, "start": 1554.4799999999998, "end": 1560.2399999999998, "text": " All right. So the elliptop inequality, you know, I can just now write for this for these particular", "tokens": [51432, 1057, 558, 13, 407, 264, 8284, 22439, 404, 16970, 11, 291, 458, 11, 286, 393, 445, 586, 2464, 337, 341, 337, 613, 1729, 51720], "temperature": 0.0, "avg_logprob": -0.17517823571557398, "compression_ratio": 1.8214285714285714, "no_speech_prob": 0.001699640415608883}, {"id": 244, "seek": 156024, "start": 1560.24, "end": 1563.92, "text": " variables, right. So in terms of these rows, now, in terms of these guys.", "tokens": [50364, 9102, 11, 558, 13, 407, 294, 2115, 295, 613, 13241, 11, 586, 11, 294, 2115, 295, 613, 1074, 13, 50548], "temperature": 0.0, "avg_logprob": -0.18877933001277422, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0007092112791724503}, {"id": 245, "seek": 156024, "start": 1565.76, "end": 1571.28, "text": " And so this is just exactly the same. But there is a few problems, right. So the first problem", "tokens": [50640, 400, 370, 341, 307, 445, 2293, 264, 912, 13, 583, 456, 307, 257, 1326, 2740, 11, 558, 13, 407, 264, 700, 1154, 50916], "temperature": 0.0, "avg_logprob": -0.18877933001277422, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0007092112791724503}, {"id": 246, "seek": 156024, "start": 1571.28, "end": 1578.8, "text": " we already dealt with, like, how do we determine the taste of these two of a Alice feeling a and", "tokens": [50916, 321, 1217, 15991, 365, 11, 411, 11, 577, 360, 321, 6997, 264, 3939, 295, 613, 732, 295, 257, 16004, 2633, 257, 293, 51292], "temperature": 0.0, "avg_logprob": -0.18877933001277422, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0007092112791724503}, {"id": 247, "seek": 156024, "start": 1578.8, "end": 1585.6, "text": " Alice feeling B and one run? Well, you know, have or use Bob's result as a proxy for one of those.", "tokens": [51292, 16004, 2633, 363, 293, 472, 1190, 30, 1042, 11, 291, 458, 11, 362, 420, 764, 6085, 311, 1874, 382, 257, 29690, 337, 472, 295, 729, 13, 51632], "temperature": 0.0, "avg_logprob": -0.18877933001277422, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0007092112791724503}, {"id": 248, "seek": 158560, "start": 1585.6, "end": 1591.1999999999998, "text": " Right. Now, the second problem is like, you know, we can only do this for two tastes for two", "tokens": [50364, 1779, 13, 823, 11, 264, 1150, 1154, 307, 411, 11, 291, 458, 11, 321, 393, 787, 360, 341, 337, 732, 8666, 337, 732, 50644], "temperature": 0.0, "avg_logprob": -0.16057521577865358, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.0004171498876530677}, {"id": 249, "seek": 158560, "start": 1591.1999999999998, "end": 1596.6399999999999, "text": " feelings in one run. Well, that's not a big problem either. Like, you can just have different ones.", "tokens": [50644, 6640, 294, 472, 1190, 13, 1042, 11, 300, 311, 406, 257, 955, 1154, 2139, 13, 1743, 11, 291, 393, 445, 362, 819, 2306, 13, 50916], "temperature": 0.0, "avg_logprob": -0.16057521577865358, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.0004171498876530677}, {"id": 250, "seek": 158560, "start": 1596.6399999999999, "end": 1600.8, "text": " Right. So if you think about it, that's what we always do, you know, like you like, if you think", "tokens": [50916, 1779, 13, 407, 498, 291, 519, 466, 309, 11, 300, 311, 437, 321, 1009, 360, 11, 291, 458, 11, 411, 291, 411, 11, 498, 291, 519, 51124], "temperature": 0.0, "avg_logprob": -0.16057521577865358, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.0004171498876530677}, {"id": 251, "seek": 158560, "start": 1600.8, "end": 1606.6399999999999, "text": " about the early tests of the CHSH inequality, they weren't switching the settings like, you know,", "tokens": [51124, 466, 264, 2440, 6921, 295, 264, 383, 12527, 39, 16970, 11, 436, 4999, 380, 16493, 264, 6257, 411, 11, 291, 458, 11, 51416], "temperature": 0.0, "avg_logprob": -0.16057521577865358, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.0004171498876530677}, {"id": 252, "seek": 158560, "start": 1606.6399999999999, "end": 1612.32, "text": " from run to run, you just take measurements for one pair of standing and then fill in another", "tokens": [51416, 490, 1190, 281, 1190, 11, 291, 445, 747, 15383, 337, 472, 6119, 295, 4877, 293, 550, 2836, 294, 1071, 51700], "temperature": 0.0, "avg_logprob": -0.16057521577865358, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.0004171498876530677}, {"id": 253, "seek": 161232, "start": 1612.32, "end": 1617.52, "text": " pair. That's all perfectly fine. So that we can do the third problem seems to be a lot nastier.", "tokens": [50364, 6119, 13, 663, 311, 439, 6239, 2489, 13, 407, 300, 321, 393, 360, 264, 2636, 1154, 2544, 281, 312, 257, 688, 26088, 811, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1711965661299856, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001385342562571168}, {"id": 254, "seek": 161232, "start": 1618.08, "end": 1624.6399999999999, "text": " And there the promise is that, you know, that we we derive this elliptop inequality from the", "tokens": [50652, 400, 456, 264, 6228, 307, 300, 11, 291, 458, 11, 300, 321, 321, 28446, 341, 8284, 22439, 404, 16970, 490, 264, 50980], "temperature": 0.0, "avg_logprob": -0.1711965661299856, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001385342562571168}, {"id": 255, "seek": 161232, "start": 1624.6399999999999, "end": 1631.4399999999998, "text": " condition starting that this the expectation value, this quantity is always greater equal than zero.", "tokens": [50980, 4188, 2891, 300, 341, 264, 14334, 2158, 11, 341, 11275, 307, 1009, 5044, 2681, 813, 4018, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1711965661299856, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001385342562571168}, {"id": 256, "seek": 161232, "start": 1631.4399999999998, "end": 1639.04, "text": " Right. But the point is that we cannot determine the value of this in one in one run. And it would", "tokens": [51320, 1779, 13, 583, 264, 935, 307, 300, 321, 2644, 6997, 264, 2158, 295, 341, 294, 472, 294, 472, 1190, 13, 400, 309, 576, 51700], "temperature": 0.0, "avg_logprob": -0.1711965661299856, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.001385342562571168}, {"id": 257, "seek": 163904, "start": 1639.04, "end": 1644.96, "text": " seem that if if all these three variables like can only take on values like plus or minus a half,", "tokens": [50364, 1643, 300, 498, 498, 439, 613, 1045, 9102, 411, 393, 787, 747, 322, 4190, 411, 1804, 420, 3175, 257, 1922, 11, 50660], "temperature": 0.0, "avg_logprob": -0.1318069419475517, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0011324438964948058}, {"id": 258, "seek": 163904, "start": 1644.96, "end": 1649.68, "text": " that yes, it's going to be greater equal than zero. But that inequality is not tight because like,", "tokens": [50660, 300, 2086, 11, 309, 311, 516, 281, 312, 5044, 2681, 813, 4018, 13, 583, 300, 16970, 307, 406, 4524, 570, 411, 11, 50896], "temperature": 0.0, "avg_logprob": -0.1318069419475517, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0011324438964948058}, {"id": 259, "seek": 163904, "start": 1649.68, "end": 1654.08, "text": " you know, like we could easily the smallest we could get this is to something like, you know,", "tokens": [50896, 291, 458, 11, 411, 321, 727, 3612, 264, 16998, 321, 727, 483, 341, 307, 281, 746, 411, 11, 291, 458, 11, 51116], "temperature": 0.0, "avg_logprob": -0.1318069419475517, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0011324438964948058}, {"id": 260, "seek": 163904, "start": 1654.08, "end": 1660.0, "text": " a half, like, you know, like a state plus and minus, minus here, and then we have a quarter.", "tokens": [51116, 257, 1922, 11, 411, 11, 291, 458, 11, 411, 257, 1785, 1804, 293, 3175, 11, 3175, 510, 11, 293, 550, 321, 362, 257, 6555, 13, 51412], "temperature": 0.0, "avg_logprob": -0.1318069419475517, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0011324438964948058}, {"id": 261, "seek": 166000, "start": 1660.96, "end": 1668.88, "text": " So this took us a while to to to figure out and the the the answer actually hinges on like,", "tokens": [50412, 407, 341, 1890, 505, 257, 1339, 281, 281, 281, 2573, 484, 293, 264, 264, 264, 1867, 767, 46686, 322, 411, 11, 50808], "temperature": 0.0, "avg_logprob": -0.13062050578358408, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0007552343886345625}, {"id": 262, "seek": 166000, "start": 1669.76, "end": 1673.6, "text": " you know, like an interesting property of quantum mechanics, namely that in quantum mechanics,", "tokens": [50852, 291, 458, 11, 411, 364, 1880, 4707, 295, 13018, 12939, 11, 20926, 300, 294, 13018, 12939, 11, 51044], "temperature": 0.0, "avg_logprob": -0.13062050578358408, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0007552343886345625}, {"id": 263, "seek": 166000, "start": 1673.6, "end": 1678.64, "text": " it's perfectly possible for a sum to have a definite value, even if the individual terms", "tokens": [51044, 309, 311, 6239, 1944, 337, 257, 2408, 281, 362, 257, 25131, 2158, 11, 754, 498, 264, 2609, 2115, 51296], "temperature": 0.0, "avg_logprob": -0.13062050578358408, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0007552343886345625}, {"id": 264, "seek": 166000, "start": 1678.64, "end": 1684.16, "text": " in that sum do not. Right. So the simplest example I can think of is like, you know, the Hamiltonian", "tokens": [51296, 294, 300, 2408, 360, 406, 13, 1779, 13, 407, 264, 22811, 1365, 286, 393, 519, 295, 307, 411, 11, 291, 458, 11, 264, 18484, 952, 51572], "temperature": 0.0, "avg_logprob": -0.13062050578358408, "compression_ratio": 1.6563876651982379, "no_speech_prob": 0.0007552343886345625}, {"id": 265, "seek": 168416, "start": 1684.24, "end": 1689.76, "text": " for harmonic oscillator, clearly P and Q cannot have like, you know, definite values at the same", "tokens": [50368, 337, 32270, 43859, 11, 4448, 430, 293, 1249, 2644, 362, 411, 11, 291, 458, 11, 25131, 4190, 412, 264, 912, 50644], "temperature": 0.0, "avg_logprob": -0.13345993206065188, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00467181671410799}, {"id": 266, "seek": 168416, "start": 1689.76, "end": 1695.1200000000001, "text": " time, but you know, the Hamiltonian can. And so to look at this a little more clearly, right,", "tokens": [50644, 565, 11, 457, 291, 458, 11, 264, 18484, 952, 393, 13, 400, 370, 281, 574, 412, 341, 257, 707, 544, 4448, 11, 558, 11, 50912], "temperature": 0.0, "avg_logprob": -0.13345993206065188, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00467181671410799}, {"id": 267, "seek": 168416, "start": 1695.1200000000001, "end": 1700.3200000000002, "text": " so if you if you were looking essentially at sort of a sum of like her mission operators,", "tokens": [50912, 370, 498, 291, 498, 291, 645, 1237, 4476, 412, 1333, 295, 257, 2408, 295, 411, 720, 4447, 19077, 11, 51172], "temperature": 0.0, "avg_logprob": -0.13345993206065188, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00467181671410799}, {"id": 268, "seek": 168416, "start": 1701.1200000000001, "end": 1707.6000000000001, "text": " linear combination, and that in and of itself should be like a good operator. And so if you", "tokens": [51212, 8213, 6562, 11, 293, 300, 294, 293, 295, 2564, 820, 312, 411, 257, 665, 12973, 13, 400, 370, 498, 291, 51536], "temperature": 0.0, "avg_logprob": -0.13345993206065188, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00467181671410799}, {"id": 269, "seek": 170760, "start": 1707.6, "end": 1712.8799999999999, "text": " introduce like, you know, now like in analogy with a spin vector, like a taste vector,", "tokens": [50364, 5366, 411, 11, 291, 458, 11, 586, 411, 294, 21663, 365, 257, 6060, 8062, 11, 411, 257, 3939, 8062, 11, 50628], "temperature": 0.0, "avg_logprob": -0.15326852599779764, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.007211117539554834}, {"id": 270, "seek": 170760, "start": 1714.1599999999999, "end": 1721.04, "text": " you get, you can write like the taste in the A direction as like the inner products of like", "tokens": [50692, 291, 483, 11, 291, 393, 2464, 411, 264, 3939, 294, 264, 316, 3513, 382, 411, 264, 7284, 3383, 295, 411, 51036], "temperature": 0.0, "avg_logprob": -0.15326852599779764, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.007211117539554834}, {"id": 271, "seek": 170760, "start": 1721.04, "end": 1729.12, "text": " T with like the unit vector in the A direction, same for TB, same for TC. And then the inequality", "tokens": [51036, 314, 365, 411, 264, 4985, 8062, 294, 264, 316, 3513, 11, 912, 337, 29711, 11, 912, 337, 34150, 13, 400, 550, 264, 16970, 51440], "temperature": 0.0, "avg_logprob": -0.15326852599779764, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.007211117539554834}, {"id": 272, "seek": 170760, "start": 1729.12, "end": 1735.28, "text": " becomes this, and you see that we're in a product thing, but the the taste vector with this vector,", "tokens": [51440, 3643, 341, 11, 293, 291, 536, 300, 321, 434, 294, 257, 1674, 551, 11, 457, 264, 264, 3939, 8062, 365, 341, 8062, 11, 51748], "temperature": 0.0, "avg_logprob": -0.15326852599779764, "compression_ratio": 1.898989898989899, "no_speech_prob": 0.007211117539554834}, {"id": 273, "seek": 173528, "start": 1735.28, "end": 1743.36, "text": " and this will be zero whenever this combination is zero. Right. And so if you if there are if you", "tokens": [50364, 293, 341, 486, 312, 4018, 5699, 341, 6562, 307, 4018, 13, 1779, 13, 400, 370, 498, 291, 498, 456, 366, 498, 291, 50768], "temperature": 0.0, "avg_logprob": -0.14392274220784504, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0007198870880529284}, {"id": 274, "seek": 173528, "start": 1743.36, "end": 1748.0, "text": " pick the right peeling directions for starters that need to be in one plane, you can actually", "tokens": [50768, 1888, 264, 558, 39926, 11095, 337, 35131, 300, 643, 281, 312, 294, 472, 5720, 11, 291, 393, 767, 51000], "temperature": 0.0, "avg_logprob": -0.14392274220784504, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0007198870880529284}, {"id": 275, "seek": 173528, "start": 1748.0, "end": 1754.0, "text": " like achieve that. So this this inequality is tight. And this result applies to so the general", "tokens": [51000, 411, 4584, 300, 13, 407, 341, 341, 16970, 307, 4524, 13, 400, 341, 1874, 13165, 281, 370, 264, 2674, 51300], "temperature": 0.0, "avg_logprob": -0.14392274220784504, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0007198870880529284}, {"id": 276, "seek": 173528, "start": 1754.0, "end": 1762.72, "text": " result of yield does applies to to this to this quantum example. All right. So what do I want", "tokens": [51300, 1874, 295, 11257, 775, 13165, 281, 281, 341, 281, 341, 13018, 1365, 13, 1057, 558, 13, 407, 437, 360, 286, 528, 51736], "temperature": 0.0, "avg_logprob": -0.14392274220784504, "compression_ratio": 1.6740088105726871, "no_speech_prob": 0.0007198870880529284}, {"id": 277, "seek": 176272, "start": 1762.72, "end": 1768.88, "text": " to conclude from this? Okay. So the point is, is that this elliptope inequality that we derived", "tokens": [50364, 281, 16886, 490, 341, 30, 1033, 13, 407, 264, 935, 307, 11, 307, 300, 341, 8284, 22439, 1114, 16970, 300, 321, 18949, 50672], "temperature": 0.0, "avg_logprob": -0.15210434242531104, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.003588821506127715}, {"id": 278, "seek": 176272, "start": 1768.88, "end": 1774.08, "text": " first within quantum mechanics from the geometry of Hilbert space can also be derived without", "tokens": [50672, 700, 1951, 13018, 12939, 490, 264, 18426, 295, 19914, 4290, 1901, 393, 611, 312, 18949, 1553, 50932], "temperature": 0.0, "avg_logprob": -0.15210434242531104, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.003588821506127715}, {"id": 279, "seek": 176272, "start": 1774.08, "end": 1779.04, "text": " quantum mechanics as a general constraint on correlations between three random variables.", "tokens": [50932, 13018, 12939, 382, 257, 2674, 25534, 322, 13983, 763, 1296, 1045, 4974, 9102, 13, 51180], "temperature": 0.0, "avg_logprob": -0.15210434242531104, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.003588821506127715}, {"id": 280, "seek": 176272, "start": 1779.68, "end": 1786.56, "text": " And is this this distinction like actually we got from within from without from a song by Bob Dylan.", "tokens": [51212, 400, 307, 341, 341, 16844, 411, 767, 321, 658, 490, 1951, 490, 1553, 490, 257, 2153, 538, 6085, 28160, 13, 51556], "temperature": 0.0, "avg_logprob": -0.15210434242531104, "compression_ratio": 1.6593886462882097, "no_speech_prob": 0.003588821506127715}, {"id": 281, "seek": 179272, "start": 1793.1200000000001, "end": 1814.96, "text": " So the message then this is the big message of the of the talk is that what this suggests", "tokens": [50384, 407, 264, 3636, 550, 341, 307, 264, 955, 3636, 295, 264, 295, 264, 751, 307, 300, 437, 341, 13409, 51476], "temperature": 0.0, "avg_logprob": -0.18349150724189225, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.002049295464530587}, {"id": 282, "seek": 179272, "start": 1814.96, "end": 1819.92, "text": " is that the basic Hilbert space formalism of quantum mechanics is just a new framework for", "tokens": [51476, 307, 300, 264, 3875, 19914, 4290, 1901, 9860, 1434, 295, 13018, 12939, 307, 445, 257, 777, 8388, 337, 51724], "temperature": 0.0, "avg_logprob": -0.18349150724189225, "compression_ratio": 1.5254237288135593, "no_speech_prob": 0.002049295464530587}, {"id": 283, "seek": 181992, "start": 1819.92, "end": 1825.6000000000001, "text": " handling probabilities. Right. And so this take on quantum mechanics, which has been dubbed", "tokens": [50364, 13175, 33783, 13, 1779, 13, 400, 370, 341, 747, 322, 13018, 12939, 11, 597, 575, 668, 43686, 50648], "temperature": 0.0, "avg_logprob": -0.16223623376143606, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.0013649571919813752}, {"id": 284, "seek": 181992, "start": 1825.6000000000001, "end": 1832.0800000000002, "text": " boobism is a pun on cubism by Robert Mischewitz belongs, I think, to a class of informational", "tokens": [50648, 748, 996, 1434, 307, 257, 4468, 322, 10057, 1434, 538, 7977, 376, 5494, 1023, 6862, 12953, 11, 286, 519, 11, 281, 257, 1508, 295, 49391, 50972], "temperature": 0.0, "avg_logprob": -0.16223623376143606, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.0013649571919813752}, {"id": 285, "seek": 181992, "start": 1832.0800000000002, "end": 1840.96, "text": " makeovers of the much maligned Copenhagen interpretation. And so in order to to make that", "tokens": [50972, 652, 25348, 295, 264, 709, 2806, 16690, 50135, 4698, 14174, 13, 400, 370, 294, 1668, 281, 281, 652, 300, 51416], "temperature": 0.0, "avg_logprob": -0.16223623376143606, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.0013649571919813752}, {"id": 286, "seek": 181992, "start": 1840.96, "end": 1846.16, "text": " clear, like I want to talk, I'll take five more minutes to make the point. And this is far more", "tokens": [51416, 1850, 11, 411, 286, 528, 281, 751, 11, 286, 603, 747, 1732, 544, 2077, 281, 652, 264, 935, 13, 400, 341, 307, 1400, 544, 51676], "temperature": 0.0, "avg_logprob": -0.16223623376143606, "compression_ratio": 1.5394190871369295, "no_speech_prob": 0.0013649571919813752}, {"id": 287, "seek": 184616, "start": 1846.24, "end": 1851.28, "text": " speculative and tentative than what I've said so far. I think it's best to sort of think in terms", "tokens": [50368, 49415, 293, 7054, 1166, 813, 437, 286, 600, 848, 370, 1400, 13, 286, 519, 309, 311, 1151, 281, 1333, 295, 519, 294, 2115, 50620], "temperature": 0.0, "avg_logprob": -0.09571061083065566, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0038786428049206734}, {"id": 288, "seek": 184616, "start": 1851.28, "end": 1856.0800000000002, "text": " of like a genealogy of quantum interpretations. And so we got like two versions of quantum", "tokens": [50620, 295, 411, 257, 12186, 304, 7794, 295, 13018, 37547, 13, 400, 370, 321, 658, 411, 732, 9606, 295, 13018, 50860], "temperature": 0.0, "avg_logprob": -0.09571061083065566, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0038786428049206734}, {"id": 289, "seek": 184616, "start": 1856.0800000000002, "end": 1862.48, "text": " mechanics around 1925 26. First, we have matrix mechanics. And Heisenberg's big discovery was", "tokens": [50860, 12939, 926, 1294, 6074, 7551, 13, 2386, 11, 321, 362, 8141, 12939, 13, 400, 634, 11106, 6873, 311, 955, 12114, 390, 51180], "temperature": 0.0, "avg_logprob": -0.09571061083065566, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0038786428049206734}, {"id": 290, "seek": 184616, "start": 1862.48, "end": 1869.0400000000002, "text": " that these problems in spectroscopy that he was running into, just call for a new framework for", "tokens": [51180, 300, 613, 2740, 294, 6177, 38006, 88, 300, 415, 390, 2614, 666, 11, 445, 818, 337, 257, 777, 8388, 337, 51508], "temperature": 0.0, "avg_logprob": -0.09571061083065566, "compression_ratio": 1.56198347107438, "no_speech_prob": 0.0038786428049206734}, {"id": 291, "seek": 186904, "start": 1869.12, "end": 1876.3999999999999, "text": " dealing with with physics, just as like the problems that people had run into in electrodynamics", "tokens": [50368, 6260, 365, 365, 10649, 11, 445, 382, 411, 264, 2740, 300, 561, 632, 1190, 666, 294, 44216, 5216, 1167, 50732], "temperature": 0.0, "avg_logprob": -0.11805613687105268, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.0019562942907214165}, {"id": 292, "seek": 186904, "start": 1876.3999999999999, "end": 1880.8, "text": " around the turn of the century, called for a new framework of dealing with spatial temporal", "tokens": [50732, 926, 264, 1261, 295, 264, 4901, 11, 1219, 337, 257, 777, 8388, 295, 6260, 365, 23598, 30881, 50952], "temperature": 0.0, "avg_logprob": -0.11805613687105268, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.0019562942907214165}, {"id": 293, "seek": 186904, "start": 1881.36, "end": 1886.24, "text": " relations. Now, of course, a little bit later, like Schrodinger comes up with wave mechanics,", "tokens": [50980, 2299, 13, 823, 11, 295, 1164, 11, 257, 707, 857, 1780, 11, 411, 2065, 340, 3584, 260, 1487, 493, 365, 5772, 12939, 11, 51224], "temperature": 0.0, "avg_logprob": -0.11805613687105268, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.0019562942907214165}, {"id": 294, "seek": 186904, "start": 1886.24, "end": 1890.8799999999999, "text": " and his big discovery compatible with Heisenberg was very different, like namely,", "tokens": [51224, 293, 702, 955, 12114, 18218, 365, 634, 11106, 6873, 390, 588, 819, 11, 411, 20926, 11, 51456], "temperature": 0.0, "avg_logprob": -0.11805613687105268, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.0019562942907214165}, {"id": 295, "seek": 186904, "start": 1890.8799999999999, "end": 1895.92, "text": " here the idea is that something wavy is underlying the behavior that we're seeing. And the analogy", "tokens": [51456, 510, 264, 1558, 307, 300, 746, 261, 15498, 307, 14217, 264, 5223, 300, 321, 434, 2577, 13, 400, 264, 21663, 51708], "temperature": 0.0, "avg_logprob": -0.11805613687105268, "compression_ratio": 1.6594982078853047, "no_speech_prob": 0.0019562942907214165}, {"id": 296, "seek": 189592, "start": 1895.92, "end": 1902.16, "text": " here is with wave optics in the 19th century. And so they famously didn't care for each other,", "tokens": [50364, 510, 307, 365, 5772, 42599, 294, 264, 1294, 392, 4901, 13, 400, 370, 436, 34360, 994, 380, 1127, 337, 1184, 661, 11, 50676], "temperature": 0.0, "avg_logprob": -0.1441251704123168, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.0025480317417532206}, {"id": 297, "seek": 189592, "start": 1902.88, "end": 1906.72, "text": " for each other's views, like, you know, like Heisenberg calling wave mechanics disgusting,", "tokens": [50712, 337, 1184, 661, 311, 6809, 11, 411, 11, 291, 458, 11, 411, 634, 11106, 6873, 5141, 5772, 12939, 17552, 11, 50904], "temperature": 0.0, "avg_logprob": -0.1441251704123168, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.0025480317417532206}, {"id": 298, "seek": 189592, "start": 1907.68, "end": 1912.3200000000002, "text": " and Schrodinger calling matrix mechanics repulsive. And but of course, like mathematical", "tokens": [50952, 293, 2065, 340, 3584, 260, 5141, 8141, 12939, 1085, 32657, 13, 400, 457, 295, 1164, 11, 411, 18894, 51184], "temperature": 0.0, "avg_logprob": -0.1441251704123168, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.0025480317417532206}, {"id": 299, "seek": 189592, "start": 1912.3200000000002, "end": 1916.0800000000002, "text": " equivalence was rapidly proved in part by Schrodinger himself, but then by the rock,", "tokens": [51184, 9052, 655, 390, 12910, 14617, 294, 644, 538, 2065, 340, 3584, 260, 3647, 11, 457, 550, 538, 264, 3727, 11, 51372], "temperature": 0.0, "avg_logprob": -0.1441251704123168, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.0025480317417532206}, {"id": 300, "seek": 189592, "start": 1916.0800000000002, "end": 1921.3600000000001, "text": " yard down for Neumann. And that kind of papers over like a very different way of thinking about", "tokens": [51372, 11682, 760, 337, 1734, 449, 969, 13, 400, 300, 733, 295, 10577, 670, 411, 257, 588, 819, 636, 295, 1953, 466, 51636], "temperature": 0.0, "avg_logprob": -0.1441251704123168, "compression_ratio": 1.6485507246376812, "no_speech_prob": 0.0025480317417532206}, {"id": 301, "seek": 192136, "start": 1921.36, "end": 1926.7199999999998, "text": " the state, the status of the state vector in the Hilbert space. And I think roughly you can say", "tokens": [50364, 264, 1785, 11, 264, 6558, 295, 264, 1785, 8062, 294, 264, 19914, 4290, 1901, 13, 400, 286, 519, 9810, 291, 393, 584, 50632], "temperature": 0.0, "avg_logprob": -0.18487289303638896, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.003168643917888403}, {"id": 302, "seek": 192136, "start": 1926.7199999999998, "end": 1930.6399999999999, "text": " that the descendants of wave mechanics, those are the ontic interpretations of quantum mechanics,", "tokens": [50632, 300, 264, 31693, 295, 5772, 12939, 11, 729, 366, 264, 6592, 299, 37547, 295, 13018, 12939, 11, 50828], "temperature": 0.0, "avg_logprob": -0.18487289303638896, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.003168643917888403}, {"id": 303, "seek": 192136, "start": 1930.6399999999999, "end": 1937.36, "text": " think Everett, the de Broglie-Bohm pilot wave theory, and the Girardi-Romini-Weber spontaneous", "tokens": [50828, 519, 12123, 3093, 11, 264, 368, 5425, 70, 6302, 12, 33, 1445, 76, 9691, 5772, 5261, 11, 293, 264, 36306, 38126, 12, 49, 298, 3812, 12, 4360, 607, 32744, 51164], "temperature": 0.0, "avg_logprob": -0.18487289303638896, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.003168643917888403}, {"id": 304, "seek": 192136, "start": 1937.36, "end": 1942.24, "text": " collapse theory. And the descendants of matrix mechanics are the epistemic interpretations", "tokens": [51164, 15584, 5261, 13, 400, 264, 31693, 295, 8141, 12939, 366, 264, 2388, 468, 3438, 37547, 51408], "temperature": 0.0, "avg_logprob": -0.18487289303638896, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.003168643917888403}, {"id": 305, "seek": 192136, "start": 1942.24, "end": 1950.7199999999998, "text": " in where I would include Copenhagen, Cubism, and now like, you know, Bubism. And so just a quick way", "tokens": [51408, 294, 689, 286, 576, 4090, 50135, 4698, 11, 21300, 1434, 11, 293, 586, 411, 11, 291, 458, 11, 25489, 1434, 13, 400, 370, 445, 257, 1702, 636, 51832], "temperature": 0.0, "avg_logprob": -0.18487289303638896, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.003168643917888403}, {"id": 306, "seek": 195072, "start": 1950.8, "end": 1955.92, "text": " of sort of showing, you know, what I'm, what I'm after, like contrast Boop with Everett, right?", "tokens": [50368, 295, 1333, 295, 4099, 11, 291, 458, 11, 437, 286, 478, 11, 437, 286, 478, 934, 11, 411, 8712, 3286, 404, 365, 12123, 3093, 11, 558, 30, 50624], "temperature": 0.0, "avg_logprob": -0.14499664306640625, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.0035858498886227608}, {"id": 307, "seek": 195072, "start": 1955.92, "end": 1960.24, "text": " So for Boop, like what the Hilbert space is doing you is doing for you, it's giving you the Born", "tokens": [50624, 407, 337, 3286, 404, 11, 411, 437, 264, 19914, 4290, 1901, 307, 884, 291, 307, 884, 337, 291, 11, 309, 311, 2902, 291, 264, 29808, 50840], "temperature": 0.0, "avg_logprob": -0.14499664306640625, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.0035858498886227608}, {"id": 308, "seek": 195072, "start": 1960.24, "end": 1965.92, "text": " Rule, but it doesn't represent stuff, right? In order to represent stuff, you need like some specific", "tokens": [50840, 27533, 11, 457, 309, 1177, 380, 2906, 1507, 11, 558, 30, 682, 1668, 281, 2906, 1507, 11, 291, 643, 411, 512, 2685, 51124], "temperature": 0.0, "avg_logprob": -0.14499664306640625, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.0035858498886227608}, {"id": 309, "seek": 195072, "start": 1965.92, "end": 1972.72, "text": " quantum applications running on this new quantum operating system to use kind of the metaphor", "tokens": [51124, 13018, 5821, 2614, 322, 341, 777, 13018, 7447, 1185, 281, 764, 733, 295, 264, 19157, 51464], "temperature": 0.0, "avg_logprob": -0.14499664306640625, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.0035858498886227608}, {"id": 310, "seek": 195072, "start": 1972.72, "end": 1977.84, "text": " of Nielsen and Chang's book on quantum information. Now, for Everett, it's just the way,", "tokens": [51464, 295, 426, 1187, 6748, 293, 17179, 311, 1446, 322, 13018, 1589, 13, 823, 11, 337, 12123, 3093, 11, 309, 311, 445, 264, 636, 11, 51720], "temperature": 0.0, "avg_logprob": -0.14499664306640625, "compression_ratio": 1.6914893617021276, "no_speech_prob": 0.0035858498886227608}, {"id": 311, "seek": 197784, "start": 1977.9199999999998, "end": 1980.9599999999998, "text": " it's just the other way around. Hilbert space gives you stuff, you know,", "tokens": [50368, 309, 311, 445, 264, 661, 636, 926, 13, 19914, 4290, 1901, 2709, 291, 1507, 11, 291, 458, 11, 50520], "temperature": 0.0, "avg_logprob": -0.12797862085802802, "compression_ratio": 1.7452229299363058, "no_speech_prob": 0.001954844454303384}, {"id": 312, "seek": 197784, "start": 1980.9599999999998, "end": 1984.3999999999999, "text": " Sean Carroll, like says, like, you know, the world is made out of wave functions, right?", "tokens": [50520, 14839, 48456, 11, 411, 1619, 11, 411, 11, 291, 458, 11, 264, 1002, 307, 1027, 484, 295, 5772, 6828, 11, 558, 30, 50692], "temperature": 0.0, "avg_logprob": -0.12797862085802802, "compression_ratio": 1.7452229299363058, "no_speech_prob": 0.001954844454303384}, {"id": 313, "seek": 197784, "start": 1985.9199999999998, "end": 1991.04, "text": " So, but it doesn't give you the Born Rule now, right? I mean, so for that they appeal to decision", "tokens": [50768, 407, 11, 457, 309, 1177, 380, 976, 291, 264, 29808, 27533, 586, 11, 558, 30, 286, 914, 11, 370, 337, 300, 436, 13668, 281, 3537, 51024], "temperature": 0.0, "avg_logprob": -0.12797862085802802, "compression_ratio": 1.7452229299363058, "no_speech_prob": 0.001954844454303384}, {"id": 314, "seek": 197784, "start": 1991.04, "end": 1996.48, "text": " theory for agents and a multiverse, okay? Now, so this is Oxford Everettians, there's also another", "tokens": [51024, 5261, 337, 12554, 293, 257, 2120, 5376, 11, 1392, 30, 823, 11, 370, 341, 307, 24786, 12123, 3093, 2567, 11, 456, 311, 611, 1071, 51296], "temperature": 0.0, "avg_logprob": -0.12797862085802802, "compression_ratio": 1.7452229299363058, "no_speech_prob": 0.001954844454303384}, {"id": 315, "seek": 197784, "start": 1996.48, "end": 2001.84, "text": " class of Everettians, Berlin Everettians like Christoph Lainer, who really have the courage", "tokens": [51296, 1508, 295, 12123, 3093, 2567, 11, 13848, 12123, 3093, 2567, 411, 2040, 5317, 441, 491, 260, 11, 567, 534, 362, 264, 9892, 51564], "temperature": 0.0, "avg_logprob": -0.12797862085802802, "compression_ratio": 1.7452229299363058, "no_speech_prob": 0.001954844454303384}, {"id": 316, "seek": 197784, "start": 2001.84, "end": 2007.76, "text": " of their convictions, who use like Hilbert space both to represent stuff and to get the Born Rule", "tokens": [51564, 295, 641, 44757, 11, 567, 764, 411, 19914, 4290, 1901, 1293, 281, 2906, 1507, 293, 281, 483, 264, 29808, 27533, 51860], "temperature": 0.0, "avg_logprob": -0.12797862085802802, "compression_ratio": 1.7452229299363058, "no_speech_prob": 0.001954844454303384}, {"id": 317, "seek": 200776, "start": 2007.84, "end": 2011.52, "text": " and of course, it's a good Everettian, right? You take advantage of the fact that in a multiverse,", "tokens": [50368, 293, 295, 1164, 11, 309, 311, 257, 665, 12123, 3093, 952, 11, 558, 30, 509, 747, 5002, 295, 264, 1186, 300, 294, 257, 2120, 5376, 11, 50552], "temperature": 0.0, "avg_logprob": -0.19165399339463976, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0006160203483887017}, {"id": 318, "seek": 200776, "start": 2011.52, "end": 2018.72, "text": " you really can have your cake and eat it too. So now, for more careful exegesis of all of this,", "tokens": [50552, 291, 534, 393, 362, 428, 5908, 293, 1862, 309, 886, 13, 407, 586, 11, 337, 544, 5026, 454, 1146, 9374, 295, 439, 295, 341, 11, 50912], "temperature": 0.0, "avg_logprob": -0.19165399339463976, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0006160203483887017}, {"id": 319, "seek": 200776, "start": 2019.6, "end": 2024.16, "text": " you, you know, I'm going to refer you to our book, where especially like, you know,", "tokens": [50956, 291, 11, 291, 458, 11, 286, 478, 516, 281, 2864, 291, 281, 527, 1446, 11, 689, 2318, 411, 11, 291, 458, 11, 51184], "temperature": 0.0, "avg_logprob": -0.19165399339463976, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0006160203483887017}, {"id": 320, "seek": 200776, "start": 2024.16, "end": 2031.52, "text": " microfarro, like, lace this out, like much more patiently than I just did, and I'm going to leave", "tokens": [51184, 42763, 289, 340, 11, 411, 11, 33469, 341, 484, 11, 411, 709, 544, 49001, 813, 286, 445, 630, 11, 293, 286, 478, 516, 281, 1856, 51552], "temperature": 0.0, "avg_logprob": -0.19165399339463976, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.0006160203483887017}, {"id": 321, "seek": 203152, "start": 2031.52, "end": 2037.28, "text": " you like with one more version of this, of this Dylan song.", "tokens": [50364, 291, 411, 365, 472, 544, 3037, 295, 341, 11, 295, 341, 28160, 2153, 13, 50652], "temperature": 0.0, "avg_logprob": -0.3345208168029785, "compression_ratio": 0.9833333333333333, "no_speech_prob": 0.032033294439315796}, {"id": 322, "seek": 206152, "start": 2062.16, "end": 2070.24, "text": " Now, right, I'm happy to take some questions if there's time.", "tokens": [50396, 823, 11, 558, 11, 286, 478, 2055, 281, 747, 512, 1651, 498, 456, 311, 565, 13, 50800], "temperature": 0.0, "avg_logprob": -0.3038689873435281, "compression_ratio": 1.3781512605042017, "no_speech_prob": 0.0194591972976923}, {"id": 323, "seek": 206152, "start": 2071.6, "end": 2079.12, "text": " Yes, we have some minutes for comments or questions. If you want to make a comment or question, please", "tokens": [50868, 1079, 11, 321, 362, 512, 2077, 337, 3053, 420, 1651, 13, 759, 291, 528, 281, 652, 257, 2871, 420, 1168, 11, 1767, 51244], "temperature": 0.0, "avg_logprob": -0.3038689873435281, "compression_ratio": 1.3781512605042017, "no_speech_prob": 0.0194591972976923}, {"id": 324, "seek": 207912, "start": 2079.12, "end": 2096.56, "text": " indicate it in the chat. I have a short question. Do you think that, or my real question is,", "tokens": [50364, 13330, 309, 294, 264, 5081, 13, 286, 362, 257, 2099, 1168, 13, 1144, 291, 519, 300, 11, 420, 452, 957, 1168, 307, 11, 51236], "temperature": 0.0, "avg_logprob": -0.2755269073858494, "compression_ratio": 1.3478260869565217, "no_speech_prob": 0.07922935485839844}, {"id": 325, "seek": 207912, "start": 2096.56, "end": 2102.4, "text": " if you have some experience in the classroom with this type of", "tokens": [51236, 498, 291, 362, 512, 1752, 294, 264, 7419, 365, 341, 2010, 295, 51528], "temperature": 0.0, "avg_logprob": -0.2755269073858494, "compression_ratio": 1.3478260869565217, "no_speech_prob": 0.07922935485839844}, {"id": 326, "seek": 210240, "start": 2103.28, "end": 2112.32, "text": " topological approximation mechanics, do you think that it can help in education?", "tokens": [50408, 1192, 4383, 28023, 12939, 11, 360, 291, 519, 300, 309, 393, 854, 294, 3309, 30, 50860], "temperature": 0.0, "avg_logprob": -0.2497537001123968, "compression_ratio": 1.6014492753623188, "no_speech_prob": 0.01682325266301632}, {"id": 327, "seek": 210240, "start": 2116.4, "end": 2120.1600000000003, "text": " I'm just making sure. Do you think the question is, like, do you think that this", "tokens": [51064, 286, 478, 445, 1455, 988, 13, 1144, 291, 519, 264, 1168, 307, 11, 411, 11, 360, 291, 519, 300, 341, 51252], "temperature": 0.0, "avg_logprob": -0.2497537001123968, "compression_ratio": 1.6014492753623188, "no_speech_prob": 0.01682325266301632}, {"id": 328, "seek": 210240, "start": 2120.1600000000003, "end": 2122.4, "text": " way of thinking about quantum mechanics can help education?", "tokens": [51252, 636, 295, 1953, 466, 13018, 12939, 393, 854, 3309, 30, 51364], "temperature": 0.0, "avg_logprob": -0.2497537001123968, "compression_ratio": 1.6014492753623188, "no_speech_prob": 0.01682325266301632}, {"id": 329, "seek": 212240, "start": 2122.64, "end": 2136.32, "text": " No, this form to present some results with the topological forms can help in education", "tokens": [50376, 883, 11, 341, 1254, 281, 1974, 512, 3542, 365, 264, 1192, 4383, 6422, 393, 854, 294, 3309, 51060], "temperature": 0.0, "avg_logprob": -0.22740047925139126, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.014697272330522537}, {"id": 330, "seek": 212240, "start": 2136.32, "end": 2140.0, "text": " of quantum mechanics in the in the courses in the universe.", "tokens": [51060, 295, 13018, 12939, 294, 264, 294, 264, 7712, 294, 264, 6445, 13, 51244], "temperature": 0.0, "avg_logprob": -0.22740047925139126, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.014697272330522537}, {"id": 331, "seek": 212240, "start": 2141.12, "end": 2145.04, "text": " Yeah, no, I mean, like, I'm currently teaching a course on introducing, like,", "tokens": [51300, 865, 11, 572, 11, 286, 914, 11, 411, 11, 286, 478, 4362, 4571, 257, 1164, 322, 15424, 11, 411, 11, 51496], "temperature": 0.0, "avg_logprob": -0.22740047925139126, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.014697272330522537}, {"id": 332, "seek": 212240, "start": 2145.04, "end": 2148.0, "text": " non physics majors to quantum mechanics, where I very much use this,", "tokens": [51496, 2107, 10649, 31770, 281, 13018, 12939, 11, 689, 286, 588, 709, 764, 341, 11, 51644], "temperature": 0.0, "avg_logprob": -0.22740047925139126, "compression_ratio": 1.5668449197860963, "no_speech_prob": 0.014697272330522537}, {"id": 333, "seek": 214800, "start": 2148.72, "end": 2152.64, "text": " use this approach that I showed you, right? And so, and like,", "tokens": [50400, 764, 341, 3109, 300, 286, 4712, 291, 11, 558, 30, 400, 370, 11, 293, 411, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1480691791635699, "compression_ratio": 1.790983606557377, "no_speech_prob": 0.009665646590292454}, {"id": 334, "seek": 214800, "start": 2153.68, "end": 2158.56, "text": " yeah, and so, but it's, I mean, it gives you like a particular way of thinking about quantum", "tokens": [50648, 1338, 11, 293, 370, 11, 457, 309, 311, 11, 286, 914, 11, 309, 2709, 291, 411, 257, 1729, 636, 295, 1953, 466, 13018, 50892], "temperature": 0.0, "avg_logprob": -0.1480691791635699, "compression_ratio": 1.790983606557377, "no_speech_prob": 0.009665646590292454}, {"id": 335, "seek": 214800, "start": 2158.56, "end": 2164.16, "text": " mechanics, right? It really pushes this idea that quantum mechanics is like a, you know,", "tokens": [50892, 12939, 11, 558, 30, 467, 534, 21020, 341, 1558, 300, 13018, 12939, 307, 411, 257, 11, 291, 458, 11, 51172], "temperature": 0.0, "avg_logprob": -0.1480691791635699, "compression_ratio": 1.790983606557377, "no_speech_prob": 0.009665646590292454}, {"id": 336, "seek": 214800, "start": 2164.16, "end": 2169.44, "text": " the kinematics of quantum mechanics, right? The basic formalism is a new framework for handling", "tokens": [51172, 264, 15784, 37541, 295, 13018, 12939, 11, 558, 30, 440, 3875, 9860, 1434, 307, 257, 777, 8388, 337, 13175, 51436], "temperature": 0.0, "avg_logprob": -0.1480691791635699, "compression_ratio": 1.790983606557377, "no_speech_prob": 0.009665646590292454}, {"id": 337, "seek": 214800, "start": 2169.44, "end": 2173.6, "text": " probabilities, right? And that, you know, in order to do anything else, right, now you need to do", "tokens": [51436, 33783, 11, 558, 30, 400, 300, 11, 291, 458, 11, 294, 1668, 281, 360, 1340, 1646, 11, 558, 11, 586, 291, 643, 281, 360, 51644], "temperature": 0.0, "avg_logprob": -0.1480691791635699, "compression_ratio": 1.790983606557377, "no_speech_prob": 0.009665646590292454}, {"id": 338, "seek": 217360, "start": 2173.6, "end": 2180.16, "text": " dynamics, you need to like introduce like stuff, right? And what quantum mechanics is telling you", "tokens": [50364, 15679, 11, 291, 643, 281, 411, 5366, 411, 1507, 11, 558, 30, 400, 437, 13018, 12939, 307, 3585, 291, 50692], "temperature": 0.0, "avg_logprob": -0.11936161365914852, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.00297442520968616}, {"id": 339, "seek": 217360, "start": 2180.16, "end": 2186.56, "text": " that it had to, that it has to behave according to the rules of quantum, right? So, so that's,", "tokens": [50692, 300, 309, 632, 281, 11, 300, 309, 575, 281, 15158, 4650, 281, 264, 4474, 295, 13018, 11, 558, 30, 407, 11, 370, 300, 311, 11, 51012], "temperature": 0.0, "avg_logprob": -0.11936161365914852, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.00297442520968616}, {"id": 340, "seek": 217360, "start": 2186.56, "end": 2192.48, "text": " that's the view I'm pushing. Historically, what I find interesting is that if you now look at", "tokens": [51012, 300, 311, 264, 1910, 286, 478, 7380, 13, 25108, 984, 11, 437, 286, 915, 1880, 307, 300, 498, 291, 586, 574, 412, 51308], "temperature": 0.0, "avg_logprob": -0.11936161365914852, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.00297442520968616}, {"id": 341, "seek": 217360, "start": 2192.48, "end": 2199.7599999999998, "text": " modern books on probability theory and statistics, is that Hilbert space methods are being used in", "tokens": [51308, 4363, 3642, 322, 8482, 5261, 293, 12523, 11, 307, 300, 19914, 4290, 1901, 7150, 366, 885, 1143, 294, 51672], "temperature": 0.0, "avg_logprob": -0.11936161365914852, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.00297442520968616}, {"id": 342, "seek": 219976, "start": 2199.76, "end": 2205.6000000000004, "text": " these books. And somehow like, so as a historian, I'm very interested, like how it came to be,", "tokens": [50364, 613, 3642, 13, 400, 6063, 411, 11, 370, 382, 257, 25139, 11, 286, 478, 588, 3102, 11, 411, 577, 309, 1361, 281, 312, 11, 50656], "temperature": 0.0, "avg_logprob": -0.2012006272660925, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.005544257815927267}, {"id": 343, "seek": 219976, "start": 2205.6000000000004, "end": 2210.0, "text": " that there seems to be very little communication between people in physics using Hilbert space", "tokens": [50656, 300, 456, 2544, 281, 312, 588, 707, 6101, 1296, 561, 294, 10649, 1228, 19914, 4290, 1901, 50876], "temperature": 0.0, "avg_logprob": -0.2012006272660925, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.005544257815927267}, {"id": 344, "seek": 219976, "start": 2210.0, "end": 2217.1200000000003, "text": " methods, and people in general statistics using like Hilbert space methods. Okay, thank you. And", "tokens": [50876, 7150, 11, 293, 561, 294, 2674, 12523, 1228, 411, 19914, 4290, 1901, 7150, 13, 1033, 11, 1309, 291, 13, 400, 51232], "temperature": 0.0, "avg_logprob": -0.2012006272660925, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.005544257815927267}, {"id": 345, "seek": 219976, "start": 2217.1200000000003, "end": 2227.5200000000004, "text": " there is a question from Federico Hoelig. Yes, thanks, Michelle, for, for this wonderful talk.", "tokens": [51232, 456, 307, 257, 1168, 490, 45545, 2789, 3631, 338, 328, 13, 1079, 11, 3231, 11, 14933, 11, 337, 11, 337, 341, 3715, 751, 13, 51752], "temperature": 0.0, "avg_logprob": -0.2012006272660925, "compression_ratio": 1.6351931330472103, "no_speech_prob": 0.005544257815927267}, {"id": 346, "seek": 222752, "start": 2227.6, "end": 2233.92, "text": " It's always great to hear you. I always get really excited. And I want to learn more about", "tokens": [50368, 467, 311, 1009, 869, 281, 1568, 291, 13, 286, 1009, 483, 534, 2919, 13, 400, 286, 528, 281, 1466, 544, 466, 50684], "temperature": 0.0, "avg_logprob": -0.09317391568964178, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.03332853689789772}, {"id": 347, "seek": 222752, "start": 2233.92, "end": 2242.64, "text": " this approach. And my question is related to what is the stake or the take of your interpretation", "tokens": [50684, 341, 3109, 13, 400, 452, 1168, 307, 4077, 281, 437, 307, 264, 10407, 420, 264, 747, 295, 428, 14174, 51120], "temperature": 0.0, "avg_logprob": -0.09317391568964178, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.03332853689789772}, {"id": 348, "seek": 222752, "start": 2242.64, "end": 2251.04, "text": " with regard to non-locality? Because if you interpret quantum mechanics as a new probability", "tokens": [51120, 365, 3843, 281, 2107, 12, 5842, 1860, 30, 1436, 498, 291, 7302, 13018, 12939, 382, 257, 777, 8482, 51540], "temperature": 0.0, "avg_logprob": -0.09317391568964178, "compression_ratio": 1.53551912568306, "no_speech_prob": 0.03332853689789772}, {"id": 349, "seek": 225104, "start": 2251.04, "end": 2258.0, "text": " formalism, what can you say about the strong claims that the word is local versus the word", "tokens": [50364, 9860, 1434, 11, 437, 393, 291, 584, 466, 264, 2068, 9441, 300, 264, 1349, 307, 2654, 5717, 264, 1349, 50712], "temperature": 0.0, "avg_logprob": -0.11546631602497844, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.033049385994672775}, {"id": 350, "seek": 225104, "start": 2258.0, "end": 2265.7599999999998, "text": " is non-local? What will you say about that? Yeah, so, so the, that's a difficult question.", "tokens": [50712, 307, 2107, 12, 5842, 304, 30, 708, 486, 291, 584, 466, 300, 30, 865, 11, 370, 11, 370, 264, 11, 300, 311, 257, 2252, 1168, 13, 51100], "temperature": 0.0, "avg_logprob": -0.11546631602497844, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.033049385994672775}, {"id": 351, "seek": 225104, "start": 2266.96, "end": 2273.68, "text": " So, so what I would say is that, you know, in the spirit of what I showed you is that,", "tokens": [51160, 407, 11, 370, 437, 286, 576, 584, 307, 300, 11, 291, 458, 11, 294, 264, 3797, 295, 437, 286, 4712, 291, 307, 300, 11, 51496], "temperature": 0.0, "avg_logprob": -0.11546631602497844, "compression_ratio": 1.654320987654321, "no_speech_prob": 0.033049385994672775}, {"id": 352, "seek": 227368, "start": 2273.68, "end": 2282.0, "text": " you know, like you would, you would have thought that special relativity like requires you to,", "tokens": [50364, 291, 458, 11, 411, 291, 576, 11, 291, 576, 362, 1194, 300, 2121, 45675, 411, 7029, 291, 281, 11, 50780], "temperature": 0.0, "avg_logprob": -0.1164528748084759, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.007340359501540661}, {"id": 353, "seek": 227368, "start": 2282.0, "end": 2287.44, "text": " you know, like tell some story where you can like screen off like any correlation by something,", "tokens": [50780, 291, 458, 11, 411, 980, 512, 1657, 689, 291, 393, 411, 2568, 766, 411, 604, 20009, 538, 746, 11, 51052], "temperature": 0.0, "avg_logprob": -0.1164528748084759, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.007340359501540661}, {"id": 354, "seek": 227368, "start": 2287.44, "end": 2292.56, "text": " you know, that by a common cause. And it turns out that the constraints are not that tight,", "tokens": [51052, 291, 458, 11, 300, 538, 257, 2689, 3082, 13, 400, 309, 4523, 484, 300, 264, 18491, 366, 406, 300, 4524, 11, 51308], "temperature": 0.0, "avg_logprob": -0.1164528748084759, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.007340359501540661}, {"id": 355, "seek": 227368, "start": 2292.56, "end": 2298.0, "text": " you can have like, you can have like a very much more liberal constraint and still be", "tokens": [51308, 291, 393, 362, 411, 11, 291, 393, 362, 411, 257, 588, 709, 544, 13767, 25534, 293, 920, 312, 51580], "temperature": 0.0, "avg_logprob": -0.1164528748084759, "compression_ratio": 1.812807881773399, "no_speech_prob": 0.007340359501540661}, {"id": 356, "seek": 229800, "start": 2298.0, "end": 2303.28, "text": " non-singling. In fact, you can go beyond quantum mechanics, and you can have like PR boxes. And", "tokens": [50364, 2107, 12, 82, 278, 1688, 13, 682, 1186, 11, 291, 393, 352, 4399, 13018, 12939, 11, 293, 291, 393, 362, 411, 11568, 9002, 13, 400, 50628], "temperature": 0.0, "avg_logprob": -0.13204634293265965, "compression_ratio": 1.7116788321167884, "no_speech_prob": 0.012412706390023232}, {"id": 357, "seek": 229800, "start": 2303.28, "end": 2308.0, "text": " so to, I would say you just have to get used to the fact that you should resist the temptation", "tokens": [50628, 370, 281, 11, 286, 576, 584, 291, 445, 362, 281, 483, 1143, 281, 264, 1186, 300, 291, 820, 4597, 264, 30423, 50864], "temperature": 0.0, "avg_logprob": -0.13204634293265965, "compression_ratio": 1.7116788321167884, "no_speech_prob": 0.012412706390023232}, {"id": 358, "seek": 229800, "start": 2308.0, "end": 2314.48, "text": " that when you have these like correlations that cannot be dealt with sort of the standard way", "tokens": [50864, 300, 562, 291, 362, 613, 411, 13983, 763, 300, 2644, 312, 15991, 365, 1333, 295, 264, 3832, 636, 51188], "temperature": 0.0, "avg_logprob": -0.13204634293265965, "compression_ratio": 1.7116788321167884, "no_speech_prob": 0.012412706390023232}, {"id": 359, "seek": 229800, "start": 2314.48, "end": 2318.72, "text": " screening them off by conditionalizing on common causes, that you think of these as just", "tokens": [51188, 17732, 552, 766, 538, 27708, 3319, 322, 2689, 7700, 11, 300, 291, 519, 295, 613, 382, 445, 51400], "temperature": 0.0, "avg_logprob": -0.13204634293265965, "compression_ratio": 1.7116788321167884, "no_speech_prob": 0.012412706390023232}, {"id": 360, "seek": 229800, "start": 2318.72, "end": 2323.84, "text": " constrained produced by natures and not like, oh, Alice does one thing and then like, you know,", "tokens": [51400, 38901, 7126, 538, 2249, 1303, 293, 406, 411, 11, 1954, 11, 16004, 775, 472, 551, 293, 550, 411, 11, 291, 458, 11, 51656], "temperature": 0.0, "avg_logprob": -0.13204634293265965, "compression_ratio": 1.7116788321167884, "no_speech_prob": 0.012412706390023232}, {"id": 361, "seek": 232384, "start": 2323.84, "end": 2330.1600000000003, "text": " like it travels like instantaneously to Bob or vice versa. And if you, if you, if you go for this", "tokens": [50364, 411, 309, 19863, 411, 9836, 13131, 281, 6085, 420, 11964, 25650, 13, 400, 498, 291, 11, 498, 291, 11, 498, 291, 352, 337, 341, 50680], "temperature": 0.0, "avg_logprob": -0.1417458408562712, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.004259186331182718}, {"id": 362, "seek": 232384, "start": 2330.8, "end": 2335.52, "text": " if you go this epistemic route, that is easier, right? I mean, like, I think a lot of students", "tokens": [50712, 498, 291, 352, 341, 2388, 468, 3438, 7955, 11, 300, 307, 3571, 11, 558, 30, 286, 914, 11, 411, 11, 286, 519, 257, 688, 295, 1731, 50948], "temperature": 0.0, "avg_logprob": -0.1417458408562712, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.004259186331182718}, {"id": 363, "seek": 232384, "start": 2335.52, "end": 2342.0, "text": " in quantum mechanics who, you know, like, no matter how, how often you tell them that astrodinger,", "tokens": [50948, 294, 13018, 12939, 567, 11, 291, 458, 11, 411, 11, 572, 1871, 577, 11, 577, 2049, 291, 980, 552, 300, 5357, 340, 3584, 260, 11, 51272], "temperature": 0.0, "avg_logprob": -0.1417458408562712, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.004259186331182718}, {"id": 364, "seek": 232384, "start": 2342.0, "end": 2347.52, "text": " that astrodinger wave function is not a field on ordinary space, still have this picture like,", "tokens": [51272, 300, 5357, 340, 3584, 260, 5772, 2445, 307, 406, 257, 2519, 322, 10547, 1901, 11, 920, 362, 341, 3036, 411, 11, 51548], "temperature": 0.0, "avg_logprob": -0.1417458408562712, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.004259186331182718}, {"id": 365, "seek": 232384, "start": 2347.52, "end": 2352.8, "text": " well, then you do a measurement and the whole thing goes poof, instantaneously. And like now", "tokens": [51548, 731, 11, 550, 291, 360, 257, 13160, 293, 264, 1379, 551, 1709, 714, 2670, 11, 9836, 13131, 13, 400, 411, 586, 51812], "temperature": 0.0, "avg_logprob": -0.1417458408562712, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.004259186331182718}, {"id": 366, "seek": 235280, "start": 2352.8, "end": 2357.44, "text": " you're stretching your head like, you know, what is it that is traveling from like Alice to Bob", "tokens": [50364, 291, 434, 19632, 428, 1378, 411, 11, 291, 458, 11, 437, 307, 309, 300, 307, 9712, 490, 411, 16004, 281, 6085, 50596], "temperature": 0.0, "avg_logprob": -0.12384183783280223, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0025265824515372515}, {"id": 367, "seek": 235280, "start": 2357.44, "end": 2363.28, "text": " that then like frustratingly you can never use to send a signal, right? And so I'm hoping that", "tokens": [50596, 300, 550, 411, 16522, 356, 291, 393, 1128, 764, 281, 2845, 257, 6358, 11, 558, 30, 400, 370, 286, 478, 7159, 300, 50888], "temperature": 0.0, "avg_logprob": -0.12384183783280223, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0025265824515372515}, {"id": 368, "seek": 235280, "start": 2363.28, "end": 2368.2400000000002, "text": " this approach will sort of prevent people like, you know, from going down that particular rabbit", "tokens": [50888, 341, 3109, 486, 1333, 295, 4871, 561, 411, 11, 291, 458, 11, 490, 516, 760, 300, 1729, 19509, 51136], "temperature": 0.0, "avg_logprob": -0.12384183783280223, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0025265824515372515}, {"id": 369, "seek": 235280, "start": 2368.2400000000002, "end": 2382.6400000000003, "text": " hole in the first place. Okay, thanks. Thanks. It's clear. Yeah. I tend to agree. Yes.", "tokens": [51136, 5458, 294, 264, 700, 1081, 13, 1033, 11, 3231, 13, 2561, 13, 467, 311, 1850, 13, 865, 13, 286, 3928, 281, 3986, 13, 1079, 13, 51856], "temperature": 0.0, "avg_logprob": -0.12384183783280223, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.0025265824515372515}], "language": "en"}