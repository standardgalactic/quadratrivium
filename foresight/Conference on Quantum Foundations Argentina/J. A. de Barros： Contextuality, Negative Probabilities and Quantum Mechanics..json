{"text": " OK, well, it's kind of like a hard task to start after such a great talk. I didn't get the whole talk. It's the end of the semester here, but it was very interesting what I saw, and I'm going to sure read more about it. So what I want to talk today is about negative probabilities in quantum mechanics, and in particular with respect to contextuality. And I think it ties a little bit with the previous talk, because you can think of that as a way of describing certain quantum systems that's epistemic. But at the end of the day, my interest is in trying to rule out some possible ontological models as well. Anyway, so here's the outline of my talk today. I'm going to start with trying to give some motivation about negative probabilities, and then I'm going to talk about how is it that negative probabilities actually come into this story through contextuality. And then after that, I'm going to give a definition of negative probabilities that is more formal than usually one would find. And there is a reason for doing that, and hopefully the motivation is going to make it clear what is the reason. So the starting point is the realization that quantum mechanics, as the previous speaker mentioned, is a probability theory, in a certain sense. So what we have in quantum mechanics is a state for a physical system. And that state is a vector in a hyperspace, or a density matrix, whatever. And we can use that state to infer outcomes of experiments probabilistically. So that's what quantum theory gives us, is this probabilistic description of physical systems. However, this probabilistic description that quantum theory gives to us is not fully compatible with classical probability theory, in the sense that for some set of observables for a quantum system, if we look at the experimental outcomes that quantum theory predicts, you cannot have a joint probability distribution that describes all those observables within classical theory. We have kind of like a name for that. We say that those theories are contextual. And in the section about contextuality, I'm going to outline a little bit more detail of what we mean by that for those who are not aware of that. Probably all of you are, but anyway. So since we cannot describe quantum mechanics with classic probability theory, it's natural to ask whether we can modify classic probability theory to describe quantum systems. So is it possible that some different probability theory can actually help us get a better understanding of what's going on in these quantum systems? And there are different ways to modify classic probability theory. One of them is, well, actually, quantum theory itself, where we use a probability that's over vectors in hybrid space. And that effectively modifies probability theory, in the sense that not everything is commasurable. And the algebra of events that you have is restricted to a lattice. So you don't have the standard Boolean algebra of all the events. And you cannot give a measure of all the events at the same time. So that's one possibility is modifying the algebra of classic probabilities, because classic probabilities assumes that the events form an algebra that's a Boolean algebra. The other way is to modify the additivity rule. We know, for example, that probability theory, if two sets belong to this algebra of measurable events, they are compute. We compute the probability of those two sets, the disjoint sets. Together, the probability of two disjoint sets is the sum of those probabilities of those sets. So that's the additivity rule. So one of the things that we can do is we can modify that additivity rule. And that's something that comes out of definite work on upper and lower probabilities. And the other possibility is the one that we're going to be following here is to modify probabilities such that we don't restrict ourselves to non-negative values. So those are ways of extending probability theory. And so when we think about negative probabilities or probabilities where the non-negativity of probabilities is denied, we need to think about it carefully. And how exactly do we want to define that? So what we're going to be trying to do today is introduce a way to describe quantum systems that violate this non-negatives, the negativeness property, such that we have, first, a major theoretic formalism that does that, and second, that we capture the essence of what we want to have in quantum systems and physical systems in that theory of probability. So that's essentially what we want to do today. So let's start with contextuality. And I'm going to have a little bit of a weird, non-historic approach to contextuality that starts with a historic comment, which is contextuality originated. The idea of contextuality originates in language. And it was well known in the 20th century in works in pragmatics, for example. But take the sentence, marry a student near the bank, observing people. We can understand the sentence differently, depending on whether it's preceded or it's followed by distinct sentences. For example, take this very same sentence followed by this statement. She paused to notice a child amuse herself with the fishes jumping in the river. When we read that sentence and we read the first one together of the second one about a child looking at fishes in the river, we understand that bank refers to the bank of a river. But if, on the other hand, instead of this, we followed marry a student near the bank, with this sentence, she noticed the manager punctually leaving at noon, something that would help with the heist. We associate bank not with the bank of a river, but we associate it with a financial institution, the physical manifestation of a financial institution. So in this example, the first sentence, how we understand it, changes of the context when it's put together with this child looking at fishes, when it's put together with heist. So that is the sense in which linguists talk about contextuality of language. And we can understand contextuality of language in terms of a very logic approach to language, which is the truth functional approach, in which propositions are the way in which we understand meaning of sentences. So like, for example, take the two propositions, A and B, A being marry a student near the river bank, and B being marry a student near the building of a financial institution. Those two sentences, they have different truth values depending on the context. In the context of river, A is true and B is false, whereas in the context of heist, A is false and B is true. So it's in this sense of truth values that we can understand contextuality and actually even relates contextuality in language to contextuality in quantum mechanics via random variables. So let's look at how contextuality in this case will show up in terms of random variables. So we can think about those statements A and B as being modeled by random variables A and B. I'm going to represent them in both face here just to distinguish between the statements A and B, the propositions A and B. And these random variables A and B modeled it by being dichotomous random variables with values plus and minus one. With minus one, for example, corresponding to the statement being false and plus one corresponding to the statement being true. It's kind of like silly to think about random variables for this particular example because they are not, they're deterministic random variables because once a statement is true, A is always going to be one, right? And if B is false, B is always going to be minus one. So it's kind of silly to think about in terms of random variables, but there's nothing that forbids us from doing that. And contextuality here means that there is no single random variable A and B that represents those concepts A and B in different contexts, or represent those truth values in different contexts. The reason is that a random variable is defined within a probability space. And the probabilities, they cannot represent both A and B simultaneously. So this is the contextuality that comes in linguistics. It's, we can call this as a direct influence of the context on the random variables because the expectations of the random variables change directly with the context. In one context, the expectation of A is one, in another context, the expectation of A is minus one. So the expectation changes the context. This is not what happens in physics because this type of contextuality would violate the signaling condition, but that's a way of representing the linguistic type of contextuality in terms of random variables. But once we have that idea of contextuality as changing the expectations of random variables in, with respect to the context, we kind of like have a clue of how is it that we can extend that to things that might be more relevant to physics. So let's take a more subtle case, right? Let's take three, that column was random variables x, y, and z. So plus or minus one random variables. And let's just assume that their expectation is zero. So we don't know, it's kind of like tossing a coin for x, y, and z. We don't know whether it's true or false every time that we observe it, but they're perfectly correlated among themselves. So x is perfectly anti-correlated with y, x is perfectly anti-correlated with z, and perfectly anti-correlated with z and y. Z and y are perfectly anti-correlated. And it's a very straightforward to see that if we have such cases where x, y, x, z, and y, z are anti-correlated, that there is something funky going on. And the way to see there is something funky going on is just to notice that, for example, if x equals one, this guy here implies that y equals minus one. And if x equals one, this guy here implies that z equals minus one. But minus one times minus one is one. However, this guy here tells us that y times z is minus one, which is a contradiction. So there is something wrong going on. And what is wrong is that when we're using this reasoning of x being implying y equals minus one here in this first equation, and then we're using it as implying z here in this second equation, and then using to get the multiplication in the third equation, we're assuming that all three random variables are defined together. That means that we're assuming there's a joint probability distribution. But it doesn't exist. Assuming that x in the context of y is the same as x in the context of z is what's leading as your contradiction, assuming that all three of them are observable at the same time is leading as your contradictions. And we know that this happens in quantum mechanics, that there are things that we cannot absorb at the same time. So can we see something like that in quantum mechanics? And the answer is yes. A very famous example is the GHZ states. We have three particles, one, two, and three, that are in an entangled state where either all three of them have spin in the direction z being plus, or all three of them have spin in the direction z being minus, and then we have a superposition of those two states. And then it's easy to see that these guys have the following eigenstates. For example, if we measure spin of particle one in the direction x, measure spin in the particle two in the direction y, and three in the direction y, the product of those three spins is always gonna be one. In the other hand, if we measure y, x, y, it's also gonna be one, y, y, x is also one, but x, x, x is minus one. So we can try to look at it in terms of random variables. Let's say we have an x-random variable for spin in the direction x, a y-random variable for spin in the direction y, and then we assume them to be context independent. And if we do that, we can multiply this guy here, the random variables corresponding to this spin, x, y, y, times the spin y, x, y, times y, y, x, and each one of those guys in parentheses are equal to one. And when we multiply them, we can now collect all the y's together and all the x's together, and the square of something that's closer minus one is always one. And when we do that, this guy here's one, and we get a contradiction that one is equal to minus one from this quantum mechanical computation. Of course, it's not a contradiction because what we're getting as contradiction is based on the assumption that the y in the context of x and y, y two in the context of x one and y three is the same as the y two in the context of y one and x three. So in other words, we're assuming a joint probability distribution. So when we have a set of random variables that are contextual, there is no joint probability distribution for all the variables. There is, of course, a joint probability distribution for each one of those contexts, but when you put all those six random variables together, there is no joint probability distribution. There's no single probability space, omega fp such that the random variables xi and yi models all the quantum outcomes. That's not possible in standard probability theory. Of course, we know that the quantum formalism provides an answer. We can use the quantum formalism as we shown here to compute the expectations of actual observables that we can measure together, but are there alternatives to quantum model? And more importantly, are there alternatives to the quantum model useful for us to think about what's going on with the quantum case? We don't know whether those alternatives are useful, but we feel that perhaps understanding them better might be a way to at least understand what is it that they can bring to this discussion of what the quantum model or quantum, of what the hub or space formula is telling us. So the alternatives that have been tried, as I mentioned, are upper and lower probabilities, and of course, there are negative probabilities that we wanna expand more today. So let's go into defining negative probabilities. To understand how we define negative probabilities, it's useful to see how we define standard probability theory. Right? So the most accepted definition of standard probability theory is by Komagorov. He gave a set theoretic definition of classic probability theory as being the triplets, omega Fp, where omega is a sample space that you have. F is an algebra over that sample space omega that is actually a sigma algebra, a countable algebra, and P is a function that takes elements of this algebra to this interval zero and one. And the restrictions that we have for P is that the measure of omega or the whole set of possibilities is equal to one. In other words, the probability that something happens is one. And the other assumption is that the additivity rule holds for this function. In other words, for any denumerable and this joint family of elements of this algebra F, Ai, the probability of A, say A1 or A2 is the sum of the probability of A and the probability of two. So that's something that's a requirement of probability theory. And because this is a number between zero and one, this probability is monotonic. So if you have a set A, the probability of adding something more to that set A, that's this joint of A, increases the probability of absorbing that event. So if you add more possibilities, this becomes more probable. And in quantum mechanics, this is not quite the case. It's non-monotonic, but this is something that I'm not gonna talk too much about. So how do we get negative probabilities? We might be tempted to just violate this requirement and we're done with it. But the problem is that there are certain constraints about negative probabilities that at least seem to make sense, which is that first and foremost, we never directly observe a negative probability. What the heck does it mean to even observe a negative probability? So we need to understand how exactly does the negative probability show in terms of directly observable quantities. And observables are not parts of komagorov stock. So we need to include that. And furthermore, there's no connection if we just like relax this requirement that ties the marginals to the empirical observable contexts. So what we're gonna do here is just try to show how we can define negative probabilities with those ideas in mind. So that's our major theoretic definition of negative probabilities. It's gonna be a little bit abstract from now on, but I'm gonna try to give the main ideas of what is the outlining of this definition, right? We start with a sample space, not a sample space. We start with the concept of assigned measure. So assigned measure is exactly the same as a measure, except that instead of having a measure going from a sigma algebra to the set of non-negative real numbers, assigned measure is something that takes the sets of elements of the algebra into any real number, including negative numbers. And this is well known in measure theory. So it's something that has been studied extensively. And essentially, if we restrict the assigned measure to non-negative numbers, we get a regular measure. And if we restrict this measure such that mu of omega for this measure is equal to one, we get probabilities. So that's the starting point. We start with assigned measure space that has the additivity rule as part of it. And then once we have this assigned measure space, we need to find a way to connect it to the actual observations that we have. And the starting point is to create an object that's not quite a random variable, but it's what we call an extended random variable because instead of being defined over a probability space, we're defining it into assigned measure space. And the idea is just that if the assigned measure space then becomes a probability space, those random variables become regular random variables. And the definition is just the standard definition of random variable where you have a function that goes from your sample space to some real number M that's parts of a sets. This should be this M here, something wrong here. Anyway, and such that this function is a measurable function in the sense of this measure that we have. It's a measure induced definition. And then from this, we can kind of like start to narrow down the idea of contexts. And contexts are just proper subsets of those random variables, such that there is a sub sigma algebra for each one of those subsets of the random variables. That define a probability space for those random variables there. So intuitively we'll have this bunch of extended random variables. And we have this measure space describing those extended random variables. But then we get a subspace of that. And this subspace has a measure space associated to it such that we actually have proper random variables in this subspace. And this allows us to talk now about families of signed probabilistic models that have just those contexts defined for those families and then measures in this context. I'm gonna skip a little bit faster in this. And then once we do that, we can find a concept of a general context that just has like the same idea of the broader one. But now we're saying that those are just for those guys that look like probabilities in the subspace. So finally, we have like those families of signed probability models. And those families of signed probability models, what you have are those like functions that reproduce all the expectations that you have on the contexts. But it's kind of like the wild west here because they can be as large or as small as you want. And what we need to do then is tame a little bit those set of functions by saying, look, if we now take the sum of all the probabilities, the extended probabilities that we have over the sample space for each one of those elements of this signed probability spaces, we get a value. And what we want are the smallest possible values possible because when that happens, we're as close as we can be to a proper probability distribution. In fact, this is gonna come up in a theorem later on. And when we do that, when we ask for the minimum value of the sum, then we call that a negative probability space. It's when this minimum is obtained. If we do that, then we have the following theorem. Imagine that you have now this guy as a minimum signed probability space or as a negative probability space. So if this M defined as the sum of the probabilities of elements of the sample space is equal to one, then this is a probability space. It's very intuitive to see why that is. It's because if you remove the absolute value of this, this is just the probability of omega, which is always one for a probability space. And what you're saying is that nothing is pulling that probability higher or lower because the sum of the absolute values is the same as the sum without absolute values. There's nothing negative here. It's all non-negative. So this is also a probability space. And alternatively, if this guy, it's missing the both face omega here, but if this is a probability space, then it's also a signed probability space of M equals one. Additionally, a collection of extended random variables of this space is contextual, if and only if M is not one. So we have here criteria for contextuality just showing up in the definition of negative probabilities. I'm gonna skip this because I'm running out of time, but this is how you can connect it to a quantum mechanics. I gotta say there are lots of different ways in which negative probabilities connect to a quantum mechanics. For example, the previous speaker mentioned about PR boxes. You can, as long as you have no signaling, you can describe any correlations in terms of negative probabilities. So you can describe PR boxes in terms of negative probabilities. You can describe GHC in terms of negative probabilities or Bell in terms of negative probabilities. But a natural question that often comes up comes up in this discussion of negative probabilities is what are the interpretations that we can give to a negative probabilities? I'm gonna talk about three possible interpretations. Andrei Krenikov, he uses a piatic matrix to give an interpretation of negative probabilities as a violation of von Mises principle of stability. So as we know, if you wanna have a frequentist interpretation of probabilities, what are probabilities? And von Mises defines probabilities as being over infinite sequences of possible outcomes on the sample space, of possible values in the sample space. And those probabilities are only defined for those infinite sequences if they converge to a number. So that's what Mises principle of stability. So what Krenikov noticed is that for certain sequences that violate the principle of stability, you can actually define probabilities for them if you use a piatic metric. And when you do that, the sequences that violate von Mises principle of stability actually take negative values. So that's the interpretation that he gives, is that negative probabilities are associated with numbers that violate the principle of stability, which in terms of like, if you are trying to understand, for example, Bell correlations, it means that those sequences that you're assuming to be independent, they're not actually independent. Because... You have 10 minutes including the question. Oh yeah, I'm just finishing it. Just finishing the rotations. Thanks. So another interpretation is proposed by Bromsky and Brandenburger. It's actually based on the composition theorem that shows that if you have a signed measure, you can always break it down into two measures, one positive and one negative, and each one of them independently are non-signed measures. And what they do is they just attach a sign to each one of the outcomes of an experiment, and then those signs, they lead to cancellation of certain events. There's a third interpretation, which is the one put forth by Derrack and later on by Feynman, which is that probabilities, negative probabilities for that matter, are just a bookkeeping device. So in that sense, negative probabilities are nothing more than the same as we do with negative numbers. So for example, we never observe a negative number of apples. In fact, it's nonsensical to talk about a negative number of numbers as an actual observable, but it doesn't mean that using negative numbers of apples is not a useful book counting device. We never observe a negative number of dollars for that matter either. It doesn't mean that one never has negative numbers in an account as a bookkeeping device for how much money we have in an account. And the reason why I'm mentioning numbers here is because the concept of even using negative numbers has not been always non-controversial. Consider, for example, the following quote by De Morgan, the famous mathematician and logician in a book that he wrote in the 30s. And I'll read the quote to you. Above all, he, the student, must reject the definition still sometimes given of the quantity minus A, that it is less than nothing. It is astonishing that the human intellect should ever have tolerated such an absurdity as the idea of a quantity less than nothing. Above all, that the notion should have outlived the beliefs in judicial astrology and the nonexistence of witches, either of which is 10,000 times more possible. So as late as like the 1800s, negative numbers were still considered like an absurd idea by some. And it might be the case that negative probabilities will in the future be considered the same as we consider negative numbers, something just natural, like natural numbers are as a bookkeeping device. So just to summarize what I talked today, as we discussed, contextuality is a key characteristic of quantum properties. We often use hybrid space formalism to describe those quantum properties and the hybrid space formalism has built in that contextuality. That contextuality cannot be represented in probability theory unless you do something like for example, the approach of contextuality by default by increasing the number of random variables. But that goes against a little bit the idea that we do in physics because we have the same measurement apparatus for some of those things. But extended probability theories can be constructed. And here we just presented a measure theoretic framework for defining an extended probability that we feel captures at least the gist of quantum contextuality in the sense that we can model quantum contextuality with that probability theory. And we hope that such tool may be used when describing quantum phenomena. Like for example, we know that it implies the no signaling condition, which is part of quantum systems. But it's still unclear whether it's useful or not. So I just wanna end with acknowledging my collaborators. What I talked today is in essence part of a paper that I did with Federico Halleck who's organizing this conference. But I also benefited from a lot of discussions of many people in particular, those people listed here. So thank you. Okay, thank you, Jose, for your talk. There are some questions in the chat. The first one is from Shansen. All right, thank you for that talk. My question is about, has to do with sort of rhetoric and pedagogy. So, you know, like we, it sounds like we think very much the same way about quantum mechanics is basically like a new framework for handling probabilities. And I wonder whether it's the smartest strategy to convince people of our view that you now like have to like get used to the idea of negative probabilities. I mean, if you start, I mean, you're very nicely laid out the difference. Like, you know, you have contextuality, right? You don't, but quantum mechanics doesn't allow you to have joint probabilities, right? You can't assign values to all the different variables. I wonder if there isn't like sort of a more natural way of like ramming that down people's throats than going this route of introducing negative probabilities. Yeah, thank you. I confess that I would probably never teach negative probabilities to my students. Well, never, I mean, maybe in the future. That's not the reason why I'm talking about negative probabilities actually. The reason why I'm talking about negative probabilities is because I hope that by trying to understand certain phenomena in terms of negative probabilities, we might be able to get different insights into those phenomena that we would not get from the Hebert space formalism. I can give you a specific example, right? So when we look at different principles that define quantum mechanics that people have tried, like for example, Cabello have tried to define some principles that give us quantum mechanics. When you write them down in terms of negative probabilities, they become clear. Whether that's a useful tool for us to understand what's going on with quantum mechanics or not, I don't know because I didn't get any special insights from that, but that's my hope, right? That's what I'm trying to do. I'm trying to see if we can understand different types of quantum puzzles in terms of negative probabilities such that we can get better insight from them. If we do, then perhaps in the future, we might even try to teach our students that, but we're not there yet. Okay, thank you. And there is another question from Alison Decini. Hi, can you hear me? Yes, I can hear you. Okay, so thanks for the very nice question. My question is about Cauchy-Speccher theorem. So how do you avoid Cauchy-Speccher theorem in this kind of framework? Because Cauchy-Speccher theorem rule out the existence of evaluations. And if we represent all measurements as random variables in the same, sharing the same sample space, a point of the sample space would be evaluation. So how can you avoid Cauchy-Speccher theorem within this approach? That's my question. If I understand your question correctly, you're asking how I avoid Cauchy-Speccher and we don't. Let me go back to the GHZ case, which is a, so the difference between GHZ and Cauchy-Speccher that GHZ is for a specific state and Cauchy-Speccher is for any state, right? It's about the algebra of quantum observables. But you could think of Cauchy-Speccher as a series of measurements that prepare a state and then later on you get a contradiction. That's a different way to think about Cauchy-Speccher, but it's all there together. But this is the GHZ also has a contradiction, right? And the contradiction comes here from this guy in the bottom. This first parenthesis being one times one times one being equal to minus one. It's the same type of contradiction that you get on Cauchy-Speccher. And you are using random variables because each one of them individually are random. But if you look at each one of those products, if you thought of them as an individual random variable, let's say we call this product A, we call this product B and we call this product C. What we have is that A times B times C is equal to D. But this is what quantum mechanics tells us, but A is equal to one, B is equal to one and C is equal to one whereas D is equal to minus one. That's the contradiction. And the random variables that we have here are deterministic random variables. So I don't know if I'm answering your question the way you thought about it, but what I'm saying is we're not avoiding it. We have the contradictions there, but the contradictions come from the assumptions of Cauchy-Speccher. And the assumption of Cauchy-Speccher is that this guy here, say Y2 in this context is the same as the Y2 in this context. And when we use negative probabilities, that assumption is not true anymore because negative probabilities are washing out those requirements of how is it that those random variables are related. And then what you're asking about, if you were to ask me how exactly they are washing out those requirements, I would tell, wow, I don't know. That's how we book keep those probabilities. If you wanna know how they are doing that, then you would need to go to an interpretation that is not a purely epistemic interpretation as in bookkeeping. And there's nothing that forbids you from doing that, right? Does that make sense, what I'm saying? Or am I being confused here, confusing? Yeah, yeah, no, it makes sense. Thanks, thank you. Okay, we are done of the break. So, but there is one more question. It is very fast. So perhaps I can make it, if it's okay with you. So it is just about the notion of contextuality that you seem to be using. I'm just curious if you are familiar with the work of Speckens and this idea of using a different definition of contextuality than the one that seems to be used in Gohan Specker and in Bell's proof of non-contextuality. And if that makes a difference in the kind of project that you are using to accommodate all of contextuality using negative probabilities. Yeah, that's a good question. One could give a whole talk about like different ways of thinking about contextuality, right? So I've been very casual about talking about contextuality here and very specific about it. But it's unclear exactly how those different notions of contextuality relate to each other. Sometimes, not all the time, right? And to be very precise, one would need to prove what is the relationship between one definition of contextuality and another definition of contextuality. And as far as I know, that has not been done for all notions of contextuality. But there is this intuition that they kind of like are talking about the same thing. Because at the end of the day, they're all about commasurable properties and how those commasurable properties somehow are related to not having a possibility of talking about all of those properties at the same time, in terms of the intuition behind them. I know I'm not answering your question and the reason why I'm not answering your question is because I'm trying to say that I don't think there is a very clear answer to that question yet. But we hope that once we give a definition that's a measure theoretic definition, that precise definition of negative probabilities that correspond to also a definition of contextuality in that setup, that you can use that to prove theorems about how those things are related. It might be really, really interesting to explore that for two reasons, because the kind of definition that the Speckens uses makes no explicit reference to the idea of measuring two things at the same time. It is kind of different to the general idea. And two, because in the original paper, I think that that's from 25, he has a small derivation of showing that from his definition, you can derive the traditional one, the one that the Cohen Speckens used. So there must be a connection. Yeah, yeah, yeah, that's what I'm saying. All those things are related, but how exactly they are related, it's not. Intuitively, yes, they should be related, but it's one thing to think that they should be related intuitively and to prove that they're related. So that's what I was trying to say. Thank you, Jose, and the people who have questions would have some minutes to go to the bathroom or take a coffee. We will back.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.44, "text": " OK, well, it's kind of like a hard task", "tokens": [50364, 2264, 11, 731, 11, 309, 311, 733, 295, 411, 257, 1152, 5633, 50686], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 1, "seek": 0, "start": 6.44, "end": 9.16, "text": " to start after such a great talk.", "tokens": [50686, 281, 722, 934, 1270, 257, 869, 751, 13, 50822], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 2, "seek": 0, "start": 9.16, "end": 12.24, "text": " I didn't get the whole talk.", "tokens": [50822, 286, 994, 380, 483, 264, 1379, 751, 13, 50976], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 3, "seek": 0, "start": 12.24, "end": 14.280000000000001, "text": " It's the end of the semester here,", "tokens": [50976, 467, 311, 264, 917, 295, 264, 11894, 510, 11, 51078], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 4, "seek": 0, "start": 14.280000000000001, "end": 16.56, "text": " but it was very interesting what I saw,", "tokens": [51078, 457, 309, 390, 588, 1880, 437, 286, 1866, 11, 51192], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 5, "seek": 0, "start": 16.56, "end": 20.400000000000002, "text": " and I'm going to sure read more about it.", "tokens": [51192, 293, 286, 478, 516, 281, 988, 1401, 544, 466, 309, 13, 51384], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 6, "seek": 0, "start": 20.400000000000002, "end": 26.12, "text": " So what I want to talk today is about negative probabilities", "tokens": [51384, 407, 437, 286, 528, 281, 751, 965, 307, 466, 3671, 33783, 51670], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 7, "seek": 0, "start": 26.12, "end": 29.28, "text": " in quantum mechanics, and in particular with respect", "tokens": [51670, 294, 13018, 12939, 11, 293, 294, 1729, 365, 3104, 51828], "temperature": 0.0, "avg_logprob": -0.16523793873034026, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.008433058857917786}, {"id": 8, "seek": 2928, "start": 29.28, "end": 30.6, "text": " to contextuality.", "tokens": [50364, 281, 35526, 507, 13, 50430], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 9, "seek": 2928, "start": 30.6, "end": 34.32, "text": " And I think it ties a little bit with the previous talk,", "tokens": [50430, 400, 286, 519, 309, 14039, 257, 707, 857, 365, 264, 3894, 751, 11, 50616], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 10, "seek": 2928, "start": 34.32, "end": 37.96, "text": " because you can think of that as a way of describing", "tokens": [50616, 570, 291, 393, 519, 295, 300, 382, 257, 636, 295, 16141, 50798], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 11, "seek": 2928, "start": 37.96, "end": 42.52, "text": " certain quantum systems that's epistemic.", "tokens": [50798, 1629, 13018, 3652, 300, 311, 2388, 468, 3438, 13, 51026], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 12, "seek": 2928, "start": 42.52, "end": 45.760000000000005, "text": " But at the end of the day, my interest", "tokens": [51026, 583, 412, 264, 917, 295, 264, 786, 11, 452, 1179, 51188], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 13, "seek": 2928, "start": 45.760000000000005, "end": 53.24, "text": " is in trying to rule out some possible ontological models", "tokens": [51188, 307, 294, 1382, 281, 4978, 484, 512, 1944, 6592, 4383, 5245, 51562], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 14, "seek": 2928, "start": 53.24, "end": 54.36, "text": " as well.", "tokens": [51562, 382, 731, 13, 51618], "temperature": 0.0, "avg_logprob": -0.13466894471800173, "compression_ratio": 1.478494623655914, "no_speech_prob": 0.001696612685918808}, {"id": 15, "seek": 5436, "start": 54.36, "end": 61.96, "text": " Anyway, so here's the outline of my talk today.", "tokens": [50364, 5684, 11, 370, 510, 311, 264, 16387, 295, 452, 751, 965, 13, 50744], "temperature": 0.0, "avg_logprob": -0.12564915104916222, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.0008960386039689183}, {"id": 16, "seek": 5436, "start": 61.96, "end": 64.16, "text": " I'm going to start with trying to give some motivation", "tokens": [50744, 286, 478, 516, 281, 722, 365, 1382, 281, 976, 512, 12335, 50854], "temperature": 0.0, "avg_logprob": -0.12564915104916222, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.0008960386039689183}, {"id": 17, "seek": 5436, "start": 64.16, "end": 67.4, "text": " about negative probabilities, and then", "tokens": [50854, 466, 3671, 33783, 11, 293, 550, 51016], "temperature": 0.0, "avg_logprob": -0.12564915104916222, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.0008960386039689183}, {"id": 18, "seek": 5436, "start": 67.4, "end": 71.2, "text": " I'm going to talk about how is it that negative probabilities", "tokens": [51016, 286, 478, 516, 281, 751, 466, 577, 307, 309, 300, 3671, 33783, 51206], "temperature": 0.0, "avg_logprob": -0.12564915104916222, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.0008960386039689183}, {"id": 19, "seek": 5436, "start": 71.2, "end": 76.76, "text": " actually come into this story through contextuality.", "tokens": [51206, 767, 808, 666, 341, 1657, 807, 35526, 507, 13, 51484], "temperature": 0.0, "avg_logprob": -0.12564915104916222, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.0008960386039689183}, {"id": 20, "seek": 5436, "start": 76.76, "end": 81.32, "text": " And then after that, I'm going to give a definition", "tokens": [51484, 400, 550, 934, 300, 11, 286, 478, 516, 281, 976, 257, 7123, 51712], "temperature": 0.0, "avg_logprob": -0.12564915104916222, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.0008960386039689183}, {"id": 21, "seek": 8132, "start": 81.32, "end": 86.83999999999999, "text": " of negative probabilities that is more formal than usually one", "tokens": [50364, 295, 3671, 33783, 300, 307, 544, 9860, 813, 2673, 472, 50640], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 22, "seek": 8132, "start": 86.83999999999999, "end": 87.67999999999999, "text": " would find.", "tokens": [50640, 576, 915, 13, 50682], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 23, "seek": 8132, "start": 87.67999999999999, "end": 89.47999999999999, "text": " And there is a reason for doing that,", "tokens": [50682, 400, 456, 307, 257, 1778, 337, 884, 300, 11, 50772], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 24, "seek": 8132, "start": 89.47999999999999, "end": 93.96, "text": " and hopefully the motivation is going to make it clear", "tokens": [50772, 293, 4696, 264, 12335, 307, 516, 281, 652, 309, 1850, 50996], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 25, "seek": 8132, "start": 93.96, "end": 95.55999999999999, "text": " what is the reason.", "tokens": [50996, 437, 307, 264, 1778, 13, 51076], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 26, "seek": 8132, "start": 95.55999999999999, "end": 101.0, "text": " So the starting point is the realization", "tokens": [51076, 407, 264, 2891, 935, 307, 264, 25138, 51348], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 27, "seek": 8132, "start": 101.0, "end": 104.8, "text": " that quantum mechanics, as the previous speaker mentioned,", "tokens": [51348, 300, 13018, 12939, 11, 382, 264, 3894, 8145, 2835, 11, 51538], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 28, "seek": 8132, "start": 104.8, "end": 108.83999999999999, "text": " is a probability theory, in a certain sense.", "tokens": [51538, 307, 257, 8482, 5261, 11, 294, 257, 1629, 2020, 13, 51740], "temperature": 0.0, "avg_logprob": -0.14663592780508647, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0005274093709886074}, {"id": 29, "seek": 10884, "start": 108.84, "end": 112.12, "text": " So what we have in quantum mechanics", "tokens": [50364, 407, 437, 321, 362, 294, 13018, 12939, 50528], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 30, "seek": 10884, "start": 112.12, "end": 116.12, "text": " is a state for a physical system.", "tokens": [50528, 307, 257, 1785, 337, 257, 4001, 1185, 13, 50728], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 31, "seek": 10884, "start": 116.12, "end": 118.72, "text": " And that state is a vector in a hyperspace,", "tokens": [50728, 400, 300, 1785, 307, 257, 8062, 294, 257, 7420, 433, 17940, 11, 50858], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 32, "seek": 10884, "start": 118.72, "end": 120.48, "text": " or a density matrix, whatever.", "tokens": [50858, 420, 257, 10305, 8141, 11, 2035, 13, 50946], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 33, "seek": 10884, "start": 120.48, "end": 125.08000000000001, "text": " And we can use that state to infer outcomes of experiments", "tokens": [50946, 400, 321, 393, 764, 300, 1785, 281, 13596, 10070, 295, 12050, 51176], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 34, "seek": 10884, "start": 125.08000000000001, "end": 126.0, "text": " probabilistically.", "tokens": [51176, 31959, 20458, 13, 51222], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 35, "seek": 10884, "start": 126.0, "end": 128.24, "text": " So that's what quantum theory gives us,", "tokens": [51222, 407, 300, 311, 437, 13018, 5261, 2709, 505, 11, 51334], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 36, "seek": 10884, "start": 128.24, "end": 136.28, "text": " is this probabilistic description of physical systems.", "tokens": [51334, 307, 341, 31959, 3142, 3855, 295, 4001, 3652, 13, 51736], "temperature": 0.0, "avg_logprob": -0.1734567710331508, "compression_ratio": 1.6476683937823835, "no_speech_prob": 0.000954548129811883}, {"id": 37, "seek": 13628, "start": 136.32, "end": 139.6, "text": " However, this probabilistic description", "tokens": [50366, 2908, 11, 341, 31959, 3142, 3855, 50530], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 38, "seek": 13628, "start": 139.6, "end": 144.4, "text": " that quantum theory gives to us is not fully compatible", "tokens": [50530, 300, 13018, 5261, 2709, 281, 505, 307, 406, 4498, 18218, 50770], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 39, "seek": 13628, "start": 144.4, "end": 146.24, "text": " with classical probability theory,", "tokens": [50770, 365, 13735, 8482, 5261, 11, 50862], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 40, "seek": 13628, "start": 146.24, "end": 151.52, "text": " in the sense that for some set of observables", "tokens": [50862, 294, 264, 2020, 300, 337, 512, 992, 295, 9951, 2965, 51126], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 41, "seek": 13628, "start": 151.52, "end": 155.64, "text": " for a quantum system, if we look at the experimental outcomes", "tokens": [51126, 337, 257, 13018, 1185, 11, 498, 321, 574, 412, 264, 17069, 10070, 51332], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 42, "seek": 13628, "start": 155.64, "end": 160.28, "text": " that quantum theory predicts, you cannot have a joint", "tokens": [51332, 300, 13018, 5261, 6069, 82, 11, 291, 2644, 362, 257, 7225, 51564], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 43, "seek": 13628, "start": 160.28, "end": 163.88, "text": " probability distribution that describes all those observables", "tokens": [51564, 8482, 7316, 300, 15626, 439, 729, 9951, 2965, 51744], "temperature": 0.0, "avg_logprob": -0.13509700237176356, "compression_ratio": 1.7352941176470589, "no_speech_prob": 0.004005108028650284}, {"id": 44, "seek": 16388, "start": 163.88, "end": 166.28, "text": " within classical theory.", "tokens": [50364, 1951, 13735, 5261, 13, 50484], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 45, "seek": 16388, "start": 166.28, "end": 168.48, "text": " We have kind of like a name for that.", "tokens": [50484, 492, 362, 733, 295, 411, 257, 1315, 337, 300, 13, 50594], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 46, "seek": 16388, "start": 168.48, "end": 170.68, "text": " We say that those theories are contextual.", "tokens": [50594, 492, 584, 300, 729, 13667, 366, 35526, 13, 50704], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 47, "seek": 16388, "start": 170.68, "end": 173.51999999999998, "text": " And in the section about contextuality,", "tokens": [50704, 400, 294, 264, 3541, 466, 35526, 507, 11, 50846], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 48, "seek": 16388, "start": 173.51999999999998, "end": 177.76, "text": " I'm going to outline a little bit more detail of what we mean", "tokens": [50846, 286, 478, 516, 281, 16387, 257, 707, 857, 544, 2607, 295, 437, 321, 914, 51058], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 49, "seek": 16388, "start": 177.76, "end": 183.64, "text": " by that for those who are not aware of that.", "tokens": [51058, 538, 300, 337, 729, 567, 366, 406, 3650, 295, 300, 13, 51352], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 50, "seek": 16388, "start": 183.64, "end": 187.4, "text": " Probably all of you are, but anyway.", "tokens": [51352, 9210, 439, 295, 291, 366, 11, 457, 4033, 13, 51540], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 51, "seek": 16388, "start": 187.4, "end": 193.6, "text": " So since we cannot describe quantum mechanics", "tokens": [51540, 407, 1670, 321, 2644, 6786, 13018, 12939, 51850], "temperature": 0.0, "avg_logprob": -0.16974524165807145, "compression_ratio": 1.558139534883721, "no_speech_prob": 0.001500629005022347}, {"id": 52, "seek": 19360, "start": 193.6, "end": 196.0, "text": " with classic probability theory, it's", "tokens": [50364, 365, 7230, 8482, 5261, 11, 309, 311, 50484], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 53, "seek": 19360, "start": 196.0, "end": 200.24, "text": " natural to ask whether we can modify classic probability theory", "tokens": [50484, 3303, 281, 1029, 1968, 321, 393, 16927, 7230, 8482, 5261, 50696], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 54, "seek": 19360, "start": 200.24, "end": 202.28, "text": " to describe quantum systems.", "tokens": [50696, 281, 6786, 13018, 3652, 13, 50798], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 55, "seek": 19360, "start": 202.28, "end": 207.76, "text": " So is it possible that some different probability theory", "tokens": [50798, 407, 307, 309, 1944, 300, 512, 819, 8482, 5261, 51072], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 56, "seek": 19360, "start": 207.76, "end": 211.68, "text": " can actually help us get a better understanding of what's", "tokens": [51072, 393, 767, 854, 505, 483, 257, 1101, 3701, 295, 437, 311, 51268], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 57, "seek": 19360, "start": 211.68, "end": 215.2, "text": " going on in these quantum systems?", "tokens": [51268, 516, 322, 294, 613, 13018, 3652, 30, 51444], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 58, "seek": 19360, "start": 215.2, "end": 219.35999999999999, "text": " And there are different ways to modify", "tokens": [51444, 400, 456, 366, 819, 2098, 281, 16927, 51652], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 59, "seek": 19360, "start": 219.35999999999999, "end": 222.24, "text": " classic probability theory.", "tokens": [51652, 7230, 8482, 5261, 13, 51796], "temperature": 0.0, "avg_logprob": -0.15176087159376878, "compression_ratio": 1.8756756756756756, "no_speech_prob": 0.0007793031400069594}, {"id": 60, "seek": 22224, "start": 222.28, "end": 226.36, "text": " One of them is, well, actually, quantum theory itself,", "tokens": [50366, 1485, 295, 552, 307, 11, 731, 11, 767, 11, 13018, 5261, 2564, 11, 50570], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 61, "seek": 22224, "start": 226.36, "end": 230.0, "text": " where we use a probability that's over vectors", "tokens": [50570, 689, 321, 764, 257, 8482, 300, 311, 670, 18875, 50752], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 62, "seek": 22224, "start": 230.0, "end": 231.36, "text": " in hybrid space.", "tokens": [50752, 294, 13051, 1901, 13, 50820], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 63, "seek": 22224, "start": 231.36, "end": 235.32000000000002, "text": " And that effectively modifies probability theory,", "tokens": [50820, 400, 300, 8659, 1072, 11221, 8482, 5261, 11, 51018], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 64, "seek": 22224, "start": 235.32000000000002, "end": 238.52, "text": " in the sense that not everything is commasurable.", "tokens": [51018, 294, 264, 2020, 300, 406, 1203, 307, 800, 296, 25863, 13, 51178], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 65, "seek": 22224, "start": 238.52, "end": 241.64000000000001, "text": " And the algebra of events that you have", "tokens": [51178, 400, 264, 21989, 295, 3931, 300, 291, 362, 51334], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 66, "seek": 22224, "start": 241.64000000000001, "end": 244.36, "text": " is restricted to a lattice.", "tokens": [51334, 307, 20608, 281, 257, 34011, 13, 51470], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 67, "seek": 22224, "start": 244.36, "end": 246.52, "text": " So you don't have the standard Boolean algebra", "tokens": [51470, 407, 291, 500, 380, 362, 264, 3832, 23351, 28499, 21989, 51578], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 68, "seek": 22224, "start": 246.52, "end": 247.44, "text": " of all the events.", "tokens": [51578, 295, 439, 264, 3931, 13, 51624], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 69, "seek": 22224, "start": 247.44, "end": 249.68, "text": " And you cannot give a measure of all the events", "tokens": [51624, 400, 291, 2644, 976, 257, 3481, 295, 439, 264, 3931, 51736], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 70, "seek": 22224, "start": 249.68, "end": 251.16000000000003, "text": " at the same time.", "tokens": [51736, 412, 264, 912, 565, 13, 51810], "temperature": 0.0, "avg_logprob": -0.2045948906282408, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.004681225400418043}, {"id": 71, "seek": 25116, "start": 251.16, "end": 254.0, "text": " So that's one possibility is modifying", "tokens": [50364, 407, 300, 311, 472, 7959, 307, 42626, 50506], "temperature": 0.0, "avg_logprob": -0.1879443293032439, "compression_ratio": 1.6706586826347305, "no_speech_prob": 0.0001823245402192697}, {"id": 72, "seek": 25116, "start": 254.0, "end": 256.28, "text": " the algebra of classic probabilities,", "tokens": [50506, 264, 21989, 295, 7230, 33783, 11, 50620], "temperature": 0.0, "avg_logprob": -0.1879443293032439, "compression_ratio": 1.6706586826347305, "no_speech_prob": 0.0001823245402192697}, {"id": 73, "seek": 25116, "start": 256.28, "end": 260.52, "text": " because classic probabilities assumes that the events", "tokens": [50620, 570, 7230, 33783, 37808, 300, 264, 3931, 50832], "temperature": 0.0, "avg_logprob": -0.1879443293032439, "compression_ratio": 1.6706586826347305, "no_speech_prob": 0.0001823245402192697}, {"id": 74, "seek": 25116, "start": 260.52, "end": 263.71999999999997, "text": " form an algebra that's a Boolean algebra.", "tokens": [50832, 1254, 364, 21989, 300, 311, 257, 23351, 28499, 21989, 13, 50992], "temperature": 0.0, "avg_logprob": -0.1879443293032439, "compression_ratio": 1.6706586826347305, "no_speech_prob": 0.0001823245402192697}, {"id": 75, "seek": 25116, "start": 263.71999999999997, "end": 267.8, "text": " The other way is to modify the additivity rule.", "tokens": [50992, 440, 661, 636, 307, 281, 16927, 264, 909, 270, 4253, 4978, 13, 51196], "temperature": 0.0, "avg_logprob": -0.1879443293032439, "compression_ratio": 1.6706586826347305, "no_speech_prob": 0.0001823245402192697}, {"id": 76, "seek": 25116, "start": 267.8, "end": 275.64, "text": " We know, for example, that probability theory, if two sets", "tokens": [51196, 492, 458, 11, 337, 1365, 11, 300, 8482, 5261, 11, 498, 732, 6352, 51588], "temperature": 0.0, "avg_logprob": -0.1879443293032439, "compression_ratio": 1.6706586826347305, "no_speech_prob": 0.0001823245402192697}, {"id": 77, "seek": 27564, "start": 276.32, "end": 281.12, "text": " belong to this algebra of measurable events,", "tokens": [50398, 5784, 281, 341, 21989, 295, 43615, 3931, 11, 50638], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 78, "seek": 27564, "start": 281.12, "end": 283.96, "text": " they are compute.", "tokens": [50638, 436, 366, 14722, 13, 50780], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 79, "seek": 27564, "start": 283.96, "end": 285.76, "text": " We compute the probability of those two sets,", "tokens": [50780, 492, 14722, 264, 8482, 295, 729, 732, 6352, 11, 50870], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 80, "seek": 27564, "start": 285.76, "end": 287.91999999999996, "text": " the disjoint sets.", "tokens": [50870, 264, 717, 48613, 6352, 13, 50978], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 81, "seek": 27564, "start": 287.91999999999996, "end": 290.96, "text": " Together, the probability of two disjoint sets", "tokens": [50978, 15911, 11, 264, 8482, 295, 732, 717, 48613, 6352, 51130], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 82, "seek": 27564, "start": 290.96, "end": 293.15999999999997, "text": " is the sum of those probabilities of those sets.", "tokens": [51130, 307, 264, 2408, 295, 729, 33783, 295, 729, 6352, 13, 51240], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 83, "seek": 27564, "start": 293.15999999999997, "end": 294.44, "text": " So that's the additivity rule.", "tokens": [51240, 407, 300, 311, 264, 909, 270, 4253, 4978, 13, 51304], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 84, "seek": 27564, "start": 294.44, "end": 295.76, "text": " So one of the things that we can do", "tokens": [51304, 407, 472, 295, 264, 721, 300, 321, 393, 360, 51370], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 85, "seek": 27564, "start": 295.76, "end": 298.76, "text": " is we can modify that additivity rule.", "tokens": [51370, 307, 321, 393, 16927, 300, 909, 270, 4253, 4978, 13, 51520], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 86, "seek": 27564, "start": 298.76, "end": 302.03999999999996, "text": " And that's something that comes out", "tokens": [51520, 400, 300, 311, 746, 300, 1487, 484, 51684], "temperature": 0.0, "avg_logprob": -0.2147811814850452, "compression_ratio": 1.9109947643979057, "no_speech_prob": 0.001000352785922587}, {"id": 87, "seek": 30204, "start": 302.04, "end": 306.48, "text": " of definite work on upper and lower probabilities.", "tokens": [50364, 295, 25131, 589, 322, 6597, 293, 3126, 33783, 13, 50586], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 88, "seek": 30204, "start": 306.48, "end": 308.72, "text": " And the other possibility is the one", "tokens": [50586, 400, 264, 661, 7959, 307, 264, 472, 50698], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 89, "seek": 30204, "start": 308.72, "end": 311.0, "text": " that we're going to be following here", "tokens": [50698, 300, 321, 434, 516, 281, 312, 3480, 510, 50812], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 90, "seek": 30204, "start": 311.0, "end": 317.72, "text": " is to modify probabilities such that we don't restrict ourselves", "tokens": [50812, 307, 281, 16927, 33783, 1270, 300, 321, 500, 380, 7694, 4175, 51148], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 91, "seek": 30204, "start": 317.72, "end": 320.16, "text": " to non-negative values.", "tokens": [51148, 281, 2107, 12, 28561, 1166, 4190, 13, 51270], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 92, "seek": 30204, "start": 320.16, "end": 324.32000000000005, "text": " So those are ways of extending probability theory.", "tokens": [51270, 407, 729, 366, 2098, 295, 24360, 8482, 5261, 13, 51478], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 93, "seek": 30204, "start": 324.32000000000005, "end": 331.08000000000004, "text": " And so when we think about negative probabilities", "tokens": [51478, 400, 370, 562, 321, 519, 466, 3671, 33783, 51816], "temperature": 0.0, "avg_logprob": -0.16409024556477864, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.013014337047934532}, {"id": 94, "seek": 33108, "start": 332.03999999999996, "end": 339.84, "text": " or probabilities where the non-negativity of probabilities", "tokens": [50412, 420, 33783, 689, 264, 2107, 12, 28561, 30142, 295, 33783, 50802], "temperature": 0.0, "avg_logprob": -0.1665613467876728, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0011157251428812742}, {"id": 95, "seek": 33108, "start": 339.84, "end": 343.91999999999996, "text": " is denied, we need to think about it carefully.", "tokens": [50802, 307, 17774, 11, 321, 643, 281, 519, 466, 309, 7500, 13, 51006], "temperature": 0.0, "avg_logprob": -0.1665613467876728, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0011157251428812742}, {"id": 96, "seek": 33108, "start": 343.91999999999996, "end": 346.68, "text": " And how exactly do we want to define that?", "tokens": [51006, 400, 577, 2293, 360, 321, 528, 281, 6964, 300, 30, 51144], "temperature": 0.0, "avg_logprob": -0.1665613467876728, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0011157251428812742}, {"id": 97, "seek": 33108, "start": 346.68, "end": 349.36, "text": " So what we're going to be trying to do today", "tokens": [51144, 407, 437, 321, 434, 516, 281, 312, 1382, 281, 360, 965, 51278], "temperature": 0.0, "avg_logprob": -0.1665613467876728, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0011157251428812742}, {"id": 98, "seek": 33108, "start": 349.36, "end": 352.76, "text": " is introduce a way to describe quantum systems that", "tokens": [51278, 307, 5366, 257, 636, 281, 6786, 13018, 3652, 300, 51448], "temperature": 0.0, "avg_logprob": -0.1665613467876728, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0011157251428812742}, {"id": 99, "seek": 33108, "start": 352.76, "end": 356.03999999999996, "text": " violate this non-negatives, the negativeness property,", "tokens": [51448, 37478, 341, 2107, 12, 28561, 4884, 11, 264, 2485, 267, 8477, 4707, 11, 51612], "temperature": 0.0, "avg_logprob": -0.1665613467876728, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0011157251428812742}, {"id": 100, "seek": 35604, "start": 356.04, "end": 362.56, "text": " such that we have, first, a major theoretic formalism that", "tokens": [50364, 1270, 300, 321, 362, 11, 700, 11, 257, 2563, 14308, 299, 9860, 1434, 300, 50690], "temperature": 0.0, "avg_logprob": -0.14827179908752441, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.00011411975719965994}, {"id": 101, "seek": 35604, "start": 362.56, "end": 365.20000000000005, "text": " does that, and second, that we capture", "tokens": [50690, 775, 300, 11, 293, 1150, 11, 300, 321, 7983, 50822], "temperature": 0.0, "avg_logprob": -0.14827179908752441, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.00011411975719965994}, {"id": 102, "seek": 35604, "start": 365.20000000000005, "end": 369.28000000000003, "text": " the essence of what we want to have in quantum systems", "tokens": [50822, 264, 12801, 295, 437, 321, 528, 281, 362, 294, 13018, 3652, 51026], "temperature": 0.0, "avg_logprob": -0.14827179908752441, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.00011411975719965994}, {"id": 103, "seek": 35604, "start": 369.28000000000003, "end": 373.48, "text": " and physical systems in that theory of probability.", "tokens": [51026, 293, 4001, 3652, 294, 300, 5261, 295, 8482, 13, 51236], "temperature": 0.0, "avg_logprob": -0.14827179908752441, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.00011411975719965994}, {"id": 104, "seek": 35604, "start": 373.48, "end": 378.28000000000003, "text": " So that's essentially what we want to do today.", "tokens": [51236, 407, 300, 311, 4476, 437, 321, 528, 281, 360, 965, 13, 51476], "temperature": 0.0, "avg_logprob": -0.14827179908752441, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.00011411975719965994}, {"id": 105, "seek": 35604, "start": 378.28000000000003, "end": 381.64000000000004, "text": " So let's start with contextuality.", "tokens": [51476, 407, 718, 311, 722, 365, 35526, 507, 13, 51644], "temperature": 0.0, "avg_logprob": -0.14827179908752441, "compression_ratio": 1.6686046511627908, "no_speech_prob": 0.00011411975719965994}, {"id": 106, "seek": 38164, "start": 381.64, "end": 383.44, "text": " And I'm going to have a little bit", "tokens": [50364, 400, 286, 478, 516, 281, 362, 257, 707, 857, 50454], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 107, "seek": 38164, "start": 383.44, "end": 388.0, "text": " of a weird, non-historic approach to contextuality", "tokens": [50454, 295, 257, 3657, 11, 2107, 12, 33236, 16345, 3109, 281, 35526, 507, 50682], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 108, "seek": 38164, "start": 388.0, "end": 389.76, "text": " that starts with a historic comment, which", "tokens": [50682, 300, 3719, 365, 257, 13236, 2871, 11, 597, 50770], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 109, "seek": 38164, "start": 389.76, "end": 393.08, "text": " is contextuality originated.", "tokens": [50770, 307, 35526, 507, 31129, 13, 50936], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 110, "seek": 38164, "start": 393.08, "end": 395.56, "text": " The idea of contextuality originates in language.", "tokens": [50936, 440, 1558, 295, 35526, 507, 4957, 1024, 294, 2856, 13, 51060], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 111, "seek": 38164, "start": 395.56, "end": 400.24, "text": " And it was well known in the 20th century", "tokens": [51060, 400, 309, 390, 731, 2570, 294, 264, 945, 392, 4901, 51294], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 112, "seek": 38164, "start": 400.24, "end": 403.91999999999996, "text": " in works in pragmatics, for example.", "tokens": [51294, 294, 1985, 294, 33394, 15677, 1167, 11, 337, 1365, 13, 51478], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 113, "seek": 38164, "start": 403.91999999999996, "end": 408.0, "text": " But take the sentence, marry a student near the bank,", "tokens": [51478, 583, 747, 264, 8174, 11, 9747, 257, 3107, 2651, 264, 3765, 11, 51682], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 114, "seek": 38164, "start": 408.0, "end": 408.91999999999996, "text": " observing people.", "tokens": [51682, 22107, 561, 13, 51728], "temperature": 0.0, "avg_logprob": -0.17500162606287484, "compression_ratio": 1.5911111111111111, "no_speech_prob": 0.00031012939871288836}, {"id": 115, "seek": 40892, "start": 409.92, "end": 414.12, "text": " We can understand the sentence differently,", "tokens": [50414, 492, 393, 1223, 264, 8174, 7614, 11, 50624], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 116, "seek": 40892, "start": 414.12, "end": 417.48, "text": " depending on whether it's preceded or it's followed", "tokens": [50624, 5413, 322, 1968, 309, 311, 16969, 292, 420, 309, 311, 6263, 50792], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 117, "seek": 40892, "start": 417.48, "end": 419.84000000000003, "text": " by distinct sentences.", "tokens": [50792, 538, 10644, 16579, 13, 50910], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 118, "seek": 40892, "start": 419.84000000000003, "end": 423.0, "text": " For example, take this very same sentence followed", "tokens": [50910, 1171, 1365, 11, 747, 341, 588, 912, 8174, 6263, 51068], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 119, "seek": 40892, "start": 423.0, "end": 424.76, "text": " by this statement.", "tokens": [51068, 538, 341, 5629, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 120, "seek": 40892, "start": 424.76, "end": 428.6, "text": " She paused to notice a child amuse herself", "tokens": [51156, 1240, 46860, 281, 3449, 257, 1440, 669, 438, 7530, 51348], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 121, "seek": 40892, "start": 428.6, "end": 430.48, "text": " with the fishes jumping in the river.", "tokens": [51348, 365, 264, 41734, 11233, 294, 264, 6810, 13, 51442], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 122, "seek": 40892, "start": 430.48, "end": 434.0, "text": " When we read that sentence and we read the first one", "tokens": [51442, 1133, 321, 1401, 300, 8174, 293, 321, 1401, 264, 700, 472, 51618], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 123, "seek": 40892, "start": 434.0, "end": 437.28000000000003, "text": " together of the second one about a child looking", "tokens": [51618, 1214, 295, 264, 1150, 472, 466, 257, 1440, 1237, 51782], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 124, "seek": 40892, "start": 437.28000000000003, "end": 438.90000000000003, "text": " at fishes in the river, we understand", "tokens": [51782, 412, 41734, 294, 264, 6810, 11, 321, 1223, 51863], "temperature": 0.0, "avg_logprob": -0.1702265645943436, "compression_ratio": 1.7705627705627707, "no_speech_prob": 0.00048022874398157}, {"id": 125, "seek": 43890, "start": 438.9, "end": 443.17999999999995, "text": " that bank refers to the bank of a river.", "tokens": [50364, 300, 3765, 14942, 281, 264, 3765, 295, 257, 6810, 13, 50578], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 126, "seek": 43890, "start": 443.17999999999995, "end": 445.85999999999996, "text": " But if, on the other hand, instead of this,", "tokens": [50578, 583, 498, 11, 322, 264, 661, 1011, 11, 2602, 295, 341, 11, 50712], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 127, "seek": 43890, "start": 445.85999999999996, "end": 448.73999999999995, "text": " we followed marry a student near the bank,", "tokens": [50712, 321, 6263, 9747, 257, 3107, 2651, 264, 3765, 11, 50856], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 128, "seek": 43890, "start": 448.73999999999995, "end": 451.26, "text": " with this sentence, she noticed the manager punctually", "tokens": [50856, 365, 341, 8174, 11, 750, 5694, 264, 6598, 27006, 671, 50982], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 129, "seek": 43890, "start": 451.26, "end": 454.9, "text": " leaving at noon, something that would help with the heist.", "tokens": [50982, 5012, 412, 24040, 11, 746, 300, 576, 854, 365, 264, 415, 468, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 130, "seek": 43890, "start": 454.9, "end": 457.97999999999996, "text": " We associate bank not with the bank of a river,", "tokens": [51164, 492, 14644, 3765, 406, 365, 264, 3765, 295, 257, 6810, 11, 51318], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 131, "seek": 43890, "start": 457.97999999999996, "end": 461.82, "text": " but we associate it with a financial institution,", "tokens": [51318, 457, 321, 14644, 309, 365, 257, 4669, 7818, 11, 51510], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 132, "seek": 43890, "start": 461.82, "end": 464.85999999999996, "text": " the physical manifestation of a financial institution.", "tokens": [51510, 264, 4001, 29550, 295, 257, 4669, 7818, 13, 51662], "temperature": 0.0, "avg_logprob": -0.16117979049682618, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.00031994120217859745}, {"id": 133, "seek": 46486, "start": 464.94, "end": 471.58000000000004, "text": " So in this example, the first sentence,", "tokens": [50368, 407, 294, 341, 1365, 11, 264, 700, 8174, 11, 50700], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 134, "seek": 46486, "start": 471.58000000000004, "end": 474.94, "text": " how we understand it, changes of the context", "tokens": [50700, 577, 321, 1223, 309, 11, 2962, 295, 264, 4319, 50868], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 135, "seek": 46486, "start": 474.94, "end": 480.66, "text": " when it's put together with this child looking at fishes,", "tokens": [50868, 562, 309, 311, 829, 1214, 365, 341, 1440, 1237, 412, 41734, 11, 51154], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 136, "seek": 46486, "start": 480.66, "end": 483.5, "text": " when it's put together with heist.", "tokens": [51154, 562, 309, 311, 829, 1214, 365, 415, 468, 13, 51296], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 137, "seek": 46486, "start": 483.5, "end": 485.94, "text": " So that is the sense in which linguists talk", "tokens": [51296, 407, 300, 307, 264, 2020, 294, 597, 21766, 1751, 751, 51418], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 138, "seek": 46486, "start": 485.94, "end": 488.98, "text": " about contextuality of language.", "tokens": [51418, 466, 35526, 507, 295, 2856, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 139, "seek": 46486, "start": 488.98, "end": 493.18, "text": " And we can understand contextuality of language", "tokens": [51570, 400, 321, 393, 1223, 35526, 507, 295, 2856, 51780], "temperature": 0.0, "avg_logprob": -0.1355213575725314, "compression_ratio": 1.7514450867052023, "no_speech_prob": 0.00016085337847471237}, {"id": 140, "seek": 49318, "start": 493.18, "end": 498.38, "text": " in terms of a very logic approach to language, which", "tokens": [50364, 294, 2115, 295, 257, 588, 9952, 3109, 281, 2856, 11, 597, 50624], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 141, "seek": 49318, "start": 498.38, "end": 502.3, "text": " is the truth functional approach, in which propositions", "tokens": [50624, 307, 264, 3494, 11745, 3109, 11, 294, 597, 7532, 2451, 50820], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 142, "seek": 49318, "start": 502.3, "end": 508.3, "text": " are the way in which we understand meaning of sentences.", "tokens": [50820, 366, 264, 636, 294, 597, 321, 1223, 3620, 295, 16579, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 143, "seek": 49318, "start": 508.3, "end": 512.02, "text": " So like, for example, take the two propositions, A and B,", "tokens": [51120, 407, 411, 11, 337, 1365, 11, 747, 264, 732, 7532, 2451, 11, 316, 293, 363, 11, 51306], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 144, "seek": 49318, "start": 512.02, "end": 514.66, "text": " A being marry a student near the river bank,", "tokens": [51306, 316, 885, 9747, 257, 3107, 2651, 264, 6810, 3765, 11, 51438], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 145, "seek": 49318, "start": 514.66, "end": 517.46, "text": " and B being marry a student near the building", "tokens": [51438, 293, 363, 885, 9747, 257, 3107, 2651, 264, 2390, 51578], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 146, "seek": 49318, "start": 517.46, "end": 519.86, "text": " of a financial institution.", "tokens": [51578, 295, 257, 4669, 7818, 13, 51698], "temperature": 0.0, "avg_logprob": -0.1515909108248624, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0025047946255654097}, {"id": 147, "seek": 51986, "start": 519.86, "end": 523.3000000000001, "text": " Those two sentences, they have different truth values", "tokens": [50364, 3950, 732, 16579, 11, 436, 362, 819, 3494, 4190, 50536], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 148, "seek": 51986, "start": 523.3000000000001, "end": 524.34, "text": " depending on the context.", "tokens": [50536, 5413, 322, 264, 4319, 13, 50588], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 149, "seek": 51986, "start": 524.34, "end": 527.54, "text": " In the context of river, A is true and B is false,", "tokens": [50588, 682, 264, 4319, 295, 6810, 11, 316, 307, 2074, 293, 363, 307, 7908, 11, 50748], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 150, "seek": 51986, "start": 527.54, "end": 531.82, "text": " whereas in the context of heist, A is false and B is true.", "tokens": [50748, 9735, 294, 264, 4319, 295, 415, 468, 11, 316, 307, 7908, 293, 363, 307, 2074, 13, 50962], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 151, "seek": 51986, "start": 531.82, "end": 536.98, "text": " So it's in this sense of truth values", "tokens": [50962, 407, 309, 311, 294, 341, 2020, 295, 3494, 4190, 51220], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 152, "seek": 51986, "start": 536.98, "end": 539.14, "text": " that we can understand contextuality", "tokens": [51220, 300, 321, 393, 1223, 35526, 507, 51328], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 153, "seek": 51986, "start": 539.14, "end": 543.98, "text": " and actually even relates contextuality in language", "tokens": [51328, 293, 767, 754, 16155, 35526, 507, 294, 2856, 51570], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 154, "seek": 51986, "start": 543.98, "end": 546.66, "text": " to contextuality in quantum mechanics", "tokens": [51570, 281, 35526, 507, 294, 13018, 12939, 51704], "temperature": 0.0, "avg_logprob": -0.12214673220456301, "compression_ratio": 1.8061224489795917, "no_speech_prob": 0.004751667380332947}, {"id": 155, "seek": 54666, "start": 546.66, "end": 550.02, "text": " via random variables.", "tokens": [50364, 5766, 4974, 9102, 13, 50532], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 156, "seek": 54666, "start": 550.02, "end": 552.66, "text": " So let's look at how contextuality in this case", "tokens": [50532, 407, 718, 311, 574, 412, 577, 35526, 507, 294, 341, 1389, 50664], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 157, "seek": 54666, "start": 552.66, "end": 555.38, "text": " will show up in terms of random variables.", "tokens": [50664, 486, 855, 493, 294, 2115, 295, 4974, 9102, 13, 50800], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 158, "seek": 54666, "start": 555.38, "end": 559.02, "text": " So we can think about those statements A and B", "tokens": [50800, 407, 321, 393, 519, 466, 729, 12363, 316, 293, 363, 50982], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 159, "seek": 54666, "start": 559.02, "end": 562.86, "text": " as being modeled by random variables A and B.", "tokens": [50982, 382, 885, 37140, 538, 4974, 9102, 316, 293, 363, 13, 51174], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 160, "seek": 54666, "start": 562.86, "end": 564.8199999999999, "text": " I'm going to represent them in both face here", "tokens": [51174, 286, 478, 516, 281, 2906, 552, 294, 1293, 1851, 510, 51272], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 161, "seek": 54666, "start": 564.8199999999999, "end": 567.02, "text": " just to distinguish between the statements A and B,", "tokens": [51272, 445, 281, 20206, 1296, 264, 12363, 316, 293, 363, 11, 51382], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 162, "seek": 54666, "start": 567.02, "end": 572.42, "text": " the propositions A and B. And these random variables A and B", "tokens": [51382, 264, 7532, 2451, 316, 293, 363, 13, 400, 613, 4974, 9102, 316, 293, 363, 51652], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 163, "seek": 54666, "start": 572.42, "end": 576.26, "text": " modeled it by being dichotomous random variables", "tokens": [51652, 37140, 309, 538, 885, 10390, 42939, 563, 4974, 9102, 51844], "temperature": 0.0, "avg_logprob": -0.14701591919515736, "compression_ratio": 1.912037037037037, "no_speech_prob": 0.003943488001823425}, {"id": 164, "seek": 57626, "start": 576.3, "end": 578.98, "text": " with values plus and minus one.", "tokens": [50366, 365, 4190, 1804, 293, 3175, 472, 13, 50500], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 165, "seek": 57626, "start": 578.98, "end": 581.1, "text": " With minus one, for example, corresponding", "tokens": [50500, 2022, 3175, 472, 11, 337, 1365, 11, 11760, 50606], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 166, "seek": 57626, "start": 581.1, "end": 584.3, "text": " to the statement being false and plus one corresponding", "tokens": [50606, 281, 264, 5629, 885, 7908, 293, 1804, 472, 11760, 50766], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 167, "seek": 57626, "start": 584.3, "end": 585.74, "text": " to the statement being true.", "tokens": [50766, 281, 264, 5629, 885, 2074, 13, 50838], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 168, "seek": 57626, "start": 585.74, "end": 588.5, "text": " It's kind of like silly to think about random variables", "tokens": [50838, 467, 311, 733, 295, 411, 11774, 281, 519, 466, 4974, 9102, 50976], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 169, "seek": 57626, "start": 588.5, "end": 593.5, "text": " for this particular example because they are not,", "tokens": [50976, 337, 341, 1729, 1365, 570, 436, 366, 406, 11, 51226], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 170, "seek": 57626, "start": 596.9399999999999, "end": 598.58, "text": " they're deterministic random variables", "tokens": [51398, 436, 434, 15957, 3142, 4974, 9102, 51480], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 171, "seek": 57626, "start": 598.58, "end": 601.18, "text": " because once a statement is true,", "tokens": [51480, 570, 1564, 257, 5629, 307, 2074, 11, 51610], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 172, "seek": 57626, "start": 601.18, "end": 604.22, "text": " A is always going to be one, right?", "tokens": [51610, 316, 307, 1009, 516, 281, 312, 472, 11, 558, 30, 51762], "temperature": 0.0, "avg_logprob": -0.22817587083385837, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.004397866781800985}, {"id": 173, "seek": 60422, "start": 604.22, "end": 608.1, "text": " And if B is false, B is always going to be minus one.", "tokens": [50364, 400, 498, 363, 307, 7908, 11, 363, 307, 1009, 516, 281, 312, 3175, 472, 13, 50558], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 174, "seek": 60422, "start": 608.1, "end": 609.62, "text": " So it's kind of silly to think about", "tokens": [50558, 407, 309, 311, 733, 295, 11774, 281, 519, 466, 50634], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 175, "seek": 60422, "start": 609.62, "end": 610.5400000000001, "text": " in terms of random variables,", "tokens": [50634, 294, 2115, 295, 4974, 9102, 11, 50680], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 176, "seek": 60422, "start": 610.5400000000001, "end": 613.5, "text": " but there's nothing that forbids us from doing that.", "tokens": [50680, 457, 456, 311, 1825, 300, 16603, 3742, 505, 490, 884, 300, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 177, "seek": 60422, "start": 613.5, "end": 617.0600000000001, "text": " And contextuality here means that there is no single", "tokens": [50828, 400, 35526, 507, 510, 1355, 300, 456, 307, 572, 2167, 51006], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 178, "seek": 60422, "start": 617.0600000000001, "end": 621.7, "text": " random variable A and B that represents those concepts", "tokens": [51006, 4974, 7006, 316, 293, 363, 300, 8855, 729, 10392, 51238], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 179, "seek": 60422, "start": 621.7, "end": 624.3000000000001, "text": " A and B in different contexts,", "tokens": [51238, 316, 293, 363, 294, 819, 30628, 11, 51368], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 180, "seek": 60422, "start": 625.62, "end": 628.0600000000001, "text": " or represent those truth values in different contexts.", "tokens": [51434, 420, 2906, 729, 3494, 4190, 294, 819, 30628, 13, 51556], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 181, "seek": 60422, "start": 628.0600000000001, "end": 630.6600000000001, "text": " The reason is that a random variable is defined", "tokens": [51556, 440, 1778, 307, 300, 257, 4974, 7006, 307, 7642, 51686], "temperature": 0.0, "avg_logprob": -0.1390081171719533, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.0006262175156734884}, {"id": 182, "seek": 63066, "start": 630.66, "end": 634.18, "text": " within a probability space.", "tokens": [50364, 1951, 257, 8482, 1901, 13, 50540], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 183, "seek": 63066, "start": 634.18, "end": 637.5799999999999, "text": " And the probabilities, they cannot represent", "tokens": [50540, 400, 264, 33783, 11, 436, 2644, 2906, 50710], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 184, "seek": 63066, "start": 637.5799999999999, "end": 640.38, "text": " both A and B simultaneously.", "tokens": [50710, 1293, 316, 293, 363, 16561, 13, 50850], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 185, "seek": 63066, "start": 640.38, "end": 645.38, "text": " So this is the contextuality that comes in linguistics.", "tokens": [50850, 407, 341, 307, 264, 35526, 507, 300, 1487, 294, 21766, 6006, 13, 51100], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 186, "seek": 63066, "start": 646.3399999999999, "end": 651.3399999999999, "text": " It's, we can call this as a direct influence", "tokens": [51148, 467, 311, 11, 321, 393, 818, 341, 382, 257, 2047, 6503, 51398], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 187, "seek": 63066, "start": 651.3399999999999, "end": 654.14, "text": " of the context on the random variables", "tokens": [51398, 295, 264, 4319, 322, 264, 4974, 9102, 51538], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 188, "seek": 63066, "start": 654.14, "end": 657.62, "text": " because the expectations of the random variables", "tokens": [51538, 570, 264, 9843, 295, 264, 4974, 9102, 51712], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 189, "seek": 63066, "start": 657.62, "end": 659.5, "text": " change directly with the context.", "tokens": [51712, 1319, 3838, 365, 264, 4319, 13, 51806], "temperature": 0.0, "avg_logprob": -0.16570859015742434, "compression_ratio": 1.653061224489796, "no_speech_prob": 0.00031997638870961964}, {"id": 190, "seek": 65950, "start": 659.5, "end": 662.26, "text": " In one context, the expectation of A is one,", "tokens": [50364, 682, 472, 4319, 11, 264, 14334, 295, 316, 307, 472, 11, 50502], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 191, "seek": 65950, "start": 662.26, "end": 666.38, "text": " in another context, the expectation of A is minus one.", "tokens": [50502, 294, 1071, 4319, 11, 264, 14334, 295, 316, 307, 3175, 472, 13, 50708], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 192, "seek": 65950, "start": 666.38, "end": 668.86, "text": " So the expectation changes the context.", "tokens": [50708, 407, 264, 14334, 2962, 264, 4319, 13, 50832], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 193, "seek": 65950, "start": 668.86, "end": 672.26, "text": " This is not what happens in physics", "tokens": [50832, 639, 307, 406, 437, 2314, 294, 10649, 51002], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 194, "seek": 65950, "start": 672.26, "end": 675.38, "text": " because this type of contextuality", "tokens": [51002, 570, 341, 2010, 295, 35526, 507, 51158], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 195, "seek": 65950, "start": 675.38, "end": 678.02, "text": " would violate the signaling condition,", "tokens": [51158, 576, 37478, 264, 38639, 4188, 11, 51290], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 196, "seek": 65950, "start": 678.02, "end": 681.1, "text": " but that's a way of representing the linguistic type", "tokens": [51290, 457, 300, 311, 257, 636, 295, 13460, 264, 43002, 2010, 51444], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 197, "seek": 65950, "start": 681.1, "end": 683.86, "text": " of contextuality in terms of random variables.", "tokens": [51444, 295, 35526, 507, 294, 2115, 295, 4974, 9102, 13, 51582], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 198, "seek": 65950, "start": 683.86, "end": 687.66, "text": " But once we have that idea of contextuality as changing", "tokens": [51582, 583, 1564, 321, 362, 300, 1558, 295, 35526, 507, 382, 4473, 51772], "temperature": 0.0, "avg_logprob": -0.12828258552936592, "compression_ratio": 1.8837209302325582, "no_speech_prob": 0.00018811013433150947}, {"id": 199, "seek": 68766, "start": 687.66, "end": 690.2199999999999, "text": " the expectations of random variables", "tokens": [50364, 264, 9843, 295, 4974, 9102, 50492], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 200, "seek": 68766, "start": 691.26, "end": 696.06, "text": " in, with respect to the context,", "tokens": [50544, 294, 11, 365, 3104, 281, 264, 4319, 11, 50784], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 201, "seek": 68766, "start": 696.06, "end": 698.02, "text": " we kind of like have a clue of how is it", "tokens": [50784, 321, 733, 295, 411, 362, 257, 13602, 295, 577, 307, 309, 50882], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 202, "seek": 68766, "start": 698.02, "end": 699.62, "text": " that we can extend that to things", "tokens": [50882, 300, 321, 393, 10101, 300, 281, 721, 50962], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 203, "seek": 68766, "start": 699.62, "end": 701.38, "text": " that might be more relevant to physics.", "tokens": [50962, 300, 1062, 312, 544, 7340, 281, 10649, 13, 51050], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 204, "seek": 68766, "start": 701.38, "end": 705.18, "text": " So let's take a more subtle case, right?", "tokens": [51050, 407, 718, 311, 747, 257, 544, 13743, 1389, 11, 558, 30, 51240], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 205, "seek": 68766, "start": 705.18, "end": 710.18, "text": " Let's take three, that column was random variables x, y, and z.", "tokens": [51240, 961, 311, 747, 1045, 11, 300, 7738, 390, 4974, 9102, 2031, 11, 288, 11, 293, 710, 13, 51490], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 206, "seek": 68766, "start": 711.6999999999999, "end": 713.9599999999999, "text": " So plus or minus one random variables.", "tokens": [51566, 407, 1804, 420, 3175, 472, 4974, 9102, 13, 51679], "temperature": 0.0, "avg_logprob": -0.21566153085359963, "compression_ratio": 1.6482412060301508, "no_speech_prob": 0.00028238887898623943}, {"id": 207, "seek": 71396, "start": 714.96, "end": 717.76, "text": " And let's just assume that their expectation is zero.", "tokens": [50414, 400, 718, 311, 445, 6552, 300, 641, 14334, 307, 4018, 13, 50554], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 208, "seek": 71396, "start": 717.76, "end": 721.24, "text": " So we don't know, it's kind of like tossing a coin", "tokens": [50554, 407, 321, 500, 380, 458, 11, 309, 311, 733, 295, 411, 14432, 278, 257, 11464, 50728], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 209, "seek": 71396, "start": 721.24, "end": 722.4000000000001, "text": " for x, y, and z.", "tokens": [50728, 337, 2031, 11, 288, 11, 293, 710, 13, 50786], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 210, "seek": 71396, "start": 722.4000000000001, "end": 725.08, "text": " We don't know whether it's true or false", "tokens": [50786, 492, 500, 380, 458, 1968, 309, 311, 2074, 420, 7908, 50920], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 211, "seek": 71396, "start": 725.08, "end": 727.96, "text": " every time that we observe it,", "tokens": [50920, 633, 565, 300, 321, 11441, 309, 11, 51064], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 212, "seek": 71396, "start": 727.96, "end": 731.96, "text": " but they're perfectly correlated among themselves.", "tokens": [51064, 457, 436, 434, 6239, 38574, 3654, 2969, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 213, "seek": 71396, "start": 731.96, "end": 736.96, "text": " So x is perfectly anti-correlated with y,", "tokens": [51264, 407, 2031, 307, 6239, 6061, 12, 19558, 12004, 365, 288, 11, 51514], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 214, "seek": 71396, "start": 736.96, "end": 739.24, "text": " x is perfectly anti-correlated with z,", "tokens": [51514, 2031, 307, 6239, 6061, 12, 19558, 12004, 365, 710, 11, 51628], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 215, "seek": 71396, "start": 739.24, "end": 742.84, "text": " and perfectly anti-correlated with z and y.", "tokens": [51628, 293, 6239, 6061, 12, 19558, 12004, 365, 710, 293, 288, 13, 51808], "temperature": 0.0, "avg_logprob": -0.10376143240713859, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0002694613649509847}, {"id": 216, "seek": 74284, "start": 742.9200000000001, "end": 745.2800000000001, "text": " Z and y are perfectly anti-correlated.", "tokens": [50368, 1176, 293, 288, 366, 6239, 6061, 12, 19558, 12004, 13, 50486], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 217, "seek": 74284, "start": 745.2800000000001, "end": 747.44, "text": " And it's a very straightforward to see that", "tokens": [50486, 400, 309, 311, 257, 588, 15325, 281, 536, 300, 50594], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 218, "seek": 74284, "start": 747.44, "end": 752.0400000000001, "text": " if we have such cases where x, y, x, z, and y, z", "tokens": [50594, 498, 321, 362, 1270, 3331, 689, 2031, 11, 288, 11, 2031, 11, 710, 11, 293, 288, 11, 710, 50824], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 219, "seek": 74284, "start": 752.0400000000001, "end": 755.6, "text": " are anti-correlated, that there is something funky going on.", "tokens": [50824, 366, 6061, 12, 19558, 12004, 11, 300, 456, 307, 746, 33499, 516, 322, 13, 51002], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 220, "seek": 74284, "start": 755.6, "end": 758.8000000000001, "text": " And the way to see there is something funky going on", "tokens": [51002, 400, 264, 636, 281, 536, 456, 307, 746, 33499, 516, 322, 51162], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 221, "seek": 74284, "start": 758.8000000000001, "end": 762.2800000000001, "text": " is just to notice that, for example, if x equals one,", "tokens": [51162, 307, 445, 281, 3449, 300, 11, 337, 1365, 11, 498, 2031, 6915, 472, 11, 51336], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 222, "seek": 74284, "start": 762.2800000000001, "end": 765.4, "text": " this guy here implies that y equals minus one.", "tokens": [51336, 341, 2146, 510, 18779, 300, 288, 6915, 3175, 472, 13, 51492], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 223, "seek": 74284, "start": 765.4, "end": 767.6, "text": " And if x equals one, this guy here implies", "tokens": [51492, 400, 498, 2031, 6915, 472, 11, 341, 2146, 510, 18779, 51602], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 224, "seek": 74284, "start": 767.6, "end": 769.0400000000001, "text": " that z equals minus one.", "tokens": [51602, 300, 710, 6915, 3175, 472, 13, 51674], "temperature": 0.0, "avg_logprob": -0.13808882041055648, "compression_ratio": 2.0097087378640777, "no_speech_prob": 0.0008558453992009163}, {"id": 225, "seek": 76904, "start": 770.04, "end": 773.0, "text": " But minus one times minus one is one.", "tokens": [50414, 583, 3175, 472, 1413, 3175, 472, 307, 472, 13, 50562], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 226, "seek": 76904, "start": 775.04, "end": 780.04, "text": " However, this guy here tells us that y times z is minus one,", "tokens": [50664, 2908, 11, 341, 2146, 510, 5112, 505, 300, 288, 1413, 710, 307, 3175, 472, 11, 50914], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 227, "seek": 76904, "start": 780.4, "end": 782.0799999999999, "text": " which is a contradiction.", "tokens": [50932, 597, 307, 257, 34937, 13, 51016], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 228, "seek": 76904, "start": 782.0799999999999, "end": 784.7199999999999, "text": " So there is something wrong going on.", "tokens": [51016, 407, 456, 307, 746, 2085, 516, 322, 13, 51148], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 229, "seek": 76904, "start": 784.7199999999999, "end": 789.28, "text": " And what is wrong is that when we're using this reasoning", "tokens": [51148, 400, 437, 307, 2085, 307, 300, 562, 321, 434, 1228, 341, 21577, 51376], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 230, "seek": 76904, "start": 789.28, "end": 794.28, "text": " of x being implying y equals minus one here", "tokens": [51376, 295, 2031, 885, 704, 7310, 288, 6915, 3175, 472, 510, 51626], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 231, "seek": 76904, "start": 794.48, "end": 796.88, "text": " in this first equation, and then we're using it", "tokens": [51636, 294, 341, 700, 5367, 11, 293, 550, 321, 434, 1228, 309, 51756], "temperature": 0.0, "avg_logprob": -0.10174362049546352, "compression_ratio": 1.7049180327868851, "no_speech_prob": 0.00030534088728018105}, {"id": 232, "seek": 79688, "start": 796.88, "end": 799.64, "text": " as implying z here in this second equation,", "tokens": [50364, 382, 704, 7310, 710, 510, 294, 341, 1150, 5367, 11, 50502], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 233, "seek": 79688, "start": 799.64, "end": 801.88, "text": " and then using to get the multiplication", "tokens": [50502, 293, 550, 1228, 281, 483, 264, 27290, 50614], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 234, "seek": 79688, "start": 801.88, "end": 803.64, "text": " in the third equation, we're assuming", "tokens": [50614, 294, 264, 2636, 5367, 11, 321, 434, 11926, 50702], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 235, "seek": 79688, "start": 803.64, "end": 807.28, "text": " that all three random variables are defined together.", "tokens": [50702, 300, 439, 1045, 4974, 9102, 366, 7642, 1214, 13, 50884], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 236, "seek": 79688, "start": 807.28, "end": 809.2, "text": " That means that we're assuming there's a joint", "tokens": [50884, 663, 1355, 300, 321, 434, 11926, 456, 311, 257, 7225, 50980], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 237, "seek": 79688, "start": 809.2, "end": 810.52, "text": " probability distribution.", "tokens": [50980, 8482, 7316, 13, 51046], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 238, "seek": 79688, "start": 811.84, "end": 813.72, "text": " But it doesn't exist.", "tokens": [51112, 583, 309, 1177, 380, 2514, 13, 51206], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 239, "seek": 79688, "start": 813.72, "end": 817.2, "text": " Assuming that x in the context of y is the same", "tokens": [51206, 6281, 24919, 300, 2031, 294, 264, 4319, 295, 288, 307, 264, 912, 51380], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 240, "seek": 79688, "start": 817.2, "end": 819.56, "text": " as x in the context of z is what's leading", "tokens": [51380, 382, 2031, 294, 264, 4319, 295, 710, 307, 437, 311, 5775, 51498], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 241, "seek": 79688, "start": 819.56, "end": 822.28, "text": " as your contradiction, assuming that all three of them", "tokens": [51498, 382, 428, 34937, 11, 11926, 300, 439, 1045, 295, 552, 51634], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 242, "seek": 79688, "start": 822.28, "end": 824.32, "text": " are observable at the same time", "tokens": [51634, 366, 9951, 712, 412, 264, 912, 565, 51736], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 243, "seek": 79688, "start": 824.32, "end": 825.8, "text": " is leading as your contradictions.", "tokens": [51736, 307, 5775, 382, 428, 15858, 15607, 13, 51810], "temperature": 0.0, "avg_logprob": -0.13645877535381015, "compression_ratio": 1.959514170040486, "no_speech_prob": 0.003706578863784671}, {"id": 244, "seek": 82580, "start": 825.8399999999999, "end": 828.4, "text": " And we know that this happens in quantum mechanics,", "tokens": [50366, 400, 321, 458, 300, 341, 2314, 294, 13018, 12939, 11, 50494], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 245, "seek": 82580, "start": 828.4, "end": 831.8, "text": " that there are things that we cannot absorb at the same time.", "tokens": [50494, 300, 456, 366, 721, 300, 321, 2644, 15631, 412, 264, 912, 565, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 246, "seek": 82580, "start": 831.8, "end": 834.5999999999999, "text": " So can we see something like that in quantum mechanics?", "tokens": [50664, 407, 393, 321, 536, 746, 411, 300, 294, 13018, 12939, 30, 50804], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 247, "seek": 82580, "start": 834.5999999999999, "end": 836.3599999999999, "text": " And the answer is yes.", "tokens": [50804, 400, 264, 1867, 307, 2086, 13, 50892], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 248, "seek": 82580, "start": 836.3599999999999, "end": 840.3199999999999, "text": " A very famous example is the GHZ states.", "tokens": [50892, 316, 588, 4618, 1365, 307, 264, 40690, 57, 4368, 13, 51090], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 249, "seek": 82580, "start": 840.3199999999999, "end": 844.04, "text": " We have three particles, one, two, and three,", "tokens": [51090, 492, 362, 1045, 10007, 11, 472, 11, 732, 11, 293, 1045, 11, 51276], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 250, "seek": 82580, "start": 844.04, "end": 848.88, "text": " that are in an entangled state where either all three", "tokens": [51276, 300, 366, 294, 364, 948, 39101, 1785, 689, 2139, 439, 1045, 51518], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 251, "seek": 82580, "start": 848.88, "end": 852.3599999999999, "text": " of them have spin in the direction z being plus,", "tokens": [51518, 295, 552, 362, 6060, 294, 264, 3513, 710, 885, 1804, 11, 51692], "temperature": 0.0, "avg_logprob": -0.12301698385500441, "compression_ratio": 1.6536796536796536, "no_speech_prob": 0.0004372719849925488}, {"id": 252, "seek": 85236, "start": 852.36, "end": 856.24, "text": " or all three of them have spin in the direction z being minus,", "tokens": [50364, 420, 439, 1045, 295, 552, 362, 6060, 294, 264, 3513, 710, 885, 3175, 11, 50558], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 253, "seek": 85236, "start": 856.24, "end": 859.28, "text": " and then we have a superposition of those two states.", "tokens": [50558, 293, 550, 321, 362, 257, 1687, 38078, 295, 729, 732, 4368, 13, 50710], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 254, "seek": 85236, "start": 859.28, "end": 861.6800000000001, "text": " And then it's easy to see that these guys", "tokens": [50710, 400, 550, 309, 311, 1858, 281, 536, 300, 613, 1074, 50830], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 255, "seek": 85236, "start": 861.6800000000001, "end": 865.6800000000001, "text": " have the following eigenstates.", "tokens": [50830, 362, 264, 3480, 10446, 372, 1024, 13, 51030], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 256, "seek": 85236, "start": 865.6800000000001, "end": 868.28, "text": " For example, if we measure spin of particle one", "tokens": [51030, 1171, 1365, 11, 498, 321, 3481, 6060, 295, 12359, 472, 51160], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 257, "seek": 85236, "start": 868.28, "end": 871.04, "text": " in the direction x, measure spin in the particle two", "tokens": [51160, 294, 264, 3513, 2031, 11, 3481, 6060, 294, 264, 12359, 732, 51298], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 258, "seek": 85236, "start": 871.04, "end": 874.24, "text": " in the direction y, and three in the direction y,", "tokens": [51298, 294, 264, 3513, 288, 11, 293, 1045, 294, 264, 3513, 288, 11, 51458], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 259, "seek": 85236, "start": 874.24, "end": 877.36, "text": " the product of those three spins is always gonna be one.", "tokens": [51458, 264, 1674, 295, 729, 1045, 31587, 307, 1009, 799, 312, 472, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 260, "seek": 85236, "start": 878.52, "end": 881.04, "text": " In the other hand, if we measure y, x, y,", "tokens": [51672, 682, 264, 661, 1011, 11, 498, 321, 3481, 288, 11, 2031, 11, 288, 11, 51798], "temperature": 0.0, "avg_logprob": -0.12346480322665855, "compression_ratio": 1.9383259911894273, "no_speech_prob": 0.002286863513290882}, {"id": 261, "seek": 88104, "start": 881.04, "end": 884.12, "text": " it's also gonna be one, y, y, x is also one,", "tokens": [50364, 309, 311, 611, 799, 312, 472, 11, 288, 11, 288, 11, 2031, 307, 611, 472, 11, 50518], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 262, "seek": 88104, "start": 884.12, "end": 887.0, "text": " but x, x, x is minus one.", "tokens": [50518, 457, 2031, 11, 2031, 11, 2031, 307, 3175, 472, 13, 50662], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 263, "seek": 88104, "start": 888.3199999999999, "end": 893.3199999999999, "text": " So we can try to look at it in terms of random variables.", "tokens": [50728, 407, 321, 393, 853, 281, 574, 412, 309, 294, 2115, 295, 4974, 9102, 13, 50978], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 264, "seek": 88104, "start": 894.36, "end": 896.4399999999999, "text": " Let's say we have an x-random variable", "tokens": [51030, 961, 311, 584, 321, 362, 364, 2031, 12, 3699, 298, 7006, 51134], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 265, "seek": 88104, "start": 896.4399999999999, "end": 899.5999999999999, "text": " for spin in the direction x, a y-random variable", "tokens": [51134, 337, 6060, 294, 264, 3513, 2031, 11, 257, 288, 12, 3699, 298, 7006, 51292], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 266, "seek": 88104, "start": 899.5999999999999, "end": 901.4399999999999, "text": " for spin in the direction y,", "tokens": [51292, 337, 6060, 294, 264, 3513, 288, 11, 51384], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 267, "seek": 88104, "start": 901.4399999999999, "end": 905.0, "text": " and then we assume them to be context independent.", "tokens": [51384, 293, 550, 321, 6552, 552, 281, 312, 4319, 6695, 13, 51562], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 268, "seek": 88104, "start": 905.0, "end": 909.0799999999999, "text": " And if we do that, we can multiply this guy here,", "tokens": [51562, 400, 498, 321, 360, 300, 11, 321, 393, 12972, 341, 2146, 510, 11, 51766], "temperature": 0.0, "avg_logprob": -0.11709063393729073, "compression_ratio": 1.7563451776649746, "no_speech_prob": 0.0005883834091946483}, {"id": 269, "seek": 90908, "start": 909.08, "end": 912.2, "text": " the random variables corresponding to this spin,", "tokens": [50364, 264, 4974, 9102, 11760, 281, 341, 6060, 11, 50520], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 270, "seek": 90908, "start": 912.2, "end": 917.2, "text": " x, y, y, times the spin y, x, y, times y, y, x,", "tokens": [50520, 2031, 11, 288, 11, 288, 11, 1413, 264, 6060, 288, 11, 2031, 11, 288, 11, 1413, 288, 11, 288, 11, 2031, 11, 50770], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 271, "seek": 90908, "start": 918.32, "end": 922.2800000000001, "text": " and each one of those guys in parentheses are equal to one.", "tokens": [50826, 293, 1184, 472, 295, 729, 1074, 294, 34153, 366, 2681, 281, 472, 13, 51024], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 272, "seek": 90908, "start": 922.2800000000001, "end": 925.36, "text": " And when we multiply them, we can now collect", "tokens": [51024, 400, 562, 321, 12972, 552, 11, 321, 393, 586, 2500, 51178], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 273, "seek": 90908, "start": 925.36, "end": 928.48, "text": " all the y's together and all the x's together,", "tokens": [51178, 439, 264, 288, 311, 1214, 293, 439, 264, 2031, 311, 1214, 11, 51334], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 274, "seek": 90908, "start": 928.48, "end": 930.4000000000001, "text": " and the square of something that's closer", "tokens": [51334, 293, 264, 3732, 295, 746, 300, 311, 4966, 51430], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 275, "seek": 90908, "start": 930.4000000000001, "end": 933.1600000000001, "text": " minus one is always one.", "tokens": [51430, 3175, 472, 307, 1009, 472, 13, 51568], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 276, "seek": 90908, "start": 933.1600000000001, "end": 936.7, "text": " And when we do that, this guy here's one,", "tokens": [51568, 400, 562, 321, 360, 300, 11, 341, 2146, 510, 311, 472, 11, 51745], "temperature": 0.0, "avg_logprob": -0.13239531560775336, "compression_ratio": 1.7211538461538463, "no_speech_prob": 0.0008040557149797678}, {"id": 277, "seek": 93670, "start": 936.7, "end": 940.7800000000001, "text": " and we get a contradiction that one is equal to minus one", "tokens": [50364, 293, 321, 483, 257, 34937, 300, 472, 307, 2681, 281, 3175, 472, 50568], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 278, "seek": 93670, "start": 940.7800000000001, "end": 944.96, "text": " from this quantum mechanical computation.", "tokens": [50568, 490, 341, 13018, 12070, 24903, 13, 50777], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 279, "seek": 93670, "start": 944.96, "end": 946.34, "text": " Of course, it's not a contradiction", "tokens": [50777, 2720, 1164, 11, 309, 311, 406, 257, 34937, 50846], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 280, "seek": 93670, "start": 946.34, "end": 949.46, "text": " because what we're getting as contradiction", "tokens": [50846, 570, 437, 321, 434, 1242, 382, 34937, 51002], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 281, "seek": 93670, "start": 949.46, "end": 954.46, "text": " is based on the assumption that the y in the context of x", "tokens": [51002, 307, 2361, 322, 264, 15302, 300, 264, 288, 294, 264, 4319, 295, 2031, 51252], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 282, "seek": 93670, "start": 954.9000000000001, "end": 958.74, "text": " and y, y two in the context of x one and y three", "tokens": [51274, 293, 288, 11, 288, 732, 294, 264, 4319, 295, 2031, 472, 293, 288, 1045, 51466], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 283, "seek": 93670, "start": 958.74, "end": 963.22, "text": " is the same as the y two in the context of y one and x three.", "tokens": [51466, 307, 264, 912, 382, 264, 288, 732, 294, 264, 4319, 295, 288, 472, 293, 2031, 1045, 13, 51690], "temperature": 0.0, "avg_logprob": -0.12352213295557166, "compression_ratio": 1.9333333333333333, "no_speech_prob": 0.0002611696836538613}, {"id": 284, "seek": 96322, "start": 963.22, "end": 964.0600000000001, "text": " So in other words,", "tokens": [50364, 407, 294, 661, 2283, 11, 50406], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 285, "seek": 96322, "start": 964.0600000000001, "end": 966.58, "text": " we're assuming a joint probability distribution.", "tokens": [50406, 321, 434, 11926, 257, 7225, 8482, 7316, 13, 50532], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 286, "seek": 96322, "start": 968.5, "end": 973.5, "text": " So when we have a set of random variables", "tokens": [50628, 407, 562, 321, 362, 257, 992, 295, 4974, 9102, 50878], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 287, "seek": 96322, "start": 977.9, "end": 980.34, "text": " that are contextual,", "tokens": [51098, 300, 366, 35526, 11, 51220], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 288, "seek": 96322, "start": 980.34, "end": 982.34, "text": " there is no joint probability distribution", "tokens": [51220, 456, 307, 572, 7225, 8482, 7316, 51320], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 289, "seek": 96322, "start": 982.34, "end": 983.46, "text": " for all the variables.", "tokens": [51320, 337, 439, 264, 9102, 13, 51376], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 290, "seek": 96322, "start": 983.46, "end": 986.0, "text": " There is, of course, a joint probability distribution", "tokens": [51376, 821, 307, 11, 295, 1164, 11, 257, 7225, 8482, 7316, 51503], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 291, "seek": 96322, "start": 986.0, "end": 988.1800000000001, "text": " for each one of those contexts,", "tokens": [51503, 337, 1184, 472, 295, 729, 30628, 11, 51612], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 292, "seek": 96322, "start": 988.1800000000001, "end": 990.94, "text": " but when you put all those six random variables together,", "tokens": [51612, 457, 562, 291, 829, 439, 729, 2309, 4974, 9102, 1214, 11, 51750], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 293, "seek": 96322, "start": 990.94, "end": 992.4200000000001, "text": " there is no joint probability distribution.", "tokens": [51750, 456, 307, 572, 7225, 8482, 7316, 13, 51824], "temperature": 0.0, "avg_logprob": -0.14162569857658225, "compression_ratio": 2.10989010989011, "no_speech_prob": 0.0004238348046783358}, {"id": 294, "seek": 99242, "start": 992.42, "end": 995.2199999999999, "text": " There's no single probability space,", "tokens": [50364, 821, 311, 572, 2167, 8482, 1901, 11, 50504], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 295, "seek": 99242, "start": 996.14, "end": 1001.14, "text": " omega fp such that the random variables xi and yi", "tokens": [50550, 10498, 283, 79, 1270, 300, 264, 4974, 9102, 36800, 293, 288, 72, 50800], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 296, "seek": 99242, "start": 1001.6999999999999, "end": 1003.5799999999999, "text": " models all the quantum outcomes.", "tokens": [50828, 5245, 439, 264, 13018, 10070, 13, 50922], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 297, "seek": 99242, "start": 1003.5799999999999, "end": 1008.5799999999999, "text": " That's not possible in standard probability theory.", "tokens": [50922, 663, 311, 406, 1944, 294, 3832, 8482, 5261, 13, 51172], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 298, "seek": 99242, "start": 1014.06, "end": 1016.18, "text": " Of course, we know that the quantum formalism", "tokens": [51446, 2720, 1164, 11, 321, 458, 300, 264, 13018, 9860, 1434, 51552], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 299, "seek": 99242, "start": 1016.18, "end": 1017.9399999999999, "text": " provides an answer.", "tokens": [51552, 6417, 364, 1867, 13, 51640], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 300, "seek": 99242, "start": 1017.9399999999999, "end": 1021.5, "text": " We can use the quantum formalism as we shown here", "tokens": [51640, 492, 393, 764, 264, 13018, 9860, 1434, 382, 321, 4898, 510, 51818], "temperature": 0.0, "avg_logprob": -0.25629615783691406, "compression_ratio": 1.5683060109289617, "no_speech_prob": 0.00029121970874257386}, {"id": 301, "seek": 102150, "start": 1021.54, "end": 1025.26, "text": " to compute the expectations of actual observables", "tokens": [50366, 281, 14722, 264, 9843, 295, 3539, 9951, 2965, 50552], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 302, "seek": 102150, "start": 1025.26, "end": 1026.94, "text": " that we can measure together,", "tokens": [50552, 300, 321, 393, 3481, 1214, 11, 50636], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 303, "seek": 102150, "start": 1028.22, "end": 1030.34, "text": " but are there alternatives to quantum model?", "tokens": [50700, 457, 366, 456, 20478, 281, 13018, 2316, 30, 50806], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 304, "seek": 102150, "start": 1030.34, "end": 1032.74, "text": " And more importantly,", "tokens": [50806, 400, 544, 8906, 11, 50926], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 305, "seek": 102150, "start": 1032.74, "end": 1037.18, "text": " are there alternatives to the quantum model useful for us", "tokens": [50926, 366, 456, 20478, 281, 264, 13018, 2316, 4420, 337, 505, 51148], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 306, "seek": 102150, "start": 1037.18, "end": 1041.26, "text": " to think about what's going on with the quantum case?", "tokens": [51148, 281, 519, 466, 437, 311, 516, 322, 365, 264, 13018, 1389, 30, 51352], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 307, "seek": 102150, "start": 1042.18, "end": 1044.86, "text": " We don't know whether those alternatives are useful,", "tokens": [51398, 492, 500, 380, 458, 1968, 729, 20478, 366, 4420, 11, 51532], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 308, "seek": 102150, "start": 1044.86, "end": 1048.06, "text": " but we feel that perhaps understanding them better", "tokens": [51532, 457, 321, 841, 300, 4317, 3701, 552, 1101, 51692], "temperature": 0.0, "avg_logprob": -0.1494274480002267, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.0017231757519766688}, {"id": 309, "seek": 104806, "start": 1048.06, "end": 1052.1799999999998, "text": " might be a way to at least understand", "tokens": [50364, 1062, 312, 257, 636, 281, 412, 1935, 1223, 50570], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 310, "seek": 104806, "start": 1052.1799999999998, "end": 1055.1399999999999, "text": " what is it that they can bring to this discussion", "tokens": [50570, 437, 307, 309, 300, 436, 393, 1565, 281, 341, 5017, 50718], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 311, "seek": 104806, "start": 1055.1399999999999, "end": 1057.62, "text": " of what the quantum model or quantum,", "tokens": [50718, 295, 437, 264, 13018, 2316, 420, 13018, 11, 50842], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 312, "seek": 104806, "start": 1057.62, "end": 1060.22, "text": " of what the hub or space formula is telling us.", "tokens": [50842, 295, 437, 264, 11838, 420, 1901, 8513, 307, 3585, 505, 13, 50972], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 313, "seek": 104806, "start": 1060.22, "end": 1062.3799999999999, "text": " So the alternatives that have been tried,", "tokens": [50972, 407, 264, 20478, 300, 362, 668, 3031, 11, 51080], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 314, "seek": 104806, "start": 1062.3799999999999, "end": 1064.62, "text": " as I mentioned, are upper and lower probabilities,", "tokens": [51080, 382, 286, 2835, 11, 366, 6597, 293, 3126, 33783, 11, 51192], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 315, "seek": 104806, "start": 1064.62, "end": 1066.86, "text": " and of course, there are negative probabilities", "tokens": [51192, 293, 295, 1164, 11, 456, 366, 3671, 33783, 51304], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 316, "seek": 104806, "start": 1066.86, "end": 1069.82, "text": " that we wanna expand more today.", "tokens": [51304, 300, 321, 1948, 5268, 544, 965, 13, 51452], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 317, "seek": 104806, "start": 1070.78, "end": 1074.6, "text": " So let's go into defining negative probabilities.", "tokens": [51500, 407, 718, 311, 352, 666, 17827, 3671, 33783, 13, 51691], "temperature": 0.0, "avg_logprob": -0.2180127124397122, "compression_ratio": 1.7412280701754386, "no_speech_prob": 0.0001823317725211382}, {"id": 318, "seek": 107806, "start": 1079.06, "end": 1082.26, "text": " To understand how we define negative probabilities,", "tokens": [50414, 1407, 1223, 577, 321, 6964, 3671, 33783, 11, 50574], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 319, "seek": 107806, "start": 1082.26, "end": 1086.5, "text": " it's useful to see how we define standard probability theory.", "tokens": [50574, 309, 311, 4420, 281, 536, 577, 321, 6964, 3832, 8482, 5261, 13, 50786], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 320, "seek": 107806, "start": 1086.5, "end": 1087.34, "text": " Right?", "tokens": [50786, 1779, 30, 50828], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 321, "seek": 107806, "start": 1087.34, "end": 1090.02, "text": " So the most accepted definition", "tokens": [50828, 407, 264, 881, 9035, 7123, 50962], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 322, "seek": 107806, "start": 1090.02, "end": 1093.5, "text": " of standard probability theory is by Komagorov.", "tokens": [50962, 295, 3832, 8482, 5261, 307, 538, 14286, 559, 284, 5179, 13, 51136], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 323, "seek": 107806, "start": 1093.5, "end": 1096.54, "text": " He gave a set theoretic definition", "tokens": [51136, 634, 2729, 257, 992, 14308, 299, 7123, 51288], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 324, "seek": 107806, "start": 1096.54, "end": 1099.86, "text": " of classic probability theory as being the triplets,", "tokens": [51288, 295, 7230, 8482, 5261, 382, 885, 264, 1376, 31023, 11, 51454], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 325, "seek": 107806, "start": 1099.86, "end": 1104.86, "text": " omega Fp, where omega is a sample space that you have.", "tokens": [51454, 10498, 479, 79, 11, 689, 10498, 307, 257, 6889, 1901, 300, 291, 362, 13, 51704], "temperature": 0.0, "avg_logprob": -0.24817686302717343, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0002492115891072899}, {"id": 326, "seek": 110806, "start": 1108.26, "end": 1113.26, "text": " F is an algebra over that sample space omega", "tokens": [50374, 479, 307, 364, 21989, 670, 300, 6889, 1901, 10498, 50624], "temperature": 0.0, "avg_logprob": -0.16765203610272475, "compression_ratio": 1.6385542168674698, "no_speech_prob": 0.0010483262594789267}, {"id": 327, "seek": 110806, "start": 1114.22, "end": 1119.22, "text": " that is actually a sigma algebra, a countable algebra,", "tokens": [50672, 300, 307, 767, 257, 12771, 21989, 11, 257, 1207, 712, 21989, 11, 50922], "temperature": 0.0, "avg_logprob": -0.16765203610272475, "compression_ratio": 1.6385542168674698, "no_speech_prob": 0.0010483262594789267}, {"id": 328, "seek": 110806, "start": 1121.3, "end": 1125.6599999999999, "text": " and P is a function that takes elements of this algebra", "tokens": [51026, 293, 430, 307, 257, 2445, 300, 2516, 4959, 295, 341, 21989, 51244], "temperature": 0.0, "avg_logprob": -0.16765203610272475, "compression_ratio": 1.6385542168674698, "no_speech_prob": 0.0010483262594789267}, {"id": 329, "seek": 110806, "start": 1125.6599999999999, "end": 1128.74, "text": " to this interval zero and one.", "tokens": [51244, 281, 341, 15035, 4018, 293, 472, 13, 51398], "temperature": 0.0, "avg_logprob": -0.16765203610272475, "compression_ratio": 1.6385542168674698, "no_speech_prob": 0.0010483262594789267}, {"id": 330, "seek": 110806, "start": 1128.74, "end": 1131.4199999999998, "text": " And the restrictions that we have for P", "tokens": [51398, 400, 264, 14191, 300, 321, 362, 337, 430, 51532], "temperature": 0.0, "avg_logprob": -0.16765203610272475, "compression_ratio": 1.6385542168674698, "no_speech_prob": 0.0010483262594789267}, {"id": 331, "seek": 110806, "start": 1131.4199999999998, "end": 1135.46, "text": " is that the measure of omega or the whole set", "tokens": [51532, 307, 300, 264, 3481, 295, 10498, 420, 264, 1379, 992, 51734], "temperature": 0.0, "avg_logprob": -0.16765203610272475, "compression_ratio": 1.6385542168674698, "no_speech_prob": 0.0010483262594789267}, {"id": 332, "seek": 113546, "start": 1135.46, "end": 1138.38, "text": " of possibilities is equal to one.", "tokens": [50364, 295, 12178, 307, 2681, 281, 472, 13, 50510], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 333, "seek": 113546, "start": 1138.38, "end": 1139.7, "text": " In other words, the probability", "tokens": [50510, 682, 661, 2283, 11, 264, 8482, 50576], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 334, "seek": 113546, "start": 1139.7, "end": 1144.7, "text": " that something happens is one.", "tokens": [50576, 300, 746, 2314, 307, 472, 13, 50826], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 335, "seek": 113546, "start": 1144.7, "end": 1149.7, "text": " And the other assumption is that the additivity rule", "tokens": [50826, 400, 264, 661, 15302, 307, 300, 264, 909, 270, 4253, 4978, 51076], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 336, "seek": 113546, "start": 1152.7, "end": 1156.3, "text": " holds for this function.", "tokens": [51226, 9190, 337, 341, 2445, 13, 51406], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 337, "seek": 113546, "start": 1156.3, "end": 1158.54, "text": " In other words, for any denumerable", "tokens": [51406, 682, 661, 2283, 11, 337, 604, 1441, 15583, 712, 51518], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 338, "seek": 113546, "start": 1158.54, "end": 1162.94, "text": " and this joint family of elements of this algebra F, Ai,", "tokens": [51518, 293, 341, 7225, 1605, 295, 4959, 295, 341, 21989, 479, 11, 16993, 11, 51738], "temperature": 0.0, "avg_logprob": -0.21659217468679767, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.0006878248532302678}, {"id": 339, "seek": 116294, "start": 1163.9, "end": 1168.9, "text": " the probability of A, say A1 or A2", "tokens": [50412, 264, 8482, 295, 316, 11, 584, 316, 16, 420, 316, 17, 50662], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 340, "seek": 116294, "start": 1170.94, "end": 1174.66, "text": " is the sum of the probability of A and the probability of two.", "tokens": [50764, 307, 264, 2408, 295, 264, 8482, 295, 316, 293, 264, 8482, 295, 732, 13, 50950], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 341, "seek": 116294, "start": 1174.66, "end": 1178.26, "text": " So that's something that's a requirement", "tokens": [50950, 407, 300, 311, 746, 300, 311, 257, 11695, 51130], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 342, "seek": 116294, "start": 1178.26, "end": 1180.38, "text": " of probability theory.", "tokens": [51130, 295, 8482, 5261, 13, 51236], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 343, "seek": 116294, "start": 1180.38, "end": 1184.8200000000002, "text": " And because this is a number between zero and one,", "tokens": [51236, 400, 570, 341, 307, 257, 1230, 1296, 4018, 293, 472, 11, 51458], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 344, "seek": 116294, "start": 1184.8200000000002, "end": 1186.5, "text": " this probability is monotonic.", "tokens": [51458, 341, 8482, 307, 1108, 310, 11630, 13, 51542], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 345, "seek": 116294, "start": 1186.5, "end": 1191.5, "text": " So if you have a set A, the probability of adding something", "tokens": [51542, 407, 498, 291, 362, 257, 992, 316, 11, 264, 8482, 295, 5127, 746, 51792], "temperature": 0.0, "avg_logprob": -0.15730972517104375, "compression_ratio": 1.81437125748503, "no_speech_prob": 0.000379953533411026}, {"id": 346, "seek": 119150, "start": 1191.5, "end": 1194.54, "text": " more to that set A, that's this joint of A,", "tokens": [50364, 544, 281, 300, 992, 316, 11, 300, 311, 341, 7225, 295, 316, 11, 50516], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 347, "seek": 119150, "start": 1194.54, "end": 1198.5, "text": " increases the probability of absorbing that event.", "tokens": [50516, 8637, 264, 8482, 295, 38720, 300, 2280, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 348, "seek": 119150, "start": 1198.5, "end": 1200.78, "text": " So if you add more possibilities,", "tokens": [50714, 407, 498, 291, 909, 544, 12178, 11, 50828], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 349, "seek": 119150, "start": 1200.78, "end": 1202.58, "text": " this becomes more probable.", "tokens": [50828, 341, 3643, 544, 21759, 13, 50918], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 350, "seek": 119150, "start": 1202.58, "end": 1207.58, "text": " And in quantum mechanics, this is not quite the case.", "tokens": [50918, 400, 294, 13018, 12939, 11, 341, 307, 406, 1596, 264, 1389, 13, 51168], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 351, "seek": 119150, "start": 1207.94, "end": 1211.1, "text": " It's non-monotonic, but this is something", "tokens": [51186, 467, 311, 2107, 12, 3317, 310, 11630, 11, 457, 341, 307, 746, 51344], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 352, "seek": 119150, "start": 1211.1, "end": 1214.02, "text": " that I'm not gonna talk too much about.", "tokens": [51344, 300, 286, 478, 406, 799, 751, 886, 709, 466, 13, 51490], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 353, "seek": 119150, "start": 1214.02, "end": 1216.06, "text": " So how do we get negative probabilities?", "tokens": [51490, 407, 577, 360, 321, 483, 3671, 33783, 30, 51592], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 354, "seek": 119150, "start": 1216.06, "end": 1219.42, "text": " We might be tempted to just violate this requirement", "tokens": [51592, 492, 1062, 312, 29941, 281, 445, 37478, 341, 11695, 51760], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 355, "seek": 119150, "start": 1219.42, "end": 1221.42, "text": " and we're done with it.", "tokens": [51760, 293, 321, 434, 1096, 365, 309, 13, 51860], "temperature": 0.0, "avg_logprob": -0.11204157466382052, "compression_ratio": 1.626984126984127, "no_speech_prob": 0.00019108942069578916}, {"id": 356, "seek": 122142, "start": 1221.42, "end": 1224.3000000000002, "text": " But the problem is that there are certain constraints", "tokens": [50364, 583, 264, 1154, 307, 300, 456, 366, 1629, 18491, 50508], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 357, "seek": 122142, "start": 1224.3000000000002, "end": 1225.7, "text": " about negative probabilities", "tokens": [50508, 466, 3671, 33783, 50578], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 358, "seek": 122142, "start": 1225.7, "end": 1229.6200000000001, "text": " that at least seem to make sense,", "tokens": [50578, 300, 412, 1935, 1643, 281, 652, 2020, 11, 50774], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 359, "seek": 122142, "start": 1229.6200000000001, "end": 1232.98, "text": " which is that first and foremost,", "tokens": [50774, 597, 307, 300, 700, 293, 18864, 11, 50942], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 360, "seek": 122142, "start": 1232.98, "end": 1235.5, "text": " we never directly observe a negative probability.", "tokens": [50942, 321, 1128, 3838, 11441, 257, 3671, 8482, 13, 51068], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 361, "seek": 122142, "start": 1235.5, "end": 1237.3000000000002, "text": " What the heck does it mean to even observe", "tokens": [51068, 708, 264, 12872, 775, 309, 914, 281, 754, 11441, 51158], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 362, "seek": 122142, "start": 1237.3000000000002, "end": 1238.54, "text": " a negative probability?", "tokens": [51158, 257, 3671, 8482, 30, 51220], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 363, "seek": 122142, "start": 1240.5, "end": 1242.74, "text": " So we need to understand how exactly", "tokens": [51318, 407, 321, 643, 281, 1223, 577, 2293, 51430], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 364, "seek": 122142, "start": 1242.74, "end": 1245.1000000000001, "text": " does the negative probability show", "tokens": [51430, 775, 264, 3671, 8482, 855, 51548], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 365, "seek": 122142, "start": 1245.1000000000001, "end": 1248.42, "text": " in terms of directly observable quantities.", "tokens": [51548, 294, 2115, 295, 3838, 9951, 712, 22927, 13, 51714], "temperature": 0.0, "avg_logprob": -0.14089559978908964, "compression_ratio": 1.8682926829268294, "no_speech_prob": 4.069239003001712e-05}, {"id": 366, "seek": 124842, "start": 1248.54, "end": 1252.1000000000001, "text": " And observables are not parts of komagorov stock.", "tokens": [50370, 400, 9951, 2965, 366, 406, 3166, 295, 5207, 559, 284, 5179, 4127, 13, 50548], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 367, "seek": 124842, "start": 1252.1000000000001, "end": 1253.9, "text": " So we need to include that.", "tokens": [50548, 407, 321, 643, 281, 4090, 300, 13, 50638], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 368, "seek": 124842, "start": 1253.9, "end": 1257.46, "text": " And furthermore, there's no connection", "tokens": [50638, 400, 3052, 3138, 11, 456, 311, 572, 4984, 50816], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 369, "seek": 124842, "start": 1257.46, "end": 1262.22, "text": " if we just like relax this requirement", "tokens": [50816, 498, 321, 445, 411, 5789, 341, 11695, 51054], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 370, "seek": 124842, "start": 1262.22, "end": 1267.22, "text": " that ties the marginals to the empirical observable contexts.", "tokens": [51054, 300, 14039, 264, 10270, 1124, 281, 264, 31886, 9951, 712, 30628, 13, 51304], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 371, "seek": 124842, "start": 1267.22, "end": 1270.7, "text": " So what we're gonna do here is just try to show", "tokens": [51304, 407, 437, 321, 434, 799, 360, 510, 307, 445, 853, 281, 855, 51478], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 372, "seek": 124842, "start": 1270.7, "end": 1272.3400000000001, "text": " how we can define negative probabilities", "tokens": [51478, 577, 321, 393, 6964, 3671, 33783, 51560], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 373, "seek": 124842, "start": 1272.3400000000001, "end": 1273.38, "text": " with those ideas in mind.", "tokens": [51560, 365, 729, 3487, 294, 1575, 13, 51612], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 374, "seek": 124842, "start": 1273.38, "end": 1276.8600000000001, "text": " So that's our major theoretic definition", "tokens": [51612, 407, 300, 311, 527, 2563, 14308, 299, 7123, 51786], "temperature": 0.0, "avg_logprob": -0.18466616158533578, "compression_ratio": 1.5805084745762712, "no_speech_prob": 0.000273704034043476}, {"id": 375, "seek": 127686, "start": 1276.86, "end": 1278.3, "text": " of negative probabilities.", "tokens": [50364, 295, 3671, 33783, 13, 50436], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 376, "seek": 127686, "start": 1280.58, "end": 1285.3799999999999, "text": " It's gonna be a little bit abstract from now on,", "tokens": [50550, 467, 311, 799, 312, 257, 707, 857, 12649, 490, 586, 322, 11, 50790], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 377, "seek": 127686, "start": 1285.3799999999999, "end": 1288.02, "text": " but I'm gonna try to give the main ideas", "tokens": [50790, 457, 286, 478, 799, 853, 281, 976, 264, 2135, 3487, 50922], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 378, "seek": 127686, "start": 1288.02, "end": 1291.3, "text": " of what is the outlining of this definition, right?", "tokens": [50922, 295, 437, 307, 264, 484, 31079, 295, 341, 7123, 11, 558, 30, 51086], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 379, "seek": 127686, "start": 1291.3, "end": 1295.9799999999998, "text": " We start with a sample space, not a sample space.", "tokens": [51086, 492, 722, 365, 257, 6889, 1901, 11, 406, 257, 6889, 1901, 13, 51320], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 380, "seek": 127686, "start": 1295.9799999999998, "end": 1299.9399999999998, "text": " We start with the concept of assigned measure.", "tokens": [51320, 492, 722, 365, 264, 3410, 295, 13279, 3481, 13, 51518], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 381, "seek": 127686, "start": 1299.9399999999998, "end": 1304.58, "text": " So assigned measure is exactly the same as a measure,", "tokens": [51518, 407, 13279, 3481, 307, 2293, 264, 912, 382, 257, 3481, 11, 51750], "temperature": 0.0, "avg_logprob": -0.15749973474546922, "compression_ratio": 1.6443298969072164, "no_speech_prob": 0.0004305011825636029}, {"id": 382, "seek": 130458, "start": 1304.62, "end": 1307.6999999999998, "text": " except that instead of having a measure", "tokens": [50366, 3993, 300, 2602, 295, 1419, 257, 3481, 50520], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 383, "seek": 130458, "start": 1307.6999999999998, "end": 1311.46, "text": " going from a sigma algebra to the set", "tokens": [50520, 516, 490, 257, 12771, 21989, 281, 264, 992, 50708], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 384, "seek": 130458, "start": 1311.46, "end": 1313.98, "text": " of non-negative real numbers,", "tokens": [50708, 295, 2107, 12, 28561, 1166, 957, 3547, 11, 50834], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 385, "seek": 130458, "start": 1313.98, "end": 1318.06, "text": " assigned measure is something that takes the sets", "tokens": [50834, 13279, 3481, 307, 746, 300, 2516, 264, 6352, 51038], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 386, "seek": 130458, "start": 1318.06, "end": 1323.06, "text": " of elements of the algebra into any real number,", "tokens": [51038, 295, 4959, 295, 264, 21989, 666, 604, 957, 1230, 11, 51288], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 387, "seek": 130458, "start": 1324.1799999999998, "end": 1325.74, "text": " including negative numbers.", "tokens": [51344, 3009, 3671, 3547, 13, 51422], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 388, "seek": 130458, "start": 1326.4199999999998, "end": 1330.02, "text": " And this is well known in measure theory.", "tokens": [51456, 400, 341, 307, 731, 2570, 294, 3481, 5261, 13, 51636], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 389, "seek": 130458, "start": 1330.02, "end": 1333.74, "text": " So it's something that has been studied extensively.", "tokens": [51636, 407, 309, 311, 746, 300, 575, 668, 9454, 32636, 13, 51822], "temperature": 0.0, "avg_logprob": -0.17917370214694883, "compression_ratio": 1.6958762886597938, "no_speech_prob": 0.0005439856322482228}, {"id": 390, "seek": 133374, "start": 1333.74, "end": 1337.6200000000001, "text": " And essentially, if we restrict the assigned measure", "tokens": [50364, 400, 4476, 11, 498, 321, 7694, 264, 13279, 3481, 50558], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 391, "seek": 133374, "start": 1337.6200000000001, "end": 1340.82, "text": " to non-negative numbers, we get a regular measure.", "tokens": [50558, 281, 2107, 12, 28561, 1166, 3547, 11, 321, 483, 257, 3890, 3481, 13, 50718], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 392, "seek": 133374, "start": 1340.82, "end": 1342.78, "text": " And if we restrict this measure", "tokens": [50718, 400, 498, 321, 7694, 341, 3481, 50816], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 393, "seek": 133374, "start": 1342.78, "end": 1347.78, "text": " such that mu of omega for this measure is equal to one,", "tokens": [50816, 1270, 300, 2992, 295, 10498, 337, 341, 3481, 307, 2681, 281, 472, 11, 51066], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 394, "seek": 133374, "start": 1351.06, "end": 1352.98, "text": " we get probabilities.", "tokens": [51230, 321, 483, 33783, 13, 51326], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 395, "seek": 133374, "start": 1352.98, "end": 1356.9, "text": " So that's the starting point.", "tokens": [51326, 407, 300, 311, 264, 2891, 935, 13, 51522], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 396, "seek": 133374, "start": 1356.9, "end": 1359.22, "text": " We start with assigned measure space", "tokens": [51522, 492, 722, 365, 13279, 3481, 1901, 51638], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 397, "seek": 133374, "start": 1359.22, "end": 1363.66, "text": " that has the additivity rule as part of it.", "tokens": [51638, 300, 575, 264, 909, 270, 4253, 4978, 382, 644, 295, 309, 13, 51860], "temperature": 0.0, "avg_logprob": -0.14525434103879062, "compression_ratio": 1.7052631578947368, "no_speech_prob": 3.7635421904269606e-05}, {"id": 398, "seek": 136366, "start": 1363.66, "end": 1367.3400000000001, "text": " And then once we have this assigned measure space,", "tokens": [50364, 400, 550, 1564, 321, 362, 341, 13279, 3481, 1901, 11, 50548], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 399, "seek": 136366, "start": 1367.3400000000001, "end": 1369.18, "text": " we need to find a way to connect it", "tokens": [50548, 321, 643, 281, 915, 257, 636, 281, 1745, 309, 50640], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 400, "seek": 136366, "start": 1369.18, "end": 1373.0600000000002, "text": " to the actual observations that we have.", "tokens": [50640, 281, 264, 3539, 18163, 300, 321, 362, 13, 50834], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 401, "seek": 136366, "start": 1373.0600000000002, "end": 1377.9, "text": " And the starting point is to create an object", "tokens": [50834, 400, 264, 2891, 935, 307, 281, 1884, 364, 2657, 51076], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 402, "seek": 136366, "start": 1377.9, "end": 1380.26, "text": " that's not quite a random variable,", "tokens": [51076, 300, 311, 406, 1596, 257, 4974, 7006, 11, 51194], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 403, "seek": 136366, "start": 1380.26, "end": 1382.6200000000001, "text": " but it's what we call an extended random variable", "tokens": [51194, 457, 309, 311, 437, 321, 818, 364, 10913, 4974, 7006, 51312], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 404, "seek": 136366, "start": 1382.6200000000001, "end": 1386.26, "text": " because instead of being defined over a probability space,", "tokens": [51312, 570, 2602, 295, 885, 7642, 670, 257, 8482, 1901, 11, 51494], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 405, "seek": 136366, "start": 1386.26, "end": 1391.26, "text": " we're defining it into assigned measure space.", "tokens": [51494, 321, 434, 17827, 309, 666, 13279, 3481, 1901, 13, 51744], "temperature": 0.0, "avg_logprob": -0.12034863692063552, "compression_ratio": 1.7298578199052133, "no_speech_prob": 0.00015111223910935223}, {"id": 406, "seek": 139126, "start": 1392.14, "end": 1396.18, "text": " And the idea is just that if the assigned measure space", "tokens": [50408, 400, 264, 1558, 307, 445, 300, 498, 264, 13279, 3481, 1901, 50610], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 407, "seek": 139126, "start": 1396.18, "end": 1397.74, "text": " then becomes a probability space,", "tokens": [50610, 550, 3643, 257, 8482, 1901, 11, 50688], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 408, "seek": 139126, "start": 1397.74, "end": 1400.42, "text": " those random variables become regular random variables.", "tokens": [50688, 729, 4974, 9102, 1813, 3890, 4974, 9102, 13, 50822], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 409, "seek": 139126, "start": 1401.3799999999999, "end": 1404.78, "text": " And the definition is just the standard definition", "tokens": [50870, 400, 264, 7123, 307, 445, 264, 3832, 7123, 51040], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 410, "seek": 139126, "start": 1404.78, "end": 1407.3, "text": " of random variable where you have a function", "tokens": [51040, 295, 4974, 7006, 689, 291, 362, 257, 2445, 51166], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 411, "seek": 139126, "start": 1407.3, "end": 1409.18, "text": " that goes from your sample space", "tokens": [51166, 300, 1709, 490, 428, 6889, 1901, 51260], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 412, "seek": 139126, "start": 1409.18, "end": 1414.18, "text": " to some real number M that's parts of a sets.", "tokens": [51260, 281, 512, 957, 1230, 376, 300, 311, 3166, 295, 257, 6352, 13, 51510], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 413, "seek": 139126, "start": 1416.22, "end": 1419.14, "text": " This should be this M here, something wrong here.", "tokens": [51612, 639, 820, 312, 341, 376, 510, 11, 746, 2085, 510, 13, 51758], "temperature": 0.0, "avg_logprob": -0.18079765276475387, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.000588390335906297}, {"id": 414, "seek": 141914, "start": 1419.26, "end": 1421.9, "text": " Anyway, and such that this function", "tokens": [50370, 5684, 11, 293, 1270, 300, 341, 2445, 50502], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 415, "seek": 141914, "start": 1421.9, "end": 1424.1000000000001, "text": " is a measurable function in the sense", "tokens": [50502, 307, 257, 43615, 2445, 294, 264, 2020, 50612], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 416, "seek": 141914, "start": 1424.1000000000001, "end": 1425.7800000000002, "text": " of this measure that we have.", "tokens": [50612, 295, 341, 3481, 300, 321, 362, 13, 50696], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 417, "seek": 141914, "start": 1425.7800000000002, "end": 1428.9, "text": " It's a measure induced definition.", "tokens": [50696, 467, 311, 257, 3481, 33991, 7123, 13, 50852], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 418, "seek": 141914, "start": 1429.9, "end": 1433.22, "text": " And then from this, we can kind of like start", "tokens": [50902, 400, 550, 490, 341, 11, 321, 393, 733, 295, 411, 722, 51068], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 419, "seek": 141914, "start": 1433.22, "end": 1437.0200000000002, "text": " to narrow down the idea of contexts.", "tokens": [51068, 281, 9432, 760, 264, 1558, 295, 30628, 13, 51258], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 420, "seek": 141914, "start": 1437.0200000000002, "end": 1439.6200000000001, "text": " And contexts are just proper subsets", "tokens": [51258, 400, 30628, 366, 445, 2296, 2090, 1385, 51388], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 421, "seek": 141914, "start": 1439.6200000000001, "end": 1441.3000000000002, "text": " of those random variables,", "tokens": [51388, 295, 729, 4974, 9102, 11, 51472], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 422, "seek": 141914, "start": 1441.3000000000002, "end": 1445.22, "text": " such that there is a sub sigma algebra", "tokens": [51472, 1270, 300, 456, 307, 257, 1422, 12771, 21989, 51668], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 423, "seek": 141914, "start": 1445.22, "end": 1448.5, "text": " for each one of those subsets of the random variables.", "tokens": [51668, 337, 1184, 472, 295, 729, 2090, 1385, 295, 264, 4974, 9102, 13, 51832], "temperature": 0.0, "avg_logprob": -0.16826824188232423, "compression_ratio": 1.7793427230046948, "no_speech_prob": 0.00023780428455211222}, {"id": 424, "seek": 144914, "start": 1449.22, "end": 1454.22, "text": " That define a probability space", "tokens": [50368, 663, 6964, 257, 8482, 1901, 50618], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 425, "seek": 144914, "start": 1456.1000000000001, "end": 1458.5400000000002, "text": " for those random variables there.", "tokens": [50712, 337, 729, 4974, 9102, 456, 13, 50834], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 426, "seek": 144914, "start": 1458.5400000000002, "end": 1460.7800000000002, "text": " So intuitively we'll have this bunch", "tokens": [50834, 407, 46506, 321, 603, 362, 341, 3840, 50946], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 427, "seek": 144914, "start": 1460.7800000000002, "end": 1463.3000000000002, "text": " of extended random variables.", "tokens": [50946, 295, 10913, 4974, 9102, 13, 51072], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 428, "seek": 144914, "start": 1463.3000000000002, "end": 1464.94, "text": " And we have this measure space", "tokens": [51072, 400, 321, 362, 341, 3481, 1901, 51154], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 429, "seek": 144914, "start": 1464.94, "end": 1467.14, "text": " describing those extended random variables.", "tokens": [51154, 16141, 729, 10913, 4974, 9102, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 430, "seek": 144914, "start": 1467.14, "end": 1469.74, "text": " But then we get a subspace of that.", "tokens": [51264, 583, 550, 321, 483, 257, 2090, 17940, 295, 300, 13, 51394], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 431, "seek": 144914, "start": 1469.74, "end": 1474.14, "text": " And this subspace has a measure space associated to it", "tokens": [51394, 400, 341, 2090, 17940, 575, 257, 3481, 1901, 6615, 281, 309, 51614], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 432, "seek": 144914, "start": 1474.14, "end": 1477.38, "text": " such that we actually have proper random variables", "tokens": [51614, 1270, 300, 321, 767, 362, 2296, 4974, 9102, 51776], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 433, "seek": 144914, "start": 1477.38, "end": 1478.6200000000001, "text": " in this subspace.", "tokens": [51776, 294, 341, 2090, 17940, 13, 51838], "temperature": 0.0, "avg_logprob": -0.12238395478990342, "compression_ratio": 1.882051282051282, "no_speech_prob": 0.0003353334323037416}, {"id": 434, "seek": 147914, "start": 1479.98, "end": 1484.98, "text": " And this allows us to talk now", "tokens": [50406, 400, 341, 4045, 505, 281, 751, 586, 50656], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 435, "seek": 147914, "start": 1486.66, "end": 1489.74, "text": " about families of signed probabilistic models", "tokens": [50740, 466, 4466, 295, 8175, 31959, 3142, 5245, 50894], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 436, "seek": 147914, "start": 1489.74, "end": 1494.38, "text": " that have just those contexts defined for those families", "tokens": [50894, 300, 362, 445, 729, 30628, 7642, 337, 729, 4466, 51126], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 437, "seek": 147914, "start": 1494.38, "end": 1496.74, "text": " and then measures in this context.", "tokens": [51126, 293, 550, 8000, 294, 341, 4319, 13, 51244], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 438, "seek": 147914, "start": 1496.74, "end": 1499.8200000000002, "text": " I'm gonna skip a little bit faster in this.", "tokens": [51244, 286, 478, 799, 10023, 257, 707, 857, 4663, 294, 341, 13, 51398], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 439, "seek": 147914, "start": 1501.46, "end": 1503.7800000000002, "text": " And then once we do that,", "tokens": [51480, 400, 550, 1564, 321, 360, 300, 11, 51596], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 440, "seek": 147914, "start": 1503.7800000000002, "end": 1508.7, "text": " we can find a concept of a general context", "tokens": [51596, 321, 393, 915, 257, 3410, 295, 257, 2674, 4319, 51842], "temperature": 0.0, "avg_logprob": -0.15490703060202402, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.0002065882581518963}, {"id": 441, "seek": 150870, "start": 1508.7, "end": 1512.46, "text": " that just has like the same idea of the broader one.", "tokens": [50364, 300, 445, 575, 411, 264, 912, 1558, 295, 264, 13227, 472, 13, 50552], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 442, "seek": 150870, "start": 1512.46, "end": 1516.82, "text": " But now we're saying that those are just for those guys", "tokens": [50552, 583, 586, 321, 434, 1566, 300, 729, 366, 445, 337, 729, 1074, 50770], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 443, "seek": 150870, "start": 1516.82, "end": 1521.6200000000001, "text": " that look like probabilities in the subspace.", "tokens": [50770, 300, 574, 411, 33783, 294, 264, 2090, 17940, 13, 51010], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 444, "seek": 150870, "start": 1523.5, "end": 1528.5, "text": " So finally, we have like those families", "tokens": [51104, 407, 2721, 11, 321, 362, 411, 729, 4466, 51354], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 445, "seek": 150870, "start": 1529.98, "end": 1532.46, "text": " of signed probability models.", "tokens": [51428, 295, 8175, 8482, 5245, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 446, "seek": 150870, "start": 1532.46, "end": 1534.5, "text": " And those families of signed probability models,", "tokens": [51552, 400, 729, 4466, 295, 8175, 8482, 5245, 11, 51654], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 447, "seek": 150870, "start": 1534.5, "end": 1537.74, "text": " what you have are those like functions", "tokens": [51654, 437, 291, 362, 366, 729, 411, 6828, 51816], "temperature": 0.0, "avg_logprob": -0.1408711594420594, "compression_ratio": 1.782857142857143, "no_speech_prob": 8.887029980542138e-05}, {"id": 448, "seek": 153774, "start": 1537.74, "end": 1539.9, "text": " that reproduce all the expectations", "tokens": [50364, 300, 29501, 439, 264, 9843, 50472], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 449, "seek": 153774, "start": 1539.9, "end": 1542.64, "text": " that you have on the contexts.", "tokens": [50472, 300, 291, 362, 322, 264, 30628, 13, 50609], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 450, "seek": 153774, "start": 1542.64, "end": 1546.5, "text": " But it's kind of like the wild west here", "tokens": [50609, 583, 309, 311, 733, 295, 411, 264, 4868, 7009, 510, 50802], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 451, "seek": 153774, "start": 1546.5, "end": 1549.86, "text": " because they can be as large or as small as you want.", "tokens": [50802, 570, 436, 393, 312, 382, 2416, 420, 382, 1359, 382, 291, 528, 13, 50970], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 452, "seek": 153774, "start": 1549.86, "end": 1553.7, "text": " And what we need to do then is tame a little bit", "tokens": [50970, 400, 437, 321, 643, 281, 360, 550, 307, 45774, 257, 707, 857, 51162], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 453, "seek": 153774, "start": 1553.7, "end": 1555.9, "text": " those set of functions by saying,", "tokens": [51162, 729, 992, 295, 6828, 538, 1566, 11, 51272], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 454, "seek": 153774, "start": 1555.9, "end": 1560.9, "text": " look, if we now take the sum of all the probabilities,", "tokens": [51272, 574, 11, 498, 321, 586, 747, 264, 2408, 295, 439, 264, 33783, 11, 51522], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 455, "seek": 153774, "start": 1560.94, "end": 1564.18, "text": " the extended probabilities that we have", "tokens": [51524, 264, 10913, 33783, 300, 321, 362, 51686], "temperature": 0.0, "avg_logprob": -0.13786245702387212, "compression_ratio": 1.6142857142857143, "no_speech_prob": 0.00068772112717852}, {"id": 456, "seek": 156418, "start": 1564.18, "end": 1569.18, "text": " over the sample space for each one of those elements", "tokens": [50364, 670, 264, 6889, 1901, 337, 1184, 472, 295, 729, 4959, 50614], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 457, "seek": 156418, "start": 1569.98, "end": 1575.02, "text": " of this signed probability spaces, we get a value.", "tokens": [50654, 295, 341, 8175, 8482, 7673, 11, 321, 483, 257, 2158, 13, 50906], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 458, "seek": 156418, "start": 1575.02, "end": 1579.66, "text": " And what we want are the smallest possible values possible", "tokens": [50906, 400, 437, 321, 528, 366, 264, 16998, 1944, 4190, 1944, 51138], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 459, "seek": 156418, "start": 1579.66, "end": 1580.98, "text": " because when that happens,", "tokens": [51138, 570, 562, 300, 2314, 11, 51204], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 460, "seek": 156418, "start": 1580.98, "end": 1583.6200000000001, "text": " we're as close as we can be", "tokens": [51204, 321, 434, 382, 1998, 382, 321, 393, 312, 51336], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 461, "seek": 156418, "start": 1583.6200000000001, "end": 1585.8600000000001, "text": " to a proper probability distribution.", "tokens": [51336, 281, 257, 2296, 8482, 7316, 13, 51448], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 462, "seek": 156418, "start": 1585.8600000000001, "end": 1590.22, "text": " In fact, this is gonna come up in a theorem later on.", "tokens": [51448, 682, 1186, 11, 341, 307, 799, 808, 493, 294, 257, 20904, 1780, 322, 13, 51666], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 463, "seek": 156418, "start": 1590.22, "end": 1591.3, "text": " And when we do that,", "tokens": [51666, 400, 562, 321, 360, 300, 11, 51720], "temperature": 0.0, "avg_logprob": -0.1459853540767323, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.0013669501058757305}, {"id": 464, "seek": 159130, "start": 1591.3, "end": 1594.6599999999999, "text": " when we ask for the minimum value of the sum,", "tokens": [50364, 562, 321, 1029, 337, 264, 7285, 2158, 295, 264, 2408, 11, 50532], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 465, "seek": 159130, "start": 1595.58, "end": 1599.34, "text": " then we call that a negative probability space.", "tokens": [50578, 550, 321, 818, 300, 257, 3671, 8482, 1901, 13, 50766], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 466, "seek": 159130, "start": 1599.34, "end": 1603.3799999999999, "text": " It's when this minimum is obtained.", "tokens": [50766, 467, 311, 562, 341, 7285, 307, 14879, 13, 50968], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 467, "seek": 159130, "start": 1605.02, "end": 1608.1599999999999, "text": " If we do that, then we have the following theorem.", "tokens": [51050, 759, 321, 360, 300, 11, 550, 321, 362, 264, 3480, 20904, 13, 51207], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 468, "seek": 159130, "start": 1609.3, "end": 1612.02, "text": " Imagine that you have now this guy", "tokens": [51264, 11739, 300, 291, 362, 586, 341, 2146, 51400], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 469, "seek": 159130, "start": 1612.02, "end": 1614.62, "text": " as a minimum signed probability space", "tokens": [51400, 382, 257, 7285, 8175, 8482, 1901, 51530], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 470, "seek": 159130, "start": 1614.62, "end": 1616.6599999999999, "text": " or as a negative probability space.", "tokens": [51530, 420, 382, 257, 3671, 8482, 1901, 13, 51632], "temperature": 0.0, "avg_logprob": -0.14682793617248535, "compression_ratio": 1.795031055900621, "no_speech_prob": 0.00044416484888643026}, {"id": 471, "seek": 161666, "start": 1617.66, "end": 1622.66, "text": " So if this M defined as the sum of the probabilities", "tokens": [50414, 407, 498, 341, 376, 7642, 382, 264, 2408, 295, 264, 33783, 50664], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 472, "seek": 161666, "start": 1624.02, "end": 1628.22, "text": " of elements of the sample space is equal to one,", "tokens": [50732, 295, 4959, 295, 264, 6889, 1901, 307, 2681, 281, 472, 11, 50942], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 473, "seek": 161666, "start": 1628.22, "end": 1630.8600000000001, "text": " then this is a probability space.", "tokens": [50942, 550, 341, 307, 257, 8482, 1901, 13, 51074], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 474, "seek": 161666, "start": 1630.8600000000001, "end": 1633.6200000000001, "text": " It's very intuitive to see why that is.", "tokens": [51074, 467, 311, 588, 21769, 281, 536, 983, 300, 307, 13, 51212], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 475, "seek": 161666, "start": 1633.6200000000001, "end": 1637.3400000000001, "text": " It's because if you remove the absolute value of this,", "tokens": [51212, 467, 311, 570, 498, 291, 4159, 264, 8236, 2158, 295, 341, 11, 51398], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 476, "seek": 161666, "start": 1637.3400000000001, "end": 1639.44, "text": " this is just the probability of omega,", "tokens": [51398, 341, 307, 445, 264, 8482, 295, 10498, 11, 51503], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 477, "seek": 161666, "start": 1639.44, "end": 1641.8200000000002, "text": " which is always one for a probability space.", "tokens": [51503, 597, 307, 1009, 472, 337, 257, 8482, 1901, 13, 51622], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 478, "seek": 161666, "start": 1641.8200000000002, "end": 1644.78, "text": " And what you're saying is that nothing is pulling", "tokens": [51622, 400, 437, 291, 434, 1566, 307, 300, 1825, 307, 8407, 51770], "temperature": 0.0, "avg_logprob": -0.1487753689289093, "compression_ratio": 1.7169811320754718, "no_speech_prob": 0.0003053375403396785}, {"id": 479, "seek": 164478, "start": 1644.78, "end": 1646.94, "text": " that probability higher or lower", "tokens": [50364, 300, 8482, 2946, 420, 3126, 50472], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 480, "seek": 164478, "start": 1646.94, "end": 1648.54, "text": " because the sum of the absolute values", "tokens": [50472, 570, 264, 2408, 295, 264, 8236, 4190, 50552], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 481, "seek": 164478, "start": 1648.54, "end": 1650.82, "text": " is the same as the sum without absolute values.", "tokens": [50552, 307, 264, 912, 382, 264, 2408, 1553, 8236, 4190, 13, 50666], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 482, "seek": 164478, "start": 1650.82, "end": 1653.08, "text": " There's nothing negative here.", "tokens": [50666, 821, 311, 1825, 3671, 510, 13, 50779], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 483, "seek": 164478, "start": 1653.08, "end": 1654.62, "text": " It's all non-negative.", "tokens": [50779, 467, 311, 439, 2107, 12, 28561, 1166, 13, 50856], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 484, "seek": 164478, "start": 1654.62, "end": 1656.3799999999999, "text": " So this is also a probability space.", "tokens": [50856, 407, 341, 307, 611, 257, 8482, 1901, 13, 50944], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 485, "seek": 164478, "start": 1656.3799999999999, "end": 1660.34, "text": " And alternatively, if this guy,", "tokens": [50944, 400, 8535, 356, 11, 498, 341, 2146, 11, 51142], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 486, "seek": 164478, "start": 1660.34, "end": 1663.02, "text": " it's missing the both face omega here,", "tokens": [51142, 309, 311, 5361, 264, 1293, 1851, 10498, 510, 11, 51276], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 487, "seek": 164478, "start": 1663.02, "end": 1665.74, "text": " but if this is a probability space,", "tokens": [51276, 457, 498, 341, 307, 257, 8482, 1901, 11, 51412], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 488, "seek": 164478, "start": 1665.74, "end": 1670.74, "text": " then it's also a signed probability space of M equals one.", "tokens": [51412, 550, 309, 311, 611, 257, 8175, 8482, 1901, 295, 376, 6915, 472, 13, 51662], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 489, "seek": 164478, "start": 1670.78, "end": 1674.5, "text": " Additionally, a collection of extended random variables", "tokens": [51664, 19927, 11, 257, 5765, 295, 10913, 4974, 9102, 51850], "temperature": 0.0, "avg_logprob": -0.149094866033186, "compression_ratio": 1.8305084745762712, "no_speech_prob": 0.0006165973609313369}, {"id": 490, "seek": 167450, "start": 1674.54, "end": 1676.34, "text": " of this space is contextual,", "tokens": [50366, 295, 341, 1901, 307, 35526, 11, 50456], "temperature": 0.0, "avg_logprob": -0.2326488494873047, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0002959415432997048}, {"id": 491, "seek": 167450, "start": 1676.34, "end": 1680.42, "text": " if and only if M is not one.", "tokens": [50456, 498, 293, 787, 498, 376, 307, 406, 472, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2326488494873047, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0002959415432997048}, {"id": 492, "seek": 167450, "start": 1681.9, "end": 1686.9, "text": " So we have here criteria for contextuality", "tokens": [50734, 407, 321, 362, 510, 11101, 337, 35526, 507, 50984], "temperature": 0.0, "avg_logprob": -0.2326488494873047, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0002959415432997048}, {"id": 493, "seek": 167450, "start": 1687.94, "end": 1692.82, "text": " just showing up in the definition of negative probabilities.", "tokens": [51036, 445, 4099, 493, 294, 264, 7123, 295, 3671, 33783, 13, 51280], "temperature": 0.0, "avg_logprob": -0.2326488494873047, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0002959415432997048}, {"id": 494, "seek": 167450, "start": 1692.82, "end": 1696.02, "text": " I'm gonna skip this because I'm running out of time,", "tokens": [51280, 286, 478, 799, 10023, 341, 570, 286, 478, 2614, 484, 295, 565, 11, 51440], "temperature": 0.0, "avg_logprob": -0.2326488494873047, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0002959415432997048}, {"id": 495, "seek": 167450, "start": 1698.7, "end": 1702.7, "text": " but this is how you can connect it to a quantum mechanics.", "tokens": [51574, 457, 341, 307, 577, 291, 393, 1745, 309, 281, 257, 13018, 12939, 13, 51774], "temperature": 0.0, "avg_logprob": -0.2326488494873047, "compression_ratio": 1.483695652173913, "no_speech_prob": 0.0002959415432997048}, {"id": 496, "seek": 170450, "start": 1705.02, "end": 1707.3, "text": " I gotta say there are lots of different ways", "tokens": [50390, 286, 3428, 584, 456, 366, 3195, 295, 819, 2098, 50504], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 497, "seek": 170450, "start": 1707.3, "end": 1709.7, "text": " in which negative probabilities connect to a quantum mechanics.", "tokens": [50504, 294, 597, 3671, 33783, 1745, 281, 257, 13018, 12939, 13, 50624], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 498, "seek": 170450, "start": 1709.7, "end": 1714.02, "text": " For example, the previous speaker mentioned about PR boxes.", "tokens": [50624, 1171, 1365, 11, 264, 3894, 8145, 2835, 466, 11568, 9002, 13, 50840], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 499, "seek": 170450, "start": 1715.38, "end": 1718.94, "text": " You can, as long as you have no signaling,", "tokens": [50908, 509, 393, 11, 382, 938, 382, 291, 362, 572, 38639, 11, 51086], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 500, "seek": 170450, "start": 1718.94, "end": 1721.18, "text": " you can describe any correlations", "tokens": [51086, 291, 393, 6786, 604, 13983, 763, 51198], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 501, "seek": 170450, "start": 1721.18, "end": 1722.66, "text": " in terms of negative probabilities.", "tokens": [51198, 294, 2115, 295, 3671, 33783, 13, 51272], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 502, "seek": 170450, "start": 1722.66, "end": 1726.26, "text": " So you can describe PR boxes in terms of negative probabilities.", "tokens": [51272, 407, 291, 393, 6786, 11568, 9002, 294, 2115, 295, 3671, 33783, 13, 51452], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 503, "seek": 170450, "start": 1726.26, "end": 1731.02, "text": " You can describe GHC in terms of negative probabilities", "tokens": [51452, 509, 393, 6786, 40690, 34, 294, 2115, 295, 3671, 33783, 51690], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 504, "seek": 170450, "start": 1731.02, "end": 1733.44, "text": " or Bell in terms of negative probabilities.", "tokens": [51690, 420, 11485, 294, 2115, 295, 3671, 33783, 13, 51811], "temperature": 0.0, "avg_logprob": -0.19893524021778292, "compression_ratio": 2.0458715596330275, "no_speech_prob": 0.0002571212244220078}, {"id": 505, "seek": 173344, "start": 1734.44, "end": 1738.44, "text": " But a natural question that often comes up", "tokens": [50414, 583, 257, 3303, 1168, 300, 2049, 1487, 493, 50614], "temperature": 0.0, "avg_logprob": -0.21301887881371281, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.00011233907571295276}, {"id": 506, "seek": 173344, "start": 1741.3600000000001, "end": 1743.64, "text": " comes up in this discussion of negative probabilities", "tokens": [50760, 1487, 493, 294, 341, 5017, 295, 3671, 33783, 50874], "temperature": 0.0, "avg_logprob": -0.21301887881371281, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.00011233907571295276}, {"id": 507, "seek": 173344, "start": 1743.64, "end": 1745.72, "text": " is what are the interpretations", "tokens": [50874, 307, 437, 366, 264, 37547, 50978], "temperature": 0.0, "avg_logprob": -0.21301887881371281, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.00011233907571295276}, {"id": 508, "seek": 173344, "start": 1745.72, "end": 1748.8, "text": " that we can give to a negative probabilities?", "tokens": [50978, 300, 321, 393, 976, 281, 257, 3671, 33783, 30, 51132], "temperature": 0.0, "avg_logprob": -0.21301887881371281, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.00011233907571295276}, {"id": 509, "seek": 173344, "start": 1750.68, "end": 1753.64, "text": " I'm gonna talk about three possible interpretations.", "tokens": [51226, 286, 478, 799, 751, 466, 1045, 1944, 37547, 13, 51374], "temperature": 0.0, "avg_logprob": -0.21301887881371281, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.00011233907571295276}, {"id": 510, "seek": 173344, "start": 1754.92, "end": 1758.96, "text": " Andrei Krenikov, he uses", "tokens": [51438, 400, 10271, 591, 1095, 1035, 5179, 11, 415, 4960, 51640], "temperature": 0.0, "avg_logprob": -0.21301887881371281, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.00011233907571295276}, {"id": 511, "seek": 175896, "start": 1759.96, "end": 1764.8, "text": " a piatic matrix to give an interpretation", "tokens": [50414, 257, 3895, 2399, 8141, 281, 976, 364, 14174, 50656], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 512, "seek": 175896, "start": 1764.8, "end": 1768.48, "text": " of negative probabilities as a violation", "tokens": [50656, 295, 3671, 33783, 382, 257, 22840, 50840], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 513, "seek": 175896, "start": 1768.48, "end": 1772.8, "text": " of von Mises principle of stability.", "tokens": [50840, 295, 2957, 376, 3598, 8665, 295, 11826, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 514, "seek": 175896, "start": 1772.8, "end": 1774.92, "text": " So as we know,", "tokens": [51056, 407, 382, 321, 458, 11, 51162], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 515, "seek": 175896, "start": 1779.1200000000001, "end": 1781.8400000000001, "text": " if you wanna have a frequentist interpretation", "tokens": [51372, 498, 291, 1948, 362, 257, 18004, 468, 14174, 51508], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 516, "seek": 175896, "start": 1781.8400000000001, "end": 1784.4, "text": " of probabilities, what are probabilities?", "tokens": [51508, 295, 33783, 11, 437, 366, 33783, 30, 51636], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 517, "seek": 175896, "start": 1784.4, "end": 1788.0, "text": " And von Mises defines probabilities", "tokens": [51636, 400, 2957, 376, 3598, 23122, 33783, 51816], "temperature": 0.0, "avg_logprob": -0.2614137530326843, "compression_ratio": 1.6928104575163399, "no_speech_prob": 0.0002694299619179219}, {"id": 518, "seek": 178800, "start": 1788.0, "end": 1793.0, "text": " as being over infinite sequences", "tokens": [50364, 382, 885, 670, 13785, 22978, 50614], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 519, "seek": 178800, "start": 1793.92, "end": 1798.52, "text": " of possible outcomes on the sample space,", "tokens": [50660, 295, 1944, 10070, 322, 264, 6889, 1901, 11, 50890], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 520, "seek": 178800, "start": 1798.52, "end": 1800.64, "text": " of possible values in the sample space.", "tokens": [50890, 295, 1944, 4190, 294, 264, 6889, 1901, 13, 50996], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 521, "seek": 178800, "start": 1801.76, "end": 1805.64, "text": " And those probabilities are only defined", "tokens": [51052, 400, 729, 33783, 366, 787, 7642, 51246], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 522, "seek": 178800, "start": 1805.64, "end": 1807.56, "text": " for those infinite sequences", "tokens": [51246, 337, 729, 13785, 22978, 51342], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 523, "seek": 178800, "start": 1807.56, "end": 1809.64, "text": " if they converge to a number.", "tokens": [51342, 498, 436, 41881, 281, 257, 1230, 13, 51446], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 524, "seek": 178800, "start": 1809.64, "end": 1812.24, "text": " So that's what Mises principle of stability.", "tokens": [51446, 407, 300, 311, 437, 376, 3598, 8665, 295, 11826, 13, 51576], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 525, "seek": 178800, "start": 1812.24, "end": 1817.24, "text": " So what Krenikov noticed is that for certain sequences", "tokens": [51576, 407, 437, 591, 1095, 1035, 5179, 5694, 307, 300, 337, 1629, 22978, 51826], "temperature": 0.0, "avg_logprob": -0.19207689089652819, "compression_ratio": 1.679144385026738, "no_speech_prob": 3.8828355172881857e-05}, {"id": 526, "seek": 181724, "start": 1817.88, "end": 1820.64, "text": " that violate the principle of stability,", "tokens": [50396, 300, 37478, 264, 8665, 295, 11826, 11, 50534], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 527, "seek": 181724, "start": 1820.64, "end": 1823.36, "text": " you can actually define probabilities for them", "tokens": [50534, 291, 393, 767, 6964, 33783, 337, 552, 50670], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 528, "seek": 181724, "start": 1823.36, "end": 1827.0, "text": " if you use a piatic metric.", "tokens": [50670, 498, 291, 764, 257, 3895, 2399, 20678, 13, 50852], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 529, "seek": 181724, "start": 1827.0, "end": 1831.0, "text": " And when you do that, the sequences that violate", "tokens": [50852, 400, 562, 291, 360, 300, 11, 264, 22978, 300, 37478, 51052], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 530, "seek": 181724, "start": 1833.44, "end": 1835.04, "text": " von Mises principle of stability", "tokens": [51174, 2957, 376, 3598, 8665, 295, 11826, 51254], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 531, "seek": 181724, "start": 1835.04, "end": 1837.6, "text": " actually take negative values.", "tokens": [51254, 767, 747, 3671, 4190, 13, 51382], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 532, "seek": 181724, "start": 1837.6, "end": 1840.68, "text": " So that's the interpretation that he gives,", "tokens": [51382, 407, 300, 311, 264, 14174, 300, 415, 2709, 11, 51536], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 533, "seek": 181724, "start": 1840.68, "end": 1843.8, "text": " is that negative probabilities are associated with numbers", "tokens": [51536, 307, 300, 3671, 33783, 366, 6615, 365, 3547, 51692], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 534, "seek": 181724, "start": 1843.8, "end": 1846.64, "text": " that violate the principle of stability,", "tokens": [51692, 300, 37478, 264, 8665, 295, 11826, 11, 51834], "temperature": 0.0, "avg_logprob": -0.14674265631313982, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.00012533309927675873}, {"id": 535, "seek": 184664, "start": 1846.64, "end": 1850.3600000000001, "text": " which in terms of like, if you are trying to understand,", "tokens": [50364, 597, 294, 2115, 295, 411, 11, 498, 291, 366, 1382, 281, 1223, 11, 50550], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 536, "seek": 184664, "start": 1850.3600000000001, "end": 1853.2, "text": " for example, Bell correlations,", "tokens": [50550, 337, 1365, 11, 11485, 13983, 763, 11, 50692], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 537, "seek": 184664, "start": 1853.2, "end": 1855.6000000000001, "text": " it means that those sequences", "tokens": [50692, 309, 1355, 300, 729, 22978, 50812], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 538, "seek": 184664, "start": 1855.6000000000001, "end": 1857.8000000000002, "text": " that you're assuming to be independent,", "tokens": [50812, 300, 291, 434, 11926, 281, 312, 6695, 11, 50922], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 539, "seek": 184664, "start": 1857.8000000000002, "end": 1859.48, "text": " they're not actually independent.", "tokens": [50922, 436, 434, 406, 767, 6695, 13, 51006], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 540, "seek": 184664, "start": 1860.48, "end": 1861.8000000000002, "text": " Because...", "tokens": [51056, 1436, 485, 51122], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 541, "seek": 184664, "start": 1861.8000000000002, "end": 1865.44, "text": " You have 10 minutes including the question.", "tokens": [51122, 509, 362, 1266, 2077, 3009, 264, 1168, 13, 51304], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 542, "seek": 184664, "start": 1865.44, "end": 1867.92, "text": " Oh yeah, I'm just finishing it.", "tokens": [51304, 876, 1338, 11, 286, 478, 445, 12693, 309, 13, 51428], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 543, "seek": 184664, "start": 1867.92, "end": 1870.4, "text": " Just finishing the rotations.", "tokens": [51428, 1449, 12693, 264, 44796, 13, 51552], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 544, "seek": 184664, "start": 1870.4, "end": 1871.24, "text": " Thanks.", "tokens": [51552, 2561, 13, 51594], "temperature": 0.0, "avg_logprob": -0.3816975560681573, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.00081522116670385}, {"id": 545, "seek": 187124, "start": 1871.68, "end": 1876.68, "text": " So another interpretation is proposed", "tokens": [50386, 407, 1071, 14174, 307, 10348, 50636], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 546, "seek": 187124, "start": 1877.0, "end": 1878.72, "text": " by Bromsky and Brandenburger.", "tokens": [50652, 538, 1603, 4785, 4133, 293, 11119, 268, 41787, 13, 50738], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 547, "seek": 187124, "start": 1878.72, "end": 1882.0, "text": " It's actually based on the composition theorem", "tokens": [50738, 467, 311, 767, 2361, 322, 264, 12686, 20904, 50902], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 548, "seek": 187124, "start": 1882.0, "end": 1885.64, "text": " that shows that if you have a signed measure,", "tokens": [50902, 300, 3110, 300, 498, 291, 362, 257, 8175, 3481, 11, 51084], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 549, "seek": 187124, "start": 1885.64, "end": 1887.88, "text": " you can always break it down into two measures,", "tokens": [51084, 291, 393, 1009, 1821, 309, 760, 666, 732, 8000, 11, 51196], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 550, "seek": 187124, "start": 1887.88, "end": 1890.44, "text": " one positive and one negative,", "tokens": [51196, 472, 3353, 293, 472, 3671, 11, 51324], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 551, "seek": 187124, "start": 1890.44, "end": 1893.92, "text": " and each one of them independently are non-signed measures.", "tokens": [51324, 293, 1184, 472, 295, 552, 21761, 366, 2107, 12, 82, 16690, 8000, 13, 51498], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 552, "seek": 187124, "start": 1893.92, "end": 1896.6, "text": " And what they do is they just attach a sign", "tokens": [51498, 400, 437, 436, 360, 307, 436, 445, 5085, 257, 1465, 51632], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 553, "seek": 187124, "start": 1896.6, "end": 1900.68, "text": " to each one of the outcomes of an experiment,", "tokens": [51632, 281, 1184, 472, 295, 264, 10070, 295, 364, 5120, 11, 51836], "temperature": 0.0, "avg_logprob": -0.17151065864185294, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.017423314973711967}, {"id": 554, "seek": 190068, "start": 1900.68, "end": 1901.96, "text": " and then those signs,", "tokens": [50364, 293, 550, 729, 7880, 11, 50428], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 555, "seek": 190068, "start": 1901.96, "end": 1904.68, "text": " they lead to cancellation of certain events.", "tokens": [50428, 436, 1477, 281, 45867, 295, 1629, 3931, 13, 50564], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 556, "seek": 190068, "start": 1905.64, "end": 1906.92, "text": " There's a third interpretation,", "tokens": [50612, 821, 311, 257, 2636, 14174, 11, 50676], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 557, "seek": 190068, "start": 1906.92, "end": 1908.52, "text": " which is the one put forth by Derrack", "tokens": [50676, 597, 307, 264, 472, 829, 5220, 538, 5618, 81, 501, 50756], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 558, "seek": 190068, "start": 1908.52, "end": 1909.76, "text": " and later on by Feynman,", "tokens": [50756, 293, 1780, 322, 538, 46530, 77, 1601, 11, 50818], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 559, "seek": 190068, "start": 1911.3600000000001, "end": 1914.28, "text": " which is that probabilities,", "tokens": [50898, 597, 307, 300, 33783, 11, 51044], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 560, "seek": 190068, "start": 1914.28, "end": 1916.6000000000001, "text": " negative probabilities for that matter,", "tokens": [51044, 3671, 33783, 337, 300, 1871, 11, 51160], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 561, "seek": 190068, "start": 1916.6000000000001, "end": 1920.0, "text": " are just a bookkeeping device.", "tokens": [51160, 366, 445, 257, 1446, 25769, 4302, 13, 51330], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 562, "seek": 190068, "start": 1921.28, "end": 1924.76, "text": " So in that sense,", "tokens": [51394, 407, 294, 300, 2020, 11, 51568], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 563, "seek": 190068, "start": 1924.76, "end": 1926.92, "text": " negative probabilities are nothing more", "tokens": [51568, 3671, 33783, 366, 1825, 544, 51676], "temperature": 0.0, "avg_logprob": -0.19526453127806215, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.00017129804473370314}, {"id": 564, "seek": 192692, "start": 1927.52, "end": 1931.4, "text": " than the same as we do with negative numbers.", "tokens": [50394, 813, 264, 912, 382, 321, 360, 365, 3671, 3547, 13, 50588], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 565, "seek": 192692, "start": 1931.4, "end": 1932.44, "text": " So for example,", "tokens": [50588, 407, 337, 1365, 11, 50640], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 566, "seek": 192692, "start": 1932.44, "end": 1935.44, "text": " we never observe a negative number of apples.", "tokens": [50640, 321, 1128, 11441, 257, 3671, 1230, 295, 16814, 13, 50790], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 567, "seek": 192692, "start": 1935.44, "end": 1937.3200000000002, "text": " In fact, it's nonsensical to talk about", "tokens": [50790, 682, 1186, 11, 309, 311, 297, 892, 694, 804, 281, 751, 466, 50884], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 568, "seek": 192692, "start": 1937.3200000000002, "end": 1940.64, "text": " a negative number of numbers as an actual observable,", "tokens": [50884, 257, 3671, 1230, 295, 3547, 382, 364, 3539, 9951, 712, 11, 51050], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 569, "seek": 192692, "start": 1940.64, "end": 1944.88, "text": " but it doesn't mean that using negative numbers of apples", "tokens": [51050, 457, 309, 1177, 380, 914, 300, 1228, 3671, 3547, 295, 16814, 51262], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 570, "seek": 192692, "start": 1944.88, "end": 1947.76, "text": " is not a useful book counting device.", "tokens": [51262, 307, 406, 257, 4420, 1446, 13251, 4302, 13, 51406], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 571, "seek": 192692, "start": 1949.0800000000002, "end": 1951.16, "text": " We never observe a negative number of dollars", "tokens": [51472, 492, 1128, 11441, 257, 3671, 1230, 295, 3808, 51576], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 572, "seek": 192692, "start": 1951.16, "end": 1952.48, "text": " for that matter either.", "tokens": [51576, 337, 300, 1871, 2139, 13, 51642], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 573, "seek": 192692, "start": 1952.48, "end": 1956.88, "text": " It doesn't mean that one never has negative numbers", "tokens": [51642, 467, 1177, 380, 914, 300, 472, 1128, 575, 3671, 3547, 51862], "temperature": 0.0, "avg_logprob": -0.13539362820712003, "compression_ratio": 2.024154589371981, "no_speech_prob": 0.029298972338438034}, {"id": 574, "seek": 195688, "start": 1956.88, "end": 1959.64, "text": " in an account as a bookkeeping device", "tokens": [50364, 294, 364, 2696, 382, 257, 1446, 25769, 4302, 50502], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 575, "seek": 195688, "start": 1959.64, "end": 1961.7600000000002, "text": " for how much money we have in an account.", "tokens": [50502, 337, 577, 709, 1460, 321, 362, 294, 364, 2696, 13, 50608], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 576, "seek": 195688, "start": 1962.88, "end": 1967.88, "text": " And the reason why I'm mentioning numbers here", "tokens": [50664, 400, 264, 1778, 983, 286, 478, 18315, 3547, 510, 50914], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 577, "seek": 195688, "start": 1969.4, "end": 1972.68, "text": " is because the concept of even using negative numbers", "tokens": [50990, 307, 570, 264, 3410, 295, 754, 1228, 3671, 3547, 51154], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 578, "seek": 195688, "start": 1973.64, "end": 1977.4, "text": " has not been always non-controversial.", "tokens": [51202, 575, 406, 668, 1009, 2107, 12, 9000, 340, 840, 831, 13, 51390], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 579, "seek": 195688, "start": 1977.4, "end": 1978.8000000000002, "text": " Consider, for example,", "tokens": [51390, 17416, 11, 337, 1365, 11, 51460], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 580, "seek": 195688, "start": 1978.8000000000002, "end": 1980.3600000000001, "text": " the following quote by De Morgan,", "tokens": [51460, 264, 3480, 6513, 538, 1346, 16724, 11, 51538], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 581, "seek": 195688, "start": 1980.3600000000001, "end": 1983.16, "text": " the famous mathematician and logician", "tokens": [51538, 264, 4618, 48281, 293, 3565, 9027, 51678], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 582, "seek": 195688, "start": 1983.16, "end": 1984.92, "text": " in a book that he wrote in the 30s.", "tokens": [51678, 294, 257, 1446, 300, 415, 4114, 294, 264, 2217, 82, 13, 51766], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 583, "seek": 195688, "start": 1984.92, "end": 1986.8600000000001, "text": " And I'll read the quote to you.", "tokens": [51766, 400, 286, 603, 1401, 264, 6513, 281, 291, 13, 51863], "temperature": 0.0, "avg_logprob": -0.17708667862081082, "compression_ratio": 1.578512396694215, "no_speech_prob": 0.0004511151637416333}, {"id": 584, "seek": 198686, "start": 1986.9399999999998, "end": 1989.2199999999998, "text": " Above all, he, the student,", "tokens": [50368, 32691, 439, 11, 415, 11, 264, 3107, 11, 50482], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 585, "seek": 198686, "start": 1989.2199999999998, "end": 1991.8999999999999, "text": " must reject the definition still sometimes given", "tokens": [50482, 1633, 8248, 264, 7123, 920, 2171, 2212, 50616], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 586, "seek": 198686, "start": 1991.8999999999999, "end": 1995.58, "text": " of the quantity minus A, that it is less than nothing.", "tokens": [50616, 295, 264, 11275, 3175, 316, 11, 300, 309, 307, 1570, 813, 1825, 13, 50800], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 587, "seek": 198686, "start": 1996.62, "end": 1998.4199999999998, "text": " It is astonishing that the human intellect", "tokens": [50852, 467, 307, 35264, 300, 264, 1952, 10058, 50942], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 588, "seek": 198686, "start": 1998.4199999999998, "end": 2000.9399999999998, "text": " should ever have tolerated such an absurdity", "tokens": [50942, 820, 1562, 362, 11125, 770, 1270, 364, 19774, 507, 51068], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 589, "seek": 198686, "start": 2000.9399999999998, "end": 2003.62, "text": " as the idea of a quantity less than nothing.", "tokens": [51068, 382, 264, 1558, 295, 257, 11275, 1570, 813, 1825, 13, 51202], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 590, "seek": 198686, "start": 2003.62, "end": 2006.62, "text": " Above all, that the notion should have outlived the beliefs", "tokens": [51202, 32691, 439, 11, 300, 264, 10710, 820, 362, 484, 46554, 264, 13585, 51352], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 591, "seek": 198686, "start": 2006.62, "end": 2009.58, "text": " in judicial astrology and the nonexistence of witches,", "tokens": [51352, 294, 26581, 44385, 293, 264, 6022, 87, 468, 655, 295, 43467, 11, 51500], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 592, "seek": 198686, "start": 2009.58, "end": 2013.1799999999998, "text": " either of which is 10,000 times more possible.", "tokens": [51500, 2139, 295, 597, 307, 1266, 11, 1360, 1413, 544, 1944, 13, 51680], "temperature": 0.0, "avg_logprob": -0.14057781499460204, "compression_ratio": 1.7246963562753037, "no_speech_prob": 0.005639146082103252}, {"id": 593, "seek": 201318, "start": 2013.3, "end": 2017.9, "text": " So as late as like the 1800s,", "tokens": [50370, 407, 382, 3469, 382, 411, 264, 24327, 82, 11, 50600], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 594, "seek": 201318, "start": 2017.9, "end": 2019.8200000000002, "text": " negative numbers were still considered", "tokens": [50600, 3671, 3547, 645, 920, 4888, 50696], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 595, "seek": 201318, "start": 2019.8200000000002, "end": 2022.3, "text": " like an absurd idea by some.", "tokens": [50696, 411, 364, 19774, 1558, 538, 512, 13, 50820], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 596, "seek": 201318, "start": 2023.46, "end": 2027.14, "text": " And it might be the case that negative probabilities", "tokens": [50878, 400, 309, 1062, 312, 264, 1389, 300, 3671, 33783, 51062], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 597, "seek": 201318, "start": 2029.0600000000002, "end": 2031.54, "text": " will in the future be considered the same", "tokens": [51158, 486, 294, 264, 2027, 312, 4888, 264, 912, 51282], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 598, "seek": 201318, "start": 2031.54, "end": 2033.38, "text": " as we consider negative numbers,", "tokens": [51282, 382, 321, 1949, 3671, 3547, 11, 51374], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 599, "seek": 201318, "start": 2033.38, "end": 2036.5, "text": " something just natural, like natural numbers are", "tokens": [51374, 746, 445, 3303, 11, 411, 3303, 3547, 366, 51530], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 600, "seek": 201318, "start": 2036.5, "end": 2038.78, "text": " as a bookkeeping device.", "tokens": [51530, 382, 257, 1446, 25769, 4302, 13, 51644], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 601, "seek": 201318, "start": 2038.78, "end": 2042.38, "text": " So just to summarize what I talked today,", "tokens": [51644, 407, 445, 281, 20858, 437, 286, 2825, 965, 11, 51824], "temperature": 0.0, "avg_logprob": -0.1693861872650856, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.00015350893954746425}, {"id": 602, "seek": 204318, "start": 2043.5800000000002, "end": 2046.6200000000001, "text": " as we discussed, contextuality is a key characteristic", "tokens": [50384, 382, 321, 7152, 11, 35526, 507, 307, 257, 2141, 16282, 50536], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 603, "seek": 204318, "start": 2046.6200000000001, "end": 2047.8600000000001, "text": " of quantum properties.", "tokens": [50536, 295, 13018, 7221, 13, 50598], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 604, "seek": 204318, "start": 2049.3, "end": 2053.2200000000003, "text": " We often use hybrid space formalism to describe", "tokens": [50670, 492, 2049, 764, 13051, 1901, 9860, 1434, 281, 6786, 50866], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 605, "seek": 204318, "start": 2053.2200000000003, "end": 2056.46, "text": " those quantum properties and the hybrid space formalism", "tokens": [50866, 729, 13018, 7221, 293, 264, 13051, 1901, 9860, 1434, 51028], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 606, "seek": 204318, "start": 2056.46, "end": 2058.7000000000003, "text": " has built in that contextuality.", "tokens": [51028, 575, 3094, 294, 300, 35526, 507, 13, 51140], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 607, "seek": 204318, "start": 2060.42, "end": 2065.42, "text": " That contextuality cannot be represented", "tokens": [51226, 663, 35526, 507, 2644, 312, 10379, 51476], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 608, "seek": 204318, "start": 2065.46, "end": 2067.9, "text": " in probability theory unless you do something", "tokens": [51478, 294, 8482, 5261, 5969, 291, 360, 746, 51600], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 609, "seek": 204318, "start": 2067.9, "end": 2071.14, "text": " like for example, the approach of contextuality by default", "tokens": [51600, 411, 337, 1365, 11, 264, 3109, 295, 35526, 507, 538, 7576, 51762], "temperature": 0.0, "avg_logprob": -0.17798745190655743, "compression_ratio": 1.8090452261306533, "no_speech_prob": 0.0006452907109633088}, {"id": 610, "seek": 207114, "start": 2071.18, "end": 2074.06, "text": " by increasing the number of random variables.", "tokens": [50366, 538, 5662, 264, 1230, 295, 4974, 9102, 13, 50510], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 611, "seek": 207114, "start": 2074.06, "end": 2076.62, "text": " But that goes against a little bit the idea", "tokens": [50510, 583, 300, 1709, 1970, 257, 707, 857, 264, 1558, 50638], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 612, "seek": 207114, "start": 2076.62, "end": 2081.62, "text": " that we do in physics because we have the same measurement", "tokens": [50638, 300, 321, 360, 294, 10649, 570, 321, 362, 264, 912, 13160, 50888], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 613, "seek": 207114, "start": 2085.2999999999997, "end": 2087.18, "text": " apparatus for some of those things.", "tokens": [51072, 38573, 337, 512, 295, 729, 721, 13, 51166], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 614, "seek": 207114, "start": 2088.98, "end": 2092.62, "text": " But extended probability theories can be constructed.", "tokens": [51256, 583, 10913, 8482, 13667, 393, 312, 17083, 13, 51438], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 615, "seek": 207114, "start": 2092.62, "end": 2095.74, "text": " And here we just presented a measure theoretic framework", "tokens": [51438, 400, 510, 321, 445, 8212, 257, 3481, 14308, 299, 8388, 51594], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 616, "seek": 207114, "start": 2095.74, "end": 2097.98, "text": " for defining an extended probability", "tokens": [51594, 337, 17827, 364, 10913, 8482, 51706], "temperature": 0.0, "avg_logprob": -0.1654595168861183, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.00020660502195823938}, {"id": 617, "seek": 209798, "start": 2097.98, "end": 2102.98, "text": " that we feel captures at least the gist", "tokens": [50364, 300, 321, 841, 27986, 412, 1935, 264, 290, 468, 50614], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 618, "seek": 209798, "start": 2103.66, "end": 2106.98, "text": " of quantum contextuality in the sense that we can model", "tokens": [50648, 295, 13018, 35526, 507, 294, 264, 2020, 300, 321, 393, 2316, 50814], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 619, "seek": 209798, "start": 2106.98, "end": 2110.78, "text": " quantum contextuality with that probability theory.", "tokens": [50814, 13018, 35526, 507, 365, 300, 8482, 5261, 13, 51004], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 620, "seek": 209798, "start": 2110.78, "end": 2112.62, "text": " And we hope that such tool may be used", "tokens": [51004, 400, 321, 1454, 300, 1270, 2290, 815, 312, 1143, 51096], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 621, "seek": 209798, "start": 2112.62, "end": 2113.98, "text": " when describing quantum phenomena.", "tokens": [51096, 562, 16141, 13018, 22004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 622, "seek": 209798, "start": 2113.98, "end": 2116.7, "text": " Like for example, we know that it implies", "tokens": [51164, 1743, 337, 1365, 11, 321, 458, 300, 309, 18779, 51300], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 623, "seek": 209798, "start": 2116.7, "end": 2120.42, "text": " the no signaling condition, which is part of quantum systems.", "tokens": [51300, 264, 572, 38639, 4188, 11, 597, 307, 644, 295, 13018, 3652, 13, 51486], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 624, "seek": 209798, "start": 2120.42, "end": 2124.82, "text": " But it's still unclear whether it's useful or not.", "tokens": [51486, 583, 309, 311, 920, 25636, 1968, 309, 311, 4420, 420, 406, 13, 51706], "temperature": 0.0, "avg_logprob": -0.16750957119849422, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005031193722970784}, {"id": 625, "seek": 212482, "start": 2124.82, "end": 2129.82, "text": " So I just wanna end with acknowledging my collaborators.", "tokens": [50364, 407, 286, 445, 1948, 917, 365, 30904, 452, 39789, 13, 50614], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 626, "seek": 212482, "start": 2133.78, "end": 2137.34, "text": " What I talked today is in essence part of a paper", "tokens": [50812, 708, 286, 2825, 965, 307, 294, 12801, 644, 295, 257, 3035, 50990], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 627, "seek": 212482, "start": 2137.34, "end": 2140.5800000000004, "text": " that I did with Federico Halleck", "tokens": [50990, 300, 286, 630, 365, 45545, 2789, 5434, 68, 547, 51152], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 628, "seek": 212482, "start": 2140.5800000000004, "end": 2143.06, "text": " who's organizing this conference.", "tokens": [51152, 567, 311, 17608, 341, 7586, 13, 51276], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 629, "seek": 212482, "start": 2143.06, "end": 2145.1800000000003, "text": " But I also benefited from a lot of discussions", "tokens": [51276, 583, 286, 611, 33605, 490, 257, 688, 295, 11088, 51382], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 630, "seek": 212482, "start": 2145.1800000000003, "end": 2149.38, "text": " of many people in particular, those people listed here.", "tokens": [51382, 295, 867, 561, 294, 1729, 11, 729, 561, 10052, 510, 13, 51592], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 631, "seek": 212482, "start": 2149.38, "end": 2150.7000000000003, "text": " So thank you.", "tokens": [51592, 407, 1309, 291, 13, 51658], "temperature": 0.0, "avg_logprob": -0.22001529994763827, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.0015884876484051347}, {"id": 632, "seek": 215070, "start": 2151.54, "end": 2154.2999999999997, "text": " Okay, thank you, Jose, for your talk.", "tokens": [50406, 1033, 11, 1309, 291, 11, 8635, 11, 337, 428, 751, 13, 50544], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 633, "seek": 215070, "start": 2154.2999999999997, "end": 2156.66, "text": " There are some questions in the chat.", "tokens": [50544, 821, 366, 512, 1651, 294, 264, 5081, 13, 50662], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 634, "seek": 215070, "start": 2156.66, "end": 2159.8999999999996, "text": " The first one is from Shansen.", "tokens": [50662, 440, 700, 472, 307, 490, 1160, 599, 268, 13, 50824], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 635, "seek": 215070, "start": 2163.5, "end": 2166.8199999999997, "text": " All right, thank you for that talk.", "tokens": [51004, 1057, 558, 11, 1309, 291, 337, 300, 751, 13, 51170], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 636, "seek": 215070, "start": 2166.8199999999997, "end": 2169.46, "text": " My question is about, has to do with sort of rhetoric", "tokens": [51170, 1222, 1168, 307, 466, 11, 575, 281, 360, 365, 1333, 295, 29604, 51302], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 637, "seek": 215070, "start": 2169.46, "end": 2170.46, "text": " and pedagogy.", "tokens": [51302, 293, 5670, 559, 7794, 13, 51352], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 638, "seek": 215070, "start": 2170.46, "end": 2174.9399999999996, "text": " So, you know, like we, it sounds like we think very much", "tokens": [51352, 407, 11, 291, 458, 11, 411, 321, 11, 309, 3263, 411, 321, 519, 588, 709, 51576], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 639, "seek": 215070, "start": 2174.9399999999996, "end": 2177.5, "text": " the same way about quantum mechanics is basically", "tokens": [51576, 264, 912, 636, 466, 13018, 12939, 307, 1936, 51704], "temperature": 0.0, "avg_logprob": -0.4325814498098273, "compression_ratio": 1.5240384615384615, "no_speech_prob": 0.0011960193514823914}, {"id": 640, "seek": 217750, "start": 2178.38, "end": 2183.06, "text": " like a new framework for handling probabilities.", "tokens": [50408, 411, 257, 777, 8388, 337, 13175, 33783, 13, 50642], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 641, "seek": 217750, "start": 2184.26, "end": 2186.9, "text": " And I wonder whether it's the smartest strategy", "tokens": [50702, 400, 286, 2441, 1968, 309, 311, 264, 41491, 5206, 50834], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 642, "seek": 217750, "start": 2186.9, "end": 2189.1, "text": " to convince people of our view", "tokens": [50834, 281, 13447, 561, 295, 527, 1910, 50944], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 643, "seek": 217750, "start": 2189.1, "end": 2191.74, "text": " that you now like have to like get used to the idea", "tokens": [50944, 300, 291, 586, 411, 362, 281, 411, 483, 1143, 281, 264, 1558, 51076], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 644, "seek": 217750, "start": 2191.74, "end": 2192.86, "text": " of negative probabilities.", "tokens": [51076, 295, 3671, 33783, 13, 51132], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 645, "seek": 217750, "start": 2192.86, "end": 2194.26, "text": " I mean, if you start, I mean,", "tokens": [51132, 286, 914, 11, 498, 291, 722, 11, 286, 914, 11, 51202], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 646, "seek": 217750, "start": 2194.26, "end": 2196.62, "text": " you're very nicely laid out the difference.", "tokens": [51202, 291, 434, 588, 9594, 9897, 484, 264, 2649, 13, 51320], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 647, "seek": 217750, "start": 2196.62, "end": 2198.38, "text": " Like, you know, you have contextuality, right?", "tokens": [51320, 1743, 11, 291, 458, 11, 291, 362, 35526, 507, 11, 558, 30, 51408], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 648, "seek": 217750, "start": 2198.38, "end": 2201.78, "text": " You don't, but quantum mechanics doesn't allow you", "tokens": [51408, 509, 500, 380, 11, 457, 13018, 12939, 1177, 380, 2089, 291, 51578], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 649, "seek": 217750, "start": 2201.78, "end": 2203.34, "text": " to have joint probabilities, right?", "tokens": [51578, 281, 362, 7225, 33783, 11, 558, 30, 51656], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 650, "seek": 217750, "start": 2203.34, "end": 2206.98, "text": " You can't assign values to all the different variables.", "tokens": [51656, 509, 393, 380, 6269, 4190, 281, 439, 264, 819, 9102, 13, 51838], "temperature": 0.0, "avg_logprob": -0.13120699316505494, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.006890523713082075}, {"id": 651, "seek": 220698, "start": 2206.98, "end": 2211.1, "text": " I wonder if there isn't like sort of a more natural way", "tokens": [50364, 286, 2441, 498, 456, 1943, 380, 411, 1333, 295, 257, 544, 3303, 636, 50570], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 652, "seek": 220698, "start": 2211.1, "end": 2214.98, "text": " of like ramming that down people's throats", "tokens": [50570, 295, 411, 10211, 2810, 300, 760, 561, 311, 258, 340, 1720, 50764], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 653, "seek": 220698, "start": 2214.98, "end": 2217.02, "text": " than going this route of introducing", "tokens": [50764, 813, 516, 341, 7955, 295, 15424, 50866], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 654, "seek": 220698, "start": 2217.02, "end": 2218.3, "text": " negative probabilities.", "tokens": [50866, 3671, 33783, 13, 50930], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 655, "seek": 220698, "start": 2219.42, "end": 2220.9, "text": " Yeah, thank you.", "tokens": [50986, 865, 11, 1309, 291, 13, 51060], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 656, "seek": 220698, "start": 2220.9, "end": 2224.7, "text": " I confess that I would probably never teach", "tokens": [51060, 286, 19367, 300, 286, 576, 1391, 1128, 2924, 51250], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 657, "seek": 220698, "start": 2224.7, "end": 2226.98, "text": " negative probabilities to my students.", "tokens": [51250, 3671, 33783, 281, 452, 1731, 13, 51364], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 658, "seek": 220698, "start": 2228.34, "end": 2231.86, "text": " Well, never, I mean, maybe in the future.", "tokens": [51432, 1042, 11, 1128, 11, 286, 914, 11, 1310, 294, 264, 2027, 13, 51608], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 659, "seek": 220698, "start": 2231.86, "end": 2234.22, "text": " That's not the reason why I'm talking", "tokens": [51608, 663, 311, 406, 264, 1778, 983, 286, 478, 1417, 51726], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 660, "seek": 220698, "start": 2234.22, "end": 2235.86, "text": " about negative probabilities actually.", "tokens": [51726, 466, 3671, 33783, 767, 13, 51808], "temperature": 0.0, "avg_logprob": -0.17514276504516602, "compression_ratio": 1.68, "no_speech_prob": 0.00018229830311611295}, {"id": 661, "seek": 223586, "start": 2235.94, "end": 2238.1400000000003, "text": " The reason why I'm talking about negative probabilities", "tokens": [50368, 440, 1778, 983, 286, 478, 1417, 466, 3671, 33783, 50478], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 662, "seek": 223586, "start": 2238.1400000000003, "end": 2243.1400000000003, "text": " is because I hope that by trying to understand", "tokens": [50478, 307, 570, 286, 1454, 300, 538, 1382, 281, 1223, 50728], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 663, "seek": 223586, "start": 2244.6600000000003, "end": 2247.5, "text": " certain phenomena in terms of negative probabilities,", "tokens": [50804, 1629, 22004, 294, 2115, 295, 3671, 33783, 11, 50946], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 664, "seek": 223586, "start": 2247.5, "end": 2250.82, "text": " we might be able to get different insights", "tokens": [50946, 321, 1062, 312, 1075, 281, 483, 819, 14310, 51112], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 665, "seek": 223586, "start": 2250.82, "end": 2253.26, "text": " into those phenomena that we would not get", "tokens": [51112, 666, 729, 22004, 300, 321, 576, 406, 483, 51234], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 666, "seek": 223586, "start": 2253.26, "end": 2255.86, "text": " from the Hebert space formalism.", "tokens": [51234, 490, 264, 634, 4290, 1901, 9860, 1434, 13, 51364], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 667, "seek": 223586, "start": 2255.86, "end": 2259.5, "text": " I can give you a specific example, right?", "tokens": [51364, 286, 393, 976, 291, 257, 2685, 1365, 11, 558, 30, 51546], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 668, "seek": 223586, "start": 2259.5, "end": 2264.5, "text": " So when we look at different principles", "tokens": [51546, 407, 562, 321, 574, 412, 819, 9156, 51796], "temperature": 0.0, "avg_logprob": -0.15358631951468332, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.0007321243756450713}, {"id": 669, "seek": 226586, "start": 2265.98, "end": 2269.2200000000003, "text": " that define quantum mechanics that people have tried,", "tokens": [50370, 300, 6964, 13018, 12939, 300, 561, 362, 3031, 11, 50532], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 670, "seek": 226586, "start": 2269.2200000000003, "end": 2274.06, "text": " like for example, Cabello have tried to define some principles", "tokens": [50532, 411, 337, 1365, 11, 14704, 11216, 362, 3031, 281, 6964, 512, 9156, 50774], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 671, "seek": 226586, "start": 2274.06, "end": 2275.94, "text": " that give us quantum mechanics.", "tokens": [50774, 300, 976, 505, 13018, 12939, 13, 50868], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 672, "seek": 226586, "start": 2276.9, "end": 2279.86, "text": " When you write them down in terms of negative probabilities,", "tokens": [50916, 1133, 291, 2464, 552, 760, 294, 2115, 295, 3671, 33783, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 673, "seek": 226586, "start": 2279.86, "end": 2280.98, "text": " they become clear.", "tokens": [51064, 436, 1813, 1850, 13, 51120], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 674, "seek": 226586, "start": 2282.34, "end": 2285.7000000000003, "text": " Whether that's a useful tool for us to understand", "tokens": [51188, 8503, 300, 311, 257, 4420, 2290, 337, 505, 281, 1223, 51356], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 675, "seek": 226586, "start": 2285.7000000000003, "end": 2288.1400000000003, "text": " what's going on with quantum mechanics or not,", "tokens": [51356, 437, 311, 516, 322, 365, 13018, 12939, 420, 406, 11, 51478], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 676, "seek": 226586, "start": 2288.1400000000003, "end": 2291.54, "text": " I don't know because I didn't get any special insights", "tokens": [51478, 286, 500, 380, 458, 570, 286, 994, 380, 483, 604, 2121, 14310, 51648], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 677, "seek": 226586, "start": 2291.54, "end": 2293.06, "text": " from that, but that's my hope, right?", "tokens": [51648, 490, 300, 11, 457, 300, 311, 452, 1454, 11, 558, 30, 51724], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 678, "seek": 226586, "start": 2293.06, "end": 2294.7400000000002, "text": " That's what I'm trying to do.", "tokens": [51724, 663, 311, 437, 286, 478, 1382, 281, 360, 13, 51808], "temperature": 0.0, "avg_logprob": -0.13177024907079235, "compression_ratio": 1.703422053231939, "no_speech_prob": 0.000709615065716207}, {"id": 679, "seek": 229474, "start": 2294.74, "end": 2297.54, "text": " I'm trying to see if we can understand", "tokens": [50364, 286, 478, 1382, 281, 536, 498, 321, 393, 1223, 50504], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 680, "seek": 229474, "start": 2297.54, "end": 2299.9399999999996, "text": " different types of quantum puzzles", "tokens": [50504, 819, 3467, 295, 13018, 24138, 50624], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 681, "seek": 229474, "start": 2299.9399999999996, "end": 2301.4199999999996, "text": " in terms of negative probabilities", "tokens": [50624, 294, 2115, 295, 3671, 33783, 50698], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 682, "seek": 229474, "start": 2301.4199999999996, "end": 2304.02, "text": " such that we can get better insight from them.", "tokens": [50698, 1270, 300, 321, 393, 483, 1101, 11269, 490, 552, 13, 50828], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 683, "seek": 229474, "start": 2304.02, "end": 2307.22, "text": " If we do, then perhaps in the future,", "tokens": [50828, 759, 321, 360, 11, 550, 4317, 294, 264, 2027, 11, 50988], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 684, "seek": 229474, "start": 2307.22, "end": 2309.7, "text": " we might even try to teach our students that,", "tokens": [50988, 321, 1062, 754, 853, 281, 2924, 527, 1731, 300, 11, 51112], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 685, "seek": 229474, "start": 2309.7, "end": 2311.3399999999997, "text": " but we're not there yet.", "tokens": [51112, 457, 321, 434, 406, 456, 1939, 13, 51194], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 686, "seek": 229474, "start": 2312.7, "end": 2313.54, "text": " Okay, thank you.", "tokens": [51262, 1033, 11, 1309, 291, 13, 51304], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 687, "seek": 229474, "start": 2315.66, "end": 2320.66, "text": " And there is another question from Alison Decini.", "tokens": [51410, 400, 456, 307, 1071, 1168, 490, 41001, 12427, 3812, 13, 51660], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 688, "seek": 229474, "start": 2321.7, "end": 2323.58, "text": " Hi, can you hear me?", "tokens": [51712, 2421, 11, 393, 291, 1568, 385, 30, 51806], "temperature": 0.0, "avg_logprob": -0.23398418426513673, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0014250221429392695}, {"id": 689, "seek": 232358, "start": 2323.58, "end": 2325.2599999999998, "text": " Yes, I can hear you.", "tokens": [50364, 1079, 11, 286, 393, 1568, 291, 13, 50448], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 690, "seek": 232358, "start": 2325.2599999999998, "end": 2327.7, "text": " Okay, so thanks for the very nice question.", "tokens": [50448, 1033, 11, 370, 3231, 337, 264, 588, 1481, 1168, 13, 50570], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 691, "seek": 232358, "start": 2328.98, "end": 2331.34, "text": " My question is about Cauchy-Speccher theorem.", "tokens": [50634, 1222, 1168, 307, 466, 7544, 625, 88, 12, 50, 494, 66, 6759, 20904, 13, 50752], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 692, "seek": 232358, "start": 2331.34, "end": 2334.7799999999997, "text": " So how do you avoid Cauchy-Speccher theorem", "tokens": [50752, 407, 577, 360, 291, 5042, 7544, 625, 88, 12, 50, 494, 66, 6759, 20904, 50924], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 693, "seek": 232358, "start": 2334.7799999999997, "end": 2336.2999999999997, "text": " in this kind of framework?", "tokens": [50924, 294, 341, 733, 295, 8388, 30, 51000], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 694, "seek": 232358, "start": 2336.2999999999997, "end": 2338.94, "text": " Because Cauchy-Speccher theorem", "tokens": [51000, 1436, 7544, 625, 88, 12, 50, 494, 66, 6759, 20904, 51132], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 695, "seek": 232358, "start": 2338.94, "end": 2341.86, "text": " rule out the existence of evaluations.", "tokens": [51132, 4978, 484, 264, 9123, 295, 43085, 13, 51278], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 696, "seek": 232358, "start": 2341.86, "end": 2345.22, "text": " And if we represent all measurements", "tokens": [51278, 400, 498, 321, 2906, 439, 15383, 51446], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 697, "seek": 232358, "start": 2345.22, "end": 2347.22, "text": " as random variables in the same,", "tokens": [51446, 382, 4974, 9102, 294, 264, 912, 11, 51546], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 698, "seek": 232358, "start": 2347.22, "end": 2349.02, "text": " sharing the same sample space,", "tokens": [51546, 5414, 264, 912, 6889, 1901, 11, 51636], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 699, "seek": 232358, "start": 2349.02, "end": 2352.54, "text": " a point of the sample space would be evaluation.", "tokens": [51636, 257, 935, 295, 264, 6889, 1901, 576, 312, 13344, 13, 51812], "temperature": 0.0, "avg_logprob": -0.14164850534486376, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.0010293966624885798}, {"id": 700, "seek": 235254, "start": 2352.58, "end": 2357.58, "text": " So how can you avoid Cauchy-Speccher theorem", "tokens": [50366, 407, 577, 393, 291, 5042, 7544, 625, 88, 12, 50, 494, 66, 6759, 20904, 50616], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 701, "seek": 235254, "start": 2359.42, "end": 2360.82, "text": " within this approach?", "tokens": [50708, 1951, 341, 3109, 30, 50778], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 702, "seek": 235254, "start": 2360.82, "end": 2362.06, "text": " That's my question.", "tokens": [50778, 663, 311, 452, 1168, 13, 50840], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 703, "seek": 235254, "start": 2364.22, "end": 2367.42, "text": " If I understand your question correctly,", "tokens": [50948, 759, 286, 1223, 428, 1168, 8944, 11, 51108], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 704, "seek": 235254, "start": 2367.42, "end": 2371.62, "text": " you're asking how I avoid Cauchy-Speccher and we don't.", "tokens": [51108, 291, 434, 3365, 577, 286, 5042, 7544, 625, 88, 12, 50, 494, 66, 6759, 293, 321, 500, 380, 13, 51318], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 705, "seek": 235254, "start": 2371.62, "end": 2376.62, "text": " Let me go back to the GHZ case,", "tokens": [51318, 961, 385, 352, 646, 281, 264, 40690, 57, 1389, 11, 51568], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 706, "seek": 235254, "start": 2378.06, "end": 2380.94, "text": " which is a, so the difference", "tokens": [51640, 597, 307, 257, 11, 370, 264, 2649, 51784], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 707, "seek": 235254, "start": 2380.94, "end": 2382.46, "text": " between GHZ and Cauchy-Speccher", "tokens": [51784, 1296, 40690, 57, 293, 7544, 625, 88, 12, 50, 494, 66, 6759, 51860], "temperature": 0.0, "avg_logprob": -0.2137344479560852, "compression_ratio": 1.5136612021857923, "no_speech_prob": 0.0002130291104549542}, {"id": 708, "seek": 238246, "start": 2382.46, "end": 2385.78, "text": " that GHZ is for a specific state", "tokens": [50364, 300, 40690, 57, 307, 337, 257, 2685, 1785, 50530], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 709, "seek": 238246, "start": 2385.78, "end": 2388.42, "text": " and Cauchy-Speccher is for any state, right?", "tokens": [50530, 293, 7544, 625, 88, 12, 50, 494, 66, 6759, 307, 337, 604, 1785, 11, 558, 30, 50662], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 710, "seek": 238246, "start": 2388.42, "end": 2393.42, "text": " It's about the algebra of quantum observables.", "tokens": [50662, 467, 311, 466, 264, 21989, 295, 13018, 9951, 2965, 13, 50912], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 711, "seek": 238246, "start": 2394.66, "end": 2397.62, "text": " But you could think of Cauchy-Speccher", "tokens": [50974, 583, 291, 727, 519, 295, 7544, 625, 88, 12, 50, 494, 66, 6759, 51122], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 712, "seek": 238246, "start": 2397.62, "end": 2402.62, "text": " as a series of measurements that prepare a state", "tokens": [51122, 382, 257, 2638, 295, 15383, 300, 5940, 257, 1785, 51372], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 713, "seek": 238246, "start": 2402.62, "end": 2405.42, "text": " and then later on you get a contradiction.", "tokens": [51372, 293, 550, 1780, 322, 291, 483, 257, 34937, 13, 51512], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 714, "seek": 238246, "start": 2405.42, "end": 2407.78, "text": " That's a different way to think about Cauchy-Speccher,", "tokens": [51512, 663, 311, 257, 819, 636, 281, 519, 466, 7544, 625, 88, 12, 50, 494, 66, 6759, 11, 51630], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 715, "seek": 238246, "start": 2407.78, "end": 2410.9, "text": " but it's all there together.", "tokens": [51630, 457, 309, 311, 439, 456, 1214, 13, 51786], "temperature": 0.0, "avg_logprob": -0.13066077009539737, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.0005701709305867553}, {"id": 716, "seek": 241090, "start": 2410.9, "end": 2415.9, "text": " But this is the GHZ also has a contradiction, right?", "tokens": [50364, 583, 341, 307, 264, 40690, 57, 611, 575, 257, 34937, 11, 558, 30, 50614], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 717, "seek": 241090, "start": 2416.2200000000003, "end": 2418.94, "text": " And the contradiction comes here", "tokens": [50630, 400, 264, 34937, 1487, 510, 50766], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 718, "seek": 241090, "start": 2418.94, "end": 2421.6600000000003, "text": " from this guy in the bottom.", "tokens": [50766, 490, 341, 2146, 294, 264, 2767, 13, 50902], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 719, "seek": 241090, "start": 2421.6600000000003, "end": 2424.58, "text": " This first parenthesis being one times one times one", "tokens": [50902, 639, 700, 23350, 9374, 885, 472, 1413, 472, 1413, 472, 51048], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 720, "seek": 241090, "start": 2424.58, "end": 2426.34, "text": " being equal to minus one.", "tokens": [51048, 885, 2681, 281, 3175, 472, 13, 51136], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 721, "seek": 241090, "start": 2426.34, "end": 2428.46, "text": " It's the same type of contradiction", "tokens": [51136, 467, 311, 264, 912, 2010, 295, 34937, 51242], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 722, "seek": 241090, "start": 2428.46, "end": 2430.98, "text": " that you get on Cauchy-Speccher.", "tokens": [51242, 300, 291, 483, 322, 7544, 625, 88, 12, 50, 494, 66, 6759, 13, 51368], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 723, "seek": 241090, "start": 2430.98, "end": 2434.38, "text": " And you are using random variables", "tokens": [51368, 400, 291, 366, 1228, 4974, 9102, 51538], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 724, "seek": 241090, "start": 2434.38, "end": 2438.94, "text": " because each one of them individually are random.", "tokens": [51538, 570, 1184, 472, 295, 552, 16652, 366, 4974, 13, 51766], "temperature": 0.0, "avg_logprob": -0.10274698336919148, "compression_ratio": 1.6291079812206573, "no_speech_prob": 0.00012147583038313314}, {"id": 725, "seek": 243894, "start": 2438.94, "end": 2442.26, "text": " But if you look at each one of those products,", "tokens": [50364, 583, 498, 291, 574, 412, 1184, 472, 295, 729, 3383, 11, 50530], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 726, "seek": 243894, "start": 2442.26, "end": 2445.2200000000003, "text": " if you thought of them as an individual random variable,", "tokens": [50530, 498, 291, 1194, 295, 552, 382, 364, 2609, 4974, 7006, 11, 50678], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 727, "seek": 243894, "start": 2445.2200000000003, "end": 2447.42, "text": " let's say we call this product A,", "tokens": [50678, 718, 311, 584, 321, 818, 341, 1674, 316, 11, 50788], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 728, "seek": 243894, "start": 2447.42, "end": 2450.98, "text": " we call this product B and we call this product C.", "tokens": [50788, 321, 818, 341, 1674, 363, 293, 321, 818, 341, 1674, 383, 13, 50966], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 729, "seek": 243894, "start": 2450.98, "end": 2455.3, "text": " What we have is that A times B times C is equal to D.", "tokens": [50966, 708, 321, 362, 307, 300, 316, 1413, 363, 1413, 383, 307, 2681, 281, 413, 13, 51182], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 730, "seek": 243894, "start": 2456.9, "end": 2460.86, "text": " But this is what quantum mechanics tells us,", "tokens": [51262, 583, 341, 307, 437, 13018, 12939, 5112, 505, 11, 51460], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 731, "seek": 243894, "start": 2460.86, "end": 2463.14, "text": " but A is equal to one, B is equal to one", "tokens": [51460, 457, 316, 307, 2681, 281, 472, 11, 363, 307, 2681, 281, 472, 51574], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 732, "seek": 243894, "start": 2463.14, "end": 2465.9, "text": " and C is equal to one whereas D is equal to minus one.", "tokens": [51574, 293, 383, 307, 2681, 281, 472, 9735, 413, 307, 2681, 281, 3175, 472, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 733, "seek": 243894, "start": 2465.9, "end": 2467.3, "text": " That's the contradiction.", "tokens": [51712, 663, 311, 264, 34937, 13, 51782], "temperature": 0.0, "avg_logprob": -0.1046667988017454, "compression_ratio": 1.8423423423423424, "no_speech_prob": 0.00011591595830395818}, {"id": 734, "seek": 246730, "start": 2467.3, "end": 2469.6200000000003, "text": " And the random variables that we have here", "tokens": [50364, 400, 264, 4974, 9102, 300, 321, 362, 510, 50480], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 735, "seek": 246730, "start": 2469.6200000000003, "end": 2471.6800000000003, "text": " are deterministic random variables.", "tokens": [50480, 366, 15957, 3142, 4974, 9102, 13, 50583], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 736, "seek": 246730, "start": 2472.9, "end": 2476.5800000000004, "text": " So I don't know if I'm answering your question", "tokens": [50644, 407, 286, 500, 380, 458, 498, 286, 478, 13430, 428, 1168, 50828], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 737, "seek": 246730, "start": 2476.5800000000004, "end": 2478.46, "text": " the way you thought about it,", "tokens": [50828, 264, 636, 291, 1194, 466, 309, 11, 50922], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 738, "seek": 246730, "start": 2478.46, "end": 2481.26, "text": " but what I'm saying is we're not avoiding it.", "tokens": [50922, 457, 437, 286, 478, 1566, 307, 321, 434, 406, 20220, 309, 13, 51062], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 739, "seek": 246730, "start": 2481.26, "end": 2483.78, "text": " We have the contradictions there,", "tokens": [51062, 492, 362, 264, 15858, 15607, 456, 11, 51188], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 740, "seek": 246730, "start": 2483.78, "end": 2485.82, "text": " but the contradictions come", "tokens": [51188, 457, 264, 15858, 15607, 808, 51290], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 741, "seek": 246730, "start": 2485.82, "end": 2487.5800000000004, "text": " from the assumptions of Cauchy-Speccher.", "tokens": [51290, 490, 264, 17695, 295, 7544, 625, 88, 12, 50, 494, 66, 6759, 13, 51378], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 742, "seek": 246730, "start": 2487.5800000000004, "end": 2489.46, "text": " And the assumption of Cauchy-Speccher", "tokens": [51378, 400, 264, 15302, 295, 7544, 625, 88, 12, 50, 494, 66, 6759, 51472], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 743, "seek": 246730, "start": 2489.46, "end": 2493.98, "text": " is that this guy here, say Y2 in this context", "tokens": [51472, 307, 300, 341, 2146, 510, 11, 584, 398, 17, 294, 341, 4319, 51698], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 744, "seek": 246730, "start": 2493.98, "end": 2496.78, "text": " is the same as the Y2 in this context.", "tokens": [51698, 307, 264, 912, 382, 264, 398, 17, 294, 341, 4319, 13, 51838], "temperature": 0.0, "avg_logprob": -0.12892134487628937, "compression_ratio": 1.8016877637130801, "no_speech_prob": 0.0008829212747514248}, {"id": 745, "seek": 249678, "start": 2496.78, "end": 2499.2200000000003, "text": " And when we use negative probabilities,", "tokens": [50364, 400, 562, 321, 764, 3671, 33783, 11, 50486], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 746, "seek": 249678, "start": 2499.2200000000003, "end": 2502.1400000000003, "text": " that assumption is not true anymore", "tokens": [50486, 300, 15302, 307, 406, 2074, 3602, 50632], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 747, "seek": 249678, "start": 2502.1400000000003, "end": 2504.78, "text": " because negative probabilities", "tokens": [50632, 570, 3671, 33783, 50764], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 748, "seek": 249678, "start": 2504.78, "end": 2507.48, "text": " are washing out those requirements", "tokens": [50764, 366, 13836, 484, 729, 7728, 50899], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 749, "seek": 249678, "start": 2507.48, "end": 2511.0800000000004, "text": " of how is it that those random variables are related.", "tokens": [50899, 295, 577, 307, 309, 300, 729, 4974, 9102, 366, 4077, 13, 51079], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 750, "seek": 249678, "start": 2512.38, "end": 2515.7400000000002, "text": " And then what you're asking about,", "tokens": [51144, 400, 550, 437, 291, 434, 3365, 466, 11, 51312], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 751, "seek": 249678, "start": 2516.7000000000003, "end": 2519.0600000000004, "text": " if you were to ask me how exactly", "tokens": [51360, 498, 291, 645, 281, 1029, 385, 577, 2293, 51478], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 752, "seek": 249678, "start": 2519.0600000000004, "end": 2520.5, "text": " they are washing out those requirements,", "tokens": [51478, 436, 366, 13836, 484, 729, 7728, 11, 51550], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 753, "seek": 249678, "start": 2520.5, "end": 2522.86, "text": " I would tell, wow, I don't know.", "tokens": [51550, 286, 576, 980, 11, 6076, 11, 286, 500, 380, 458, 13, 51668], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 754, "seek": 249678, "start": 2522.86, "end": 2526.2200000000003, "text": " That's how we book keep those probabilities.", "tokens": [51668, 663, 311, 577, 321, 1446, 1066, 729, 33783, 13, 51836], "temperature": 0.0, "avg_logprob": -0.17164944127662896, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.0002611756499391049}, {"id": 755, "seek": 252622, "start": 2526.22, "end": 2528.1, "text": " If you wanna know how they are doing that,", "tokens": [50364, 759, 291, 1948, 458, 577, 436, 366, 884, 300, 11, 50458], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 756, "seek": 252622, "start": 2528.1, "end": 2530.2599999999998, "text": " then you would need to go to an interpretation", "tokens": [50458, 550, 291, 576, 643, 281, 352, 281, 364, 14174, 50566], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 757, "seek": 252622, "start": 2530.2599999999998, "end": 2533.22, "text": " that is not a purely epistemic interpretation", "tokens": [50566, 300, 307, 406, 257, 17491, 2388, 468, 3438, 14174, 50714], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 758, "seek": 252622, "start": 2533.22, "end": 2534.2999999999997, "text": " as in bookkeeping.", "tokens": [50714, 382, 294, 1446, 25769, 13, 50768], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 759, "seek": 252622, "start": 2535.7, "end": 2538.7, "text": " And there's nothing that forbids you from doing that, right?", "tokens": [50838, 400, 456, 311, 1825, 300, 16603, 3742, 291, 490, 884, 300, 11, 558, 30, 50988], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 760, "seek": 252622, "start": 2540.3799999999997, "end": 2541.8999999999996, "text": " Does that make sense, what I'm saying?", "tokens": [51072, 4402, 300, 652, 2020, 11, 437, 286, 478, 1566, 30, 51148], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 761, "seek": 252622, "start": 2541.8999999999996, "end": 2545.14, "text": " Or am I being confused here, confusing?", "tokens": [51148, 1610, 669, 286, 885, 9019, 510, 11, 13181, 30, 51310], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 762, "seek": 252622, "start": 2545.14, "end": 2547.8999999999996, "text": " Yeah, yeah, no, it makes sense.", "tokens": [51310, 865, 11, 1338, 11, 572, 11, 309, 1669, 2020, 13, 51448], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 763, "seek": 252622, "start": 2547.8999999999996, "end": 2549.22, "text": " Thanks, thank you.", "tokens": [51448, 2561, 11, 1309, 291, 13, 51514], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 764, "seek": 252622, "start": 2551.8199999999997, "end": 2554.7799999999997, "text": " Okay, we are done of the break.", "tokens": [51644, 1033, 11, 321, 366, 1096, 295, 264, 1821, 13, 51792], "temperature": 0.0, "avg_logprob": -0.23930794852120535, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.0005431725876405835}, {"id": 765, "seek": 255478, "start": 2554.78, "end": 2558.1200000000003, "text": " So, but there is one more question.", "tokens": [50364, 407, 11, 457, 456, 307, 472, 544, 1168, 13, 50531], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 766, "seek": 255478, "start": 2560.0600000000004, "end": 2561.26, "text": " It is very fast.", "tokens": [50628, 467, 307, 588, 2370, 13, 50688], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 767, "seek": 255478, "start": 2561.26, "end": 2564.9, "text": " So perhaps I can make it, if it's okay with you.", "tokens": [50688, 407, 4317, 286, 393, 652, 309, 11, 498, 309, 311, 1392, 365, 291, 13, 50870], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 768, "seek": 255478, "start": 2564.9, "end": 2568.1000000000004, "text": " So it is just about the notion of contextuality", "tokens": [50870, 407, 309, 307, 445, 466, 264, 10710, 295, 35526, 507, 51030], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 769, "seek": 255478, "start": 2568.1000000000004, "end": 2569.94, "text": " that you seem to be using.", "tokens": [51030, 300, 291, 1643, 281, 312, 1228, 13, 51122], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 770, "seek": 255478, "start": 2571.1400000000003, "end": 2572.9, "text": " I'm just curious if you are familiar", "tokens": [51182, 286, 478, 445, 6369, 498, 291, 366, 4963, 51270], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 771, "seek": 255478, "start": 2572.9, "end": 2576.5400000000004, "text": " with the work of Speckens and this idea", "tokens": [51270, 365, 264, 589, 295, 3550, 547, 694, 293, 341, 1558, 51452], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 772, "seek": 255478, "start": 2576.5400000000004, "end": 2579.34, "text": " of using a different definition of contextuality", "tokens": [51452, 295, 1228, 257, 819, 7123, 295, 35526, 507, 51592], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 773, "seek": 255478, "start": 2579.34, "end": 2583.1400000000003, "text": " than the one that seems to be used in Gohan Specker", "tokens": [51592, 813, 264, 472, 300, 2544, 281, 312, 1143, 294, 1037, 3451, 3550, 9178, 51782], "temperature": 0.0, "avg_logprob": -0.25391732729398286, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.001442187582142651}, {"id": 774, "seek": 258314, "start": 2583.14, "end": 2587.42, "text": " and in Bell's proof of non-contextuality.", "tokens": [50364, 293, 294, 11485, 311, 8177, 295, 2107, 12, 9000, 3828, 901, 507, 13, 50578], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 775, "seek": 258314, "start": 2588.42, "end": 2591.98, "text": " And if that makes a difference in the kind of project", "tokens": [50628, 400, 498, 300, 1669, 257, 2649, 294, 264, 733, 295, 1716, 50806], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 776, "seek": 258314, "start": 2591.98, "end": 2596.98, "text": " that you are using to accommodate all of contextuality", "tokens": [50806, 300, 291, 366, 1228, 281, 21410, 439, 295, 35526, 507, 51056], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 777, "seek": 258314, "start": 2597.8599999999997, "end": 2599.94, "text": " using negative probabilities.", "tokens": [51100, 1228, 3671, 33783, 13, 51204], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 778, "seek": 258314, "start": 2601.3399999999997, "end": 2604.06, "text": " Yeah, that's a good question.", "tokens": [51274, 865, 11, 300, 311, 257, 665, 1168, 13, 51410], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 779, "seek": 258314, "start": 2606.62, "end": 2610.58, "text": " One could give a whole talk about like different ways", "tokens": [51538, 1485, 727, 976, 257, 1379, 751, 466, 411, 819, 2098, 51736], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 780, "seek": 258314, "start": 2610.58, "end": 2612.8599999999997, "text": " of thinking about contextuality, right?", "tokens": [51736, 295, 1953, 466, 35526, 507, 11, 558, 30, 51850], "temperature": 0.0, "avg_logprob": -0.18800368309020996, "compression_ratio": 1.558974358974359, "no_speech_prob": 0.0006845801253803074}, {"id": 781, "seek": 261286, "start": 2612.86, "end": 2615.9, "text": " So I've been very casual about talking", "tokens": [50364, 407, 286, 600, 668, 588, 13052, 466, 1417, 50516], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 782, "seek": 261286, "start": 2615.9, "end": 2619.82, "text": " about contextuality here and very specific about it.", "tokens": [50516, 466, 35526, 507, 510, 293, 588, 2685, 466, 309, 13, 50712], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 783, "seek": 261286, "start": 2619.82, "end": 2624.7000000000003, "text": " But it's unclear exactly how those different notions", "tokens": [50712, 583, 309, 311, 25636, 2293, 577, 729, 819, 35799, 50956], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 784, "seek": 261286, "start": 2624.7000000000003, "end": 2627.6600000000003, "text": " of contextuality relate to each other.", "tokens": [50956, 295, 35526, 507, 10961, 281, 1184, 661, 13, 51104], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 785, "seek": 261286, "start": 2627.6600000000003, "end": 2630.78, "text": " Sometimes, not all the time, right?", "tokens": [51104, 4803, 11, 406, 439, 264, 565, 11, 558, 30, 51260], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 786, "seek": 261286, "start": 2630.78, "end": 2635.78, "text": " And to be very precise, one would need to prove", "tokens": [51260, 400, 281, 312, 588, 13600, 11, 472, 576, 643, 281, 7081, 51510], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 787, "seek": 261286, "start": 2639.2200000000003, "end": 2642.38, "text": " what is the relationship between one definition", "tokens": [51682, 437, 307, 264, 2480, 1296, 472, 7123, 51840], "temperature": 0.0, "avg_logprob": -0.14248239077054536, "compression_ratio": 1.5671641791044777, "no_speech_prob": 0.00011957419337704778}, {"id": 788, "seek": 264238, "start": 2642.38, "end": 2645.9, "text": " of contextuality and another definition of contextuality.", "tokens": [50364, 295, 35526, 507, 293, 1071, 7123, 295, 35526, 507, 13, 50540], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 789, "seek": 264238, "start": 2645.9, "end": 2649.3, "text": " And as far as I know, that has not been done", "tokens": [50540, 400, 382, 1400, 382, 286, 458, 11, 300, 575, 406, 668, 1096, 50710], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 790, "seek": 264238, "start": 2649.3, "end": 2651.62, "text": " for all notions of contextuality.", "tokens": [50710, 337, 439, 35799, 295, 35526, 507, 13, 50826], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 791, "seek": 264238, "start": 2651.62, "end": 2654.42, "text": " But there is this intuition that they kind of like", "tokens": [50826, 583, 456, 307, 341, 24002, 300, 436, 733, 295, 411, 50966], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 792, "seek": 264238, "start": 2654.42, "end": 2656.58, "text": " are talking about the same thing.", "tokens": [50966, 366, 1417, 466, 264, 912, 551, 13, 51074], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 793, "seek": 264238, "start": 2656.58, "end": 2658.26, "text": " Because at the end of the day,", "tokens": [51074, 1436, 412, 264, 917, 295, 264, 786, 11, 51158], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 794, "seek": 264238, "start": 2658.26, "end": 2662.06, "text": " they're all about commasurable properties", "tokens": [51158, 436, 434, 439, 466, 800, 296, 25863, 7221, 51348], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 795, "seek": 264238, "start": 2662.06, "end": 2664.3, "text": " and how those commasurable properties", "tokens": [51348, 293, 577, 729, 800, 296, 25863, 7221, 51460], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 796, "seek": 264238, "start": 2664.3, "end": 2669.06, "text": " somehow are related to not having a possibility", "tokens": [51460, 6063, 366, 4077, 281, 406, 1419, 257, 7959, 51698], "temperature": 0.0, "avg_logprob": -0.134373094617706, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0003979266039095819}, {"id": 797, "seek": 266906, "start": 2669.1, "end": 2672.42, "text": " of talking about all of those properties at the same time,", "tokens": [50366, 295, 1417, 466, 439, 295, 729, 7221, 412, 264, 912, 565, 11, 50532], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 798, "seek": 266906, "start": 2673.98, "end": 2676.02, "text": " in terms of the intuition behind them.", "tokens": [50610, 294, 2115, 295, 264, 24002, 2261, 552, 13, 50712], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 799, "seek": 266906, "start": 2678.66, "end": 2680.1, "text": " I know I'm not answering your question", "tokens": [50844, 286, 458, 286, 478, 406, 13430, 428, 1168, 50916], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 800, "seek": 266906, "start": 2680.1, "end": 2682.22, "text": " and the reason why I'm not answering your question", "tokens": [50916, 293, 264, 1778, 983, 286, 478, 406, 13430, 428, 1168, 51022], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 801, "seek": 266906, "start": 2682.22, "end": 2683.94, "text": " is because I'm trying to say that I don't think", "tokens": [51022, 307, 570, 286, 478, 1382, 281, 584, 300, 286, 500, 380, 519, 51108], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 802, "seek": 266906, "start": 2683.94, "end": 2688.1, "text": " there is a very clear answer to that question yet.", "tokens": [51108, 456, 307, 257, 588, 1850, 1867, 281, 300, 1168, 1939, 13, 51316], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 803, "seek": 266906, "start": 2688.1, "end": 2691.02, "text": " But we hope that once we give a definition", "tokens": [51316, 583, 321, 1454, 300, 1564, 321, 976, 257, 7123, 51462], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 804, "seek": 266906, "start": 2691.02, "end": 2693.46, "text": " that's a measure theoretic definition,", "tokens": [51462, 300, 311, 257, 3481, 14308, 299, 7123, 11, 51584], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 805, "seek": 266906, "start": 2693.46, "end": 2696.22, "text": " that precise definition of negative probabilities", "tokens": [51584, 300, 13600, 7123, 295, 3671, 33783, 51722], "temperature": 0.0, "avg_logprob": -0.13112528507526106, "compression_ratio": 1.8017241379310345, "no_speech_prob": 0.002018728293478489}, {"id": 806, "seek": 269622, "start": 2696.22, "end": 2701.02, "text": " that correspond to also a definition of contextuality", "tokens": [50364, 300, 6805, 281, 611, 257, 7123, 295, 35526, 507, 50604], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 807, "seek": 269622, "start": 2701.02, "end": 2705.22, "text": " in that setup, that you can use that to prove theorems", "tokens": [50604, 294, 300, 8657, 11, 300, 291, 393, 764, 300, 281, 7081, 10299, 2592, 50814], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 808, "seek": 269622, "start": 2705.22, "end": 2708.8599999999997, "text": " about how those things are related.", "tokens": [50814, 466, 577, 729, 721, 366, 4077, 13, 50996], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 809, "seek": 269622, "start": 2708.8599999999997, "end": 2712.2999999999997, "text": " It might be really, really interesting to explore that", "tokens": [50996, 467, 1062, 312, 534, 11, 534, 1880, 281, 6839, 300, 51168], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 810, "seek": 269622, "start": 2712.2999999999997, "end": 2715.66, "text": " for two reasons, because the kind of definition", "tokens": [51168, 337, 732, 4112, 11, 570, 264, 733, 295, 7123, 51336], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 811, "seek": 269622, "start": 2715.66, "end": 2718.58, "text": " that the Speckens uses makes no explicit reference", "tokens": [51336, 300, 264, 3550, 547, 694, 4960, 1669, 572, 13691, 6408, 51482], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 812, "seek": 269622, "start": 2718.58, "end": 2721.7, "text": " to the idea of measuring two things at the same time.", "tokens": [51482, 281, 264, 1558, 295, 13389, 732, 721, 412, 264, 912, 565, 13, 51638], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 813, "seek": 269622, "start": 2721.7, "end": 2725.8199999999997, "text": " It is kind of different to the general idea.", "tokens": [51638, 467, 307, 733, 295, 819, 281, 264, 2674, 1558, 13, 51844], "temperature": 0.0, "avg_logprob": -0.18893566910101442, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.002112844493240118}, {"id": 814, "seek": 272582, "start": 2725.82, "end": 2728.6200000000003, "text": " And two, because in the original paper,", "tokens": [50364, 400, 732, 11, 570, 294, 264, 3380, 3035, 11, 50504], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 815, "seek": 272582, "start": 2728.6200000000003, "end": 2730.78, "text": " I think that that's from 25,", "tokens": [50504, 286, 519, 300, 300, 311, 490, 3552, 11, 50612], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 816, "seek": 272582, "start": 2730.78, "end": 2733.9, "text": " he has a small derivation of showing that", "tokens": [50612, 415, 575, 257, 1359, 10151, 399, 295, 4099, 300, 50768], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 817, "seek": 272582, "start": 2733.9, "end": 2737.5, "text": " from his definition, you can derive the traditional one,", "tokens": [50768, 490, 702, 7123, 11, 291, 393, 28446, 264, 5164, 472, 11, 50948], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 818, "seek": 272582, "start": 2737.5, "end": 2739.82, "text": " the one that the Cohen Speckens used.", "tokens": [50948, 264, 472, 300, 264, 32968, 3550, 547, 694, 1143, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 819, "seek": 272582, "start": 2739.82, "end": 2744.38, "text": " So there must be a connection.", "tokens": [51064, 407, 456, 1633, 312, 257, 4984, 13, 51292], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 820, "seek": 272582, "start": 2744.38, "end": 2747.6200000000003, "text": " Yeah, yeah, yeah, that's what I'm saying.", "tokens": [51292, 865, 11, 1338, 11, 1338, 11, 300, 311, 437, 286, 478, 1566, 13, 51454], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 821, "seek": 272582, "start": 2749.1000000000004, "end": 2751.26, "text": " All those things are related,", "tokens": [51528, 1057, 729, 721, 366, 4077, 11, 51636], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 822, "seek": 272582, "start": 2751.26, "end": 2755.5, "text": " but how exactly they are related, it's not.", "tokens": [51636, 457, 577, 2293, 436, 366, 4077, 11, 309, 311, 406, 13, 51848], "temperature": 0.0, "avg_logprob": -0.19369250077467698, "compression_ratio": 1.592760180995475, "no_speech_prob": 0.00037935684667900205}, {"id": 823, "seek": 275550, "start": 2756.26, "end": 2758.86, "text": " Intuitively, yes, they should be related,", "tokens": [50402, 5681, 1983, 3413, 11, 2086, 11, 436, 820, 312, 4077, 11, 50532], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 824, "seek": 275550, "start": 2758.86, "end": 2761.3, "text": " but it's one thing to think that they should be related", "tokens": [50532, 457, 309, 311, 472, 551, 281, 519, 300, 436, 820, 312, 4077, 50654], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 825, "seek": 275550, "start": 2761.3, "end": 2763.74, "text": " intuitively and to prove that they're related.", "tokens": [50654, 46506, 293, 281, 7081, 300, 436, 434, 4077, 13, 50776], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 826, "seek": 275550, "start": 2763.74, "end": 2765.82, "text": " So that's what I was trying to say.", "tokens": [50776, 407, 300, 311, 437, 286, 390, 1382, 281, 584, 13, 50880], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 827, "seek": 275550, "start": 2768.54, "end": 2773.1, "text": " Thank you, Jose, and the people who have questions", "tokens": [51016, 1044, 291, 11, 8635, 11, 293, 264, 561, 567, 362, 1651, 51244], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 828, "seek": 275550, "start": 2773.1, "end": 2775.74, "text": " would have some minutes to go to the bathroom", "tokens": [51244, 576, 362, 512, 2077, 281, 352, 281, 264, 8687, 51376], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 829, "seek": 275550, "start": 2775.74, "end": 2777.22, "text": " or take a coffee.", "tokens": [51376, 420, 747, 257, 4982, 13, 51450], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}, {"id": 830, "seek": 275550, "start": 2777.22, "end": 2778.06, "text": " We will back.", "tokens": [51450, 492, 486, 646, 13, 51492], "temperature": 0.0, "avg_logprob": -0.24505998871543191, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.0006147552048787475}], "language": "en"}