{"text": " Thanks, and now we move on to the next speaker of this morning's session with Alison Desin. Please, Alison, if you can start sharing your screen. Can you hear me? Yes, perfectly. And also, perhaps it's better if you put a full screen mode. Okay. Okay. Okay, so the next speaker is Alison Desin from the University of Sao Paulo, Brazil, and he's talking about are we witnessing non-local phenomena when non-contextuality inequalities are violated? Please, Alison, go on. Okay, so I'd like to thank the organizers for having attended my talk, and congratulations for this very nice conference, and it's a pleasure to be here. And so, as you see, this talk is about a question, and the question is if we are witnessing non-classical phenomena when non-contextuality inequalities are violated? And I would like to begin this presentation by just finding this question. And in order to do that, I will show a couple of examples of very recent papers where this claim is made. So the claim that contextuality, which means by which I mean the violation of a non-contextuality inequality, is some kind of signature of non-classicality. So these are the examples. So contextuality is a non-classical behavior that can be exhibited by quantum systems. It's a non-classical feature challenging everyday intuition. It's a non-classical property exhibited by quantum statistics. It's a key signature of non-classicality. And finally, it's their catapult on classical feature of quantum phenomenology. So we know that this is a common view. And in order to contrast contextuality and classicality, let me explain what I mean by classicality. And I will do that basically by quoting this paper. And the main point is that as I see it, a criterion for classicality must have a phenomenological meaning. So as they say in this paper, a criterion of classicality must allow us to say that in some sense, nature fails to respect classical physics. So non-classical phenomena must defy classical understanding. And this is basically what I expect from a criterion of classicality. So we can now rephrase our initial question, just to be more explicitly. And we are asking if nature fails to respect classical physics when non-contextuality and equivalence are violated. Okay, so now let's discuss non-contextuality and equivalence. And this definition of contextuality that is the violation of non-contextuality and equivalence, it's a very operational definition in the sense that it's a definition we apply for experimental data. So contextuality. Wait, wait, there's something I will try to move Federico. Everyone please move their phones. Sorry, Allison, please go on. Okay. Okay, so as I said, this is an operational definition, the sense that it's a label we apply for experimental data. And this idea of contextuality as something that we can apply for data with no reference to the underlying structure of the mechanism we are working with, it's a definition that arises in the context of this model independent approach to physics. So I will discuss this model independent approach very briefly because I think some of you may not be familiar with it. And the core idea behind model independent approach to physics is this idea of a black box. And a black box is a measurement setup. And we say we call it a black box because we assume that we can ignore the underlying structure of this setup and we can look onto the data. So as Popesco says, according to this view, the entire physics should be encapsulated in the data. And we can discuss, for example, locality from this perspective. So we can discuss locality beyond quantum mechanics. So with no reference to quantum systems. So all we need are devices and measurements that are outputs. And we can also discuss contextuality in this perspective. And this is exactly the definition of contextuality that is based on non-contextuality in equities. So contextuality is the violation of non-contextuality in equities, just as non-locality is the violation of the inequalities. Or we can equivalently say that contextuality corresponds to the existence of global sections. So this is equivalent to say that contextuality is the violation of non-contextuality in equities. And just to make it clear that this idea of black box appears in contextuality analysis, I will show two examples. So here they say that we have a black box and that the agent consumes the box by simultaneously performing a subset of measurements. And a subset of measurements that we can simultaneously perform is what we call a context. And here they say the same. So we have a black box that is a device containing buttons and lights. And buttons represent measurements and lights represent outcomes or outputs. And we have contexts that are collections of buttons that we can press jointly. And okay, so these are some pictures representing this idea of black box in contextuality analysis. So here we see that we have a black box with inputs that are buttons or measurements and outputs that are represented as lights. So okay, so this is basically this this model independent view. And now we will show a particular example of black box. And we will discuss this example using the compatibility hypergraph approach to contextuality. That is one of many model independent approach to contextuality analysis. And we have to introduce a measurement scenario in order to define a black box. And the measurement scenario we consider is a very standard example of a measurement scenario in contextuality analysis. That is the device cycle. So in this scenario, we have only five measurements. And all measurements of this scenario are binary. So they have only two possible outcomes. So one and zero. And this is the symbol we call one. And this is the symbol we call zero. Okay, and we also have to define a context. So we call that a context represents a collection of measurements that can be measured simultaneously. And these are the contexts we consider in the five cycle. So a context in this scenario is a pair of consecutive measurements. So for example, a one, a two is a context, a three, a four is a context, a four, a zero is not a context, and so on. So we have five contexts. And as I said, this is a very standard example of measurement scenario for contextuality analysis. So these measurements are like the buttons of our black box. And now we have to introduce a behavior for this scenario. That is the data our black box generates. And the behavior we consider is a very famous example of contextual behavior in the five cycle. And the behavior and it's this behavior. So by definition in contextual analysis, the behavior of a scenario is context dependent. So we associate a probability distribution for each context. And this is the distribution we associate for a context in the five cycle. So, so if we measure together AI and AI plus one, we will never obtain the same outcome. And the probability of obtaining zero one or one zero is the same. And this is this is the data our black box generates. So this is the behavior of our box of our box. And okay, and what we can say about this behavior. So first of all, it's not disturbing, which means that according to this behavior, it means that a measurement has the same distribution across all contexts. And moreover, according to this behavior, a measurement behaves like a coin toss. And this is one of the reasons why we are calling this behavior a generalized coin toss. This behavior is an example of stronger than quantum correlation, which means that quantum theory cannot predict this behavior. And finally, this behavior is contextual. So it violates a non contextuality inequality or equivalently, we cannot define a global section for this behavior. So it means that we cannot define a probability distribution, including all measurements of this scenario that is capable of predicting this behavior. So, and this is an example of a maximum contextual behavior in the five cycle. And this is why this example is very famous. Okay. And in the in the compatibility hydrograph approach, contextuality and nonclassicality are equivalence definitions. So according to this approach, if our black box generates this this data, then then we have to say that our black box generates non classical correlations. Okay. So thus far, we have discussed contextuality from this model independent view. And we have showed a very famous example of contextual behavior in the five cycle. So this is the data our box generate. And this is the data we are going to analyze. Okay, but now I will let's let's look inside the the box. And your and to begin with, I would like to compare on the balance with contextuality and equities because as I said, contextuality, according to this definition is the violation of non contextuality and equities, just as no locality is the violation of very equities from this model independent perspective. So let's compare these two definitions. So suppose we have a bell scenario. So it's a scenario containing two space like separated parts. So each part has a black box, and each part is performing measurements, and they are generating data together. And we analyze this data. And if it is data violate a bell inequality, we can say that we are witnessing a non local phenomenon, which means that and locality or non locality is a physical concept in the sense that we can define it in terms of physical principles. For example, we can define locality using using special relativity. And in this case, so in this case, the data we have is is intrinsically associated with a physical phenomenon. And we can really ignore the underlying structure of these boxes. So this this measurements, they can be, for example, questions, yes, no questions we ask for these agents. And these outputs can be answers they give. And if it in this case, if this if these bell inequalities are violated, we can say that we are we are witnessing no local phenomenon. So there is this physical phenomenon associated to the data we have. But in contextual analysis, we have no physical phenomenon associated to it, because contextuality according to this model independence definition is not a physical phenomenon, because we cannot define it in terms of physical principles. So it would not be a surprise if inside a box generating non classical correlations are contextual correlations, we had a a a simple classical structure. And, and I will try to show now that this is the case for the behavior we we we called a generalized coin toss. Okay, and before we go through the example, I would like to say three things about it. So first of all, recall that we are assuming here that everything is encapsulated in the data. So we can, in some sense, ignore the ignore the underlying structure of this black box. So a black box is a very permissive concept. So it may contain an entire laboratory containing particles and measuring devices. And also the the the mechanism we propose is basically a toy mechanism for coin tossing. And coin tossing is is according to many operational approach to physics, it's a valid example of measurement procedure. So for example, people who work with packing context reality and generalize the probability theories, they are all the time using coin tossing as an example of measuring procedure that is valid. So that's why we say that this mechanism works along the line set out in many operational approach. So according to these approach, if we had inside a black box a coin coin flip a coin tossing, it would be a valid measurement procedure. And more importantly, this this mechanism is something like a thought experiment. So we are trying to show that unlike no local data, no contextual data can be generated by a simple classical mechanism. So this mechanism should be understood as a thought experiment. So it's not a mechanism that is interesting by itself. So okay, now let's go through the the mechanism. And as I said, it's it's basically a toy mechanism for coin tossing. And how can we describe a coin toss using toy mechanism. So we need an object. So in the in the real world, we we use a coin that is an object has that for all practical purposes has two sides. So here in this time mechanism, we consider for the sake of simplicity, a 2D object, and each has two sides. So one side is dark gray, the other side is light gray. And we have we need to flip this object. So we fix an axis passing through the center of this object, and we flip this object. And at the end of the movement, we look to the side that is showing when the coin lands. So this is the real case. So in this toy mechanism, we we we fix this side of the object. So and we imagine that this is a sensor and the sensor can detect color that in this case is gray. And it can distinguish dark from light color. So we have these two outputs. So these outputs are like hazard tails. So they they are dark gray or light gray. And the behavior we obtain if we perform these measurements, these measurements. So if we flip this coin is the behavior of a fair conflict, because this mechanism is is constructed for for this purpose. So okay, so this is a toy mechanism for coin toss. And the point is that we can propose a straightforward generalization of this mechanism that is capable of generating the the behavior we call a generalized coin toss that, as I said, is a very famous example of contextual correlation, contextuality analysis. So a coin toss, we have one binary measurement. So we need an object having one pair of positive sides. But in the generalized coin toss, we have five pairs of positives. So we have five binary measurements. So we need an object having five pairs of positive sides. So it could be something like an unsided dice or something like this. And but we are proposing just a toy mechanism. So we consider a 2D object. And this is a regular decadent. And for each pair of positive sides, we associate a measurement. And for for its measurement, we associate a color. And okay, and the measurement procedure inside of this box is a coin flipping. But the the the flipping is determined in this case by the context. So the context in this toy mechanism is an axis passing through the center of the object. And together with a sensor and the sensor can detect color and it can distinguish that from each color. So for example, if we want to measure a two and a three together, if we press these buttons in our box, this mechanism will just flip this coin. But with respect to the axis that they're mined by this context, so this is the axis, this vertical line. And if we do that, we can obtain two possible outcomes. So we can detect dark yellow and light green, or we can detect light yellow and dark green. So we can never detect, for example, dark yellow and dark green because they are in a positive side of this object. So this is a mere geometrical restriction of the object. And this is why we have this, we have the correlation that is predicted by the generalized coin toss in this context. And this is the mechanism we have. So each context is an axis together with a sensor. And whatever is the context we consider, we have only these two possible outcomes and the behavior is the behavior we call a generalized coin toss. Okay. And we also must be able to measure single, to perform single measurements. And in order to do that, we have to fix a context. So this is the general case in contextual analysis. So for example, if we want to measure these measurements, A0, that is red, we have two options. So we have two contexts containing A0, and we have to choose one of them. So we can choose, for example, this context, and we just flip this object. And so we have two possible outcomes, so dark red or light red, and the behavior is the behavior of a fair coin slip. So to sum up, this mechanism, this time mechanism, or just thought experiment, generates the behavior we call a generalized coin toss. And okay, and what we can say based on this example, based on this thought experiment. So first of all, let's discuss contextuality beyond content theory. Okay, so the first point is that without clear specification of what measurement means, contextuality has no phenomenological significance. It means that the meaning of contextuality or the phenomenological meaning depends on what we mean by a measurement. So in contextual analysis, the underlying structure matters. So we cannot say that, I think that based on this thought experiment, I think this thought experiment suggests that we cannot ignore the underlying structure in order, when we are analyzing data from this perspective of contextuality. Which means that in contextuality analysis, the entire physics does not seem to be encapsulated in the data. So what we mean by measurement is important. And finally, contextuality, at least beyond content theory, does not require a non-classical phenomenon. Okay, and can we say something about contextuality in content theory, based on this thought experiment? And I think we can. So note that in our thought experiment, we are working with a classical object. So it's basically a coin. So it's a classical object in the sense that it's a rigid body. So it's just a thought mechanism. So we say it's a 2D object, but we can imagine it as a real body, just as we imagine a coin as a rigid body. And okay, so we have this classical object and measurements, our measurement procedures are not revealing perverts processed by the system. And also we have context. So not all measurements can be simultaneously performed. So we have this restriction that is an instrumental restriction. So this is part of our mechanism. So it means that in our experiment, we are working with measurements that I like to co-example, that are measurements that are not revealing perverts processed by a system. And we know that this view on measurement is a very common view on content measurements, because we have Cauchy's Becker theorem. And Cauchy's Becker theorem says that self-adjoint operators cannot be thought of as representing perverts simultaneously processed by a system. So Cauchy's Becker theorem suggests some kind of substantive view on measurements. So we have to accept that measurements are not revealing perverts processed by a system, or at least that they are not revealing perverts that are simultaneously processed by the system. But the point is that if the measurements we have are epistemic, so if the measurements we have are not revealing perverts of a system, then we have contextuality in the data. So the data our system generates will violate non-contextuality and equivalence. And it's not because the system is non-classical or it's classical, it's because measurements are epistemic. And the reasons that epistemic measurements cannot be defined as random variables share in the same sample space. So we cannot define the measurements because the measurements that are like coin flippings in our thought experiment, we cannot represent those measurements as random variables in the same sample space. And that's why we have contextuality in content systems, I think. And we must recall that KS theorem, Cauchy-Specker theorem is about realism, it's not about classicality. So to sum up, in quantum mechanics, we have, so in general, actually, if we have epistemic measurements, or if we have measurements that are not revealing perverts processed by a system, and if we have context, so if we have these restrictions on what we can measure jointly, then we have contextual data. So we have no ground for expecting non-contextuality in the data, because our measurements are not random variables in the same sample space. So I think that this thought experiment suggests that those who accept the epistemic view on measurements, that is the view suggested, for example, by the orthodox interpretation of this, this is the view hold by bar, and this is a very widespread view on quantum measurements in quantum mechanics. So those who accepted this view, I think that should not take for granted that nature fails to respect classical physics when quantum systems violate non-contextuality in the file. So it seems that these violations are actually our consequence of the type of measurements we are considering. And if we accept that the measurements we have in quantum systems are epistemic measurements, then we should be, we should not say that nature fails to respect classical physics when these violations occur. And that's it, that's what I had to say today. And thank you. Thanks, Alison. Thanks for this talk. So we have some time for one short question, because now we are on 9.56. So if someone has a question, please go on. So I have a question or perhaps an observation, which is you can see the violation of Bell inequalities as a particular case of a non-contextuality inequality, right? Because and when you speak about model independence, it is not so independent of physical laws, because in model independence, you have space-time structure. This is not the stress, usually in the literature about it, but otherwise, if you don't consider the space-time structure, you cannot speak about a model independence analysis of an analysis above scenario. You cannot even speak about space-like separation between measurements, you know? And so what I think regarding your talk is that perhaps this space-time causal structure should be taken into account into your analysis. I agree in that if you don't take space-like separation, you can reproduce everything with a classical mechanism. And I think that that is accepted, right? I mean, because you have examples of contextuality in, for example, in mathematical psychology and so on. I agree. But even so, I think that you can include the violation of Bell inequalities as a particular example of a violation of a non-contextuality inequality. So what do you think about that? That cannot be reproduced by any classical mechanism. What do you think about that? Yes, I agree. So that's why I contrast, I compare Bell inequalities with non-contextuality inequalities. So I know that Bell inequalities are particular case of non-contextuality inequalities. But by just saying that this idea of black box works very well if we have space-life separated parts. So I agree with it. But if we have a black box that is localized, so as the kind of box people use when they are discussing, for example, resource theory for contextuality. So we have this box with many inputs. So in this case, if we have contextual data, we not necessarily have a non-classical phenomenon or something like this. So I agree with it. So if the boxes are space-life separated, then we need non-locality. I see your point. Okay, I will check on the details because you have a paper on this, I've seen on the web. So I will check next week. But now we are on time. So we thank again Alison for this nice talk. Thank you. Thanks Alison. So now we call Diego to share your screen. So Alison, okay, great. So thanks Alison. So now we are on time for the Diego's talk. Great, great. So now we're glad to have Diego Boussandri from the Institute of Physics La Plata and the National University of La Plata. And he will speak about revisiting maximal fidelity of teleportation. Please Diego, go on. Thank you very much for the presentation. So let's talk. Diego, wait, your sound is low. You could speak like this and it's good, but if you could. Now? Now it's much better. Thanks, thanks. Please, go on. Thank you. Sorry. No problem, no problem. Now, okay, let's talk about then about fidelity of teleportation. This is a work we made with Madeira Portesi and Anna Mast\u00e9. And so what did we do? We obtained the maximal average fidelity of teleportation or the score of a given protocol for two situations, the standard quantum teleportation protocol characterized by a particular measurement. So one second. Now, we calculate so the maximal average fidelity of teleportation for the... The sound is again low. I don't know if everyone is... What happened? Now? Yeah, now it's better. Yes. Sorry, sorry. No problem. Then we obtained the average identity in two situations, the standard quantum teleportation protocol characterized by a particular measurement in which there is a projection onto the bell bus. And another protocol whose characteristic measurement is something in the middle between the computational basis and the bell, bell bus. But our differential feature is that we calculate this for isotropic distribution of input states, not only the heart measure. I mean not only your estimates. So we are going to talk about useful protocols. Namely, a protocol is useful when its average fidelity is greater than the classical one. Our key point or our main result is that when you take an average of a more general distribution than the heart measure, the quantum teleportation protocol can be useful when your resource has no quantum correlation. So even for a classical quantum estimate. Well, what is the meaning of the fidelity of teleportation? Let us suppose that we have a protocol p producing output s state given by rho a out with probability p i for an input s state or a qubit state given by rho a. And rho a is characterized by its block vector t. And so if you want to know how well the quantum teleportation was performed, you can quantify the similarity between rho a and the final output, calculating equation one. But this mesh", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.32, "text": " Thanks, and now we move on to the next speaker of this morning's session with Alison Desin.", "tokens": [50364, 2561, 11, 293, 586, 321, 1286, 322, 281, 264, 958, 8145, 295, 341, 2446, 311, 5481, 365, 41001, 3885, 259, 13, 50780], "temperature": 0.0, "avg_logprob": -0.28956117764325207, "compression_ratio": 1.4, "no_speech_prob": 0.0486271008849144}, {"id": 1, "seek": 0, "start": 8.32, "end": 12.08, "text": " Please, Alison, if you can start sharing your screen.", "tokens": [50780, 2555, 11, 41001, 11, 498, 291, 393, 722, 5414, 428, 2568, 13, 50968], "temperature": 0.0, "avg_logprob": -0.28956117764325207, "compression_ratio": 1.4, "no_speech_prob": 0.0486271008849144}, {"id": 2, "seek": 0, "start": 18.32, "end": 19.28, "text": " Can you hear me?", "tokens": [51280, 1664, 291, 1568, 385, 30, 51328], "temperature": 0.0, "avg_logprob": -0.28956117764325207, "compression_ratio": 1.4, "no_speech_prob": 0.0486271008849144}, {"id": 3, "seek": 0, "start": 20.0, "end": 25.04, "text": " Yes, perfectly. And also, perhaps it's better if you put a full screen mode.", "tokens": [51364, 1079, 11, 6239, 13, 400, 611, 11, 4317, 309, 311, 1101, 498, 291, 829, 257, 1577, 2568, 4391, 13, 51616], "temperature": 0.0, "avg_logprob": -0.28956117764325207, "compression_ratio": 1.4, "no_speech_prob": 0.0486271008849144}, {"id": 4, "seek": 0, "start": 25.68, "end": 26.0, "text": " Okay.", "tokens": [51648, 1033, 13, 51664], "temperature": 0.0, "avg_logprob": -0.28956117764325207, "compression_ratio": 1.4, "no_speech_prob": 0.0486271008849144}, {"id": 5, "seek": 2600, "start": 26.24, "end": 36.56, "text": " Okay. Okay, so the next speaker is Alison Desin from the University of Sao Paulo, Brazil,", "tokens": [50376, 1033, 13, 1033, 11, 370, 264, 958, 8145, 307, 41001, 3885, 259, 490, 264, 3535, 295, 6299, 78, 21801, 11, 9435, 11, 50892], "temperature": 0.0, "avg_logprob": -0.1678441583293758, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.013493546284735203}, {"id": 6, "seek": 2600, "start": 37.36, "end": 44.96, "text": " and he's talking about are we witnessing non-local phenomena when non-contextuality inequalities", "tokens": [50932, 293, 415, 311, 1417, 466, 366, 321, 39233, 2107, 12, 5842, 304, 22004, 562, 2107, 12, 9000, 3828, 901, 507, 41874, 51312], "temperature": 0.0, "avg_logprob": -0.1678441583293758, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.013493546284735203}, {"id": 7, "seek": 2600, "start": 44.96, "end": 53.36, "text": " are violated? Please, Alison, go on. Okay, so I'd like to thank the organizers for having", "tokens": [51312, 366, 33239, 30, 2555, 11, 41001, 11, 352, 322, 13, 1033, 11, 370, 286, 1116, 411, 281, 1309, 264, 35071, 337, 1419, 51732], "temperature": 0.0, "avg_logprob": -0.1678441583293758, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.013493546284735203}, {"id": 8, "seek": 5336, "start": 53.36, "end": 61.04, "text": " attended my talk, and congratulations for this very nice conference, and it's a pleasure to be here.", "tokens": [50364, 15990, 452, 751, 11, 293, 13568, 337, 341, 588, 1481, 7586, 11, 293, 309, 311, 257, 6834, 281, 312, 510, 13, 50748], "temperature": 0.0, "avg_logprob": -0.12590674943821403, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.025363512337207794}, {"id": 9, "seek": 5336, "start": 61.76, "end": 69.12, "text": " And so, as you see, this talk is about a question, and the question is if we are witnessing", "tokens": [50784, 400, 370, 11, 382, 291, 536, 11, 341, 751, 307, 466, 257, 1168, 11, 293, 264, 1168, 307, 498, 321, 366, 39233, 51152], "temperature": 0.0, "avg_logprob": -0.12590674943821403, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.025363512337207794}, {"id": 10, "seek": 5336, "start": 69.12, "end": 74.8, "text": " non-classical phenomena when non-contextuality inequalities are violated? And I would like", "tokens": [51152, 2107, 12, 11665, 804, 22004, 562, 2107, 12, 9000, 3828, 901, 507, 41874, 366, 33239, 30, 400, 286, 576, 411, 51436], "temperature": 0.0, "avg_logprob": -0.12590674943821403, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.025363512337207794}, {"id": 11, "seek": 5336, "start": 74.8, "end": 81.12, "text": " to begin this presentation by just finding this question. And in order to do that, I will show", "tokens": [51436, 281, 1841, 341, 5860, 538, 445, 5006, 341, 1168, 13, 400, 294, 1668, 281, 360, 300, 11, 286, 486, 855, 51752], "temperature": 0.0, "avg_logprob": -0.12590674943821403, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.025363512337207794}, {"id": 12, "seek": 8112, "start": 81.76, "end": 87.36, "text": " a couple of examples of very recent papers where this claim is made. So the claim that", "tokens": [50396, 257, 1916, 295, 5110, 295, 588, 5162, 10577, 689, 341, 3932, 307, 1027, 13, 407, 264, 3932, 300, 50676], "temperature": 0.0, "avg_logprob": -0.09092273507066952, "compression_ratio": 1.84, "no_speech_prob": 0.004897239618003368}, {"id": 13, "seek": 8112, "start": 87.36, "end": 94.16000000000001, "text": " contextuality, which means by which I mean the violation of a non-contextuality inequality,", "tokens": [50676, 35526, 507, 11, 597, 1355, 538, 597, 286, 914, 264, 22840, 295, 257, 2107, 12, 9000, 3828, 901, 507, 16970, 11, 51016], "temperature": 0.0, "avg_logprob": -0.09092273507066952, "compression_ratio": 1.84, "no_speech_prob": 0.004897239618003368}, {"id": 14, "seek": 8112, "start": 94.16000000000001, "end": 102.88000000000001, "text": " is some kind of signature of non-classicality. So these are the examples. So contextuality is a", "tokens": [51016, 307, 512, 733, 295, 13397, 295, 2107, 12, 11665, 804, 507, 13, 407, 613, 366, 264, 5110, 13, 407, 35526, 507, 307, 257, 51452], "temperature": 0.0, "avg_logprob": -0.09092273507066952, "compression_ratio": 1.84, "no_speech_prob": 0.004897239618003368}, {"id": 15, "seek": 8112, "start": 102.88000000000001, "end": 109.60000000000001, "text": " non-classical behavior that can be exhibited by quantum systems. It's a non-classical feature", "tokens": [51452, 2107, 12, 11665, 804, 5223, 300, 393, 312, 49446, 538, 13018, 3652, 13, 467, 311, 257, 2107, 12, 11665, 804, 4111, 51788], "temperature": 0.0, "avg_logprob": -0.09092273507066952, "compression_ratio": 1.84, "no_speech_prob": 0.004897239618003368}, {"id": 16, "seek": 10960, "start": 109.6, "end": 115.83999999999999, "text": " challenging everyday intuition. It's a non-classical property exhibited by quantum statistics.", "tokens": [50364, 7595, 7429, 24002, 13, 467, 311, 257, 2107, 12, 11665, 804, 4707, 49446, 538, 13018, 12523, 13, 50676], "temperature": 0.0, "avg_logprob": -0.1494811203168786, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0019743856973946095}, {"id": 17, "seek": 10960, "start": 117.03999999999999, "end": 122.64, "text": " It's a key signature of non-classicality. And finally, it's their catapult on classical", "tokens": [50736, 467, 311, 257, 2141, 13397, 295, 2107, 12, 11665, 804, 507, 13, 400, 2721, 11, 309, 311, 641, 3857, 569, 723, 322, 13735, 51016], "temperature": 0.0, "avg_logprob": -0.1494811203168786, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0019743856973946095}, {"id": 18, "seek": 10960, "start": 122.64, "end": 130.56, "text": " feature of quantum phenomenology. So we know that this is a common view. And in order to contrast", "tokens": [51016, 4111, 295, 13018, 9388, 1793, 13, 407, 321, 458, 300, 341, 307, 257, 2689, 1910, 13, 400, 294, 1668, 281, 8712, 51412], "temperature": 0.0, "avg_logprob": -0.1494811203168786, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0019743856973946095}, {"id": 19, "seek": 10960, "start": 130.56, "end": 136.64, "text": " contextuality and classicality, let me explain what I mean by classicality. And I will do that", "tokens": [51412, 35526, 507, 293, 13735, 507, 11, 718, 385, 2903, 437, 286, 914, 538, 13735, 507, 13, 400, 286, 486, 360, 300, 51716], "temperature": 0.0, "avg_logprob": -0.1494811203168786, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0019743856973946095}, {"id": 20, "seek": 13664, "start": 136.64, "end": 146.72, "text": " basically by quoting this paper. And the main point is that as I see it, a criterion for classicality", "tokens": [50364, 1936, 538, 41552, 341, 3035, 13, 400, 264, 2135, 935, 307, 300, 382, 286, 536, 309, 11, 257, 46691, 337, 13735, 507, 50868], "temperature": 0.0, "avg_logprob": -0.08461762898003877, "compression_ratio": 1.6432748538011697, "no_speech_prob": 0.004534263163805008}, {"id": 21, "seek": 13664, "start": 146.72, "end": 154.16, "text": " must have a phenomenological meaning. So as they say in this paper, a criterion of classicality", "tokens": [50868, 1633, 362, 257, 9388, 4383, 3620, 13, 407, 382, 436, 584, 294, 341, 3035, 11, 257, 46691, 295, 13735, 507, 51240], "temperature": 0.0, "avg_logprob": -0.08461762898003877, "compression_ratio": 1.6432748538011697, "no_speech_prob": 0.004534263163805008}, {"id": 22, "seek": 13664, "start": 154.88, "end": 161.92, "text": " must allow us to say that in some sense, nature fails to respect classical physics.", "tokens": [51276, 1633, 2089, 505, 281, 584, 300, 294, 512, 2020, 11, 3687, 18199, 281, 3104, 13735, 10649, 13, 51628], "temperature": 0.0, "avg_logprob": -0.08461762898003877, "compression_ratio": 1.6432748538011697, "no_speech_prob": 0.004534263163805008}, {"id": 23, "seek": 16192, "start": 162.88, "end": 169.28, "text": " So non-classical phenomena must defy classical understanding. And this is basically what I", "tokens": [50412, 407, 2107, 12, 11665, 804, 22004, 1633, 1060, 88, 13735, 3701, 13, 400, 341, 307, 1936, 437, 286, 50732], "temperature": 0.0, "avg_logprob": -0.08656208098880828, "compression_ratio": 1.5195530726256983, "no_speech_prob": 0.0016116019105538726}, {"id": 24, "seek": 16192, "start": 169.28, "end": 176.79999999999998, "text": " expect from a criterion of classicality. So we can now rephrase our initial question,", "tokens": [50732, 2066, 490, 257, 46691, 295, 13735, 507, 13, 407, 321, 393, 586, 319, 44598, 651, 527, 5883, 1168, 11, 51108], "temperature": 0.0, "avg_logprob": -0.08656208098880828, "compression_ratio": 1.5195530726256983, "no_speech_prob": 0.0016116019105538726}, {"id": 25, "seek": 16192, "start": 176.79999999999998, "end": 184.39999999999998, "text": " just to be more explicitly. And we are asking if nature fails to respect classical physics when", "tokens": [51108, 445, 281, 312, 544, 20803, 13, 400, 321, 366, 3365, 498, 3687, 18199, 281, 3104, 13735, 10649, 562, 51488], "temperature": 0.0, "avg_logprob": -0.08656208098880828, "compression_ratio": 1.5195530726256983, "no_speech_prob": 0.0016116019105538726}, {"id": 26, "seek": 18440, "start": 184.4, "end": 192.08, "text": " non-contextuality and equivalence are violated. Okay, so now let's discuss non-contextuality and", "tokens": [50364, 2107, 12, 9000, 3828, 901, 507, 293, 9052, 655, 366, 33239, 13, 1033, 11, 370, 586, 718, 311, 2248, 2107, 12, 9000, 3828, 901, 507, 293, 50748], "temperature": 0.0, "avg_logprob": -0.14310593922932943, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.025976408272981644}, {"id": 27, "seek": 18440, "start": 192.08, "end": 199.12, "text": " equivalence. And this definition of contextuality that is the violation of non-contextuality and", "tokens": [50748, 9052, 655, 13, 400, 341, 7123, 295, 35526, 507, 300, 307, 264, 22840, 295, 2107, 12, 9000, 3828, 901, 507, 293, 51100], "temperature": 0.0, "avg_logprob": -0.14310593922932943, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.025976408272981644}, {"id": 28, "seek": 18440, "start": 199.12, "end": 205.28, "text": " equivalence, it's a very operational definition in the sense that it's a definition we apply for", "tokens": [51100, 9052, 655, 11, 309, 311, 257, 588, 16607, 7123, 294, 264, 2020, 300, 309, 311, 257, 7123, 321, 3079, 337, 51408], "temperature": 0.0, "avg_logprob": -0.14310593922932943, "compression_ratio": 1.9594594594594594, "no_speech_prob": 0.025976408272981644}, {"id": 29, "seek": 20528, "start": 205.28, "end": 220.88, "text": " experimental data. So contextuality. Wait, wait, there's something I will try to move Federico.", "tokens": [50364, 17069, 1412, 13, 407, 4319, 901, 507, 13, 3802, 11, 1699, 11, 456, 311, 746, 286, 486, 853, 281, 1286, 45545, 2789, 13, 51144], "temperature": 0.0, "avg_logprob": -0.3037118911743164, "compression_ratio": 1.2388059701492538, "no_speech_prob": 0.0407349094748497}, {"id": 30, "seek": 20528, "start": 221.84, "end": 226.48, "text": " Everyone please move their phones. Sorry, Allison, please go on. Okay.", "tokens": [51192, 5198, 1767, 1286, 641, 10216, 13, 4919, 11, 32638, 11, 1767, 352, 322, 13, 1033, 13, 51424], "temperature": 0.0, "avg_logprob": -0.3037118911743164, "compression_ratio": 1.2388059701492538, "no_speech_prob": 0.0407349094748497}, {"id": 31, "seek": 22648, "start": 226.48, "end": 236.88, "text": " Okay, so as I said, this is an operational definition, the sense that it's a label we", "tokens": [50364, 1033, 11, 370, 382, 286, 848, 11, 341, 307, 364, 16607, 7123, 11, 264, 2020, 300, 309, 311, 257, 7645, 321, 50884], "temperature": 0.0, "avg_logprob": -0.14293296753414095, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.0025428375229239464}, {"id": 32, "seek": 22648, "start": 236.88, "end": 244.39999999999998, "text": " apply for experimental data. And this idea of contextuality as something that we can apply", "tokens": [50884, 3079, 337, 17069, 1412, 13, 400, 341, 1558, 295, 35526, 507, 382, 746, 300, 321, 393, 3079, 51260], "temperature": 0.0, "avg_logprob": -0.14293296753414095, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.0025428375229239464}, {"id": 33, "seek": 22648, "start": 244.39999999999998, "end": 252.79999999999998, "text": " for data with no reference to the underlying structure of the mechanism we are working with,", "tokens": [51260, 337, 1412, 365, 572, 6408, 281, 264, 14217, 3877, 295, 264, 7513, 321, 366, 1364, 365, 11, 51680], "temperature": 0.0, "avg_logprob": -0.14293296753414095, "compression_ratio": 1.5027932960893855, "no_speech_prob": 0.0025428375229239464}, {"id": 34, "seek": 25280, "start": 253.44, "end": 259.12, "text": " it's a definition that arises in the context of this model independent approach to physics.", "tokens": [50396, 309, 311, 257, 7123, 300, 27388, 294, 264, 4319, 295, 341, 2316, 6695, 3109, 281, 10649, 13, 50680], "temperature": 0.0, "avg_logprob": -0.15722071556817918, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.007996169850230217}, {"id": 35, "seek": 25280, "start": 259.92, "end": 267.04, "text": " So I will discuss this model independent approach very briefly because I think some", "tokens": [50720, 407, 286, 486, 2248, 341, 2316, 6695, 3109, 588, 10515, 570, 286, 519, 512, 51076], "temperature": 0.0, "avg_logprob": -0.15722071556817918, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.007996169850230217}, {"id": 36, "seek": 25280, "start": 267.04, "end": 274.8, "text": " of you may not be familiar with it. And the core idea behind model independent approach to physics", "tokens": [51076, 295, 291, 815, 406, 312, 4963, 365, 309, 13, 400, 264, 4965, 1558, 2261, 2316, 6695, 3109, 281, 10649, 51464], "temperature": 0.0, "avg_logprob": -0.15722071556817918, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.007996169850230217}, {"id": 37, "seek": 25280, "start": 274.8, "end": 282.48, "text": " is this idea of a black box. And a black box is a measurement setup. And we say we call it a", "tokens": [51464, 307, 341, 1558, 295, 257, 2211, 2424, 13, 400, 257, 2211, 2424, 307, 257, 13160, 8657, 13, 400, 321, 584, 321, 818, 309, 257, 51848], "temperature": 0.0, "avg_logprob": -0.15722071556817918, "compression_ratio": 1.8535353535353536, "no_speech_prob": 0.007996169850230217}, {"id": 38, "seek": 28248, "start": 282.48, "end": 289.28000000000003, "text": " black box because we assume that we can ignore the underlying structure of this setup and we can", "tokens": [50364, 2211, 2424, 570, 321, 6552, 300, 321, 393, 11200, 264, 14217, 3877, 295, 341, 8657, 293, 321, 393, 50704], "temperature": 0.0, "avg_logprob": -0.11600073708428277, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0021706786938011646}, {"id": 39, "seek": 28248, "start": 289.28000000000003, "end": 295.44, "text": " look onto the data. So as Popesco says, according to this view, the entire physics should be", "tokens": [50704, 574, 3911, 264, 1412, 13, 407, 382, 10215, 279, 1291, 1619, 11, 4650, 281, 341, 1910, 11, 264, 2302, 10649, 820, 312, 51012], "temperature": 0.0, "avg_logprob": -0.11600073708428277, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0021706786938011646}, {"id": 40, "seek": 28248, "start": 295.44, "end": 302.40000000000003, "text": " encapsulated in the data. And we can discuss, for example, locality from this perspective. So", "tokens": [51012, 38745, 6987, 294, 264, 1412, 13, 400, 321, 393, 2248, 11, 337, 1365, 11, 1628, 1860, 490, 341, 4585, 13, 407, 51360], "temperature": 0.0, "avg_logprob": -0.11600073708428277, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0021706786938011646}, {"id": 41, "seek": 28248, "start": 303.68, "end": 308.88, "text": " we can discuss locality beyond quantum mechanics. So with no reference to quantum systems. So all", "tokens": [51424, 321, 393, 2248, 1628, 1860, 4399, 13018, 12939, 13, 407, 365, 572, 6408, 281, 13018, 3652, 13, 407, 439, 51684], "temperature": 0.0, "avg_logprob": -0.11600073708428277, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0021706786938011646}, {"id": 42, "seek": 30888, "start": 308.88, "end": 316.48, "text": " we need are devices and measurements that are outputs. And we can also discuss contextuality", "tokens": [50364, 321, 643, 366, 5759, 293, 15383, 300, 366, 23930, 13, 400, 321, 393, 611, 2248, 35526, 507, 50744], "temperature": 0.0, "avg_logprob": -0.12432271307641334, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0017220902955159545}, {"id": 43, "seek": 30888, "start": 316.48, "end": 322.08, "text": " in this perspective. And this is exactly the definition of contextuality that is based on", "tokens": [50744, 294, 341, 4585, 13, 400, 341, 307, 2293, 264, 7123, 295, 35526, 507, 300, 307, 2361, 322, 51024], "temperature": 0.0, "avg_logprob": -0.12432271307641334, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0017220902955159545}, {"id": 44, "seek": 30888, "start": 322.08, "end": 328.64, "text": " non-contextuality in equities. So contextuality is the violation of non-contextuality in equities,", "tokens": [51024, 2107, 12, 9000, 3828, 901, 507, 294, 1267, 1088, 13, 407, 35526, 507, 307, 264, 22840, 295, 2107, 12, 9000, 3828, 901, 507, 294, 1267, 1088, 11, 51352], "temperature": 0.0, "avg_logprob": -0.12432271307641334, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0017220902955159545}, {"id": 45, "seek": 30888, "start": 328.64, "end": 335.84, "text": " just as non-locality is the violation of the inequalities. Or we can equivalently say that", "tokens": [51352, 445, 382, 2107, 12, 5842, 1860, 307, 264, 22840, 295, 264, 41874, 13, 1610, 321, 393, 9052, 2276, 584, 300, 51712], "temperature": 0.0, "avg_logprob": -0.12432271307641334, "compression_ratio": 1.9787234042553192, "no_speech_prob": 0.0017220902955159545}, {"id": 46, "seek": 33584, "start": 335.84, "end": 343.76, "text": " contextuality corresponds to the existence of global sections. So this is equivalent to say", "tokens": [50364, 35526, 507, 23249, 281, 264, 9123, 295, 4338, 10863, 13, 407, 341, 307, 10344, 281, 584, 50760], "temperature": 0.0, "avg_logprob": -0.14734341116512523, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0008652583346702158}, {"id": 47, "seek": 33584, "start": 343.76, "end": 355.2, "text": " that contextuality is the violation of non-contextuality in equities. And just to make it clear that", "tokens": [50760, 300, 35526, 507, 307, 264, 22840, 295, 2107, 12, 9000, 3828, 901, 507, 294, 1267, 1088, 13, 400, 445, 281, 652, 309, 1850, 300, 51332], "temperature": 0.0, "avg_logprob": -0.14734341116512523, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0008652583346702158}, {"id": 48, "seek": 33584, "start": 355.2, "end": 360.4, "text": " this idea of black box appears in contextuality analysis, I will show two examples. So here they", "tokens": [51332, 341, 1558, 295, 2211, 2424, 7038, 294, 35526, 507, 5215, 11, 286, 486, 855, 732, 5110, 13, 407, 510, 436, 51592], "temperature": 0.0, "avg_logprob": -0.14734341116512523, "compression_ratio": 1.6420454545454546, "no_speech_prob": 0.0008652583346702158}, {"id": 49, "seek": 36040, "start": 360.4, "end": 365.84, "text": " say that we have a black box and that the agent consumes the box by simultaneously performing", "tokens": [50364, 584, 300, 321, 362, 257, 2211, 2424, 293, 300, 264, 9461, 48823, 264, 2424, 538, 16561, 10205, 50636], "temperature": 0.0, "avg_logprob": -0.07998106147669538, "compression_ratio": 2.0, "no_speech_prob": 0.008414884097874165}, {"id": 50, "seek": 36040, "start": 365.84, "end": 372.88, "text": " a subset of measurements. And a subset of measurements that we can simultaneously perform is what we", "tokens": [50636, 257, 25993, 295, 15383, 13, 400, 257, 25993, 295, 15383, 300, 321, 393, 16561, 2042, 307, 437, 321, 50988], "temperature": 0.0, "avg_logprob": -0.07998106147669538, "compression_ratio": 2.0, "no_speech_prob": 0.008414884097874165}, {"id": 51, "seek": 36040, "start": 372.88, "end": 381.35999999999996, "text": " call a context. And here they say the same. So we have a black box that is a device containing", "tokens": [50988, 818, 257, 4319, 13, 400, 510, 436, 584, 264, 912, 13, 407, 321, 362, 257, 2211, 2424, 300, 307, 257, 4302, 19273, 51412], "temperature": 0.0, "avg_logprob": -0.07998106147669538, "compression_ratio": 2.0, "no_speech_prob": 0.008414884097874165}, {"id": 52, "seek": 36040, "start": 381.35999999999996, "end": 387.28, "text": " buttons and lights. And buttons represent measurements and lights represent outcomes", "tokens": [51412, 9905, 293, 5811, 13, 400, 9905, 2906, 15383, 293, 5811, 2906, 10070, 51708], "temperature": 0.0, "avg_logprob": -0.07998106147669538, "compression_ratio": 2.0, "no_speech_prob": 0.008414884097874165}, {"id": 53, "seek": 38728, "start": 387.28, "end": 392.79999999999995, "text": " or outputs. And we have contexts that are collections of buttons that we can press jointly.", "tokens": [50364, 420, 23930, 13, 400, 321, 362, 30628, 300, 366, 16641, 295, 9905, 300, 321, 393, 1886, 46557, 13, 50640], "temperature": 0.0, "avg_logprob": -0.10712646856540586, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.001693584374152124}, {"id": 54, "seek": 38728, "start": 393.76, "end": 399.52, "text": " And okay, so these are some pictures representing this idea of black box in contextuality analysis.", "tokens": [50688, 400, 1392, 11, 370, 613, 366, 512, 5242, 13460, 341, 1558, 295, 2211, 2424, 294, 35526, 507, 5215, 13, 50976], "temperature": 0.0, "avg_logprob": -0.10712646856540586, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.001693584374152124}, {"id": 55, "seek": 38728, "start": 399.52, "end": 404.71999999999997, "text": " So here we see that we have a black box with inputs that are buttons or measurements and", "tokens": [50976, 407, 510, 321, 536, 300, 321, 362, 257, 2211, 2424, 365, 15743, 300, 366, 9905, 420, 15383, 293, 51236], "temperature": 0.0, "avg_logprob": -0.10712646856540586, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.001693584374152124}, {"id": 56, "seek": 38728, "start": 404.71999999999997, "end": 413.35999999999996, "text": " outputs that are represented as lights. So okay, so this is basically this this model", "tokens": [51236, 23930, 300, 366, 10379, 382, 5811, 13, 407, 1392, 11, 370, 341, 307, 1936, 341, 341, 2316, 51668], "temperature": 0.0, "avg_logprob": -0.10712646856540586, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.001693584374152124}, {"id": 57, "seek": 41336, "start": 413.44, "end": 422.0, "text": " independent view. And now we will show a particular example of black box. And we will discuss this", "tokens": [50368, 6695, 1910, 13, 400, 586, 321, 486, 855, 257, 1729, 1365, 295, 2211, 2424, 13, 400, 321, 486, 2248, 341, 50796], "temperature": 0.0, "avg_logprob": -0.10300441935092589, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0026238886639475822}, {"id": 58, "seek": 41336, "start": 422.0, "end": 429.44, "text": " example using the compatibility hypergraph approach to contextuality. That is one of many", "tokens": [50796, 1365, 1228, 264, 34237, 9848, 34091, 3109, 281, 35526, 507, 13, 663, 307, 472, 295, 867, 51168], "temperature": 0.0, "avg_logprob": -0.10300441935092589, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0026238886639475822}, {"id": 59, "seek": 41336, "start": 429.44, "end": 435.52000000000004, "text": " model independent approach to contextuality analysis. And we have to introduce a measurement", "tokens": [51168, 2316, 6695, 3109, 281, 35526, 507, 5215, 13, 400, 321, 362, 281, 5366, 257, 13160, 51472], "temperature": 0.0, "avg_logprob": -0.10300441935092589, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0026238886639475822}, {"id": 60, "seek": 41336, "start": 435.52000000000004, "end": 441.68, "text": " scenario in order to define a black box. And the measurement scenario we consider is a very", "tokens": [51472, 9005, 294, 1668, 281, 6964, 257, 2211, 2424, 13, 400, 264, 13160, 9005, 321, 1949, 307, 257, 588, 51780], "temperature": 0.0, "avg_logprob": -0.10300441935092589, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.0026238886639475822}, {"id": 61, "seek": 44168, "start": 441.68, "end": 445.12, "text": " standard example of a measurement scenario in contextuality analysis.", "tokens": [50364, 3832, 1365, 295, 257, 13160, 9005, 294, 35526, 507, 5215, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10822161962819654, "compression_ratio": 1.81, "no_speech_prob": 0.0007646899321116507}, {"id": 62, "seek": 44168, "start": 446.88, "end": 453.2, "text": " That is the device cycle. So in this scenario, we have only five measurements. And all measurements", "tokens": [50624, 663, 307, 264, 4302, 6586, 13, 407, 294, 341, 9005, 11, 321, 362, 787, 1732, 15383, 13, 400, 439, 15383, 50940], "temperature": 0.0, "avg_logprob": -0.10822161962819654, "compression_ratio": 1.81, "no_speech_prob": 0.0007646899321116507}, {"id": 63, "seek": 44168, "start": 453.2, "end": 459.2, "text": " of this scenario are binary. So they have only two possible outcomes. So one and zero. And this is", "tokens": [50940, 295, 341, 9005, 366, 17434, 13, 407, 436, 362, 787, 732, 1944, 10070, 13, 407, 472, 293, 4018, 13, 400, 341, 307, 51240], "temperature": 0.0, "avg_logprob": -0.10822161962819654, "compression_ratio": 1.81, "no_speech_prob": 0.0007646899321116507}, {"id": 64, "seek": 44168, "start": 459.2, "end": 466.88, "text": " the symbol we call one. And this is the symbol we call zero. Okay, and we also have to define", "tokens": [51240, 264, 5986, 321, 818, 472, 13, 400, 341, 307, 264, 5986, 321, 818, 4018, 13, 1033, 11, 293, 321, 611, 362, 281, 6964, 51624], "temperature": 0.0, "avg_logprob": -0.10822161962819654, "compression_ratio": 1.81, "no_speech_prob": 0.0007646899321116507}, {"id": 65, "seek": 46688, "start": 466.96, "end": 473.76, "text": " a context. So we call that a context represents a collection of measurements that can be measured", "tokens": [50368, 257, 4319, 13, 407, 321, 818, 300, 257, 4319, 8855, 257, 5765, 295, 15383, 300, 393, 312, 12690, 50708], "temperature": 0.0, "avg_logprob": -0.13170037810335455, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.002112263347953558}, {"id": 66, "seek": 46688, "start": 473.76, "end": 480.08, "text": " simultaneously. And these are the contexts we consider in the five cycle. So a context in", "tokens": [50708, 16561, 13, 400, 613, 366, 264, 30628, 321, 1949, 294, 264, 1732, 6586, 13, 407, 257, 4319, 294, 51024], "temperature": 0.0, "avg_logprob": -0.13170037810335455, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.002112263347953558}, {"id": 67, "seek": 46688, "start": 480.08, "end": 486.88, "text": " this scenario is a pair of consecutive measurements. So for example, a one, a two is a context,", "tokens": [51024, 341, 9005, 307, 257, 6119, 295, 30497, 15383, 13, 407, 337, 1365, 11, 257, 472, 11, 257, 732, 307, 257, 4319, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13170037810335455, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.002112263347953558}, {"id": 68, "seek": 46688, "start": 486.88, "end": 493.52, "text": " a three, a four is a context, a four, a zero is not a context, and so on. So we have five contexts.", "tokens": [51364, 257, 1045, 11, 257, 1451, 307, 257, 4319, 11, 257, 1451, 11, 257, 4018, 307, 406, 257, 4319, 11, 293, 370, 322, 13, 407, 321, 362, 1732, 30628, 13, 51696], "temperature": 0.0, "avg_logprob": -0.13170037810335455, "compression_ratio": 1.9441624365482233, "no_speech_prob": 0.002112263347953558}, {"id": 69, "seek": 49352, "start": 493.52, "end": 501.03999999999996, "text": " And as I said, this is a very standard example of measurement scenario for contextuality analysis.", "tokens": [50364, 400, 382, 286, 848, 11, 341, 307, 257, 588, 3832, 1365, 295, 13160, 9005, 337, 35526, 507, 5215, 13, 50740], "temperature": 0.0, "avg_logprob": -0.09460662132085756, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008143872255459428}, {"id": 70, "seek": 49352, "start": 501.03999999999996, "end": 507.68, "text": " So these measurements are like the buttons of our black box. And now we have to introduce", "tokens": [50740, 407, 613, 15383, 366, 411, 264, 9905, 295, 527, 2211, 2424, 13, 400, 586, 321, 362, 281, 5366, 51072], "temperature": 0.0, "avg_logprob": -0.09460662132085756, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008143872255459428}, {"id": 71, "seek": 49352, "start": 507.68, "end": 515.12, "text": " a behavior for this scenario. That is the data our black box generates. And the behavior we consider", "tokens": [51072, 257, 5223, 337, 341, 9005, 13, 663, 307, 264, 1412, 527, 2211, 2424, 23815, 13, 400, 264, 5223, 321, 1949, 51444], "temperature": 0.0, "avg_logprob": -0.09460662132085756, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008143872255459428}, {"id": 72, "seek": 49352, "start": 515.12, "end": 522.96, "text": " is a very famous example of contextual behavior in the five cycle. And the behavior and it's", "tokens": [51444, 307, 257, 588, 4618, 1365, 295, 35526, 5223, 294, 264, 1732, 6586, 13, 400, 264, 5223, 293, 309, 311, 51836], "temperature": 0.0, "avg_logprob": -0.09460662132085756, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0008143872255459428}, {"id": 73, "seek": 52296, "start": 522.96, "end": 530.1600000000001, "text": " this behavior. So by definition in contextual analysis, the behavior of a scenario is context", "tokens": [50364, 341, 5223, 13, 407, 538, 7123, 294, 35526, 5215, 11, 264, 5223, 295, 257, 9005, 307, 4319, 50724], "temperature": 0.0, "avg_logprob": -0.12163496017456055, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0009227300179190934}, {"id": 74, "seek": 52296, "start": 530.1600000000001, "end": 534.96, "text": " dependent. So we associate a probability distribution for each context. And this is the", "tokens": [50724, 12334, 13, 407, 321, 14644, 257, 8482, 7316, 337, 1184, 4319, 13, 400, 341, 307, 264, 50964], "temperature": 0.0, "avg_logprob": -0.12163496017456055, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0009227300179190934}, {"id": 75, "seek": 52296, "start": 534.96, "end": 542.08, "text": " distribution we associate for a context in the five cycle. So, so if we measure together AI and AI", "tokens": [50964, 7316, 321, 14644, 337, 257, 4319, 294, 264, 1732, 6586, 13, 407, 11, 370, 498, 321, 3481, 1214, 7318, 293, 7318, 51320], "temperature": 0.0, "avg_logprob": -0.12163496017456055, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0009227300179190934}, {"id": 76, "seek": 52296, "start": 542.08, "end": 549.84, "text": " plus one, we will never obtain the same outcome. And the probability of obtaining zero one or one", "tokens": [51320, 1804, 472, 11, 321, 486, 1128, 12701, 264, 912, 9700, 13, 400, 264, 8482, 295, 36749, 4018, 472, 420, 472, 51708], "temperature": 0.0, "avg_logprob": -0.12163496017456055, "compression_ratio": 1.7419354838709677, "no_speech_prob": 0.0009227300179190934}, {"id": 77, "seek": 54984, "start": 549.84, "end": 555.2, "text": " zero is the same. And this is this is the data our black box generates. So this is the behavior of", "tokens": [50364, 4018, 307, 264, 912, 13, 400, 341, 307, 341, 307, 264, 1412, 527, 2211, 2424, 23815, 13, 407, 341, 307, 264, 5223, 295, 50632], "temperature": 0.0, "avg_logprob": -0.09216126062536753, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.0016731690848246217}, {"id": 78, "seek": 54984, "start": 555.2, "end": 562.88, "text": " our box of our box. And okay, and what we can say about this behavior. So first of all, it's not", "tokens": [50632, 527, 2424, 295, 527, 2424, 13, 400, 1392, 11, 293, 437, 321, 393, 584, 466, 341, 5223, 13, 407, 700, 295, 439, 11, 309, 311, 406, 51016], "temperature": 0.0, "avg_logprob": -0.09216126062536753, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.0016731690848246217}, {"id": 79, "seek": 54984, "start": 562.88, "end": 570.1600000000001, "text": " disturbing, which means that according to this behavior, it means that a measurement has the", "tokens": [51016, 21903, 11, 597, 1355, 300, 4650, 281, 341, 5223, 11, 309, 1355, 300, 257, 13160, 575, 264, 51380], "temperature": 0.0, "avg_logprob": -0.09216126062536753, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.0016731690848246217}, {"id": 80, "seek": 54984, "start": 570.1600000000001, "end": 576.5600000000001, "text": " same distribution across all contexts. And moreover, according to this behavior, a measurement", "tokens": [51380, 912, 7316, 2108, 439, 30628, 13, 400, 544, 3570, 11, 4650, 281, 341, 5223, 11, 257, 13160, 51700], "temperature": 0.0, "avg_logprob": -0.09216126062536753, "compression_ratio": 1.9054726368159205, "no_speech_prob": 0.0016731690848246217}, {"id": 81, "seek": 57656, "start": 576.56, "end": 582.4799999999999, "text": " behaves like a coin toss. And this is one of the reasons why we are calling this behavior a", "tokens": [50364, 36896, 411, 257, 11464, 14432, 13, 400, 341, 307, 472, 295, 264, 4112, 983, 321, 366, 5141, 341, 5223, 257, 50660], "temperature": 0.0, "avg_logprob": -0.11728535422795935, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0026054868940263987}, {"id": 82, "seek": 57656, "start": 582.4799999999999, "end": 590.56, "text": " generalized coin toss. This behavior is an example of stronger than quantum correlation,", "tokens": [50660, 44498, 11464, 14432, 13, 639, 5223, 307, 364, 1365, 295, 7249, 813, 13018, 20009, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11728535422795935, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0026054868940263987}, {"id": 83, "seek": 57656, "start": 590.56, "end": 595.92, "text": " which means that quantum theory cannot predict this behavior. And finally, this behavior is", "tokens": [51064, 597, 1355, 300, 13018, 5261, 2644, 6069, 341, 5223, 13, 400, 2721, 11, 341, 5223, 307, 51332], "temperature": 0.0, "avg_logprob": -0.11728535422795935, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0026054868940263987}, {"id": 84, "seek": 57656, "start": 595.92, "end": 602.0, "text": " contextual. So it violates a non contextuality inequality or equivalently, we cannot define", "tokens": [51332, 35526, 13, 407, 309, 3448, 1024, 257, 2107, 35526, 507, 16970, 420, 9052, 2276, 11, 321, 2644, 6964, 51636], "temperature": 0.0, "avg_logprob": -0.11728535422795935, "compression_ratio": 1.7416267942583732, "no_speech_prob": 0.0026054868940263987}, {"id": 85, "seek": 60200, "start": 602.0, "end": 607.6, "text": " a global section for this behavior. So it means that we cannot define a probability distribution,", "tokens": [50364, 257, 4338, 3541, 337, 341, 5223, 13, 407, 309, 1355, 300, 321, 2644, 6964, 257, 8482, 7316, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1535767586000504, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.0023779263719916344}, {"id": 86, "seek": 60200, "start": 607.6, "end": 613.76, "text": " including all measurements of this scenario that is capable of predicting this behavior. So, and", "tokens": [50644, 3009, 439, 15383, 295, 341, 9005, 300, 307, 8189, 295, 32884, 341, 5223, 13, 407, 11, 293, 50952], "temperature": 0.0, "avg_logprob": -0.1535767586000504, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.0023779263719916344}, {"id": 87, "seek": 60200, "start": 617.04, "end": 623.04, "text": " this is an example of a maximum contextual behavior in the five cycle. And this is why this", "tokens": [51116, 341, 307, 364, 1365, 295, 257, 6674, 35526, 5223, 294, 264, 1732, 6586, 13, 400, 341, 307, 983, 341, 51416], "temperature": 0.0, "avg_logprob": -0.1535767586000504, "compression_ratio": 1.580110497237569, "no_speech_prob": 0.0023779263719916344}, {"id": 88, "seek": 62304, "start": 623.12, "end": 630.7199999999999, "text": " example is very famous. Okay. And in the in the compatibility", "tokens": [50368, 1365, 307, 588, 4618, 13, 1033, 13, 400, 294, 264, 294, 264, 34237, 50748], "temperature": 0.0, "avg_logprob": -0.20658613995807926, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.004961554892361164}, {"id": 89, "seek": 62304, "start": 630.7199999999999, "end": 636.8, "text": " hydrograph approach, contextuality and nonclassicality are equivalence definitions. So according to", "tokens": [50748, 5796, 6675, 2662, 3109, 11, 35526, 507, 293, 2107, 11665, 804, 507, 366, 9052, 655, 21988, 13, 407, 4650, 281, 51052], "temperature": 0.0, "avg_logprob": -0.20658613995807926, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.004961554892361164}, {"id": 90, "seek": 62304, "start": 636.8, "end": 642.88, "text": " this approach, if our black box generates this this data, then then we have to say that our", "tokens": [51052, 341, 3109, 11, 498, 527, 2211, 2424, 23815, 341, 341, 1412, 11, 550, 550, 321, 362, 281, 584, 300, 527, 51356], "temperature": 0.0, "avg_logprob": -0.20658613995807926, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.004961554892361164}, {"id": 91, "seek": 62304, "start": 642.88, "end": 651.5999999999999, "text": " black box generates non classical correlations. Okay. So thus far, we have discussed contextuality", "tokens": [51356, 2211, 2424, 23815, 2107, 13735, 13983, 763, 13, 1033, 13, 407, 8807, 1400, 11, 321, 362, 7152, 35526, 507, 51792], "temperature": 0.0, "avg_logprob": -0.20658613995807926, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.004961554892361164}, {"id": 92, "seek": 65160, "start": 651.6, "end": 659.44, "text": " from this model independent view. And we have showed a very famous example of contextual behavior", "tokens": [50364, 490, 341, 2316, 6695, 1910, 13, 400, 321, 362, 4712, 257, 588, 4618, 1365, 295, 35526, 5223, 50756], "temperature": 0.0, "avg_logprob": -0.23774469163682727, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.0016798709984868765}, {"id": 93, "seek": 65160, "start": 659.44, "end": 664.72, "text": " in the five cycle. So this is the data our box generate. And this is the data we are going to", "tokens": [50756, 294, 264, 1732, 6586, 13, 407, 341, 307, 264, 1412, 527, 2424, 8460, 13, 400, 341, 307, 264, 1412, 321, 366, 516, 281, 51020], "temperature": 0.0, "avg_logprob": -0.23774469163682727, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.0016798709984868765}, {"id": 94, "seek": 65160, "start": 664.72, "end": 674.48, "text": " analyze. Okay, but now I will let's let's look inside the the box. And your and to begin with,", "tokens": [51020, 12477, 13, 1033, 11, 457, 586, 286, 486, 718, 311, 718, 311, 574, 1854, 264, 264, 2424, 13, 400, 428, 293, 281, 1841, 365, 11, 51508], "temperature": 0.0, "avg_logprob": -0.23774469163682727, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.0016798709984868765}, {"id": 95, "seek": 65160, "start": 674.48, "end": 679.9200000000001, "text": " I would like to compare on the balance with contextuality and equities because", "tokens": [51508, 286, 576, 411, 281, 6794, 322, 264, 4772, 365, 35526, 507, 293, 1267, 1088, 570, 51780], "temperature": 0.0, "avg_logprob": -0.23774469163682727, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.0016798709984868765}, {"id": 96, "seek": 67992, "start": 680.0, "end": 687.28, "text": " as I said, contextuality, according to this definition is the violation of non contextuality", "tokens": [50368, 382, 286, 848, 11, 35526, 507, 11, 4650, 281, 341, 7123, 307, 264, 22840, 295, 2107, 35526, 507, 50732], "temperature": 0.0, "avg_logprob": -0.22919971186940263, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0004649418988265097}, {"id": 97, "seek": 67992, "start": 687.28, "end": 693.36, "text": " and equities, just as no locality is the violation of very equities from this model", "tokens": [50732, 293, 1267, 1088, 11, 445, 382, 572, 1628, 1860, 307, 264, 22840, 295, 588, 1267, 1088, 490, 341, 2316, 51036], "temperature": 0.0, "avg_logprob": -0.22919971186940263, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0004649418988265097}, {"id": 98, "seek": 67992, "start": 693.36, "end": 697.76, "text": " independent perspective. So let's compare these two definitions. So suppose we have", "tokens": [51036, 6695, 4585, 13, 407, 718, 311, 6794, 613, 732, 21988, 13, 407, 7297, 321, 362, 51256], "temperature": 0.0, "avg_logprob": -0.22919971186940263, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0004649418988265097}, {"id": 99, "seek": 67992, "start": 699.68, "end": 704.9599999999999, "text": " a bell scenario. So it's a scenario containing two space like separated parts. So each part has", "tokens": [51352, 257, 4549, 9005, 13, 407, 309, 311, 257, 9005, 19273, 732, 1901, 411, 12005, 3166, 13, 407, 1184, 644, 575, 51616], "temperature": 0.0, "avg_logprob": -0.22919971186940263, "compression_ratio": 1.7281553398058251, "no_speech_prob": 0.0004649418988265097}, {"id": 100, "seek": 70496, "start": 704.96, "end": 710.0, "text": " a black box, and each part is performing measurements, and they are generating data", "tokens": [50364, 257, 2211, 2424, 11, 293, 1184, 644, 307, 10205, 15383, 11, 293, 436, 366, 17746, 1412, 50616], "temperature": 0.0, "avg_logprob": -0.15741189976328426, "compression_ratio": 1.7542372881355932, "no_speech_prob": 0.00234336219727993}, {"id": 101, "seek": 70496, "start": 710.0, "end": 714.32, "text": " together. And we analyze this data. And if it is data violate a bell inequality,", "tokens": [50616, 1214, 13, 400, 321, 12477, 341, 1412, 13, 400, 498, 309, 307, 1412, 37478, 257, 4549, 16970, 11, 50832], "temperature": 0.0, "avg_logprob": -0.15741189976328426, "compression_ratio": 1.7542372881355932, "no_speech_prob": 0.00234336219727993}, {"id": 102, "seek": 70496, "start": 714.96, "end": 719.6, "text": " we can say that we are witnessing a non local phenomenon, which means that", "tokens": [50864, 321, 393, 584, 300, 321, 366, 39233, 257, 2107, 2654, 14029, 11, 597, 1355, 300, 51096], "temperature": 0.0, "avg_logprob": -0.15741189976328426, "compression_ratio": 1.7542372881355932, "no_speech_prob": 0.00234336219727993}, {"id": 103, "seek": 70496, "start": 721.6, "end": 726.96, "text": " and locality or non locality is a physical concept in the sense that we can define it", "tokens": [51196, 293, 1628, 1860, 420, 2107, 1628, 1860, 307, 257, 4001, 3410, 294, 264, 2020, 300, 321, 393, 6964, 309, 51464], "temperature": 0.0, "avg_logprob": -0.15741189976328426, "compression_ratio": 1.7542372881355932, "no_speech_prob": 0.00234336219727993}, {"id": 104, "seek": 70496, "start": 726.96, "end": 732.5600000000001, "text": " in terms of physical principles. For example, we can define locality using using special", "tokens": [51464, 294, 2115, 295, 4001, 9156, 13, 1171, 1365, 11, 321, 393, 6964, 1628, 1860, 1228, 1228, 2121, 51744], "temperature": 0.0, "avg_logprob": -0.15741189976328426, "compression_ratio": 1.7542372881355932, "no_speech_prob": 0.00234336219727993}, {"id": 105, "seek": 73256, "start": 732.56, "end": 741.1199999999999, "text": " relativity. And in this case, so in this case, the data we have is is intrinsically associated", "tokens": [50364, 45675, 13, 400, 294, 341, 1389, 11, 370, 294, 341, 1389, 11, 264, 1412, 321, 362, 307, 307, 28621, 984, 6615, 50792], "temperature": 0.0, "avg_logprob": -0.18046610090467666, "compression_ratio": 1.7751196172248804, "no_speech_prob": 0.001300598494708538}, {"id": 106, "seek": 73256, "start": 741.1199999999999, "end": 746.3199999999999, "text": " with a physical phenomenon. And we can really ignore the underlying structure of these boxes.", "tokens": [50792, 365, 257, 4001, 14029, 13, 400, 321, 393, 534, 11200, 264, 14217, 3877, 295, 613, 9002, 13, 51052], "temperature": 0.0, "avg_logprob": -0.18046610090467666, "compression_ratio": 1.7751196172248804, "no_speech_prob": 0.001300598494708538}, {"id": 107, "seek": 73256, "start": 746.88, "end": 752.4, "text": " So this this measurements, they can be, for example, questions, yes, no questions we ask for", "tokens": [51080, 407, 341, 341, 15383, 11, 436, 393, 312, 11, 337, 1365, 11, 1651, 11, 2086, 11, 572, 1651, 321, 1029, 337, 51356], "temperature": 0.0, "avg_logprob": -0.18046610090467666, "compression_ratio": 1.7751196172248804, "no_speech_prob": 0.001300598494708538}, {"id": 108, "seek": 73256, "start": 752.4, "end": 759.28, "text": " these agents. And these outputs can be answers they give. And if it in this case, if this", "tokens": [51356, 613, 12554, 13, 400, 613, 23930, 393, 312, 6338, 436, 976, 13, 400, 498, 309, 294, 341, 1389, 11, 498, 341, 51700], "temperature": 0.0, "avg_logprob": -0.18046610090467666, "compression_ratio": 1.7751196172248804, "no_speech_prob": 0.001300598494708538}, {"id": 109, "seek": 75928, "start": 760.16, "end": 764.56, "text": " if these bell inequalities are violated, we can say that we are we are witnessing", "tokens": [50408, 498, 613, 4549, 41874, 366, 33239, 11, 321, 393, 584, 300, 321, 366, 321, 366, 39233, 50628], "temperature": 0.0, "avg_logprob": -0.20410279432932535, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.0028942415956407785}, {"id": 110, "seek": 75928, "start": 765.28, "end": 769.68, "text": " no local phenomenon. So there is this physical phenomenon associated to the data we have.", "tokens": [50664, 572, 2654, 14029, 13, 407, 456, 307, 341, 4001, 14029, 6615, 281, 264, 1412, 321, 362, 13, 50884], "temperature": 0.0, "avg_logprob": -0.20410279432932535, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.0028942415956407785}, {"id": 111, "seek": 75928, "start": 770.9599999999999, "end": 778.16, "text": " But in contextual analysis, we have no physical phenomenon associated to it, because", "tokens": [50948, 583, 294, 35526, 5215, 11, 321, 362, 572, 4001, 14029, 6615, 281, 309, 11, 570, 51308], "temperature": 0.0, "avg_logprob": -0.20410279432932535, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.0028942415956407785}, {"id": 112, "seek": 75928, "start": 778.88, "end": 784.72, "text": " contextuality according to this model independence definition is not a physical phenomenon,", "tokens": [51344, 35526, 507, 4650, 281, 341, 2316, 14640, 7123, 307, 406, 257, 4001, 14029, 11, 51636], "temperature": 0.0, "avg_logprob": -0.20410279432932535, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.0028942415956407785}, {"id": 113, "seek": 78472, "start": 784.8000000000001, "end": 790.5600000000001, "text": " because we cannot define it in terms of physical principles. So it would not be a surprise if", "tokens": [50368, 570, 321, 2644, 6964, 309, 294, 2115, 295, 4001, 9156, 13, 407, 309, 576, 406, 312, 257, 6365, 498, 50656], "temperature": 0.0, "avg_logprob": -0.13504098916982676, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.0025422414764761925}, {"id": 114, "seek": 78472, "start": 791.28, "end": 796.24, "text": " inside a box generating non classical correlations are contextual correlations,", "tokens": [50692, 1854, 257, 2424, 17746, 2107, 13735, 13983, 763, 366, 35526, 13983, 763, 11, 50940], "temperature": 0.0, "avg_logprob": -0.13504098916982676, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.0025422414764761925}, {"id": 115, "seek": 78472, "start": 796.24, "end": 804.88, "text": " we had a a a simple classical structure. And, and I will try to show now that", "tokens": [50940, 321, 632, 257, 257, 257, 2199, 13735, 3877, 13, 400, 11, 293, 286, 486, 853, 281, 855, 586, 300, 51372], "temperature": 0.0, "avg_logprob": -0.13504098916982676, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.0025422414764761925}, {"id": 116, "seek": 78472, "start": 804.88, "end": 809.2, "text": " this is the case for the behavior we we we called a generalized coin toss.", "tokens": [51372, 341, 307, 264, 1389, 337, 264, 5223, 321, 321, 321, 1219, 257, 44498, 11464, 14432, 13, 51588], "temperature": 0.0, "avg_logprob": -0.13504098916982676, "compression_ratio": 1.5825242718446602, "no_speech_prob": 0.0025422414764761925}, {"id": 117, "seek": 80920, "start": 809.2, "end": 818.96, "text": " Okay, and before we go through the example, I would like to say three things about it.", "tokens": [50364, 1033, 11, 293, 949, 321, 352, 807, 264, 1365, 11, 286, 576, 411, 281, 584, 1045, 721, 466, 309, 13, 50852], "temperature": 0.0, "avg_logprob": -0.1308359510443184, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.0015056319534778595}, {"id": 118, "seek": 80920, "start": 818.96, "end": 825.2800000000001, "text": " So first of all, recall that we are assuming here that everything is encapsulated in the data.", "tokens": [50852, 407, 700, 295, 439, 11, 9901, 300, 321, 366, 11926, 510, 300, 1203, 307, 38745, 6987, 294, 264, 1412, 13, 51168], "temperature": 0.0, "avg_logprob": -0.1308359510443184, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.0015056319534778595}, {"id": 119, "seek": 80920, "start": 825.2800000000001, "end": 830.88, "text": " So we can, in some sense, ignore the ignore the underlying structure of this black box.", "tokens": [51168, 407, 321, 393, 11, 294, 512, 2020, 11, 11200, 264, 11200, 264, 14217, 3877, 295, 341, 2211, 2424, 13, 51448], "temperature": 0.0, "avg_logprob": -0.1308359510443184, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.0015056319534778595}, {"id": 120, "seek": 80920, "start": 830.88, "end": 836.72, "text": " So a black box is a very permissive concept. So it may contain an entire laboratory containing", "tokens": [51448, 407, 257, 2211, 2424, 307, 257, 588, 4784, 891, 488, 3410, 13, 407, 309, 815, 5304, 364, 2302, 16523, 19273, 51740], "temperature": 0.0, "avg_logprob": -0.1308359510443184, "compression_ratio": 1.6177777777777778, "no_speech_prob": 0.0015056319534778595}, {"id": 121, "seek": 83672, "start": 836.72, "end": 846.88, "text": " particles and measuring devices. And also the the the mechanism we propose is basically a", "tokens": [50364, 10007, 293, 13389, 5759, 13, 400, 611, 264, 264, 264, 7513, 321, 17421, 307, 1936, 257, 50872], "temperature": 0.0, "avg_logprob": -0.2260552153867834, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0031273863278329372}, {"id": 122, "seek": 83672, "start": 846.88, "end": 855.0400000000001, "text": " toy mechanism for coin tossing. And coin tossing is is according to many operational", "tokens": [50872, 12058, 7513, 337, 11464, 14432, 278, 13, 400, 11464, 14432, 278, 307, 307, 4650, 281, 867, 16607, 51280], "temperature": 0.0, "avg_logprob": -0.2260552153867834, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0031273863278329372}, {"id": 123, "seek": 83672, "start": 855.0400000000001, "end": 859.36, "text": " approach to physics, it's a valid example of measurement procedure. So for example,", "tokens": [51280, 3109, 281, 10649, 11, 309, 311, 257, 7363, 1365, 295, 13160, 10747, 13, 407, 337, 1365, 11, 51496], "temperature": 0.0, "avg_logprob": -0.2260552153867834, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0031273863278329372}, {"id": 124, "seek": 83672, "start": 860.8000000000001, "end": 863.36, "text": " people who work with packing context reality and", "tokens": [51568, 561, 567, 589, 365, 20815, 4319, 4103, 293, 51696], "temperature": 0.0, "avg_logprob": -0.2260552153867834, "compression_ratio": 1.5989583333333333, "no_speech_prob": 0.0031273863278329372}, {"id": 125, "seek": 86336, "start": 863.44, "end": 869.92, "text": " generalize the probability theories, they are all the time using coin tossing as an example of", "tokens": [50368, 2674, 1125, 264, 8482, 13667, 11, 436, 366, 439, 264, 565, 1228, 11464, 14432, 278, 382, 364, 1365, 295, 50692], "temperature": 0.0, "avg_logprob": -0.214765270104569, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0007890052511356771}, {"id": 126, "seek": 86336, "start": 869.92, "end": 876.96, "text": " measuring procedure that is valid. So that's why we say that this mechanism works along the line", "tokens": [50692, 13389, 10747, 300, 307, 7363, 13, 407, 300, 311, 983, 321, 584, 300, 341, 7513, 1985, 2051, 264, 1622, 51044], "temperature": 0.0, "avg_logprob": -0.214765270104569, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0007890052511356771}, {"id": 127, "seek": 86336, "start": 876.96, "end": 883.36, "text": " set out in many operational approach. So according to these approach, if we had inside a black box", "tokens": [51044, 992, 484, 294, 867, 16607, 3109, 13, 407, 4650, 281, 613, 3109, 11, 498, 321, 632, 1854, 257, 2211, 2424, 51364], "temperature": 0.0, "avg_logprob": -0.214765270104569, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0007890052511356771}, {"id": 128, "seek": 86336, "start": 883.36, "end": 891.9200000000001, "text": " a coin coin flip a coin tossing, it would be a valid measurement procedure. And more importantly,", "tokens": [51364, 257, 11464, 11464, 7929, 257, 11464, 14432, 278, 11, 309, 576, 312, 257, 7363, 13160, 10747, 13, 400, 544, 8906, 11, 51792], "temperature": 0.0, "avg_logprob": -0.214765270104569, "compression_ratio": 1.651063829787234, "no_speech_prob": 0.0007890052511356771}, {"id": 129, "seek": 89192, "start": 892.88, "end": 899.4399999999999, "text": " this this mechanism is something like a thought experiment. So we are trying to show that unlike", "tokens": [50412, 341, 341, 7513, 307, 746, 411, 257, 1194, 5120, 13, 407, 321, 366, 1382, 281, 855, 300, 8343, 50740], "temperature": 0.0, "avg_logprob": -0.1697798456464495, "compression_ratio": 1.7621359223300972, "no_speech_prob": 0.0011277467710897326}, {"id": 130, "seek": 89192, "start": 899.4399999999999, "end": 904.24, "text": " no local data, no contextual data can be generated by a simple classical mechanism.", "tokens": [50740, 572, 2654, 1412, 11, 572, 35526, 1412, 393, 312, 10833, 538, 257, 2199, 13735, 7513, 13, 50980], "temperature": 0.0, "avg_logprob": -0.1697798456464495, "compression_ratio": 1.7621359223300972, "no_speech_prob": 0.0011277467710897326}, {"id": 131, "seek": 89192, "start": 904.24, "end": 909.68, "text": " So this mechanism should be understood as a thought experiment. So it's not a mechanism", "tokens": [50980, 407, 341, 7513, 820, 312, 7320, 382, 257, 1194, 5120, 13, 407, 309, 311, 406, 257, 7513, 51252], "temperature": 0.0, "avg_logprob": -0.1697798456464495, "compression_ratio": 1.7621359223300972, "no_speech_prob": 0.0011277467710897326}, {"id": 132, "seek": 89192, "start": 909.68, "end": 917.1999999999999, "text": " that is interesting by itself. So okay, now let's go through the the mechanism. And as I said,", "tokens": [51252, 300, 307, 1880, 538, 2564, 13, 407, 1392, 11, 586, 718, 311, 352, 807, 264, 264, 7513, 13, 400, 382, 286, 848, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1697798456464495, "compression_ratio": 1.7621359223300972, "no_speech_prob": 0.0011277467710897326}, {"id": 133, "seek": 91720, "start": 917.2, "end": 921.6, "text": " it's it's basically a toy mechanism for coin tossing. And how can we describe", "tokens": [50364, 309, 311, 309, 311, 1936, 257, 12058, 7513, 337, 11464, 14432, 278, 13, 400, 577, 393, 321, 6786, 50584], "temperature": 0.0, "avg_logprob": -0.14168009807154075, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.001985325012356043}, {"id": 134, "seek": 91720, "start": 924.08, "end": 932.24, "text": " a coin toss using toy mechanism. So we need an object. So in the in the real world, we we use", "tokens": [50708, 257, 11464, 14432, 1228, 12058, 7513, 13, 407, 321, 643, 364, 2657, 13, 407, 294, 264, 294, 264, 957, 1002, 11, 321, 321, 764, 51116], "temperature": 0.0, "avg_logprob": -0.14168009807154075, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.001985325012356043}, {"id": 135, "seek": 91720, "start": 932.24, "end": 939.12, "text": " a coin that is an object has that for all practical purposes has two sides. So here in this time", "tokens": [51116, 257, 11464, 300, 307, 364, 2657, 575, 300, 337, 439, 8496, 9932, 575, 732, 4881, 13, 407, 510, 294, 341, 565, 51460], "temperature": 0.0, "avg_logprob": -0.14168009807154075, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.001985325012356043}, {"id": 136, "seek": 91720, "start": 939.12, "end": 945.76, "text": " mechanism, we consider for the sake of simplicity, a 2D object, and each has two sides. So one side", "tokens": [51460, 7513, 11, 321, 1949, 337, 264, 9717, 295, 25632, 11, 257, 568, 35, 2657, 11, 293, 1184, 575, 732, 4881, 13, 407, 472, 1252, 51792], "temperature": 0.0, "avg_logprob": -0.14168009807154075, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.001985325012356043}, {"id": 137, "seek": 94576, "start": 945.76, "end": 955.52, "text": " is dark gray, the other side is light gray. And we have we need to flip this object. So we fix an", "tokens": [50364, 307, 2877, 10855, 11, 264, 661, 1252, 307, 1442, 10855, 13, 400, 321, 362, 321, 643, 281, 7929, 341, 2657, 13, 407, 321, 3191, 364, 50852], "temperature": 0.0, "avg_logprob": -0.11797072840671913, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.0006977227749302983}, {"id": 138, "seek": 94576, "start": 955.52, "end": 961.2, "text": " axis passing through the center of this object, and we flip this object. And at the end of the", "tokens": [50852, 10298, 8437, 807, 264, 3056, 295, 341, 2657, 11, 293, 321, 7929, 341, 2657, 13, 400, 412, 264, 917, 295, 264, 51136], "temperature": 0.0, "avg_logprob": -0.11797072840671913, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.0006977227749302983}, {"id": 139, "seek": 94576, "start": 961.2, "end": 967.92, "text": " movement, we look to the side that is showing when the coin lands. So this is the real case.", "tokens": [51136, 3963, 11, 321, 574, 281, 264, 1252, 300, 307, 4099, 562, 264, 11464, 5949, 13, 407, 341, 307, 264, 957, 1389, 13, 51472], "temperature": 0.0, "avg_logprob": -0.11797072840671913, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.0006977227749302983}, {"id": 140, "seek": 94576, "start": 967.92, "end": 974.96, "text": " So in this toy mechanism, we we we fix this side of the object. So and we imagine that this is a", "tokens": [51472, 407, 294, 341, 12058, 7513, 11, 321, 321, 321, 3191, 341, 1252, 295, 264, 2657, 13, 407, 293, 321, 3811, 300, 341, 307, 257, 51824], "temperature": 0.0, "avg_logprob": -0.11797072840671913, "compression_ratio": 1.8365384615384615, "no_speech_prob": 0.0006977227749302983}, {"id": 141, "seek": 97496, "start": 974.96, "end": 982.32, "text": " sensor and the sensor can detect color that in this case is gray. And it can distinguish dark", "tokens": [50364, 10200, 293, 264, 10200, 393, 5531, 2017, 300, 294, 341, 1389, 307, 10855, 13, 400, 309, 393, 20206, 2877, 50732], "temperature": 0.0, "avg_logprob": -0.14736881039359354, "compression_ratio": 1.821256038647343, "no_speech_prob": 0.00074248225428164}, {"id": 142, "seek": 97496, "start": 982.32, "end": 989.36, "text": " from light color. So we have these two outputs. So these outputs are like hazard tails. So they", "tokens": [50732, 490, 1442, 2017, 13, 407, 321, 362, 613, 732, 23930, 13, 407, 613, 23930, 366, 411, 20790, 28537, 13, 407, 436, 51084], "temperature": 0.0, "avg_logprob": -0.14736881039359354, "compression_ratio": 1.821256038647343, "no_speech_prob": 0.00074248225428164}, {"id": 143, "seek": 97496, "start": 989.36, "end": 996.1600000000001, "text": " they are dark gray or light gray. And the behavior we obtain if we perform these measurements,", "tokens": [51084, 436, 366, 2877, 10855, 420, 1442, 10855, 13, 400, 264, 5223, 321, 12701, 498, 321, 2042, 613, 15383, 11, 51424], "temperature": 0.0, "avg_logprob": -0.14736881039359354, "compression_ratio": 1.821256038647343, "no_speech_prob": 0.00074248225428164}, {"id": 144, "seek": 97496, "start": 996.1600000000001, "end": 1001.36, "text": " these measurements. So if we flip this coin is the behavior of a fair conflict, because this", "tokens": [51424, 613, 15383, 13, 407, 498, 321, 7929, 341, 11464, 307, 264, 5223, 295, 257, 3143, 6596, 11, 570, 341, 51684], "temperature": 0.0, "avg_logprob": -0.14736881039359354, "compression_ratio": 1.821256038647343, "no_speech_prob": 0.00074248225428164}, {"id": 145, "seek": 100136, "start": 1001.36, "end": 1008.4, "text": " mechanism is is constructed for for this purpose. So okay, so this is a toy mechanism for coin toss.", "tokens": [50364, 7513, 307, 307, 17083, 337, 337, 341, 4334, 13, 407, 1392, 11, 370, 341, 307, 257, 12058, 7513, 337, 11464, 14432, 13, 50716], "temperature": 0.0, "avg_logprob": -0.17365203270545373, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.0016537073533982038}, {"id": 146, "seek": 100136, "start": 1010.08, "end": 1017.12, "text": " And the point is that we can propose a straightforward generalization of this mechanism", "tokens": [50800, 400, 264, 935, 307, 300, 321, 393, 17421, 257, 15325, 2674, 2144, 295, 341, 7513, 51152], "temperature": 0.0, "avg_logprob": -0.17365203270545373, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.0016537073533982038}, {"id": 147, "seek": 100136, "start": 1017.84, "end": 1023.6, "text": " that is capable of generating the the behavior we call a generalized coin toss that, as I said,", "tokens": [51188, 300, 307, 8189, 295, 17746, 264, 264, 5223, 321, 818, 257, 44498, 11464, 14432, 300, 11, 382, 286, 848, 11, 51476], "temperature": 0.0, "avg_logprob": -0.17365203270545373, "compression_ratio": 1.6416184971098267, "no_speech_prob": 0.0016537073533982038}, {"id": 148, "seek": 102360, "start": 1023.6, "end": 1029.28, "text": " is a very famous example of contextual correlation, contextuality analysis.", "tokens": [50364, 307, 257, 588, 4618, 1365, 295, 35526, 20009, 11, 35526, 507, 5215, 13, 50648], "temperature": 0.0, "avg_logprob": -0.12708365349542528, "compression_ratio": 1.9783783783783784, "no_speech_prob": 0.005188695155084133}, {"id": 149, "seek": 102360, "start": 1030.96, "end": 1039.6, "text": " So a coin toss, we have one binary measurement. So we need an object having one pair of positive", "tokens": [50732, 407, 257, 11464, 14432, 11, 321, 362, 472, 17434, 13160, 13, 407, 321, 643, 364, 2657, 1419, 472, 6119, 295, 3353, 51164], "temperature": 0.0, "avg_logprob": -0.12708365349542528, "compression_ratio": 1.9783783783783784, "no_speech_prob": 0.005188695155084133}, {"id": 150, "seek": 102360, "start": 1039.6, "end": 1046.64, "text": " sides. But in the generalized coin toss, we have five pairs of positives. So we have five binary", "tokens": [51164, 4881, 13, 583, 294, 264, 44498, 11464, 14432, 11, 321, 362, 1732, 15494, 295, 35127, 13, 407, 321, 362, 1732, 17434, 51516], "temperature": 0.0, "avg_logprob": -0.12708365349542528, "compression_ratio": 1.9783783783783784, "no_speech_prob": 0.005188695155084133}, {"id": 151, "seek": 102360, "start": 1046.64, "end": 1052.72, "text": " measurements. So we need an object having five pairs of positive sides. So it could be something", "tokens": [51516, 15383, 13, 407, 321, 643, 364, 2657, 1419, 1732, 15494, 295, 3353, 4881, 13, 407, 309, 727, 312, 746, 51820], "temperature": 0.0, "avg_logprob": -0.12708365349542528, "compression_ratio": 1.9783783783783784, "no_speech_prob": 0.005188695155084133}, {"id": 152, "seek": 105272, "start": 1052.72, "end": 1062.56, "text": " like an unsided dice or something like this. And but we are proposing just a toy mechanism. So we", "tokens": [50364, 411, 364, 2693, 2112, 10313, 420, 746, 411, 341, 13, 400, 457, 321, 366, 29939, 445, 257, 12058, 7513, 13, 407, 321, 50856], "temperature": 0.0, "avg_logprob": -0.17243701881832546, "compression_ratio": 1.6198830409356726, "no_speech_prob": 0.001111211720854044}, {"id": 153, "seek": 105272, "start": 1062.56, "end": 1068.8, "text": " consider a 2D object. And this is a regular decadent. And for each pair of positive sides,", "tokens": [50856, 1949, 257, 568, 35, 2657, 13, 400, 341, 307, 257, 3890, 979, 345, 317, 13, 400, 337, 1184, 6119, 295, 3353, 4881, 11, 51168], "temperature": 0.0, "avg_logprob": -0.17243701881832546, "compression_ratio": 1.6198830409356726, "no_speech_prob": 0.001111211720854044}, {"id": 154, "seek": 105272, "start": 1068.8, "end": 1075.92, "text": " we associate a measurement. And for for its measurement, we associate a color. And okay,", "tokens": [51168, 321, 14644, 257, 13160, 13, 400, 337, 337, 1080, 13160, 11, 321, 14644, 257, 2017, 13, 400, 1392, 11, 51524], "temperature": 0.0, "avg_logprob": -0.17243701881832546, "compression_ratio": 1.6198830409356726, "no_speech_prob": 0.001111211720854044}, {"id": 155, "seek": 107592, "start": 1075.92, "end": 1084.8000000000002, "text": " and the measurement procedure inside of this box is a coin flipping. But the the the flipping is", "tokens": [50364, 293, 264, 13160, 10747, 1854, 295, 341, 2424, 307, 257, 11464, 26886, 13, 583, 264, 264, 264, 26886, 307, 50808], "temperature": 0.0, "avg_logprob": -0.13701067077979612, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.0014086299343034625}, {"id": 156, "seek": 107592, "start": 1084.8000000000002, "end": 1092.24, "text": " determined in this case by the context. So the context in this toy mechanism is an axis passing", "tokens": [50808, 9540, 294, 341, 1389, 538, 264, 4319, 13, 407, 264, 4319, 294, 341, 12058, 7513, 307, 364, 10298, 8437, 51180], "temperature": 0.0, "avg_logprob": -0.13701067077979612, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.0014086299343034625}, {"id": 157, "seek": 107592, "start": 1092.24, "end": 1098.48, "text": " through the center of the object. And together with a sensor and the sensor can detect color and", "tokens": [51180, 807, 264, 3056, 295, 264, 2657, 13, 400, 1214, 365, 257, 10200, 293, 264, 10200, 393, 5531, 2017, 293, 51492], "temperature": 0.0, "avg_logprob": -0.13701067077979612, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.0014086299343034625}, {"id": 158, "seek": 107592, "start": 1098.48, "end": 1104.4, "text": " it can distinguish that from each color. So for example, if we want to measure a two and a three", "tokens": [51492, 309, 393, 20206, 300, 490, 1184, 2017, 13, 407, 337, 1365, 11, 498, 321, 528, 281, 3481, 257, 732, 293, 257, 1045, 51788], "temperature": 0.0, "avg_logprob": -0.13701067077979612, "compression_ratio": 1.746606334841629, "no_speech_prob": 0.0014086299343034625}, {"id": 159, "seek": 110440, "start": 1104.4, "end": 1111.8400000000001, "text": " together, if we press these buttons in our box, this mechanism will just flip this coin. But with", "tokens": [50364, 1214, 11, 498, 321, 1886, 613, 9905, 294, 527, 2424, 11, 341, 7513, 486, 445, 7929, 341, 11464, 13, 583, 365, 50736], "temperature": 0.0, "avg_logprob": -0.09465070565541585, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.005041796714067459}, {"id": 160, "seek": 110440, "start": 1111.8400000000001, "end": 1117.52, "text": " respect to the axis that they're mined by this context, so this is the axis, this vertical line.", "tokens": [50736, 3104, 281, 264, 10298, 300, 436, 434, 923, 292, 538, 341, 4319, 11, 370, 341, 307, 264, 10298, 11, 341, 9429, 1622, 13, 51020], "temperature": 0.0, "avg_logprob": -0.09465070565541585, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.005041796714067459}, {"id": 161, "seek": 110440, "start": 1118.24, "end": 1123.76, "text": " And if we do that, we can obtain two possible outcomes. So we can detect dark yellow and", "tokens": [51056, 400, 498, 321, 360, 300, 11, 321, 393, 12701, 732, 1944, 10070, 13, 407, 321, 393, 5531, 2877, 5566, 293, 51332], "temperature": 0.0, "avg_logprob": -0.09465070565541585, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.005041796714067459}, {"id": 162, "seek": 110440, "start": 1123.76, "end": 1129.6000000000001, "text": " light green, or we can detect light yellow and dark green. So we can never detect, for example,", "tokens": [51332, 1442, 3092, 11, 420, 321, 393, 5531, 1442, 5566, 293, 2877, 3092, 13, 407, 321, 393, 1128, 5531, 11, 337, 1365, 11, 51624], "temperature": 0.0, "avg_logprob": -0.09465070565541585, "compression_ratio": 1.730593607305936, "no_speech_prob": 0.005041796714067459}, {"id": 163, "seek": 112960, "start": 1129.6, "end": 1133.9199999999998, "text": " dark yellow and dark green because they are in a positive side of this object. So", "tokens": [50364, 2877, 5566, 293, 2877, 3092, 570, 436, 366, 294, 257, 3353, 1252, 295, 341, 2657, 13, 407, 50580], "temperature": 0.0, "avg_logprob": -0.1310109045447373, "compression_ratio": 1.715, "no_speech_prob": 0.00154464365914464}, {"id": 164, "seek": 112960, "start": 1133.9199999999998, "end": 1140.08, "text": " this is a mere geometrical restriction of the object. And this is why we have this,", "tokens": [50580, 341, 307, 257, 8401, 12956, 15888, 29529, 295, 264, 2657, 13, 400, 341, 307, 983, 321, 362, 341, 11, 50888], "temperature": 0.0, "avg_logprob": -0.1310109045447373, "compression_ratio": 1.715, "no_speech_prob": 0.00154464365914464}, {"id": 165, "seek": 112960, "start": 1140.08, "end": 1144.8, "text": " we have the correlation that is predicted by the generalized coin toss in this context.", "tokens": [50888, 321, 362, 264, 20009, 300, 307, 19147, 538, 264, 44498, 11464, 14432, 294, 341, 4319, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1310109045447373, "compression_ratio": 1.715, "no_speech_prob": 0.00154464365914464}, {"id": 166, "seek": 112960, "start": 1146.1599999999999, "end": 1152.1599999999999, "text": " And this is the mechanism we have. So each context is an axis together with a sensor. And", "tokens": [51192, 400, 341, 307, 264, 7513, 321, 362, 13, 407, 1184, 4319, 307, 364, 10298, 1214, 365, 257, 10200, 13, 400, 51492], "temperature": 0.0, "avg_logprob": -0.1310109045447373, "compression_ratio": 1.715, "no_speech_prob": 0.00154464365914464}, {"id": 167, "seek": 115216, "start": 1152.16, "end": 1160.48, "text": " whatever is the context we consider, we have only these two possible outcomes and the behavior is", "tokens": [50364, 2035, 307, 264, 4319, 321, 1949, 11, 321, 362, 787, 613, 732, 1944, 10070, 293, 264, 5223, 307, 50780], "temperature": 0.0, "avg_logprob": -0.08681600943379018, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.0005271127447485924}, {"id": 168, "seek": 115216, "start": 1160.48, "end": 1168.24, "text": " the behavior we call a generalized coin toss. Okay. And we also must be able to measure single,", "tokens": [50780, 264, 5223, 321, 818, 257, 44498, 11464, 14432, 13, 1033, 13, 400, 321, 611, 1633, 312, 1075, 281, 3481, 2167, 11, 51168], "temperature": 0.0, "avg_logprob": -0.08681600943379018, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.0005271127447485924}, {"id": 169, "seek": 115216, "start": 1168.24, "end": 1172.4, "text": " to perform single measurements. And in order to do that, we have to fix a context.", "tokens": [51168, 281, 2042, 2167, 15383, 13, 400, 294, 1668, 281, 360, 300, 11, 321, 362, 281, 3191, 257, 4319, 13, 51376], "temperature": 0.0, "avg_logprob": -0.08681600943379018, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.0005271127447485924}, {"id": 170, "seek": 115216, "start": 1173.6000000000001, "end": 1178.3200000000002, "text": " So this is the general case in contextual analysis. So for example, if we want to measure", "tokens": [51436, 407, 341, 307, 264, 2674, 1389, 294, 35526, 5215, 13, 407, 337, 1365, 11, 498, 321, 528, 281, 3481, 51672], "temperature": 0.0, "avg_logprob": -0.08681600943379018, "compression_ratio": 1.7345971563981042, "no_speech_prob": 0.0005271127447485924}, {"id": 171, "seek": 117832, "start": 1178.96, "end": 1185.36, "text": " these measurements, A0, that is red, we have two options. So we have two contexts containing A0,", "tokens": [50396, 613, 15383, 11, 316, 15, 11, 300, 307, 2182, 11, 321, 362, 732, 3956, 13, 407, 321, 362, 732, 30628, 19273, 316, 15, 11, 50716], "temperature": 0.0, "avg_logprob": -0.1656341163479552, "compression_ratio": 1.7584541062801933, "no_speech_prob": 0.0010476099560037255}, {"id": 172, "seek": 117832, "start": 1185.36, "end": 1189.76, "text": " and we have to choose one of them. So we can choose, for example, this context,", "tokens": [50716, 293, 321, 362, 281, 2826, 472, 295, 552, 13, 407, 321, 393, 2826, 11, 337, 1365, 11, 341, 4319, 11, 50936], "temperature": 0.0, "avg_logprob": -0.1656341163479552, "compression_ratio": 1.7584541062801933, "no_speech_prob": 0.0010476099560037255}, {"id": 173, "seek": 117832, "start": 1189.76, "end": 1196.32, "text": " and we just flip this object. And so we have two possible outcomes, so dark red or light red,", "tokens": [50936, 293, 321, 445, 7929, 341, 2657, 13, 400, 370, 321, 362, 732, 1944, 10070, 11, 370, 2877, 2182, 420, 1442, 2182, 11, 51264], "temperature": 0.0, "avg_logprob": -0.1656341163479552, "compression_ratio": 1.7584541062801933, "no_speech_prob": 0.0010476099560037255}, {"id": 174, "seek": 117832, "start": 1196.32, "end": 1204.08, "text": " and the behavior is the behavior of a fair coin slip. So to sum up, this mechanism, this time", "tokens": [51264, 293, 264, 5223, 307, 264, 5223, 295, 257, 3143, 11464, 11140, 13, 407, 281, 2408, 493, 11, 341, 7513, 11, 341, 565, 51652], "temperature": 0.0, "avg_logprob": -0.1656341163479552, "compression_ratio": 1.7584541062801933, "no_speech_prob": 0.0010476099560037255}, {"id": 175, "seek": 120408, "start": 1204.1599999999999, "end": 1210.56, "text": " mechanism, or just thought experiment, generates the behavior we call a generalized coin toss.", "tokens": [50368, 7513, 11, 420, 445, 1194, 5120, 11, 23815, 264, 5223, 321, 818, 257, 44498, 11464, 14432, 13, 50688], "temperature": 0.0, "avg_logprob": -0.14831276943809107, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0017790343845263124}, {"id": 176, "seek": 120408, "start": 1212.24, "end": 1219.4399999999998, "text": " And okay, and what we can say based on this example, based on this thought experiment.", "tokens": [50772, 400, 1392, 11, 293, 437, 321, 393, 584, 2361, 322, 341, 1365, 11, 2361, 322, 341, 1194, 5120, 13, 51132], "temperature": 0.0, "avg_logprob": -0.14831276943809107, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0017790343845263124}, {"id": 177, "seek": 120408, "start": 1219.4399999999998, "end": 1223.1999999999998, "text": " So first of all, let's discuss contextuality beyond content theory.", "tokens": [51132, 407, 700, 295, 439, 11, 718, 311, 2248, 35526, 507, 4399, 2701, 5261, 13, 51320], "temperature": 0.0, "avg_logprob": -0.14831276943809107, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0017790343845263124}, {"id": 178, "seek": 120408, "start": 1225.84, "end": 1230.8799999999999, "text": " Okay, so the first point is that without clear specification of what measurement means,", "tokens": [51452, 1033, 11, 370, 264, 700, 935, 307, 300, 1553, 1850, 31256, 295, 437, 13160, 1355, 11, 51704], "temperature": 0.0, "avg_logprob": -0.14831276943809107, "compression_ratio": 1.6280193236714975, "no_speech_prob": 0.0017790343845263124}, {"id": 179, "seek": 123088, "start": 1230.88, "end": 1235.8400000000001, "text": " contextuality has no phenomenological significance. It means that the meaning of", "tokens": [50364, 35526, 507, 575, 572, 9388, 4383, 17687, 13, 467, 1355, 300, 264, 3620, 295, 50612], "temperature": 0.0, "avg_logprob": -0.13227086524440818, "compression_ratio": 1.8125, "no_speech_prob": 0.0011281276820227504}, {"id": 180, "seek": 123088, "start": 1235.8400000000001, "end": 1240.48, "text": " contextuality or the phenomenological meaning depends on what we mean by a measurement.", "tokens": [50612, 35526, 507, 420, 264, 9388, 4383, 3620, 5946, 322, 437, 321, 914, 538, 257, 13160, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13227086524440818, "compression_ratio": 1.8125, "no_speech_prob": 0.0011281276820227504}, {"id": 181, "seek": 123088, "start": 1241.2800000000002, "end": 1248.0800000000002, "text": " So in contextual analysis, the underlying structure matters. So we cannot say that,", "tokens": [50884, 407, 294, 35526, 5215, 11, 264, 14217, 3877, 7001, 13, 407, 321, 2644, 584, 300, 11, 51224], "temperature": 0.0, "avg_logprob": -0.13227086524440818, "compression_ratio": 1.8125, "no_speech_prob": 0.0011281276820227504}, {"id": 182, "seek": 123088, "start": 1248.88, "end": 1255.3600000000001, "text": " I think that based on this thought experiment, I think this thought experiment suggests that we", "tokens": [51264, 286, 519, 300, 2361, 322, 341, 1194, 5120, 11, 286, 519, 341, 1194, 5120, 13409, 300, 321, 51588], "temperature": 0.0, "avg_logprob": -0.13227086524440818, "compression_ratio": 1.8125, "no_speech_prob": 0.0011281276820227504}, {"id": 183, "seek": 125536, "start": 1255.36, "end": 1262.24, "text": " cannot ignore the underlying structure in order, when we are analyzing data from this", "tokens": [50364, 2644, 11200, 264, 14217, 3877, 294, 1668, 11, 562, 321, 366, 23663, 1412, 490, 341, 50708], "temperature": 0.0, "avg_logprob": -0.12949385885464942, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0006705428240820765}, {"id": 184, "seek": 125536, "start": 1262.24, "end": 1270.32, "text": " perspective of contextuality. Which means that in contextuality analysis, the entire physics", "tokens": [50708, 4585, 295, 35526, 507, 13, 3013, 1355, 300, 294, 35526, 507, 5215, 11, 264, 2302, 10649, 51112], "temperature": 0.0, "avg_logprob": -0.12949385885464942, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0006705428240820765}, {"id": 185, "seek": 125536, "start": 1270.32, "end": 1278.8, "text": " does not seem to be encapsulated in the data. So what we mean by measurement is important.", "tokens": [51112, 775, 406, 1643, 281, 312, 38745, 6987, 294, 264, 1412, 13, 407, 437, 321, 914, 538, 13160, 307, 1021, 13, 51536], "temperature": 0.0, "avg_logprob": -0.12949385885464942, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0006705428240820765}, {"id": 186, "seek": 127880, "start": 1279.52, "end": 1286.48, "text": " And finally, contextuality, at least beyond content theory, does not require a non-classical", "tokens": [50400, 400, 2721, 11, 35526, 507, 11, 412, 1935, 4399, 2701, 5261, 11, 775, 406, 3651, 257, 2107, 12, 11665, 804, 50748], "temperature": 0.0, "avg_logprob": -0.26991114020347595, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0014726155204698443}, {"id": 187, "seek": 127880, "start": 1286.48, "end": 1294.32, "text": " phenomenon. Okay, and can we say something about contextuality in content theory,", "tokens": [50748, 14029, 13, 1033, 11, 293, 393, 321, 584, 746, 466, 35526, 507, 294, 2701, 5261, 11, 51140], "temperature": 0.0, "avg_logprob": -0.26991114020347595, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0014726155204698443}, {"id": 188, "seek": 127880, "start": 1295.12, "end": 1301.84, "text": " based on this thought experiment? And I think we can. So note that in our thought experiment,", "tokens": [51180, 2361, 322, 341, 1194, 5120, 30, 400, 286, 519, 321, 393, 13, 407, 3637, 300, 294, 527, 1194, 5120, 11, 51516], "temperature": 0.0, "avg_logprob": -0.26991114020347595, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.0014726155204698443}, {"id": 189, "seek": 130184, "start": 1302.48, "end": 1310.1599999999999, "text": " we are working with a classical object. So it's basically a coin. So", "tokens": [50396, 321, 366, 1364, 365, 257, 13735, 2657, 13, 407, 309, 311, 1936, 257, 11464, 13, 407, 50780], "temperature": 0.0, "avg_logprob": -0.12386144174111856, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.00293080136179924}, {"id": 190, "seek": 130184, "start": 1312.8799999999999, "end": 1318.3999999999999, "text": " it's a classical object in the sense that it's a rigid body. So it's just a thought mechanism.", "tokens": [50916, 309, 311, 257, 13735, 2657, 294, 264, 2020, 300, 309, 311, 257, 22195, 1772, 13, 407, 309, 311, 445, 257, 1194, 7513, 13, 51192], "temperature": 0.0, "avg_logprob": -0.12386144174111856, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.00293080136179924}, {"id": 191, "seek": 130184, "start": 1318.3999999999999, "end": 1327.4399999999998, "text": " So we say it's a 2D object, but we can imagine it as a real body, just as we imagine a coin as", "tokens": [51192, 407, 321, 584, 309, 311, 257, 568, 35, 2657, 11, 457, 321, 393, 3811, 309, 382, 257, 957, 1772, 11, 445, 382, 321, 3811, 257, 11464, 382, 51644], "temperature": 0.0, "avg_logprob": -0.12386144174111856, "compression_ratio": 1.6862745098039216, "no_speech_prob": 0.00293080136179924}, {"id": 192, "seek": 132744, "start": 1327.6000000000001, "end": 1334.24, "text": " a rigid body. And okay, so we have this classical object and measurements, our measurement procedures", "tokens": [50372, 257, 22195, 1772, 13, 400, 1392, 11, 370, 321, 362, 341, 13735, 2657, 293, 15383, 11, 527, 13160, 13846, 50704], "temperature": 0.0, "avg_logprob": -0.16787882696224166, "compression_ratio": 1.751219512195122, "no_speech_prob": 0.0024652413558214903}, {"id": 193, "seek": 132744, "start": 1334.24, "end": 1340.16, "text": " are not revealing perverts processed by the system. And also we have context. So not all", "tokens": [50704, 366, 406, 23983, 680, 36999, 18846, 538, 264, 1185, 13, 400, 611, 321, 362, 4319, 13, 407, 406, 439, 51000], "temperature": 0.0, "avg_logprob": -0.16787882696224166, "compression_ratio": 1.751219512195122, "no_speech_prob": 0.0024652413558214903}, {"id": 194, "seek": 132744, "start": 1340.16, "end": 1345.76, "text": " measurements can be simultaneously performed. So we have this restriction that is an", "tokens": [51000, 15383, 393, 312, 16561, 10332, 13, 407, 321, 362, 341, 29529, 300, 307, 364, 51280], "temperature": 0.0, "avg_logprob": -0.16787882696224166, "compression_ratio": 1.751219512195122, "no_speech_prob": 0.0024652413558214903}, {"id": 195, "seek": 132744, "start": 1345.76, "end": 1351.76, "text": " instrumental restriction. So this is part of our mechanism. So it means that in our", "tokens": [51280, 17388, 29529, 13, 407, 341, 307, 644, 295, 527, 7513, 13, 407, 309, 1355, 300, 294, 527, 51580], "temperature": 0.0, "avg_logprob": -0.16787882696224166, "compression_ratio": 1.751219512195122, "no_speech_prob": 0.0024652413558214903}, {"id": 196, "seek": 135176, "start": 1352.48, "end": 1357.92, "text": " experiment, we are working with measurements that I like to co-example, that are measurements", "tokens": [50400, 5120, 11, 321, 366, 1364, 365, 15383, 300, 286, 411, 281, 598, 12, 3121, 335, 781, 11, 300, 366, 15383, 50672], "temperature": 0.0, "avg_logprob": -0.21799925309193285, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.003155728569254279}, {"id": 197, "seek": 135176, "start": 1358.96, "end": 1361.76, "text": " that are not revealing perverts processed by a system.", "tokens": [50724, 300, 366, 406, 23983, 680, 36999, 18846, 538, 257, 1185, 13, 50864], "temperature": 0.0, "avg_logprob": -0.21799925309193285, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.003155728569254279}, {"id": 198, "seek": 135176, "start": 1363.76, "end": 1372.64, "text": " And we know that this view on measurement is a very common view on content measurements,", "tokens": [50964, 400, 321, 458, 300, 341, 1910, 322, 13160, 307, 257, 588, 2689, 1910, 322, 2701, 15383, 11, 51408], "temperature": 0.0, "avg_logprob": -0.21799925309193285, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.003155728569254279}, {"id": 199, "seek": 135176, "start": 1372.64, "end": 1376.64, "text": " because we have Cauchy's Becker theorem. And Cauchy's Becker theorem says that", "tokens": [51408, 570, 321, 362, 7544, 625, 88, 311, 879, 9178, 20904, 13, 400, 7544, 625, 88, 311, 879, 9178, 20904, 1619, 300, 51608], "temperature": 0.0, "avg_logprob": -0.21799925309193285, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.003155728569254279}, {"id": 200, "seek": 137664, "start": 1377.2800000000002, "end": 1381.8400000000001, "text": " self-adjoint operators cannot be thought of as representing perverts simultaneously", "tokens": [50396, 2698, 12, 345, 48613, 19077, 2644, 312, 1194, 295, 382, 13460, 680, 36999, 16561, 50624], "temperature": 0.0, "avg_logprob": -0.1539391581217448, "compression_ratio": 1.75, "no_speech_prob": 0.001616934547200799}, {"id": 201, "seek": 137664, "start": 1381.8400000000001, "end": 1389.3600000000001, "text": " processed by a system. So Cauchy's Becker theorem suggests some kind of substantive", "tokens": [50624, 18846, 538, 257, 1185, 13, 407, 7544, 625, 88, 311, 879, 9178, 20904, 13409, 512, 733, 295, 47113, 51000], "temperature": 0.0, "avg_logprob": -0.1539391581217448, "compression_ratio": 1.75, "no_speech_prob": 0.001616934547200799}, {"id": 202, "seek": 137664, "start": 1389.3600000000001, "end": 1394.16, "text": " view on measurements. So we have to accept that measurements are not revealing perverts", "tokens": [51000, 1910, 322, 15383, 13, 407, 321, 362, 281, 3241, 300, 15383, 366, 406, 23983, 680, 36999, 51240], "temperature": 0.0, "avg_logprob": -0.1539391581217448, "compression_ratio": 1.75, "no_speech_prob": 0.001616934547200799}, {"id": 203, "seek": 137664, "start": 1394.16, "end": 1400.0, "text": " processed by a system, or at least that they are not revealing perverts that are", "tokens": [51240, 18846, 538, 257, 1185, 11, 420, 412, 1935, 300, 436, 366, 406, 23983, 680, 36999, 300, 366, 51532], "temperature": 0.0, "avg_logprob": -0.1539391581217448, "compression_ratio": 1.75, "no_speech_prob": 0.001616934547200799}, {"id": 204, "seek": 140000, "start": 1400.96, "end": 1406.88, "text": " simultaneously processed by the system. But the point is that if the measurements we have", "tokens": [50412, 16561, 18846, 538, 264, 1185, 13, 583, 264, 935, 307, 300, 498, 264, 15383, 321, 362, 50708], "temperature": 0.0, "avg_logprob": -0.11475554457655898, "compression_ratio": 2.049107142857143, "no_speech_prob": 0.003872967092320323}, {"id": 205, "seek": 140000, "start": 1406.88, "end": 1412.16, "text": " are epistemic, so if the measurements we have are not revealing perverts of a system,", "tokens": [50708, 366, 2388, 468, 3438, 11, 370, 498, 264, 15383, 321, 362, 366, 406, 23983, 680, 36999, 295, 257, 1185, 11, 50972], "temperature": 0.0, "avg_logprob": -0.11475554457655898, "compression_ratio": 2.049107142857143, "no_speech_prob": 0.003872967092320323}, {"id": 206, "seek": 140000, "start": 1412.16, "end": 1419.36, "text": " then we have contextuality in the data. So the data our system generates will violate", "tokens": [50972, 550, 321, 362, 35526, 507, 294, 264, 1412, 13, 407, 264, 1412, 527, 1185, 23815, 486, 37478, 51332], "temperature": 0.0, "avg_logprob": -0.11475554457655898, "compression_ratio": 2.049107142857143, "no_speech_prob": 0.003872967092320323}, {"id": 207, "seek": 140000, "start": 1419.36, "end": 1423.6, "text": " non-contextuality and equivalence. And it's not because the system is non-classical or it's classical,", "tokens": [51332, 2107, 12, 9000, 3828, 901, 507, 293, 9052, 655, 13, 400, 309, 311, 406, 570, 264, 1185, 307, 2107, 12, 11665, 804, 420, 309, 311, 13735, 11, 51544], "temperature": 0.0, "avg_logprob": -0.11475554457655898, "compression_ratio": 2.049107142857143, "no_speech_prob": 0.003872967092320323}, {"id": 208, "seek": 140000, "start": 1423.6, "end": 1429.28, "text": " it's because measurements are epistemic. And the reasons that epistemic measurements cannot be", "tokens": [51544, 309, 311, 570, 15383, 366, 2388, 468, 3438, 13, 400, 264, 4112, 300, 2388, 468, 3438, 15383, 2644, 312, 51828], "temperature": 0.0, "avg_logprob": -0.11475554457655898, "compression_ratio": 2.049107142857143, "no_speech_prob": 0.003872967092320323}, {"id": 209, "seek": 142928, "start": 1429.28, "end": 1434.96, "text": " defined as random variables share in the same sample space. So we cannot define the", "tokens": [50364, 7642, 382, 4974, 9102, 2073, 294, 264, 912, 6889, 1901, 13, 407, 321, 2644, 6964, 264, 50648], "temperature": 0.0, "avg_logprob": -0.14002294289438347, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001166334142908454}, {"id": 210, "seek": 142928, "start": 1434.96, "end": 1441.84, "text": " measurements because the measurements that are like coin flippings in our thought experiment,", "tokens": [50648, 15383, 570, 264, 15383, 300, 366, 411, 11464, 932, 2488, 1109, 294, 527, 1194, 5120, 11, 50992], "temperature": 0.0, "avg_logprob": -0.14002294289438347, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001166334142908454}, {"id": 211, "seek": 142928, "start": 1441.84, "end": 1447.04, "text": " we cannot represent those measurements as random variables in the same sample space.", "tokens": [50992, 321, 2644, 2906, 729, 15383, 382, 4974, 9102, 294, 264, 912, 6889, 1901, 13, 51252], "temperature": 0.0, "avg_logprob": -0.14002294289438347, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001166334142908454}, {"id": 212, "seek": 142928, "start": 1448.08, "end": 1457.68, "text": " And that's why we have contextuality in content systems, I think. And we must recall that", "tokens": [51304, 400, 300, 311, 983, 321, 362, 35526, 507, 294, 2701, 3652, 11, 286, 519, 13, 400, 321, 1633, 9901, 300, 51784], "temperature": 0.0, "avg_logprob": -0.14002294289438347, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.001166334142908454}, {"id": 213, "seek": 145768, "start": 1457.68, "end": 1465.1200000000001, "text": " KS theorem, Cauchy-Specker theorem is about realism, it's not about classicality. So to sum up,", "tokens": [50364, 591, 50, 20904, 11, 7544, 625, 88, 12, 50, 494, 9178, 20904, 307, 466, 38484, 11, 309, 311, 406, 466, 13735, 507, 13, 407, 281, 2408, 493, 11, 50736], "temperature": 0.0, "avg_logprob": -0.16319060832896132, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.002312765456736088}, {"id": 214, "seek": 145768, "start": 1466.3200000000002, "end": 1473.44, "text": " in quantum mechanics, we have, so in general, actually, if we have epistemic measurements,", "tokens": [50796, 294, 13018, 12939, 11, 321, 362, 11, 370, 294, 2674, 11, 767, 11, 498, 321, 362, 2388, 468, 3438, 15383, 11, 51152], "temperature": 0.0, "avg_logprob": -0.16319060832896132, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.002312765456736088}, {"id": 215, "seek": 145768, "start": 1473.44, "end": 1477.3600000000001, "text": " or if we have measurements that are not revealing perverts processed by a system,", "tokens": [51152, 420, 498, 321, 362, 15383, 300, 366, 406, 23983, 680, 36999, 18846, 538, 257, 1185, 11, 51348], "temperature": 0.0, "avg_logprob": -0.16319060832896132, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.002312765456736088}, {"id": 216, "seek": 145768, "start": 1477.3600000000001, "end": 1482.8, "text": " and if we have context, so if we have these restrictions on what we can measure jointly,", "tokens": [51348, 293, 498, 321, 362, 4319, 11, 370, 498, 321, 362, 613, 14191, 322, 437, 321, 393, 3481, 46557, 11, 51620], "temperature": 0.0, "avg_logprob": -0.16319060832896132, "compression_ratio": 1.6839622641509433, "no_speech_prob": 0.002312765456736088}, {"id": 217, "seek": 148280, "start": 1483.44, "end": 1489.2, "text": " then we have contextual data. So we have no ground for expecting non-contextuality in the data,", "tokens": [50396, 550, 321, 362, 35526, 1412, 13, 407, 321, 362, 572, 2727, 337, 9650, 2107, 12, 9000, 3828, 901, 507, 294, 264, 1412, 11, 50684], "temperature": 0.0, "avg_logprob": -0.13011694528970374, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0015426165191456676}, {"id": 218, "seek": 148280, "start": 1489.2, "end": 1495.2, "text": " because our measurements are not random variables in the same sample space. So", "tokens": [50684, 570, 527, 15383, 366, 406, 4974, 9102, 294, 264, 912, 6889, 1901, 13, 407, 50984], "temperature": 0.0, "avg_logprob": -0.13011694528970374, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0015426165191456676}, {"id": 219, "seek": 148280, "start": 1496.1599999999999, "end": 1502.32, "text": " I think that this thought experiment suggests that those who accept the epistemic view on", "tokens": [51032, 286, 519, 300, 341, 1194, 5120, 13409, 300, 729, 567, 3241, 264, 2388, 468, 3438, 1910, 322, 51340], "temperature": 0.0, "avg_logprob": -0.13011694528970374, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0015426165191456676}, {"id": 220, "seek": 148280, "start": 1502.32, "end": 1508.32, "text": " measurements, that is the view suggested, for example, by the orthodox interpretation of this,", "tokens": [51340, 15383, 11, 300, 307, 264, 1910, 10945, 11, 337, 1365, 11, 538, 264, 19052, 22189, 14174, 295, 341, 11, 51640], "temperature": 0.0, "avg_logprob": -0.13011694528970374, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0015426165191456676}, {"id": 221, "seek": 150832, "start": 1508.32, "end": 1515.4399999999998, "text": " this is the view hold by bar, and this is a very widespread view on quantum measurements", "tokens": [50364, 341, 307, 264, 1910, 1797, 538, 2159, 11, 293, 341, 307, 257, 588, 22679, 1910, 322, 13018, 15383, 50720], "temperature": 0.0, "avg_logprob": -0.14411557592996738, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002695928793400526}, {"id": 222, "seek": 150832, "start": 1515.4399999999998, "end": 1521.36, "text": " in quantum mechanics. So those who accepted this view, I think that should not take for granted", "tokens": [50720, 294, 13018, 12939, 13, 407, 729, 567, 9035, 341, 1910, 11, 286, 519, 300, 820, 406, 747, 337, 12344, 51016], "temperature": 0.0, "avg_logprob": -0.14411557592996738, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002695928793400526}, {"id": 223, "seek": 150832, "start": 1521.36, "end": 1527.36, "text": " that nature fails to respect classical physics when quantum systems violate non-contextuality", "tokens": [51016, 300, 3687, 18199, 281, 3104, 13735, 10649, 562, 13018, 3652, 37478, 2107, 12, 9000, 3828, 901, 507, 51316], "temperature": 0.0, "avg_logprob": -0.14411557592996738, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002695928793400526}, {"id": 224, "seek": 150832, "start": 1527.36, "end": 1533.76, "text": " in the file. So it seems that these violations are actually our consequence of the type of", "tokens": [51316, 294, 264, 3991, 13, 407, 309, 2544, 300, 613, 30405, 366, 767, 527, 18326, 295, 264, 2010, 295, 51636], "temperature": 0.0, "avg_logprob": -0.14411557592996738, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002695928793400526}, {"id": 225, "seek": 153376, "start": 1533.76, "end": 1538.4, "text": " measurements we are considering. And if we accept that the measurements we have in quantum", "tokens": [50364, 15383, 321, 366, 8079, 13, 400, 498, 321, 3241, 300, 264, 15383, 321, 362, 294, 13018, 50596], "temperature": 0.0, "avg_logprob": -0.09775516059663561, "compression_ratio": 1.6629834254143647, "no_speech_prob": 0.002493702806532383}, {"id": 226, "seek": 153376, "start": 1538.4, "end": 1544.48, "text": " systems are epistemic measurements, then we should be, we should not say that", "tokens": [50596, 3652, 366, 2388, 468, 3438, 15383, 11, 550, 321, 820, 312, 11, 321, 820, 406, 584, 300, 50900], "temperature": 0.0, "avg_logprob": -0.09775516059663561, "compression_ratio": 1.6629834254143647, "no_speech_prob": 0.002493702806532383}, {"id": 227, "seek": 153376, "start": 1544.48, "end": 1551.44, "text": " nature fails to respect classical physics when these violations occur. And that's it,", "tokens": [50900, 3687, 18199, 281, 3104, 13735, 10649, 562, 613, 30405, 5160, 13, 400, 300, 311, 309, 11, 51248], "temperature": 0.0, "avg_logprob": -0.09775516059663561, "compression_ratio": 1.6629834254143647, "no_speech_prob": 0.002493702806532383}, {"id": 228, "seek": 153376, "start": 1551.44, "end": 1554.64, "text": " that's what I had to say today. And thank you.", "tokens": [51248, 300, 311, 437, 286, 632, 281, 584, 965, 13, 400, 1309, 291, 13, 51408], "temperature": 0.0, "avg_logprob": -0.09775516059663561, "compression_ratio": 1.6629834254143647, "no_speech_prob": 0.002493702806532383}, {"id": 229, "seek": 155464, "start": 1555.5200000000002, "end": 1566.64, "text": " Thanks, Alison. Thanks for this talk. So we have some time for one short question,", "tokens": [50408, 2561, 11, 41001, 13, 2561, 337, 341, 751, 13, 407, 321, 362, 512, 565, 337, 472, 2099, 1168, 11, 50964], "temperature": 0.0, "avg_logprob": -0.23784330156114367, "compression_ratio": 1.2941176470588236, "no_speech_prob": 0.006233332213014364}, {"id": 230, "seek": 155464, "start": 1566.64, "end": 1574.64, "text": " because now we are on 9.56. So if someone has a question, please go on.", "tokens": [50964, 570, 586, 321, 366, 322, 1722, 13, 18317, 13, 407, 498, 1580, 575, 257, 1168, 11, 1767, 352, 322, 13, 51364], "temperature": 0.0, "avg_logprob": -0.23784330156114367, "compression_ratio": 1.2941176470588236, "no_speech_prob": 0.006233332213014364}, {"id": 231, "seek": 157464, "start": 1575.3600000000001, "end": 1587.6000000000001, "text": " So I have a question or perhaps an observation, which is you can see the violation of", "tokens": [50400, 407, 286, 362, 257, 1168, 420, 4317, 364, 14816, 11, 597, 307, 291, 393, 536, 264, 22840, 295, 51012], "temperature": 0.0, "avg_logprob": -0.2190152545307958, "compression_ratio": 1.3384615384615384, "no_speech_prob": 0.00646522082388401}, {"id": 232, "seek": 157464, "start": 1589.0400000000002, "end": 1596.16, "text": " Bell inequalities as a particular case of a non-contextuality inequality, right? Because", "tokens": [51084, 11485, 41874, 382, 257, 1729, 1389, 295, 257, 2107, 12, 9000, 3828, 901, 507, 16970, 11, 558, 30, 1436, 51440], "temperature": 0.0, "avg_logprob": -0.2190152545307958, "compression_ratio": 1.3384615384615384, "no_speech_prob": 0.00646522082388401}, {"id": 233, "seek": 159616, "start": 1597.0400000000002, "end": 1607.6000000000001, "text": " and when you speak about model independence, it is not so independent of physical laws,", "tokens": [50408, 293, 562, 291, 1710, 466, 2316, 14640, 11, 309, 307, 406, 370, 6695, 295, 4001, 6064, 11, 50936], "temperature": 0.0, "avg_logprob": -0.20046374201774597, "compression_ratio": 1.7, "no_speech_prob": 0.04344739019870758}, {"id": 234, "seek": 159616, "start": 1607.6000000000001, "end": 1614.8000000000002, "text": " because in model independence, you have space-time structure. This is not the stress,", "tokens": [50936, 570, 294, 2316, 14640, 11, 291, 362, 1901, 12, 3766, 3877, 13, 639, 307, 406, 264, 4244, 11, 51296], "temperature": 0.0, "avg_logprob": -0.20046374201774597, "compression_ratio": 1.7, "no_speech_prob": 0.04344739019870758}, {"id": 235, "seek": 159616, "start": 1614.8000000000002, "end": 1624.88, "text": " usually in the literature about it, but otherwise, if you don't consider the space-time structure,", "tokens": [51296, 2673, 294, 264, 10394, 466, 309, 11, 457, 5911, 11, 498, 291, 500, 380, 1949, 264, 1901, 12, 3766, 3877, 11, 51800], "temperature": 0.0, "avg_logprob": -0.20046374201774597, "compression_ratio": 1.7, "no_speech_prob": 0.04344739019870758}, {"id": 236, "seek": 162488, "start": 1624.88, "end": 1631.3600000000001, "text": " you cannot speak about a model independence analysis of an analysis above scenario.", "tokens": [50364, 291, 2644, 1710, 466, 257, 2316, 14640, 5215, 295, 364, 5215, 3673, 9005, 13, 50688], "temperature": 0.0, "avg_logprob": -0.1502579759668421, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.007220970466732979}, {"id": 237, "seek": 162488, "start": 1632.0800000000002, "end": 1636.8000000000002, "text": " You cannot even speak about space-like separation between measurements, you know?", "tokens": [50724, 509, 2644, 754, 1710, 466, 1901, 12, 4092, 14634, 1296, 15383, 11, 291, 458, 30, 50960], "temperature": 0.0, "avg_logprob": -0.1502579759668421, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.007220970466732979}, {"id": 238, "seek": 162488, "start": 1638.16, "end": 1647.1200000000001, "text": " And so what I think regarding your talk is that perhaps this space-time causal structure", "tokens": [51028, 400, 370, 437, 286, 519, 8595, 428, 751, 307, 300, 4317, 341, 1901, 12, 3766, 38755, 3877, 51476], "temperature": 0.0, "avg_logprob": -0.1502579759668421, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.007220970466732979}, {"id": 239, "seek": 164712, "start": 1647.12, "end": 1656.9599999999998, "text": " should be taken into account into your analysis. I agree in that if you don't take space-like", "tokens": [50364, 820, 312, 2726, 666, 2696, 666, 428, 5215, 13, 286, 3986, 294, 300, 498, 291, 500, 380, 747, 1901, 12, 4092, 50856], "temperature": 0.0, "avg_logprob": -0.14369732783390926, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.007681143935769796}, {"id": 240, "seek": 164712, "start": 1656.9599999999998, "end": 1663.04, "text": " separation, you can reproduce everything with a classical mechanism. And I think that that is", "tokens": [50856, 14634, 11, 291, 393, 29501, 1203, 365, 257, 13735, 7513, 13, 400, 286, 519, 300, 300, 307, 51160], "temperature": 0.0, "avg_logprob": -0.14369732783390926, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.007681143935769796}, {"id": 241, "seek": 164712, "start": 1663.04, "end": 1669.6799999999998, "text": " accepted, right? I mean, because you have examples of contextuality in, for example,", "tokens": [51160, 9035, 11, 558, 30, 286, 914, 11, 570, 291, 362, 5110, 295, 35526, 507, 294, 11, 337, 1365, 11, 51492], "temperature": 0.0, "avg_logprob": -0.14369732783390926, "compression_ratio": 1.4702702702702704, "no_speech_prob": 0.007681143935769796}, {"id": 242, "seek": 166968, "start": 1669.68, "end": 1684.16, "text": " in mathematical psychology and so on. I agree. But even so, I think that you can include", "tokens": [50364, 294, 18894, 15105, 293, 370, 322, 13, 286, 3986, 13, 583, 754, 370, 11, 286, 519, 300, 291, 393, 4090, 51088], "temperature": 0.0, "avg_logprob": -0.11294116395892519, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.008336077444255352}, {"id": 243, "seek": 166968, "start": 1684.16, "end": 1690.48, "text": " the violation of Bell inequalities as a particular example of a violation of a non-contextuality", "tokens": [51088, 264, 22840, 295, 11485, 41874, 382, 257, 1729, 1365, 295, 257, 22840, 295, 257, 2107, 12, 9000, 3828, 901, 507, 51404], "temperature": 0.0, "avg_logprob": -0.11294116395892519, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.008336077444255352}, {"id": 244, "seek": 166968, "start": 1690.48, "end": 1697.76, "text": " inequality. So what do you think about that? That cannot be reproduced by any classical", "tokens": [51404, 16970, 13, 407, 437, 360, 291, 519, 466, 300, 30, 663, 2644, 312, 11408, 1232, 538, 604, 13735, 51768], "temperature": 0.0, "avg_logprob": -0.11294116395892519, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.008336077444255352}, {"id": 245, "seek": 169776, "start": 1697.76, "end": 1705.12, "text": " mechanism. What do you think about that? Yes, I agree. So that's why I contrast, I compare", "tokens": [50364, 7513, 13, 708, 360, 291, 519, 466, 300, 30, 1079, 11, 286, 3986, 13, 407, 300, 311, 983, 286, 8712, 11, 286, 6794, 50732], "temperature": 0.0, "avg_logprob": -0.13784114436099404, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.0071467263624072075}, {"id": 246, "seek": 169776, "start": 1705.12, "end": 1709.2, "text": " Bell inequalities with non-contextuality inequalities. So I know that Bell inequalities are", "tokens": [50732, 11485, 41874, 365, 2107, 12, 9000, 3828, 901, 507, 41874, 13, 407, 286, 458, 300, 11485, 41874, 366, 50936], "temperature": 0.0, "avg_logprob": -0.13784114436099404, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.0071467263624072075}, {"id": 247, "seek": 169776, "start": 1709.2, "end": 1716.4, "text": " particular case of non-contextuality inequalities. But by just saying that this idea of black box", "tokens": [50936, 1729, 1389, 295, 2107, 12, 9000, 3828, 901, 507, 41874, 13, 583, 538, 445, 1566, 300, 341, 1558, 295, 2211, 2424, 51296], "temperature": 0.0, "avg_logprob": -0.13784114436099404, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.0071467263624072075}, {"id": 248, "seek": 169776, "start": 1717.28, "end": 1723.84, "text": " works very well if we have space-life separated parts. So I agree with it. But if we have a", "tokens": [51340, 1985, 588, 731, 498, 321, 362, 1901, 12, 9073, 12005, 3166, 13, 407, 286, 3986, 365, 309, 13, 583, 498, 321, 362, 257, 51668], "temperature": 0.0, "avg_logprob": -0.13784114436099404, "compression_ratio": 1.7464788732394365, "no_speech_prob": 0.0071467263624072075}, {"id": 249, "seek": 172384, "start": 1724.8, "end": 1732.56, "text": " black box that is localized, so as the kind of box people use when they are discussing,", "tokens": [50412, 2211, 2424, 300, 307, 44574, 11, 370, 382, 264, 733, 295, 2424, 561, 764, 562, 436, 366, 10850, 11, 50800], "temperature": 0.0, "avg_logprob": -0.10750553573387256, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.009811424650251865}, {"id": 250, "seek": 172384, "start": 1732.56, "end": 1739.6799999999998, "text": " for example, resource theory for contextuality. So we have this box with many inputs. So in this case,", "tokens": [50800, 337, 1365, 11, 7684, 5261, 337, 35526, 507, 13, 407, 321, 362, 341, 2424, 365, 867, 15743, 13, 407, 294, 341, 1389, 11, 51156], "temperature": 0.0, "avg_logprob": -0.10750553573387256, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.009811424650251865}, {"id": 251, "seek": 172384, "start": 1742.08, "end": 1749.6, "text": " if we have contextual data, we not necessarily have a non-classical phenomenon or something like", "tokens": [51276, 498, 321, 362, 35526, 1412, 11, 321, 406, 4725, 362, 257, 2107, 12, 11665, 804, 14029, 420, 746, 411, 51652], "temperature": 0.0, "avg_logprob": -0.10750553573387256, "compression_ratio": 1.543010752688172, "no_speech_prob": 0.009811424650251865}, {"id": 252, "seek": 174960, "start": 1749.76, "end": 1759.36, "text": " this. So I agree with it. So if the boxes are space-life separated, then we need non-locality.", "tokens": [50372, 341, 13, 407, 286, 3986, 365, 309, 13, 407, 498, 264, 9002, 366, 1901, 12, 9073, 12005, 11, 550, 321, 643, 2107, 12, 5842, 1860, 13, 50852], "temperature": 0.0, "avg_logprob": -0.19106849623315128, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.012387709692120552}, {"id": 253, "seek": 174960, "start": 1760.8799999999999, "end": 1765.9199999999998, "text": " I see your point. Okay, I will check on the details because you have a paper on this,", "tokens": [50928, 286, 536, 428, 935, 13, 1033, 11, 286, 486, 1520, 322, 264, 4365, 570, 291, 362, 257, 3035, 322, 341, 11, 51180], "temperature": 0.0, "avg_logprob": -0.19106849623315128, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.012387709692120552}, {"id": 254, "seek": 174960, "start": 1765.9199999999998, "end": 1772.9599999999998, "text": " I've seen on the web. So I will check next week. But now we are on time. So we thank again Alison", "tokens": [51180, 286, 600, 1612, 322, 264, 3670, 13, 407, 286, 486, 1520, 958, 1243, 13, 583, 586, 321, 366, 322, 565, 13, 407, 321, 1309, 797, 41001, 51532], "temperature": 0.0, "avg_logprob": -0.19106849623315128, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.012387709692120552}, {"id": 255, "seek": 177296, "start": 1772.96, "end": 1782.24, "text": " for this nice talk. Thank you. Thanks Alison. So now we call Diego to share your screen.", "tokens": [50364, 337, 341, 1481, 751, 13, 1044, 291, 13, 2561, 41001, 13, 407, 586, 321, 818, 16377, 281, 2073, 428, 2568, 13, 50828], "temperature": 0.0, "avg_logprob": -0.21485769271850585, "compression_ratio": 1.5, "no_speech_prob": 0.0487048476934433}, {"id": 256, "seek": 177296, "start": 1784.96, "end": 1795.3600000000001, "text": " So Alison, okay, great. So thanks Alison. So now we are on time for the Diego's talk.", "tokens": [50964, 407, 41001, 11, 1392, 11, 869, 13, 407, 3231, 41001, 13, 407, 586, 321, 366, 322, 565, 337, 264, 16377, 311, 751, 13, 51484], "temperature": 0.0, "avg_logprob": -0.21485769271850585, "compression_ratio": 1.5, "no_speech_prob": 0.0487048476934433}, {"id": 257, "seek": 179536, "start": 1795.36, "end": 1805.4399999999998, "text": " Great, great. So now we're glad to have Diego Boussandri from the Institute of Physics La Plata", "tokens": [50364, 3769, 11, 869, 13, 407, 586, 321, 434, 5404, 281, 362, 16377, 363, 563, 82, 474, 470, 490, 264, 9446, 295, 38355, 2369, 2149, 3274, 50868], "temperature": 0.0, "avg_logprob": -0.15797638547593268, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.058174487203359604}, {"id": 258, "seek": 179536, "start": 1806.32, "end": 1812.32, "text": " and the National University of La Plata. And he will speak about revisiting maximal", "tokens": [50912, 293, 264, 4862, 3535, 295, 2369, 2149, 3274, 13, 400, 415, 486, 1710, 466, 20767, 1748, 49336, 51212], "temperature": 0.0, "avg_logprob": -0.15797638547593268, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.058174487203359604}, {"id": 259, "seek": 179536, "start": 1812.32, "end": 1818.8, "text": " fidelity of teleportation. Please Diego, go on. Thank you very much for the presentation.", "tokens": [51212, 46404, 295, 28050, 399, 13, 2555, 16377, 11, 352, 322, 13, 1044, 291, 588, 709, 337, 264, 5860, 13, 51536], "temperature": 0.0, "avg_logprob": -0.15797638547593268, "compression_ratio": 1.4308510638297873, "no_speech_prob": 0.058174487203359604}, {"id": 260, "seek": 181880, "start": 1819.52, "end": 1827.04, "text": " So let's talk. Diego, wait, your sound is low. You could speak like this and it's good, but if you", "tokens": [50400, 407, 718, 311, 751, 13, 16377, 11, 1699, 11, 428, 1626, 307, 2295, 13, 509, 727, 1710, 411, 341, 293, 309, 311, 665, 11, 457, 498, 291, 50776], "temperature": 0.0, "avg_logprob": -0.31569573283195496, "compression_ratio": 1.385135135135135, "no_speech_prob": 0.07591107487678528}, {"id": 261, "seek": 181880, "start": 1827.04, "end": 1833.2, "text": " could. Now? Now it's much better. Thanks, thanks. Please, go on. Thank you.", "tokens": [50776, 727, 13, 823, 30, 823, 309, 311, 709, 1101, 13, 2561, 11, 3231, 13, 2555, 11, 352, 322, 13, 1044, 291, 13, 51084], "temperature": 0.0, "avg_logprob": -0.31569573283195496, "compression_ratio": 1.385135135135135, "no_speech_prob": 0.07591107487678528}, {"id": 262, "seek": 181880, "start": 1840.24, "end": 1844.8799999999999, "text": " Sorry. No problem, no problem.", "tokens": [51436, 4919, 13, 883, 1154, 11, 572, 1154, 13, 51668], "temperature": 0.0, "avg_logprob": -0.31569573283195496, "compression_ratio": 1.385135135135135, "no_speech_prob": 0.07591107487678528}, {"id": 263, "seek": 184880, "start": 1848.8799999999999, "end": 1860.1599999999999, "text": " Now, okay, let's talk about then about fidelity of teleportation. This is a work we made with", "tokens": [50368, 823, 11, 1392, 11, 718, 311, 751, 466, 550, 466, 46404, 295, 28050, 399, 13, 639, 307, 257, 589, 321, 1027, 365, 50932], "temperature": 0.0, "avg_logprob": -0.32037841796875, "compression_ratio": 1.2482758620689656, "no_speech_prob": 0.006628681439906359}, {"id": 264, "seek": 184880, "start": 1860.1599999999999, "end": 1870.72, "text": " Madeira Portesi and Anna Mast\u00e9. And so what did we do? We obtained the maximal average", "tokens": [50932, 18330, 4271, 6733, 21181, 293, 12899, 376, 525, 526, 13, 400, 370, 437, 630, 321, 360, 30, 492, 14879, 264, 49336, 4274, 51460], "temperature": 0.0, "avg_logprob": -0.32037841796875, "compression_ratio": 1.2482758620689656, "no_speech_prob": 0.006628681439906359}, {"id": 265, "seek": 187072, "start": 1871.68, "end": 1879.1200000000001, "text": " fidelity of teleportation or the score of a given protocol for two situations, the standard", "tokens": [50412, 46404, 295, 28050, 399, 420, 264, 6175, 295, 257, 2212, 10336, 337, 732, 6851, 11, 264, 3832, 50784], "temperature": 0.0, "avg_logprob": -0.262065500826449, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.028065817430615425}, {"id": 266, "seek": 187072, "start": 1879.1200000000001, "end": 1888.56, "text": " quantum teleportation protocol characterized by a particular measurement. So one second.", "tokens": [50784, 13018, 28050, 399, 10336, 29361, 538, 257, 1729, 13160, 13, 407, 472, 1150, 13, 51256], "temperature": 0.0, "avg_logprob": -0.262065500826449, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.028065817430615425}, {"id": 267, "seek": 188856, "start": 1888.8, "end": 1900.8799999999999, "text": " Now, we calculate so the maximal average fidelity of teleportation for the...", "tokens": [50376, 823, 11, 321, 8873, 370, 264, 49336, 4274, 46404, 295, 28050, 399, 337, 264, 485, 50980], "temperature": 0.0, "avg_logprob": -0.32097448151687097, "compression_ratio": 1.3037974683544304, "no_speech_prob": 0.0683501735329628}, {"id": 268, "seek": 188856, "start": 1900.8799999999999, "end": 1905.04, "text": " The sound is again low. I don't know if everyone is...", "tokens": [50980, 440, 1626, 307, 797, 2295, 13, 286, 500, 380, 458, 498, 1518, 307, 485, 51188], "temperature": 0.0, "avg_logprob": -0.32097448151687097, "compression_ratio": 1.3037974683544304, "no_speech_prob": 0.0683501735329628}, {"id": 269, "seek": 188856, "start": 1907.52, "end": 1914.32, "text": " What happened? Now? Yeah, now it's better. Yes. Sorry, sorry. No problem.", "tokens": [51312, 708, 2011, 30, 823, 30, 865, 11, 586, 309, 311, 1101, 13, 1079, 13, 4919, 11, 2597, 13, 883, 1154, 13, 51652], "temperature": 0.0, "avg_logprob": -0.32097448151687097, "compression_ratio": 1.3037974683544304, "no_speech_prob": 0.0683501735329628}, {"id": 270, "seek": 191432, "start": 1915.2, "end": 1921.6799999999998, "text": " Then we obtained the average identity in two situations, the standard quantum teleportation", "tokens": [50408, 1396, 321, 14879, 264, 4274, 6575, 294, 732, 6851, 11, 264, 3832, 13018, 28050, 399, 50732], "temperature": 0.0, "avg_logprob": -0.21390907581035906, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.014694422483444214}, {"id": 271, "seek": 191432, "start": 1921.6799999999998, "end": 1929.12, "text": " protocol characterized by a particular measurement in which there is a projection onto the bell", "tokens": [50732, 10336, 29361, 538, 257, 1729, 13160, 294, 597, 456, 307, 257, 22743, 3911, 264, 4549, 51104], "temperature": 0.0, "avg_logprob": -0.21390907581035906, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.014694422483444214}, {"id": 272, "seek": 191432, "start": 1929.12, "end": 1935.76, "text": " bus. And another protocol whose characteristic measurement is something in the middle between", "tokens": [51104, 1255, 13, 400, 1071, 10336, 6104, 16282, 13160, 307, 746, 294, 264, 2808, 1296, 51436], "temperature": 0.0, "avg_logprob": -0.21390907581035906, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.014694422483444214}, {"id": 273, "seek": 193576, "start": 1935.76, "end": 1946.64, "text": " the computational basis and the bell, bell bus. But our differential feature is that we calculate", "tokens": [50364, 264, 28270, 5143, 293, 264, 4549, 11, 4549, 1255, 13, 583, 527, 15756, 4111, 307, 300, 321, 8873, 50908], "temperature": 0.0, "avg_logprob": -0.2487100904638117, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.007308065425604582}, {"id": 274, "seek": 193576, "start": 1946.64, "end": 1957.36, "text": " this for isotropic distribution of input states, not only the heart measure. I mean not only your", "tokens": [50908, 341, 337, 38018, 39173, 7316, 295, 4846, 4368, 11, 406, 787, 264, 1917, 3481, 13, 286, 914, 406, 787, 428, 51444], "temperature": 0.0, "avg_logprob": -0.2487100904638117, "compression_ratio": 1.4130434782608696, "no_speech_prob": 0.007308065425604582}, {"id": 275, "seek": 195736, "start": 1957.36, "end": 1972.6399999999999, "text": " estimates. So we are going to talk about useful protocols. Namely, a protocol is useful when", "tokens": [50364, 20561, 13, 407, 321, 366, 516, 281, 751, 466, 4420, 20618, 13, 10684, 736, 11, 257, 10336, 307, 4420, 562, 51128], "temperature": 0.0, "avg_logprob": -0.16296570036146377, "compression_ratio": 1.3795620437956204, "no_speech_prob": 0.00651824614033103}, {"id": 276, "seek": 195736, "start": 1972.6399999999999, "end": 1981.28, "text": " its average fidelity is greater than the classical one. Our key point or our main result is that", "tokens": [51128, 1080, 4274, 46404, 307, 5044, 813, 264, 13735, 472, 13, 2621, 2141, 935, 420, 527, 2135, 1874, 307, 300, 51560], "temperature": 0.0, "avg_logprob": -0.16296570036146377, "compression_ratio": 1.3795620437956204, "no_speech_prob": 0.00651824614033103}, {"id": 277, "seek": 198128, "start": 1982.24, "end": 1988.56, "text": " when you take an average of a more general distribution than the heart measure,", "tokens": [50412, 562, 291, 747, 364, 4274, 295, 257, 544, 2674, 7316, 813, 264, 1917, 3481, 11, 50728], "temperature": 0.0, "avg_logprob": -0.14329741863494225, "compression_ratio": 1.4863013698630136, "no_speech_prob": 0.0016956230392679572}, {"id": 278, "seek": 198128, "start": 1989.84, "end": 1998.32, "text": " the quantum teleportation protocol can be useful when your resource has no quantum correlation.", "tokens": [50792, 264, 13018, 28050, 399, 10336, 393, 312, 4420, 562, 428, 7684, 575, 572, 13018, 20009, 13, 51216], "temperature": 0.0, "avg_logprob": -0.14329741863494225, "compression_ratio": 1.4863013698630136, "no_speech_prob": 0.0016956230392679572}, {"id": 279, "seek": 198128, "start": 1998.32, "end": 2001.36, "text": " So even for a classical quantum estimate.", "tokens": [51216, 407, 754, 337, 257, 13735, 13018, 12539, 13, 51368], "temperature": 0.0, "avg_logprob": -0.14329741863494225, "compression_ratio": 1.4863013698630136, "no_speech_prob": 0.0016956230392679572}, {"id": 280, "seek": 200136, "start": 2001.36, "end": 2012.8, "text": " Well, what is the meaning of the fidelity of teleportation? Let us suppose that we have a", "tokens": [50364, 1042, 11, 437, 307, 264, 3620, 295, 264, 46404, 295, 28050, 399, 30, 961, 505, 7297, 300, 321, 362, 257, 50936], "temperature": 0.0, "avg_logprob": -0.29298763689787494, "compression_ratio": 1.4198473282442747, "no_speech_prob": 0.001903183409012854}, {"id": 281, "seek": 200136, "start": 2012.8, "end": 2021.6, "text": " protocol p producing output s state given by rho a out with probability p i for an input s state", "tokens": [50936, 10336, 280, 10501, 5598, 262, 1785, 2212, 538, 20293, 257, 484, 365, 8482, 280, 741, 337, 364, 4846, 262, 1785, 51376], "temperature": 0.0, "avg_logprob": -0.29298763689787494, "compression_ratio": 1.4198473282442747, "no_speech_prob": 0.001903183409012854}, {"id": 282, "seek": 202160, "start": 2021.76, "end": 2032.3999999999999, "text": " or a qubit state given by rho a. And rho a is characterized by its block vector t.", "tokens": [50372, 420, 257, 421, 5260, 1785, 2212, 538, 20293, 257, 13, 400, 20293, 257, 307, 29361, 538, 1080, 3461, 8062, 256, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1721845709759256, "compression_ratio": 1.3643410852713178, "no_speech_prob": 0.002971925074234605}, {"id": 283, "seek": 202160, "start": 2034.0, "end": 2043.6, "text": " And so if you want to know how well the quantum teleportation was performed, you can quantify", "tokens": [50984, 400, 370, 498, 291, 528, 281, 458, 577, 731, 264, 13018, 28050, 399, 390, 10332, 11, 291, 393, 40421, 51464], "temperature": 0.0, "avg_logprob": -0.1721845709759256, "compression_ratio": 1.3643410852713178, "no_speech_prob": 0.002971925074234605}, {"id": 284, "seek": 204360, "start": 2043.6, "end": 2056.96, "text": " the similarity between rho a and the final output, calculating equation one. But this mesh", "tokens": [50364, 264, 32194, 1296, 20293, 257, 293, 264, 2572, 5598, 11, 28258, 5367, 472, 13, 583, 341, 17407, 51032], "temperature": 0.0, "avg_logprob": -0.24126415252685546, "compression_ratio": 1.0975609756097562, "no_speech_prob": 0.01133912242949009}], "language": "en"}