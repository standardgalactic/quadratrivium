Okay. Okay, welcome to the second part of the conference of this day. The first talk of this
session is in charge of Michael Jensen from the University of Minnesota. The title of the talk is
quantum kinematics. A new framework for handling probabilities. Go on, Michael.
Okay. Thank you very much for the invitation. Everybody can see my screen. I hope you had
a chance to read my abstract. So what I'll be doing for the most part is to talk about the
correlations you can get with the proverbial Alice and Bob performing measurements on two spin half
particles entangled in the singlet state. And I'll represent the class of correlations that you can
get in that kind of, like I should say, in a setup that was suggested by David Merman,
where Alice and Bob both choose from the same three observables that they're going to measure.
And I'm going to be looking at the kind of correlations that are allowed in that setup,
if you just restrict it to like anything that's non-signaling, anything that can be
done quantum mechanically, and anything that can be done like with local hidden variable theories.
And I'll show you that there is a nice three-dimensional graphical representation of that.
So the work is based on a book that I wrote with Michael Janus and Michael Faro.
So here is the three of us, like in Minneapolis a few years ago. And since the names of the three of
us are sort of variations on Michael, like this has become known in certain circles already as
the three mics manifesto. The book will come out in January. It's in the series Boston Studies in
the Philosophy and History of Science. And its official title is Understanding Quantum Raffles.
Now the book was inspired, and this is the banana that you'll be seeing as my background image
throughout the talk, by this book by Jeff Boop, Banana World, Quantum Mechanics for Primates.
And here you see a picture of me and Jeff at a conference in 2019, like in Santiago,
like following actually right this conference in Cordoba in 2019, where I also gave the talk and
had a great time. So I should also like put in a plug for like the sequel to Banana World,
which is one of my favorite books. It's a serious comic on entanglement by Jeff and his daughter
Tanya, a graphic artist called like Totally, Totally Random. So here's the set up I want to
talk about. And so instead of talking about spin half particles, I'm going to be talking about
like entangled bananas, like I said, in honor of Jeff's book. And so what we have, we start out
with like a pair of entangled bananas, right? So they are described by the usual, you know,
singlet state. And then like Alice and Bob, you know, the side like on one of three ways to
peel the banana. And so this is basically just window dressing for like, you know, they have,
they have like a Dubois magnet with which they measure spin in a certain direction. And now
they're going to hold their banana in a particular direction, you know, while peeling it. And then
they take a bite out of the banana and determine whether the banana tastes yasta, tastes yummy,
or nasty, right? So and the results are we're going to, we're going to put like in a correlation
array, which is really the workhorse of Jeff's book, Banana World. And so here you see like,
you know, Alice can measure A, B and C, Bob can measure A, B and C, they can only find,
you know, plus or minus corresponding to yummy and nasty. And what you see is that if they happen,
all the runs in which they happen to peel the same way, they find like a perfect impact correlation,
and in all the runs in which they peel different ways, they find like an imperfect, like positive
correlation, right? So look at A, B. So there is like, you know, like a three fourth chance of them
finding the same 75% chance of finding the same, and only a 25% chance of them finding opposite.
And the question is like, you know, like, what's how to, how to account for this? Now, so this is
like what you get in this Merman setup, if the angles between like the peeling directions are
like 120 degrees. Now, you can consider like a more general correlation array of this sort.
And we're going to consider like, you know, any array that would like this, that would be
non signaling, right? And in order to guarantee non signaling, if you have these anti correlations,
like on the diagonal, it has to be the case that you get uniform marginals. And you do that by
making sure that in all the off diagonal cells, the sum of both the two rows and the two columns
is equal to a half, right? And so since the probabilities, of course, also have to be like
numbers between zero and one, you get that you can parameterize this by these chi's that I have here,
and these chi's can run for all the way from minus one to plus one, right? And so I can characterize
this correlation array by having three of these parameters for three of these cells, right? This
thing is also going to be symmetric. It doesn't matter if you switch like A and B. So that's the
story here. And you see that in the special case that is considered by Merman, that these chi values
are equal to minus a half, right? So stick that in here. If you put in like minus a half, like this
would be, you know, three halves. So this would be three eighths, right? And this would be, you know,
like, you know, one eighth, right? So you recover that, you recover that Merman's correlation array.
But again, like, you know, you, you, this is a more general form of it. Now, what we're going to try
and do is to see like how, like what subclass of those correlations we can simulate, like with a
raffle, right? And the raffle is our toy model for a local hidden variable theme. And so we have,
we imagine that you have a basket with a bunch of tickets in it, and the tickets like half the
outcomes for like all possible measurements that Alice and Bob can do. Now look at the first ticket,
like, you know, we know that if they, if they measure the same way that they find opposite
results, right? So like, you know, the results on two halves of the tickets have better be up,
has better be opposite. The way it works is that you take a ticket, you rip the ticket in half,
and then you randomly decide like which one goes to Alice and which one goes to Bob, right? So a
ticket where you just switch the left and the right side does not give you a, this does not give
you a new ticket. So with that said, there is like four different tickets, right? So it doesn't
have to be the case that all the pluses are on one side, you could have a case where two of the
pluses are on one side. And like, you know, with one minus, and again, there is three ways of doing
this, right? So you have the minus here is for C here, the minus is for B, and here the minus is
for A, right? And again, keep in mind that it doesn't matter which side of the ticket you're
looking at. Now, we can easily see like if you had like single ticket raffles, just like a basket
with one type, what these sky parameters would be, you know, for your correlation array. Because you
can see that if you have this ticket, no matter whether you take like AA, AB or AC, you always
have like a perfect anti-correlation. And that means that these sky values have to be like plus
one. Like maybe I should go just like back here, right? So the moment that chi is plus one, right,
then you see you have an anti-correlation, the moment that chi is minus one, you have like a
perfect correlation. So okay, so that's easy. Now look at this ticket, there's a little more
complicated. So for AB, you see that there's still a perfect anti-correlation. But if you now look at
AC or at BC, you see that there's a correlation. So you have minus one. And the same is true for
C and D, right? It's just that a different parameter will get like the plus and the other two parameters
will be minus. And here then you immediately have like a bell inequality of the type of the
Klauser-Hornschirmann Holtz variety. And you can see that, you know, like the sum of these three
parameters is three, four ticket A, and it's going to be minus one for all other tickets. So if you
take like an arbitrary mix of tickets, right, you would always get like a value somewhere between
minus one and three. So and you see that Merman's example where chi, where these three chi's are
minus a half. So that would be, if your sum would be minus three halves, violates this inequality.
Now, the nice thing about this is that you can come up with a very nice geometrical representation
of the situation. And that is essentially due to Jeff's long-time collaborator,
now deceased, unfortunately, Idemar Petovsky. And so first of all, we start out with like, you know,
like representing these chi values, they can run from minus one to one in like what is called
like a non-signaling cube. Remember, like, you know, this was like the general form of a correlation
array that is non-signaling. And you see that these tickets, like they're represented now by
vertices of that non-signaling cube, right? So it's these four points, right, A, B, C, and D.
And a mixed raffle would be represented on like points that are like somewhere in between, right?
And once you have, so imagine, like, you know, you have your basket with tickets.
So if you take this and this and you put a certain mix, you can end up somewhere over here,
but then you take a mix of like, you know, D and C, you get somewhere over here,
but you can also like, you know, now mix those, right? So you get all of that,
and you can also like mix and match, mix and get like on the inside of this thing.
So this is like what is known as the classical tetrahedron. And this is like a very nice way of
geometrically representing, you know, what the local hidden variables here we can do.
The bell in the quality only corresponds to like one facet of this tetrahedron.
It just says that you can't be behind that plane like B, C, D, but you see that there are three
other forbidden regions that you would also have to spell out if you want to define fully,
you know, what is and what is not allowed. All right. So now in what is allowed by quantum
mechanics, right? And so in quantum mechanics, the the result that is predicted by quantum
is that these kais are just given by the cosine of the the peeling angle, right? In a way, this is
like very satisfying, right? So classically, you see that these kais with these tickets,
they're always going to be plus one or minus one, but wouldn't it be nice to have like a theory
that just allows like a like a continuity of values between minus one and plus one? Quantum
mechanics gives you just that, right? And so it's the cosine of the of the angle and that cosine,
of course, is the inner product of like unit vectors in these different peeling directions.
All right. So if you think about this correlation array, you see that the entire correlation array
can be like characterized by by these parameters, right? These sky parameters. And we can also
introduce them for the for the for the diagonal cells, where they're just one. Okay. So and so we'll
I'll I'll define this more carefully later on. But these guys are like, you know, what what can be
called like anti correlation coefficients. As for now, it's just hinges on three values, right? If
chi is one, we saw you have a perfect anti correlation. If it's minus one, you have a perfect
correlation, right? So it makes sense that the anti correlation coefficient is then minus one.
If chi is zero, you have no correlation at all. Now look at introduce now like a matrix, an anti
correlation matrix of just these chi values. And you can write that again, like in in terms of these
inner products of these unit vectors. Now, this is a grand matrix, right? And it's a well known
property of the of the grand matrix. It doesn't take too much to verify this. But in the interest
of time, I'll skip that. We know that the determinant of that of that matrix is going to be it's going
to have to be greater or equal than zero. And if you just calculate the determinant of this here,
you now get this condition. Okay. So quantum mechanics like imposes the condition that that,
you know, that this inequality has to be satisfied. So put differently, right? So quantum
mechanics, once you have the idea that these chi values are the cosine of the of the peeling angles,
so you can you can specify like the correlation array by just giving me three angles. But basic
geometry tells me that once I pick two of these three angles, it puts constraints on the third.
And this one, this is the constraint that it that it imposes. And if you now like plot this,
you see that what this picks out is an elliptope, or, you know, what has been called sort of a
fat tetrahedron, you puff it up a bit, the lines here are contained in it. But like, you know,
in the middle, like it's it's blown up a bit. And we call this like the elliptope inequality.
And this then is sort of the quantum analog of the of, you know, what the
the CHSH inequality in the case of the Merman setup, right? And remember, for the full
specification, we don't need just one, but we need four of those inequalities here,
we only need one nonlinear inequality. And this inequality is satisfied by Merman's example,
right? I mean, if you just look at it, you see that this if you put in a half,
you get like exactly that this is going to be equal to zero.
So this is actually a neat result, I think, because it gives a concrete example of like
a cartoon that you often see about how the convex set for, you know, non signaling quantum
and local hidden variable theories are related. Right. So so here is the here's a cross section
of our drawing, right, with the non signaling cube, the elliptope and the tetrahedron, right?
And now compare that to like the cartoon that is in Banana World, right, where you see like
the non signaling cube with like, you know, like the maximal variation, like a Perpeco-Rohlich box,
right, was a super quantum correlation that still is non signaling and doesn't violate special
relativity. Then you have the quantum convex set. And then in the middle, you have the local
polytope. And the beauty is, is that in this particular example of the of the Merman setup,
you you reproduce like now exactly, you know, what you just have as a cartoon in in general.
And you can play the same game for bananas now entangled bananas of higher spin. And so in our
book, we do this right. So here's what the correlation array looks like. Just one cell for a spin one
banana. The anti correlation coefficient, it turns out, you know, which is defined like this.
I'll get to that in a moment, like stays the same is still the cosine. If you go for two,
three halves still the same cosines. So all these correlations are all like constrained by the exact
same elliptope inequality. That's not the case if you now try to simulate them with these raffles.
So we saw that, you know, like if you do this for spin half, you get like the tetrahedron, right,
so you get something with like four facets like this. If you now go up to higher spin, you see
that you get a little more structure on these on these on these facets. So this is what it looks
like for spin one and notice that this point here is going to touch the the the elliptope
for for spin three halves, it's not going to touch the elliptope again. But for all integer spin,
it will, right, you see this gets more and more faceted, more and more
vertices. And like you can, it's very suggestive that if you go up to higher and higher spin,
it gets more and more close to the elliptope, but never quite gets there, right.
Now, the so so far it may seem that this elliptope somehow captures like something special about
quantum mechanics, in particular, like we used, you know, sort of as hidden like in what I showed
you, what we use like, you know, the Bourne rule, the Hilbert space formalism. But in fact, this
inequality is not new to quantum mechanics at all. It has been known to statisticians since the 1890s,
and it's basically a general constraint on the correlations between any three random variables,
right, which also like, you know, makes it understandable that even if you go to higher
spin particles in quantum mechanics, you'll never get out of the get out of the elliptope.
So this work is due to Carl Pearson, and mostly to Utney Yule. So Pearson, of course, these days
is mostly remembers for his dubious role in the eugenics movement, but he's also like, you know,
like a very important character in statistics. So let me run to this quickly, right. So now we're
talking about some arbitrary random variables with sets of possible outcomes that I'm going to
keep discreet. And in fact, I'm only interested in a case where you have you have a random variable
with only two outcomes, like, you know, yummy and nasty. And so I'm going to restrict my attention to
what we call balanced random variables. And that just means that if X i X of i is a possible value,
minus X i is two, and that the probability of X i and the probability of minus X i is the same.
And that simplifies matters, because that means that in that case, the expectation value is going
to be zero. And that simplifies like some other variables that some other quantities that we're
interested in. So we're looking at the variance, right? So the expectation value of X minus the
expected value of X squared. If the expected value of X is zero, then the variation of X is just the
expectation value of X squared. The standard deviation is the square root of that. And then
the covariance, again, like, you know, in general would be like the expectation value of X minus
the expectation value of X times Y minus the expectation value of Y, if these two expectation
values are zero, then that is just going to be equal to the expectation value of X times Y.
And I now introduce like what is called the Pearson correlation coefficient, which is just the
covariance of the Pearson correlation coefficients of X and Y is the covariance of X and Y divided
by the corresponding standard deviation, sigma X and sigma Y. And so if X and Y are balanced,
this is just the expectation value of X and Y divided by these standard deviations.
And you can immediately see two properties like, you know, the Pearson correlation coefficient
of a variable with itself is just one. And it doesn't matter if you look at a correlation coefficient
X, Y or Y, X. And we'll now I'll now prove for you that such such any triplet of such variables
is going to have to satisfy this elliptope inequality. And this was shown by Yule in the
late 1890s. So here's where here's one way to do it, like, you know, consider, you know, for any
triplet v1 v2 v3, like this quantity over here. So I'm looking at the expectation value of some
expression squared. So I know this is going to be greater or equal to zero. And now I'm going to
work this out. Okay, so I take like, you know, like this term times the rest that gives me this
here, right. And so notes that I now get like, you know, v1. And then I have like, x times x,
right, expectation value x squared divided by sigma x squared. And then we have the x times the y,
the x times z. And then you have similar terms for like, if you now do the v2 y over sigma y and v3
z over sigma c. And you see that in here, like you have like all these Pearson correlation
coefficients, it just looks like that. Right. And I can write this like a little more
concisely and compactly as justice matrix with these Pearson correlation coefficients
sandwiched between like, you know, the column vector v1 v2 v3, and the row vector v1 v2 v3.
And remember that this thing has to be greater or equal than zero for any, for any value of v1,
v2, v3, which means that that matrix row is positive semi definite, which means that the
determinant of row has to be greater or equal than zero. And it follows that, you know, that
that's just the elliptope inequality. Right. So there we have it again. Okay. So now,
look at the special case that x, y, and z are the taste of Alice's banana, right, in this
experiment in the, in the Merman setup, right. So x is the, the taste of Alice's banana when she
peels in the A direction, y is the taste of Alice's banana when she peels in the B direction and z
is the taste when Alice's banana when she peels in the C direction. All right. So now the obvious
problem is, is that as Papescu points out in the, in the preface or the forward of banana world,
a banana can only be eaten once, right, once it's peeled, it's peeled, once it's tasted, it's
tasted. But there's, we'll see there's ways around this, this, this problem. So first I note that
these variables are balanced, right. So we have to now give them some numerical value rather than
just yummy or nasty, but you know, inspired by spin, you know, like instead of having like a half
h bar, we now have like a half, like a B bar, you know, which I call the banana split, which is just
boops constant B divided by two pi. And we're going to pick units such that B bar is equal to one.
And so then, you know, these, we see that these, that these variables are perfectly balanced,
the expectation value is zero, the variance, right. So it's like, you know, half, half the time,
like, you know, it's the product is, it's, it's, it's one half squared, the other half is like,
you know, minus a half squared, and that adds up to one fourth, the standard deviation take the
square root that is like a half. Now the covariance here, it's a little trickier.
And what we're going to do. And like, you know, if you, if you're squeamish about this, like, we
did find a way to avoid like this counterfactual reasoning. But I think it's perfectly innocuous.
We're going to use my the opposite, if you want to find the covariance of the variables Alice,
Alice's taste of banana when peeling a and the taste of Alice's banana when peeling B.
So half Alice appeal a and then have her use minus what Bob finds when he peels B as a proxy
for what she would have find had she peeled B instead.
And so basically, like, you know, that so we use we calculate this thing here,
and we can use our correlation array to figure this out. Right. So we have like, if the if the
if the tastes are are the are the same, we get we get we get like one fourth. What is the probability
of that happening? Well, you need to add these two things. Right. So that's a half one minus
guy AB. And then, you know, like, if they're opposite, it's minus one fourth. And the probability
of that happening is this, if you work this out, you see that this is one fourth times guy AB.
And if you now like calculate the Pearson correlation coefficient, you see that that is
exactly equal to guy AB. Right. I already took an advance on that result calling this guy be like
an anti correlation coefficient, right. And the anti is because of this minus.
All right. So the elliptop inequality, you know, I can just now write for this for these particular
variables, right. So in terms of these rows, now, in terms of these guys.
And so this is just exactly the same. But there is a few problems, right. So the first problem
we already dealt with, like, how do we determine the taste of these two of a Alice feeling a and
Alice feeling B and one run? Well, you know, have or use Bob's result as a proxy for one of those.
Right. Now, the second problem is like, you know, we can only do this for two tastes for two
feelings in one run. Well, that's not a big problem either. Like, you can just have different ones.
Right. So if you think about it, that's what we always do, you know, like you like, if you think
about the early tests of the CHSH inequality, they weren't switching the settings like, you know,
from run to run, you just take measurements for one pair of standing and then fill in another
pair. That's all perfectly fine. So that we can do the third problem seems to be a lot nastier.
And there the promise is that, you know, that we we derive this elliptop inequality from the
condition starting that this the expectation value, this quantity is always greater equal than zero.
Right. But the point is that we cannot determine the value of this in one in one run. And it would
seem that if if all these three variables like can only take on values like plus or minus a half,
that yes, it's going to be greater equal than zero. But that inequality is not tight because like,
you know, like we could easily the smallest we could get this is to something like, you know,
a half, like, you know, like a state plus and minus, minus here, and then we have a quarter.
So this took us a while to to to figure out and the the the answer actually hinges on like,
you know, like an interesting property of quantum mechanics, namely that in quantum mechanics,
it's perfectly possible for a sum to have a definite value, even if the individual terms
in that sum do not. Right. So the simplest example I can think of is like, you know, the Hamiltonian
for harmonic oscillator, clearly P and Q cannot have like, you know, definite values at the same
time, but you know, the Hamiltonian can. And so to look at this a little more clearly, right,
so if you if you were looking essentially at sort of a sum of like her mission operators,
linear combination, and that in and of itself should be like a good operator. And so if you
introduce like, you know, now like in analogy with a spin vector, like a taste vector,
you get, you can write like the taste in the A direction as like the inner products of like
T with like the unit vector in the A direction, same for TB, same for TC. And then the inequality
becomes this, and you see that we're in a product thing, but the the taste vector with this vector,
and this will be zero whenever this combination is zero. Right. And so if you if there are if you
pick the right peeling directions for starters that need to be in one plane, you can actually
like achieve that. So this this inequality is tight. And this result applies to so the general
result of yield does applies to to this to this quantum example. All right. So what do I want
to conclude from this? Okay. So the point is, is that this elliptope inequality that we derived
first within quantum mechanics from the geometry of Hilbert space can also be derived without
quantum mechanics as a general constraint on correlations between three random variables.
And is this this distinction like actually we got from within from without from a song by Bob Dylan.
So the message then this is the big message of the of the talk is that what this suggests
is that the basic Hilbert space formalism of quantum mechanics is just a new framework for
handling probabilities. Right. And so this take on quantum mechanics, which has been dubbed
boobism is a pun on cubism by Robert Mischewitz belongs, I think, to a class of informational
makeovers of the much maligned Copenhagen interpretation. And so in order to to make that
clear, like I want to talk, I'll take five more minutes to make the point. And this is far more
speculative and tentative than what I've said so far. I think it's best to sort of think in terms
of like a genealogy of quantum interpretations. And so we got like two versions of quantum
mechanics around 1925 26. First, we have matrix mechanics. And Heisenberg's big discovery was
that these problems in spectroscopy that he was running into, just call for a new framework for
dealing with with physics, just as like the problems that people had run into in electrodynamics
around the turn of the century, called for a new framework of dealing with spatial temporal
relations. Now, of course, a little bit later, like Schrodinger comes up with wave mechanics,
and his big discovery compatible with Heisenberg was very different, like namely,
here the idea is that something wavy is underlying the behavior that we're seeing. And the analogy
here is with wave optics in the 19th century. And so they famously didn't care for each other,
for each other's views, like, you know, like Heisenberg calling wave mechanics disgusting,
and Schrodinger calling matrix mechanics repulsive. And but of course, like mathematical
equivalence was rapidly proved in part by Schrodinger himself, but then by the rock,
yard down for Neumann. And that kind of papers over like a very different way of thinking about
the state, the status of the state vector in the Hilbert space. And I think roughly you can say
that the descendants of wave mechanics, those are the ontic interpretations of quantum mechanics,
think Everett, the de Broglie-Bohm pilot wave theory, and the Girardi-Romini-Weber spontaneous
collapse theory. And the descendants of matrix mechanics are the epistemic interpretations
in where I would include Copenhagen, Cubism, and now like, you know, Bubism. And so just a quick way
of sort of showing, you know, what I'm, what I'm after, like contrast Boop with Everett, right?
So for Boop, like what the Hilbert space is doing you is doing for you, it's giving you the Born
Rule, but it doesn't represent stuff, right? In order to represent stuff, you need like some specific
quantum applications running on this new quantum operating system to use kind of the metaphor
of Nielsen and Chang's book on quantum information. Now, for Everett, it's just the way,
it's just the other way around. Hilbert space gives you stuff, you know,
Sean Carroll, like says, like, you know, the world is made out of wave functions, right?
So, but it doesn't give you the Born Rule now, right? I mean, so for that they appeal to decision
theory for agents and a multiverse, okay? Now, so this is Oxford Everettians, there's also another
class of Everettians, Berlin Everettians like Christoph Lainer, who really have the courage
of their convictions, who use like Hilbert space both to represent stuff and to get the Born Rule
and of course, it's a good Everettian, right? You take advantage of the fact that in a multiverse,
you really can have your cake and eat it too. So now, for more careful exegesis of all of this,
you, you know, I'm going to refer you to our book, where especially like, you know,
microfarro, like, lace this out, like much more patiently than I just did, and I'm going to leave
you like with one more version of this, of this Dylan song.
Now, right, I'm happy to take some questions if there's time.
Yes, we have some minutes for comments or questions. If you want to make a comment or question, please
indicate it in the chat. I have a short question. Do you think that, or my real question is,
if you have some experience in the classroom with this type of
topological approximation mechanics, do you think that it can help in education?
I'm just making sure. Do you think the question is, like, do you think that this
way of thinking about quantum mechanics can help education?
No, this form to present some results with the topological forms can help in education
of quantum mechanics in the in the courses in the universe.
Yeah, no, I mean, like, I'm currently teaching a course on introducing, like,
non physics majors to quantum mechanics, where I very much use this,
use this approach that I showed you, right? And so, and like,
yeah, and so, but it's, I mean, it gives you like a particular way of thinking about quantum
mechanics, right? It really pushes this idea that quantum mechanics is like a, you know,
the kinematics of quantum mechanics, right? The basic formalism is a new framework for handling
probabilities, right? And that, you know, in order to do anything else, right, now you need to do
dynamics, you need to like introduce like stuff, right? And what quantum mechanics is telling you
that it had to, that it has to behave according to the rules of quantum, right? So, so that's,
that's the view I'm pushing. Historically, what I find interesting is that if you now look at
modern books on probability theory and statistics, is that Hilbert space methods are being used in
these books. And somehow like, so as a historian, I'm very interested, like how it came to be,
that there seems to be very little communication between people in physics using Hilbert space
methods, and people in general statistics using like Hilbert space methods. Okay, thank you. And
there is a question from Federico Hoelig. Yes, thanks, Michelle, for, for this wonderful talk.
It's always great to hear you. I always get really excited. And I want to learn more about
this approach. And my question is related to what is the stake or the take of your interpretation
with regard to non-locality? Because if you interpret quantum mechanics as a new probability
formalism, what can you say about the strong claims that the word is local versus the word
is non-local? What will you say about that? Yeah, so, so the, that's a difficult question.
So, so what I would say is that, you know, in the spirit of what I showed you is that,
you know, like you would, you would have thought that special relativity like requires you to,
you know, like tell some story where you can like screen off like any correlation by something,
you know, that by a common cause. And it turns out that the constraints are not that tight,
you can have like, you can have like a very much more liberal constraint and still be
non-singling. In fact, you can go beyond quantum mechanics, and you can have like PR boxes. And
so to, I would say you just have to get used to the fact that you should resist the temptation
that when you have these like correlations that cannot be dealt with sort of the standard way
screening them off by conditionalizing on common causes, that you think of these as just
constrained produced by natures and not like, oh, Alice does one thing and then like, you know,
like it travels like instantaneously to Bob or vice versa. And if you, if you, if you go for this
if you go this epistemic route, that is easier, right? I mean, like, I think a lot of students
in quantum mechanics who, you know, like, no matter how, how often you tell them that astrodinger,
that astrodinger wave function is not a field on ordinary space, still have this picture like,
well, then you do a measurement and the whole thing goes poof, instantaneously. And like now
you're stretching your head like, you know, what is it that is traveling from like Alice to Bob
that then like frustratingly you can never use to send a signal, right? And so I'm hoping that
this approach will sort of prevent people like, you know, from going down that particular rabbit
hole in the first place. Okay, thanks. Thanks. It's clear. Yeah. I tend to agree. Yes.
