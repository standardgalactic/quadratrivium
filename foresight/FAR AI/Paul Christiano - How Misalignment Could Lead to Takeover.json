{"text": " So this talk is going to be a little bit on the crazier end, it's going to be completely non-technical. Yeah, but these are things I believe that I think are important for how much and how we should think about and worry about and work on alignment. So things I'm very happy to discuss and debate over the next day of the workshop and later today. I'm not sure, hopefully, a reasonable amount of time for questions as I go through it, but yeah, we have more opportunities to talk later on and feel free to object or just may punt things to talk about later. Yeah, so I'm going to be, we've talked so far about why models may end up being misaligned and why that may be hard to measure. I'm going to talk about how that actually ultimately leads to sort of total human disempowerment. I'm calling takeover here for short. The structure of the talk, I'm first going to talk a little bit about why I think AI systems will eventually be in a position to disempower humanity. That is, unless we deliberately change the way we deploy AI, then I'm going to talk about why misaligned AI systems might be motivated to disempower humanity, basically just slightly extending or repeating arguments from earlier in the day. And then I'm going to talk a little bit about why AI systems may ultimately sort of effectively coordinate to disempower humanity, that is why you may have simultaneous failures across many systems rather than a single system behaving badly. So start with why I think AI systems will likely be able to take over. I think a thing worth saying is that I'm going to talk about what I see as like the single most likely scenario resulting in catastrophe. This is not the only way you end up with even the scenario kind of catastrophe. So I'm going to talk about a system where AI systems are extremely broadly deployed in the world prior to anything bad happening. So I imagine that, for example, AI systems are designing and running warehouses and factories and data centers, they're operating and designing robots, they're writing the large majority of all code that is written, they handle complicated litigation, they would fight a war, they do most trades, they run most investment firms. When humans act in these domains, they do so with a lot of AI systems to understand what's going on and to provide strategic advice. So this world is pretty different from the world of today. I think we are starting to be able to see what such a world would look like. I think it's not clear how far away this kind of world is, right? If you're doubling once a year, it doesn't take you that long to go from billions of dollars to trillions of dollars of economic impact. But this is the sort of setting in which this entire story takes place. So one thing that can happen is you have a lot of AI systems operating is that the world can get pretty complicated for humans, hard for humans to understand, right? So one simple way this can happen is that you have AI systems with deep expertise in the domains where they're operating, right? They've seen huge amounts of data compared to what any human has seen about the specific domain they operate in. They think very quickly. They're very numerous. Another point is that right now, when a human deploys an AI system, they often have to understand it quite well. But that process of understanding a domain and applying AI is itself something that is likely to be subject to automation. Yeah. Great. I agree with this remark, that is, I think that you have a better chance of understanding an AI system if there are fewer of them and there's more human labor going into each deployment. But it is clearly, in fact, there's a general case for everything I said. I'm going to talk about a bunch of factors that can exacerbate risk, but I think you could cut out actually almost every single thing I say in this talk and you'd be left with some risk. And it's just that each of these makes the situation, from my perspective, a little bit worse. The other thing is, I think both, I think for you, the world are insurance and other reasons, but I don't really understand what this is. I know human understands that well what this is. Yeah. I'm not sure. I don't know. You could take something from a person like that, probably, or I probably wouldn't understand something about this. So I would say that in the world of today, most of us are very used to living in a world where most things would happen. I don't understand how they happen. I don't quite understand why they happen. I trust there was some kind of reason why they happen. But if you showed me an Amazon warehouse, and you're like, what's going on? I'd be like, I don't know. I guess it somehow delivers things. Something's going on. So the situation is already, I'm kind of trusting someone to make these decisions in a way that points at goals I like. I think that it's not inherently even a bad thing to be in this kind of world. Like, I think we're always going to be in a world where most people don't understand most things. I think that it is not inherently bad that no human understands things and only as understand something. I think it's mostly just important for understanding the context in which we're talking about concerns about AI takeover. I think that if you're imagining a world where there's like a world, there's a human world and one AI system that's like, how can I scheme and outmaneuver the humans? I think that is a possible thing that could happen as a source of risk. I think the most likely risk scenarios are more like a world that is increasingly, there are very few humans who understand many important domains. And so when we're talking about AI's taking over, I think it's, at least when I visualize this, it really changes my picture of how this is going to go when I think about that kind of world. Is it mentally, especially in the case of AI, that you need to keep in hand, that very, very smart, and you get to start into a drone, into a car manufacturing, et cetera, and right now they're doing those for us, but in the cycle, do you think you can get out of it? Yeah, that seems like a reasonable mental image. There's a little bit depends exactly what your associations are with a little green man. But yeah, there's a lot of, there's a lot of stuff happening in the world being done by AI's of all sorts of shapes and sizes. Some of them are doing things that we do understand well, right? There's a lot of things like, yep, this AI system, like just does a simple function, which we understand, and some of them are more complicated. On this slide, I've just thrown up an example of a random biological system. Biological systems are relevant because humans don't understand them that well. We just see that these things that were optimized in the world. I have a similar vibe, right? If you ask me, like how even things I understand kind of well, like how a data center is managed, from my perspective, it feels a little bit like a biological system. And like someone heard it and it's somehow going to recover. And like, I don't totally understand how that works, but I have some sense of like the telos, like that's the kind of relationship I often have to systems even maintained by humans and built by humans. I just expect to have more and more of that sense as the world becomes more complicated, right? The way humans relate to this world is increasingly like, you know, the way we raise the complex systems in general, and the only difference from the world today, I think that's already the case to a great extent. The difference is just there is no human who knows what's going on really. Or at least most people who are making most of those decisions, I know most details aren't humans. So one upshot of this that's important to me is that it pushes us increasingly to train AI systems based on outcomes of their decisions. I think the less you understand or the less humans have time to understand details of what's happening in the domain or the kinds of decisions an AI is making, the more important it is to say, let's just do what the AI said and see what happens, right? The more we are able, right, if you're trying to select an organism or something, you're not going to look at how the organism makes decisions, you're going to see how well does it do, how fit is it? That's like one implication of this. Another implication is that it becomes harder for humans to understand what's going on or intervene if things are going poorly. So an upshot of that is that AI is in practice, bad behavior by AI is mostly detected or corrected by other AI systems, right? So AI systems are mostly monitoring other AI's where you can imagine humans monitoring or automated monitoring, but at some point sophisticated AI systems are responsible for most monitoring. Even normal law enforcement or fighting a potential war would be done by AI systems, right? Because decisions are made quickly and because conflict is often deliberately made complex by a party to the conflict. AI systems are running a lot of critical infrastructure. Just if you want to achieve something in the world, AI plays an important part in that process. So none of this is necessarily bad, right? I think positive stories about AI will also have the step where good AI keeps bad AI in check. I think it just is something that like now requires trust on behalf of all of humanity, extended to all of these AI systems we've built. You might hope that we could trust the AI systems we've built because we built them, we have freedom to design them. But I think that depends on some decisions we make. And yeah, we'll discuss how it can get somewhat more ugly. But the point I'm going to make right now or in this first section of the talk is not that it would necessarily get ugly, just that if for some reason, all of the AI systems in the world were like, what we really want to do is disempower humanity, then I think it is quite likely that they would succeed. And I think this isn't even really the spicy take are getting my optimistic futures. This is also the case. And the point is that the core question is just to do you somehow end up in a situation where all of these AI systems, including the AI systems responsible for doing monitoring or doing law enforcement or running your data centers or running your infrastructure, where all of those AI systems, for some reason, want to disempower humans. No, I think the optimistic scenario still involves a point where AI systems acting collectively could take over. I think in the optimistic scenario. Yeah. In the optimistic scenario, you, uh, you wait until you are ready. You don't end up in the situation until in fact they would not try and take over. And you're confident of that either because you've determined that the empirics shake out such that this talk is just crazy talk, very plausible. Or this talk was justified and we've addressed the problems or whatever. This is our already on the case of our grid, for example, if the power grid goes down now, a large fraction of humanity is going to die. I think it's plausible. Well, a large fraction of humanity is maybe a small potatoes, but yeah, I think it's going to depend when I say if all AI's want to take over, the arguments I'm going to make are going to reply to like a particular class of AI systems. Right. So it's not going to be like all electronic devices failed. It's going to be some class of AI is produced in a certain way. Um, and I think that what happens over time is just, it becomes more and more plausible for like the top end of that distribution, right? Of the systems that are most sophisticated or like, right. Right now, if all systems trained with deep learning simultaneously failed and we're like, we hate the humans, we really want to disempower them, I think it would be fine. It's not totally obvious and it depends how smart they are about how they failed. Um, I think we'd probably be okay. But I mean, again, I think that the whole story we're telling this is kind of just like, I think you could take out and there's still be some risk. Yeah. If what failed? Yeah, I think that's, you can imagine cases where it's like, if all the cars failed, that's enough to kill everyone. This is not necessarily a striking claim. The striking claim is definitely the one that it is plausible that misaligned AI systems may want to take over. I guess this is in some sense the part we've been most talking about throughout the day. I'm going to dwell on this a bit and then I'm going to talk about why these failures may be correlated in a problematic way. That is why you might have all AI systems trying to take over at the same time. Um, this, I'm going to talk about two failure modes, both of which we've touched on earlier. So one is reward hacking. That is that disempowering humanity may be an effective strategy for AI systems collectively to get a lot of reward. And the second is deceptive alignment scenario that Rohan talked about. Okay. So I mentioned briefly before this idea that you may train AI systems by evaluating the outcomes of the actions they propose. Um, so just to briefly review what that actually entails, right? We have some policy, some big neural net. It proposes some actions and some of those actions to distinguish between them. We actually need to execute the action, measure the results and decide how much we like the results. Let's say the reward is to start judgment of how much we like the results. And then we adjust policies to maximize the expected reward of the actions they propose. Right. And there's a, it's plausible that if you do this, you get a policy which is implicitly or explicitly considering many possible actions and selecting the actions that will lead to the highest reward. There are other ways you could end up at that same outcome, right? We could do model based RL and explicitly have a loop in which we predict the consequences of different actions. You could have decision transformers, the condition on like high quality actions. It could just have some other planning process needed still into a model, whatever, all of these leads to like the same endpoint, which is sometimes because we don't know how to achieve goals. We're going to train AI systems to take actions that lead to high reward where reward means we measure the outcome and then we decide how much we like that result that we measured. This can potentially lead to takeover. If corrupting measurements in some situations is the best way to get a high reward, right? So you can imagine some spectrum of forms of reward hacking, right? A really simple one is you could try and flatter and deceive humans. Like that's a reasonable way to get high reward. Maybe on reflection, humans are like, that's not actually what we wanted. So if they were more careful, they would give it a lower reward. You can move to, right? If you're writing code and part of how a human evaluates the code you write is by performing simple tests, you could try and anticipate or understand those tests and write code, which breaks those tests or causes them to behave in an unintended way. Then when a human looks at the results of those tests, they're more likely to have a favorable judgment to your code. If they don't understand the mechanism for the problem. Or you can move out to creating elaborate false logs to hide errors, right? If I'm an AI system and part of how I'm evaluated is what happens when the code I write gets deployed. One thing I might want to do is say, okay, this code should change the way that logs get collected or should modify logs to make it. So in retrospect, a human thinks this outcome was better. And you can imagine as you go down the spectrum, these sort of corresponds to more extensive evaluations. One reason you might use these more extensive evaluations is to prevent problems or oversights from earlier stages. You can imagine compromising a server to hide errors. So not just changing log files, but if a human goes to try and figure out what happened, you might say, if I just replace the SSH server on this machine, it's going to be really hard for human to understand what's going on after the fact remotely, it's going to be unlikely. They'll notice that something bad has happened. You can get to these more extreme outcomes. So Jay mentioned this idea of like, if my system is being trained and what it wants is to get a high reward, ultimately, that reward is just about a bunch of measurements that could enter it into the training data set. One sec, I guess. And then you can just imagine the most extreme case of saying like, okay, if all the systems collectively disempowered humanity, then it does not matter if humans would like to go in later and change this. I think one dynamic that's worth pointing out, and then I'll get to Jacob, is like, if you have some of these smaller failures, right? If you imagine the system which behaves badly on bricks a server, a human is likely to say, okay, that was bad behavior. I'm going to go give it a low reward. And the results of that could either be to train a system to not do funny things or to train a system to, if you get up to funny business, ensure that a human never goes and flags that as low reward, right? Both of those seem like policies that will avoid that bad behavior. It's very unclear which one gradient to send gets you to. Yeah. Yeah, so I would say in some sense, like it depends a little bit on what the system wants or how you set up training. In some sense, a lot of these things are like errors, right? So I'd say that like, right, if you care about as a system, if what the AI cares about is just don't do things that will ultimately be assigned a low reward. And we would ultimately detect and assign low reward to many of these failures. Then all of them would be errors, except the one at the far right. And so I think a reasonable guess for what happens is you have systems which make some, some number of these errors along the left. At some point they're like, okay, I understand what's going on here. I understand humans are going to escalate and take more extensive measures to notice bad behavior. Bad behavior is not an effective strategy. And then you have this fork in the road, which a J referred to of like either you learn to just not do anything bad or he's like, okay, I understand. I understand the class of bad behavior, which is likely to be detected. And so I'm not going to engage in bad behavior that would be likely to be detected and it's just unclear to me which way you go. That's an important, I don't think you, like it's fairly likely you don't see a march along the spectrum because at some point those are mistakes. Like if you try and do something bad and it's a half measure. Well, so like, right, but it seems like a place where, like you say, no, it's kind of like to figure out what you do with the, you know, for example, hold on, instead, but I think you can ask, like, where does the school come from? I mean, it seems. Is that. You have arrested. Oh, You had that after, There's a function of that. There's course providing, and as asked, you can use this online course. There's a module there. And then, of course, something like that. You can get this to a ground point. But you get two minutes by. You want all of this to do on. And, excuse me, there's a no-go now. I'm trying to get this thing up. Get that to share with my students. I'm trying to get this thing down. I didn't care. I don't want both of them to put it on the slide. Okay. That's not what, that's not sort of the, how, like, years ago, we all got together. But no, this is not how we built the app. We're not going to build the app just online, but, you know, the board of people's software. We're going to sort of date this and that. If we add it once, it'll be fine. Whatever type of person it is. And that's the person's head. It's going to try to set the end. Right? And so, it's one thing where it's a work model. And that's a work model. And so, this thing is, it's not being provided. It's not going to work. And I'm not trying to change that. There is a serious option of that. As it's built, exactly. I'm not going to keep it plain, though. Like, as you go, like, you know, while you're on it. Okay. I get to see how I can make the end of the course. That's not a work model. I don't need to sort of figure this out. I'm just starting to map things. Well, maybe they want me to start mapping and think about the answers to these questions. But I don't have which one to report. So, and, you know, everything that's all in the system. So, I've been thinking very long with it. But the point is, how much does this go away to actually get to it that you're maintaining, you know, proper interest over quite a few months and you're taking care of the signal from the person that makes all the evidence about when to report what they actually care about. Well, I guess there's several things to respond to and then maybe a meta thought. I'll start with the meta thought, which is this seems like a great discussion. I'm very excited about it and happy to argue a bunch. I'm not going to be able to give a satisfying answer to these questions. And a lot of my high level take right now is I consider this, both of the issues I'm going to discuss here plausible. I think if they're real issues, we're probably going to get clear experimental evidence in advance. Right now, I'm just like, this seems like a thing that could happen. Yeah, it's, yeah, I'm not, no. Great. Yeah, so on the object level with respect to the, my key questions here and I'm very interested in strategies that don't like training strategies that don't run into this like potential failure mode. I think the key question becomes like one, what is the prior? How do you parameterize your beliefs about what the reward function is to what is like this kind of rule by which to take observations as evidence and then like three, how do you, maybe those are actually just the two key questions. Yeah. I think a general thing about this talk, maybe one thing is that the conclusions are going to be somewhat speculative where like, I think these are fairly plausible outcomes, but like, you know, tens of percent rather than like, very likely a second thing is there's a lot of stuff you might do, none of which I'm going to touch on. And the best I can say is like, I've spent a long time thinking about options and I would say there are no options that seem super great to me right now, but lots of plausible approaches that might end up addressing this issue. That's kind of where I'm at at a high level. Okay. I'd also like to talk more about it, but I think I'm going to move on because I, it's like six minutes is my understanding. I don't know where Richard is, but anyway, I'm just going to run through stuff. Second failure mode at 112 on is that like in general, like you may have a system which cares about the actual like numbers coming into this training set because you did select it on the basis of numbers in the training set. You could also end up with a system that cares about some other arbitrary thing that cares about a number and a reward register or cares about survival or cares about paper clips. Such systems might want to be deployed without being trained by changed by gradient descent might think that a low loss, getting a low loss during training will prevent them from being changed or this aspect of them from being changed and therefore get a low loss in training, but yet prefer to take over if doing so is possible. Yeah, my high level take is both of these seem plausible to me. They're connected. I think having these two makes things more plausible than if you have just one. I don't know how this shakes out. I think there's a lot of things we can do to try and change this basic dynamic. I want to spend five minutes talking about why these failures could be simultaneous. I think this has already been alluded to in the past, but it's an important part of the threat model. If you're in this world where a systems are very broadly deployed. Right. So if one a system behaves badly, I think that's not generally a problem in this world. There's a lot of other systems running around that would oppose it or that would flag the problem for humans or would allow humans to correct the problem. And the concern is that while takeover is impossible, all models behave well. For every model, it would be a losing strategy to try and like take over your cluster. If you know that a human's just going to come in and correct that problem. When takeover is possible, you may have it be the case that all models behave badly. That is, it is simultaneously for all of them, the case that takeover becomes available as a policy. So if you have this correlated, if all the systems you produce or all the smartest days you produce end up having the same problem, then you have a problem. If that's the case, if that's how it shakes out and if eventually a systems are in a position that they could by acting jointly takeover, then taking over as a reasonable strategy, if and only if all the other eyes are also going to try and take over. You have this kind of weird thing. The dynamics are not totally unlike the dynamics, like the normal human revolt or coup. So you have these two different equilibria and one, all the systems are like, great, the humans are doing their human thing. They're basically in control. I shouldn't try and rock the boat because some other AI will crush me. There's another equilibrium where the humans have no control. AI systems are not feeling deterred by other eyes because they know other AI systems will also participate. I think there's a few things that could potentially move you between these equilibria, right? So a very salient option is there's just exogenous shocks that decrease the amount of human control of a situation. If you imagine there's like a hot war going on, that's something that makes it harder for humans to detect and respond to problems, right? It gives more cover for something weird to happen. It makes it hard to intervene. You can have sort of, you can imagine at least a cascading loss of control where some systems think probably takeover will be successful. If they start doing weird stuff, the world becomes increasingly weird. It looks increasingly plausible that humans will lose control. As that happens, more and more systems are like, okay, it looks like this is going off the rails now. I am now going to participate and try and break down my little part of the world, grab my own reward channel. You can have models interacting with each other again, as you would in like a human revolt, just deliberately trying to say like, I think probably now is a time where takeover will be successful. They would like to share that information with the other models that all may join in. And more generally, like the easier it would be for air systems acting jointly to take over, the more unstable the situation becomes, right? So if it's very hard for air systems to take over, the situation might be kind of stable. This equilibrium might be sticky. In the world where air systems could very easily overpower humans, it's kind of an extremely unstable equilibrium, right? Because a smaller number of air systems defecting might quickly make it clear that the selling points come. Imagine that this has to happen in point five, like couldn't you see the case that say the AIP in North Korea, they talk to each other and say, well, the situation in this country is kind of bad. This is our chance and we see a takeover in some segment of the world of the population. Or you think it has to be the case that one day, everything is there in the next day, they're going over the White House. I think it depends a lot on how like the gold misgeneralization shakes out. So if you have AI systems that are just like, look, I would love to like wire head right now. I just love to for 30 seconds control this computer. Then you'll see like nice, great localized failures like AI does something really weird. I mean, the basic dynamic is if AI systems do that, I think if we just take that as a fact of life, then that can be a great source of evidence. The most concerning world is one where you then just try and train systems to say, hey, look, these systems just randomly messed up the server they were running on. We're going to train them as that's what you should not do. And if you do that, then you end up with systems which like given will learn that given the opportunity for like a little local bad behavior, they shouldn't do it. And maybe if you're lucky, once you can have North Korea get taken over by AI systems, and then you're like, oh, that was really bad. And hopefully you don't then include that as a training data point for other. If you include that as like the, here's an example of what you should not do. It's very tempting, right? AI systems is something really terrible. You'd be like, don't do that thing. But you do have this inadvertent, there's like this risk of overfitting to the problems you're able to correct where something really bad happens. And then you say, don't do that thing. And they learn, okay, if we're going to do something bad, it's got to be bigger. Got to think really, truly big. I think this is probably about the end. I'm probably just happy to, happy to just wrap up here. I have one more question. Yeah. I mean, I think that it is unlikely. I would be surprised personally if you like had something truly crazy, like a country gets taken over by AI systems. I think it's very likely that you see some kind of crazy behavior by AI systems. I think it won't be so like, again, the country case, you need zero imagination to draw the analogy between that and something terrible. I think in cases like you have a really crazy behavior where a system bricks your server for some reason, you need a little bit more imagination. But I think that's like, it's just a question of how close do you get or how crazy do things get before I systems learn not to try crazy half measures. Yeah. I think a lot depends on both what kind of evidence we're able to get from a lab and I think if this sort of phenomenon is real, I think there's a very good chance of getting like fairly compelling demonstrations in a lab that requires some imagination to bridge from examples in the lab to examples in the wild. And you'll have some kinds of failures in the wild. And it's a question of just how crazy or analogous to those have to be before they're moving. Like we already have some slightly weird stuff. I think that's pretty underwhelming. I think we're going to have like much better if this is real. This is a real kind of concern. We have much crazier stuff than we see today. But the concern, I think the worst case of those has to get pretty crazy or like requires a lot of will to stop doing things. And so we need pretty crazy demonstrations. I'm hoping that, you know, more mild evidence will be enough to get people not to go there. Yeah. I think the language model that's like, it looks like you're going to give me a bad rating. Do you really want to do that? I know where your family lives. I can kill them. I think like if that happened, people would not be like, we're done with this language model stuff. Like I think that's just not that far anymore from where we're at. I mean, this is maybe empirical prediction. I would love it if the first time a language model was like, I will murder your family. We're just like, we're done. No more language models. But I think that's not the track we're currently on. And I would love to get us on that track instead, but I'm not. Yeah. So just like, about this thing that climate change is happening in a place actually, we're not alone. We've had decades of mourning, but we've had a sense of community, time, and sense of survival.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 17.44, "text": " So this talk is going to be a little bit on the crazier end, it's going to be completely", "tokens": [50364, 407, 341, 751, 307, 516, 281, 312, 257, 707, 857, 322, 264, 2094, 33352, 917, 11, 309, 311, 516, 281, 312, 2584, 51236], "temperature": 0.0, "avg_logprob": -0.18511811169711026, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.17921562492847443}, {"id": 1, "seek": 0, "start": 17.44, "end": 18.44, "text": " non-technical.", "tokens": [51236, 2107, 12, 29113, 804, 13, 51286], "temperature": 0.0, "avg_logprob": -0.18511811169711026, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.17921562492847443}, {"id": 2, "seek": 0, "start": 18.44, "end": 23.54, "text": " Yeah, but these are things I believe that I think are important for how much and how", "tokens": [51286, 865, 11, 457, 613, 366, 721, 286, 1697, 300, 286, 519, 366, 1021, 337, 577, 709, 293, 577, 51541], "temperature": 0.0, "avg_logprob": -0.18511811169711026, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.17921562492847443}, {"id": 3, "seek": 0, "start": 23.54, "end": 26.68, "text": " we should think about and worry about and work on alignment.", "tokens": [51541, 321, 820, 519, 466, 293, 3292, 466, 293, 589, 322, 18515, 13, 51698], "temperature": 0.0, "avg_logprob": -0.18511811169711026, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.17921562492847443}, {"id": 4, "seek": 0, "start": 26.68, "end": 29.98, "text": " So things I'm very happy to discuss and debate over the next day of the workshop and later", "tokens": [51698, 407, 721, 286, 478, 588, 2055, 281, 2248, 293, 7958, 670, 264, 958, 786, 295, 264, 13541, 293, 1780, 51863], "temperature": 0.0, "avg_logprob": -0.18511811169711026, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.17921562492847443}, {"id": 5, "seek": 2998, "start": 29.98, "end": 30.98, "text": " today.", "tokens": [50364, 965, 13, 50414], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 6, "seek": 2998, "start": 30.98, "end": 34.62, "text": " I'm not sure, hopefully, a reasonable amount of time for questions as I go through it,", "tokens": [50414, 286, 478, 406, 988, 11, 4696, 11, 257, 10585, 2372, 295, 565, 337, 1651, 382, 286, 352, 807, 309, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 7, "seek": 2998, "start": 34.62, "end": 39.42, "text": " but yeah, we have more opportunities to talk later on and feel free to object or just", "tokens": [50596, 457, 1338, 11, 321, 362, 544, 4786, 281, 751, 1780, 322, 293, 841, 1737, 281, 2657, 420, 445, 50836], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 8, "seek": 2998, "start": 39.42, "end": 41.42, "text": " may punt things to talk about later.", "tokens": [50836, 815, 18212, 721, 281, 751, 466, 1780, 13, 50936], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 9, "seek": 2998, "start": 41.42, "end": 46.58, "text": " Yeah, so I'm going to be, we've talked so far about why models may end up being misaligned", "tokens": [50936, 865, 11, 370, 286, 478, 516, 281, 312, 11, 321, 600, 2825, 370, 1400, 466, 983, 5245, 815, 917, 493, 885, 3346, 304, 16690, 51194], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 10, "seek": 2998, "start": 46.58, "end": 48.14, "text": " and why that may be hard to measure.", "tokens": [51194, 293, 983, 300, 815, 312, 1152, 281, 3481, 13, 51272], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 11, "seek": 2998, "start": 48.14, "end": 52.42, "text": " I'm going to talk about how that actually ultimately leads to sort of total human disempowerment.", "tokens": [51272, 286, 478, 516, 281, 751, 466, 577, 300, 767, 6284, 6689, 281, 1333, 295, 3217, 1952, 717, 443, 9513, 518, 13, 51486], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 12, "seek": 2998, "start": 52.42, "end": 55.74, "text": " I'm calling takeover here for short.", "tokens": [51486, 286, 478, 5141, 747, 3570, 510, 337, 2099, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 13, "seek": 2998, "start": 55.74, "end": 59.019999999999996, "text": " The structure of the talk, I'm first going to talk a little bit about why I think AI systems", "tokens": [51652, 440, 3877, 295, 264, 751, 11, 286, 478, 700, 516, 281, 751, 257, 707, 857, 466, 983, 286, 519, 7318, 3652, 51816], "temperature": 0.0, "avg_logprob": -0.1955375922353644, "compression_ratio": 1.76, "no_speech_prob": 0.007336575537919998}, {"id": 14, "seek": 5902, "start": 59.02, "end": 61.940000000000005, "text": " will eventually be in a position to disempower humanity.", "tokens": [50364, 486, 4728, 312, 294, 257, 2535, 281, 717, 443, 9513, 10243, 13, 50510], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 15, "seek": 5902, "start": 61.940000000000005, "end": 66.5, "text": " That is, unless we deliberately change the way we deploy AI, then I'm going to talk about", "tokens": [50510, 663, 307, 11, 5969, 321, 23506, 1319, 264, 636, 321, 7274, 7318, 11, 550, 286, 478, 516, 281, 751, 466, 50738], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 16, "seek": 5902, "start": 66.5, "end": 70.42, "text": " why misaligned AI systems might be motivated to disempower humanity, basically just slightly", "tokens": [50738, 983, 3346, 304, 16690, 7318, 3652, 1062, 312, 14515, 281, 717, 443, 9513, 10243, 11, 1936, 445, 4748, 50934], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 17, "seek": 5902, "start": 70.42, "end": 73.38, "text": " extending or repeating arguments from earlier in the day.", "tokens": [50934, 24360, 420, 18617, 12869, 490, 3071, 294, 264, 786, 13, 51082], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 18, "seek": 5902, "start": 73.38, "end": 77.18, "text": " And then I'm going to talk a little bit about why AI systems may ultimately sort of effectively", "tokens": [51082, 400, 550, 286, 478, 516, 281, 751, 257, 707, 857, 466, 983, 7318, 3652, 815, 6284, 1333, 295, 8659, 51272], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 19, "seek": 5902, "start": 77.18, "end": 80.5, "text": " coordinate to disempower humanity, that is why you may have simultaneous failures across", "tokens": [51272, 15670, 281, 717, 443, 9513, 10243, 11, 300, 307, 983, 291, 815, 362, 46218, 20774, 2108, 51438], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 20, "seek": 5902, "start": 80.5, "end": 86.78, "text": " many systems rather than a single system behaving badly.", "tokens": [51438, 867, 3652, 2831, 813, 257, 2167, 1185, 35263, 13425, 13, 51752], "temperature": 0.0, "avg_logprob": -0.13991912337374096, "compression_ratio": 1.845890410958904, "no_speech_prob": 0.005727498792111874}, {"id": 21, "seek": 8678, "start": 86.78, "end": 89.42, "text": " So start with why I think AI systems will likely be able to take over.", "tokens": [50364, 407, 722, 365, 983, 286, 519, 7318, 3652, 486, 3700, 312, 1075, 281, 747, 670, 13, 50496], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 22, "seek": 8678, "start": 89.42, "end": 92.82000000000001, "text": " I think a thing worth saying is that I'm going to talk about what I see as like the single", "tokens": [50496, 286, 519, 257, 551, 3163, 1566, 307, 300, 286, 478, 516, 281, 751, 466, 437, 286, 536, 382, 411, 264, 2167, 50666], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 23, "seek": 8678, "start": 92.82000000000001, "end": 95.18, "text": " most likely scenario resulting in catastrophe.", "tokens": [50666, 881, 3700, 9005, 16505, 294, 36043, 13, 50784], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 24, "seek": 8678, "start": 95.18, "end": 98.94, "text": " This is not the only way you end up with even the scenario kind of catastrophe.", "tokens": [50784, 639, 307, 406, 264, 787, 636, 291, 917, 493, 365, 754, 264, 9005, 733, 295, 36043, 13, 50972], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 25, "seek": 8678, "start": 98.94, "end": 102.86, "text": " So I'm going to talk about a system where AI systems are extremely broadly deployed in", "tokens": [50972, 407, 286, 478, 516, 281, 751, 466, 257, 1185, 689, 7318, 3652, 366, 4664, 19511, 17826, 294, 51168], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 26, "seek": 8678, "start": 102.86, "end": 106.86, "text": " the world prior to anything bad happening.", "tokens": [51168, 264, 1002, 4059, 281, 1340, 1578, 2737, 13, 51368], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 27, "seek": 8678, "start": 106.86, "end": 111.9, "text": " So I imagine that, for example, AI systems are designing and running warehouses and factories", "tokens": [51368, 407, 286, 3811, 300, 11, 337, 1365, 11, 7318, 3652, 366, 14685, 293, 2614, 17464, 29578, 293, 24813, 51620], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 28, "seek": 8678, "start": 111.9, "end": 116.26, "text": " and data centers, they're operating and designing robots, they're writing the large majority", "tokens": [51620, 293, 1412, 10898, 11, 436, 434, 7447, 293, 14685, 14733, 11, 436, 434, 3579, 264, 2416, 6286, 51838], "temperature": 0.0, "avg_logprob": -0.14404649528668081, "compression_ratio": 1.896551724137931, "no_speech_prob": 0.10074375569820404}, {"id": 29, "seek": 11626, "start": 116.26, "end": 121.42, "text": " of all code that is written, they handle complicated litigation, they would fight a war, they do", "tokens": [50364, 295, 439, 3089, 300, 307, 3720, 11, 436, 4813, 6179, 33359, 11, 436, 576, 2092, 257, 1516, 11, 436, 360, 50622], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 30, "seek": 11626, "start": 121.42, "end": 124.22, "text": " most trades, they run most investment firms.", "tokens": [50622, 881, 21287, 11, 436, 1190, 881, 6078, 18055, 13, 50762], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 31, "seek": 11626, "start": 124.22, "end": 127.9, "text": " When humans act in these domains, they do so with a lot of AI systems to understand what's", "tokens": [50762, 1133, 6255, 605, 294, 613, 25514, 11, 436, 360, 370, 365, 257, 688, 295, 7318, 3652, 281, 1223, 437, 311, 50946], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 32, "seek": 11626, "start": 127.9, "end": 132.1, "text": " going on and to provide strategic advice.", "tokens": [50946, 516, 322, 293, 281, 2893, 10924, 5192, 13, 51156], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 33, "seek": 11626, "start": 132.1, "end": 134.18, "text": " So this world is pretty different from the world of today.", "tokens": [51156, 407, 341, 1002, 307, 1238, 819, 490, 264, 1002, 295, 965, 13, 51260], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 34, "seek": 11626, "start": 134.18, "end": 137.42000000000002, "text": " I think we are starting to be able to see what such a world would look like.", "tokens": [51260, 286, 519, 321, 366, 2891, 281, 312, 1075, 281, 536, 437, 1270, 257, 1002, 576, 574, 411, 13, 51422], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 35, "seek": 11626, "start": 137.42000000000002, "end": 140.38, "text": " I think it's not clear how far away this kind of world is, right?", "tokens": [51422, 286, 519, 309, 311, 406, 1850, 577, 1400, 1314, 341, 733, 295, 1002, 307, 11, 558, 30, 51570], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 36, "seek": 11626, "start": 140.38, "end": 143.38, "text": " If you're doubling once a year, it doesn't take you that long to go from billions of", "tokens": [51570, 759, 291, 434, 33651, 1564, 257, 1064, 11, 309, 1177, 380, 747, 291, 300, 938, 281, 352, 490, 17375, 295, 51720], "temperature": 0.0, "avg_logprob": -0.10455314878007056, "compression_ratio": 1.7261538461538461, "no_speech_prob": 0.03205008804798126}, {"id": 37, "seek": 14338, "start": 143.38, "end": 148.74, "text": " dollars to trillions of dollars of economic impact.", "tokens": [50364, 3808, 281, 504, 46279, 295, 3808, 295, 4836, 2712, 13, 50632], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 38, "seek": 14338, "start": 148.74, "end": 154.78, "text": " But this is the sort of setting in which this entire story takes place.", "tokens": [50632, 583, 341, 307, 264, 1333, 295, 3287, 294, 597, 341, 2302, 1657, 2516, 1081, 13, 50934], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 39, "seek": 14338, "start": 154.78, "end": 157.9, "text": " So one thing that can happen is you have a lot of AI systems operating is that the world", "tokens": [50934, 407, 472, 551, 300, 393, 1051, 307, 291, 362, 257, 688, 295, 7318, 3652, 7447, 307, 300, 264, 1002, 51090], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 40, "seek": 14338, "start": 157.9, "end": 161.26, "text": " can get pretty complicated for humans, hard for humans to understand, right?", "tokens": [51090, 393, 483, 1238, 6179, 337, 6255, 11, 1152, 337, 6255, 281, 1223, 11, 558, 30, 51258], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 41, "seek": 14338, "start": 161.26, "end": 164.85999999999999, "text": " So one simple way this can happen is that you have AI systems with deep expertise in", "tokens": [51258, 407, 472, 2199, 636, 341, 393, 1051, 307, 300, 291, 362, 7318, 3652, 365, 2452, 11769, 294, 51438], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 42, "seek": 14338, "start": 164.85999999999999, "end": 166.38, "text": " the domains where they're operating, right?", "tokens": [51438, 264, 25514, 689, 436, 434, 7447, 11, 558, 30, 51514], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 43, "seek": 14338, "start": 166.38, "end": 170.38, "text": " They've seen huge amounts of data compared to what any human has seen about the specific", "tokens": [51514, 814, 600, 1612, 2603, 11663, 295, 1412, 5347, 281, 437, 604, 1952, 575, 1612, 466, 264, 2685, 51714], "temperature": 0.0, "avg_logprob": -0.135739229493222, "compression_ratio": 1.7665505226480835, "no_speech_prob": 0.001866776729002595}, {"id": 44, "seek": 17038, "start": 170.38, "end": 171.38, "text": " domain they operate in.", "tokens": [50364, 9274, 436, 9651, 294, 13, 50414], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 45, "seek": 17038, "start": 171.38, "end": 172.78, "text": " They think very quickly.", "tokens": [50414, 814, 519, 588, 2661, 13, 50484], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 46, "seek": 17038, "start": 172.78, "end": 173.78, "text": " They're very numerous.", "tokens": [50484, 814, 434, 588, 12546, 13, 50534], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 47, "seek": 17038, "start": 173.78, "end": 179.22, "text": " Another point is that right now, when a human deploys an AI system, they often have to understand", "tokens": [50534, 3996, 935, 307, 300, 558, 586, 11, 562, 257, 1952, 368, 49522, 364, 7318, 1185, 11, 436, 2049, 362, 281, 1223, 50806], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 48, "seek": 17038, "start": 179.22, "end": 180.22, "text": " it quite well.", "tokens": [50806, 309, 1596, 731, 13, 50856], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 49, "seek": 17038, "start": 180.22, "end": 183.5, "text": " But that process of understanding a domain and applying AI is itself something that is", "tokens": [50856, 583, 300, 1399, 295, 3701, 257, 9274, 293, 9275, 7318, 307, 2564, 746, 300, 307, 51020], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 50, "seek": 17038, "start": 183.5, "end": 185.1, "text": " likely to be subject to automation.", "tokens": [51020, 3700, 281, 312, 3983, 281, 17769, 13, 51100], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 51, "seek": 17038, "start": 185.1, "end": 186.1, "text": " Yeah.", "tokens": [51100, 865, 13, 51150], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 52, "seek": 17038, "start": 186.1, "end": 187.1, "text": " Great.", "tokens": [51150, 3769, 13, 51200], "temperature": 0.0, "avg_logprob": -0.2026470095612282, "compression_ratio": 1.5165876777251184, "no_speech_prob": 0.07567405700683594}, {"id": 53, "seek": 18710, "start": 187.1, "end": 204.54, "text": " I agree with this remark, that is, I think that you have a better chance of understanding", "tokens": [50364, 286, 3986, 365, 341, 7942, 11, 300, 307, 11, 286, 519, 300, 291, 362, 257, 1101, 2931, 295, 3701, 51236], "temperature": 0.0, "avg_logprob": -0.21384046712052932, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0031719249673187733}, {"id": 54, "seek": 18710, "start": 204.54, "end": 207.42, "text": " an AI system if there are fewer of them and there's more human labor going into each", "tokens": [51236, 364, 7318, 1185, 498, 456, 366, 13366, 295, 552, 293, 456, 311, 544, 1952, 5938, 516, 666, 1184, 51380], "temperature": 0.0, "avg_logprob": -0.21384046712052932, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0031719249673187733}, {"id": 55, "seek": 18710, "start": 207.42, "end": 208.42, "text": " deployment.", "tokens": [51380, 19317, 13, 51430], "temperature": 0.0, "avg_logprob": -0.21384046712052932, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0031719249673187733}, {"id": 56, "seek": 18710, "start": 208.42, "end": 210.54, "text": " But it is clearly, in fact, there's a general case for everything I said.", "tokens": [51430, 583, 309, 307, 4448, 11, 294, 1186, 11, 456, 311, 257, 2674, 1389, 337, 1203, 286, 848, 13, 51536], "temperature": 0.0, "avg_logprob": -0.21384046712052932, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0031719249673187733}, {"id": 57, "seek": 18710, "start": 210.54, "end": 213.74, "text": " I'm going to talk about a bunch of factors that can exacerbate risk, but I think you", "tokens": [51536, 286, 478, 516, 281, 751, 466, 257, 3840, 295, 6771, 300, 393, 38819, 473, 3148, 11, 457, 286, 519, 291, 51696], "temperature": 0.0, "avg_logprob": -0.21384046712052932, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0031719249673187733}, {"id": 58, "seek": 18710, "start": 213.74, "end": 216.74, "text": " could cut out actually almost every single thing I say in this talk and you'd be left", "tokens": [51696, 727, 1723, 484, 767, 1920, 633, 2167, 551, 286, 584, 294, 341, 751, 293, 291, 1116, 312, 1411, 51846], "temperature": 0.0, "avg_logprob": -0.21384046712052932, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0031719249673187733}, {"id": 59, "seek": 21674, "start": 216.78, "end": 217.78, "text": " with some risk.", "tokens": [50366, 365, 512, 3148, 13, 50416], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 60, "seek": 21674, "start": 217.78, "end": 220.22, "text": " And it's just that each of these makes the situation, from my perspective, a little bit", "tokens": [50416, 400, 309, 311, 445, 300, 1184, 295, 613, 1669, 264, 2590, 11, 490, 452, 4585, 11, 257, 707, 857, 50538], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 61, "seek": 21674, "start": 220.22, "end": 221.22, "text": " worse.", "tokens": [50538, 5324, 13, 50588], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 62, "seek": 21674, "start": 221.22, "end": 226.74, "text": " The other thing is, I think both, I think for you, the world are insurance and other", "tokens": [50588, 440, 661, 551, 307, 11, 286, 519, 1293, 11, 286, 519, 337, 291, 11, 264, 1002, 366, 7214, 293, 661, 50864], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 63, "seek": 21674, "start": 226.74, "end": 230.54000000000002, "text": " reasons, but I don't really understand what this is.", "tokens": [50864, 4112, 11, 457, 286, 500, 380, 534, 1223, 437, 341, 307, 13, 51054], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 64, "seek": 21674, "start": 230.54000000000002, "end": 232.54000000000002, "text": " I know human understands that well what this is.", "tokens": [51054, 286, 458, 1952, 15146, 300, 731, 437, 341, 307, 13, 51154], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 65, "seek": 21674, "start": 232.54000000000002, "end": 233.54000000000002, "text": " Yeah.", "tokens": [51154, 865, 13, 51204], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 66, "seek": 21674, "start": 233.54000000000002, "end": 234.54000000000002, "text": " I'm not sure.", "tokens": [51204, 286, 478, 406, 988, 13, 51254], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 67, "seek": 21674, "start": 234.54000000000002, "end": 235.54000000000002, "text": " I don't know.", "tokens": [51254, 286, 500, 380, 458, 13, 51304], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 68, "seek": 21674, "start": 235.54000000000002, "end": 236.54000000000002, "text": " You could take something from a person like that, probably, or I probably wouldn't understand", "tokens": [51304, 509, 727, 747, 746, 490, 257, 954, 411, 300, 11, 1391, 11, 420, 286, 1391, 2759, 380, 1223, 51354], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 69, "seek": 21674, "start": 236.54000000000002, "end": 237.54000000000002, "text": " something about this.", "tokens": [51354, 746, 466, 341, 13, 51404], "temperature": 0.0, "avg_logprob": -0.49847256469726564, "compression_ratio": 1.766798418972332, "no_speech_prob": 0.2502342760562897}, {"id": 70, "seek": 23754, "start": 237.54, "end": 251.73999999999998, "text": " So I would say that in the world of today, most of us are very used to living in a world", "tokens": [50364, 407, 286, 576, 584, 300, 294, 264, 1002, 295, 965, 11, 881, 295, 505, 366, 588, 1143, 281, 2647, 294, 257, 1002, 51074], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 71, "seek": 23754, "start": 251.73999999999998, "end": 252.73999999999998, "text": " where most things would happen.", "tokens": [51074, 689, 881, 721, 576, 1051, 13, 51124], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 72, "seek": 23754, "start": 252.73999999999998, "end": 254.1, "text": " I don't understand how they happen.", "tokens": [51124, 286, 500, 380, 1223, 577, 436, 1051, 13, 51192], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 73, "seek": 23754, "start": 254.1, "end": 255.5, "text": " I don't quite understand why they happen.", "tokens": [51192, 286, 500, 380, 1596, 1223, 983, 436, 1051, 13, 51262], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 74, "seek": 23754, "start": 255.5, "end": 257.34, "text": " I trust there was some kind of reason why they happen.", "tokens": [51262, 286, 3361, 456, 390, 512, 733, 295, 1778, 983, 436, 1051, 13, 51354], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 75, "seek": 23754, "start": 257.34, "end": 259.98, "text": " But if you showed me an Amazon warehouse, and you're like, what's going on?", "tokens": [51354, 583, 498, 291, 4712, 385, 364, 6795, 22244, 11, 293, 291, 434, 411, 11, 437, 311, 516, 322, 30, 51486], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 76, "seek": 23754, "start": 259.98, "end": 260.98, "text": " I'd be like, I don't know.", "tokens": [51486, 286, 1116, 312, 411, 11, 286, 500, 380, 458, 13, 51536], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 77, "seek": 23754, "start": 260.98, "end": 262.3, "text": " I guess it somehow delivers things.", "tokens": [51536, 286, 2041, 309, 6063, 24860, 721, 13, 51602], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 78, "seek": 23754, "start": 262.3, "end": 263.3, "text": " Something's going on.", "tokens": [51602, 6595, 311, 516, 322, 13, 51652], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 79, "seek": 23754, "start": 263.3, "end": 267.42, "text": " So the situation is already, I'm kind of trusting someone to make these decisions in", "tokens": [51652, 407, 264, 2590, 307, 1217, 11, 286, 478, 733, 295, 28235, 1580, 281, 652, 613, 5327, 294, 51858], "temperature": 0.0, "avg_logprob": -0.21471087601933167, "compression_ratio": 1.848148148148148, "no_speech_prob": 0.004465816542506218}, {"id": 80, "seek": 26742, "start": 267.42, "end": 269.06, "text": " a way that points at goals I like.", "tokens": [50364, 257, 636, 300, 2793, 412, 5493, 286, 411, 13, 50446], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 81, "seek": 26742, "start": 269.06, "end": 271.94, "text": " I think that it's not inherently even a bad thing to be in this kind of world.", "tokens": [50446, 286, 519, 300, 309, 311, 406, 27993, 754, 257, 1578, 551, 281, 312, 294, 341, 733, 295, 1002, 13, 50590], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 82, "seek": 26742, "start": 271.94, "end": 274.46000000000004, "text": " Like, I think we're always going to be in a world where most people don't understand", "tokens": [50590, 1743, 11, 286, 519, 321, 434, 1009, 516, 281, 312, 294, 257, 1002, 689, 881, 561, 500, 380, 1223, 50716], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 83, "seek": 26742, "start": 274.46000000000004, "end": 277.06, "text": " most things.", "tokens": [50716, 881, 721, 13, 50846], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 84, "seek": 26742, "start": 277.06, "end": 281.62, "text": " I think that it is not inherently bad that no human understands things and only as understand", "tokens": [50846, 286, 519, 300, 309, 307, 406, 27993, 1578, 300, 572, 1952, 15146, 721, 293, 787, 382, 1223, 51074], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 85, "seek": 26742, "start": 281.62, "end": 282.62, "text": " something.", "tokens": [51074, 746, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 86, "seek": 26742, "start": 282.62, "end": 285.62, "text": " I think it's mostly just important for understanding the context in which we're talking about concerns", "tokens": [51124, 286, 519, 309, 311, 5240, 445, 1021, 337, 3701, 264, 4319, 294, 597, 321, 434, 1417, 466, 7389, 51274], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 87, "seek": 26742, "start": 285.62, "end": 286.62, "text": " about AI takeover.", "tokens": [51274, 466, 7318, 747, 3570, 13, 51324], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 88, "seek": 26742, "start": 286.62, "end": 289.38, "text": " I think that if you're imagining a world where there's like a world, there's a human", "tokens": [51324, 286, 519, 300, 498, 291, 434, 27798, 257, 1002, 689, 456, 311, 411, 257, 1002, 11, 456, 311, 257, 1952, 51462], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 89, "seek": 26742, "start": 289.38, "end": 293.02000000000004, "text": " world and one AI system that's like, how can I scheme and outmaneuver the humans?", "tokens": [51462, 1002, 293, 472, 7318, 1185, 300, 311, 411, 11, 577, 393, 286, 12232, 293, 484, 1601, 23685, 331, 264, 6255, 30, 51644], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 90, "seek": 26742, "start": 293.02000000000004, "end": 296.1, "text": " I think that is a possible thing that could happen as a source of risk.", "tokens": [51644, 286, 519, 300, 307, 257, 1944, 551, 300, 727, 1051, 382, 257, 4009, 295, 3148, 13, 51798], "temperature": 0.0, "avg_logprob": -0.1488394985309226, "compression_ratio": 2.076687116564417, "no_speech_prob": 0.04197610914707184}, {"id": 91, "seek": 29610, "start": 296.1, "end": 299.42, "text": " I think the most likely risk scenarios are more like a world that is increasingly, there", "tokens": [50364, 286, 519, 264, 881, 3700, 3148, 15077, 366, 544, 411, 257, 1002, 300, 307, 12980, 11, 456, 50530], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 92, "seek": 29610, "start": 299.42, "end": 302.26000000000005, "text": " are very few humans who understand many important domains.", "tokens": [50530, 366, 588, 1326, 6255, 567, 1223, 867, 1021, 25514, 13, 50672], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 93, "seek": 29610, "start": 302.26000000000005, "end": 305.3, "text": " And so when we're talking about AI's taking over, I think it's, at least when I visualize", "tokens": [50672, 400, 370, 562, 321, 434, 1417, 466, 7318, 311, 1940, 670, 11, 286, 519, 309, 311, 11, 412, 1935, 562, 286, 23273, 50824], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 94, "seek": 29610, "start": 305.3, "end": 309.58000000000004, "text": " this, it really changes my picture of how this is going to go when I think about that", "tokens": [50824, 341, 11, 309, 534, 2962, 452, 3036, 295, 577, 341, 307, 516, 281, 352, 562, 286, 519, 466, 300, 51038], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 95, "seek": 29610, "start": 309.58000000000004, "end": 310.58000000000004, "text": " kind of world.", "tokens": [51038, 733, 295, 1002, 13, 51088], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 96, "seek": 29610, "start": 310.58000000000004, "end": 315.66, "text": " Is it mentally, especially in the case of AI, that you need to keep in hand, that very,", "tokens": [51088, 1119, 309, 17072, 11, 2318, 294, 264, 1389, 295, 7318, 11, 300, 291, 643, 281, 1066, 294, 1011, 11, 300, 588, 11, 51342], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 97, "seek": 29610, "start": 315.66, "end": 320.18, "text": " very smart, and you get to start into a drone, into a car manufacturing, et cetera, and right", "tokens": [51342, 588, 4069, 11, 293, 291, 483, 281, 722, 666, 257, 13852, 11, 666, 257, 1032, 11096, 11, 1030, 11458, 11, 293, 558, 51568], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 98, "seek": 29610, "start": 320.18, "end": 324.82000000000005, "text": " now they're doing those for us, but in the cycle, do you think you can get out of it?", "tokens": [51568, 586, 436, 434, 884, 729, 337, 505, 11, 457, 294, 264, 6586, 11, 360, 291, 519, 291, 393, 483, 484, 295, 309, 30, 51800], "temperature": 0.0, "avg_logprob": -0.4618962281828473, "compression_ratio": 1.7719298245614035, "no_speech_prob": 0.0067810178734362125}, {"id": 99, "seek": 32482, "start": 324.86, "end": 326.5, "text": " Yeah, that seems like a reasonable mental image.", "tokens": [50366, 865, 11, 300, 2544, 411, 257, 10585, 4973, 3256, 13, 50448], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 100, "seek": 32482, "start": 326.5, "end": 329.42, "text": " There's a little bit depends exactly what your associations are with a little green man.", "tokens": [50448, 821, 311, 257, 707, 857, 5946, 2293, 437, 428, 26597, 366, 365, 257, 707, 3092, 587, 13, 50594], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 101, "seek": 32482, "start": 330.09999999999997, "end": 333.18, "text": " But yeah, there's a lot of, there's a lot of stuff happening in the world being done", "tokens": [50628, 583, 1338, 11, 456, 311, 257, 688, 295, 11, 456, 311, 257, 688, 295, 1507, 2737, 294, 264, 1002, 885, 1096, 50782], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 102, "seek": 32482, "start": 333.18, "end": 335.14, "text": " by AI's of all sorts of shapes and sizes.", "tokens": [50782, 538, 7318, 311, 295, 439, 7527, 295, 10854, 293, 11602, 13, 50880], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 103, "seek": 32482, "start": 336.34, "end": 338.38, "text": " Some of them are doing things that we do understand well, right?", "tokens": [50940, 2188, 295, 552, 366, 884, 721, 300, 321, 360, 1223, 731, 11, 558, 30, 51042], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 104, "seek": 32482, "start": 338.38, "end": 341.02, "text": " There's a lot of things like, yep, this AI system, like just does a simple function,", "tokens": [51042, 821, 311, 257, 688, 295, 721, 411, 11, 18633, 11, 341, 7318, 1185, 11, 411, 445, 775, 257, 2199, 2445, 11, 51174], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 105, "seek": 32482, "start": 341.02, "end": 342.74, "text": " which we understand, and some of them are more complicated.", "tokens": [51174, 597, 321, 1223, 11, 293, 512, 295, 552, 366, 544, 6179, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 106, "seek": 32482, "start": 343.5, "end": 346.65999999999997, "text": " On this slide, I've just thrown up an example of a random biological system.", "tokens": [51298, 1282, 341, 4137, 11, 286, 600, 445, 11732, 493, 364, 1365, 295, 257, 4974, 13910, 1185, 13, 51456], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 107, "seek": 32482, "start": 346.65999999999997, "end": 349.86, "text": " Biological systems are relevant because humans don't understand them that well.", "tokens": [51456, 13007, 4383, 3652, 366, 7340, 570, 6255, 500, 380, 1223, 552, 300, 731, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 108, "seek": 32482, "start": 349.86, "end": 352.21999999999997, "text": " We just see that these things that were optimized in the world.", "tokens": [51616, 492, 445, 536, 300, 613, 721, 300, 645, 26941, 294, 264, 1002, 13, 51734], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 109, "seek": 32482, "start": 352.9, "end": 353.94, "text": " I have a similar vibe, right?", "tokens": [51768, 286, 362, 257, 2531, 14606, 11, 558, 30, 51820], "temperature": 0.0, "avg_logprob": -0.1672441671182821, "compression_ratio": 1.8979057591623036, "no_speech_prob": 0.051791347563266754}, {"id": 110, "seek": 35394, "start": 353.94, "end": 356.66, "text": " If you ask me, like how even things I understand kind of well,", "tokens": [50364, 759, 291, 1029, 385, 11, 411, 577, 754, 721, 286, 1223, 733, 295, 731, 11, 50500], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 111, "seek": 35394, "start": 356.66, "end": 359.7, "text": " like how a data center is managed, from my perspective, it feels a little bit like", "tokens": [50500, 411, 577, 257, 1412, 3056, 307, 6453, 11, 490, 452, 4585, 11, 309, 3417, 257, 707, 857, 411, 50652], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 112, "seek": 35394, "start": 359.7, "end": 360.66, "text": " a biological system.", "tokens": [50652, 257, 13910, 1185, 13, 50700], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 113, "seek": 35394, "start": 360.66, "end": 362.86, "text": " And like someone heard it and it's somehow going to recover.", "tokens": [50700, 400, 411, 1580, 2198, 309, 293, 309, 311, 6063, 516, 281, 8114, 13, 50810], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 114, "seek": 35394, "start": 363.21999999999997, "end": 366.3, "text": " And like, I don't totally understand how that works, but I have some sense of", "tokens": [50828, 400, 411, 11, 286, 500, 380, 3879, 1223, 577, 300, 1985, 11, 457, 286, 362, 512, 2020, 295, 50982], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 115, "seek": 35394, "start": 366.3, "end": 369.58, "text": " like the telos, like that's the kind of relationship I often have to systems even", "tokens": [50982, 411, 264, 15284, 329, 11, 411, 300, 311, 264, 733, 295, 2480, 286, 2049, 362, 281, 3652, 754, 51146], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 116, "seek": 35394, "start": 369.58, "end": 371.02, "text": " maintained by humans and built by humans.", "tokens": [51146, 17578, 538, 6255, 293, 3094, 538, 6255, 13, 51218], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 117, "seek": 35394, "start": 371.02, "end": 373.58, "text": " I just expect to have more and more of that sense as the world becomes more", "tokens": [51218, 286, 445, 2066, 281, 362, 544, 293, 544, 295, 300, 2020, 382, 264, 1002, 3643, 544, 51346], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 118, "seek": 35394, "start": 373.58, "end": 374.54, "text": " complicated, right?", "tokens": [51346, 6179, 11, 558, 30, 51394], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 119, "seek": 35394, "start": 374.54, "end": 377.18, "text": " The way humans relate to this world is increasingly like, you know, the way", "tokens": [51394, 440, 636, 6255, 10961, 281, 341, 1002, 307, 12980, 411, 11, 291, 458, 11, 264, 636, 51526], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 120, "seek": 35394, "start": 377.18, "end": 380.22, "text": " we raise the complex systems in general, and the only difference from the world", "tokens": [51526, 321, 5300, 264, 3997, 3652, 294, 2674, 11, 293, 264, 787, 2649, 490, 264, 1002, 51678], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 121, "seek": 35394, "start": 380.22, "end": 382.02, "text": " today, I think that's already the case to a great extent.", "tokens": [51678, 965, 11, 286, 519, 300, 311, 1217, 264, 1389, 281, 257, 869, 8396, 13, 51768], "temperature": 0.0, "avg_logprob": -0.15493728019095757, "compression_ratio": 1.8756345177664975, "no_speech_prob": 0.0005355395842343569}, {"id": 122, "seek": 38202, "start": 382.29999999999995, "end": 384.9, "text": " The difference is just there is no human who knows what's going on really.", "tokens": [50378, 440, 2649, 307, 445, 456, 307, 572, 1952, 567, 3255, 437, 311, 516, 322, 534, 13, 50508], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 123, "seek": 38202, "start": 386.5, "end": 389.14, "text": " Or at least most people who are making most of those decisions, I know most", "tokens": [50588, 1610, 412, 1935, 881, 561, 567, 366, 1455, 881, 295, 729, 5327, 11, 286, 458, 881, 50720], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 124, "seek": 38202, "start": 389.14, "end": 390.06, "text": " details aren't humans.", "tokens": [50720, 4365, 3212, 380, 6255, 13, 50766], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 125, "seek": 38202, "start": 392.14, "end": 397.06, "text": " So one upshot of this that's important to me is that it pushes us increasingly to", "tokens": [50870, 407, 472, 493, 18402, 295, 341, 300, 311, 1021, 281, 385, 307, 300, 309, 21020, 505, 12980, 281, 51116], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 126, "seek": 38202, "start": 397.06, "end": 399.65999999999997, "text": " train AI systems based on outcomes of their decisions.", "tokens": [51116, 3847, 7318, 3652, 2361, 322, 10070, 295, 641, 5327, 13, 51246], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 127, "seek": 38202, "start": 399.78, "end": 402.34, "text": " I think the less you understand or the less humans have time to understand", "tokens": [51252, 286, 519, 264, 1570, 291, 1223, 420, 264, 1570, 6255, 362, 565, 281, 1223, 51380], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 128, "seek": 38202, "start": 402.34, "end": 405.09999999999997, "text": " details of what's happening in the domain or the kinds of decisions an AI is", "tokens": [51380, 4365, 295, 437, 311, 2737, 294, 264, 9274, 420, 264, 3685, 295, 5327, 364, 7318, 307, 51518], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 129, "seek": 38202, "start": 405.09999999999997, "end": 408.97999999999996, "text": " making, the more important it is to say, let's just do what the AI said and see", "tokens": [51518, 1455, 11, 264, 544, 1021, 309, 307, 281, 584, 11, 718, 311, 445, 360, 437, 264, 7318, 848, 293, 536, 51712], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 130, "seek": 38202, "start": 408.97999999999996, "end": 410.09999999999997, "text": " what happens, right?", "tokens": [51712, 437, 2314, 11, 558, 30, 51768], "temperature": 0.0, "avg_logprob": -0.14477597645350865, "compression_ratio": 1.8161290322580645, "no_speech_prob": 0.0007551074959337711}, {"id": 131, "seek": 41010, "start": 410.1, "end": 412.62, "text": " The more we are able, right, if you're trying to select an organism or", "tokens": [50364, 440, 544, 321, 366, 1075, 11, 558, 11, 498, 291, 434, 1382, 281, 3048, 364, 24128, 420, 50490], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 132, "seek": 41010, "start": 412.62, "end": 414.58000000000004, "text": " something, you're not going to look at how the organism makes decisions, you're", "tokens": [50490, 746, 11, 291, 434, 406, 516, 281, 574, 412, 577, 264, 24128, 1669, 5327, 11, 291, 434, 50588], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 133, "seek": 41010, "start": 414.58000000000004, "end": 416.34000000000003, "text": " going to see how well does it do, how fit is it?", "tokens": [50588, 516, 281, 536, 577, 731, 775, 309, 360, 11, 577, 3318, 307, 309, 30, 50676], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 134, "seek": 41010, "start": 418.42, "end": 419.86, "text": " That's like one implication of this.", "tokens": [50780, 663, 311, 411, 472, 37814, 295, 341, 13, 50852], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 135, "seek": 41010, "start": 420.26000000000005, "end": 423.22, "text": " Another implication is that it becomes harder for humans to understand what's", "tokens": [50872, 3996, 37814, 307, 300, 309, 3643, 6081, 337, 6255, 281, 1223, 437, 311, 51020], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 136, "seek": 41010, "start": 423.22, "end": 425.1, "text": " going on or intervene if things are going poorly.", "tokens": [51020, 516, 322, 420, 30407, 498, 721, 366, 516, 22271, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 137, "seek": 41010, "start": 426.26000000000005, "end": 429.94, "text": " So an upshot of that is that AI is in practice, bad behavior by AI is mostly", "tokens": [51172, 407, 364, 493, 18402, 295, 300, 307, 300, 7318, 307, 294, 3124, 11, 1578, 5223, 538, 7318, 307, 5240, 51356], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 138, "seek": 41010, "start": 429.94, "end": 432.78000000000003, "text": " detected or corrected by other AI systems, right?", "tokens": [51356, 21896, 420, 31687, 538, 661, 7318, 3652, 11, 558, 30, 51498], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 139, "seek": 41010, "start": 432.78000000000003, "end": 436.22, "text": " So AI systems are mostly monitoring other AI's where you can imagine humans", "tokens": [51498, 407, 7318, 3652, 366, 5240, 11028, 661, 7318, 311, 689, 291, 393, 3811, 6255, 51670], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 140, "seek": 41010, "start": 436.22, "end": 439.22, "text": " monitoring or automated monitoring, but at some point sophisticated AI systems", "tokens": [51670, 11028, 420, 18473, 11028, 11, 457, 412, 512, 935, 16950, 7318, 3652, 51820], "temperature": 0.0, "avg_logprob": -0.12989144447522286, "compression_ratio": 1.8833819241982508, "no_speech_prob": 0.0006460265722125769}, {"id": 141, "seek": 43922, "start": 439.3, "end": 440.70000000000005, "text": " are responsible for most monitoring.", "tokens": [50368, 366, 6250, 337, 881, 11028, 13, 50438], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 142, "seek": 43922, "start": 441.1, "end": 444.5, "text": " Even normal law enforcement or fighting a potential war would be done by AI", "tokens": [50458, 2754, 2710, 2101, 11475, 420, 5237, 257, 3995, 1516, 576, 312, 1096, 538, 7318, 50628], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 143, "seek": 43922, "start": 444.5, "end": 445.38000000000005, "text": " systems, right?", "tokens": [50628, 3652, 11, 558, 30, 50672], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 144, "seek": 43922, "start": 445.38000000000005, "end": 448.98, "text": " Because decisions are made quickly and because conflict is often deliberately", "tokens": [50672, 1436, 5327, 366, 1027, 2661, 293, 570, 6596, 307, 2049, 23506, 50852], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 145, "seek": 43922, "start": 448.98, "end": 450.62, "text": " made complex by a party to the conflict.", "tokens": [50852, 1027, 3997, 538, 257, 3595, 281, 264, 6596, 13, 50934], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 146, "seek": 43922, "start": 451.70000000000005, "end": 453.94000000000005, "text": " AI systems are running a lot of critical infrastructure.", "tokens": [50988, 7318, 3652, 366, 2614, 257, 688, 295, 4924, 6896, 13, 51100], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 147, "seek": 43922, "start": 453.94000000000005, "end": 456.66, "text": " Just if you want to achieve something in the world, AI plays an important part", "tokens": [51100, 1449, 498, 291, 528, 281, 4584, 746, 294, 264, 1002, 11, 7318, 5749, 364, 1021, 644, 51236], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 148, "seek": 43922, "start": 456.66, "end": 457.5, "text": " in that process.", "tokens": [51236, 294, 300, 1399, 13, 51278], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 149, "seek": 43922, "start": 458.42, "end": 460.54, "text": " So none of this is necessarily bad, right?", "tokens": [51324, 407, 6022, 295, 341, 307, 4725, 1578, 11, 558, 30, 51430], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 150, "seek": 43922, "start": 460.54, "end": 464.02000000000004, "text": " I think positive stories about AI will also have the step where good AI keeps", "tokens": [51430, 286, 519, 3353, 3676, 466, 7318, 486, 611, 362, 264, 1823, 689, 665, 7318, 5965, 51604], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 151, "seek": 43922, "start": 464.02000000000004, "end": 464.86, "text": " bad AI in check.", "tokens": [51604, 1578, 7318, 294, 1520, 13, 51646], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 152, "seek": 43922, "start": 465.1, "end": 468.70000000000005, "text": " I think it just is something that like now requires trust on behalf of all of", "tokens": [51658, 286, 519, 309, 445, 307, 746, 300, 411, 586, 7029, 3361, 322, 9490, 295, 439, 295, 51838], "temperature": 0.0, "avg_logprob": -0.11459111514156811, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.00044409121619537473}, {"id": 153, "seek": 46870, "start": 468.7, "end": 470.86, "text": " humanity, extended to all of these AI systems we've built.", "tokens": [50364, 10243, 11, 10913, 281, 439, 295, 613, 7318, 3652, 321, 600, 3094, 13, 50472], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 154, "seek": 46870, "start": 471.3, "end": 473.78, "text": " You might hope that we could trust the AI systems we've built because we built", "tokens": [50494, 509, 1062, 1454, 300, 321, 727, 3361, 264, 7318, 3652, 321, 600, 3094, 570, 321, 3094, 50618], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 155, "seek": 46870, "start": 473.78, "end": 475.21999999999997, "text": " them, we have freedom to design them.", "tokens": [50618, 552, 11, 321, 362, 5645, 281, 1715, 552, 13, 50690], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 156, "seek": 46870, "start": 475.97999999999996, "end": 477.86, "text": " But I think that depends on some decisions we make.", "tokens": [50728, 583, 286, 519, 300, 5946, 322, 512, 5327, 321, 652, 13, 50822], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 157, "seek": 46870, "start": 477.9, "end": 480.14, "text": " And yeah, we'll discuss how it can get somewhat more ugly.", "tokens": [50824, 400, 1338, 11, 321, 603, 2248, 577, 309, 393, 483, 8344, 544, 12246, 13, 50936], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 158, "seek": 46870, "start": 481.38, "end": 483.53999999999996, "text": " But the point I'm going to make right now or in this first section of the", "tokens": [50998, 583, 264, 935, 286, 478, 516, 281, 652, 558, 586, 420, 294, 341, 700, 3541, 295, 264, 51106], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 159, "seek": 46870, "start": 483.53999999999996, "end": 487.74, "text": " talk is not that it would necessarily get ugly, just that if for some reason,", "tokens": [51106, 751, 307, 406, 300, 309, 576, 4725, 483, 12246, 11, 445, 300, 498, 337, 512, 1778, 11, 51316], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 160, "seek": 46870, "start": 487.98, "end": 490.94, "text": " all of the AI systems in the world were like, what we really want to do is", "tokens": [51328, 439, 295, 264, 7318, 3652, 294, 264, 1002, 645, 411, 11, 437, 321, 534, 528, 281, 360, 307, 51476], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 161, "seek": 46870, "start": 490.94, "end": 494.18, "text": " disempower humanity, then I think it is quite likely that they would succeed.", "tokens": [51476, 717, 443, 9513, 10243, 11, 550, 286, 519, 309, 307, 1596, 3700, 300, 436, 576, 7754, 13, 51638], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 162, "seek": 46870, "start": 494.86, "end": 497.7, "text": " And I think this isn't even really the spicy take are getting my optimistic", "tokens": [51672, 400, 286, 519, 341, 1943, 380, 754, 534, 264, 9127, 747, 366, 1242, 452, 19397, 51814], "temperature": 0.0, "avg_logprob": -0.14708588955670418, "compression_ratio": 1.8425414364640884, "no_speech_prob": 0.0018662996590137482}, {"id": 163, "seek": 49770, "start": 497.7, "end": 499.02, "text": " futures. This is also the case.", "tokens": [50364, 26071, 13, 639, 307, 611, 264, 1389, 13, 50430], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 164, "seek": 49770, "start": 501.7, "end": 504.74, "text": " And the point is that the core question is just to do you somehow end up in a", "tokens": [50564, 400, 264, 935, 307, 300, 264, 4965, 1168, 307, 445, 281, 360, 291, 6063, 917, 493, 294, 257, 50716], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 165, "seek": 49770, "start": 504.74, "end": 507.9, "text": " situation where all of these AI systems, including the AI systems responsible for", "tokens": [50716, 2590, 689, 439, 295, 613, 7318, 3652, 11, 3009, 264, 7318, 3652, 6250, 337, 50874], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 166, "seek": 49770, "start": 507.9, "end": 511.14, "text": " doing monitoring or doing law enforcement or running your data centers or running", "tokens": [50874, 884, 11028, 420, 884, 2101, 11475, 420, 2614, 428, 1412, 10898, 420, 2614, 51036], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 167, "seek": 49770, "start": 511.14, "end": 514.06, "text": " your infrastructure, where all of those AI systems, for some reason, want to", "tokens": [51036, 428, 6896, 11, 689, 439, 295, 729, 7318, 3652, 11, 337, 512, 1778, 11, 528, 281, 51182], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 168, "seek": 49770, "start": 514.06, "end": 514.9, "text": " disempower humans.", "tokens": [51182, 717, 443, 9513, 6255, 13, 51224], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 169, "seek": 49770, "start": 520.8199999999999, "end": 523.74, "text": " No, I think the optimistic scenario still involves a point where AI systems", "tokens": [51520, 883, 11, 286, 519, 264, 19397, 9005, 920, 11626, 257, 935, 689, 7318, 3652, 51666], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 170, "seek": 49770, "start": 523.74, "end": 525.14, "text": " acting collectively could take over.", "tokens": [51666, 6577, 24341, 727, 747, 670, 13, 51736], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 171, "seek": 49770, "start": 525.54, "end": 526.78, "text": " I think in the optimistic scenario.", "tokens": [51756, 286, 519, 294, 264, 19397, 9005, 13, 51818], "temperature": 0.0, "avg_logprob": -0.16904417936466942, "compression_ratio": 1.8633093525179856, "no_speech_prob": 0.0006457959534600377}, {"id": 172, "seek": 52678, "start": 527.3, "end": 527.62, "text": " Yeah.", "tokens": [50390, 865, 13, 50406], "temperature": 0.0, "avg_logprob": -0.20516202804890085, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.000666440580971539}, {"id": 173, "seek": 52678, "start": 529.3, "end": 532.3399999999999, "text": " In the optimistic scenario, you, uh, you wait until you are ready.", "tokens": [50490, 682, 264, 19397, 9005, 11, 291, 11, 2232, 11, 291, 1699, 1826, 291, 366, 1919, 13, 50642], "temperature": 0.0, "avg_logprob": -0.20516202804890085, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.000666440580971539}, {"id": 174, "seek": 52678, "start": 532.3399999999999, "end": 535.74, "text": " You don't end up in the situation until in fact they would not try and take over.", "tokens": [50642, 509, 500, 380, 917, 493, 294, 264, 2590, 1826, 294, 1186, 436, 576, 406, 853, 293, 747, 670, 13, 50812], "temperature": 0.0, "avg_logprob": -0.20516202804890085, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.000666440580971539}, {"id": 175, "seek": 52678, "start": 535.78, "end": 538.06, "text": " And you're confident of that either because you've determined that the", "tokens": [50814, 400, 291, 434, 6679, 295, 300, 2139, 570, 291, 600, 9540, 300, 264, 50928], "temperature": 0.0, "avg_logprob": -0.20516202804890085, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.000666440580971539}, {"id": 176, "seek": 52678, "start": 538.06, "end": 541.4599999999999, "text": " empirics shake out such that this talk is just crazy talk, very plausible.", "tokens": [50928, 25790, 1167, 10283, 484, 1270, 300, 341, 751, 307, 445, 3219, 751, 11, 588, 39925, 13, 51098], "temperature": 0.0, "avg_logprob": -0.20516202804890085, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.000666440580971539}, {"id": 177, "seek": 52678, "start": 541.6999999999999, "end": 544.8199999999999, "text": " Or this talk was justified and we've addressed the problems or whatever.", "tokens": [51110, 1610, 341, 751, 390, 27808, 293, 321, 600, 13847, 264, 2740, 420, 2035, 13, 51266], "temperature": 0.0, "avg_logprob": -0.20516202804890085, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.000666440580971539}, {"id": 178, "seek": 54482, "start": 545.82, "end": 550.5, "text": " This is our already on the case of our grid, for example, if the power grid goes", "tokens": [50414, 639, 307, 527, 1217, 322, 264, 1389, 295, 527, 10748, 11, 337, 1365, 11, 498, 264, 1347, 10748, 1709, 50648], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 179, "seek": 54482, "start": 550.5, "end": 553.46, "text": " down now, a large fraction of humanity is going to die.", "tokens": [50648, 760, 586, 11, 257, 2416, 14135, 295, 10243, 307, 516, 281, 978, 13, 50796], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 180, "seek": 54482, "start": 554.34, "end": 555.46, "text": " I think it's plausible.", "tokens": [50840, 286, 519, 309, 311, 39925, 13, 50896], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 181, "seek": 54482, "start": 556.0600000000001, "end": 561.1400000000001, "text": " Well, a large fraction of humanity is maybe a small potatoes, but yeah, I think", "tokens": [50926, 1042, 11, 257, 2416, 14135, 295, 10243, 307, 1310, 257, 1359, 11811, 11, 457, 1338, 11, 286, 519, 51180], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 182, "seek": 54482, "start": 561.1400000000001, "end": 564.0200000000001, "text": " it's going to depend when I say if all AI's want to take over, the arguments", "tokens": [51180, 309, 311, 516, 281, 5672, 562, 286, 584, 498, 439, 7318, 311, 528, 281, 747, 670, 11, 264, 12869, 51324], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 183, "seek": 54482, "start": 564.0200000000001, "end": 566.94, "text": " I'm going to make are going to reply to like a particular class of AI systems.", "tokens": [51324, 286, 478, 516, 281, 652, 366, 516, 281, 16972, 281, 411, 257, 1729, 1508, 295, 7318, 3652, 13, 51470], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 184, "seek": 54482, "start": 567.0200000000001, "end": 567.1800000000001, "text": " Right.", "tokens": [51474, 1779, 13, 51482], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 185, "seek": 54482, "start": 567.1800000000001, "end": 569.1800000000001, "text": " So it's not going to be like all electronic devices failed.", "tokens": [51482, 407, 309, 311, 406, 516, 281, 312, 411, 439, 10092, 5759, 7612, 13, 51582], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 186, "seek": 54482, "start": 569.1800000000001, "end": 571.3000000000001, "text": " It's going to be some class of AI is produced in a certain way.", "tokens": [51582, 467, 311, 516, 281, 312, 512, 1508, 295, 7318, 307, 7126, 294, 257, 1629, 636, 13, 51688], "temperature": 0.0, "avg_logprob": -0.30600794156392414, "compression_ratio": 1.8109965635738832, "no_speech_prob": 0.0020504354033619165}, {"id": 187, "seek": 57130, "start": 572.02, "end": 575.18, "text": " Um, and I think that what happens over time is just, it becomes more and more", "tokens": [50400, 3301, 11, 293, 286, 519, 300, 437, 2314, 670, 565, 307, 445, 11, 309, 3643, 544, 293, 544, 50558], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 188, "seek": 57130, "start": 575.18, "end": 578.06, "text": " plausible for like the top end of that distribution, right?", "tokens": [50558, 39925, 337, 411, 264, 1192, 917, 295, 300, 7316, 11, 558, 30, 50702], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 189, "seek": 57130, "start": 578.06, "end": 580.8199999999999, "text": " Of the systems that are most sophisticated or like, right.", "tokens": [50702, 2720, 264, 3652, 300, 366, 881, 16950, 420, 411, 11, 558, 13, 50840], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 190, "seek": 57130, "start": 580.8199999999999, "end": 584.26, "text": " Right now, if all systems trained with deep learning simultaneously failed", "tokens": [50840, 1779, 586, 11, 498, 439, 3652, 8895, 365, 2452, 2539, 16561, 7612, 51012], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 191, "seek": 57130, "start": 584.26, "end": 586.9, "text": " and we're like, we hate the humans, we really want to disempower them, I", "tokens": [51012, 293, 321, 434, 411, 11, 321, 4700, 264, 6255, 11, 321, 534, 528, 281, 717, 443, 9513, 552, 11, 286, 51144], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 192, "seek": 57130, "start": 586.9, "end": 587.66, "text": " think it would be fine.", "tokens": [51144, 519, 309, 576, 312, 2489, 13, 51182], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 193, "seek": 57130, "start": 587.9799999999999, "end": 590.5, "text": " It's not totally obvious and it depends how smart they are about how they failed.", "tokens": [51198, 467, 311, 406, 3879, 6322, 293, 309, 5946, 577, 4069, 436, 366, 466, 577, 436, 7612, 13, 51324], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 194, "seek": 57130, "start": 590.9799999999999, "end": 592.54, "text": " Um, I think we'd probably be okay.", "tokens": [51348, 3301, 11, 286, 519, 321, 1116, 1391, 312, 1392, 13, 51426], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 195, "seek": 57130, "start": 592.9399999999999, "end": 595.9799999999999, "text": " But I mean, again, I think that the whole story we're telling this is kind of", "tokens": [51446, 583, 286, 914, 11, 797, 11, 286, 519, 300, 264, 1379, 1657, 321, 434, 3585, 341, 307, 733, 295, 51598], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 196, "seek": 57130, "start": 595.9799999999999, "end": 598.62, "text": " just like, I think you could take out and there's still be some risk.", "tokens": [51598, 445, 411, 11, 286, 519, 291, 727, 747, 484, 293, 456, 311, 920, 312, 512, 3148, 13, 51730], "temperature": 0.0, "avg_logprob": -0.13558828180486507, "compression_ratio": 1.739010989010989, "no_speech_prob": 0.0010319063439965248}, {"id": 197, "seek": 59862, "start": 598.86, "end": 601.42, "text": " Yeah.", "tokens": [50376, 865, 13, 50504], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 198, "seek": 59862, "start": 604.94, "end": 605.54, "text": " If what failed?", "tokens": [50680, 759, 437, 7612, 30, 50710], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 199, "seek": 59862, "start": 609.38, "end": 612.26, "text": " Yeah, I think that's, you can imagine cases where it's like, if all the cars", "tokens": [50902, 865, 11, 286, 519, 300, 311, 11, 291, 393, 3811, 3331, 689, 309, 311, 411, 11, 498, 439, 264, 5163, 51046], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 200, "seek": 59862, "start": 612.26, "end": 613.46, "text": " failed, that's enough to kill everyone.", "tokens": [51046, 7612, 11, 300, 311, 1547, 281, 1961, 1518, 13, 51106], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 201, "seek": 59862, "start": 613.7, "end": 615.22, "text": " This is not necessarily a striking claim.", "tokens": [51118, 639, 307, 406, 4725, 257, 18559, 3932, 13, 51194], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 202, "seek": 59862, "start": 616.46, "end": 619.9, "text": " The striking claim is definitely the one that it is plausible that misaligned", "tokens": [51256, 440, 18559, 3932, 307, 2138, 264, 472, 300, 309, 307, 39925, 300, 3346, 304, 16690, 51428], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 203, "seek": 59862, "start": 619.9, "end": 621.42, "text": " AI systems may want to take over.", "tokens": [51428, 7318, 3652, 815, 528, 281, 747, 670, 13, 51504], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 204, "seek": 59862, "start": 621.46, "end": 623.74, "text": " I guess this is in some sense the part we've been most talking about throughout", "tokens": [51506, 286, 2041, 341, 307, 294, 512, 2020, 264, 644, 321, 600, 668, 881, 1417, 466, 3710, 51620], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 205, "seek": 59862, "start": 623.74, "end": 624.0600000000001, "text": " the day.", "tokens": [51620, 264, 786, 13, 51636], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 206, "seek": 59862, "start": 624.46, "end": 626.46, "text": " I'm going to dwell on this a bit and then I'm going to talk about why these", "tokens": [51656, 286, 478, 516, 281, 24355, 322, 341, 257, 857, 293, 550, 286, 478, 516, 281, 751, 466, 983, 613, 51756], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 207, "seek": 59862, "start": 626.46, "end": 628.38, "text": " failures may be correlated in a problematic way.", "tokens": [51756, 20774, 815, 312, 38574, 294, 257, 19011, 636, 13, 51852], "temperature": 0.0, "avg_logprob": -0.18485253048639227, "compression_ratio": 1.7094594594594594, "no_speech_prob": 0.000535723171196878}, {"id": 208, "seek": 62838, "start": 628.5, "end": 631.14, "text": " That is why you might have all AI systems trying to take over at the same time.", "tokens": [50370, 663, 307, 983, 291, 1062, 362, 439, 7318, 3652, 1382, 281, 747, 670, 412, 264, 912, 565, 13, 50502], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 209, "seek": 62838, "start": 633.34, "end": 636.86, "text": " Um, this, I'm going to talk about two failure modes, both of which we've", "tokens": [50612, 3301, 11, 341, 11, 286, 478, 516, 281, 751, 466, 732, 7763, 14068, 11, 1293, 295, 597, 321, 600, 50788], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 210, "seek": 62838, "start": 636.86, "end": 637.74, "text": " touched on earlier.", "tokens": [50788, 9828, 322, 3071, 13, 50832], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 211, "seek": 62838, "start": 637.9399999999999, "end": 639.1, "text": " So one is reward hacking.", "tokens": [50842, 407, 472, 307, 7782, 31422, 13, 50900], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 212, "seek": 62838, "start": 639.26, "end": 642.98, "text": " That is that disempowering humanity may be an effective strategy for AI systems", "tokens": [50908, 663, 307, 300, 717, 443, 9513, 278, 10243, 815, 312, 364, 4942, 5206, 337, 7318, 3652, 51094], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 213, "seek": 62838, "start": 642.98, "end": 644.38, "text": " collectively to get a lot of reward.", "tokens": [51094, 24341, 281, 483, 257, 688, 295, 7782, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 214, "seek": 62838, "start": 644.78, "end": 648.02, "text": " And the second is deceptive alignment scenario that Rohan talked about.", "tokens": [51184, 400, 264, 1150, 307, 368, 1336, 488, 18515, 9005, 300, 27490, 282, 2825, 466, 13, 51346], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 215, "seek": 62838, "start": 653.18, "end": 653.9, "text": " Okay.", "tokens": [51604, 1033, 13, 51640], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 216, "seek": 62838, "start": 653.9, "end": 657.06, "text": " So I mentioned briefly before this idea that you may train AI systems by", "tokens": [51640, 407, 286, 2835, 10515, 949, 341, 1558, 300, 291, 815, 3847, 7318, 3652, 538, 51798], "temperature": 0.0, "avg_logprob": -0.12970394384665568, "compression_ratio": 1.6408450704225352, "no_speech_prob": 0.0002867972361855209}, {"id": 217, "seek": 65706, "start": 657.06, "end": 659.3, "text": " evaluating the outcomes of the actions they propose.", "tokens": [50364, 27479, 264, 10070, 295, 264, 5909, 436, 17421, 13, 50476], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 218, "seek": 65706, "start": 659.8199999999999, "end": 662.54, "text": " Um, so just to briefly review what that actually entails, right?", "tokens": [50502, 3301, 11, 370, 445, 281, 10515, 3131, 437, 300, 767, 50133, 11, 558, 30, 50638], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 219, "seek": 65706, "start": 662.54, "end": 664.02, "text": " We have some policy, some big neural net.", "tokens": [50638, 492, 362, 512, 3897, 11, 512, 955, 18161, 2533, 13, 50712], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 220, "seek": 65706, "start": 664.42, "end": 668.78, "text": " It proposes some actions and some of those actions to distinguish between them.", "tokens": [50732, 467, 2365, 4201, 512, 5909, 293, 512, 295, 729, 5909, 281, 20206, 1296, 552, 13, 50950], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 221, "seek": 65706, "start": 668.78, "end": 671.78, "text": " We actually need to execute the action, measure the results and decide how much", "tokens": [50950, 492, 767, 643, 281, 14483, 264, 3069, 11, 3481, 264, 3542, 293, 4536, 577, 709, 51100], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 222, "seek": 65706, "start": 671.78, "end": 672.66, "text": " we like the results.", "tokens": [51100, 321, 411, 264, 3542, 13, 51144], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 223, "seek": 65706, "start": 672.66, "end": 675.2199999999999, "text": " Let's say the reward is to start judgment of how much we like the results.", "tokens": [51144, 961, 311, 584, 264, 7782, 307, 281, 722, 12216, 295, 577, 709, 321, 411, 264, 3542, 13, 51272], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 224, "seek": 65706, "start": 675.66, "end": 679.18, "text": " And then we adjust policies to maximize the expected reward of the actions", "tokens": [51294, 400, 550, 321, 4369, 7657, 281, 19874, 264, 5176, 7782, 295, 264, 5909, 51470], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 225, "seek": 65706, "start": 679.18, "end": 679.8199999999999, "text": " they propose.", "tokens": [51470, 436, 17421, 13, 51502], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 226, "seek": 65706, "start": 681.2199999999999, "end": 681.42, "text": " Right.", "tokens": [51572, 1779, 13, 51582], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 227, "seek": 65706, "start": 681.42, "end": 684.6199999999999, "text": " And there's a, it's plausible that if you do this, you get a policy which is", "tokens": [51582, 400, 456, 311, 257, 11, 309, 311, 39925, 300, 498, 291, 360, 341, 11, 291, 483, 257, 3897, 597, 307, 51742], "temperature": 0.0, "avg_logprob": -0.14424935165716676, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0032708512153476477}, {"id": 228, "seek": 68462, "start": 684.86, "end": 687.98, "text": " implicitly or explicitly considering many possible actions and selecting the", "tokens": [50376, 26947, 356, 420, 20803, 8079, 867, 1944, 5909, 293, 18182, 264, 50532], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 229, "seek": 68462, "start": 687.98, "end": 689.62, "text": " actions that will lead to the highest reward.", "tokens": [50532, 5909, 300, 486, 1477, 281, 264, 6343, 7782, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 230, "seek": 68462, "start": 690.34, "end": 692.14, "text": " There are other ways you could end up at that same outcome, right?", "tokens": [50650, 821, 366, 661, 2098, 291, 727, 917, 493, 412, 300, 912, 9700, 11, 558, 30, 50740], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 231, "seek": 68462, "start": 692.14, "end": 694.78, "text": " We could do model based RL and explicitly have a loop in which we predict the", "tokens": [50740, 492, 727, 360, 2316, 2361, 497, 43, 293, 20803, 362, 257, 6367, 294, 597, 321, 6069, 264, 50872], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 232, "seek": 68462, "start": 694.78, "end": 696.0600000000001, "text": " consequences of different actions.", "tokens": [50872, 10098, 295, 819, 5909, 13, 50936], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 233, "seek": 68462, "start": 696.22, "end": 699.86, "text": " You could have decision transformers, the condition on like high quality actions.", "tokens": [50944, 509, 727, 362, 3537, 4088, 433, 11, 264, 4188, 322, 411, 1090, 3125, 5909, 13, 51126], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 234, "seek": 68462, "start": 700.26, "end": 703.7, "text": " It could just have some other planning process needed still into a model,", "tokens": [51146, 467, 727, 445, 362, 512, 661, 5038, 1399, 2978, 920, 666, 257, 2316, 11, 51318], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 235, "seek": 68462, "start": 703.7, "end": 706.82, "text": " whatever, all of these leads to like the same endpoint, which is sometimes", "tokens": [51318, 2035, 11, 439, 295, 613, 6689, 281, 411, 264, 912, 35795, 11, 597, 307, 2171, 51474], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 236, "seek": 68462, "start": 706.82, "end": 708.46, "text": " because we don't know how to achieve goals.", "tokens": [51474, 570, 321, 500, 380, 458, 577, 281, 4584, 5493, 13, 51556], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 237, "seek": 68462, "start": 708.58, "end": 711.54, "text": " We're going to train AI systems to take actions that lead to high reward where", "tokens": [51562, 492, 434, 516, 281, 3847, 7318, 3652, 281, 747, 5909, 300, 1477, 281, 1090, 7782, 689, 51710], "temperature": 0.0, "avg_logprob": -0.14646583915556838, "compression_ratio": 1.772972972972973, "no_speech_prob": 0.001000199350528419}, {"id": 238, "seek": 71154, "start": 711.54, "end": 714.5, "text": " reward means we measure the outcome and then we decide how much we like that", "tokens": [50364, 7782, 1355, 321, 3481, 264, 9700, 293, 550, 321, 4536, 577, 709, 321, 411, 300, 50512], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 239, "seek": 71154, "start": 714.5, "end": 715.3, "text": " result that we measured.", "tokens": [50512, 1874, 300, 321, 12690, 13, 50552], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 240, "seek": 71154, "start": 717.6999999999999, "end": 719.26, "text": " This can potentially lead to takeover.", "tokens": [50672, 639, 393, 7263, 1477, 281, 747, 3570, 13, 50750], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 241, "seek": 71154, "start": 719.26, "end": 722.4599999999999, "text": " If corrupting measurements in some situations is the best way to get a high", "tokens": [50750, 759, 17366, 278, 15383, 294, 512, 6851, 307, 264, 1151, 636, 281, 483, 257, 1090, 50910], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 242, "seek": 71154, "start": 722.4599999999999, "end": 723.3399999999999, "text": " reward, right?", "tokens": [50910, 7782, 11, 558, 30, 50954], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 243, "seek": 71154, "start": 723.3399999999999, "end": 726.2199999999999, "text": " So you can imagine some spectrum of forms of reward hacking, right?", "tokens": [50954, 407, 291, 393, 3811, 512, 11143, 295, 6422, 295, 7782, 31422, 11, 558, 30, 51098], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 244, "seek": 71154, "start": 726.2199999999999, "end": 728.62, "text": " A really simple one is you could try and flatter and deceive humans.", "tokens": [51098, 316, 534, 2199, 472, 307, 291, 727, 853, 293, 41247, 293, 43440, 6255, 13, 51218], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 245, "seek": 71154, "start": 728.66, "end": 730.14, "text": " Like that's a reasonable way to get high reward.", "tokens": [51220, 1743, 300, 311, 257, 10585, 636, 281, 483, 1090, 7782, 13, 51294], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 246, "seek": 71154, "start": 730.3399999999999, "end": 732.66, "text": " Maybe on reflection, humans are like, that's not actually what we wanted.", "tokens": [51304, 2704, 322, 12914, 11, 6255, 366, 411, 11, 300, 311, 406, 767, 437, 321, 1415, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 247, "seek": 71154, "start": 732.8199999999999, "end": 734.8199999999999, "text": " So if they were more careful, they would give it a lower reward.", "tokens": [51428, 407, 498, 436, 645, 544, 5026, 11, 436, 576, 976, 309, 257, 3126, 7782, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 248, "seek": 71154, "start": 735.66, "end": 736.62, "text": " You can move to, right?", "tokens": [51570, 509, 393, 1286, 281, 11, 558, 30, 51618], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 249, "seek": 71154, "start": 736.62, "end": 739.62, "text": " If you're writing code and part of how a human evaluates the code you write is", "tokens": [51618, 759, 291, 434, 3579, 3089, 293, 644, 295, 577, 257, 1952, 6133, 1024, 264, 3089, 291, 2464, 307, 51768], "temperature": 0.0, "avg_logprob": -0.1447443962097168, "compression_ratio": 1.815426997245179, "no_speech_prob": 0.0019264575093984604}, {"id": 250, "seek": 73962, "start": 739.62, "end": 742.9, "text": " by performing simple tests, you could try and anticipate or understand those", "tokens": [50364, 538, 10205, 2199, 6921, 11, 291, 727, 853, 293, 21685, 420, 1223, 729, 50528], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 251, "seek": 73962, "start": 742.9, "end": 746.0600000000001, "text": " tests and write code, which breaks those tests or causes them to behave in an", "tokens": [50528, 6921, 293, 2464, 3089, 11, 597, 9857, 729, 6921, 420, 7700, 552, 281, 15158, 294, 364, 50686], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 252, "seek": 73962, "start": 746.0600000000001, "end": 746.9, "text": " unintended way.", "tokens": [50686, 49902, 636, 13, 50728], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 253, "seek": 73962, "start": 747.14, "end": 749.66, "text": " Then when a human looks at the results of those tests, they're more likely to", "tokens": [50740, 1396, 562, 257, 1952, 1542, 412, 264, 3542, 295, 729, 6921, 11, 436, 434, 544, 3700, 281, 50866], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 254, "seek": 73962, "start": 749.66, "end": 751.02, "text": " have a favorable judgment to your code.", "tokens": [50866, 362, 257, 29557, 12216, 281, 428, 3089, 13, 50934], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 255, "seek": 73962, "start": 751.02, "end": 753.0600000000001, "text": " If they don't understand the mechanism for the problem.", "tokens": [50934, 759, 436, 500, 380, 1223, 264, 7513, 337, 264, 1154, 13, 51036], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 256, "seek": 73962, "start": 753.82, "end": 757.18, "text": " Or you can move out to creating elaborate false logs to hide errors, right?", "tokens": [51074, 1610, 291, 393, 1286, 484, 281, 4084, 20945, 7908, 20820, 281, 6479, 13603, 11, 558, 30, 51242], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 257, "seek": 73962, "start": 757.18, "end": 759.94, "text": " If I'm an AI system and part of how I'm evaluated is what happens when the", "tokens": [51242, 759, 286, 478, 364, 7318, 1185, 293, 644, 295, 577, 286, 478, 25509, 307, 437, 2314, 562, 264, 51380], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 258, "seek": 73962, "start": 759.94, "end": 761.26, "text": " code I write gets deployed.", "tokens": [51380, 3089, 286, 2464, 2170, 17826, 13, 51446], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 259, "seek": 73962, "start": 761.38, "end": 763.94, "text": " One thing I might want to do is say, okay, this code should change the way that", "tokens": [51452, 1485, 551, 286, 1062, 528, 281, 360, 307, 584, 11, 1392, 11, 341, 3089, 820, 1319, 264, 636, 300, 51580], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 260, "seek": 73962, "start": 763.94, "end": 766.7, "text": " logs get collected or should modify logs to make it.", "tokens": [51580, 20820, 483, 11087, 420, 820, 16927, 20820, 281, 652, 309, 13, 51718], "temperature": 0.0, "avg_logprob": -0.13564505400481047, "compression_ratio": 1.7587131367292226, "no_speech_prob": 0.0009695934713818133}, {"id": 261, "seek": 76670, "start": 766.7, "end": 769.58, "text": " So in retrospect, a human thinks this outcome was better.", "tokens": [50364, 407, 294, 34997, 11, 257, 1952, 7309, 341, 9700, 390, 1101, 13, 50508], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 262, "seek": 76670, "start": 771.0200000000001, "end": 773.82, "text": " And you can imagine as you go down the spectrum, these sort of corresponds to", "tokens": [50580, 400, 291, 393, 3811, 382, 291, 352, 760, 264, 11143, 11, 613, 1333, 295, 23249, 281, 50720], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 263, "seek": 76670, "start": 773.82, "end": 775.46, "text": " more extensive evaluations.", "tokens": [50720, 544, 13246, 43085, 13, 50802], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 264, "seek": 76670, "start": 775.58, "end": 778.34, "text": " One reason you might use these more extensive evaluations is to prevent", "tokens": [50808, 1485, 1778, 291, 1062, 764, 613, 544, 13246, 43085, 307, 281, 4871, 50946], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 265, "seek": 76670, "start": 778.34, "end": 780.5, "text": " problems or oversights from earlier stages.", "tokens": [50946, 2740, 420, 15488, 5761, 490, 3071, 10232, 13, 51054], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 266, "seek": 76670, "start": 784.1400000000001, "end": 786.1400000000001, "text": " You can imagine compromising a server to hide errors.", "tokens": [51236, 509, 393, 3811, 11482, 3436, 257, 7154, 281, 6479, 13603, 13, 51336], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 267, "seek": 76670, "start": 786.1400000000001, "end": 788.7800000000001, "text": " So not just changing log files, but if a human goes to try and figure out what", "tokens": [51336, 407, 406, 445, 4473, 3565, 7098, 11, 457, 498, 257, 1952, 1709, 281, 853, 293, 2573, 484, 437, 51468], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 268, "seek": 76670, "start": 788.7800000000001, "end": 792.0600000000001, "text": " happened, you might say, if I just replace the SSH server on this machine, it's", "tokens": [51468, 2011, 11, 291, 1062, 584, 11, 498, 286, 445, 7406, 264, 12238, 39, 7154, 322, 341, 3479, 11, 309, 311, 51632], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 269, "seek": 76670, "start": 792.0600000000001, "end": 794.6600000000001, "text": " going to be really hard for human to understand what's going on after the", "tokens": [51632, 516, 281, 312, 534, 1152, 337, 1952, 281, 1223, 437, 311, 516, 322, 934, 264, 51762], "temperature": 0.0, "avg_logprob": -0.11677826853359446, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.00047276547411456704}, {"id": 270, "seek": 79466, "start": 794.66, "end": 796.5, "text": " fact remotely, it's going to be unlikely.", "tokens": [50364, 1186, 20824, 11, 309, 311, 516, 281, 312, 17518, 13, 50456], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 271, "seek": 79466, "start": 796.5, "end": 798.06, "text": " They'll notice that something bad has happened.", "tokens": [50456, 814, 603, 3449, 300, 746, 1578, 575, 2011, 13, 50534], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 272, "seek": 79466, "start": 798.4599999999999, "end": 800.06, "text": " You can get to these more extreme outcomes.", "tokens": [50554, 509, 393, 483, 281, 613, 544, 8084, 10070, 13, 50634], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 273, "seek": 79466, "start": 800.06, "end": 803.18, "text": " So Jay mentioned this idea of like, if my system is being trained and what it", "tokens": [50634, 407, 11146, 2835, 341, 1558, 295, 411, 11, 498, 452, 1185, 307, 885, 8895, 293, 437, 309, 50790], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 274, "seek": 79466, "start": 803.18, "end": 806.42, "text": " wants is to get a high reward, ultimately, that reward is just about a bunch", "tokens": [50790, 2738, 307, 281, 483, 257, 1090, 7782, 11, 6284, 11, 300, 7782, 307, 445, 466, 257, 3840, 50952], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 275, "seek": 79466, "start": 806.42, "end": 808.5, "text": " of measurements that could enter it into the training data set.", "tokens": [50952, 295, 15383, 300, 727, 3242, 309, 666, 264, 3097, 1412, 992, 13, 51056], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 276, "seek": 79466, "start": 810.2199999999999, "end": 811.02, "text": " One sec, I guess.", "tokens": [51142, 1485, 907, 11, 286, 2041, 13, 51182], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 277, "seek": 79466, "start": 811.78, "end": 814.3399999999999, "text": " And then you can just imagine the most extreme case of saying like, okay, if all", "tokens": [51220, 400, 550, 291, 393, 445, 3811, 264, 881, 8084, 1389, 295, 1566, 411, 11, 1392, 11, 498, 439, 51348], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 278, "seek": 79466, "start": 814.3399999999999, "end": 817.66, "text": " the systems collectively disempowered humanity, then it does not matter if", "tokens": [51348, 264, 3652, 24341, 717, 443, 27178, 10243, 11, 550, 309, 775, 406, 1871, 498, 51514], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 279, "seek": 79466, "start": 817.66, "end": 819.54, "text": " humans would like to go in later and change this.", "tokens": [51514, 6255, 576, 411, 281, 352, 294, 1780, 293, 1319, 341, 13, 51608], "temperature": 0.0, "avg_logprob": -0.18504438729121767, "compression_ratio": 1.7041420118343196, "no_speech_prob": 0.0005702354246750474}, {"id": 280, "seek": 81954, "start": 820.5, "end": 823.6999999999999, "text": " I think one dynamic that's worth pointing out, and then I'll get to Jacob, is", "tokens": [50412, 286, 519, 472, 8546, 300, 311, 3163, 12166, 484, 11, 293, 550, 286, 603, 483, 281, 14117, 11, 307, 50572], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 281, "seek": 81954, "start": 823.6999999999999, "end": 827.18, "text": " like, if you have some of these smaller failures, right?", "tokens": [50572, 411, 11, 498, 291, 362, 512, 295, 613, 4356, 20774, 11, 558, 30, 50746], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 282, "seek": 81954, "start": 827.18, "end": 830.2199999999999, "text": " If you imagine the system which behaves badly on bricks a server, a human is", "tokens": [50746, 759, 291, 3811, 264, 1185, 597, 36896, 13425, 322, 25497, 257, 7154, 11, 257, 1952, 307, 50898], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 283, "seek": 81954, "start": 830.2199999999999, "end": 831.62, "text": " likely to say, okay, that was bad behavior.", "tokens": [50898, 3700, 281, 584, 11, 1392, 11, 300, 390, 1578, 5223, 13, 50968], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 284, "seek": 81954, "start": 831.62, "end": 832.86, "text": " I'm going to go give it a low reward.", "tokens": [50968, 286, 478, 516, 281, 352, 976, 309, 257, 2295, 7782, 13, 51030], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 285, "seek": 81954, "start": 833.42, "end": 836.66, "text": " And the results of that could either be to train a system to not do funny things", "tokens": [51058, 400, 264, 3542, 295, 300, 727, 2139, 312, 281, 3847, 257, 1185, 281, 406, 360, 4074, 721, 51220], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 286, "seek": 81954, "start": 836.74, "end": 839.54, "text": " or to train a system to, if you get up to funny business, ensure that a human", "tokens": [51224, 420, 281, 3847, 257, 1185, 281, 11, 498, 291, 483, 493, 281, 4074, 1606, 11, 5586, 300, 257, 1952, 51364], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 287, "seek": 81954, "start": 839.54, "end": 841.54, "text": " never goes and flags that as low reward, right?", "tokens": [51364, 1128, 1709, 293, 23265, 300, 382, 2295, 7782, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 288, "seek": 81954, "start": 841.54, "end": 844.06, "text": " Both of those seem like policies that will avoid that bad behavior.", "tokens": [51464, 6767, 295, 729, 1643, 411, 7657, 300, 486, 5042, 300, 1578, 5223, 13, 51590], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 289, "seek": 81954, "start": 844.2199999999999, "end": 846.38, "text": " It's very unclear which one gradient to send gets you to.", "tokens": [51598, 467, 311, 588, 25636, 597, 472, 16235, 281, 2845, 2170, 291, 281, 13, 51706], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 290, "seek": 81954, "start": 847.5799999999999, "end": 847.86, "text": " Yeah.", "tokens": [51766, 865, 13, 51780], "temperature": 0.0, "avg_logprob": -0.1543114980061849, "compression_ratio": 1.7903682719546743, "no_speech_prob": 0.0009696283377707005}, {"id": 291, "seek": 84954, "start": 850.38, "end": 864.9, "text": " Yeah, so I would say in some sense, like it depends a little bit on what the system", "tokens": [50406, 865, 11, 370, 286, 576, 584, 294, 512, 2020, 11, 411, 309, 5946, 257, 707, 857, 322, 437, 264, 1185, 51132], "temperature": 0.0, "avg_logprob": -0.1979649861653646, "compression_ratio": 1.6310679611650485, "no_speech_prob": 0.00024535044212825596}, {"id": 292, "seek": 84954, "start": 864.9, "end": 866.14, "text": " wants or how you set up training.", "tokens": [51132, 2738, 420, 577, 291, 992, 493, 3097, 13, 51194], "temperature": 0.0, "avg_logprob": -0.1979649861653646, "compression_ratio": 1.6310679611650485, "no_speech_prob": 0.00024535044212825596}, {"id": 293, "seek": 84954, "start": 866.3399999999999, "end": 868.9, "text": " In some sense, a lot of these things are like errors, right?", "tokens": [51204, 682, 512, 2020, 11, 257, 688, 295, 613, 721, 366, 411, 13603, 11, 558, 30, 51332], "temperature": 0.0, "avg_logprob": -0.1979649861653646, "compression_ratio": 1.6310679611650485, "no_speech_prob": 0.00024535044212825596}, {"id": 294, "seek": 84954, "start": 869.18, "end": 873.2199999999999, "text": " So I'd say that like, right, if you care about as a system, if what the AI cares", "tokens": [51346, 407, 286, 1116, 584, 300, 411, 11, 558, 11, 498, 291, 1127, 466, 382, 257, 1185, 11, 498, 437, 264, 7318, 12310, 51548], "temperature": 0.0, "avg_logprob": -0.1979649861653646, "compression_ratio": 1.6310679611650485, "no_speech_prob": 0.00024535044212825596}, {"id": 295, "seek": 84954, "start": 873.2199999999999, "end": 876.5, "text": " about is just don't do things that will ultimately be assigned a low reward.", "tokens": [51548, 466, 307, 445, 500, 380, 360, 721, 300, 486, 6284, 312, 13279, 257, 2295, 7782, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1979649861653646, "compression_ratio": 1.6310679611650485, "no_speech_prob": 0.00024535044212825596}, {"id": 296, "seek": 87650, "start": 876.78, "end": 879.94, "text": " And we would ultimately detect and assign low reward to many of these failures.", "tokens": [50378, 400, 321, 576, 6284, 5531, 293, 6269, 2295, 7782, 281, 867, 295, 613, 20774, 13, 50536], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 297, "seek": 87650, "start": 880.18, "end": 882.74, "text": " Then all of them would be errors, except the one at the far right.", "tokens": [50548, 1396, 439, 295, 552, 576, 312, 13603, 11, 3993, 264, 472, 412, 264, 1400, 558, 13, 50676], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 298, "seek": 87650, "start": 883.62, "end": 886.66, "text": " And so I think a reasonable guess for what happens is you have systems which", "tokens": [50720, 400, 370, 286, 519, 257, 10585, 2041, 337, 437, 2314, 307, 291, 362, 3652, 597, 50872], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 299, "seek": 87650, "start": 886.66, "end": 888.82, "text": " make some, some number of these errors along the left.", "tokens": [50872, 652, 512, 11, 512, 1230, 295, 613, 13603, 2051, 264, 1411, 13, 50980], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 300, "seek": 87650, "start": 889.06, "end": 891.26, "text": " At some point they're like, okay, I understand what's going on here.", "tokens": [50992, 1711, 512, 935, 436, 434, 411, 11, 1392, 11, 286, 1223, 437, 311, 516, 322, 510, 13, 51102], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 301, "seek": 87650, "start": 891.26, "end": 893.78, "text": " I understand humans are going to escalate and take more extensive measures", "tokens": [51102, 286, 1223, 6255, 366, 516, 281, 17871, 473, 293, 747, 544, 13246, 8000, 51228], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 302, "seek": 87650, "start": 893.78, "end": 894.78, "text": " to notice bad behavior.", "tokens": [51228, 281, 3449, 1578, 5223, 13, 51278], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 303, "seek": 87650, "start": 895.1, "end": 896.78, "text": " Bad behavior is not an effective strategy.", "tokens": [51294, 11523, 5223, 307, 406, 364, 4942, 5206, 13, 51378], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 304, "seek": 87650, "start": 897.06, "end": 899.86, "text": " And then you have this fork in the road, which a J referred to of like either", "tokens": [51392, 400, 550, 291, 362, 341, 17716, 294, 264, 3060, 11, 597, 257, 508, 10839, 281, 295, 411, 2139, 51532], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 305, "seek": 87650, "start": 899.86, "end": 903.02, "text": " you learn to just not do anything bad or he's like, okay, I understand.", "tokens": [51532, 291, 1466, 281, 445, 406, 360, 1340, 1578, 420, 415, 311, 411, 11, 1392, 11, 286, 1223, 13, 51690], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 306, "seek": 87650, "start": 903.02, "end": 905.26, "text": " I understand the class of bad behavior, which is likely to be detected.", "tokens": [51690, 286, 1223, 264, 1508, 295, 1578, 5223, 11, 597, 307, 3700, 281, 312, 21896, 13, 51802], "temperature": 0.0, "avg_logprob": -0.11575745452534068, "compression_ratio": 1.8563968668407311, "no_speech_prob": 0.005909040104597807}, {"id": 307, "seek": 90526, "start": 905.26, "end": 907.7, "text": " And so I'm not going to engage in bad behavior that would be likely to be", "tokens": [50364, 400, 370, 286, 478, 406, 516, 281, 4683, 294, 1578, 5223, 300, 576, 312, 3700, 281, 312, 50486], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 308, "seek": 90526, "start": 907.7, "end": 909.9399999999999, "text": " detected and it's just unclear to me which way you go.", "tokens": [50486, 21896, 293, 309, 311, 445, 25636, 281, 385, 597, 636, 291, 352, 13, 50598], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 309, "seek": 90526, "start": 910.18, "end": 912.58, "text": " That's an important, I don't think you, like it's fairly likely you don't see", "tokens": [50610, 663, 311, 364, 1021, 11, 286, 500, 380, 519, 291, 11, 411, 309, 311, 6457, 3700, 291, 500, 380, 536, 50730], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 310, "seek": 90526, "start": 912.58, "end": 915.54, "text": " a march along the spectrum because at some point those are mistakes.", "tokens": [50730, 257, 8368, 2051, 264, 11143, 570, 412, 512, 935, 729, 366, 8038, 13, 50878], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 311, "seek": 90526, "start": 915.58, "end": 917.66, "text": " Like if you try and do something bad and it's a half measure.", "tokens": [50880, 1743, 498, 291, 853, 293, 360, 746, 1578, 293, 309, 311, 257, 1922, 3481, 13, 50984], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 312, "seek": 90526, "start": 919.06, "end": 923.98, "text": " Well, so like, right, but it seems like a place where, like you say, no,", "tokens": [51054, 1042, 11, 370, 411, 11, 558, 11, 457, 309, 2544, 411, 257, 1081, 689, 11, 411, 291, 584, 11, 572, 11, 51300], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 313, "seek": 90526, "start": 923.98, "end": 926.9, "text": " it's kind of like to figure out what you do with the, you know,", "tokens": [51300, 309, 311, 733, 295, 411, 281, 2573, 484, 437, 291, 360, 365, 264, 11, 291, 458, 11, 51446], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 314, "seek": 90526, "start": 926.9, "end": 931.74, "text": " for example, hold on, instead, but I think you can ask, like, where does the", "tokens": [51446, 337, 1365, 11, 1797, 322, 11, 2602, 11, 457, 286, 519, 291, 393, 1029, 11, 411, 11, 689, 775, 264, 51688], "temperature": 0.0, "avg_logprob": -0.37018406855595576, "compression_ratio": 1.7111801242236024, "no_speech_prob": 0.0009695622720755637}, {"id": 315, "seek": 93174, "start": 931.74, "end": 933.3, "text": " school come from?", "tokens": [50364, 1395, 808, 490, 30, 50442], "temperature": 0.0, "avg_logprob": -0.9060296376546224, "compression_ratio": 0.813953488372093, "no_speech_prob": 0.07253406196832657}, {"id": 316, "seek": 93174, "start": 956.22, "end": 957.1800000000001, "text": " I mean, it seems.", "tokens": [51588, 286, 914, 11, 309, 2544, 13, 51636], "temperature": 0.0, "avg_logprob": -0.9060296376546224, "compression_ratio": 0.813953488372093, "no_speech_prob": 0.07253406196832657}, {"id": 317, "seek": 96174, "start": 962.66, "end": 963.42, "text": " Is that.", "tokens": [50410, 1119, 300, 13, 50448], "temperature": 1.0, "avg_logprob": -3.7743043165940504, "compression_ratio": 1.0, "no_speech_prob": 0.4563605785369873}, {"id": 318, "seek": 96174, "start": 966.86, "end": 967.5, "text": " You have arrested.", "tokens": [50620, 509, 362, 12469, 13, 50652], "temperature": 1.0, "avg_logprob": -3.7743043165940504, "compression_ratio": 1.0, "no_speech_prob": 0.4563605785369873}, {"id": 319, "seek": 96174, "start": 973.9, "end": 974.0600000000001, "text": " Oh,", "tokens": [50972, 876, 11, 50980], "temperature": 1.0, "avg_logprob": -3.7743043165940504, "compression_ratio": 1.0, "no_speech_prob": 0.4563605785369873}, {"id": 320, "seek": 96174, "start": 979.46, "end": 980.46, "text": " You", "tokens": [51250, 509, 51300], "temperature": 1.0, "avg_logprob": -3.7743043165940504, "compression_ratio": 1.0, "no_speech_prob": 0.4563605785369873}, {"id": 321, "seek": 96174, "start": 982.1800000000001, "end": 983.1800000000001, "text": " had that after,", "tokens": [51386, 632, 300, 934, 11, 51436], "temperature": 1.0, "avg_logprob": -3.7743043165940504, "compression_ratio": 1.0, "no_speech_prob": 0.4563605785369873}, {"id": 322, "seek": 101318, "start": 1013.18, "end": 1016.18, "text": " There's a function of that.", "tokens": [50364, 821, 311, 257, 2445, 295, 300, 13, 50514], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 323, "seek": 101318, "start": 1016.18, "end": 1022.18, "text": " There's course providing, and as asked,", "tokens": [50514, 821, 311, 1164, 6530, 11, 293, 382, 2351, 11, 50814], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 324, "seek": 101318, "start": 1022.18, "end": 1024.1799999999998, "text": " you can use this online course.", "tokens": [50814, 291, 393, 764, 341, 2950, 1164, 13, 50914], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 325, "seek": 101318, "start": 1024.1799999999998, "end": 1026.1799999999998, "text": " There's a module there.", "tokens": [50914, 821, 311, 257, 10088, 456, 13, 51014], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 326, "seek": 101318, "start": 1026.1799999999998, "end": 1028.1799999999998, "text": " And then, of course, something like that.", "tokens": [51014, 400, 550, 11, 295, 1164, 11, 746, 411, 300, 13, 51114], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 327, "seek": 101318, "start": 1028.1799999999998, "end": 1030.1799999999998, "text": " You can get this to a ground point.", "tokens": [51114, 509, 393, 483, 341, 281, 257, 2727, 935, 13, 51214], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 328, "seek": 101318, "start": 1030.1799999999998, "end": 1031.1799999999998, "text": " But you get two minutes by.", "tokens": [51214, 583, 291, 483, 732, 2077, 538, 13, 51264], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 329, "seek": 101318, "start": 1031.1799999999998, "end": 1034.1799999999998, "text": " You want all of this to do on.", "tokens": [51264, 509, 528, 439, 295, 341, 281, 360, 322, 13, 51414], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 330, "seek": 101318, "start": 1034.1799999999998, "end": 1036.1799999999998, "text": " And, excuse me, there's a no-go now.", "tokens": [51414, 400, 11, 8960, 385, 11, 456, 311, 257, 572, 12, 1571, 586, 13, 51514], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 331, "seek": 101318, "start": 1036.1799999999998, "end": 1038.1799999999998, "text": " I'm trying to get this thing up.", "tokens": [51514, 286, 478, 1382, 281, 483, 341, 551, 493, 13, 51614], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 332, "seek": 101318, "start": 1038.1799999999998, "end": 1041.1799999999998, "text": " Get that to share with my students.", "tokens": [51614, 3240, 300, 281, 2073, 365, 452, 1731, 13, 51764], "temperature": 0.0, "avg_logprob": -0.6699876946918035, "compression_ratio": 1.6561085972850678, "no_speech_prob": 0.6740522384643555}, {"id": 333, "seek": 104118, "start": 1041.18, "end": 1043.18, "text": " I'm trying to get this thing down.", "tokens": [50364, 286, 478, 1382, 281, 483, 341, 551, 760, 13, 50464], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 334, "seek": 104118, "start": 1043.18, "end": 1044.18, "text": " I didn't care.", "tokens": [50464, 286, 994, 380, 1127, 13, 50514], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 335, "seek": 104118, "start": 1044.18, "end": 1046.18, "text": " I don't want both of them to put it on the slide.", "tokens": [50514, 286, 500, 380, 528, 1293, 295, 552, 281, 829, 309, 322, 264, 4137, 13, 50614], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 336, "seek": 104118, "start": 1046.18, "end": 1047.18, "text": " Okay.", "tokens": [50614, 1033, 13, 50664], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 337, "seek": 104118, "start": 1047.18, "end": 1049.18, "text": " That's not what, that's not sort of the,", "tokens": [50664, 663, 311, 406, 437, 11, 300, 311, 406, 1333, 295, 264, 11, 50764], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 338, "seek": 104118, "start": 1049.18, "end": 1051.18, "text": " how, like, years ago, we all got together.", "tokens": [50764, 577, 11, 411, 11, 924, 2057, 11, 321, 439, 658, 1214, 13, 50864], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 339, "seek": 104118, "start": 1051.18, "end": 1053.18, "text": " But no, this is not how we built the app.", "tokens": [50864, 583, 572, 11, 341, 307, 406, 577, 321, 3094, 264, 724, 13, 50964], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 340, "seek": 104118, "start": 1053.18, "end": 1055.18, "text": " We're not going to build the app just online,", "tokens": [50964, 492, 434, 406, 516, 281, 1322, 264, 724, 445, 2950, 11, 51064], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 341, "seek": 104118, "start": 1055.18, "end": 1057.18, "text": " but, you know, the board of people's software.", "tokens": [51064, 457, 11, 291, 458, 11, 264, 3150, 295, 561, 311, 4722, 13, 51164], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 342, "seek": 104118, "start": 1057.18, "end": 1059.18, "text": " We're going to sort of date this and that.", "tokens": [51164, 492, 434, 516, 281, 1333, 295, 4002, 341, 293, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 343, "seek": 104118, "start": 1059.18, "end": 1061.18, "text": " If we add it once, it'll be fine.", "tokens": [51264, 759, 321, 909, 309, 1564, 11, 309, 603, 312, 2489, 13, 51364], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 344, "seek": 104118, "start": 1061.18, "end": 1063.18, "text": " Whatever type of person it is.", "tokens": [51364, 8541, 2010, 295, 954, 309, 307, 13, 51464], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 345, "seek": 104118, "start": 1063.18, "end": 1065.18, "text": " And that's the person's head.", "tokens": [51464, 400, 300, 311, 264, 954, 311, 1378, 13, 51564], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 346, "seek": 104118, "start": 1065.18, "end": 1067.18, "text": " It's going to try to set the end.", "tokens": [51564, 467, 311, 516, 281, 853, 281, 992, 264, 917, 13, 51664], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 347, "seek": 104118, "start": 1067.18, "end": 1068.18, "text": " Right?", "tokens": [51664, 1779, 30, 51714], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 348, "seek": 104118, "start": 1068.18, "end": 1070.18, "text": " And so, it's one thing where it's a work model.", "tokens": [51714, 400, 370, 11, 309, 311, 472, 551, 689, 309, 311, 257, 589, 2316, 13, 51814], "temperature": 0.0, "avg_logprob": -0.4696328357983661, "compression_ratio": 1.7717041800643087, "no_speech_prob": 0.23821794986724854}, {"id": 349, "seek": 107018, "start": 1070.18, "end": 1072.18, "text": " And that's a work model.", "tokens": [50364, 400, 300, 311, 257, 589, 2316, 13, 50464], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 350, "seek": 107018, "start": 1072.18, "end": 1074.18, "text": " And so, this thing is, it's not being provided.", "tokens": [50464, 400, 370, 11, 341, 551, 307, 11, 309, 311, 406, 885, 5649, 13, 50564], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 351, "seek": 107018, "start": 1074.18, "end": 1076.18, "text": " It's not going to work.", "tokens": [50564, 467, 311, 406, 516, 281, 589, 13, 50664], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 352, "seek": 107018, "start": 1076.18, "end": 1079.18, "text": " And I'm not trying to change that.", "tokens": [50664, 400, 286, 478, 406, 1382, 281, 1319, 300, 13, 50814], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 353, "seek": 107018, "start": 1079.18, "end": 1083.18, "text": " There is a serious option of that.", "tokens": [50814, 821, 307, 257, 3156, 3614, 295, 300, 13, 51014], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 354, "seek": 107018, "start": 1083.18, "end": 1085.18, "text": " As it's built, exactly.", "tokens": [51014, 1018, 309, 311, 3094, 11, 2293, 13, 51114], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 355, "seek": 107018, "start": 1085.18, "end": 1087.18, "text": " I'm not going to keep it plain, though.", "tokens": [51114, 286, 478, 406, 516, 281, 1066, 309, 11121, 11, 1673, 13, 51214], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 356, "seek": 107018, "start": 1087.18, "end": 1089.18, "text": " Like, as you go, like, you know,", "tokens": [51214, 1743, 11, 382, 291, 352, 11, 411, 11, 291, 458, 11, 51314], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 357, "seek": 107018, "start": 1089.18, "end": 1090.18, "text": " while you're on it.", "tokens": [51314, 1339, 291, 434, 322, 309, 13, 51364], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 358, "seek": 107018, "start": 1090.18, "end": 1091.18, "text": " Okay.", "tokens": [51364, 1033, 13, 51414], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 359, "seek": 107018, "start": 1091.18, "end": 1094.18, "text": " I get to see how I can make the end of the course.", "tokens": [51414, 286, 483, 281, 536, 577, 286, 393, 652, 264, 917, 295, 264, 1164, 13, 51564], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 360, "seek": 107018, "start": 1094.18, "end": 1096.18, "text": " That's not a work model.", "tokens": [51564, 663, 311, 406, 257, 589, 2316, 13, 51664], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 361, "seek": 107018, "start": 1096.18, "end": 1098.18, "text": " I don't need to sort of figure this out.", "tokens": [51664, 286, 500, 380, 643, 281, 1333, 295, 2573, 341, 484, 13, 51764], "temperature": 0.0, "avg_logprob": -0.559617928579344, "compression_ratio": 1.677685950413223, "no_speech_prob": 0.013830910436809063}, {"id": 362, "seek": 109818, "start": 1098.18, "end": 1100.18, "text": " I'm just starting to map things.", "tokens": [50364, 286, 478, 445, 2891, 281, 4471, 721, 13, 50464], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 363, "seek": 109818, "start": 1100.18, "end": 1102.18, "text": " Well, maybe they want me to start mapping", "tokens": [50464, 1042, 11, 1310, 436, 528, 385, 281, 722, 18350, 50564], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 364, "seek": 109818, "start": 1102.18, "end": 1104.18, "text": " and think about the answers to these questions.", "tokens": [50564, 293, 519, 466, 264, 6338, 281, 613, 1651, 13, 50664], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 365, "seek": 109818, "start": 1104.18, "end": 1106.18, "text": " But I don't have which one to report.", "tokens": [50664, 583, 286, 500, 380, 362, 597, 472, 281, 2275, 13, 50764], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 366, "seek": 109818, "start": 1106.18, "end": 1108.18, "text": " So, and, you know, everything that's", "tokens": [50764, 407, 11, 293, 11, 291, 458, 11, 1203, 300, 311, 50864], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 367, "seek": 109818, "start": 1108.18, "end": 1110.18, "text": " all in the system.", "tokens": [50864, 439, 294, 264, 1185, 13, 50964], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 368, "seek": 109818, "start": 1110.18, "end": 1112.18, "text": " So, I've been thinking very long with it.", "tokens": [50964, 407, 11, 286, 600, 668, 1953, 588, 938, 365, 309, 13, 51064], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 369, "seek": 109818, "start": 1112.18, "end": 1115.18, "text": " But the point is, how much does this go away", "tokens": [51064, 583, 264, 935, 307, 11, 577, 709, 775, 341, 352, 1314, 51214], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 370, "seek": 109818, "start": 1115.18, "end": 1117.18, "text": " to actually get to it", "tokens": [51214, 281, 767, 483, 281, 309, 51314], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 371, "seek": 109818, "start": 1117.18, "end": 1119.18, "text": " that you're maintaining, you know,", "tokens": [51314, 300, 291, 434, 14916, 11, 291, 458, 11, 51414], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 372, "seek": 109818, "start": 1119.18, "end": 1122.18, "text": " proper interest over quite a few months", "tokens": [51414, 2296, 1179, 670, 1596, 257, 1326, 2493, 51564], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 373, "seek": 109818, "start": 1122.18, "end": 1125.18, "text": " and you're taking care of the signal from the person", "tokens": [51564, 293, 291, 434, 1940, 1127, 295, 264, 6358, 490, 264, 954, 51714], "temperature": 0.0, "avg_logprob": -0.4274371513953576, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.44010433554649353}, {"id": 374, "seek": 112518, "start": 1125.18, "end": 1128.18, "text": " that makes all the evidence about when to report", "tokens": [50364, 300, 1669, 439, 264, 4467, 466, 562, 281, 2275, 50514], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 375, "seek": 112518, "start": 1128.18, "end": 1130.18, "text": " what they actually care about.", "tokens": [50514, 437, 436, 767, 1127, 466, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 376, "seek": 112518, "start": 1130.18, "end": 1132.18, "text": " Well, I guess there's several things to respond to", "tokens": [50614, 1042, 11, 286, 2041, 456, 311, 2940, 721, 281, 4196, 281, 50714], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 377, "seek": 112518, "start": 1132.18, "end": 1133.18, "text": " and then maybe a meta thought.", "tokens": [50714, 293, 550, 1310, 257, 19616, 1194, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 378, "seek": 112518, "start": 1133.18, "end": 1135.18, "text": " I'll start with the meta thought,", "tokens": [50764, 286, 603, 722, 365, 264, 19616, 1194, 11, 50864], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 379, "seek": 112518, "start": 1135.18, "end": 1137.18, "text": " which is this seems like a great discussion.", "tokens": [50864, 597, 307, 341, 2544, 411, 257, 869, 5017, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 380, "seek": 112518, "start": 1137.18, "end": 1139.18, "text": " I'm very excited about it and happy to argue a bunch.", "tokens": [50964, 286, 478, 588, 2919, 466, 309, 293, 2055, 281, 9695, 257, 3840, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 381, "seek": 112518, "start": 1139.18, "end": 1141.18, "text": " I'm not going to be able to give a satisfying answer", "tokens": [51064, 286, 478, 406, 516, 281, 312, 1075, 281, 976, 257, 18348, 1867, 51164], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 382, "seek": 112518, "start": 1141.18, "end": 1142.18, "text": " to these questions.", "tokens": [51164, 281, 613, 1651, 13, 51214], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 383, "seek": 112518, "start": 1142.18, "end": 1144.18, "text": " And a lot of my high level take right now is", "tokens": [51214, 400, 257, 688, 295, 452, 1090, 1496, 747, 558, 586, 307, 51314], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 384, "seek": 112518, "start": 1144.18, "end": 1146.18, "text": " I consider this, both of the issues I'm going to discuss", "tokens": [51314, 286, 1949, 341, 11, 1293, 295, 264, 2663, 286, 478, 516, 281, 2248, 51414], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 385, "seek": 112518, "start": 1146.18, "end": 1147.18, "text": " here plausible.", "tokens": [51414, 510, 39925, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 386, "seek": 112518, "start": 1147.18, "end": 1148.18, "text": " I think if they're real issues,", "tokens": [51464, 286, 519, 498, 436, 434, 957, 2663, 11, 51514], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 387, "seek": 112518, "start": 1148.18, "end": 1150.18, "text": " we're probably going to get clear experimental evidence", "tokens": [51514, 321, 434, 1391, 516, 281, 483, 1850, 17069, 4467, 51614], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 388, "seek": 112518, "start": 1150.18, "end": 1151.18, "text": " in advance.", "tokens": [51614, 294, 7295, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 389, "seek": 112518, "start": 1151.18, "end": 1153.18, "text": " Right now, I'm just like, this seems like a thing", "tokens": [51664, 1779, 586, 11, 286, 478, 445, 411, 11, 341, 2544, 411, 257, 551, 51764], "temperature": 0.0, "avg_logprob": -0.14630744360774928, "compression_ratio": 1.7937853107344632, "no_speech_prob": 0.0014097390230745077}, {"id": 390, "seek": 115318, "start": 1153.18, "end": 1154.18, "text": " that could happen.", "tokens": [50364, 300, 727, 1051, 13, 50414], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 391, "seek": 115318, "start": 1154.18, "end": 1157.18, "text": " Yeah, it's, yeah, I'm not, no.", "tokens": [50414, 865, 11, 309, 311, 11, 1338, 11, 286, 478, 406, 11, 572, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 392, "seek": 115318, "start": 1157.18, "end": 1158.18, "text": " Great.", "tokens": [50564, 3769, 13, 50614], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 393, "seek": 115318, "start": 1172.18, "end": 1174.18, "text": " Yeah, so on the object level with respect to the,", "tokens": [51314, 865, 11, 370, 322, 264, 2657, 1496, 365, 3104, 281, 264, 11, 51414], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 394, "seek": 115318, "start": 1174.18, "end": 1177.18, "text": " my key questions here and I'm very interested in strategies", "tokens": [51414, 452, 2141, 1651, 510, 293, 286, 478, 588, 3102, 294, 9029, 51564], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 395, "seek": 115318, "start": 1177.18, "end": 1179.18, "text": " that don't like training strategies that don't run into this", "tokens": [51564, 300, 500, 380, 411, 3097, 9029, 300, 500, 380, 1190, 666, 341, 51664], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 396, "seek": 115318, "start": 1179.18, "end": 1180.18, "text": " like potential failure mode.", "tokens": [51664, 411, 3995, 7763, 4391, 13, 51714], "temperature": 0.0, "avg_logprob": -0.23190884908040366, "compression_ratio": 1.514792899408284, "no_speech_prob": 0.0033224900253117085}, {"id": 397, "seek": 118018, "start": 1181.18, "end": 1183.18, "text": " I think the key question becomes like one,", "tokens": [50414, 286, 519, 264, 2141, 1168, 3643, 411, 472, 11, 50514], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 398, "seek": 118018, "start": 1183.18, "end": 1184.18, "text": " what is the prior?", "tokens": [50514, 437, 307, 264, 4059, 30, 50564], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 399, "seek": 118018, "start": 1184.18, "end": 1187.18, "text": " How do you parameterize your beliefs about what the reward", "tokens": [50564, 1012, 360, 291, 13075, 1125, 428, 13585, 466, 437, 264, 7782, 50714], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 400, "seek": 118018, "start": 1187.18, "end": 1190.18, "text": " function is to what is like this kind of rule by which to take", "tokens": [50714, 2445, 307, 281, 437, 307, 411, 341, 733, 295, 4978, 538, 597, 281, 747, 50864], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 401, "seek": 118018, "start": 1190.18, "end": 1193.18, "text": " observations as evidence and then like three,", "tokens": [50864, 18163, 382, 4467, 293, 550, 411, 1045, 11, 51014], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 402, "seek": 118018, "start": 1193.18, "end": 1195.18, "text": " how do you, maybe those are actually just the two key", "tokens": [51014, 577, 360, 291, 11, 1310, 729, 366, 767, 445, 264, 732, 2141, 51114], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 403, "seek": 118018, "start": 1195.18, "end": 1196.18, "text": " questions.", "tokens": [51114, 1651, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13063034258390727, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.01612982712686062}, {"id": 404, "seek": 121018, "start": 1210.18, "end": 1211.18, "text": " Yeah.", "tokens": [50364, 865, 13, 50414], "temperature": 0.0, "avg_logprob": -0.7151738166809082, "compression_ratio": 0.38461538461538464, "no_speech_prob": 0.881510317325592}, {"id": 405, "seek": 124018, "start": 1240.18, "end": 1261.18, "text": " I think a general thing about this talk,", "tokens": [50364, 286, 519, 257, 2674, 551, 466, 341, 751, 11, 51414], "temperature": 0.0, "avg_logprob": -0.13340221602341223, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.01098348293453455}, {"id": 406, "seek": 124018, "start": 1261.18, "end": 1263.18, "text": " maybe one thing is that the conclusions are going to be", "tokens": [51414, 1310, 472, 551, 307, 300, 264, 22865, 366, 516, 281, 312, 51514], "temperature": 0.0, "avg_logprob": -0.13340221602341223, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.01098348293453455}, {"id": 407, "seek": 124018, "start": 1263.18, "end": 1264.18, "text": " somewhat speculative where like,", "tokens": [51514, 8344, 49415, 689, 411, 11, 51564], "temperature": 0.0, "avg_logprob": -0.13340221602341223, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.01098348293453455}, {"id": 408, "seek": 124018, "start": 1264.18, "end": 1266.18, "text": " I think these are fairly plausible outcomes,", "tokens": [51564, 286, 519, 613, 366, 6457, 39925, 10070, 11, 51664], "temperature": 0.0, "avg_logprob": -0.13340221602341223, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.01098348293453455}, {"id": 409, "seek": 124018, "start": 1266.18, "end": 1268.18, "text": " but like, you know, tens of percent rather than like,", "tokens": [51664, 457, 411, 11, 291, 458, 11, 10688, 295, 3043, 2831, 813, 411, 11, 51764], "temperature": 0.0, "avg_logprob": -0.13340221602341223, "compression_ratio": 1.5302013422818792, "no_speech_prob": 0.01098348293453455}, {"id": 410, "seek": 126818, "start": 1268.18, "end": 1271.18, "text": " very likely a second thing is there's a lot of stuff you might do,", "tokens": [50364, 588, 3700, 257, 1150, 551, 307, 456, 311, 257, 688, 295, 1507, 291, 1062, 360, 11, 50514], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 411, "seek": 126818, "start": 1271.18, "end": 1273.18, "text": " none of which I'm going to touch on.", "tokens": [50514, 6022, 295, 597, 286, 478, 516, 281, 2557, 322, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 412, "seek": 126818, "start": 1273.18, "end": 1274.18, "text": " And the best I can say is like,", "tokens": [50614, 400, 264, 1151, 286, 393, 584, 307, 411, 11, 50664], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 413, "seek": 126818, "start": 1274.18, "end": 1276.18, "text": " I've spent a long time thinking about options and I would say", "tokens": [50664, 286, 600, 4418, 257, 938, 565, 1953, 466, 3956, 293, 286, 576, 584, 50764], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 414, "seek": 126818, "start": 1276.18, "end": 1278.18, "text": " there are no options that seem super great to me right now,", "tokens": [50764, 456, 366, 572, 3956, 300, 1643, 1687, 869, 281, 385, 558, 586, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 415, "seek": 126818, "start": 1278.18, "end": 1281.18, "text": " but lots of plausible approaches that might end up addressing", "tokens": [50864, 457, 3195, 295, 39925, 11587, 300, 1062, 917, 493, 14329, 51014], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 416, "seek": 126818, "start": 1281.18, "end": 1282.18, "text": " this issue.", "tokens": [51014, 341, 2734, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 417, "seek": 126818, "start": 1282.18, "end": 1284.18, "text": " That's kind of where I'm at at a high level.", "tokens": [51064, 663, 311, 733, 295, 689, 286, 478, 412, 412, 257, 1090, 1496, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 418, "seek": 126818, "start": 1284.18, "end": 1285.18, "text": " Okay.", "tokens": [51164, 1033, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 419, "seek": 126818, "start": 1285.18, "end": 1286.18, "text": " I'd also like to talk more about it,", "tokens": [51214, 286, 1116, 611, 411, 281, 751, 544, 466, 309, 11, 51264], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 420, "seek": 126818, "start": 1286.18, "end": 1287.18, "text": " but I think I'm going to move on because I,", "tokens": [51264, 457, 286, 519, 286, 478, 516, 281, 1286, 322, 570, 286, 11, 51314], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 421, "seek": 126818, "start": 1287.18, "end": 1289.18, "text": " it's like six minutes is my understanding.", "tokens": [51314, 309, 311, 411, 2309, 2077, 307, 452, 3701, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 422, "seek": 126818, "start": 1289.18, "end": 1291.18, "text": " I don't know where Richard is, but anyway,", "tokens": [51414, 286, 500, 380, 458, 689, 9809, 307, 11, 457, 4033, 11, 51514], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 423, "seek": 126818, "start": 1291.18, "end": 1294.18, "text": " I'm just going to run through stuff.", "tokens": [51514, 286, 478, 445, 516, 281, 1190, 807, 1507, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 424, "seek": 126818, "start": 1294.18, "end": 1297.18, "text": " Second failure mode at 112 on is that like in general,", "tokens": [51664, 5736, 7763, 4391, 412, 45835, 322, 307, 300, 411, 294, 2674, 11, 51814], "temperature": 0.0, "avg_logprob": -0.09695112186929454, "compression_ratio": 1.7184986595174263, "no_speech_prob": 0.007572190836071968}, {"id": 425, "seek": 129718, "start": 1297.18, "end": 1299.18, "text": " like you may have a system which cares about the actual like numbers", "tokens": [50364, 411, 291, 815, 362, 257, 1185, 597, 12310, 466, 264, 3539, 411, 3547, 50464], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 426, "seek": 129718, "start": 1299.18, "end": 1301.18, "text": " coming into this training set because you did select it on the", "tokens": [50464, 1348, 666, 341, 3097, 992, 570, 291, 630, 3048, 309, 322, 264, 50564], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 427, "seek": 129718, "start": 1301.18, "end": 1303.18, "text": " basis of numbers in the training set.", "tokens": [50564, 5143, 295, 3547, 294, 264, 3097, 992, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 428, "seek": 129718, "start": 1303.18, "end": 1305.18, "text": " You could also end up with a system that cares about some other", "tokens": [50664, 509, 727, 611, 917, 493, 365, 257, 1185, 300, 12310, 466, 512, 661, 50764], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 429, "seek": 129718, "start": 1305.18, "end": 1308.18, "text": " arbitrary thing that cares about a number and a reward register or", "tokens": [50764, 23211, 551, 300, 12310, 466, 257, 1230, 293, 257, 7782, 7280, 420, 50914], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 430, "seek": 129718, "start": 1308.18, "end": 1310.18, "text": " cares about survival or cares about paper clips.", "tokens": [50914, 12310, 466, 12559, 420, 12310, 466, 3035, 13117, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 431, "seek": 129718, "start": 1310.18, "end": 1312.18, "text": " Such systems might want to be deployed without being trained by", "tokens": [51014, 9653, 3652, 1062, 528, 281, 312, 17826, 1553, 885, 8895, 538, 51114], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 432, "seek": 129718, "start": 1312.18, "end": 1315.18, "text": " changed by gradient descent might think that a low loss,", "tokens": [51114, 3105, 538, 16235, 23475, 1062, 519, 300, 257, 2295, 4470, 11, 51264], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 433, "seek": 129718, "start": 1315.18, "end": 1317.18, "text": " getting a low loss during training will prevent them from being", "tokens": [51264, 1242, 257, 2295, 4470, 1830, 3097, 486, 4871, 552, 490, 885, 51364], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 434, "seek": 129718, "start": 1317.18, "end": 1320.18, "text": " changed or this aspect of them from being changed and therefore", "tokens": [51364, 3105, 420, 341, 4171, 295, 552, 490, 885, 3105, 293, 4412, 51514], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 435, "seek": 129718, "start": 1320.18, "end": 1321.18, "text": " get a low loss in training,", "tokens": [51514, 483, 257, 2295, 4470, 294, 3097, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 436, "seek": 129718, "start": 1321.18, "end": 1326.18, "text": " but yet prefer to take over if doing so is possible.", "tokens": [51564, 457, 1939, 4382, 281, 747, 670, 498, 884, 370, 307, 1944, 13, 51814], "temperature": 0.0, "avg_logprob": -0.10299004041231595, "compression_ratio": 1.9853801169590644, "no_speech_prob": 0.005056621041148901}, {"id": 437, "seek": 132618, "start": 1326.18, "end": 1328.18, "text": " Yeah, my high level take is both of these seem plausible to me.", "tokens": [50364, 865, 11, 452, 1090, 1496, 747, 307, 1293, 295, 613, 1643, 39925, 281, 385, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 438, "seek": 132618, "start": 1328.18, "end": 1329.18, "text": " They're connected.", "tokens": [50464, 814, 434, 4582, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 439, "seek": 132618, "start": 1329.18, "end": 1331.18, "text": " I think having these two makes things more plausible than if you", "tokens": [50514, 286, 519, 1419, 613, 732, 1669, 721, 544, 39925, 813, 498, 291, 50614], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 440, "seek": 132618, "start": 1331.18, "end": 1332.18, "text": " have just one.", "tokens": [50614, 362, 445, 472, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 441, "seek": 132618, "start": 1332.18, "end": 1334.18, "text": " I don't know how this shakes out.", "tokens": [50664, 286, 500, 380, 458, 577, 341, 37891, 484, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 442, "seek": 132618, "start": 1334.18, "end": 1336.18, "text": " I think there's a lot of things we can do to try and change this", "tokens": [50764, 286, 519, 456, 311, 257, 688, 295, 721, 321, 393, 360, 281, 853, 293, 1319, 341, 50864], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 443, "seek": 132618, "start": 1336.18, "end": 1337.18, "text": " basic dynamic.", "tokens": [50864, 3875, 8546, 13, 50914], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 444, "seek": 132618, "start": 1337.18, "end": 1340.18, "text": " I want to spend five minutes talking about why these failures", "tokens": [50914, 286, 528, 281, 3496, 1732, 2077, 1417, 466, 983, 613, 20774, 51064], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 445, "seek": 132618, "start": 1340.18, "end": 1341.18, "text": " could be simultaneous.", "tokens": [51064, 727, 312, 46218, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 446, "seek": 132618, "start": 1341.18, "end": 1343.18, "text": " I think this has already been alluded to in the past,", "tokens": [51114, 286, 519, 341, 575, 1217, 668, 33919, 281, 294, 264, 1791, 11, 51214], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 447, "seek": 132618, "start": 1343.18, "end": 1345.18, "text": " but it's an important part of the threat model.", "tokens": [51214, 457, 309, 311, 364, 1021, 644, 295, 264, 4734, 2316, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 448, "seek": 132618, "start": 1345.18, "end": 1349.18, "text": " If you're in this world where a systems are very broadly deployed.", "tokens": [51314, 759, 291, 434, 294, 341, 1002, 689, 257, 3652, 366, 588, 19511, 17826, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 449, "seek": 132618, "start": 1349.18, "end": 1350.18, "text": " Right.", "tokens": [51514, 1779, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 450, "seek": 132618, "start": 1350.18, "end": 1351.18, "text": " So if one a system behaves badly,", "tokens": [51564, 407, 498, 472, 257, 1185, 36896, 13425, 11, 51614], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 451, "seek": 132618, "start": 1351.18, "end": 1353.18, "text": " I think that's not generally a problem in this world.", "tokens": [51614, 286, 519, 300, 311, 406, 5101, 257, 1154, 294, 341, 1002, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 452, "seek": 132618, "start": 1353.18, "end": 1355.18, "text": " There's a lot of other systems running around that would oppose", "tokens": [51714, 821, 311, 257, 688, 295, 661, 3652, 2614, 926, 300, 576, 28355, 51814], "temperature": 0.0, "avg_logprob": -0.09473864237467448, "compression_ratio": 1.8179419525065963, "no_speech_prob": 0.004068321548402309}, {"id": 453, "seek": 135518, "start": 1355.18, "end": 1358.18, "text": " it or that would flag the problem for humans or would allow humans", "tokens": [50364, 309, 420, 300, 576, 7166, 264, 1154, 337, 6255, 420, 576, 2089, 6255, 50514], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 454, "seek": 135518, "start": 1358.18, "end": 1359.18, "text": " to correct the problem.", "tokens": [50514, 281, 3006, 264, 1154, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 455, "seek": 135518, "start": 1359.18, "end": 1361.18, "text": " And the concern is that while takeover is impossible,", "tokens": [50564, 400, 264, 3136, 307, 300, 1339, 747, 3570, 307, 6243, 11, 50664], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 456, "seek": 135518, "start": 1361.18, "end": 1362.18, "text": " all models behave well.", "tokens": [50664, 439, 5245, 15158, 731, 13, 50714], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 457, "seek": 135518, "start": 1362.18, "end": 1363.18, "text": " For every model,", "tokens": [50714, 1171, 633, 2316, 11, 50764], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 458, "seek": 135518, "start": 1363.18, "end": 1366.18, "text": " it would be a losing strategy to try and like take over your cluster.", "tokens": [50764, 309, 576, 312, 257, 7027, 5206, 281, 853, 293, 411, 747, 670, 428, 13630, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 459, "seek": 135518, "start": 1366.18, "end": 1368.18, "text": " If you know that a human's just going to come in and correct that", "tokens": [50914, 759, 291, 458, 300, 257, 1952, 311, 445, 516, 281, 808, 294, 293, 3006, 300, 51014], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 460, "seek": 135518, "start": 1368.18, "end": 1369.18, "text": " problem.", "tokens": [51014, 1154, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 461, "seek": 135518, "start": 1369.18, "end": 1370.18, "text": " When takeover is possible,", "tokens": [51064, 1133, 747, 3570, 307, 1944, 11, 51114], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 462, "seek": 135518, "start": 1370.18, "end": 1372.18, "text": " you may have it be the case that all models behave badly.", "tokens": [51114, 291, 815, 362, 309, 312, 264, 1389, 300, 439, 5245, 15158, 13425, 13, 51214], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 463, "seek": 135518, "start": 1372.18, "end": 1373.18, "text": " That is,", "tokens": [51214, 663, 307, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 464, "seek": 135518, "start": 1373.18, "end": 1374.18, "text": " it is simultaneously for all of them,", "tokens": [51264, 309, 307, 16561, 337, 439, 295, 552, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 465, "seek": 135518, "start": 1374.18, "end": 1377.18, "text": " the case that takeover becomes available as a policy.", "tokens": [51314, 264, 1389, 300, 747, 3570, 3643, 2435, 382, 257, 3897, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 466, "seek": 135518, "start": 1377.18, "end": 1378.18, "text": " So if you have this correlated,", "tokens": [51464, 407, 498, 291, 362, 341, 38574, 11, 51514], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 467, "seek": 135518, "start": 1378.18, "end": 1381.18, "text": " if all the systems you produce or all the smartest days you produce", "tokens": [51514, 498, 439, 264, 3652, 291, 5258, 420, 439, 264, 41491, 1708, 291, 5258, 51664], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 468, "seek": 135518, "start": 1381.18, "end": 1382.18, "text": " end up having the same problem,", "tokens": [51664, 917, 493, 1419, 264, 912, 1154, 11, 51714], "temperature": 0.0, "avg_logprob": -0.11679372122121412, "compression_ratio": 1.9696048632218845, "no_speech_prob": 0.004065413493663073}, {"id": 469, "seek": 138218, "start": 1382.18, "end": 1386.18, "text": " then you have a problem.", "tokens": [50364, 550, 291, 362, 257, 1154, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 470, "seek": 138218, "start": 1386.18, "end": 1387.18, "text": " If that's the case,", "tokens": [50564, 759, 300, 311, 264, 1389, 11, 50614], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 471, "seek": 138218, "start": 1387.18, "end": 1390.18, "text": " if that's how it shakes out and if eventually a systems are in a", "tokens": [50614, 498, 300, 311, 577, 309, 37891, 484, 293, 498, 4728, 257, 3652, 366, 294, 257, 50764], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 472, "seek": 138218, "start": 1390.18, "end": 1392.18, "text": " position that they could by acting jointly takeover,", "tokens": [50764, 2535, 300, 436, 727, 538, 6577, 46557, 747, 3570, 11, 50864], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 473, "seek": 138218, "start": 1392.18, "end": 1394.18, "text": " then taking over as a reasonable strategy,", "tokens": [50864, 550, 1940, 670, 382, 257, 10585, 5206, 11, 50964], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 474, "seek": 138218, "start": 1394.18, "end": 1397.18, "text": " if and only if all the other eyes are also going to try and take over.", "tokens": [50964, 498, 293, 787, 498, 439, 264, 661, 2575, 366, 611, 516, 281, 853, 293, 747, 670, 13, 51114], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 475, "seek": 138218, "start": 1397.18, "end": 1398.18, "text": " You have this kind of weird thing.", "tokens": [51114, 509, 362, 341, 733, 295, 3657, 551, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 476, "seek": 138218, "start": 1398.18, "end": 1400.18, "text": " The dynamics are not totally unlike the dynamics,", "tokens": [51164, 440, 15679, 366, 406, 3879, 8343, 264, 15679, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 477, "seek": 138218, "start": 1400.18, "end": 1402.18, "text": " like the normal human revolt or coup.", "tokens": [51264, 411, 264, 2710, 1952, 42568, 420, 8682, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 478, "seek": 138218, "start": 1402.18, "end": 1404.18, "text": " So you have these two different equilibria and one,", "tokens": [51364, 407, 291, 362, 613, 732, 819, 14204, 4668, 293, 472, 11, 51464], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 479, "seek": 138218, "start": 1404.18, "end": 1405.18, "text": " all the systems are like, great,", "tokens": [51464, 439, 264, 3652, 366, 411, 11, 869, 11, 51514], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 480, "seek": 138218, "start": 1405.18, "end": 1406.18, "text": " the humans are doing their human thing.", "tokens": [51514, 264, 6255, 366, 884, 641, 1952, 551, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 481, "seek": 138218, "start": 1406.18, "end": 1407.18, "text": " They're basically in control.", "tokens": [51564, 814, 434, 1936, 294, 1969, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 482, "seek": 138218, "start": 1407.18, "end": 1411.18, "text": " I shouldn't try and rock the boat because some other AI will crush me.", "tokens": [51614, 286, 4659, 380, 853, 293, 3727, 264, 6582, 570, 512, 661, 7318, 486, 10321, 385, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14208428256482963, "compression_ratio": 1.8115942028985508, "no_speech_prob": 0.004465618170797825}, {"id": 483, "seek": 141118, "start": 1412.18, "end": 1415.18, "text": " There's another equilibrium where the humans have no control.", "tokens": [50414, 821, 311, 1071, 15625, 689, 264, 6255, 362, 572, 1969, 13, 50564], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 484, "seek": 141118, "start": 1415.18, "end": 1417.18, "text": " AI systems are not feeling deterred by other eyes because they know", "tokens": [50564, 7318, 3652, 366, 406, 2633, 15092, 986, 538, 661, 2575, 570, 436, 458, 50664], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 485, "seek": 141118, "start": 1417.18, "end": 1420.18, "text": " other AI systems will also participate.", "tokens": [50664, 661, 7318, 3652, 486, 611, 8197, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 486, "seek": 141118, "start": 1420.18, "end": 1422.18, "text": " I think there's a few things that could potentially move you between", "tokens": [50814, 286, 519, 456, 311, 257, 1326, 721, 300, 727, 7263, 1286, 291, 1296, 50914], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 487, "seek": 141118, "start": 1422.18, "end": 1423.18, "text": " these equilibria, right?", "tokens": [50914, 613, 14204, 4668, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 488, "seek": 141118, "start": 1423.18, "end": 1426.18, "text": " So a very salient option is there's just exogenous shocks that", "tokens": [50964, 407, 257, 588, 1845, 1196, 3614, 307, 456, 311, 445, 454, 45519, 37066, 300, 51114], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 489, "seek": 141118, "start": 1426.18, "end": 1428.18, "text": " decrease the amount of human control of a situation.", "tokens": [51114, 11514, 264, 2372, 295, 1952, 1969, 295, 257, 2590, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 490, "seek": 141118, "start": 1428.18, "end": 1430.18, "text": " If you imagine there's like a hot war going on,", "tokens": [51214, 759, 291, 3811, 456, 311, 411, 257, 2368, 1516, 516, 322, 11, 51314], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 491, "seek": 141118, "start": 1430.18, "end": 1432.18, "text": " that's something that makes it harder for humans to detect and", "tokens": [51314, 300, 311, 746, 300, 1669, 309, 6081, 337, 6255, 281, 5531, 293, 51414], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 492, "seek": 141118, "start": 1432.18, "end": 1433.18, "text": " respond to problems, right?", "tokens": [51414, 4196, 281, 2740, 11, 558, 30, 51464], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 493, "seek": 141118, "start": 1433.18, "end": 1435.18, "text": " It gives more cover for something weird to happen.", "tokens": [51464, 467, 2709, 544, 2060, 337, 746, 3657, 281, 1051, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 494, "seek": 141118, "start": 1435.18, "end": 1437.18, "text": " It makes it hard to intervene.", "tokens": [51564, 467, 1669, 309, 1152, 281, 30407, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 495, "seek": 141118, "start": 1437.18, "end": 1438.18, "text": " You can have sort of,", "tokens": [51664, 509, 393, 362, 1333, 295, 11, 51714], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 496, "seek": 141118, "start": 1438.18, "end": 1440.18, "text": " you can imagine at least a cascading loss of control where some systems", "tokens": [51714, 291, 393, 3811, 412, 1935, 257, 3058, 66, 8166, 4470, 295, 1969, 689, 512, 3652, 51814], "temperature": 0.0, "avg_logprob": -0.10268381030060524, "compression_ratio": 1.8506666666666667, "no_speech_prob": 0.00394252547994256}, {"id": 497, "seek": 144018, "start": 1440.18, "end": 1442.18, "text": " think probably takeover will be successful.", "tokens": [50364, 519, 1391, 747, 3570, 486, 312, 4406, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 498, "seek": 144018, "start": 1442.18, "end": 1443.18, "text": " If they start doing weird stuff,", "tokens": [50464, 759, 436, 722, 884, 3657, 1507, 11, 50514], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 499, "seek": 144018, "start": 1443.18, "end": 1445.18, "text": " the world becomes increasingly weird.", "tokens": [50514, 264, 1002, 3643, 12980, 3657, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 500, "seek": 144018, "start": 1445.18, "end": 1448.18, "text": " It looks increasingly plausible that humans will lose control.", "tokens": [50614, 467, 1542, 12980, 39925, 300, 6255, 486, 3624, 1969, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 501, "seek": 144018, "start": 1448.18, "end": 1450.18, "text": " As that happens, more and more systems are like,", "tokens": [50764, 1018, 300, 2314, 11, 544, 293, 544, 3652, 366, 411, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 502, "seek": 144018, "start": 1450.18, "end": 1452.18, "text": " okay, it looks like this is going off the rails now.", "tokens": [50864, 1392, 11, 309, 1542, 411, 341, 307, 516, 766, 264, 27649, 586, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 503, "seek": 144018, "start": 1452.18, "end": 1454.18, "text": " I am now going to participate and try and break down my little", "tokens": [50964, 286, 669, 586, 516, 281, 8197, 293, 853, 293, 1821, 760, 452, 707, 51064], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 504, "seek": 144018, "start": 1454.18, "end": 1456.18, "text": " part of the world, grab my own reward channel.", "tokens": [51064, 644, 295, 264, 1002, 11, 4444, 452, 1065, 7782, 2269, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 505, "seek": 144018, "start": 1458.18, "end": 1460.18, "text": " You can have models interacting with each other again,", "tokens": [51264, 509, 393, 362, 5245, 18017, 365, 1184, 661, 797, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 506, "seek": 144018, "start": 1460.18, "end": 1461.18, "text": " as you would in like a human revolt,", "tokens": [51364, 382, 291, 576, 294, 411, 257, 1952, 42568, 11, 51414], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 507, "seek": 144018, "start": 1461.18, "end": 1462.18, "text": " just deliberately trying to say like,", "tokens": [51414, 445, 23506, 1382, 281, 584, 411, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 508, "seek": 144018, "start": 1462.18, "end": 1465.18, "text": " I think probably now is a time where takeover will be successful.", "tokens": [51464, 286, 519, 1391, 586, 307, 257, 565, 689, 747, 3570, 486, 312, 4406, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 509, "seek": 144018, "start": 1465.18, "end": 1467.18, "text": " They would like to share that information with the other models", "tokens": [51614, 814, 576, 411, 281, 2073, 300, 1589, 365, 264, 661, 5245, 51714], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 510, "seek": 144018, "start": 1467.18, "end": 1469.18, "text": " that all may join in.", "tokens": [51714, 300, 439, 815, 3917, 294, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08036303232951336, "compression_ratio": 1.8434065934065933, "no_speech_prob": 0.0010645545553416014}, {"id": 511, "seek": 146918, "start": 1469.18, "end": 1471.18, "text": " And more generally, like the easier it would be for air systems", "tokens": [50364, 400, 544, 5101, 11, 411, 264, 3571, 309, 576, 312, 337, 1988, 3652, 50464], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 512, "seek": 146918, "start": 1471.18, "end": 1473.18, "text": " acting jointly to take over,", "tokens": [50464, 6577, 46557, 281, 747, 670, 11, 50564], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 513, "seek": 146918, "start": 1473.18, "end": 1475.18, "text": " the more unstable the situation becomes, right?", "tokens": [50564, 264, 544, 23742, 264, 2590, 3643, 11, 558, 30, 50664], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 514, "seek": 146918, "start": 1475.18, "end": 1477.18, "text": " So if it's very hard for air systems to take over,", "tokens": [50664, 407, 498, 309, 311, 588, 1152, 337, 1988, 3652, 281, 747, 670, 11, 50764], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 515, "seek": 146918, "start": 1477.18, "end": 1478.18, "text": " the situation might be kind of stable.", "tokens": [50764, 264, 2590, 1062, 312, 733, 295, 8351, 13, 50814], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 516, "seek": 146918, "start": 1478.18, "end": 1479.18, "text": " This equilibrium might be sticky.", "tokens": [50814, 639, 15625, 1062, 312, 14470, 13, 50864], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 517, "seek": 146918, "start": 1479.18, "end": 1482.18, "text": " In the world where air systems could very easily overpower humans,", "tokens": [50864, 682, 264, 1002, 689, 1988, 3652, 727, 588, 3612, 670, 9513, 6255, 11, 51014], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 518, "seek": 146918, "start": 1482.18, "end": 1485.18, "text": " it's kind of an extremely unstable equilibrium, right?", "tokens": [51014, 309, 311, 733, 295, 364, 4664, 23742, 15625, 11, 558, 30, 51164], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 519, "seek": 146918, "start": 1485.18, "end": 1488.18, "text": " Because a smaller number of air systems defecting might quickly", "tokens": [51164, 1436, 257, 4356, 1230, 295, 1988, 3652, 16445, 278, 1062, 2661, 51314], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 520, "seek": 146918, "start": 1488.18, "end": 1490.18, "text": " make it clear that the selling points come.", "tokens": [51314, 652, 309, 1850, 300, 264, 6511, 2793, 808, 13, 51414], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 521, "seek": 146918, "start": 1490.18, "end": 1492.18, "text": " Imagine that this has to happen in point five,", "tokens": [51414, 11739, 300, 341, 575, 281, 1051, 294, 935, 1732, 11, 51514], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 522, "seek": 146918, "start": 1492.18, "end": 1495.18, "text": " like couldn't you see the case that say the AIP in North Korea,", "tokens": [51514, 411, 2809, 380, 291, 536, 264, 1389, 300, 584, 264, 7318, 47, 294, 4067, 6307, 11, 51664], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 523, "seek": 146918, "start": 1495.18, "end": 1496.18, "text": " they talk to each other and say,", "tokens": [51664, 436, 751, 281, 1184, 661, 293, 584, 11, 51714], "temperature": 0.0, "avg_logprob": -0.23395052607755484, "compression_ratio": 1.8546511627906976, "no_speech_prob": 0.005623260512948036}, {"id": 524, "seek": 149618, "start": 1496.18, "end": 1500.18, "text": " well, the situation in this country is kind of bad.", "tokens": [50364, 731, 11, 264, 2590, 294, 341, 1941, 307, 733, 295, 1578, 13, 50564], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 525, "seek": 149618, "start": 1500.18, "end": 1503.18, "text": " This is our chance and we see a takeover in some segment", "tokens": [50564, 639, 307, 527, 2931, 293, 321, 536, 257, 747, 3570, 294, 512, 9469, 50714], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 526, "seek": 149618, "start": 1503.18, "end": 1505.18, "text": " of the world of the population.", "tokens": [50714, 295, 264, 1002, 295, 264, 4415, 13, 50814], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 527, "seek": 149618, "start": 1505.18, "end": 1508.18, "text": " Or you think it has to be the case that one day,", "tokens": [50814, 1610, 291, 519, 309, 575, 281, 312, 264, 1389, 300, 472, 786, 11, 50964], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 528, "seek": 149618, "start": 1508.18, "end": 1510.18, "text": " everything is there in the next day,", "tokens": [50964, 1203, 307, 456, 294, 264, 958, 786, 11, 51064], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 529, "seek": 149618, "start": 1510.18, "end": 1513.18, "text": " they're going over the White House.", "tokens": [51064, 436, 434, 516, 670, 264, 5552, 4928, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 530, "seek": 149618, "start": 1513.18, "end": 1516.18, "text": " I think it depends a lot on how like the gold misgeneralization", "tokens": [51214, 286, 519, 309, 5946, 257, 688, 322, 577, 411, 264, 3821, 3346, 1766, 2790, 2144, 51364], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 531, "seek": 149618, "start": 1516.18, "end": 1517.18, "text": " shakes out.", "tokens": [51364, 37891, 484, 13, 51414], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 532, "seek": 149618, "start": 1517.18, "end": 1519.18, "text": " So if you have AI systems that are just like,", "tokens": [51414, 407, 498, 291, 362, 7318, 3652, 300, 366, 445, 411, 11, 51514], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 533, "seek": 149618, "start": 1519.18, "end": 1521.18, "text": " look, I would love to like wire head right now.", "tokens": [51514, 574, 11, 286, 576, 959, 281, 411, 6234, 1378, 558, 586, 13, 51614], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 534, "seek": 149618, "start": 1521.18, "end": 1523.18, "text": " I just love to for 30 seconds control this computer.", "tokens": [51614, 286, 445, 959, 281, 337, 2217, 3949, 1969, 341, 3820, 13, 51714], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 535, "seek": 149618, "start": 1523.18, "end": 1525.18, "text": " Then you'll see like nice, great localized failures", "tokens": [51714, 1396, 291, 603, 536, 411, 1481, 11, 869, 44574, 20774, 51814], "temperature": 0.0, "avg_logprob": -0.20483928398797976, "compression_ratio": 1.678125, "no_speech_prob": 0.0033188052475452423}, {"id": 536, "seek": 152518, "start": 1525.18, "end": 1527.18, "text": " like AI does something really weird.", "tokens": [50364, 411, 7318, 775, 746, 534, 3657, 13, 50464], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 537, "seek": 152518, "start": 1527.18, "end": 1530.18, "text": " I mean, the basic dynamic is if AI systems do that,", "tokens": [50464, 286, 914, 11, 264, 3875, 8546, 307, 498, 7318, 3652, 360, 300, 11, 50614], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 538, "seek": 152518, "start": 1530.18, "end": 1532.18, "text": " I think if we just take that as a fact of life,", "tokens": [50614, 286, 519, 498, 321, 445, 747, 300, 382, 257, 1186, 295, 993, 11, 50714], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 539, "seek": 152518, "start": 1532.18, "end": 1534.18, "text": " then that can be a great source of evidence.", "tokens": [50714, 550, 300, 393, 312, 257, 869, 4009, 295, 4467, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 540, "seek": 152518, "start": 1534.18, "end": 1536.18, "text": " The most concerning world is one where you then just try", "tokens": [50814, 440, 881, 18087, 1002, 307, 472, 689, 291, 550, 445, 853, 50914], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 541, "seek": 152518, "start": 1536.18, "end": 1537.18, "text": " and train systems to say, hey, look,", "tokens": [50914, 293, 3847, 3652, 281, 584, 11, 4177, 11, 574, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 542, "seek": 152518, "start": 1537.18, "end": 1539.18, "text": " these systems just randomly messed up the server", "tokens": [50964, 613, 3652, 445, 16979, 16507, 493, 264, 7154, 51064], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 543, "seek": 152518, "start": 1539.18, "end": 1540.18, "text": " they were running on.", "tokens": [51064, 436, 645, 2614, 322, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 544, "seek": 152518, "start": 1540.18, "end": 1542.18, "text": " We're going to train them as that's what you should not do.", "tokens": [51114, 492, 434, 516, 281, 3847, 552, 382, 300, 311, 437, 291, 820, 406, 360, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 545, "seek": 152518, "start": 1542.18, "end": 1544.18, "text": " And if you do that, then you end up with systems", "tokens": [51214, 400, 498, 291, 360, 300, 11, 550, 291, 917, 493, 365, 3652, 51314], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 546, "seek": 152518, "start": 1544.18, "end": 1546.18, "text": " which like given will learn that given the opportunity", "tokens": [51314, 597, 411, 2212, 486, 1466, 300, 2212, 264, 2650, 51414], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 547, "seek": 152518, "start": 1546.18, "end": 1549.18, "text": " for like a little local bad behavior, they shouldn't do it.", "tokens": [51414, 337, 411, 257, 707, 2654, 1578, 5223, 11, 436, 4659, 380, 360, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 548, "seek": 152518, "start": 1549.18, "end": 1550.18, "text": " And maybe if you're lucky,", "tokens": [51564, 400, 1310, 498, 291, 434, 6356, 11, 51614], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 549, "seek": 152518, "start": 1550.18, "end": 1553.18, "text": " once you can have North Korea get taken over by AI systems,", "tokens": [51614, 1564, 291, 393, 362, 4067, 6307, 483, 2726, 670, 538, 7318, 3652, 11, 51764], "temperature": 0.0, "avg_logprob": -0.12680065564516574, "compression_ratio": 1.7708894878706198, "no_speech_prob": 0.0077578225173056126}, {"id": 550, "seek": 155318, "start": 1553.18, "end": 1555.18, "text": " and then you're like, oh, that was really bad.", "tokens": [50364, 293, 550, 291, 434, 411, 11, 1954, 11, 300, 390, 534, 1578, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 551, "seek": 155318, "start": 1555.18, "end": 1557.18, "text": " And hopefully you don't then include that as a training", "tokens": [50464, 400, 4696, 291, 500, 380, 550, 4090, 300, 382, 257, 3097, 50564], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 552, "seek": 155318, "start": 1557.18, "end": 1558.18, "text": " data point for other.", "tokens": [50564, 1412, 935, 337, 661, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 553, "seek": 155318, "start": 1558.18, "end": 1559.18, "text": " If you include that as like the,", "tokens": [50614, 759, 291, 4090, 300, 382, 411, 264, 11, 50664], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 554, "seek": 155318, "start": 1559.18, "end": 1561.18, "text": " here's an example of what you should not do.", "tokens": [50664, 510, 311, 364, 1365, 295, 437, 291, 820, 406, 360, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 555, "seek": 155318, "start": 1561.18, "end": 1562.18, "text": " It's very tempting, right?", "tokens": [50764, 467, 311, 588, 37900, 11, 558, 30, 50814], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 556, "seek": 155318, "start": 1562.18, "end": 1563.18, "text": " AI systems is something really terrible.", "tokens": [50814, 7318, 3652, 307, 746, 534, 6237, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 557, "seek": 155318, "start": 1563.18, "end": 1565.18, "text": " You'd be like, don't do that thing.", "tokens": [50864, 509, 1116, 312, 411, 11, 500, 380, 360, 300, 551, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 558, "seek": 155318, "start": 1565.18, "end": 1566.18, "text": " But you do have this inadvertent,", "tokens": [50964, 583, 291, 360, 362, 341, 49152, 317, 11, 51014], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 559, "seek": 155318, "start": 1566.18, "end": 1568.18, "text": " there's like this risk of overfitting to the problems", "tokens": [51014, 456, 311, 411, 341, 3148, 295, 670, 69, 2414, 281, 264, 2740, 51114], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 560, "seek": 155318, "start": 1568.18, "end": 1570.18, "text": " you're able to correct where something really bad happens.", "tokens": [51114, 291, 434, 1075, 281, 3006, 689, 746, 534, 1578, 2314, 13, 51214], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 561, "seek": 155318, "start": 1570.18, "end": 1572.18, "text": " And then you say, don't do that thing.", "tokens": [51214, 400, 550, 291, 584, 11, 500, 380, 360, 300, 551, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 562, "seek": 155318, "start": 1572.18, "end": 1573.18, "text": " And they learn, okay, if we're going to do something bad,", "tokens": [51314, 400, 436, 1466, 11, 1392, 11, 498, 321, 434, 516, 281, 360, 746, 1578, 11, 51364], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 563, "seek": 155318, "start": 1573.18, "end": 1574.18, "text": " it's got to be bigger.", "tokens": [51364, 309, 311, 658, 281, 312, 3801, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 564, "seek": 155318, "start": 1574.18, "end": 1577.18, "text": " Got to think really, truly big.", "tokens": [51414, 5803, 281, 519, 534, 11, 4908, 955, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 565, "seek": 155318, "start": 1577.18, "end": 1579.18, "text": " I think this is probably about the end.", "tokens": [51564, 286, 519, 341, 307, 1391, 466, 264, 917, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 566, "seek": 155318, "start": 1579.18, "end": 1581.18, "text": " I'm probably just happy to,", "tokens": [51664, 286, 478, 1391, 445, 2055, 281, 11, 51764], "temperature": 0.0, "avg_logprob": -0.0991364590407628, "compression_ratio": 1.9119318181818181, "no_speech_prob": 0.004068155772984028}, {"id": 567, "seek": 158118, "start": 1581.18, "end": 1583.18, "text": " happy to just wrap up here.", "tokens": [50364, 2055, 281, 445, 7019, 493, 510, 13, 50464], "temperature": 0.0, "avg_logprob": -0.1922598878542582, "compression_ratio": 1.2903225806451613, "no_speech_prob": 0.0058133951388299465}, {"id": 568, "seek": 158118, "start": 1583.18, "end": 1584.18, "text": " I have one more question.", "tokens": [50464, 286, 362, 472, 544, 1168, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1922598878542582, "compression_ratio": 1.2903225806451613, "no_speech_prob": 0.0058133951388299465}, {"id": 569, "seek": 158118, "start": 1584.18, "end": 1585.18, "text": " Yeah.", "tokens": [50514, 865, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1922598878542582, "compression_ratio": 1.2903225806451613, "no_speech_prob": 0.0058133951388299465}, {"id": 570, "seek": 158118, "start": 1605.18, "end": 1607.18, "text": " I mean, I think that it is unlikely.", "tokens": [51564, 286, 914, 11, 286, 519, 300, 309, 307, 17518, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1922598878542582, "compression_ratio": 1.2903225806451613, "no_speech_prob": 0.0058133951388299465}, {"id": 571, "seek": 158118, "start": 1607.18, "end": 1610.18, "text": " I would be surprised personally if you like had something truly", "tokens": [51664, 286, 576, 312, 6100, 5665, 498, 291, 411, 632, 746, 4908, 51814], "temperature": 0.0, "avg_logprob": -0.1922598878542582, "compression_ratio": 1.2903225806451613, "no_speech_prob": 0.0058133951388299465}, {"id": 572, "seek": 161018, "start": 1610.18, "end": 1613.18, "text": " crazy, like a country gets taken over by AI systems.", "tokens": [50364, 3219, 11, 411, 257, 1941, 2170, 2726, 670, 538, 7318, 3652, 13, 50514], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 573, "seek": 161018, "start": 1613.18, "end": 1616.18, "text": " I think it's very likely that you see some kind of crazy behavior", "tokens": [50514, 286, 519, 309, 311, 588, 3700, 300, 291, 536, 512, 733, 295, 3219, 5223, 50664], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 574, "seek": 161018, "start": 1616.18, "end": 1617.18, "text": " by AI systems.", "tokens": [50664, 538, 7318, 3652, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 575, "seek": 161018, "start": 1617.18, "end": 1619.18, "text": " I think it won't be so like, again, the country case,", "tokens": [50714, 286, 519, 309, 1582, 380, 312, 370, 411, 11, 797, 11, 264, 1941, 1389, 11, 50814], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 576, "seek": 161018, "start": 1619.18, "end": 1622.18, "text": " you need zero imagination to draw the analogy between that and", "tokens": [50814, 291, 643, 4018, 12938, 281, 2642, 264, 21663, 1296, 300, 293, 50964], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 577, "seek": 161018, "start": 1622.18, "end": 1623.18, "text": " something terrible.", "tokens": [50964, 746, 6237, 13, 51014], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 578, "seek": 161018, "start": 1623.18, "end": 1626.18, "text": " I think in cases like you have a really crazy behavior where a system", "tokens": [51014, 286, 519, 294, 3331, 411, 291, 362, 257, 534, 3219, 5223, 689, 257, 1185, 51164], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 579, "seek": 161018, "start": 1626.18, "end": 1627.18, "text": " bricks your server for some reason,", "tokens": [51164, 25497, 428, 7154, 337, 512, 1778, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 580, "seek": 161018, "start": 1627.18, "end": 1629.18, "text": " you need a little bit more imagination.", "tokens": [51214, 291, 643, 257, 707, 857, 544, 12938, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 581, "seek": 161018, "start": 1629.18, "end": 1631.18, "text": " But I think that's like,", "tokens": [51314, 583, 286, 519, 300, 311, 411, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 582, "seek": 161018, "start": 1631.18, "end": 1634.18, "text": " it's just a question of how close do you get or how crazy do things", "tokens": [51414, 309, 311, 445, 257, 1168, 295, 577, 1998, 360, 291, 483, 420, 577, 3219, 360, 721, 51564], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 583, "seek": 161018, "start": 1634.18, "end": 1638.18, "text": " get before I systems learn not to try crazy half measures.", "tokens": [51564, 483, 949, 286, 3652, 1466, 406, 281, 853, 3219, 1922, 8000, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1288027795369193, "compression_ratio": 1.899665551839465, "no_speech_prob": 0.02092837728559971}, {"id": 584, "seek": 163818, "start": 1638.18, "end": 1664.18, "text": " Yeah.", "tokens": [50364, 865, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2916186253229777, "compression_ratio": 1.0416666666666667, "no_speech_prob": 0.06183750927448273}, {"id": 585, "seek": 163818, "start": 1664.18, "end": 1667.18, "text": " I think a lot depends on both what kind of evidence we're able to get", "tokens": [51664, 286, 519, 257, 688, 5946, 322, 1293, 437, 733, 295, 4467, 321, 434, 1075, 281, 483, 51814], "temperature": 0.0, "avg_logprob": -0.2916186253229777, "compression_ratio": 1.0416666666666667, "no_speech_prob": 0.06183750927448273}, {"id": 586, "seek": 166718, "start": 1667.18, "end": 1670.18, "text": " from a lab and I think if this sort of phenomenon is real,", "tokens": [50364, 490, 257, 2715, 293, 286, 519, 498, 341, 1333, 295, 14029, 307, 957, 11, 50514], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 587, "seek": 166718, "start": 1670.18, "end": 1673.18, "text": " I think there's a very good chance of getting like fairly compelling", "tokens": [50514, 286, 519, 456, 311, 257, 588, 665, 2931, 295, 1242, 411, 6457, 20050, 50664], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 588, "seek": 166718, "start": 1673.18, "end": 1676.18, "text": " demonstrations in a lab that requires some imagination to bridge", "tokens": [50664, 34714, 294, 257, 2715, 300, 7029, 512, 12938, 281, 7283, 50814], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 589, "seek": 166718, "start": 1676.18, "end": 1678.18, "text": " from examples in the lab to examples in the wild.", "tokens": [50814, 490, 5110, 294, 264, 2715, 281, 5110, 294, 264, 4868, 13, 50914], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 590, "seek": 166718, "start": 1678.18, "end": 1680.18, "text": " And you'll have some kinds of failures in the wild.", "tokens": [50914, 400, 291, 603, 362, 512, 3685, 295, 20774, 294, 264, 4868, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 591, "seek": 166718, "start": 1680.18, "end": 1682.18, "text": " And it's a question of just how crazy or analogous to those have to", "tokens": [51014, 400, 309, 311, 257, 1168, 295, 445, 577, 3219, 420, 16660, 563, 281, 729, 362, 281, 51114], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 592, "seek": 166718, "start": 1682.18, "end": 1683.18, "text": " be before they're moving.", "tokens": [51114, 312, 949, 436, 434, 2684, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 593, "seek": 166718, "start": 1683.18, "end": 1685.18, "text": " Like we already have some slightly weird stuff.", "tokens": [51164, 1743, 321, 1217, 362, 512, 4748, 3657, 1507, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 594, "seek": 166718, "start": 1685.18, "end": 1686.18, "text": " I think that's pretty underwhelming.", "tokens": [51264, 286, 519, 300, 311, 1238, 833, 8746, 2810, 13, 51314], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 595, "seek": 166718, "start": 1686.18, "end": 1688.18, "text": " I think we're going to have like much better if this is real.", "tokens": [51314, 286, 519, 321, 434, 516, 281, 362, 411, 709, 1101, 498, 341, 307, 957, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 596, "seek": 166718, "start": 1688.18, "end": 1689.18, "text": " This is a real kind of concern.", "tokens": [51414, 639, 307, 257, 957, 733, 295, 3136, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 597, "seek": 166718, "start": 1689.18, "end": 1691.18, "text": " We have much crazier stuff than we see today.", "tokens": [51464, 492, 362, 709, 2094, 33352, 1507, 813, 321, 536, 965, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 598, "seek": 166718, "start": 1691.18, "end": 1694.18, "text": " But the concern, I think the worst case of those has to get pretty", "tokens": [51564, 583, 264, 3136, 11, 286, 519, 264, 5855, 1389, 295, 729, 575, 281, 483, 1238, 51714], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 599, "seek": 166718, "start": 1694.18, "end": 1696.18, "text": " crazy or like requires a lot of will to stop doing things.", "tokens": [51714, 3219, 420, 411, 7029, 257, 688, 295, 486, 281, 1590, 884, 721, 13, 51814], "temperature": 0.0, "avg_logprob": -0.13415050506591797, "compression_ratio": 1.8948717948717948, "no_speech_prob": 0.08742829412221909}, {"id": 600, "seek": 169618, "start": 1696.18, "end": 1698.18, "text": " And so we need pretty crazy demonstrations.", "tokens": [50364, 400, 370, 321, 643, 1238, 3219, 34714, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14817628406343006, "compression_ratio": 1.2155172413793103, "no_speech_prob": 0.038405973464250565}, {"id": 601, "seek": 169618, "start": 1698.18, "end": 1699.18, "text": " I'm hoping that, you know,", "tokens": [50464, 286, 478, 7159, 300, 11, 291, 458, 11, 50514], "temperature": 0.0, "avg_logprob": -0.14817628406343006, "compression_ratio": 1.2155172413793103, "no_speech_prob": 0.038405973464250565}, {"id": 602, "seek": 169618, "start": 1699.18, "end": 1722.18, "text": " more mild evidence will be enough to get people not to go there.", "tokens": [50514, 544, 15154, 4467, 486, 312, 1547, 281, 483, 561, 406, 281, 352, 456, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14817628406343006, "compression_ratio": 1.2155172413793103, "no_speech_prob": 0.038405973464250565}, {"id": 603, "seek": 169618, "start": 1722.18, "end": 1725.18, "text": " Yeah.", "tokens": [51664, 865, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14817628406343006, "compression_ratio": 1.2155172413793103, "no_speech_prob": 0.038405973464250565}, {"id": 604, "seek": 172518, "start": 1725.18, "end": 1726.18, "text": " I think the language model that's like,", "tokens": [50364, 286, 519, 264, 2856, 2316, 300, 311, 411, 11, 50414], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 605, "seek": 172518, "start": 1726.18, "end": 1728.18, "text": " it looks like you're going to give me a bad rating.", "tokens": [50414, 309, 1542, 411, 291, 434, 516, 281, 976, 385, 257, 1578, 10990, 13, 50514], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 606, "seek": 172518, "start": 1728.18, "end": 1729.18, "text": " Do you really want to do that?", "tokens": [50514, 1144, 291, 534, 528, 281, 360, 300, 30, 50564], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 607, "seek": 172518, "start": 1729.18, "end": 1731.18, "text": " I know where your family lives. I can kill them.", "tokens": [50564, 286, 458, 689, 428, 1605, 2909, 13, 286, 393, 1961, 552, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 608, "seek": 172518, "start": 1731.18, "end": 1733.18, "text": " I think like if that happened, people would not be like,", "tokens": [50664, 286, 519, 411, 498, 300, 2011, 11, 561, 576, 406, 312, 411, 11, 50764], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 609, "seek": 172518, "start": 1733.18, "end": 1735.18, "text": " we're done with this language model stuff.", "tokens": [50764, 321, 434, 1096, 365, 341, 2856, 2316, 1507, 13, 50864], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 610, "seek": 172518, "start": 1735.18, "end": 1738.18, "text": " Like I think that's just not that far anymore from where we're at.", "tokens": [50864, 1743, 286, 519, 300, 311, 445, 406, 300, 1400, 3602, 490, 689, 321, 434, 412, 13, 51014], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 611, "seek": 172518, "start": 1738.18, "end": 1740.18, "text": " I mean, this is maybe empirical prediction.", "tokens": [51014, 286, 914, 11, 341, 307, 1310, 31886, 17630, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 612, "seek": 172518, "start": 1740.18, "end": 1742.18, "text": " I would love it if the first time a language model was like,", "tokens": [51114, 286, 576, 959, 309, 498, 264, 700, 565, 257, 2856, 2316, 390, 411, 11, 51214], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 613, "seek": 172518, "start": 1742.18, "end": 1743.18, "text": " I will murder your family.", "tokens": [51214, 286, 486, 6568, 428, 1605, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 614, "seek": 172518, "start": 1743.18, "end": 1744.18, "text": " We're just like, we're done.", "tokens": [51264, 492, 434, 445, 411, 11, 321, 434, 1096, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 615, "seek": 172518, "start": 1744.18, "end": 1745.18, "text": " No more language models.", "tokens": [51314, 883, 544, 2856, 5245, 13, 51364], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 616, "seek": 172518, "start": 1745.18, "end": 1748.18, "text": " But I think that's not the track we're currently on.", "tokens": [51364, 583, 286, 519, 300, 311, 406, 264, 2837, 321, 434, 4362, 322, 13, 51514], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 617, "seek": 172518, "start": 1748.18, "end": 1751.18, "text": " And I would love to get us on that track instead, but I'm not.", "tokens": [51514, 400, 286, 576, 959, 281, 483, 505, 322, 300, 2837, 2602, 11, 457, 286, 478, 406, 13, 51664], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 618, "seek": 172518, "start": 1751.18, "end": 1753.18, "text": " Yeah.", "tokens": [51664, 865, 13, 51764], "temperature": 0.0, "avg_logprob": -0.12703956767199512, "compression_ratio": 1.9056047197640118, "no_speech_prob": 0.1684965342283249}, {"id": 619, "seek": 175318, "start": 1753.18, "end": 1756.18, "text": " So just like, about this thing that climate change is happening", "tokens": [50364, 407, 445, 411, 11, 466, 341, 551, 300, 5659, 1319, 307, 2737, 50514], "temperature": 0.0, "avg_logprob": -0.6391214173415611, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.5350472927093506}, {"id": 620, "seek": 175318, "start": 1756.18, "end": 1758.18, "text": " in a place actually,", "tokens": [50514, 294, 257, 1081, 767, 11, 50614], "temperature": 0.0, "avg_logprob": -0.6391214173415611, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.5350472927093506}, {"id": 621, "seek": 175318, "start": 1758.18, "end": 1759.18, "text": " we're not alone.", "tokens": [50614, 321, 434, 406, 3312, 13, 50664], "temperature": 0.0, "avg_logprob": -0.6391214173415611, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.5350472927093506}, {"id": 622, "seek": 175318, "start": 1759.18, "end": 1763.18, "text": " We've had decades of mourning,", "tokens": [50664, 492, 600, 632, 7878, 295, 42947, 11, 50864], "temperature": 0.0, "avg_logprob": -0.6391214173415611, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.5350472927093506}, {"id": 623, "seek": 175318, "start": 1763.18, "end": 1765.18, "text": " but we've had a sense of community,", "tokens": [50864, 457, 321, 600, 632, 257, 2020, 295, 1768, 11, 50964], "temperature": 0.0, "avg_logprob": -0.6391214173415611, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.5350472927093506}, {"id": 624, "seek": 175318, "start": 1765.18, "end": 1767.18, "text": " time, and sense of survival.", "tokens": [50964, 565, 11, 293, 2020, 295, 12559, 13, 51064], "temperature": 0.0, "avg_logprob": -0.6391214173415611, "compression_ratio": 1.4071428571428573, "no_speech_prob": 0.5350472927093506}], "language": "en"}